{"cell_type":{"a8ea6904":"code","131f3f5a":"code","1579c7d0":"code","87f34097":"code","f229177a":"code","e4c95850":"code","a03522a4":"code","3ca6f90f":"code","9b837de7":"code","6303cc48":"code","b17c4a59":"code","176d0ad4":"code","98dbf4c1":"code","229254ce":"code","e249dbad":"code","e930742d":"code","860cec4c":"code","4815f1ae":"code","50f779b6":"code","5f22be32":"code","923fd498":"code","541c3932":"code","9b877adb":"code","7c5d09c8":"code","03d01e84":"code","fed20f35":"code","48f9f01d":"code","ceb9254e":"code","33003896":"code","24991f27":"code","2fa701ac":"code","d035dd5c":"code","3b754a32":"code","10253098":"code","a7d9f117":"code","3169a6d0":"code","08083c0b":"code","5441d43a":"code","e389d80c":"code","1e8470a3":"code","26385fba":"code","3d523985":"markdown","add9949c":"markdown","f3bb0840":"markdown","ec293387":"markdown","759a82d7":"markdown","7b6139f0":"markdown","906393b0":"markdown","a2cca810":"markdown","39ca5f21":"markdown","dd684ca0":"markdown"},"source":{"a8ea6904":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","131f3f5a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom matplotlib import pyplot\nimport seaborn as sn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nimport sklearn\nfrom sklearn import preprocessing\n","1579c7d0":"path = '..\/input\/health-insurance-cross-sell-prediction\/'\ntrain_df = pd.read_csv(path + \"train.csv\")\ntest_df = pd.read_csv(path + \"test.csv\")","87f34097":"print(\"The Shape of Train Data Set :\",train_df.shape)\nprint(\"The Shape of Test Data Set :\", test_df.shape)","f229177a":"print(\"Columns of Train Data Set: \\n\",train_df.columns)\nprint(\"-------------------------\")\nprint(\"-------------------------\")\nprint(\"Columns of Test Data Set: \\n\",test_df.columns)","e4c95850":"train_df.head(4)","a03522a4":"train_df.info()","3ca6f90f":"sn.countplot(x=\"Gender\", data = train_df)","9b837de7":"sn.countplot(x=\"Driving_License\", data = train_df)","6303cc48":"sn.countplot(x=\"Previously_Insured\", data = train_df)","b17c4a59":"sn.countplot(x=\"Vehicle_Age\", data = train_df)","176d0ad4":"sn.countplot(x=\"Vehicle_Damage\", data = train_df)","98dbf4c1":"sn.countplot(x=\"Response\", data = train_df)","229254ce":"sn.distplot(train_df.Age)","e249dbad":"sn.distplot(train_df.Annual_Premium)","e930742d":"Numerical_Features = ['Age', 'Driving_License', 'Vehicle_Age','Annual_Premium','Vintage']\ntrain_df[Numerical_Features].describe()","860cec4c":"fig = plt.figure(figsize =(10, 7)) \nplt.boxplot(train_df.Age) \nplt.show() ","4815f1ae":"fig = plt.figure(figsize =(8, 7)) \nplt.boxplot(train_df.Annual_Premium) \nplt.show() ","50f779b6":"fig = plt.figure(figsize =(8, 7)) \nplt.boxplot(train_df.Vintage) \nplt.show() ","5f22be32":"train_df[Numerical_Features].corr()","923fd498":"X= train_df[['Gender', 'Age', 'Driving_License', 'Region_Code','Previously_Insured', 'Vehicle_Age','Vehicle_Damage', 'Annual_Premium','Policy_Sales_Channel', 'Vintage']]\ny= train_df['Response']","541c3932":"#there is some categorical features that need to be encoded\nX_features = list(X.columns)\nencoded_Data_df= pd.get_dummies(X[X_features],drop_first=True)\nX=encoded_Data_df","9b877adb":"radm_clf = RandomForestClassifier( max_depth=15,n_estimators=20,max_features = 'auto')\n## Fitting the model with the training set\nradm_clf.fit(X,y )","7c5d09c8":"feature_rank = pd.DataFrame( { 'feature': X.columns,'importance': radm_clf.feature_importances_ } )\n## Sorting the features based on their importances with mosti important feature at top.\nfeature_rank = feature_rank.sort_values('importance', ascending =False)\nplt.figure(figsize=(8, 6))\nsn.barplot( y = 'feature', x = 'importance', data = feature_rank )","03d01e84":"sn.countplot(\"Response\", data=train_df)","fed20f35":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)","48f9f01d":"print(\"Shape of X after over-Sampling:\", X.shape)\nprint(\"Shape of y after over-Sampling:\", y.shape)","ceb9254e":"sn.countplot(y)","33003896":"#Dropping feature \"Driving_License\"\nX= X.drop(['Driving_License'],axis=1)","24991f27":"## Initializing the StandardScaler\nX_scaler = StandardScaler()\n## Standardize all the feature columns\nX_scaled = X_scaler.fit_transform(X)\nX=X_scaled","2fa701ac":"#Splitting the dataset into the traing set and test set\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=43)","d035dd5c":"gboost_clf = GradientBoostingClassifier()","3b754a32":"gboost_clf.fit(X_train,y_train)","10253098":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","a7d9f117":"def plot_ROC(fpr, tpr, m_name):\n    roc_auc = sklearn.metrics.auc(fpr, tpr)\n    plt.figure(figsize=(10,8))\n    lw = 2\n    plt.plot(fpr, tpr, color='blue',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)    \n    plt.plot([0, 1], [0, 1], color='red', lw=lw, linestyle='--', alpha=0.5)    \n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.grid(True)\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.title('Receiver operating characteristic for %s'%m_name, fontsize=20)\n    plt.legend(loc=\"lower right\", fontsize=16)\n    plt.show()","3169a6d0":"Gboost_preds = gboost_clf.predict_proba(X_test)\nGboost_class = gboost_clf.predict(X_test)\nGboost_score = roc_auc_score(y_test, Gboost_preds[:,1], average = 'weighted')\n(fpr, tpr, thresholds) = roc_curve(y_test, Gboost_preds[:,1])\nplot_ROC(fpr, tpr, 'Gboost')","08083c0b":"#there is some categorical features that need to be encoded\nFeatures = list(test_df.columns)\nencoded_Data_df= pd.get_dummies(test_df[Features],drop_first=True)\ntest_df=encoded_Data_df","5441d43a":"Test = test_df.drop([\"id\",\"Driving_License\"],axis=1)\nTest.head(4)","e389d80c":"pred = gboost_clf.predict(Test)","1e8470a3":"submit = pd.DataFrame(index=test_df.index)\nsubmit[\"id\"] = test_df.id\nsubmit[\"Response\"] = pred\nsubmit.set_index('id').reset_index(inplace=True)\nsubmit.head()","26385fba":"submit.to_csv(\"Submission.csv\")","3d523985":"# preparing & submitting the final result","add9949c":"**Importing Required Libraries **","f3bb0840":"# Since Data Set is impbalanced, I will use SMOTE to balance the representation of Response Feature in the data set","ec293387":"# Gradient Boosting Classifier","759a82d7":"# Exploring Data Set","7b6139f0":"# Shape of Training & Test Data Set","906393b0":"# Columns of Test & Train Data Set","a2cca810":"# Driving_License is not a significant feature and hence will drop from model building ","39ca5f21":"# **Importing Data Set**","dd684ca0":"# Feature Selection For Model "}}