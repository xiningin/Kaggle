{"cell_type":{"450a20af":"code","bd98dc8d":"code","ce38a82f":"code","7a1ad677":"code","514dea41":"code","4a04036a":"code","377c59d3":"code","5b77d7c2":"code","55f71832":"code","02770997":"code","1a78727e":"code","28a128c2":"code","d9282d02":"code","023678e2":"code","c75665fe":"code","9e62c612":"code","45355f56":"markdown","ea549499":"markdown","a585037d":"markdown","22b5803e":"markdown","cba67228":"markdown","66e85d16":"markdown","0c4ff7c9":"markdown","c46d4a6d":"markdown","17e522d1":"markdown"},"source":{"450a20af":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","bd98dc8d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import initializers\nfrom keras.optimizers import Adam","ce38a82f":"generator = Sequential()\ngenerator.add(layers.Dense(256, input_shape=(100,), kernel_initializer=initializers.RandomNormal(stddev = 0.02)))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(512))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(1024))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(28*28, activation='tanh'))","7a1ad677":"optimizer = Adam(lr=0.0002, beta_1=0.5)\ngenerator.compile(optimizer= optimizer, loss='binary_crossentropy')\ngenerator.summary()","514dea41":"def generate_images(count=1):\n    input = np.random.normal(0, 1, size=[count, 100])\n    images = generator.predict(input)\n    images *= 255 # pixels should be in range 0-255\n    images = images.reshape((count, 28, 28))\n    return images\n    ","4a04036a":"image = generate_images(3)\nplt.figure(figsize=(15,5))\nfor i in range(3):\n    plt.subplot('13{0}'.format(i+1))\n    plt.imshow(image[i], cmap='gray')\nplt.show()","377c59d3":"discriminator = Sequential()\ndiscriminator.add(layers.Dense(1024, input_dim=784))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(512))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(256))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(1, activation='sigmoid'))\n","5b77d7c2":"discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\ndiscriminator.summary()","55f71832":"gan = Sequential()\ngan.add(generator)\ndiscriminator.trainable = False\ngan.add(discriminator)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')\ngan.summary()","02770997":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nsamples = train_data.drop(columns='label').values\nsamples = samples\/255 - 1","1a78727e":"history = pd.DataFrame(columns=['d_loss', 'd_acc', 'gan_loss'])","28a128c2":"\ndef train(batch_size=32, epochs=1):\n    half_batch_size = np.floor(batch_size\/2).astype(np.int32)\n    steps = int(len(samples)\/batch_size)\n    for epoch in range(epochs):\n        for step in range(steps):\n            y = np.zeros(batch_size) #fake_images\n            y[:half_batch_size] = 0.9  # real images\n            generated_images = generator.predict(np.random.normal(0, 1, size=[half_batch_size, 100]))\n            real_images = samples[np.random.randint(0, samples.shape[0], size=half_batch_size)]\n            x = np.concatenate((generated_images,real_images))\n            discriminator.trainable = True\n            d_metrics = discriminator.train_on_batch(x, y)\n            noise = np.random.normal(0, 1, size=[batch_size, 100])\n            discriminator.trainable = False\n            gan_loss = gan.train_on_batch(noise, np.zeros(batch_size))\n            history.loc[epoch*steps+steps] = [d_metrics[0], d_metrics[1], gan_loss]\n        # visualize training progress\n        str = f'Epoch {epoch}: [D loss: {d_metrics[0]} acc: {d_metrics[1]}] | [G loss: {gan_loss}'\n        print(str)\n        images = generate_images(9)\n        plt.figure(figsize=(15,5))\n        for i in range(9):\n            plt.subplot('19{0}'.format(i+1))\n            plt.imshow(images[i], cmap='gray_r' ,interpolation='nearest')\n        plt.show()\n\n\n    return history","d9282d02":"history = train(batch_size=128, epochs=20)","023678e2":"plt.figure(figsize=(15, 5))\nplt.title('Discriminator loss')\nplt.plot(history['d_loss'])","c75665fe":"plt.figure(figsize=(15, 5))\nplt.title('GAN loss')\nplt.plot(history['gan_loss'])","9e62c612":"images = generate_images(9)\nplt.figure(figsize=(15,5))\nfor i in range(9):\n    plt.subplot('19{0}'.format(i+1))\n    plt.imshow(images[i], cmap='gray_r' ,interpolation='nearest')\nplt.savefig('generated_digits.png')","45355f56":"Descriminator loss","ea549499":"## GAN - Generative Adversarial Network","a585037d":"Untrained generator generates something like that","22b5803e":"### training","cba67228":"GAN loss","66e85d16":"Generator as an input will take vector of length 100 with random numbers in range (0, 1)","0c4ff7c9":"Discriminator will try to detect if the input image is made by generator or it is real.","c46d4a6d":"## Discriminator","17e522d1":"## Generator"}}