{"cell_type":{"c5c91ebf":"code","e55621ad":"code","a3a9848f":"code","1958a183":"code","1333fc9f":"code","ebdad08e":"code","a820dcbc":"code","a54c837a":"code","19d82d9b":"code","2842cfee":"code","585a60b9":"code","353d3859":"markdown","6fe09be1":"markdown","0ce8c8f3":"markdown"},"source":{"c5c91ebf":"# Importing all the required libraries\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline\n","e55621ad":"# Checking the directory \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","a3a9848f":"# Visually Inspect Image Dataset \n\ninput_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human'\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 7))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train', 'validation']):\n    set_path = input_path+'\/'+_set\n    ax[i].imshow(plt.imread(set_path+'\/horses\/'+os.listdir(set_path+'\/horses')[0]), cmap='gray')\n    ax[i].set_title('Set: {}, type:horses'.format(_set))\n    ax[i+2].imshow(plt.imread(set_path+'\/humans\/'+os.listdir(set_path+'\/humans')[0]), cmap='gray')\n    ax[i+2].set_title('Set: {}, type:humans'.format(_set))\n    ","1958a183":"# Image Preprocessing\n\ninput_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human'\n\ndef process_data(img_dims, batch_size):\n  \n   \n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=input_path + '\/train\/', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=input_path + '\/validation\/', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n\n    return train_gen, test_gen","1333fc9f":"# Hyperparameters\n\nimg_dims = 200\nepochs = 10\nbatch_size = 20\n","ebdad08e":"# Getting the data\ntrain_gen, test_gen = process_data(img_dims, batch_size)","a820dcbc":"#Inception V3 \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\npre_trained_model = InceptionV3(input_shape=(200,200,3),include_top=False,weights='imagenet')\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n\npre_trained_model.summary()","a54c837a":"# Fully Connected Layer\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nDl_1 = tf.keras.layers.Dropout(rate = 0.2)\npre_prediction_layer = tf.keras.layers.Dense(180, activation='relu')\nDl_2 = tf.keras.layers.Dropout(rate = 0.2)\nprediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\n\n\nmodel_V3 = tf.keras.Sequential([\n  pre_trained_model,\n  global_average_layer,\n  Dl_1,\n  pre_prediction_layer,\n  Dl_2,\n  prediction_layer\n])","19d82d9b":"#Compiling Fully Connected Layer\nmodel_V3.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel_V3.summary()\n","2842cfee":"# I will be using the following to reduce the learning rate by the factor of 0.2 when the 'val_loss' will increase in consecutive 3 epochs.\n# Callbacks \nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=2, mode='max')","585a60b9":"#Fitting the model\nhist = model_V3.fit_generator(\n           train_gen, steps_per_epoch=50, \n           epochs=10, validation_data=test_gen, \n           validation_steps=12 , callbacks=[lr_reduce])\n","353d3859":"As seen from above **Training loss (0.5087)** is just above the **Validation loss(0.5068**) model is working quite extraordinary .Considering the powerful nature of the inception v3 , it has accurately guessed  almost all the samples of the validation set at the end. Seems that validation set has simplier examples than the training set .","6fe09be1":"**WHAT IS TRANFER LEARNING ?**\nTransfer learning refers to a technique for predictive modeling on a different but somehow similar problem that can then be reused partly or wholly to accelerate the training and improve the performance of a model on the problem of interest.\n\nIn deep learning, this means reusing the weights in one or more layers from a pre-trained network model in a new model and either keeping the weights fixed, fine tuning them, or adapting the weights entirely when training the model.\n\n**WHAT IS INCEPTION V3?**\nCheck out the following link by the google ai on Inception V3.\nhttps:\/\/ai.googleblog.com\/2016\/03\/train-your-own-image-classifier-with.html","0ce8c8f3":"Hey reader , I will be using the dataset \"Horses Vs Humans\" for this computer problem . \n\n*About the Data :\nThe set contains 500 rendered images of various species of horse in various poses in various locations. It also contains 527 rendered images of humans in various poses and locations. Emphasis has been taken to ensure diversity of humans, and to that end there are both men and women as well as Asian, Black, South Asian and Caucasians present in the training set. The validation set adds 6 different figures of different gender, race and pose to ensure breadth of dat*\n"}}