{"cell_type":{"b64e0645":"code","0fc2878d":"code","fee99342":"code","af7cd143":"code","cdd2fa0f":"code","bdb49640":"code","bb46901e":"code","c7d1130b":"markdown","b5204c15":"markdown","34708691":"markdown","9c05f05e":"markdown","5db4c5f8":"markdown","e2509163":"markdown","4924a840":"markdown","35aa5a71":"markdown","6c811440":"markdown","770b9f53":"markdown","15ad2a04":"markdown","b0ed52f8":"markdown"},"source":{"b64e0645":"import numpy as np  # linear algebra\nimport pandas as pd  # data manipulation and processing\nimport matplotlib.pyplot as plt  # data visualization\nimport seaborn as sns  # more attractive visualizations\nimport statsmodels.api as sm  # will help us apply regression model","0fc2878d":"sns.set()  # (optional), will make all matplotlib visualizations appear in seaborn skins","fee99342":"data = pd.read_csv(\"..\/input\/real-estate-price-size-year\/real_estate_price_size_year.csv\")\ndata.head()","af7cd143":"y = data[\"price\"]  # inferred\nx1 = data[[\"size\", \"year\"]]  # regressors, data[<array of regressors>]","cdd2fa0f":"plt.scatter(y, data[\"size\"])  # plotting prices against sizes\nplt.xlabel(\"price\")\nplt.ylabel(\"size\")\nplt.show()\nplt.scatter(y, data[\"year\"])  # plotting prices against years\nplt.xlabel(\"price\")\nplt.ylabel(\"year\")\nplt.show()","bdb49640":"x = sm.add_constant(x1)  # adding constant (i.e. coefficient of b0, all of them will be 1)\nresults = sm.OLS(y, x).fit()\nresults.summary()","bb46901e":"y_hat = -5.772e+06 + (227.7009 * data[\"size\"]) + (2916.7853 * data[\"year\"])","c7d1130b":"**Foreword:** This notebook was maintained simultaneously when I was learning Linear Regression. This notebook is second part of the three-notebook series, which tend to explain process of applying Linear Regression on a dataset. You can find all parts by clicking given links:\n\n[**1. First Linear Regression Model**](https:\/\/www.kaggle.com\/salmankhi\/my-first-regression-mode)\n\n[**2. Multiple Variable Linear Regression Model**](https:\/\/www.kaggle.com\/salmankhi\/multiple-linear-regression)\n\n[**3. Linear Regression on Categorical Data**](https:\/\/www.kaggle.com\/salmankhi\/regression-on-categorical-data)","b5204c15":"## 4. Visualization:\nIt is not possible to plot a y and x1 on single graph, as they both are not of same size.\n\nWhat can we do instead, is plot size and year against price individually to check whether they both are in linear relationship with price or not.\n\nIf any of the regressor shows non linear relationship with the dependent variable we can not continue our multiple linear regression model with having that particular regressor.","34708691":"## 1. Importing Libraries","9c05f05e":"## 6. Substituting values in Multiple Linear Regression Equation\n\nWe will not be plotting regression for this example as it is not in 2D. But, we can find a price of a house for given 'size' and 'year' of construction by using following equation.","5db4c5f8":"Like for house of size = 500 and year = 2018, predicted price is 227923,\n\nfor house of size = 700 and year = 2020, predicted price is 279296\n\nand for house of size = 300 and year = 1980, predicted price is 123483.","e2509163":"Both the regressors do not seem to be in non linear relationship with the dependent variable here, so we can continue applying regression on them.","4924a840":"## 2. Reading Data","35aa5a71":"## 5. Applying Multiple Linear Regression","6c811440":"**Now for the example of Multiple Linear Regression Model,** we will be using the same real estate data we used earlier for Simple Linear Regression with added column having year of construction in it. And we will add year as second regressor to our model.","770b9f53":"## Multiple Linear Regression\n\nIn most cases, the variability of the dependent variable 'y' can not be defined by taking only one explanatory variable under consideration and some other variables ('x1', 'x2',..., 'xk') must be taken into account to get better model.\n\nWhen there are multiple independant variables (or regressors) to affect dependent variable, we use **Multiple Linear Regression.** It is quite similar to Simple Linear Regression, but instead of getting a two dimensional regression line, we get nth dimensional object which, if is more than three dimensional, can not be visualized.\n\n**Multiple Linear Regression Equation**\n\n<center>for population:Y = \u03b20 + \u03b21*x1 + \u03b22*x2 +...+ \u03b2k*xk + error<\/center>\n\n<center>for sample: y_hat = b0 + b1*x1 + b2*x2 +...+ bk*xk<\/center>\n\nwhere, y - inferred variable, x - regressors, b\/\u03b2 - coefficients of regressors","15ad2a04":"**Summary tells us,**\n- b0 = -5.772e+06\n- b1 = 227.7009\n- b2 = 2916.7853\n- P>|t| for all of the coefficients is 0.000, meaning each regressor is driving the variability of 'y'\n- P-Vale of f-statistics is very small, we can reject the H0 that b1 = b2 = 0","b0ed52f8":"## 3. Saving Dependent Variable and Regressors"}}