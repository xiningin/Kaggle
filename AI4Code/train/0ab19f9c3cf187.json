{"cell_type":{"30fdace3":"code","878bcad8":"code","72327da4":"code","56d9f3a1":"code","64f5e3af":"code","14f3d869":"code","38e9c904":"code","7ae1dd2f":"code","03e96f85":"code","866804bd":"code","4cd0c952":"code","d300231a":"code","27ca34a7":"code","07662aeb":"code","efdcd02f":"code","4ca6fad6":"code","f3ca72c8":"code","4586ed0a":"code","29eb1b46":"code","3c036f14":"code","52c3be93":"code","a0dcdb8f":"code","91b40187":"code","f361629f":"code","d91d1201":"code","f88a5bae":"code","39d6755d":"code","54af0c8e":"code","308208eb":"code","cc9301e7":"code","8860cf8f":"code","f0373dd1":"code","2abb8f6f":"code","0f486110":"code","c9630694":"code","b75fcc57":"code","a7e231a7":"code","a24d413c":"code","131fa5eb":"code","023457ee":"code","0ab47c9a":"code","409437d4":"code","df9db5ec":"code","24a80c6b":"code","7f5002e6":"code","afb609f8":"code","3e5d95cc":"code","076fc9ed":"code","439061fc":"markdown","dfb20cd7":"markdown","7ba15ef0":"markdown","c74627cd":"markdown","11e7733f":"markdown","88e99616":"markdown","94e2b212":"markdown","42a630ef":"markdown","16821677":"markdown","2d7a1ef8":"markdown","e100f18c":"markdown","39ec4863":"markdown","0f1a5a11":"markdown","a9475754":"markdown","0b7f4f36":"markdown","1e40beb8":"markdown","05fafc72":"markdown","5f62b470":"markdown","3bfde3b1":"markdown","02fe6f27":"markdown","b56e3d4e":"markdown","62ac4b1a":"markdown","0b7f5dc1":"markdown","90ed0476":"markdown","71ca9f1d":"markdown"},"source":{"30fdace3":"# Importa a biblioteca de express\u00e3o regular ou regular expression (re)\nimport re\n\n# Encontra a palavra ab no texto abcdef\nprint(re.match('ab', 'abcde'))\n\n# Procura pela palavra zz no texto abcde mas nao encontra nada\nprint(re.match('zz', 'abcde'))","878bcad8":"# Extrair cada palavra usando \u201c*\u201d \nprint(re.findall('\\w*','IPEA - Instituto de Pesquisa Economica Aplicada'))","72327da4":"# Extrair cada palavra usando \u201c*\u201d. Agora vamos remover os espa\u00e7os com \u201c+\u201d.\nprint(re.findall(r'\\w+','IPEA - Instituto de Pesquisa Economica Aplicada'))","56d9f3a1":"print(re.findall('\\w+','IPEA Instituto'))","64f5e3af":"# Extrai a \u00faltima palavra\nprint(re.findall(r'\\w+$','IPEA - Instituto de Pesquisa Economica Aplicada'))","14f3d869":"# Extrai a data de uma string. Usamos o \\d para extrair os d\u00edgitos.\nresult=re.findall(r'\\d{2}-\\d{2}-\\d{4}','Amit 34-3456 12-05-2007, XYZ 56-4532 11-11-2011, ABC 67-8945 12-01-2009') \nprint(result)","38e9c904":"# Insere uma nova linha a cada . ? ou !\ntexto = 'IPEA. Instituto de Pesquisa Aplicada! Bras\u00edlia-DF.'\nre.split(\"[.]\", texto)","7ae1dd2f":"# 1. Crie um texto com o seguinte conte\u00fado: \"A explos\u00e3o aconteceu em 2005, por\u00e9m s\u00f3 em 2012 foram desvendadas as causas do acidente.\"\ntexto = 'A explos\u00e3o aconteceu em 2005, por\u00e9m s\u00f3 em 2012 foram desvendadas as causas do acidente.'\n# 2. Encontre e imprima apenas os n\u00fameros do texto criado para capturarmos os anos citados no texto.\nprint(re.findall('\\d+',texto))\n# 3. Substitua todas as v\u00edrgulas por . e atribua a variavel de nome igual a texto2. Imprima texto2\ntexto2 = re.sub(',','.',texto)\n# 4. Divida o texto2 onde tiver . e imprima o resultado\nprint(re.split('\\.',texto2))","03e96f85":"# Vamos criar um Dicion\u00e1rio Goiano\ndicionario = '''Ca\u00e7ar - Goiano n\u00e3o procura, goiano ca\u00e7a, Ex: N\u00e3o sei onde est\u00e1, mas vou ca\u00e7ar esse papel para voc\u00ea.\nTrem - Qualquer coisa pode ser chamada de trem, inclusive um trem, Ex: \u00d4\u00f4\u00f4 trem b\u00e3o (\u00f4, coisa boa), J\u00e1 ouvi at\u00e9 mesmo a seguinte declara\u00e7\u00e3o de amor: Te amo, Trem!.\nDimais da conta - Em Goi\u00e1s, deve-se evitar utilizar a palavra \u201cdemais\u201d isolada, a forma correta \u00e9 \u201cdemais da conta\u201d, Ex: Gosto disso demais da conta, Conhe\u00e7o demais da conta!\nCustoso - Teimoso, Tamb\u00e9m ou\u00e7o como se fosse algo que d\u00ea trabalho, Ex: Esse moleque \u00e9 custoso demais da conta, Quando se encontra uma crian\u00e7a sempre se diz: e\u00eah,qui mininu custoso!\nPegou - \u00c9 usado em di\u00e1logos desta maneira: \" Eu tava l\u00e1 em casa v\u00eanu TV a\u00ed meu pai PEGOU e fal\u00f4 assim \u00f3.\n'''\ndicionario","866804bd":"# Transforma\u00e7\u00e3o de letras para min\u00fasculas\ndicionario = dicionario.lower()\ndicionario","4cd0c952":"frase = \"Be happy. Don't worry. Be happy!\"","d300231a":"# Tokenization de palavras\nfrom nltk.tokenize import word_tokenize\nword_tokenize('Voc\u00ea vai ter um \u00f3timo dia hoje!')","27ca34a7":"# Cria uma sequencia de tokens unicos\nunique_tokens = set(word_tokenize(frase))\nunique_tokens","07662aeb":"frase","efdcd02f":"# Tokenization de senten\u00e7as.\nfrom nltk.tokenize import sent_tokenize\nfrases = sent_tokenize(frase)\nfrases","4ca6fad6":"from nltk.tokenize import word_tokenize, sent_tokenize\ndicp = word_tokenize(dicionario)\ndics = sent_tokenize(dicionario)","f3ca72c8":"# Remove a pontua\u00e7\u00e3o. Padr\u00e3o: tudo que \u00e9 diferente de palavras \\w e espa\u00e7os \\s substitui por nda\nimport re\nfrase_limpa = re.sub(r'[^\\w\\s]','', frase) # Para uma senten\u00e7a\nfrase_limpa","4586ed0a":"# Remove caracteres especiais, pontua\u00e7\u00e3o e d\u00edgitos para uma lista\ntexto = [re.sub(\"(\\\\d|\\\\W)+\", \" \", e) for e in frases] \ntexto","29eb1b46":"stopwords = ['objeto','contrata\u00e7\u00e3o']","3c036f14":"# Download das stopwords. OBS: lembre de habilitr o uso da Internet em Settings.\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n# Define as stopwords\nstopwords = stopwords.words('portuguese')\n\n# Qtd de stopwords\nprint(len(stopwords))\n\n# Exemplo de stopwords\nstopwords[0:10]","52c3be93":"# Stemming\nfrom nltk.stem import PorterStemmer\nst = PorterStemmer()\nword_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\nfor word in word_list: print(st.stem(word))","a0dcdb8f":"# Stemming\nfrom nltk.stem import LancasterStemmer\nlancaster=LancasterStemmer()\nword_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\nfor word in word_list: print(lancaster.stem(word))","91b40187":"# Stemming para senten\u00e7as. Transforma\nfrom nltk.stem import LancasterStemmer\nstem = LancasterStemmer()\nsentence_words = nltk.word_tokenize(frase)\nfor sentence in sentence_words: print(stem.stem(sentence))","f361629f":"# Stemming em Portugues\nfrom nltk.stem.snowball import SnowballStemmer \nstemmer = SnowballStemmer(\"portuguese\") \nfor sentence in dicp: print(stemmer.stem(sentence))","d91d1201":"# RSLPS\nimport nltk \nfrom nltk.stem import RSLPStemmer\n\nstemmerpt = RSLPStemmer()\nfor sentence in dicp: print(stemmerpt.stem(sentence))","f88a5bae":"# Lemmatization\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nlem = WordNetLemmatizer()\nword_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\nfor word in word_list: print(lem.lemmatize(word))","39d6755d":"# Lemmatization\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nlem = WordNetLemmatizer()\nsentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\nsentence_words = nltk.word_tokenize(sentence)\nfor sentence in sentence_words: print(lem.lemmatize(sentence))","54af0c8e":"# Contagem de tokens de palavra\nfrom collections import Counter\ncontagempalavras = Counter(word_tokenize(frase))\ncontagempalavras","308208eb":"# Imprime as palavras mais comuns\nprint(contagempalavras.most_common(10))","cc9301e7":"# Contagem de senten\u00e7as\nfrom collections import Counter\ncontagemsentencas = Counter(sent_tokenize(frase))\ncontagemsentencas","8860cf8f":"# Bag of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\n\n# Cria a matriz de baf of words\nX = vectorizer.fit_transform(dics)\nX.toarray()\n\n# Outra forma de imprimimr o mesmo resultado da matriz (X) de bag of words\nprint(vectorizer.fit_transform(dics).todense())","f0373dd1":"# Vocabulario. \nprint(vectorizer.vocabulary_)\n\n# Quantidade de palavras no vocabul\u00e1rio\nlen(vectorizer.vocabulary_)","2abb8f6f":"# Imprime a matriz Bag of Words\nimport pandas as pd\npd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())","0f486110":"noticias = '''Funcionaria do Ibope e Datafolha denuncia manipula\u00e7\u00e3o das pesquisas eleitorais.\nPesquisa do Ipea traz informa\u00e7\u00e3o errada sobre estupro e roupas curtas.\nDatafolha est\u00e1 fazendo uma pesquisa eleitoral no Whatsapp.\nDilma tem contrato para Ibope manipular pesquisas.\nDilma gastou 73 milh\u00f5es em um sal\u00e3o de beleza quando era presidente.\nUber vai comprar a Avianca e oferecer passagens com 50% de desconto.\nIdosos t\u00eam direito a 50% de desconto em passagens a\u00e9reas.\nIdoso ganhou viagem em jato da for\u00e7a a\u00e9rea e foi ejetado sem querer.\nS\u00e9rgio Moro anuncia fim do IPVA e diz que cobran\u00e7a \u00e9 ilegal.\nBras\u00edlia ter\u00e1 parque da Disney.\n'''\nnoticias = word_tokenize(noticias)\nvectorizer = CountVectorizer()\nvectorizer.fit_transform(noticias).todense()\nlen(vectorizer.vocabulary_)","c9630694":"# 1. Crie uma variavel com o texto de not\u00edcias falsas\n# 2. Fa\u00e7a a tokeniza\u00e7\u00e3o das noticias\n# 3. Crie o Bag of Words\n# 4. Imprima o vocabul\u00e1rio\n# 5. Qual a Quantidade de palavras no vocabul\u00e1rio?","b75fcc57":"# Valida\u00e7\u00e3o do Exempllo\ndoc1 = ((27 * ' car ') + (3 * ' auto ') + (0 * ' insurance ') + (14 * ' best '))\ndoc2 = ((4 * ' car ') + (33 * ' auto ') + (33 * ' insurance ') + (0 * ' best '))\ndoc3 = ((24 * ' car ') + (0 * ' auto ') + (29 * ' insurance ') + (17 * ' best '))\ncorpus = [doc1,doc2,doc3]\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\nimport pandas as pd\npd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vectorizer.get_feature_names())","a7e231a7":"# TF-IDF do Dicion\u00e1rio Goiano\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, max_df=0.85)\ntfidf_matrix = tfidf_vectorizer.fit_transform(dics)\nprint(tfidf_matrix.shape)","a24d413c":"# Imprime a matriz TF-IDF\nimport pandas as pd\npd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vectorizer.get_feature_names())","131fa5eb":"# 1. Crie o TF-IDF de noticias falsas do exercicio 3. Qual o shape da matriz?","023457ee":"# Por exemplo\ndef cosine_sim(text1, text2):\n    tfidf = vectorizer.fit_transform([text1, text2])\n    return ((tfidf * tfidf.T).A)[0,1]\n\n\ncosine_sim('abc', 'abc')\ncosine_sim('abc', 'dois cachorrinhos passeando no parque')","0ab47c9a":"# Calcula o Cosseno da matriz TF-IDF. Pode ser usada para encontrar similaridades entre documentos e entre senten\u00e7as\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Compara o primeiro documento com os demais\ncosine_similarity(tfidf_matrix[0:1], tfidf_matrix)","409437d4":"import nltk\nnltk.jaccard_distance(set(\"goiano\"), set(\"goiano\"))\nnltk.jaccard_distance(set(\"goiano\"), set(\"mineiro\"))","df9db5ec":"# No NLTK \u00e9 chamada de Edit Distance\nimport nltk\nnltk.edit_distance('goiano','goiano')\nnltk.edit_distance('goiano','goiana')\nnltk.edit_distance('goiano','mineiro')","24a80c6b":"# RESPOSTA EXERCICIOS 1\n\n# 1. Crie um texto com o seguinte conte\u00fado: A explos\u00e3o aconteceu em 2005, por\u00e9m s\u00f3 em 2012 foram desvendadas as causas do acidente. \ntexto = 'A explos\u00e3o aconteceu em 2005, por\u00e9m, s\u00f3 em 2012, foram desvendadas as causas do acidente'\n\n# 2. Encontre e imprima apenas os n\u00fameros do texto criado para capturarmos os anos citados no texto.\nprint(re.findall(r'\\d{4}',texto))\n\n# 3. Substitua todas as v\u00edrgulas por . e atribua a variavel de nome igual a texto2.\ntexto2 = re.sub(',','.',texto)\n\n# Imprima texto2\nprint(texto2)\n\n# 4. Divida o texto2 onde tiver . e imprima o resultado\nprint(re.split(r'[.]',texto2))","7f5002e6":"# RESPOSTA EXERCICIO 2\n# 1. Fa\u00e7a a tokeniza\u00e7\u00e3o do Dicion\u00e1rio Goianio (dicionario) em palavras: salve numa variavel chamada dicp\nfrom nltk.tokenize import word_tokenize\ndicp = word_tokenize(dicionario)\n\n# Quantos tokens foram criados?\nlen(dicp)","afb609f8":"# RESPOSTA EXERCICIO 2\n# 2. Fa\u00e7a a tokeniza\u00e7\u00e3o do Dicion\u00e1rio Goianio (dicionario) em senten\u00e7as: salve numa variavel chamada dics\nfrom nltk.tokenize import sent_tokenize\ndics = sent_tokenize(dicionario)\n\n# Quantos tokens foram criados?\nlen(dics)\n\ntype(dics)","3e5d95cc":"# RESPOSTA 3\n# 1. Crie uma variavel com o texto de not\u00edcias falsas\nnoticias = '''Funcionaria do Ibope e Datafolha denuncia manipula\u00e7\u00e3o das pesquisas eleitorais.\nPesquisa do Ipea traz informa\u00e7\u00e3o errada sobre estupro e roupas curtas.\nDatafolha est\u00e1 fazendo uma pesquisa eleitoral no Whatsapp.\nDilma tem contrato para Ibope manipular pesquisas.\nDilma gastou 73 milh\u00f5es em um sal\u00e3o de beleza quando era presidente.\nUber vai comprar a Avianca e oferecer passagens com 50% de desconto.\nIdosos t\u00eam direito a 50% de desconto em passagens a\u00e9reas.\nIdoso ganhou viagem em jato da for\u00e7a a\u00e9rea e foi ejetado sem querer.\nBras\u00edlia ter\u00e1 parque da Disney.\n'''\n\n# 2. Fa\u00e7a a tokeniza\u00e7\u00e3o das noticias\nfrom nltk.tokenize import sent_tokenize\nnoticias = sent_tokenize(noticias)\n\n# 3. Crie o Bag of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nprint(vectorizer.fit_transform(noticias).todense())\n\n# 4. Imprima o vocabul\u00e1rio\nprint(vectorizer.vocabulary_)\n\n# 5. Qual a Quantidade de palavras no vocabul\u00e1rio?\nlen(vectorizer.vocabulary_)","076fc9ed":"# RESPOSTA 4\n# 1. Crie o TF-IDF de noticias falsas do exercicio 3. \nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)\ntfidf_matrix = tfidf_vectorizer.fit_transform(noticias)\n\n# Qual o shape da matriz?\nprint(tfidf_matrix.shape)","439061fc":"---\n# 1. Express\u00f5es Regulares\nUma **express\u00e3o regular**, **regex**, **regexp** ou **Regular Expression** identifica caracteres. Estes caracteres podem ser de letras, n\u00fameros, caracteres especiais, espa\u00e7os, em letra mai\u00fascula, min\u00fascula, de qualquer tipo. \n\nO uso de express\u00f5es regulares permitem encontrar palavras em documentos, remover caracteres indesejados, entre v\u00e1rias outras manipula\u00e7\u00f5es. Para usar as express\u00f5es regulares, iremos usar a biblioteca `re` do Python. Como sintaxe temos `re.funcao('padr\u00e3o','texto)`. Por exemplo: encontra a palavra abc no texto abcdef: `re.match('abc', 'abcde')`.","dfb20cd7":"## Tokenization\nA NLTK ou Natural Language Toolkit \u00e9 uma ferramenta do Python usada para extrair os tokens (partes) de um texto. A tokeniza\u00e7\u00e3o pode extrair principalmente palavras e senten\u00e7as de um texto. Mas tamb\u00e9m, pode extrair trechos de texto a partir de regras definidas em express\u00f5es regulares. A tokeniza\u00e7\u00e3o pode nos ajudar a facilmente mapear partes de discurso, encontrar palavras comuns, remover palavras indesejadas.\n* **word_tokenize:** faz a tokeniza\u00e7\u00e3o do texto em palavras. \n* **sent_tokenize:** faz a tokeniza\u00e7\u00e3o do texto em senten\u00e7as.\n* **regexp_tokenize:** faz a tokeniza\u00e7\u00e3o do texto de acordo com o padr\u00e3o da express\u00e3o regular.","7ba15ef0":"**[Voltar para a P\u00e1gina Inicial do Curso](https:\/\/www.kaggle.com\/c\/ml-em-python)**\n\n# **Minera\u00e7\u00e3o de Textos**\nO **Text Mining** ou Minera\u00e7\u00e3o de Textos \u00e9 o processo de obter informa\u00e7\u00f5es a partir de um texto. Para isso, utilizamos o Processamento de Linguagem Natural ou **Natural Language Processing (NLP)** que busca converter a linguagem humana para um formato mais manipul\u00e1vel e que fa\u00e7a mais sentido ao computador. Dessa forma, \u00e9 poss\u00edvel extrair padr\u00f5es de textos. \n\nEstes padr\u00f5es extra\u00eddos em textos s\u00e3o usados por exemplo para an\u00e1lise de discursos, an\u00e1lise de not\u00edcias de jornais e revistas, descobrir a opini\u00e3o das pessoas, analisar conversas de chat, email ou twitter. A Minera\u00e7\u00e3o de Textos tamb\u00e9m \u00e9 muito usada para sumariza\u00e7\u00e3o, tradu\u00e7\u00e3o, busca de informa\u00e7\u00f5es e extra\u00e7\u00e3o de informa\u00e7\u00f5es diversas.\n\n![](http:\/\/www.revistaespacios.com\/a17v38n05\/09-03.png)\n\nNo Python, usaremos a biblioteca NLTK - Natural Language Toolkit. A **NLTK** cont\u00e9m algoritmos para an\u00e1lise de sentimentos, extra\u00e7\u00e3o de t\u00f3picos. Outra biblioteca que tamb\u00e9m ser\u00e1 usada \u00e9 ainda a sklearn que cont\u00e9m algoritmos de pr\u00e9-processamento para TF-IDF e Bag of Words, entre outros.\n\n### Conte\u00fado da Minera\u00e7\u00e3o de Textos 1\n1. Express\u00f5es Regulares\n2. Pr\u00e9-processamento de Dados aplicado \u00e0 TEXTOS (cap\u00edtulo extra)\n3. Bag-of-words\n4. TF-IDF\n5. M\u00e9tricas de similaridade (co-seno, Jaccard, Levenshtein, etc).\n\n![](http:\/\/res.cloudinary.com\/dyd911kmh\/image\/upload\/f_auto,q_auto:best\/v1535125878\/NLTK3_zwbdgg.png)\n\n### Conte\u00fado da Minera\u00e7\u00e3o de Textos 2\n6. An\u00e1lise de sentimentos\n7. Extra\u00e7\u00e3o de t\u00f3picos\n8. Problemas comuns no uso de textos (alta dimensionalidade, matrizes esparsas, etc) e como resolv\u00ea-los.","c74627cd":"### 2. Exerc\u00edcio de Tokeniza\u00e7\u00e3o\n1. Fa\u00e7a a tokeniza\u00e7\u00e3o do Dicion\u00e1rio Goianio (dicionario) em palavras: salve numa variavel chamada dicp. Quantos tokens foram criados?\n2. Fa\u00e7a a tokeniza\u00e7\u00e3o do Dicion\u00e1rio Goianio (dicionario) em senten\u00e7as: salve numa variavel chamada dics. Quantos tokens foram criados?","11e7733f":"## 1. Exerc\u00edcios de express\u00f5es regulares\n1. Crie um texto com o seguinte conte\u00fado: \"A explos\u00e3o aconteceu em 2005, por\u00e9m s\u00f3 em 2012 foram desvendadas as causas do acidente.\"\n2. Encontre e imprima apenas os n\u00fameros do texto criado para capturarmos os anos citados no texto.\n3. Substitua todas as v\u00edrgulas por . e atribua a variavel de nome igual a texto2. Imprima texto2\n4. Divida o texto2 onde tiver . e imprima o resultado\n","88e99616":"### Contagem de Frequencia\nUsamos o Counter da biblioteca collections para fazer a contagem de tokens. ","94e2b212":"## Stemming e Lemmatization\nStemming diminui para o radical da palavra. O Lemmatization diminui, por\u00e9m \u00e9 mais conservador e mant\u00e9m o sentido da palavra. Tem v\u00e1rios algoritmos, por exemplo:\n* [PorterStemmer](https:\/\/tartarus.org\/martin\/PorterStemmer\/)\n* [LancasterStemmer](https:\/\/www.nltk.org\/_modules\/nltk\/stem\/lancaster.html)\n* [SnowBallStemmer](https:\/\/snowballstem.org\/). Demonstra\u00e7\u00e3o e teste: [demo](https:\/\/snowballstem.org\/demo.html)\n* [RSLPS - Removedor de Sufixos da L\u00edngua Portuguesa](https:\/\/www.nltk.org\/_modules\/nltk\/stem\/rslp.html)\n","42a630ef":"---\n# 3. Bag of Words\nPara encontrar os termos de um texto, iniciamos com o pr\u00e9-processamento que envolve a limpeza. Depois, fazemos a **tokeniza\u00e7\u00e3o**. A partir da tokeniza\u00e7\u00e3o, criamos o **vocabul\u00e1rio**. Por fim, fazemos a **vetoriza\u00e7\u00e3o** que ir\u00e1 gerar uma matriz do vocabul\u00e1rio com a quantidade de vezes que cada termo aparece no corpus. \n\n![](https:\/\/cdn-media-1.freecodecamp.org\/images\/qRGh8boBcLLQfBvDnWTXKxZIEAk5LNfNABHF)\n\nO bag of words (BOW) \u00e9 uma t\u00e9cnica usada para identificar t\u00f3picos num texto com base na frequencia que eles aparecem. Antes de usar Bag of Words, \u00e9 preciso usar a tokeniza\u00e7\u00e3o para extrair as palavras ou senten\u00e7as de interesse. Depois, contamos a quantidade de vezes que o token aparece. Quanto mais frequente a palavra, mais importante pode ser. \u00c9 uma forma de encontrar as palavras mais significantes do texto.\n\nLimita\u00e7\u00f5es: A bag of words n\u00e3o considera o significado da palavra no documento, ignora o contexto em que \u00e9 usado. Para documentos grandes, o tamanho do vetor pode ser enorme e resultar em muito tempo de processamento.","16821677":"### Quais s\u00e3o os operadores mais comuns usados para especificar os padr\u00f5es?\n| Operadores |                Descri\u00e7\u00e3o                                                            |\n|----------- | ------------------------------------------------------------------------------------ |\n| .          | Corresponde a qualquer caractere \u00fanico, exceto a nova linha \u201c\\ n\u201d.                                                                                                                                |\n| ?          | Corresponde a 0 ou uma ocorr\u00eancia do padr\u00e3o, encontrada \u00e0 esquerda                                                                                                                                |\n| +          | Corresponde a uma ou mais ocorr\u00eancias do padr\u00e3o, encontradas \u00e0 esquerda                                                                                                                           |\n| *          | Corresponde a 0 ou mais ocorr\u00eancias do padr\u00e3o, encontradas \u00e0 esquerda                                                                                                                             |\n| \\w         | Corresponde a um caracter alfanum\u00e9rico                                                                                                                                                            |\n| \\W         | Corresponde a um caracter n\u00e3o-alfanum\u00e9rico                                                                                                                                                        |\n| \\d         | Encontra d\u00edgitos [0-9]                                                                                                                                                                            |\n| \\D         | Encontra n\u00e3o-d\u00edgitos                                                                                                                                                                              |\n| \\s         | Corresponde com caracter \u00fanico de espa\u00e7o em branco (espa\u00e7o, nova linha, retorno, tab, from)                                                                                                       |\n| \\S         | Corresponde a qualquer caracter que n\u00e3o espa\u00e7o em branco                                                                                                                                          |\n| \\b         | Fronteira entre palavra e n\u00e3o-palavra                                                                                                                                                             |\n| \\B         | Oposto de \\b                                                                                                                                                                                      |\n| [..]       | Corresponde com qualquer caracter \u00fanico nos colchetes e [^\u2026] corresponde a qualquer caracter \u00fanico fora dos colchetes                                                                             |\n| [^\u2026]       | Corresponde a qualquer caracter \u00fanico fora dos colchetes                                                                                                                                          |\n| \\          | Usado para caracteres de significado especial como \\. para corresponder a um per\u00edodo ou `\\+`para sinal `+`  |\n| `^` e `$`      | `^ e $` correspondem ao in\u00edcio e final da string, respectivamente                                                                                                                                   |\n| {n, m}     | Encontra pelo menos n e no m\u00e1ximo m ocorr\u00eancias da express\u00e3o precedente, se escrevermos com {,m} ent\u00e3o ir\u00e1 retornar pelo menos qualquer m\u00ednima ocorr\u00eancia at\u00e9 no m\u00e1ximo m da express\u00e3o precedente |\n| a &#124; b      | Corresponde a `a` ou `b``                                                         |\n| ()         | Agrupa express\u00f5es regulares e retorna o texto correspondente                                                                                                                                      |\n| \\t, \\n, \\r | Corresponde a tab, nova linha, retorno                                            |","2d7a1ef8":"---\n# 2. Pr\u00e9-Processamento de Dados aplicado \u00e0 TEXTOS\nAntes de iniciarmos o conte\u00fado de Minera\u00e7\u00e3o de Textos, precisamos conhecer algumas t\u00e9cnicas, as mais usadas, aplicadas no pr\u00e9-processamento de textos com o foco em realizar a limpeza, transforma\u00e7\u00e3o, padroniza\u00e7\u00e3o do texto para preparar o texto antes da minera\u00e7\u00e3o de textos. Isto inclui:\n* Transforma\u00e7\u00e3o de letras para mai\u00fasculas\/min\u00fasculas\n* Tokeniza\u00e7\u00e3o\n* Remo\u00e7\u00e3o de n\u00fameros, caracteres especiais e pontua\u00e7\u00e3o\n* Remo\u00e7\u00e3o de Stopwords\n* Stemming\n* Lemmatization","e100f18c":"## 3. Exerc\u00edcios\nVamos analisar as not\u00edcias falsas. Fonte: boatos.org\n1. Crie um texto de not\u00edcias falsas, com o conte\u00fado: <br\/>\nFuncionaria do Ibope e Datafolha denuncia manipula\u00e7\u00e3o das pesquisas eleitorais.\nPesquisa do Ipea traz informa\u00e7\u00e3o errada sobre estupro e roupas curtas.\nDatafolha est\u00e1 fazendo uma pesquisa eleitoral no Whatsapp.\nDilma tem contrato para Ibope manipular pesquisas.\nDilma gastou 73 milh\u00f5es em um sal\u00e3o de beleza quando era presidente.\nUber vai comprar a Avianca e oferecer passagens com 50% de desconto.\nIdosos t\u00eam direito a 50% de desconto em passagens a\u00e9reas.\nIdoso ganhou viagem em jato da for\u00e7a a\u00e9rea e foi ejetado sem querer.\nS\u00e9rgio Moro anuncia fim do IPVA e diz que cobran\u00e7a \u00e9 ilegal.\nBras\u00edlia ter\u00e1 parque da Disney.\n\n2. Fa\u00e7a a tokeniza\u00e7\u00e3o das noticias\n3. Crie o Bag of Words\n4. Imprima o vocabul\u00e1rio\n5. Qual a Quantidade de palavras no vocabul\u00e1rio?","39ec4863":"---\n# Material Complementar\n1. [Sklearn Cheat Sheet](https:\/\/s3.amazonaws.com\/assets.datacamp.com\/blog_assets\/Scikit_Learn_Cheat_Sheet_Python.pdf)\n2. [Site de Convers\u00e3o e Teste de Express\u00e3o Regular](http:\/\/www.pyregex.com\/)\n3. [Biblioteca de Express\u00e3o Regular re](https:\/\/docs.python.org\/3\/library\/re.html)\n4. [Livro - Introduction to Information Retrieval](https:\/\/nlp.stanford.edu\/IR-book\/pdf\/irbookonlinereading.pdf)\n5. [M\u00e9tricas de Similaridade para M\u00fasicas de Bandas](https:\/\/www.benfrederickson.com\/distance-metrics\/)\n\n---\n## RESPOSTA DOS EXERC\u00cdCIOS","0f1a5a11":"### Remo\u00e7\u00e3o de n\u00fameros, caracteres especiais e pontua\u00e7\u00e3o","a9475754":"### Quais s\u00e3o os m\u00e9todos mais comuns?\n* **re.match()**: Esse m\u00e9todo encontra equival\u00eancia se ela ocorrer no in\u00edcio da string. Uso: re.match(padr\u00e3o, string)\n* **re.search()**: \u00c9 similar a match() mas n\u00e3o nos restringe a encontrar equival\u00eancia apenas no come\u00e7o da string. O m\u00e9todo search() consegue encontrar um padr\u00e3o em qualquer posi\u00e7\u00e3o da string mas que somente retorna a primeira ocorr\u00eancia do padr\u00e3o de busca. Uso: re.search(padr\u00e3o, string)\n* **re.findall()**: \u00c9 \u00fatil obter uma lista de todos os padr\u00f5es encontrados. N\u00e3o h\u00e1 restri\u00e7\u00f5es em buscar do come\u00e7o ou do fim. Funciona como ambas re.search() e re.match(). Uso: re.findall(padr\u00e3o, string)\n* **re.split()**: Este m\u00e9todo ajuda a dividir a string pela ocorr\u00eancias do padr\u00e3o dado. Uso: re.split(padr\u00e3o, string)\n* **re.sub()**: \u00c0s vezes \u00e9 \u00fatil buscar um padr\u00e3o de string e substitu\u00ed-lo por uma nova sub-string. Se o padr\u00e3o n\u00e3o for encontrado, a string \u00e9 retornada sem mudan\u00e7as. Uso: re.sub(padr\u00e3o, replace, string)","0b7f4f36":"### Kernel - Minera\u00e7\u00e3o de Textos de Compras\nhttps:\/\/www.kaggle.com\/debkings\/comprasgovjan2019","1e40beb8":"### Levenshtein\nCalcula a quantidade de edi\u00e7\u00f5es m\u00ednimas para transformar uma palavra em outra. Ou um texto em outro. A quantidade de edi\u00e7\u00f5es pode ser a quantidade de inser\u00e7\u00e3o, dele\u00e7\u00e3o ou substitui\u00e7\u00e3o. Ser\u00e1 zero se os textos forem exatamente iguais.","05fafc72":"### Bag of Words (BoW)\n![](https:\/\/i0.wp.com\/datameetsmedia.com\/wp-content\/uploads\/2017\/05\/bagofwords2.002.jpeg?resize=1024%2C382)","5f62b470":"## Stopwords\nAs stopwords s\u00e3o palavras vazias ou muito frequentes que n\u00e3o agregam na an\u00e1lise. Elas s\u00e3o removidas para simplificar a an\u00e1lise do texto. ","3bfde3b1":"### Jaccard\nMede a similaridade entre dois elementos comparando o tamanho da interse\u00e7\u00e3o entre eles. \n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/22453ac41837fe3f74b74840d03fc83a8ed17ed4)\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/1\/1f\/Intersection_of_sets_A_and_B.svg\/200px-Intersection_of_sets_A_and_B.svg.png)\nJaccard calcula apenas a distancia entre duas palavras, enquanto que a Cosseno leva em considera\u00e7\u00e3o to tamanho total do vetor da matriz TF-IDF ou Bag of Words.","02fe6f27":"---\n# 4. TF-IDF\n* **Termo:** palavra\n* **Documento:** conjunto de palavras. Ex: t\u00edtulo e conte\u00fado.\n* **Corpus:** o total do conjunto de todos os documentos\n* **Vocabul\u00e1rio:** a lista de todas as poss\u00edveis palavras no corpus\n\n![](https:\/\/i1.wp.com\/datameetsmedia.com\/wp-content\/uploads\/2017\/05\/bf.jpeg?resize=1024%2C383)\n\nA **Frequencia de Termos** mede a frequencia de um termo num documento e \u00e9 calculada dividindo o n\u00famero de ocorr\u00eancias do termo no documento pelo total de termos do documento. A frequ\u00eancia de termos depende do tamanho do documento e da generalidade da palavra. Quanto maior um documento e mais comum for a palavra, maiores chances dela aparecer com mais frequ\u00eancia. N\u00e3o devemos confundir a frequencia de termos com a frequencia de documentos. \n\nA **Frequencia de Documentos** mede a import\u00e2ncia de um documento de acordo com o total de todo o conjunto de documentos (corpus) e contabiliza a quantidade de documentos em que o termo aparece. Assim, a **Frequencia Inversa do Documento** mede a informatividade e \u00e9 calculada pelo log da divis\u00e3o da quantidade total de documentos pelo total de documentos contendo uma palavra espec\u00edfica. O log \u00e9 usado para evitar grandes n\u00fameros quando o documento \u00e9 grande. Adicionamos + 1 na f\u00f3rmula para evitar problemas de divis\u00e3o por 0, assim, quando o termo n\u00e3o estiver presente adicionamos 1 no denominador. A Frequ\u00eancia inversa de documentos vai ser bem baixa para palavras que aparecerem muitas vezes em v\u00e1rios documentos, como \u00e9 o caso das stopwords.\n\nAo final, fazemos a multiplica\u00e7\u00e3o de TF x IDF. **Term Frequency (TF)** e **Inverse Document Frequency (IDF)** ajudam a determinar as palavras mais importantes num documento e encontrar documentos de relev\u00e2ncia. \n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQ6PG50YSYAGR8xe2-nTWrnYYBP4hsByy1jym-gCfuhKyQVqBWdyg)\n![](https:\/\/nlp.stanford.edu\/IR-book\/html\/htmledition\/img409.png)\n\nFonte, refer\u00eancia do exemplo: https:\/\/nlp.stanford.edu\/IR-book\/html\/htmledition\/tf-idf-weighting-1.html\n\nTF doc1 = 14 \/ (27 + 3 + 0 + 14) = 14 \/ 44 = 0.318\n\nTF doc2 = 0 \/ (4 + 33 + 33 + 0) = 0 \/ 70 = 0\n\nTF doc3 = 17 \/ (24 + 0 + 29 + 17) = 17 \/ 70 = 0.25\n\nIDF = log(3\/2) = log(1.5) = 0.176\n\nTFIDF doc1 = 0.32 * 0.17 = **0.055**\n\nTFIDF doc2 = 0 * 0.17 = **0**\n\nTFIDF doc3 = 0.24 * 0.17 = **0.044**","b56e3d4e":"## 4. Exerc\u00edcios\n1. Crie o TF-IDF do texto de not\u00edcias falsas do Exercicio 3. Qual o shape da matriz?","62ac4b1a":"---\n# 5. M\u00e9tricas de Similaridade\n* Coseno\n* Jaccard\n* Levenshtein\n\n### Coseno\nA Cosine Similarity ou similaridade de cosseno mede a similaridade entre dois vetores e produz uma medida cosseno que \u00e9 o angulo entre os dois vetores. Vai de -1 a 1. Sendo -1 para exatamente oposto e 1 para exatamente igual. Por\u00e9m, na minera\u00e7\u00e3o de textos, a similaridade cosseno entre dois documentos vai de 0 a 1 porque o TF-IDF n\u00e3o pode ser negativo. \n![](https:\/\/4.bp.blogspot.com\/-DnfQBdz4dAQ\/WqokeQA-d2I\/AAAAAAAAP4E\/6RdRjLga8kET8cQsfQ2UYZu4qT_cWsQ8wCLcBGAs\/s1600\/cosine.png)","0b7f5dc1":"Exemplo Com Calculo Errado\n![](https:\/\/slideplayer.com.br\/slide\/359154\/2\/images\/8\/TF-IDF+Wt%2Cdoc1+%3D+%2814%2F27%29+%2A+log2+3%2F31+%3D+-1%2C75+Exemplo.jpg)","90ed0476":"---\n### Pr\u00f3xima Aula\n[Minera\u00e7\u00e3o de Textos 2](https:\/\/www.kaggle.com\/debkings\/9-minera-o-de-textos-2)","71ca9f1d":"Percebam que:\n* Aumenta quando o termo aparece muitas vezes em poucos documento\n* Diminui quando o termo aparece em muitos documentos\n* Diminui quando o termo aparece poucas vezes no documento"}}