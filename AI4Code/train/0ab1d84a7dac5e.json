{"cell_type":{"bd0766a7":"code","45741f9d":"code","6efcabb3":"code","b51e4701":"code","93f542fa":"code","640bc1d8":"code","8d006395":"code","19ba5901":"code","f3b8bed4":"code","3500676f":"code","7aef0653":"code","321d1882":"code","201e29a6":"code","f9e7e8b3":"code","d42df3bd":"code","803ed57b":"code","f2a7ce1c":"code","d42fbaa2":"code","82778d87":"code","891e8e54":"code","14aab945":"code","d1ff0271":"code","527d0432":"code","8c601b35":"code","eeb50bf3":"markdown","e6293f28":"markdown","cb1c306a":"markdown","a8da4b00":"markdown","efbdb16a":"markdown","788e464f":"markdown","0e5210bf":"markdown","fb924a68":"markdown"},"source":{"bd0766a7":"!pip install yfinance\nimport os\nimport time\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf \n\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\nnp.random.seed(233)\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nNOW_DATE = datetime.datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d\")","45741f9d":"def plot_candle(stock_df, exclude_date, title='Stocks Name'):\n    '''function for plotting stock data'''\n    fig = go.Figure(data=[\n        go.Candlestick(\n            x=stock_df.index,\n            open=stock_df.Open, \n            high=stock_df.High,\n            low=stock_df.Low, \n            close=stock_df.Close)\n    ])\n\n    fig.update_xaxes(\n        rangeslider_visible=False,\n        rangebreaks=[dict(values=exclude_date)] # hide dates with no values\n    )\n    \n    fig.update_layout(\n    title=title,\n    )\n\n    fig.show()\n\ndef remove_holiday(df_stock):\n    dt_all = pd.date_range(start=df_stock.Date.iloc[0],end=df_stock.Date.iloc[-1])\n    dt_obs = [d.strftime(\"%Y-%m-%d\") for d in df_stock.Date]\n    dt_breaks = [d for d in dt_all.strftime(\"%Y-%m-%d\").tolist() if not d in dt_obs]\n    return dt_breaks","6efcabb3":"telkom = yf.download('TLKM.JK','2017-01-01',NOW_DATE) \ntelkom['Date'] = telkom.index","b51e4701":"# telkom[telkom.Volume == 0]\n# telkom[telkom.Date == '2020-11-07']\ndt_breaks = remove_holiday(telkom)","93f542fa":"plot_candle(telkom, dt_breaks, 'Telkom')","640bc1d8":"from sklearn.preprocessing import MinMaxScaler\n\ndef scale_train(dataset):\n    scaler = MinMaxScaler(feature_range=(0,1))\n    scaled_data = scaler.fit_transform(dataset)\n\n    return scaled_data, scaler\n\ndef scale_test(dataset, scaler):\n    scaled_data = scaler.transform(dataset)\n\n    return scaled_data","8d006395":"telkom.loc[:'2021-06-01'].Open.values","19ba5901":"tr_end = '2021-06-01'\nval_end = '2021-09-01'\n\n# slice the date\ntrain_open = telkom.loc[:tr_end][['Open']].values\ntrain_high = telkom.loc[:tr_end][['High']].values\ntrain_low = telkom.loc[:tr_end][['Low']].values\ntrain_close = telkom.loc[:tr_end][['Close']].values\n\nval_open = telkom.loc[tr_end:val_end][['Open']].values\nval_high = telkom.loc[tr_end:val_end][['High']].values\nval_low = telkom.loc[tr_end:val_end][['Low']].values\nval_close = telkom.loc[tr_end:val_end][['Close']].values\n\n# scaled\no_tr_scaled, scaler_o = scale_train(train_open) \no_val_scaled = scale_test(val_open, scaler_o)\n\nh_tr_scaled, scaler_h = scale_train(train_high) \nh_val_scaled = scale_test(val_high, scaler_h)\n\nl_tr_scaled, scaler_l = scale_train(train_low) \nl_val_scaled = scale_test(val_low, scaler_l)\n\nc_tr_scaled, scaler_c = scale_train(train_close) \nc_val_scaled = scale_test(val_close, scaler_c)\n\n# Full data\nfull_open = telkom[['Open']].values\nfull_high = telkom[['High']].values\nfull_low = telkom[['Low']].values\nfull_close = telkom[['Close']].values\n\no_full_scaled, full_scaler_o = scale_train(full_open)\nh_full_scaled, full_scaler_h = scale_train(full_high)\nl_full_scaled, full_scaler_l = scale_train(full_low)\nc_full_scaled, full_scaler_c = scale_train(full_close)","f3b8bed4":"c_tr_scaled","3500676f":"c_tr_scaled.shape, c_val_scaled.shape, o_full_scaled.shape","7aef0653":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\ntf.random.set_seed(233)\n\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.map(lambda w: (w[:-1], w[-1:]))\n    return ds.batch(batch_size).prefetch(1)\n\nFLEN, LNGTH, LEN2, BATCH = 1162, 1086, 62, 32\n\n# Train-Valid Data Generator\nopen_train_gen = TimeseriesGenerator(o_tr_scaled, o_tr_scaled, length=LNGTH, batch_size=BATCH)\nopen_valid_gen = TimeseriesGenerator(o_val_scaled, o_val_scaled, length=LEN2, batch_size=BATCH)\n\nhigh_train_gen = TimeseriesGenerator(h_tr_scaled, h_tr_scaled, length=LNGTH, batch_size=BATCH)\nhigh_valid_gen = TimeseriesGenerator(h_val_scaled, h_val_scaled, length=LEN2, batch_size=BATCH)\n\nlow_train_gen = TimeseriesGenerator(l_tr_scaled, l_tr_scaled, length=LNGTH, batch_size=BATCH)\nlow_valid_gen = TimeseriesGenerator(l_val_scaled, l_val_scaled, length=LEN2, batch_size=BATCH)\n\nclose_train_gen = TimeseriesGenerator(c_tr_scaled, c_tr_scaled, length=LNGTH, batch_size=BATCH)\nclose_valid_gen = TimeseriesGenerator(c_val_scaled, c_val_scaled, length=LEN2, batch_size=BATCH)\n\n# Full Data Generator\nopen_full_gen = TimeseriesGenerator(o_full_scaled, o_full_scaled, length=FLEN, batch_size=BATCH)\nhigh_full_gen = TimeseriesGenerator(h_full_scaled, h_full_scaled, length=FLEN, batch_size=BATCH)\nlow_full_gen = TimeseriesGenerator(l_full_scaled, l_full_scaled, length=FLEN, batch_size=BATCH)\nclose_full_gen = TimeseriesGenerator(c_full_scaled, c_full_scaled, length=FLEN, batch_size=BATCH)\n\n# Test for three months in the future (about 65 datapoint)\nfuture_dt = np.array([[i] for i in range(65)])     \nfuture_gen = TimeseriesGenerator(future_dt, future_dt, length=64, batch_size=BATCH)","321d1882":"close_train_gen","201e29a6":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping, Callback\ntf.random.set_seed(233)\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n\nclass custom_callback(Callback):\n    total_t0 = 0\n    def on_train_begin(self, logs={}):\n        self.total_t0 = time.time()\n    def on_train_end(self, logs={}):\n        print('')\n        print('Training complete!')\n        print('Total training took {:} (h:mm:ss)'.format(format_time(time.time()-self.total_t0)))\n\ndef rmsle_custom(y_true, y_pred):\n    msle = tf.keras.losses.MeanSquaredLogarithmicError()\n    return K.sqrt(msle(y_true, y_pred)) \n\ndef build_model(train_point, opt=tf.optimizers.Adam(), loss=rmsle_custom):\n    # Build the LSTM model\n    model = Sequential()\n    model.add(LSTM(128, return_sequences=True, input_shape= (train_point,1)))\n    model.add(LSTM(64, return_sequences=False))\n    model.add(Dense(25))\n    model.add(Dense(1))\n\n    # Compile the model\n    model.compile(optimizer=opt, loss=loss, metrics=[tf.metrics.MeanAbsoluteError()])\n    \n    return model\n\ncb = tf.keras.callbacks\ncallbacks_c = custom_callback()","f9e7e8b3":"# Build the model (open price)\nmodel_open = build_model(LNGTH)\ntf.keras.utils.plot_model(model_open, show_shapes=True, rankdir='TP')","d42df3bd":"hist_open =  model_open.fit(\n    open_train_gen,\n    epochs=2,\n    validation_data=open_valid_gen,\n    callbacks=[callbacks_c],\n    verbose=2\n)","803ed57b":"# high price\nmodel_high = build_model(LNGTH)\nhist_high =  model_high.fit(\n    high_train_gen,\n    epochs=2,\n    validation_data=high_valid_gen,\n    callbacks=[callbacks_c],\n    verbose=2\n)","f2a7ce1c":"# low price\nmodel_low = build_model(LNGTH)\nhist_low =  model_low.fit(\n    low_train_gen,\n    epochs=2,\n    validation_data=low_valid_gen,\n    callbacks=[callbacks_c],\n    verbose=2\n)","d42fbaa2":"# close price\nmodel_close = build_model(LNGTH)\nhist_close =  model_close.fit(\n    close_train_gen,\n    epochs=2,\n    validation_data=close_valid_gen,\n    callbacks=[callbacks_c],\n    verbose=2\n)","82778d87":"# Full model\nmodel_open_full = build_model(FLEN)\nhist_open_full =  model_open_full.fit(\n    open_full_gen,\n    epochs=2,\n    callbacks=[callbacks_c],\n    verbose=2\n)\n\nprint()\n\nmodel_high_full = build_model(FLEN)\nhist_high_full =  model_high_full.fit(\n    high_full_gen,\n    epochs=2,\n    callbacks=[callbacks_c],\n    verbose=2\n)\n\nprint()\n\nmodel_low_full = build_model(FLEN)\nhist_low_full =  model_low_full.fit(\n    low_full_gen,\n    epochs=2,\n    callbacks=[callbacks_c],\n    verbose=2\n)\n\nprint()\n\nmodel_close_full = build_model(FLEN)\nhist_close_full =  model_close_full.fit(\n    close_full_gen,\n    epochs=2,\n    callbacks=[callbacks_c],\n    verbose=2\n)","891e8e54":"# fit model & predict the future\ndef pred_future_deep(model, future_dt):\n    list_pred = []\n    \n    first_eval_batch = future_dt\n    current_batch = first_eval_batch.reshape((1, 65, 1))\n    \n    for i in range(len(future_dt)):\n\n        # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n        current_pred = [i for i in model.predict(current_batch)[0]]\n\n        # store prediction\n        list_pred.append(current_pred) \n\n#         if i == 0:\n            # update batch to now include prediction and drop first value\n        current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n            \n#         current_batch = np.append(current_batch[:],[[current_pred]],axis=1)\n        \n    return list_pred","14aab945":"# Open\nres_open3m = pred_future_deep(model_open_full, future_dt)\nres_open3m = full_scaler_o.inverse_transform(res_open3m)\nres_open3m.shape\n\n# High\nres_high3m = pred_future_deep(model_high_full, future_dt)\nres_high3m = full_scaler_h.inverse_transform(res_high3m)\nres_high3m.shape\n\n# Low\nres_low3m = pred_future_deep(model_low_full, future_dt)\nres_low3m = full_scaler_l.inverse_transform(res_low3m)\nres_low3m.shape\n\n# Close\nres_close3m = pred_future_deep(model_close_full, future_dt)\nres_close3m = full_scaler_c.inverse_transform(res_close3m)\nres_close3m.shape","d1ff0271":"!pip install Pytanggalmerah\nfrom pytanggalmerah import TanggalMerah\n\nforecast_date = pd.DatetimeIndex(np.arange('2021-09-21', '2021-12-31', dtype='datetime64'))\n\n# Indonesia Holidays\ntgm = TanggalMerah()\nlist_hodya = list()\n\nfor i in forecast_date:\n    tgm.set_date(i.year, i.month, i.day)\n    list_hodya.append(tgm.is_sunday())\n    \nholday = pd.DataFrame({'ds':forecast_date, 'holiday':list_hodya})\nholday = holday[holday.holiday].reset_index(drop=True)\nholday.holiday = holday.holiday.apply(lambda x: 'Sunday')\n\nstday = holday.copy()\nstday.ds = stday.ds.apply(lambda x: x - pd.DateOffset(1))\n\nweekend_full = pd.concat([holday,stday]).sort_values(by='ds').reset_index(drop=True)\n\nnew_forecast_date = forecast_date.drop(weekend_full.ds)\ndate_new = new_forecast_date[:65]\ndate_new","527d0432":"def verify_low(cols):\n    '''\n    Validate for price that Low<=Close\n    '''\n    low = cols[0]\n    close = cols[1]\n    \n    if low <= close:\n        return low\n    return close\n\ndef verify_close(cols):\n    '''\n    Validate for price that Low<=Close\n    '''\n    low = cols[0]\n    close = cols[1]\n    \n    if close >= low:\n        return close\n    return low\n        \nforecast_df = pd.DataFrame({\n    'Date': date_new,\n    'Open': res_open3m.reshape(-1),\n    'High': res_high3m.reshape(-1),\n    'Low': res_low3m.reshape(-1),\n    'Close': res_close3m.reshape(-1),\n})\n\nforecast_df['Close_temp'] = forecast_df['Close'].copy()\nforecast_df['Close'] = forecast_df[['Low', 'Close_temp']].apply(verify_close, axis=1)\nforecast_df['Low'] = forecast_df[['Low', 'Close_temp']].apply(verify_low, axis=1)\nforecast_df = forecast_df.drop(['Close_temp'], axis=1)\nforecast_df = forecast_df.set_index('Date')\nforecast_df","8c601b35":"plot_candle(forecast_df, weekend_full.ds, 'Telkom Forecast')","eeb50bf3":"# TLKM","e6293f28":"Okay the result not quite like expected, see you for future improvement ...","cb1c306a":"# Preparation","a8da4b00":"# Modelling","efbdb16a":"The Error was pretty good (only around IDR 0.3 for every price type) --> because we know the price above IDR 2500, so that was very small ","788e464f":"Forecast using LSTM and FBProphet (soon). <br>\nNot only in one price type but whether four (OHLC) to become a supplimental analysis. <br>\nThe chart shown as candlestick (if you are a `Technical Analyst` or use that method for almost all the time in your <br> trading or investing) this will be better than just a line chart for close price alone. ","0e5210bf":"# Indonesian Stock Market Forecasting","fb924a68":"# Result"}}