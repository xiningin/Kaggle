{"cell_type":{"5f12d88e":"code","09fd00d8":"code","59248060":"code","fe061903":"code","6d6cccce":"code","e6168082":"code","2edb0bb9":"code","f7cd5169":"code","459ab54b":"code","1c44f584":"code","6d4e7ce7":"code","0fddaaf4":"code","c92194bd":"code","1e8184a4":"code","5181a19f":"code","94958fd7":"code","018b746b":"code","8f024be7":"code","33e27c21":"code","c5f6793b":"code","4ebcd6b0":"code","9879ed76":"code","2d3d1e1c":"code","08d35a2a":"code","d5fce334":"code","aac52e06":"code","619224f4":"code","c70a0953":"code","2b5a5e9c":"code","9cab1613":"markdown","c7294f33":"markdown","2ef8b583":"markdown","6171614a":"markdown","e8350db9":"markdown","47cb212e":"markdown","6cc7594d":"markdown","6f467c6b":"markdown","9db1aa9e":"markdown"},"source":{"5f12d88e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09fd00d8":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n# For feature Selection\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import SelectKBest\n# For Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import  LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","59248060":"#import Data\ndf=pd.read_csv('\/kaggle\/input\/sloan-digital-sky-survey\/Skyserver_SQL2_27_2018 6_51_39 PM.csv')\n","fe061903":"#see first 5 rows\ndf.head()\n","6d6cccce":"#see numbers of rows and columns\ndf.shape\n","e6168082":"#see data types of columns\ndf.info()","2edb0bb9":"df.drop(columns=['objid','specobjid'],inplace=True)","f7cd5169":"df.head()","459ab54b":"\nsns.countplot(df['camcol'])","1c44f584":"#see which is the most class \nsns.countplot(df['class'])","6d4e7ce7":"# see if there are missing values\ndf.isna().sum()","0fddaaf4":"#change  category data into nummerical \ndef change_category (cat):\n    if cat=='STAR':\n        return 0\n    elif cat == 'GALAXY':\n        return 1 \n    else :\n        return 2\n    ","c92194bd":"df['ClassCat']=df['class'].apply(change_category)","1e8184a4":"df.head()","5181a19f":"sns.pairplot(df[['u','g','r','i']])","94958fd7":"df.drop(columns='class',inplace=True)","018b746b":"X=df.drop(columns='ClassCat')","8f024be7":"y=df['ClassCat']","33e27c21":"\nbest_feature = SelectKBest(score_func=f_regression,k='all')\nfit = best_feature.fit(X,y)","c5f6793b":"score = pd.DataFrame(fit.scores_)\ncolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([columns,score],axis=1)\nfeatureScores.columns = ['Feature','Score']\nfeatureScores = featureScores.sort_values(by='Score',ascending=False).reset_index(drop=True)\n\nfeatureScores","4ebcd6b0":"X= X[featureScores.Feature[:8].values]\n","9879ed76":"X=StandardScaler().fit_transform(X)","2d3d1e1c":"X_train ,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)","08d35a2a":"\nlogreg= LogisticRegression()\nlogreg.fit(X_train,y_train)\ny_pred=logreg.predict(X_test)\nlog_reg_acc=logreg.score(X_test,y_test)\nprint(' Logisitic Regression score {}'.format(log_reg_acc))\nprint(' Root Mean Squared Error  {}'.format(np.sqrt(mean_squared_error(y_test,y_pred))))\n\n\n","d5fce334":"\nknn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,y_train)\ny_pred1=knn.predict(X_test)\nknn_acc=knn.score(X_test,y_test)\n\nprint(' KNN score {}'.format(knn_acc))\nprint(' Root Mean Squared Error  {}'.format(np.sqrt(mean_squared_error(y_test,y_pred1))))\n\n\n","aac52e06":"\ndt=DecisionTreeClassifier(max_leaf_nodes=20,random_state=0)\ndt.fit(X_train,y_train)\ny_pred2=dt.predict(X_test)\ndt_score=dt.score(X_test,y_test)\n\nprint(' Decision Tree   score {}'.format(dt_score))\nprint(' Root Mean Squared Error  {}'.format(np.sqrt(mean_squared_error(y_test,y_pred2))))\n","619224f4":"\nrf=RandomForestClassifier(n_estimators=120)\nrf.fit(X_train,y_train)\ny_pred3=rf.predict(X_test)\nrf_acc=rf.score(X_test,y_test)\nprint(' Random Forest score {}'.format(rf_acc))\nprint(' Root Mean Squared Error  {}'.format(np.sqrt(mean_squared_error(y_test,y_pred3))))","c70a0953":"\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\ny_pred4 = linear_svc.predict(X_test)\nlinear_svc_acc=linear_svc.score(X_test,y_test)\nprint(' Random Forest score {}'.format(linear_svc_acc))\nprint(' Root Mean Squared Error  {}'.format(np.sqrt(mean_squared_error(y_test,y_pred4))))\n","2b5a5e9c":"models = pd.DataFrame({\n    'Model': [ 'KNN', 'Logistic Regression', \n              'Random Forest' ,'Linear SVC', \n              'Decision Tree'],\n    'Score': [knn_acc, log_reg_acc, rf_acc, \n              linear_svc_acc ,dt_score]})\nmodels.sort_values(by='Score', ascending=False)","9cab1613":"# Random Forest Classifier","c7294f33":"# Explore Data\n","2ef8b583":"# Feature Selection","6171614a":"# KNeighbour Classifier","e8350db9":"# Machine Learning","47cb212e":"# Logistic Regression","6cc7594d":"# Prepare for Machine Learning","6f467c6b":"# Linear SVC","9db1aa9e":"# Decision Tree Classifier"}}