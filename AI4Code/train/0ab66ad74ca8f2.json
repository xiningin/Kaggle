{"cell_type":{"c0752528":"code","db05b7c2":"code","199efe66":"code","8584ac97":"code","5cdcb819":"code","bdca5fb3":"code","11fd8de4":"code","de42f835":"code","866925a7":"code","883653ee":"code","3204bd1e":"code","57543a06":"code","383067d2":"code","52f49aca":"code","817150dc":"code","e317f19b":"code","57ba8524":"code","a16c5422":"code","486ebf64":"code","f8ec5ab5":"markdown","b95f583b":"markdown","96c54cc6":"markdown","89ad8dab":"markdown","22b81936":"markdown","08be2a2c":"markdown","1e94df03":"markdown","f75ef529":"markdown","3c68c842":"markdown"},"source":{"c0752528":"import os \nimport pandas as pd \nimport numpy as np\nimport time \nimport cv2 \nfrom PIL import Image \n\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms \n\nimport xgboost as xgb\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import quantile_transform\n\nDEVICE = torch.device('cuda:0')\nDATA_SOURCE = os.path.join('..', 'input', 'aptos2019-blindness-detection')\nMODEL_SOURCE = os.path.join('..', 'input', 'torchvisionmodelspartial1')","db05b7c2":"def crop_image(img,tol=7):\n    w, h = img.shape[1],img.shape[0]\n    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray_img = cv2.blur(gray_img,(5,5))\n    shape = gray_img.shape \n    gray_img = gray_img.reshape(-1,1)\n    quant = quantile_transform(gray_img, n_quantiles=256, random_state=0, copy=True)\n    quant = (quant*256).astype(int)\n    gray_img = quant.reshape(shape)\n    xp = (gray_img.mean(axis=0)>tol)\n    yp = (gray_img.mean(axis=1)>tol)\n    x1, x2 = np.argmax(xp), w-np.argmax(np.flip(xp))\n    y1, y2 = np.argmax(yp), h-np.argmax(np.flip(yp))\n    if x1 >= x2 or y1 >= y2 : # something wrong with the crop\n        return img # return original image\n    else:\n        img1=img[y1:y2,x1:x2,0]\n        img2=img[y1:y2,x1:x2,1]\n        img3=img[y1:y2,x1:x2,2]\n        img = np.stack([img1,img2,img3],axis=-1)\n    return img\n\ndef process_image(image, size=512):\n    image = cv2.resize(image, (size,int(size*image.shape[0]\/image.shape[1])))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    try:\n        image = crop_image(image, tol=15)\n    except Exception as e:\n        image = image\n        print( str(e) )\n    return image","199efe66":"os.makedir('goog')\nos.listdir('.\/')","8584ac97":"class RetinopathyDatasetTrain(Dataset):\n\n    def __init__(self, transform, eval_set=False, eval_frac=0.5, random_state=42):\n        if not os.path.exists(\"cache\"): os.mkdir(\"cache\")\n        self.transform = transform\n        self.base_transform = transforms.Resize((224, 224))        \n        # read data list, split in train and eval, select the set\n        csv_file = os.path.join(DATA_SOURCE, \"train.csv\")\n        df = pd.read_csv(csv_file)\n        df_train = df.sample(n=int(df.shape[0]*(1-eval_frac)), random_state=random_state)\n        ix=[i for i in df.index if i not in df_train.index.values.tolist()]  \n        df_eval = df.loc[ix]            \n        if eval_set : df = df_eval\n        else :        df = df_train\n        self.data = df.reset_index(drop=True)\n            \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get image and process it to tensor ready for the model, extract features\n        folder = os.path.join(DATA_SOURCE, \"train_images\")\n        code = str(self.data.loc[idx, 'id_code'])\n        file = code + \".png\"\n        cache_path = os.path.join(\"cache\",code+\".png\")\n        cached = os.path.exists(cache_path)\n        if not cached : \n            path = os.path.join(folder, file)\n            image = cv2.imread(path)\n            image = process_image(image)\n            imgpil = Image.fromarray(image)\n            imgpil = self.base_transform(imgpil)\n            imgpil.save(cache_path,\"PNG\")\n        imgpil = Image.open(cache_path)\n        img_tensor = self.transform(imgpil)\n        label = self.data.loc[idx, \"diagnosis\"]\n        return {'image': img_tensor, 'label': label}","5cdcb819":"class RetinopathyDatasetTest(Dataset):\n\n    def __init__(self, eval_set=False, random_state=42):\n        # read data list, split in train and eval, select the set\n        csv_file = os.path.join(DATA_SOURCE, \"test.csv\")\n        df = pd.read_csv(csv_file)\n        print(df)\n        self.data = df.reset_index(drop=True)\n        self.transform = transforms.Compose(\n                        [transforms.Resize((224, 224)),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], \n                                             [0.229, 0.224, 0.225])])\n            \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get image and process it to tensor ready for the model, extract features\n        folder = os.path.join(DATA_SOURCE, \"test_images\")\n        code = str(self.data.loc[idx, 'id_code'])\n        file = code + \".png\"\n        path = os.path.join(folder, file)\n        image = cv2.imread(path)\n        image = process_image(image)\n        imgpil = Image.fromarray(image)\n        img_tensor = self.transform(imgpil)\n        return {'image': img_tensor}","bdca5fb3":"# Training loops\ndef train_model(model, optimizer, train_data_loader, eval_data_loader, \n                file_name, num_epochs = 50, patience = 7, prev_loss = 1000.00):\n    criterion = nn.CrossEntropyLoss()\n    countdown = patience\n    best_loss = 1000.00\n    since = time.time()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        counter = 0\n        for bi, d in enumerate(train_data_loader):\n            counter += 1\n            inputs = d[\"image\"].to(DEVICE, dtype=torch.float)\n            labels = d[\"label\"].to(DEVICE, dtype=torch.long)\n            model.to(DEVICE)\n            model.train()\n            optimizer.zero_grad()\n            outputs = model(inputs) \n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            loss_val=(running_loss \/ (counter * train_data_loader.batch_size))\n            print(\"{:3} {:.4f} {:.4f}\".format(counter, loss.item()*1, loss_val), end=\"\\r\")\n        epoch_loss = running_loss \/ ( len(train_data_loader) * train_data_loader.batch_size)\n        time_elapsed = time.time() - since\n        print(\" T{:3}\/{:3} loss: {:.4f} ({:3.0f}m {:2.0f}s) \".format( \n            epoch, num_epochs - 1, epoch_loss,time_elapsed \/\/ 60, time_elapsed % 60))\n        running_loss = 0.0\n        counter = 0\n        for bi, d in enumerate(eval_data_loader):\n            counter += 1\n            inputs = d[\"image\"].to(DEVICE, dtype=torch.float)\n            labels = d[\"label\"].to(DEVICE, dtype=torch.long)\n            model.to(DEVICE)\n            model.eval()\n            with torch.no_grad():\n                outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            loss_val=(running_loss \/ (counter * eval_data_loader.batch_size))\n            print(\"{:3} {:.4f} {:.4f}\".format(counter, loss.item()*1, loss_val), end=\"\\r\")\n        epoch_loss = running_loss \/ ( len(eval_data_loader) * eval_data_loader.batch_size)\n        if epoch_loss < best_loss : \n            best_loss = epoch_loss\n            if epoch_loss < prev_loss:\n                torch.save(model.state_dict(), file_name)\n                prev_loss = epoch_loss\n                print(\"*\", end=\"\")\n            else:\n                print(\".\", end=\"\")\n            countdown = patience\n        else:\n            print(\"{:1}\".format(countdown), end=\"\")\n            countdown -= 1\n        time_elapsed = time.time() - since\n        print(\"E{:3}\/{:3} loss: {:.4f} ({:3.0f}m {:2.0f}s)\".format( \n            epoch, num_epochs - 1, epoch_loss,time_elapsed \/\/ 60, time_elapsed % 60 ))\n\n        if countdown <= 0 : break\n\n    return prev_loss\n    print(\"done.\")\n# Model training","11fd8de4":"aug_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbase_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 48\ndata_train = RetinopathyDatasetTrain(aug_transform, eval_frac=0.25, random_state=69)\ndata_loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n                                                shuffle=True, num_workers=0, \n                                                drop_last=False)\ndata_eval = RetinopathyDatasetTrain(base_transform, eval_set=True, \n                                    eval_frac=0.25, random_state=69)\ndata_loader_eval = torch.utils.data.DataLoader(data_eval,batch_size=batch_size, \n                                               shuffle=False, num_workers=0, \n                                               drop_last=False)","de42f835":"def get_base_model():\n    model = torchvision.models.densenet161(pretrained=False)\n    model_path = os.path.join(MODEL_SOURCE, \"densenet161.pth\")\n    model.load_state_dict(torch.load(model_path))\n    model.classifier = nn.Sequential(\n        nn.BatchNorm1d(2208),\n        nn.Dropout(p=0.25),\n        nn.Linear(in_features=2208, out_features=2048, bias=True),\n        nn.ReLU(),\n        nn.BatchNorm1d(2048),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=2048, out_features=5, bias=True),\n    )\n    model = model.to(DEVICE)\n    model.eval()\n    \n    return model","866925a7":"bst_loss = 10000.00\nfor no in range(5):\n    print(\"-\"*22,no)\n    model = get_base_model()\n    plist = [{'params': model.features.denseblock2.parameters()},\n             {'params': model.features.denseblock3.parameters()},\n             {'params': model.features.denseblock4.parameters()},\n             {'params': model.classifier.parameters()}]\n    optimizer = optim.Adam(plist, lr=0.001)\n    bst_loss = train_model(model, optimizer, data_loader_train, data_loader_eval, \"tmp.pth\", prev_loss=bst_loss)","883653ee":"# load the pretrained CNN used as feature extractor\n# no classifier defined, we will take the raw output from the CNN layers\nextractor = torchvision.models.densenet161(pretrained=False)\nextractor.classifier = nn.Sequential(\n    nn.BatchNorm1d(2208),\n    nn.Dropout(p=0.25),\n    nn.Linear(in_features=2208, out_features=2048, bias=True),\n    nn.ReLU(),\n    nn.BatchNorm1d(2048),\n    nn.Dropout(p=0.5),\n    nn.Linear(in_features=2048, out_features=5, bias=True),\n)\nmodel_path = os.path.join(\"tmp.pth\")\nextractor.load_state_dict(torch.load(model_path))\nextractor.classifier = nn.Identity()\nextractor = extractor.to(DEVICE)\nextractor.eval()","3204bd1e":"data_loader_train = torch.utils.data.DataLoader(RetinopathyDatasetTrain(base_transform), \n                            batch_size=64, shuffle=True, num_workers=0, drop_last=False)\ndata_loader_eval = torch.utils.data.DataLoader(RetinopathyDatasetTrain(base_transform, \n                                                                       eval_set=True), \n                            batch_size=64, shuffle=True, num_workers=0, drop_last=False)\n\ndef get_train_features(data_loader):\n    for bi, d in enumerate(data_loader):\n        print(\".\", end=\"\")\n        img_tensor = d[\"image\"].to(DEVICE)\n        target = d[\"label\"].numpy()\n        with torch.no_grad(): feature = extractor(img_tensor)\n        feature = feature.cpu().detach().squeeze(0).numpy()\n        if bi == 0 :\n            features = feature \n            targets = target \n        else :\n            features = np.concatenate([features, feature], axis=0)\n            targets = np.concatenate([targets, target], axis=0)\n    print(\"\")\n    return features, targets\n\nprint(\".............................\")\nfeatures_train, targets_train = get_train_features(data_loader_train)\nfeatures_eval, targets_eval = get_train_features(data_loader_eval)","57543a06":"XGBOOST_PARAM = {\n    \"random_state\" : 42,\n    'objective': 'multi:softmax',\n    \"num_class\" : 5,\n    \"n_estimators\" : 200,\n    \"eval_metric\" : \"mlogloss\"\n}\n\nxgb_model_1 = xgb.XGBClassifier(**XGBOOST_PARAM)\nxgb_model_1 = xgb_model_1.fit(features_train,targets_train.reshape(-1),\n                        eval_set=[(features_eval, targets_eval.reshape(-1))],\n                        early_stopping_rounds=20,\n                        verbose=True)\nprediction = xgb_model_1.predict(features_eval)","383067d2":"xgb_model_2 = xgb.XGBClassifier(**XGBOOST_PARAM)\nxgb_model_2 = xgb_model_2.fit(features_eval,targets_eval.reshape(-1),\n                        eval_set=[(features_train, targets_train.reshape(-1))],\n                        early_stopping_rounds=20,\n                        verbose=True)","52f49aca":"print(\"Cohen Kappa quadratic score\", \n      cohen_kappa_score(targets_eval, prediction, weights=\"quadratic\"))\n_ = xgb.plot_importance(xgb_model_1, max_num_features=12)","817150dc":"prediction1 = xgb_model_1.predict(features_eval)\nprediction2 = xgb_model_2.predict(features_train)\ntargets = np.concatenate([targets_eval, targets_train], axis=0)\nprediction = np.concatenate([prediction1, prediction2], axis=0)\nprint(\"Cohen Kappa quadratic score\", \n      cohen_kappa_score(targets, prediction, weights=\"quadratic\"))","e317f19b":"data_loader = torch.utils.data.DataLoader(RetinopathyDatasetTest(), \n                            batch_size=2, shuffle=False, num_workers=0, drop_last=False)\n\ndef get_test_features(data_loader):\n    for bi, d in enumerate(data_loader):\n        if bi % 32 == 0 : print(\".\", end=\"\")\n        img_tensor = d[\"image\"].to(DEVICE)\n        with torch.no_grad(): feature = extractor(img_tensor)\n        feature = feature.cpu().detach().squeeze(0).numpy()\n        if bi == 0 :\n            features = feature \n        else :\n            features = np.concatenate([features, feature], axis=0)\n    print(\"\")\n    return features\n\nprint(\"...............................\")\nfeatures = get_test_features(data_loader)","57ba8524":"prediction1 = xgb_model_1.predict_proba(features)\nprediction2 = xgb_model_2.predict_proba(features)\nprediction = (prediction1 + prediction2).argmax(axis=1)\ncsv_file = os.path.join(DATA_SOURCE, \"sample_submission.csv\")\ndf = pd.read_csv(csv_file)\ndf[\"diagnosis\"] = prediction\ndf.to_csv('submission.csv',index=False)","a16c5422":"df","486ebf64":"# cleaning\nfor e in os.listdir(\"cache\"):\n    os.remove(os.path.join(\"cache\", e))\nos.rmdir(\"cache\")","f8ec5ab5":"# Extract test features from CNN","b95f583b":"# PyTorch's style data loader defintion\nadapted from : https:\/\/www.kaggle.com\/abhishek\/very-simple-pytorch-training-0-59","96c54cc6":"# Imports, settings and references","89ad8dab":"# Prediction using XGB","22b81936":"# Re-train the pre-trained model","08be2a2c":"# Fit the XGBoost model","1e94df03":"# Evaluation","f75ef529":"# Extract train features from CNN","3c68c842":"# Pre-processing\nInspired by: # https:\/\/www.kaggle.com\/ratthachat\/aptos-updated-preprocessing-ben-s-cropping"}}