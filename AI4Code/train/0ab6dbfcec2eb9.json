{"cell_type":{"bbd7a13e":"code","a1208518":"code","156b6560":"code","3c566392":"code","c46dd1eb":"code","e664f4b4":"code","a3ba2a6e":"code","79d1039f":"code","71680f21":"code","04f39034":"code","03507910":"code","00cfef31":"code","6a6d580b":"code","c156a6b3":"code","395629db":"code","62efeae4":"markdown","05f77ebd":"markdown","01a0e524":"markdown","533a7e60":"markdown","773f1001":"markdown","28674811":"markdown","c9b15556":"markdown","e815b22b":"markdown","88b725dc":"markdown"},"source":{"bbd7a13e":"import os\nimport shutil\nimport pandas as pd\nimport random\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet201\n\nimport cv2\n\nimport warnings\nwarnings.filterwarnings('ignore')","a1208518":"train_df = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv\")\ntrain_df['img_name'] = train_df['image_id'] + \".jpg\"\ntrain_df.head()","156b6560":"target_multi_cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\nprint(\"Multi Classification Targets\")\nprint(train_df[target_multi_cols].sum())","3c566392":"def balance_set(df, x_cols, y_cols):\n    ros = RandomOverSampler(random_state=42)\n\n    x_multi, y_multi = ros.fit_resample(df[x_cols], df[y_cols].values)\n    data = pd.concat([x_multi, pd.DataFrame(y_multi, columns= y_cols)], axis=1)\n    return data\n\ntrain_multi = balance_set(train_df, \n                          x_cols = [\"image_id\", \"img_name\"],\n                          y_cols = target_multi_cols)\n\n\nlabels = train_multi[target_multi_cols]\nlabel_names = labels[labels==1].stack().reset_index()['level_1']\nlabel_names.index = train_multi.index\ntrain_multi['label_names'] = label_names\n\nprint(\"Multi Classification Labels\")\nprint(train_multi[target_multi_cols].sum())","c46dd1eb":"# a look at the multi class dataframe\ntrain_multi.head()","e664f4b4":"def blur_preprocessing(img):\n    return cv2.blur(img, (5, 5))\n\ntf.random.set_seed(99)\n\n## Initalize Image Data Generator with Augmentation\nimg_data_generator = ImageDataGenerator(rescale=1\/255, \n                                        validation_split=0.2,\n                                        rotation_range = 180,\n                                        horizontal_flip = True,\n                                        vertical_flip = True,\n                                        preprocessing_function=blur_preprocessing\n                                       )\n\n\n## Recreate datasets from dataframe\ntrain_data_multi = img_data_generator.flow_from_dataframe(dataframe=train_multi,\n                                                    directory=\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/\",\n                                                    x_col=\"img_name\",\n                                                    y_col= \"label_names\",\n                                                    target_size=(256, 256),\n                                                    class_mode='categorical',\n                                                    batch_size=32,\n                                                    subset='training',\n                                                    shuffle=True,\n                                                    seed=42)\n\nval_data_multi = img_data_generator.flow_from_dataframe(dataframe=train_multi,\n                                                    directory=\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/\",\n                                                    x_col=\"img_name\",\n                                                    y_col=\"label_names\",\n                                                    target_size=(256, 256),\n                                                    class_mode='categorical',\n                                                    batch_size=32,\n                                                    subset='validation',\n                                                    shuffle=True,\n                                                    seed=42)","a3ba2a6e":"def show_imgs(df, num):\n    fig, ax = plt.subplots(1,num, figsize=(18,9))\n    for x, y in df:\n        for img in range(num):\n            ax[img].imshow(x[img])\n            if y[img][0]:\n                title=\"healthy\"\n            else:\n                title='unhealthy'\n            ax[img].set_title(title)\n        break\nshow_imgs(train_data_multi, 5)","79d1039f":"# learning rate decay\nlearning_rate_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0003, \n                                                                         decay_steps=2, \n                                                                         decay_rate=0.97, \n                                                                         staircase=False)","71680f21":"try:\n    os.mkdir(\"..\/tmp\")\nexcept:\n    print(\"Directory \/tmp already exists\")\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"..\/tmp\/multi_class_weights_1\", \n                                                monitor='val_loss', \n                                                verbose=1, \n                                                save_best_only=False,\n                                                save_weights_only=True, \n                                                period=1)\n\n\n","04f39034":"class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n    \n    def on_train_begin(self, logs=None):\n        self.patience = 3\n        self.best = 0\n        self.wait = 0\n    \n    def on_epoch_end(self, epoch, logs=None):\n        if np.greater(logs[\"val_accuracy\"], self.best):\n            self.wait = 0\n            self.best = logs[\"val_accuracy\"]\n        else:\n            self.wait +=1\n            if self.wait >= self.patience:\n                print(f\"Stopping Training. Validation accuracy hasn't improved >= {self.patience} times\")\n                self.model.stop_training=True","03507910":"def dense_net_model(trainable_weights=False, weights_path=None):\n    \n    tf.keras.backend.clear_session()\n    \n    dense_net = DenseNet201(input_shape=(256, 256, 3), weights=\"imagenet\", include_top=False)\n    \n    for layer in dense_net.layers:\n        layer.trainable=trainable_weights\n    \n    model = tf.keras.models.Sequential([dense_net,\n                                        tf.keras.layers.GlobalAveragePooling2D(),\n                                        tf.keras.layers.Dense(128, activation='relu'),\n                                        tf.keras.layers.Dropout(0.3),\n                                        tf.keras.layers.Dense(4, activation='softmax')\n                                ])\n    \n    if weights_path:\n        model.load_weights(weights_path)\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n    \n    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n    \n    return model\n\ndense_net_transfer = dense_net_model(trainable_weights=True)\n\ndense_net_transfer_history = dense_net_transfer.fit(train_data_multi, validation_data=val_data_multi, epochs=25, steps_per_epoch=32, callbacks=[checkpoint, EarlyStoppingCallback()])","00cfef31":"#plot loss and accuracy helper function\ndef plot_loss_accuracy(history):\n    fig, axs = plt.subplots(1,2, figsize=(12, 5))\n\n    hist = history.history\n\n    for ax, metric in zip(axs, [\"loss\", \"accuracy\"]):\n        ax.plot(hist[metric])\n        ax.plot(hist[\"val_\"+metric])\n        ax.legend([metric, \"val_\" + metric])\n        ax.set_title(metric)\n\nplot_loss_accuracy(dense_net_transfer_history)","6a6d580b":"test_df = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv\")\ntest_df['img_name'] = test_df['image_id'] + \".jpg\"\n\ntest_datagen = ImageDataGenerator(rescale=1\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n                                                  directory=\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/\",\n                                                  x_col=\"img_name\",\n                                                  y_col=None,\n                                                  target_size=(256, 256),\n                                                  class_mode=None,\n                                                  batch_size=3,\n                                                  shuffle=False,\n                                                  seed=42)\n\ntest_generator.reset()","c156a6b3":"\npreds = dense_net_transfer.predict_generator(test_generator, verbose=1, steps=607)\n\npreds_df = pd.DataFrame(preds, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n\nsubmission = pd.concat([test_df.image_id, preds_df], axis=1)\n\nsubmission.head()","395629db":"submission.to_csv(\"submission_DenseNet.csv\", index=False)","62efeae4":"<a id=\"image-datagen\"><\/a>\n# Image Data Generator\n\nThe Image Data Generator API allows images to be baatch loaded and augmented on the fly. It can be used to return a tf.dataset.Dataset object that uses subdirectories to determin the labels. \n\nI.e. if sub directories are class_a, and class_b the generator will identify them as class 0 and 1. \n\nImage data generator contains 3 main methods for sourcing your images:\n- *flow()*\n- *flow_from_dataframe()*\n- *flow_from_directory()*\n\nEach method returns an iterator of tuples (x, y) where x and y are batches of the images, and labels respectively.\n\n<a id=\"setup\"><\/a>\n## Setup\n\n***flow_from_dataframe()*** allows us to read filenames from a dataframe. So we can define the root path, the dataframe, and the columns that contain the file names, and target labels.\n\n***flow_from_directory()*** requires a specific directory setup to work correctly. It will read files directly from the parent directory passed in. Each directory must contain subfolders with the names of the classes. To have a train, valid, and test setup you need to create subdirectories for each class within each. \n\n![image.png](attachment:image.png)\n\nIf no subdirectory is present image data generator will not return class labels. This could be desired, for example in the case of the test folder in the above image.\n\n<a id=\"image-augmentation\"><\/a>\n## Augmentation\n\nImage augmentation applies transforms to an image and results in additional images that the network can train on. Image data generator has [many options](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator) and also allows custom preprocesing functions through the parameter of the same name.\n\nThe images below are augmented with:\n- Rotation of up to 180 degrees\n- Horizontal Flips\n- Verticle Flips\n- A preprocessing function adding a small blur to the image","05f77ebd":"<a id=\"densenet\"><\/a>\n## DenseNet\n\nDenseNet is the successor of ResNet and is distinguished as having fewer parameters and higher accuracy. It achieves this by connecting additional inputs from all previous layers into the feature maps of the current layer. As described in [this great article on DenseNet](https:\/\/towardsdatascience.com\/review-densenet-image-classification-b6631a8ef803): \"each layer is receiving a collective knowlege from all preceeding layers\".\n\nTwo advantages of DenseNet's architecture makes it ideal for using transferlearning for the Multi Classification task here:\n1. Diversity of features in convolution maps - useful for detecting small detailed features for example.\n2. Maintaining low complexitiy features - useful for detecting obvious defects in the leaf.\n\n\nWe use the `tf.keras.applications.DenseNet201` implementation of DenseNet with the 'imagenet' weights.","01a0e524":"<a id=\"model-checkpoint\"><\/a>\n## Model Checkpoints\nModel Checkpoints are a call mack technique that allows us to save the model or weights at a given frequency. This allows us to:\n1. Start and stop the model at arbitary points in the training process.\n2. Track and log the progression of the weights. If `save_best_only=True` this will only save the weights\/models with the best performance.\n3. Roll back a model to a specific point in trianing. I.e. if performance becomes poor we can modify the network, reload the weights and start again.\n\nModel checkpoints are implmented with the `tf.keras.callbacks.ModelCheckpoint`. [Documentation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ModelCheckpoint)","533a7e60":"<a id=\"multi-class-model\"><\/a>\n# Multi Classification Modelling\n\n<a id=\"learning-rate-decay\"><\/a>\n## Learning Rate Decay\nLearning rate decay is a method of changing the learning rate with the number of epochs. The technique is used as a form of regularization and to fine tune a model bringing it closer to the local minimum.\n\nIntuitively learning rate decay means smaller steps along the gadient towards the local minima. So the longer we train, the lower the learning rate will be.  Initally we take large steps along the gradient we find we could result in a situation like the \"high learning rate\" graph below. Learning rate decay prevents this by reducing the learning rate gradually, with the effect of taking smaller steps and more likely to find the minimum. The drawback is that reducing the learning rate too quick and we could end up similar to the graph \"learning rate too low\". The following article from [Machine Learning Mastery](https:\/\/machinelearningmastery.com\/learning-rate-for-deep-learning-neural-networks\/#:~:text=The%20way%20in%20which%20the,value%20to%20a%20small%20value.) is a good reference.\n\n![image.png](attachment:image.png)\n\nSource: [bdhammel.com](http:\/\/www.bdhammel.com\/learning-rates\/)\n\n### Types of Learning Rate Decay in Tensorflow\nWe can control the learning rate with the module tf.keras.optimizers.schedules with the following types of decay [Tensorflow Documentation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/schedules).\n- ExponentialDecay: A LearningRateSchedule that uses an exponential decay schedule.\n- InverseTimeDecay: A LearningRateSchedule that uses an inverse time decay schedule.\n- LearningRateSchedule: A serializable learning rate decay schedule.\n- PiecewiseConstantDecay: A LearningRateSchedule that uses a piecewise constant decay schedule.\n- PolynomialDecay: A LearningRateSchedule that uses a polynomial decay schedule.\n\n","773f1001":"<a id=\"balance-data\"><\/a>\n# Balance Dataset\n\nCreate a balanced dataset for each of the multi classification targets. This results in an equal number of sampels between the multiple classes.","28674811":"<a id=\"transfer-learning\"><\/a>\n## Transfer learning\nTransfer learning is the practice of using a model, and weights that was trained on a differnt task and applying it to a new task. The idea is to take advantage of what the model learned on the original task and to \"transfer\" this to the current task.\n\nThis is achieved by reusing part of the original model's architechre and only changing the last few layers - typically the dense layers. In the diagram below we see a generic network with a generic task. This could be something like ImageNet that was trained on 1000+ objects. But we're just interested in a few classes, so we reuse the trained weights early in the model. The result is the second network, where we use a specific dataset, for a specific task. \n\n![image.png](attachment:image.png)\nSource: [Open Journal For Quantam Science](https:\/\/quantum-journal.org\/papers\/q-2020-10-09-340\/)\n\nThere are several advantages of using transfer learning:\n1. Leverage learned weights on much larger datasets and the ability to fine tune the weights. Using the `layer.trainable = False` we can control if a layer's weights will be trained or not. For some tasks it might be advantageous to allow some of the weights in early layers to train and in doing so, fine tune for the specific task. \n2. Need for a much smaller dataset. Training an accurate model from scratch can require 10X, 100X times the numbers of samples needed to generalize the network for the task.\n\n\n","c9b15556":"Explore some of the images and see how they look.","e815b22b":"<a id=\"making-predictions\"><\/a>\n## Making Predictions\n\n`ImageDataGenerator` can also be used to create predictions in a similar way as when we trained the model with the `.flow_from_dataframe` method. However to predict we don't need to define a y_col. The reset method is called on the data generator to reset the batch starting point after inference.","88b725dc":"# Introduction\n\nThis notebook builds two models using the plant pathology dataset with the aim of practicing building a tensorflow classifier in preparation for the tensorflow certification exam. It is part of a series of notebooks and resources contained in this [github repo](https:\/\/github.com\/nicholasjhana\/tensorflow-certification-study-guide).\n\n\nThe plant pathology challenge is to classifiy apple leaves according to their image. Leaves can be classified as \"healthy\", \"multiple diseases\", \"scab\", and \"rust\". In this notebook we model the multi classification problem using transfer learning. Along the way are short discussions of tensorflow API concepts and how to use them.\n\n## Tensorflow Concepts\nThis notebook covers the following topics from the tensorflow certification handbook:\n- Directory labelling structure for Image Data Generator\n- Using Image Data Generator with dataframes\n- Using image augmentation with Image Data Generator\n- Using learning rate decay\n- Using transfer learning and model checkpoints\n\n\n## Acknowledgements\n- [Plant Pathology 2020 : EDA + Models - tarunpaparaju](https:\/\/www.kaggle.com\/tarunpaparaju\/plant-pathology-2020-eda-models#Modeling-)\n- [Tutorial on using Keras flow_from_directory and generators - Vijayabhaskar J\n](https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)\n- [How to use .predict_generator() on new Images - Keras](https:\/\/stackoverflow.com\/questions\/52270177\/how-to-use-predict-generator-on-new-images-keras\/55991598)\n- [What Learning Rate Should I Use? - B. D. Hammel](http:\/\/www.bdhammel.com\/learning-rates\/)\n- [DenseNet \u2014 Dense Convolutional Network - Sik-Ho Tsang](https:\/\/towardsdatascience.com\/review-densenet-image-classification-b6631a8ef803)\n\n## Notebook Contents\n- [Balance Data](#balance-data)\n- [Image Data Generator](#image-datagen)\n    - [Setup](#setup)\n    - [Image Augmentation](#image-augmentation)\n- [Multi Classification Modelling](#multi-class-model)\n    - [Learning rate decay](#learning-rate-decay)\n    - [Model checkpoints](#model-checkpoint)\n    - [Transfer learning](#transfer-learning)\n    - [DenseNet](#densenet)\n    - [Making predictions](#making-predictions)"}}