{"cell_type":{"654aaa39":"code","b2eef438":"code","3ed90e66":"code","6c656510":"code","3ab4d77c":"code","2a26a375":"code","34163fa4":"code","13838d37":"code","aa5ef7f5":"code","3b999a9d":"code","5bd5ee2a":"code","6b1d35af":"code","823650ec":"code","7c259511":"code","83b32a5b":"code","0b4ecf28":"code","029a47d8":"code","cdadf599":"code","992d6b8e":"code","a9ef5f0f":"code","c72df39e":"code","1e411c71":"code","36ef428e":"code","64bb894c":"code","4b9adb24":"code","7c9c43f0":"code","202fdf2f":"code","c8daff2f":"code","621e4457":"code","4642e711":"code","068b5f89":"code","155f1716":"code","6cbeb662":"code","dd7a0173":"code","6bbe1fe4":"code","39dfcb07":"code","c6d64ccc":"code","4a8248ab":"code","2a706e63":"code","162b7c03":"code","df78a5e1":"code","d67a69d7":"code","48ca7c72":"code","f204b750":"code","e2d1a810":"code","c4f4b6d2":"code","69b59ddc":"code","4e0ae627":"code","a5349353":"code","055a20fc":"code","29f02506":"code","4b61bdff":"code","6d6425d3":"code","b542b7c0":"code","e9250e05":"code","f1000e01":"code","fa098f72":"code","22ba3efb":"code","5c2911c9":"code","7aca253e":"code","44d736f1":"code","c6e7e916":"markdown","be74ed64":"markdown","ee84a820":"markdown"},"source":{"654aaa39":"#Importing the necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')","b2eef438":"#Loading the dataset\n\ntrain=pd.read_csv(r'..\/input\/house-prices-advanced-regression-techniques\/train.csv')","3ed90e66":"#Viewing the first five rows of the train dataset\n\ntrain.head()","6c656510":"#Checking the number of rows and columns\n\ntrain.shape","3ab4d77c":"#Loading the test dataset\n\ntest=pd.read_csv(r'..\/input\/house-prices-advanced-regression-techniques\/test.csv')","2a26a375":"#Checking the number of rows and columns of test dataset\n\ntest.shape","34163fa4":"#Summarizing the distribution of the data\n\ntrain.describe()","13838d37":"#Datatypes of the features in training data\n\ntrain.dtypes","aa5ef7f5":"#Count of each datatype of the features\n\ntrain.dtypes.value_counts()","3b999a9d":"#Summarizing the distribution of the target variable\n\ntrain['SalePrice'].describe()","5bd5ee2a":"# Checking for id duplicates\n\nunique=len(set(train['Id']))\ntotal=len(train['Id'])\ndup=total - unique\nprint(\"No of duplicate ID values in train dataset :\",dup)\n\nunique_t=len(set(test['Id']))\ntotal_t=len(test['Id'])\ndup_t=total_t - unique_t\nprint(\"No of duplicate ID values in test dataset :\",dup_t)\n","6b1d35af":"# Since ID values are all unique, dropping this feature\n# Creating a new dataframe to store the id values of test dataset for final submission\n\nsubmission=pd.DataFrame()\nsubmission['Id']=test['Id']\ntrain.drop(['Id'],axis=1,inplace=True)\ntest.drop(['Id'],axis=1,inplace=True)","823650ec":"# Missing values in train dataset\n\nmisval=train.isnull().sum()\nmisval=misval[misval>0]\nprint(misval)","7c259511":"# Dropping features with more than 600 missing values\n\ntrain.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)","83b32a5b":"# Numerical features vs Categorical features\n\nnum_feat=train.select_dtypes(exclude=[object]).columns\ncat_feat=train.select_dtypes(include=[object]).columns\nprint(\"No. of numerical features:\",len(num_feat))\nprint(num_feat)\nprint(\"No. of categorical features:\",len(cat_feat))\nprint(cat_feat)\n","0b4ecf28":"# Imputing missing values in numerical features with their median\n\ntrain=train.fillna(train.median())\nsns.heatmap(train.isnull(),cbar=False)","029a47d8":"# Missing values in categorical features of train dataset\n\nmisval=train.isnull().sum()\nmisval=misval[misval>0]\nprint(misval)","cdadf599":"# Imputing missing values in categorical features with their mode, one by one","992d6b8e":"train['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])","a9ef5f0f":"train['BsmtCond']=train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])","c72df39e":"train['BsmtExposure']=train['BsmtExposure'].fillna(train['BsmtExposure'].mode()[0])","1e411c71":"train['BsmtFinType1']=train['BsmtFinType1'].fillna(train['BsmtFinType1'].mode()[0])","36ef428e":"train['BsmtFinType2']=train['BsmtFinType2'].fillna(train['BsmtFinType2'].mode()[0])","64bb894c":"train['GarageType']=train['GarageType'].fillna(train['GarageType'].mode()[0])","4b9adb24":"train['GarageFinish']=train['GarageFinish'].fillna(train['GarageFinish'].mode()[0])","7c9c43f0":"train['GarageQual']=train['GarageQual'].fillna(train['GarageQual'].mode()[0])","202fdf2f":"train['GarageCond']=train['GarageCond'].fillna(train['GarageCond'].mode()[0])","c8daff2f":"train['MasVnrType']=train['MasVnrType'].fillna(train['MasVnrType'].mode()[0])","621e4457":"train['Electrical']=train['Electrical'].fillna(train['Electrical'].mode()[0])","4642e711":"sns.heatmap(train.isnull(),cbar=False)","068b5f89":"# Missing values in test dataset\n\nmisval_t=test.isnull().sum()\nmisval_t=misval_t[misval_t>0]\nprint(misval_t)","155f1716":"# Dropping features with more than 600 missing values\n\ntest.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)","6cbeb662":"# Numerical features vs Categorical features\n\nnum_feat_test= test.select_dtypes(exclude='object').columns\ncat_feat_test= test.select_dtypes(include='object').columns\nprint(\"No. of numerical features in test dataset:\",len(num_feat_test))\nprint(num_feat_test)\nprint(\"No. of categorical features in test dataset:\",len(cat_feat_test))\nprint(cat_feat_test)\n","dd7a0173":"# Imputing missing values in numerical features of test dataset with their median\n\ntest=test.fillna(test.median())\nsns.heatmap(test.isnull(),cbar=False)","6bbe1fe4":"#Imputing missing values in categorical features of test dataset with their mode\n\ntest['BsmtQual']=test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])\ntest['BsmtCond']=test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\ntest['BsmtExposure']=test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])\ntest['BsmtFinType1']=test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\ntest['BsmtFinType2']=test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])\ntest['GarageType']=test['GarageType'].fillna(test['GarageType'].mode()[0])\ntest['GarageFinish']=test['GarageFinish'].fillna(test['GarageFinish'].mode()[0])\ntest['GarageQual']=test['GarageQual'].fillna(test['GarageQual'].mode()[0])\ntest['GarageCond']=test['GarageCond'].fillna(test['GarageCond'].mode()[0])\ntest['MasVnrType']=test['MasVnrType'].fillna(test['MasVnrType'].mode()[0])","39dfcb07":"#Checking whether null values are present in the other columns\n\nmisval_t=test.isnull().sum()\nmisval_t=misval_t[misval_t>0]\nprint(misval_t)","c6d64ccc":"# Unlike train dataset, there are more features with missing values in the test dataset.\n# Therefore, imputing them with their mode too.","4a8248ab":"test['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])\ntest['Utilities']=test['Utilities'].fillna(test['Utilities'].mode()[0])\ntest['Exterior1st']=test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\ntest['Exterior2nd']=test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\ntest['KitchenQual']=test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\ntest['Functional']=test['Functional'].fillna(test['Functional'].mode()[0])\ntest['SaleType']=test['SaleType'].fillna(test['SaleType'].mode()[0])","2a706e63":"#Visualizing whether null values are present after imputation\n\nsns.heatmap(test.isnull(),cbar=False)","162b7c03":"#Viewing the shape of test dataset after preprocessing\n\ntest.shape","df78a5e1":"#Viewing the shape of train dataset after preprocessing\n\ntrain.shape","d67a69d7":"#Concatenating the test and train data\n\nfile=pd.concat([train,test],axis=0)\nfile.shape","48ca7c72":"# One hot encoding of categorical features\n\nfile=pd.get_dummies(file)\nfile.shape","f204b750":"#Viewing the first five rows of the file after concatenating train and test dataset and applying one hot encoding \n\nfile.head()","e2d1a810":"# Since we do not have the SalePrice feature in the test dataset, we get all NaN values in that column.\n\nmis_file=file.isnull().sum()\nmis_file=mis_file[mis_file>0]\nprint(mis_file)","c4f4b6d2":"traindata=file.iloc[:1460]\ntraindata.shape","69b59ddc":"traindata.head()","4e0ae627":"testdata=file.iloc[1460:]\n\n# Since the test data has all Nan values in SalePrice column, we will drop that column.\n\ntestdata.drop(['SalePrice'],axis=1,inplace=True)\ntestdata.shape","a5349353":"#Visualizing the distribution of target variable\n\nsns.distplot(traindata['SalePrice'])","055a20fc":"#Since the distribution is right skewed, log transformation is done for attaining normal distribution\n\ntraindata['SalePrice']= np.log(traindata['SalePrice'])\nsns.distplot(traindata['SalePrice'])","29f02506":"x_train=traindata.drop(['SalePrice'],axis=1)\ny_train=traindata['SalePrice']","4b61bdff":"\n#Standardization of the numerical features\n\nscaler=StandardScaler()\nscaler.fit_transform(x_train)","6d6425d3":"model=Lasso()\n\nparam_grid={'alpha':[1e-4,1e-2,1,10,100]}\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\nresult=grid_search.fit(x_train,y_train)\nprint(\"Best score using Lasso: %f with %s\"%(result.best_score_,result.best_params_))","b542b7c0":"model=ElasticNet()\n\nparam_grid={'alpha':[1e-4,1e-2,1,10],'l1_ratio':[0,0.5,1]}\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\nresult=grid_search.fit(x_train,y_train)\nprint(\"Best score using ElasticNet: %f with %s\"%(result.best_score_,result.best_params_))","e9250e05":"model=RandomForestRegressor()\n\nn_estimators=[10,50,100,150,200,250,300]\nmax_features=['sqrt','log2']\nparam_grid=dict(n_estimators=n_estimators,max_features=max_features)\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\nresult=random_search.fit(x_train,y_train)\nprint(\"Best score using RandomForest: %f with %s\"%(result.best_score_,result.best_params_))","f1000e01":"model=xgboost.XGBRegressor()\n\nbooster=['gbtree','gblinear']\nlearning_rate=[0.001,0.01,0.1,0.2,0.5]\nn_estimators=[50,100,150,200,250,300]\nmax_depth=[2,4,6,8]\nparam_grid=dict(booster=booster,max_depth=max_depth,n_estimators=n_estimators,learning_rate=learning_rate)\n\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\nresult=random_search.fit(x_train,y_train)\nprint(\"Best score using XGBoost: %f with %s\"%(result.best_score_,result.best_params_))","fa098f72":"#The parameters chosen by random seach which gave the highest score and minimum loss.\n\nprint(result.best_estimator_)","22ba3efb":"#Since xgboost gives the lowest negative mean squared error, we will use the hyperparameter tuned model to predict the SalePrice.\n\nf_model=xgboost.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=8,\n             min_child_weight=1, monotone_constraints='()',\n             n_estimators=300, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)\nf_model.fit(x_train,y_train)","5c2911c9":"#Predicting the SalePrice values and taking their antilog to store as predictions.\n\ny_pred=f_model.predict(testdata)\npredictions=np.exp(y_pred)\nprint(predictions)","7aca253e":"#Predicted target variable is stored in a new csv file for submission\n\nsubmission['SalePrice']=predictions\nsubmission.to_csv(r\"C:\\Users\\Dipanjan Dey Sarkar\\OneDrive\\Documents\\sampleSubmission.csv\",index=False)","44d736f1":"#Visualizing the distribution of the predicted SalePrice\n\nsns.distplot(predictions)","c6e7e916":"Objective: To predict the SalePrice of houses using the dataset provided in the competition - using regression techniques","be74ed64":"# Predictive Modeling","ee84a820":"Features:\n\nHere's a brief version of what you'll find in the data description file.\n\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale"}}