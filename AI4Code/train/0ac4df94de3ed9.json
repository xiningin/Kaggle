{"cell_type":{"612303b4":"code","81c0f761":"code","384b9541":"code","a285debf":"code","d8a15f47":"code","47f7e6bf":"code","0cc302f3":"code","0ffc72a3":"code","2b7fd1b3":"code","66516d81":"code","875482c1":"markdown","b055b0bc":"markdown","14298e68":"markdown","8594d3e6":"markdown","d397c078":"markdown","3db664c7":"markdown","e565e5e1":"markdown"},"source":{"612303b4":"import pandas as pd\n# load data\n#dataset = pd.read_csv(\"..\/input\/gender_testdata.csv\")\ndataset = pd.read_excel(\"..\/input\/gender\/gender.xlsx\")","81c0f761":"dataset[\"NAME\"] = dataset[\"FIRST_NAME\"] + \" \" + dataset[\"LAST_NAME\"]\ndataset.groupby('SEX')['FIRST_NAME'].count()","384b9541":"dataset.head()","a285debf":"# Dropping last 20K rows as we have limitation in memory in this kernel. In real case this line code have to be commented\ndataset.drop(dataset.tail(20000).index,inplace=True)","d8a15f47":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(dataset[\"NAME\"].values.astype('U')).toarray()\ny = dataset.iloc[:, 2].values","47f7e6bf":"# split to train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)","0cc302f3":"print ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","0ffc72a3":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","2b7fd1b3":"y_pred= classifier.predict(X_test)","66516d81":"########## Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint('Accurancy: {:.0f}%'.format(classifier.score(X_test, y_test)*100))","875482c1":"Convert a collection of text documents to a matrix of token counts\n\nThis implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n\nIf you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.","b055b0bc":"# **Training Model - Naive Bayes**","14298e68":"Splitting  To Train\/Test Data","8594d3e6":"# <font color=blue|red|green|pink|yellow>GURU<\/font>\n[www.aiguru.az](http:\/\/aiguru.az)\n## Determine Gender By Name\n### Author   : Ramin Hashimzade\n### Location : Azerbaijan, Baku","d397c078":"### Concatenate First Name & Last Name","3db664c7":"### Datasset Description\nData Generated for test purpose, for confidential reason I can not share real Data. For training you have to have much more data.\n\n*   FIRST_NAME\n*   LAST_NAME\n*   SEX (M\/F)","e565e5e1":"### Import Library"}}