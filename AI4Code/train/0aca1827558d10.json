{"cell_type":{"3817153b":"code","911c665a":"code","8c480249":"code","e0ef2649":"code","ef377ec5":"code","c7c70461":"code","d3a5819e":"code","4180ac77":"code","0f4d4252":"code","13b329ee":"code","c3e5cc16":"code","2f107d1c":"code","db8eb543":"code","8d3f5cf0":"code","357865e8":"code","6a45dba8":"code","2ab3722d":"code","cb175356":"code","7542b526":"code","2cb60481":"markdown","194df524":"markdown","fb3d3f27":"markdown","1ed4d333":"markdown","080555de":"markdown","cf88f0b8":"markdown","2df63a67":"markdown","b63975e3":"markdown","211d69ea":"markdown","898c976c":"markdown","7ab2bfdd":"markdown","792f9ed4":"markdown","f7361814":"markdown","05f1978d":"markdown","dafa6a07":"markdown","094d56ba":"markdown","15d86a9f":"markdown","7f52798f":"markdown","1ea599bf":"markdown","4f39652f":"markdown","b35c508c":"markdown","97d7f9c8":"markdown","45c2ce31":"markdown","3b561503":"markdown","56154378":"markdown","ebaae273":"markdown","9431bfdb":"markdown","2059b850":"markdown","73e4fb0e":"markdown"},"source":{"3817153b":"import numpy as np\nimport pandas as pd","911c665a":"df = pd.read_csv(\"..\/input\/project2\/sensor_train.csv\", parse_dates=[\"timestamp\"], index_col=0)","8c480249":"df = df.dropna(axis=\"columns\", thresh=len(df) * 0.50).dropna()","e0ef2649":"df.plot(subplots=True, figsize=(12,60));","ef377ec5":"train_idx = np.where(df.index < \"2018-05-15\")[0]\nval_idx = np.where(df.index >= \"2018-05-15\")[0]","c7c70461":"# general machine learning\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier","d3a5819e":"from sklearn.metrics import confusion_matrix, balanced_accuracy_score, make_scorer, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GridSearchCV","4180ac77":"X, y = (df.iloc[:,:-1].values, df.iloc[:,-1].values)","0f4d4252":"# initialisierung des modells (mit default hyperparametern)\ndt = DecisionTreeClassifier()\n\n# lernen des modells\ndt.fit(X[train_idx], y[train_idx])\n\n# vorhersage neuer daten\nyhat = dt.predict(X[val_idx])\n\n# berechnung der confusion matrix\ncm = confusion_matrix(y[val_idx], yhat)\n\n# visualisierung der confusion matrix\nConfusionMatrixDisplay(cm).plot();","13b329ee":"# angabe der zu durchsuchenden parameter\nparam_grid = {\"max_depth\": [None, 5, 10, 15, 20, 25, 30, 35, 40]}\n\n# definition des verfahrens zur hyperparameteroptimierung (in dem fall holdout validierung)\n# und auswertung anhand von `balanced_accuracy_score`\ngs = GridSearchCV(dt, param_grid,\n                  cv=[(train_idx, val_idx)],\n                  scoring=make_scorer(balanced_accuracy_score),\n                  n_jobs=-1)","c3e5cc16":"# durchsuchen der parameter und anzeige der besten vorhersage und besten parameter\ngs.fit(X, y)\ngs.best_score_, gs.best_params_","2f107d1c":"# definition des finalen modells\nfinal = gs.best_estimator_","db8eb543":"!pip install skorch --quiet","8d3f5cf0":"# torch sklearn bridge\nimport torch\nimport skorch\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer","357865e8":"class MLP(torch.nn.Module):\n    def __init__(self, input_dim=10, num_units=100, num_classes=2, activation=torch.nn.ReLU()):\n        super(MLP, self).__init__()\n\n        self.activation = activation\n        self.dense0 = torch.nn.Linear(input_dim, num_units)\n        self.dense1 = torch.nn.Linear(num_units, num_units)\n        self.output = torch.nn.Linear(num_units, num_classes)\n        self.softmax = torch.nn.Softmax(dim=-1)\n\n    def forward(self, X, **kwargs):\n        X = self.activation(self.dense0(X))\n        X = self.activation(self.dense1(X))\n        X = self.softmax(self.output(X))\n        return X","6a45dba8":"class InputShapeSetter(skorch.callbacks.Callback):\n    def on_train_begin(self, net, X, y):\n        net.set_params(module__input_dim=X.shape[-1])","2ab3722d":"net = skorch.NeuralNetClassifier(MLP,\n                                 lr=0.01,\n                                 max_epochs=50,\n                                 train_split=skorch.dataset.ValidSplit(cv=[(train_idx, val_idx)]),\n                                 callbacks=[InputShapeSetter()])","cb175356":"pipe = Pipeline([\n    # transform input features to standard-normal distribution\n    ('scale', StandardScaler()),\n    # convert numpy values to torch values\n    ('convert', FunctionTransformer(torch.FloatTensor)),\n    # provide the values to the network\n    ('net', net)\n])","7542b526":"pipe.fit(X, y)","2cb60481":"## 1. Question\/Task + Data","194df524":"> Lernen Sie ein Modell anhand der Trainingsdaten und bewerten Sie das Modell anhand der Validierungsdaten (siehe Beispiel)","fb3d3f27":"> Finden Sie die optimalen Hyperparameter (siehe Beispiel)","1ed4d333":"**Stellen Sie nun sicher, dass Ihr Notebook abgabebereit ist. Rufen Sie hierf\u00fcr links oben `Run\/Restart Session + Run\/Run All` um alle Berechnungen erneut durchzuf\u00fchren.\nVersichern Sie sich, dass keine Fehler aufgetreten sind und geben Sie das Notebook ab.**","080555de":"> Schaffen Sie sich einen \u00dcberblick \u00fcber den Datensatz und nutzen Sie hierf\u00fcr bereits bekannte Methoden wie z.B. `df.info()`","cf88f0b8":"> Extrahieren Sie die `X` (features) und `y` (target) Werte aus dem vorbereiteten Datensatz (siehe Beispiel)","2df63a67":"> Untersuchen Sie die Daten nach fehlenden Werten und entfernen Sie diese. Das Ziel ist es m\u00f6glichst viel Information f\u00fcr die sp\u00e4tere Vorhersage zu erhalten.","b63975e3":"> Speichern Sie ihr bestes Modell als `final` Variable","211d69ea":"> Erstellen Sie einen Index f\u00fcr Trainings- und Validierungsdaten in dem Sie folgende Zelle aufrufen. Stellen Sie daf\u00fcr sicher, dass ihr vorverarbeiteter Datensatz in der Variable `df` gespeichert wurde.","898c976c":"Man kann z.B. mit `df.isna().sum()` feststellen wie viele Daten pro Spalte fehlen. Bei vielen fehlenden Daten entfernt man oft die ganze Spalte, z.B. mit `df.dropna(axis=\"columns\", thresh=len(df) * 0.50)`. Der Befehlt beh\u00e4lt nur Spalten in denen mehr als 50% der Werte vorhanden sind. Ob man fehlende Werte entfernt oder z.B. mit einem Wert ersetzt ist vom Hintergrundwissen und der Aufgabenstellung abh\u00e4ngig. Wenn man gen\u00fcgend Daten hat bevorzugt man \u00fcblicherweise das Entfernen von Daten. Nachdem man die Spalten mit vielen fehlenden Werten entfernt hat kann man z.B. alle verbleibenden Beobachtungen mit fehlenden Werte entfernen durch `df.dropna()`.","7ab2bfdd":"> Betrachten Sie wie viele Auspr\u00e4gungen es f\u00fcr den zu Vorhersagenden Wert gibt mit","792f9ed4":"> Optional: Bedenken Sie Datenvorverarbeitungsschritte f\u00fcr sp\u00e4ter gew\u00e4hlte Algorithmen (z.B. Normalisierung)","f7361814":"Sensoren einer Maschine zeichnen kontinuierlich Daten auf und der Maschinenzustand der letzten Monate wurde laufend manuell \u00fcberwacht. Auf Basis der Beobachtungen besteht Ihre Aufgabe nun darin festzustellen ob sich die Maschine in einem normalen oder anormalen Zustand befindet.","05f1978d":"> Optional: Identifizieren Sie sinnvolle Merkmale anhand Ihrer vorherigen Analyse","dafa6a07":"## 4. Choose Model Class","094d56ba":"Importieren Sie folgende in der Vorlesung besprochene Modelle sowie Hilfsfunktionen.","15d86a9f":"Das hier abgegebene Modell durchl\u00e4uft sp\u00e4ter die Bewertung anhand der zur\u00fcckgehaltenen Daten.","7f52798f":"Das Ziel ist es einen Algorithmus zu finden, welcher auf den zur\u00fcckgehaltenen Testdaten optimal funktioniert. Die Produktionsexperten in Ihrem Unternehmen legen fest, dass ihr Modell m\u00f6glichst viele Fehlst\u00e4nde erkennen soll aber gleichzeitig m\u00f6glichst wenige falsche Fehlst\u00e4nde liefern soll. Sie liefern hierf\u00fcr folgende Formel: $$\\texttt{balanced-accuracy} = \\frac{1}{2}\\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP}\\right )$$. Der Wert entspricht dem Mittel aus Sensitivit\u00e4t und Spezifit\u00e4t, siehe <https:\/\/en.wikipedia.org\/wiki\/Sensitivity_and_specificity>. Gl\u00fccklicherweise ist diese Funktion bereits in `sklearn.metrics` implementiert!","1ea599bf":"## 2. Preprocessing","4f39652f":"### 1.1 F\u00fchren Sie folgenden Befehl aus um die Daten zu laden.","b35c508c":"Ihr Trainingsindex ist nun gespeichert als `train_idx` und beinhaltet alle Daten vom 1. April bis zum 14. Mai 2018. Der Validierungsindex ist gespeichert als `val_idx` und beinhaltet die Daten vom 15. Mai bis zum 16. Juni 2018.","97d7f9c8":"## 5\/6. Train Model - Evaluate Model","45c2ce31":"> Visualisieren Sie den vorverarbeiteten Trainingsdatensatz um ein besseres Verst\u00e4ndnis zu erhalten (siehe Beispiel)","3b561503":"## 3. Choose Features","56154378":"Die Maschinenzust\u00e4nde befinden sich in der Spalte `machine_status`, wobei `0` den normalen und `1` den anormalen Zustand beschreibt.\n\nErzeugen Sie ein Vorhersagemodell um diese Zust\u00e4nde in Zukunft automatisiert vorherzusagen.","ebaae273":"Das folgende Beispiel zeigt wie man ein neuronales Netzwerk eigenst\u00e4ndig anlegt und lernt. Sie k\u00f6nnen ein solches neuronales Netz nutzen.","9431bfdb":"# 00 - Project 2 - Zustands\u00fcberwachung einer Maschine","2059b850":"## 7. Final Model","73e4fb0e":"# Extra: Training Custom Neural Networks"}}