{"cell_type":{"eeecc076":"code","4b5af793":"code","c9f66408":"code","7efdebcd":"code","37873f6f":"code","d56f1718":"code","e9843bdf":"code","70829faf":"code","84dc70f8":"code","3142e143":"code","e6b96942":"code","ab36bb1f":"code","65c85b48":"code","8b084af8":"markdown","bede93ec":"markdown"},"source":{"eeecc076":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b5af793":"import tensorflow as tf # These lib will be useful in getting the APIs for tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential\nimport os # for creating directories, os related stuff\nimport math\nimport shutil # to shuffle the images in the dir\nimport random # again to shufle I guess, not sure!\nimport matplotlib.pyplot as plt # to plt\nimport seaborn as sns # to plt\nfrom keras.preprocessing.image import load_img, img_to_array # load image from the dirs\nfrom glob import glob #get the paths which has some pattern to follow\nimport cv2","c9f66408":"data = pd.read_csv('..\/input\/lego-minifigures-classification\/index.csv')\ndata.head(10)","7efdebcd":"for path in data['path']:\n    img = cv2.imread(str('..\/input\/lego-minifigures-classification'+'\/'+path)) #Just reading the path to get the very first image\n    print(np.array(img)\/255)\n    break","37873f6f":"X = []\ny = []\n\nfor path in data['path']:\n    img = cv2.imread(str('..\/input\/lego-minifigures-classification'+'\/'+path))\n    resized_img = cv2.resize(img,(224,224)) # Resizing the image\n    scaled_img = np.array(resized_img)\/255 # Scaling the image\n    X.append(scaled_img) # Appending it to X","d56f1718":"y = np.array(data['class_id'])-1","e9843bdf":"X = np.array(X)\ny = np.array(y)","70829faf":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,random_state=0)","84dc70f8":"data_augmentation = Sequential([\n    layers.experimental.preprocessing.RandomFlip('horizontal',input_shape = (224,224,3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n])","3142e143":"num_classes = data['class_id'].nunique()","e6b96942":"model = Sequential([\n    data_augmentation,\n    layers.Conv2D(64,3,padding='same',activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32,3,padding='same',activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(16,3,padding='same',activation='relu'),\n    layers.Flatten(),\n    layers.Dense(128,activation='relu'),\n    layers.Dense(num_classes),\n])","ab36bb1f":"model.compile(\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # since we did not use any activation in the output layer\n    optimizer = 'adam',\n    metrics = ['accuracy'],\n)","65c85b48":"model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=50,verbose=2)","8b084af8":"### Model Building","bede93ec":"Imoprting Libraries"}}