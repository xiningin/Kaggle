{"cell_type":{"67d58732":"code","f54c515a":"code","2a9fc185":"code","d53b85c3":"code","7a857da9":"code","c6de0743":"code","71fed4c0":"code","6a376427":"code","4b8109a5":"code","b6ed2b11":"code","db3980dc":"code","e52c0776":"code","5f824dbe":"code","439eaca8":"code","2dad19f7":"markdown","9dd40ae9":"markdown","fdcd1c72":"markdown","b74f6cd8":"markdown","f9e0b182":"markdown","2256e2fd":"markdown","5441312a":"markdown","c787e2a6":"markdown","89a4a7fb":"markdown","d5e12a3b":"markdown","37fda5fd":"markdown","44adc83b":"markdown","8e6000de":"markdown"},"source":{"67d58732":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html > \/dev\/null\n!pip install git+https:\/\/github.com\/tmabraham\/upit.git >\/dev\/null","f54c515a":"from upit.data.unpaired import *\nfrom upit.models.cyclegan import *\nfrom upit.train.cyclegan import *\nfrom upit.inference.cyclegan import *\nfrom fastai.vision.all import *\n","2a9fc185":"trainA_path = Path('..\/input\/gan-getting-started\/photo_jpg')\ntrainB_path = Path('..\/input\/gan-getting-started\/monet_jpg')\nprint(f\"There are {len(trainA_path.ls())} photos\")\nprint(f\"There are {len(trainB_path.ls())} Monet paintings\")","d53b85c3":"dls = get_dls(trainA_path, trainB_path,load_size=256,crop_size=256)","7a857da9":"dls.show_batch()","c6de0743":"cycle_gan = CycleGAN(3,3,64,gen_blocks=3)","71fed4c0":"learn = cycle_learner(dls, cycle_gan,opt_func=partial(Adam,mom=0.5,sqr_mom=0.999),show_img_interval=8)","6a376427":"learn.lr_find()","4b8109a5":"learn.fit_flat_lin(7,7,2e-4)","b6ed2b11":"b = dls.one_batch()\n_,_,preds = learn.get_preds(dl=[b], with_decoded=True)","db3980dc":"dls.show_batch((b[0], b[1]), max_n=2, show=True)\nplt.suptitle('Input')\ndls.show_batch((preds[1],preds[0]), max_n=2, show=True)\nplt.suptitle('Predictions')","e52c0776":"testA_path = '..\/input\/gan-getting-started\/photo_jpg\/'\npred_path = '..\/images\/'","5f824dbe":"get_preds_cyclegan(learn,testA_path,pred_path,suffix='jpg')","439eaca8":"import shutil\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","2dad19f7":"## Imports","9dd40ae9":"## Model definition\n\nI provide the `CycleGAN` class, which is just an `nn.Module` for generating converted images. See [documentation](https:\/\/tmabraham.github.io\/UPIT\/models.cyclegan\/#Full-model) for more information. Note that the original paper uses `gen_blocks=9` but let's try a smaller model of `gen_blocks=3`.","fdcd1c72":"## Install dependencies and package","b74f6cd8":"Using some fastai functions, we can view some predictions.","f9e0b182":"## Load data","2256e2fd":"# UPIT \n> A fastai\/PyTorch package for *U*n-*P*aired *I*mage-to-image *T*ranslation currently with CycleGAN implementation.\n\nCode available [here](https:\/\/github.com\/tmabraham\/UPIT).\n\n[In a YouTube talk](https:\/\/www.youtube.com\/watch?v=gT8-wDPLOBg) on Abhishek Thakur's channel, I introduced UPIT as a simple package for using the CycleGAN model. It was built with fastai and nbdev. Please watch the video for more information about the CycleGAN model and the package. Also see the [package documentation](https:\/\/tmabraham.github.io\/UPIT\/).\n\n\nHere's a quick summary of the CycleGAN method:\n![image.png](attachment:image.png)\n\nThe idea is that the discriminator of domain B will provide a training signal for the generator to generate images with the style of domain B, while the cycle-consistency (reconstruction) loss will nudge the generator to maintain some aspects of the original image (like the shape and structure) in the final output image.\n\nThe generator uses the following ResNet-block-based architecture:\n![generator](https:\/\/miro.medium.com\/max\/875\/1*PVBSmRcCz9xfw-fCNi_q5g.png)\n\nThe discriminator uses a [70x70 PatchGAN](https:\/\/arxiv.org\/abs\/1611.07004):\n![discriminator](https:\/\/miro.medium.com\/max\/875\/1*46CddTc5JwkFW_pQb4nGZQ.png)\n\nSee my talk for more details.\n","5441312a":"## Conclusion:\n\nTo summarize, my package makes CycleGAN training and inference easy and effortless. It simply takes effectively five lines of code:\n```\ndls = get_dls(trainA_path, trainB_path)\ncycle_gan = CycleGAN(3,3,64,gen_blocks=3)\nlearn = cycle_learner(dls, cycle_gan,opt_func=partial(Adam,mom=0.5,sqr_mom=0.999),show_img_interval=8)\nlearn.fit_flat_lin(12,12,2e-4)\nget_preds_cyclegan(learn, testA_path, preds_path)\n```\n\nPlease upvote this kernel if you found this helpful! Additionally, please check out my [talk](https:\/\/www.youtube.com\/watch?v=gT8-wDPLOBg) for more information! \n\nI plan to implement other unpaired image-to-image translation models in this public library. I am currently planning to add:\n- DualGAN\n- GANILLA\n- DiscoGAN\n\n**Comment below** if you have suggestions for other **unpaired image-to-image translation** models to add.\n\nAdditionally, I plan to add easier methods for viewing results (including during training) and better support for using custom models. **Let me know if you have any suggested features!**\n\n## Acknowledgements\n\nThank you to Andrew Shaw for his help porting over the fastai v1 code. Thank you to the fast.ai team for providing the original fastai v1 version of the CycleGAN.\n\nDiagrams were taken (w\/ or w\/o modification) from [here](https:\/\/github.com\/yunjey\/mnist-svhn-transfer) and [here](https:\/\/towardsdatascience.com\/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d).","c787e2a6":"The original CycleGAN paper uses a constant learning rate for half of training, and then linearly decaying to zero for the remainder of training. I added the `fit_flat_lin` method to implement this schedule. Note that the original paper runs for 200 epochs in total, but for now we run for 10 epochs.","89a4a7fb":"Finally, I provide `get_preds_cyclegan` to generate predictions from images in `testA_path` and save to `pred_path`. See [documentation](https:\/\/tmabraham.github.io\/UPIT\/inference.cyclegan\/#get_preds_cyclegan).","d5e12a3b":"In the package, I provide a `get_dls` function that loads the dataset in the fastai-specific `DataLoaders` format given just the domain A and B folder paths. I also recently added subset functionality (just the number of desired files are provided). See [documentation](https:\/\/tmabraham.github.io\/UPIT\/data.unpaired\/#get_dls) for more information.","37fda5fd":"Thankfully, all that's needed for submission is a zipped folder of those predicted images:","44adc83b":"We need to instantiate a fastai `Learner` object used to train a model (couples the data, model, and optimizer with callbacks, allowing for training and inference). I provide the `cycle_learner` function to do this. It will add the necessary `CycleGANTrainer` callback defined in my library, allowing for the generator-discriminator training. See the [documentation](https:\/\/tmabraham.github.io\/UPIT\/train.cyclegan\/#cycle_learner) for further details.","8e6000de":"If we want, we can use the `learn.lr_find()` command to find the best learning rate. We will find it is often around 1-2e-4, which is also the recommended learning rate in the original CycleGAN paper."}}