{"cell_type":{"ef10c537":"code","387d0d17":"code","84b0e619":"code","c85aa8a4":"code","4e8224f2":"code","af29ce13":"code","52d50ad2":"code","b42392be":"code","fd4ac2d7":"code","01f80c99":"code","7fe7bbf4":"code","b72c1cdc":"code","8eccbb64":"code","54370b12":"code","008acb57":"code","cda7a849":"code","d29e4fdf":"code","3e34e420":"code","3fe4d877":"code","e0cd6f3f":"code","d1b5a0a0":"code","c597d137":"code","5d72918e":"code","85a0c1ed":"code","141a420c":"code","7688afcc":"code","a56bdd25":"code","e82646d4":"code","c6c9b8c3":"code","4183b9a6":"code","052fcac9":"code","a1701169":"code","94ce5bb2":"code","eff4ceba":"code","359fc182":"code","314a11ed":"code","0a1fb4be":"code","ef65af7b":"code","bfe7a97b":"code","7775b4d1":"code","0934c645":"markdown","78093ac8":"markdown","3e6d992f":"markdown","0ed9a1a8":"markdown","1b5323cc":"markdown","655258ab":"markdown","3affb6cd":"markdown","7ec8bafc":"markdown","0d6d1939":"markdown","ee21383b":"markdown","a6f80b0c":"markdown","19fb407e":"markdown","3754f154":"markdown","6bcb0876":"markdown","0846d6f0":"markdown","feb95f08":"markdown","70d636b2":"markdown","d5cc2922":"markdown","8f7dcb25":"markdown","cddbb18d":"markdown","daf90743":"markdown","bcb24a6e":"markdown","06ec6ab5":"markdown","27299166":"markdown","b630006b":"markdown","b0c496bf":"markdown","49f4de96":"markdown","ed022324":"markdown","8afffca9":"markdown","e4b77eb2":"markdown","b6cf670d":"markdown","479bbe68":"markdown","58797ca1":"markdown","710d87ae":"markdown","d7ed1695":"markdown","dfabb36a":"markdown","0a2acd70":"markdown","10c810ff":"markdown","730a4298":"markdown","8d7580e7":"markdown","f0eb41c8":"markdown","08f8e720":"markdown","935b7401":"markdown","c0590222":"markdown","1cae3b74":"markdown","5875f934":"markdown","cc4354af":"markdown"},"source":{"ef10c537":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","387d0d17":"# Show the Dataset Path to get detaset\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","84b0e619":"#  Create New Variable and stores the dataset values as Data Frame\n\nloan_train = pd.read_csv('\/kaggle\/input\/loan-eligible-dataset\/loan-train.csv')\nloan_test = pd.read_csv('\/kaggle\/input\/loan-eligible-dataset\/loan-test.csv')","c85aa8a4":"loan_train.head()","4e8224f2":"loan_train","af29ce13":"print(\"Rows: \", len(loan_train))","52d50ad2":"print(\"Columns: \", len(loan_train.columns))","b42392be":"print(\"Shape : \", loan_train.shape)","fd4ac2d7":"loan_train_columns = loan_train.columns # assign to a variable\nloan_train_columns # print the list of columns","01f80c99":"loan_train.describe()","7fe7bbf4":"loan_train.info()\n ","b72c1cdc":"def explore_object_type(df ,feature_name):\n    \"\"\"\n    To know, How many values available in object('categorical') type of features\n    And Return Categorical values with Count.\n    \"\"\"    \n    if df[feature_name].dtype ==  'object':\n        print(df[feature_name].value_counts())","8eccbb64":"# Now, Test and Call a function for gender only\nexplore_object_type(loan_train, 'Gender')","54370b12":"# Solution is, Do you remember we have variable with name of `loan_train_columns`, Right,  let's use it\n# 'Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status'\n\nfor featureName in loan_train_columns:\n    if loan_train[featureName].dtype == 'object':\n        print('\\n\"' + str(featureName) + '\\'s\" Values with count are :')\n        explore_object_type(loan_train, str(featureName))","008acb57":"import missingno as msno","cda7a849":"# list of how many percentage values are missing\nloan_train\n\nloan_train.isna().sum()\n# round((loan_train.isna().sum() \/ len(loan_train)) * 100, 2)","d29e4fdf":"msno.bar(loan_train)","3e34e420":"msno.matrix(loan_train )\n","3fe4d877":"loan_train['Credit_History'].fillna(loan_train['Credit_History'].mode(), inplace=True) # Mode\nloan_test['Credit_History'].fillna(loan_test['Credit_History'].mode(), inplace=True) # Mode\n\n\nloan_train['LoanAmount'].fillna(loan_train['LoanAmount'].mean(), inplace=True) # Mean\nloan_test['LoanAmount'].fillna(loan_test['LoanAmount'].mean(), inplace=True) # Mean","e0cd6f3f":"loan_train.Loan_Status = loan_train.Loan_Status.replace({\"Y\": 1, \"N\" : 0})\n# loan_test.Loan_Status = loan_test.Loan_Status.replace({\"Y\": 1, \"N\" : 0}) \n\nloan_train.Gender = loan_train.Gender.replace({\"Male\": 1, \"Female\" : 0})\nloan_test.Gender = loan_test.Gender.replace({\"Male\": 1, \"Female\" : 0})\n\nloan_train.Married = loan_train.Married.replace({\"Yes\": 1, \"No\" : 0})\nloan_test.Married = loan_test.Married.replace({\"Yes\": 1, \"No\" : 0})\n\nloan_train.Self_Employed = loan_train.Self_Employed.replace({\"Yes\": 1, \"No\" : 0})\nloan_test.Self_Employed = loan_test.Self_Employed.replace({\"Yes\": 1, \"No\" : 0})\n","d1b5a0a0":"\nloan_train['Gender'].fillna(loan_train['Gender'].mode()[0], inplace=True)\nloan_test['Gender'].fillna(loan_test['Gender'].mode()[0], inplace=True)\n\nloan_train['Dependents'].fillna(loan_train['Dependents'].mode()[0], inplace=True)\nloan_test['Dependents'].fillna(loan_test['Dependents'].mode()[0], inplace=True)\n\nloan_train['Married'].fillna(loan_train['Married'].mode()[0], inplace=True)\nloan_test['Married'].fillna(loan_test['Married'].mode()[0], inplace=True)\n\nloan_train['Credit_History'].fillna(loan_train['Credit_History'].mean(), inplace=True)\nloan_test['Credit_History'].fillna(loan_test['Credit_History'].mean(), inplace=True)\n","c597d137":"from sklearn.preprocessing import LabelEncoder\nfeature_col = ['Property_Area','Education', 'Dependents']\nle = LabelEncoder()\nfor col in feature_col:\n    loan_train[col] = le.fit_transform(loan_train[col])\n    loan_test[col] = le.fit_transform(loan_test[col])","5d72918e":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport seaborn as sns\nsns.set_style('dark')\n","85a0c1ed":"loan_train","141a420c":"loan_train.plot(figsize=(18, 8))\n\nplt.show()","7688afcc":"plt.figure(figsize=(18, 6))\nplt.subplot(1, 2, 1)\n\n\nloan_train['ApplicantIncome'].hist(bins=10)\nplt.title(\"Loan Application Amount \")\n\nplt.subplot(1, 2, 2)\nplt.grid()\nplt.hist(np.log(loan_train['LoanAmount']))\nplt.title(\"Log Loan Application Amount \")\n\nplt.show()","a56bdd25":"plt.figure(figsize=(18, 6))\nplt.title(\"Relation Between Applicatoin Income vs Loan Amount \")\n\nplt.grid()\nplt.scatter(loan_train['ApplicantIncome'] , loan_train['LoanAmount'], c='k', marker='x')\nplt.xlabel(\"Applicant Income\")\nplt.ylabel(\"Loan Amount\")\nplt.show()","e82646d4":"plt.figure(figsize=(12, 6))\nplt.plot(loan_train['Loan_Status'], loan_train['LoanAmount'])\nplt.title(\"Loan Application Amount \")\nplt.show()","c6c9b8c3":"plt.figure(figsize=(12,8))\nsns.heatmap(loan_train.corr(), cmap='coolwarm', annot=True, fmt='.1f', linewidths=.1)\nplt.show()","4183b9a6":"# import ml model from sklearn pacakge\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score\n","052fcac9":"logistic_model = LogisticRegression()","a1701169":"train_features = ['Credit_History', 'Education', 'Gender']\n\nx_train = loan_train[train_features].values\ny_train = loan_train['Loan_Status'].values\n\nx_test = loan_test[train_features].values\n","94ce5bb2":"logistic_model.fit(x_train, y_train)","eff4ceba":"# Predict the model for testin data\n\npredicted = logistic_model.predict(x_test)\n","359fc182":"# check the coefficeints of the trained model\nprint('Coefficient of model :', logistic_model.coef_)\n","314a11ed":"# check the intercept of the model\nprint('Intercept of model',logistic_model.intercept_)","0a1fb4be":"# Accuray Score on train dataset\n# accuracy_train = accuracy_score(x_test, predicted)\nscore = logistic_model.score(x_train, y_train)\nprint('accuracy_score overall :', score)\nprint('accuracy_score percent :', round(score*100,2))\n","ef65af7b":"\n# predict the target on the test dataset\npredict_test = logistic_model.predict(x_test)\nprint('Target on test data',predict_test) \n","bfe7a97b":"import pickle as pkl","7775b4d1":"# save the model to disk\nfilename = 'logistic_model.pkl'\npkl.dump(logistic_model, open(filename, 'wb')) # wb means write as binary\n\n\n","0934c645":"> ## *Note: Your output maybe shorter or longer, It's totally depend upon your dataset's columns* ","78093ac8":"#### As I said the above cell, this the information of all the methamatical details from dataset. Like `count`, `mean`, `standard deviation (std)`, `min`, `quartiles(25%, 50%, 75%)` and `max`.","3e6d992f":"Also we can get the shape of the dataset using `shape` attribute","0ed9a1a8":"### Now, You can check your current directory. You can see the file with named \"logistic_model.pkl\"","1b5323cc":"# Import Packages","655258ab":" You can load this data with the `read_csv()` method from `pandas` package. It converts the data set to a python dataframe.","3affb6cd":"> ### *After we collecting the data, Next step we need to understand what kind of data we have.*","7ec8bafc":"`Loan_Status` feature boolean values, So we replace `Y` values with `1` and `N` values with `0`\nand same for other `Boolean` types of columns","0d6d1939":"<a id=\"3\"><\/a><br>\n# 3. Data Visualizations\n\n\nIn this section, We are showing the visual information from the dataset, For that we need some pakages that are `matplotlib` and `seaborn`\n\n","ee21383b":"\n## Dataset Key Information.\n  \n---  \n  \n> - `Loan_ID`--------------> Unique Loan ID.\n- `Gender`   --------------> Male\/ Female \n- `Married`  --------------> Applicant married (Y\/N) \n- `Dependents` ------------> Number of dependents \n- `Education` -------------> Applicant Education (Graduate\/ Under Graduate) \n- `Self_Employed` ---------> Self-employed (Y\/N) \n- `ApplicantIncome` -------> Applicant income \n- `CoapplicantIncome` -----> Coapplicant income \n- `LoanAmount`  -----------> Loan amount in thousands \n- `Loan_Amount_Term` ------> Term of a loan in months \n- `Credit_History` --------> Credit history meets guidelines \n- `Property_Area` ---------> Urban\/ Semi-Urban\/ Rural \n- `Loan_Status` -----------> Loan approved (Y\/N) ","a6f80b0c":"<a id=\"1\"><\/a><br>\n# 1. Gathering Data","19fb407e":"As we can see in the output.\n\n1. There are `614` entries\n- There are total 13 features (0 to 12)\n- There are three types of datatype `dtypes: float64(4), int64(1), object(8)`\n- It's Memory usage that is, `memory usage: 62.5+ KB`\n- Also, We can check how many missing values available in the `Non-Null Count` column","3754f154":"### Also we can get the column as an list(array) from dataset\n\n> **Note: DataFrame.columns returns the total columns of the dataset,\n> Store the number of columns in variable `loan_train_columns`**","6bcb0876":"> ### **Before fitting the model, We need to decide how many feature are available for testing and training, then after complete this step. fitt the model** \n\nCurrently, we are using `Credit_History', 'Education', 'Gender` features for training so let's create train and test variables","0846d6f0":"In this heatmap, we can clearly seen the relation between two variables ","feb95f08":"- After defined a function, Let's call it. and check what's the output of our created function.","70d636b2":"--- \n---\n\n<div class=\"text-center\">\n    <h1>That's it Guys,<\/h1>\n    <h1>\ud83d\ude4f<\/h1>\n    \n        \n        I Hope you guys you like and enjoy it, and learn something interesting things from this notebook, \n        \n        Even I learn a lots of things while I'm creating this notebook\n    \n        Keep Learning,\n        Regards,\n        Vikas Ukani.\n    \n<\/div>\n\n---\n---\n\n<img src=\"https:\/\/static.wixstatic.com\/media\/3592ed_5453a1ea302b4c4588413007ac4fcb93~mv2.gif\" align=\"center\" alt=\"Thank You\" style=\"min-height:20%; max-height:20%\" width=\"90%\" \/>\n\n","d5cc2922":"* In this step, We have a lots of Machine Learning Model from sklearn package, and we need to decide which model is give us the better performance. then we use that model in final stage and send to the production level.","8f7dcb25":"- First of all we use the `loan_train.describe()` method to shows the important information from the dataset\n- It provides the `count`, `mean`, `standard deviation (std)`, `min`, `quartiles` and `max` in its output.","cddbb18d":"* Let's build the model","daf90743":"### # convert Categorical variable with Numerical values.","bcb24a6e":"# Introduction","06ec6ab5":"### Now, Understanding the Data","27299166":"### In this notebook kernal, I'm going to predictions customers are eligible for the loan and check whether what are the missing criteria to know why customer not getting loan to make there own house.\n\n\n<div class=\"text-success \"><h4> We will learning about, Data Analysis Preprocess such as, <\/h4><\/div>\n\n--- \n\n> ### Steps are:\n\n\n1. [Gathering Data](#1)\n- [Exploratory Data Analysis](#2)\n- [Data Visualizations](#3)\n- [Machine Learning Model Decision.](#4)\n- [Traing the ML Model](#5)\n- [Predict Model](#6)\n- [Deploy Model](#7)\n\n\n\n \n**Hope** you guys ****Love It**** and get a better **learning experience**.  \ud83d\ude4f","b630006b":"\n<img align=\"center\" src=\"https:\/\/www.rdccbank.com\/uploads\/loan-sub-types-template\/housing-b.jpg\" alt=\"House Loan\" \/>\n\n---\n\n<div class=\"text-danger\" >\n    <h4>Let's Say, You are the owner of the <b>Housing Finance Company<\/b> and you want to build your own model to predict the customers are applying for the home loan and company want to check and validate the customer are eligible for the home loan.\n    <\/h4>\n<\/div>","b0c496bf":"First of all, we are use `LogisticRegression` from `sklearn.linear_model` package. Here is the little information about `LogisticRegression`.\n\n`Logistic Regression` is a **classification algorithm**. It is used to predict a binary outcome (`1 \/ 0`, `Yes \/ No`, and `True \/ False`) given a set of independent variables. To represent binary \/ categorical outcome, we use dummy variables. You can also think of logistic regression as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as the dependent variable.\n\n![](https:\/\/www.analyticsvidhya.com\/wp-content\/uploads\/2015\/10\/logit.png)","49f4de96":"<a id=\"5\"><\/a><br>\n# 5. Traing the ML Model","ed022324":"<a id=\"7\"><\/a><br>\n# 7. Deploy Model","8afffca9":"> ### Another method is `info()`, This method show us the information about the dataset, Like\n\n1. What's the type of culumn have?\n- How many rows available in the dataset?\n- What are the features are there?\n- How many null values available in the dataset?\n- Ans so on...","e4b77eb2":"* Here, `Property_Area`, `Dependents` and `Education` has multiple values so now we can use `LabelEncoder` from `sklearn` package","b6cf670d":"\n- Finally, we are done so far. The last step is to deploy our model in production map. So we need to export our model and bind with web application API. \n\nUsing pickle we can export our model and store in to `logistic_model.pkl` file, so we can ealy access this file and calculate customize prediction using Web App API.\n\n\n#### A little bit information about pickle:\n\n`Pickle` is the standard way of serializing objects in Python. You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file. Later you can load this file to deserialize your model and use it to make new predictions\n\n\n>>  Here is example of the Pickle export model\n\n\n\n```\nmodel.fit(X_train, Y_train)\n# save the model to disk\nfilename = 'finalized_model.sav'\npickle.dump(model, open(filename, 'wb'))\n\n# some time later...\n\n# load the model from disk\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X_test, Y_test)\nprint(result)\n```","479bbe68":"Pandas has inbuild attribute to get all column from the dataset, With the help of this feature we can get the how many column available we have.","58797ca1":"\n# <div class=\"text-primary\"> The Problem is,  <\/div>\n\n### In a Simple Term, Company wants to make automate the Loan Eligibility Process in a real time scenario related to customer's detail provided while applying application for home loan forms.\n\n\nYou will use the training set to build your model, and the test set to validate it. Both the files are stored on the web as CSV files; their URLs are already available as character strings in the sample code.\n\n","710d87ae":"> ### Here, we can see there are many rows and many columns, To know how many records and columns are available in our dataset, we can use the `shape` attribute or we can use `len()` to know how many records and how many features available in the dataset.","d7ed1695":"- As we can see here, there are too many columns missing with small amount of null values so we use `mean` amd `mode` to replace with `NaN` values.","dfabb36a":"\n- We need to fill null values with `mean` and `median` using `missingno` package","0a2acd70":"<a id=\"4\"><\/a><br>\n# 4. Choose ML Model.","10c810ff":"- Here's one little issue occurred, Suppose in your datasets there are lots of feature to defined like this above code. ","730a4298":"- As we can see in the above output, there are too many columns, ( columns known as features as well. )\n\nWe can also use `loan_train` to show few rows from the first five and last five record from the dataset","8d7580e7":"<div class='text-center'>\n    <h1>\ud83c\udfe7 Loan Eligibility Prediction \ud83d\udcb0 using Machine Learning Models \ud83e\udd16   <\/h1>\n<\/div>\n","f0eb41c8":"- Lets display the some few information from our large datasets\n\nHere, We shows the first five rows from datasets","08f8e720":"<a id=\"6\"><\/a><br>\n# 6. Predict Model","935b7401":"First of all, we need to importing the necessary packages to work with the data to solve our problem","c0590222":"- First of all, We explore object type of data\nSo let's make a function to know how many types of values available in the column","1cae3b74":"- To read model from file\n\n```\n# load the model from disk\nloaded_model = pkl.load(open(filename, 'rb')) # rb means read as binary\nresult = loaded_model.score(X_test, Y_test)\n\n```","5875f934":"<a id=\"2\"><\/a><br>\n# 2. Exploratory Data Analysis\n\nIn this section, We learn about extra information about data and it's characteristics.\n","cc4354af":"> ### Finally, We have all the features with numerical values,"}}