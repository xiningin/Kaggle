{"cell_type":{"fdcf29c9":"code","3563891f":"code","5ae7e0c4":"code","582f8afb":"code","1eec4d5a":"code","7d23ad37":"code","9a23a8e0":"code","684b791c":"code","628eec8f":"code","c32c0ca4":"code","8a9984df":"code","e472130a":"code","35128306":"code","8893d75a":"code","5975b7b7":"code","b8ece35f":"code","2eab1bbf":"code","b3f6f500":"code","1be61e66":"code","690804b7":"markdown"},"source":{"fdcf29c9":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc704\uce58 \ud655\uc778\n! ls ..\/input\/state-farm-distracted-driver-detection\/","3563891f":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc704\uce58 \ud655\uc778\n! ls ..\/input\/state-farm-distracted-driver-detection\/imgs","5ae7e0c4":"# \ub79c\ub364\ud558\uac8c \ubc30\uc815\ub41c GPU \ud655\uc778\n! nvidia-smi","582f8afb":"# \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \uc124\uce58\n! pip install torch\n! pip install torchvision","1eec4d5a":"# \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac import\nimport pandas as pd\nimport subprocess\nimport torch\nimport torch.optim as optim\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision\nfrom torchvision import transforms\n\nimport os\nimport random\nfrom glob import glob\nimport cv2\nimport numpy as np\nfrom tqdm.notebook import tqdm","7d23ad37":"# \uc8fc\uc694 \ud30c\ub77c\ubbf8\ud130 \uc9c0\uc815\nEPOCH = 20\nBATCH_SIZE = 16\nPATIENCE = 5\nDATA_PATH = '..\/input\/state-farm-distracted-driver-detection'","9a23a8e0":"# \uc774\ubbf8\uc9c0 \ub85c\ub529\uc2dc \uc804\ucc98\ub9ac \ud568\uc218 \uc815\uc758\n# Normalize\ub294 ImageNet \ub370\uc774\ud130\uc5d0 \uae30\ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uae30 \uc704\ud55c \ud568\uc218\ntransform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","684b791c":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc911, \uc6b4\uc804\uc790 \uae30\uc900\uc73c\ub85c 20%\ub97c \uac80\uc99d \ub370\uc774\ud130\ub85c \uc0ac\uc6a9\nclasses = [f'c{i}' for i in range(10)]\nseed = 2020\nvalidation_split = 0.2\n\n# \uc6b4\uc804\uc790 \uc815\ubcf4 \uc77d\uc5b4\uc624\uae30\ndriver_list = pd.read_csv(f'{DATA_PATH}\/driver_imgs_list.csv')\ndrivers = np.unique(driver_list['subject'].values)\n\n# \uc6b4\uc804\uc790 \uae30\uc900 split\nsplit = int(np.floor(validation_split * len(drivers)))\nnp.random.seed(seed)\ntrn_idx, val_idx = drivers[split:], drivers[:split]","628eec8f":"# \uc6b4\uc804\uc790 \uae30\uc900\uc73c\ub85c \ud559\uc2b5\/\uac80\uc99d \ub370\uc774\ud130 \ubd84\ub9ac\nsplit_dir = 'driver_split'\nif not os.path.exists(split_dir):\n    cmd = f'mkdir {split_dir}'\n    subprocess.call(cmd, shell=True)\n    for d in ['train', 'valid']:\n        cmd = f'mkdir {split_dir}\/{d}'\n        subprocess.call(cmd, shell=True)\n        for cl in classes:\n            cmd = f'mkdir {split_dir}\/{d}\/{cl}'\n            subprocess.call(cmd, shell=True)\n\ntrn_cnt = 0\nval_cnt = 0\nfor i, driver_info in driver_list.iterrows():\n    driver = driver_info['subject']\n    label = driver_info['classname']\n    img_path = driver_info['img']\n    # symlink\ub97c \ud1b5\ud574\uc11c \uc774\ubbf8\uc9c0 \ud30c\uc77c\uc744 \uc9c0\uc815\n    if driver in trn_idx:\n        if not os.path.exists(f'{split_dir}\/train\/{label}\/{img_path}'):\n            os.symlink(os.path.abspath(f'{DATA_PATH}\/imgs\/train\/{label}\/{img_path}'), f'{split_dir}\/train\/{label}\/{img_path}')\n        trn_cnt += 1\n    else:\n        if not os.path.exists(f'{split_dir}\/valid\/{label}\/{img_path}'):\n            os.symlink(os.path.abspath(f'{DATA_PATH}\/imgs\/train\/{label}\/{img_path}'), f'{split_dir}\/valid\/{label}\/{img_path}')\n        val_cnt += 1","c32c0ca4":"# \uc6b4\uc804\uc790 \uad6c\ubd84\uc744 \uc704\ud574 \uc784\uc758\ub85c \uc0dd\uc131\ud55c \ub514\ub809\ud1a0\ub9ac \ud655\uc778\n! ls -ahl driver_split","8a9984df":"# \ud559\uc2b5 \ub370\uc774\ud130, \uac80\uc99d \ub370\uc774\ud130 \ub85c\ub354 \uc815\uc758\ntrain_dataset = torchvision.datasets.ImageFolder(f'.\/{split_dir}\/train',\n                                                 transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=BATCH_SIZE,\n                                           shuffle=True,\n                                           num_workers=2)\nvalid_dataset = torchvision.datasets.ImageFolder(f'.\/{split_dir}\/valid',\n                                                 transform=transform)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                           batch_size=BATCH_SIZE,\n                                           num_workers=2)","e472130a":"# GPU \uc0ac\uc6a9\uc744 \uc704\ud55c device \ubcc0\uc218 \uc815\uc758\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","35128306":"# CNN \ubaa8\ub378 \ub85c\ub529\n# ImageNet\uc5d0\uc11c \uae30\ud559\uc2b5\ub41c Resnet50 \ubaa8\ub378\uacfc \ud30c\ub77c\ubbf8\ud130\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\uae30\nmodel_conv = torchvision.models.resnet50(pretrained=True)","8893d75a":"# \ucd5c\uc885 layer\ub97c \uc6b0\ub9ac \ubb38\uc81c\uc5d0 \uc54c\ub9de\uac8c \uc7ac\uad6c\uc131\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Sequential(\n        nn.Linear(num_ftrs, num_ftrs),\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(num_ftrs, num_ftrs),\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(num_ftrs, len(classes)))\nprint(f'# model : {model_conv}')\nmodel_conv = model_conv.to(device)","5975b7b7":"# \ud559\uc2b5 \uc635\uc158 : \uc190\uc2e4 \ud568 \uc218 \ubc0f optimizer \uc815\uc758\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_conv.parameters(), lr=0.0001, weight_decay=1e-6, momentum=0.9)\nsoftmax = nn.Softmax(dim=1)\nbest_valid_score = 999\npatience = 0","b8ece35f":"def train(model_conv, train_loader, optimizer, criterion, trn_cnt):\n    running_loss = 0.\n    running_acc = 0.\n\n    # \ud559\uc2b5 \uc9c4\ub3c4 \ud655\uc778\uc744 \uc704\ud55c progress_bar\n    pbar = tqdm(total=trn_cnt)\n    cnt = 0\n    for i, data in enumerate(train_loader, 0):\n        # \ub370\uc774\ud130 \ub85c\ub354\uc5d0\uc11c BATCH_SIZE \ub9cc\ud07c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ub85c\ub529\n        inputs, labels = data\n        # GPU\ub85c \ub370\uc774\ud130 \uc774\ub3d9\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # \ud559\uc2b5\uc744 \uc704\ud55c \uc900\ube44\n        optimizer.zero_grad()\n        model_conv.train()\n        outputs = model_conv(inputs)\n        probs = softmax(outputs)\n\n        # \uc815\ud655\ub3c4 \uacc4\uc0b0\n        _, preds = probs.max(axis=1)\n        running_acc += sum(labels == preds) \/ (1. * BATCH_SIZE)\n\n        # \uc190\uc2e4 \ud568\uc218 \uacc4\uc0b0\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()  # Gradient Descent HERE!\n\n        running_loss += loss.item()\n        cnt += 1\n\n        pbar.update(BATCH_SIZE)\n    pbar.close()\n    return running_loss \/ cnt, running_acc \/ cnt","2eab1bbf":"def evaluate(model_conv, valid_loader, criterion):\n    # 1 Epoch\ub9c8\ub2e4 \uac80\uc99d \ub370\uc774\ud130\uc5d0 \ub300\ud558\uc5ec \ud3c9\uac00\n    with torch.no_grad():\n        model_conv.eval()\n        valid_loss = 0.0\n        valid_acc = 0.0\n        cnt = 0\n        pbar = tqdm(total=val_cnt)\n        for data in valid_loader:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model_conv(inputs)\n            probs = softmax(outputs)\n\n            _, preds = probs.max(axis=1)\n            valid_acc += sum(labels == preds) \/ (1. * BATCH_SIZE)\n\n            labels.require_grad = False\n            loss = criterion(outputs, labels)\n            valid_loss += loss\n            cnt += 1\n            pbar.update(BATCH_SIZE)\n        pbar.close()\n    return valid_loss \/ cnt, valid_acc \/ cnt","b3f6f500":"# EPOCH \ud69f\uc218 \ub9cc\ud07c \ud559\uc2b5 \uc9c4\ud589\nfor epoch in range(EPOCH):\n    print(f'# Epoch : {epoch}..')\n    # 1 Epoch \ud559\uc2b5\n    trn_loss, trn_acc = train(model_conv, train_loader, optimizer, criterion, trn_cnt)\n    print(f'# train loss : {trn_loss} train acc : {trn_acc}')\n    \n    # \uac80\uc99d \ub370\uc774\ud130 \uae30\uc900 \ud3c9\uac00\n    valid_loss, valid_acc = evaluate(model_conv, valid_loader, criterion)\n    print(f'# valid loss | valid_loss : {valid_loss} valid_acc : {valid_acc}')\n\n\n    # \uac80\uc99d \ub370\uc774\ud130\uc758 \ud3c9\uac00 \ucc99\ub3c4 \uae30\uc900\uc73c\ub85c \ucd5c\uc801\uc758 \ubaa8\ub378 \uc120\uc815\n    if valid_loss < best_valid_score:\n        best_valid_score = valid_loss\n        print(f'# Saving best model.. epoch {epoch} | valid_loss {valid_loss}')\n        torch.save(model_conv, '.\/model.baseline.driver_split')\n        patience = 0\n    patience += 1\n\n    # early_stopping\n    if patience == PATIENCE:\n        break\n\nprint('Finished Training')","1be61e66":"from glob import glob\n\nTEST_SIZE = 79726\nBATCH_SIZE = 128\n\n# \uce90\uae00 \uc81c\ucd9c\uc744 \uc704\ud55c test_id \uc77d\uc5b4\uc624\uae30\ntest_ids = [os.path.basename(fl) for fl in glob(f'{DATA_PATH}\/imgs\/test\/img_*.jpg')]\ntest_ids.sort()\n\n# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc804\ucc98\ub9ac \ud568\uc218 \uc815\uc758\ntransform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \ub85c\ub529\uc744 \uc704\ud55c \ub370\uc774\ud130 \ub85c\ub354 \uc815\uc758\ntest_dataset = torchvision.datasets.ImageFolder(f'{DATA_PATH}\/imgs',\n                                                transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=BATCH_SIZE,\n                                          num_workers=2)\n\n# GPU \uc0ac\uc6a9\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# \uc800\uc7a5\ub41c \ubaa8\ub378 \ub85c\ub529\nmodel_conv = torch.load('model.baseline.driver_split')\nprint(f'# model : {model_conv}')\nmodel_conv = model_conv.to(device)\nsoftmax = nn.Softmax(dim=1)\n\npbar = tqdm(total=TEST_SIZE)\nend_flag = False\nwith open('submission.csv', 'w') as out:\n    # write header\n    out.write('img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n')\n\n    for i, data in enumerate(test_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            model_conv.eval()\n            outputs = model_conv(inputs)\n            probs = softmax(outputs)\n\n            # \ud074\ub798\uc2a4\ubcc4 \ud655\ub960 \uc608\uce21\uac12 \uc800\uc7a5\ud558\uae30\n            for j, prob in enumerate(probs):\n                if BATCH_SIZE * i + j >= TEST_SIZE:\n                    end_flag = True\n                    break\n                    \n                test_id = test_ids[i * BATCH_SIZE + j]\n                prob = ','.join([str(round(val, 3)) for val in prob.cpu().detach().numpy()])\n                out.write(f'{test_id},{prob}\\n')\n\n        pbar.update(BATCH_SIZE)\n\n        if end_flag:\n            break\npbar.close()\n\nprint('Finished Eval')","690804b7":"## \ud559\uc2b5 \ub370\uc774\ud130 \uc6b4\uc804\uc790 \uae30\ubc18 \uad50\ucc28 \uac80\uc99d\n- \uae30\uc874 : 26\uba85\uc758 \ub370\uc774\ud130\ub97c 8:2 \ub79c\ub364 \uc154\ud50c\n- \uac1c\uc120 : 26\uba85\uc744 8:2\ub85c \ubd84\ub9ac \ud558\uc5ec, \ud559\uc2b5 \uc6b4\uc804\uc790 \/ \uac80\uc99d \uc6b4\uc804\uc790 "}}