{"cell_type":{"ee273ef4":"code","1212f7ff":"code","eb3ed2f9":"code","32e83db1":"code","b0a16416":"code","d274bcc8":"code","4b10e43a":"code","3cdf5fa4":"code","161ad96e":"code","4ac0f592":"code","c1750d75":"code","da98645e":"code","c2b6a8f1":"code","160ecccb":"code","43547da9":"code","5735c2e5":"code","07558081":"code","a91e1900":"code","39700f96":"code","cb2ccd38":"code","35d46a77":"code","f9e7867d":"code","d0e86410":"code","78366d45":"code","1b165c31":"code","b28bf209":"code","36b0f1fb":"code","1173e196":"code","d6023498":"code","ca666f51":"code","c01fcc4e":"code","53ebd7e7":"code","82cb7ece":"code","6bf242e1":"code","e0c7397c":"code","a60fb5fa":"code","1f4121eb":"code","ed23e893":"code","29144f46":"code","641f7825":"code","25df401b":"code","8424faf7":"code","fd4c1521":"code","ff267d50":"code","516f9a9f":"code","54ef9c3c":"code","170fa987":"code","a0fd9f07":"code","f023b1d0":"code","5599fe32":"code","076ec8e7":"code","3c38f37b":"code","4279afcb":"code","5ba0846d":"code","8f2ae31c":"code","0f19c552":"code","02bcb0c3":"code","59b7f5ef":"code","6c2005b0":"code","9ccaae41":"code","58519ff9":"code","7054535c":"code","f5e0c457":"code","e25d3feb":"code","8b51c159":"code","1bad76fb":"code","d2cd7c8e":"code","8f569130":"code","c25ed485":"code","53824480":"code","68a66b8d":"code","886ce192":"code","6803ff01":"code","510ff288":"code","d21314bd":"code","034d591b":"code","fcbf2e2f":"code","ab6aa6e4":"code","c0a0c3c8":"code","14769c37":"markdown","7c90ca65":"markdown","fbd87296":"markdown","4f3e9548":"markdown","97573348":"markdown","0be56dda":"markdown","7d9c7bb9":"markdown","80f8f502":"markdown","954f227f":"markdown","bd8ea764":"markdown","b37d5618":"markdown","5dc5febc":"markdown","e58a363d":"markdown","be08a8ca":"markdown","db5ba01a":"markdown","99b52db0":"markdown","acda1fbc":"markdown","04c841a1":"markdown","ffab7f9f":"markdown","9dfbe26e":"markdown","20c67f77":"markdown","2e3c69b4":"markdown","8af9a213":"markdown","b279cec2":"markdown","650908a8":"markdown","dd026e02":"markdown","56597ca7":"markdown","42a872d6":"markdown","077959e5":"markdown","d735001f":"markdown","4744c587":"markdown","3cd5c1b6":"markdown","c2d1091b":"markdown","31bd27d3":"markdown","d202c5f3":"markdown","3025888b":"markdown","b0db310e":"markdown","cc0265ef":"markdown","69f420cc":"markdown"},"source":{"ee273ef4":"# KimBaek Seyeong\n# Class Data Analysis and Utilization\n\n# Comparison between 2019,12 and 2020,10\nimport re\nimport time\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nimport matplotlib as mpl\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nfrom multiprocessing import Pool\nimport nltk\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport random as rd\n\ndf1 = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2019_12_after_preprocessing.csv\", low_memory = False)\ndf2 = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2020_10_after_preprocessing.csv\", low_memory = False)\ndf1ch = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2019_12_changed_compared_with_2020_10_after_preprocessing.csv\", low_memory = False)\ndf2ch = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2020_10_changed_compared_with_2019_12_after_preprocessing.csv\", low_memory = False)\ndfad = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2020_10_added_compared_with_2019_12_after_preprocessing.csv\", low_memory = False)\ndfdr = pd.read_csv(\"\/kaggle\/input\/kbs-airbnb-after-preprocessing\/2020_10_dropped_compared_with_2019_12_after_preprocessing.csv\", low_memory = False)","1212f7ff":"def text_cleaning(data): # multi-string \ud615\uc2dd\uc73c\ub85c \uc800\uc7a5\ub41c \ud30c\uc77c\uc744 \uadf8\ub300\ub85c \uc0ac\uc6a9\ud560 \uacbd\uc6b0\uc758 \ucf54\ub4dc\n    # \uc601\ubb38\uc790 \uc774\uc678 \ubb38\uc790\ub294 \uacf5\ubc31\uc73c\ub85c \ubcc0\ud658\n    only_english = re.sub('[^a-zA-Z]', ' ', str(data))\n \n    # \uc18c\ubb38\uc790 \ubcc0\ud658\n    no_capitals = only_english.lower().split()\n \n    # \ubd88\uc6a9\uc5b4 \uc81c\uac70\n    stops = set(stopwords.words('english'))\n    no_stops = [word for word in no_capitals if not word in stops]\n \n    # \uc5b4\uac04 \ucd94\ucd9c\n    stemmer = nltk.stem.SnowballStemmer('english')\n    stemmer_words = [stemmer.stem(word) for word in no_stops]\n \n    # \uacf5\ubc31\uc73c\ub85c \uad6c\ubd84\ub41c \ubb38\uc790\uc5f4\ub85c \uacb0\ud569\ud558\uc5ec \uacb0\uacfc \ubc18\ud658\n    return ' '.join(stemmer_words)","eb3ed2f9":"df1.info()\nprint(\"\\n\")\ndf2.info()\nprint(\"\\n\")\ndf1ch.info()\nprint(\"\\n\")\ndf2ch.info()\nprint(\"\\n\")\ndfad.info()\nprint(\"\\n\")\ndfdr.info()","32e83db1":"print(df1.isnull().sum())\nprint(\"\\n\")\nprint(df2.isnull().sum())\nprint(\"\\n\")\nprint(df1ch.isnull().sum())\nprint(\"\\n\")\nprint(df2ch.isnull().sum())\nprint(\"\\n\")\nprint(dfad.isnull().sum())\nprint(\"\\n\")\nprint(dfdr.isnull().sum())","b0a16416":"df1_group1 = df1.groupby('neighbourhood_group_cleansed').size()\ndf1_group2 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndf1_group3 = df1.groupby('room_type').size()\ndf1_group4 = df1.groupby('price').size()\ndf1_group5 = df1.groupby('review_scores_rating').size()\ndf1_group6 = df1.groupby(['neighbourhood_group_cleansed', 'room_type']).size()\ndf1_group7 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'room_type']).size()\ndf1_group8 = df1.groupby(['neighbourhood_group_cleansed', 'price']).size()\ndf1_group9 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'price']).size()\ndf1_group10 = df1.groupby(['neighbourhood_group_cleansed', 'review_scores_rating']).size()\ndf1_group11 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'review_scores_rating']).size()\ndf1_group12 = df1.groupby(['neighbourhood_group_cleansed', 'room_type', 'price']).size()\ndf1_group13 = df1.groupby(['neighbourhood_group_cleansed', 'room_type', 'review_scores_rating']).size()\ndf1_group14 = df1.groupby(['neighbourhood_group_cleansed', 'price', 'review_scores_rating']).size()\ndf1_group15 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'room_type', 'price']).size()\ndf1_group16 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'room_type', 'review_scores_rating']).size()\ndf1_group17 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'price', 'review_scores_rating']).size()\ndf1_group18 = df1.groupby(['neighbourhood_group_cleansed', 'room_type', 'price', 'review_scores_rating']).size()\ndf1_group19 = df1.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed', 'room_type', 'price', 'review_scores_rating']).size()","d274bcc8":"for i in range(1, 20):\n    name1 = globals()['df1_group{}'.format(i)]\n    print(name1)\n    print(name1.describe())\n    print(\"\\n\")","4b10e43a":"df1_group2_1 = df1_group2['Bronx']\ndf1_group2_1 = pd.DataFrame(df1_group2_1)","3cdf5fa4":"bronx_list = [item for item in df1_group2_1.index]\nbronx_list","161ad96e":"df1_group2_2 = df1_group2['Brooklyn']\ndf1_group2_2 = pd.DataFrame(df1_group2_2)\nbrooklyn_list = [item for item in df1_group2_2.index]\n\ndf1_group2_3 = df1_group2['Manhattan']\ndf1_group2_3 = pd.DataFrame(df1_group2_3)\nmanhattan_list = [item for item in df1_group2_3.index]\n\ndf1_group2_4 = df1_group2['Queens']\ndf1_group2_4 = pd.DataFrame(df1_group2_4)\nqueens_list = [item for item in df1_group2_4.index]\n\ndf1_group2_5 = df1_group2['Staten Island']\ndf1_group2_5 = pd.DataFrame(df1_group2_5)\nstatenisland_list = [item for item in df1_group2_5.index]","4ac0f592":"biggroup_list = [item for item in df1_group1.index]\nroomtype_list = [item for item in df1_group3.index]","c1750d75":"df1_tmp1 = df1.dropna(subset=['price'])\ndf1_tmp2 = df1.dropna(subset=['review_scores_rating'])","da98645e":"# percentage distribution array of price\np = [i for i in range(100)]\ncontent = np.percentile(df1_tmp1['price'], p, interpolation='nearest')\nlen(content)","c2b6a8f1":"# print percent of value\ndef price_percentage_to_string(start, stop, step):\n    p = np.arange(start, stop, step)\n    prev = 'start'\n    try:\n        for i in p:\n            if prev != content[i]:\n                msg = '\uac00\uaca9\uc774 ' + str(content[i]) + '$ \uc774\ub0b4\uc5d0 \ubd84\ud3ec\ud558\ub294 \uc219\uc18c\ub294 \uc804\uccb4 \ub370\uc774\ud130\uc758 ' + str(i) + '\ud37c\uc13c\ud2b8\uc785\ub2c8\ub2e4.'\n                print(msg)\n                prev = content[i]\n    except IndexError:\n        pass\nprice_percentage_to_string(0, 100, 1)","160ecccb":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(df1_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","43547da9":"# print percent of value\ndef review_scores_rating_percentage_to_string(start, stop, step):\n    p = np.arange(start, stop, step)\n    prev = 'start'\n    try:\n        for i in p:\n            if prev != content[i]:\n                msg = '\uc0ac\uc6a9\uc790 \ud3c9\uc810 \ud3c9\uade0\uc774 ' + str(content[i]) + '\uc810 \uc774\ub0b4\uc5d0 \ubd84\ud3ec\ud558\ub294 \uc219\uc18c\ub294 \uc804\uccb4 \ub370\uc774\ud130\uc758 ' + str(i) + '\ud37c\uc13c\ud2b8\uc785\ub2c8\ub2e4.'\n                print(msg)\n                prev = content[i]\n    except IndexError:\n        pass\nreview_scores_rating_percentage_to_string(0, 100, 1)","5735c2e5":"df1 = df1[df1.neighbourhood_group_cleansed != 'Bronx']\ndf1 = df1[df1.neighbourhood_group_cleansed != 'Staten Island']\ndf2 = df2[df2.neighbourhood_group_cleansed != 'Bronx']\ndf2 = df2[df2.neighbourhood_group_cleansed != 'Staten Island']\ndf1ch = df1ch[df1ch.neighbourhood_group_cleansed != 'Bronx']\ndf1ch = df1ch[df1ch.neighbourhood_group_cleansed != 'Staten Island']\ndf2ch = df2ch[df2ch.neighbourhood_group_cleansed != 'Bronx']\ndf2ch = df2ch[df2ch.neighbourhood_group_cleansed != 'Staten Island']\ndfad = dfad[dfad.neighbourhood_group_cleansed != 'Bronx']\ndfad = dfad[dfad.neighbourhood_group_cleansed != 'Staten Island']\ndfdr = dfdr[dfdr.neighbourhood_group_cleansed != 'Bronx']\ndfdr = dfdr[dfdr.neighbourhood_group_cleansed != 'Staten Island']","07558081":"for i in range(len(biggroup_list)):\n    print(biggroup_list[i])","a91e1900":"biggroup_list.remove('Bronx')\nbiggroup_list.remove('Staten Island')","39700f96":"for i in range(len(biggroup_list)):\n    globals()['df1_group{}'.format(i+1)] = df1[df1.neighbourhood_group_cleansed == biggroup_list[i]]","cb2ccd38":"for i in range(len(roomtype_list)):\n    globals()['df1_group{}'.format(i+4)] = df1[df1.room_type == roomtype_list[i]]","35d46a77":"for i in range(len(brooklyn_list)):\n    globals()['df1_group{}'.format(i+8)] = df1[df1.neighbourhood_cleansed == brooklyn_list[i]]\n\nlen(brooklyn_list)","f9e7867d":"for i in range(len(manhattan_list)):\n    globals()['df1_group{}'.format(i+55)] = df1[df1.neighbourhood_cleansed == manhattan_list[i]]\n\nlen(manhattan_list)","d0e86410":"for i in range(len(queens_list)):\n    globals()['df1_group{}'.format(i+87)] = df1[df1.neighbourhood_cleansed == queens_list[i]]\n    \nlen(queens_list)","78366d45":"df1_group138 = df1[df1.price < 81]\ndf1_group139 = df1[df1.price < 150]\ndf1_group139 = df1_group139[df1_group139.price >= 81]\ndf1_group140 = df1[df1.price >= 150]","1b165c31":"df1_group141 = df1[df1.review_scores_rating < 93]\ndf1_group142 = df1[df1.review_scores_rating < 98]\ndf1_group142 = df1_group142[df1_group142.price >= 93]\ndf1_group143 = df1[df1.review_scores_rating >= 98]","b28bf209":"for i in range(len(roomtype_list)):\n    globals()['df1_group1n{}'.format(i+1)] = df1_group1[df1_group1.room_type == roomtype_list[i]]","36b0f1fb":"df2_group1 = df2.groupby('neighbourhood_group_cleansed').size()\ndf2_group2 = df2.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndf2_group3 = df2.groupby('room_type').size()\ndf2_group4 = df2.groupby('price').size()\ndf2_group5 = df2.groupby('review_scores_rating').size()","1173e196":"biggroup_list2 = [item for item in df2_group1.index]\n\ndf2_group2_1 = df2_group2['Brooklyn']\ndf2_group2_1 = pd.DataFrame(df2_group2_1)\nbrooklyn_list2 = [item for item in df2_group2_1.index]\n\ndf2_group2_2 = df2_group2['Manhattan']\ndf2_group2_2 = pd.DataFrame(df2_group2_2)\nmanhattan_list2 = [item for item in df2_group2_2.index]\n\ndf2_group2_3 = df2_group2['Queens']\ndf2_group2_3 = pd.DataFrame(df2_group2_3)\nqueens_list2 = [item for item in df2_group2_3.index]\n\nroomtype_list2 = [item for item in df2_group3.index]\n\ndf2_tmp1 = df2.dropna(subset=['price'])\ndf2_tmp2 = df2.dropna(subset=['review_scores_rating'])\n\n# percentage distribution array of price\ncontent = np.percentile(df2_tmp1['price'], p, interpolation='nearest')\nlen(content)","d6023498":"price_percentage_to_string(0, 100, 1)","ca666f51":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(df2_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","c01fcc4e":"review_scores_rating_percentage_to_string(0, 100, 1)","53ebd7e7":"for i in range(len(biggroup_list2)): #3\n    globals()['df2_group{}'.format(i+1)] = df2[df2.neighbourhood_group_cleansed == biggroup_list2[i]]\n\nfor i in range(len(roomtype_list2)): #4\n    globals()['df2_group{}'.format(i+4)] = df2[df2.room_type == roomtype_list2[i]]\n    \nfor i in range(len(brooklyn_list2)): #47\n    globals()['df2_group{}'.format(i+8)] = df2[df2.neighbourhood_cleansed == brooklyn_list2[i]]\n\nfor i in range(len(manhattan_list2)): #32\n    globals()['df2_group{}'.format(i+55)] = df2[df2.neighbourhood_cleansed == manhattan_list2[i]]\n\nfor i in range(len(queens_list2)): #51\n    globals()['df2_group{}'.format(i+87)] = df2[df2.neighbourhood_cleansed == queens_list2[i]]\n    \ndf2_group138 = df2[df2.price < 78]\ndf2_group139 = df2[df2.price < 139]\ndf2_group139 = df2_group139[df2_group139.price >= 78]\ndf2_group140 = df2[df2.price >= 139]\n\ndf2_group141 = df2[df2.review_scores_rating < 94]\ndf2_group142 = df2[df2.review_scores_rating < 98]\ndf2_group142 = df2_group142[df2_group142.price >= 94]\ndf2_group143 = df2[df2.review_scores_rating >= 98]","82cb7ece":"df1ch_group1 = df1ch.groupby('neighbourhood_group_cleansed').size()\ndf1ch_group2 = df1ch.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndf1ch_group3 = df1ch.groupby('room_type').size()\ndf1ch_group4 = df1ch.groupby('price').size()\ndf1ch_group5 = df1ch.groupby('review_scores_rating').size()","6bf242e1":"biggroup_list3 = [item for item in df1ch_group1.index]\n\ndf1ch_group2_1 = df1ch_group2['Brooklyn']\ndf1ch_group2_1 = pd.DataFrame(df1ch_group2_1)\nbrooklyn_list3 = [item for item in df1ch_group2_1.index]\n\ndf1ch_group2_2 = df1ch_group2['Manhattan']\ndf1ch_group2_2 = pd.DataFrame(df1ch_group2_2)\nmanhattan_list3 = [item for item in df1ch_group2_2.index]\n\ndf1ch_group2_3 = df1ch_group2['Queens']\ndf1ch_group2_3 = pd.DataFrame(df1ch_group2_3)\nqueens_list3 = [item for item in df1ch_group2_3.index]\n\nroomtype_list3 = [item for item in df1ch_group3.index]\n\ndf1ch_tmp1 = df1ch.dropna(subset=['price'])\ndf1ch_tmp2 = df1ch.dropna(subset=['review_scores_rating'])\n\n# percentage distribution array of price\ncontent = np.percentile(df1ch_tmp1['price'], p, interpolation='nearest')\nlen(content)","e0c7397c":"price_percentage_to_string(0, 100, 1)","a60fb5fa":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(df1ch_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","1f4121eb":"review_scores_rating_percentage_to_string(0, 100, 1)","ed23e893":"for i in range(len(biggroup_list3)): #3\n    globals()['df1ch_group{}'.format(i+1)] = df1ch[df1ch.neighbourhood_group_cleansed == biggroup_list3[i]]\n\nfor i in range(len(roomtype_list3)): #4\n    globals()['df1ch_group{}'.format(i+4)] = df1ch[df1ch.room_type == roomtype_list3[i]]\n    \nfor i in range(len(brooklyn_list3)): #47\n    globals()['df1ch_group{}'.format(i+8)] = df1ch[df1ch.neighbourhood_cleansed == brooklyn_list3[i]]\n\nfor i in range(len(manhattan_list3)): #32\n    globals()['df1ch_group{}'.format(i+55)] = df1ch[df1ch.neighbourhood_cleansed == manhattan_list3[i]]\n\nfor i in range(len(queens_list3)): #50\n    globals()['df1ch_group{}'.format(i+87)] = df1ch[df1ch.neighbourhood_cleansed == queens_list3[i]]\n    \ndf1ch_group137 = df1ch[df1ch.price < 85]\ndf1ch_group138 = df1ch[df1ch.price < 150]\ndf1ch_group138 = df1ch_group138[df1ch_group138.price >= 85]\ndf1ch_group139 = df1ch[df1ch.price >= 150]\n\ndf1ch_group140 = df1ch[df1ch.review_scores_rating < 94]\ndf1ch_group141 = df1ch[df1ch.review_scores_rating < 98]\ndf1ch_group141 = df1ch_group141[df1ch_group141.price >= 94]\ndf1ch_group142 = df1ch[df1ch.review_scores_rating >= 98]","29144f46":"df2ch_group1 = df2ch.groupby('neighbourhood_group_cleansed').size()\ndf2ch_group2 = df2ch.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndf2ch_group3 = df2ch.groupby('room_type').size()\ndf2ch_group4 = df2ch.groupby('price').size()\ndf2ch_group5 = df2ch.groupby('review_scores_rating').size()","641f7825":"biggroup_list4 = [item for item in df2ch_group1.index]\n\ndf2ch_group2_1 = df2ch_group2['Brooklyn']\ndf2ch_group2_1 = pd.DataFrame(df2ch_group2_1)\nbrooklyn_list4 = [item for item in df2ch_group2_1.index]\n\ndf2ch_group2_2 = df2ch_group2['Manhattan']\ndf2ch_group2_2 = pd.DataFrame(df2ch_group2_2)\nmanhattan_list4 = [item for item in df2ch_group2_2.index]\n\ndf2ch_group2_3 = df2ch_group2['Queens']\ndf2ch_group2_3 = pd.DataFrame(df2ch_group2_3)\nqueens_list4 = [item for item in df2ch_group2_3.index]\n\nroomtype_list4 = [item for item in df2ch_group3.index]\n\ndf2ch_tmp1 = df2ch.dropna(subset=['price'])\ndf2ch_tmp2 = df2ch.dropna(subset=['review_scores_rating'])\n\n# percentage distribution array of price\ncontent = np.percentile(df2ch_tmp1['price'], p, interpolation='nearest')\nlen(content)","25df401b":"price_percentage_to_string(0, 100, 1)","8424faf7":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(df2ch_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","fd4c1521":"review_scores_rating_percentage_to_string(0, 100, 1)","ff267d50":"for i in range(len(biggroup_list4)): #3\n    globals()['df2ch_group{}'.format(i+1)] = df2ch[df2ch.neighbourhood_group_cleansed == biggroup_list4[i]]\n\nfor i in range(len(roomtype_list4)): #4\n    globals()['df2ch_group{}'.format(i+4)] = df2ch[df2ch.room_type == roomtype_list4[i]]\n    \nfor i in range(len(brooklyn_list4)): #47\n    globals()['df2ch_group{}'.format(i+8)] = df2ch[df2ch.neighbourhood_cleansed == brooklyn_list4[i]]\n\nfor i in range(len(manhattan_list4)): #32\n    globals()['df2ch_group{}'.format(i+55)] = df2ch[df2ch.neighbourhood_cleansed == manhattan_list4[i]]\n\nfor i in range(len(queens_list4)): #51\n    globals()['df2ch_group{}'.format(i+87)] = df2ch[df2ch.neighbourhood_cleansed == queens_list4[i]]\n    \ndf2ch_group138 = df2ch[df2ch.price < 79]\ndf2ch_group139 = df2ch[df2ch.price < 139]\ndf2ch_group139 = df2ch_group139[df2ch_group139.price >= 79]\ndf2ch_group140 = df2ch[df2ch.price >= 139]\n\ndf2ch_group141 = df2ch[df2ch.review_scores_rating < 94]\ndf2ch_group142 = df2ch[df2ch.review_scores_rating < 98]\ndf2ch_group142 = df2ch_group142[df2ch_group142.price >= 94]\ndf2ch_group143 = df2ch[df2ch.review_scores_rating >= 98]","516f9a9f":"dfad_group1 = dfad.groupby('neighbourhood_group_cleansed').size()\ndfad_group2 = dfad.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndfad_group3 = dfad.groupby('room_type').size()\ndfad_group4 = dfad.groupby('price').size()\ndfad_group5 = dfad.groupby('review_scores_rating').size()","54ef9c3c":"biggroup_list5 = [item for item in dfad_group1.index]\n\ndfad_group2_1 = dfad_group2['Brooklyn']\ndfad_group2_1 = pd.DataFrame(dfad_group2_1)\nbrooklyn_list5 = [item for item in dfad_group2_1.index]\n\ndfad_group2_2 = dfad_group2['Manhattan']\ndfad_group2_2 = pd.DataFrame(dfad_group2_2)\nmanhattan_list5 = [item for item in dfad_group2_2.index]\n\ndfad_group2_3 = dfad_group2['Queens']\ndfad_group2_3 = pd.DataFrame(dfad_group2_3)\nqueens_list5 = [item for item in dfad_group2_3.index]\n\nroomtype_list5 = [item for item in dfad_group3.index]\n\ndfad_tmp1 = dfad.dropna(subset=['price'])\ndfad_tmp2 = dfad.dropna(subset=['review_scores_rating'])\n\n# percentage distribution array of price\ncontent = np.percentile(dfad_tmp1['price'], p, interpolation='nearest')\nlen(content)","170fa987":"price_percentage_to_string(0, 100, 1)","a0fd9f07":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(dfad_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","f023b1d0":"review_scores_rating_percentage_to_string(0, 100, 1)","5599fe32":"for i in range(len(biggroup_list5)): #3\n    globals()['dfad_group{}'.format(i+1)] = dfad[dfad.neighbourhood_group_cleansed == biggroup_list5[i]]\n\nfor i in range(len(roomtype_list5)): #4\n    globals()['dfad_group{}'.format(i+4)] = dfad[dfad.room_type == roomtype_list5[i]]\n    \nfor i in range(len(brooklyn_list5)): #46\n    globals()['dfad_group{}'.format(i+8)] = dfad[dfad.neighbourhood_cleansed == brooklyn_list5[i]]\n\nfor i in range(len(manhattan_list5)): #32\n    globals()['dfad_group{}'.format(i+54)] = dfad[dfad.neighbourhood_cleansed == manhattan_list5[i]]\n\nfor i in range(len(queens_list5)): #41\n    globals()['dfad_group{}'.format(i+86)] = dfad[dfad.neighbourhood_cleansed == queens_list5[i]]\n    \ndfad_group127 = dfad[dfad.price < 75]\ndfad_group128 = dfad[dfad.price < 135]\ndfad_group128 = dfad_group128[dfad_group128.price >= 75]\ndfad_group129 = dfad[dfad.price >= 135]\n\ndfad_group130 = dfad[dfad.review_scores_rating < 94]\ndfad_group131 = dfad[dfad.review_scores_rating < 98]\ndfad_group131 = dfad_group131[dfad_group131.price >= 94]\ndfad_group132 = dfad[dfad.review_scores_rating >= 98]","076ec8e7":"dfdr_group1 = dfdr.groupby('neighbourhood_group_cleansed').size()\ndfdr_group2 = dfdr.groupby(['neighbourhood_group_cleansed', 'neighbourhood_cleansed']).size()\ndfdr_group3 = dfdr.groupby('room_type').size()\ndfdr_group4 = dfdr.groupby('price').size()\ndfdr_group5 = dfdr.groupby('review_scores_rating').size()","3c38f37b":"biggroup_list6 = [item for item in dfdr_group1.index]\n\ndfdr_group2_1 = dfdr_group2['Brooklyn']\ndfdr_group2_1 = pd.DataFrame(dfdr_group2_1)\nbrooklyn_list6 = [item for item in dfdr_group2_1.index]\n\ndfdr_group2_2 = dfdr_group2['Manhattan']\ndfdr_group2_2 = pd.DataFrame(dfdr_group2_2)\nmanhattan_list6 = [item for item in dfdr_group2_2.index]\n\ndfdr_group2_3 = dfdr_group2['Queens']\ndfdr_group2_3 = pd.DataFrame(dfdr_group2_3)\nqueens_list6 = [item for item in dfdr_group2_3.index]\n\nroomtype_list6 = [item for item in dfdr_group3.index]\n\ndfdr_tmp1 = dfdr.dropna(subset=['price'])\ndfdr_tmp2 = dfdr.dropna(subset=['review_scores_rating'])\n\n# percentage distribution array of price\ncontent = np.percentile(dfdr_tmp1['price'], p, interpolation='nearest')\nlen(content)","4279afcb":"print(len(biggroup_list6))\nprint(len(brooklyn_list6))\nprint(len(manhattan_list6))\nprint(len(queens_list6))\nprint(len(roomtype_list6))","5ba0846d":"price_percentage_to_string(0, 100, 1)","8f2ae31c":"# percentage distribution array of review_scores_rating\ncontent = np.percentile(dfdr_tmp2['review_scores_rating'], p, interpolation='nearest')\nlen(content)","0f19c552":"review_scores_rating_percentage_to_string(0, 100, 1)","02bcb0c3":"for i in range(len(biggroup_list6)): #3\n    globals()['dfdr_group{}'.format(i+1)] = dfdr[dfdr.neighbourhood_group_cleansed == biggroup_list6[i]]\n\nfor i in range(len(roomtype_list6)): #4\n    globals()['dfdr_group{}'.format(i+4)] = dfdr[dfdr.room_type == roomtype_list6[i]]\n    \nfor i in range(len(brooklyn_list6)): #45\n    globals()['dfdr_group{}'.format(i+8)] = dfdr[dfdr.neighbourhood_cleansed == brooklyn_list6[i]]\n\nfor i in range(len(manhattan_list6)): #31\n    globals()['dfdr_group{}'.format(i+53)] = dfdr[dfdr.neighbourhood_cleansed == manhattan_list6[i]]\n\nfor i in range(len(queens_list6)): #49\n    globals()['dfdr_group{}'.format(i+84)] = dfdr[dfdr.neighbourhood_cleansed == queens_list6[i]]\n    \ndfdr_group133 = dfdr[dfdr.price < 80]\ndfdr_group134 = dfdr[dfdr.price < 155]\ndfdr_group134 = dfdr_group134[dfdr_group134.price >= 80]\ndfdr_group135 = dfdr[dfdr.price >= 155]\n\ndfdr_group136 = dfdr[dfdr.review_scores_rating < 94]\ndfdr_group137 = dfdr[dfdr.review_scores_rating < 98]\ndfdr_group137 = dfdr_group137[dfdr_group137.price >= 94]\ndfdr_group138 = dfdr[dfdr.review_scores_rating >= 98]","59b7f5ef":"for i in range(1, 144):\n    globals()['df1_group{}_df'.format(i)] = pd.DataFrame(globals()['df1_group{}'.format(i)])\n    name0= \"df1_group\"+str(i)\n    globals()['df1_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n\nfor i in range(1, 144):\n    globals()['df2_group{}_df'.format(i)] = pd.DataFrame(globals()['df2_group{}'.format(i)])\n    name0= \"df2_group\"+str(i)\n    globals()['df2_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n\nfor i in range(1, 143):\n    globals()['df1ch_group{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_group{}'.format(i)])\n    name0= \"df1ch_group\"+str(i)\n    globals()['df1ch_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nfor i in range(1, 144):\n    globals()['df2ch_group{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_group{}'.format(i)])\n    name0= \"df2ch_group\"+str(i)\n    globals()['df2ch_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nfor i in range(1, 133):\n    globals()['dfad_group{}_df'.format(i)] = pd.DataFrame(globals()['dfad_group{}'.format(i)])\n    name0= \"dfad_group\"+str(i)\n    globals()['dfad_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nfor i in range(1, 139):\n    globals()['dfdr_group{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_group{}'.format(i)])\n    name0= \"dfdr_group\"+str(i)\n    globals()['dfdr_group{}_df'.format(i)].to_csv(name0+'.csv', index=False)","6c2005b0":"def use_multiprocess(func, iter, workers):\n    pool = Pool(processes=workers)\n    result = pool.map(func, iter)\n    pool.close()\n    return result","9ccaae41":"def text_cleaning(data):\n    only_english = re.sub('[^a-zA-Z]', ' ', str(data))\n    no_capitals = only_english.lower().split()\n    stops = set(stopwords.words('english'))\n    no_stops = [word for word in no_capitals if not word in stops]\n    stemmer = nltk.stem.SnowballStemmer('english')\n    stemmer_words = [stemmer.stem(word) for word in no_stops]\n    return ' '.join(stemmer_words)","58519ff9":"def counter(input_list):\n    word_count = {}\n    for word in input_list:\n        if word in  word_count:\n            word_count[word] += 1\n        else:\n            word_count[word] = 1\n    return word_count","7054535c":"print(type(df1_group1))\nprint(type(df1_group1['description']))","f5e0c457":"# df1\nstart_time = time.time()\nfor i in range(1, 144):\n    name1 = globals()['df1_group{}'.format(i)]\n    globals()['df1_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['df1_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['df1_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['df1_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['df1_cleaned1_{}'.format(i)])\n    globals()['df1_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['df1_cleaned2_{}'.format(i)])\n    globals()['df1_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['df1_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","e25d3feb":"# df2\nstart_time = time.time()\nfor i in range(1, 144):\n    name1 = globals()['df2_group{}'.format(i)]\n    globals()['df2_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['df2_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['df2_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['df2_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['df2_cleaned1_{}'.format(i)])\n    globals()['df2_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['df2_cleaned2_{}'.format(i)])\n    globals()['df2_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['df2_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","8b51c159":"# df1ch\nstart_time = time.time()\nfor i in range(1, 143):\n    name1 = globals()['df1ch_group{}'.format(i)]\n    globals()['df1ch_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['df1ch_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['df1ch_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['df1ch_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_cleaned1_{}'.format(i)])\n    globals()['df1ch_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_cleaned2_{}'.format(i)])\n    globals()['df1ch_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","1bad76fb":"# df2ch\nstart_time = time.time()\nfor i in range(1, 144):\n    name1 = globals()['df2ch_group{}'.format(i)]\n    globals()['df2ch_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['df2ch_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['df2ch_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['df2ch_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_cleaned1_{}'.format(i)])\n    globals()['df2ch_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_cleaned2_{}'.format(i)])\n    globals()['df2ch_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","d2cd7c8e":"# dfad\nstart_time = time.time()\nfor i in range(1, 133):\n    name1 = globals()['dfad_group{}'.format(i)]\n    globals()['dfad_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['dfad_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['dfad_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['dfad_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_cleaned1_{}'.format(i)])\n    globals()['dfad_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_cleaned2_{}'.format(i)])\n    globals()['dfad_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","8f569130":"# dfdr\nstart_time = time.time()\nfor i in range(1, 139):\n    name1 = globals()['dfdr_group{}'.format(i)]\n    globals()['dfdr_cleaned1_{}'.format(i)] = use_multiprocess(text_cleaning, name1['description'], 3)\n    globals()['dfdr_cleaned2_{}'.format(i)] = use_multiprocess(text_cleaning, name1['neighborhood_overview'], 3)\n    globals()['dfdr_cleaned3_{}'.format(i)] = use_multiprocess(text_cleaning, name1['amenities'], 3)\n    globals()['dfdr_cleaned1_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_cleaned1_{}'.format(i)])\n    globals()['dfdr_cleaned2_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_cleaned2_{}'.format(i)])\n    globals()['dfdr_cleaned3_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_cleaned3_{}'.format(i)])\nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","c25ed485":"# df1\nstart_time = time.time()\nfor i in range(1, 144):\n    #1\n    name0 = globals()['df1_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['df1_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['df1_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['df1_count1_{}_df'.format(i)] = pd.DataFrame(globals()['df1_count1_{}'.format(i)])\n    globals()['df1_count2_{}_df'.format(i)] = pd.DataFrame(globals()['df1_count2_{}'.format(i)])\n    globals()['df1_count3_{}_df'.format(i)] = pd.DataFrame(globals()['df1_count3_{}'.format(i)])\n    name0 = \"df1_count1_\"+str(i)\n    globals()['df1_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df1_count2_\"+str(i)\n    globals()['df1_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df1_count3_\"+str(i)\n    globals()['df1_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","53824480":"# df2\nstart_time = time.time()\nfor i in range(1, 144):\n    #1\n    name0 = globals()['df2_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['df2_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['df2_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['df2_count1_{}_df'.format(i)] = pd.DataFrame(globals()['df2_count1_{}'.format(i)])\n    globals()['df2_count2_{}_df'.format(i)] = pd.DataFrame(globals()['df2_count2_{}'.format(i)])\n    globals()['df2_count3_{}_df'.format(i)] = pd.DataFrame(globals()['df2_count3_{}'.format(i)])\n    name0 = \"df2_count1_\"+str(i)\n    globals()['df2_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df2_count2_\"+str(i)\n    globals()['df2_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df2_count3_\"+str(i)\n    globals()['df2_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","68a66b8d":"# df1ch\nstart_time = time.time()\nfor i in range(1, 143):\n    #1\n    name0 = globals()['df1ch_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1ch_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['df1ch_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1ch_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['df1ch_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df1ch_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['df1ch_count1_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_count1_{}'.format(i)])\n    globals()['df1ch_count2_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_count2_{}'.format(i)])\n    globals()['df1ch_count3_{}_df'.format(i)] = pd.DataFrame(globals()['df1ch_count3_{}'.format(i)])\n    name0 = \"df1ch_count1_\"+str(i)\n    globals()['df1ch_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df1ch_count2_\"+str(i)\n    globals()['df1ch_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df1ch_count3_\"+str(i)\n    globals()['df1ch_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","886ce192":"# df2ch\nstart_time = time.time()\nfor i in range(1, 144):\n    #1\n    name0 = globals()['df2ch_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2ch_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['df2ch_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2ch_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['df2ch_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['df2ch_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['df2ch_count1_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_count1_{}'.format(i)])\n    globals()['df2ch_count2_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_count2_{}'.format(i)])\n    globals()['df2ch_count3_{}_df'.format(i)] = pd.DataFrame(globals()['df2ch_count3_{}'.format(i)])\n    name0 = \"df2ch_count1_\"+str(i)\n    globals()['df2ch_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df2ch_count2_\"+str(i)\n    globals()['df2ch_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"df2ch_count3_\"+str(i)\n    globals()['df2ch_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","6803ff01":"# dfad\nstart_time = time.time()\nfor i in range(1, 133):\n    #1\n    name0 = globals()['dfad_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfad_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['dfad_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfad_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['dfad_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfad_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['dfad_count1_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_count1_{}'.format(i)])\n    globals()['dfad_count2_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_count2_{}'.format(i)])\n    globals()['dfad_count3_{}_df'.format(i)] = pd.DataFrame(globals()['dfad_count3_{}'.format(i)])\n    name0 = \"dfad_count1_\"+str(i)\n    globals()['dfad_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"dfad_count2_\"+str(i)\n    globals()['dfad_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"dfad_count3_\"+str(i)\n    globals()['dfad_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","510ff288":"# dfdr\nstart_time = time.time()\nfor i in range(1, 139):\n    #1\n    name0 = globals()['dfdr_cleaned1_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfdr_count1_{}'.format(i)] = count1\n    \n    #2\n    name0 = globals()['dfdr_cleaned2_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfdr_count2_{}'.format(i)] = count1\n    \n    #3\n    name0 = globals()['dfdr_cleaned3_{}_df'.format(i)]\n\n    for j in range(0, len(name0)):\n        name1 = name0.iloc[j, 0]\n        name1 = str(name1)\n        name2 = name1.lower().split()\n        globals()['list1_{}'.format(j)] = name2\n\n    list1 = []\n    for j in range(0, len(name0)):\n        list1 = list1 + globals()['list1_{}'.format(j)]\n    \n    count1 = counter(list1)\n    count1 = sorted(count1.items(), key=lambda x:x[1], reverse=True)\n    globals()['dfdr_count3_{}'.format(i)] = count1\n    \n    # save\n    globals()['dfdr_count1_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_count1_{}'.format(i)])\n    globals()['dfdr_count2_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_count2_{}'.format(i)])\n    globals()['dfdr_count3_{}_df'.format(i)] = pd.DataFrame(globals()['dfdr_count3_{}'.format(i)])\n    name0 = \"dfdr_count1_\"+str(i)\n    globals()['dfdr_count1_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"dfdr_count2_\"+str(i)\n    globals()['dfdr_count2_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    name0 = \"dfdr_count3_\"+str(i)\n    globals()['dfdr_count3_{}_df'.format(i)].to_csv(name0+'.csv', index=False)\n    \nprint('\uc2e4\ud589 \uc2dc\uac04 :', (time.time() - start_time))","d21314bd":"#mpl.rcParams['figure.figsize']=(8.0,6.0)    #(6.0,4.0)\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1\n\nstopwords = set(STOPWORDS)","034d591b":"# df1\nfor i in range(1, 144):\n    globals()['df1_wc1_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1_count1_{}'.format(i)]))\n    globals()['df1_wc2_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1_count2_{}'.format(i)]))\n    globals()['df1_wc3_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1_count3_{}'.format(i)]))\n\nfor i in range(1, 144):\n    print(globals()['df1_wc1_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1_wc1_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1_word1_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df1_wc2_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1_wc2_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1_word2_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df1_wc3_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1_wc3_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1_word3_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)","fcbf2e2f":"# df2\nfor i in range(1, 144):\n    globals()['df2_wc1_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2_count1_{}'.format(i)]))\n    globals()['df2_wc2_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2_count2_{}'.format(i)]))\n    globals()['df2_wc3_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2_count3_{}'.format(i)]))\n\nfor i in range(1, 144):\n    print(globals()['df2_wc1_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2_wc1_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2_word1_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df2_wc2_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2_wc2_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2_word2_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df2_wc3_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2_wc3_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2_word3_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)","ab6aa6e4":"# df1ch\nfor i in range(1, 143):\n    globals()['df1ch_wc1_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1ch_count1_{}'.format(i)]))\n    globals()['df1ch_wc2_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1ch_count2_{}'.format(i)]))\n    globals()['df1ch_wc3_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df1ch_count3_{}'.format(i)]))\n    \n\nfor i in range(1, 143):\n    print(globals()['df1ch_wc1_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1ch_wc1_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1ch_word1_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df1ch_wc2_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1ch_wc2_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1ch_word2_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df1ch_wc3_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df1ch_wc3_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df1ch_word3_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)","c0a0c3c8":"# df2ch\nfor i in range(1, 144):\n    globals()['df2ch_wc1_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2ch_count1_{}'.format(i)]))\n    globals()['df2ch_wc2_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2ch_count2_{}'.format(i)]))\n    globals()['df2ch_wc3_{}'.format(i)] = WordCloud(background_color='white',\n                                            stopwords=stopwords,\n                                            max_words=200,\n                                            max_font_size=50, \n                                            random_state=42\n                                            ).generate(str(globals()['df2ch_count3_{}'.format(i)]))\n\nfor i in range(1, 144):\n    print(globals()['df2ch_wc1_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2ch_wc1_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2ch_word1_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df2ch_wc2_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2ch_wc2_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2ch_word2_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)\n    print(globals()['df2ch_wc3_{}'.format(i)])\n    fig = plt.figure(1)\n    plt.imshow(globals()['df2ch_wc3_{}'.format(i)])\n    plt.axis('off')\n    plt.show()\n    name = 'df2ch_word3_'+str(i)+'.png'\n    fig.savefig(name, dpi=900)","14769c37":"\uac00\uaca9\uacfc \ud3c9\uade0\uc740 \uc0c1\/\uc911\/\ud558\uc758 3\uac00\uc9c0\ub85c \ub098\ub20c \uc608\uc815\uc785\ub2c8\ub2e4.\n\n\ub530\ub77c\uc11c\n* price : 81\uc774\ub0b4(34%) 150\uc774\ub0b4(32%; 66%) 150\uc774\uc0c1(34%)\n* review_scores_rating : 93\uc774\ub0b4(29%) 98\uc774\ub0b4(34%; 63%) 98\uc774\uc0c1(37%)\n\n\ub97c \uae30\uc900\uc73c\ub85c \ub098\ub204\uac8c \ub429\ub2c8\ub2e4.","7c90ca65":"\uc6b0\uc120, \uac01 \ub370\uc774\ud130 \ud504\ub808\uc784\uc758 column \uc815\ubcf4\ub97c \ud655\uc778\ud558\uae30 \uc704\ud574 info() function\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4.","fbd87296":"# Input Datasets","4f3e9548":"* group1 : neighbourhood_group_cleansed\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group2 : neighbourhood_cleansed\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group3 : room_type\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group4 : price\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group5 : review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group6 : neighbourhood_group_cleansed, room_type\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group7 : neighbourhood_cleansed, room_type\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group8 : neighbourhood_group_cleansed, price\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group9 : neighbourhood_cleansed, price\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group10 : neighbourhood_group_cleansed, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group11 : neighbourhood_cleansed, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group12 : neighbourhood_group_cleansed, room_type, price\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group13 : neighbourhood_group_cleansed, room_type, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group14 : neighbourhood_group_cleansed, price, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group15 : neighbourhood_cleansed, room_type, price\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group16 : neighbourhood_cleansed, room_type, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group17 : neighbourhood_cleansed, price, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group18 : neighbourhood_group_cleansed, room_type, price, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84\n* group19 : neighbourhood_cleansed, room_type, price, review_scores_rating\uc5d0 \ub530\ub978 \uadf8\ub8f9 \uad6c\ubd84","97573348":"\uc774\uc5b4\uc9c0\ub294 notebook\uc5d0\uc11c\ub294 grouping\ud55c \uac83\ub4e4\uc744 \ubc14\ud0d5\uc73c\ub85c 2019\ub144\uacfc 2020\ub144\uc758 \uac01 column \ud2b9\ud788 numerical data\uc5d0\uc11c \uc5b4\ub5a4 \ubcc0\ud654\uac00 \uc788\uc5c8\ub294\uc9c0\ub97c \ud655\uc778\ud558\ub824\uace0 \ud569\ub2c8\ub2e4.\n\n\uc774\ub294 \uc804\uccb4 \ub370\uc774\ud130\uc14b, \uadf8\ub9ac\uace0 grouping \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc9c4\ud589\ub420 \uc608\uc815\uc774\uba70, \ube44\uad50\ud560 column\uc740 accommodates, price, minimum_nights, maximum_nights, availablity_365\uc785\ub2c8\ub2e4.\n\nmin\uac12\uacfc max\uac12\uc758 \uadf8\ub798\ud504, mean\uac12\uacfc average\uac12\uc758 \uadf8\ub798\ud504, \uc5bc\ub9c8\ub098 \ubd84\ud3ec\uc758 \ucc28\uc774\uac00 \uc788\ub294\uc9c0\ub97c \ud655\uc778\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\ub450 \uc2dc\uae30\uc758 \uac12 \ubcc0\ud654\ub97c \ud655\uc778\ud568\uc73c\ub85c\uc368 2021\ub144\uc758 \ub370\uc774\ud130\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud560 \uac83\uc778\uc9c0\uc5d0 \ub300\ud574 \uac04\ub7b5\ud558\uac8c \uc608\uce21\ud574\ubcfc \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n\ub610\ud55c, \ub3d9\uc77c\ud55c \uc219\uc18c\uc5d0\uc11c \ubcc0\ud654\ud55c \ub370\uc774\ud130\uc758 \uc804\uccb4 column\uc744 \ube44\uad50\ud558\uba70 \uc65c \ubcc0\ud654\ud588\ub294\uc9c0\uc5d0 \ub300\ud574 \uc704\uc640 \uc720\uc0ac\ud55c \ucc28\uc774\ub97c \ubcf4\uba74\uc11c \uc720\ucd94\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\uc774\uc5b4 \uc0ad\uc81c\ub41c \ub370\uc774\ud130\uc14b\ub3c4 \uc720\uc0ac\ud558\uac8c \uc218\uce58\ub97c \ud655\uc778\ud558\uba70 \uc774\uc720\ub97c \uc720\ucd94\ud560 \uac83\uc774\uace0, \ucd94\uac00\ub41c \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\ub3c4 \uc218\uce58\ub97c \ud1b5\ud574 \ud655\uc778\ud560 \uac83\uc785\ub2c8\ub2e4.","0be56dda":"# \uc791\uc131\ud55c notebook \ucc38\uace0\uc6a9 url \ucca8\ubd80\n\n* Preprocessing Airbnb Data 2019\/12 and 2020\/10 : https:\/\/www.kaggle.com\/kimbaekseyeong\/preprocessing-airbnb-data-2019-12-and-2020-10\n* Data Extraction Airbnb Data 2019\/12 and 2020\/10 : https:\/\/www.kaggle.com\/kimbaekseyeong\/extracting-dataset-airbnb-data-2019-12-and-2020-10\n* NB for Regular Expression Test : https:\/\/www.kaggle.com\/kimbaekseyeong\/nb-for-regular-expression-test\n* Analysis Airbnb Data 2019\/12 and 2020\/10 : https:\/\/www.kaggle.com\/kimbaekseyeong\/analysis-airbnb-data-2019-12-and-2020-10\n* Analysis(2) Airbnb Data 2019\/12 and 2020\/10 : https:\/\/www.kaggle.com\/kimbaekseyeong\/analysis-2-airbnb-data-2019-12-and-2020-10","7d9c7bb9":"price\uc640 review_scores_rating\uc758 \ubc31\ubd84\uc704 \uac12\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.\n\n\ud655\uc778 \uc774\uc804\uc5d0 nan\uc778 \ub370\uc774\ud130\uac00 \uc788\ub2e4\uba74 \uba3c\uc800 \uc9c0\uc6c1\ub2c8\ub2e4.","80f8f502":"df1~dr group (\uac01 143 143 142 143 132 138) save","954f227f":"\ub450 \uadf8\ub8f9 \ub0b4\uc5d0 \ubaa8\ub450 \uc874\uc7ac\ud558\ub294\uc9c0 \uc5ec\ubd80\ub97c \uac04\ub2e8\ud558\uac8c \ud655\uc778\ud574 \uc138\ubd80 \uadf8\ub8f9\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc544\ub798\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.\n\nbrooklyn \ub370\uc774\ud130\ub97c roomtype \ubcc4\ub85c \uad6c\ubd84\ud574\uc11c row \ucd94\ucd9c:","bd8ea764":"* df1 : 143\n* df2 : 143\n* df1ch : 142\n* df2ch : 143\n* dfad : 132\n* dfdr : 138","b37d5618":"\uc55e\uc120 notebook\uc5d0\uc11c \uc815\ub9ac\ud55c \uc801 \uc788\uc73c\ubbc0\ub85c \uac01 column\uc758 \ud65c\uc6a9 \ubc29\uc2dd\uc774\ub098 \uc758\ubbf8\uc5d0 \ub300\ud574\uc11c\ub294 \uc791\uc131\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\uc774\uc911\uc5d0\uc11c grouping\uc5d0 \ud65c\uc6a9\ud558\uae30 \uc801\uc808\ud55c column\uc740 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'room_type'\uc774\uba70 \ubd80\uac00\uc801\uc73c\ub85c 'price', 'review_scores_rating'\uc744 \uc0dd\uac01\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac01 data frame\uc5d0\uc11c \ucd94\ucd9c \uac00\ub2a5\ud55c \uad6c\ubd84 \ubc29\uc2dd\uc740 \uc544\ub798\uc640 \uac19\uc774 \uc0dd\uac01\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.","5dc5febc":"\uc544\ub798\ub294 dfad\uc785\ub2c8\ub2e4.","e58a363d":"df1ch\ub294 1~142\n\n\uc544\ub798\ub294 df2ch\uc785\ub2c8\ub2e4.","be08a8ca":"* df1_group1 : Brooklyn data in df1 #47\n* df1_group2 : Manhattan data in df1 #32\n* df1_group3 : Queens data in df1 #51\n* df1_group4 : Entire home\/apt data in df1\n* df1_group5 : Hotel room data in df1\n* df1_group6 : Private room data in df1\n* df1_group7 : Shared room data in df1\n* df1_group8 ~ 54 : small group of Brooklyn data in df1\n* df1_group55 ~ 86 : small group of Manhattan data in df1\n* df1_group87 ~ 137 : small group of Queens data in df1\n* df1_group138 : price 81 \ubbf8\ub9cc in df1\n* df1_group139 : price 81 \uc774\uc0c1 150 \ubbf8\ub9cc in df1\n* df1_group140 : price 150 \uc774\uc0c1 in df1\n* df1_group141 : \ud3c9\uc810 93 \ubbf8\ub9cc in df1\n* df1_group142 : \ud3c9\uc810 93 \uc774\uc0c1 98 \ubbf8\ub9cc in df1\n* df1_group143 : \ud3c9\uc810 98 \uc774\uc0c1 in df1","db5ba01a":"df2, df1ch, df2ch, dfad, dfdr\uc5d0\uc11c\uc758 grouping\ub3c4 \uc9c4\ud589\ud569\ub2c8\ub2e4.\n\n\uc544\ub798\ub294 df2\uc785\ub2c8\ub2e4.","99b52db0":"df2ch\uc5d0\uc11c\ub294\n* price : 79\uc774\ub0b4(34%) 139\uc774\ub0b4(33%; 67%) 139\uc774\uc0c1(33%)\n* review_scores_rating : 94\uc774\ub0b4(33%) 98\uc774\ub0b4(32%; 65%) 98\uc774\uc0c1(35%)","acda1fbc":"# Data Grouping for Word Analysis","04c841a1":"# Notebook Outline\n\nAnalysis(2) notebook\uc5d0 \uc774\uc5b4 \uc791\uc131\ud569\ub2c8\ub2e4.\n\n\uc774\uc5b4\uc9c0\ub294 notebook\uc5d0\uc11c \uc9c4\ud589\ud560 \uc0ac\ud56d\ub4e4\uc740 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n* \uadf8\ub8f9 \ub098\ub204\uae30 + \ub098\ub220\uc11c numerical, non-numerical \ub370\uc774\ud130 \uc2dc\uac01\ud654 \ubc0f \ube44\uad50 (\uadf8\ub8f9\ubcc4, \uc2dc\uae30\ubcc4)","ffab7f9f":"dfdr\uc5d0\uc11c\ub294\n* price : 80\uc774\ub0b4(34%) 155\uc774\ub0b4(34%; 68%) 155\uc774\uc0c1(32%)\n* review_scores_rating : 93\uc774\ub0b4(34%) 98\uc774\ub0b4(32%; 66%) 98\uc774\uc0c1(34%)","9dfbe26e":"\uc55e\uc11c biggroup_list, roomtype_list, brooklyn_list, manhattan_list, queens_list\ub97c \uc791\uc131\ud588\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ub9ac\uc2a4\ud2b8\uc758 \uc6d0\uc18c\ub97c \uc774\uc6a9\ud574 \ub530\ub85c \ub2e8\uc5b4\ub97c \uc791\uc131\ud560 \ud544\uc694 \uc5c6\uc774 \ud574\ub2f9\ud558\ub294 row\ub97c \ucd94\ucd9c\ud574 \uc0c8\ub85c\uc6b4 \uacf3\uc5d0 \ub2f4\uc73c\ub824 \ud569\ub2c8\ub2e4.","20c67f77":"# Data Grouping","2e3c69b4":"# Word Cloud","8af9a213":"\ub370\uc774\ud130 \ud504\ub808\uc784 \uc774\ub984 \uba54\ubaa8\n* df1 : 2019\ub144 12\uc6d4 Airbnb \uc81c\uacf5 NY, United States \ub370\uc774\ud130\uc14b\n* df2 : 2020\ub144 10\uc6d4 Airbnb \uc81c\uacf5 NY, United States \ub370\uc774\ud130\uc14b\n* df1ch : 2019\ub144 12\uc6d4 Airbnb \uc81c\uacf5 NY, United States \ub370\uc774\ud130\uc14b \uc911 2020\ub144 10\uc6d4\uc5d0 \ub370\uc774\ud130\uc5d0 \ubcc0\ub3d9\uc0ac\ud56d\uc774 \uc788\ub294 \ub9e4\ubb3c\n* df2ch : 2020\ub144 10\uc6d4 Airbnb \uc81c\uacf5 NY, United States \ub370\uc774\ud130\uc14b \uc911 2019\ub144 12\uc6d4\uacfc \ube44\uad50\ud588\uc744 \ub54c \ub370\uc774\ud130 \ubcc0\ub3d9\uc0ac\ud56d\uc774 \uc788\ub294 \ub9e4\ubb3c\n* dfad : 2019\ub144 12\uc6d4\uc5d0\ub294 \uc5c6\uc5c8\uc73c\ub098 2020\ub144 10\uc6d4\uc5d0 \ucd94\uac00\ub41c \ub370\uc774\ud130 \ubaa8\uc74c \ub370\uc774\ud130\uc14b\n* dfdr : 2019\ub144 12\uc6d4\uc5d0\ub294 \uc788\uc5c8\uc73c\ub098 2020\ub144 10\uc6d4\uc5d0 \uc0ac\ub77c\uc9c4 \ub370\uc774\ud130 \ubaa8\uc74c \ub370\uc774\ud130\uc14b\n\ndescription(2), neighborhood_overview(3), amenities(15)","b279cec2":"\uc9c0\uae08\uae4c\uc9c0 \ub370\uc774\ud130\ud504\ub808\uc784 df1\uc73c\ub85c \ud070 \uc9c0\uc5ed, \uc791\uc740 \uc9c0\uc5ed, \ubc29 \uad6c\ubd84, \uac00\uaca9, \uc0ac\uc6a9\uc790 \ud3c9\uc810 \ud3c9\uade0\uc744 \uae30\uc900\uc73c\ub85c \uadf8\ub8f9\uc744 \ub098\ub220\ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n\n\uc2e4\uc81c\ub85c \uc6cc\ub4dc \ud074\ub77c\uc6b0\ub4dc\uc640 \ub2e8\uc5b4 \ube48\ub3c4 \uc218\ub97c \ud655\uc778\ud558\uae30 \uc704\ud574, \ub2e4\uc2dc \ud55c \ubc88 grouping\uc744 \uc9c4\ud589\ud574\ubcf4\ub824 \ud569\ub2c8\ub2e4.\n\n\uc5ec\uae30\uc11c \uc7a0\uae50! Bronx\uc640 Staten Island\uc758 \ub370\uc774\ud130 \uc218\uac00 \uc804\uccb4 \ub370\uc774\ud130\uc758 1~4% \uc218\uc900\uc73c\ub85c \ubbf8\ubbf8\ud558\uae30 \ub54c\ubb38\uc5d0, \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uba3c\uc800 \uc81c\uac70\ud558\ub294 \uacfc\uc815\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4.","650908a8":"neighbourhood_group_cleansed, room_type\ub3c4 \uac19\uc740 \ubc29\ubc95\uc73c\ub85c index list\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n\nprice\uc640 review_scores_rating\uc740 \ubc31\ubd84\uc704\ub85c \uac12\uc744 \ud655\uc778\ud574, \uad6c\uac04\uc744 \ub098\ub220 \ub2e4\uc2dc grouping \ud569\ub2c8\ub2e4.","dd026e02":"dfad\uc5d0\uc11c\ub294\n* price : 75\uc774\ub0b4(34%) 135\uc774\ub0b4(33%; 67%) 135\uc774\uc0c1(33%)\n* review_scores_rating : 94\uc774\ub0b4(36%) 98\uc774\ub0b4(15%; 51%) 98\uc774\uc0c1(57%)","56597ca7":"df1ch\uc5d0\uc11c\ub294\n* price : 85\uc774\ub0b4(34%) 150\uc774\ub0b4(33%; 67%) 150\uc774\uc0c1(33%)\n* review_scores_rating : 94\uc774\ub0b4(31%) 98\uc774\ub0b4(30%; 61%) 98\uc774\uc0c1(38%)","42a872d6":"\uc544\ub798\ub294 df1ch \uc785\ub2c8\ub2e4.","077959e5":"Analysis(2) notebook\uc5d0\uc11c \uc791\uc131\ud55c non-numerical data preprocessing function \ucf54\ub4dc\ub97c \ubbf8\ub9ac \uc791\uc131\ud569\ub2c8\ub2e4.","d735001f":"\uc6b0\uc120 19\uac1c\uc758 \uadf8\ub8f9\uc744 \ub098\ub204\ub294 \uac83\uc740 pandas \ubaa8\ub4c8\uc758 groupby \ud568\uc218\ub97c \ud1b5\ud574 \uac00\ub2a5\ud569\ub2c8\ub2e4.","4744c587":"price : 81\uc774\ub0b4(34%) 150\uc774\ub0b4(32%; 66%) 150\uc774\uc0c1(34%)\n\nreview_scores_rating : 93\uc774\ub0b4(29%) 98\uc774\ub0b4(34%; 63%) 98\uc774\uc0c1(37%)","3cd5c1b6":"# Continued...\n\n","c2d1091b":"\ucd1d 19\uac1c\uc758 \uae30\uc900\uc73c\ub85c grouping\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4.\n\ngrouping\uc744 \ud558\ub294 \ubaa9\uc801\uc740 application \uc0ac\uc6a9\uc790 \uc120\ud0dd \uc2dc\uc5d0 \uc120\ud0dd\ud55c \uc694\uc18c\ub4e4\uc5d0 \ub530\ub77c \uae30\uc874\uc758 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e8\uc5b4\uc758 \ucd9c\ud604 \ube48\ub3c4\uac00 \ub192\uc558\ub358 \ub2e8\uc5b4\ub97c \ucd94\ucc9c\ud558\uae30 \uc704\ud568\uc785\ub2c8\ub2e4.\n\n\ub530\ub77c\uc11c group \ubcc4\ub85c \ub2e8\uc5b4\uc758 \ube48\ub3c4\ub97c \ud655\uc778\ud558\uace0 wordcloud\ub97c \uadf8\ub9ac\ub824\uace0 \ud569\ub2c8\ub2e4.\n\n\uc774\ub97c \uc704\ud574\uc11c \uc18c\uadf8\ub8f9 \ub2e8\uc704\ub85c \ub098\ub220 \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \ub9cc\ub4e0 \ub2e4\uc74c, analysis notebook\uacfc analysis(2) notebook\uc5d0\uc11c \uc9c4\ud589\ud55c \ubd80\ubd84\uc744 \ub2e4\uc2dc \uc9c4\ud589\ud574\uc57c \ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.","31bd27d3":"\uc704\uc640 \uac19\uc740 \ubc29\uc2dd\uc73c\ub85c \uc791\uc740 \uc9c0\uc5ed group\uc758 list\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n* \ud070 \uc9c0\uc5ed group : Bronx, Brooklyn, Manhattan, Queens, Staten Island ","d202c5f3":"df2\uc5d0\uc11c\ub294\n* price : 78\uc774\ub0b4(34%) 139\uc774\ub0b4(33%; 67%) 139\uc774\uc0c1(33%)\n* review_scores_rating : 94\uc774\ub0b4(34%) 98\uc774\ub0b4(28%; 62%) 98\uc774\uc0c1(38%)","3025888b":"* df1 : 143\n* df2 : 143\n* df1ch : 142\n* df2ch : 143\n* dfad : 132\n* dfdr : 138","b0db310e":"dfad\ub294 1~132\n\n\uc544\ub798\ub294 dfdr\uc785\ub2c8\ub2e4.","cc0265ef":"dfdr\uc740 1~138","69f420cc":"# Word Count"}}