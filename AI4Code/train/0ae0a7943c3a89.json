{"cell_type":{"b17d7798":"code","fccf388a":"code","5ebd4eab":"code","f9b567be":"code","dc4ab053":"code","ef74d019":"code","099e6ac0":"code","c6e2dfa4":"code","93c637bb":"code","cfb7f0b0":"code","b0e5ca3b":"code","780b4954":"code","30f7c3d7":"code","139f244b":"code","c92054e1":"code","875f6e75":"code","bc6ee854":"code","08866faf":"code","2f96e52e":"code","6a354772":"code","9889f2a7":"code","5d71d1b8":"code","babfd722":"code","cd3c614b":"code","3b2c40ef":"code","0c610055":"code","97f66004":"code","517d7cb2":"code","c85b5527":"code","0ca68cde":"code","2547db95":"code","87233181":"code","6dea17e8":"code","8e86c4a5":"code","995e6d96":"code","02e4a1d1":"code","4a72ec9f":"code","a1413663":"code","062b524e":"code","766e0496":"code","2452ec6c":"code","c2575f01":"code","8de944a7":"code","3f6e7733":"code","d3e5ff27":"code","b63e56a5":"code","94d5501a":"code","3d2258b9":"code","063dc52e":"code","e15f0b70":"code","e25d1817":"code","129b982a":"code","905c1737":"code","d9f6829a":"code","111a67a0":"code","cfd0c4ab":"code","a83685dd":"code","b0985644":"code","290c33ec":"code","8e66d699":"code","365f4e49":"markdown","49117bf5":"markdown","e7f2ae17":"markdown","61619d6f":"markdown","d4a7ccf5":"markdown","496e430c":"markdown","063f1469":"markdown","76f9a6ad":"markdown","3e110bde":"markdown","16b63472":"markdown","645aafbc":"markdown","092b0fd4":"markdown","604b0e2d":"markdown","5c08df99":"markdown","e4524df6":"markdown","f100df2e":"markdown","907d5b1a":"markdown"},"source":{"b17d7798":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport os\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","fccf388a":"# reading the dataset\ncars = pd.read_csv(r'\/kaggle\/input\/car-price\/CarPrice_Assignment.csv')\n","5ebd4eab":"# summary of the dataset: 205 rows, 26 columns, no null values\nprint(cars.info())","f9b567be":"# head\ncars.head()","dc4ab053":"# symboling: -2 (least risky) to +3 most risky\n# Most cars are 0,1,2\ncars['symboling'].astype('category').value_counts()\n\n","ef74d019":"# aspiration: An (internal combustion) engine property showing \n# whether the oxygen intake is through standard (atmospheric pressure)\n# or through turbocharging (pressurised oxygen intake)\n\ncars['aspiration'].astype('category').value_counts()","099e6ac0":"# drivewheel: frontwheel, rarewheel or four-wheel drive \ncars['drivewheel'].astype('category').value_counts()","c6e2dfa4":"# wheelbase: distance between centre of front and rarewheels\nplt.figure(figsize=(20,5))\nsns.distplot(cars['wheelbase'])\nplt.show()","93c637bb":"# curbweight: weight of car without occupants or baggage\nplt.figure(figsize=(20,5))\nsns.distplot(cars['curbweight'])\nplt.show()","cfb7f0b0":"# stroke: volume of the engine (the distance traveled by the piston in each cycle)\nplt.figure(figsize=(20,5))\nsns.distplot(cars['stroke'])\nplt.show()","b0e5ca3b":"# compression ration: ratio of volume of compression chamber at largest capacity to least capacity\nplt.figure(figsize=(20,5))\nsns.distplot(cars['compressionratio'])\nplt.show()","780b4954":"# target variable: price of car\nplt.figure(figsize=(20,5))\nsns.distplot(cars['price'])\nplt.show()","30f7c3d7":"# all numeric (float and int) variables in the dataset\ncars_numeric = cars.select_dtypes(include=['float', 'int'])\ncars_numeric.head()","139f244b":"# dropping symboling and car_ID \ncars_numeric = cars_numeric.drop(['symboling','car_ID'], axis=1)\ncars_numeric.head()","c92054e1":"#paiwise scatter plot\nsns.pairplot(cars_numeric)\nplt.show()","875f6e75":"# correlation matrix\ncor = cars_numeric.corr()\ncor","bc6ee854":"# plotting correlations on a heatmap\n\n# figure size\nplt.figure(figsize=(16,8))\n\n# heatmap\nsns.heatmap(cor, cmap=\"rainbow\", annot=True)\nplt.show()\n","08866faf":"# variable formats\ncars.info()","2f96e52e":"# converting symboling to categorical\ncars['symboling'] = cars['symboling'].astype('object')\ncars.info()","6a354772":"# CarName: first few entries\ncars['CarName'][:30]","9889f2a7":"# Extracting carname\n\n#str.split() by space\ncarnames = cars['CarName'].apply(lambda x: x.split(\" \")[0])\ncarnames[:30]","5d71d1b8":"import re\n\n# regex: any alphanumeric sequence before a space, may contain a hyphen\np = re.compile(r'\\w+-?\\w+')\ncarnames = cars['CarName'].apply(lambda x: re.findall(p, x)[0])\nprint(carnames)","babfd722":"# New column car_company\ncars['car_company'] = cars['CarName'].apply(lambda x: re.findall(p, x)[0])","cd3c614b":"# look at all values \ncars['car_company'].astype('category').value_counts()","3b2c40ef":"# replacing misspelled car_company names\n\n# volkswagen\ncars.loc[(cars['car_company'] == \"vw\") | \n         (cars['car_company'] == \"vokswagen\")\n         , 'car_company'] = 'volkswagen'\n\n# porsche\ncars.loc[cars['car_company'] == \"porcshce\", 'car_company'] = 'porsche'\n\n# toyota\ncars.loc[cars['car_company'] == \"toyouta\", 'car_company'] = 'toyota'\n\n# nissan\ncars.loc[cars['car_company'] == \"Nissan\", 'car_company'] = 'nissan'\n\n# mazda\ncars.loc[cars['car_company'] == \"maxda\", 'car_company'] = 'mazda'","0c610055":"cars['car_company'].astype('category').value_counts()","97f66004":"# drop carname variable\ncars = cars.drop('CarName', axis=1)","517d7cb2":"cars.info()","c85b5527":"# outliers\ncars.describe()","0ca68cde":"cars.info()","2547db95":"# split into X and y\nX = cars.loc[:, ['symboling', 'fueltype', 'aspiration', 'doornumber',\n       'carbody', 'drivewheel', 'enginelocation', 'wheelbase', 'carlength',\n       'carwidth', 'carheight', 'curbweight', 'enginetype', 'cylindernumber',\n       'enginesize', 'fuelsystem', 'boreratio', 'stroke', 'compressionratio',\n       'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n       'car_company']]\n\ny = cars['price']\n","87233181":"# creating dummy variables for categorical variables\n\n# subset all categorical variables\ncars_categorical = X.select_dtypes(include=['object'])\ncars_categorical.head()\n","6dea17e8":"# convert into dummies\ncars_dummies = pd.get_dummies(cars_categorical, drop_first=True)\ncars_dummies.head()","8e86c4a5":"# drop categorical variables \nX = X.drop(list(cars_categorical.columns), axis=1)","995e6d96":"# concat dummy variables with X\nX = pd.concat([X, cars_dummies], axis=1)","02e4a1d1":"# split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)","4a72ec9f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']]=scaler.fit_transform(X_train[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']])\nX_train.head()","a1413663":"X_test[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']]=scaler.transform(X_test[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']])\nX_test.head()","062b524e":"# list of alphas to tune\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\n\nridge = Ridge()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train, y_train) ","766e0496":"cv_results = pd.DataFrame(model_cv.cv_results_)\n\ncv_results.head()","2452ec6c":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('int')\n\n# plotting\nplt.figure(figsize=(20,10))\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.grid()\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","c2575f01":"cv_results = cv_results[cv_results['param_alpha']<=200]","8de944a7":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('int')\n\n# plotting\nplt.figure(figsize=(20,10))\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.grid()\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","3f6e7733":"alpha = 15\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_","d3e5ff27":"imp_ridge = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Coefficient\": ridge.coef_})\nimp_ridge.sort_values(by=\"Coefficient\", ascending=False)","b63e56a5":"imp_ridge=imp_ridge.drop([imp_ridge.index[56], imp_ridge.index[43],imp_ridge.index[46]])\nimp_ridge.sort_values(by=\"Coefficient\", ascending=False)","94d5501a":"y_pred = ridge.predict(X_test)","3d2258b9":"fig = plt.figure(figsize=(20,10))\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16) \nplt.show()","063dc52e":"df= pd.DataFrame({'Actual':y_test,'Predictions':y_pred})\ndf['Predictions']= round(df['Predictions'],2)\ndf.head()","e15f0b70":"from sklearn import metrics ","e25d1817":"metrics.explained_variance_score(y_test,y_pred)","129b982a":"metrics.mean_absolute_error(y_test,y_pred)","905c1737":"metrics.max_error(y_test,y_pred)","d9f6829a":"metrics.mean_squared_error(y_test,y_pred)","111a67a0":"metrics.mean_squared_log_error(y_test,y_pred)","cfd0c4ab":"metrics.median_absolute_error(y_test,y_pred)","a83685dd":"metrics.r2_score(y_test,y_pred)","b0985644":"metrics.mean_poisson_deviance(y_test,y_pred)","290c33ec":"metrics.mean_gamma_deviance(y_test,y_pred)","8e66d699":"metrics.mean_tweedie_deviance(y_test,y_pred)","365f4e49":"Notice that **some car-company names are misspelled** - vw and vokswagen should be volkswagen, porcshce should be porsche, toyouta should be toyota, Nissan should be nissan, maxda should be mazda etc.\n\nThis is a data quality issue, let's solve it.","49117bf5":"Let's now make a pairwise scatter plot and observe linear relationships.","e7f2ae17":"## Model Building and Evaluation","61619d6f":"The ```car_company``` variable looks okay now. Let's now drop the car name variable.","d4a7ccf5":"Let's create a new column to store the company name and check whether it looks okay.","496e430c":"This is quite hard to read, and we can rather plot correlations between variables. Also, a heatmap is pretty useful to visualise multiple correlations in one plot.","063f1469":"Notice that the carname is what occurs before a space, e.g. alfa-romero, audi, chevrolet, dodge, bmx etc.\n\nThus, we need to simply extract the string before a space. There are multiple ways to do that.\n\n\n","76f9a6ad":"#### Understanding the Data Dictionary\n\nThe data dictionary contains the meaning of various attributes; some non-obvious ones are:","3e110bde":"## Data Preparation \n\n\n#### Data Preparation\n\nLet's now prepare the data and build the model.","16b63472":"## Data Cleaning\n\nLet's now conduct some data cleaning steps. \n\nWe've seen that there are no missing values in the dataset. We've also seen that variables are in the correct format, except ```symboling```, which should rather be a categorical variable (so that dummy variable are created for the categories).\n\nNote that it *can* be used in the model as a numeric variable also. \n\n","645aafbc":"### Data Understanding and Exploration\n\nLet's first have a look at the dataset and understand the size, attribute names etc.","092b0fd4":"## Ridge Regression","604b0e2d":"The heatmap shows some useful insights:\n\nCorrelation of price with independent variables:\n- Price is highly (positively) correlated with wheelbase, carlength, carwidth, curbweight, enginesize, horsepower (notice how all of these variables represent the size\/weight\/engine power of the car)\n\n- Price is negatively correlated to ```citympg``` and ```highwaympg``` (-0.70 approximately). This suggest that cars having high mileage may fall in the 'economy' cars category, and are priced lower (think Maruti Alto\/Swift type of cars, which are designed to be affordable by the middle class, who value mileage more than horsepower\/size of car etc.)\n\nCorrelation among independent variables:\n- Many independent variables are highly correlated (look at the top-left part of matrix): wheelbase, carlength, curbweight, enginesize etc. are all measures of 'size\/weight', and are positively correlated \n\n\nThus, while building the model, we'll have to pay attention to multicollinearity (especially linear models, such as linear and logistic regression, suffer more from multicollinearity).","5c08df99":"Netx, we need to extract the company name from the column ```CarName```. ","e4524df6":"#### Data Exploration\n\nTo perform linear regression, the (numeric) target variable should be linearly related to *at least one another numeric variable*. Let's see whether that's true in this case.\n\n\nWe'll first subset the list of all (independent) numeric variables, and then make a **pairwise plot**.","f100df2e":"Here, although the variable ```symboling``` is numeric (int), we'd rather treat it as categorical since it has only 6 discrete values. Also, we do not want 'car_ID'.","907d5b1a":"## Car Price Prediction \n\nThe solution is divided into the following sections: \n- Data understanding and exploration\n- Data cleaning\n- Data preparation\n- Model building and evaluation\n"}}