{"cell_type":{"2f90b0b9":"code","75524371":"code","aa47166d":"code","9518383c":"code","dde56ea0":"code","5317fbf0":"code","cc124656":"code","e4665ad0":"code","d98d99aa":"code","4bb09c19":"code","54248c6e":"code","1e252ca8":"code","c3c6316b":"code","87599312":"code","2e8d323f":"code","1827c396":"code","5d4f4754":"code","bbd4bf63":"code","13e31c7c":"code","3889d5de":"code","09797d4d":"code","64ba2835":"code","7f7cfe3d":"code","cbd51608":"code","bfccbee9":"code","f62e9ee4":"code","0852985b":"code","e9314deb":"code","bf67ec0b":"code","8d3235e8":"code","5e09274d":"code","35c10975":"code","2ee5e4d0":"code","6fea7389":"code","91bf7cc7":"code","f0ed9723":"code","fbeaa5b8":"code","b9be0b85":"code","837fc19c":"code","62736d17":"code","2c1fc990":"code","89f176cc":"code","1b343478":"code","717c7018":"code","b76ce493":"code","d04d4628":"code","35576438":"code","3b45c0e6":"code","ca2654ec":"code","7307a809":"code","f13ad56a":"code","81fb184b":"code","3b30dd50":"code","5efd8908":"code","e3d902f3":"code","1bf22d76":"code","0cea7d8c":"code","87a39364":"code","a949d284":"code","c22c2e04":"code","319650ef":"code","81799934":"code","ed4eeee2":"code","160f16e7":"code","761b6929":"code","063404c7":"code","32186895":"code","5326df77":"code","9763ef61":"code","c9cef766":"code","348d3596":"code","c820a384":"code","d3eaa0b2":"code","045064fc":"code","fbd1fcff":"code","e21e02da":"code","feb3f52a":"code","ab878aa1":"code","451ad727":"code","67244513":"code","556a2fd3":"code","aefb466c":"code","99a0b052":"code","2fdb14be":"code","da4b0b17":"code","024e8749":"code","0224a96d":"code","ef2d4831":"code","98092a6c":"code","7c09d658":"code","65910e81":"code","6cfeaaaf":"code","19784509":"code","90326916":"code","b8e48ab6":"code","9469d8a9":"code","c668f68c":"code","093186cf":"code","9be59cc7":"code","ada84e77":"code","e73d7467":"code","040678aa":"code","1c9ddb15":"code","9acbb34a":"code","2b2979eb":"code","86ac4649":"code","57ef6445":"code","7fe5f657":"markdown","4d8f40ec":"markdown","cc0f55ad":"markdown","76a3be93":"markdown","bbbdbd0d":"markdown","6832c8a0":"markdown","e934a387":"markdown","56f3dea4":"markdown","24a0868f":"markdown","1d43595e":"markdown","0bdeac19":"markdown","781eb435":"markdown","a2ef87aa":"markdown","2029bff7":"markdown"},"source":{"2f90b0b9":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","75524371":"df=pd.read_csv('..\/input\/titanic\/train.csv')\ntype(df)","aa47166d":"df.info()","9518383c":"df.describe()","dde56ea0":"df.head(10)","5317fbf0":"#checking for null values\ndf.isnull()","cc124656":"#missing values\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()\/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","e4665ad0":"#heat map to show which features contain missing values\nsns.heatmap(df.isnull(),cmap=\"YlGnBu\",yticklabels=False)","d98d99aa":"#pie chart visualization whether person survived or not \nTotalPassengers=df['Survived'].value_counts().to_dict()\nsurvived=TotalPassengers[1]\ndidNotSurvive=TotalPassengers[0]\nlabels=['Survived','Did Not Survive']\nsizes=[survived,didNotSurvive]\nfig1,ax1=plt.subplots()\nax1.pie(sizes,labels=labels,shadow=True,startangle=90,autopct='%1.1f%%',colors=['tab:blue','tab:orange'])\nax1.axis('equal')\nax1.title.set_text('Survivors Pie Chart')\nplt.show()","4bb09c19":"#list differnt columns\ndf.columns.values","54248c6e":"#data visualization based on age and gender\nsurvived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nwomen = df[df['Sex']=='female']\nmen = df[df['Sex']=='male']\nax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\nax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\nax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\nax.legend()\n_ = ax.set_title('Male')","1e252ca8":"#survived vs not survived figure\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',data=df,palette=\"rainbow\")","c3c6316b":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',palette='rainbow',data=df)","87599312":"#survivors according to Pclass\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',palette='rainbow',data=df) ","2e8d323f":"sns.barplot(x='Pclass', y='Survived', data=df)","1827c396":"sns.distplot(df.Pclass)","5d4f4754":"sns.countplot(x='SibSp',data=df)","bbd4bf63":"#plot shows ages of different Pcalss who survived\nplt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=df,palette='winter')\nsns.swarmplot(x=\"Pclass\", y=\"Age\", data=df, color=\".25\")","13e31c7c":"df.head()","3889d5de":"df['Cabin'].unique()","09797d4d":"#filling the age missing data\ndata = [df]\n\nfor dataset in data:\n    mean = df[\"Age\"].mean()\n    std = df[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = df[\"Age\"].astype(int)\ndf[\"Age\"].isnull().sum()","64ba2835":"df['Embarked'].describe()","7f7cfe3d":"#fill Embarked missing data with s as it is the most common one\ndf['Embarked']=df['Embarked'].fillna('S')","cbd51608":"df","bfccbee9":"total = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()\/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","f62e9ee4":"#dropping these features\ndf=df.drop(['PassengerId','Cabin','Ticket'],axis=1)","0852985b":"df","e9314deb":"#encoding \ngenders = {\"male\": 0, \"female\": 1}\ndf['Sex'] = df['Sex'].map(genders)","bf67ec0b":"df","8d3235e8":"#encoding\nports = {\"S\": 0, \"C\": 1, \"Q\": 2}\ndf['Embarked']=df['Embarked'].map(ports)","5e09274d":"df","35c10975":"df['Fare'].astype(int)","2ee5e4d0":"df","6fea7389":"data = [df]\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"HighClass\": 5}\n\nfor dataset in data:\n    # extract titles\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    # replace titles with a more common title or as Rare\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'HighClass')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # convert titles into numbers\n    dataset['Title'] = dataset['Title'].map(titles)\n    # filling NaN with 0, to get safe\n    dataset['Title'] = dataset['Title'].fillna(0)\ndf = df.drop(['Name'], axis=1)\n","91bf7cc7":"df","f0ed9723":"#Function for plotting confusion matrix\n\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    #plt.figure(figsize=[10,10])\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 verticalalignment=\"center\",\n                 color=\"blue\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","fbeaa5b8":"# FUNCTION TO CALCULATE TRUE POSITIVE, TRUE NEGATIVE ,FALSE POSITIVE AND FALSE NEGATIVE \n\ndef perf_measure(y_actual, y_hat):\n    y_actual=np.array(y_actual)\n    y_hat=np.array(y_hat)\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i] and y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)","b9be0b85":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score","837fc19c":"X_train=df.drop(['Survived'],axis=1)\ny_train=df['Survived']","62736d17":"clf_lr= LogisticRegression(solver='liblinear', penalty='l1')\nclf_lr.fit(X_train, y_train)\npred_lr=clf_lr.predict(X_train)","2c1fc990":"clf_lr.score(X_train,y_train)","89f176cc":"print(classification_report(y_train,pred_lr))","1b343478":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_lr=confusion_matrix(y_train,pred_lr)\n#print(cnf_matrix_lr)\nplot_confusion_matrix(cnf_matrix_lr,[0,1],normalize=False,title=\"Confusion Matrix\")","717c7018":"# PLOTTING AUC-ROC CURVE\n\nprobs_lr= clf_lr.predict_proba(X_train)\nprobs_lr=probs_lr[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_lr)\nplt.title(\"AUC-ROC curve--LR\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","b76ce493":"clf_mnb=MultinomialNB(alpha=0.2)\n\nclf_mnb.fit(X_train,y_train)\npred_mnb=clf_mnb.predict(X_train)\nacc_mnb=clf_mnb.score(X_train,y_train)\n\n#acc=accuracy_score(y_test,pred)\nprint(\"Accuracy : \",acc_mnb)","d04d4628":"print(classification_report(y_train,pred_mnb))","35576438":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_mnb=confusion_matrix(y_train,pred_mnb)\n#print(cnf_matrix_mnb)\nplot_confusion_matrix(cnf_matrix_mnb,[0,1],normalize=False,title=\"Confusion Matrix\")","3b45c0e6":"# PLOTTING AUC-ROC CURVE\n\nprobs_mnb= clf_mnb.predict_proba(X_train)\nprobs_mnb=probs_mnb[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_mnb)\nplt.title(\"AUC-ROC curve--MNB\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","ca2654ec":"clf_knn= KNeighborsClassifier(n_neighbors=49)\nclf_knn.fit(X_train,y_train)\n\npred_knn=clf_knn.predict(X_train)\nacc_knn=clf_knn.score(X_train,y_train)\n\nprint(\"Accuracy : \",acc_knn)","7307a809":"print(classification_report(y_train,pred_knn))","f13ad56a":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_knn=confusion_matrix(y_train,pred_knn)\n#print(cnf_matrix_knn)\nplot_confusion_matrix(cnf_matrix_knn,[0,1],normalize=False,title=\"Confusion Matrix\")","81fb184b":"# PLOTTING AUC-ROC CURVE\n\nprobs_knn= clf_knn.predict_proba(X_train)\nprobs_knn=probs_knn[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_knn)\nplt.title(\"AUC-ROC curve--KNN\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","3b30dd50":"clf_svm = svm.SVC(kernel='rbf',probability=True)\n\nclf_svm.fit(X_train,y_train)\npred_svm=clf_svm.predict(X_train)\nacc_svm=clf_svm.score(X_train,y_train)\n\nprint(\"Accuracy : \",acc_svm)","5efd8908":"print(classification_report(y_train,pred_svm))","e3d902f3":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_svm=confusion_matrix(y_train,pred_svm)\n#print(cnf_matrix_svm)\nplot_confusion_matrix(cnf_matrix_svm,[0,1],normalize=False,title=\"Confusion Matrix\")","1bf22d76":"# PLOTTING AUC-ROC CURVE\n\nprobs_svm= clf_svm.predict_proba(X_train)\nprobs_svm=probs_svm[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_svm)\nplt.title(\"AUC-ROC curve--SVM\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","0cea7d8c":"clf_dtc=DecisionTreeClassifier(random_state=0)\n\nclf_dtc.fit(X_train,y_train)\npred_dtc=clf_dtc.predict(X_train)\nacc_dtc=clf_dtc.score(X_train,y_train)\n\nprint(\"Accuracy : \",acc_dtc)","87a39364":"print(classification_report(y_train,pred_dtc))","a949d284":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_dtc=confusion_matrix(y_train,pred_dtc)\n#print(cnf_matrix_dtc)\nplot_confusion_matrix(cnf_matrix_dtc,[0,1],normalize=False,title=\"Confusion Matrix\")","c22c2e04":"# PLOTTING AUC-ROC CURVE\n\nprobs_dtc= clf_dtc.predict_proba(X_train)\nprobs_dtc=probs_dtc[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_dtc)\nplt.title(\"AUC-ROC curve--DTC\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","319650ef":"clf_rf= RandomForestClassifier(n_estimators=31, random_state=111)\n\nclf_rf.fit(X_train,y_train)\npred_rf=clf_rf.predict(X_train)\nacc_rf=clf_rf.score(X_train,y_train)\n\nprint(\"Accuracy : \",acc_rf)","81799934":"print(classification_report(y_train,pred_rf))","ed4eeee2":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_rf=confusion_matrix(y_train,pred_rf)\n#print(cnf_matrix_rf)\nplot_confusion_matrix(cnf_matrix_rf,[0,1],normalize=False,title=\"Confusion Matrix\")","160f16e7":"# PLOTTING AUC-ROC CURVE\n\nprobs_rf= clf_rf.predict_proba(X_train)\nprobs_rf=probs_rf[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_rf)\n\nplt.title(\"AUC-ROC curve--RandomForest\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","761b6929":"from keras import models\nfrom keras.layers import Dense","063404c7":"model=models.Sequential()\nmodel.add(Dense(32,activation='relu',input_shape=(X_train.shape[1],)))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))","32186895":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])","5326df77":"hist=model.fit(X_train,y_train,batch_size=32,epochs=200)","9763ef61":"pred_mlp=model.predict(X_train)\npred_mlp[pred_mlp>=0.5]=1\npred_mlp[pred_mlp<0.5]=0\nprint(pred_mlp)","c9cef766":"acc_mlp=accuracy_score(pred_mlp,y_train)\nprint(acc_mlp)","348d3596":"print(classification_report(y_train,pred_mlp))","c820a384":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_mlp=confusion_matrix(y_train,pred_mlp)\n#print(cnf_matrix_mlp)\nplot_confusion_matrix(cnf_matrix_mlp,[0,1],normalize=False,title=\"Confusion Matrix\")","d3eaa0b2":"# PLOTTING AUC-ROC CURVE\n\nprobs_mlp= model.predict_proba(X_train)\nfpr, tpr, thresholds = metrics.roc_curve(y_train,probs_mlp)\nplt.title(\"AUC-ROC curve--MLP\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","045064fc":"classifiers=[]\n\nclassifiers.append(('LogisticRegression',clf_lr))\nclassifiers.append(('MNB',clf_mnb))\nclassifiers.append(('KNN',clf_knn))\nclassifiers.append(('SVM',clf_svm))\nclassifiers.append(('Desicion Tree',clf_dtc))\nclassifiers.append(('Random Forest',clf_rf))\nclassifiers.append(('MLP',model))","fbd1fcff":"result=[]\ncnf_matric_parameter=[]\nfor i,v in classifiers:\n    if i=='MLP':\n        pred=v.predict(X_train)\n        pred[pred>=0.5]=1\n        pred[pred<0.5]=0\n        #print(pred)\n        acc=accuracy_score(y_train,pred)\n        precision = precision_score(y_train,pred)\n        recall=recall_score(y_train, pred)\n        f_measure=f1_score(y_train,pred)\n        result.append((i,acc,precision,recall,f_measure))\n        \n        TP,FP,TN,FN=perf_measure(y_train,pred)\n        cnf_matric_parameter.append((i,TP,FP,TN,FN))\n        continue\n        \n    \n    pred=v.predict(X_train)\n    acc=accuracy_score(y_train,pred)\n    precision = precision_score(y_train,pred)\n    recall=recall_score(y_train, pred)\n    #print(precision)\n    f_measure=f1_score(y_train,pred)\n    result.append((i,acc,precision,recall,f_measure))\n    \n    TP,FP,TN,FN=perf_measure(y_train,pred)\n    cnf_matric_parameter.append((i,TP,FP,TN,FN))","e21e02da":"column_names=['Algorithm','Accuracy','Precision','Recall','F-measure']\ndf1=pd.DataFrame(result,columns=column_names)\nprint(df1)","feb3f52a":"df1.plot(kind='bar', ylim=(0.65,1.0), figsize=(15,6), align='center', colormap=\"Accent\")\nplt.xticks(np.arange(8), df1['Algorithm'],fontsize=15)\nplt.ylabel('Score',fontsize=20)\nplt.title('Distribution by Classifier',fontsize=20)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,fontsize=20)","ab878aa1":"test_df=pd.read_csv('..\/input\/titanic\/test.csv')","451ad727":"test_df","67244513":"test_df.describe()","556a2fd3":"total = test_df.isnull().sum().sort_values(ascending=False)\npercent_1 = test_df.isnull().sum()\/test_df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","aefb466c":"data = [test_df]\n\nfor dataset in data:\n    mean = df[\"Age\"].mean()\n    std = df[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = df[\"Age\"].astype(int)\ndf[\"Age\"].isnull().sum()","99a0b052":"test_df=test_df.drop(['PassengerId','Cabin','Ticket'],axis=1)","2fdb14be":"genders = {\"male\": 0, \"female\": 1}\ntest_df['Sex'] = test_df['Sex'].map(genders)","da4b0b17":"ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\ntest_df['Embarked']=test_df['Embarked'].map(ports)","024e8749":"test_df['Fare'].describe()","0224a96d":"test_df['Fare']=test_df['Fare'].fillna(test_df['Fare'].mean())","ef2d4831":"test_df['Fare'].astype(int)","98092a6c":"data = [test_df]\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"HighClass\": 5}\n\nfor dataset in data:\n    # extract titles\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    # replace titles with a more common title or as Rare\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'HighClass')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # convert titles into numbers\n    dataset['Title'] = dataset['Title'].map(titles)\n    # filling NaN with 0, to get safe\n    dataset['Title'] = dataset['Title'].fillna(0)\ntest_df = test_df.drop(['Name'], axis=1)\n","7c09d658":"total = test_df.isnull().sum().sort_values(ascending=False)\npercent_1 = test_df.isnull().sum()\/test_df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","65910e81":"test_df.head(10)","6cfeaaaf":"X_test=test_df","19784509":"X_test.shape[0]","90326916":"pred_mlp=model.predict(X_test)\npred_mlp[pred_mlp>=0.5]=1\npred_mlp[pred_mlp<0.5]=0\npred_mlp.shape","b8e48ab6":"\npred_mlp=pred_mlp.flatten()","9469d8a9":"pred_mlp.shape","c668f68c":"results=[]","093186cf":"for i in range(418):\n    results.append(int(pred_mlp[i]))","9be59cc7":"len(results)","ada84e77":"results=[int(x) for x in results]","e73d7467":"len(results)","040678aa":"result=pd.Series(results,name=\"Survived\")\nresult.shape","1c9ddb15":"submission=pd.concat([pd.Series(range(892,418+892),name=\"PassengerId\"),result],axis=1)","9acbb34a":"submission","2b2979eb":"submission.to_csv('my_submissions',index=False)","86ac4649":"my_sub=pd.read_csv('my_submissions')","57ef6445":"my_sub","7fe5f657":"# Logistic Regression","4d8f40ec":"# SVM","cc0f55ad":"# Importing Libraries\n","76a3be93":"# Random Forest","bbbdbd0d":"# Loading Testing data","6832c8a0":"# DTC","e934a387":"# KNN","56f3dea4":"# Importing classifiers using sklearn","24a0868f":"# Getting the Data\n","1d43595e":"# comparison between different algorithms","0bdeac19":"# Preprocessing","781eb435":"# MNB","a2ef87aa":"# MLP","2029bff7":"# Data Analysis"}}