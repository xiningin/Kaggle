{"cell_type":{"febb3478":"code","3dbc46ba":"code","a9b8a1cc":"code","c6b3063b":"code","6182f6bc":"code","40dc1f79":"code","fdf6a856":"code","4e805971":"code","cdbe5813":"code","e7c8262a":"code","b07dbaa9":"code","43503d55":"code","e7c8525d":"code","198ad3e2":"code","ea11e676":"code","adcb10dc":"code","20abc215":"code","f8a5d5ca":"code","a7c52479":"code","2445ad95":"code","3e0bd4a8":"code","0946524a":"code","3b12ac24":"code","9aca761c":"code","9e95b25a":"code","b17b306c":"code","461806eb":"code","03db90b9":"code","64a5c39f":"code","1f6d81c8":"code","c948b814":"code","7911fb7c":"code","df3adff6":"code","fb40af3e":"code","7e32973b":"code","e8914d1f":"code","36540294":"code","c2768ad6":"code","2d011aed":"code","be6ba0bc":"code","0afdff4e":"code","1e8791c8":"code","a352fa90":"code","ee153f10":"code","0800dfc3":"code","2b39de27":"code","b0620e87":"code","fcd689c5":"code","75239c50":"code","7f5717ab":"code","5e1d9d93":"code","b7e72890":"code","36086532":"code","f8db470d":"code","1a9cdbf9":"code","fee4f4a2":"code","ded76248":"code","21e05776":"code","a300239c":"code","2bbc3182":"code","68d527ff":"code","0361aa40":"code","c9518fe5":"markdown","ef5a48fb":"markdown","3352e796":"markdown","fbd83457":"markdown","d30faebe":"markdown","a422b28f":"markdown","6e07463f":"markdown","8794d9b2":"markdown","26a90461":"markdown","115f9fb6":"markdown","177a6013":"markdown","49a54450":"markdown","d178ba5b":"markdown","62f38c7a":"markdown","6037551d":"markdown","12f542fa":"markdown","70e0987a":"markdown","2547d159":"markdown","5df77269":"markdown","60cb15e3":"markdown","a5ec21e1":"markdown","4df79fcd":"markdown","f2157e40":"markdown","4ccd1ce5":"markdown","e3c4595e":"markdown"},"source":{"febb3478":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport skimage\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, ReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras.regularizers import l1,l2,L1L2\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","3dbc46ba":"Black_Box_Attack_Type_Main_Path = Path(\"..\/input\/black-box-attack\/IMG_PMU_DATA_NT_VF_001\")","a9b8a1cc":"Attack_Path = list(Black_Box_Attack_Type_Main_Path.glob(r\"*\/*.jpg\"))","c6b3063b":"Attack_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Attack_Path))","6182f6bc":"Attack_Path_Series = pd.Series(Attack_Path,name=\"JPG\").astype(str)\nAttack_Labels_Series = pd.Series(Attack_Labels,name=\"TYPE\")","40dc1f79":"Main_Attack_Data = pd.concat([Attack_Path_Series,Attack_Labels_Series],axis=1)","fdf6a856":"print(Main_Attack_Data.head(-1))","4e805971":"print(Main_Attack_Data[\"TYPE\"].value_counts())","cdbe5813":"Main_Attack_Data = Main_Attack_Data.sample(frac=1).reset_index()","e7c8262a":"print(Main_Attack_Data.head(-1))","b07dbaa9":"plt.style.use(\"dark_background\")","43503d55":"Main_Attack_Data[\"TYPE\"].hist(figsize=(15,8))\nplt.show()","e7c8525d":"Main_Attack_Data[\"TYPE\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,figsize=(15,8))\nplt.show()","198ad3e2":"Example_IMG = Main_Attack_Data[\"JPG\"][32]\nReading_IMG = cv2.imread(Example_IMG)\nTransformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_IMG.shape)\nplt.ylabel(Transformation_IMG.size)\nplt.title(Main_Attack_Data[\"TYPE\"][32])\n\nplt.imshow(Transformation_IMG)","ea11e676":"Example_IMG = Main_Attack_Data[\"JPG\"][3]\nReading_IMG = cv2.imread(Example_IMG)\nTransformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_IMG.shape)\nplt.ylabel(Transformation_IMG.size)\nplt.title(Main_Attack_Data[\"TYPE\"][3])\n\nplt.imshow(Transformation_IMG)","adcb10dc":"figure,axis = plt.subplots(5,5,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(Main_Attack_Data[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    \n    operating.set_xlabel(Transformation_IMG.shape)\n    operating.set_ylabel(Transformation_IMG.size)\n    operating.set_title(Main_Attack_Data[\"TYPE\"][indexing])\n    operating.imshow(Transformation_IMG)\n    \nplt.tight_layout()\nplt.show()\n    ","20abc215":"DB_FLT_DATA = Main_Attack_Data[Main_Attack_Data[\"TYPE\"] == \"DB_FLT\"]\nDB_GNL_DATA = Main_Attack_Data[Main_Attack_Data[\"TYPE\"] == \"DB_GNL\"]\nDB_SMS_DATA = Main_Attack_Data[Main_Attack_Data[\"TYPE\"] == \"DB_SMS\"]\n\nDB_FLT_DATA = DB_FLT_DATA.reset_index()\nDB_GNL_DATA = DB_GNL_DATA.reset_index()\nDB_SMS_DATA = DB_SMS_DATA.reset_index()","f8a5d5ca":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_FLT_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    \n    operating.set_xlabel(Transformation_IMG.shape)\n    operating.set_ylabel(Transformation_IMG.size)\n    operating.set_title(DB_FLT_DATA[\"TYPE\"][indexing])\n    operating.imshow(Transformation_IMG)\n    \nplt.tight_layout()\nplt.show()","a7c52479":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_GNL_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    \n    operating.set_xlabel(Transformation_IMG.shape)\n    operating.set_ylabel(Transformation_IMG.size)\n    operating.set_title(DB_GNL_DATA[\"TYPE\"][indexing])\n    operating.imshow(Transformation_IMG)\n    \nplt.tight_layout()\nplt.show()","2445ad95":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_SMS_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    \n    operating.set_xlabel(Transformation_IMG.shape)\n    operating.set_ylabel(Transformation_IMG.size)\n    operating.set_title(DB_SMS_DATA[\"TYPE\"][indexing])\n    operating.imshow(Transformation_IMG)\n    \nplt.tight_layout()\nplt.show()","3e0bd4a8":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_FLT_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    _,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n    \n    operating.set_xlabel(Threshold_IMG.shape)\n    operating.set_ylabel(Threshold_IMG.size)\n    operating.set_title(DB_FLT_DATA[\"TYPE\"][indexing])\n    operating.imshow(Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","0946524a":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_GNL_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    _,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n    \n    operating.set_xlabel(Threshold_IMG.shape)\n    operating.set_ylabel(Threshold_IMG.size)\n    operating.set_title(DB_GNL_DATA[\"TYPE\"][indexing])\n    operating.imshow(Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","3b12ac24":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_SMS_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n    _,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n    \n    operating.set_xlabel(Threshold_IMG.shape)\n    operating.set_ylabel(Threshold_IMG.size)\n    operating.set_title(DB_SMS_DATA[\"TYPE\"][indexing])\n    operating.imshow(Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","9aca761c":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_FLT_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n_,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Threshold_IMG)\naxis[1].set_xlabel(np.mean(Threshold_IMG))","9e95b25a":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_GNL_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n_,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Threshold_IMG)\naxis[1].set_xlabel(np.mean(Threshold_IMG))","b17b306c":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_SMS_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2RGB)\n_,Threshold_IMG = cv2.threshold(Transformation_IMG,200,255,cv2.THRESH_TOZERO)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Threshold_IMG)\naxis[1].set_xlabel(np.mean(Threshold_IMG))","461806eb":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_FLT_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\n    Adaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n    \n    operating.set_xlabel(Adaptive_Threshold_IMG.shape)\n    operating.set_ylabel(Adaptive_Threshold_IMG.size)\n    operating.set_title(DB_FLT_DATA[\"TYPE\"][indexing])\n    operating.imshow(Adaptive_Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","03db90b9":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_GNL_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\n    Adaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n    \n    operating.set_xlabel(Adaptive_Threshold_IMG.shape)\n    operating.set_ylabel(Adaptive_Threshold_IMG.size)\n    operating.set_title(DB_GNL_DATA[\"TYPE\"][indexing])\n    operating.imshow(Adaptive_Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","64a5c39f":"figure,axis = plt.subplots(3,3,figsize=(10,10))\n\nfor indexing,operating in enumerate(axis.flat):\n    \n    Picking_IMG = cv2.imread(DB_SMS_DATA[\"JPG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\n    Adaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n    \n    operating.set_xlabel(Adaptive_Threshold_IMG.shape)\n    operating.set_ylabel(Adaptive_Threshold_IMG.size)\n    operating.set_title(DB_SMS_DATA[\"TYPE\"][indexing])\n    operating.imshow(Adaptive_Threshold_IMG)\n    \nplt.tight_layout()\nplt.show()","1f6d81c8":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_FLT_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\nAdaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Adaptive_Threshold_IMG)\naxis[1].set_xlabel(np.mean(Adaptive_Threshold_IMG))","c948b814":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_GNL_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\nAdaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Adaptive_Threshold_IMG)\naxis[1].set_xlabel(np.mean(Adaptive_Threshold_IMG))","7911fb7c":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPicking_IMG = cv2.imread(DB_SMS_DATA[\"JPG\"][indexing])\nTransformation_IMG = cv2.cvtColor(Picking_IMG,cv2.COLOR_BGR2GRAY)\nAdaptive_Threshold_IMG = cv2.adaptiveThreshold(Transformation_IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n\naxis[0].imshow(Transformation_IMG)\naxis[0].set_xlabel(np.mean(Transformation_IMG))\naxis[1].imshow(Adaptive_Threshold_IMG)\naxis[1].set_xlabel(np.mean(Adaptive_Threshold_IMG))","df3adff6":"X_Train,X_Test = train_test_split(Main_Attack_Data,train_size=0.9,random_state=42,shuffle=True)","fb40af3e":"print(X_Train.shape)","7e32973b":"print(X_Test.shape)","e8914d1f":"Train_IMG_Generator = ImageDataGenerator(rescale=1.\/255,\n                                        shear_range=0.3,\n                                        zoom_range=0.3,\n                                        rotation_range=25,\n                                        brightness_range=[0.4,1.0],\n                                        horizontal_flip=True,\n                                        width_shift_range=0.3,\n                                        height_shift_range=0.3,\n                                        validation_split=0.1,\n                                         channel_shift_range=0.3,\n                                         fill_mode=\"nearest\")","36540294":"Test_IMG_Generator = ImageDataGenerator(rescale=1.\/255)","c2768ad6":"Example_IMG = Main_Attack_Data[\"JPG\"][123]\nLoading_IMG = image.load_img(Example_IMG)\nArray_IMG = image.img_to_array(Loading_IMG)\nArray_IMG = Array_IMG.reshape((1,) + Array_IMG.shape)\n\ni = 0\n\nfor batch in Train_IMG_Generator.flow(Array_IMG,batch_size=32):\n    \n    plt.figure(i)\n    \n    Image_Main = plt.imshow(image.img_to_array(batch[0]))\n    \n    i += 1\n    \n    if i % 6 == 0:\n        break\nplt.show()","2d011aed":"Train_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=X_Train,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"TYPE\",\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"categorical\",\n                                                   subset=\"training\",\n                                                   target_size=(80,300))","be6ba0bc":"Validation_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=X_Train,\n                                                        x_col=\"JPG\",\n                                                        y_col=\"TYPE\",\n                                                        color_mode=\"rgb\",\n                                                        class_mode=\"categorical\",\n                                                        subset=\"validation\",\n                                                        target_size=(80,300))","0afdff4e":"Test_Set = Test_IMG_Generator.flow_from_dataframe(dataframe=X_Test,\n                                                        x_col=\"JPG\",\n                                                        y_col=\"TYPE\",\n                                                        color_mode=\"rgb\",\n                                                        class_mode=\"categorical\",\n                                                        target_size=(80,300))","1e8791c8":"print(\"TRAIN: \")\nprint(Train_Set.class_indices)\nprint(Train_Set.classes[0:5])\nprint(Train_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_Set.class_indices)\nprint(Validation_Set.classes[0:5])\nprint(Validation_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_Set.class_indices)\nprint(Test_Set.classes[0:5])\nprint(Test_Set.image_shape)","a352fa90":"for data_batch,label_batch in Train_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","ee153f10":"for data_batch,label_batch in Validation_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","0800dfc3":"for data_batch,label_batch in Test_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","2b39de27":"Model = Sequential()\n\nModel.add(Conv2D(32,3,\n                          activation=\"relu\",\n                 input_shape=(80,300,3),padding=\"same\"))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2)))\n\n#\nModel.add(Conv2D(64,3,\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Conv2D(128,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.5))\nModel.add(MaxPooling2D((2)))\n\n#\nModel.add(Conv2D(64,3,\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Conv2D(128,3,\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.5))\nModel.add(GlobalAveragePooling2D())\n\n#\nModel.add(Flatten())\nModel.add(Dense(256,\n                activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(3,\n                activation=\"softmax\"))","b0620e87":"print(Model.summary())","fcd689c5":"plot_model(Model,to_file=\"Model_CNN.png\",show_layer_names=True,show_dtype=True,show_shapes=True)","75239c50":"Call_Back_Early_Stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\nCall_Back_Check = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_model\")","7f5717ab":"Model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","5e1d9d93":"CNN_Model = Model.fit(Train_Set,\n                      validation_data=Validation_Set,\n                            callbacks=[Call_Back_Early_Stop,Call_Back_Check],\n                      epochs=50)","b7e72890":"Model_Results = Model.evaluate(Test_Set)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","36086532":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","f8db470d":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","1a9cdbf9":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","fee4f4a2":"plt.plot(CNN_Model.history[\"val_loss\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","ded76248":"Dict_Summary = pd.DataFrame(CNN_Model.history)\nDict_Summary.plot()","21e05776":"Prediction_Main_Result = Model.predict(Test_Set)\nPrediction_Class_Result = Model.predict_classes(Test_Set)","a300239c":"Prediction_Main_Result = Prediction_Main_Result.argmax(axis=-1)","2bbc3182":"print(Prediction_Main_Result)","68d527ff":"print(Prediction_Class_Result)","0361aa40":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(X_Test[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction_Main_Result[i]}\")\n    ax.set_xlabel(X_Test[\"TYPE\"].iloc[i])\nplt.tight_layout()\nplt.show()","c9518fe5":"#### TO SERIES","ef5a48fb":"# HISTORY","3352e796":"#### TRAINING","fbd83457":"#### STRUCTURE","d30faebe":"#### PATH","a422b28f":"#### APPLY","6e07463f":"# IMAGE GENERATOR","8794d9b2":"#### CHECKING","26a90461":"#### GENERAL","115f9fb6":"#### LABELS","177a6013":"#### TO DATAFRAME","49a54450":"#### TYPE","d178ba5b":"#### PREDICTION","62f38c7a":"# MODEL","6037551d":"##### Context\nThe applications for wide area monitoring, protection, and control systems (WAMPC) at the control center, help with providing resilient, efficient, and secure operation of the transmission system of the smart grid. The increased proliferation of phasor measurement units (PMUs) in this space has inspired many prudent applications to assist in the process of decision making in the control centers. Machine learning (ML) based decision support systems have become viable with the availability of abundant high-resolution wide area operational PMU data. We propose a deep neural network (DNN) based supervisory protection and event diagnosis system and demonstrate that it works with very high degree of confidence. The system introduces a supervisory layer that processes the data streams collected from PMUs and detects disturbances in the power systems that may have gone unnoticed by the local monitoring and protection system. Then, we investigate compromise of the insights of this ML based supervisory control by crafting adversaries that corrupt the PMU data via minimal coordinated manipulation and identification of the spatio-temporal regions in the multidimensional PMU data in a way that the DNN classifier makes wrong event predictions.\n\n##### Content\nThis dataset contains images that represent PMU data described in the reference paper. Each image has a dimension of [300X20X3] comprising of 300 time points, 10 voltage and 10 frequency measurements, and 3 fundamental color intensities. Each of the image represents the instance of a disturbance. We consider a disturbance pattern length of 5s, with 0.5 s before the trigger and 4.5 s after the trigger. Voltage and frequency data streams from 10 PMUs at a sampling rate of 60 frames per second, were aggregated to form these pseudo color images. The data-set consisted of three sub-folders: 1. 344 instances of faults located in the sub-folder \u201cDBFLT\u201d 2. 140 instances of loss of generation located in the sub-folder \u201cDBGNL\u201d 3. 21 instances of synchronous motor switching events located in the sub-folder \u201cDB_SMS\u201d.","12f542fa":"#### ADAPTIVE THRESHOLD","70e0987a":"#### HOW TO LOOK BY GENERATOR","2547d159":"#### STRUCTURE","5df77269":"#### SHUFFLE","60cb15e3":"# SPLITTING TRAIN AND TEST","a5ec21e1":"#### THRESHOLD","4df79fcd":"# VISUALIZATION","f2157e40":"# PACKAGES AND LIBRARIES","4ccd1ce5":"#### MAIN","e3c4595e":"# PATH, LABEL, TRANSFORMATION"}}