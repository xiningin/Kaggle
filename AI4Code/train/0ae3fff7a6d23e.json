{"cell_type":{"dfc68e21":"code","2e4f9b35":"code","caa19203":"code","1ece5312":"code","087c934f":"code","1171860d":"code","56c602dd":"code","b5b05bb0":"code","8cdc745a":"code","0e76c4cd":"code","1c864cb9":"code","257dff02":"code","ac6263bf":"code","a8c43bdf":"code","3758c3ec":"code","e40d941f":"code","26ce747d":"code","f264f3f1":"code","0df05902":"code","fb8b0c68":"code","d4d5af07":"code","53ec57a8":"code","db11e55d":"code","0c29a74a":"code","7166449c":"code","d8d4e4ed":"code","10c005a8":"code","e6f62f6e":"code","7810e525":"code","ca92dd4b":"code","aaf155d3":"code","5291dac3":"code","aa64ffd8":"code","231bfc3f":"code","0ecf62e1":"code","21a649ea":"code","f160124e":"code","3806a612":"code","ce631a7e":"code","c05a2294":"code","cf7991ec":"code","33e11baa":"code","6b74b646":"code","c9ad84f0":"code","6d511b09":"code","80bd20e7":"code","4ba2bce3":"code","cfb0905b":"code","1afe1c92":"code","3d03dee5":"code","5ee78b52":"code","484f0775":"code","3285c792":"code","cf1abcde":"code","f64f9205":"code","c6bae802":"code","96226ca6":"code","5be0f267":"code","b7ac14cf":"code","67b6d71a":"code","3c8818c0":"markdown","2c6eed1a":"markdown","57c73bfa":"markdown","c0064251":"markdown","0b2722ad":"markdown","92bff663":"markdown","a2d7063f":"markdown","4688969e":"markdown","00ef11e2":"markdown","8cf3328c":"markdown","6deb915a":"markdown","3a151b52":"markdown","774490d0":"markdown","75da9ae4":"markdown"},"source":{"dfc68e21":"import pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt","2e4f9b35":"#Downloading and uploading a years worth of the company bike share data\nsep2020 = pd.read_csv('..\/input\/092020\/202009-divvy-tripdata.csv')\noct2020 = pd.read_csv('..\/input\/102020\/202010-divvy-tripdata.csv')\nnov2020 = pd.read_csv('..\/input\/112020\/202011-divvy-tripdata.csv')\ndec2020 = pd.read_csv('..\/input\/122020\/202012-divvy-tripdata.csv')\njan2021 = pd.read_csv('..\/input\/012021\/202101-divvy-tripdata.csv')\nfeb2021 = pd.read_csv('..\/input\/022021\/202102-divvy-tripdata.csv')\nmar2021 = pd.read_csv('..\/input\/032021\/202103-divvy-tripdata.csv')\napr2021 = pd.read_csv('..\/input\/042021\/202104-divvy-tripdata.csv')\nmay2021 = pd.read_csv('..\/input\/052021\/202105-divvy-tripdata.csv')\njun2021 = pd.read_csv('..\/input\/062021\/202106-divvy-tripdata.csv')\njul2021 = pd.read_csv('..\/input\/072021\/202107-divvy-tripdata.csv')\naug2021 = pd.read_csv('..\/input\/082021\/202108-divvy-tripdata.csv')\n\n#Compile the collected data collected from multiple .csv files to clean and utilize data more efficiently\nseries = [sep2020, oct2020, nov2020, dec2020, jan2021, feb2021, mar2021, apr2021, may2021, jun2021, jul2021, aug2021] \ndftrip1 = pd.concat(series)\ndftrip1.to_csv('2020-2021_Aug_r.csv')","caa19203":"#Counting Rows to determine whether the full merge was completed\nr = len(dftrip1)\nt = len(sep2020) + len(oct2020) + len(nov2020) + len(dec2020) + len(jan2021) + len(feb2021) + len(mar2021) + len(apr2021) + len(may2021) + len(jun2021) + len(jul2021) + len(aug2021)\nprint(t, \"equals\", r)","1ece5312":"#df_trip1 = pd.read_csv('..\/input\/august-2020-2021-ride-data\/2020-2021_Aug_raw.csv')\n#df_trip = pd.read_csv('.\/2020-2021_Aug_r.csv')\ndf_trip = dftrip1.copy()\ndf_trip","087c934f":"#resetting the index helps clean up the mered datasets along the indexed rows, so that we have acontinuos index counter instead of multiple indexes counted over for each month\ndf_trip = df_trip.reset_index()\ndel df_trip['index']\ndf_trip","1171860d":"#If we are going to be manipulating this data it would be good to understand what type of data we are working with.\ndf_trip.info()","56c602dd":"#Are there any cells void of information that we might need to fill?\ndf_trip.isna().any()","b5b05bb0":"#how much information is actually missing in each of these columns?\ndf_trip.count()","8cdc745a":"#Seeing as this date and time information appears to be completely filled, we can make sure that they are entered as more managable date time objects rather than just string objects\ndf_trip['Start'] = pd.to_datetime(df_trip['started_at'])\ndf_trip['End'] = pd.to_datetime(df_trip['ended_at'])\ndel df_trip['ended_at']\ndel df_trip['started_at']\ndf_trip.head()","0e76c4cd":"#here we check to confirm that these newly converted columns are not missing any information\ndf_trip.isna().any()","1c864cb9":"#Find and fill NaN with the correct missing values\ndf_trip[df_trip['start_station_id'].isna()]\n\n\n#df_trip.loc[isNaN(df_trip['end_station_name']) == True]\n#(To Find:)\n#Clark St & Armitage Ave\t94.0\tNaN\tNaN\t41.918265\t-87.636360\t41.88\t-87.62\t\n#41.760000\t-87.650000\t   41.76\t-87.65\t\n#Cottage Grove Ave & Oakwood Blvd\tTA1308000038\tNaN\tNaN\t41.822989\t-87.607163\t41.84\t-87.61\t\n#Broadway & Sheridan Rd\t13323\tNaN\tNaN\t41.952799\t-87.650012\t41.96\t-87.65\t\n#Michigan Ave & Lake St\t52.0\tNaN\tNaN\t41.885784\t-87.624948\t41.89\t-87.63\t\n#lat = 41.949378 long = -87.646519 --> Pine Grove Ave & Waveland Ave | ID:232.0\n\n#df_trip.loc[(df_trip['end_lng'] == -87.646381)]    \n#(To Find:)\n#lat = 41.949378 long = -87.646519 --> Pine Grove Ave & Waveland Ave | ID:232.0\n#41.949378\t-87.646519\n#Rockwell St & Eastwood Ave\t478.0\tPine Grove Ave & Waveland Ave\t232.0\t41.965856\t-87.693702\t41.949378\t-87.646381\n#NaN\tNaN\tPine Grove Ave & Waveland Ave\tTA1307000150\t41.920000\t-87.660000\t41.949378\t-87.646708\t\n#41.950000\t-87.660000","257dff02":"#It would seem that there is an indication of what station name and id that can store and receive bikes and the langitude and longitude location of the station\n#amongst these sets of data, we can clean up some of the missing information for the stations and locations\ndf_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000)]","ac6263bf":"# in this case we can see that the starting and ending latitude and longitude is associated with station name \"W Oakdale Ave & N Broadway\" and station id \"20252.0\"\n# Lets fill in the blanks\ndf_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000) & (df_trip['start_station_name'].isna())]","a8c43bdf":"#df_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000) & (df_trip['start_station_name'].isna())]\ndef isNaN(num):\n    return num!= num\n\nfor i in range(0,len(df_trip['start_station_name'])):\n    if df_trip.loc[i,'start_lat']== 41.940000 and df_trip.loc[i,'start_lng'] == -87.640000 and isNaN(df_trip.loc[i,'start_station_name']) == True:\n        df_trip.loc[i,'start_station_name'] = \"W Oakdale Ave & N Broadway\"    \nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.940000 and df_trip.loc[i,'end_lng'] == -87.640000 and isNaN(df_trip.loc[i,'end_station_name']) == True:\n        df_trip.loc[i,'end_station_name'] = \"W Oakdale Ave & N Broadway\" \nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.940000 and df_trip.loc[i,'start_lng'] == -87.640000 and isNaN(df_trip.loc[i,'start_station_id']) == True:\n        df_trip.loc[i,'start_station_id'] = 20252.0    \nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.940000 and df_trip.loc[i,'end_lng'] == -87.640000 and isNaN(df_trip.loc[i,'end_station_id']) == True:\n        df_trip.loc[i,'end_station_id'] = 20252.0","3758c3ec":"#check\n#df_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000) & (df_trip['start_station_name'].isna())]\ndf_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000)]","e40d941f":"#check\n#df_trip.loc[(df_trip['start_lat']== 41.940000) & (df_trip['start_lng'] == -87.640000) & (df_trip['end_station_name'].isna())]\ndf_trip.loc[(df_trip['end_lat']== 41.940000) & (df_trip['end_lng'] == -87.640000)]","26ce747d":"#Check\ndf_trip.loc[(df_trip['end_lat']== 41.940000) & (df_trip['end_lng'] == -87.640000)]","f264f3f1":"df_trip.loc[(df_trip['start_lat']== 41.930000) & (df_trip['start_lng'] == -87.640000)]\n#lat = 41.930000 long = -87.640000 --> Hampden Ct & Diversey Ave | ID:202480.0","0df05902":"for i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.930000 and df_trip.loc[i,'start_lng'] == -87.640000 and isNaN(df_trip.loc[i,'start_station_id']) == True:\n        df_trip.loc[i,'start_station_id'] = 202480.0  \n        \nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.930000 and df_trip.loc[i,'end_lng'] == -87.640000 and isNaN(df_trip.loc[i,'end_station_id']) == True:\n        df_trip.loc[i,'end_station_id'] = 202480.0   \n        \nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.930000 and df_trip.loc[i,'start_lng'] == -87.640000 and isNaN(df_trip.loc[i,'start_station_name']) == True:\n        df_trip.loc[i,'start_station_name'] = 'Hampden Ct & Diversey Ave'   \n\nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.930000 and df_trip.loc[i,'end_lng'] == -87.640000 and isNaN(df_trip.loc[i,'end_station_name']) == True:\n        df_trip.loc[i,'end_station_name'] = 'Hampden Ct & Diversey Ave'  ","fb8b0c68":"#df_trip.loc[(df_trip['end_lat']== 41.950000) & (df_trip['end_lng'] == -87.660000)]\n#df_trip.loc[(df_trip['end_lat']== 41.950000) & (df_trip['end_lng'] == -87.660000) & (df_trip['end_station_name'].isna())]\n#df_trip.loc[(df_trip['end_lat']== 41.950000) & (df_trip['end_lng'] == -87.660000) & (isNaN(df_trip['end_station_name']) == False)]\n#df_trip.loc[(df_trip['start_lat']== 41.950000) & (df_trip['start_lng'] == -87.660000) & (df_trip['start_station_name'].isna())]\n#if df_trip.loc[(df_trip['start_lat']== 41.950000) & (df_trip['start_lng'] == -87.660000)]\n#41.950000\t-87.660000\n#based on the abave searches it would appear that we have no identifyable name listed in any record of the dataset that would relate to the coordinates 41.950000\t-87.660000\n#for this reason we will list this location as unknown to see if it can be accounted for in our location visit tally\nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.950000 and df_trip.loc[i,'start_lng'] == -87.660000 and isNaN(df_trip.loc[i,'start_station_name']) == True:\n        df_trip.loc[i,'start_station_name'] = 'Unknown Location'   \n\nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.950000 and df_trip.loc[i,'end_lng'] == -87.660000 and isNaN(df_trip.loc[i,'end_station_name']) == True:\n        df_trip.loc[i,'end_station_name'] = 'Unknown Location'  ","d4d5af07":"#Check\ndf_trip.loc[isNaN(df_trip['end_station_name']) == True]","53ec57a8":"df_trip.loc[(df_trip['end_lng'] == -87.646381)]","db11e55d":"for i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.949378 and df_trip.loc[i,'start_lng'] == -87.646381 and isNaN(df_trip.loc[i,'start_station_id']) == True:\n        df_trip.loc[i,'start_station_id'] = 232.0   \nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.949378 and df_trip.loc[i,'end_lng'] == -87.646381 and isNaN(df_trip.loc[i,'end_station_id']) == True:\n        df_trip.loc[i,'end_station_id'] = 232.0    \n        \nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.949378 and df_trip.loc[i,'start_lng'] == -87.646381 and isNaN(df_trip.loc[i,'start_station_name']) == True:\n        df_trip.loc[i,'start_station_name'] = 'Pine Grove Ave & Waveland Ave'\nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.949378 and df_trip.loc[i,'end_lng'] == -87.646381 and isNaN(df_trip.loc[i,'end_station_name']) == True:\n        df_trip.loc[i,'end_station_name'] = 'Pine Grove Ave & Waveland Ave'  \n        \nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.949378 and df_trip.loc[i,'start_lng'] == -87.646708 and isNaN(df_trip.loc[i,'start_station_id']) == True:\n        df_trip.loc[i,'start_station_id'] = 'TA1307000150'  \nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.949378 and df_trip.loc[i,'end_lng'] == -87.646708 and isNaN(df_trip.loc[i,'end_station_id']) == True:\n        df_trip.loc[i,'end_station_id'] = 'TA1307000150'\n\nfor i in range(0,len(df_trip['start_lat'])):\n    if df_trip.loc[i,'start_lat']== 41.949378 and df_trip.loc[i,'start_lng'] == -87.646708 and isNaN(df_trip.loc[i,'start_station_name']) == True:\n        df_trip.loc[i,'start_station_name'] = 'Pine Grove Ave & Waveland Ave'\nfor i in range(0,len(df_trip['end_lat'])):\n    if df_trip.loc[i,'end_lat']== 41.949378 and df_trip.loc[i,'end_lng'] == -87.646708 and isNaN(df_trip.loc[i,'end_station_name']) == True:\n        df_trip.loc[i,'end_station_name'] = 'Pine Grove Ave & Waveland Ave'  ","0c29a74a":"#Test\nweekday = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\nwkdy = df_trip['End'][0].strftime(\"%w\")\nprint(weekday[int(wkdy)])","7166449c":"#Determining how many rides that may have a start time that is larger than the end time of a ridde which may cause issue with the curation measurement\n#The reason for times  being recorded in such a way is most likely due to rides extending past midnight which might my\novnt = []\ndpst = []\nfor l in range(0, len(df_trip['Start'])):\n    if df_trip['Start'][int(l)].strftime(\"%w\") != df_trip['End'][int(l)].strftime(\"%w\"):\n        ovnt.append(l)\n    else:\n        dpst.append('a')\n        \nt = len(df_trip['Start'])\no = len(ovnt)\nd = len(dpst)\n\nprint('Overnight Rides = ', o)\nprint(t - o - d)\nprint('Total Count = ', t)\nprint('Percentage overnight ride within the sample population = ', (o\/t)*100)","d8d4e4ed":"#Figure out the time of day people are traveling most often (by weekday and by month)\ntime_comp = {'00':'12-AM', '01':'01-AM', '02':'02-AM', '03':'03-AM', '04':'04-AM', '05':'05-AM', '06':'06-AM', '07':'07-AM', '08':'08-AM', '09':'09-AM', '10':'10-AM', \n             '11':'11-AM', '12':'12-PM', '13':'01-PM', '14':'02-PM', '15':'03-PM', '16':'04-PM', '17':'05-PM', '18':'06-PM', '19':'07-PM', '20':'08-PM', '21':'09-PM', \n             '22':'10-PM', '23':'11-PM',}\ntod = []\nfor n in range(0,len(df_trip['Start'])):\n    yn = df_trip['Start'][n].strftime(\"%H\")\n    tod.append(time_comp[yn])\n\n#df_trip['hour'] = df_trip.loc[:,'Start'].strftime(\"%H\")\ndf_trip['hour'] = pd.DataFrame(tod, columns=['hour'])\ndf_trip.head()","10c005a8":"#Creating a column that will help determine which day of the week a ride started\/took place \nweekday = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\nwkday = []\nfor s in range(0,len(df_trip['Start'])):\n    e = df_trip['Start'][s].strftime(\"%w\")\n    wkday.append(weekday[int(e)])\n\ndf_trip['weekday'] = pd.DataFrame(wkday, columns=['weekday'])\n\ndf_trip.head()","e6f62f6e":"#Adding new column to identify the month each ride takes place, to make sorting information easier\nmonthname = {'01':'January', '02':'February', '03':'March', '04':'April', '05':'May',\n            '06':'June', '07':'July', '08':'August', '09':'September', '10':'October',\n            '11':'November', '12':'December'}\n\nmnth = []\nfor s in range(0,len(df_trip['Start'])):\n    y = df_trip['Start'][s].strftime(\"%m\")\n    mnth.append(monthname[y])\n\ndf_trip['month'] = pd.DataFrame(mnth, columns=['month'])\n\ndf_trip.head()","7810e525":"#Computing Ride Duration for each run and listing those values in a new column\n    \ndf_trip['duration'] = abs(df_trip['End'] - df_trip['Start'])\ndf_trip.head()","ca92dd4b":"df_trip.groupby(['month']).size()","aaf155d3":"#Test\ndf_trip.loc[df_trip['month'] == 'August'].count()","5291dac3":"#Test\ndf_trip.groupby(['start_station_name']).size()","aa64ffd8":"member_class = df_trip.groupby(['member_casual']).size()\nprint(member_class)","231bfc3f":"df_trip_mem = df_trip.loc[df_trip['member_casual'] == 'member']\ndf_trip_mem.head()","0ecf62e1":"df_trip_cas = df_trip.loc[df_trip['member_casual'] == 'casual']\ndf_trip_cas.head()","21a649ea":"#Here we determine the type of bikes either rider tends to frequnt most by creating a table and graph to display the correlation\nride_type = df_trip.groupby(['rideable_type']).count()\nride_type_tot = ride_type['ride_id']\nride_typem = df_trip_mem.groupby(['rideable_type']).count()\nride_type_mem = ride_typem['start_station_id']\nride_typec = df_trip_cas.groupby(['rideable_type']).count()\nride_type_cas = ride_typec['start_lat']\n\n#Merge\/join these dataframes by Start Loc as index\n\nride_type_cnts = [\n    ride_type_tot, \n    ride_type_cas, \n    ride_type_mem\n    ]\nride_type_cnt = pd.concat(ride_type_cnts, join='outer', axis=1)\nride_type_cnt = ride_type_cnt.rename(columns={'ride_id':'Total','start_station_id':'Member','start_lat':'Casual'})\nride_type_cnt","f160124e":"ride_type_cnt.plot(kind='bar')","3806a612":"#Here we can determine how many bike rides these riders engaged in over the month\nmonthcount = df_trip.groupby(['month']).count()\nmonthcount_tot = monthcount['ride_id']\nmonthcountm = df_trip_mem.groupby(['month']).count()\nmonthcount_mem = monthcountm['start_station_id']\nmonthcountc = df_trip_cas.groupby(['month']).count()\nmonthcount_cas = monthcountc['start_lat']\n\n#Merge\/join these dataframes by Start Loc as index\n\nmonthcount_cnts = [\n    monthcount_tot, \n    monthcount_cas, \n    monthcount_mem\n    ]\nmonthcount_cnt = pd.concat(monthcount_cnts, join='outer', axis=1)\nmonthcount_cnt = monthcount_cnt.rename(columns={'ride_id':'Total','start_station_id':'Member','start_lat':'Casual'})\nmonthname = {'01':'January', '02':'February', '03':'March', '04':'April', '05':'May',\n            '06':'June', '07':'July', '08':'August', '09':'September', '10':'October',\n            '11':'November', '12':'December'}\nmonthcount_cnt = monthcount_cnt.loc[['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], :]\nmonthcount_cnt","ce631a7e":"monthcount_cnt.plot(kind='bar')  ","c05a2294":"#Here we determine the full duration of rides that took place over the month\n#we first start with setting the overall duration chart to which we can add the member and cassual runs to later on\nmonthdur = {}\nmonthnum = {'1':'01', '2':'02', '3':'03', '4':'04', '5':'05',\n            '6':'06', '7':'07', '8':'08', '9':'09', '10':'10',\n            '11':'11', '12':'12'}\n\nfor n in range(1,13):\n    ln = monthnum[str(n)]\n    rn = df_trip[df_trip['month']==monthname[ln]]['duration'].sum()\n    monthdur[monthname[ln]] = rn\n\nmonthdur","cf7991ec":"monthdurdf = pd.DataFrame([monthdur])\nmonthdurdf = monthdurdf.transpose()\nmonthdurdf = monthdurdf.rename(columns={0:'Monthly_Duration'}) \nmonthdurdf","33e11baa":"monthdurc = {}\nmonthdurm = {}\n\nfor nc in range(1,13):\n    lnc = monthnum[str(nc)]\n    rnc = df_trip_cas[df_trip_cas['month']==monthname[lnc]]['duration'].sum()\n    monthdurc[monthname[lnc]] = rnc\n    \nfor nm in range(1,13):\n    lnm = monthnum[str(nm)]\n    rnm = df_trip_mem[df_trip_mem['month']==monthname[lnm]]['duration'].sum()\n    monthdurm[monthname[lnm]] = rnm\n    \nmonthdurdfc = pd.DataFrame([monthdurc])\nmonthdurdfm = pd.DataFrame([monthdurm])\n\nmonthdurdfc = monthdurdfc.transpose()\nmonthdurdfm = monthdurdfm.transpose()\n\nmonthdurdfc = monthdurdfc.rename(columns={0:'Cas_Duration'}) \nmonthdurdfm = monthdurdfm.rename(columns={0:'Mem_Duration'})\n\nmonthdurdf['Casual'] = monthdurdfc['Cas_Duration']\nmonthdurdf['Member'] = monthdurdfm['Mem_Duration']\n\nmonthdurdf","6b74b646":"mdt = []\nfor ndt in range(0,len(monthdurdf.index)):\n    ndtt = monthdurdf.Monthly_Duration[ndt].days\n    mdt.append(ndtt)\nmdtc = []\nfor ndc in range(0,len(monthdurdf.index)):\n    ndtc = monthdurdf.Casual[ndc].days\n    mdtc.append(ndtc)\nmdtm = []\nfor ndm in range(0,len(monthdurdf.index)):\n    ndtm = monthdurdf.Member[ndm].days\n    mdtm.append(ndtm)\nprint(mdt)\nprint(mdtc)\nprint(mdtm)\nmonthdurdfnum = pd.DataFrame(list(zip(mdt, mdtc, mdtm)), index = monthdurdf.index, columns = ['Monthly_Dnum','Casnum','Memnum'])\n#monthdurdfnum\nmonthdurdfnum.plot(kind='bar') ","c9ad84f0":"#Here we find how many rides per week day we are getting record of\nwkday = df_trip.groupby(['weekday']).count()\nwkday_tot = wkday['ride_id']\nwkdaym = df_trip_mem.groupby(['weekday']).count()\nwkday_mem = wkdaym['rideable_type']\nwkdayc = df_trip_cas.groupby(['weekday']).count()\nwkday_cas = wkdayc['start_lat']\n\n#Merge\/join these dataframes by Start Loc as index\n\nwkday_cnts = [\n    wkday_tot, \n    wkday_cas, \n    wkday_mem\n    ]\nwkday_cnt = pd.concat(wkday_cnts, join='outer', axis=1)\nwkday_cnt = wkday_cnt.rename(columns={'ride_id':'Total','rideable_type':'Member','start_lat':'Casual'})\n\nwkday_cnt = wkday_cnt.loc[['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], :]\nwkday_cnt","6d511b09":"wkday_cnt.plot(kind='bar')","80bd20e7":"#Now we are breaking down the week day count over the course of each month to see id there is any change in the overall result as it relates to different times of year\nwkpmnth = df_trip.groupby(by=['month', 'weekday']).size()\nprint(wkpmnth)","4ba2bce3":"mnthpwk = df_trip.groupby(by=['weekday',]).size()\nprint(mnthpwk)","cfb0905b":"mnthpwk_df = pd.DataFrame({'count' : df_trip.groupby(['weekday','month']).size()}).reset_index()\nmnthpwk_df","1afe1c92":"janmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\njanmcnt = janmcnt.set_index('weekday')\ndel janmcnt['month']\njanmcnt = janmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\nfebmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\nfebmcnt = febmcnt.set_index('weekday')\ndel febmcnt['month']\nfebmcnt = febmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\nmarmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\nmarmcnt = marmcnt.set_index('weekday')\ndel marmcnt['month']\nmarmcnt = marmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\naprmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\naprmcnt = aprmcnt.set_index('weekday')\ndel aprmcnt['month']\naprmcnt = aprmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\nmaymcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\nmaymcnt = maymcnt.set_index('weekday')\ndel maymcnt['month']\nmaymcnt = maymcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\njunmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\njunmcnt = junmcnt.set_index('weekday')\ndel junmcnt['month']\njunmcnt = junmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\njulmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\njulmcnt = julmcnt.set_index('weekday')\ndel julmcnt['month']\njulmcnt = julmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\naugmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\naugmcnt = augmcnt.set_index('weekday')\ndel augmcnt['month']\naugmcnt = augmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\nsepmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\nsepmcnt = sepmcnt.set_index('weekday')\ndel sepmcnt['month']\nsepmcnt = sepmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\noctmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\noctmcnt = octmcnt.set_index('weekday')\ndel octmcnt['month']\noctmcnt = octmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\nnovmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\nnovmcnt = novmcnt.set_index('weekday')\ndel novmcnt['month']\nnovmcnt = novmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\ndecmcnt = mnthpwk_df.iloc[[11,23,35,47,59,71, 83],:]\ndecmcnt = decmcnt.set_index('weekday')\ndel decmcnt['month']\ndecmcnt = decmcnt.loc[['Sunday','Monday','Tuesday','Wednesday','Thursday', 'Friday', 'Saturday'], :]\n\n#We will now have a view of how the ride count of each day of the week varies with the months of the year\njanmcnt.plot(kind='bar', title='January')\nfebmcnt.plot(kind='bar', title='February')\nmarmcnt.plot(kind='bar', title='March')\naprmcnt.plot(kind='bar', title='April')\nmaymcnt.plot(kind='bar', title='May')\njunmcnt.plot(kind='bar', title='June')\njulmcnt.plot(kind='bar', title='July')\naugmcnt.plot(kind='bar', title='August')\nsepmcnt.plot(kind='bar', title='September')\noctmcnt.plot(kind='bar', title='October')\nnovmcnt.plot(kind='bar', title='November')\ndecmcnt.plot(kind='bar', title='December')","3d03dee5":"#Here we determine most and least frequently visited start locations for the members and casual riders\nstartloc = df_trip.groupby(['start_station_name']).count()\nstartloc_tot = startloc['ride_id']\nstartlocm = df_trip_mem.groupby(['start_station_name']).count()\nstartloc_mem = startlocm['end_lat']\nstartlocc = df_trip_cas.groupby(['start_station_name']).count()\nstartloc_cas = startlocc['start_lat']\n\n#Merge\/join these dataframes by Start Loc as index\n\nstartloc_cnts = [\n    startloc_tot, \n    startloc_cas, \n    startloc_mem\n    ]\nstartloc_cnt = pd.concat(startloc_cnts, join='outer', axis=1)\nstartloc_cnt = startloc_cnt.rename(columns={'ride_id':'Total','end_lat':'Member','start_lat':'Casual'})\nstartloc_cnt","5ee78b52":"#Here we determine most and least frequently visited end locations for the members and casual riders\nendloc = df_trip.groupby(['end_station_name']).count()\nendloc_tot = endloc['ride_id']\nendlocm = df_trip_mem.groupby(['end_station_name']).count()\nendloc_mem = endlocm['end_lat']\nendlocc = df_trip_cas.groupby(['end_station_name']).count()\nendloc_cas = endlocc['start_lat']\n\n#Merge\/join these dataframes by Start Loc as index\n\nendloc_cnts = [\n    endloc_tot, \n    endloc_cas, \n    endloc_mem\n    ]\nendloc_cnt = pd.concat(endloc_cnts, join='outer', axis=1)\nendloc_cnt = endloc_cnt.rename(columns={'ride_id':'Total','end_lat':'Member','start_lat':'Casual'})\nendloc_cnt","484f0775":"print(startloc_cnt.nlargest(5, 'Total'))\nprint(endloc_cnt.nlargest(5, 'Total'))","3285c792":"df_triptime = df_trip.loc[:,['month','weekday','hour']]\n#time_list = ['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM', \n#             '11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',]\n#df_triptime.groupby('hour').size()\n#.orderby(time_list)#.plot(kind='bar', title='Ride Count per Hour (Yeary)')\n\ntovll = pd.DataFrame({'count' : df_triptime.groupby('hour').size()}).reset_index()\ntovll = tovll.set_index('hour')\ntovll = tovll.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\ntovll.plot(kind='bar',title='Ride Count per Hour (Yeary)')","cf1abcde":"tmph= pd.DataFrame({'count' : df_triptime.groupby(['month','hour']).size()}).reset_index()\ntmph","f64f9205":"jantcnta = tmph.loc[(tmph['month'] == 'January')]\njantcnta = jantcnta.set_index('hour')\ndel jantcnta['month']\njantcnta = jantcnta.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\njantcnta","c6bae802":"jantcnt = tmph.loc[(tmph['month'] == 'January')]\njantcnt = jantcnt.set_index('hour')\ndel jantcnt['month']\njantcnt = jantcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nfebtcnt = tmph.loc[(tmph['month'] == 'February')]\nfebtcnt = febtcnt.set_index('hour')\ndel febtcnt['month']\nfebtcnt = febtcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nmartcnt = tmph.loc[(tmph['month'] == 'March')]\nmartcnt = martcnt.set_index('hour')\ndel martcnt['month']\nmartcnt = martcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\naprtcnt = tmph.loc[(tmph['month'] == 'April')]\naprtcnt = aprtcnt.set_index('hour')\ndel aprtcnt['month']\naprtcnt = aprtcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nmaytcnt = tmph.loc[(tmph['month'] == 'May')]\nmaytcnt = maytcnt.set_index('hour')\ndel maytcnt['month']\nmaytcnt = maytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\njuntcnt = tmph.loc[(tmph['month'] == 'June')]\njuntcnt = juntcnt.set_index('hour')\ndel juntcnt['month']\njuntcnt = juntcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\njultcnt = tmph.loc[(tmph['month'] == 'July')]\njultcnt = jultcnt.set_index('hour')\ndel jultcnt['month']\njultcnt = jultcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\naugtcnt = tmph.loc[(tmph['month'] == 'August')]\naugtcnt = augtcnt.set_index('hour')\ndel augtcnt['month']\naugtcnt = augtcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nseptcnt = tmph.loc[(tmph['month'] == 'September')]\nseptcnt = septcnt.set_index('hour')\ndel septcnt['month']\nseptcnt = septcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nocttcnt = tmph.loc[(tmph['month'] == 'October')]\nocttcnt = octtcnt.set_index('hour')\ndel octtcnt['month']\nocttcnt = octtcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nnovtcnt = tmph.loc[(tmph['month'] == 'November')]\nnovtcnt = novtcnt.set_index('hour')\ndel novtcnt['month']\nnovtcnt = novtcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\ndectcnt = tmph.loc[(tmph['month'] == 'December')]\ndectcnt = dectcnt.set_index('hour')\ndel dectcnt['month']\ndectcnt = dectcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\n#We will now have a view of how the ride count of each day of the week varies with the months of the year\njantcnt.plot(kind='bar', title='January')\nfebtcnt.plot(kind='bar', title='February')\nmartcnt.plot(kind='bar', title='March')\naprtcnt.plot(kind='bar', title='April')\nmaytcnt.plot(kind='bar', title='May')\njuntcnt.plot(kind='bar', title='June')\njultcnt.plot(kind='bar', title='July')\naugtcnt.plot(kind='bar', title='August')\nseptcnt.plot(kind='bar', title='September')\nocttcnt.plot(kind='bar', title='October')\nnovtcnt.plot(kind='bar', title='November')\ndectcnt.plot(kind='bar', title='December')","96226ca6":"mthtmecnts = jantcnt.copy()\nmthtmecnts = mthtmecnts.rename(columns={\"count\": \"January\"})\nmthtmecnts['February'] = febtcnt['count']\nmthtmecnts['March'] = martcnt['count']\nmthtmecnts['April'] = aprtcnt['count']\nmthtmecnts['May'] = maytcnt['count']\nmthtmecnts['June'] = juntcnt['count']\nmthtmecnts['July'] = jultcnt['count']\nmthtmecnts['August'] = augtcnt['count']\nmthtmecnts['September'] = septcnt['count']\nmthtmecnts['October'] = octtcnt['count']\nmthtmecnts['November'] = novtcnt['count']\nmthtmecnts['December'] = dectcnt['count']\nmthtmecnts","5be0f267":"#df_triptime.groupby(['weekday','hour']).size()#.plot(kind='bar', title='Ride Count per Hour (Monthly)')\ntwph= pd.DataFrame({'count' : df_triptime.groupby(['weekday','hour']).size()}).reset_index()\ntwph","b7ac14cf":"sundaytcnt = twph.loc[(twph['weekday'] == 'Sunday')]\nsundaytcnt = sundaytcnt.set_index('hour')\ndel sundaytcnt['weekday']\nsundaytcnt = sundaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nmondaytcnt = twph.loc[(twph['weekday'] == 'Monday')]\nmondaytcnt = mondaytcnt.set_index('hour')\ndel mondaytcnt['weekday']\nmondaytcnt = mondaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\ntuesdaytcnt = twph.loc[(twph['weekday'] == 'Tuesday')]\ntuesdaytcnt = tuesdaytcnt.set_index('hour')\ndel tuesdaytcnt['weekday']\ntuesdaytcnt = tuesdaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nwednesdaytcnt = twph.loc[(twph['weekday'] == 'Wednesday')]\nwednesdaytcnt = wednesdaytcnt.set_index('hour')\ndel wednesdaytcnt['weekday']\nwednesdaytcnt = wednesdaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nthursdaytcnt = twph.loc[(twph['weekday'] == 'Thursday')]\nthursdaytcnt = thursdaytcnt.set_index('hour')\ndel thursdaytcnt['weekday']\nthursdaytcnt = thursdaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nfridaytcnt = twph.loc[(twph['weekday'] == 'Friday')]\nfridaytcnt = fridaytcnt.set_index('hour')\ndel fridaytcnt['weekday']\nfridaytcnt = fridaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\nsaturdaytcnt = twph.loc[(twph['weekday'] == 'Saturday')]\nsaturdaytcnt = saturdaytcnt.set_index('hour')\ndel saturdaytcnt['weekday']\nsaturdaytcnt = saturdaytcnt.loc[['12-AM', '01-AM', '02-AM', '03-AM', '04-AM', '05-AM', '06-AM', '07-AM', '08-AM', '09-AM', '10-AM','11-AM', '12-PM', '01-PM', '02-PM', '03-PM', '04-PM', '05-PM', '06-PM', '07-PM', '08-PM', '09-PM','10-PM', '11-PM',],:]\n\n#Graph each weekday time count\nsundaytcnt.plot(kind='bar', title = 'Sunday')\nmondaytcnt.plot(kind='bar', title = 'Monday')\ntuesdaytcnt.plot(kind='bar', title = 'Tuesday')\nwednesdaytcnt.plot(kind='bar', title = 'Wednesday')\nthursdaytcnt.plot(kind='bar', title = 'Thurdsay')\nfridaytcnt.plot(kind='bar', title = 'Friday')\nsaturdaytcnt.plot(kind='bar', title = 'Saturday')","67b6d71a":"#Compile data into one chart for easy viewing\nwktmecnts = sundaytcnt.copy()\nwktmecnts = wktmecnts.rename(columns={\"count\": \"Sunday\"})\nwktmecnts['Monday'] = mondaytcnt['count']\nwktmecnts['Tuesday'] = tuesdaytcnt['count']\nwktmecnts['Wednesday'] = wednesdaytcnt['count']\nwktmecnts['Thursday'] = thursdaytcnt['count']\nwktmecnts['Friday'] = fridaytcnt['count']\nwktmecnts['Saturday'] = saturdaytcnt['count']\n\nwktmecnts","3c8818c0":"The weekends tend to be the time for which most riders are active. Despite the spike of casual riders on saturday and sunday, the member ridership is generaly consistent throughout the week with wednesday ranking as the day with the highest ride count over the year","2c6eed1a":"While looking at this data breifly, we might also recognize that there are som rides that have bikes being picked up and plased back at their same station within a matter of seconds. From this we can tell that there are some initiated rides that did not have any travel or wear on the bike.","57c73bfa":"It would seem that both the ride count and ride durations run as one would expect with increasing volume during the warmer months an decreasing during the colder months. In this set of data, the duration counted during the month of december read an uncharacteristically large amount of negative time durations for which reason the end times were recorded as happening before the start times, is unclear. As this data could be an outlier, the general relationship between ride time and time of year can be approximated by the other 11 of the 12 months.\n\nMembers also, seem to be riding less overall time over the year than the more casual members, even though on a monthly basis, there are more recorded rides being made by the member participants in the study.\n\nIt is also noticable that the months from May to August (warmest\/hottest months of the year) are when the casual riders come out the most for a ride, while there are some later months that the ride time may run long the collective member ride duration.","c0064251":"It's easy to see from the graphs and charting of the times that people are taking bikes out for rides, that most people would be heading out around mid-day on the weekends and early eveing (lat-afternoons --> 5:00pm) during the week days.","0b2722ad":"Now that we have these new datasets, it'll be easier to compare the two membertypes. ","92bff663":"Cleaning data - checking to see that all categoris that hould have fixed sets of row values are as intended by showing each category and column in grouping\n\nIt appears we have both start and end times and locations for each trip in reference to individual riders who can be identified as casual or annual members in accordance with their ride ID numbers. We can also determine which type of bike they may have used to make these trips.\n\nWhat may help us better understand the customer's daily activity is identifying which days of the week they were active, as well as the durations of their rides.","a2d7063f":"This test run to count the value of entries for the month of august, shows that there is missing data in the start and end station and id, as well as ending coordinates (long and latitude).\n\nAs there is input information missing mainly in the bike docking locations, we might want to ask if there are issues with people properly docking or disengaging bikes, or if there are bikes simply not being returned at all.\n\nAnother issue might be that there is an issue with the migration of the data from the website to excell and then back on to this online platform, where some of the data may have been lost along the way.","4688969e":"Here we can see that there is no deviation of the midweek and weekends being the days of most frequent travel throughout the month. There is consistency withheld for the overall and monthly readings.","00ef11e2":"Now that the data is combined and saved for use we may continue with preparation and analysis","8cf3328c":"The majority of rides seem to be made on the classic bike, followed by the electric and then docked bike in quantity. both members and casual riders seem to collectively favor the classic bikes over the electric and docked bikes, while the Member riders would appear to use the electric bikes the least out of all their available options. The same can be said for the casual riders as well, though there may be a smaller differnce in the quantity of docked bike and electric bike users in their number.","6deb915a":"As we have almost finished cleaning and setting up the data enough to work with and analyze for our intended purposes, the last point of set up will be seperating Annual member and Casual rider data to compare","3a151b52":"As can be seen through the collection of the most frequently visited end and start locaions, they would be the same general locations of focus for most riders (member and casual). With this we know where the highest volume of riders we receive, go to and come from if we were to focus  on a general location to market to, interms of casual rider convergence to member status. Haven taken a look at the least visited locations in the database listing the bottom 5 location (even up to the bottom 10) dont have record of more than 1 or 2 recorded visits over the entire year of bike share information. For this reason it is not shown during this analysis.","774490d0":"Suggestions:\n\n- Setting more bikes and or stations in areas where casuall members frequent\n- Focusing campaigns for member deals on peope (or exixting casual riders) who live in the locations casual riders seem to travel.\n- Summer\/Sprng time sales\/incentives to set up an annual membership when the warmer months come around and more people can be seen riding\n- Casual riders appear to be taking longer trips overall in comparison to the annual members, and the majority of rides seem to happen after normal daytime work hours as well as mid-day on the weekends: Focusing advertisements on those who are taking longer rides for recreation or wellness may prove beneficial.","75da9ae4":"# The company: Cyclistic\nCyclistic is a bike-share program that features more than 5,800 bicycles that are geotracked and locked into a network of over 600 docking stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime. The majority of riders opt for traditional bikes; about 8% of riders use the assistive options offered by Cyclistic that sets them apart from their competitors stadart two-wheel bikes. Cyclistic users are more likely to ride for leisure, but about 30% use them to commute to work each day.  \n  \nUntil now, Cyclistic\u2019s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members. \n  \nCyclistic\u2019s finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, the director of marketing believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, the director believes there is a very good chance to convert casual riders into members, noting that casual riders are already aware of the bike-share program and have chosen Cyclistic for their mobility needs. \n\n## My Role\nAs a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, the team will design a new marketing strategy to convert casual riders into annual members.\n\n## The Goal\nDesign marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. The director of marketing and their team are  interested in analyzing the Cyclistic historical bike trip data to identify trends. \n\n\u25cf Find out the differences and commonalities between casual riders and annual members.\n\u25cf Find out how this information can help us market to more, potentially annual, members, or convert casual riders to annual members.\n\n### Stakeholders Considered:\n\u25cf Lily Moreno: The director of marketing and your manager. Moreno is responsible for the development of campaigns   \nand initiatives to promote the bike-share program. These may include email, social media, and other channels.   \n\n\u25cf Cyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy.  \n\n\u25cf Cyclistic executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.\n\n### Data\n\nPulled from the link below:\nhttps:\/\/divvy-tripdata.s3.amazonaws.com\/index.html\n"}}