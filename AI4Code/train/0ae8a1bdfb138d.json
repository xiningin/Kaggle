{"cell_type":{"0376de56":"code","c8d9bfc3":"code","b82c3b79":"code","e03678ae":"code","e0086cb8":"code","5d9112c0":"code","3d809376":"code","e38da01a":"code","2657a69b":"code","7c69ae8d":"code","6cd08ec8":"code","070388c4":"code","d8254842":"code","64ffb672":"code","92dbb6d8":"code","1497bb48":"code","6d8b03d4":"code","57ab0ea6":"code","404468be":"code","1e3b6509":"code","8d103593":"code","9b161776":"code","d7e16eb9":"code","e6c7b73f":"code","1b757b54":"code","90112d27":"code","4566f7ec":"code","c74c278e":"code","252d894b":"code","7bf51cc6":"code","1864f983":"markdown","bc9527b2":"markdown","13732cfa":"markdown","a317bf17":"markdown","cc3a018a":"markdown"},"source":{"0376de56":"### import pandas and numpy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Data Visualization Library\nimport seaborn as sns #Data Visualization Library\n\n#to present all column in results\npd.set_option(\"display.max_columns\", None)\n\n# read the train dataset\ndf_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","c8d9bfc3":"# show first rows of data to be familir with the shape of data \ndf_train.head()","b82c3b79":"df_test.info()","e03678ae":"df_train.info()","e0086cb8":"#getting statistics information from numircal data\ndf_train.describe()","5d9112c0":"df_train.Age.hist(bins=100,rwidth = .8,figsize=(14,4))\nplt.title('Age')\nplt.show()","3d809376":"#getting information from catagorial data\nprint(df_train.describe(exclude=[np.number]).shape)\ndf_train.describe(exclude=[np.number])","e38da01a":"df_train.shape","2657a69b":"#Get information about different values in all features to study if there is a missing or unlogical values \nfor col in df_train.select_dtypes(include=['object']):\n    print(f'For column {col}\\n------------------\\n')\n    print(df_train[col].value_counts())\n    print('\\n')","7c69ae8d":"df_train.isna().sum()[df_train.isna().sum() != 0]","6cd08ec8":"df_test.isna().sum()[df_train.isna().sum() != 0]","070388c4":"#data is very low so it is not the best option to drop any of it and it is better to fill it with proper values\ndf_train['Embarked']= df_train[\"Embarked\"].fillna('S')\ndf_train['Cabin']= df_train[\"Cabin\"].fillna('others')\n\ndf_test['Embarked']= df_test[\"Embarked\"].fillna('S')\ndf_test['Cabin']= df_test[\"Cabin\"].fillna('others')\n# cat_cols[\"Embarked\"].value_counts()","d8254842":"sns.boxplot(x=\"Survived\", y=\"Age\", data=df_train)","64ffb672":"from sklearn.impute import SimpleImputer\nnull_cols = df_train.columns[df_train.isna().any()==True].tolist()\nimputer = SimpleImputer(missing_values=np.NAN, strategy=\"mean\")\nimputer = imputer.fit(df_train[null_cols])\nclean_cols = imputer.transform(df_train[null_cols])\ndf_train[null_cols] = clean_cols\ndf_train.head()\n\n#for test data\nnull_cols_test = df_test.columns[df_test.isna().any()==True].tolist()\nimputer_test = SimpleImputer(missing_values=np.NAN, strategy=\"mean\")\nimputer_test = imputer_test.fit(df_test[null_cols_test])\nclean_cols_test = imputer_test.transform(df_test[null_cols_test])\ndf_test[null_cols_test] = clean_cols_test","92dbb6d8":"print(df_train.isna().sum()[df_train.isna().sum() != 0])\nprint(df_test.isna().sum()[df_train.isna().sum() != 0])","1497bb48":"sns.heatmap(df_train.corr(), annot=True)","6d8b03d4":"df_train.drop(axis=1,columns=[\"Name\",\"PassengerId\"],inplace = True)\ndf_test.drop(axis=1,columns=[\"Name\",\"PassengerId\"],inplace = True)","57ab0ea6":"cat_cols = df_train.select_dtypes(include=['object'])\ncols_names=cat_cols.columns\nprint(cols_names)\nfrom sklearn.preprocessing import LabelEncoder\nlabelEncoder = LabelEncoder()\nfor col in cols_names:\n    df_train[col] = labelEncoder.fit_transform(df_train[col])\n    df_test[col] = labelEncoder.fit_transform(df_test[col])\n","404468be":"df_train.head()","1e3b6509":"df_test.head()","8d103593":"y = df_train.Survived              \nx = df_train.drop(['Survived'], axis=1)\nprint(x.info())\ny.shape","9b161776":"x.head()","d7e16eb9":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x , y , train_size=0.8 , test_size=0.2,random_state=0)\ny_val.shape","e6c7b73f":"#import logistic regression model\nfrom sklearn.linear_model import LogisticRegression \nmodel = LogisticRegression(solver='liblinear') \nmodel.fit(x_train, y_train)","1b757b54":"# Making prediction\ny_pred = model.predict(x_val)\n\n# Calculate the accuracy\nfrom sklearn.metrics import accuracy_score\nacc = accuracy_score(y_pred, y_val)\nprint('Test accuracy is', acc)","90112d27":"# y_pred=logreg.predict(df_test)","4566f7ec":"df_test.info()","c74c278e":"y_final_pred = model.predict(df_test)\n\nsubmission = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsubmission_df = pd.DataFrame()\nsubmission_df[\"PassengerId\"] = submission.PassengerId\n\nsubmission_df[\"Survived\"] = y_final_pred","252d894b":"pd.set_option(\"display.max_rows\", None)\nsubmission_df\n","7bf51cc6":"submission_df.to_csv(\"submission.csv\", index = False, header = True)","1864f983":"#### We need to drop the name and passengerId column from our data because they are not related or affected on result","bc9527b2":"**We can see from previous plot that there is not too much outliers for age so it will be good option if will fill null data in age feature with the mean**","13732cfa":"# EDA\n**Getting important information about numircal and Catagorial data and getting some insights from it**","a317bf17":"##### we can see from above scdule that the name is not important column because it like index that not have relation with data so I will drop it later\n##### Also we can note the number of male is more than females","cc3a018a":"# Data Exploration"}}