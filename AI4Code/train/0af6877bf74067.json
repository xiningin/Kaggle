{"cell_type":{"12310b6d":"code","15c52274":"code","aa8947a6":"code","10fe7479":"code","717fee79":"code","cacbc27d":"code","6cb08b1a":"code","e81851bb":"code","dcfdea00":"code","dc33910d":"code","96f59671":"code","adaa1679":"code","a8174fd0":"code","50e189b2":"code","ffffee03":"code","b3b0a1d9":"code","f134f7ab":"code","1515c182":"code","d27cb42b":"code","9ff6de89":"code","dc9abb7a":"code","43b33082":"code","29195d31":"code","69639e31":"code","b48b33b2":"code","d26e632d":"code","1f600c39":"code","63a0bf22":"code","ab40b20a":"code","c53e080a":"code","685f77b3":"code","056140ae":"code","03fb3c03":"code","d0b5ccae":"code","08864bbe":"code","960d405c":"code","4e217839":"code","45e18d0b":"code","5baf15f9":"code","fda8d3aa":"code","2efe7ff4":"code","0c5911bd":"code","0f18f368":"code","3b85ace5":"code","9b30ecfa":"code","46881262":"code","0cc936b7":"code","c704ed4c":"code","b5617c2a":"code","8ffcdee8":"code","f5deed98":"code","e74d70e7":"code","73463f84":"code","6a4b6f54":"code","1d672eae":"code","9616165d":"code","d55ea893":"markdown","5799eccd":"markdown","c053527d":"markdown","73de5106":"markdown","14497e70":"markdown","c04843f8":"markdown","0dfba1e0":"markdown","22fff6dc":"markdown","34b8498e":"markdown","754f2131":"markdown"},"source":{"12310b6d":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \\\n    roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows',None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 170)","15c52274":"df=pd.read_csv(\"..\/input\/testtitanic\/titanic_data.csv\")","aa8947a6":"df.head()","10fe7479":"#Column isimlerini b\u00fcy\u00fct\u00fcyoruz.\ndf.columns = [col.upper() for col in df.columns]","717fee79":"#Bilet numaralar\u0131n\u0131n uzunlu\u011funa bak\u0131yoruz.\ndf[\"TICKET_N\"] = [len(i) for i in df[\"TICKET\"]]","cacbc27d":"#Baz\u0131 bilet numaralar\u0131nda yaln\u0131zca say\u0131 baz\u0131lar\u0131nda ise hem say\u0131 hem harf bulunmakta, bunun ayr\u0131m\u0131n\u0131 \n# yap\u0131yoruz.\nfor i in df[\"TICKET\"]:\n    if i.isdigit():\n        df.loc[(df[\"TICKET\"] == i), \"TICKET_ASCII\"] = 0\n    else:\n        df.loc[(df[\"TICKET\"] == i), \"TICKET_ASCII\"] = 1","6cb08b1a":" df[\"CABIN\"].tail() #G\u00f6r\u00fcld\u00fc\u011f\u00fc gibi bo\u015f de\u011ferler bulunmakta.","e81851bb":"#Cabin numaralar\u0131n\u0131n bo\u015f olma sebebi gemi m\u00fcrettebat\u0131n\u0131n cabin numaras\u0131n\u0131n olmamas\u0131ym\u0131\u015f,\n#Bu y\u00fczden buradaki bo\u015f de\u011ferler de bir anlam ifade etti\u011finden yolcular\u0131n cabin numaras\u0131n\u0131n 1 \n# m\u00fcrettebat\u0131nkinin ise 0 d\u00f6nmesini sa\u011fl\u0131yoruz.\ndf[\"NEW_CABIN_BOOL\"] = df[\"CABIN\"].notnull().astype('int')","dcfdea00":"#\u0130simlerin uzunlu\u011funu sayd\u0131r\u0131yoruz.\ndf[\"NEW_NAME_COUNT\"] = df[\"NAME\"].str.len()","dc33910d":"# sat\u0131rlardaki toplam kelime say\u0131s\u0131na bak\u0131yoruz.\ndf[\"NEW_NAME_WORD_COUNT\"] = df[\"NAME\"].apply(lambda x: len(str(x).split(\" \")))","96f59671":"#Ki\u015filerin unvanlar\u0131na bu regex koduyla ula\u015f\u0131yoruz.\ndf.NAME.str.extract(' ([A-Za-z]+)\\.', expand=False).head()","adaa1679":"df['NEW_TITLE'] = df.NAME.str.extract(' ([A-Za-z]+)\\.', expand=False)","a8174fd0":"#Yolcular\u0131n ka\u00e7 ki\u015fi birlikte(yak\u0131nlar\u0131yla) seyahat etti\u011fini sorguluyoruz.Yaln\u0131z da olabilirler.\ndf[\"NEW_FAMILY_SIZE\"] = df[\"SIBSP\"] + df[\"PARCH\"] + 1","50e189b2":"df.loc[((df['SIBSP'] + df['PARCH']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ndf.loc[((df['SIBSP'] + df['PARCH']) == 0), \"NEW_IS_ALONE\"] = \"YES\"","ffffee03":"# ya\u015flar\u0131 kategorik hale getiriyoruz,gen\u00e7 olgun ya\u015fl\u0131 gibi\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'","b3b0a1d9":"# ya\u015f ile cinsiyeti birlikte de\u011ferlendirmek i\u00e7in bu kodlar\u0131 yaz\u0131yoruz.\ndf.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'young'), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'mature'), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'senior'), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'young'), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'mature'), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'senior'), 'NEW_SEX_CAT'] = 'seniorfemale'","f134f7ab":"def grab_col_names(dataframe, cat_th=10, car_th=20):    \n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car","1515c182":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\nnum_cols","d27cb42b":"def nums_cols_new(df, num_cols):\n    a = df.shape[0]\n    for col in num_cols:\n        if (df.loc[((a) - 1, col)] - df.loc[0, col]) \/ (a - 1) == 1:\n            print(col)\n            num_cols.remove(col)\n    return num_cols","9ff6de89":"num_cols = nums_cols_new(df, num_cols)","dc9abb7a":"num_cols","43b33082":"#Age de\u011fi\u015fkeninin quantile \u00e7eyreklik de\u011ferlerine bak\u0131yoruz.\nq1 = df[\"AGE\"].quantile(0.25)\nq3 = df[\"AGE\"].quantile(0.75)\niqr = q3 - q1\nup = q3 + 1.5 * iqr\nlow = q1 - 1.5 * iqr","29195d31":"#Ayk\u0131r\u0131 de\u011ferleri bask\u0131l\u0131yoruz.\ndf.loc[(df[\"AGE\"] < low), \"AGE\"] = low\ndf.loc[(df[\"AGE\"] > up), \"AGE\"] = up","69639e31":"#Eksik de\u011feri olan t\u00fcm columnlar\u0131 bu \u015fekilde elde ediyoruz.\nna_col = [col for col in df.columns if df[col].isnull().sum() > 0]","b48b33b2":"#En \u00e7ok hangi columnda eksik de\u011fer var ona bak\u0131p s\u0131ral\u0131yoruz.\ndf[na_col].isnull().sum().sort_values(ascending=False)\nn_miss = df[na_col].isnull().sum().sort_values(ascending=False)","d26e632d":"n_miss","1f600c39":"#Bu columnlardan istedi\u011fimiz bilgileri ald\u0131k art\u0131k siliyoruz.\nremove_cols = [\"TICKET\", \"NAME\", \"CABIN\"]\ndf.drop(remove_cols, inplace=True, axis=1)","63a0bf22":"df.isnull().sum()","ab40b20a":"# Age de\u011fi\u015fkenindeki null de\u011ferleri unvanlar\u0131n\u0131n ya\u015f ortalamas\u0131na g\u00f6re dolduruyoruz.\ndf[\"AGE\"] = df[\"AGE\"].fillna(df.groupby(\"NEW_TITLE\")[\"AGE\"].transform(\"median\"))","c53e080a":"# tipi object(kategorik de\u011fi\u015fken) olan ve e\u015fsiz en fazla 10 tane de\u011feri olanlar\u0131n null de\u011ferlerini mode'lar\u0131yla dolduruyoruz.\ndf = df.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0)","685f77b3":"df.isnull().sum().sum()","056140ae":"#Age de\u011ferlerini tekrar kategorize ediyoruz, eksik de\u011ferleri doldurdu\u011fumuz i\u00e7in bu i\u015flemi tekrar yap\u0131yoruz.\ndf[\"NEW_AGE_PCLASS\"] = df[\"AGE\"] * df[\"PCLASS\"]\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'","03fb3c03":"df.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'young'), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'mature'), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['NEW_AGE_CAT'] == 'senior'), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'young'), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'mature'), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['NEW_AGE_CAT'] == 'senior'), 'NEW_SEX_CAT'] = 'seniorfemale'","d0b5ccae":"# numerik olmayan ve yaln\u0131zca iki e\u015fsiz s\u0131n\u0131f\u0131 olan column isimlerini getiriyoruz.\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]","08864bbe":"from sklearn.preprocessing import LabelEncoder","960d405c":"labelencoder = LabelEncoder()\nfor i in binary_cols:\n    df[i] = labelencoder.fit_transform(df[i])","4e217839":"def rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n\ndef rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n                    and (temp_df[col].value_counts() \/ len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n    return temp_df","45e18d0b":"rare_analyser(df, \"SURVIVED\", cat_cols)\ndf = rare_encoder(df, 0.01)","5baf15f9":"# e\u015fsiz s\u0131n\u0131f say\u0131s\u0131 10 ile 2 aras\u0131nda olan column isimlerini getiriyoruz.\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]","fda8d3aa":"#One hot encoding\ndf=pd.get_dummies(df, columns=ohe_cols, drop_first=True)","2efe7ff4":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","0c5911bd":"useless_cols = [col for col in df.columns if\n                df[col].nunique() == 2 and (df[col].value_counts() \/ len(df) < 0.01).any(axis=None)]","0f18f368":"df.drop(useless_cols, axis=1, inplace=True)","3b85ace5":"#Modele katmadan \u00f6nce standartla\u015ft\u0131rma i\u015flemini uyguluyoruz.\nscaler = StandardScaler()","9b30ecfa":"df[num_cols] = scaler.fit_transform(df[num_cols])","46881262":"#Bu bir s\u0131n\u0131fland\u0131rma problemi oldu\u011fundan do\u011frusal s\u0131n\u0131fland\u0131rma modellerinden biri olan logistic regressionu\n# kullan\u0131yoruz.\nfrom sklearn.linear_model import LogisticRegression","0cc936b7":"y = df[\"SURVIVED\"]\nX = df.drop([\"PASSENGERID\", \"SURVIVED\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=46)","c704ed4c":"log_model = LogisticRegression().fit(X_train, y_train)","b5617c2a":"#E\u011fitti\u011fimiz veri setinin modelle tahmin \u00fcretmesini sa\u011fl\u0131yoruz.\ny_pred = log_model.predict(X_train)\naccuracy_score(y_train, y_pred)","8ffcdee8":"#Tahminlerin 1-0 olma olas\u0131l\u0131klar\u0131n\u0131 getiriyor\ny_prob = log_model.predict_proba(X_test)[:, 1]\n\n# Test setinde modelimizi kontrol etme zaman\u0131,tahmin \u00fcretiyoruz.\ny_pred = log_model.predict(X_test)","f5deed98":"# ACCURACY,\n#Do\u011fru tahminlerin t\u00fcm tahminlere oran\u0131n\u0131 verir.\naccuracy_score(y_test, y_pred)","e74d70e7":"# PRECISION\n#Pozitif olarak tahmin edilenlerin do\u011fru tahmin edilme oranlar\u0131n\u0131 verir.\nprecision_score(y_test, y_pred)","73463f84":"# RECALL\n#Ger\u00e7ekte pozitif olan durumlar\u0131n do\u011fru tahmin edilme oran\u0131n\u0131 verir.\nrecall_score(y_test, y_pred)","6a4b6f54":"f1_score(y_test, y_pred)","1d672eae":"# AUC\n# roc e\u011frisinin alt\u0131nda kalan alan\u0131 verir.\nroc_auc_score(y_test, y_prob)","9616165d":"#Veee sonu\u00e7,s\u0131n\u0131fland\u0131rma raporumuza eri\u015ftik.\nprint(classification_report(y_test, y_pred))","d55ea893":"### Kurulan Modelin Ba\u015far\u0131s\u0131n\u0131 \u00d6l\u00e7me","5799eccd":"### Ayk\u0131r\u0131 De\u011ferleri Bask\u0131lama","c053527d":"****TITANIC VER\u0130 SET\u0130N\u0130N HOLDOUT Y\u00d6NTEM\u0130YLE AYRILIP \u00dcZER\u0130NDE SINIFLANDIRMA TAHM\u0130N MODEL\u0130 KURULMASI****","73de5106":"S\u0131n\u0131fland\u0131rma problemlerinde f1-score,auc score,recall ve precision ba\u015far\u0131 de\u011ferlendirme \u00f6l\u00e7\u00fctlerine bak\u0131yoruz.1'e ne kadar yak\u0131nlarsa o kadar mutlu oluyoruz. :)\nG\u00f6r\u00fc\u015fmek \u00fczereeeee :)","14497e70":"### Model Kurma","c04843f8":"### Encoding","0dfba1e0":"### \u00d6zellik Olu\u015fturma","22fff6dc":"### Eksik De\u011ferler","34b8498e":"### Standartla\u015ft\u0131rma","754f2131":"Veri Seti Hakk\u0131nda Bilgi:\nVeri seti Titanic gemi kazas\u0131nda bulunan ki\u015filere ait bilgileri i\u00e7ermektedir.\n768 g\u00f6zlem ve 12 de\u011fi\u015fkenden olu\u015fmaktad\u0131r.\nHedef de\u011fi\u015fken \"Survived\" olarak belirtilmi\u015f olup;\n1, ki\u015finin hayatta kalmas\u0131n\u0131;\n0 ise ki\u015finin hayat\u0131n\u0131 kaybetmesini belirtmektedir.\n\n**Kaynak**: https:\/\/bootcamp.veribilimiokulu.com\/egitim\/veri-bilimci-yetistirme-programi\/"}}