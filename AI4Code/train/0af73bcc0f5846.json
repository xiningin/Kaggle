{"cell_type":{"4c7f861b":"code","6aee9d32":"code","d88cbd55":"code","1646e2b5":"code","4b41e9f6":"code","b095dbe4":"code","ea108f15":"code","3b95c503":"code","3b6ac567":"code","0a8aca37":"code","d32e6e47":"code","18f48d24":"code","b33e5191":"markdown","65bc6860":"markdown","966b6213":"markdown","5c4e3fea":"markdown"},"source":{"4c7f861b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","6aee9d32":"# Load Data\ntrain = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv')\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv')\n\ntrain.rename(columns={\n        'Id': 'id',\n        'Date': 'date',\n        'Province_State':'state',\n        'Country_Region':'country',\n        'ConfirmedCases': 'confirmed',\n        'Fatalities':'deaths',\n        }, inplace=True)\n\ntest.rename(columns={\n        'ForecastId': 'id',\n        'Date': 'date',\n        'Province_State':'state',\n        'Country_Region':'country',\n        }, inplace=True)\n\n\n\nvalid = train[train['date'] >= test['date'].min()]\ntrain = train[(train['date'] < test['date'].min())]\n\nvalid['date'] = pd.to_datetime(valid['date'])\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\n\ntrain['date'] = (train['date'] - pd.Timestamp('2020-03-01')).dt.days\nvalid['date'] = (valid['date'] - pd.Timestamp('2020-03-01')).dt.days\ntest['date']  = (test['date'] - pd.Timestamp('2020-03-01')).dt.days\n\ntrain['loc'] = train['country'].astype(str) + '-' + train['state'].astype(str)\nvalid['loc'] = valid['country'].astype(str) + '-' + valid['state'].astype(str)\ntest['loc'] = test['country'].astype(str) + '-' + test['state'].astype(str)","d88cbd55":"def get_order(max_order):\n    RMSE_order={} #Dict for the key:value pairs of order and RMSE\n    for order in range(1,max_order,1):    #the maximum order for the optimization is set here\n        z = np.polyfit(X_train_.values, y_train_.values, order)\n        pf = np.poly1d(z)\n        \n        y_preds_ = np.round(X_valid_.apply(pf)).clip(lower=y_linear)\n\n        predictions[coords] = y_preds_\n\n        RMSE_get_order=np.sqrt(np.sum(np.square(y_preds_-y_valid_)))\n        RMSE_order[order]=RMSE_get_order\n        result = min(RMSE_order, key=RMSE_order.get)\n    return result","1646e2b5":"all_coords = train['loc'].unique().tolist()\nprint(all_coords)","4b41e9f6":"predictions = dict()\nRMSE = dict()\ntotal_RMSE = 0\nfit_order=1 # If get_order fails the fit_order is set to\nall_orders_used=[]\n#This is for visualising the data. As there are 306 datasets only a fraction of 20 sets can be choosen here\n_, ax = plt.subplots(10,2, figsize=(15, 50))\nax = ax.flatten()\n\nfor k,coords in tqdm(enumerate(all_coords[70:90])):   #Define the part of the dataset you want to look at, e.g. [200:220]\n    X_train_ = train[train['loc']==coords]['date']#.values.reshape(-1,1)\n    y_train_ = train[train['loc']==coords]['confirmed']#.values.reshape(-1,1)\n    \n    X_valid_ = valid[valid['loc']==coords]['date']#.values.reshape(-1,1)\n    y_valid_ = valid[valid['loc']==coords]['confirmed']#.values.reshape(-1,1)\n    \n    last_diff = y_train_.iloc[-1] - y_train_.iloc[-2]\n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_valid_)+1,1)\n    \n    fit_order=get_order(11) # Here the order up to the maximum order is optimized to the data\n    all_orders_used.append(fit_order)\n    \n    z = np.polyfit(X_train_.values, y_train_.values, fit_order)\n    pf = np.poly1d(z)\n        \n    y_preds_ = np.round(X_valid_.apply(pf)).clip(lower=y_linear)\n    \n    predictions[coords] = y_preds_\n    RMSE[coords]=np.sqrt(np.sum(np.square(y_preds_-y_valid_)))\n    total_RMSE += np.sqrt(np.sum(np.square(y_preds_-y_valid_)))\n\n    sns.lineplot(x=valid[valid['loc']==coords]['date'], y=valid[valid['loc']==coords]['confirmed'], label='y-valid',ax=ax[k])\n    sns.lineplot(x=train[train['loc']==coords]['date'], y=train[train['loc']==coords]['confirmed'], label='y-train',ax=ax[k])\n    sns.lineplot(x=valid[valid['loc']==coords]['date'], y=y_preds_, label='y-preds',ax=ax[k])\n    ax[k].set_title(f'Confirmed cases: ({coords})')\n\n\nprint(total_RMSE)\nprint(all_orders_used)","b095dbe4":"all_coords = train['loc'].unique().tolist()\npredictions = dict()\nRMSE = dict()\ntotal_RMSE = 0\nfit_order=1 # If get_order fails the fit_order is set to\nall_orders_used=[]\n\n#This is for visualising the data. As there are 306 datasets only a fraction of 20 sets can be choosen here\n_, ax = plt.subplots(10,2, figsize=(15, 50))\nax = ax.flatten()\n\nfor k,coords in tqdm(enumerate(all_coords[260:280])): #Define the part of the dataset you want to look at\n    \n    X_train_ = train[train['loc']==coords]['date']#.values.reshape(-1,1)\n    y_train_ = train[train['loc']==coords]['deaths']#.values.reshape(-1,1)\n    \n    X_valid_ = valid[valid['loc']==coords]['date']#.values.reshape(-1,1)\n    y_valid_ = valid[valid['loc']==coords]['deaths']#.values.reshape(-1,1)\n    \n    last_diff = y_train_.iloc[-1] - y_train_.iloc[-2]\n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_valid_)+1,1)\n    \n    fit_order=get_order(11)\n    all_orders_used.append(fit_order)\n\n    z = np.polyfit(X_train_.values, y_train_.values, fit_order)\n    pf = np.poly1d(z)\n        \n    y_preds_ = np.round(X_valid_.apply(pf)).clip(lower=y_linear)\n    \n    predictions[coords] = y_preds_\n    RMSE[coords]=np.sqrt(np.sum(np.square(y_preds_-y_valid_)))\n    total_RMSE += np.sqrt(np.sum(np.square(y_preds_-y_valid_)))\n\n    sns.lineplot(x=valid[valid['loc']==coords]['date'], y=valid[valid['loc']==coords]['deaths'], label='y-valid',ax=ax[k])\n    sns.lineplot(x=train[train['loc']==coords]['date'], y=train[train['loc']==coords]['deaths'], label='y-train',ax=ax[k])\n    sns.lineplot(x=valid[valid['loc']==coords]['date'], y=y_preds_, label='y-preds',ax=ax[k])\n    ax[k].set_title(f'Fatalities: ({coords})')\n    \nprint(total_RMSE)\nprint(all_orders_used)","ea108f15":"submission = pd.DataFrame()\nsubmission['loc'] = test['loc']\nsubmission.reset_index(inplace=True)\n\nsubmission['ConfirmedCases'] = 0\nsubmission['Fatalities'] = 0","3b95c503":"all_coords = train['loc'].unique().tolist()\npredictions = dict()\nRMSE = dict()\ntotal_RMSE = 0\nfit_order=1\n\nfor coords in all_coords:\n    \n    X_train_ = train[train['loc']==coords]['date']#.values.reshape(-1,1)\n    y_train_ = train[train['loc']==coords]['confirmed']#.values.reshape(-1,1)\n    \n    X_valid_ = valid[valid['loc']==coords]['date']#.values.reshape(-1,1)\n    y_valid_ = valid[valid['loc']==coords]['confirmed']#.values.reshape(-1,1)\n    \n    X_test_ = test[test['loc']==coords]['date']#.values.reshape(-1,1)\n    \n    last_diff = y_train_.iloc[-1] - y_train_.iloc[-2]\n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_valid_)+1,1)\n    \n    fit_order=get_order(11)\n    \n    z = np.polyfit(X_train_.values, y_train_.values, fit_order)\n    pf = np.poly1d(z)\n    \n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_test_)+1,1)\n        \n    y_preds_ = np.round(X_test_.apply(pf)).clip(lower=y_linear)\n    \n\n    submission.loc[submission['loc']==coords,'ConfirmedCases'] = y_preds_","3b6ac567":"all_coords = train['loc'].unique().tolist()\npredictions = dict()\nRMSE = dict()\ntotal_RMSE = 0\n\nfit_grade=1\n\nfor coords in all_coords:\n    \n    X_train_ = train[train['loc']==coords]['date']#.values.reshape(-1,1)\n    y_train_ = train[train['loc']==coords]['deaths']#.values.reshape(-1,1)\n    \n    X_valid_ = valid[valid['loc']==coords]['date']#.values.reshape(-1,1)\n    y_valid_ = valid[valid['loc']==coords]['deaths']#.values.reshape(-1,1)\n    \n    X_test_ = test[test['loc']==coords]['date']#.values.reshape(-1,1)\n    \n    last_diff = y_train_.iloc[-1] - y_train_.iloc[-2]\n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_valid_)+1,1)\n    \n    fit_order=get_order(11)\n\n    z = np.polyfit(X_train_.values, y_train_.values, fit_order)\n    pf = np.poly1d(z)\n        \n    y_linear = y_train_.iloc[-1] + last_diff*np.arange(1,len(X_test_)+1,1)\n    \n    y_preds_ = np.round(X_test_.apply(pf)).clip(lower=y_linear)\n    \n\n    \n    submission.loc[submission['loc']==coords,'Fatalities'] = y_preds_","0a8aca37":"submission.drop('loc', axis=1, inplace=True)\nsubmission['index'] = submission['index'] + 1\nsubmission.rename(columns={\n    'index' : 'ForecastId'}, inplace=True)","d32e6e47":"submission","18f48d24":"submission.to_csv('submission.csv', index=False)","b33e5191":"The result shows that many different orders are used for the best polynomial fit.\nBut a higher order than 10 does not decrease the RMSE significantly","65bc6860":"To get an optimized order of the polynomial I defined the function get_order. This function can be added in the model","966b6213":"Playing with the model and getting an idea of what's happening ...\n\n**Beginning with confirmed cases**","5c4e3fea":"**... and the fatalities**"}}