{"cell_type":{"96f28a2c":"code","d4d33aaa":"code","f9ca2184":"code","d3774aca":"code","0810bb98":"code","d339bbb3":"code","dc4a085b":"code","f4669431":"code","6257ac80":"code","aad6e570":"code","98ac214f":"code","2ff174d2":"code","d27472dd":"code","d0b13860":"code","bcb720b1":"code","3081d610":"code","57b6dce8":"code","1d5e3cdb":"code","dd06618d":"code","9f02f3c6":"code","06368774":"code","2d2af3e3":"code","7ddcc338":"code","c1b23d69":"code","30dd06c2":"code","36169d01":"code","a134ac75":"code","581f0afc":"code","f3e7d142":"code","489537af":"code","81e1fbb9":"code","86cce855":"code","4c3f2c33":"code","df24f59d":"code","837841d4":"code","075ec462":"code","68689dd7":"markdown","1127bf04":"markdown","8cb3c5e8":"markdown","955b5788":"markdown","6df0961a":"markdown","0406f211":"markdown","67ed60d5":"markdown","9f4cd2e6":"markdown","0d563ba8":"markdown","1555833a":"markdown","5a0a384c":"markdown","696f4c05":"markdown","82d96881":"markdown","e60bf693":"markdown","72fd00ba":"markdown","7a676db7":"markdown","53f430c2":"markdown","b1a8bacd":"markdown","295ec10f":"markdown","d76595c6":"markdown","88845075":"markdown","041a6e8a":"markdown","6eca7876":"markdown","404a1df6":"markdown","20742c3c":"markdown","8d6717f5":"markdown"},"source":{"96f28a2c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, Flatten","d4d33aaa":"(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()","f9ca2184":"print(len(X_train))\nprint(len(y_train))\nprint(len(X_test))\nprint(len(y_test))\n","d3774aca":"X_train[0]","0810bb98":"X_train[0].shape","d339bbb3":"plt.matshow(X_train[0])","dc4a085b":"y_train[0]","f4669431":"X_train = X_train \/ 255\nX_test = X_test \/ 255","6257ac80":"X_train[0]","aad6e570":"X_train.shape","98ac214f":"X_train_flattened = X_train.reshape(len(X_train), 28*28)","2ff174d2":"X_train_flattened.shape","d27472dd":"X_test.shape","d0b13860":"X_test_flattened = X_test.reshape(len(X_test), 28*28)","bcb720b1":"X_test_flattened.shape","3081d610":"model = keras.Sequential()\n\nmodel.add(Dense(10, input_shape = (784,), activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","57b6dce8":"model.fit(X_train_flattened, y_train, epochs = 5)","1d5e3cdb":"model.evaluate(X_test_flattened, y_test)[1]","dd06618d":"y_pred = model.predict(X_test_flattened)","9f02f3c6":"plt.matshow(X_test[0])","06368774":"y_pred[0]","2d2af3e3":"np.argmax(y_pred[0])","7ddcc338":"y_pred_labels = [np.argmax(i) for i in y_pred]\ny_pred_labels[:5]","c1b23d69":"cm = tf.math.confusion_matrix(labels = y_test, predictions = y_pred_labels)\n\nsns.heatmap(cm, annot = True, fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nplt.show()","30dd06c2":"model = keras.Sequential()\n\nmodel.add(Dense(100, input_shape = (784,), activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","36169d01":"model.fit(X_train_flattened, y_train, epochs = 5)","a134ac75":"model.evaluate(X_test_flattened, y_test)[1]","581f0afc":"y_pred = model.predict(X_test_flattened)","f3e7d142":"y_pred_labels = [np.argmax(i) for i in y_pred]\ny_pred_labels[:5]","489537af":"cm = tf.math.confusion_matrix(labels = y_test, predictions = y_pred_labels)\n\nsns.heatmap(cm, annot = True, fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nplt.show()","81e1fbb9":"model = keras.Sequential()\n\nmodel.add(Flatten(input_shape = (28, 28)))\nmodel.add(Dense(100, activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 5)","86cce855":"model.evaluate(X_test, y_test)[1]","4c3f2c33":"model = keras.Sequential()\n\nmodel.add(Flatten(input_shape = (28, 28)))\nmodel.add(Dense(100, activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'RMSprop',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 5)\n\nmodel.evaluate(X_test, y_test)[1]","df24f59d":"model = keras.Sequential()\n\nmodel.add(Flatten(input_shape = (28, 28)))\nmodel.add(Dense(100, activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'SGD',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 5)\n\nmodel.evaluate(X_test, y_test)[1]","837841d4":"model = keras.Sequential()\n\nmodel.add(Flatten(input_shape = (28, 28)))\nmodel.add(Dense(100, activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'Adadelta',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 5)\n\nmodel.evaluate(X_test, y_test)[1]","075ec462":"model = keras.Sequential()\n\nmodel.add(Flatten(input_shape = (28, 28)))\nmodel.add(Dense(100, activation = 'relu'))\nmodel.add(Dense(10, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'Nadam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 5)\n\nmodel.evaluate(X_test, y_test)[1]","68689dd7":"<br\/>\n\n## **Shape of X_train**\n\n60000 - Number of images  \n28 - Height of the images  \n28 - width of the images","1127bf04":"## **Importing necessary modules**","8cb3c5e8":"<br\/>\n\n## **After scalling**\nAfter scalling, the pixel values will look like this. Now they all come in the range of 0 to 1.","955b5788":"<br\/>\n\n## **We are done! Now it's time for playing with our models. Let's see how Changing hyper-parameters, Adding hidden layers will affect our models**\n<br\/>\n<br\/>\n\n## **Adding a hidden layer to check the new performance**\n\n","6df0961a":"<br\/>\n\n## **Let's see how accurately our model can predict**\nPick up the 1st image of X_test. It's seven.","0406f211":"<br\/>\n\n## **This is just an alternative manner, So don't expected the model evaluation score to be improved**\n<br\/>\n<br\/>\n\n## **Let's try other optimizers**","67ed60d5":"<br\/>\n\n## **After flattening**","9f4cd2e6":"<br\/>\n\n## **Time for creating a confusion matrix**","0d563ba8":"<br\/>\n\n## **Flattening X_train**\nFlattening the image means convert the 28*28 array in one layer","1555833a":"<br\/>\n\n## **Note:**  \nIf we can remember, we just flattened the 28 x 28 image pixels in one layer. Set that layer to variable X_train_flattened and put that when we were training our models.  \n**Alternative:**  \nBut we can also do the same thing in an alternative manner. we can add a Flattening layer to our model architecture and it will flatten the image pixels into one layer. So this time, when we will train our model, we will use X_train variable instead of X_train_flattened as our image pixels will be flattened in the model architecture.","5a0a384c":"<br\/>\n\n## **Now let's see what the label of the iamge says?**\nIt's also five as expected.","696f4c05":"<br\/>\n\n## **Load the Mnist Dataset**","82d96881":"<br\/>\n\n## **Number of images in each set**\n\nwe got 60000 images for training and 10000 for testing!","e60bf693":"<br\/>\n\n## **Prediction**","72fd00ba":"<br\/>\n\n## **Evaluation of the model**","7a676db7":"<br\/>\n\n## **Scalling**\nwell, now we come to the most important part of building a model - scalling.  \nI built a model without scalling. It gave me a score about 40 to 50%. Then I scaled the features. See the difference in the score in your own eye!","53f430c2":"<br\/>\n\n## **Doing the same thing for X_test**","b1a8bacd":"<br\/>\n\n## **First image of X_train set**\nThis output shows the pixel values of that iamge. The range of the pixel values is 0 to 255.","295ec10f":"<br\/>\n\n## **Now converting all the probabilities into their corresponding index by argmax along with list comprehension**","d76595c6":"## **Now see what our model predicted**\nWell, don't afraid. this values are just the probabilities of being the digit from 0 to 1.  \nAll we have to do is to find the index with the highest probability. So here comes up **np.argmax**.","88845075":"<br\/>\n\n## **Wow! By adding just one hidden layer, our model evaluation score becomes 97% from 92%!**","041a6e8a":"<br\/>\n<br\/>\n\n**Thanks for the patience. Don't forget to share your thoughts along with suggestions in this regard. And if you find it helpful, please upvote.**","6eca7876":"<br\/>\n\n## **Let's see the image**\nIt's a five.","404a1df6":"<br\/>\n\n## **Shape of the image**\nBasically it indicates the pixel size of an image.  \n1st element of the tuple - image height  \n2nd element of the tuple - image width","20742c3c":"<br\/>\n\n## **Model Architecture**","8d6717f5":"<br\/>\n\n## **Train the model**"}}