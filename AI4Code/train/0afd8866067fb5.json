{"cell_type":{"47c9a9d7":"code","572dbe6f":"code","45c1ac85":"code","a6f2a0c6":"code","17aed358":"code","a7bb908f":"code","1babf765":"code","3ea4112b":"code","bfdf7bae":"code","29ea536f":"code","06b27443":"code","6e242fdb":"code","48bc89fb":"code","a95a72c3":"code","1f88682d":"code","ee0f8427":"code","a526d46e":"code","faa5fba8":"code","0c903ed7":"code","f178c390":"code","446add2a":"code","1bc6a0dc":"code","868795db":"code","181899dd":"code","d1142452":"code","1b4aba68":"code","8b59eb8c":"code","aa21951e":"code","9d8863a1":"code","43aadb30":"code","1ae99217":"code","8504b7a6":"code","60d2d2a8":"code","50a66234":"code","c61c670e":"code","dea5f8fb":"code","b9bf4dcb":"code","6ab940b1":"code","b79224cd":"code","905d15db":"markdown"},"source":{"47c9a9d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","572dbe6f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD,PCA\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","45c1ac85":"df_train = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/train_users_2.csv.zip') # Training Set\ndf_test = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/test_users.csv.zip') # Testing Set\ndf_original = df_train.copy()","a6f2a0c6":"df_train.head() # Head of the dataframe","17aed358":"print(\"The Dimensions of the training set is \" , df_train.shape)\nprint(\"The Dimensions of the testing set is \",df_test.shape)","a7bb908f":"labels = df_train['country_destination'].values\n\ndf_train.drop('country_destination',axis=1,inplace=True) # Droping Target Variable","1babf765":"# Concatenating training and testing sets for further use\ndf_all = pd.concat([df_train,df_test],axis=0,ignore_index=True) ","3ea4112b":"print(\"The Dimensions of Total Set is \",df_all.shape)","bfdf7bae":"# Function that returns the missing percentage of each column in the dataset.\ndef missing_percentage(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = total\/len(df)*100\n    df = pd.concat([total,percent],axis=1,keys=['Total','Percent'])\n    return df.sort_values(by='Percent',ascending=False)","29ea536f":"missing_percentage(df_all) # No need to store in a variable","06b27443":"# Droping 'date_first_booking' column as it is having roughly 67% missing data \ndf_all.drop(['id','date_first_booking'],axis=1,inplace=True)\ndf_all.head()","6e242fdb":"df_all['date_dac'] = df_all['date_account_created'].apply(lambda x:x.split('-')[2])\ndf_all['date_dac'] = df_all['date_dac'].astype('int')\n\n# We can also do this following like above \"date_dac\" column.\ndf_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'])\ndf_all['month_dac'] = df_all['date_account_created'].apply(lambda x:x.month)\ndf_all['year_dac'] = df_all['date_account_created'].apply(lambda x:x.year)\n\n# No further use of 'date_account_created' column because we retrieved every information from it.\ndf_all.drop('date_account_created',axis=1,inplace=True)","48bc89fb":"# Retrieving year,month and date from timestamp.\ntfa = np.vstack(df_all.timestamp_first_active.astype(str).\n                apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)","a95a72c3":"df_all['tfa_year'] = tfa[:,0]\ndf_all['tfa_month'] = tfa[:,1]\ndf_all['tfa_date'] = tfa[:,2]","1f88682d":"df_all = df_all.drop('timestamp_first_active',axis=1)","ee0f8427":"# Function that returns the Categorical columns\ndef Categorical(df):\n    categories = []\n    for column in df.columns:\n        if df[column].dtype =='object' or len(df[column].value_counts()) < 20:\n            categories.append(column)\n    return categories","a526d46e":"Categories = Categorical(df_all)\n\n# Some of the Categorical columns are int-type. So, Changed them to object.\ndf_all[Categories] = df_all[Categories].astype('object')\n\nCategories","faa5fba8":"missing_percentage(df_all)","0c903ed7":"order1 = df_original['country_destination'].value_counts()\norder2 = order1.index\nplt.figure(figsize=(10,7))\nsns.countplot(df_original['country_destination'],order=order2)\nplt.xlabel('Country Destination')\nplt.ylabel('Country Destination Count')\nfor i in range(order1.shape[0]):\n    count = order1[i]\n    strg = '{:0.2f}%'.format(100*count\/df_all.shape[0])\n    plt.text(i,count+1000,strg,ha='center')","f178c390":"sns.set_style('whitegrid')\nplt.figure(figsize=(10,7))\nsns.distplot(df_all['age'].dropna(),kde=False,bins=50)\nplt.xlabel('Age')\nplt.ylabel('Age Count')\nplt.title('The Distribution of Age')","446add2a":"order1 = df_all['gender'].value_counts()\norder2 = order1.index\nplt.figure(figsize=(10,7))\nsns.countplot(df_all['gender'],order=order2)\nplt.xlabel('Gender')\nfor i in range(order1.shape[0]):\n    count = order1[i]\n    strg = '{:0.2f}%'.format(100*count\/df_all.shape[0])\n    plt.text(i,count+1000,strg,ha='center')","1bc6a0dc":"order1 = df_all['signup_method'].value_counts()\norder2 = order1.index\nplt.figure(figsize=(10,7))\nsns.countplot(df_all['signup_method'],order=order2)\nplt.xlabel('Signup Method')\nfor i in range(order1.shape[0]):\n    count = order1[i]\n    strg = '{:0.2f}%'.format(100*count\/df_all.shape[0])\n    plt.text(i,count+1000,strg,ha='center')","868795db":"plt.figure(figsize=(12,7))\nsns.countplot(df_original['country_destination'],hue=df_original['gender'])","181899dd":"# Filling 'first_affiliate_tracked' column using Random Forest Classifier\n\ndef completing_fa_tracked(df):\n    age = df['age']\n    df = df.drop('age',axis=1)\n    y = df['first_affiliate_tracked']\n    df.drop('first_affiliate_tracked',axis=1,inplace=True)\n    \n    cato = Categorical(df)\n    onehot = pd.get_dummies(df[cato],drop_first = True)\n    df = df.drop(cato,axis=1)\n    df = pd.concat([df,onehot],axis=1)\n    df = pd.concat([df,y],axis=1)\n    \n    temp_train = df.loc[df.first_affiliate_tracked.notnull()] \n    temp_test = df.loc[df.first_affiliate_tracked.isnull()]\n    \n    X_train= temp_train.drop('first_affiliate_tracked',axis=1)\n    y_train = temp_train['first_affiliate_tracked']\n    X_test = temp_test.drop('first_affiliate_tracked',axis=1)\n    \n    le = LabelEncoder()\n    le.fit(y_train)\n    y_train = le.transform(y_train)\n    \n    pca = PCA(n_components=12)\n    pca.fit(X_train)\n    X_train_pca = pca.transform(X_train)\n    X_test_pca = pca.transform(X_test)\n    \n    \n    rfc = RandomForestClassifier(n_estimators=400, n_jobs=-1)\n    rfc.fit(X_train_pca, y_train)\n    predicted_fa = rfc.predict(X_test_pca)\n    \n    print(\"score:\" ,rfc.score(X_train_pca,y_train))\n    \n    df.loc[df.first_affiliate_tracked.notnull(),\"first_affiliate_tracked\"] = y_train\n    df.loc[df.first_affiliate_tracked.isnull(), \"first_affiliate_tracked\"] = predicted_fa\n    df['age'] = age\n    \n    df['first_affiliate_tracked'] = df['first_affiliate_tracked'].astype('object')\n    fa_t = pd.get_dummies(df['first_affiliate_tracked'],drop_first=True)\n    df = df.drop('first_affiliate_tracked',axis=1)\n    df = pd.concat([df,fa_t],axis=1)\n    \n    return df","d1142452":"df_all = completing_fa_tracked(df_all)","1b4aba68":"df_all.head()","8b59eb8c":"missing_percentage(df_all)","aa21951e":"# Filling 'age' column using Random Forest Regressor\n\ndef completing_age(df):\n    \n    temp_train = df.loc[df.age.notnull()] \n    temp_test = df.loc[df.age.isnull()]\n    \n    X_train= temp_train.drop('age',axis=1)\n    y_train = temp_train['age']\n    X_test = temp_test.drop('age',axis=1)\n\n    pca = PCA(n_components=12)\n    pca.fit(X_train)\n    X_train_pca = pca.transform(X_train)\n    X_test_pca = pca.transform(X_test)\n    \n    # Truncated SVD Can work efficiently with Sparse dataset. So it's better to use.\n    \n    t_svd = TruncatedSVD(n_components=12) \n    t_svd.fit(X_train)\n    X_train_tsvd = t_svd.transform(X_train)\n    X_test_tsvd = t_svd.transform(X_test)\n    \n    X_train_new = np.concatenate([X_train_pca,X_train_tsvd],axis=1)\n    X_test_new = np.concatenate([X_test_pca,X_test_tsvd],axis=1)\n    \n    rfr = RandomForestRegressor(n_estimators=400, n_jobs=-1)\n    rfr.fit(X_train_new, y_train)\n    predicted_age = rfr.predict(X_test_new)\n    \n    print(\"score:\" ,rfr.score(X_train_new,y_train))\n    \n    df.loc[df.age.notnull(),\"age\"] = y_train\n    df.loc[df.age.isnull(), \"age\"] = predicted_age\n    \n    return df","9d8863a1":"df_all = completing_age(df_all)","43aadb30":"missing_percentage(df_all)","1ae99217":"df_all['age'] = df_all['age'].astype('int32') # Converting float to int.","8504b7a6":"df_all.head()","60d2d2a8":"train = df_all.iloc[0:len(df_train),:]\ntest = df_all.iloc[len(df_train):,:]","50a66234":"le = LabelEncoder()\n# Label Encoding the labels \n\ny = le.fit_transform(labels)","c61c670e":"xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \nxgb.fit(train, y)","dea5f8fb":"# Predictions using predict_proba to get the probabilities of classes\n\ny_pred = xgb.predict_proba(test)","b9bf4dcb":"# Considering the 5 Classes with Highest Probabilities\nid_test = df_test['id']\nids = []\ncts = []\nfor i in range(len(id_test)):\n    idx = id_test[i]\n    ids += [idx] * 5\n    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()","6ab940b1":"# Submission \nsub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsub.to_csv('sub.csv',index=False)","b79224cd":"filename = 'Airbnb.pkl'\n\n# Saving model using pickle\npickle.dump(xgb, open(filename, 'wb'))","905d15db":"## Hurrah ..!! Successfully filled Missing values."}}