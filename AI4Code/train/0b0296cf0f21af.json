{"cell_type":{"f1d2ba93":"code","b80d76fe":"code","7ee780ac":"code","2e7d959d":"code","df172211":"code","cec5b317":"code","a852a7b1":"code","986418d7":"code","42823a13":"code","e2293358":"code","aec88e87":"code","40c166ff":"code","1b2a01dd":"code","cb729d7e":"code","d93c9a61":"code","6b116cdd":"code","eaed691d":"code","960715f7":"code","884257cd":"code","4cfe0fd0":"code","2ee65b9a":"code","9fc28588":"code","cb16978a":"code","41f928fc":"markdown","d9901a29":"markdown","3ce90e11":"markdown","cf971947":"markdown","1c067923":"markdown","3ba3811f":"markdown","77508b9d":"markdown","69ac0b65":"markdown","52509fce":"markdown","621401b3":"markdown","8a290044":"markdown","84c88256":"markdown","66ecb037":"markdown","c8d19420":"markdown","daed97ea":"markdown","100af23a":"markdown","68e6cc5a":"markdown","4b9f8a3a":"markdown","0c3bb7e5":"markdown","30be0f2e":"markdown","55ee43bf":"markdown"},"source":{"f1d2ba93":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b80d76fe":"train = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/sample_submission.csv')","7ee780ac":"train.head(5)","2e7d959d":"sns.violinplot(data=train, y='TARGET(PRICE_IN_LACS)')\nplt.show()","df172211":"train['TARGET(PRICE_IN_LACS)'].describe()","cec5b317":"train[train['TARGET(PRICE_IN_LACS)']>3999]","a852a7b1":"train[train['SQUARE_FT']>10000000]","986418d7":"f, axes = plt.subplots(1,1,figsize=(15,5))\nsns.scatterplot(data=train, x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)')\nplt.show()","42823a13":"f, axes = plt.subplots(1,2,figsize=(15,5))\nsns.scatterplot(data=train[train['SQUARE_FT']<399999], x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)', ax=axes[0])\nsns.scatterplot(data=train[train['SQUARE_FT']>399999], x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)', ax=axes[1])\nplt.show()","e2293358":"def get_city_name(address):\n    return address[address.find(',')+1:]\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)","aec88e87":"len(train['CITY'].unique())","40c166ff":"def BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)","1b2a01dd":"train['BHK_NO.']","cb729d7e":"train.columns","d93c9a61":"features = ['POSTED_BY', 'UNDER_CONSTRUCTION', 'RERA', 'BHK_NO.', \n            'BHK_OR_RK', 'READY_TO_MOVE', 'RESALE']\n\nfor feature in features:\n\n    f, axes = plt.subplots(1,2,figsize=(15,5))\n\n    sns.countplot(data=train, x=feature, ax=axes[0])\n    sns.violinplot(data=train, x=feature, y='TARGET(PRICE_IN_LACS)', ax=axes[1])\n    plt.show()","6b116cdd":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","eaed691d":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","960715f7":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","884257cd":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df['SQUARE_FT'].to_numpy().reshape(-1, 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","4cfe0fd0":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\n\ndef get_city_name(address):\n    return address[address.find(',')+1:]\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","2ee65b9a":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\n\ndef get_city_name(address):\n    return address[address.find(',')+1:]\n\n\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)\n\ndef BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","9fc28588":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\n\n\ndef BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","cb16978a":"df = pd.read_csv('\/kaggle\/input\/house-price-prediction-challenge\/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","41f928fc":"# The other categorical features","d9901a29":"## Using only the area of the house\n\nAll the r2 scores are worse than the previous scenario. However, this can be because of the outliers present in both the price and area.","3ce90e11":"My main interest in the dataset will be how the different features affect the price and then building some kind of a model for prediction.\n\nAll the features are categorical expect Square feet.\n\nAs a side task, I will also try to create some kind of a map using the Longitudes and Latitudes features.\n\nSince the test dataset has no actuals available, I will further split the train dataset into test and train dataset for testing the accuracy of the model.","cf971947":"# Extracting city out of address","1c067923":"The difference between the median and the mean clearly shows the outliers. The maximum price is 30,000  Lacs. Is this a data error? ","3ba3811f":"# Converting more than 5 BHK to 5 BHK","77508b9d":"Taking a look at houses of area more than 10,000,000:","69ac0b65":"# And the winner is:","52509fce":"# STATUS: MARKED AS FINAL","621401b3":"I found three houses with price which I will classify as outliers. They are located in Bangalore and have a huge area covering. In fact these are the only ones which have an area of more than 10,000,000 square feet.","8a290044":"# Train and test data\n\nI will further split the train data available to test and train.\n\nI will experiment with the different type of data transformations.\n\nIn all scenarios, the decision tree regressor is gving a better accuracy.","84c88256":"# Area covered and relation to price","66ecb037":"# House Price Prediction Challenge\n\nWelcome to the House Price Prediction Challenge, you will test your regression skills by designing an algorithm to accurately predict the house prices in India. Accurately predicting house prices can be a daunting task. The buyers are just not concerned about the size(square feet) of the house and there are various other factors that play a key role to decide the price of a house\/property. It can be extremely difficult to figure out the right set of attributes that are contributing to understanding the buyer's behavior as such. This dataset has been collected across various property aggregators across India. In this competition, provided the 12 influencing factors your role as a data scientist is to predict the prices as accurately as possible.\n\nAlso, in this competition, you will get a lot of room for feature engineering and mastering advanced regression techniques such as Random Forest, Deep Neural Nets, and various other ensembling techniques. ","c8d19420":"Hmm.. This actually showed slightly reduced performance compared to when we were using full addresses..","daed97ea":"# Exploring the data\n\n## Taking a look at the price column\n\nLooks like there is an outlier in the dataset.","100af23a":"## Dropping the address, latitude and logitude columns\n\nThe linear regression model has improved a lot, however a long way to coming closer to the decision tree regressor. Ridge and lasso still has no change. ","68e6cc5a":"# Extracting the cities","4b9f8a3a":"# First look at data\n\nThe following are the features available in the dataset:\n\n1. POSTED_BY \t         - Category marking who has listed the property\n2. UNDER_CONSTRUCTION    - Under Construction or Not\n3. RERA \t- Real Estate (Regulation and Development) Act, 2016\n4. BHK_NO \t- Number of Rooms\n5. BHKORRK \t- Type of property -  Room and Kitchen (RK) or Bedroom, Hall, Kitchen (BHK)\n6. SQUARE_FT \t- Total area of the house in square feet\n7. READYTOMOVE - \tCategory marking Ready to move or Not\n8. RESALE \t- Category marking Resale or not\n9. ADDRESS \t- Address of the property\n10. LONGITUDE - \tLongitude of the property\n11. LATITUDE - \tLatitude of the property\n\nThe target column is the Price in Lacs.","0c3bb7e5":"## Dropping the latitude and logitude columns\n\n\nThe decision tree regressor has improved. The linear regression still has a r2 score in negative.. Ridge and Lasso is almost the same as before..","30be0f2e":"# Using transformed BHK feature","55ee43bf":"## The lazy model\n\nUsing the dataset as it is, the winner is decision tree regressor. The linear regression has a r2 score in negative.."}}