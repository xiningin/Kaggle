{"cell_type":{"14b4c846":"code","645ea01a":"code","4b643c83":"code","174ede58":"code","771edd29":"code","f6b61baa":"code","9662649f":"code","8423b374":"markdown","fb06935d":"markdown","acc15df9":"markdown","4792de1d":"markdown","4a0d90f5":"markdown","48eb1243":"markdown","8538da7c":"markdown","388da86a":"markdown","d6af948d":"markdown"},"source":{"14b4c846":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))","645ea01a":"train_all = pd.read_csv(\"..\/input\/opt_digits_train.csv\")\ntrain_all = train_all.reset_index(drop=True)\nlabels = train_all.iloc[:,64]\ntrain_all = train_all.drop(labels = [\"64\"],axis = 1) ","4b643c83":"clusters = np.zeros(len(train_all))\nk = 20\nn = train_all.shape[0]\nc = train_all.shape[1]\nmean = np.mean(train_all, axis = 0)\nstd = np.std(train_all, axis = 0)\ncenters = np.random.randn(k,c) + mean.values.reshape(1,64)","174ede58":"centers_L2 = centers.copy()\ncenters_old = np.zeros(centers.shape) \ncenters_new = centers.copy() \n\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\nerror = np.linalg.norm(centers_new - centers_old)","771edd29":"while error != 0:\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(train_all - centers_new[i], axis=1,ord=1) #L1 distances \n\n    clusters = np.argmin(distances, axis = 1)\n    centers_old = centers_new.copy()\n\n    for i in range(k):\n        centers_new[i] = np.mean(train_all[clusters == i], axis=0)\n        \n    error = np.linalg.norm(centers_new - centers_old)","f6b61baa":"cluster_separete= []\ny = []\n\nfor m in range(20):\n    cluster_separete.append(labels[clusters == m])\nfor a in range(20):\n    x = []\n    for b in range(10):\n        x.append((cluster_separete[a]==b).sum())   \n    y.append(np.argmax(x))\n\ntotal_error = 0\nfor z in range(20):\n    total_true = (cluster_separete[z] == y[z]).sum()\n    total_error = total_error+ cluster_separete[z].shape[0]-total_true\n    \nk_means_clustering_error = total_error\/train_all.shape[0] ","9662649f":"centers_old_L2 = np.zeros(centers_L2.shape) # to store old centers\ncenters_new_L2 = centers_L2.copy() # Store new centers\nclusters_L2 = np.zeros(n)\n\ndistances_L2 = np.zeros((n,k))\nerror_L2 = np.linalg.norm(centers_new_L2 - centers_old_L2)\ni = 0 \nwhile error_L2 != 0:\n    for i in range(k):\n        distances_L2[:,i] = np.linalg.norm(train_all - centers_new_L2[i],axis=1)  #L2 distances \n    clusters_L2 = np.argmin(distances_L2, axis = 1)\n    centers_old_L2 = centers_new_L2.copy()\n    for i in range(k):\n        centers_new_L2[i] = np.mean(train_all[clusters_L2 == i], axis=0)        \n    error_L2 = np.linalg.norm(centers_new_L2 - centers_old_L2)\n\n\n\ncluster_seperate_L2 = []\ny_L2 = []\n\nm = 0\nfor m in range(20):\n    cluster_seperate_L2.append(labels[clusters_L2 == m])\nfor a in range(20):\n    x = []\n    for b in range(10):\n        x.append((cluster_seperate_L2[a]==b).sum())   \n    y_L2.append(np.argmax(x))\n    \ntotal_error_L2 = 0\nfor z in range(20):\n    total_true_L2 = (cluster_seperate_L2[z] == y_L2[z]).sum()\n    total_error_L2 = total_error_L2+ cluster_seperate_L2[z].shape[0]-total_true_L2\n\nk_means_clustering_error_L2 = total_error_L2\/train_all.shape[0] \n\nprint('Q3-k_means_clustering_error L1 and L2')\nprint(k_means_clustering_error)\nprint(k_means_clustering_error_L2)","8423b374":"## Step 2\nDetermine randomly k means center. \nk = 20 ","fb06935d":"## K Means Clustering not using any framework\n\nK means Clustering is a type of unsupervised learning. The goal of this algortihm is to find groups in the data. L1 and L2 distance are used.\n\n\nReference to this book. : Ethem Alpayd\u0131n Introduction to Machine Learning, third edition\n\n\n","acc15df9":"## Step 4\n* K = 20, \n* Number of Label  = 10 \n* Clusters is assigned to each label.\n* Calculate error - True Labels and Clusters labels","4792de1d":"## Step 3\n* Find the distances of all figures to the centers and label them with the smallest distance\n* Each data point is assigned to its nearest centroid. \n* The centroids are recomputed.\n* If error equals zero, stop loop (No data points change clusters)","4a0d90f5":"## Step 3\n* Store old centers\n* Store new centers\n* Error equals ( New center - Old centers)","48eb1243":"L2 distances is the best solutions in this problem.","8538da7c":"## L2 Distances","388da86a":"## Step 1 \nRead Data and Extract Label","d6af948d":"## L1 distances"}}