{"cell_type":{"4e674d18":"code","f987818f":"code","a0f47064":"code","e992f8cb":"code","8a364408":"code","28dfdee9":"code","1645c4ca":"code","0758ad39":"code","67bd76ee":"code","2dbfaba5":"code","99ddbc78":"code","00a1b9e4":"code","b166fb1f":"code","dc597741":"code","2bb39250":"code","7dd3b956":"code","511c7c6c":"code","1b0659a4":"code","b8bec078":"markdown","a13bbcfa":"markdown","56eda4fa":"markdown","b7d138d5":"markdown","36b88573":"markdown","24c05b7e":"markdown","b441fc33":"markdown","8aa61ffe":"markdown","ca91b461":"markdown","5aef5da1":"markdown","99f04c91":"markdown","bd167aca":"markdown","da97fc7d":"markdown","7617a645":"markdown","2dadd09f":"markdown","e389663d":"markdown","12971ee1":"markdown","d9ffea37":"markdown","49509da4":"markdown","902ee1d4":"markdown","9c9ba3a9":"markdown","49e80ee2":"markdown","4856ad9b":"markdown","22b92b21":"markdown","432cf2a0":"markdown","d2b39698":"markdown","23308bbb":"markdown","cf96ae58":"markdown","0f9f883f":"markdown","0c3024ea":"markdown","ec629a35":"markdown"},"source":{"4e674d18":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n!pip install openpyxl","f987818f":"def show_values_on_bars(axs, h_v=\"v\", space=0.4, fontsize = 12, fontcolor = \"black\", arredondamento = 0):\n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height() + float(space)\n                _arredondamento = \"{:.\"+str(arredondamento)+\"f}\"\n                value = _arredondamento.format(round(p.get_height(), arredondamento))\n                ax.text(_x, _y, value, ha=\"center\", fontsize = fontsize, color = fontcolor) \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, value, ha=\"left\", fontsize = fontsize, color = fontcolor)\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","a0f47064":"def plotador(bd, x, y, tipo = \"Linha\", hue = \"\", rotacao = 0, tamanho = (19,7), imprimeLabels = True, fontsize = 16):\n  import matplotlib.pyplot as plt\n  import seaborn as sns\n\n  plt.figure(figsize = tamanho)\n  \n  if tipo == \"Linha\":\n    if hue == \"\":\n      ax = sns.lineplot(data=bd, x = x, y = y)\n    else:\n      ax = sns.lineplot(data=bd, x = x, y = y, hue = hue)\n  elif tipo == \"Barras\":\n    if hue == \"\":\n      ax = sns.barplot(data=bd, x = x, y = y)\n    else:\n      ax = sns.barplot(data=bd, x = x, y = y, hue = hue)\n\n  if imprimeLabels:\n    show_values_on_bars(ax, space = - 15, fontsize = 20, fontcolor = \"white\", arredondamento= 0)\n\n  plt.xticks(rotation = rotacao)\n  plt.xticks(fontsize = fontsize)\n  plt.yticks(fontsize = fontsize)\n  plt.xlabel(x, fontsize = fontsize)\n  plt.ylabel(y, fontsize = fontsize)\n\n  #plt.show()\n\n  return ax","e992f8cb":"dados = pd.read_excel(\"\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx\")\n\ndados.head()","8a364408":"dadosTabelaDinamica = dados.pivot(index=\"PATIENT_VISIT_IDENTIFIER\", columns=\"WINDOW\", values=\"ICU\")\ndadosTabelaDinamica[\"Tipo\"] = dadosTabelaDinamica.sum(axis=1)\n\ndicio = {5: \"0-2\", 4: \"2-4\", 3: \"4-6\", 2: \"6-12\", 1:\"ABOVE_12\", 0: \"N\u00e3o foi para UTI\"}\n\ndadosTabelaDinamica[\"Tipo Janela\"] = dadosTabelaDinamica[\"Tipo\"].replace(dicio)\n\ntemp = dadosTabelaDinamica.groupby(\"Tipo Janela\").count()\n# Isso aqui \u00e9 a quantidade de pessoas que entram na UTI (ou n\u00e3o), em qual momento\n#190 n\u00e3o entram\n#65 entram apenas nas 6 a 12 horas\n#31 entre 4 e 6 horas e assim por diante\n\n# Em outras palavras, \u00e9 uma distribui\u00e7\u00e3o de frequ\u00eancias das janelas de interna\u00e7\u00e3o\n\n#sns.barplot(data = temp.reset_index(), x = \"Tipo Janela\", y = \"ABOVE_12\")\ntemp[\"Percentual\"] = temp[\"ABOVE_12\"]\/temp[\"ABOVE_12\"].sum()\n\nx = \"Tipo Janela\"\ny = \"Percentual\"\n\nax = plotador(x = x, y = y, bd = temp.reset_index(), tipo = \"Barras\", rotacao = 0, tamanho = (19,7), imprimeLabels=False, fontsize = 16)\nshow_values_on_bars(ax, space = - 0.03, fontsize = 20, fontcolor = \"white\", arredondamento= 2)\nplt.title(\"Quantidade de pessoas que entraram na UTI (ou n\u00e3o), por janela de tempo (em %)\", fontsize = 18)\n\nplt.show()","28dfdee9":"naoUTI = temp.loc[\"N\u00e3o foi para UTI\"]\ntemp2 = temp.drop(\"N\u00e3o foi para UTI\")\n\n#sns.barplot(data = temp.reset_index(), x = \"Tipo Janela\", y = \"ABOVE_12\")\nax = plotador(x = \"Tipo Janela\", y = \"Percentual\", bd = temp2.reset_index(), tipo = \"Barras\", rotacao = 0, tamanho = (19,7), imprimeLabels=False)\nshow_values_on_bars(ax, space = - .02, fontsize = 20, fontcolor = \"white\", arredondamento= 2)\nplt.title(\"Quantidade de pessoas que entraram na UTI, por janela de tempo (em %)\", fontsize = 18)\nplt.show()","1645c4ca":"def treinaERoda(dados, coluna, imprimir_metrica = False, imprimirFeatures = False,\n                modelo = \"LogisticRegression\", metrica = \"accuracy_score\", zero_division = \"warn\", iteracoes = 50,\n                n_splits = 5, n_repeats = 10, max_depth = 3, n_estimators = 100,\n                estrategia = 'prior',\n                penalty='l2', loss='squared_hinge', dual=False, tol=0.0001, C=1.0,\n                kernel = \"rbf\", degree=3, gamma = \"scale\",\n                nu = 0.5):\n  \n  import numpy as np\n  from sklearn.model_selection import train_test_split \n\n  semente = 1279871492\n  np.random.seed(semente)\n  dados = dados.sample(frac = 1).reset_index(drop = True)\n  #y = dados[\"ICU\"]\n  #x = dados[dados.describe().columns].drop([\"ICU\"], axis =1)\n\n  y = dados[coluna]\n  x = dados[dados.describe().columns].drop([coluna], axis =1)\n\n  from sklearn.model_selection import train_test_split \n  \n  x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)\n\n  if modelo == \"LogisticRegression\":\n    from sklearn.linear_model import LogisticRegression\n    modelo = LogisticRegression(max_iter = 10000)\n\n  elif modelo == \"DecisionTreeClassifier\":\n    from sklearn.tree import DecisionTreeClassifier\n    modelo = DecisionTreeClassifier(max_depth = max_depth)\n\n  elif modelo == \"RandomForestClassifier\":\n    from sklearn.ensemble import RandomForestClassifier\n    modelo = RandomForestClassifier(max_depth = max_depth, n_estimators = n_estimators)\n  \n  elif modelo == \"DummyClassifier\":\n    #https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.dummy.DummyClassifier.html\n    from sklearn.dummy import DummyClassifier\n    # strategy{\u201cstratified\u201d, \u201cmost_frequent\u201d, \u201cprior\u201d, \u201cuniform\u201d, \u201cconstant\u201d}\n    if estrategia == \"constant\":\n      modelo = DummyClassifier(strategy = estrategia, constant = n_estimators)\n    else:\n      modelo = DummyClassifier(strategy = estrategia)\n\n  elif modelo == \"LinearSVM\":\n    # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n    from sklearn.svm import LinearSVC\n    # penalty{\u2018l1\u2019, \u2018l2\u2019}\n    # loss{\u2018hinge\u2019, \u2018squared_hinge\u2019}\n\n    modelo = LinearSVC(penalty=penalty, loss=loss, dual=dual, tol=tol, C=C, max_iter = iteracoes)\n\n  elif modelo == \"KernelSVM\":\n    # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html\n    from sklearn.svm import SVC\n    # kernel{\u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmoid\u2019, \u2018precomputed\u2019}\n    modelo = SVC(C = C, kernel = kernel, gamma=gamma, degree=degree)\n    \n  elif modelo == \"NuSVM\":\n    # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC\n    from sklearn.svm import NuSVC\n    # kernel{\u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmoid\u2019, \u2018precomputed\u2019}\n    modelo = NuSVC(nu = nu, kernel = kernel, gamma=gamma, degree=degree)\n\n  elif modelo == \"NeuralNetwork\":\n    # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html\n    from sklearn.neural_network import MLPClassifier\n    modelo = MLPClassifier(random_state=semente, max_iter=iteracoes)\n\n  elif modelo == \"GradientBoosting\":\n    #https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingClassifier.html\n    from sklearn.ensemble import GradientBoostingClassifier\n    modelo = GradientBoostingClassifier()\n\n\n  modelo.fit(x_train, y_train)\n  y_pred = modelo.predict(x_test)\n\n\n    #Print Feature Importance:\n  if imprimirFeatures:\n    #https:\/\/www.analyticsvidhya.com\/blog\/2016\/02\/complete-guide-parameter-tuning-gradient-boosting-gbm-python\/\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(12,4))\n    feat_imp = pd.Series(modelo.feature_importances_, predictors).sort_values(ascending=False)\n    feat_imp.plot(kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')\n\n  if metrica == \"plot_confusion_metrics\":\n    # Com essa m\u00e9trica conseguimos ver a acur\u00e1cia, mas tamb\u00e9m outas 4 informa\u00e7\u00f5es:\n    ## Verdadeiro Positivo: Acertou a label em um resultado positivo (1\/1)\n    ## Verdadeiro Negativo: Acertou a label em um resultado negativo (0\/0)\n    ## Falso Positivo: Errou a label, porque foi previsto um positivo quando era negativo (0\/1) -> inferior (resultado \u00e9 0) esquerdo (previs\u00e3o \u00e9 1)\n    ## Falso Negativo: Errou a label, porque foi previsto um negativo quando era positivo (1\/0) -> superior (resultado \u00e9 1) direito (previs\u00e3o \u00e9 0)\n\n    from sklearn.metrics import plot_confusion_matrix\n    #https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.plot_confusion_matrix.html\n    import matplotlib.pyplot as plt\n    if imprimir_metrica:\n      metrica_calculada = plot_confusion_matrix(modelo, x_test, y_test)\n      imprimir_metrica = False\n\n  elif metrica == \"classification_report\":\n    # Para ser sincero eu n\u00e3o entendi a explica\u00e7\u00e3o do Thiago\n    # https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall\n    #precision: Verdadeiro positivo\/(todos os positivos no y_pred), ou seja, nos diz qu\u00e3o v\u00e1lidos ou precisos s\u00e3o as previs\u00f5es, ou se tem muitas previs\u00f5es erradas\n    #recall: Verdadeiro positivo\/(resultados positivos no y_test), ou seja, nos diz qu\u00e3o completas s\u00e3o as previs\u00f5es, ou se tem previs\u00f5es faltando\n    #f1-score: m\u00e9dia harm\u00f4nica dos outros dois\n\n    from sklearn.metrics import classification_report\n    #metrica_calculada = classification_report(y_test, y_pred, zero_division = zero_division)\n\n    #from sklearn.model_selection import RepeatedStratifiedKFold\n    #from sklearn.model_selection import cross_val_predict\n    #cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats = n_repeats)\n    #y_pred = cross_val_predict(modelo, x_test, y_test, cv = cv)\n    metrica_calculada = classification_report(y_test, y_pred, zero_division = zero_division)\n\n  else:\n    from sklearn.model_selection import RepeatedStratifiedKFold\n    from sklearn.model_selection import cross_val_score\n    #https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_validate.html\n    #https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\n\n\n    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats = n_repeats)\n    # https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\n    validacao = cross_val_score(modelo, x_train, y_train, cv = cv, scoring = metrica)\n    \n    if imprimir_metrica:\n      #metrica_lista = validacao[\"test_score\"]\n      print(\"[\" + metrica + \"] M\u00e9d: \" + \"{:.3f}\".format(np.mean(validacao)) + \", e Desvio Padr\u00e3o: \" + \"{:.3f}\".format(np.std(validacao)))\n    \n    return modelo, validacao\n\n  if imprimir_metrica:\n    print(metrica_calculada)\n  \n  return modelo, [metrica_calculada]","0758ad39":"def organizaDados(dados, dropna = True):\n\n  if dropna == True:\n    dadosTemp = dados.dropna()\n  else:\n    features_continuas = dados.iloc[:, 13:-2].columns\n\n    features_continuas = dados.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index=False)[features_continuas].fillna(method=\"bfill\").fillna(method=\"ffill\")\n    features_categoricas = dados.iloc[:, :13]\n    saida = dados.iloc[:, -2:]\n    dadosTemp = pd.concat([features_categoricas, features_continuas, saida], ignore_index = True, axis=1)\n    dadosTemp.columns = dados.columns\n\n  casos =  dadosTemp[(dadosTemp[\"WINDOW\"] == \"0-2\")  & (dadosTemp[\"ICU\"] == 1)]\n  \n  dadosTempSemInicio = dadosTemp[~dadosTemp[\"PATIENT_VISIT_IDENTIFIER\"].isin(casos[\"PATIENT_VISIT_IDENTIFIER\"])]\n\n  foiParaUTI = dadosTemp.groupby(\"PATIENT_VISIT_IDENTIFIER\").max()[\"ICU\"] \n  # diferentemente do curso, eu n\u00e3o estou pegando apenas os dados das duas primeiras horas, e que tenham ido para a UTI em algum momento\n  # estou pegando os dados de todos os momentos, e indicando que uma pessoa com aqueles sinais eventualmente foi para a UTI\n  # acho que pode dar mais informa\u00e7\u00e3o para o modelo desse jeito\n  dadosTempSemInicioComICU = dadosTempSemInicio.set_index(\"PATIENT_VISIT_IDENTIFIER\").drop(\"ICU\", axis = 1).join(pd.DataFrame(foiParaUTI), how=\"outer\")\n  dadosTempSemInicioComICU = dadosTempSemInicioComICU.dropna()\n  #dadosPreenchidosSemInicio\n\n  # Window eu posso simplesmente tirar, isso pouco importa\n  dadosTempColunasNumericas = dadosTempSemInicioComICU.drop(\"WINDOW\", axis = 1)\n  #AGE_PERCENTIL \u00e9 uma coluna que indica a idade, mas em grupos de 10 em 10 anos. Vamos converter para um n\u00famero\n\n  colunaDeIdade = dadosTempColunasNumericas[\"AGE_PERCENTIL\"]\n  \n  colunaDeIdade = colunaDeIdade.str.replace(\"Above 90\", \"100\", regex = True).replace(\"th\", \"\", regex = True).astype(\"int\")\n  dadosTempColunasNumericas[\"Idade aproximada\"] = colunaDeIdade\n\n  dadosTempColunasNumericas = dadosTempColunasNumericas.drop(\"AGE_PERCENTIL\", axis = 1)\n\n  dadosTempFinal = removeCorrelacoes(dadosTempColunasNumericas)\n\n  return dadosTempFinal","67bd76ee":"def removeCorrelacoes(dados, alta_correlacao = 0.95):\n  matriz_excluir = dados.corr().abs().where(np.triu(np.ones(dados.corr().shape), k = 1).astype(np.bool))\n  colunas_excluir = [coluna for coluna in matriz_excluir.columns if any(matriz_excluir[coluna] > alta_correlacao)]\n  \n  return dados.drop(colunas_excluir, axis = 1)","2dbfaba5":"dadosFiltradosFinal = organizaDados(dados, dropna = True)","99ddbc78":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,  zero_division = 1,\n              modelo = \"DummyClassifier\", metrica = \"recall\", n_estimators = 100,\n               estrategia = \"stratified\");\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,  zero_division = 1,\n              modelo = \"DummyClassifier\", metrica = \"accuracy\", n_estimators = 100,\n               estrategia = \"stratified\");","00a1b9e4":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n                modelo = \"LogisticRegression\", metrica = \"recall\", n_splits = 5, n_repeats = 10, iteracoes = 50);\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n                modelo = \"LogisticRegression\", metrica = \"accuracy\", n_splits = 5, n_repeats = 10, iteracoes = 50);","b166fb1f":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"LinearSVM\", metrica = \"recall\",\n              penalty='l1', loss='squared_hinge', dual=False, tol=0.00001, C=0.1, iteracoes = 10000);\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"LinearSVM\", metrica = \"accuracy\",\n              penalty='l1', loss='squared_hinge', dual=False, tol=0.00001, C=0.1, iteracoes = 10000);","dc597741":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"KernelSVM\", metrica = \"recall\", \n              kernel='linear', gamma = \"auto\", C=10);\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"KernelSVM\", metrica = \"accuracy\", \n              kernel='linear', gamma = \"auto\", C=10);","2bb39250":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n              modelo = \"NuSVM\", metrica = \"recall\",\n              nu=0.31, kernel='poly', degree = 2, gamma = \"auto\");\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n              modelo = \"NuSVM\", metrica = \"accuracy\",\n              nu=0.31, kernel='poly', degree = 2, gamma = \"auto\");","7dd3b956":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n              modelo = \"RandomForestClassifier\", metrica = \"recall\");\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n              modelo = \"RandomForestClassifier\", metrica = \"accuracy\");","511c7c6c":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n                modelo = \"NeuralNetwork\", metrica = \"recall\", iteracoes = 3000);\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True, \n                modelo = \"NeuralNetwork\", metrica = \"accuracy\", iteracoes = 3000);","1b0659a4":"treinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"GradientBoosting\", metrica = \"recall\");\n\ntreinaERoda(dadosFiltradosFinal, \"ICU\", imprimir_metrica = True,\n              modelo = \"GradientBoosting\", metrica = \"accuracy\");","b8bec078":"# 2. Resultados obtidos","a13bbcfa":"## 3.3 Explora\u00e7\u00e3o dos dados","56eda4fa":"# 5. Apresenta\u00e7\u00e3o dos modelos com melhores resultados","b7d138d5":"<div id=\"dois\"><\/div>\n\nNeste trabalho, foram avaliados 7 algoritmos de Machine Learning, ap\u00f3s defini\u00e7\u00e3o do baseline comparativo com um algoritmo Dummy. Na tabela abaixo vemos os algoritmos avaliados, assim como as m\u00e9tricas de **recall** e **accuracy** (e desvios padr\u00e3o), calculadas via cross validation:\n\n\n<table style=\"text-align:center; width:75%\">\n  <tr>\n    <th>Algoritmo<\/th>\n    <th>Recall m\u00e9dio<\/th>\n    <th>Accuracy m\u00e9dio<\/th>\n  <\/tr>\n  <tr>\n    <td>Dummy Classifier (baseline)<\/td>\n    <td>0.561 +- 0.091<\/td>\n    <td>0.511 +- 0.061<\/td>\n  <\/tr>\n  <tr>\n    <td>Regress\u00e3o Log\u00edstica<\/td>\n    <td>0.844 +- 0.045<\/td>\n    <td>0.856 +- 0.032<\/td>\n  <\/tr>\n  <tr>\n    <td>Linear SVM<\/td>\n    <td>0.817 +- 0.055<\/td>\n    <td>0.840 +- 0.033<\/td>\n  <\/tr>\n  <tr>\n    <td>Kernel SVM<\/td>\n    <td>0.815 +- 0.056<\/td>\n    <td>0.825 +- 0.041<\/td>\n  <\/tr>\n  <tr>\n    <td>NU SVM<\/td>\n    <td>0.786 +- 0.066<\/td>\n    <td>0.828 +- 0.038<\/td>\n  <\/tr>\n  <tr>\n    <td>Random Forest<\/td> \n    <td>0.833 +- 0.061<\/td> \n    <td>0.864 +- 0.038<\/td>\n  <\/tr>\n  <tr>\n    <td>Redes Neurais<\/td> \n    <td>0.833 +- 0.070<\/td>\n    <td>0.832 +- 0.039<\/td>\n  <\/tr>\n  <tr>\n    <td><b>Gradient Boosting Tree<\/b><\/td>\n    <td><b>0.868<\/b> +- 0.051<\/td>\n    <td><b>0.875<\/b> +- 0.034<\/td>\n  <\/tr>\n<\/table>\n\n[As m\u00e9tricas recall e accuracy foram escolhidas de acordo com os crit\u00e9rios descritos na se\u00e7\u00e3o 4.1.](#quatropontoum)\n\nAtrav\u00e9s da tabela acima, pode-se observar que todos os algoritmos testados apresentam resultados vantajosos em compara\u00e7\u00e3o ao baseline, mas entre eles, tamb\u00e9m podemos destacar o **Gradient Boosting Tree como algoritmo mais eficiente, atingindo cerca de 87% tanto em recall quanto accuracy**.","36b88573":"\u00c9 importante reparar que os casos de **falsos negativos precisam ser cuidadosamente tratados**, uma vez que liberar um paciente, quando na verdade ele precisaria de cuidados intensivos, pode ser fatal. A inten\u00e7\u00e3o \u00e9 encontrar um modelo que minimize os falsos negativos, o que **\u00e9 o principal motivo de escolher recall [1] como m\u00e9trica principal para avalia\u00e7\u00e3o**.\n\nDe forma mais detalhada, recall \u00e9 dado pela f\u00f3rmula:\n\n$$recall = \\frac{tp}{tp + fn}$$\n\nonde $tp$ \u00e9 a quantidade de positivos verdadeiros (ou *true positives*) e $fn$ \u00e9 a quantidade de falsos negativos (ou *false negatives*).\n\nO recall pode ser considerado **a capacidade do modelo de encontrar positivos verdadeiros dentro do conjunto de itens que deveriam ter sido previstos como positivos. Em outras palavras, de todos os resultados que deveriam ser positivos, quantos o modelo conseguiu prever?**\n\nOu seja, estaremos olhando apenas para os positivos (quem realmente precisa ir para UTI) e otimizando o algoritmo para aquele que conseguir melhor acertar esse tipo de caso.\n\nJ\u00e1 os casos de falsos positivos s\u00e3o ruins em termos de lota\u00e7\u00e3o das UTIs e aten\u00e7\u00e3o (ou tempo) gastos com um paciente que n\u00e3o necessariamente precisaria ir para UTI. Mas mesmo assim, \u00e9 melhor que ele esteja na UTI do que n\u00e3o esteja, desde que haja espa\u00e7o dispon\u00edvel para ele. Tamb\u00e9m \u00e9 necess\u00e1rio minimizar isso, e **como m\u00e9trica secund\u00e1ria, utilizaremos o accuracy [1] geral do modelo (ou f1-score), j\u00e1 que permite balancear as m\u00e9tricas de recall e precision**.\n\nAl\u00e9m disso, **\u00e9 importante que a avalia\u00e7\u00e3o das m\u00e9tricas recall e accuracy seja feita atrav\u00e9s de cross validation [2]**, garantindo que o modelo seja testado de maneira geral nos dados.","24c05b7e":"Nessa se\u00e7\u00e3o, s\u00e3o definidas as bibliotecas utilizadas para a prepara\u00e7\u00e3o de dados e desenvolvimento das an\u00e1lises. \n\nPara cria\u00e7\u00e3o e avalia\u00e7\u00e3o dos algoritmos de Machine Learning, as bibliotecas utilizadas ficaram dentro da fun\u00e7\u00e3o espec\u00edfica para isso, [na se\u00e7\u00e3o 4.2](#quatropontodois).","b441fc33":"### 4.4.7 Redes Neurais","8aa61ffe":"### 4.4.5 NU SVM","ca91b461":"### 4.4.4 Kernel SVM","5aef5da1":"Percebe-se pelos gr\u00e1ficos acima que cerca de **metade de nossos pacientes n\u00e3o necessitam de atendimento intensivo**.\n\nPor outro lado, a outra metade, que \u00e9 um grupo significativo de pacientes, ir\u00e1 necessitar de atendimento intensivo. Ao mesmo tempo, n\u00e3o se sabe a propor\u00e7\u00e3o exata ao longo de um dia, de modo que todo paciente \u00e9 um paciente de UTI, e a capacidade da UTI pode se tornar imprevis\u00edvel rapidamente.\n\n**Apenas com as m\u00e9dias e propor\u00e7\u00f5es, hora a hora, n\u00e3o teremos uma capacidade de agir no curto prazo, uma vez que esse comportamento m\u00e9dio s\u00f3 aparece no longo prazo**. Isto \u00e9, ao longo de poucas horas, o n\u00famero de pacientes indo para UTI pode aumentar rapidamente, fugindo do padr\u00e3o m\u00e9dio.\n\nEsse comportamento torna necess\u00e1rio um modelo de previs\u00e3o, que seja capaz de olhar os dados do paciente e indicar um sinal ao m\u00e9dico:\n- Positivo, caso o paciente tenha tend\u00eancia a necessitar de UTI;\n- Negativo, caso o paciente n\u00e3o tenha tend\u00eancia de ir para UTI.","99f04c91":"# 3. Prepara\u00e7\u00e3o dos dados e An\u00e1lise estat\u00edstica inicial","bd167aca":"## 4.2 Fun\u00e7\u00e3o de teste dos algoritmos\n\n<div id=\"quatropontodois\"><\/div>\n\nFoi desenvolvida uma \u00fanica fun\u00e7\u00e3o para comparar os modelos, de forma que o usu\u00e1rio pode selecionar o algoritmo de ML para classifica\u00e7\u00e3o e os hiper par\u00e2metros. **A fun\u00e7\u00e3o ir\u00e1 instanciar esse modelo, separar a base de dados nas por\u00e7\u00f5es de treinamento e teste, depois ir\u00e1 treinar aquele modelo com os dados de treinamento e ent\u00e3o gerar a previs\u00e3o**. \n\nEm seguida, tamb\u00e9m com a indica\u00e7\u00e3o do usu\u00e1rio, **a fun\u00e7\u00e3o seleciona o tipo de m\u00e9trica ou relat\u00f3rio a ser avaliado, produz a m\u00e9trica com cross validation e (caso desejado pelo usu\u00e1rio) imprime essa m\u00e9trica e retorna tanto o modelo treinado quanto as m\u00e9tricas**.","da97fc7d":"## 4.4 Compara\u00e7\u00f5es entre modelos\n\nNeste ponto, [\u00e9 importante referenciar o notebook auxiliar, onde foram feitos os testes com cada algoritmo](https:\/\/colab.research.google.com\/drive\/1QoS9tLd0X7_G8TpKxznPyxwOdXEgdYNS?usp=sharing), uma vez que este trabalho foi criado de maneira iterativa, com ajustes finos nos hiper par\u00e2metros buscando encontrar os melhores resultados de *recall* e *accuracy* em cada caso.\n\nNeste trabalho de busca pelos melhores par\u00e2metros, foram criados mais de 60 modelos, que levam v\u00e1rios minutos para rodar.\n\n**Portanto, no notebook deste Projeto Final, permanecer\u00e3o apenas as execu\u00e7\u00f5es que geraram os melhores modelos, com os resultados apresentados na [se\u00e7\u00e3o 2](#dois)**.\n\nA respeito dos modelos escolhidos para compara\u00e7\u00e3o, **foram selecionadas as op\u00e7\u00f5es mais prov\u00e1veis de gerar bons resultados para o problema de classifica\u00e7\u00e3o [3]**. A saber:\n- Dummy Classifier (para defini\u00e7\u00e3o de um baseline comparativo)\n- Regress\u00e3o Log\u00edstica\n- Support Vector Machine (Linear SVM, Kernel SVM e NU SVM)\n- Random Forest (Decision Tree ensemble)\n- Neural Networks\n- Gradient Boosting Tree","7617a645":"Inicialmente \u00e9 feito um tratamento dos dados para observar a propor\u00e7\u00e3o de pacientes que foram internados em fun\u00e7\u00e3o da janela de tempo. Ou seja, dessa maneira conseguiremos entender a **distribui\u00e7\u00e3o de frequ\u00eancias dos pacientes de acordo com a sua interna\u00e7\u00e3o (ou n\u00e3o) ao longo do tempo**.","2dadd09f":"Antes de iniciar a modelagem, \u00e9 importante preparar os dados, de maneira a utilizar a melhor configura\u00e7\u00e3o de *features* poss\u00edvel. [A explora\u00e7\u00e3o dos dados para essa prepara\u00e7\u00e3o foi feita no notebook auxiliar](https:\/\/colab.research.google.com\/drive\/1QoS9tLd0X7_G8TpKxznPyxwOdXEgdYNS#scrollTo=veMTLyq-BGtA&uniqifier=3).\n\nNeste trabalho, foram escolhidas duas estrat\u00e9gias de prepara\u00e7\u00e3o dos dados:\n1. Simples remo\u00e7\u00e3o dos registros que possu\u00edam valores NaN, deixando a base com cerca de 545 linhas a menos, ou 28% do total, gerando a base de dados *dadosFiltrados*;\n2. Preenchimento dos registros NaN com o valor anterior do mesmo paciente, gerando a base de dados *dadosPreenchidos*.\n\nA princ\u00edpio, o receio de utilizar a estrat\u00e9gia n\u00famero 1 \u00e9 perder informa\u00e7\u00e3o, e consequentemente qualidade. Mas os testes nos diferentes algoritmos indicaram que essa base com os dados Filtrados gerava modelos melhores em geral, e portanto **dadosFiltrados foi a base escolhida para modelagem**.","e389663d":"### 4.4.6 Random Forest","12971ee1":"# 6. Fontes e refer\u00eancias\n\n1. [Precision e Recall](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall)\n2. [Cross validation](https:\/\/en.wikipedia.org\/wiki\/Cross-validation_(statistics))\n3. [An easy guide to choose the right Machine Learning algorithm](https:\/\/www.kdnuggets.com\/2020\/05\/guide-choose-right-machine-learning-algorithm.html)","d9ffea37":"# 1. Problem\u00e1tica","49509da4":"### 4.4.2 Regress\u00e3o Log\u00edstica","902ee1d4":"## 4.3 Prepara\u00e7\u00e3o dos dados para a modelagem","9c9ba3a9":"## 3.1 Bibliotecas","49e80ee2":"### 4.4.8 Boosting Gradient Tree","4856ad9b":"## 3.2 Fun\u00e7\u00f5es para plot de gr\u00e1ficos","22b92b21":"### 4.4.3 Linear SVM","432cf2a0":"# 4. Modelagem","d2b39698":"Abaixo est\u00e3o duas fun\u00e7\u00f5es padronizadas para gera\u00e7\u00e3o de gr\u00e1ficos padronizados, usando *matplotlib* e *seaborn*.\n\nElas foram usadas especificamente na se\u00e7\u00e3o 3.3, mas podem ser usadas fora do contexto deste trabalho pois s\u00e3o fun\u00e7\u00f5es generalistas.","23308bbb":"Para este notebook, a prepara\u00e7\u00e3o dos dados foi consolidada nas fun\u00e7\u00f5es abaixo.\n\n**Foram preparadas duas fun\u00e7\u00f5es que far\u00e3o a organiza\u00e7\u00e3o dos dados**. As seguintes tarefas s\u00e3o desenvolvidas nessas fun\u00e7\u00f5es:\n1. Preenchimento de valores vazios com os valores medidos anteriormente, para cada paciente (utilizando par\u00e2metro *bfill*), indicado pelo usu\u00e1rio na fun\u00e7\u00e3o com o par\u00e2metro *dropna*;\n2. Identifica\u00e7\u00e3o dos pacientes que foram para UTI, estendendo esse \"status\" para todos as medi\u00e7\u00f5es daquele paciente (ou seja, um determinado paciente em um dado momento ser\u00e1 classificado como 1 no campo *UCI* se ele for para a UTI em qualquer janela de tempo);\n3. Limpeza e ajuste de campos que n\u00e3o ser\u00e3o utilizados para os algoritmos de Machine Learning (como a janela de tempo) ou que s\u00e3o categ\u00f3ricos na base (como a idade do paciente, que foi transformada para inteiro);\n4. Remo\u00e7\u00e3o de correla\u00e7\u00f5es internas entre as vari\u00e1veis, considerando uma correla\u00e7\u00e3o maior do que 0.95.","cf96ae58":"### 4.4.1 Definindo um baseline com Dummy Classifier","0f9f883f":"Em linhas gerais, o trabalho apresentado neste notebook conseguiu encontrar e apresentar diversos modelos melhores do que o baseline, conforme indicado pela tabela da [se\u00e7\u00e3o 2](#dois).\n\nTodos os modelos avaliados tiveram accuracy geral maior do que 0.80, e apenas 1 deles teve recall menor do que 0.80, o que torna poss\u00edvel afirmar que h\u00e1 boas op\u00e7\u00f5es para auxiliar a tomada de decis\u00e3o da equipe de sa\u00fade do Hospital S\u00edrio Liban\u00eas (e qualquer outra institui\u00e7\u00e3o, desde que haja dados semelhantes aos utilizados para este trabalho).\n\n\u00c9 interessante observar que um algoritmo simples como Regress\u00e3o Linear apresenta resultado muito bom, ficando atr\u00e1s apenas da **Gradient Boosting Tree**. \n\nEste \u00e9 um resultado promissor porque ainda h\u00e1 possibilidade de otimizar esse modelo com outras t\u00e9cnicas, ou com uma varredura mais exaustiva dos hiper par\u00e2metros.\n\n**Para os objetivos deste trabalho, acredita-se que o resultado apresentado seja positivo, com alto \u00edndice de acerto dos resultados: 87% de recall e accuracy atrav\u00e9s do algoritmo de Gradient Boosting Tree, e com papel importante para apoiar a tomada de decis\u00e3o do Hospital S\u00edrio Liban\u00eas em sua miss\u00e3o de salvar vidas.**","0c3024ea":"## 4.1 Estrat\u00e9gia de avalia\u00e7\u00e3o dos algoritmos de Machine Learning\n<div id=\"quatropontoum\"> \n<\/div>","ec629a35":"<p style=\"text-align:center;\">\n        <img src=\"https:\/\/github.com\/ricardopeloi\/bootcamp-alura-data-science\/raw\/main\/hospital%20sirio%20libanes%20logo.png\" width=\"30%\">\n<\/p>\n\nA *COVID-19* tem se mostrado um problema mundial de propor\u00e7\u00f5es hist\u00f3ricas.\n\nEm fun\u00e7\u00e3o disso, diversas t\u00e9cnicas t\u00eam sido utilizadas em todo o mundo em uma tentativa de conter a transmiss\u00e3o do v\u00edrus, reduzir sua mortalidade e tamb\u00e9m munir equipes de sa\u00fade de informa\u00e7\u00f5es e dados para melhoria da tomada de decis\u00e3o.\n\nEstas t\u00e9cnicas podem se desdobrar nas mais diversas \u00e1reas do conhecimento, e de maneira interdisciplinar. Por exemplo, a COVID-19 trouxe um dos maiores e mais terr\u00edveis dilemas poss\u00edveis \u00e0 mente dos profissionais da \u00e1rea da Sa\u00fade, quando uma equipe de m\u00e9dicos e enfermeiros deve gerir os leitos de UTI dispon\u00edveis e decidir quais pacientes ter\u00e3o prioridade de tratamento em cada momento.\n\nNesse contexto, **utilizar tecnologia para apoiar a \u00e1rea da Sa\u00fade em seu trabalho \u00e9 essencial**.\n\nNo trabalho desenvolvido nesse notebook, procuraremos entender os [dados dispon\u00edveis dos sinais vitais de diversos  pacientes, assim como a necessidade de interna\u00e7\u00e3o em UTI (ou n\u00e3o) de cada um desses pacientes.](https:\/\/www.kaggle.com\/S%C3%ADrio-Libanes\/covid19)\n\nAtrav\u00e9s desses dados, ser\u00e1 gerado um modelo de Machine Learning capaz de prever quais pacientes tem maiores chances de precisar de UTI, ou n\u00e3o."}}