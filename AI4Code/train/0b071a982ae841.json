{"cell_type":{"30755ef4":"code","be13d9f7":"code","a73e1252":"markdown","a75093fd":"markdown"},"source":{"30755ef4":"import torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\ntensor = torch.FloatTensor([[1,2],[3,4]])\nvariable = Variable(tensor,requires_grad=True)\n\nprint(tensor)\nprint(variable)\n\nt_out = torch.mean(tensor*tensor)#\u5e73\u5747\u503c\nv_out = torch.mean(variable*variable)\nprint(t_out)#=1\/4*sum(var*var)\nprint(v_out)\n\nv_out.backward()\nprint(variable.grad)#=d(v_out)\/d(variable)=1\/4*2*variable = variable\/2","be13d9f7":"import torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nx = torch.unsqueeze(torch.linspace(-1,1,100),dim=1)\ny = x.pow(2)+20*torch.rand(x.size())\n\nx,y = Variable(x) ,Variable(y)\n\nclass Net(torch.nn.Module):  # \u7ee7\u627f torch \u7684 Module\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()     # \u7ee7\u627f __init__ \u529f\u80fd\n        # \u5b9a\u4e49\u6bcf\u5c42\u7528\u4ec0\u4e48\u6837\u7684\u5f62\u5f0f\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   \n        # \u9690\u85cf\u5c42\u7ebf\u6027\u8f93\u51fa\n        self.predict = torch.nn.Linear(n_hidden, n_output)   \n        # \u8f93\u51fa\u5c42\u7ebf\u6027\u8f93\u51fa\n\n    def forward(self, x):   # \u8fd9\u540c\u65f6\u4e5f\u662f Module \u4e2d\u7684 forward \u529f\u80fd\n        # \u6b63\u5411\u4f20\u64ad\u8f93\u5165\u503c, \u795e\u7ecf\u7f51\u7edc\u5206\u6790\u51fa\u8f93\u51fa\u503c\n        x = F.sigmoid(self.hidden(x))      # \u6fc0\u52b1\u51fd\u6570(\u9690\u85cf\u5c42\u7684\u7ebf\u6027\u503c)\n        x = self.predict(x)             # \u8f93\u51fa\u503c\n        return x\nnet = Net(n_feature=1, n_hidden=10, n_output=1)\n#print(net)  # net \u7684\u7ed3\u6784\nplt.ion()   # \u753b\u56fe\nplt.show()\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.2)  # \u4f20\u5165 net \u7684\u6240\u6709\u53c2\u6570, \u5b66\u4e60\u7387\nloss_func = torch.nn.MSELoss()      # \u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u7684\u8bef\u5dee\u8ba1\u7b97\u516c\u5f0f (\u5747\u65b9\u5dee)\n\nfor t in range(100):\n    prediction = net(x)     # \u5582\u7ed9 net \u8bad\u7ec3\u6570\u636e x, \u8f93\u51fa\u9884\u6d4b\u503c\n    loss = loss_func(prediction, y)     # \u8ba1\u7b97\u4e24\u8005\u7684\u8bef\u5dee\n    optimizer.zero_grad()   # \u6e05\u7a7a\u4e0a\u4e00\u6b65\u7684\u6b8b\u4f59\u66f4\u65b0\u53c2\u6570\u503c\n    loss.backward()         # \u8bef\u5dee\u53cd\u5411\u4f20\u64ad, \u8ba1\u7b97\u53c2\u6570\u66f4\u65b0\u503c\n    optimizer.step()    # \u5c06\u53c2\u6570\u66f4\u65b0\u503c\u65bd\u52a0\u5230 net \u7684 parameters \u4e0a\n\n#\u756b\u5716\nfor t in range(200):\n    if t % 10 == 0:\n        # plot and show learning process\n        plt.cla()\n        plt.scatter(x.data.numpy(), y.data.numpy())\n        plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)\n        plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})\n        plt.pause(0.1)","a73e1252":"variable(\u8b8a\u91cf)","a75093fd":"regression"}}