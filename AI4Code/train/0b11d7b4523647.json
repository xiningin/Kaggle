{"cell_type":{"5b9161fd":"code","69d68e50":"code","d2137b04":"code","83528eac":"code","1c098751":"code","bc9ee1cc":"code","4ddc095a":"code","7e6ad74d":"code","08a286e9":"code","0271bb06":"code","99ae4949":"code","d5e30a74":"code","f79bc4c3":"code","3cd7cf71":"code","0115254a":"code","e92b47ca":"code","f4f05316":"code","d5d302f8":"code","f21218f3":"code","a2d1113d":"code","c291461b":"code","a4c8ee93":"code","8706aed7":"code","4de6943d":"code","5ac35d9e":"code","f0a03914":"code","d353b6ae":"code","5da017b4":"code","da05b342":"code","93a89c44":"markdown","3ff0c092":"markdown"},"source":{"5b9161fd":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nimport glob\nimport cv2\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","69d68e50":"#constants\n\nFAST_RUN = False\nIMAGE_WIDTH=64\nIMAGE_HEIGHT=64\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","d2137b04":"filenames = os.listdir(\"..\/input\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename[4]\n    if category == 'r':   #paper\n        categories.append(0)\n    elif category == 's': #glass\n        categories.append(1)\n    elif category=='t': #plastic\n        categories.append(2)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","83528eac":"df.head()","1c098751":"df.tail()","bc9ee1cc":"df['category'].value_counts().plot.bar()","4ddc095a":"sample = random.choice(filenames)\nimage = load_img(\"..\/input\/train\/\"+sample)\nplt.imshow(image)\nprint(sample)","7e6ad74d":"from numpy.random import seed\nimport tensorflow as tf\n\n\nseed(42)\ntf.random.set_seed(42)\n    ","08a286e9":"model = Sequential()\n\nmodel.add(Conv2D(8, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(4, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(4, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(4, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax')) # 3 because we have 3 categories\n\nopt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","0271bb06":"df[\"category\"] = df[\"category\"].replace({0: 'paper', 1: 'glass', 2: 'plastic'}) \ndf['category'].value_counts().plot.bar()","99ae4949":"train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","d5e30a74":"train_df['category'].value_counts().plot.bar()","f79bc4c3":"validate_df['category'].value_counts().plot.bar()","3cd7cf71":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=35","0115254a":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"..\/input\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())","e92b47ca":"validation_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"..\/input\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","f4f05316":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"..\/input\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","d5d302f8":"example_df = validate_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"..\/input\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","f21218f3":"epochs=20 if FAST_RUN else 100\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    #callbacks=callbacks\n)","a2d1113d":"model.save_weights(\"model.h5\")","c291461b":"\nplt.plot(history.history['loss'], color='b', label=\"Training loss\")\nplt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","a4c8ee93":"acc = np.mean(history.history['accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('Accuracy',(acc*100)))\n\n\n\nplt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nplt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","8706aed7":"test_filenames = os.listdir(\"..\/input\/test\/\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","4de6943d":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/input\/test\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","5ac35d9e":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","f0a03914":"test_df['category'] = np.argmax(predict, axis=-1)","d353b6ae":"label_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","5da017b4":"test_df['category'] = test_df['category'].replace({ 'plastic': 2,'glass': 1, 'paper': 0 })","da05b342":"sample_test = test_df.head(40)\n\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"..\/input\/test\/\"+filename, target_size=IMAGE_SIZE)\n    plt.subplot(8, 5, index+1)\n    plt.title('pred:%s' % (labels[np.argmax(predict[index])]))\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","93a89c44":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\nearlystop = EarlyStopping(patience=10)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.1, \n                                            min_lr=0.000001)\n\ncallbacks = [earlystop, learning_rate_reduction]","3ff0c092":"# **Building Model**\n"}}