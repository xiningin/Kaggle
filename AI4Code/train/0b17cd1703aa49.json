{"cell_type":{"7d7d102e":"code","3fcfcaee":"code","4a0aecba":"code","97ff2464":"code","2f99dca0":"code","aa2d9d58":"code","354a3afe":"code","62bf5cde":"code","3ca228d5":"code","d53d330f":"code","c307618f":"code","7af96552":"code","7f90f7e6":"code","35162bc3":"code","ba8671ae":"code","95685be2":"code","fc6cdcf6":"code","2ae4eb35":"code","28b001c3":"markdown"},"source":{"7d7d102e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fcfcaee":"import seaborn as sns\nimport matplotlib.pyplot as plt","4a0aecba":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()\n\nX_test = test_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]","97ff2464":"\ndf = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n\n# Let's start with splitting numerical cols and cat columns\ndf_nums = df.select_dtypes(exclude='object')\ndf_objs = df.select_dtypes(include='object')\n\n# transform in dummy variables, dropping the k-est columns of\n#every feature to avoid dummy trap.\ndf_objs = pd.get_dummies(df_objs, drop_first=True)\n\n# rejoin all the columns\nfinal_df = pd.concat([df_nums,df_objs],axis=1)\n\nfinal_df.head()\n","2f99dca0":"X = final_df[['Pclass', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare']]\ny = final_df['Survived']\n\nX.head()","aa2d9d58":"X.info()","354a3afe":"# DEPENDENCY OF N\u00b0 SIBLING RESPECT AGE\nsns.scatterplot(x='Age',y= 'SibSp',data=X)","62bf5cde":"X['Age'] = X.groupby('SibSp')['Age'].transform(lambda val: val.fillna(val.mean()))\nX['Age'] = X['Age'].fillna(0)","3ca228d5":"X.info()","d53d330f":"# ------ RANDOM FOREST ----------\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n\n# Training the Random Forest Classification model on the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators =10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Complete report!!\nprint(classification_report(y_test,y_pred))\nprint( 'ACCURACY = (TP + TN) \/ ALL \\nPRECISION = TP \/ (TP + FP) \\nRECALL = TP \/ (TP + FN) \\nF1 SCORE = (2*PRECISION*RECALL) \/ (PRECISION + RECALL)')\n","c307618f":"df = test_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n\n# Let's start with splitting numerical cols and cat columns\ndf_nums = df.select_dtypes(exclude='object')\ndf_objs = df.select_dtypes(include='object')\n\n# transform in dummy variables, dropping the k-est columns of\n#every feature to avoid dummy trap.\ndf_objs = pd.get_dummies(df_objs, drop_first=True)\n\n# rejoin all the columns\nfinal_df = pd.concat([df_nums,df_objs],axis=1)\n\nfinal_df.head()","7af96552":"X_test_fin = final_df[['Pclass', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare']]\nX_test_fin.head()","7f90f7e6":"X_test_fin.info()","35162bc3":"X_test_fin['Fare'] = df['Fare'].transform(lambda val: val.fillna(val.mean()))\nX_test_fin.info()","ba8671ae":"X_test_fin['Age'] = X_test_fin.groupby('SibSp')['Age'].transform(lambda val: val.fillna(val.mean()))\nX_test_fin['Age'] = X_test_fin['Age'].fillna(0)\nX_test_fin.info()","95685be2":"X_test_fin['Age'].hist(bins=20)","fc6cdcf6":"# Predicting the Test set results\ny_pred_fin = classifier.predict(X_test_fin)\ny_pred_fin","2ae4eb35":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred_fin})\noutput.head()","28b001c3":"#pclass: A proxy for socio-economic status (SES) (best : 1, worse: 3)\n#sibsp \t# of siblings \/ spouses aboard the Titanic\n#parch \t# of parents \/ children aboard the Titanic\n#ticket \tTicket number \t\n#fare \tPassenger fare \t\n#cabin \tCabin number \t\n#embarked \tPort of Embarkation"}}