{"cell_type":{"c9ae40eb":"code","95002867":"code","7a8e09dd":"code","59dfbedd":"code","6ce888b3":"code","dcf04d66":"code","ce0c3c6c":"code","bb1e2a6c":"code","9defa09a":"code","1064a17d":"markdown","fea92c95":"markdown","a7d79ae7":"markdown","bea43f4d":"markdown","a793fd80":"markdown","fee4dd2d":"markdown","794b1677":"markdown","55c10a14":"markdown"},"source":{"c9ae40eb":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport matplotlib.text as  mtext\n\ndf = pd.read_csv('..\/input\/ncaam-march-madness-scores-19852021\/data_cleaned.csv')\nsns.set()\n%matplotlib inline","95002867":"margin = df['WSCORE']-df['LSCORE']\n#we'll hang on to the histogram values for use later\nhist, bin_edges = np.histogram(margin,range=(1,np.max(margin)+1),bins=np.max(margin))\nprob = hist\/np.sum(hist)\n\nm = np.median(margin)\nplt.axvline(x=np.median(margin),color='C1',linestyle='--')\nplt.annotate(f'Median = {np.median(margin)}',(1.1*np.median(margin),0.95*max(hist)))\nsns.histplot(margin,discrete=True)\nplt.xlabel('Margin of Victory')\nplt.show()","7a8e09dd":"twowaysum = np.zeros(len(prob))\nfor i in range(len(prob)):\n    diff = abs(i+1-m)\n    if m-diff < 0:\n        lower = 0\n    else:\n        lower = int(m-diff)\n    twowaysum[i] = np.sum(prob[lower:int(m+diff+1)])\n\n#the \"relative pain of loss\" based on scoring margin will be used later. Save this as csv if you're doing this offlinne\nscore_margin_df = pd.DataFrame(data={'Margin':bin_edges[:-1],'Relative Pain':twowaysum})\nplt.plot(bin_edges[:-1],twowaysum)\nplt.xlabel(\"Margin of Loss\")\nplt.ylabel(\"Relative Pain of Loss\")\nplt.show()","59dfbedd":"seed_diff = df['WSEED']-df['LSEED']\ncounts = seed_diff.value_counts()\nsd = np.arange(0,16)\nupset,normal = np.zeros(len(sd)), np.zeros(len(sd))\n#some wins have never happened (a 16 has never faced a 2 and a 15 has never faced a 1), so we'll use some try\/except statements here\nfor i in sd:\n    try:\n        upset[abs(i)] = counts[i]\n    except:\n        upset[abs(i)] = 0\n\n    try:\n        normal[abs(i)] = counts[-i]\n    except:\n        upset[abs(i)] = 0\n\n#same as with the scoring margin dataframe, we'll save the win chance df for later use\np_upset = upset\/(upset+normal)\np_normal = normal\/(upset+normal)\nwin_chance_df = pd.DataFrame(data={'Seed Difference':sd,'P Expected Win':p_normal,'P Upset Win':p_upset})\n\nbar1 = sns.barplot(x=sd, y=p_normal, color='#f9bc86',label='Higher Ranked Team')\nbar2 = sns.barplot(x=sd, y=p_upset, bottom=p_normal, color='#a3acff',label='Lower Ranked Team')\nplt.legend(loc='upper right',bbox_to_anchor=(1,1.2))\nplt.xlabel('Difference in Seed')\nplt.ylabel('Probability of Winning')\nplt.show()","6ce888b3":"all_teams = np.concatenate((df['WTEAM'],df['LTEAM']))\nteams  = np.unique(all_teams)\nprev_year = dict.fromkeys(teams, 0)\nhb = pd.DataFrame(np.zeros(len(teams)),teams,columns=['1984'])","dcf04d66":"years = np.sort(df['YEAR'].unique())\nfor year in years:\n    results = df[df['YEAR'] == year]\n    new_pain = {}\n    for i,row in results.iterrows():\n        seed_diff = int(row['LSEED']-row['WSEED'])\n        margin =  int(row['WSCORE']-row['LSCORE'])\n        #this 1.007 is explained above\n        sp = 1.007-score_margin_df.iloc[margin-1]['Relative Pain']\n        round_mod = np.exp(0.3722*row['ROUND'])\n        #this modifier basically exists to say that regardless of scores\/seeds, it hurts more to lose later in the tournament\n        #this is determine based on a fit to viewership for an average game based on which round it is, which has a strong (R^2=0.97) correlation\n        #sources for viewership for the last 2 tournaments: https:\/\/www.sportsvideo.org\/2021\/04\/01\/ratings-roundup-a-deep-dive-into-march-madness-numbers-uconn-baylor-in-ncaa-womens-tournament-hits-ten-year-high\/ and https:\/\/www.sportsmediawatch.com\/ncaa-final-four-ratings-history-most-watched-games-cbs-tbs-nbc\/\n        if seed_diff >  -0.5: #this is the expected case\n            wc = win_chance_df.iloc[seed_diff]['P Expected Win']\n        else: #this is the upset case\n            wc = win_chance_df.iloc[-1*seed_diff]['P Upset Win']\n\n        new_pain[row['LTEAM']] = round_mod\/(wc*sp)\n        #if the game was the championship game, wipe away the winner's heartbreak\n        if row['ROUND'] == 6:\n             new_pain[row['WTEAM']] = (-2\/3)*prev_year[row['WTEAM']]\n\n    current_pain = {}\n    for team in prev_year:\n        #decay previous heartbreak by 2\/3rds\n        current_pain[team] = prev_year[team]*(2\/3)\n        if team in list(new_pain.keys()):\n            current_pain[team] += new_pain[team]\n\n    temp = pd.DataFrame(current_pain.values(),current_pain.keys(),columns=[str(year)])\n    hb = pd.concat([hb,temp],axis=1)\n    prev_year = current_pain","ce0c3c6c":"hb['2021'].sort_values(ascending=False)[0:10]","bb1e2a6c":"prev_year = dict.fromkeys(teams, 0)\nhb = pd.DataFrame(np.zeros(len(teams)),teams,columns=['1984'])\n\nyears = np.sort(df['YEAR'].unique())\nfor year in years:\n    results = df[df['YEAR'] == year]\n    new_pain = {}\n    for i,row in results.iterrows():\n        seed_diff = int(row['LSEED']-row['WSEED'])\n        margin =  int(row['WSCORE']-row['LSCORE'])\n        sp = 1.007-score_margin_df.iloc[margin-1]['Relative Pain']\n        round_mod = np.exp(0.3722*row['ROUND'])\n        if seed_diff >  -0.5:\n            wc = win_chance_df.iloc[seed_diff]['P Expected Win']\n        else:\n            wc = win_chance_df.iloc[-1*seed_diff]['P Upset Win']\n\n        new_pain[row['LTEAM']] = round_mod\/(wc*sp)\n\n    current_pain = {}\n    for team in prev_year:\n        current_pain[team] = prev_year[team]\n        if team in list(new_pain.keys()):\n            current_pain[team] += new_pain[team]\n\n    temp = pd.DataFrame(current_pain.values(),current_pain.keys(),columns=[str(year)])\n    hb = pd.concat([hb,temp],axis=1)\n    prev_year = current_pain","9defa09a":"hb['2021'].sort_values(ascending=False)[0:10]","1064a17d":"Now let's move on to the seeds of each team. The first round has predetermined matchups (1 vs 16, 2 vs 15, etc.), but past that point we need to look at each actual seed difference and how often they win. This will help us later to quantify just how rare it is for a \\#3 to beat a \\#1, or anyn other random matchup that may happen.","fea92c95":"The heartbreak dataframe is now complete! Let's take a look at the results for the top 10 most heartbroken teams currently (2021)","a7d79ae7":"There's Virginia in \\#1, still followed up by Oklahoma. Duke is third, but possibly just because they go to the tournament so often, which is a flaw with the idea of heartbreak never going away. But that's just a subjective part of the model.","bea43f4d":"Now time for the calculation. I decided to use the probability of the seed matchup resulting in the win\/loss of the game, the probabilty of the score being not 10 points (either higher or lower), and the round. A little bit of extra research shows (links in comments below) shows that the average viewership for each game follows an exponential curve (e^0.3722\\*round) so I will use that found the heartbreak factor as well.\n\nThe seemingly-random 1.007 is created to prevent a divide by 0 error, and make sure that the worst scoring difference ever is equal to the worst seed upset ever. The worse loss ever (58 points) has a value of 1. The worst seed upset (16 UMBC beat 1 Virginia) has a probability of 1\/144, or 0.007\n\nLastly I decided to add in a time-decay\/winning element. Each year the previous year's heartbreak decays geometrically (beinng multiplied by 2\/3rd, meaning that after 10 years a heartbreak is only 2% of how it originally felt). And if a team wins the whole tournament their entire heartbreak is wiped clean. Don't believe me? Ask a Cubs fan.","a793fd80":"Oklahoma has it! Without worrying too much about details, this does make sense: Oklahoma was handed to largest loss in Final Four history in 2016 when they lost to Villanova 95-51. That's a very late round and a very large margin of loss, so it makes sense.\n\nVirginia *could* have shown up here for their 2018 loss to UMBC (the only time a \\#1 seed has ever lost to a \\#16 team, and it was by 20 points) but they went on to win the whole tournament in 2019, wiping their entire slate clean. Let's see how things would go if heartbreak never went away. Just need to recreate the heartbreak dataframe...","fee4dd2d":"In order to create a metric for \"heartbreak\" we should check out what the data looks like and what we can get out of it. Let's start with the margin of victory.","794b1677":"The margin of victory seems to be decently distributed. We could try fitting this with a distribution (possibly a modified Poisson distribution?) but instead we can just pull from this discrete distribution. I have marked the median because I personally wanted to capture the feeling of how rare the margin of loss is compared to the average. I would argue that losing by 1 hurts as much as losing by 20. So let's integrate from the median outwards in both directions. (If you think that losing by more points is strictly worse, then just integrate from 0 to the right. If you think that losing by a narrow margin is strictly worse, then just integrate from 60 to the left.)","55c10a14":"Okay we're ready to start calculating (I'll mention the round of the game later). Start off by initializing a dataframe for heartbreak of each time in each year. There were tournaments before 1985, but that's where this data begins (as the 64-team format began in 1985) so we set everyone to 0 heartbreak at that point."}}