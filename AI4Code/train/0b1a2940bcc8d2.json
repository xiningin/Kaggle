{"cell_type":{"7e4167e4":"code","1ffb1922":"code","926e7a12":"code","0cd24928":"code","25726e8d":"code","ed0a1434":"code","060dd6ca":"code","53d59c04":"code","ec3aaa49":"code","5d763d32":"code","916dcaa2":"code","e8d3669e":"code","3bbafa79":"code","afa441b3":"code","f5bb214f":"code","b83efe61":"code","5113ab0f":"code","3e716e90":"code","8015d1dd":"code","ed75558f":"code","3e64d0ea":"code","d1faae86":"code","97b80406":"code","f8250a00":"code","036feb7c":"code","073c4847":"code","c8c7168a":"code","da381f5c":"code","9caebcbe":"code","6e8ff33b":"code","0181b7d0":"code","ed44bc85":"code","0cd767fe":"markdown","cde68def":"markdown","36831e8e":"markdown","2f86ed9a":"markdown","647835fc":"markdown","f7d95961":"markdown","b26bcc18":"markdown","bee9628e":"markdown","f976d784":"markdown","3607f2e6":"markdown","6ddfdb23":"markdown","fa508308":"markdown","5cc94c99":"markdown","e2dea7c3":"markdown","0968c836":"markdown","2a3d6580":"markdown","7a784c0a":"markdown","ebf6f066":"markdown","f72d7598":"markdown","1ac4f34c":"markdown","8b748d41":"markdown","07243b64":"markdown","ba96bc94":"markdown"},"source":{"7e4167e4":"import numpy as np  \nimport pandas as pd  \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n","1ffb1922":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","926e7a12":"LABELS = [\"No Claim Filed\", \"Claim Filed\"]","0cd24928":"data = pd.read_csv('\/kaggle\/input\/porto-seguro-safe-driver-prediction\/train.csv')","25726e8d":"data.head()","ed0a1434":"data.shape","060dd6ca":"data.target.value_counts()","53d59c04":"sns.countplot(data.target);\nplt.xlabel('Is Filed Claim?');\nplt.ylabel('Number of occurrences');\nplt.show()","ec3aaa49":"count_classes = pd.value_counts(data['target'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot = 0)\n\nplt.title(\"Claims Distribution\")\n\nplt.xticks(range(2), LABELS)\n\nplt.xlabel(\"Claims --> \")\n\nplt.ylabel(\"Frequency --> \")\n\nplt.show()","5d763d32":"X = data.drop('target', axis = 1)\ny = data.target\n\ndata.shape, X.shape, y.shape","916dcaa2":"# y_us.value_counts()[0] \n# X.shape[0]","e8d3669e":"data_table = pd.DataFrame()\n\ndata_table['technique'] = ['Original Data']\ndata_table['X_Shape'] = [X.shape[0]]\ndata_table['y_Shape'] = [y.shape[0]]\ndata_table['target_0'] = [y.value_counts()[0]]\ndata_table['target_1'] = [y.value_counts()[1]]\n\ndata_table","3bbafa79":"from imblearn.under_sampling import NearMiss","afa441b3":"nm = NearMiss()","f5bb214f":"X_us, y_us = nm.fit_sample(X, y)","b83efe61":"print('Shape for Imbalanced Class :')\ndisplay(X.shape, y.shape)\nprint('Count of target : {} '.format(y.value_counts()))\n\n\nprint('Shape for Balanced Class :')\ndisplay(X_us.shape, y_us.shape)\nprint('Count of target : {} '.format(y_us.value_counts()))","5113ab0f":"new_row = {'technique': 'Under Sampling - NearMiss', 'X_Shape': X_us.shape[0], 'y_Shape':y_us.shape[0], 'target_0': y_us.value_counts()[0], 'target_1' : y_us.value_counts()[1]}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","3e716e90":"from imblearn.under_sampling import RandomUnderSampler","8015d1dd":"rus = RandomUnderSampler(random_state=42, replacement=True)  \nX_rus, y_rus = rus.fit_resample(X, y)","ed75558f":"new_row = {\n    'technique': 'Under Sampling - RandomUnderSampler', \n    'X_Shape': X_rus.shape[0], \n    'y_Shape':y_rus.shape[0], \n    'target_0': y_rus.value_counts()[0], \n    'target_1' : y_rus.value_counts()[1]\n}\n\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","3e64d0ea":"from imblearn.over_sampling import RandomOverSampler","d1faae86":"os = RandomOverSampler() # Default sampling_strategy='auto'","97b80406":"X_os, y_os = os.fit_sample(X, y)","f8250a00":"new_row = {\n    'technique': 'Over Sampling - Auto', \n    'X_Shape': X_os.shape[0], \n    'y_Shape':y_os.shape[0], \n    'target_0': y_os.value_counts()[0], \n    'target_1' : y_os.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","036feb7c":"os2 = RandomOverSampler(sampling_strategy=0.5)\n\nX_os2, y_os2 = os2.fit_sample(X, y)","073c4847":"new_row = {\n    'technique': 'Over Sampling - half', \n    'X_Shape': X_os2.shape[0], \n    'y_Shape':y_os2.shape[0], \n    'target_0': y_os2.value_counts()[0], \n    'target_1' : y_os2.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","c8c7168a":"from imblearn.over_sampling import SMOTE\n","da381f5c":"smote = SMOTE(sampling_strategy = 'minority')\nX_smote, y_smote = smote.fit_sample(X, y)","9caebcbe":"new_row = {\n    'technique': 'SMOTE - minority', \n    'X_Shape': X_smote.shape[0], \n    'y_Shape':y_smote.shape[0], \n    'target_0': y_smote.value_counts()[0], \n    'target_1' : y_smote.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","6e8ff33b":"from imblearn.combine import SMOTETomek","0181b7d0":"smk = SMOTETomek(random_state=9)\nX_smk, y_smk = smk.fit_sample(X, y)","ed44bc85":"new_row = {\n    'technique': 'SMOTETomek_9', \n    'X_Shape': X_smk.shape[0], \n    'y_Shape':y_smk.shape[0], \n    'target_0': y_smk.value_counts()[0], \n    'target_1' : y_smk.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","0cd767fe":"## In here first i am going to focus on the Imbalanced Class handling.","cde68def":"You can try with various other random state.","36831e8e":"# 1: Under Sampling","2f86ed9a":"Lets have the counts in some kind of DataFrame to see the difference in a glance.","647835fc":"# 1.2 Under Sampling using RandomUnderSampler\n`RandomUnderSampler` is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. \n\nUnder-sample the majority class(es) by randomly picking samples with or without replacement.","f7d95961":"# Target \/ Class Exploration","b26bcc18":"# 3: SMOTE\n`SMOTE` (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picingk a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n\nThis technique generates synthetic data for the minority class.\n\nhttps:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.SMOTE.html ","bee9628e":"A widely adopted technique for dealing with highly unbalanced datasets is called resampling. \n\nIt consists of removing samples from the majority class (under sampling) and \/ or adding more examples from the minority class (over sampling).\n\nDespite the advantage of balancing classes, these techniques also have their weaknesses. \n\n* The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. \n* In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n\nTo implement this resampling techniques we are going to use Python imbalanced-learn module (`imblearn`). It is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n\nOther resampling techniques like SMOTE; SMOTETomek etc are also there, which will see below.","f976d784":"# Data Load","3607f2e6":"# 4: SMOTETomek\nIts a combination of over-sampling and under-sampling, using the SMOTE and Tomek links techniques.","6ddfdb23":"# 2: Over Sampling\nOne way to fight imbalance data is to generate new samples in the minority classes. The most naive strategy is to generate new samples by randomly sampling with replacement of the currently available samples. The `RandomOverSampler` offers such a scheme.","fa508308":"# Porto Seguro Safe Driver Prediction Competation\n\nhttps:\/\/www.kaggle.com\/c\/porto-seguro-safe-driver-prediction\/data\n\nIn this competition, we will predict the probability that an auto insurance policy holder files a claim.\n\nPlease read the overview and Evaluation process.","5cc94c99":"As we already know that the proportion of records with `target` = 1 (Claim Filed) is far less than `target` = 0 (No Claim Filed). \n\nThis can lead to a model that has great accuracy but does have any added value in practice.","e2dea7c3":"# Import Library","0968c836":"Set the label","2a3d6580":"Lets visualize the same with more precise","7a784c0a":"There are various other parameters such as `random_state`, `k_neighbors` etc which can be changed as well.","ebf6f066":"Before we start with handling, lets have X and y.","f72d7598":"Note: One can select any of the technique based on the problem, but make sure to use proper and correct evulation metrix.\n\nDont go with accuracy; score. \n\nSome of the metrics, which might works best with such imbalanced dataset are as below. Try considering them.\n1. Confusion Matrix\n2. Precision\n3. Recall\n4. F1-Score\n5. AUC-ROC Curve","1ac4f34c":"Get the count of target.","8b748d41":"# Techniques to handle Class Imbalance","07243b64":"# 1.1 Under Sampling using NearMiss","ba96bc94":"We already knew that the `target` columns signifies whether or not a claim was filed for that policy holder."}}