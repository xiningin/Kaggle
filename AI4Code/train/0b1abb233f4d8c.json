{"cell_type":{"7b3b629c":"code","465f04bd":"code","797d2e1d":"code","e412d922":"code","b4f5481d":"code","8d25963c":"code","18b5733f":"code","998bb694":"code","096383b1":"code","f96165d1":"code","191796d3":"code","da7c341e":"code","63847802":"code","7f01933d":"code","cb7f94bc":"code","48ce6c45":"code","88abfc5d":"code","1f9c0c1a":"code","5375ab6a":"code","c7a6dc8a":"code","9d8aa5f6":"code","f90233b0":"markdown","f455d2a9":"markdown","bc7bafdf":"markdown","8d86917c":"markdown","c9aea69c":"markdown","50f50456":"markdown","b05913c6":"markdown","432aa42e":"markdown","00bf0cfc":"markdown","230ff256":"markdown","d8ea1e3c":"markdown","937b849d":"markdown","60cf3e41":"markdown","141a58ae":"markdown","a1d2b044":"markdown","3fb033fd":"markdown"},"source":{"7b3b629c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nfrom scipy.interpolate import interp1d\nimport pylab","465f04bd":"pylab.rcParams['figure.figsize'] = (9, 6.0)","797d2e1d":"xs=np.linspace(-5,10,200)\nks= np.arange(50)","e412d922":"pmf_binom=st.binom.pmf(ks,50,0.25) # Modelling a Binomial distribution with probabilty of success = 25%\nplt.bar(ks,pmf_binom,label=\"Binomial Distribution\",alpha=0.8) \npmf_poisson=st.poisson.pmf(ks,30) # Modelling a poisson distribution with average 30 (say, average support calls received every night)\nplt.bar(ks,pmf_poisson,label=\"Poisson Distribution\",alpha=0.8)\nplt.xlabel(\"K value\")\nplt.ylabel(\"Probability\")\nplt.legend();","b4f5481d":"\nprint(f\"Probability of getting 10 successes: {st.binom.pmf(10,50,0.25):.3f} \")\nprint(f\"Probability of getting upto 15 successes : {st.binom.cdf(15,50,0.25):.3f} \")\nprint(f\"Probability of getting 45 calls in a night: {st.poisson.pmf(45,30):.4f}\")\nprint(f\"Probability of getting atleast 40 calls in a night: {st.poisson.sf(40,30):.4f}\") #It's same as 1-CDF\n","8d25963c":"unif_pdf=st.uniform.pdf(xs,-4,10)\nplt.plot(xs,unif_pdf,label=\"Uniform(-4,10)\",alpha=0.8,ls=\"--\")\nnorm_pdf=st.norm.pdf(xs,5,2)\nplt.plot(xs,norm_pdf,label=\"Normal(5,2)\",alpha=0.8,ls=\"--\")\nexp_pdf=st.expon.pdf(xs,2)\nplt.plot(xs,exp_pdf,label=\"Exponential(0.5)\",alpha=0.8,ls=\"--\")\nst_pdf=st.t.pdf(xs,1)\nplt.plot(xs,st_pdf,label=\"T (1)\",alpha=0.8,ls=\"--\")\npdf_lognorm=st.lognorm.pdf(xs,1)\nplt.plot(xs,pdf_lognorm,label=\"Lognorm (1)\",alpha=0.8,ls=\"--\")\n\nplt.legend()\nplt.xlabel(\"xs\")\nplt.ylabel(\"Probability\");","18b5733f":"# Let's define some random xs and ys\nxs = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, \n      5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0]\nys = [0.2, 0.165, 0.167, 0.166, 0.154, 0.134, 0.117, \n      0.108, 0.092, 0.06, 0.031, 0.028, 0.048, 0.077, \n      0.103, 0.119, 0.119, 0.103, 0.074, 0.038, 0.003]","998bb694":"plt.scatter(xs,ys,label=\"Data\")\nplt.xlabel(\"Xs\")\nplt.ylabel(\"Observed PDF\")\nplt.title(\"Random Distribution\");","096383b1":"x1=np.linspace(min(xs),max(xs),1000) # Defining an array of xs\ny1=interp1d(xs,ys)(x1) # Interpolate function; Linear\ny2=interp1d(xs,ys,kind=\"quadratic\")(x1) #Quadratic","f96165d1":"plt.plot(x1,y1,label=\"Linear\")\nplt.plot(x1,y2,label=\"Quadratic\")\nplt.scatter(xs,ys,c='black',s=30,label=\"Original\")\nplt.xlabel(\"Xs\")\nplt.ylabel(\"Observed PDF\")\nplt.title(\"Emperical Distribution\");\nplt.legend();","191796d3":"from scipy.integrate import simps\n\ndef get_pdf(x,y,a,b,res=1000):\n    x_norm=np.linspace(min(x),max(x),res)\n    y_norm=interp1d(x,y,kind=\"quadratic\")(x_norm)\n    normalization=simps(y_norm,x_norm)\n    \n    x1=np.linspace(a,b,res)\n    y1=interp1d(x,y,kind=\"quadratic\")(x1)\n    pdf=simps(y1,x=x1)\/normalization\n    return pdf\n\ndef get_cdf(x,y,v):\n    return get_pdf(x,y,min(x),v)\n    \ndef get_sf(x,y,v):\n    return 1- get_cdf(x,y,v)","da7c341e":"def plot_pdf(x,y,a,b):\n    x_interpolate=np.linspace(min(x),max(x),1000)\n    y_interpolate=interp1d(x,y,kind=\"quadratic\")(x_interpolate)\n    plt.plot(x_interpolate,y_interpolate,label=\"Interpolation\")\n    plt.scatter(x,y,s=20,label=\"Original\")\n    z=plt.fill_between(x1,0,y_interpolate,where=(x1>=a) & (x1<=b),alpha=0.5)\n    plt.annotate(f\"p = {get_pdf(x,y,a,b):.3f}\",(7,0.05))\n    plt.xlabel(\"Values of Xs\")\n    plt.ylabel(\"Probability\")\n    plt.title(\"PDF of a Non-Parametrized Distribution\")\n    plt.legend()","63847802":"print(f\"Probability of getting a value between 6 and 9 is: {np.round(get_cdf(xs,ys,v=9)-get_cdf(xs,ys,v=6),3)}\")\nplot_pdf(xs,ys,a=6,b=9)","7f01933d":"x1=np.linspace(min(xs),max(xs),1000)\ny2=interp1d(xs,ys,kind=\"quadratic\")(x1)\ncdf=y2.cumsum()\/y2.sum()\nplt.plot(x1,cdf)\nplt.xlabel(\"Values of xs\")\nplt.ylabel(\"Probability of X<=x\")\nplt.title(\"CDF of a Non-Parametrized Distribution\");","cb7f94bc":"plt.hist(st.norm.rvs(10,2,1000),bins=50);  # Random Sampling from a normal distribution. There arrays show the X and Y values\nplt.xlabel(\"Xs\")\nplt.ylabel(\"PDF Outcome\");\nprint(f\"10 samples from a Normal distribution with mean 10 and sd 2:\\n {st.norm.rvs(10,2,10)}\")\n","48ce6c45":"samples=np.ceil(st.uniform.rvs(0,6,(1000,3))).sum(axis=1)\nprint(f\"Number of times the rolled sum was greater than 16 is {np.sum(samples>16)}\")\nplt.hist(samples,bins=50);\nplt.xlabel(\"Sum of three dice\")\nplt.ylabel(\"frequency\")\nplt.title(\"Sum of three dice in 1000 rolls\");","88abfc5d":"xs=np.linspace(0,4,200) #Defining p(x)\ndef pdf(xs):\n    return(np.sin(xs**2)+1)\n\npx=pdf(xs)","1f9c0c1a":"plt.plot(xs,px,label=\"Actual curve\")\nplt.fill_between(xs,0,px,alpha=0.1)\nplt.xlim(0,4)\nplt.ylim(0,2)\nplt.xlabel(\"Values of Xs\")\nplt.ylabel(\"P(x)\");","5375ab6a":"random_x=st.uniform.rvs(0,4,100)\nrandom_y=st.uniform.rvs(0,4,100)\nplt.scatter(random_x,random_y,label=\"Random samples\")\nplt.plot(xs,px,label=\"Actual curve\")\nplt.fill_between(xs,0,px,alpha=0.1)\nplt.xlim(0,4)\nplt.ylim(0,2)\nplt.xlabel(\"Values of Xs\")\nplt.ylabel(\"P(x)\")\nplt.title(\"Sampling from uniform distribution\")\nplt.legend(loc=2);","c7a6dc8a":"passed=random_y<pdf(random_x)\nplt.scatter(random_x[passed],random_y[passed],label=\"Picked\",c='g',s=20)\nplt.scatter(random_x[~passed],random_y[~passed],label=\"rejected\",c='r',s=20,marker='x')\nplt.plot(xs,px,label=\"Distribution\",ls=\"--\")\nplt.fill_between(xs,0,px,alpha=0.1)\nplt.xlim(0,4)\nplt.ylim(0,2)\nplt.legend(loc=2)\nplt.xlabel(\"Values of Xs\")\nplt.ylabel(\"P(x)\")\nplt.title(\"Rejecting the samples lying beyond the p(x) region\");","9d8aa5f6":"n2=100000\nx=st.uniform.rvs(scale=4,size=n2) #Scale is just the parameter of uniform dist(b-a)\ny=st.uniform.rvs(scale=2,size=n2) #All the values \nx_final=x[y<=pdf(x)]  #Accepted values\nprint(f\"Number of points selected: {len(x_final)}\")\nintegral=simps(px,x=xs)\nplt.plot(xs,px\/integral,label=\"Actual curve\")\nplt.fill_between(xs,0,px\/integral,alpha=0.1) #to make this an actual PDF between 0 and 1\nplt.hist(x_final,density=True,histtype='step',bins=100,label='Sample PDF')\nplt.legend()\nplt.xlim(0,4)\nplt.ylim(0,0.5)\nplt.xlabel(\"Values of Xs\")\nplt.ylabel(\"Probability\");","f90233b0":"## Sampling from a distribution\n- Sampling can be done easily with the rvs function within each distribution","f455d2a9":"Hi Everyone, Posting my first kernel on understanding the basic statistical tools in scipy and invoking them.\nThere exist numerous probability distribution functions that define various real life phenomenon. I am going to explore a few popular discrete and continuous models. Along side, I am going to try form an emperical model for distributions which cannot be adequately parametrised into a few parameters. I'll also perform random sampling from such emperical distribution.","bc7bafdf":"#### Plotting the graph","8d86917c":"### Discrete PMFs\n- Binomial Distribution: It can be use to model probability distributions of $k$ sucesses in $n$ trials where the probability of success $p$ is known.\n\n $$Pr(k;n,p)=\\begin{pmatrix} n\\\\k \\end{pmatrix} p^k (1-p)^{n-k}$$\n \n\n- Poisson Distribution: The Poisson distribution is the discrete probability distribution of the number of events occurring in a given time period, given the average number of times the event occurs over that time period.\n\n$$P(k;\\lambda)= \\frac{\\lambda^k e^{-\\lambda}}{k}$$ ","c9aea69c":"\n\n\n# Thank You!\n\n","50f50456":"- The above chart looks nothing like we have seen before and if we we're required to find the values of y for any given x (other than what we already have) we would need to interpolate to find data in between the points.\n- We can define our interpolate function from scipy.Interpolate and use that to find the values of y.\n- I am going to define two fuctions, linear and quadratic, but if needed higher order functions can be used as well.","b05913c6":"- Above plot shows comparision between different distribution, given there respective parameters.\n- Uniform distribution has upper and lower bound as model parameters.\n- Normal distribution has it's mean and standard deviation that uniquely defines the curve. The mean defines the centre of the distribution and thus where the peak lies. The width is given by deviation that shows the spread of our data.\n- Exponential distribution can be used to model time intervals between two events and is parametrized by $\\lambda$, the rate of change. Radio active decay is the most popular example. \n- Log normal is often prefferd to model RVs which cannot take negative values, such as mass of objects and stock prices. Comparing the above graphs, we notice while the normal curve is symmetrical around the mean, log normal is positively skewed (right). Often, the skewness is important in determining the appropriate distribution for an investment decision-making.\n- Student's t-distribution is used where the population size is not enough to be considered as a normal distribution or the population variance is unknown. Above we have plotted a t-distribution with 1 degree of freedom.","432aa42e":"### Rejection Sampling\n\nLet us say we don't have a nice easy analytic distribution, and that we cannot use one to approximate our distribution. \nThe idea of rejection sampling is that although we cannot easily sample from $f$ , there exists another density $g$, like a Normal distribution,uniform distribution or perhaps a t-distribution, from which it is easy for us to sample (because there\u2019s a built in function or someone else wrote a nice function). Then we can sample from  g directly and then \u201creject\u201d the samples in a strategic way to make the resulting \u201cnon-rejected\u201d samples look like they came from f.\n\nThe problem with rejection sampling is that it is inefficient as considarable amaount of points will be rejected.\n\nIn a simpler way:\n\n1. Sample a uniform `x` value (You can choose any other predefined dist as well as long as it make sense)\n2. Sample a uniform `y` value from `0` to the maximum probability in your PDF\n3. If $y > p(x)$, throw out the point.\n\nEasier to see in practise. Lets try and sample from the *unnormalised* distribution $p(x) = \\sin(x^2) + 1$ from $0 \\rightarrow 4$ ","00bf0cfc":"We see that the Quadratic Function is smooth enough and does a really good job hence there is no reason to move to a cubic or higher order model as there won't be much different. However, can be explored if needed.\n\n\nNow let's calculate the CDF and the probability between two bounds Using `scipy.integrate`. We have to define our CDF function by integrating the pdf to get the cummalative value.\n\nWe have multiple options for that:\n\n* `scipy.integrate.trapz` for low accuracy but high speed.\n* `scipy.integrate.simps` for medium accuracy and pretty high speed.\n* `scipy.integrate.quad` for high accuracy and low sped.\n\nI am going to use `simps` but other options can be explored if needed.","230ff256":"- Let's do a Random sampling from rolls of three dice and check if the sum is greater\/smaller than certain number\n- Since all the sides are equaly likely we can take random sample from an uniform distribution","d8ea1e3c":"- For plotting the CDF of the function we need to take the cummalative sum over ys and normalize it to keep the value between 0 and 1.\n- An alternate way could be adding the pdfs, defined above, at every point of x which will give a more accurate result but will be considerable slower. As long as we have enough points, $cumsum()$ should work really well.","937b849d":"## Non Parametrised Statistics.\n- There are instances where we have no clue about the underlying distribution of the data and it cannot be given by a mathematical analytic form but instead has a random shape.\n- Where we don't have the parameters of the distibution we are considering.","60cf3e41":"We see that by taking `100000` points we just get around `59000` samples. So if we need `100000` samples in first place, then we have to keep testing more points.","141a58ae":"### Continous PDFs\n- Uniform Distribution: Every outcome is equaly likely and has a constant probability.\n\n$$\nf(x) = \\left\\{\n    \\begin{array}\\\\\n        \\frac{1}{b-a} & \\mbox{if } \\ a\\leq x \\leq b  \\\\\n        0 & \\mbox{otherwise } \n    \\end{array}\n\\right.\n$$\n\n\n- Normal Distribution\n\n\n$$\nf(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma}e^{-\\frac{1}{2}{\\begin{pmatrix}{{\\frac{x-\\mu}{2}}}\\end{pmatrix}}^2}\n$$\n\n\n- Exponential Distribution\n\n$$ f(x;\\lambda)= \\lambda e^{-\\lambda x}$$\n\n\n- Log Normal\n- Student's t-distribution","a1d2b044":"###### To plot a pdf we have to normalize the distribution by it's Integral value. \nNote: A histogram can be normalised just by adding $Density=True$. However, need to normalize the distrubution functions otherwise\n\nLet us sample from the above distribution. Note: if we need n samples, we just need to take some n2>n random samples and keep adding onto it as a part of n2 gets rejected, until we get n points.","3fb033fd":"#### Let's answer these questions: \n- What would be the probablity of getting 10 success from such binomial model?\n- Probability of getting upto 15 successes?\n- How likely are we to recieve 45 calls in one night?\n- What would be the probability of receiving at least 40 calls in one night."}}