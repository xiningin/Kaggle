{"cell_type":{"15e56a90":"code","adcf59e6":"code","f52741f7":"code","c7c96159":"code","e73cac24":"code","566ff7f4":"code","69f0fd9a":"code","bb26fafe":"code","72eb7ca8":"code","61897f11":"code","e2a72f87":"code","30ff69dd":"code","3d69405e":"code","3eca18ba":"code","62a2733a":"code","4bb7a921":"code","986b301f":"code","6c48fb66":"code","f5c32efe":"code","c06442a7":"code","04d3cc25":"code","98302dd3":"code","2faab227":"code","7fd4a83a":"code","763b5245":"code","b54b5515":"code","452d51db":"code","93d1f1e2":"code","c9fb203e":"code","ca657d57":"markdown","909495ec":"markdown","30e0a9f9":"markdown","aa3734b8":"markdown","f2cfd4e3":"markdown","28a80a12":"markdown","17c22a80":"markdown","d2723938":"markdown","996fa9fd":"markdown","9d3da904":"markdown","b9909adf":"markdown","7347dfb1":"markdown","472a62b8":"markdown","64d5dc68":"markdown","5d8e8b6a":"markdown","a983cdc9":"markdown","867c7b4f":"markdown","1cfa1728":"markdown","f8f029b4":"markdown","335fa88a":"markdown","8613cbad":"markdown","dc575f97":"markdown","1ae234b1":"markdown","81f9a732":"markdown"},"source":{"15e56a90":"import numpy as np \nimport pandas as pd \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom seaborn import heatmap\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import chi2\nimport pandas_profiling\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.tree import export_graphviz\n%matplotlib inline","adcf59e6":"traindf=pd.read_csv('..\/input\/titanic\/train.csv').set_index('PassengerId')\ntestdf=pd.read_csv('..\/input\/titanic\/test.csv').set_index('PassengerId')\n\ntraindf.columns","f52741f7":"cor=traindf.corr()\nmask = np.triu(np.ones_like(cor, dtype=np.bool))\nheatmap(cor.abs(),mask=mask,annot=True)","c7c96159":"print('Train DF')\nfor col in traindf:\n    \n    print(col,traindf[col].isna().sum())\nprint('-'*30)\nprint('Test DF')\nfor col in testdf:\n    \n    print(col,testdf[col].isna().sum())\n","e73cac24":"traindf[\"Age\"] = traindf[\"Age\"].fillna(traindf.groupby(\"Pclass\")[\"Age\"].transform(\"mean\"))\ntestdf[\"Age\"] = testdf[\"Age\"].fillna(testdf.groupby(\"Pclass\")[\"Age\"].transform(\"mean\"))","566ff7f4":"\ntraindf['Alone'] = np.where((traindf['Parch']==0) & (traindf['SibSp']==0), 1, 0)\ntraindf['NoFamily'] = traindf['SibSp']+traindf['Parch']\ntraindf['Cabin_N']=traindf['Cabin'].str.extract('(\\d+)')\ntraindf['Cabin_N']=pd.to_numeric(traindf['Cabin_N'])\ntraindf['Cabin_Ch']=traindf['Cabin'].str.extract('(\\D+)')\n\npattern = \",\\\\s(.*?)\\.\"\ntraindf['Title']=traindf['Name'].str.extract(pattern)","69f0fd9a":"testdf['Alone'] = np.where((testdf['Parch']==0) & (testdf['SibSp']==0), 1, 0)\ntestdf['NoFamily'] = testdf['SibSp']+testdf['Parch']\ntestdf['Cabin_N']=testdf['Cabin'].str.extract('(\\d+)')\ntestdf['Cabin_N']=pd.to_numeric(testdf['Cabin_N'])\ntestdf['Cabin_Ch']=testdf['Cabin'].str.extract('(\\D+)')\ntestdf['Title']=testdf['Name'].str.extract(pattern)","bb26fafe":"palette =[\"C3\",\"C2\"]\n\nf, axes = plt.subplots(3,3,figsize=(15,15))\n\n#f.delaxes(axes[2, 2])\nplt.figure()\n\nsns.countplot(x=\"Pclass\",data=traindf,hue='Survived',ax=axes[0,0],palette=palette)\nsns.countplot(x=\"Sex\",data=traindf,hue='Survived',ax=axes[0,1],palette=palette)\nsns.countplot(x=\"SibSp\",data=traindf,hue='Survived',ax=axes[0,2],palette=palette)\nsns.countplot(x=\"Parch\",data=traindf,hue='Survived',ax=axes[1,0],palette=palette)\nsns.countplot(x=\"Embarked\",data=traindf,hue='Survived',ax=axes[1,1],palette=palette)\nsns.countplot(x=\"Alone\",data=traindf,hue='Survived',ax=axes[1,2],palette=palette)\nsns.countplot(x=\"NoFamily\",data=traindf,hue='Survived',ax=axes[2,0],palette=palette)\nsns.countplot(x=\"Cabin_Ch\",data=traindf,hue='Survived',ax=axes[2,1],palette=palette)\nplt_t=sns.countplot(x=\"Title\",data=traindf,hue='Survived',ax=axes[2,2],palette=palette)\nplt_t.set_xticklabels(plt_t.get_xticklabels(), rotation=90)\nplt.show()","72eb7ca8":"cont_tbl=pd.crosstab(traindf['Title'], traindf['Survived'])\ncont_tbl_perc= pd.crosstab(traindf['Title'], traindf['Survived']).apply(lambda r: r\/r.sum(), axis=1)\npd.concat([cont_tbl,cont_tbl_perc],axis=1)\n","61897f11":"NoFamily_Cat_dict={}\nfor key in [0,4,5,6]:\n    NoFamily_Cat_dict[key]=1\n\nfor key in [1,2,3]:\n    NoFamily_Cat_dict[key]=2    \n\n    \nfor key in [7,10]:\n    NoFamily_Cat_dict[key]=3\n    \n\n    \ntraindf['NoFamily_Cat']=traindf['NoFamily'].map(NoFamily_Cat_dict)\ntestdf['NoFamily_Cat']=testdf['NoFamily'].map(NoFamily_Cat_dict)\n","e2a72f87":"Parch_Cat_dict={}\nfor key in [0,5]:\n    Parch_Cat_dict[key]=1\n\nfor key in [1,3]:\n    Parch_Cat_dict[key]=2    \n\n    \nfor key in [4,6]:\n    Parch_Cat_dict[key]=3\n    \n\nfor key in [2]:\n    Parch_Cat_dict[key]=4\n    \ntraindf['Parch_Cat']=traindf['Parch'].map(Parch_Cat_dict)\ntestdf['Parch_Cat']=testdf['Parch'].map(Parch_Cat_dict)\n","30ff69dd":"Cabin_Cat_dict={}\nfor key in ['C','E','D','B','F']:\n    Cabin_Cat_dict[key]=1\n\nfor key in ['G']:\n    Cabin_Cat_dict[key]=2    \n\n    \nfor key in ['A']:\n    Cabin_Cat_dict[key]=3\n    \n\nfor key in ['F G','T']:\n    Cabin_Cat_dict[key]=4\n\n\nfor key in ['F E']:\n    Cabin_Cat_dict[key]=5\n\ntraindf['Cabin_Ch_Cat']=traindf['Cabin_Ch'].map(Cabin_Cat_dict)\ntestdf['Cabin_Ch_Cat']=testdf['Cabin_Ch'].map(Cabin_Cat_dict)","3d69405e":"Title_Cat_dict={}\nfor key in ['Capt','Don','Jonkheer','Rev']:\n    Title_Cat_dict[key]=1\n\nfor key in ['Col','Major','Dr','Master']:\n    Title_Cat_dict[key]=2    \n\n    \nfor key in ['Miss','Mrs']:\n    Title_Cat_dict[key]=3\n    \n\nfor key in ['Lady','Mlle','Mme','Ms','the Countess','Sir']:\n    Title_Cat_dict[key]=4\n\n\n\n\ntraindf['Title_Cat']=traindf['Title'].map(Title_Cat_dict)\ntestdf['Title_Cat']=testdf['Title'].map(Title_Cat_dict)","3eca18ba":"continouos_cols=['Age','SibSp','Parch','Fare']\nf, axes = plt.subplots(3,2,figsize=(15,15))\nplt.figure()\nf.delaxes(axes[2, 1])\n\nsns.boxplot(x=traindf['Survived'],y=traindf['Age'],ax=axes[0,0],palette=palette)\nsns.boxplot(x=traindf['Survived'],y=traindf['SibSp'],ax=axes[0,1],palette=palette)\nsns.boxplot(x=traindf['Survived'],y=traindf['Parch'],ax=axes[1,0],palette=palette)\nsns.boxplot(x=traindf['Survived'],y=traindf['Fare'],ax=axes[1,1],palette=palette)\nsns.boxplot(x=traindf['Survived'],y=traindf['Cabin_N'],ax=axes[2,0],palette=palette)\nplt.show()\n","62a2733a":"sns.distplot(traindf.loc[traindf['Survived'] == 0]['Age'] ,color=\"r\")\nsns.distplot(traindf.loc[traindf['Survived'] == 1]['Age'],color=\"g\")","4bb7a921":"sns.distplot(traindf.loc[traindf['Survived'] == 0]['Cabin_N'] ,color=\"r\")\nsns.distplot(traindf.loc[traindf['Survived'] == 1]['Cabin_N'],color=\"g\")\n","986b301f":"traindf['Age_Quart']=pd.cut(traindf['Age'], bins=[0, 16, 30,60,100])\ntestdf['Age_Quart']=pd.cut(testdf['Age'], bins=[0, 16, 30,60,100])","6c48fb66":"traindf['Cabin_N_Quart']=pd.cut(traindf['Cabin_N'], bins=[0, 50, 100,150,1000])\ntestdf['Cabin_N_Quart']=pd.cut(testdf['Cabin_N'], bins=[0, 50, 100,150,1000])","f5c32efe":"traindf[\"Cabin_N\"] = traindf[\"Cabin_N\"].fillna(traindf.groupby(\"Pclass\")[\"Cabin_N\"].transform(\"mean\"))\ntraindf[\"Cabin_Ch\"] = traindf[\"Cabin_Ch\"].fillna(traindf.mode().iloc[0]['Cabin_Ch'])\ntraindf[\"Embarked\"] = traindf[\"Embarked\"].fillna(traindf.mode().iloc[0]['Embarked'])","c06442a7":"testdf[\"Cabin_N\"] = testdf[\"Cabin_N\"].fillna(testdf.groupby(\"Pclass\")[\"Cabin_N\"].transform(\"mean\"))\ntestdf[\"Cabin_Ch\"] = testdf[\"Cabin_Ch\"].fillna(testdf.mode().iloc[0]['Cabin_Ch'])\ntestdf[\"Embarked\"] = testdf[\"Embarked\"].fillna(testdf.mode().iloc[0]['Embarked'])\ntestdf[\"Fare\"]=testdf[\"Fare\"].fillna(np.mean(testdf['Fare']))","04d3cc25":"traindf.drop(columns=['Ticket','Name','Cabin','Age','Cabin_Ch','NoFamily','Parch','Cabin_N','Title'],inplace=True)\n\ntraindf=pd.get_dummies(data=traindf, columns=['Sex','Cabin_Ch_Cat','Alone','Age_Quart','Embarked','NoFamily_Cat','Parch_Cat',\n                                                'Cabin_N_Quart','Title_Cat'])\n","98302dd3":"testdf.drop(columns=['Ticket','Name','Cabin','Age','Cabin_Ch','NoFamily','Parch','Cabin_N','Title'],inplace=True)\n\ntestdf=pd.get_dummies(data=testdf, columns=['Sex','Cabin_Ch_Cat','Alone','Age_Quart','Embarked','NoFamily_Cat','Parch_Cat',\n                                                'Cabin_N_Quart','Title_Cat'])\n","2faab227":"print('Train DF')\nfor col in traindf:\n    \n    print(col,traindf[col].isna().sum())\nprint('-'*30)\nprint('Test DF')\nfor col in testdf:\n    \n    print(col,testdf[col].isna().sum())\n","7fd4a83a":"y=traindf['Survived'].copy()\nX=traindf.copy().drop('Survived',axis=1)\nX_test=testdf.copy()\n\nscaler=MinMaxScaler()\n\n","763b5245":"lc=LogisticRegression(penalty='l1', solver='liblinear')\npipe=Pipeline(steps=[('scaler',scaler),('lc',lc)])\ngrid_params={'lc__C':[0.01,0.1,1,10,100,1000]}\nsearchL=GridSearchCV(pipe,grid_params)\nsearchL.fit(X,y)\n\nprint(\"Best parameter (CV score=%0.3f):\" % searchL.best_score_)\nprint(searchL.best_params_)","b54b5515":"lc=LogisticRegression(penalty='l2',max_iter=5000)\npipe=Pipeline(steps=[('scaler',scaler),('lc',lc)])\ngrid_params={'lc__C':[0.01,0.1,1,10,100,1000]}\nsearchR=GridSearchCV(pipe,grid_params)\nsearchR.fit(X,y)\n\nprint(\"Best parameter (CV score=%0.3f):\" % searchR.best_score_)\nprint(searchR.best_params_)","452d51db":"lc=RandomForestClassifier(random_state=14)\npipe=Pipeline(steps=[('scaler',scaler),('lc',lc)])\ngrid_params={'lc__n_estimators':[220,250,270],'lc__max_depth':[6,7,8]}\nsearchRF=GridSearchCV(pipe,grid_params)\nsearchRF.fit(X,y)\n\nprint(\"Best parameter (CV score=%0.3f):\" % searchRF.best_score_)\nprint(searchRF.best_params_)","93d1f1e2":"missing_cols = set( X.columns ) - set( X_test.columns )\n\nfor c in missing_cols:\n    X_test[c] = 0\n\nX_test = X_test[X.columns]","c9fb203e":"model=RandomForestClassifier(random_state=21,n_estimators=220,max_depth=7)\n\nX=scaler.fit_transform(X)\nX_test=scaler.transform(X_test)\n\nmodel.fit(X,y)\npred_test=model.predict(X_test)\npassengerId_test=testdf.index\n\npd.DataFrame({'Survived':pred_test,'PassengerId':passengerId_test}).to_csv('Submission_Final.csv',index=False)","ca657d57":"* 0 to 16: Mostly survived\n* 16 to 22 : Mostly died\n","909495ec":"## Handling Nulls","30e0a9f9":"# Libraries","aa3734b8":"First we use correlation to see the relation between numerical features:","f2cfd4e3":"Based on correlation, Age has the most correlation with PClass so we fill the null values of Age based on the mean of Age of each PClass.","28a80a12":"Based on the plots, we group some labels of each feature together:","17c22a80":"* In PClass most of First classes have survived, the majority of Second classes have died and most of the Third classes have died.\n* Most of males haved died and most of females have survived.\n* For SibSp=0 most of them have died, the majority of SibSP=1 have survived but SibSP in (2,3,4) have survived mostly.Also all of SibSp>=5 have died.\n* For Parch=0 mostly have died, Parch=1 the majority have survived, Parch=2 is nearly equal, Parch=3 the majority have survived and all of Parch>5 have died.\n* In Embarked, most of 'S' have died, the majority of 'C' have survived and the majority of 'Q' have died.\n* The majority of people who are alone have survived (there isn't much of a difference) but most of people who are not alone have died.\n* Most of people with NoFamily=0 have died, but the majority of people whose NoFamily was between 1 & 3 have survived. Also most of people with majoirty between 4 & 6 have died. Also all of people with NoFamily>=7 have died.\n* Most of the people with Cabin_Ch in (C,E,D,B,F) have survived.","d2723938":"Perhaps Test DataFrame doesn't have some values of categorical features. So we add them to testdf with value=0","996fa9fd":"# Create Models","9d3da904":"## Lasso Logistic Regression","b9909adf":"# Data Cleansing","7347dfb1":"Null values in each feature:","472a62b8":"We can create some features, based on the existing features:\n1. When a passenger does not have Parch or SibSp, he\/she is alone.\n2. Sum of SibSp and Parch is the number of family members in Titanic.\n3. Cabin feature has a numerical part and an alphabetical part. We can seperate these two.\n4. All names have a title (Mr,Mrs,Sir,Doc,...) we can take these titles and put them in a seperate column.","64d5dc68":"* Lower ages have survived more than older ones.  \n* larger Parchs have survived more.  \n* Larger fares have survived more.  \n* Lower Cabin_N have a slightly better chance to survive.","5d8e8b6a":"## Plots (Numerical Features)","a983cdc9":"# Read Data","867c7b4f":"## Ridge Logistic Regression","1cfa1728":"## Encoding Categorical Features","f8f029b4":"## Plots (Categorical Features)","335fa88a":"We can clearly see some patterns based on Title feature.","8613cbad":"## Random Forest","dc575f97":"## Binning (Numerical Features)","1ae234b1":"## Binning (Categorical Features)","81f9a732":"## Correlation"}}