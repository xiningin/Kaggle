{"cell_type":{"96052227":"code","c9c7208b":"code","61e9b226":"code","93b5df43":"code","b8730535":"code","6227dbf2":"code","6d271e94":"code","9f43fadc":"code","93f857a2":"code","b0268fb5":"code","26018494":"code","257a30b0":"code","6753cd91":"code","cfc77dfd":"code","f7f0d58e":"code","38a3ca7f":"code","b5eb385b":"markdown","dc92b4b3":"markdown","dae59180":"markdown","0ef561d5":"markdown","3eed94ef":"markdown","602c5b52":"markdown","494057be":"markdown","9d580ec0":"markdown","76816b97":"markdown","21f13dfa":"markdown","45f55bf2":"markdown","ca43351c":"markdown","2fb28fd9":"markdown","98ca0494":"markdown","26b2415e":"markdown","004e573a":"markdown","b9c826b5":"markdown","4d47e616":"markdown","dfe9e86b":"markdown","98a3be0f":"markdown","5ff90224":"markdown","466247a7":"markdown","e93090cc":"markdown"},"source":{"96052227":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime","c9c7208b":"!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","61e9b226":"df = pd.read_csv(\"\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")\ndf.columns","93b5df43":"train_df, test_df = train_test_split(df,\n                                     train_size=0.6,\n                                     random_state=2018)\ntrain_df.sentiment.value_counts(normalize=True)","b8730535":"from fastai.text.all import *\n\ndls = TextDataLoaders.from_df(train_df, text_col='review', label_col='sentiment')\ndls.show_batch(max_n=3)","6227dbf2":"start = datetime.now()\n\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(epochs=4, base_lr=1e-2)\n\nend = datetime.now()\nfastai_time = (end - start).total_seconds()","6d271e94":"print(f\"fastai model training takes {fastai_time} seconds\")","9f43fadc":"tokenize_df(test_df, text_cols='review', tok_text_col='text')\ntest_dl = learn.dls.test_dl(test_df.review)  #initialize the test dataloader\n## Gives tuple of three elements - predict_proba and predictions\npreds_probs, dummy, preds = learn.get_preds(dl=test_dl, with_decoded=True)","93f857a2":"y_true = test_df.sentiment.replace(\"negative\", 0)\ny_true = y_true.replace(\"positive\", 1).to_numpy()","b0268fb5":"from sklearn.metrics import accuracy_score\nfastai_score = accuracy_score(y_true=y_true, y_pred=to_np(preds))\nfastai_score","26018494":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate","257a30b0":"X_train, y_train = train_df['review'], train_df['sentiment']\nX_test, y_test = test_df['review'], test_df['sentiment']","6753cd91":"start = datetime.now()\n\npipe = make_pipeline(TfidfVectorizer(stop_words='english'), LogisticRegression(max_iter=500))\npipe.fit(X_train, y_train)\n\nend = datetime.now()\nlr_time = (end - start).total_seconds()\n\nresults = pd.DataFrame(cross_validate(pipe, X_train, y_train, return_train_score=True))\npd.DataFrame(results.mean()).T","cfc77dfd":"print(f\"Logistic regression model training takes {lr_time} seconds\")","f7f0d58e":"pipe.named_steps['logisticregression'].coef_\ncoefficients = pipe.named_steps[\"logisticregression\"].coef_.flatten().tolist()\n\ntext_columns = pipe.named_steps[\"tfidfvectorizer\"].get_feature_names()\ncoefs = {\n    \"coefficient\": coefficients,\n    \"magnitude\": np.absolute(coefficients),\n }\ncoef_df = pd.DataFrame(coefs, index=text_columns).sort_values(\"magnitude\", ascending=False)\ncoef_df.head(n=10)","38a3ca7f":"lr_score = pipe.score(X_test, y_test)\nlr_score","b5eb385b":"## 2.3. Scoring on the test set.","dc92b4b3":"# 2. Using Logistic Regression","dae59180":"## 2.2. Training Logistic model","0ef561d5":"## 1.2. Converting df to data blocks","3eed94ef":"## 1.1. Importing packages, loading datasets","602c5b52":"# 0. Common packages for both models","494057be":"## 1.4. Scoring on the test set","9d580ec0":"|                  | fastai                                                                                    | Logistic Regression                                                                                |\n|------------------|-------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n| CSV usage        | Need to convert pandas df to data blocks                                                  | Uses pandas df                                                                                     |\n| Training time    | - Takes a lot more time. <br> - GPU required even for small datasets.                        | Trains fairly quickly.                                                                             |\n| Scores           | Gives amazing scores on validation and test sets.                                         | Comparably worse scores.                                                                |\n| Interpretability | Very hard to interpret the results.                                                       | Can easily visualize the coefficients and its impact on the predictions.                           |\n| Use case         | - Great for Kaggle competitions. <br> - Scores are more important than model interpretability. | - Good for making inferential statistics. <br> - Model interpretability are more important than scores. |","76816b97":"- stop_words=english eliminates the common English words like is, a, the, etc.\n- Sklearn calls the validation score outputs from its cross_validate as test score and not validation score.","21f13dfa":"- Here, we change the labels of test_df from [negative, positive] to [0, 1] since the preds are in the [0, 1] format.\n- Then, we convert the pandas series to numpy format.","45f55bf2":"- An `epoch` defines the number of times that a learning algorithm will go through the complete training dataset. It can be treated as an hyperparameter. Higher number of epochs means more time required for training.  \n- `AWD_LSTM` is a language training model. You can read about it [here](https:\/\/medium.com\/ai%C2%B3-theory-practice-business\/awd-lstm-6b2744e809c5).\n- We store the time required to train the model in `fastai_time`.","ca43351c":"## 2.1. Importing packages for LR, splitting target feature","2fb28fd9":"We will use the common split of data given below for both the models.","98ca0494":"# 3. Difference between the approaches","26b2415e":"Yay! We do not have class imbalance. So, we can safely use `accuracy` as a metric for scoring our models.","004e573a":"- We get a good look at how our regression model is making the predictions.\n- Negative coefficients means that the presence of these words pushes the predcitions to base class which is `negative` here.\n- On the other hand, words such as `great` and `excellent` pushes our predictions to a `positive` sentiment review.\n- The limitation of using `TfidfVectorizer` is that we are eliminating the context in which the word is used.","b9c826b5":"The output `preds` is in Tensor format. So, we use to_np() to convert it to a numpy array.","4d47e616":"- I'm grateful that you spent time reading\/skimming all the way through. \n- Comments\/suggestions\/criticisms on the notebook would be highly appreciated.\n- Check out my other work on [Kaggle](https:\/\/www.kaggle.com\/rrrohit).","dfe9e86b":"`Fastai` doesn't have any explicit method to score on test data with labels. So, we make predictions on the unlabelled test data and then combine the predictions with its labels, scoring using accuracy method from sklearn. There might be easier way to do it ","98a3be0f":"`Data Block` is a high level API used to quickly get your data(CSV, Image, Audio, etc.) in `DataLoaders`.","5ff90224":"In this notebook, the goal is to showcase the implementation of two powerful methods (fastai and Logisitic Regression) used in Data Science.  \nThe focus is not on EDA, but mainly on training, runtime, interpretability, and score on the common split of train and test datasets for both the models.\n\nNote: You can reduce the train_size to decrease the runtime of the notebook.","466247a7":"# 1. Using fastai","e93090cc":"## 1.3. Training model using AWD_LSTM"}}