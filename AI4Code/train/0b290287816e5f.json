{"cell_type":{"19393aef":"code","a9c6df5f":"code","074f11b4":"code","dc464206":"code","cff62d94":"code","e6e6be7e":"code","a3a6ac4b":"code","eeceff41":"code","199fffaf":"code","79af38f9":"code","d87fc45a":"code","4d5ebca4":"code","69bab5cd":"code","a9a6e771":"code","f7388155":"code","00cebe00":"code","69ea59dc":"code","95e9c841":"code","44f8fdcf":"code","45922e2f":"code","800cd17e":"code","1f028308":"code","fc5b7d0f":"code","57445e78":"code","5490a3c9":"code","9cddf492":"code","61bec75d":"code","8c52354f":"markdown","103bd1ee":"markdown","ce500a27":"markdown"},"source":{"19393aef":"!pip install Pillow==6.1 # Version7\u3067PILLOW_VERSION\u304c\u7121\u304f\u306a\u3063\u305f\u70ba","a9c6df5f":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport torch\nfrom torch import optim \nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np","074f11b4":"class Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"..\/input\/us-concrete-crack\"\n        positive=\"Positive\"\n        negative=\"Negative\"\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n        positive_files.sort()\n        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n        negative_files.sort()\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)    \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n        \n        \n        image=Image.open(self.all_files[idx])\n        y=self.Y[idx]\n          \n        \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y","dc464206":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n# transforms.ToTensor()\n#transforms.Normalize(mean, std)\n#transforms.Compose([])\n\ntransform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])\n","cff62d94":"dataset_train=Dataset(transform=transform,train=True)\ndataset_val=Dataset(transform=transform,train=False)","e6e6be7e":"def show_data(data_sample, shape = (227, 227, 3)):\n    # (3 x 227 x 227) => (227 x 227 x 3)\n    transposed_imarr = np.transpose(data_sample[0].numpy().reshape((3, 227, 227)), (1, 2, 0))\n    # BGR format => RGB format\n    assert transposed_imarr.shape == shape\n    B, G, R = transposed_imarr.T\n    rgb_imarr = np.array((R, G, B)).T\n    plt.imshow(rgb_imarr)\n    plt.title('y = {}'.format(data_sample[1]))\n    plt.show()\n\nprint(\"Shape of data element: \", dataset_train[0][0].shape)\nprint(\"Type of data element: \", dataset_train[0][1].type())\nfor i in range(4):\n    show_data(dataset_train[i])","a3a6ac4b":"# Create the data loader\ntrain_loader = DataLoader(dataset=dataset_train, batch_size=1000)\n\n# Create the data loader\nval_loader = DataLoader(dataset=dataset_val, batch_size=1000)","eeceff41":"# Define a function to plot accuracy and loss\ndef plot_accuracy_loss(training_results): \n    plt.subplot(2, 1, 1)\n    plt.plot(training_results['train_loss'], 'r', label='training loss')\n    plt.ylabel('loss')\n    plt.title('training loss iterations')\n    plt.legend(loc=\"best\")\n    plt.subplot(2, 1, 2)\n    plt.plot(training_results['validation_acc'], label='validation accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epochs')\n    plt.legend(loc=\"best\")\n    plt.show()","199fffaf":"# The class for plotting\n\nclass plot_diagram():\n    \n    # Constructor\n    def __init__(self):\n        self.error = []\n        self.parameter = []\n        \n    # Executor\n    def __call__(self, Yhat, w, error, n):\n        self.error.append(error)\n        self.parameter.append(w.data)\n        plt.subplot(212)\n        plt.plot(self.X, Yhat.detach().numpy())\n        plt.plot(self.X, self.Y,'ro')\n        plt.xlabel(\"A\")\n        plt.ylim(-20, 20)\n        plt.subplot(211)\n        plt.title(\"Data Space (top) Estimated Line (bottom) Iteration \" + str(n))\n        plt.plot(self.parameter_values.numpy(), self.Loss_function)   \n        plt.plot(self.parameter, self.error, 'ro')\n        plt.xlabel(\"B\")\n        plt.figure()\n    \n    # Destructor\n    def __del__(self):\n        plt.close('all')","79af38f9":"# Define the function for plotting the channels\n\ndef plot_channels(W):\n    n_out = W.shape[0]\n    n_in = W.shape[1]\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(n_out, n_in)\n    fig.subplots_adjust(hspace=0.1)\n    out_index = 0\n    in_index = 0\n    \n    #plot outputs as rows inputs as columns \n    for ax in axes.flat:\n        if in_index > n_in-1:\n            out_index = out_index + 1\n            in_index = 0\n        ax.imshow(W[out_index, in_index, :, :], vmin=w_min, vmax=w_max, cmap='seismic')\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        in_index = in_index + 1\n\n    plt.show()","d87fc45a":"# Define the function for plotting the parameters\n\ndef plot_parameters(W, number_rows=1, name=\"\", i=0):\n    W = W.data[:, i, :, :]\n    n_filters = W.shape[0]\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(number_rows, n_filters \/\/ number_rows)\n    fig.subplots_adjust(hspace=0.4)\n\n    for i, ax in enumerate(axes.flat):\n        if i < n_filters:\n            # Set the label for the sub-plot.\n            ax.set_xlabel(\"kernel:{0}\".format(i + 1))\n\n            # Plot the image.\n            ax.imshow(W[i, :], vmin=w_min, vmax=w_max, cmap='seismic')\n            ax.set_xticks([])\n            ax.set_yticks([])\n    plt.suptitle(name, fontsize=10)    \n    plt.show()","4d5ebca4":"# Define the function for plotting the activations\ndef plot_activations(A, number_rows=1, name=\"\", i=0):\n    A = A[0, :, :, :].detach().numpy()\n    n_activations = A.shape[0]\n    A_min = A.min().item()\n    A_max = A.max().item()\n    fig, axes = plt.subplots(number_rows, n_activations \/\/ number_rows)\n    fig.subplots_adjust(hspace = 0.4)\n\n    for i, ax in enumerate(axes.flat):\n        if i < n_activations:\n            # Set the label for the sub-plot.\n            ax.set_xlabel(\"activation:{0}\".format(i + 1))\n\n            # Plot the image.\n            ax.imshow(A[i, :], vmin=A_min, vmax=A_max, cmap='seismic')\n            ax.set_xticks([])\n            ax.set_yticks([])\n    plt.show()","69bab5cd":"torch.manual_seed(0)\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, input_channels=3, out_1=8, out_2=16, n_class=2):\n        super(Net, self).__init__()\n        # x = [N, 3, 227, 227]\n        self.conv1 = nn.Conv2d(\n            in_channels=input_channels,\n            out_channels=out_1,\n            kernel_size=3,\n            stride=2 # without padding\n        )\n        # x = [N, 8, 113, 113] \u203b dimension = ((n+2*padding-filter)\/stride)+1 (n=height or width)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        # x = [N, 8, 56, 56]\n        self.conv2 = nn.Conv2d(\n            in_channels=out_1,\n            out_channels=out_2,\n            kernel_size=3,\n            stride=2 # without padding\n        )\n        # x = [N, 16, 27, 27]\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        # x = [N, 16, 13, 13]\n        self.fc1 = nn.Linear(out_2*13*13, n_class) # => 2704\n        \n    # Prediction\n    def forward(self, x, i=None):\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = self.maxpool2(F.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        if i is not None and i < 1:\n            print(\"x.shape:\", x.shape)\n#             print(\"weight, bias:\",self.state_dict())\n#             print(\"weight:\",self.linear.weight)\n#             print(\"bias:\",self.linear.bias)\n        yhat = F.softmax(self.fc1(x), dim=1)\n#         yhat = F.softmax(self.fc1(x), dim=-1)\n        return yhat\n\n    # Outputs activation, this is not necessary\n    def activations(self, x):\n        z1 = self.conv1(x)\n        a1 = F.relu(z1)\n        out1 = self.maxpool1(a1)\n        z2 = self.conv2(out1)\n        a2 = F.relu(z2)\n        out2 = self.maxpool1(a2)\n        return z1,a1,z2,a2,out2,out1.view(out1.size(0),-1)\n","a9a6e771":"model = Net()\n#print(\"The parameters: \", list(model.parameters()))\nplot_parameters(model.state_dict()['conv1.weight'], number_rows=4, name=\"1st layer kernels before training \")\nplot_parameters(model.state_dict()['conv2.weight'], number_rows=4, name='2nd layer kernels before training' )","f7388155":"n_epochs = 5\nlearning_rate = 0.1\nmomentum = 0.1\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\ncriterion = nn.CrossEntropyLoss()\ngradient_plot = plot_diagram()\ninput_dim = 3*227*227\noutput_dim = 2 # Softmax\u3092\u4f7f\u3046\u305f\u3081\u3001\u30d0\u30a4\u30ca\u30ea\u3067\u306f\u306a\u304f\u30012\u30af\u30e9\u30b9\u3068\u3059\u308b\n\ndef train(model, train_loader, validate_loader, optimizer, criterion, dataset_val, epochs, print_flg=True):\n    results = {'train_loss': [], 'validation_acc': []}\n    for epoc in range(epochs):\n        print(epoc)\n        # train\n        COST = 0\n        for i, (x, y) in enumerate(train_loader):\n#             x_reshaped = x.view(-1, input_dim)\n            if print_flg is True:\n#                 print(x.size(0), x.size(1))\n                print(\"The shape of x: \", x.shape)\n                print_flg = False\n            optimizer.zero_grad()\n            outputs = model(x, i)\n            loss = criterion(outputs, y)\n            loss.backward()\n            optimizer.step()\n            # plot the diagram for us to have a better idea\n#             gradient_plot(loss.data.item(), epoc)\n            COST += loss.data\n        results['train_loss'].append(COST)\n        print('cost:', COST)\n\n        # evaluate\n        correct = 0\n        for x,y in validate_loader:\n#             x_reshaped = x.view(-1, input_dim)\n            outputs = model(x)\n            _, predicted = torch.max(outputs, 1) # choose 1 class from 2 classes\n            correct += (predicted == y).sum().item()\n        accuracy = 100 * (correct \/ len(dataset_val))\n        results['validation_acc'].append(accuracy)\n        print('accuracy:', accuracy)\n    return results\n# Train Model with 5 epochs\ntraining_results = train(model, train_loader, val_loader, optimizer, criterion, dataset_val, n_epochs)\n","00cebe00":"# Plot the loss and accuracy\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(training_results['train_loss'], color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Cost', color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot(training_results['validation_acc'], color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()\nprint(training_results['train_loss'])","69ea59dc":"show_data(dataset_train[0])","95e9c841":"# Determine the activations\nout = model.activations(dataset_train[0][0].view(1, 3, 227, 227))\n# \/ZFNet-MLP-Mix\/blob\/master\/samples\/michigan\/PyTorch\/9.5_CNN_How_To_Plot_Kernel_Parameters.ipynb\u53c2\u7167\n\n# Plot the outputs after the first CNN\nplot_activations(out[0], number_rows=4, name=\"Output after the 1st CNN\")","44f8fdcf":"# Plot the outputs after the first Relu\nplot_activations(out[1], number_rows=4, name=\"Output after the 1st Relu\")","45922e2f":"# Plot the outputs after the second CNN\nplot_activations(out[2], number_rows=4, name=\"Output after the 2nd CNN\")","800cd17e":"# Plot the outputs after the second Relu\nplot_activations(out[3], number_rows=4, name=\"Output after the 2nd Relu\")","1f028308":"# Plot the channels\n\nplot_channels(model.state_dict()['conv1.weight'])\nplot_channels(model.state_dict()['conv2.weight'])","fc5b7d0f":"import torchvision.models as models\nmodel = models.resnet18(pretrained=True)\n\n# Set no trainable to parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace the output layer with Liner layer(2 classes)\nmodel.fc = nn.Linear(512, 2)\n# print(model)\n# print(model.fc.weight.requires_grad)\nfor parameter in model.parameters():\n    print(parameter.requires_grad)","57445e78":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)","5490a3c9":"import time\nn_epochs = 1\nstart_time = time.time()\ndef train(model, train_loader, validate_loader, optimizer, criterion, dataset_val, epochs):\n    results = {'train_loss': [], 'validation_acc': []}\n    for epoc in range(epochs):\n        print(epoc)\n        # train\n        COST = 0\n        for x, y in train_loader:\n            model.train() # to do dropout\n            optimizer.zero_grad() # clear gradient \n            outputs = model(x) # make a prediction \n            loss = criterion(outputs, y) # calculate loss \n            loss.backward() # calculate gradients of parameters \n            optimizer.step() # update parameters \n            COST += loss.data\n            results['train_loss'].append(loss.data)\n        print('cost:', COST)\n\n        # evaluate\n        correct = 0\n        for x_test,y_test in validate_loader:\n            model.eval() # not to do dropout\n            outputs = model(x_test)\n            _, predicted = torch.max(outputs, 1) # find max\n            correct += (predicted == y_test).sum().item()\n        accuracy = correct \/ len(dataset_val)\n        results['validation_acc'].append(accuracy)\n        print('accuracy:', accuracy)\n    return results\n\ntraining_results = train(model, train_loader, val_loader, optimizer, criterion, dataset_val, n_epochs)","9cddf492":"plt.plot(training_results['train_loss'])\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()\n","61bec75d":"# Plot the misclassified samples\n\ncount = 0\ni = 0\nfor x_test, y_test in dataset_val:\n#     outputs = model(x_test)\n    outputs = model(x_test.view(-1, 3, 227, 227)) # batch\u5f62\u5f0f\u306b\u5909\u63db\n    _, yhat = torch.max(outputs, 1)\n    if yhat != y_test:\n        show_data((x_test, y_test))\n        plt.show()\n#         print(\"yhat:\", yhat)\n#         print(\"actual \", y_test)\n        print('sample {0} predicted value: {1} actual value:{2}'.format(i, yhat, y_test))\n        count += 1\n    i += 1\n    if count >= 4:\n        break","8c52354f":"Print out first four Dataset Images. (Positive(include crack) are in even rows and Negative are in odd rows)","103bd1ee":"# In the case of Resnet18","ce500a27":"### \u25c9research question\n**How to classify concrete crack using PyTorch and concrete crack images**\n* I have numerous images which are taken at lots of concrete structure sites.\n* Those images are devided into Positive(include crack) and Negative folders.\n* I must create a model to classify the picture is including crack or not.\n\n### \u25c9the region and the domain category that this data sets are about\n**USA, CONCRETE STRUCTURE IMAGES**"}}