{"cell_type":{"9dee0604":"code","06550d8b":"code","95dc67a8":"code","6db08953":"code","11b451a1":"code","d30f2747":"code","f3f89868":"code","4d17bae5":"code","a13570a0":"code","492f1e62":"code","23cbcba0":"code","eb24870f":"code","a3c7b034":"code","b9b3c333":"code","1c5b4034":"code","7c3182f3":"code","358c115e":"code","d2425614":"code","bc1927ff":"markdown","008d5002":"markdown","2a41e669":"markdown","00d75ec2":"markdown"},"source":{"9dee0604":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","06550d8b":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Train shape : \",train_df.shape)\nprint(\"Test shape : \",test_df.shape)","95dc67a8":"train_df.head()","6db08953":"train_df.target.value_counts()","11b451a1":"train_df.question_text.sample(10).values","d30f2747":"train_df['length']=train_df.question_text.apply(lambda x: len(x))\ntrain_df.head()","f3f89868":"test_df['length']=test_df.question_text.apply(lambda x: len(x))\ntest_df.head()","4d17bae5":"print('Average questions length in train is {0:.0f}.'.format(train_df.length.mean()))\nprint('Average questions length in test is {0:.0f}.'.format(test_df.length.mean()))\nprint()\nprint('Maximum questions length in train is {0:.0f}.'.format(train_df.length.max()))\nprint('Maximum questions length in test is {0:.0f}.'.format(test_df.length.max()))\nprint()\nprint('Minimum questions length in train is {0:.0f}.'.format(train_df.length.min()))\nprint('Minimum questions length in test is {0:.0f}.'.format(test_df.length.min()))\nprint()\nprint('Average word length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x.split())))))\nprint('Average word length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x.split())))))","a13570a0":"print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\nprint('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))","492f1e62":"print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\nprint('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))","23cbcba0":"import re\nimport nltk\nfrom nltk.corpus import stopwords\ndef clean_text(raw_text):\n    raw_text=raw_text.strip()\n    try:\n        no_encoding=raw_text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n    except:\n        no_encoding = raw_text\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",no_encoding) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) ","eb24870f":"train_df['clean_ques']=train_df.question_text.apply(clean_text)\ntrain_df.sample(10)","a3c7b034":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.pipeline import Pipeline,FeatureUnion\nfrom sklearn.metrics import confusion_matrix,classification_report,f1_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n# nb = MultinomialNB()\nft=FeatureUnion([('ct', CountVectorizer(analyzer='char',ngram_range=(1,5),max_df=0.9)),('ct2', CountVectorizer(analyzer='word',ngram_range=(1,4),max_df=0.9))])\npipeline = Pipeline([\n    ('bow',ft),  # strings to token integer counts\n    ('clf', LogisticRegression(solver='saga', class_weight='balanced', C=0.45,max_iter=250, verbose=1))\n])\npipeline.get_params().keys()","b9b3c333":"pipeline.fit(train_df['clean_ques'].values,train_df.target)\nimport gc\ngc.collect()","1c5b4034":"test_df['clean_ques']=test_df.question_text.apply(clean_text)","7c3182f3":"pr=pipeline.predict(test_df['clean_ques'].values)","358c115e":"sub=pd.DataFrame({'qid':test_df.qid,'prediction':pr})\nsub.prediction.value_counts()","d2425614":"sub.to_csv('submission.csv',index=False)","bc1927ff":"### Will try with Embeddings next!!! Stay Tuned","008d5002":"## Lets clean the text\n\nAlthough i find it pretty cleaned, but ofcourse the stopwords needs to be removed and sanitized.","2a41e669":"# Quora Insincere Questions\n\n## Detect toxic content to improve online conversations\n\nAn existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n\nQuora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n\n![quora](https:\/\/qph.fs.quoracdn.net\/main-qimg-6ba8f7e24e68df3e8d44ed9cf3263fd8)\n\n\n### Lets start having some imports","00d75ec2":"## Pipeline Model\n\n### Logistic Regression with CountVectorizer"}}