{"cell_type":{"9582bf29":"code","28316eea":"code","7d90ab34":"code","8c6e61c4":"code","3b50d5b3":"code","8660df8f":"code","8eb7e556":"code","2c613b78":"code","8ee9a1ef":"code","df86cc02":"code","0b7119d5":"code","eeb5e986":"code","7bf659d4":"code","0f58939e":"code","ac51b382":"code","88dc02be":"code","29e6528c":"code","b537da36":"code","b40742d0":"code","0943b9e7":"code","9c558533":"code","793c7f0a":"code","b7a48964":"code","759009ac":"code","c48807d5":"code","c1cf75f7":"code","35dd4d5f":"code","d0d9ca96":"markdown","24ac829a":"markdown"},"source":{"9582bf29":"#https:\/\/www.kaggle.com\/nikhilroxtomar\/u-net-dropout-augmentation-stratification\nimport numpy as np\nimport pandas as pd\nimport os\nfrom random import randint\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\nfrom tqdm import tqdm_notebook\nfrom keras import backend as K\nimport tensorflow as tf\nimport gc\n#pd.set_option('display.max_colwidth',50)","28316eea":"Train_Image_folder='..\/input\/train\/images\/'\nTrain_Mask_folder='..\/input\/train\/masks\/'\nTest_Image_folder='..\/input\/test\/images\/'\nTrain_Image_name=os.listdir(path=Train_Image_folder)\nTest_Image_name=os.listdir(path=Test_Image_folder)\nTrain_Image_path=[]\nTrain_Mask_path=[]\nTrain_id=[]\nfor i in Train_Image_name:\n    path1=Train_Image_folder+i\n    path2=Train_Mask_folder+i\n    id1=i.split(sep='.')[0]\n    Train_Image_path.append(path1)\n    Train_Mask_path.append(path2)\n    Train_id.append(id1)\n  \n\nTest_Image_path=[]\nTest_id=[]\nfor i in Test_Image_name:\n    path=Test_Image_folder+i\n    id2=i.split(sep='.')[0]\n    Test_Image_path.append(path)\n    Test_id.append(id2)\n    \ndf_Train_path=pd.DataFrame({'id':Train_id,'Train_Image_path':Train_Image_path,'Train_Mask_path':Train_Mask_path})\ndf_Test_path=pd.DataFrame({'id':Test_id,'Test_Image_path':Test_Image_path})\n\ndf_depths=pd.read_csv('..\/input\/depths.csv')\ndf_sub=pd.read_csv('..\/input\/sample_submission.csv')\ndf_Train_path=df_Train_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_Test_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_sub.merge(df_Test_path,on='id',how='left')\nprint(df_Train_path.shape,df_Test_path.shape)\ndf_Train_path.head()","7d90ab34":"df_Test_path.drop('rle_mask',axis=1,inplace=True)\ndf_Test_path.head()","8c6e61c4":"df_Train_path[\"images\"] = [np.array(load_img(path=idx, grayscale=True)) \/ 255 for idx in tqdm_notebook(df_Train_path.Train_Image_path)]\ndf_Train_path[\"masks\"]=[np.array(load_img(path=idx, grayscale=True)) \/ 255 for idx in tqdm_notebook(df_Train_path.Train_Mask_path)]\ndf_Train_path[\"coverage\"] = df_Train_path.masks.map(np.sum) \/ pow(101, 2)\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ndf_Train_path[\"coverage_class\"] = df_Train_path.coverage.map(cov_to_class)\n#df_Train_path.head(2)","3b50d5b3":"img_size_ori = 101\nimg_size_target = 128\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n\ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n","8660df8f":"ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    df_Train_path.id.values,\n    np.array(df_Train_path.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(df_Train_path.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    df_Train_path.coverage.values,\n    df_Train_path.z.values,\n    test_size=0.2, stratify=df_Train_path.coverage_class, random_state=123)","8eb7e556":"gc.collect()","2c613b78":"print(ids_train.shape,ids_valid.shape)\nprint(x_train.shape,y_train.shape)\nprint(x_valid.shape,y_valid.shape)\nprint(cov_train.shape,cov_test.shape)\nprint(depth_train.shape,depth_test.shape)","8ee9a1ef":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","df86cc02":"# Another method\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","0b7119d5":"def build_model(input_layer, start_neurons):\n    # 128 -> 64\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    # 64 -> 32\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    # 32 -> 16\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    # 16 -> 8\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    # 8 -> 16\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n    # 16 -> 32\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n    # 32 -> 64\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n    # 64 -> 128\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3,3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3,3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3,3), activation=\"relu\", padding=\"same\")(uconv1)\n\n    uncov1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer\n\ninput_layer = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 16)","eeb5e986":"model = Model(input_layer, output_layer)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.001), metrics=[mean_iou])\n#model.summary()","7bf659d4":"# Data augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)","0f58939e":"gc.collect()","ac51b382":"early_stopping = EarlyStopping(patience=10, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\".\/keras.model\", save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n\nepochs = 200\nbatch_size = 32\n\nhistory = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr])","88dc02be":"model = load_model(\".\/keras.model\",custom_objects={'mean_iou': mean_iou})","29e6528c":"preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\npreds_valid = np.array([downsample(x) for x in preds_valid])\ny_valid = np.array([downsample(x) for x in y_valid])","b537da36":"# src: https:\/\/www.kaggle.com\/aglotero\/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","b40742d0":"thresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(y_valid, np.int32(preds_valid > threshold)) for threshold in tqdm_notebook(thresholds)])","0943b9e7":"threshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\nprint('Best Threshold: ',threshold_best)","9c558533":"#threshold_best=6.5","793c7f0a":"# Source https:\/\/www.kaggle.com\/bguberfain\/unet-with-depth\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs","b7a48964":"x_test = np.array([upsample(np.array(load_img(path=idx, grayscale=True))) \/ 255 for idx in tqdm_notebook(df_Test_path.Test_Image_path)]).reshape(-1, img_size_target, img_size_target, 1)","759009ac":"preds_test = model.predict(x_test)","c48807d5":"pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(df_Test_path.id.values))}","c1cf75f7":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","35dd4d5f":"sub.head()","d0d9ca96":"### Spliting","24ac829a":"###  Model"}}