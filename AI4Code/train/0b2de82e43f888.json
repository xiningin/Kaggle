{"cell_type":{"252ca321":"code","6160a4d5":"code","7d984631":"code","a729667a":"code","b18fecbf":"code","6c6d646f":"code","c8160d9f":"code","47626778":"code","a423beba":"code","7a9a288a":"code","28845fa2":"code","a0e60bd4":"code","acb60737":"code","1e225cc1":"code","cbdb6f8d":"code","0f6e6124":"code","feb79938":"code","22ea0214":"code","86749f17":"code","c532e5b1":"code","4cf50dba":"code","cdf8cc3b":"code","d3c8a8dd":"code","08056e92":"markdown","8039c6da":"markdown","cd234217":"markdown","e3c5add2":"markdown","561b3ace":"markdown","4dd652c6":"markdown","9613b205":"markdown","c0da1cf6":"markdown","f79ce5c0":"markdown","15759294":"markdown","8134fe46":"markdown","20290232":"markdown","a0ef45f1":"markdown","eee2b0c5":"markdown","edbffaaf":"markdown","f7ec0382":"markdown","f3b9783d":"markdown","13ca618c":"markdown","2c13b437":"markdown","528b6dbf":"markdown","4b4dc995":"markdown","9c0fa2ed":"markdown"},"source":{"252ca321":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input d from sklearn.cross_validation import train_test_split\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","6160a4d5":"df_user = pd.read_csv('\/kaggle\/input\/user-ids\/BX-Users.csv',encoding='latin-1')","7d984631":"df_user.head()","a729667a":"#column_names = ['isbn', 'book_title']\ndf_books = pd.read_csv('\/kaggle\/input\/bookratings\/BX-Book-Ratings.csv', encoding='latin-1')","b18fecbf":"df_books.head()","6c6d646f":"df = pd.read_csv('\/kaggle\/input\/books-dataset\/BX-Books.csv',encoding='latin-1',nrows=10000)","c8160d9f":"df.head()","47626778":"df.describe()","a423beba":"df = pd.merge(df,df_books,on='isbn')\ndf.head()","7a9a288a":"n_users = df.user_id.nunique()\nn_books = df.isbn.nunique()\n\nprint('Num. of Users: '+ str(n_users))\nprint('Num of Books: '+str(n_books))","28845fa2":"isbn_list = df.isbn.unique()\nprint(\" Length of isbn List:\", len(isbn_list))\ndef get_isbn_numeric_id(isbn):\n    #print (\"  isbn is:\" , isbn)\n    itemindex = np.where(isbn_list==isbn)\n    return itemindex[0][0]","a0e60bd4":"userid_list = df.user_id.unique()\nprint(\" Length of user_id List:\", len(userid_list))\ndef get_user_id_numeric_id(user_id):\n    #print (\"  isbn is:\" , isbn)\n    itemindex = np.where(userid_list==user_id)\n    return itemindex[0][0]","acb60737":"df['user_id_order'] = df['user_id'].apply(get_user_id_numeric_id)","1e225cc1":"df['isbn_id'] = df['isbn'].apply(get_isbn_numeric_id)\ndf.head()","cbdb6f8d":"new_col_order = ['user_id_order', 'isbn_id', 'rating', 'book_title', 'book_author','year_of_publication','publisher','isbn','user_id']\ndf = df.reindex(columns= new_col_order)\ndf.head()","0f6e6124":"from sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(df, test_size=0.30)","feb79938":"#Create two user-book matrices, one for training and another for testing\ntrain_data_matrix = np.zeros((n_users, n_books))\nfor line in train_data.itertuples():\n    train_data_matrix[line[1]-1, line[2]-1] = line[3]  \n\ntest_data_matrix = np.zeros((n_users, n_books))\nfor line in test_data.itertuples():\n    test_data_matrix[line[1]-1, line[2]-1] = line[3]","22ea0214":"from sklearn.metrics.pairwise import pairwise_distances\nuser_similarity = pairwise_distances(train_data_matrix, metric='cosine')\nitem_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')","86749f17":"user_similarity","c532e5b1":"def predict(ratings, similarity, type='user'):\n    if type == 'user':\n        mean_user_rating = ratings.mean(axis=1)\n        #You use np.newaxis so that mean_user_rating has same format as ratings\n        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) \/ np.array([np.abs(similarity).sum(axis=1)]).T\n    elif type == 'item':\n        pred = ratings.dot(similarity) \/ np.array([np.abs(similarity).sum(axis=1)])     \n    return pred","4cf50dba":"item_prediction = predict(train_data_matrix, item_similarity, type='item')\nuser_prediction = predict(train_data_matrix, user_similarity, type='user')","cdf8cc3b":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\ndef rmse(prediction, ground_truth):\n    prediction = prediction[ground_truth.nonzero()].flatten() \n    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n    return sqrt(mean_squared_error(prediction, ground_truth))","d3c8a8dd":"print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\nprint('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))","08056e92":"Read the books Data and explore","8039c6da":"Converting both user_id and isbn to ordered list i.e. from 0...n-1","cd234217":"Merge the dataframes. For all practical purposes, User Master Data is not required. So, ignore dataframe df_user","e3c5add2":"Convert ISBN to numeric numbers in order ","561b3ace":"## Approach: You Will Use Memory-Based Collaborative Filtering\n\nMemory-Based Collaborative Filtering approaches can be divided into two main sections: **user-item filtering** and **item-item filtering**. \n\nA *user-item filtering* will take a particular user, find users that are similar to that user based on similarity of ratings, and recommend items that those similar users liked. \n\nIn contrast, *item-item filtering* will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items as input and outputs other items as recommendations. \n\n* *Item-Item Collaborative Filtering*: \u201cUsers who liked this item also liked \u2026\u201d\n* *User-Item Collaborative Filtering*: \u201cUsers who are similar to you also liked \u2026\u201d","4dd652c6":"## Train Test Split\n\nRecommendation Systems  are difficult to evaluate, but you will still learn how to evaluate them. In order to do this, you'll split your data into two sets. However, you won't do your classic X_train,X_test,y_train,y_test split. Instead, you can actually just segement the data into two sets of data:","9613b205":"Re-index columns to build matrix later on","c0da1cf6":"Read the data using pandas in DataFrame df","f79ce5c0":"Take a quick look at the user data.","15759294":"# End","8134fe46":"### Evaluation\nThere are many evaluation metrics, but one of the most popular metric used to evaluate accuracy of predicted ratings is *Root Mean Squared Error (RMSE)*.","20290232":"Do the same for user_id , convert it into numeric and in order","a0ef45f1":"Next step is to make predictions","eee2b0c5":"In both cases, you create a user-book matrix which is built from the entire dataset.\n\nSince you have split the data into testing and training, you will need to create two ``[828 x 8051]`` matrices (all users by all books). This is going to be  a very large matrix\n\nThe training matrix contains 70% of the ratings and the testing matrix contains 30% of the ratings.  ","edbffaaf":"Clean up NaN values","f7ec0382":"You can use the [pairwise_distances](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.pairwise.pairwise_distances.html) function from sklearn to calculate the cosine similarity. Note, the output will range from 0 to 1 since the ratings are all positive.","f3b9783d":"Now, let's take a quick look at the number of unique users and books.","13ca618c":"## The Data\n\nYou will use data from http:\/\/www2.informatik.uni-freiburg.de\/~cziegler\/BX\/ \n____\n\nObjective is to recommend books to a user based on purchase history and behavior of other users\n\n## Getting Started\n\nImport some libraries you will need:","2c13b437":"\nBooks Recommender System\n\nRecommendation Systems usually rely on larger datasets and specifically need to be organized in a particular fashion. ","528b6dbf":"Now, read the data where ratings are given by users. You will read only first 10K rows otherwise, Out Of Memory  error can occur.","4b4dc995":"Since, you only want to consider predicted ratings that are in the test dataset, you filter out all other elements in the prediction matrix with: `prediction[ground_truth.nonzero()]`. ","9c0fa2ed":"### Both the approach yield almost same result"}}