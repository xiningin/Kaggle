{"cell_type":{"ec01b06f":"code","b28b0073":"code","b0c847fc":"code","c0a7c9b7":"code","4f8920ab":"code","8cf2f5cf":"code","6fefe2e4":"code","dab7aa79":"code","4e244926":"code","d47fadec":"code","2cdfa7f9":"code","c019150e":"code","138f2c72":"markdown","cda7c54b":"markdown","3ba182ec":"markdown","b3d271ad":"markdown"},"source":{"ec01b06f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk\nimport collections\nfrom wordcloud import WordCloud\nfrom gensim.models import Word2Vec\nimport os\n\nprint(os.listdir(\"..\/input\"))","b28b0073":"# input dataframe\ndf = pd.read_csv('..\/input\/bhagavad-gita.csv')\ndf.head(5)","b0c847fc":"df.drop(df.columns[[0, 1, 3, 4]], axis=1, inplace=True)","c0a7c9b7":"df.head(10)","4f8920ab":"df = df.apply(lambda row: row['devanagari'].replace('\u0964',' ').strip().split(), axis=1)","8cf2f5cf":"df.head(10)","6fefe2e4":"data = []\nfor row in df:\n    temp = []\n    for words in row:\n        if len(words)>3:\n            temp.append(words)\n    data.append(temp)\ndata_flat = [item for sublist in data for item in sublist]","dab7aa79":"# as per my knowledge of this holy document it makes sense to see these results because of the words used such as \u092d\u093e\u0930\u0924, \u0905\u0930\u094d\u091c\u0941\u0928, \u0915\u0930\u094d\u092e, \u091c\u094d\u091e\u093e\u0928\u0902.\ntop_10 = [i[0] for i in sorted(dict(collections.Counter(data_flat)).items(), key=lambda k: k[1], reverse=True)[:10]]\ntop_10","4e244926":"from nltk.text import Text  \nbgita = Text(data_flat)\nbgita.concordance('\u092d\u093e\u0930\u0924')","d47fadec":"def jaccard(a, b):\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\nsim = 0.0\nfor i in data:\n    for j in data:\n        score = jaccard(set(i), set(j))\n        if score > sim and i!=j:\n            sim = score\n            doc1 = i\n            doc2 = j\n\nprint (round(sim*100, 2),'%', doc1, doc2)","2cdfa7f9":"model = Word2Vec(data, size=100, window=10, min_count=2, workers=4)","c019150e":"model.most_similar('\u0905\u0930\u094d\u091c\u0941\u0928')","138f2c72":"## Getting to know the most prominent 10 words used across the document","cda7c54b":"## Getting to know the context of any word","3ba182ec":"## Sentences with top syntactic similarity","b3d271ad":"## Training a word2vec model for capturing semantic similarity"}}