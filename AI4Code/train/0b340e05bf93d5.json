{"cell_type":{"ea805c28":"code","8cfade1f":"code","608f3e3f":"code","62ce7e8a":"code","fa3e509c":"code","85aaa63d":"code","b4077749":"code","7e9eb837":"code","4e28680f":"code","9ea03523":"code","39473484":"code","775ae58e":"code","59e3630f":"code","3a29933c":"code","6e93f079":"code","2594e315":"code","9ff1b71e":"code","e1f04f71":"code","910e9233":"code","c205c768":"code","c0803ac1":"code","27c1f3fd":"code","d97386c7":"code","4914b21a":"code","2138d840":"code","4528facc":"code","313f5f6d":"code","8ea3266b":"code","68dd1c0d":"code","2d22eb69":"markdown"},"source":{"ea805c28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cfade1f":"    import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    import pandas as pd\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.ensemble import GradientBoostingRegressor\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n    from sklearn import preprocessing, feature_selection\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.linear_model import LinearRegression,LassoCV\n    from sklearn.model_selection import train_test_split,GridSearchCV\n    import math\n    from scipy import stats\n    sns.set()\n    UCI_data=pd.read_csv(\"\/kaggle\/input\/UCI_data.csv\",index_col=0,parse_dates=True)\n    UCI_data.head()\n    ","608f3e3f":"UCI_data.info()","62ce7e8a":"UCI_data.describe()","fa3e509c":"plt.figure()\nUCI_data.hist(figsize=(20,20))\nplt.show()","85aaa63d":"UCI_data.plot(kind='box',subplots=True,figsize=(20,30))\nplt.show()","b4077749":"UCI_data['Hours']=UCI_data.index.hour\nUCI_data['Weekday']=UCI_data.index.weekday\nUCI_data['Month']=UCI_data.index.month\nUCI_data['Day']=UCI_data.index.day\nUCI_data['Minutes']=UCI_data.index.minute\nUCI_data['Years']=UCI_data.index.year","7e9eb837":"\nsns.boxplot(x=UCI_data['Weekday'], y=UCI_data['TARGET_energy'],data=UCI_data)\nplt.title(\"Plot of energy fluctuation  with Weekdays\")\nplt.ylabel(\"TARGET_energy\")\nplt.xlabel(\"Weekdays\")\nplt.xticks(np.arange(7))\nplt.show()","4e28680f":"\"Hourly distribution of energy use\",\nsns.boxplot(x=UCI_data['Hours'], y=UCI_data['TARGET_energy'],data=UCI_data)\nplt.title(\"Plot of energy fluctuation  with Hours\")\nplt.ylabel(\"TARGET_energy\")\nplt.xlabel(\"Hours\")\nplt.show()","9ea03523":"\"Correlation matrix to study the nature of the relationship \\n\",\nfig,ax=plt.subplots(figsize=(20,20))\nsns.heatmap(UCI_data.corr(),vmin=-1, vmax=1, center=0,cmap=\"YlOrRd\",annot=True, fmt='.2f')\nplt.show()","39473484":" \"Monthy peak of energy usage\",\nfigure,ax=plt.subplots(figsize=(5,5))\nUCI_data['TARGET_energy'].resample('M').sum().plot(kind='bar',color='orange')\nx=np.arange(5)\nplt.title(\"Plot of energy use through out the time periods on monthly basis\")\nplt.ylabel(\"Energy Consumption in Wh\")\nplt.xlabel(\"Months\")\nax.set_xticks(x)\nax.set_xticklabels(['Jan','Feb','Mar','Apr','May'])\nplt.show()","775ae58e":"#\"Separation of target and predictors\\n\",\ntarget=UCI_data['TARGET_energy']\npredictors=UCI_data.drop('TARGET_energy',axis=1)","59e3630f":"#\"Study of peak hours of usage of energy\"\nplt.bar(predictors['Hours'],target,color=\"red\")\nplt.title(\"Plot of energy fluctuation  with Hours of Day\")\nplt.ylabel(\"TARGET_energy\")\nplt.xlabel(\"Hours\")\nplt.show()","3a29933c":"#Relationship study between target variable and predictors\\n\",\nfor i in predictors.columns:\n plt.scatter(predictors[i],target,color=\"red\")\n plt.title(\"Plot for\"+i+\"with Target Energy\")\n plt.ylabel(\"TARGET_energy\")\n plt.xlabel(i)\n plt.show()","6e93f079":"UCI_data.reset_index(inplace=True)# Dropping the date feature\\n\",\nUCI_data.drop('date',axis=1,inplace=True)","2594e315":"UCI_predictors_train_valid,UCI_predictors_test,UCI_target_energy_train_valid,UCI_target_energy_test=train_test_split(predictors,target,test_size=0.1,random_state=42)","9ff1b71e":"#Separation of training and Validation sets.\\n\",\nUCI_predictors_train,UCI_predictors_valid,UCI_target_energy_train,UCI_target_energy_valid=train_test_split(UCI_predictors_train_valid,UCI_target_energy_train_valid,test_size=0.2,random_state=42)","e1f04f71":"#Normalization process done for feature normalization\",\nmx=MinMaxScaler()\nX_train_transformed=mx.fit_transform(UCI_predictors_train)\nX_valid_transformed=mx.transform(UCI_predictors_valid)\nX_test_transformed=mx.transform(UCI_predictors_test)","910e9233":"#Feature selection\",\nselector=feature_selection.SelectKBest(feature_selection.f_regression,k=20)\nX_train_new=selector.fit_transform(X_train_transformed,UCI_target_energy_train)\nX_valid_new=selector.transform(X_valid_transformed)\nX_test_new=selector.transform(X_test_transformed)\nprint(\"Shape of training features: \",X_train_new.shape)\nprint(\"Shape of validation features: \",X_valid_new.shape)\nskb_mask=selector.get_support()\nprint(skb_mask)\nout_list=[]\nskb_features = []\nfor bool,feature in zip(skb_mask, UCI_predictors_train.columns):\n if bool:\n  skb_features.append(feature)\nprint('Optimal number of features :',len(skb_features))\nprint('Best features :',skb_features)\nfor col in UCI_predictors_train.columns:\n skb_pvalues=stats.pearsonr(UCI_predictors_train[col],UCI_target_energy_train)\n out_list.append([col,skb_pvalues[0],skb_pvalues[1]])\n p_value_df=pd.DataFrame(out_list,columns=[\"Features\",\"Correlation\",\"P-values\"])\n print(\"Dataframe for p-values of features:\",\"\\n\",p_value_df.head())\nfig, ax = plt.subplots(figsize=(15,8))\nplt.bar(p_value_df[\"Features\"],p_value_df[\"P-values\"],color=\"green\")\nplt.xticks(range(len( UCI_predictors_train.columns)))\nplt.xticks(rotation=45, ha='right')\nplt.title(\"Plot of Features against their p-values from Select K Best Method\")\nplt.ylabel(\"p-values\")\nplt.xlabel(\"Features\")\nplt.show()","c205c768":" #Performance of Linear Regression with all features\n    \nlasso = LassoCV(alphas=[0.006, 0.01, 0.03, 0.06,0.25,0.5, 0.1,0.3, 0.6, 1],max_iter=100000, cv=5)\nlasso.fit(X_train_transformed,UCI_target_energy_train)\ny_predicted = lasso.predict(X_valid_transformed)\nplt.figure(figsize=(10, 5))\nplt.scatter(UCI_target_energy_valid, y_predicted, s=20)\nplt.title(\"Actual Vs Predicted value without feature selection\")\nplt.xlabel('Actual Value')\nplt.ylabel('Predicted Value')","c0803ac1":"#Performance of Linear Regression with selected features\nlasso = LassoCV(alphas=[0.006, 0.01, 0.03, 0.06,0.25,0.5, 0.1,0.3, 0.6, 1],max_iter=100000, cv=5)\nlasso.fit(X_train_new,UCI_target_energy_train)\ny_predicted = lasso.predict(X_valid_new)\nplt.figure(figsize=(10, 5))\nplt.scatter(UCI_target_energy_valid, y_predicted, s=20)\nplt.title(\"Actual Vs Predicted value with feature selection\")\nplt.xlabel('Actual Value')\nplt.ylabel('Predicted Value')","27c1f3fd":"#Function for Random Forest with Grid Search cross-validation\\n\",\ndef modelselection_forest(model,model_param):\n model_design=GridSearchCV(model,model_param,cv=5,n_jobs=-1)\n model_design.fit(X_train_new,UCI_target_energy_train)\n result_predict=model_design.predict(X_valid_new)\n print(\"RMSE score for RF\",math.sqrt(mean_squared_error(UCI_target_energy_valid,result_predict)))\n print(\"Train data score is \",model_design.score(X_train_new,UCI_target_energy_train))\n print(\"Validation data score is \",model_design.score(X_valid_new,UCI_target_energy_valid))\n print(\"The best parameter for the model is\")\n print(model_design.best_params_)","d97386c7":"\"#Function for Gradient Boosting Model with Grid Search cross-validation\\n\",\ndef modelselection_gbm(model,model_param):\n model_design=GridSearchCV(model,model_param,cv=5,n_jobs=-1)\n model_design.fit(X_train_new,UCI_target_energy_train)\n result_predict=model_design.predict(X_valid_new)\n print(\"RMSE score for GBM\",math.sqrt(mean_squared_error(UCI_target_energy_valid,result_predict)))\n print(\"Train data score is \",model_design.score(X_train_new,UCI_target_energy_train))\n print(\"Validation data score is \",model_design.score(X_valid_new,UCI_target_energy_valid))\n print(\"The best parameter for the model is\")\n print(model_design.best_params_)","4914b21a":"\"#Function for KNN model with Grid Search cross-validation\\n\",\ndef modelselection_knn(model,model_param):\n model_design=GridSearchCV(model,model_param,cv=5,n_jobs=-1)\n model_design.fit(X_train_new,UCI_target_energy_train)\n result_predict=model_design.predict(X_valid_new)\n print(\"RMSE score for KNN\",math.sqrt(mean_squared_error(UCI_target_energy_valid,result_predict)))\n print(\"Train data score is \",model_design.score(X_train_new,UCI_target_energy_train))\n print(\"Validation data score is \",model_design.score(X_valid_new,UCI_target_energy_valid))\n print(\"The best parameter for the model is\")\n print(model_design.best_params_)","2138d840":"#Parameter defining for models and calling for cross validations\\n\",\nparameter_for_gradient_boost={'n_estimators':[80,100,200],'loss':['ls','lad','huber','quantile'],'learning_rate':[0.1,0.5],'max_features':['auto','sqrt'],'criterion':['friedman_mse','mse']}\nparameter_for_knn={'n_neighbors':[2,3,4,5,6,7],'weights':['uniform','distance'],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],'p':[1,2]}\nparameter_for_forest={'max_features':['auto','sqrt'],'criterion':['mse']}\nneigbour_regressor=KNeighborsRegressor()\nforest_regressor=RandomForestRegressor()\ngradient_regressor=GradientBoostingRegressor()\nprint(\"Result for Random Forest Regressor\")\nmodelselection_forest(forest_regressor,parameter_for_forest)\nprint(\"Result for GradientBoost Regressor\")\nmodelselection_gbm(gradient_regressor,parameter_for_gradient_boost)\nprint(\"Result for KNN Regressor\"),\nmodelselection_knn(neigbour_regressor,parameter_for_knn)","4528facc":"print(\"Prediction for the rest unseen data\")\nprint(\"******** For GBM Model*********\")\nmodel=GradientBoostingRegressor(n_estimators=200,criterion='friedman_mse',learning_rate=0.5,loss='ls',max_features='sqrt')\nmodel.fit(X_train_new,UCI_target_energy_train)\ny_pred_new=model.predict(X_test_new)\nprint(\"RMSE score for the unseen test dataset\",math.sqrt(mean_squared_error(UCI_target_energy_test,y_pred_new)))\nprint(\"R2 score the unseen test dataset :\",r2_score(UCI_target_energy_test,y_pred_new))\n","313f5f6d":"#Prediction study over unseen data\\n\",\nplt.scatter(UCI_target_energy_test, y_pred_new, s=20)\nplt.title(\"Actual Vs Predicted value for GBM\")\nplt.xlabel('Actual Value')\nplt.ylabel('Predicted Value')","8ea3266b":"print(\"Prediction for the rest unseen data\")\nprint(\"******** For Random Forest Model*********\")\nmodel=RandomForestRegressor(criterion='mse',max_features='sqrt')\nmodel.fit(X_train_new,UCI_target_energy_train)\ny_pred_new_rf=model.predict(X_test_new)\nprint(\"RMSE score for the unseen test dataset\",math.sqrt(mean_squared_error(UCI_target_energy_test,y_pred_new_rf)))\nprint(\"R2 score the unseen test dataset :\",r2_score(UCI_target_energy_test,y_pred_new_rf))\n","68dd1c0d":"#Prediction over unseen data\\n\",\nplt.scatter(UCI_target_energy_test, y_pred_new_rf, s=20)\nplt.title(\"Actual Vs Predicted value for Random Forest\")\nplt.xlabel('Actual Value')\nplt.ylabel('Predicted Value')","2d22eb69":"In the above result it can be seen that Random Forest and KNN does reflect much of overfitting."}}