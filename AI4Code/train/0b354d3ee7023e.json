{"cell_type":{"6d7f74cf":"code","e9f5e16f":"code","f39a3203":"code","2805da0c":"code","d078ff80":"code","7ed4aebd":"code","38c6229f":"code","3e61deb0":"code","da7f08c1":"code","953d1d00":"code","5ab30a11":"code","77b0a1ee":"code","f3d6f2b4":"code","83b3606a":"code","d916a7d7":"code","063e4813":"code","cbb64e66":"code","68746020":"code","eeb3e655":"code","15d94cca":"code","624bff74":"code","c7bdd61c":"code","96e3f699":"code","08e449b5":"code","9e2e3b82":"code","8dc70605":"code","cfe967fd":"code","788628d7":"code","b4c8fcfa":"code","5151f65c":"code","7a987c91":"code","2c961a15":"code","92297fea":"code","0702dc69":"code","f8495f61":"code","1e99b602":"code","8a405ef9":"code","59084b1b":"code","7f1e8a2e":"code","82b2cd1b":"code","e43d0220":"code","3d2d949b":"code","e92b899e":"code","4adb0ec3":"code","3942ee24":"code","cf47154b":"code","089e856e":"code","e2fcf091":"code","e18dd7c0":"code","109927b5":"code","275f56b0":"code","87719dbf":"code","f830f6dc":"code","35b7a252":"code","508500c0":"code","57806f7d":"code","78bb9f6a":"markdown","47417937":"markdown","14599584":"markdown","2b45e07c":"markdown","25f88a23":"markdown","fb89de81":"markdown","5f33c5f8":"markdown","20ddc835":"markdown","1bd702e5":"markdown","f5019cfc":"markdown","605bffcd":"markdown","3abbb301":"markdown","6ba45ae0":"markdown","095d2ffe":"markdown","ac1956a0":"markdown","4260eda1":"markdown","133b66fe":"markdown","cf2c3ec0":"markdown","1a185189":"markdown","22228b4d":"markdown"},"source":{"6d7f74cf":"import os\nimport shutil\nfrom tqdm import tqdm\nimport random\nimport numpy as np\nfrom tensorflow import keras\nimport tensorflow as tf\nimport pathlib\nimport matplotlib.pyplot as plt\nimport pandas as pd","e9f5e16f":"# Uncomment this if you are executing this code on colab\n\n# os.environ['KAGGLE_USERNAME'] = \"username\" # username from the json file\n# os.environ['KAGGLE_KEY'] = \"key\" # key from the json file\n\n# !kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p \/content\/drive\/MyDrive\/Projects\/Image_search_engine\/train_zip\/","f39a3203":"train_zip_path = r'\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip'\ntest_zip_path = r'\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip'\nbase_dir = '\/kaggle\/working\/Data\/'\nunzip_dir = '\/kaggle\/working\/data\/'\nno_of_images = 6000 #No of images we want to take for training and validation, for validation set we will take 80% of training","2805da0c":"if not os.path.exists(unzip_dir):\n    os.makedirs(unzip_dir)\n    print(f'Directory ceated at {unzip_dir}')","d078ff80":"shutil.rmtree(unzip_dir)","7ed4aebd":"import zipfile\nwith zipfile.ZipFile(train_zip_path) as f:\n    f.extractall(unzip_dir)\nf.close","38c6229f":"with zipfile.ZipFile(test_zip_path) as f:\n    f.extractall(unzip_dir)\nf.close","3e61deb0":"# Let's see how many files we have in unziped folder\nlen(os.listdir(unzip_dir + 'train\/'))","da7f08c1":"# If we have base directory in path we are going to remove the directory\nif os.path.exists(base_dir):\n      shutil.rmtree(base_dir )\n\n# Creating typical folder structure used in image classification where images are stoored in respective classes \nos.makedirs(base_dir + 'train\/dog')\nos.makedirs(base_dir + 'train\/cat')\nos.makedirs(base_dir + 'val\/dog')\nos.makedirs(base_dir + 'val\/cat')","953d1d00":"# Now i am saving dog and cat images name in list, so that i can copy those images to the folder structure we need\ncat_filename = []\ndog_filename = []\n\nfor i in tqdm(os.listdir(unzip_dir + 'train\/')):\n    if i.startswith('dog'):\n        dog_filename.append(i)\n    else:\n        cat_filename.append(i)","5ab30a11":"# source = '\/content\/drive\/MyDrive\/Projects\/Image_search_engine\/data\/train\/'\n\nfor id_, image  in tqdm(enumerate(random.sample(dog_filename,no_of_images))):\n    if id_<int(0.8 * no_of_images):\n        shutil.copy2(unzip_dir + 'train\/' + image, base_dir + 'train\/' + 'dog\/' )\n    else:\n        shutil.copy2(unzip_dir + 'train\/'  + image, base_dir + 'val\/' + 'dog\/' )\n        \nfor id_, image  in tqdm(enumerate(random.sample(cat_filename,no_of_images))):\n    if id_<int(0.8 * no_of_images):\n        shutil.copy2(unzip_dir + 'train\/' + image, base_dir + 'train\/' + 'cat\/' )\n    else:\n        shutil.copy2(unzip_dir + 'train\/' + image, base_dir + 'val\/' + 'cat\/' )","77b0a1ee":"TRAIN_DATA_DIR = base_dir + 'train\/'\nVALIDATION_DATA_DIR = base_dir + 'val\/'\nbatch_size = 32","f3d6f2b4":"# pathlib.Path, will listing of subdirectories in the \"TRAIN_DATA_DIR\"\ntrain_data_dir = pathlib.Path(TRAIN_DATA_DIR)\n\n# .glob will find all files by using pattern we provided in the paranthessis of glob, Here all files in subfolders which is\n# Having extension as .jpg\nimage_count_train = len(list(train_data_dir.glob('*\/*.jpg')))\nprint(image_count_train)","83b3606a":"# Similarly we will do for VALIDATION_DATA_DIR\nvalid_data_dir = pathlib.Path(VALIDATION_DATA_DIR)\nimage_count_valid= len(list(valid_data_dir.glob('*\/*.jpg')))\nprint(image_count_valid)","d916a7d7":"# A dataset of all files matching one or more glob patterns metioned in \"tf.data.Dataset.list_files(pattern)\"\" \ntrain_list_ds = tf.data.Dataset.list_files(str(train_data_dir\/'*\/*'), shuffle=False)\n\n# We are shuffling the dataset with buffer size as image_count_train, Which is the best way to shuffle dataset,\n# But sometimes we can't fit that much of data in ram at a time, so I try to use 10% of data \ntrain_list_ds = train_list_ds.shuffle(image_count_train, reshuffle_each_iteration=False)\n\n# Similarly we will do this for validation data\nvalid_list_ds = tf.data.Dataset.list_files(str(valid_data_dir\/'*\/*'), shuffle=False)\nvalid_list_ds = valid_list_ds.shuffle(image_count_valid, reshuffle_each_iteration=False)","063e4813":"# As we can see from the result we have stored path of each image in \"train_list_ds\"\nfor f in train_list_ds.take(10):\n    print(f)","cbb64e66":"# Now, Need to know how many classes we have ? , Which are stored inside the \"class_names\" variable as list of strings\nclass_names= [i.name for i in train_data_dir.glob('*')]\nclass_names","68746020":"def get_label(file_path):\n    # split the path by seperator \"\/\"\n    parts = tf.strings.split(file_path,  os.path.sep)\n\n    # eg. let's assume value inside the \"one_hot\" will be [1, 0], this means that this file is belong to of class \n    # dog from list of class_names ['dog', 'cat'] \n    one_hot = parts[-2] == class_names\n\n    return tf.argmax(one_hot) # Return 1 or 0","eeb3e655":"def decode_image(file_path):\n\n    # read image in the string format\n    image = tf.io.read_file(file_path)\n\n    # decode image, this will decode string into array\n    image = tf.io.decode_jpeg(image)\n\n    return tf.image.resize(image, size =[224, 224]) # resize the image [224,224]","15d94cca":"def process_img(file_path):\n\n    # using \"get_label\" function we will get label\n    label = get_label(file_path)\n\n    # using \"decode_label\" function we will get image in format of array\n    image = decode_image(file_path)\n\n    return  image, label # returning image and label","624bff74":"# prefetch base on the memory available\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Finally we will call \"process_img\" function, using map, This will store image and label in train_ds. \ntrain_ds = train_list_ds.map(process_img, AUTOTUNE )\n\n# Similarly for valid dataset\nvalid_ds = valid_list_ds.map(process_img, AUTOTUNE)","c7bdd61c":"def configure_for_performance(ds):\n\n    #  To train a model with this dataset you will want the data:\n    #  To be well shuffled.\n    #  To be batched.\n    #  Batches to be available as soon as possible.\n    ds = ds.cache()\n    ds = ds.shuffle(buffer_size=1000)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size = AUTOTUNE)\n    return ds","96e3f699":"# configure the performance\ntrain_ds = configure_for_performance(train_ds)\nvalid_ds  = configure_for_performance(valid_ds)","08e449b5":"# Let's visualize the dataset\nimage_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n\n    label = label_batch[i]\n    plt.title(class_names[label])\n    plt.axis(\"off\")","9e2e3b82":"base_model = keras.applications.MobileNet(input_shape=(224,224,3),weights = 'imagenet', include_top=False)\n# base_model.summary()","8dc70605":"# Set base model trainable as false\nbase_model.trainable = True\nfor layer in base_model.layers[:-25]:\n    layer.trainable =False","cfe967fd":"# keras input with image shape (224, 224 , 3)\ninputs = keras.Input(shape = (224,224,3))\n\n# Preprocessing of image\n  # rescaling by dividing 255.0\nx = keras.layers.experimental.preprocessing.Rescaling(1.\/255)(inputs)\n\n  # RandomRotation by 20\nx = keras.layers.experimental.preprocessing.RandomRotation(20)(x)\n  # RandomHeight by 0.2\nx = keras.layers.experimental.preprocessing.RandomHeight(0.2)(x)\n  # RandomWidth by 0.2\nx = keras.layers.experimental.preprocessing.RandomWidth(0.2)(x)\n\n# Let's pass the model to base model\nx = base_model(x)\n\n# Global average pooling for passing to dense layer \nx = keras.layers.GlobalAveragePooling2D()(x)\n\n# Dense layer with 64 neuron\nx = keras.layers.Dense(64, activation ='relu')(x)\n\n# Dropout 20% of neuron\nx = keras.layers.Dropout(0.2)(x)\n\n# Let's predict\noutputs= keras.layers.Dense(2, activation='softmax')(x)\n\n# finally we are here to create model\nmodel = keras.Model(inputs, outputs)","788628d7":"# Compile the model\n\n # We use SparseCategoricalCrossentropy because our label are in integet format\nmodel.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n             optimizer = keras.optimizers.Adam(learning_rate=0.001),\n             metrics = ['accuracy'])","b4c8fcfa":"# We will stop training of model if there is no change in val loss upto 3 iteration\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3)","5151f65c":"# Fit the model \nhistory = model.fit(train_ds, epochs = 20,\n          validation_data = valid_ds,\n         batch_size = 32, callbacks = [early_stopping])","7a987c91":"import pandas as pd\npd.DataFrame(history.history).plot()","2c961a15":"Model_path= '\/kaggle\/working\/Model\/'","92297fea":"# Check is model path exists or not, otherwise create one\nif not os.path.exists(Model_path):\n    os.makedirs(Model_path)\n    print(f'New dir created at {Model_path}')","0702dc69":"model.save(Model_path + '\/cat_dog.h5')","f8495f61":"model = keras.models.load_model(Model_path + '\/cat_dog.h5')","1e99b602":"def get_image(img_path = None):\n    # This functions, will return img array, \n    # if image path is not given it will choose randomly from the val directory, either from dog or cat class\n    if img_path == None:\n        random_class = str(random.sample(class_names,1)[0])\n        img_path = os.path.join(base_dir + 'val\/' +random_class + '\/'+ random.sample(os.listdir(base_dir + 'val\/'+ random_class + '\/'),1)[0])\n    else:\n        img = tf.io.read_file(img_path)\n        img = tf.image.decode_image(img, channels=3)\n        img = tf.image.resize(img, size = [224,224])\n        img = tf.expand_dims(img.numpy(), axis = 0)\n    return img","8a405ef9":"pred_prob_0= [] # prob of class 0\npred_prob_1= [] # prob of class 1\npred_class = [] # pred class by our model\nactual_class = [] # Actualc class\npath_of_image = [] # path of ptredicted image\n\nfor cat_name in class_names:\n    for im_g in tqdm(os.listdir(base_dir + 'val\/' + cat_name + '\/')):  \n        pred = model.predict(get_image(img_path=base_dir + 'val\/' + cat_name + '\/' + im_g))\n        pred_prob_0.append(pred[0][0])\n        pred_prob_1.append(pred[0][1])\n        pred_class.append(np.argmax(pred))\n        actual_class.append(class_names.index(cat_name))\n        path_of_image.append(base_dir + 'val\/' + cat_name + '\/' + im_g)\n  ","59084b1b":"# Let's store all data we collected inside a dataframe\ndf = pd.DataFrame(columns = ['pred_prob_0', 'pred_prob_1', 'pred_class', 'actual_class'])\ndf['pred_prob_0'] = pred_prob_0\ndf['pred_prob_1'] = pred_prob_1\ndf['pred_class'] = pred_class\ndf['actual_class'] = actual_class\ndf['path_of_image'] = path_of_image\n# df['pred_class'] = df['pred_class'].astype('int64')\n# df['actual_class'] = df['actual_class'].astype('int64')\ndf.sample(10)","7f1e8a2e":"# Images with predicted class as dog with highest probability\nx = df[df['pred_class']==0].sort_values(by = ['pred_prob_0'], ascending = False, axis = 0).iloc[:9]\nplt.figure(figsize=(12,12))\nfor idx in range(9):\n    plt.subplot(3,3, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob dog {round(x.iloc[idx][\"pred_prob_0\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","82b2cd1b":"# Now lets see images predicted as dog with least probability\n\nx = df[df['pred_class']==0].sort_values(by = ['pred_prob_0'], ascending = True, axis = 0).iloc[:9]\nplt.figure(figsize=(10,10))\nfor idx in range(9):\n    plt.subplot(3,3, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob dog {round(x.iloc[idx][\"pred_prob_0\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","e43d0220":"# Let's see those which are confident about dog inspite of cats\n\nx = df[(df['pred_class']==0) & (df['actual_class']==1)].sort_values(by = ['pred_prob_0'], ascending = False, axis = 0).iloc[:9]\nle = len(x)\nplt.figure(figsize=(10,10))\nfor idx in range(4):\n    plt.subplot(2,2, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob as dog {round(x.iloc[idx][\"pred_prob_0\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","3d2d949b":"# Images with predicted class as cat with highest probability\nx = df[df['pred_class']==1].sort_values(by = ['pred_prob_1'], ascending = False, axis = 0).iloc[:9]\nplt.figure(figsize=(12,12))\nfor idx in range(9):\n    plt.subplot(3,3, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob cat {round(x.iloc[idx][\"pred_prob_1\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","e92b899e":"# Now lets see images predicted as cat with least probability\nx = df[df['pred_class']==1].sort_values(by = ['pred_prob_1'], ascending = True, axis = 0).iloc[:9]\nplt.figure(figsize=(10,10))\nfor idx in range(9):\n    plt.subplot(3,3, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob cat {round(x.iloc[idx][\"pred_prob_1\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","4adb0ec3":"# Let's see those which are confident about cat inspite of dog\n\nx = df[(df['pred_class']==1) & (df['actual_class']==0)].sort_values(by = ['pred_prob_1'], ascending = False, axis = 0).iloc[:9]\nplt.figure(figsize=(10,10))\nfor idx in range(4):\n    plt.subplot(2,2, idx+1)\n    img = get_image(x.iloc[idx]['path_of_image'])\n    plt.imshow(tf.squeeze(img, axis=0)\/255.0)\n    plt.title(label = f'Pred_prob as cat {round(x.iloc[idx][\"pred_prob_1\"], 2)} \\n Actual image {class_names[x.iloc[idx][\"actual_class\"]]}')\n    plt.axis('off')","3942ee24":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score","cf47154b":"print(f\"Accuracy of our model is {accuracy_score(df['actual_class'], df['pred_class'])}\")","089e856e":"# Pie chart\n\nlabels = ['Correctly predicted', 'Incorrectly predicted']\nsizes = [accuracy_score(df['actual_class'], df['pred_class']), 1-accuracy_score(df['actual_class'], df['pred_class'])]\nexplode = (0, 0.1)  # only \"explode\" the 2nd slice\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()\n\n# it's look really cool","e2fcf091":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns","e18dd7c0":"cm = confusion_matrix(df['actual_class'], df['pred_class'])\ncm","109927b5":"ax = sns.heatmap(cm, annot=True, fmt='g');\n\n## set title, X\/Y Labels.\nax.set_title('Seaborn Confusion Matrix');\nax.set_xlabel('Predicted Class')\nax.set_ylabel('Actual Class');\n## For the Tick Labels, the labels should be in Alphabetical order\nax.xaxis.set_ticklabels(class_names)\nax.yaxis.set_ticklabels(class_names)","275f56b0":"TP = cm[0][0]\nFP = cm[1][0]\nFN = cm[0][1]\nTN = cm[1][1]","87719dbf":"'''comment :-\n      We are predicting correcly a positive class with 97% times, among positive prediction\n      '''\nprecision = TP\/(TP+FN)\nprecision","f830f6dc":"''' comment:\n 97% times we are classifying positive image correctly\n'''\nRecall = TP\/(TP + FN)\nRecall","35b7a252":"# It will take into account both precicion and recall, \n# Best value for f1 score is 1 and the worst 0\n\nF1_score = 2* ((precision * Recall)\/(precision + Recall))\nF1_score","508500c0":"specificity = (TN\/(TN+FP))\nspecificity","57806f7d":"# If you come along to the end of this notebook, Please do comment for any improvement, Thank you :) ","78bb9f6a":"### d) Evaluate model by visualizing","47417937":"### c) Build model withiout finetuning\n\nWe will use Mobilenet pretrained model","14599584":"#### 4) Recall\nThis will tell us, How many predicted positive among all positive in our dataset.  \n\n$ Recall = \\frac{\\text{TP}}{\\text{TP + FN}} $\n\neg. as we can see from the confusion matrix, 1184 of dog class are predicted correctly and 16 predicted as cat though the image is of dog.","2b45e07c":"### e) evaluation matrics ","25f88a23":"You will need to unzip file you downloaded from kaggle  \nThere are multiple way to unzip the file  \n- 1) Using zipfile liabrary , We get flexibility to deal with the zipfile\n- 2) Using command line, Sometime I prefer to use command line as shown below    \n```\n!unzip zip_file_path -d destination_folder\n\n```\n\nHold a cup of coffee for a minute till it unzip","fb89de81":"Let's download dataset from kaggle to drive and have look at Procedure you will need to follow  \n>1) Download kaggle.json from kaggle\/username\/account , In that json you will get username and key.  \n>2) Replace key in the code below and execute \n```\n>import os  \n>os.environ['KAGGLE_USERNAME'] = \"usenrname\" # username from the json file  \n>os.environ['KAGGLE_KEY'] = \"key\" # key from the json file  \n```\n>3) Now copy API command from kaggle, You can get that in Data tab of the competition, It will be like this.   \n*(Attention : Please don't use double quotes to the path)*  \n```\n>*!kaggle competitions download -c \"compitition name seperated with (-)\" -p \"folder path where you want to download dataset\"*  \n```","5f33c5f8":"#### Arrange unzip images in the folder structure below","20ddc835":"#### Analysis of dog class\n\nIntentionally i have written this code again and again to have big picture what we are doing","1bd702e5":"#### 1) Classification accuracy\n\n","f5019cfc":"#### 3) Precision\n\nThis will tell us how many predicted positive are correcly classified  \n$ Precision = \\frac{\\text{TP}}{\\text{TP + FP}} $\n\n","605bffcd":"#### Analysis of cat class","3abbb301":"\n$Accuracy = \\frac{\\text{Number of correct prediction }}{\\text{ No of all prediction }}$","6ba45ae0":"### b) Data Preparation \nTo have faster communication while training we will take advantage by prefetching images using tensorflow, This is procedure we can follow for every dataset in this format, This will drastically decrease the training time ","095d2ffe":"#### 6) Specificity\n\nProportion of negative class that is correctly predicted negative  , We can say this as recall for negative class\n\n$ Specificity = \\frac{\\text{TN}}{\\text{TN + FP}} $","ac1956a0":"### a) Download the dataset from kaggle and arrange images as per requirnment, \nIf you are executing on colab","4260eda1":"#### Unzip file","133b66fe":"This doesent look good , we will try to plot","cf2c3ec0":" Let's evaluate our dataset on \n> Some questions we need to answer\n>> 1) Which images are the most confident?    \n>> 2) Which images are the list confident?    \n>> 3) Which images got high confidence instead of high probability?  ","1a185189":"#### 2) Confusion Matrix","22228b4d":"#### 5) F1 Score\n\n$\\text{F1 score} = 2 * \\frac{\\text{precision} *  \\text{recall}}{\\text{precision} +  \\text{recall}}$"}}