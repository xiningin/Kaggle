{"cell_type":{"abdd5a59":"code","53dbe557":"code","1ed1ce96":"code","26bd6995":"code","68ec53f5":"code","ce44cbb6":"code","edbd61fa":"code","1f664af8":"code","2b239e23":"code","4a3b50f7":"code","5a2da1b2":"code","5a18f6da":"code","971c4552":"code","1bd07e3e":"code","7c8ceccf":"code","a23837bb":"markdown","a6aefcf7":"markdown","88d51aab":"markdown","1a490b64":"markdown","f6b27e39":"markdown","362fb728":"markdown","c5e4d17b":"markdown","aaf1840f":"markdown"},"source":{"abdd5a59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","53dbe557":"import pandas as pd\nimport numpy as np \n\ndata_dir = \"..\/input\/\"\n\ndf = pd.read_csv(data_dir + '\/spam.csv', encoding='latin-1')  \n# \u7f16\u7801\u76f8\u5173\u9605\u8bfbhttp:\/\/blog.csdn.net\/robertcpp\/article\/details\/7837712 \n\n# \u67e5\u770b\u6570\u636e\ndf.head()","1ed1ce96":"# \u67e5\u770bv2\u7684\u6837\u672c\ndf.v2.head()","26bd6995":"# \u67e5\u770bv1\u7684\u6837\u672c\ndf.v1.head()","68ec53f5":"# \u67e5\u770b\u6570\u636e\u7684\u7eac\u5ea6\ndf.shape","ce44cbb6":"from sklearn.model_selection import train_test_split\n\n# \u628a\u6570\u636e\u62c6\u5206\u6210\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\n# train_test_split (X, Y, test_size=0.2, random_state=0)\ndata_train, data_test, labels_train, labels_test = train_test_split(\n    df.v2,\n    df.v1, \n    test_size=0.2, \n    random_state=0) \n\n# \u67e5\u770b\u8bad\u7ec3\u96c6\u6837\u672c\nprint (data_train.head())\n# \u67e5\u770b\u8bad\u7ec3\u96c6\u6807\u6ce8\nprint (labels_train.head())\n# \u67e5\u770b\u8bad\u7ec3\u96c6\u7684\u6837\u672c\u4e2a\u6570\nprint(data_train.shape)\n# \u67e5\u770b\u6d4b\u8bd5\u673a\u7684\u6837\u672c\u4e2a\u6570\nprint(data_test.shape)","edbd61fa":"from sklearn.feature_extraction.text import CountVectorizer\n# \u8c03\u7528\u5e93\u6765\u6784\u9020\u5206\u7c7b\u5668\u6240\u9700\u7684\u8f93\u5165\u6570\u636e\nvectorizer = CountVectorizer()\n\n#fit_transform\u4e00\u5171\u5b8c\u6210\u4e86\u4e24\u4ef6\u4e8b. fit: build dict (i.e. word->wordID)  transform: convert document (i.e. each line in the file) to word vector \n#http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n#fit: \u7edf\u8ba1\u5355\u8bcd\u7684\u603b\u4e2a\u6570\uff0c\u5efa\u6210\u4e00\u4e2a\u8868\uff0c\u6bcf\u4e2a\u5355\u8bcd\u7ed9\u4e00\u4e2a\u6807\u53f7 (\u8fd9\u4e2a\u5e93\u5185\u90e8\u5b9e\u73b0\u6709\u4e00\u4e2a\u7f3a\u9677\uff0c\u4f1a\u628a\u957f\u5ea6\u4e3a1\u7684\u5355\u8bcd\u7ed9\u8fc7\u6ee4\u6389\u4e86)\n#transform:\u7edf\u8ba1\u6bcf\u53e5\u8bdd\u6bcf\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\n\n# \u7528\u8bad\u7ec3\u96c6\u7684\u5355\u8bcd\u6765\u5efa\u7acb\u8bcd\u5e93\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u96c6\u7684\u6570\u636e\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5c5e\u4e8e\u672a\u77e5\u6570\u636e\uff0c\u4e14\u628a\u8bad\u7ec3\u96c6\u6bcf\u53e5\u8bdd\u8bcd(\u4e5f\u5c31\u662finput doc\u4e2d\u7684\u6bcf\u4e00\u884c)\u53d8\u6210\u5411\u91cf\u5f62\u6001\ndata_train_count = vectorizer.fit_transform(data_train)\n# \u628a\u6d4b\u8bd5\u96c6\u6bcf\u53e5\u8bdd\u53d8\u6210\u5411\u91cf\u5f62\u6001\ndata_test_count  = vectorizer.transform(data_test)","1f664af8":"# \u8bad\u7ec3\u6570\u636e\u7eac\u5ea6 \n# 7612 \u4e5f\u5c31\u662ffit\u8fc7\u7a0b\u4e2d\u5efa\u7acb\u7684\u8bcd\u6c47\u8868\u7684size\nprint (data_train_count.shape)\n# \u6d4b\u8bd5\u6570\u636e\u7eac\u5ea6\nprint (data_test_count.shape)","2b239e23":"# \u770b\u770b\u8fd9\u4e9b\u6570\u636e\u957f\u4ec0\u4e48\u6837\n# \u8bcd\u6c47\u8868 \uff08\u592a\u957f\u4e86\uff0c\u6211\u8fd9\u91cc\u6ce8\u91ca\u6389\uff09\nprint (len(vectorizer.vocabulary_))\n#print (vectorizer.vocabulary_)\n# print first 3 lines. \n# each line: represent the word verctor for a setence\/email content which is just the each line in the input file i.e. spam.csv\n# each line: e.g. [0,0,1, 2.....0,0,0] 1\u8868\u793a\u8bcd\u5178\u4e2dindex \u4e3a2\u7684\u5355\u8bcd\uff0c\u5728\u8fd9\u4e00\u4efddoc\/\u90ae\u4ef6\uff0c\u4e2d\u51fa\u73b01\u6b21\uff0c2\u8868\u793a\u5178\u4e2dindex 3\u7684\u5355\u8bcd\uff0c\u5728\u8fd9\u4e00\u4efddoc\/\u90ae\u4ef6\u4e2d\u51fa\u73b02\u6b21\nprint(data_train_count.toarray()[0:4])","4a3b50f7":"import matplotlib.pyplot as plt # \u753b\u56fe\u5e38\u7528\u5e93\n\n# \u6211\u4eec\u6765\u770b\u770b\u5355\u8bcd\u7684\u5206\u5e03. \u7edf\u8ba1\u6bcf\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\n# \u56e0\u4e3amatrix\u6bcf\u4e00\u884c\u5c31\u4ee3\u8868\u4e00\u4e2a\u53e5\u5b50\u91cc\u7684\u5355\u8bcd\u5206\u5e03, \u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\uff08i.e. column\uff09\u7684\u6570\u503c\u5373\u8868\u793a\uff0cdict\u91cc\u5bf9\u5e94\u7684index\u7684\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570. \u6240\u4ee5\u77e9\u9635\u6309\u5217\u6c42\u548c\u5c31\u53ef\u4ee5\u6c42\u51fa\u6bcf\u4e2a\u5355\u8bcd\u5728\u603b\u7684spam.csv\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\noccurrence = data_train_count.toarray().sum(axis=0) #\u628a\u77e9\u9635\u6309\u5217\u6c42\u548c\nplt.plot(occurrence)\nplt.show() # \u663e\u793a\u56fe\u5f62\uff0c x \u8f74\u8868\u793a\u5355\u8bcd\u7684index, y\u8f74\u8868\u793a\uff0cdict\u4e2d\u5bf9\u5e94index\u7684\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\n\n# \u6309\u7167\u6bcf\u4e2a\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\u4ece\u9ad8\u5230\u4f4e\u8fdb\u884c\u6392\u5e8f. get_feature_names \u5373\u662fdict\u91cc\u9762\u7684word.\n# build dataframe\nword_freq_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'occurrence':occurrence})\nword_freq_df_sort = word_freq_df.sort_values(by=['occurrence'], ascending=False)\nword_freq_df_sort.head()","5a2da1b2":"from sklearn.naive_bayes import MultinomialNB\n\nclf = MultinomialNB()\nclf.fit(data_train_count, labels_train)\npredictions = clf.predict(data_test_count)\nprint(predictions)","5a18f6da":"from sklearn.metrics import accuracy_score\n\nprint (accuracy_score(labels_test, predictions))","971c4552":"from sklearn.metrics import classification_report,confusion_matrix\nprint (confusion_matrix(labels_test, predictions))","1bd07e3e":"print (classification_report(labels_test, predictions))","7c8ceccf":"from sklearn.model_selection import cross_val_score\n# \u4ecedf\u83b7\u5f97\u5168\u90e8\u90ae\u4ef6\u5185\u5bb9\u548c\u6807\u6ce8\ndata_content = df.v2\ndata_label = df.v1\nvect = CountVectorizer()\n# \u5728\u6574\u4f53\u6570\u636e\u96c6\u4e0a\u6784\u5efa\u8bcd\u6c47\u8868\u4ee5\u53ca\u8f6c\u5316\u6210\u8ba1\u6570\u683c\u5f0f Note: \u8fd9\u91cc\u4e0d\u9700\u8981train, validation split. cross_val_score will handle this split\ndata_count = vect.fit_transform(data_content)\n# \u4ea4\u53c9\u9a8c\u8bc1 clf = MultinomialNB()\n# cross_val_score(model, X, Y, cv=20, scoring=\"accuracy\")\ncross_val = cross_val_score(clf, data_count, data_label, cv=20, scoring='accuracy')\n# \u6253\u5370\u6bcf\u7ec4\u5b9e\u9a8c\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\nprint (cross_val)\n# \u6c42\u5e73\u5747\u503c\nprint (np.mean(cross_val))","a23837bb":"**\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u4ee5\u53ca\u9884\u6d4b**","a6aefcf7":"**\u56fe\u5f62\u5316\u5c55\u793a\u4e00\u4e9b\u6570\u636e\uff0c\u83b7\u5f97\u66f4\u76f4\u89c2\u7684\u7406\u89e3**","88d51aab":"\n**\u5783\u573e\u90ae\u4ef6\u5206\u7c7b**\n\nhttps:\/\/www.kaggle.com\/uciml\/sms-spam-collection-dataset","1a490b64":"**\u628a\u6570\u636e\u62c6\u5206\u6210\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6**","f6b27e39":"**\u5176\u4ed6\u5e38\u7528\u6307\u6807: \uff08Precision, Recall, F1-score, confusion_matrix\uff09**","362fb728":"**\u6784\u5efa\u6a21\u578b\u6240\u9700\u8981\u7684\u6570\u636e\u683c\u5f0f\uff1a\u4e00\u4e2a\u8bcd\u6c47\u8868\uff0c\u4ee5\u53ca\u8bad\u7ec3\u53ca\u6d4b\u8bd5\u6570\u636e\u7684\u8ba1\u6570\u4fe1\u606f\uff1a(\u53e5\u5b50id,\u5355\u8bcdid)->\u8ba1\u6570**","c5e4d17b":"**\u4ea4\u53c9\u9a8c\u8bc1\u7684\u793a\u8303:**","aaf1840f":"**\u8ba1\u7b97\u6a21\u578b\u7684\u51c6\u786e\u7387**"}}