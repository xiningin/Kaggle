{"cell_type":{"e725408d":"code","9dde092b":"code","c826b559":"code","ec43a88a":"markdown","42ccce3c":"markdown","34f781f2":"markdown"},"source":{"e725408d":"import os\nimport numpy\nfrom sklearn import metrics\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score","9dde092b":"wr = open('results.txt', \"w\", encoding='utf8')\nmybest = pd.read_csv('\/kaggle\/input\/mybest\/sub9523.csv')\nsub = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-test-translated\/jigsaw_miltilingual_test_translated.csv')\nsub1 = pd.read_csv('\/kaggle\/input\/mysub42\/sub9458.csv')\nsub['prd'] = sub1['toxic']\n\n#Ranges here may be manually reset to save computing time.\n#p = [1.30,0.60,0.80,0.50,0.60,0.60]\nfor p0 in numpy.arange(1.2, 1.3, 0.1):\n    for p1 in numpy.arange(0.6, 0.7, 0.1):\n        for p2 in numpy.arange(0.8, 0.9, 0.1):\n            for p3 in numpy.arange(0.6, 0.7, 0.1):\n                for p4 in numpy.arange(0.6, 0.7, 0.1):\n                    for p5 in numpy.arange(0.6, 0.7, 0.1):\n                        out = []\n                        for _, row in sub.iterrows():\n                            item = [row['id'], row['prd'], row['lang']]\n                            if(item[2]=='es'):\n                                if(item[1]<0.7):\n                                    item[1] *= p0#1.250    99.9455    99.8233\n                            elif(item[2]=='fr'):\n                                if(item[1]<0.7):\n                                    item[1] *= p1#0.950    99.9436    99.8294\n                            elif(item[2]=='ru'):\n                                if(item[1]<0.7):\n                                    item[1] *= p2#0.900    99.9409    99.8379\n                            elif(item[2]=='it'):\n                                if(item[1]<0.7):\n                                    item[1] *= p3#0.750    99.9480    99.8688\n                            elif(item[2]=='tr'):\n                                if(item[1]<0.7):\n                                    item[1] *= p4#0.900    99.9486    99.8715\n                            elif(item[2]=='pt'):\n                                if(item[1]<0.7):\n                                    item[1] *= p5#-3 0.9991403473465919 0.9981593\n\n                            out.append(item)\n\n                        of = pd.DataFrame(out, columns=['id', 'toxic', 'lang'])\n                        score1 = roc_auc_score(mybest.toxic.round().astype(int), of.toxic.values)\n                        score2 = roc_auc_score(of.toxic.round().astype(int), mybest.toxic.values)\n                        line = '%1.2f,%1.2f,%1.2f,%1.2f,%1.2f,%1.2f\\t%2.4f\\t%2.4f'%(p0, p1,p2,p3,p4,p5, 100*score1, 100*score2)\n                        print(line)\n                        wr.write(line+'\\n')\nwr.close()","c826b559":"wr = open('results.txt', \"w\", encoding='utf8')\nmybest = pd.read_csv('\/kaggle\/input\/mybest\/sub9523.csv')\nsub = pd.read_csv('\/kaggle\/input\/jigsaw-multilingual-toxic-test-translated\/jigsaw_miltilingual_test_translated.csv')\nsub1 = pd.read_csv('\/kaggle\/input\/mysub42\/sub9458.csv')\nsub['prd'] = sub1['toxic']\n\ndic = {}#Profanity dictionary.\noft = open('\/kaggle\/input\/profanity\/Profanity.txt', \"r\", encoding='utf8')\nfor l in oft:\n    ele = l.strip().lower().split(':')\n    dic[ele[0]] = ele[1]\noft.close()\n\n#I set all weights as 1 and tune them one by one to save computing time.\nlen, les, lit, ltr, lfr, lru, lpt = 1., 1., 1., 1., 1., 1., 1.\n\n#len 1052 1.4: 99.9771    99.9512\n#les 101 1.00:    99.9771    99.9512\n#lit 235 1.10:    99.9770    99.9515\n#ltr 41 1.00:    99.9770    99.9515\n#lfr 202 1.00:    99.9770    99.9515\n#lru 1.30:    99.9680    99.7974\n#lpt 66 1.30:    99.9771    99.9519\n\nenpros = dic['en'].split(',')\nfor len in numpy.arange(1.3, 1.4, 0.1):\n    out = []\n    found = 0\n    for _, row in sub.iterrows():\n        if(row['lang']=='es'):\n            lmd = les#99.4925    99.2043\n        elif(row['lang']=='it'):\n            lmd = lit\n        elif(row['lang']=='tr'):\n            lmd = ltr\n        elif(row['lang']=='fr'):\n            lmd = lfr\n        elif(row['lang']=='ru'):\n            lmd = lru\n        else:\n            lmd = lpt\n\n        item = [row['id'], row['prd']]\n        if(item[1]<0.5):\n            for w in enpros:\n                if(str(row['translated']).lower().find(w)>=0):\n                    item[1] *= len\n                    found += 1\n                    break\n\n            ws = dic[row['lang']].split(',')\n            for w in ws:\n                if(str(row['content']).lower().find(w)>=0):\n                    item[1] *= lmd\n                    #if(row['lang']=='pt'):\n                        #found += 1\n                    break\n        out.append(item)\n\n\n    of = pd.DataFrame(out, columns=['id', 'toxic'])\n    \n    score1 = roc_auc_score(mybest.toxic.round().astype(int), of.toxic.values)\n    score2 = roc_auc_score(of.toxic.round().astype(int), mybest.toxic.values)\n    l = '%1.2f:\\t%2.4f\\t%2.4f'%(len, 100*score1, 100*score2)\n    print(found, l)\n    wr.write(l+'\\n')\nwr.close()","ec43a88a":"**2. Learn profanity weights.**","42ccce3c":"**1. Learn language weights.**","34f781f2":"**This notebook is used for learning language and profanity weights.**\nTo avoid overfitting, I randomly choose one set from the top 10 best weights and accept it if it leads to an increase in my public leaderboard score."}}