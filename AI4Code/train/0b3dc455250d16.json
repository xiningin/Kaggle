{"cell_type":{"c2e015f7":"code","91d603ac":"code","42eebd07":"code","31676f9a":"code","bab5e372":"code","f05c944f":"code","1beeee01":"code","4deda0a7":"code","d0beaa4e":"code","45723993":"code","11cc24af":"code","589e7929":"code","eb2acabd":"code","6ffe0baf":"code","f1fed712":"code","85c33e1d":"code","572ba4ba":"code","ed9ca6db":"code","dc49bc5b":"code","f451f003":"code","e1d8b7e1":"code","379f8633":"code","c9ea6869":"code","a2ae2581":"code","2d3040f5":"code","d3a8cf5a":"code","919fca33":"code","a8bac5d7":"code","542e8bff":"code","d67e6d4a":"code","d7bd1926":"code","6084678b":"code","f3466dd1":"code","535ea82a":"code","d18a956f":"code","8597b694":"code","da8ccd9a":"code","a3cb63c5":"code","89d103f4":"code","631d2c01":"code","6d87c64c":"markdown","15ee8b67":"markdown","53fa9903":"markdown","18e23128":"markdown","6fd5db47":"markdown","d18739c8":"markdown","eaf91fda":"markdown","98af443c":"markdown","1132f56a":"markdown","7afdede4":"markdown","75203e54":"markdown","d4c3a122":"markdown","a10a0968":"markdown","fb64a371":"markdown","1426c0fb":"markdown","c0f2f055":"markdown"},"source":{"c2e015f7":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport cv2","91d603ac":"mask_path = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\"\nno_mask_path = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithoutMask\"","42eebd07":"image_mask = []\ntarget_mask = []\nfor i in os.listdir(mask_path):\n    pic = os.path.join(mask_path + \"\/\", i)\n    image_mask.append(pic)\n    target_mask.append(\"mask\")   \n\nimage_no_mask = []\ntarget_no_mask = []\nfor i in os.listdir(no_mask_path):\n    pic = os.path.join(no_mask_path + \"\/\", i)\n    image_no_mask.append(pic)\n    target_no_mask.append(\"without_mask\")\n\nmask = pd.DataFrame()\nmask[\"image\"] = image_mask\nmask[\"target\"] = target_mask\n\nno_mask = pd.DataFrame()\nno_mask[\"image\"] = image_no_mask\nno_mask[\"target\"] = target_no_mask\n\ndata = pd.concat([mask, no_mask], axis = 0, ignore_index = True)\ndata = shuffle(data)\ndata","31676f9a":"sns.countplot(data[\"target\"])","bab5e372":"w_mask  = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\/1023.png'\nwo_mask = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithoutMask\/1004.png'\n\nimages = [w_mask, wo_mask]","f05c944f":"img1 = cv2.imread(w_mask)\nimg2 = cv2.imread(wo_mask)\n\nimgs = [img1, img2]","1beeee01":"def img_read( images ):\n    res = cv2.imread(images)\n    return res\ndef convert2rgb(img):\n    res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return res","4deda0a7":"img = convert2rgb(imgs[0])\nplt.figure(figsize=(12,8))\nplt.imshow(img)\nplt.title(\"With Mask\", color = \"green\", size = 14)\nplt.grid(color='#999999', linestyle='-')\nplt.show()","d0beaa4e":"img = convert2rgb(imgs[1])\nplt.figure(figsize=(12,8))\nplt.imshow(img)\nplt.title(\"Without Mask\", color = \"green\", size = 14)\nplt.grid(color='#999999', linestyle='-')\nplt.show()","45723993":"#Color Channel on image with mask\n\nimport skimage.io as io\nimport matplotlib.pyplot as plt\n\n# Read\nimg = io.imread(w_mask)\n\n# Split\nred = img[:, :, 0]\ngreen = img[:, :, 1]\nblue = img[:, :, 2]\n\n# Plot\nfig, axs = plt.subplots(2,2)\n\nax_00 = axs[0,0].imshow(img)\naxs[0,0].set_title('With Mask')\naxs[0,0].xaxis.set_major_formatter(plt.NullFormatter())  # kill xlabels\naxs[0,0].yaxis.set_major_formatter(plt.NullFormatter())  # kill ylabels\n\ncax_01 = axs[0,1].imshow(red, cmap='Reds')\nfig.colorbar(cax_01, ax=axs[0,1])\naxs[0,1].set_title('Red Channel')\naxs[0,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[0,1].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_10 = axs[1,0].imshow(green, cmap='Greens')\nfig.colorbar(cax_10, ax=axs[1,0])\naxs[1,0].set_title('Green Channel')\naxs[1,0].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,0].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_11 = axs[1,1].imshow(blue, cmap='Blues')\nfig.colorbar(cax_11, ax=axs[1,1])\naxs[1,1].set_title('Blue Channel')\naxs[1,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,1].yaxis.set_major_formatter(plt.NullFormatter())\nplt.show()\n\n\n# Plot histograms\nfig, axs = plt.subplots(3, sharex=True, sharey=True)\n\naxs[0].hist(red.ravel(), bins=10)\naxs[0].set_title('Red')\naxs[1].hist(green.ravel(), bins=10)\naxs[1].set_title('Green')\naxs[2].hist(blue.ravel(), bins=10)\naxs[2].set_title('Blue')\n\nplt.show()","11cc24af":"#Color Channel on image without mask\n\n# Read\nim = io.imread(wo_mask)\n\n# Split\nred = im[:, :, 0]\ngreen = im[:, :, 1]\nblue = im[:, :, 2]\n\n# Plot\nfig, axs = plt.subplots(2,2)\n\ncax_00 = axs[0,0].imshow(im)\naxs[0,0].set_title('Without Mask')\naxs[0,0].xaxis.set_major_formatter(plt.NullFormatter())  # kill xlabels\naxs[0,0].yaxis.set_major_formatter(plt.NullFormatter())  # kill ylabels\n\ncax_01 = axs[0,1].imshow(red, cmap='Reds')\nfig.colorbar(cax_01, ax=axs[0,1])\naxs[0,1].set_title('Red Channel')\naxs[0,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[0,1].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_10 = axs[1,0].imshow(green, cmap='Greens')\nfig.colorbar(cax_10, ax=axs[1,0])\naxs[1,0].set_title('Green Channel')\naxs[1,0].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,0].yaxis.set_major_formatter(plt.NullFormatter())\n\ncax_11 = axs[1,1].imshow(blue, cmap='Blues')\nfig.colorbar(cax_11, ax=axs[1,1])\naxs[1,1].set_title('Blue Channel')\naxs[1,1].xaxis.set_major_formatter(plt.NullFormatter())\naxs[1,1].yaxis.set_major_formatter(plt.NullFormatter())\nplt.show()\n\n# Plot histograms\nfig, axs = plt.subplots(3, sharex=True, sharey=True)\n\naxs[0].hist(red.ravel(), bins=10)\naxs[0].set_title('Red')\naxs[1].hist(green.ravel(), bins=10)\naxs[1].set_title('Green')\naxs[2].hist(blue.ravel(), bins=10)\naxs[2].set_title('Blue')\n\nplt.show()\n","589e7929":"import numpy as np\nimport pandas as pd\nimport argparse\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","eb2acabd":"#Read Image\/Import\nwithmask_path = '..\/input\/example\/example_01.png'\nwithmask = cv2.imread(withmask_path, cv2.IMREAD_UNCHANGED)\nwithmask1 = cv2.cvtColor(withmask, cv2.COLOR_BGR2RGB)\n#Display Images\nplt.imshow(withmask1)","6ffe0baf":"def cont_bright(img):\n    alpha = 1.4 # Contrast control (1.0-3.0)\n    beta = 0 # Brightness control (0-100)\n    adjusted = cv2.convertScaleAbs(withmask1, alpha=alpha, beta=beta)\n    return adjusted","f1fed712":"image_adjust= cont_bright(withmask1)\n\nfig, ax = plt.subplots(1, 2, figsize=(5, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('ADJUSTED', fontsize=12)\n\nax[0].imshow(withmask1\/255);\nax[1].imshow(image_adjust);","85c33e1d":"# CROPPING\ndef crop(withmask, x, y, h, w):\n    crop_img = withmask[y:y+h, x:x+w]\n    return crop_img","572ba4ba":"image_crop = crop(withmask1, 150, 210, 180, 190)\n\nfig, ax = plt.subplots(1, 2, figsize=(5, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('CROPPED', fontsize=12)\n\nax[0].imshow(withmask1\/255);\nax[1].imshow(image_crop);","ed9ca6db":"# RESIZING\ndef resize(img):\n    withmask = cv2.resize(withmask1,(600,500))\n    return withmask","dc49bc5b":"image_resize= resize(withmask1)\n\nfig, ax = plt.subplots(1, 2, figsize=(5, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('RESIZED', fontsize=12)\n\nax[0].imshow(withmask1\/255);\nax[1].imshow(image_resize);","f451f003":"#image  gray  function\ndef  gray_image(image):\n    mask = create_mask_for_image(image)\n    output = cv2.cvtColor(withmask1,  cv2.COLOR_BGR2GRAY)\n    return output\/255","e1d8b7e1":"#Grayed Image\nimage_gray =  cv2.cvtColor(withmask1, cv2.COLOR_BGR2GRAY)\n\nfig, ax = plt.subplots(1, 2, figsize=(5, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('GRAY', fontsize=12)\n\nax[0].imshow(withmask1\/255);\nax[1].imshow(image_gray, cmap='gray');","379f8633":"gray_img = cv2.cvtColor(withmask1, cv2.COLOR_RGB2GRAY)","c9ea6869":"# Threshold on image\n_, threshold_img = cv2.threshold(gray_img, 40, 255, cv2.THRESH_BINARY)\n\nplt.imshow(cv2.cvtColor(threshold_img, cv2.COLOR_GRAY2RGB))","a2ae2581":"face_gray = cv2.cvtColor(withmask1, cv2.COLOR_BGR2GRAY)\nface_preprocessed = cv2.GaussianBlur(face_gray, (5, 5), 0)\n\nplt.imshow(cv2.cvtColor(face_preprocessed, cv2.COLOR_GRAY2RGB))","2d3040f5":"adaptive_thresh = cv2.adaptiveThreshold(gray_img,255,\\\n                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n                                         cv2.THRESH_BINARY,11,2)\nplt.imshow(cv2.cvtColor(adaptive_thresh, cv2.COLOR_GRAY2RGB))","d3a8cf5a":"#Threshold on blurred image\nimg_blur_small = cv2.GaussianBlur(withmask1, (7,7), 25)\nimg_blur_large = cv2.GaussianBlur(withmask1, (15,15), 0)\n\ngray_blur_img = cv2.cvtColor(img_blur_small, cv2.COLOR_BGR2GRAY)\n_, threshold_img_blur = cv2.threshold(gray_blur_img, 40, 255, cv2.THRESH_BINARY)\nplt.imshow(cv2.cvtColor(threshold_img_blur, cv2.COLOR_GRAY2RGB))","919fca33":"_, face_binary = cv2.threshold(face_preprocessed, 40, 255, cv2.THRESH_BINARY)\n\n#Invert image to get the mask\nface_binary = cv2.bitwise_not(face_binary)\nmorph_kernel = np.ones((5,5),np.uint8)\n\nface_morph = cv2.morphologyEx(face_binary, cv2.MORPH_CLOSE, morph_kernel)\n\nplt.imshow(cv2.cvtColor(face_morph, cv2.COLOR_GRAY2RGB))","a8bac5d7":"# find contours\nface_contours, _ = cv2.findContours(face_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# make copy of image\nface_and_contours = np.copy(withmask)\n\n# find contours of large enough area\nmin_face_area = 60\nlarge_contours = [cnt for cnt in face_contours if cv2.contourArea(cnt) > min_face_area]\n\n# draw contours\ncv2.drawContours(face_and_contours, large_contours, 0, (255,0,0))\n\nplt.imshow(cv2.cvtColor(face_and_contours, cv2.COLOR_BGR2RGB))","542e8bff":"bounding_img = np.copy(withmask)\n\n# for each contour find bounding box, draw rectangle, and put mask text\nfor contour in large_contours:\n    x, y, w, h = cv2.boundingRect(contour)\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    textSize = cv2.getTextSize(text=\"Mask\", fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=3)\n    cv2.putText(bounding_img,\n                    text = \"Mask\",\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (0.5*w)\/textSize[0][0],\n                    color = (0, 255, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n    cv2.rectangle(bounding_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n\nplt.imshow(cv2.cvtColor(bounding_img, cv2.COLOR_BGR2RGB))","d67e6d4a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport os\nimport random\nimport cv2","d7bd1926":"train_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\"\nval_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"\ntest_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\"\n\nclasses = [\"With Mask\", \"Without Mask\"]","6084678b":"def load_rand():\n    X=[]\n \n    for sub_dir in tqdm(os.listdir(train_dir)):\n        print(sub_dir)\n        path_main=os.path.join(train_dir,sub_dir)\n        i=0\n        for img_name in os.listdir(path_main):\n            if i>=6:\n                break\n            img=cv2.imread(os.path.join(path_main,img_name))\n            img=cv2.resize(img,(100,100))\n            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            X.append(img)\n            i+=1\n    return X","f3466dd1":"X=load_rand()\n\nX=np.array(X)\nX.shape","535ea82a":"#Figure 1. With Mask\n\nn = 10\n\nplt.figure(figsize=(30, n))\nfor i in range(n):\n   \n    sample = random.choice(os.listdir(train_dir + \"\/WithMask\"))\n  \n    img_dir = train_dir + \"\/WithMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n   \n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"With Mask\")\nplt.show()   ","d18a956f":"#Figure 2. Without Mask\n\nplt.figure(figsize=(30, n))\nfor i in range(n):\n  \n    sample = random.choice(os.listdir(train_dir + \"\/WithoutMask\"))\n   \n    img_dir = train_dir + \"\/WithoutMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"Without Mask\")\nplt.show()","8597b694":"import tensorflow as tf\nimport keras\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nimport numpy as np\nimport argparse \nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","da8ccd9a":"model = tf.keras.models.load_model(\"..\/input\/modelh5\/My_Model.h5\")\nimages=['..\/input\/example\/example_01.png', '..\/input\/example\/example_02.png','..\/input\/example\/example_03.png' ]\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')","a3cb63c5":"img = images[0]    # Add path here\n    \nimg = plt.imread(img,format='8UC1')\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\ngray = np.array(gray, dtype='uint8')\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n\n# Draw the rectangle around each face\nfor (x, y, w, h) in faces:\n\n    face = img[y:y+h, x:x+w]\n    face = cv2.resize(face, (224, 224))\n    face = img_to_array(face)\n    face = preprocess_input(face)\n    face = np.expand_dims(face, axis=0)\n    (mask, withoutMask) = model.predict(face)[0]\n    mask = mask*100\n    withoutMask = withoutMask*100\n    \n    font = cv2.FONT_HERSHEY_SIMPLEX\n    \n    # Getting Text Size in pixel\n    print(\"Image Width: \" , w)\n    textSize = cv2.getTextSize(text=\"No Mask: \" + str(\"%.2f\" % round(mask, 2)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=3)\n    print(\"Text Width: \" , textSize[0][0])\n    \n    if mask > withoutMask:\n        cv2.putText(img,\n                    text = \"Mask: \" + str(\"%.2f\" % round(mask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (2*w)\/textSize[0][0],\n                    color = (0, 255, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 5)\n    else:\n        cv2.putText(img,\n                    text = \"No Mask: \" + str(\"%.2f\" % round(withoutMask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (1.8*w)\/textSize[0][0],\n                    color = (255, 0, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 5)\n\n# Display\nplt.imshow(img)\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)","89d103f4":"img = images[1]    # Add path here\n    \nimg = plt.imread(img,format='8UC1')\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\ngray = np.array(gray, dtype='uint8')\n\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n\n# Draw the rectangle around each face\nfor (x, y, w, h) in faces:\n\n    face = img[y:y+h, x:x+w]\n    face = cv2.resize(face, (224, 224))\n    face = img_to_array(face)\n    face = preprocess_input(face)\n    face = np.expand_dims(face, axis=0)\n    (mask, withoutMask) = model.predict(face)[0]\n    mask = mask*100\n    withoutMask = withoutMask*100\n    \n    font = cv2.FONT_HERSHEY_SIMPLEX\n    \n    # Getting Text Size in pixel\n    print(\"Image Width: \" , w)\n    textSize = cv2.getTextSize(text=\"No Mask: \" + str(\"%.2f\" % round(mask, 2)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=3)\n    print(\"Text Width: \" , textSize[0][0])\n    \n    if mask > withoutMask:\n        cv2.putText(img,\n                    text = \"Mask: \" + str(\"%.2f\" % round(mask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (2*w)\/textSize[0][0],\n                    color = (0, 255, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 5)\n    else:\n        cv2.putText(img,\n                    text = \"No Mask: \" + str(\"%.2f\" % round(withoutMask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (1.8*w)\/textSize[0][0],\n                    color = (255, 0, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 5)\n\n# Display\nplt.imshow(img)\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)","631d2c01":"img = images[2]    # Add path here\n    \nimg = plt.imread(img,format='8UC1')\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\ngray = np.array(gray, dtype='uint8')\n\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n\n# Draw the rectangle around each face\nfor (x, y, w, h) in faces:\n\n    face = img[y:y+h, x:x+w]\n    face = cv2.resize(face, (224, 224))\n    face = img_to_array(face)\n    face = preprocess_input(face)\n    face = np.expand_dims(face, axis=0)\n    (mask, withoutMask) = model.predict(face)[0]\n    mask = mask*100\n    withoutMask = withoutMask*100\n    \n    font = cv2.FONT_HERSHEY_SIMPLEX\n    \n    # Getting Text Size in pixel\n    print(\"Image Width: \" , w)\n    textSize = cv2.getTextSize(text=\"No Mask: \" + str(\"%.2f\" % round(mask, 2)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=3)\n    print(\"Text Width: \" , textSize[0][0])\n    \n    if mask > withoutMask:\n        cv2.putText(img,\n                    text = \"Mask: \" + str(\"%.2f\" % round(mask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (2*w)\/textSize[0][0],\n                    color = (0, 255, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 5)\n    else:\n        cv2.putText(img,\n                    text = \"No Mask: \" + str(\"%.2f\" % round(withoutMask, 2)),\n                    org = (x-5,y-15),\n                    fontFace=font,\n                    fontScale = (1.8*w)\/textSize[0][0],\n                    color = (255, 0, 0),\n                    thickness = 3,\n                    lineType = cv2.LINE_AA)\n        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 5)\n\n# Display\nplt.imshow(img)\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)","6d87c64c":"# **Mask Detetction on Images**\n\n\n**INTRODUCTION**\n\nAirborne contamination is common when a person talks, sneezes, or coughs is transmitted by COVID, the COVID19 coronavirus. There has been heightened debate in recent weeks on the possible usage of face mask to aid in exiting lockout and preventing more surges in Covid-19 infections.\n\nFace mask is a mouth and nose covering made of polypropylene fiber or cotton cloth that is worn specifically to prevent the dissemination of infectious agents (such as viruses or bacteria)While this form of face covering has the potential to be critical in combating the infection, there are many myths on how they function.\n\n**PROBLEM**\n\nDue to the arising of Covid Cases in our country, the safety protocol is strictly implemented to reduce the aftermath of coronvirus. With this, face mask is highly required in going out in our own premises.\n\n**SOLUTION\/OBJECTIVES**\n\n* The detection of face mask is to maintain the orderliness and safety of a person, as such, a benefecial way to deteriorate the cases in our country.\n\n* By the use of detection of face shield or eyeglasses in a person who worned it and for those who don't can be a solution to give an alert or warning to the violators.\n\n* Create a model that will be able (detect\/predict\/classify) whether the person is wearing a face mask, it will recognize and classify. It will also classify whether the person is not wearing a mask.\n\n**Data**\n\n*Dataset*: Face-mask-12k-images-dataset(From Kaggle Dataset='..\/input\/face-mask-12k-images-dataset')\n         It includes Train, Test, and Validation Set of images that is classifies masks with or without wear.","15ee8b67":"# **References**\n\n* https:\/\/en.wikipedia.org\/wiki\/Computer_vision\n\n* http:\/\/szeliski.org\/Book\/\n\n* https:\/\/opencv-python-tutroals.readthedocs.io\/","53fa9903":"In Image Preprocessing, the images will undergo the process of cropping, resizing, masking, adjust contrast and brightness grayscale and Image Segmentation. We use cropping to clearly detect specific parts of an image. Resizing to rescale the image if the image is in need of rescaling to ease the analyzation of the image. Masking is needed to identify the the white masks. Image segmentation's role is to put boundaries in the face and the mask so we can simplify the image and we can efficiently analyze it. Grayscale is used to further amplify the color of the white mask.","18e23128":"# *Experiment 03*","6fd5db47":"Detecting Mask on images with mask ","d18739c8":"Detecting Mask on images without wearing mask","eaf91fda":"In Data Analysis, we were to check all the datasets that we have and check if it was all accessible. The Dataset has 5000 withmask images and 5000 without mask images. We will also divide an image into color pixels so that we can clearly analyze the texture of the image. And lastly, the image will undergo under different channels so that we can analyze its channel distributions.","98af443c":"# **Limitations**\n\n* Limited only on clear and has difficulties in recognizing low light photos.\n\n* It can't detect a 100% accuracy of the different images.\n\n* This project can be improved more.","1132f56a":"**Image Segmentation**","7afdede4":"# *Experiment 01*","75203e54":"# **METHODOLOGY**\n# Methods for Solution\n\n**I. Data Analysis**","d4c3a122":"# *Experiment 02*","a10a0968":"Detecting mask on images with multiple Faces (with or without wearing mask)","fb64a371":"**II. Image Preprocessing**","1426c0fb":"# **RESULT**","c0f2f055":"Load Dataset Images"}}