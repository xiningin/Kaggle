{"cell_type":{"86a78316":"code","19b06846":"code","4a3725b7":"code","daa1d80f":"code","86c48e9b":"code","1a1fcf48":"code","98845b37":"code","39370c83":"markdown","ec40505c":"markdown","42845cca":"markdown","5534df80":"markdown","3ea12d4b":"markdown","8bedb1da":"markdown","4b69dc4c":"markdown","cadc7fdc":"markdown"},"source":{"86a78316":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom sklearn import preprocessing, model_selection\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","19b06846":"train_split = 0.7\nEPOCHS = 13\ntrain_batch = 8\ntest_batch = 4\nlearning_rate = 0.001\nimage_size = 100\nclasses = ['Apple', 'Banana', 'Orange', 'Pineapple', 'Strawberry','Other']\nrate_gray = 0.2         # The rate of random images to be grayed by transformer\nrate_flip = 0.4         # The rate of random images to be horizontally fliped by transformer\n","4a3725b7":"class IMG_Dataset(Dataset):\n    def __init__(self,file_name):\n        # Import data\n        filedata = pd.read_csv(file_name)\n        \n        # Train \/ Test split\n        trainset,testset = model_selection.train_test_split(\n                                                        filedata,\n                                                        train_size = train_split,\n                                                        random_state=11)\n        # Separate features from labels\n        x_train = trainset.iloc[:,:-1].values\n        x_test = testset.iloc[:,:-1].values\n        train_labels = trainset.iloc[:,-1].values\n        test_labels = testset.iloc[:,-1].values\n        \n        # Preprocess data before entering into net\n        scaler = preprocessing.StandardScaler()\n        x_train = scaler.fit_transform(x_train)\n        x_test = scaler.fit_transform(x_test)\n        \n        # Utilizing TorchVision transforms on random images to improve learning\n        transformer = torchvision.transforms.Compose([\n                                          transforms.RandomGrayscale(rate_gray),\n                                          transforms.RandomHorizontalFlip(rate_flip)])\n        x_train = torch.from_numpy(x_train).long()\n        x_train = transformer(x_train)\n        \n        # Prepare 4 datasets for Net processes\n        self.X_train = torch.tensor(x_train,\n                        dtype=torch.float32).reshape(-1,1,image_size,image_size)\n        self.X_test = torch.tensor(x_test,\n                        dtype=torch.float32).reshape(-1,1,image_size,image_size)\n        self.train_labels = torch.tensor(train_labels)\n        self.test_labels = torch.tensor(test_labels)\n        \n     \n    def __len__(self):\n        return len(self.train_labels)\n        \n    def __getitem__(self,index):\n        return self.X_train[index],self.train_labels[index]","daa1d80f":"class Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel (G) of 100*100, 1 output channels\n        self.conv1 = nn.Conv2d(1, 1, 9)  #Conv. of 1*9*9 filter, 1 stride, 0 pads\n        self.conv2 = nn.Conv2d(1, 1, 15) #Conv. of 1*15*15 filter, 1 stride, 0 pads\n        self.fc1 = nn.Linear(16*16, 120)  #FC layer 16*16 to 120 nuerons\n        self.fc2 = nn.Linear(120, 84) #FC layer 120 to 84 nuerons\n        self.fc3 = nn.Linear(84, 6) # Output logits layer classes + 1 for noise\n        \n    def forward(self, x):\n        # input --> conv1-->tanh-->avg.Pool-->sigmoid-->conv2-->tanh-->avg.Pool\n        # -->sigmoid-->FC1-->tanh-->FC2-->tanh-->logits\n        # Average pooling over a (2, 2) window\n        x = F.sigmoid(F.max_pool2d(F.tanh(self.conv1(x)), (2, 2)))\n        x = F.sigmoid(F.max_pool2d(F.tanh(self.conv2(x)), 2))\n        x = x.view(-1, self.num_flat_features(x)) #Flatten features by batch\n        x = F.tanh(self.fc1(x))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x) \n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","86c48e9b":"def test_validation():    \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            org_data.X_test, org_data.test_labels = data\n            test_outputs = net(org_data.X_test)\n            _, predicted = torch.max(test_outputs.data, 1)\n            total += org_data.test_labels.size(0)\n            correct += (predicted == data[1]).sum().item()\n            if i % 60 == 59:\n                fig,ax = plt.subplots(1,test_batch)\n                plt.tight_layout(w_pad=2.0)\n                for img in range(len(data[1])):\n                    sample = torch.squeeze(data[0][img])\n                    label = data[1][img]\n                    ax[img].imshow(sample)\n                    ax[img].axis('off')\n                    ax[img].axes.get_xaxis().set_visible(False)\n                    ax[img].axes.get_yaxis().set_visible(False)\n                    ax[img].text(0,50,'{}'.format(classes[label]),color='white',fontweight='bold')\n                    ax[img].set_title('{}\/{}: Predicted:\\n{}'.format(i+1,img+1,classes[predicted[img]]))   \n                plt.show()\n                \n    print('% Accuracy of the network on test images:', round(100 * correct \/ total,2))","1a1fcf48":"if __name__ == '__main__':\n    \n    #Create Train \/ Test DataLoaders\n    org_data = IMG_Dataset('..\/input\/eyantrafruitsdataset\/dataset_attr.csv')\n    trainloader = DataLoader(org_data, batch_size=train_batch,\n                             shuffle=True, num_workers=4)\n    testloader = DataLoader(org_data, batch_size=test_batch,\n                            shuffle=False, num_workers=4)\n     \n    \n    #Call LeNet5 Network and declare Loss criteria and Optimizing Method\n    net = Net()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n    loss_history = []\n    accuracy_history = []\n    #Training Main loop\n    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n        running_loss = 0.0\n        total = 0\n        correct = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            # forward + backward + optimize\n            train_outputs = net(inputs)\n            _, predicted = torch.max(train_outputs.data, 1)\n            total = org_data.train_labels.size(0)\n            correct += (predicted == data[1]).sum().item()\n            loss = criterion(train_outputs, labels)\n            loss.backward()\n            optimizer.step()\n    \n            # print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:    # print every 10 mini-batches\n                print('[%d, %5d] loss: %.3f ' %\n                      (epoch + 1, i + 1, running_loss))\n        loss_history.append(running_loss)\n        accuracy = 100*correct\/total\n        accuracy_history.append(accuracy)\n        print('epoch',epoch+1,'completed with loss:',round(running_loss,3),' & accuracy[%]:',round(accuracy,2))\n    print('Finished Training')\n    \n    # Plot loss and accuracy progress during training phase\n    dx = range(EPOCHS)\n    headline1 = 'Cross-Entropy Loss w. Adam opt.(LR='+str(learning_rate)+')'\n    text1 = 'After '+str(EPOCHS)+' epochs, Loss is:'+str(round(loss_history[-1],3))\n    plt.plot(dx,loss_history,c='r',linewidth=4,label='Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(headline1)\n    plt.text(int(EPOCHS\/2),50,text1)\n    plt.show()\n    \n    headline2 = 'Accuracy w. Adam opt.(LR='+str(learning_rate)+')'\n    text2 = 'After '+str(EPOCHS)+' epochs, Accuracy is:'+str(round(accuracy_history[-1],2))\n    plt.plot(dx,accuracy_history,c='b',linewidth=4,label='Accuracy') \n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title(headline2)\n    plt.text(int(EPOCHS\/2),90,text2)\n    plt.show()","98845b37":"test_validation()","39370c83":"# Images Data Entry and Preparations","ec40505c":"# Main Program\n","42845cca":"# Test validation runs the net after train phase with trained weights using predefined test dataloader and presenting images with their labeled class vs. predicted class ","5534df80":"# Deep Learning net model based on LeNet5 model","3ea12d4b":"# Study Objectives\nThis Notebook is a classification study on eyantra fruits dataset utilizing PyTorch and based on LeNet5 model adjusted for\ndata structure a charachteristics (100x100, single channel).\nData is splitted into train \/ test and uploaded using 2 pre-defined dataloaders.\nThis is done in order to optimize batch size and running speed of 2 situations\n\nIn addition, I utilized Trochvision transformers on trainset images for improving learning process.\nEnjoy\n\nDeep Learning, LeNet5, Dataloader, PyTorch, Torchvision, Transform, Image Classification ","8bedb1da":"# Hyper Parameters","4b69dc4c":"# Run validation on test data","cadc7fdc":"# Importing Python libraries"}}