{"cell_type":{"c51bcee3":"code","711dd962":"code","b60bc84e":"code","107f84e2":"code","4109a744":"code","76cbe0a0":"code","641e46e2":"code","a802c0ee":"code","ee2c7c90":"code","ec2a8729":"code","6e10ca62":"code","a6b276a4":"code","29968abd":"code","3c09fe19":"code","f73efb29":"code","85a7991b":"code","7ac52345":"code","3c001c22":"code","6d877fcb":"code","1e3b7047":"code","22c18e20":"code","f289f0ce":"code","7b4a4661":"code","6ca7cbc1":"code","285e394e":"code","0eb1651b":"code","73cb479a":"code","fdeb0ce2":"code","8f9a18b8":"code","e9aa36b2":"code","b9104242":"code","72f0fde5":"code","75ce9019":"code","9d4ca888":"code","6eabf158":"code","89c91642":"code","e35ee773":"code","0829bf28":"code","6b2722e0":"code","923dd7d4":"code","701beb91":"code","0ac4320c":"code","a41fec98":"code","b4f65cb8":"code","23802cdf":"code","4193e840":"code","cc04458b":"code","fd061bbd":"code","98131bf7":"code","75e8822e":"code","13267c5b":"code","4e0bd10e":"code","2a810a94":"code","de6cdd89":"code","8cb7fc39":"code","664941e1":"code","d42e07d1":"code","d59bd6e5":"code","f00ea0e9":"code","ff692e2f":"code","59a983d0":"code","56eb1003":"code","9b5ba6ea":"code","1a2beb19":"code","e8787880":"code","7e53ef0e":"code","0503617b":"code","41777d7a":"code","790eff44":"code","f4d0669d":"code","debad6e3":"markdown","c86ebd42":"markdown","33fc23ab":"markdown","e50dc5fb":"markdown","b58ed1c0":"markdown","7c775cc8":"markdown","35a6411c":"markdown","99f13097":"markdown"},"source":{"c51bcee3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nlis = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        lis.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","711dd962":"import pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport PIL.Image as image\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\nfrom plotly.offline import iplot, plot, init_notebook_mode\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport tqdm\nimport warnings","b60bc84e":"TRAIN_IMGS = '\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/'\nTEST_IMGS = '\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/'","107f84e2":"warnings.filterwarnings('ignore')\ninit_notebook_mode('connected')\nplt.rcParams['figure.figsize'] = [12,6]\ntqdm.tqdm.pandas()","4109a744":"train_df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')","76cbe0a0":"train_df['label_names']=np.select(choicelist=[\"Cassava Bacterial Blight (CBB)\",\n                                              \"Cassava Brown Streak Disease (CBSD)\", \n                                              \"Cassava Green Mottle (CGM)\", \n                                              \"Cassava Mosaic Disease (CMD)\",\n                                              \"Healthy\"],\n                                 condlist=[train_df['label']==0,\n                                           train_df['label']==1,\n                                           train_df['label']==2,\n                                           train_df['label']==3,\n                                           train_df['label']==4])","641e46e2":"fig = plt.subplot(1, 2, 1).figure\n# fig.set_figheight(10)\n# fig.set_figwidth(25)\nsns.countplot('label_names', data = train_df)\nplt.title('Count of label names', fontdict={'size':20, 'color':'white'})\nplt.tick_params(labelrotation=90, labelsize = 15, axis = 'x')\nplt.tick_params(labelcolor='white', axis = 'y')\n\n\n# ax.set_figheight(10)\n\nplt.subplot(1, 2, 2)\nsns.countplot('label', data = train_df)\nplt.title('Count of label', fontdict = {'size':20, 'color':'white'})\nplt.tick_params(labelsize = 15, labelcolor='white', axis = 'x')","a802c0ee":"def display_images(label, rows=2, cols = 2, image = False):\n    images = train_df[train_df['label'] == label]['image_id'].sample(rows*cols).values\n    fig, ax = plt.subplots(nrows = rows, ncols = cols, figsize= (15, 10))\n    ax = ax.flatten()\n    for i in range(len(images)):\n        quick = cv2.imread(TRAIN_IMGS+images[i])\n        quick = cv2.cvtColor(quick, cv2.COLOR_BGR2RGB)\n        ax[i].imshow(quick)\n        ax[i].set_title(train_df[train_df['label']==label]['label_names'].head(1).values[0])","ee2c7c90":"display_images(0)","ec2a8729":"display_images(1)","6e10ca62":"display_images(2)","a6b276a4":"display_images(3)","29968abd":"display_images(4)","3c09fe19":"def color_channels(label):\n    img_details = train_df[train_df['label']==label].sample(1).values\n    quick = cv2.imread(TRAIN_IMGS+img_details[:, 0][0])\n    quick = cv2.cvtColor(quick, cv2.COLOR_BGR2RGB)\n    fig = make_subplots(1, 2)\n    red = go.Histogram({'x': cv2.calcHist(quick, [0], None, [255], [0, 255]).reshape(-1), 'text':'Red', 'marker':{'color':'red'}, 'name':'Red', 'xbins':{'size':1}})\n    green = go.Histogram({'x':cv2.calcHist(quick, [1], None, [255], [0, 255]).reshape(-1), 'text':'Green', 'marker':{'color':'green'}, 'name':'Green', 'xbins':{'size':1}})\n    blue = go.Histogram({'x':cv2.calcHist(quick, [2], None, [255], [0, 255]).reshape(-1), 'text':'Blue', 'marker':{'color':'blue'}, 'name':'Blue', 'xbins':{'size':1}})\n    fig.add_trace(red, row =1, col=2)\n    fig.add_trace(green, row= 1, col=2)\n    fig.add_trace(blue, row = 1, col=2)\n    fig.add_trace(go.Image({'name' : img_details[:, 2][0]}, z = quick ))\n    layout = {'title':'Color channel Histogram', 'barmode':'stack', 'template':'simple_white'}\n    fig.update_layout(layout)\n    # fig = go.Figure(data = data, layout=layout)\n    iplot(fig)","f73efb29":"color_channels(0)","85a7991b":"color_channels(1)","7ac52345":"color_channels(2)","3c001c22":"color_channels(3)","6d877fcb":"color_channels(4)","1e3b7047":"dat = train_df.head(1)\nquick = cv2.imread(TRAIN_IMGS+dat.values[:, 0][0])\nquick = cv2.cvtColor(quick, cv2.COLOR_BGR2RGB)\nfig = make_subplots(rows=2, cols = 2)\nfig2 = ff.create_distplot([quick[:, :, 0][0]], ['Red'], colors=['red'])\nfig3  = ff.create_distplot([quick[:, :, 1][0]], ['Green'], colors = ['green'])\nfig4 = ff.create_distplot([quick[:, :, 2][0]], ['Blue'], colors = ['blue'])\nfig.add_trace(go.Histogram(fig2['data'][0]), row = 1, col = 1)\nfig.add_trace(go.Scatter(fig2['data'][1]), row = 1, col = 1)\nfig.add_trace(go.Histogram(fig3['data'][0]), row=1, col = 2)\nfig.add_trace(go.Scatter(fig3['data'][1]), row = 1, col=2)\nfig.add_trace(go.Histogram(fig4['data'][0]), row = 2, col = 1)\nfig.add_trace(go.Scatter(fig4['data'][1]), row = 2, col = 1)\nlayout = dict(title = \"Distribution of Color channel values in %s.\" %dat.values[:, 0][0])\nfig.update_layout(layout)\nfig.show()","22c18e20":"# test=ImageDataGenerator(rescale=1\/255).flow_from_dataframe(train_df.head(100),\n#                                                            TRAIN_IMGS, x_col='image_id',\n#                                                            y_col = 'label', class_mode='raw',\n#                                                            shuffle=False, batch_size=100, target_size = (600, 800))\n# train_images = test[0][0]","f289f0ce":"def load_image(image_id):\n    image = cv2.imread(TRAIN_IMGS + image_id)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \ntrain_images = train_df[\"image_id\"][:100].progress_apply(load_image)","7b4a4661":"red_values = [np.mean(train_images[idx][:, :, 0]) for idx in range(len(train_images))]\ngreen_values = [np.mean(train_images[idx][:, :, 1]) for idx in range(len(train_images))]\nblue_values = [np.mean(train_images[idx][:, :, 2]) for idx in range(len(train_images))]\nvalues = [np.mean(train_images[idx]) for idx in range(len(train_images))]","6ca7cbc1":"fig = make_subplots(rows=2, cols = 2)\n# trace1 = dict(x = values,  = 'Channels', text = 'Channels', marker = dict(color='purple'))\nvals = ff.create_distplot([values], group_labels=['Channels'], colors=['purple'])\nreds  = ff.create_distplot([red_values], group_labels=['Red Values'], colors = ['red'])\ngreens = ff.create_distplot([green_values], group_labels=['Green Values'], colors = ['green'])\nblues = ff.create_distplot([blue_values], group_labels = ['Blue Values'], colors = ['blue'])\n\nfig.add_trace(vals['data'][0], row=1, col = 1)\nfig.add_trace(vals['data'][1], row = 1, col = 1)\nfig.add_trace(reds['data'][0], row = 1, col = 2)\nfig.add_trace(reds['data'][1], row = 1, col = 2)\nfig.add_trace(greens['data'][0], row=2, col = 1)\nfig.add_trace(greens['data'][1], row = 2, col = 1)\nfig.add_trace(blues['data'][0], row = 2, col= 2)\nfig.add_trace(blues['data'][1], row = 2, col = 2)\n\nfig.update_traces({'marker':{'line':{'width':0.3}}})","285e394e":"trace1 = dict(y = red_values, type = 'box', name = 'Red', marker = dict(color = 'red'), text = 'Red values')\ntrace2 = dict(y = green_values, type = 'box', name = 'Green', marker = dict(color = 'green'), text = 'Green values')\ntrace3 = dict(y = blue_values, type = 'box', name = 'Blue', marker = dict(color = 'blue'), text = 'Blue values')\nfig = go.Figure()\nfig.add_trace(trace1)\nfig.add_trace(trace2)\nfig.add_trace(trace3)\nlayout = dict(title = 'Color values box plot')\nfig.update_layout(layout)\n\niplot(fig)","0eb1651b":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[0])\nplt.title('Normal Image', fontdict={'size':30})\n\nkernel = np.ones((5, 5), dtype = np.float32)\/22\nimg = cv2.filter2D(train_images[0], -1,kernel)\nplt.subplot(1, 2, 2)\nplt.imshow(img)\nplt.title('Image blurred using filter2D with kernel', fontdict={'size':30})","73cb479a":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[99])\nplt.title('Normal Image', fontdict={'size':30})\n\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.blur(train_images[99], (5, 5)))\nplt.title('Image blurred using blur', fontdict = {'size':30})","fdeb0ce2":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[27])\nplt.title('Normal Image', fontdict={'size':30})\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.GaussianBlur(train_images[27], (5, 5), 10))\nplt.title('Image blurred using GaussianBlur', fontdict = {'size':30})","8f9a18b8":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.medianBlur(train_images[69], 5))\nplt.title('Image blurred using medianBlurr', fontdict = {'size':20})","e9aa36b2":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[20])\nplt.title('Normal Image', fontdict = {'size':20})\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.bilateralFilter(train_images[20], 11, 75, 75))\nplt.title('Image blurred using bilateralFilter');","b9104242":"sticker = cv2.resize(train_images[10], (250, 250))","72f0fde5":"plt.figure(figsize = (12, 5))\nplt.imshow(train_images[11])","75ce9019":"#Overlaying images of different sizes\ncopy = train_images[11].copy()\ncopy[350:, 550:] = sticker","9d4ca888":"plt.figure(figsize = (12, 6))\nplt.imshow(copy)","6eabf158":"#using addFilter\nprint(train_images[10].shape)\nprint(train_images[11].shape)\n\nplt.figure(figsize = (10, 6))\nplt.imshow(cv2.addWeighted(train_images[10], 0.6, train_images[11], 0.6, 0.3))","89c91642":"#Blending images of different sizes\nsticker = cv2.imread('\/kaggle\/input\/opencv-practice-zip\/computer-vision-with-python\/Computer-Vision-with-Python\/DATA\/watermark_no_copy.png')\nsticker = cv2.cvtColor(sticker, cv2.COLOR_BGR2RGB) \nplt.imshow(sticker)\nprint(sticker.shape)\n\nsticker = cv2.resize(sticker, (250, 250))","e35ee773":"#Blending images of different sizes\ngray_sticker = cv2.cvtColor(sticker, cv2.COLOR_RGB2GRAY)\nmask_inv = cv2.bitwise_not(gray_sticker)\nwhite_background = np.full(sticker.shape, 255, dtype=np.uint8)\nfg = cv2.bitwise_or(sticker, sticker, mask = mask_inv)\nroi = train_images[12][:250, :250]\ntrain_images[12][:250, :250]= cv2.bitwise_or(roi, fg)\n\nplt.figure(figsize=(12, 6))\nplt.imshow(train_images[12])","0829bf28":"#Gradiets\nsobel_x = cv2.Sobel(cv2.cvtColor(train_images[11], cv2.COLOR_RGB2GRAY), None, 1, 0, (7, 7))\nsobel_y = cv2.Sobel(cv2.cvtColor(train_images[11], cv2.COLOR_RGB2GRAY), None, 0, 1, (7, 7))","6b2722e0":"plt.figure(figsize = (10, 6))\nplt.imshow(cv2.addWeighted(sobel_x, 0.6, sobel_y, 0.6, 0.5), cmap = 'gray')","923dd7d4":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\n\nplt.subplot(1, 2, 2)\nret, thresh_img = cv2.threshold(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), 120, 255, cv2.THRESH_BINARY)\nplt.imshow(thresh_img, cmap = 'gray')\nplt.title('Thresholded image using THRESH_BINARY', fontdict = {'size':20})","701beb91":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\n\nplt.subplot(1, 2, 2)\nret, thresh_img = cv2.threshold(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), 120, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(thresh_img, cmap = 'gray')\nplt.title('Thresholded image using THRESH_BINARY_INV', fontdict = {'size':20})","0ac4320c":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\n\nplt.subplot(1, 2, 2)\nret, thresh_img = cv2.threshold(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), 120, 255, cv2.THRESH_TOZERO)\nplt.imshow(thresh_img, cmap = 'gray')\nplt.title('Thresholded image using THRESH_TOZERO', fontdict = {'size':20})","a41fec98":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\n\nplt.subplot(1, 2, 2)\nret, thresh_img = cv2.threshold(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), 120, 255, cv2.THRESH_TOZERO_INV)\nplt.imshow(thresh_img, cmap = 'gray')\nplt.title('Thresholded image using THRESH_TOZERO_INV', fontdict = {'size':20})","b4f65cb8":"fig = plt.subplot(1, 2, 1)\nfig.figure.set_figheight(30)\nfig.figure.set_figwidth(30)\nplt.imshow(train_images[69])\nplt.title('Normal Image', fontdict = {'size':20})\n\n\nplt.subplot(1, 2, 2)\nret, thresh_img = cv2.threshold(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), 120, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplt.imshow(thresh_img, cmap = 'gray')\nplt.title('Thresholded image using THRESH_TOZERO', fontdict = {'size':20})","23802cdf":"#Create a black Blank image\nblank_img = np.zeros((1080, 1920))\n#Add text ABCDE to blank image\ncv2.putText(blank_img, \"Daimond Hands\", (350, 600), cv2.FONT_HERSHEY_SIMPLEX,5, (255, 255, 255), 25, cv2.LINE_AA)\n\nplt.imshow(blank_img, cmap = 'gray')","4193e840":"#Erode foreground\nkernel = np.ones((5, 5), np.uint8)\nplt.imshow(cv2.erode(blank_img, kernel, iterations = 3), cmap = 'gray')","cc04458b":"#Remove White Noise\nwhite_noise = np.random.randint(0, 2, (1080, 1920))\nwhite_noise = white_noise*255\nimg = blank_img.copy()\nnoise_img = img + white_noise\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(noise_img, cmap = 'gray')\nplt.title('Noisy Image')\n\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.morphologyEx(noise_img.astype('uint8'), cv2.MORPH_OPEN, kernel), cmap = 'gray')\nplt.title('De-Noised Image')","fd061bbd":"black_noise = np.random.randint(0, 2, (1080, 1920))\nblack_noise = black_noise*-255\nnoise_img = img + black_noise\nnoise_img[noise_img==-255] = 0\n\nplt.subplot(1, 2, 1)\nplt.imshow(noise_img, cmap = 'gray')\nplt.title('Noisy image')\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.morphologyEx(noise_img, cv2.MORPH_CLOSE, kernel), cmap = 'gray')\nplt.title('De-Noised image');","98131bf7":"plt.subplot(1, 2, 1)\nplt.imshow(img, cmap = 'gray')\nplt.title('Noisy, image')\n\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel), cmap = 'gray')\nplt.title('Hollowed image')","75e8822e":"chess = cv2.imread('\/kaggle\/input\/opencv-practice-zip\/computer-vision-with-python\/Computer-Vision-with-Python\/DATA\/flat_chessboard.png')\nchess = cv2.cvtColor(chess, cv2.COLOR_BGR2RGB)\nplt.subplot(1, 2, 1)\nplt.imshow(chess)\n\nret, corners = cv2.findChessboardCorners(chess, (7, 7))\nplt.subplot(1, 2, 2)\ncopy = chess.copy()\nplt.imshow(cv2.drawChessboardCorners(copy, (7, 7), corners, ret));","13267c5b":"#Finding corners of corner harris algorithm\ndst = cv2.cornerHarris(cv2.cvtColor(train_images[12], cv2.COLOR_RGB2GRAY), 3, 3, 0.01)\n\ndst = cv2.dilate(dst, None)\ncopy = train_images[12].copy()\ncopy[dst>0.06*dst.max()] = [255, 0, 0]\n\nplt.imshow(copy);","4e0bd10e":"#Finding corners using corner harris algorithm\ndst = cv2.cornerHarris(cv2.cvtColor(chess, cv2.COLOR_RGB2GRAY), 3, 3, 0.1)\n\ndst = cv2.dilate(dst, None)\n\ncopy = chess.copy()\n\ncopy[dst>0.06*dst.max()] = [255, 0, 0]\n\nplt.imshow(copy);","2a810a94":"#Find corners using goodFeaturesToTrack(Shi Tomasi algorithm)\n\ncorners = cv2.goodFeaturesToTrack(cv2.cvtColor(chess, cv2.COLOR_RGB2GRAY), 50, 0.01, 4, 10, None)\n\ncorners = np.int0(corners)\ncopy = chess.copy()\nfor i in corners:\n    x, y = i.ravel()\n    cv2.circle(copy, (x, y), 3, 255, -1)\nplt.imshow(copy);","de6cdd89":"#Find corners using goodFeaturesToTrack(Shi Tomasi algorithm)\n\ncopy = train_images[42].copy()\ncorners = cv2.goodFeaturesToTrack(cv2.cvtColor(copy, cv2.COLOR_RGB2GRAY), 30, 0.06, 3)\n\ncorners = np.int0(corners)\n\nfor i in corners:\n    x, y = i.ravel()\n    cv2.circle(copy, (x, y), 10, 255, -1)\n    \nplt.imshow(copy)","8cb7fc39":"#Canny Edge detection\nfig = plt.subplot(1, 2, 1)\n# fig.figure.set_figheight(50)\n# fig.figure.set_figwidth(50)\nplt.imshow(train_images[0])\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.Canny(train_images[0], 100, 200), cmap= 'gray')","664941e1":"#Canny Edge detection after blurring\nfig = plt.subplot(1, 3, 1)\nfig.figure.set_figheight(20)\nfig.figure.set_figwidth(20)\nplt.imshow(train_images[0])\nplt.title('Normal image')\n\ncopy = train_images[0].copy()\n\nblurred = cv2.GaussianBlur(copy, (7, 7), 10)\nplt.subplot(1, 3, 2)\nplt.imshow(blurred)\nplt.title('Blurred image')\n\nplt.subplot(1, 3, 3)\nplt.imshow(cv2.Canny(blurred, 100, 200))\nplt.title('Edges after blurring')","d42e07d1":"#Grid detection\ndots = cv2.imread('\/kaggle\/input\/opencv-practice-zip\/computer-vision-with-python\/Computer-Vision-with-Python\/DATA\/dot_grid.png')\n# dots = cv2.cvtColor(dots, cv2.COLOR_BGR2RGB)\nplt.imshow(dots)","d59bd6e5":"#Grid detection\nret, corners = cv2.findCirclesGrid(dots, (10, 10), cv2.CALIB_CB_SYMMETRIC_GRID)\ncopy = dots.copy()\nplt.imshow(cv2.drawChessboardCorners(copy, (10, 10), corners, ret))","f00ea0e9":"#Contour detection using findContours\nimg = cv2.imread('\/kaggle\/input\/opencv-practice-zip\/Computer-Vision-with-Python\/DATA\/internal_external.png', 0)\nplt.imshow(img, cmap = 'gray')","ff692e2f":"#External Contours\ncontours, hierarchy = cv2.findContours(img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n\nexternal_countours = np.zeros(img.shape)\n\nfor i in range(len(contours)):\n    if hierarchy[0][i][3] == -1:\n        cv2.drawContours(external_countours, contours, i, 255, 5)\n        \nplt.imshow(external_countours, cmap = 'gray')","59a983d0":"#Internal Contours\ninternal_contours = np.zeros(img.shape)\nfor i in range(len(contours)):\n    if hierarchy[0][i][3] != -1:\n        cv2.drawContours(internal_contours, contours, i, 255, -1)\n        \nplt.imshow(internal_contours, cmap= 'gray')","56eb1003":"contours, hierarchy = cv2.findContours(cv2.cvtColor(train_images[69], cv2.COLOR_RGB2GRAY), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n\nexternal_countours = np.zeros(train_images[69].shape)\n\nfor i in range(len(contours)):\n    if hierarchy[0][i][3] == -1:\n        cv2.drawContours(external_countours, contours, i, 255, 5)\n        \nplt.imshow(external_countours)","9b5ba6ea":"img1 = train_images[10]\nimg2 = train_images[14]","1a2beb19":"plt.imshow(img1)","e8787880":"plt.imshow(img2)","7e53ef0e":"#Brute Force detection with ORB descreptors\norb = cv2.ORB_create()\n\nkp1, des1 = orb.detectAndCompute(img1, None)\nkp2, des2 = orb.detectAndCompute(img2, None)\n\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n\nmatches = bf.match(des1, des2)\n\nmatches = sorted(matches , key = lambda x:x.distance)\n\nimg1_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags = 2)","0503617b":"plt.imshow(img1_matches)\nplt.title('ORB feature detection')","41777d7a":"#Brute Force detection with SIFT Descriptors and Ratio Test\nsift = cv2.SIFT_create()\n\nkp1, des1 = sift.detectAndCompute(img1, None)\nkp2, des2 = sift.detectAndCompute(img2, None)\n\nbf = cv2.BFMatcher()\n\nmatches = bf.knnMatch(des1, des2, k = 2)\n\ngood = []\n\nfor match1, match2 in matches:\n    if match1.distance < 0.75*match2.distance:\n        good.append([match1])\nsift_matches = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, flags=2)","790eff44":"plt.imshow(sift_matches)\nplt.title('SIFT Descriptors')","f4d0669d":"sift = cv2.SIFT_create()\n\nkp1, des1 = sift.detectAndCompute(img1, None)\nkp2, des2 = sift.detectAndCompute(img2, None)\n\nFLANN_INDEX_KDTREE = 0\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks = 50)\n\nflann = cv2.FlannBasedMatcher(index_params, search_params)\n\nmatches = flann.knnMatch(des1, des2, k = 2)\n\ngood = []\n\nfor i, (match1, match2) in enumerate(matches):\n    if match1.distance < 0.7* match2.distance:\n        good.append(match1)\n    \nflann_matches = cv2.drawMatches(img1, kp1, img2, kp2, good, None, flags=2)\n\nplt.imshow(flann_matches)","debad6e3":"# Blending","c86ebd42":"# Thresholding","33fc23ab":"# Morphology","e50dc5fb":"# Feature Matching","b58ed1c0":"# Corner Detection","7c775cc8":"# Edge Detection","35a6411c":"# Contour detection","99f13097":"# Blurring"}}