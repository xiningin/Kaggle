{"cell_type":{"c0d8eb1d":"code","a2b1ff00":"code","f8a6a037":"code","16ddabbe":"code","1b994a1b":"code","ec0c4406":"code","8cfa06e9":"code","d324fcd8":"code","08b31222":"code","89ddd4cc":"code","0e933090":"code","3830e17d":"code","f9493576":"code","7d768f35":"code","84402f93":"code","822b2a07":"markdown","fb12120f":"markdown","bf87de34":"markdown","66e73ee7":"markdown","9a7317c6":"markdown"},"source":{"c0d8eb1d":"import numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport warnings\nwarnings.filterwarnings('ignore')","a2b1ff00":"PATH = '\/kaggle\/input\/animals10\/raw-img\/'\nCATEGORIES = os.listdir(PATH)\nNUM_CLASSES = len(CATEGORIES)","f8a6a037":"SIZE = 128\nBATCH_SIZE = 32\nEPOCHS = 10","16ddabbe":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)","1b994a1b":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(CATEGORIES[np.argmax(labels[i])])\n        plt.axis(\"off\")","ec0c4406":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","8cfa06e9":"from tensorflow.keras.applications.resnet import ResNet101\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n\n# = = = = = ResNet101 CNN Model = = = = =\n\nbase_model = ResNet101(weights='imagenet', include_top=False)\nbase_model.trainable = False\n\n# = = = = = TOP NN Model = = = = =\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.1)(x)\n\n# = = = = = Coupling = = = = =\n\npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\n# = = = = = Complete Model = = = = =\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)\n#model.summary()","d324fcd8":"history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)","08b31222":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nxepochs = [x for x in range (len(history.history['loss']))]\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy over time\", \"Loss over time\"))\n\nfor metric in ['accuracy', 'val_accuracy']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=1)\n\nfor metric in ['loss', 'val_loss']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=2)\n\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\nfig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n\nfig.show()","89ddd4cc":"val_samples = sum([y.shape[0] for [_, y] in val_ds])\nval_samples","0e933090":"y_val = []\ny_val_pred = []\n\nfor images, targets in val_ds:\n    for image, target in zip(images, targets):\n        img_array = image.numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        y_val_pred.append(np.argmax(prediction))\n        y_val.append(np.argmax(target))","3830e17d":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val, y_val_pred)","f9493576":"import plotly.express as px\n\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"Real\"),\n    x=CATEGORIES,\n    y=CATEGORIES\n)\n\nfig.update_xaxes(side=\"top\")\nfig.show()","7d768f35":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_val, y_val_pred, target_names=CATEGORIES))","84402f93":"plt.figure(figsize=(20, 10))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        prediction_name = CATEGORIES[np.argmax(prediction)]\n        real_name = CATEGORIES[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})\n        \n        plt.axis(\"off\")","822b2a07":"# Dati","fb12120f":"# Addestramento","bf87de34":"# Transfer Learning","66e73ee7":"# Visualizziamo alcune immagini","9a7317c6":"# Matrice di confusione"}}