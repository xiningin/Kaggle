{"cell_type":{"220ea4cd":"code","81116748":"code","0abc4265":"code","9bf8a0bb":"code","130fbfd5":"code","e145ca3e":"code","e9fd132e":"code","ecdb6ece":"code","d8e75e56":"code","dd4a9c30":"code","c7adfa2f":"code","9f3fff07":"code","ddcb9c5d":"code","f131e6f7":"code","1a68ba38":"code","6b6fc684":"code","cb06275a":"code","591f51a6":"code","e3c608dc":"code","39fa8a66":"code","0388f4c9":"code","367a0244":"code","eb1cb9fc":"code","9d06fe91":"code","6b4c4650":"code","ac70c0e2":"code","594bd2e6":"code","e17f3394":"code","5f15e9bb":"code","67edf692":"code","81cf0588":"markdown","87219513":"markdown","2e5a4993":"markdown","b92771b9":"markdown","1d5584f5":"markdown","35631793":"markdown","b5884d21":"markdown","500a45df":"markdown","cd7f31e1":"markdown"},"source":{"220ea4cd":"import numpy as np \nimport pandas as pd \nimport os \nimport sys \nimport torch\nimport torchvision","81116748":"fish_categories = []\npath = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\nfor directory in os.listdir(path):\n    if '.' not in directory:\n        fish_categories.append(directory)\n        \nprint(fish_categories)","0abc4265":"image_directory = {}\nfor i in fish_categories:\n    image_directory[i] = [os.path.join(path,i,i,j) for j in  os.listdir(os.path.join(path,i,i))]","9bf8a0bb":"file_category = []\nfile_name = []\nfor i in image_directory.keys():\n    for j in image_directory[i]:\n        file_category.append(i)\n        file_name.append(j)","130fbfd5":"data = {'categories':file_category,'file_name':file_name}","e145ca3e":"image_df = pd.DataFrame(data)\nimage_df.head()","e9fd132e":"import PIL\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader, Dataset","ecdb6ece":"import matplotlib.pyplot as plt\n\nx = image_df.sample()\nrandom_category = x.categories.values[0]\nrandom_file_name = x.file_name.values[0]\nprint(random_category)\nprint(random_file_name)\nimg = PIL.Image.open(random_file_name)\nplt.imshow(img)\nplt.title(random_category)\n","d8e75e56":"img_array = np.array(img)\nprint(img_array.shape)\nimg_array_transposed = np.transpose(img_array,(2,0,1))\nprint(img_array_transposed.shape)","dd4a9c30":"str_to_int = {}\nfor i in range(len(fish_categories)):\n    str_to_int[fish_categories[i]]=i\n    \nprint(str_to_int)","c7adfa2f":"int_to_str = dict([(value, key) for key, value in str_to_int.items()])\nprint(int_to_str)","9f3fff07":"transform = T.Compose([T.Resize(256),T.CenterCrop(224),T.Resize(64),T.ToTensor(),T.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])])","ddcb9c5d":"class FishDataset(Dataset):\n    def __init__(self,data,path,transform=None):\n        self.data = data\n        self.path = path\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        image_path = self.data.file_name[idx]\n        image = PIL.Image.open(image_path)\n        category_name = self.data.categories[idx]\n        label = str_to_int[category_name]\n        if self.transform:\n            image = self.transform(image)\n            \n        \n#         image = torch.Tensor(np.transpose(np.array(image),(2,0,1)))\n        return image,label\n        ","f131e6f7":"dataset = FishDataset(data=image_df,path=path,transform=transform)","1a68ba38":"img, lab = dataset[34]\nprint(img.shape)\nplt.imshow(img.numpy().transpose((2,1,0)))\nplt.title(fish_categories[int(lab)])\nplt.axis('off')\nplt.show()","6b6fc684":"train_data,test_data = torch.utils.data.random_split(dataset,[7000,2000])\nvalid_data,test_data = torch.utils.data.random_split(test_data,[1000,1000])","cb06275a":"trainloader = DataLoader(train_data,batch_size=64,shuffle=True)\nvalidloader = DataLoader(valid_data,batch_size=64,shuffle=False)\ntestloader = DataLoader(test_data,batch_size=1,shuffle=False)","591f51a6":"import torch.nn as nn\nimport torch.nn.functional as F","e3c608dc":"cuda_available = torch.cuda.is_available()\n\nif cuda_available:\n    print('True')\nelse:\n    print('False')","39fa8a66":"print(len(fish_categories))","0388f4c9":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1 = nn.Conv2d(3,16,3)\n        self.conv2 = nn.Conv2d(16,32,3)\n        self.conv3 = nn.Conv2d(32,64,3)\n        self.pool = nn.MaxPool2d(2,2)\n        self.dropout = nn.Dropout(0.25)\n        self.fc1 = nn.Linear(64*6*6,500)\n        self.fc2 = nn.Linear(500,9)\n    \n    def forward(self,x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1,64*6*6)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x","367a0244":"model =  Net()\nprint(model)","eb1cb9fc":"if cuda_available:\n    model.cuda()","9d06fe91":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)","6b4c4650":"n_epochs = 15\nvalid_loss_min = np.Inf\n\nfor epoch in range(1,n_epochs+1):\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    model.train()\n    \n    for data,target in trainloader:\n        if cuda_available:\n            data,target = data.cuda(),target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output,target)\n        loss.backward()\n        optimizer.step()\n        train_loss+=loss.item()*data.size(0)\n    \n    model.eval()\n    \n    for data,target in validloader:\n        if cuda_available:\n            data,target = data.cuda(),target.cuda()\n        output = model(data)\n        loss = criterion(output,target)\n        valid_loss+=loss.item()*data.size(0)\n        \n    train_loss = train_loss\/len(trainloader.sampler)\n    valid_loss = valid_loss\/len(validloader.sampler)\n    \n    print('Epoch: {} , Training Loss: {:.6f}, Validation Loss: {:.6f}'.format(epoch,train_loss,valid_loss))\n    \n    if valid_loss<=valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_fish.pt')\n        valid_loss_min = valid_loss\n        ","ac70c0e2":"model.load_state_dict(torch.load('model_fish.pt'))","594bd2e6":"test_loss = 0.0 \ny_pred = []\ny_label = []\nmodel.eval()\nfor data,target in testloader:\n    if cuda_available:\n        data,target = data.cuda(),target.cuda()\n    output = model(data)\n    loss = criterion(output,target)\n    _,pred = torch.max(output,dim=1)\n    pred = pred.cpu().item()\n    y_pred.append(pred)\n    y_label.append(target.cpu().item())\n    test_loss+=loss.item()*data.size(0)\n    \ntest_loss = test_loss\/len(testloader.sampler)\nprint('Test loss : {:.6f}'.format(test_loss))\n    \n    ","e17f3394":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score","5f15e9bb":"accuracy = accuracy_score(y_label,y_pred)\nprint('Accuracy : {:.3f} %'.format(accuracy*100))","67edf692":"import seaborn as sns\nfig = plt.figure(figsize=(10,10))\ncm = confusion_matrix(y_label,y_pred)\nax=sns.heatmap(cm,fmt=' ',annot=True,cmap='Blues')\nax.invert_yaxis()\nax.set_xticklabels(fish_categories,rotation=90)\nax.set_yticklabels(fish_categories,rotation=0)\nax.set_xlabel('Actual Category')\nax.set_ylabel('Predicted Category')\nax.set_title('Actual Vs Predicted Category')\nplt.show()","81cf0588":"# Importing the dataset","87219513":"## Loading the saved state","2e5a4993":"# Metrics and Evaluation","b92771b9":"# Building the Neural Network","1d5584f5":"## Accuracy","35631793":"# Training and Testing the Model","b5884d21":"# Building the Dataset Class","500a45df":"## Calculating test loss","cd7f31e1":"## Confusion Matrix"}}