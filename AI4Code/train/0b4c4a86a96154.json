{"cell_type":{"a249ecf7":"code","6d42eec6":"code","904a8151":"code","77e80e1d":"code","1a022bdf":"code","a056f28d":"code","348f64c1":"code","e4470e5f":"code","eeaa18af":"code","6d40750b":"code","f8f98aeb":"code","3b53d586":"code","6ae1247f":"code","1c44f237":"code","06206d2f":"code","ba96cdde":"code","b9c93f46":"markdown","8604dd27":"markdown","ce578744":"markdown","d3ea20c0":"markdown","b5621ade":"markdown","e5081141":"markdown","97271ff6":"markdown","b5a11692":"markdown","2b3065cd":"markdown","9623ff88":"markdown","d433cabe":"markdown"},"source":{"a249ecf7":"# imports\n\nfrom keras.applications import vgg16\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.models import Model\nfrom keras.applications.imagenet_utils import preprocess_input\n\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pandas as pd","6d42eec6":"# parameters setup\n\nimgs_path = \"..\/input\/style\/\"\nimgs_model_width, imgs_model_height = 224, 224\n\nnb_closest_images = 5 # number of most similar images to retrieve","904a8151":"# load the model\nvgg_model = vgg16.VGG16(weights='imagenet')\n\n# remove the last layers in order to get features instead of predictions\nfeat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(\"fc2\").output)\n\n# print the layers of the CNN\nfeat_extractor.summary()","77e80e1d":"files = [imgs_path + x for x in os.listdir(imgs_path) if \"png\" in x]\n\nprint(\"number of images:\",len(files))","1a022bdf":"# load an image in PIL format\noriginal = load_img(files[0], target_size=(imgs_model_width, imgs_model_height))\nplt.imshow(original)\nplt.show()\nprint(\"image loaded successfully!\")","a056f28d":"# convert the PIL image to a numpy array\n# in PIL - image is in (width, height, channel)\n# in Numpy - image is in (height, width, channel)\nnumpy_image = img_to_array(original)\n\n# convert the image \/ images into batch format\n# expand_dims will add an extra dimension to the data at a particular axis\n# we want the input matrix to the network to be of the form (batchsize, height, width, channels)\n# thus we add the extra dimension to the axis 0.\nimage_batch = np.expand_dims(numpy_image, axis=0)\nprint('image batch size', image_batch.shape)\n\n# prepare the image for the VGG model\nprocessed_image = preprocess_input(image_batch.copy())","348f64c1":"# get the extracted features\nimg_features = feat_extractor.predict(processed_image)\n\nprint(\"features successfully extracted!\")\nprint(\"number of image features:\",img_features.size)\nimg_features","e4470e5f":"# load all the images and prepare them for feeding into the CNN\n\nimportedImages = []\n\nfor f in files:\n    filename = f\n    original = load_img(filename, target_size=(224, 224))\n    numpy_image = img_to_array(original)\n    image_batch = np.expand_dims(numpy_image, axis=0)\n    \n    importedImages.append(image_batch)\n    \nimages = np.vstack(importedImages)\n\nprocessed_imgs = preprocess_input(images.copy())\n","eeaa18af":"# extract the images features\n\nimgs_features = feat_extractor.predict(processed_imgs)\n\nprint(\"features successfully extracted!\")\nimgs_features.shape","6d40750b":"# compute cosine similarities between images\n\ncosSimilarities = cosine_similarity(imgs_features)\n\n# store the results into a pandas dataframe\n\ncos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)\n# len(cos_similarities_df.columns)\ncos_similarities_df.head()","f8f98aeb":"# function to retrieve the most similar products for a given one\n\ndef retrieve_most_similar_products(given_img):\n\n    plt.title(\"Original product\",color='b')\n    original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))\n    plt.imshow(original)\n    plt.show()\n\n    #print(\"-----------------------------------------------------------------------\")\n    #print(\"most similar products:\")\n\n    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index\n    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]\n\n    for i in range(0,len(closest_imgs)):\n        original = load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))\n        plt.title(\"similarity score :\"+str(closest_imgs_scores[i]), color='b')\n        plt.imshow(original)\n        plt.show()","3b53d586":"retrieve_most_similar_products(files[1])","6ae1247f":"retrieve_most_similar_products(files[2])","1c44f237":"retrieve_most_similar_products(files[3])","06206d2f":"retrieve_most_similar_products(files[4])","ba96cdde":"retrieve_most_similar_products(files[5])","b9c93f46":"# 5. compute cosine similarities\n\nNow that we have features for every image, we can compute similarity metrics between every image couple.\n\nWe will use here the cosine similarity metric.","8604dd27":"## 4. feed all the images into the CNN\n\nWe were able to do the feature extraction process for one image. Now let's do it for all our images!","ce578744":"![](https:\/\/images4.programmersought.com\/992\/d8\/d83e5a1f963df52826e8592241dc8358.png)","d3ea20c0":"# Conclusi\u00f3nes\n* El sistema de recomendaci\u00f3n (muy b\u00e1sico) es capaz de encontrar productos similares con cierta precisi\u00f3n\n* La mayor\u00eda de las veces los productos recuperados tienen el mismo prop\u00f3sito e incluso tienen un aspecto muy similar\n* Ser\u00eda interesante implementarlo con Flask o Streamlit\n* Quiz\u00e1s ser\u00eda interesante considerar m\u00e1s modelos preentrenados o cortar en capas m\u00e1s tempranas\n","b5621ade":"# 6. retrieve most similar products\n\nThe final step is to implement a function that, for any given product, returns the visually most similar products.","e5081141":"## 1. load the VGG pre-trained model from Keras\n\nKeras module contains several pre-trained models that can be loaded very easily. \n\nFor our recommender system based on visual similarity, we need to load a Convolutional Neural Network (CNN) that will be able to interpret the image contents.\n\nIn this example we will load the VGG16 model trained on imagenet, a big labeled images database.\n\nIf we take the whole model, we will get an output containing probabilities to belong to certain classes, but that is not what we want.\n\nWe want to retrieve all the information that the model was able to get in the images.\n\nIn order to do so, we have to remove the last layers of the CNN which are only used for classes predictions.","97271ff6":"## Deep learning vs machine learning\n\n\n![](https:\/\/image.slidesharecdn.com\/abelbrownnvidiarakuten2016-170208065814\/95\/introduction-to-deep-learning-nvidia-7-638.jpg)\n![](https:\/\/i2.wp.com\/semiengineering.com\/wp-content\/uploads\/2018\/01\/MLvsDL.png)\n\n## Composici\u00f3n de una imagen\n\n![](https:\/\/image.slidesharecdn.com\/acmerobotics-techtonictuesdaypresentation-180309202010\/95\/robotics-visionaided-navigation-and-motion-path-planning-on-lowend-android-hardware-10-638.jpg)\n\n## Composici\u00f3n CNN base\n\n![](http:\/\/www.bangkokmedjournal.com\/storage\/BKKMEDJ-15-1\/15-1-1\/15-1-1-F1.jpg)\n\n\n* (Input) Capa de entrada (input)\n* (Filtros) N-Capas extractoras de caracter\u00edsticas \n* (Aprendizaje) Capas de aprendizaje \n* (Classificador) Capa de clasificaci\u00f3n\n\n## Transfer learning\n\n\n![](http:\/\/miro.medium.com\/max\/1000\/1*LUFUl_8fqS97nUzpcFjgWw.png)\n\n\n* Partir de un modelo CNN previamente entrenado sobre un dominio \n* CORTAR el modelo entrenado por las capas de aprendizaje\n* (1) Anexar nuevas capas de aprendizaje y volver entrenar, o (2) extraer caracteristicas de cada imagen\n\n\n## Calcular similitudes\n* Calcularemos similitudes entre los diferentes productos utilizando las caracter\u00edsticas de cada imagen extra\u00edda anteriormente.\n* Se podr\u00eda considerar informaci\u00f3n adicional como: la categor\u00eda del producto, el tama\u00f1o, el color, etc. ","b5a11692":"## 3. feed one image into the CNN\n\nFirst we observe what output we get when putting one image into the CNN.\n\nThe following steps are:\n- loading the image\n- preparing the image to feed it into the CNN\n- get the CNN output which will correspond to the image features","2b3065cd":"\n# IDEA: Sistema de recomendaci\u00f3n basado en similitud visual\n\nEl objetivo de este experimento es crear un sistema de recomendaci\u00f3n muy b\u00e1sico: \n- (1) para un producto de moda dado\n- (2) queremos recomendar productos que se vean similares\n\nEste tipo de sistema de recomendaci\u00f3n se utiliza a menudo al navegar por sitios web de compras. Por lo general, aparecen en las p\u00e1ginas de productos como una secci\u00f3n de **\"tambi\u00e9n te puede gustar\"**. \n\nIDEA: Si un cliente muestra inter\u00e9s por un producto al navegar por su p\u00e1gina, tambi\u00e9n puede estar interesado en productos similares.","9623ff88":"## 0. imports and parameters setup","d433cabe":"## 2. get the images paths"}}