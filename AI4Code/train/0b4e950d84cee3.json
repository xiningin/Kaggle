{"cell_type":{"02e9d678":"code","4605e747":"code","e9406d9d":"code","0e179669":"code","5d846a66":"code","e58575cd":"code","1abb6075":"code","85f86338":"code","d911a05c":"code","bb87e980":"code","2d5c3e61":"code","79724bc6":"code","05fea873":"code","1b73e111":"code","e6337805":"code","03c86d15":"code","b32d71f7":"code","6868a94d":"code","2d13aee3":"code","357340d6":"code","77ca7b9e":"code","ff11eb20":"code","27c8a747":"code","3462e52a":"code","dfa8c1ce":"code","0eb1e75b":"code","7e6e7f53":"code","33df4a98":"code","7dfaa516":"code","78ef1eba":"code","6b3e15fe":"code","3eb88e27":"code","6269cdab":"code","79e168a6":"code","e7e10f2f":"code","4e4c0651":"code","4d96ea68":"code","acb46ede":"code","4e13ab2a":"code","305169c3":"code","c3760336":"code","3c31fc7c":"code","eefd7c21":"code","3dee5ac8":"code","7f9cafb7":"code","91b994c1":"code","a853631c":"code","cfb1b798":"code","0f3d5d97":"code","d562b3d5":"code","70a2dec3":"code","89fa667e":"code","7e975b27":"code","2e74def9":"code","5213c7d1":"code","4adf9373":"code","bd24e7d6":"code","59ac41cc":"code","3d8430a6":"code","3e3411d1":"code","735d33ee":"code","61114f57":"code","a4837779":"code","6f0e5b53":"code","4c57eabc":"code","70fecf77":"code","593da0b6":"code","b3bbaf19":"code","868effc9":"code","e6188623":"code","d39c7f5c":"code","ef147912":"code","7a8086da":"code","ce5a1f98":"code","3c5a264f":"code","9dd28296":"code","778d528c":"markdown","e532238e":"markdown","446b42fa":"markdown","a9ed8396":"markdown","ea70ec1a":"markdown","b58f7610":"markdown","80f5b487":"markdown","3338928c":"markdown","5cd1acba":"markdown","aaf5aa92":"markdown","e3501251":"markdown","c5c0306a":"markdown","13bf7367":"markdown","98d6369c":"markdown","be6865f3":"markdown","77feed56":"markdown","be525f31":"markdown","00f28fc7":"markdown","dd9203eb":"markdown","41e5c5e8":"markdown","4254113e":"markdown","9abef2aa":"markdown","cfbf20ff":"markdown","7f8973c2":"markdown","92c7e314":"markdown","b28e821b":"markdown","adebcc87":"markdown","08714110":"markdown","a2ca6fb4":"markdown","e4389719":"markdown","102fd611":"markdown","4ef77a2f":"markdown","a597f9ec":"markdown","8295e68b":"markdown","d39fc6ed":"markdown","c3342a05":"markdown","8b87fc02":"markdown","9eb00b9e":"markdown","367156c7":"markdown","d6526c69":"markdown","15823bdd":"markdown","c102adc4":"markdown","7c28e048":"markdown","75588a78":"markdown","73d8e66c":"markdown","d0ea1f95":"markdown","6a3a21d9":"markdown","4e7966b8":"markdown","a8c94aca":"markdown","b6df5d0c":"markdown","396ab3f1":"markdown"},"source":{"02e9d678":"#import the required libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import RFE\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","4605e747":"# read the data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nbike_data = pd.read_csv('\/kaggle\/input\/boombikes\/day.csv', parse_dates=['dteday'])","e9406d9d":"# Top 5 rows\nbike_data.head()","0e179669":"# Bottom 5 rows\nbike_data.tail()","5d846a66":"# Dataframe shape\nbike_data.shape","e58575cd":"# Checking data type and null values\nbike_data.info()","1abb6075":"# Summary for numerical variables\nbike_data.describe()","85f86338":"# verify the null records\nbike_data.isnull().sum()","d911a05c":"print('No of rows before drop duplicates:',bike_data.shape[0])\nbike_data.drop_duplicates(subset=None, inplace=True)\nprint('No of rows after drop duplicates:',bike_data.shape[0])","bb87e980":"# Season Variable\nbike_data.season.value_counts()","2d5c3e61":"# Convert season data in categorical values (1:spring, 2:summer, 3:fall, 4:winter)\nbike_data.season = bike_data.season.map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\nbike_data.season.value_counts(normalize=True)","79724bc6":"# year variable\nbike_data.yr.value_counts()","05fea873":"# Month variable\nbike_data.mnth.value_counts()","1b73e111":"# Convert month data in categorical values\nbike_data.mnth = bike_data.mnth.map({\n    1:'Jan', \n    2:'Feb', \n    3:'Mar', \n    4:'Apr',\n    5:'May',\n    6:'Jun',\n    7:'Jul',\n    8:'Aug',\n    9:'Sep',\n    10:'Oct',\n    11:'Nov',\n    12:'Dec'})\nbike_data.mnth.value_counts(normalize=True)","e6337805":"# holiday variable\nbike_data.holiday.value_counts()","03c86d15":"# Weekday variable\nbike_data.weekday.value_counts()","b32d71f7":"bike_data.weekday = bike_data.weekday.map({\n    0:'Sun',\n    1:'Mon',\n    2:'Tue',\n    3:'Wed',\n    4:'Thu',\n    5:'Fri',\n    6:'Sat'\n})\nbike_data.weekday.value_counts()","6868a94d":"bike_data.workingday.value_counts()","2d13aee3":"bike_data.weathersit.value_counts()","357340d6":"#Converting data as\n#\t\t 1: Clear, Few clouds, Partly cloudy, Partly cloudy ---> Clear\n#\t\t 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist ---> Cloudy\n#\t\t 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds ---> LightRain\n#\t\t 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog ---> Thunderstorm\n\nbike_data.weathersit = bike_data.weathersit.map({1:'Clear',2:'Cloudy',3:'LightRain',4:'Thunderstorm'})\nbike_data.weathersit.value_counts(normalize=True)","77ca7b9e":"# Verify dataframe post encoding\nbike_data.info()","ff11eb20":"# As yr, holiday and workingday are categorical variable, therefore converting the datatype to categorical\nbike_data.yr = bike_data.yr.astype('category')\nbike_data.holiday = bike_data.holiday.astype('category')\nbike_data.workingday = bike_data.workingday.astype('category')\nbike_data.info()","27c8a747":"# Numerical columns for EDA\nnumerical_columns = bike_data.select_dtypes(include=['int64','float64']).columns\n\n# categorical columns for EDA\ncategorical_columns = bike_data.select_dtypes(exclude=['int64','float64','datetime64']).columns","3462e52a":"# Distribution plot for numerical columns\nplt.figure(figsize=(20,10))\n\nfor i in range(len(numerical_columns)):\n    plt.subplot(2,4,i+1)\n    sns.distplot(bike_data[numerical_columns[i]])\n\nplt.show()","dfa8c1ce":"# Box plot for numerical variables\nplt.figure(figsize=(20,10))\n\nfor i in range(len(numerical_columns)):\n    plt.subplot(2,4,i+1)\n    sns.boxplot(bike_data[numerical_columns[i]], orient='h')\n\nplt.show()","0eb1e75b":"# We will handle outliers through 1.5*iqr method\n\nb_rows = bike_data.shape[0]\n\nfor i in ['hum','windspeed'] :\n    q75,q25 = np.percentile(bike_data.loc[:,i],[75,25])\n    iqr = q75-q25\n    \n    min = q25 - (iqr*1.5)\n    max = q75 + (iqr*1.5)\n    \n    bike_data = bike_data.drop(bike_data[bike_data.loc[:,i] < min].index)\n    bike_data = bike_data.drop(bike_data[bike_data.loc[:,i] > max].index)\na_rows = bike_data.shape[0]\n\nprint('percent reduction in data after deleting outliers:',(b_rows-a_rows)\/b_rows*100)","7e6e7f53":"# Categorical data analysis\nplt.figure(figsize=(20,15))\n\nfor i in range(len(categorical_columns)):\n    plt.subplot(3,3,i+1)\n    sns.boxplot(x=categorical_columns[i], y='cnt', data=bike_data)\n\nplt.show()","33df4a98":"def categorical_plot(col):\n    sns.set(style=\"whitegrid\")\n    plt.figure(figsize = (12,6))\n    total = float(len(bike_data))\n    plt.subplot(1,2,1)\n    ax =sns.barplot(col,'cnt',data=bike_data, ci=0)\n\n    plt.subplot(1,2,2)\n    ax = sns.barplot(col,'cnt',data=bike_data, hue='yr', ci=0)\n    l=plt.legend()\n    l.get_texts()[0].set_text('2018')\n    l.get_texts()[1].set_text('2019')\n    plt.show()","7dfaa516":"categorical_plot('season')","78ef1eba":"categorical_plot('weathersit')","6b3e15fe":"categorical_plot('mnth')","3eb88e27":"categorical_plot('weekday')","6269cdab":"categorical_plot('workingday')","79e168a6":"categorical_plot('holiday')","e7e10f2f":"plt.figure(figsize=(10,10))\n\nsns.pairplot(bike_data[numerical_columns])\nplt.show()","4e4c0651":"correlation =  bike_data[numerical_columns].corr()\nmask = np.array(correlation)\nmask[np.tril_indices_from(mask)] = False\n\nplt.figure(figsize=(10,10))\nsns.heatmap(correlation, mask=mask, cmap=\"RdYlGn\", annot=True)\nplt.show()","4d96ea68":"#Based on the high level analysis of the data and the data dictionary, the following variables can be removed from further analysis -\n\n#instant: It is only an index value\nbike_data.drop('instant', axis=1, inplace=True)\n\n#dteday: This has the date, Since we already have separate columns for 'year' & 'month' we could live without this column\nbike_data.drop('dteday', axis=1, inplace=True)\n\n# atemp has high correlation with temp and also same correlation with target variable, we can get rid of one variable thereofre we will drop atemp column\nbike_data.drop('atemp', axis=1, inplace=True)\n\n#Since our objective is to find the total count of bikes and not by specific category, we will drop these two columns.\nbike_data.drop('casual', axis=1, inplace=True)\nbike_data.drop('registered', axis=1, inplace=True)","acb46ede":"bike_data_with_dummies = pd.get_dummies(bike_data[categorical_columns], drop_first=True)\n\nbike_data_with_dummies","4e13ab2a":"# Dropping the original columns as there would be duplicate variables\nbike_data = bike_data.drop(categorical_columns, axis=1)","305169c3":"# Concate dummy dataframe to the original dataframe\nbike_data = pd.concat([bike_data, bike_data_with_dummies], axis=1)","c3760336":"# Verify the changes\nbike_data","3c31fc7c":"np.random.seed(0)\nbike_data_train, bike_data_test = train_test_split(bike_data, train_size=0.7, random_state=100)","eefd7c21":"bike_data_train","3dee5ac8":"bike_data_test","7f9cafb7":"# Verify the correlation of the variables in the train set\n\ncorrelation =  bike_data_test.corr()\nmask = np.array(correlation)\nmask[np.tril_indices_from(mask)] = False\n\nplt.figure(figsize=(20,20))\nsns.heatmap(correlation, mask=mask, cmap=\"RdYlGn\")\nplt.show()","91b994c1":"# Scalling the numerical variables using the standard scaller\nnumerical_columns = ['temp','hum', 'windspeed','cnt']\n\nsc = StandardScaler()\nbike_data_train[numerical_columns] = sc.fit_transform(bike_data_train[numerical_columns])\nbike_data_test[numerical_columns] = sc.transform(bike_data_test[numerical_columns])","a853631c":"# Summary of the numerical variable post scalling\nbike_data_train[numerical_columns].describe()","cfb1b798":"bike_data_test[numerical_columns].describe()","0f3d5d97":"#Functions to build model and verify VIF\n\ndef build_model(X,y):\n    lm = LinearRegression()\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return lm\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif","d562b3d5":"# Prepare X and Y variable for the predictions\ny_train = bike_data_train.pop('cnt')\nX_train = bike_data_train","70a2dec3":"lm1 = build_model(X_train, y_train)\ncheckVIF(X_train)","89fa667e":"# Dropping workingday_1 as it has high correlations with other independant variables\nX_train.drop('workingday_1', axis=1, inplace=True)","7e975b27":"lm1 = build_model(X_train, y_train)\ncheckVIF(X_train)","2e74def9":"# Dropping season_winter as it has high correlations with other independant variables\nX_train.drop('season_winter', axis=1, inplace=True)","5213c7d1":"lm3 = build_model(X_train, y_train)\ncheckVIF(X_train)","4adf9373":"# Dropping weekday_Thu due to high p-value as it is not sighnificant for the model.\nX_train.drop('weekday_Thu', axis=1, inplace=True)\nlm4 = build_model(X_train, y_train)\ncheckVIF(X_train)","bd24e7d6":"# Dropping weekday_Wed, weekday_Sat, mnth_Feb due to high p-value as it is not sighnificant for the model.\nX_train.drop(['weekday_Wed','weekday_Sat','mnth_Feb'], axis=1, inplace=True)\nlm5 = build_model(X_train, y_train)\ncheckVIF(X_train)","59ac41cc":"# Dropping 'mnth_Dec, mnth_Jun, mnth_Nov due to high p-value as it is not sighnificant for the model.\nX_train.drop(['mnth_Dec','mnth_Jun','mnth_Nov'], axis=1, inplace=True)\nlm6 = build_model(X_train, y_train)\ncheckVIF(X_train)","3d8430a6":"# Dropping weekday_Mon, mnth_Aug to high p-value as it is not sighnificant for the model.\nX_train.drop(['weekday_Mon','mnth_Aug'], axis=1, inplace=True)\nlm7 = build_model(X_train, y_train)\ncheckVIF(X_train)","3e3411d1":"# Dropping season_summer to high p-value as it is not sighnificant for the model.\nX_train.drop(['season_summer'], axis=1, inplace=True)\nlm8 = build_model(X_train, y_train)\ncheckVIF(X_train)","735d33ee":"# Dropping mnth_Jan to high p-value as it is not sighnificant for the model.\nX_train.drop(['mnth_Jan'], axis=1, inplace=True)\nlm9 = build_model(X_train, y_train)\ncheckVIF(X_train)","61114f57":"# Dropping mnth_May, weekday_Thu to high p-value as it is not sighnificant for the model.\nX_train.drop(['mnth_May'], axis=1, inplace=True)\nlm10 = build_model(X_train, y_train)\ncheckVIF(X_train)","a4837779":"lm10.params","6f0e5b53":"sm.graphics.plot_ccpr(lm10, 'temp')\nplt.show()","4c57eabc":"sm.graphics.plot_ccpr(lm10, 'windspeed')\nplt.show()","70fecf77":"sm.graphics.plot_ccpr(lm10, 'hum')\nplt.show()","593da0b6":"# Verify that there is no correlation among residual terms\nX_train = sm.add_constant(X_train)\ny_train_pred = lm10.predict(X_train)\nresidual = y_train - y_train_pred\nsns.scatterplot(y_train,residual)\nplt.plot(y_train,(y_train - y_train), '-r')\nplt.xlabel('Count')\nplt.ylabel('Residual')\nplt.show()","b3bbaf19":"checkVIF(X_train)","868effc9":"# Verify that residuals are normally distributed\nres = y_train-y_train_pred\n\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms')                  \nplt.xlabel('Errors')                         \nplt.show()","e6188623":"sm.qqplot((y_train - y_train_pred), fit=True, line='45')\nplt.show()","d39c7f5c":"# Prepare x and y variable from test set\ny_test = bike_data_test.pop('cnt')\nX_test = bike_data_test","ef147912":"# Filter columns from the final X_train  \ncol=X_train.columns\nX_test = sm.add_constant(X_test)\nX_test=X_test[col]\nX_test","7a8086da":"# Making predictions using the final model (lm10)\ny_pred = lm10.predict(X_test)","ce5a1f98":"# Plotting y_test and y_pred to understand the spread\nfig = plt.figure()\nplt.scatter(y_test, y_pred, alpha = 0.5)\nfig.suptitle('y_test vs y_pred')             \nplt.xlabel('y_test')                          \nplt.ylabel('y_pred') ","3c5a264f":"# Calculating R-squared and Adj. R-squared for the test dataset\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, y_pred)\nr2","9dd28296":"# n is number of rows in test dataset\nn = X_test.shape[0]\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\nadjusted_r2 = round(1-(1-r2)*(n-1)\/(n-p-1),6)\nadjusted_r2","778d528c":"### Model-8","e532238e":"##### There is no visible pattern in residual values, thus homoscedacity is well preserved","446b42fa":"**Inference**\n- Clear weather is seems to be most favorable for bike riding, followed by cloudy weather.\n- It seems people avoid bike riding during Rainy season \n- Similar trend in the Year on Year graph","a9ed8396":"As there is no missing value in the data set, we do not have to handle any missing data.","ea70ec1a":"**Inferences**\nBelow observations can be maded with above graph:\n- Instant is an index variable, not much useful in the model. We can consider dropping it.\n- There is linear relationship of temp and atemp variable with cnt. however there is very strong relationship between temp and atemp. therefore we can only use one in our model building.\n- There seems to be negative relationship of hum and windspeed variables with cnt.\n- There is a strong relationship of casual and registered variable with cnt, need further analysis.","b58f7610":"# Model Validation\n\n#### We validate the below assumptions of Linear Regression\n- 1. Linear Relationship \n- 2. Homoscedasticity \n- 3. Absence of Multicollinearity\n- 4. Normality of Errors","80f5b487":"**Inferene**\n- Highest number for bookings are done in fall, followed by summer and winter.\n- Number of bookings increased in 2019, compare to the year 2018\n- Jun-Sep are the busiest months in terms of the bookings.\n- More number of booking during non-holiday than during holiday\n- Days of the week are mostly flat in terms of bookings.\n- Bookings are quite similar betweek working or non-working days.\n- Clear weather is seems to be most favorable for bike riding, followed by cloudy weather.","3338928c":"**Inference**\n- Not much difference in day wise bookings, Thursday recorded most number of bookings followed by Saturday and Sunday.\n- Least number of booking was on Friday in 2018, where as Tuesday is least booking day in 2019","5cd1acba":"# Problem Statement\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n- Which variables are significant in predicting the demand for shared bikes.\n- How well those variables describe the bike demands\n- Based on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. ","aaf5aa92":"### Model-3","e3501251":"**Inference**\n- we can clearly see that instant, temp, atemp, registered and cnt are normally distributed. They don't have any outliers.\n- There seems to be some outliers in hum, windspeed and casual which we need to handle","c5c0306a":"### 1. Linear Relationship","13bf7367":"# Scalling the numerical variables","98d6369c":"# Duplicate check","be6865f3":"### 1. Hypothesis Testing :\n\nHypothesis Testing States that\n\n- H0:B1=B2=...=Bn=0 \n- H1: at least one Bi!=0","77feed56":"# Business Goal\n\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","be525f31":"### Model-9","00f28fc7":"##### Based on the histogram, we can conclude that error terms are following a normal distribution","dd9203eb":"### Model-2","41e5c5e8":"- R-squared: 0.861 and Adj. R-squared: 0.852\n- Model is successfully able to explain by 86% of its variables however there are multiple insignicant variables (hight p-value) and multicollinear variables. we will iterate multiple times by removing these variables to get the best suited model.\n","4254113e":"# Missing Data Check","9abef2aa":"### 2. Homoscedasticity","cfbf20ff":"*  |R-squared | Adj. R-squared \n:--------------|:---------|:--------------\nTrain Data Set |0.851     | 0.847\nTest Data Set  |0.812     | 0.798\n---\nOverall we have a decent model, but we also acknowledge that we could do better. <br>\nAs per the final model, below variables have significate influence on the target variable i.e. no of bookings. Therefore they should be considered before making any decesion.<br>\n- **yr**<br>\nA coefficient value of \u20181.019406\u2019 indicated that a year wise the rental numbers are increasing\n- **Temp**<br>\nA coefficient value of \u20180.432292\u2019 indicated that a temperature has significant impact on bike rentals \n- **Weathersit_LightRain (value=3))**<br>\nA coefficient value of \u2018-0.944379\u2019 indicated that the light snow and light rain deters people from renting out bikes","7f8973c2":"### Model-4","92c7e314":"# Making Predictions Using the Final Model","b28e821b":"# Encoding categorical variables","adebcc87":"##### The above plots represents the relationship between the model and the predictor variables. and we can see clearly that linearity is well preserved","08714110":"# Train Test Split","a2ca6fb4":"**Inference**\n- Now we have a model where \n    - R-squared:0.851 and Adj. R-squared: 0.847\n    - No variable have p-value more than 0.05\n    - No variable where VIF is more than 5\n#### This seems to be a stable model, Now we will move to its interpretation ","e4389719":"# Reading and Understanding the Data","102fd611":"# Data Preparation for Modeling\n\n### Dummy variable creation for categorical columns","4ef77a2f":"### Model-5","a597f9ec":"# Summary","8295e68b":"**Inference**\n- Non-holidays have recorded more number of bookings, than holidays.\n- May be more people use these bikes for their daily commute.\n- Similar trend in the Year on Year graph","d39fc6ed":"**Inference**\n- No much difference in the booking in terms of working and non-working days \n- Non working day recorded little more number of bookings.\n- Similar trend in the Year on Year graph","c3342a05":"### Model-6","8b87fc02":"### Model-7","9eb00b9e":"# Model Interpretation","367156c7":"##### All the predictor variables have VIF value less than 5. So we can assume that there are insignificant multicollinearity among the predictor variables.","d6526c69":"### Model-1","15823bdd":"##### it is evident that all our coefficients are not equal to zero, which means we REJECT the NULL HYPOTHESIS","c102adc4":"### Model-10","7c28e048":"**Inference**\n- All the colums are normally distributed except windspeed and casual, which are little skewed.\n- Need more investigation to identify the outliers","75588a78":"**Inference**\n- Most people ride bike during May to Oct month as these months recorded highest bookings.\n- January recorded the least number of booking\n- Similar trend in the Year on Year graph","73d8e66c":"# Model Evaluation","d0ea1f95":"#### 2. F-Staitsics\n\n- F-statistic: 198.7 \n- Prob (F-statistic): 9.43e-191\n\n##### The F-Statistics value of 198.7, which is greater than 1 and the p-value is very small (approx) states that the overall model is significant","6a3a21d9":"**Inferences**\nBelow observations can be maded with above graph:\n- We can confirm high correlation between temp and atemp variable.\n- We can confirm negative relationship of hum and windspeed variables with cnt.\n- casual & registered: Both these columns contains the count of bike booked by different categories of customers. From the analysis, we can understand that 'cnt = 'casual' + 'registered'. Since our objective is to find the total count of bikes and not by specific category, we will drop these two columns.","4e7966b8":"### 3. Multicollnearity","a8c94aca":"### 4. Normality of error","b6df5d0c":"# Exploratory Data Analysis","396ab3f1":"**Inference**\n- Highest number for bookings are done in fall, followed by summer and winter.\n- Year on Year shows the same trend"}}