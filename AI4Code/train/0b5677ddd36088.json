{"cell_type":{"5dbcc5c2":"code","2a477acb":"code","2cc79134":"code","2c55f180":"code","1ffccbfb":"code","7b053826":"code","50183532":"code","4542dd15":"code","9409ac74":"code","122e1108":"code","e294fcb0":"code","5c91cbd3":"code","862105cf":"code","707adbd2":"code","3353aeef":"code","a2a006ec":"code","08001a6d":"code","110132a7":"code","a82a00f5":"code","702289cc":"code","ec52e53a":"code","933a1d5a":"code","78f100b9":"code","4de1845c":"code","b0bb3bbd":"code","29a7f7b8":"code","ec683fc2":"code","e9bcf287":"code","b7f95961":"code","8a242949":"code","bce63813":"code","a26e42b1":"markdown"},"source":{"5dbcc5c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a477acb":"df = pd.read_csv('..\/input\/bostonhoustingmlnd\/housing.csv')","2cc79134":"df.head(10).T","2c55f180":"df.info()","1ffccbfb":"df.count()","7b053826":"#Recherche corr\u00e9lation\n\ntabcorr = df.corr()  ","50183532":"tabcorr","4542dd15":"#Carte de temp\u00e9rature\nplt.figure(figsize=(12,12))\nsns.heatmap(abs(tabcorr), cmap=\"coolwarm\")","9409ac74":"#Regroupement des param\u00e8tres par cluster\nsns.clustermap(abs(tabcorr), cmap=\"coolwarm\")","122e1108":"#dendrogramme des corr\u00e9lations entre les caract\u00e9ristiques\nfrom scipy.cluster import hierarchy as hc\n\ncorr = 1 - df.corr()\ncorr_condensed = hc.distance.squareform(corr)\nlink = hc.linkage(corr_condensed, method='ward')\nplt.figure(figsize=(12,12))\nden = hc.dendrogram(link, labels=df.columns, orientation='left', leaf_font_size=10)","e294fcb0":"#On s'int\u00e9resse plus pr\u00e9cis\u00e9ment \u00e0 la valeur des maisons\ncorrelations = tabcorr.MEDV\nprint(correlations)","5c91cbd3":"correlations = correlations.drop(['MEDV'],axis=0)","862105cf":"#Les corr\u00e9lations fortement n\u00e9gatives sont aussi significatives que les positives ; on consid\u00e8re donc les valeurs absolues, et on trie par ordre d\u00e9croissant\nprint(abs(correlations).sort_values(ascending=False))","707adbd2":"#R\u00e9gression lin\u00e9aire multiple\ndf.columns","3353aeef":"continuous_features = ['PTRATIO','LSTAT', 'MEDV']\ndiscrete_features = ['RM']","a2a006ec":"df1 = df[df.MEDV<1000000].drop(discrete_features, axis=1)","08001a6d":"X = df1.drop(['MEDV'], axis=1)\ny = df1.MEDV\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","110132a7":"from sklearn.linear_model import LinearRegression","a82a00f5":"lm = LinearRegression()\nlm.fit(X_train, y_train)            # apprentissage\ny_pred = lm.predict(X_test)         # pr\u00e9diction sur l'ensemble de test","702289cc":"# On trace le nuage de points pour comparer la pr\u00e9diction et les r\u00e9sultats attendus\nplt.figure(figsize=(12,12))\nplt.scatter(y_test, y_pred)\nplt.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()], color='red', linewidth=3)\nplt.xlabel(\"MEDV\")\nplt.ylabel(\"Prediction MEDV\")\nplt.title(\"MEDV reels vs predictions\")","ec52e53a":"#on peut visualiser la distribution de l'erreur avec seaborn\nsns.distplot(y_test-y_pred)","933a1d5a":"#erreur sur les moindres carr\u00e9s\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","78f100b9":"# rapport des variances estim\u00e9e\/r\u00e9elle\nscoreR2 = r2_score(y_test, y_pred)\nprint(scoreR2)","4de1845c":"lm.score(X_test,y_test)","b0bb3bbd":"# R\u00e9gression par for\u00eat al\u00e9atoire\nX = df.drop(['MEDV'], axis=1)\ny = df.MEDV\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","29a7f7b8":"from sklearn import ensemble\nrf = ensemble.RandomForestRegressor()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)\nprint(rf.score(X_test,y_test))","ec683fc2":"plt.figure(figsize=(12,12))\nplt.scatter(y_test, y_rf)\nplt.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()], color='red', linewidth=3)\nplt.xlabel(\"MEDV\")\nplt.ylabel(\"Prediction MEDV\")\nplt.title(\"MEDV reels vs predictions\")","e9bcf287":"sns.distplot(y_test-y_rf)","b7f95961":"print(np.sqrt(mean_squared_error(y_test, y_rf)))","8a242949":"rf.score(X_test,y_test)","bce63813":"#Importance des caract\u00e9ristiques\nimport xgboost as XGB\nxgb  = XGB.XGBRegressor()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\nprint(xgb.score(X_test,y_test))\n\nplt.figure(figsize=(12,12))\nplt.scatter(y_test, y_xgb)\nplt.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()], color='red', linewidth=3)\nplt.xlabel(\"MEDV\")\nplt.ylabel(\"Prediction MEDV\")\nplt.title(\"MEDV reels vs predictions\")","a26e42b1":"#RM - nombre moyen de pi\u00e8ces par logement\n#PTRATIO - ratio \u00e9l\u00e8ves-enseignant par ville\n#LSTAT -% de statut inf\u00e9rieur de la population\n#MEDV - Valeur m\u00e9diane des logements occup\u00e9s par leur propri\u00e9taire en 1000 $"}}