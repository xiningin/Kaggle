{"cell_type":{"509c1555":"code","3f4fb93f":"code","330b168a":"code","04dcc72b":"code","e5464403":"code","3b9b879c":"code","df0e0c9b":"code","66da628f":"code","c7b90a4e":"code","7a0d3954":"code","fcb4038c":"code","e55eea33":"code","87a36e64":"code","c43b363d":"code","f8711507":"code","9a682597":"code","5b8f5e10":"code","4a791add":"code","9a0e10c9":"code","6cfe5411":"code","e8f6bda7":"code","3d0f12bf":"code","1ee2ae16":"code","8c6246fd":"code","5d18668f":"code","a4340092":"code","8421f843":"code","9c605424":"code","21747105":"code","7079ae3b":"code","0f2250d6":"code","12122cf8":"code","d8f303df":"code","be9dd2fe":"code","963f31e1":"code","c050b93c":"code","33968bf4":"code","86fa9afd":"code","b2bf70fb":"code","4631ae3d":"code","008b1247":"code","02c96cdb":"code","37480cec":"code","4f269ece":"code","3d21c04b":"code","d24d327b":"code","a1750655":"code","bd479186":"code","fa8d4c5e":"code","d4aeeda2":"code","903f70e6":"code","51776251":"code","bcf674a3":"code","fd81f75f":"code","386bdbc8":"code","d2bdee79":"code","31c854d6":"code","7162195f":"code","e745255f":"code","e2c82e66":"code","f9e13f60":"code","10f24ca5":"code","1a3d8e54":"code","0a10034f":"code","ab845e65":"code","253db4a2":"code","66fb8426":"code","a9ee9d71":"code","1c10d1fb":"code","d9c33125":"code","90a4a115":"code","f495c8d6":"code","2c1edc64":"code","4e935261":"code","2af6147f":"code","8d5096a1":"code","26575db8":"code","6dc38af6":"code","79b853d8":"code","ffad05e4":"code","124fdf76":"code","aa033b1a":"code","8837a2cf":"code","8b85a45e":"code","72c8e1e8":"code","7ef6d84b":"code","cb45feba":"code","5c6697cd":"code","df78e468":"code","c100679f":"code","1d09fc09":"code","1feb8fb0":"code","93c23ed6":"code","a499eb0b":"code","6cad638d":"code","6ad3a5f0":"code","053cd6ad":"code","dd4e4c01":"code","2fd3b779":"code","3421b8b8":"code","bc1c2c9a":"code","794467d1":"code","2aea0aef":"code","7312c8b3":"code","809332ea":"code","379a5ec8":"code","1fd649b4":"code","433f5c29":"code","fb3f98dc":"code","30d1053e":"code","46137354":"code","356ff53a":"code","9156d949":"code","5b9f3559":"code","330790d1":"code","9c93c919":"code","63444d40":"code","8237acd4":"code","f54fcc9b":"code","71fab481":"code","7edf7cc0":"code","907e5ae1":"code","d96cf35e":"code","5704e970":"code","69d2ab61":"code","0e2446b5":"code","5d1ca6ac":"code","07b0fcfb":"code","f1f76f4b":"code","cfddcc35":"code","f15dad0d":"code","23aeed2e":"code","b8760c34":"code","8bb82aee":"code","55506c68":"code","96f487dd":"code","a7b5da86":"code","b556f638":"code","86b1cc13":"code","0509af0a":"code","a1f3c2dc":"code","ae3b1d6c":"code","4a19e716":"code","db930d8c":"code","6666dab9":"code","e255188c":"code","9a376d9d":"code","d358ab7d":"code","84946276":"code","c87b2f4f":"code","9d736828":"code","0a6536f5":"code","a8e73c4b":"markdown","5d72efe4":"markdown","b531f464":"markdown","b2484e22":"markdown","d84cfd54":"markdown","83fdf7c1":"markdown","df0c4bf5":"markdown","eba32783":"markdown","2bde073f":"markdown","592e8636":"markdown","f8c8261b":"markdown","60362ddb":"markdown","85f7f8e8":"markdown","22114d08":"markdown","55f849b9":"markdown","fd7f6679":"markdown","fdda2a1f":"markdown","9a0eb976":"markdown","7fd5cd5e":"markdown","cf31f932":"markdown","93f9b862":"markdown","58a1de52":"markdown","083af7ea":"markdown","101a022a":"markdown","2fe2230e":"markdown","0388acef":"markdown","10a6e6a8":"markdown","bcf3ebf8":"markdown","3450a3e0":"markdown","ce54c533":"markdown","f520ced6":"markdown","490823be":"markdown","c2b64f52":"markdown","2343924b":"markdown","c5e28c4e":"markdown","f6f4953b":"markdown","6880ea1e":"markdown","0197df90":"markdown","05d00a63":"markdown","1cf5f92a":"markdown","689651ea":"markdown","b9b0dd70":"markdown","8392fa00":"markdown","9dd31185":"markdown","dda64968":"markdown","443202e5":"markdown","bcab2543":"markdown","b3ce6996":"markdown","e9037e2c":"markdown","a3b1fc9a":"markdown","f737ac32":"markdown","5c88639e":"markdown","2a40b99d":"markdown","ab5f65b8":"markdown","d02ff39e":"markdown","c82b4207":"markdown","91d7b1b6":"markdown","5937fde5":"markdown","d55bc627":"markdown","b855ba77":"markdown","7db1b5c5":"markdown","ba146a3e":"markdown"},"source":{"509c1555":"# \u041f\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0441\u0442\u0430\u0431\u0438\u043b\u044c\u043d\u0443\u044e \u0432\u0435\u0440\u0441\u0438\u044e CatBoost\n!pip uninstall catboost --yes\n!pip install catboost==0.15.2","3f4fb93f":"import os\nimport tqdm\nimport pickle\nimport math as m\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium \nimport warnings\n\nimport hyperopt \nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.dummy import DummyRegressor\nfrom xgboost import XGBRegressor, DMatrix\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor, Pool, cv ","330b168a":"import shap\nshap.initjs()","04dcc72b":"warnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nsns.set()","e5464403":"# \u0421\u0438\u0441\u0442\u0435\u043c\u043d\u044b\u0435 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u044b\nEXT_DATA = '\/kaggle\/input\/external-geodata'\nPREPROCESS = '\/kaggle\/input\/airbnb-preprocess'\nDATA = '\/kaggle\/input\/spsu-intensives'\nCWD = os.getcwd()\nVAL_SIZE = 0.1\nDEVICE = 'CPU'\n\n# \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\nmmt_dict = {'test': os.path.join(DATA, 'test.csv'),\n            'train': os.path.join(DATA, 'train.csv'),\n            'districts': os.path.join(EXT_DATA, 'districts.csv'),\n            'parks': os.path.join(EXT_DATA, 'parks.csv'),\n            'sights': os.path.join(EXT_DATA, 'sights.csv')}","3b9b879c":"os.chdir(PREPROCESS)\nimport make_master_table as mmt\nos.chdir(CWD)","df0e0c9b":"# \u041a\u043e\u0440\u0440\u0435\u0442\u0438\u0440\u043e\u0432\u043a\u0430 \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043f\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043d\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u044b:\ndef correct_test(df):\n    newdf = df.copy(deep=True)\n    zeros = [556, 748, 1628, 1951, 4048, 5926, 6106]\n    nines = [557,1010,1288,1961,2114,2476,3564,4319,5358,6228,6541]\n    large = [5450]\n    \n    newdf.loc[newdf['Id'].isin(zeros), 'Predicted'] = 0\n    newdf.loc[newdf['Id'].isin(nines), 'Predicted'] = 9999\n    newdf.loc[newdf['Id'].isin(large), 'Predicted'] = 12624\n    \n    return newdf","66da628f":"df_test = pd.read_csv(os.path.join(DATA, 'test.csv'))\ndf_train = pd.read_csv(os.path.join(DATA, 'train.csv'))\n\nunknown = list(set(df_test.select_dtypes(object)['property_type'].unique())-set(df_train['property_type'].unique()))\ndf_test[df_test['property_type'].isin(unknown)]","c7b90a4e":"df_train.groupby(['property_type'])['price'].median()","7a0d3954":"df_train.info()","fcb4038c":"df_test.info()","e55eea33":"df_train.describe()","87a36e64":"df_test.describe()","c43b363d":"df_train[df_train['price']==0]","f8711507":"df_train[df_train['price']>0.5*df_train['price'].max()]","9a682597":"df_train = df_train[df_train['price']!=0].copy(deep=True)\ndf_train = df_train[df_train['price']<9000].copy(deep=True)\ndf_train.reset_index(inplace=True, drop=True)","5b8f5e10":"fig = plt.figure(figsize=(6,5))\nplt.hist(df_train['price'], bins=50)\nplt.xlim((0, 1300))\nplt.title('df_train: Price', fontsize=14)","4a791add":"df_train['log_price'] = np.log(df_train['price'])\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nax1, ax2 = axes[0], axes[1]\n\nax1.hist(df_train['price'], bins=50)\nax1.set_xlim((0, 1300))\nax1.set_title('df_train: Price', fontsize=14)\n\nax2.hist((df_train['log_price']))\nax2.set_title('df_train: Log Price', fontsize=14)\n\nplt.show()","9a0e10c9":"fig, axes = plt.subplots(1, 2, figsize=(12, 5))\nax1, ax2 = axes[0], axes[1]\n\nsns.boxplot(y=\"price\", data=df_train, ax=ax1)\nax1.set_title('df_train: Price', fontsize=14)\n\nsns.boxplot(data=df_train['log_price'], ax=ax2)\nax2.set_title('df_train: Log Price', fontsize=14)\n\nplt.show()","6cfe5411":"# \u0421\u0442\u0440\u043e\u043a\u043e\u0432\u044b\u0435 \u0442\u0438\u043f\u044b \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435\nfor c in df_train.columns:\n    if isinstance(df_train.iloc[0][c], str):\n        print(f'Column: {c}')","e8f6bda7":"df_train['host_is_superhost'].value_counts()","3d0f12bf":"df_train['host_identity_verified'].value_counts()","1ee2ae16":"df_train['property_type'].value_counts()","8c6246fd":"df_train['room_type'].value_counts()","5d18668f":"df_train['instant_bookable'].value_counts()","a4340092":"df_train['cancellation_policy'].value_counts()","8421f843":"# \u0422\u0435\u043f\u043b\u043e\u043a\u0430\u0440\u0442\u0430 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439 \nfig = plt.figure(figsize=(8,7))\nax = sns.heatmap(df_train.iloc[:,1:].corr(), vmin=0, vmax=1, cmap = 'YlGnBu')\nplt.show()","9c605424":"fig, axes = plt.subplots(nrows=7, ncols=3, figsize=(12, 27))\nsubset = df_train.select_dtypes(include=['int64', 'float64',]).columns[2:-1]\nfor ax, feature in tqdm.tqdm_notebook(zip(axes.reshape(-1,1).tolist(), subset.tolist())):\n    df_train.plot(feature,\"log_price\", subplots=True, kind=\"scatter\", \n                  ax=ax, c='blue', alpha = 0.3)\nplt.tight_layout()","21747105":"def get_orderlist(df, xs, j, k, y, sort):\n    if sort:\n        return df.groupby([xs[j,k]])[y].median().sort_values(ascending=False).index.tolist()\n    else:\n        pass\ndef boxplot_mat(df, x_columns, y, nrows, ncols, figsize, sort):\n    xs = np.array(x_columns).reshape(nrows, ncols)\n    fig, ax = plt.subplots(nrows, ncols, figsize=figsize)\n    for j in range(0,nrows):\n        for k in range(0,ncols):\n            orderlist = get_orderlist(df, xs, j, k, y, sort)\n            sns.boxplot(df[xs[j,k]],np.log(df[y]), ax=ax[j, k], order=orderlist)\n    plt.show()","7079ae3b":"boxplot_mat(df_train, \n            ['host_is_superhost', 'host_identity_verified',\n             'property_type', 'room_type',\n             'instant_bookable', 'cancellation_policy'], \n             'log_price', \n             2, 3, (22, 12), True)","0f2250d6":"boxplot_mat(df_train, \n            ['bedrooms', 'accommodates',\n             'bathrooms', 'beds',], \n             'log_price', \n             2, 2, (14, 10), False)","12122cf8":"fig = plt.figure(figsize=(16,10))\norderlist = df_train.groupby(['property_type'])['log_price'].median().sort_values(ascending=False).index.tolist()\nsns.boxplot(df_train['property_type'],\n            df_train['log_price'],\n            order = orderlist)\nplt.xticks(rotation=90)\nplt.show()","d8f303df":"this_map = folium.Map(prefer_canvas=True)\nstd = df_train[df_train['price']!=0]['log_price'].std()\nmean = df_train[df_train['price']!=0]['log_price'].mean()\nlegend_html =  \"\"\"\n        <div \n    <br>\n        &nbsp; Mean + 3*std\n        <i class=\"fa fa-circle fa-1x\"\n        style=\"color:#ff0000\"><\/i>   \n  <br>\n        &nbsp; Mean -  3*std \n        <i class=\"fa fa-circle fa-1x\"\n        style=\"color:#008000\"><\/i>   \n  <br>  \n      <\/div>\n      \"\"\"  \ndef return_color(log_price):\n    if log_price > mean+3*std:\n        return 'red'\n    elif log_price < mean-3*std:\n        return 'green'\n    else:\n        return 'blue'\n\ndef plot_dot(point):\n    folium.CircleMarker(location=[point['latitude'], point['longitude']],\n                        radius=1,\n                        weight=point['log_price']\/(5 if point['color'] =='blue' else 1),\n                        color=point['color'],\n                        fill=True,\n                        alpha=0.3).add_to(this_map)\n\nfor i in tqdm.tqdm_notebook(range(df_train[df_train['price']!=0].shape[0])):\n    point = df_train[df_train['price']!=0][['longitude','latitude', 'log_price']].iloc[i,:].to_dict()\n    point['color'] = return_color(point['log_price'])\n    plot_dot(point)\n\nthis_map.fit_bounds(this_map.get_bounds())\nthis_map.get_root().html.add_child(folium.Element(legend_html))\n\nthis_map.save('MelbournePlot_train.html')\nthis_map","be9dd2fe":"this_map = folium.Map(prefer_canvas=True)\nfor i in tqdm.tqdm_notebook(range(df_test.shape[0])):\n    point = df_test[['longitude','latitude']].iloc[i,:].to_dict()\n    point['log_price'] = 1\n    point['color'] = 'blue'\n    plot_dot(point)\n\nthis_map.fit_bounds(this_map.get_bounds())\n\nthis_map.save('MelbournePlot_test.html')\nthis_map","963f31e1":"# \u0420\u0430\u0441\u0447\u0435\u0442 \u0440\u0430\u0441\u0441\u043e\u0442\u044f\u043d\u0438\u044f \u043c\u0435\u0436\u0434\u0443 \u043e\u0431\u044a\u0435\u043a\u0442\u0430\u043c\u0438 \u043d\u0430 \u0433\u0435\u043e\u0438\u0434\u0435\ndef gps_distance(pos1, pos2, earth_rad=6350000.):\n    # pos - [lat, long]\n    # er - \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0434\u0438\u0443\u0441 \u0437\u0435\u043c\u043b\u0438, \u0432 \u043c\u0435\u0442\u0440\u0430\u0445 \n    coord_mtrx = np.array([pos1[0],pos2[0],pos1[1],pos2[1]])\n    # \u041f\u0435\u0440\u0435\u0432\u043e\u0434 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442 \u0432 \u0440\u0430\u0434\u0438\u0430\u043d\u044b\n    coord_mtrx = (coord_mtrx*m.pi)\/180    \n    \n    # \u0420\u0430\u0441\u0447\u0435\u0442 \u043d\u0430 \u0431\u0430\u0437\u0435 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u043d\u043e\u0433\u043e \u0440\u0430\u0434\u0438\u0443\u0441\u0430 \u0433\u0435\u043e\u0438\u0434\u0430 \n    sin_delta_long = pow(m.sin( (coord_mtrx[3]-coord_mtrx[2])\/2 ),2)\n    sin_delta_lat = pow(m.sin( (coord_mtrx[1]-coord_mtrx[0])\/2 ),2)\n    under_sq = sin_delta_lat + m.cos(coord_mtrx[1])*m.cos(coord_mtrx[0])*sin_delta_long\n    phi = 2*m.asin(m.sqrt(under_sq))\n    dist = (earth_rad)*phi\n    return dist","c050b93c":"# \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u044b\u043d\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a 1: \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u0434\u043e \u0446\u0435\u043d\u0442\u0440\u0430 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0430 \u043f\u043e \u043f\u043e\u0438\u0441\u043a\u043e\u0432\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0435\ndef city_center_feature(df):\n    # \u0426\u0435\u043d\u0442\u0440 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0430 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u043e \u043f\u043e\u0438\u0441\u043a\u043e\u0432\u043e\u043c\u0443 \u0437\u0430\u043f\u0440\u043e\u0441\u0443 OpenStreet Map: -37.8142176,144.9631608\n    # https:\/\/nominatim.openstreetmap.org\/details.php?place_id=258938382\n    MELBOURNE_POS = [-37.8142176,144.9631608]\n    distns = []\n    for i in tqdm.tqdm_notebook(range(df.shape[0])):\n        obj_pos = [df.iloc[i]['latitude'], df.iloc[i]['longitude']]\n        distns.append(gps_distance(MELBOURNE_POS, obj_pos))\n    df['center_dist'] = distns\n    df['log_center_dist'] = np.log(df['center_dist'])\n    return df\ndf_train = city_center_feature(df_train)","33968bf4":"fig, axes = plt.subplots(1, 2, figsize=(12, 5))\nax1, ax2 = axes[0], axes[1]\n\nax1.hist(df_train['center_dist'])\nax1.set_title('df_train: Center distance', fontsize=14)\n\nax2.hist((df_train['log_center_dist']))\nax2.set_title('df_train: Log Center distance', fontsize=14)\n\nplt.show()","86fa9afd":"fig, axes = plt.subplots(1, 2, figsize=(12, 5))\nax1, ax2 = axes[0], axes[1]\n\nsns.boxplot(y=\"center_dist\", data=df_train, ax=ax1)\nax1.set_title('df_train: Center distance', fontsize=14)\n\nsns.boxplot(data=df_train['log_center_dist'], ax=ax2)\nax2.set_title('df_train: Log Center distance', fontsize=14)\n\nplt.show()","b2bf70fb":"fig = plt.figure(figsize=(8,5))\nsns.scatterplot(df_train['log_center_dist'], df_train['log_price'], alpha=0.5)\nplt.show()","4631ae3d":"df_districts = pd.read_csv(os.path.join(EXT_DATA, 'districts.csv'))\ndf_districts","008b1247":"# \u0411\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0439 \u0440\u0430\u0439\u043e\u043d \u043a \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u0430\u043c\ndef close_district_feature(df, df_districts):\n    close_district = []\n    for i in tqdm.tqdm_notebook(range(df.shape[0])):\n        obj_pos = [df.iloc[i]['latitude'], df.iloc[i]['longitude']]\n        distns = dict()\n        for j in range(df_districts.shape[0]):\n            district, district_pos = df_districts.iloc[j]['District'],\\\n                                                       (df_districts.iloc[j]['latitude'],\\\n                                                        df_districts.iloc[j]['longitude'])\n            distns[district] = gps_distance(district_pos, obj_pos)\n        result = sorted(distns.items(), key=lambda x: x[1])[0]\n        close_district.append(result[0])\n        #df.loc[i, ['close_district']] = result[0]\n    df['close_district'] = close_district\n    return df\ndf_train = close_district_feature(df_train, df_districts)","02c96cdb":"fig = plt.figure(figsize=(10,5))\norderlist = df_train.groupby(['close_district'])['log_price'].median().sort_values(ascending=False).index.tolist()\nsns.boxplot(df_train['close_district'],\n            df_train['log_price'],\n            order = orderlist)\nplt.xticks(rotation=90)\nplt.show()","37480cec":"# \u041f\u0430\u0440\u043a\u043e\u0432 \u0432 \u0440\u0430\u0434\u0438\u0443\u0441\u0435 n \u043a\u043c \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 \ndf_parks = pd.read_csv(os.path.join(EXT_DATA, 'parks.csv'))\ndf_parks","4f269ece":"# \u041f\u0430\u0440\u043a\u043e\u0432 \u0432 \u0440\u0430\u0434\u0438\u0443\u0441\u0435 n \u043a\u043c \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 \ndef parks_feature(df, df_parks, n_list):  \n    for n in n_list:\n        df[f'parks_{n}km'] = None\n    for i in tqdm.tqdm_notebook(range(df.shape[0])):\n        obj_pos = [df.iloc[i]['latitude'], df.iloc[i]['longitude']]\n        distns = []\n        for j in range(df_parks.shape[0]):\n            park, park_pos = df_parks.iloc[j]['park'],\\\n                                                       (df_parks.iloc[j]['latitude'],\\\n                                                        df_parks.iloc[j]['longitude'])\n            distns.append(gps_distance(park_pos, obj_pos))\n            \n        for n in n_list:\n            parks_cnt = len(np.array(distns)[np.array(distns)<=[n*1000]])\n            df.loc[i, [f'parks_{n}km']] = parks_cnt\n    return df\n\ndf_train = parks_feature(df_train, df_parks,[2,5,10,15])","3d21c04b":"df_train = df_train[~df_train['log_price'].isnull()].copy(deep=True)\ndf_train.info()","d24d327b":"df_train.describe()","a1750655":"fig, axes = plt.subplots(2, 2, figsize=(9, 6))\naxes = sum(axes.reshape(-1,1).tolist(),[])\nfor ax, field in zip(axes,['parks_2km','parks_5km',\n                           'parks_10km','parks_15km']):\n    ax.scatter(df_train[field], df_train['log_price'])\n    ax.set_xlabel(field)\n    ax.set_ylabel('log_price')\n    ax.set_title(f'Scatter Plot: {field}', fontsize=14)\nplt.tight_layout()\nplt.show()","bd479186":"# \u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u0430\u0436\u043d\u044b\u0435 \u043c\u0435\u0441\u0442\u0430 \u0433\u043e\u0440\u043e\u0434\u0430 \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c Airbnb \u0438 \u0430\u043d\u0430\u043b\u0438\u0437\u0435 \u043a\u0430\u0440\u0442 \u0441 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \u0436\u0438\u043b\u044c\u044f\ndf_sights = pd.read_csv(os.path.join(EXT_DATA, 'sights.csv'))\ndf_sights","fa8d4c5e":"# \u0420\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0434\u043e 20 \u0442\u043e\u0447\u0435\u043a \u0433\u043e\u0440\u043e\u0434\u0430\ndef sights_feature(df, df_sights): \n    for j in tqdm.tqdm_notebook(range(df_sights.shape[0])):\n        place, district_pos = df_sights.iloc[j]['place'],\\\n                                                    (df_sights.iloc[j]['latitude'],\\\n                                                    df_sights.iloc[j]['longitude'])\n        # print(place)\n        df[place] = None\n        tmp = []\n        for i in range(df.shape[0]):\n            obj_pos = [df.iloc[i]['latitude'], df.iloc[i]['longitude']]\n            tmp.append(gps_distance(district_pos, obj_pos))\n        df[place] = tmp\n    return df\ndf_train = sights_feature(df_train, df_sights)","d4aeeda2":"fig, axes = plt.subplots(nrows=7, ncols=3, figsize=(12, 27))\nsubset = df_train.iloc[:,37:].columns.tolist()\nfor ax, feature in tqdm.tqdm_notebook(zip(axes.reshape(-1,1).tolist(), subset)):\n    sns.scatterplot(np.log(df_train[feature]),df_train['log_price'],ax=ax[0])\nplt.tight_layout()","903f70e6":"df_dummies = pd.get_dummies(df_train[df_train.select_dtypes('object').columns.tolist()])\n\nfor c in df_dummies.columns.tolist():\n    df_train[c]=None\ndf_train[df_dummies.columns.tolist()] = df_dummies.values\nfor c in df_train.select_dtypes('object').columns.tolist():\n    del df_train[c]","51776251":"# \u0417\u0430\u043f\u0438\u0448\u0435\u043c \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u044c 3 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432\nn = df_train.shape[0]\nnullable = []\nfor c in df_train.columns.tolist():\n    if df_train[~df_train[c].isnull()].shape[0]!=n:\n        nullable.append(c)\n\nnullable_dict = dict()\nnullable_dict['zero'] = dict()\nnullable_dict['mean'] = dict()\nnullable_dict['median'] = dict()\nfor c in nullable:\n    nullable_dict['zero'][c] = 0\n    nullable_dict['mean'][c] = df_train[c].mean()\n    nullable_dict['median'][c] = df_train[c].median()\n    \n# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0441\u043e \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f\u043c\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438\nwith open('fill_value_strategies.pkl', 'wb') as f:\n    pickle.dump(nullable_dict, f)","bcf674a3":"def fill_na(df, nullable_dict, strategy):\n    fill_dict = nullable_dict[strategy]\n    for c in list(fill_dict.keys()):\n        df[c].fillna(fill_dict[c], inplace=True)\n    return df\n\ndef preprocess_data(data, strategy, scaler_type='standard'):\n    \n    scalers = {'standard':StandardScaler(),\n               'robust':RobustScaler(),\n               'minmax':MinMaxScaler()}\n    \n    scaler = scalers[scaler_type]\n    data2 = data.copy(deep=True)\n    data2 = fill_na(data2, nullable_dict, strategy)\n    cols_ = data2.columns.tolist()\n    for c in ['id','log_price', 'price']:\n        try:\n            cols_.remove(c)\n        except:\n            pass\n    scaler.fit(data2[cols_])\n    data2[cols_] = scaler.transform(data2[cols_])\n    \n    y_train = data2['log_price']\n\n    cols = data2.columns.tolist()\n    for c in ['id','price', 'log_price']:\n        try:\n            cols.remove(c)\n        except:\n            pass\n    return data2.loc[:,cols], y_train, cols, scaler","fd81f75f":"mmt_instance = mmt.MasterTable(**mmt_dict)\ndf_train = mmt_instance.make_train(with_dummy=True)","386bdbc8":"def cv_result(model, X, y, cv=5,scoring='neg_mean_squared_error'):\n    nmse = cross_val_score(model, X, y, cv=cv, scoring=scoring) \n    rmse = [(-x)**0.5 for x in nmse]\n    print(f'CrossVal RMSE: {np.mean(rmse)}')\n    model.fit(X,y)\n    print(f'Intercept:{model.intercept_}')\n    stat = [X.columns.tolist(), model.coef_.tolist()]\n    res = pd.DataFrame({'Coef':stat[1]}, index=stat[0])\n    res.sort_values(by=['Coef'], inplace=True, ascending=False)\n    return res","d2bdee79":"df_train2, y_train, cols, _ = preprocess_data(df_train, 'zero')","31c854d6":"reg = LinearRegression()\ncv_result(reg, df_train2.loc[:,cols[:21]], y_train)","7162195f":"reg = LinearRegression()\ncv_result(reg, df_train2.loc[:,cols], y_train)","e745255f":"def regulizer_alpha(model, X, y, alphas, cv=5, scoring='neg_mean_squared_error', return_data=False):\n    models = [model(a) for a in alphas]\n    res = [cross_val_score(model, X, y, cv=cv, scoring=scoring) for model in models]\n    mean_rmse = [np.mean((-x)**0.5) for x in res]\n    \n    fig = plt.figure(figsize = (6,4))\n    plt.plot(alphas, mean_rmse, label ='Mean CV RMSE')\n    plt.xlabel('Alpha coefficient')\n    plt.ylabel('Mean RMSE')\n    plt.legend()\n    plt.title('\u0417\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c Mean CV RMSE \u043e\u0442 alpha.'+\\\n              f'\\n\u041e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435: {alphas[np.argmin(mean_rmse)]} | RMSE: {min(mean_rmse)}')\n    print(f'RMSE: {min(mean_rmse)}| alpha: {alphas[np.argmin(mean_rmse)]}')\n    plt.show()\n    if return_data:\n        return mean_rmse","e2c82e66":"# Ridge: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Ridge, df_train2.loc[:,cols[:21]], y_train, np.arange(0.05, 50, 0.5))","f9e13f60":"# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(0.05, 50, 0.5))","10f24ca5":"# Lasso: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Lasso, df_train2.loc[:,cols[:21]], y_train, np.arange(0.001, 20, 0.05))","1a3d8e54":"# Lasso: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Lasso, df_train2.loc[:,cols], y_train, np.arange(0.001, 20, 0.05))","0a10034f":"# \u041d\u0430\u0441\u0442\u0440\u043e\u0438\u043c Ridge \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0442\u043e\u0447\u043d\u0435\u0435\n# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(1e-4, 2, 5e-3))","ab845e65":"df_train2, y_train,_ , _ = preprocess_data(df_train, 'mean')","253db4a2":"# Ridge: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Ridge, df_train2.loc[:,cols[:21]], y_train, np.arange(0.05, 50, 0.5))","66fb8426":"# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(0.05, 50, 0.5))","a9ee9d71":"# Lasso: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Lasso, df_train2.loc[:,cols[:21]], y_train, np.arange(0.001, 20, 0.05))","1c10d1fb":"# Lasso: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Lasso, df_train2.loc[:,cols], y_train, np.arange(0.001, 20, 0.05))","d9c33125":"# \u041d\u0430\u0441\u0442\u0440\u043e\u0438\u043c Ridge \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0442\u043e\u0447\u043d\u0435\u0435\n# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(1e-4, 2, 5e-3), return_data=False)","90a4a115":"df_train2, y_train, _, _ = preprocess_data(df_train, 'median')","f495c8d6":"# Ridge: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Ridge, df_train2.loc[:,cols[:21]], y_train, np.arange(0.05, 50, 0.5))","2c1edc64":"# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(0.05, 50, 0.5))","4e935261":"# Lasso: \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\nregulizer_alpha(Lasso, df_train2.loc[:,cols[:21]], y_train, np.arange(0.001, 20, 0.05))","2af6147f":"# Lasso: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Lasso, df_train2.loc[:,cols], y_train, np.arange(0.001, 20, 0.05))","8d5096a1":"# \u041d\u0430\u0441\u0442\u0440\u043e\u0438\u043c Ridge \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0442\u043e\u0447\u043d\u0435\u0435\n# Ridge: \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0433\u0435\u043e\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nregulizer_alpha(Ridge, df_train2.loc[:,cols], y_train, np.arange(1e-4, 2, 5e-3))","26575db8":"df_train2, y_train, _, _ = preprocess_data(df_train, 'zero')","6dc38af6":"ridge = Ridge(0.0001)\ndf_ridge = cv_result(ridge, df_train2.loc[:,cols], y_train)\ndf_ridge.head(20)","79b853d8":"lasso = Lasso(0.001)\ndf_lasso = cv_result(lasso, df_train2.loc[:,cols], y_train)\ndf_lasso.head(20)","ffad05e4":"df_train2, y_train, _, _ = preprocess_data(df_train, 'zero')","124fdf76":"def cvknn_result(X, y, **kwargs):\n    rmses = []\n    for k in tqdm.tqdm_notebook(kwargs['k']):\n        model = KNeighborsRegressor(n_neighbors=k,\n                                    metric=kwargs['metric'],\n                                    metric_params=kwargs['param'])\n        nmse = cross_val_score(model, X, y, cv=kwargs['cv'], \\\n                               scoring=kwargs['scoring']) \n        rmse = [(-x)**0.5 for x in nmse]\n        rmses.append(np.mean(rmse))\n                                                  \n    fig, ax = plt.subplots()\n    ax.plot(kwargs['k'], rmses)\n    plt.title(f'Optimal neighbours: {1 + np.argmin(rmses)}'+\\\n              f'\\nCV RMSE: {rmses[np.argmin(rmses)]}')\n    ax.set_xlabel('Number of neighbours')\n    ax.set_ylabel('CV RMSE')\n    print(f'RMSE: {rmses[np.argmin(rmses)]} | k: {1 + np.argmin(rmses)}')\n    plt.show()","aa033b1a":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols[:21]], y_train, **params_dict)","8837a2cf":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols], y_train, **params_dict)","8b85a45e":"df_train2, y_train, _, _ = preprocess_data(df_train, 'mean')","72c8e1e8":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols[:21]], y_train, **params_dict)","7ef6d84b":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols], y_train, **params_dict)","cb45feba":"df_train2, y_train, _, _ = preprocess_data(df_train, 'median')","5c6697cd":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols[:21]], y_train, **params_dict)","df78e468":"params_dict = {'k': np.arange(1, 31), 'metric':'minkowski',\n               'param':{'p': 2}, 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncvknn_result(df_train2.loc[:,cols], y_train, **params_dict)","c100679f":"def cv_random_forest(X, y, **kwargs):\n    rmses = []\n    trees = kwargs['trees']\n    for k in tqdm.tqdm_notebook(trees):\n        model = RandomForestRegressor(random_state=42,n_estimators=k)\n        nmse = cross_val_score(model, X, y, cv=kwargs['cv'], \\\n                               scoring=kwargs['scoring']) \n        rmse = [(-x)**0.5 for x in nmse]\n        rmses.append(np.mean(rmse))\n                                                  \n    fig, ax = plt.subplots()\n    ax.plot(kwargs['trees'], rmses)\n    \n    plt.title(f'Optimal trees: {trees[np.argmin(rmses)]}'+\\\n              f'\\nCV RMSE: {rmses[np.argmin(rmses)]}')\n    ax.set_xlabel('Number of trees')\n    ax.set_ylabel('CV RMSE')\n    print(f'RMSE: {rmses[np.argmin(rmses)]} | Trees: {trees[np.argmin(rmses)]}')\n    plt.show()","1d09fc09":"df_train2, y_train, _, _ = preprocess_data(df_train, 'zero')","1feb8fb0":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols[:21]], y_train, **params_dict)","93c23ed6":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols], y_train, **params_dict)","a499eb0b":"df_train2, y_train, _, _ = preprocess_data(df_train, 'mean')","6cad638d":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols[:21]], y_train, **params_dict)","6ad3a5f0":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols], y_train, **params_dict)","053cd6ad":"df_train2, y_train, _, _ = preprocess_data(df_train, 'median')","dd4e4c01":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols[:21]], y_train, **params_dict)","2fd3b779":"params_dict = {'trees': np.arange(5, 201, 20), 'cv':5,\n               'scoring':'neg_mean_squared_error'}\ncv_random_forest(df_train2.loc[:,cols], y_train, **params_dict)","3421b8b8":"df_train2, y_train, cols, _ = preprocess_data(df_train, 'zero')","bc1c2c9a":"def rf_randomized_cv_search(X, y, **kwargs):\n    rf = RandomForestRegressor()\n    rf_random = RandomizedSearchCV(estimator = rf,\n                                   param_distributions = kwargs['random_grid'], \n                                   n_iter = kwargs['iter'], cv = kwargs['cv'],\n                                   verbose=kwargs['verbose'], random_state=42, n_jobs = -1)\n    rf_random.fit(X, y)\n    best_params = rf_random.best_estimator_\n\n    # CV RMSE\n    model = RandomForestRegressor(random_state=42, n_estimators=kwargs['n_estimators'],\n                                  max_features=best_params.max_features,\n                                  max_depth=best_params.max_depth,\n                                  min_samples_split=best_params.min_samples_split,\n                                  min_samples_leaf=best_params.min_samples_leaf,\n                                  bootstrap=best_params.bootstrap)\n    nmse = cross_val_score(model, X, y, cv=kwargs['cv'], \\\n                               scoring=kwargs['scoring']) \n    rmse = [(-x)**0.5 for x in nmse]\n    print(f'RMSE: {np.mean(rmse)}')\n    print(f'CV list: {rmse}')\n    \n    return best_params","794467d1":"max_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nSTEPS = 15\nrandom_grid = {\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap\n              }\nparams_dict = {'random_grid':random_grid,\n               'cv':5, 'iter':STEPS,'verbose':2,\n               'scoring':'neg_mean_squared_error', 'n_estimators':145}","2aea0aef":"best = rf_randomized_cv_search(df_train2.loc[:,cols], y_train,**params_dict)","7312c8b3":"rf_explainer = shap.TreeExplainer(best)\nshap_values = rf_explainer.shap_values(df_train2.loc[:,cols], approximate=True)","809332ea":"shap.summary_plot(shap_values, df_train2.loc[:,cols])","379a5ec8":"shap.summary_plot(shap_values, df_train2.loc[:,cols], plot_type=\"bar\")","1fd649b4":"class RFHyperoptSearch:\n    def __init__(self, X, y, cv):\n        super(RFHyperoptSearch, self).__init__()\n        self.X = X\n        self.y = y\n        self.cv = cv\n        \n    def rmse(self, y, y_pred):\n        return np.sqrt(np.mean((y_pred - y)**2))\n    \n    def eval_func(self, params):\n        \n        for k in list(params.keys()):\n            if k=='min_weight_fraction_leaf':\n                pass\n            params[k] = int(round(params[k],0))\n        \n        model = RandomForestRegressor(**params, random_state=42)\n        scoring_rmse = make_scorer(self.rmse, greater_is_better=False)\n        rmse = -cross_val_score(model, self.X, self.y, cv=self.cv, \\\n                                scoring=scoring_rmse)\n        return np.mean(rmse)","433f5c29":"params_space = {'max_depth': hyperopt.hp.uniform('max_depth', 100, 200),\n                'n_estimators': hyperopt.hp.uniform('n_estimators', 140, 160),\n                'min_samples_split': hyperopt.hp.uniform('min_samples_split', 2, 40),\n                'min_samples_leaf': hyperopt.hp.uniform('min_samples_leaf', 2, 30)}\n\nhyperopt_inst = RFHyperoptSearch(df_train2.loc[:,cols], y_train, 5)\ntrials = hyperopt.Trials()\nbest = hyperopt.fmin(\n    hyperopt_inst.eval_func,\n    space=params_space,\n    algo=hyperopt.tpe.suggest,\n    max_evals=10,\n    trials=trials,\n    rstate=np.random.RandomState(42)\n)\nprint(best)","fb3f98dc":"best","30d1053e":"best['n_estimators'] = int(best['n_estimators'])\nbest['min_samples_leaf'] = int(best['min_samples_leaf'])\nbest['min_samples_split'] = int(best['min_samples_split'])\nrf = RandomForestRegressor(**best, random_state=42)\nrf.fit(df_train2.loc[:,cols], y_train)\nrf_explainer = shap.TreeExplainer(rf)\nshap_values = rf_explainer.shap_values(df_train2.loc[:,cols], approximate=True)","46137354":"shap.summary_plot(shap_values, df_train2.loc[:,cols])","356ff53a":"shap.summary_plot(shap_values, df_train2.loc[:,cols], plot_type=\"bar\")","9156d949":"mmt_instance = mmt.MasterTable(**mmt_dict)\ndf_train = mmt_instance.make_train(with_dummy=True)","5b9f3559":"df_train2, y_train2, _ , boost_scaler = preprocess_data(df_train, 'zero')\n\nX_train, X_val, y_train, y_val = train_test_split(df_train2, y_train2, test_size=VAL_SIZE,\n                                                  random_state=42, shuffle=True)","330790d1":"class HyperOpt:\n    def __init__(self, **kwargs):\n        super(HyperOpt, self).__init__()\n        self.kwargs = kwargs\n       \n    def hyperopt_xgb_score(self, params):\n        \n        model = XGBRegressor(l2_leaf_reg=int(params['l2_leaf_reg']),\n                             learning_rate=params['learning_rate'],\n                             max_depth=int(params['max_depth']),\n                             gamma = params['gamma'],\n                             reg_alpha = params['reg_alpha'],\n                             reg_lambda = params['reg_lambda'],\n                             n_estimators=self.kwargs['n_estimators'],\n                             objective='reg:squarederror',\n                             verbosity=0,\n                             random_seed=42,\n                             task_type=DEVICE)\n        fit_params={'early_stopping_rounds': self.kwargs['rounds'], \n                    'eval_metric': 'rmse',\n                    'verbose': self.kwargs['verbose'],\n                    'eval_set': [[self.kwargs['X_val'],  self.kwargs['y_val']]]}\n        \n        xgb_cv = cross_val_score(model, self.kwargs['X_train'], self.kwargs['y_train'], \n                                 cv = self.kwargs['cv'], \n                                 scoring = 'neg_mean_squared_error',\n                                 fit_params = fit_params)\n        best_rmse = np.mean([(-x)**0.5 for x in xgb_cv])\n        print(f'Best RMSE: {best_rmse}', params)\n        return best_rmse\n    \n    def hyperopt_catb_score(self, params):\n        model = CatBoostRegressor(l2_leaf_reg=int(params['l2_leaf_reg']),\n                                  learning_rate=params['learning_rate'],\n                                  iterations=self.kwargs['iterations'],\n                                  ignored_features = self.kwargs['ignored_features'],\n                                  eval_metric='RMSE',\n                                  random_seed=42,\n                                  task_type=DEVICE,\n                                  logging_level='Silent'\n                                 )\n    \n        cv_data = cv(Pool(self.kwargs['X_train'], self.kwargs['y_train'], \n                          cat_features=self.kwargs['categorical_features_indices']),\n                     model.get_params())\n        best_rmse = np.min(cv_data['test-RMSE-mean'])\n        return best_rmse\n    \n    def hyperopt_lgbm_score(self, params):\n        model = LGBMRegressor(learning_rate=params['learning_rate'],\n                              max_depth=int(params['max_depth']),\n                              n_estimators=int(self.kwargs['n_estimators']),\n                              subsample=params['subsample'],\n                              reg_alpha = params['reg_alpha'],\n                              reg_lambda = params['reg_lambda'],\n                              silent = True,\n                              metric='rmse',\n                              random_state=42)\n        \n        fit_params={'early_stopping_rounds': self.kwargs['rounds'], \n                    'eval_metric': 'rmse',\n                    'verbose': self.kwargs['verbose'],\n                    'eval_set': [[self.kwargs['X_val'],  self.kwargs['y_val']]]}\n        \n        lgb_cv = cross_val_score(model, self.kwargs['X_train'], self.kwargs['y_train'], \n                                 cv = self.kwargs['cv'], \n                                 scoring = 'neg_mean_squared_error',\n                                 fit_params = fit_params)\n        \n        best_rmse = np.mean([(-x)**0.5 for x in lgb_cv])\n        print(f'Best RMSE: {best_rmse}', params)\n        return best_rmse","9c93c919":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0441 \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438, 1500 \u0434\u0435\u0440\u0435\u0432\u044c\u044f\u043c\u0438 \u0438 \u0440\u0430\u043d\u043d\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u043e\u0439\nparams = {'n_estimators':1500,\n          'objective':'reg:squarederror',\n          'random_seed':42,\n          'verbosity':0,\n          'task_type': DEVICE,\n          'early_stopping_rounds':50}\ngbm = XGBRegressor(**params)\ngbm.fit(X_train,y_train, eval_set=[[X_val, y_val]])","63444d40":"nlistgbm, implistgbm = [], []\nfor n, imp in zip(X_train.columns.tolist(), gbm.feature_importances_):\n    nlistgbm.append(n)\n    implistgbm.append(imp)\n    \ndf_impgbm = pd.DataFrame({'Feature':nlistgbm, 'Importance': implistgbm})\ndf_impgbm.sort_values(by=['Importance'], ascending=False).head(20)","8237acd4":"min(gbm.evals_result_['validation_0']['rmse'])","f54fcc9b":"best = {'gamma': 0.15340366103115533,\n 'l2_leaf_reg': 2.0,\n 'learning_rate': 0.00853890793354474,\n 'max_depth': 5.971733628773733,\n 'reg_alpha': 1.8400184528746324,\n 'reg_lambda': 1.0868061353806249}","71fab481":"# \u041e\u0431\u0443\u0447\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nparams = {'n_estimators':2200,\n          'objective':'reg:squarederror',\n          'random_seed':42,\n          'verbosity':0,\n          'task_type':DEVICE}\n\nbest['max_depth'] = round(best['max_depth'])\nparams.update(best)\nprint(params)\n\ngbm = XGBRegressor(**params)\n# \u0412\u044b\u0434\u0435\u043b\u0438\u043c \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438\nX_train, X_val, y_train, y_val = train_test_split(df_train2, y_train2,\n                                                  test_size=VAL_SIZE, random_state=42,\n                                                  shuffle=True)\ngbm.fit(X_train,y_train, eval_set=[[X_val, y_val]])","7edf7cc0":"nlistgbm, implistgbm = [], []\nfor n, imp in zip(X_train.columns.tolist(), gbm.feature_importances_):\n    nlistgbm.append(n)\n    implistgbm.append(imp)\n    \ndf_impgbm = pd.DataFrame({'Feature':nlistgbm, 'Importance': implistgbm})\ndf_impgbm.sort_values(by=['Importance'], ascending=False).head(20)","907e5ae1":"xgb_explainer = shap.TreeExplainer(gbm)\nshap_values = xgb_explainer.shap_values(X_val, approximate=True)","d96cf35e":"shap.summary_plot(shap_values, X_val)","5704e970":"shap.summary_plot(shap_values, X_val, plot_type=\"bar\")","69d2ab61":"test_to_submit = mmt_instance.make_test(with_dummy=True)","0e2446b5":"def process_test_data(scaler, test_data):\n    test_data.fillna(value=0, inplace=True)\n    test_id = test_data['id'].copy(deep=True)\n    try:\n        del test_data['id']\n    except:\n        pass\n    \n    columns = test_data.columns.tolist()\n    for c in test_data.select_dtypes('object').columns.tolist():\n        columns.remove(c)\n    test_data[columns] = scaler.transform(test_data[columns])\n    return test_data, test_id\n\ndef predict_test(test_data, model):\n    result = model.predict(test_data)\n    # \u0414\u043b\u044f \u0432\u043e\u0437\u0432\u0440\u0430\u0442\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u0439 \u0446\u0435\u043d\u044b \u0432\u043e\u0437\u0432\u0435\u0434\u0435\u043c \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c \u0432 exp\n    return np.exp(result) ","5d1ca6ac":"test_to_submit_processed, test_to_submit_id = process_test_data(boost_scaler, test_to_submit)\npred = predict_test(test_to_submit_processed, gbm)\n\nsubmit_result_xgb = pd.DataFrame({'Id':test_to_submit_id.values,\n                                  'Predicted':pred})\nsubmit_result_xgb = correct_test(submit_result_xgb)\nsubmit_result_xgb.to_csv('xgb_submit_kaggle.csv', index=False)","07b0fcfb":"mmt_instance = mmt.MasterTable(**mmt_dict)\ndf_train = mmt_instance.make_train(with_dummy=False)","f1f76f4b":"def catboost_data_preparation(data):\n    try:\n        del data['id']\n    except:\n        pass\n    data.fillna(value=0, inplace=True)\n    data_cols = data.columns.tolist()\n    categorical_features_indices = [data_cols.index(x) for x in data.select_dtypes('object').columns.tolist()]\n    \n    #for x in data.columns.tolist():\n        #print(x, data[~data[x].isnull()].shape)\n    # \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n    scaler = StandardScaler()\n    cols = data.columns.tolist()\n    for c in data.select_dtypes('object').columns.tolist()+['price', 'log_price']:\n        cols.remove(c)\n    data[cols] = scaler.fit_transform(data[cols])\n    return categorical_features_indices, cols, scaler, data\ncategorical_features_indices, catbs_cols, catb_scaler, data = catboost_data_preparation(df_train)","cfddcc35":"categorical_features_indices","f15dad0d":"X_train, X_val, y_train, y_val = train_test_split(df_train, df_train['log_price'],\n                                                  test_size=VAL_SIZE, random_state=42,\n                                                  shuffle=True)","23aeed2e":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0441 \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nparams = {'iterations': 3000,\n          'loss_function': 'RMSE',\n          'eval_metric': 'RMSE',\n          'ignored_features':['price', 'log_price'],\n          'use_best_model': True,\n          'logging_level': 'Silent',\n          'task_type': DEVICE}\n   \ncatb = CatBoostRegressor(**params)\ntrain_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\nvalidate_pool = Pool(X_val, y_val, cat_features=categorical_features_indices)\ncatb.fit(train_pool, eval_set=validate_pool)","b8760c34":"nlist, implist = [], []\nfor n, imp in zip(catb.feature_names_, catb.feature_importances_):\n    nlist.append(n)\n    implist.append(imp)\n    \ndf_imp = pd.DataFrame({'Feature':nlist, 'Importance': implist})\ndf_imp.sort_values(by=['Importance'], ascending=False).head(20)","8bb82aee":"catb.best_score_","55506c68":"best = {'l2_leaf_reg': 6.0, 'learning_rate': 0.08390144719977513}","96f487dd":"# \u0418\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nparams = {\n    'iterations': 2200,\n    'learning_rate': 0.003,\n    'l2_leaf_reg': 2.0,\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'ignored_features':['price', 'log_price'],\n    'task_type': DEVICE}\n\nparams.update(best)\nparams.update({'use_best_model': True})\n    \n# \u0412\u044b\u0434\u0435\u043b\u0438\u043c \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438\nX_train, X_val, y_train, y_val = train_test_split(data, data['log_price'],test_size=VAL_SIZE, \n                                                  random_state=42, shuffle=True)\ncatb = CatBoostRegressor(**params)\ntrain_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\nvalidate_pool = Pool(X_val, y_val, cat_features=categorical_features_indices)\ncatb.fit(train_pool, eval_set=validate_pool)","a7b5da86":"nlist, implist = [], []\nfor n, imp in zip(catb.feature_names_, catb.feature_importances_):\n    nlist.append(n)\n    implist.append(imp)\n    \ndf_imp = pd.DataFrame({'Feature':nlist, 'Importance': implist})\ndf_imp.sort_values(by=['Importance'], ascending=False).head(20)","b556f638":"catb_explainer = shap.TreeExplainer(catb)\nshap_values = catb_explainer.shap_values(validate_pool)","86b1cc13":"shap.summary_plot(shap_values, X_val)","0509af0a":"shap.summary_plot(shap_values, X_val, plot_type=\"bar\")","a1f3c2dc":"test_to_submit = mmt_instance.make_test(with_dummy=False)\n\ntest_to_submit_processed, test_to_submit_id = process_test_data(catb_scaler, test_to_submit)\n\n# \u0414\u043b\u044f catboost \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0432\u0441\u0435\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432, \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\u0445 \u0442\u0440\u0435\u0439\u043d\u0443. \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e:\ntest_to_submit_processed['price'] = 0\ntest_to_submit_processed['log_price'] = 0\ntest_to_submit_processed = test_to_submit_processed[X_train.columns.tolist()]","ae3b1d6c":"pred = predict_test(test_to_submit_processed, catb)\n\nsubmit_result_catb = pd.DataFrame({'Id':test_to_submit_id.values,\n                                   'Predicted':pred})\nsubmit_result_catb = correct_test(submit_result_catb)\nsubmit_result_catb.to_csv('catb_submit_kaggle.csv',index=False)","4a19e716":"df_train = mmt_instance.make_train(with_dummy=True)\n\ndf_train2, y_train2, _ , boost_scaler = preprocess_data(df_train, 'zero', 'standard')\nX_train, X_val, y_train, y_val = train_test_split(df_train2, y_train2, test_size=VAL_SIZE,\n                                                  random_state=42, shuffle=True)","db930d8c":"## \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0441 \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nparams = {'n_estimators':1500,\n          'random_seed':42,\n          'metric':'rmse',\n          'silent':True,\n          'early_stopping_rounds':50\n         }\nlgbm = LGBMRegressor(**params)\nlgbm.fit(X_train, y_train, eval_set=[[X_val, y_val]])","6666dab9":"nlistlgbm, implistlgbm = [], []\nfor n, imp in zip(X_train.columns.tolist(), lgbm.feature_importances_):\n    nlistlgbm.append(n)\n    implistlgbm.append(imp)\n    \ndf_implgbm = pd.DataFrame({'Feature':nlistlgbm, 'Importance': implistlgbm})\ndf_implgbm.sort_values(by=['Importance'], ascending=False).head(20)","e255188c":"lgbm.best_score_","9a376d9d":"best = {'learning_rate': 0.00865486636310301, \n        'max_depth': 14.36591078571328, \n        'reg_alpha': 0.6068202197683499, \n        'reg_lambda': 1.766630554761724, \n        'subsample': 0.8373883555532842}","d358ab7d":"# \u041e\u0431\u0443\u0447\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nparams = {'n_estimators':1500,\n          'random_seed':42,\n          'metric':'rmse',\n          'early_stopping_rounds':50\n         }\n\nbest['max_depth'] = int(best['max_depth'])\nparams.update(best)\nprint(params)\n\nlgbm = LGBMRegressor(**params)\n# \u0412\u044b\u0434\u0435\u043b\u0438\u043c \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438\nX_train, X_val, y_train, y_val = train_test_split(df_train2, y_train2,\n                                                  test_size=VAL_SIZE, random_state=42,\n                                                  shuffle=True)\nlgbm.fit(X_train,y_train, eval_set=[[X_val, y_val]])","84946276":"lgbm_explainer = shap.TreeExplainer(lgbm)\nshap_values = lgbm_explainer.shap_values(X_val)","c87b2f4f":"shap.summary_plot(shap_values, X_val)","9d736828":"shap.summary_plot(shap_values, X_val, plot_type=\"bar\")","0a6536f5":"test_to_submit = mmt_instance.make_test(with_dummy=True)\n\ntest_to_submit_processed, test_to_submit_id = process_test_data(boost_scaler, test_to_submit)\npred = predict_test(test_to_submit_processed, lgbm)\n\nsubmit_result_lgbm = pd.DataFrame({'Id':test_to_submit_id.values,\n                                  'Predicted':pred})\n\nsubmit_result_lgbm = correct_test(submit_result_lgbm)\nsubmit_result_lgbm.to_csv('lgbm_submit_kaggle.csv',index=False)","a8e73c4b":"\u0412 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0435\u0441\u0442\u044c \u043d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438: __`Castle, Barn, Train`__. \u0417\u0430\u043c\u043e\u043a \u0431\u0443\u0434\u0435\u0442 \u0441\u0442\u043e\u0438\u0442\u044c \u0437\u043d\u0430\u0447\u0438\u043c\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 \u0436\u0438\u043b\u044c\u044f, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0438\u0437\u043c\u0435\u043d\u0438\u043c \u0435\u0433\u043e \u043d\u0430 \u043a\u0430\u0442\u0435\u043e\u0440\u0438\u044e \u0441 \u043d\u0430\u0438\u0432\u044b\u0441\u0448\u0435\u0439 \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439 \u0446\u0435\u043d\u044b - Treehouse.\n\u041e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0442\u0438\u043f\u044b \u0436\u0438\u043b\u044c\u044f - `Train` \u0438 `Barn` \u043d\u0435\u0434\u043e\u0440\u043e\u0433\u0438\u0435, \u0438\u0445 \u043c\u043e\u0436\u043d\u043e \u0432\u043d\u0435\u0441\u0442\u0438 \u0432 `Hostel`.","5d72efe4":"\u041d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0439 \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0430 \u0446\u0435\u043d\u044b. ","b531f464":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0441\u0440\u0435\u0434\u043d\u0438\u043c","b2484e22":"__\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0441\u0440\u0435\u0434\u043d\u0438\u043c:__","d84cfd54":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043e\u0431\u044b\u0447\u043d\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e \u0441 \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u044b\u043c \u043d\u0430\u0431\u043e\u0440\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u0431\u0435\u0437 \u043d\u0435\u0433\u043e. __\u041f\u0435\u0440\u0432\u0438\u0447\u043d\u0430 \u0441\u0442\u0440\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 - \u043d\u0443\u043b\u044f\u043c\u0438.__","83fdf7c1":"\u0418\u0441\u0445\u043e\u0434\u044f \u0438\u0437 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439, \u043c\u043e\u0436\u043d\u043e \u0441\u043a\u0430\u0437\u0430\u0442\u044c \u0447\u0442\u043e \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u044c \u0438\u043c\u0435\u044e\u0442:\n\n            \u043a\u043e\u043b-\u0432\u043e \u0437\u0430\u0441\u0435\u043b\u044f\u0435\u043c\u044b\u0445 \u0438 \u043a\u043e\u043b-\u0432\u043e \u0432\u0430\u043d\u043d\u044b\u0445 \u043a\u043e\u043c\u043d\u0430\u0442,\n            \u043a\u043e\u043b-\u0432\u043e \u0437\u0430\u0441\u0435\u043b\u044f\u0435\u043c\u044b\u0445 \u0438 \u043a\u043e\u043b-\u0432\u043e \u0441\u043f\u0430\u043b\u044c\u043d\u044b\u0445 \u043a\u043e\u043c\u043d\u0430\u0442, \n            \u043a\u043e\u043b-\u0432\u043e \u0437\u0430\u0441\u0435\u043b\u044f\u0435\u043c\u044b\u0445 \u0438 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u0440\u043e\u0432\u0430\u0442\u0435\u0439, \n            \u043a\u043e\u043b-\u0432\u043e \u0437\u0430\u0441\u0435\u043b\u044f\u0435\u043c\u044b\u0445 \u0438 \u0446\u0435\u043d\u0430. \n\n\u042d\u0442\u0438 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0435 \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0438 \u043b\u0435\u0433\u043a\u043e \u043b\u043e\u0433\u0438\u0447\u043d\u043e \u043e\u0431\u044a\u044f\u0441\u043d\u0438\u043c\u044b, \u0442\u0430\u043a \u043a\u0430\u043a \u043e\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043b\u044e\u0434\u0435\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0445\u043e\u0442\u044f\u0442 \u0441\u043d\u044f\u0442\u044c \u0436\u0438\u043b\u044c\u0435, \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0435 \u043a\u043e\u043b-\u0432\u043e \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0430, \u0447\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u043c\u0435\u0442\u0440\u0430\u0436, \u0442\u0435\u043c, \u0441\u043a\u043e\u0440\u0435\u0435 \u0432\u0441\u0435\u0433\u043e, \u0435\u0433\u043e \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0431\u0443\u0434\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0435.\n\u0422\u0430\u043a\u0436\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u044c \u0435\u0441\u0442\u044c \u043c\u0435\u0436\u0434\u0443: `review_scores_rating` \u0438 \u0435\u0433\u043e \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0449\u0438\u043c\u0438.","df0c4bf5":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u043a\u0430\u043a\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043c\u043e\u0436\u043d\u043e \u0432\u044b\u0434\u0435\u043b\u0438\u0442\u044c \u043a\u0430\u043a \u043b\u0438\u043d\u0435\u0439\u043d\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0446\u0435\u043d\u044b.","eba32783":" boxplot \u043f\u043e \u0446\u0435\u043d\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, \u0447\u0442\u043e \u0432 \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0435\u0441\u0442\u044c \u0432\u044b\u0431\u0440\u043e\u0441\u044b, \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e \u0432\u044b\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u0447\u0435\u043d\u044c \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439. \u0421\u043a\u043e\u0440\u0435\u0435 \u0432\u0441\u0435\u0433\u043e \u044d\u0442\u043e \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u0441\u0434\u0430\u0447\u0435 \u0434\u043e\u0440\u043e\u0433\u0438\u0445 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u043e\u0432 \u0438\u043b\u0438 \u0446\u0435\u043b\u044b\u0445 \u0437\u0434\u0430\u043d\u0438\u0439, \u043b\u0438\u0431\u043e \u0441\u0438\u0441\u0442\u0435\u043c\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f.\n \n\u041f\u0440\u043e\u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u0432 \u0446\u0435\u043d\u0443 \u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0432 boxplot, \u043c\u043e\u0436\u043d\u043e \u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u0447\u0442\u043e \u043c\u0435\u0434\u0438\u0430\u043d\u0430 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e 125. \u0415\u0441\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, \u0446\u0435\u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u0435\u043d\u044c\u0448\u0435 \u043f\u0435\u0440\u0432\u043e\u0439 \u043a\u0432\u0430\u0440\u0442\u0438\u043b\u0438. ","2bde073f":"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433, \u043a\u0430\u043a \u0438 \u043f\u043e\u043b\u0430\u0433\u0430\u0435\u0442\u0441\u044f, \u0432 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u043c\u0435\u0440\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044e \u0442\u0438\u043f\u0430 \u0436\u0438\u043b\u044c\u044f, \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u0438 \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u0433\u043e \u0440\u0430\u0439\u043e\u043d\u0430 \u0433\u043e\u0440\u043e\u0434\u0430 \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u0446\u0435\u043d\u044b, \u0434\u0430\u043b\u0435\u0435 \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e xgboost, \u0446\u0435\u043d\u0430 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442\u0441\u044f \u0447\u0438\u0441\u043b\u043e\u043c \u0441\u043f\u0430\u043b\u0435\u043d, \u043e\u0434\u043d\u0430\u043a\u043e \u043f\u043e\u043b\u0438\u0442\u0438\u043a\u0430 \u043e\u0442\u043c\u0435\u043d\u044b \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0438 \u0441\u0440\u0435\u0434\u043d\u0435\u043c\u0435\u0441\u044f\u0447\u043d\u044b\u0435 \u043e\u0442\u0437\u044b\u0432\u044b \u0441\u0442\u0430\u043b\u0438 \u0431\u043e\u043b\u0435\u0435 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u043c\u0438.","592e8636":"<a id='rforest'><\/a>     \n### Random Forest\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","f8c8261b":"\u0411\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u043f\u043e \u0441\u0434\u0430\u0447\u0435 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u043d\u0435 \u0434\u0430\u043b\u044c\u0448\u0435 \u0447\u0435\u043c \u0432 10000 \u043c \u043e\u0442 \u0446\u0435\u043d\u0442\u0440\u0430 \u0433\u043e\u0440\u043e\u0434\u0430.","60362ddb":"\u041f\u0440\u0438\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442 5 \u043e\u0447\u0435\u043d\u044c \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0446\u0435\u043d\u044b. \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u0430\u0442 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u0430\u043c \u0432 \u0446\u0435\u043d\u0442\u0440\u0435 \u0433\u043e\u0440\u043e\u0434\u0430 \u0438 \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u043e\u043c\u0443 \u0434\u043e\u043c\u0443.","85f7f8e8":"\u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u0438\u043f\u044b \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u044e\u0442\u0441\u044f \u0432 \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u043c \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0435.","22114d08":"\u041d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0430 \u0434\u0438\u0441\u0442\u0430\u043d\u0446\u0438\u0438 \u0434\u043e \u0446\u0435\u043d\u0442\u0440\u0430 \u043e\u0442 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0430 \u0446\u0435\u043d\u044b.\n\n\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043f\u043e OpenStreet Map \u0438 Google Maps","55f849b9":" \u041f\u0440\u043e\u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u0432 \u0446\u0435\u043d\u0443, \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043e\u0442\u043a\u043b\u0438\u043a\u0430 \u0441\u0442\u0430\u043b\u043e \u0431\u043b\u0438\u0436\u0435 \u043a \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u043c\u0443. \u0426\u0435\u043d\u0430 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0435\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u0441\u043e\u0441\u0440\u0435\u0434\u043e\u0442\u043e\u0447\u0435\u043d\u0430 \u043c\u0435\u0436\u0434\u0443 90 \u0438 160. \u041f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u0441 \u0446\u0435\u043d\u043e\u0439 \u0434\u043e 60 \u0438 \u0431\u043e\u043b\u044c\u0448\u0435 250 \u043c\u0435\u043d\u044c\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u043d\u0430 \u0440\u044b\u043d\u043a\u0435.","fd7f6679":"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0446\u0435\u043d\u044b \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 0, \u0447\u0442\u043e \u043f\u043e\u0434\u043e\u0437\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0438 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u043e\u0439 \u0432 \u0434\u0430\u043d\u043d\u044b\u0445 airbnb, \u043b\u0438\u0431\u043e \u043a\u0430\u043a \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u043c\u043e\u0436\u0435\u0442 \u0432\u043d\u0435\u0441\u0442\u0438 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0432 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442. \u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u043c\u0435\u0434\u0438\u0430\u043d\u044b, \u0447\u0442\u043e \u0442\u043e\u0436\u0435 \u0433\u043e\u0432\u043e\u0440\u0438\u0442 \u043e \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0432\u044b\u0431\u0440\u043e\u0441\u0435.","fdda2a1f":"[](http:\/\/)<a id='conclusion'><\/a>\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)\n \n ### Conclusion\n \n \n\u0414\u043b\u044f \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447\u0438 \u043f\u043e \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044e \u0446\u0435\u043d\u044b \u043d\u0430 \u0436\u0438\u043b\u044c\u0435 \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c Airbnb \u0431\u044b\u043b\u0438 \u043f\u0440\u043e\u0442\u0435\u0441\u0442\u0440\u043e\u0432\u0430\u043d\u044b \u043c\u043e\u0434\u0435\u043b\u0438 \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438,\u0432 \u0442\u043e\u043c \u0447\u0438\u0441\u043b\u0435 \u0441 \u0443\u0447\u0451\u0442\u043e\u043c \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438 L1 \u0438 L2, k-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u0433\u043e \u0441\u043e\u0441\u0435\u0434\u0430, \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430, \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430 \u0432 \u0442\u0440\u0451\u0445 \u0440\u0430\u0441\u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u043d\u044b\u0445 \u0432\u0430\u0440\u0438\u0430\u0446\u0438\u044f\u0445.\n\n\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0438\u0437 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f - \u043c\u043e\u0434\u0435\u043b\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430.\n\n\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0435 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043d\u043e\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043d\u0430 leaderboard-\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043c\u043e\u0434\u0435\u043b\u0438 XGBoost \u043d\u0435\u0441\u043c\u043e\u0442\u0440\u044f \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e \u043f\u043e \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u043e 5 \u0444\u043e\u043b\u0434\u0430\u043c, \u043e\u043d \u0443\u0441\u0442\u0443\u043f\u0430\u043b LightGBM \u043c\u043e\u0434\u0435\u043b\u0438. \u042d\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u0433\u043e\u0432\u043e\u0440\u0438\u0442\u044c \u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0435\u0449\u0435 \u043c\u043e\u0436\u043d\u043e \u0443\u0447\u0435\u0441\u0442\u044c \u043f\u0440\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438. \u0421\u043e\u0432\u043c\u0435\u0441\u0442\u043d\u043e \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 `hyperopt` \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0434\u043e\u0441\u0442\u0438\u0447\u044c \u043e\u0448\u0438\u0431\u043a\u0438 __RMSE `127.86639`__ \u043d\u0430 70% leaderboard-\u0430.\n\n\u041e\u0441\u043d\u043e\u0432\u044b\u0432\u0430\u044f\u0441\u044c \u043d\u0430 \u0434\u0430\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438, \u0438 \u043c\u0435\u0442\u043e\u0434\u043e\u043b\u043e\u0433\u0438\u0438 `shap`-\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432\u043b\u0438\u044f\u043d\u0438\u044f \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u0432 \u043d\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043e\u0442\u043a\u043b\u0438\u043a\u0430, \u043c\u043e\u0436\u043d\u043e \u043f\u0435\u0440\u0435\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u0441\u0430\u043c\u044b\u0435 \u0432\u0430\u0436\u043d\u044b\u0435 \u0444\u0430\u043a\u0442\u043e\u0440\u044b \u0441 \u0442\u043e\u0447\u043a\u0438 \u0437\u0440\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u0444\u043e\u0440\u043c\u0438\u0440\u0443\u044e\u0449\u0438\u0445 \u0446\u0435\u043d\u0443 \u043d\u0430 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u044c Airbnb:\n`room_type_Entire_home\/apt, accommodates, bedrooms, bathrooms, reviews_per_month, extra_people`.\n\n\u041c\u0435\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u043c\u0438, \u043d\u043e \u043f\u043e\u0432\u043b\u0438\u044f\u0432\u0448\u0438\u043c\u0438 \u043d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u0441\u0442\u0430\u043b\u0438 \u0438 \u043d\u043e\u0432\u044b\u0435 \u0433\u0435\u043e\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u044b\u0435 \u0444\u0430\u043a\u0442\u043e\u0440\u044b:\n`St kilda Festival, National Gallery of Victoria, Royal Botanic Gardens, Healthville, Guys Hill, DFO South Wharf, Warbertone` - \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u044b\u0435 \u0440\u0430\u0439\u043e\u043d\u044b \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0430, \u043f\u0440\u0438\u0433\u043e\u0440\u043e\u0434\u043d\u044b\u0435 \u0437\u043e\u043d\u044b, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0442\u0443\u0440\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043c\u0435\u0441\u0442\u0430. \u0414\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0431\u043b\u0438\u0437\u043b\u0435\u0436\u0430\u0449\u0438\u0445 \u043f\u0430\u0440\u043a\u043e\u0432 \u043d\u0435 \u0434\u0430\u043b\u0438 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0440\u043e\u0441\u0442\u0430.","9a0eb976":"1. \u0414\u043b\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 `hyperopt`","7fd5cd5e":"\u0418\u0437\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0436\u0438\u043b\u044c\u044e \u043d\u0430 \u043a\u0430\u0440\u0442\u0435 \u0434\u043b\u044f df_train \u0438 df_test.","cf31f932":"<a id='xgboost'><\/a>     \n### XGBoost\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","93f9b862":"\u0412 \u043d\u0430\u0448\u0435\u043c \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0438 \u043f\u043e SHAP-\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c \u043f\u0440\u0438 \u0440\u0435\u0448\u0435\u043d\u0438\u0438, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u043c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RandomizedSearch, \u043c\u043e\u0436\u043d\u043e \u0432\u044b\u0434\u0435\u043b\u0438\u0442\u044c 1 \u0441\u0438\u043b\u044c\u043d\u043e \u0432\u043b\u0438\u044f\u044e\u0449\u0438\u0439 \u0444\u0430\u043a\u0442\u043e\u0440 - (\u0442\u0438\u043f \u0436\u0438\u043b\u044c\u044f \u0446\u0435\u043b\u044b\u0439 \u0434\u043e\u043c \u0438\u043b\u0438 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b) \u0438 4 \u0432\u043b\u0438\u044f\u044e\u0449\u0438\u0445 (\u0442\u0438\u043f \u0436\u0438\u043b\u044c\u044f \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u043c\u043d\u0430\u0442\u0430, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u0430\u043b\u0435\u043d \u0438 \u0432\u0430\u043d\u043d\u044b\u0445 \u043a\u043e\u043c\u043d\u0430\u0442, \u0432\u043c\u0435\u0441\u0442\u0438\u043c\u043e\u0441\u0442\u044c \u0436\u0438\u043b\u044c\u044f).\n\u041f\u0440\u0438 \u0440\u0435\u0448\u0435\u043d\u0438\u0438, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u043c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e HyperoptSearch, \u0441\u0430\u043c\u044b\u043c \u0432\u0430\u0436\u043d\u044b\u043c \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u043c \u043e\u0441\u0442\u0430\u0435\u0442\u0441\u044f \u0442\u0438\u043f \u0436\u0438\u043b\u044c\u044f \u0446\u0435\u043b\u044b\u0439 \u0434\u043e\u043c \u0438\u043b\u0438 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b, \u043e\u0434\u043d\u0430\u043a\u043e \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u043e \u043d\u0435 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u043c \u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u0441\u044f \u0444\u0430\u043a\u0442\u043e\u0440 \u0442\u0438\u043f \u0436\u0438\u043b\u044c\u044f \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u043c\u043d\u0430\u0442\u0430, \u0430 \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0445 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0435\u0432 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043b\u0430\u0441\u044c.","58a1de52":"[](http:\/\/)<a id='evaluation'><\/a>\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)\n \n---\n__\u041e\u0446\u0435\u043d\u0438\u0432\u0430\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 5 Fold Cross Validation:__\n\n---\n __\u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435__\n \n \n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u043d\u0443\u043b\u044f\u043c\u0438\n     1. LinearRegression: overfit\n     2. Ridge:        RMSE: 0.49774990821195464| alpha: 21.05\n     3. Lasso:        RMSE: 0.49774287472413076| alpha: 0.001\n     4. kNN:          RMSE: 0.442948105614102 | k: 14\n     5. RandomForest: RMSE: 0.4054379713816679 | Trees: 185\n \n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u0441\u0440\u0435\u0434\u043d\u0438\u043c\n      1. LinearRegression: overfit\n      2. Ridge:        RMSE: 0.4956077353742178| alpha: 49.55\n      3. Lasso:        RMSE: 0.49557104626971504| alpha: 0.001\n      4. kNN:          RMSE: 0.46069152837274707 | k: 13\n      5. RandomForest: RMSE: 0.40894477722105876 | Trees: 185\n \n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439\n      1. LinearRegression: overfit\n      2. Ridge:        RMSE: 0.49444512065651003| alpha: 49.55\n      3. Lasso:        RMSE: 0.494421107862383| alpha: 0.001\n      4. kNN:          RMSE: 0.45771999855863515 | k: 13\n      5. RandomForest: RMSE: 0.40953938482646757 | Trees: 185\n  \n---\n__\u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0433\u0435\u043e\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432__\n\n---\n \n \n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u043d\u0443\u043b\u044f\u043c\u0438 (\u041b\u0443\u0447\u0448\u0438\u0439 \u0441\u0446\u0435\u043d\u0430\u0440\u0438\u0439)\n     1. LinearRegression: overfit\n     2. Ridge:        RMSE: 0.40808357116375804| alpha: 0.0001\n     3. Lasso:        RMSE: 0.40955581469049684| alpha: 0.001\n     4. kNN:          RMSE: 0.4473864007355662 | k: 13\n     5. RandomForest: RMSE: 0.3837541529824527 | Trees: 145\n \n    5.1. RandomSearchCV: RMSE: 0.38297787345656426\n\n    5.2. HyperoptSearchCV: RMSE: 0.3892024159966049\n                          {'max_depth': 131.94472510397674,\n                           'min_samples_leaf': 3.9334375444609178,\n                           'min_samples_split': 33.64001722796847,\n                           'n_estimators': 149.09402104442745}\n\n    6. Boosting\n     \n    6.1. XGBoost: RMSE: 0.3632259282949432\n \n               {'gamma': 0.15340366103115533,\n                'l2_leaf_reg': 2.0,\n                'learning_rate': 0.00853890793354474,\n                'max_depth': 5.971733628773733,\n                'reg_alpha': 1.8400184528746324,\n                'reg_lambda': 1.0868061353806249}\n    \n    6.2. Catboost: RMSE: 0.3968598625977784\n\n               {'l2_leaf_reg': 6.0,\n                'learning_rate': 0.08390144719977513}\n               \n    6.3 LightGBM: RMSE: 0.3624\n               {'learning_rate': 0.00865486636310301, \n                 'max_depth': 14.36591078571328, \n                 'reg_alpha': 0.6068202197683499, \n                 'reg_lambda': 1.766630554761724, \n                 'subsample': 0.8373883555532842}\n\n\n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u0441\u0440\u0435\u0434\u043d\u0438\u043c\n     1. LinearRegression: overfit\n     2. Ridge:       RMSE: 0.40994227306017883| alpha: 3.55\n     3. Lasso:       RMSE: 0.4109165072396806| alpha: 0.001\n     4. kNN:         RMSE: 0.4459067082695377 | k: 14\n     5. RandomForest:RMSE: 0.3860926855419885 | Trees: 125\n \n \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 NaN \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439\n     1. LinearRegression: overfit\n     2. Ridge:        RMSE: 0.40902546969558723| alpha: 1.9951\n     3. Lasso:        RMSE: 0.4098469372333785| alpha: 0.001\n     4. kNN:          RMSE: 0.44594866627509855 | k: 14\n     5. RandomForest: RMSE: 0.3857117252559245 | Trees: 125","083af7ea":"__RandomizedSearch:__","101a022a":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439","2fe2230e":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439","0388acef":"\u041d\u0430\u043f\u0438\u0448\u0435\u043c `score functions` \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u043e\u0432 \u0434\u043b\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441 `hyperopt`.","10a6e6a8":"<a id='start'><\/a>\n# SPSU intensives\n### Advanced Econometrics with Elements of Statistical Learning and Big Data Analytics\n[C\u0442\u0440\u0430\u043d\u0438\u0446\u0430 \u043d\u0430 Kaggle](https:\/\/www.kaggle.com\/c\/spsu-intensives\/overview)\n\n\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)\n * [Business context and problem formulation](#business)\n * [Methodology](#method)\n * [Evaluation results](#evaluation)\n * [Data preprocessing and EDA](#data_preprocessing)\n    * [Regression, Ridge, Lasso](#regression) \n    * [kNN](#knn) \n    * [RandomForest](#rforest)\n    * [Boosting](#boost):\n         * [XGBoost](#xgboost)\n         * [CatBoost](#catboost)\n         * [LightGBM](#lightgbm)\n * [Conclusion](#conclusion) ","bcf3ebf8":"<a id='regression'><\/a>     \n### Regression, Ridge, Lasso\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","3450a3e0":"\u0417\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u0435\u0439 \u0432\u0441\u0435\u0433\u043e \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0441\u0432\u044f\u0437\u044c \u0446\u0435\u043d\u044b \u0436\u0438\u043b\u044c\u044f \u0441 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0430\u043c\u0438 \u0434\u043e\u043c\u0430 - `accommodates, bathrooms, bedrooms`, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0441\u0442\u0430\u0432\u043a\u0430\u043c\u0438 \u0443\u0431\u043e\u0440\u043a\u0438 \u0438 \u0441\u0442\u0430\u0432\u043a\u0430\u043c\u0438 \u0434\u0435\u043f\u043e\u0437\u0438\u0442\u0430  - `cleaning fee`, `security deposit`. \u041d\u0435\u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u043a\u0443\u0447\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c \u0448\u0438\u0440\u043e\u0442\u044b \u0438 \u0434\u043e\u043b\u0433\u043e\u0442\u044b, \u0447\u0442\u043e \u0433\u043e\u0432\u043e\u0440\u0438\u0442 \u043e \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0432\u043b\u0438\u044f\u043d\u0438\u044f \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u0430\u0442\u0442\u0435\u0440\u043d\u0430 \u043d\u0430 \u0446\u0435\u043d\u0443. \u0421\u0430\u043c\u044b\u0439 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 - \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0434\u043e \u0446\u0435\u043d\u0442\u0440\u0430 \u0433\u043e\u0440\u043e\u0434\u0430 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d.","ce54c533":"    catb_kwargs = {'iterations':2200,'X_train':data,'y_train':data['log_price'],\n                   'categorical_features_indices':categorical_features_indices,\n                   'ignored_features':['price', 'log_price']}\n\n    params_space = {\n        'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n        'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 1e-1),\n        'max_depth': hyperopt.hp.uniform('max_depth', 2, 20)}\n\n    catb_hyperopt_inst = HyperOpt(**catb_kwargs)\n    trials = hyperopt.Trials()\n    best = hyperopt.fmin(\n        catb_hyperopt_inst.hyperopt_catb_score,\n        space=params_space,\n        algo=hyperopt.tpe.suggest,\n        max_evals=15,\n        trials=trials,\n        rstate=np.random.RandomState(42)\n    )\n    print(best)","f520ced6":"\u0412 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 \u0442\u0435\u0441\u0442\u0435 \u0435\u0441\u0442\u044c \u0441\u0442\u043e\u043b\u0431\u0446\u044b \u0441 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438. \u0414\u043b\u044f \u0438\u0445 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435\u043c 3 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0439: \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043d\u0443\u043b\u0435\u043c, \u0441\u0440\u0435\u0434\u043d\u0438\u043c \u0438 \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439.","490823be":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439","c2b64f52":"<a id='data_preprocessing'><\/a>     \n### Data preprocessing and EDA\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","2343924b":"<a id='knn'><\/a>     \n### kNN\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","c5e28c4e":"\u0422\u0435\u043f\u0435\u0440\u044c \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u043e\u0431\u0440\u0430\u0442\u0438\u0442\u044c\u0441\u044f \u043a \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u043c\u0443 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u0435\u0440\u0432\u0438\u0447\u043d\u043e\u0433\u043e \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0443 \u0434\u0430\u043d\u043d\u044b\u0445:","f6f4953b":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u0432 \u0432 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0441 \u043d\u0438\u0437\u043a\u0438\u043c RMSE \u0438 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0439 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043d\u0443\u043b\u044f\u043c\u0438:","6880ea1e":"\u041d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0437\u0430\u0438\u0432\u0438\u0441\u043c\u043e\u0441\u0442\u0438 \u0447\u0438\u0441\u043b\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u043f\u0430\u0440\u043a\u043e\u0432 \u043e\u0442 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0430 \u0446\u0435\u043d\u044b.","0197df90":"\u0421 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RandomizedSearch, HyperoptSearch \u043d\u0430\u0439\u0434\u0435\u043c \u0441\u0443\u0431\u043e\u043f\u0442\u0438\u043c\u0443\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0445 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432","05d00a63":"\u0426\u0435\u043d\u044b \u0431\u043e\u043b\u044c\u0448\u0435\u0439 \u0447\u0430\u0441\u0442\u0438 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u0441\u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u044b \u0432 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0435 \u043e\u0442 0 \u0434\u043e 200. \u0414\u0430\u043b\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0439, \u043d\u0430\u0447\u0438\u043d\u0430\u044e\u0449\u0438\u0445\u0441\u044f \u0441 200, \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442\u0441\u044f, \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u0432 13 \u0440\u0430\u0437.\n\n\u0411\u0443\u0434\u0435\u043c \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0430 \u0446\u0435\u043d\u044b, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e \u0437\u043d\u0447\u0435\u043d\u0438\u0439 \u0441\u043a\u0443\u0447\u0435\u043d\u044b \u0432 \u0440\u0430\u0439\u043e\u043d\u0435 \u043d\u0443\u043b\u044f.","1cf5f92a":"LightGBM \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0441\u043e\u0431\u0438\u0440\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0441 CPU, `(n_estimators=1500, max_evals=15)`\n\n    best_score = 0.3624\n    best = {'learning_rate': 0.00865486636310301, \n            'max_depth': 14.36591078571328, \n            'reg_alpha': 0.6068202197683499, \n            'reg_lambda': 1.766630554761724, \n            'subsample': 0.8373883555532842}","689651ea":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043d\u0443\u043b\u0435\u043c","b9b0dd70":"> \u041c\u043e\u0434\u0435\u043b\u044c LightGBM \u0438\u043c\u0435\u0435\u0442 \u0431\u043e\u043b\u0435\u0435 \u0430\u0434\u0435\u043a\u0432\u0430\u0442\u043d\u0443\u044e \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044e \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432 bedrooms \u0438 bathrooms, \u0437\u043d\u0430\u043a\u0438 shap-\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0442\u0435\u043f\u0435\u0440\u044c \u043e\u0431\u044a\u044f\u0441\u043d\u0438\u043c\u044b. \u0412 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u043e\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0435\u0442 \u0430\u043d\u0430\u043b\u043e\u0433\u0438, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0432\u044b\u0448\u0435. \u0421\u0430\u043c\u044b\u043c \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u043c \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u043c \u0432 \u043c\u043e\u0434\u0435\u043b\u0438 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0442\u0438\u043f \u0436\u0438\u043b\u044c\u044f - \u0434\u043e\u043c \u0438\u043b\u0438 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b.","8392fa00":"<a id='catboost'><\/a>     \n### Catboost\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","9dd31185":"\u041d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u0441\u0442\u0430\u0431\u0438\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u0435\u043d\u0435\u0435 \u0447\u0435\u043c \u043d\u0430 1500 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0443\u0440\u043e\u0432\u043d\u0435 `0.435` \u0441 50 stopping rounds.","dda64968":"<a id='boost'><\/a>     \n### Boosting\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","443202e5":"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u044b\u043b\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u043d\u0430 \u043c\u0430\u0448\u0438\u043d\u0435 c `DEVICE=GPU (n_estimators=1500, max_evals=15)`\n\n        best loss: 0.3632259282949432\n        {'gamma': 0.15340366103115533,\n         'l2_leaf_reg': 2.0,\n         'learning_rate': 0.00853890793354474,\n         'max_depth': 5.971733628773733,\n         'reg_alpha': 1.8400184528746324,\n         'reg_lambda': 1.0868061353806249}","bcab2543":"\n    xgb_kwargs = {'cv':5, 'n_estimators':2200, 'verbose':False,'rounds':50,\n                  'X_train':X_train, 'X_val':X_val, 'y_train':y_train, 'y_val':y_val}\n\n    params_space = {'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n                    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 1e-2),\n                    'max_depth': hyperopt.hp.uniform('max_depth', 2, 10),\n                    'gamma': hyperopt.hp.uniform('gamma', 0, 3),\n                    'reg_alpha': hyperopt.hp.uniform('reg_alpha', 0, 2),\n                    'reg_lambda': hyperopt.hp.uniform('reg_lambda', 0, 2)\n                   }\n    xgb_hyperopt_inst = HyperOpt(**xgb_kwargs)\n    trials = hyperopt.Trials()\n    best = hyperopt.fmin(\n        xgb_hyperopt_inst.hyperopt_xgb_score,\n        space=params_space,\n        algo=hyperopt.tpe.suggest,\n        max_evals=30,\n        trials=trials,\n        rstate=np.random.RandomState(42)\n    )\n    print(best)","b3ce6996":"[](http:\/\/)<a id='method'><\/a>\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)\n \n ### Methodology\n \n \u0414\u043b\u044f \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0446\u0435\u043d\u044b \u043d\u0430 Airbnb \u0436\u0438\u043b\u044c\u0435 \u0432 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0435 \u0432\u044b\u0431\u0440\u0430\u043d \u043f\u043e\u0434\u0445\u043e\u0434 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0430\u0431\u043e\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043e\u0442 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043a \u0431\u043e\u043b\u0435\u0435 \u0441\u043b\u043e\u0436\u043d\u044b\u043c, \u0430 \u0442\u0430\u043a\u0436\u0435 \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439. \u0412\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438: \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u0438 \u0435\u0451 \u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0441 L1 \u0438 L2 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0435\u0439, \u043c\u0435\u0442\u043e\u0434 k-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439, \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441, 3 \u0432\u0430\u0440\u0438\u0430\u0446\u0438\u0438 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430: XGBoost, CatBoost, LightGBM. \u041d\u0430 \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438 \u0442\u0430\u043a\u0436\u0435 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u0432 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439: \u043d\u0443\u043b\u0435\u043c, \u0441\u0440\u0435\u0434\u043d\u0438\u043c, \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439.\n \n \u0414\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0432\u044b\u0431\u0440\u0430\u043d \u043c\u0435\u0442\u043e\u0434 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043d\u0430 5 \u0444\u043e\u043b\u0434\u0430\u0445 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 RMSE. \u0414\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0430 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u0442\u0441\u044f 10% \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e \u0438 \u043f\u043e\u0438\u0441\u043a \u043c\u043e\u043c\u0435\u043d\u0442\u0430 \u0440\u0430\u043d\u043d\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043a \u0446\u0435\u043b\u044c\u044e \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043a\u0430\u043a \u043c\u043e\u0436\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0435\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f \u043e\u0431\u043e\u0431\u0449\u0430\u044e\u0449\u0435\u0439 \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u0438.\n \n \u041f\u0440\u0438 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043f\u0435\u0440\u0435\u0431\u043e\u0440 \u043f\u043e \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u043a\u0435 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0433\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432, \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043f\u0435\u0440\u0435\u0431\u043e\u0440, \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 __`hyperopt`__ [__hyperopt on GitHub__](#https:\/\/github.com\/hyperopt\/hyperopt), \u043e\u0431\u043e\u0437\u043d\u0430\u0447\u0435\u043d\u043d\u0430\u044f \u043a\u0430\u043a \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0439 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u044b\u0439 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u044e\u0449\u0430\u044f \u0432\u043d\u0443\u0442\u0440\u0438 \u0441\u0435\u0431\u044f \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043f\u0435\u0440\u0435\u0431\u043e\u0440 \u0438 Tree of Parzen Estimators [__Algorithms for Hyper-Parameter Optimization__](#https:\/\/papers.nips.cc\/paper\/4443-algorithms-for-hyper-parameter-optimization.pdf).\n \n\n \n \n __Feature engineering:__\n \n \u042d\u043b\u0435\u043c\u0435\u043d\u0442 feature engineering \u043e\u0441\u043d\u043e\u0432\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u043f\u043e\u0438\u0441\u043a\u0435 \u043d\u043e\u0432\u044b\u0445 \u0433\u0435\u043e\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u0431\u044b\u0442\u044c \u043f\u0440\u0438\u0432\u044f\u0437\u0430\u043d\u044b \u043a \u043e\u0431\u044a\u0435\u043a\u0442\u0430\u043c \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438 \u0442\u0435\u043c \u0438\u043b\u0438 \u0438\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c. \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u0432\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043a\u0430\u0441\u0430\u044e\u0442\u0441\u044f \u0446\u0435\u043d\u0442\u0440\u0430 \u0433\u043e\u0440\u043e\u0434\u0430, \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u0440\u0430\u0439\u043e\u043d\u043e\u0432 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0430, \u0440\u044f\u0434 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0445 \u043c\u0435\u0441\u0442, \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c\u044b\u0445 Airbnb, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u043f\u0430\u0440\u043a\u043e\u0432\u044b\u0445 \u043c\u0435\u0441\u0442.\n \n \n__Model interpretation:__\n\n\u0423\u0441\u043b\u043e\u0436\u043d\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0432\u0435\u0434\u0435\u0442 \u043a \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u044e \u0431\u044b\u0441\u0442\u0440\u043e\u0439 \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u0443\u0435\u043c\u043e\u0441\u0442\u0438 \u0438\u0445 \u0440\u0430\u0431\u043e\u0442\u044b. \u0414\u043b\u044f \u0438\u0445 \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u043f\u043e\u043d\u0438\u043c\u0430\u043d\u0438\u044f \u0432 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0439 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u043d\u043e\u0439 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043c\u0435\u0442\u043e\u0434\u044b \u043f\u043e\u0441\u0442\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432. \u042d\u0442\u043e \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e \u0432\u0430\u0436\u043d\u043e \u0432 \u0447\u0443\u0432\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043a \u0440\u0438\u0441\u043a\u0443 \u043e\u0431\u043b\u0430\u0441\u0442\u044f\u0445 - \u0444\u0438\u043d\u0430\u043d\u0441\u0430\u0445, \u043c\u0435\u0434\u0438\u0446\u0438\u043d\u0435, \u0433\u0434\u0435 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0434\u0430\u0436\u0435 \u043e\u0434\u043d\u043e\u0433\u043e \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043d\u0435\u0441\u043e\u043f\u043e\u0441\u0442\u0430\u0432\u0438\u043c\u0430 \u0441 \u0440\u044f\u0434\u043e\u043c \u0434\u0440\u0443\u0433\u0438\u0445 \u043e\u0431\u043b\u0430\u0441\u0442\u0435\u0439 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0439.\n\n\u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u0434\u043b\u044f  \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043d\u0430 \u0431\u0430\u0437\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043f\u043e\u043c\u0438\u043c\u043e \u0432\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u043e\u0439 \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0432 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u043c \u0431\u0443\u0441\u0442\u0438\u043d\u0433\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0431\u0438\u0431\u0438\u043b\u0438\u043e\u0442\u0435\u043a\u0443 __`shap`__ [__shap on GitHub__](#https:\/\/github.com\/slundberg\/shap), \u0447\u0442\u043e\u0431\u044b \u043e\u043f\u0438\u0441\u0430\u0442\u044c \u043e\u0431\u0449\u0435\u0435 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0438 \u0441\u0438\u043b\u0443 \u0432\u043b\u0438\u044f\u043d\u0438\u044f \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u0432 \u043d\u0430 \u0446\u0435\u043d\u0443 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0445.","e9037e2c":"__HyperoptSearch:__","a3b1fc9a":"\u041e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0443\u044e \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","f737ac32":"\u041c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0441\u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043e \u0432 \u043e\u0434\u043d\u043e\u043c \u043c\u0435\u0441\u0442\u0435, \u043f\u043e\u044d\u0442\u043e\u043c\u0443, \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u043c \u043f\u043e price,\n\u0440\u0430\u0437\u0443\u043c\u043d\u043e \u043f\u0435\u0440\u0435\u0432\u0435\u0441\u0442\u0438 \u0434\u0438\u0441\u0442\u0430\u043d\u0446\u0438\u044e \u0432 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c \u0434\u0438\u0441\u0442\u0430\u043d\u0446\u0438\u0438","5c88639e":"\u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0440\u0435\u0434\u0435\u043b \u043d\u0430\u0441\u044b\u0449\u0435\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u0438 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0438 \u0432 1500 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 RMSE \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043a\u043e\u043b\u0435\u0431\u043b\u0435\u0442\u0441\u044f \u0432 \u0440\u0430\u0439\u043e\u043d\u0435 `0.437`. \u041f\u043e\u0434\u0431\u0435\u0440\u0435\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u0435 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0435\u0439 \u0438 \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u043c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u043c \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e\u043c \u0434\u043b\u044f \u0440\u0430\u043d\u043d\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.","2a40b99d":"\u041f\u0440\u0438 \u0443\u0441\u043b\u043e\u0432\u0438\u0438 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e, \u0432\u044b\u044f\u0441\u043d\u0438\u043c \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u0434\u043b\u044f \u043c\u0438\u043d\u0438\u043c\u0443\u043c\u0430 RMSE \u043f\u043e \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n\n---\n\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043d\u0443\u043b\u0435\u043c","ab5f65b8":"<a id='lightgbm'><\/a>     \n### LightGBM\n\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)","d02ff39e":"\u041c\u043e\u0436\u043d\u043e \u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u0447\u0442\u043e \u0446\u0435\u043d\u0430 \u043d\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043e\u0442\u0442\u043e\u0433\u043e \u0438\u043c\u0435\u0435\u0442 \u043b\u0438 \u0430\u0440\u0435\u043d\u0434\u043e\u0434\u0430\u0442\u0435\u043b\u044c \u0441\u0442\u0430\u0442\u0443\u0441 `\"super host\"` \u0438 \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0436\u0434\u0435\u043d\u0430 \u043b\u0438 \u0435\u0433\u043e \u043b\u0438\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0441\u0430\u0439\u0442\u0435. \u0422\u0430\u043a\u0436\u0435 \u043d\u0430 \u0446\u0435\u043d\u0443 \u043d\u0435 \u0432\u043b\u0438\u044f\u0435\u0442 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0441\u0440\u0430\u0437\u0443 \u0437\u0430\u0440\u0435\u0437\u0435\u0440\u0432\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u044c.\n\n\u0421\u0430\u043c\u0430\u044f \u0434\u043e\u0440\u043e\u0433\u0430\u044f \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u044c - \u044d\u0442\u043e \u0430\u0440\u0435\u043d\u0434\u0430 \u0446\u0435\u043b\u043e\u0433\u043e \u0434\u043e\u043c\u0430 \u0438\u043b\u0438 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u043e\u0432. \u0421\u0430\u043c\u044b\u0435 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043f\u043e \u0430\u0440\u0435\u043d\u0434\u0435 - \u044d\u0442\u043e \u043e\u0431\u0449\u0438\u0435 \u043a\u043e\u043c\u043d\u0430\u0442\u044b.\n\u041f\u043e\u043b\u0438\u0442\u0438\u043a\u0430 \u043f\u043e \u043e\u0442\u043c\u0435\u043d\u0435 \u0431\u0440\u043e\u043d\u0438 \u0438\u043c\u0435\u0435\u0442 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u043d\u0430 \u0446\u0435\u043d\u0443, \u0442\u0430\u043a \u043c\u0435\u0434\u0438\u0430\u043d\u0430 \u0446\u0435\u043d\u044b \u0441 \u0433\u0438\u0431\u043a\u043e\u0439 \u043f\u043e\u043b\u0438\u0442\u0438\u043a\u043e\u0439 \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0430\u044f \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0431\u043e\u043b\u0435\u0435 \u0436\u0435\u0441\u0442\u043a\u0438\u0445 \u043f\u043e\u043b\u0438\u0442\u0438\u043a.","c82b4207":"    lgbm_kwargs = {'cv':5, 'n_estimators':1500, 'verbose':False, 'rounds':50,\n                   'X_train':X_train, 'X_val':X_val, 'y_train':y_train, 'y_val':y_val}\n\n    params_space = {'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-4, 1e-2),\n                    'max_depth': hyperopt.hp.uniform('max_depth', 2, 15),\n                    'subsample': hyperopt.hp.uniform('subsample', 0, 1),\n                    'reg_alpha': hyperopt.hp.uniform('reg_alpha', 0, 2),\n                    'reg_lambda': hyperopt.hp.uniform('reg_lambda', 0, 2)\n                   }\n    lgbm_hyperopt_inst = HyperOpt(**lgbm_kwargs)\n    trials = hyperopt.Trials()\n    best = hyperopt.fmin(\n        lgbm_hyperopt_inst.hyperopt_lgbm_score,\n        space=params_space,\n        algo=hyperopt.tpe.suggest,\n        max_evals=15,\n        trials=trials,\n        rstate=np.random.RandomState(42)\n    )\n    print(best)","91d7b1b6":"\u0421\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0441\u0440\u0435\u0434\u043d\u0438\u043c","5937fde5":"\u0412 \u043e\u0442\u043b\u0438\u0447\u0438\u0435 \u043e\u0442 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0434\u043e \u0446\u0435\u043d\u0442\u0440\u0430 \u0433\u043e\u0440\u043e\u0434\u0430 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u0440\u0430\u0439\u043e\u043d\u0430 \u043d\u0430 \u043c\u0435\u0434\u0438\u0430\u043d\u0443 \u0446\u0435\u043d\u044b.","d55bc627":"[](http:\/\/)<a id='business'><\/a>\n [\u0412 \u043d\u0430\u0447\u0430\u043b\u043e](#start)\n \n ### Business context and problem formulation\n \nAirbnb - \u043e\u0434\u043d\u0430 \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0445 \u043e\u043d\u043b\u0430\u0439\u043d-\u043f\u043b\u043e\u0449\u0430\u0434\u043a\u043e\u043a \u0434\u043b\u044f \u0440\u0430\u0437\u043c\u0435\u0449\u0435\u043d\u0438\u044f, \u043f\u043e\u0438\u0441\u043a\u0430 \u0438 \u043a\u0440\u0430\u0442\u043a\u043e\u0441\u0440\u043e\u0447\u043d\u043e\u0439 \u0430\u0440\u0435\u043d\u0434\u044b \u0447\u0430\u0441\u0442\u043d\u043e\u0433\u043e \u0436\u0438\u043b\u044c\u044f \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u043c\u0438\u0440\u0443.\n\u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044f \u043d\u0430 \u0440\u044b\u043d\u043a\u0435 \u0441 2008 \u0433\u043e\u0434\u0430, \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u0438\u043c\u0435\u0435\u0442 \u0432 \u0441\u0432\u043e\u0435\u0439 \u0431\u0430\u0437\u0435 \u043e\u0433\u0440\u043e\u043c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043e \u0441\u0434\u0430\u044e\u0449\u0435\u043c\u0441\u044f \u0436\u0438\u043b\u044c\u0435 \u0432 65 000 \u0433\u043e\u0440\u043e\u0434\u0430\u0445 191 \u0441\u0442\u0440\u0430\u043d \u043c\u0438\u0440\u0430.\n\u041f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u043e\u0433\u0438\u0447\u043d\u044b\u043c, \u043f\u043e\u0438\u0441\u043a \u0437\u0430\u043a\u043e\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0438 \u043d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0439 \u0446\u0435\u043d\u044b \u043e\u0442 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0435\u0432 \u0436\u0438\u043b\u044c\u044f \u0434\u043b\u044f, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0440\u0430\u0437\u0432\u0438\u0442\u0438\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438. \u0422\u0430\u043a, \u0432\u044b\u044f\u0432\u0438\u0432 \u0440\u0435\u0433\u0440\u0435\u0441\u043e\u0440\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u0432\u043b\u0438\u044f\u044e\u0442 \u043d\u0430 \u0446\u0435\u043d\u0443 \u0436\u0438\u043b\u044c\u044f, \u0438 \u0441\u043f\u0440\u043e\u0441\u0438\u0432 \u043f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u0438\u043a\u043e\u0432, \u0447\u0442\u043e \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u0440\u0438\u043e\u0440\u0438\u0442\u0435\u0442\u043d\u044b\u043c \u0434\u043b\u044f \u043d\u0438\u0445 (\u0431\u043b\u0438\u0437\u043e\u0441\u0442\u044c \u0434\u043e\u0441\u0442\u043e\u043f\u0440\u0438\u043c\u0435\u0447\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0435\u0439, \u0431\u0430\u0440\u043e\u0432, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u0435\u0441\u0442, \u043b\u0438\u0431\u043e \u043e\u0442\u0437\u044b\u0432\u043e\u0432 \u0438 \u0442.\u0434.), \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043e\u0442\u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u0441\u0435 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0431\u043e\u043b\u0435\u0435 \u043f\u0435\u0440\u0441\u043e\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043e.","b855ba77":"\u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u043d\u0430 \u0446\u0435\u043d\u0443 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438 \u0438\u043c\u0435\u0435\u0435\u0442 \u0435\u0433\u043e \u0442\u0438\u043f - \u0446\u0435\u043b\u044b\u0439 \u0434\u043e\u043c \u0438\u043b\u0438 \u0430\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b, \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u0432\u043c\u0435\u0441\u0442\u0438\u043c\u043e\u0441\u0442\u044c \u0436\u0438\u043b\u044c\u044f, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u0430\u043b\u0435\u043d \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0442 \u0446\u0435\u043d\u0443. \u0412 \u0447\u0430\u0441\u0442\u0438 \u0432\u0430\u043d\u043d\u044b\u0445 \u043a\u043e\u043c\u043d\u0430\u0442 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0430\u043d\u043e\u043c\u0430\u043b\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043c\u043e\u0436\u0435\u0442 \u0433\u043e\u0432\u043e\u0440\u0438\u0442\u044c \u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u044d\u0442\u043e\u0433\u043e \u0444\u0430\u043a\u0442\u043e\u0440\u0430 \u0438, \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e, \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u043e\u0448\u0438\u0431\u043e\u043a \u0432 \u0434\u0430\u043d\u043d\u044b\u0445. \u041f\u043e\u043c\u0438\u043c\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a \u0434\u043e\u043c\u0430 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0432\u043b\u0438\u044f\u043d\u0438\u044f \u043d\u0430 \u0446\u0435\u043d\u0443 \u043f\u043e \u0432\u0441\u0435\u043c\u0443 X_val \u0438\u043c\u0435\u0435\u0442 \u043d\u0430\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u0430\u043b\u0435\u0440\u0435\u0438\u044f \u0412\u0438\u043a\u0442\u043e\u0440\u0438\u0438 \u0432 \u041c\u0435\u043b\u044c\u0431\u0443\u0440\u043d\u0435, St Kilda Festival - \u043c\u0435\u0441\u0442\u043e \u0443 \u043f\u0440\u0438\u0431\u0440\u0435\u0436\u043d\u043e\u0439 \u0437\u043e\u043d\u044b \u0438 \u043f\u043b\u044f\u0436\u0430, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0437\u0430\u0433\u043e\u0440\u043e\u0434\u043d\u044b\u0439 \u0440\u0430\u0439\u043e\u043d Warbertone \u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u0431\u043b\u0430\u0441\u0442\u0435\u0439 \u0432 \u0446\u0435\u043d\u0442\u0440\u0435 \u0433\u043e\u0440\u043e\u0434\u0430.","7db1b5c5":"![](http:\/\/)\u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0440\u0435\u0434\u0435\u043b \u043d\u0430\u0441\u044b\u0449\u0435\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u043c\u0435\u043d\u0435\u0435 \u0447\u0435\u043c \u0437\u0430 3000 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 RMSE \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043a\u043e\u043b\u0435\u0431\u043b\u0435\u0442\u0441\u044f \u0432 \u0440\u0430\u0439\u043e\u043d\u0435 `0.438`. \u041f\u043e\u0434\u0431\u0435\u0440\u0435\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u0435 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b. \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043d\u0430\u0441\u044b\u0449\u0435\u043d\u0438\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435 \u043f\u043e\u043b\u043d\u043e\u0435.","ba146a3e":"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u044b\u043b\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u043d\u0430 \u043c\u0430\u0448\u0438\u043d\u0435 c `DEVICE=GPU (n_estimators=2200, max_evals=10)`\n\n        best loss: 0.3968598625977784\n        {'l2_leaf_reg': 6.0, 'learning_rate': 0.08390144719977513}"}}