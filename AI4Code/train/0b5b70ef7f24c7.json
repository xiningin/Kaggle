{"cell_type":{"5712fcd2":"code","771f4c56":"code","b5ba0fef":"code","0c07d6f6":"code","f168fbfb":"code","d363f536":"code","336e6924":"code","fc0d838b":"code","f578b95c":"code","d72a0f4f":"code","edb4fef5":"code","077b57cd":"code","20a638de":"code","4bf32300":"code","79cbd30b":"code","24773200":"code","56d0f85b":"code","09c18e2b":"code","607d52a9":"code","65549199":"code","d0473509":"code","9ab83129":"code","4f10dfbc":"code","6d66c40c":"code","e8eb83ca":"code","80b25f7f":"code","bb613c4d":"code","54153467":"code","eea17c91":"code","4fda53eb":"code","59d15ab2":"code","cf4300e3":"code","7cad9dba":"code","7b907176":"code","52caf5d9":"code","70958a74":"code","8c9618bc":"code","fcacada9":"markdown","8f1ae2a6":"markdown","26a0e015":"markdown","3b316b57":"markdown","b6ae578f":"markdown","09e6fe03":"markdown","1b0030ff":"markdown","4acb0334":"markdown","0bd5dbeb":"markdown","00cbef23":"markdown","d9397074":"markdown","3ecb3e34":"markdown","d45b4755":"markdown","bf20a4e3":"markdown","5d991570":"markdown","73a790f4":"markdown","9e681c71":"markdown","c555bccc":"markdown","b99612d7":"markdown"},"source":{"5712fcd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt # graphing library\n%matplotlib inline\n\n# Import tensorflow and keras. We will use the keras that is a part of the tensorflow package\n# as opposed to the standalone keras\nimport tensorflow as tf\nfrom tensorflow import keras\n","771f4c56":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b5ba0fef":"training_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nsubmission_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","0c07d6f6":"training_data.head()","f168fbfb":"submission_df.head()","d363f536":"print(\"Training data (rows, columns):\" + str(training_data.shape))\nprint(\"Submission data (rows, columns):\" + str(submission_df.shape))\n","336e6924":"# We have a Dataframe that has labelled data of the right shape so let's split up that dataframe\n# so that we can use it for test, train, and validation. This allows us to move forward with the data we DO have\n#\n# Sample the training_data Dataframe and select 70% of the data for the training_df, testing_df, validation_df dataframes\n# We set the random_state to a specific number so we can reproduce the results\n\ntraining_df = training_data.sample(frac=0.7, random_state=1)\n\n# Drop the already selected values from the training_data dataframe, what is left is our testing data\ntesting_df = training_data.drop( training_df.index )\n\nprint(\"Training data (rows, columns):\" + str(training_df.shape))\nprint(\"Testing data (rows, columns):\" + str(testing_df.shape))\n\nprint( str(training_data.shape[0] - (training_df.shape[0] + testing_df.shape[0] )) + \" rows not accounted for\" )\n","fc0d838b":"training_labels = training_df[\"label\"].values\ntraining_df = training_df.drop( columns=['label'])","f578b95c":"# Confirm that the data is of the right shape\nprint( \"Training data (rows, columns):\" + str(training_df.shape) )\nprint( \"Label Count: \" + str(training_labels.size) )","d72a0f4f":"testing_labels = testing_df['label'].values\ntesting_df = testing_df.drop( columns=['label'])","edb4fef5":"# Confirm that the data is of the right shape\nprint( \"Testing data (rows, columns):\" + str(testing_df.shape) )\nprint( \"Testing Label Count: \" + str(testing_labels.size) )\n","077b57cd":"print( training_df.describe() )","20a638de":"# Normalize all the values in the dataframe so that they are values of range 0..255 by dividing the dataframe by 255 (the max value)\n\ntesting_df \/= 255\ntraining_df \/= 255","4bf32300":"#reshape the rows into (28x28) since that is the original image format for mnist data\nIMG_WIDTH = 28\nIMG_HEIGHT = 28\nIMG_CHANNELS = 1 #this would be 3 for an RGB image, 4 for RGBA, but just 1 for grayscale image\n\n#reshape the data into image shape\ntraining_values = training_df.values.reshape( training_df.shape[0], IMG_WIDTH, IMG_HEIGHT )","79cbd30b":"plt.imshow(training_values[0], cmap=plt.get_cmap('gray'))\nplt.title( training_labels[0] )","24773200":"training_values = training_df.values.reshape( training_df.shape[0], IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS )\ntesting_values = testing_df.values.reshape( testing_df.shape[0], IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS )","56d0f85b":"print(training_labels.shape)\nprint(training_labels[:10])","09c18e2b":"NUM_CLASSES = 10\ntraining_labels_categorical = tf.keras.utils.to_categorical(training_labels)\ntesting_labels_categorical = tf.keras.utils.to_categorical(testing_labels)\n\nprint( training_labels_categorical.shape )\nprint( testing_labels_categorical.shape )","607d52a9":"print( training_labels[0] )\nprint( training_labels_categorical[0])","65549199":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\nfrom tensorflow.python.keras.optimizers import Adam ,RMSprop\n\nprint(\"Tensorflow Version: \" + tf.version.VERSION)\nprint(\"Keras Version: \" + tf.keras.__version__)\n\n# set the number of epochs for training the models\nEPOCHS=35\n\n# how many samples will the system see at one time before it updates its weights\nBATCH_SIZE=64","d0473509":"model = tf.keras.Sequential()\n\nmodel.add(layers.Conv2D(32, 3, 3, activation='relu', input_shape=(IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS)))\nmodel.add(layers.Conv2D(32, 3, 3, activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation=\"relu\"))\nmodel.add(layers.Dropout(0.50))     \nmodel.add(layers.Dense(10, activation=\"softmax\"))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()        \n\n\nhistory = model.fit( training_values, training_labels_categorical, validation_split=0.1, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, verbose=1 )\n","9ab83129":"plt.plot( history.history['acc'])\nplt.plot( history.history['val_acc'])\nplt.title( 'Model accuracy')\nplt.ylabel( 'accuracy')\nplt.xlabel( 'epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","4f10dfbc":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","6d66c40c":"score = model.evaluate( testing_values, testing_labels_categorical, verbose=1)\n\nprint( \"Model1 Score: \" + str(score) )","e8eb83ca":"model2 = tf.keras.Sequential()\n\nmodel2.add(layers.Conv2D(32, kernel_size=5, padding='same', activation='relu', input_shape=(IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS)))\nmodel2.add(layers.MaxPool2D())\nmodel2.add(layers.Dropout(0.40))\n\nmodel2.add(layers.Conv2D(64, kernel_size=5, activation='relu'))\nmodel2.add(layers.MaxPool2D())\nmodel2.add(layers.Dropout(0.40))\n\nmodel2.add(layers.Flatten())\nmodel2.add(layers.Dense(128, activation=\"relu\"))\nmodel2.add(layers.Dropout(0.40))  \n\nmodel2.add(layers.Dense(10, activation=\"softmax\"))\n\nmodel2.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel2.summary()   \n\nhistory = model2.fit( training_values, training_labels_categorical, validation_split=0.1, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, verbose=1 )","80b25f7f":"plt.plot( history.history['acc'])\nplt.plot( history.history['val_acc'])\nplt.title( 'Model accuracy')\nplt.ylabel( 'accuracy')\nplt.xlabel( 'epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","bb613c4d":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","54153467":"score = model2.evaluate( testing_values, testing_labels_categorical, verbose=1)\n\nprint( \"Model2 Score: \" + str(score) )","eea17c91":"model3 = tf.keras.Sequential()\n\nmodel3.add(layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel3.add(layers.BatchNormalization())\n\nmodel3.add(layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel3.add(layers.BatchNormalization())\n\nmodel3.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel3.add(layers.Dropout(0.25))\n\nmodel3.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel3.add(layers.BatchNormalization())\n\nmodel3.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel3.add(layers.BatchNormalization())\nmodel3.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel3.add(layers.Dropout(0.25))\n\nmodel3.add(layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel3.add(layers.BatchNormalization())\nmodel3.add(layers.Dropout(0.25))\n\nmodel3.add(layers.Flatten())\nmodel3.add(layers.Dense(256, activation = \"relu\"))\nmodel3.add(layers.BatchNormalization())\nmodel3.add(layers.Dropout(0.25))\n\nmodel3.add(layers.Dense(10, activation = \"softmax\"))\n\n\nmodel3.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel3.summary()\n\nhistory = model3.fit( training_values, training_labels_categorical, validation_split=0.1, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, verbose=1 )","4fda53eb":"plt.plot( history.history['acc'])\nplt.plot( history.history['val_acc'])\nplt.title( 'Model accuracy')\nplt.ylabel( 'accuracy')\nplt.xlabel( 'epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","59d15ab2":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","cf4300e3":"score = model3.evaluate( testing_values, testing_labels_categorical, verbose=1)\n\nprint( \"Model3 Score: \" + str(score) )","7cad9dba":"modelCheckPoint = ModelCheckpoint( filepath=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\",\n                                   monitor=\"val_acc\",\n                                   verbose=1,\n                                   save_best_only=True,\n                                   mode='max')\n\n# generate more training data\ndatagen = ImageDataGenerator(\n        rotation_range= 8,  \n        zoom_range = 0.13,  \n        width_shift_range=0.13, \n        height_shift_range=0.13)\n\n\ninitial_learning_rate = 0.001\noptimizer = Adam(lr=initial_learning_rate, decay= initial_learning_rate \/ (EPOCHS*1.3))\n\nmodel4 = tf.keras.Sequential()\n\nmodel4.add(layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel4.add(layers.BatchNormalization())\n\nmodel4.add(layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel4.add(layers.BatchNormalization())\n\nmodel4.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel4.add(layers.Dropout(0.25))\n\nmodel4.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel4.add(layers.BatchNormalization())\n\nmodel4.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel4.add(layers.BatchNormalization())\nmodel4.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel4.add(layers.Dropout(0.25))\n\nmodel4.add(layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel4.add(layers.BatchNormalization())\nmodel4.add(layers.Dropout(0.25))\n\nmodel4.add(layers.Flatten())\nmodel4.add(layers.Dense(256, activation = \"relu\"))\nmodel4.add(layers.BatchNormalization())\nmodel4.add(layers.Dropout(0.25))\n\nmodel4.add(layers.Dense(10, activation = \"softmax\"))\n\n\nmodel4.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel4.summary()\n\nhistory = model4.fit_generator(  datagen.flow(training_values, training_labels_categorical, batch_size=BATCH_SIZE), validation_data=(testing_values, testing_labels_categorical), steps_per_epoch=training_values.shape[0] \/\/ BATCH_SIZE, epochs=EPOCHS, verbose=1, callbacks=[modelCheckPoint] )","7b907176":"plt.plot( history.history['acc'])\nplt.plot( history.history['val_acc'])\nplt.title( 'Model accuracy')\nplt.ylabel( 'accuracy')\nplt.xlabel( 'epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()\n","52caf5d9":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend( ['train', 'val'], loc='upper left')\nplt.show()","70958a74":"score = model4.evaluate( testing_values, testing_labels_categorical, verbose=1)\n\nprint( \"Score: \" + str(score) )","8c9618bc":"#prepare the submission data\nsubmission_df \/= 255\nsubmission_values = submission_df.values.reshape( submission_df.shape[0], IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS )\n\n# model prediction on test data\npredictions = model4.predict_classes(submission_values, verbose=0)\n\n# submission\nsubmissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n    \"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","fcacada9":"System is completed and should have predicted the classes for the submission_data that it has never seen before. This can be downloaded in the file below.","8f1ae2a6":"**Test\/Train\/Split in Pandas** \n\nWe will split up the data using Pandas, only, so that we can minimize our dependencies on any other libraries (and Pandas provides us all the functionality that we need).\n","26a0e015":"**Reshaping data for CNN**\n\nWhile a grayscale image has an implicit single channel for the grayscale, we need to explicitly set this before handing the data over to our CNN so that it will be able to process it properly","3b316b57":"** Print a sample of the submission data **\n\nOnce we train the network, we will generate a result for a set of data that the network has not seen and use that for the submission.\n","b6ae578f":"**Data Normalization**\n\nThe data that we have is not of the proper range. The pixel values run from min(0) to max(255) because these images were originally grayscale images. While this is fine for display data, we want to get these into the range of 0-1 for the training process. When working with machine learning data, we want all of our data normalized so there are no issues from having wild ranges of data values across features.","09e6fe03":"**One Hot Categorical Encoding**\n\nThe data that we have needs to be able to fit into one of 10 categories in the output layer so that we can categorize the output. Right now we don't have our labels in categories - we just have an array of results. What we need is for each element to be stretched so that each output represents each of the 10 possibilities that we have and the actual output is marked properly. \n\nThis categorical encoding where we represent all of the categories and the correct output category is marked as \"hot\" is referred to as one-hot encoding.","1b0030ff":"**Print a sample of the training data**","4acb0334":"**Clean dataframe and extract labels**\n\nThe dataframes contain all of the data, but we need to extract the label column from the dataframe and also remove it from the training data since it is not trainable data","0bd5dbeb":"Here we can see that in the old training_label format we simply represented a single value for the output. As such the network would not be able to output to a set of probabilities for each of the possible outcomes.\n\nIn training_labels_new, the network can output to each of the possible outcomes with the knowledge that one of them is the the appropriate outcome and can use this to know to backprop error for results that don't land on the correct label. Note that the results of training_labels[0] results in that items index in the training_labels_categorical being marked as 1.","00cbef23":"** Import requirements for the environment **\n\nThis is the standard import of the machine learning set for Numpy, Pandas, Matplotlib, Tensorflow, and Keras","d9397074":"<a href=\".\/DR.csv\"> Download File <\/a>","3ecb3e34":"Perform the same steps for the testing data","d45b4755":"**Keras Models**\n\nNow that we have all of the data properly formatted, it is time to build a model that will analyze the data and learn the patterns that are in it","bf20a4e3":"\n**Model 2**\n","5d991570":"**Displaying Sample Data**\n\nLet's reshape the data that we have into images instead of rolled out pixel values. This is accomplished using the reshape method. We do this because we're dealing with images and would want to use the CNN methods for our neural network.","73a790f4":"**Model 4**\n\nIn Model 4 we will perform some Data Augmentation to provide more training data for the system. Having more training data is always useful when training a neural network. Data Augmentation takes an existing set of training data and returns a *new* dataset. It is important to note that the original data is **NOT** included in the returned dataset.\n\nWe will also use learning rate decay. Decay will help us to get closer to a minimum by taking smaller steps later in the learning process. If we keep the learning rate too high, we may skip over a minimum. If you are confused by this, look at how back prop works.","9e681c71":"**Load the training and testing data**\n\nThe test.csv file contains all of the data that will be used for the submission. This will be data that the model hasn't seen and will be well suited to measuring how effective the model generalized.","c555bccc":"**Import input files**\n\nKaggle stores all of the datasets attached to this notebook in the \/kaggle\/input directory underneath a directory named for the dataset.","b99612d7":"**Model 3**\n"}}