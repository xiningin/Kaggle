{"cell_type":{"c282f9c7":"code","d9e22033":"code","badfd3e2":"code","e16f5c08":"code","d948b2cd":"code","f0ac298e":"code","5e6f251a":"code","f4df661b":"code","24702bae":"code","4408df10":"code","cc5545d5":"code","dbb4ddb0":"code","96171037":"code","e0453095":"code","3c7b58c9":"code","17f38ff2":"code","504b52eb":"code","1be2821f":"code","db00f05e":"code","86d6002a":"code","2eceb8bf":"code","2e4133bc":"code","b78bdb8c":"code","9e335f62":"markdown","4ad756b5":"markdown","b267a3f3":"markdown","076f7b5f":"markdown","7eeb30ac":"markdown","45a40b8f":"markdown","9aac6f76":"markdown","a3dac7f1":"markdown","3c5c0b51":"markdown","e6ae4cbb":"markdown","5b59b163":"markdown","d9e228e3":"markdown","b2c7e39a":"markdown","1e2b390d":"markdown","542b47ef":"markdown"},"source":{"c282f9c7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nimport random\nimport scipy\nimport shutil\n\nfrom pprint import pprint\nfrom glob import glob\nfrom pathlib import Path\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","d9e22033":"!mkdir ~\/blood-cells\n!mkdir ~\/blood-cells\/dataset-master\/\n!cp -r ..\/input\/dataset-master\/dataset-master\/labels.csv ~\/blood-cells\/dataset-master\/\n!cp -r ..\/input\/dataset-master\/dataset-master\/JPEGImages\/ ~\/blood-cells\/dataset-master\/","badfd3e2":"os.listdir('\/tmp\/blood-cells\/dataset-master\/')","e16f5c08":"PATH = Path('\/tmp\/blood-cells\/dataset-master\/') # Kaggle is '\/tmp\/blood-cells\/dataset-master\/'","d948b2cd":"labels_df = pd.read_csv(PATH.joinpath('labels.csv'))\nlabels_df = labels_df.dropna(subset=['Image', 'Category']) # drop columns that we don't use\nlabels_df['Image'] = labels_df['Image'].apply(\n    lambda x: 'BloodImage_0000' + str(x) + '.jpg' \n    if x < 10 \n    else ('BloodImage_00' + str(x) + '.jpg' if x > 99 else 'BloodImage_000' + str(x) + '.jpg')\n)\nlabels_df = labels_df[['Image', 'Category']]\nlabels_df.head(15)","f0ac298e":"all_image_paths = {\n    os.path.basename(x): x for x in glob(\n        os.path.join(PATH, '*', '*.jpg')\n    )\n}\n# all_image_paths = [x for x in p.glob('**\/*.jpg')]\nprint('Scans found:', len(all_image_paths), ', Total Headers', labels_df.shape[0])","5e6f251a":"labels_df['image_path'] = labels_df['Image'].map(all_image_paths.get)\nlabels_df.head(10)","f4df661b":"count_of_labels_per_cat = labels_df.Category.value_counts()\nto_remove_cat = count_of_labels_per_cat[count_of_labels_per_cat < 10].index \ndf_next = labels_df.replace(to_remove_cat, np.nan)\ndf = df_next.dropna()\nprint(df.Category.value_counts())\ndf.head(12)","24702bae":"train_df, test_df = train_test_split(\n    df, \n    test_size = 0.30,\n    stratify = df['Category']\n)\nprint('shape of data split: ', 'train:', f'{train_df.shape}', 'test:', f'{test_df.shape}')","4408df10":"print(train_df.Category.value_counts(), '\\n')\nprint(test_df.Category.value_counts())","cc5545d5":"os.mkdir(f'{PATH}\/train_original')\nos.mkdir(f'{PATH}\/test_original')\n\nfor f in df.Category.unique():\n    os.mkdir(f'{PATH}\/train_original\/{f}')\n    os.mkdir(f'{PATH}\/test_original\/{f}')","dbb4ddb0":"for p in train_df.itertuples():\n    file_path = f'{PATH}\/JPEGImages\/{p.Image}' \n    train_path = f'{PATH}\/train_original\/{p.Category}\/{p.Image}'\n    shutil.copyfile(f'{file_path}', f'{train_path}')","96171037":"for p in test_df.itertuples():\n    file_path = f'{PATH}\/JPEGImages\/{p.Image}' \n    test_path = f'{PATH}\/test_original\/{p.Category}\/{p.Image}'\n    shutil.copyfile(f'{file_path}', f'{test_path}')","e0453095":"augmented_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n#     zoom_range=0.1,\n    channel_shift_range=50,\n    rescale=1. \/ 255,\n    shear_range=0.4,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='constant'\n)","3c7b58c9":"os.mkdir(f'{PATH}\/train')\n \nfor f in df.Category.unique():\n    os.mkdir(f'{PATH}\/train\/{f}')\n\nfor f in os.listdir(f'{PATH}\/train_original'):\n    if (str(f) != '.DS_Store'):\n        pics = os.listdir(f'{PATH}\/train_original\/{f}')\n        \n        for img in pics:\n            if len(os.listdir(f'{PATH}\/train\/{f}')) >= 2500:\n                break\n            loaded_img = load_img(f'{PATH}\/train_original\/{f}\/{img}')\n            x_test = img_to_array(loaded_img)\n            x_test = x_test.reshape((1,) + x_test.shape)\n            augmented_datagen.fit(x_test)\n            batches = 0\n            for batch in augmented_datagen.flow(x_test, save_to_dir=f'{PATH}\/train\/{f}', save_prefix=f'{f}'):\n                batches += 1\n                if batches > 400 or len(os.listdir(f'{PATH}\/train\/{f}')) >= 2500 :\n                    break","17f38ff2":"os.mkdir(f'{PATH}\/test')\n \nfor f in df.Category.unique():\n    os.mkdir(f'{PATH}\/test\/{f}')\n\nfor f in os.listdir(f'{PATH}\/test_original'):\n    if (str(f) != '.DS_Store'):\n        pics = os.listdir(f'{PATH}\/test_original\/{f}')\n        \n        for img in pics:\n            if len(os.listdir(f'{PATH}\/test\/{f}')) >= 500:\n                break\n            loaded_img = load_img(f'{PATH}\/test_original\/{f}\/{img}')\n            x_test = img_to_array(loaded_img)\n            x_test = x_test.reshape((1,) + x_test.shape)\n            augmented_datagen.fit(x_test)\n            batches = 0\n            for batch in augmented_datagen.flow(x_test, save_to_dir=f'{PATH}\/test\/{f}', save_prefix=f'{f}'):\n                batches += 1\n                if batches > 150 or len(os.listdir(f'{PATH}\/test\/{f}')) >= 500 :\n                    break","504b52eb":"# Example of just created images in the file system of Kaggle\nprint(os.listdir('\/tmp\/blood-cells\/dataset-master\/train\/MONOCYTE')[:3], '\\n')\nprint(os.listdir('\/tmp\/blood-cells\/dataset-master\/test\/MONOCYTE')[:3], '\\n')","1be2821f":"all_augmented_train_image_paths = {\n    os.path.basename(x): x for x in glob(\n        os.path.join(PATH \/ \"train\/\", '*', '*.png')\n        )   \n}\nall_augmented_test_image_paths = {\n    os.path.basename(x): x for x in glob(\n        os.path.join(PATH \/ \"test\/\", '*', '*.png')\n        )   \n}\n# all_image_paths = [x for x in p.glob('**\/*.jpg')]\nprint('Augmented train scans found:', len(all_augmented_train_image_paths))\nprint('Augmented test scans found:', len(all_augmented_test_image_paths))\n","db00f05e":"train_augmented_df = pd.DataFrame()\ntest_augmented_df = pd.DataFrame()\n\ntrain_augmented_df['image'] = all_augmented_train_image_paths.keys()\ntest_augmented_df['image'] = all_augmented_test_image_paths.keys()\n\ntrain_augmented_df['image_path'] = train_augmented_df['image'].map(all_augmented_train_image_paths.get)\ntest_augmented_df['image_path'] = test_augmented_df['image'].map(all_augmented_test_image_paths.get)\n\ntrain_augmented_df['category'] = train_augmented_df['image'].apply(lambda x: x.split('_')[0])\ntest_augmented_df['category'] = test_augmented_df['image'].apply(lambda x: x.split('_')[0])\n\nprint(train_augmented_df.category.value_counts(), '\\n')\nprint(test_augmented_df.category.value_counts())","86d6002a":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    validation_split=0.2,\n)\ntest_datagen = ImageDataGenerator(\n    rescale=1. \/ 255\n)\n\ntrain_generator=train_datagen.flow_from_directory(\n    f'{PATH}\/train',\n    target_size=(72,96), \n    batch_size=32,\n)\ntest_generator=test_datagen.flow_from_directory(\n    f'{PATH}\/test', \n    class_mode=\"categorical\", \n    target_size=(72,96), \n    batch_size=32\n)","2eceb8bf":"#augmented_datagen\n\nx,y = train_generator.next()\nfor i in range(0,1):\n    image = x[i]\n    plt.imshow(image)\n    plt.show()","2e4133bc":"for i in [train_generator, test_generator]:\n    x, y = next(i)\n    fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n    for (c_x, c_y, c_ax) in zip(x, y, m_axs.flatten()):\n    #     print(c_x, '\\n') # image array\n    #     print(c_y, '\\n') # category\n    #     print(c_ax, '\\n') # dunno?\n        c_ax.imshow(c_x[:,:])\n        c_ax.set_title(c_y)\n        c_ax.axis('off')","b78bdb8c":"# from sklearn.metrics import classification_report, confusion_matrix\n\n# pred_Y = tb_model.predict(test_X, \n#                           batch_size = 32, \n#                           verbose = True)\n\n# plt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\n# print(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Cardiomegaly']))","9e335f62":"Creating directory and seperate the bulk of images to its own categories","4ad756b5":"Create new DataFrame, just for augmented images.","b267a3f3":"## Copy images to an own created directory for convinience","076f7b5f":"#### Finding all the test set images","7eeb30ac":"### Augmented images\n\nFind all the just created augmented images.","45a40b8f":"-","9aac6f76":"#### Creating \nIterate over the test folder. Alter every image and create the altered images in the right folder, with respect to the category.\n\nTweak the 'batches' > 20 for wanting to create the amount of augmented images","a3dac7f1":"Root path. From here we can reach all the files.","3c5c0b51":"##### Even more cleaning of the data\nDropping categories that have not enough data. Anything less then 10 we drop. Meaning that we only get to keep 4 categories.","e6ae4cbb":"### Normalise the distribution over the augmented data\nWe want to have an equel set distribution over the categories","5b59b163":"Creating an ImageDataGenerator. From this we get the augmented images.\n\nTweak these settings to your liking, to get the right kind of augmented images","d9e228e3":"# Overview\n\nAs an assignmentfor for the course Machine Learning we choose to create an Convolutional Neural Network where we are going to classify red blood cells. We choose the following dataset. https:\/\/www.kaggle.com\/paultimothymooney\/blood-cells\n\nPart of the assignment is that we need to create our own augmentation data from the original samples. We wanted to almost re-create the original. The key is that we have an even distribution over the categories [EOSINOPHIL, LYMPHOCYTE, MONOCYTE, NEUTROPHIL].\n","b2c7e39a":"#### Mapping the image to the right image path","1e2b390d":"-","542b47ef":"#### Reading CSV file for image information\nChange image name to the full name of the images, just as in the directory.\nWe do this so that we can map the path to the image directly."}}