{"cell_type":{"e5a7a7df":"code","050806bc":"code","c0f50ea7":"code","9340f531":"code","6a52e699":"code","91f710da":"code","bb301038":"code","25d320b7":"code","d9cf6925":"code","bb5521a2":"code","ed0e732b":"code","b0c76be7":"code","a1e9ea1e":"code","d43bc430":"code","3d7063e3":"code","52a1461a":"code","b409a6d6":"code","86c5c5a1":"code","f6e47325":"code","388d1a87":"code","fc47fcb9":"code","0607f583":"code","2a0a808c":"code","5d5e2fbb":"code","8a0b5762":"code","554c69f0":"code","63cb8d5e":"code","31d13c3d":"code","68eb561c":"code","1f6fefa2":"code","19d672f3":"code","88d9a658":"code","e03295c1":"code","47a39ca3":"code","d1c15137":"code","8d05a09a":"markdown","d5656577":"markdown","110fd45a":"markdown","055dacd6":"markdown","1d4c09a8":"markdown","3fe92bee":"markdown","3d3907c0":"markdown","d96e8a1b":"markdown","dd3ec7eb":"markdown","c8f6e37c":"markdown","23625cd3":"markdown"},"source":{"e5a7a7df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","050806bc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c0f50ea7":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain_data.head(10)","9340f531":"train_data.info()    ","6a52e699":"data = pd.concat([train_data,test_data])\ndata","91f710da":"data.groupby(['Pclass'])['Age'].mean()","bb301038":"# Let's define a function that map the missing values to mean of age grouped by PClass\ndef fill_age(cols):\n    Pclass = cols[0]\n    Age = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 39\n        elif Pclass == 2:\n            return 30\n        elif Pclass == 3:\n            return 25\n    else:\n        return Age    ","25d320b7":"data['Age'] = data[['Pclass','Age']].apply(fill_age,axis=1)","d9cf6925":"# let's define a function that coninuous variable Age into a categorical variable \ndef cat_age(col):\n    if 0<col<=12:\n        return 'children'\n    if 12<col<=18:\n        return 'ado'\n    if 18<col<=35:\n        return 'young adult'\n    if 35<col<=60:\n        return 'adult'\n    if 60<col<=100:\n        return 'elder'","bb5521a2":"data['Age'] = data['Age'].apply(cat_age)\ndata","ed0e732b":"# Computing mean Fare value for each Pclass\nmean_Fare = data[data['Fare']!=0].groupby(['Pclass'])['Fare'].mean()\nmean_Fare","b0c76be7":"# Replacing 0 Fare by Pclass mean Fare values\nfor i in [1,2,3]:\n    data.loc[((data['Fare']==0)|(data['Fare'].isnull())) & (data['Pclass']==i),'Fare'] = mean_Fare[i]","a1e9ea1e":"# Cr\u00e9ating column Pers_per_Ticket corresponding to the number of person that share the same ticket\ndata['Pers_per_Ticket']  = data.Ticket.apply(lambda x : data.groupby('Ticket',axis=0).PassengerId.count()[x])\n# Creating column Fare_per_pers corresponding to the price of the ticket divided by the number of person sharing that ticket\ndata['Fare_per_pers'] = data.Fare \/ data.Pers_per_Ticket\ndata","d43bc430":"sns.distplot(data[data['Fare_per_pers']>60].Fare_per_pers)","3d7063e3":"_, bins = np.histogram(data.Fare_per_pers)\ng = sns.FacetGrid(data, hue=\"Pclass\",height=8)\ng = g.map(sns.distplot, \"Fare_per_pers\", bins=bins)","52a1461a":"fig = plt.figure(figsize=(30,10))\nsns.distplot(data.Fare_per_pers)","b409a6d6":"data","86c5c5a1":"data.Fare_per_pers = pd.qcut(data.Fare_per_pers,q=4)","f6e47325":"data","388d1a87":"# Keeping only the Status of the person (Mr., Miss., Dr., Reverent., ...)\ndata.Name = data.Name.apply(lambda x : x.split(\",\")[1].split(\".\")[0])","fc47fcb9":"status_dict=\\\n{' Mr'            : 'Mr',\n ' Mrs'           : 'Mrs' ,\n ' Miss'          : 'Miss'  ,\n ' Master'        : 'Master',\n ' Don'           : 'Royalty',\n ' Rev'           : 'Officer' ,\n ' Dr'            : 'Officer' ,\n ' Mme'           : 'Mrs',\n ' Ms'            : 'Mrs',\n ' Major'         : 'Officer',\n ' Lady'          : 'Royalty' ,\n ' Sir'           : 'Royalty',\n ' Mlle'          : 'Miss',\n ' Col'           : 'Officer',\n ' Capt'          : 'Officer',\n ' the Countess'  : 'Royalty',\n ' Jonkheer'      : 'Royalty',\n ' Dona'          : 'Royalty'}\n\ndef Name_status(col):\n    return status_dict[col]\n    \ndata.Name = data.Name.apply(Name_status)","0607f583":"data.Name.value_counts()","2a0a808c":"data.groupby(['Name'])['Survived'].mean()","5d5e2fbb":"# Dropping the 2 rows with Embarked missing values\n\ndata.dropna(subset=['Embarked'],inplace=True)","8a0b5762":"data.info()","554c69f0":"data","63cb8d5e":"data.Cabin = data.Cabin.apply(lambda x : list(str(x))[0])","31d13c3d":"data['Pclass'] = data['Pclass'].apply(lambda x : str(x))\ndata['SibSp'] = data['SibSp'].apply(lambda x : str(x))\ndata['Parch'] = data['Parch'].apply(lambda x : str(x))\ndata['Pers_per_ticket'] = data['Pers_per_Ticket'].apply(lambda x : str(x))\n\ncategorical = pd.get_dummies(data[['Survived','Pclass','Name','Sex','Age','Cabin','SibSp','Parch','Embarked','Pers_per_Ticket','Fare_per_pers']])\ncategorical","68eb561c":"X_train=categorical[~categorical.Survived.isnull()].drop('Survived',axis=1)\ny_train=categorical[~categorical.Survived.isnull()].Survived\n\nX_test = categorical[categorical.Survived.isnull()].drop('Survived',axis=1)\ny_test = categorical[categorical.Survived.isnull()].Survived\n\n#from sklearn.model_selection import train_test_split\n#X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.33, random_state=42)","1f6fefa2":"from sklearn.svm import SVC,LinearSVC\nfrom sklearn.model_selection import GridSearchCV","19d672f3":"model1 = SVC()\nparam_grid = {'C':[0.01,0.1,1,2,5,10,20,30,50,100]}\nGrid = GridSearchCV(model1, param_grid=param_grid, cv=5)\nGrid.fit(X_train,y_train)\n\nprint(f'Best param = {Grid.best_params_}')\ngrid_result = pd.DataFrame(Grid.cv_results_)\nprint(f\"Best accuracy for {Grid.best_params_} = {grid_result['mean_test_score'][Grid.best_index_]}\")","88d9a658":"#Prediction:\ny_test = Grid.predict(X_test)\n\n# submission file\nresult = pd.DataFrame({'PassengerId':test_data.PassengerId,'Survived': y_test })\nresult.Survived = result.Survived.apply(lambda x : int(x))\nresult.to_csv('model1_SVM_results.csv',index=False)","e03295c1":"from sklearn.ensemble import RandomForestClassifier","47a39ca3":"model2 = RandomForestClassifier()\nparam_grid = {'n_estimators':[10,100,500,1000]}\nGrid2 = GridSearchCV(model2, param_grid=param_grid, cv=5)\nGrid2.fit(X_train,y_train)","d1c15137":"print(f\"Best param: {Grid2.best_params_}\")\nGrid2_result = pd.DataFrame(Grid2.cv_results_)\nprint(f\"Best accuracy for {Grid2.best_params_}: {Grid2_result['mean_test_score'][Grid2.best_index_]}\")","8d05a09a":"### Age feature engineering to fill missing data","d5656577":"## Fare feature engineering to replace 0 values","110fd45a":"### Age to categorical","055dacd6":"## Fare_per_pers to categorical","1d4c09a8":"# 1 - Data clining and feature engineering","3fe92bee":"## Data split","3d3907c0":"## Name feature engineering ","d96e8a1b":"## Fare per person","dd3ec7eb":"Merging train and test set to apply data cleaning and feature engineering","c8f6e37c":"## Model 2 : Random Forrest","23625cd3":"## Model 1 : SVM"}}