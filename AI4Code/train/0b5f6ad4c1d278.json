{"cell_type":{"cd07dccf":"code","f5603875":"code","368ebffd":"code","0360ae83":"code","5739dfb6":"code","533b438c":"code","a25c38ec":"code","921888bc":"code","3c35ec2d":"code","2a55449d":"code","29ac67b0":"code","cf3aa164":"code","cc154c96":"code","2d09288d":"code","4b509cd5":"code","7b932277":"code","aaa82454":"code","2c1c6a96":"code","24ff6c87":"code","8afec131":"code","cca4de42":"code","1b69bb34":"code","9ca10236":"code","457c86cc":"code","01066757":"code","3c1a032f":"code","67cc2cd7":"code","276580fd":"code","637f715d":"markdown"},"source":{"cd07dccf":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport numpy as np\nimport scipy.misc\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\nfrom tensorflow.python.framework.ops import EagerTensor\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline","f5603875":"IMAGE_SIZE = 32\nBATCH_SIZE = 32\nCHANNELS = 3\nEPOCHS = 50","368ebffd":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/devnagri-script-classification\/Data\/Train\",\n    shuffle = True,\n    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n    batch_size = BATCH_SIZE\n)","0360ae83":"class_names = dataset.class_names","5739dfb6":"len(class_names)","533b438c":"n_classes = len(class_names)","a25c38ec":"for image_batch, label_batch in dataset.take(1):\n    plt.imshow(image_batch[0].numpy().astype(\"uint8\"))\n    plt.title(class_names[label_batch[0]])\n    plt.axis(\"off\")","921888bc":"n_classes","3c35ec2d":"def partition(data, train_split=0.8, valid_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    data_size = len(data)\n    \n    if shuffle:\n        data = data.shuffle(shuffle_size, seed=12)\n    \n    train_size = int(data_size*train_split)\n    valid_size = int(data_size*valid_split)\n    \n    train_ds = data.take(train_size)\n    valid_ds = data.skip(train_size).take(valid_size)\n    test_ds = data.skip(train_size).skip(valid_size)\n\n    return train_ds, valid_ds, test_ds","2a55449d":"train_ds, valid_ds, test_ds = partition(dataset)","29ac67b0":"len(train_ds), len(valid_ds), len(test_ds)","cf3aa164":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE) \nvalid_ds = valid_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE) \ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE) ","cc154c96":"def identity_block(X, f, filters, training=True, initializer=random_uniform):\n    F1, F2, F3 = filters\n \n    X_shortcut = X\n\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X) \n\n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training)\n\n    X = Add()([X_shortcut, X])\n    X = Activation('relu')(X) \n\n    return X","2d09288d":"def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    \n    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n    \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","4b509cd5":"def ResNet50(input_shape = (32, 32, 3), classes = n_classes):\n    X_input = Input(input_shape)\n\n    X = ZeroPadding2D((3, 3))(X_input)\n    X = tf.keras.layers.Rescaling(1.0\/255)(X)\n    X = tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)(X)\n\n    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n    \n    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n    \n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n    X = identity_block(X, 3, [256, 256, 1024])\n    X = identity_block(X, 3, [256, 256, 1024]) \n\n    X = AveragePooling2D(pool_size=(2, 2))(X) \n\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    model = Model(inputs = X_input, outputs = X)\n\n    return model","7b932277":"model = ResNet50(input_shape = (32, 32, 3), classes = n_classes)\nprint(model.summary())","aaa82454":"model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)","2c1c6a96":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    validation_data=valid_ds,\n    verbose=1\n)","24ff6c87":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","8afec131":"plt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(range(EPOCHS), acc, label='Training Accuracy')\nplt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(EPOCHS), loss, label='Training Loss')\nplt.plot(range(EPOCHS), val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","cca4de42":"model.evaluate(test_ds)","1b69bb34":"model.save(\"model\")","9ca10236":"class_names = dataset.class_names","457c86cc":"folder_path = '..\/input\/devnagri-script-classification\/Data\/Test'","01066757":"n_classes = len(class_names)","3c1a032f":"sample = pd.read_csv('..\/input\/devnagri-script-classification\/Data\/sample_submission.csv')","67cc2cd7":"import os\nimport cv2\n\nfor i in range(sample.shape[0]):\n    img = os.path.join(folder_path, str(i+1)+'.png')\n    img = cv2.imread(img)\n    img = np.expand_dims(img, 0)\n    sample.loc[i, 'Category'] = class_names[np.argmax(model.predict(img))]","276580fd":"sample.to_csv('submission.csv', index=False)","637f715d":"# RESNET"}}