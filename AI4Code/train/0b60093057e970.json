{"cell_type":{"3943ac4c":"code","0da90aff":"code","b036be3b":"code","7df79ebc":"code","1d1444d9":"code","cc48c7ea":"code","5e6d5b5e":"code","0f9c9373":"code","047ca5ca":"code","4c5a3a29":"code","c2ddec19":"markdown","983d21e5":"markdown","5e0b6f18":"markdown","9c7569a1":"markdown","ff2bfc7b":"markdown","8b35130c":"markdown","789d28f9":"markdown","6a9c1229":"markdown","d9e2fdcb":"markdown","87237d4e":"markdown"},"source":{"3943ac4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0da90aff":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\n\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten,Dense\nfrom keras.preprocessing.image import ImageDataGenerator","b036be3b":"train_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","7df79ebc":"def sigmoid(x):\n    return 1\/(1+np.exp(-x))\n\ndef face_detector(face_image_path):\n    face_model = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\")\n    img = cv2.imread(face_image_path)\n    img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n    img_color = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n    faces = face_model.detectMultiScale3(img, minNeighbors=6,outputRejectLevels =True)\n    faces_probs = sigmoid(faces[-1])\n    for i,d in enumerate(faces[0]):\n        (x,y,w,h) = d\n        if faces_probs[i]>0.95:\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),(0,0,255),1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n\n    \nface_detector(\"..\/input\/face-mask-detection\/images\/maksssksksss244.png\")","1d1444d9":"def data_agument(train_dir,val_dir,test_dir,target_size_ = (128,128),zoom_range_ = 0.2,shear_range_=0.2,batch_size_ = 32,class_mode_ = 'binary'):\n    train_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip=True, zoom_range=zoom_range_,shear_range=shear_range_)\n    train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=target_size_,class_mode='binary',batch_size=batch_size_)\n\n    val_datagen = ImageDataGenerator(rescale=1.0\/255)\n    val_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=target_size_,class_mode=class_mode_,batch_size=batch_size_)\n\n    test_datagen = ImageDataGenerator(rescale=1.0\/255)\n    test_generator = train_datagen.flow_from_directory(directory=test_dir,target_size=target_size_,class_mode=class_mode_,batch_size=batch_size_)\n    return train_generator,val_generator,test_generator\ntrain_gen,val_gen,test_gen = data_agument(train_dir,val_dir,test_dir)","cc48c7ea":"def build_train_model(train_generator,test_generator,val_generator,epoch = 25):\n    vgg19 = VGG19(weights = 'imagenet',include_top = False,input_shape = (128,128,3))\n    for layer in vgg19.layers:\n        layer.trainable = False\n\n    model = Sequential()\n    model.add(vgg19)\n    model.add(Flatten())\n    model.add(Dense(1,activation = 'sigmoid'))\n    model.summary()\n\n    model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n\n    history = model.fit_generator(generator=train_generator,\n                                  steps_per_epoch=len(train_generator)\/\/32,\n                                  epochs=epoch,validation_data=val_generator,\n                                  validation_steps=len(val_generator)\/\/32)\n    model.save('masknet.h5')\n    return history,model\nhistory,model = build_train_model(train_gen,test_gen,test_gen)","5e6d5b5e":"def evaluate(test_generator):\n    accuracy = model.evaluate_generator(test_generator)\n    print(\"VGG19 MODEL ACCURACY : \"+ str(accuracy[1]))\n    return accuracy\naccuracy = evaluate(test_gen)    ","0f9c9373":"plt.plot(history.history['loss'])\nplt.title('---: Model Loss :---')\nplt.ylabel('<-------Loss---------->')\nplt.xlabel('<-------Epoch--------->')\nplt.legend(['Loss'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.title('---: Model Accuracy :---')\nplt.ylabel('<--------Accuracy-------->')\nplt.xlabel('<--------Epoch---------->')\nplt.legend(['Accuracy'], loc='lower right')\nplt.show()","047ca5ca":"def predict(sample_img_path):\n    mask_label = {0:'MASK',1:'NO MASK'}\n    dist_label = {0:(0,255,0),1:(255,0,0)}\n    face_model = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n    img = cv2.imread(sample_img_path)\n    img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n    img_color = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n    faces = face_model.detectMultiScale3(img, minNeighbors=6,outputRejectLevels =True)\n    print(faces[0])\n    print(faces[-1])\n    \n    faces_probs = sigmoid(faces[-1])\n    print(faces_probs)\n    for i,d in enumerate(faces[0]):\n        (x,y,w,h) = d\n        if faces_probs[i]>0.95:\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),(0,0,255),4)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n    plt.show()\n    for i in range(len(faces[0])):\n        if faces_probs[i]>0.95:\n            (x,y,w,h) = faces[0][i]\n            crop = img_color[y:y+h,x:x+w]\n            crop = cv2.resize(crop,(128,128))\n            crop = np.reshape(crop,[1,128,128,3])\/255.0\n            mask_result = model.predict(crop)\n            #print(type(mask_result))\n            #print(mask_result)\n            cv2.putText(img_color,mask_label[np.round(mask_result[0][0])] +\" \"+ str(faces_probs[i]) ,(x, y-10),\n            cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[np.round(mask_result[0][0])],2)\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),dist_label[np.round(mask_result[0][0])],2)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n    plt.show()\npredict(\"..\/input\/face-mask-detection\/images\/maksssksksss244.png\")","4c5a3a29":"print(\"TATAL ACCURACY BY VGG19 MODEL : {} \".format(accuracy[1]))","c2ddec19":"# **Ploting Loss and Accuracy**","983d21e5":"# **Predict for Single Image**","5e0b6f18":"# **Loading The Data**","9c7569a1":"# **Data Agumentation**","ff2bfc7b":"# **Installing Requirements**","8b35130c":"# **Evaluatation**","789d28f9":"1. **Installing Requirements**\n2. **Loading The Data.**\n3. **CascadeClassifier**\n4. **Data Agumentation**\n5. **Build Model and Train**\n6. **Evaluate**\n7. **Ploting Loss and Accuracy**\n8. **Predict for Single Image**\n    * **Crop & Reshape Image**\n    * **predict**\n    * **plot**\n\n","6a9c1229":"# **Build Model and Train**","d9e2fdcb":"# **CascadeClassifier**","87237d4e":"# Table of Content"}}