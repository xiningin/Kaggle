{"cell_type":{"782ed354":"code","c4ea2406":"code","edfe421c":"code","1f7c22ab":"code","c9a2f1c7":"code","608930a2":"code","6f30b82d":"code","4db078bf":"code","c7def087":"code","cdff0430":"code","25841216":"code","703444f3":"code","b0ef0a62":"code","ba949f53":"code","248731b4":"code","39ce1b3f":"code","fc6f7e36":"code","4f45e959":"code","3cf1a633":"code","022dc116":"code","8755eb68":"code","74e647cb":"code","0f0afd2a":"markdown","b3d1345f":"markdown","b7076417":"markdown","e974b7da":"markdown","5b823d9d":"markdown","b42e2d07":"markdown","7d03615f":"markdown","8732257f":"markdown","0c8c73ef":"markdown","29b0e6c1":"markdown","2402650f":"markdown","64159993":"markdown"},"source":{"782ed354":"!git clone https:\/\/github.com\/leekunhee\/Mask_RCNN.git\n!cd Mask_RCNN && python setup.py install","c4ea2406":"import os,sys\nimport pandas as pd\nimport numpy as np\nfrom os import listdir\nfrom numpy import zeros, asarray, expand_dims, mean\nfrom matplotlib import pyplot\n\nROOT_DIR = os.path.abspath(\".\/Mask_RCNN\")\nsys.path.append(ROOT_DIR) \n\nfrom mrcnn.utils import Dataset,extract_bboxes\nfrom mrcnn.visualize import display_instances\nfrom mrcnn.config import Config\nfrom mrcnn.model import MaskRCNN\nfrom mrcnn.utils import compute_ap\nfrom mrcnn.model import load_image_gt\nfrom mrcnn.model import mold_image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","edfe421c":"bb_df = pd.read_csv('..\/input\/car-object-detection\/data\/train_solution_bounding_boxes (1).csv')","1f7c22ab":"bb_df.head() #displaying the first couple of rows","c9a2f1c7":"bb_df.describe() #checking the count and overview of data","608930a2":"bb_df.nunique() #count of unique values in the dataset","6f30b82d":"class CarsDataset(Dataset):\n    '''\n    Dataset class to load the images and their bounding boxes in the form of masks\n    '''\n    def load_dataset(self, dataset_dir='..\/input\/car-object-detection\/data', mode='train'):\n        '''\n        This function is used to load the dataset. We will only use 500 images for training the rest are for validation.\n        We also have test set for which we dont have labels but are useful for visually checking \n        for how effective the training was\n        '''\n        self.add_class('dataset',1,'car')\n        if mode=='train':\n            images_dir = dataset_dir + '\/training_images\/'\n            for i in range(500):\n                image_id = bb_df.iloc[i,0]\n                img_path = images_dir + image_id\n                self.add_image('dataset', image_id=image_id, path=img_path)\n        if mode=='val':\n            images_dir = dataset_dir + '\/training_images\/'\n            for i in range(500,len(bb_df)):\n                image_id = bb_df.iloc[i,0]\n                img_path = images_dir + image_id\n                self.add_image('dataset', image_id=image_id, path=img_path)\n        if mode=='test':\n            images_dir = dataset_dir + '\/testing_images\/'\n            for filename in listdir(images_dir):\n                image_id = filename\n                img_path = images_dir + filename\n                self.add_image('dataset', image_id=image_id, path=img_path)\n        \n    def extract_boxes(self, filename):\n        '''\n        To get the coordinates of the bounding boxes.\n        '''\n        boxes = list()\n        xmin = int(bb_df[bb_df['image']==filename].iloc[0,1])\n        ymin = int(bb_df[bb_df['image']==filename].iloc[0,2])\n        xmax = int(bb_df[bb_df['image']==filename].iloc[0,3])\n        ymax = int(bb_df[bb_df['image']==filename].iloc[0,4])\n        coors = [xmin, ymin, xmax, ymax]\n        boxes.append(coors)\n        width = 380\n        height = 676\n        return boxes, width, height\n    def load_mask(self, image_id):\n        '''\n        Takes the co-ordinates and uses that to make it into a mask.\n        '''\n        info = self.image_info[image_id]\n        file = info['id']\n        boxes, w, h = self.extract_boxes(file)\n        masks = zeros([w, h, len(boxes)], dtype='uint8')\n        class_ids = list()\n        for i in range(len(boxes)):\n            box = boxes[i]\n            row_s, row_e = box[1], box[3]\n            col_s, col_e = box[0], box[2]\n            masks[row_s:row_e, col_s:col_e, i] = 1\n            class_ids.append(self.class_names.index('car'))\n        return masks, asarray(class_ids, dtype='int32')\n    \n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path']","4db078bf":"#Loading all the datasets we will need.\ntrain_set = CarsDataset()\ntrain_set.load_dataset(mode='train')\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_ids))\n\nval_set = CarsDataset()\nval_set.load_dataset(mode='val')\nval_set.prepare()\nprint('Validate: %d' % len(val_set.image_ids))\n \ntest_set = CarsDataset()\ntest_set.load_dataset(mode='test')\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_ids))","c7def087":"def plot(num_img=5):\n    for i in range(num_img):\n        image_id = np.random.randint(0,len(train_set.image_ids))\n        image = train_set.load_image(image_id)\n        mask, class_ids = train_set.load_mask(image_id)\n        pyplot.imshow(image)\n        pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.3)\n        pyplot.show()","cdff0430":"plot()","25841216":"class CarsConfig(Config):\n    NAME = \"cars_cfg\"\n    NUM_CLASSES = 2 #Bckground is counted as class too so background + cars = 2 labels\n    STEPS_PER_EPOCH = 200\n    VALIDATION_STEPS = 20\n    IMAGES_PER_GPU = 1\n    IMAGE_MIN_DIM = 384\n    IMAGE_MAX_DIM = 448\n    \nconfig = CarsConfig()","703444f3":"config.display() #list of all available configurations","b0ef0a62":"model = MaskRCNN(mode='training', model_dir='.\/', config=config)","ba949f53":"model.load_weights('..\/input\/mask-rcnn-coco-weights\/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])","248731b4":"model.train(train_set, val_set, learning_rate=config.LEARNING_RATE, epochs=10, layers='all')","39ce1b3f":"class PredictionConfig(Config):\n    NAME = \"cars_cfg\"\n    NUM_CLASSES = 2\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    USE_MINI_MASK = False","fc6f7e36":"cfg = PredictionConfig()\nmodel = MaskRCNN(mode='inference', model_dir='.\/', config=cfg)","4f45e959":"for i in listdir():\n    if i[:4]=='cars':\n        path=i\nmodel.load_weights('.\/'+path+'\/mask_rcnn_cars_cfg_0010.h5', by_name=True)","3cf1a633":"def evaluate_model(dataset, model, cfg):\n    APs = list()\n    for image_id in dataset.image_ids:\n        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id)\n        scaled_image = mold_image(image, cfg)\n        sample = expand_dims(scaled_image, 0)\n        yhat = model.detect(sample, verbose=0)\n        r = yhat[0]\n        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n        APs.append(AP)\n    mAP = mean(APs)\n    return mAP","022dc116":"train_mAP = evaluate_model(train_set, model, cfg)\nprint(\"Train mAP: %.3f\" % train_mAP)\nval_mAP = evaluate_model(val_set, model, cfg)\nprint(\"Validation mAP: %.3f\" % val_mAP)","8755eb68":"def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n    for i in range(n_images):\n        id = np.random.randint(0,len(dataset.image_ids))\n        pyplot.figure(figsize=(50, 50))\n        image = dataset.load_image(id)\n        mask, _ = dataset.load_mask(id)\n        scaled_image = mold_image(image, cfg)\n        sample = expand_dims(scaled_image, 0)\n        yhat = model.detect(sample, verbose=0)[0]\n        pyplot.subplot(n_images, 2, i*2+1)\n        pyplot.imshow(image)\n        pyplot.title('Actual')\n        for j in range(mask.shape[2]):\n            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n        pyplot.subplot(n_images, 2, i*2+2)\n        pyplot.imshow(image)\n        pyplot.title('Predicted')\n        ax = pyplot.gca()\n        for box in yhat['rois']:\n            y1, x1, y2, x2 = box\n            width, height = x2 - x1, y2 - y1\n            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n            ax.add_patch(rect)\n    pyplot.show()","74e647cb":"from matplotlib.patches import Rectangle\nplot_actual_vs_predicted(val_set, model, cfg)","0f0afd2a":"# Dataset\n\nFirst we will read from the csv and try to understand the format of data.","b3d1345f":"Here we will visualise some of the images from the dataset along side their masks.","b7076417":"# Evaluation\n\nWe need to define a seperate config file for predictions purposes.","e974b7da":"# Training\n\nThis config file contains a lot of important parameters for model training.","5b823d9d":"We are going to load pre-trained weights for this task. This will save us a lot of time because these algorithms can take a lot of time to converge","b42e2d07":"# References\n\nI referred to this blog about objection detection with mask-rcnn and applied that to this dataset about cars.\nLink: https:\/\/machinelearningmastery.com\/how-to-train-an-object-detection-model-with-keras\/","7d03615f":"Loading the saved weights to perform inference.","8732257f":"Here we will calculate mean average precision for our model. To know in detail what it means try referring to this blog\nhttps:\/\/towardsdatascience.com\/map-mean-average-precision-might-confuse-you-5956f1bfa9e2","0c8c73ef":"# Actual vs Predicted\n\nFianlly we will compare our model preformances by simply seeing how well it is detecting cars compared to the real bounding boxes.","29b0e6c1":"As you can see from above that total unique rows for image is less than total number of rows meaning we have some images repeated multiple times i.e some images have multiple cars in them. Which is why some images are repeated to give the data about their multiple bounding boxes.","2402650f":"# Importing and Installing libraries\n\nFor my code I am using this repository that supports Tensorflow 2+.","64159993":"Thank you for your time, and dont forget to upvote this notebook if you found it helpful."}}