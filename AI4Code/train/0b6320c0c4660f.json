{"cell_type":{"1cfe79bc":"code","f5f3f395":"code","a3339cf8":"code","007ad723":"code","cf6a34d7":"code","3cbbe314":"code","dda1a11c":"code","6b0f7290":"code","55302347":"code","fb9e2da5":"code","d18693b7":"code","a789cfbc":"code","6d8c8547":"code","ff2cd834":"code","1aef19c1":"code","2a1c5960":"code","3204a9e5":"code","e939d70a":"code","e05c4238":"code","455fc0fe":"code","83a9bb2c":"code","7d709a0d":"code","e697fd54":"code","e6523712":"code","f2e7f768":"code","b948903a":"code","d6f564c2":"code","c4d68105":"code","8c8c6730":"code","8971ef2a":"code","691b59b3":"code","006c1e35":"code","0bbaa691":"code","524fa39c":"code","577ef57f":"code","e01867a9":"code","e9b7f977":"code","f41597e2":"code","8f83a225":"code","49bf0fc7":"code","d6d5c0e5":"code","310f6661":"code","2990b774":"code","561b10e5":"code","dd569b3a":"code","542e2c10":"code","963686df":"code","67def4d9":"code","9dcd2f54":"code","80e9f478":"code","e3a3fbb6":"code","039fcc05":"code","0063aadd":"code","d88d4953":"code","d3d3cb27":"code","faccf0cc":"markdown","efec1cdf":"markdown","63a628cc":"markdown","6de1ae24":"markdown","ce1263b3":"markdown","220c246b":"markdown","5e07f166":"markdown","70c0b4d4":"markdown","11c33477":"markdown","28edfa65":"markdown","0bffdc63":"markdown","1a9abea3":"markdown","4c297dfb":"markdown","c9c2aff2":"markdown","1ad91170":"markdown","e1f6cbab":"markdown","755df396":"markdown","3f22967a":"markdown","cb6e26f0":"markdown","3bb3c6f2":"markdown","ffdc3983":"markdown","6d540e2d":"markdown","2a559388":"markdown"},"source":{"1cfe79bc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","f5f3f395":"df = pd.read_csv('..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv')","a3339cf8":"!pip install pandas_profiling","007ad723":"from pandas_profiling import ProfileReport","cf6a34d7":"design_report = ProfileReport(df)\ndesign_report.to_file(output_file='report.html')","3cbbe314":"design_report","dda1a11c":"df.head(10)","6b0f7290":"df.shape","55302347":"df.info()","fb9e2da5":"df.describe()","d18693b7":"df['Credit_History'].value_counts()","a789cfbc":"df['Credit_History'] = df['Credit_History'].astype('O')","6d8c8547":"df.describe(include='O')","ff2cd834":"df.drop('Loan_ID',axis=1,inplace=True)","1aef19c1":"df.duplicated().any()","2a1c5960":"df.Loan_Status.value_counts().plot.bar(color='blue')","3204a9e5":"plt.figure(figsize=(8,6))\nsns.countplot(df['Loan_Status']);\n\nprint('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] \/ len(df)))\nprint('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] \/ len(df)))","e939d70a":"# Credit_History\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Credit_History');\n\n# we didn't give a loan for most people who got Credit History = 0\n# but we did give a loan for most of people who got Credit History = 1\n# so we can say if you got Credit History = 1 , you will have better chance to get a loan\n\n# important feature","e05c4238":"# Gender\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Gender');\n\n# most males got loan and most females got one too so (No pattern)\n\n# i think it's not so important feature, we will see later","455fc0fe":"# Married\nplt.figure(figsize=(15,5))\nsns.countplot(x='Married', hue='Loan_Status', data=df);\n\n# most people who get married did get a loan\n# if you'r married then you have better chance to get a loan :)\n# good feature","83a9bb2c":"df.Dependents.value_counts()","7d709a0d":"# Dependents\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Dependents', hue='Loan_Status', data=df);\n\n# first if Dependents = 0 , we got higher chance to get a loan ((very hight chance))\n# good feature","e697fd54":"# Education\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Education');\n\n# If you are graduated or not, you will get almost the same chance to get a loan (No pattern)\n# Here you can see that most people did graduated, and most of them got a loan\n# on the other hand, most of people who did't graduate also got a loan, but with less percentage from people who graduated\n\n# not important feature","e6523712":"# Self_Employed\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Self_Employed');\n\n# No pattern (same as Education)","f2e7f768":"# Property_Area\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Property_Area', hue='Loan_Status', data=df);\n\n# We can say, Semiurban Property_Area got more than 50% chance to get a loan\n\n# good feature","b948903a":"sns.heatmap(df.corr(),annot=True)\nplt.show()","d6f564c2":"df.isnull().sum().sort_values(ascending = False)","c4d68105":"cat_data = []\nnum_data = []\n\nfor i,c in enumerate(df.dtypes):\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else :\n        num_data.append(df.iloc[:, i])","8c8c6730":"cat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","8971ef2a":"cat_data.head()","691b59b3":"num_data.head()","006c1e35":"cat_data.isnull().sum()","0bbaa691":"# If you want to fill every column with its own most frequent value you can use\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncat_data.isnull().sum().any() # no more missing data ","524fa39c":"num_data.isnull().sum()","577ef57f":"# fill every missing value with their previous value in the same column\n\nnum_data.fillna(method='bfill', inplace=True)\nnum_data.isnull().sum().any() # no more missing data ","e01867a9":"from sklearn.preprocessing import LabelEncoder  \nle = LabelEncoder()\ncat_data.head()","e9b7f977":"# transform the target column\n\ntarget_values = {'Y': 0 , 'N' : 1}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)","f41597e2":"# transform other columns\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","8f83a225":"cat_data.head(10)","49bf0fc7":"target.head()","d6d5c0e5":"df = pd.concat([cat_data, num_data, target], axis=1)","310f6661":"df.head()","2990b774":"X = pd.concat([cat_data,num_data],axis=1)\ny = target","561b10e5":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n","dd569b3a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","542e2c10":"    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)","963686df":"model = LogisticRegression()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n","67def4d9":"def metrics(y_true,y_pred,retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))\n    ","9dcd2f54":"metrics(y_test,y_pred)","80e9f478":"tree = DecisionTreeClassifier(max_depth=2,random_state=42)","e3a3fbb6":"tree.fit(X_train,y_train)\ny_pred_tree = tree.predict(X_test)","039fcc05":"metrics(y_test,y_pred_tree)","0063aadd":"forest = RandomForestClassifier()\nforest.fit(X_train,y_train)\ny_pred_forest = forest.predict(X_test)","d88d4953":"metrics(y_test,y_pred_forest)","d3d3cb27":"# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\nprint(forest.get_params())","faccf0cc":"### Using Random Forest","efec1cdf":"We got no duplicated rows","63a628cc":"We have missing data , we will handle them as we go","6de1ae24":"Before analyse the dependents columns let's analyse the different value inside.","ce1263b3":"We are going to work on binary classification problem, where we got some information about sample of peoples , and we need to predict whether we should give some one a loan or not depending on his information . we actually have a few sample size (614 rows), so we will go with machine learning techniques to solve our problem .","220c246b":"## Import libraries","5e07f166":"### Correlation","70c0b4d4":"### Processing our data","11c33477":"We can now contact our cat data, num data, and our target data","28edfa65":"### Train the data","0bffdc63":"### Categorical columns\n","1a9abea3":"## The Dataset\nIn the Dataset we find the following variables:\n- Loan ID, the identifier code of each applicant.\n- Gender, Male or Female for each applicant.\n- Married, the maritage state.\n- Dependents, how many dependents does the applicant have?\n- Education, the level of education, graduate or non graduate\n- Self Employed, Yes or No in the case\n- Applicant Income\n- Coapplicant Income\n- Loan Amount\n- Loan Amount Term\n- Credit History, just Yes or No in the case\n- Property Area, urban, semiurban or rural area of the applicant\u2019s property\n- Loan Status, Yes or No ( The independent Variable)","4c297dfb":"### Using Logistic Regression","c9c2aff2":"Missing values","1ad91170":"we are going to use LabelEncoder :","e1f6cbab":"##### Among all industries, the insurance domain has one of the largest uses of analytics & data science methods. This dataset provides you a taste of working on data sets from insurance companies \u2013 what challenges are faced there, what strategies are used, which variables influence the outcome, etc. This is a classification problem. The data has 615 rows and 13 columns.\n\n**Problem: Predict if a loan will get approved or not.**","755df396":"Let's separate the numerical columns from the categorical\n","3f22967a":"Let's analyse our data with pandas profiling first","cb6e26f0":"We will drop ID because it's not important for our model","3bb3c6f2":"It seems that credit history is 1 or 0. So let's change it to binary","ffdc3983":"##### Do we have any duplicate ?","6d540e2d":"#### Let's look at our target","2a559388":"### Using Decision Tree"}}