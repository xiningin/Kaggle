{"cell_type":{"3450cade":"code","05126c93":"code","3eacabd9":"code","32b3e687":"code","86aff0d6":"code","e8505087":"code","05d057a0":"code","cc9def05":"code","02ff27c3":"code","e408c623":"code","85e8c598":"code","e661717f":"code","d7c32903":"code","ebedf9c2":"code","1a52a260":"code","db5abcde":"code","09796c40":"code","ac337175":"code","b31a18e6":"code","75df6329":"code","d4f0ec2b":"code","d4d42164":"code","cbbf6a7b":"code","a273d6c4":"code","87d4df9d":"code","a15ad5c2":"code","f3612f1f":"code","add60bd8":"code","55d7b612":"code","3f85bb73":"code","042b5ca1":"code","a41bb1ef":"code","cb339774":"code","efeacb2c":"code","64a6c92e":"code","6a1aa979":"code","64881441":"code","35a381c1":"markdown","7b28318b":"markdown","a86d035f":"markdown","af3cbb9c":"markdown","067a8eec":"markdown","37a57bb2":"markdown","d685364a":"markdown","4369e14c":"markdown","6a6c494b":"markdown","1b69167e":"markdown","fa2340e8":"markdown","4f8b66be":"markdown","b9b242db":"markdown","cff62489":"markdown","16f88a0b":"markdown"},"source":{"3450cade":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05126c93":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3eacabd9":"data=pd.read_csv(r\"\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv\",sep=\";\")\ndata.head()","32b3e687":"data.info()","86aff0d6":"data.describe()","e8505087":"data.isna().sum()","05d057a0":"data[\"age\"]=data[\"age\"]\/365\ndata[\"age\"]=data[\"age\"].astype(\"int\")","cc9def05":"data=data.drop(columns=[\"id\"])","02ff27c3":"fig, ax = plt.subplots(figsize=(15,10))\nsns.boxplot(data=data, width= 0.5,ax=ax,  fliersize=3)\nplt.title(\"Visualization of outliers\")","e408c623":"outlier = ((data[\"ap_hi\"]>200) | (data[\"ap_lo\"]>180) | (data[\"ap_lo\"]<50) | (data[\"ap_hi\"]<=80) | (data[\"height\"]<=100)\n             | (data[\"weight\"]<=28) )\nprint(\"There is {} outlier\".format(data[outlier][\"cardio\"].count()))","85e8c598":"data = data[~outlier]","e661717f":"X = data.drop(columns = ['cardio'])\ny = data['cardio']","d7c32903":"plt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\n\nfor column in X:\n    if plotnumber<=16 :\n        ax = plt.subplot(4,4,plotnumber)\n        sns.stripplot(y,X[column])\n    plotnumber+=1\n\nplt.tight_layout()","ebedf9c2":"corr = X.corr()\nf, ax = plt.subplots(figsize = (15,15))\nsns.heatmap(corr, annot=True, fmt=\".3f\", linewidths=0.5,cmap=\"Blues_r\", ax=ax)","1a52a260":"from sklearn.preprocessing import MinMaxScaler\nscalar=MinMaxScaler()\nx_scaled=scalar.fit_transform(X)","db5abcde":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,roc_curve, roc_auc_score","09796c40":"x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.30,random_state=420)","ac337175":"dtc = DecisionTreeClassifier()\nran = RandomForestClassifier(n_estimators=90)\nknn = KNeighborsClassifier(n_neighbors=79)\nsvm = SVC(random_state=6)","b31a18e6":"models = {\"Decision tree\" : dtc,\n          \"Random forest\" : ran,\n          \"KNN\" : knn,\n          \"SVM\" : svm}\nscores= { }","75df6329":"for key, value in models.items():    \n    model = value\n    model.fit(x_train, y_train)\n    scores[key] = model.score(x_test, y_test)","d4f0ec2b":"scores_frame = pd.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","d4d42164":"from sklearn.metrics import plot_roc_curve","cbbf6a7b":"disp = plot_roc_curve(dtc,x_test,y_test)\n\nplot_roc_curve(ran,x_test,y_test,ax=disp.ax_)\n\nplot_roc_curve(knn,x_test,y_test,ax=disp.ax_)\n\nplot_roc_curve(svm,x_test,y_test,ax=disp.ax_)\n","a273d6c4":"predicted_svc=svm.predict(x_test)","87d4df9d":"predicted_knn=knn.predict(x_test)","a15ad5c2":"accuracy=accuracy_score(y_test,predicted_svc)\nprint(\"The accuracy of svc model is : \",accuracy)","f3612f1f":"conf_mat = confusion_matrix(y_test,predicted_svc)\nprint(\"The Confusion Matrix for SVC in this dataset is : \\n\",conf_mat)","add60bd8":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","55d7b612":"# Precison\nPrecision = true_positive\/(true_positive+false_positive)\nprint(\"The precision of this svc model is : \",Precision)","3f85bb73":"# Recall\nRecall= true_positive\/(true_positive+false_negative)\nprint(\"The Recall score of svc model is : \",Recall)","042b5ca1":"F1_Score = 2*(Recall * Precision) \/ (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","a41bb1ef":"accuracy=accuracy_score(y_test,predicted_knn)\nprint(\"The accuracy of knn model is : \",accuracy)","cb339774":"conf_mat = confusion_matrix(y_test,predicted_knn)\nprint(\"The Confusion Matrix for KNN in this dataset is : \\n\",conf_mat)","efeacb2c":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","64a6c92e":"# Precison\nPrecision = true_positive\/(true_positive+false_positive)\nprint(\"The precision of this knn model is : \",Precision)","6a1aa979":"# Recall\nRecall= true_positive\/(true_positive+false_negative)\nprint(\"The Recall score of knn model is : \",Recall)","64881441":"F1_Score = 2*(Recall * Precision) \/ (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","35a381c1":"#### From the table and graph we can see that the SVM and KNN are performing better than other models","7b28318b":"#### Here we can see some outliers present in some features\n#### There are some abnormal values present in every data which not possible\n#### The systolic and diastolic pressure values have values in negative and some are abnormal\n#### I made a research on this features and tried to to reduce the outliers\n","a86d035f":"### SVC gives a better result than other models,in terms of Accuracy score,Auc score and F1_score Svc gives good result. so we can take svc to predict whether a person has cardio or not with good accuracy of 73%.","af3cbb9c":"### We already have 69301 data and this 1434 is only a 2% of it.\n### So we have enough data to train the model even if we remove these outliers.\n### Without replacing values for these outliers we can remove it.","067a8eec":"### Evaluation of KNN","37a57bb2":"### age is given in days we need to convert that into years for easy understanding","d685364a":"## Scaling of data","4369e14c":"### From the graph we can see that if ap_lo is more than 120 there is high chance of cardio\n### If the age is less 38 there is very less chance or no chance of cardio\n### If the weight is more than 175 there is a chance of cardio","6a6c494b":"### Evaluation of SVC","1b69167e":"### there are some corrections need to be made","fa2340e8":"### we can see that there is no much collinearity between any data","4f8b66be":"### Here there is no null values present","b9b242db":"## Heat map to check the multicollinearity","cff62489":"# Conclusion","16f88a0b":"### Let's evaluate with other metrics"}}