{"cell_type":{"477279c4":"code","7cb3fd00":"code","644d7de6":"code","0fe94cca":"code","b5e8114a":"code","7fa7b234":"code","15b9cb64":"code","fbed6683":"code","6bf16e5f":"code","0d6b88d5":"code","f652deba":"code","fb1a2282":"markdown","5e8a4894":"markdown","cb30dd59":"markdown","1c302c0d":"markdown"},"source":{"477279c4":"import pandas as pd\nimport numpy as np\npd.set_option('max_rows', 1000)\npd.set_option('max_columns', 200)\nfrom IPython.display import display\n# reading data\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndisplay(train.head())\ndisplay(train.describe())\ntrain.info()","7cb3fd00":"def data_cleaning(data):\n    # encode sex\n    data.Sex =  data.Sex.factorize()[0]\n    # encoding miss age \n    data.Age = data.Age.apply(lambda x: x\/\/10)\n    data.Age.fillna(-1, inplace=True)\n    data.Fare = data.Fare.apply(lambda x: x\/\/50)\n    # NAN becomes n\n    data.Cabin = data.Cabin.astype(str).apply(lambda x: x[0])\n    data.Cabin = data.Cabin.factorize()[0]\n    data.Embarked = data.Embarked.astype(str).apply(lambda x: x[0])\n    data.Embarked = data.Embarked.factorize()[0]\n    return data\n\ntrain_cleaned = data_cleaning(train)\ntest_cleaned = data_cleaning(test)","644d7de6":"def trainVStest(train, test, *cols):\n    for col in cols:\n        display(test[col].value_counts(normalize=True))\n        display(train[col].value_counts(normalize=True))\n\ntrainVStest(train_cleaned, test_cleaned, 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch','Fare', 'Cabin', 'Embarked')","0fe94cca":"# plot against target to extract information\nimport matplotlib.pyplot as plt \ndef plotVStarget(data, target, *cols):\n    for col in cols:\n        table = data.groupby([col], as_index=False)[target].mean()\n        plt.bar(table.iloc[:, 0], table.iloc[:, 1])\n        plt.title(col)\n        plt.show()\nplotVStarget(train_cleaned, 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch','Fare', 'Cabin', 'Embarked')","b5e8114a":"# make sure train test encoding is the same before apply this, as we see from EDA, there are some classes not available in test\n# from Age plot\ndef data_engineering(data):\n    data['G_Age'] = data.Age.apply(lambda x: 1 if x==0 else 0)\n    data['G_SibSp'] = data.SibSp.apply(lambda x:1 if (x==1 or x==2) else 0)\n    data['B_SibSp'] = data.SibSp.apply(lambda x:1 if x>=4 else 0)\n    data['G_Parch'] = data.Parch.apply(lambda x:1 if (x==1 or x==2 or x==3) else 0)\n    data['B_Parch'] = data.Parch.apply(lambda x:1 if x>=5 else 0)\n    data['B_Fare'] = data.Fare.apply(lambda x:1 if x==0 else 0)\n    data['G_Cabin'] = data.Cabin.apply(lambda x:1 if (x==2 or x==4 or x==6) else 0)\n    data['B_Cabin'] = data.Cabin.apply(lambda x:1 if x==0 else 0)\n    data['G_Embarked'] = data.Embarked.apply(lambda x:1 if x==3 else 0)\n    return data\ntrain_cleaned = data_engineering(train_cleaned)\ntest_cleaned = data_engineering(test_cleaned)","7fa7b234":"# before stacking, make sure no NANs or non-numeric for the input columns \ndisplay(train_cleaned.isnull().sum(axis=0))\ndisplay(test_cleaned.isnull().sum(axis=0))","15b9cb64":"# fill in missing fare with median for test_cleaned\ntest_cleaned.Fare.fillna(test_cleaned.Fare.median(), inplace=True)","fbed6683":"# prepare the input columns to model fitting\ntrain_col = train_cleaned.columns.tolist()\ntest_col = test_cleaned.columns.tolist()\nprint(train_col)\nprint(test_col)\ninput_col = set(test_col) - set(['PassengerId', 'Name', 'Ticket'])\nprint(input_col)","6bf16e5f":"# 1st level: GBT_R, RF_R, SVR, LR. KNN_R \n# 2nd level: Linear model\nimport sklearn.ensemble as ensemble\nimport sklearn.neighbors as neighbors\nimport sklearn.linear_model as linear\nimport sklearn.svm as svm\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn import tree\nfrom sklearn import neural_network\nfrom sklearn.model_selection import train_test_split\n\nmodels = [[ensemble.GradientBoostingRegressor(),\n           ensemble.RandomForestRegressor(),\n           svm.SVR(),\n           linear.BayesianRidge(),\n           GaussianProcessRegressor(),\n           tree.DecisionTreeRegressor(),\n           neural_network.MLPRegressor(),\n           neighbors.KNeighborsRegressor()], \n         linear.BayesianRidge()]\n\n# creates dataframe to store first level result\nfirst_level_B = pd.DataFrame()\nfirst_level_C = pd.DataFrame()\ni = 0\nfor AB_C in [(train_cleaned[input_col], test_cleaned[input_col])]:\n    AB, C = AB_C[0], AB_C[1]\n    A_x, B_x, A_y, B_y = train_test_split(AB, train_cleaned.Survived, test_size=0.5, random_state=42)\n    for model in models[0]:\n        model.fit(A_x, A_y)\n        first_level_B[type(model).__name__+'_'+str(i)] = model.predict(B_x)\n        first_level_C[type(model).__name__+'_'+str(i)] = model.predict(C)\n    i += 1\n    \nfirst_level_B['B_y'] = B_y.to_numpy()\ndisplay(first_level_B.head())\nfirst_level_C.head()","0d6b88d5":"# perform second level stacking\nfinal_model = models[1]\nfinal_model.fit(first_level_B.iloc[:,:-1], first_level_B.iloc[:,-1])\nfrom sklearn.metrics import accuracy_score\ntraining_prediction = final_model.predict(first_level_B.iloc[:,:-1])\ntraining_prediction = training_prediction > 0.5\ntraining_accuracy = accuracy_score(first_level_B.iloc[:,-1], training_prediction)\nprint(training_accuracy)\n\nsubmission = final_model.predict(first_level_C.iloc[:,:]) > 0.5","f652deba":"# output submission.csv\nsubmission_df = pd.DataFrame({'PassengerId':test_cleaned.PassengerId , 'Survived':submission.astype(np.int32)})\nsubmission_df.to_csv('.\/submission.csv', index=False)\nfrom IPython.display import FileLink\nFileLink(r'.\/submission.csv')","fb1a2282":"# Step 3. Stacking from multiple classes of models","5e8a4894":"# **Step 1: EDA**\n    1. cleaning the dataset e.g scale, encoding, Null, duplicate features\n    2. checking train vs test distribution as this can affect our validation setup\n    3. explore features and feature interaction by plots","cb30dd59":"# **Step 2: Advanced Feature engineering**\n    1. Engineering based on domain knowledge\n    2. decompose dense feature and more feature interaction\n    3. mean encoding or target encoding (optional)\n    4. apply PCA or tsne to model with high dimension (if dimensionality is high)","1c302c0d":"*It seems that for the most part, train and test are similar, however for some attributes like Embarked, train can be learnt more*"}}