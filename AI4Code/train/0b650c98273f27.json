{"cell_type":{"e8cb2cce":"code","f905c8c3":"code","819f3e87":"code","86b15fe6":"code","a80f3968":"code","72e8ec34":"code","7819d952":"code","191c81e9":"code","c3503f17":"code","38c7ccbb":"code","c9f61206":"code","24ca89f3":"code","393d21ad":"code","52707064":"code","91e11eaa":"code","56444616":"code","7f729419":"code","c076862a":"code","18a7b5e5":"code","11ff890f":"code","096c60c3":"code","87fa8a1c":"code","2ce0c65d":"code","bf38b5ac":"code","fc62b23f":"code","f2bfc970":"code","f765f38a":"code","be73d8e8":"code","bdfbde64":"code","c3a3cebd":"code","c0de72aa":"code","6596c0c3":"code","00d6aa10":"code","7d730ea6":"code","218a4f4d":"code","3dba1337":"code","b9b10a48":"code","8326c8ea":"code","6a34b9dc":"code","00e0e0b2":"code","2ea5497c":"code","bed532aa":"code","5bf95e2d":"code","6e17bf2c":"code","8c5c31d2":"code","2a10817c":"code","dec0bb2a":"code","2cd257af":"code","4d4c837c":"code","74dca8eb":"code","d3d252c6":"code","f6cab3e7":"code","2ce8b115":"code","8bf4ee1c":"code","2b87bd2b":"markdown","5cd2b526":"markdown","ad9650bc":"markdown","3652bcf0":"markdown","80b9dae9":"markdown","4267e8a0":"markdown","b711e731":"markdown","e28e0145":"markdown","14375850":"markdown","87bcdd89":"markdown","e65f521e":"markdown","ea4bc23b":"markdown","dec32cf7":"markdown","fedf0846":"markdown","3271b007":"markdown","63ed2e99":"markdown","2241c7cb":"markdown","addfa081":"markdown","c7d8d2cc":"markdown","a073ecad":"markdown","e93e5403":"markdown","dad59590":"markdown","7de72e1c":"markdown","ff34a172":"markdown","75a79693":"markdown","ad0859c6":"markdown","44e82e45":"markdown","362bd64e":"markdown","51567ce9":"markdown","8de7660b":"markdown","40b897c9":"markdown","f4f53911":"markdown","a822c26c":"markdown","eab2853e":"markdown","c5b7dcd7":"markdown","2418223b":"markdown","1429e22e":"markdown","31e09ac7":"markdown","49a2d842":"markdown","95836614":"markdown","e344759e":"markdown","1439b5a2":"markdown","cc058469":"markdown","67747b74":"markdown","26c1f476":"markdown","3d0458ce":"markdown","eae939fe":"markdown","4055fc45":"markdown"},"source":{"e8cb2cce":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier ","f905c8c3":"train = pd.read_csv('\/kaggle\/input\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/test.csv')","819f3e87":"train.head()","86b15fe6":"train.shape","a80f3968":"test.head()","72e8ec34":"test.shape","7819d952":"train.describe()","191c81e9":"train.info()","c3503f17":"sns.countplot(x=\"price_range\", data=train,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))","38c7ccbb":"train.columns","c9f61206":"print('number of unique values for attery power is : {}'.format(len(train.battery_power.unique())))\ntrain.battery_power.unique()","24ca89f3":"train['battery code'] = round(train['battery_power']\/100)","393d21ad":"print('number of unique values for attery power is : {}'.format(len(train['battery code'].unique())))\ntrain['battery code'].unique()","52707064":"sns.jointplot(\"battery code\", \"price_range\", train, kind='kde')","91e11eaa":"sns.barplot(x=\"battery code\", y=\"price_range\", data=train)","56444616":"train.drop(['battery code'], axis=1, inplace=True)","7f729419":"sns.barplot(x=\"dual_sim\", y=\"price_range\", data=train)","c076862a":"train.drop(['dual_sim'], axis=1, inplace=True)","18a7b5e5":"sns.barplot(x=\"blue\", y=\"price_range\", data=train)","11ff890f":"train.drop(['blue'], axis=1, inplace=True)","096c60c3":"sns.jointplot(\"clock_speed\", \"price_range\", train, kind='kde')","87fa8a1c":"sliced_train = train.loc[:,['price_range','battery_power','clock_speed'] ]","2ce0c65d":"sliced_train.head()","bf38b5ac":"sns.heatmap(sliced_train.corr(), annot=True, linewidths=.5, fmt= '.1f')","fc62b23f":"sliced_train = train.loc[:,['price_range','fc', 'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores']]   ","f2bfc970":"sliced_train.head()","f765f38a":"sns.heatmap(sliced_train.corr(), annot=True, linewidths=.5, fmt= '.1f')","be73d8e8":"sliced_train = train.loc[:,['price_range', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w']]   ","bdfbde64":"sliced_train.head()","c3a3cebd":"sns.heatmap(sliced_train.corr(), annot=True, linewidths=.5, fmt= '.1f')","c0de72aa":"sliced_train = train.loc[:,['price_range', 'talk_time', 'three_g', 'touch_screen', 'wifi']]   ","6596c0c3":"sliced_train.head()","00d6aa10":"sns.heatmap(sliced_train.corr(), annot=True, linewidths=.5, fmt= '.1f')","7d730ea6":"X_data = train.drop(['price_range'], axis=1, inplace=False)\ny_data = train['price_range']","218a4f4d":"X_data.head()","3dba1337":"X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=44, shuffle =True)","b9b10a48":"print('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","8326c8ea":"SelectedModel = SVC(gamma='auto_deprecated')\nSelectedParameters = {'kernel':('linear', 'rbf'), 'C':[1,2,3,4,5]}\n\n\nGridSearchModel = GridSearchCV(SelectedModel,SelectedParameters, cv = 2,return_train_score=True)\nGridSearchModel.fit(X_train, y_train)\nsorted(GridSearchModel.cv_results_.keys())\nGridSearchResults = pd.DataFrame(GridSearchModel.cv_results_)[['mean_test_score', 'std_test_score', 'params' , 'rank_test_score' , 'mean_fit_time']]","6a34b9dc":"print('All Results are :\\n', GridSearchResults )\nprint('===========================================')\nprint('Best Score is :', GridSearchModel.best_score_)\nprint('===========================================')\nprint('Best Parameters are :', GridSearchModel.best_params_)\nprint('===========================================')\nprint('Best Estimator is :', GridSearchModel.best_estimator_)","00e0e0b2":"SVCModel =  GridSearchModel.best_estimator_\nSVCModel.fit(X_train, y_train)","2ea5497c":"print('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n\n\ny_pred = SVCModel.predict(X_test)\nprint('Predicted Value for SVCModel is : ' , y_pred[:10])","bed532aa":"SelectedModel = LogisticRegression(penalty='l2' , solver='sag',random_state=33)\nSelectedParameters = {'C':[1,2,3,4,5]}\n\n\nGridSearchModel = GridSearchCV(SelectedModel,SelectedParameters, cv = 4,return_train_score=True)\nGridSearchModel.fit(X_train, y_train)\nsorted(GridSearchModel.cv_results_.keys())\nGridSearchResults = pd.DataFrame(GridSearchModel.cv_results_)[['mean_test_score', 'std_test_score', 'params' , 'rank_test_score' , 'mean_fit_time']]","5bf95e2d":"print('All Results are :\\n', GridSearchResults )\nprint('===========================================')\nprint('Best Score is :', GridSearchModel.best_score_)\nprint('===========================================')\nprint('Best Parameters are :', GridSearchModel.best_params_)\nprint('===========================================')\nprint('Best Estimator is :', GridSearchModel.best_estimator_)","6e17bf2c":"DTModel_ = DecisionTreeClassifier(criterion = 'entropy',max_depth=3,random_state = 33)\nGaussianNBModel_ = GaussianNB()\nBernoulliNBModel_ = BernoulliNB(alpha = 0.1)\nMultinomialNBModel_= MultinomialNB(alpha = 0.1)\nSGDModel_ = SGDClassifier(loss='log', penalty='l2', max_iter=10000, tol=1e-5)","8c5c31d2":"#loading Voting Classifier\nVotingClassifierModel = VotingClassifier(estimators=[('DTModel',DTModel_),('GaussianNBModel',GaussianNBModel_),\n                                                     ('BernoulliNBModel',BernoulliNBModel_),\n                                                     ('MultinomialNBModel',MultinomialNBModel_),\n                                                     ('SGDModel',SGDModel_)], voting='hard')\nVotingClassifierModel.fit(X_train, y_train)","2a10817c":"#Calculating Details\nprint('VotingClassifierModel Train Score is : ' , VotingClassifierModel.score(X_train, y_train))\nprint('VotingClassifierModel Test Score is : ' , VotingClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')","dec0bb2a":"SVCModel =  SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,decision_function_shape='ovr', degree=3,\n                gamma='auto_deprecated',kernel='linear', max_iter=-1, probability=False, random_state=None,\n                shrinking=True, tol=0.001, verbose=False)\nSVCModel.fit(X_train, y_train)\n\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\nprint('----------------------------------------------------')","2cd257af":"test.head()","4d4c837c":"test.drop(['id','blue','dual_sim'], axis=1, inplace=True)","74dca8eb":"print('Test Dimension is {}'.format(test.shape))\ntest.head()","d3d252c6":"print('X_train Dimension is {}'.format(X_train.shape))\nX_train.head()","f6cab3e7":"final_result = SVCModel.predict(test)\nfinal_result","2ce8b115":"test.insert(18,'Expected Price',final_result)","8bf4ee1c":"test.head(30)","2b87bd2b":"which will have to be exactly like the 18 features in training dataset","5cd2b526":"# Mobile Phone Price Classification\nby : Hesham Asem\n\n\nhere we have two datasets , the training which contain 2000 sample of cell phone features & the price range between 0 , 1 , 2 , 3\n\nthen a test dataset which contain 1000 sample size with the same features \n\nhttps:\/\/www.kaggle.com\/iabhishekofficial\/mobile-price-classification\n\nour task is to classifiy the test dataset , to know the price range for each one of the 1000 test dataset\n\n____\n\nlet's start with importing the libraries\n","ad9650bc":"how about its result ? ","3652bcf0":"oh , it looks that existing or vanishing the dual sim in the phone , will not affect so much in the price range , & that mean that this feature is kinda useless\n\nso it's better to drop it , to avoid any misleading in the training\n\n","80b9dae9":"great , clean data with no nulls nor missing data . let's move on . \n\n____\n\n# Features Effect\n\nwe need to measure the effect of some features , to know weather we'll keep them ot drop them if they are useless\n\nlet's first have a look to distribution of price range among all data set","4267e8a0":"now how about its score in training & testing data ? ","b711e731":"then let's read the datasets","e28e0145":"it show kinda same result , which means that battery power is an important feature or training cause it affects the price \n\n\nok , we don't need that new feature any more , let's drop it & we'll use the original battery_power in the training later","14375850":"great  , only 16 values make it easier now to start using seaborn on it , to find correlation between it & price range","87bcdd89":"____\n\nok , what are the best values for it  ? ","e65f521e":"again with other features","ea4bc23b":"& here its shape","dec32cf7":"and the last part","fedf0846":"yea it's affect is not so much , but some how it will be useful , so let's keep it \n\n____________\n\n# Feature Correlation\n\nalso we need to have a look to the correlation some features & the output (Price_range)\n\nsince we have several features , so making a one confusion matrix will not be a good idea , cause it will show nothing \n\nso we'll make a temporary sliced dataframe , which will contain some feature each time , added to the price range","3271b007":"also here the test dataset ( which we'll not need it right now )","63ed2e99":"___\n\n# Building the Model\n\n\nhow about using SVC ? he is a good classifier\n\nso let's use girdsearch tool , to pick the best parameters for it , specially th kernel type & the value of C\n","2241c7cb":"____\n\nnow let's check the bluetooth & its affect on price","addfa081":"we can notice there are some features which are binary ( either 0 or 1 ) like : blue , dual_sim , fc , four_g  and so \n\nalso there are no categorical values , so we'll not be in need for aking dummies\n\nhow about the usual problem the Nulls . ","c7d8d2cc":"ok , let's use heatmap from seaborn to see its correlation","a073ecad":"also we need to be sure that there are only 18 features","e93e5403":"how about training dataset","dad59590":"let's have a look to it ","7de72e1c":"ok , lets have a look to the battery_power feature , to know unique values for it\n","ff34a172":"perfect , now lets predict it","75a79693":"a very good accuracy , & even we avoided OF , since test accuracy is 96%\n\n____\n\nok let's check if Logistic Regression might help us , also using GirdSearch tool ","ad0859c6":"looks that majority of cell phones with low battery power , concentrated in the area of less price range , & vice versa\n\nhow about the amount of phones with specific battery power versus price range , lets use barplot","44e82e45":"a 97% accuracy looks great , now let's use the best estimator ( with linear kernel & C = 1) to fit our data","362bd64e":"___\n\n# Predict Test Data\n\nok , let's now have look to the real test data (which is different from test data used in the model) ","51567ce9":"___\n\n# Splitting the Data\n\nok , since we are ready now , we'll need first to divide the training data into training & test datasets , to be able to check the model accuracy \n\nlet's first specify features & output ","8de7660b":"clock speed have no strong correlation , but let's keep it\n\nnow we'll repeat the same step with other features","40b897c9":"____\n\n# Data Processing\n\nwe need to have a quick look to the features in the training dataset","f4f53911":"again , it doesn't matter weather the phone got bluetooth or not , so dropping it will be a good idea to avoid any misleading","a822c26c":"also its shape","eab2853e":"how about the relationship between dual sim & price range  ? ","c5b7dcd7":"ohhh , only 62 % , which will not be suitable at all . . \n\n____\n\nok how about using Voting Classifier , which will use (Decision Tree, Gaussian NB , Bernoulli NB , Multinomial NB , and SGD Classifier ) ? \n\nlet's use it ","2418223b":"more than 1000 unique values will make it not easy to show its statistics , ok let's make a temporary new feature , which will be rounded values for dividing it by 100 , so we can reduce number of unizue values , to make it easy","1429e22e":"ok , it's equally distributed , 500 sample size for each class . \n\nnow let's have a list of all features","31e09ac7":"we need to drop 'id' feature , plus the two unused feature from training data (blue & dual_sim)","49a2d842":"now let's use sklearn to divide it intro training & testing data","95836614":"not very good , only SVC which show best accuracy \n\n____\n\nso let's use it now to apply for the read test dataset","e344759e":"how about the score ? ","1439b5a2":"now how about unique values for the new feature ","cc058469":"and insert it as a new feature in the test dataframe","67747b74":"now how X looks ? ","26c1f476":"here we go , here is the final result","3d0458ce":"and have a look to their dimensions","eae939fe":"___\n\n# Finally\n\nhope you enjoyed it & found this kernel useful \n\n","4055fc45":"let's check the clock speed"}}