{"cell_type":{"7682b667":"code","5e3395bc":"code","70120183":"code","b3f6f2f6":"code","56d27919":"code","795d628a":"code","316309bd":"code","5ddd76bb":"code","88dbc084":"code","686f0c99":"code","64e2d5ea":"code","5aff7287":"code","15e020be":"code","6c754448":"code","ffef3f05":"code","827da585":"code","94a44307":"code","b025be81":"code","a2c44114":"code","a911c6f9":"code","04f6e502":"code","8ae0360a":"code","6ff9f716":"code","389ff654":"code","55508fd8":"code","f71db96c":"code","efef3387":"code","4e5eb78d":"code","aa058f37":"code","1ad4047d":"code","6f99d48f":"code","5c44ec24":"code","4f12a219":"code","6e27da97":"code","6180610f":"code","adf5e022":"code","ba735adc":"code","660a537f":"code","156462ec":"code","3c754a57":"code","cc25f1c2":"code","4c11a57f":"code","1f52fa08":"code","ff98f8cc":"code","e6e0dd29":"code","b8b4a4fa":"code","439224c8":"code","907d87cc":"code","fade04f4":"code","5653b4c0":"code","c96211dd":"code","547203e1":"code","22129e5d":"code","a00f1f0b":"code","b31eb2ce":"code","1850aa45":"code","39c3092d":"code","41e969a4":"code","cbdc7a24":"code","64a39839":"code","68ad6b70":"code","e18e7ffb":"code","7b5dcab5":"code","15782684":"code","cd7061c4":"code","d1b191e0":"code","0cbf3eb1":"code","24eb4d00":"code","df90f342":"code","d87d1693":"code","42291646":"code","efa8baa8":"code","ab7c01e7":"code","fb317996":"code","b0f6061c":"code","18b78cda":"code","f601f183":"code","17446b0d":"code","56b477b1":"code","0b3f177c":"markdown","492de9a7":"markdown","967ddf80":"markdown","07544e5a":"markdown","162f1c1c":"markdown","7affc78a":"markdown","77f206d6":"markdown","5bea10b5":"markdown","6d6ba38f":"markdown","4029a1e2":"markdown","68866472":"markdown","916db5b3":"markdown","098c56a8":"markdown","882f33ba":"markdown","b9ece2bc":"markdown","d31abfb7":"markdown","06908729":"markdown","65a13af6":"markdown","69d14832":"markdown","3e405417":"markdown","cd93073c":"markdown","79da9429":"markdown","b8f4e46f":"markdown","665dc331":"markdown","ec008753":"markdown","dbaf41f5":"markdown","47b7248b":"markdown","9cc3a20f":"markdown","1520bf26":"markdown","5bb68a09":"markdown","e9e809ee":"markdown","190de60e":"markdown","fa656da9":"markdown","20846de1":"markdown","5490c33e":"markdown","2ec5bd77":"markdown","2a972324":"markdown","8e42f00e":"markdown","92774691":"markdown","bd93e591":"markdown","aee6b9ea":"markdown","04620d3d":"markdown","73f9193b":"markdown","b4866678":"markdown","ea8715a8":"markdown","fe25cdef":"markdown","18d1fae5":"markdown","74893e40":"markdown","187d77bd":"markdown"},"source":{"7682b667":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","5e3395bc":"audi = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/audi.csv')\nbmw = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv')\nford = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/ford.csv')\nhyundai = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/hyundi.csv')\nmerc = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/merc.csv')\nskoda = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/skoda.csv')\ntoyota = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/toyota.csv')\nvauxhall = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/vauxhall.csv')\nvw = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/vw.csv')","70120183":"print(\"Columns in the Audi dataframe:\") \nprint(list(audi.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the BMW dataframe:\")\nprint(list(bmw.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Ford dataframe:\")\nprint(list(ford.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Hyundai dataframe:\")\nprint(list(hyundai.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Mercedes dataframe:\")\nprint(list(merc.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Skoda dataframe:\")\nprint(list(skoda.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Toyota dataframe:\")\nprint(list(toyota.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the Vauxhall dataframe:\")\nprint(list(vauxhall.columns))\nprint(\"-\" * 50)\nprint(\"Columns in the VW dataframe:\")\nprint(list(vw.columns))","b3f6f2f6":"hyundai.rename({'tax(\u00a3)': 'tax'},axis=1,inplace=True)","56d27919":"audi['make'] = 'Audi'\nbmw['make'] = 'BMW'\nford['make'] = 'Ford'\nhyundai['make'] = 'Hyundai'\nmerc['make'] = 'Mercedes'\nskoda['make'] = 'Skoda'\ntoyota['make'] = 'Toyota'\nvauxhall['make'] = 'Vauxhall'\nvw['make'] = 'Volkswagen'","795d628a":"df = pd.concat([audi, bmw, ford, hyundai, merc, skoda, toyota, vauxhall, vw], axis=0, ignore_index=True)","316309bd":"df.info()","5ddd76bb":"df.head()","88dbc084":"df.isnull().sum()","686f0c99":"df.nunique()","64e2d5ea":"df.describe()","5aff7287":"df[df['year'] == 2060]","15e020be":"df = df.drop(df[df['year'] == 2060].index)","6c754448":"df[df['year'] == 1970]","ffef3f05":"df = df.drop(df[df['year'] == 1970].index)","827da585":"df[df['engineSize'] == 0]","94a44307":"df[df['mileage'] == 1]","b025be81":"len(df[(df['mileage'] ==1) & (df['year'] != 2020)])","a2c44114":"df = df.drop(df[(df['mileage']==1) & (df['year']<= 2019)].index)","a911c6f9":"df[df['tax'] == 0]","04f6e502":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True)","8ae0360a":"sns.scatterplot(x=df['mileage'],y=df['price'])\nplt.title('Scatter plot of Mileage against Price')","6ff9f716":"plt.figure(figsize=(10,8))\nsns.boxplot(x='make',y='price',data=df)","389ff654":"for i in range(91,100,1):\n    print('The {0}th percentile of price is {1}'.format(i, np.percentile(df['price'],i)))","55508fd8":"for i in np.arange(99,100,0.1):\n    print('The {0}th percentile of price is {1}'.format(round(i,1), np.percentile(df['price'],i)))","f71db96c":"df[(df['make'] == 'Hyundai') & (df['price'] > 80000)]","efef3387":"df = df.drop(df[(df['make'] == 'Hyundai') & (df['price'] > 80000)].index)","4e5eb78d":"df[(df['make'] == 'Skoda') & (df['price']> 80000)]","aa058f37":"df = df.drop(df[(df['make'] == 'Skoda') & (df['price'] > 80000)].index)","1ad4047d":"sns.boxplot(x=df['fuelType'],y=df['price'])","6f99d48f":"sns.boxplot(x=df['transmission'],y=df['price'])","5c44ec24":"sns.distplot(df['price'])","4f12a219":"sns.distplot(df['year'])","6e27da97":"sns.distplot(df['mileage'])","6180610f":"sns.distplot(df['tax'])","adf5e022":"sns.distplot(df['mpg'])","ba735adc":"sns.distplot(df['engineSize'])","660a537f":"from sklearn.model_selection import train_test_split","156462ec":"df.head()","3c754a57":"X = df.drop(['price'], axis = 1)\ny = df['price']","cc25f1c2":"X_transmission = pd.get_dummies(X['transmission'], drop_first=True)\nX_transmission.rename(columns={'Other':'Other Transmission'}, inplace=True)\nX_fuelType = pd.get_dummies(X['fuelType'], drop_first=True)\nX_fuelType.rename(columns={'Other':'Other FuelType'}, inplace=True)\nX_make = pd.get_dummies(X['make'], drop_first=True)\nX_model = pd.get_dummies(X['model'], drop_first=True)\nX = pd.concat([X,X_transmission,X_fuelType,X_make, X_model],axis=1)\nX.drop(['transmission', 'fuelType', 'make', 'model'], axis = 1, inplace=True)","4c11a57f":"X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.33, random_state=42)","1f52fa08":"X_train = X_train_.copy(deep=True)\nX_test = X_test_.copy(deep=True)\ny_train = y_train_.copy(deep=True)\ny_test = y_test_.copy(deep=True)","ff98f8cc":"engineSize_median = X_train['engineSize'].median()\nprint('The median of Engine Size is : {0}'.format(engineSize_median))\nengineSize_median = 1.6","e6e0dd29":"X_train['engineSize'] = X_train['engineSize'].replace(to_replace=0,value=engineSize_median)\nX_test['engineSize'] = X_test['engineSize'].replace(to_replace=0,value=engineSize_median)","b8b4a4fa":"tax_mean = X_train['tax'].mean()\nprint('The mean of tax is {0}'.format(tax_mean))\ntax_mean = 120.41","439224c8":"X_train['tax'] = X_train['tax'].replace(to_replace=0,value=tax_mean)\nX_test['tax'] = X_test['tax'].replace(to_replace=0,value=tax_mean)","907d87cc":"from scipy import stats","fade04f4":"mileage,mileage_lambda = stats.boxcox(X_train['mileage'])","5653b4c0":"print('The lambda for boxcox transform of mileage is {0}'.format(mileage_lambda))\nmileage_lambda=0.36762127618713064","c96211dd":"sns.distplot(mileage)","547203e1":"test_mileage = stats.boxcox(X_test['mileage'],mileage_lambda)","22129e5d":"X_train['mileage_transformed'] = mileage\nX_test['mileage_transformed'] = test_mileage","a00f1f0b":"X_train.head()","b31eb2ce":"price,price_lambda = stats.boxcox(y_train)","1850aa45":"print('The lambda for boxcox transform of price is {0}'.format(price_lambda))\nprice_lambda=0.03888231697484755","39c3092d":"sns.distplot(price)","41e969a4":"test_price = stats.boxcox(y_test,price_lambda)","cbdc7a24":"y_train_trans = price\ny_test_trans = test_price","64a39839":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport pickle","68ad6b70":"X_train.drop(['mileage'], axis=1, inplace=True)\nX_test.drop(['mileage'], axis=1, inplace=True)","e18e7ffb":"reg = LinearRegression()\nreg.fit(X_train, y_train_trans)","7b5dcab5":"y_train_pred = reg.predict(X_train)\ny_pred = reg.predict(X_test)","15782684":"train_r2 = r2_score(y_train_trans, y_train_pred)\nprint('The train R2 value is {0}'.format(train_r2))\n\ntest_r2 = r2_score(y_test_trans, y_pred)\nprint('The test R2 value is {0}'.format(test_r2))","cd7061c4":"!rm -rf \/kaggle\/working\/models\n!rm -rf \/kaggle\/working\/data\n!mkdir models\n!mkdir data","d1b191e0":"with open('\/kaggle\/working\/data\/linear_regression.pkl', 'wb') as f:\n    pickle.dump(reg,f)\nwith open('\/kaggle\/working\/data\/X_train.pkl', 'wb') as f:\n    pickle.dump(X_train,f)\nwith open('\/kaggle\/working\/data\/X_test.pkl', 'wb') as f:\n    pickle.dump(X_test,f)\nwith open('\/kaggle\/working\/data\/y_train.pkl', 'wb') as f:\n    pickle.dump(y_train,f)\nwith open('\/kaggle\/working\/data\/y_test.pkl', 'wb') as f:\n    pickle.dump(y_test,f)\nwith open('\/kaggle\/working\/data\/y_train_trans.pkl', 'wb') as f:\n    pickle.dump(y_train_trans,f)\nwith open('\/kaggle\/working\/data\/y_test_trans.pkl', 'wb') as f:\n    pickle.dump(y_test_trans,f)","0cbf3eb1":"reg = DecisionTreeRegressor(random_state=42)\nparameters = {\"max_depth\":np.array([1, 2, 5, 10, 50, 100]), \"min_samples_split\":np.array([1, 5, 10, 50, 100, 500])}\nclf = GridSearchCV(reg, param_grid = parameters, cv = 5, scoring = 'r2', n_jobs=-1, verbose=5)\nclf.fit(X_train, y_train_trans)\nprint(clf.best_estimator_)\nbest_reg = clf.best_estimator_\nbest_reg.fit(X_train, y_train_trans)","24eb4d00":"y_train_pred = best_reg.predict(X_train)\ny_pred = best_reg.predict(X_test)\ntrain_r2 = r2_score(y_train_trans, y_train_pred)\nprint('The train R2 value is {0}'.format(train_r2))\n\ntest_r2 = r2_score(y_test_trans, y_pred)\nprint('The test R2 value is {0}'.format(test_r2))","df90f342":"with open('\/kaggle\/working\/data\/decisiontree_regression.pkl', 'wb') as f:\n    pickle.dump(best_reg,f)","d87d1693":"reg = RandomForestRegressor(random_state=42)\nparameters = {\"max_depth\": [2, 3, 5, 8, 10, 15, 20, 25, 30, 40, 50,100],\n              \"n_estimators\": [10, 20, 30, 40, 50, 80, 100, 150, 200],\n                \"max_features\": ['auto', 'sqrt']\n             }\nrcv = RandomizedSearchCV(reg, param_distributions = parameters, cv = 3, scoring = 'r2', n_jobs=-1, verbose=10)\nrcv.fit(X_train, y_train_trans)\nprint(rcv.best_estimator_)\nbest_reg = rcv.best_estimator_\nbest_reg.fit(X_train, y_train_trans)","42291646":"y_train_pred = best_reg.predict(X_train)\ny_pred = best_reg.predict(X_test)\ntrain_r2 = r2_score(y_train_trans, y_train_pred)\nprint('The train R2 value is {0}'.format(train_r2))\n\ntest_r2 = r2_score(y_test_trans, y_pred)\nprint('The test R2 value is {0}'.format(test_r2))","efa8baa8":"with open('\/kaggle\/working\/data\/randomforest_regression.pkl', 'wb') as f:\n    pickle.dump(best_reg,f)","ab7c01e7":"from xgboost import XGBRegressor","fb317996":"xgb = XGBRegressor(n_jobs = -1)\nparameters = {\"max_depth\":np.array([1, 5, 10, 50, 150, 200, 250]), \"n_estimators\":np.array([3, 9, 11,15, 25, 50, 70, 150, 200, 250, 300])}\nreg = GridSearchCV(xgb, parameters, cv = 3, scoring='r2', n_jobs=-1, verbose = 10) \nreg.fit(X_train, y_train_trans)\nprint(reg.best_estimator_)\nbest_reg = reg.best_estimator_\nbest_reg.fit(X_train, y_train_trans)","b0f6061c":"y_train_pred = best_reg.predict(X_train)\ny_pred = best_reg.predict(X_test)\ntrain_r2 = r2_score(y_train_trans, y_train_pred)\nprint('The train R2 value is {0}'.format(train_r2))\n\ntest_r2 = r2_score(y_test_trans, y_pred)\nprint('The test R2 value is {0}'.format(test_r2))","18b78cda":"with open('\/kaggle\/working\/data\/xgboost_regression.pkl', 'wb') as f:\n    pickle.dump(best_reg,f)","f601f183":"from prettytable import PrettyTable","17446b0d":"results = []\n\n# add the results in a list\nresults.append(['Model','Train R2','Test R2'])\nresults.append(['Linear Regression',0.94,0.939])\nresults.append(['Decision Tree',0.987,0.949])\nresults.append(['Random Forest',0.991,0.962])\nresults.append(['XGBoost',0.987,0.968])","56b477b1":"table = PrettyTable()\ntable.field_names = results[0]\nfor i in range(len(results)):\n    if i!=0:\n        table.add_row(results[i])\nprint(table)","0b3f177c":"## Checking the number of columns in each dataset","492de9a7":"# Feature Engineering","967ddf80":"### Year","07544e5a":"### MPG","162f1c1c":"# Exploratory Data Analysis","7affc78a":"There are 272 rows with engine size as 0. So this needs to be handled in the feature engineering part","77f206d6":"There are nearly 6300 datapoints with tax as 0. So this should be handled in feature engineering","5bea10b5":"### Price","6d6ba38f":"# Results","4029a1e2":"Since there are only 37 cars with mileage as 1, these data points can be removed.","68866472":"# Conclusion","916db5b3":"### Engine Size","098c56a8":"1. It is observed that in hyundai dataset, the tax column is having a special character (pound).","882f33ba":"### Transmission","b9ece2bc":"Engine Size","d31abfb7":"# Model Creation","06908729":"Some vehicles are from the year 2020. So it makes sense. But There are some vehicles that have the year less than 2020 but with mileage as 1","65a13af6":"Also it is observed that there are some cars with the year 1970","69d14832":"## Adding a column make to identify the manufacturer for combining the datasets","3e405417":"### Linear Regression","cd93073c":"### Price","79da9429":"There is an extremely positive correlation between year and price and an extremely negative correlation between mileage and price. This makes sense, since newer cars are generally more expensive and cars with more mileage are relatively cheaper. We also notice a negative correlation between mileage and year - the newer a car is the less miles it is likely to have travelled. Furthermore, we notice a positive correlation between engine size and price, as well as engine size and tax. This follows expectation, since it is common practice for manufacturers to sell models with larger engines for a higher price in comparison to the same model with a smaller engine. As a result, due to the higher price, a larger tax payment is required, hence the positive correlation. This also explains the positive correlation between tax and price.","b8f4e46f":"### By observing the unique values we can understand that the columns \"Model\", \"fuelType\" and \"transmission\" and \"make\" are categorical columns","665dc331":"### Mileage","ec008753":"It is evident that the Automatic and Semi-Automatic cars are higher price than the manual transmission. This feature has clear significant influence on the price of the vehicles","dbaf41f5":"It is observed that there is 1 car from the manufacturer Ford that is having year as 2060. Since we don't have any other information regarding this data, we can remove this entry","47b7248b":"Price","9cc3a20f":"Tax","1520bf26":"### Engine Size","5bb68a09":"### Decision Tree","e9e809ee":"There are some cars with mileage as 1","190de60e":"It is observed that XGBoost is giving the best R Square metric value on test data","fa656da9":"# Predict the sale price for the Pre-Owned Cars","20846de1":"### Mileage","5490c33e":"It is observed that the petrol vehicles are cheaper than the other fuel type vehicles","2ec5bd77":"### Tax","2a972324":"## XGBoost","8e42f00e":"Mileage","92774691":"### Tax","bd93e591":"The data contains 9 csv files, with each file has the information about each car brand, including Audi, BMW, Ford, Hyundai, Mercedes, Skoda, Toyota, Vauxhall and Volkswagen.","aee6b9ea":"It is observed that mileage and price are having right skewed distribution","04620d3d":"### There are no missing values in the dataset","73f9193b":"### Year","b4866678":"It is observed that the cars Audi, BMW, Mercedes, Volkswagen have higher price than average. But the cars Hyundai and Skoda points seems to be outliers. So those points can be removed","ea8715a8":"## Reading the Data","fe25cdef":"There are only 2 cars with the year as 1970. Also in the current situation the cars with the model of 1970's are not allowed to be used these 2 cars can be removed from the data.","18d1fae5":"### Random Forest","74893e40":"### Fuel Type","187d77bd":"From the info we got from the dataset, it is observed that there is atleast 1 car with the year as 2060"}}