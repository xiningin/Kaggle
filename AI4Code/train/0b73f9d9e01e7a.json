{"cell_type":{"4bb6f897":"code","d37a69c3":"code","5a52fc1e":"code","8fea7da2":"code","a80e1c44":"code","d64540a0":"code","4a1c00ca":"code","94e18137":"code","dfcd8e65":"code","f87f1e89":"code","cd0968dc":"code","4f2a9ff9":"code","11c55255":"code","b731e27d":"code","2e7ba8ca":"code","3116e9ab":"code","e46c0455":"code","bc27d907":"code","6e468e09":"code","808fb0a7":"code","547010d5":"code","88545032":"code","4cd9ced6":"code","e5dbeba5":"code","ed5cb8c8":"code","98746143":"code","e512bf0f":"code","95410d63":"code","6249e709":"code","40fb089c":"code","d65f6c37":"code","87ed4c58":"code","4355e29c":"code","4351c850":"code","ae1ef99b":"code","bce3f189":"code","b453e97f":"code","84ce1ef3":"code","47dfc7ad":"markdown","7152712e":"markdown","4d1fc6d9":"markdown","e0650045":"markdown","5fb7fadd":"markdown","194e566a":"markdown","c4652ecd":"markdown","6da58e3c":"markdown","163c1235":"markdown","5ffbc387":"markdown"},"source":{"4bb6f897":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn import metrics, preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.decomposition import PCA\nimport lightgbm as lgb\n\npd.set_option('display.max_columns', 400)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d37a69c3":"train_identity_df = pd.read_csv(os.path.join('..\/input\/ieee-fraud-detection\/', 'train_identity.csv'))\ntrain_transaction_df = pd.read_csv(os.path.join('..\/input\/ieee-fraud-detection\/', 'train_transaction.csv'))\ntest_identity_df = pd.read_csv(os.path.join('..\/input\/ieee-fraud-detection\/', 'test_identity.csv'))\ntest_transaction_df = pd.read_csv(os.path.join('..\/input\/ieee-fraud-detection\/', 'test_transaction.csv'))","5a52fc1e":"print(f\"train identity: {train_identity_df.shape}\")\nprint(f\"train transaction: {train_transaction_df.shape}\")\nprint(f\"test identity: {test_identity_df.shape}\")\nprint(f\"test transaction: {test_transaction_df.shape}\")","8fea7da2":"train_identity_df.head()","a80e1c44":"train_transaction_df.head()","d64540a0":"test_identity_df.head()","4a1c00ca":"test_transaction_df.head()","94e18137":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","dfcd8e65":"missing_data(train_identity_df)","f87f1e89":"missing_data(test_identity_df)","cd0968dc":"missing_data(train_transaction_df)","4f2a9ff9":"missing_data(test_transaction_df)","11c55255":"df = pd.DataFrame()\nfor column in list(train_identity_df.columns.values):\n    field_type = train_identity_df[column].dtype\n    df=df.append(pd.DataFrame({'column':column,'train':train_identity_df[column].nunique(), 'test':test_identity_df[column].nunique(),\\\n                               'type':field_type},index=[0]))\ndf['delta'] = df.train - df.test\ndf['flag'] = (df['delta'] < 0).astype(int)\ntest_dom_categories = df.loc[(df.flag == 1) & (df.type == 'object'), 'column']\ndf = df.transpose()\n\nprint('Unique column values in identity datasets')\ndf","b731e27d":"print(f\"Columns of type `object` and with more categories in test than in train: {list(test_dom_categories)}\")","2e7ba8ca":"df = pd.DataFrame()\nfor column in list(test_transaction_df.columns.values):\n    field_type = test_transaction_df[column].dtype\n    try:\n        df=df.append(pd.DataFrame({'column':column,'train':train_transaction_df[column].nunique(), \\\n            'test':test_transaction_df[column].nunique(), 'type':field_type},index=[0]))\n    except:\n        \"Error trying to add target from test\"\ndf['delta'] = df.train - df.test\ndf['flag'] = (df['delta'] < 0).astype(int)\ntest_dom_categories = df.loc[(df.flag == 1) & (df.type == 'object'), 'column']\ndf = df.transpose()\n\nprint('Unique column values in transaction datasets')\ndf","3116e9ab":"print(f\"Columns of type `object` and with more categories in test than in train: {list(test_dom_categories)}\")","e46c0455":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:30], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()   ","bc27d907":"plot_count('id_30', 'train: id_30', df=train_identity_df, size=4)","6e468e09":"plot_count('id_30', 'test: id_30', df=test_identity_df, size=4)","808fb0a7":"plot_count('id_31', 'train: id_31', df=train_identity_df, size=4)","547010d5":"plot_count('id_31', 'test: id_31', df=test_identity_df, size=4)","88545032":"plot_count('id_33', 'train: id_33', df=train_identity_df, size=4)","4cd9ced6":"plot_count('id_33', 'test: id_33', df=test_identity_df, size=4)","e5dbeba5":"plot_count('DeviceInfo', 'train: DeviceInfo', df=train_identity_df, size=4)","ed5cb8c8":"plot_count('DeviceInfo', 'test: DeviceInfo', df=test_identity_df, size=4)","98746143":"plot_count('P_emaildomain', 'train: P_emaildomain', df=train_transaction_df, size=4)","e512bf0f":"plot_count('P_emaildomain', 'test: P_emaildomain', df=test_transaction_df, size=4)","95410d63":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","6249e709":"identity_cols = list(train_identity_df.columns.values)\ntransaction_cols = list(train_transaction_df.drop('isFraud', axis=1).columns.values)","40fb089c":"X_train = pd.merge(train_transaction_df[transaction_cols + ['isFraud']], train_identity_df[identity_cols], how='left')\nX_train = reduce_mem_usage(X_train)\nX_test = pd.merge(test_transaction_df[transaction_cols], train_identity_df[identity_cols], how='left')\nX_test = reduce_mem_usage(X_test)","d65f6c37":"X_train_id = X_train.pop('TransactionID')\nX_test_id = X_test.pop('TransactionID')\ndel train_identity_df,train_transaction_df, test_identity_df, test_transaction_df","87ed4c58":"all_data = X_train.append(X_test, sort=False).reset_index(drop=True)","4355e29c":"vcols = [f'V{i}' for i in range(1,340)]\n\nsc = preprocessing.MinMaxScaler()\n\npca = PCA(n_components=2) #0.99\nvcol_pca = pca.fit_transform(sc.fit_transform(all_data[vcols].fillna(-1)))\n\nall_data['_vcol_pca0'] = vcol_pca[:,0]\nall_data['_vcol_pca1'] = vcol_pca[:,1]\nall_data['_vcol_nulls'] = all_data[vcols].isnull().sum(axis=1)\n\nall_data.drop(vcols, axis=1, inplace=True)","4351c850":"all_data['_P_emaildomain__addr1'] = all_data['P_emaildomain'] + '__' + all_data['addr1'].astype(str)\nall_data['_card1__card2'] = all_data['card1'].astype(str) + '__' + all_data['card2'].astype(str)\nall_data['_card1__addr1'] = all_data['card1'].astype(str) + '__' + all_data['addr1'].astype(str)\nall_data['_card2__addr1'] = all_data['card2'].astype(str) + '__' + all_data['addr1'].astype(str)\nall_data['_card12__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)\nall_data['_card_all__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)\nall_data['_amount_decimal'] = ((all_data['TransactionAmt'] - all_data['TransactionAmt'].astype(int)) * 1000).astype(int)\nall_data['_amount_decimal_len'] = all_data['TransactionAmt'].apply(lambda x: len(re.sub('0+$', '', str(x)).split('.')[1]))\nall_data['_amount_fraction'] = all_data['TransactionAmt'].apply(lambda x: float('0.'+re.sub('^[0-9]|\\.|0+$', '', str(x))))\ncols = ['ProductCD','card1','card2','card5','card6','P_emaildomain','_card_all__addr1']\n\nfor f in cols:\n    all_data[f'_amount_mean_{f}'] = all_data['TransactionAmt'] \/ all_data.groupby([f])['TransactionAmt'].transform('mean')\n    all_data[f'_amount_std_{f}'] = all_data['TransactionAmt'] \/ all_data.groupby([f])['TransactionAmt'].transform('std')\n    all_data[f'_amount_pct_{f}'] = (all_data['TransactionAmt'] - all_data[f'_amount_mean_{f}']) \/ all_data[f'_amount_std_{f}']\n\nfor f in cols:\n    vc = all_data[f].value_counts(dropna=False)\n    all_data[f'_count_{f}'] = all_data[f].map(vc)\n    \ncat_cols = [f'id_{i}' for i in range(12,39)]\nfor i in cat_cols:\n    if i in all_data.columns:\n        all_data[i] = all_data[i].astype(str)\n        all_data[i].fillna('unknown', inplace=True)\n\nenc_cols = []\nfor i, t in all_data.loc[:, all_data.columns != 'isFraud'].dtypes.iteritems():\n    if t == object:\n        enc_cols.append(i)\n        all_data[i] = pd.factorize(all_data[i])[0]  ","ae1ef99b":"X_train = all_data[all_data['isFraud'].notnull()]\nX_test = all_data[all_data['isFraud'].isnull()].drop('isFraud', axis=1)\nY_train = X_train.pop('isFraud')\ndel all_data","bce3f189":"params={'learning_rate': 0.0097,\n        'objective': 'binary',\n        'metric': 'auc',\n        'num_threads': -1,\n        'num_leaves': 256,\n        'verbose': 1,\n        'random_state': 314,\n        'bagging_fraction': 1,\n        'feature_fraction': 0.82\n       }","b453e97f":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nclf = lgb.LGBMClassifier(**params, n_estimators=4000)\nclf.fit(X_train, Y_train)\noof_preds = clf.predict_proba(X_train, num_iteration=clf.best_iteration_)[:,1]\nsub_preds = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:,1]","84ce1ef3":"submission = pd.DataFrame()\nsubmission['TransactionID'] = X_test_id\nsubmission['isFraud'] = sub_preds\nsubmission.to_csv('submission.csv', index=False)","47dfc7ad":"## Data values distribution","7152712e":"# Submission","4d1fc6d9":"# Data exploration","e0650045":"# Model","5fb7fadd":"<h1>IEEE-CIS Fraud Detection EDA & Model<\/h1>\n\n**Note**: this kernel uses for the feature engineering and model the following kernel: https:\/\/www.kaggle.com\/plasticgrammer\/ieee-cis-fraud-detection-eda","194e566a":"# Load data","c4652ecd":"## Missing data and data types","6da58e3c":"# Load packages","163c1235":"## Glimpse the data","5ffbc387":"## Categorical fields distribution"}}