{"cell_type":{"34a48f9e":"code","1e50f939":"code","b64bd1ba":"code","e44cca62":"code","36c0a9fc":"code","3bff9e0e":"code","4e40601e":"code","26e1c705":"code","db810a38":"code","1dcf506c":"code","7e66a29a":"code","4b4449ff":"code","b100a637":"code","0816f5ea":"code","0ee1ea96":"code","c327e830":"code","71ad4c8b":"code","d4be6a87":"code","49fa0a80":"code","eda6afcb":"markdown","8d2505c2":"markdown"},"source":{"34a48f9e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sb","1e50f939":"df = pd.read_csv(\"..\/input\/irisset\/bezdekIris.data\")\ndf.head()","b64bd1ba":"measured_irises = pd.crosstab(index=df[\"class\"],columns=\"Number of measured Irises\")      \n\n#displaying number of all irises in dataset\nmeasured_irises.head()","e44cca62":"#Splitting data for each species\niris_setosa=df.loc[df[\"class\"]==\"Iris-setosa\"]\niris_virginica=df.loc[df[\"class\"]==\"Iris-virginica\"]\niris_versicolor=df.loc[df[\"class\"]==\"Iris-versicolor\"]","36c0a9fc":"# Displaying histogram with each parameter for each species we have\n\nsb.FacetGrid(df,hue=\"class\",height=5).map(sb.distplot,\"sepal_length_in_cm\").add_legend()\nsb.FacetGrid(df,hue=\"class\",height=5).map(sb.distplot,\"sepal_width_in_cm\").add_legend()\nsb.FacetGrid(df,hue=\"class\",height=5).map(sb.distplot,\"petal_length_in_cm\").add_legend()\nsb.FacetGrid(df,hue=\"class\",height=5).map(sb.distplot,\"petal_width_in_cm\").add_legend()\nplt.show()","3bff9e0e":"# More visualization\nsb.pairplot(df,hue=\"class\",height=3);\nplt.show()","4e40601e":"x = df.iloc[:, [0, 1]].values","26e1c705":"#Finding the optimum number of clusters for k-means classification\nfrom sklearn.cluster import KMeans\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)","db810a38":"plt.plot(range(1, 11), wcss)\nplt.title('The elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') #within cluster sum of squares\nplt.show()","1dcf506c":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(x)","7e66a29a":"#Visualising the clusters\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'blue', label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'red', label = 'Iris-versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')\n\n#Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')\n\nplt.legend()","4b4449ff":"#Self K-means algorithm implementation \n\nx_values = df['sepal_length_in_cm']\ny_values = df['sepal_width_in_cm']","b100a637":"#First Iteration\n\nk = 3\n\n#Getting random centroids\ncentroids = {\n    i+1: [np.random.uniform(min(x_values), max(x_values)), np.random.uniform(min(y_values), max(y_values))]\n    for i in range(k)\n}\n\ncentroids","0816f5ea":"fig = plt.figure(figsize=(5, 5))\nplt.scatter(x_values, y_values, color='k')\ncolmap = {1: 'r', 2: 'g', 3: 'b'}\nfor i in centroids.keys():\n    plt.scatter(*centroids[i], color=colmap[i])\nplt.xlim(min(x_values)- 0.5, max(x_values + 0.5))\nplt.ylim(min(y_values) - 0.5, max(y_values) + 0.5)\nplt.show()","0ee1ea96":"## Assiging all data to clusters\n\ndef get_distance_array(x_values, y_values, centroid, num_of_records):\n    array=[]\n    \n    for i in range(num_of_records):\n        # sqrt((x1 - x2)^2 - (y1 - y2)^2)\n        array.append(\n            np.sqrt(\n                (x_values[i] - centroid[0]) ** 2\n                + (y_values[i] - centroid[1]) ** 2)\n            )\n    return array\n\ndef assign(x_values, y_values, centroids):\n    df = pd.DataFrame()\n    df['x_values'] = x_values\n    df['y_values'] = y_values\n\n    for i in centroids.keys():\n        df['distance_from_{}'.format(i)] = get_distance_array(x_values, y_values, centroids[i], len(df))\n    \n    centroid_distance_cols = ['distance_from_{}'.format(i) for i in centroids.keys()]\n    df['closest'] = df.loc[:, centroid_distance_cols].idxmin(axis=1)\n    df['closest'] = df['closest'].map(lambda x: int(x.lstrip('distance_from_')))\n    df['color'] = df['closest'].map(lambda x: colmap[x])\n    \n    return df\n\ndata = assign(x_values, y_values, centroids)\ndata.head()","c327e830":"fig = plt.figure(figsize=(5, 5))\nplt.scatter(x_values, y_values, color=data['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    plt.scatter(*centroids[i], color=colmap[i])\nplt.xlim(min(x_values)- 0.5, max(x_values + 0.5))\nplt.ylim(min(y_values) - 0.5, max(y_values) + 0.5)\nplt.show()","71ad4c8b":"## Update position of centroids\n\ndef update(k):\n    for i in centroids.keys():\n        centroids[i][0] = np.mean(data[data['closest'] == i]['x_values'])\n        centroids[i][1] = np.mean(data[data['closest'] == i]['y_values'])\n    return k\n","d4be6a87":"while True:\n    closest_centroids = data['closest'].copy(deep=True)\n    centroids = update(centroids)\n    data = assign(x_values, y_values, centroids)\n    if closest_centroids.equals(data['closest']):\n        break","49fa0a80":"fig = plt.figure(figsize=(5, 5))\nax = plt.axes()\nplt.scatter(data['x_values'], data['y_values'], color=data['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    plt.scatter(*centroids[i], color=colmap[i])\nplt.xlim(min(x_values)- 0.5, max(x_values + 0.5))\nplt.ylim(min(y_values) - 0.5, max(y_values) + 0.5)\nplt.show()","eda6afcb":"Classes we have: Iris setosa, Iris virginica, Iris versicolor","8d2505c2":"So I should choose k = 3"}}