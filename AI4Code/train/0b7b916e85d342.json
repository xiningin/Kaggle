{"cell_type":{"7fbaa0cc":"code","ae4725ee":"code","5ebeb444":"code","c16dc507":"code","dec2d18f":"code","16596980":"code","560510c3":"code","2a68c93c":"code","255973fc":"code","21a1b1d2":"code","e813bf05":"code","e0a05437":"code","c43a1162":"code","90e56d78":"code","30540e46":"code","53a01975":"code","9e4dadf0":"code","e8b61e3e":"code","34ed503b":"code","c66627a0":"code","e84c4ad1":"code","2e9f08a0":"code","49bda6ae":"code","590949c0":"code","aef31ac9":"code","a389ebb6":"code","b00d3fce":"code","524fbd2e":"code","4ec68840":"code","3da59da6":"code","acbccfdf":"code","ee41ab25":"code","407b705c":"code","7d4e574d":"code","d28ecc27":"code","51cdef45":"code","d6e3aa98":"markdown","b56371a1":"markdown","847643c4":"markdown","726b47ba":"markdown","e2870d79":"markdown","8c6c8b36":"markdown","797fc29c":"markdown","d6639452":"markdown","37ce14df":"markdown","1489ca3a":"markdown","6df3a73d":"markdown","b9f500d7":"markdown"},"source":{"7fbaa0cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae4725ee":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nimport h5py","5ebeb444":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_data.head()","c16dc507":"train_data.shape","dec2d18f":"# ISOLATING THE LABELS FOR EACH IMAGE    :\n# since the first column contains the target (label of the image) . we will isolate it from the training data. \n# we will also one-hot-encode the label beacuse this is the desired format of labels for keras when softmax function\n# is used from predictions.\n\nlabel = train_data.to_numpy()[:,0]\nx = train_data.to_numpy()[:,1:]","16596980":"print(label)","560510c3":"print(x)","2a68c93c":"print(x.shape)","255973fc":"# we will transform the input into an array of dimention [length of image x breadth of image x no.of images]\n# which is acceptable by the keras implementation.\n\nx = x.reshape(42000, 28, 28, 1)","21a1b1d2":"print(x.shape)","e813bf05":"# Normalize Pixel Data   \n# Each pixel values lies between [0,255].This value range is too high and it will be difficult for any model to learn.  \n# The best approach is normalize the data. \n# In this case, as the pixel value is in the known range it sufficient to scale the pixel values in range [0,1] by simply \n# dividing the array by 255.\n\nx = x\/255","e0a05437":"img_rows, img_cols = 28, 28\nnum_classes = 10\ny = keras.utils.to_categorical(label, num_classes)","c43a1162":"# def prep_data(raw):\n#     img_rows, img_cols = 28, 28\n#     num_classes = 10\n#     y = raw[:, 0]\n#     out_y = keras.utils.to_categorical(y, num_classes)\n#     x = raw[:,1:]\n#     num_images = raw.shape[0]\n#     out_x = x.reshape(num_images, img_rows, img_cols, 1)\n#     out_x = out_x \/ 255\n#     return out_x, out_y , img_rows, img_cols, num_classes, num_images\n\n#mnist_file = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\n#mnist_data = np.loadtxt(mnist_file, skiprows=1, delimiter=',')\n#x, y, img_rows, img_cols, num_classes, num_images= prep_data(mnist_data)\nprint('input shape : {}'.format(x.shape))\nprint('output shape : {}'.format(y.shape))","90e56d78":"#initializing our model\nfirst_cnn = Sequential()","30540e46":"#adding the first convolutional layer\nfirst_cnn.add(Conv2D(filters = 16,\n                     kernel_size = 5,\n                     activation = 'relu',\n                     input_shape = (img_rows, img_cols, 1)))","53a01975":"first_cnn","9e4dadf0":"#adding the first pooling layer\nfirst_cnn.add(MaxPooling2D(pool_size=(2,2)))","e8b61e3e":"# Dropout layer drops the few activation nodes while training, which acts as regularization. \n# Do not let the model to over-fit.\n\nfirst_cnn.add(Dropout(0.25))","34ed503b":"#adding the second convolutional layer\nfirst_cnn.add(Conv2D(filters = 32,\n                     kernel_size = 5,\n                     activation = 'relu'))","c66627a0":"#adding the second pooling layer\nfirst_cnn.add(MaxPooling2D(pool_size=(2,2)))","e84c4ad1":"first_cnn.add(Dropout(0.25))","2e9f08a0":"#adding the flattening layer, whose output will be used as the final NN's input\nfirst_cnn.add(Flatten())","49bda6ae":"#adding the hidden layer\nfirst_cnn.add(Dense(units = 64,\n                    activation ='relu'))\nfirst_cnn.add(Dense(units = num_classes,\n                    activation = 'softmax'))","590949c0":"first_cnn.compile(loss = \"categorical_crossentropy\",\n                   optimizer = 'adam',\n                   metrics = ['accuracy'])","aef31ac9":"# Let us now check our final CNN model\nfirst_cnn.summary()","a389ebb6":"Wsave = first_cnn.get_weights()","b00d3fce":"print(Wsave)","524fbd2e":"#Let us now fit our model to the data and see it in action.\n\nhistory = first_cnn.fit(x,\n              y,\n              batch_size = 100,\n              epochs = 100,\n              validation_split = 0.2 )","4ec68840":"print(Wsave)","3da59da6":"# To better analyse our data , let us plot its performance as a function of no.of epochs.\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.title('loss')\nplt.legend()\nplt.show()\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.title('accuracy')\nplt.legend()\nplt.show()","acbccfdf":"first_cnn.set_weights(Wsave)\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose= 1 , patience=5)\nmc = ModelCheckpoint(\"best_cnn.h5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\nhistory = first_cnn.fit(x,\n                        y,\n                        batch_size = 100,\n                        epochs = 100,\n                        validation_split = 0.2,\n                        verbose = 1,\n                        callbacks = [es,mc])","ee41ab25":"cnn_best = load_model(\"best_cnn.h5\")\n\n_, train_acc = cnn_best.evaluate(x, y, verbose=0)\nprint(\"Train: {}\".format(train_acc))","407b705c":"plt.figure(figsize=(10, 5))\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.title('loss')\nplt.legend()\nplt.show()\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.title('accuracy')\nplt.legend()\nplt.show()","7d4e574d":"def image_journey(img_num):\n    layer_outputs = [layer.output for layer in first_cnn.layers[:4]]\n    activation_model = keras.Model(inputs=first_cnn.inputs, outputs=layer_outputs)\n    activations = activation_model.predict(x[img_num].reshape(1,28,28,1))\n    layer_list=['1st convolution layer','1st pooling layer','2nd convolution layer','2nd pooling layer']\n    fig, ax = plt.subplots(1, 1 ,figsize = (4,4))\n    plt.subplots_adjust(left=0, bottom=-0.2, right=1, top=0.9,wspace=None, hspace=0.1)\n    fig.suptitle('original image', fontsize=30)\n    ax.imshow(x[img_num][:,:,0], cmap='gray')\n    for i in range(4):\n        activation = activations[i]\n        activation_index=0\n        fig, ax = plt.subplots(1, 6 ,figsize = (30,3))\n        fig.suptitle(layer_list[i], fontsize=50)\n        plt.subplots_adjust(left=0, bottom=-0.6, right=1, top=0.6,wspace=None, hspace=0.1)\n        for row in range(0,6):\n            ax[row].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1\nimage_journey(200)","d28ecc27":"# Make our predictions with our CNN model and submit our predictions.\n\nmnist_test = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\nmnist_test = np.loadtxt(mnist_test, skiprows=1, delimiter=',')\n\nnum_images = mnist_test.shape[0]\n\nout_x = mnist_test.reshape(num_images, img_rows, img_cols, 1)\nout_x = out_x \/ 255\n\nresults = first_cnn.predict(out_x)\nresults = np.argmax(results,axis = 1)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(results)+1)),\"Label\": results})\nsubmissions.to_csv(\"\/kaggle\/working\/submission.csv\", index=False, header=True)","51cdef45":"!ls \/kaggle\/working","d6e3aa98":"2nd pooling layer  :\n==\nthe 2nd pooling has same specifications as the first pooling layer.","b56371a1":"flattening layer  :\n==\nwe will now add the flattening layer","847643c4":"![](https:\/\/static.wixstatic.com\/media\/d77a32_076f341258d24f47852625faaa726620~mv2.jpeg\/v1\/fill\/w_1422,h_760,al_c,q_85,usm_0.66_1.00_0.01\/1_uAeANQIOQPqWZnnuH-VEyw.webp)","726b47ba":"* Training set has 42,000 images.  \n* It has 785 columns, 1st coloumn is label for the image and rest 784 are the pixel values.  \n* It is flattened.","e2870d79":"final neural network (prediction model):\n==\ninput layer :  the input layer for the final Neural Network is the same as the flattening layer's output, that is the flattened vector.  \n\nhidden layer :  hidden layer of n3 = 64 nodes and activation funtion = relu  \n\noutput layer :  nodes = number of classes(10) and activation funtion = softmax  ","8c6c8b36":"1st pooling layer  :\n==\nthe pooling layer takes patches of size [2x2] into consideration and has a stride of size = 2 as default ","797fc29c":"2nd convolutional layer  :\n==\nno of filters (n2) = 32  \nfilter dimentions = [5x5]  \nwe will use the relu function as the activation function.","d6639452":"> The last thing that we need to do is 'compile' our CNN model . This is where we specify the loss-function (we will use 'categorical-crossentropy') , the optimizer (we use 'adam' so that the model's learning rate is automatically optimized ) , and for easy evaluation , the metric we will choose is accuracy .","37ce14df":"**MNIST dataset has the following features:**\n\n* Dataset size 60,000 samples of handwritten images.\n* The size of each image is 28x28 pixels.\n* Each image has only 1 color channel, i.e., grayscale image.\n* Each pixel has value in the range of [0,255] where 0 represents black, and 255 represents white.\n* Each image has labeled from 0-9.","1489ca3a":"1st convolutional layer  :\n==\n\nno of filters (n1) = 16  \nfilter dimentions = [5x5]  \nwe will use the relu function as the activation function for all the layers except the output layer.\nwe need to pass the dimentions of the input as input shape , only for the first layer","6df3a73d":"> We see that after a certain no.of epochs the validation loss increases and from there on osciliates non-unformly . this means that beyond a certain epoch our model begins to overfit ! . One of the methods of controlling overfitting is by using   'early stopping' .\n\n**early stopping**  : while the model trains , beyond a certain epoch the loss and accuracy tends to fluctuate. we try to 'catch' the model when it is at its best by saving the model when it has it's lowest loss or highest accuracy , some allowance is given to ensure that the we have the best model , that is called 'patience'. patience is the no of epochs that is allowed to train , to check if the accuracy\/loss gets better or not .","b9f500d7":"**Shamelessly copied from https:\/\/www.kaggle.com\/kumarselvakumaran for my learning**"}}