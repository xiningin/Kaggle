{"cell_type":{"19dbf047":"code","7fa6866d":"code","555c752c":"code","1af43539":"code","c624f9b2":"code","85ff0e5b":"code","93d696f7":"code","291f4cd3":"code","67ec5393":"code","d71d8114":"code","a677fa38":"code","3fb8e834":"code","a80193cc":"code","9471898e":"code","4c1cac45":"code","2f9a6e21":"code","fadadf6d":"code","d17a589f":"code","2a3d5f07":"code","c36b8e22":"code","3b4dc8c2":"code","9910d7d7":"code","8aedab39":"code","c009e1c8":"code","7548b216":"code","a794cd69":"code","724f8c3a":"code","ed613785":"code","390e1dc7":"code","d5110b5d":"code","4c772437":"code","f0cfb16f":"code","ad45add3":"code","58c00bf4":"code","ad091740":"code","c388666c":"code","e0941dc0":"code","856cd55d":"code","7dbd37ba":"code","09dff767":"code","667a065b":"code","26707f04":"code","e0d13bec":"code","8cadb497":"code","31f6a6ea":"code","9b28ecb3":"code","dcfe7e6b":"code","0a11ea40":"code","e6b6c34f":"code","fc1948eb":"code","003204b1":"code","bf4589b0":"code","06ee31f8":"code","e2ab59d8":"code","ae866836":"code","5d2e3435":"code","f183baba":"code","79693626":"code","4e620789":"code","7887b376":"code","d98a600f":"code","5595ef8b":"code","53866683":"code","1b743c23":"code","c6fb6134":"code","179c3bb1":"code","b2f74275":"code","a9430e60":"code","8a96018c":"code","c9356ab4":"code","1f7ccb52":"code","6862c160":"markdown","c87adf4d":"markdown","27ea00a7":"markdown","fbc60d35":"markdown","0c695ca6":"markdown","8bd824c8":"markdown","92d4000c":"markdown","cdc4386d":"markdown","293010a6":"markdown","7f841ef1":"markdown","01b83423":"markdown","19fee0c9":"markdown","f04f9274":"markdown","1f0a9270":"markdown","758fb987":"markdown","946dddc1":"markdown","bee38ec4":"markdown","c5636711":"markdown","918e7eb5":"markdown","433ae5b8":"markdown","9eb7483f":"markdown","8c62f27e":"markdown","beb0de71":"markdown","95194d40":"markdown","ce67b62f":"markdown","22b044a7":"markdown","b345d981":"markdown","bd1dd2fc":"markdown","a21a5eba":"markdown","a84bc18d":"markdown","79df4551":"markdown","da40c6ac":"markdown","1bfb376e":"markdown","022e08ed":"markdown","a070d8e2":"markdown","e165152d":"markdown","d4c2f1c2":"markdown","5590d775":"markdown","823e82cf":"markdown","5246f529":"markdown","300e49cd":"markdown","c809a05e":"markdown","9a2c2fa4":"markdown","26f177b3":"markdown","d1171a43":"markdown","1e53d5d2":"markdown","9fe36b7d":"markdown","45c84a0b":"markdown","634996ab":"markdown","b417f002":"markdown","d217d960":"markdown","98f19d30":"markdown","b96c1df6":"markdown","64fba47b":"markdown","735ca1bd":"markdown"},"source":{"19dbf047":"# load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport sklearn\nsns.set()","7fa6866d":"# load dataset\n\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n\n# train_df = pd.read_csv('..\/inputs\/Costa Rica household\/train.csv')\n# test_df = pd.read_csv('..\/inputs\/Costa Rica household\/test.csv')","555c752c":"train_df.shape","1af43539":"test_df.shape","c624f9b2":"train_df.columns.values","85ff0e5b":"train_df.head()","93d696f7":"train_df.isnull().sum()[train_df.isnull().sum() > 0]","291f4cd3":"import missingno as msno","67ec5393":"msno.matrix(train_df[['v2a1', 'v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']], color = (0.211, 0.215, 0.274))\nplt.show()","d71d8114":"sns.countplot(train_df.loc[(pd.isnull(train_df['v2a1'])), 'tipovivi1'])\nplt.title(\"Ownership\")\nplt.show()","a677fa38":"train_df.loc[(pd.isnull(train_df['v2a1']) & train_df['tipovivi1'] == 1), 'v2a1'] = 0","3fb8e834":"train_df = train_df.loc[pd.notnull(train_df['v2a1'])]","a80193cc":"train_df['v18q1'].dropna().value_counts()","9471898e":"train_df.loc[(pd.isnull(train_df['v18q1'])), 'v18q1'] = 0","4c1cac45":"train_df['rez_esc'].dropna().value_counts()","2f9a6e21":"# statistical measures of those with rez_esc\n\ntrain_df.loc[pd.notnull(train_df['rez_esc']),('age')].describe()","fadadf6d":"# statistical measures of those with missing rez_esc\n\ntrain_df.loc[pd.isnull(train_df['rez_esc']),('age')].describe()","d17a589f":"# train_df.drop(columns='rez_esc', inplace = True)\ntrain_df.loc[pd.isnull(train_df['rez_esc']), 'rez_esc'] = 0","2a3d5f07":"train_df.loc[pd.isnull(train_df['meaneduc']), ('edjefa', 'edjefe', 'escolari', 'meaneduc')]","c36b8e22":"train_df.loc[pd.isnull(train_df['meaneduc']), 'meaneduc'] = train_df.loc[pd.isnull(train_df['meaneduc']), 'escolari']","3b4dc8c2":"train_df.loc[pd.isnull(train_df['SQBmeaned']), 'SQBmeaned'] = train_df.loc[pd.isnull(train_df['SQBmeaned']), 'meaneduc']**2","9910d7d7":"len(train_df.loc[train_df['age'] == 0].index)","8aedab39":"train_df = train_df.loc[train_df['age']!=0]","c009e1c8":"msno.matrix(train_df[['v2a1', 'v18q1', 'meaneduc', 'SQBmeaned']], color = (0.211, 0.215, 0.274))\nplt.show()","7548b216":"train_df.groupby('dependency').size()","a794cd69":"mode = train_df.loc[(train_df['dependency'] != 'yes') & (train_df['dependency'] != 'no'), 'dependency'].astype(float).mode()\nmode","724f8c3a":"def mutate_columns(df):\n    df.loc[df['dependency']=='no', 'dependency'] =  np.sqrt(df['SQBdependency'])\n    df.loc[df['dependency']=='yes', 'dependency'] = np.sqrt(df['SQBdependency'])\n    df['dependency'] = df['dependency'].astype('float16')\n    \n    #The same applies with edjefe and edjefa EXCEPT that the 'yes' value doesn't make any sense? Does it to you? \n    #Anyway, let's just impute for 'yes' values\n    \n    df.loc[df['edjefe']=='no', 'edjefe'] = 0\n    df.loc[df['edjefe']=='yes', 'edjefe'] = 4\n    df['edjefe'] = df['edjefe'].astype('uint8')\n    \n    df.loc[df['edjefa']=='no', 'edjefa'] = 0\n    df.loc[df['edjefa']=='yes', 'edjefa'] = 4\n    df['edjefa'] = df['edjefa'].astype('uint8')","ed613785":"mutate_columns(train_df)\nmutate_columns(test_df)","390e1dc7":"plt.figure(figsize = (10,5))\nsns.countplot(x='Target', data=train_df, palette=\"OrRd_r\")\nplt.xticks([0,1,2,3],['extreme poverty','moderate poverty','vulnerable households','non vulnerable households'])\nplt.xlabel('')\nplt.ylabel('')\nplt.title(\"Poverty Levels\", fontsize = 14)\n\nplt.show()","d5110b5d":"tdf = train_df[['Target']]\nn_train_df = train_df\nfor col in ['v18q', 'refrig', 'computer', 'television', 'mobilephone', 'v14a']:\n    n_train_df[col] = n_train_df[col].astype('category')\ndfcat = pd.get_dummies(n_train_df[[ 'v18q', 'refrig', 'computer', 'television', 'mobilephone', 'v14a']])\ndf_ = pd.concat([dfcat, tdf], axis=1)","4c772437":"df_ = df_.groupby(['Target']).sum()\ndf_.reset_index(inplace = True)","f0cfb16f":"plt.figure(figsize=(12,4))\ngroups = ['extreme','moderate','vulnerable','non-vulnerable']\n\nordered_df = df_.sort_values(by='Target')\nmy_range=range(1,len(df_.index)+1)\n\n\nplt.scatter(ordered_df['v18q_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['v18q_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['v18q_1'], xmax=ordered_df['v18q_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Tablet ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['refrig_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['refrig_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['refrig_1'], xmax=ordered_df['refrig_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Refrigerator ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['computer_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['computer_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['computer_1'], xmax=ordered_df['computer_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Computer ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['television_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['television_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['television_1'], xmax=ordered_df['television_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Television ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['mobilephone_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['mobilephone_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['mobilephone_1'], xmax=ordered_df['mobilephone_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Mobile phone ownership\", fontsize = 14)\nplt.show()\n","ad45add3":"df_ = train_df[['Target', 'male', 'female', 'age']]\ndf_.loc[(train_df['male'] == 1), 'sex'] = 'male'\ndf_.loc[(train_df['female'] == 1), 'sex'] = 'female'\n\nplt.figure(figsize = (10,8))\nsns.violinplot(x='Target',y='age', data=df_, hue='sex', split=True)\nplt.xticks(np.arange(0,5),groups)\nplt.show()\n","58c00bf4":"plt.figure(figsize = (15,15))\ngs = gridspec.GridSpec(4, 2, hspace=0.3)\n\nplt.subplot(gs[0,0])\ng = sns.countplot(train_df['r4h3'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Total males in a household\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nlegend = g.get_legend()\nlegend.set_title(\"Income group\")\nnew_labels = ['extreme', 'moderate', 'vulnerable', 'non-vulnerable']\nfor t, l in zip(legend.texts, new_labels): t.set_text(l)\n\nplt.subplot(gs[0,1])\ng = sns.countplot(train_df['r4m3'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Total females in a household\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nlegend = g.get_legend()\nlegend.set_title(\"Income group\")\nnew_labels = ['extreme', 'moderate', 'vulnerable', 'non-vulnerable']\nfor t, l in zip(legend.texts, new_labels): t.set_text(l)\n\nplt.subplot(gs[1,0]) \nsns.countplot(train_df['r4h1'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Males < 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\n\nplt.subplot(gs[1,1]) \nsns.countplot(train_df['r4m1'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Females < 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(gs[2,0]) \nsns.countplot(train_df['r4h2'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Males >= 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\nplt.subplot(gs[2,1]) \nsns.countplot(train_df['r4m2'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Females >= 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\nplt.show()","ad091740":"df_q = train_df[['Target', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3']]\ndf_q.loc[df_q['epared1'] == 1, 'wall'] = 'Bad'\ndf_q.loc[df_q['epared2'] == 1, 'wall'] = 'Regular'\ndf_q.loc[df_q['epared3'] == 1, 'wall'] = 'Good'\n\ndf_q.loc[df_q['etecho1'] == 1, 'roof'] = 'Bad'\ndf_q.loc[df_q['etecho2'] == 1, 'roof'] = 'Regular'\ndf_q.loc[df_q['etecho3'] == 1, 'roof'] = 'Good'\n\ndf_q.loc[df_q['eviv1'] == 1, 'floor'] = 'Bad'\ndf_q.loc[df_q['eviv2'] == 1, 'floor'] = 'Regular'\ndf_q.loc[df_q['eviv3'] == 1, 'floor'] = 'Good'\n\ndf_q = df_q[['Target', 'wall', 'roof', 'floor']]","c388666c":"print(\"Roof quality\")\nprint(\"==============================================================================================================================\")\ndf_q.loc[df_q['Target'] == 1, 'Target'] = 'Extreme'\ndf_q.loc[df_q['Target'] == 2,'Target'] = 'Moderate'\ndf_q.loc[df_q['Target'] == 3,'Target'] = 'Vulnerable'\ndf_q.loc[df_q['Target'] == 4,'Target'] = 'Non-Vulnerable'\nax = sns.catplot(x = 'roof', col = 'Target', data = df_q, kind=\"count\", col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()\n\nprint(\"Wall quality\")\nprint(\"==============================================================================================================================\")\n\nax = sns.catplot(x = 'wall', col = 'Target', data = df_q, kind=\"count\" ,col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable'], order = ['Bad', 'Regular', 'Good']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()\n\nprint(\"Floor quality\")\nprint(\"==============================================================================================================================\")\n\nax = sns.catplot(x = 'floor', col = 'Target', data = df_q, kind=\"count\", col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()","e0941dc0":"# bars1 = [12, 28, 1, 8, 22]\n# bars2 = [28, 7, 16, 4, 10]\n# bars3 = [25, 3, 23, 25, 17]\n \n# # Heights of bars1 + bars2 (TO DO better)\n# bars = [40, 35, 17, 12, 32]\n \n# # The position of the bars on the x-axis\n# r = [0,1,2,3,4]\n \n# # Names of group and bar width\n# names = ['A','B','C','D','E']\n# barWidth = 1\n \n# # Create brown bars\n# plt.bar(r, bars1, color='#7f6d5f', edgecolor='white', width=barWidth)\n# # Create green bars (middle), on top of the firs ones\n# plt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white', width=barWidth)\n# # Create green bars (top)\n# plt.bar(r, bars3, bottom=bars, color='#2d7f5e', edgecolor='white', width=barWidth)\n \n# # Custom X axis\n# plt.xticks(r, names, fontweight='bold')\n# plt.xlabel(\"group\")\n","856cd55d":"plt.figure(figsize = (10,6))\nplt.subplot(111)\nsns.boxplot(x = 'Target', y = 'overcrowding', data = train_df)\nplt.title('Person per room')\nplt.xlabel('')\nplt.ylabel('')\nplt.xticks(np.arange(0,4), ['extreme','moderate','vulnerable','non-vulnerable'])\nplt.show()","7dbd37ba":"def feature_engineer(x):\n    x['escolari_age'] = x['escolari'] \/ x['age']\n    x['refrig'] = x['refrig'].astype(int)\n    x['computer'] = x['computer'].astype(int)\n    x['television'] = x['television'].astype(int)\n    x['mobilephone'] = x['mobilephone'].astype(int)\n    x['v14a'] = x['v14a'].astype(int)\n    x['v18q'] = x['v18q'].astype(int)\n    x['epared1'] = x['epared1'].astype(int)\n    x['epared2'] = x['epared2'].astype(int)\n    x['epared3'] = x['epared3'].astype(int)\n    x['etecho1'] = x['etecho1'].astype(int)\n    x['etecho2'] = x['etecho2'].astype(int)\n    x['etecho3'] = x['etecho3'].astype(int)\n    \n    x['eviv1'] = x['eviv1'].astype(int)\n    x['eviv2'] = x['eviv2'].astype(int)\n    x['eviv3'] = x['eviv3'].astype(int)\n    x['abastaguadentro'] = x['abastaguadentro'].astype(int)\n    x['abastaguafuera'] = x['abastaguafuera'].astype(int)\n    x['abastaguano'] = x['abastaguano'].astype(int)\n    x['abastaguano'] = x['abastaguano'].astype(int)\n    x[['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']] = x[['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']].apply(pd.to_numeric)\n    \n    x['appliances'] = (x['refrig'] + x['computer'] + x['television'])\n\n    x['rent_by_hhsize'] = x['v2a1'] \/ x['hhsize'] # rent by household size\n    x['rent_by_people'] = x['v2a1'] \/ x['r4t3'] # rent by people in household\n    x['rent_by_rooms'] = x['v2a1'] \/ x['rooms'] # rent by number of rooms\n    x['rent_by_living'] = x['v2a1'] \/ x['tamviv'] # rent by number of persons living in the household\n    x['rent_by_minor'] = x['v2a1'] \/ x['hogar_nin']\n    x['rent_by_adult'] = x['v2a1'] \/ x['hogar_adul']\n    x['rent_by_dep'] = x['v2a1'] \/ x['dependency']\n    x['rent_by_head_educ'] = x['v2a1'] \/ (x['edjefe'] + x['edjefa'])\n    x['rent_by_educ'] = x['v2a1'] \/ x['meaneduc']\n    x['rent_by_numPhone'] = x['v2a1'] \/ x['qmobilephone']\n    x['rent_by_gadgets'] = x['v2a1'] \/ (x['computer'] + x['mobilephone'] + x['v18q'])\n    x['rent_by_num_gadgets'] = x['v2a1'] \/ (x['v18q1'] + x['qmobilephone'])\n    x['rent_by_appliances'] = x['v2a1'] \/ x['appliances']\n    \n    x['under12'] = x['r4t1']\/x['r4t3']\n    x['under12_male'] = x['r4h1']\/x['r4t3']\n    x['under12_female'] = x['r4m1']\/x['r4t3']\n    x['Proportion_male'] = x['r4h3']\/x['r4t3']\n    x['Proportion_female'] = x['r4m3']\/x['r4t3']\n    \n    x['tablet_density'] = x['v18q1'] \/ x['r4t3']\n    x['phone_density'] = x['qmobilephone'] \/ x['r4t3']\n    \n    x['wall_qual'] = x['epared3'] - x['epared1']\n    x['roof_qual'] = x['etecho3'] - x['etecho1']\n    x['floor_qual'] = x['eviv3'] - x['eviv1']\n    x['water_qual'] = x['abastaguadentro'] - x['abastaguano']\n    \n    x['house_qual'] = x['wall_qual'] + x['roof_qual'] + x['floor_qual']\n    \n    x['person_per_room'] = x['hhsize'] \/ x['rooms']\n    x['person_per_appliances'] = x['hhsize'] \/ x['appliances']\n    \n    x['educ_qual'] = (1 * x['instlevel1']) + (2 * x['instlevel2']) + (3 * x['instlevel3']) + (4 * x['instlevel4']) + (5 * x['instlevel5']) + (6 * x['instlevel6']) + ( 7 * x['instlevel7']) + (8 * x['instlevel8']) + (9 * x['instlevel9'])\n    x['educ_by_individual'] = x['escolari']\/x['r4t3']\n    x['educ_by_adult'] = x['escolari']\/(x['r4t3'] - x['r4t1'])\n    x['educ_by_child'] = x['escolari']\/x['r4t1']\n    \n    x['max_educ'] = np.max(x[['edjefa','edjefe']])\n    \n    def reverse_label_encoding(row, df):\n        for c in df.columns:\n            if row[c] == 1:\n                return int(c[-1])\n            \n    def rate_sanitary(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'sanitario2':\n            return 3\n        elif row[c] == 'sanitario3':\n            return 2\n        elif row[c] == 'sanitario5':\n            return 1\n        else:\n            return 0\n        \n    def rate_cooking(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'energcocinar2':\n            return 3\n        elif row[c] == 'energcocinar3':\n            return 2\n        elif row[c] == 'energcocinar4':\n            return 1\n        else:\n            return 0\n        \n    def rate_rubbish(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'elimbasu1':\n            return 1\n        elif row[c] == 'elimbasu2':\n            return 2\n        else:\n            return 0\n            \n    x['sanitary'] = x.apply(lambda q: reverse_label_encoding(q, x[['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']]), axis=1)\n    x['cooking'] =  x.apply(lambda q: reverse_label_encoding(q, x[['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']]), axis=1)\n    x['rubbish'] = x.apply(lambda q: reverse_label_encoding(q, x[['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']]), axis=1)\n    x['region'] = x.apply(lambda q: reverse_label_encoding(q, x[['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']]), axis=1)\n    \n    x['sanitary_i'] = x.apply(lambda q: rate_sanitary(q, x[['sanitary']]), axis = 1)\n    x['cooking_i'] = x.apply(lambda q: rate_cooking(q, x[['cooking']]), axis = 1)\n    x['rubbish_i'] = x.apply(lambda q: rate_rubbish(q, x[['rubbish']]), axis = 1)\n    \n    x['zone'] = x['area1'] - x['area2']\n\n    x.replace([np.inf, -np.inf], 0, inplace = True)\n    x.fillna(0, inplace = True)","09dff767":"feature_engineer(train_df)\nfeature_engineer(test_df)","667a065b":"train_df.shape","26707f04":"# def agg_features(y):\n#     agg_feat = ['hacdor', 'v18q1', 'dis', 'r4h3', 'r4m3', 'age', 'hogar_nin', 'hogar_adul', 'hogar_total', 'dependency',\n#                 'appliances', 'phone_density', 'tablet_density', 'house_qual', 'person_per_appliances', 'educ_qual'\n#                ]\n#     # https:\/\/www.kaggle.com\/gaxxxx\/exploratory-data-analysis-lightgbm\n#     for group in ['idhogar', 'zone', 'region']:\n#         for feat in agg_feat:\n#             for agg_m in ['mean','sum']:\n#                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()[[feat, group]]\n# #                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n#                 new_col = feat + '_' + agg_m + '_' + group \n#                 id_agg.rename(columns = {feat : new_col} , inplace = True)\n#                 y = y.merge(id_agg, how = 'left', on = group)\n\n    \n#     drop_ = ['sanitary', 'cooking', 'rubbish', 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n#             'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6',\n#             'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']\n    \n#     y.drop((drop_), inplace = True, axis = 1)\n#     y.replace([np.inf, -np.inf], 0, inplace = True)\n#     y.fillna(0, inplace = True)\n#     return y","e0d13bec":"def agg_features(y):\n    mean_list = []\n    #o_list = ['escolari', 'age', 'escolari_age', 'phone_density', 'rez_esc', 'dis', 'male', 'female','v2a1','house_qual', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total']\n    count_list = ['escolari_age', 'phone_density', 'rez_esc', 'dis', 'male', 'female','v2a1','house_qual', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total', 'escolari','estadocivil1','estadocivil2','estadocivil3','estadocivil4','estadocivil5','estadocivil6','estadocivil7','parentesco1', 'parentesco2', 'parentesco3',\n                 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']\n        \n#     for group in ['idhogar', 'region']:\n#         for feat in o_list:\n#             for agg_m in ['sum']:\n#                 id_agg = y[feat].groupby(y[group]).agg(agg_m)#.reset_index()[[feat, group]]\n# #                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n#                 new_col = feat + '_' + agg_m + '_' + group \n#                 #id_agg.rename(columns = {feat : new_col} , inplace = True)\n#                 #y = y.merge(id_agg, how = 'left', on = group)\n#                 y[new_col] = id_agg\n                \n    for group in ['idhogar']:            \n        for item in count_list:\n            for agg_m in ['mean','std','min','max','sum']:\n                id_agg = y[item].groupby(y[group]).agg(agg_m)#.reset_index()[[feat, group]]\n    #                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n                new_col = item + '_' + agg_m + '_' + group \n                    #id_agg.rename(columns = {feat : new_col} , inplace = True)\n                    #y = y.merge(id_agg, how = 'left', on = group)\n                y[new_col] = id_agg\n                \n    drop_ = ['sanitary', 'cooking', 'rubbish', 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n            'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'tamhog', 'tamviv', 'hhsize', 'v18q', \n             'v14a', 'agesq','mobilephone', 'female', 'estadocivil1','estadocivil2','estadocivil3','estadocivil4','estadocivil5','estadocivil6','estadocivil7', 'parentesco2', 'parentesco3',\n                 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12', 'lugar1', 'lugar2', 'lugar3', 'lugar4', \n             'lugar5', 'lugar6', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned',\n            'r4t1', 'r4t2', 'r4t3']\n    \n    y.drop((drop_), inplace = True, axis = 1)\n    y.replace([np.inf, -np.inf], 0, inplace = True)\n    y.fillna(0, inplace = True)\n    return y\n            \n            \n# for item in aggr_mean_list:\n#     group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n#     group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n#     new_col = item + '_aggr_mean'\n#     df_train[new_col] = group_train_mean\n#     df_test[new_col] = group_test_mean","8cadb497":"train_df = agg_features(train_df)\ntest_df = agg_features(test_df)","31f6a6ea":"train_df = train_df.loc[train_df['parentesco1'] == 1]\ntrain_df.fillna(value=0, inplace=True)","9b28ecb3":"train_df.shape","dcfe7e6b":"y = train_df[['Target']]\nx = train_df.drop(['Target','Id','idhogar'], axis = 1)","0a11ea40":"train_df.columns.tolist()","e6b6c34f":"from sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb","fc1948eb":"clf = RandomForestClassifier()\nclf.fit(x, y)\n\nimp = clf.feature_importances_\nname = np.array(x.columns.values.tolist())\n\n\ndf_imp = pd.DataFrame({'feature':name, 'importance':imp})\ndf_imp = df_imp.sort_values(by='importance', ascending=False)","003204b1":"# https:\/\/www.kaggle.com\/skooch\/lgbm-with-random-split\/notebook\n\ndef feature_importance(forest, X_train):\n    ranked_list = []\n    \n    importances = forest.feature_importances_\n\n    indices = np.argsort(importances)[::-1]\n\n    # Print the feature ranking\n    print(\"Feature ranking:\")\n\n    for f in range(X_train.shape[1]):\n        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[indices[f]])\n        ranked_list.append(X_train.columns[indices[f]])\n    \n    return ranked_list    ","bf4589b0":"plt.figure(figsize=(8,20))\nsns.barplot(df_imp.loc[(df_imp['importance'] > 0.0005),'importance'], y = df_imp.loc[(df_imp['importance'] > 0.0005),'feature'])\nplt.title('Important features')\nplt.show()","06ee31f8":"important_cols = df_imp.loc[(df_imp['importance']>0),'feature']","e2ab59d8":"x_ = x[important_cols]\n# plt.figure(figsize = (20,16))\n# sns.heatmap(x_.corr(), cmap='YlOrRd')\n# plt.show()","ae866836":"# x_ = x[['meaneduc', 'dependency', 'person_per_room', 'qmobilephone', 'overcrowding', 'hogar_nin', 'age', 'r4t2', 'rooms', 'cielorazo', 'r4h3', 'r4h2', 'r4m3', 'v2a1', 'rent_by_hhsize', 'r4t1', 'escolari', 'v18q', 'r4m1', 'bedrooms', 'edjefe', 'eviv3', 'epared3', 'hogar_adul', 'etecho3', 'r4m2', 'tamviv']]","5d2e3435":"from sklearn.preprocessing import StandardScaler","f183baba":"features = [c for c in x_.columns if c not in ['Target']]\ntarget = train_df['Target']\n\n# scaler = StandardScaler()\n# x_ = scaler.fit_transform(x_)","79693626":"from sklearn.model_selection import train_test_split","4e620789":"from imblearn.combine import SMOTETomek\nsmote_tomek = SMOTETomek(random_state=0)\nX_resampled, y_resampled = smote_tomek.fit_sample(x_, target)","7887b376":"# from imblearn.under_sampling import RandomUnderSampler\n# rus = RandomUnderSampler(random_state=0)\n# X_resampled, y_resampled = rus.fit_sample(x_, target)","d98a600f":"X_train, X_valid, y_train, y_valid = train_test_split(X_resampled,  y_resampled, test_size=0.1, random_state=1)\n#X_train, X_valid, y_train, y_valid = train_test_split(x_,  target, test_size=0.1, random_state=1)","5595ef8b":"pd.options.display.width =300\nX_resampled = pd.DataFrame(X_resampled)\nX_resampled.columns = features\n\ny_resampled = pd.DataFrame(y_resampled)\ny_resampled.columns = ['Target']\n\nX_train_df = pd.DataFrame(X_train)\nX_train_df.columns = features","53866683":"import xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import VotingClassifier","1b743c23":"skf = StratifiedKFold(n_splits=5, shuffle=True)","c6fb6134":"# heavily influenced by https:\/\/www.kaggle.com\/skooch\/lgbm-with-random-split\/notebook\n\n# xgboost = xgb.XGBClassifier(n_estimators=3000, learning_rate=0.2, max_depth = 5, n_classes = 4,\n#                            objective = 'multi:softprob', colsample_bytree = 0.8)\n\nlgbm = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n                             colsample_bytree =  0.88, min_child_samples = 90, num_leaves = 16, subsample = 0.94)","179c3bb1":"# imp = final.feature_importances_\n# name = np.array(X_train_df.columns.tolist())\n\n\n# df_imp = pd.DataFrame({'feature':name, 'importance':imp})\n# df_imp = df_imp.sort_values(by='importance', ascending=False)\n# feat_to_remove = df_imp.loc[df_imp['importance']<=0]","b2f74275":"predicts_lgb = []\nfor train_index, test_index in skf.split(X_resampled, y_resampled):\n    X_t, X_v = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n    y_t, y_v = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n    \n    lgbm.fit(X_t, y_t)\n    predicts_lgb.append(lgbm.predict(test_df[features]))","a9430e60":"# predicts_xgb = []\n# for train_index, test_index in skf.split(x_, target):\n#     X_t, X_v = x_.iloc[train_index], x_.iloc[test_index]\n#     y_t, y_v = target.iloc[train_index], target.iloc[test_index]\n    \n#     xgboost.fit(X_t, y_t, eval_set=[(X_v, y_v)], early_stopping_rounds=50)\n#     predicts_xgb.append(xgboost.predict(test_df[features]))","8a96018c":"# predict = vc.predict(test_df[features].values)","c9356ab4":"submission = pd.DataFrame()\nsubmission['Id'] = test_df['Id']\nsubmission['Target'] = np.array(predicts_lgb).mean(axis=0).round().astype(int)\n#submission['Target'] = np.array(predict)","1f7ccb52":"submission.to_csv('submissions.csv', index=False)","6862c160":"v2a1 is defined as the monthly rent payment of the household. I will assume that those with missing values of v2a1 already owns the house, let's investigate how many of those missing values already owns the house using the tipovivi1 column.","c87adf4d":"SQBmeaned is just square of meaneduc","27ea00a7":"### Variable analysis","fbc60d35":"No zero value, which means the missing values really means zero tablets owned.","0c695ca6":"We could predict the age of this rows, but that would be on a different Kernel. Let's delete these rows for the meantime","8bd824c8":"### Sampling and splitting","92d4000c":"#### Age column","cdc4386d":"For now let us focus on the training data.","293010a6":"meaneduc is defined as average years of education for adults (18+)","7f841ef1":"rez_esc is defined as the Years behind in school. As usual let's check for the value count","01b83423":"Most of the missing monthly rent payment already owns the house, let's impute zero on these rows","19fee0c9":"### Uniform values","f04f9274":"> #  Costa Rican Household : EDA - Feature Selection - Prediction","1f0a9270":"#### The target!","758fb987":"Let us remove the remaining missing values for now. ","946dddc1":"Our target variable is named Target, duhh. Let's explore our target variable","bee38ec4":"As your income group goes up, so is your age. <br>\nA lot of data under age 20 for the extreme, moderate, and vulnerable income groups. Non-vulnerable on the other hand contains a lot of data with over 20 years of age.","c5636711":"#### meaneduc column","918e7eb5":"Let's do an investigation regarding the missing values from these columns","433ae5b8":"#### House quality","9eb7483f":"https:\/\/www.kaggle.com\/grfiv4\/plotting-feature-importances","8c62f27e":"#### rez_esc column","beb0de71":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Data Exploration<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Missing-values\" data-toc-modified-id=\"Missing-values-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Missing values<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#v2a1-column-\" data-toc-modified-id=\"v2a1-column--1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;<\/span>v2a1 column <a id=\"v2a1_c\"><\/a><\/a><\/span><\/li><li><span><a href=\"#v18q1-column\" data-toc-modified-id=\"v18q1-column-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;<\/span>v18q1 column<\/a><\/span><\/li><li><span><a href=\"#rez_esc-column\" data-toc-modified-id=\"rez_esc-column-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;<\/span>rez_esc column<\/a><\/span><\/li><li><span><a href=\"#meaneduc-column\" data-toc-modified-id=\"meaneduc-column-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;<\/span>meaneduc column<\/a><\/span><\/li><li><span><a href=\"#SQBmeaned-column\" data-toc-modified-id=\"SQBmeaned-column-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;<\/span>SQBmeaned column<\/a><\/span><\/li><li><span><a href=\"#Age-column\" data-toc-modified-id=\"Age-column-1.1.6\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;<\/span>Age column<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Uniform-values\" data-toc-modified-id=\"Uniform-values-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Uniform values<\/a><\/span><\/li><li><span><a href=\"#Variable-analysis\" data-toc-modified-id=\"Variable-analysis-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Variable analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#The-target!\" data-toc-modified-id=\"The-target!-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;<\/span>The target!<\/a><\/span><\/li><li><span><a href=\"#Ownership-by-income-group\" data-toc-modified-id=\"Ownership-by-income-group-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;<\/span>Ownership by income group<\/a><\/span><\/li><li><span><a href=\"#Sex-(the-gender)-and-age-by-income-group\" data-toc-modified-id=\"Sex-(the-gender)-and-age-by-income-group-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;<\/span>Sex (the gender) and age by income group<\/a><\/span><\/li><li><span><a href=\"#House-quality\" data-toc-modified-id=\"House-quality-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;<\/span>House quality<\/a><\/span><\/li><li><span><a href=\"#Services\" data-toc-modified-id=\"Services-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;<\/span>Services<\/a><\/span><\/li><li><span><a href=\"#Overcrowding-problem\" data-toc-modified-id=\"Overcrowding-problem-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;<\/span>Overcrowding problem<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Modelling<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Feature-engineering\" data-toc-modified-id=\"Feature-engineering-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Feature engineering<\/a><\/span><\/li><li><span><a href=\"#Feature-selection\" data-toc-modified-id=\"Feature-selection-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Feature selection<\/a><\/span><\/li><li><span><a href=\"#Feature-Scaling\" data-toc-modified-id=\"Feature-Scaling-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>Feature Scaling<\/a><\/span><\/li><li><span><a href=\"#Sampling-and-splitting\" data-toc-modified-id=\"Sampling-and-splitting-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;<\/span>Sampling and splitting<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#XGboost\" data-toc-modified-id=\"XGboost-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;<\/span>LGBM<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Submission<\/a><\/span><\/li><li><span><a href=\"#Summary,-conclusion-and-recommendation\" data-toc-modified-id=\"Summary,-conclusion-and-recommendation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Summary, conclusion and recommendation<\/a><\/span><\/li><\/ul><\/div>","95194d40":"<b>Background:<\/b>\n\nMany social programs have a hard time making sure the right people are given enough aid. It\u2019s especially tricky when a program focuses on the poorest segment of the population. The world\u2019s poorest typically can\u2019t provide the necessary income and expense records to prove that they qualify.\n \nBeyond Costa Rica, many countries face this same problem of inaccurately assessing social need. If Kagglers can generate an improvement, the new algorithm could be implemented in other countries around the world.\n\nTo address this problem we will try to find an optimal solution to classify the income group of families based on household attributes attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need. ","ce67b62f":"SQBmeaned and meaneduc are highly correlated with each other, so we will just use meaneduc. The same with SQBovercrowding and overcrowding, just use overcrowding. hogar_nin is selected ahead of SQBhogar_nin, age ahead of SQBage and agesq, escolari ahead of SQBescolari, v2a1 ahead of rent_by_rooms. tamhog, tamviv, r4t3 and SQBhogar_total, hhsize are highly correlated with each other let's use tamviv because it has higher importance.\n<hr>\nActually, just kidding XGBosst and LGBM are immune to multicollinearity.","22b044a7":"## Data Exploration","b345d981":"You could see above that dependency column contains numerical values and 'no' and 'yes'. <br>\nFor the 'no' values let's impute zero, while for 'yes' let's impute the mode or the most frequent value.","bd1dd2fc":"For selecting the most appopriate columns for our model we will perform two operations. <br>\n<ol>\n    <li>Random Forest for feature importance<\/li>\n    <li>Eliminate highly correlated values<\/li>\n<\/ol>","a21a5eba":"### Missing values","a84bc18d":"We wan't our variables to be in uniform, meaning if it's numeric, then keep it numeric afterall predictive models only understand numeric values.","79df4551":"### Feature selection","da40c6ac":"We're done imputing missing values here is the summary:\n<ol>\n    <li>We've imputed zero values for v2a1 pertaining that a household does not have a monthly rent because they own the house.<\/li>\n    <li>We've also imputed zero values for v18q1. Not everyone owns a tablet at their homes.<\/li>\n    <li>Unfortunately, we've removed rez_vec because it has too much missing values and imputation is not ideal even more so deletion of rows.<\/li>\n    <li>While exploring rez_vec, we've noticed zero values on the age column, this is not possible so for the meantime we've removed those rows.<\/li>\n    <li>meaneduc column is imputed by the value of escolari (years of education). And SQBmeaned is computed <\/li>\n<\/ol>","1bfb376e":"#### Overcrowding problem ","022e08ed":"#### v18q1 column","a070d8e2":"First thing that we would like to do is to apply proper treatment on these missing values.","e165152d":"#### SQBmeaned column","d4c2f1c2":"### Feature Scaling","5590d775":"## Submission","823e82cf":"That's a lot of column, we may want to remove some of them later","5246f529":"--# This is a BEGINNER'S kernel, please go easy on me. Your comments, suggestions and tips will be highly appreciated and if you liked this kernel please upvote. Thank you very much.","300e49cd":"For meaneduc let's just copy escolari (years of education) to the meaneduc","c809a05e":"There seems to be a big imbalance in our data, we may want to apply sampling later on.","9a2c2fa4":"### Feature engineering","26f177b3":"## Modelling","d1171a43":"v18q1 is defined as the number of tablets household owns. It looks too easy that these missing values are 'zeros', hmmmm just to make sure I will check the value counts for v18q1","1e53d5d2":"#### Ownership by income group","9fe36b7d":"----- TO be continued","45c84a0b":"## Summary, conclusion and recommendation","634996ab":"#### Sex (the gender) and age by income group","b417f002":"#### Services","d217d960":"**Unfortunatelly for some reason, I cannot install the latest version of seaborn in this kernel which has the catplot. Please leave a comment if you know the answer to this problem of mine.**","98f19d30":"We could infer from the table above that those with 'Years behind school' data are teenagers and kids with ages 7-17 and those with missing values are much older. This may be due to older people can't remember how many years they are behind already. Unfortunately, we may not be able to perform proper treatment on the missing values of this column, so let's drop this column.\n<hr>\nAlso, the minimum value of age for those with missing rez_esc is zero. I'll have to deal with that later","b96c1df6":"#### LGBM","64fba47b":"Yikes! There are zero values already. Let's investigate further","735ca1bd":"#### v2a1 column <a id = 'v2a1_c'><\/a>"}}