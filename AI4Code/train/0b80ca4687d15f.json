{"cell_type":{"5562c927":"code","4e336f67":"code","a9d9c9f7":"code","62db2f00":"code","0d1c38b3":"code","86a44e24":"code","25091bbc":"code","eab88b1c":"code","5331a861":"code","1fd617fe":"code","5cd9d69d":"code","7e2d1f78":"code","598e0e10":"code","0ef1d870":"code","7780553e":"code","e8359c18":"code","a76aa3c3":"code","367aa9dd":"code","1811eef6":"code","cf85dbec":"code","c498c49a":"code","f508f10f":"code","bde4469d":"code","f4e39641":"code","c5abd102":"code","a0bd1ee3":"code","77f58712":"code","96118339":"code","4746dff8":"code","d2175c72":"code","21c7d1f1":"code","ffdbb21e":"code","b4a1ab6c":"code","67b67b33":"code","d7e0d991":"code","497f9757":"code","927e74b6":"code","1eac1d48":"code","0e4569a9":"code","491aeccd":"code","7b38d1c4":"code","f4a78259":"code","905f7a07":"code","e4c3a223":"code","8ab6ef35":"code","1b61b9cd":"code","415eb39a":"markdown","45b66167":"markdown","74424999":"markdown","522e8c8d":"markdown"},"source":{"5562c927":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e336f67":"import numpy as np\nimport pandas as pd\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\n\nimport pandas, xgboost, numpy, textblob, string\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","a9d9c9f7":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntrain.head()","62db2f00":"train.isnull().sum()","0d1c38b3":"train.drop([\"keyword\",\"location\"],axis = 1,inplace = True)","86a44e24":"train[\"text\"] = train[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))","25091bbc":"train[\"text\"]","eab88b1c":"train[\"text\"] = train[\"text\"].str.replace(\"[\\d]\",\"\")","5331a861":"train[\"text\"]","1fd617fe":"train[\"text\"] = train[\"text\"].str.replace(\"[^\\w\\s]\",\"\")","5cd9d69d":"train[\"text\"]","7e2d1f78":"import nltk\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nsw = stopwords.words(\"english\")","598e0e10":"sw.append(\"u\")\nsw.append(\"im\")","0ef1d870":"train[\"text\"] = train[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))","7780553e":"train[\"text\"]","e8359c18":"from textblob import Word\nnltk.download(\"wordnet\")","a76aa3c3":"train[\"text\"] = train[\"text\"].apply(lambda x: \" \".join(Word(word).lemmatize() for word in x.split()))","367aa9dd":"train[\"text\"]","1811eef6":"train[\"text\"] = train[\"text\"].str.replace('http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\"\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"We're\", \"We are\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"That's\", \"That is\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"won't\", \"will not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"they're\", \"they are\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"Can't\", \"Cannot\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"wasn't\", \"was not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"don\\x89\u00db\u00aat\", \"do not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"aren't\", \"are not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"isn't\", \"is not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"You're\", \"You are\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"I'M\", \"I am\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"shouldn't\", \"should not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"wouldn't\", \"would not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"i'm\", \"I am\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"We've\", \"We have\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"Didn't\", \"Did not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"it's\", \"it is\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"can't\", \"cannot\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"don't\", \"do not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"you're\", \"you are\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"I've\", \"I have\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"Don't\", \"do not\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"I'll\", \"I will\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"Let's\", \"Let us\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"Could've\", \"Could have\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"youve\", \"you have\")\ntrain[\"text\"] = train[\"text\"].str.replace(r\"It's\", \"It is\")","cf85dbec":"train[\"text\"].head()","c498c49a":"from sklearn.model_selection import train_test_split","f508f10f":"tf1 = (train[\"text\"][0:1000]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()","bde4469d":"tf1.columns = [\"words\",\"tf\"]","f4e39641":"tf","c5abd102":"x = tf1[tf1[\"tf\"] > 30].sort_values(by = \"tf\" , ascending = False)","a0bd1ee3":"x.plot.bar( x = \"words\", y = \"tf\", color = \"green\");","77f58712":"from wordcloud import WordCloud","96118339":"for i in range(1,5):\n    text = train[\"text\"][i]\n    wordcloud = WordCloud().generate(text)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n    ","4746dff8":"x_train,x_test,y_train,y_test = train_test_split(train[\"text\"],train[\"target\"],\n                                                test_size = 0.3,\n                                                random_state = 18)","d2175c72":"vectorizer = CountVectorizer()\nvectorizer.fit(x_train)","21c7d1f1":"x_train_count = vectorizer.transform(x_train)\nx_test_count = vectorizer.transform(x_test)","ffdbb21e":"lr = linear_model.LogisticRegression()\nlr_model = lr.fit(x_train_count,y_train)\ny_pred = lr_model.predict(x_test_count)\n\naccuracy_score(y_test,y_pred)","b4a1ab6c":"test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","67b67b33":"test.info()","d7e0d991":"test.drop([\"keyword\",\"location\"], axis = 1,inplace = True)","497f9757":"test.info()","927e74b6":"def prep(test):\n    test[\"text\"] = test[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n    \n    test[\"text\"] = test[\"text\"].str.replace(\"[\\d]\",\"\")\n    \n    test[\"text\"] = test [\"text\"].str.replace(\"[^\\w\\s]\",\"\")\n    \n    test[\"text\"] = test[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n    \n    test[\"text\"] = test[\"text\"].apply(lambda x: \" \".join(Word(word).lemmatize() for word in x.split()))\n    \n    test[\"text\"] = test[\"text\"].str.replace('http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\"\")\n    \n    test[\"text\"] = test[\"text\"].str.replace(r'(((http)(s)?|www(.)?)(:\/\/)?\\S+)',\"\")\n    \n    test[\"text\"] = test[\"text\"].str.replace(r\"\\x89\u00db\u00d3\", \"\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"he's\", \"he is\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"there's\", \"there is\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"We're\", \"We are\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"That's\", \"That is\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"won't\", \"will not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"they're\", \"they are\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"Can't\", \"Cannot\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"wasn't\", \"was not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"don\\x89\u00db\u00aat\", \"do not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"aren't\", \"are not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"isn't\", \"is not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"You're\", \"You are\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"I'M\", \"I am\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"shouldn't\", \"should not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"wouldn't\", \"would not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"i'm\", \"I am\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"We've\", \"We have\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"Didn't\", \"Did not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"it's\", \"it is\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"can't\", \"cannot\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"don't\", \"do not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"you're\", \"you are\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"I've\", \"I have\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"Don't\", \"do not\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"I'll\", \"I will\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"Let's\", \"Let us\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"Could've\", \"Could have\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"youve\", \"you have\")\n    test[\"text\"] = test[\"text\"].str.replace(r\"It's\", \"It is\")\n    \n    return test\n    ","1eac1d48":"df = prep(test)","0e4569a9":"test_x = df[\"text\"] ","491aeccd":"vectorizer = CountVectorizer()\nvectorizer.fit(test_x)\nvectorizer.transform(test_x)","7b38d1c4":"x_test_vec = vectorizer.transform(test_x)","f4a78259":"x_train_vec = vectorizer.transform(x_train)","905f7a07":"nb = naive_bayes.MultinomialNB()\nnb_model = nb.fit(x_train_vec,y_train)\ny_pred = nb_model.predict(x_test_vec)\ny_pred\n","e4c3a223":"dictionary_ = {}\ndictionary_[\"id\"] = test.id\ndictionary_[\"target\"] = y_pred\nsubmission = pd.DataFrame(dictionary_)","8ab6ef35":"submission","1b61b9cd":"submission.to_csv(\"submission_1.csv\" , index = None)","415eb39a":"# Dropping Numbers","45b66167":"# Lemmatization","74424999":"# Cleaning & Preprocessing","522e8c8d":"# Dropping punctuation marks"}}