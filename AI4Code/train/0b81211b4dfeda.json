{"cell_type":{"640eb187":"code","44bcd005":"code","66bc4839":"code","613b8a00":"code","c743575a":"code","ea7e9329":"code","ef3fe7fa":"code","3491a2fb":"code","bc1db5a0":"code","6e4b47f2":"code","fb9ee222":"code","8934d57a":"code","93d981b6":"code","c8f15536":"code","4cb19982":"code","1a79afba":"code","9723b2aa":"code","4ef7f465":"code","9d7acea1":"code","44e97f02":"code","1ff386d5":"code","c8ef1f88":"code","af3c1bad":"code","8dc1f563":"code","76aa8338":"code","5df17e20":"code","cad9f7c9":"code","b4c06580":"code","74c5a0c5":"code","6915fd2c":"code","13ebaa6d":"code","a21ebc3a":"code","560ca503":"code","a56a970f":"code","556da2c7":"code","244dc038":"code","e6dc8afc":"code","a99e2ea4":"code","1cc8c6e7":"code","14a6b3a7":"code","3b512d49":"code","d1c964dc":"code","a119c98d":"code","4b4c2a19":"code","51350f0f":"code","59ae1787":"code","975a35af":"code","478c128c":"code","5df66d00":"code","1096772a":"code","484222b4":"code","5ed48813":"code","4694870b":"code","e0c91d0f":"code","6860dcb4":"code","96a3cb4b":"code","16cc4a39":"code","11983ad6":"code","70d391e7":"code","71c877e5":"code","99375f3b":"code","a56e9e36":"code","91b6fbcf":"code","773b5996":"code","f8a66f0c":"code","775b3768":"code","d80b027b":"code","dbe13873":"code","5e5df7b4":"code","748d4376":"code","c637fc92":"markdown","e3ab214e":"markdown","d4c565fe":"markdown","2635f8a9":"markdown","1d97616d":"markdown","06d38440":"markdown","75525450":"markdown","98eb74eb":"markdown","0bf14393":"markdown","4e7a1d01":"markdown","b9fd430a":"markdown","4adeb4c5":"markdown","83cd50c8":"markdown","381ceead":"markdown","da0daf7c":"markdown","7e41efec":"markdown","f5135325":"markdown","a5cafe06":"markdown","8bb7fd4d":"markdown","57a9be2d":"markdown","583837f2":"markdown","34bed4c2":"markdown","f5e86b4a":"markdown","dd8699c2":"markdown","6a9f0491":"markdown","3bc630c0":"markdown","65c35123":"markdown","1151874a":"markdown","3f655031":"markdown","cdc7d24b":"markdown","4e2ba992":"markdown","2c095e87":"markdown","cfd84795":"markdown","d59c8b0a":"markdown","d79805db":"markdown","570ad3b1":"markdown","da20ab95":"markdown","fb7241c5":"markdown","72cf63c0":"markdown","e061e600":"markdown","3378f4ee":"markdown","372c88c6":"markdown","12d25f5d":"markdown"},"source":{"640eb187":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","44bcd005":"def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","66bc4839":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nss = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","613b8a00":"print(train.shape)\nprint(test.shape)","c743575a":"train.info()","ea7e9329":"train.dropna(inplace=True)","ef3fe7fa":"test.info()","3491a2fb":"train.head()","bc1db5a0":"train.describe()","6e4b47f2":"temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","fb9ee222":"plt.figure(figsize=(12,6))\nsns.countplot(x='sentiment',data=train)","8934d57a":"fig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","93d981b6":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","c8f15536":"results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","4cb19982":"jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')","1a79afba":"train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text","9723b2aa":"train.head()","4ef7f465":"hist_data = [train['Num_words_ST'],train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels,show_curve=False)\nfig.update_layout(title_text='Distribution of Number Of words')\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=700,\n    paper_bgcolor=\"LightSteelBlue\",\n)\nfig.show()","9d7acea1":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")","44e97f02":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\np2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")","1ff386d5":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)","c8ef1f88":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\np2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\nplt.legend(labels=['positive','negative'])","af3c1bad":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)","8dc1f563":"k = train[train['Num_word_text']<=2]","76aa8338":"k.groupby('sentiment').mean()['jaccard_score']","5df17e20":"k[k['sentiment']=='positive']","cad9f7c9":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","b4c06580":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","74c5a0c5":"train.head()","6915fd2c":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","13ebaa6d":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","a21ebc3a":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","560ca503":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","a56a970f":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","556da2c7":"train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords","244dc038":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","e6dc8afc":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","a99e2ea4":"Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']","1cc8c6e7":"#MosT common positive words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","14a6b3a7":"fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","3b512d49":"#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","d1c964dc":"fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\nfig.show()","a119c98d":"#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Reds')","4b4c2a19":"fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","51350f0f":"fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\nfig.show()","59ae1787":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","975a35af":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","478c128c":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","5df66d00":"fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\nfig.show()","1096772a":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Positive Words')\nplt.show()","484222b4":"Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap='Reds')","5ed48813":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Negative Words')\nplt.show()","4694870b":"Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Oranges')","e0c91d0f":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Neutral Words')\nplt.show()","6860dcb4":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'u', \"im\"}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=400, \n                    height=200,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \nd = '\/kaggle\/input\/masks-for-wordclouds\/'","96a3cb4b":"pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\nplot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")","16cc4a39":"plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)","11983ad6":"plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)","70d391e7":"df_train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","71c877e5":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set","99375f3b":"df_train = df_train[df_train['Num_words_text']>=3]","a56e9e36":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'..\/working\/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","91b6fbcf":"# pass model = nlp if you want to train on top of existing model \n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","773b5996":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models\/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models\/model_neg'\n    return model_out_path","f8a66f0c":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","775b3768":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","d80b027b":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","dbe13873":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","5e5df7b4":"selected_texts = []\nMODELS_BASE_PATH = '..\/input\/tse-spacy-model\/models\/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","748d4376":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","c637fc92":"# Leer los datos ","e3ab214e":"Podemos ver algunas tendencias interesantes aqu\u00ed:  * Los tweets positivos y negativos tienen una alta curtosis y, por lo tanto, los valores se concentran en dos regiones estrechas y de alta densidad.  * Los tweets neutrales tienen un valor de curtosis bajo y su densidad aumenta cerca de los valores de 1  Para aquellos que no saben:  * La curtosis es la medida de cu\u00e1n pico es una distribuci\u00f3n y cu\u00e1nta propagaci\u00f3n est\u00e1 alrededor de ese pico.  * La asimetr\u00eda mide cu\u00e1nto se desv\u00eda una curva de una distribuci\u00f3n normal ","d4c565fe":"# Si ","2635f8a9":"He agregado m\u00e1s palabras como im, u (que decimos que estaban all\u00ed en las palabras m\u00e1s comunes, perturbando nuestro an\u00e1lisis) como palabras vac\u00edas ","1d97616d":"## Conclusi\u00f3n de EDA  * Podemos ver en la gr\u00e1fica de puntuaci\u00f3n de jaccard que hay un pico para la gr\u00e1fica negativa y positiva alrededor de la puntuaci\u00f3n de 1. Eso significa que hay un grupo de tweets donde hay una alta similitud entre el texto y los textos seleccionados, si podemos encontrar esos grupos, entonces podemos predecir texto para textos seleccionados para esos tweets independientemente del segmento  Veamos si podemos encontrar esos grupos, una idea interesante ser\u00eda revisar los tweets que tienen un n\u00famero de palabras menor a 3 en el texto, porque all\u00ed el texto podr\u00eda usarse completamente como texto. ","06d38440":"# Acerca de esta competencia\n\nUsted es alguien que est\u00e1 comenzando recientemente en PNL o se ha convertido en un maestro, independientemente de d\u00f3nde se encuentre en la cadena de aprendizaje, puedo apostar que ha trabajado en el an\u00e1lisis de sentimientos y, si no lo har\u00e1, simplemente no puede evitarlo. . \u00bfPuedes?. El <b> an\u00e1lisis de sentimientos <\/b> es para PNL. <b> '\u00bfQu\u00e9 feliz cumplea\u00f1os para ti' <\/b> es para los guitarristas, verdad? Empiece aqu\u00ed <br>\n<br>\nEn caso de que no est\u00e9 al tanto del an\u00e1lisis de sentimientos, aqu\u00ed hay un muy buen art\u00edculo: https:\/\/towardsdatascience.com\/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17\n<br> <br>\nRecientemente, Kaggle lanz\u00f3 una nueva competencia para el COVID-19 Scare, llamada Twitter Sentiment Extraction, s\u00e9 que es una competencia de an\u00e1lisis de sentimientos de Twitter, pero Kaggle nunca te decepciona, no podr\u00eda haber sido tan sencillo, despu\u00e9s de todo, ha durado dos meses. Entonces, lo que pide esta competencia no son las puntuaciones de sentimiento, sino la parte del tweet (palabra o frase) que refleja el sentimiento. Interesante, \u00bfno? Esta competencia es especial, as\u00ed que si quieres mejorar tus habilidades de PNL, esta competencia es para ti.\n\n# Agradecimientos\n* https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes -> FUNCI\u00d3N WORDCLOUDS\n* https:\/\/www.kaggle.com\/rohitsingh9990\/ner-training-using-spacy-0-628-lb -> Para comprender c\u00f3mo entrenar NER espacial en entradas personalizadas\n\n\n# Acerca de este cuaderno\n\nEn este kernel, explicar\u00e9 brevemente la estructura del conjunto de datos y generar\u00e9 y analizar\u00e9 metafunciones. Luego, visualizar\u00e9 el conjunto de datos usando Matplotlib, seaborn y Plotly para obtener la mayor informaci\u00f3n posible. Tambi\u00e9n abordar\u00e9 este problema como un problema NER para construir un modelo\n<br> <br>\nEn caso de que reci\u00e9n est\u00e9 comenzando con la PNL, aqu\u00ed hay una gu\u00eda para abordar casi cualquier problema de PNL del Gran Maestro @Abhishek Thakur\nhttps:\/\/www.slideshare.net\/abhishekkrthakur\/approaching-almost-any-nlp-problem\n\n\n<b> Este kernel es un trabajo en progreso, y seguir\u00e9 actualiz\u00e1ndolo a medida que avanza la competencia y aprendo m\u00e1s y m\u00e1s cosas sobre los datos <\/b>\n\n** <span style = \"color: Red\"> Si encuentra \u00fatil este kernel, por favor vote hacia arriba, me motiva a escribir m\u00e1s contenido de calidad ** ","75525450":"As\u00ed que tenemos 27486 tweets en el conjunto de trenes y 3535 tweets en el conjunto de prueba ","98eb74eb":"* Podemos ver palabras como get, go, dont, got, u, can, lol, like son comunes en los tres segmentos. Eso es interesante porque palabras como no y no puedo son m\u00e1s de naturaleza negativa y palabras como lol son m\u00e1s de naturaleza positiva. \u00bfSignifica esto que nuestros datos est\u00e1n etiquetados incorrectamente, tendremos m\u00e1s informaci\u00f3n sobre esto despu\u00e9s del an\u00e1lisis de N-gram  * Ser\u00e1 interesante ver la palabra \u00fanica para diferentes sentimientos. ","0bf14393":"** En las versiones anteriores de este cuaderno, utilic\u00e9 N\u00famero de palabras en el texto seleccionado y el texto principal, Longitud de las palabras en el texto y seleccionadas como meta caracter\u00edsticas principales, pero en el contexto de esta competencia donde tenemos que predecir selected_text que es un subconjunto de texto, las caracter\u00edsticas m\u00e1s \u00fatiles para generar ser\u00edan **: -  * Diferencia en el n\u00famero de palabras de Selected_text y Text  * Puntuaciones de similitud de Jaccard entre el texto y Selected_text  Por lo tanto, no ser\u00e1 \u00fatil para nosotros generar caracter\u00edsticas que usamos antes, ya que aqu\u00ed no tienen importancia.  Para qui\u00e9n no sabe qu\u00e9 es Jaccard Similarity: https:\/\/www.geeksforgeeks.org\/find-the-jaccard-index-and-jaccard-distance-between-the-two-given-sets\/ ","4e7a1d01":"** Al observar las palabras \u00fanicas de cada sentimiento, ahora tenemos mucha m\u00e1s claridad sobre los datos, estas palabras \u00fanicas son determinantes muy fuertes del sentimiento de los tweets ** ","b9fd430a":"** A continuaci\u00f3n se muestra una funci\u00f3n auxiliar que genera colores aleatorios que se pueden usar para dar diferentes colores a sus gr\u00e1ficos. Si\u00e9ntase libre de usarla ** ","4adeb4c5":"\u00a1Vaya! Mientras limpiamos nuestro conjunto de datos, no eliminamos las palabras vac\u00edas y, por lo tanto, podemos ver que la palabra m\u00e1s com\u00fan es 'para'. Intentemos de nuevo despu\u00e9s de eliminar las palabras vac\u00edas ","83cd50c8":"## Palabras m\u00e1s comunes en nuestro texto seleccionado de destino ","381ceead":"## Veamos palabras \u00fanicas en cada segmento  Veremos palabras \u00fanicas en cada segmento en el siguiente orden:  * Positivo  * Negativo  * Neutral ","da0daf7c":"### Limpieza del Corpus  Ahora, antes de sumergirnos en la extracci\u00f3n de informaci\u00f3n de palabras en texto y texto seleccionado, primero limpiemos los datos ","7e41efec":"#### NUBE DE PALABRAS DE TWEETS NEUTRALES  Ya hemos visualizado nuestras palabras negativas m\u00e1s comunes, pero las nubes de palabras nos brindan mucha m\u00e1s claridad ","f5135325":"* El diagrama de n\u00famero de palabras es realmente interesante, los tweets que tienen un n\u00famero de palabras superior a 25 son muy inferiores y, por lo tanto, el diagrama de distribuci\u00f3n del n\u00famero de palabras est\u00e1 sesgado a la derecha ","a5cafe06":"## Qu\u00e9 sabemos actualmente sobre nuestros datos:\n\nAntes de comenzar, veamos algunas cosas que ya sabemos sobre los datos y que nos ayudar\u00e1n a obtener m\u00e1s conocimientos nuevos:\n* Sabemos que selected_text es un subconjunto de texto\n* Sabemos que selected_text contiene solo un segmento de texto, es decir, no salta entre dos oraciones. Por ejemplo: - Si el texto es 'Pas\u00e9 toda la ma\u00f1ana en una reuni\u00f3n con un proveedor, y mi jefe no estaba contento con ellos. Mucha diversi\u00f3n. Ten\u00eda otros planes para mi ma\u00f1ana 'El texto seleccionado puede ser' mi jefe no estaba contento con ellos. Mucha diversi\u00f3n 'o' Mucha diversi\u00f3n 'pero no puede ser' Buenos d\u00edas, vendedor y mi jefe,\n* Gracias a esta discusi\u00f3n: https: \/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/138520 Sabemos que los tweets neutrales tienen una similitud jaccard del 97 por ciento entre el texto y el texto seleccionado\n* Tambi\u00e9n como se discuti\u00f3 aqu\u00ed https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/138272, hay filas donde selected_text comienza entre las palabras y, por lo tanto, selected_texts no siempre tienen sentido y ya que no lo sabemos si la salida del conjunto de prueba contiene estas discrepancias o no, no estamos seguros de que el preprocesamiento y la eliminaci\u00f3n de las puntuaciones sea una buena idea o no ","8bb7fd4d":"Dibujemos un gr\u00e1fico de embudo para una mejor visualizaci\u00f3n ","57a9be2d":"No pude trazar el gr\u00e1fico kde para tweets neutrales porque la mayor\u00eda de los valores para la diferencia en el n\u00famero de palabras eran cero. Podemos verlo claramente ahora, si hubi\u00e9ramos usado la funci\u00f3n al principio, habr\u00edamos sabido que el texto y el texto seleccionado son en su mayor\u00eda lo mismo para los tweets neutrales, por lo que siempre es importante tener en cuenta el objetivo final al realizar EDA ","583837f2":"Entonces podemos ver que las palabras m\u00e1s comunes en el texto seleccionado y el texto son casi las mismas, lo cual era obvio ","34bed4c2":"No pude trazar kde de jaccard_scores de tweets neutrales por la misma raz\u00f3n, por lo que trazar\u00e9 una trama de distribuci\u00f3n ","f5e86b4a":"# Importaci\u00f3n de necesidades ","dd8699c2":"Por lo tanto, est\u00e1 claro que la mayor\u00eda de las veces, el texto se usa como texto seleccionado. Podemos mejorar esto procesando previamente el texto que tiene una longitud de palabra menor a 3. Recordaremos esta informaci\u00f3n y la usaremos en la construcci\u00f3n de modelos. ","6a9f0491":"** Ahora ser\u00e1 m\u00e1s interesante ver la diferencia en el n\u00famero de palabras y puntuaciones de jaccard en diferentes sentimientos ** ","3bc630c0":"### Tweets positivos ","65c35123":"Podemos ver que existe similitud entre el texto y el texto seleccionado. Veamos m\u00e1s de cerca ","1151874a":"## 1) Modelando el problema como NER\n\nEl reconocimiento de entidades con nombre (NER) es un problema est\u00e1ndar de PNL que implica detectar entidades con nombre (personas, lugares, organizaciones, etc.) de un fragmento de texto y clasificarlas en un conjunto predefinido de categor\u00edas.\nPara comprender NER, aqu\u00ed hay un muy buen art\u00edculo: https:\/\/towardsdatascience.com\/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n\nUsaremos spacy para crear nuestro propio modelo o modelos NER personalizados (separados para cada Sentiment). La motivaci\u00f3n para este enfoque es, por supuesto, el kernel compartido por Rohit Singh, as\u00ed que si encuentra \u00fatil su kernel, por favor vote por \u00e9l.\n\n\u00bfQu\u00e9 ser\u00e1 diferente con mi soluci\u00f3n?\n* Usar\u00e9 text como selected_text para todos los tweets neutrales debido a su gran similitud con jaccard\n* Tambi\u00e9n usar\u00e9 text como selected_text para todos los tweets que tengan un n\u00famero de palabras menor a 3 en el texto como se explic\u00f3 antes\n* Entrenar\u00e9 dos modelos diferentes para tweets positivos y negativos\n* No preprocesar\u00e9 los datos porque el texto seleccionado contiene texto sin formato ","3f655031":"Veamos la distribuci\u00f3n de tweets en el tren. ","cdc7d24b":"# Notas finales\nKaggle siempre proporciona muchos d\u00edas para una competencia que uno puede utilizar para aprender y crecer.Como promet\u00ed, present\u00e9 mi primer modelo, junto con una explicaci\u00f3n, puede leer la documentaci\u00f3n de Spacy y el kernel de Rohit Singh ya que todo el c\u00f3digo proviene de su. si comprende cualquier parte del c\u00f3digo, no dude en comentar y preguntar, intentar\u00e9 resolverlo.\nComo esta es mi primera competencia, tambi\u00e9n estoy aprendiendo a lo largo del camino, volver\u00e9 con ideas m\u00e1s originales y algunos modelos geniales a medida que aprenda m\u00e1s y m\u00e1s sobre preguntas \/ respuestas, otras t\u00e9cnicas diferentes, varias formas de BERT y los datos en s\u00ed.\n\n** Gracias por el enorme amor y aprecio, lamento no haber actualizado el kernel con el enfoque de preguntas y respuestas, todav\u00eda estoy aprendiendo todas las t\u00e9cnicas necesarias, \u00a1lo actualizar\u00e9 pronto! **\n<br> <br> \u00a1MANT\u00c9NGASE SINTONIZADO!\n\n<span style = \"color: Red\"> Espero que les haya gustado mi kernel. Un upvote es un gesto de agradecimiento y aliento que me llena de energ\u00eda para seguir mejorando mis esfuerzos, sea amable de mostrar uno ;-) ","4e2ba992":"### Predicci\u00f3n con el modelo entrenado ","2c095e87":"# Palabras m\u00e1s comunes Sentimientos Sabio  Veamos las palabras m\u00e1s comunes en diferentes sentimientos. ","cfd84795":"** Para una comprensi\u00f3n completa de c\u00f3mo entrenar Spacy NER con entradas personalizadas, lea la documentaci\u00f3n de Spacy junto con la presentaci\u00f3n del c\u00f3digo en este cuaderno: https:\/\/spacy.io\/usage\/training#ner Siga las instrucciones de Actualizaci\u00f3n de Spacy NER * * ","d59c8b0a":"Veamos la distribuci\u00f3n de las metacaracter\u00edsticas ","d79805db":"## Es hora de nubes de palabras  Construiremos nubes de palabras en el siguiente orden:  * WordCloud de tweets neutrales  * WordCloud de tweets positivos  * WordCloud de tweets negativos ","570ad3b1":"# Modelado\n\nEsta es la primera competencia de kaggle, en la que estoy participando y este podr\u00eda ser el caso de muchos de nosotros. Debido a la estructura \u00fanica del planteamiento del problema, es dif\u00edcil para cualquier principiante o novato de competencias responder a la pregunta \"\u00bfQu\u00e9 modelo to Use \"?. Mis pensamientos iniciales fueron que esta competencia no es para m\u00ed y ya termin\u00e9 aqu\u00ed, pero luego record\u00e9 algo, estuve en el KaggleDays Meetup Delhi este a\u00f1o y tuve esta maravillosa oportunidad de conocer al Gran Maestro Abhishek Thakur y durante el Sesi\u00f3n de preguntas y respuestas Le pregunt\u00e9 que las competiciones de kaggle son tan diversas, \u00fanicas, requieren muchos conocimientos previos y, por lo tanto, da miedo participar, a lo que respondi\u00f3 y cito \"\u00a1Aterrador, s\u00ed! aprende si no vas a participar \".\n\nAs\u00ed que aqu\u00ed estoy luchando para abrirme camino a trav\u00e9s de esta competencia y tratando de aprender cosas diferentes e insto a todos a hacer lo mismo, puede que no est\u00e9 tan bien establecido para dar consejos, pero realmente quer\u00eda compartir esa historia para motivar a la gente.\n\nDespu\u00e9s de pasar por los foros de discusi\u00f3n, seguir los consejos de los expertos y ver el tutorial de Abhishek Sir anoche, este problema se puede modelar de la siguiente manera:\n* Reconocimiento de entidad nombrada\n* Problema de preguntas y respuestas\n* Tambi\u00e9n encontr\u00e9 un enfoque simple compartido por Nick en su hermoso kernel donde tiene el concepto de Gini Impurity para dar peso a las palabras presentes en los tweets y luego predecir usando el peso de esas palabras: https:\/\/www.kaggle.com\/ nkoprowicz \/ a-simple-solution-using-only-word-count \/ notebook. Compru\u00e9belo.\n* Otras ideas de modelado: - https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/139803 -> Aqu\u00ed hay una muy buena idea\n* Otra idea \u00fatil: - https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/139335\n\nRecursos:\n* Para problemas de modelado como NER: https:\/\/www.kaggle.com\/rohitsingh9990\/ner-training-using-spacy-0-628-lb\n* Para problemas de modelado AS Q&A: https:\/\/www.kaggle.com\/jonathanbesomi\/question-answering-starter-pack ---> Esta es una gu\u00eda completa y desde cero ","da20ab95":"#### Modelos de entrenamiento para tweets positivos y negativos ","fb7241c5":"No hay valores nulos en el conjunto de prueba ","72cf63c0":"Entonces, las dos primeras palabras comunes fueron I'm, as\u00ed que la elimin\u00e9 y tom\u00e9 datos de la segunda fila ","e061e600":"Tenemos un valor nulo en el tren, ya que el campo de prueba para el valor es NAN, simplemente lo eliminaremos ","3378f4ee":"Selected_text es un subconjunto de texto ","372c88c6":"## Generaci\u00f3n de metacaracter\u00edsticas ","12d25f5d":"# Palabras m\u00e1s comunes en el texto  Veamos tambi\u00e9n las palabras m\u00e1s comunes en Text "}}