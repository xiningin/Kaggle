{"cell_type":{"f849f8de":"code","c7e39e7a":"code","56264e67":"code","1db4ef73":"code","e7fdc035":"code","d321194d":"code","85b2a0c4":"code","f2906da5":"code","3d8c9541":"code","d787ef15":"code","c43e3c43":"code","5c522d42":"code","e344834d":"code","0a640368":"code","1395d4d4":"code","5b5c75d5":"code","3ff4d88d":"code","beeccd10":"code","c59798aa":"code","39e4bb01":"code","f799a773":"code","0b94c98f":"code","ddf514bd":"code","b903330d":"code","585b5a84":"code","a38c9aa2":"code","75ab75f0":"code","38b46523":"code","7e67addf":"markdown"},"source":{"f849f8de":"!pip install xlrd\n!pip install openpyxl\n!pip install tqdm\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom scipy.fft import fft\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, robust_scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\nfrom numpy import array\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM\nfrom keras.layers import LSTM, TimeDistributed\nfrom keras.layers import Dense\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras import optimizers","c7e39e7a":"df = pd.read_excel(\"..\/input\/irpckaggle\/compressor-edit.xlsx\")\ndf.date = pd.to_datetime(df.date)\ndf = df.set_index(\"date\")\ndf.head()","56264e67":"df.columns","1db4ef73":"plan = pd.read_excel(\"..\/input\/irpckaggle\/\u2557\u251c\u2568\u255f\u2564\u2561\u2558\u03b1\u00f1\u251c\u256b\u03a6\u2550\u00ba\u00bf\u2564\u00ed\u251c.xlsx\")\nplan.MalFnSt = pd.to_datetime(plan.MalFnSt)\nplan.MalFnEnd = pd.to_datetime(plan.MalFnEnd)\n\nplan","e7fdc035":"# df[['VI3108101X.PV', 'VI3108101Y.PV', 'VI3108102X.PV', 'VI3108102Y.PV',\n#        'VI3108131X.PV', 'VI3108131Y.PV', 'VI3108132X.PV', 'VI3108132Y.PV',\n#        'VI3108151X.PV', 'VI3108151Y.PV', 'VI3108152X.PV', 'VI3108152Y.PV',\n#        'VI3108161X.PV', 'VI3108161Y.PV', 'VI3108162X.PV', 'VI3108162Y.PV']]\n# df['SI3104901.PV'].plot()\n# df.loc['2018', ['SI3104901.PV']].plot()\n\nfig, ax = plt.subplots(figsize=(24,6))\n\n# change this to months\n# ax.xaxis.set_major_locator(mdates.MinuteLocator(byminute = [0, 30]))\n# ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n\n# number of rows where motor RPM below 5000\nprint(f\"There are {df[df['SI3104901.PV'] < 5000].shape[0]} rows below 5000\")\n\n# df['SI3104901.PV'].plot(figsize = (20,6), ax = ax) # all records\ndf[df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(figsize = (20,6), ax = ax) # only records where RPM > 5000\n\n\n\nfor idx, (datestart, dateend) in tqdm(plan[['MalFnSt', 'MalFnEnd']].iterrows()):\n    ax.axvline(datestart, color ='k', linestyle = '--')\n#     try:\n#         ax.axvline(dateend, color ='r', linestyle = '--')\n#     except:\n#         print(dateend)\n    \n    ","d321194d":"fig, ax = plt.subplots(figsize=(24,6))\n\ndf[df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(figsize = (20,6), ax = ax, color = 'black') # only records where RPM > 5000\n\nfor idx, (datestart, dateend) in tqdm(plan[['MalFnSt', 'MalFnEnd']].iterrows()):\n    ax.axvline(datestart, color ='k', linestyle = '--')\n    \nax2 = ax.twinx()\n\ndf[df['SI3104901.PV'] > 5000][['VI3108101X.PV', 'VI3108101Y.PV']].plot(figsize = (20,6), ax = ax2) ","85b2a0c4":"df[:'2020-06']","f2906da5":"df['2019-12-10':][df['SI3104901.PV'] > 5000].index","3d8c9541":"from scipy.signal import find_peaks\n\n\nfig, ax = plt.subplots(figsize=(30,10)); ax2 = ax.twinx()\n# df['2019-12-10':][df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(ax = ax, color = 'black')\ntemperature_columns = ['TI3104801.PV', 'TI3104802.PV', 'TI3104901.PV',\n       'TI3104902.PV', 'TI3105203.PV', 'TI3105301.PV', 'TI3108102.PV',\n       'TI3108104.PV', 'TI3108105.PV', 'TI3108106.PV', 'TI3108107.PV',\n       'TI3108108.PV', 'TI3108111.PV', 'TI3108113.PV', 'TI3108114.PV',\n       'TI3108115.PV', 'TI3108116.PV', 'TI3108119.PV', 'TI3108131.PV',\n       'TI3108132.PV', 'TI3108134.PV', 'TI3108135.PV', 'TI3108136.PV']\n\n\n\nfor i in ['TI3108106.PV']:\n    x = np.real(fft(df['2019-12-10':][df['SI3104901.PV'] > 5000][[i]])).reshape(-1)\n    peaks, _ = find_peaks(x, width = 5, height = 58, prominence = 1, distance = 10)\n    ax.plot(x)\n    ax.plot(peaks, x[peaks], 'o')\n\n","d787ef15":"import datetime\n\nfig, ax = plt.subplots(figsize=(30,10)); ax2 = ax.twinx()\n\ndf['2019-12-10':][df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(ax = ax, color = 'black') # only records where RPM > 5000\ndf['2019-12-10':][df['SI3104901.PV'] > 5000][['TI3104801.PV', 'TI3104802.PV', 'TI3104901.PV',\n       'TI3104902.PV', 'TI3105203.PV', 'TI3105301.PV', 'TI3108102.PV',\n       'TI3108104.PV', 'TI3108105.PV', 'TI3108106.PV', 'TI3108107.PV',\n       'TI3108108.PV', 'TI3108111.PV', 'TI3108113.PV', 'TI3108114.PV',\n       'TI3108115.PV', 'TI3108116.PV', 'TI3108119.PV', 'TI3108131.PV',\n       'TI3108132.PV', 'TI3108134.PV', 'TI3108135.PV', 'TI3108136.PV']].plot(ax = ax2)\n\nfor idx, (datestart, dateend) in plan[(plan['MalFnSt'] < '2020-06') & (plan['MalFnSt'] > '2019-12-10')][['MalFnSt', 'MalFnEnd']].iterrows():\n    ax.axvline(datestart, color ='k', linestyle = '--')\n    \nax.set_title('All Temperatures')\nax.axvline(datetime.datetime(2019,12,26), color = 'blue')\nax.axvline(datetime.datetime(2020,2,18), color = 'blue')\nplt.show()","c43e3c43":"fig, ax = plt.subplots(figsize=(30,10)); ax2 = ax.twinx()\n\ndf['2019-12-10':][df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(ax = ax, color = 'black') # only records where RPM > 5000\ndf['2019-12-10':][df['SI3104901.PV'] > 5000][['VI3108131X.PV', 'VI3108131Y.PV', 'VI3108132X.PV', 'VI3108132Y.PV',\n                               'VI3108151X.PV', 'VI3108151Y.PV', 'VI3108152X.PV', 'VI3108152Y.PV']].plot(ax = ax2)\n\nfor idx, (datestart, dateend) in plan[(plan['MalFnSt'] < '2020-06') & (plan['MalFnSt'] > '2019-12-10')][['MalFnSt', 'MalFnEnd']].iterrows():\n    ax.axvline(datestart, color ='k', linestyle = '--')\n    \nax.set_title('L-Shaft Frequencies (Motor Side)')\nax.axvline(datetime.datetime(2019,12,26), color = 'blue')\nax.axvline(datetime.datetime(2020,2,18), color = 'blue')\nplt.show()","5c522d42":"fig, ax = plt.subplots(figsize=(30,10)); ax2 = ax.twinx()\n\ndf['2019-12-10':][df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(ax = ax, color = 'black') # only records where RPM > 5000\ndf['2019-12-10':][df['SI3104901.PV'] > 5000][['VI3108101X.PV', 'VI3108101Y.PV', 'VI3108102X.PV', 'VI3108102Y.PV',\n                               'VI3108161X.PV', 'VI3108161Y.PV', 'VI3108162X.PV', 'VI3108162Y.PV']].plot(ax = ax2)\n\nfor idx, (datestart, dateend) in plan[(plan['MalFnSt'] < '2020-06') & (plan['MalFnSt'] > '2019-12-10')][['MalFnSt', 'MalFnEnd']].iterrows():\n    ax.axvline(datestart, color ='k', linestyle = '--')\n    \nax.set_title('H-Shaft Frequencies (Compressor Side)')\nax.axvline(datetime.datetime(2019,12,26), color = 'blue')\nax.axvline(datetime.datetime(2020,2,18), color = 'blue')\nplt.show()","e344834d":"fig, ax = plt.subplots(figsize=(30,10)); ax2 = ax.twinx()\n\ndf['2019-12-10':][df['SI3104901.PV'] > 5000]['SI3104901.PV'].plot(ax = ax, color = 'black') # only records where RPM > 5000\ndf['2019-12-10':][df['SI3104901.PV'] > 5000][['VI3108101X.PV', 'VI3108101Y.PV', 'VI3108102X.PV', 'VI3108102Y.PV',\n                               'VI3108161X.PV', 'VI3108161Y.PV', 'VI3108162X.PV', 'VI3108162Y.PV']].plot(ax = ax2)\n\nfor idx, (datestart, dateend) in plan[(plan['MalFnSt'] < '2020-06') & (plan['MalFnSt'] > '2019-12-10')][['MalFnSt', 'MalFnEnd']].iterrows():\n    ax.axvline(datestart, color ='k', linestyle = '--')\n    \nax.set_title('H-Shaft Frequencies (Compressor Side)')\nax.axvline(datetime.datetime(2019,12,26), color = 'blue')\nax.axvline(datetime.datetime(2020,2,18), color = 'blue')\nplt.show()","0a640368":"scaler = StandardScaler()\n\ntrain_df = df['2020':]\nscaled_train_df = pd.DataFrame(scaler.fit_transform(train_df), \n                         index=train_df.index, columns=train_df.columns)\nscaled_train_df.head()","1395d4d4":"input_enc = len(df.columns)\ndropout = 0.0\n\ninput_enc_layer = Input(shape=(None, input_enc))\nlayer = LSTM(25,\n#                               stateful=False\n#                               activation=enc_act[0], recurrent_activation=enc_rec_act[0],\n#                               activity_regularizer=regularizers.l1(10e-100),\n#                               batch_input_shape=batch_input_shape,\n                               return_sequences=True,\n#                               return_state=True,\n                               #dropout=dropout,\n                               #recurrent_dropout=dropout\n                              )(input_enc_layer)\n\nlayer = LSTM(50,\n#                               stateful=False\n#                               activation=enc_act[0], recurrent_activation=enc_rec_act[0],\n#                               activity_regularizer=regularizers.l1(10e-100),\n#                               batch_input_shape=batch_input_shape,\n                               return_sequences=True,\n#                               return_state=True,\n                               #dropout=dropout,\n                               #recurrent_dropout=dropout\n                              )(input_enc_layer)\n\nlayer = LSTM(25,\n#                               stateful=False\n#                               activation=enc_act[0], recurrent_activation=enc_rec_act[0],\n#                               activity_regularizer=regularizers.l1(10e-100),\n#                               batch_input_shape=batch_input_shape,\n                               return_sequences=False,\n#                               return_state=True,\n                               #dropout=dropout,\n                               #recurrent_dropout=dropout\n                              )(layer)\n\n\nlayer = Dense(1,activation='linear')(layer)\n\n\n#output_layer = TimeDistributed(Dense(input_enc, activation='linear'))(layer)\n\nops = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel = Model(inputs=input_enc_layer, outputs=layer)\nmodel.compile(optimizer=ops,\n              loss='mse',\n              metrics=['mse'])\n","5b5c75d5":"model.summary()\n","3ff4d88d":"def lookback_window(input_df, window_size, step=1):\n    #input_array: 2D np array of size (num_timesteps, window_size)\n    #window_size: int, size of the window to slice array\n    #step: int, number of timestep to increment window by\n    #return: a 3D array of size (batch_size, window_size, num_features) \n\n    samples = input_df.shape[0] - window_size + step\n    sensors = input_df.shape[1]\n    \n    array = np.empty(shape=(int(samples\/step), window_size, sensors))\n    index = pd.DataFrame(data=np.empty(int(samples\/step)))\n                     \n    for s in range(int(samples\/step)):\n        array[s, :, :] = input_df.iloc[s*step : s*step + window_size, :]\n        index.iloc[s] = input_df.index[s*step + window_size - 1]\n        \n    return index, array\n","beeccd10":"val_split = 0.2\nwindow_size = 24\nstep = 1\n\nindices, input_train_enc = lookback_window(scaled_train_df, window_size, step)\n\ntrain_size_enc = int(input_train_enc.shape[0]*(1 - val_split))\nval_data_enc    = input_train_enc[train_size_enc:-1, :, :]\ninput_train_enc = input_train_enc[0:train_size_enc, :, :]\n\nhistory = model.fit(input_train_enc[:,0:-1,:], input_train_enc[:,-1,0],\n                    epochs=10,\n                    batch_size=256,\n                    shuffle=False,\n                    validation_data=(val_data_enc[:,0:-1,:], val_data_enc[:,-1,0]),\n                    verbose=1).history\n\nmodel.save('weights2.h5')\n","c59798aa":"from keras.models import load_model\n\nmodel = load_model('weights2.h5')\nval_split = 0.2\nwindow_size = 24\nstep = 1\n","39e4bb01":"window = 24\np = 0.1\nrg = 1\n\n\ntrain_index, batches = lookback_window(scaled_train_df, window_size, step)\ntrain_prediction = model.predict(batches[:,0:-1,:])\n","f799a773":"scaled_train_df.loc[train_index.iloc[:,0],['']] ","0b94c98f":"train = scaled_train_df.loc[train_index.iloc[:,0],'FIC3104801.PV']  #these are the valid train indices according to the mask\ntrain_error = np.absolute(train.values - train_prediction.flatten())**2\ntrain_error = pd.DataFrame(data=train_error,\\\n                           index=train.index)\ntrain = pd.Series(data=train_error.sum(axis=1))\ntrain_mean = train.rolling(window).mean().dropna()\ntrain_std  = train.rolling(window).std().dropna()\n","ddf514bd":"ax = train_mean.plot(figsize=(20, 10))\nax.set_title(\"anomaly score for Train and FIC3104801.PV\", fontsize=35)\nax.set_ylabel(\"anomaly score\", fontsize=30)\n","b903330d":"[d for d in train_mean.nlargest(10).index]","585b5a84":"test_df = df['2020-01-10':]\nscaled_test_df = pd.DataFrame(scaler.transform(test_df), \n                         index=test_df.index, columns=test_df.columns)\nscaled_test_df.head()\n","a38c9aa2":"test_index, batches = lookback_window(scaled_test_df, window_size, step)\ntest_prediction = model.predict(batches[:,0:-1,:])\n\ntest = scaled_test_df.loc[test_index.iloc[:,0],'FIC3104801.PV']  #these are the valid test indices according to the mask\ntest_error = np.absolute(test.values - test_prediction.flatten())**2\ntest_error = pd.DataFrame(data=test_error,\\\n                           index=test.index)\ntest = pd.Series(data=test_error.sum(axis=1))\ntest_mean = test.rolling(window).mean().dropna()\ntest_std  = test.rolling(window).std().dropna()\n","75ab75f0":"test_mean.plot(figsize=(20,10))\n","38b46523":"test_mean.nlargest(10)\n","7e67addf":"## Plotting Individual Vibrations"}}