{"cell_type":{"ba4cd67f":"code","7cc3c18f":"code","d085180e":"code","0e7b3a16":"code","105ccbb5":"code","b0f85463":"code","01d284fc":"code","7d03c7bc":"code","406f9cf5":"code","8a1610ac":"code","94880634":"code","71ab5a41":"code","44f24e6b":"code","c83fa0c6":"code","23661239":"code","74299b27":"code","586b5509":"code","a1d623b3":"code","6bb1f5b7":"code","ecc08b43":"code","0befd3d0":"code","8f3cba31":"code","ad0a9cd1":"code","1a6bb5c2":"code","250b9eed":"code","c60a300e":"code","e1773bc6":"code","4a28ba3e":"code","be8a9b75":"code","de6e9841":"code","a6fb2f16":"code","5d401b45":"code","7b9e8e25":"code","058556d2":"code","5d0ef60a":"code","6f6ce4fd":"code","e86799a3":"code","f1bd0fb6":"code","f9cd84ec":"code","e4586837":"code","bc7c2b16":"code","e2f01de7":"code","bd432054":"code","b4b7c71e":"code","dffccfc9":"code","6a03e672":"code","8cbf9356":"code","965062a4":"code","2e135898":"code","9eb9c2af":"code","534b4190":"code","f250ede0":"code","8f1c871a":"code","7ec163aa":"code","846248b9":"code","26323b3f":"code","83515570":"code","62b78e43":"code","210ed729":"code","0b655b73":"code","061778ef":"code","2f1cd3f6":"code","74d1681c":"code","e8003cf3":"code","96655d72":"code","81a1c5d1":"code","91b2d844":"code","a443475b":"code","089a3946":"code","2b8d126d":"code","d7e4c18d":"code","effa7656":"markdown","82edbee4":"markdown","5fd84177":"markdown","564ba988":"markdown","87ae7615":"markdown","f4f42a51":"markdown","98fecf50":"markdown","33ff0098":"markdown","e9a9342f":"markdown","bfaff0f2":"markdown","b72cabef":"markdown","ad1dd660":"markdown","8d9276c1":"markdown","da25b753":"markdown","3900376d":"markdown","81d65368":"markdown"},"source":{"ba4cd67f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7cc3c18f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d085180e":"# loading the data\ndata = pd.read_csv('\/kaggle\/input\/glassdoor_jobs.csv')\ndata.head(3)","0e7b3a16":"data.info()","105ccbb5":"data.columns","b0f85463":"data.isna().sum()","01d284fc":"# take a copy of data and remove unnecessary attributes\nemp_data = data.copy(deep= True)\nemp_data.drop(columns= ['Unnamed: 0'], inplace = True)\nemp_data.head()","7d03c7bc":"emp_data.columns","406f9cf5":"emp_data['Job Title'].unique()","8a1610ac":"\n# job title cleaning\n\ndef jobtitle_cleaner(title):\n    if 'data scientist' in title.lower():\n        return 'D-sci'\n    elif 'data engineer' in title.lower():\n        return 'D-eng'\n    elif 'analyst' in title.lower():\n        return 'analyst'\n    elif 'machine learning' in title.lower():\n        return 'ML'\n    elif 'manager' in title.lower():\n        return 'manager'\n    elif 'director' in title.lower():\n        return 'director'\n    elif 'research' in title.lower():\n        return 'R&D'\n    else:\n        return 'na'","94880634":"emp_data['JobTitles'] = emp_data['Job Title'].apply(jobtitle_cleaner)","71ab5a41":"emp_data['Job Title'].unique()","44f24e6b":"emp_data['JobTitles'].unique()","c83fa0c6":"\nemp_data['JobTitles'].value_counts()","23661239":"senior_list = ['sr','sr.','senior','principal', 'research', 'lead', 'R&D','II', 'III']\njunior_list = ['jr','jr.','junior']\n\n\ndef jobseniority(title):\n    for i in senior_list:\n        if i in title.lower():\n            return 'Senior Prof'\n            \n    for j in junior_list:\n        if j in title.lower():\n            return 'Junior Prof'\n        else:\n            return 'No Desc'","74299b27":"\nemp_data['Job Seniority'] = emp_data['Job Title'].apply(jobseniority)","586b5509":"\nemp_data['Job Seniority'].unique()","a1d623b3":"emp_data['Job Seniority'].value_counts()","6bb1f5b7":"# job descriptions\njobs_list = ['python', 'excel','r studio', 'spark','aws']\n\nfor i in jobs_list:\n    emp_data[i+'_'+'job'] = emp_data['Job Description'].apply(lambda x : 1 if i in x.lower() else 0)\n","ecc08b43":"\nfor i in jobs_list:\n    print(emp_data[i+'_'+'job'].value_counts())","0befd3d0":"emp_data['Company Name'].unique()","8f3cba31":"emp_data['Company Name'][0].split('\\n')[0]","ad0a9cd1":"# remove numbers from company name\nemp_data['Company Name'] = emp_data['Company Name'].apply(lambda x : x.split(\"\\n\")[0])\nemp_data['Company Name'].value_counts()","1a6bb5c2":"emp_data['Headquarters'].unique()","250b9eed":"\nemp_data['Hquarters'] = emp_data['Headquarters'].str.split(',').str[1]\nemp_data['Hquarters'].value_counts().head()","c60a300e":"emp_data['Location'].unique()","e1773bc6":"\nemp_data['loaction spots'] = emp_data['Location'].str.split(',').str[1]\nemp_data['loaction spots'].value_counts().head()","4a28ba3e":"emp_data['Competitors'].unique()","be8a9b75":"emp_data['compitator company'] = emp_data['Competitors'].str.split(',').str[0].replace('-1', 'no compitator')","de6e9841":"\nemp_data['compitator company'].value_counts()","a6fb2f16":"emp_data['Type of ownership'].unique()","5d401b45":"\nemp_data['Ownership'] = emp_data['Type of ownership'].str.split('-').str[1].replace(np.NaN, 'others')\nemp_data['Ownership'].value_counts()","7b9e8e25":"emp_data['Revenue'].unique()","058556d2":"emp_data['Revenue'] = emp_data['Revenue'].str.replace('-1','others')","5d0ef60a":"emp_data['Revenue'].value_counts()","6f6ce4fd":"emp_data['Size'].unique()","e86799a3":"emp_data['Size'] = emp_data['Size'].str.replace('-1','others')\nemp_data['Size'].value_counts()","f1bd0fb6":"emp_data[\"Salary Estimate\"].unique()","f9cd84ec":"\nemp_data['min_sal'] = emp_data['Salary Estimate'].str.split(\",\").str[0].str.replace('(Glassdoor est.)','')","e4586837":"emp_data['min_sal'] = emp_data['min_sal'].str.replace('(Glassdoor est.)','').str.split('-').str[0].str.replace('$','').str.replace('K','')","bc7c2b16":"emp_data['min_sal'].unique()","e2f01de7":"emp_data['min_sal'] = emp_data['min_sal'].str.replace('Employer Provided Salary:','')\nemp_data['min_sal'].unique()","bd432054":"emp_data['max_sal'] = emp_data['Salary Estimate'].str.split(\",\").str[0].str.replace('(Glassdoor est.)','')\nemp_data['max_sal']","b4b7c71e":"emp_data['max_sal'] = emp_data['max_sal'].str.replace('(Glassdoor est.)','').str.split('-').str[1].str.replace('$','').str.replace('K','')","dffccfc9":"\nemp_data['max_sal'] = emp_data['max_sal'].str.replace('(Employer est.)','')","6a03e672":"emp_data['max_sal'] = emp_data['max_sal'].str.split().str[0].str.replace('(','').str.replace(')','')","8cbf9356":"emp_data['max_sal'].unique()","965062a4":"emp_data['min_sal'] = pd.to_numeric(emp_data['min_sal'], errors='coerce')\ntype(emp_data['min_sal'])","2e135898":"emp_data['min_sal'].isna().sum()","9eb9c2af":"emp_data['min_sal'].hist()\nplt.show()","534b4190":"emp_data['max_sal'].isna().sum()","f250ede0":"\nemp_data['min_sal'] = emp_data['min_sal'].replace(np.nan, emp_data['min_sal'].mean())","8f1c871a":"emp_data['min_sal'].isna().sum()","7ec163aa":"\nemp_data['max_sal'] = pd.to_numeric(emp_data['max_sal'], errors='coerce')\ntype(emp_data['max_sal'])","846248b9":"emp_data['max_sal'].isnull().sum()","26323b3f":"\nemp_data['max_sal'].hist()\nplt.show()","83515570":"\nemp_data['avg.salary'] = (emp_data['min_sal'] + emp_data['max_sal'])\/ 2","62b78e43":"emp_data['avg.salary'].hist()\nplt.show()","210ed729":"\nemp_data.head()","0b655b73":"final_data = emp_data[['Rating',\n       'Company Name', 'Size',\n       'Type of ownership','Sector', 'Revenue',\n       'JobTitles', 'Job Seniority', 'python_job', 'excel_job', 'r studio_job',\n       'spark_job', 'aws_job', 'Hquarters', 'loaction spots',\n       'compitator company', 'Ownership','avg.salary']]\nfinal_data.head()","061778ef":"final_data = pd.get_dummies(data = final_data, columns = ['Company Name', 'Size', 'Type of ownership', 'Sector',\n       'Revenue', 'JobTitles', 'Job Seniority','Hquarters', 'loaction spots',\n       'compitator company', 'Ownership'])","2f1cd3f6":"\nfinal_data.head()","74d1681c":"from sklearn.preprocessing import MinMaxScaler\nms = MinMaxScaler()\nfinal_data[['Rating', 'avg.salary']] = ms.fit_transform(final_data[['Rating', 'avg.salary']])","e8003cf3":"final_data.head()","96655d72":"# split the data into attributes and lable\nX = final_data.drop(columns= 'avg.salary').values\ny = final_data.iloc[:, 6].values","81a1c5d1":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","91b2d844":"# Using GridSearchCV to find the best algorithm for this problem\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\n\ndef find_best_model(X, y):\n    models = {\n        'linear_regression': {\n            'model': LinearRegression(),\n            'parameters': {\n                'n_jobs': [-1]\n            }\n            \n        },\n        \n        'decision_tree': {\n            'model': DecisionTreeRegressor(criterion='mse', random_state= 0),\n            'parameters': {\n                'max_depth': [5,10]\n            }\n        },\n        \n        'random_forest': {\n            'model': RandomForestRegressor(criterion='mse', random_state= 0),\n            'parameters': {\n                'n_estimators': [10,15,20,50,100,200]\n            }\n        },\n        \n        'svm': {\n            'model': SVR(gamma='auto'),\n            'parameters': {\n                'C': [1,10,20],\n                'kernel': ['rbf','linear']\n            }\n        }\n\n    }\n    \n    scores = [] \n    cv_shuffle = ShuffleSplit(n_splits=5, test_size=0.20, random_state=0)\n        \n    for model_name, model_params in models.items():\n        gs = GridSearchCV(model_params['model'], model_params['parameters'], cv = cv_shuffle, return_train_score=False)\n        gs.fit(X, y)\n        scores.append({\n            'model': model_name,\n            'best_parameters': gs.best_params_,\n            'Test score': gs.best_score_\n        })\n        \n    return pd.DataFrame(scores, columns=['model','best_parameters','Test score'])\n\nfind_best_model(X_train, y_train)","a443475b":"# Creating linear regression model\nfrom sklearn.linear_model import LinearRegression\nlr_model = LinearRegression()\n# Fitting the dataset to the model\nlr_model.fit(X_train, y_train)\nprint(\"Accuracy of the Linear Regression Model on Training set is : {}% and on Test set is {}%\".format(round(lr_model.score(X_train, y_train),4)*100, round(lr_model.score(X_test, y_test),4)*100))","089a3946":"# Creating decision tree regression model\nfrom sklearn.tree import DecisionTreeRegressor\ndecision_model = DecisionTreeRegressor(criterion='mse', max_depth=10, random_state=0)\n# Fitting the dataset to the model\ndecision_model.fit(X_train, y_train)\nprint(\"Accuracy of the Decision Tree Regression Model on Training set is : {}% and on Test set is {}%\".format(round(decision_model.score(X_train, y_train),4)*100, round(decision_model.score(X_test, y_test),4)*100))","2b8d126d":"# Creating random forest regression model\nfrom sklearn.ensemble import RandomForestRegressor\nforest_model = RandomForestRegressor(n_estimators=100, criterion='mse', random_state=0)\n# Fitting the dataset to the model\nforest_model.fit(X_train, y_train)\nprint(\"Accuracy of the Random Forest Regression Model on Training set is : {}% and on Test set is {}%\".format(round(forest_model.score(X_train, y_train),4)*100, round(forest_model.score(X_test, y_test),4)*100))","d7e4c18d":"# Creating AdaBoost regression model\nfrom sklearn.ensemble import AdaBoostRegressor\nadb_model = AdaBoostRegressor(base_estimator=decision_model, n_estimators=250, learning_rate=1, random_state=0)\n# Fitting the dataset to the model\nadb_model.fit(X_train, y_train)\nprint(\"Accuracy of the AdaBoost Regression Model on Training set is : {}% and on Test set is {}%\".format(round(adb_model.score(X_train, y_train),4)*100, round(adb_model.score(X_test, y_test),4)*100))","effa7656":"### Getting dummies","82edbee4":"### Head quarters Handling","5fd84177":"### Job Title Handling","564ba988":"### Size Handling","87ae7615":"### Scaling","f4f42a51":"### Type of ownership Handling","98fecf50":"### Data gathering","33ff0098":"### Revenue Handling","e9a9342f":"### Location Handling","bfaff0f2":"### Job Description Handling","b72cabef":"### Company Name Handling","ad1dd660":"### Model selection","8d9276c1":"\n### Data Cleaning\n- inorder to perform any kind of operations first we need to clean the data otherwise model says **garbage in = garbage out**","da25b753":"### train and test","3900376d":"### Compitators Handling","81d65368":"### Salary estimate Handling"}}