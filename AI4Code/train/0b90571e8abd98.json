{"cell_type":{"61a05b36":"code","21397647":"code","955c0444":"code","fba73e8e":"code","e59dc7d7":"code","8b12dc5d":"code","c5ca4391":"code","7fca7b44":"code","ddf33e7e":"code","50497ceb":"code","a294fe96":"code","ecf1554d":"code","27e9f119":"code","12a15a9e":"code","5f46982a":"code","3fe143b6":"code","20dea2f6":"code","e9cdead2":"code","46f1791f":"code","e3ab87bb":"code","1722795c":"code","770854bd":"code","d8f724a5":"code","6bae4337":"markdown","3209efd1":"markdown","a1c8c727":"markdown","85cb7b1e":"markdown","d2942688":"markdown","b243923c":"markdown","24fbe8ea":"markdown","6fc6f0dc":"markdown","85d51cb9":"markdown","0e2c0144":"markdown","584069da":"markdown","98cdc8fb":"markdown","53ae1f46":"markdown","4ed7ff8a":"markdown","46c7f70c":"markdown","3393bacd":"markdown","d4d2e68e":"markdown","8617f87f":"markdown","bd01f2a2":"markdown","4adcd0a6":"markdown","03cce577":"markdown","127eda00":"markdown","4a9fbd63":"markdown","502cb549":"markdown","17d0ad09":"markdown"},"source":{"61a05b36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21397647":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nData_set = pd.read_csv(\"..\/input\/amazon-top-50-bestselling-books-2009-2019\/bestsellers with categories.csv\")","955c0444":"Data_set.head()","fba73e8e":"Data_set.describe()","e59dc7d7":"# sorting by Name \nData_set.sort_values(\"Name\", inplace = True) \n  \n# dropping ALL duplicte values \nData_set.drop_duplicates(subset =\"Name\", \n                     keep = False, inplace = True) ","8b12dc5d":"Data_set.describe()","c5ca4391":"# with regression\nsns.pairplot(Data_set, kind=\"reg\")\nplt.show()","7fca7b44":"y = list(Data_set['User Rating'])\nx = list(Data_set['Reviews'])\n\nplt.xlabel('Number of Reviews') \nplt.ylabel('Ratings') \nplt.title('Full Data Set View') \nplt.grid(True)\n\nplt.scatter(x, y)\nplt.show()","ddf33e7e":"#redoing plot removing books with less than 4 rating or more than 30000 review\n\nRefinedData_set = Data_set[((Data_set['User Rating'] >= 4) & (Data_set['Reviews'] <= 30000))]\ny = list(RefinedData_set['User Rating'])\nx = list(RefinedData_set['Reviews'])\n\nplt.xlabel('Number of Reviews') \nplt.ylabel('Ratings') \nplt.title('Refind Data Set View') \nplt.grid(True) \n\nplt.scatter(x, y)\nplt.show()","50497ceb":"data = RefinedData_set.groupby('User Rating')['Reviews'].mean()\nx = data.index.values\ny = data.values\n\nplt.xlabel('Ratings') \nplt.ylabel('Mean number of Reviews') \nplt.title('Ratings v\/s Average Reviews') \nplt.grid(True) \n\nplt.plot(x, y)\nplt.show()","a294fe96":"y = list(Data_set['Price'])\nx = list(Data_set['Reviews'])\n\nplt.xlabel('Number of Reviews') \nplt.ylabel('Price') \nplt.title('Full Data Set View') \nplt.grid(True)\n\nplt.scatter(x, y)\nplt.show()","ecf1554d":"#redoing plot removing books with Price > 40 or more than 40000 review\n\nRefinedData_set = Data_set[((Data_set['Price'] <= 40) & (Data_set['Reviews'] <= 40000))]\ny = list(RefinedData_set['Price'])\nx = list(RefinedData_set['Reviews'])\n\nplt.xlabel('Number of Reviews') \nplt.ylabel('Price') \nplt.title('Refined Data Set View') \nplt.grid(True) \n\nplt.scatter(x, y)\nplt.show()","27e9f119":"y = list(RefinedData_set['Price'])\n\nstep_count = 2\narray_range = np.arange(0, max(y)+step_count, step_count)\ndata = RefinedData_set.groupby(pd.cut(RefinedData_set['Price'], array_range))['Reviews'].mean()\n\nx = array_range[1:]\ny = data.values\n\nplt.xlabel('Price') \nplt.ylabel('Mean number of Reviews') \nplt.title('Price v\/s Average Reviews') \nplt.grid(True) \n\nplt.plot(x, y)\nplt.show()\n","12a15a9e":"y = list(Data_set['Price'])\nx = list(Data_set['User Rating'])\n\nplt.xlabel('User Rating') \nplt.ylabel('Price') \nplt.title('Full Data Set View') \nplt.grid(True)\n\nplt.scatter(x, y)\nplt.show()","5f46982a":"#redoing plot removing books with books with ratings < 4 and Price > 40\n\nRefinedData_set = Data_set[((Data_set['Price'] <= 40) & (Data_set['User Rating'] >= 4))]\ny = list(RefinedData_set['Price'])\nx = list(RefinedData_set['User Rating'])\n\nplt.xlabel('User Rating') \nplt.ylabel('Price') \nplt.title('Refined Data Set View') \nplt.grid(True) \n\nplt.scatter(x, y)\nplt.show()","3fe143b6":"y = list(RefinedData_set['Price'])\n\nstep_count = 2\narray_range = np.arange(0, max(y)+step_count, step_count)\ndata = RefinedData_set.groupby(pd.cut(RefinedData_set['Price'], array_range))['User Rating'].mean()\n\nx = array_range[1:]\ny = data.values\n\nplt.xlabel('Price') \nplt.ylabel('Mean User Rating') \nplt.title('Price v\/s User Rating') \nplt.grid(True) \n\nplt.plot(x, y)\nplt.show()\n","20dea2f6":"y = list(RefinedData_set['Price'])\nstep_count = 2\narray_range = np.arange(0, max(y)+step_count, step_count)\ndata = RefinedData_set.groupby(pd.cut(RefinedData_set['Price'], array_range))[['User Rating','Reviews']].mean()","e9cdead2":"data","46f1791f":"Revised_data = Data_set.groupby('Name')[['User Rating','Price']].mean()\nRevised_data = Revised_data.sort_values(by = ['User Rating','Price'],ascending = [0,1])\n","e3ab87bb":"Revised_data['Price'] = Revised_data['Price'].replace(0,0.1)","1722795c":"Revised_data['Rating\/Price'] = Revised_data['User Rating']\/Revised_data['Price']\nRevised_data = Revised_data.sort_values(by = ['Rating\/Price'],ascending = [0])\n\nstep_count = 5\narray_range = np.arange(0, max(y)+step_count, step_count)","770854bd":"prev_price = 0\nfor i in array_range:\n    if(i > 0):\n        data = Revised_data[((Revised_data['Price'] > prev_price) & (Revised_data['Price'] <= i))]\n        print (\"\\n\" + str(prev_price) + \" to \" + str(i) + \" : \" )\n        print(data.head(2))\n        prev_price = i","d8f724a5":"# 3D view of data\n#y_z = data.values\n#x_price = y_z[:,1]\n#y_rating = y_z[:,0]\n#z_review = array_range[1:]\n\n# Data for three-dimensional scattered points\n#ax = plt.axes(projection='3d')\n#ax.scatter3D(x_price, y_rating, z_review, c=z_review, cmap='Greens')\n#ax.plot3D(x_price, y_rating, z_review, 'gray')","6bae4337":"# Removing Outliers","3209efd1":"To remove outliers will remove books with ratings < 4 and Price > 40","a1c8c727":"From all the above attempt we see that even summarizing the data didnt help bring in any apparent correlation between these parameters","85cb7b1e":"No apparent correlation appears between variables. We will now need to remove outliers and try to see if correlation exist in summarized data.","d2942688":"**View summary of the data**","b243923c":"Turns out books with less than 4 ratings are hardly reviewed.\nThere are very few books with more than 30000 review","24fbe8ea":"Count has dropped from 550 to 255 showing that there were close to 50% of republished books","6fc6f0dc":"# Impact of Ratings on Number of Reviews","85d51cb9":"To remove outliers will remove books with Reviews > 40000 and Price > 40","0e2c0144":"# Plotting to see the mean of number of reviews at different ratings ","584069da":"# **Removing Outliers**","98cdc8fb":"# Impact of Price on Ratings","53ae1f46":"# Find the best Books to read in different price ranges \n\nlike from 0 to 5 USD, 5 to 10 USD based on Ranking and Price","4ed7ff8a":"Replace all 0 priced books with 0.1","46c7f70c":"# Mean of Reviews Grouping By Price Range\nTrying to group by price range and then taking mean of number of Reviews","3393bacd":"# Validating the range for highest ratings","d4d2e68e":"# Ranking Books Based on Rating and Price. Which Book have the cheapest books at Highest Rating","8617f87f":"It is clear that 28 to 30 is the range for highest ratings","bd01f2a2":"# Dropping duplicate books that have been republished over the years","4adcd0a6":"# Impact of Price on Number of Reviews","03cce577":"# Using Pairplot to see if there are any obvious correlation between variables","127eda00":"**Checking to see if there is any correlation between number of reviews and ratings**","4a9fbd63":"Clearly books in the 28 to 30 USD bracket have highest ratings","502cb549":"# Removing Outliers","17d0ad09":"**Loading the Data**"}}