{"cell_type":{"7a91e08d":"code","fb019805":"code","265c0796":"code","d7318c12":"code","03651fe3":"code","bc5bdcca":"code","e5043b47":"code","1b6645c0":"code","ad57018c":"code","02c8b848":"code","0dafad27":"code","eaf3218d":"code","16f2f402":"code","ba2bfe5a":"code","2fe08e12":"code","52a6cb2e":"code","1e6bf452":"code","54ec0c1a":"code","28614e14":"code","919fd0fe":"code","d691e6f2":"code","47186340":"markdown","8ce75ce7":"markdown","75e7275f":"markdown","b1b53147":"markdown","394328c9":"markdown","f08a40e6":"markdown","cf6aa3ad":"markdown","2e831781":"markdown","a3f8d672":"markdown","65150688":"markdown","85040a14":"markdown","34dc1f23":"markdown","05012b75":"markdown","c84b6038":"markdown","000c8b8a":"markdown","dde5ca9b":"markdown","f3914aeb":"markdown","d2e62c97":"markdown"},"source":{"7a91e08d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb019805":"!pip install -U lightautoml","265c0796":"import logging\nimport time\nimport requests\nlogging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task","d7318c12":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 17 # fixed random to keep repeatability\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 600 # Time in seconds for automl run\nTARGET_NAME = 'final_price' # Target column name","03651fe3":"train = pd.read_csv('..\/input\/ods-hw-datasets\/train_data.csv')\nX, y = train_test_split(train, test_size=TEST_SIZE, random_state=RANDOM_STATE)\nprint (len(X), \"\/\", len(y))","bc5bdcca":"task = Task('reg', loss='mae', metric='mae')\nroles = {'target': TARGET_NAME, 'drop': ['row_ID']}","e5043b47":"%%time \nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                      )\noof_pred = automl.fit_predict(X, roles = roles)\n","1b6645c0":"fast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)","ad57018c":"test_pred = automl.predict(y)\nprint('OOF score: ', \"%.0f\" % mean_absolute_error(y[TARGET_NAME].values, test_pred.data[:, 0]))\n","02c8b848":"realtest = pd.read_csv('..\/input\/ods-hw-datasets\/test_data.csv')\nsubmission = pd.read_csv('..\/input\/ods-hw-datasets\/sample_submission.csv')\n\nreal_pred_1 = automl.predict(realtest)\nsubmission[TARGET_NAME] = real_pred_1.data[:, 0]\nsubmission.to_csv('pred_raw_baseline.csv', index = False)","0dafad27":"pd.set_option('display.max_rows', None) \ntrain.head()","eaf3218d":"def clean_gearbox (df):\n    f = df.copy()\n    f['cleaned_gearbox'] = f['vehicle_gearbox_type']\n    return f.replace({'cleaned_gearbox' : { 'Tiptronic' : 'Automatic', 'Variator' : 'Automatic'}})","16f2f402":"def clean_mileage (df):\n    f = df.copy()\n    f['cleaned_mileage'] = f['current_mileage']\n    f['cleaned_mileage'] = round((f['current_mileage'] \/ 5000)).astype(int) * 5000\n    return f","ba2bfe5a":"#Uncomment to see the list\n#train.groupby(by = ['vehicle_manufacturer','vehicle_model']).size()","2fe08e12":"def clean_model (df):\n    a = df.copy()\n    #Creating list of models for two first words\n    model_list = ['TOYOTA', 'MAZDA', 'MINI', 'MERCEDES-BENZ', 'TESLA', 'LEXUS']\n    #Keep 1 word for models which are NOT in the list (the \"~\" sign)\n    a.loc[~a['vehicle_manufacturer'].isin(model_list), 'cleaned_model'] = a['vehicle_model'].str.split().str[0]\n    #Keep 2 words for models in the list\n    term = a['vehicle_manufacturer'].isin(model_list)\n    a.loc[term == 1, 'cleaned_model'] = a['vehicle_model'].str.split().str[:2].str.join(' ')\n    return a","52a6cb2e":"train_mod = clean_gearbox(train)\ntrain_mod = clean_mileage(train_mod)\ntrain_mod = clean_model(train_mod)\nX1, y1 = train_test_split(train_mod, test_size=TEST_SIZE, random_state=RANDOM_STATE)\nprint (len(X1), \"\/\", len(y1))\nX1.head()","1e6bf452":"task = Task('reg', loss='mae', metric='mae')\nroles = {'target': TARGET_NAME, 'drop': ['row_ID']}","54ec0c1a":"%%time \nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                      )\noof_pred = automl.fit_predict(X1, roles = roles)","28614e14":"fast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)","919fd0fe":"test_pred1 = automl.predict(y1)\nprint('OOF score: ', \"%.0f\" % mean_absolute_error(y[TARGET_NAME].values, test_pred1.data[:, 0]))","d691e6f2":"test_mod = clean_gearbox(realtest)\ntest_mod = clean_mileage(test_mod)\ntest_mod = clean_model(test_mod)\nreal_pred2 = automl.predict(test_mod)\nsubmission2 = pd.read_csv('..\/input\/ods-hw-datasets\/sample_submission.csv')\nsubmission2[TARGET_NAME] = real_pred2.data[:, 0]\nsubmission2.to_csv('pred_modified.csv', index = False)\n","47186340":"And now the most dirty - ```vehicle_model```","8ce75ce7":"Loading train data and split it for train & test sets as 80\/20","75e7275f":"Next is ```current_mileage\t```","b1b53147":"My idea with features is the following:\n\n```_manufacturer```: OK<br>\n```_model```: very bad, will return to this later<br>\n```_category```: OK<br>\n```_milliage```: I want to round it up to 5.000<br>\n```_year```: OK<br>\n```_gearbox_type```: I'm going to merge all automatic gearboxes and leave just two categories: \"Mechanical\" and \"Automatic\". Usually potential buyers are choosing by this way<br>\n```_doors_cnt```: I have some doubts but let's leave it as is for now<br>\n```_wheels```: OK<br>\n```_color```: OK<br>\n```_interior_color```: OK<br>\n```_vin```: I have some ideas, but first let's try just to drop it (not to use in the model)<br>\n```_leather_interior```: OK<br>\n```_deal_type```: OK<br>\n\nLightAutoML developpers suggest not to replace existing features, but to add new ones and I will do like this<br>\nFinally I decided to add 3 new features that's mean I have to create 3 fuctions.<br> \nI start from the end of list: ```vehicle_gearbox_type```","394328c9":"I ","f08a40e6":"Create AutoML from preset","cf6aa3ad":"Create Task and setup columns roles","2e831781":"When I have submitted both files I got:<br>\n***1872*** scores for the raw baseline<br>\n***2061*** scores for modified basline<br>\n<br>\nSo my approach to feature modification was wrong...<br>\nSeems to me I have to improve my skills a lot\n","a3f8d672":"Let's apply these functions to ```train``` and then split it again for X & y","65150688":"No, it didn't help at least on our test (20% from train) - I got 2109 instead of 1894 I had.<br>\nBTW lets apply my functions to the ```test``` and generate new predictions","85040a14":"In this kernel I'm going to get some experience with LightAutoML framework and check my skills with feature engineering\n\nMy plan is the following:\n- to run LightAutoML simple baseline at raw data with default parameters\n- to play with features\n- to check does it improve simple baseline results ot not ?\n- to submit both results and compare\n","34dc1f23":"Now we repeat previous steps to get new predictions with new features","05012b75":"I'm going to use very naive rule:\n- to keep only **two first** words in ```vehicle_model``` for: LEXUS, MAZDA, MERCEDES-BENZ, MINI, TESLA and TOYOTA\n- to keep jut **first** word in ```vehicle_model``` for all the rest manufacturers\n\nI could lose some useful information with this, but I wish to drop all the mess in models list. We'll see later will it works...","c84b6038":"Than importing LAMA libraries","000c8b8a":"and set default parameters","dde5ca9b":"Let's have a look what do we have:","f3914aeb":"As we can see LightAutoML likes new features more than raw ones except the ```vehicle_gearbox_type```<br>\nDoes it really help ?","d2e62c97":"So we got score **1894** with the baseline 'from the box'. Let's keep it in mind and try to do something with features.\nI will use common sense (as much as I understand it :) ) and will try get some new features to get the more realistic attributes (for the \"real\" potential buyer)  and categorize those features in the most clear way.\n\nHopefully LightAutoML will appreciate my approach )\n\nP.S. In order to compare two real submissions later let's make a real test and export the csv with gotten prediction:"}}