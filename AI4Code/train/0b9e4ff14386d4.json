{"cell_type":{"842d11e5":"code","b6bc0ef5":"code","b16b435f":"code","ac952d23":"code","bab6951e":"code","02f45147":"code","1fa27011":"code","920b8de0":"code","54233671":"code","71415133":"code","9e91e3c9":"code","b43d1c27":"code","5bb298b6":"code","7092f67f":"code","75069acd":"code","3fac4cf3":"code","b59bc5fc":"markdown","16a92e91":"markdown","a3ebbc8b":"markdown","e711293d":"markdown","cce0604d":"markdown","493aabfd":"markdown","8a32568a":"markdown","e26adf3c":"markdown","8f99a845":"markdown","3ac88996":"markdown","e9845a79":"markdown","9a896478":"markdown","53a9ff8a":"markdown","6db06ec2":"markdown","a302534f":"markdown","80818d74":"markdown","da3aa909":"markdown","f0bb91a9":"markdown","d0f29c0d":"markdown","d03e9e71":"markdown","a6b440f4":"markdown","f5e34825":"markdown","55c83ac6":"markdown","a8c1f033":"markdown"},"source":{"842d11e5":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import utils\nfrom sklearn.metrics import classification_report\n\nimport os, PIL\nfrom glob import glob\n\nimport tensorflow as tf\n\nprint(tf.__version__)","b6bc0ef5":"\"\"\" Sequential Model Architecture \"\"\"\nSequential = tf.keras.models.Sequential\n\n\"\"\" Data Preprocessing Functions \"\"\"\nResizing = tf.keras.layers.experimental.preprocessing.Resizing\nRescaling = tf.keras.layers.experimental.preprocessing.Rescaling\n\n\"\"\" Data Augmentation Functions \"\"\"\nRandomFlip = tf.keras.layers.experimental.preprocessing.RandomFlip\nRandomRotation = tf.keras.layers.experimental.preprocessing.RandomRotation\nRandomZoom = tf.keras.layers.experimental.preprocessing.RandomZoom\n\n\"\"\" Artificial Neural Network Layer Inventory \"\"\"\nDense = tf.keras.layers.Dense\nDropout = tf.keras.layers.Dropout\n\n\"\"\" Convolutional Neural Network Layer Inventory \"\"\"\nConv2D = tf.keras.layers.Conv2D\nMaxPool2D = tf.keras.layers.MaxPool2D\nFlatten = tf.keras.layers.Flatten\n\n\"\"\" Residual Network Layer Inventory \"\"\"\nResNet50 = tf.keras.applications.resnet50.ResNet50\n\n\"\"\" Function to Load Images from Target Folder \"\"\"\nimage_dataset_from_directory = tf.keras.preprocessing.image_dataset_from_directory","b16b435f":"DATA_DIRECTORY = \"..\/input\/video-game-covers\/dataset\"\nFIGHTING_GENRE_COVERS = f\"{DATA_DIRECTORY}\/fighting\/*\"\nINDIE_GENRE_COVERS = f\"{DATA_DIRECTORY}\/indie\/*\"\nPLATFORM_GENRE_COVERS = f\"{DATA_DIRECTORY}\/platform\/*\"\nPUZZLE_GENRE_COVERS = f\"{DATA_DIRECTORY}\/puzzle\/*\"\nSPORT_GENRE_COVERS = f\"{DATA_DIRECTORY}\/indie\/*\"\n\nprint(f\"{len(glob(FIGHTING_GENRE_COVERS))} Fighting Game Covers\")\nprint(f\"{len(glob(INDIE_GENRE_COVERS))} Indie Game Covers\")\nprint(f\"{len(glob(PLATFORM_GENRE_COVERS))} Platform Game Covers\")\nprint(f\"{len(glob(PUZZLE_GENRE_COVERS))} Puzzle Game Covers\")\nprint(f\"{len(glob(SPORT_GENRE_COVERS))} Sport Game Covers\")","ac952d23":"batch_size = 32\nIMAGE_WIDTH = 224\nIMAGE_HEIGHT = 224","bab6951e":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\ntrain = image_dataset_from_directory(\n    directory=DATA_DIRECTORY,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=batch_size\n)\n\nvalidation = image_dataset_from_directory(\n    directory=DATA_DIRECTORY,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=batch_size\n)\n\nclass_names = train.class_names\nprint(class_names)","02f45147":"plt.figure(figsize=(10, 10))\nfor images, labels in train.take(1):\n  for i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","1fa27011":"train = train.cache().shuffle(4000).prefetch(buffer_size=tf.data.AUTOTUNE)\nvalidation = validation.cache().prefetch(buffer_size=tf.data.AUTOTUNE)","920b8de0":"input_tensor = tf.keras.Input(shape=(224,224,3))\nweights = \"..\/input\/resnet50weights\/imagenet.h5\"\nresnet_model = ResNet50(include_top=False, weights=weights, input_tensor=input_tensor)","54233671":"for layer in resnet_model.layers[:143]:\n    layer.trainable = False\n\nfor i, layer in enumerate(resnet_model.layers):\n    print(i, layer.name, \"Trainable: \", layer.trainable)","71415133":"resizing_layer = Resizing(IMAGE_HEIGHT, IMAGE_WIDTH)\nnormalization_layer = tf.keras.layers.BatchNormalization()\n\ninput_layer = tf.keras.layers.InputLayer(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\nflip_layer = RandomFlip(mode=\"horizontal_and_vertical\")\nrotation_layer = RandomRotation(factor=0.2, fill_mode=\"nearest\")\nzoom_layer = RandomZoom(height_factor=0.2, width_factor=0.3, fill_mode=\"nearest\")\n\naugmentation_layer = Sequential([flip_layer, rotation_layer, zoom_layer])\n\nflatten_layer = Flatten()\n\ndropout_layer = Dropout(0.3)\n\ndense_layer_1 = Dense(256, activation=\"relu\")\ndense_layer_2 = Dense(128, activation=\"relu\")\ndense_layer_3 = Dense(64, activation=\"relu\")\noutput_layer = Dense(5, activation=\"softmax\")","9e91e3c9":"model = Sequential()\n\nmodel.add(input_layer)\nmodel.add(augmentation_layer)\nmodel.add(resizing_layer)\nmodel.add(resnet_model)\nmodel.add(flatten_layer)\nmodel.add(normalization_layer)\nmodel.add(dense_layer_1)\nmodel.add(dropout_layer)\nmodel.add(dense_layer_2)\nmodel.add(dropout_layer)\nmodel.add(dense_layer_3)\nmodel.add(dropout_layer)\nmodel.add(output_layer)\n\nmodel.summary()","b43d1c27":"model.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=\"adam\",\n              metrics=[\"accuracy\"])","5bb298b6":"history = model.fit(train, validation_data=validation, epochs=5)","7092f67f":"model.evaluate(validation)","75069acd":"plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Test Accuracy\")\nplt.legend()\nplt.show()","3fac4cf3":"plt.plot(history.history[\"loss\"], label=\"Train Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Test Loss\")\nplt.legend()\nplt.show()","b59bc5fc":"Here is where I imported my data.  As you might have guessed, there wasn't much of an existing source I could use to get the image data I needed for this specific task.  This meant that I needed to collect, organize, and clean the data myself for this project.  Luckily, I was able to find an excellent database for video games that I used to pull my images from.  I used their api and wrote a script to collect the images I wanted and save them for use in this project.  It was here that I identified one of the inevitable roadblocks that as you'll see, hindered my results.\n\nGames are complex works of art, and more often than not, they tend to involve varying types of gameplay experiences.  Relatively few games have only one genre.  Most games are a combination of them, such as platforming and adventure games, or indie and puzzle games.  I'll touch on this more towards the end of the project, but for now let's just focus on getting data to work on.  To keep things manageable, I narrowed down my genres to the 5 categories that I believe to be most distinctive: Fighting, Indie, Platform, Puzzle, and Sport.  If you're interested to see more about how I obtained my data, you can check out my github repo here: [Video Game Genre Prediction Github](https:\/\/github.com\/Kou-kun42\/Video-Game_Genre-Prediction)","16a92e91":"## Image Data Aggregation <a id=2><\/a>","a3ebbc8b":"We can now fit our training data!  To keep things timely, I decided to keep epochs short at 5.  I believe a longer runtime will result in better accuracy, but this is adequate to allow us to reflect and understand our progress.","e711293d":"As we are using a precalibrated network, we don't want to change most of the values that it has when we start fitting our model.  To do this, I've set the trainable property to false for all but the last slice of layers.","cce0604d":"## Results <a id=5><\/a>","493aabfd":"In this project, I attempt to create a classification deep learning model to predict the genre of a video game based off its cover artwork.  I've detailed all the steps I worked through to achieve my final results, and I'll provide my insight and thoughts on each point along the process.  The goal of this project is to gain a better understanding of neural network development by creating a convolutional neural network that ingests multiclass image data and predicts class properties.\n\nI chose this topic as I just have a general curiousity and interest towards gaming, and I thought it would be fun to bring a light hearted topic and try to apply advanced techniques that could pick up on certain patterns when it comes to marketing and user acquisition.\n\nLet's get started!\n\n* [Initialization](#1)\n* [Image Data Aggregation](#2)\n* [Transfer Learning](#3)\n* [Model Creation](#4)\n* [Results](#5)\n* [Conclusion](#6)","8a32568a":"Here's a run where I was able to get slightly better results:\n\n\n![Fit Results](https:\/\/github.com\/Kou-kun42\/Video-Game_Genre-Prediction\/blob\/main\/model\/Fit%20Results.png?raw=true)\n\n\n![Accuracy Plots](https:\/\/github.com\/Kou-kun42\/Video-Game_Genre-Prediction\/blob\/main\/model\/Accuracy%20Plots.png?raw=true)","e26adf3c":"We can now compile our model with the respective properties.  Since the class values are integerized, we can use sparse categorical crossentropy for loss.  I found the results turned out best with adam as the optimizer.","8f99a845":"## Conclusion <a id=6><\/a>\n\nAs you can tell, the results aren't great.  Looking at the plots, it looks like the accuracy is trending upwards, so it might be possible to get slightly better results with a longer runtime.  It wouldn't create a drastic difference however, and our results are enough to pause and evaluate our progress.  There's many reasons I can think of that contribute to the low accuracy, but the most prevalent issue comes back to where we started with gathering our image data.  As most of the games I used consist of multiple genres, it doesn't really make much sense to try and predict a single one just based off cover art.\n\nOne thing I can definitely do to improve this data is to pick games that only have a single genre.  Strictly speaking, this would probably help our accuracy, but it doesn't really mean much in regards to what I set off to accomplish.  Having a very specific set of data means our model would only work well with that specific type of data.\n\nI think if I really wanted to build off of this, I should choose a different task entirely.  Instead of a classification model, I think a multi-trait prediction approach would be more suited.  This way, we can account for the multiple genres games have, and have a model that predicts multiple likelihoods of genres that correspond with cover artworks.\n\n\nI hope you enjoyed my exploration of neural network modeling and thanks for reading!","3ac88996":"I've plotted the accuracies of our results below.","e9845a79":"This is where I ingest the images and split them to create training and testing sets to fit my model and validate the results.  I'm using a 20% test split, which results in 4000 images for train and 1000 images for validation.","9a896478":"I started by providing the input layer which takes in the image data provided.  Then I utilized several augmentations to provide more variance to the images.  Next is a resizing layer to make the inconsistencies from the augmentations uniform again.  I'm then applying the ResNet50 model.  After that, I've provided a flattening layer followed by a batch normalization layer to rescale the pixel colorization.  Lastly, I've added 3 dense layers and 3 dropout layers, followed by the final output layer of the model.  The dropout layers will help avoid overfitting the data.","53a9ff8a":"In order to improve performance and optimize data ingestion we can cache the image sets.","6db06ec2":"We can run a validation test to confirm our results.","a302534f":"Here's a quick sample of some of the training images after they've been resized.","80818d74":"## Transfer Learning Incorporation <a id=3><\/a>","da3aa909":"# Video Game Genre Prediction \ud83c\udfae","f0bb91a9":"My approach to this problem was to incorporate transfer learning as a basis for my model.  ResNet50 is a pretrained CNN that has precalibrated weights from more than a million images in the imagenet database.  This allows us to start our model off with a powerful network that we can then build from by incorporating more layers trained specifically to our data.","d0f29c0d":"Here is where we can finally start building the model.  I went through numerous iterations of this process before finally landing at the result below.  You can refer to my github that I linked earlier to see more of my designing process.","d03e9e71":"Here I'm resizing the images and setting the batch size to work well with what ResNet50 will expect when I add it later.","a6b440f4":"## Model Creation <a id=4><\/a>","f5e34825":"I simply began by importing the relevant modules and then creating variable names for the processing layers that we'll use later to create the model.","55c83ac6":"## Imports and Initializations <a id=1><\/a>","a8c1f033":"Before we proceed with the model creation, I'll mention why I chose to use a Convolutional Neural Network approach instead of utilizing machine learning algorithms like K-Nearest Neighbors or Naive Bayes.  While these algorithms are incredibly efficient at tasks like feature prediction or text classification, the image classification task I am performing would not bode well with them due to the way image data is structured.  CNNs are far more efficient and make more sense to use due to their strong ability to classify images."}}