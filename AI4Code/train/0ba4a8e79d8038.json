{"cell_type":{"593b0adb":"code","1fa92def":"code","2cbd0699":"code","d31ea74d":"code","2ca0ad46":"code","c6dbd2d4":"code","78a9d7a6":"code","dd29d0fc":"code","4390e706":"code","13ddab70":"code","8b9649c7":"code","92e02282":"code","07e4fc01":"code","d393f516":"code","bcc9e280":"code","4af8b81c":"code","507ae124":"code","a1e6d2bc":"code","bb797d5a":"code","d9935939":"code","e93214f5":"code","244b91e7":"code","2abcceb3":"code","03d64163":"code","ba12e2f3":"code","165eb34a":"code","cdb5b934":"code","efaa8998":"code","a13644fd":"code","6da214e6":"code","bfc53968":"code","a25e925a":"code","7973c597":"code","c9166efe":"code","6dbc002c":"code","d4aebcd4":"code","95cd0900":"code","ea860487":"code","e633b888":"markdown","290f5e64":"markdown","5f51fda7":"markdown","715332cd":"markdown","02c4db8d":"markdown","443502e6":"markdown","b3eab649":"markdown","4a19dc33":"markdown","ca5b1c86":"markdown","d80fd656":"markdown","bfed541f":"markdown","e4a6d8fb":"markdown","9a46bfa2":"markdown","8271a8d5":"markdown","fe6ef9a5":"markdown","edb0f03b":"markdown","42eb5436":"markdown","eb26d66a":"markdown","63c4ab1f":"markdown","295f5cad":"markdown","a2a90963":"markdown","acff7df1":"markdown","fb2eec89":"markdown"},"source":{"593b0adb":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport re\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","1fa92def":"# Genenrate training set and testing set\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n#train = pd.read_csv('\/Users\/machen\/Downloads\/titanic data\/train.csv')\n#test = pd.read_csv('\/Users\/machen\/Downloads\/titanic data\/test.csv')\nfull = train.append( test , ignore_index = True )","2cbd0699":"train.head()","d31ea74d":"full.describe()","2ca0ad46":"# Pivot pclass and survival rate\ntrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","c6dbd2d4":"# Pivot sex and survival rate\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","78a9d7a6":"# Pivot sibling number and survival rate\nsibsp_sur = train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='SibSp', ascending=False)\nsibsp_sur.plot(x='SibSp', y='Survived')","dd29d0fc":"# Pivot parch number and survival rate\nparch_sur = train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Parch', ascending=False)\nparch_sur.plot(x='Parch', y = 'Survived')","4390e706":"## Pivot embark port and survival rate\ntrain[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Embarked', ascending=False)","13ddab70":"# slicing data by embark and sex, people boarding from port C have higher survival, regardless of the sex. \ntrain[[\"Embarked\", \"Survived\",'Sex']].groupby(['Embarked','Sex'], as_index=False).mean().sort_values(by='Embarked', ascending=False)","8b9649c7":"# slicing data by embark and class. Higher percentage of passengers are at class 1.\ntrain[[\"Embarked\", \"Survived\",'Pclass']].groupby(['Embarked','Pclass'], as_index=False).count().sort_values(by='Embarked', ascending=False)","92e02282":"# slicing data by embark and sex, people boarding from port C have higher survival, regardless of the sex. \ntrain[[\"Embarked\", \"Survived\",'Pclass']].groupby(['Embarked','Pclass'], as_index=False).mean().sort_values(by='Embarked', ascending=False)","07e4fc01":"## plot histgram of age for each segment of embark data\n## passengers embarking at port C have higher percentage of infants and elderly people, resulting in higher survival rate.\nfig, (axis1,axis2, axis3) = plt.subplots(1,3,figsize=(15,4))\naxis1.set_title('Age hist - embark S')\naxis2.set_title('Age hist - embark Q')\naxis3.set_title('Age hist - embark C')\n\ntrain[train['Embarked']=='S']['Age'].hist(bins=70, ax=axis1)\ntrain[train['Embarked']=='Q']['Age'].hist(bins=70, ax=axis2)\ntrain[train['Embarked']=='C']['Age'].hist(bins=70, ax=axis3)","d393f516":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\. ', name)\n    if title_search:\n        return title_search.group(1)\n    return \"\"","bcc9e280":"full['title'] = full['Name'].apply(get_title)\nfull['title'].value_counts()","4af8b81c":"full['title'] = full['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Rare')\nfull['title'] = full['title'].replace('Mlle','Miss')\nfull['title'] = full['title'].replace('Ms','Miss')\nfull['title'] = full['title'].replace('Mme','Mrs')\nfull['title'].value_counts()","507ae124":"# average survived passengers by age, sliced by Sex\nfig, (axis1,axis2) = plt.subplots(2,1,figsize=(30,16))\naverage_age = train[['Sex',\"Age\", \"Survived\"]].groupby(['Sex','Age'],as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=average_age[average_age['Sex']=='female'],ax = axis1)\nsns.barplot(x='Age', y='Survived', data=average_age[average_age['Sex']=='male'],ax = axis2)","a1e6d2bc":"full['Age'].hist(bins = 60)","bb797d5a":"#full['Fare'].hist(bins = 60)\nfull[full['Fare']<100]['Fare'].hist(bins = 20)","d9935939":"full.isnull().sum()","e93214f5":"# Fill missing values of Age with the average of Age (median)\nfull[ 'Age' ] = full.Age.fillna( full.Age.median() )\n\n# Fill missing values of Fare with the average of Fare (median)\nfull[ 'Fare' ] = full.Fare.fillna( full.Fare.median() )","244b91e7":"full.set_value((full['Fare']<40) , 'fare_category','40-')\nfull.set_value((full['Fare']>40) & (full['Fare']<=100), 'fare_category','40-100')\nfull.set_value((full['Fare']>100) & (full['Fare']<=200), 'fare_category','200-300')\nfull.set_value((full['Fare']>200) , 'fare_category','300+')\nfull.head()","2abcceb3":"full.set_value(full['Age']<=12, 'age_category','childrean')\nfull.set_value((full['Age']>12) & (full['Age']<60), 'age_category','adult')\nfull.set_value(full['Age']>=60, 'age_category','elderly')\nfull.head()","03d64163":"# Transform Sex into binary values 0 and 1\nsex = pd.Series(np.where( full.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\nsex.head()","ba12e2f3":"# Create a new variable for every unique value of Pclass\npclass = pd.get_dummies( full.Pclass , prefix='Pclass' )\npclass.head()","165eb34a":"# Create a new variable to represent whether one passenger has siblings or parches\nfull['family']= full[ 'Parch' ] + full[ 'SibSp' ] +1 #including the passenger self\nfamily = pd.get_dummies(full['family'], prefix='Family Size')\nfamily.head()","cdb5b934":"# Createa a new variable for every age category\nage = pd.get_dummies(full['age_category'], prefix = 'Age')\nage.head()","efaa8998":"# Create a new variable for every fare category\nfare = pd.get_dummies(full['fare_category'],prefix = 'Fare')\nfare.head()","a13644fd":"# Select which features\/variables to include in the dataset:\n# pclass , sex , family , fare, Age, \n\nfull_X = pd.concat( [ pclass , sex , family , age, fare ] , axis=1 )\nfull_X.head()","6da214e6":"# Create all datasets that are necessary to train, validate and test models\nX_train = full_X[ 0:891 ]\nY_train = train.Survived\nX_test = full_X[ 891: ]\nX_train.shape, Y_train.shape, X_test.shape","bfc53968":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","a25e925a":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","7973c597":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","c9166efe":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","6dbc002c":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","d4aebcd4":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', \n              'Support Vector Machines',\n              'Stochastic Gradient Decent',\n              'Decision Tree',\n              'Random Forest'],\n    'Score': [acc_log, acc_svc, acc_sgd, acc_decision_tree, acc_random_forest\n              ]})\nmodels.sort_values(by='Score', ascending=False)","95cd0900":"## feature importance in random forest model\ncolnames = X_train.columns\nimportance_dic = dict(zip(colnames,random_forest.feature_importances_))\nimportance_dic","ea860487":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","e633b888":"# 4. Transforming Data","290f5e64":"# 3. Exploratory Data Analysis","5f51fda7":"## 3.1 Import Libraries","715332cd":"### Obeservations\n1. Age \n\nFrom below segmented survival rate vs. age by Sex plots, we can see female gender does not should strong relationship between age and survival rate. While male group show high survival rate for children and elderly people. So we decide to cut age into three bins: infants\/childrean(age<=12), adult(12<age<80), elderly(age>=60)","02c4db8d":"## 5.2 Model Selection","443502e6":"## 3.2 Acquire Data","b3eab649":"2. Fare\n\nThere is clearly increase in survival rate as fare goes up. Hence we decide to cut fare into three bins.","4a19dc33":"# 5. Modeling","ca5b1c86":"## 3.4 Explore the relationship between numerical variables and survival","d80fd656":"## 3.3 Pivoting Categorical Data","bfed541f":"### Embarking\nPeople **embarking at port C** have higher survival rate, which raises our attention why this is happening.\n\nSo we slice the data with factors we find related to survival: Sex, Pclass, Age, and find that the reason that port C has higher survival rate is that higher percentage of passengers are at class 1.","e4a6d8fb":"## 5.1 Running Models","9a46bfa2":"## 4.3 Transforming Categorical Data into Numerical Data","8271a8d5":"### Name\nWe use regular expression to extract title from names.","fe6ef9a5":"## 4.1 Deal with Missing Values\n\nCheck how many null values each feature has.","edb0f03b":"# 1. Objective\nThis book is to analyze the Titanic dataset on Kaggle(https:\/\/www.kaggle.com\/c\/titanic), and predict survival of test dataset. Based on the analysis, obervations on people who are more likely to survive are proposed.","42eb5436":"View distribution of numerical data.","eb26d66a":"View data.","63c4ab1f":"From analysis above, among all categorical variables, Sex has the biggest influence on survival. Hence, we segment data by Sex when exploring the relationship between numerical variables and survival.\n","295f5cad":"### Obervations\n1. People at higher class have higher survival rate, hence Pclass should be included in the model;\n2. Female suvived at higher chance than male;\n3. The correlation between SibSp\/Parch and survival is random for certain values, these two variables can be combined into a new feature;\n4. Passengers got on board on port C have higher survival, but this was due to the constitution of the passengers: higher percentage of class 1, infants and elderly people; So we can conclude that Embarked variable is not related to survival, and drop it.\n5. Drop Name, Ticket and Cabin;\n","a2a90963":"## 4.3 Create training set and testing set","acff7df1":"## 4.2 Band numerical data (Age, Fare)","fb2eec89":"# 2. Problem Description\n\n>\"The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\n>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\"\n"}}