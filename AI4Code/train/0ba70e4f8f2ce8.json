{"cell_type":{"44153eb9":"code","0c6d9352":"code","6c86301a":"code","614c97ed":"code","bf2171b4":"code","c3233ca2":"code","de12232e":"code","d70c14b4":"code","8fd4e1e4":"code","8dc7e805":"code","49c84c32":"code","da669e29":"code","fc192cfe":"code","d5dd77de":"code","43edb04d":"code","f3d90373":"code","99e0a4c1":"code","14c4ad11":"code","a0b7a039":"code","3f2d36f4":"code","a4a81bcd":"code","0d51bbf6":"code","5aac1e5b":"code","88f41e07":"code","a94ea5d6":"code","55f31d54":"markdown","f4faa798":"markdown","c2cbab3a":"markdown","9809dd54":"markdown","b75004dd":"markdown","6b57888c":"markdown","ff6ab3c8":"markdown","95330c81":"markdown","6564caf4":"markdown","4a105c9f":"markdown","baa490a7":"markdown","56b4f6bb":"markdown","f60149cc":"markdown","aea9f894":"markdown","42744497":"markdown","8a40650c":"markdown","c52986b8":"markdown","2a0dbbe8":"markdown","1f4dc020":"markdown","f4644ce8":"markdown","a6069ddd":"markdown","a3ec90ad":"markdown","176ad8ef":"markdown","8a1612a4":"markdown"},"source":{"44153eb9":"# Numerical libraries\nimport numpy as np\n\n# to handle data in form of rows and columns \nimport pandas as pd\n\nfrom sklearn import preprocessing\n\n# Import Linear Regression machine learning library\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.metrics import r2_score\n\n\n#importing ploting libraries\nimport matplotlib.pyplot as plt\n\n#importing seaborn for statistical plots\nimport seaborn as sns","0c6d9352":"#read the data and store it in data frame\ndf = pd.read_csv('\/kaggle\/input\/autompg-dataset\/auto-mpg.csv')\ndf","6c86301a":"#the car name feature is not helping so we can drop it.\ndf = df.drop('car name',axis=1)","614c97ed":"#just drop the Nan records\ndf.dropna()","bf2171b4":"#replace special character or junk data\ndf = df.replace('?',np.nan)","c3233ca2":"#replace the Nan value with the Mean value\ndf = df.apply(lambda x: x.fillna(x.median()),axis=0)","de12232e":"#Separate independent and dependent variables\n\n# Copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\nX = df.drop('mpg',axis=1)\n\n# Copy the 'mpg' column alone into the y dataframe. This is the dependent variable\ny = df[['mpg']]","d70c14b4":"# scale all the columns of df. This will produce a numpy array\nX_scaled = preprocessing.scale(X)\nX_scaled = pd.DataFrame(X_scaled,columns=X.columns)\n\ny_scaled = preprocessing.scale(y)\ny_scaled = pd.DataFrame(y_scaled,columns=y.columns)","8fd4e1e4":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y_scaled,test_size=0.30,random_state=1)","8dc7e805":"reg_model = LinearRegression()\nreg_model.fit(X_train,y_train)\n","49c84c32":"for idx,col_name in enumerate(X_train.columns):\n    print('Coefficient for {} is {}'.format(col_name,reg_model.coef_[0][idx]))","da669e29":"intercept = reg_model.intercept_[0]\nprint('The intercept of the model is {}'.format(intercept))","fc192cfe":"ridge = Ridge(alpha=0.3)\nridge.fit(X_train,y_train)\n\nprint('Ridge model',(ridge.coef_))","d5dd77de":"lasso = Lasso(alpha=0.1)\nlasso.fit(X_train,y_train)\nprint('Lasso coefficeient :',lasso.coef_)","43edb04d":"print(\"Linear Regression Training score is {}\".format(reg_model.score(X_train,y_train)))\nprint(\"Linear Regression Training score is {}\".format(reg_model.score(X_test,y_test)))","f3d90373":"print(\"Redge Training model score is {}\".format(ridge.score(X_train,y_train)))\nprint(\"Redge Test model score is {}\".format(ridge.score(X_test,y_test)))","99e0a4c1":"print(\"Lasso Training model score is {}\".format(lasso.score(X_train,y_train)))\nprint(\"Lasso Test model score is {}\".format(lasso.score(X_test,y_test)))","14c4ad11":"#import the required library\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2,interaction_only=True)\n","a0b7a039":"X_poly = poly.fit_transform(X_scaled)\nX_poly.shape","3f2d36f4":"#create train and test model using new X dataframe    \n\nX_poly = poly.fit_transform(X_scaled)\nX_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.30, random_state=1)\nX_test.shape","a4a81bcd":"reg_model.fit(X_train,y_train)\nprint(reg_model.coef_[0])","0d51bbf6":"ridge = Ridge(alpha=0.3)\nridge.fit(X_train,y_train)\nprint(\"Ridge model coefficient is {}\".format(ridge.coef_))","5aac1e5b":"print(\"Train model accuracy :\" ,\n      ridge.score(X_train,y_train))\nprint(\"Test model accuracy :\" ,\n      ridge.score(X_test,y_test))","88f41e07":"lasso = Lasso(alpha=0.3)\nlasso.fit(X_train,y_train)\nprint(\"Lasso model coefficient is {}\".format(lasso.coef_))","a94ea5d6":"print(\"Train model accuracy :\" ,\n      lasso.score(X_train,y_train))\nprint(\"Test model accuracy :\" ,\n      lasso.score(X_test,y_test))","55f31d54":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">**Dataset**\n\nThe dataset has been taken from the UCI Machine Learning Repository. It can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Auto+MPG\n\nThe aim is to predict the mpg attribute. The dataset contains the following variables:\n\n* mpg: continuous\n* cylinders: multi-valued discrete\n* displacement: continuous\n* horsepower: continuous\n* weight: continuous\n* acceleration: continuous\n* model year: multi-valued discrete\n* origin: multi-valued discrete\n* car name: string (unique for each instance)","f4faa798":"* More or less similar results but with less complex models.  Complexity is a function of variables and coefficients\n* Note - with Lasso, we get equally good result in test though not so in training. \n* Further, the **number of dimensions is much less in LASSO**  model than ridge or un-regularized model\n* Lasso give good results with only 5 dimensions but Ridge and regular regression give the same with 10 dimensions\n* Over all Lasso model will survie in production well since its use less dimensions because with more dimensions we may endup with Overfit issue","c2cbab3a":"#Separate independent and dependent variablesScaling the features","9809dd54":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\"> Create a LASSO model and print the coefficients","b75004dd":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">Intro ...\n    \nThis note book will cover the basic of Linear Regression(shrinkage) model and performance comparison of its type \n* Ridge Regression\n* Lasso Regression\n\nThese will help us to avoid the overfitting problem by avoid \"[curse of dimensionality](https:\/\/www.kdnuggets.com\/2017\/04\/must-know-curse-dimensionality.html)\" in linear model.\n","6b57888c":"Now print and check the coefficient of our Regression model","ff6ab3c8":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">  score Comparison","95330c81":"* The model sholud have peaks and valley which is known by magnitudite of coefficient which tends to overfit problem","6564caf4":"* We can clearly see that the Lasso model makes some of coefficient as zero because model thinks that those are not useful dimensions","4a105c9f":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">Data Preprocessing ","baa490a7":"here fit a simple  linear regression model","56b4f6bb":"* degree: the option \"degree\" used to mention how many new feature need to create and the value is \"2\" which means that function will create new dimension where its origional dimension raised to power 2 only.\n* interaction_only: the \"interaction_only\" option set to True whic means the function will consider the dimensions with relationships between there.\n","f60149cc":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\"> Fit non regularized linear model on poly features","aea9f894":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">Load required Libs","42744497":"* By observing results above  its clear that \"Lasso\" giving good performance like Redge but with less number of dimensions\n* So Lasso model is ised in many situation for **Dimensionality Reduction or Feature Selection**.","8a40650c":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">Create a RIDGE model and print the coefficients","c52986b8":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\"> Play With Polynomial models \n\n* Polynomial function will take existing dimesions and understand the relationship bewtween those dimensions and will generate new dimensions.([power of polynomial](https:\/\/acadgild.com\/blog\/polynomial-regression-understand-power-of-polynomials))\n","2a0dbbe8":"* The option \"alpha\" is called regularization term .Please read here for more info [Regularization ](https:\/\/www.geeksforgeeks.org\/regularization-in-machine-learning\/)\n* The regularization term \"alpha\" helps to prevent\/stop the co-efficient to become high.\n* The value of alpha should not be high or low","1f4dc020":"* using poly funtion we arrived with 29 dimensions ","f4644ce8":"* Observe that the co-efficients are now changed little bit from the coefficient of origional model.","a6069ddd":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\"> Play with Ridge model with Poly feature","a3ec90ad":"Now split the data into two for train model and test model.","176ad8ef":"* **Observe:**\n* many of the coefficients have become 0 indicating drop of those dimensions from the model\n* Lasso minimise the co-efficeint to Zero but ridge reduce it fractionaly \n* Lasso removed\/droped 5 dimesion which its thinks those are useless.","8a1612a4":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#8a3ebe;\">Model Building Process\n"}}