{"cell_type":{"13a30ce6":"code","ac4e213b":"code","835d613c":"code","5da88f54":"code","764be975":"code","eaa95813":"code","578d7170":"code","cbcc1783":"code","53696277":"code","1c8d2902":"code","14591051":"code","d86dffba":"code","60a867a6":"code","c7380c87":"code","8340c889":"code","3b037d67":"code","39c5386e":"code","d14679b8":"code","eeff4a46":"code","9dca8992":"code","000087cf":"code","840a5a89":"code","84773cb8":"code","7a5409b8":"code","2ddd2982":"code","6a48ee95":"code","0cf020ae":"code","b7671bcf":"code","15e3cf22":"code","096e4185":"code","68abbaae":"code","8c4748bb":"code","7245e198":"code","de404f3f":"code","a17be61f":"code","fb0ecc6d":"code","b98a1d2c":"code","ddb725ed":"code","5feb61a0":"code","b613083f":"markdown","a813df7a":"markdown","8843ae8d":"markdown","3614a3be":"markdown"},"source":{"13a30ce6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac4e213b":"import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nfrom sklearn import preprocessing\nwarnings.filterwarnings(\"ignore\")\n\n\n","835d613c":"df =pd.read_csv('..\/input\/seedsdata\/seeds.csv')","5da88f54":"df.shape","764be975":"df.skew()","eaa95813":"#deleting null values\ndatacleaned=df.dropna()\ndatacleaned.isnull().sum()\n","578d7170":"df.corr()","cbcc1783":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        ","53696277":" def Head(value=5):\n            print('\\033[1m'+'displaying the', value, 'rows'+'\\033[0m')\n            a=df.head(value)\n            return a\n            print(\"--------------------------------------------------------------------------\")\nHead()","1c8d2902":" def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()","14591051":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","d86dffba":"def Size():\n    print('\\033[1m'+\"The size of dataset is :\"+'\\033[0m')\n    siz=df.size\n    print(siz,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nSize()","60a867a6":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()","c7380c87":"def ISNULL():\n    print('\\033[1m'+\"Detection of missing values\"+'\\033[0m')\n    co2=df.isnull().sum()\n    print(co2,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nISNULL()","8340c889":"def Ndim():\n    print('\\033[1m'+\"The dimensions of data set are:\"+'\\033[0m')\n    co4=df.ndim\n    print(co4,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNdim()","3b037d67":"def Nunique():\n    print('\\033[1m'+\"Total number of unique values are:\"+'\\033[0m')\n    co5=df.nunique()\n    print(co5,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNunique()","39c5386e":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","d14679b8":"def Duplicated():\n    print('\\033[1m'+\"Total number of duplicate rows\"+'\\033[0m')\n    co7=df.duplicated().count()\n    return(co7)\n    print(\"--------------------------------------------------------------------------\")\nDuplicated()","eeff4a46":"def ISNA():\n    print('\\033[1m'+\"The detected missing values are :\"+'\\033[0m')\n    co8=df.isna().sum()\n    return(co8)\n    print(\"--------------------------------------------------------------------------\")\nISNA()","9dca8992":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","000087cf":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","840a5a89":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","84773cb8":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     ","7a5409b8":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","2ddd2982":"for i in df.columns:\n    sns.distplot(df[i],kde=True)\n    plt.show()","6a48ee95":"plt.figure(figsize=(10,7))\nsns.histplot(data=df)\nplt.show()\n","0cf020ae":"plt.figure(figsize=(10,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","b7671bcf":"\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df.drop(['seedType'],axis = 1))","15e3cf22":"feature=df\nfeature=feature.drop(['seedType','ID'],axis=1)","096e4185":"label=df['seedType']","68abbaae":"X_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)","8c4748bb":"print(X_train.shape,y_train.shape)","7245e198":"print(X_test.shape,y_test.shape)","de404f3f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","a17be61f":"forest= RandomForestClassifier(n_estimators =1, random_state = 0)","fb0ecc6d":"\nforest.fit(X_train,y_train)  ","b98a1d2c":"y_pred = forest.predict(X_test)\n","ddb725ed":"forest.score(X_test,y_test)","5feb61a0":"cmat = confusion_matrix(y_test,y_pred)\nprint('TN - True Negative {}'.format(cmat[0,0]))\nprint('FP - False Positive {}'.format(cmat[0,1]))\nprint('FN - False Negative {}'.format(cmat[1,0]))\nprint('TP - True Positive {}'.format(cmat[1,1]))\nprint('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\nprint('Misclassification Rate: {}'.format(np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))))","b613083f":"# Relation Plots","a813df7a":"# Data Visualization","8843ae8d":"# Data Modelling and Feature Extraction","3614a3be":"# Exploratory Data Analysis"}}