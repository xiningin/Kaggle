{"cell_type":{"08d5e4f6":"code","ec26a258":"code","fe9db190":"code","9afae349":"code","6d974f31":"code","337ce078":"code","c527fc15":"code","69b1b2b2":"code","2ef14a35":"code","9f50e463":"code","ab03f328":"code","f2a4ecee":"code","0a58a52f":"code","e2bc606a":"code","5a365cee":"code","e7827588":"code","55d58eb6":"code","6e4b75dd":"code","4252bce4":"code","3a5ab957":"markdown","fbfd945b":"markdown","51139050":"markdown","064cf718":"markdown","1eb60c65":"markdown","efaf4d44":"markdown","22e2f97c":"markdown","1901d561":"markdown","76a27f6e":"markdown","64e2984f":"markdown","6f4385ae":"markdown","ac511ce7":"markdown"},"source":{"08d5e4f6":"import pandas as pd","ec26a258":"# Load train dataset\ntrain_data = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/travel_insurance\/Training_set_label.csv\")","fe9db190":"# Load test dataset\ntest_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/travel_insurance\/Testing_set_label.csv')","9afae349":"# Train data looks like:\ntrain_data.head()","6d974f31":"# Test data looks like:\ntest_data.head()","337ce078":"# Drop the column 'Destination' from both train and test set, and drop the target variable 'Claim' from the train dataset\ntrain_data.drop(['Destination', 'Claim'], axis=1, inplace=True)\ntest_data.drop('Destination', axis=1, inplace=True)","c527fc15":"# Select the categorical columns\ncat_train = train_data.select_dtypes('object')\ncat_test = test_data.select_dtypes('object')","69b1b2b2":"cat_train.nunique()","2ef14a35":"cat_test.nunique()","9f50e463":"train = pd.get_dummies(cat_train)\ntest = pd.get_dummies(cat_test)","ab03f328":"# checking the number of features in train and test set\nprint(\"There are {} features in train set\".format(len(train.columns)))\nprint(\"There are {} features in test set\".format(len(test.columns)))","f2a4ecee":"# Getting the missing feature\nmissing_feature = list(set(train.columns) - set(test.columns))[0]\nprint(missing_feature)","0a58a52f":"# Adding the missing feature to the test data\ntest[missing_feature] = 0","e2bc606a":"# Check the number of feature in test set\nlen(test.columns)","5a365cee":"from sklearn.preprocessing import OneHotEncoder","e7827588":"cat_train.dropna(inplace=True)\ncat_test.dropna(inplace=True)","55d58eb6":"ohe = OneHotEncoder(handle_unknown = 'ignore')\nencoded_train = ohe.fit_transform(cat_train).toarray()\ntrain = pd.DataFrame(encoded_train, columns=ohe.get_feature_names(cat_train.columns))","6e4b75dd":"encoded_test = ohe.transform(cat_test).toarray()\ntest = pd.DataFrame(encoded_test, columns=ohe.get_feature_names(cat_test.columns))","4252bce4":"# checking the number of features in train and test set\nprint(\"There are {} features in train set\".format(len(train.columns)))\nprint(\"There are {} features in test set\".format(len(test.columns)))","3a5ab957":"# Method 1: One hot Encoding using pd.get_dummies()","fbfd945b":"### Checking the number of unique values in all the categorical columns in both train and test set","51139050":"The OneHotEncoder() class from sklearn has an attribute named 'handle_unknown'. By default this attribute's value is 'error' which throws an error whenever it sees the unknown category. In order to handle the unknown category, we can pass this attribute's value as 'ignore'\n\nFrom [sklearn documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html):\n\n**handle_unknown{\u2018error\u2019, \u2018ignore\u2019}, default=\u2019error\u2019**\n\nWhether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to \u2018ignore\u2019 and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.","064cf718":"# Introduction\n\nOften we encounter some categories in train dataset which are not present in the test dataset or vice-versa which becomes problematic when doing one hot encoding. After one-hot encoding we face the issue that there are more features in train set than the test set or the vice-versa. And, we all know that if a model is trained on x number of features, to make prediction out of it we need to pass test set with x number of features.\n\nIn this tutorial, we will discuss two different ways of dealing with it.\n\n### About the Data\nThe dataset we will use here is related to travel insurance. The objective for this dataset is to find out if the insurance buyer will claim the insurance in near future or not.\n\nThere are 11 variables in the dataset including the target variable.\n\n#### Data Description\n*  Duration: Travel duration\n*  Destination: Travel destination\n*  Agency: Agency Name\n*  Commission: Commission on the insurance\n*  Age: Age of the insurance buyer\n*  Gender: Gender of the insurance buyer\n*  Agency Type: What is the agency type?\n*  Distribution Channel: offline\/online\n*  Product Name: Name of the insurance plan\n*  Net Sales: Net sales\n*  Claim: If the insurance is claimed or not (the target variable), 0 = not claimed, 1 = claimed\n\nThis dataset is available at the official GitHub page of DPhi: https:\/\/github.com\/dphi-official\/Datasets\/tree\/master\/travel_insurance\n\nTo load the train dataset run the below command in your notebook:\n```\nimport pandas as pd\ntrain_data = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/travel_insurance\/Training_set_label.csv\")\n```\n\nTo load the test_dataset run the below command in your notebook:\n```\ntest_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/travel_insurance\/Testing_set_label.csv')\n```\n\n\n\n\n\n","1eb60c65":"Now, both train and test set have equal number of features.\n\n# Conclusion\nIn the second method we don't need to add or remove any features manually but in case of the first method, we either need to remove or add the unknown categories in train or test set.","efaf4d44":"Before using OneHotEncoder, make sure the data doesn't contain any null values otherwise it will throw an error","22e2f97c":"Now, there are 48 features in train set and 47 features in test set. If you train a model using the train set, the model will ask you for 48 features while testing also. So in this case, we can find out the one feature in train that is not present in test and add that column in the test set with all values as 0.","1901d561":"### The problem with this approach\n1. If there are more missing features from test, it might become little difficult to add all those many columns to test set.\n2. What if there are some categories (or say features after one-hot encoding) which are present in test but not in train? In this case you need to manually add or remove all those categories that are present in test but not in train to the train data as we did above.","76a27f6e":"Now, there are 48 features in test set also.","64e2984f":"We can observe above that there are 26 categories in 'Product Name' column of train data while only 25 categories in 'Product Name' column of test data","6f4385ae":"Now do one hot encoding on test data. But on test data we will use only 'transform' method instead of fit_transform.","ac511ce7":"# Method 2: Using OneHotEncoder() from sklearn.preprocessing"}}