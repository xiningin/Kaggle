{"cell_type":{"f2a3c636":"code","2bcf9a4d":"code","fe064a5b":"code","98936b2a":"code","5da59488":"code","a1bbcaf7":"code","61d3ea3a":"code","235d2343":"code","55699d57":"code","d8bd8620":"code","c5895fd8":"markdown","985042da":"markdown","6ff4b3a0":"markdown","3abb90ab":"markdown","69571010":"markdown","5905b3c4":"markdown"},"source":{"f2a3c636":"!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > \/dev\/null 2>&1","2bcf9a4d":"import numpy as np\nimport random\nimport pandas as pd\nimport datatable as dt\nimport gc\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict","fe064a5b":"data_types_dict = {\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'content_type_id':'int8',\n    'answered_correctly': 'int8'\n}\n\ntrain_df = dt.fread('..\/input\/riiid-test-answer-prediction\/train.csv', columns=set(data_types_dict.keys())).to_pandas()","98936b2a":"# delete lecture rows\ntrain_df = train_df[~train_df['content_type_id']]\ntrain_df.drop('content_type_id', axis=1, inplace=True)\ngc.collect()","5da59488":"# Added the 6th digit to question_id to distinguish answered_correctly\ntrain_df['word'] = train_df['content_id'] + train_df['answered_correctly'] * 100000","a1bbcaf7":"# memory error\n# sentences = {}\n\n# for _, group in enumerate(tqdm(train_df.groupby('user_id'))):\n#     sentences[group[0]] = list(group[1]['word'].apply(str))","61d3ea3a":"sentences = defaultdict(list)\n\nfor _,row in enumerate(tqdm(train_df[['user_id', 'word']].values)):\n    sentences[row[0]].append(str(row[1]))","235d2343":"del train_df\nsentences = list(sentences.values())\ngc.collect()","55699d57":"from gensim.models import Word2Vec, KeyedVectors\n\nmodel = Word2Vec(sentences,  sg=1, size=100, window=5, min_count=1, sample=0)\nmodel.wv.save_word2vec_format(\"vec.pt\", binary=True)\n\ndel model, sentences\ngc.collect()","d8bd8620":"wv = KeyedVectors.load_word2vec_format('vec.pt', binary=True)\nprint('most_similar')\nprint(wv.most_similar('105692'))\n\nprint('get_vector')\nprint(wv.get_vector('105692'))","c5895fd8":"[This Notebook](https:\/\/www.kaggle.com\/imazekishota\/riiid-lgbm-with-word2vec) is LGBM training code.","985042da":"# Read Data","6ff4b3a0":"# Data to Sentence","3abb90ab":"# This Notebook is Training word2vec Model with content_id\nFirst of all, Thank you Kaggle, the Competition Host and competitor!!  \nThis competition gives me a lot of learning.  \n  \nAnd I'm impressed with Kaggle's culture of sharing ideas with everyone.\n\nIn this competition, I learned how to use the new idea of word2vec from [this discussion](https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/discussion\/209576) and other.  \nThank you @ML_Bear for sharing ideas!!\n\nSo I decided to try implementing this idea.  \n\n\nThis is my first implementation of word2vec, so I may make some mistakes.  \nBut I'll share it in this notebook!!  \n\nIf you have any concerns about memory savings or processing speed, please let me know.  ","69571010":"# Import","5905b3c4":"# word2vec"}}