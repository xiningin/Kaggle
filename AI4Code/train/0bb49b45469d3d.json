{"cell_type":{"8e217efc":"code","9607b01b":"code","ae2cda66":"code","6606edec":"code","61f0077b":"code","e63df335":"code","4b9aa73c":"code","f6ec8d7a":"code","d3d0229a":"code","6ea778c5":"code","f2a71535":"code","5b66c646":"code","0ffc559d":"code","54784a83":"code","c51cb396":"code","5d7beae1":"code","03c0887e":"code","defeb1c8":"markdown","b999d2e5":"markdown","2014facb":"markdown","5203b980":"markdown","1f857ae9":"markdown","6402ba6e":"markdown","01b66f92":"markdown","caeb1c54":"markdown","f07cec2e":"markdown","80187242":"markdown","1fb865a1":"markdown","c290f76a":"markdown","9f6cdfbd":"markdown"},"source":{"8e217efc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom plotly.figure_factory import create_gantt\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport os, re, gc \n\nfrom io import StringIO\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","9607b01b":"filename = '\/kaggle\/input\/corpus-of-russian-news-articles-from-lenta\/lenta-ru-news.csv'\ndf = pd.read_csv(filename)\ndf.head(10)","ae2cda66":"df.info()","6606edec":"df['date'] = pd.to_datetime(df['date'])\ndf['date'] = df['date'].dt.floor('D')","61f0077b":"countNewsPerYear = df.groupby(df['date'].dt.year).size()\nplt.figure(figsize=(12, 8))\nfig = countNewsPerYear.plot(kind='bar')\nfig.set_title('TOTAL NUMBER OF NEWS ARTICLES')\nfig.set_xlabel('YEAR')\nfig.set_ylabel('NUMBER OF NEWS ARTICLES')","e63df335":"df.loc[df['date'].dt.year == 1914]","4b9aa73c":"df['date'][:5] = df['date'][:5] + pd.offsets.DateOffset(year=2014)\n\ndf = df.sort_values(['date'], ascending=True)\ndf = df.reset_index(drop=True)","f6ec8d7a":"amountOfNans = df.iloc[:, 2:4].isna().sum() \namountOfNans.sort_values(ascending = False ) \/ df.shape[0] * 100","d3d0229a":"df = df[df['topic'].notna()]\ndf = df[df['text'].notna()]\n\n#refresh the indexes\ndf = df.set_index(np.arange(len(df.index)))","6ea778c5":"#Remove extra space from '\u041a\u0443\u043b\u044c\u0442\u043f\u0440\u043e\u0441\u0432\u0435\u0442 '\ndf_topic = []\n\nfor i in df['topic']:\n    if i == '\u041a\u0443\u043b\u044c\u0442\u043f\u0440\u043e\u0441\u0432\u0435\u0442 ':\n        df_topic.append('\u041a\u0443\u043b\u044c\u0442\u043f\u0440\u043e\u0441\u0432\u0435\u0442')\n    else:\n        df_topic.append(i)\n\ndf['topic'] = df_topic\n\ndel df_topic\ngc.collect() ","f2a71535":"# Unique topic names\nnameOfTopics = df['topic'].unique()\n\ndf_dict = []\nfor i in nameOfTopics:      \n    serie = df[df['topic'] == i]   \n    # add first, last date appearance for each topic\n    df_dict.append(dict(Task=i, Start=serie.iloc[0, 5], Finish=serie.iloc[-1, 5]))\n    \nfig = create_gantt(df_dict, title='The date appearance of topics', height=600, bar_width=0.5, width=600)\nfig.show()\n\ndel df_dict\ngc.collect() ","5b66c646":"countNewsPerTopic = df.groupby(df['topic']).size()\ncountNewsPerTopic = countNewsPerTopic.sort_values(ascending = False)\n\nplt.figure(figsize=(12, 8))\nfig = countNewsPerTopic.plot(kind='bar')\nfig.set_title('TOTAL NUMBER OF NEWS ARTICLES')\nfig.set_xlabel('TOPIC')\nfig.set_ylabel('NUMBER OF NEWS ARTICLES')","0ffc559d":"rareTopics = ['\u041a\u0440\u044b\u043c','\u041a\u0443\u043b\u044c\u0442\u043f\u0440\u043e\u0441\u0432\u0435\u0442', '\u041b\u0435\u0433\u043f\u0440\u043e\u043c', '\u0411\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430', '\u041e\u0440\u0443\u0436\u0438\u0435', '\u0427\u041c-2014', '\u0421\u043e\u0447\u0438', '\u041c\u0435\u0434\u041d\u043e\u0432\u043e\u0441\u0442\u0438', '69-\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c'] \npercOfRareTopic = sum((df['topic'].isin(rareTopics)))\/ len(df['topic']) * 100\n\nprint(f'{percOfRareTopic:.3f}% for rare topics')","54784a83":"mask = np.logical_not(df['topic'].isin(rareTopics))\ndf = df[mask]\n\n\ndel mask\ngc.collect() ","c51cb396":"#refresh the indexes\ndf = df.set_index(np.arange(len(df.index)))\n#Remove url and date from the dataset\ndf = df.drop(['url', 'date'], axis = 1)","5d7beae1":"df.to_csv('textFromEDA.csv', index = False)","03c0887e":"preprocFile = '\/kaggle\/input\/a-job-project\/preprocess_text2.csv'\n\nnew_df = pd.read_csv(preprocFile)","defeb1c8":"We found something intresting in 1914 year. Let's check it by clicking on the link","b999d2e5":"How we can see the dataset is unbalanced and some topics seems nearly zero. We need to check how many percent of rare topics is in the entire dataset. We need to know this, because in the future we will create a model for extracting the topic from the text.Then a larger number of topics, than greater the chance that the model may make mistakes","2014facb":"# Metrics\nWe should check two metrics: Logistic Loss, F1 Score. These two metrics are well suited to our task.\nLogistic Loss metric considers confidence in a particular class. In F1 Score, it is necessary that the precision and recall are equal to one and it is close to zero if one of the arguments is close to zero. Accuracy is not a good metric because we have an unbalanced dataset.","5203b980":"1. Given https:\/\/github.com\/yutkin\/Lenta.Ru-News-Dataset, perform EDA on it focusing on the following:\n  - Provide descriptive statistics\n  - Anomaly detection","1f857ae9":"That news was written in 2014. We should change the date for them.","6402ba6e":"We can see \u041c\u0435\u0434\u043d\u043e\u0432\u043e\u0441\u0442\u0438, \u0421\u043e\u0447\u0438, \u0427\u041c-2014 and \u0411\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 are less important then others","01b66f92":"Percentages of nans for topic and text","caeb1c54":"We must drop Nans in topic and text beacuse in the future, we will create a model for extracting topic from text. Without text or topic we can't train the model","f07cec2e":"We check the appearance of topics to understand how important the topic is. Then shorter the life span of the topic than less important it is.","80187242":"We have found that the word '\u041a\u0443\u043b\u044c\u0442\u043f\u0440\u043e\u0441\u0432\u0435\u0442 ' has an extra space.","1fb865a1":"We plot the number of news for each year . ","c290f76a":"Convert object to datatime64 and round the date to the day.","9f6cdfbd":"Now we plot the number of news for each topic. Then more number of topics than more important the topic is"}}