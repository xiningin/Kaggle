{"cell_type":{"70e907e7":"code","cd844ed5":"code","5c94db92":"code","e45a3b80":"code","49cf46f0":"code","ab0080fb":"code","f197dbcf":"code","fffb3434":"code","d61cedd0":"code","6c3aae5d":"markdown","fcf6130d":"markdown","7026eb04":"markdown","0398cd06":"markdown","586ba598":"markdown","b6d3fcd1":"markdown","37470870":"markdown","254e0f11":"markdown","1a63782e":"markdown","84177041":"markdown","a33b1cb2":"markdown","db8cf446":"markdown","d31e5e2f":"markdown","435b1c41":"markdown","24cd5336":"markdown","7d7777b9":"markdown","e9a2dbb7":"markdown","54897ad7":"markdown","011981e7":"markdown"},"source":{"70e907e7":"! pip install seaborn --upgrade","cd844ed5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Plotting libraries\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c94db92":"train_data = pd.read_csv(\"\/kaggle\/input\/mydata\/train.csv\").drop(columns=['id'])\n\ndata_target = train_data.Bankrupt\ndata_predictors = train_data.drop(['Bankrupt'], axis = 1)\n\ntrain_data.head()","e45a3b80":"data_predictors.head()","49cf46f0":"data_target.head()","ab0080fb":"cols_with_missing = [col for col in train_data.columns \n                                 if train_data[col].isnull().any()]\ncols_with_missing","f197dbcf":"train_data = train_data.drop(columns=['one if net income was negative for the last two year zero otherwise'])\ntrain_data.describe()","fffb3434":"sns.countplot(data=train_data, x = 'Bankrupt')","d61cedd0":"#f, axs = plt.subplots(2, 2, figsize = (8,6))\nfor col in train_data.columns:\n    sns.catplot(kind = 'box', data=train_data, x = col, height = 1)\n    ","6c3aae5d":"**Isaac Munshi on Kaggle**","fcf6130d":"Here is how I visualized the outliars with box and whisker plots. If you click run, good luck. My little laptop could not handle the 90+ whisker plots. It took a lot of patience and a lot of scrolling to look through this data.","7026eb04":"# 8. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your decision tree model.","0398cd06":"# 10. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your random forest model.","586ba598":"1. You must load the data from the provided CSV files.\n\n2. You must check for missing values within the training data.\n\n3. If the training data contains missing values, you must describe and implement an approach to handle those missing values.\n\n4. You must check for outliers within the training data.\n\n5. If the training data contains outliers, you must describe and implement an approach to handle those outliers.\n\n6. You must determine whether or not you will implement normalization or standardization, and explain your decision.\n\n7. You must build and train a decision tree model on the training data.\n\n8. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your decision tree model.\n\n9. You must build and train a random forest model on the training data.\n\n10. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your random forest model.\n\n11. You must select the best model that you are able to generate and use that model to predict the target vector for the test data.\n\n12. Your notebook must be saved with the output enabled so that we can see the results of each cell after it has been run.","b6d3fcd1":"I noticed that some of the columns have no importance or will hurt the data;\n'one if net income was negative...' was all 0's\n\n'one if total liabilities exceeds totall assets...' was almost all 0's, only 4 were 1's and out of those 4, 3 were bankrupt. A 75% rate is not justifiable to rely on. I am keeping it in for now just in case some trees use it well but I will\/might remove it in the future...","37470870":"No missing values.","254e0f11":"# 7. You must build and train a decision tree model on the training data.","1a63782e":"# 12. Your notebook must be saved with the output enabled so that we can see the results of each cell after it has been run.","84177041":"# 1. You must load the data from the provided CSV files.","a33b1cb2":"# 6. You must determine whether or not you will implement normalization or standardization, and explain your decision.","db8cf446":"train_data.info()","d31e5e2f":"# If the training data contains missing values, you must describe and implement an approach to handle those missing values.","435b1c41":"# 2. You must check for missing values within the training data.","24cd5336":"# 9. You must build and train a random forest model on the training data.","7d7777b9":"# 5. If the training data contains outliers, you must describe and implement an approach to handle those outliers.","e9a2dbb7":"I do notice some outliers, some where the outlier is 0 and some where the outlier is 1. Let me try to use the quartiles to determine outliers.","54897ad7":"# 4. You must check for outliers within the training data.","011981e7":"# 11. You must select the best model that you are able to generate and use that model to predict the target vector for the test data."}}