{"cell_type":{"5cfe6de8":"code","1e069518":"code","11a1ba20":"code","4e1cfb5e":"code","f4d94749":"code","746c3d77":"code","704fea61":"code","1f951519":"code","9be69a6c":"code","14a269f1":"code","d98f6514":"code","50457401":"code","98101fc0":"code","7a2ab71b":"code","8620cb32":"code","834fea59":"code","63d333b7":"code","defa5c82":"code","ee8068d7":"code","70d55005":"code","d35200df":"code","6c481d0c":"code","0f39d4ae":"code","24f1d993":"code","5ce74f95":"code","633b345a":"code","bc06b0fa":"code","28a57421":"code","d402b32c":"code","24024afe":"code","fdbf070b":"code","3ad1f481":"code","e180f86e":"code","b96844a6":"code","eb125941":"markdown","726400e2":"markdown","8987d90a":"markdown","91e3ed45":"markdown","95bff0e4":"markdown","6f7b245a":"markdown","7d73eb20":"markdown"},"source":{"5cfe6de8":"!pip install mido\n!pip install pygame\n!pip install music21","1e069518":"import pandas as pd\nimport numpy as np\nfrom mido import MidiFile\nimport pygame\nimport IPython\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport keras.layers as L\nimport keras.models as M\nimport keras\nfrom keras.layers import SimpleRNN,LSTM,GRU\nfrom sklearn.model_selection import train_test_split\nfrom IPython import *\nfrom music21 import *\nimport os\nimport tensorflow as tf","11a1ba20":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","4e1cfb5e":"data=pd.read_csv('..\/input\/musicnet-dataset\/musicnet_metadata.csv')","f4d94749":"# Making live plots\n# Importing the mid file first\nmid=MidiFile('..\/input\/musicnet-dataset\/musicnet_midis\/musicnet_midis\/Beethoven\/2313_qt15_1.mid',clip=True)\n# Having a look at the tracks of the mid file\nmid.tracks","746c3d77":"# Having a look at the msges of the tracks let's have a look at the first one since it only have 325 messages\nfor i in mid.tracks[1] :\n    print(i)","704fea61":"# Well you can see clearly there are many meta messages here how will we solve that ??\n# I got an idea let's get all the values with note on here \nnote_on=[]\nn=50\nfor m in range(n):\n    mid=MidiFile('..\/input\/musicnet-dataset\/musicnet_midis\/musicnet_midis\/Beethoven\/'+os.listdir('..\/input\/musicnet-dataset\/musicnet_midis\/musicnet_midis\/Beethoven')[m],clip=True)\n    for j in range(len(mid.tracks)):\n        for i in mid.tracks[j] :\n            if str(type(i))!=\"<class 'mido.midifiles.meta.MetaMessage'>\" :\n                x=str(i).split(' ')\n                if x[0]=='note_on':\n                    note_on.append(int(x[2].split('=')[1]))","1f951519":"import time\nfrom IPython.display import clear_output\ndef live_plot_make(x,range_=20,pause_time=0.01,skip_a_do=1):\n    for i in range(0,len(x)-range_,skip_a_do):\n        plt.figure(figsize=(18,8))\n        x_plot=x[i:i+range_]\n        y_plot=[i for i in range(range_)]\n        fig=plt.plot(y_plot,x_plot,marker='D')\n        plt.ylim([min(x),max(x)])\n        time.sleep(pause_time)\n        clear_output(wait=True)\n        plt.show()\n","9be69a6c":"live_plot_make(note_on,range_=100,pause_time=0.02,skip_a_do=1000)","14a269f1":"len(note_on)","d98f6514":"'''We are gonna take a frame of 10 notes at a time since we have 1437 notes takin 10 notes at a time will give us\n        about 1427 training samples . Lets try :)'''\ntraining_data=[]\nlabels=[]\nfor i in range(20,len(note_on)):\n    training_data.append(note_on[i-20:i])\n    labels.append(note_on[i])","50457401":"print('Training data is :',training_data[0],' The label for it is :',labels[0])","98101fc0":"# How many different type of notes can we have in the labels column\ndifferent_labels=set(labels)\nprint('The different type of labels that we can have and might need to predict are : ',len(different_labels))","7a2ab71b":"# Function to build the model\ndef build_model():\n    model=M.Sequential()\n    model.add(LSTM(128,input_shape=(10,1)))\n    model.add(L.Dense(1,'relu'))\n    model.compile(loss='MSE',optimizer='adam')\n    return model","8620cb32":"def build_model_softmax():\n    model=M.Sequential()\n    model.add(LSTM(128,input_shape=(10,1),return_sequences=True))\n    model.add(LSTM(128))\n    model.add(L.Flatten())\n    model.add(L.Dense(40,'relu'))\n    model.add(L.Dense(40,'softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam')\n    return model","834fea59":"def build_model_lstm2():\n    model=M.Sequential()\n    model.add(LSTM(200,input_shape=(10,1),unroll=True,return_sequences=True))\n    model.add(L.Dropout(0.4))\n    model.add(LSTM(100))\n    model.add(L.Dense(100,'relu'))\n    model.add(L.Dropout(0.2))\n    model.add(L.Dense(1,'relu'))\n    model.compile(loss='MSE',optimizer='adam')\n    return model","63d333b7":"def build_model_softmax():\n    model=M.Sequential()\n    model.add(LSTM(200,input_shape=(10,1),unroll=True,return_sequences=True))\n    model.add(L.Dropout(0.4))\n    model.add(LSTM(100))\n    model.add(L.Dense(100,'relu'))\n    model.add(L.Dropout(0.2))\n    model.add(L.Dense(1,'relu'))\n    model.compile(loss='MSE',optimizer='adam')\n    return model","defa5c82":"with strategy.scope():\n    model=build_model_lstm2()","ee8068d7":"early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0)","70d55005":"training_data=np.array(training_data)\ntraining_data=training_data.reshape((training_data.shape[0],training_data.shape[1],1))\nlabels=np.array(labels)","d35200df":"# Let's make training and validation data\nX_train, X_test, y_train, y_test = train_test_split(training_data, labels, test_size=0.05, random_state=42)","6c481d0c":"X_train.shape","0f39d4ae":"model.fit(X_train,y_train,epochs=200,batch_size=32 * strategy.num_replicas_in_sync,\n          validation_data=(X_test,y_test),callbacks=[early_stop])","24f1d993":"# Saving the model\nmodel.save('Auto_Song_Maker.h5')","5ce74f95":"history=model.history.history\nplt.plot([i for i in range(len(history['loss']))],history['loss'])\nplt.plot([i for i in range(len(history['val_loss']))],history['val_loss'])","633b345a":"training_data[0].reshape(1,20,1)","bc06b0fa":"model.predict(training_data[0].reshape(1,20,1))[0][0]","28a57421":"###### Let's do some random predictions now\nn=200\nstarter_notes=training_data[0]\nx=training_data[0].reshape(1,20,1)\ntune=list(training_data[0].reshape(-1,))\nfor i in range(n) :\n    pred=int(model.predict(x)[0][0])\n    if round(pred)==round(tune[-1]):\n        p=np.random.choice(['a','b','c'])\n        if p=='a':\n            pred=65\n        elif p=='b':\n            pred=60\n        else:\n            pred=70\n    tune.append(pred)\n    x=tune[-10:]\n    x=np.array(x)\n    x=x.reshape(1,10,1)\n    ","d402b32c":"tune=list(np.array(tune).astype('float32'))","24024afe":"offset = 0\noutput_notes = []\n# create note and chord objects based on the values generated by the model\nfor patterns in tune:\n    pattern=str(patterns)\n    # pattern is a chord\n    if ('.' in pattern) or pattern.isdigit():\n        notes_in_chord = pattern.split('.')\n        notes = []\n        for current_note in notes_in_chord:\n            new_note = note.Note(int(current_note))\n            new_note.storedInstrument = instrument.Piano()\n            notes.append(new_note)\n        new_chord = chord.Chord(notes)\n        new_chord.offset = offset\n        output_notes.append(new_chord)\n    # pattern is a note\n    else:\n        new_note = note.Note(pattern)\n        new_note.offset = offset\n        new_note.storedInstrument = instrument.Piano()\n        output_notes.append(new_note)\n    # increase offset each iteration so that notes do not stack\n    offset += 0.5","fdbf070b":"output_notes","3ad1f481":"midi_stream = stream.Stream(output_notes)\n","e180f86e":"midi_stream.write('midi','test_output.mid')","b96844a6":"IPython.display.Audio('.\/test_output.wav')","eb125941":"## You might need to wait until the popup window on the top right dissappears","726400e2":"# Kinda weird tune but it will learn in time :)","8987d90a":"# That was just one song :) Don't know how much chaos will occur after n songs :)","91e3ed45":"## Hehe something i created from scratch :) Hope you like this animated plot :)\n## You might need to save this to gif if you wanna add it in markdown","95bff0e4":"# First Step Creating Data For Our Model","6f7b245a":"# Try running the file . The plot above is animation but will only work while file is running :)","7d73eb20":"# Thank you  Hope you liked it :)"}}