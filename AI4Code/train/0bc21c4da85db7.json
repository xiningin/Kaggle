{"cell_type":{"65d7f78f":"code","6c3d9fec":"code","510be920":"code","5964f3c9":"code","215116df":"code","602250e0":"code","e9c127dd":"code","4c4d2640":"code","5efac333":"code","bbbaf43a":"code","790d9968":"code","efbef245":"code","49441fb3":"code","dd8d8eae":"code","cf04f3c1":"code","0c0546b2":"code","a6c4e7ed":"code","7d092e57":"code","310e3131":"code","bc844bce":"code","fcb68ef1":"code","206c3790":"code","013411e4":"code","31026bc8":"code","717e0700":"code","61ccfc46":"code","4badeecc":"code","879120a8":"code","65fb9673":"code","b099f60d":"code","970bab39":"code","69c8fcf3":"code","583dbb35":"code","9b5b953e":"code","225acb89":"code","24f0673c":"code","a0cdc661":"code","769598af":"code","9753550c":"code","825dde0c":"code","b63c8ec1":"code","ad34178e":"code","e13ca115":"code","b4e7cde4":"code","dfba4ab4":"code","a11ca89a":"code","3f64d609":"code","280bdfd7":"code","81b285fa":"code","426ba06f":"code","ab6e7bbe":"markdown","03baecfb":"markdown","27bcd93d":"markdown","866e902f":"markdown","92f173bb":"markdown","6fdb35d9":"markdown","7d38c5d6":"markdown","77d383fd":"markdown","d35cbc10":"markdown","6c4ac5b2":"markdown","34eaa68b":"markdown","7454068a":"markdown","a488c620":"markdown","49e37e3a":"markdown","70d11b51":"markdown","fbfd4fa6":"markdown","c903cf38":"markdown","cdf70360":"markdown"},"source":{"65d7f78f":"# Main aim is to understand more about the data\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\n# Display all the columns of the dataframe\npd.pandas.set_option('display.max_columns', None)","6c3d9fec":"dataset = pd.read_csv('..\/input\/housepricepredictions\/train.csv')\n\n# print shape of the dataset with rows and columns\nprint(dataset.shape)","510be920":"# print top 5 records\ndataset.head()","5964f3c9":"# Here will check the percentage of NaN values present in each feature\n# Step-1: Make the list of features which has missing values\nfeatures_with_na = [features for features in dataset.columns if dataset[features].isnull().sum()>1]\n\n# Step-2: Feature name and percentage of missing values\n#for feature in features_with_na:\n    #print(feature, np.round(dataset[feature].isnull().mean(), 4), ' % of missing values')\n\ndf_train_missing = pd.DataFrame(np.round(dataset[features_with_na].isnull().mean(), 4), columns=[' % missing values'])\ndf_train_missing","215116df":"data = dataset.copy()\nfor feature in features_with_na:\n    # let's convert all the Nan values to 1, otherwise zero for easy plotting the relationship with the SalesPrice\n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    # let's calculate the mean SalePrice where the information is missing or present\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()\n","602250e0":"print('Id of houses {}'.format(len(dataset.Id)))","e9c127dd":"# Lets see the data types present in our dataset\ndataset.dtypes.unique()","4c4d2640":"# list of numerical variables\nnumerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\nprint('Number of numerical variables', len(numerical_features))\n\n# Visualize the numerical features\ndataset[numerical_features].head()","5efac333":"# list of variables that contain year information\nyear_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\nyear_feature","bbbaf43a":"# let's explore the content of these year variables\nfor feature in year_feature:\n    print(feature, dataset[feature].unique())","790d9968":"# Lets analyze the Temporal Datetime Variables\n# We will check whether there is a relation between year the house is sold and Sale Price\ndataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title('House Price vs Year Sold')","efbef245":"# Lets analyze the Temporal Datetime Variables\n# We will check the relationship between these year features and SalesPrice \n# and see how price is changing over the years\n# Here we will compare the difference between ALL years features with Sale Price\n\ndata = dataset.copy()\nfor feature in year_feature:\n    if feature != 'YrSold':\n        # we will capture the difference between year variable and year the house was sold for\n        data[feature] = data['YrSold'] - data[feature]\n        \n        plt.scatter(data[feature], data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n        ","49441fb3":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\ndiscrete_features = [feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint('Total discrete variables: {}'.format(len(discrete_features)))","dd8d8eae":"discrete_features","cf04f3c1":"data[discrete_features].head()","0c0546b2":"## Lets Find the realtionship between discrete variables and SalePice\nfor feature in discrete_features:\n    data = dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","a6c4e7ed":"continuous_feature = [feature for feature in numerical_features if feature not in discrete_features+year_feature+['Id']]\nprint('Continuous feature count {}'.format(len(continuous_feature)))","7d092e57":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\ndata = dataset.copy()\nfor feature in continuous_feature:\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel('Count')\n    plt.title(feature)\n    plt.show()","310e3131":"# We will be using logarithmic transformation\ndata = dataset.copy()\nfor feature in continuous_feature:\n    if 0 in data[feature].unique() or feature in data['SalePrice']:\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data['SalePrice'] = np.log(data['SalePrice'])\n        plt.scatter(data[feature], data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.title(feature)\n        plt.show()","bc844bce":"data = dataset.copy()\nfor feature in continuous_feature:\n    if 0 in data[feature].unique(): # here we pass if the unique values\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","fcb68ef1":"categorical_features = [feature for feature in dataset.columns if dataset[feature].dtypes=='O']\n#len(categorical_features)\ncategorical_features","206c3790":"# checking the cardinality of categorical variables\ncat_count = []\nfor feature in categorical_features:\n    cat_count.append(len(dataset[feature].unique()))\n    \ndata_cat = pd.DataFrame({'Feature': categorical_features, 'No of Categories': cat_count})\ndata_cat","013411e4":"## Relationship between categorical variable and dependent feature SalePrice\n\ndata = dataset.copy()\nfor feature in categorical_features:\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","31026bc8":"# Capture all the nan values\n# Handle categorical features which are missing\nfeatures_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\nfeature_missing = pd.DataFrame(np.round(dataset[features_nan].isnull().mean(),4), columns=[' % missing values'])\nfeature_missing","717e0700":"# Replace missing value with a new label\ndef repalce_categorical_feature(data, features_nan):\n    data[features_nan] = data[features_nan].fillna('Missing')\n    return data\n\ndata = dataset.copy()\ndataset = repalce_categorical_feature(data, features_nan)\ndataset[features_nan].isnull().sum()","61ccfc46":"dataset.head()","4badeecc":"# Checking missing values for numerical variables\nnumerical_with_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n\n# Print all the numerical nan variables and percentage of missing values\nnumerical_missing = pd.DataFrame(np.round(dataset[numerical_with_nan].isnull().mean(), 4), columns=[' % missing values'])\nnumerical_missing","879120a8":"# Replacing the numerical missing values\nfor feature in numerical_with_nan:\n    # Shall replace by using median since there are outliers\n    median_value = dataset[feature].median()\n    \n    # create a new feature to capture nan values\n    dataset[feature+'nan'] = np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value, inplace=True)\n\ndataset[numerical_with_nan].isnull().sum()","65fb9673":"dataset.head(10)","b099f60d":"# Temporal variables(Date Time variables)\nfor feature in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n    dataset[feature] = dataset['YrSold'] - dataset[feature]\n\ndataset.head()","970bab39":"dataset[['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']].head()","69c8fcf3":"num_features = ['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\nfor feature in num_features:\n    dataset[feature] = np.log(dataset[feature])\n    \ndataset.head()","583dbb35":"\ncategorical_features","9b5b953e":"for feature in categorical_features:\n    temp = dataset.groupby(feature)['SalePrice'].count()\/len(dataset)\n    temp_df = temp[temp>0.01].index\n    dataset[feature] = np.where(dataset[feature].isin(temp_df), dataset[feature], 'Rare_var')\n    \ndataset.head(20)","225acb89":"for feature in categorical_features:\n    labels_ordered = dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered = {k:i for i,k in enumerate(labels_ordered, 0)}\n    dataset[feature] = dataset[feature].map(labels_ordered)\n    \ndataset.head(10)","24f0673c":"scaling_feature = [feature for feature in dataset.columns if feature not in ['Id', 'SalePrice']]\nlen(scaling_feature)","a0cdc661":"scaling_feature","769598af":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(dataset[scaling_feature])","9753550c":"scaler.transform(dataset[scaling_feature])","825dde0c":"# transform the train and test set, and add on the Id and SalePrice variables\ndata = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                 pd.DataFrame(scaler.transform(dataset[scaling_feature]), columns=scaling_feature)], axis=1)","b63c8ec1":"data.head()","ad34178e":"data.to_csv('X_train.csv', index=False)","e13ca115":"dataset = pd.read_csv('X_train.csv')\ndataset.head()","b4e7cde4":"# capture the dependent feature\ny_train = dataset[['SalePrice']]","dfba4ab4":"# Drop dependent feature from dataset\nX_train = dataset.drop(['Id', 'SalePrice'], axis=1)","a11ca89a":"### Apply Feature Selection\n# first, I specify the Lasso Regression model, and I\n# select a suitable alpha (equivalent of penalty).\n# The bigger the alpha the less features that will be selected.\n\n# Then I use the selectFromModel object from sklearn, which\n# will select the features which coefficients are non-zero\n\n## for feature slection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\nfeature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) #remember to set the seed, the random state in this function\nfeature_sel_model.fit(X_train, y_train)","3f64d609":"feature_sel_model.get_support()","280bdfd7":"# let's print the number of total and selected features\n\n# this is how we can make a list of the selected features\nselected_feat = X_train.columns[(feature_sel_model.get_support())]\n\n# Print stats\nprint('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))\nprint('features with coefficients shrank to zero: {}'.format(np.sum(feature_sel_model.estimator_.coef_ == 0)))","81b285fa":"selected_feat","426ba06f":"X_train = X_train[selected_feat]\nX_train.head()","ab6e7bbe":"#### Categorical variables\n","03baecfb":"#### Outliers","27bcd93d":"### Feature Engineering\n\nWe will be performing below steps in Feature Engineering\n\n- Missing values\n- Temporal variables\n- Categorical variables: remove rare labels\n- Standardize the values of the variables of the same range\n\n#### Missing values","866e902f":"#### Numerical Variables","92f173bb":"### Data Analysis","6fdb35d9":"#### Observation\nThe columns Alley,PoolQC,Fence and MiscFeature have more than 80% of missing values,Now lets see whether there is a relationship between missing values and the target feature(SalePrice) by plotting them","7d38c5d6":"###### Temporal Variables(Eg: Datetime Variables)\nFrom the Dataset we have 4 year variables. We have to extract information from the datetime variables like no of years or no of days. One example in this specific scenario can be difference in years between the year the house was built and the year the house was sold. We will be performing this analysis in the Feature Engineering.","77d383fd":"#### Numerical Variables\n\nSince the numerical variables are skewed we will perform log normal distribution","d35cbc10":"#### Observation\nwe can see from the plots above that Some discrete variables have relationship with the SalesPrice and some seems to be constant with the SalesPrice\n\n\n##### Continous variables","6c4ac5b2":"#### Feature Scaling","34eaa68b":"#### Observation\nwe can see that as the difference between the year features and the year sold increases then the house price decreases exponentially\n\n\n##### DIscrete variables","7454068a":"From the above dataset some of the features like 'id' is not required","a488c620":"#### Missing values","49e37e3a":"## Data Analysis, Feature Engineering and Feature Selection","70d11b51":"### Data Analysis involves finding out the below steps and analysing them\n- Missing values\n- All the numerical variables\n- Distribution of numerical variables\n- Categorical variables\n- Cardinality of categorical variables\n- Outliers\n- Relationship between independent and dependent features(SalePrice)","fbfd4fa6":"### Feature Selection","c903cf38":"#### Handling Rare categorical  feature\n\nWe will remove categorical variables that are present less than 1% of the observations","cdf70360":"#### Observation\nHere With the relation between the missing values and the dependent variable is clearly evident.We cannot remove these rows where NaN values are present as there is a dependency, so we have to replace these NaN values with something meaningful which we will do in the Feature Engineering section"}}