{"cell_type":{"414b6c07":"code","497c722d":"code","7455c075":"code","08441399":"code","b6568b77":"code","c2ca44bc":"code","21940783":"code","1ca9490b":"code","668d7cc0":"code","0a49bafb":"code","c43cb8ad":"code","372ea17e":"code","fad6a0c0":"code","354fa426":"code","d596cfd5":"code","406c49bc":"code","6de1dda9":"code","2378065f":"code","8990f9a6":"code","f74047db":"code","9526d0af":"code","cb128e3a":"code","9a4dd7c9":"code","1115a661":"code","8a3df7f7":"markdown","2e9e1ccb":"markdown","62ba91b0":"markdown","f3454520":"markdown","97b63405":"markdown","4f09451d":"markdown","eb3d9956":"markdown","a2e2a098":"markdown","e25d93da":"markdown","d1fd9ab7":"markdown","b3d12e05":"markdown","4c75f635":"markdown","99658fe2":"markdown","0f4db4c3":"markdown","8e991ad8":"markdown"},"source":{"414b6c07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","497c722d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)\n","7455c075":"def load_diabets():\n    data = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\n    return data\n\ndf = load_diabets()","08441399":"df.describe().T","b6568b77":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n\ncheck_df(df)","c2ca44bc":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    It gives the names of categorical, numerical and categorical but cardinal variables in the data set.\n    Note: Categorical variables with numerical appearance are also included in categorical variables.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                The dataframe from which variable names are to be retrieved\n        cat_th: int, optional\n                Class threshold value for numeric but categorical variables\n        car_th: int, optinal\n                Class threshold for categorical but cardinal variables\n\n    Returns\n    ------\n        cat_cols: list\n                Categorical variable list\n        num_cols: list\n                Numerical variable list\n        cat_but_car: list\n                Categorical view cardinal variable list\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = the total number of variables\n        num_but_cat is inside cat_cols.\n        The sum of 3 lists with return is equal to the total number of variables: cat_cols + num_cols + cat_but_car = number of variables\n\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","21940783":"df[\"Outcome\"].value_counts()\n\n#0    500\n#1    268\n#Name: Outcome, dtype: int64\n\n#The number of people with disease is 268, the number of people without the disease is 500","1ca9490b":"sns.countplot(x=\"Outcome\",data=df)\nplt.show(block=True)\n\ndef target_summary(dataframe, target, cat_cols, num_cols):\n    for col in dataframe:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        if col in cat_cols:\n             print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                                \"RATIO\":100*dataframe[col].value_counts(),\n                                \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n        if col in num_cols:\n            print(pd.DataFrame({\"MEAN\": dataframe.groupby(target)[col].mean()}), end=\"\\n\\n\\n\")\n\ntarget_summary(df, \"Outcome\", cat_cols, num_cols)","668d7cc0":"sns.boxplot(x=df[\"Age\"])\nplt.show(block=True)\n\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit,up_limit\n\noutlier_thresholds(df,num_cols)","0a49bafb":"def check_outlier(dataframe, col_name ):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n    \ncheck_outlier(df,num_cols)\n","c43cb8ad":"def grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\ngrab_outliers(df, \"Age\", index=True)\n\ngrab_outliers(df, \"SkinThickness\", index=True)","372ea17e":"df.isnull().values.any()\n\ndf.isnull().sum()\n\ndf.notnull().sum()\n \ndf.isnull().sum().sum()\n\ndf[df.isnull().any(axis=1)]\n\ndf[df.notnull().all(axis=1)]\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\nmissing_values_table(df)\n\nmissing_values_table(df, True)","fad6a0c0":"def corr_plot(data, remove=[\"Id\"], corr_coef = \"pearson\", figsize=(20, 20)):\n    if len(remove) > 0:\n        num_cols2 = [x for x in data.columns if (x not in remove)]\n\n    sns.set(font_scale=1.1)\n    c = data[num_cols2].corr(method = corr_coef)\n    mask = np.triu(c.corr(method = corr_coef))\n    plt.figure(figsize=figsize)\n    sns.heatmap(c,\n                annot=True,\n                fmt='.1f',\n                cmap='coolwarm',\n                square=True,\n                mask=mask,\n                linewidths=1,\n                cbar=False)\n    plt.show()\n\ncorr_plot(df, corr_coef = \"spearman\")","354fa426":"df[[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",]]=df[[\"Glucose\",\n                                                                     \"BloodPressure\",\n                                                                     \"SkinThickness\",\n                                                                     \"Insulin\",\n                                                                     \"BMI\"]].replace(0,np.NaN)\n\ndf.isnull().sum()\n\n","d596cfd5":"df = pd.get_dummies(df[cat_cols + num_cols], drop_first=True)\nscaler = MinMaxScaler()\ndf = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n\n","406c49bc":"\n\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=33)\ndf = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n\ndf = pd.DataFrame(scaler.inverse_transform(df), columns=df.columns)\n\ndf.head()","6de1dda9":"corr_plot(df, corr_coef = \"spearman\")","2378065f":"for col in num_cols:\n    print(col, check_outlier(df, col))","8990f9a6":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)\n\nfor col in num_cols:\n   print(col, check_outlier(df,col))\n\ndf.head()","f74047db":"df['BMI'].max()\n\ndf['BMI_Ranges'] = pd.cut(df['BMI'],[0,18.5,25,30,45,60],labels = [\"Underweight\",\"Normal\",\"Overweight\",\n                                                                               \"Fat\", \"Obese\"])\n\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show(block=True)\n\ncat_summary(df, \"BMI_Ranges\", True)","9526d0af":"df.groupby(\"Outcome\")[\"BMI_Ranges\"].value_counts()","cb128e3a":"cat_cols=[\"BMI_Ranges\"]\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\ndf=one_hot_encoder(df, cat_cols, drop_first=True)\n\ndf.head()","9a4dd7c9":"rs = RobustScaler()\ndf[num_cols] = rs.fit_transform(df[num_cols])\n\ndf[num_cols].head()","1115a661":"\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)","8a3df7f7":"**Examining The Correlation**","2e9e1ccb":"**Observing Missing Values**","62ba91b0":"**Separating Variables By Type**","f3454520":"\n**Filling Missing Values With \"NaN\"**\n","97b63405":"**Robust Scaling**","4f09451d":"**\u0130mplementation of KNN**","eb3d9956":"**Outlier Check**","a2e2a098":"**\u0130mporting Dataset**","e25d93da":"**Statistical \u0130nformations**","d1fd9ab7":"**Model Creation**","b3d12e05":"**Outlier Detection**","4c75f635":"**Examining Columns By Target Variable**","99658fe2":"**Creating New Value**","0f4db4c3":"**One Hot Encoding** ","8e991ad8":"**Standardization of Variables**"}}