{"cell_type":{"490cbc89":"code","c5a88a6f":"code","15fd6194":"markdown","c771bf85":"markdown"},"source":{"490cbc89":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom keras.preprocessing import image\n\nimgs_test_path = os.path.join('\/kaggle\/input\/dogs-cats-images\/dataset','test_set')\nimgs_train_path = os.path.join('\/kaggle\/input\/dogs-cats-images\/dataset','training_set')\n\n#filelist=[fil for fil in os.listdir(imgs_others_path)]\n\n\nbatch_size = 128\nimg_height = 180\nimg_width = 180\n\n#data_dir = pathlib.Path(os.path.join('Images'))\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  imgs_train_path,\n  seed=212,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  imgs_test_path,\n  seed=212,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nclass_names = train_ds.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        random_num = np.random.randint(0, len(images))\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[random_num].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[random_num]])\n        plt.axis(\"off\")\n\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nnum_classes = 2\n\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(img_height, img_width, 3)),\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2,width_factor=0.2,fill_mode='reflect'),\n    tf.keras.layers.Conv2D(32, 5,activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, 3,activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64),  \n    tf.keras.layers.Dropout(rate=0.2),\n    tf.keras.layers.Dense(32,activation='relu'),    \n    tf.keras.layers.Dense(num_classes)\n    \n])\n\nmodel.summary()\n\n#tf.keras.optimizers.Adam(learning_rate=0.00001)\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nepochs=400\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n\nmodel.save('Model1\/my_model',overwrite=True)","c5a88a6f":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()\n","15fd6194":"The model begins to demonstrate overfitting after around 200 epochs. An accuracy of roughly 82% is achieved.","c771bf85":"The code should be run with gpu acceleration and takes around 33 minutes to run.\nSome description:\nThe training and validation data sets are first loaded.\nThe the model is prepared which first contrains preprocessing layers which first normalizes the images.\nThen at we augment the data to include random a flip, rotate and translation - the logic being that the network should ideally\nbe invariant to these operations, or that it is equivalent of simply having more data - reducing overfitting and allowing for higher predictive power.\nTwo convolution layers are added which filters the image providing us with some features in the images.\nThe a linear dense layer followed by a relu layer. The number of nodes in the layer is low enough that we dont immediately end up in\na scenario of overfitting.\nThe dropout layer helps with convergence.\nThe model is then fitted and saved."}}