{"cell_type":{"b9fabab4":"code","8edbc52c":"code","d3fa2722":"code","86727fd3":"code","6cb50089":"code","e80be88e":"code","d3e4c730":"code","8f654439":"code","61b0ee51":"code","2d84e144":"code","80a060e5":"code","8978c1d7":"code","a175577f":"code","37d7f883":"code","33063425":"code","ffda1bb2":"code","916283e3":"code","08afea45":"code","945128ba":"code","b23d6718":"code","6dcc678d":"code","7ad1881a":"code","d38fc649":"code","d20d0bf9":"code","42835bc4":"code","8ad3f174":"code","0cd13df2":"code","81415e4e":"code","432d403b":"code","defc005a":"code","2226466c":"code","4bbb7053":"code","2db7b003":"code","f22d385e":"code","7f5a6639":"code","97c97739":"code","024b3942":"code","f3bc13f1":"code","81485a71":"code","ddec9b66":"code","1650a0dc":"code","96afe5ab":"code","172027f0":"code","021b4f19":"code","df17fa60":"code","50643096":"code","dd1cfb37":"code","0701f3c6":"code","870a10ca":"code","420eefc2":"code","9db646d7":"code","4c4bd229":"code","dc46f7ac":"code","818f04fe":"code","606a499f":"code","99dbd092":"code","46013384":"code","6e580f76":"code","415c6009":"code","2c502c7a":"code","1d7354f9":"code","caf577cc":"code","7f01f704":"code","5f8f2146":"code","1c6dc36a":"code","a70b9241":"code","067bf035":"code","d01aa90e":"code","bd4ec4c3":"code","fb8ec66a":"code","e15ad0c8":"code","120f567d":"code","17e0899d":"code","bf5c1239":"code","3d2c808f":"code","1ca58459":"code","56134ff0":"code","bb3fefd7":"code","81bbd0fc":"code","4128a5e7":"code","41eb8598":"code","0a6ad996":"code","8041cb80":"code","38a9108d":"code","b50750a8":"code","74ef9a0e":"code","04abbf8f":"code","cc130455":"code","2b171085":"code","e098189d":"code","5802bff9":"code","97a6a123":"code","b25f717b":"code","fa8d8f41":"code","06dc80ae":"code","d712d661":"code","0c5ac344":"code","bb16b067":"code","cfdccce0":"code","eb34def4":"code","fe7e1a2a":"code","e2772d6a":"code","3be808ef":"code","14f844ed":"code","a72d9d71":"code","32b23b8f":"code","7f0c3903":"markdown","fdac81ee":"markdown","5e0d929c":"markdown","db6d2d2b":"markdown","0e2a6aa9":"markdown","3cfca67e":"markdown","5c88422f":"markdown","b393ddea":"markdown","c6a39f13":"markdown","6656954f":"markdown","b30de673":"markdown","2f02c58d":"markdown","8145024e":"markdown","15ca3e2a":"markdown","17248c7a":"markdown","d408ffc5":"markdown","2c2fd48f":"markdown","8ee8020c":"markdown","7db14630":"markdown","ca1329ab":"markdown","26e34f83":"markdown","6620f4bd":"markdown","c077c7e9":"markdown","ec7e2b4d":"markdown","f51788a0":"markdown","33d881b8":"markdown","6b8f2605":"markdown","aa17069e":"markdown","9780a1ba":"markdown","7d8b68f2":"markdown","4a7fa9e3":"markdown","27c304ad":"markdown","af8f9786":"markdown","cd6f7ddf":"markdown","789acd2d":"markdown","02f71355":"markdown","65286280":"markdown","8670b69a":"markdown","d666ed0d":"markdown","4f5a9422":"markdown","677caebe":"markdown","731ce89f":"markdown","a704cc33":"markdown","38cae0d1":"markdown","6a5cbd37":"markdown","fea0d9f9":"markdown"},"source":{"b9fabab4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/fifa19\/data.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8edbc52c":"#Creating Data Frame\ndata = pd.read_csv('..\/input\/fifa19\/data.csv')","d3fa2722":"#Getting Information\ndata.info()","86727fd3":"#Data correlation List\ndata.corr()","6cb50089":"#correlation map\nf,ax = plt.subplots(figsize=(30, 30))\nsns.heatmap(data.corr(), annot=True, linewidths=.8, fmt= '.2f',ax=ax)\nplt.show()","e80be88e":"#Geeting First 20 Object \ndata.head(20)","d3e4c730":"data.columns","8f654439":"#Age younger than 18 and overall bigger than 70 players\ndata[(data['Age']<18) & (data['Overall']>70)]","61b0ee51":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Potential.plot(kind = 'line', color = 'g',label = 'Potential',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Overall.plot(color = 'r',label = 'Overall',linewidth=1, alpha = 0.9,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","2d84e144":"# Scatter Plot \n# x = BallControl, y = ShortPassing\ndata.plot(kind='scatter', x='BallControl', y='ShortPassing',alpha = 0.5,color = 'red')\nplt.xlabel('BallControl')              # label = name of label\nplt.ylabel('ShortPassing')\nplt.title('BallControl-ShortPassing Scatter Plot')            # title = title of plot","80a060e5":"# Histogram\n# bins = number of bar in figure\ndata.Age.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.show()","8978c1d7":"# clf() = cleans it up again you can start a fresh\ndata.Age.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","a175577f":"#create dictionary and look its keys and values\ndictionary = {'Hans' : '18','Refik' : '32'}\nprint(dictionary.keys())\nprint(dictionary.values())","37d7f883":"dictionary['Hans'] = \"19\"    # update existing entry\nprint(dictionary)\ndictionary['Miranda'] = \"25\"       # Add new entry\nprint(dictionary)\ndel dictionary['Refik']              # remove entry with key 'Refik'\nprint(dictionary)\nprint('Miranda' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)","33063425":"data = pd.read_csv('..\/input\/fifa19\/data.csv')","ffda1bb2":"series = data['Potential']        # data['Potential'] = series\nprint(type(series))\ndata_frame = data[['Potential']]  # data[['Potential']] = data frame\nprint(type(data_frame))","916283e3":"# 1 - Filtering Pandas data frame\nx = data['Agility']>80     # There are 18142 players who have higher Agility value than 80\ndata[x]","08afea45":"# 2 - Filtering pandas with logical_and\n# There are only 1 player who have higher Balance value than 75 and higher LongPassing value than 90\ndata[np.logical_and(data['Balance']>75, data['LongPassing']>90 )]","945128ba":"# Stay in loop if condition( i is not equal 9) is true\ni = 0\nwhile i != 9:\n    print('i is: ',i)\n    i +=1 \nprint(i,' is equal to 9')","b23d6718":"# Stay in loop if condition( i is not equal 9) is true\nlis = [1,2,3,4,5,6,7,8,9]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7, 7:8, 8:9\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'Hans':'19','Miranda':'25'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['LongPassing']][0:1].iterrows():\n    print(index,\" : \",value)\n\n","6dcc678d":"# example of what we learn above\ndef tuble_ex():\n    \"\"\" return defined t tuble\"\"\"\n    t = (5,9,7)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","7ad1881a":"# guess print what\nx = 0\ndef f():\n    x = 1\n    return x\nprint(x)      # x = 0 global scope\nprint(f())    # x = 1 local scope","d38fc649":"# What if there is no local scope\nx = 1\ndef f():\n    y = 9*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","d20d0bf9":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","42835bc4":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add four local variable \"\"\"\n        a = 9\n        x = 2\n        y = 3\n        z = 1\n        q = x * z  + a \/ y\n        return q\n    return add()**2\nprint(square())    ","8ad3f174":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(11,22,33))","0cd13df2":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(9,7,5,3)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(Hans='19', Miranda='25' ,Refik='32')","81415e4e":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(9))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(7,9,11))","432d403b":"number_list = [1,2,3]\ny = map(lambda x:x**3,number_list)\nprint(list(y))","defc005a":"# iteration example\nname = \"messi\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)         # print remaining iteration","2226466c":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","4bbb7053":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))\n","2db7b003":"num1 = [9,19,29]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","f22d385e":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**3 if i == 5 else i-5 if i < 12 else i+5 for i in num1]\nprint(num2)","7f5a6639":"# lets return fifa 19 csv and make one more list comprehension example\n# lets classify players whether they have high or low overall. Our threshold is average overall.\nthreshold = data.Overall.mean()\ndata[\"Overall_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Overall]\ndata.loc[:10,[\"Overall_level\",\"Overall\"]] # we will learn loc more detailed later","97c97739":"data = pd.read_csv('..\/input\/fifa19\/data.csv')\ndata.head()  # head shows first 5 rows","024b3942":"# tail shows last 5 rows\ndata.tail()","f3bc13f1":"# columns gives column names of features\ndata.columns","81485a71":"# shape gives number of rows and columns in a tuble\ndata.shape","ddec9b66":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","1650a0dc":"# For example lets look frequency of player types\nprint(data.Position.value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 santrafor players or 70 Goolkeeper players","96afe5ab":"# For example max age is 45 or min potential is 48\ndata.describe() #ignore null entries","172027f0":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Potential',by = 'Age')","021b4f19":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","df17fa60":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Overall','Potential'])\nmelted","50643096":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","dd1cfb37":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","0701f3c6":"data1 = data['Overall'].head()\ndata2= data['Potential'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","870a10ca":"data.dtypes","420eefc2":"# lets convert object(str) to categorical and int to float.\ndata['Name'] = data['Name'].astype('category')\ndata['Overall'] = data['Overall'].astype('int64')","9db646d7":"data.dtypes","4c4bd229":"# Lets look at does Fifa19  data have nan value\n# As you can see there are 18207 entries. However 'Loaned From' has 1264 non-null object.\ndata.info()","dc46f7ac":"# Lets chech 'Loaned From'\ndata[\"Loaned From\"].value_counts(dropna =False)\n# As you can see, there are 16943 NAN value","818f04fe":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Loaned From\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","606a499f":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","99dbd092":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","46013384":"assert  data['Loaned From'].notnull().all() # returns nothing because we drop nan values","6e580f76":"data[\"Loaned From\"].fillna('empty',inplace = True)","415c6009":"assert  data['Loaned From'].notnull().all() # returns nothing because we do not have nan values","2c502c7a":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'ID'\n# assert data.Age.dtypes == np.float","1d7354f9":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","caf577cc":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","7f01f704":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","5f8f2146":"# Plotting all data \ndata1 = data.loc[:,[\"Age\",\"Agility\",\"Potential\"]]\ndata1.plot()\n# it is confusing","1c6dc36a":"# subplots\ndata1.plot(subplots = True)\nplt.show()","a70b9241":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Age\",y = \"Potential\")\nplt.show()","067bf035":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Potential\",bins = 50,range= (0,250),normed = True)","d01aa90e":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Potential\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Potential\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","bd4ec4c3":"data.describe()","fb8ec66a":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","e15ad0c8":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of Fifa19 data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","120f567d":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","17e0899d":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","bf5c1239":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","3d2c808f":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","1ca58459":"## read data\ndata = pd.read_csv('..\/input\/fifa19\/data.csv')\ndata= data.set_index(\"Unnamed: 0\")\ndata.head()","56134ff0":"# indexing using square brackets\ndata[\"Age\"][1]","bb3fefd7":"# using column attribute and row label\ndata.Age[1]","81bbd0fc":"# using loc accessor\ndata.loc[1,[\"Age\"]]","4128a5e7":"# Selecting only some columns\ndata[[\"Age\",\"Potential\"]]","41eb8598":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"Overall\"]))     # series\nprint(type(data[[\"Overall\"]]))   # data frames","0a6ad996":"# Slicing and indexing series\ndata.loc[1:10,\"Overall\":\"Marking\"]   # 10 and \"Marking\" are inclusive","8041cb80":"# Reverse slicing \ndata.loc[10:1:-1,\"Overall\":\"Marking\"] ","38a9108d":"# From something to end\ndata.loc[1:10,\"Potential\":] ","b50750a8":"boolean = data.Age < 27\ndata[boolean]","74ef9a0e":"# Combining filters\nfirst_filter = data.Age > 25\nsecond_filter = data.Potential >75\ndata[first_filter & second_filter]","04abbf8f":"# Filtering column based others\ndata.Age[data.Overall<47]","cc130455":"# Plain python functions\ndef div(n):\n    return n\/2\ndata.Potential.apply(div)","2b171085":"# Or we can use lambda function\ndata.Potential.apply(lambda n : n\/2)","e098189d":"# Defining column using other columns\ndata[\"max improve point\"] = data.Potential - data.Overall\ndata.head()","5802bff9":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","97a6a123":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"ID\")\n# also you can use \n# data.index = data[\"#\"]","b25f717b":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/fifa19\/data.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","fa8d8f41":"# Setting index : Age is outer Potential is inner index\ndata1 = data.set_index([\"Age\",\"Potential\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # how to use indexes","06dc80ae":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","d712d661":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","0c5ac344":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","bb16b067":"# level determines indexes\ndf1.unstack(level=0)","cfdccce0":"df1.unstack(level=1)","eb34def4":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","fe7e1a2a":"df","e2772d6a":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","3be808ef":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","14f844ed":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","a72d9d71":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","32b23b8f":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()\n","7f0c3903":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","fdac81ee":"zip(): zip lists","5e0d929c":"In this part, you learn:\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops","db6d2d2b":"### WHILE and FOR LOOPS","0e2a6aa9":"# 1. INTRODUCTION TO PYTHON","3cfca67e":"### Including Library And Import CSV File:","5c88422f":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool","b393ddea":"<a id=\"30\"><\/a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","c6a39f13":"### MATPLOTLIB","6656954f":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.","b30de673":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","2f02c58d":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","8145024e":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","15ca3e2a":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","17248c7a":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others","d408ffc5":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end","2c2fd48f":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","8ee8020c":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","7db14630":"\n### DICTIONARY\n","ca1329ab":"<a id=\"29\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","26e34f83":"<a id=\"32\"><\/a> <br>\n# MANIPULATING DATA FRAMES WITH PANDAS","6620f4bd":"# 2. PYTHON DATA SCIENCE TOOLBOX","c077c7e9":"### NESTED FUNCTION","ec7e2b4d":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","f51788a0":"Up to now, you learn \n* User defined function \n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n* Anonymous function\n* List comprehensio","33d881b8":"In this part, you learn:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","6b8f2605":"### ITERATORS","aa17069e":"### ANONYMOUS FUNCT\u0130ON\n","9780a1ba":"Thank you for your votes and comments","7d8b68f2":"### SCOPE","4a7fa9e3":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","27c304ad":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data","af8f9786":"### USER DEFINED FUNCTION","cd6f7ddf":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting","789acd2d":"### DEFAULT and FLEXIBLE ARGUMENTS","02f71355":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","65286280":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label","8670b69a":"### PANDAS","d666ed0d":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","4f5a9422":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","677caebe":"### LIST COMPREHENS\u0130ON\n**One of the most important topic of this kernel**","731ce89f":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","a704cc33":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing","38cae0d1":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","6a5cbd37":"### LAMBDA FUNCTION","fea0d9f9":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),boolean,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for analysis especially for sklearn(we will learn later)"}}