{"cell_type":{"315f6469":"code","9546134e":"code","cef55fa5":"code","6a5fd3a1":"code","baeec21f":"code","e1289f85":"code","0065f90b":"code","abaf03a0":"code","e2c9af40":"code","4fb0b8ad":"code","ced991af":"code","a10610b8":"code","28c6e69b":"code","3ea6eb9a":"code","ce521cb3":"code","01fa1cb5":"code","e4b9529c":"code","47b86422":"code","4884cd20":"code","d173838a":"code","ce729e9a":"code","a2b6e2a6":"code","3263128e":"code","a710a3cf":"code","15b0f40e":"code","40321aa6":"code","139232af":"code","63249e7d":"code","b54c48ae":"code","23f8634f":"code","83053b7a":"code","f3c6917c":"code","e165c5b0":"code","25e2ff73":"code","a14fd745":"code","b3cafeb2":"code","2c0ad34e":"code","6003dd49":"code","a41ac05a":"code","427f98ed":"code","7b37a003":"code","361b7a48":"code","353a77da":"code","a9a55790":"code","355f2dcc":"code","9d783158":"code","0f5a20ba":"code","a41db2d6":"code","43cdfb3d":"code","0c18bb89":"code","38d1dbdf":"code","a780693b":"code","e695deb4":"code","15a4b89a":"code","b15254bc":"code","dd458fad":"markdown","5b59c93e":"markdown","2c3482f4":"markdown","923d7c76":"markdown","759776a2":"markdown","0edf649b":"markdown","d4f4b62a":"markdown","b47419dc":"markdown","6d35b998":"markdown","312f4e17":"markdown","0f7fe42e":"markdown","3ccb36ff":"markdown","92c29114":"markdown","722fea3e":"markdown","f2b28f10":"markdown","8d3d729e":"markdown","ad5cca4d":"markdown","e1f1aa2c":"markdown","f06d4b0d":"markdown","6655307c":"markdown","9344caa6":"markdown"},"source":{"315f6469":"pip install openpyxl","9546134e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n## For Visualization\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n### %matplotlib inline will make your plot outputs appear and be stored within the notebook.\n\nimport warnings\nwarnings.filterwarnings('ignore')","cef55fa5":"## Read File from UCI \n### pd.read_csv('https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00291\/airfoil_self_noise.dat', sep=\"\\t\", names = ['Frequency','Angle of attack','Chord length','Free-stream velocity','Suction\/side','Scaled\/sound'])","6a5fd3a1":"%%time\ndf= pd.read_excel('..\/input\/online-retail-for-market-basket-analysis\/Online Retail.xlsx')\ndf","baeec21f":"df.info()","e1289f85":"df.hist(figsize=(22,5), edgecolor='Black', linewidth=1.2, layout=(1,4));","0065f90b":"df.describe(include= 'all')","abaf03a0":"### Check for Duplicates\n# Use the DataFrame.duplicated() method to return a series of boolean values thus we add .sum() to get no of duplicate value\ndf.duplicated().sum()","e2c9af40":"### Drop Duplicates\ndf.drop_duplicates(inplace=True)","4fb0b8ad":"df[df['InvoiceNo'].str.contains('C', na=False, regex=True)]","ced991af":"#Data Cleaning\ndf['Description'] = df['Description'].str.strip()                  #removes spaces from beginning and end\ndf.dropna(axis=0, subset=['InvoiceNo'], inplace=True)              #removes duplicate invoice\ndf['InvoiceNo'] = df['InvoiceNo'].astype('str')                    #converting invoice number to be string\ndf = df[~df['InvoiceNo'].str.contains('C')]                        #remove the credit transactions \ndf.head()","a10610b8":"sns.heatmap(df.isnull(), cbar=False);","28c6e69b":"df.isnull().mean()*100","3ea6eb9a":"df[df['CustomerID'].isna()]","ce521cb3":"### Storing df with not na CustomerId\ndfc= df[df['CustomerID'].notna()]","01fa1cb5":"plt.figure(figsize=(22,7))\nplt.subplot(2,2,1)\ndf.UnitPrice.plot()\nplt.title('Unit Price of complete dataset', fontsize=15)\nplt.subplot(2,2,2)\ndfc.UnitPrice.plot(color='red')\nplt.title('Unit Price when CustomerId is not null', fontsize=15)\n\nplt.subplot(2,2,3)\nsns.boxplot(df.UnitPrice, palette='Blues')\nplt.title('Boxplot of Unit Price of complete dataset', fontsize=15)\nplt.subplot(2,2,4)\nsns.boxplot(dfc.UnitPrice, color='red')\nplt.title('Boxplot of Unit Price when CustomerId is not null', fontsize=15)\n\nplt.tight_layout()","e4b9529c":"# Checking for rows with UnitPrice == 0\ndf[df['UnitPrice']== 0]","47b86422":"df[df['UnitPrice']<0]","4884cd20":"df[df['UnitPrice']==0]","d173838a":"### Max description is nan, so lets create a temp data frame to check for notna entries in description\ntemp= df[df['UnitPrice']==0]\ntemp[temp['Description'].notna()].head(50)","ce729e9a":"### Lets check 'GLASS JAR KINGS CHOICE' price to check my hypothesis that up= 0 means return\/cancel\ndf[df['Description']=='GLASS JAR KINGS CHOICE'].describe()","a2b6e2a6":"df[df['UnitPrice']==0].Description.unique()","3263128e":"### Why Quantity is in -ve\ndf[df['Quantity']<0]","a710a3cf":"df[df['Quantity']<0].Description.unique()","15b0f40e":"### Exploring gifts in StockCode\ndf[df['StockCode'].str.contains('gift', na=False, regex=True)]","40321aa6":"### Randomly checked an InvoiceNo and all 283 entries have missing CustomerID\ndf[df['InvoiceNo']=='539492']","139232af":"from wordcloud import WordCloud, STOPWORDS\nstopwords = STOPWORDS\nwc= WordCloud(background_color='Black',stopwords=stopwords, height=1080, width =1920)\n\nbody =temp['Description'].dropna().to_string(index=False)\n### Generate word cloud\nwc.generate(body)\n## Visualize\nplt.figure(figsize=(22,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Description for Unit Price==0\", fontsize=15)\nwc.to_file('body.png');","63249e7d":"body1 =df[df['Quantity']<0].Description.dropna().to_string(index=False)\n### Generate word cloud\nwc.generate(body1)\n## Visualize\nplt.figure(figsize=(22,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Description for Quantity<0\", fontsize=15)\nwc.to_file('body1.png');","b54c48ae":"import datetime as datetime\nfrom datetime import datetime\n#datetime.strptime('2013-01-01 09:10:12', '%Y-%m-%d %H:%M:%S')","23f8634f":"df['invoice_date'] = df['InvoiceDate'].dt.date\ndf['invoice_time_hour'] = df['InvoiceDate'].dt.hour\ndf['invoice_time_min'] = df['InvoiceDate'].dt.minute\n\n### Converting invoice date to data time\ndf['invoice_date']= pd.to_datetime(df['invoice_date'], infer_datetime_format= True)","83053b7a":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'invoice_time_hour', data=df, palette= 'Blues');","f3c6917c":"plt.figure(figsize=(10,5))\nsns.countplot(x= 'invoice_time_min', data=df,  palette= 'viridis')\nplt.xticks(np.arange(0, 59+1, 3.0));  ### Setting interval of min to 3","e165c5b0":"### How many items each customer buy?\n# dfc.InvoiceNo.value_counts()\nprint(\"On Average no of orders placed ny a customer\")\nprint(dfc.InvoiceNo.nunique()\/dfc.CustomerID.nunique())","25e2ff73":"dfc.groupby('CustomerID').sum()\n# .InvoiceNo.plot()","a14fd745":"dfc","b3cafeb2":"### Top 10 Products (Best seller)\nproduct_group =dfc.groupby('StockCode').mean()\nproduct_group","2c0ad34e":"product_group.sort_values('Quantity')","6003dd49":"df.Country.nunique()","a41ac05a":"dfc.Country.nunique()","427f98ed":"dfc.Country.value_counts()","7b37a003":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\n\n#### To view all columns from dataframe\npd.set_option('display.max_columns', None)","361b7a48":"dfc[dfc['Country']=='Germany']","353a77da":"dfc[dfc['Country']=='Germany'].InvoiceNo.nunique()","a9a55790":"dfc[dfc['Country']=='Germany'].Description.nunique()","355f2dcc":"#Separating transactions for Germany\n### GroupBy Invoice and Description and sum of quantity\n### .unstack() :: Pivot a level of the (necessarily hierarchical) index labels.\nmybasket_ger = (dfc[dfc['Country'] ==\"Germany\"]\n          .groupby(['InvoiceNo', 'Description'])['Quantity']\n          .sum().unstack().reset_index().fillna(0)\n          .set_index('InvoiceNo'))\n\nmybasket_ger","9d783158":"#converting all positive vaues to 1 and everything else to 0\n### i.e all no less than 1 to 0\n### and all no greater than equal to 1 to 1\n\n## Why doing this because I want my data to be only 0 & 1 as this is the only value my algo is expecting as input\n\ndef my_encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\nmy_basket_sets = mybasket_ger.applymap(my_encode_units)\nmy_basket_sets.drop('POSTAGE', inplace=True, axis=1) #Remove \"postage\" as an item\n### Display sample of set\nmy_basket_sets.sample(3)","0f5a20ba":"#Generatig frequent itemsets\nmy_frequent_itemsets = apriori(my_basket_sets, min_support=0.07, use_colnames=True)","a41db2d6":"#generating rules\nmy_rules = association_rules(my_frequent_itemsets, metric=\"lift\", min_threshold=1)","43cdfb3d":"#viewing top 100 rules\nmy_rules.head(100)","0c18bb89":"## For comparing with Rule 1 and 5\nmy_basket_sets['ROUND SNACK BOXES SET OF4 WOODLAND'].sum()","38d1dbdf":"### Rule 1\nmy_basket_sets['PLASTERS IN TIN WOODLAND ANIMALS'].sum()","a780693b":"### Rule 5\nmy_basket_sets['SPACEBOY LUNCH BOX'].sum()","e695deb4":"#Filtering rules based on condition \n    ### lift >= 3 && Confidence >=3\nmy_rules[ (my_rules['lift'] >= 3) &\n       (my_rules['confidence'] >= 0.3) ]","15a4b89a":"my_rules[ (my_rules['lift'] >= 2) &\n       (my_rules['confidence'] >= 0.6) ]","b15254bc":"my_rules[ (my_rules['lift'] < 3) &\n       (my_rules['confidence'] < 0.3) ]","dd458fad":"Now we can observe that no of columns have shot up from **8 columns to 1695 columns as it is the no of unique description** and since we group df by index and there are **457 unique index thus rows are reduced to 457**\n\n`NOTE`\n* If value=0 that mean this product wasn't present in this invoice.\n* If value=n `Where n is +ve int`` it means that item was present n time in the invoice.","5b59c93e":"## Date time Formating","2c3482f4":"Places where UnitPrice is 0.0 `CustomerID` is NaN and `Description` is also NaN","923d7c76":"## Making reecommendations\n\n![150664527-0e3c8d13-a5a9-429f-896d-1f5899a73c8f.jpg](attachment:904e8532-14b8-4caf-a3cb-bddff1a64087.jpg)","759776a2":"# To Do in EDA:\n1. Create a word cloud for description.\n2. Check for average Quantity.\n3. Unique customer id and invoice and try to find order placed per customer.\n4. No of Country with order volume.\n5. Seperate Invoice Date with Invoice Time","0edf649b":"## Attribute Information:\n\n* InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n* StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n* Description: Product (item) name. Nominal.\n* Quantity: The quantities of each product (item) per transaction. Numeric.\n* InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n* UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n* CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n* Country: Country name. Nominal, the name of the country where each customer resides.\n\n","d4f4b62a":"# Training Model Apriori\n### Apriori algo uses frequent item sets to generate association rules. It is based on the concept that a subset of a frequent item set must also be a frequent item set.\n### Frequent itme set is an itemset whose support value is greater than a threshold value.\n\n**What is apriori algorithm?**\n\nApriori Algorithm is a Machine Learning algorithm that is used to gain insight into the structured relationships between different items involved. It\u2019s a data mining technique that is used for mining frequent itemsets and relevant association rules.\n\nExample: Recommending products based on your purchased items. You can see this in different e-commerce websites. (Recommendation system)\n\nThings that we need to know before implementation:\n\n**Association rule:** It identifies frequent patterns and associations(relations) among a set of items. Ex: If you go to buy a keyboard, you might also get a mouse. So place them aside in your market to get more profit. **Association rule** can be thought as ***if-else relationship***. \nIf `A` => Then `B` here A is called `antecedent` and B is called `Consequent`. Consequent comes along as an item with an antecedent group or the group of antecedents.\n### 3 Types of Matrices which help to measure the Association\n\n\n**Support**: Frequency of combination of (A & B) by N.Support refers to the default popularity of an item and can be calculated by finding the number of transactions containing a particular item divided by total number of transactions.\n\nSupport (Keyboard) = (Transactions containing (Keyboard)) \/ (Total Transactions))\n\n**Confidence**: Confidence refers to the likelihood that an item B (mouse) is also bought if item A (keyboard) is bought. Like our keyboard and mouse example.\n\nConfidence(Keyboard\u2192Mouse) = (Transactions containing both (Keyboard and Mouse))\/(Transactions containing Keyboard)\n\n**Lift**: Lift(Keyboard -> Mouse) refers to the increase in the ratio of sale of Mouse when the Keyboard is sold. Lift(Keyboard -> Mouse) can be calculated by dividing Confidence(Keyboard\u2192Mouse) divided by Support(Mouse).\n\nLift(Keyboard -> Mouse) = (Confidence(Keyboard\u2192Mouse))   \/  (Support (Mouse))\n\n![Apriori-Algorithm-Data-sets.jpg](attachment:2dce661a-ca5f-45ed-9c9f-be6f6e0c6ad6.jpg)\n","b47419dc":"## Top 100 rules\n***antecedents*** Implies => ***consequents***","6d35b998":"## Data Cleaning","312f4e17":"### How come Unit price is 0, Lets investigate","0f7fe42e":"# Thank You!","3ccb36ff":"### Recap about Support, Confidence and lift\n![150663391-a86fc7b7-0070-4114-90d7-1fb74f15f707.png](attachment:5dc0f90e-7491-43c2-a929-24161e69b669.png)","92c29114":"* ROUND SNACK BOXES SET OF4 WOODLAND occurs 112 times follwed by 'PLASTERS IN TIN WOODLAND ANIMALS' occuring 63 time\n* ROUND SNACK BOXES SET OF4 WOODLAND occurs 112 times follwed by 'SPACEBOY LUNCH BOX' occuring 47 time","722fea3e":"There are **1336 rows having quantity in -ve**. Lets check their description\/ reason for being in -ve","f2b28f10":"Quantity is -ve only when I tem is **sent to wrong adrees**, **is damaged** or **is returned or cancelled**","8d3d729e":"Intresting unit price seem to -ve too. lets check all posibilities","ad5cca4d":"### Lets pick 2nd top country i.e `Germany` to perform MBA as UK have a lot of entries and it will make our computation very slow","e1f1aa2c":"# Market Basket Analysis (MBA)\n\n![MBA Theoru(1).jpg](attachment:d9a27df0-b22d-4117-9846-a011515a84ed.jpg)\n\n### Applications\n1. Retail\/supply Markets\/ FMCG Companies\n2. Insurance Companies\n3. Medical\n4. Bank\/ Credic Card Companies\n5. Telecom Analyse Various Services offered by Telecom Companies and what customers are purchasing","f06d4b0d":"### Market Basket Abakysis is one of the key Techniques used by large retailers to uncover associations between items\n\n![do-a-market-basket-analysis-you-may-also-like.jpg](attachment:3c3580dc-5579-4e56-8f05-0de70b9459cf.jpg)","6655307c":"Quantit","9344caa6":"### Country wise analysis of data"}}