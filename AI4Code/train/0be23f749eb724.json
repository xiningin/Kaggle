{"cell_type":{"78e0b5d0":"code","47219c00":"code","6a645b3c":"code","669365c9":"code","afd6b91f":"code","7b11d7d2":"code","7ea05c8f":"code","129e2c72":"code","435de585":"code","4ffc96f8":"code","990d1622":"code","3805b253":"code","7cc56d1a":"code","8308581c":"code","4a273961":"code","1959cd05":"code","76b72fa6":"code","6dafb2a5":"code","3eced2c1":"code","4f083647":"code","7046c122":"code","9448fb2f":"code","c3ceba3e":"code","ec9b6fa3":"code","76c19f8c":"code","caff6f63":"code","49b19ee8":"code","d8ac229c":"code","b2c78421":"markdown","b66d6e07":"markdown","da14799e":"markdown","db86ed21":"markdown","807f3740":"markdown","63cbddb5":"markdown","d90621b2":"markdown","e88b6362":"markdown","b5ac37dc":"markdown","e4646af4":"markdown","32089896":"markdown","a8220422":"markdown","180471e3":"markdown","64e7ea67":"markdown","1cd8e250":"markdown","f9ebf2fd":"markdown","c94b849e":"markdown","ced66071":"markdown","cfffcb07":"markdown","e82848c7":"markdown","56013402":"markdown","ca208fd9":"markdown","64aa356f":"markdown","a913526f":"markdown","09bdfabd":"markdown","186d4cee":"markdown","37117c6d":"markdown","5603f91b":"markdown"},"source":{"78e0b5d0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n# This ensures plots are displayed inline in the Jupyter notebook\n%matplotlib inline","47219c00":"\n# Load the training datset\nbike_data = pd.read_csv(\"\/kaggle\/input\/ml-basics-data-files\/daily-bike-share.csv\")\nprint(f\"Shape of dataframe: {bike_data.shape}\")\nbike_data.head()","6a645b3c":"# Use pandas DatetimeIndex to take out the day values from the given date \nbike_data['day'] = pd.DatetimeIndex(bike_data['dteday']).day\n\nprint(f\"New shape of dataframe: {bike_data.shape}\")\nbike_data.head(32)","669365c9":"# Show datatype of each column\nbike_data.dtypes","afd6b91f":"numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\nbike_data[numeric_features + ['rentals']].describe()","7b11d7d2":"# Get the label column\nlabel = bike_data['rentals']\n\n# Create a figure for 2 subplots ( 2 rows and 1 column)\nfig, ax = plt.subplots(2, 1, figsize=(9,12))\n\nlegend = \"Mean:\" + format(label.mean(), '.2f') + \", Median:\" + format(label.median(), '.2f') + \", Mode:\" + format(label.mode()[0], '.2f')\n# Plot the histogram\n\"\"\"A histogram displays numerical data by grouping data into \"bins\" of equal width. Each bin is plotted as a bar whose height corresponds to how many data points are in that bin. Bins are also sometimes called \"intervals\", \"classes\", or \"buckets\".\"\"\"\nax[0].hist(label, bins=100, label = legend)\nax[0].set_ylabel('Frequency')\nax[0].legend()\n\n# Add lines for mean median and mode\nax[0].axvline(label.mean(), color= 'magenta', linestyle= 'dashed', linewidth=2)\nax[0].axvline(label.median(), color= 'cyan', linestyle='dashed', linewidth= 2)\nax[0].axvline(label.mode()[0], color= 'red', linestyle='dashed', linewidth= 2)\n\n# Plot the boxplot\nax[1].boxplot(label, vert=False)\nax[1].set_xlabel('Rentals')\n\nfig.suptitle('Rental Distribution')\n\nfig.show()","7ea05c8f":"#Plot histgram for each of the numerical features\nfor col in numeric_features:\n    fig = plt.figure(figsize=(9,6))\n    ax = fig.gca() # To get current axes\n    feature = bike_data[col]\n    feature.hist(bins= 100, ax =ax)\n    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n    ax.axvline(feature.mode()[0], color= 'red', linestyle='dashed', linewidth= 2)\n    \n    title = \"Mean:\" + format(label.mean(), '.2f') + \", Median:\" + format(label.median(), '.2f') + \", Mode:\" + format(label.mode()[0], '.2f')\n    ax.set_title(col + \"(\" + title +\")\")\nplt.show()                     ","129e2c72":"# plot a bar plot for each categorical feature count\ncategorical_features = ['season','mnth','holiday','weekday','workingday','weathersit', 'day']\n\nfor col in categorical_features:\n    counts = bike_data[col].value_counts().sort_index()\n    fig = plt.figure(figsize=(9, 6))\n    ax = fig.gca()  # To get current axes\n    counts.plot.bar(ax = ax, color='steelblue')\n    ax.set_title(col + ' counts')\n    ax.set_xlabel(col) \n    ax.set_ylabel(\"Frequency\")\nplt.show()","435de585":"for col in numeric_features:\n    fig = plt.figure(figsize=(9, 6))\n    ax = fig.gca() # To get current axes\n    feature = bike_data[col]\n    label = bike_data['rentals']\n    correlation = feature.corr(label)\n    plt.scatter(x=feature, y=label)\n    plt.xlabel(col)\n    plt.ylabel('Bike Rentals')\n    ax.set_title('rentals vs ' + col + '- correlation: ' + str(correlation))\nplt.show()","4ffc96f8":"# plot a boxplot for the label by each categorical feature\nfor col in categorical_features:\n    fig = plt.figure(figsize=(9, 6))\n    ax = fig.gca() # To get current axis\n    bike_data.boxplot(column = 'rentals', by = col, ax = ax)\n    ax.set_title('Label by ' + col)\n    ax.set_ylabel(\"Bike Rentals\")\nplt.show()","990d1622":"# Separate features and labels\nX = bike_data[['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values\ny = bike_data['rentals'].values\n\nprint(f'Features: {X[:5]}, \\nLabels: {y[:5]}')","3805b253":"from sklearn.model_selection import train_test_split\n\n# Split data 70%-30% into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 0)\nprint (f'X_train: {X_train.shape} \\nX_test: {X_test.shape} \\ny_train: {y_train.shape} \\ny_test: {y_test.shape}')","7cc56d1a":"from sklearn.linear_model import LinearRegression\n\n# Fit the linear regression on the training set\nmodel = LinearRegression().fit(X_train, y_train)\nprint(model)","8308581c":"predictions = model.predict(X_test)\nnp.set_printoptions(suppress=True) # suppress = True, suppresses the use of scientific notation for small numbers\n\nprint(f'Predicted labels: {np.round(predictions)[:10]}')\nprint(f'Actaul labels: {y_test[:10]}')","4a273961":"plt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, \u2026 0.\np = np.poly1d(z) # Define the polynimial function\nprint(f'Polynomial function: {p}')\nplt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\nplt.show()","1959cd05":"from sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, predictions)\nprint(f'MSE: {mse}')\n\nrmse = np.sqrt(mse)\nprint(f'RMSE: {rmse}')\n\nr2 = r2_score(y_test, predictions)\nprint(f'R2: {r2}')","76b72fa6":"from sklearn.linear_model import Lasso\n\n# Fit Lasso model on training set\nmodel = Lasso().fit(X_train, y_train)\nprint(model)\n\n# Evaluate the model using text data\npredictions = model.predict(X_test)\n\nmse = mean_squared_error(y_test, predictions)\nprint(f'MSE: {mse}')\n\nrmse = np.sqrt(mse)\nprint(f'RMSE: {rmse}')\n\nr2 = r2_score(y_test, predictions)\nprint(f'R2: {r2}')\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, \u2026 0.\np = np.poly1d(z) # Define the polynimial function\nprint(f'Polynomial function: {p}')\nplt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\nplt.show()","6dafb2a5":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import export_text\n\n# Fit decistion tree model on training set alos known as model training\nmodel = DecisionTreeRegressor().fit(X_train, y_train)\nprint(model)\n\n# Visualize the model tree\ntree = export_text(model)\nprint(tree)","3eced2c1":"# Evaluate the model using the test data\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(f'MSE: {mse}')\nrmse = np.sqrt(mse)\nprint(f'RMSE: {rmse}')\nr2 = r2_score(y_test, predictions)\nprint(f'R2: {r2}')\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, \u2026 0.\np = np.poly1d(z) # Define the polynimial function\nprint(f'Polynomial function: {p}')\nplt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\nplt.show()","4f083647":"from sklearn.ensemble import RandomForestRegressor\n\n# Train the model\nmodel = RandomForestRegressor().fit(X_train, y_train)\nprint (model, \"\\n\")\n\n# Evaluate the model using the test data\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(f'MSE: {mse}')\nrmse = np.sqrt(mse)\nprint(f'RMSE: {rmse}')\nr2 = r2_score(y_test, predictions)\nprint(f'R2: {r2}')\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, \u2026 0.\np = np.poly1d(z) # Define the polynimial function\nprint(f'Polynomial function: {p}')\nplt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\nplt.show()","7046c122":"# Train the model\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Fit a lasso model on the training set\nmodel = GradientBoostingRegressor().fit(X_train, y_train)\nprint (model, \"\\n\")\n\n# Evaluate the model using the test data\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(f'MSE: {mse}')\nrmse = np.sqrt(mse)\nprint(f'RMSE: {rmse}')\nr2 = r2_score(y_test, predictions)\nprint(f'R2: {r2}')\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, \u2026 0.\np = np.poly1d(z) # Define the polynimial function\nprint(f'Polynomial function: {p}')\nplt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\nplt.show()","9448fb2f":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, r2_score\n\n# Use a Gradient Boosting algorithm\nalg = GradientBoostingRegressor()\n\n# Try these hyperparameter values\nparams = {\n 'learning_rate': [0.1, 0.5, 1.0],\n 'n_estimators' : [50, 100, 150]\n }\n\n# Find the best hyperparameter combination to optimize the R2 metric\nscore = make_scorer(r2_score)\ngridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\ngridsearch.fit(X_train, y_train)\nprint(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n\n# Get the best model\nmodel=gridsearch.best_estimator_\nprint(model, \"\\n\")\n\n# Evaluate the model using the test data\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\n# overlay the regression line\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","c3ceba3e":"# Train the model\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Define preprocessing for numeric columns (scale them)\nnumeric_features = [6,7,8,9]\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())])\n\n# Define preprocessing for categorical features (encode them)\ncategorical_features = [0,1,2,3,4,5]\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n\n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', GradientBoostingRegressor())])\n\n\n# fit the pipeline to train a linear regression model on the training set\nmodel = pipeline.fit(X_train, (y_train))\nprint (model)","ec9b6fa3":"# Get predictions\npredictions = model.predict(X_test)\n\n# Display metrics\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions')\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","76c19f8c":"# Use a different estimator in the pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', RandomForestRegressor())])\n\n\n# fit the pipeline to train a linear regression model on the training set\nmodel = pipeline.fit(X_train, (y_train))\nprint (model, \"\\n\")\n\n# Get predictions\npredictions = model.predict(X_test)\n\n# Display metrics\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\n# Plot predicted vs actual\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Daily Bike Share Predictions - Preprocessed')\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","caff6f63":"import joblib\n\n# Save the model as a pickle file\nfilename = 'bike-share.pkl'\njoblib.dump(model, filename) # Save it at \/kaggle\/working\/bike-share.pkl","49b19ee8":"# Load the model from the file\nloaded_model = joblib.load('\/kaggle\/working\/bike-share.pkl')\n\n# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\nX_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\nprint ('New sample: {}'.format(list(X_new[0])))\n\n# Use the model to predict tomorrow's rentals\nresult = loaded_model.predict(X_new)\nprint('Prediction: {:.0f} rentals'.format(np.round(result[0])))","d8ac229c":"# An array of features based on five-day weather forecast\nX_new = np.array([[0,1,1,0,0,1,0.344167,0.363625,0.805833,0.160446],\n                  [0,1,0,1,0,1,0.363478,0.353739,0.696087,0.248539],\n                  [0,1,0,2,0,1,0.196364,0.189405,0.437273,0.248309],\n                  [0,1,0,3,0,1,0.2,0.212122,0.590435,0.160296],\n                  [0,1,0,4,0,1,0.226957,0.22927,0.436957,0.1869]])\n\n# Use the model to predict rentals\nresults = loaded_model.predict(X_new)\nprint('5-day rental predictions:')\nfor prediction in results:\n    print(np.round(prediction))","b2c78421":"As you can see from above metrics, there is lots of scope to do better!\n\n## Experiment with Algorithms\nThe linear regression algorithm we used to train the model has some predictive capability, but there are many kinds of regression algorithm we could try, including:\n\n* **Linear algorithms**: Not just the Linear Regression algorithm we used above (which is technically an Ordinary Least Squares algorithm), but other variants such as Lasso and Ridge.\n* **Tree-based algorithms**: Algorithms that build a decision tree to reach a prediction.\n* **Ensemble algorithms**: Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n\n\n### Try Another Linear Algorithm\nLet's try training our regression model by using a Lasso algorithm. We can do this by just changing the estimator in the training code.","b66d6e07":"We've now seen a number of common techniques used to train predictive models for regression. In a real project, you'd likely try a few more algorithms, hyperparameters, and preprocessing transformations; but by now you should have got the general idea. Let's explore how you can use the trained model with new data.\n\n## Use the Trained Model\nFirst, let's save the model.","da14799e":"After separating the dataset, we now have numpy arrays named X containing the features, and y containing the labels. To randomly split the data, we'll use the train_test_split function in the scikit-learn library. This library is one of the most widely used machine learning packages for Python.","db86ed21":"For good measure, let's also try a boosting ensemble algorithm. We'll use a Gradient Boosting estimator, which like a Random Forest algorithm builds multiple trees, but instead of building them all independently and taking the average result, each tree is built on the outputs of the previous one in an attempt to incrementally reduce the loss (error) in the model.","807f3740":"Many of the categorical features show a more or less uniform distribution (meaning there's roughly the same number of rows for each category). Exceptions to this include:\n\n* **holiday**: There are many fewer days that are holidays than days that aren't.\n* **workingday**: There are more working days than non-working days.\n* **weathersit**: Most days are category 1 (clear), with category 2 (mist and cloud) the next most common. There are comparitively few category 3 (light rain or snow) days, and no category 4 (heavy rain, hail, or fog) days at all.\n\nNow that we know something about the distribution of the data in our columns, we can start to look for relationships between the features and the rentals label we want to be able to predict.\n\nFor the numeric features, we can create scatter plots that show the intersection of feature and label values. We can also calculate the correlation statistic to quantify the apparent relationship.","63cbddb5":"### Try a Decision Tree Algorithm\nAs an alternative to a linear model, there's a category of algorithms for machine learning that uses a tree-based approach in which the features in the dataset are examined in a series of evaluations, each of which results in a branch in a decision tree based on the feature value. At the end of each series of branches are leaf-nodes with the predicted label value based on the feature values.\n\nIt's easiest to see how this works with an example. Let's train a Decision Tree regression model using the bike rental data. After training the model, the code below will print the model definition and a text representation of the tree it uses to predict label values.","d90621b2":"Comparing each prediction with its corresponding \"ground truth\" actual value isn't a very efficient way to determine how well the model is predicting. Let's see if we can get a better indication by visualizing a scatter plot that compares the predictions to the actual labels. We'll also overlay a trend line to get a general sense for how well the predicted labels align with the true labels.","e88b6362":"The plots show that the number of daily rentals ranges from 0 to just over 3,400. However, the mean (and median) number of daily rentals is closer to the low end of that range, with most of the data between 0 and around 2,200 rentals. The few values above this are shown in the box plot as small circles, indicating that they are outliers - in other words, unusually high or low values beyond the typical range of most of the data.\n\nWe can do the same kind of visual exploration of the numeric features. Let's create a histogram for each of these.","b5ac37dc":"As you can see columns temp, atemp, hum and windspeech are of 'float64' datatype and label 'rentals' is of 'int64' datatype. We can use pandas **describe** method to generate descriptive statistics for these columns. Please note that columns season, yr, mnth, holiday, weekday\t, workingday, weathersit, day are alos numeric but they represent the categorical data.\n\n**We will use histograms for numeric contnuous values visualization and bar chart of categorical data visualization.**","e4646af4":"> Note: The use of random values in the Gradient Boosting algorithm results in slightly different metrics each time. In this case, the best model produced by hyperparameter tuning is unlikely to be significantly better than one trained with the default hyperparameter values; but it's still useful to know about the hyperparameter tuning technique!\n\n## Preprocess the Data\nWe trained a model with data that was loaded straight from a source file, with only moderately successful results.\n\nIn practice, it's common to perform some preprocessing of the data to make it easier for the algorithm to fit a model to it. \n\n### Scaling numeric features\nThere are multiple ways you can scale numeric data, such as calculating the minimum and maximum values for each column and assigning a proportional value between 0 and 1, or by using the mean and standard deviation of a normally distributed variable to mainatain the same spread of values on a different scale.\n\n### Encoding categorical variables\nMachine learning models work best with numeric features rather than text values, so you generally need to convert categorical features into numeric representations. You can apply ordinal encoding to substitute a unique integer value for each category. Another common technique is to use one hot encoding to create individual binary (0 or 1) features for each possible category value. \n\nTo apply these preprocessing transformations to the bike rental, we'll make use of a Scikit-Learn feature named pipelines. These enable us to define a set of preprocessing steps that end with an algorithm. You can then fit the entire pipeline to the data, so that the model encapsulates all of the preprocessing steps as well as the regression algorithm. This is useful, because when we want to use the model to predict values from new data, we need to apply the same transformations (based on the same statistical distributions and category encodings used with the training data).","32089896":"The tree-based model doesn't seem to have improved over the linear model, so what else could we try?\n\n### Try an Ensemble Algorithm\nEnsemble algorithms work by combining multiple base estimators to produce an optimal model, either by appying an aggregate function to a collection of base models (sometimes referred to a bagging) or by building a sequence of models that build on one another to improve predictive performance (referred to as boosting).\n\nFor example, let's try a Random Forest model, which applies an averaging function to multiple Decision Tree models for a better overall model.","a8220422":"# Introduction\nIn this notebook, we'll focus on regression, using an example based on a real study in which data for a bicycle sharing scheme was collected and used to predict the number of rentals based on seasonality and weather conditions. We'll use a simplified version of the dataset from that study.\n\nNote: This is my study notebook, for original notebook please refer https:\/\/github.com\/satishgunjal\/ml-basics\/blob\/master\/02%20-%20Regression.ipynb\n\n\n# Import Libraries","180471e3":"So now we have a tree-based model; but is it any good? Let's evaluate it with the test data.","64e7ea67":"## Optimize Hyperparameters\nTake a look at the **GradientBoostingRegressor** estimator definition in the output above, and note that it, like the other estimators we tried previously, includes a large number of parameters that control the way the model is trained. In machine learning, the term **parameters** refers to values that can be determined from data; values that you specify to affect the behavior of a training algorithm are more correctly referred to as **hyperparameters**.\n\nThe specific hyperparameters for an estimator vary based on the algorithm that the estimator encapsulates. In the case of the **GradientBoostingRegressor** estimator, the algorithm is an ensemble that combines multiple decision trees to create an overall predictive model. You can learn about the hyperparameters for this estimator in the Scikit-Learn documentation.\n\nWe won't go into the details of each hyperparameter here, but they work together to affect the way the algorithm trains a model. In many cases, the default values provided by Scikit-Learn will work well; but there may be some advantage in modifying hyperparameters to get better predictive performance or reduce training time.\n\nSo how do you know what hyperparameter values you should use? Well, in the absence of a deep understanding of how the underlying algorithm works, you'll need to experiment. Fortunately, SciKit-Learn provides a way to tune hyperparameters by trying multiple combinations and finding the best result for a given performance metric.\n\nLet's try using a **grid search** approach to try combinations from a grid of possible values for the **learning_rate** and **n_estimators****** hyperparameters of the **GradientBoostingRegressor** estimator.","1cd8e250":"The numeric features seem to be more normally distributed, with the mean and median nearer the middle of the range of values, coinciding with where the most commonly occurring values are. \n\nWe've explored the distribution of the numeric values in the dataset, but what about the categorical features? These aren't continuous numbers on a scale, so we can't use histograms; but we can plot a bar chart showing the count of each discrete value for each category.","f9ebf2fd":"Now, we can load it whenever we need it, and use it to predict labels for new data. This is often called scoring or inferencing.","c94b849e":"# Challenge: Predict Real Estate Prices\nThink you're ready to create your own regression model? Try the challenge of predicting real estate property prices in the [\/challenges\/02 - Real Estate Regression Challenge.ipynb](https:\/\/render.githubusercontent.com\/view\/challenges\/02%20-%20Real%20Estate%20Regression%20Challenge.ipynb) notebook!","ced66071":"We can see that the mean number of daily rentals is around 848; but there's a comparatively large standard deviation, indicating a lot of variance in the number of rentals per day. To understand it better lets visulaize the rentals data.\n\n","cfffcb07":"## Evaluate the Trained Model\nNow that we've trained the model, we can use it to predict rental counts for the features we held back in our validation dataset (X_test). Then we can compare these predictions to the actual label values to evaluate how well (or not!) the model is working.","e82848c7":"# Explaore the Data\nThe data consists of the following columns:\n\n* instant: A unique row identifier\n* dteday: The date on which the data was observed - in this case, the data was collected daily; so there's one row per date.\n* season: A numerically encoded value indicating the season (1:spring, 2:summer, 3:fall, 4:winter)\n* yr: The year of the study in which the observation was made (the study took place over two years - year 0 represents 2011, and year 1 represents 2012)\n* mnth: The calendar month in which the observation was made (1:January ... 12:December)\n* holiday: A binary value indicating whether or not the observation was made on a public holiday)\n* weekday: The day of the week on which the observation was made (0:Sunday ... 6:Saturday)\n* workingday: A binary value indicating whether or not the day is a working day (not a weekend or holiday)\n* weathersit: A categorical value indicating the weather situation (1:clear, 2:mist\/cloud, 3:light rain\/snow, 4:heavy rain\/hail\/snow\/fog)\n* temp: The temperature in celsius (normalized)\n* atemp: The apparent (\"feels-like\") temperature in celsius (normalized)\n* hum: The humidity level (normalized)\n* windspeed: The windspeed (normalized)\n* rentals: The number of bicycle rentals recorded.\n\nIn this dataset, rentals represents the label (the y value) our model must be trained to predict. The other columns are potential features (x values).\n\nAs part of feature engineering we are going to add a new column named **day** to the dataframe by extracting the day component from the existing **dteday** column. The new column represents the day of the month from 1 to 31.","56013402":"The pipeline is composed of the transformations and the algorithm used to train the model. To try an alternative algorithm you can just change that step to a different kind of estimator.","ca208fd9":"We'll use the a linear regression algorithm, a common starting point for regression that works by trying to find a linear relationship between the X values and the y label. The resulting model is a function that conceptually defines a line where every possible X and y value combination intersect.\n\nIn Scikit-Learn, training algorithms are encapsulated in estimators, and in this case we'll use the LinearRegression estimator to train a linear regression model.","64aa356f":"OK, the model is trained, including the preprocessing steps. Let's see how it performs with the validation data.","a913526f":"The model's predict method accepts an array of observations, so you can use it to generate multiple predictions as a batch. For example, suppose you have a weather forecast for the next five days; you could use the model to predict bike rentals for each day based on the expected weather conditions.","09bdfabd":"The plots show some variance in the relationship between some category values and rentals. For example, there's a clear difference in the distribution of rentals on weekends (0 or 6) and those during the working week (weekday 1 to 5). Similarly, there are notable differences for holiday and workingday categories. There's a noticable trend that shows different rental distributions in summer and fall months compared to spring and winter months. The weathersit category also seems to make a difference in rental distribution. The day feature we created for the day of the month shows little variation, indicating that it's probably not predictive of the number of rentals.\n\n# Train a Regression Model\n\nNow that we've explored the data, it's time to use it to train a regression model that uses the features we've identified as potentially predictive to predict the rentals label. The first thing we need to do is to separate the features we want to use to train the model from the label we want it to predict.\n","186d4cee":"The results aren't conclusive, but if you look closely at the scatter plots for temp and atemp, you can see a vague diagonal trend showing that higher rental counts tend to coincide with higher temperatures; and a correlation value of just over 0.5 for both of these features supports this observation. Conversely, the plots for hum and windspeed show a slightly negative correlation, indicating that there are fewer rentals on days with high humidity or windspeed.\n\nNow let's compare the categorical features to the label. We'll do this by creating box plots that show the distribution of rental counts for each category.","37117c6d":"There's a definite diagonal trend, and the intersections of the predicted and actual values are generally following the path of the trend line; but there's a fair amount of difference between the ideal function represented by the line and the results. This variance represents the residuals of the model - in other words, the difference between the label predicted when the model applies the coefficients it learned during training to the validation data, and the actual value of the validation label. These residuals when evaluated from the validation data indicate the expected level of error when the model is used with new data for which the label is unknown.\n\nYou can quantify the residuals by calculating a number of commonly used evaluation metrics. We'll focus on the following three:\n\n* **Mean Square Error (MSE)**: The mean of the squared differences between predicted and actual values. This yields a relative metric in which the smaller the value, the better the fit of the model\n* **Root Mean Square Error (RMSE)**: The square root of the MSE. This yields an absolute metric in the same unit as the label (in this case, numbers of rentals). The smaller the value, the better the model (in a simplistic sense, it represents the average number of rentals by which the predictions are wrong!)\n* **Coefficient of Determination (usually known as R-squared or R2**: A relative metric in which the higher the value, the better the fit of the model. In essence, this metric represents how much of the variance between predicted and actual label values the model is able to explain.\n\nLet's use Scikit-Learn to calculate these metrics for our model, based on the predictions it generated for the validation data.","5603f91b":"# Load the Data"}}