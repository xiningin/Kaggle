{"cell_type":{"f2eff3f9":"code","b6555993":"code","c6c19a76":"code","752742c2":"code","e7eced34":"code","35a104b5":"code","77ca45bc":"code","ca67d753":"code","59d268cf":"markdown"},"source":{"f2eff3f9":"# External input from full train dfdc_train_part_0\n!ls -l \/kaggle\/input\/strange-video","b6555993":"import argparse\nimport sys\nimport os\nimport cv2\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nINPUT_ROOT = \"\/kaggle\/input\/strange-video\"\n\n# Strange sample\nFAKE_NAME = \"owxbbpjpch.mp4\"\nSAMPLE_FAKE1 = INPUT_ROOT + os.sep + FAKE_NAME\nSAMPLE_ORG1 = INPUT_ROOT + os.sep + \"wynotylpnm.mp4\"","c6c19a76":"# Expand white area above threshold\ndef enhance(fgmask, ek, dk):\n    kernel = np.ones((ek, ek), np.uint8)\n    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n    kernel = np.ones((dk, dk), np.uint8)\n    fgmask = cv2.dilate(fgmask, kernel, iterations=1)\n    return fgmask","752742c2":"# Differences between Fake and Real by Frame\ndef _get_background_subtraction(image1, image2):\n    fgbg = cv2.createBackgroundSubtractorMOG2()\n    fgbg.apply(image1)\n    fgmask = fgbg.apply(image2)\n    fgmask = enhance(fgmask, 3, 11)\n    fgmask = enhance(fgmask, 22, 31)\n    return fgmask","e7eced34":"# Differences between Fake and Real by Video\ndef video_diff(org, fake, out):\n    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n    corg = cv2.VideoCapture(org)\n    cfake = cv2.VideoCapture(fake)\n    writer = None\n    mask_writer = None\n    while True:\n        cret, forg = corg.read()\n        fret, ffake = cfake.read()\n        if not cret or not fret:\n            print(\"end\")\n            break\n        diff = _get_background_subtraction(forg, ffake)\n        cimg = cv2.hconcat([forg, ffake, cv2.cvtColor(diff, cv2.COLOR_GRAY2RGB)])\n        cimg = cv2.resize(cimg, (int(cimg.shape[1]\/4), int(cimg.shape[0]\/4)))\n        if writer is None:\n            writer = cv2.VideoWriter(\"blend_{}.mp4\".format(out), fourcc, 30, (cimg.shape[1], cimg.shape[0]))\n            mask_writer = cv2.VideoWriter(\"mask_{}.MOV\".format(out), fourcc, 30, (diff.shape[1], diff.shape[0]))\n        writer.write(cimg)\n        mask_writer.write(cv2.cvtColor(diff, cv2.COLOR_GRAY2RGB))","35a104b5":"video_diff(SAMPLE_ORG1, SAMPLE_FAKE1, FAKE_NAME.split(\".\")[0])","77ca45bc":"!ls -l \/kaggle\/working","ca67d753":"blend = cv2.VideoCapture(\"\/kaggle\/working\/blend_owxbbpjpch.mp4\")\nblend.set(0,5*1000)\n_, f = blend.read()\nplt.imshow(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\nplt.show()\nblend.set(0,6*1000)\n_, f = blend.read()\nplt.imshow(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\nplt.show()\nblend.set(0,7*1000)\n_, f = blend.read()\nplt.imshow(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\nplt.show()\nblend.set(0,8*1000)\n_, f = blend.read()\nplt.imshow(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\nplt.show()","59d268cf":"# Need to locate the face?\nI am considering an approach without face detection. It simply analyzes the behavior of Fake using the difference between Fake and Original as Ground Truth.<br>\nHowever, areas of no interest are included in the difference between Fake and Original because of Fake noise.\nThose areas of no interest are removed by \"Erode and Delite\".<br>\nI applied this process to a strange sample.In this video, Fake moves slowly from the chest to the face.....\n"}}