{"cell_type":{"3623d88c":"code","a233b62c":"code","bee7e1b8":"code","3067adc7":"code","3505f284":"code","e30e16a9":"code","1799a1a9":"code","f99ff0e6":"code","d0766c6a":"code","565a2ce5":"code","d86e40c7":"code","8635634d":"markdown","077c77cd":"markdown","c0d6e267":"markdown","ef2bd49f":"markdown","7709b84f":"markdown","35b9ab88":"markdown","3556fe94":"markdown","d8b0fbf5":"markdown","b3e5517a":"markdown","9077a6c7":"markdown","70b4a6c1":"markdown"},"source":{"3623d88c":"import numpy as np\nimport pandas as pd\nfrom pandas import read_csv\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport itertools\nimport graphviz \nimport json\nimport time\nimport gc\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom collections import Counter\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve, StratifiedKFold, train_test_split\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\nimport networkx as nx\nimport warnings\n%matplotlib inline\ninit_notebook_mode(connected=True)\nwarnings.filterwarnings(\"ignore\")\nnotebookstart= time.time()","a233b62c":"train_df = pd.read_json('..\/input\/train.json')\ntest_df = pd.read_json('..\/input\/test.json')\ntrain=train_df\ntrain.head(15)","bee7e1b8":"train=train_df\ntotal = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum()\/train.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total missing', 'Percent missing'])\nprint(\"             # of Rows, Columns:\",train.shape)\nprint(missing_train_data.head())","3067adc7":"# adapted from https:\/\/www.kaggle.com\/ashishpatel26\/scrumptious-cooking-foods\ncolor_theme = dict(color = ['rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)',\n                   'rgba(188,143,143,1)','rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(189,183,107,1)','rgba(188,143,143,1)','rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(169,169,169,1)','rgba(255,160,122,1)'])\ntemp = train['cuisine'].value_counts()\ntrace = go.Bar(y=temp.index[::-1],x=(temp)[::-1],orientation = 'h',marker=color_theme)\nlayout = go.Layout(title = \"Count of recipes per cuisine\",xaxis=dict(title='Recipe count',tickfont=dict(size=14,)),\n                   yaxis=dict(title='Cuisine',titlefont=dict(size=16),tickfont=dict(size=14)),margin=dict(l=200,))\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig,filename='basic-bar')","3505f284":"# adapted from https:\/\/www.kaggle.com\/ash316\/what-is-the-rock-cooking-ensembling-network\ntrain_df['seperated_ingredients'] = train_df['ingredients'].apply(','.join)\ntest_df['seperated_ingredients'] = test_df['ingredients'].apply(','.join)\ntrain_df['for ngrams']=train_df['seperated_ingredients'].str.replace(',',' ')\ndef generate_ngrams(text, n):\n    words = text.split(' ')\n    iterations = len(words) - n + 1\n    for i in range(iterations):\n       yield words[i:i + n]\ndef net_diagram(*cuisines):\n    ngrams = {}\n    for title in train_df[train_df.cuisine==cuisines[0]]['for ngrams']:\n            for ngram in generate_ngrams(title, 2):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df.columns = ['count']\n    ngrams_mws_df['cusine'] = cuisines[0]\n    ngrams_mws_df.reset_index(level=0, inplace=True)\n\n    ngrams = {}\n    for title in train_df[train_df.cuisine==cuisines[1]]['for ngrams']:\n            for ngram in generate_ngrams(title, 2):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df1 = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df1.columns = ['count']\n    ngrams_mws_df1['cusine'] = cuisines[1]\n    ngrams_mws_df1.reset_index(level=0, inplace=True)\n    cuisine1=ngrams_mws_df.sort_values('count',ascending=False)[:25]\n    cuisine2=ngrams_mws_df1.sort_values('count',ascending=False)[:25]\n    df_final=pd.concat([cuisine1,cuisine2])\n    g = nx.from_pandas_dataframe(df_final,source='cusine',target='index')\n    cmap = plt.cm.RdYlGn\n    colors = [n for n in range(len(g.nodes()))]\n    k = 0.35\n    pos=nx.spring_layout(g, k=k)\n    nx.draw_networkx(g,pos, node_size=df_final['count'].values*8, cmap = cmap, node_color=colors, edge_color='grey', font_size=15, width=3)\n    plt.title(\"Top 25 Bigrams for %s and %s\" %(cuisines[0],cuisines[1]), fontsize=30)\n    plt.gcf().set_size_inches(30,30)\n    plt.show()\n    plt.savefig('network.png')\nnet_diagram('french','cajun_creole')","e30e16a9":"# adapted from https:\/\/www.kaggle.com\/nicapotato\/this-model-is-bland-simple-logistic-starter\ndf = pd.read_json('..\/input\/train.json').set_index('id')\ntest_df = pd.read_json('..\/input\/test.json').set_index('id')\ntraindex = df.index\ntestdex = test_df.index\ny = df.cuisine.copy()\ndf = pd.concat([df.drop(\"cuisine\", axis=1), test_df], axis=0)\ndf_index = df.index\ndel test_df; gc.collect();\nvect = CountVectorizer()\ndummies = vect.fit_transform(df.ingredients.str.join(' '))\ndf = pd.DataFrame(dummies.todense(),columns=vect.get_feature_names())\ndf.index= df_index\nX = df.loc[traindex,:]\ntest_df = df.loc[testdex,:]\ndel df; gc.collect();","1799a1a9":"# adapted from https:\/\/www.kaggle.com\/shivamb\/what-s-cooking-tf-idf-with-ovr-svm\ndef read_dataset(path):\n    return json.load(open(path)) \ntrain = read_dataset('..\/input\/train.json')\ntest = read_dataset('..\/input\/test.json')\ndef generate_text(data):\n    text_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n    return text_data \ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n        x = tfidf.fit_transform(txt)\n    else:\n        x = tfidf.transform(txt)\n    x = x.astype('float16')\n    return x \nX2 = tfidf_features(train_text, flag=\"train\")\nX_test3 = tfidf_features(test_text, flag=\"test\")\nlb = LabelEncoder()\ny2 = lb.fit_transform(target)","f99ff0e6":"# adapted from https:\/\/machinelearningmastery.com\/compare-machine-learning-algorithms-python-scikit-learn\/\ndef compareAccuracy(a, b): \n    print('\\nCompare Multiple Classifiers: \\n')\n    print('K-Fold Cross-Validation Accuracy: \\n')\n    names = []\n    models = []\n    resultsAccuracy = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('RF', RandomForestClassifier()))\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n        resultsAccuracy.append(accuracy_results)\n        names.append(name)\n        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n        print(accuracyMessage) \n    # Boxplot\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: Accuracy')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsAccuracy)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: Accuracy Score')\n    plt.show()    \n      \ndef defineModels():\n    print('\\nLR = LogisticRegression')\n    print('LSVM = LinearSVM')\n    print('RF = RandomForestClassifier')","d0766c6a":"compareAccuracy(X,y)\ndefineModels()","565a2ce5":"compareAccuracy(X2,y2)\ndefineModels()","d86e40c7":"model = LinearSVC()\nmodel.fit(X, y)\nsubmission = model.predict(test_df)\nsubmission_df = pd.Series(submission, index=testdex).rename('cuisine')\nsubmission_df.to_csv(\"recipe_submission.csv\", index=True, header=True)\nmodel.fit(X2, y2)\ny_test3 = model.predict(X_test3)\ny_pred = lb.inverse_transform(y_test3)\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('recipe_submission2.csv', index=False)","8635634d":"*Step 3: Feature Engineering*","077c77cd":"Evaluate Method 2 of 2 ([TfidVectorizer](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html)) with Logistic Regression, Linear SVM, and Random Forest models.\n","c0d6e267":"Evaluate Method 1 of 2 ([CountVectorizer](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html)) with Logistic Regression, Linear SVM, and Random Forest models.","ef2bd49f":"*Step 5: Submit Results*","7709b84f":"*Step 1: Import Python Packages*","35b9ab88":"**Predict cuisine type from recipe ingedients**","3556fe94":"*Step 4: Evaluate ML Models*","d8b0fbf5":"*Step 2: Exploratory Data Analysis*","b3e5517a":"For submission we will use an approach that uses [CountVectorizer](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html)() for engineering features and [LinearSVM](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html)() for making predictions. ","9077a6c7":"* Method 1 of 2: [CountVectorizer](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html)","70b4a6c1":"* Method 2 of 2: [TfidVectorizer](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html)"}}