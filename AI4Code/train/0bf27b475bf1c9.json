{"cell_type":{"8748e48b":"code","07cdfc30":"code","44eb3b74":"code","69092123":"code","5365515d":"code","176452cf":"code","05116cad":"code","7e54b9ea":"code","cdee3a79":"code","4683870f":"code","bad6b2df":"code","ec1d4502":"code","ea2ad35b":"code","8e2ce942":"code","02289cd6":"code","2213fe6a":"code","0e022132":"code","01c2d303":"code","1af3b3ad":"code","59614a88":"code","4f46baee":"code","fe073ee0":"markdown","f620378d":"markdown","99ecc26e":"markdown","3bc64263":"markdown","3232a804":"markdown"},"source":{"8748e48b":"!pip uninstall --y kaggle\n!pip install --upgrade pip\n!pip install kaggle==1.5.6","07cdfc30":"!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\n!ls -lha kaggle.json\n!chmod 600 ~\/.kaggle\/kaggle.json","44eb3b74":"!kaggle competitions download -c 18011765watermelon-price","69092123":"!unzip 18011765watermelon-price.zip","5365515d":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.nn as nn \nimport torch.optim as optim","176452cf":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntorch.manual_seed(777)\nif device == 'cuda':\n    torch.cuda.manual_seed_all(777)","05116cad":"train = pd.read_csv('train_water_melon_price.csv')\nprint(train.head(10))\nprint(train.info())","7e54b9ea":"test = pd.read_csv('test_watermelon_price.csv')\nprint(test.head(10))\nprint(test.info())","cdee3a79":"learning_rate = 0.01\ntraining_epoch = 2000\nbatch_size = 50","4683870f":"x_train = train.iloc[:,1:-1]\ny_train = train.iloc[:,[-1]]\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nx_train = torch.FloatTensor(x_train)\ny_train = torch.FloatTensor(y_train)\n\nprint(x_train.shape)\nprint(y_train.shape)","bad6b2df":"train_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n\n","ec1d4502":"class MishFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        x = ctx.saved_variables[0]\n        sigmoid = torch.sigmoid(x)\n        tanh_sp = torch.tanh(F.softplus(x)) \n        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n\nclass Mish(nn.Module):\n    def forward(self, x):\n        return MishFunction.apply(x)\n\ndef to_Mish(model):\n    for child_name, child in model.named_children():\n        if isinstance(child, nn.ReLU):\n            setattr(model, child_name, Mish())\n        else:\n            to_Mish(child)","ea2ad35b":"linear1 = nn.Linear(7,8,bias=True)\nlinear2 = nn.Linear(8,8,bias=True)\nlinear3 = nn.Linear(8,8,bias=True)\nlinear4 = nn.Linear(8,8,bias=True)\nlinear5 = nn.Linear(8,1,bias=True)\nmish = Mish() # activation function\n","8e2ce942":"nn.init.kaiming_normal_(linear1.weight)\nnn.init.kaiming_uniform_(linear2.weight)\nnn.init.kaiming_uniform_(linear3.weight)\nnn.init.kaiming_normal_(linear4.weight)\nnn.init.kaiming_uniform_(linear5.weight)\n","02289cd6":"model = torch.nn.Sequential(\n    linear1,mish,\n    linear2,mish,\n    linear3,mish,\n    linear4,mish,\n    linear5\n).to(device)","2213fe6a":"loss = nn.MSELoss().to(device)\noptimizer = optim.Adam(model.parameters(),lr=learning_rate)","0e022132":"total_batch = len(data_loader)\n\nfor epoch in range(training_epoch):\n    avg_cost = 0\n    for X,Y in data_loader:\n        X = X.to(device)\n        Y = Y.to(device)\n\n        optimizer.zero_grad()\n        hypothesis = model(X)\n        cost = loss(hypothesis,Y)\n        cost.backward()\n        optimizer.step()\n\n\n        avg_cost += cost\/total_batch\n    \n    if epoch % 10 == 0:  \n        print('Epoch:', '%d' % (epoch ), 'Cost =', '{:.9f}'.format(avg_cost))\nprint('Learning Finished')","01c2d303":"test_data = test.iloc[:,1:]\ntest_data = np.array(test_data)\ntest_data = torch.FloatTensor(test_data).to(device)\n\nwith torch.no_grad():\n    predict = model(test_data)\n\npredict","1af3b3ad":"correct_prediction = predict.cpu().numpy().reshape(-1,1)","59614a88":"submit = pd.read_csv('submit_sample.csv')\nfor i in range(len(correct_prediction)):\n  submit['Expected'][i]=correct_prediction[i].item()\nsubmit.to_csv('submit.csv', mode = 'w', index = False, header = True)\nsubmit\n","4f46baee":"!kaggle competitions submit -c 18011765watermelon-price -f submit.csv -m \"14010974_\uc774\uae30\ud0dd\"","fe073ee0":"> \ub77c\uc774\ube0c\ub7ec\ub9ac \uc784\ud3ec\ud2b8","f620378d":"> \ubaa8\ub378 \uc124\uacc4","99ecc26e":"> \ubaa8\ub378 \ud559\uc2b5","3bc64263":"> Train,Test \ub370\uc774\ud130 \ub85c\ub4dc","3232a804":"Mish Activation Function - [Mish \ub17c\ubb38 \ub9c1\ud06c](https:\/\/arxiv.org\/abs\/1908.08681)"}}