{"cell_type":{"2d0c527d":"code","f5b98a38":"code","f0a75dca":"code","81eab6e9":"code","5aab72e3":"code","8cd41ee7":"code","ed255947":"code","9d245eab":"code","c3aa46c1":"code","27116f1d":"code","ed502540":"code","1440d42b":"code","18e01bde":"code","2d08aebe":"code","446ec66e":"code","06fd6231":"markdown"},"source":{"2d0c527d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, ZeroPadding2D, Input\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\n\n%matplotlib inline\n\npd.set_option(\"display.max_rows\", 6)\n\nnp.random.seed(2)","f5b98a38":"!ls ..\/input","f0a75dca":"# Load the data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ntrain_X = (train.iloc[:,:-1]\/255).values.copy()\ntrain_y = (train['label']).values.copy()\ntest = (test\/255).values.copy()\n\nprint(train_X.shape)\nprint(train_y.shape)\nprint(test.shape)\n","81eab6e9":"train_X = np.reshape(train_X, (42000, 28,28,1))\nnew_X = np.zeros((42000,28,28,3))\nfor i in range(len(new_X)):\n    tmp = np.stack((train_X[i],)*3, axis=-1)\n    new_X[i] = np.resize(tmp, (28,28,3))\ntrain_X = new_X\n\n\ntest = np.reshape(test, (28000, 28,28,1))\nnew_X = np.zeros((28000,28,28,3))\nfor i in range(len(new_X)):\n    tmp = np.stack((test[i],)*3, axis=-1)\n    new_X[i] = np.resize(tmp, (28,28,3))\ntest = new_X\n\n\nfrom keras.utils import to_categorical\ntrain_y = to_categorical(train_y, num_classes=10)\n","5aab72e3":"batch_size = 4\ndatagen = ImageDataGenerator(\n    validation_split=.2,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    fill_mode='nearest')\n\ntrain_generator = datagen.flow(\n        train_X,\n        train_y,\n        shuffle=True,\n        subset='training',\n        batch_size=batch_size,)\nval_generator = datagen.flow(\n        train_X,\n        train_y,\n        subset='validation',\n        batch_size=batch_size,)\n\n","8cd41ee7":"\nplt.figure(figsize=(15,10)) \nfor X_batch, y_batch in train_generator:\n    for i in range(0, 4):\n        plt.subplot(220 + 1 + i)\n        plt.imshow(X_batch[i].reshape(28,28,3), cmap=plt.get_cmap('gray'))\n    plt.show()\n    break\n#g = plt.imshow(train_X[0][:,:,0])","ed255947":"\nconv_base = VGG16(#weights='imagenet',\n                  include_top=False,\n                  input_shape=(36, 36, 3))\n\n#for layer in conv_base.layers[:-4]:\n#   layer.trainable = False\n#for layer in conv_base.layers:\n#    print(layer, layer.trainable)\n","9d245eab":"\nfor layer in conv_base.layers:\n   layer.trainable = True\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(padding=(32-28, 32-28), input_shape=(28,28,3)))\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n","c3aa46c1":"from keras.optimizers import SGD, Adam\n\n# I manually change the lr to 1e-3 when it gets stuck on .98\nmodel.compile(optimizer=SGD(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","27116f1d":"from keras.models import load_model\n\nmodel = load_model('vgg16_dense.h5')","ed502540":"epochs = 1 # change epochs to improve\n\nmodel.fit_generator(train_generator, \n                    validation_data=val_generator, \n                    validation_steps=(42000*.2)\/\/batch_size, \n                    epochs=epochs, \n                    steps_per_epoch=(42000-42000*.2)\/\/batch_size)\n","1440d42b":"model.save('vgg16_dense.h5')","18e01bde":"pred = model.predict(test)\npred.shape","2d08aebe":"plt.figure(figsize=(4,4)) \nplt.imshow(test[100].reshape(28,28,3), cmap=plt.get_cmap('gray'))\n","446ec66e":"out_label = [ np.argmax(i) for i in pred]\nout_imageid = [ i+1 for i in range(len(test))]\nout = pd.DataFrame()\nout['ImageId'] = out_imageid\nout['Label'] = out_label\n\nout.to_csv('submission.csv', index=False)\nout","06fd6231":"# VGG16 trained from scratch: 0.99600\n\nHere I use a VGG16 CNN from Keras. In a first attempt, I just removed the top Dense layer and added mine, keeping all the base model frozen, but results were poor. Then I unfrozen the last 4 layers but still the VGG16 performed around `0.98`, which was not enough to beat another model I made in the past weeks.\n\nSo I unfrozen all the network and trained it all for a few epochs to `0.99342` on validation set, reaching the same score on the leaderboard. I manually tuned the learning rate from `1e-02` to `1e-03` when it reached a plateau. I plan to add a Callback to automate this process.\n\nImportant:  I used Keras ImageDataGenerator to augment data with some basic manipulations and used 36x36 input shape for VGG16.\n\nAny advice is welcome!"}}