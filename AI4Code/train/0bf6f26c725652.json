{"cell_type":{"becfe9f3":"code","c857791e":"code","0f4c8e83":"code","a13088e9":"code","5e608c0f":"code","4051a4a9":"code","0f492074":"code","c2afbf7f":"code","4ec00abc":"code","14fb0884":"code","f4cfe520":"code","b6c4333a":"markdown","7889a10c":"markdown","69363c37":"markdown","3ad6a08d":"markdown","58df1d33":"markdown","9fe31740":"markdown","4d6b3c05":"markdown","f83ba2da":"markdown","2557d8bd":"markdown"},"source":{"becfe9f3":"import requests # for getting web contents\nfrom bs4 import BeautifulSoup # for scraping web contents\nimport pandas as pd # for data analysis","c857791e":"# link of web page that you want to scrap data\nURL = ''\n\n# get web data\npage = requests.get(URL)\n\n# parse web data\nsoup = BeautifulSoup(page.content, \"html.parser\")","0f4c8e83":"# find the table\n# our trageted table is last\n\n# getting the table head because it may contains headings (column names)\nhtml_thead = soup.find_all('thead')[-1]\n\n#getting all the rows in table head\nhtml_tr = [tr for tr in html_thead.find_all('tr')]\n\n# list to store all table headings\nheadings = []\n\n# loop through table head\nfor tr in html_tr:\n    # getting all th\n    th = tr.find_all(['th'])\n    # storing all th value in row and removing white space\n    row = [i.text.strip() for i in th]\n    # append headings \n    headings.append(row)\n    \n# print heading\nprint(headings)","a13088e9":"# getting the table body\nhtml_tbody = soup.find_all('tbody')[-1]\n\n#getting all the rows in table body\nhtml_text = [tr for tr in html_tbody.find_all('tr')]\n\n# list to store all content\ncontent = []\n\n# loop through table body\nfor tr in html_text:\n    # getting all th, td\n    th = tr.find_all(['th','td'])\n    # storing all th value in row and removing white space\n    row = [i.text.strip() for i in th]\n    # append content \n    content.append(row)\n    \n# print content\nprint(content)","5e608c0f":"# save contents in a dataframe\ndata = pd.DataFrame(content[:], columns=headings[0])","4051a4a9":"# check few top rows of data\ndata.head()","0f492074":"# getting Generate descriptive statistics of data. Generate descriptive statistics include count, mean, std, min_value, 25%, 50%, 75%, max_value\ndata.describe()","c2afbf7f":"# get the column labels of the data.\ndata.columns","4ec00abc":"# rename column name if required\ndata = data.rename(columns={'First Column Name':'New Name', 'Second Column Name':'New Name'})","14fb0884":"# remove extra characters from columns\ndata['column name'] = data['column name'].str.replace('%','')\ndata['column name'] = data['column name'].str.replace(',','')","f4cfe520":"# save data\ndata.to_csv('fileName.csv', index=False)","b6c4333a":"## Data Analysis\n### Look at Example Records","7889a10c":"## URL\nFor web scrapping it's important to have url.","69363c37":"### Descriptive Statistics","3ad6a08d":"### # data info\ndata.info()Summary of data-type, columns, non-null values, memory usage.","58df1d33":"### Column labels","9fe31740":"## Import Libraries\nImporting libraries are necessary for any project. We're going to import commonly used Webscrapping and Data Analysis libraries. Make sure all libraries are installed.\n","4d6b3c05":"## Data Cleaning\n### Rename Column Name","f83ba2da":"### Remove unwanted symbols (like % and thousand comma from integer)","2557d8bd":"## Save Data into CSV"}}