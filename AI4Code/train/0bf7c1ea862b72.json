{"cell_type":{"e56b68ed":"code","6530437c":"code","a5ceec52":"code","3960fbca":"code","70d72891":"code","4060653f":"code","beb4d4e2":"code","2af0ad90":"code","394badb6":"code","00d95126":"code","16681035":"code","8f9c47ec":"code","b0da9743":"code","47832edb":"code","6877de46":"code","0744a20a":"code","6d16ccd7":"code","987f8b0f":"code","9908a68c":"code","d56342f6":"code","d177a152":"code","5646b9c7":"code","8fc5feea":"code","aa542b22":"code","7ca6549f":"code","d1fda9d6":"code","e20b1cba":"code","556347af":"code","2ca7bbdf":"code","19affccb":"code","1dc91bc1":"code","85f2a874":"code","c8e116af":"code","5282bd50":"code","c30ec2a6":"code","891cb479":"code","f8753ca6":"code","6cfff39e":"code","b30b3d0c":"code","c2512393":"code","84425a91":"code","ee078a1c":"code","c5f10017":"code","b139891a":"code","4f0b69fa":"code","8ea92be4":"code","f95f2fee":"code","e2b4d06c":"code","efc2b113":"code","321fb50e":"code","9c16f210":"code","905b62f8":"code","f58a4d94":"code","fe04625c":"code","1e3c8b75":"code","8e5287c1":"code","d1f41a43":"code","c8fe70e0":"code","9c2d1b77":"code","d69b61e5":"code","87879b1a":"code","1f13bfed":"code","caa2fe46":"code","e906099c":"code","b8ace464":"code","50707833":"code","e0e3bf0e":"code","e705ff32":"code","afdbf2c2":"code","095d6002":"code","0c71c8b3":"code","df804b9f":"code","be247a28":"code","0516d099":"code","e12cf45d":"code","84fdfb0b":"code","cb6a85f5":"code","2fc6583a":"code","3a9e612d":"code","1efac9a9":"code","806a662e":"code","416caea4":"code","3871a942":"code","2f25b527":"code","194b18bc":"code","0b43ab6d":"code","af6e9c63":"code","6c410cf6":"code","0550d909":"code","7b5bbdf0":"code","47ff7b30":"code","0525bba6":"code","5669d704":"code","5d3e9aa5":"markdown","13fb09f2":"markdown","24adcc2c":"markdown","2131f696":"markdown","edc9cc32":"markdown","075c4a2b":"markdown","82d630bc":"markdown","0fd22136":"markdown","713a66f2":"markdown","4fa8eff6":"markdown","21aa1de5":"markdown","864c9757":"markdown","1cc7b501":"markdown","572225fe":"markdown","f6ec924e":"markdown","053b5e62":"markdown","d0d5b016":"markdown","5fb1d1b8":"markdown","d6d833d2":"markdown","e52987af":"markdown","32fa5ba0":"markdown","0d802520":"markdown","83c5fcae":"markdown","44d95269":"markdown","102d8cbd":"markdown","13ad08a0":"markdown","37db2fb3":"markdown","eec92681":"markdown","c846ebe3":"markdown","fc4d03dd":"markdown","d5a206f2":"markdown","c071ca6c":"markdown","9e133752":"markdown","06b7409b":"markdown","1566907f":"markdown","c421b6a1":"markdown","a259eccf":"markdown","6975fda0":"markdown","7d8ba623":"markdown","1f2c7463":"markdown","53619f0d":"markdown","754893d6":"markdown","8d3f8077":"markdown","56fff317":"markdown","27369280":"markdown","0f183de2":"markdown","26e6ac4d":"markdown","6f2617f2":"markdown","bfccc195":"markdown","2f657517":"markdown","e789aa94":"markdown","85331c6c":"markdown","4fe6ade0":"markdown","66e9d84d":"markdown","2803070e":"markdown","fedfd6fd":"markdown","7478b337":"markdown","70999610":"markdown","363619b8":"markdown","f1866086":"markdown","b1817606":"markdown","1fce56ea":"markdown","d4f83763":"markdown","e325d393":"markdown","f612bd6e":"markdown","03eaabd8":"markdown","3269c825":"markdown","2dcd251c":"markdown","75a81d93":"markdown","776c1efe":"markdown","eb033279":"markdown"},"source":{"e56b68ed":"# import libraries\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_color_codes(\"pastel\")\nsns.set_style(\"whitegrid\")\n%matplotlib inline\n\nfrom pyspark.sql import SparkSession, Window\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import sum as Fsum\nfrom pyspark.sql.functions import min as Fmin\nfrom pyspark.sql.functions import max as Fmax\nfrom pyspark.sql.functions import avg, col, concat, count, desc, asc, explode, lit, split, stddev, udf, isnan, when, rank, from_unixtime\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import MinMaxScaler, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder","6530437c":"# Create spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Sparkify\") \\\n    .getOrCreate()","a5ceec52":"# Read in full sparkify dataset\nevent_data = \"..\/input\/mini_sparkify_event_data.json\"\ndf = spark.read.json(event_data)","3960fbca":"df.head(5)","70d72891":"df.printSchema()","4060653f":"df.describe().show()","beb4d4e2":"df.describe('artist').show()","2af0ad90":"df.describe('sessionId').show()","394badb6":"df.describe('userId').show()","00d95126":"df.count()","16681035":"df.select(\"page\").dropDuplicates().sort(\"page\").show()","8f9c47ec":"def count_missing(df, col):\n    \"\"\"\n    A helper function which count how many missing values in a colum of the dataset.\n    \n    This function is useful because the data can be either three cases below:\n    \n    1. NaN\n    2. Null\n    3. \"\" (empty string)\n    \"\"\"\n    return df.filter((isnan(df[col])) | (df[col].isNull()) | (df[col] == \"\")).count()","b0da9743":"print(\"[missing values]\\n\")\nfor col in df.columns:\n    missing_count = count_missing(df, col)\n    if missing_count > 0:\n        print(\"{}: {}\".format(col, missing_count))","47832edb":"df_without_missing_id = df.dropna(how = \"any\", subset = [\"userId\", \"sessionId\"])\ndf_without_missing_id = df_without_missing_id.filter(df[\"userId\"] != \"\") # `userId` should not be empty string","6877de46":"print(\"df:                    {}\".format(df.count()))\nprint(\"df_without_missing_id: {}\".format(df_without_missing_id.count())) # no missing values\n\nif df.count() == df_without_missing_id.count():\n    print(\"No missing values with userId and sessionId\")\nelse:\n    print(\"{} rows have been removed.\".format(df.count() - df_without_missing_id.count()))","0744a20a":"num_cols = []\ncat_cols = []\n\nfor s in df.schema:\n    data_type = str(s.dataType)\n    if data_type == \"StringType\":\n        cat_cols.append(s.name)\n    \n    if data_type == \"LongType\" or data_type == \"DoubleType\":\n        num_cols.append(s.name)","6d16ccd7":"num_cols","987f8b0f":"cat_cols","9908a68c":"df_without_missing_id.describe(num_cols).show()","d56342f6":"df_without_missing_id.select(\"status\").dropDuplicates().show()","d177a152":"df_without_missing_id.select(\"auth\").dropDuplicates().show()","5646b9c7":"df_without_missing_id.select(\"gender\").dropDuplicates().show()","8fc5feea":"df_without_missing_id.select(\"level\").dropDuplicates().show()","aa542b22":"df_without_missing_id.select(\"location\").dropDuplicates().show(10)","7ca6549f":"df_without_missing_id.select(\"method\").dropDuplicates().show()","d1fda9d6":"df_without_missing_id.select(\"page\").dropDuplicates().show()","e20b1cba":"df_without_missing_id.select(\"userAgent\").dropDuplicates().show(10)","556347af":"df_without_missing_id.filter(\"page = 'Cancellation Confirmation'\").show(10)","2ca7bbdf":"flag_churned_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\ndf_churned = df_without_missing_id.withColumn(\"churned\", flag_churned_event(\"page\"))","19affccb":"churned_rate = df_churned.groupby(\"userId\").agg({\"churned\": \"sum\"}).select(avg(\"sum(churned)\")).collect()[0][\"avg(sum(churned))\"]\nprint(\"churned: {:.2f}%\".format(churned_rate * 100))","1dc91bc1":"df_churned.select([\"userId\", \"gender\", \"level\", \"page\", \"status\", \"ts\", \"churned\"]).show(30)","85f2a874":"windowval = Window.partitionBy(\"userId\").orderBy(asc(\"ts\")).rangeBetween(Window.unboundedPreceding, 0)\ndf_phase = df_churned.withColumn(\"phase\", Fsum('churned').over(windowval))\ndf_churn = df_phase.withColumn(\"churn\", Fmax('churned').over(Window.partitionBy(\"userId\")))","c8e116af":"df_churn.select([\"userId\", \"gender\", \"level\", \"page\", \"status\", \"ts\", \"churned\", \"phase\", \"churn\"]).show(20)","5282bd50":"df_churn.filter(df_churn[\"churn\"] == 1).select([\"userId\", \"gender\", \"level\", \"page\", \"status\", \"ts\", \"churned\", \"phase\", \"churn\"]).show(20)","c30ec2a6":"churned_user_count = df_churn.filter(df_churn[\"churn\"] == 1).select(\"userId\").dropDuplicates().count()\nprint(\"churned user count: {} (total: {})\".format(churned_user_count, df_churn.count()))\nprint(\"churned user rate: {:.2f}%\".format(churned_user_count \/ df_churn.count() * 100))","891cb479":"func_churn_label = udf(lambda x: 'Churn' if x == 1 else 'Not Churn')","f8753ca6":"df_churn_user = df_churn.groupby(\"userId\").max(\"churn\").withColumnRenamed(\"max(churn)\", \"churn\").select([\"userId\", \"churn\"])","6cfff39e":"pd_gender = df_churn.select([\"userId\", \"gender\", \"churn\"]).withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_gender.head()","b30b3d0c":"sns.countplot(x=\"gender\", hue=\"churn\", data=pd_gender);","c2512393":"pd_level = df_churn.select([\"userId\", \"level\", \"churn\"]).withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_level.head()","84425a91":"sns.countplot(x=\"level\", hue=\"churn\", data=pd_level);","ee078a1c":"pd_artist = df_churn_user.join(df_churn.groupby(\"userId\") \\\n                                    .agg({\"artist\": \"count\"}) \\\n                                    .withColumnRenamed(\"count(artist)\", \"artist_count\"), [\"userId\"]) \\\n                         .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_artist.head()","c5f10017":"sns.boxplot(x=\"churn\", y=\"artist_count\", data=pd_artist);","b139891a":"pd_song = df_churn_user.join(df_churn.groupby(\"userId\") \\\n                                     .agg({\"song\": \"count\"}) \\\n                                     .withColumnRenamed(\"count(song)\", \"song_count\"), [\"userId\"]) \\\n                       .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_song.head()","4f0b69fa":"sns.boxplot(x=\"churn\", y=\"song_count\", data=pd_song);","8ea92be4":"pd_length = df_churn_user.join(df_churn.groupby(\"userId\") \\\n                                       .agg({\"length\": \"sum\"}) \\\n                                       .withColumnRenamed(\"sum(length)\", \"total_length\"), [\"userId\"]) \\\n                          .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_length.head()","f95f2fee":"sns.boxplot(x=\"churn\", y=\"total_length\", data=pd_length);","e2b4d06c":"pd_visit = df_churn_user.join(df_churn.groupby(\"userId\") \\\n                                      .count() \\\n                                      .withColumnRenamed(\"count\", \"visit_count\"), [\"userId\"]) \\\n                         .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_visit.head()","efc2b113":"sns.boxplot(x=\"churn\", y=\"visit_count\", data=pd_visit);","321fb50e":"pd_up = df_churn_user.join(df_churn.filter((df_churn[\"page\"] == 'Thumbs Up')) \\\n                                   .groupby(\"userId\") \\\n                                   .count() \\\n                                   .withColumnRenamed(\"count\", \"up_count\"), [\"userId\"]) \\\n                     .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_up.head()","9c16f210":"sns.boxplot(x=\"churn\", y=\"up_count\", data=pd_up);","905b62f8":"pd_down = df_churn_user.join(df_churn.filter((df_churn[\"page\"] == 'Thumbs Down')) \\\n                                   .groupby(\"userId\") \\\n                                   .count() \\\n                                   .withColumnRenamed(\"count\", \"down_count\"), [\"userId\"]) \\\n                     .withColumn(\"churn\", func_churn_label(\"churn\")).toPandas()\npd_down.head()","f58a4d94":"sns.boxplot(x=\"churn\", y=\"down_count\", data=pd_down);","fe04625c":"df_churn.show(1)","1e3c8b75":"df_original = df_churn.groupby('userId').max(\"churn\").withColumnRenamed(\"max(churn)\", \"target\")","8e5287c1":"df_original.show(10)","d1f41a43":"user_artist = df_churn.groupby(\"userId\").agg({\"artist\": \"count\"}).withColumnRenamed(\"count(artist)\", \"artist_count\")\nuser_artist.show(5)","c8fe70e0":"flag_gender = udf(lambda x: 1 if x == \"F\" else 0, IntegerType())\ndf_churn_with_gender = df_churn.withColumn(\"gender\", flag_gender(\"gender\"))\ndf_churn_with_gender.show(1)","9c2d1b77":"user_gender = df_churn_with_gender.groupby('userId').agg({\"gender\": \"max\"}).withColumnRenamed(\"max(gender)\", \"gender\")\nuser_gender.show(5)","d69b61e5":"user_length = df_churn.groupby('userId').agg({\"length\": \"sum\"}).withColumnRenamed(\"sum(length)\", \"length\")\nuser_length.show(5)","87879b1a":"user_thumbs_up = df_churn.filter(df_churn[\"page\"] == 'Thumbs Up').groupby('userId').count().withColumnRenamed(\"count\", \"thumb_up\")\nuser_thumbs_up.show(5)","1f13bfed":"user_thumbs_down = df_churn.filter(df_churn[\"page\"] == 'Thumbs Down').groupby('userId').count().withColumnRenamed(\"count\", \"thumb_down\")\nuser_thumbs_down.show(5)","caa2fe46":"flag_level = udf(lambda x: 1 if x == \"paid\" else 0, IntegerType())\ndf_churn_with_level = df_churn.withColumn(\"level\", flag_level(\"level\"))\ndf_churn_with_level.show(1)","e906099c":"user_level = df_churn_with_level.groupby('userId').agg({\"level\": \"max\"}).withColumnRenamed(\"max(level)\", \"level\")\nuser_level.show(5)","b8ace464":"user_song = df_churn.groupby(\"userId\").agg({\"song\": \"count\"}).withColumnRenamed(\"count(song)\", \"song_count\")\nuser_song.show(5)","50707833":"merged_df = df_original.join(user_artist, ['userId']) \\\n    .join(user_gender, ['userId']) \\\n    .join(user_length, ['userId']) \\\n    .join(user_level, ['userId']) \\\n    .join(user_thumbs_up, ['userId']) \\\n    .join(user_thumbs_down, ['userId']) \\\n    .join(user_song, ['userId'])","e0e3bf0e":"merged_df.show(5)","e705ff32":"merged_df_without_user = merged_df.drop(\"userId\")\nfeature_columns = [col for col in merged_df_without_user.columns if col!='target']\nfeature_columns","afdbf2c2":"train, test = merged_df_without_user.randomSplit([0.7, 0.3], seed=0)","095d6002":"def build_model(classifier, param):\n    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n    pipeline = Pipeline(stages=[assembler, scaler, classifier])\n\n    model = CrossValidator(\n        estimator=pipeline,\n        estimatorParamMaps=param,\n        evaluator=MulticlassClassificationEvaluator(labelCol='target', metricName='f1'),\n        numFolds=5,\n    )\n    return model","0c71c8b3":"lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"target\")\nparam = ParamGridBuilder().build()\nmodel = build_model(lr, param)","df804b9f":"%%time\nfit_model = model.fit(train)","be247a28":"pred = fit_model.transform(test)","0516d099":"pred.select(\"prediction\").dropDuplicates().collect()","e12cf45d":"evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"target\")\nf1_score = evaluator.evaluate(pred, {evaluator.metricName: \"f1\"})\nprint(\"f1: {}\".format(f1_score))","84fdfb0b":"rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"target\")\nrf_param = ParamGridBuilder().build()\nrf_model = build_model(rf, rf_param)","cb6a85f5":"%%time\nrf_fit_model = rf_model.fit(train)","2fc6583a":"rf_pred = rf_fit_model.transform(test)","3a9e612d":"rf_pred.select(\"prediction\").dropDuplicates().collect()","1efac9a9":"rf_f1_score = evaluator.evaluate(rf_pred, {evaluator.metricName: \"f1\"})\nprint(\"f1: {}\".format(rf_f1_score))","806a662e":"gbt =GBTClassifier(featuresCol=\"scaled_features\", labelCol=\"target\")\ngbt_param = ParamGridBuilder().build()\ngbt_model = build_model(gbt, gbt_param)","416caea4":"%%time\ngbt_fit_model = gbt_model.fit(train)","3871a942":"gbt_pred = gbt_fit_model.transform(test)","2f25b527":"gbt_pred.select(\"prediction\").dropDuplicates().collect()","194b18bc":"gbt_f1_score = evaluator.evaluate(gbt_pred, {evaluator.metricName: \"f1\"})\nprint(\"f1: {}\".format(gbt_f1_score))","0b43ab6d":"rf_feature_importance_df = pd.DataFrame()\nrf_feature_importance_df['feature'] = feature_columns\nrf_feature_importance_df['importance'] = rf_fit_model.bestModel.stages[2].featureImportances.values.tolist()\nrf_feature_importance_df = rf_feature_importance_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\nrf_feature_importance_df","af6e9c63":"plt.figure(figsize=(7,7))\nsns.barplot(x='importance', y='feature', data=rf_feature_importance_df, color=\"b\")\nplt.title('Feature Importance')\nplt.ylabel('');","6c410cf6":"classifier = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"target\")\n\nparam_grid = ParamGridBuilder() \\\n    .addGrid(classifier.maxDepth,[5, 10]) \\\n    .addGrid(classifier.numTrees, [20, 50]) \\\n    .addGrid(classifier.minInstancesPerNode, [1, 10]) \\\n    .addGrid(classifier.subsamplingRate, [0.7, 1.0]) \\\n    .build()\n\nmodel_tuned = build_model(classifier, param_grid)","0550d909":"%%time\nfit_model_tuned = model_tuned.fit(train)","7b5bbdf0":"best_model = fit_model_tuned.bestModel\nbest_model.stages[2].save(\"random_forest_tuned\")","47ff7b30":"best_model_pred = best_model.transform(test)","0525bba6":"best_model_pred.show(5)","5669d704":"best_f1_score = evaluator.evaluate(best_model_pred, {evaluator.metricName: \"f1\"})\nprint(\"f1: {}\".format(best_f1_score))","5d3e9aa5":"auth","13fb09f2":"Even if the predictions are all 0, f1 score is around 0.73 as a result of the imbalanced dataset.\n\nI've decided to use this score as a baseline result and I will try to create a better model.","24adcc2c":"Page\n\n* Thumbs Up\n* Thumbs Down","2131f696":"Build model","edc9cc32":"gender","075c4a2b":"page: Thumbs Up \/ Thumbs Down","82d630bc":"# Load and Clean Dataset\n\nIn this notebook, the file name, `mini_sparkify_event_data.json`, will be loaded and cleaned such as handling of invalid or missing values.","0fd22136":"location (only showing top 10)","713a66f2":"All the predicted values are 0 (Not churned)","4fa8eff6":"# Modeling\n\n\nIn this modeling section, the below tasks will be executed to build models. Three machine learning models will be examined and I will decide one of them based on the evaluation results for further hypyer parameter tuning.\n\n* scaling\n* train\/test split\n* build models\n  * Logistic Regression\n  * Random Forest classifier\n  * GBT classifier\n* evaluate the models based on f1 score since churned users in the dataset are fairly small so the distribution of target variables are extremely biased.","21aa1de5":"All the `page` events in the dataset:\n\n- About\n- Add Friend\n- Add to Playlist\n- Cancel\n- Cancellation Confirmation: **This even wil be used as a flag of churn**\n- Downgrade\n- Error\n- Help \n- Home\n- Login \n- Logout\n- NextSong \n- Register \n- Roll Advert\n- Save Settings \n- Settings\n- Submit Downgrade\n- Submit Registration\n- Submit Upgrade\n- Thumbs Down\n- Thumbs Up\n- Upgrade","864c9757":"churned rate (from total event logs)","1cc7b501":"up","572225fe":"userAgent (only showing top 10)","f6ec924e":"# Exploratory Data Analysis","053b5e62":"GBT","d0d5b016":"method","5fb1d1b8":"The first five rows of the dataset.","d6d833d2":"First, I will try Logistic Regression as a baseline model. Logistic Regression model is much simpler model than other two models. The time needed for training is relatiely shorter than others so it would be a good idea to use this model as a baseline.","e52987af":"# Sparkify Project Workspace","32fa5ba0":"### Feature Engineering Ideas\n\n* artist\n  * [x] the number of artist\n* [x] gender: 0 or 1\n* length\n  * [x] the total length\n* [x] level: 0 or 1\n* page\n  * [x] the number of `Thumbs Up`\n  * [x] the number of `Thumbs Down`\n* song\n  * [x] the number of song","0d802520":"down","83c5fcae":"## missing values","44d95269":"52 userIds were churned","102d8cbd":"The final result is better than the Random Forest model with default parameters.\nGiven that the full dataset (12GB) would provide different results compared with the small subset (128MB), further hyperparameter tuning will be required to gain stable results.","13ad08a0":"artist","37db2fb3":"The below columns will be examined:\n\n* artist\n  * [x] the number of artist\n* [x] gender: 0 or 1\n* length\n  * [x] the total length\n* [x] level: 0 or 1\n* page\n  * [x] the number of `Thumbs Up`\n  * [x] the number of `Thumbs Down`\n* song\n  * [x] the number of song","eec92681":"According to the feature importances provided by the Random Forest model, `Thumbs Up` and `Thumbs Down` seem to be important while the level of the users do not really matter.","c846ebe3":"Define a common function to convert churn value (0 or 1) to `Not Churn` or `Churn`\n\nBoth matplotlib and seaborn plot libraries require pandas dataframe, not pyspark dataframe, so I need to convert the pyspark dataframe to pandas one. I do this conversion every time for a small subset of the dataset because if I do this conversion for all the dataset, it takes time and causes an error.","fc4d03dd":"`userId` and `sessionId`\n\nIf the below Ids are null or empty, delete those rows:\n\n* userId\n* sessionId","d5a206f2":"Random Forest","c071ca6c":"level","9e133752":"### Define Churn\n\nChurn will be defined as when `Cancellation Confirmation` events happen, and users with the events are churned users in this analysis.","06b7409b":"### Category columns","1566907f":"Statistics of the `sessionId` column","c421b6a1":"### Try different models","a259eccf":"This is a [Udacity nanodegree](https:\/\/www.udacity.com\/course\/data-scientist-nanodegree--nd025) project (Data Science Capstone).\nThis project uses users' event data from Sparkify, which is an imaninary digital music service similar to Spotify or Pandora, to build a model to predict users' churn.\n\nThe original dataset is 12GB but a small subset of the dataset (128MB) will be used in this notebook.","6975fda0":"Original dataframe to be merged later","7d8ba623":"`page` kind","1f2c7463":"Statistics of the `artist` column","53619f0d":"There are three HTTP status codes:\n\n* 307: Temporary Redirect\n* 404: Not Found\n* 200: OK","754893d6":"level","8d3f8077":"Check how many missing values in each column","56fff317":"In this section, hyperparameter tuning will be executed for Random Forest model.","27369280":"### Hyperparameter Tuning","0f183de2":"Drop `userId` column (which is not necessary for modeling)","26e6ac4d":"length","6f2617f2":"## Statistics","bfccc195":"# Feature Engineering","2f657517":"churn: `Cancellation Confirmation`","e789aa94":"Join all the features","85331c6c":"page","4fe6ade0":"Train\/Test split","66e9d84d":"song","2803070e":"### Feature Importances","fedfd6fd":"length","7478b337":"## Number columns","70999610":"level","363619b8":"### Explore Data\n\nIn this section, data exploration will be done comparing churned users with not churned users, inspecting if there are any big differences between the two groups.","f1866086":"artist count per userId","b1817606":"gender","1fce56ea":"song count per userId","d4f83763":"Statistics of the whole dataset","e325d393":"Total rows: 286,500","f612bd6e":"With default parameters (without hyperparameter tuning), Random Forest gives me a better result than that of GBT classifier.\nLet's dig into more on Random Forest.","03eaabd8":"page: total visits","3269c825":"gender","2dcd251c":"Detect number columns and category columns.\n\n* num_cols: Number columns (Long or Double)\n* cat_cols: Category columns (String)","75a81d93":"Statistics of the `userId` column","776c1efe":"Random Forest","eb033279":"Schema information\n\n* artist: Artist name (ex. Daft Punk)\n* auth: User authentication status (ex. Logged)\n* firstName: User first name (ex. Colin)\n* gender: Gender (ex. F or M)\n* itemInSession: Item count in a session (ex. 52)\n* lastName: User last name (ex. Freeman)\n* length: Length of song (ex. 223.60771)\n* level: User plan (ex. paid)\n* location: User's location (ex. Bakersfield)\n* method: HTTP method (ex. PUT)\n* page: Page name (ex. NextSong)\n* registration: Registration timestamp (unix timestamp) (ex. 1538173362000)\n* sessionId: Session ID (ex. 29)\n* song: Song (ex. Harder Better Faster Stronger)\n* status: HTTP status (ex. 200)\n* ts: Event timestamp(unix timestamp) (ex. 1538352676000)\n* userAgent: User's browswer agent (ex. Mozilla\/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko\/20100101 Firefox\/31.0)\n* userId: User ID (ex. 30)"}}