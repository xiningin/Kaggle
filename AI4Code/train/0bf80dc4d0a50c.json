{"cell_type":{"617cdcf1":"code","1b3a2cec":"code","cc59dc1a":"code","e0ffd24f":"code","742853cd":"code","87c03794":"code","77d54798":"code","146fa1d9":"code","2352e539":"code","ef47df6a":"code","97387d60":"code","870efd62":"code","d7bd080e":"code","c0410bfe":"code","2224f537":"code","deb3d921":"markdown","14dfd776":"markdown","e2d029cd":"markdown"},"source":{"617cdcf1":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport os\n\nimport random\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\npd.options.display.precision = 15\n\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom fastai.tabular import * \nfrom tqdm import tqdm_notebook\nfrom fastai.callbacks import *","1b3a2cec":"%%time\ntrain = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32},nrows=6e8)","cc59dc1a":"min = -100\nmax = 100\nspread = 110\ndef get_counts(sequence):     \n    counts = [0]*spread\n    unique_count = np.unique(sequence, return_counts=True)\n    for i in range(0,len(unique_count[0])):\n        val = unique_count[0][i]\n        count = unique_count[1][i]\n        r = count*val\n        if val <= min:\n            counts[0] += r\n        elif val >= max:\n            counts[-1] += r\n        else:\n            counts[int(val\/2)+int(spread\/2)] += r\n\n    return counts","e0ffd24f":"interval = 75000\ncounts = [get_counts(train.acoustic_data.values[i:i+150000]) for i in tqdm_notebook(range(0,len(train),interval))]\nttfs = [train.time_to_failure.values[i] for i in range(0,len(train),interval)]\ndel train\n\nlabels = [\"D\"+str(i) for i in range(0,len(counts[0]))]\n\ndf = pd.DataFrame(counts, columns=labels)\nttf_df = pd.DataFrame(ttfs, columns=[\"expected\"])\ndf = df.join(ttf_df)","742853cd":"df.head(3)","87c03794":"path =\"..\/tmp\"\ntry:\n    os.makedirs(path)\nexcept:\n    pass","77d54798":"tpath = \"..\/input\/test\"\nfiles = os.listdir(tpath)\ni = 0\ntest_id = []\ntest_df = pd.DataFrame(dtype=np.float64, columns=df.columns.values[:-1])\nfor f in tqdm_notebook(files):\n    seg = pd.read_csv(f'{tpath}\/{f}')\n    converted = get_counts(seg.acoustic_data.values)\n    test_df.loc[i] = converted\n    test_id.append(f.replace(\".csv\", \"\"))\n    i+=1","146fa1d9":"num = len(df)\ninterval = int(num\/100)\nvalues = int(num\/(5*100))\nvalid_idx = []\nfor i in range(0,len(df)-values,interval):\n    for j in range(0,values-1):\n        valid_idx.append(i+j)","2352e539":"valid_ttfs = np.array([df.iloc[i].expected for i in valid_idx])","ef47df6a":"data = TabularDataBunch.from_df(path, df, \"expected\", valid_idx=valid_idx, test_df=test_df, procs=[Normalize])\n# data = TabularDataBunch.from_df(path, df, \"expected\", valid_idx=valid_idx, procs=[Normalize])","97387d60":"%%time\n\nbest_learn = None\nbest_mae = 9999\n\nfor i in range(0, 99):\n    learn = tabular_learner(data=data, layers=[200,100], metrics=mae, ps=0.5, y_range=(-1,15))\n    learn.callbacks = [SaveModelCallback(learn, every='improvement', mode='min', name='best')]\n    learn.fit_one_cycle(20, 1e-2)\n    gc.collect()\n\n    preds = learn.get_preds(DatasetType.Valid)[0].numpy().flatten()\n    new_mae = np.abs(valid_ttfs-preds).mean()\n    if new_mae < best_mae or not best_learn:\n        best_learn = learn\n        best_mae = new_mae\n    print(f'Run {i} - Best MAE: {best_mae}')","870efd62":"preds = best_learn.get_preds(DatasetType.Test)[0].numpy().flatten()","d7bd080e":"tpath = \"..\/input\/test\"\nfiles = os.listdir(tpath)\nfiles = [f.replace(\".csv\",\"\") for f in files]\nfiles[:3]","c0410bfe":"results = pd.DataFrame({\"seg_id\":files, \"time_to_failure\":preds})\nresults.head()","2224f537":"results.to_csv('submission.csv',index=False)","deb3d921":"* spread 200 - 2.02\n* spread 300 - ","14dfd776":"# Test Data","e2d029cd":"# Submission"}}