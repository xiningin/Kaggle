{"cell_type":{"68e9b545":"code","d16a7b3c":"code","1fe55b61":"code","5c44871d":"code","c9fcb55c":"code","0d502758":"code","16e047e2":"code","848076b6":"code","e30f63fe":"code","9420429b":"code","1cf21039":"code","11243ea8":"code","88aa9d2c":"code","401c1e67":"code","b60dcdec":"code","140e81c5":"code","99118fd2":"code","fa32cf73":"code","ed07ade7":"code","441d7c8b":"code","9b491429":"code","b1906577":"code","9bf3708f":"code","e4b498bc":"markdown","190980cc":"markdown","bb06dbcf":"markdown","e37a31c1":"markdown","dd3c58ca":"markdown","ca37e0c9":"markdown","a6d510d6":"markdown","0785e708":"markdown","b1b980ae":"markdown","38fb704f":"markdown","87e54acb":"markdown"},"source":{"68e9b545":"# data viz and dataframe handling packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\n\n#file handling\nimport os\n#from google.colab import files\n\n# data preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n\n# machine learning model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n# model selection\nfrom sklearn.model_selection import GridSearchCV\n\n# model evaluation\nfrom sklearn.metrics import (confusion_matrix,plot_confusion_matrix,plot_roc_curve,classification_report,accuracy_score,confusion_matrix)\n","d16a7b3c":"# import diabetes dataset from kaggle\nos.environ['KAGGLE_USERNAME'] = \"minkewang\" # username\nos.environ['KAGGLE_KEY'] = \"4ac64942fb1cdf679a628708e3cae405\" # key\n! kaggle datasets download -d uciml\/pima-indians-diabetes-database # api copied from kaggle","1fe55b61":"dbdata = pd.read_csv('pima-indians-diabetes-database.zip', compression='zip', header=0, sep=',', quotechar='\"',thousands=r',',encoding= 'unicode_escape')","5c44871d":"dbdata.sample(5)","c9fcb55c":"#check if there is nulls in the dataset\ndbdata.isnull().sum()","0d502758":" # summary statistics of all columns\n dbdata.describe()","16e047e2":"# correlation plot\ndbdata.corr().style.background_gradient(cmap=plt.cm.Blues)","848076b6":"## patients with diabetes seem to have a normally distributed pregnancies times\nsns.distplot(dbdata[dbdata['Outcome']==1]['Pregnancies'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['Pregnancies'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('Pregnancies for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['Pregnancies']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['Pregnancies']),color='blue', linestyle='--')","e30f63fe":"## Glucose level\nsns.distplot(dbdata[dbdata['Outcome']==1]['Glucose'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['Glucose'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('Glucose for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['Glucose']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['Glucose']),color='blue', linestyle='--')","9420429b":"## BloodPressure\nsns.distplot(dbdata[dbdata['Outcome']==1]['BloodPressure'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['BloodPressure'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('BloodPressure for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['BloodPressure']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['BloodPressure']),color='blue', linestyle='--')","1cf21039":"## SkinThickness\nsns.distplot(dbdata[dbdata['Outcome']==1]['SkinThickness'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['SkinThickness'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('SkinThickness for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['SkinThickness']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['SkinThickness']),color='blue', linestyle='--')","11243ea8":"## Insulin\nsns.distplot(dbdata[dbdata['Outcome']==1]['Insulin'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['Insulin'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('Insulin for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['Insulin']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['Insulin']),color='blue', linestyle='--')","88aa9d2c":"## BMI\nsns.distplot(dbdata[dbdata['Outcome']==1]['BMI'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['BMI'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('BMI for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['BMI']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['BMI']),color='blue', linestyle='--')","401c1e67":"## DiabetesPedigreeFunction \nsns.distplot(dbdata[dbdata['Outcome']==1]['DiabetesPedigreeFunction'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['DiabetesPedigreeFunction'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('DiabetesPedigreeFunction for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['DiabetesPedigreeFunction']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['DiabetesPedigreeFunction']),color='blue', linestyle='--')","b60dcdec":"## Age \nsns.distplot(dbdata[dbdata['Outcome']==1]['Age'],bins=10,kde_kws={'label':'Diebetes'})\nsns.distplot(dbdata[dbdata['Outcome']==0]['Age'],bins=10,kde_kws={'label':'No Diebetes'})\nplt.title('Age for patients\/non-patients')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==0]['Age']),color='red', linestyle='--')\nplt.axvline(np.median(dbdata[dbdata['Outcome']==1]['Age']),color='blue', linestyle='--')","140e81c5":"dbdata['Outcome'].value_counts()\/len(dbdata)","99118fd2":"#Define X, y variable Standardization \ny=dbdata.iloc[:,-1]\nstd = StandardScaler()                 # scale numeric columns\nX = pd.DataFrame(std.fit_transform(dbdata.iloc[:,:-1]),columns=dbdata.iloc[:,:-1].columns)","fa32cf73":"#Split train test dataset\nX_train,X_test, y_train,y_test= train_test_split(X, y, test_size=0.25, random_state=0)","ed07ade7":"def model_prediction(algorithm, X_train, X_test, y_train):\n  algorithm_fit = algorithm.fit(X_train, y_train)\n  predictions  = algorithm.predict(X_test)\n  probabilities = algorithm.predict_proba(X_test)\n  return algorithm_fit, predictions, probabilities","441d7c8b":"def prediction(algorithm, X_train, X_test, y_train, y_test) :\n    \n    # model prediction\n    algorithm_fit, predictions, probabilities = model_prediction(algorithm, X_train, X_test, y_train)\n\n    # print summary\n    print (\"\\n Classification report : \\n\", classification_report(y_test, predictions))\n    print (\"Accuracy   Score : \", accuracy_score(y_test, predictions))\n\n    # plot confusion matrix \n    plot_confusion_matrix(algorithm_fit, X_test, y_test, cmap=plt.cm.Blues,display_labels=['No Diabetes','Diabetes'])\n    plt.title('Confusion Matrix')\n    \n    # plot roc curve\n    plot_roc_curve(algorithm_fit, X_test, y_test)\n    ax = plt.gca()\n    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r')\n    plt.title('Receiver Operating Characteristic')\n    ","9b491429":"##logistic regression classifier with hyperparameter tuning using GridSearchCV\nparameters = {'penalty' : ['l1', 'l2'], 'C' : np.logspace(-4, 4, 20)}\nlogit = GridSearchCV(LogisticRegression(random_state=0),parameters,cv = 5, verbose=True, n_jobs=-1)\nprediction(logit,X_train, X_test, y_train, y_test)","b1906577":"##svm classifer with hyperparameter tuning using GridSearchCV\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvc = GridSearchCV(SVC(random_state=0,probability=True), parameters, cv = 5, verbose=True, n_jobs=-1)\nprediction(svc,X_train, X_test, y_train, y_test)","9bf3708f":"## random forest classifer with hyperparameter tuning using GridSearchCV\nparameters = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\nrf = GridSearchCV(RandomForestClassifier(), parameters, cv = 3, n_jobs = -1, verbose = 2)\nprediction(rf,X_train, X_test, y_train, y_test)","e4b498bc":"### Define Functions for model and evaluation\n\n**(confusion matrix, precision, recall, ROC AUC)**\n\n\n","190980cc":"### Random Forest Classification","bb06dbcf":"# Import Data & EDA","e37a31c1":"# Prediction: Diabetes Diagnosis ","dd3c58ca":"### Support Vector Machine -SVC","ca37e0c9":"### Standardize and split Tran Test Dataset ","a6d510d6":"Model Evaluation and Intepretation: \n","0785e708":"From the above correlation plot we can see that there is no sever mutlicoliearity problem with the dataset.","b1b980ae":"# Model Evaluation and Intepretation \n\n**Classification Report** <br>\nFrom the model classification report, we can see the accuracy rate of the model shows the overall rate of correctly predicted results or both true positive and true negatives out of all the predictions made. But it is not a good measure in this case because it gives equal importance to the false positives and false negatives. The data is imbalanced where patients data with only 35% with diabetes. Thus, correctly predicting no diabetes is of less use. \n\n**Confusion Matrix** <br>\nThe confusion matrix shows the predicted result on the test dataset using our trained model. \n\n**Precision vs Recall**<BR>\nIn this classification task where we would like to correctly predict the result of diabete diagnostic, the result of false negative is more severe than false positives because informing patients of no disease can result in delayed medical treatment and damage their health. Thus, we should give more emphasis to the metrics on the false negative rate, or the recall which is \nthe proportion of correctly identified positive out of all actual positives. Precision here indicates the proportion of correctly predicted positive observations out of all predicted psitive indentifications which is of less importance than the recall because higher recall lead to more severe outcome on the patients. Based on the tuned model of Logistic Regression, Random Forest and Support Vector Machine, we can clearly see that the SVC model performace is better. Thus, we can use this trained model to predict the diabetes diagnostic in the future. \n\n**ROC-AUC**<BR>\nThe ROC-AUC curve shows the True positive rate versus the False positive rate curve for all the threshold values ranging from 0 to 1. In an ROC curve, each point in the ROC space is associated with a different confusion matrix. A diagnoal line from the bottom left to the top right represent we have at least 50% chance to correctly predict diabetes even if we are guess randomly. AUC shows how much the model is capable of distingushing between different classes. From the tuned model above, we can see that the three models have similar ROC curve meaning that the three models perform similar in terms of identify postive and negative diabetes diagnostics. ","38fb704f":"### Logistic Regression","87e54acb":"# Import packages"}}