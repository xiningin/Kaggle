{"cell_type":{"976b849d":"code","76c3fbbe":"code","d3bb5f80":"code","595c5e84":"code","b2b7cc4e":"code","9ab0d277":"code","ef2678c9":"code","8d136263":"code","ac2c89b2":"code","485e5b02":"code","98dd51f1":"code","7f504763":"code","fef5bf1a":"code","a5d2fd51":"code","8e0d4c2f":"code","61bce2fd":"code","fe0c5d04":"code","f0c31f0f":"code","fbd30668":"code","b40c5a35":"code","fbaa84c2":"code","72defc72":"code","8118eda9":"code","3eb3f447":"code","bfc63af3":"code","dc907343":"code","e1a1e911":"code","9a5a5bda":"markdown","776da6d4":"markdown","d0bbea78":"markdown","9f2638ec":"markdown","8744ed71":"markdown","ebd805f5":"markdown","a37e4bc7":"markdown","e88ce43c":"markdown","34d967ee":"markdown"},"source":{"976b849d":"# install orderedset\n!cp -r ..\/input\/orderedset\/ordered-set-4.0.2 .\/\n%cd ordered-set-4.0.2\/\n!pip install -e .\n%cd ..","76c3fbbe":"!pip install ..\/input\/cu101torch140\/torch-1.4.0-cp37-cp37m-linux_x86_64.whl\n!pip install ..\/input\/torchvision050cp37\/torchvision-0.5.0-cp37-cp37m-linux_x86_64.whl\n!pip install ..\/input\/mmcvwhl\/addict-2.2.1-py3-none-any.whl\n!pip install ..\/input\/mmdetection20-5-13\/terminal-0.4.0-py3-none-any.whl\n!pip install ..\/input\/mmdetection20-5-13\/terminaltables-3.1.0-py3-none-any.whl\n!pip install ..\/input\/pytestrunner\/pytest_runner-5.2-py2.py3-none-any.whl # new\n!pip install ..\/input\/cityscapesscripts150\/cityscapesScripts-1.5.0-py3-none-any.whl\n!pip install ..\/input\/imagecorruptions\/imagecorruptions-1.1.0-py3-none-any.whl\n!pip install ..\/input\/asynctest\/asynctest-0.13.0-py3-none-any.whl\n!pip install ..\/input\/codecov\/codecov-2.1.7-py2.py3-none-any.whl\n!pip install ..\/input\/ubelt9\/ubelt-0.9.1-py3-none-any.whl\n!pip install ..\/input\/kwarray\/kwarray-0.5.8-py2.py3-none-any.whl\n!pip install ..\/input\/xdoctest\/xdoctest-0.12.0-py2.py3-none-any.whl","d3bb5f80":"!cp -r ..\/input\/mmcv60 .\/\n%cd mmcv60\/\n!pip install -e .\n%cd ..","595c5e84":"import sys\nsys.path.append('mmcv60') # To find local version","b2b7cc4e":"!cp -r ..\/input\/detors .\/mmdetection","9ab0d277":"!rm -rf .\/mmdetection\/mmdet\/apis\/inference.py\n!cp  ..\/input\/mmdetapisinference\/inference.py .\/mmdetection\/mmdet\/apis\/inference.py","ef2678c9":"%cd mmdetection\n!cp -r ..\/..\/input\/mmdetection20-5-13\/cocoapi\/cocoapi .\n%cd cocoapi\/PythonAPI\n!make\n!make install\n!python setup.py install\n%cd ..\/..\n!pip install -v -e .\n\n%cd ..\/\nsys.path.append('mmdetection') # To find local version","8d136263":"# add to sys python path for pycocotools\nsys.path.append('\/opt\/conda\/lib\/python3.7\/site-packages\/pycocotools-2.0-py3.7-linux-x86_64.egg') # To find local version","ac2c89b2":"import mmcv\n\nfrom mmdet.apis import init_detector, inference_detector, show_result_pyplot\nfrom mmcv import Config\nfrom mmdet.models import build_detector\nfrom mmcv.runner import load_checkpoint\nfrom mmcv.parallel import MMDataParallel\nfrom mmdet.apis import single_gpu_test\nfrom mmdet.datasets import build_dataloader, build_dataset\n\nimport pandas as pd\nimport os\nimport json\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch","485e5b02":"!cp  ..\/input\/detectors2\/WheatDetectoRS_mstrain_400_1200_r50_40e.py .\/mmdetection\/configs\/DetectoRS\/","98dd51f1":"config = '.\/mmdetection\/configs\/DetectoRS\/WheatDetectoRS_mstrain_400_1200_r50_40e.py'\ncheckpoint = '\/kaggle\/input\/detectors2\/epoch_40.pth'\nmodel = init_detector(config, checkpoint, device='cuda:0')\n# model = init_detector(config, checkpoint, device='cpu')","7f504763":"import cv2\nimg = '\/kaggle\/input\/global-wheat-detection\/test\/2fd875eaa.jpg'\nresult = inference_detector(model, img)\n# img = cv2.imread(img)\nprint(type(img))\nshow_result_pyplot(img, result,['wheat'], score_thr=0.3)","fef5bf1a":"result[0][0].shape","a5d2fd51":"!mkdir  mmdetection\/data\/\n!mkdir  mmdetection\/data\/Wheatdetection\n!mkdir  mmdetection\/data\/Wheatdetection\/annotations\n!cp -r ..\/input\/global-wheat-detection\/test mmdetection\/data\/Wheatdetection\/test\n","8e0d4c2f":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)\ndef gen_test_annotation(test_data_path, annotation_path):\n    test_anno_dict = {}\n    test_anno_dict[\"info\"] = \"jianqiu created\"\n    test_anno_dict[\"license\"] = [\"license\"]\n    id = 0\n    test_anno_list = []\n    for img in os.listdir(test_data_path):\n        if img.endswith('jpg'):\n            id += 1\n            img_info = {}\n            img_size = Image.open(os.path.join(test_data_path, img)).size\n            img_info['height'] = img_size[1]\n            img_info['width'] = img_size[0]\n            img_info['id'] = id            \n            img_info['file_name'] = img\n            test_anno_list.append(img_info)\n    test_anno_dict[\"images\"] = test_anno_list\n    test_anno_dict[\"categories\"] = [\n    {\n      \"id\": 1,\n      \"name\": \"wheat\"\n    }\n  ]\n    with open(annotation_path, 'w+') as f:\n        json.dump(test_anno_dict, f)","61bce2fd":"DIR_INPUT = '\/kaggle\/working\/mmdetection\/data\/Wheatdetection'\nDIR_TEST = f'{DIR_INPUT}\/test'\nDIR_ANNO = f'{DIR_INPUT}\/annotations'\n\nDIR_WEIGHTS = '\/kaggle\/input\/detectors2'\nWEIGHTS_FILE = f'{DIR_WEIGHTS}\/epoch_40.pth'\n\n# prepare test data annotations\ngen_test_annotation(DIR_TEST, DIR_ANNO + '\/detection_test.json')","fe0c5d04":"config_file = '\/kaggle\/input\/detestorstest\/WheatDetectoRS_mstrain_400_1200_r50_40e.py'\ncfg = Config.fromfile(config_file)\ncfg.data.test.test_mode = True\n\ndistributed = False\ndataset = build_dataset(cfg.data.test)\ndata_loader = build_dataloader(\n    dataset,\n    imgs_per_gpu = 1,\n    workers_per_gpu=1,\n    dist=distributed,\n    shuffle=False)","f0c31f0f":"!mkdir -p \/root\/.cache\/torch\/checkpoints\/","fbd30668":"!cp ..\/input\/resnet50\/resnet50-19c8e357.pth \/root\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth","b40c5a35":"# Wbf\n!pip install --no-deps '..\/input\/timm-package\/timm-0.1.26-py3-none-any.whl' > \/dev\/null\n","fbaa84c2":"import sys\nsys.path.insert(0, \"..\/input\/weightedboxesfusion\")\nfrom ensemble_boxes import *","72defc72":"import numpy as np\ndef run_wbf(prediction, image_size=1024, iou_thr=0.43, skip_box_thr=0.43, weights=None):\n    boxes = [(prediction[:, :4]\/(image_size-1)).tolist()]\n    scores = [(prediction[:,4]).tolist()]\n    labels = [(np.ones(prediction[:,4].shape[0])).tolist() ]\n\n    boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=iou_thr)\n    boxes, scores, labels = weighted_boxes_fusion([boxes], [scores], [labels], weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels","8118eda9":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\ncheckpoint = load_checkpoint(model, WEIGHTS_FILE, map_location='cpu') # 'cuda:0'\n\nmodel.CLASSES = dataset.CLASSES\n\nmodel = MMDataParallel(model, device_ids=[0])\noutputs = single_gpu_test(model, data_loader, False)\n\nresults = []\n\nfor images_info, result in zip(dataset.img_infos, outputs):\n    boxes, scores, labels = run_wbf(result[0][0])\n#     boxes = result[0][0][:, :4]\n#     scores = result[0][0][:, 4]\n    boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n    boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n\n    result = {\n        'image_id': images_info['filename'][:-4],\n        'PredictionString': format_prediction_string(boxes, scores)\n    }\n\n    results.append(result)","3eb3f447":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n\n# save result\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","bfc63af3":"!rm -rf mmdetection\/\n!rm -rf mmcv60\/","dc907343":"!rm -rf ordered-set-4.0.2","e1a1e911":"len(results[4]['PredictionString'].split(' '))\/\/5","9a5a5bda":"# start to inference","776da6d4":"copy the training config file and checkpoint ","d0bbea78":"install mmcv 0.6.0","9f2638ec":"# install package without internet\nprovided by \u667a\u661f\u4e91\uff08\u667a\u661fAI\uff09","8744ed71":"# There is the latest SOTA object detection model DetectoRS naive model\nIt is based on the mmdetection frame. There is the naive model without any tricks for training (40 epochs)\n\nHere is the paper.DetectoRS: [Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution](http:\/\/https:\/\/arxiv.org\/abs\/2006.02334)\n\nsource code https:\/\/github.com\/JianqiuChen\/DetectoRS.git\n\nmyconfig file https:\/\/github.com\/JianqiuChen\/Kaggle-wheat-detection.git \n\ncoco-format dataset for wheat detection https:\/\/www.kaggle.com\/jqeric\/wheatcoco","ebd805f5":"install pretrain model","a37e4bc7":"## inference ","e88ce43c":"## \u6700\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578bDetectoRS\uff0c\u5355\u6a21\u578b\u7248\u672c\u3002\u65e0\u7f51\u5b89\u88c5\n\n\u57fa\u4e8emmdetection \u6846\u67b6\uff0c\u4f7f\u7528\u539f\u59cb\u53c2\u6570\u8bad\u7ec3\u8fed\u4ee340\u8f6e\u3002\u672a\u5f15\u5165\u5176\u4ed6\u8bad\u7ec3\u6280\u5de7\n\n\u540e\u7eed\u4f1a\u9010\u6e10\u52a0\u5165\u4e00\u4e9b\u65b9\u6cd5\u4ee5\u63d0\u5347\u6548\u679c\u3002 \u6b64\u65b9\u6cd5\u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u6709\u9700\u8981\u7684\u4eba\uff01\n\n\u5199notebook\u4e0d\u5bb9\u6613\uff0c\u9ebb\u70e6\u5927\u5bb6\u652f\u6301\u4e00\u4e0b\u70b9\u4e2aup\uff01\n\n\u66f4\u591a\u7684\u8bad\u7ec3\u7ec6\u8282\u548c\u5185\u5bb9\u6211\u4f1a\u5728github\u4e0a\u4e0a\u4f20 \u667a\u661f\u4e91\u56e2\u961f\u656c\u4e0a\uff01\n\n\u4e3a\u4e86\u65b9\u4fbf\u5927\u5bb6\u4f7f\u7528\u5b66\u4e60\uff0c\u6211\u5df2\u5c06coco\u683c\u5f0f\u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u4f20\uff01\nhttps:\/\/www.kaggle.com\/jqeric\/wheatcoco","34d967ee":"## install pycoco and setup the mmdet"}}