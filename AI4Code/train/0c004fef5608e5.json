{"cell_type":{"b0b0e993":"code","e1359a0f":"code","24770e12":"code","1271b47a":"code","b4a47568":"code","cb297e3a":"code","89502bbc":"code","ee692734":"code","afb5f178":"code","edd0aa5d":"code","c14a5e92":"code","2d7ae8c3":"code","fc6734fa":"code","b2eaab01":"code","2b11d50b":"code","f2a1638e":"code","c52b5162":"code","9e6fab6d":"code","a1a1e1d7":"code","3dc6fe4a":"code","52afe353":"code","328bfa85":"code","edd63ca3":"code","821659fc":"code","3a5515a7":"code","a18317cc":"code","b188e581":"code","2878899a":"code","46cae919":"code","8d643caa":"code","cb01d8ca":"code","df469d2f":"code","e1eeba4c":"code","8b5ec9db":"code","e9da5069":"code","1205edb1":"code","e8c1a7b2":"code","26617772":"code","7fd8b60c":"code","79232d7d":"code","876f7325":"code","365ac88f":"code","0671cd40":"code","75ed051c":"code","84ba1bd4":"code","4e8d6ddc":"code","04232933":"code","4751e952":"code","c1dfbe4f":"code","6ee34f40":"code","1d751806":"code","67534f52":"code","9be58027":"code","bb33e4cf":"code","744c5463":"code","4f9fe5a6":"code","6a912755":"code","145951df":"code","635a6c61":"code","432610bf":"markdown","6769052d":"markdown","91c270e7":"markdown","518fadef":"markdown","2ba36db0":"markdown","7985888a":"markdown","9ce4af14":"markdown","2f64d604":"markdown","97cfeebe":"markdown","b3a1f402":"markdown","c00c400a":"markdown","873f26e3":"markdown","e05d60cb":"markdown","1e6dd8b5":"markdown","428d1c2c":"markdown","06715d51":"markdown","e1e720a3":"markdown","b6797ddc":"markdown"},"source":{"b0b0e993":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1359a0f":"movies = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')\ncredits = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')","24770e12":"movies.head()","1271b47a":"movies.shape","b4a47568":"credits.head()","cb297e3a":"credits.shape","89502bbc":"movies = movies.merge(credits, on='title')","ee692734":"movies.shape","afb5f178":"movies.info()","edd0aa5d":"movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]","c14a5e92":"movies.head()","2d7ae8c3":"movies.isnull().sum()","fc6734fa":"movies.dropna(subset=['overview'],inplace=True)","b2eaab01":"movies.isnull().sum()","2b11d50b":"movies.duplicated().sum()","f2a1638e":"movies.iloc[0]['genres']","c52b5162":"import ast","9e6fab6d":"def genres_and_keywords(text):\n    L1 = []\n    for i in ast.literal_eval(text):\n        L1.append(i['name'])\n    L = L1[:]\n    L1.clear()\n    return L","a1a1e1d7":"movies['genres'] = movies['genres'].apply(genres_and_keywords)","3dc6fe4a":"movies.head()","52afe353":"movies.iloc[0]['keywords']","328bfa85":"movies['keywords'] = movies['keywords'].apply(genres_and_keywords)","edd63ca3":"movies.head()","821659fc":"movies['overview'] = movies['overview'].apply(lambda x: x.split())","3a5515a7":"movies.head()","a18317cc":"def process_cast(text):\n    L = []\n    counter = 0\n    for i in ast.literal_eval(text):\n        if counter < 3:\n            L.append(i['name'])\n        else:\n            break\n        counter+=1\n    L1 = L[:]\n    L.clear()\n    return L1","b188e581":"movies['cast'] = movies['cast'].apply(process_cast)","2878899a":"movies.head()","46cae919":"def process_crew(text):\n    L = []\n    for i in ast.literal_eval(text):\n        if i['job'] == 'Director':\n            L.append(i['name'])\n            break\n    L1 = L[:]\n    L.clear()\n    return L1","8d643caa":"movies['crew'] = movies['crew'].apply(process_crew)","cb01d8ca":"movies.head()","df469d2f":"movies['genres'] = movies['genres'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\nmovies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\nmovies['cast'] = movies['cast'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\nmovies['crew'] = movies['crew'].apply(lambda x:[i.replace(\" \",\"\") for i in x])","e1eeba4c":"movies.head()","8b5ec9db":"movies['tags'] = movies['genres'] + movies['keywords'] + movies['overview'] + movies['cast'] + movies['crew']","e9da5069":"movies.head()","1205edb1":"final = movies[['movie_id', 'title', 'tags']]\nfinal.head()","e8c1a7b2":"final['tags'] = final['tags'].apply(lambda x:\" \".join(x))","26617772":"final['tags'][0]","7fd8b60c":"final['tags'] = final['tags'].apply(lambda x:x.lower())","79232d7d":"final.head()","876f7325":"import nltk\nfrom nltk.corpus import stopwords","365ac88f":"def removeStopWords(text): \n    x = [] \n    for i in text.split():     \n        if i not in stopwords.words('english'):         \n            x.append(i)        \n    y = x[:]\n    x.clear()         \n    return y","0671cd40":"final['tags'] = final['tags'].apply(removeStopWords)","75ed051c":"from nltk.stem.porter import PorterStemmer\npt = PorterStemmer()","84ba1bd4":"def stem(text):\n    y = []\n    for i in text:\n        y.append(pt.stem(i))\n        \n    return \" \".join(y)","4e8d6ddc":"final['tags'] = final['tags'].apply(stem)","04232933":"from sklearn.feature_extraction.text import CountVectorizer","4751e952":"cv = CountVectorizer(stop_words = 'english',max_features=5000)","c1dfbe4f":"vectors = cv.fit_transform(final['tags']).toarray()","6ee34f40":"vectors.shape","1d751806":"y = final.iloc[:,1].values","67534f52":"from sklearn.metrics.pairwise import cosine_similarity","9be58027":"similarity = cosine_similarity(vectors)","bb33e4cf":"similarity.shape","744c5463":"def recommend(movie):\n    movie_index = final[final['title'] == movie].index[0]\n    distances = similarity[movie_index]\n    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x:x[1])[1:11]\n    \n    for i in movies_list:\n        print(final.iloc[i[0]].title)","4f9fe5a6":"recommend(\"Spider-Man\")","6a912755":"import pickle","145951df":"## pickle.dump(final.to_dict(), open('movies_dict.pkl', 'wb'))","635a6c61":"## pickle.dump(similarity, open('similarity.pkl', 'wb'))","432610bf":"# **Removing all the spaces from the words of the columns**","6769052d":"# **Removing stop words**","91c270e7":"# **Genres column**","518fadef":"# Overview column","2ba36db0":"# **Crew column**","7985888a":"# Checking for null values","9ce4af14":"# **Merging both the datasets on the basis of 'title' column**","2f64d604":"# **Text Vectorization**","97cfeebe":"**Movies dataset**\n1. genres\n2. movie_id\n3. keywords\n4. title\n5. overview\n6. cast\n7. crew","b3a1f402":"# **Converting the 'tags' column from list to string**","c00c400a":"# **Dropping all the unnecessary columns**","873f26e3":"# **Converting the lists in the tags column to lowercase string**","e05d60cb":"# **Cast column**","1e6dd8b5":"**Dropping the null values**","428d1c2c":"# **Stemming the text**","06715d51":"# Keywords column","e1e720a3":"# **Adding all the lists of the columns in a single column**","b6797ddc":"# **Calculating cosine similarity of each movie with every movies**"}}