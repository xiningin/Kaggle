{"cell_type":{"c9cc7e17":"code","a13b3df8":"code","981d9fc8":"code","5ed89c33":"code","933b2916":"code","c2a4613d":"code","4d517622":"code","f932a88b":"code","8c241d2c":"code","fea1046b":"code","a3606274":"code","06597ba5":"markdown","294022f9":"markdown","35a812a8":"markdown","6b53b580":"markdown","b8ec63b1":"markdown","c894735e":"markdown","88a6f53b":"markdown","97393054":"markdown"},"source":{"c9cc7e17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a13b3df8":"df = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding='latin-1')\ndf.shape","981d9fc8":"df.head()","5ed89c33":"df= df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1)\ndf= df.rename(columns={'v2':'text','v1':'label'})","933b2916":"df.head()","c2a4613d":"df.isnull().any()        #check if there is any null data","4d517622":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv=CountVectorizer(stop_words='english')\n\nfeature_vectors= cv.fit_transform(df['text'])\n","f932a88b":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(feature_vectors,df['label'],test_size=0.3, random_state=42)\nprint(np.shape(x_train), np.shape(x_test),np.shape(y_train))\nprint('There are {} samples in the training set and {} samples in the test set'.format(\nx_train.shape[0], x_test.shape[0]))\n","8c241d2c":"from sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nmodel_SVM = SVC()\nmodel_SVM.fit(x_train, y_train)\n\ny_pred_SVM = model_SVM.predict(x_test)\n\nprint(\"Training Accuracy using SVM :\", model_SVM.score(x_train, y_train))\nprint(\"Testing Accuracy using SVM:\", model_SVM.score(x_test, y_test))\n\nprint('Confusion matrix')\ncm1 = confusion_matrix(y_test, y_pred_SVM)\nprint(cm1)\n\nprint(\"Accuracy Score for Test Set using SVM:\", accuracy_score(y_test, y_pred_SVM))","fea1046b":"from sklearn.naive_bayes import MultinomialNB\n\nmodel_NB= MultinomialNB()\nmodel_NB.fit(x_train,y_train)\n\ny_pred_NB=model_NB.predict(x_test)\n\nprint(\"Training Accuracy using Naive Bayes:\", model_NB.score(x_train, y_train))\nprint(\"Testing Accuracy using Naive Bayes:\", model_NB.score(x_test, y_test))\n\nprint('Confusion matrix')\ncm2 = confusion_matrix(y_test, y_pred_NB)\nprint(cm2)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score for Test Set using Naive Bayes:\", accuracy_score(y_test, y_pred_NB))","a3606274":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_RF=RandomForestClassifier(n_estimators=31, random_state=111)\nmodel_RF.fit(x_train,y_train)\n\ny_pred_RF=model_RF.predict(x_test)\n\nprint(\"Training Accuracy using Random Forest:\", model_RF.score(x_train, y_train))\nprint(\"Testing Accuracy using Random Forest:\", model_RF.score(x_test, y_test))\n\nprint('Confusion matrix')\ncm3 = confusion_matrix(y_test, y_pred_RF)\nprint(cm3)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score for Test Set using Random Forest:\", accuracy_score(y_test, y_pred_RF))","06597ba5":"## **Importing some basic libraries**","294022f9":"## Performance Metrics\n\nThe Confusion matrix is one of the most intuitive metrics used for finding the correctness and accuracy of the model.\n\nTN FP\n\nFN TP\n\nThe precision is the ratio TP \/ (TP + FP) where TP is the number of true positives and FP the number of false positives.\n\nFor this use case, the precision should be higher i.e. less False Positives(FP) because we don't want ham messages to be classified as spam and hence, missing out on any important message.\n\n**Comparing the results**\n\nSupport Vector Machine(SVM) performs the best with zero False Positives and highest accuracy.","35a812a8":"## **Modelling**\n\n**Support Vector Machine**","6b53b580":"## **Reading the data**","b8ec63b1":"**Naive Bayes**","c894735e":"## **Creating bag of words**","88a6f53b":"**Random Forest**","97393054":"# **Spam Filtering using NLP**\nTo train 3 different models that classify messages as spam or ham and choose the model with highest precision.\n\n* SVM Classifier\n* Naive Bayes Classifier\n* Random Forest Classifier"}}