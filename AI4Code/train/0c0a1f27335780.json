{"cell_type":{"f741a7a3":"code","dd4d8019":"code","020372d5":"code","1831452b":"code","002d69ef":"code","4f1fe325":"code","ad30987a":"code","bdeda59a":"code","879c7ca1":"code","dd33c551":"code","43c878b6":"code","156b5de0":"code","e4bf5c34":"code","a6368b8b":"code","66083849":"code","c19502da":"code","47d8ac13":"code","b66d8b0c":"code","0e3e880b":"code","f36694c1":"code","edfa8bc9":"code","8ad42da8":"code","a70b9c2a":"code","8fb9e901":"code","ea44ea47":"markdown","a2cbdc45":"markdown","ba748f5d":"markdown","62843f8f":"markdown","bb8ffaa5":"markdown","1c5bfc99":"markdown","d6e12875":"markdown","9d957dd6":"markdown","3725ec18":"markdown"},"source":{"f741a7a3":"import pandas  as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.dates as mdates","dd4d8019":"train_data = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv\")\nsub_data = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/submission.csv\")","020372d5":"train_data.head()","1831452b":"plt.figure(figsize=(20,20))\nmonths = mdates.MonthLocator()\nmonths_fmt = mdates.DateFormatter(\"%m\")\n# Firstly getting knowledge of what the unique countries we have.\nunique_countries = train_data[\"Country_Region\"].unique()\n# So there are 187 total unqiue countries we have . we will take into consideration all of these and prepare a dataframe \n# of has three columns viz (country name ,confirmed , fatalities) . \nfig,ax = plt.subplots()\nfig.figsize = (20,20)\n# Making a dictionary to hold all countries as  keys .\nConfirmed = [c for i,c in enumerate(train_data[\"TargetValue\"]) if i%2==0]\nFatalities  =  [c for i,c in enumerate(train_data[\"TargetValue\"]) if i%2!=0]\ncountries = [c for i,c in enumerate(train_data[\"Country_Region\"]) if i%2==0]\ndates = [c for i,c in enumerate(train_data[\"Date\"]) if i%2==0]\n\n# DataFrame Made such that we don't have to apply transformations in further visualizations.\ndf_ccf = pd.DataFrame(columns=[\"Country\",\"Confirmed\",\"Fatalities\",\"Date\"])\ndf_ccf[\"Country\"] = countries\ndf_ccf[\"Confirmed\"] = Confirmed\ndf_ccf[\"Fatalities\"] = Fatalities\ndf_ccf[\"Date\"] = dates\n\ndf_ccf = df_ccf.set_index(\"Country\")\n# Visualization of Confirmed Cases of 10 Countries.\n\nfor i,uc in enumerate(unique_countries):\n    if i<5:\n        ax.plot(df_ccf.loc[uc,\"Date\"],df_ccf.loc[uc,\"Confirmed\"],label=uc)\n    \nax.xaxis.set_major_locator(months)\nax.xaxis.set_major_formatter(months_fmt)\nplt.legend()\nplt.show()\n\n# As we can see we are not able to find any pattern in the data so lets some another visualizations.","002d69ef":"# Just taking top 5 Countries with the Confirmed Cases and Fatalities being High\ntop20_c = {e:np.sum(df_ccf.loc[e,\"Confirmed\"]) for e in unique_countries}\ntop20_c = sorted(top20_c.items(),key=lambda x:x[1],reverse=True)","4f1fe325":"df_ccf.groupby(\"Country\").sum().loc[\"US\"]","ad30987a":"top20_f = {e:np.sum(df_ccf.loc[e,\"Fatalities\"]) for e in unique_countries}\nfor e in top20_f:\n    print(e)\ntop20_f = sorted(top20_f.items(),key=lambda x:x[1],reverse=True)\ntop20_f = [v for (k,v) in top20_f[:20]]","bdeda59a":"reduced_df = df_ccf.groupby(\"Country\").sum().sort_values(by=\"Confirmed\",ascending=False)[:20]\nplt.figure(figsize=(20,8))\nreduced_df[\"Confirmed\"].plot(kind=\"bar\",color=\"green\",edgecolor=\"black\",label=\"Confirmed\")\nreduced_df[\"Fatalities\"].plot(kind=\"bar\",color=\"darkred\",edgecolor=\"red\",label=\"Fatalities\")\nplt.suptitle(\"Confirmed Cases And Fatalities Top-20 Countries\",fontsize=30,color=\"brown\",fontfamily=\"italics\")\nplt.legend()\nplt.show()","879c7ca1":"plt.figure(figsize=(10,7))\ncolor = plt.cm.get_cmap(\"viridis\",20)\ncolor = color.colors\nfor i,(k,v) in enumerate(top20_c):\n    if i<20:\n        plt.bar(i,height=v,label=k,color=color[i])\nplt.plot(top20_f,c=\"darkred\",marker=\"s\")\nplt.legend()\nplt.title(\"Top-20 Country When Confirmed Cases\",fontsize=28,fontstyle=\"oblique\",color=\"steelblue\",fontfamily=\"cursive\")\nplt.show()","dd33c551":"plt.plot(range(20),top20_f,marker=\"o\")\n# Here we can Visualize that #Deaths are following the same order with Country meaning more the Confirmed Cases\n# in the Country more the Deaths hence they should be directly Proportional To each other.","43c878b6":"# Lets Visualize the Confirmed\/Fatalities ratio of top-20 country to support our statement,\nratio = [c[1]\/f for c,f in zip(top20_c,top20_f) if f!=0]\nplt.plot(range(len(ratio)),ratio,linewidth=2,marker=\"s\") # Improve COloring Scheme\nplt.show()\n\n# here our assumption of Fatalities changing as Confirmed Cases Fails because when that would be the case then\n# we could have got the ratio to be constant or almost constant but here it varies drastically.","156b5de0":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","e4bf5c34":"# Pipeline and GridSearch\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib import dates","a6368b8b":"features = train.drop([\"TargetValue\"],axis=1)\nfeatures[\"Date\"] = dates.datestr2num(features[\"Date\"])\nlabels = train[\"TargetValue\"]\nrfr_new = RandomForestRegressor(n_estimators=300,max_features=\"sqrt\")\nX_train,X_test,Y_train,Y_test = train_test_split(features,labels,test_size=0.2,random_state=42)\nX_train","66083849":"rfr_new.fit(X_train,Y_train)","c19502da":"rfr_new.predict(X_test)","47d8ac13":"Y_train_pred = rfr_new.predict(X_train)\nprint(f\"R2 Score: {round(r2_score(Y_train,Y_train_pred),2)*100} %\")\nprint(f\"MSE: {mean_squared_error(Y_train,Y_train_pred)}\")","b66d8b0c":"Y_test_pred = rfr_new.predict(X_test)\nprint(f\"R2 Score: {round(r2_score(Y_test,Y_test_pred),2)*100} %\")\nprint(f\"MSE: {mean_squared_error(Y_test,Y_test_pred)}\")","0e3e880b":"# Getting predictions from current model for test.csv\ntest = test_data.drop([\"ForecastId\",\"Country_Region\",\"Target\",\"Province_State\",\"County\"],axis=1)\ntest[\"Date\"] = pd.to_datetime(test[\"Date\"]).dt.strftime(\"%Y%m%d\").astype(int)\npreds = pipeline.predict(test)","f36694c1":"preds = [int(e) for e in preds]\noutputs = pd.DataFrame({\"Id\":test.index,\"TargetValue\":preds})","edfa8bc9":"a=outputs.groupby([\"Id\"])[\"TargetValue\"].quantile(q=0.05).reset_index()\nb= outputs.groupby([\"Id\"])[\"TargetValue\"].quantile(q=0.5).reset_index()\nc = outputs.groupby([\"Id\"])[\"TargetValue\"].quantile(q=0.95).reset_index()","8ad42da8":"a.columns = [\"Id\",\"q0.05\"]\nb.columns = [\"Id\",\"q0.5\"]\nc.columns = [\"Id\",\"q0.95\"]\na = pd.concat([a,b[\"q0.5\"],c[\"q0.95\"]],1)\na[\"q0.05\"] = a[\"q0.05\"].clip(0,10000)\na[\"q0.5\"] = a[\"q0.5\"].clip(0,10000)\na[\"q0.95\"] = a[\"q0.95\"].clip(0,10000)\na[\"Id\"] = a[\"Id\"]+1","a70b9c2a":"submission = pd.melt(a,id_vars=[\"Id\"],value_vars=[\"q0.05\",\"q0.5\",\"q0.95\"])\nsubmission[\"variable\"] = submission[\"variable\"].str.replace(\"q\",\"\",regex=False)\nsubmission[\"ForecastId_Quantile\"] = submission[\"Id\"].astype(str)+\"_\"+submission[\"variable\"]\nsubmission[\"TargetValue\"] = submission[\"value\"]\nsubmission = submission[[\"ForecastId_Quantile\",\"TargetValue\"]]\nsubmission.reset_index(drop=True,inplace=True)\nsubmission.head()","8fb9e901":"submission.to_csv(\"submission.csv\",index=False)","ea44ea47":"### Getting Predictions..","a2cbdc45":"# Random Forest Regressor ","ba748f5d":"### Calculating R2 Score and Mean Squared Error","62843f8f":"### Prepairing for Submission..","bb8ffaa5":"# EDA on Data","1c5bfc99":"### Fitting the Model","d6e12875":"### Looking through Confirmed Cases of Countries.","9d957dd6":"### Preprocessing..","3725ec18":"### Extracting Features and Labels.."}}