{"cell_type":{"9c66a4e1":"code","56d2aa61":"code","4927b17e":"code","9ff0e76e":"code","fd09332c":"code","c2351031":"code","98e09a68":"code","da1dff96":"code","daafeb62":"code","b5694747":"code","ca83a399":"code","b17138fa":"code","3d60aa04":"code","3ba4ab11":"code","7bfc1f98":"code","17934f95":"code","e424eb96":"code","9f388762":"code","76b28ecc":"code","de8fa86a":"code","799e76c9":"code","56f8bdd4":"code","995d7c81":"code","5a666501":"code","0d87efd4":"code","77ad988e":"code","5e8e6575":"code","e0b5e364":"code","36aa1790":"code","fdb9bc56":"code","6fec7420":"code","fa4f9e0d":"code","0fa62ec5":"markdown","5c7b76a3":"markdown","0f954bf6":"markdown","6e46685d":"markdown","3c966e21":"markdown","6fd359f5":"markdown","344bbf3e":"markdown","8a1bcecf":"markdown","a4aaddb3":"markdown","8122071e":"markdown","a5fc3639":"markdown","8e84fd67":"markdown","4471d79d":"markdown","0d312d4a":"markdown","bf16ee73":"markdown","1f70f8dc":"markdown","8702db88":"markdown"},"source":{"9c66a4e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","56d2aa61":"import keras as keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import LSTM, GRU,SimpleRNN\nfrom keras.layers import Dense, Embedding, Bidirectional, Dropout, Flatten\nfrom keras.optimizers import Adam, SGD\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nearly_stop=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')","4927b17e":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","9ff0e76e":"train.head()","fd09332c":"test.head()","c2351031":"print('Training Dataset contain {} samples'.format(train.shape[0]))\nprint('Testing Dataset contain {} samples'.format(test.shape[0]))","98e09a68":"train = train.drop(['id', 'keyword', 'location'], axis=1)\ntest = test.drop(['id', 'keyword', 'location'], axis=1)","da1dff96":"y_train =  train['target'].values\nX_train = train.drop(['target'], axis=1).values.reshape(len(train),)\nX_test = test['text'].values.reshape(len(test),)","daafeb62":"print(X_test)","b5694747":"print(y_train)\nprint(X_train)","ca83a399":"total_tweets = np.concatenate((X_train, X_test))\nprint('Total tweets : ', len(total_tweets))","b17138fa":"total_tweets","3d60aa04":"\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(total_tweets)\n\n# Vocbvulary Size\n#\u3000trian\u3001test\u306e\u30c4\u30a4\u30fc\u30c8\u306e\u7dcf\u5358\u8a9e\u6570\uff08\u5358\u8a9e\u306e\u6b21\u5143\u6570\uff09\u3092\u53d6\u5f97\nvocab_size = len(tokenizer.word_index) + 1\nprint('Size of Vocabulary : ', vocab_size)","3ba4ab11":"# Maximum length for padding sequence\nmaxlen = max(len(x.split()) for x in total_tweets)\nprint('Maximum length of tweet : ', maxlen)","7bfc1f98":"X_train_token = tokenizer.texts_to_sequences(X_train)\nX_test_token = tokenizer.texts_to_sequences(X_test)\n\nprint('Text before tokenized')\nprint(X_train[0])\nprint('\\nText after tokenized')\nprint(X_train_token[0])","17934f95":"X_train_pad = pad_sequences(X_train_token, maxlen=maxlen, padding='post')\nX_test_pad = pad_sequences(X_test_token, maxlen=maxlen, padding='post')\n\nprint('Tokenized text before padding')\nprint(X_train_token[0])\nprint('\\nTokenized text after padding')\nprint(X_train_pad[0])","e424eb96":"\nembed_units=100\nhidden_units=128\n\nmodel=Sequential()\nmodel.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel.add(SimpleRNN(hidden_units))\nmodel.add(Dropout(0.2))\n#model.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()\n","9f388762":"learning_rate = 0.0001\n\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","76b28ecc":"batch_size_1= 150\nbatch_size_2= 300\nbatch_size_3= 700\nnum_itr = 5\nes_cb=keras.callbacks.EarlyStopping( patience=0, verbose=0)\nmodel_history = model.fit(X_train_pad, y_train, \n                          batch_size=batch_size_1, \n                          epochs=num_itr, \n                          validation_split=0.3,\n                          callbacks=[es_cb])","de8fa86a":"\n\nmodel_BRNN=Sequential()\nmodel_BRNN.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_BRNN.add(Bidirectional(SimpleRNN(hidden_units)))\nmodel_BRNN.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_BRNN.add(Dense(256, activation='relu'))\nmodel_BRNN.add(Dropout(0.2))\nmodel_BRNN.add(Dense(1, activation='sigmoid'))\n\nmodel_BRNN.summary()\n","799e76c9":"learning_rate = 0.0001\n\nmodel_BRNN.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","56f8bdd4":"model_BRNN_history = model_BRNN.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.2,\n                          callbacks=[es_cb])","995d7c81":"\n\nmodel_LS = Sequential()\nmodel_LS.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_LS.add(Bidirectional(LSTM(hidden_units)))\nmodel_LS.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_LS.add(Dense(256, activation='relu'))\nmodel_LS.add(Dropout(0.2))\nmodel_LS.add(Dense(1, activation='sigmoid'))\n\nmodel_LS.summary()","5a666501":"learning_rate = 0.0001\n\nmodel_LS.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","0d87efd4":"model_LS_history = model_LS.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.4,\n                          callbacks=[es_cb])","77ad988e":"\nmodel_BLS=Sequential()\nmodel_BLS.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_BLS.add(Bidirectional(LSTM(hidden_units)))\nmodel_BLS.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_BLS.add(Dense(256, activation='relu'))\nmodel_BLS.add(Dropout(0.2))\nmodel_BLS.add(Dense(1, activation='sigmoid'))\n\nmodel_BLS.summary()\n","5e8e6575":"learning_rate = 0.0001\n\nmodel_BLS.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","e0b5e364":"\nmodel_BLS_history = model_LS.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.9,\n                          callbacks=[es_cb])","36aa1790":"pred = model_LS.predict(X_test_pad)","fdb9bc56":"sub = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\nsub[\"target\"] = pred\nsub[\"target\"] = sub[\"target\"].apply(lambda x : 0 if x<=.5 else 1)","6fec7420":"sub","fa4f9e0d":"sub.to_csv(\"submit_5.csv\", index=False)","0fa62ec5":"## Bidirectional\u3000SimpleRNN","5c7b76a3":"## \u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057\u3066\u3044\u304f\n\u5143\u30cd\u30bf\u306e\u65b9\u306fBidirectional\u3000LSTM\u3067\u5b66\u7fd2\u3055\u308c\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001\u3044\u308d\u3044\u308d\u3068\u8a66\u3057\u3066\u307f\u305f\u304b\u3063\u305f\u306e\u3067\u4e0b\u8a18\u306e\u56db\u3064\u306e\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057\u3066\u7cbe\u5ea6\u3092\u6bd4\u8f03\u3057\u307e\u3057\u305f\n\nBidirectional\u3063\u3066\uff1f\uff1f\n\u666e\u901a\u306eRNN\u3060\u3068\u524d\u304b\u3089\u9806\u306b\u6b21\u306e\u6587\u5b57\u3092\u4e88\u60f3\u3057\u3066\u3044\u304f\u304c\u3001Bidirectional\u3092\u3064\u3051\u308b\u3068\u524d\u3068\u5f8c\u308d\u304b\u3089\u8aad\u3093\u3067\u6b21\u306b\u51fa\u3066\u304f\u308b\u6587\u5b57\u3092\u4e88\u60f3\u3067\u304d\u308b\u3002\u2192\u7cbe\u5ea6\u304c\u3088\u304f\u306a\u308b\u3089\u3057\u3044\n\n[\u53c2\u8003\u8a18\u4e8b](https:\/\/sleepless-se.net\/2019\/03\/21\/%E3%80%90python%E3%80%91bidirectionalrnn-create-sentence\/)","0f954bf6":"**Dataset Load**","6e46685d":"numpy.concatenate()\u306e\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\n\n\u7d50\u5408\u3059\u308b\u914d\u5217ndarray\u306e\u30ea\u30b9\u30c8\u3092\u6307\u5b9a\n\n\u7d50\u5408\u3059\u308b\u8ef8\uff08\u6b21\u5143\uff09\u3092\u6307\u5b9a: \u5f15\u6570axis\n\nnumpy.stack()\u3067\u65b0\u305f\u306a\u8ef8\uff08\u6b21\u5143\uff09\u306b\u6cbf\u3063\u3066\u7d50\u5408\n\nnumpy.block()\u3067\u914d\u7f6e\u3092\u6307\u5b9a\u3057\u3066\u7d50\u5408\n\nnumpy.vstack()\u3067\u7e26\u306b\u7d50\u5408\n\nnumpy.hstack()\u3067\u6a2a\u306b\u7d50\u5408\n\nnumpy.dstack()\u3067\u6df1\u3055\u65b9\u5411\u306b\u7d50\u5408","3c966e21":"## \u5206\u304b\u3063\u305f\u3053\u3068\n\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306e\u524d\u51e6\u7406\u306e\u4ed5\u65b9\nBidirectional LSTM \u304c\uff08\u7406\u7531\u306f\u306f\u304b\u3089\u306a\u3044\u304c\uff09\u4e00\u756a\u3044\u3044\u30b9\u30b3\u30a2\u3092\u51fa\u3059\u3063\u3066\u3053\u3068\n","6fd359f5":"\u5358\u8a9e\u306e\u6587\u5b57\u5217\u306eindex\u3092\u69cb\u7bc9","344bbf3e":"\n\u8981\u7d20\u306e\u5408\u308f\u306a\u3044\u914d\u5217\u306b\u5bfe\u3057\u3066\u30010 \u3067\u57cb\u3081\u308b\u306a\u3069\u3057\u3066\u914d\u5217\u306e\u30b5\u30a4\u30ba\u3092\u4e00\u81f4\u3055\u305b\u308b\u3002\n[\u53c2\u8003\u8a18\u4e8b](https:\/\/qiita.com\/9ryuuuuu\/items\/2830fee559a41d00aa2b)\n\n\n\u4e00\u756a\u9577\u3044tweet\u306e\u5358\u8a9e\u6570\u306b\u5408\u308f\u305b\u308b\npaddding='post\u2019\n\u306b\u3059\u308b\u3068\u5f8c\u308d\u306b0\u304c\u8ffd\u52a0\u3055\u308c\u308b\n\n","8a1bcecf":"**Preprocessing**","a4aaddb3":"\u3044\u308d\u3044\u308d\u3044\u3058\u3063\u3066\u307f\u305f\u7d50\u679c\u3001\nvalidation-split\u3092\u6975\u7aef\u306b\u6319\u3052\u3066\u3044\u308b\u306e\u306b\u3001\u306a\u304b\u306a\u304b\u826f\u3044\u5024\u3092\u5b89\u5b9a\u3057\u3066\u51fa\u3057\u7d9a\u3051\u3066\u3044\u308b\uff08\u306a\u305c\u304b\u306f\u308f\u304b\u3089\u3093\uff09","8122071e":"## \u7591\u554f\u70b9\nvalidation-split\u3092\u3092\u6975\u7aef\u306b\u4e0a\u3052\u308b\u3068val\u2015accuracy\u304c\u4ee5\u4e0a\u306b\u3088\u304f\u306a\u308b\u539f\u56e0\uff08\u6240\u8a6e\u4e8c\u5024\u5206\u985e\u3060\u304b\u3089\u78ba\u7387\u306e\u554f\u984c\uff1f\uff09\n\u30d1\u30e9\u30e1\u30fc\u30bf\u3044\u3058\u3063\u3066\u3082fit\u3057\u76f4\u3059\u3054\u3068\u306b\u3060\u3044\u3076\u5024\u304c\u304b\u308f\u308b\u306e\u3067\u3069\u306e\u3088\u3046\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u3059\u308c\u3070\u3044\u3044\u306e\u304b\u308f\u304b\u3089\u306a\u3044","a5fc3639":"We will drop 'id', 'keyword' and 'location columns as we are going to train an RNN only on text data.","8e84fd67":"# Bidirectional LSTM ","4471d79d":"## LSTM","0d312d4a":"\uff0a\uff0a\u3064\u3044\u5148\u65e5RNN\u306e\u52c9\u5f37\u3092\u59cb\u3081\u305f\u306e\u3067\u3001\u305d\u3053\u307e\u3067\u96e3\u3057\u3044\u3053\u3068\u3092\u3057\u3066\u3044\u306a\u3044\u65b9\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u30b3\u30d4\u30fc\u3057\u3066\u4e00\u90e8\u7de8\u96c6\u3057\u3066\u3044\u307e\u3059\u3002\n\u306a\u308b\u3079\u304f\u3001\u77e5\u3089\u306a\u3044\u3053\u3068\u304c\u3042\u3063\u305f\u3089\u8aac\u660e\u3084\u30ea\u30f3\u30af\u3092\u4e57\u3063\u3051\u308b\u3088\u3046\u306b\u3057\u3066\u307e\u3059\u3001","bf16ee73":"\u6587\u5b57\u5217\u3092\u6574\u6570\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db","1f70f8dc":"\u3044\u308d\u3044\u308d\u3044\u3058\u3063\u3066\u307f\u305f\u7d50\u679c\nvalidation-split\u3092\u6975\u7aef\u306b\u4e0a\u3052\u308b\u3068\u305f\u307e\u306b\u3044\u3044\u6570\u5b57\u3092\u51fa\u3059\u3001\uff08\u3088\u304f\u308f\u304b\u3089\u3093\uff09\nvalidation-split\u30920.4\u3050\u3089\u3044\u306b\u3057\u3066\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u3044\u3058\u3063\u3066\u307f\u305f\u304c\u305d\u3093\u306a\u306b\u5909\u308f\u3089\u306a\u3044","8702db88":"## [tokenizer\u306e\u4f7f\u3044\u304b\u305f\u307e\u3068\u3081](https:\/\/weblabo.oscasierra.net\/python\/keras-tokenizer.html)"}}