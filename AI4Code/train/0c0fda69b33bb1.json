{"cell_type":{"637fbc98":"code","c609fca5":"code","574dc8dd":"code","3b26d7c3":"code","9d69b529":"code","03930072":"code","946514dc":"code","8b7a731d":"code","b18a6ae1":"code","44f203a2":"code","c5852845":"code","64623181":"code","3d5d365f":"code","1e1c5651":"code","825f90ca":"code","15766b74":"code","2a0c0aed":"code","d7e4f8c5":"code","5b3d240d":"code","efeba5f6":"code","604189dc":"code","348610ad":"code","96d1d3bb":"code","35341e67":"code","04c3d232":"code","b1cf8a84":"code","4154fe22":"code","8e223226":"code","ec418589":"code","99c4441c":"code","7fb21499":"code","f7df5972":"code","81392a58":"code","dd0ea5d1":"code","00efc086":"code","e6a91229":"code","0799849f":"markdown","74e727b3":"markdown","eda075e8":"markdown","0f9f5419":"markdown"},"source":{"637fbc98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns # data visualization\n\n# Scikit-Learn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\n\n# Warning Library\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c609fca5":"# Read data\ndata = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv', sep=',')","574dc8dd":"# First 5 rows \ndata.head()","3b26d7c3":"# Drop id and Unnamed: 32 from data. \ndata.drop(['id', 'Unnamed: 32'], inplace=True, axis=1) #axis = 1: do it by column","9d69b529":"# Change diagnosis name to target\ndata.rename(columns={'diagnosis': 'target'}, inplace=True)\ndata.head()","03930072":"# Print target column's values\n# Visualize number of target (M and B's)\nsns.countplot(data['target'])\nprint(data.target.value_counts())","946514dc":"# Replace M to 1 and B to 0\ndata['target'] = [1 if i.strip() == 'M' else 0 for i in data.target]","8b7a731d":"print(\"length of the data:\", len(data))\nprint(\"Shape of the data:\", data.shape)","b18a6ae1":"# Information of data\ndata.info()","44f203a2":"data.describe().T","c5852845":"# Correlation\ncorr_matrix = data.corr()","64623181":"ax = sns.heatmap(\n    corr_matrix, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","3d5d365f":"sns.clustermap(corr_matrix, annot=True, fmt=\".2f\")\nplt.title('Correlation Between Features');","1e1c5651":"threshold = 0.75\nfilter_ = np.abs(corr_matrix['target']) > threshold\ncorr_features = corr_matrix.columns[filter_].tolist()\nsns.clustermap(data[corr_features].corr(), annot=True, fmt=\".2f\")\nplt.title(\"Correlation Between Features with Correlation Threshold 0.75\");","825f90ca":"# Box plot\ndata_melted = pd.melt(data,\n                      id_vars='target',\n                      var_name='features',\n                      value_name='value')\nplt.figure()\nsns.boxplot(x='features', y=\"value\", hue='target', data=data_melted)\nplt.xticks(rotation=90)\nplt.show()","15766b74":"# Pair plot\nsns.pairplot(data[corr_features], diag_kind='kde', markers='+', hue='target')\nplt.show();","2a0c0aed":"y = data.target\nX = data.drop('target', axis=1)\ncolumns = X.columns.tolist()","d7e4f8c5":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(X)","5b3d240d":"X_score = clf.negative_outlier_factor_","efeba5f6":"outlier_score = pd.DataFrame()\noutlier_score['score'] = X_score","604189dc":"outlier_score","348610ad":"plt.figure()\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], color='k', s=3, label='Data Points'); ","96d1d3bb":"radius = (X_score.max() - X_score) \/ (X_score.max() - X_score.min())","35341e67":"plt.scatter(X.iloc[:, 0], X.iloc[:, 1], s=1000*radius, edgecolors='r', facecolors='none', label='Outlier Scores')\nplt.legend()\nplt.show()","04c3d232":"plt.figure()\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], color='k', s=3, label='Data Points')\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], s=1000*radius, edgecolors='r', facecolors='none', label='Outlier Scores')\nplt.legend()\nplt.show();","b1cf8a84":"threshold = -2.5\nfilter_ = outlier_score['score'] < threshold\noutlier_index = outlier_score[filter_].index.tolist()","4154fe22":"plt.figure()\nplt.scatter(X.iloc[outlier_index, 0], X.iloc[outlier_index, 1], color='blue', s=50, label='Oultlier Points')\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], color='k', s=3, label='Data Points')\n\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], s=1000*radius, edgecolors='r', facecolors='none', label='Outlier Scores')\nplt.legend()\nplt.show();","8e223226":"# Drop outliers \nX = X.drop(outlier_index)\ny = y.drop(outlier_index).values","ec418589":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)","99c4441c":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","7fb21499":"X_train_df = pd.DataFrame(X_train, columns=columns)","f7df5972":"X_train_df_desc = X_train_df.describe().T","81392a58":"X_train_df['target'] = y_train\n# Box plot\ndata_melted = pd.melt(X_train_df, id_vars='target',\n                     var_name='features', value_name='value')\nplt.figure()\nsns.boxplot(x='features', y='value', hue='target', data=data_melted)\nplt.xticks(rotation=90)\nplt.show()","dd0ea5d1":"# KNN\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nscore = knn.score(X_test, y_test)\nprint(\"Score:\", score)\nprint(\"confusion matrix:\", cm)\nprint(\"Accuracy Score:\", acc)","00efc086":"# Choose best parameters\n\ndef KNN_Best_Params(X_train, X_test, y_train, y_test):\n    k_range = list(range(1, 31))\n    weight_options = ['uniform', 'distance']\n    \n    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n    \n    knn = KNeighborsClassifier()\n    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n    grid.fit(X_train, y_train)\n    \n    print(f'Best training score: {grid.best_score_} with oarameters: {grid.best_params_}')\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(X_train, y_train)\n    \n    y_pred_test = knn.predict(X_test)\n    y_pred_train = knn.predict(X_train)\n    \n    cm_test = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    \n    acc_test = accuracy_score(y_test, y_pred_test)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    \n    print(f\"Test Score : {acc_test}, Train Score : {acc_train}\")\n    print()\n    print(\"Confusion Matrix Test: \", cm_test)\n    print(\"Confusion Matrix Train : \", cm_train)\n    \n    return grid","e6a91229":"grid = KNN_Best_Params(X_train, X_test, y_train, y_test)","0799849f":"**There are some correlated features**","74e727b3":"# **Outlier**","eda075e8":"**EDA**","0f9f5419":"# **Train Test Split**"}}