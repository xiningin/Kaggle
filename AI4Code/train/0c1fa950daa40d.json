{"cell_type":{"df6656f0":"code","4d6167c9":"code","777fa307":"code","b899988e":"code","06d69924":"code","2ba2d84b":"code","0eec2b41":"code","423b7c4d":"code","76899282":"code","92b5f6d3":"code","2768832e":"code","9c26a415":"code","3d0901cb":"code","34d7fe47":"code","635812ae":"code","75d6e429":"code","4236f66c":"code","2ec36b79":"code","4c9939aa":"code","2786562f":"code","3a4dfd39":"code","08e80f70":"code","ee40e453":"markdown","3b5a173f":"markdown","238fc9e3":"markdown","ed5c1042":"markdown","62f17663":"markdown"},"source":{"df6656f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d6167c9":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","777fa307":"\ntrain = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\n# test = pd.read_csv('..\/input\/mobile-price-classification\/test.csv')\n\nX_train = train.drop([\"price_range\"],axis=1)\ny_train = train[\"price_range\"]","b899988e":"print(train.columns)\nprint(train.head())\n\n","06d69924":"# print(test.columns)\n# print(test.head())","2ba2d84b":"train.info()\ntrain.describe()","0eec2b41":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nX_train = sc.fit_transform(X_train)","423b7c4d":"# from sklearn.model_selection import train_test_split\n# X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size = 0.3, random_state = 0)","76899282":"X_train1 = X_train\ny_train1 = y_train","92b5f6d3":"import sklearn","2768832e":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train1, y_train1)","9c26a415":"y_pred_logistic = classifier.predict(X_train1)","3d0901cb":"acc_logistic = round(classifier.score(X_train1,y_train1) * 100, 2)\nprint(acc_logistic)","34d7fe47":"classifier.coef_.shape","635812ae":"weights = classifier.coef_\nbias = classifier.intercept_","75d6e429":"true = 0\npredictions = []\nyidx = y_train1.index\nfor j in range(X_train1.shape[0]):\n    f = [0, 0, 0, 0]\n    for i in range(4):\n        f[i] = np.dot(X_train1[j], weights[i]) + bias[i]\n    pred = f.index(max(f))\n    if (pred == y_train1[yidx[j]]):\n        true += 1\n    predictions.append(pred)","4236f66c":"true \/ X_train1.shape[0]","2ec36b79":"weights[0]","4c9939aa":"weights.shape","2786562f":"bias","3a4dfd39":"weightsWithBias = np.zeros((4, 21))\nfor i in range(4):\n    weightsWithBias[i] = np.append(weights[i],bias[i])","08e80f70":"np.savetxt(\"weights.csv\", weightsWithBias, delimiter=\",\")","ee40e453":"# Importing the dataset","3b5a173f":"# Analyzing the data","238fc9e3":"# Fitting logistic regression to the training set","ed5c1042":"# Importing the libraries","62f17663":"# Splitting the dataset into the Training set and Test set"}}