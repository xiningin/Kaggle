{"cell_type":{"6231211b":"code","2180df5f":"code","cad7baf0":"code","83d12e7c":"code","66ed3679":"code","165eeda6":"code","ae2d89f4":"code","3642596f":"code","75e61211":"code","9095c446":"code","2a9419e0":"code","227a1123":"code","349244fc":"code","660715b3":"code","05073c30":"code","20e4adf4":"code","6e7a692d":"code","3a2e053c":"code","7e6a0e00":"code","47d65b33":"code","42eebc79":"code","23d2fcfb":"code","661f14d1":"code","38770abd":"code","6f9bed15":"code","f2a907f1":"code","855a5d3c":"code","ec62c41d":"code","2320a49a":"code","4573381c":"code","9568bd35":"code","4fbabeab":"code","a711b736":"code","dcb44f69":"code","e680224e":"code","96c6f51c":"code","52caf99c":"code","f3fcba17":"code","9593cfb2":"code","6b4d5499":"code","be52d623":"code","ac68a146":"code","dba1e02e":"code","a22a5dea":"code","262df435":"code","46d03323":"code","95cd4f94":"code","f7db3b09":"code","4056ea70":"code","2e25aa35":"code","4e905097":"code","0180a23c":"code","bdda529e":"code","6419c069":"code","7979a285":"code","8dd20ab6":"code","0133dd35":"code","53a6429b":"code","6f89d76d":"code","4bbd0e76":"code","f81cde23":"code","9b73eb4b":"code","b19ab3df":"code","4aa36846":"code","1232a714":"code","e8b3b5d8":"code","6727cca4":"code","0f899ac2":"code","8d5ce7c8":"code","e8e5d83c":"code","aaff8c99":"markdown","f9801206":"markdown","000e6aae":"markdown","8b053ae1":"markdown","00f16b05":"markdown","e2bb8213":"markdown","a0a73e70":"markdown","7ebe7658":"markdown","7b130a0d":"markdown","9d6e0386":"markdown","6968f688":"markdown","d29dd8c9":"markdown","ec3efd94":"markdown","17574fa3":"markdown","0eb8d2f6":"markdown","f1976a01":"markdown","2dcb071a":"markdown","6af748ac":"markdown","90d0ac53":"markdown","b9c2f69f":"markdown","545d8f6a":"markdown","f81cd289":"markdown","220f7606":"markdown","cd22bd5e":"markdown","67f2f96b":"markdown","a58d3769":"markdown","c941ea26":"markdown","388406cd":"markdown","756293cf":"markdown","7b50329a":"markdown","fc6b0031":"markdown","570f5d66":"markdown","122dad90":"markdown","f57d2ab7":"markdown"},"source":{"6231211b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2180df5f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cad7baf0":"# Local\n# df = pd.read_csv('dataR2.csv')\n\n# kaggle\ndf = pd.read_csv('\/kaggle\/input\/breast-cancer-coimbra-data-set\/dataR2.csv')\ndf.head()","83d12e7c":"df","66ed3679":"plt.figure(figsize=(20,10))\nplt.title('Classification Count')\nsns.countplot(data=df, x ='Classification')","165eeda6":"plt.figure(figsize=(20,10))\nplt.title('Histogram of Age')\nsns.histplot(data=df, x='Age', bins=22, kde=True)","ae2d89f4":"plt.figure(figsize=(20,10))\nsns.boxplot(data=df, x='Age')","3642596f":"plt.figure(figsize=(20,10))\nplt.title('Age vs BMI color by Classification')\nsns.scatterplot(data=df, x='Age',y='BMI', hue='Classification',s=150)","75e61211":"plt.figure(figsize=(20,10))\nplt.title('Heatmap')\nsns.heatmap(data=df.corr(), annot=True)\n","9095c446":"plt.figure(figsize=(20,10))\nplt.title('HOMA vs Glucose color by Classification')\nsns.scatterplot(data=df, x='HOMA',y='Glucose', hue='Classification',s=150)","2a9419e0":"plt.figure(figsize=(20,10))\nplt.title('Leptin vs BMI color by Classification')\nsns.scatterplot(data=df, x='Leptin',y='BMI', hue='Classification',s=150)","227a1123":"df.corr()[['Classification']].sort_values('Classification', ascending= True)[:-1]","349244fc":"plt.figure(figsize=(20,10))\nplt.title('Resistin vs BMI color by Classification')\nsns.scatterplot(data=df, x='Resistin',y='BMI', hue='Classification',s=150)","660715b3":"plt.figure(figsize=(20,10))\nplt.title('Insulin vs HOMA color by Classification')\nsns.scatterplot(data=df, x='Insulin',y='HOMA', hue='Classification',s=150)","05073c30":"plt.figure(figsize=(20,10))\nplt.title('Insulin vs Glucose color by Classification')\nsns.scatterplot(data=df, x='Insulin',y='Glucose', hue='Classification',s=150)","20e4adf4":"plt.figure(figsize=(20,10))\nplt.title('Box Plot of the dataset')\nsns.boxplot(data=df)","6e7a692d":"plt.figure(figsize=(20,10))\nplt.title('Box Plot of the dataset')\nsns.boxplot(data=df.drop(['MCP.1','Classification'], axis=1))","3a2e053c":"plt.figure(figsize=(20,10))\nplt.title('Box Plot of Glucose')\nsns.boxplot(data=df, x='Glucose')","7e6a0e00":"df[(df['Glucose'] < 70) | (df['Glucose'] > 120)]","47d65b33":"plt.figure(figsize=(20,10))\nplt.title('Box Plot of Resistin')\nsns.boxplot(data=df, x='Resistin')","42eebc79":"df[(df['Resistin'] > 35)]","23d2fcfb":"df[(df['Resistin'] > 80)]","661f14d1":"df = df.drop(df[(df['Resistin'] > 80)].index)","38770abd":"plt.figure(figsize=(20,10))\nplt.title('Box Plot of the MCP.1')\nsns.boxplot(data=df, x='MCP.1')","6f9bed15":"df[(df['MCP.1'] > 750)].sort_values('MCP.1')","f2a907f1":"df[(df['MCP.1'] > 1500)]","855a5d3c":"df = df.drop(df[(df['MCP.1'] > 1500)].index)","ec62c41d":"df","2320a49a":"X = df.drop('Classification', axis=1)\ny = df['Classification']","4573381c":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","9568bd35":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","4fbabeab":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","a711b736":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier","dcb44f69":"from warnings import filterwarnings\nfilterwarnings('ignore')","e680224e":"def fit_and_score(models, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train,y_train)\n        model_scores[name] = model.score(X_test,y_test)\n\n    model_scores = pd.DataFrame(model_scores, index=['Score']).transpose()\n    model_scores = model_scores.sort_values('Score')\n        \n    return model_scores","96c6f51c":"models = {'LogisticRegression': LogisticRegression(max_iter=10000),\n          'KNeighborsClassifier': KNeighborsClassifier(),\n          'SVC': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier(),\n          'RandomForestClassifier': RandomForestClassifier(),\n          'AdaBoostClassifier': AdaBoostClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier(),\n          'XGBClassifier': XGBClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'XGBRFClassifier': XGBRFClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'LGBMClassifier':LGBMClassifier()}","52caf99c":"baseline_model_scores = fit_and_score(models, X_train, X_test, y_train, y_test)","f3fcba17":"baseline_model_scores","9593cfb2":"plt.figure(figsize=(20,10))\nsns.barplot(data=baseline_model_scores.sort_values('Score').T)\nplt.title('Baseline Model Precision Score')\nplt.xticks(rotation=90);","6b4d5499":"from sklearn.model_selection import RandomizedSearchCV","be52d623":"def randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_rs_scores = {}\n    model_rs_best_param = {}\n    \n    for name, model in models.items():\n        rs_model = RandomizedSearchCV(model,\n                                     param_distributions=params[name],\n                                      cv=3,\n                                     n_iter=30,\n                                     verbose=0)        \n        rs_model.fit(X_train,y_train)\n        model_rs_scores[name] = rs_model.score(X_test,y_test)\n        model_rs_best_param[name] = rs_model.best_params_\n        \n    return model_rs_scores, model_rs_best_param","ac68a146":"models = {'SVC': SVC(),\n         'LogisticRegression': LogisticRegression(max_iter=10000),\n         'KNeighborsClassifier': KNeighborsClassifier()}\n\nparams = {'SVC':{},\n          'LogisticRegression':{},\n          'KNeighborsClassifier': {}\n         }","dba1e02e":"model_rs_scores_base, model_rs_best_param_base = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","a22a5dea":"model_rs_scores_base","262df435":"models = {'SVC': SVC(),\n         'LogisticRegression': LogisticRegression(max_iter=10000),\n         'KNeighborsClassifier': KNeighborsClassifier()}\n\nparams = {'SVC':{'C' : np.linspace(0.1,0.9, 9),\n                'kernel':['linear', 'ploy', 'rbf', 'sigmoid'],\n                'gamma': np.linspace(0,1,11),\n                },\n          'LogisticRegression':{'penalty': ['l1','l2','elasticnet','none'],\n                               'C' : np.linspace(0.1,0.9, 9),\n                               'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                               'l1_ratio': np.linspace(0.1,0.9, 9)},\n          'KNeighborsClassifier': {'n_neighbors': np.arange(1,59,10),\n                                  'weights': ['uniform','distance'],\n                                  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                                  'leaf_size': np.arange(1,101,10),\n                                  'p': np.arange(1,10),\n                                  }\n         }","46d03323":"model_rs_scores1, model_rs_best_param1 = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","95cd4f94":"model_rs_scores1","f7db3b09":"model_rs_best_param1","4056ea70":"params = {'SVC':{'C' : np.linspace(0.4,0.6, 9),\n                'kernel':['linear', 'ploy', 'rbf', 'sigmoid'],\n                'gamma': np.linspace(0.3,0.5,11),\n                },\n          'LogisticRegression':{'penalty': ['l1','l2','elasticnet','none'],\n                               'C' : np.linspace(0.0,0.2, 9),\n                               'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                               'l1_ratio': np.linspace(0.1,0.3, 9)},\n          'KNeighborsClassifier': {'n_neighbors': np.arange(15,30),\n                                  'weights': ['uniform','distance'],\n                                  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                                  'leaf_size': np.arange(1,10),\n                                  'p': [2],\n                                  }\n         }","2e25aa35":"model_rs_scores2, model_rs_best_param2 = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","4e905097":"model_rs_scores2","0180a23c":"model_rs_best_param2","bdda529e":"from sklearn.model_selection import GridSearchCV","6419c069":"def gridsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_gs_scores = {}\n    model_gs_best_param = {}\n    \n    for name, model in models.items():\n        gs_model = GridSearchCV(model,\n                                param_grid=params[name],\n                                n_jobs=-1,\n                                cv=5,\n                                verbose=0)\n        \n        gs_model.fit(X_train,y_train)\n\n        model_gs_scores[name] = gs_model.score(X_test,y_test)\n        model_gs_best_param[name] = gs_model.best_params_\n\n    model_gs_scores = pd.DataFrame(model_gs_scores, index=['Accuracy'])\n    model_gs_scores = model_gs_scores.transpose().sort_values('Accuracy')\n        \n    return model_gs_scores, model_gs_best_param","7979a285":"models = {'SVC': SVC(),\n         'LogisticRegression': LogisticRegression(max_iter=10000),\n         'KNeighborsClassifier': KNeighborsClassifier()}\n\nparams = {'SVC':{'C' : np.linspace(0.4,0.6, 9),\n                'kernel':['linear', 'ploy', 'rbf', 'sigmoid'],\n                'gamma': np.linspace(0.3,0.5,11),\n                },\n          'LogisticRegression':{'penalty': ['l1','l2','elasticnet','none'],\n                               'C' : np.linspace(0.0,0.2, 9),\n                               'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                               'l1_ratio': np.linspace(0.1,0.3, 9)},\n          'KNeighborsClassifier': {'n_neighbors': np.arange(15,30),\n                                  'weights': ['uniform','distance'],\n                                  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                                  'leaf_size': np.arange(1,10),\n                                  'p': [2],\n                                  }\n         }","8dd20ab6":"model_gs_scores_1, model_gs_best_param_1 = gridsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","0133dd35":"model_gs_scores_1","53a6429b":"model_gs_best_param_1","6f89d76d":"from sklearn.metrics import classification_report, plot_confusion_matrix,plot_roc_curve\nfrom sklearn.model_selection import cross_val_score","4bbd0e76":"model = LogisticRegression(C=0.2, l1_ratio=0.25, penalty='elasticnet',solver='saga')","f81cde23":"model.fit(X_train,y_train)\ny_preds = model.predict(X_test)","9b73eb4b":"print(classification_report(y_test,y_preds))","b19ab3df":"plot_confusion_matrix(model, X_test, y_test)","4aa36846":"plot_roc_curve(model,X_test,y_test)","1232a714":"feat_importances = pd.DataFrame(model.coef_[0], index=X.columns)","e8b3b5d8":"feat_importances","6727cca4":"plt.figure(figsize=(20,10))\nplt.xticks(rotation=90)\nplt.title('Feature Importances')\nsns.barplot(data= feat_importances.sort_values(0).T);","0f899ac2":"def get_cv_score(model, X, y, cv=5):\n    \n    \n    cv_accuracy = cross_val_score(model,X,y,cv=cv,\n                         scoring='accuracy')\n    print(f'Cross Validaion accuracy Scores: {cv_accuracy}')\n    print(f'Cross Validation accuracy Mean Score: {cv_accuracy.mean()}')\n    \n    cv_precision = cross_val_score(model,X,y,cv=cv,\n                         scoring='precision')\n    print(f'Cross Validaion precision Scores: {cv_precision}')\n    print(f'Cross Validation precision Mean Score: {cv_precision.mean()}')\n    \n    cv_recall = cross_val_score(model,X,y,cv=cv,\n                         scoring='recall')\n    print(f'Cross Validaion recall Scores: {cv_recall}')\n    print(f'Cross Validation recall Mean Score: {cv_recall.mean()}')\n    \n    cv_f1 = cross_val_score(model,X,y,cv=cv,\n                         scoring='f1')\n    print(f'Cross Validaion f1 Scores: {cv_f1}')\n    print(f'Cross Validation f1 Mean Score: {cv_f1.mean()}')   \n    \n    cv_merics = pd.DataFrame({'Accuracy': cv_accuracy.mean(),\n                         'Precision': cv_precision.mean(),\n                         'Recall': cv_recall.mean(),\n                         'f1': cv_recall.mean()},index=[0])\n    \n    return cv_merics","8d5ce7c8":"cv_merics = get_cv_score(model, X_train, y_train, cv=5)","e8e5d83c":"cv_merics","aaff8c99":"With the grid CV done, we will use the LogisticRegression to build the final model and do the evalution on it.","f9801206":"## Standard Imports","000e6aae":"# 5. Modelling","8b053ae1":"# 4. Features\n\n## Inputs \/  Features\n\n    1. Age (years)\n    2. BMI (kg\/m2)\n    3. Glucose (mg\/dL)\n    4. Insulin (\u00b5U\/mL)\n    5. HOMA\n    6. Leptin (ng\/mL)\n    7. Adiponectin (\u00b5g\/mL)\n    8. Resistin (ng\/mL)\n    9. MCP-1(pg\/dL)\n\n## Output \/ Label\n    10. Classification - 1 = Healthy controls \/ 2 = Patients\n","00f16b05":"## Confusion Matrix","e2bb8213":"## Classification Report","a0a73e70":"## RS Model 1","7ebe7658":"# 1. Problem Definition\n\nHow we can use various python based Machine Learning Model and the given parameters to predict if the person has Breast Cancer?","7b130a0d":"## RS model 2","9d6e0386":"# Breast Cancer Classification","6968f688":"with the model, with the CV evalution, we are able to get the following:\n\n    Accuracy 0.775163\n    Precision 0.738333 \t\n    Recall 0.808333 \t\n    f1 0.808333\t \t","d29dd8c9":"Going to take the following approach:\n\n1. Problem definition\n2. Data\n3. Evaluation\n4. Features\n5. Modelling\n6. Model Evaluation\n7. Experimentation \/ Improvements","ec3efd94":"# 7. Experimentation \/ Improvements\n\nwith a lower scoring model of 78% accuracy in the CV and for cancer classification, we hope to get a better scoring model.\n\nmaybe we can look into the follow for improvements:\n\n    1. Check for other outliers?\n    2. Build and looking in to the data again to build a better model\n    3. Getting more data, as the current dataset is small","17574fa3":"## Feature Importance","0eb8d2f6":"## Evalution using cross-validation","f1976a01":"## Data Exporation","2dcb071a":"# 6. Model Evaluation","6af748ac":"we will not consider this as outliers as the Glucose high usually indicates the classification as 2","90d0ac53":"## Model Imports","b9c2f69f":"## GS model 1","545d8f6a":"## Grid Search CV","f81cd289":"let's take a look at the follow as it has closer correlation to the Classification:\n    \n    BMI \t-0.132586\n    Resistin \t0.227310\n    Insulin \t0.276804\n    HOMA \t0.284012\n    Glucose \t0.384315\n","220f7606":"This are the follow models we can have a closer look at as it provides a better R2 score\n\n    LogisticRegression \t0.826087\n    KNeighborsClassifier \t0.826087\n    SVC \t0.826087","cd22bd5e":"## Baseline CV model","67f2f96b":"## Random Search CV","a58d3769":"# 3. Evaluation\n\nAs this is a classification problem, we will use the classification metics for evauluting the model","c941ea26":"On Closer look, we will drop the follow rows as they look to be outliers","388406cd":"#### Finding outliers","756293cf":"we will drop this as it is an outlier","7b50329a":"## Reading the Dataset","fc6b0031":"## Baseline model scores","570f5d66":"## ROC Curve","122dad90":"# 2. Data\n\nData from: https:\/\/www.kaggle.com\/yasserhessein\/breast-cancer-coimbra-data-set\n\n## Data Set Information:\n\nThere are 10 predictors, all quantitative, and a binary dependent variable, indicating the presence or absence of breast cancer.\nThe predictors are anthropometric data and parameters which can be gathered in routine blood analysis.\nPrediction models based on these predictors, if accurate, can potentially be used as a biomarker of breast cancer.\n\n## Source:\n\nMiguel Patr\u00edcio(miguelpatricio '@' gmail.com), Jos\u00e9 Pereira (jafcpereira '@' gmail.com), Joana Cris\u00f3stomo (joanacrisostomo '@' hotmail.com), Paulo Matafome (paulomatafome '@' gmail.com), Raquel Sei\u00e7a (rmfseica '@' gmail.com), Francisco Caramelo (fcaramelo '@' fmed.uc.pt), all from the Faculty of Medicine of the University of Coimbra and also Manuel Gomes (manuelmgomes '@' gmail.com) from the University Hospital Centre of Coimbra","f57d2ab7":"Dataset's label is balanced but is not very big"}}