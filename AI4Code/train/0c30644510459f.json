{"cell_type":{"36010898":"code","0a68f40b":"code","e1e81055":"code","fc1dba78":"code","c7f11a30":"code","f21059ec":"code","59135f84":"code","9de0f58e":"code","e6c42413":"code","36fd585a":"code","c185d1d8":"code","7efc6e7b":"code","2ac10739":"code","a61b0757":"code","adcdee2c":"code","6b5d8279":"code","36f1ae18":"code","bdc890f0":"code","50325fc5":"code","cc96ce97":"code","484efdd7":"code","83bc4a43":"code","6300a0a0":"code","46bb0eff":"code","eedcedad":"code","c212aac5":"code","4fcceb4d":"code","dc1df2e9":"code","cc8add56":"code","5a5f2058":"code","a78b9797":"code","e51663e2":"code","92845d05":"code","8dacc230":"code","520b8a99":"code","7cd07ee9":"code","4991f356":"code","b1b9030c":"code","239eb4f8":"code","673ae385":"code","95d01759":"code","f46610d0":"code","60476c8c":"code","f3d6f470":"code","4b169164":"code","7acc2099":"code","de63ccb8":"code","1bf1eb3b":"code","62373fd8":"code","2648f2b6":"code","d9ef5250":"code","b4f1d4ae":"code","a7e7697a":"code","8e6c7625":"code","3922354d":"code","6bd0da23":"code","46a7f587":"code","d466dc89":"code","d378dda2":"code","134739b3":"code","3d87ed2a":"code","aa5af6f7":"markdown","1de463fc":"markdown","41390771":"markdown","a0cb1370":"markdown","4273fff8":"markdown","1857fa63":"markdown","b94169dd":"markdown","c6a12cbc":"markdown","fed2da37":"markdown","b80be93e":"markdown","0770d8ee":"markdown","9e33e336":"markdown","9ef286db":"markdown","4fb08e8d":"markdown","d9581a54":"markdown","c06bccef":"markdown","3bd2873c":"markdown","7adf517e":"markdown","3f73b7ea":"markdown","062361c7":"markdown","037c8d1d":"markdown","7bc584cf":"markdown","2110cbe4":"markdown","4db1a076":"markdown","7996d6de":"markdown","90baecf4":"markdown"},"source":{"36010898":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a68f40b":"from tqdm.notebook import tqdm","e1e81055":"import tensorflow as tf","fc1dba78":"import seaborn as sns","c7f11a30":"!pip install ktrain","f21059ec":"import ktrain","59135f84":"#df=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip\")\n#df=pd.read_csv(\"\/kaggle\/input\/d\/julian3833\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\n#\/kaggle\/input\/d\/julian3833\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv\n#\/kaggle\/input\/d\/julian3833\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv\n\n#\/kaggle\/input\/d\/julian3833\/jigsaw-toxic-comment-classification-challenge\/test.csv\n\ndf=pd.read_csv(\"\/kaggle\/input\/toxicity-2022-augumentation\/augumented_train_set.csv\",index_col=0)","9de0f58e":"df_valid=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\",index_col=0)","e6c42413":"comments_to_score=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\",index_col=0)","36fd585a":"df.head(1)","c185d1d8":"df.describe()","7efc6e7b":"class_1,class_2 = df.toxic.value_counts()\nprint(class_1,class_2)","2ac10739":"class_2","a61b0757":"#df.toxic ","adcdee2c":"df.predicted_score.value_counts()","6b5d8279":"\nc2 = df[df[\"toxic\"] >0]\nc1 = df[df.toxic == 0]\nprint(len(c1),len(c2))\ndf_2 = c1.sample(class_2)\nprint(len(df_2))","36f1ae18":"undersampled_df = pd.concat([df_2,c2],axis=0)\nundersampled_df.drop_duplicates(subset =\"comment_text\",keep = False, inplace = True)","bdc890f0":"df=undersampled_df","50325fc5":"print(len(undersampled_df))","cc96ce97":"#df=df.sample(3000)\n#df_valid=df_valid.sample(3000)\n#comments_to_score=comments_to_score.sample(3000)","484efdd7":"comments_to_score.head()","83bc4a43":"df.head()","6300a0a0":"#df['score']=df['toxic']+2*df['severe_toxic']+3*df['obscene']+4*df['threat']+5*df['identity_hate']\n#df['score']=2*df['toxic']+4*df['severe_toxic']+df['obscene']+4*df['threat']+df['insult']+4*df['identity_hate']+df['predicted_score']\n#df['score']=df['toxic']+2*df['severe_toxic']+df['obscene']+df['threat']+df['insult']+df['identity_hate']+0.5*df['predicted_score']\n#df['score']=df['toxic']+2*df['severe_toxic']+df['obscene']+df['threat']+df['insult']+df['identity_hate']\ndf['score']=0.32*df['toxic']+1.5*df['severe_toxic']+0.16*df['obscene']+1.5*df['threat']+0.64*df['insult']+1.5*df['identity_hate']\n#df['score']=2*(df['toxic']+2*df['severe_toxic']+0.5*df['obscene']+df['threat']+0.5*df['insult']+df['identity_hate'])+df['predicted_score']","46bb0eff":"#df['score']=2*df['score']","eedcedad":"#this was used for romanian language in original script. \n#df=df.replace(regex={r'\u0163': '\u021b', '\u015f': '\u0219','\u0162': '\u021a', '\u015e': '\u0218'})","c212aac5":"df.rename(columns={'comment_text':'sentences'},inplace=True)\n#df.rename(columns={'sentiments_tags':'labels'},inplace=True)","4fcceb4d":"import seaborn as sns\nsns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"score\", data=df)","dc1df2e9":"df.score.value_counts()","cc8add56":"df.describe()","5a5f2058":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.25)\ntest, valid = train_test_split(test, test_size=0.05)","a78b9797":"description_train = train.sentences.values\n\ndescription_test = test.sentences.values\n\n\nX_less_toxic =df_valid.less_toxic.values\nX_more_toxic =df_valid.more_toxic.values\nX_comments_to_score =comments_to_score.text.values","e51663e2":"print(len(description_train),len(description_test))","92845d05":"#etichete'\n#y_train = train.labels.to_numpy()\n#y_valid = valid.labels.to_numpy()\n#y_test = test.labels.to_numpy()\nlabels_train = train.score.values\nlabels_test = test.score.values","8dacc230":"print(len(labels_train),len(labels_test))","520b8a99":"x_train = description_train\ny_train = labels_train\nx_test = description_test\ny_test = labels_test","7cd07ee9":"#x_train","4991f356":"#y_test","b1b9030c":"from ktrain import text","239eb4f8":"text.print_text_regression_models()","673ae385":"trn, val, preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n                                          x_test=x_test, y_test=y_test,\n                                          ngram_range=1, \n                                          maxlen=300, \n                                          max_features=50000)\n\n# model = text.text_regression_model('bigru', train_data=trn, preproc=preproc)\n# learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32)","95d01759":"model = text.text_regression_model('bigru', train_data=trn, preproc=preproc)\nlearner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32)","f46610d0":"learner.lr_find(max_epochs=2)","60476c8c":"learner.lr_plot()","f3d6f470":"learner.fit_onecycle(2e-4, 3)","4b169164":"learner.plot('loss')","7acc2099":"learner.autofit(2e-5, 5)","de63ccb8":"learner.plot('loss')","1bf1eb3b":"learner.view_top_losses(n=3, preproc=preproc)","62373fd8":"predictor = ktrain.get_predictor(learner.model, preproc)","2648f2b6":"idx = np.random.randint(len(x_test))\nprint('Description: %s' % (x_test[idx]))\nprint('Actual score: %s' % (y_test[idx]))","d9ef5250":"predictor.predict(x_test[idx])","b4f1d4ae":"p1 = predictor.predict(X_less_toxic)\np2 = predictor.predict(X_more_toxic)\n# Validation Accuracy\n(p1 < p2).mean()","a7e7697a":"print( \"performance is :\",(p1 < p2).mean())","8e6c7625":"predicted_scores = predictor.predict(X_comments_to_score)\n","3922354d":"comments_to_score.head()","6bd0da23":"comments_to_score['score']=predicted_scores","46a7f587":"submission=comments_to_score[['score']]","d466dc89":"submission.to_csv('submission.csv')","d378dda2":"submission.head()","134739b3":"df_valid['p1_score']=p1\ndf_valid['p2_score']=p2","3d87ed2a":"df_valid.to_csv('validationscores.csv')","aa5af6f7":"Prepare the dataset for tokenisation","1de463fc":"Let's make a prediction for a random text in the validation set.","41390771":"Load evaluation dataset","a0cb1370":"A very simple regression exercise. 0.800 rating with no tweak.","4273fff8":"The dataset from previous competition is loaded. The scoring is the real challange. ","1857fa63":"Load training dataset","b94169dd":"**STEP 2: Create a Text Regression Model and Wrap in Learner**","c6a12cbc":"**STEP 1: Preprocess the Data**","fed2da37":"**STEP 3: Estimate the LR**","b80be93e":"STEP 5: Making Predictions","0770d8ee":"Scoring experiments. ","9e33e336":"Testing","9ef286db":"Evaluation using validation_data.csv","4fb08e8d":"**STEP 5: Making Predictions**","d9581a54":"Warning: for competition the fasttext vector must be downloaded here, since no internet acces is permited. ","c06bccef":"Split in train and test. The validation subset is not used here. \nImpartire date in instruire test si validare","3bd2873c":"Testare","7adf517e":"Dataframe description","3f73b7ea":"Load pretrained vectors for ktrain","062361c7":"STEP 4: Train and Inspect the Model","037c8d1d":"Samplig for testing purpose\n-to be commenteted for submission","7bc584cf":"Thanks to Arun S. Maiya creator of the tutorial\nhttps:\/\/nbviewer.org\/github\/amaiya\/ktrain\/blob\/master\/tutorials\/tutorial-A3-hugging_face_transformers.ipynb","2110cbe4":"Load comments to score","4db1a076":"Verificare interna.","7996d6de":"Manual tuning","90baecf4":"Undersampling majority class"}}