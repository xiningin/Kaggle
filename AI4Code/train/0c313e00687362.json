{"cell_type":{"c932ddb5":"code","32b53735":"code","825d8304":"code","2985f212":"code","685c3b8e":"code","cad74a39":"code","fcf4e111":"code","405861cf":"code","885e1f88":"code","8f25a852":"code","32b24a7b":"code","79a6eb9f":"code","20e867fc":"code","436be6d9":"markdown","e900c4ae":"markdown"},"source":{"c932ddb5":"from keras.layers import Dense, Conv2D, Flatten\nfrom keras.layers import MaxPooling2D, Activation, Dropout\nfrom keras.models import Sequential, load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom keras.backend import image_data_format\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import TensorBoard\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport datetime as dt\nimport numpy as np\nimport cv2\nimport os\n%matplotlib inline","32b53735":"train_path = r'..\/input\/petclassdata\/pet_class_data\/train'\ntest_path = r'..\/input\/petclassdata\/pet_class_data\/test'","825d8304":"os.listdir(train_path), os.listdir(test_path)","2985f212":"# creating Image generator to create more data samples\ntrain_gen = ImageDataGenerator(\n            rotation_range=10,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            rescale=1.\/255,\n            horizontal_flip=True,\n            vertical_flip=True,\n            validation_split=0.25,\n            fill_mode='nearest')\n\ntest_gen = ImageDataGenerator(rescale=1.\/255)\n\ndef create_sample_dataset(train_path, test_path, train_samples=0, test_samples=0):\n    # creating samples for training data\n    for fold in os.listdir(train_path):\n        for t_img in glob(train_path + '\/' + fold + '\/*.jpg'):\n            img = img_to_array(load_img(t_img))\n            img = img.reshape((1,) + img.shape)\n            i = 0\n            for batch in train_gen.flow(img, \n                                         batch_size=1,\n                                         save_to_dir=train_path + '\/' + fold,\n                                         save_prefix=fold,\n                                         save_format='jpg'):\n                if i == new_train_samples:\n                    break\n                i += 1\n\n\n    # creating samples for testing data\n    for fold in os.listdir(test_path):\n        for t_img in glob(test_path + '\/' + fold + '\/*.jpg'):\n            img = img_to_array(load_img(t_img))\n            img = img.reshape((1, ) + img.shape)\n            i = 0\n            for batch in test_gen.flow(img, \n                                         batch_size=1,\n                                         save_to_dir=test_path + '\/' + fold,\n                                         save_prefix=fold,\n                                         save_format='jpg'):\n                if i == new_test_samples:\n                    break\n                i += 1","685c3b8e":"# new_train_samples = 50\n# new_test_samples = 20\n# create_sample_dataset(train_path, test_path, new_train_samples, new_test_samples)","cad74a39":"batch_size = 32\ntrain_image = train_gen.flow_from_directory(train_path,\n                                           target_size=(150, 150),\n                                           batch_size=batch_size,\n                                           subset='training',\n                                           class_mode='binary')\n\nvalidation_image = train_gen.flow_from_directory(train_path,\n                                           target_size=(150, 150),\n                                           batch_size=batch_size,\n                                           subset='validation',\n                                           class_mode='binary')\n\nif image_data_format == 'channels_first':\n    input_shape = (3, 150, 150)\nelse:\n    input_shape = (150, 150, 3)","fcf4e111":"def get_model():\n    model = Sequential()\n\n    # First Convolutional layer\n    model.add(Conv2D(64, (3, 3), input_shape=input_shape, activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    # Second Convolutional layer\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    # Flattening the input\n    model.add(Flatten())\n\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.4))\n\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n            #  optimizer='sgd',\n            #  optimizer='rmsprop',\n             metrics=['accuracy'])\n\n    print('Model building done')\n    return model\n\n\ndef run_model(model, train_samples, test_samples, train_image, test_image, iteration=0, batch_size=8):\n    my_callbacks = [\n#     EarlyStopping(patience=8),\n    ModelCheckpoint(filepath='..\/model_cp.{epoch:02d}-{val_loss:.2f}.h5')\n#     TensorBoard(log_dir='\/content\/drive\/My Drive\/datasets\/pet_class_data\/model_checkpoint\/logs')\n    ]\n    model.fit_generator(train_image,\n                   steps_per_epoch=train_samples\/\/batch_size,\n                   epochs=iteration,\n                   validation_steps=test_samples\/\/batch_size,\n                   callbacks = my_callbacks,\n                   validation_data=validation_image\n                   )\n    # list all data in history\n    history = model.history\n    # print(history.history.keys())\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'])\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'])\n    plt.show()  ","405861cf":"train_samples, validation_samples = train_image.samples, validation_image.samples\nprint('Total train samples: {} and classes {}\\nTotal test samples: {} and classes {}'.format(train_samples, np.unique(train_image.classes), validation_samples, np.unique(validation_image.classes)))\nmy_model = get_model()\nmy_model.summary()","885e1f88":"# running model\nepochs = 150\nmy_model = get_model()\nrun_model(my_model, train_samples, validation_samples, train_image, validation_image, iteration=epochs, batch_size=batch_size)\nmy_model.save(r'\/content\/drive\/My Drive\/datasets\/pet_class_data\/model\/model_'+str(epochs)+'_'+str(dt.datetime.now()))","8f25a852":"history = my_model.history\nmax(history.history['accuracy']), max(history.history['val_accuracy'])","32b24a7b":"min(history.history['loss']), min(history.history['val_loss'])","79a6eb9f":"image = '..\/input\/petclassdata\/pet_class_data\/test\/cats\/cats_0_1140.jpg'\nimg = cv2.imread(image)\nplt.imshow(img)\nplt.show()\nimg = cv2.resize(img,(150,150))\nimg = np.reshape(img, (1, 150, 150, 3))\nclasses = my_model.predict_classes(img)\nprint(classes)","20e867fc":"image = '..\/input\/petclassdata\/pet_class_data\/test\/dogs\/101.jpg'\nimg = cv2.imread(image)\nplt.imshow(img)\nplt.show()\nimg = cv2.resize(img,(150,150))\nimg = np.reshape(img, (1, 150, 150, 3))\nclasses = my_model.predict_classes(img)\nprint(classes)","436be6d9":"**Sample prediction to check the model performance on new image**","e900c4ae":"#### Pet Classification Model Using CNN.\n\nPROJECT DESCRIPTION\n\nBuild a CNN model that classifies the given pet images correctly into dog and cat images. \n\nThe CNN model is having the following layers: \n\n        Input layer \n\n        Convolutional layer 1 with 32 filters of kernel size[3, 3] \n        Pooling layer 1 with pool size[2,2] and stride 2 \n\n        Convolutional layer 2 with 64 filters of kernel size[3, 3] \n        Pooling layer 2 with pool size[2,2] and stride 2 \n\n        Flattening the Input \n\n        Dense layer with 64 nodes, activation 'ReLU' dropout = 0.2\n\n        Dense layer with 32 nodes, activation 'ReLU' dropout = 0.4\n\n        Output layer with 1 node, activation 'Sigmoid'"}}