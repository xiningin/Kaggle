{"cell_type":{"f7c18755":"code","46e313f1":"code","12d9aca1":"code","f66e8ef2":"code","9facca32":"code","446a4aa9":"code","eb188936":"code","9350338a":"code","1e399f66":"code","747ba702":"code","fe29e0e7":"code","11a0f613":"code","f18ac64a":"code","c820c2a1":"code","6860f5d2":"code","41f15760":"markdown","d09a6ad3":"markdown","64765d53":"markdown","03d8c6d9":"markdown","c9849626":"markdown","3dfc4f4e":"markdown","299813b6":"markdown","f49cd67b":"markdown","cd77adf3":"markdown","eadb74cd":"markdown","c9fa963a":"markdown","bbb625d2":"markdown","28779e89":"markdown","4b50cfa3":"markdown","59e3140f":"markdown","a7b1bc99":"markdown","884b5e9c":"markdown"},"source":{"f7c18755":"import tensorflow.compat.v1 as tf\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom scipy.io import loadmat\nimport os\nfrom pywt import wavedec\nfrom functools import reduce\nfrom scipy import signal\nfrom scipy.stats import entropy\nfrom scipy.fft import fft, ifft\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras as K\nimport matplotlib.pyplot as plt\nimport scipy\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold,cross_validate\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import Sequential, Model, load_model\nimport matplotlib.pyplot as plt;\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv1D,Conv2D,Add\nfrom tensorflow.keras.layers import MaxPool1D, MaxPooling2D\nimport seaborn as sns","46e313f1":"data = pd.read_csv(\"..\/input\/eeg-brainwave-dataset-feeling-emotions\/emotions.csv\")\nprint(data.info())","12d9aca1":"data","f66e8ef2":"fft_data = data.loc[:,'fft_0_b':'fft_749_b']","9facca32":"fft_data","446a4aa9":"fft_data.iloc[0,:].plot(figsize=(15,10))","eb188936":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['label']=le.fit_transform(data['label'])","9350338a":"y = data.pop('label')\nX = data\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=48)\nX_train = np.array(X_train).reshape((X_train.shape[0],X_train.shape[1],1))\nX_test = np.array(X_test).reshape((X_test.shape[0],X_test.shape[1],1))\ny_train = pd.get_dummies(y_train)\ny_test = pd.get_dummies(y_test)","1e399f66":"inputs = tf.keras.Input(shape=(X_train.shape[1],1))\n\ngru = tf.keras.layers.GRU(256, return_sequences=True)(inputs)\nflat = Flatten()(gru)\noutputs = Dense(3, activation='softmax')(flat)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary()","747ba702":"tf.keras.utils.plot_model(model)","fe29e0e7":"def train_model(model,x_train, y_train,x_test,y_test, save_to, epoch = 2):\n\n        opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n\n        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n        mc = ModelCheckpoint(save_to + '_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch \/ 10.))\n        \n        model.compile(optimizer=opt_adam,\n                  loss=['categorical_crossentropy'],\n                  metrics=['accuracy'])\n        \n        history = model.fit(x_train,y_train,\n                        batch_size=32,\n                        epochs=epoch,\n                        validation_data=(x_test,y_test),\n                        callbacks=[es,mc,lr_schedule])\n        \n        saved_model = load_model(save_to + '_best_model.h5')\n        \n        return model,history","11a0f613":"model,history = train_model(model, X_train, y_train,X_test, y_test, save_to= '.\/', epoch = 40) ","f18ac64a":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c820c2a1":"model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\nprint(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))","6860f5d2":"y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))\ny_test = y_test.idxmax(axis=1)\n\ncm = confusion_matrix(y_test, y_pred)\nclr = classification_report(y_test, y_pred)\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","41f15760":"The 3 labels are : \"NEGATIVE\", \"NEUTRAL\" and \"POSITIVE\".","d09a6ad3":"### Plotting the validation curves ","64765d53":"The loss function used will be 'Categorical_CrossEntropy'. We will be using callback functions like Early_Stopping to avoid overfitting and lr_scheduler to change the learning rate while model trains.\n\nWe will be training for 100 epochs starting with learning_rate = 0.001 and batch_size = 64.","03d8c6d9":"### Importing necessary libraries","c9849626":"### Training the model. ","3dfc4f4e":"2. Confusion matrix along with classification reports (includes metrics like precision, F1-score)","299813b6":"### Defining the Model's architecture ","f49cd67b":"1. Test accuracy","cd77adf3":"### Plotting the model ","eadb74cd":"### Viewing a sample of time series data ","c9fa963a":"![](https:\/\/2rdnmg1qbg403gumla1v9i2h-wpengine.netdna-ssl.com\/wp-content\/uploads\/sites\/3\/2014\/04\/brainFacts-579411100-770x533-1-745x490.jpg)","bbb625d2":"### Encoding the 3 distinct labels ","28779e89":"### Reading EEG data with feature extracted ","4b50cfa3":"Problem in hand : Given EEG data from subjects who were watching movies, let's try to predict the emotional state of a subject during a given movie.","59e3140f":"## Please upvote if you found it useful :) ","a7b1bc99":"### Evaluating the model ","884b5e9c":"### Defining necessary features for model training. "}}