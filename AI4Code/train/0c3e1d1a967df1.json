{"cell_type":{"aff845d6":"code","bb54c520":"code","350e15f8":"code","3df98756":"code","16aae4b8":"code","958278e0":"code","006a7792":"code","252613cf":"code","2e4d081c":"code","db8ae756":"code","08449c50":"code","0908d368":"code","b6bc49a1":"code","ddd1bde1":"code","299b3a00":"code","48bf325b":"code","fe7bc0e2":"code","b0e3d202":"code","d5d7afea":"code","51ffbf3b":"code","cde517fc":"code","d5cc9a91":"code","49ae34bc":"code","623decab":"code","413bb051":"code","833ecb02":"code","fbcd9f94":"code","40c917ac":"markdown","a3e1c616":"markdown","33cb280e":"markdown","7e84ecc7":"markdown","e19ea764":"markdown","cb20f797":"markdown","39adca53":"markdown","9c184fb2":"markdown","22b1737e":"markdown","f6da9472":"markdown","596518d3":"markdown","8a81a2f7":"markdown","4e1e62e5":"markdown","b2c77434":"markdown","842966ae":"markdown","2a3b7ca5":"markdown","4ed17688":"markdown"},"source":{"aff845d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb54c520":"import pickle # to read .p files\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping\nimport pandas as pd\nimport matplotlib.pyplot as plt","350e15f8":"train_file = open(\"\/kaggle\/input\/germantrafficsigns\/train.p\", \"rb\")\ntrain_data_full = pickle.load(train_file)\ntrain_file.close()\n\nvalid_file = open(\"\/kaggle\/input\/germantrafficsigns\/valid.p\", \"rb\")\nvalid_data_full = pickle.load(valid_file)\nvalid_file.close()\n\ntest_file = open(\"\/kaggle\/input\/germantrafficsigns\/test.p\", \"rb\")\ntest_data_full = pickle.load(test_file)\ntest_file.close()","3df98756":"print(train_data_full.keys())\nprint(\"features shape: \", train_data_full[\"features\"].shape)\nprint(\"labels shape: \", train_data_full[\"labels\"].shape)","16aae4b8":"train_data = train_data_full[\"features\"]\nvalid_data = valid_data_full[\"features\"]\ntest_data = test_data_full[\"features\"]\n\n# normalization\ntrain_data = train_data\/255.0\nvalid_data = valid_data\/255.0\ntest_data = test_data\/255.0\n\n# prepare labels\ntrain_labels = to_categorical(train_data_full[\"labels\"]) \nvalid_labels = to_categorical(valid_data_full[\"labels\"])\ntest_labels = to_categorical(test_data_full[\"labels\"])","958278e0":"train_data[100]\npicture = train_data[100]\nplt.imshow(picture)\nplt.show()","006a7792":"signnames = pd.read_csv(\"\/kaggle\/input\/germantrafficsigns\/signnames.csv\")\nprint(signnames.head())\nnumber_of_classes = len(signnames[\"ClassId\"])\nprint(\"number of classes = \", number_of_classes)","252613cf":"from keras.applications import VGG16\nconv_base = VGG16(input_shape = (32,32,3), include_top = False, weights = \"imagenet\")","2e4d081c":"conv_base.summary()","db8ae756":"train_features = conv_base.predict(train_data)\ntest_features = conv_base.predict(test_data)\nvalid_features = conv_base.predict(valid_data)","08449c50":"train_features.shape","0908d368":"dense_model = models.Sequential()\ndense_model.add(layers.Flatten(input_shape = (1, 1, 512)))\ndense_model.add(layers.Dense(units = 80, activation = \"relu\"))\ndense_model.add(layers.Dense(units = number_of_classes, activation = \"softmax\"))\n\ninitial_weights = dense_model.get_weights() # save the initial weights for the later use\ndense_model.summary()","b6bc49a1":"dense_model.set_weights(initial_weights) # restore the initial weights in order to start the training from the beginning on every run of the cell\noptimizer_use = optimizers.RMSprop()\ndense_model.compile(optimizer = optimizer_use, loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\nhistory = dense_model.fit(train_features, train_labels, epochs = 20, batch_size = 32, validation_data = (valid_features, valid_labels))","ddd1bde1":"acc_values = history.history['categorical_accuracy']\nval_acc_values = history.history['val_categorical_accuracy']\nepochs = range(1, len(acc_values) + 1)\nplt.plot(epochs, acc_values, 'b', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'r', label = 'Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","299b3a00":"intermediate_model_2 = models.Model(inputs = conv_base.input, outputs = conv_base.get_layer(\"block2_pool\").output)\nintermediate_model_2.summary()","48bf325b":"Get predictions of the new convolutional base.","fe7bc0e2":"train_features_intermediate_2 = intermediate_model_2.predict(train_data)\ntest_features_intermediate_2 = intermediate_model_2.predict(test_data)\nvalid_features_intermediate_2 = intermediate_model_2.predict(valid_data)","b0e3d202":"conv_dense_model = models.Sequential()\nconv_dense_model.add(layers.Conv2D(filters = 128, input_shape = (8,8,128), activation = \"relu\", kernel_size = (3,3)))\nconv_dense_model.add(layers.MaxPooling2D(pool_size = (2,2)))\nconv_dense_model.add(layers.Conv2D(filters = 256, activation = \"relu\", kernel_size = (3,3)))\nconv_dense_model.add(layers.Flatten(input_shape = (1, 1, 256)))\nconv_dense_model.add(layers.Dense(units = 80, activation = \"relu\"))\nconv_dense_model.add(layers.Dense(units = number_of_classes, activation = \"softmax\"))\n\ninitial_weights_conv_dense = conv_dense_model.get_weights()\nconv_dense_model.summary()","d5d7afea":"conv_dense_model.set_weights(initial_weights_conv_dense)\noptimizer_use = optimizers.RMSprop()\nconv_dense_model.compile(optimizer = optimizer_use, loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\nhistory = conv_dense_model.fit(train_features_intermediate_2, train_labels, epochs = 10, batch_size = 32, validation_data = (valid_features_intermediate_2, valid_labels))","51ffbf3b":"acc_values_2 = history.history['categorical_accuracy']\nval_acc_values_2 = history.history['val_categorical_accuracy']\nepochs = range(1, len(acc_values_2) + 1)\nplt.plot(epochs, acc_values_2, 'b', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values_2, 'r', label = 'Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","cde517fc":"conv_dense_reg_model = models.Sequential()\nconv_dense_reg_model.add(layers.BatchNormalization(input_shape = (8,8,128)))\nconv_dense_reg_model.add(layers.Conv2D(filters = 128, activation = \"relu\", kernel_size = (3,3)))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.MaxPooling2D(pool_size = (2,2)))\nconv_dense_reg_model.add(layers.Conv2D(filters = 256, activation = \"relu\", kernel_size = (3,3)))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.Flatten(input_shape = (1, 1, 256)))\nconv_dense_reg_model.add(layers.Dense(units = 80, activation = \"relu\"))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.Dense(units = number_of_classes, activation = \"softmax\"))\n\ninitial_weights_conv_dense_reg = conv_dense_reg_model.get_weights()\nconv_dense_reg_model.summary()","d5cc9a91":"conv_dense_reg_model.set_weights(initial_weights_conv_dense_reg)\noptimizer_use = optimizers.RMSprop(momentum = 0.0)\nconv_dense_reg_model.compile(optimizer = optimizer_use, loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\nhistory = conv_dense_reg_model.fit(train_features_intermediate_2, train_labels, epochs = 10, batch_size = 32, validation_data = (valid_features_intermediate_2, valid_labels))","49ae34bc":"acc_values_2_reg = history.history['categorical_accuracy']\nval_acc_values_2_reg = history.history['val_categorical_accuracy']\nepochs = range(1, len(acc_values_2_reg) + 1)\nplt.plot(epochs, acc_values_2_reg, 'b', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values_2_reg, 'r', label = 'Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","623decab":"conv_dense_reg_model = models.Sequential()\nconv_dense_reg_model.add(layers.BatchNormalization(input_shape = (8,8,128)))\nconv_dense_reg_model.add(layers.Conv2D(filters = 128, activation = \"relu\", kernel_size = (3,3)))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.MaxPooling2D(pool_size = (2,2)))\nconv_dense_reg_model.add(layers.Dropout(0.5))\nconv_dense_reg_model.add(layers.Conv2D(filters = 256, activation = \"relu\", kernel_size = (3,3)))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.Flatten(input_shape = (1, 1, 256)))\nconv_dense_reg_model.add(layers.Dropout(0.5))\nconv_dense_reg_model.add(layers.Dense(units = 80, activation = \"relu\"))\nconv_dense_reg_model.add(layers.BatchNormalization())\nconv_dense_reg_model.add(layers.Dropout(0.5))\nconv_dense_reg_model.add(layers.Dense(units = number_of_classes, activation = \"softmax\"))\n\ninitial_weights_conv_dense_reg = conv_dense_reg_model.get_weights()\nconv_dense_reg_model.summary()","413bb051":"conv_dense_reg_model.set_weights(initial_weights_conv_dense_reg)\noptimizer_use = optimizers.RMSprop(momentum = 0.0)\nconv_dense_reg_model.compile(optimizer = optimizer_use, loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\ncallbacks_list = [EarlyStopping(monitor = 'val_categorical_accuracy', patience = 4, restore_best_weights = True)]\nhistory = conv_dense_reg_model.fit(train_features_intermediate_2, train_labels, epochs = 10, batch_size = 32, validation_data = (valid_features_intermediate_2, valid_labels), callbacks = callbacks_list)","833ecb02":"acc_values_2_reg = history.history['categorical_accuracy']\nval_acc_values_2_reg = history.history['val_categorical_accuracy']\nepochs = range(1, len(acc_values_2_reg) + 1)\nplt.plot(epochs, acc_values_2_reg, 'b', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values_2_reg, 'r', label = 'Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","fbcd9f94":"evals = conv_dense_reg_model.evaluate(test_features_intermediate_2, test_labels)","40c917ac":"Get some information about data.","a3e1c616":"Read information about classes of the road signs.","33cb280e":"Download the pre-trained model and weights.","7e84ecc7":"Get the output of the convolutional base","e19ea764":"That looks better: 98.2% of the both validation and training accuracies. Finally we make an evaluation on the test set.","cb20f797":"Build a classifier with the some convolutional layers before the dense ones.","39adca53":"That looks better: we still have overfitting, but the validation accuracy is 94.7% instead of 48%; the training accuracy is 99% \n\nIt is time to apply some regularization methods. First of all add the batch normalization.","9c184fb2":"Features represent the pictures of a size 32 x 32 with 3 channels.\n\nNow prepare data for the training.","22b1737e":"Build a dense classifier: we will use the output of the convolutional base as an input for the dense classifier.\n","f6da9472":"Show one of the pictures. Just to see how it looks like.","596518d3":"Train the model: use the train_features_intermediate_2 on input. ","8a81a2f7":"Get a convolutional model: conv_base without some latest layers.","4e1e62e5":"We can see that the network is overfitted: the validation accuracy is much lower than the training one; however, even the training accuracy is not large enough. That means that it doesn't make sense to apply the regularization technics.\n\nThe reason is probably that the pre-trained model was adapted to the specific images of the imagenet dataset which significantly differ from our task. The first layers of the convolutional base detect the general-purpose patterns which are useful for the large variety of the tasks, whereas the last layers learn the task-specific patterns. So the obvious idea to try: to get an output of the first layers of the convolutional base and use it as an input for the classifier. But the classifier will have some number of the convolutional layers before the dense ones in this case. ","b2c77434":"Here we want to apply the pre-trained VGG16 network for the road data signs classification and play a little bit with the parameters.","842966ae":"Read data.","2a3b7ca5":"Train the classifier.","4ed17688":"We have an improvement: 97% of the validation accuracy was achieved, but still the overfitting is obvious with 99.9% of the training accuracy. Add some dropout layers."}}