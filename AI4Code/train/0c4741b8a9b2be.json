{"cell_type":{"5fd99ae8":"code","64149847":"code","70a2d26f":"code","9a01b8d5":"code","5d413540":"code","81f5fe86":"code","13ce9b86":"code","b460eb0e":"code","ae535b2c":"code","4d6acddf":"code","6e63ed7d":"code","86d5e68f":"code","81d10880":"markdown","b162de30":"markdown","9b688236":"markdown","02b63f69":"markdown","71089516":"markdown"},"source":{"5fd99ae8":"import numpy as np\nimport pandas as pd \nfrom keras.layers import Input, Dense, BatchNormalization, Add, GaussianNoise, Dropout, Activation\nfrom keras.models import Model, Sequential\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.layers import Wrapper\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfile_train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nfile_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","64149847":"#auxiliares\nprecisiones_globales=[]\nepochs = 50\ndef precision(model, registrar=False):\n    y_pred = model.predict(train_dfX)\n    train_auc = roc_auc_score(train_dfY, y_pred)\n    y_pred = model.predict(val_dfX)\n    val_auc = roc_auc_score(val_dfY, y_pred)\n    print('Train AUC: ', train_auc)\n    print('Vali AUC: ', val_auc)\n    if registrar:\n        precisiones_globales.append([train_auc,val_auc])","70a2d26f":"train_df_raw = file_train\ntrain_df_raw.head()\n#vemos que ticket, fare, cabin no son importantes\n#vemos que sex es male o female, hay que convertirlo a 1 y 0\n#eso en realidad me parece algo complicado, preferiria lo siguiente, vamos a droppear name, fare, ticket, cabin, embarked y no se si age porque salven a los carajitos\n#SibSp es si tiene familia, o sea sibling spouse y parch es parent children","9a01b8d5":"test_df_raw = file_test\ntest_df_raw.head()\n#aqui vemos que esta el id de pasajero, name, ticket, fare, cabin y embarked de nuevo, podemos droppearlos tambien supongo","5d413540":"#entonces vamos a hacer esos cambios\n#mantenemos los viejos no modificados\ntrain = file_train\ntest = file_test\n#ojo, run all y one hot encoding para female y male\nfile_train = file_train.replace([\"male\", \"female\"], [0,1]) \nfile_train = file_train.drop(['Name','Ticket','Fare','Cabin','Embarked'],axis=1)\nfile_train = file_train.fillna(0)\ntrain_df_raw = file_train\ntrain_df_raw.head()","81f5fe86":"file_test = file_test.replace([\"male\", \"female\"], [0,1])\nfile_test = file_test.drop(['Name','Ticket','Fare','Cabin','Embarked'], axis=1)\nfile_test = file_test.fillna(0)\ntest_df_raw = file_test\ntest_df_raw.head()\n#y ya con estos cambios creo que podemos empezar a hacer el modelo","13ce9b86":"#variables X y Y con las que se van a entrenar al modelo\ntrain_dfY = file_train[\"Survived\"]\ntrain_dfX = file_train[[\"PassengerId\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\"]]\ntest_df = file_test[[\"PassengerId\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\"]]\nsubmission = test_df[['PassengerId']].copy()\n#normalizando valores\nsc = StandardScaler()\ntrain_dfX = sc.fit_transform(train_dfX)\ntest_df = sc.transform(test_df)","b460eb0e":"#separando entrenamiento de validacion\ntrain_dfX, val_dfX,train_dfY, val_dfY = train_test_split(train_dfX,train_dfY , test_size=0.1, stratify=train_dfY)\nprint(\"Entrenamiento: \",train_dfX.shape)\nprint(\"Validacion : \",val_dfX.shape)","ae535b2c":"#creamos el modelo\n#el modelo posee 6 capas desde el input layer hasta el output final, el input layer posee 150 nodos, la capa 1 100, la 2 tiene 50, la 3 tiene 10 la 4 tiene 2 y el output tiene 1.\nmodel = Sequential()\n#input\nmodel.add(Dense(150, input_shape = (6,))) #6 por entramiento y validacion\nmodel.add(Activation(\"relu\"))\n#el input layer y el hidden layer 1 utilizan relu como funcion de activacion y las demas utilizan entre relu y sigmoide, a medida que baja la cantidad, se usa sigmoide.\n#escondidas\nmodel.add(Dense(100, input_shape = (150,)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dense(50, input_shape = (100,)))\nmodel.add(Activation(\"sigmoid\"))\nmodel.add(Dense(10, input_shape = (50,)))\nmodel.add(Activation(\"sigmoid\"))\nmodel.add(Dense(2, input_shape = (10,)))\nmodel.add(Activation(\"sigmoid\"))\n#nos fuimos guiando con otros modelos y resultados previos para ayudar a determinar un numero de capas y nodos que fuese optimo\n#output\nmodel.add(Dense(1, input_shape = (2,)))\nmodel.add(Activation(\"sigmoid\"))\n#ademas los resultados obtenidos nos parecieron suficientemente buenos como para no tener que regularizar.\n#compile para clasificacion\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","4d6acddf":"#entrenamiento del modelo\n train_history = model.fit(train_dfX, train_dfY, batch_size=50, epochs=epochs, validation_data=(val_dfX, val_dfY))\n#estos son los valores que mejor resultado dieron","6e63ed7d":"precision(model,True)\n#You might need a way of handling missing values, such as pandas.DataFrame.fillna or sklearn.preprocessing.Imputer. See our Missing Values tutorial for more details.\n#creo que por eso daba loss: nan","86d5e68f":"y_test = np.round(model.predict(test_df))\ny_test = y_test.astype(np.int32)\nsubmission['Survived'] = y_test\nsubmission = pd.DataFrame(submission)\nsubmission.to_csv('submission.csv', index=False)","81d10880":"Entrenamiento del modelo","b162de30":"Preprocesamiento de datos","9b688236":"Resultado de modelo","02b63f69":"Juan Montenegro\n\nIvan Loscher","71089516":"Arquitectura del modelo"}}