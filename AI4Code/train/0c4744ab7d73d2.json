{"cell_type":{"a538fa38":"code","34e78167":"code","266184b2":"code","c294e6ff":"code","43556d66":"code","ffff4a47":"code","9891833a":"code","e91f8248":"code","d6445af0":"code","316de87c":"code","3b7d357a":"code","107c9d84":"code","5082dc5b":"code","caad27a7":"code","98f3eb3e":"code","b827df2a":"code","fe9e2c4c":"code","162dc253":"code","b1830047":"code","f6805d97":"code","b52e428d":"code","81725d67":"code","34c96558":"code","c2467a2b":"code","b33f75ff":"code","d2c41d1c":"code","73f51528":"code","91779eec":"code","3ee0bf0d":"code","f81a4864":"code","da849f0f":"code","8ca4df6c":"code","5a1e7fc5":"code","540bcfdb":"code","4649ca29":"code","ab2f02fc":"code","3cf5d4b6":"code","fbac9071":"code","0debef8d":"code","682865ff":"code","d2862105":"code","34337cd0":"code","802ee666":"code","83958227":"code","861a704d":"code","bf6ba820":"code","1aaec6e8":"code","13968075":"code","db7170e8":"code","e0e90940":"code","2f294f5c":"code","d9fe02b8":"code","5add0d70":"code","d7d24966":"code","943c1f2b":"code","f07ab570":"markdown","3f122ed3":"markdown","9754f675":"markdown","da3ae93f":"markdown","ce62f08b":"markdown","965d44fb":"markdown","2d3bff4c":"markdown","4be3569e":"markdown","9aaab368":"markdown","15db67e8":"markdown","cfb1f2e5":"markdown","e7ad64ae":"markdown","5de26482":"markdown","f681fd2e":"markdown","a8b22893":"markdown","58c37d72":"markdown","6d9db293":"markdown"},"source":{"a538fa38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport librosa\nimport IPython.display as ipd\nimport librosa.display\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34e78167":"\ncount = 0\nX_train, y_train = [], []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/freespokendigitsdataset\/recordings'):\n    for filename in filenames:\n        full_path = os.path.join(dirname, filename)\n        print(full_path)\n        label = filename.split('_')[0]\n        X_train.append(full_path)\n        y_train.append(label)\n        count = count +1\n        if(count == 5):\n            break\n            \n\n\n","266184b2":"print('first file ', X_train[0])\nprint(y_train)\n\n    \n\n","c294e6ff":"print(y_train[4])\nipd.Audio(X_train[4])","43556d66":"X, sr = librosa.load(X_train[4])\nX.shape","ffff4a47":"fig, ax = plt.subplots()\nlibrosa.display.waveplot(X, sr=sr, ax= ax)","9891833a":"print(y_train[2])\nipd.Audio(X_train[2])\n","e91f8248":"X, sr = librosa.load(X_train[2])\nfig, ax = plt.subplots()\nlibrosa.display.waveplot(X, sr=sr, ax= ax)","d6445af0":"def plot_melSpec(X):\n    y, sr = librosa.load(X)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n    fig, ax = plt.subplots()\n    plt.figure(figsize=(20,8))\n    S_dB = librosa.power_to_db(S, ref=np.max) \n    img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, ax=ax)\n    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n    ax.set(title='Mel-frequency spectrogram')\n\n","316de87c":"print(y_train[3])\nipd.Audio(X_train[3])\n\n","3b7d357a":"plot_melSpec(X_train[3])","107c9d84":"def getMFCC(X):\n    y, sr = librosa.load(X, duration=5.0)\n    print('duration  of audio is ', len(y)*(1\/sr))\n    S = librosa.feature.melspectrogram(y=y, sr=8000, n_fft=2048, hop_length=512, n_mels=128)\n    print(S.shape)\n    return librosa.feature.mfcc(S=librosa.power_to_db(S))","5082dc5b":"mfcc_coef1 = getMFCC(X_train[2])\nmfcc_coef1.shape\n\n","caad27a7":"mfcc_coef2 = getMFCC(X_train[4])\nmfcc_coef2.shape","98f3eb3e":"#check minimum duration of audio present in data\ndef checkShortestAudio(DirPath='\/kaggle\/input\/freespokendigitsdataset\/recordings'):\n    shortest= 1000\n    shortestFile = ''\n    for dirname, _, filenames in os.walk(DirPath):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            y, sr = librosa.load(full_path)\n            duration = len(y)*(1\/sr)\n            if(duration<shortest):\n                shortest = duration\n                shortestFile = filename\n    return shortest,shortestFile\n    \n\n            ","b827df2a":"s,sf = checkShortestAudio()\ns,sf","fe9e2c4c":"ipd.Audio('\/kaggle\/input\/freespokendigitsdataset\/recordings\/6_yweweler_3.wav')","162dc253":"#check minimum duration of audio present in data\ndef checkLongestAudio(DirPath='\/kaggle\/input\/freespokendigitsdataset\/recordings'):\n    longest= 0\n    longestFile = ''\n    for dirname, _, filenames in os.walk(DirPath):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            y, sr = librosa.load(full_path)\n            duration = len(y)*(1\/sr)\n            if(duration>longest):\n                longest = duration\n                longestFile = filename\n    return longest,longestFile","b1830047":"l,lf = checkLongestAudio()\nl,lf","f6805d97":"ipd.Audio('\/kaggle\/input\/freespokendigitsdataset\/recordings\/9_theo_16.wav')","b52e428d":"def getFullData(DirPath='\/kaggle\/input\/freespokendigitsdataset\/recordings',sr=8000):\n    Xfull = []\n    y = []\n    count =0;\n    for dirname, _, filenames in os.walk(DirPath):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            label = int(filename.split('_')[0])\n            X, _ = librosa.load(full_path,sr=sr)\n            Xfull.append(X)\n            y.append(label)\n            count = count +1\n    return Xfull,y\n    ","81725d67":"X,y = getFullData()","34c96558":"print('length of x: ', len(X), ' and length of y: ',len(y),' and number of samples in first data of X :', len(X[0]), ' first data y ', y[0])","c2467a2b":"def plot_Audio_duration_bar(signals,rate=8000):\n    sample_duration = [len(x)\/rate for x in signals]\n    plt.figure(figsize=(12,8))\n    plt.hist(sample_duration)\n    ","b33f75ff":"plot_Audio_duration_bar(X)","d2c41d1c":"def getUniformedLengthData(DirPath='\/kaggle\/input\/freespokendigitsdataset\/recordings',sr=8000,duration=1.0):\n    N = int(sr*duration)\n    X_data = np.ndarray(shape=(3000,N), dtype=float)\n    y = np.ndarray(shape=(3000,1), dtype=int)\n    count =0;\n    for dirname, _, filenames in os.walk(DirPath):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            label = int(filename.split('_')[0])\n            X, _ = librosa.load(full_path,sr=sr,duration = 1.0)\n            if(len(X) < N):\n                        X = np.pad(X, (0, N - len(X)), constant_values = (0, 0))\n            X_data[count] = X\n            y[count] = label\n            count = count+1\n    return X_data,y\n                        ","73f51528":"X_data_u, y_u = getUniformedLengthData()\nX_data_u.shape, y_u.shape","91779eec":"X_df = pd.DataFrame(X_data_u)\ny_df = pd.DataFrame(y_u)","3ee0bf0d":"def splitData(X,y,index):\n    X1,X2 = X[:index],X[index:]\n    y1,y2 = y[:index],y[index:]\n    return (X1,y1),(X2,y2)","f81a4864":"(X_train_full, y_train_full), (X_test, y_test) = splitData(X_df,y_df,2000)","da849f0f":"X_train_full.shape,y_train_full.shape,X_test.shape,y_test.shape","8ca4df6c":"X_valid, X_train = X_train_full[1500:], X_train_full[:1500]\ny_valid, y_train = y_train_full[1500:], y_train_full[:1500]","5a1e7fc5":"X_valid.shape,X_train.shape,y_valid.shape,y_train.shape, np.unique(y_df)","540bcfdb":"import tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.models.Sequential([\n    #keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n    keras.layers.LeakyReLU(),\n    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n    keras.layers.LeakyReLU(),\n    keras.layers.Dense(10, activation=\"softmax\")\n])","4649ca29":"model.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=keras.optimizers.SGD(lr=1e-1),\n              metrics=[\"accuracy\"])","ab2f02fc":"history = model.fit(X_train, y_train, epochs=20,\n                    validation_data=(X_valid, y_valid))","3cf5d4b6":"def getMFCC(y):\n    S = librosa.feature.melspectrogram(y=y, sr=8000, n_fft=2048, hop_length=512, n_mels=128)\n    return librosa.feature.mfcc(S=librosa.power_to_db(S))","fbac9071":"X_train_np= X_train.to_numpy()\nX_train_np.shape,X_train_np[0].shape","0debef8d":"# X_train_np[0] contains 8000 samples of audio, lets convert it into mfcc and see data size\nmfcc= getMFCC(X_train_np[0])\nmfcc.shape","682865ff":"def convertToMFCCData(X):\n    mfccData = np.ndarray(shape=(len(X),20,16), dtype=float)\n    count = 0\n    for i in range(0,len(X)):\n        y = X[i]\n        mfcc = getMFCC(y)\n        mfccData[count] = mfcc\n        count = count +1\n    return mfccData\n    \n\n    ","d2862105":"X_train_mfccs = convertToMFCCData(X_train_np)\nX_train_mfccs.shape","34337cd0":"X_valid_np = X_valid.to_numpy()\nX_valid_mfccs = convertToMFCCData(X_valid_np)\nX_valid_mfccs.shape","802ee666":"modelMFCC = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[20, 16]),\n    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n    keras.layers.LeakyReLU(),\n     keras.layers.Dense(200, kernel_initializer=\"he_normal\"),\n    keras.layers.LeakyReLU(),\n    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n    keras.layers.LeakyReLU(),\n    keras.layers.Dense(10, activation=\"softmax\")\n])","83958227":"modelMFCC.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=keras.optimizers.SGD(lr=1e-4),\n              metrics=[\"accuracy\"])","861a704d":"history = modelMFCC.fit(X_train_mfccs, y_train, epochs=100,\n                    validation_data=(X_valid_mfccs, y_valid))","bf6ba820":"sample_testing = X_valid_mfccs[200:202]\nnp.argmax(modelMFCC.predict(sample_testing), axis=-1)\n","1aaec6e8":"y_testing = y_valid.to_numpy()\nys = y_testing[200:202]\nys\n","13968075":"X_test_np = X_test.to_numpy()\nX_test_mfcc = convertToMFCCData(X_test_np)","db7170e8":"modelMFCC.evaluate(X_test_mfcc, y_test)","e0e90940":"XSample, _ = librosa.load('\/kaggle\/input\/freespokendigitsdataset\/recordings\/9_theo_16.wav',sr=8000, duration=1.0)\nXSample= np.expand_dims(XSample, axis=0)\nXSample.shape\nXSampleMFCC = convertToMFCCData(XSample)\nXSampleMFCC.shape","2f294f5c":"np.argmax(modelMFCC.predict(XSampleMFCC), axis=-1)","d9fe02b8":"ipd.Audio('\/kaggle\/input\/freespokendigitsdataset\/recordings\/4_lucas_16.wav')","5add0d70":"XSample, _ = librosa.load('\/kaggle\/input\/freespokendigitsdataset\/recordings\/4_lucas_16.wav',sr=8000, duration=1.0)\n\nXSample.shape","d7d24966":"XSample = np.pad(XSample, (0, 8000 - len(XSample)), constant_values = (0, 0))\nXSample= np.expand_dims(XSample, axis=0)\nXSampleMFCC = convertToMFCCData(XSample)","943c1f2b":"np.argmax(modelMFCC.predict(XSampleMFCC), axis=-1)","f07ab570":"As above, after converting to MFCC will get 2-D data of (20,16) from array of 8000 values of samples","3f122ed3":"Lets create a new model to be trained for MFCC data","9754f675":"As seen above, most audios are around .25 to .6-7, very less after .75 and some outlieres are after 2 seconds","da3ae93f":"We reached training accuracy 99.23% and validation accuracy 90% in 100 epochs. Lets try to predict a value","ce62f08b":"Above we have 3000 audio files data with 8000 samples each","965d44fb":"Above MFCC coeficients are different for 2 different audio files as they have different duration of audio","2d3bff4c":"lets test it for a audio file","4be3569e":"#  check minimum duration of audio present in data","9aaab368":"Prepare MFCC data to feed in dense network","15db67e8":"As seen above, shortest audio is for .14 seconds","cfb1f2e5":"Get samples from audio for 1.0 seconds so that number of samples are same for audio duration >=1 and as for audio less than 1 seconds, pads the generated samples to make them of same size as others","e7ad64ae":"# get MFCC coeficients","5de26482":"Get full data to analyze duration of audios in full dataset","f681fd2e":"As above, we got 90% accuracy on test audio set","a8b22893":"# Analyzing first five files","58c37d72":"Lets run a dense network on samples of audio on amplitude based","6d9db293":"As above, longest audio is of 2.28 seconds in which 9 is uttered"}}