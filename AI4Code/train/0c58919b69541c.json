{"cell_type":{"d743132a":"code","e2375978":"code","26a80722":"code","cca49737":"code","5fe505e3":"code","d785e689":"code","2e265f75":"code","64a02195":"code","de4651d7":"code","387cca90":"code","df3c2822":"code","4e405e13":"code","7ee36c9f":"code","9ab9cefd":"code","e3ca1e13":"code","8c388082":"code","dfde5b37":"code","9c6122f9":"code","e5dd592b":"code","568639cb":"code","76809689":"markdown","c9b2d0c3":"markdown","e2927f1c":"markdown","5360f3ae":"markdown","e32560f0":"markdown","bf76010c":"markdown","3bf12408":"markdown","036c3aed":"markdown","7d4abcfe":"markdown","f9799508":"markdown","ebd3ab73":"markdown","27344cbf":"markdown"},"source":{"d743132a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.options.display.width = None\npd.set_option(\"max_colwidth\", None)\npd.options.display.max_rows = 999\nimport cv2\nimport pickle\nimport gzip\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, metrics, datasets\nfrom sklearn.utils import Bunch\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.svm import SVC\nfrom skimage.io import imread\nfrom skimage.transform import resize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport skimage\nimport os","e2375978":"from sklearn.utils import Bunch\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\nimport pickle\nfrom sklearn import metrics","26a80722":"flat_data = '..\/input\/golfdb-entire-image\/flat_dat.npy'\ntarget = '..\/input\/golfdb-entire-image\/target.npy'\ntarget_names = '..\/input\/golfdb-entire-image\/target_names.npy'\nimages = '..\/input\/golfdb-entire-image\/images.npy'\nDESCR = '..\/input\/golfdb-entire-image\/descr.npy'","cca49737":"swing_image_dataset = Bunch()\nswing_image_dataset['data'] = np.load(flat_data)\nswing_image_dataset['target'] = np.load(target)\nswing_image_dataset['target_names'] = np.load(target_names)\nswing_image_dataset['images'] = np.load(images)\nswing_image_dataset['DESCR'] = np.load(DESCR)","5fe505e3":"swing_image_dataset.data.shape","d785e689":"X = MinMaxScaler().fit_transform(swing_image_dataset.data)\ny = swing_image_dataset.target","2e265f75":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nn_comp = 1000\npca = PCA().fit(X)\n\nprint(pca.explained_variance_ratio_)\nplt.figure(figsize=(15,10))\nplt.ylim(0.0,1.1)\nplt.plot(np.cumsum(pca.explained_variance_ratio_), linewidth=3)\n# plt.axhline(y=0.95, color='r', linestyle='-')\n# plt.text(500, 0.85, '95% cut-off threshold', color = 'red', fontsize=14)\nplt.xlabel('number of components', fontsize=21)\nplt.ylabel('cumulative explained variance', fontsize=21)\nplt.title('Scree Plot using PCA', fontsize=24)\n# plt.rc('xtick', labelsize=16)\nplt.rc('font', size=16)\n# plt.rc('ytick', labelsize=16)\nplt.grid()\nplt.show()","64a02195":"rseed = 42","de4651d7":"\n# '''Split data, but randomly allocate to training\/test sets'''\nX_train, X_test, y_train, y_test = train_test_split(X, swing_image_dataset.target, test_size=0.2, random_state=rseed)","387cca90":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca = PCA(n_components = 500)\nX_train = pca.fit(X_train, y_train).transform(X_train)","df3c2822":"plt.figure(figsize=(18,15))\nfor  i, target_name in zip([ 0, 1, 2, 3, 4, 5, 6, 7], swing_image_dataset.target_names):\n    plt.scatter(X_train[y_train == i, 0], X_train[y_train == i, 1], label=target_name)\nplt.legend(fontsize=23, loc ='upper right')\nplt.title('PCA of GolfDB dataset')\n\nplt.show()","4e405e13":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nX_train, X_test, y_train, y_test = train_test_split(X, swing_image_dataset.target, test_size=0.2, random_state=rseed)\nlda = LDA(n_components = 7)\nX_train = lda.fit(X_train, y_train).transform(X_train)","7ee36c9f":"plt.figure(figsize=(18,15))\nfor  i, target_name in zip([ 0, 1, 2, 3, 4, 5, 6, 7], swing_image_dataset.target_names):\n    plt.scatter(X_train[y_train == i, 0], X_train[y_train == i, 1], label=target_name)\nplt.legend(fontsize=23, loc ='upper right')\nplt.title('LDA of GolfDB dataset')\n\nplt.show()","9ab9cefd":"from sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import cross_val_score\ndef feature_gridsearch(model):\n    rseed = 42\n    print(model)\n    feature_extractors = ['PCA', 'LDA', 'None']\n    lda_n_comp = [4, 5, 6, 7]\n    pca_n_comp =  [50, 100, 125, 150, 200, 500]\n    lda = LDA()\n    pca = PCA()\n    output_model = []\n    \n    for feature_extractor in feature_extractors: \n        if feature_extractor == \"PCA\":\n            print('PCA')\n            output_pca = []\n            for n_comp in pca_n_comp:\n                print(n_comp)\n                y = swing_image_dataset.target\n                X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n                pca = PCA(n_components = n_comp)\n                X = pca.fit(X, y).transform(X)\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n                accuracy_pca = cross_val_score(model, X_train, y_train, scoring='accuracy', cv =4, n_jobs=-1)\n                print(accuracy_pca)\n                print(accuracy_pca.mean()*100)\n                print(accuracy_pca.std()*100)\n                output_pca.append(accuracy_pca)\n            output_model.append(output_pca)\n            print(output_pca)\n        elif feature_extractor == \"LDA\":\n            print(\"LDA\")\n            output_lda = []\n            for n_comp in lda_n_comp: \n                print(n_comp)\n                y = swing_image_dataset.target\n                X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n                lda = LDA(n_components = n_comp)\n                X = lda.fit(X, y).transform(X)\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n                accuracy_lda = cross_val_score(model, X_train, y_train, scoring='accuracy', cv =4, n_jobs=-1)\n                print(accuracy_lda)\n                print(accuracy_lda.mean()*100)\n                print(accuracy_lda.std()*100)\n                output_lda.append(accuracy_lda)\n            output_model.append(output_pca)\n        else: #None\n            print('None')\n            y = swing_image_dataset.target\n            X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n            accuracy_none = cross_val_score(model, X_train, y_train, scoring='accuracy', cv =4, n_jobs=-1)\n            print(accuracy_none)\n            print(accuracy_none.mean()*100)\n            print(accuracy_none.std()*100)\n            output_model.append(accuracy_none)\n    return output_model","e3ca1e13":"from sklearn.svm import LinearSVC\nlinearsvm = LinearSVC(random_state=rseed, C=10, multi_class='crammer_singer')\npca_lda_tuning = feature_gridsearch(linearsvm)\nprint(pca_lda_tuning)","8c388082":"from sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostClassifier\nfrom catboost import Pool, cv\ndef feature_gridsearch_catboost():\n    rseed = 42\n    feature_extractors = ['PCA', 'LDA', 'None']\n    lda_n_comp = [4, 5, 6, 7]\n    pca_n_comp =  [50, 100, 125, 150, 200, 500]\n    lda = LDA()\n    pca = PCA()\n    for feature_extractor in feature_extractors: \n        if feature_extractor == \"PCA\":\n            print('PCA')\n            for n_comp in pca_n_comp:\n                print(n_comp)\n                y = swing_image_dataset.target\n                X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n                pca = PCA(n_components = n_comp)\n                X = pca.fit(X, y).transform(X)\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n                cv_dataset = Pool(data=X_train, label=y_train) #built in method for catboost cross-validation\n                params = {'random_state':42,\n                                'depth':4, \n                                'bagging_temperature' :1.5, \n                                'l2_leaf_reg':7,  \n                                'learning_rate':0.03, \n                                 'eval_metric':'Accuracy', \n                                 'task_type':\"GPU\",\n                                'use_best_model': True,\n                              'loss_function': 'MultiClass'\n                }\n\n                scores = cv(cv_dataset,params, fold_count=4)\n                print(scores)\n                cat_df = pd.DataFrame(scores)\n                file_name = \"catboost_PCA_\" + str(n_comp) +\".csv\"\n                cat_df.to_csv(file_name)\n        elif feature_extractor == \"LDA\":\n            print(\"LDA\")\n            for n_comp in lda_n_comp: \n                print(n_comp)\n                y = swing_image_dataset.target\n                X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n                lda = LDA(n_components = n_comp)\n                X = lda.fit(X, y).transform(X)\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n                cv_dataset = Pool(data=X_train, label=y_train)\n                params = {'random_state':42,\n                                'depth':4, \n                                'bagging_temperature' :1.5, \n                                'l2_leaf_reg':7,  \n                                'learning_rate':0.03, \n                                 'eval_metric':'Accuracy', \n                                 'task_type':\"GPU\",\n                                'use_best_model': True,\n                              'loss_function': 'MultiClass'\n                }\n\n                scores = cv(cv_dataset,params, fold_count=4)\n                print(scores)\n                cat_df = pd.DataFrame(scores)\n                file_name = \"catboost_LDA_\" + str(n_comp) +\".csv\"\n                cat_df.to_csv(file_name)\n        else: #None\n            print('None')\n            y = swing_image_dataset.target\n            X = MinMaxScaler().fit_transform(swing_image_dataset.data)\n            lda = LDA(n_components = n_comp)\n            X = lda.fit(X, y).transform(X)\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n            cv_dataset = Pool(data=X_train, label=y_train)\n            params = {'random_state':42,\n                            'depth':4, \n                            'bagging_temperature' :1.5, \n                            'l2_leaf_reg':7,  \n                            'learning_rate':0.03, \n                             'eval_metric':'Accuracy', \n                             'task_type':\"GPU\",\n                            'use_best_model': True,\n                          'loss_function': 'MultiClass'\n            }\n\n            scores = cv(cv_dataset,params, fold_count=4)\n            print(scores)\n            cat_df = pd.DataFrame(scores)\n            file_name = \"catboost_None.csv\"\n            cat_df.to_csv(file_name)","dfde5b37":"feature_gridsearch_catboost()","9c6122f9":"from sklearn import tree\nclf_dt = tree.DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=3, random_state=rseed)\noutput_dt = feature_gridsearch(clf_dt)\nprint(output_dt)","e5dd592b":"from sklearn.ensemble import RandomForestClassifier \nclf_rf = RandomForestClassifier(min_samples_leaf=3, min_samples_split=3, random_state=rseed)\noutput_rf = feature_gridsearch(clf_rf)\nprint(output_rf)","568639cb":"from sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=7, p=2)\noutput_knn = feature_gridsearch(clf_knn)\nprint(output_knn)","76809689":"Best split up doing the PCA and LDA stages separately in kaggle as seesion time limit is 9hrs. ","c9b2d0c3":"#### This script implements hyperparameter tuning for both PCA and LDA dimensionality reduction. To determine the optimal number of components. ","e2927f1c":"### Random Forests","5360f3ae":"PCA Gridsearch components","e32560f0":"### CatBoost","bf76010c":"### Decision Tree Classifier","3bf12408":"### Exploratory Data Analysis","036c3aed":"#### PCA Scree Plot ","7d4abcfe":"### KNN","f9799508":"plt.xlabel('LD1')\nplt.ylabel('LD2')\nplt.scatter(X[:,0],\n           X[:,1],\n           c=swing_image_dataset.target,\n           cmap='rainbow',\n           alpha=0.7,\n           edgecolors='b')\nplt.legend()","ebd3ab73":"### Load Dataset","27344cbf":"### LinearSVM"}}