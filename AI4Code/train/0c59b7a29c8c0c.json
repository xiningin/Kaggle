{"cell_type":{"1573dd88":"code","6d936c7b":"code","c2ddbdbd":"code","983e4d8a":"code","2b87c238":"code","8283fbac":"code","fa8161b1":"code","10b863f2":"markdown","a54d03ba":"markdown","7fceec09":"markdown","6735a14f":"markdown","35dc6639":"markdown","b45b1210":"markdown","4abcd0ba":"markdown","73caa62c":"markdown"},"source":{"1573dd88":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Libraries for Recommendation System\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d936c7b":"data_movie = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/movie.csv\")\ndata_rating = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/rating.csv\")","c2ddbdbd":"movie = data_movie.loc[:,{\"movieId\",\"title\"}]\nrating = data_rating.loc[:,{\"userId\",\"movieId\",\"rating\"}]","983e4d8a":"data = pd.merge(movie,rating)\ndata = data.iloc[:1000000,:]\nuser_movie_table = data.pivot_table(index = [\"title\"],columns = [\"userId\"],values = \"rating\").fillna(0)\nuser_movie_table.head(10)","2b87c238":"# We choose random movie.\nquery_index = np.random.choice(user_movie_table.shape[0])\nprint(\"Choosen Movie is: \",user_movie_table.index[query_index])","8283fbac":"user_movie_table_matrix = csr_matrix(user_movie_table.values)\nmodel_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\nmodel_knn.fit(user_movie_table_matrix)\ndistances, indices = model_knn.kneighbors(user_movie_table.iloc[query_index,:].values.reshape(1,-1), n_neighbors = 6)","fa8161b1":"movie = []\ndistance = []\n\nfor i in range(0, len(distances.flatten())):\n    if i != 0:\n        movie.append(user_movie_table.index[indices.flatten()[i]])\n        distance.append(distances.flatten()[i])    \n\nm=pd.Series(movie,name='movie')\nd=pd.Series(distance,name='distance')\nrecommend = pd.concat([m,d], axis=1)\nrecommend = recommend.sort_values('distance',ascending=False)\n\nprint('Recommendations for {0}:\\n'.format(user_movie_table.index[query_index]))\nfor i in range(0,recommend.shape[0]):\n    print('{0}: {1}, with distance of {2}'.format(i, recommend[\"movie\"].iloc[i], recommend[\"distance\"].iloc[i]))","10b863f2":"In this movie.csv file, as we will use movieid and title columns. We are creating new dataframe using this two columns. At the same time, as we will use userId,movieid and rating columns. We are creating new dataframe using this three columns from rating.csv. ","a54d03ba":"# Conclusion\n\n* Recommendation systems predict according to previous experience. \n* There are two methods for CF: User based and Item based.\n* How to find between two items by using machine learning algorith (KNN)\n* How to set up basic recommendation system.\n* How to work recommendation systems.\n\n#### If you have any question and comment I will be happy to hear it.","7fceec09":"In this below section, you can see recommendations for Up Close and Personal movie. ","6735a14f":"There are various methods in order to find similarity. In this kernel, I used to KNN algorithm in order to find similarity. \n\n## What is the K-Nearest Neighbor Algorithm?\n\nKNN is used for both classification and regression problems. In classification problems to predict the label of a instance we first find k closest instances to the given one based on the distance metric and based on the majority voting scheme or weighted majority voting(neighbors which are closer are weighted higher) we predict the labels.\n\nK-nearest neighbor finds the k most similar items to a particular instance based on a given distance metric like euclidean, jaccard similarity , minkowsky or custom distance measures. In this my model, I used to cosine as metric. ","35dc6639":"# Recommendation System with Collaborative Filtering using Nearest Neighbors\n\nHi everybody ! In this kernel, I'm going to set up movie recommendation system. In this system, I'm going to use nearest neighbors algorithm and collaborative filtering. As dataset, I used to MovieLens 20M Dataset. If this kernel is benefit for you. Don't forget voting my kernel for my motivation. :) \n\nEnjoy with machine learning !\n\n\n<img src=\"https:\/\/miro.medium.com\/max\/15721\/0*3C6CUn1FEC_raM8c\" width=\"700\" height=\"700\">","b45b1210":"# What is the Recommendation System?\n\n* Based on previous(past) behaviours, it predicts the likelihood that a user would prefer an item.\n* For example, Netflix uses recommendation system. It suggest people new movies according to their past activities that are like watching and voting movies.\n* The purpose of recommender systems is recommending new things that are not seen before from people.\n* There are several methods in recommendation systems. In this kernel, I used to collaborative filtering method. \n\n## Collaborative Filtering\n\nCollaborative filtering is making recommend according to combination of your experience and experiences of other people. There are two collaborative filtering methods: User Based CF and Item Based CF\n\n### User Based Collaborative Filtering\n\nIt is calculated similarity people in user vs item matrix. For example, we let think that there are two people. First one watched 2 movies that are lord of the rings and hobbit. Second one watched only lord of the rings movie. it recommends hobbit movie to second one. \n\nUser based collaborative filtering has some problems. In this system, each row of matrix is user. Therefore, comparing and finding similarity between of them is computationaly hard and spend too much computational power. Also, habits of people can be changed. Therefore making correct and useful recommendation can be hard in time.\n\nIn order to solve these problems, lets look at another recommender system that is item based collaborative filtering\n\n### Item Based Collaborative Filtering\n\nIt is calculated similarity items in user vs item matrix. For example, we let think that there are two movies: Lord of the Rings and Hobbit. Three people watched lord of the rings and hobbit. If fourth person watched lord of the rings. He\/she could like Hobbit. So that the system recommends Hobbit to fourth people. \n\nIn general recommendation systems use to item based collaborative filtering. Item based CF improved to solve the problem of user based CF. As people minds and habits can change and items doesn't change. It is prefered.","4abcd0ba":"### **Let's describe dataset:**\n\nIn this dataset has 6 csv files. I used to movie.csv and rating.csv. We let analyze this csv files. \n\nrating.csv that contains ratings of movies by users:\n\n* userId\n* movieId\n* rating\n* timestamp\n\nmovie.csv that contains movie information:\n\n* movieId\n* title\n* genres","73caa62c":"We are combining two dataframe (movie and rating) and are creating movie vs user matrix."}}