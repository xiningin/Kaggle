{"cell_type":{"ccde5449":"code","14ead77a":"code","aa26a816":"code","cff7563c":"code","f3e44bd5":"code","9410dda0":"code","50665f80":"code","33fb3d23":"code","47e2c748":"code","64b88873":"code","e6c8817b":"code","541c070a":"code","785bd782":"code","e4298ce0":"code","fc0ddcce":"code","2682535c":"code","46732f46":"code","6ed60be1":"code","d714cd93":"code","5bf0f44e":"code","c2b73ee2":"code","4e03e34e":"code","07fb4258":"code","0cb39806":"code","c9209c87":"markdown","8cda31f1":"markdown","7a6cd38a":"markdown","305c9331":"markdown","03d1249b":"markdown","10730db0":"markdown","4d89fe3e":"markdown","59135b3a":"markdown","c05fe952":"markdown","bd04350d":"markdown","116d007b":"markdown","8399ffec":"markdown","b1dfe3ce":"markdown","a3e7176e":"markdown","09a256b4":"markdown","8778f46d":"markdown","fd2712e6":"markdown","3881aff5":"markdown","1b61ea8e":"markdown","6864b744":"markdown","3dd053f7":"markdown","936f5df8":"markdown","dca15129":"markdown","157447b9":"markdown","6c461e6f":"markdown","a7187594":"markdown"},"source":{"ccde5449":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14ead77a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.patches import Rectangle\nfrom matplotlib_venn import venn2, venn2_circles\n\nimport seaborn as sns\nimport re\n\nimport string\nimport spacy # Leading library for NLP\nnlp = spacy.load('en')\n\nfrom wordcloud import WordCloud\nfrom sklearn.linear_model import LinearRegression","aa26a816":"df = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', header=1)\n\ndf.head()","cff7563c":"print('shape: ', df.shape)\nprint('columns with NaN values: \\n', df.isna().sum().loc[df.isna().sum() != 0].shape[0])","f3e44bd5":"print(\"In '2020 Kaggle ML & DS Survey', {} had attended the survey.\".format(df.shape[0]))","9410dda0":"def plot_frequency_charts(df, feature, title, xlabel, pallete):\n    freq_df = pd.DataFrame()\n    freq_df[feature] = df[feature]\n    \n    f, ax = plt.subplots(1,1, figsize=(16,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette=pallete)\n\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n\n    plt.title('Frequency and percentage of {}'.format(title),weight='bold', size=15)\n    plt.ylabel('Frequency', size=12, weight='bold')\n    plt.xlabel(xlabel, size=12, weight='bold')\n    plt.xticks(rotation=90)\n    plt.show()","50665f80":"plot_frequency_charts(df, 'What is your age (# years)?', 'age group','Age Group', 'inferno')","33fb3d23":"plot_frequency_charts(df, 'What is your gender? - Selected Choice', 'gender','Gender', 'inferno')","47e2c748":"\nplot_frequency_charts(df, 'In which country do you currently reside?', 'responders currently reside in','Country', 'winter')","64b88873":"df_gender_time = df.groupby(['What is your gender? - Selected Choice']).agg({'Duration (in seconds)':'mean'}).reset_index()\n\nf, ax = plt.subplots(1,1, figsize=(15,5))\nsplot = sns.barplot(df_gender_time['What is your gender? - Selected Choice'],\n                                   df_gender_time['Duration (in seconds)'], alpha=0.8)\n\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center',\n                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\nplt.title('Average time taken to fill the form - genderwise',weight='bold', size=15)\nplt.xlabel('Gender', fontsize=12, fontweight='bold')\nplt.ylabel('Time Taken in seconds', fontsize=12, fontweight='bold')\nplt.xticks(rotation=90)\nplt.show()","e6c8817b":"\nplot_frequency_charts(df, \n'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?',\n\"responder's education\",'Education', 'brg')","541c070a":"plot_frequency_charts(df, \n'Select the title most similar to your current role (or most recent title if retired): - Selected Choice',\n\"responder's occupation\",'Occupations', 'winter')","785bd782":"plot_frequency_charts(df, 'For how many years have you been writing code and\/or programming?',\n                      \"responder's coding experience\",'Duration', 'viridis')","e4298ce0":"plot_frequency_charts(df,\n    'What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice',\n                      \"responder's recommend an aspiring data scientist to learn first\",'Programming language', 'husl')","fc0ddcce":"df['What type of computing platform do you use most often for your data science projects? - Selected Choice'] = df[\n    'What type of computing platform do you use most often for your data science projects? - Selected Choice'].replace(\n    {'A personal computer or laptop':'PC or Laptop',\n     'A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)':'Cloud platform',\n     'A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)':'Deep Learning workstation'})\n\nplot_frequency_charts(df,\n    'What type of computing platform do you use most often for your data science projects? - Selected Choice',\n                      \"type of computing platform used\",'Platform', 'brg')","2682535c":"plot_frequency_charts(df, 'Approximately how many times have you used a TPU (tensor processing unit)?',\n                      \"responder's used TPU (tensor processing unit)\",'Occations', 'twilight')","46732f46":"data = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\n\ndata.head()","6ed60be1":"dff = pd.DataFrame()\n\nrelevant_2020 = pd.DataFrame()","d714cd93":"relevant_2020['Age'] = data.Q1\nrelevant_2020['Compensation_Amout'] = data.Q24\nrelevant_2020['Country'] = data.Q3\nrelevant_2020['Occupation'] = data.Q5\n#relevant_2020['Occupation_Freeform'] = data.Q5_OTHER\nrelevant_2020['Education'] = data.Q4\nrelevant_2020['Language_Recommendation'] = data.Q8\n#relevant_2020['Language_Recommendation_Freeform'] = data.Q8_OTHER\nrelevant_2020['Programming_Experience'] = data.Q6\n\nrelevant_2020['Hosted_Notebook_Products__Kaggle_Notebooks'] = data.Q10_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Google_Colab'] = data.Q10_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Azure_Notebooks'] =data.Q10_Part_3.apply(lambda x: 0 if x != x else 1)| data.Q17_OTHER.apply(lambda x: 1 if ('databricks' in str(x).lower()) else 0)\n\nrelevant_2020['Hosted_Notebook_Products__Google_Cloud_Datalab'] = data.Q10_Part_11.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Paperspace_Gradient'] = data.Q10_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__FloydHub'] = data.Q10_OTHER.apply(lambda x: 1 if ('floyd' in str(x).lower()) else 0)\nrelevant_2020['Hosted_Notebook_Products__Binder_JupyterHub'] = data.Q10_Part_5.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__IBM_Watson_Studio'] = data.Q10_Part_7.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Code_Ocean'] = data.Q10_Part_6.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__AWS_Notebook'] =data.Q10_Part_9.apply(lambda x: 0 if x != x else 1) | data.Q10_Part_8.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Domino_Datalab'] = data.Q10_OTHER.apply(lambda x: 1 if ('domino' in str(x).lower()) else 0) \nrelevant_2020['Hosted_Notebook_Products__Crestle'] = data.Q10_OTHER.apply(lambda x: 1 if ('crestle' in str(x).lower()) else 0) \nrelevant_2020['Hosted_Notebook_Products__Cocalc'] = data.Q10_OTHER.apply(lambda x: 1 if ('cocalc' in str(x).lower()) else 0) \nrelevant_2020['Hosted_Notebook_Products__Datalore'] = data.Q10_OTHER.apply(lambda x: 1 if ('datalore' in str(x).lower()) else 0)\nrelevant_2020['Hosted_Notebook_Products__Google_Cloud_AI'] = data.Q10_Part_10.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Databricks'] = data.Q10_Part_12.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__None'] = data.Q10_Part_13.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hosted_Notebook_Products__Other'] = data.Q17_OTHER\n\nrelevant_2020['Activities__Analyze_and_understand_data'] = data.Q23_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Build_ML_service'] = data.Q23_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Build_data_infrastructure'] = data.Q23_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Build_prototypes'] = data.Q23_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Build_Experimentation'] = data.Q23_Part_5.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Research'] = data.Q23_Part_6.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__None'] = data.Q23_Part_7.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Activities__Other'] = data.Q23_OTHER\n\nrelevant_2020['Algorithms__Linear_or_Logistic_Regression'] = data.Q17_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Decision_Trees_or_Random_Forests'] =data.Q17_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Gradient_Boosting_Machines'] =data.Q17_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Bayesian_Approaches'] = data.Q17_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Evolutionary_Approaches'] =data.Q17_Part_5.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Dense_Neural_Networks'] = data.Q17_Part_6.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__CNN'] = data.Q17_Part_7.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__GAN'] = data.Q17_Part_8.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__RNN'] = data.Q17_Part_9.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Transformer_Networks'] = data.Q17_Part_10.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__None'] = data.Q17_Part_11.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithms__Other'] = data.Q17_OTHER\n\nrelevant_2020['Algorithm_Cluster_Traditional_ML'] = relevant_2020.Algorithms__Linear_or_Logistic_Regression| relevant_2020.Algorithms__Decision_Trees_or_Random_Forests | relevant_2020.Algorithms__Gradient_Boosting_Machines | relevant_2020.Algorithms__Bayesian_Approaches | relevant_2020.Algorithms__Evolutionary_Approaches | relevant_2020.Algorithms__Dense_Neural_Networks\nrelevant_2020['Algorithm_Cluster_Deep_Learning_Vision'] = relevant_2020.Algorithms__CNN | relevant_2020.Algorithms__GAN\nrelevant_2020['Algorithm_Cluster_Deep_Learning_NLP'] = relevant_2020.Algorithms__RNN | relevant_2020.Algorithms__Transformer_Networks\nrelevant_2020['Algorithm_Cluster_Deep_Learning'] = relevant_2020['Algorithm_Cluster_Deep_Learning_Vision'] | relevant_2020['Algorithm_Cluster_Deep_Learning_NLP']\nrelevant_2020['Algorithm_Cluster_Other'] = relevant_2020['Algorithms__Other'].apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Algorithm_Cluster_None'] = ((relevant_2020.Algorithm_Cluster_Traditional_ML == 0) & (relevant_2020.Algorithm_Cluster_Deep_Learning_Vision == 0 )\n                                           & (relevant_2020.Algorithm_Cluster_Deep_Learning_NLP == 0) & (relevant_2020.Algorithm_Cluster_Other == 0)).astype(int)\n\nrelevant_2020['Hardware__CPU'] = data.Q12_OTHER.apply(lambda x: 1 if ('cpu' in str(x).lower()) else 0)\nrelevant_2020['Hardware__GPU'] = data.Q12_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hardware__TPU'] = data.Q12_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hardware__None'] = data.Q12_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Hardware__Other'] = data.Q12_OTHER\n\nrelevant_2020['Framework__TensorFlow'] = data.Q16_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Framework__Keras'] = data.Q16_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Framework__PyTorch'] = data.Q16_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Framework__TensorFlow_Keras'] = relevant_2020['Framework__TensorFlow'] & relevant_2020['Framework__Keras']\nrelevant_2020['Framework__TensorFlow_Keras_PyTorch'] = relevant_2020['Framework__TensorFlow'] | relevant_2020['Framework__Keras'] | relevant_2020['Framework__PyTorch']\n\nrelevant_2020['Cloud_Platform__GCP'] =data.Q26_A_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__AWS'] =data.Q26_A_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Azure'] =data.Q26_A_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__IBM'] =data.Q26_A_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Alibaba'] = data.Q26_A_Part_9.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Tencent'] = data.Q26_A_Part_10.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Salesforce'] = data.Q26_A_Part_7.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Oracle'] = data.Q26_A_Part_5.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__SAP'] = data.Q26_A_Part_6.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__VMWare'] = data.Q26_A_Part_8.apply(lambda x: 0 if x != x else 1) \nrelevant_2020['Cloud_Platform__Red_Hat'] = data.Q26_A_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__None'] = data.Q26_A_Part_11.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Cloud_Platform__Other'] = data.Q26_A_OTHER.apply(lambda x: 0 if x != x else 1)\n\n\n\nrelevant_2020['Media__Twitter'] = data.Q39_Part_1.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Newsletters'] = data.Q39_Part_2.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Reddit'] = data.Q39_Part_3.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Kaggle'] = data.Q39_Part_4.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Course_Forums'] = data.Q39_Part_5.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__YouTube'] = data.Q39_Part_6.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Podcast'] = data.Q39_Part_7.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Blogs'] = data.Q39_Part_8.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Journal_Publications'] = data.Q39_Part_9.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Slack'] = data.Q39_Part_10.apply(lambda x: 0 if x != x else 1) \nrelevant_2020['Media__None'] = data.Q39_Part_11.apply(lambda x: 0 if x != x else 1)\nrelevant_2020['Media__Other'] =data.Q39_OTHER.apply(lambda x: 0 if x != x else 1)","5bf0f44e":"relevant_2020['Year'] = 2020\nrelevant_2020 = relevant_2020.loc[1:].reset_index(drop=True)\n\ndff = relevant_2020","c2b73ee2":"def categorize_occupations(x):\n    if 'data scien' in x:\n        return 'Data Scientist'\n    elif 'software developer' in x:\n        return 'Software Engineer'\n    elif any(s in x for s in ['student', 'intern']):\n        return 'Student'\n    elif 'research' in x:\n        return 'Research Scientist'\n    elif 'data analy' in x:\n        return 'Data Analyst'\n    elif 'ness analy' in x:\n        return 'Business Analyst'\n    elif any(s in x for s in ['prof', 'teach', 'lect', 'educat', 'faculty', 'academi']):\n        return 'Teacher\/Professor'\n    elif any(s in x for s in ['ngineer', 'enginner']):\n        return 'Other Engineer'\n    elif 'project' in x:\n        return 'Product\/Project Manager'\n    elif any(s in x for s in ['lead', 'manag', 'head', 'direct', 'dircetor']):\n        return 'Manager'\n    elif any(s in x for s in ['chief', 'cto', 'ceo', 'coo','cfo', 'cio', 'cdo']):\n        return 'Chief Officer'\n    elif 'test' in x:\n        return 'Software Tester'\n    elif 'tired' in x:\n        'Not employed'\n    elif any(s in x for s in ['writer', 'journal']):\n        'Data Journalist'\n    else:\n        return 'Other'\n    \ndict_occupation = {'Software Developer\/Software Engineer' : 'Software Engineer',\n               'Researcher' : 'Research Scientist',\n               'Scientist\/Researcher' : 'Research Scientist',\n               'Research Assistant' : 'Research Scientist',\n                   \n               'Marketing Analyst' : 'Other',\n                   'Salesperson' : 'Other',\n                   \n                   'Consultant' : 'Other',\n              }\ndff['Occupation'] = dff['Occupation'].replace(dict_occupation)\n\n\ndff.Activities__Other = dff.Activities__Other.fillna('NaN')\ndff.Occupation = dff.apply(lambda x: 'Student' if (('student' in x.Activities__Other.lower()) & ~('teach' in x.Activities__Other.lower()) & ~('educate' in x.Activities__Other.lower()) & (x.Occupation != 'Student')) else x.Occupation, axis = 1)","4e03e34e":"temp = dff.groupby('Year').agg(Survey_Participants = ('Year', 'count' ),\n                       Algorithm_Cluster_Traditional_ML = ('Algorithm_Cluster_Traditional_ML', 'sum'),\n                       Algorithm_Cluster_Deep_Learning_Vision = ('Algorithm_Cluster_Deep_Learning_Vision', 'sum'),\n                       Algorithm_Cluster_Deep_Learning_NLP = ('Algorithm_Cluster_Deep_Learning_NLP', 'sum'),\n                       Algorithm_Cluster_Deep_Learning = ('Algorithm_Cluster_Deep_Learning', 'sum'),\n                       Algorithms__None = ('Algorithms__None', 'sum'),\n                              Algorithms_Cluster_Other = ('Algorithm_Cluster_Other', 'sum'),\n                      )\nfor c in temp.columns:\n    if c != 'Survey_Participants':\n        temp[c] = temp[c] \/ temp['Survey_Participants'] *100\n\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(16,8))\nax[0].set_title(\"Percentage of Kagglers' \\nUsage of Machine Learning Algorithms\", fontsize=16)\n\ngroup1 = int((dff[(dff.Year == 2020) & (dff.Algorithm_Cluster_Traditional_ML == 0) & (dff.Algorithm_Cluster_Deep_Learning != 0)].shape[0] \/ dff[(dff.Year == 2020)].shape[0])*100)\ngroup2 = int((dff[(dff.Year == 2020) & (dff.Algorithm_Cluster_Traditional_ML != 0) & (dff.Algorithm_Cluster_Deep_Learning == 0)].shape[0] \/ dff[(dff.Year == 2020)].shape[0])*100) \nintersection = int((dff[(dff.Year == 2020) & (dff.Algorithm_Cluster_Traditional_ML != 0) & (dff.Algorithm_Cluster_Deep_Learning != 0)].shape[0] \/ dff[(dff.Year == 2020)].shape[0])*100)\n\nv1 = venn2(subsets = (group1, group2, intersection),\n          set_labels = ( '', '', ''),\n          set_colors=( 'deepskyblue', 'lightgrey'),\n           alpha=1,\n           ax=ax[0])\n\nv1.get_patch_by_id('11').set_color('skyblue')\nc1 = venn2_circles(subsets = (group1, group2, intersection), color='skyblue', ax=ax[0])\nc1[0].set_lw(3.0)\nc1[1].set_lw(0.0)\nax[0].annotate('Deep Learning', xy=v1.get_label_by_id('10').get_position() - np.array([0, -0.05]), xytext=(-70,70),ha='center', textcoords='offset points', \narrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5',color='gray'))\n\nax[0].annotate('Traditional Machine Learning\\n (Regression, Decision Trees, \\nGBM, etc.)', xy=v1.get_label_by_id('01').get_position() - np.array([0, -0.05]), xytext=(70,70),\nha='center', textcoords='offset points', \narrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.5',color='gray'))\n\nax[0].annotate('Both', xy=v1.get_label_by_id('11').get_position() - np.array([0, -0.05]), xytext=(0,70),\nha='center', textcoords='offset points',\narrowprops=dict(arrowstyle='->', color='gray'))","07fb4258":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 5))\n\nsns.countplot(data.iloc[1:].Q15, order=['Under 1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years','5-10 years',  '10-20 years',\n       '20 or more years'], palette='Blues')\n\nax.set_title('Machine Learning Experience', fontsize = 14)\nax.set_ylabel(ylabel = 'Number of Respondents', fontsize = 12)\nax.set_xlabel(xlabel = 'Years of Machine Learning Experience', fontsize = 12)","0cb39806":"temp = dff[(dff.Occupation.isin(['Data Scientist', 'Research Scientist']) & (dff.Year==2020))]\ntemp = temp.groupby(['Year', 'Occupation']).agg(Framework__TensorFlow_Keras_PyTorch = ('Framework__TensorFlow_Keras_PyTorch', 'sum' ),\n                                                                    Framework__TensorFlow = ('Framework__TensorFlow', 'sum'),\n                                                                    Framework__Keras = ('Framework__Keras', 'sum'),\n                                                                    Framework__PyTorch = ('Framework__PyTorch', 'sum'),\n                                                                    Framework__TensorFlow_Keras = ('Framework__TensorFlow_Keras', 'sum'))\n\ntemp['Framework__TensorFlow'] = temp['Framework__TensorFlow'] \/ temp['Framework__TensorFlow_Keras_PyTorch']\ntemp['Framework__Keras'] = temp['Framework__Keras'] \/ temp['Framework__TensorFlow_Keras_PyTorch']\ntemp['Framework__PyTorch'] = temp['Framework__PyTorch'] \/ temp['Framework__TensorFlow_Keras_PyTorch']\ntemp['Framework__TensorFlow_Keras'] = temp['Framework__TensorFlow_Keras'] \/ temp['Framework__TensorFlow_Keras_PyTorch']\n\ntemp = temp.reset_index(drop=False)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\nfor i, occ in enumerate(['Data Scientist', 'Research Scientist']):#, 'Student']):\n\n    framework_by_occupation = temp[temp.Occupation==occ][['Year', 'Framework__TensorFlow', 'Framework__Keras', 'Framework__PyTorch']]\n    reg_tensorflow = LinearRegression().fit(np.array(framework_by_occupation.Year).reshape(-1, 1), np.array(framework_by_occupation.Framework__TensorFlow).reshape(-1, 1))\n    reg_keras = LinearRegression().fit(np.array(framework_by_occupation.Year).reshape(-1, 1), np.array(framework_by_occupation.Framework__Keras).reshape(-1, 1))\n    reg_pytorch = LinearRegression().fit(np.array(framework_by_occupation.Year).reshape(-1, 1), np.array(framework_by_occupation.Framework__PyTorch).reshape(-1, 1))\n    \n    framework_by_occupation = framework_by_occupation.append({'Year':2021, \n                  'Framework__TensorFlow': reg_tensorflow.predict(np.array([[2021]]))[0,0], \n                  'Framework__Keras': reg_keras.predict(np.array([[2021]]))[0,0], \n                  'Framework__PyTorch': reg_pytorch.predict(np.array([[2021]]))[0,0], }, \n                 ignore_index=True)\n    framework_by_occupation = framework_by_occupation.append({'Year':2022, \n                  'Framework__TensorFlow': reg_tensorflow.predict(np.array([[2022]]))[0,0], \n                  'Framework__Keras': reg_keras.predict(np.array([[2022]]))[0,0], \n                  'Framework__PyTorch': reg_pytorch.predict(np.array([[2022]]))[0,0], }, \n                 ignore_index=True)\n    \n    framework_by_occupation.set_index('Year').plot(ax=ax[i], marker='x')\n    \n    ax[i].set_ylim([0,1])\n    ax[i].set_ylabel(ylabel = 'Percentage of Respondents Used by [0.01%]', fontsize = 14)\n    ax[i].set_xlabel(xlabel = 'Year', fontsize = 14)\n    ax[i].set_xticks([2018, 2019, 2020, 2021, 2022,])# 2023, 2024])                                    \n    ax[i].add_patch(Rectangle((2020.5, 0), 4, 1, fill=True, alpha=0.2, color='Grey', lw=0))\n    ax[i].annotate('Prediction', xy=(2020.8, 0.9), fontsize=14, color='black')\n    ax[i].set_title(occ, fontsize = 16)","c9209c87":"# Occupation :","8cda31f1":"In the above code and graph We are predicting the estimated time take by various category of genders to fill the survey form. This is the nice visualization seeing Average category of man takes approx 9147 sec to respond to the form given.Woman takes 9234 secs to fill it.","7a6cd38a":"We are observing the variation of degrees in the above plot.We came to know person who is participating in the kaggle is mostly from Masters degree following which there is Bachelor's degree which has 34.83%. \nI would like to say degree doesn't matter for entering into the filed, this is just the survey. If we are interested and have the zeal to coe upon, then we can surely reach great heights..\n","305c9331":"# Education:","03d1249b":"Person having more years of experience has more paricipation in the field which is so true because 22.69% are using kaggle for doing projects who has 5 years experience .....","10730db0":"# Number of times TPU used:","4d89fe3e":"# Objective\n\nthe objective is to tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration.The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners.This is an opportunity to be creative and tell the story of a community you identify with or are passionate about!","59135b3a":"# Q1: PyTorch or TensorFlow\/Keras?\nThis question might even be more frequently asked \"I am new to Deep Learning. Should I start with PyTorch or TensorFlow\/Keras?\"Here is the answer.","c05fe952":"# Gender:","bd04350d":"# Typs of Computing platform:","116d007b":"We are able to redict from the above graph that India has most percentage of residers that is 29% while others have sam distribution Follow on USA , Brazil , russia.","8399ffec":"**Findings**\n\n* 31% of Kagglers regularly use both traditional Machine Learning and Deep Learning algorithms\n* Most Kagglers using Deep Learning algorithms also use traditional machine learning algorithms","b1dfe3ce":"# Age Group:","a3e7176e":"# Programming Language:","09a256b4":"We usually know the thing we are predicting in above graph i.e Programming language supportive in data Science.\nThe graph is preicting that Python is the most used programing language which we already know because Most of the persons working in the field have their proficiency in this language.\nAlthough kaggle supports both Python and R but we know Google colab which only supports Python.\nSo this survey is quiet useful for us.","8778f46d":"# Country:","fd2712e6":"Since we are all here to learn, let's explore what we can learn from Kagglers that are more experienced in machine learning, professional data scientists and researchers in the field.","3881aff5":"### size of the dataset for the persons attending the Survey form.","1b61ea8e":"# Kagglers are Levelling Up\n\nThis year, we have seen a large selection of different competitions on Kaggle. My feeling is that competitions with tabular data might be more popular among Kagglers. I think this is because we are all here to learn and competitions with tabular data are especially beginner friendly because you can apply traditional machine learning algorithms, which might be easier to apply for beginners.","6864b744":"From the Understanding of the above graph we can see that more than half of the graph is below 30 years of Age.\nperson having Age between 25-29 years is using Kaggle as the platform for data science is huge and massive.\nOther years are so comparitive, We cant differentiate between ages of persons.but Yes we are seeing less response from the ages above 40.","3dd053f7":"# Filling form genderwise","936f5df8":"# Coding experience:","dca15129":"# Introduction\n\nWelcome to Kaggle's annual Machine Learning and Data Science Survey competition!\nThis year, as in 2017, 2018, and 2019 kaggle set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live for 3.5 weeks in October, and after cleaning the data we finished with 20,036 responses!\n\nThere's a lot to explore here. The results include raw numbers about who is working with data, what\u2019s happening with machine learning in different industries, and the best ways for new data scientists to break into the field.\nIn our fourth year running this survey, community is suprised, awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This survey data EDA provides an overview of the industry on an aggregate scale. For that reason, we\u2019re invited by the researchers to dive deep into the survey datasets and help them tell the diverse stories of data scientists from around the world.\n\n\nThe Kaggle's 2020 Machine Learning and Data Science Survey data consists about 20,036 responses from Kaggle members.  From the total data, we will be focusing on analyzing responses from India.","157447b9":"## Kaggle is About Learning and Sharing Knowledge\nI want to explore what the current trends in Data Science are and what we can learn from experienced Machine Learning practitioners.","6c461e6f":"# Dataset\n\n\nIn the dataset we are given two files. Main data and Supplementary data. \nMain data consists of *kaggle_survey_2020_responses.csv*:  Responses to multiple choice questions (only a single choice can be selected) were recorded in individual columns. Responses to multiple selection questions (multiple choices can be selected) were split into multiple columns (with one column per answer choice).\n\nSupplementary data consists of teo files:\n1. kaggle_survey_2020_answer_choices.pdf: *list of answer choices for every question*\nWith footnotes describing which questions were asked to which respondents.\n\n2. kaggle_survey_2020_methodology.pdf: a description of how the survey was conducted.","a7187594":"**Importing the Dataset**"}}