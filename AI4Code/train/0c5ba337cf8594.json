{"cell_type":{"143d3b64":"code","0b3463bc":"code","cc716d6b":"code","02a8f8bd":"code","0d79f77d":"code","227863f7":"code","730da87c":"code","49e61735":"code","4dfbbe85":"code","1567856d":"code","bb55e000":"code","ec8685df":"code","56b65423":"code","853b8e67":"code","e5b559f0":"code","ff1668a1":"code","012f152a":"code","7ce3aac1":"code","cad9f936":"code","b3f5e059":"code","427129a8":"code","07db9d52":"code","263092bf":"code","458371cb":"code","ddf53420":"code","ffc5c99f":"code","17f1e721":"markdown","32295483":"markdown","c38168e6":"markdown","84f11b74":"markdown","ae4fa91b":"markdown","8c977695":"markdown","385c6b9c":"markdown"},"source":{"143d3b64":"# inspirated by a friend - https:\/\/www.kaggle.com\/brandao\/starting-point-in-r\n#\n#\n# # data.y <- ifelse(data$`SARS-Cov-2 exam result` == \"positive\", 1, 0);\n#\n#\n#\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n%matplotlib inline\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.set_option(\"display.max_rows\",500)\npd.set_option(\"display.max_columns\",500)","0b3463bc":"df = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\nprint(\"Data Frame, shape: \", df.shape)\nprint(\"Columns: \", list(df.columns))\ndf.head()","cc716d6b":"df.describe().T","02a8f8bd":"null_counts = df.isnull().sum()\/len(df)\nplt.figure(figsize=(16,8))\nplt.xticks(np.arange(len(null_counts))+0.5,null_counts.index,rotation='vertical')\nplt.ylabel('fraction of rows with missing data')\nplt.bar(np.arange(len(null_counts)),null_counts)\nplt.show()","0d79f77d":"# drop non-feature columns\nfeature_columns = df.columns.drop([\n    'Patient ID', \n    'SARS-Cov-2 exam result', \n    'Patient addmited to regular ward (1=yes, 0=no)', \n    'Patient addmited to semi-intensive unit (1=yes, 0=no)', \n    'Patient addmited to intensive care unit (1=yes, 0=no)'\n])\n# create multi-index with (count, fraction, number of NaN sequences) per feature column\niterables = [feature_columns,['count','fraction','seq']]\nindex = pd.MultiIndex.from_product(iterables,names=['feature','stat'])\n# use list of IDs as index (only sorted for easier navigation)\nids = df['Patient ID'].unique()\nids.sort()\n# create empty data frame\nnan_df = pd.DataFrame(data=None,index=df['SARS-Cov-2 exam result'].unique(),columns=index)\n\nfrom itertools import groupby\n# iterate over all asset ID\ntotal_groups = len(df.groupby('SARS-Cov-2 exam result'))\nprint(\"Groups:\", total_groups)\nfor i, (name, group) in enumerate(df.groupby('SARS-Cov-2 exam result')):\n    print('i:', i, '\/', total_groups, ', SARS-Cov-2 exam result:', name)\n    # for every feature column\n    for c in feature_columns:\n        #print('name:', name, \", group:\", len(group), ', c:', c)\n        # total number of rows with missing data\n        nan_count = group[c].isnull().sum()\n        # time span this ID was present\n        timespan = len(group[c])\n        # row indices for missing data\n        nan_indices = pd.isnull(group[c]).to_numpy().nonzero()[0]\n        # get number of joint time spans of missing values\n        nseq = len(list(groupby(enumerate(nan_indices),lambda x:x[0]-x[1])))\n        nan_df.loc[name][c,'count'] = nan_count\n        nan_df.loc[name][c,'fraction'] = nan_count * 1.0\/timespan\n        nan_df.loc[name][c,'seq'] = nseq\n        \nnan_df.head(20).T\n","227863f7":"fractions = nan_df.xs('fraction',level='stat',axis=1)\nfraction_mean = fractions.mean()\nfraction_std = fractions.std()\nplt.figure(figsize=(16,8))\nplt.xticks(np.arange(len(fraction_mean)),fraction_mean.index,rotation='vertical')\nplt.errorbar(np.arange(len(fraction_mean)),fraction_mean,yerr=fraction_std,fmt='o')\nplt.ylabel('mean fraction of rows with missing data per [SARS-Cov-2 exam result]');\nplt.show()","730da87c":"plt.hist(fractions.values.flatten(),bins=50)\nplt.xlabel('fraction of rows with missing data per [SARS-Cov-2 exam result]')\nplt.legend()\nplt.show()","49e61735":"nseq = nan_df.xs('seq',level='stat',axis=1)\nnseq_mean = nseq.mean()\nnseq_std = nseq.std()\nplt.figure(figsize=(16,8))\nplt.xticks(np.arange(len(nseq_mean)),nseq_mean.index,rotation='vertical') #todo: check this (we don't have timestamp)\nplt.errorbar(np.arange(len(nseq_mean)),nseq_mean,yerr=nseq_std,fmt='o')\nplt.ylabel('mean number of connected NaN ranges')\nplt.show()","4dfbbe85":"plt.hist(nseq.values.flatten(),bins=50)\nplt.xlabel('number of connected time ranges with missing data per [SARS-Cov-2 exam result]');  #todo: check this (we don't have timestamp)\nplt.legend()\nplt.show()","1567856d":"from sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold\nimport lightgbm as lgb\nimport shap","bb55e000":"cat_features = [\n    i for i in df.columns if str(df[i].dtype) in ['object', 'category']\n]\nif len(cat_features) > 0:\n    df[cat_features] = df[cat_features].astype('category')\nprint(df.dtypes)\n\n# lgb don't like strings\/category, only numbers and boolean\ndf_lgb = df.copy()\nfor i in cat_features:\n    df_lgb[i] = df[i].cat.codes\n# it don't like complex names too..\ndf_lgb.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_lgb.columns]\nprint(df_lgb.columns)\n\ny = (df['SARS-Cov-2 exam result'] == 'positive').astype(int)\nx = df_lgb.drop(['Patient_ID', \n                 'SARS_Cov_2_exam_result', \n                 'Patient_addmited_to_regular_ward__1_yes__0_no_', \n                 'Patient_addmited_to_semi_intensive_unit__1_yes__0_no_', \n                 'Patient_addmited_to_intensive_care_unit__1_yes__0_no_'\n                ], axis=1)\nprint(y.shape, x.shape, df_lgb.shape)","ec8685df":"# x\/y train\/test\nwhile True:\n    train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y)\n    train_weight = 1-train_y.replace(train_y.value_counts()\/len(train_y))\n    valid_weight = 1-valid_y.replace(valid_y.value_counts()\/len(valid_y))\n    if len(train_y.unique()) > 1 and len(valid_y.unique()) > 1:\n        break\npositive_weight = train_weight[train_y==1].values[0]\ntrain_data=lgb.Dataset(train_x,label=train_y, weight=train_weight)\nvalid_data=lgb.Dataset(valid_x,label=valid_y, weight=valid_weight, reference=train_data)\n\nprint(\"train_y:\\n\",train_y.value_counts())\nprint(\"valid_y:\\n\",valid_y.value_counts())\nprint(\"y:\\n\", y.value_counts())\n","56b65423":"#Select Hyper-Parameters\nparams = {'metric': 'auc',\n          'objective':'binary',\n          'eta': 0.004,\n          'boosting_type': 'gbdt',\n          'colsample_bytree': 0.9,\n          'max_depth': 9,\n          'n_estimators': 1200,\n          'subsample': 0.9,\n          'num_threads': -1,\n          'scale_pos_weight': positive_weight\n}\n#Train model on selected parameters and number of iterations\nlgbm = lgb.train(\n    params=params,\n    train_set=train_data,\n    valid_sets=valid_data,\n    early_stopping_rounds=500,\n    verbose_eval=100,\n#    categorical_feature=cat_features\n)","853b8e67":"y_hat = lgbm.predict(x)\nscore = roc_auc_score(y, y_hat)\nprint(\"Overall AUC: {:.3f}\" .format(score))\nplt.figure(figsize=(12,12))\nplt.subplot(2,3,1)\nplt.hist(lgbm.predict(x[y==1]), label='y=1', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,2)\nplt.hist(lgbm.predict(train_x[y==1]), label='train y=1', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,3)\nplt.hist(lgbm.predict(valid_x[y==1]), label='valid y=1', bins=50, density=True)\nplt.legend()\n\nplt.subplot(2,3,4)\nplt.hist(lgbm.predict(x[y==0]), label='y=0', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,5)\nplt.hist(lgbm.predict(train_x[y==0]), label='train y=0', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,6)\nplt.hist(lgbm.predict(valid_x[y==0]), label='valid y=0', bins=50, density=True)\nplt.legend()\nplt.show()\n","e5b559f0":"def create_threshold_chart(y_hat, y, weight):\n    # valid threshold\n    x, y1, y2, y3, y4 = np.array(range(0,100))\/100., [], [], [], []\n    for ii, i in enumerate(x):\n        predicted_class = y_hat>i\n        y1.append(len(y[(predicted_class==1) & (y==0)])\/len(y[y==0]))\n        y2.append(len(y[(predicted_class==0) & (y==1)])\/len(y[y==1]))\n        y3.append(\n            len(y[(predicted_class==1) & (y==0)]) * weight[0] \/ \n            (len(y[y==0]) * weight[0] + len(y[y==1]) * weight[1])\n        )\n        y4.append(\n            len(y[(predicted_class==0) & (y==1)]) * weight[0] \/ \n            (len(y[y==0]) * weight[0] + len(y[y==1]) * weight[1])\n        )\n    \n    plt.figure(figsize=(14,7))\n    plt.subplot(1,2,1)\n    plt.title(\"False rates\")\n    plt.plot(x, y1, label='false positives')\n    plt.plot(x, y2, label='false negatives')\n    plt.xlabel(\"Classifier Threshold\")\n    plt.ylabel(\"False Rate %\")\n    plt.legend()\n    \n    plt.subplot(1,2,2)\n    plt.title(\"False rates, weighted by positive\/negative weight\\n(0=\" + str(weight[0]) + \", 1=\" + str(weight[1]) + \")\")\n    plt.plot(x, y3, label='false positives')\n    plt.plot(x, y4, label='false negatives')\n    plt.xlabel(\"Classifier Threshold\")\n    plt.ylabel(\"False Rate %\")\n    plt.legend()\n    \n    plt.show()\ncreate_threshold_chart(\n    y_hat=lgbm.predict(valid_x),\n    y=valid_y,\n    weight={0:1-positive_weight, 1:positive_weight}\n)","ff1668a1":"%time shap_values = shap.TreeExplainer(lgbm).shap_values(valid_x)\nprint(shap_values[0].shape)","012f152a":"shap.summary_plot(shap_values, valid_x)\n","7ce3aac1":"print(\"Total columns to display:\", len(valid_x.columns))\nfor i in valid_x.columns:\n    shap.dependence_plot(i, shap_values[0], valid_x)\n    plt.show()","cad9f936":"# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importance(),x.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 20))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\n","b3f5e059":"y = (df['SARS-Cov-2 exam result'] == 'positive').astype(int)\nx = df_lgb.drop([\n    'Patient_age_quantile',\n    'Patient_ID', \n    'SARS_Cov_2_exam_result', \n    'Patient_addmited_to_regular_ward__1_yes__0_no_', \n    'Patient_addmited_to_semi_intensive_unit__1_yes__0_no_', \n    'Patient_addmited_to_intensive_care_unit__1_yes__0_no_'\n], axis=1)\nprint(y.shape, x.shape, df_lgb.shape)\n\n# x\/y train\/test\n# x\/y train\/test\nwhile True:\n    train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y)\n    train_weight = 1-train_y.replace(train_y.value_counts()\/len(train_y))\n    valid_weight = 1-valid_y.replace(valid_y.value_counts()\/len(valid_y))\n    if len(train_y.unique()) > 1 and len(valid_y.unique()) > 1:\n        break\npositive_weight = train_weight[train_y==1].values[0]\ntrain_data=lgb.Dataset(train_x,label=train_y, weight=train_weight)\nvalid_data=lgb.Dataset(valid_x,label=valid_y, weight=valid_weight, reference=train_data)\n\nprint(\"train_y:\\n\",train_y.value_counts())\nprint(\"valid_y:\\n\",valid_y.value_counts())\nprint(\"y:\\n\", y.value_counts())\n\n#Select Hyper-Parameters\nparams = {'metric': 'auc',\n          'objective':'binary',\n          'eta': 0.004,\n          'boosting_type': 'gbdt',\n          'colsample_bytree': 0.9,\n          'max_depth': 9,\n          'n_estimators': 1200,\n          'subsample': 0.9,\n          'num_threads': -1,\n          'scale_pos_weight': positive_weight\n}\n#Train model on selected parameters and number of iterations\nlgbm = lgb.train(\n    params=params,\n    train_set=train_data,\n    valid_sets=valid_data,\n    early_stopping_rounds=500,\n    verbose_eval=100,\n#    categorical_feature=cat_features\n)","427129a8":"# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importance(),x.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 20))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\n","07db9d52":"%time shap_values = shap.TreeExplainer(lgbm).shap_values(valid_x)\nprint(shap_values[0].shape)","263092bf":"shap.summary_plot(shap_values, valid_x)\n","458371cb":"print(\"Total columns to display:\", len(valid_x.columns))\nfor i in valid_x.columns:\n    shap.dependence_plot(i, shap_values[0], valid_x)\n    plt.show()","ddf53420":"plt.figure(figsize=(12,12))\nplt.subplot(2,3,1)\nplt.hist(lgbm.predict(x[y==1]), label='y=1', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,2)\nplt.hist(lgbm.predict(train_x[y==1]), label='train y=1', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,3)\nplt.hist(lgbm.predict(valid_x[y==1]), label='valid y=1', bins=50, density=True)\nplt.legend()\n\nplt.subplot(2,3,4)\nplt.hist(lgbm.predict(x[y==0]), label='y=0', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,5)\nplt.hist(lgbm.predict(train_x[y==0]), label='train y=0', bins=50, density=True)\nplt.legend()\nplt.subplot(2,3,6)\nplt.hist(lgbm.predict(valid_x[y==0]), label='valid y=0', bins=50, density=True)\nplt.legend()\nplt.show()\n\ncreate_threshold_chart(\n    y_hat=lgbm.predict(valid_x),\n    y=valid_y,\n    weight={0:1-positive_weight, 1:positive_weight}\n)","ffc5c99f":"cat_features = [\n    i for i in df.columns if str(df[i].dtype) in ['object', 'category']\n]\nif len(cat_features) > 0:\n    df[cat_features] = df[cat_features].astype('category')\n\n# lgb don't like strings\/category, only numbers and boolean\ndf_lgb = df.copy()\nfor i in cat_features:\n    df_lgb[i] = df[i].cat.codes\n# it don't like complex names too..\ndf_lgb.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_lgb.columns]\n\nfor with_without in [0,1]:\n    for task in [\n         'Patient_addmited_to_regular_ward__1_yes__0_no_', \n         'Patient_addmited_to_semi_intensive_unit__1_yes__0_no_', \n         'Patient_addmited_to_intensive_care_unit__1_yes__0_no_'\n    ]:\n        print('TASK: ', task, \"without age column\" if with_without == 1 else '')\n        if 'positive' in df_lgb[task].unique():\n            y = (df_lgb[task] == 'positive').astype(int)\n        else:\n            y = (df_lgb[task] == 1).astype(int)\n        x = df_lgb.drop(['Patient_ID', \n                         'SARS_Cov_2_exam_result', \n                         'Patient_addmited_to_regular_ward__1_yes__0_no_', \n                         'Patient_addmited_to_semi_intensive_unit__1_yes__0_no_', \n                         'Patient_addmited_to_intensive_care_unit__1_yes__0_no_'\n                        ], axis=1)\n        if with_without == 1:\n            x = x.drop(['Patient_age_quantile'], axis=1)\n        # x\/y train\/test\n        error_count = 0\n        while True:\n            train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y)\n            train_weight = 1-train_y.replace(train_y.value_counts()\/len(train_y))\n            valid_weight = 1-valid_y.replace(valid_y.value_counts()\/len(valid_y))\n            if len(train_y.unique()) > 1 and len(valid_y.unique()) > 1:\n                break\n            error_count += 1\n            print(\n                \"error [\", error_count,\"] spliting dataset, len(train_y)=\",\n                len(train_y.unique()) ,\n                \" or len(valid_y)=\",\n                len(valid_y.unique()),\n                \" are equal to 1\")\n            if error_count>10:\n                break\n        if error_count>10:\n            print(\"Can't split dataset\")\n            continue\n\n        positive_weight = train_weight[train_y==1].values[0]\n        train_data=lgb.Dataset(train_x,label=train_y, weight=train_weight)\n        valid_data=lgb.Dataset(valid_x,label=valid_y, weight=valid_weight, reference=train_data)\n\n        #Select Hyper-Parameters\n        params = {'metric': 'auc',\n                  'objective':'binary',\n                  'eta': 0.004,\n                  'boosting_type': 'gbdt',\n                  'colsample_bytree': 0.9,\n                  'max_depth': 9,\n                  'n_estimators': 1200,\n                  'subsample': 0.9,\n                  'num_threads': -1,\n                  'scale_pos_weight': positive_weight\n        }\n\n        #Train model on selected parameters and number of iterations\n        lgbm = lgb.train(\n            params=params,\n            train_set=train_data,\n            valid_sets=valid_data,\n            early_stopping_rounds=500,\n            verbose_eval=0,\n        #    categorical_feature=cat_features\n        )\n        # sorted(zip(clf.feature_importances_, X.columns), reverse=True)\n        feature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importance(),x.columns)), columns=['Value','Feature'])\n\n        plt.figure(figsize=(20, 20))\n        sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n        plt.title(task + ' - LightGBM Features (avg over folds)')\n        plt.tight_layout()\n        plt.show()\n        \n        shap_values = shap.TreeExplainer(lgbm).shap_values(valid_x)\n        shap.summary_plot(shap_values, valid_x)\n        plt.show()\n        \n        plt.figure(figsize=(12,12))\n        plt.subplot(2,3,1)\n        plt.hist(lgbm.predict(x[y==1]), label='y=1', bins=50, density=True)\n        plt.legend()\n        plt.subplot(2,3,2)\n        plt.title(task)\n        plt.hist(lgbm.predict(train_x[y==1]), label='train y=1', bins=50, density=True)\n        plt.legend()\n        plt.subplot(2,3,3)\n        plt.hist(lgbm.predict(valid_x[y==1]), label='valid y=1', bins=50, density=True)\n        plt.legend()\n\n        plt.subplot(2,3,4)\n        plt.hist(lgbm.predict(x[y==0]), label='y=0', bins=50, density=True)\n        plt.legend()\n        plt.subplot(2,3,5)\n        plt.hist(lgbm.predict(train_x[y==0]), label='train y=0', bins=50, density=True)\n        plt.legend()\n        plt.subplot(2,3,6)\n        plt.hist(lgbm.predict(valid_x[y==0]), label='valid y=0', bins=50, density=True)\n        plt.legend()\n        plt.show()\n        \n        create_threshold_chart(\n            y_hat=lgbm.predict(valid_x),\n            y=valid_y,\n            weight={0:1-positive_weight, 1:positive_weight}\n        )","17f1e721":"# Let's test other tasks","32295483":"# Let's remove age","c38168e6":"well... very bad results, probably will send to home someone sick, or leave someone \"good\" at hospital","84f11b74":"# Missing values\n\nhttps:\/\/www.kaggle.com\/cgump3rt\/investigate-missing-values","ae4fa91b":"# gradient boost - y=SARS-Cov-2 exam result","8c977695":"# Feature importance LGBM","385c6b9c":"# Shap values\n\nhttps:\/\/www.kaggle.com\/cast42\/lightgbm-model-explained-by-shap"}}