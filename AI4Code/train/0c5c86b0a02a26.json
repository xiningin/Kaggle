{"cell_type":{"1b5c1e70":"code","740fe9a9":"code","ac1eeb5f":"code","0e5e5709":"code","3bf7f2eb":"code","ad370550":"code","dcee3a37":"code","5d2f2100":"code","0878dfd0":"code","55ead657":"markdown","d3f779c1":"markdown","8ab28830":"markdown","5fdc6134":"markdown","e961b8e7":"markdown","16f4ae81":"markdown","6ae6cdcf":"markdown","c99234c4":"markdown","1e89a2ad":"markdown","cda584fa":"markdown","78ed05a2":"markdown"},"source":{"1b5c1e70":"import os\nimport math\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom google.cloud import storage","740fe9a9":"# For uploading to GCS buckets:\nSTORAGE_CLIENT = storage.Client(project='kaggle-playground-170215')\n# For converting images to TFRecord files:\nWORKING_DIRECTORY = \".\/\"\nBASE_DIR = '\/kaggle\/input\/flowers-recognition\/flowers\/flowers'\nFILE_PATTERN = BASE_DIR + '\/*\/*.jpg'\nTARGET_SIZE = [512, 512]\nCLASSES = os.listdir(BASE_DIR)\nAUTO = tf.data.experimental.AUTOTUNE\nSHARDS = 16\n\ndef create_bucket(dataset_name):\n    \"\"\"Creates a new bucket. https:\/\/cloud.google.com\/storage\/docs\/ \"\"\"\n    bucket = STORAGE_CLIENT.create_bucket(dataset_name)\n    print('Bucket {} created'.format(bucket.name))\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Uploads a file to the bucket. https:\/\/cloud.google.com\/storage\/docs\/ \"\"\"\n    bucket = STORAGE_CLIENT.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n    \ndef list_blobs(bucket_name):\n    \"\"\"Lists all the blobs in the bucket. https:\/\/cloud.google.com\/storage\/docs\/\"\"\"\n    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n    for blob in blobs:\n        print(blob.name)\n        \ndef download_to_kaggle(bucket_name,destination_directory,file_name):\n    \"\"\"Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook\"\"\"\n    os.makedirs(destination_directory, exist_ok = True)\n    full_file_path = os.path.join(destination_directory, file_name)\n    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n    for blob in blobs:\n        blob.download_to_filename(full_file_path)\n    \ndef decode_jpeg_and_label(filename):\n  bits = tf.io.read_file(filename)\n  image = tf.image.decode_jpeg(bits)\n  label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='\/')\n  label = label.values[-2]\n  return image, label\n\ndef resize_and_crop_image(image, label):\n  # Resize and crop using \"fill\" algorithm:\n  # always make sure the the resulting image\n  # is cut out from the source image so that\n  # it fills the TARGET_SIZE entirely with no\n  # black bars and a preserved aspect ratio.\n  w = tf.shape(image)[0]\n  h = tf.shape(image)[1]\n  tw = TARGET_SIZE[1]\n  th = TARGET_SIZE[0]\n  resize_crit = (w * th) \/ (h * tw)\n  image = tf.cond(resize_crit < 1,\n                  lambda: tf.image.resize(image, [w*tw\/w, h*tw\/w]), # if true\n                  lambda: tf.image.resize(image, [w*th\/h, h*th\/h])  # if false\n                 )\n  nw = tf.shape(image)[0]\n  nh = tf.shape(image)[1]\n  image = tf.image.crop_to_bounding_box(image, (nw - tw) \/\/ 2, (nh - th) \/\/ 2, tw, th)\n  return image, label\n\ndef recompress_image(image, label):\n  height = tf.shape(image)[0]\n  width = tf.shape(image)[1]\n  image = tf.cast(image, tf.uint8)\n  image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n  return image, label, height, width\n\n# Three types of data can be stored in TFRecords: bytestrings, integers and floats\n# They are always stored as lists, a single data element will be a list of size 1\n\ndef _bytestring_feature(list_of_bytestrings):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n\ndef _int_feature(list_of_ints): # int64\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n\ndef _float_feature(list_of_floats): # float32\n  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n  \ndef to_tfrecord(tfrec_filewriter, img_bytes, label, height, width):  \n  class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)\n  one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses\n  feature = {\n      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n      \"class\": _int_feature([class_num]),        # one class in the list\n      # additional (not very useful) fields to demonstrate TFRecord writing\/reading of different types of data\n      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n      \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n  }\n  return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n        \n        # additional (not very useful) fields to demonstrate TFRecord writing\/reading of different types of data\n        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n        \"size\":          tf.io.FixedLenFeature([2], tf.int64),  # two integers\n        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)        # a certain number of floats\n    }\n    # decode the TFRecord\n    example = tf.io.parse_single_example(example, features)\n    # FixedLenFeature fields are now ready to use: exmple['size']\n    # VarLenFeature fields require additional sparse_to_dense decoding\n    image = tf.image.decode_jpeg(example['image'], channels=3)\n    image = tf.reshape(image, [*TARGET_SIZE, 3])\n    class_num = example['class']\n    label  = example['label']\n    height = example['size'][0]\n    width  = example['size'][1]\n    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n    return image, class_num, label, height, width, one_hot_class\n\ndef display_9_images_from_dataset(dataset):\n  plt.figure(figsize=(13,13))\n  subplot=331\n  for i, (image, label) in enumerate(dataset):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image.numpy().astype(np.uint8))\n    plt.title(label.numpy().decode(\"utf-8\"), fontsize=16)\n    subplot += 1\n    if i==8:\n      break\n  plt.tight_layout()\n  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n  plt.show()","ac1eeb5f":"def convert_image_dataset_to_tfrecords_format(BASE_DIR,FILE_PATTERN,\n                                              TARGET_SIZE,CLASSES,\n                                              WORKING_DIRECTORY,\n                                              SHARDS,AUTO):\n    '''\n    Converts an image dataset into TFRecords format.\n    Note that the image dataset should be organized\n    such that different classes of images in different \n    folders.\n    '''\n    nb_images = len(tf.io.gfile.glob(FILE_PATTERN))\n    shard_size = math.ceil(1.0 * nb_images \/ SHARDS)\n    #print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))\n    filenames = tf.data.Dataset.list_files(FILE_PATTERN, seed=35155) # This also shuffles the images\n    dataset1 = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)\n    #display_9_images_from_dataset(dataset1)\n    dataset2 = dataset1.map(resize_and_crop_image, num_parallel_calls=AUTO)  \n    #display_9_images_from_dataset(dataset2)\n    dataset3 = dataset2.map(recompress_image, num_parallel_calls=AUTO)\n    dataset3 = dataset3.batch(shard_size) # sharding: there will be one \"batch\" of images per file \n    #print(\"Writing TFRecords\")\n    for shard, (image, label, height, width) in enumerate(dataset3):\n      # batch size used as shard size here\n      shard_size = image.numpy().shape[0]\n      # good practice to have the number of records in the filename\n      filename = WORKING_DIRECTORY + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n      with tf.io.TFRecordWriter(filename) as out_file:\n        for i in range(shard_size):\n          example = to_tfrecord(out_file,\n                                image.numpy()[i], # re-compressed image: already a byte string\n                                label.numpy()[i],\n                                height.numpy()[i],\n                                width.numpy()[i])\n          out_file.write(example.SerializeToString())\n        #print(\"Wrote file {} containing {} records\".format(filename, shard_size))\n    # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n    # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n    # to allow order-altering optimizations.\n    option_no_order = tf.data.Options()\n    option_no_order.experimental_deterministic = False\n    dataset4 = tf.data.Dataset.list_files(WORKING_DIRECTORY + \"*.tfrec\")\n    dataset4 = dataset4.with_options(option_no_order)\n    dataset4 = dataset4.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n    dataset4 = dataset4.map(read_tfrecord, num_parallel_calls=AUTO)\n    dataset4 = dataset4.shuffle(300)\n    display_dataset = dataset4.map(lambda image, class_num, label, height, width, one_hot_class: (image, label))\n    #display_9_images_from_dataset(display_dataset)\n    return dataset4","0e5e5709":"convert_image_dataset_to_tfrecords_format(BASE_DIR,FILE_PATTERN,\n                                              TARGET_SIZE,CLASSES,\n                                              WORKING_DIRECTORY,\n                                              SHARDS,AUTO)\n#!rm '__notebook_source__.ipynb'\n#!rm -r '.ipynb_checkpoints'\n\nlist_of_files = os.listdir('\/kaggle\/working\/')\nprint(list_of_files)","3bf7f2eb":"bucket_name = 'flowers_dataset_1'         \ntry:\n    create_bucket(bucket_name)   \nexcept:\n    pass","ad370550":"for file in list_of_files:\n    local_data = WORKING_DIRECTORY+file\n    file_name = file\n    upload_blob(bucket_name, local_data, file_name)\n\nprint('\\nData inside of the GCS Bucket ',bucket_name,':\\n')\nlist_blobs(bucket_name)  ","dcee3a37":"# os.listdir('\/kaggle\/working\/flowers\/')\n    \n# # FileNotFoundError: [Errno 2] No such file or directory: '\/kaggle\/working\/flowers\/'","5d2f2100":"destination_directory = '\/kaggle\/working\/flowers\/'       \nfor file_name in list_of_files:\n    download_to_kaggle(bucket_name,destination_directory,file_name)","0878dfd0":"os.listdir('\/kaggle\/working\/flowers\/')","55ead657":"*Step 7: Download the data from GCS back into your notebook to verify that it really exists*","d3f779c1":"*Step 4: Convert your image dataset to TFRecords format*","8ab28830":"**Example notebook:**\n* https:\/\/www.kaggle.com\/mgornergoogle\/flowers-with-keras-and-xception-fine-tuned-on-gpu","5fdc6134":"*Step 8: Preview the data you just downloaded*","e961b8e7":"*Step 1: Import Python Modules*","16f4ae81":"*Step 3: Write a function to return an image dataset as a collection of TFRecords files*","6ae6cdcf":"*Step 6: Upload your data to the GCS Bucket*","c99234c4":"# How to convert a Kaggle dataset into a GCS bucket full of TFrecord files\n* adapted form https:\/\/codelabs.developers.google.com\/codelabs\/keras-flowers-data\/","1e89a2ad":"*Step 2: Define Variables and Helper Functions*","cda584fa":"*Step 9: Use your GCS bucket full of TFRecord files to train a machine learning model using a TPU.*","78ed05a2":"*Step 5: Create a new GCS Bucket*"}}