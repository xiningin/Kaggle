{"cell_type":{"74b8932b":"code","98c934b9":"code","d518b345":"code","acbe51cb":"code","eb09d947":"code","6f8d7a13":"code","8d565dc2":"code","ec104c20":"code","aa858847":"code","3805a30d":"code","0d1cfa58":"code","1620ffee":"code","37542612":"code","393a5dd1":"code","d57df113":"code","f80ac044":"code","54b5e229":"code","67064e1c":"code","e21a7083":"code","2622bb1d":"code","0d417064":"code","76c8272f":"code","bd6407a8":"code","0758d63c":"code","c05543c0":"markdown"},"source":{"74b8932b":"import numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n","98c934b9":"data_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv\")\ndata_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv\")\ndata_sub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")","d518b345":"display(data_train.head())\ndisplay(data_test.head())\ndisplay(data_sub.head())","acbe51cb":"display(data_train.info())\ndisplay(data_test.info())\ndisplay(data_sub.info())","eb09d947":"#drop the id\ndata_train = data_train.drop(['id'], axis=1)\ndata_test = data_test.drop(['id'], axis=1)","6f8d7a13":"data_train['target'].value_counts()","8d565dc2":"plt.figure(figsize=(10,8))\nsns.countplot(data_train['target'],\n                   linewidth=5,\n                   edgecolor=sns.color_palette(\"dark\", 3),palette=\"Set3\")","ec104c20":"data_train['newtarget'] = data_train['target'].map({'Class_1':0,\n                                                  'Class_2':1,\n                                                  'Class_3':2, \n                                                  'Class_4':3})","aa858847":"data_train.head()","3805a30d":"plt.figure(figsize=(18,25))\nsns.boxplot(data=data_train, orient=\"h\",palette=\"Set3\");\n","0d1cfa58":"plt.figure(figsize=(18,25))\nsns.boxplot(data=data_test.iloc[:,1:], orient=\"h\",palette=\"Set3\");","1620ffee":"data_train.corr()['newtarget']","37542612":"# Independant variable\nX = data_train.iloc[:,:-2]\n\n# Dependant variable\ny = data_train['newtarget']","393a5dd1":"# split  data into training and testing sets of 70:30 ratio\n# 30% of test size selected\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=1)","d57df113":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nmodel_1 = make_pipeline(StandardScaler(), SGDClassifier())\n\nprint(model_1.fit(X, y))\n\nprint(model_1.score(X_test,y_test))\n\n\ny_pred = model_1.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","f80ac044":"from sklearn.ensemble import RandomForestClassifier\nmodel_2 = make_pipeline(StandardScaler(), RandomForestClassifier())\n\nprint(model_2.fit(X, y))\n\nprint(model_2.score(X_test,y_test))\n\ny_pred = model_2.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","54b5e229":"from sklearn import neighbors\nmodel_3 = make_pipeline(StandardScaler(), neighbors.KNeighborsClassifier())\n\nprint(model_3.fit(X, y))\n\nprint(f'score Model:',model_3.score(X_test,y_test))\n\ny_pred = model_3.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","67064e1c":"import xgboost as xgb\nmodel_4 = make_pipeline(StandardScaler(),xgb.XGBClassifier())\n\nprint(model_4.fit(X, y))\n\nprint(f'score Model:',model_4.score(X_test,y_test))\n\ny_pred = model_4.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","e21a7083":"models = pd.DataFrame({\n    'Model': ['SGDClassifier','Random Forest Classifier',\n              'K Neighbors Classifier', 'XGB Classifier'],\n\n    'Score': [model_1.score(X_test,y_test)*100,\n              model_2.score(X_test,y_test)*100,\n              model_3.score(X_test,y_test)*100, \n              model_4.score(X_test,y_test)*100]})","2622bb1d":"models.sort_values(by='Score', ascending=True)","0d417064":"%%time\n\ntest_pred = model_2.predict(data_test)\nprint('Prediction for test set:\\n{}\\nShape = {}'.format(test_pred[:5], test_pred.shape))","76c8272f":"test_pred","bd6407a8":"data_sub.to_csv('submission.csv', index=False)","0758d63c":"data_sub","c05543c0":"\n\n## 4 Algorithms Classifier\n### We used 4 algorithms Classifier\n\n\n* SGD Classifier\n* Random Forest Classifier\n* XGB Classifier\n* KNeighbors Classifier\n\n\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/26479\/logos\/thumb76_76.png?t=2021-04-09-00-56-24\" width=\"800px\">\n\n###  Data Description\n\nThe dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.\n\n\n### Files\n* train.csv - the training data, one product (id) per row, with the associated features (feature_*) and class label (target)\n* test.csv - the test data; you must predict the probability the id belongs to each class\n* sample_submission.csv - a sample submission file in the correct format\n\n\n\n#### Dataset Link\n\n\n##### [Here](https:\/\/www.kaggle.com\/c\/tabular-playground-series-may-2021\/code)\n\n"}}