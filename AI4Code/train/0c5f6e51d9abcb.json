{"cell_type":{"02455927":"code","7c04de9b":"code","464a583e":"code","2c8eb3b1":"code","4c1fa5e8":"code","23ab795f":"code","2d660055":"code","adf72261":"code","f2205423":"code","287d3cfd":"code","b06dac4e":"code","b1d091a4":"code","3f74dad6":"code","3e3a7711":"code","9d155e03":"code","fd4268f0":"code","1db0a0d6":"code","52b531af":"code","d93a3a80":"code","6a098bf7":"code","da511f0d":"code","23ff1c83":"code","9c9fcdfc":"code","07e1dc68":"code","223e1d8e":"code","3e5eee78":"code","f4770442":"code","4958effb":"code","d04a3d36":"code","50298361":"code","0d64dae1":"code","cb97e73a":"code","3cf1b845":"code","291ac91e":"markdown","4c39723d":"markdown","222f9909":"markdown","3abe2bf6":"markdown","2ea68ff8":"markdown","e85de4ca":"markdown","d9b3cbb2":"markdown","9f1a97e3":"markdown","474a018e":"markdown","b9514184":"markdown","25a3ab7a":"markdown","a3ce2389":"markdown","b9752ee1":"markdown","a928160b":"markdown","df84a54e":"markdown","7e203739":"markdown","9922fc64":"markdown"},"source":{"02455927":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c04de9b":"!pip install xlrd\n!pip install openpyxl\n!pip install lifetimes\n!pip install missingno\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.preprocessing import MinMaxScaler\nfrom lifetimes import BetaGeoFitter\nfrom lifetimes import GammaGammaFitter\nfrom lifetimes.plotting import plot_period_transactions\nimport warnings\nwarnings.filterwarnings(\"ignore\")","464a583e":"# Read the 2010-2011 data in the OnlineRetail II excel. Make a copy of the data frame you created.\n\ndf = pd.read_excel(\"\/kaggle\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")\ndf_copy = df.copy()\ndf.head()","2c8eb3b1":"#Checking Variables\n\ndef check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(3))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(3))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","4c1fa5e8":"df.describe([0.01,0.25,0.50,0.75,0.99]).T","23ab795f":"# There is no specific correlation between missing values\n\nmsno.heatmap(df)","2d660055":"sns.boxplot(df[\"Quantity\"]);","adf72261":"sns.boxplot(df[\"Price\"]);","f2205423":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","287d3cfd":"replace_with_thresholds(df,\"Quantity\")\nreplace_with_thresholds(df,\"Price\")","b06dac4e":"# outliers values are now cleaner.\n\ndf.describe([0.01,0.25,0.50,0.75,0.99]).T","b1d091a4":"def data_prep(dataframe):\n    dataframe.dropna(axis=0, inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n    return dataframe","3f74dad6":"df= data_prep(df)\ncheck_df(df)","3e3a7711":"sns.boxplot(df[\"Quantity\"])","9d155e03":"sns.boxplot(df[\"Price\"]);","fd4268f0":"df[\"InvoiceDate\"].max()\ntoday_date = dt.datetime(2011, 12, 11)\n\n# recency\n# frequency\n# monetary\n\nrfm = df.groupby(\"Customer ID\").agg({\"InvoiceDate\": lambda x: (today_date - x.max()).days,\n                               \"Invoice\": lambda x: x.nunique(),\n                               \"TotalPrice\": lambda x: x.sum()})\n\nrfm.columns = [\"recency\", \"frequency\", \"monetary\"]\n\nrfm = rfm[rfm[\"monetary\"] > 0]\nrfm.head()","1db0a0d6":"rfm[\"recency_score\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n\nrfm[\"frequency_score\"] = pd.qcut(rfm['frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n\nrfm[\"monetary_score\"] = pd.qcut(rfm['monetary'], 5, labels=[1, 2, 3, 4, 5])","52b531af":"rfm[\"RFM_SCORE\"] = (rfm['recency_score'].astype(str) +\n                    rfm['frequency_score'].astype(str))","d93a3a80":"seg_map = {\n    r'[1-2][1-2]': 'hibernating',\n    r'[1-2][3-4]': 'at_Risk',\n    r'[1-2]5': 'cant_loose',\n    r'3[1-2]': 'about_to_sleep',\n    r'33': 'need_attention',\n    r'[3-4][4-5]': 'loyal_customers',\n    r'41': 'promising',\n    r'51': 'new_customers',\n    r'[4-5][2-3]': 'potential_loyalists',\n    r'5[4-5]': 'champions'\n}\n\n\nrfm['segment'] = rfm['RFM_SCORE'].replace(seg_map, regex=True)\n\nrfm[[\"segment\", \"recency\", \"frequency\", \"monetary\"]].groupby(\"segment\").agg([\"mean\", \"count\"])","6a098bf7":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"segment\", y=\"frequency\", data=rfm)","da511f0d":"check_df(rfm)","23ff1c83":"def create_cltv_calculated(dataframe):\n    # avg_order_value\n    dataframe['avg_order_value'] = dataframe['monetary'] \/ dataframe['frequency']\n\n    # purchase_frequency\n    dataframe[\"purchase_frequency\"] = dataframe['frequency'] \/ dataframe.shape[0]\n\n    # repeat rate & churn rate\n    repeat_rate = dataframe[dataframe.frequency > 1].shape[0] \/ dataframe.shape[0]\n    churn_rate = 1 - repeat_rate\n\n    # profit_margin\n    dataframe['profit_margin'] = dataframe['monetary'] * 0.05\n\n    # Customer Value\n    dataframe['cv'] = (dataframe['avg_order_value'] * dataframe[\"purchase_frequency\"])\n\n    # Customer Lifetime Value\n    dataframe['cltv'] = (dataframe['cv'] \/ churn_rate) * dataframe['profit_margin']\n\n    # minmaxscaler\n    scaler = MinMaxScaler(feature_range=(1, 100))\n    scaler.fit(dataframe[[\"cltv\"]])\n    dataframe[\"cltv_calculated\"] = scaler.transform(dataframe[[\"cltv\"]])\n\n    dataframe[\"cltv_calculated_segment\"] = pd.qcut(dataframe[\"cltv_calculated\"], 3, labels=[\"C\", \"B\", \"A\"])\n\n    dataframe = dataframe[[\"recency\", \"frequency\", \"monetary\", \"segment\",\n                           \"cltv_calculated\", \"cltv_calculated_segment\"]]\n\n    return dataframe","9c9fcdfc":"rfm_cltv = create_cltv_calculated(rfm)\ncheck_df(rfm_cltv)","07e1dc68":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"segment\", y=\"cltv_calculated\", data=rfm_cltv)","223e1d8e":"rfm_cltv.head()","3e5eee78":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"cltv_calculated\", y=\"cltv_calculated_segment\", data=rfm_cltv)","f4770442":"# The correlation seems very weak. \n\nplt.scatter(rfm_cltv.monetary,rfm_cltv.frequency,s=75)\n\n\nplt.xlabel(\"monetary\")\nplt.ylabel(\"frequency\")\nplt.legend()\nplt.show()","4958effb":"def create_cltv_predicted(dataframe):\n    today_date = dt.datetime(2011, 12, 11)\n\n    ## recency value customized\n    rfm = dataframe.groupby('Customer ID').agg({'InvoiceDate': [lambda date: (date.max()-date.min()).days,\n                                                                lambda date: (today_date - date.min()).days],\n                                                'Invoice': lambda num: num.nunique(),\n                                                'TotalPrice': lambda TotalPrice: TotalPrice.sum()})\n\n    rfm.columns = rfm.columns.droplevel(0)\n\n    ## recency_cltv_predicted\n    rfm.columns = ['recency_cltv_predicted', 'T', 'frequency', 'monetary']\n\n    ## basic monetary_avg\n    rfm[\"monetary\"] = rfm[\"monetary\"] \/ rfm[\"frequency\"]\n\n    rfm.rename(columns={\"monetary\": \"monetary_avg\"}, inplace=True)\n    \n    ## recency_weekly_cltv_predicted\n    rfm[\"recency_weekly_cltv_predicted\"] = rfm[\"recency_cltv_predicted\"] \/ 7\n    rfm[\"T_weekly\"] = rfm[\"T\"] \/ 7\n\n\n\n    # CONTROL\n    rfm = rfm[rfm[\"monetary_avg\"] > 0]\n\n    ## recency filter\n    rfm = rfm[(rfm['frequency'] > 1)]\n\n    rfm[\"frequency\"] = rfm[\"frequency\"].astype(int)\n\n    # BGNBD\n    bgf = BetaGeoFitter(penalizer_coef=0.01)\n    bgf.fit(rfm['frequency'],\n            rfm['recency_weekly_cltv_predicted'],\n            rfm['T_weekly'])\n    \n    # Gamma Gamma\n    ggf = GammaGammaFitter(penalizer_coef=0.01)\n    ggf.fit(rfm['frequency'], rfm['monetary_avg'])\n    rfm[\"expected_average_profit\"] = ggf.conditional_expected_average_profit(rfm['frequency'],\n                                                                             rfm['monetary_avg'])\n    # 6 months cltv_p\n    cltv = ggf.customer_lifetime_value(bgf,\n                                       rfm['frequency'],\n                                       rfm['recency_weekly_cltv_predicted'],\n                                       rfm['T_weekly'],\n                                       rfm['monetary_avg'],\n                                       time=6,\n                                       freq=\"W\",\n                                       discount_rate=0.01)\n\n    rfm[\"cltv_predicted\"] = cltv\n\n    # minmaxscaler\n    scaler = MinMaxScaler(feature_range=(1, 100))\n    scaler.fit(rfm[[\"cltv_predicted\"]])\n    rfm[\"cltv_predicted\"] = scaler.transform(rfm[[\"cltv_predicted\"]])\n\n    # rfm.fillna(0, inplace=True)\n\n    # cltv_predicted_segment\n    rfm[\"cltv_predicted_segment\"] = pd.qcut(rfm[\"cltv_predicted\"], 3, labels=[\"C\", \"B\", \"A\"])\n\n    ## recency_cltv_predicted, recency_weekly_cltv_predicted\n    rfm = rfm[[\"recency_cltv_predicted\", \"T\", \"monetary_avg\", \"recency_weekly_cltv_predicted\", \"T_weekly\",\n               \"expected_average_profit\",\"cltv_predicted\", \"cltv_predicted_segment\"]]\n\n\n    return rfm","d04a3d36":"rfm_cltv_predicted = create_cltv_predicted(df)\ncheck_df(rfm_cltv_predicted)","50298361":"rfm_cltv_predicted.head()","0d64dae1":"rfm_cltv_predicted.groupby('cltv_predicted_segment').agg('expected_average_profit').mean().plot(kind='bar', colormap='copper_r');\n\nplt.ylabel(\"profit\");","cb97e73a":"crm_final = rfm_cltv.merge(rfm_cltv_predicted, on=\"Customer ID\", how=\"left\")\ncheck_df(crm_final)","3cf1b845":"# will be effective in campaign decisions\n\ncrm_final.sort_values(by=\"monetary_avg\", ascending=False).head()","291ac91e":"# FINAL\n\nSo we can analyze each metric comparatively.\n\nWe can make different decisions for customers in different segments.\n\nWe can make different campaigns according to the decisions taken.\n\nAfter that, the productivity of the campaign can be measured by making different offers to the masses.","4c39723d":"# Naming & Analysing RFM Segments","222f9909":"# CLTV Preticted\n\n**What is a cohort model?**\n\nInstead of simply assuming all the customers to be one group, we can try to split them into multiple groups and calculate the CLTV for each group.\n\nNote: recency value customized. (One of the key differences between RFM and CLTV)\n\n**BG-NBD**\n\nIn short, expected sales value. Used to estimate how many purchases customers can make over a period of time\n\nThis method computes the probability that a customer with history (frequency, recency_weekly, T_weekly) is currently alive.(relationship between recency & frequency)\n\n**Gamma Gamma**\n\n-conditional expected number of purchases up to time-\n\nNote1: There should be no correlation between the frequency of transactions and their monetary value.\n\nNote2: We are considering only customers who made repeat purchases with the business i.e., frequency > 0. Because, if the frequency is 0, it means that they are a one-time customer and are considered already dead.","3abe2bf6":"# CLTV Calculated\n\nThis time we divided people into A, B, C segments. (Not to be confused with rfm segmentation.) Let's remember we do life-time value calculations.\n\nThe calculations in the table have been made.\n\nStandardization process was done for better understanding.","2ea68ff8":"# **CRM Analytics (RFM Analysis, CLTV Calculate, CLTV Prediction)**\n\n# What is CRM?\n\nCustomer relationship management (CRM) is the combination of practices, strategies and technologies that companies use to manage and analyze customer interactions and data throughout the customer lifecycle.CRM targets to gain new customers other than existing customers.With CRM software, the customer feels special, so dependency occurs for the company or product.In this study, we will create CRM by making RFM and then CLTV.\n\n# What is RFM?\n\nRFM represents a method used for measuring customer value. An RFM analysis can show you who are the most valuable customers for your business. The ones who buy most frequently, most often, and spend the most. First of all, the metrics you have seen are calculated.\n\n![image.png](attachment:c631cbc0-1fa1-46e3-89c1-68736c23d970.png)!\n\n**Recency:** The value that indicates how much time has passed since a customer's last activity or transaction with the brand. The activity is usually a purchase, but sometimes variations are used such as the last visit to a website or the use of a mobile app.\n\n**Frequency:** How often a customer shows in a certain period of activity value. Customers who operate more often may be more loyal than others.\n\n**Monetary:** It is the value that shows how much a customer has spent in a certain period of time. Dividing the value of the spend by frequency shows us the average purchase amount.\n\n# Dataset and Story\n\nAn e-commerce company wants to segment its customers and determine marketing strategies according to these segments. The company believes that marketing activities specific to customer segments that exhibit common behaviors will increase revenue. For example, it is desired to organize different campaigns for new customers and different campaigns to retain very profitable customers for the company.\n\nThe dataset named Online Retail includes the sales of a UK-based online store between 01\/12\/2009-09\/12\/2011. This company's product catalog includes souvenirs. The majority of the company's customers are corporate customers.\n\n**Variables of the data set:**\n\n* InvoiceNo : The number of the invoice, unique per each purchase. Refund invoice numbers contain \"C\"\n* StockCode : Unique code per each item\n* Description : Name of the item\n* Quantity : The number of items within the invoice\n* InvoiceDate : Date and time of the purchase\n* UnitPrice : Price of a single item, as of Sterlin\n* CustomerID : Unique id number per each customer\n* Country : The country where the customer is living\n\n**What is the purpose?**\n\nIn this notebook, we will create CRM by making RFM and then CLTV.","e85de4ca":"Check out descriptive statistics of numerical variables. See the difference between 75% and 99% values and then See the difference between 99% and max values. We can think that there are some outliers.","d9b3cbb2":"Missing values are deleted. Canceled Invoices are not received and and a new variable was created.","9f1a97e3":"# Creating RFM Metrics & Calculating RFM Scores","474a018e":"Variables are as follows after they are cleared of outliers values.","b9514184":"Then segments are created.\n\n**So why are we doing this?**\n\nWe look for answers to these questions;\n\n-Who is our most profitable customer? -What is it they appreciate in my products or services? -Who are my new customers? -How do I attract new customers to the company?\n\nThe answers to the questions are hidden in the segmentation.\n\nWith better RFM segmentation, we\u2019ll be able to address certain segments in a personalized manner, based on their needs and preferences.\n\nBrowse the scheme to more easily understand segmentation.\n\n![image.png](attachment:d17c2a27-2ecf-4a40-ad31-6c8920358b6a.png)","25a3ab7a":"# Load Dataset","a3ce2389":"# Data Preprocessing","b9752ee1":"# CRM","a928160b":"We segmented our RFM values with the qcut () function. The high recency value means that the customer gets away from us. For this reason, we made the labels decreasing in order to avoid confusion.","df84a54e":"In order to see the RFM values together, we defined a variable named \"RFM_SCORE\" and combined the RFM values by converting them to strings. If we tried to combine without converting, we might get an error because it would not combine the two categorical variables. (We do not include monetary_score)","7e203739":"# Customer Life Time Value\n\nCustomer lifetime value is how much money a customer will bring your brand throughout their entire time as a paying customer.It is the monetary value that a customer will give to a company during its relationship-communication with a company.\n\nIn fact, it is to be able to extract the future situation from the current situation of the customer.\n\nFor this we will first make a simple calculation and then we will add the time factor.","9922fc64":"Outlier values are trimmed (very little) without damaging the data.Here we have set a lower and upper limit. But since the lower limit is set, we'll only assign it to the upper limit. We'll do it for Quantity and Price."}}