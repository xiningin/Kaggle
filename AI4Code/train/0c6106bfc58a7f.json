{"cell_type":{"edfe342c":"code","b9ea4c52":"code","2af6f093":"code","2eba0153":"code","8b53c213":"code","a3a7a923":"code","5181cfa6":"code","71fd60da":"code","23d15cff":"code","ee891748":"code","29ab5093":"code","d978b557":"code","40c7a511":"code","44e61f50":"code","627ba791":"code","2cbb2ba6":"code","e2ab7961":"code","466fc853":"code","f14cc52c":"code","e74b7ec7":"code","49dae110":"code","4c2557f1":"markdown","cec72c48":"markdown","7d9b3968":"markdown","a6a9caaa":"markdown","f3d8c92d":"markdown","356da8dc":"markdown","8b509646":"markdown","910bfa4c":"markdown","275b4d54":"markdown","9b8c964b":"markdown"},"source":{"edfe342c":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nimport keras.layers as L","b9ea4c52":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)","2af6f093":"from kaggle_datasets import KaggleDatasets","2eba0153":"AUTO = tf.data.experimental.AUTOTUNE\nGCS_DS_Path = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_Path)","8b53c213":"IMAGE_SIZE = [224,224]\nGCS_PATH = GCS_DS_Path + '\/tfrecords-jpeg-224x224'","a3a7a923":"training_file = tf.io.gfile.glob(GCS_PATH+'\/train\/*.tfrec') \ntest_file = tf.io.gfile.glob(GCS_PATH+'\/test\/*.tfrec')\nvalid_file = tf.io.gfile.glob(GCS_PATH+'\/val\/*.tfrec')","5181cfa6":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0 \n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","71fd60da":"\ndef get_training_dataset():\n    dataset = load_dataset(training_file, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(valid_file, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(test_file, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset","23d15cff":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()","ee891748":"ds_iter = iter(ds_train.unbatch().batch(20))","29ab5093":"one_batch = next(ds_iter)","d978b557":"for i in range(1,20):\n    plt.subplot(4,5,i)\n    plt.imshow(one_batch[0][i],aspect='auto')","40c7a511":"def convblock(filter_size,is_block2=False):\n    model.add(L.Conv2D(filter_size,kernel_size=(3,3),padding='same',activation='relu'))\n    model.add(L.Conv2D(filter_size,kernel_size=(3,3),padding='same',activation='relu'))\n    if is_block2:\n        model.add(L.Conv2D(filter_size,kernel_size=(3,3),padding='same',activation='relu'))\n    model.add(L.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))","44e61f50":"weights = keras.utils.get_file('vgg16_weights','https:\/\/storage.googleapis.com\/tensorflow\/keras-applications\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels.h5')","627ba791":"with strategy.scope():\n    model = keras.Sequential()\n    model.add(L.InputLayer(input_shape=(224,224,3)))\n    convblock(64)\n    \n    convblock(128)\n    \n    convblock(256,is_block2=True)\n\n    convblock(512,is_block2=True)\n    \n    convblock(512,is_block2=True)\n    model.add(L.Flatten())\n    model.add(L.Dense(4096,activation='relu'))\n    model.add(L.Dense(4096,activation='relu'))\n    model.add(L.Dense(1000,activation='relu'))\n    model.load_weights(weights)\n    for Layers in model.layers:\n        Layers.trainable = False\n    model.add(L.Dense(104, activation='softmax')) # since our dataset have 104 classes","2cbb2ba6":"model.summary()","e2ab7961":"model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)","466fc853":"NUM_TRAINING_IMAGES = 12753\nNUM_TEST_IMAGES = 7382\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE","f14cc52c":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,steps_per_epoch=STEPS_PER_EPOCH\n)","e74b7ec7":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","49dae110":"print('Generating submission.csv file...')\n\n# Get image ids from test set and convert to unicode\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","4c2557f1":"# Model","cec72c48":"To make TFRecords dataset we will use TFRecordDataset Class available in tf.data module","7d9b3968":"<img src=\"https:\/\/miro.medium.com\/max\/2268\/1*CrjJwSX9S7f759dK2EtGJQ.png\">","a6a9caaa":"<p style=\"font-size:18px\">VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes.<\/p>","f3d8c92d":"<div style=\"font-size:20px\"><p>\nTensor Processing Units (TPUs) are Google\u2019s custom-developed application-specific integrated circuits (ASICs) used to accelerate machine learning workloads previous algorithm take took weeks to train on GPUs can even be trained in hours using TPUs.<\/p><p> We can use TPUs from cloud services like google cloud or for free from Kaggle or google colab In this tutorial we will see how can we use TPU on TFRecords. TFRecords is a file format optimized for TensorFlow that is used for storing a sequence of binary records. It is very useful for large dataset since only data that is required is loaded in batches<\/p>\n<\/div>","356da8dc":"# Preparing Data","8b509646":"Helper Function to make ConvBlock","910bfa4c":"# Refrences\n1. )https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission\n2. )https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/\n3. )https:\/\/cloud.google.com\/tpu\n4. )https:\/\/en.wikipedia.org\/wiki\/Tensor_Processing_Unit\n5. )https:\/\/medium.com\/mostly-ai\/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564 ","275b4d54":"To use TPU, we must load our data from GCS to that we need GCS path of our dataset which we can get using KaggleDatasets","9b8c964b":"# Importing Libraries"}}