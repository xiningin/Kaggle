{"cell_type":{"b1213b83":"code","71ccb5bf":"code","1323e9d3":"code","60560716":"code","5080cb85":"code","950b8d6a":"code","9a036785":"code","d9792195":"code","6ee4f5df":"code","9a316ec4":"code","ad12542d":"code","c3737d22":"code","4328fe4f":"code","a11451c4":"code","189f51f8":"markdown","b42b123c":"markdown","392d8309":"markdown","15f8b9e1":"markdown","b99f23fd":"markdown"},"source":{"b1213b83":"#importing libraries\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns","71ccb5bf":"#importing the dataset\nds = pd.read_csv(\"..\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv\")\nds.head()","1323e9d3":"#checking for null values\nds.isnull().sum()","60560716":"#defining dependent and independent vectors\n#taking only title for prediction\nx = ds.iloc[:,2:3]\ny = ds['label']","5080cb85":"ds['label'].value_counts()","950b8d6a":"#checking number of real and fake news\nsns.countplot(x = 'label',data = ds)","9a036785":"#Text Cleaning and preprocessing\n\ncleaned = []\nfor i in range(0,len(ds)):\n    \n    #removing words any other than (a-z) and (A-Z)\n    text = re.sub('[^a-zA-Z]',' ', x['tweet'][i])\n    \n    #converting all words into lower case\n    text = text.lower()\n    \n    #tokenizing \n    text = text.split()\n    \n    #stemming and removing stopwords\n    ps = PorterStemmer()\n    text = [ps.stem(words) for words in text if words not in stopwords.words('english')]\n    text = ' '.join(text)\n    cleaned.append(text)","d9792195":"#cleaned text\ncleaned[:5]","6ee4f5df":"#taking dictionary size 5000\nvocab_size = 5000\n\n#one hot encoding\none_hot_dir = [one_hot(words,vocab_size) for words in cleaned]\n\n#length of all rows should be equal therefore applying padding\n#this will adjust size by adding 0 at staring of the shorter rows\nembedded_layer = pad_sequences(one_hot_dir,padding = 'pre')\nembedded_layer","9a316ec4":"#converting into numpy arrays.\nx = np.array(embedded_layer)\ny = np.array(y)","ad12542d":"#splitting the Dataset into Train and Test set\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)","c3737d22":"from tensorflow.keras import regularizers\n#creating model using LSTM\nmodel = Sequential()\n\n#taking number features as 64\nmodel.add(Embedding(vocab_size,64,input_length = len(embedded_layer[0])))\n#model.add(Dropout(0.4))\n\n#adding LSTM layers with 128 neurons\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.4))\n\n#adding output layer \nmodel.add(Dense(1,activation=\"sigmoid\"))\n\n#compiling the model\nmodel.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n\n#summary of model\nmodel.summary()\n\n#training the model\nmodel.fit(x_train, y_train, validation_data = (x_test,y_test), epochs = 5, batch_size = 32)","4328fe4f":"#predicting and getting accuracy\ny_pred = model.predict(x_test)\ny_pred = (y_pred > 0.5)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","a11451c4":"#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","189f51f8":"# **SENTIMENT ANALYSIS USING LSTM**\n\nThe objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n\nFormally, given a training sample of tweets and labels, where label '1' denotes the tweet is racist\/sexist and label '0' denotes the tweet is not racist\/sexist, your objective is to predict the labels on the test dataset.","b42b123c":"\n**NO NULL VALUES FOUND**","392d8309":"**OUR MATRIX IS NOW READY FOR THE LSTM**","15f8b9e1":"**AS YOU CAN SEE O HAVE (~ 30000) VALUES AND 1 HAVE (~ 2500) VALUES**","b99f23fd":"**DATA IS NOW READY FOR ONE HOT ENCODING**\n\nOur motive here is to create an embedding layer of texts for the LSTM, OneHot encoding prepares our text array into a format required by embedding layer."}}