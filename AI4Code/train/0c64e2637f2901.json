{"cell_type":{"591c378a":"code","e6c101d3":"code","53205a30":"code","75616bc2":"code","560bb91c":"code","fd86e12d":"code","b0fd6ba7":"code","0befda88":"code","adbde02c":"code","d11b61c5":"code","f0ae3a3b":"code","7ca327d2":"code","9674d983":"code","41edb242":"code","fe856b25":"code","988bff88":"code","df2d538c":"code","3d6f2b1f":"code","fa08c7ff":"code","cd186e37":"code","e2043798":"code","06b29db8":"code","0c1d9d87":"code","ff5e10a7":"code","c0f36f9f":"code","bab1e0f9":"code","f2ed281b":"code","12484ffd":"code","0f522cf8":"code","c0d43d5e":"code","f2dedc1f":"code","6d0521f6":"code","ca1ba6f5":"code","4e2056f1":"code","afd07ce2":"markdown","100824a7":"markdown","ac4ae468":"markdown","ff8ab724":"markdown","e3dfe809":"markdown","124fed9b":"markdown","9517f542":"markdown","7c69f3c9":"markdown","04e97c71":"markdown","4c29d987":"markdown","d0ddb82c":"markdown","67f18459":"markdown","1bc58a35":"markdown"},"source":{"591c378a":"import pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('..\/input\/spam-ham\/spam.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","e6c101d3":"data=pd.read_csv('..\/input\/spam-ham\/spam.csv',encoding='latin-1')","53205a30":"data.head(10)","75616bc2":"data.tail(10)","560bb91c":"data.shape,data.describe()","fd86e12d":"import numpy as np\n#delete the columns with nan\ndata=data.dropna(axis=1)\n#data.replace(0, np.nan, inplace= True)\ndata.head(5)","b0fd6ba7":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()#creating the instance\ndata['class']=le.fit_transform(data['class'])\ndata.head()","0befda88":"print(len(data['message']))\nprint(data['class'].value_counts(normalize=True))","adbde02c":"from sklearn.feature_extraction.text import CountVectorizer\nv=CountVectorizer()\nmessages=v.fit_transform(data['message'])\nprint(messages.toarray())","d11b61c5":"messages.shape","f0ae3a3b":"import nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ncv=TfidfVectorizer()\nmessagess=cv.fit_transform(data['message']).toarray()\nprint(messagess)","7ca327d2":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(messages,data['class'],test_size=0.1)#countervectorizer\nX_train,X_test,Y_train,Y_test=train_test_split(messagess,data['class'],test_size=0.1)#tfidf vectorizer","9674d983":"from imblearn.over_sampling import RandomOverSampler","41edb242":"sampler = RandomOverSampler(sampling_strategy=0.5)\nx_over_train,y_over_train = sampler.fit_resample(x_train,y_train)#cv","fe856b25":"X_over_train,Y_over_train = sampler.fit_resample(X_train,Y_train)#tfidf","988bff88":"print('CounteVectoriser:\\nBefore sampling:\\n',y_train.value_counts())\nprint()\nprint('After Sampling :\\n',y_over_train.value_counts())\nprint(\"\\n \\nTFIDF Vectoriser:\\n Before sampling:\\n\",Y_train.value_counts())\nprint()\nprint('After Sampling :\\n',Y_over_train.value_counts())","df2d538c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report","3d6f2b1f":"log_reg=LogisticRegression()\nlog_reg.fit(x_train,y_train)#cv\nlog_reg.fit(X_train,Y_train)#tfidf\ny_pred_lr=log_reg.predict(x_test)#cv\nY_pred_lr=log_reg.predict(X_test)#tfidf\nprint(\"Count vectoriser:\\n\")\nprint(confusion_matrix(y_test,y_pred_lr))\nprint(classification_report(y_test,y_pred_lr,digits=5))\nprint(\"\\n\\nTFIDF:\\n\")\nprint(confusion_matrix(Y_test,Y_pred_lr))\nprint(classification_report(Y_test,Y_pred_lr,digits=5))","fa08c7ff":"log_reg_over=LogisticRegression()\nlog_reg_over.fit(x_over_train,y_over_train)#cv\nlog_reg_over.fit(X_over_train,Y_over_train)#tfidf\ny_pred_lr=log_reg_over.predict(x_test)\nY_pred_lr=log_reg_over.predict(X_test)\nprint(\"CountVectoriser:\\n\")\ncm_cv=confusion_matrix(y_test,y_pred_lr)\nprint(cm_cv)\nprint(classification_report(y_test,y_pred_lr,digits=5))\nprint(\"\\n\\nTFIDF:\\n\")\ncm_tfidfv=confusion_matrix(Y_test,Y_pred_lr)\nprint(cm_tfidfv)\nprint(classification_report(Y_test,Y_pred_lr,digits=5))","cd186e37":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.heatmap(cm_cv,annot=True)","e2043798":"sns.heatmap(cm_tfidfv,annot=True)","06b29db8":"from sklearn.metrics import accuracy_score\nLR=accuracy_score(Y_test,Y_pred_lr)\nprint(LR)","0c1d9d87":"from sklearn.naive_bayes import MultinomialNB\nNB_classifier =MultinomialNB()\nNB_classifier.fit(X_over_train , Y_over_train)\ny_pred_nb = NB_classifier.predict(X_test)","ff5e10a7":"Y_test.head(),y_pred_nb[0:5]","c0f36f9f":"cm=confusion_matrix(Y_test,y_pred_nb)\nprint(cm)\nprint(classification_report(Y_test,y_pred_nb,digits=5))","bab1e0f9":"sns.heatmap(cm,annot=True)","f2ed281b":"NB=accuracy_score(Y_test,y_pred_nb)\nprint(NB)","12484ffd":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X_over_train,Y_over_train)\ny_pred_dt = model.predict(X_test)","0f522cf8":"Y_test.head(),y_pred_dt[0:5]","c0d43d5e":"cm=confusion_matrix(Y_test,y_pred_dt)\nprint(cm)\nprint(classification_report(Y_test,y_pred_dt,digits=5))","f2dedc1f":"sns.heatmap(cm,annot=True)","6d0521f6":"DT=accuracy_score(Y_test,y_pred_dt)\nprint(DT)","ca1ba6f5":"print(\"Accuracy :\\n (a) logistic regression : \"+str(LR)+\"\\n (b) Decision Tree : \"+str(DT)+\"\\n (c) Naive bayes : \"+str(NB))\n","4e2056f1":"if((DT>LR) and (DT>NB)):\n    print(\"Decision tree algorithm is much accurate than other two algorithm ie, accuracy(dt)=\"+str(DT))\nelif((LR>DT) and (LR>NB)):\n    print(\"Logistic Regression algorithm is much accurate than other two algorithm ie, accuracy(lr)=\"+str(LR))\nelse:\n    print(\"Naive bayes algorithm is much accurate than other two algorithm ie, accuracy(nb)=\"+str(NB))","afd07ce2":"# Decision tree","100824a7":"accuracy=(TP+TN)\/Total   \n        \nPrecision=TP\/(TP+FP)\n\nRecall=TP\/(TP+FN)\n      \nF1-Score=2*Precision*Recall\/(Precision+Recall)","ac4ae468":"# CountVectorizer","ff8ab724":"### After Over Sampling","e3dfe809":"### Before  over sampling","124fed9b":"# logistic regression","9517f542":"### Oversampling","7c69f3c9":"## TFIDF (Term Frequency and Inverse Document Frequency)","04e97c71":"# train test split","4c29d987":"Term Frequency=(No. of rep of words in sentence)\/(No. of words in sentence)\nIDF=(No. of sentences)\/(No. of sentences containing words)","d0ddb82c":"# Naive bayes ","67f18459":"# accuracy of all the model","1bc58a35":"# label encoding"}}