{"cell_type":{"d0727d37":"code","d5b6f24e":"code","5d798b73":"code","c7d0a570":"code","c5a86f0f":"code","5455fc28":"code","72bff6db":"code","ae468a76":"code","74ae8758":"code","4e87a034":"code","6b82265a":"code","51f2b09d":"code","77698b3c":"code","7b25b2ff":"code","51d362f3":"code","74cc73b0":"code","a02679bf":"code","e2767d87":"code","b4e3015f":"code","72c27ebf":"code","55e8887f":"code","7716d321":"code","16b41bce":"code","365413d0":"code","bc5ff7c6":"code","8b89d68f":"code","d2f33817":"code","32400638":"code","54c5a84b":"code","6eaedb65":"code","f23893e2":"code","974ac65f":"code","4ca83636":"code","2489843b":"code","a70bad33":"code","1da0c5bd":"code","df1ff858":"code","4ca6ef05":"code","8ad44f35":"code","c1793115":"code","c6ddd715":"code","0c08e979":"code","24886278":"code","a28967e9":"code","15a2f70f":"code","667df8df":"code","3cdc90aa":"code","b5e64835":"code","c18e1017":"code","e392bbad":"code","18819aa0":"code","a8c5116d":"code","6000ff9e":"code","df384e1e":"code","20d23a40":"code","a45de71f":"code","79686e11":"code","4fe76b65":"code","181ee946":"code","defe599b":"code","b24d2fb7":"code","5c91552a":"code","28b00cf9":"code","e1b531f1":"code","179adc3f":"code","247169ae":"code","29054dc5":"code","0ae9550f":"code","c30df314":"code","448f0bd9":"code","85c79e67":"code","a2a2a8fc":"code","08c8508a":"markdown","4006ae6a":"markdown","d7f5a30f":"markdown","89d076b9":"markdown","f8f85446":"markdown","761ed9d8":"markdown","cf843e5c":"markdown","64dbabe5":"markdown","b69a31dc":"markdown","e0ffce7e":"markdown","8a6036ac":"markdown","113e2479":"markdown","81fae1ff":"markdown","c416716c":"markdown","3761b246":"markdown","843d425a":"markdown","f28cabdd":"markdown","18609c58":"markdown","66c2b97a":"markdown","dda4d15b":"markdown","39c2a4bc":"markdown","c5456756":"markdown","7e452176":"markdown","85958c5c":"markdown","089a73eb":"markdown","61fc62e7":"markdown","2a62bf43":"markdown","85bfd557":"markdown","7fa039d8":"markdown","a4c3e790":"markdown","ab9db0e3":"markdown","ad121a81":"markdown","69762f26":"markdown","05bca952":"markdown","3538d998":"markdown","8b95c96a":"markdown","f2ecc3aa":"markdown","8fd08c21":"markdown","228eb811":"markdown","72fec6d6":"markdown","3f3c2a52":"markdown","a60c1fd2":"markdown","166b4168":"markdown","95ff2e98":"markdown","cccb981d":"markdown","c8fd31ce":"markdown","19d51941":"markdown","e6498f41":"markdown","7526d079":"markdown","86384a96":"markdown","55b38940":"markdown","aa76aece":"markdown","a366edb9":"markdown","b4cfbc2e":"markdown","9289c4fe":"markdown","cc28aa33":"markdown","8b278ba3":"markdown","d93bf41f":"markdown","f351e3eb":"markdown","d8614925":"markdown","8023a416":"markdown","2c0da895":"markdown","f4205aee":"markdown","f1c14923":"markdown","693cc403":"markdown","2f6ef68d":"markdown","7da9a99f":"markdown","6a07f01a":"markdown","b228dc77":"markdown","79ebc009":"markdown","6b31b286":"markdown","1a40a287":"markdown","4b2e60a1":"markdown","470d1b24":"markdown","b8bbb18f":"markdown","557791a1":"markdown","d748e8f8":"markdown","ca674057":"markdown","08afce25":"markdown","d1b21710":"markdown"},"source":{"d0727d37":"pip install treeinterpreter","d5b6f24e":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#from statsmodels.graphics import tsaplots\n#import statsmodels.api as sm\nimport seaborn as sns\nimport numpy as np\n#import calendar\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import r2_score, mean_squared_error as MSE\n#from scipy.stats import spearmanr, pearsonr\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom scipy.cluster import hierarchy as hc\nimport scipy\nfrom treeinterpreter import treeinterpreter as ti\nfrom collections import Counter","5d798b73":"plt.style.use('fivethirtyeight')","c7d0a570":"df =  pd.read_excel('..\/input\/Absenteeism_at_work_new.xls')","c5a86f0f":"df.info()","5455fc28":"df.columns = df.columns.str.replace('\/', 'per').str.strip()","72bff6db":"df.groupby('ID')[['ID']].count().head()","ae468a76":"len(df.columns)","74ae8758":"df.shape","4e87a034":"df.head()","6b82265a":"df['Social drinker'] = df['Social drinker'].astype('bool')\ndf['Social smoker'] = df['Social smoker'].astype('bool')\ndf['Disciplinary failure'] = df['Disciplinary failure'].astype('bool')\ndf['Seasons'] = df['Seasons'].astype('category')\ndf['Education'] = df['Education'].astype('category')\ndf['Day of the week'] = df['Day of the week'].astype('category')\ndf['Month of absence'] = df['Month of absence'].astype('category')\ndf['Reason for absence'] = df['Reason for absence'].astype('category')","51f2b09d":"df.info()","77698b3c":"df.isnull().sum()","7b25b2ff":"df['Absenteeism time in hours'].describe","51d362f3":"df[df['Month of absence']==0]","74cc73b0":"df[df['Reason for absence']==27][['Absenteeism time in hours']].mean()","a02679bf":"df.loc[(df['Reason for absence']==27) & (df['Absenteeism time in hours']==0),'Absenteeism time in hours']=3","e2767d87":"df.loc[(df['Absenteeism time in hours']==0),'Absenteeism time in hours']=8","b4e3015f":"len(df[df['Absenteeism time in hours']==8])","72c27ebf":"season_mapping = {1:'Summer', 2:'Autumn', 3:'Winter', 4:'Spring'}\ndf['season_name'] = df.Seasons.map(season_mapping)\ndf['season_name'] = df['season_name'].astype('category')\ndf.drop_duplicates(['Seasons', 'season_name'])[['Seasons','season_name']]","55e8887f":"import calendar\ndf['month_name'] =  df['Month of absence'].apply(lambda x: calendar.month_abbr[x])","7716d321":"reason_mapping = {\n    0: 'Unknown',\n    1: 'Certain infectious and parasitic diseases',\n    2: 'Neoplasms',\n    3: 'Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism',\n    4: 'Endocrine, nutritional and metabolic diseases',\n    5: 'Mental and behavioural disorders',\n    6: 'Diseases of the nervous system',\n    7: 'Diseases of the eye and adnexa',\n    8: 'Diseases of the ear and mastoid process',\n    9: 'Diseases of the circulatory system',\n    10: 'Diseases of the respiratory system',\n    11: 'Diseases of the digestive system',\n    12: 'Diseases of the skin and subcutaneous tissue',\n    13: 'Diseases of the musculoskeletal system and connective tissue',\n    14: 'Diseases of the genitourinary system',\n    15: 'Pregnancy, childbirth and the puerperium',\n    16: 'Certain conditions originating in the perinatal period',\n    17: 'Congenital malformations, deformations and chromosomal abnormalities',\n    18: 'Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified',\n    19: 'Injury, poisoning and certain other consequences of external causes',\n    20: 'External causes of morbidity and mortality',\n    21: 'Factors influencing health status and contact with health services',\n    22: 'Patient follow-up',\n    23: 'Medical consultation',\n    24: 'Blood donation',\n    25: 'Laboratory examination',\n    26: 'Unjustified absence',\n    27: 'Physiotherapy',\n    28: 'Dental consultation'\n}\ndf['reason_text'] = df['Reason for absence'].map(reason_mapping)","16b41bce":"education_mapping = {\n    1: 'High School',\n    2: 'Graduate',\n    3: 'Post Graduate',\n    4: 'Master & Doctor'\n}\neducation_list = {'High School', 'Graduate', 'Post Graduate', 'Master & Doctor'}\ndf['Education_detail'] = df['Education'].map(education_mapping)\n#df['Education_detail'] = df['Education_detail'].astype('category')\ncategory_education = pd.api.types.CategoricalDtype(categories=education_list, ordered=True)\ndf['Education_detail'] = df['Education_detail'].astype(category_education)","365413d0":"df.head()","bc5ff7c6":"age_count = df.groupby(['Age']).agg({'ID': pd.Series.nunique})\nax = age_count.plot(kind='bar', figsize=(10,4), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(age_count.values):\n    ax.text(i-.24, v +0.2, str(v[0]), color='firebrick')\nax.set_xlabel('Age')\nax.set_ylabel('Count of employees')\nax.set_title('Agewise count of employees')\nplt.show()","8b89d68f":"edu_count = df.groupby(['Education_detail']).agg({'ID': pd.Series.nunique})\nax = edu_count.plot(kind='bar', figsize=(8,5), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(edu_count.values):\n    ax.text(i-.065, v + 0.8, str(v[0]), color='firebrick')\nax.set_xlabel('Education')\nax.set_ylabel('Count')\nax.set_title('Educationwise count of employees')\nplt.show()","d2f33817":"age_work_sum = df.groupby('Age', as_index=False)[['Work load Averageperday']].mean()\nax = age_work_sum.plot(kind='bar', x='Age', figsize=(8,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\nax.set_ylabel('Work load average per day')\nax.set_title('Average work load per day by age')\nplt.show()","32400638":"age_abs = df.groupby('Age')[['Absenteeism time in hours']].mean()\nax = age_abs.plot(kind='bar', figsize=(8,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(age_abs.values):\n    ax.text(i-.25, v + 0.2, str(np.int(np.round(v))), color='firebrick')\nax.set_ylabel('Absenteeism time in hours')\nax.set_title('Average Absenteeism time in hours by age')\nplt.show()","54c5a84b":"dis_abs = df.groupby('Distance from Residence to Work')[['Absenteeism time in hours']].mean()\nax = dis_abs.plot(kind='bar', figsize=(8,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(dis_abs.values):\n    ax.text(i-.25, v + 0.1, str(np.int(np.round(v))), color='firebrick')\nax.set_xlabel('Distance from Residence to Work (km)')\nax.set_ylabel('Absenteeism time in hours')\nax.set_title('Average Absenteeism time in hours by distance')\nplt.show()","6eaedb65":"age_dis = df.groupby('Age')[['Distance from Residence to Work']].mean()\n\nax = age_dis.plot(kind='bar', figsize=(8,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\n\nfor i, v in enumerate(age_dis.values):\n    ax.text(i-.28, v + 1, str(np.int(np.round(v))), color='firebrick')\nax.set_ylabel('Distance from Residence to Work')\nax.set_title('Average Distance from Residence to Work by age')\nplt.show()","f23893e2":"dis_exp = df.groupby('Distance from Residence to Work')[['Transportation expense']].mean()\nax = dis_exp.plot(kind='bar', figsize=(10,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(dis_exp.values):\n    ax.text(i-.45, v + 8, str(np.int(np.round(v))), color='firebrick')\nax.set_ylabel('Transportation expense')\nax.set_title('Average Transportation expense by distance to work')\nplt.show()","974ac65f":"ax = df.groupby('Age')['Son', 'Pet'].sum().plot(figsize=(8,6))\nax.set_ylabel('Count')\nax.set_title('Count of Pet & Son by Age')\nplt.show()","4ca83636":"# % of Social drinker those are smokers\nemp_social = df.drop_duplicates(['ID', 'Social drinker', 'Social smoker'])[['ID', 'Social drinker', 'Social smoker']]\nemp_social[emp_social['Social drinker']==True]['Social smoker'].mean()","2489843b":"# % of Social smokers are drinkers\nemp_social[emp_social['Social smoker']==True]['Social drinker'].mean()","a70bad33":"drink_sum = df[(df['Social drinker'] == True) & (df['Social smoker']==False)]['Absenteeism time in hours'].sum()\nsmok_sum = df[(df['Social drinker'] == False) & (df['Social smoker']==True)]['Absenteeism time in hours'].sum()\ndrink_smok_sum = df[(df['Social drinker'] == True) & (df['Social smoker']==True)]['Absenteeism time in hours'].sum()\nabs_sum = df[(df['Social drinker'] == False) & (df['Social smoker']==False)]['Absenteeism time in hours'].sum()\nabsen = [drink_sum, smok_sum, drink_smok_sum, abs_sum]\npie_labels = ['drinker', 'smoker', 'drinker & smoker', 'No drinker\/smoker']\nfig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(aspect=\"equal\"))\n\ndef func(pct, allvals):\n    absolute = int(pct\/100.*np.sum(allvals))\n    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n\nwedges, texts, autotexts = ax.pie(absen, autopct=lambda pct: func(pct, absen), textprops=dict(color='w'))\nax.legend(wedges, pie_labels, title='Social Drinkers\/Smokers', loc='right', bbox_to_anchor=(1, 0, 0.5, 1))\nplt.setp(autotexts, size=10, weight=\"bold\")\nax.set_title('Absenteeism by Social Drinkers\/Smokers')\n#plt.pie(absen, labels=pie_labels)\nplt.show()\n","1da0c5bd":"reason_abs = df.groupby('reason_text', as_index=False)['Absenteeism time in hours'].sum()\nwith pd.option_context('display.max_colwidth', -1):\n    display(reason_abs.sort_values('Absenteeism time in hours', ascending=False).style.hide_index())","df1ff858":"season_abs = df.groupby('season_name')['Absenteeism time in hours'].sum()\nax = season_abs.plot(kind='bar', figsize=(8,5), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(season_abs.values):\n    ax.text(i-.12, v + 22, str(np.int(np.round(v))), color='firebrick')\nax.set_xlabel('Seasons')\nax.set_ylabel('Sum of Absenteeism hours')\nax.set_title('Sum of Absenteeism hours by Seasons')\nplt.show()","4ca6ef05":"month_abs = df.groupby('month_name')['Absenteeism time in hours'].sum()\nax = month_abs.plot(kind='bar', figsize=(8,6), legend=False, color=\"navajowhite\",edgecolor='darkred')\nfor i, v in enumerate(month_abs.values):\n    ax.text(i-0.3, v + 12, str(np.int(np.round(v))), color='firebrick')\nax.set_xlabel('Month')\nax.set_ylabel('Sum of Absenteeism hours')\nax.set_title('Sum of Absenteeism hours by Month')\nplt.show()","8ad44f35":"mar_abs = df[df['Month of absence']==3].groupby('reason_text', as_index=False)['Absenteeism time in hours'].sum()\nwith pd.option_context('display.max_colwidth', -1):\n    display(mar_abs.sort_values('Absenteeism time in hours', ascending=False).style.hide_index())","c1793115":"jul_abs = df[df['Month of absence']==7].groupby('reason_text', as_index=False)['Absenteeism time in hours'].sum()\nwith pd.option_context('display.max_colwidth', -1):\n    display(jul_abs.sort_values('Absenteeism time in hours', ascending=False).style.hide_index())","c6ddd715":"df.head()","0c08e979":"bins = [25, 35, 45, 55, np.inf]\nnames = [25, 35, 45, 55]\ndf['age_range'] = pd.cut(df['Age'], bins, labels=names)","24886278":"abs_bins = [0, 4, np.inf]\nabs_names = ['0', '1']\ndf['abs_range'] = pd.cut(df['Absenteeism time in hours'], abs_bins, labels=abs_names)","a28967e9":"df_features = df[['Reason for absence', 'Month of absence', 'Day of the week', 'Transportation expense', \n        'Distance from Residence to Work', 'Service time', 'age_range', 'Work load Averageperday', 'Hit target',\n        'Disciplinary failure', 'Son', 'Pet', 'Weight', 'Height', 'Body mass index']]","15a2f70f":"df_features.head()","667df8df":"X = df_features\ny = df['abs_range']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","3cdc90aa":"from sklearn.naive_bayes import GaussianNB \ngnb = GaussianNB() \ngnb.fit(X_train, y_train) \n  \ny_pred_nb = gnb.predict(X_test) \n  \nprint(classification_report(y_test, y_pred_nb))","b5e64835":"from sklearn.ensemble import AdaBoostClassifier\n\nclf = AdaBoostClassifier(n_estimators=20)\nclf.fit(X_train, y_train)\n\ny_pred_adb = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred_adb))","c18e1017":"model = RandomForestClassifier(n_estimators=20, random_state=0, n_jobs=-1)\nmodel.fit(X_train,y_train)\n\ny_pred_rf = model.predict(X_test)\n\nprint(classification_report(y_test, y_pred_rf))","e392bbad":"ax = (pd.Series(model.feature_importances_, index=X.columns)\n   .nlargest(19)\n   .plot(kind='barh', figsize=(8,6), color='navajowhite',edgecolor='darkred'))\nplt.show()","18819aa0":"from sklearn.model_selection import RandomizedSearchCV\nn_estimators = [int(x) for x in np.linspace(start=100, stop = 2000, num = 20)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_sample_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators' : n_estimators,\n               'max_features' : max_features,\n               'max_depth' : max_depth,\n               'min_samples_split' : min_samples_split,\n               'min_samples_leaf': min_sample_leaf,\n               'bootstrap' : bootstrap\n              }\n\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv=5, error_score= np.nan, \n                               verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_train, y_train)","a8c5116d":"# The below will provide us the best parameters from the Random Search CV.\n\nrf_random.best_params_","6000ff9e":"from sklearn.ensemble import RandomForestClassifier\nmodel_random = rf_random.best_estimator_\nmodel_random.fit(X_train, y_train)\npredictions_random = model_random.predict(X_test)","df384e1e":"print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions_random))","20d23a40":"print(classification_report(y_test, predictions_random))","a45de71f":"metrics.f1_score(y_test, predictions_random, average='micro')","79686e11":"from collections import Counter","4fe76b65":"Counter(y_train)","181ee946":"Counter(y_test)","defe599b":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'bootstrap' : [True],\n    'max_depth' : [8, 10, 12, 14],\n    'max_features' : ['sqrt'],\n    'min_samples_leaf' : [1, 3, 4],\n    'min_samples_split' : [7, 10, 12],\n    'n_estimators' : [250, 275, 300, 325]\n    \n}\n\nrf = RandomForestClassifier()\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv=5, n_jobs = -1, error_score=np.nan, verbose = 2)\n\ngrid_search.fit(X_train, y_train)","b24d2fb7":"grid_search.best_params_","5c91552a":"from sklearn.ensemble import GradientBoostingClassifier\nmodel_grid = grid_search.best_estimator_\nmodel_grid.fit(X_train, y_train)\npredictions_grid = model_grid.predict(X_test)","28b00cf9":"print(classification_report(y_test, predictions_grid))","e1b531f1":"row = X_test.values[None, 0]\nrow","179adc3f":"prediction, bias, contributions = ti.predict(model, row)","247169ae":"prediction[0], bias[0]","29054dc5":"print(model.predict_proba(row))","0ae9550f":"model.classes_ ","c30df314":"print(model.predict(row))","448f0bd9":"for c, feature in zip(contributions[0], X.columns):\n    print (feature, c)","85c79e67":"# Let us sum the contributions for this row.\n\nprint(contributions.sum(axis=1))","a2a2a8fc":"with np.printoptions(precision=3, suppress=True):\n    print(contributions.sum(axis=1) + bias[0])","08c8508a":"> The above results shows that this dataset is not a regular attendence dataset. This dataset only has absent hours of the employees for the period.\n\n> First step in the cleaning of the dataset is to change the appropriate data types of the columns.","4006ae6a":">How much percentage of Social Drinkers are Social Smokers also?","d7f5a30f":">The above will have Season Name along with Season and the below command will have Month names.","89d076b9":">We have the bias from the trainset, let us add the above contributions to the bias.","f8f85446":"### 2.10 Absenteeism by Social habits","761ed9d8":"# 2. Exploratory Data Analysis","cf843e5c":"### 2.15 July month Absenteeism hours by Reason","64dbabe5":"### 2.14 March month Absenteeism hours by Reason","b69a31dc":">The hypothesis i have was that if the distance to work increase the absenteeism hours will increase. But the below graph nullifies my hypothesis.","e0ffce7e":">Let us check the employee counts by Age. Notice one minor hack to count the unique IDs. As the employee count are almost similar, we are not able to decipher much.","8a6036ac":">The below table shows the highest Abseenteeism hours to lowest by Reason. The data is from courier company and the employees needs to deliver the packages and the Top 2 reason for absence shows that.\nThere is one hack to hide the index column.","113e2479":">Looks like 60% of Social drinkers are absent and interestingly 32% of Non-smoker & Non-drinker are also absent.","81fae1ff":">The above value shows that there are less values in the test\/validation set.\n\n>The random search gives us the range of the values and using that We can do the Grid Search to tune the model with exact parameters.","c416716c":"### 2.2 Educationwise Employee Count","3761b246":"### 2.4 Average Absenteeism hours by Age","843d425a":">After adding new columns for the reference columns, let us quickly check the first 5 rows from the dataset.","f28cabdd":">The most common problem we have is to justify the predictions. Why the model has predicted in a way? otherwise it is alwo known as blackbox.\n\n>This challenge can be solved easily in the Random Forest by the beautiful python package TreeInterpreter\n\n>Let us take one row and try to predict & interpret.","18609c58":">Let us check the prediction & bias values.","66c2b97a":"> Let us check the train & test data for each classification.","dda4d15b":">As per the classes above, the prediction is <4 for the selected row. Let us check that also","39c2a4bc":"> After changing the datatype of few columns you can notice the size of the dataset reduced from 122KB to 84KB.\nThe next step is to check whether there is any missing values in the dataset.","c5456756":"### 2.11 Absenteeism by Reason","7e452176":">AdaBoost Classifier","85958c5c":"# 4. Interpreting the Model","089a73eb":">Let us use the above model to predict & evaluate.","61fc62e7":">RandomForest Classifier","2a62bf43":">Another hypothesis I had was that higher age employees might stay closer to the office. It might be true till the Age 33, but the other values are not significant to compare.","85bfd557":"# 5. Conclusions\n","7fa039d8":"### 2.7 Average Transportation expense by Distance","a4c3e790":"# 3. Train and Test Split","ab9db0e3":"> Allows decomposing each prediction into `bias` and `feature contribution` components as described in http:\/\/blog.datadive.net\/interpreting-random-forests\/","ad121a81":"X = df_features\ny = df['Absenteeism time in hours']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","69762f26":">Most importantly we have to see the contributions for each feature. The below list clearly shows the contributions for all the 4 classes.","05bca952":">Looks like the March month & July month reasons are not matching.","3538d998":"# 1. Import and Clean Data\n>The first step is to import and clean the data for analysis. The process of cleaning might vary based on the quality and size of the dataset.","8b95c96a":">How much percentage of Social Smokers are Social Drinkers also?","f2ecc3aa":">This is the challenge in the small dataset. We changed the target variable as Classification\n\n>The target variable is Absenteeism in hours. Let us change to classification, so the multiclass variable is '=<4' as '0' and '>4' as '1'. This is just random assumption that employee absence can be half day, full day or more......","8fd08c21":">Looks like winter has highest Absenteeism.","228eb811":"> Let us check the data quickly to understand the contents. ID is the unique employee id in the dataset. The below command returns the count of rows for each ID from the dataset.","72fec6d6":"### 2.3 Average work load by Age","3f3c2a52":">Hyper parameter tuning is a process is to change the parameters of the model and identify which parameter gives us the better accuracy. The cross validation in Grid & Random Search helps us to use Stratified K-fold to create validation set within trained data. The CV value 5 or above uses Stratified K-fold.","a60c1fd2":"# **Classification based predictive model for absenteeism of employees at work**","166b4168":"### **GridSearch**","95ff2e98":"### 2.1 Agewise Employee Count","cccb981d":"> Now let us check the invalid values in the target variable.","c8fd31ce":"## 1.1 Manually setting up the data types of certain variables for EDA purpose","19d51941":">To check the prediction of the Tree Interpreter, let us predict for the same feature using Random Forest model. Here we are using prediction probability to compare the values.","e6498f41":">Absenteeism seems to be same across Age except for one age.","7526d079":">After using the FeatureImportance attribute of RandomForest, We removed four columns from df_features that are Season, Social_smoker, Social Drinker, Education ","86384a96":">Gaussian Naive Bayes Classifier","55b38940":">The below graph shows that the employees who has Son are mostly having a pet. This is interesting.","aa76aece":"### 2.9 Smoker & Drinker Stats","a366edb9":"### 2.13 Absenteeism hours by Month","b4cfbc2e":"### **RandomSearchCV**","9289c4fe":">After updating the value for the above row, now we can update Absenteeism in hours as 8 for all the rows with Disciplinary failure.","cc28aa33":"> The above results shows that this dataset has just 740 rows with the size of 122 KB. One of the column \"Work load Average\/day\" has forward slash and we are replacing to avoid unnecessary errors in future.","8b278ba3":">The transportation expense is not increasing by distance but we don't have transport mode, so this is not helping us.","d93bf41f":"### 2.8 Pet & Son counts by Age","f351e3eb":">Getting to detail from Seasons to Month, Looks like March & July has the highest number of Absenteeism hours.","d8614925":"* Employees with low performance cause a vital lose for organizations and the absenteeism consider to be one of the factors that affect performance So, understanding the causes of absenteeism may power the organization with a competitive advantages tool and open the area of research for computer and human resources fields. \n* The aim of this analysis is to discover the factors and causes of employees absence using computerized technologies.\n* Original dataset is available at https:\/\/archive.ics.uci.edu\/ml\/datasets\/Absenteeism+at+work\n\n![Employees](http:\/\/bbrc.in\/bbrc\/wp-content\/uploads\/2019\/02\/fig1_opt-7.jpeg)","8023a416":"# 3.4 Hyper Parameter tuning with Cross Validation","2c0da895":">We performed some data cleaning in excel which are not specified here\n\n>But if you need the cleaned dataset use this one =>=>=> https:\/\/www.kaggle.com\/miracle9to9\/absenteeism-dataset","f4205aee":"### ***Feature Importance (Important of features that recognised by the RF model)***\n>This is one way of interpreting the Random Forest Model and we can see the contributions from the features. This is at high level we can understand the importance of features.","f1c14923":"> The above reason is available in the UCI data description document and the below will update the education.","693cc403":"### 2.5 Average Absenteeism hours by Distance to work","2f6ef68d":">The work load seems to be same irrespective of the age.","7da9a99f":">Let us check the March month reason.","6a07f01a":">The Tree interpreter values and the model's prediction probability matches and the 4th class has the highest value. Now let us check the classess from the model.","b228dc77":"> We can see the mean value for Reason 27 and let us update Absenteeism hours as 3 for this row.","79ebc009":"> The below graph shows that High School educated employees are higher than the rest.","6b31b286":"### 2.6 Average distance to work by Age","1a40a287":"# 3.3 ML Model\n>Let us split the data","4b2e60a1":">Thank You","470d1b24":">The above matches with earlier prediction probabilities from the model. Now we know exactly the why the model has predicted the 4th class <4.","b8bbb18f":">Let us predict using Tree Interpreter for the above feature. The Tree Interpreter provides us the prediction, bias of the trainset & contributions to prediction for each feature. I have used the initial model and we can use any model.\n","557791a1":"> =>From this analysis company should predominantly focus on employees who are marking high absenteeism (represented with '>4' or class'1' in an analysis) which is major cause of business loss.\n\n> =>Organisation can consider following points for improvement:-\n> 1. Arrange health camps as health issues are observed amongst employees\n> 2. Provide paid leaves, Encash leaves.\n> 3. Rented accomodation for employees who are living far.\n> 4. Grant excess compensation for overtime and more....","d748e8f8":"> Looks like there is no missing value in the dataset. Now we have to check the valid values in the dataset. There is no specific logic to this process. If there is any datetime value, need to check invalid date time values. If there are numeric values, need to check the outliers. Check the distribution of values etc.,","ca674057":">After checking the zero values in Absenteeism in hours column, let us get ready for Exploratory Data Analysis. It's better to add additional columns for visualization as this dataset has only numeric values.","08afce25":"### 2.12 Absenteeism hours by Seasons","d1b21710":">After using the FeatureImportance atttribute of RF Classifier we removed four columns from our df_features they are season, social_smoker, social_drinker, eduaction to increase accuracy."}}