{"cell_type":{"14d9c0f0":"code","6fd42f60":"code","0013dfae":"code","697ad1fd":"code","a5d6ac51":"code","5335f9ae":"code","74885df7":"code","ad142712":"code","8fe38540":"code","f4fd1e72":"code","3ecd36f0":"code","2ddb455b":"code","856dc7bb":"code","6908c5a7":"code","91fe1e12":"code","9d72ed86":"code","a1c370f2":"code","e277d942":"code","f57d1889":"code","19b8b9ef":"code","f945682e":"code","df8f9b4e":"code","68fbd256":"code","d9a9ff40":"code","4ea8e9e9":"code","4f97bb5b":"code","e5e23ca1":"code","3125ec11":"code","0caa015c":"code","c53d73a0":"code","baf3744d":"code","f1083adf":"code","6e8d5766":"code","0afb4f79":"code","0031b859":"code","dc4f9bf1":"code","23bd8712":"code","5e0d9989":"code","e82ba2cc":"code","e9b2760e":"code","e1fc6002":"code","4b08ebc0":"code","03ff6198":"code","c307f47d":"code","37af6d04":"code","da07a077":"code","27b6466f":"code","1b1c3b84":"code","a217e6e4":"code","412415cb":"code","ca7d2e8b":"code","b84f941f":"code","ec53af9d":"code","5a41c50c":"code","db89a7a4":"code","dfcee98f":"markdown","2e643cf6":"markdown","548f496f":"markdown","5562f62f":"markdown","1887130a":"markdown","dab6ee4f":"markdown","179a9253":"markdown","3583ed46":"markdown","01d97a2c":"markdown","ed5646b0":"markdown","60825565":"markdown"},"source":{"14d9c0f0":"!pip install -qqU fastai==2.1.7","6fd42f60":"import fastai; print(\"fastai:\", fastai.__version__)\nimport torch; print(\"torch:\", torch.__version__)","0013dfae":"from fastai.vision.all import *\nimport torchvision ","697ad1fd":"new_data_path = Path(\"..\/input\/cassava-leaf-disease-classification\/\")\nold_data_path = Path(\"..\/input\/cassavaold\/\")\ndedup_path = Path(\"..\/input\/cassavadedup\/\")","a5d6ac51":"new_data_path.ls().map(lambda o: o.name)","5335f9ae":"train_images = get_image_files(new_data_path\/'train_images')\ntest_images = get_image_files(new_data_path\/'test_images')\ntrain_df = pd.read_csv(new_data_path\/'train.csv')","74885df7":"len(train_images), len(test_images)","ad142712":"new_images = train_images","8fe38540":"train_df['label'].value_counts()","f4fd1e72":"labeldict = json.loads((new_data_path\/'label_num_to_disease_map.json').open().read())\nlabeldict = {int(k):v for k,v in labeldict.items()}","3ecd36f0":"train_df['label'].map(labeldict).value_counts()","2ddb455b":"%%timeit\nimg1 = PILImage.create(train_images[0]) \nimg1 = ToTensor()(img1)","856dc7bb":"%%timeit\nimg2 = torchvision.io.read_image(train_images[0].as_posix())","6908c5a7":"old_train_images = get_image_files(old_data_path\/'train')\nold_test_images = get_image_files(old_data_path\/'test')\nold_unsup_images = get_image_files(old_data_path\/'extraimages')","91fe1e12":"old_images = old_train_images + old_test_images + old_unsup_images","9d72ed86":"len(old_images)","a1c370f2":"len(old_images), len(new_images)","e277d942":"oldlabeldict = {'cbsd': 'Cassava Brown Streak Disease (CBSD)',\n                 'healthy': 'Healthy',\n                 'cmd': 'Cassava Mosaic Disease (CMD)',\n                 'cgm': 'Cassava Green Mottle (CGM)',\n                 'cbb': 'Cassava Bacterial Blight (CBB)',\n                 '0': 'Unsup', # test\n                 'extraimages': 'Unsup'}","f57d1889":"labeldict","19b8b9ef":"old_images2labels = dict(zip(old_images, [oldlabeldict[o] for o in old_images.map(lambda o: o.parent.name)]))\n\nnew_images2labels = dict(zip(train_df['image_id'], train_df['label']))\nnew_images2labels = {k:labeldict[v] for k,v in new_images2labels.items()}\nnew_images2labels = {o:new_images2labels[o.name] for o in new_images}","f945682e":"Counter(old_images2labels.values())","df8f9b4e":"Counter(new_images2labels.values())","68fbd256":"all_images2label = {**old_images2labels, **new_images2labels}","d9a9ff40":"Counter(all_images2label.values())","4ea8e9e9":"len(all_images2label)","4f97bb5b":"label_vocab = {'Cassava Bacterial Blight (CBB)':0,\n             'Cassava Brown Streak Disease (CBSD)':1,\n             'Cassava Green Mottle (CGM)':2,\n             'Cassava Mosaic Disease (CMD)':3,\n             'Healthy':4, \n             'Unsup':5}","e5e23ca1":"# create dataframe for merged data\nfnames, labels = zip(*all_images2label.items())\nfnames = [str(o) for o in fnames]\ndata_df = pd.DataFrame({'fnames':fnames, 'labels':labels})\ndata_df['source'] = data_df.fnames.apply(lambda o: o.split(\"\/\")[2])","3125ec11":"data_df.to_csv(\"merged_training_data.csv\", index=False)","0caa015c":"data_df","c53d73a0":"counts_df = data_df.groupby(['source', 'labels']).count(); counts_df","baf3744d":"counts_df.groupby(level=0).apply(lambda x: x \/ float(x.sum()))","f1083adf":"counts_df.drop(index='Unsup', level='labels').apply(lambda x: x \/ float(x.sum()))","6e8d5766":"all_images = old_images + new_images; len(all_images)","0afb4f79":"# Fastai\nsize = (224,224)\nbs = 64\n\ntfms = [[PILImage.create, ToTensor, \n         Resize(size, method='squish')], # We don't want to crop different parts of the same image if we are going to look for dedups!\n        [lambda o: all_images2label[o], Categorize(label_vocab)]]\n\ndsets = Datasets(all_images, tfms=tfms, splits=None)\n\nbatch_tfms = [IntToFloatTensor, Normalize.from_stats(*imagenet_stats)]\ndls = dsets.dataloaders(bs=bs, after_batch=batch_tfms)","0031b859":"show_image(dsets[0][0]);","dc4f9bf1":"%%time\ndls.show_batch(max_n=25)","23bd8712":"# load\nembeddings = torch.load(dedup_path\/\"embeddings.pth\")\nembeddings.shape, len(all_images)","5e0d9989":"all_images = pd.read_pickle(dedup_path\/\"all_images_filenames.pkl\")","e82ba2cc":"embeddings.shape, len(all_images)","e9b2760e":"import cuml","e1fc6002":"embeddings_np = embeddings.numpy()","4b08ebc0":"KNN = 4\nmodel = cuml.neighbors.NearestNeighbors(n_neighbors=KNN)\nmodel.fit(embeddings_np)\ndistances, indices = model.kneighbors(embeddings_np)","03ff6198":"plt.hist(np.min(distances[:, 1:], 1));","c307f47d":"lower = 0\nupper = 25\nmask = (distances < upper)*(distances >= lower)","37af6d04":"dup_idxs = mask[:, 1:].sum(1) > 0\nprint(f\"Total potential duplicates: {sum(dup_idxs)}\")","da07a077":"dup_indices, dup_mask, dup_distances = indices[dup_idxs], mask[dup_idxs], distances[dup_idxs]\nsortidxs = np.argsort(dup_distances[:, 1])\ndup_indices, dup_mask, dup_distances = dup_indices[sortidxs], dup_mask[sortidxs], dup_distances[sortidxs]","27b6466f":"i = 0\nfor idxs, m in zip(dup_indices, dup_mask):\n    masked_idxs = idxs[m]\n    \n    if masked_idxs[0] != idxs[0]:\n        masked_idxs = [idxs[0]] + list(masked_idxs)\n    \n    fnames = [all_images[i] for i in masked_idxs]\n    titles = [all_images2label[fn] for fn in fnames]\n    imgs = [PILImage.create(fn) for fn in fnames]\n    show_images(imgs, imsize=5, titles=titles)\n    i += 1\n    if i == 20: break","1b1c3b84":"data_df.head()","a217e6e4":"image2groupid = {}\ni = 0\nfor idxs, m in zip(dup_indices, dup_mask):\n    \n    masked_idxs = idxs[m]\n    \n    if masked_idxs[0] != idxs[0]:\n        masked_idxs = [idxs[0]] + list(masked_idxs)\n        \n    for idx in masked_idxs:\n        image2groupid[str(all_images[idx])] = i \n    \n    i += 1","412415cb":"len(image2groupid)","ca7d2e8b":"data_df['knn_groups'] = data_df['fnames'].map(image2groupid)","b84f941f":"unique_groups = np.unique(data_df.dropna().knn_groups.values)","ec53af9d":"k = np.random.choice(unique_groups)\ngroup_df = data_df.query(f\"knn_groups == {k}\")\ngroup_df","5a41c50c":"show_images([open_image(o) for o in group_df['fnames']], imsize=7)","db89a7a4":"data_df.to_csv(\"merged_training_data.csv\",index=False)","dfcee98f":"We can see label distributions are different in 2 datasets","2e643cf6":"### 2) Get Embeddings ","548f496f":"Part 2 of [notebook](https:\/\/www.kaggle.com\/keremt\/cassava-eda-imagehash-cnn-dedup-old-and-new-data)\n\nIn this notebook we find dedups using Rapids","5562f62f":"### b) Old Data\n\nPlease upvote if you use: https:\/\/www.kaggle.com\/keremt\/cassavaold","1887130a":"## 3) KNN","dab6ee4f":"## CNN Based Dedup (Part2)","179a9253":"We have enough variability between 30 - 35 distances indicating different samples, so we can probably thresholds as < 30. You can also play with different `upper` and `lower` to see how nearest neighbors change.\n\nHere I keep 30 to be conservative, but you may pick lower upper threshold.\n\nActually let's go with 25, as we can start seeing duplicates from that point :)","3583ed46":"### Save groups","01d97a2c":"### a) New Data","ed5646b0":"### Normalize labels ","60825565":"## Data"}}