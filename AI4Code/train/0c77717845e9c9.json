{"cell_type":{"2a85ac97":"code","69d3976f":"code","a46c4b3b":"code","3890742f":"code","57840b94":"code","d88beebe":"code","2ad3e51c":"code","aeb2fcb4":"code","79d32b55":"code","7b154f99":"code","f5a42742":"code","0eaf044b":"code","7bf9c8be":"code","88a93ad1":"code","81e9e62a":"code","bf5a9b73":"code","1c08d999":"code","382ecf55":"code","2aa5eb8a":"code","8536a6ce":"code","d3b58ef6":"code","572ee2a9":"code","66b8e990":"code","6a7e47fb":"code","568bf276":"code","fc2906d7":"code","531c04cf":"code","a5a7bd5c":"code","e0252a45":"code","d73dbcb2":"code","8792aede":"code","c1bf1c8a":"markdown","1db180b9":"markdown","6a89dd14":"markdown","2c15b0b2":"markdown","edc1538c":"markdown","4e38fa22":"markdown"},"source":{"2a85ac97":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/brain-tumor-classification-mri'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","69d3976f":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_green)\nsns.palplot(colors_red)","a46c4b3b":"labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']","3890742f":"X_train = []\ny_train = []\nimage_size = 150\nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Training',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Testing',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)","57840b94":"k=0\nfig, ax = plt.subplots(1,4,figsize=(20,20))\nfig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            ax[k].imshow(X_train[j])\n            ax[k].set_title(y_train[j])\n            ax[k].axis('off')\n            k+=1\n            break\n        j+=1","d88beebe":"X_train, y_train = shuffle(X_train,y_train, random_state=101)\nX_train.shape","2ad3e51c":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)\ny_train","aeb2fcb4":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","79d32b55":"effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","7b154f99":"model = effnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(4,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet.input, outputs = model)","f5a42742":"model.summary()\n","0eaf044b":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n","7bf9c8be":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","88a93ad1":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","81e9e62a":"filterwarnings('ignore')\n\nepochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","bf5a9b73":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)","1c08d999":"print(classification_report(y_test_new,pred))","382ecf55":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport cv2\nfrom glob import glob\n\nimport tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set parameters\nIMAGE_SIZE = (256, 256)","2aa5eb8a":"mask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\ntrain_files = [file.replace('_mask', '') for file in mask_files]","8536a6ce":"def diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                   \"mask_path\": mask_files,\n                  \"diagnosis\":[diagnosis(x) for x in mask_files]})\ndf.head()","d3b58ef6":"ax = df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(10,6), color=['blue', 'red'])\nax.set_title('Data Distribution')\nax.set_ylabel('Total Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=15)","572ee2a9":"# Visualize MRI with Mask\ndf_positive = df[df['diagnosis']=='1'].sample(5).values\ndf_negative = df[df['diagnosis']=='0'].sample(5).values\n\ndef show_data(df, positive=True):\n    images = []\n    masks = []\n    for data in df:\n        img = cv2.imread(data[0])\n        mask = cv2.imread(data[1])\n        images.append(img)\n        masks.append(mask)\n    images = np.hstack(np.array(images))\n    masks = np.hstack(np.array(masks))\n    \n    fig = plt.figure(figsize=(25,25))\n    if positive:\n        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n    else:\n        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n    grid[0].imshow(images)\n    grid[0].set_title('Images', fontsize=15)\n    grid[0].axis('off')\n    grid[1].imshow(masks)\n    grid[1].set_title('Masks', fontsize=15)\n    grid[1].axis('off')\n    if positive:\n        grid[2].imshow(images)\n        grid[2].imshow(masks, alpha=0.4)\n        grid[2].set_title('Brain MRI with mask', fontsize=15)\n        grid[2].axis('off')\n        \nshow_data(df_positive)\nshow_data(df_negative, positive=False)","66b8e990":"# splitting data\nfrom sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","6a7e47fb":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img \/ 255.\n    mask = mask \/ 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","568bf276":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) \/ (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","fc2906d7":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","531c04cf":"# Set parameters\nEPOCHS = 15\nBATCH_SIZE = 32\nlearning_rate = 0.1","a5a7bd5c":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \nval_gen = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    \nmodel = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n\n\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\nmodel.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brainMRI_seg.hdf5', verbose=0, save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=15)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = val_gen,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)\n","e0252a45":"plt.figure(figsize=(8,15))\nplt.subplot(3,1,1)\nplt.plot(model.history.history['loss'], 'b-', label='train_loss')\nplt.plot(model.history.history['val_loss'], 'r-', label='val_loss')\nplt.legend(loc='best')\nplt.title('Loss')\n\nplt.subplot(3,1,2)\nplt.plot(model.history.history['iou'], 'b-', label='train_iou')\nplt.plot(model.history.history['val_iou'], 'r-', label='val_iou')\nplt.legend(loc='best')\nplt.title('IoU')\n\nplt.subplot(3,1,3)\nplt.plot(model.history.history['dice_coef'], 'b-', label='train_dice_coef')\nplt.plot(model.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\nplt.legend(loc='best')\nplt.title('Dice Coef')","d73dbcb2":"# Evaluate the model\ntest_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) \/ BATCH_SIZE)\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","8792aede":"# visualize the results\nfor i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","c1bf1c8a":"### Transfer Learning","1db180b9":"# 1. Classification","6a89dd14":"## Evaluation\nIn this,\n0 - Glioma Tumor\n1 - No Tumor\n2 - Meningioma Tumor\n3 - Pituitary Tumor","2c15b0b2":"# **2. Segmentation**","edc1538c":"### UNET model","4e38fa22":"## Data Preperation"}}