{"cell_type":{"16beb239":"code","c43eaed0":"code","ac4b2475":"code","be5598df":"code","d421b405":"code","2838fb2c":"code","d65c1d46":"code","dd6c992e":"code","0e67f4c9":"code","28ba3ad8":"markdown","572063b6":"markdown","4a800353":"markdown","ce2a97cb":"markdown"},"source":{"16beb239":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c43eaed0":"import pandas as pd\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.utils import to_categorical \nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, ZeroPadding2D, BatchNormalization, Dropout, Dense, Flatten, Activation, Add, concatenate\nfrom keras.initializers import glorot_uniform, he_uniform, Zeros\nimport matplotlib.pyplot as plt\n","ac4b2475":"train_X = np.load(\"\/kaggle\/input\/train-data\/train_X.npy\")\n\ntrain_y = np.asarray(pd.read_csv(\"\/kaggle\/input\/train-data\/train.csv\").iloc[:,1])\n\ntrain_y = to_categorical(train_y)","be5598df":"kernel_init = glorot_uniform()\n\ndef identity_block(X, F1, F2, F3, k, stage, block):\n    conv_name_base = 'Conv'+str(stage)+str(block)\n    bn_name_base = 'BN'+str(stage)+str(block)\n    \n    X_shortcut = X # I will need this to add with convolutional o\/p\n    \n    X = Conv2D(F1, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=kernel_init, name=conv_name_base+'2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_a')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F2, kernel_size=(k,k), strides=(1,1), padding='same', kernel_initializer=kernel_init, name=conv_name_base+'2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_b')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=kernel_init, name=conv_name_base+'2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_c')(X)\n    \n    X = Add()([X_shortcut, X])\n    X = Activation('relu')(X)\n    \n    return X","d421b405":"def convolutional_block(X, F1, F2, F3, k, s, stage, block):\n    conv_name_base = 'Conv'+str(stage)+str(block)\n    bn_name_base = 'BN'+str(stage)+str(block)\n    \n    X_shortcut = X # I will need this to add with convolutional o\/p\n    X_shortcut = Conv2D(F3, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_initializer=kernel_init, name=conv_name_base+'1')(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n    \n    X = Conv2D(F1, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_initializer=kernel_init, name=conv_name_base+'2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_a')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F2, kernel_size=(k,k), strides=(1,1), padding='same', kernel_initializer=kernel_init, name=conv_name_base+'2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_b')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=kernel_init, name=conv_name_base+'2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'_c')(X) \n    \n    \n    X = Add()([X_shortcut, X])\n    X = Activation('relu')(X)\n    \n    return X","2838fb2c":"X_input = Input(shape=(100,100,3))\n\n    \n# Zero-Padding\nX = ZeroPadding2D((3, 3))(X_input)\n    \n# Stage 1\nX = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\nX = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\nX = Activation('relu')(X)\nX = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n# Stage 2\nX = convolutional_block(X, k= 3, F1=64, F2=64, F3=256, stage = 2, block='a', s = 1)\nX = identity_block(X, k=3, F1=64, F2=64, F3=256, stage=2, block='b')\nX = identity_block(X, k=3, F1=64, F2=64, F3=256, stage=2, block='c')\n\n# Stage 3\nX = convolutional_block(X, k=3, F1=128, F2=128, F3=512, stage=3, block='a', s=2)\nX = identity_block(X, k=3, F1=128, F2=128, F3=512, stage=3, block='b')\nX = identity_block(X, k=3, F1=128, F2=128, F3=512, stage=3, block='c')\nX = identity_block(X, k=3, F1=128, F2=128, F3=512, stage=3, block='d')\n\n# Stage 4\nX = convolutional_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='a', s=2)\nX = identity_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='b')\nX = identity_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='c')\nX = identity_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='d')\nX = identity_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='e')\nX = identity_block(X, k=3, F1=256, F2=256, F3=1024, stage=4, block='f')\n\n# Stage 5\nX = convolutional_block(X, k=3, F1=512, F2=512, F3=2048, stage=5, block='a', s=2)\nX = identity_block(X, k=3, F1=512, F2=512, F3=2048, stage=5, block='b')\nX = identity_block(X, k=3, F1=512, F2=512, F3=2048, stage=5, block='c')\n\n# AVGPOOL\nX = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n\n# Output layer\nX = Flatten()(X)\nX = Dense(103, activation='softmax', name='fc' + str(103), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    ","d65c1d46":"# Create model\nmodel = Model(inputs = X_input, outputs = X, name='ResNet50')\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","dd6c992e":"model.fit(train_X, train_y, validation_split=0.2, epochs = 100, batch_size=128)","0e67f4c9":"import matplotlib.pyplot as plt \nprint(model.history.history.keys())\nplt.figure(1)\nplt.plot(model.history.history['accuracy'])\nplt.plot(model.history.history['val_accuracy'])\nplt.legend(['training accuracy', 'validation accuracy'])\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')","28ba3ad8":"There are 100+ types of flowers which are to be classified. A labeled set is given for training. In this kernel I will make a Residual Network for the problem statement. Previously I used VGG16 and GoogLeNet network to train on the same dataset.","572063b6":"Residual Convolutional Block","4a800353":"Resnet50 Network","ce2a97cb":"Residual Identity Block"}}