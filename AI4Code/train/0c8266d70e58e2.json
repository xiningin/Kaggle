{"cell_type":{"209599a4":"code","63215e16":"code","08597ac5":"code","c7333b62":"code","73121cea":"code","433e4298":"code","b581d357":"code","7ba70d23":"code","c30343ed":"code","f64216f3":"code","f03ac8ce":"code","f80c7a1a":"code","860a1e5d":"code","a0e4fa92":"code","853abaa9":"code","9a3b5711":"code","b5f565f0":"code","30d27390":"code","fbbd7602":"code","2b82cf9f":"code","cb30f4af":"code","3a9dc2b9":"code","1d25dd0d":"code","9ca07c3d":"code","72dfd5f8":"code","09c3ef63":"code","abd02df7":"code","224e848a":"code","8adf43c4":"code","ae9335da":"code","4e9e2609":"code","77f84174":"code","97db196b":"markdown","f3fed51d":"markdown","fe37a64d":"markdown","23be5a0d":"markdown","b9c37894":"markdown","55588df1":"markdown","c1b00695":"markdown","a63f7c0b":"markdown","bd0b1eb8":"markdown","3721d2c7":"markdown","fef961d6":"markdown","6d74dc27":"markdown","f5c176d8":"markdown","07d37032":"markdown","293f4681":"markdown","c98dfe94":"markdown","a053f044":"markdown","b135c1ec":"markdown","ef02e713":"markdown","0a9410d7":"markdown","171f5b84":"markdown"},"source":{"209599a4":"import os\nimport numpy as np \nimport pandas as pd \nimport json\nfrom pandas.io.json import json_normalize\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected=True)","63215e16":"from scipy import stats\nfrom numpy import random\n\nimport time\nfrom datetime import datetime","08597ac5":"%matplotlib inline\n\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected=True)\n\ncolor = sns.color_palette()\nfrom plotly import subplots\nfrom plotly import version\n\npy.init_notebook_mode(connected=True)\n\nfrom sklearn import model_selection, preprocessing, metrics\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999","c7333b62":"# read in data\n\ndf = pd.read_csv(\"..\/input\/ga-customer-revenue-prediction\/test.csv\", nrows=10000)\ndf.shape","73121cea":"# See the variables \ndf.head()\n","433e4298":"# See the variables \ndf.dtypes","b581d357":"pd.set_option('display.max_columns', None)\n\ndef load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/test.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df\n","7ba70d23":"pd.set_option('display.max_columns', None)\n\ndef load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df\n","c30343ed":"train = load_df()\ntrain.shape","f64216f3":"os.getcwd()","f03ac8ce":"train.to_csv('train_flat.csv', index=False)","f80c7a1a":"train = pd.read_csv(r'.\/train_flat.csv', dtype={'fullVisitorId': 'str'}, nrows=100000)\ntrain.head()","860a1e5d":"train.shape","a0e4fa92":"train.info()","853abaa9":"print (\"There are \" + str(train.shape[0]) + \" rows and \" + str(train.shape[1]) + \" raw columns in this dataset\")\n\nprint (\"Snapshot: \", train.head())","9a3b5711":"miss_per = {}\nfor k, v in dict(train.isna().sum(axis=0)).items():\n    if v == 0:\n        continue\n    miss_per[k] = 100 * float(v) \/ len(train)\n    \nimport operator \nsorted_x = sorted(miss_per.items(), key=operator.itemgetter(1), reverse=True)\nprint (\"There are \" + str(len(miss_per)) + \" columns with missing values\")\n\nkys = [_[0] for _ in sorted_x][::-1]\nvls = [_[1] for _ in sorted_x][::-1]\ntrace1 = go.Bar(y = kys, orientation=\"h\" , x = vls, marker=dict(color=\"#d6a5ff\"))\nlayout = go.Layout(title=\"Missing Values Percentage\", \n                   xaxis=dict(title=\"Missing Percentage\"), \n                   height=400, margin=dict(l=300, r=300))\nfigure = go.Figure(data = [trace1], layout = layout)\niplot(figure)","b5f565f0":"device_cols = [\"device.browser\", \"device.deviceCategory\", \"device.operatingSystem\"]\n\ncolors = [\"#d6a5ff\", \"#fca6da\", \"#f4d39c\", \"#a9fcca\"]\ntraces = []\nfor i, col in enumerate(device_cols):\n    t = train[col].value_counts()\n    traces.append(go.Bar(marker=dict(color=colors[i]),orientation=\"h\", y = t.index[:15][::-1], x = t.values[:15][::-1]))\n\nfig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Visits: Category\", \"Visits: Browser\",\"Visits: OS\"], print_grid=False)\nfig.append_trace(traces[1], 1, 1)\nfig.append_trace(traces[0], 1, 2)\nfig.append_trace(traces[2], 1, 3)\n\nfig['layout'].update(height=400, showlegend=False, title=\"Visits by Device Attributes\")\niplot(fig)\n\n## convert transaction revenue to float\ntrain[\"totals.transactionRevenue\"] = train[\"totals.transactionRevenue\"].astype('float')\n\ndevice_cols = [\"device.browser\", \"device.deviceCategory\", \"device.operatingSystem\"]\n\nfig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Mean Revenue: Category\", \"Mean Revenue: Browser\",\"Mean Revenue: OS\"], print_grid=False)\n\ncolors = [\"red\", \"green\", \"purple\"]\ntrs = []\nfor i, col in enumerate(device_cols):\n    tmp = train.groupby(col).agg({\"totals.transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"totals.transactionRevenue\" : \"Mean Revenue\"})\n    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n    tr = go.Bar(x = tmp[\"Mean Revenue\"][::-1], orientation=\"h\", marker=dict(opacity=0.5, color=colors[i]), y = tmp[col][::-1])\n    trs.append(tr)\n\nfig.append_trace(trs[1], 1, 1)\nfig.append_trace(trs[0], 1, 2)\nfig.append_trace(trs[2], 1, 3)\nfig['layout'].update(height=400, showlegend=False, title=\"Mean Revenue by Device Attributes\")\niplot(fig)","30d27390":"geo_cols = ['geoNetwork.city', 'geoNetwork.continent','geoNetwork.country',\n            'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region','geoNetwork.subContinent']\ngeo_cols = ['geoNetwork.continent','geoNetwork.subContinent']\n\ncolors = [\"#d6a5ff\", \"#fca6da\"]\nfig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Visits : GeoNetwork Continent\", \"Visits : GeoNetwork subContinent\"], print_grid=False)\ntrs = []\nfor i,col in enumerate(geo_cols):\n    t = train[col].value_counts()\n    tr = go.Bar(x = t.index[:20], marker=dict(color=colors[i]), y = t.values[:20])\n    trs.append(tr)\n\nfig.append_trace(trs[0], 1, 1)\nfig.append_trace(trs[1], 1, 2)\nfig['layout'].update(height=400, margin=dict(b=150), showlegend=False)\niplot(fig)\n\n\ngeo_cols = ['geoNetwork.continent','geoNetwork.subContinent']\nfig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Mean Revenue: Continent\", \"Mean Revenue: SubContinent\"], print_grid=False)\n\ncolors = [\"blue\", \"orange\"]\ntrs = []\nfor i, col in enumerate(geo_cols):\n    tmp = train.groupby(col).agg({\"totals.transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"totals.transactionRevenue\" : \"Mean Revenue\"})\n    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n    tr = go.Bar(y = tmp[\"Mean Revenue\"], orientation=\"v\", marker=dict(opacity=0.5, color=colors[i]), x= tmp[col])\n    trs.append(tr)\n\nfig.append_trace(trs[0], 1, 1)\nfig.append_trace(trs[1], 1, 2)\nfig['layout'].update(height=450, margin=dict(b=200), showlegend=False)\niplot(fig)","fbbd7602":"tmp1 = train[\"geoNetwork.country\"].value_counts()\n\n# plotly globe credits - https:\/\/www.kaggle.com\/arthurtok\/generation-unemployed-interactive-plotly-visuals\ncolorscale = [[0, 'rgb(102,194,165)'], [0.005, 'rgb(102,194,165)'], \n              [0.01, 'rgb(171,221,164)'], [0.02, 'rgb(230,245,152)'], \n              [0.04, 'rgb(255,255,191)'], [0.05, 'rgb(254,224,139)'], \n              [0.10, 'rgb(253,174,97)'], [0.25, 'rgb(213,62,79)'], [1.0, 'rgb(158,1,66)']]\n\ndata = [ dict(\n        type = 'choropleth',\n        autocolorscale = False,\n        colorscale = colorscale,\n        showscale = True,\n        locations = tmp1.index,\n        z = tmp1.values,\n        locationmode = 'country names',\n        text = tmp1.values,\n        marker = dict(\n            line = dict(color = '#fff', width = 2)) )           ]\n\nlayout = dict(\n    height=500,\n    title = 'Visits by Country',\n    geo = dict(\n        showframe = True,\n        showocean = True,\n        oceancolor = '#222',\n        projection = dict(\n        type = 'orthographic',\n            rotation = dict(\n                    lon = 60,\n                    lat = 10),\n        ),\n        lonaxis =  dict(\n                showgrid = False,\n                gridcolor = 'rgb(102, 102, 102)'\n            ),\n        lataxis = dict(\n                showgrid = False,\n                gridcolor = 'rgb(102, 102, 102)'\n                )\n            ),\n        )\nfig = dict(data=data, layout=layout)\niplot(fig)\n\n\n","2b82cf9f":"tmp1.head()\n#tmp1.shape\n#tmp1.dtypes\nprint(tmp1.index)\ntmp1['Hong Kong']","cb30f4af":"tmp2 = train.groupby([\"geoNetwork.country\"]).mean()[\"totals.transactionRevenue\"] \ntmp2 = tmp2.fillna(0)\ntmp2.head()\nprint(tmp2.index)\ntmp2['Hong Kong']\n#tmp2.dtypes","3a9dc2b9":"# plotly globe credits - https:\/\/www.kaggle.com\/arthurtok\/generation-unemployed-interactive-plotly-visuals\ncolorscale = [[0, 'rgb(102,194,165)'], [0.005, 'rgb(102,194,165)'], \n              [0.01, 'rgb(171,221,164)'], [0.02, 'rgb(230,245,152)'], \n              [0.04, 'rgb(255,255,191)'], [0.05, 'rgb(254,224,139)'], \n              [0.10, 'rgb(253,174,97)'], [0.25, 'rgb(213,62,79)'], [1.0, 'rgb(158,1,66)']]\n\ndata = [ dict(\n        type = 'choropleth',\n        autocolorscale = False,\n        colorscale = colorscale,\n        showscale = True,\n        locations = tmp2.index,\n        z = tmp2,\n        locationmode = 'country names',\n        text = tmp2,\n        marker = dict(\n            line = dict(color = '#fff', width = 2)) )           ]\n\nlayout = dict(\n    height=500,\n    title = 'Visits by Country',\n    geo = dict(\n        showframe = True,\n        showocean = True,\n        oceancolor = '#222',\n        projection = dict(\n        type = 'orthographic',\n            rotation = dict(\n                    lon = 60,\n                    lat = 10),\n        ),\n        lonaxis =  dict(\n                showgrid = False,\n                gridcolor = 'rgb(102, 102, 102)'\n            ),\n        lataxis = dict(\n                showgrid = False,\n                gridcolor = 'rgb(102, 102, 102)'\n                )\n            ),\n        )\nfig = dict(data=data, layout=layout)\niplot(fig)","1d25dd0d":"fig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"TrafficSource Campaign (not-set removed)\", \"TrafficSource Medium\"], print_grid=False)\n\ncolors = [\"#d6a5ff\", \"#fca6da\", \"#f4d39c\", \"#a9fcca\"]\nt1 = train[\"trafficSource.campaign\"].value_counts()\nt2 = train[\"trafficSource.medium\"].value_counts()\ntr1 = go.Bar(x = t1.index, y = t1.values, marker=dict(color=colors[3]))\ntr2 = go.Bar(x = t2.index, y = t2.values, marker=dict(color=colors[2]))\ntr3 = go.Bar(x = t1.index[1:], y = t1.values[1:], marker=dict(color=colors[0]))\ntr4 = go.Bar(x = t2.index[1:], y = t2.values[1:])\n\nfig.append_trace(tr3, 1, 1)\nfig.append_trace(tr2, 1, 2)\nfig['layout'].update(height=400, margin=dict(b=100), showlegend=False)\niplot(fig)","9ca07c3d":"tmp = train[\"channelGrouping\"].value_counts()\ncolors = [\"#8d44fc\", \"#ed95d5\", \"#caadf7\", \"#6161b7\", \"#7e7eba\", \"#babad1\"]\ntrace = go.Pie(labels=tmp.index, values=tmp.values, marker=dict(colors=colors))\nlayout = go.Layout(title=\"Channel Grouping\", height=400)\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig, filename='basic_pie_chart')","72dfd5f8":"def _add_date_features(df):\n    df['date'] = df['date'].astype(str)\n    df[\"date\"] = df[\"date\"].apply(lambda x : x[:4] + \"-\" + x[4:6] + \"-\" + x[6:])\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    \n    df[\"month\"]   = df['date'].dt.month\n    df[\"day\"]     = df['date'].dt.day\n    df[\"weekday\"] = df['date'].dt.weekday\n    return df \n\ntrain = _add_date_features(train)","09c3ef63":"tmp = train['date'].value_counts().to_frame().reset_index().sort_values('index')\ntmp = tmp.rename(columns = {\"index\" : \"dateX\", \"date\" : \"visits\"})\n\ntr = go.Scatter(mode=\"lines\", x = tmp[\"dateX\"].astype(str), y = tmp[\"visits\"])\nlayout = go.Layout(title=\"Visits by date\", height=400)\nfig = go.Figure(data = [tr], layout = layout)\niplot(fig)\n\n\ntmp = train.groupby(\"date\").agg({\"totals.transactionRevenue\" : \"mean\"}).reset_index()\ntmp = tmp.rename(columns = {\"date\" : \"dateX\", \"totals.transactionRevenue\" : \"mean_revenue\"})\ntr = go.Scatter(mode=\"lines\", x = tmp[\"dateX\"].astype(str), y = tmp[\"mean_revenue\"])\nlayout = go.Layout(title=\"MonthlyRevenue by date\", height=400)\nfig = go.Figure(data = [tr], layout = layout)\niplot(fig)","abd02df7":"fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Visits by Month\", \"Visits by MonthDay\", \"Visits by WeekDay\"], print_grid=False)\ntrs = []\nfor i,col in enumerate([\"month\", \"day\", \"weekday\"]):\n    t = train[col].value_counts()\n    tr = go.Bar(x = t.index, marker=dict(color=colors[i]), y = t.values)\n    trs.append(tr)\n\nfig.append_trace(trs[0], 1, 1)\nfig.append_trace(trs[1], 1, 2)\nfig.append_trace(trs[2], 1, 3)\nfig['layout'].update(height=400, showlegend=False)\niplot(fig)\n\n\n\ntmp1 = train.groupby('month').agg({\"totals.transactionRevenue\" : \"mean\"}).reset_index()\ntmp2 = train.groupby('day').agg({\"totals.transactionRevenue\" : \"mean\"}).reset_index()\ntmp3 = train.groupby('weekday').agg({\"totals.transactionRevenue\" : \"mean\"}).reset_index()\n\nfig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"MeanRevenue by Month\", \"MeanRevenue by MonthDay\", \"MeanRevenue by WeekDay\"], print_grid=False)\ntr1 = go.Bar(x = tmp1.month, marker=dict(color=\"red\", opacity=0.5), y = tmp1['totals.transactionRevenue'])\ntr2 = go.Bar(x = tmp2.day, marker=dict(color=\"orange\", opacity=0.5), y = tmp2['totals.transactionRevenue'])\ntr3 = go.Bar(x = tmp3.weekday, marker=dict(color=\"green\", opacity=0.5), y = tmp3['totals.transactionRevenue'])\n\nfig.append_trace(tr1, 1, 1)\nfig.append_trace(tr2, 1, 2)\nfig.append_trace(tr3, 1, 3)\nfig['layout'].update(height=400, showlegend=False)\niplot(fig)","224e848a":"vn = train[\"visitNumber\"].value_counts()\ndef vn_bins(x):\n    if x == 1:\n        return \"1\" \n    elif x < 5:\n        return \"2-5\"\n    elif x < 10:\n        return \"5-10\"\n    elif x < 50:\n        return \"10-50\"\n    elif x < 100:\n        return \"50-100\"\n    else:\n        return \"100+\"\n    \nvn = train[\"visitNumber\"].apply(vn_bins).value_counts()\n\ntrace1 = go.Bar(y = vn.index[::-1], orientation=\"h\" , x = vn.values[::-1], marker=dict(color=\"#7af9ad\"))\nlayout = go.Layout(title=\"Visit Numbers Distribution\", \n                   xaxis=dict(title=\"Frequency\"),yaxis=dict(title=\"VisitNumber\") ,\n                   height=400, margin=dict(l=300, r=300))\nfigure = go.Figure(data = [trace1], layout = layout)\niplot(figure)","8adf43c4":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nagg_dict = {}\nfor col in [\"totals.bounces\", \"totals.hits\", \"totals.newVisits\", \"totals.pageviews\", \"totals.transactionRevenue\"]:\n    train[col] = train[col].astype('float')\n    agg_dict[col] = \"sum\"\ntmp = train.groupby(\"fullVisitorId\").agg(agg_dict).reset_index()\ntmp.head()","ae9335da":"non_zero = tmp[tmp[\"totals.transactionRevenue\"] > 0][\"totals.transactionRevenue\"]\nprint (\"There are \" + str(len(non_zero)) + \" visitors in the train dataset having non zero total transaction revenue\")\n\nplt.figure(figsize=(12,6))\nsns.distplot(non_zero)\nplt.title(\"Distribution of Non Zero Total Transactions\");\nplt.xlabel(\"Total Transactions\");","4e9e2609":"plt.figure(figsize=(12,6))\nsns.distplot(np.log1p(non_zero))\nplt.title(\"Log Distribution of Non Zero Total Transactions\");\nplt.xlabel(\"Log - Total Transactions\");","77f84174":"def getbin_hits(x):\n    if x < 5:\n        return \"1-5\"\n    elif x < 10:\n        return \"5-10\"\n    elif x < 30:\n        return \"10-30\"\n    elif x < 50:\n        return \"30-50\"\n    elif x < 100:\n        return \"50-100\"\n    else:\n        return \"100+\"\n\ntmp[\"total.hits_bin\"] = tmp[\"totals.hits\"].apply(getbin_hits)\ntmp[\"totals.bounces_bin\"] = tmp[\"totals.bounces\"].apply(lambda x : str(x) if x <= 5 else \"5+\")\ntmp[\"totals.pageviews_bin\"] = tmp[\"totals.pageviews\"].apply(lambda x : str(x) if x <= 50 else \"50+\")\n\nt1 = tmp[\"total.hits_bin\"].value_counts()\nt2 = tmp[\"totals.bounces_bin\"].value_counts()\nt3 = tmp[\"totals.newVisits\"].value_counts()\nt4 = tmp[\"totals.pageviews_bin\"].value_counts()\n\nfig = tools.make_subplots(rows=2, cols=2, subplot_titles=[\"Total Hits per User\", \"Total Bounces per User\", \n                                                         \"Total NewVistits per User\", \"Total PageViews per User\"], print_grid=False)\n\ntr1 = go.Bar(x = t1.index[:20], y = t1.values[:20])\ntr2 = go.Bar(x = t2.index[:20], y = t2.values[:20])\ntr3 = go.Bar(x = t3.index[:20], y = t3.values[:20])\ntr4 = go.Bar(x = t4.index, y = t4.values)\n\nfig.append_trace(tr1, 1, 1)\nfig.append_trace(tr2, 1, 2)\nfig.append_trace(tr3, 2, 1)\nfig.append_trace(tr4, 2, 2)\n\nfig['layout'].update(height=700, showlegend=False)\niplot(fig)","97db196b":"### 3.4 Channel Grouping","f3fed51d":"> - So we can observe that there are some columns in the dataset having very large number of missing values. \n\n## 3. Exploration - Univariate Analysis \n\nLets perform the univariate analysis and plot some distributions of variables in the dataset\n\n### 3.1 Device Attributes\n\nLets plot the distribution of device attributes","fe37a64d":"### 3.3 Traffic Attributes\n\nLets now plot the traffic attributes","23be5a0d":"### 4.3 Visitor Profile Attributes","b9c37894":"# Workshop 4: Google Analytics Customer Revenue Prediction\n\n\n\n### Contents of this Kernel\n\n1. Problem Statement  \n2. Dataset Understanding  \n3. Exploration  \n4. Visitor Profile  \n \n\n## 1. Problem Statement \n\n#### In this exercise https:\/\/www.kaggle.com\/c\/ga-customer-revenue-prediction , the aim is to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. The exercise here is an explosition of the data and look into the GA data about the personas of the visitors and the analysis might lead to a better use of marketing budgets for those companies who choose to use data analysis on top of GA data. \n\n#### One of the skill here is learn a simple python code on how to convert the JSON format data usually collected over webs, mobile applications and IoT log files into a python data framework for analysis. \n\n### Questions:\n\n#### Q1: Identify the personna of the visitors who are contributing greater proportion of revenue to the merchant?\n#### Q2: Propose a A\/B test experiment and formulate a hypothesis to test your obervations\n\n#### As the first step, lets load the required libraries.\n","55588df1":"Only \"device\", \"geoNetwork\", \"totals\", \"trafficSource\" are JSON objects whereas \"customDimensions\" and \"hits\" are different data nested dictionary objects. One will notice that the data strcuture of series of \"customDimensions\" and \"hits\" are more complicated, in this exercise, they are not included in the analysis.","c1b00695":"### 2.1 Dataset Preparation\n\nLets read the dataset in csv format and unwrap the json fields. Students can reference on https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.json_normalize.html \nand\nhttps:\/\/www.kaggle.com\/julian3833\/1-quick-start-read-csv-and-flatten-json-fields","a63f7c0b":"Remember to download the text.csv (6G bit) from below link to the same directory for working in this Jupyter notebook exercises.\n\nSince github does not allow to upload file more than 2Gbit, the data file is placed on my Google drive as follows:\nhttps:\/\/drive.google.com\/file\/d\/1euXsx5hfq0N5mowMyo3ecqEGcwzHalpT\/view?usp=sharing\n","bd0b1eb8":"### 2.2 Dataset Snapshot\n\nLets view the snapshot of the test dataset. ","3721d2c7":"### 3.5 Visits by date, month and day","fef961d6":"### 2.3 Missing Values Percentage\n\nFrom the snapshot we can observe that there are many missing values in the dataset. Let's plot the missing values percentage for columns having missing values. \n\n> The following graph shows only those columns having missing values, all other columns are fine. ","6d74dc27":"## Reload Flattened Dataset Directly","f5c176d8":"If your PC does not have plotly, you need to find way to install plotly to call in init_notebook_mode, iplot, plotly.graph_objs and tools","07d37032":"> - There is a significant difference in visits from mobile and tablets, but mean revenue for both of them is very close.  \n> - Interesting to note that maximum visits are from Chrome browser however maximum revenue is collected from visits throught firefox. \n> - Chrome OS users has generated maximum revenue though maximum visits are from windows and macintosh users  \n\n### 3.2 GeoNetwork Attributes ","293f4681":"#### Run the whole data may take hours depending the computing efficiency of your machine, it is suggested to limit to data size of 100000","c98dfe94":"Lets take the natural log on the transactions","a053f044":"### 3.6 Visit Number Frequency","b135c1ec":"### 4.2 Total Transactions Revenue","ef02e713":"## 2. Understanding the Dataset\n\nThe data is shared in csv format. The csv files contains some filed with json objects. The description about dataset fields is given  https:\/\/www.kaggle.com\/c\/ga-customer-revenue-prediction\/data \n\n","0a9410d7":"#### Nested data: hits\n\"hits\" record all the pages footprints. The Google Analytics data variables description one can find some details about https:\/\/support.google.com\/analytics\/answer\/3437719?hl=en. Google develops a BigQuery SQL API that one can access its GA data for further AB design testing, reference https:\/\/towardsdatascience.com\/how-to-query-and-calculate-google-analytics-data-in-bigquery-cab8fc4f396 (which we will come back to look into it in lecture 8-9)","171f5b84":"## 4. Visitor Profile \n\nLets create the visitor profile by aggregating the rows for every customer. \n\n### 4.1 Visitor Profile Snapshot"}}