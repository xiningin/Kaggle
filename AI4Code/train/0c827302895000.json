{"cell_type":{"c2db8a0c":"code","6f25760d":"code","6dae275d":"code","515020c1":"code","7a3b4434":"code","2f913d6d":"code","71597986":"code","177df4a6":"code","c69cb401":"code","ac3bcd96":"code","0bdf7505":"code","9793a8ce":"code","7d351225":"code","6e89234b":"code","863d990d":"code","4922da60":"code","94e55a94":"code","a44b17c1":"markdown","4ad9f91c":"markdown","b4a93048":"markdown","81eb35e4":"markdown","bdc344ab":"markdown","37cc7389":"markdown","e7a12fe1":"markdown","d76b5b77":"markdown","02e5c24d":"markdown","52ed1134":"markdown","26453e85":"markdown","9ee22f19":"markdown","7734a587":"markdown","6716d891":"markdown"},"source":{"c2db8a0c":"from sklearn.datasets import load_iris\n\niris = load_iris()\nprint(iris.target_names)","6f25760d":"data = iris.data # atributos\ntarget = iris.target # classes","6dae275d":"print(data[0])\nprint(iris.target_names[target[0]])","515020c1":"# separando os dados\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.9, shuffle=True, random_state=42)\n\nprint(data.shape)\nprint(X_train.shape)\nprint(X_test.shape)","7a3b4434":"# treinando o modelo\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)","2f913d6d":"# predizendo\ny_pred = knn.predict(X_test)\nprint(y_pred)\nprint(y_test)\n\n# comparando com gabarito\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","71597986":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test, y_pred))","177df4a6":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Matriz de confus\u00e3o',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('Gabarito')\n    plt.xlabel('Predi\u00e7\u00e3o')\n    plt.tight_layout()\n\n\n# calcula a matriz de confus\u00e3o\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=iris.target_names,\n                      title='Matriz de confus\u00e3o sem normaliza\u00e7\u00e3o')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=iris.target_names, normalize=True,\n                      title='Matriz de confus\u00e3o normalizada')\n\nplt.show()","c69cb401":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nX_r = pca.fit_transform(X_test)\n\ncolors = ['navy', 'turquoise', 'darkorange']\nfor color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n    plt.scatter(X_r[y_test == i, 0], X_r[y_test == i, 1], color=color, alpha=.8, label=target_name)\nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of IRIS dataset')","ac3bcd96":"# Coloque seu c\u00f3digo aqui\nX_train, X_test, y_train, y_test = train_test_split(data, target, \n                                                    test_size=0.5, \n                                                    shuffle=True, \n                                                    random_state=42)\nprint(data.shape)\nprint(X_train.shape)\nprint(X_test.shape)","0bdf7505":"knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)","9793a8ce":"y_pred = knn.predict(X_test)\naccuracy_score(y_test, y_pred)","7d351225":"cnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=iris.target_names,\n                      title='Matriz de confus\u00e3o sem normaliza\u00e7\u00e3o')","6e89234b":"knn = KNeighborsClassifier(n_neighbors=3, weights = \"uniform\", metric = \"euclidean\")\nknn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)\naccuracy_score(y_test, y_pred)","863d990d":"# Coloque o c\u00f3digo aqui\npca = PCA(n_components=2)\nX_r = pca.fit_transform(X_train)\n\nfor color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n    plt.scatter(X_r[y_train == i, 0], X_r[y_train == i, 1], color=color, alpha=.8, label=target_name)\n    \nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of IRIS dataset - Treino')","4922da60":"pca = PCA(n_components=2)\nX_r = pca.fit_transform(X_test)\n\nfor color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n    plt.scatter(X_r[y_test == i, 0], X_r[y_test == i, 1], color=color, alpha=.8, label=target_name)\n    \nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of IRIS dataset - Teste')\nplt.plot()","94e55a94":"pca = PCA(n_components=2)\nX_r = pca.fit_transform(data)\n\nfor color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n    plt.scatter(X_r[target == i, 0], X_r[target == i, 1], color=color, alpha=.8, label=target_name)\n    \nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of IRIS dataset')\nplt.plot()","a44b17c1":"A fun\u00e7\u00e3o *train_test_split* facilita o processo de separa\u00e7\u00e3o dados, pois \u00e9 totalmente parametriz\u00e1vel. Essa e todas as outras fun\u00e7\u00f5es do Scikit-Learn s\u00e3o bem documentadas e repletas de exemplo. Nesse caso, especificamente, a fun\u00e7\u00e3o precisa receber X e y (atributos e classe respectivamente), o tamanho da parcela que ser\u00e1 usada para teste e o estado de aleatoriedade.\n\nO estado de aleatoriedade \u00e9 um n\u00famero que serve como base para gerar os outros n\u00fameros aleat\u00f3rios. Por exemplo, essa fun\u00e7\u00e3o *train_test_split* pode embaralhar as amostras se for desejado. Esse embaralhamento depende de um gerador rand\u00f4mico. \n\n**Mas como tornar esse experimento reprodut\u00edvel se o gerador for rand\u00f4mico?** Basta especificar um random_state e mant\u00ea-lo, para que todas as opera\u00e7\u00f5es que dependam de aleatoriedade sejam \"fixas\" nesse contexto, sem varia\u00e7\u00e3o.","4ad9f91c":"### (3) Exiba os dados em duas dimens\u00f5es para cada conjunto (treino e teste) e verifique se a distribui\u00e7\u00e3o das classes continua similar \u00e0 base original.","b4a93048":"Em seguida, \u00e9 necess\u00e1rio verificar se o modelo treinado tem uma boa performance, utilizando o modelo para predizer os r\u00f3tulos dos dados de teste e conferindo-os com o gabarito. Uma outra facilidade do Scikit-Learn \u00e9 a an\u00e1lise de resultados com as m\u00e9tricas prontas.\nMais informa\u00e7\u00f5es podem ser obtidas em: [https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.metrics](https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.metrics)","81eb35e4":"Uma an\u00e1lise mais detalhada por classe vai mostrar que a classe setosa \u00e9 relativamente f\u00e1cil de classificar, mas as outras duas t\u00eam sobreposi\u00e7\u00e3o (versicolor e virg\u00ednica), o que leva a erros no m\u00e9todo de aprendizagem dos vizinhos pr\u00f3ximos. Para perceber isso mais claramente, vamos visualizar graficamente a distribui\u00e7\u00e3o das classes.\n\nO n\u00famero de dimens\u00f5es \u00e9 um problema a ser contornado. Visto que essa base tem 4 atributos, seria bastante complicado tentar visualizar os dados em sua forma original. **O que pode ser feito para visualizar um conjunto de dados em 2D \u00e9 a redu\u00e7\u00e3o de dimensionalidade.** Realizar isso no Scikit-Learn \u00e9 relativamente simples devido \u00e0 classe PCA.","bdc344ab":"Conclui-se aqui essa introdu\u00e7\u00e3o sobre o Scikit-Learn, abordando alguns aspectos da biblioteca e facilidades, como:\n* leitura de dados;\n* divis\u00e3o entre treino e teste;\n* utiliza\u00e7\u00e3o de m\u00e9todo de aprendizagem;\n* m\u00e9tricas de avalia\u00e7\u00e3o de modelo; e\n* redu\u00e7\u00e3o de dimensionalidade.","37cc7389":"Essa visualiza\u00e7\u00e3o tamb\u00e9m ajuda a perceber quando um m\u00e9todo de divis\u00e3o linear teria bom resultados. \u00c9 poss\u00edvel perceber pela imagem que uma fun\u00e7\u00e3o linear conseguiria separar facilmente a classe setosa das demais, mas apenas uma fun\u00e7\u00e3o n\u00e3o-linear faria esse trabalho entre a versicolor e a virg\u00ednica nessa visualiza\u00e7\u00e3o.","e7a12fe1":"A descri\u00e7\u00e3o desses dados est\u00e1 dispon\u00edvel na pr\u00f3pria p\u00e1gina do Scikit-Learn: https:\/\/scikit-learn.org\/stable\/datasets\/index.html#iris-dataset\n\nAo mostrar a primeira linha de dados, \u00e9 poss\u00edvel observar que os valores s\u00e3o coerentes com a descri\u00e7\u00e3o da base, assim como \u00e9 poss\u00edvel verificar a qual classe essa linha est\u00e1 associada:","d76b5b77":"## Scikit-Learn \u00e9 uma biblioteca que facilita a prototipa\u00e7\u00e3o de modelos em aprendizado de m\u00e1quina.\n\nA prototipa\u00e7\u00e3o de modelos de aprendizado de m\u00e1quina podem ser custosas se n\u00e3o forem utilizadas ferramentas apropriadas. Scikit-Learn se tornou a biblioteca mais comum para aprendizado de m\u00e1quina em Python, e a maioria das outras bibliotecas fazem integra\u00e7\u00e3o com ela.\n\nEssa biblioteca permite trabalhar os dados, limp\u00e1-los, criar modelos e utilizar diversos m\u00e9todos de aprendizagem com poucas linhas de c\u00f3digo.","02e5c24d":"Como m\u00e9todo de aprendizagem, vamos considerar os vizinhos pr\u00f3ximos: k-NN. Os m\u00e9todos de aprendizagem, assim como v\u00e1rias fun\u00e7\u00f5es de fluxo de aprendizado de m\u00e1quina dentro do Scikit-Learn herdam classes que t\u00eam as seguintes funcionalidades: fit, transform, fit_transform.\n\n* Fit: Serve para ajustar um modelo aos dados\n* Transform: Serve para ajustar os dados a um modelo\n* Fit_Transform: Faz os dois anteriores de uma vez s\u00f3","52ed1134":"# Exerc\u00edcios\n\n### (1) Recarregue os dados da \u00cdris, divida o conjunto metade para treino e metade para teste. Em seguida, aplique o algoritmo KNN e verifique qual foi a acur\u00e1cia obtida.","26453e85":"Al\u00e9m do atributo *target_names*, a fun\u00e7\u00e3o *load_iris()* traz muitas informa\u00e7\u00f5es e o pr\u00f3prio conjunto de dados. A seguir, \u00e9 mostrado como acessar os atributos e as classes, bem como informa\u00e7\u00f5es estat\u00edsticas da base.","9ee22f19":"O resultado de acur\u00e1cia em 96% \u00e9 bastante expressivo normalmente, mas na base Iris \u00e9 um resultado simplesmente satisfat\u00f3rio. Isso porque a base Iris \u00e9 para prop\u00f3sitos did\u00e1ticos e facilmente 'separ\u00e1vel', ent\u00e3o muitas configura\u00e7\u00f5es e mesmo outros tipos de divis\u00e3o v\u00e3o levar a resultados similares.\n\nAlgo importante de ser analisado, e bastante facilitado pelo Scikit-Learn, \u00e9 o acerto e erro por classe. Para isso, \u00e9 utilizada a matriz de confus\u00e3o. Na forma mais simples, ela pode ser representada pela fun\u00e7\u00e3o *confusion_matrix* . Um exemplo retirado da documenta\u00e7\u00e3o do Scikit-Learn permite uma visualiza\u00e7\u00e3o mais agrad\u00e1vel. Ambos exemplos s\u00e3o dados a seguir.","7734a587":"## Carregando os dados prontos do Scikit-Learn\n\nA biblioteca tamb\u00e9m conta com algumas bases de dados cl\u00e1ssicas embutida dentro de sua implementa\u00e7\u00e3o, portanto sem a necessidade de fazer download de arquivos externos. Essas bases est\u00e3o dispon\u00edveis no m\u00f3dulo sklearn.datasets. A seguir, a base de dados IRIS \u00e9 carregada:","6716d891":"### (2) Ainda com os dados separados metade a metade, analise quais par\u00e2metros do KNN podem ser modificados e se eles melhoram o resultado de acur\u00e1cia. Procure mais informa\u00e7\u00f5es na documenta\u00e7\u00e3o do Scikit-Learn."}}