{"cell_type":{"62bc467c":"code","15aaedb7":"code","79abe44d":"code","276ee297":"code","cd5cb75a":"code","7506f01f":"code","e69f2c9e":"code","367b4fe8":"code","fc5be7fb":"code","1bea7f0e":"code","caebabaf":"code","15fcf4ef":"code","e5565a13":"code","7fe462a7":"code","9d30133d":"code","ff9c45a4":"code","12d8356b":"code","b703d071":"code","1beee3bb":"markdown","60179466":"markdown","1643696f":"markdown","71e88d69":"markdown","51731c7b":"markdown","1d6b1444":"markdown","50b1498c":"markdown","2c286c5d":"markdown","e606262c":"markdown","a16c6037":"markdown","ae704b61":"markdown"},"source":{"62bc467c":"import pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport time","15aaedb7":"FOLDER = '\/kaggle\/input\/'\nIMAGES = FOLDER + 'train_images\/'\nprint(os.listdir(FOLDER))","79abe44d":"df_train = pd.read_csv(FOLDER + 'train.csv')\ndf_train_idx = df_train.set_index(\"image_id\")\nidx_train = df_train['image_id']\nunicode_map = {codepoint: char for codepoint, char in pd.read_csv(FOLDER + 'unicode_translation.csv').values}","276ee297":"def label_reader(label):\n    try:\n        code_arr = np.array(label['labels'].split(' ')).reshape(-1, 5)\n    except:\n        return\n    return code_arr","cd5cb75a":"idx = idx_train[0]\ndf_code = pd.DataFrame(label_reader(df_train_idx.loc[idx]))\ndf_code['image_id'] = idx\ndf_code.columns = ['char', 'x', 'y', 'w', 'h', 'image_id']\ndf_code[['x', 'y', 'w', 'h']] = df_code[['x', 'y', 'w', 'h']].astype('int')","7506f01f":"def get_center(coord):\n    return np.vstack([coord[:, 0] + coord[:, 2] \/\/2, coord[:, 1] + coord[:, 3] \/\/2]).T","e69f2c9e":"coord = df_code.query('image_id == \"{}\"'.format(idx))[['x', 'y','w','h']].values\ncenters =get_center(coord)","367b4fe8":"image_path = IMAGES + idx + '.jpg'\nimg = cv2.imread(image_path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.scatter(centers[:,0], centers[:,1])\nplt.imshow(img)\nplt.show()","fc5be7fb":"from sklearn.cluster import KMeans","1bea7f0e":"def get_cluster_n(centers, min_n=3, max_n=10):\n    stds_list = []\n    for n in range(min_n, max_n):\n        X = centers.copy()\n        X[:, 1] = X[:, 1]\/100\n\n        df_center = pd.DataFrame(centers)\n        df_center['col_n'] = KMeans(n_clusters=n).fit(X).labels_\n        stds_list.append(df_center.groupby('col_n').std().mean().values)\n\n    stds = np.array(stds_list)\n    xsm = np.log(stds[:,0])\n    n_xsm = np.argmin(xsm[1:] - xsm[:-1]) + 1\n    \n    return n_xsm + min_n","caebabaf":"get_cluster_n(centers)","15fcf4ef":"n = get_cluster_n(centers)\nX = centers.copy().astype('float')\nX[:, 1] = X[:, 1]\/100\ndf_center = pd.DataFrame(centers)\ndf_center['col_n'] = KMeans(n_clusters=n).fit(X).labels_\ncols = df_center['col_n'].unique()\nfor col in cols:\n    temp = df_center.query('col_n == {}'.format(col))\n    plt.scatter(temp[0], temp[1])\n    plt.imshow(img)\nplt.show()","e5565a13":"df_center['char'] = df_code.query('image_id == \"{}\"'.format(idx))['char'] # add unicode\ncols = df_center.sort_values(0, ascending=False)['col_n'].unique() # sort by center_x because clustering labels are random.\nchars = []\nfor col in cols:\n    chars.extend(df_center.query('col_n == {}'.format(col)).sort_values(1)['char'].replace(unicode_map))\n    chars.append(' ')","7fe462a7":"string = ''\nfor c in chars:\n    string += c","9d30133d":"string","ff9c45a4":"def gen_df_code(df_idx, idx):\n    df_code = pd.DataFrame(label_reader(df_idx.loc[idx]), columns = ['char', 'x', 'y', 'w', 'h'])\n    df_code['image_id'] = idx\n    df_code = df_code.reset_index()\n    df_code[['x','y','w','h']] = df_code[['x','y','w','h']].astype('int')\n\n    centers = get_center(df_code[['x','y','w','h']].values)\n    df_code[['center_x', 'center_y']] = pd.DataFrame(centers)\n\n    X = centers.copy().astype('float')\n    X[:, 1] = X[:, 1]\/100\n    df_code['col_n'] =  KMeans(n_clusters=get_cluster_n(centers)).fit(X).labels_\n    \n    new_col_n = np.zeros(0)\n    new_index = np.zeros(0)\n    cols = df_code.sort_values('center_x', ascending=False)['col_n'].unique()\n    for i, col in enumerate(cols):\n        temp = df_code.query('col_n == {}'.format(col))\n        new_index = np.hstack([new_index, temp['index'].values])\n        new_col_n = np.hstack([new_col_n, np.ones(len(temp)) * i])\n\n    del df_code['col_n']\n    df_new_idx = pd.DataFrame([new_index, new_col_n]).T\n    df_new_idx.columns = ['index', 'col_n']\n    df_code = pd.merge(df_code, df_new_idx, on='index').sort_values('col_n').reset_index(drop=True)\n    del df_code['index']\n    df_code['col_n'] = df_code['col_n'].astype('int')\n\n    return df_code","12d8356b":"def gen_string(df_code):\n    cols = df_code['col_n'].unique()\n    chars = []\n    for col in cols:\n        chars.extend(df_code.query('col_n == {}'.format(col)).sort_values('center_y')['char'].replace(unicode_map))\n        chars.append(' ')\n\n    string = ''\n    for c in chars:\n        string += c\n\n    print(string)","b703d071":"for idx in tqdm(idx_train[:40]):\n    df_code = gen_df_code(df_train_idx, idx)\n    gen_string(df_code)\n\n    image_path = IMAGES + idx + '.jpg'\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    cols = df_code['col_n'].unique()\n    for col in cols:\n        centers = df_code.query('col_n == {}'.format(col))[['center_x','center_y']].values\n        plt.scatter(centers[:,0], centers[:,1])\n    plt.imshow(img)\n    plt.show()","1beee3bb":"### convert box coordinate to center coordinate\n\nCharactors order may be important to predict charactors, not only from those shape. Becuase our task is not a simple object detection, charactors are wrote seamlessly.\n\nmy idea is to order charactors at first, focusing those center. These can be obtained by converting coordinate as below.","60179466":"###  k-mean clustering for each column\nit looks easy to cluster the columns if we find num of clusters. However, num of columns is different for each document. I'd like to casually use k-mean method, but num of cluster muse be specified before applying the method. \n\nMy simple idea is below\n- Transverse variance in the same columns might be small and the variance between columns might be large. \n- Longitudinal distance is small compered to transverse distance. \n- It's bclustering for each column \netter to get longitudinal scale small which means shrinking columns to split cluster transverse-wise easily.\n\nAccodring to above, several k-mean clusterings are carried out for searching for better num of clusters. Idea for the function is that difference of SD shall be large when column clustering get to be successfull while searching n_clusters from small number.","1643696f":"## generalize above\nGeneralizing can be done easily, with iteration of 'image_id' below. However, the splitting columns is not successfull, such as '100241706_00007_2'\n\nI need more sophisticated clustering method..","71e88d69":"# order charactors by clustering columns ","51731c7b":"Hello, kagglers!\n\nMy idea for dealing with the task is ordering charactors at first. Because sequences of charactors are seamless which means orders can help us to predict charactors from its relations. \n\nJapanese sentences can be wrote longitudinal (from up-right to down left). Columns could possibly  clustered and ordered then charactors are ordered one-dimensional.\n\nFirst image '100241706_00004_2.jpg' is successful as below. \n\n'\u81ea\u5e8f \u82e5\u3044\u6642\u306e\u6c17\u5f37\u306b\u5df1\u3084\u308c\u3068\u601d\u3075 \u305f\u7d30\u5de5\u3082\u8001\u6b66\u8005\u306e\u304b\u306a\u3057\u3055\u306f \u606f\u5b50\u306b\u53ca\u305a\u6d6e\u4e16\u3092\u88cf\u306e\u4e09\u7573\u306b \u907f\u3066\u6b63\u98a8\u306e\u4ff3\u8ae7\u3092\u697d\u3057\u3081 \u3069\u3082\u6839\u304c\u8077\u4eba\u306e\u6587\u76f2\u3060\u3051\u3053\u305d\u3051\u308c '\n\nHowever, generalization of this pipeline has something wrong. In this trial, 3 documents in 10 was not successful. In addition, execution time for this pipeline is long.\n\nI keep going to get more sophisticated clustering.\n\n(20190820) I found better solution. With the solution, 19 in 20 seem to be successful. Now, we can get orders of charactors and use them for learning.","1d6b1444":"It's difficult to understand this poem, even though I'm a Japanese.\n\nThe meaning may be below,????\n\n\"Looking back. how sad old warrior feels, even though he'd considered he was strong in his young, is strong as he is craftsman-like and\u3000illiteracy even though he has fun from ideal poem behind his son.\"\n\nIt's diffcult...","50b1498c":"###  load data","2c286c5d":"let's show coordinate the centers. As you know, Japanese sentences can be wrote 'columns-wise' which is red from up-right to down-left, especially in historical documents.","e606262c":"### split unicode and coordinate\nlabels are aligned as 'unicode, x, y, w, t, unicode, x, y, w, h,,,' which can be reshaped matrix (num_char, (code, pos(4-dim))) or (-1, 5)","a16c6037":"## index\n- load data\n- split unicode and coordinate\n- convert box coordinate to center coordinate\n- k-mean clustering for each column\n- generate full sentence string\n- generalize above","ae704b61":"### generate full sentence string\n\nLooks good. Total 6 columns are there in this document, including title column. The we can get ordered string as a sentence."}}