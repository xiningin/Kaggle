{"cell_type":{"2929fd91":"code","e1f92242":"code","b6942be8":"code","cda1855c":"code","2e3768a0":"code","b2561155":"code","e5722313":"code","3c707fb4":"code","7a7f2c67":"code","a583e3dd":"code","15c3ebd4":"code","decb8daa":"code","1354793d":"code","df11973c":"code","275901d8":"code","79dfdb68":"code","fb7141c5":"code","4be5ae81":"code","606fe7b0":"code","b6f40eeb":"code","ee0861d4":"code","f8fb792a":"code","5ee00de1":"code","71b0e55f":"code","02a3096a":"code","3c5c6fb3":"code","45dc9e9c":"code","f159dc0f":"code","fcf88aff":"code","2ecf7327":"code","17f34b76":"code","dda1fd23":"code","53fc73a0":"code","05b6c088":"code","08b64b36":"code","f3c1bb2a":"code","3138630d":"code","a2158575":"code","9da44570":"code","3bed288d":"code","1ee4dcf0":"code","c5d2767a":"code","762807af":"code","0e2647f6":"code","e08453c8":"code","4d320c25":"code","f258be3e":"code","b821234f":"code","24a74b0b":"markdown","fdd6de72":"markdown","58b0b59d":"markdown","f99918df":"markdown","22c49965":"markdown","12cefbf5":"markdown","ec1f9f69":"markdown","0f977d38":"markdown","540f8439":"markdown","a9beb9ce":"markdown","3bb1cbb4":"markdown","e10e21b1":"markdown","52539fa1":"markdown","8f15f0b7":"markdown","1fbe4ead":"markdown","dcfa1dd4":"markdown","bdc363be":"markdown","a0bb7fb6":"markdown","32545816":"markdown","ce8584e5":"markdown","394fc4d7":"markdown","a2b66f3f":"markdown","59177b77":"markdown","9bc56716":"markdown","87008ff3":"markdown","1deca927":"markdown","11f855e8":"markdown","d64d9650":"markdown","6ad8397a":"markdown","92e3c638":"markdown","9047e8e4":"markdown","956537d8":"markdown"},"source":{"2929fd91":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n\n# machine learning\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import preprocessing\n\n%matplotlib inline\n\nplt.style.use('seaborn-dark-palette')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e1f92242":"%time data = pd.read_csv('..\/input\/lok-sabha-election-candidate-list-2004-to-2019\/LokSabha2004.csv')","b6942be8":"missing = (data.isnull().sum())","cda1855c":"type(missing[missing>0])","2e3768a0":"data","b2561155":"data.describe()","e5722313":"data.info()","3c707fb4":"data.shape","7a7f2c67":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    missing_data['Types'] = types\n    return(np.transpose(missing_data))","a583e3dd":"%%time\nmissing_data(data)","15c3ebd4":"data['Winner'].value_counts()","decb8daa":"\nplt.figure(figsize=(10,6))\nsns.countplot('Winner', data=data, palette='Set3')\nplt.xticks(rotation=90)\nplt.title('Winner Count',fontsize=20)\nplt.ylabel('Count',fontsize=16)\nplt.xlabel('Winner?',fontsize=16)","1354793d":"def build_wordcloud(df, title):\n    wordcloud = WordCloud(\n        background_color='black', \n        stopwords=set(STOPWORDS), \n        max_words=100, \n        max_font_size=40, \n        random_state=666\n    ).generate(str(df))\n\n    fig = plt.figure(1, figsize=(15,15))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","df11973c":"build_wordcloud(data['Candidate'], 'Prevalent words in Name for all dataset')","275901d8":"temp = data['Party'].value_counts().head(20)","79dfdb68":"plt.figure(figsize=(10,6))\nsns.barplot(x=temp.index, y=temp.values, palette='Set3')\nplt.xticks(rotation=90)\nplt.title('Number of Seats Contested by PARTIES (TOP 20)',fontsize=20)\nplt.ylabel('Number of Seats',fontsize=16)\nplt.xlabel('Political Parties',fontsize=16)","fb7141c5":"data = data.fillna(0)","4be5ae81":"data.drop(['Candidate'], axis=1, inplace=True)","606fe7b0":"data","b6f40eeb":"data[\"Party\"] = data[\"Party\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Party\"],prefix=\"Party\")","ee0861d4":"data[\"Education\"] = data[\"Education\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Education\"],prefix=\"Education\")","f8fb792a":"data[\"Constituency\"] = data[\"Constituency\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Constituency\"],prefix=\"Constituency\")","5ee00de1":"data['Gender'] = data['Gender'].map({'M':1, 'F':0})","71b0e55f":"X = data.copy().drop('Winner', axis=1)\ny = data['Winner']","02a3096a":"X_scaled = preprocessing.scale(X)","3c5c6fb3":"X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.3)\nX_train.shape, Y_train.shape, X_test.shape","45dc9e9c":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_test, Y_test)\nknn_accuracy","f159dc0f":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, knn_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","fcf88aff":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, knn_Y_pred))","2ecf7327":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_test, Y_test)\ndecision_tree_accuracy","17f34b76":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, decision_tree_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","dda1fd23":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, decision_tree_Y_pred))","53fc73a0":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_test, Y_test)\nsvc_accuracy","05b6c088":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, svm_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","08b64b36":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, svm_Y_pred))","f3c1bb2a":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=1000)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_test, Y_test)\nrandom_forest_accuracy","3138630d":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, random_forest_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","a2158575":"\n# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, random_forest_Y_pred))","9da44570":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\ngaussian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_test, Y_test)\ngaussian_accuracy","3bed288d":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, gaussian_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","1ee4dcf0":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, gaussian_Y_pred))","c5d2767a":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_test, Y_test)\nsgd_accuracy","762807af":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, sgd_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","0e2647f6":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, sgd_Y_pred))","e08453c8":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_test, Y_test)\nlinear_svc_accuracy","4d320c25":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, linear_svc_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","f258be3e":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, linear_svc_Y_pred))","b821234f":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Linear SVC', 'Decision Tree','Random Forest', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes'],\n    'Score': [svc_accuracy, knn_accuracy, linear_svc_accuracy, decision_tree_accuracy, random_forest_accuracy, sgd_accuracy, gaussian_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","24a74b0b":"<a id='library'><\/a>\n# Import Required Libraries\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","fdd6de72":"Let's check information of the dataset.","58b0b59d":"## Party Analysis","f99918df":"## Stochastic Gradient Descent Classifier","22c49965":"## Name wordcloud","12cefbf5":"## Data contains:\n- **Candidate** - Name of the Candidate.\n- **Party** - Policatical Party.\n- **Criminal Cases** - Criminal Cases against candidate.\n- **Education** - Education of candidate.\n- **Age** - Age of candidate.\n- **Total Assets** - Total assets of candidate.\n- **Constituency** - Name of constituency from candidate stand in election.\n- **Liabilities** - Total Liabilities of candidate.\n- **Winner** - Does candidate won in election that year? (0 - No, 1- Yes)\n- **Gender** - Gender of candidate. (M-Male, F-Female)","ec1f9f69":"Let's check statistics of data.","0f977d38":"Let's glimpse at dataset.","540f8439":"## Gaussian Naive Bayes Classifier","a9beb9ce":"## SVM Classifier","3bb1cbb4":"Let's check shape of the dataset.","e10e21b1":"# Load Dataset","52539fa1":"We have 260 missing\/NaN values in Total Assest. I will decide what to do with this value after data analysis. ","8f15f0b7":"## KNN Classifier","1fbe4ead":"We make few observation here:\n- In `age` feature we can see minimum value is `Zero (0)`, which is wrong we might have some wrong values. In data analysis part I will decide what to do with this candidates.\n- We have max 36 criminal cases value and lowest is zero. This feature probably help in prediction.","dcfa1dd4":"# Exploring important features","bdc363be":"# Model Prediction","a0bb7fb6":"## Check the data","32545816":"Let's check if there is any missing value in the data.","ce8584e5":"<a id='introduction'><\/a>\n# Introduction\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","394fc4d7":"## Decision Tree Classifier","a2b66f3f":"<font color='blue' size=6> 2004 Lok Sabha Candidate Winner Prediction<\/font>\n<hr\/>\n<font size=2> - Durgesh Samariya | The ML PhD Student <\/font>\n","59177b77":"<font color='slateblue' size=+2.5> The Class Variable; Winner\n    <\/font>","9bc56716":"# Data exploration","87008ff3":"## Linear SVM Classifier","1deca927":"# Feature Mapping","11f855e8":"<font color='red' size=5><center>Please Upvote my kernel if you like my work.<\/center><\/font>","d64d9650":"## Random Forest Classifier","6ad8397a":"We have 3642 samples in dataset and 10 features.","92e3c638":"Let's load `LokSabha2004.csv` file.","9047e8e4":"In 2004, total 3642 candidates participated in election. However 388 won the election and 3254 lose.","956537d8":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:MediumSeaGreen; border:0' role=\"tab\" aria-controls=\"home\"><center>Table of Content<\/center><\/h1>\n\n- [1. Introduction](#introduction)\n- [2. Import Required Libraries](#library)"}}