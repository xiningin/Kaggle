{"cell_type":{"e9f9f74d":"code","83917ad5":"code","ec4931c2":"code","8f0b1306":"code","04e27084":"code","de38ae27":"code","815fcde6":"code","d43a4726":"code","f1177b2b":"code","a7db6659":"code","6cb1e514":"code","d28eb21d":"code","d121b57f":"code","f06ed19f":"code","45a642ee":"code","2df328dc":"code","b71a8b9d":"code","dd20b6cb":"code","1f847947":"code","7e6b2aa0":"code","c60473e4":"code","a9f0a172":"code","c3f80d11":"code","67d4670c":"code","afef707d":"code","90c833dd":"code","03e8fd47":"code","dbc20729":"code","a5f2ab73":"code","2ece7de7":"code","a60696a1":"code","a89b00e1":"code","cb99de07":"code","99ff54cc":"code","0e7b8205":"code","22db7275":"code","34cf2cda":"code","06ca788f":"code","309b757e":"code","6cbb3045":"code","37a5d0bf":"code","44705121":"code","2ef117ba":"code","66e99cf6":"code","84112f2c":"code","3670911e":"code","d76f59da":"code","1a78ecf3":"code","c334ae4f":"code","3224fdf1":"code","e0ff1398":"code","1c6fa170":"code","2e220999":"code","437636c0":"code","359341a2":"code","d1310630":"code","7738bb65":"code","66a8ae7a":"code","2f895449":"code","ef51e7b3":"code","8efbb618":"code","989b3cae":"code","4d306e8a":"code","db855737":"code","6a83d4e0":"code","580014e0":"code","9471a577":"code","c8870342":"code","c98b1e71":"code","148fd740":"code","6cf4bf0c":"markdown","6dd57c44":"markdown","7c53c131":"markdown","d2018a8b":"markdown","60b59f09":"markdown","e82370c0":"markdown","2ec64607":"markdown","d4107527":"markdown","5c099813":"markdown","6e4d968d":"markdown","032d4862":"markdown","c83ba2f2":"markdown","4ab4839f":"markdown","359665d9":"markdown"},"source":{"e9f9f74d":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai import *\nfrom fastai.text import *","83917ad5":"# bs=48\n# bs=24\nbs=128","ec4931c2":"import torch\ntorch.cuda.device_count()\ntorch.cuda.set_device(0)","8f0b1306":"# Utilizei para copiar o dataset da folha de SP da pasta input (read-only) para a pasta working\n#import os\n#!cp -r '..\/input\/news-of-the-site-folhauol\/' '..\/working'\n#print(os.listdir(\"..\/working\/news-of-the-site-folhauol\"))","04e27084":"lang = 'pt'\nname = f'{lang}News'\ndata_path = \"..\/input\/news-of-the-site-folhauol\"\npath = data_path\nlm_fns = [f'{lang}_wt', f'{lang}_wt_vocab']","de38ae27":"#Monta um databunch a partir do dataset da folha\n#data = (TextList.from_csv(path,'articles.csv')\n#            .split_by_rand_pct(0.1, seed=42)\n#            .label_for_lm()           \n#            .databunch(bs=bs, num_workers=1))\n#len(data.vocab.itos),len(data.train_ds),len(data.valid_ds)","815fcde6":"# Demonstra como salvar e carregar o databunch\n#data.save(f'{lang}_databunch')\n#data = load_data(path, f'{lang}_databunch', bs=bs)","d43a4726":"#Cria um learn model a partir do databunch \n# Destaque para o par\u00e2metro pretrained=False demonstrando que n\u00e3o existe um pr\u00e9-treinamento\n#learn = language_model_learner(data, AWD_LSTM, drop_mult=0.5, pretrained=False).to_fp16()","f1177b2b":"#Ajusta a learning rate, descongela as camadas e roda 10 vezes o primeiro ciclo \n#lr = 1e-2\n#lr *= bs\/48  # Scale learning rate by batch size\n\n#learn.unfreeze()\n#learn.fit_one_cycle(10, lr, moms=(0.8,0.7))","a7db6659":"#Criamos a pasta models\n#mdl_path = path+'\/models'\n#os.mkdir(mdl_path)\n#print(os.listdir(path))","6cb1e514":"# Salvamos pt_wt na pasta models\n#fileName = lm_fns[0]\n#learn.to_fp32().save(fileName, with_opt=False)\n#print(os.listdir(path+'\/models'))","d28eb21d":"# Salvamos pt_wt_vocab.pkl na pasta models\n#fileName = path +'\/models\/'+ lm_fns[1] + '.pkl'\n#print (fileName)\n#learn.data.vocab.save(fileName)\n#print(os.listdir(path+'\/models'))","d121b57f":"#Carrega o dataset do olist da pasta input\nfrom pandas import read_csv\ndf = read_csv('..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv')","f06ed19f":"#transforma nas colunas que representam tempo string para timestamp \ndf['review_creation_date'] =  pd.to_datetime(df['review_creation_date'])\ndf['review_answer_timestamp'] = pd.to_datetime(df['review_answer_timestamp'])","45a642ee":"#transforma o review score em categorias\ndf['sentimento'] = pd.cut(df['review_score'],[0,2,3,5],labels=['negativo','neutro','positivo'])","2df328dc":"#Cria um nova coluna 'text' a partir do t\u00edtulo e da mensagem dos coment\u00e1rios\nx = []\n\nfor i in zip(df['review_comment_title'],df['review_comment_message']):\n  x.append(str(i[0]) + ' ' + str(i[1]))\n\ndf['text'] = x","b71a8b9d":"#Retira alguns colunas que n\u00e3o ser\u00e3o utilizadas\ndf.drop(['review_id','order_id','review_score','review_answer_timestamp','review_comment_title','review_comment_message'],axis=1,inplace=True)","dd20b6cb":"#Balanceamento dos coment\u00e1rios positivos, neutros e negativos\ndf_nn = df[(df.sentimento == 'negativo')|(df.sentimento == 'neutro')]\ndf_pos = df[(df.sentimento == 'positivo')&(df.text != 'nan nan')].reset_index(drop=True).iloc[np.random.permutation(np.arange(11500)),:]\ndf_final = pd.concat([df_nn,df_pos])\ndf_final = df_final[df_final.text != 'nan nan'].copy().reset_index(drop=True)","1f847947":"#Cria uma coluna text_tratado aplicando as substitucioes definadas no metodo pre_process\ndef pre_process(texto):\n  texto = texto.replace(' nan ','')\n  texto = texto.replace('nan ','')\n  texto = texto.replace(' nan','')\n  texto = re.sub('\\r',' ',texto)\n  texto = re.sub('\\n',' ',texto)\n  texto = re.sub(',',' ',texto)\n  texto = re.sub('\\.',' ',texto)\n  texto = re.sub('\\?',' ',texto)\n  texto = re.sub('\\!',' ',texto)\n  texto = re.sub('\\;',' ',texto)\n  return texto\n\ndf_final['text_tratado'] = df_final.text.apply(pre_process)","7e6b2aa0":"# Cria a pasta models e transfere os arquivos que representam o modelo pr\u00e9-treinado da folha de SP \nimport os\nprint(os.listdir('..\/input\/portuguesenewsulmfit\/'))\nos.mkdir('..\/working\/models\/')\nos.system(\"mv ..\/input\/portuguesenewsulmfit\/* ..\/working\/models\/\")\nprint(os.listdir('..\/working\/models\/'))","c60473e4":"#Cria um databunch do dataset do Olist\npath = '..\/working'\ndata_lm = (TextList.from_df(df_final, path, cols='text_tratado')\n    .split_by_rand_pct(0.1, seed=42)\n    .label_for_lm()           \n    .databunch(bs=bs, num_workers=1))","a9f0a172":"#Cria um learner model a partir do databunch do Olist e do learner model anterior da Folha ( pretrained_fnames=lm_fns )\nlm_fns = ['pt_wt', 'pt_wt_vocab']\nlearn_lm = language_model_learner(data_lm, AWD_LSTM, pretrained_fnames=lm_fns, drop_mult=1.0)","c3f80d11":"#Ajusta a learning rate e roda 2 vezes o primeiro ciclo do modelo\nlr = 1e-3\nlr *= bs\/48\nlearn_lm.fit_one_cycle(2, lr*10, moms=(0.8,0.7))","67d4670c":"#Descongela o modelo e roda 8 vezes o primeiro ciclo \n# Destaque para a learning rate que n\u00e3o est\u00e1 multiplicada por 10 dessa vez\nlearn_lm.unfreeze()\nlearn_lm.fit_one_cycle(8, lr, moms=(0.8,0.7))","afef707d":"#Salva os arquivos que representam o learner model\nlearn_lm.save(f'{lang}fine_tuned')\nlearn_lm.save_encoder(f'{lang}fine_tuned_enc')","90c833dd":"#Salva o vocabulario\nfileName = '..\/working\/models\/'+ f'{lang}fine_tuned_vocab' + '.pkl'\nlearn_lm.data.vocab.save(fileName)\nprint(os.listdir('..\/working\/models'))","03e8fd47":"print(path)","dbc20729":"#Para criar o classificar passa como par\u00e2metros: \n# dataframe do Olist\n# caminho para a pasta onde se encontra a pasta models\n# vocabulario ja treinado com o Olist\n# Coluna que sera classificada no caso 'text_tratado'\n# Coluna que representa a classificacao no caso coluna 'sentimento'\ndata_clas = (TextList.from_df(df_final, path, vocab=data_lm.vocab, cols='text_tratado')\n    .split_by_rand_pct(0.1, seed=42)\n    .label_from_df(cols='sentimento')\n    .databunch(bs=bs, num_workers=1))","a5f2ab73":"#Demonstra como salvar o classificador e depois carreg\u00e1-lo novamente\ndata_clas.save(f'{lang}_textlist_class')\ndata_clas = load_data(path, f'{lang}_textlist_class', bs=bs, num_workers=1)","2ece7de7":"#Define o metodo que sera utilizado para comparar a precision and recall\nfrom sklearn.metrics import f1_score\n@np_func\n# No notebook nn-vietnamese.ipynb n\u00e3o foi passado valor para o parametro average \n# Portanto estava sendo utilizado o valor default \"binary\", \n# por\u00e9m como a label \u00e9 multiclass 'positivo', 'neutro' e 'negativo' nao podia ser \"binary\"\n# As op\u00e7\u00f5es dispon\u00edveis para esse parametro estao descritas aqui \n#https:\/\/en.wikipedia.org\/wiki\/F1_score\n\ndef f1(inp,targ): return f1_score(targ, np.argmax(inp, axis=-1), average='micro')","a60696a1":"#Cria um modelo a partir do classificador\n#Nao entendi pq tem que se conectar na internet para baixar um arquivo wt103\nlearn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics=[accuracy,f1]).to_fp16()\nlearn_c.load_encoder(f'{lang}fine_tuned_enc')\nlearn_c.freeze()","a89b00e1":"#Redefine a learning rate e roda duas vezes o primeiro ciclo \nlr=2e-2\nlr *= bs\/48\nlearn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))","cb99de07":"learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))","99ff54cc":"learn_c.freeze_to(-2)\nlearn_c.fit_one_cycle(2, slice(lr\/(2.6**4),lr), moms=(0.8,0.7))","0e7b8205":"learn_c.freeze_to(-3)\nlearn_c.fit_one_cycle(2, slice(lr\/2\/(2.6**4),lr\/2), moms=(0.8,0.7))","22db7275":"learn_c.unfreeze()\nlearn_c.fit_one_cycle(1, slice(lr\/10\/(2.6**4),lr\/10), moms=(0.8,0.7))","34cf2cda":"learn_c.save(f'{lang}clas')","06ca788f":"bs=128\nlang = 'pt'\nlm_fns = [f'{lang}_wt_bwd', f'{lang}_wt_vocab_bwd']\npath = \"..\/working\/\"","309b757e":"!cp '..\/input\/news-of-the-site-folhauol\/articles.csv' '..\/working'\nprint(os.listdir(\"..\/working\/\"))","6cbb3045":"#Monta um databunch a partir do dataset da folha\n# S\u00f3 que agora de tr\u00e1s para frente\ndata = (TextList.from_csv(path,'articles.csv')\n            .split_by_rand_pct(0.1, seed=42)\n            .label_for_lm()           \n            .databunch(bs=bs, num_workers=1, backwards=True))\nlen(data.vocab.itos),len(data.train_ds),len(data.valid_ds)","37a5d0bf":"data.save(f'{lang}_databunch_bwd')","44705121":"data = load_data(path, f'{lang}_databunch_bwd', bs=bs, backwards=True)","2ef117ba":"#Cria um learn model a partir do databunch \n# Destaque para o par\u00e2metro pretrained=False demonstrando que n\u00e3o existe um pr\u00e9-treinamento\nlearn = language_model_learner(data, AWD_LSTM, drop_mult=0.5, pretrained=False).to_fp16()","66e99cf6":"#Ajusta a learning rate, interessante que na primeira vez\n# foi utilizado lr = 1e-2\nlr = 3e-3\nlr *= bs\/48  # Scale learning rate by batch size","84112f2c":"learn.unfreeze()\nlearn.fit_one_cycle(10, lr, moms=(0.8,0.7))","3670911e":"# Cria a pasta models, se ela j\u00e1 n\u00e3o existir\nmdl_path = path+'models'\nos.mkdir(mdl_path)\nprint(os.listdir(path))","d76f59da":"# Salvamos pt_wt na pasta models\nfileName = lm_fns[0]\nlearn.to_fp32().save(fileName, with_opt=False)\nprint(os.listdir(path+'\/models'))","1a78ecf3":"# Salvamos pt_wt_vocab_bwd.pkl na pasta models\nfileName = path +'\/models\/'+ lm_fns[1] + '.pkl'\n#print (fileName)\nlearn.data.vocab.save(fileName)\nprint(os.listdir(path+'\/models'))","c334ae4f":"#Cria um databunch do dataset do Olist\n#Destaque para o backwards=True para dizer que agora \u00e9 de tr\u00e1s para frente \npath = '..\/working'\ndata_lm = (TextList.from_df(df_final, path, cols='text_tratado')\n    .split_by_rand_pct(0.1, seed=42)\n    .label_for_lm()           \n    .databunch(bs=bs, num_workers=1,backwards=True))","3224fdf1":"#Cria um learner model a partir do databunch do Olist e do learner model BWD da Folha ( pretrained_fnames=lm_fns )\nlang = 'pt'\nlm_fns = [f'{lang}_wt_bwd', f'{lang}_wt_vocab_bwd']\nlearn_lm = language_model_learner(data_lm, AWD_LSTM, pretrained_fnames=lm_fns, drop_mult=1.0)","e0ff1398":"#Ajusta a learning rate e roda 2 vezes o primeiro ciclo do modelo\nlr = 1e-3\nlr *= bs\/48\nlearn_lm.fit_one_cycle(2, lr*10, moms=(0.8,0.7))","1c6fa170":"#Descongela o modelo e roda 8 vezes o primeiro ciclo \n# Destaque para a learning rate que n\u00e3o est\u00e1 multiplicada por 10 dessa vez\nlearn_lm.unfreeze()\nlearn_lm.fit_one_cycle(8, lr, moms=(0.8,0.7))","2e220999":"#Salva os arquivos que representam o learner model BWD\nlearn_lm.save(f'{lang}fine_tuned_bwd')\nlearn_lm.save_encoder(f'{lang}fine_tuned_enc_bwd')","437636c0":"#Salva o vocabulario\nfileName = '..\/working\/models\/'+ f'{lang}fine_tuned_vocab_bwd' + '.pkl'\nlearn_lm.data.vocab.save(fileName)\nprint(os.listdir('..\/working\/models'))","359341a2":"#Para criar o classificar passa como par\u00e2metros: \n# dataframe do Olist\n# caminho para a pasta onde se encontra a pasta models\n# vocabulario ja treinado com o Olist\n# Coluna que sera classificada no caso 'text_tratado'\n# Coluna que representa a classificacao no caso coluna 'sentimento'\ndata_clas = (TextList.from_df(df_final, path, vocab=data_lm.vocab, cols='text_tratado')\n    .split_by_rand_pct(0.1, seed=42)\n    .label_from_df(cols='sentimento')\n    .databunch(bs=bs, num_workers=1,backwards=True))","d1310630":"#Demonstra como salvar o classificador e depois carreg\u00e1-lo novamente\ndata_clas.save(f'{lang}_textlist_class_bwd')\ndata_clas = load_data(path, f'{lang}_textlist_class', bs=bs, num_workers=1,backwards=True)","7738bb65":"#Cria um modelo a partir do classificador BWD\n#Nao entendi pq tem que se conectar na internet para baixar um arquivo wt103\nlearn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics=[accuracy,f1]).to_fp16()\nlearn_c.load_encoder(f'{lang}fine_tuned_enc')\nlearn_c.freeze()","66a8ae7a":"#Redefine a learning rate e roda duas vezes o primeiro ciclo \nlr=2e-2\nlr *= bs\/48\nlearn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))","2f895449":"learn_c.fit_one_cycle(2, lr, moms=(0.8,0.7))","ef51e7b3":"learn_c.freeze_to(-2)\nlearn_c.fit_one_cycle(2, slice(lr\/(2.6**4),lr), moms=(0.8,0.7))","8efbb618":"learn_c.freeze_to(-3)\nlearn_c.fit_one_cycle(2, slice(lr\/2\/(2.6**4),lr\/2), moms=(0.8,0.7))","989b3cae":"learn_c.unfreeze()\nlearn_c.fit_one_cycle(1, slice(lr\/10\/(2.6**4),lr\/10), moms=(0.8,0.7))","4d306e8a":"learn_c.save(f'{lang}clas_bwd')","db855737":"print(os.listdir('..\/working'))","6a83d4e0":"data_clas = load_data(path, f'{lang}_textlist_class', bs=bs, num_workers=1)\nlearn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics=[accuracy,f1]).to_fp16()\nlearn_c.load(f'{lang}clas', purge=False);","580014e0":"preds,targs = learn_c.get_preds(ordered=True)\naccuracy(preds,targs),f1(preds,targs)","9471a577":"#utiliza a t\u00e9cnica de ir de tr\u00e1s para frente backwards (bwd)\ndata_clas_bwd = load_data(path, f'{lang}_textlist_class_bwd', bs=bs, num_workers=1, backwards=True)\nlearn_c_bwd = text_classifier_learner(data_clas_bwd, AWD_LSTM, drop_mult=0.5, metrics=[accuracy,f1]).to_fp16()\nlearn_c_bwd.load(f'{lang}clas_bwd', purge=False);","c8870342":"preds_b,targs_b = learn_c_bwd.get_preds(ordered=True)\naccuracy(preds_b,targs_b),f1(preds_b,targs_b)","c98b1e71":"preds_avg = (preds+preds_b)\/2","148fd740":"accuracy(preds_avg,targs_b),f1(preds_avg,targs_b)","6cf4bf0c":"> ## Portuguese News model","6dd57c44":"Na competi\u00e7\u00e3o do vietn\u00e3 os tr\u00eas melhores colocados conseguiram a seguinte pontua\u00e7\u00e3o:\nCompetition top 3 f1 scores: 0.90, 0.89, 0.89. \nO ganhador usou um combinado de 4 modelos: TextCNN, VDCNN, HARNN, and SARNN.\nNo nosso treinamento em portugu\u00eas com a folha de SP e o Olist tivemos um F1 score de 0.796 ","7c53c131":"## Classifica\u00e7\u00e3o de sentimento com o BWD","d2018a8b":"### Create pretrained model","60b59f09":"Save the pretrained model and vocab:","e82370c0":"## ULMFiT from scratch (backwards)","2ec64607":"## Ensemble","d4107527":"Save the pretrained model and vocab:","5c099813":"## Enriquece o learner model BWD com o Olist","6e4d968d":"## Portuguese sentiment analysis","032d4862":"> ### Cria o classificador de sentimentos","c83ba2f2":"# Tratamento do dataset do Olist","4ab4839f":"### Ir\u00e1 explorar a combina\u00e7\u00e3o de mais de uma t\u00e9cnica","359665d9":"> # Portuguese ULMFiT from scratch"}}