{"cell_type":{"3ea9537b":"code","c8f242fd":"code","2434039b":"code","30923a72":"code","8483466d":"code","2488454d":"code","fee4b7c5":"code","a2a1b105":"code","ba2ddf76":"code","c189d2be":"code","ea38e280":"code","c8b67395":"code","314005ec":"code","7f082aa0":"code","98ec1a33":"code","e3f27de2":"code","a0e410d8":"code","5d6a0aa8":"code","9cd1e774":"code","1cefc3df":"code","8681d09e":"code","5c0a8df8":"code","4888b44e":"code","38305a15":"code","14dfec12":"code","5a485bbd":"code","82e5a8b0":"code","7a4d6c35":"code","698d68f7":"code","65e1684d":"code","6076e041":"code","ac14d1c2":"code","824eaf5a":"code","65e9b07a":"code","d94a23a7":"code","de428ce7":"markdown","3d4c2509":"markdown","079be529":"markdown","bae6ca9e":"markdown","645c2981":"markdown","0e98541b":"markdown","42094af5":"markdown","831afd8f":"markdown","8754c83e":"markdown","02296257":"markdown","72e56336":"markdown","a4ac4fe9":"markdown","efcef244":"markdown","8815db70":"markdown","060904c9":"markdown","9e9dae78":"markdown","8d66acee":"markdown","8aae6984":"markdown","23e8e161":"markdown","a269bb56":"markdown","db88cb1d":"markdown","12ccd755":"markdown","da07f5ba":"markdown"},"source":{"3ea9537b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c8f242fd":"from fastai.text import *","2434039b":"#!pip install pytorch-transformers","30923a72":"from pytorch_transformers import BertTokenizer,BertForSequenceClassification","8483466d":"bert_model = \"bert-base-chinese\"\nmax_seq_len = 128\nbatch_size = 32","2488454d":"bert_tokenizer = BertTokenizer.from_pretrained(bert_model)","fee4b7c5":"#len(list(bert_tokenizer.vocab.items()))","a2a1b105":"bert_vocab = Vocab(list(bert_tokenizer.vocab.keys()))","ba2ddf76":"#\u4e3afastai\u521b\u5efa\u4f7f\u7528Bert\u7684Tokenizer\nclass BertFastaiTokenizer(BaseTokenizer):\n    def __init__(self, tokenizer, max_seq_len=128, **kwargs):\n        self.pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n    \n    def __call__(self, *args, **kwargs):\n        return self\n    \n    def tokenizer(self, t):\n        return [\"[CLS]\"] + self.pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]","c189d2be":"tok_func = BertFastaiTokenizer(bert_tokenizer, max_seq_len=max_seq_len)","ea38e280":"bert_fastai_tokenizer = Tokenizer(\n    tok_func=tok_func,\n    pre_rules = [],\n    post_rules = []\n)","c8b67395":"#\u4f7f\u7528BertForSequenceClassification\u6a21\u578b\uff0c\u53ea\u53d6\u7ed3\u679ctuple\u7684\u7b2c\u4e00\u4e2a\u503c\nclass MyNoTupleModel(BertForSequenceClassification):\n    def forward(self, *args, **kwargs):\n        return super().forward(*args, **kwargs)[0]","314005ec":"#BertForSequenceClassification\u9884\u8bad\u7ec3\u6a21\u578b\nbert_pretrained_model = MyNoTupleModel.from_pretrained(bert_model,num_labels=80)","7f082aa0":"!mkdir dataset\n!cp -r \/kaggle\/input\/sentiment-analysis-simplified\/simplified_train.csv \/kaggle\/working\/dataset\/simplified_train.csv\n!cp -r \/kaggle\/input\/sentiment-analysis-simplified\/simplified_valid.csv \/kaggle\/working\/dataset\/simplified_valid.csv","98ec1a33":"train = pd.read_csv(\"\/kaggle\/working\/dataset\/simplified_train.csv\")\nvalid = pd.read_csv(\"\/kaggle\/working\/dataset\/simplified_valid.csv\")\n#test = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis\/dataset\/ai_challenger_sentiment_analysis_testa_20180816\/sentiment_analysis_testa.csv\")","e3f27de2":"path = Path(\".\")","a0e410d8":"label_cols = ['location_traffic_convenience_1',\n 'location_traffic_convenience_0',\n 'location_traffic_convenience_-1',\n 'location_traffic_convenience_-2',\n 'location_distance_from_business_district_1',\n 'location_distance_from_business_district_0',\n 'location_distance_from_business_district_-1',\n 'location_distance_from_business_district_-2',\n 'location_easy_to_find_1',\n 'location_easy_to_find_0',\n 'location_easy_to_find_-1',\n 'location_easy_to_find_-2',\n 'service_wait_time_1',\n 'service_wait_time_0',\n 'service_wait_time_-1',\n 'service_wait_time_-2',\n 'service_waiters_attitude_1',\n 'service_waiters_attitude_0',\n 'service_waiters_attitude_-1',\n 'service_waiters_attitude_-2',\n 'service_parking_convenience_1',\n 'service_parking_convenience_0',\n 'service_parking_convenience_-1',\n 'service_parking_convenience_-2',\n 'service_serving_speed_1',\n 'service_serving_speed_0',\n 'service_serving_speed_-1',\n 'service_serving_speed_-2',\n 'price_level_1',\n 'price_level_0',\n 'price_level_-1',\n 'price_level_-2',\n 'price_cost_effective_1',\n 'price_cost_effective_0',\n 'price_cost_effective_-1',\n 'price_cost_effective_-2',\n 'price_discount_1',\n 'price_discount_0',\n 'price_discount_-1',\n 'price_discount_-2',\n 'environment_decoration_1',\n 'environment_decoration_0',\n 'environment_decoration_-1',\n 'environment_decoration_-2',\n 'environment_noise_1',\n 'environment_noise_0',\n 'environment_noise_-1',\n 'environment_noise_-2',\n 'environment_space_1',\n 'environment_space_0',\n 'environment_space_-1',\n 'environment_space_-2',\n 'environment_cleaness_1',\n 'environment_cleaness_0',\n 'environment_cleaness_-1',\n 'environment_cleaness_-2',\n 'dish_portion_1',\n 'dish_portion_0',\n 'dish_portion_-1',\n 'dish_portion_-2',\n 'dish_taste_1',\n 'dish_taste_0',\n 'dish_taste_-1',\n 'dish_taste_-2',\n 'dish_look_1',\n 'dish_look_0',\n 'dish_look_-1',\n 'dish_look_-2',\n 'dish_recommendation_1',\n 'dish_recommendation_0',\n 'dish_recommendation_-1',\n 'dish_recommendation_-2',\n 'others_overall_experience_1',\n 'others_overall_experience_0',\n 'others_overall_experience_-1',\n 'others_overall_experience_-2',\n 'others_willing_to_consume_again_1',\n 'others_willing_to_consume_again_0',\n 'others_willing_to_consume_again_-1',\n 'others_willing_to_consume_again_-2']","5d6a0aa8":"train.head()\n","9cd1e774":"#batch_size = 2","1cefc3df":"databunch = TextClasDataBunch.from_df(path, train, valid,\n                                     tokenizer=bert_fastai_tokenizer,\n                                     vocab=bert_vocab,\n                                     include_bos=False,\n                                     include_eos=False,\n                                     text_cols=\"simplified_content\",\n                                     label_cols=label_cols,\n                                     bs=batch_size,\n                                     collate_fn=partial(pad_collate,pad_first=False,pad_idx=0)\n                                     )","8681d09e":"#databunch.save()","5c0a8df8":"databunch.show_batch()","4888b44e":"#\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u6bcf4\u4e2a\u6fc0\u6d3b\u503c\u4f5c\u4e3a\u4e00\u7ec4\uff08\u4e00\u4e2a\u7c92\u5ea6\uff09\u8ba1\u7b97CrossEntropyLoss\nclass FineGritLoss(nn.CrossEntropyLoss):\n    __constants__ = ['weight', 'ignore_index', 'reduction']\n    \n    def __init__(self, weight=None, size_average=None, ignore_index=-100,\n                 reduce=None, reduction='mean'):\n        super(FineGritLoss, self).__init__(weight, size_average, reduce, reduction)\n        self.ignore_index = ignore_index\n    \n    def forward(self, input, target):\n        batch_size = input.shape[0]\n        grouped = input.resize(batch_size*20,4)\n        grouped_target = target.resize(batch_size*20,4)\n        target_argmax = grouped_target.argmax(-1)\n        loss = F.cross_entropy(grouped, target_argmax, weight=self.weight,\nignore_index=self.ignore_index, reduction=self.reduction)\n        return loss","38305a15":"#\u81ea\u5b9a\u4e49accuracy\uff0c\u6bcf4\u4e2a\u6fc0\u6d3b\u503c\u4f5c\u4e3a\u4e00\u7ec4\u53d6argmax\u4f5c\u4e3a\u8f93\u51fa\ndef accuracy_f(input:Tensor, targs:Tensor)->Rank0Tensor:\n    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n    n = targs.shape[0]\n    input = input.view(n,20,-1).argmax(dim=-1).view(n,-1)\n    targs = targs.view(n,20,-1).argmax(dim=-1).view(n,-1)\n    return (input==targs).float().mean()","14dfec12":"#\u81ea\u5b9a\u4e49f1 score\uff0c\u6bcf4\u4e2a\u6fc0\u6d3b\u503c\u4f5c\u4e3a\u4e00\u7ec4\u53d6argmax\u4f5c\u4e3a\u8f93\u51fa\ndef f1(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=1, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n    \"Computes the f_beta between `preds` and `targets`\"\n    beta2 = beta ** 2\n    if sigmoid: y_pred = y_pred.sigmoid()\n    n = y_true.shape[0]\n    max_to_zero = y_pred.view(n,20,-1).max(dim=-1).values.view(n,20,1).repeat(1,1,4)-y_pred.view(n,20,-1)\n    y_pred = torch.eq(max_to_zero.cuda(), torch.zeros(n,20,4).cuda()).cuda()\n    #y_pred = torch.eq(max_to_zero, torch.zeros(n,20,4))\n    y_pred = y_pred.float().view(n,-1)\n    \n    y_true = y_true.float()\n    TP = (y_pred*y_true).sum(dim=1)\n    prec = TP\/(y_pred.sum(dim=1)+eps)\n    rec = TP\/(y_true.sum(dim=1)+eps)\n    res = (prec*rec)\/(prec*beta2+rec+eps)*(1+beta2)\n    return res.mean()","5a485bbd":"learn = Learner(databunch,\n               bert_pretrained_model,\n               loss_func=FineGritLoss(),\n               metrics=[accuracy_f,f1])","82e5a8b0":"learn.lr_find()\n","7a4d6c35":"learn.recorder.plot()","698d68f7":"learn.fit_one_cycle(2, 1e-3)","65e1684d":"learn.save('first')","6076e041":"learn.freeze_to(-2)","ac14d1c2":"learn.fit_one_cycle(1, 1e-4)","824eaf5a":"learn.freeze_to(-3)","65e9b07a":"learn.fit_one_cycle(1, 1e-4)","d94a23a7":"learn.predict('\u51fa\u4e4e\u610f\u6599\u5730\u60ca\u8273\uff0c\u6930\u5b50\u9e21\u6e05\u70ed\u964d\u706b\uff0c\u7f8e\u5bb9\u517b\u989c\uff0c\u5927\u5927\u6ee1\u8db3\u4e86\u7231\u5403\u706b\u9505\u6015\u4e0a\u706b\u661f\u4eba\u3002\u6930\u5b50\u51bb\u662f\u5e05\u5e05\u7684\u8001\u677f\u539f\u521b\uff0c\u4e0d\u52a0\u5409\u5229\u4e01\u7247\uff0c\u800c\u662f\u5728\u4e13\u4e1a\u673a\u5668\u53d1\u9175\uff0c\u53ea\u52a0\u6de1\u5976\u6cb9\u548c\u6930\u6c41\uff0c\u8fd8\u662f\u6bcf\u5929\u9650\u91cf\uff1b\u9e21\u8089\u5f88\u5ae9\uff0c\u662f\u4e0d\u5403\u9972\u6599\u7684\u5ae9\u9e21\uff1b\u87f9\u67f3\u592a\u597d\u5403\u4e86\uff0c\u65e5\u672c\u8fdb\u53e3\uff0c\u5f53\u523a\u8eab\u76f4\u63a5\u8638\u9171\u6cb9\u5403\u6bd4\u5728\u9505\u91cc\u716e\u4e86\u8fd8\u597d\u5403\uff0c\u53ef\u89c1\u98df\u6750\u7684\u65b0\u9c9c\uff0c\u518d\u4e5f\u4e0d\u4f1a\u60f3\u5403\u666e\u901a\u706b\u9505\u5e97\u51b0\u9547\u7684\u87f9\u8089\u68d2\u4e86\uff1b\u852c\u83dc\u5f88\u65b0\u9c9c\uff0c\u8001\u677f\u8bf4\u662f\u5728\u5927\u5174\u6709\u852c\u83dc\u56ed\uff1b\u7172\u4ed4\u996d\u4e5f\u662f\u9ad8\u4e8e\u4e00\u822c\u6c34\u5e73\uff0c\u8001\u677f\u8bf4\u9057\u61be\u7684\u662f\u5546\u573a\u53ea\u80fd\u7528\u7535\u7089\uff0c\u4e0d\u80fd\u7528\u4f20\u7edf\u505a\u6cd5\u3002\u6700\u540e\uff0c\u5b89\u5229\u4e00\u4e0b\u8001\u677f\uff0c\u539f\u6765\u662f\u897f\u9910\u53a8\u5e08\uff0c\u770b\u5f97\u51fa\u662f\u5bf9\u98df\u7269\u6709\u8981\u6c42\u7684\u4eba\uff0c\u4e00\u4e07\u4e2a\u8d5e\uff01\uff01\uff01')","de428ce7":"\u4fee\u6539df\uff0c\u6dfb\u52a0\u65b0\u5217\u4f5c\u4e3alabel\uff0c\u753120\u4e2a\u7c7b\u522bx4\u4e2a\u72b6\u6001\u7ec4\u621080\u4e2alabel\uff0c\u6bcf\u4e2alabel\u503c\u662f0\u62161\u3002\u8f6c\u6362\u6210\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898","3d4c2509":"\u5206\u7c7b\u8bad\u7ec3","079be529":"add_label_columns(valid)","bae6ca9e":"def simplify_content(df):\n    df['simplified_content']=df.apply(lambda x : HanziConv.toSimplified(x['content']) ,axis = 1)","645c2981":"\u8f6c\u4e3a\u7b80\u4f53","0e98541b":"!pip install hanziconv","42094af5":"train.head()","831afd8f":"def add_label_columns(df):\n    #\u6dfb\u52a0score\u5217\n    for s in score:\n        df[str(s)] = s    \n    #\u6dfb\u52a0label\u5217\n    for c in columns:\n        for s in score:\n            new_column = c + '_' + str(s)\n            df[new_column]=df.apply(lambda x : judge_equal(x[c], x[str(s)]) ,axis = 1)","8754c83e":"simplify_content(train)\nsimplify_content(valid)","02296257":"train.to_csv('dataset\/train.csv')\nvalid.to_csv('dataset\/valid.csv')","72e56336":"\"test = pd.read_csv(\"\/kaggle\/working\/dataset\/ai_challenger_sentiment_analysis_testa_20180816\/sentiment_analysis_testa.csv\")","a4ac4fe9":"train = pd.read_csv(\"\/kaggle\/working\/dataset\/train.csv\")\nvalid = pd.read_csv(\"\/kaggle\/working\/dataset\/valid.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis\/dataset\/ai_challenger_sentiment_analysis_testa_20180816\/sentiment_analysis_testa.csv\")","efcef244":"train.head()\n","8815db70":"from hanziconv import HanziConv","060904c9":"\u6784\u9020fastai\u4e2d\u7684bert\u7c7b\u3001\u5bf9\u8c61","9e9dae78":"add_label_columns(train)","8d66acee":"columns = train.columns.array[2:]\nscore = [1,0,-1,-2]","8aae6984":"!mkdir dataset\n!cp -r \/kaggle\/input\/ai-challenger-sentiment-analysis\/dataset\/train.csv \/kaggle\/working\/dataset\/train.csv\n!cp -r \/kaggle\/input\/ai-challenger-sentiment-analysis\/dataset\/valid.csv \/kaggle\/working\/dataset\/valid.csv","23e8e161":"!cp -r \/kaggle\/input\/dataset \/kaggle\/working","a269bb56":"def judge_equal(a, b):\n    if a == b:\n        return 1\n    else:\n        return 0","db88cb1d":"train = pd.read_csv(\"\/kaggle\/working\/dataset\/ai_challenger_sentiment_analysis_trainingset_20180816\/sentiment_analysis_trainingset.csv\")","12ccd755":"valid = pd.read_csv(\"\/kaggle\/working\/dataset\/ai_challenger_sentiment_analysis_validationset_20180816\/sentiment_analysis_validationset.csv\")","da07f5ba":"train.to_csv('dataset\/simplified_train.csv') \nvalid.to_csv('dataset\/simplified_valid.csv')"}}