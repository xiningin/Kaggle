{"cell_type":{"f9d15f4a":"code","de550901":"code","749da8b0":"code","c685048b":"code","f15a94ed":"code","94aa08e8":"code","f2032fc6":"code","adc81dfa":"code","54c9284f":"code","61e9db85":"code","368cff7a":"code","87cee936":"code","3aea16f6":"code","321c7fbb":"code","24ef0f7d":"code","9a9b1512":"code","9332c9f4":"markdown","fdb79a35":"markdown"},"source":{"f9d15f4a":"pip install -q openai","de550901":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGPT3_KEY = user_secrets.get_secret(\"GPT3_KEY\")","749da8b0":"import numpy as np\nimport pandas as pd\nimport openai\nimport json \nfrom tqdm.notebook import tqdm\n\npd.set_option('display.max_colwidth', 10000)\nMAX_COMMENT_LEN = 1024\nopenai.api_key = GPT3_KEY\nMAX_COMMENTS_TO_PROCESS = 2000000\nENGINE = 'text-similarity-ada-001'\nDEBUG = False\n\n# https:\/\/beta.openai.com\/docs\/guides\/embeddings\/what-are-embeddings\nENGINE_PRICE_PER_TOKEN = {\n    'text-similarity-davinci-001': 0.6 \/ 1000,\n    'text-similarity_curie-001': 0.06 \/ 1000,\n    'text-similarity-babbage-001': 0.012 \/ 1000,\n    'text-similarity-ada-001': 0.008 \/ 1000\n}","c685048b":"df_train = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')","f15a94ed":"def gen_train_comments(df):\n    return np.unique(np.concatenate([df['less_toxic'].values, df['more_toxic'].values]))\n\ntrain_comments = gen_train_comments(df_train.head(MAX_COMMENTS_TO_PROCESS))\ndf_train_comments = pd.DataFrame({'text': train_comments})","94aa08e8":"print('Total comments', len(df_train_comments))","f2032fc6":"df_train_comments['emb_text'] = df_train_comments['text'].str.replace(\"\\n\", \" \").str.slice(0, MAX_COMMENT_LEN)","adc81dfa":"estimated_tokens = df_train_comments['emb_text'].str.split().apply(lambda v: len(v)).sum()","54c9284f":"print('Estimated tokens', estimated_tokens, ' Estimated price $', estimated_tokens * ENGINE_PRICE_PER_TOKEN[ENGINE])","61e9db85":"def gen_embeddings(comments, engine):\n    if DEBUG:\n        return np.random.randn(len(comments), 1024)\n    else:\n        return np.array([d['embedding'] for d in openai.Embedding.create(input=comments.tolist(), engine=engine)['data']])","368cff7a":"embs = []\nfor df in tqdm(np.array_split(df_train_comments, len(df_train_comments) \/\/ 100)):\n    embs.append(gen_embeddings(df['emb_text'], ENGINE))    \nembs = np.concatenate(embs)","87cee936":"df_train_comments['embedding'] = embs.tolist()","3aea16f6":"df_train_comments[['text', 'embedding']].to_csv(f'{ENGINE}_embeddings.csv', index=False)","321c7fbb":"df_emb = pd.read_csv(f'{ENGINE}_embeddings.csv', dtype={'embedding': str})\ndf_emb['embedding'] = df_emb['embedding'].apply(lambda v: json.loads(v))\ndf_emb.head(1)","24ef0f7d":"df_train = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\ndf_train = pd.merge(df_train, df_emb, left_on='less_toxic', right_on='text').rename(columns={'embedding': 'less_toxic_emb'}).drop(columns=['text'])\ndf_train = pd.merge(df_train, df_emb, left_on='more_toxic', right_on='text').rename(columns={'embedding': 'more_toxic_emb'}).drop(columns=['text'])\ndf_train.head(1)","9a9b1512":"df_test = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')\ndf_test = pd.merge(df_test, df_emb, left_on='text', right_on='text')\ndf_test.head(1)","9332c9f4":"# Usage example","fdb79a35":"# Generate GPT-3 embeddings\n\nGPT-3 text embeddings can be generated by a set of GPT-3 models: https:\/\/beta.openai.com\/docs\/guides\/embeddings\/what-are-embeddings\n\nNote that different engines produce embeddings of different sizes:\n\n* Ada (1024 dimensions),\n* Babbage (2048 dimensions),\n* Curie (4096 dimensions),\n* Davinci (12288 dimensions).\n\nThis notebook generates GPT-3 embeddings for all comments from https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating challenge. \n\n**See the usage example below and don't forget to like this notebook if you find it interesting!**"}}