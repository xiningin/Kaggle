{"cell_type":{"487a8106":"code","9bd246b4":"code","f312017e":"code","5aa7b513":"code","286fde7b":"code","4da06b5c":"code","f3ea2992":"code","373e41d2":"code","f0abbc5d":"code","f887d4be":"code","99089d37":"code","1ae9ae62":"code","609a4059":"code","61e7af6c":"code","d6471844":"code","0a909721":"code","76b063f8":"code","594bb7ed":"markdown","e7a93f77":"markdown","20e72283":"markdown","ddacd426":"markdown","8f639688":"markdown","28268462":"markdown","77cd11b6":"markdown","46ddb8c5":"markdown","2509aa7c":"markdown","325c57e8":"markdown","4f37372a":"markdown","2e1375df":"markdown","41ee530b":"markdown","e430a3db":"markdown","d2d41c52":"markdown","9749e4ea":"markdown","aeeb0e7e":"markdown"},"source":{"487a8106":"import random, warnings\nimport pandas as pd\nimport seaborn as sns\nfrom nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nSEED = 0\nwarnings.filterwarnings(\"ignore\")","9bd246b4":"# Auxiliary functions\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\ndef evaluate_model(train_set, validation_set):\n    train_set['jaccard'] = train_set.apply(lambda x: jaccard(x['selected_text'], x['prediction']), axis=1)\n    validation_set['jaccard'] = validation_set.apply(lambda x: jaccard(x['selected_text'], x['prediction']), axis=1)\n\n    print('Train set Jaccard: %.3f' % train_set['jaccard'].mean())\n    print('Validation set Jaccard: %.3f' % validation_set['jaccard'].mean())\n\n    print('\\nMetric by sentiment')\n    for sentiment in train_df['sentiment'].unique():\n        print('\\nSentiment == %s' % sentiment)\n        print('Train set Jaccard: %.3f' % train_set[train_set['sentiment'] == sentiment]['jaccard'].mean())\n        print('Validation set Jaccard: %.3f' % validation_set[validation_set['sentiment'] == sentiment]['jaccard'].mean())","f312017e":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\n\nprint('Train samples: %s' % len(train))\nprint('Test samples: %s' % len(test))\ndisplay(train.head())","5aa7b513":"sample_0 = 0\nsample_1 = 1\nsample_2 = 2\n\nprint('Example %d' % sample_0)\nprint('Text: %s' % train['text'].values[sample_0])\nprint('Sentiment: %s' % train['sentiment'].values[sample_0])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_0])\n\nprint('\\nExample %d' % sample_1)\nprint('Text: %s' % train['text'].values[sample_1])\nprint('Sentiment: %s' % train['sentiment'].values[sample_1])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_1])\n\nprint('\\nExample %d' % sample_2)\nprint('Text: %s' % train['text'].values[sample_2])\nprint('Sentiment: %s' % train['sentiment'].values[sample_2])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_2])","286fde7b":"sentiment_order = train['sentiment'].unique()\nsns.set(style=\"darkgrid\")\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x='sentiment', data=train, palette=\"Set3\", order=sentiment_order, ax=ax1).set_title(\"Train\")\nsns.countplot(x='sentiment', data=test, palette=\"Set3\", order=sentiment_order, ax=ax2).set_title(\"Test\")\nplt.show()","4da06b5c":"train['text'].fillna('', inplace=True)\ntrain['selected_text'].fillna('', inplace=True)\n\ntrain['text_len'] = train['text'].apply(lambda x : len(x))\ntrain['text_wordCnt'] = train['text'].apply(lambda x : len(x.split(' ')))\ntrain['selected_text_len'] = train['selected_text'].apply(lambda x : len(x))\ntrain['selected_text_wordCnt'] = train['selected_text'].apply(lambda x : len(x.split(' ')))\ntest['text_len'] = test['text'].apply(lambda x : len(x))\ntest['text_wordCnt'] = test['text'].apply(lambda x : len(x.split(' ')))\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 10), sharex=True)\nsns.distplot(train['text_len'], ax=ax1).set_title(\"Train\")\nsns.distplot(test['text_len'], ax=ax2).set_title(\"Test\")\nplt.show()\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 10), sharex=True)\nsns.distplot(train['text_wordCnt'], ax=ax1).set_title(\"Train\")\nsns.distplot(test['text_wordCnt'], ax=ax2).set_title(\"Test\")\nplt.show()","f3ea2992":"f, ax = plt.subplots(1, 1, figsize=(24, 5), sharex=True)\nsns.distplot(train['selected_text_len'], ax=ax).set_title(\"Train\")\nplt.show()\n\nf, ax = plt.subplots(1, 1, figsize=(24, 5), sharex=True)\nsns.distplot(train['selected_text_wordCnt'], ax=ax).set_title(\"Train\")\nplt.show()","373e41d2":"eng_stopwords = stopwords.words('english')\n\ntrain['text'] = train['text'].str.replace('[^a-z ]','')\ntrain['selected_text'] = train['selected_text'].str.replace('[^a-z ]','')\ntrain['text'] = train['text'].apply(lambda x: x.lower())\ntrain['selected_text'] = train['selected_text'].apply(lambda x: x.lower())\n\nfreq_dist = FreqDist([word for comment in train['text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()\n\nfreq_dist = FreqDist([word for comment in train['selected_text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on selected_text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()","f0abbc5d":"test['text'] = test['text'].str.replace('[^a-z ]','')\ntest['text'] = test['text'].apply(lambda x: x.lower())\n\nfreq_dist = FreqDist([word for comment in test['text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()","f887d4be":"sns.jointplot(\"selected_text_len\", \"text_len\", data=train, kind=\"reg\", color=\"m\", height=12)\nplt.show()","99089d37":"sns.jointplot(\"selected_text_wordCnt\", \"text_wordCnt\", data=train, kind=\"reg\", color=\"m\", height=12)\nplt.show()","1ae9ae62":"train_df, validation_df = train_test_split(train, test_size=0.2, random_state=SEED)\n\nprint('Train set size: %s' % len(train_df))\nprint('Validation set size: %s' % len(validation_df))","609a4059":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[-5:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[-5:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","61e7af6c":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[5:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[5:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","d6471844":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"]\nvalidation_df[\"prediction\"] = validation_df[\"text\"]\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","0a909721":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.split()[-20:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.split()[-20:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","76b063f8":"test = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')\nsubmission[\"selected_text\"] = test[\"text\"]\nsubmission.to_csv(\"submission.csv\", index=False)\ndisplay(submission.head(10))","594bb7ed":"# Let's evaluate some heuristic models\n\n## Last 5 words","e7a93f77":"# Selected text (label) length and word count","20e72283":"## Dependencies","ddacd426":"# Let's take a look if the text size seems to have an impact on the selected text size\n\nIt seems that the text length is nicely distributed along with the values and the selected text size has most of its values very short, with less than 10 characters.","8f639688":"# And now text word count\n\nAgain the text word count has a nice distribution along with the values with a small peak around 10 words and the selected text word count has most of its values around with less than 3 words.","28268462":"## Last 20 characters","77cd11b6":"# Sentiment distribution\n\nAs we can see the distribution of the sentiment feature is practically the same between train and test sets.","46ddb8c5":" # EDA\n \n # First let's look at some samples","2509aa7c":"# Test set predictions","325c57e8":"# Train\/validation split","4f37372a":"<center><img src='https:\/\/www.kdnuggets.com\/images\/sentiment-fig-1-689.jpg' height=\"200\" width=\"500\"><\/center>\n<h1><center>Tweet Sentiment Extraction<\/center><\/h1>\n<h2><center>Extract support phrases for sentiment labels<\/center><\/h2>\n\nIn this competition our objective is to construct a model that can look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it.\n(work in progress)","2e1375df":"## Same as text","41ee530b":"## First 5 words","e430a3db":"# Text data statistics\n\n# Text length and word count","d2d41c52":"# Test set word frequency","9749e4ea":"# Train set word frequency","aeeb0e7e":"## Load data"}}