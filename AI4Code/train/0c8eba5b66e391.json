{"cell_type":{"28e706ff":"code","b6632413":"code","b2358000":"code","8471595c":"code","4b167c51":"code","9b5bd65e":"code","acfaf686":"code","7ba8de60":"code","302981e7":"code","7e9b345e":"code","441df0ef":"code","e41ae5be":"code","de73c10a":"code","ed9cb16f":"code","7d6db82f":"code","7e260845":"code","89b15b1f":"code","05c44651":"code","8ba1f14d":"code","13a21059":"markdown","81635f6f":"markdown","afd4eae0":"markdown","215effd5":"markdown","6482d5fc":"markdown","c0a714f4":"markdown"},"source":{"28e706ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport zipfile\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b6632413":"local_zip_train_path = '..\/input\/dogs-vs-cats\/train.zip'\nzip_train_file = zipfile.ZipFile(local_zip_train_path, 'r')\nzip_train_file.extractall('..\/kaggle\/working')\nzip_train_file.close()","b2358000":"local_zip_test_path = '..\/input\/dogs-vs-cats\/test1.zip'\nzip_test_file = zipfile.ZipFile(local_zip_test_path, 'r')\nzip_test_file.extractall('..\/kaggle\/working')\nzip_test_file.close()","8471595c":"print(os.listdir('..\/kaggle\/working'))","4b167c51":"filenames = os.listdir('..\/kaggle\/working\/train')\n\nclass_categ = []\n\nfor file in filenames:\n    \n    categ_str = file.split('.')[0]\n    \n    if categ_str == 'dog':\n        class_categ.append('cat')\n    else:\n        class_categ.append('dog')\n\ndata_frame = pd.DataFrame({'file_name': filenames, 'category': class_categ})\ndata_frame","9b5bd65e":"from sklearn.model_selection import train_test_split\n\ndf_train, df_validate =  train_test_split(data_frame, test_size = 0.2, random_state = 0)\n\ndf_train = df_train.reset_index(drop=True)\ndf_validate = df_validate.reset_index(drop=True)\n\ntraining_data_size = df_train.shape[0]\nvalidation_data_size = df_validate.shape[0]","acfaf686":"from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\nmodel = tf.keras.models.Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","7ba8de60":"model.compile(optimizer=tf.keras.optimizers.Adam(), loss= 'binary_crossentropy', metrics= ['accuracy'])","302981e7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen =  ImageDataGenerator(rescale=1.\/255, \n                                    rotation_range=15,\n                                    shear_range=0.1,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1)\n\nvalidate_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_gen = train_datagen.flow_from_dataframe(df_train,  '..\/kaggle\/working\/train',x_col='file_name', y_col='category', batch_size= 64,target_size=(128,128), class_mode='binary')\nval_gen = validate_datagen.flow_from_dataframe(df_validate,  '..\/kaggle\/working\/train',x_col='file_name', y_col='category', batch_size= 32,target_size=(128,128), class_mode='binary')","7e9b345e":"total_train = df_train.shape[0]\ntotal_validate = df_validate.shape[0]\nbatch_size = 256\nEPOCHS_ = 15","441df0ef":"model_history = model.fit_generator(train_gen, \n                                    validation_data=val_gen, \n                                    epochs=EPOCHS_, \n                                    steps_per_epoch=total_train \/\/ batch_size, \n                                    validation_steps=total_validate \/\/ batch_size)","e41ae5be":"model.save_weights('model.h5')","de73c10a":"from matplotlib import pyplot as plt\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 15, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 15, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","ed9cb16f":"test_filenames = os.listdir(\"..\/kaggle\/working\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","7d6db82f":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/kaggle\/working\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(128,128),\n    batch_size=batch_size,\n    shuffle=False\n)","7e260845":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))\npredict","89b15b1f":"test_df['category'] = predict >= 0.5\ntest_df['category']","05c44651":"test_df['category'].value_counts().plot.bar()","8ba1f14d":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","13a21059":"### Unzipping the data\n","81635f6f":"## Save model weights","afd4eae0":"## CNN - Arch","215effd5":"## Preparing Data","6482d5fc":"## Testing Data","c0a714f4":"## Splitting Data"}}