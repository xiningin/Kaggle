{"cell_type":{"0575984f":"code","e4d664c2":"code","6080c63b":"code","fff1835c":"code","cee73f17":"markdown","c71ae97e":"markdown","b9d6cad0":"markdown","0a8336a9":"markdown"},"source":{"0575984f":"import pandas as pd\n\ndf = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nprint(df.isna().sum())\n\ndata= df.fillna(df.mean())\ndata['Embarked']=data['Embarked'].fillna(\"S\")\n\nprint(data.isna().sum())\n\ndata=data.drop(columns=['Cabin','Name','PassengerId','Ticket'])\n\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndata['Sex']=le.fit_transform(data['Sex'])\ndata['Embarked']=le.fit_transform(data['Embarked'])\n\nx=data.drop(columns=['Survived'])\ny=data['Survived']\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test =train_test_split(x,y)\n","e4d664c2":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nmodellm = LogisticRegression(solver='liblinear', random_state=0)\nmodellm.fit(x_train, y_train)\ny_pred=modellm.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"LM\" ,end=\"  \")\nprint(modellm.score(x_test,y_test))\n\n\n#Decision Tree\nfrom sklearn import tree\nmodeldt = tree.DecisionTreeClassifier(max_depth=3)\nmodeldt.fit(x_train, y_train)\ny_pred=modeldt.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"DT\" ,end=\"  \")\nprint(modeldt.score(x_test,y_test))\n\n\n#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nmodelnb = GaussianNB()\nmodelnb.fit(x_train, y_train)\ny_pred=modelnb.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"NB\" ,end=\"  \")\nprint(modelnb.score(x_test,y_test))\n\n\n#SVM\nfrom sklearn.svm import SVC\nmodelsv=SVC( C=10000)\nmodelsv.fit(x_train, y_train)\ny_pred=modelsv.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"SVM\" ,end=\"  \")\nprint(modelsv.score(x_test,y_test))\n\n\n\n#RF\nfrom sklearn.ensemble import RandomForestClassifier\nmodelrf = RandomForestClassifier(n_estimators=200,max_depth=3)\nmodelrf.fit(x_train, y_train)\ny_pred=modelrf.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"RF\" ,end=\"  \")\nprint(modelrf.score(x_test,y_test))\n\n\n#GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\nmodelgbm=GradientBoostingClassifier()\nmodelgbm.fit(x_train,y_train)\ny_pred=modelgbm.predict(x_test)\n#print(confusion_matrix(y_test, y_pred)) \nprint(\"GBM\" ,end=\"  \")\nprint(modelgbm.score(x_test,y_test))","6080c63b":"from sklearn.ensemble import VotingClassifier\nevc = VotingClassifier(estimators=[('gbm',modelgbm),('rf',modelrf),\n                                   ('svm',modelsv),('dt',modeldt)], \n                       voting='hard')\nevc.fit(x_train,y_train)\nprint(evc.score(x_test,y_test))\n","fff1835c":"testd = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsubmit = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntestd= testd.fillna(testd.mean())\ntestd=testd.drop(columns=['Cabin','Name','PassengerId','Ticket'])\nprint(testd.isna().sum())\n\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ntestd['Sex']=le.fit_transform(testd['Sex'])\ntestd['Embarked']=le.fit_transform(testd['Embarked'])\n\n\np = evc.predict(testd)\nsubmit.Survived=p\nsubmit.to_csv(\"titanic.csv\", index=False)","cee73f17":"**Ensemble models**","c71ae97e":"**Prediction**","b9d6cad0":"**Models training**","0a8336a9":"**Importing Data Set, Filling NA values, Label Encoding And Train-Test Split**"}}