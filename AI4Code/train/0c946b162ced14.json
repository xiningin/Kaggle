{"cell_type":{"106171e3":"code","29c61db2":"code","eb20a4a5":"code","6acbc0fe":"code","d580fbad":"code","2894e753":"code","d419dd0d":"code","a383089d":"code","7f7de39f":"code","7339ae1f":"code","44c777ca":"code","0882b6f2":"code","0d03410e":"code","2d2a6805":"code","2aeeb518":"code","10ef3096":"code","eeb3186a":"code","6cb84a9e":"code","896cede3":"code","ca172448":"code","5d431c68":"code","2f1699cf":"code","797297e8":"code","f4519310":"code","c0d79305":"code","29564f35":"code","706a15fe":"code","36241fe6":"code","672cc415":"code","c4c06bcd":"code","063588a0":"code","3f9185c0":"code","9e1b809d":"code","9b9d6df8":"code","48d11fbb":"code","2c9d4534":"code","dbcf5c5a":"code","f16510d7":"markdown","68e32b5c":"markdown","70b9e772":"markdown","867e8b0f":"markdown","bea73120":"markdown","06bda583":"markdown","a89d0065":"markdown","3fa2aeb1":"markdown","102c395a":"markdown","9e4d714d":"markdown","723dc16f":"markdown","91d38420":"markdown","6bc82f06":"markdown","9a69d508":"markdown","b8b83354":"markdown","672d9498":"markdown","d2b319e8":"markdown","936f36ca":"markdown","faef6b7d":"markdown","df0ee42b":"markdown","ae225d3d":"markdown"},"source":{"106171e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29c61db2":"import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport gc\nimport seaborn as sns\nimport xgboost as xgb\nimport lightgbm as lgb\nimport datetime\n\nfrom time import time\nfrom lightgbm import LGBMModel,LGBMClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.under_sampling import ClusterCentroids,RandomUnderSampler,AllKNN\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import datasets, metrics, model_selection\nfrom sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score\nfrom sklearn.model_selection import KFold, TimeSeriesSplit","eb20a4a5":"train_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntrain_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\ntest_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ntest_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')","6acbc0fe":"print('Train_identity: ', train_id.shape)\nprint('Train_transaction: ', train_trans.shape)\nprint('Test_identity: ',test_id.shape)\nprint('Test_transaction: ', test_trans.shape)","d580fbad":"train = pd.merge(train_id,train_trans,left_on='TransactionID',right_on='TransactionID',how='right')\ntest = pd.merge(test_id,test_trans,left_on='TransactionID',right_on='TransactionID',how='right')\ntrain.head()","2894e753":"del train_id\ndel train_trans\ndel test_id\ndel test_trans\ngc.collect()","d419dd0d":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","a383089d":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","7f7de39f":"train_y = train['isFraud']\ntrain = train.drop(columns=['isFraud'])\n\ntrain = train.fillna(-999)\ntest = test.fillna(-999)\ntrain.head()","7339ae1f":"cat_col=[]\nfor col in train:\n  if train[col].dtype == 'object':\n    cat_col.append(col)\nfor col in cat_col:\n  le = LabelEncoder()\n  train[col] = le.fit_transform(train[col].astype(str).values)\ntrain.head()","44c777ca":"test_col=[]\nfor col in test:\n  if test[col].dtype == 'object':\n    test_col.append(col)\nfor col in test_col:\n  le = LabelEncoder()\n  test[col] = le.fit_transform(test[col].astype(str).values)\ntest.head()","0882b6f2":"# id_cate = ['ProductCD','card4','card6','M1','M2','M3','M4','M5','M6','M7','M8','M9','DeviceType','DeviceInfo','id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18','id_19', 'id_20', 'id_21', 'id_22', 'id_23','id_24', 'id_25','id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32','id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']\n# for col in train[id_cate]:\n#     train[col] = train[col].astype('category')","0d03410e":"# test_id_cate = ['ProductCD','card4','card6','M1','M2','M3','M4','M5','M6','M7','M8','M9','DeviceType','DeviceInfo','id-12', 'id-13', 'id-14', 'id-15', 'id-16', 'id-17', 'id-18','id-19', 'id-20', 'id-21', 'id-22', 'id-23','id-24', 'id-25','id-26', 'id-27', 'id-28', 'id-29', 'id-30', 'id-31', 'id-32','id-33', 'id-34', 'id-35', 'id-36', 'id-37', 'id-38']\n# for col in test[test_id_cate]:\n#     test[col] = test[col].astype('category')","2d2a6805":"sub =  pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv')","2aeeb518":"train_x = train","10ef3096":"train_x, train_y = RandomUnderSampler().fit_resample(train_x, train_y)\ntrain_y.value_counts().plot.bar()","eeb3186a":"X_train,X_test,y_train,y_test = train_test_split(train_x,train_y,shuffle = True,random_state = 255,test_size = 0.2)\n\ndel train_x,train\ngc.collect()","6cb84a9e":"%%time\neval_set = [(X_train, y_train), (X_test, y_test)]\nclf = xgb.XGBClassifier( \n        n_estimators=500,\n        max_depth=9,\n        learning_rate=0.05,\n        subsample=0.9,\n        missing=-999,\n        colsample_bytree=0.9,\n        gamma = 0.2,\n        alpha = 4,\n        use_label_encoder=False,\n        tree_method='gpu_hist' \n    \n    )\nclf.fit(X_train,y_train,eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=False)","896cede3":"test_y = clf.predict(X_test)\nprint('Accuracy score:',accuracy_score(y_test,test_y))\nprint('F1 score:',f1_score(y_test,test_y))\nprint('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score(y_test,test_y))\nprint('Confusion maxtrix',confusion_matrix(y_test,test_y))","ca172448":"metrics.plot_roc_curve(clf, X_test, y_test) ","5d431c68":"feature_important = clf.get_booster().get_score(importance_type=\"weight\")\nkeys = list(feature_important.keys())\nvalues = list(feature_important.values())\n\ndata = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n\n# Top 10 features\ndata.head(20)","2f1699cf":"predictions = [round(value) for value in test_y]\nresults = clf.evals_result()\nepochs = len(results[\"validation_0\"][\"error\"])\nx_axis = range(0, epochs)","797297e8":"fig, ax = plt.subplots(figsize=(12,12))\nax.plot(x_axis, results[\"validation_0\"][\"logloss\"], label=\"Train\")\nax.plot(x_axis, results[\"validation_1\"][\"logloss\"], label=\"Test\")\nax.legend()\nplt.ylabel(\"Log Loss\")\nplt.title(\"XGBoost Log Loss\")\nplt.show()","f4519310":"fig, ax = plt.subplots(figsize=(12,12))\nax.plot(x_axis, results[\"validation_0\"][\"error\"], label=\"Train\")\nax.plot(x_axis, results[\"validation_1\"][\"error\"], label=\"Test\")\nax.legend()\nplt.ylabel(\"Classification Error\")\nplt.title(\"XGBoost Classification Error\")\nplt.show()","c0d79305":"y_preds = clf.predict_proba(test)\nsub_xgb = pd.DataFrame({\n    'TransactionID' : sub.TransactionID,\n    'isFraud' : y_preds[:,1]\n})\nsub_xgb.head()","29564f35":"sub_xgb.to_csv('xgboost.csv',index=False)","706a15fe":"%%time\nlgbm = lgb.LGBMClassifier(\n        boosting_type='gbdt', \n        num_leaves=2**8, \n        max_depth=- 1, \n        learning_rate=0.01,\n        n_estimators=800, \n        objective= 'binary', \n        subsample=0.7, \n        subsample_freq=1, \n        colsample_bytree=0.5, \n        n_jobs=- 1, \n)\nlgbm.fit(X_train,y_train)","36241fe6":"test_y = lgbm.predict(X_test)\nprint('Accuracy score:',accuracy_score(y_test,test_y))\nprint('F1 score:',f1_score(y_test,test_y))\nprint('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score(y_test,test_y))\nprint('Confusion maxtrix',confusion_matrix(y_test,test_y))","672cc415":"metrics.plot_roc_curve(lgbm, X_test, y_test) ","c4c06bcd":"test_y = lgbm.predict_proba(test)\nsubmission = pd.DataFrame({\n    'TransactionID' : sub.TransactionID,\n    'isFraud' : test_y[:,1]\n})\nsubmission.head()","063588a0":"submission.to_csv('lgbm.csv',index=False)","3f9185c0":"lgb_params = {\n                    'objective':'binary',\n                    'boosting_type':'gbdt',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.01,\n                    'num_leaves': 2**8,\n                    'max_depth':-1,\n                    'tree_learner':'serial',\n                    'colsample_bytree': 0.5,\n                    'subsample_freq':1,\n                    'subsample':0.7,\n                    'n_estimators':800,\n                    'max_bin':255,\n                    'verbose':-1,\n                } ","9e1b809d":"folds = TimeSeriesSplit(n_splits=5)\n\naucs = list()\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = X_train.columns\n\ntraining_start_time = time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X_train, y_train)):\n    start_time = time()\n    print('Training on fold {}'.format(fold + 1))\n    \n    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(X_train.iloc[test_idx], label=y_train.iloc[test_idx])\n    clf = lgb.train(lgb_params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=100)\n    \n    feature_importances['fold_{}'.format(fold + 1)] = clf.feature_importance()\n    aucs.append(clf.best_score['valid_1']['auc'])\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\nprint('-' * 30)\nprint('Training has finished.')\nprint('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\nprint('Mean AUC:', np.mean(aucs))\nprint('-' * 30)","9b9d6df8":"feature_importances['average'] = feature_importances[['fold_{}'.format(fold + 1) for fold in range(folds.n_splits)]].mean(axis=1)\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\nplt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));","48d11fbb":"best_iter = clf.best_iteration\nclf = lgb.LGBMClassifier(**lgb_params, num_boost_round=best_iter)\nclf.fit(X_train, y_train)","2c9d4534":"test_y = clf.predict_proba(test)\nsubmission = pd.DataFrame({\n    'TransactionID' : sub.TransactionID,\n    'isFraud' : test_y[:,1]\n})\nsubmission.head()","dbcf5c5a":"submission.to_csv('lgbm_fold.csv',index=False)","f16510d7":"## Gi\u1ea3m k\u00edch c\u1ee1 d\u1eef li\u1ec7u\nC\u00e1c gi\u00e1 tr\u1ecb trong t\u1eadp d\u1eef li\u1ec7u ch\u01b0a \u0111\u01b0\u1ee3c l\u01b0u \u1edf ki\u1ec3u t\u1ed1i \u01b0u nh\u1ea5t, g\u00e2y kh\u00f3 kh\u0103n trong qu\u00e1 tr\u00ecnh ch\u1ea1y m\u00f4 h\u00ecnh. \n\n=> V\u00ec th\u1ebf ta s\u1ebd x\u1eed l\u00fd v\u1ea5n \u0111\u1ec1 n\u00e0y b\u1eb1ng c\u00e1ch \u0111\u1ed5i ki\u1ec3u d\u1eef li\u1ec7u","68e32b5c":"### LightGBM & TimeSeriesSplit","70b9e772":"## Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u \u0111\u1ec3 \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh","867e8b0f":"![image.png](attachment:36fa80a5-32e4-4614-961c-4ea918bfde7d.png)","bea73120":"## Categorical Features\nCho LGBM nh\u1eadn bi\u1ebft \u0111\u00e2u l\u00e0 c\u00e1c tr\u01b0\u1eddng ki\u1ec3u Category\n\nTuy nhi\u00ean sau khi th\u1eed nghi\u1ec7m k\u1ebft qu\u1ea3 kh\u00f4ng \u0111\u01b0\u1ee3c c\u1ea3i thi\u1ec7n m\u00e0 c\u00f2n th\u1ea5p h\u01a1n ban \u0111\u1ea7u, v\u00ec th\u1ebf s\u1ebd kh\u00f4ng th\u1ef1c hi\u1ec7n vi\u1ec7c n\u00e0y n\u1eefa","06bda583":"Nh\u1eadn x\u00e9t: D\u1eef li\u1ec7u \u0111\u00e3 tr\u1edf n\u00ean c\u00e2n b\u1eb1ng","a89d0065":"## Label Encoder\nC\u00e1c gi\u00e1 tr\u1ecb trong b\u1ea3ng v\u1eabn t\u1ed3n t\u1ea1i c\u1ea3 ki\u1ec3u s\u1ed1 l\u1eabn ch\u1eef, v\u00ec th\u1ebf ta s\u1ebd s\u1eed d\u1ee5ng Label Encoder","3fa2aeb1":"## M\u00f4 h\u00ecnh\nDo c\u00e1ch VESTA g\u1eafn c\u1edd c\u00e1c giao d\u1ecbch gian l\u1eadn, n\u1ebfu ph\u00e1t hi\u1ec7n gian l\u1eadn \u0111\u1ed1i v\u1edbi kh\u00e1ch h\u00e0ng, t\u1ea5t c\u1ea3 c\u00e1c giao d\u1ecbch c\u1ee7a kh\u00e1ch h\u00e0ng n\u00e0y c\u0169ng \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u l\u00e0 gian l\u1eadn. C\u00e1c ph\u01b0\u01a1ng ph\u00e1p d\u1ef1a tr\u00ean c\u00e2y quy\u1ebft \u0111\u1ecbnh ho\u1ea1t \u0111\u1ed9ng t\u1ed1t trong vi\u1ec7c l\u1ecdc ra c\u00e1c t\u00ednh n\u0103ng quan tr\u1ecdng. \n\nB\u00ean c\u1ea1nh \u0111\u00f3, d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c cho \u1edf d\u1ea1ng b\u1ea3ng, v\u00e0 thi\u1ebfu r\u1ea5t nhi\u1ec1u gi\u00e1 tr\u1ecb\n\n=> Do \u0111\u00f3, \u1edf \u0111\u00e2y ta s\u1ebd s\u1eed d\u1ee5ng 2 m\u00f4 h\u00ecnh XGBoost v\u00e0 LighGBM ","102c395a":"**Top 10 Features**","9e4d714d":"![image.png](attachment:b8c99480-f288-4e5f-a64f-f1d43996dc73.png)","723dc16f":"### XGBoost","91d38420":"# 2.Ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u","6bc82f06":"# 1.T\u1ed5ng quan","9a69d508":"## Merge 2 t\u1eadp Transaction v\u00e0 Identity\nDo 2 lo\u1ea1i d\u1eef li\u1ec7u \u0111\u1ec1u chung tr\u01b0\u1eddng Transaction ID, n\u00ean em quy\u1ebft \u0111\u1ecbnh s\u1ebd merge 2 t\u1eadp v\u1edbi nhau, d\u00f9ng Transaction ID l\u00e0m key d\u00f9ng ki\u1ec3u join right","b8b83354":"## T\u00e1ch d\u1eef li\u1ec7u ","672d9498":"## X\u1eed l\u00fd v\u1ea5n \u0111\u1ec1 m\u1ea5t c\u00e2n b\u1eb1ng d\u1eef li\u1ec7u\nDo l\u01b0\u1ee3ng d\u1eef li\u1ec7u b\u1ecb m\u1ea5t c\u00e2n b\u1eb1ng kh\u00e1 nghi\u00eam tr\u1ecdng\n\n=> V\u00ec th\u1ebf ta s\u1ebd s\u1eed d\u1ee5ng Undersampling \u0111\u1ec3 x\u1eed l\u00ed v\u1ea5n \u0111\u1ec1 n\u00e0y","d2b319e8":"# 3. Th\u1ef1c nghi\u1ec7m","936f36ca":"### LightGBM","faef6b7d":"![image.png](attachment:278d41ee-ce9d-4bd5-9055-0c9f23019a0d.png)","df0ee42b":"**Nh\u1eadn x\u00e9t:**\n\n* 2 thu\u1eadt to\u00e1n tr\u00ean ho\u1ea1t \u0111\u1ed9ng t\u1ed1t \u0111\u00fang nh\u01b0 mong \u0111\u1ee3i.\n\n* LightGBM ch\u1ea1y ch\u1eadm h\u01a1n kh\u00e1 nhi\u1ec1u so v\u1edbi XGBoost\n\n* K\u1ebft qu\u1ea3 c\u1ee7a LGBM \u1edf Private LB cao h\u01a1n XGB(0.9058 > 0.9056), nh\u01b0ng \u1edf Public LB l\u1ea1i th\u1ea5p h\u01a1n (0.9312<0.9329)\n\n* K\u1ebft qu\u1ea3 c\u1ee7a LGBM th\u1ea5p h\u01a1n khi s\u1eed d\u1ee5ng TimeSeriesSplit \n\n##### =>  XGBoost ho\u1ea1t \u0111\u1ed9ng t\u1ed1t h\u01a1n so v\u1edbi LightGBM\n\n**M\u1ed9t s\u1ed1 ph\u01b0\u01a1ng ph\u00e1p c\u1ea3i ti\u1ebfn:**\n* Lo\u1ea1i b\u1ecf b\u1edbt c\u00e1c feautures kh\u00f4ng c\u1ea7n thi\u1ebft, c\u00f3 th\u1ec3 k\u1ebft h\u1ee3p c\u00e1c tr\u01b0\u1eddng th\u00e0nh 1 features th\u00f4ng quan Features Important\n* S\u1eed d\u1ee5ng th\u00eam c\u00e1c ph\u01b0\u01a1ng ph\u00e1p Fold kh\u00e1c cho LGBM\n* C\u00e0i \u0111\u1eb7t c\u00e1c tham s\u1ed1 cho thu\u1eadt to\u00e1n t\u1ed1t h\u01a1n\n* S\u1eed d\u1ee5ng PCA  \u0111\u1ec3 gi\u1ea3m s\u1ed1 chi\u1ec1u d\u1eef li\u1ec7u","ae225d3d":"## Fill NaN\nB\u00ean c\u1ea1nh \u0111\u00f3, l\u01b0\u1ee3ng d\u1eef li\u1ec7u trong b\u1ea3ng thi\u1ebfu h\u1ee5t r\u1ea5t nhi\u1ec1u. Tuy nhi\u00ean 2 model XGB v\u00e0 LGBM \u0111\u1ec1u t\u1ef1 x\u1eed l\u00ed \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 n\u00e0y, v\u00ec th\u1ebf ta s\u1ebd fill NaN v\u1edbi -999 (\u0111\u1ec3 tr\u00e1nh tr\u00f9ng v\u1edbi c\u00e1c gi\u00e1 tr\u1ecb trong c\u1ed9t)"}}