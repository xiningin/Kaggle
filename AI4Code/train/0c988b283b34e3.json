{"cell_type":{"4be98cb5":"code","7cc2d670":"code","251ba7ef":"code","57c6dab8":"code","d0a712d9":"code","9ffe4880":"code","4b89b66c":"code","e677391b":"code","37b7145c":"code","cf7a8274":"code","f9a00f9f":"code","5c8bfd0a":"code","9d66d765":"code","1d987d1b":"code","2bee29fd":"markdown","dc575867":"markdown","f5bf5170":"markdown","0ad339bd":"markdown","5cf92082":"markdown","d8afa806":"markdown","3d7d2b5a":"markdown","a92c6702":"markdown","d6ebdf11":"markdown","b18b41cf":"markdown","e4401a74":"markdown","faa6cf4e":"markdown","b72ab4bb":"markdown"},"source":{"4be98cb5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7cc2d670":"df = pd.read_csv(\"\/kaggle\/input\/videogamesales\/vgsales.csv\")\ndf.head()","251ba7ef":"df.info()","57c6dab8":"df.isnull().sum()","d0a712d9":"df = df.fillna(0)","9ffe4880":"df.sort_values(\"Global_Sales\", axis = 0, ascending = False, inplace = True) \ndf","4b89b66c":"plt.figure(figsize=(10,5))\nsns.countplot(df[\"Genre\"])\nplt.show()","e677391b":"plt.figure(figsize=(20,5))\nsns.countplot(df[\"Platform\"])\nplt.show()","37b7145c":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\")\nplt.show()","cf7a8274":"x = np.array(df.loc[:,\"NA_Sales\"]).reshape(-1,1)\ny = np.array(df.loc[:,\"Global_Sales\"]).reshape(-1,1)\nplt.figure(figsize=(10,5))\nplt.xlabel(\"NA Sales\")\nplt.ylabel(\"Global Sales\")\nplt.scatter(x,y,c=\"red\")","f9a00f9f":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\n#predict range\npredict_space = np.linspace(min(x), max(x)).reshape(-1,1)\n#fitting\nlin_reg.fit(x,y)\n#predict\ny_head = lin_reg.predict(predict_space)\n\n# R square score\nprint(\"R square score: \",lin_reg.score(x,y))\n# Plot regression line and scatter\nplt.figure(figsize=(15,6))\nplt.scatter(x=x,y=y,c=\"red\")\nplt.plot(predict_space, y_head, color='blue', linewidth=3)\nplt.xlabel('NA Sales')\nplt.ylabel('Global Sales')\nplt.show()","5c8bfd0a":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\n#polynomial regression fitting\npoly_reg = PolynomialFeatures(degree=5)\nx_polynomial = poly_reg.fit_transform(x) # I determined that X array as polynomial fit value and I'll use it for linear regression model's fit.\n\n\nlin_reg = LinearRegression()\n\n\n#fitting\nlin_reg.fit(x_polynomial,y) \n\n#predict\ny_head = lin_reg.predict(x_polynomial)\n\n# Visualize\n\nprint(\"R Square Score: \",r2_score(y,y_head))\n\n\nplt.figure(figsize=(15,6))\nplt.scatter(x=x,y=y,c=\"red\")\nplt.plot(x, y_head, color='blue', linewidth=3)\nplt.xlabel('NA Sales')\nplt.ylabel('Global Sales')\nplt.show()","9d66d765":"from sklearn.tree import DecisionTreeRegressor\n\n\ntree_reg = DecisionTreeRegressor()\n\n#fitting and prediction\ntree_reg.fit(x,y)\n\nx_ = np.arange(min(x),max(x),0.01).reshape(-1,1) # I increased leaf of tree actually \ny_head = tree_reg.predict(x) # machine will do prediction according to x_ \n\n#visualize\n\nprint(\"R Square Score: \",r2_score(y,y_head))\n\n\nplt.figure(figsize=(15,6))\nplt.scatter(x,y,c=\"red\")\nplt.plot(x,y_head,c=\"green\")\nplt.xlabel(\"NA Sales\")\nplt.ylabel(\"Global Sales\")\nplt.show()","1d987d1b":"from sklearn.ensemble import RandomForestRegressor\n\nrandom_forest = RandomForestRegressor(n_estimators=100,random_state=42)\n#fitting\nrandom_forest.fit(x,y)\n\n#prediction\ny_head = random_forest.predict(x)\n\n# visualize and R-Square Score\n\nprint(\"R Square Score: \",r2_score(y,y_head))\n\nplt.figure(figsize=(15,6))\nplt.scatter(x,y,c=\"red\")\nplt.plot(x,y_head,c=\"blue\")\nplt.xlabel(\"NA Sales\")\nplt.ylabel(\"Global Sales\")\nplt.show()","2bee29fd":"<a id=\"1\"><\/a> <br>\n# Import libraries","dc575867":"<a id=\"2\"><\/a> <br>\n# Loading data","f5bf5170":"<a id=\"8\"><\/a> <br>\n# Conclusion\n\nI found that the most accuracy R Square value is decision tree regression for this data.","0ad339bd":"<a id=\"3\"><\/a> <br>\n## Basic Data Analysis","5cf92082":"<a id=\"4\"><\/a> <br>\n## Linear Regression","d8afa806":"### Basic skimming on data","3d7d2b5a":"<a id=\"7\"><\/a> <br>\n## Random Forest Regression","a92c6702":"I want to fill them as 0","d6ebdf11":"it seems that 16598 is limit of the index so,\nYear and Publisher columns have NaN values.","b18b41cf":"<a id=\"6\"><\/a> <br>\n## Decision Tree Regression","e4401a74":"There is 0.94 correlation between NA Sales and Global Sales so I'll use that for linear regression","faa6cf4e":"<a id=\"5\"><\/a> <br>\n## Polynomial Linear Regression","b72ab4bb":"# INTRODUCTION\n* In this kernel, we will investigate video games sales in terms of machine learning regressions.\n\n<br>Content:\n1. [Import Libraries](#1)\n1. [Reading Data and Basic skimming on the data](#2)\n1. [Basic Data Analysis](#3)\n1. [Linear Regression](#4)\n1. [Polynomial Linear Regression](#5)\n1. [Decision Tree Regression](#6)\n1. [Random Forest Regression](#7)\n1. [Conclusion](#8)\n"}}