{"cell_type":{"167460f8":"code","c5888c3d":"code","f215de2d":"code","c05c6a87":"code","2fde5290":"code","21f9da67":"code","c1895f85":"code","978e3baf":"code","001fb821":"code","898c600d":"code","eed2d142":"code","cb759240":"code","9e65223b":"code","18dbe43d":"code","8c6839a3":"code","1b2d5e81":"code","e5247e40":"code","e5c063fb":"code","8c8b1be0":"code","f64d5e3f":"code","aa612efd":"code","99d01df9":"code","55222355":"code","9eb967e7":"code","ec241f39":"code","08d580b6":"code","391b4d32":"markdown","e069e1cb":"markdown","7fdeb44f":"markdown","6c7e4636":"markdown","6a67ce27":"markdown","05864e95":"markdown","b79ccbbc":"markdown","090e77c7":"markdown","d981ba8a":"markdown","aa6345fb":"markdown","35f20a6e":"markdown","ea7baf95":"markdown","939b008d":"markdown","6079a885":"markdown","27a5fa36":"markdown","4c30b374":"markdown","8f5402b3":"markdown","180a5217":"markdown","8ab200a8":"markdown","5ef7a3a1":"markdown","79f6ef2a":"markdown","49f72857":"markdown","b44afbfd":"markdown"},"source":{"167460f8":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport PIL.ImageOps\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as utils\nimport torchvision.transforms as transforms\nimport torchvision.utils\nfrom itertools import combinations\nfrom PIL import Image\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader,Dataset","c5888c3d":"def imshow(img,text=None,should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(\n            75,\n            8,\n            text,\n            style='italic',\n            fontweight='bold',\n            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10}\n        )\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","f215de2d":"class ContrastiveLoss(th.nn.Module):\n    \"Contrastive loss function\"\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = th.mean(\n            (1 - label) * th.pow(euclidean_distance, 2) +\n            label * th.pow(th.clamp(self.margin - euclidean_distance, min=0.0), 2)\n        )\n        return loss_contrastive","c05c6a87":"training_dir_list = os.listdir('..\/input\/dac-yapikredi-project\/train (1)\/train')\ntraining_data = pd.DataFrame(\n    list(combinations(training_dir_list, 2)),\n    columns=['img1no', 'img2no']\n)\ntraining_data = training_data[\n    training_data.img1no.str[4:7] == training_data.img2no.str[4:7]\n]\ntraining_data = training_data.sort_values([\"img1no\", \"img2no\"])\ntraining_data = training_data.reset_index(drop=True)\ntraining_data['label'] = 0\ntraining_data.to_csv('.\/train_data.csv', index=False)\ntraining_data","2fde5290":"testing_dir_list = os.listdir('..\/input\/dac-yapikredi-project\/test\/test')\ntest_data = pd.DataFrame(\n    list(combinations(testing_dir_list, 2)), columns=['img1no', 'img2no']\n)\ntest_data = test_data[test_data.img1no.str[4:7] == test_data.img2no.str[4:7]]\ntest_data = test_data.sort_values([\"img1no\", \"img2no\"])\ntest_data = test_data.reset_index(drop=True)\ntest_data['label'] = 0\ntest_data.to_csv('.\/test_data.csv', index=False)\ntest_data","21f9da67":"idinfo = pd.read_csv(\"..\/input\/dac-yapikredi-project\/idinfo.csv\")\nidinfo","c1895f85":"submission = pd.read_csv(\"..\/input\/dac-yapikredi-project\/samplesub2c.csv\")\nidinfo1 = pd.DataFrame(\n    'NFI-' +\n    idinfo['person1'].astype(str).str.zfill(3) +\n    idinfo['imgno1'].astype(str).str.zfill(2) +\n    idinfo['person1'].astype(str).str.zfill(3) +\n    '.png',\n    columns=['img1no']    \n)\nidinfo1['img2no'] = (\n        'NFI-' +\n        idinfo['person2'].astype(str).str.zfill(3) +\n        idinfo['imgno2'].astype(str).str.zfill(2) +\n        idinfo['person2'].astype(str).str.zfill(3) +\n        '.png'   \n)\nidinfo1['label'] = np.where(idinfo1.img1no.str[4:7] == idinfo1.img2no.str[4:7], 0, 1)\nidinfo1.to_csv('.\/testing.csv', index=False)\nidinfo1","978e3baf":"# dac-yapikredi-project veri setini y\u00fckleme \ntraining_dir = \"..\/input\/dac-yapikredi-project\/train (1)\/train\"\ntraining_csv = \"..\/input\/training-data-label\/training_data_label.csv\"\n\ntesting_dir = \"..\/input\/dac-yapikredi-project\/test\/test\"\ntesting_csv = \"..\/input\/test-data-label\/test_data_label.csv\"\n\nbatch_size = 64  # 32\nepochs = 40  # 256","001fb821":"# veri setini \u00f6n i\u015fleme ve resimlerin yeniden boyutland\u0131r\u0131lmas\u0131\nclass SiameseDataset():\n\n    def __init__(self, training_csv=None, training_dir=None, transform=None):\n        # resimlerin etiketleri ve dizinleri\n        self.train_df = pd.read_csv(training_csv)\n        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n        self.train_dir = training_dir\n        self.transform = transform\n\n    def __getitem__(self, index):\n        # resimlerin dizinleri\n        image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n        image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n\n        # resimlerin y\u00fcklenmesi\n        img0 = Image.open(image1_path)\n        img1 = Image.open(image2_path)\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n\n        # resimlerin yeniden boyutland\u0131r\u0131lmas\u0131\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n\n        return img0, img1, th.from_numpy(\n            np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n        )\n\n    def __len__(self):\n        return len(self.train_df)","898c600d":"# E\u011fitim veri setinin y\u00fcklenmesi\nsiamese_dataset = SiameseDataset(\n    training_csv,\n    training_dir,\n    transform=transforms.Compose([transforms.Resize((105, 105)), transforms.ToTensor()])    \n)","eed2d142":"# \u00d6rnek imza resimleri\nvis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\ndataiter = iter(vis_dataloader)\n\nexample_batch = next(dataiter)\nconcatenated = th.cat((example_batch[0], example_batch[1]), 0)\nimshow(torchvision.utils.make_grid(concatenated))\nprint(example_batch[2].numpy())","cb759240":"# Standart CNN\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        \n        # Ard\u0131\u015f\u0131k CNN katmanlar\u0131n\u0131n ayarlanmas\u0131\n        self.cnn1 = nn.Sequential(\n            \n            nn.Conv2d(1, 96, kernel_size=11, stride=1),\n            nn.ReLU(inplace=True),\n            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n            nn.MaxPool2d(3, stride=2),\n            \n            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n            nn.ReLU(inplace=True),\n            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n\n            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n\n        )\n        \n        # Ba\u011flant\u0131l\u0131 katmanlar\u0131n tan\u0131mlanmas\u0131\n        self.fc1 = nn.Sequential(\n            nn.Linear(30976, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p=0.5),\n            \n            nn.Linear(1024, 128),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(128,2)\n        )        \n  \n  \n    def forward_once(self, x):\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2","9e65223b":"# Dataloader'i kullanarak veri setini pytorch tensors'a y\u00fckleme\ntrain_dataloader = DataLoader(\n    siamese_dataset,\n    shuffle=True,\n    num_workers=8,\n    batch_size=batch_size\n)   \n# Siamese Network\nnet = SiameseNetwork().cuda()\n# Loss Function\ncriterion = ContrastiveLoss()\n# Optimizer\noptimizer = th.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)","18dbe43d":"# Modelin e\u011fitilmesi fonksiyonu\ndef train():\n    loss=[] \n    counter=[]\n    iteration_number = 0\n\n    for epoch in range(1,epochs):\n        for i, data in enumerate(train_dataloader,0):\n            img0, img1 , label = data\n            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n            optimizer.zero_grad()\n            output1, output2 = net(img0, img1)\n            loss_contrastive = criterion(output1 ,output2, label)\n            loss_contrastive.backward()\n            optimizer.step()\n            \n        print(\"Epoch {}\\n Current loss {}\\n\".format(epoch, loss_contrastive.item()))\n        iteration_number += 10\n        counter.append(iteration_number)\n        loss.append(loss_contrastive.item())\n    show_plot(counter, loss)   \n    return net","8c6839a3":"# Ekran kart\u0131n\u0131n CUDA mimarisini kullanmas\u0131 i\u00e7in ayarlanmas\u0131\ndevice = th.device('cuda' if th.cuda.is_available() else 'cpu')\n\n# Modelin e\u011fitilmesi\nmodel = train()\nth.save(model.state_dict(), \"model.pt\")","1b2d5e81":"print(\"<Model saved successfully>\")","e5247e40":"testing_dir = \"..\/input\/dac-yapikredi-project\/test\/test\"\ntesting_csv = \".\/testing.csv\"\n\nbatch_size = 64  # 32\nepochs = 40  # 256","e5c063fb":"# Test veri setinin y\u00fcklenmesi\ntest_dataset = SiameseDataset(\n    training_csv=testing_csv,\n    training_dir=testing_dir,\n    transform=transforms.Compose([transforms.Resize((105, 105)),transforms.ToTensor()])\n)\ntest_dataloader = DataLoader(test_dataset, num_workers=6, batch_size=1, shuffle=True)","8c8b1be0":"# Ekran kart\u0131n\u0131n CUDA mimarisini kullanmas\u0131 i\u00e7in ayarlanmas\u0131\ndevice = th.device('cuda' if th.cuda.is_available() else 'cpu')\n\n# E\u011fitilen modelin y\u00fcklenmesi\nmodel = SiameseNetwork().to(device)\nmodel.load_state_dict(th.load(\".\/model.pt\"))","f64d5e3f":"counter = 0\nfor i, data in enumerate(test_dataloader, 0):\n    x0, x1, label = data\n    concatenated = th.cat((x0, x1), 0)\n    output1, output2 = model(x0.to(device), x1.to(device))\n    eucledian_distance = F.pairwise_distance(output1, output2)\n    submission['score'][i] = eucledian_distance\n    counter = counter + 1\n    if counter == len(submission):\n        break","aa612efd":"eucledian_distance_min = submission['score'].min()\neucledian_distance_max = submission['score'].max()","99d01df9":"# \u00d6klid uzakl\u0131\u011f\u0131n\u0131n, benzerlik skoruna d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi\nsubmission['score'] = (\n        (submission['score'] - submission['score'].min()) \/\n        (submission['score'].max() - submission['score'].min())\n)\n\n# Ayn\u0131 m\u00fc\u015fterinin ayn\u0131 imza resmi i\u00e7in 1.00 benzerlik\nindices = np.where(idinfo1.img1no == idinfo1.img2no)\nfor i in indices:\n    submission['score'][i] = 0\n\nsubmission['score'] = 1 - submission['score']","55222355":"submission","9eb967e7":"submission.to_csv('.\/submission.csv', index=False)","ec241f39":"counter = 0\nlist_0 = th.FloatTensor([[0]])\nlist_1 = th.FloatTensor([[1]])\nfor i, data in enumerate(test_dataloader, 0): \n  x0, x1, label = data\n  concatenated = th.cat((x0, x1), 0)\n  output1, output2 = model(x0.to(device), x1.to(device))\n  eucledian_distance = F.pairwise_distance(output1, output2)\n  \n  if label == list_0:\n    label = \"Ayn\u0131 M\u00fc\u015fteri\"\n  else:\n    label = \"Farkl\u0131 M\u00fc\u015fteri\"\n      \n  imshow(\n      torchvision.utils.make_grid(concatenated),\n      'Benzerlik Skoru: {:.2f} Label: {}'.format(\n          (eucledian_distance.item() - eucledian_distance_min) \/\n          (eucledian_distance_max - eucledian_distance_min),\n          label          \n      )   \n  )\n  counter = counter + 1  \n  if counter == 10:\n     break","08d580b6":"\"\"\"test_dataloader = DataLoader(test_dataset,num_workers=6,batch_size=1,shuffle=True)\naccuracy=0\ncounter=0\ncorrect=0\nfor i, data in enumerate(test_dataloader,0): \n  x0, x1 , label = data\n  # onehsot applies in the output of 128 dense vectors which is then converted to 2 dense vectors\n  output1,output2 = model(x0.to(device),x1.to(device))\n  res=th.abs(output1.cuda() - output2.cuda())\n  label=label[0].tolist()\n  label=int(label[0])\n  result=th.max(res,1)[1][0][0][0].data[0].tolist()\n  if label == result:\n        correct=correct+1\n        counter=counter+1\n#   if counter ==20:\n#      break\n    \naccuracy=(correct\/len(test_dataloader))*100\nprint(\"Accuracy:{}%\".format(accuracy))\"\"\"","391b4d32":"<font size =\"5\"> \u0130\u00e7indekiler <\/font>\n1. <a href='#gir'>Giri\u015f<\/a>\n2. <a href='#sia'>Siamese Networks<\/a>\n3. <a href='#ben'>Benzerlik Skoru: \u00d6klid Uzakl\u0131\u011f\u0131 (Euclidean Distance)<\/a>\n4. <a href='#con'>Contrastive Loss<\/a>\n5. <a href='#kul'>Kullan\u0131lan Python K\u00fct\u00fcphaneleri<\/a>\n6. <a href='#kay'>Kay\u0131p Fonksiyonunun Tan\u0131mlanmas\u0131<\/a>\n7. <a href='#ver'>Veri \u00d6n \u0130\u015fleme (Data pre-processing)<\/a>\n8. <a href='#siam'>Siamese Network'\u00fcn Tan\u0131mlanmas\u0131<\/a>\n9. <a href='#mod'>Modelin E\u011fitilmesi<\/a>\n10. <a href='#son'>Sonu\u00e7lar<\/a>\n11. <a href='#kayn'>Kaynak\u00e7a<\/a>","e069e1cb":"<a id='ben'><\/a>\n# 3. Benzerlik Skoru: \u00d6klid Uzakl\u0131\u011f\u0131 (Euclidean Distance)\n\n![](https:\/\/camo.githubusercontent.com\/6e838e683cd62e3089e7f8e8ca708cc2705ff87e\/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4c774f42627747584d5a5579364f7a6b464150547a772e706e67)\n\nSiamese Network 1'a, bir m\u00fc\u015fterinin imzas\u0131n\u0131n resmi girdi olarak verilir ve yapay sinir a\u011f\u0131 girdinin encode edilmi\u015f halini \u00fcretir. Ayn\u0131 m\u00fc\u015fterinin farkl\u0131 bir imzas\u0131n\u0131n resmi ise Siamese Network 2'ya girdi olarak verilir ve a\u011f yine bir encode edilmi\u015f \u00e7\u0131kt\u0131 \u00fcretir. Bu iki \u00e7\u0131kt\u0131 aras\u0131ndaki \u00f6klid uzakl\u0131\u011f\u0131na bir d\u00f6n\u00fc\u015f\u00fcm uygulanarak benzerlik skoru hesaplanm\u0131\u015f olur. E\u011fer benzerlik skoru \u00f6nceden belirlenen bir e\u015fik de\u011ferinin (threshold value) alt\u0131nda ise bu iki imzan\u0131n ayn\u0131 m\u00fc\u015fteriye ait oldu\u011fu, e\u011fer fark e\u015fik de\u011ferinin \u00fczerinde ise bu iki imzan\u0131n ayn\u0131 m\u00fc\u015fteriye ait olmad\u0131\u011f\u0131 anla\u015f\u0131l\u0131r.\n\n$$D_w=\\sqrt{\\sum_{i=1}^n (\\boldsymbol{x_{i}}-\\boldsymbol{y_{i}})^2}$$\n\nE\u015fitlikte $\\boldsymbol{x_{i}}$ ve $\\boldsymbol{y_{i}}$ modelin \u00fcretti\u011fi iki encode vekt\u00f6r\u00fcd\u00fcr. Bu iki vekt\u00f6r, bu problem i\u00e7in 123(?) elemandan olu\u015fur. \u0130ki vekt\u00f6r\u00fcn, eleman-eleman farklar\u0131n\u0131n kareleri toplan\u0131p, bu toplam\u0131n karek\u00f6k\u00fc al\u0131narak \u00f6klid uzakl\u0131\u011f\u0131 hesaplanm\u0131\u015f olur.\n\n\u00d6klid uzakl\u0131\u011f\u0131ndan benzerlik skorunu elde etmek i\u00e7in, 'Min-Max scaling' kullan\u0131lm\u0131\u015ft\u0131r. Buradaki ama\u00e7, \u00f6klid uzakl\u0131klar\u0131n\u0131n da\u011f\u0131l\u0131m\u0131n\u0131 de\u011fi\u015ftirmeden $[0,1]$ aral\u0131\u011f\u0131na ta\u015f\u0131makt\u0131r. \n\n$$x_{scaled}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n\nBu de\u011fer bize benzemezlik skorunu verece\u011finden, benzerlik skorunu elde etmek i\u00e7in \u00f6l\u00e7eklenmi\u015f de\u011ferler $1$'den \u00e7\u0131kart\u0131lm\u0131\u015ft\u0131r.\n\n'Min-Max scaling', u\u00e7 de\u011ferlere (outlier) kar\u015f\u0131 duyarl\u0131 oldu\u011fundan, benzerlik skorunu elde etmeden \u00f6nce ve elde ettikten sonraki da\u011f\u0131l\u0131mlar kar\u015f\u0131la\u015ft\u0131r\u0131lm\u0131\u015ft\u0131r.","7fdeb44f":"<a id='kay'><\/a>\n# 6. Kay\u0131p Fonksiyonunun Tan\u0131mlanmas\u0131","6c7e4636":"![](https:\/\/i.imgur.com\/6XFZDKq.jpg)","6a67ce27":"<a id='sia'><\/a>\n# 2. Siamese Networks\n\n\nSiamese Networks, ilk olarak 90'l\u0131 y\u0131llar\u0131n ba\u015flar\u0131nda Bromley ve LeCun taraf\u0131ndan imza do\u011frulama probleminde kullan\u0131lm\u0131\u015ft\u0131r.\n    \nSiamese Networks, birbirinden farkl\u0131 iki girdi (input) kabul eden, birbirinin ayn\u0131s\u0131 iki yapay sinir a\u011f\u0131ndan olu\u015fturulmu\u015ftur. Bu sinir a\u011flar\u0131nda, her iki a\u011fda da parametreler ortakt\u0131r. Bu strateji, sinir a\u011flar\u0131n\u0131n \u00fcretti\u011fi tahminlerin tutarl\u0131 olmas\u0131n\u0131 sa\u011flar. Ayn\u0131 a\u011f\u0131rl\u0131\u011fa sahip sinir a\u011flar\u0131 olduklar\u0131 i\u00e7in birbirine \u00e7ok benzeyen iki resim kullan\u0131ld\u0131\u011f\u0131nda a\u011f\u0131n \u00fcretece\u011fi benzerlik skoru, bu iki resmin ayn\u0131 kayna\u011fa (bu problemde ayn\u0131 m\u00fc\u015fteriye) ait oldu\u011funu g\u00f6sterecektir. Farkl\u0131 iki resim girdi olarak verildi\u011finde ise benzerlik skoru \u00e7ok k\u00fc\u00e7\u00fck olaca\u011f\u0131 i\u00e7in bu iki resmin farkl\u0131 kaynaklara ait oldu\u011funu g\u00f6sterecektir.\n\n# Siamese Networks Mimarisi\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*hBJRs10uBc9a2Ol10N-jlg.png)\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*IhjVjQwQuCdsZk3Qcavt-w.png)","05864e95":"<a id='kayn'><\/a>\n# 8. Kaynak\u00e7a\n\n<a id='[1]'><\/a>\n* [Signature Verification using a \"Siamese\" Time Delay Neural Network](https:\/\/papers.nips.cc\/paper\/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf)\n* [Signature Verification System Using Siamese Networks](https:\/\/github.com\/seanbenhur\/siamese_net#signature-verification-system-using-siamese-networks)\n* [SigNet: Convolutional Siamese Network for Writer Independent Offline Signature Verification](https:\/\/arxiv.org\/abs\/1707.02131)\n* [Siamese Neural Networks for One-shot Image Recognition](http:\/\/cs231n.stanford.edu\/reports\/2017\/pdfs\/801.pdf)\n* [Siamese Convolutional Neural Networks for Authorship Verification](http:\/\/cs231n.stanford.edu\/reports\/2017\/pdfs\/801.pdf)\n* [Siamese Neural Network (With Pytorch Code Example)](https:\/\/innovationincubator.com\/siamese-neural-network-with-pytorch-code-example\/)    \n* [ICDAR 2011 Dataset](https:\/\/drive.google.com\/drive\/folders\/1hFljH9AKhxxIqH-3fj72mCMA6Xh3Vv0m)\n* [Yapay Zeka Terimleri S\u00f6zl\u00fc\u011f\u00fc](https:\/\/github.com\/deeplearningturkiye\/turkce-yapay-zeka-terimleri)\n* [Siyam A\u011flar\u0131(Siamese Networks) ve Y\u00fcz Do\u011frulama Sistemi](https:\/\/snnclsr.github.io\/2018\/04\/16\/siamese-networks\/)","b79ccbbc":"<a id='son'><\/a>\n# 10. Sonu\u00e7lar","090e77c7":"# <center> **DAC - Yap\u0131 Kredi Project**\n### <center> **Serbest D\u00fczen Dijital Dok\u00fcman \u00dcst\u00fcnde \u0130mza Do\u011frulama Vaka \u00c7al\u0131\u015fmas\u0131 \u00c7\u00f6z\u00fcm\u00fc (MSE: 0.00518)**\n### <center> Abdullah Altay","d981ba8a":"* Baz\u0131 \u0130mza \u0130kililerinin Resimleri ve Benzerlik Skorlar\u0131","aa6345fb":"\u00d6ncelikle Data & Analytics Challenge'\u0131 d\u00fczenledikleri i\u00e7in Bo\u011fazi\u00e7i \u00dcniversitesi Y\u00f6neylem Ara\u015ft\u0131rma Kul\u00fcb\u00fc'ne, Insider ve Yap\u0131 Kredi \u015firketlerine te\u015fekk\u00fcrlerimizi sunar\u0131z.","35f20a6e":"## * Precision-Recall De\u011ferleri ve Confusion Matrisinin K\u0131yaslanmas\u0131","ea7baf95":"<a id='kul'><\/a>\n# 5. Kullan\u0131lan Python K\u00fct\u00fcphaneleri","939b008d":"<a id='con'><\/a>\n# 4. Contrastive Loss\n\nYapay sinir a\u011flar\u0131n\u0131n amac\u0131 hata fonksiyonunu (loss function) m\u00fcmk\u00fcn olan en d\u00fc\u015f\u00fck seviyeye getirmektir. Tahmin bazl\u0131 (prediction based) hata fonksiyonlar\u0131n\u0131n aksine, burada uzakl\u0131k bazl\u0131 bir hata fonksiyonu tan\u0131mlanm\u0131\u015ft\u0131r.\n\n$$(1-Y)\\frac{1}{2}{D_w}^2 + (Y)\\frac{1}{2}{max(0,  m-D_w)}^2$$\n\nE\u015fitlikte $Y$, girdi olarak verilen imza resimleri ayn\u0131 m\u00fc\u015fteriye ait ise 1, farkl\u0131 m\u00fc\u015fterilere ait ise 0 olur. $D_w$ iki vekt\u00f6r aras\u0131ndaki uzakl\u0131\u011f\u0131, $m$ ise 'margin'\u2018i temsil eder.\n\nE\u011fer iki resim aras\u0131ndaki uzakl\u0131k 0 olursa, hata fonksiyonu $(0 + 0) = 0$ gibi bir sonu\u00e7 \u00fcretir ve bu y\u00fczden t\u00fcrevler $0$ olur ve model e\u011fitilemeyecektir. Bu problemi \u00e7\u00f6zmek i\u00e7in $margin(m)$ de\u011ferini hata fonksiyonuna eklenir ve bir \u00e7\u0131kt\u0131 \u00fcretmeye zorlan\u0131r.","6079a885":"## * Receiver Operating Characteristic (ROC) ve Precision-Recall E\u011frileri\n\n![](https:\/\/aapm.onlinelibrary.wiley.com\/cms\/asset\/bf8a0769-824e-4891-8f33-97b685214432\/mp14397-fig-0007-m.jpg)\n\n\n\n* TPR : M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imzan\u0131n model taraf\u0131ndan do\u011frulanmama durumunda, m\u00fc\u015fteriden yeniden imza atmas\u0131n\u0131 isteme olas\u0131l\u0131\u011f\u0131.\n* FPR : M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza model taraf\u0131ndan do\u011frulanm\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklenmemektedir.","27a5fa36":"<a id='mod'><\/a>\n# 9. Modelin E\u011fitilmesi","4c30b374":"## * Se\u00e7ilen Precision-Recall De\u011ferinin Problemdeki R\u00f6l\u00fc","8f5402b3":"<a id='ver'><\/a>\n# 7. Veri \u00d6n \u0130\u015fleme (Data pre-processing)","180a5217":"## * Precision-Recall Noktas\u0131n\u0131n Belirlenmesi\n\n![](https:\/\/miro.medium.com\/max\/302\/1*0W7a6S1w70aLOBBRO815oA.png)\n\nG\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi recall ve precision iki \u00f6nemli metrik ve aralar\u0131nda bir trade-off var. Bununla ba\u015f edebilmek i\u00e7in F1-skoru kullan\u0131l\u0131yor. F1-skoru ekstrem durumlar\u0131 cezaland\u0131rmak i\u00e7in aritmetik ortalama yerine harmonik ortalamay\u0131 kullan\u0131yor.","8ab200a8":"## * Precision-Recall De\u011ferleri Confusion Matrisi\n\n<img src=\"https:\/\/i.hizliresim.com\/AOodP8.jpg\" width=\"800\">\n\n* 37541 M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza model taraf\u0131ndan do\u011frulanm\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklenmemektedir. (TN)\n* 2746 M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza model taraf\u0131ndan do\u011frulanm\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklenmektedir. (TP)\n* 258 M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza model taraf\u0131ndan do\u011frulanmam\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklenmektedir. (FP)\n* 1071 M\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza model taraf\u0131ndan do\u011frulanmam\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklenmemektedir. (FN)\n\nM\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imzan\u0131n (e\u011fitilen modeli kullanarak) do\u011frulanmak istendi\u011fi bir senaryoda, -test verisetinde oldu\u011fu gibi farkl\u0131 m\u00fc\u015fterilerin imzalar\u0131 de\u011fil, ayn\u0131 m\u00fc\u015fterinin imzas\u0131 do\u011frulanmak istedi\u011finde...\n\nM\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza -ger\u00e7ekte benzer iken- model taraf\u0131ndan do\u011frulanmam\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 kabul edilebilir. Ancak m\u00fc\u015fterinin daha \u00f6nceden elde edilen bir imzas\u0131 ile yeni att\u0131\u011f\u0131 bir imza -ger\u00e7ekte benzer de\u011fil iken yani sahteyken- model taraf\u0131ndan do\u011frulanm\u0131\u015f ve m\u00fc\u015fteriden yeniden imza atmas\u0131 beklememek kabul edilebilemez. Di\u011fer bir deyi\u015fle false negative false positiveden daha kritik. Kanserli birini tespit edemeyip \u00f6l\u00fcm\u00fcne neden olmaktansa kanser olmayan biri i\u00e7in yanl\u0131\u015f tahmin yap\u0131p onu hastaneye \u00e7a\u011f\u0131rmak daha kabul edilebilir.","5ef7a3a1":"<a id='gir'><\/a>\n# 1. Giri\u015f","79f6ef2a":"<a id='siam'><\/a>\n# 8. Siamese Network'\u00fcn Tan\u0131mlanmas\u0131","49f72857":"Son halini g\u00fcncelleyece\u011fim. Eksikte olsa payla\u015fmak istedim.","b44afbfd":"M\u00fckemmele yak\u0131n bir skor ile birinci olan SiegmundsHof ekibini, son g\u00fcn ikincilik m\u00fccalesi verdi\u011fimiz VOLTRAN ekibini ve son saatlerde s\u00fcrpriz \u015fekilde iki ekibi de ekarte eden Abnormal Distribution ekibini tebrik ederiz."}}