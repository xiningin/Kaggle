{"cell_type":{"09177ead":"code","72eaf67e":"code","cdedd2e9":"code","f776d77f":"code","163640a4":"code","267343a1":"code","0a32ab81":"code","75eade84":"code","8805a385":"code","b1719c17":"code","53c7cae2":"code","2f866142":"code","886d03d1":"code","23763fb2":"code","f48c521a":"code","fb919000":"code","bc598c65":"code","ec92d66b":"code","bd0339c5":"code","220061af":"code","beba3f37":"code","a5f53ecc":"code","eee24ebd":"code","851696b0":"code","0686d857":"code","aa3fa407":"code","2bd88e45":"code","2ab38a80":"code","6d0b9ca9":"code","841e54a7":"code","167c08ae":"code","317f880b":"code","f7f27789":"code","2683f21c":"code","1a52f9c9":"code","1e91728c":"code","ac432ce6":"code","825020f3":"code","2fba961d":"code","8ffc3fea":"code","58ae9e77":"code","cac9c2b9":"code","c89a1b87":"code","ef846ab5":"code","b010206d":"code","07f2ffca":"code","0f459fb0":"code","c7aa2508":"code","b67864b1":"code","51da5fe9":"code","421c7c94":"code","0f1fc280":"code","83a91fd8":"code","e4d6af23":"code","f612c6cd":"code","30225a12":"code","2ec3182f":"markdown","530d464c":"markdown","b1fd25f8":"markdown","4d2de0a2":"markdown","ca73daad":"markdown","1c4fc245":"markdown","c9ab0421":"markdown","fe774340":"markdown","ad8ec081":"markdown","537e4b21":"markdown","04f0bff0":"markdown"},"source":{"09177ead":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72eaf67e":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","cdedd2e9":"train.isnull().sum()","f776d77f":"train.dtypes","163640a4":"train.head()","267343a1":"name_list=[]\nfor i in train['Name']:\n    if 'Mr' in i:\n        name_list.append('Mr')\n    elif 'Miss' in i:\n        name_list.append('Miss')\n    elif 'Master' in i:\n        name_list.append('Master')\n    elif 'Mrs' in i:\n        name_list.append('Mrs')\n    else:\n        name_list.append('Others') ","0a32ab81":"name_list_test=[]\nfor i in test['Name']:\n    if 'Mr' in i:\n        name_list_test.append('Mr')\n    elif 'Miss' in i:\n        name_list_test.append('Miss')\n    elif 'Master' in i:\n        name_list_test.append('Master')\n    elif 'Mrs' in i:\n        name_list_test.append('Mrs')\n    else:\n        name_list_test.append('Others') ","75eade84":"train['Name']=name_list\ntest['Name']=name_list_test","8805a385":"train.head()","b1719c17":"train['Age'].fillna(train['Age'].mean(),inplace=True)\ntrain['Embarked'].fillna('U',inplace=True)\ntrain['Cabin'].fillna('U',inplace=True)","53c7cae2":"train['Cabin']=[i[0] for i in train['Cabin']]","2f866142":"cabin_category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'T':8, 'U':9}\ntrain['Cabin'] = train['Cabin'].map(cabin_category)","886d03d1":"train.isnull().sum()","23763fb2":"test.isnull().sum()","f48c521a":"test.dtypes","fb919000":"test['Age'].fillna(test['Age'].mean(),inplace=True)\ntest['Fare'].fillna(test['Fare'].mean(),inplace=True)\ntest['Cabin'].fillna('U',inplace=True)","bc598c65":"test['Cabin']=[k[0] for k in test['Cabin']]","ec92d66b":"test['Cabin'] = test['Cabin'].map(cabin_category)","bd0339c5":"test.isnull().sum()","220061af":"train.head()","beba3f37":"test.head()","a5f53ecc":"train['Sex']=train['Sex'].map({'male':0,'female':1})\ntest['Sex']=test['Sex'].map({'male':0,'female':1})","eee24ebd":"train['Age']=train['Age'].astype(int)\ntest['Age']=test['Age'].astype(int)","851696b0":"train['family']=train['SibSp']+train['Parch']\ntest['family']=test['SibSp']+test['Parch']\ntrain['family']=train['family'].astype(int)\ntest['family']=test['family'].astype(int)","0686d857":"train['Fare']=np.log1p(train['Fare'])\ntest['Fare']=np.log1p(test['Fare'])","aa3fa407":"bins= [0, 25, 45, 65, 100]\nlabels = ['children','teens', 'adults','seniorcitizen']\ntrain['Age']=pd.cut(train['Age'], bins=bins, labels=labels, right=False)\ntest['Age']=pd.cut(test['Age'], bins=bins, labels=labels, right=False)","2bd88e45":"y=train['Survived']\nX=train.drop(['PassengerId','Survived','SibSp','Parch','Ticket'],axis=1)\ntest=test.drop(['PassengerId','SibSp','Parch','Ticket'],axis=1)","2ab38a80":"X.head()","6d0b9ca9":"test.head()","841e54a7":"X=pd.get_dummies(X,drop_first=True)\ntest=pd.get_dummies(test,drop_first=True)","167c08ae":"X.shape,test.shape","317f880b":"test.head()","f7f27789":"X.head()","2683f21c":"X.columns","1a52f9c9":"test.columns","1e91728c":"X=X[test.columns]","ac432ce6":"X.shape","825020f3":"y.shape","2fba961d":"test.shape","8ffc3fea":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=19)","58ae9e77":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\n\n# we must apply the scaling to the test set that we computed for the training set\nX_test_scaled = scaler.transform(X_test)","cac9c2b9":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(max_iter=10000)\nlogreg.fit(X_train_scaled, y_train)\n\n#R-Squared Score\nprint(\"R-Squared for Train set: {:.3f}\".format(logreg.score(X_train_scaled, y_train)))\nprint(\"R-Squared for test set: {:.3f}\" .format(logreg.score(X_test_scaled, y_test)))","c89a1b87":"from sklearn.svm import LinearSVC\n\nsvmclf = LinearSVC(C=50)\nsvmclf.fit(X_train, y_train)\n\nprint('Accuracy of Linear SVC classifier on training set: {:.2f}'\n     .format(svmclf.score(X_train, y_train)))\nprint('Accuracy of Linear SVC classifier on test set: {:.2f}'\n     .format(svmclf.score(X_test, y_test)))","ef846ab5":"svmclf = LinearSVC()\nsvmclf.fit(X_train_scaled, y_train)\n\nprint('Accuracy of Linear SVC classifier on training set: {:.2f}'\n     .format(svmclf.score(X_train_scaled, y_train)))\nprint('Accuracy of Linear SVC classifier on test set: {:.2f}'\n     .format(svmclf.score(X_test_scaled, y_test)))","b010206d":"from sklearn.svm import SVC\n\nsvcclf = SVC(gamma=0.1)\nsvcclf.fit(X_train, y_train)\n\nprint('Accuracy of Linear SVC classifier on training set: {:.2f}'\n     .format(svcclf.score(X_train, y_train)))\nprint('Accuracy of Linear SVC classifier on test set: {:.2f}'\n     .format(svcclf.score(X_test, y_test)))","07f2ffca":"svcclf = SVC(gamma=50)\nsvcclf.fit(X_train_scaled, y_train)\n\nprint('Accuracy of Linear SVC classifier on training set: {:.2f}'\n     .format(svcclf.score(X_train_scaled, y_train)))\nprint('Accuracy of Linear SVC classifier on test set: {:.2f}'\n     .format(svcclf.score(X_test_scaled, y_test)))","0f459fb0":"from sklearn.tree import DecisionTreeClassifier\n\ndtclf = DecisionTreeClassifier(max_depth = 3).fit(X_train, y_train)\n\nprint('Accuracy of Decision Tree classifier on training set: {:.2f}'\n     .format(dtclf.score(X_train, y_train)))\nprint('Accuracy of Decision Tree classifier on test set: {:.2f}'\n     .format(dtclf.score(X_test, y_test)))","c7aa2508":"from sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(random_state=2)","b67864b1":"# Set our parameter grid\nparam_grid = { \n    'criterion' : ['gini', 'entropy'],\n    'n_estimators': [100, 300, 500],\n    'max_features': ['auto', 'log2'],\n    'max_depth' : [3, 5, 7]    \n}","51da5fe9":"from sklearn.model_selection import GridSearchCV\n\nrandomForest_CV = GridSearchCV(estimator = rfclf, param_grid = param_grid, cv = 5)\nrandomForest_CV.fit(X_train, y_train)","421c7c94":"randomForest_CV.best_params_","0f1fc280":"rf_clf = RandomForestClassifier(random_state = 2, criterion = 'gini', max_depth = 7, max_features = 'auto', n_estimators = 500)\n\nrf_clf.fit(X_train, y_train)\npredictions = rf_clf.predict(X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, predictions) * 100","83a91fd8":"from lightgbm import LGBMClassifier\nmodel = LGBMClassifier(boosting_type='gbdt',\n                       max_depth=5,\n                       learning_rate=0.05,\n                       n_estimators=5000,\n                       min_child_weight=0.01,\n                       colsample_bytree=0.5,\n                       random_state=1994,\n                       objective='binary')\n\nmodel.fit(X_train,y_train,\n          eval_set=[(X_train,y_train),(X_test, y_test.values)],\n          early_stopping_rounds=100,\n          verbose=200)\n\npred_y = model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(pred_y, y_test) * 100\n","e4d6af23":"submission['Survived']=model.predict(test)","f612c6cd":"submission.head()","30225a12":"submission.to_csv('titanic_09.csv',index=False)","2ec3182f":"## RandomForestClassifier with Hyperparameter Tuning","530d464c":"## Final Submission","b1fd25f8":"## Linear SVM","4d2de0a2":"## Inporting Libraries & Dataset","ca73daad":"## Linear SVM on scaled data","1c4fc245":"## Preprocessing of data and filling NA values","c9ab0421":"## Decision Tree Classifier","fe774340":"## Scaling using MinMaxScaler","ad8ec081":"## LightGBM model","537e4b21":"## LightGBM seems to be best choice","04f0bff0":"## Logistic Regression"}}