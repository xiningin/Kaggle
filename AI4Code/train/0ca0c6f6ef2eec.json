{"cell_type":{"aa39b36a":"code","a05ed023":"code","80c51778":"code","a954d799":"code","36538170":"code","aed23828":"code","8be40a4b":"code","ba4d0d7f":"code","68f0f1aa":"code","ffffcac9":"code","219b0704":"code","2f4080ee":"code","713208d9":"code","799c73d9":"code","5af34616":"code","f1f776e7":"code","8c7d1555":"code","8648325f":"code","b9f7c5a2":"code","8adf777c":"code","245c1c21":"code","c7a93859":"code","963ee259":"code","2a1c5b04":"code","3cb316a4":"code","5661a3fb":"code","bef15a70":"code","5f41eb08":"code","927de7af":"code","6e8310a9":"code","510ef8be":"code","7f47af89":"code","2ca9dbb2":"code","667feb3f":"code","897be609":"code","0d4f886f":"code","318df926":"code","3d6445ea":"code","4b75e402":"code","83f8676f":"code","2070c6cd":"code","2825a3a6":"code","2f03c82b":"code","01d81f0b":"code","85778315":"code","541e9c22":"code","e6fec7c2":"code","1dc92aae":"code","5e6ca1fa":"code","6bc588cc":"code","bf0ee25b":"code","49ab0b34":"code","d9422d61":"code","0dcd7253":"code","66d25fc0":"code","cfe4af65":"code","1134de46":"code","e28e72a5":"code","0e01a3bb":"code","611bb959":"code","04776db5":"code","6baaff97":"code","ed02b6bc":"code","c415ae18":"code","8e063f68":"code","53e3ff35":"code","ebe68c7c":"code","7672d0e5":"code","e02fcb0b":"markdown","a458ac27":"markdown","d77d2581":"markdown","42d31e63":"markdown","8ffab7bf":"markdown","aa99f82f":"markdown","55e15eea":"markdown","779c2fad":"markdown","db9f47ac":"markdown","eab1f001":"markdown","27358696":"markdown"},"source":{"aa39b36a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, make_scorer","a05ed023":"from matplotlib.pyplot import figure\nimport warnings\nwarnings.filterwarnings(\"ignore\")","80c51778":"# Copied from github\n\ndef histogram_boxplot(feature, figsize=(10,5), bins = None):\n    \n    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2,\n                                           sharex = True, \n                                           gridspec_kw = {\"height_ratios\": (.25, .75)}, \n                                           figsize = figsize \n                                           ) \n    \n    sns.boxplot(x=feature, ax=ax_box2, showmeans=True, color='violet')\n    sns.histplot(x=feature, kde=F, ax=ax_hist2, bins=bins,palette=\"winter\") if bins else sns.histplot(feature, kde=False, ax=ax_hist2) \n    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') \n    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') ","a954d799":"# Copied from github \n\ndef box_plt(feature, variable):\n    plt.figure(figsize=(15,6)) \n    \n    sns.boxplot(feature, x='Class',y=variable, data=data,palette='coolwarm',showmeans=True,\n           meanprops={\"marker\":\"^\",\n                    \"markerfacecolor\":\"white\",\n                    \"markeredgecolor\":\"black\",\n                    \"markersize\":\"8\"});","36538170":"data  = pd.read_csv(\"..\/input\/dry-beans-classification-iti-ai-pro-intake01\/train.csv\")\ntest= pd.read_csv(\"..\/input\/dry-beans-classification-iti-ai-pro-intake01\/test.csv\")\ndata.head()","aed23828":"data_heads = data.iloc[:, 1:-1].columns.array # Excluding ID and target\ndata_heads","8be40a4b":"data.shape","ba4d0d7f":"data.info()","68f0f1aa":"data[data_heads].describe().T","ffffcac9":"data[data_heads].isnull().sum()","219b0704":"fig, axes = plt.subplots(4, 4, figsize=(20, 22))\nfor i, axe in enumerate(axes.flatten()):\n    sns.histplot(data[data_heads[i]], ax = axe)\n    median = data[data_heads[i]].median()\n    axe.set_title(data_heads[i] + f' ,Median : {median:0.1f}')\n    axe.axvline(median, color ='red', lw=2, alpha = 0.55)","2f4080ee":"fig, axes = plt.subplots(4, 4, figsize=(20, 22))\nfor i, axe in enumerate(axes.flatten()):\n    sns.boxplot(data = data[data_heads[i]], ax = axe)\n    axe.set_title(data_heads[i])\n    \nplt.tight_layout()\nplt.show()","713208d9":"for col in data_heads:\n    histogram_boxplot(data[col])","799c73d9":"plt.figure(figsize=(8,3))\ndata['y'].value_counts().sort_values().tail(7).plot(kind='barh', fontsize=12)\nplt.title(\"Distributioin of Target variable 'Class'\");","5af34616":"box_plt(data[\"y\"], data['Area'])\nbox_plt(data[\"y\"], data['ConvexArea'])","f1f776e7":"box_plt(data[\"y\"], data['Perimeter'])","8c7d1555":"box_plt(data[\"y\"], data['MajorAxisLength'])\nbox_plt(data[\"y\"], data['MinorAxisLength'])","8648325f":"box_plt(data[\"y\"], data['AspectRation'])","b9f7c5a2":"box_plt(data[\"y\"], data['Eccentricity'])","8adf777c":"box_plt(data[\"y\"], data['EquivDiameter'])","245c1c21":"box_plt(data[\"y\"], data['ShapeFactor1'])\nbox_plt(data[\"y\"], data['ShapeFactor2'])\nbox_plt(data[\"y\"], data['ShapeFactor3'])\nbox_plt(data[\"y\"], data['ShapeFactor4'])","c7a93859":"# sns.pairplot(data[data_heads]);","963ee259":"plt.figure(figsize=(14, 14))\ndat_cor = data.corr()\nsns.heatmap(dat_cor, cmap = 'YlGnBu', annot=True, square=True);","2a1c5b04":"from sklearn.preprocessing import StandardScaler","3cb316a4":"data[data_heads].head()","5661a3fb":"scaler = StandardScaler()\ndata_heads = pd.Series(data_heads)\n\ndata[data_heads] = pd.DataFrame(scaler.fit_transform(data[data_heads].values), columns=data[data_heads].columns, index=data.index)\n\n","bef15a70":"data[data_heads].head()","5f41eb08":"from sklearn.cluster import KMeans\nkmeans= KMeans(n_clusters=7)\n\nX = data.drop(columns=['ID','y'])\ny = data['y']","927de7af":"kmeans.fit(X)\nlabels= kmeans.predict(X)","6e8310a9":"print(labels[:8])","510ef8be":"#data['cluter']= labels","7f47af89":"data.head(40)","2ca9dbb2":"print(y.head(8))","667feb3f":"print(y.value_counts())","897be609":"from sklearn.model_selection import train_test_split","0d4f886f":"train_df, val_df = train_test_split(data, test_size=0.20, random_state=3) \n\nx_train = train_df.drop(columns=['ID','y'])\ny_train = train_df['y']\n\nx_val = val_df.drop(columns=['ID','y'])\ny_val = val_df['y']\n","318df926":"from xgboost import XGBClassifier","3d6445ea":"xg_model = XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.25,\n                max_depth = 20, alpha = 10, n_estimators = 40)","4b75e402":"xg_model.fit(x_train,y_train)","83f8676f":"y_pred= xg_model.predict(x_val)","2070c6cd":"xg_model.score(x_val,y_val)","2825a3a6":"f1 = make_scorer(f1_score , average = \"weighted\")","2f03c82b":"params_ada = {\n    \"n_estimators\": [5, 10, 15, 20],\n    \"learning_rate\": [0.4, 0.6, 0.8, 1.0]\n}\n","01d81f0b":"gs_ada = GridSearchCV(AdaBoostClassifier(base_estimator = RandomForestClassifier(max_depth = 10, n_estimators = 20, random_state = 42)), param_grid = params_ada, scoring = f1, cv = 4, n_jobs = -1)","85778315":"gs_ada.fit(x_train, y_train)","541e9c22":"gs_ada.cv_results_","e6fec7c2":"gs_ada.best_params_","1dc92aae":"ada = AdaBoostClassifier(base_estimator = RandomForestClassifier(max_depth = 10, n_estimators = 20, random_state = 42), n_estimators = 20, learning_rate = 0.6, random_state = 42)","5e6ca1fa":"def classification_task(estimator, attributes, labels):\n    \"\"\"\n    Function: \"fit\", \"predict\" and \"score\" values of an estimator.\n    \n    Parameters: estimator, attributes (X) and labels (y).\n    \n    Returns: model's performance measured as accuracy and f1_score.\n    \"\"\"\n    estimator.fit(attributes, labels)\n    predictions = estimator.predict(attributes)\n    \n    print(f\"Accuracy: {accuracy_score(labels, predictions)}\")\n    print(f\"F1 score: {f1_score(labels, predictions, average = 'weighted')}\")","6bc588cc":"classification_task(ada, x_train, y_train)","bf0ee25b":"classification_task(ada, x_val, y_val)","49ab0b34":"#classification_task(ada, test_features, test_labels_enc)","d9422d61":"#from sklearn.model_selection import GridSearchCV\n","0dcd7253":"'''\nparam = {'n_estimators' : range(2,100), \n'max_depth' : [12],\n'min_samples_split':[5],\n'min_samples_leaf':[2],\n'alpha' : range(1,10)}\n\ngridSearch_XGB=GridSearchCV(model,param,scoring='r2',cv=5)\ngridSearch_XGB.fit(x_train,y_train)\npredictionsXGB = gridSearch_XGB.predict(x_val)\n\nprint(\"max_depth= \",depth,\" RMSLE= \", np.sqrt(mean_squared_log_error( y_val, predictionsXGB )))\n'''","66d25fc0":"#param= {'n_estimators' : [10,20,30,40,60,80],'max_depth' : range(1,9), 'alpha':range(1,11)}\n#gs_model= GridSearchCV(model,param,scoring='r2',cv=5)\n","cfe4af65":"ID= test['ID']","1134de46":"test= test.drop('ID', axis= 1)","e28e72a5":"test= pd.DataFrame(scaler.fit_transform(test.values), columns=test.columns, index=test.index)","0e01a3bb":"test.head()","611bb959":"test_labels= kmeans.predict(test)\n#test['cluster']= test_labels","04776db5":"test.head()","6baaff97":"predicted = ada.predict(test)","ed02b6bc":"y_pred= xg_model.predict(test)","c415ae18":"test['y']= predicted\n","8e063f68":"test['ID']= ID","53e3ff35":"test[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)","ebe68c7c":"test[['ID', 'y']].head()","7672d0e5":"#y_cluster = test['cluster'].replace({0: 'SIRA', 1: 'CALI', 2: 'BOMBAY', 3: 'DERMASON' , 4: 'HOROZ' ,5: 'SEKER' , 6: 'BARBUNYA'})","e02fcb0b":"---","a458ac27":"- BOMBAY having higher Area, follwed by Cali and Barbunya. Least Area is for Dermason and Seker.","d77d2581":"- Bombay having higher Major Axis Length followed by Calia and Barbunya, least Major Axis Length is for Dermason and Seker.\n- Bombay having higher Minor Axis values, followed by Barbuya and Cali, least being Dermason. ","42d31e63":"- ShapeFactor 2 and 3 merely have the same trend, but ShapeFactor4 has a different (**Skewed**) one.\n","8ffab7bf":"<div class=\"alert alert-block alert-info\">\n    - Area is right skewed bit lot of max outliers, we can observe few extreme values afer 210000. <br> \n    - Perimeter is right-skewed data with max outliers; from 1900 onwards, we can see few data points having significantly higher values. <br>\n    - Major Axis Length is right-skewed data with max outliers; from 700 onwards, we can see few data points having significantly higher values. <br>\n    - Minor Axis Length is right-skewed data with max outliers; from 300 onwards, we can see significantly higher values. <br>\n    - Eccentricity is left-skewed with minimum outliers; we can see few data points having significantly lesser values <br>\n    - EquivDiameter is right-skewed data. <br>\n    - Extent is left-skewed data. <br>\n    - Compactness is normally distributed. <br>\n    - Shapefactor 1 is normally distributed with min and max outliers. <br>\n    - ShapeFactor 2 is normally distributed without any outliers. <br> \n    - ShapeFactor 4 is extremely left skewed with minimum outliers. <br>\n    - Comparing to ShapeFactor 3, 2, and 1 we can observe ShapeFactor 4 is extremely skewed. <br> \n    \n    - Most of the features are skewed, some features having significantly higher or lower values.\n    \n<\/div> \n\n---","aa99f82f":"---\n## Uni-Variate Data Analysis:","55e15eea":"---\n\n## Bi-Variate and Multi-Variate Data Analysis:","779c2fad":"- From the above we conclude that the majority of features are having higher correlation. (**Calculated from each others**)\n- We can handle these correlation issues in two ways: <br>\n1) either drop those highly correlated features<br>\n2) Leave them as it is because Tree-based models doesn't get affected with correlated traits, when they decide to split, the tree will choose only one of the perfectly correlated features. However, Linear Models are not immune to that problem and you should fix it before training the model.","db9f47ac":"- The Plot above shows how the target is distributed.","eab1f001":"---\n\n<center> <h1> EDA <\/h1> <\/center> \n\n---\n\n### Data Attributes:\n\n    1.  Area (A): The area of a bean zone and the number of pixels within its boundaries.\n    2.  Perimeter (P): Bean circumference is defined as the length of its border.\n    3.  Major axis length (L): The distance between the ends of the longest line that can be drawn from a bean.\n    4.  Minor axis length (l): The longest line that can be drawn from the bean while standing perpendicular to the axis.\n    5.  Aspect ratio (K): Defines the relationship between L and l.\n    6.  Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.\n    7.  Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\n    8.  Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area.\n    9.  Extent (Ex): The ratio of the pixels in the bounding box to the bean area.\n    10. Solidity (S): Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\n    11. Roundness (R): Calculated with the following formula: (4piA)\/(P^2)\n    12. Compactness (CO): Measures the roundness of an object: Ed\/L\n    13. ShapeFactor1 (SF1)\n    14. ShapeFactor2 (SF2)\n    15. ShapeFactor3 (SF3)\n    16. ShapeFactor4 (SF4)\n    17. Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)","27358696":"- Bombay having higher Perimeter, followed by Barbunya and Cali. Least Perimeter is for Dermason and Seker."}}