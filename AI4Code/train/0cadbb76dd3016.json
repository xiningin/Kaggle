{"cell_type":{"f63e13c9":"code","0b2b5764":"code","9f5a7dec":"code","b0c6e9d4":"code","b67fa661":"code","2fed36b5":"code","42f1b21e":"code","59c8f096":"code","f123cb55":"code","50fbe691":"code","5b7b7c10":"code","5b951009":"code","0582ce15":"code","b659b528":"code","91250df5":"code","43e86846":"code","509dda8e":"code","3004432d":"code","b0f48576":"code","e24c2097":"code","17b9b430":"markdown","a59e38e6":"markdown","20342e51":"markdown","d2b84532":"markdown","4a1ea07d":"markdown","ab420912":"markdown"},"source":{"f63e13c9":"# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\nimport sys\nimport pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib\nimport keras\n\nprint('Python: {}'.format(sys.version))\nprint('Numpy: {}'.format(np.__version__))\nprint('Sklearn: {}'.format(sklearn.__version__))\nprint('Pandas: {}'.format(pd.__version__))\nprint('Matplotlib: {}'.format(matplotlib.__version__))\nprint('Keras: {}'.format(keras.__version__))","0b2b5764":"# import the dataset\n\nnames = ['A1_Score',\n        'A2_Score',\n        'A3_Score',\n        'A4_Score',\n        'A5_Score',\n        'A6_Score',\n        'A7_Score',\n        'A8_Score',\n        'A9_Score',\n        'A10_Score',\n        'age',\n        'gender',\n        'ethnicity',\n        'jundice',\n        'family_history_of_PDD',\n        'contry_of_res',\n        'used_app_before',\n        'result',\n        'age_desc',\n        'relation',\n        'class']\n\n# read the file\ndata = pd.read_table('..\/input\/Autism-Child-Data_modified.txt', sep = ',', names = names)","9f5a7dec":"# print the shape of the DataFrame, so we can see how many examples we have\nprint('Shape of DataFrame: {}'.format(data.shape))\nprint(data.loc[0])","b0c6e9d4":"# print out multiple patients at the same time\ndata.loc[:10]","b67fa661":"# print out a description of the dataframe\ndata.describe()","2fed36b5":"# drop unwanted columns\ndata = data.drop(['result', 'age_desc'], axis=1)","42f1b21e":"data.loc[:10]","59c8f096":"# create X and Y datasets for training\nx = data.drop(['class'], 1)\ny = data['class']","f123cb55":"x.loc[:10]","50fbe691":"# convert the data to categorical values - one-hot-encoded vectors\nX = pd.get_dummies(x)","5b7b7c10":"# print the new categorical column labels\nX.columns.values","5b951009":"# print an example patient from the categorical data\nX.loc[1]","0582ce15":"# convert the class data to categorical values - one-hot-encoded vectors\nY = pd.get_dummies(y)","b659b528":"Y.iloc[:10]","91250df5":"from sklearn import model_selection\n# split the X and Y data into training and testing datasets\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size = 0.2)","43e86846":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","509dda8e":"# build a neural network using Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n# define a function to build the keras model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim=96, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n    \n    # compile model\n    adam = Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n    return model\n\nmodel = create_model()\n\nprint(model.summary())","3004432d":"# fit the model to the training data\nmodel.fit(X_train, Y_train, epochs=50, batch_size=10, verbose = 1)","b0f48576":"# generate classification report using predictions for categorical model\nfrom sklearn.metrics import classification_report, accuracy_score\n\npredictions = model.predict_classes(X_test)\npredictions","e24c2097":"print('Results for Categorical Model')\nprint(accuracy_score(Y_test[['YES']], predictions))\nprint(classification_report(Y_test[['YES']], predictions))","17b9b430":"# 5. Training the Network\n\nNow it's time for the fun! Training a Keras model is as simple as calling model.fit().","a59e38e6":"# 4. Building the Network - Keras\n\nIn this project, we are going to use Keras to build and train our network. This model will be relatively simple and will only use dense (also known as fully connected) layers. This is the most common neural network layer. The network will have one hidden layer, use an Adam optimizer, and a categorical crossentropy loss. We won't worry about optimizing parameters such as learning rate, number of neurons in each layer, or activation functions in this project; however, if you have the time, manually adjusting these parameters and observing the results is a great way to learn about their function!","20342e51":"# 6. Testing and Performance Metrics\n\nNow that our model has been trained, we need to test its performance on the testing dataset. The model has never seen this information before; as a result, the testing dataset allows us to determine whether or not the model will be able to generalize to information that wasn't used during its training phase. We will use some of the metrics provided by scikit-learn for this purpose!","d2b84532":"# 3. Split the Dataset into Training and Testing Datasets\n\nBefore we can begin training our neural network, we need to split the dataset into training and testing datasets. This will allow us to test our network after we are done training to determine how well it will generalize to new data. This step is incredibly easy when using the train_test_split() function provided by scikit-learn!","4a1ea07d":"# 2. Data Preprocessing\n\nThis dataset is going to require multiple preprocessing steps. First, we have columns in our DataFrame (attributes) that we don't want to use when training our neural network. We will drop these columns first. Secondly, much of our data is reported using strings; as a result, we will convert our data to categorical labels. During our preprocessing, we will also split the dataset into X and Y datasets, where X has all of the attributes we want to use for prediction and Y has the class labels.","ab420912":"# 1. Importing the Dataset\n\nWe will obtain the data from the UCI Machine Learning Repository; however, since the data isn't contained in a csv or txt file, we will have to download the compressed zip file and then extract the data manually. Once that is accomplished, we will read the information in from a text file using Pandas."}}