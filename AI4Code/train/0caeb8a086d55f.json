{"cell_type":{"a35fcbb2":"code","b5bbcce3":"code","dc2792c3":"code","d0ae7b5d":"code","699cc4bc":"code","25829d2a":"code","9a72f8ac":"code","59d618d3":"code","05f6ff90":"markdown","ce0cfddb":"markdown","e8340cd7":"markdown","4017cce2":"markdown","ca0009c6":"markdown","8ef93364":"markdown","b0e31eb3":"markdown","a6dc4bc4":"markdown","7467324c":"markdown","b707662f":"markdown","28b120d5":"markdown","7d96796a":"markdown","1e46010d":"markdown","3067666f":"markdown","23c875cd":"markdown","5570796d":"markdown"},"source":{"a35fcbb2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5bbcce3":"df = pd.read_csv(os.path.join(dirname,filename))\n\nset_items = list()\nfor row in df.fillna('').iterrows():\n    item_row = row[1].values\n    #exists 'asparagus' and ' asparagus'\n    item_row = [item.strip() for item in item_row if item != \"\"]\n    set_items.append(set(item_row))\n\ntransactions = list(set_items)\n\n#showing the output\ntransactions[:3]","dc2792c3":"from mlxtend.preprocessing import TransactionEncoder\n\n# Instantiate transaction encoder and fit in my list of sets data\nencoder = TransactionEncoder().fit(transactions)\n\n# Transform my actual data for a new representation\nonehot = encoder.transform(transactions)\n\n# Convert onehot encoded data to DataFrame\nonehot = pd.DataFrame(onehot, columns = encoder.columns_)\n\nonehot.iloc[:3]","d0ae7b5d":"#Most purchased items\nsupport = onehot.mean()\nsupport.sort_values()\n\n(100*support.sort_values(ascending=False))[:20].plot(kind='bar',grid=True,figsize = (12,5))\nplt.title(\"Probability of item in basket\",fontsize = 16)\nplt.xlabel('Item')\nplt.ylabel('Probability')","699cc4bc":"toy_items = [{'coal', 'sirloin', 'beer','pork'},\n             {'pork','beer', 'grounded beef'},\n             {'chicken', 'pork','grounded beef'},\n             {'sirloin', 'coal','pork'},\n             {'pork','coal', 'sirloin', 'coke'},\n             {'beer', 'coal','pork'}]\n\n#Pre-processing steps\nenc = TransactionEncoder().fit(toy_items)\nonehot_toy = enc.transform(toy_items)\n\n# Convert onehot encoded data to DataFrame\nonehot_toy = pd.DataFrame(onehot_toy, columns = enc.columns_)\n\nonehot_toy.astype(int)","25829d2a":"print('grounded beef support:', onehot_toy['grounded beef'].mean())\nprint('grounded beef & beer support:', np.logical_and(onehot_toy['grounded beef'],onehot_toy['beer']).mean())","9a72f8ac":"from itertools import permutations\n\ndef confidence(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() \/(df[itemA].mean()))\n\ndef lift(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() \/(df[itemA].mean() * df[itemB].mean()))\n\ndef leverage(itemA,itemB,df):\n    return np.logical_and(df[itemA],df[itemB]).mean() - (df[itemA].mean()*df[itemB].mean())\n\n\nitem_pairs = list()\nfor itemA,itemB in permutations(onehot,2):\n    item_pairs.append(list((itemA,itemB, #names\n                            onehot[itemA].sum(),onehot[itemB].sum(), #individual count\n                            np.logical_and(onehot[itemA],onehot[itemB]).sum(), #pair count\n                            confidence(itemA,itemB,onehot), #confidence\n                            lift(itemA,itemB,onehot), #lift\n                            leverage(itemA,itemB,onehot), # leverage\n                            ))) # \n    \nitem_pairs = pd.DataFrame(item_pairs,columns = ['itemA','itemB',\n                                                'countItemA','countItemB',\n                                                'countItemA&B',\n                                                'Confidence',\n                                                'Lift',\n                                                'Leverage'])\n\nitem_pairs.sample(5)","59d618d3":"THRESHOLD = 50\nitem_pairs[item_pairs['countItemA&B'] >= THRESHOLD].sort_values(by = 'Lift',ascending=False)[:10]","05f6ff90":"### Toy Data","ce0cfddb":"When we're dealing with Market Basket Analysis problems, it's really **interesting to calculate some metrics about our products**, but let's answer some questions about this dataset and understand our data before.\n\n### What is the best selling items in the dataset?\n\n","e8340cd7":"## Loading Data & Pre-processing\n\nFirst, we need to load the data and transform in a interest format for analysis.\nI conveniently want to transform the data **in a list of set format**.\n\nAs the example below:\n\n``\n[{'french fries', 'whole wheat pasta'},\n {'light cream', 'shallot', 'soup'},\n {'frozen vegetables', 'green tea', 'spaghetti'}]\n``\n\nI want to work with sets because, it's important to just consider **unique items purchased in a basket**.<br>\nIf someone bought 6 eggs, we will consider a egg purchase.","4017cce2":"We can even calculate these metrics with help of python","ca0009c6":"Looks like we have a interesting table as output and we can make filters to see interesting products for promotions.\n\nI will filter for products that occured at **least 50 times together**, this will filter for products that occured a reasonable number of times in baskets, after the filter, I will sort my data by **'Lift'**\n\nFell free to play with the filters in the data and incorporate metrics in this notebook :)","8ef93364":"<!--![Spiderman-OK](https:\/\/www.criarmeme.com.br\/meme\/meme-5109--ok-!.jpg) -->","b0e31eb3":"Very interesting, looks like the TOP 5 most common items in baskets are : mineral watter, eggs, spaghetti, french fries and chocolate.\n\nIt's important to note that the analysis above is just considering each item individually.\n\n- **From historic purchases, we can infer from out data** that the probability to have a mineral water in a random basket is ~24%\n\n- **From historic purchases, we can infer from out data** that the probability to have a eggs in a random basket is ~17%\n\n...\n\n- **From historic purchases, we can infer from out data** that the probability to have a turky in a random basket is ~6%\n\nThis is pretty insightfull!<br>\nIf I own this supermarket and know the most common items, I can give discount on these items to attract more customers  and consequently I will be able to increase my revenue.\n\n![](https:\/\/i.imgur.com\/YoVEnLJ.jpg)\n","a6dc4bc4":"I want to bring a point of attention:\n\n### Always question the data !\n\nNote that this analysis is completely **dependent of the data being analyzed**.\n\nIf we get data from the **month of december, probably our data could be biased for Christmas items**, this means turkey could have a higher proportion because of the period.This means **it can be interesting to group data by similar months to consider the seasonality of items, this way we can give the best promotion for our clients.**","7467324c":"Our output is as expected :) !\n\nNow we need to transform this representation in a one-hot encoded format.\nA one Hot encoded is a way to transform categories into numbers, we can do this using the mlxtend module.\nI exemplify a One-Hot Encoded example below :\n\n\n![One-Hot-Encoding](https:\/\/i.imgur.com\/5Q3nKB1.png)","b707662f":"Ok! Everything as expected :).\n\n![](https:\/\/www.criarmeme.com.br\/meme\/meme-5109--ok-!.jpg)","28b120d5":"### Support\n\nLet's start our metric discussion with Support!<br>\nSupport is a metric that measures the percentage of orders that contain the item set.<br> \n\n$$ Support(X) = \\frac{Freq(X)}{N} \\in  [0,1]$$\n\n\n$$ Support(X \\& Y) = \\frac{Freq(X\\&Y)}{N} \\in  [0,1]$$\n\nWhere:\n- $Freq$ measures the frequency of the item \n- $N$ total Baskets\n- $X\\&Y$ means itemX appears with itemY\n\n---\n\nLet's calculate some examples bellow for further understanding of the metric!\n\nLet's calculate the Support of grounded beef:\n\n$$ Support(grounded\\ beef) = \\frac{Freq(grounded\\ beef)}{N} = \\frac{2}{6} = 0.33$$\n\nNow let's calculate the support of grounded beef & beer :\n\n$$ Support(grounded\\ beef\\ \\&\\ beer) = \\frac{Freq(grounded\\ beef\\ \\&\\ beer)}{N} = \\frac{1}{6} = 0.166$$","7d96796a":"### Confidence\n\nConfidence gives the proportion of items Y purchased when item X is already is the basket.<br>\nWe could \"read\" this metric as \"Proportion of Y when X is purchased\".\n\n\n$$ Confidence(X \\rightarrow  Y) = \\frac{Support(X \\&  Y)}{Support(X)} = \\frac{Freq(X \\&  Y)}{Freq(X)} \\in [0,1]$$\n\nIt's important to note that **Confidence is not commutative**, it means:\n\n$$ Confidence(X \\rightarrow  Y) \\neq  Confidence(Y \\rightarrow  X) $$\n\nLet's make an example of beer and coal\n\n$$ Confidence(beer \\rightarrow  coal) = \\frac{Support(beer \\&  coal)}{Support(beer)} = \\frac{2}{3} = 0.66$$\n\n$$ Confidence(coal \\rightarrow  beer)= \\frac{Support(coal \\&  beer)}{Support(coal)} = \\frac{2}{4} = 0.5 $$\n\n\nFrom our data, we can infer the probability of a customer buying coal given he\/she bought beer is 66%\n\nFrom our data, we can infer the probability of a customer buying beer given he\/she bought coal is 50%\n\nSince Confidence is a metric that varies from 0 to 1, where 0 means a \"not occurance\" of product Y when X and 1 is a perfect coincidence(for every product X bought, the basket had the item Y).\n\nIt's important to note that Confidence overestimates values for common items in Y, in our data, every consumer bought 'pork', let's evaluate pork and coke confidence!\n\n$$ Confidence(coke \\rightarrow  pork) = \\frac{Support(coke \\&  pork)}{Support(coke)} = \\frac{1}{1} = 1$$\n\n$$ Confidence(pork \\rightarrow  coke)= \\frac{Support(pork \\&  coke)}{Support(pork)} = \\frac{1}{6} = 0.166 $$","1e46010d":"Leverage and Lift are metrics that try to incorporate the randomness of each item in the data.<br>\nThe term $Support(X) Support(Y)$ gives the probability of the items occuring considering [independent events](https:\/\/en.wikipedia.org\/wiki\/Independence_(probability_theory)) of purchases\n\nThe main difference of Lift and Leverage are the method to incorporate this information, leverage uses the $-$ sign and varies from -1 to 1 while Lift uses $\/$ and varies from 0 to $\\infty $\n\n\n$$ Leverage(X \\&  Y) = Support(X \\&  Y) - Support(X) Support(Y) \\in  [-1,1]$$\n\n---\n\n$$ Lift(X \\& Y) = \\frac{Support(X \\&  Y)}{Support(X) Support(Y)} \\in  [0,\\infty ]$$\n\n","3067666f":"## Metrics\n\nFor the discussion about the metrics, let's use a toy example.<br>\nImagine you're the owner of a butchery and you have a set of baskets.<br>\nLet's calculate some metrics and have a discussion about each commom metric used in Market Basket Analysis<br>\n\n![](https:\/\/i.imgur.com\/QNYPsxp.png)","23c875cd":"Let's define the functions learned above to calculate the metrics from the original data.\n\n\n```python\ndef metric(itemX,itemY,data):\n    value = <formula>\n    return value\n```","5570796d":"## Calculating Metrics"}}