{"cell_type":{"315089a8":"code","0b9fd840":"code","08a1ff02":"code","42af0736":"code","fd4a3553":"code","fa0513cc":"code","a5455ff9":"code","2d1fd89a":"code","5d318787":"code","854c67ff":"code","8bd8cf2f":"code","fb1aeaf9":"code","6f6fe2f5":"code","56167d88":"code","e6647ccd":"code","db7a57c4":"code","04f4b61f":"code","5b3e50d4":"code","aa600e80":"code","df1b7162":"code","55451f6e":"code","9a257c08":"code","7c3f7b31":"markdown","53604a39":"markdown"},"source":{"315089a8":"#data manipulation libraries\nimport numpy as np\nimport pandas as pd\n\n#data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0b9fd840":"# Loading our dataset\ndf = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')","08a1ff02":"df.head()","42af0736":"df.describe()","fd4a3553":"df.info()","fa0513cc":"#As we can clearly see that there are no null values in our dataset, we can begin with our data analysis.","a5455ff9":"sns.pairplot(df, palette=\"viridis\")","2d1fd89a":"#Lets see if there's any correlation in our data\nplt.figure(figsize=(15,15))\nsns.heatmap(df.corr(), cmap='viridis', annot=True)","5d318787":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","854c67ff":"scaler.fit(df.drop('Outcome', axis=1))","8bd8cf2f":"scaler_features = scaler.transform(df.drop('Outcome', axis=1))","fb1aeaf9":"df_feat = pd.DataFrame(scaler_features,columns=df.columns[:-1])\ndf_feat.head()","6f6fe2f5":"from sklearn.model_selection import train_test_split","56167d88":"X_train, X_test, y_train, y_test = train_test_split(scaler_features,df['Outcome'],\n                                                    test_size=0.30)","e6647ccd":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()","db7a57c4":"knn.fit(X_train, y_train)\npred = knn.predict(X_test)","04f4b61f":"#Now let's evaluate our model performance\n#There are two widely used persormance metrics\nfrom sklearn.metrics import classification_report, confusion_matrix","5b3e50d4":"print(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, pred))","aa600e80":"#Lets go ahead and choose an elbow methodto get correct k value\nerror_rate = []\n\n# Will take some time\nfor i in range(1,50):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","df1b7162":"plt.figure(figsize=(10,6))\nplt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","55451f6e":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","9a257c08":"# NOW WITH K=33\nknn = KNeighborsClassifier(n_neighbors=9)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=33')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))\n","7c3f7b31":"**Observations:** \n* We notice that the bloodpressure of a person ranges from 0 to 122, which does not make any sense because the blood pressure cannot be 0. \n* In adittion, the minimum and maximum age of the person is 21 and 81 respectively.\n","53604a39":"**Observations:** We see that there are no null or object values in our entire dataset. This is already a cleaned data that has been made available to us!"}}