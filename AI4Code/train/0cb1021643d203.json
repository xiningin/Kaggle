{"cell_type":{"ce26b0bd":"code","6e9a703f":"code","620a5c2e":"code","b45f4530":"code","865b6cb4":"code","95c5fe33":"code","c5e08c21":"code","78f72452":"code","7dd3aae9":"code","e13ba1e2":"code","c503a6fc":"code","29f5a188":"code","c54ae8d4":"code","ccf7f395":"code","8dc7d134":"code","9fccb248":"code","0804af48":"code","eb3020c7":"code","ace0002d":"code","72ff4d6f":"code","80c144a2":"code","c8566f2b":"code","a1c6babb":"code","c28d065a":"code","fb8e52ef":"code","dcdadbcd":"code","03d1f745":"code","125731ce":"code","dae222cc":"code","a891acb7":"code","7d91aaa9":"code","c19453e9":"code","42a1e8be":"code","6eaa3725":"code","90a926ff":"code","5efefc14":"code","1a93e0cc":"code","257b654f":"code","7b89f1fb":"code","dc6e9e85":"code","086e385b":"code","a116e5d4":"code","431ef377":"code","daadaafc":"code","9e8159f6":"code","2b8a2c77":"code","ee3eeffe":"code","3c45c110":"code","57671967":"code","25b2b2a8":"markdown","b7674f3f":"markdown","3b2f4e4e":"markdown","10019dbc":"markdown","2ad52476":"markdown","e9c14a9e":"markdown","a83a4558":"markdown","7f432b5e":"markdown","9dc08100":"markdown","a75a01de":"markdown","b11822ca":"markdown","2fb42f6f":"markdown","5b8cda95":"markdown","5fbf44f1":"markdown","c2f04fcb":"markdown","a7652a91":"markdown","cd81003a":"markdown","e96c0dcd":"markdown","4a419535":"markdown","5c22d461":"markdown","e438b2f5":"markdown","4cc821ee":"markdown","02f7f206":"markdown","1e568028":"markdown","bac2ba86":"markdown","0030ce5f":"markdown","e5a1575c":"markdown","828491ca":"markdown","90716007":"markdown","87e1e9ed":"markdown","1c2b830d":"markdown","ed2cbe15":"markdown","0b995194":"markdown","1512dd93":"markdown","c30fe3a4":"markdown","ef0bc394":"markdown","ccab4c06":"markdown","6235e94c":"markdown","aee58884":"markdown"},"source":{"ce26b0bd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re \nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\nfrom sklearn.naive_bayes import BernoulliNB,GaussianNB,MultinomialNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.svm import SVC","6e9a703f":"df = pd.read_csv(\"..\/input\/reviews\/Restaurant_Reviews.tsv\",delimiter=\"\\t\")","620a5c2e":"df.head()","b45f4530":"df.info()","865b6cb4":"sns.countplot(x='Liked', data=df);","95c5fe33":"# Selected first row.\ndf[\"Review\"][0]","c5e08c21":"review = re.sub(\"[^a-zA-Z]\",\" \",df[\"Review\"][0])\nreview","78f72452":"print(f'Unclean review: {df[\"Review\"][0]} \\nClean review: {review}')","7dd3aae9":"# remember review\nreview","e13ba1e2":"# let's check review's data-type\ntype(review)","c503a6fc":"# if review is a string-type, we can use string methods\nreview = review.lower()","29f5a188":"# let's check\nreview","c54ae8d4":"# We can download stopwords;\n\nnltk.download(\"stopwords\")","ccf7f395":"# We are preparing our data for the process we will do \n# by converting the string review variable into a list.\nreview = review.split()\nreview","8dc7d134":"ps = PorterStemmer()\nreview = [ps.stem(word) for word in review if not word in set(stopwords.words(\"english\"))]","9fccb248":"review","0804af48":"print(f\"\"\"\nunprocessed data: {df[\"Review\"][0]}\npreprocessed data: {\" \".join(review)}\n\"\"\")","eb3020c7":"reviews = []\nfor i in range(len(df)):\n    review = re.sub(\"[^a-zA-Z]\",\" \",df[\"Review\"][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in str(stopwords.words(\"english\"))]\n    reviews.append(\" \".join(review))","ace0002d":"# Take a look \n\nreviews[:4]","72ff4d6f":"cv = CountVectorizer(max_features = 1500)","80c144a2":"# Select undependent variables and converting to array\nX = cv.fit_transform(reviews).toarray()","c8566f2b":"# Sparse Matrix\nX","a1c6babb":"# Shape | x: data, y: max_features (that we have defined)\nX.shape ","c28d065a":"# Select dependent variables\ny = df[\"Liked\"].values","fb8e52ef":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)","dcdadbcd":"# to store accuracy scores\nalgorithms = {} ","03d1f745":"nb_algorithms = [BernoulliNB,GaussianNB,MultinomialNB]\nfor algorithm in nb_algorithms:\n    model = algorithm().fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test,y_pred)\n\n    \n    print(f'=> Algorithm: {algorithm.__name__}\\nConfusion Matrix:\\n\\n {cm} \\n\\nAccuracy Score: {accuracy_score(y_test,y_pred)}\\n Classification Report:\\n\\n{classification_report(y_test,y_pred)}\\n{\"-\"*25}')\n    algorithms[algorithm.__name__] = accuracy_score(y_test,y_pred)","125731ce":"mlpc_model = MLPClassifier(activation=\"logistic\",max_iter=10000).fit(X_train,y_train)\ny_pred = mlpc_model.predict(X_test)","dae222cc":"algorithms[\"MLPClassifier\"] = accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", accuracy_score(y_test,y_pred))","a891acb7":"print(classification_report(y_test,y_pred))","7d91aaa9":"xgb = XGBClassifier().fit(X_train,y_train)\n\ny_pred = xgb.predict(X_test)","c19453e9":"algorithms[\"XGBoost\"] = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy Score:\", accuracy_score(y_test,y_pred))","42a1e8be":"print(classification_report(y_test,y_pred))","6eaa3725":"catb = CatBoostClassifier().fit(X_train,y_train)\ny_pred = catb.predict(X_test)\nalgorithms[\"CatBoost\"] = accuracy_score(y_test,y_pred)","90a926ff":"print(\"Accuracy Score:\", accuracy_score(y_test,y_pred))","5efefc14":"catb = CatBoostClassifier()\n\ncatb_params = {\"learning_rate\":[0.01,0.03,0.1],\n              \"iterations\":[100,200,500],\n              \"depth\":[4,5,8]}\n\ncatb_cv_model = GridSearchCV(catb, catb_params, cv=2, n_jobs=-1,verbose=2).fit(X_train,y_train,verbose=False)","1a93e0cc":"catb_cv_model.best_params_","257b654f":"catb_cv_model.best_score_","7b89f1fb":"catb_tuned = CatBoostClassifier(learning_rate=catb_cv_model.best_params_[\"learning_rate\"],\n                           iterations=catb_cv_model.best_params_[\"iterations\"],\n                           depth=catb_cv_model.best_params_[\"depth\"]).fit(X_train,y_train,verbose=False)\n\ny_pred = catb_tuned.predict(X_test)","dc6e9e85":"algorithms[\"CatBoost_Tuned\"] = accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", accuracy_score(y_test,y_pred))","086e385b":"print(classification_report(y_test,y_pred))","a116e5d4":"svm_model = SVC(kernel = \"rbf\").fit(X_train,y_train)\ny_pred = svm_model.predict(X_test)\nprint(\"Accuracy Score:\", accuracy_score(y_test,y_pred))\nalgorithms[\"SVC\"] = accuracy_score(y_test,y_pred)","431ef377":"svm = SVC()\nsvm_params = {\"C\":np.arange(1,3),\n             \"kernel\":[\"linear\",\"rbf\",\"sigmoid\"]}\nsvm_cv_model = GridSearchCV(svm,svm_params,cv=3,verbose=2,n_jobs=-1).fit(X_train,y_train)\n","daadaafc":"svm_cv_model.best_params_","9e8159f6":"svm_cv_model.best_score_","2b8a2c77":"svm_tuned = SVC(C=svm_cv_model.best_params_[\"C\"],\n               kernel=svm_cv_model.best_params_[\"kernel\"]).fit(X_train,y_train)\n\ny_pred = svm_tuned.predict(X_test)","ee3eeffe":"algorithms[\"SVC_Tuned\"] = accuracy_score(y_test,y_pred)\nprint(\"Accuracy Score:\", accuracy_score(y_test,y_pred))","3c45c110":"print(classification_report(y_test,y_pred))","57671967":"algorithms","25b2b2a8":"<h3 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:175%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Data Preprocessing<\/h3><a id=\"2\"><\/a>","b7674f3f":"<h2 style=\"background-color:#166088;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 10px 10px;color:#dbe9ee\">Thank you for reading<\/h2>\n\n<center>\n<link rel=\"stylesheet\" href=\"https:\/\/maxcdn.bootstrapcdn.com\/font-awesome\/4.4.0\/css\/font-awesome.min.css\">\n<a href=\"https:\/\/www.linkedin.com\/in\/ardasamet\/\" class=\"social-icon si-rounded si-small si-linkedin\">\n  <i class=\"fa fa-linkedin\">  LinkedIn<\/i>\n<\/a>\n<\/center>","3b2f4e4e":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">SVC<\/h3><a id=\"15\"><\/a>","10019dbc":"Another important issue for clean data is to find the root of the word.\n\nIf we take the root of the word \"liked\", which is the verb of the sentence \"I liked this product\", it becomes \"like\" and it makes the data clean even if it doesn't change anything semantically\n\n","2ad52476":"<h3 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:175%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Bag Of Words<\/h3><a id=\"7\"><\/a>","e9c14a9e":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Capitalization<\/h3><a id=\"4\"><\/a>","a83a4558":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Count Vectorizer \/ Sparse Matrix<\/h3><a id=\"8\"><\/a>","7f432b5e":"* The distribution of the dependent variable is important for the models to be built. Otherwise, there may be bias. The distribution is fine in this dataset.","9dc08100":"With \"Count Vectorizer\" we will create Sparse Matrix of reviews","a75a01de":"<h2 style=\"background-color:#166088;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 10px 10px;color:#dbe9ee\">Welcome<\/h2>\n\n<h4><center>This notebook is a simple sentiment analysis exercise. The aim is to have an introductory knowledge of NLP's \"Data Preprocessing\", \"Bag Of Words\" and \"Machine Learning\" steps<\/center><\/h4>","b11822ca":"Capitalization isn't always a problem, and can sometimes contain important information for the feature.\n\nFor Example;\n\n* i hate this product\n* i HATE this product\n\nWe can think that these two sentences that are the same have different effects due to the use of capital letters.\n\nBut for our case, we will make all the words lowercase to learn how to use","2fb42f6f":"<h3 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:175%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Machine Learning: Classification<\/h3><a id=\"10\"><\/a>","5b8cda95":"<h5>Firstly, let's select a row to understand how it works<\/h5>","5fbf44f1":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">First Look<\/h3><a id=\"16\"><\/a>\n\n","c2f04fcb":"Before we move on to the algorithms, we have to split our dataset into train\/test","a7652a91":"* **It means:** It creates a new list called review and there is no stop word in it. It also takes root words.","cd81003a":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Dictation<\/h3><a id=\"3\"><\/a>\n\n","e96c0dcd":"* Although as you can see there is no semantic difference, the review looks cleaner now","4a419535":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Neural Networks<\/h3><a id=\"12\"><\/a>","5c22d461":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Stop Words \/ Corpus \/ Stemmer<\/h3><a id=\"5\"><\/a>","e438b2f5":"* Dtypes looks good and it's nice that there is no missing value.","4cc821ee":"Up to the present;\n\n* We cleaned reviews from unnecessary characters\n* We have rooted the sentences\n\nBut; This does not mean that all our data is clean. Although it depends on the dataset, maybe dozens of more cleaning operations could be done even in this dataset. This notebook will not also mention all the details","02f7f206":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Naive Bayes<\/h3><a id=\"11\"><\/a>","1e568028":"<br> <br>\n\n#### SVC: Model Tuning ","bac2ba86":"* There 2 columns,\n    * \"Review\" column shows reviews,<br>\n    * \"Liked\" column gives information about their positive or negative reviews","0030ce5f":"<h2 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:200%;text-align:left;border-radius: 7px 7px;color:#dbe9ee\">Table Of Contents<\/h2>\n\n* [Imports](#1)<br>\n\n\n* [Data Preprocessing](#2)\n    * [First Look](#16)\n    * [Dictation](#3)\n    * [Capitalization](#4)\n    * [Stop Words \/ Corpus \/ Stemmer](#5)\n    * [Implementation of all data](#6)<br>\n    \n\n    \n* [Bag Of Words](#7)\n    * [Count Vectorizer \/ Sparse Matrix](#8)\n    \n\n    \n* [Machine Learning: Classification](#10)\n    * [Naive Bayes](#11)\n    * [Neural Networks](#12)\n    * [XGBoost](#13)\n    * [CatBoost](#14)\n    * [SVC](#15)\n    \n\n    \n* [Conclusion](#17)\n","e5a1575c":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">CatBoost<\/h3><a id=\"14\"><\/a>","828491ca":"<br> <br> <br>\n\n<h3 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:175%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Conclusion<\/h3><a id=\"17\"><\/a>","90716007":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">XGBoost<\/h3><a id=\"13\"><\/a>","87e1e9ed":"#### Accuracy Scores of Algorithms;","1c2b830d":"> re.sub(\"[^a-zA-Z]\",\" \",df[\"Review\"][0])\n\n* **It Means:** Replace all non-[a-zA-Z] values in df[\"Review\"][0] with \" \"\n    * Here, we use the expression \"^\" to mean \"non-[a-zA-Z]\" ie: [^a-zA-Z]. This is used to say the opposite in python","ed2cbe15":"Removing stop words is important to create clean data. The reason for this is to better understand the value implied by the comment.\n\nFor Example;\n\n* \"i like this product\"\n\nWhen you remove the stop words from the sentence, it becomes \"like product\". and although these two sentences have the same meaning, the sentence without a stopword is a cleaner data","0b995194":"Now that we have explained what we want to do through a single review, we can now preprocess the entire dataset.","1512dd93":"<br> <br>\n\n#### CatBoost: Model Tuning ","c30fe3a4":"* An accurate and successful data pre-processing is important for us to develop successful ML models. Therefore, we need to clean up the characters we do not want in the reviews (things that will reduce the success of the model) and create clean data.\n\n* Let's clear everything but words in our data (like punctuation)","ef0bc394":"Although the **\"BernoulliNB\"** algorithm has the highest **\"Accuracy Score\"**, this does not make it the best algorithm or the most successful model.\n\n**Before starting an NLP or ML project**, goals are determined, actions are taken in line with these goals, and metrics are selected. I mean, the metrics to look at are project dependent.\n\n**Data Preprocessing and Bag Of Words Stages** are very important in an NLP project. As this is a simple introductory notebook, these steps are not in-depth.\n\n**More successful and accurate models can be developed** with much deeper and thoughtful Data Preprocessing, Bag Of Words And Machine Learning (Especially with Optimizations) Stages.","ccab4c06":"We have finished the data preprocessing phase. The current stage is: \"Bag Of Words\"","6235e94c":"<h3 style=\"background-color:#4F6D7A;font-family:newtimeroman;font-size:175%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Imports<\/h3><a id=\"1\"><\/a>","aee58884":"<h3 style=\"background-color:#4A6FA5;font-family:newtimeroman;font-size:150%;text-align:left;border-radius: 5px 5px;color:#dbe9ee\">Implementation of all data<\/h3><a id=\"6\"><\/a>"}}