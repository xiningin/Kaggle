{"cell_type":{"5a972a85":"code","8f7d3fdf":"code","7f870794":"code","6307448a":"code","b857046b":"code","4b437747":"code","53f2dbf7":"code","7166d41e":"code","2f3869c2":"code","4e6454b4":"code","63690bb4":"code","8d57a702":"code","654a799b":"code","5a9301db":"code","40198455":"code","83f2475f":"code","92f073ee":"code","51f85868":"code","87981c29":"code","a9fec817":"code","39294a19":"code","ab1234dc":"code","d318a991":"markdown","59189260":"markdown"},"source":{"5a972a85":"import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torchvision import transforms\nfrom torchvision import models\nfrom torchvision.io import read_image\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport os","8f7d3fdf":"# get image path\ntrain_path = '..\/input\/dogs-vs-cats\/train\/train\/'\n\nimage_file_path = np.array([train_path + i for i in os.listdir(train_path)])\n\nlabels = np.array([\n    0 if name.split('\/')[-1].startswith('cat') else 1\n    for name in image_file_path\n])\n\nprint(len(image_file_path),len(labels))","7f870794":"# show result\nimage_file_path[:10], labels[:10]","6307448a":"# The data set is divided into train_set and other_set according to 8:2\ntrain_val_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2021)\n\nfor train_index, val_index in train_val_sss.split(image_file_path, labels):\n    train_path, val_path = image_file_path[train_index],image_file_path[val_index]\n    train_labels, val_labels = labels[train_index],labels[val_index]\n    \n\n# The data set is divided into val_set and test_set according to 1:1\nval_test_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=2021)\n\nfor val_index, test_index in val_test_sss.split(val_path, val_labels):\n    val_path, test_path = val_path[val_index],val_path[test_index]\n    val_labels, test_labels = val_labels[val_index],val_labels[test_index]\n    \n# You will end up with 8: 1: 1 training sets, validation sets, and test sets,\n# each of which has the same ratio of cats and dogs","b857046b":"print(len(train_path),len(train_labels),train_labels.sum())\nprint(len(val_path),len(val_labels),val_labels.sum())\nprint(len(test_path),len(test_labels),test_labels.sum())","4b437747":"# Define how to load a dataset\nclass MyData(Dataset):\n    def __init__(self, filepath, labels=None, transform=None):\n        self.filepath = filepath\n        self.labels = labels\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image = read_image(self.filepath[index]) # The image dimension after reading is [channl, height, width]\n        image = image.to(torch.float32) \/ 255. # Convert to float32 type, divide by 255 to normalize\n        if self.transform is not None:\n            image = self.transform(image)\n        if self.labels is not None:\n            return image, self.labels[index]\n        return image\n\n    def __len__(self):\n        return self.filepath.shape[0]","53f2dbf7":"image_size = [224, 224]\nbatch_size = 64","7166d41e":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.Resize([256, 256]),\n    transforms.RandomCrop(image_size),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","2f3869c2":"ds1 = MyData(train_path, train_labels, transform)\nds2 = MyData(val_path, val_labels, transform)\nds3 = MyData(test_path, test_labels, transform)\n\ntrain_ds = DataLoader(ds1, batch_size=batch_size, shuffle=True)\nval_ds = DataLoader(ds2, batch_size=batch_size, shuffle=True)\ntest_ds = DataLoader(ds3, batch_size=batch_size, shuffle=True)","4e6454b4":"# View enhancement effects on a picture\n\nimage = read_image(train_path[0])\nimage = image.to(torch.float32) \/ 255.\nimage = image.unsqueeze(0)\n\nplt.figure(figsize=(12,12))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    img = transform(image)\n    img = img[0,:,:,:].data.numpy().transpose([1,2,0])\n    img = std * img + mean   # Anti Normalize\n    img = np.clip(img, 0, 1)\n    plt.imshow(img)\n    plt.axis('off')\nplt.show()","63690bb4":"# View the picture of a batch in the training set\nfor step, (bx, by) in enumerate(train_ds):\n    if step > 0:\n        break\n    plt.figure(figsize=(16,16))\n    for i in range(len(by)):\n        plt.subplot(8,8,i+1)\n        image = bx[i,:,:,:].data.numpy().transpose([1,2,0])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n        plt.imshow(image)\n        plt.axis('off')\n        plt.title('cat' if by[i].data.numpy()==0 else 'dog')\n    plt.show()","8d57a702":"model = models.resnet50(pretrained=True)\nin_features = model.fc.in_features  # Gets the input dimension of the top output layer\nmodel.fc = nn.Linear(in_features, 2)  # Replace the output layer with the one you need, and the output dimension is 2\nmodel.add_module('softmax', nn.Softmax(dim=-1)) # add a softmax layer\n\n# Freeze the parameters of other layers except the top layer\nfor name, m in model.named_parameters():\n    if name.split('.')[0] != 'fc':\n        m.requires_grad_(False)","654a799b":"print(model)","5a9301db":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)","40198455":"optimizer = Adam(model.parameters(), lr=0.0001)\nloss_fun = F.cross_entropy","83f2475f":"def train(model, epoch, train_ds):\n    model.train()\n    total_num = len(train_ds.dataset)\n    train_loss = 0\n    correct_num = 0\n\n    for image, label in train_ds:\n        image = image.to(device)\n        label = label.to(device)\n        # Convert the tag from int32 type to long type, otherwise the calculation loss will report an error\n        label = label.to(torch.long)\n\n        output = model(image)\n        loss = loss_fun(output, label)\n        train_loss += loss.item() * label.size(0)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        predict = torch.argmax(output, dim=-1)\n        correct_num += label.eq(predict).sum()\n\n    train_loss = train_loss \/ total_num\n    train_acc = correct_num \/ total_num\n    print('epoch: {} --> train_loss: {:.6f} - train_acc: {:.6f} - '.format(\n        epoch, train_loss, train_acc), end='')\n    \n\ndef evaluate(model, eval_ds, mode='val'):\n    model.eval()\n\n    total_num = len(eval_ds.dataset)\n    eval_loss = 0\n    correct_num = 0\n\n    for image, label in eval_ds:\n        image = image.to(device)\n        label = label.to(device)\n        label = label.to(torch.long)\n        \n        output = model(image)\n        loss = loss_fun(output, label)\n        eval_loss += loss.item() * label.size(0)\n\n        predict = torch.argmax(output, dim=-1)\n        correct_num += label.eq(predict).sum()\n    \n    eval_loss = eval_loss \/ total_num\n    eval_acc = correct_num \/ total_num\n    \n    print('{}_loss: {:.6f} - {}_acc: {:.6f}'.format(\n        mode, eval_loss, mode, eval_acc))","92f073ee":"for epoch in range(20):\n    train(model, epoch, train_ds)\n    evaluate(model, val_ds)","51f85868":"# test model\nevaluate(model, test_ds, mode='test')","87981c29":"# Freeze the parameters of layers to fine-tune model\nfor name, m in model.named_parameters():\n    if name.split('.')[0] != 'fc':\n        m.requires_grad_(True)","a9fec817":"# Use an optimizer with a smaller learning rate\noptimizer = Adam(model.parameters(), lr=0.00001)","39294a19":"for epoch in range(3):\n    train(model, epoch, train_ds)\n    evaluate(model, val_ds)","ab1234dc":"torch.save(model,'model.pkl')","d318a991":"# \u52a0\u8f7d\u6570\u636e","59189260":"# \u6784\u5efa\u6a21\u578b"}}