{"cell_type":{"751a18e6":"code","8c9d5c33":"code","a5eea77e":"code","02f448bf":"code","5a0f3260":"code","06a4aecf":"code","776661f6":"code","915a0f93":"markdown","b7fc4fea":"markdown","b3f24129":"markdown","825e27b3":"markdown"},"source":{"751a18e6":"!pip install reverse_geocoder\nimport reverse_geocoder as revgc\nrevgc.search((47.4943, -122.24092))","8c9d5c33":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder","a5eea77e":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test  = pd.read_csv('..\/input\/test.csv')","02f448bf":"df_train['price'] = np.log1p(df_train['price'])\n\ndf_train = df_train.loc[df_train['id']!=8990]\ndf_train = df_train.loc[df_train['id']!=456]\ndf_train = df_train.loc[df_train['id']!=7259]\ndf_train = df_train.loc[df_train['id']!=2777]\ndf_train = df_train.loc[df_train['bedrooms']<9]\n\nskew_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n\nfor c in skew_columns:\n    df_train[c] = np.log1p(df_train[c].values)\n    df_test[c] = np.log1p(df_test[c].values)\n    \nfor df in [df_train,df_test]:\n    df['date'] = df['date'].apply(lambda x: x[0:8])\n    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n    df['yr_renovated'] = df['yr_renovated'].fillna(df['yr_built'])\n\nfor df in [df_train,df_test]:\n    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n    #df['grade_condition'] = df['grade'] * df['condition']\n    df['sqft_ratio'] = df['sqft_living'] \/ df['sqft_lot']\n    df['sqft_total_size'] = df['sqft_living'] + df['sqft_lot'] + df['sqft_above'] + df['sqft_basement']\n    df['sqft_total15'] = df['sqft_living15'] + df['sqft_lot15'] \n    df['is_renovated'] = df['yr_renovated'] - df['yr_built']\n    df['is_renovated'] = df['is_renovated'].apply(lambda x: 0 if x == 0 else 1)\n    df['date'] = df['date'].astype('int')\n    \ndf_train['per_price'] = df_train['price']\/df_train['sqft_total_size']\nzipcode_price = df_train.groupby(['zipcode'])['per_price'].agg({'mean','var'}).reset_index()\ndf_train = pd.merge(df_train,zipcode_price,how='left',on='zipcode')\ndf_test = pd.merge(df_test,zipcode_price,how='left',on='zipcode')\ndel df_train['per_price']\n\ny_reg = df_train['price']\ndel df_train['price']\ndel df_train['id']\ntest_id = df_test['id']\ndel df_test['id']\n\ntrain_columns = [c for c in df_train.columns if c not in ['id']]\n\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\nparam = {'num_leaves': 32,\n         'min_data_in_leaf': 30, \n         'objective':'regression',\n         'max_depth': -1,\n         'learning_rate': 0.015,\n         \"min_child_samples\": 15,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.7,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": 1,\n         \"nthread\": 8,\n         \"random_state\": 1}\n         \n#prepare fit model with cross-validation\nfolds = KFold(n_splits=5, shuffle=True, random_state=777)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\nfeature_importance_df = pd.DataFrame()\n\n#run model\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train)):\n    print(str(fold_)+'-th fold')\n    trn_data = lgb.Dataset(df_train.iloc[trn_idx][train_columns], label=y_reg.iloc[trn_idx])#, categorical_feature=categorical_feats)\n    val_data = lgb.Dataset(df_train.iloc[val_idx][train_columns], label=y_reg.iloc[val_idx])#, categorical_feature=categorical_feats)\n\n    num_round = 100000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1500)\n    oof[val_idx] = clf.predict(df_train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n    #feature importance\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = train_columns\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    #predictions\n    predictions += clf.predict(df_test[train_columns], num_iteration=clf.best_iteration) \/ folds.n_splits\n    print()\ncv = np.sqrt(mean_squared_error(oof, y_reg))\nprint(cv)","5a0f3260":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test  = pd.read_csv('..\/input\/test.csv')","06a4aecf":"df_train['price'] = np.log1p(df_train['price'])\n\ndf_train = df_train.loc[df_train['id']!=8990]\ndf_train = df_train.loc[df_train['id']!=456]\ndf_train = df_train.loc[df_train['id']!=7259]\ndf_train = df_train.loc[df_train['id']!=2777]\ndf_train = df_train.loc[df_train['bedrooms']<9]\n\nskew_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n\nfor c in skew_columns:\n    df_train[c] = np.log1p(df_train[c].values)\n    df_test[c] = np.log1p(df_test[c].values)\n    \nfor df in [df_train,df_test]:\n    df['date'] = df['date'].apply(lambda x: x[0:8])\n    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n    df['yr_renovated'] = df['yr_renovated'].fillna(df['yr_built'])\n    \nfor df in [df_train,df_test]:\n    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n    #df['grade_condition'] = df['grade'] * df['condition']\n    df['sqft_ratio'] = df['sqft_living'] \/ df['sqft_lot']\n    df['sqft_total_size'] = df['sqft_living'] + df['sqft_lot'] + df['sqft_above'] + df['sqft_basement']\n    df['sqft_total15'] = df['sqft_living15'] + df['sqft_lot15'] \n    df['is_renovated'] = df['yr_renovated'] - df['yr_built']\n    df['is_renovated'] = df['is_renovated'].apply(lambda x: 0 if x == 0 else 1)\n    df['date'] = df['date'].astype('int')\n    \ndf_train['per_price'] = df_train['price']\/df_train['sqft_total_size']\nzipcode_price = df_train.groupby(['zipcode'])['per_price'].agg({'mean','var'}).reset_index()\ndf_train = pd.merge(df_train,zipcode_price,how='left',on='zipcode')\ndf_test = pd.merge(df_test,zipcode_price,how='left',on='zipcode')\ndel df_train['per_price']\n\n\n# ----------------------------------  added  -------------------------------\n\n\n#df_train['country'] = df_train.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['cc'],axis=1)\ndf_train['admin1'] = df_train.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['admin1'],axis=1)\ndf_train['admin2'] = df_train.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['admin2'],axis=1)\ndf_train['st_name'] = df_train.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['name'],axis=1)\n\nle_admin1 = LabelEncoder()\nle_admin2 = LabelEncoder()\nle_st = LabelEncoder()\n#le.fit(df_train['country'].unique())\n#df_train['country'] = le.transform(le.fit(df_train['country']))\nle_admin1.fit(df_train['admin1'].unique())\ndf_train['admin1'] = le_admin1.transform(df_train['admin1'])\nle_admin2.fit(df_train['admin2'].unique())\ndf_train['admin2'] = le_admin2.transform(df_train['admin2'])\nle_st.fit(df_train['st_name'].unique())\ndf_train['st_name'] = le_st.transform(df_train['st_name'])\n\n\n#df_test['country'] = df_test.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['cc'],axis=1)\ndf_test['admin1'] = df_test.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['admin1'],axis=1)\ndf_test['admin2'] = df_test.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['admin2'],axis=1)\ndf_test['st_name'] = df_test.apply(lambda row: revgc.search((row['lat'],row['long']))[0]['name'],axis=1)\n\nle_admin1 = LabelEncoder()\nle_admin2 = LabelEncoder()\nle_st = LabelEncoder()\n#le.fit(df_test['country'].unique())\n#df_test['country'] = le.transform(le.fit(df_test['country']))\nle_admin1.fit(df_test['admin1'].unique())\ndf_test['admin1'] = le_admin1.transform(df_test['admin1'])\nle_admin2.fit(df_test['admin2'].unique())\ndf_test['admin2'] = le_admin2.transform(df_test['admin2'])\nle_st.fit(df_test['st_name'].unique())\ndf_test['st_name'] = le_st.transform(df_test['st_name'])\n\n\n# ----------------------------------  added  -------------------------------\n\n\ny_reg = df_train['price']\ndel df_train['price']\ndel df_train['id']\ntest_id = df_test['id']\ndel df_test['id']\n\ntrain_columns = [c for c in df_train.columns if c not in ['id']]\n\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\nparam = {'num_leaves': 32,\n         'min_data_in_leaf': 30, \n         'objective':'regression',\n         'max_depth': -1,\n         'learning_rate': 0.015,\n         \"min_child_samples\": 15,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.7,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": 1,\n         \"nthread\": 8,\n         \"random_state\": 1}\n         \n#prepare fit model with cross-validation\nfolds = KFold(n_splits=5, shuffle=True, random_state=777)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\nfeature_importance_df = pd.DataFrame()\n\n#run model\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train)):\n    print(str(fold_)+'-th fold')\n    trn_data = lgb.Dataset(df_train.iloc[trn_idx][train_columns], label=y_reg.iloc[trn_idx])#, categorical_feature=categorical_feats)\n    val_data = lgb.Dataset(df_train.iloc[val_idx][train_columns], label=y_reg.iloc[val_idx])#, categorical_feature=categorical_feats)\n\n    num_round = 100000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1500)\n    oof[val_idx] = clf.predict(df_train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n    #feature importance\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = train_columns\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    #predictions\n    predictions += clf.predict(df_test[train_columns], num_iteration=clf.best_iteration) \/ folds.n_splits\n    print()\ncv = np.sqrt(mean_squared_error(oof, y_reg))\nprint(cv)","776661f6":"submmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmmission['price'] = np.expm1(predictions)\nsubmmission.to_csv('.\/submission.csv', index=False)","915a0f93":"# Google's Reverse Geocoder\ub97c \uc774\uc6a9\ud55c \uc704\ub3c4(lat)\uc640 \uacbd\ub3c4(long) \ubd84\uc11d\n\n[Hyun woo kim](https:\/\/www.kaggle.com\/chocozzz)\ub2d8\uc758 \ucee4\ub110 [House Price Prediction EDA (updated 2019.03.12)](https:\/\/www.kaggle.com\/chocozzz\/house-price-prediction-eda-updated-2019-03-12)\uc744 \uae30\ubc18\uc73c\ub85c \"Reverse Geocoder\"\ub97c \uc801\uc6a9\ud558\uc5ec \uc5bb\uc740 feature\ub97c \uc0ac\uc6a9\ud55c \uac83\uacfc \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740\uac83\uc744 \ube44\uad50\ud558\uc600\uc2b5\ub2c8\ub2e4. \uc704\uce58 \uc815\ubcf4\uc5d0 \ub300\ud55c \ud65c\uc6a9\uc774 \ub354 \ud65c\ubc1c\ud574\uc9c0\uae30\ub97c \uae30\ub300\ud558\uba70 \uacf5\uc720\ud569\ub2c8\ub2e4. <br\/>\n\n\uac80\uc0c9\uc744 \uc81c\ub300\ub85c \ud558\uace0 kernel\uc744 commit \ud588\uc5b4\uc57c \ud588\ub294\ub370, [eun yong](https:\/\/www.kaggle.com\/namepen)\ub2d8\uaed8\uc11c \uc774\ubbf8 \uacf5\uc720\ud558\uc2e0 \ucee4\ub110\uc774 \uc788\uc2b5\ub2c8\ub2e4. <br\/>\n[\uc704\ub3c4\uc640 \uacbd\ub3c4\ub97c \uc8fc\uc18c \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud558\uae30](https:\/\/www.kaggle.com\/namepen\/lat-long)\uc744 \uaf2d \ucc38\uace0\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.<br\/>\n~~\ub2e4\ud589\ud788\ub3c4 \uc874\uc7ac\ud558\ub294~~ \ucc28\uc774\uc810\uc740, label encoding\uc744 \uc801\uc6a9\ud55c \uac83\uacfc cv \uc131\ub2a5 \ubcc0\ud654\ub97c \uccb4\ud06c\ud574\ubcf8 \uac83\uc73c\ub85c \ubcfc \uc218 \uc788\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\n[Sangeun Kim](https:\/\/www.kaggle.com\/tichangel)\ub2d8\uc758 \ub514\uc2a4\ucee4\uc158 [\uc9d1\uac12\uacfc \uc9c0\uc5ed\uc131](https:\/\/www.kaggle.com\/c\/2019-2nd-ml-month-with-kakr\/discussion\/85282)\uc5d0 \uc870\uae08\uc774\ub098\ub9c8 \ub3c4\uc6c0\uc774 \ub418\uae38 \uae30\ub300\ud569\ub2c8\ub2e4.\n\n\uc774 \ucee4\ub110\uc758 \ud575\uc2ec\uc740 Google\uc758 __reverse geocoder__\ub97c \uc774\uc6a9\ud574 \uc704\ub3c4\uc640 \uacbd\ub3c4\ub97c \uc9c0\uc5ed \uc815\ubcf4\ub85c \ubc14\uafb8\uace0, <br\/>\n\uc9c0\uc5ed \uc815\ubcf4\ub97c __label encoding__\ud558\uc5ec __additional feature__\ub97c \ub9cc\ub4e4\uc5b4\ub0b8 \uac83\uc785\ub2c8\ub2e4. <br\/>\nnew method \ud30c\ud2b8\uc758 \ucf54\ub4dc\uc5d0\uc11c, added \ubd80\ubd84\ub9cc \ucd94\uac00 \ub41c \uac83\uc785\ub2c8\ub2e4. <br\/>\n\n\ubcc0\ud658\uc804 cv: 0.1575515789473009\n\ubcc0\ud658\ud6c4 cv: 0.15739441545488744\n\n\ub85c, \uc870\uae08 \ubcc0\ud654\uac00 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.\n\n__\uc81c kernel\uc5d0 vote \ud574\uc8fc\uc2dc\uba74 \uacf5\uc720\uc5d0 \ud06c\ub098\ud070 \ud798\uc774 \ub429\ub2c8\ub2e4.__<br\/>\n\n1. [basic](#basic)\n2. [new-method](#new-method)","b7fc4fea":"# new method","b3f24129":"# basic","825e27b3":"reverse geocoder\uc758 \uc608)"}}