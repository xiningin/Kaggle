{"cell_type":{"93c4d1e1":"code","73704991":"code","8993c4c9":"code","199d8cce":"code","fd2e1199":"code","40dd4ba5":"code","9f7a1b0a":"code","0652b9b3":"code","7b09393b":"code","d465baff":"code","b82ec1fb":"code","8fcec6ef":"code","3cd10047":"code","72332a07":"code","2c6286ec":"code","7f0cf865":"code","5caaaa9d":"code","caf37d8f":"code","6c47aac1":"code","8a2e4478":"code","cf69d0e2":"code","c916190f":"code","41a9c276":"markdown","b3a15137":"markdown","08c9af49":"markdown","f91d7c00":"markdown","ece079fa":"markdown","f0597f1c":"markdown","a02445ca":"markdown"},"source":{"93c4d1e1":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport itertools\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123","73704991":"TRAIN_DIR = ('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/')\nTEST_DIR = ('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/')\nVAL_DIR = ('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/')","8993c4c9":"def load_data(dir_path, IMG_SIZE):\n   \n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '\/' + file)\n                    img = img.astype('float32') \/ 255\n                    resized = cv2.resize(img, IMG_SIZE, interpolation = cv2.INTER_AREA)\n                    X.append(resized)\n                    y.append(i)\n            i += 1\n    X = np.array(X)\n    y = np.array(y)\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels","199d8cce":"IMG_SIZE= (150, 150)","fd2e1199":"X_train, y_train, train_labels = load_data(TRAIN_DIR, IMG_SIZE)","40dd4ba5":"X_test, y_test, test_labels = load_data(TEST_DIR,IMG_SIZE)","9f7a1b0a":"X_val, y_val, val_labels = load_data(VAL_DIR,IMG_SIZE)","0652b9b3":"def plot_samples(X, y, labels_dict, n=50):\n   \n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n\/j)\n\n        plt.figure(figsize=(15,6))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle(labels_dict[index])\n        plt.show()","7b09393b":"plot_samples(X_train, y_train, train_labels, 30)","d465baff":"RATIO_LIST = []\nfor set in (X_train, X_test, X_val):\n    for img in set:\n        RATIO_LIST.append(img.shape[1]\/img.shape[0])\n        \nplt.hist(RATIO_LIST)\nplt.title('Distribution of Image Ratios')\nplt.xlabel('Ratio Value')\nplt.ylabel('Count')\nplt.show()","b82ec1fb":"def process_data(img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n      directory=TRAIN_DIR, \n      target_size=(IMG_SIZE), \n      batch_size=batch_size, \n      class_mode='binary', \n      shuffle=True)\n\n    val_gen = test_val_datagen.flow_from_directory(\n      directory=VAL_DIR, \n      target_size=(IMG_SIZE), \n      batch_size=batch_size, \n      class_mode='binary', \n      shuffle=True)\n    \n    return train_gen, val_gen","8fcec6ef":"train_gen, val_gen = process_data(IMG_SIZE, 32)","3cd10047":"from tensorflow.keras.applications.vgg16 import VGG16\n\nbase_model = VGG16(\n        weights=None,\n        include_top=False, \n        input_shape=IMG_SIZE + (3,)\n    )\n\n# base_model.summary()","72332a07":"NUM_CLASSES = 1\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(4096, activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(NUM_CLASSES,activation=\"sigmoid\"))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\nmodel.summary()","2c6286ec":"epochs = 20\nbatch_size = 30","7f0cf865":"history = model.fit_generator(\n    generator = train_gen,\n    steps_per_epoch=50,\n    epochs=epochs,\n    validation_data = val_gen,\n    validation_steps=25,\n    \n)","5caaaa9d":"# def deep_model(model, X_train, y_train, X_val, y_val, epochs, batch_size):\n   \n#     model.compile(optimizer=RMSprop(lr=1e-4)\n#                   , loss='categorical_crossentropy'\n#                   , metrics=['accuracy'])\n    \n#     history = model.fit(X_train\n#                        , y_train\n#                        , epochs=epochs\n#                        , batch_size=batch_size\n#                        , validation_data=(X_val, y_val)\n#                        , verbose=1)\n#     return history","caf37d8f":"# history = deep_model(model, X_train, y_train, X_val, y_val, epochs, batch_size)","6c47aac1":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","8a2e4478":"# validate on train set\n\npredictions = model.predict(X_train)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_train, predictions)\nprint('train Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_train, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(test_labels.items()), normalize=False)","cf69d0e2":"# validate on test set\n\npredictions = model.predict(X_test)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_test, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(test_labels.items()), normalize=False)","c916190f":"# def eval_metric(model, history, metric_name):\n    \n#     metric = history.history[metric_name]\n#     val_metric = history.history['val_' + metric_name]\n#     e = range(1, len(metric) + 1)\n#     plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n#     plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n#     plt.xlabel('Epoch number')\n#     plt.ylabel(metric_name)\n#     plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n#     plt.legend()\n#     plt.show()","41a9c276":"**Test Data**","b3a15137":"**Validation Data**","08c9af49":"# Build The Model","f91d7c00":"# Import Libraries","ece079fa":"# Data Augmentation For Handling Overfitting","f0597f1c":"**Train Data**","a02445ca":"# Load Data"}}