{"cell_type":{"8cbb8f99":"code","887e3ecf":"code","c3ae4095":"code","7dbf91e2":"code","a38869d7":"code","6c3da4b1":"code","45422c65":"code","6b04863e":"code","45510311":"code","b8797e00":"code","6f11ef11":"code","c0361025":"code","044a13a8":"code","c0c00a85":"code","fa9bd075":"code","8be06be1":"code","4a115ed0":"code","2635f0c5":"code","db6465aa":"code","0390f963":"code","d8218243":"code","b8d4eee3":"code","df176332":"code","d04969a3":"code","7e501d40":"code","61c8d682":"code","dc27e0c5":"code","ccd3534f":"markdown","38e115fc":"markdown"},"source":{"8cbb8f99":"import numpy as np\nimport pandas as pd","887e3ecf":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","c3ae4095":"df_train = import_data('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ndf_test = import_data('..\/input\/tabular-playground-series-dec-2021\/test.csv')","7dbf91e2":"df_test = df_test.set_index('Id')\ndf_test.head()","a38869d7":"df_train = df_train.set_index('Id')\ndf_train.head()","6c3da4b1":"df_train.isnull().sum().sum()","45422c65":"df_train['Cover_Type'].value_counts()","6b04863e":"df_train = df_train[df_train['Cover_Type'] != 5]\ndf_train","45510311":"X = df_train.drop('Cover_Type', axis=1)\nX.head()","b8797e00":"y = df_train['Cover_Type']\ny","6f11ef11":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","c0361025":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y)\n","044a13a8":"import lightgbm as lgb","c0c00a85":"train_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test)","fa9bd075":"df_train['Cover_Type'].unique()","8be06be1":"import optuna","4a115ed0":"def objective(trial):\n    \n    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.20, stratify = y)\n    dtrain = lgb.Dataset(train_x, label=train_y)\n    dtest = lgb.Dataset(valid_x, label=valid_y)\n    param = {\n        \"is_unbalance\": True,\n        'objective': 'multiclass',\n        \"num_class\": 8, #df_train['Cover_Type'].nunique()+1\n        'metric': \"multi_logloss\",\n        'verbosity': -1,\n        \"num_threads\": -1,\n        'num_iterations': 1000,\n        'n_estimators': 7000,\n        \"learning_rate\": trial.suggest_float('learning_rate',0.01,0.2),\n        'boosting_type': trial.suggest_categorical('boosting',['gbdt']),\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'max_depth': trial.suggest_int('max_depth', 2,15),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0)\n        #'bagging_freq': trial.suggest_int('bagging_freq', 1, 7)\n    }\n    \n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"multi_logloss\")\n    \n    gbm = lgb.train(param, dtrain, valid_sets= [dtest])\n    y_pred = gbm.predict(valid_x)\n    test_preds = [np.argmax(x) for x in y_pred]\n    accuracy = accuracy_score(valid_y, test_preds)\n    return accuracy","2635f0c5":"study = optuna.create_study(direction=\"maximize\")\n\nstudy.optimize(objective, n_trials=100, timeout=600)","db6465aa":"print(\"Number of finished trials: {}\".format(len(study.trials)))\n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))","0390f963":"study.trials_dataframe()","d8218243":"train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.20, stratify = y)\ndtrain = lgb.Dataset(train_x, label=train_y)\ndtest = lgb.Dataset(valid_x, label=valid_y)\n\nparams = {\n    'learning_rate': 0.05992665960877217,\n    'boosting': 'gbdt',\n    'lambda_l2': 2.537222734343992, \n    'num_leaves': 225, 'max_depth': 10,\n    \"is_unbalance\" : True,\n    'objective': 'multiclass',\n    \"num_class\": 8, #df_train['Cover_Type'].nunique()+1\n    'metric': \"multi_logloss\",\n    'verbosity': -1,\n    \"num_threads\": -1,\n    'num_iterations': 1000\n    }\n\ngbm = lgb.train(params, dtrain, valid_sets = [dtest])\ny_pred = gbm.predict(valid_x)\ntest_preds = [np.argmax(x) for x in y_pred]\nprint(accuracy_score(valid_y, test_preds))","b8d4eee3":"pred = gbm.predict(df_test)","df176332":"pred = [np.argmax(x) for x in pred]","d04969a3":"df_subb = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\ndf_subb['Cover_Type'] = pred","7e501d40":"df_subb = df_subb.set_index('Id')","61c8d682":"df_subb","dc27e0c5":"df_subb.to_csv('lgb_subb.csv')","ccd3534f":"## Lightboost","38e115fc":"## Optuna"}}