{"cell_type":{"a1b8e445":"code","c1e8cf62":"code","a4a93cfe":"code","e5ad1474":"code","d61e9cfd":"code","40934bc1":"code","40846825":"code","00bdc817":"code","a33440c8":"code","3d7fcafa":"code","6453b1cd":"code","20bcf3d6":"code","b216689e":"code","da766229":"code","7ff61171":"code","9394b0cb":"markdown","976db3c9":"markdown","2e951b86":"markdown","64c7f9fa":"markdown","cd36e3b3":"markdown","a5394274":"markdown","a965f507":"markdown","b4a3772b":"markdown","d6a882d1":"markdown","98d1e695":"markdown","61c5456e":"markdown","c97a7907":"markdown","3433464a":"markdown","f37626d6":"markdown","3f8e1f96":"markdown"},"source":{"a1b8e445":"import numpy as np # linear algebra\nimport os\nfrom time import time\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, image\nfrom keras.utils import np_utils\nimport json\nfrom PIL import Image\nimport os\nimport tensorflow as tf","c1e8cf62":"data_dir = \"..\/input\/coin-images\/coins\/data\"\n\ndata_train_path =  data_dir + '\/train'\ndata_valid_path = data_dir + '\/validation'\ndata_test_path =  data_dir + '\/test'\n\nprint(os.listdir(\"..\/input\/coin-images\/coins\/data\"))","a4a93cfe":"with open('..\/input\/coin-images\/cat_to_name.json', 'r') as json_file:\n    cat_2_name = json.load(json_file)\n\nprint(cat_2_name['200'])","e5ad1474":"batch_size=60\n\n# Transforms\ndatagen_train = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.1,  # randomly shift images horizontally \n    height_shift_range=0.1,  # randomly shift images vertically\n    horizontal_flip=True,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True)\n\ndatagen_valid = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.1,  # randomly shift images horizontally\n    height_shift_range=0.1,  # randomly shift images vertically\n    horizontal_flip=True,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True)\n\ndatagen_test = ImageDataGenerator(\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True,\n    rescale=1.\/255)","d61e9cfd":"\ntrain_generator = datagen_train.flow_from_directory(\n        data_train_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalid_generator = datagen_valid.flow_from_directory(\n        data_valid_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')\n\ntest_generator = datagen_test.flow_from_directory(\n        data_test_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')","40934bc1":"import matplotlib.pyplot as plt\n\n\n# Lets have a look at some of our images\nimages, labels = train_generator.next()\n\nfig = plt.figure(figsize=(20,10))\nfig.subplots_adjust(wspace=0.2, hspace=0.4)\n\n# Lets show the first 32 images of a batch\nfor i, img in enumerate(images[:32]):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(img)\n    image_idx = np.argmax(labels[i])","40846825":"int_to_dir = {v: k for k, v in train_generator.class_indices.items()}","00bdc817":"from keras.applications import MobileNetV2\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.models import Model\n\n\ninput_tensor = Input(shape=(224, 224, 3))\nbase_model = MobileNetV2(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=input_tensor,\n    input_shape=(224, 224, 3),\n    pooling='avg')\n\nfor layer in base_model.layers:\n    layer.trainable = True  # trainable has to be false in order to freeze the layers\n\nx = Dense(512, activation='relu')(base_model.output)\nx = Dropout(.8)(x)\n\npredictions = Dense(211, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n","a33440c8":"from keras.optimizers import Adam\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n             metrics=['accuracy'])","3d7fcafa":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nnum_train = len(train_generator.filenames)\nnum_valid = len(valid_generator.filenames)\nnum_test = len(train_generator.filenames)\n\n\n# When to save the model\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n                               save_best_only=True)\n\n# Reduce learning rate when loss doesn't improve after n epochs\nscheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=5, min_lr=1e-8, verbose=1)\n\n# Stop early if model doesn't improve after n epochs\nearly_stopper = EarlyStopping(monitor='val_loss', patience=12,\n                              verbose=0, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch=num_train\/\/batch_size,\n                    epochs=100,\n                    verbose=1,\n                    callbacks=[checkpointer, scheduler, early_stopper],\n                    validation_data=valid_generator,\n                    validation_steps=num_valid\/\/batch_size)","6453b1cd":"#model.load_weights('..\/input\/mobilenetv2-weights\/model.weights.best.hdf5')","20bcf3d6":"model.save('mobilenet.h5')","b216689e":"score = model.evaluate_generator(test_generator, steps=num_test\/\/1, verbose=1)\nprint('\\n', 'Test accuracy:', score[1])","da766229":"def normalizer(img):\n    img_expand = np.expand_dims(img, axis=0)\n\n    generator = ImageDataGenerator(\n        featurewise_std_normalization=True,\n        samplewise_std_normalization=True,\n        rescale=1.\/255)\n    image_flow = generator.flow(\n        img_expand,\n        y=None,\n        batch_size=1\n    )\n    \n    return image_flow.next()","7ff61171":"def get_prediction(img, real_label):\n    img = image.img_to_array(img)\/255\n    \n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    img = (img - mean)\/std\n    \n    img_expand = np.expand_dims(img, axis=0)\n\n    prediction = model.predict(img_expand)\n    prediction_int = np.argmax(prediction)\n\n    dir_int = int_to_dir[prediction_int]\n    label_name = cat_2_name[str(dir_int)]\n    \n    plt.imshow(img)\n    \n    print(\"Predicted: {}\\nReal:      {}\".format(label_name, cat_2_name[str(real_label)]))\n    print()\n\n\nfor i in range(10):\n    random_index = np.random.randint(0, len(test_generator.filenames))\n    \n    img = test_generator.filenames[random_index]\n    img = image.load_img(\"..\/input\/coin-images\/coins\/data\/test\/\"+img, target_size=(224,224))\n    real_label = test_generator.filenames[random_index].split(\"\/\")[0]\n\n    get_prediction(img, real_label)","9394b0cb":"**Create the model using a pre-trained ResNet50. I add only the fully connected layers at the end.**","976db3c9":"**Sanity check to make sure nothing crazy is happening**","2e951b86":"**Load the data using the generators**","64c7f9fa":"**Evaluate our model**","cd36e3b3":"**Specify the optimizer**","a5394274":"**Specify location of our data**","a965f507":"**Specify how I want to train the model and train the model. How to save the model, when to stop training etc.**","b4a3772b":"**Load our saved model with the best scores**","d6a882d1":"**Keras maps each folder (class) to a number. Create a dictionary that maps the number assigned by keras to our folder real number**","98d1e695":"**Load the json that maps the folder number to the coin name**","61c5456e":"**Load libraries**","c97a7907":"**Create generators to apply transformations to the images during training**","3433464a":"**Plot the images to check transformations**","f37626d6":"**Normalizer**","3f8e1f96":"**The end**"}}