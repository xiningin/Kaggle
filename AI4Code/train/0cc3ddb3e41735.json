{"cell_type":{"4f4ea002":"code","56054be4":"code","bcb0ff25":"code","b32d9810":"code","0ca6a2f0":"code","48903211":"code","abde9961":"code","405657df":"code","1e14b7c7":"code","3be5d520":"code","e4079ef7":"code","37ca4a40":"code","4dcf01f1":"code","b26e6d5c":"code","8f3cfe9c":"code","19c2f4f7":"code","845faf46":"code","b321f9d1":"code","31a96176":"code","39fc7688":"code","c7d333d5":"code","5e61d5b2":"code","eeb44045":"code","ef4fdea0":"code","314f254b":"code","829f8352":"code","2030f1d3":"code","6f5473dd":"code","5837fe22":"code","87f29ab7":"code","a0b8a66e":"code","a2bf3f29":"code","45abba5f":"code","a195f3cd":"code","a7661bc5":"code","ddab84fa":"code","eae23aaa":"code","ed349817":"code","a28d4159":"code","f177d595":"code","4e51cdcf":"code","42551806":"markdown","07415538":"markdown","e72a60cd":"markdown","70d58990":"markdown","de38230f":"markdown","d167ae09":"markdown","fc6b7697":"markdown","b0bcc898":"markdown","57c6816d":"markdown","1be17844":"markdown"},"source":{"4f4ea002":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56054be4":"import warnings\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#ignore warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","bcb0ff25":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/train.csv\", index_col=0, parse_dates=True)\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/test.csv\", index_col=0, parse_dates=True)","b32d9810":"train.head()","0ca6a2f0":"print(train.shape, test.shape)","48903211":"train.info()","abde9961":"train['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])","405657df":"train.info()","1e14b7c7":"# number of unique values\ntrain.nunique()","3be5d520":"categorical_cols = [cols for cols in train.select_dtypes('object')]\nprint(categorical_cols)","e4079ef7":"# counting the number of occurence of each value\nfor col in categorical_cols:\n    print(f\"{col}:\")\n    print(f\"{train[col].value_counts()}\")\n    print(\"\\n\")","37ca4a40":"print(train.date.min())\nprint(train.date.max())","4dcf01f1":"print(test.date.min())\nprint(test.date.max())","b26e6d5c":"plt.figure(figsize=(10,5))\nplt.bar(train['date'], train['num_sold'])","8f3cfe9c":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=train.loc[train['country']=='Norway', 'num_sold'], label='Norway', ax=ax)\nsns.distplot(x=train.loc[train['country']=='Finland', 'num_sold'], label='Finland', ax=ax)\nsns.distplot(x=train.loc[train['country']=='Sweden', 'num_sold'], label='Sweden', ax=ax)\nplt.legend()\nplt.show()","19c2f4f7":"fig, ax = plt.subplots(1, 3, figsize=(12,6))\nsns.boxplot(data=train, x='country', y='num_sold', ax=ax[0])\nsns.boxplot(data=train, x='product', y='num_sold', ax=ax[1])\nsns.boxplot(data=train, x='store', y='num_sold', ax=ax[2])\nplt.show()","845faf46":"import holidays","b321f9d1":"holiday_list = []\nholiday_dict = {}\nfor date, name in holidays.Finland(years=[2015, 2016, 2017, 2018, 2019]).items():\n    holiday_list.append([date, name])\n    \nfor date, name in holidays.Norway(years=[2015, 2016, 2017, 2018, 2019]).items():\n    holiday_list.append([date, name])\n    \nfor date, name in holidays.Sweden(years=[2015, 2016, 2017, 2018, 2019]).items():\n    if name!='S\u00f6ndag':\n        holiday_list.append([date, name.replace(\", S\u00f6ndag\", \"\")])\n        \n\nfor i in range(len(holiday_list)):\n    holiday_dict[holiday_list[i][0]] = holiday_list[i][1]","31a96176":"def create_features(df):\n    df['day'] = df['date'].dt.day\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['DayOfYear'] = df['date'].dt.dayofyear\n    df['weekday'] = df['date'].dt.weekday\n    df['WeekOfYear'] = df['date'].dt.weekofyear\n    df['quarter'] = df['date'].dt.quarter\n#     df['IsLeapYear'] = df['date'].dt.is_leap_year\n    df['weekend'] = (df['date'].dt.weekday>=5).astype(int)\n    df['holiday_name'] = df['date'].map(holiday_dict)\n    df['is_holiday'] = np.where(df['holiday_name'].notnull(), 1, 0)\n    df['holiday_name'] = df['holiday_name'].fillna(\"No holiday\")\n    df['DayOfMonth'] = df['date'].dt.days_in_month\n    df['daysinmonth'] = df['date'].dt.days_in_month\n    df['country_store_product'] = df['country'].astype(str) + df['store'].astype(str) + df['product'].astype(str)\n    df['country_store'] = df['country'].astype(str) + df['store'].astype(str)\n    df['store_product'] = df['store'].astype(str) + df['product'].astype(str) \n    df['country_product'] = df['country'].astype(str) + df['product'].astype(str)\n    df.drop(columns=['date'], inplace=True)\n    \ncreate_features(train)\ncreate_features(test)","39fc7688":"# train['lag1'] = train['num_sold'].shift(1)","c7d333d5":"corr_matrix = train.corr().abs()\nupper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\nprint(upper_tri)","5e61d5b2":"corr = sns.heatmap(upper_tri)\nplt.show()","eeb44045":"from sklearn.feature_selection import mutual_info_regression","ef4fdea0":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","314f254b":"train.columns","829f8352":"# train.lag1 = train.lag1.fillna(0)","2030f1d3":"X = train.copy()\ny = X.pop('num_sold')","6f5473dd":"mi_scores = make_mi_scores(X, y)","5837fe22":"mi_scores","87f29ab7":"plot_mi_scores(make_mi_scores(X, y))","a0b8a66e":"# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n# print(to_drop)","a2bf3f29":"# train.drop(columns= to_drop, inplace=True)\n# test.drop(columns= to_drop, inplace=True)","45abba5f":"categorical_cols= [col for col in train.select_dtypes([\"object\", \"category\"])]\ntrain = pd.get_dummies(train, columns=categorical_cols)\ntest = pd.get_dummies(test, columns=categorical_cols)","a195f3cd":"categorical_cols","a7661bc5":"y = train['num_sold']\ntrain.drop(columns=['num_sold'], axis=1, inplace=True)","ddab84fa":"from sklearn.model_selection import TimeSeriesSplit\nfolds = TimeSeriesSplit(6)","eae23aaa":"#defining error function SMAPE \n# Symmetric mean absolute percentage error (SMAPE or sMAPE) is an accuracy measure based on percentage (or relative) errors\ndef smape(actual, forecast):\n    num = np.abs(forecast-actual)\n    den = (np.abs(actual) + np.abs(forecast))\/2\n    \n    return 100*np.mean(num\/den)","ed349817":"from catboost import CatBoostRegressor\n\ny_pred = np.zeros(len(test))\nscores = []\n\nfor fold, (train_id, test_id) in enumerate (folds.split(train)):\n    print(f\"Fold: {fold}\")\n    \n    X_train, y_train = train.iloc[train_id], y.iloc[train_id]\n    X_valid, y_valid = train.iloc[test_id], y.iloc[test_id]\n    params = {'eval_metric': 'SMAPE', 'iterations': 1000}\n    cat = CatBoostRegressor(**params)\n    \n    cat.fit(X_train, y_train, eval_set=(X_valid, y_valid),\n           early_stopping_rounds=2000, verbose=1000)\n    \n    print('\\n')\n    valid_pred =  cat.predict(X_valid)\n    valid_score = smape(y_valid, valid_pred)\n    scores.append(valid_score)\n    \n    y_pred += cat.predict(test)\/folds.n_splits","a28d4159":"score = np.array(scores).mean()\nprint(f\"Mean SMAPE: {score}\")","f177d595":"submission = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\nsubmission.num_sold = y_pred\nsubmission['num_sold'] = submission['num_sold'].apply(np.ceil)\nsubmission","4e51cdcf":"submission.to_csv('.\/submission.csv', index=False)","42551806":"Refer: [this notebook](https:\/\/www.kaggle.com\/maxencefzr\/tps-jan22-eda-simple-catboost?scriptVersionId=84486229&cellId=26)","07415538":"## Feature Selection","e72a60cd":"## Categorical encoding","70d58990":"##### Finding range of values in train and test data","de38230f":"## Feature Engineering","d167ae09":"In order to avoid using the future data for prediction, we make use of TimeSeriesSplit from Scikit-learn","fc6b7697":"## EDA","b0bcc898":"## CatBoost Regressor model","57c6816d":"## Cross-validation","1be17844":"Reference: [this notebook](https:\/\/www.kaggle.com\/hasanbasriakcay\/playground-jan-22-eda-feature-engineering\/notebook)"}}