{"cell_type":{"4ae92964":"code","522f26de":"code","2890b57a":"code","713d6bc6":"code","1f101d7f":"code","b21fcc55":"code","c13995bb":"code","e17f909d":"code","9683ed58":"code","b9211179":"code","9cbdb0f4":"code","046b9b4a":"code","676e4cd4":"code","5eb500d3":"code","f153f415":"code","92db123d":"code","6bee2f1b":"code","e56fb5b6":"code","6e13bd43":"code","379609f7":"code","6efe8e96":"code","d86085a0":"code","efbe0a8c":"code","b08e1995":"code","f58c7a68":"code","4bd8f8e3":"code","2a167f4a":"code","631ce2fb":"code","fe8fae63":"code","b6459ab8":"code","cad4c83a":"code","fa58cd5c":"code","d65df0d1":"code","61d4a94c":"code","a834750d":"code","9f48bf84":"code","18c9de1c":"code","d05b55c4":"code","c5d41b80":"code","8996b37f":"code","1b13e3d1":"code","a27278d6":"code","5da62306":"markdown","6f9b8f81":"markdown","cc3f9622":"markdown","8478171c":"markdown","c812ccbc":"markdown","13595b3f":"markdown","3488c873":"markdown","d22cee38":"markdown","2039c2f3":"markdown"},"source":{"4ae92964":"import os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\n\nimport numpy as np # linear algebra\nimport pandas as pd\n#pd.set_option(\"display.max_rows\", 101)\nimport math\n\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 10\nimport seaborn as sns\nfrom PIL import Image\n\nfrom collections import Counter\nfrom collections import defaultdict\n\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","522f26de":"DIRin1 = \"..\/input\/severstal-steel-defect-detection\"\nprint(\"DIRin1 =\", os.listdir(DIRin1))\nDIRtrain = os.path.join(DIRin1,\"train_images\")\nDIRtest = os.path.join(DIRin1,\"test_images\")\n\nDIRin2 = \"..\/input\/defect-detection-training\"\nprint(\"DIRin2 =\", os.listdir(DIRin2))\n# save path\nweights_path = os.path.join(DIRin2,\"DefectDetection.h5\")\nhistory_path = os.path.join(DIRin2,\"DefectDetection_history.csv\")\n\nprint(\"Num of Train img\\t:\",len(os.listdir(DIRtrain)))\nprint(\"Num of Test img\\t\\t:\",len(os.listdir(DIRtest)))","2890b57a":"##### Training conditions ##### \nbatch_size = 16\n\nNoTRAIN = True    # True:No further training, use pre-learned weights\nRESUME = False    # True:Resume Training, False:Start from the beginning\n\nif RESUME:\n    initial_epoch = 50    # initial_epoch when training resumes\nelse:\n    initial_epoch = 0\nepochs = initial_epoch + 10\nsteps_per_epoch = 200","713d6bc6":"train_df = pd.read_csv(os.path.join(DIRin1, \"train.csv\"))\ntrain_df.head()","1f101d7f":"# Transform class to column\ntrain_df['fname'], train_df['cls'] = zip(*train_df['ImageId_ClassId'].str.split('_'))\ntrain_df['cls'] = train_df['cls'].astype(int)\ntrain_df = train_df.pivot(index='fname',columns='cls',values='EncodedPixels')\ntrain_df['defects'] = train_df.count(axis=1)\n#train_df.reset_index()\ntrain_df.head(10)","b21fcc55":"# Presence of defects in each images\nno_defects_num = np.sum(train_df['defects'] == 0)\ndefects_num = len(train_df) - no_defects_num\nprint(\"no_defect imgs \\t:\", no_defects_num)\nprint(\"defects imgs \\t:\", defects_num)","c13995bb":"# Number of defects for each class\nclass_defects = len(train_df) - train_df.isnull().sum() # class\u6bce\u306e\u6b20\u9665\u6570\nclass_defects[:4]","e17f909d":"# check images size\ntrain_size = defaultdict(int)\ntest_size = defaultdict(int)\n\nfor fPath in Path(DIRtrain).iterdir():\n    img = Image.open(fPath)\n    train_size[img.size] += 1\nfor fPath in Path(DIRtest).iterdir():\n    img = Image.open(fPath)\n    test_size[img.size] += 1\n    \nprint(\"train_img_size :\",train_size)\nprint(\"test_img_size  :\",test_size)","9683ed58":"palet = [(250, 230, 20), (30, 200, 241), (200, 30, 250), (250,60,20)]\n\nfig, ax = plt.subplots(1, 4, figsize=(6, 2))\nfor i in range(4):\n    ax[i].axis('off')\n    ax[i].imshow(np.ones((10, 40, 3), dtype=np.uint8) * palet[i])\n    ax[i].set_title(\"class{}\".format(i+1))\n\nplt.show()","b9211179":"def mask2rgba(mask):\n    rgba_list = []\n    for idx in range(4):    # idx: class id\n        rgba = cv2.cvtColor(mask[:, :, idx], cv2.COLOR_GRAY2RGBA)\n        rgba[:, :, :3] = rgba[:, :, :3] \/255 * palet[idx]\n        rgba_list.append(rgba)\n    return rgba_list","9cbdb0f4":"def make_mask(row_id):\n    fname = train_df.iloc[row_id].name\n\n    labels = train_df.iloc[row_id][:4]\n    masks = np.zeros((256, 1600, 4), dtype=np.uint8)    # 4:class 1\uff5e4 (ch:0\uff5e3)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            mask = np.zeros(256 * 1600, dtype=np.uint8)\n            for pos, le in zip(positions, length):\n                mask[pos:(pos + le)] = 255\n            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n    return fname, masks","046b9b4a":"def show_mask_image(row_id, contour = True):\n    name, mask = make_mask(row_id)\n    img = cv2.imread(os.path.join(DIRtrain, name))\n\n    if contour:\n        for ch in range(4):\n            contours, _ = cv2.findContours(mask[:, :, ch],\n                            cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n            for i in range(0, len(contours)):\n                cv2.polylines(img, contours[i], True, palet[ch], 2)\n    else:\n        for ch in range(4):\n            img[mask[:,:,ch]==255] = palet[ch]\n        \n    fig, ax = plt.subplots(figsize=(7,7))\n    ax.set_title(name)\n    ax.imshow(img)\n    ax.axis('off')\n    plt.show()","676e4cd4":"# classify defects\nidx_class_1 = list(filter(lambda r:not pd.isna(train_df.iloc[r,0]), range(len(train_df))))\nidx_class_2 = list(filter(lambda r:not pd.isna(train_df.iloc[r,1]), range(len(train_df))))\nidx_class_3 = list(filter(lambda r:not pd.isna(train_df.iloc[r,2]), range(len(train_df))))\nidx_class_4 = list(filter(lambda r:not pd.isna(train_df.iloc[r,3]), range(len(train_df))))\n# Nouber of defects class\nidx_no_defect = list(filter(lambda r:train_df.iloc[r,4] == 0, range(len(train_df))))\nidx_1_defect = list(filter(lambda r:train_df.iloc[r,4] == 1, range(len(train_df))))\nidx_class_multi = list(filter(lambda r:train_df.iloc[r,4] >= 2, range(len(train_df))))","5eb500d3":"# no defect sumple\nfor idx in idx_no_defect[:3]:\n    show_mask_image(idx)","f153f415":"# class_1 defect sumple (Yellow)\nfor idx in idx_class_1[:3]:\n    show_mask_image(idx, contour=False)","92db123d":"# class_2 defect sumple (lightblue)\nfor idx in idx_class_2[:3]:\n    show_mask_image(idx, contour=True)","6bee2f1b":"# class_3 defect sumple (purple)\nfor idx in idx_class_3[:3]:\n    show_mask_image(idx, contour=False)","e56fb5b6":"# class_4 defect sumple (red)\nfor idx in idx_class_4[:3]:\n    show_mask_image(idx, contour=True)","6e13bd43":"# contain multi class defects\nfor idx in idx_class_multi[:3]:\n    show_mask_image(idx, contour=False)","379609f7":"# U-Net\n# https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data#Vanilla-Unet\n\ninput_shape = (256, 1600, 1)\ninputs = Input(input_shape)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\np5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\nc55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\nc55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\nu6 = concatenate([u6, c5])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu71 = concatenate([u71, c4])\nc71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\nc61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\n\n# Load pre-traind weights\nif (NoTRAIN or RESUME) and os.path.exists(weights_path):\n    model.load_weights(weights_path)\n\nmodel.summary()","6efe8e96":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \\\n            \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","d86085a0":"optimizer = Adam()\nmodel.compile(optimizer, 'binary_crossentropy', metrics=[dice_coef])","efbe0a8c":"# Train Data Generator\ndef Xy_generator(ids, batch_size):\n    Xs = []; ys = []\n    while True:\n        for i in ids:\n            name, mask = make_mask(i)\n            img = cv2.imread(os.path.join(DIRtrain, name),\n                             cv2.IMREAD_GRAYSCALE)\n            img = img[..., np.newaxis]    # Add channel axis\n            img = img \/ 255.           # 0\uff5e1\n            mask = mask \/ 255.         # 0\uff5e1\n            Xs.append(img); ys.append(mask)\n            if len(Xs) == batch_size:\n                X = np.array(Xs); y = np.array(ys)\n                Xs = []; ys = []\n                yield [X, y]","b08e1995":"# Train Data\ntrain_ids, val_ids = train_test_split(range(len(train_df)), test_size=0.2)\ntrain_gen = Xy_generator(train_ids, batch_size)\nval_gen = Xy_generator(val_ids, batch_size)","f58c7a68":"# generator test\nfor X, y in Xy_generator(range(len(train_df)), 4):\n    break\n\nprint('X.shape:',X.shape, '\\ny.shape:',y.shape)\n\nrow = 0\n# from train_df\nshow_mask_image(row, contour=True)\n# from generator\nfig, axs = plt.subplots(5, figsize=(7,7))\naxs[0].imshow(X[row,:,:,0])\naxs[0].axis('off')\naxs[0].set_title(train_df.iloc[row].name)\nfor i in range(4):\n    axs[i+1].imshow(y[row,:,:,i])\n    axs[i+1].axis('off')","4bd8f8e3":"# Callback\ncheckpoint = ModelCheckpoint(\"DefectDetection.h5\", monitor='val_dice_coef',\n                             verbose=1,save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","2a167f4a":"# Fit\nif NoTRAIN == False or RESUME:\n    history = model.fit_generator(generator=train_gen,\n                              steps_per_epoch=steps_per_epoch,\n                              initial_epoch=initial_epoch,\n                              epochs=epochs,\n                              validation_data=val_gen,\n                              validation_steps = len(val_ids)\/\/batch_size,\n                              verbose=2,\n                              shuffle=True,\n                              callbacks=callbacks_list)","631ce2fb":"# Plot the loss and dice_coef curves\nif (NoTRAIN or RESUME) and os.path.exists(history_path):\n    hist_df = pd.read_csv(history_path)        # Load previous training history\nif RESUME and os.path.exists(history_path):\n    hist_df1 = pd.DataFrame(history.history)[['loss','val_loss','dice_coef','val_dice_coef']]\n    hist_df = pd.concat([hist_df, hist_df1], ignore_index=True)    # Concat history\nelif NoTRAIN == False and RESUME == False:\n    hist_df = pd.DataFrame(history.history)[['loss','val_loss','dice_coef','val_dice_coef']]\n\n# Plot\nfig, ax = plt.subplots(1,2,figsize=(10, 3))\n\nax[0].plot(hist_df['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist_df['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist_df['dice_coef'], color='b', label=\"Training dice_coef\")\nax[1].plot(hist_df['val_dice_coef'], color='r',label=\"Validation dice_coef\")\nlegend = ax[1].legend(loc='best', shadow=True)","fe8fae63":"# Save history (for next Resume)\nhist_df.to_csv(\"DefectDetection_history.csv\", index=False)","b6459ab8":"# Load the weights that had the best score for predict\nif NoTRAIN == False or RESUME:\n    model.load_weights(\"DefectDetection.h5\")","cad4c83a":"# Binarize the mask output by NN\ndef binarize(masks, th = 0.5):\n    # Maximum value of each channel per pixel\n    mask_max = np.zeros_like(masks[:,:,0])\n    mask_max = np.fmax(masks[:,:,0],masks[:,:,1])\n    mask_max = np.fmax(mask_max,masks[:,:,2])\n    mask_max = np.fmax(mask_max,masks[:,:,3])\n    # Remove non-maximum pixels\n    m = np.zeros_like(masks)\n    for ch in range(4):\n        m[:,:,ch] = (masks[:,:,ch] == mask_max) * masks[:,:,ch]\n    # Binarization\n    m = (m>th) * 1\n    return m","fa58cd5c":"def show_predict_img(df, row):\n    if df == \"train_df\":\n        name = train_df.iloc[row].name\n        img = cv2.imread(os.path.join(DIRtrain, name),\n                             cv2.IMREAD_GRAYSCALE)\n    else:\n        if df == \"submit_df\":\n            name = test_df.iloc[row\/\/4,0].split('_')[0]\n        elif df == \"test_df\":\n            name = test_df.iloc[row,0]\n        img = cv2.imread(os.path.join(DIRtest, name),\n                             cv2.IMREAD_GRAYSCALE)\n\n    img_ = img[..., np.newaxis]    # Add channel axis\n    img_ = img_[np.newaxis, ...]    # Add batch axis\n    img_ = img_ \/ 255.              # 0\uff5e1\n\n    pred_masks = model.predict(img_)\n    bin_masks = binarize(pred_masks[0, ...], 0.5)\n\n    fig, axs = plt.subplots(5,2, figsize=(12, 6))\n    axs[0,0].imshow(img)\n    axs[0,0].axis('off')\n    axs[0,0].set_title(name)\n    axs[0,1].axis('off')\n    axs[0,1].set_title(\"after binarize\")\n    for i in range(4):\n        axs[i+1,0].imshow(pred_masks[0,:,:,i])\n        axs[i+1,0].axis('off')\n        axs[i+1,0].set_title('class '+ str(i+1))\n        axs[i+1,1].imshow(bin_masks[:,:,i])\n        axs[i+1,1].axis('off')\n        axs[i+1,1].set_title('class '+ str(i+1))","d65df0d1":"# predict sumple\nshow_predict_img(\"train_df\", 4)","61d4a94c":"submit_df = pd.read_csv(os.path.join(DIRin1,'sample_submission.csv'))\nsubmit_df['EncodedPixels'] = np.nan\nsubmit_df.head(5)","a834750d":"temp_df = pd.DataFrame()\ntemp_df['ImageId'] = submit_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_df = pd.DataFrame(temp_df['ImageId'].unique(), columns=['ImageId'])\ntest_df.head()","9f48bf84":"def mask2rle(mask):\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[:-1:2]\n    return ' '.join(str(x) for x in runs)","18c9de1c":"def build_rles(masks):\n    width, height, depth = masks.shape\n    masks = binarize(masks, th = 0.5)\n    rles = [mask2rle(masks[:, :, i]) for i in range(depth)]\n\n    return rles","d05b55c4":"# Predict test images\nfor i, line in tqdm(test_df.iterrows()):\n    img = cv2.imread(os.path.join(DIRtest, line['ImageId']),\n                     cv2.IMREAD_GRAYSCALE)\n    img = img[..., np.newaxis]    # Add channel axis\n    img = img[np.newaxis, ...]    # Add butch axis\n    img = img \/ 255.              # 0\uff5e1\n    pred_masks = model.predict(img)[0]\n    rles = build_rles(pred_masks)\n    for j in range(4):\n        if len(rles[j])>0:\n            submit_df.iloc[i*4+j,1] = rles[j]","c5d41b80":"submit_df.head(30)","8996b37f":"# Number of Defect Detection\nsubmit_df['EncodedPixels'].count()","1b13e3d1":"# Detected sumple\nshow_predict_img(\"submit_df\",26)","a27278d6":"submit_df.to_csv('submission.csv', index=False)","5da62306":"## Predict","6f9b8f81":"## Training","cc3f9622":"## Model","8478171c":"## Steel Defect Detection\nThis is starter kernel.<BR>\nI used many kernels as a reference for creating this kernel. Especially,<BR>\n[\"clear mask visualization and simple eda (GoldFish)\"](https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda) for image data visualization.<BR>\n[\"RLE functions - Run Lenght Encode & Decode (Paulo Pinto)\"](https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode) for rle encode-decode.<BR>\n[\"Intro - chest xray, DICOM, viz, U-nets - full data (Jesper)\"](https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data#Vanilla-Unet) for model","c812ccbc":"## Submission","13595b3f":"Training is inadequate at the regular time of the one-hour competition. So I traind 50 epochs on my local PC (about 3 hours). And This kernel does not perform any further training, but uses pre-learned weights data.<BR>\nIf you want to train, set `NoTRAIN = False`.","3488c873":"## Image Data confirmation","d22cee38":"## Prepare Training","2039c2f3":"## Visualization"}}