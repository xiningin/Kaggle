{"cell_type":{"568225da":"code","6a005912":"code","6c974e09":"code","148e8123":"code","e3f51f6d":"code","51e46d71":"code","b3d87e04":"code","d48ded7a":"code","197ece79":"code","507b9c92":"code","a598aef8":"code","8a1e934f":"code","ebbeb574":"code","32e2eb2d":"code","78b93dcc":"code","bceda769":"code","d427f730":"code","df3b3595":"code","4088baf8":"code","51cff69a":"code","46ffe820":"code","32b508e6":"code","7db05e81":"code","ce12e742":"code","af65efe7":"code","548acc38":"code","869e85ad":"code","af9fbd52":"code","8add026c":"code","b4ad1bf5":"code","5ac439ca":"code","811a7119":"code","49220dc7":"code","66c8ad27":"code","59d90c80":"code","fc934de4":"code","b911a97b":"code","5d73a535":"code","406a66c3":"code","fda27392":"code","bb356abc":"code","0b07edfc":"code","efd2dac0":"markdown","c76a0e6b":"markdown","7ff02cfe":"markdown","6c39aae9":"markdown","1d68eb3f":"markdown","6f6f543b":"markdown","a9258fae":"markdown","3b013413":"markdown","fd3eb903":"markdown"},"source":{"568225da":"import numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\nimport tensorflow as tf\nfrom tensorflow import keras","6a005912":"## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation\n## Load the NIH data to all_xray_df\nall_xray_df = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..\/input\/data','images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df.sample(3)","6c974e09":"# Using only PA images\npa_xray_df = all_xray_df.drop(all_xray_df.loc[all_xray_df['View Position']=='AP'].index)","148e8123":"## Splitting finding lables into individual rows\ncleaned = pa_xray_df.rename(columns={'Finding Labels': 'labels'})\ncleaned = cleaned.set_index('Image Index').labels.str.split('|', expand=True).stack().reset_index(level=1, drop=True).to_frame('lables')\ncleaned.head()","e3f51f6d":"# getting dummy variables for the lables and grouping by the index.\ncleaned = pd.get_dummies(cleaned, columns=['lables']).groupby(level=0).sum()","51e46d71":"cleaned.head()","b3d87e04":"# ensuring both data frames use the same index\npa_xray_df.set_index('Image Index', inplace=True)","d48ded7a":"# merging dummy variable columns with the data frame containing the image paths.\nprepared_df = pa_xray_df.merge(cleaned, left_index = True, right_index=True)","197ece79":"prepared_df.head()","507b9c92":"## Renamiong dummy column to 'pneumonia_class' that will allow us to look at \n## images with or without pneumonia for binary classification\n\nprepared_df.rename(columns={'lables_Pneumonia': 'pneumonia_class'}, inplace=True)","a598aef8":"# Checking that class is binary\nprepared_df.pneumonia_class.unique()","8a1e934f":"prepared_df.to_csv(\"prepared_df.csv\")","ebbeb574":"prepared_df = pd.read_csv(\"prepared_df.csv\", index_col=\"Image Index\")","32e2eb2d":"# checking class imbalance\nprepared_df['pneumonia_class'].value_counts()","78b93dcc":"train_data, val_data = train_test_split(prepared_df, test_size=0.2, stratify = prepared_df['pneumonia_class'], random_state=42)","bceda769":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True)\n\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center=False,\n    featurewise_std_normalization=False)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_data, directory=None, x_col='path', y_col='pneumonia_class', weight_col=None,\n    target_size=(224, 224), color_mode='rgb', classes=None,\n    class_mode='raw', batch_size=32, shuffle=True, seed=42,\n    save_to_dir=None, save_prefix='', save_format='png', subset=None,\n    interpolation='nearest', validate_filenames=True\n)\nvalidation_generator = val_datagen.flow_from_dataframe(\n    val_data, directory=None, x_col='path', y_col='pneumonia_class', weight_col=None,\n    target_size=(224, 224), color_mode='rgb', classes=None,\n    class_mode='raw', batch_size=32, shuffle=True, seed=42,\n    save_to_dir=None, save_prefix='', save_format='png', subset=None,\n    interpolation='nearest', validate_filenames=True\n)","d427f730":"## May want to look at some examples of our augmented training data. \n## This is helpful for understanding the extent to which data is being manipulated prior to training, \n## and can be compared with how the raw data look prior to augmentation\n\nt_x, t_y = next(train_generator)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    if c_y == 1: \n        c_ax.set_title('Pneumonia')\n    else:\n        c_ax.set_title('No Pneumonia')\n    c_ax.axis('off')","df3b3595":"METRICS = [\n          keras.metrics.TruePositives(name='tp'),\n          keras.metrics.FalsePositives(name='fp'),\n          keras.metrics.TrueNegatives(name='tn'),\n          keras.metrics.FalseNegatives(name='fn'), \n          keras.metrics.BinaryAccuracy(name='accuracy'),\n          keras.metrics.Precision(name='precision'),\n          keras.metrics.Recall(name='recall'),\n          keras.metrics.AUC(name='auc'),\n        ]","4088baf8":"# defining model generator\ndef get_model(metrics = METRICS, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    \n    densenet = tf.keras.applications.DenseNet201(weights = 'imagenet', include_top=False, pooling = 'avg', input_shape=[224, 224, 3])\n    densenet.trainable = True # Using pretrained weights due to compute limitation on the worspace.\n    model = tf.keras.Sequential([\n            densenet,\n            tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n            ])\n\n    model.compile(\n            optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False),\n            loss = keras.losses.BinaryCrossentropy(),\n            metrics = METRICS\n            )\n    return model","51cff69a":"# defining learning rate sheduler (currently not used)\nLR_START = 0.0001\nLR_MAX = 0.0001\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 3\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = np.random.random_sample() * LR_START # Using random learning rate for initial epochs.\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX \n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN # Rapid decay of learning rate to improve convergence.\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","46ffe820":"# defining early stopping\nes_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=5,\n    mode='max',\n    restore_best_weights=True)","32b508e6":"checkpoint_path = \"training\/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","7db05e81":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU'))) #check gpu status","ce12e742":"# calculating class weights to adress class imbalance\npositive_findings = 630\nnegative_findings = 66680\ntotal = positive_findings+negative_findings\n\ninitial_bias = np.log([positive_findings\/negative_findings])\n\nweight_for_0 = (1 \/ negative_findings)*(total)\/2.0 \nweight_for_1 = (1 \/ positive_findings)*(total)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","af65efe7":"model = get_model(output_bias = initial_bias)","548acc38":"model.summary()","869e85ad":"#with active_session():\nhistory = model.fit(train_generator, \n                        epochs = 10, \n                        verbose = 2, \n                        validation_data = validation_generator, \n                        callbacks = [lr_callback, es_callback, cp_callback], \n                        class_weight = class_weight)","af9fbd52":"\"\"\"Plotting the history of model training \n(due to time requirement of the training \nand workspace timing out this may not be available):\"\"\"\n\ndef plot_metrics(history):\n    metrics =  ['loss', 'auc', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch,  history.history[metric], color='b', label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric],\n             color='r', linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n          plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n          plt.ylim([0.8,1])\n        else:\n          plt.ylim([0,1])\n\n    plt.legend()","8add026c":"if history is not None:\n    plot_metrics(history)","b4ad1bf5":"model.save('models\/dense_model_retrained')","5ac439ca":"## After training, make some predictions to assess your model's overall performance\n## Note that detecting pneumonia is hard even for trained expert radiologists, \n## so there is no need to make the model perfect.\nweight_path = checkpoint_path\nmodel.load_weights(weight_path)","811a7119":"results = model.evaluate(validation_generator, verbose=2)\nprint(\"Loss: {:0.4f}\".format(results[0]))","49220dc7":"# Plotting AUC.\ndef plot_auc(t_y, p_y):\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    fpr, tpr, thresholds = roc_curve(t_y, p_y)\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % ('Pneumonia', auc(fpr, tpr)))\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n\n## Checking presicion recall curve based on thresholds.\n\ndef plot_precision_recall_curve(t_y, p_y):\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    precision, recall, thresholds = precision_recall_curve(t_y, p_y)\n    c_ax.plot(recall, precision, label = '%s (AP Score:%0.2f)'  % ('Pneumonia', average_precision_score(t_y,p_y)))\n    c_ax.legend()\n    c_ax.set_xlabel('Recall')\n    c_ax.set_ylabel('Precision')","66c8ad27":"valX, valY = next(validation_generator)\npred_Y = model.predict(valX, batch_size = 32, verbose = True)","59d90c80":"plot_auc(valY, pred_Y)","fc934de4":"plot_precision_recall_curve(valY, pred_Y)","b911a97b":"# F1 calulator helper fuction.\ndef  calc_f1(prec,recall):\n    return 2*(prec*recall)\/(prec+recall)","5d73a535":"precision, recall, thresholds = precision_recall_curve(valY, pred_Y)","406a66c3":"# Look at the threshold where precision is 0.8\nprecision_value = 0.8\nidx = (np.abs(precision - precision_value)).argmin() \nprint('Precision is: '+ str(precision[idx]))\nprint('Recall is: '+ str(recall[idx]))\nprint('Threshold is: '+ str(thresholds[idx]))\nprint('F1 Score is: ' + str(calc_f1(precision[idx],recall[idx])))","fda27392":"# Look at the threshold where recall is 0.8\nrecall_value = 0.8\nidx = (np.abs(recall - recall_value)).argmin() \nprint('Precision is: '+ str(precision[idx]))\nprint('Recall is: '+ str(recall[idx]))\nprint('Threshold is: '+ str(thresholds[idx]))\nprint('F1 Score is: ' + str(calc_f1(precision[idx],recall[idx])))","bb356abc":"## Let's look at some examples of true vs. predicted with our best model: \n\nYOUR_THRESHOLD = 0.5\n\nfig, m_axs = plt.subplots(10, 10, figsize = (16, 16))\ni = 0\nfor (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    if c_y == 1: \n        if pred_Y[i] > YOUR_THRESHOLD:\n             c_ax.set_title('1, 1')\n        else:\n             c_ax.set_title('1, 0')\n    else:\n        if pred_Y[i] > YOUR_THRESHOLD: \n             c_ax.set_title('0, 1')\n        else:\n             c_ax.set_title('0, 0')\n    c_ax.axis('off')\n    i=i+1","0b07edfc":"## Just save model architecture to a .json:\n\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","efd2dac0":"## Early processing of metadata for easier model training:","c76a0e6b":"#### First suggestion: perform some image augmentation on your data","7ff02cfe":"# Basline GPU DenseNet Model\n\nTrying out a densenet201 architecture for Xray Pneumonia Detection. This model shall serve as a baseline for a TPU accelerated model.","6c39aae9":"Playing with classification thresholds:","1d68eb3f":"# Data Preprocessing:","6f6f543b":"##### Plotting some performance statistics:","a9258fae":"## Building model: ","3b013413":"### Start training! ","fd3eb903":"## Train-Validation Split:"}}