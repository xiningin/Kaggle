{"cell_type":{"4b2762ce":"code","ae7c12ed":"code","f67a65ff":"code","9ebd5efc":"code","5ea7a216":"code","ad70f241":"code","3feec808":"code","afc6531a":"code","7829ae04":"code","bd3b07c1":"code","2b9ee562":"code","f7508e62":"code","b6b30000":"code","bbf718ea":"code","e25d9be2":"code","cc900677":"code","6d8aebba":"code","13b24a7f":"code","389a3ce4":"code","11ecfc7c":"code","49769268":"code","575711e4":"code","9a74c7fd":"code","33814220":"code","c7aa1e6a":"code","77551828":"code","b9cf852c":"code","7f9510b5":"code","48e4697c":"code","61773599":"code","257da5fe":"code","c093f5d8":"code","210aa4b2":"code","2ece9d8d":"code","f0bb23d9":"code","9f2658b0":"code","28caa9b6":"code","02dfa5cf":"code","3e37ac70":"code","3074f3b9":"markdown","1dcb9a7d":"markdown","fc2e7fbe":"markdown","b7520a67":"markdown"},"source":{"4b2762ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae7c12ed":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nimport shutil\nimport numpy as np\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l2\nfrom shutil import copyfile\nfrom os import getcwd","f67a65ff":"local_zip = '..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip'\n\nzip_ref = zipfile.ZipFile(local_zip, 'r')\n\nzip_ref.extractall('\/kaggle\/working\/')\nzip_ref.close()","9ebd5efc":"base_dir = '\/kaggle\/working\/'\ntrain_dir = os.path.join(base_dir, 'train')\ntrain_img_names = os.listdir(train_dir)","5ea7a216":"train_img_names[:10]","ad70f241":"print('total training images :', len(train_img_names ))","3feec808":"categories= list()\nfor image in train_img_names:\n    category = image.split(\".\")[0]\n    if category == \"dog\":\n        categories.append(\"dog\")\n    else:\n        categories.append(\"cat\")\ndf= pd.DataFrame({\"Image\":train_img_names, \"Category\": categories})","afc6531a":"df.head()","7829ae04":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nplt.figure(figsize=(12,10))\nsns.countplot(data=df, x=\"Category\",palette=\"magma\")","bd3b07c1":"sample = random.choice(train_img_names)\nplt.imshow(plt.imread((\"\/kaggle\/working\/train\/\"+sample)))","2b9ee562":"sample = random.choice(train_img_names)\nplt.imshow(plt.imread((\"\/kaggle\/working\/train\/\"+sample)))","f7508e62":"from sklearn.model_selection import train_test_split\ntrain,validation= train_test_split(df, test_size=0.1)\ntrain = train.reset_index(drop=True)\nvalidation = validation.reset_index(drop=True)","b6b30000":"train","bbf718ea":"validation","e25d9be2":"plt.figure(figsize=(13,10))\nsns.countplot(data=train, x=\"Category\",palette=\"viridis\")","cc900677":"plt.figure(figsize=(13,10))\nsns.countplot(data=validation, x=\"Category\",palette=\"plasma\")","6d8aebba":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\n\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_dataframe(train,\n                                                    directory=\".\/train\",\n                                                    x_col='Image',\n                                                    y_col='Category',\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))   ","13b24a7f":"validation_datagen  = ImageDataGenerator( rescale = 1.0\/255.)\nvalidation_generator =  validation_datagen.flow_from_dataframe(validation,\n                                                            directory=\".\/train\",\n                                                              x_col='Image',\n                                                             y_col='Category',\n                                                              batch_size=20,\n                                                              class_mode  = 'binary',\n                                                              target_size = (150, 150))","389a3ce4":"import tensorflow\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=3,activation=\"relu\", input_shape=(150,150,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=64, kernel_size=3,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=128, kernel_size=3, activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=256, kernel_size=3, activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=256, kernel_size=3, activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=2, strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(units=1024, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=1, activation=\"sigmoid\"))","11ecfc7c":"model.summary()","49769268":"model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","575711e4":"callback=EarlyStopping(monitor=\"val_loss\", patience=2)\ncallback_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=2, factor=0.5, min_lr=0.00001)","9a74c7fd":"\n\nhistory=model.fit(train_generator, validation_data=validation_generator, \n                  epochs=8, callbacks=[callback,callback_lr])","33814220":"pd.DataFrame(model.history.history)","c7aa1e6a":"sns.set_style(\"darkgrid\")\npd.DataFrame(model.history.history).plot(figsize=(15,10))","77551828":"acc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","b9cf852c":"# Extracting the zip file\n\ntest_zip = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip'\nzip_ref = zipfile.ZipFile(test_zip, 'r')\nzip_ref.extractall('\/kaggle\/working')\nzip_ref.close()\n\n","7f9510b5":"test_dir = '\/kaggle\/working\/test\/'\ntest_images = os.listdir(os.path.join(test_dir))\ntest_images[:10]","48e4697c":"test_df = pd.DataFrame({'Image': test_images})\ntest_df.head()","61773599":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(test_df,\n                                                  directory=\"\/kaggle\/working\/test\",\n                                                 x_col=\"Image\",\n                                                 y_col=None,\n                                                  class_mode  = None,\n                                                 target_size=(150,150),\n                                                shuffle = True,\n                                                batch_size=20)","257da5fe":"predictions = model.predict(test_generator,steps = np.ceil(12500\/20))\npredictions","c093f5d8":"test_df[\"category\"]=pd.DataFrame(predictions, columns=[\"category\"])\ntest_df","210aa4b2":"def labelizor(prediction):\n    if prediction > 0.5:\n        return 1\n    else:\n        return 0","2ece9d8d":"test_df[\"category\"] = test_df[\"category\"].apply(labelizor)\ntest_df","f0bb23d9":"plt.figure(figsize=(13,10))\nsns.countplot(data=test_df, x=\"category\",palette=\"magma\")","9f2658b0":"test_df=test_df.reset_index()\ntest_df","28caa9b6":"test_df=test_df.rename(columns={\"index\": \"id\"})\ntest_df","02dfa5cf":"submission_df=test_df.copy()\nsubmission_df.drop(\"Image\", axis=1, inplace=True)\nsubmission_df","3e37ac70":"submission_df.to_csv('submission.csv', index=False)","3074f3b9":"## 2. Building a Small Model from Scratch","1dcb9a7d":"## 4. Preparing Test Data and Submission","fc2e7fbe":"## 1. Preparation of Data and Exploratory Data Analysis","b7520a67":"## 3. Performance Evaluation of the Training"}}