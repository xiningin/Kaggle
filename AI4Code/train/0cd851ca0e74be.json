{"cell_type":{"d951808b":"code","c8a043b3":"code","c4b16fa1":"code","52fe7727":"code","b97b1fde":"code","9c66d9ae":"code","af239715":"code","e482916c":"code","8670635b":"code","8317a77b":"code","b264c575":"code","abf078f0":"code","f3ecf3ed":"code","0c9893d8":"code","3cf66ae9":"code","fa113f6f":"code","c99f084f":"code","4227d89d":"code","270b8372":"code","0659868c":"code","782569ba":"code","14958c3d":"code","28823cbb":"code","d5c0b57c":"code","93521f9f":"code","4d6f9c2d":"code","d25d9270":"code","e2473dd1":"code","a6dc6961":"markdown","11b238cf":"markdown","6d2beba7":"markdown","db29f9bd":"markdown","8c9d9e74":"markdown","632b547a":"markdown","fc28130d":"markdown","e6170baf":"markdown"},"source":{"d951808b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8a043b3":"!pip install pyreadstat","c4b16fa1":"df=pd.read_spss(\"..\/input\/covid19-lockdown-pain-interference-resilience\/COVIDPAIN_EuropeanJPsychotraumatology_AELpez-Martnez.sav\")\npd.set_option('display.max_columns', None)\n\ndf.tail(2)","52fe7727":"df[\"Sexo\"].value_counts()","b97b1fde":"# For viz: Ratio of Males & Females\n\nx=df.groupby(['Sexo'])['Sexo'].count()\ny=len(df)\nr=((x\/y)).round(2)\n\nmf_ratio = pd.DataFrame(r).T","9c66d9ae":"fig, ax = plt.subplots(1,1,figsize=(6.5, 2.5))\n\nax.barh(mf_ratio.index, mf_ratio['Hombre'], \n        color='#244747', alpha=0.7, label='Hombre')\nax.barh(mf_ratio.index, mf_ratio['Mujer'], left=mf_ratio['Hombre'], \n        color='#91b8bd', alpha=0.7, label='Mujer')\n\nax.set_xlim(0, 1)\nax.set_xticks([])\nax.set_yticks([])\n#ax.set_yticklabels(mf_ratio.index, fontfamily='serif', fontsize=11)\n\n# male percentage\nfor i in mf_ratio.index:\n    ax.annotate(f\"{int(mf_ratio['Hombre'][i]*100)}%\", \n                   xy=(mf_ratio['Hombre'][i]\/2, i),\n                   va = 'center', ha='center',fontsize=60, fontweight='light', fontfamily='serif',\n                   color='white')\n\n    ax.annotate(\"Hombre\", \n                   xy=(mf_ratio['Hombre'][i]\/2, -0.25),\n                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',\n                   color='white')\n    \n    \nfor i in mf_ratio.index:\n    ax.annotate(f\"{int(mf_ratio['Mujer'][i]*100)}%\", \n                   xy=(mf_ratio['Hombre'][i]+mf_ratio['Mujer'][i]\/2, i),\n                   va = 'center', ha='center',fontsize=60, fontweight='light', fontfamily='serif',\n                   color='#244747')\n    ax.annotate(\"Mujer\", \n                   xy=(mf_ratio['Hombre'][i]+mf_ratio['Mujer'][i]\/2, -0.25),\n                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',\n                   color='#244747')\n\n\n# Title & Subtitle\nfig.text(0.125,1.03,'Hombre & Mujer distribution', fontfamily='serif',fontsize=15, fontweight='bold')\nfig.text(0.125,0.92,'We see a fairly even split, but with many more females.',fontfamily='serif',fontsize=12)  \n\nfor s in ['top', 'left', 'right', 'bottom']:\n    ax.spines[s].set_visible(False)\n    \n\n\n#ax.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.06))\n\n# Removing legend due to labelled plot\nax.legend().set_visible(False)\nplt.show()","af239715":"fig = plt.figure(figsize=(12, 8))\ngs = fig.add_gridspec(3,1)\ngs.update(hspace= -0.55)\n\naxes = list()\ncolors = [\"#004c70\", \"#990000\",'#990000']\n\nfor idx, cls, c in zip(range(4), df['Edad'].unique(), colors):\n    axes.append(fig.add_subplot(gs[idx, 0]))\n    \n    # you can also draw density plot with matplotlib + scipy.\n    sns.kdeplot(x='Dolor_total', data=df[df['Edad']==cls], \n                fill=True, ax=axes[idx], cut=3, bw_method=0.25, \n                lw=1.4, edgecolor='lightgray',multiple=\"stack\", palette=['#91b8bd','#244747'], alpha=0.7,hue='Sexo') \n    \n    \n    \n               \n    axes[idx].set_ylim(0, 0.04)\n    axes[idx].set_xlim(0, 100)\n    \n    axes[idx].set_yticks([])\n    if idx != 2 : axes[idx].set_xticks([])\n    axes[idx].set_ylabel('')\n    axes[idx].set_xlabel('')\n    \n    spines = [\"top\",\"right\",\"left\",\"bottom\"]\n    for s in spines:\n        axes[idx].spines[s].set_visible(False)\n        \n    axes[idx].patch.set_alpha(0)\n    axes[idx].text(-0.2,0.001,f'{cls} ',fontweight=\"light\", fontfamily='serif', fontsize=11,ha=\"right\")\n    if idx != 4 : axes[idx].get_legend().remove() # changed to 4 to remove legend. This says, if it is not the 4th plot remove the legend\n    \n\nfig.text(0.13,0.8,\"Pain distribution by Gender and Age\", fontweight=\"bold\", fontfamily='serif', fontsize=15)\nfig.text(0.13,0.77,'Interestingly, Seniors have no higer Dolor total than 60.',fontfamily='serif',fontsize=12)\n\nfig.text(0.776,0.77,\"Hombre\", fontweight=\"bold\", fontfamily='serif', fontsize=15, color='#244247')\nfig.text(0.825,0.77,\"|\", fontweight=\"bold\", fontfamily='serif', fontsize=15, color='black')\nfig.text(0.835,0.77,\"Mujer\", fontweight=\"bold\", fontfamily='serif', fontsize=15, color='#91b8bd')\n\nplt.show()","e482916c":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Edad\"].value_counts().plot.barh(color=['blue', 'red','lime','purple','teal','cyan'], title='Age',)","8670635b":"df[\"Civil\"].value_counts().plot.barh(figsize = (8,6))","8317a77b":"df[\"N_Educativo\"].value_counts().plot.barh(color=['blue', 'red','lime','purple'], title='Educational Degree')","b264c575":"df[\"Laboral\"].value_counts().plot.barh(color=['blue', 'red','lime','purple', 'teal', 'magenta'], title='Working Status')","abf078f0":"df[\"Diagnostico\"].value_counts().plot.barh(figsize = (8,6), title= 'Diagnosis')","f3ecf3ed":"df[\"Resilencia_total\"].value_counts()","0c9893d8":"df[\"Tipo_trauma\"].value_counts().plot.barh(color=['blue', 'red','lime','purple', 'darkolivegreen'], title='Kind of Trauma', figsize = (8,6))","3cf66ae9":"#Codes by Rafet Kandar https:\/\/www.kaggle.com\/rafetkandar\/titanic-eda-visualization-prediction\n\ndef bar_plot(variable):\n    \"\"\"\n    input : variable ex : \"Sexo\"\n    output : bar plot & value count  \n    \"\"\"\n    # get feature\n    var = df[variable]\n    #count number of categorical variable (value\/sample)\n    varValue = var.value_counts()\n\n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue,color = \"green\", edgecolor = \"black\", linewidth = 2)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","fa113f6f":"category1 = [\"WHO_WHO1\",\"Agresi\u00f3n_dico\",\"Tratamiento\",\"BPI_Alivio_1\",\"Con_rutinas\",\"Con_actividad\", \"Estr\u00e9s__C_msexual\", \"Medicaci\u00f3n\"]\nfor c in category1:\n    bar_plot(c)","c99f084f":"#Codes by Rafet Kandar https:\/\/www.kaggle.com\/rafetkandar\/titanic-eda-visualization-prediction\n\ndef plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(df[variable])\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist \".format(variable))\n    plt.show()","4227d89d":"numericVar = [\"BPI_interferencia_total\",\"N\u00famero_traumas\",\"Dolor_total\"]\nfor n in numericVar:\n    plot_hist(n)","270b8372":"df = pd.get_dummies(df)","0659868c":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","782569ba":"df_len = len(df)","14958c3d":"df_len","28823cbb":"test = df[df_len:]\ntest.drop(labels = [\"Dolor_total\"],axis = 1, inplace = True)","d5c0b57c":"train = df[:df_len]\nX_train = train.drop(labels = \"Dolor_total\", axis = 1)\ny_train = train[\"Dolor_total\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","93521f9f":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","4d6f9c2d":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","d25d9270":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","e2473dd1":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","a6dc6961":"#Why the number 1 of 13% is not appearing?","11b238cf":"#ValueError: Unknown label type: 'continuous'","6d2beba7":"![](https:\/\/www.newvictoria.co.uk\/media\/uploads\/Blog\/newvictoriahospital_myofascialpain_blog.jpg)newvictoria.co.uk","db29f9bd":"#Codes by Joshua Swords https:\/\/www.kaggle.com\/joshuaswords\/data-visualization-clustering-mall-data ","8c9d9e74":"#Codes by Rafet Kandar https:\/\/www.kaggle.com\/rafetkandar\/titanic-eda-visualization-prediction","632b547a":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT8-Rl87nrZrzbg3YjTNgzSfLoQL12qQVN2Vg&usqp=CAU)tranquillarosa.co.uk","fc28130d":"#Adverse effects of COVID-19-related lockdown on pain, physical activity and psychological well-being \n#in people with chronic pain\n\nAuthors: Nicholas Fallon, Christopher Brown, Hannah Twiddy, Eleanor Brian, Bernhard Frank, Turo Nurmikko, Andrej Stancak\n\nFirst Published November 21, 2020 Research Article - https:\/\/doi.org\/10.1177\/2049463720973703\n\nCountries across the world imposed lockdown restrictions during the COVID-19 pandemic. It has been proposed that lockdown conditions, including social and physical distancing measures, may disproportionately impact those living with chronic pain and require rapid adaptation to treatment and care strategies.\n\nUsing an online methodology, the authors investigated how lockdown restrictions in the United Kingdom impacted individuals with chronic pain (N\u2009=\u2009431) relative to a healthy control group (N\u2009=\u200988). Data were collected during the most stringent period of lockdown in the United Kingdom (mid-April to early-May 2020).\n\nIn accordance with the fear-avoidance model, they hypothesised lockdown-related increases in pain and psychological distress, which would be mediated by levels of pain catastrophising. Responses indicated that people with chronic pain perceived increased pain severity, compared to their estimation of typical pain levels prior to lockdown (p\u2009<\u2009.001). They were also more adversely affected by lockdown conditions compared to pain-free individuals, demonstrating greater self-perceived increases in anxiety and depressed mood, increased loneliness and reduced levels of physical exercise (p\u2009\u2a7d\u2009.001). \n\nHierarchical regression analysis revealed that pain catastrophising was an important factor relating to the extent of self-perceived increases in pain severity during lockdown (\u03b2\u2009=\u2009.27, p\u2009<\u2009.001) and also mediated the relationship between decreased mood and pain. Perceived decreases in levels of physical exercise also related to perceptions of increased pain (\u03b2\u2009=\u2009.15, p\u2009<\u2009.001).\n\nInterestingly, levels of pain intensity (measured at two time points at pre and during lockdown) in a subgroup (N\u2009=\u200985) did not demonstrate a significant change. However, individuals in this subgroup still reported self-perceived pain increases during lockdown, which were also predicted by baseline levels of pain catastrophising. Overall, the findings indicate that people with chronic pain suffer adverse effects of lockdown including self-perceived increases in their pain. Remote pain management provision to target reduction of pain catastrophising and increase health behaviours including physical activity could be beneficial for this vulnerable population.\n\nhttps:\/\/journals.sagepub.com\/doi\/full\/10.1177\/2049463720973703","e6170baf":"#ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."}}