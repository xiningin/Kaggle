{"cell_type":{"14501bd5":"code","9a72e5af":"code","18632c0d":"code","06d798ba":"code","2679ebd0":"code","a2e52805":"markdown","47afbb51":"markdown","ff2955ec":"markdown","0ff2bf42":"markdown","965c08f0":"markdown","d6eec596":"markdown","4eedafa1":"markdown","a24722c0":"markdown"},"source":{"14501bd5":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\nbitcoin_blockchain = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                              dataset_name=\"bitcoin_blockchain\")\nbitcoin_blockchain.list_tables()","9a72e5af":"query = \"\"\" WITH time AS \n            (\n                SELECT TIMESTAMP_MILLIS(timestamp) AS trans_time,\n                    transaction_id\n                FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n            )\n            SELECT COUNT(transaction_id) AS transactions,\n                EXTRACT(MONTH FROM trans_time) AS month,\n                EXTRACT(YEAR FROM trans_time) AS year\n            FROM time\n            GROUP BY year, month \n            ORDER BY year, month\n        \"\"\"\n\n# note that max_gb_scanned is set to 21, rather than 1\ntransactions_per_month = bitcoin_blockchain.query_to_pandas_safe(query, max_gb_scanned=24)\ntransactions_per_month","18632c0d":"# import plotting library\nimport matplotlib.pyplot as plt\n\n# plot monthly bitcoin transactions\nplt.plot(transactions_per_month.transactions)\nplt.title(\"Monthly Bitcoin Transcations\")","06d798ba":"# Your code goes here :)\nquery1=\"\"\"WITH time AS(SELECT transaction_id AS transactions,\n                                TIMESTAMP_MILLIS(timestamp) AS trans_time FROM `bigquery-public-data.bitcoin_blockchain.transactions`)\n                                SELECT COUNT(transactions) AS number_of_transactions, EXTRACT(DAYOFYEAR FROM trans_time) AS day FROM time WHERE EXTRACT(YEAR FROM trans_time)=2017 GROUP BY day\"\"\"\ntransactions_by_day_2017 = bitcoin_blockchain.query_to_pandas(query1)\ntransactions_by_day_2017\nplt.scatter(transactions_by_day_2017['day'],transactions_by_day_2017['number_of_transactions'])\n","2679ebd0":"bitcoin_blockchain.head('transactions')\nquery2=\"\"\"SELECT merkle_root,COUNT(transaction_id) AS no_of_transactions FROM `bigquery-public-data.bitcoin_blockchain.transactions` GROUP BY merkle_root\"\"\"\ntransactions_by_merkle_root=bitcoin_blockchain.query_to_pandas(query2)\ntransactions_by_merkle_root","a2e52805":"Since they're returned sorted, we can just plot the raw results to show us the number of Bitcoin transactions per month over the whole timespan of this dataset.","47afbb51":"# Scavenger hunt\n___\n\n> **Important note**: Today's dataset is bigger than the ones we've used previously, so your queries will be more than 1 Gigabyte. You can still run them by setting the \"max_gb_scanned\" argument in the `query_to_pandas_safe()` function to be large enough to run your query, or by using the `query_to_pandas()` function instead.\n\nNow it's your turn! Here are the questions I would like you to get the data to answer. Practice using at least one alias in each query. \n\n* How many Bitcoin transactions were made each day in 2017?\n    * You can use the \"timestamp\" column from the \"transactions\" table to answer this question. You can check the [notebook from Day 3](https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-day-3\/) for more information on timestamps.","ff2955ec":"<table>\n    <tr>\n        <td>\n        <center>\n        <font size=\"+1\">If you haven't used BigQuery datasets on Kaggle previously, check out the <a href = \"https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-handbook\/\">Scavenger Hunt Handbook<\/a> kernel to get started.<\/font>\n        <\/center>\n        <\/td>\n    <\/tr>\n<\/table>\n\n___ \n\n## Previous days:\n\n* [**Day 1:** SELECT, FROM & WHERE](https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-day-1\/)\n* [**Day 2:** GROUP BY, HAVING & COUNT()](https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-day-2\/)\n* [**Day 3:** ORDER BY & Dates](https:\/\/www.kaggle.com\/rtatman\/sql-scavenger-hunt-day-3\/)\n\n____\n","0ff2bf42":"## AS & WITH\n___\n\nSo far we've learned how to use these clauses in our queries: \n\n    SELECT ... \n    FROM ...\n    (WHERE) ...\n    GROUP BY ...\n    (HAVING) ...\n    ORDER BY\nBy this point, our queries are getting pretty long, which can make them hard to puzzle out exactly what we're asking for.\n\nWe've also started using functions like EXTRACT() to get information out of dates or aggregate functions like COUNT(). You may have noticed, however, that the columns that we use these functions are are returned with names like `_f0` and `_f1`, which aren't very helpful.\n\nDon't worry, though, we're going to learn how to get around both of these problems. Today, we're going to learn how to use AS and WITH to tidy up our queries and make them easier to read.\n\n### AS\n___\n\nFirst, let's talk about the AS clause. AS lets you refer to the the columns generated by your queries with different names, which is also know as \"aliasing\". (If you use Python a lot you might already have used `as` for aliasing if you've ever done something like `import pandas as pd` or `imports seaborn as sns`.)\n\nTo use AS in SQL, you just insert it right after the name of the column you select. Here's an example of a query **without** an AS clause:  \n\n        SELECT EXTRACT(DAY FROM column_with_timestamp), data_point_3\n        FROM `bigquery-public-data.imaginary_dataset.imaginary_table`\nAnd here's an example of the same query, but with AS.\n\n        SELECT EXTRACT(DAY FROM column_with_timestamp) AS day,\n                data_point_3 AS data\n        FROM `bigquery-public-data.imaginary_dataset.imaginary_table`\nBoth of these queries will return the exact same table, but in the second query the columns returned will be called `day` and `data`, rather than the default names of `_f0` and `data_point_3`.\n\n### WITH... AS\n____\n\nOn its own, AS is a convenient way to make your code easier to read and tidy up the data returned by your query. It's even more powerful when combined with WITH in what's called a \"common table expression\" or CTE.\n\n> **Common table expression**: A temporary table that you return within your query. You can then write queries against the new table you've created. CTE's only exist inside the query where you create them, though, so you can't reference them in later queries.\n\nCTE's are very helpful for breaking up your queries into readable chunks and make it easier to follow what's going on in your code. \n\nLet's look at how to use them. We're going to be the same small Pets table that we've been working with previously, but now it includes information on the ages of all the different animals. These are in a column called \"Years_old\":\n\n![](https:\/\/i.imgur.com\/01s9TwR.png)\n\nWe might want to ask questions about older animals in particular. One way that we could do this is to create a CTE that only contains information about older animals and then write get information about it. So we can create a CTE which only contains information about animals more than five years old like this:\n\n    # note that this query won't return anything!\n    WITH Seniors AS \n            (\n                SELECT ID, Name\n                FROM `bigquery-public-data.pet_records.pets`\n                WHERE Years_old > 5\n            )\nThis will create the following temporary table that we can then refer to in the rest of our query, which only has the ID and Name of the animals that are seniors:\n\n![](https:\/\/i.imgur.com\/LBippKL.png)\n\nIf we wanted additional information about this table, we can write a query under it. So this query will create the CTE shown above, and then return all the ID's from it (in this case just 2 and 4).\n\n    WITH Seniors AS \n            (\n                SELECT ID, Name\n                FROM `bigquery-public-data.pet_records.pets`\n                WHERE Years_old > 5\n            )\n    SELECT ID\n    FROM Seniors\nWe could do this without a CTE, but if this were the first part of a very long query, removing the CTE would make it much harder to follow.","965c08f0":"Pretty cool, huh? :)\n\nAs you can see, common table expressions let you shift a lot of your data cleaning into SQL. That's an especially good thing in the case of BigQuery because it lets you take advantage of BigQuery's parallelization, which means you'll get your results more quickly.","d6eec596":"Now we're going to write a query to get the number of transactions per month. One problem here is that this dataset uses timestamps rather than dates, and they're stored in this dataset as integers. We'll have to convert these into a format that BigQuery recognizes using TIMESTAMP_MILLIS(). We can do that using a CTE and then write a second part of the query against the new, temporary table we created. This has the advantage of breaking up our query into two, logical parts. \n\n* Convert the integer to a timestamp\n* Get information on the date of transactions from the timestamp\n\nYou can see the query I used to do this below.","4eedafa1":"* How many transactions are associated with each merkle root?\n    * You can use the \"merkle_root\" and \"transaction_id\" columns in the \"transactions\" table to answer this question. \n    * Note that the earlier version of this question asked \"How many *blocks* are associated with each merkle root?\", which would be one block for each root. Apologies for the confusion!","a24722c0":"## Example: How many Bitcoin transactions are made per month?\n____\n\nNow let's work through an example with a real dataset. Today, we're going to be working with a Bitcoin dataset (Bitcoin is a popular but volatile cryptocurrency). We're going to use a common table expression (CTE) to find out how many Bitcoin transactions were made per month for the entire timespan of this dataset.\n\nFirst, just like the last three days, we need to get our environment set up:"}}