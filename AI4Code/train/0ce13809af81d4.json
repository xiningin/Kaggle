{"cell_type":{"5a51fb73":"code","a9ea0886":"code","d6545fa9":"code","72664865":"code","2773bea8":"code","0cc5b8aa":"code","aaf89ceb":"code","586da90d":"code","1e8be869":"code","d9e6cdaa":"code","009a14d0":"code","1bfc5b8e":"code","50fb0d76":"code","aa7702e8":"code","432d7d57":"code","67872fb4":"markdown","d4fd07c7":"markdown","ac36865f":"markdown","1510780d":"markdown"},"source":{"5a51fb73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport gc\nimport random\n\nfrom IPython import display as ipd\nfrom tqdm import tqdm\nimport lightgbm as lgb\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom sklearn.metrics import accuracy_score, mean_squared_error, f1_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport imblearn\nprint(imblearn.__version__)\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport optuna \nfrom optuna.visualization.matplotlib import plot_optimization_history\nfrom optuna.visualization.matplotlib import plot_param_importances","a9ea0886":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        if col != 'time':\n            col_type = df[col].dtypes\n            if col_type in numerics:\n                c_min = df[col].min()\n                c_max = df[col].max()\n                if str(col_type)[:3] == 'int':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)  \n                else:\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        df[col] = df[col].astype(np.float16)\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ndef get_stats(df):\n    stats = pd.DataFrame(index=df.columns, columns=['na_count', 'n_unique', 'type', 'memory_usage'])\n    for col in df.columns:\n        stats.loc[col] = [df[col].isna().sum(), df[col].nunique(dropna=False), df[col].dtypes, df[col].memory_usage(deep=True, index=False) \/ 1024**2]\n    stats.loc['Overall'] = [stats['na_count'].sum(), stats['n_unique'].sum(), None, df.memory_usage(deep=True).sum() \/ 1024**2]\n    return stats\n\ndef seeding(SEED, use_tf=False):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    if use_tf:\n        tf.random.set_seed(SEED)\n    print('seeding done!!!')","d6545fa9":"RANDOM_SEED = 98765\nDEBUG = False\nTUNING = False\n\nseeding(RANDOM_SEED)\n\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\n\ntrain = train.sample(frac=1.0)\n\ntarget = train.Cover_Type\ntrain.drop(['Id','Cover_Type','Soil_Type7','Soil_Type15'], axis=1, inplace=True)\ntest.drop(['Id','Soil_Type7','Soil_Type15'], axis=1, inplace=True)\n\n# reduce memory footprint\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\ngc.collect()","72664865":"cont_cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1']\n\ncat_cols = ['Wilderness_Area1',\n       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n       'Soil_Type6', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']","2773bea8":"# map targets to match LGBM class reqs\ndef remap_target_classes(y):\n    for i in range(1,8):\n        y[y==i] = i-1\n    return y\n\nsampler = RandomOverSampler(sampling_strategy='auto', random_state=RANDOM_SEED)\nX_sample, y_sample = sampler.fit_resample(train, target)\n\ny_sample = remap_target_classes(y_sample)\n\ndel sampler\ngc.collect()\n\n# doublecheck class distribution\nif DEBUG:\n    y_sample.hist()","0cc5b8aa":"## to speed thing up - resample and reduce the size of train and target datasets\nDEBUG_SAMPLE = 500000\n\nif DEBUG:\n    temp = pd.concat( [X_sample, y_sample], axis=1 )\n    temp = temp[:DEBUG_SAMPLE]\n    y = temp.Cover_Type\n    X = temp.drop(['Cover_Type'], axis=1)\n    del temp\nelse:\n    ## full dataset takes too much time\n    y = y_sample[:4000000]\n    X = X_sample[:4000000]","aaf89ceb":"#scaler = StandardScaler()\n#X_scaled = scaler.fit_transform(X[cont_cols])\n#test_scaled = scaler.transform(test[cont_cols])\n\n#X = pd.DataFrame(X_scaled, index=X.index, columns=cont_cols)\n#test = pd.DataFrame(test_scaled, index=test.index, columns=cont_cols)","586da90d":"LEARNING_RATE = 0.01\nMAX_DEPTH = -1\nNUM_LEAVES = 31\nTOTAL_SPLITS = 3\nNUM_BOOST_ROUND = 500\nEARLY_STOPPING_ROUNDS = 20\nVERBOSE_EVAL = 100\n    \n\ndef objective(trial, X, y):\n    \n    param_grid = {\n        'verbosity': -1,\n        'num_class' : 7,\n        'boosting_type': 'gbdt', \n        'objective': 'multiclass', \n        'metric': ['multi_logloss'],\n        'n_estimators': trial.suggest_categorical('n_estimators', [2000]),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 200, 1000, step=100),\n        'max_bin': trial.suggest_int('max_bin', 200, 1000),\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 1.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 1.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 512),      \n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }    \n        \n    X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.25, random_state=RANDOM_SEED, shuffle=True)\n    eval_results = {}  # to record eval results for plotting\n    model = lgb.train(\n        param_grid, valid_names=[\"train\", \"valid\"], \n        train_set=lgb.Dataset(X_train, y_train ), \n        num_boost_round = NUM_BOOST_ROUND,\n        valid_sets = [lgb.Dataset(X_valid, y_valid)],\n        callbacks=[lgb.log_evaluation(VERBOSE_EVAL), \n                   lgb.early_stopping(EARLY_STOPPING_ROUNDS, False, True),\n                   lgb.record_evaluation(eval_result=eval_results)],\n    )\n    \n    yhat = np.argmax(model.predict(X_valid, workers=8), axis=1)\n    score = f1_score(yhat, y_valid, average=\"macro\")        \n    return score","1e8be869":"N_TRIALS = 100\n\nif TUNING:\n    study = optuna.create_study(direction='minimize')\n    objective_func = lambda trial: objective(trial, X, y)\n    study.optimize(objective_func, n_trials=N_TRIALS)  # number of iterations\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n    print(\"Best trial:\")\n    trial = study.best_trial\n    print(\"  Value: {}\".format(trial.value))\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value)) ","d9e6cdaa":"if TUNING:\n    plot_optimization_history(study);","009a14d0":"if TUNING:\n    plot_param_importances(study);","1bfc5b8e":"def run_train(X, y, run_params, splits, num_boost_round, verbose_eval, early_stopping_rounds ):\n    models = []\n    oof_predicted = []\n    eval_results = {}  # to record eval results for plotting\n    folds = StratifiedKFold(n_splits=splits, random_state=RANDOM_SEED)\n        \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n+1} started')\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        model = lgb.train(\n            run_params, valid_names=[\"train\", \"valid\"], \n            train_set=lgb.Dataset(X_train, y_train ), \n            num_boost_round = num_boost_round,\n            valid_sets = [lgb.Dataset(X_valid, y_valid)],\n            callbacks=[lgb.log_evaluation(verbose_eval), \n                       lgb.early_stopping(early_stopping_rounds, False, True),\n                       lgb.record_evaluation(eval_result=eval_results)],\n        )\n        yhat = model.predict(X_valid)\n        score = accuracy_score(np.argmax(yhat, axis=1), y_valid)\n        print(f\"OOF accuracy score: {score}\" )\n        models.append(model)\n    return models, oof_predicted, eval_results","50fb0d76":"## check if TUNING, best params could be used\n\nrun_params = {\n    'verbose': -1,\n    'num_class' : 7,\n    'boosting_type': 'gbdt', \n    'objective': 'multiclass', \n    'metric': ['multi_logloss'],\n    'n_estimators': 2000,\n    'learning_rate': 0.08418575294220242,\n    'num_leaves': 500,\n    'max_depth': 10,\n    'min_data_in_leaf': 300,\n    'max_bin': 267,\n    'lambda_l1': 0,\n    'lambda_l2': 45,       \n}\n\ntune_params = {\n    'verbose': -1,\n    'num_class' : 7,\n    'boosting_type': 'gbdt', \n    'objective': 'multiclass', \n    'metric': ['multi_logloss'],    \n    'n_estimators': 2000, \n    'learning_rate': 0.04122605595365002, \n    'max_depth': 8, \n    'min_data_in_leaf': 500, \n    'max_bin': 394, \n    'lambda_l1': 1.281829871734324e-07, \n    'lambda_l2': 5.228067696440779e-08, \n    'num_leaves': 195, \n    'feature_fraction': 0.7414105581913129, \n    'bagging_fraction': 0.790802808109213, \n    'bagging_freq': 7, \n    'min_child_samples': 75\n}\n\nif TUNING:\n    for key, value in study.best_trial.params.items():\n        run_params[key] = value\n    \n\nTOTAL_SPLITS = 5\nNUM_BOOST_ROUND = 2000\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE_EVAL = 200\n\nmodels, oof_predicted, eval_results = run_train(X, y, tune_params, TOTAL_SPLITS, NUM_BOOST_ROUND, VERBOSE_EVAL, EARLY_STOPPING_ROUNDS)","aa7702e8":"ax = lgb.plot_metric(eval_results, metric='multi_logloss')\nplt.show()","432d7d57":"predicted = []\nfor model in models:\n    predicted.append(np.argmax(model.predict(test), axis=1))\n    \ntest_pred = np.mean(predicted, axis=0).astype(int)       \n    \n# map targets back \ntest_pred[test_pred== 6] = 7\ntest_pred[test_pred== 5] = 6\ntest_pred[test_pred== 4] = 5\ntest_pred[test_pred== 3] = 4\ntest_pred[test_pred== 2] = 3\ntest_pred[test_pred== 1] = 2\ntest_pred[test_pred== 0] = 1\n\nsubmission['Cover_Type'] = test_pred\nsubmission.to_csv('submission.csv', index=False, float_format='%.6f')\nsubmission.head(20)","67872fb4":"## Tuning","d4fd07c7":"## Predict","ac36865f":"## Dealing with imbalanced targets","1510780d":"## Model and train"}}