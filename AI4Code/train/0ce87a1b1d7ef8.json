{"cell_type":{"611f4b90":"code","c0d8aa01":"code","c2473100":"code","ff9160ca":"code","a651210e":"code","0dca40a2":"code","262e7e18":"code","a27c6b9b":"code","16667614":"code","be0a5d09":"code","63096f6a":"code","818c049a":"code","19a5115f":"code","35d7d516":"code","d0987087":"code","dc150e16":"code","8772e189":"code","d18a87cd":"markdown","090064e4":"markdown","34e9b957":"markdown","21abf635":"markdown"},"source":{"611f4b90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c0d8aa01":"data = pd.read_csv('..\/input\/wisc_bc_data.csv')","c2473100":"data.head(10)","ff9160ca":"data.drop([\"id\"],axis=1,inplace=True)\n","a651210e":"data.head(10)","0dca40a2":"M = data[data.diagnosis=='M']\nB = data[data.diagnosis=='B']","262e7e18":"plt.scatter(M.smoothness_mean,M.compactness_mean,color='purple',label='Malignant',alpha=0.3)\nplt.scatter(B.smoothness_mean,B.compactness_mean,color='blue',label='Benign',alpha=0.3)\nplt.xlabel('Malignant')\nplt.ylabel('Benign')\nplt.legend()\nplt.show()","a27c6b9b":"data.diagnosis= [1 if each==\"M\" else 0 for each in data.diagnosis]\ny=data.diagnosis.values\nx_data = data.drop([\"diagnosis\"],axis=1)","16667614":"x = (x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))  # Normalization","be0a5d09":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)","63096f6a":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3) \nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint(\"{} nn score: {}\".format(3,knn.score(x_test,y_test)))","818c049a":"score_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k\")\nplt.ylabel(\"accuracy\")\nplt.show()","19a5115f":"from sklearn.svm import SVC\nsvm = SVC(random_state=1) \nsvm.fit(x_train,y_train)\n\nprint(\"primy accuracy of SVM algorithm : \",svm.score(x_test,y_test))","35d7d516":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#test\nprint(\"Accuracy of Naive-Bayes Algorithm\",nb.score(x_test,y_test))","d0987087":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=42)\n\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\n# Accuracy\nprint(\"Accuracy of Decision Tree Algorithm\",dt.score(x_test,y_test))","dc150e16":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\nprint(\"Accuracy of Random Forest Algorithm\",rf.score(x_test,y_test))","8772e189":"accuracy_list=[]\nfor i in range(1,11,1):\n    rf = RandomForestClassifier(n_estimators=i,random_state=1) \n    rf.fit(x_train,y_train)\n    accuracy_list.append(rf.score(x_test,y_test))\nplt.plot(range(1,11),accuracy_list)\nplt.xlabel(\"Number of estimators\")\nplt.ylabel(\"Accuracy\")\nplt.show()","d18a87cd":"For Naive-Bayes Classification","090064e4":"For Random Forest Classification","34e9b957":"For  EDA (Exploratory Data Analysis)","21abf635":"For KNN(K-Nearest Neighbor) Classification"}}