{"cell_type":{"fc014c03":"code","5e782667":"code","aae979ac":"code","2b07212d":"code","c9064577":"code","d63521f5":"code","534249ad":"code","62198236":"code","b68ff3f2":"code","518e470d":"code","3377316c":"code","6019e0c2":"markdown","95f2d6c9":"markdown","14682c65":"markdown","44163159":"markdown","f4458fa0":"markdown","a2dd4f3e":"markdown","00b21c9e":"markdown","e5af0485":"markdown"},"source":{"fc014c03":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e782667":"train_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/train.csv.zip')\ntest_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/test.csv.zip')","aae979ac":"train_data.describe()","2b07212d":"print(\"Colums: \", train_data.columns.values)\nprint(\"Shape: \", train_data.shape)","c9064577":"print(\"Missing values:\")\nprint(train_data.isnull().sum())","d63521f5":"def encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)\n    classes = list(le.classes_)                   \n    test_ids = test.id                 \n\n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    return train, labels, test, test_ids, classes\n\nX, y, test_data, test_ids, classes = encode(train_data, test_data)\ntrain_data.head(1)","534249ad":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)","62198236":"from sklearn.preprocessing import normalize\nX_train_norm=normalize(X_train)\nX_test_norm=normalize(X_test)","b68ff3f2":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nclf = LinearDiscriminantAnalysis()\n\nclf.fit(X_train_norm, y_train)\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test_norm, y_test) * 100, 2)) + \"%\")","518e470d":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(criterion='entropy',\n                             n_estimators=700,\n                             min_samples_split=5,\n                             min_samples_leaf=1,\n                             max_features = \"auto\",\n                             oob_score=True,\n                             random_state=0,\n                             n_jobs=-1)\n\nclf.fit(X_train_norm, y_train)\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test_norm, y_test) * 100, 2)) + \"%\")","3377316c":"clf = LinearDiscriminantAnalysis()\nclf.fit(X_train_norm, y_train)\nresult = clf.predict_proba(normalize(test_data))\ndf = pd.DataFrame(result, columns=classes)\ndf.insert(0, 'id', test_ids)\ndf.reset_index()\n\nprint(result.shape)\nfilename = 'Prediction.csv'\ndf.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","6019e0c2":"# Encode data","95f2d6c9":"# Analyze data\n\n**Describe data**\n\n* look at columns\n* check shape\n* check null columns","14682c65":"# RandomForestClassifier","44163159":"# LinearDiscriminantAnalysis","f4458fa0":"# Prepare data","a2dd4f3e":"# Load data\n","00b21c9e":"# Export","e5af0485":"**Cool, there are no missing values =)**"}}