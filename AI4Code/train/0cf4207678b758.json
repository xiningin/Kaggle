{"cell_type":{"8378504c":"code","7cfb8032":"code","71eda88c":"code","0f0927f7":"code","8f1a9328":"code","6486ad6a":"code","a7adf555":"code","305a40c8":"code","69688768":"code","632d9fe4":"code","4f41f165":"code","c0eae7a2":"code","199d21c6":"code","54cab7b5":"code","43049524":"code","d21be895":"code","5ce0a404":"code","b176c257":"code","074d16b7":"code","1d275a68":"code","0e1973e1":"code","5aa0af7d":"markdown","886f039e":"markdown","1ad40a3b":"markdown","ade8f3e3":"markdown","c4c42559":"markdown","1a3daa9b":"markdown"},"source":{"8378504c":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.datasets as sk\nimport plotly.express as px\nimport plotly.subplots as pxs\nimport skimage.io as ski\nimport plotly.graph_objects as pxg\nimport librosa as lr\nimport librosa.display as lrd\n\nplt.rcParams['figure.figsize'] = [9, 9] ","7cfb8032":"#\u041d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 iris\niris_data = pd.DataFrame(data=sk.load_iris().data, columns=sk.load_iris().feature_names)\niris_data.shape","71eda88c":"iris_data.head(15)","0f0927f7":"#\u041a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f iris\niris_data.corr().style.background_gradient(cmap=\"coolwarm\")","8f1a9328":"#\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e\u0431 iris\niris_data.describe()","6486ad6a":"#\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 iris\npx.bar(iris_data)","a7adf555":"# fashion mnist\nfashion_mnist_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')\nfashion_mnist_data.shape","305a40c8":"clothing_labels = {}\nfor el in set(fashion_mnist_data.label):\n    clothing_labels[el] = list(fashion_mnist_data.label).count(el)\nset(clothing_labels), clothing_labels\n\n","69688768":"fig = px.pie(values=clothing_labels.values(), names=clothing_labels.keys())\nfig.show()","632d9fe4":"#chinese mnist\nchinese_mnist_data = pd.read_csv(\"\/kaggle\/input\/chinese-mnist\/chinese_mnist.csv\")\nchinese_mnist_data.shape","4f41f165":"#\u0421\u0442\u043e\u043b\u0431\u0446\u044b \u0438\u0437 \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\nchinese_mnist_data.keys()","c0eae7a2":"def return_image(el):\n    return f\"input_{el[0]}_{el[1]}_{el[2]}.jpg\"\nchinese_mnist_data['image'] = chinese_mnist_data.apply(return_image, axis=1)","199d21c6":"px.imshow(ski.imread(f\"\/kaggle\/input\/chinese-mnist\/data\/data\/{chinese_mnist_data.image[0]}\"), color_continuous_scale='gray')","54cab7b5":"# \u0447\u0438\u0442\u0430\u0435\u043c \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 signmnist\nsign_mnist = pd.read_csv(\"\/kaggle\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv\")\nsign_mnist.shape","43049524":"sign_mnist.label.unique()","d21be895":"# \u0431\u0440\u0438\u0442\u0430\u043d\u0441\u043a\u0438\u0435 \u0431\u0443\u043a\u0432\u044b \u0438 \u0438\u0445 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\nsign_lab_unique = {}\nfor el in set(sign_mnist.label):\n    sign_lab_unique[el] = list(sign_mnist.label).count(el)\nsign_lab_unique","5ce0a404":"# \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445\npx.pie(values=sign_lab_unique.values(), names=sign_lab_unique.keys())","b176c257":"#\u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \"sound\"\nsound_set = pd.read_csv(\"\/kaggle\/input\/urbansound8k\/UrbanSound8K.csv\")\nsound_set.head(30)","074d16b7":"# \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\nsound_unique = {}\nfor el in set(sound_set.classID):\n    sound_unique[el] = list(sound_set.classID).count(el)\nsound_unique","1d275a68":"# \u043f\u0435\u0440\u0435\u0434\u043d\u0438\u0439 \u043f\u043b\u0430\u043d - 1, \u0444\u043e\u043d\u043e\u0432\u044b\u0435 \u0437\u0432\u0443\u043a\u0438 - 2 \nsound_for_back = {}\nfor el in set(sound_set.salience):\n    sound_for_back[el] = list(sound_set.salience).count(el)\nsound_for_back","0e1973e1":"#\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c sounds\npx.pie(values=sound_unique.values(), names=sound_unique.keys())","5aa0af7d":"\u0412\u0438\u043a\u043e\u043d\u0430\u0442\u0438 Data Understanding \u0430\u043d\u0430\u043b\u0456\u0437 \u0442\u0430\u043a\u0438\u0445 \u043d\u0430\u0431\u043e\u0440\u0456\u0432 \u0434\u0430\u043d\u0438\u0445:\n\nIris\nMNIST\nFashion MNIST\nchinese-mnist (https:\/\/www.kaggle.com\/gpreda\/chinese-mnist)\nsign-language-mnist (https:\/\/www.kaggle.com\/datamunge\/sign-language-mnist)\nUrban Sound (https:\/\/www.kaggle.com\/chrisfilo\/urbansound8k)\nUrban Sound Spectrograms (https:\/\/www.kaggle.com\/gokulrejith\/urban-sound-8k-images)\n\nData Understanding \u043f\u0435\u0440\u0435\u0434\u0431\u0430\u0447\u0430\u0454:\n\u0430\u043d\u0430\u043b\u0456\u0437 \u043e\u043f\u0438\u0441\u043e\u0432\u043e\u0457 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0438 (\u0441\u0435\u0440\u0435\u0434\u043d\u0454 \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f, \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0456\u044f, \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0435 \u0442\u0430 \u043c\u0456\u043d\u0456\u043c\u0430\u043b\u044c\u043d\u0435. \u041a\u0456\u043b\u044c\u043a\u0456\u0441\u0442\u044c \u0441\u043f\u043e\u0441\u0442\u0435\u0440\u0435\u0436\u0435\u043d\u044c \u0443 \u043a\u043b\u0430\u0441\u0430\u0445)\n\u0432\u0456\u0437\u0443\u0430\u043b\u0456\u0437\u0430\u0446\u0456\u044f \u0434\u0430\u043d\u0438\u0445 (\u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442\u043e\u0432\u0443\u0432\u0430\u0442\u0438 \u0431\u0456\u0431\u043b\u0456\u043e\u0442\u0435\u043a\u0438 PIL, OpenCV, scikit-image, librosa, seaborn, plotly)","886f039e":"conclusion (urban sound) this dataset contains .wav files of different sounds. you can represent sound files as array of numbers. also this dataset contains foreground and background sounds as well. dataset has 9 different types of audio fragments (child play, dog bark, air cond, etc)","1ad40a3b":"conclusion (mnist fashion) mnist fashion dataset contains 10000 photos of different types of clothes. there's 10 types of clothes (T-shirt\/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot). this dataset can be used for machine learning for clothes classification","ade8f3e3":"conclusion (sign mnist) sign mnist dataset can be used for machine learning algorithm for understanding sign language. this dataset contains 25 letters in 28x28 format.","c4c42559":"conclusion (chinese mnist) chinese mnist dataset contains images with chinese characters. this dataset can be used to train a learning algorithm to classify chinese letters and translate chinese text (use in translator)","1a3daa9b":"conclusion (iris): iris dataset is a dataset about Iris plant. This dataset contains 4 columns (outer leaf height, outer leaf width, inner leaf height, inner leaf width), and 150 rows (150 plants). This dataset can be used to generate more information about Iris plants"}}