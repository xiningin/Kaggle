{"cell_type":{"a9587afc":"code","c903c31b":"code","84d0162c":"code","cc278a40":"code","972436f1":"code","dc59983c":"code","bb53ff9d":"code","c6527083":"code","9ab1600d":"code","1ee9e705":"code","65af5e4c":"code","7d641b06":"code","8302830b":"code","7a687f8e":"code","3059f723":"code","c0288113":"code","0c4cab28":"code","3870059e":"code","e5cf4c33":"code","f0f2d463":"code","1ffec291":"code","a4f9a761":"code","e61d5df6":"code","69da1360":"code","8b3a3711":"code","b976a4f8":"code","336ab1f6":"code","13bca791":"code","22ec1f98":"code","a8daf927":"code","4e8bd69d":"code","23ae6bee":"code","0a5cde31":"code","3f5910d5":"code","1429f607":"code","fedaeee7":"code","988301a3":"code","19809a75":"code","c5d584d7":"code","4f857de5":"code","ee6df33f":"code","c5bd25f1":"code","ae77fa53":"code","48f497a4":"code","5c4d7522":"code","62ea07c6":"code","79e77d81":"code","981d68a4":"code","7f4599cb":"code","5c360321":"code","441b4227":"code","b7ad2952":"code","75763bfc":"code","1fbfbf02":"code","83309384":"code","ec2eb5b8":"code","6dfef8d6":"code","e6ec1953":"code","4aab68c7":"code","9c17e18a":"code","6f079039":"code","d228ee1b":"code","7948568e":"code","03053126":"code","f50492ee":"code","2871f165":"markdown","9ad5bce0":"markdown","54dbed70":"markdown","da567161":"markdown","aa2f6b1a":"markdown","8cb4d851":"markdown","effbaa86":"markdown","24d258a2":"markdown","990e1528":"markdown","99361f99":"markdown","2f59ed6e":"markdown","043bd82b":"markdown","d5b1c0f4":"markdown"},"source":{"a9587afc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c903c31b":"df=pd.read_csv(\"..\/input\/donorsprediction\/Raw_Data_for_train_test.csv\")","84d0162c":"df","cc278a40":"df.head()","972436f1":"df.columns","dc59983c":"df.describe()","bb53ff9d":"df.isnull().sum()","c6527083":"df.columns[df.isnull().any()]","9ab1600d":"# create a list of our conditions\nconditions = [\n    (df['TARGET_D'] >= 50),\n    (df['TARGET_D'] >= 20) & (df['TARGET_D'] < 50),\n    (df['TARGET_D'] >= 13) & (df['TARGET_D'] < 20),\n    (df['TARGET_D'] >= 10) & (df['TARGET_D'] < 13),\n    (df['TARGET_D'] < 10)\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['A', 'B', 'C', 'D','E']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndf['DONATION_TYPE'] = np.select(conditions, values)\n\n# display updated DataFrame\ndf.head()","1ee9e705":"df","65af5e4c":"df.isnull().sum()","7d641b06":"df['TARGET_D']=df['TARGET_D'].fillna(df['TARGET_D'].mean())","8302830b":"# create a list of our conditions\nconditions = [\n    (df['TARGET_D'] >= 50),\n    (df['TARGET_D'] >= 20) & (df['TARGET_D'] < 50),\n    (df['TARGET_D'] >= 13) & (df['TARGET_D'] < 20),\n    (df['TARGET_D'] >= 10) & (df['TARGET_D'] < 13),\n    (df['TARGET_D'] < 10)\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['A', 'B', 'C', 'D','E']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndf['DONATION_TYPE'] = np.select(conditions, values)\n\n# display updated DataFrame\ndf.head()","7a687f8e":"df.isnull().sum()","3059f723":"#target d contains a lot of null values ,so delete this column\ndf=df.drop(['TARGET_D'],axis=1)","c0288113":"df=df.drop(['TARGET_B'],axis=1)","0c4cab28":"df['DONOR_AGE']=df['DONOR_AGE'].fillna(df['DONOR_AGE'].mean())","3870059e":"df['DONOR_AGE']=df['DONOR_AGE'].astype('int64')","e5cf4c33":"df['INCOME_GROUP']=df['INCOME_GROUP'].fillna(df['INCOME_GROUP'].mode()[0])","f0f2d463":"df['INCOME_GROUP']=df['INCOME_GROUP'].astype('int64')","1ffec291":"df['WEALTH_RATING']=df['WEALTH_RATING'].fillna(df['WEALTH_RATING'].mode()[0])","a4f9a761":"df['WEALTH_RATING']=df['WEALTH_RATING'].astype('int64')","e61d5df6":"df=df.dropna()","69da1360":"df.columns[df.isnull().any()]","8b3a3711":"df","b976a4f8":"len(df.DONATION_TYPE.unique())","336ab1f6":"df['DONATION_TYPE'].value_counts()","13bca791":"from sklearn.preprocessing import LabelEncoder\n\nlabeled_df = df.copy()\n\nlabel_encoder = LabelEncoder().fit (df['DONATION_TYPE'])\n\nlabeled_species = label_encoder.transform(df['DONATION_TYPE'])","22ec1f98":"classes = list(label_encoder.classes_)  \nclasses","a8daf927":"labeled_df","4e8bd69d":"labeled_df=labeled_df.drop('URBANICITY',axis=1)\nlabeled_df=labeled_df.drop('SES', axis=1)\nlabeled_df=labeled_df.drop('HOME_OWNER', axis=1)\nlabeled_df=labeled_df.drop('DONOR_GENDER', axis=1)\nlabeled_df=labeled_df.drop('OVERLAY_SOURCE', axis=1)\nlabeled_df=labeled_df.drop('CLUSTER_CODE', axis=1)\nlabeled_df=labeled_df.drop('RECENCY_STATUS_96NK', axis=1)","23ae6bee":"labeled_df","0a5cde31":"X=labeled_df.drop('DONATION_TYPE', axis=1)\ny=labeled_df.DONATION_TYPE","3f5910d5":"X","1429f607":"y","fedaeee7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)","988301a3":"X_train","19809a75":"X_train.dtypes","c5d584d7":"''''parameters = {\n    'n_estimators': list(range(100, 1001, 100)), \n    'learning_rate': [l \/ 100 for l in range(5, 50, 10)], \n    'max_depth': list(range(6, 20, 10))\n}\nparameters'''","4f857de5":"para = list(range(100, 1001, 100))\nprint(para)","ee6df33f":"''''from sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import log_loss\n\ngsearch = GridSearchCV(estimator=XGBClassifier(random_state=1,objective='multi:softprob'),\n                       param_grid = parameters, \n                       scoring='neg_log_loss',\n                       n_jobs=4,cv=5, verbose=1)'''","c5bd25f1":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\nresults = {}\nfor n in para:\n    print('para=', n)\n    model = RandomForestClassifier(n_estimators=n)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    accu = accuracy_score(y_true=y_test, y_pred=preds)\n    f1 = f1_score(y_true=y_test, y_pred=preds, average='micro')\n    print(classification_report(y_true=y_test, y_pred=preds))\n    print('--------------------------')\n    results[n] = f1","ae77fa53":"import matplotlib.pylab as plt\n# sorted by key, return a list of tuples\nlists = sorted(results.items()) \np, a = zip(*lists) # unpack a list of pairs into two tuples\nplt.plot(p, a)\nplt.show()","48f497a4":"best_para = max(results, key=results.get)\nprint('best para', best_para)\nprint('value', results[best_para])","5c4d7522":"test_df = pd.read_csv('..\/input\/donorsprediction\/Predict_donor.csv')\ntest_df.head()","62ea07c6":"test_df.columns[test_df.isnull().any()]","79e77d81":"test_df['DONOR_AGE']=test_df['DONOR_AGE'].fillna(test_df['DONOR_AGE'].mean())","981d68a4":"test_df['DONOR_AGE']=test_df['DONOR_AGE'].astype('int64')","7f4599cb":"test_df['INCOME_GROUP']=test_df['INCOME_GROUP'].fillna(test_df['INCOME_GROUP'].mode()[0])","5c360321":"test_df['INCOME_GROUP']=test_df['INCOME_GROUP'].astype('int64')","441b4227":"test_df['WEALTH_RATING']=test_df['WEALTH_RATING'].fillna(test_df['WEALTH_RATING'].mode()[0])","b7ad2952":"test_df['WEALTH_RATING']=test_df['WEALTH_RATING'].astype('int64')","75763bfc":"test_df=test_df.dropna()","1fbfbf02":"test_df.columns[test_df.isnull().any()]","83309384":"test_df.dtypes","ec2eb5b8":"test_df","6dfef8d6":"test_df=test_df.drop('URBANICITY',axis=1)\ntest_df=test_df.drop('SES', axis=1)\ntest_df=test_df.drop('HOME_OWNER', axis=1)\ntest_df=test_df.drop('DONOR_GENDER', axis=1)\ntest_df=test_df.drop('OVERLAY_SOURCE', axis=1)\ntest_df=test_df.drop('CLUSTER_CODE', axis=1)\ntest_df=test_df.drop('RECENCY_STATUS_96NK', axis=1)","e6ec1953":"test_df.dtypes","4aab68c7":"test_df.columns","9c17e18a":"test_df","6f079039":"test_df.shape","d228ee1b":"X_train.shape","7948568e":"X_train.dtypes","03053126":"Target = model.predict(test_df)\nTarget","f50492ee":"PREDICTED_df = pd.DataFrame()\nPREDICTED_df['DONATION_TYPE'] = Target\nPREDICTED_df['CONTROL_NUMBER'] = test_df['CONTROL_NUMBER']\nPREDICTED_df.head()","2871f165":"# Define X and y","9ad5bce0":"# Random Forest classifier","54dbed70":"# Build model","da567161":"# Missing values","aa2f6b1a":"#  Hypter-parameter tuning","8cb4d851":"Spilt data into train and test","effbaa86":"# Read Data","24d258a2":"drop  categorical col.","990e1528":"# Predict the test data","99361f99":"# Find missing values","2f59ed6e":"create a new column called DONATION_TYPE","043bd82b":"# make label encoder to categorical coulmns","d5b1c0f4":"# Define GridSearchCV for hypter-parameter tuning"}}