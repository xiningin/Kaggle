{"cell_type":{"164780e1":"code","35bb3edc":"code","bbb5c8a3":"code","79265455":"code","721603c8":"code","503caf2f":"code","64202c16":"code","6b5067f7":"code","db809dc4":"code","c3c04ccc":"code","c8056caa":"code","f7c65b39":"code","bea83d6f":"code","9941d69d":"code","0083769f":"code","9f16f8ee":"code","07e6945d":"code","5f152e59":"code","54d45129":"code","dad153d1":"code","ad008db7":"markdown","45ddc15b":"markdown","861b0e3f":"markdown","7d270f1b":"markdown","3868ea4e":"markdown","837f9236":"markdown","8774f1f8":"markdown","a4e360de":"markdown","73042864":"markdown"},"source":{"164780e1":"import shutil\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import resample\nimport numpy as np \nimport pandas as pd \nimport os \nfrom os import listdir\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom keras.utils import np_utils\nfrom sklearn.metrics import accuracy_score\n%matplotlib inline\n#************************************************","35bb3edc":"os.mkdir('augmented')\nos.mkdir('\/kaggle\/working\/augmented\/benign')\nos.mkdir('\/kaggle\/working\/augmented\/malignant')\n","bbb5c8a3":"def getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n                \n    return allFiles\n\n","79265455":"files_benign=getListOfFiles('..\/input\/breakhis\/BreaKHis_v1\/BreaKHis_v1\/histology_slides\/breast\/benign')\nfor f in files_benign:\n    if f.endswith('.png'):\n        \n        shutil.copy(f,'augmented\/benign')\nfiles_malignant=getListOfFiles('..\/input\/breakhis\/BreaKHis_v1\/BreaKHis_v1\/histology_slides\/breast\/malignant')\nfor f in files_malignant:\n    if f.endswith('.png'):\n        \n        shutil.copy(f,'augmented\/malignant')","721603c8":"benign=getListOfFiles('\/kaggle\/working\/augmented\/benign')\nmalignent=getListOfFiles('\/kaggle\/working\/augmented\/malignant')\n","503caf2f":"image.load_img(benign[0], target_size=(120,120,1), grayscale=False)\n    ","64202c16":"\nimage.load_img(malignent[0], target_size=(120,120,1), grayscale=False)\n    ","6b5067f7":"len(benign)+len(malignent)","db809dc4":"data = pd.DataFrame(index=np.arange(0, len(benign)+len(malignent)), columns=[\"image\", \"target\"])\nk=0\nfor c in [0,1]:\n        if c==1:\n            for m in range(len(benign)):\n                data.iloc[k][\"image\"] = benign[m]\n                data.iloc[k][\"target\"] = 0\n                k += 1\n        else:\n            for m in range(len(malignent)):\n                data.iloc[k][\"image\"] = malignent[m]\n                data.iloc[k][\"target\"] = 1\n                k += 1\n                \n","c3c04ccc":"data.head()","c8056caa":"data.shape","f7c65b39":"count=data[\"target\"].value_counts() \ncount\n","bea83d6f":"import seaborn as sns\n'''\nVisualize the target variable\n'''\n\ntarget=sns.countplot(data['target'])\ntarget.set_xticklabels(['0',' 1' ])\nplt.show()","9941d69d":"# downsample the malignant targets\nmal_downsampled = resample(data[data['target']==1],n_samples=data[data['target']==0].shape[0], random_state=42)\n# combine minority and downsampled majority\ndownsampled = pd.concat([data[data['target']==0], mal_downsampled])\n# check new class counts\ndownsampled['target'].value_counts()","0083769f":"downsampled.head()","9f16f8ee":"downsampled.shape","07e6945d":"train_image = []\ny = []\n\nfor i in tqdm(range(downsampled.shape[0])):\n    img = image.load_img(downsampled['image'].iloc[i], target_size=(28,28,1), grayscale=False)\n    img = image.img_to_array(img)\n    img = img\/255\n    train_image.append(img)\n\n        \nX = np.array(train_image)\ny = downsampled.iloc[:,-1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state=42, test_size=0.2 , shuffle=True)\n\nY_train = np_utils.to_categorical(y_train, 2)\nY_test = np_utils.to_categorical(y_test, 2)\nY_val = np_utils.to_categorical(y_val, 2)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)","5f152e59":"model = Sequential()\n#convlouton layer with the number of filters, filter size, strides steps, padding or no, activation type and the input shape.\nmodel.add(Conv2D(30, kernel_size = (3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,3)))\n#pooling layer to reduce the volume of input image after convolution,\nmodel.add(MaxPool2D(pool_size=(1,1)))\n#flatten layer to flatten the output\nmodel.add(Flatten())   # flatten output of conv\nmodel.add(Dense(150, activation='relu'))  # hidden layer of 150 neuron\nmodel.add(Dense(2, activation='softmax'))  # output layer\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n\nhistory = model.fit(X_train, Y_train, batch_size=10, epochs = 5, validation_data=(X_test, Y_test))","54d45129":"history_df = pd.DataFrame(history.history)\nhistory_df.plot()","dad153d1":"y_pred = model.predict_classes(X_val)\nacc_test = 0\n\nfor i in range(X_val.shape[0]):\n    if(y_pred[i] == y_val[i]):\n        acc_test= acc_test+1\nprint(\"Accuracy test : \"  , acc_test\/X_val.shape[0]*100)","ad008db7":"# Check if there is Unbalanced data ","45ddc15b":"# Evaluate Model","861b0e3f":"# begnin slide","7d270f1b":"# Classify","3868ea4e":"# Fit","837f9236":"# malignant slide","8774f1f8":"# Solve unbalanced data ","a4e360de":"# Liberaries","73042864":"# Read Data"}}