{"cell_type":{"acc88e61":"code","ba610d13":"code","b1e4f79f":"code","c705e4bb":"code","ad5d04f3":"code","825dfbb9":"code","ce83156c":"code","bc764567":"code","fd6b0489":"code","fc4ef5e9":"markdown","25b4218a":"markdown","64c963ba":"markdown","fc51b831":"markdown"},"source":{"acc88e61":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\n# Import H2O AutoML\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init(max_mem_size='16G')","ba610d13":"# Read training set\ndata_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_train.head()\n\n# Read evaluation set\ndata_eval = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata_eval.head()\n","b1e4f79f":"def feature_engineering(data):\n\n    # Column Pclass\n    dummies = pd.get_dummies(data['Pclass'], prefix='Pclass')\n    data = pd.concat([data, dummies], axis=1)\n    \n    # Column Name\n    data['Name_Mr'] = data['Name'].str.contains('Mr.').astype(int)\n    data['Name_Mrs'] = data['Name'].str.contains('Mrs.').astype(int)\n    data['Name_Miss'] = data['Name'].str.contains('Miss.').astype(int)\n    data['Name_Master'] = data['Name'].str.contains('Master.').astype(int)\n    data['Name_Doctor'] = data['Name'].str.contains('Dr.').astype(int)\n    data['Name_Ms'] = data['Name'].str.contains('Ms.').astype(int)\n    data['Name_Rev'] = data['Name'].str.contains('Rev.').astype(int)\n    data['Name_Major'] = data['Name'].str.contains('Major.').astype(int)\n    data['Name_OtherTitle']=((data.Name_Mr==0)&(data.Name_Mrs==0)&(data.Name_Miss==0)&(data.Name_Master==0)&(data.Name_Doctor==0)&(data.Name_Ms==0)&(data.Name_Rev==0)&(data.Name_Major==0)).astype(int)\n    \n    # Column Sex\n    data['Sex'] = data['Sex'].map({'male':0, 'female':1})\n    \n    # Column Ticket\n    data['Ticket_PC'] = data['Ticket'].fillna('').str.contains('PC').astype(int)\n    data['Ticket_CA'] = data['Ticket'].fillna('').str.contains('CA').astype(int)\n    data['Ticket_A\/5'] = data['Ticket'].fillna('').str.contains('A\/5').astype(int)\n    data['Ticket_A\/4'] = data['Ticket'].fillna('').str.contains('A\/4').astype(int)\n    data['Ticket_PP'] = data['Ticket'].fillna('').str.contains('PP').astype(int)\n    data['Ticket_SOTON'] = data['Ticket'].fillna('').str.contains('SOTON').astype(int)\n    data['Ticket_STON'] = data['Ticket'].fillna('').str.contains('STON').astype(int)\n    data['Ticket_SC\/Paris'] = data['Ticket'].fillna('').str.contains('SC\/PARIS').astype(int)\n    data['Ticket_W\/C'] = data['Ticket'].fillna('').str.contains('W\/C').astype(int)\n    data['Ticket_FCC'] = data['Ticket'].fillna('').str.contains('FCC').astype(int)\n    data['Ticket_LINE'] = data['Ticket'].fillna('').str.contains('LINE').astype(int)\n    data['Ticket_SOC'] = data['Ticket'].fillna('').str.contains('SOC').astype(int)\n    data['Ticket_SC'] = data['Ticket'].fillna('').str.contains('SC').astype(int)\n    data['Ticket_C'] = data['Ticket'].fillna('').str.contains('C ').astype(int)\n    data['Ticket_Numeric'] = data['Ticket'].str.isnumeric().astype(int)\n       \n    # Column Cabin\n    data['Cabin_A'] = data.Cabin.fillna('').str.contains('A').astype(int)\n    data['Cabin_B'] = data.Cabin.fillna('').str.contains('B').astype(int)\n    data['Cabin_C'] = data.Cabin.fillna('').str.contains('C').astype(int)\n    data['Cabin_D'] = data.Cabin.fillna('').str.contains('D').astype(int)\n    data['Cabin_E'] = data.Cabin.fillna('').str.contains('E').astype(int)\n    data['Cabin_F'] = data.Cabin.fillna('').str.contains('F').astype(int)\n    data['Cabin_G'] = data.Cabin.fillna('').str.contains('G').astype(int)\n    \n    # Column Embarked\n    dummies = pd.get_dummies(data['Embarked'], prefix='Embarked')\n    data = pd.concat([data, dummies], axis=1)\n    \n    # Drop columns\n    data.drop(columns=['PassengerId','Name', 'Ticket', 'Cabin', 'Embarked', 'Pclass'], inplace=True)\n    \n    return data","c705e4bb":"# Cleanse train set\ndata_train_cleansed = feature_engineering(data_train.copy())","ad5d04f3":"# Train AutoML Model\nH2O_train = h2o.H2OFrame(data_train_cleansed)\nx =H2O_train.columns\ny ='Survived'\nx.remove(y)\n\nH2O_train[y] = H2O_train[y].asfactor()\n\naml = H2OAutoML(max_runtime_secs = 80000,nfolds=10)\naml.train(x=x, y=y, training_frame=H2O_train)\n\n# Print AutoML leaderboard\naml.leaderboard","825dfbb9":"#                max_runtime_secs=36000,\u6700\u5927\u8fd0\u884c\u65f6\u95f4\n#                max_runtime_secs_per_model=3600,\u6700\u5927\u5355\u6a21\u578b\u8fd0\u884c\u65f6\u95f4\n#seed\uff0c\u968f\u4fbf\u9009\uff0c\u968f\u673a\u79cd\u5b50\n#                nfolds=10, \u4ea4\u53c9\u9a8c\u8bc1\uff0c\u8d8a\u5927\u4ea4\u53c9\u9a8c\u8bc1\u5ea6\u8d8a\u9ad8\uff0c\u7ed3\u679c\u8d8a\u597d\uff0c\u8d8a\u8017\u65f6\uff0c\u9ed8\u8ba4\u4e3a5\n#sort_metric: Specifies the metric used to sort the Leaderboard by at the end of an AutoML run. Available options include:\n#AUTO: This defaults to AUC for binary classification, mean_per_class_error for multinomial classification, and deviance for regression.\n#For binomial classification choose between AUC, \"logloss\", \"mean_per_class_error\", \"RMSE\", \"MSE\". For multinomial classification choose between \"mean_per_class_error\", \"logloss\", \"RMSE\", \"MSE\". For regression choose between \"deviance\", \"RMSE\", \"MSE\", \"MAE\", \"RMLSE\".\n#max_models=333,\u6700\u5927\u6a21\u578b\u6570\u76ee\uff1b\u9ed8\u8ba4\u4e3a\u65e0\u7a77\u5927\n#                include_algos=['XGBoost'], \u6b64\u9009\u9879\u5141\u8bb8\u60a8\u6307\u5b9a\u5728\u6a21\u578b\u6784\u5efa\u9636\u6bb5\u8981\u5305\u62ec\u5728AutoML\u8fd0\u884c\u4e2d\u7684\u7b97\u6cd5\u5217\u8868\u3002\u8be5\u9009\u9879\u9ed8\u8ba4\u4e3aNone \/ Null\uff0c\u8fd9\u610f\u5473\u7740\u5c06\u5305\u62ec\u6240\u6709\u7b97\u6cd5\uff0c\u9664\u975e\u5728\u8be5exclude_algos\u9009\u9879\u4e2d\u6307\u5b9a\u4e86\u4efb\u4f55\u7b97\u6cd5\u3002\n#                verbosity='info'\u4f20\u9012\u4f55\u79cd\u4fe1\u606f\uff0cinfo\u4e3a\u5168\u90e8","ce83156c":"# model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n# model = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])","bc764567":"# Get train data accuracy\npred = aml.predict(h2o.H2OFrame(data_train_cleansed))\npred = pred.as_data_frame()['predict'].tolist()\n\naccuracy = sum(1 for x,y in zip(np.round(pred),data_train_cleansed.Survived) if x == y) \/ len(data_train_cleansed.Survived)\nprint('accuracy:',accuracy)","fd6b0489":"# Transform test set\ndata_eval_cleansed = feature_engineering(data_eval.copy())\n\nX_eval = data_eval_cleansed\n\ny_eval_pred = aml.predict(h2o.H2OFrame(X_eval))\ny_eval_pred = y_eval_pred.as_data_frame()['predict'].tolist()\n\noutput = pd.DataFrame({'PassengerId': data_eval.PassengerId, 'Survived': y_eval_pred})\noutput.to_csv('my_submission_202002015.csv', index=False)\nprint(\"Your submission was successfully saved!\")","fc4ef5e9":"### 3. Model Training","25b4218a":"### 2. Feature Engineering","64c963ba":"### 4. Predict Evalutaion Set","fc51b831":"### 1. Load Data"}}