{"cell_type":{"fae30a4f":"code","46558433":"code","56d54b59":"code","7e9660e2":"code","b1100452":"code","8e1663cc":"code","7940cc08":"markdown","fbb038c3":"markdown"},"source":{"fae30a4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46558433":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\npd.set_option('display.max_columns', 100)\n\n# Read the data\nX_train_full = pd.read_csv('..\/input\/30-days-of-ml\/train.csv', index_col='id')\nX_test_full = pd.read_csv('..\/input\/30-days-of-ml\/test.csv', index_col='id')\n\n# X_train_full = pd.read_csv('..\/input\/30-days-of-ml\/train.csv', index_col='id', nrows=100)\n# X_test_full = pd.read_csv('..\/input\/30-days-of-ml\/test.csv', index_col='id', nrows=100)\n\n# print(X_full.shape) # (300000, 25)\n# print(X_full.head)\n\n# Remove rows with missing target, separate target from predictors\n# X_full.dropna(axis=0, subset=['target'], inplace=True) # Commeting this line as there is no missing value for target\n# print(X_full.shape) # (300000, 25)\n\ny = X_train_full.target\nX_train_full.drop(['target'], axis=1, inplace=True)\n\n# print(X_full.shape) # (300000, 24)\n# print(y.shape) # (300000,)\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y, train_size=0.8, test_size=0.2, random_state=0)","56d54b59":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n# function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","7e9660e2":"from sklearn.preprocessing import OneHotEncoder\n\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n\n# print(object_cols) # ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_test_full[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\nOH_cols_test.index = X_test_full.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\nnum_X_test = X_test_full.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n\n# print(OH_X_train.head)","b1100452":"# print(\"MAE (One-Hot Encoding):\") \n# print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","8e1663cc":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(OH_X_train, y_train)\npreds = model.predict(OH_X_test)\n\n# Save test predictions to file\noutput = pd.DataFrame({'id': X_test_full.index,\n                       'target': preds})\noutput.to_csv('30ML-submission.csv', index=False)\n","7940cc08":"# Upvote and follow me if you found it useful","fbb038c3":"# 30 Day Of ML - Using one hot encoding"}}