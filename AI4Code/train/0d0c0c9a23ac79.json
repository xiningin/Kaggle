{"cell_type":{"8a2c9a34":"code","1cc2789d":"code","b31c169b":"code","f4592625":"code","9a8f02ed":"code","d5b1d0a4":"code","48a86653":"code","1d988a0b":"code","4bd3d56b":"code","06eb11b8":"code","d51e4837":"code","9d31ea2b":"code","7bb37d0a":"code","d2e8d4ec":"code","30301b38":"code","3c3c9ce2":"code","f69f9659":"code","b04744b2":"code","28c2c0cc":"markdown","09126906":"markdown","c6d4f34e":"markdown","5a69fc63":"markdown","664a8e4a":"markdown","dbc70f8d":"markdown","31b8f1f3":"markdown"},"source":{"8a2c9a34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nimport pylab as pl\nfrom PIL import Image\nimport cv2\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1cc2789d":"img = \"..\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/withMaskDataset\/DNU016CWPZOGFRK5YA3X.jpg\"\n_ = plt.figure(figsize = (15,20))\n_ = plt.axis('off')\n_ = plt.imshow(mpimg.imread(img))","b31c169b":"# Reading color image\nmask = cv2.imread('\/kaggle\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/withMaskDataset\/DNU016CWPZOGFRK5YA3X.jpg')\nplt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\nplt.show()","f4592625":"print('The shape of image is ', mask.shape)","9a8f02ed":"mask_r  = cv2.imread('\/kaggle\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/withMaskDataset\/DNU016CWPZOGFRK5YA3X.jpg')\nmask_r[:,:,1:2] = 0\nplt.imshow(mask_r)\nplt.show()","d5b1d0a4":"mask_g  = cv2.imread('\/kaggle\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/withMaskDataset\/DNU016CWPZOGFRK5YA3X.jpg')\nmask_g[:,:,(0,2)] = 0\nplt.imshow(mask_g)\nplt.show()","48a86653":"mask_b  = cv2.imread('\/kaggle\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/withMaskDataset\/DNU016CWPZOGFRK5YA3X.jpg')\nmask_b[:,:,0:1] = 0\nplt.imshow(mask_b)\nplt.show()","1d988a0b":"from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\nfrom keras.models import Sequential\n\nimport glob, os, random","4bd3d56b":"#remove one withMaskDataset from path (file) to avoid an empty list\n\nbase_path = '..\/input\/medical-face-mask-detection-dataset\/withMaskDataset\/'\n\nimg_list = glob.glob(os.path.join(base_path, '*\/*.jpg'))\n\nprint(len(img_list))","06eb11b8":"for i, img_path in enumerate(random.sample(img_list, 6)):\n    img = load_img(img_path)\n    img = img_to_array(img, dtype=np.uint8)\n\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img.squeeze())","d51e4837":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.1\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    seed=0\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    seed=0\n)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nprint(labels)","9d31ea2b":"model = Sequential([\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n    MaxPooling2D(pool_size=2),\n\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n\n    Flatten(),\n\n    Dense(64, activation='relu'),\n\n    Dense(6, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","7bb37d0a":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","d2e8d4ec":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","30301b38":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","3c3c9ce2":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","f69f9659":"test_x, test_y = validation_generator.__getitem__(1)\n\npreds = model.predict(test_x)\n\nplt.figure(figsize=(16, 16))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n   # plt.title('pred:%s \/ truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n    plt.imshow(test_x[i])","b04744b2":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thank you Brad Lee @kairess for the script')","28c2c0cc":"#Take a Shot??","09126906":"#Another Shot??","c6d4f34e":"#I commented plt.title above since I got Key error: 2 or 1. I hope it will work. Inside I had images \n\n#not classified (preds). I think I got that error since the images belong to only 1 class as I wrote\n\n#six snippets above. I'll find out if it has worked only when all that shots have finished to run.","5a69fc63":"#Code by Brad Lee https:\/\/www.kaggle.com\/kairess\/garbage-classification","664a8e4a":"#Why more shots? The author didn't explain it.","dbc70f8d":"#Plotting the RGB channels of the image","31b8f1f3":"#The original code (above) has 6 classes (garbage: glass, metal, paper, plastic, trash). Mine found \n\n#only 1(One) class and that will prevent me to perform the last snippet."}}