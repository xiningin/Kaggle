{"cell_type":{"8a8f33c6":"code","39b6d204":"code","218b03d1":"code","c0cd1460":"code","2e5da81b":"code","810cf91c":"code","309324d4":"code","a474659b":"code","e5728494":"code","83937a5d":"code","f4f1add1":"code","e94a00ee":"code","8286c06b":"code","626afed9":"code","4b450c8b":"code","98b8e500":"code","01f08c79":"code","5c7b9588":"code","9072d8c3":"code","fcd55f15":"code","28c0ca1d":"code","4488e0c6":"code","ff542c0f":"code","cbfc1ecd":"code","5ce7a43a":"code","ac21725c":"code","7a69293b":"code","4201eeb9":"code","611e894a":"code","235d5067":"code","7b404f1d":"code","d89352c3":"code","69cedcc8":"code","d5e2a284":"code","20398ea4":"code","074565db":"code","28fec1e1":"code","1cf80261":"code","3df6fdbc":"code","6aa13c1e":"code","8dcb5509":"code","b0f5b676":"code","dd9dfff9":"code","d1fbb8f0":"code","0b137946":"code","583bb56f":"code","e7dd710e":"code","af19b319":"code","e9d4ac7e":"code","7e4ba45b":"code","36775741":"code","baeaffff":"code","08eb22cc":"code","91b44394":"markdown","420eee9d":"markdown","f8d5d11b":"markdown","2a873c6a":"markdown","8e5e4621":"markdown","bfcbcc47":"markdown","b9f1715d":"markdown","e1f6014e":"markdown","16cdf9be":"markdown","70400540":"markdown","350421e6":"markdown"},"source":{"8a8f33c6":"import gc\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nimport multiprocessing\ncores = multiprocessing.cpu_count()\n\nmyfavouritenumber = 0\nseed = myfavouritenumber\nrandom.seed(seed)\n\nimport warnings\nwarnings.filterwarnings('ignore')","39b6d204":"%%time\ndf_train = pd.read_feather('..\/input\/ashrae-feather\/train.ft')\n\nbuilding = pd.read_feather('..\/input\/ashrae-feather\/building.ft')\nle = LabelEncoder()\nbuilding.primary_use = le.fit_transform(building.primary_use)\n\nweather_train = pd.read_feather('..\/input\/ashrae-feather\/weather_train.ft')\nweather_test = pd.read_feather('..\/input\/ashrae-feather\/weather_test.ft')","218b03d1":"%%time\ndf_train = df_train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20 18\")')\ndf_train = df_train.query('not (building_id == 681 & meter == 0 & timestamp <= \"2016-04-27\")')\ndf_train = df_train.query('not (building_id == 761 & meter == 0 & timestamp <= \"2016-09-02\")')\ndf_train = df_train.query('not (building_id == 799 & meter == 0 & timestamp <= \"2016-09-02\")')\ndf_train = df_train.query('not (building_id == 802 & meter == 0 & timestamp <= \"2016-08-24\")')\ndf_train = df_train.query('not (building_id == 1073 & meter == 0 & timestamp <= \"2016-10-26\")')\ndf_train = df_train.query('not (building_id == 1094 & meter == 0 & timestamp <= \"2016-09-08\")')\ndf_train = df_train.query('not (building_id == 29 & meter == 0 & timestamp <= \"2016-08-10\")')\ndf_train = df_train.query('not (building_id == 40 & meter == 0 & timestamp <= \"2016-06-04\")')\ndf_train = df_train.query('not (building_id == 45 & meter == 0 & timestamp <= \"2016-07\")')\ndf_train = df_train.query('not (building_id == 106 & meter == 0 & timestamp <= \"2016-11\")')\ndf_train = df_train.query('not (building_id == 107 & meter == 0 & timestamp >= \"2016-11-10\")')\ndf_train = df_train.query('not (building_id == 112 & meter == 0 & timestamp < \"2016-10-31 15\")')\ndf_train = df_train.query('not (building_id == 144 & meter == 0 & timestamp > \"2016-05-14\" & timestamp < \"2016-10-31\")')\ndf_train = df_train.query('not (building_id == 147 & meter == 0 & timestamp > \"2016-06-05 19\" & timestamp < \"2016-07-18 15\")')\ndf_train = df_train.query('not (building_id == 171 & meter == 0 & timestamp <= \"2016-07-05\")')\ndf_train = df_train.query('not (building_id == 177 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-09-26\" & timestamp < \"2016-12-12\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-08-30\" & timestamp < \"2016-09-08\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-09-18\" & timestamp < \"2016-09-25\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 0 & timestamp <= \"2016-05-11\")')\ndf_train = df_train.query('not (building_id == 269 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\ndf_train = df_train.query('not (building_id == 304 & meter == 0 & timestamp >= \"2016-11-20\")')\ndf_train = df_train.query('not (building_id == 545 & meter == 0 & timestamp > \"2016-01-17\" & timestamp < \"2016-02-10\")')\ndf_train = df_train.query('not (building_id == 604 & meter == 0 & timestamp < \"2016-11-21\")')\ndf_train = df_train.query('not (building_id == 693 & meter == 0 & timestamp > \"2016-09-07\" & timestamp < \"2016-11-23\")')\ndf_train = df_train.query('not (building_id == 693 & meter == 0 & timestamp > \"2016-07-12\" & timestamp < \"2016-05-29\")')\ndf_train = df_train.query('not (building_id == 723 & meter == 0 & timestamp > \"2016-10-06\" & timestamp < \"2016-11-22\")')\ndf_train = df_train.query('not (building_id == 733 & meter == 0 & timestamp > \"2016-05-29\" & timestamp < \"2016-06-22\")')\ndf_train = df_train.query('not (building_id == 733 & meter == 0 & timestamp > \"2016-05-19\" & timestamp < \"2016-05-20\")')\ndf_train = df_train.query('not (building_id == 803 & meter == 0 & timestamp > \"2016-9-25\")')\ndf_train = df_train.query('not (building_id == 815 & meter == 0 & timestamp > \"2016-05-17\" & timestamp < \"2016-11-17\")')\ndf_train = df_train.query('not (building_id == 848 & meter == 0 & timestamp > \"2016-01-15\" & timestamp < \"2016-03-20\")')\ndf_train = df_train.query('not (building_id == 857 & meter == 0 & timestamp > \"2016-04-13\")')\ndf_train = df_train.query('not (building_id == 909 & meter == 0 & timestamp < \"2016-02-02\")')\ndf_train = df_train.query('not (building_id == 909 & meter == 0 & timestamp < \"2016-06-23\")')\ndf_train = df_train.query('not (building_id == 1008 & meter == 0 & timestamp > \"2016-10-30\" & timestamp < \"2016-11-21\")')\ndf_train = df_train.query('not (building_id == 1113 & meter == 0 & timestamp < \"2016-07-27\")')\ndf_train = df_train.query('not (building_id == 1153 & meter == 0 & timestamp < \"2016-01-20\")')\ndf_train = df_train.query('not (building_id == 1169 & meter == 0 & timestamp < \"2016-08-03\")')\ndf_train = df_train.query('not (building_id == 1170 & meter == 0 & timestamp > \"2016-06-30\" & timestamp < \"2016-07-05\")')\ndf_train = df_train.query('not (building_id == 1221 & meter == 0 & timestamp < \"2016-11-04\")')\ndf_train = df_train.query('not (building_id == 1225 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-01-13 22\" & timestamp < \"2016-03-08 12\")')\ndf_train = df_train.query('not (building_id == 1241 & meter == 0 & timestamp > \"2016-07-14\" & timestamp < \"2016-11-19\")')\ndf_train = df_train.query('not (building_id == 1250 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1255 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 0 & timestamp > \"2016-08-23\")')\ndf_train = df_train.query('not (building_id == 1265 & meter == 0 & timestamp > \"2016-05-06\" & timestamp < \"2016-05-26\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1275 & building_id <= 1280 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1283 & meter == 0 & timestamp > \"2016-07-08\" & timestamp < \"2016-08-03\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1302 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 0 & timestamp > \"2016-07-25 22\" & timestamp < \"2016-07-27 16\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 0 & timestamp > \"2016-01-26\" & timestamp < \"2016-06-02 12\")')\ndf_train = df_train.query('not (building_id == 1319 & meter == 0 & timestamp > \"2016-05-17 16\" & timestamp < \"2016-06-07 12\")')\ndf_train = df_train.query('not (building_id == 1319 & meter == 0 & timestamp > \"2016-08-18 14\" & timestamp < \"2016-09-02 14\")')\ndf_train = df_train.query('not (building_id == 1322 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n\n# 2nd cleaning\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1297 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1300 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1299 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1221 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1225 & building_id <= 1226 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1241 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1226 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1225 & building_id <= 1226 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1305 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1307 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1231 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1275 & building_id <= 1297 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1300 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1293 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 0 & timestamp > \"2016-9-28 07\" & timestamp < \"2016-10-11 18\")')\ndf_train = df_train.query('not (building_id == 1225 & meter == 1 & timestamp > \"2016-8-22 23\" & timestamp < \"2016-10-11 14\")')\ndf_train = df_train.query('not (building_id == 1230 & meter == 1 & timestamp > \"2016-8-22 08\" & timestamp < \"2016-10-05 18\")')\ndf_train = df_train.query('not (building_id == 904 & meter == 0 & timestamp < \"2016-02-17 08\")')\ndf_train = df_train.query('not (building_id == 986 & meter == 0 & timestamp < \"2016-02-17 08\")')\ndf_train = df_train.query('not (building_id == 954 & meter == 0 & timestamp < \"2016-08-08 11\")')\ndf_train = df_train.query('not (building_id == 954 & meter == 0 & timestamp < \"2016-06-23 08\")')\ndf_train = df_train.query('not (building_id >= 745 & building_id <= 770 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\ndf_train = df_train.query('not (building_id >= 774 & building_id <= 787 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n\n# 3rd cleaning hourly spikes\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp == \"2016-02-26 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp == \"2016-02-26 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp == \"2016-02-26 01\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n\ndf_train = df_train.query('not (building_id != 1227 & building_id != 1281 & building_id != 1314 & building_id >=1223 & building_id < 1335 & meter==0 & meter_reading==0)')\n\n# 4th cleaning (using hindsight from leaks)\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter==1 & timestamp > \"2016-07-16 04\" & timestamp < \"2016-07-19 11\")')\ndf_train = df_train.query('not (building_id == 107 & meter == 0 & timestamp <= \"2016-07-06\")')\ndf_train = df_train.query('not (building_id == 180 & timestamp >= \"2016-02-17 12\")')\ndf_train = df_train.query('not (building_id == 182 & meter == 0)')\ndf_train = df_train.query('not (building_id == 191 & meter == 0 & timestamp >= \"2016-12-22 09\")')\ndf_train = df_train.query('not (building_id == 192 & meter == 1 & timestamp >= \"2016-05-09 18\")')\ndf_train = df_train.query('not (building_id == 192 & meter == 3 & timestamp >= \"2016-03-29 05\" & timestamp <= \"2016-04-04 08\")')\ndf_train = df_train.query('not (building_id == 207 & meter == 1 & timestamp > \"2016-07-02 20\" & timestamp < \"2016-08-25 12\")')\ndf_train = df_train.query('not (building_id == 258 & timestamp > \"2016-09-18\" & timestamp < \"2016-12-12 13\")')\ndf_train = df_train.query('not (building_id == 258 & timestamp > \"2016-08-29 08\" & timestamp < \"2016-09-08 14\")')\ndf_train = df_train.query('not (building_id == 257 & meter == 1 & timestamp < \"2016-03-25 16\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 1 & timestamp > \"2016-05-10 17\" & timestamp < \"2016-08-17 11\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 1 & timestamp > \"2016-08-28 01\" & timestamp < \"2016-10-31 13\")')\ndf_train = df_train.query('not (building_id == 220 & meter == 1 & timestamp > \"2016-09-23 01\" & timestamp < \"2016-09-23 12\")')\ndf_train = df_train.query('not (building_id == 281 & meter == 1 & timestamp > \"2016-10-25 08\" & timestamp < \"2016-11-04 15\")')\ndf_train = df_train.query('not (building_id == 273 & meter == 1 & timestamp > \"2016-04-03 04\" & timestamp < \"2016-04-29 15\")')\ndf_train = df_train.query('not (building_id == 28 & meter == 0 & timestamp < \"2016-10-14 20\")')\ndf_train = df_train.query('not (building_id == 71 & meter == 0 & timestamp < \"2016-08-18 20\")')\ndf_train = df_train.query('not (building_id == 76 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 14\")')\ndf_train = df_train.query('not (building_id == 101 & meter == 0 & timestamp > \"2016-10-12 13\" & timestamp < \"2016-10-12 18\")')\ndf_train = df_train.query('not (building_id == 7 & meter == 1 & timestamp > \"2016-11-03 09\" & timestamp < \"2016-11-28 14\")')\ndf_train = df_train.query('not (building_id == 9 & meter == 1 & timestamp > \"2016-12-06 08\")')\ndf_train = df_train.query('not (building_id == 43 & meter == 1 & timestamp > \"2016-04-03 08\" & timestamp < \"2016-06-06 13\")')\ndf_train = df_train.query('not (building_id == 60 & meter == 1 & timestamp > \"2016-05-01 17\" & timestamp < \"2016-05-01 21\")')\ndf_train = df_train.query('not (building_id == 75 & meter == 1 & timestamp > \"2016-08-05 13\" & timestamp < \"2016-08-26 12\")')\ndf_train = df_train.query('not (building_id == 95 & meter == 1 & timestamp > \"2016-08-08 10\" & timestamp < \"2016-08-26 13\")')\ndf_train = df_train.query('not (building_id == 97 & meter == 1 & timestamp > \"2016-08-08 14\" & timestamp < \"2016-08-25 14\")')\ndf_train = df_train.query('not (building_id == 1232 & meter == 1 & timestamp > \"2016-06-23 16\" & timestamp < \"2016-08-31 20\")')\ndf_train = df_train.query('not (building_id == 1236 & meter == 1 & meter_reading >= 3000)')\ndf_train = df_train.query('not (building_id == 1239 & meter == 1 & timestamp > \"2016-03-11 16\" & timestamp < \"2016-03-27 17\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 1 & timestamp > \"2016-08-22 17\" & timestamp < \"2016-09-22 20\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1269 & meter == 1 & meter_reading >= 2000)')\ndf_train = df_train.query('not (building_id == 1272 & meter == 1 & timestamp > \"2016-08-11 12\" & timestamp < \"2016-08-30 19\")')\ndf_train = df_train.query('not (building_id == 1273 & meter == 1 & timestamp > \"2016-05-31 14\" & timestamp < \"2016-06-17\")')\ndf_train = df_train.query('not (building_id == 1276 & meter == 1 & timestamp < \"2016-02-03 23\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-05-18\" & timestamp < \"2016-05-26 09\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-02-28 23\" & timestamp < \"2016-05-02 05\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-06-12 01\" & timestamp < \"2016-7-07 06\")')\ndf_train = df_train.query('not (building_id == 1288 & meter == 1 & timestamp > \"2016-07-07 15\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id == 1311 & meter == 1 & timestamp > \"2016-04-25 18\" & timestamp < \"2016-05-13 14\")')\ndf_train = df_train.query('not (building_id == 1099 & meter == 2)')\n\ndf_train = df_train.query('not (building_id == 1329 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\ndf_train = df_train.query('not (building_id == 1331 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\ndf_train = df_train.query('not (building_id == 1427 & meter == 0 & timestamp > \"2016-04-11 10\" & timestamp < \"2016-04-11 14\")')\ndf_train = df_train.query('not (building_id == 1426 & meter == 2 & timestamp > \"2016-05-03 09\" & timestamp < \"2016-05-03 14\")')\ndf_train = df_train.query('not (building_id == 1345 & meter == 0 & timestamp < \"2016-03-01\")')\ndf_train = df_train.query('not (building_id == 1346 & timestamp < \"2016-03-01\")')\ndf_train = df_train.query('not (building_id == 1359 & meter == 0 & timestamp > \"2016-04-25 17\" & timestamp < \"2016-07-22 14\")')\ndf_train = df_train.query('not (building_id == 1365 & meter == 0 & timestamp > \"2016-08-19 00\" & timestamp < \"2016-08-19 07\")')\ndf_train = df_train.query('not (building_id == 1365 & meter == 0 & timestamp > \"2016-06-18 22\" & timestamp < \"2016-06-19 06\")')\n\ndf_train = df_train.query('not (building_id == 18 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 16\")')\ndf_train = df_train.query('not (building_id == 18 & meter == 0 & timestamp > \"2016-11-05 05\" & timestamp < \"2016-11-05 15\")')\ndf_train = df_train.query('not (building_id == 101 & meter == 0 & meter_reading > 800)')\n\ndf_train = df_train.query('not (building_id == 1384 & meter == 0 & meter_reading == 0 )')\ndf_train = df_train.query('not (building_id >= 1289 & building_id <= 1301 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1243 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1263 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1284 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1286 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1263 & meter == 0 & timestamp > \"2016-11-10 11\" & timestamp < \"2016-11-10 15\")')\n\ndf_train = df_train.query('not (building_id == 1238 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1329 & meter == 2 & timestamp > \"2016-11-21 12\" & timestamp < \"2016-11-29 12\")')\ndf_train = df_train.query('not (building_id == 1249 & meter == 2 & meter_reading == 0)')\n\ndf_train = df_train.query('not (building_id == 1250 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-05 18\" & timestamp < \"2016-03-05 22\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-27 00\" & timestamp < \"2016-03-27 23\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-11 09\" & timestamp < \"2016-04-13 03\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-29 00\" & timestamp < \"2016-04-30 15\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 2 & timestamp < \"2016-06-06 19\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter == 1 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & building_id != 1296 & building_id != 129 & building_id != 1298 & building_id != 1299 & meter == 2 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter == 3 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')","c0cd1460":"# building_meter_week_hour statistical feature - groups building_id, meter, weekday, and hour and mean encode to target meter reading variable\n\nbm_cols = ['bm', 'weekday', 'hour',]\ndf_train['hour'] = df_train['timestamp'].dt.hour\ndf_train['weekday'] = df_train['timestamp'].dt.weekday\ndf_train['bm'] = df_train['building_id'].apply(lambda x: str(x)) + '_' + df_train['meter'].apply(lambda x: str(x))\nbm = df_train.groupby(bm_cols)['meter_reading'].mean().rename('bm_week_hour').to_frame()\ndf_train = df_train.merge(bm, right_index=True, left_on=bm_cols, how='left')\ndf_train.drop(['bm'], axis=1, inplace=True)\ndf_train.head()","2e5da81b":"weather = pd.concat([weather_train, weather_test],ignore_index=True)\n\nweather_key = ['site_id', 'timestamp']\nfull_weather = weather[weather_key + ['air_temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()","810cf91c":"full_weather['timestamp'] = pd.to_datetime(full_weather['timestamp'])","309324d4":"# calculate ranks of hourly temperatures within date\/site_id chunks\nfull_weather['temp_rank'] = full_weather.groupby(['site_id', full_weather.timestamp.dt.date])['air_temperature'].rank('average')\n\n# create a dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\ndf_2d = full_weather.groupby(['site_id', full_weather.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n\n# Subtract the columnID of temperature peak by 14, getting the timestamp alignment gap.\nsite_ids_offsets = pd.Series(df_2d.values.argmax(axis=1) - 14)\nsite_ids_offsets.index.name = 'site_id'\n\ndef timestamp_align(df):\n    df['offset'] = df.site_id.map(site_ids_offsets)\n    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n    df['timestamp'] = df['timestamp_aligned']\n    del df['timestamp_aligned']\n    return df","a474659b":"## Memory optimization\n\n# Original code from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16\n\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    \n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","e5728494":"df_train = reduce_mem_usage(df_train, use_float16=True)\nbuilding = reduce_mem_usage(building, use_float16=True)\nweather_train = reduce_mem_usage(weather_train, use_float16=True)","83937a5d":"def rmse(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(ypred - ytrue), axis=0))\ndef rmsle(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(np.log1p(ypred) - np.log1p(ytrue)), axis=0))","f4f1add1":"le = LabelEncoder()\n\ndef prepare_data(X, building_data, weather_data, test=False):\n    \"\"\"\n    Preparing final dataset with all features.\n    \"\"\"\n    # align timestamp\n    weather_data = timestamp_align(weather_data)\n    \n    X = X.merge(building_data, on=\"building_id\", how=\"left\")\n    X = X.merge(weather_data, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    \n    X.sort_values(\"timestamp\")\n    X.reset_index(drop=True)\n    \n    gc.collect()\n    \n    X.timestamp = pd.to_datetime(X.timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n    X.square_feet = np.log1p(X.square_feet)\n    \n    X[\"hour\"] = X.timestamp.dt.hour\n    X[\"weekday\"] = X.timestamp.dt.weekday\n    X['hour'] = X['hour'].astype('int8')\n    X['weekday'] = X['weekday'].astype('int8')\n    \n    drop_features = [\"timestamp\", \"site_id\",\"sea_level_pressure\", \"precip_depth_1_hr\",]# \"wind_direction\", \"wind_speed\"]\n\n    X.drop(drop_features, axis=1, inplace=True)\n\n    X = reduce_mem_usage(X, use_float16=True)\n    \n    if test:\n        row_ids = X.row_id\n        X.drop(\"row_id\", axis=1, inplace=True)\n        return X, row_ids\n    else:\n        y = np.log1p(X.meter_reading)\n        X.drop(\"meter_reading\", axis=1, inplace=True)\n        return X, y","e94a00ee":"X_train, y_train = prepare_data(df_train, building, weather_train)\n\ndel df_train, weather_train\ngc.collect()","8286c06b":"%%time\nX_half_1 = X_train[X_train['hour'] <= 11]\nX_half_2 = X_train[X_train['hour'] >  11]\n\ny_half_1 = y_train[X_train['hour'] <= 11]\ny_half_2 = y_train[X_train['hour'] >  11]\n\ncategorical_features = [\"building_id\", \"meter\", \"primary_use\", \"hour\", \"weekday\",]\n\nd_half_1 = lgb.Dataset(X_half_1, label=y_half_1, categorical_feature=categorical_features, free_raw_data=False)\nd_half_2 = lgb.Dataset(X_half_2, label=y_half_2, categorical_feature=categorical_features, free_raw_data=False)\n\nwatchlist_1 = [d_half_1, d_half_2]\nwatchlist_2 = [d_half_2, d_half_1]\n\nparams = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 40,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\",\n    \"num_threads\": 2\n}\n\nprint(\"Building model with first half and validating on second half:\")\nmodel_half_1 = lgb.train(params, train_set=d_half_1, num_boost_round=500, valid_sets=watchlist_1, verbose_eval=200, early_stopping_rounds=200)\n\nprint(\"Building model with second half and validating on first half:\")\nmodel_half_2 = lgb.train(params, train_set=d_half_2, num_boost_round=500, valid_sets=watchlist_2, verbose_eval=200, early_stopping_rounds=200)","626afed9":"%%time\npred = np.zeros(len(X_train))\npred1 = model_half_1.predict(X_half_2)\npred2 = model_half_2.predict(X_half_1)","4b450c8b":"pred = np.zeros(len(X_train))\npred[X_train['hour'] <= 11] += pred2\npred[X_train['hour'] >  11] += pred1\nprint(f\"Half\/Half RMSE: {rmse(pred, y_train):.4f}\")","98b8e500":"%%time\nplt.figure(figsize=(8,8))\nplt.scatter(y_train, pred)\nplt.xlabel('y_true')\nplt.ylabel('pred')\nplt.show()","01f08c79":"import matplotlib.pyplot as plt\n\ndef plot_feature_importance(model):\n    importance_df = pd.DataFrame(model.feature_importance(),\n                                 index=X_train.columns,\n                                 columns=['importance']).sort_values('importance')\n    fig, ax = plt.subplots(figsize=(6, 6))\n    importance_df.plot.barh(ax=ax)\n    plt.show()","5c7b9588":"plot_feature_importance(model_half_1)","9072d8c3":"plot_feature_importance(model_half_2)","fcd55f15":"# save model to file\npickle.dump(model_half_1, open(\"model_half_1.pkl\", \"wb\"))\npickle.dump(model_half_2, open(\"model_half_2.pkl\", \"wb\"))\npickle.dump(pred, open(\"pred_L1.pkl\", \"wb\"))","28c0ca1d":"del X_train, X_half_1, X_half_2, y_half_1, y_half_2, d_half_1, d_half_2, \ndel watchlist_1, watchlist_2, pred, pred1, pred2\ngc.collect()","4488e0c6":"%%time\nweather_test = pd.read_feather('..\/input\/ashrae-feather\/weather_test.ft')\ndf_test = pd.read_feather('..\/input\/ashrae-feather\/test.ft')\n\ndf_test['hour'] = df_test['timestamp'].dt.hour\ndf_test['weekday'] = df_test['timestamp'].dt.weekday\ndf_test['bm'] = df_test['building_id'].apply(lambda x: str(x)) + '_' + df_test['meter'].apply(lambda x: str(x))\ndf_test = df_test.merge(bm, right_index=True, left_on=bm_cols, how='left')\ndf_test.drop('bm', axis=1, inplace=True)\n\ndf_test = reduce_mem_usage(df_test, use_float16=True)\nweather_test = reduce_mem_usage(weather_test, use_float16=True)\n\nX_test, row_ids = prepare_data(df_test, building, weather_test, test=True)","ff542c0f":"X_test.head()","cbfc1ecd":"del df_test, building, weather_test\ngc.collect()","5ce7a43a":"%%time\npred = np.expm1(model_half_1.predict(X_test, num_iteration=model_half_1.best_iteration)) \/ 2\n\ndel model_half_1\ngc.collect()\n\npred += np.expm1(model_half_2.predict(X_test, num_iteration=model_half_2.best_iteration)) \/ 2\n    \ndel model_half_2\ngc.collect()","ac21725c":"submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(pred, 0, a_max=None)})\nsubmission['meter_reading'] = submission['meter_reading'].astype('float32')\nsubmission['row_id'] = submission['row_id'].astype('int32')\nsubmission.to_csv(\"submission.csv\", index=False, chunksize=25000)","7a69293b":"submission.head()","4201eeb9":"print(f\"submission mean: {submission['meter_reading'].mean():.4f}\")\nprint(f\"submission std: {submission['meter_reading'].std():.4f}\")\nprint(f\"submission min: {submission['meter_reading'].min():.4f}\")\nprint(f\"submission max: {submission['meter_reading'].max():.4f}\")","611e894a":"sns.distplot(np.log1p(submission['meter_reading'].values), kde=False);\ngc.collect()","235d5067":"site0 = pd.read_feather('..\/input\/ucf-building-meter-reading\/site0.ft')\ndf_test = pd.read_feather('..\/input\/ashrae-feather\/test.ft')","7b404f1d":"merged = df_test.merge(site0, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","d89352c3":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","69cedcc8":"print(f'RMSLE of buildings 0-104: {rmsle(ytrue, pred):.4f}')","d5e2a284":"site1 = pd.read_feather('..\/input\/ucl-data-leakage-episode-2\/site1.ft')\nsite1 = site1.query('timestamp >= 2017')","20398ea4":"merged = df_test.merge(site1, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","074565db":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","28fec1e1":"del merged, site1\nprint(f'RMSLE of buildings 105-155: {rmsle(ytrue, pred):.4f}')","1cf80261":"site2 = pd.read_feather('..\/input\/asu-feather\/site2.ft')\nsite2 = site2.query('timestamp >= 2017')","3df6fdbc":"merged = df_test.merge(site2, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","6aa13c1e":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","8dcb5509":"del site2, merged\nprint(f'RMSLE of buildings 156-290: {rmsle(ytrue, pred):.4f}')","b0f5b676":"site4 = pd.read_feather('..\/input\/ucb-feather\/site4.ft')\nsite4 = site4.query('timestamp >= 2017')","dd9dfff9":"merged = df_test.merge(site4, left_on=['building_id', 'timestamp'], \n              right_on=['building_id', 'timestamp'], how='left')","d1fbb8f0":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","0b137946":"del site4, merged\nprint(f'RMSLE of 74\/91 buildings : {rmsle(ytrue, pred):.4f}')","583bb56f":"site15 = pd.read_feather('..\/input\/cornell-feather\/site15.ft')\nsite15 = site15.query('timestamp >= 2017')\nsite15 = site15.drop_duplicates()","e7dd710e":"merged = df_test.merge(site15, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","af19b319":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","e9d4ac7e":"del site15, merged\nprint(f'RMSLE of buildings 1325-1448: {rmsle(ytrue, pred):.4f}')","7e4ba45b":"site012 = pd.read_feather('..\/input\/comb-leaked-dataset\/site012.ft')\nsite012 = site012.query('timestamp >= 2017')","36775741":"merged = df_test.merge(site012, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","baeaffff":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","08eb22cc":"del site012, merged\ngc.collect()\nprint(f'RMSLE of buildings 0-290: {rmsle(ytrue, pred):.4f}')","91b44394":"# Submission Validation Cornell Site15 (bld 1325-1448)","420eee9d":"# Submission","f8d5d11b":"# Submission Validation Site0-2 (bld 0-290)","2a873c6a":"# Submission Validation ASU Site2 (bld 156-290)","8e5e4621":"# Scoring test data","bfcbcc47":"# Submission Validation UCB Site4 (74 blds)","b9f1715d":"# Submission Validation ASU Site1 (bld 105-155)","e1f6014e":"# Preparing test data","16cdf9be":"# Save Model","70400540":"# Submission Validation (bld 0-104)","350421e6":"# Morning\/Evening Split\n\nCredit to:\n\n[kxx](https:\/\/www.kaggle.com\/kailex) for https:\/\/www.kaggle.com\/kailex\/ac-dc <br>\n[Vopani](https:\/\/www.kaggle.com\/rohanrao) for https:\/\/www.kaggle.com\/rohanrao\/ashrae-half-and-half <br>\n[NZ](https:\/\/www.kaggle.com\/nz0722) for https:\/\/www.kaggle.com\/nz0722\/aligned-timestamp-lgbm-by-meter-type\n\nIn this notebook, I split training data in half by hour in the day, where I train on first 12 hours and validate on last 12 hours and vice-versa. In addition, I've included manual data cleaning, and outlier removal. Included in this notebook is a feature I created myself - a statistical feature that groups building_id, meter, weekday, and hour mean encoded to target meter_reading. I also added timestamp alignment for weather features.\n\nTraining validation and testing validation (leaked ground truth labels for site_id 0,1,2,4,15) were used to validate this model's performance."}}