{"cell_type":{"a1c65be4":"code","c817be00":"code","a4940217":"code","c52019b1":"code","7d2e1fd5":"code","4433dece":"code","6cbd4dcd":"code","a410e28f":"code","1336eaec":"code","4eac4a58":"code","bf584266":"code","86170b7a":"code","3c97f852":"code","62fe8c32":"code","577db211":"code","d3e2fb73":"code","9f68a6fa":"code","2d001175":"code","b0154759":"code","e607a245":"code","8c133cf2":"code","dd88c92b":"code","55ce1580":"code","f797ac11":"code","33c5d13f":"code","22e7e128":"code","a581686f":"code","2ae9f5a8":"code","b7d2fd14":"code","fa9ea9a6":"code","cc1aa91b":"code","0e3bccc0":"code","21b5a47a":"code","66aff2f8":"code","8e615d75":"code","5a44360f":"code","5948a55e":"code","57011947":"code","097fd362":"code","a6414bcb":"code","dcfd5208":"code","f17bb810":"code","eea1d1a9":"code","a3e8817c":"code","a2cae734":"code","5af82c7d":"code","e03dd52b":"code","c502a46f":"code","3433230d":"code","cb83368a":"code","1f026abd":"code","746f51d0":"code","44d3b792":"code","e8dd868c":"code","8fc02a05":"code","6f1f81ad":"code","54ee0c1e":"code","0538ca9e":"code","08527e99":"code","d6a97c26":"code","5988ba1c":"markdown","46927a9d":"markdown"},"source":{"a1c65be4":"class CFG:\n    debug=False\n    #height=256\n    #width=256\n    lr=1e-4\n    batch_size=16\n    epochs=5\n    seed=777\n    target_size=1\n    target_col = \"label\"\n    n_fold=4\nSIZE = 512","c817be00":"import sys\n\nimport gc\nimport os\nimport random\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport skimage.io\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold,GroupKFold\n\nfrom functools import partial\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip,RandomGamma, RandomRotate90,GaussNoise,RGBShift,GaussianBlur\nfrom albumentations.pytorch import ToTensorV2","a4940217":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=42)\n","c52019b1":"!pip install efficientnet_pytorch","7d2e1fd5":"\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_name('efficientnet-b0')\nprint(model)\n","4433dece":"!pip install geffnet","6cbd4dcd":"import geffnet\nmodel = geffnet.create_model('efficientnet_b0', pretrained=True)\nmodel.classifier=nn.Identity()\na =torch.randn((10,3,512,512))\nprint(model(a.float()).size())\nprint(model)","a410e28f":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(torch.cuda.current_device())","1336eaec":"#\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210\nimport glob\npath_list=glob.glob(\"\/kaggle\/input\/glaucomadataset\/Glaucoma\/*\")\nlabel_list = np.ones(len(path_list))\nn_path_list=glob.glob(\"\/kaggle\/input\/glaucomadataset\/Non Glaucoma\/*\")\nn_label_list = np.zeros(len(n_path_list))\npath_list.extend(n_path_list)\nlabels = np.concatenate([label_list, n_label_list])\nprint(len(path_list),labels.shape)\ndf = pd.DataFrame(columns =[\"file\",\"label\"])\ndf[\"file\"] = path_list\ndf[\"label\"] = labels\n","4eac4a58":"df = df.sample(frac=1)","bf584266":"df.head()","86170b7a":"df.tail()","3c97f852":"df[df[\"label\"]==1][\"file\"].values[0]","62fe8c32":"china = pd.read_csv(\"\/kaggle\/input\/panda-efnetb2-180-weight\/china_gla.csv\")\nchina[\"file\"] = [\"\/kaggle\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K\/Training Images\/{}\".format(china[\"filename\"].values[i]) for i in range(len(china))]\nchina[\"label\"] = china[\"Gla\"]\nchina.head()","577db211":"##concat china_data\n\nchina_ = china.drop([\"Unnamed: 0\",\"Patient Age\",\"ID\",\"Patient Sex\"],axis=1)\nchina_1 = china_.head(300)\nchina_0 = china_.tail(300)\nprint(china_.head())\nchina_0[\"from_china\"]=1\nchina_1[\"from_china\"]=1\n#df[\"from_china\"]=0\ncat_df = pd.concat([china_1,china_0])\nprint(cat_df.shape)\ncat_df.head()\n","d3e2fb73":"import matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\nidx=0\nimage = cv2.imread(cat_df['file'].values[idx])\nplt.imshow(image)\nplt.show()\nimport math\ndef get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]\/2), math.ceil(pad_diff[0]\/2)\n    l, r = math.floor(pad_diff[1]\/2), math.ceil(pad_diff[1]\/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\ndef crop_object(img, thresh=10, maxval=200, square=False):\n    \"\"\"\n    Source: https:\/\/stackoverflow.com\/questions\/49577973\/how-to-crop-the-biggest-object-in-image-with-python-opencv\n    \"\"\"\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)# convert to grayscale\n    #plt.imshow(gray,cmap=\"gray\")\n    #plt.show()#\u666e\u901a\u306b\u767d\u9ed2\u306e\u304c\u307f\u3048\u308b\n    # threshold to get just the signature (INVERTED)\n    retval, thresh_gray = cv2.threshold(gray, thresh=thresh, maxval=maxval, type=cv2.THRESH_BINARY)\n    #plt.imshow(thresh_gray,cmap=\"gray\")\n    #plt.show()\n    contours, hierarchy = cv2.findContours(thresh_gray,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n    #https:\/\/qiita.com\/anyamaru\/items\/fd3d894966a98098376c\n    # Find object with the biggest bounding box\n    mx = (0,0,0,0)      # biggest bounding box so far\n    mx_area = 0\n    for cont in contours:\n        x,y,w,h = cv2.boundingRect(cont)\n        area = w*h\n        if area > mx_area:\n            mx = x,y,w,h\n            mx_area = area\n    x,y,w,h = mx#(0,0,0,0)\u306a\u306e\u306fcontours\u306b\u4f55\u3082\u5165\u3063\u3066\u306a\u3044\u304b\u3089\n    crop = img[y:y+h, x:x+w]\n    if square:\n        pad_width = get_pad_width(crop, max(crop.shape))\n        crop = np.pad(crop, pad_width=pad_width, mode='constant', constant_values=255)\n    return crop\n\ncroped= crop_object(image)\nplt.imshow(croped)\nplt.show()","9f68a6fa":"class TrainDataset(Dataset):\n    def __init__(self, df,crop=True,transform1=None, transform2=None):\n        self.df = df\n        self.crop =crop\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file'].values[idx]\n        image = skimage.io.MultiImage(file_path)[0]\n        if self.crop:\n            image = crop_object(image)\n        image = cv2.resize(image,(SIZE,SIZE))\n        label_ = self.df[\"label\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n            \n        label = torch.tensor(label_).long()\n        #print(label_,type(label_),label,label.size())\n        \n        return image, label","2d001175":"##train_test_split\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(cat_df, test_size=0.3,stratify = cat_df[\"label\"], random_state=2020)\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)","b0154759":"##train_valid_split\nif CFG.debug:\n    folds = train.sample(n=200, random_state=CFG.seed).reset_index(drop=True).copy()\nelse:\n    folds = train.copy()\ntrain_labels = folds[\"label\"].values\nkf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n    print(\"num_train,val\",len(train_index),len(val_index),len(val_index)+len(train_index))\n    folds.loc[val_index, 'fold'] = int(fold)\n\nfolds['fold'] = folds['fold'].astype(int)\nfolds.to_csv('folds.csv', index=None)\nfolds.head()","e607a245":"import sklearn.metrics as metric\n\ndef auc(y,y_hat):\n    return metric.roc_auc_score(y,y_hat)\n","8c133cf2":"def get_transforms1(*, data):\n\n    #train,valid\u4ee5\u5916\u3060\u3063\u305f\u3089\u6012\u308b\n    \n    if data == 'train':\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            #GaussNoise(p=0.5),\n            #RandomRotate90(p=0.5),\n            #RandomGamma(p=0.5),\n            #RandomAugMix(severity=3, width=3, alpha=1., p=0.5),\n            #GaussianBlur(p=0.5),\n            #GridMask(num_grid=3, p=0.3),\n            #Cutout(p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif data == 'valid':\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            )\n        ])\n\ndef to_tensor(*args):\n\n        return Compose([\n            ToTensorV2()\n        ])","dd88c92b":"base_model = torchvision.models.resnet18(pretrained =True)\nbase_model.fc = nn.Linear(base_model.fc.in_features, 1)\n","55ce1580":"#\u753b\u50cf\u306e\u78ba\u8a8d\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndataset = TrainDataset(train.reset_index(drop=True), \n                                 transform1=None,transform2=None)#get_transforms1(data='train')\ndata_loader = DataLoader(dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=8)\nx=0\nfor img,label in data_loader:\n    img = img.detach().numpy()[x]\n    print(img.shape,label.detach().numpy()[x])\n    plt.imshow(img)\n    plt.show()\n    break","f797ac11":"%%time\nfor img,label in data_loader:\n    img = img.detach().numpy()[0].transpose(1,2,0)\n    plt.imshow(img)\n    plt.show()\n    break","33c5d13f":"class Model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = torchvision.models.resnet18(pretrained =False)\n        self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n        \n        \n    def forward(self, x):\n        x = self.model(x)#\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u306e\u6d41\u308c\u306b\u540c\u3058\n        return x","22e7e128":"class efenet_Model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = geffnet.efficientnet_b0(pretrained=True, drop_rate=0.25)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 1)\n        \n        \n    def forward(self, x):\n        x = self.model(x)#\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u306e\u6d41\u308c\u306b\u540c\u3058\n        return x","a581686f":"class extract_Model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = geffnet.create_model('efficientnet_b0', pretrained=True)\n        self.model.classifier=nn.Identity()\n    \n        \n    def forward(self, x):\n        x = self.model(x)#\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u306e\u6d41\u308c\u306b\u540c\u3058\n        return x\n    \nclass TrainDataset(Dataset):\n    def __init__(self, df, transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file'].values[idx]\n        image = skimage.io.MultiImage(file_path)[0]\n        image = cv2.resize(image,(SIZE,SIZE))\n        label = self.df[\"label\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n            \n        label = torch.tensor(label).float()\n        \n        return image, label\n\ndataset = TrainDataset(folds.reset_index(drop=True), \n                                 transform1=None,transform2=to_tensor())\nloader = DataLoader(dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4)\n##extract vecotr from images\ntk0 = tqdm(enumerate(loader), total=len(loader))\nembeds =[]\nmodel = extract_Model()\nmodel.to(device)\nfor i, (images, labels) in tk0:\n    images = images.to(device)\n    labels = labels.to(device)\n    with torch.no_grad():\n        embed = model(images.float())\n    embeds.append(embed.cpu().detach().numpy())\n","2ae9f5a8":"embeds_ =np.concatenate(embeds)\nprint(embeds_.shape,len(folds))","b7d2fd14":"china_dataset = TrainDataset(cat_df.reset_index(drop=True),transform1=None,transform2=to_tensor())\nchina_loader = DataLoader(china_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4)\ntk1 = tqdm(enumerate(china_loader), total=len(china_loader))\nembeds_china =[]\nfor i, (images, labels) in tk1:\n    images = images.to(device)\n    labels = labels.to(device)\n    with torch.no_grad():\n        embed = model(images.float())\n    embeds_china.append(embed.cpu().detach().numpy())\nembeds_china_ =np.concatenate(embeds_china)","fa9ea9a6":"import numpy as np\nfrom sklearn import manifold\nimport matplotlib.pyplot as plt\n%matplotlib inline\nmds = manifold.MDS(n_components=2, dissimilarity=\"euclidean\", random_state=6)\nmds_result = mds.fit_transform(embeds_)\n#where_from_data = folds[\"from_china\"]\nwhich_Gla = folds[\"label\"]\n\n#plt.scatter(mds_result[:, 0], mds_result[:, 1], c=where_from_data)\n#plt.show()\nplt.scatter(mds_result[:, 0], mds_result[:, 1], c=which_Gla)\nplt.show()","cc1aa91b":"import umap\nembedding = umap.UMAP().fit_transform(embeds_)\n#plt.scatter(embedding[:, 0], embedding[:, 1], c=where_from_data)\n#plt.show()\nplt.scatter(embedding[:, 0], embedding[:, 1], c=which_Gla)\nplt.show()","0e3bccc0":"from sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2)\ntsne = tsne_model.fit_transform(embeds_)\n#plt.scatter(tsne[:, 0], tsne[:, 1], c=where_from_data)\n#plt.show()\nplt.scatter(tsne[:, 0], tsne[:, 1], c=which_Gla)\nplt.show()","21b5a47a":"which_Gla = cat_df[\"label\"]\nembedding_ = umap.UMAP().fit_transform(embeds_china_)\n#plt.scatter(embedding[:, 0], embedding[:, 1], c=where_from_data)\n#plt.show()\nplt.scatter(embedding_[:, 0], embedding_[:, 1], c=which_Gla)\nplt.show()","66aff2f8":"tsne_model = TSNE(n_components=2)\ntsne = tsne_model.fit_transform(embeds_china_)\n#plt.scatter(tsne[:, 0], tsne[:, 1], c=where_from_data)\n#plt.show()\nplt.scatter(tsne[:, 0], tsne[:, 1], c=which_Gla)\nplt.show()","8e615d75":"mds_result_ = mds.fit_transform(embeds_china_)\nplt.scatter(mds_result_[:, 0], mds_result_[:, 1], c=which_Gla)\nplt.show()","5a44360f":"def train_fn(fold):\n    print(f\"### fold: {fold} ###\")\n\n        \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    train_dataset = TrainDataset(folds.loc[trn_idx].reset_index(drop=True), \n                                 transform1=None,transform2=to_tensor())#get_transforms1(data='train')\n    valid_dataset = TrainDataset(folds.loc[val_idx].reset_index(drop=True), \n                                 transform1=None,transform2=to_tensor())#get_transforms1(data='valid')\n    \n    \n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4)\n    model = efenet_Model()\n    #model = Model()\n    \n    model.to(device)\n    \n    optimizer = Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n    #scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n    #scheduler = CosineAnnealingLR(optimizer, T_max=20, eta_min=0.001)\n    \n    criterion = nn.BCELoss()#weight = class_weight\n    best_score = -100\n    best_loss = np.inf\n    best_preds = None\n    \n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n\n        model.train()\n        \"\"\"\n        if epoch <3:\n            for param in model.parameters():\n                param.requires_grad = False\"\"\"\n        avg_loss = 0.\n\n        optimizer.zero_grad()\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader))\n\n        for i, (images, labels) in tk0:\n            #if i ==0:\n                #print(images.size())\n\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(images.float())\n            y_preds = torch.sigmoid(y_preds.view(-1))\n            #if i ==0:\n                #print(y_preds.size(),labels.size())#\u540c\u3058\n            loss = criterion(y_preds, labels)\n            #loss = criterion(y_preds.view, labels)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            avg_loss += loss.item() \/ len(train_loader)\n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader))\n\n        for i, (images, labels) in tk1:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                y_preds = model(images.float())\n                \n                y_preds = torch.sigmoid(y_preds.view(-1))\n            preds.append(y_preds.to('cpu').numpy())\n            valid_labels.append(labels.to('cpu').numpy())\n\n            loss = criterion(y_preds, labels)\n            avg_val_loss += loss.item() \/ len(valid_loader)\n        \n        #scheduler.step(avg_val_loss)\n            \n        preds = np.concatenate(preds)\n        #print(preds.shape)\n        valid_labels = np.concatenate(valid_labels)\n\n        score = auc(valid_labels,preds)\n\n        elapsed = time.time() - start_time\n        print(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.6f}  avg_val_loss: {avg_val_loss:.6f}  time: {elapsed:.0f}s')\n        print(f'  Epoch {epoch+1} - AUC: {score}')\n        \n        if score>best_score:#auc\u306e\u30b9\u30b3\u30a2\u304c\u826f\u304b\u3063\u305f\u3089\u4e88\u6e2c\u5024\u3092\u66f4\u65b0...best_epoch\u3092\u304d\u3081\u308b\u305f\u3081\n            best_score = score\n            best_preds = preds\n            print(\"====\",f'  Epoch {epoch+1} - Save Best Score: {best_score:.4f}',\"===\")\n            torch.save(model.state_dict(), f'fold{fold}_resnet18_baseline.pth')#\u5404epoch\u306e\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3002\u3002\u3002best_epoch\u7d42\u4e86\u6642\u306e\u30e2\u30c7\u30eb\u3092\u63a8\u8ad6\u306b\u4f7f\u7528\u3059\u308b\uff1f\n    \n    return best_preds, valid_labels,model","5948a55e":"preds = []\nvalid_labels = []\nmodels =[]\nfor fold in range(CFG.n_fold):\n    _preds, _valid_labels,_model = train_fn(fold)\n    preds.append(_preds)\n    valid_labels.append(_valid_labels)\n    models.append(_model)","57011947":"##\npreds_ = np.concatenate(preds)\nvalid_labels_ = np.concatenate(valid_labels)\n\nscore = auc(valid_labels_,preds_)\nimport datetime\n\ndt_now = datetime.datetime.now()\nprint(\"\u73fe\u5728\u6642\u523b\",dt_now)\nprint(\"=====AUC(CV)======\",score)","097fd362":"train_df = pd.DataFrame()\ntrain_df[\"predict\"] = preds\ntrain_df[\"label\"] = valid_labels\ntrain_df[\"abs_pred-true\"] = np.abs(train_df[\"predict\"]-train_df[\"label\"])\n#train_df = train_df.sort_values('abs_pred-true', ascending=False)\ntrain_df.head(130)","a6414bcb":"from sklearn import metrics\n\nfpr, tpr, thresholds = metrics.roc_curve(valid_labels_, preds_)\nimport matplotlib.pyplot as plt\nplt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%score)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate(1-Specificity)')\nplt.ylabel('True Positive Rate(Recall)')\nplt.grid(True)\nplt.show()","dcfd5208":"class TestDataset(Dataset):\n    def __init__(self, df, transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file'].values[idx]\n        image = skimage.io.MultiImage(file_path)[0]\n        image = cv2.resize(image,(SIZE,SIZE))\n        label = self.df[\"label\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n        return image\n    \nclass baseline_model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        #self.model = torchvision.models.resnet18(pretrained =False)\n        #self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n        self.model = geffnet.efficientnet_b0(pretrained=False, drop_rate=0.25)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 1)\n        \n        \n    def forward(self, x):\n        x = self.model(x)#\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u306e\u6d41\u308c\u306b\u540c\u3058\n        return x\ndef fix_model_state_dict(state_dict):\n    from collections import OrderedDict\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k\n        if name.startswith('model.'):\n            name = name[6:]  # remove 'model.' of dataparallel\n        new_state_dict[name] = v\n    return new_state_dict\n\ndef inference(model, test_loader, device):\n    \n    model.to(device) \n    \n    probs = []\n\n    for i, images in tqdm(enumerate(test_loader), total=len(test_loader)):\n            \n        images = images.to(device)\n            \n        with torch.no_grad():\n            y_preds = model(images)\n            y_preds = torch.sigmoid(y_preds.view(-1))\n            \n        probs.append(y_preds.to('cpu').numpy())\n\n    probs = np.concatenate(probs)\n    \n    return probs\n\ndef submit():\n        print('run inference')\n        test_dataset = TestDataset(test, transform1=get_transforms1(data='valid'),transform2=to_tensor())\n        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n        probs = []\n        for fold in range(CFG.n_fold):\n            weights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(fold)\n            model = baseline_model()\n            state_dict = torch.load(weights_path,map_location=device)\n            model.load_state_dict(state_dict)\n            _probs = inference(model, test_loader, device)\n            probs.append(_probs)\n        probs = np.mean(probs, axis=0)\n        return probs","f17bb810":"len(test)","eea1d1a9":"test['predict'] = submit()\nprint(test.head())\nscore = auc(test['label'].values[:],test['predict'])\nprint(\"=====AUC(inner_test)======\",score)","a3e8817c":"def submit():\n        print('run inference')\n        test_dataset = TestDataset(df, transform1=get_transforms1(data='valid'),transform2=to_tensor())\n        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n        probs = []\n        for fold in range(CFG.n_fold):\n            weights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(fold)\n            model = baseline_model()\n            state_dict = torch.load(weights_path,map_location=device)\n            model.load_state_dict(state_dict)\n            _probs = inference(model, test_loader, device)\n            probs.append(_probs)\n        probs = np.mean(probs, axis=0)\n        return probs\n\ndf['predict'] = submit()\nprint(df.head())\nscore = auc(df['label'].values[:],df['predict'])\nprint(\"=====AUC(inner_test)======\",score)","a2cae734":"#check test_df\npd.set_option('display.max_rows', 500)\ntest_df = test\ntest_df[\"abs_pred-true\"] = np.abs(test_df[\"predict\"]-test_df[\"label\"])\ntest_df = test_df.sort_values('abs_pred-true', ascending=False)\ntest_df.head(30)\n","5af82c7d":"mistake_file = test_df[\"file\"].values[0]\nprint(mistake_file)\nimage = skimage.io.MultiImage(mistake_file)[0]\nimage = cv2.resize(image,(SIZE,SIZE))\nplt.imshow(image)\nplt.show()\nprint(\"label:1,predict:\t0.150904\")","e03dd52b":"mistake_file = test_df[\"file\"].values[1]\nprint(mistake_file)\nimage = skimage.io.MultiImage(mistake_file)[0]\nimage = cv2.resize(image,(SIZE,SIZE))\nplt.imshow(image)\nplt.show()\nprint(\"label:1,predict:0.306142\")","c502a46f":"china = pd.read_csv(\"\/kaggle\/input\/panda-efnetb2-180-weight\/china_gla.csv\")\nchina.head()","3433230d":"%%time\nfile_path = china['filename'].values[0]\nfile_path = \"\/kaggle\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/Training Images\/{}\".format(file_path)\nimage = cv2.imread(file_path)\nimage = cv2.resize(image,(SIZE,SIZE))\nplt.imshow(image)\nplt.show()","cb83368a":"a = china.head(300)\nb = china.tail(300)\nchina = pd.concat([a,b])\nchina=china.reset_index()","1f026abd":"\nclass TestDataset_china(Dataset):\n    def __init__(self, df, transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['filename'].values[idx]\n        file_path = \"\/kaggle\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/Training Images\/{}\".format(file_path)\n        image = cv2.imread(file_path)\n        image = cv2.resize(image,(SIZE,SIZE))\n        label = self.df[\"Gla\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n        return image\n    \nweights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(0)\nmodel = baseline_model()\nstate_dict = torch.load(weights_path,map_location=device)\nmodel.load_state_dict(state_dict)\ntest_dataset = TestDataset_china(china, transform1=get_transforms1(data='valid'),transform2=to_tensor())\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n_probs = inference(model,test_loader, device)\n\nscore = auc(china['Gla'].values[:],_probs)\nprint(\"=====AUC(china_single_fold)======\",score)","746f51d0":"china['Gla'].values[:10]","44d3b792":"_probs[:10]","e8dd868c":"test.head(20)","8fc02a05":"import warnings\nwarnings.simplefilter('ignore')\n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n            return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file'].values[idx]\n        image = skimage.io.MultiImage(file_path)[0]\n        image = cv2.resize(image,(SIZE,SIZE))\n        original = image\n        label = self.df[\"label\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n        return image,original,label\nweights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(0)\nmodel = baseline_model()\nstate_dict = torch.load(weights_path,map_location=device)\nmodel.load_state_dict(state_dict)\ndef getCAM(img,weight_fc,j=0):\n    m = torchvision.models.resnet18(pretrained =False)\n    m.fc = nn.Linear(m.fc.in_features, 1)\n    state_dict = torch.load(\"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(0),map_location=device)\n    m.load_state_dict(fix_model_state_dict(state_dict))\n    m = nn.Sequential(*list(m.children())[:-2])\n    m.to(device)\n    with torch.no_grad():\n        feature_conv = m(img).cpu().detach().numpy()\n    bs, nc, h, w = feature_conv.shape\n    #print(bs)\n    cam = weight_fc.dot(feature_conv[j,:, :, ].reshape((nc, h*w)))\n    cam = cam.reshape(h, w)\n    cam = cam - np.min(cam)\n    cam_img = cam \/ np.max(cam)\n    return cam_img\n\ncheck = train\n\ntest_dataset = TestDataset(check, transform1=None,transform2=to_tensor())\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nmodel.to(device) \n    \nprobs = []\nfig = plt.figure(figsize=(20, 15))\n\nfc_params = list(model.model.fc.parameters())\nweight = np.squeeze(fc_params[0].cpu().data.numpy())\nimg_size =512\n\nfor i, (images,original,label) in tqdm(enumerate(test_loader), total=len(test_loader)):\n    images = images.to(device)\n    with torch.no_grad():\n        y_preds = model(images.float())\n        y_preds = torch.sigmoid(y_preds.view(-1))\n    if i <10:\n        cur_images = images.cpu().permute(0,2,3,1).detach().numpy()\n        for j in range(cur_images.shape[0]):\n            #print(\"{0}\u30d0\u30c3\u30c1\u76ee\u3001{1}\u679a\u76ee\".format(i,j))\n            print('Label:{0}, Predict:{1}'.format(label.view(-1)[j], y_preds[j]))\n            ax = fig.add_subplot(100, 200, i+1, xticks=[], yticks=[])\n            plt.imshow(cv2.cvtColor(cur_images[j], cv2.COLOR_BGR2RGB))\n            #ax.set_title('Label:{0}, Predict:{1}'.format(label.view(-1)[j], y_preds[j]), fontsize=14)\n            plt.show()\n            heatmap = getCAM(images.float(), weight,j=j)\n            ax = fig.add_subplot(100, 200, i+1, xticks=[], yticks=[])\n            plt.imshow(cv2.cvtColor(cur_images[j], cv2.COLOR_BGR2RGB))\n            plt.imshow(cv2.resize(heatmap, (img_size, img_size), interpolation=cv2.INTER_LINEAR), alpha=0.5, cmap='jet')\n            plt.show()\n            #if j==0:break\n        \n            \n    \n    probs.append(y_preds.to('cpu').numpy())\n\nprobs = np.concatenate(probs)\nprint(\"AUC\",auc(check['label'].values[:],probs))\n","6f1f81ad":"class TrainDataset(Dataset):\n    def __init__(self, df, transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file'].values[idx]\n        image = skimage.io.MultiImage(file_path)[0]\n        image = cv2.resize(image,(SIZE,SIZE))\n        label = self.df[\"label\"].values[idx]\n        origin_img = image\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n\n        \n            \n        label = torch.tensor(label).float()\n        \n        return image, label,origin_img","54ee0c1e":"import torch.nn.functional as F\nclass SaveFeatures():\n    \"\"\" Extract pretrained activations\"\"\"\n    features = None\n    def __init__(self, m):\n        self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output):\n        self.features = ((output.cpu()).data).numpy()\n    def remove(self):\n        self.hook.remove()\n\n\ndef getCAM_(feature_conv, weight_fc, class_idx):\n    #Heatmap\u53d6\u5f97\n    print(\"feature_conv\",feature_conv)#None\n    _, nc, h, w = feature_conv.shape\n    cam = weight_fc.dot(feature_conv[0,:, :, ].reshape((nc, h*w)))\n    cam = cam.reshape(h, w)\n    cam = cam - np.min(cam)\n    cam_img = cam \/ np.max(cam)\n    return cam_img\n\n\ndef plotGradCAM(model, final_conv, fc_params, train_loader, \n                row=2, col=4, img_size=256, device='cuda', original=False):\n    for param in model.parameters():\n        param.requires_grad = False\n    model.to(device)\n    model.eval()\n    # save activated_features from conv\n    activated_features = SaveFeatures(final_conv)\n    # save weight from fc\n    weight = np.squeeze(fc_params[0].cpu().data.numpy())\n    # original images\n    if original:\n        fig = plt.figure(figsize=(20, 15))\n        for i, (img, target, org_img) in enumerate(train_loader):\n            if i ==0:\n                print(img.size())#bs,h,w,c\n            img = img.permute(0, 3, 1, 2)\n            if i ==0:\n                print(img.size())#bs,c,h,w\n            output = model(img.to(device))\n            \n            pred_idx = torch.sigmoid(output).to('cpu').numpy()\n            if i ==0:\n                print(\"\u5143\u753b\u50cf\",org_img.size())#1, 512, 512, 3\n            cur_images = org_img.numpy().transpose((0,1,2,3))\n            if i ==0:\n                print(\"cur_images\",cur_images.shape)#1, 512, 3, 512\n            ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n            plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n            ax.set_title('Label:{0}, Predict:{1}'.format(target[0], pred_idx[0]), fontsize=14)\n            if i == row*col-1:\n                break\n        plt.show()\n    # heatmap images\n    fig = plt.figure(figsize=(20, 15))\n    for i, (img, target, _) in enumerate(train_loader):\n        img = img.permute(0, 3, 1, 2)#bs,c,h,w\n        if i ==0:\n            print(\"val,img\",img.size())#1, 3, 512, 512\n            #print(\"check_label\",target)\n        output = model(img.to(device).float())\n        pred_idx = torch.sigmoid(output).to('cpu').numpy()#0~1\n        if i ==0:\n            print(\"pred_idx\",pred_idx)\n        cur_images = img.cpu().numpy().transpose((0,2,3,1))\n        if i ==0:\n            print(\"val,cur_images\",cur_images.shape)#1, 3, 512, 512\n        #heatmap = getCAM(activated_features.features, weight, pred_idx)\n        heatmap = getCAM(img, weight)\n        ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n        plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n        plt.imshow(cv2.resize(heatmap, (img_size, img_size), interpolation=cv2.INTER_LINEAR), alpha=1, cmap='jet')\n        ax.set_title('Label:{0}, Predict:{1}'.format(target[0], pred_idx[0]), fontsize=14)\n        if i == row*col-1:\n            break\n    plt.show()","0538ca9e":"class_loaders = []\n# we use fold=0 model for Grad-CAM\nfor fold in [0]:\n    \n    # idx\n    val_idx = folds[folds['fold'] == fold].index # check by val data\n    #val_idx = folds[folds['fold'] != fold].index # check by train data\n    \n    # prepare each label loader\n    for i in range(2):\n        valid_dataset = TrainDataset(folds.loc[val_idx][folds[CFG.target_col]==i].reset_index(drop=True),  \n                                     transform1=get_transforms1(data='valid'))\n        valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n        class_loaders.append(valid_loader)\nprint(class_loaders[0])","08527e99":"\"\"\"\nlabel = 1\nweights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(0)\nmodel = baseline_model(weights_path)\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=SIZE, device=device, original=True)\"\"\"","d6a97c26":"\"\"\"\nlabel = 0\nweights_path = \"\/kaggle\/working\/fold{}_resnet18_baseline.pth\".format(0)\nmodel = baseline_model(weights_path)\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=SIZE, device=device, original=True)\"\"\"","5988ba1c":"OScular\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\uff08\u4ee5\u4e0b\u4e2d\u56fd\u7523\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u547c\u3076\uff09\u306f\u5206\u96e2\u304c\u96e3\u3057\u305d\u3046\u3002","46927a9d":"glaucomadataset\u7531\u6765\u306e\u30c7\u30fc\u30bf\u306f\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306b\u901a\u3057\u305f\u30d9\u30af\u30c8\u30eb\u3092\u6b21\u5143\u5727\u7e2e\u3059\u308b\u3068\u5272\u3068\u306f\u3063\u304d\u308a\u75be\u60a3\u304b\u5426\u304b\u304c\u5225\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3002"}}