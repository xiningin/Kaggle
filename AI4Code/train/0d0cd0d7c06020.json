{"cell_type":{"7e568e85":"code","06d45068":"code","abcf34c4":"code","a9417461":"code","eb8a78f2":"code","8d800ad1":"code","f8b7ab68":"code","4c287e96":"code","0cae2f04":"code","ecf79532":"code","281f64cd":"code","857ee71b":"code","65df5a1b":"code","3227ae23":"code","83ba7d12":"code","54bce99a":"code","0588b721":"code","1dad8fb6":"code","2b21346b":"code","26fe3c24":"code","ec103207":"code","f8c6bd2d":"code","63d67505":"code","c61604ed":"code","fa7b7b96":"code","a93ecdc4":"code","fb7b8958":"code","ebc26dcf":"code","09fd2837":"code","cf390bf2":"code","6164d40c":"code","9320dbfd":"code","de143605":"code","25542b55":"code","7d79d65a":"code","a8fd6b2a":"code","ea071710":"markdown","b868f5f0":"markdown","4b5b3cc5":"markdown","fd884f7e":"markdown","fb909018":"markdown","c32da34f":"markdown","85c9bae4":"markdown","0bce5fbd":"markdown","c29165e6":"markdown","1840a859":"markdown","ba375f16":"markdown","e470bc40":"markdown","22f2b584":"markdown","8d2820ba":"markdown","679a5716":"markdown","3fd0ed4a":"markdown","573be6d9":"markdown","f5ebd37c":"markdown"},"source":{"7e568e85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","06d45068":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost","abcf34c4":"data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nprint(\"Data shape: \", data.shape)\nprint(\"Duplicates: \", data.duplicated().sum())\nprint()\nprint(data.isnull().sum())\nprint()\ndata.head()","a9417461":"df = data.copy()","eb8a78f2":"numerics = ['int64', 'float64']\nnumerical = df[[c for c,v in df.dtypes.items() if v in numerics]]\ncategorical = df[[c for c,v in df.dtypes.items() if v not in numerics]]","8d800ad1":"for col in numerical.columns:\n    numerical.fillna(numerical[col].mean(), inplace=True, axis=1)","f8b7ab68":"X = numerical.drop(['Id', 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold', 'SalePrice'], axis=1)\nY = numerical[['SalePrice']]\nprint(X.shape, Y.shape)","4c287e96":"scaler = StandardScaler()\nscaler.fit(X)\nX_ = scaler.transform(X)\nX = pd.DataFrame(data=X_, columns = X.columns)\nX.head()","0cae2f04":"xtrain ,xtest, ytrain, ytest = train_test_split(X.values, Y.values, test_size=0.25, random_state=12)\nprint(xtrain.shape, ytrain.shape)\nprint(xtest.shape, ytest.shape)","ecf79532":"model = LinearRegression(fit_intercept=True, n_jobs =1)\nmodel.fit(xtrain, ytrain)","281f64cd":"pred_LinearRegression = model.predict(xtest)","857ee71b":"def make_dataframe(pred, ytest, columns=5):\n    pp = pred.tolist()\n    ap = ytest.tolist()\n    #pp = np.squeeze(pp, axis=1)\n    #ap = np.squeeze(ap, axis=1)\n    data = pd.DataFrame({\n        'Predicted Price' : pp,\n        'Actual Price' : ap\n    })\n    return data.head(columns)","65df5a1b":"make_dataframe(pred_LinearRegression, ytest)","3227ae23":"def plot_predictions(pred, ytest):\n    sns.set_context('poster')\n    plt.figure(figsize=(12,8))\n    plt.plot(ytest[:100], label='original');\n    plt.plot(pred[:100], label='prediciton');\n    plt.legend();","83ba7d12":"plot_predictions(pred_LinearRegression, ytest)","54bce99a":"r2_LinearRegression = r2_score(pred_LinearRegression, ytest)\nr2_LinearRegression","0588b721":"mse_LinearRegression = mean_squared_error(ytest, pred_LinearRegression)\nmse_LinearRegression","1dad8fb6":"model = DecisionTreeRegressor(random_state=0)\nmodel.fit(xtrain, ytrain)","2b21346b":"pred_DecisionTreeRegressor = model.predict(xtest)","26fe3c24":"make_dataframe(pred_DecisionTreeRegressor, ytest)","ec103207":"plot_predictions(pred_DecisionTreeRegressor, ytest)","f8c6bd2d":"r2_DecisionTreeRegressor = r2_score(pred_DecisionTreeRegressor, ytest)\nr2_DecisionTreeRegressor","63d67505":"mse_pred_DecisionTreeRegressor = mean_squared_error(ytest, pred_DecisionTreeRegressor)\nmse_pred_DecisionTreeRegressor","c61604ed":"model = RandomForestRegressor(n_estimators=300, random_state=0)\nmodel.fit(xtrain, ytrain)","fa7b7b96":"pred_RandomForestRegressor = model.predict(xtest)","a93ecdc4":"make_dataframe(pred_RandomForestRegressor, ytest)","fb7b8958":"plot_predictions(pred_RandomForestRegressor, ytest)","ebc26dcf":"r2_RandomForestRegressor = r2_score(pred_RandomForestRegressor, ytest)\nr2_RandomForestRegressor","09fd2837":"mse_RandomForestRegressor = mean_squared_error(ytest, pred_RandomForestRegressor)\nmse_RandomForestRegressor","cf390bf2":"model = xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.001,\n                 max_depth=3,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.75,\n                 reg_lambda=0.45,\n                 subsample=0.6,\n                 seed=42)\nmodel.fit(xtrain, ytrain)","6164d40c":"pred_XGBRegressor = model.predict(xtest)","9320dbfd":"make_dataframe(pred_XGBRegressor, ytest)","de143605":"plot_predictions(pred_XGBRegressor, ytest)","25542b55":"r2_XGBRegressor = r2_score(pred_XGBRegressor, ytest)\nr2_XGBRegressor","7d79d65a":"mse_XGBRegressor = mean_squared_error(ytest, pred_XGBRegressor)\nmse_XGBRegressor","a8fd6b2a":"results = pd.DataFrame({\n    'Algorithms' : ['Linear Regression', 'DecisionTreeRegressor', 'RandomForestRegressor', 'XGBRegressor'],\n    'r2 Score' : [r2_LinearRegression, r2_DecisionTreeRegressor, r2_RandomForestRegressor, r2_XGBRegressor],\n    'Mean Square Error' : [mse_LinearRegression, mse_pred_DecisionTreeRegressor, mse_RandomForestRegressor, mse_XGBRegressor]\n})\nresults","ea071710":"#### r2 Score","b868f5f0":"#### Mean Squared Error","4b5b3cc5":"#### r2 Score","fd884f7e":"### Dropping columns","fb909018":"## List of Mean Squared Error and r2 Scores","c32da34f":"#### r2 Score","85c9bae4":"#### r2 Score","0bce5fbd":"## Linear Regression","c29165e6":"## DecisionTreeRegressor","1840a859":"#### Mean Squared Error","ba375f16":"## RandomForestRegressor","e470bc40":"### Spliting data in numerical and catagorical","22f2b584":"#### Mean Squared Error","8d2820ba":"## XGBRegressor","679a5716":"#### Mean Squared Error","3fd0ed4a":"### Scaling Data","573be6d9":"### Spliting data in test and train","f5ebd37c":"### Filling missing values with mean"}}