{"cell_type":{"1a9ce592":"code","9b52e7c1":"code","f84ab6a2":"code","923607da":"code","54208b17":"code","50a11702":"code","0f5a2eb5":"code","a87a0dff":"code","fcd43a57":"code","80d717f2":"code","49c871e2":"code","9d62430d":"code","b68232d7":"code","4871d5b5":"code","1fa86bfa":"code","5e362e35":"code","b49fc518":"code","a044ebfc":"code","cf20c805":"code","8fd85b05":"code","ddf9e291":"code","37e27d8c":"code","2a392a74":"code","83878377":"code","5c212bac":"code","718a2ba7":"code","b0ab83eb":"code","78eabb84":"code","6246c9be":"code","78f96318":"code","27f2366d":"code","7d3d18f3":"code","82be0e12":"markdown","916fb6a5":"markdown","75c6248a":"markdown","2b4b4098":"markdown","13c5c276":"markdown","65af8e3b":"markdown","3d86891a":"markdown","ecb119f0":"markdown","8087d442":"markdown","f1c58aa8":"markdown","359a98ce":"markdown","86cc7b82":"markdown","3bfc3336":"markdown","11aac6e0":"markdown","bdd6c1b0":"markdown","e85b6112":"markdown","7ebfe91b":"markdown","a9433d4d":"markdown","667f463e":"markdown","0bb0f279":"markdown","2f59a07e":"markdown","08353a5a":"markdown"},"source":{"1a9ce592":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b52e7c1":"import warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline","f84ab6a2":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","923607da":"df.info()","54208b17":"df.head()","50a11702":"plt.figure(figsize=(12,6))\nsns.distplot(df['age'], bins=50, color='tab:purple', kde=False)\nplt.xlabel('Patient Age', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.title('Distribution of Patient Age', fontsize=18)\nplt.show()","0f5a2eb5":"plt.figure(figsize=(12,6))\nsns.boxplot(data=df, x='sex', y='age', palette='Set1')\nplt.xticks([0,1], ['Female', 'Male'])\nplt.xlabel('Patient Sex', fontsize=12)\nplt.ylabel('Patiient Age', fontsize=12)\nplt.title('Patient Age Distribution Based on Sex', fontsize=18)\nplt.show()","a87a0dff":"plt.figure(figsize=(12,20))\n\nplt.subplot(411)\nsns.violinplot(data=df, x = 'sex', y = 'age', hue = 'DEATH_EVENT', palette = 'Set1')\nplt.xticks([0,1], ['Female', 'Male'])\nplt.xlabel('Patient Sex', fontsize = 12)\nplt.ylabel('Patient Age', fontsize = 12)\nplt.legend(loc='center left', bbox_to_anchor = (1, 0.5), title = 'Death Event', fontsize=12)\nplt.title('Patient Age Distribution Based on Sex and Survival Outcome', fontsize=18)\n\nplt.subplot(412)\nsns.violinplot(data=df, x = 'smoking', y = 'age', hue = 'DEATH_EVENT', palette = 'Set1')\nplt.xticks([0,1], ['No', 'Yes'])\nplt.xlabel('Smoker', fontsize = 12)\nplt.ylabel('Patient Age', fontsize = 12)\nplt.legend(loc='center left', bbox_to_anchor = (1, 0.5), title ='Death Event', fontsize=12)\nplt.title('Patient Age Distribution Based on Smoker Class and Survival Outcome', fontsize=18)\n\nplt.subplot(413)\nsns.violinplot(data=df, x = 'diabetes', y = 'age', hue = 'DEATH_EVENT', palette = 'Set1')\nplt.xticks([0,1], ['No', 'Yes'])\nplt.xlabel('Diabetic Patient', fontsize = 12)\nplt.ylabel('Patient Age', fontsize = 12)\nplt.legend(loc='center left', bbox_to_anchor = (1, 0.5), title = 'Death Event', fontsize=12)\nplt.title('Patient Age Distribution Based on Diabetes Class and Survival Outcome', fontsize=18)\n\nplt.subplot(414)\nsns.violinplot(data=df, x = 'anaemia', y = 'age', hue = 'DEATH_EVENT', palette = 'Set1')\nplt.xticks([0,1], ['No', 'Yes'])\nplt.xlabel('Anaemic Patient', fontsize = 12)\nplt.ylabel('Patient Age', fontsize = 12)\nplt.legend(loc='center left', bbox_to_anchor = (1, 0.5), title = 'Death Event', fontsize=12)\nplt.title('Patient Age Distribution Based on Anaemia Class and Survival Outcome', fontsize=18)\n\nplt.subplots_adjust(hspace=0.4)\nplt.show()","fcd43a57":"plt.figure(figsize=(12,20))\n\nplt.subplot(411)\nsns.distplot(df[df['DEATH_EVENT']==1]['creatinine_phosphokinase'], \n             bins=50, label = 'Survived', color = 'blue', kde=False)\nsns.distplot(df[df['DEATH_EVENT']==0]['creatinine_phosphokinase'], \n             bins=50, label = 'Died', color = 'red', kde=False)\nplt.xlabel('Creatine Phosphokinase', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.legend()\nplt.title('Creatinine Phosphokinase Distribution', fontsize=14)\n\nplt.subplot(412)\nsns.distplot(df[df['DEATH_EVENT']==0]['serum_sodium'], \n             bins=50, label = 'Survived', color = 'blue', kde=False)\nsns.distplot(df[df['DEATH_EVENT']==1]['serum_sodium'], \n             bins=50, label = 'Died', color = 'red', kde=False)\nplt.xlabel('Serum Sodium', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.legend()\nplt.title('Serum Sodium Distribution', fontsize=14)\n\nplt.subplot(413)\nsns.distplot(df[df['DEATH_EVENT']==0]['serum_creatinine'], \n             bins=50, label = 'Survived', color = 'blue', kde=False)\nsns.distplot(df[df['DEATH_EVENT']==1]['serum_creatinine'], \n             bins=50, label = 'Died', color = 'red', kde=False)\nplt.xlabel('Serum Creatinine', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.legend()\nplt.title('Serum Creatinine Distribution', fontsize=14)\n\nplt.subplot(414)\nsns.distplot(df[df['DEATH_EVENT']==0]['ejection_fraction'], \n             bins=50, label = 'Survived', color = 'blue', kde=False)\nsns.distplot(df[df['DEATH_EVENT']==1]['ejection_fraction'], \n             bins=50, label = 'Died', color = 'red', kde=False)\nplt.xlabel('Ejection Fraction', fontsize=12)\nplt.ylabel('Counts', fontsize=12)\nplt.legend()\nplt.title('Ejection Fraction Distribution', fontsize=14)\n\nplt.subplots_adjust(hspace=0.45)\nplt.show()","80d717f2":"plt.figure(figsize=(12,6))\nsns.distplot(df[df['DEATH_EVENT']==0]['time'], kde=False, bins=50, color='b', label = 'Survived')\nsns.distplot(df[df['DEATH_EVENT']==1]['time'], kde=False, bins=50, color='r', label = 'Died')\nplt.xlabel('Follow up Period (Days)', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title('Distribution of Patients Follow Up Period', fontsize=18)\nplt.legend()\nplt.show()","49c871e2":"plt.figure(figsize=(14,14))\n\nplt.subplot(221)\nsmoker = df[df['smoking']==1]\nsmoker_surv = smoker[df['DEATH_EVENT']==0]['smoking']\nsmoker_died = smoker[df['DEATH_EVENT']==1]['smoking']\nsmoker_vals = [len(smoker_surv), len(smoker_died)]\nlabels = ['Survived', 'Died']\nplt.pie(smoker_vals, autopct='%1.1f%%', textprops=dict(color='black', size=20), colors=['tab:blue', \n                                                                                        'tab:red'])\nplt.legend(labels, loc='best', bbox_to_anchor=(1,0.5))\nplt.title('Smoker Patient', fontsize = 18)\n\nplt.subplot(222)\nhbp = df[df['high_blood_pressure']==1]\nhbp_surv = hbp[df['DEATH_EVENT']==0]['high_blood_pressure']\nhbp_died = hbp[df['DEATH_EVENT']==1]['high_blood_pressure']\nhbp_vals = [len(hbp_surv), len(hbp_died)]\nlabels = ['Survived', 'Died']\nplt.pie(hbp_vals, autopct='%1.1f%%', textprops=dict(color='black', size=20), colors=['tab:blue', \n                                                                                        'tab:red'])\nplt.legend(labels, loc='best', bbox_to_anchor=(1,0.5))\nplt.title('High Blood Pressure Patient', fontsize = 18)\n\nplt.subplot(223)\nanaemia = df[df['anaemia']==1]\nanaemia_surv = anaemia[df['DEATH_EVENT']==0]['anaemia']\nanaemia_died = anaemia[df['DEATH_EVENT']==1]['anaemia']\ndiabetes_vals = [len(anaemia_surv), len(anaemia_died)]\nlabels = ['Survived', 'Died']\nplt.pie(diabetes_vals, autopct='%1.1f%%', textprops=dict(color='black', size=20), colors=['tab:blue', \n                                                                                        'tab:red'])\nplt.legend(labels, loc = 'best', bbox_to_anchor=(1,0.5))\nplt.title('Anemic Patient', fontsize = 18)\n\nplt.subplot(224)\ndiabetes = df[df['diabetes']==1]\ndiabetes_surv = diabetes[df['DEATH_EVENT']==0]['diabetes']\ndiabetes_died = diabetes[df['DEATH_EVENT']==1]['diabetes']\nanaemic_vals = [len(diabetes_surv), len(diabetes_died)]\nlabels = ['Survived', 'Died']\nplt.pie(anaemic_vals, autopct='%1.1f%%', textprops=dict(color='black', size=20), colors=['tab:blue', \n                                                                                        'tab:red'])\nplt.legend(labels, loc = 'best', bbox_to_anchor=(1,0.5))\nplt.title('Diabetic Patient', fontsize = 18)\n\nplt.show()","9d62430d":"plt.figure(figsize=(9,9))\n\nsmoker = df[df['smoking']==1]\nnon_smoker = df[df['smoking']==0]\n\nsmoker_surv = smoker[df['DEATH_EVENT']==0]\nsmoker_notsurv = smoker[df['DEATH_EVENT']==1]\nnon_smoker_surv = non_smoker[df['DEATH_EVENT']==0]\nnon_smoker_notsurv = non_smoker[df['DEATH_EVENT']==1]\n\nvals = [len(smoker_surv), len(smoker_notsurv), \n        len(non_smoker_surv), len(non_smoker_notsurv)]\n\nlabels = ['Smoker - Survived', 'Smoker - Died',\n          'Non-Smoker - Survived', 'Non-Smoker - Died']\n\nexplode = (0.01, 0.01, 0.01, 0.01)\n\nplt.pie(x=vals, autopct='%1.1f%%', \n        textprops=dict(c=\"black\", size=20), \n        explode = explode, startangle = 10, \n        wedgeprops={'width':0.75}, colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange'])\n\nplt.legend(labels, loc='center left', \n           bbox_to_anchor=(1, 0.5, 0.5, 0),\n           fontsize=16, handlelength=2, \n           handleheight=1)\n\nplt.title('Survival for Smokers and Non-Smokers', fontsize='20')\nplt.axis('tight')\nplt.show()","b68232d7":"plt.figure(figsize=(9,9))\n\nno_hbp = df[df['high_blood_pressure']==0]\nhbp = df[df['high_blood_pressure']==1]\n\nhbp_surv = hbp[df['DEATH_EVENT']==0]\nhbp_died = hbp[df['DEATH_EVENT']==1]\nno_hbp_surv = no_hbp[df['DEATH_EVENT']==0]\nno_hbp_died = no_hbp[df['DEATH_EVENT']==1]\n\nlabels = [ 'HBP - Survived', 'HBP - Died', \n         'No HBP - Survived', 'No HBP - Died']\n\nvals = [len(no_hbp_surv), len(no_hbp_died), \n        len(hbp_surv), len(hbp_died)]\n\nexplode = (0.01, 0.01, 0.01, 0.01)\n\nplt.pie(vals, autopct='%1.1f%%', \n        textprops=dict(c=\"black\", size=20), startangle = -75,\n        explode = explode, \n        wedgeprops={'width':0.75}, colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange'])\n\nplt.legend(labels, loc='center left', \n           bbox_to_anchor=(1, 0.5, 0.5, 0),\n           fontsize=16, handlelength=2, \n           handleheight=1)\n\nplt.title('Survival for Patients With and Without High Blood Pressure', fontsize=20)\nplt.axis('tight')\nplt.show()","4871d5b5":"plt.figure(figsize=(9,9))\n\nno_anaemia = df[df['anaemia']==0]\nanaemia = df[df['anaemia']==1]\n\nanaemia_surv = anaemia[df['DEATH_EVENT']==0]\nanaemia_died = anaemia[df['DEATH_EVENT']==1]\nno_anaemia_surv = no_anaemia[df['DEATH_EVENT']==0]\nno_anaemia_died = no_anaemia[df['DEATH_EVENT']==1]\n\nlabels = [ 'Anaemia - Survived', 'Anaemia - Died', \n         'No Anaemia - Survived', 'No Anaemia - Died']\n\nvals = [len(no_anaemia_surv), len(no_anaemia_died), \n        len(anaemia_surv), len(anaemia_died)]\n\nexplode = (0.01, 0.01, 0.01, 0.01)\n\nplt.pie(vals, autopct='%1.1f%%', \n        textprops=dict(c=\"black\", size=20), startangle = -55,\n        explode = explode, \n        wedgeprops={'width':0.75}, colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange'])\n\nplt.legend(labels, loc='center left', \n           bbox_to_anchor=(1, 0.5, 0.5, 0),\n           fontsize=16, handlelength=2, \n           handleheight=1)\n\nplt.title('Survival for Anaemic and Non-Anaemic Patients', fontsize=20)\nplt.axis('tight')\nplt.show()","1fa86bfa":"plt.figure(figsize=(9,9))\n\nno_diabetes = df[df['diabetes']==0]\ndiabetes = df[df['diabetes']==1]\n\ndiabetes_surv = diabetes[df['DEATH_EVENT']==0]\ndiabetes_died = diabetes[df['DEATH_EVENT']==1]\nno_diabetes_surv = no_diabetes[df['DEATH_EVENT']==0]\nno_diabetes_died = no_diabetes[df['DEATH_EVENT']==1]\n\nlabels = [ 'Diabetes - Survived', 'Diabetes - Died', \n         'No Diabetes - Survived', 'No Diabetes - Died']\n\nvals = [len(no_diabetes_surv), len(no_diabetes_died), \n        len(diabetes_surv), len(diabetes_died)]\n\nexplode = (0.01, 0.01, 0.01, 0.01)\n\nplt.pie(vals, autopct='%1.1f%%', \n        textprops=dict(c=\"black\", size=20), startangle = -52,\n        explode = explode, \n        wedgeprops={'width':0.75}, colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange'])\n\nplt.legend(labels, loc='center left', \n           bbox_to_anchor=(1, 0.5, 0.5, 0),\n           fontsize=16, handlelength=2, \n           handleheight=1)\n\nplt.title('Survival for Diabetic and Non-Diabetic Patients', fontsize=20)\nplt.axis('tight')\nplt.show()","5e362e35":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), cmap='coolwarm', annot=True, vmin=-1)\nplt.show()","b49fc518":"from sklearn.model_selection import train_test_split","a044ebfc":"#Selecting the relevant features\nfeatures = ['ejection_fraction', 'serum_creatinine', 'time']\nX = df[features]\ny = df['DEATH_EVENT']","cf20c805":"#Test size chosen to be 25% of data entries\n#Hence, 224 entries to train the model and 75 entries to test the predictions against \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)","8fd85b05":"from sklearn.svm import SVC","ddf9e291":"classifier = SVC()\nclassifier.fit(X_train, y_train)","37e27d8c":"y_preds = classifier.predict(X_test)","2a392a74":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","83878377":"print(classification_report(y_test, y_preds))","5c212bac":"plt.figure(figsize=(9,9))\ncon_matrix = confusion_matrix(y_test, y_preds)\nsns.heatmap(con_matrix, cmap='YlGnBu', annot=True, \n            cbar=False, square=True,\n            xticklabels=['No Heart Failure', 'Heart Failure'], \n            yticklabels=['No Heart Failure', 'Heart Failure'] )\n\nplt.yticks(rotation=0, fontsize = 12)\nplt.xticks(fontsize=12)\n\nplt.ylabel('True Label', fontsize=14)\nplt.xlabel('Predicted Label', fontsize=14)\nplt.title('Support Vector Classifier - Confusion Matrix', fontsize=20)\nplt.show()","718a2ba7":"y_test = np.array(y_test)\nnp.concatenate((y_test.reshape(len(y_test),1), y_preds.reshape(len(y_preds),1)),1)","b0ab83eb":"np.concatenate((y_test.reshape(len(y_test),1), y_preds.reshape(len(y_preds),1)),1)[34]","78eabb84":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","6246c9be":"log_class = LogisticRegression()\nlog_class.fit(X_train, y_train)\n\nknn_class = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_class.fit(X_train, y_train)\n\nnb_class = GaussianNB()\nnb_class.fit(X_train, y_train)\n\ntree_class = DecisionTreeClassifier(criterion='entropy')\ntree_class.fit(X_train, y_train)\n\nrf_class = RandomForestClassifier(criterion='entropy')\nrf_class.fit(X_train, y_train)","78f96318":"log_preds = log_class.predict(X_test)\nlog_acc = accuracy_score(y_test, log_preds)\n\nknn_preds = knn_class.predict(X_test)\nknn_acc = accuracy_score(y_test, knn_preds)\n\nnb_preds = nb_class.predict(X_test)\nnb_acc = accuracy_score(y_test, nb_preds)\n\ntree_preds = tree_class.predict(X_test)\ntree_acc = accuracy_score(y_test, tree_preds)\n\nrf_preds = rf_class.predict(X_test)\nrf_acc = accuracy_score(y_test, rf_preds)","27f2366d":"accuracy_list = []\nsvc_acc = accuracy_score(y_test, y_preds)\n\naccuracy_list.append(100*svc_acc)\naccuracy_list.append(100*log_acc)\naccuracy_list.append(100*knn_acc)\naccuracy_list.append(100*nb_acc)\naccuracy_list.append(100*tree_acc)\naccuracy_list.append(100*rf_acc)","7d3d18f3":"plt.figure(figsize=(14,7))\n\n#Labels for the respective models used\nclassifier_list = ['SVC', 'Logistic Regression','KNN', 'Naive Bayes', 'DecisionTree', 'RandomForest']\n#Creating the barplot and showing the accuracy score for each method\nchart = sns.barplot(x=classifier_list, y=accuracy_list, palette = 'tab10')\nfor p in chart.patches:\n             chart.annotate(\"%.f\" % p.get_height(), (p.get_x() + p.get_width() \/ 2., p.get_height()),\n                 ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n                 textcoords='offset points')\n\nplt.xlabel('Classifier Type', fontsize=14)\nplt.ylabel('Accuracy Score (%)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.title('Accuracy Score for Different Classification Methods', fontsize=20)\n\nplt.show()","82be0e12":"With the particular parameters chosen (these being the relevant features from the original data frame (X) and the model test_size and random_state) we have achieved an accuracy of 91%. Hence, of the 75 DEATH_EVENT predictions made, the model accurately classified 68. Lets take a closer look at this result by visualising the confusion matrix. ","916fb6a5":"**One of the features present in the dataset is the follow up period (in days) for each patient, labelled as 'time'. Lets explore how this feature is distributed between patients who survived and those who died.**","75c6248a":"As shown above, for the patients randomly chosen from the dataset when the data was split, the model correctly classified 53 instances of no heart failure and 15 instances of heart failure. We are then left with 7 cases of incorrect classification. More specifically, we have 2 cases of false positives, where patients were classified as having died when in fact they survived, and 5 cases of false negatives, where patients were classified as having survived when in fact they died. ","2b4b4098":"**Lets take a look at the correlation between the different features.**","13c5c276":"**Reading the data.**","65af8e3b":"**Just as a quick exercise, lets compare accuracy score between the SVC method detailed above and other possible classification methods. The data is split the same way following the specifications used for the trian_test_split method applied previously.** ","3d86891a":"# Applying Different Classification Methods","ecb119f0":"# Importing the Data and Relevant Packages","8087d442":"**Lets take this a step further and explore the age distribution for patients who died and those who survived based on whether they were male or female, smokers or non-smokers, diabetic or not diabetic and anaemic or not anaemic. From the classification found in the dataset itself, a patient's survival or death is indicated by a value of 0 or 1, respectively, within the DEATH_EVENT column.**","f1c58aa8":"# Evaluating Performance","359a98ce":"More than 60% of patients who fall under the category of smoker, having high blood pressure, being anaemic and being diabetic survived. What about when we include the patients that do not have any of these features? What is the split between survival and death for all 299 entries?","86cc7b82":"**Lets take a look at the distribution of patients' creatinine phosphokinase, serum sodium, serum creatinine and ejection fraction. Once again, we can split the data between patients who survived and those who died.**","3bfc3336":"This quick comparison shows that SVC, along with Random Forest, returns the best accuracy score when compared to other classification methods. This value, however, will vary depending on the conditions specified in the train_test_split.","11aac6e0":"# Predicting Patient Survival","bdd6c1b0":"**Lets now build the classification model. For this particular case, a Support Vector Machine Classifier will be used.**","e85b6112":"From the heatmap above, we can see that the 3 features most correlated (both positvely and negatively) with a patient's survival outcome (DEATH_EVENT) are ejection fraction, serum_creatinine and time. Therefore, when splitting the data into a train and test set, we can explicitely select the three features mentioned instead of the complete dataset.","7ebfe91b":"**Lets take a quick look at the type of data in the dataset and the first 5 entries:**","a9433d4d":"Here, we see that for the first patient entry, the true label was 0 and our model predicted 0 i.e. patient survived and we predicted that they survived. For the second entry, our prediction was the same as the true value. For the third entry, the correct classification was made again and so on. The first error appears at entry number 34 as the patient died but was classified as having survived, as shown below. ","667f463e":"# Exploratory Data Analysis","0bb0f279":"**Four features which we may intuitively think will have an effect on a patient's survival are smoking, high blood pressure, anaemia and diabetes. Lets investigate the survival rate for the patients which fall in each category.**","2f59a07e":"**Lets explore the data to see how the different features present are distributed between the patients**","08353a5a":"**We can directly compare the DEATH_EVENT outcome (Survived = 0, Died = 1) from the test set (y_test) and predicted set (y_preds) by reshaping the relevant arrays to achieve a patient by patient examination.**"}}