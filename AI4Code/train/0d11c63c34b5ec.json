{"cell_type":{"6318c7e1":"code","9a633cd2":"code","1fcf4b68":"code","ebc9e2fb":"code","7b3e5b37":"code","3d58e037":"code","2d0980bc":"code","c8be1a76":"code","4b1eeb55":"code","857b3303":"code","11a73a50":"code","351388d3":"code","47677185":"code","d0b69fca":"code","e0b20c05":"code","859b4058":"code","d240d56b":"code","a901a116":"code","fafe3bb6":"code","0ec787a7":"code","a8929136":"code","4f357096":"code","8bdb3003":"code","b9b43754":"code","1502e4d3":"code","6aeb51ce":"code","6457feb4":"code","2bd2b87f":"code","0b9c927c":"code","290593a3":"code","5de7b338":"code","099e62e2":"code","996cef69":"code","05ad8b5c":"code","6fc46663":"code","91f0071a":"code","c70f0a80":"code","ffbabe38":"code","f44534b2":"code","4e41a50e":"code","755ff870":"code","6219e40b":"code","f8a748d2":"code","c865f741":"code","100a43f7":"code","881dd626":"code","1929a67b":"code","8d23ef54":"code","f172558c":"code","c2c6f35a":"code","69573d99":"code","63edbd55":"code","3eba83de":"code","afecc6bf":"code","b1b19a4c":"code","cd315835":"code","4266c71a":"code","ae3e5226":"code","4a13035f":"code","b64f90f3":"code","3d5c3ee2":"code","7a931f80":"code","661b9fe6":"code","41a765af":"code","5b9c8162":"code","5d1839af":"code","6d8609ec":"code","32af5673":"code","4362a60d":"code","5bd057de":"code","eb3d4ad9":"code","90373b7a":"code","113e8fc6":"code","7d17450c":"code","1ddb89f5":"code","39fc749f":"code","2f466903":"code","c251a220":"code","e68de52f":"code","c872b6d4":"code","48eb2333":"code","31721e78":"code","70e2f787":"code","a2cd5f39":"code","fd756f47":"code","8017daed":"code","10faa601":"code","adaa46f4":"code","a516dbda":"code","06b91bd2":"code","c6e98ac0":"code","eb1f392c":"code","5d41ea79":"code","858b564e":"code","97e7102d":"markdown","ab6b2ea0":"markdown","1353188f":"markdown","61f3c952":"markdown","67b75a40":"markdown","5f24f68c":"markdown","5b678765":"markdown","53c7bffd":"markdown","8fc1e798":"markdown","67ab62cc":"markdown","3e9ad597":"markdown","3b214463":"markdown","5a810ef0":"markdown","b86f3567":"markdown","f946bd1a":"markdown","43377d90":"markdown","037addda":"markdown","9008e480":"markdown","fcfd4810":"markdown","41306ac0":"markdown","a53d55dc":"markdown","51e16765":"markdown","b378bedf":"markdown","7bf98173":"markdown","a2e03ac8":"markdown","7bdeb3b5":"markdown","951a82b4":"markdown","aee3bb61":"markdown","d9cf20d7":"markdown","f1f3a25c":"markdown"},"source":{"6318c7e1":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nfrom itertools import product\nimport pickle\nimport scipy.stats as ss\n\nimport missingno as msno\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML\nimport seaborn as sns\npd.options.plotting.backend =  'matplotlib'#\"plotly\"\n\nimport IPython\ndef display(*dfs):\n    for df in dfs:\n        IPython.display.display(df)","9a633cd2":"def get_time_features(df):\n    df['year'] = df.index.year\n    df['month'] = df.index.month\n    df['weekofyear'] = df.index.isocalendar().week\n    df['day'] = df.index.day\n    df['dayofyear'] = df.index.dayofyear\n    df['quarter'] = df.index.quarter","1fcf4b68":"## visualization functions\n\ndef autolabel(xx, yy, names, ax):\n    for x, y, ann in zip(xx, yy, names):\n        ax.annotate('{}'.format(ann),\n                    xy=(x, y),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n        \n        \ndef plot_window_corr(df, features_main, features_lag, trend='positive', ewm_max=7):\n    \"\"\" Calculate correlation coeffitients between targets (from features_main) and \n    fueatures_lag. Features are exp smoothed for different windows (from 0 up to ewm_max).\n    Results are ploted on grapth with highlighted optimal values of window.\n    Also, resuls with optimel windows are returned as list of dict\"\"\"\n    \n    res_lags = []\n    rows, cols = len(features_main),len(features_lag)\n    fig, axes = plt.subplots(rows,cols, figsize=(cols*4,rows*4))\n\n    if not isinstance(axes, np.ndarray): axes = np.array([[axes]])\n    if axes.shape != (rows, cols): axes = axes.reshape((rows, cols))\n    for f1,ax in zip(features_main, axes):\n        for f2, ax0 in zip(features_lag, ax):\n            res, to_add = [], {}\n            to_add['f_main'] = f1\n            to_add['f_lag'] = f2\n            for i in range(ewm_max):\n                temp = df[[f1,f2]].copy()#.ewm(i).mean()\n                temp[f2] = temp[f2].ewm(i,  min_periods=65).mean()#.shift(i)\n                temp = temp.dropna()\n                res.append(ss.pearsonr(temp[f1], temp[f2]))\n\n            res = pd.DataFrame(res, columns=['corr', 'p'])\n            res['significant'] = np.where(res.p <= 0.05,'black', 'blue')\n            res.reset_index().plot(kind='scatter', x='index', y='corr', \n                                   color=res['significant'], ax=ax0)\n            \n            if trend == 'positive':\n                res.loc[res['corr'] <= 0, 'corr']  = np.nan # take only positives\n                ax0.plot([res['corr'].argmax()]*2, [res['corr'].min(), res['corr'].max()])\n                autolabel([res['corr'].argmax()], [res['corr'].max()], [f'{res[\"corr\"].argmax()}'], ax=ax0)\n                to_add['lag'] = res[\"corr\"].argmax()\n            elif trend == 'negative':\n                res.loc[res['corr'] >= 0, 'corr']  = np.nan # take only negatives \n                ax0.plot([res['corr'].argmin()]*2, [res['corr'].min(), res['corr'].max()])\n                autolabel([res['corr'].argmin()], [res['corr'].min()], [f'{res[\"corr\"].argmin()}'], ax=ax0)\n                to_add['lag'] = res[\"corr\"].argmin()\n            \n            res_lags.append(to_add)\n            ax0.set_title(f1)\n\n    for ax, f2 in zip(axes.ravel()[:cols], features_lag):\n        ax.set_title(f2,  fontweight='bold')\n        \n    return res_lags\n\n\ndef format_res_windows(res_windows, features_depth, features_rainfall):\n    res = pd.pivot_table(pd.DataFrame(res_windows), index='f_main', columns='f_lag', values='lag').reindex(index=features_depth, columns=features_rainfall)\n    return res, res.style.background_gradient(\"Blues_r\", axis=1)\n\n\ndef plot_corr_for_targets(features_depth, features_rainfall, res_windows, auser_df):\n    rainfall_corr = []\n    for f_main, f_lag in product(features_depth, [f for f in features_rainfall]):\n        window = res_windows.loc[f_main, f_lag]\n        name = f'{f_lag}_{window}'\n        rainfall_corr.append(dict(f_main=f_main, f_lag=name, corr=auser_df[[f_main]].corrwith(auser_df[name]).iloc[0]))\n\n    rainfall_corr = pd.DataFrame(rainfall_corr)\n\n    fig, axes = plt.subplots(1, features_depth.__len__(), figsize=(25,5))\n    fig.subplots_adjust(wspace=1)\n    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n    for (f_main, gr), ax in zip(rainfall_corr.groupby('f_main'), \n                                axes.ravel()):\n        gr['f_lag'] = gr['f_lag'].str.replace('Rainfall_', '').str.replace('_mean', '')\n        ax.set_title(f_main)\n        sns.heatmap(gr.drop('f_main', axis=1).set_index('f_lag'),vmin=0, vmax=1, annot=True,\n                    cmap=cmap, ax=ax, cbar=False)\n        ax.set_ylabel(None)\n        \n    return rainfall_corr\n\n\ndef plot_dependencies_by_month(features_depth, features_lags, auser_df, rainfall_window):\n    rows, cols = len(features_depth), len(features_lags)\n    fig ,axes = plt.subplots(rows, cols,\n                             figsize=( len(features_lags)*4, len(features_depth)*4))\n    if axes.shape != (rows, cols): axes = axes.reshape((rows, cols))\n        \n    for f_main, axes_depth in zip(features_depth, axes):\n        features_lags = rainfall_window[f_main].keys()\n        for f_lag, ax in zip(features_lags, axes_depth):\n            f_lag = f'{f_lag}_{rainfall_window[f_main][f_lag]}'\n            temp = auser_df.groupby('month')[[f_main, f_lag]].mean().reset_index()\n            temp.plot(x=f_lag, y=f_main, ax=ax, \n                      colormap='Paired', style='-o')\n\n            for l1 in range(0, temp.shape[0]):\n                delta = (temp[f_lag].max() - temp[f_lag].min())*0.05\n                ax.text(temp[f_lag][l1]+delta, temp[f_main][l1], temp['month'][l1], \n                        horizontalalignment='left', \n                        size='medium', color='black', \n                        weight='semibold')\n","ebc9e2fb":"auser = pd.read_csv('\/kaggle\/input\/acea-water-prediction\/Aquifer_Auser.csv', parse_dates=['Date'], dayfirst=True,)\\\n                    .rename(columns={'Date':'date'}).set_index('date').sort_index()\npetrignano = pd.read_csv('\/kaggle\/input\/acea-water-prediction\/Aquifer_Petrignano.csv', parse_dates=['Date'], dayfirst=True,)\\\n                    .rename(columns={'Date':'date'}).set_index('date').sort_index()\ndoganella = pd.read_csv('\/kaggle\/input\/acea-water-prediction\/Aquifer_Doganella.csv', parse_dates=['Date'], dayfirst=True,)\\\n                    .rename(columns={'Date':'date'}).set_index('date').sort_index()\nluco = pd.read_csv('\/kaggle\/input\/acea-water-prediction\/Aquifer_Luco.csv', parse_dates=['Date'], dayfirst=True,)\\\n                    .rename(columns={'Date':'date'}).set_index('date').sort_index()","7b3e5b37":"from sklearn.preprocessing import LabelEncoder\nfrom geopy.geocoders import Nominatim\nimport folium\n\nlocations = {}\n\nlocations['Settefrati'] = {'lat' : 41.669624, 'lon' : 13.850011 }\nlocations['Velletri'] = {'lat' : 41.6867015, 'lon' : 12.7770433 }\nlocations['Petrignano'] = {'lat' : 43.1029282, 'lon' : 12.5237369 }\nlocations['Piaggione'] = {'lat' : 43.936794, 'lon' : 10.5040929 }\nlocations['S_Fiora'] = {'lat' : 42.854, 'lon' : 11.556 }\nlocations['Abbadia_S_Salvatore'] = {'lat' : 42.8809724, 'lon' : 11.6724203 }\nlocations['Vetta_Amiata'] = {'lat' : 42.8908958, 'lon' : 11.6264863 }\nlocations['Castel_del_Piano'] = {'lat' : 42.8932352, 'lon' : 11.5383804 }\nlocations['Terni'] = {'lat' : 42.6537515, 'lon' : 12.43981163 }\nlocations['Bastia_Umbra'] = {'lat' : 43.0677554, 'lon' : 12.5495816  }\nlocations['S_Savino'] = {'lat' : 43.339, 'lon' : 11.742 }\nlocations['Monteroni_Arbia_Biena'] = {'lat' : 43.228279, 'lon' : 11.4021433 }\nlocations['Monticiano_la_Pineta'] = {'lat' : 43.1335066 , 'lon' : 11.2408464 }\nlocations['Montalcinello'] = {'lat' : 43.1978783, 'lon' : 11.0787906 }\nlocations['Sovicille'] = {'lat' : 43.2806018, 'lon' : 11.2281756 }\nlocations['Simignano'] = {'lat' : 43.2921965, 'lon' : 11.1680079 }\nlocations['Mensano'] = {'lat' : 43.3009594 , 'lon' : 11.0548528 }\nlocations['Siena_Poggio_al_Vento'] = {'lat' : 43.1399762, 'lon' : 11.3832092 }\nlocations['Scorgiano'] = {'lat' : 43.3521445 , 'lon' : 11.15867 }\nlocations['Ponte_Orgia'] = {'lat' : 43.2074581 , 'lon' : 11.2504416 }\nlocations['Pentolina'] = {'lat' : 43.1968029, 'lon' : 11.1754672 }\nlocations['Montevarchi'] = {'lat' : 43.5234999, 'lon' : 11.5675911 }\nlocations['Incisa'] = {'lat' : 43.6558723, 'lon' : 11.4526838 }\nlocations['Camaldoli'] = {'lat' : 43.7943293, 'lon' : 11.8199481 }\nlocations['Bibbiena'] = {'lat' : 43.6955475, 'lon' : 11.817341 }\nlocations['Stia'] = {'lat' : 43.801537, 'lon' : 11.7067347 }\nlocations['Laterina'] = {'lat' : 43.5081823, 'lon' : 11.7102588 }\nlocations['Monteporzio'] = {'lat' : 41.817251, 'lon' : 12.7050839 }\nlocations['Pontetetto'] = {'lat' : 43.8226294, 'lon' : 10.4940843 }\nlocations['Ponte_a_Moriano'] = {'lat' : 43.9083609 , 'lon' : 10.5342488 }\nlocations['Calavorno'] = {'lat' : 44.0217216, 'lon' : 10.5297323 }\nlocations['Borgo_a_Mozzano'] = {'lat' : 43.978948, 'lon' : 10.545703  }\nlocations['Gallicano'] = {'lat' : 44.0606512, 'lon' : 10.435668  }\nlocations['Tereglio_Coreglia_Antelminelli'] = {'lat' : 44.0550548 , 'lon' : 10.5623594 }\nlocations['Lucca_Orto_Botanico'] = {'lat' : 43.84149865, 'lon' : 10.51169066 }\nlocations['Orentano'] = {'lat' : 43.7796506, 'lon' : 10.6583892 }\nlocations['Fabbriche_di_Vallico'] = {'lat' : 43.997647, 'lon' : 10.4279  }\nlocations['Monte_Serra'] = {'lat' : 43.750833, 'lon' : 10.555278 }\nlocations['Mangona'] = {'lat' : 44.0496863, 'lon' : 11.1958797 }\nlocations['Le_Croci'] = {'lat' : 44.0360503, 'lon' : 11.2675661 }\nlocations['Cavallina'] = {'lat' : 43.9833515, 'lon' : 11.2323312 }\nlocations['S_Agata'] = {'lat' : 43.9438247, 'lon' : 11.3089835 }\nlocations['Firenze'] = {'lat' : 43.7698712, 'lon' : 11.2555757 }\nlocations['S_Piero'] = {'lat' : 43.9637372, 'lon' : 11.3182991 }\nlocations['Vernio'] = {'lat' : 44.0440508 , 'lon' : 11.1498804  }\nlocations['Consuma'] = {'lat' : 43.784, 'lon' : 11.585 }\nlocations['Croce_Arcana']  = {'lat' : 44.1323056, 'lon' : 10.7689152 }\nlocations['Laghetto_Verde']  = {'lat' :   42.883, 'lon' : 11.662  }\n\nlocations_df = pd.DataFrame(columns=['city', 'lat', 'lon'] )\n\ndef get_location_coordinates(df, column_type, cluster, target_df):\n    for location in df.columns[df.columns.str.startswith(column_type)]:\n        location = location.split(column_type)[1]\n\n        loc_dict = {}\n        loc_dict['city'] = location\n        loc_dict['cluster'] = cluster\n        loc_dict['type'] = column_type[:-1]\n        loc_dict['lat'] = locations[location]['lat']\n        loc_dict['lon'] = locations[location]['lon']\n\n        target_df = target_df.append(loc_dict, ignore_index=True)\n\n    return target_df\n\nlocations_df = get_location_coordinates(auser, 'Temperature_', 'auser_df', locations_df)\nlocations_df = get_location_coordinates(auser, 'Rainfall_', 'auser_df', locations_df)\n\nlocations_df = get_location_coordinates(doganella, 'Temperature_', 'doganella_df', locations_df)\nlocations_df = get_location_coordinates(doganella, 'Rainfall_', 'doganella_df', locations_df)\n\nlocations_df = get_location_coordinates(luco, 'Temperature_', 'luco_df', locations_df)\nlocations_df = get_location_coordinates(luco, 'Rainfall_', 'luco_df', locations_df)\n\nlocations_df = get_location_coordinates(petrignano, 'Temperature_', 'petrignano_df', locations_df)\nlocations_df = get_location_coordinates(petrignano, 'Rainfall_', 'petrignano_df', locations_df)\n\n# locations_df = get_location_coordinates(lake_biliancino_df, 'Temperature_', 'lake_biliancino_df', locations_df)\n# locations_df = get_location_coordinates(lake_biliancino_df, 'Rainfall_', 'lake_biliancino_df', locations_df)\n\n# locations_df = get_location_coordinates(river_arno_df, 'Temperature_', 'river_arno_df', locations_df)\n# locations_df = get_location_coordinates(river_arno_df, 'Rainfall_', 'river_arno_df', locations_df)\n\n# locations_df = get_location_coordinates(water_spring_amiata_df, 'Temperature_', 'water_spring_amiata_df', locations_df)\n# locations_df = get_location_coordinates(water_spring_amiata_df, 'Rainfall_', 'water_spring_amiata_df', locations_df)\n\n# locations_df = get_location_coordinates(water_spring_lupa_df, 'Temperature_', 'water_spring_lupa_df', locations_df)\n# locations_df = get_location_coordinates(water_spring_lupa_df, 'Rainfall_', 'water_spring_lupa_df', locations_df)\n\n# locations_df = get_location_coordinates(water_spring_madonna_df, 'Temperature_', 'water_spring_madonna_df', locations_df)\n# locations_df = get_location_coordinates(water_spring_madonna_df, 'Rainfall_', 'water_spring_madonna_df', locations_df)\n\n# Drop duplicates\nlocations_df = locations_df.sort_values(by='city').drop_duplicates().reset_index(drop=True)\n\n# Label Encode cluster feature for visualization puposes\nle = LabelEncoder()\nle.fit(locations_df.cluster)\nlocations_df['cluster_enc'] = le.transform(locations_df.cluster)","3d58e037":"m = folium.Map(location=[42.6, 12.4], tiles='cartodbpositron',zoom_start=7)\n\ncolors = ['purple','lightred','green', 'lightblue', 'red', 'blue', 'darkblue','lightgreen', 'orange',  'darkgreen', 'beige',  'pink', 'darkred', 'darkpurple', 'cadetblue',]\nicons = {'Temperature': 'certificate',\n        'Rainfall': 'cloud'}\n\ngeolocator = Nominatim(user_agent='myapplication')\nfor city, gr in locations_df.groupby('city'):\n    if gr.shape[0] > 1: icon = 'th-list' \n    else: icon = icons[gr.iloc[0]['type']]\n    folium.Marker([gr.iloc[0].lat, \n                  gr.iloc[0].lon],\n                  popup=city, \n                  icon=folium.Icon(color=colors[gr.iloc[0].cluster_enc], icon=icon)).add_to(m)\n    \nm","2d0980bc":"import json\ngeo_file = json.load(open('\/kaggle\/input\/geo-data-water-italia\/geo_data.json', 'rb'))['features']\n\ngeo_dict = {}\nfor el in geo_file:\n    sea_level = el['description'].split()\n    try:\n        sea_level = float(sea_level[sea_level.index('[m]<\/b>')+1].replace('<br', ''))\n    except:\n        sea_level = None\n    geo_dict[el['name']] = dict(ids=el['id'], lat=el['lat'], lon=el['lon'], latlon=(el['lat'], el['lon']), sea_level=sea_level)    \n\ngeo_data = []\nfor df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features = df.columns\n    features = features.str.replace('Rainfall_', '').str.replace('Depth_to_Groundwater_', '')\\\n    .str.replace('Temperature_', '').str.replace('Volume_', '').str.replace('Hydrometry_', '')\\\n    .str.replace('_', ' ')\n    features = features.str.replace('Tereglio Coreglia Antelminelli', 'Tereglio')\\\n                        .str.replace('Lucca Orto Botanico', 'Lucca (Orto Botanico)')\\\n                        .str.replace('Monte S Quirico', 'Monte S.Quirico')\\\n                        .str.replace('Rainfall_Monticiano_la_Pineta', 'Rainfall_Monticiano_La_Pineta')\\\n    \n    \n    for f in features:\n        try:\n            geo_data.append(dict(**dict(aquifer=name, name=f), **geo_dict[f]))\n        except:\n            continue\n        \ngeo_data = pd.DataFrame(geo_data)\ngeo_data['name'] = geo_data['name'].str.replace('(','').str.replace(')', '').str.replace('.',' ')\n\nfor f in geo_data['name']:\n    geo_data.loc[geo_data['name']==f, 'feature_name'] = [x for x in auser.columns.tolist() + doganella.columns.tolist() + luco.columns.tolist() + petrignano.columns.tolist() \n                                                         if f.replace(' ', '_') in x ]\n\ngeo_data['type'] = geo_data.feature_name.str.split('_').apply(lambda x: x[0])\ngeo_data.head()","c8be1a76":"# check data on missing days\nfor df in [auser, doganella, luco, petrignano]:\n    shift = df.reset_index().date - auser.reset_index().date.shift(1)\n    assert shift.value_counts().shape[0] == 1","4b1eeb55":"get_time_features(auser)\nget_time_features(doganella)\nget_time_features(luco)\nget_time_features(petrignano)","857b3303":"# replace 0 depth in targets with nans\nfeatures_depth = [f for f in auser.columns if 'Depth' in f]\nauser[features_depth] = auser[features_depth].replace(0, np.nan)\n\nfeatures_depth = [f for f in luco.columns if 'Depth' in f]\nluco[features_depth] = luco[features_depth].replace(0, np.nan)","11a73a50":"for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features_rainfall = [f for f in df.columns if 'Rainfall' in f]\n    if features_rainfall.__len__() > 1:\n        fig, ax = plt.subplots(figsize=(20, 30))\n        df[features_rainfall].plot(subplots=True, layout=(20,2), ax=ax)\n    else:\n        fig, ax = plt.subplots(figsize=(10,5))\n        df[features_rainfall].plot(ax=ax)","351388d3":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_rainfall = [f for f in df.columns if 'Rainfall' in f]\n    temp = df[features_rainfall].resample('MS', ).mean()\n    temp['month'] = temp.index.month\n    temp.groupby('month').mean().plot(legend=False, title=name, ax=ax)\n    ax.set_ylabel('Rainfall')\n#     subplots=True, layout=(5,2), figsize=(10, 5*1.5));","47677185":"features_rainfall = features_depth = [f for f in luco.columns if 'Rainfall' in f]\ntemp = luco[features_rainfall].resample('MS').mean()\ntemp.max().sort_values()","d0b69fca":"features_rainfall = features_depth = [f for f in luco.columns if 'Rainfall' in f]\nluco[features_depth].describe()","e0b20c05":"from urllib import request","859b4058":"# for 0-24 hours range\ndownloaded_features0_24 = pd.DataFrame(columns=['date'])\nfor ids in geo_data[geo_data.type=='Rainfall'].ids:\n#                                 https:\/\/www.sir.toscana.it\/archivio\/download.php?IDST=pluvio0_24&IDS=TOS03002742\n    context = request.urlopen(f'https:\/\/www.sir.toscana.it\/archivio\/download.php?IDST=pluvio0_24&IDS={ids}').read().decode('utf-8')\n    to_add = pd.DataFrame([x.split(';') for x in context[context.find(\"gg\/mm\/aaaa\") -1:].replace('@', '').replace(',','.').split('\\r\\n')])\n    to_add = to_add.iloc[1:, :-1]\n    to_add.columns = ['date', f'{geo_data.loc[geo_data.ids==ids, \"feature_name\"].iloc[0]}']\n    \n    downloaded_features0_24 = downloaded_features0_24.merge(to_add, on='date', how='outer')\n    \ndownloaded_features0_24","d240d56b":"# for 9-9 hours range of day\ndownloaded_features9_9 = pd.DataFrame(columns=['date'])\nfor ids in geo_data[geo_data.type=='Rainfall'].ids:\n#                                 https:\/\/www.sir.toscana.it\/archivio\/download.php?IDST=pluvio0_24&IDS=TOS03002742\n    context = request.urlopen(f'https:\/\/www.sir.toscana.it\/archivio\/download.php?IDSTpluvio&IDS={ids}').read().decode('utf-8')\n    to_add = pd.DataFrame([x.split(';') for x in context[context.find(\"gg\/mm\/aaaa\") -1:].replace('@', '').replace(',','.').split('\\r\\n')])\n    to_add = to_add.iloc[1:, :-1]\n    to_add.columns = ['date', f'{geo_data.loc[geo_data.ids==ids, \"feature_name\"].iloc[0]}']\n    \n    downloaded_features9_9 = downloaded_features9_9.merge(to_add, on='date', how='outer')\n    \ndownloaded_features9_9","a901a116":"downloaded_features0_24.date = pd.to_datetime(downloaded_features0_24.date, dayfirst=True)\ndownloaded_features0_24.set_index('date', inplace=True)\ndownloaded_features0_24.sort_index(inplace=True)\ndownloaded_features0_24 = downloaded_features0_24.iloc[:-1]\ndownloaded_features0_24 = downloaded_features0_24.replace('', np.nan).astype('float')\n\ndownloaded_features9_9.date = pd.to_datetime(downloaded_features9_9.date, dayfirst=True)\ndownloaded_features9_9.set_index('date', inplace=True)\ndownloaded_features9_9.sort_index(inplace=True)\ndownloaded_features9_9 = downloaded_features9_9.iloc[:-1]\ndownloaded_features9_9 = downloaded_features9_9.replace('', np.nan).astype('float')","fafe3bb6":"# compare 3 datasets\ntemp = downloaded_features0_24[['Rainfall_Pentolina']].merge(downloaded_features9_9[['Rainfall_Pentolina']], left_index=True, right_index=True)\ntemp.columns = ['0_24', '9_9']\ntemp = temp.merge(luco.Rainfall_Pentolina, left_index=True, right_index=True)\ntemp.plot(subplots=True)\ntemp.plot();","0ec787a7":"# get differences between downloaded data and our\ntemp_diff = pd.concat(((temp.Rainfall_Pentolina - temp['0_24']), (temp.Rainfall_Pentolina - temp['9_9'])), axis=1)\ntemp_diff.columns = ['0_24', '9_9']\ntemp2 = temp_diff.groupby([temp.index.year, temp.index.month]).mean().dropna(how='all')\nassert temp2[temp2!=0]['9_9'].value_counts().shape[0] == 0\ntemp2[temp2!=0]['0_24'].plot.hist()","a8929136":"# find rainfall features, for which datasets are differ\ntreshold = 20\n\nfor f in downloaded_features0_24.columns:\n    temp = downloaded_features0_24[[f]].merge(downloaded_features9_9[f], left_index=True, right_index=True)\n    temp.columns = ['0_24', '9_9']\n    for df in [auser, doganella, luco, petrignano]:\n        try:\n            temp = temp.merge(df[f], left_index=True, right_index=True)\n            break\n        except KeyError:\n            continue\n    \n    temp_diff = pd.concat(((temp[f] - temp['0_24']), (temp[f] - temp['9_9'])), axis=1)\n    temp_diff.columns = ['0_24', '9_9']\n    temp2 = temp_diff.groupby([temp.index.year, temp.index.month]).mean().dropna(how='all')\n    for new_f in ['0_24', '9_9']:\n        if temp2[temp2.abs() >= treshold][new_f].dropna().shape[0] > 0:\n            print(f'{f} differs from {new_f}')","4f357096":"#  replace our data with outliers on downloaded one\nfor f in ['Rainfall_Scorgiano', 'Rainfall_Pentolina']:\n    luco = luco.merge(downloaded_features0_24[f], left_index=True, right_index=True, how='left', suffixes=['_drop', ''])\n    luco.drop(f'{f}_drop', axis=1, inplace=True)","8bdb3003":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_rainfall = [f for f in df.columns if 'Rainfall' in f]\n    temp = df[features_rainfall].resample('MS', ).mean()\n    temp['month'] = temp.index.month\n    temp.groupby('month').mean().plot(legend=False, title=name, ax=ax)","b9b43754":"features_rainfall = [f for f in auser.columns if 'Rainfall' in f and 'cumsum' not in 'f' and 'sum' not in f and 'ratio' not in f] \nfeatures_depth = [f for f in auser.columns if 'Depth' in f]\nres_windows = plot_window_corr(auser, features_depth, features_rainfall, ewm_max=300)","1502e4d3":"_ = plot_window_corr(auser, [features_depth[0]], features_rainfall, ewm_max=3000)","6aeb51ce":"res_windows, style = format_res_windows(res_windows,features_depth, features_rainfall)\nres_windows.iloc[0] = pd.DataFrame(_).lag.values\nstyle","6457feb4":"auser_df = auser[features_depth].copy()\nauser_df['year'] = auser_df.index.year\nauser_df['month'] = auser_df.index.month\n\n# save rainfall features names (with window size) for different wells\nrainfall_windows = {f_main: {f_lag:res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_rainfall}\n                                 for f_main in features_depth\n                   }\n\nfor f_main, f_lag in product(features_depth, [f for f in features_rainfall]):\n    window = res_windows.loc[f_main, f_lag]\n    auser_df[f'{f_lag}_{window}'] = auser[f_lag].ewm(window, min_periods=65).mean()","2bd2b87f":"rainfall_corr = plot_corr_for_targets(features_depth, features_rainfall, res_windows, auser_df)","0b9c927c":"img = plt.imread('\/kaggle\/input\/geo-data-water-italia\/map.png')\nfig, axes = plt.subplots(1, 5, figsize = (8*5,8))\n# fig.subplots_adjust(wspace=0.01)\n\nborders = (10.4, 10.8, 43.7, 44.2)\nmy_cmap = sns.light_palette(\"Navy\", as_cmap=True) #sns.color_palette(\"coolwarm\", as_cmap=True)\n\ngeo_rainfall = geo_data[(geo_data['type']=='Rainfall') & (geo_data.aquifer =='auser')]\nfor f_main, ax in zip(features_depth, axes.ravel()):\n    ax.set_xlim(borders[0],borders[1])\n    ax.set_ylim(borders[2],borders[3])\n    \n    lons, lats, corrs, labels  = [], [], [], []\n    for i,point in geo_rainfall.iterrows():\n        lons.append(point.lon)\n        lats.append(point.lat)\n        f_lag = point.feature_name\n        idx = (rainfall_corr.f_main == f_main) & (rainfall_corr['f_lag'].apply(lambda x: x.find(point.feature_name)!=-1))  # take current f_lag\n        corrs.append(rainfall_corr[idx]['corr'].iloc[0])\n        labels.append(i)\n        \n    ax.scatter(lons, lats, #zorder=1, \n               c=5000*np.array(corrs), s=5000*np.array(corrs), label=labels, cmap=my_cmap)\n    autolabel(geo_rainfall.lon, geo_rainfall.lat, geo_rainfall['name'])\n    autolabel(lons, np.array(lats) - 0.015, [round(corr, 2) for corr in corrs])\n    \n    ax.set_title(f_main)\n    ax.imshow(img, zorder=0, extent=borders, aspect='equal',\n               alpha=0.75)\n","290593a3":"# temp = rainfall_corr.copy()\n# temp['f_lag'] = temp.f_lag.str.split('_').apply(lambda x: '_'.join(x[:-1]))\n\n# temp_merge = res_windows.unstack().reset_index().rename(columns={0:'window'}).merge(temp, on=['f_main', 'f_lag'], how='outer')\n# temp_merge['f_main'] = temp_merge['f_main'].astype('category').cat.codes\n# temp_merge.plot(kind='scatter', x='window', y='corr', c='f_main', colormap='viridis', xlim=(40, 200))","5de7b338":"# dependences of depth on rainfall by months\nplot_dependencies_by_month(features_depth, features_rainfall, auser_df, rainfall_windows)","099e62e2":"features_rainfall = [f for f in doganella.columns if 'Rainfall' in f and 'cumsum' not in 'f' and 'sum' not in f and 'ratio' not in f] \nfeatures_depth = [f for f in doganella.columns if 'Depth' in f]\nres_windows = plot_window_corr(doganella, features_depth, features_rainfall, ewm_max=2000)","996cef69":"res_windows, style = format_res_windows(res_windows,features_depth, features_rainfall)\nstyle","05ad8b5c":"doganella_df = doganella[features_depth].copy()\ndoganella_df['year'] = doganella_df.index.year\ndoganella_df['month'] = doganella_df.index.month\n\nfor f_main, f_lag in product(features_depth, [f for f in features_rainfall]):\n    window = res_windows.loc[f_main, f_lag]\n    doganella_df[f'{f_lag}_{window}'] = doganella[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\nrainfall_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_rainfall}\n                                 for f_main in features_depth\n                   })","6fc46663":"rainfall_corr = plot_corr_for_targets(features_depth, features_rainfall, res_windows, doganella_df)","91f0071a":"# plot_dependencies_by_month(features_depth, features_rainfall, doganella_df, rainfall_windows)","c70f0a80":"features_rainfall = [f for f in luco.columns if 'Rainfall' in f and 'cumsum' not in 'f' and 'sum' not in f and 'ratio' not in f] \nfeatures_depth = [f for f in luco.columns if 'Depth' in f]\nres_windows = plot_window_corr(luco, features_depth, features_rainfall, ewm_max=1500)","ffbabe38":"res_windows, style = format_res_windows(res_windows,features_depth, features_rainfall)\nres_windows.iloc[-1,1] = 0\nstyle","f44534b2":"luco_df = luco[features_depth].copy()\nluco_df['year'] = luco_df.index.year\nluco_df['month'] = luco_df.index.month\n\nfor f_main, f_lag in product(features_depth, [f for f in features_rainfall]):\n    window = res_windows.loc[f_main, f_lag]\n    luco_df[f'{f_lag}_{window}'] = luco[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\nrainfall_windows.update({f_main.replace('Pozzo', 'Pozzo_luco'): {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_rainfall}\n                                 for f_main in features_depth\n                   })","4e41a50e":"rainfall_corr = plot_corr_for_targets(features_depth, features_rainfall, res_windows, luco_df)","755ff870":"# temp = rainfall_corr.copy()\n# temp['f_lag'] = temp.f_lag.str.split('_').apply(lambda x: '_'.join(x[:-1]))\n\n# temp_merge = res_windows.unstack().reset_index().rename(columns={0:'window'}).merge(temp, on=['f_main', 'f_lag'], how='outer')\n# temp_merge['f_main'] = temp_merge['f_main'].astype('category').cat.codes\n# temp_merge.plot(kind='scatter', x='window', y='corr', c='f_main', colormap='viridis')","6219e40b":"# plot_dependencies_by_month(features_depth, features_rainfall, luco_df, rainfall_windows)","f8a748d2":"features_rainfall = [f for f in petrignano.columns if 'Rainfall' in f and 'cumsum' not in 'f' and 'sum' not in f and 'ratio' not in f] \nfeatures_depth = [f for f in petrignano.columns if 'Depth' in f]\nres_windows =  plot_window_corr(petrignano, features_depth, features_rainfall, ewm_max=200)","c865f741":"res_windows, style = format_res_windows(res_windows,features_depth, features_rainfall)\nstyle","100a43f7":"petrignano_df = petrignano[features_depth].copy()\npetrignano_df['year'] = petrignano_df.index.year\npetrignano_df['month'] = petrignano_df.index.month\n\nfor f_main, f_lag in product(features_depth, [f for f in features_rainfall]):\n    window = res_windows.loc[f_main, f_lag]\n    petrignano_df[f'{f_lag}_{window}'] = petrignano[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\nrainfall_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_rainfall}\n                                 for f_main in features_depth\n                   })","881dd626":"_ = plot_corr_for_targets(features_depth, features_rainfall, res_windows, petrignano_df)","1929a67b":"# plot_dependencies_by_month(features_depth, features_rainfall, petrignano_df, rainfall_windows)","8d23ef54":"import pickle \npickle.dump(rainfall_windows, open('rainfall_windows.pkl', 'wb'))","f172558c":"for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features_volume = [f for f in df.columns if 'Volume' in f]\n    if features_volume.__len__() > 1:\n        fig, ax = plt.subplots(figsize=(20, 30))\n        df[features_volume].plot(subplots=True, layout=(20,2), ax=ax)\n    else:\n        fig, ax = plt.subplots(figsize=(10,5))\n        df[features_volume].plot(ax=ax)","c2c6f35a":"features_volume = [f for f in auser.columns if 'Volume' in f]\nauser[features_volume] = auser[features_volume].replace(0, np.nan)","69573d99":"import seaborn as sns\n\nfig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_volume = [f for f in df.columns if 'Volume' in f]\n    sns.boxplot(data=df[features_volume].unstack().reset_index(), x=0, y='level_0', ax=ax)\n    ax.set_title(name)","63edbd55":"features_volume = [f for f in doganella.columns if 'Volume' in f]\ndoganella[features_volume] = -doganella[features_volume]","3eba83de":"import scipy.stats as ss\n\nvolume = []\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    volume.extend([f for f in df.columns if 'Volume' in f])\n    \ncols = 5\nrows = len(volume) \/\/ cols\nrows  = rows + 1 if len(volume) % cols != 0 else rows\n\nfig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\nfor ax, v in zip(axes.ravel(), volume):\n    for df, name in zip([auser, doganella, luco, petrignano],\n                        ['auser', 'doganella', 'luco', 'petrignano']):\n        try:\n            ss.probplot(df[v].dropna(), plot=ax)\n            ax.set_title(f'{v.replace(\"Volume_\", \"\")}')\n            break\n        except KeyError:\n            continue","afecc6bf":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_volume = [f for f in df.columns if 'Volume' in f]\n    temp = df[features_volume].resample('MS', ).mean()\n    temp['month'] = temp.index.month\n    temp.groupby('month').mean().plot(legend=True, title=name, ax=ax)\n    ax.set_ylabel('Volume')\n","b1b19a4c":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_volume = [f for f in df.columns if 'Volume' in f]\n    df.groupby('month')[features_volume].median().plot(legend=True, title=name, ax=ax)\n    ax.set_ylabel('Volume')\n","cd315835":"# plot standatrized volumes\nfig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_volume = [f for f in df.columns if 'Volume' in f]\n    temp = df[features_volume].copy()\n#     temp = df[features_volume].resample('MS', ).mean().abs()\n    temp[features_volume] = (temp[features_volume] - temp[features_volume].mean())\/temp[features_volume].std()\n    temp['month'] = temp.index.month\n    temp.groupby('month').median().plot(legend=True, title=name, ax=ax)\n    ax.set_ylabel('Volume')\nfig.suptitle('Standartized volume by months');","4266c71a":"features_volume = [f for f in auser.columns if 'Volume' in f ] \nfeatures_depth = [f for f in auser.columns if 'Depth' in f]\nres_windows =  plot_window_corr(auser, features_depth, features_volume, ewm_max=2500)","ae3e5226":"res_windows, style = format_res_windows(res_windows,features_depth, features_volume)\nres_windows.iloc[-1, 2] = 0\nstyle","4a13035f":"for f_main, f_lag in product(features_depth, [f for f in features_volume]):\n    window = res_windows.loc[f_main, f_lag]\n    auser_df[f'{f_lag}_{window}'] = auser[f_lag].ewm(window, min_periods=65).mean()\n    \nvolume_windows = {f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_volume}\n                                 for f_main in features_depth\n                   }","b64f90f3":"_ = plot_corr_for_targets(features_depth, features_volume, res_windows, auser_df)","3d5c3ee2":"# plot_dependencies_by_month(features_depth, features_volume, auser_df, volume_windows)","7a931f80":"features_volume = [f for f in doganella.columns if 'Volume' in f ] \nfeatures_depth = [f for f in doganella.columns if 'Depth' in f]\nres_windows =  plot_window_corr(doganella, features_depth, features_volume, ewm_max=2000)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_volume)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_volume]):\n    window = res_windows.loc[f_main, f_lag]\n    doganella_df[f'{f_lag}_{window}'] = doganella[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\nvolume_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_volume}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_volume, res_windows, doganella_df)","661b9fe6":"# plot_dependencies_by_month(features_depth, features_volume, doganella_df, volume_windows)","41a765af":"features_volume = [f for f in luco.columns if 'Volume' in f ] \nfeatures_depth = [f for f in luco.columns if 'Depth' in f]\nres_windows =  plot_window_corr(luco, features_depth, features_volume, ewm_max=1000)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_volume)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_volume]):\n    window = res_windows.loc[f_main, f_lag]\n    luco_df[f'{f_lag}_{window}'] = luco[f_lag].ewm(window, min_periods=65).mean()\n    \nvolume_windows.update({f_main.replace('Pozzo', 'Pozzo_luco'): {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_volume}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_volume, res_windows, luco_df)","5b9c8162":"# plot_dependencies_by_month(features_depth, features_volume, luco_df, volume_windows)","5d1839af":"features_volume = [f for f in petrignano.columns if 'Volume' in f ] \nfeatures_depth = [f for f in petrignano.columns if 'Depth' in f]\nres_windows =  plot_window_corr(petrignano, features_depth, features_volume, ewm_max=200)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_volume)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_volume]):\n    window = res_windows.loc[f_main, f_lag]\n    petrignano_df[f'{f_lag}_{window}'] = petrignano[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\nvolume_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_volume}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_volume, res_windows, petrignano_df)","6d8609ec":"# plot_dependencies_by_month(features_depth, features_volume, petrignano_df, volume_windows)","32af5673":"pickle.dump(volume_windows, open('volume_windows.pkl', 'wb'))","4362a60d":"for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features_temperature = [f for f in df.columns if 'Temperature' in f]\n    if features_temperature.__len__() > 1:\n        fig, ax = plt.subplots(figsize=(20, 30))\n        df[features_temperature].plot(subplots=True, layout=(20,2), ax=ax)\n    else:\n        fig, ax = plt.subplots(figsize=(10,5))\n        df[features_temperature].plot(ax=ax)","5bd057de":"temperatures = []\nfor df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    temperatures.extend([f for f in df.columns if 'Temperature' in f])\n    \nfig ,axes = plt.subplots(6,2, figsize=(20,20))\n\nfor ax, f in zip(axes.ravel(), temperatures):\n    for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n        try:\n            temp = df[f].copy().to_frame()\n            temp['is0'] = False\n            temp['is0'][temp[f].notna()] = temp[f].dropna().rolling(2).mean() == 0\n            temp[f].plot(ax=ax, title=f)\n            ax.scatter(temp[temp.is0].index, temp[temp.is0][f], c='r')\n            break\n        except KeyError:\n            continue","eb3d4ad9":"for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features_temp = [f for f in df.columns if 'Temperature' in f]\n    for f in features_temp:\n        temp = df[f].copy().to_frame()\n        temp['is0'] = False\n        temp['is0'][temp[f].notna()] = temp[f].dropna().rolling(2).mean() == 0\n        df[f][temp.is0] = np.nan\n","90373b7a":"import seaborn as sns\n\nfig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_temp = [f for f in df.columns if 'Temperature' in f]\n    sns.boxplot(data=df[features_temp].unstack().reset_index(), x=0, y='level_0', ax=ax)\n    ax.set_title(name)","113e8fc6":"import scipy.stats as ss\n\ntemperature = []\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    temperature.extend([f for f in df.columns if 'Temperature' in f])\n    \ncols = 5\nrows = len(temperature) \/\/ cols\nrows  = rows + 1 if len(temperature) % cols != 0 else rows\n\nfig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\nfor ax, v in zip(axes.ravel(), temperature):\n    for df, name in zip([auser, doganella, luco, petrignano],\n                        ['auser', 'doganella', 'luco', 'petrignano']):\n        try:\n            ss.probplot(df[v].dropna(), plot=ax)\n            ax.set_title(f'{v.replace(\"Temperature_\", \"\")}')\n            break\n        except KeyError:\n            continue","7d17450c":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_temperature = [f for f in df.columns if 'Temperature' in f]\n    df.groupby('month')[features_temperature].mean().plot(legend=True, title=name, ax=ax, style='-o')\n    ax.set_ylabel('Temperature')","1ddb89f5":"features_temperature = [f for f in auser.columns if 'Temperature' in f ] \nfeatures_depth = [f for f in auser.columns if 'Depth' in f]\nres_windows =  plot_window_corr(auser, features_depth, features_temperature, trend='negative', ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_temperature)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_temperature]):\n    window = res_windows.loc[f_main, f_lag]\n    auser_df[f'{f_lag}_{window}'] = auser[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\ntemperature_windows = {f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_temperature}\n                                 for f_main in features_depth\n                   }\n\n_ = plot_corr_for_targets(features_depth, features_temperature, res_windows, auser_df)","39fc749f":"# plot_dependencies_by_month(features_depth, features_temperature, auser_df, temperature_windows)","2f466903":"features_temperature = [f for f in doganella.columns if 'Temperature' in f ] \nfeatures_depth = [f for f in doganella.columns if 'Depth' in f]\nres_windows =  plot_window_corr(doganella, features_depth, features_temperature, trend='negative',  ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_temperature)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_temperature]):\n    window = res_windows.loc[f_main, f_lag]\n    doganella_df[f'{f_lag}_{window}'] = doganella[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\ntemperature_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_temperature}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_temperature, res_windows, doganella_df)","c251a220":"# plot_dependencies_by_month(features_depth, features_temperature, doganella_df, temperature_windows)","e68de52f":"features_temperature = [f for f in luco.columns if 'Temperature' in f ] \nfeatures_depth = [f for f in luco.columns if 'Depth' in f]\nres_windows =  plot_window_corr(luco, features_depth, features_temperature, trend='negative',  ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_temperature)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_temperature]):\n    window = res_windows.loc[f_main, f_lag]\n    luco_df[f'{f_lag}_{window}'] = luco[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\ntemperature_windows.update({f_main.replace('Pozzo', 'Pozzo_luco'): {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_temperature}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_temperature, res_windows, luco_df)","c872b6d4":"# plot_dependencies_by_month(features_depth, features_temperature, luco_df, temperature_windows)","48eb2333":"features_temperature = [f for f in petrignano.columns if 'Temperature' in f ] \nfeatures_depth = [f for f in petrignano.columns if 'Depth' in f]\nres_windows =  plot_window_corr(petrignano, features_depth, features_temperature, trend='negative', ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_temperature)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_temperature]):\n    window = res_windows.loc[f_main, f_lag]\n    petrignano_df[f'{f_lag}_{window}'] = petrignano[f_lag].ewm(window, min_periods=65).mean()\n    \n# save rainfall features names (with window size) for different wells\ntemperature_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_temperature}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_temperature, res_windows, petrignano_df)","31721e78":"# plot_dependencies_by_month(features_depth, features_temperature, petrignano_df, temperature_windows)","70e2f787":"pickle.dump(temperature_windows, open('temperature_windows.pkl', 'wb'))","a2cd5f39":"for df, name in zip([auser, doganella, luco, petrignano],\n                    ['auser', 'doganella', 'luco', 'petrignano']):\n    features_hydrometry = [f for f in df.columns if 'Hydrometry' in f]\n    if features_hydrometry.__len__() > 1:\n        fig, ax = plt.subplots(figsize=(20, 30))\n        df[features_hydrometry].plot(subplots=True, layout=(20,2), ax=ax)\n        print(name)\n    elif features_hydrometry.__len__() == 1:\n        fig, ax = plt.subplots(figsize=(10,5))\n        df[features_hydrometry].plot(ax=ax)\n        print(name)\n    else:\n        continue","fd756f47":"features_hydrometry = [f for f in df.columns if 'Hydrometry' in f]\npetrignano[features_hydrometry] = petrignano[features_hydrometry].replace(0, np.nan)","8017daed":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_hydro = [f for f in df.columns if 'Hydrometry' in f]\n    if len(features_hydro) >= 1:\n        sns.boxplot(data=df[features_hydro].unstack().reset_index(), x=0, y='level_0', ax=ax)\n        ax.set_title(name)\n    ","10faa601":"hydrometry = []\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    hydrometry.extend([f for f in df.columns if 'Hydrometry' in f])\n    \ncols = 5\nrows = len(hydrometry) \/\/ cols\nrows  = rows + 1 if len(hydrometry) % cols != 0 else rows\n\nfig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\nfor ax, v in zip(axes.ravel(), hydrometry):\n    for df, name in zip([auser, doganella, luco, petrignano],\n                        ['auser', 'doganella', 'luco', 'petrignano']):\n        try:\n            ss.probplot(df[v].dropna(), plot=ax)\n            ax.set_title(f'{v.replace(\"Hydrometry_\", \"\")}')\n            break\n        except KeyError:\n            continue","adaa46f4":"fig, axes = plt.subplots(1, 4, figsize=(8*4, 5))\n\nfor ax, df, name in zip(axes.ravel(), [auser, doganella, luco, petrignano],\n                       ['auser', 'doganella', 'luco', 'petrignano']):\n    features_hydro = [f for f in df.columns if 'Hydrometry' in f]\n    if len(features_hydro) >= 1:\n        df.groupby('month')[features_hydro].median().plot(legend=True, title=name, ax=ax, style='-o')\n        ax.set_ylabel('Hydrometry')","a516dbda":"features_hydrometry = [f for f in auser.columns if 'Hydrometry' in f ] \nfeatures_depth = [f for f in auser.columns if 'Depth' in f]\nres_windows =  plot_window_corr(auser, features_depth, features_hydrometry,  ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_hydrometry)\nres_windows[res_windows == -1] = 0\ntemp =  plot_window_corr(auser, [features_depth[0]], [features_hydrometry[1]], trend='negative',  ewm_max=1500)\nres_windows.iloc[0, 1] = temp[0]['lag']\n\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_hydrometry]):\n    window = res_windows.loc[f_main, f_lag]\n    auser_df[f'{f_lag}_{window}'] = auser[f_lag].ewm(window, min_periods=65).mean()\n    \nhydrometry_windows = {f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_hydrometry}\n                                 for f_main in features_depth\n                   }\n\n_ = plot_corr_for_targets(features_depth, features_hydrometry, res_windows, auser_df)","06b91bd2":"features_hydrometry = [f for f in petrignano.columns if 'Hydrometry' in f ] \nfeatures_depth = [f for f in petrignano.columns if 'Depth' in f]\nres_windows =  plot_window_corr(petrignano, features_depth, features_hydrometry,  ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_hydrometry)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_hydrometry]):\n    window = res_windows.loc[f_main, f_lag]\n    petrignano_df[f'{f_lag}_{window}'] = petrignano[f_lag].ewm(window, min_periods=65).mean()\n    \nhydrometry_windows.update({f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                                           for f_lag in features_hydrometry}\n                                 for f_main in features_depth\n                   })\n\n_ = plot_corr_for_targets(features_depth, features_hydrometry, res_windows, petrignano_df)","c6e98ac0":"pickle.dump(hydrometry_windows, open('hydro_windows.pkl', 'wb'))","eb1f392c":"features_depth = [f for f in auser.columns if 'Depth' in f]\nfeatures_depth2 = ['Depth_to_Groundwater_PAG',  'Depth_to_Groundwater_DIEC']\nfor f in features_depth2:\n    features_depth.remove(f)\n\nres_windows =  plot_window_corr(auser, features_depth, features_depth2, ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_depth2)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_depth2]):\n    window = res_windows.loc[f_main, f_lag]\n    auser_df[f'{f_lag}_{window}'] = auser[f_lag].ewm(window, min_periods=65).mean()\n    \ndepth_windows = {f_main: {f_lag: res_windows.loc[f_main, f_lag]\n                          for f_lag in features_depth2}\n                for f_main in features_depth\n                }\n\n_ = plot_corr_for_targets(features_depth, features_depth2, res_windows, auser_df)","5d41ea79":"features_depth = [f for f in luco.columns if 'Depth' in f]\nfeatures_depth2 = ['Depth_to_Groundwater_Pozzo_1', 'Depth_to_Groundwater_Pozzo_3',\n                   'Depth_to_Groundwater_Pozzo_4']\nfor f in features_depth2:\n    features_depth.remove(f)\n\nres_windows =  plot_window_corr(luco, features_depth, features_depth2, trend='negative', ewm_max=500)\n\nres_windows, style = format_res_windows(res_windows,features_depth, features_depth2)\nres_windows[res_windows == -1] = 0\ndisplay(style)\n\nfor f_main, f_lag in product(features_depth, [f for f in features_depth2]):\n    window = res_windows.loc[f_main, f_lag]\n    luco_df[f'{f_lag}_{window}'] = luco[f_lag].ewm(window, min_periods=65).mean()\n    \ndepth_windows.update({f_main.replace('Pozzo', 'Pozzo_luco'): {f_lag: res_windows.loc[f_main, f_lag]\n                          for f_lag in features_depth2}\n                for f_main in features_depth\n                })\n\n# _ = plot_corr_for_targets([features_depth], features_depth2, res_windows, luco_df)","858b564e":"pickle.dump(depth_windows, open('depth_windows.pkl', 'wb'))","97e7102d":"## Luco","ab6b2ea0":"## Luco","1353188f":"## Petrignano","61f3c952":"## Doganella","67b75a40":"# Common analysis of Hydrometry","5f24f68c":"# Common analysis of Temperature","5b678765":"# Windows for ewm in Corr Rainfall","53c7bffd":"## Luco","8fc1e798":"# Common volume analysis","67ab62cc":"# Location features map\nVisualize geo data for all features","3e9ad597":"# Common rainfalls analysis","3b214463":"# Datasets","5a810ef0":"# Data preprocessing","b86f3567":"All dependencies looks close to each other with common pattern - lowest rainfalls for summer months (6,7 and, 8). But in auser datasets there are 2 lines which are differ from other. Find them and try to find what is wrong","f946bd1a":"## Petrignano","43377d90":"# Windows for Corr unpredicted Targets","037addda":"## Doganella","9008e480":"## Petrignano","fcfd4810":"## Doganella","41306ac0":"Now, one can see difference in influencing on depth by rainfalls for south (LT2) and north wells (other)","a53d55dc":"Get rainfalls data for each rainfalls from https:\/\/www.sir.toscana.it\/consistenza-rete and compare with our datasets","51e16765":"# Functions","b378bedf":"Not commont behavior for Pentolina and Scorgiano Rainfalls in Luco","7bf98173":"# Windows for ewm in Corr Volume\n## Auser","a2e03ac8":"#### Auser","7bdeb3b5":"# Windows for ewm in Corr Temperature\n## Auser","951a82b4":"## Petrignano","aee3bb61":"# Get additional geo data\njson file was  downloaded from official website https:\/\/www.sir.toscana.it\/consistenza-rete","d9cf20d7":"8 columns - Rainfall Croce Arcana - dependencies are differ from other - big difference between 12 and 1 month (december and january)","f1f3a25c":"# Windows for ewm in Corr Hydrometry\n## Auser"}}