{"cell_type":{"7874c361":"code","ee6d6e4c":"code","c4e5ff8f":"code","c3e330cb":"code","46fc4fc3":"code","1a4bdf0b":"code","9d9bc1e4":"code","ca188652":"code","eaaf7063":"code","fe4a05fe":"code","e19a2345":"code","5ca8bf13":"code","564bd63f":"code","ca9f3701":"code","333c5dc9":"code","dd52a3b3":"code","0e4c3389":"code","e9e83995":"code","ac310560":"code","fc97450c":"code","9d12e871":"code","3a097b3d":"code","affc346d":"code","a77822f2":"code","f0a3c577":"code","73c09dfe":"code","8d71704b":"code","5b9dae9d":"code","1043ec18":"code","655f114c":"code","9752946a":"code","aa49051f":"code","c1c26b02":"code","9a77a369":"code","499a1e95":"code","1342a9ef":"code","fda2a052":"code","afc05ae4":"code","4eaf2c35":"code","cc9eaecd":"code","9d696fd5":"code","b6fab7bc":"code","e3e6c639":"code","a6265d00":"code","94d5385d":"code","be0d98c0":"code","af7b5015":"code","b5b623ad":"code","a073cfa6":"code","1a905ff7":"markdown","18fbe20b":"markdown","b368ec70":"markdown","4ab9556b":"markdown"},"source":{"7874c361":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee6d6e4c":"# We have used the data collected by a fleet of 20 autonomous vehicles along a fixed route in Palo Alto, California, over a four-month period. It consists of 170,000 scenes, where each scene is 25 seconds long and captures the perception output of the self-driving system, which encodes the precise positions and motions of nearby vehicles, cyclists, and pedestrians over time.","c4e5ff8f":"# In this project, we have analyzed the various rotation and direction of the data to analyze in which direction the vehicle should move forward.","c3e330cb":"# Importing Libraries\n\nimport os, shutil\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers import Input, Dense\n\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nprint(tf.__version__)","46fc4fc3":"# Importing tha data set. \ndata = pd.read_csv('..\/input\/automobile\/lyftdata.csv')","1a4bdf0b":"#Shape of the data\ndata.shape","9d9bc1e4":"# Checking the top values of the data set.\ndata.head()","ca188652":"#Dropping the columns 'agent_id' and 'frame_db_id' as it doesn't add value to our analyzation.\ndata = data.drop([\"agent_id\"],axis=1)\ndata = data.drop([\"frame_db_id\"],axis=1)","eaaf7063":"# Checking the top values of the data set.\ndata.head()","fe4a05fe":"#Converting the data to DtaFrame\ndata = pd.DataFrame(data)","e19a2345":"#Assigning the independent valriables to x and dependent variable to y\nx = data.drop([\"yaw\"],axis=1)\ny = data[\"yaw\"]","5ca8bf13":"# Checking the top values of the data set.\nx.head()","564bd63f":"# Checking the top values of the data set.\ny.head()","ca9f3701":"# Checking the unique values of the column 'yaw' in y.\ny.unique()","333c5dc9":"# Checking shape of x and y\nx.shape, y.shape","dd52a3b3":"# Splitting the dataset into Train and Test\nx_train, x_test,y_train, y_test = train_test_split(x,y,test_size=0.3, random_state =0)","0e4c3389":"# Checking the shape of Train and Test data set\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","e9e83995":"# Scaling the Train and Test Data\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","ac310560":"# Converting Train and Test data to numpy\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()","fc97450c":"x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\nx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)","9d12e871":"# Checking shape of Traina and Test Data\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","3a097b3d":"# Bulding 1D CNN Model with epoch = 10\nepochs = 10\nmodel= Sequential()\nmodel.add(Conv1D(32,2,activation=\"relu\",input_shape=x_train[0].shape))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv1D(16,2,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(8,activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation=\"sigmoid\"))","affc346d":"# Summary of the model\nmodel.summary()","a77822f2":"model.compile(optimizer=Adam(lr=0.001), loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","f0a3c577":"history = model.fit(x_train,y_train, epochs=epochs, batch_size=128, validation_data=(x_test, y_test),verbose=1)","73c09dfe":"def plot_learningcurve(history, epoch):\n    epoch_range=range(1,epoch+1)\n    plt.plot(epoch_range,history.history[\"accuracy\"])\n    plt.plot(epoch_range,history.history[\"val_accuracy\"])\n    plt.title(\"Model_accuracy\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Train\",\"Val\"],loc=\"upper left\")\n    plt.show()\n    \n    \n    plt.plot(epoch_range,history.history[\"loss\"])\n    plt.plot(epoch_range,history.history[\"val_loss\"])\n    plt.title(\"Model_loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Train\",\"Val\"],loc=\"upper left\")\n    plt.show()","8d71704b":"# Plotting the results of epoch = 10 model\nplot_learningcurve(history, epochs)","5b9dae9d":"# Taking epoh =2 for the 1D CNN model\nepochs = 20\nmodel= Sequential()\nmodel.add(Conv1D(32,2,activation=\"relu\",input_shape=x_train[0].shape))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv1D(16,2,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(8,activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(optimizer=Adam(lr=0.001), loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\n# Plotting the results of epoch = 20 model\nhistory = model.fit(x_train,y_train, epochs=epochs, batch_size=128, validation_data=(x_test, y_test),verbose=1)\nplot_learningcurve(history, epochs)","1043ec18":"from tensorflow.keras.preprocessing import sequence\nimport tensorflow as tf\nfrom tensorflow.keras.layers import SimpleRNN\nfrom keras.layers import Input, Dense","655f114c":"from tensorflow.keras import Sequential\nmodel= Sequential()\nmodel.add(SimpleRNN(32,input_shape=x_train[0].shape, activation=\"relu\"))\nmodel.add(Dense(8,activation=\"relu\"))\nmodel.add(Dense(1))\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\nmodel.summary()","9752946a":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])","aa49051f":"history = model.fit(x_train,y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test),verbose=1)","c1c26b02":"def display_models_plots(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(accuracy) + 1)\n    plt.plot(epochs, accuracy, 'r', label='Training acc')\n    plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","9a77a369":"# Plotting the results\ndisplay_models_plots(history)","499a1e95":"history = model.fit(x_train,y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test),verbose=1)","1342a9ef":"def display_models_plots(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(accuracy) + 1)\n    plt.plot(epochs, accuracy, 'r', label='Training acc')\n    plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","fda2a052":"# Plotting the results\ndisplay_models_plots(history)","afc05ae4":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","4eaf2c35":"model=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')","cc9eaecd":"model.summary()","9d696fd5":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.models import load_model\nfrom keras.layers import LSTM\nK.clear_session()\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(16, input_shape=(x_train.shape[1],1), activation='relu', return_sequences=False))\nmodel_lstm.add(Dense(1))\nmodel_lstm.compile(loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\nearly_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\nhistory = model_lstm.fit(x_train, y_train, epochs=10, batch_size=512,validation_data=(x_test, y_test), verbose=1, shuffle=False, callbacks=[early_stop])","b6fab7bc":"y_pred_test_lstm = model_lstm.predict(x_test)\ny_train_pred_lstm = model_lstm.predict(x_train)\nprint(\"The R2 score on the Train set is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred_lstm)))\nr2_train = r2_score(y_train, y_train_pred_lstm)\n\nprint(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred_test_lstm)))\nr2_test = r2_score(y_test, y_pred_test_lstm)","e3e6c639":"score_lstm= model_lstm.evaluate(x_test, y_test, batch_size=128)","a6265d00":"print('LSTM: {}'.format(score_lstm))","94d5385d":"y_pred_test_LSTM = model_lstm.predict(x_test)","be0d98c0":"plt.plot(y_test, label='True')\nplt.plot(y_pred_test_LSTM, label='LSTM')\nplt.title(\"LSTM's_Prediction\")\nplt.xlabel('Observation')\nplt.ylabel('INR_Scaled')\nplt.legend()\nplt.show()","af7b5015":"def show_plot(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(accuracy) + 1)\n    plt.plot(epochs, accuracy, 'r', label='Training acc')\n    plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","b5b623ad":"# Plotting the results of the model\nshow_plot(history)","a073cfa6":"# We are getting the accuracy of 71.31% for 1D CNN model which is the highest among the  3 model we made. In this case, we are suggessting to use 1D CNN model for the better prediction of direction in self driving vehicles.","1a905ff7":"# Model 1 : Building 1D CNN Model","18fbe20b":"# Model 3 : Building LSTM Model","b368ec70":"# 1 refers to Right 0 refers to Straight -1 refers to Left","4ab9556b":"# Model 2 : Building RNN Model"}}