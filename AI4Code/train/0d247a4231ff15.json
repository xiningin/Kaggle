{"cell_type":{"ea155c90":"code","a68eb42c":"code","1a599770":"code","61e6a1b0":"code","70862ca2":"code","e29ef9b7":"code","5baf17e3":"markdown","c67a6f8a":"markdown","28cce12c":"markdown","5748d1b3":"markdown","061cdcfa":"markdown","970a8dbc":"markdown","32ab06c9":"markdown","ae7866a5":"markdown","e4ceccfb":"markdown","6022c130":"markdown","09606b77":"markdown","89560ad2":"markdown","703bbfea":"markdown","13e4ae63":"markdown","a710641a":"markdown","e99ccea2":"markdown","316d84cf":"markdown","85d89bc4":"markdown","177f6c91":"markdown","c44d2774":"markdown","f5b77c04":"markdown"},"source":{"ea155c90":"#Numpy is used so that we can deal with array's, which are necessary for any linear algebra\n# that takes place \"under-the-hood\" for any of these algorithms.\n\nimport numpy as np\n\n\n#Pandas is used so that we can create dataframes, which is particularly useful when\n# reading or writing from a CSV.\n\nimport pandas as pd\n\n\n#Matplotlib is used to generate graphs in just a few lines of code.\n\nimport matplotlib.pyplot as plt\n\n\n#LinearRegression is the class of the algorithm we will be using.\n\nfrom sklearn.linear_model import LinearRegression\n\n#Polynomial Features will allow us to fit a polynomial model to the data. \n\nfrom sklearn.preprocessing import PolynomialFeatures\n\n","a68eb42c":"#read the data from csv\ndataset = pd.read_csv('..\/input\/position-salaries\/Position_Salaries.csv')\n\n#set independent variable by using all rows, but just column 1.\nX = dataset.iloc[:, 1:2].values\n\n#set the dependent variable using all rows but only the last column. \ny = dataset.iloc[:, 2].values\n\n#take a look at our dataset\ndataset","1a599770":"#I am going to wrap this all in a function.\ndef define_model(degree):\n\n    #create an object of the class PolynomialFeatures\n    poly_reg = PolynomialFeatures(degree)\n\n    #call fit_transform on the x variables.\n    X_poly = poly_reg.fit_transform(X)\n\n    #now fit the transformed x's to the y's\n    poly_reg.fit(X_poly, y)\n\n    #create an object of the class LinearRegression\n    lin_reg = LinearRegression()\n\n    #fit the model to our transformed X\n    lin_reg.fit(X_poly, y)\n    \n    #return these so we can pass them into the visualization\n    return lin_reg, poly_reg\n\n#call our function with the desired degrees (4). \nlin_reg, poly_reg = define_model(4)","61e6a1b0":"# create a function so we can reuse the code.\ndef show_regression(lin_reg, poly_reg):\n    #create a scatter plot with x and y.\n    plt.scatter(X, y, color = 'red')\n    #plot the predictions as a blue line.\n    plt.plot(X, lin_reg.predict(poly_reg.fit_transform(X)), color = 'blue')\n    #axes and title labels.\n    plt.title('Salary Model')\n    plt.xlabel('Position level')\n    plt.ylabel('Salary')\n    #show the completed plot\n    plt.show()\n    \n#call our function.     \nshow_regression(lin_reg, poly_reg)","70862ca2":"#Predicting a new result with Polynomial Regression\n#call fit transform on the position level using the poly_reg object.\n#feed this into the linear regression object to predict it.\n#convert it to an int so it is easier to read (by default its a floating point in an array)\n#assign to a variable so we can print it.\n\nsalary = int(lin_reg.predict(poly_reg.fit_transform([[7.5]])))\n\nprint(\"Estimated Salary: $\", salary)","e29ef9b7":"# degree = int(input(\"Please input the degree.\"))\n# lin_reg, poly_reg = define_model(degree)\n# show_regression(lin_reg, poly_reg)","5baf17e3":"Our selection should seek to fit the current data well, and generalize to new data. \n\n![image.png](attachment:image.png)","c67a6f8a":"We can use our model to make a prediction now.  Let's look at someone who's been a Partner (level 7) for a while, and is applying for a Senior Partner Role (level 8).  Let's predict what they may currently be making by calling our model on level 7.5","28cce12c":"This challenge is known as the \"bias variance tradeoff\".\n\n![image.png](attachment:image.png)","5748d1b3":"However, polynomial regression differs in that it allows us fit curved lines\/planes to our data.\n\n![image.png](attachment:image.png)","061cdcfa":"Polynomial regression still uses \"least squares\", but it is an \"overdetermined system\" meaning that there are more equations than unknowns.\n\n![image.png](attachment:image.png)","970a8dbc":"This makes it a fantastic modeling tool for \"exponential\" datasets. \n\n![image.png](attachment:image.png)","32ab06c9":"Regression meaning we predict a numerical value, instead of a \u201cclass\u201d.\n\n![image.png](attachment:image.png)","ae7866a5":"Supervised meaning we use labeled data to train the model.\n\n![image.png](attachment:image.png)\n","e4ceccfb":"Therefore,  we must rely on matrix multiplication to solve for the the best fit. \n\n![image.png](attachment:image.png)","6022c130":"With our imports complete, we now read in the data using Pandas.\n\nWe will set a independent variable (X) and a dependent variable (y).","09606b77":"That's it! \n\nNow we can visualize the results and see how it did. ","89560ad2":"## Implementation\n\nIn this section I will implement the code in its simplest verison so that it is understandable if you are brand new to machine learning. \n\nBelow we will predict salary based on the current role someone is in.  Salary tends to grow exponentially with each promotion level so this makes it a good dataset for polynomial regression.\n\n**The independent variables is**:\n* Position Level\n    \n**The dependent variable is** \n* Salary\n    \nThe first step is to start with \"imports\". These are \"libraries\" of pre-written code that will help us significantly.","703bbfea":"Overall, Polynomial Regression is an essential tool in your Machine Learning arsenal. However, it is very sensitive to outliers, and we must take care when selecting the degree to avoid overfitting.","13e4ae63":"In practice, this is handled by our statistical software, we just need to select the \"degree\" of the polynomial.\n\n![image.png](attachment:image.png)","a710641a":"> ### This notebook is separated into two parts:\n\n**1) Conceptual Overview:**  I will introduce the topic in 200 words or less.\n\n**2) Implementation:**  I will implement the algorithm in as few lines as possible.","e99ccea2":"To keep this conceptually simple and avoid abstraction, we are using a very small dataset here.  \n\nBecause of this we will not be splitting part of it out into a training\/validation\/test set.\n\nIf we had data on 1000's of employees, we would absolutely complete this step.\n\nSo now we can go right to defining the model.\n\nWe will select a degree of 4. ","316d84cf":"> # Enough to be Dangeous: Polynomial Regression\n\n> ### This is the 3rd notebook of my **\"Enough to be Dangeous\"** notebook series\n\nSee the other notebooks here:\n\n[Simple Linear regression](https:\/\/www.kaggle.com\/thaddeussegura\/enough-to-be-dangeous-simple-linear-regression)\n\n[Multiple Linear Regression](https:\/\/www.kaggle.com\/thaddeussegura\/enough-to-be-dangerous-multiple-linear-regression)\n","85d89bc4":"As we increase the degree, the bias decreases, but the variance increases.  We want to stop where these two factors are minimized.\n\n![image.png](attachment:image.png)","177f6c91":"## Conceptual Overview\n\nLike simple and multiple regression, Polynomial regression is a \"supervised\" \"regression\" algorithm.\n\n![image.png](attachment:image.png)","c44d2774":"One thing that we should experiment with is altering the degree of the polynomial.  \n\nCopy and Edit the notebook (Blue button in the upper right) and then uncomment (delete the #) and run (shift+enter) the cell below to input whichever degree you'd like and see the results. ","f5b77c04":"This is accomplished by \"exponentiating\" our variable by taking it to powers greater than 1. \n\n![image.png](attachment:image.png)"}}