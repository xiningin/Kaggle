{"cell_type":{"668e270f":"code","6931bc2e":"code","ac000c89":"code","7b176a5e":"code","3e9c998e":"code","cd6bd641":"code","517c5011":"code","b8fef75d":"code","a197879b":"code","66bd3a4c":"code","e70882cb":"code","b590e5be":"code","7eb17516":"code","5e417d65":"code","4d4f2616":"code","ef83af96":"code","bfaecdd3":"code","ffbf714c":"code","25922992":"code","3a678889":"code","d5a56b41":"code","ea195254":"code","62ad709a":"code","5e8d16bc":"code","711b31b8":"code","d0ff72dd":"code","d10b12c0":"code","30e83883":"code","5cfe2ae3":"code","5b0ca6e3":"code","4f9fac76":"code","18c29d6c":"code","bf7aded5":"code","221343d7":"code","f6adb5db":"code","3a92eb5f":"code","5c97b07c":"code","bc1433a1":"code","64e6a1f8":"code","e1ed69ba":"markdown","1d0952ba":"markdown","1f4d0e00":"markdown","58232abf":"markdown","3d596b42":"markdown","01669f20":"markdown","b5b41b3a":"markdown","9234dc09":"markdown","95430a53":"markdown","e774f69d":"markdown"},"source":{"668e270f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6931bc2e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns ","ac000c89":"bread_df = pd.read_csv('\/kaggle\/input\/the-bread-basket\/bread basket.csv')","7b176a5e":"#viewing top 5 rows \nbread_df.head()","3e9c998e":"bread_df.shape","cd6bd641":"bread_df.isna().sum()#checking null values","517c5011":"bread_df.describe(include='all')#checking 5 number summary","b8fef75d":"bread_df.dtypes","a197879b":"bread_df['Item'].nunique()","66bd3a4c":"bread_df.head(1)","e70882cb":"bread_df['date_time'] = pd.to_datetime(bread_df['date_time'])","b590e5be":"bread_df['Transaction'].nunique()","7eb17516":"bread_df.head(2)","5e417d65":"sns.countplot(x='period_day',data=bread_df)\nplt.show()\nprint(\"Percentage Wise Count\\n\",bread_df['period_day'].value_counts(normalize=True)*100)","4d4f2616":"sns.countplot(x='weekday_weekend',data=bread_df)\nplt.show()\nprint(\"Percentage Wise Count\\n\",bread_df['weekday_weekend'].value_counts(normalize=True)*100)","ef83af96":"bread_df['time'] = bread_df['date_time'].dt.time","bfaecdd3":"bread_df['hour'] = bread_df['date_time'].dt.hour","ffbf714c":"bread_df['month'] = bread_df['date_time'].dt.month","25922992":"bread_df.head()","3a678889":"\n# Replacing hours with text\nhour_in_num = (1,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23)\nhour_in_obj = ('1-2','7-8','8-9','9-10','10-11','11-12','12-13','13-14','14-15',\n               '15-16','16-17','17-18','18-19','19-20','20-21','21-22','22-23','23-24')\nbread_df['hour'] = bread_df['hour'].replace(hour_in_num, hour_in_obj)\n\n# Extracting weekday and replacing it with text\nbread_df['weekday'] = bread_df['date_time'].dt.weekday\nbread_df['weekday'] = bread_df['weekday'].replace((0,1,2,3,4,5,6), \n                                          ('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'))\n\n# dropping date_time column\nbread_df.drop('date_time', axis = 1, inplace = True)","d5a56b41":"bread_df.head()","ea195254":"bread_df['month'] = bread_df['month'].replace((1,2,3,4,5,6,7,8,9,10,11,12), \n                                          ('January','February','March','April','May','June','July','August',\n                                          'September','October','November','December'))","62ad709a":"bread_df.head()","5e8d16bc":"bread_df['Item'] = bread_df['Item'].apply(lambda x:x.strip())","711b31b8":"bread_df['Item'] = bread_df['Item'].apply(lambda x:x.lower())","d0ff72dd":"bread_df.head(2)","d10b12c0":"plt.figure(figsize=(15,5))\nsns.barplot(x = bread_df['Item'].value_counts().head(20).index,y=bread_df['Item'].value_counts().head(20).values, palette = 'gnuplot')\nplt.xlabel('Items', size = 15)\nplt.xticks(rotation=45)\nplt.ylabel('Count of Items', size = 15)\nplt.title('Top 20 Items purchased by customers', color = 'green', size = 20)\nplt.show()","30e83883":"month_trans = bread_df.groupby('month')['Transaction'].count().reset_index()\nmonth_trans.loc[:,\"monthorder\"] = [4,8,12,2,1,7,6,3,5,11,10,9]\nplt.figure(figsize=(12,8))\nsns.barplot(x='month',y='Transaction',data=bread_df)\nplt.xlabel('Month Name')\nplt.ylabel('Count')\nplt.title('Count Per Month')\nplt.show()","5cfe2ae3":"month_trans = bread_df.groupby('weekday')['Transaction'].count().reset_index()\nmonth_trans.loc[:,\"weekorder\"] = [4,0,5,6,3,1,2]\nplt.figure(figsize=(12,8))\nsns.barplot(x='weekday',y='Transaction',data=bread_df)\nplt.xlabel('weekday Name')\nplt.ylabel('Count')\nplt.title('Count Per weekday')\nplt.show()","5b0ca6e3":"hourTran = bread_df.groupby('hour')['Transaction'].count().reset_index()\nhourTran.loc[:,\"hourorder\"] = [1,10,11,12,13,14,15,16,17,18,19,20,21,22,23,7,8,9]\nhourTran.sort_values(\"hourorder\",inplace=True)\n\nplt.figure(figsize=(12,5))\nsns.barplot(data = bread_df, x = \"Transaction\", y = \"hour\")\nplt.ylabel('Hours', size = 15)\nplt.xlabel('Orders each hour', size = 15)\nplt.title('Count of orders received each hour', color = 'green', size = 20)\nplt.show()","4f9fac76":"bread_df.groupby(['period_day','Item']).count().reset_index().sort_values(['period_day','Transaction'],ascending=False)\nday = ['morning','afternoon','evening','night']\n\nplt.figure(figsize=(15,8))\nfor i,j in enumerate(day):\n    plt.subplot(2,2,i+1)\n    df1 = bread_df[bread_df.period_day==j].head(10)\n    sns.barplot(data=df1, y=df1.Item, x=df1.Transaction, color='pink')\n    plt.xlabel('')\n    plt.ylabel('')\n    plt.title('Top 10 items people like to order in \"{}\"'.format(j), size=13)\n\nplt.show()","18c29d6c":"transactions_str = bread_df.groupby(['Transaction', 'Item'])['Item'].count().reset_index(name ='Count')\ntransactions_str\n","bf7aded5":"from mlxtend.frequent_patterns import association_rules, apriori","221343d7":"my_basket = transactions_str.pivot_table(index='Transaction', columns='Item', values='Count', aggfunc='sum').fillna(0)\nmy_basket.tail()","f6adb5db":"def encode(x):\n    if x<=0:\n        return 0\n    if x>=1:\n        return 1","3a92eb5f":"my_basket_sets = my_basket.applymap(encode)\nmy_basket_sets.tail()","5c97b07c":"# using the 'apriori algorithm' with min_support=0.01 (1% of 9465)\n# It means the item should be present in atleast 94 transaction out of 9465 transactions only when we considered that item in\n# frequent itemset\nfrequent_items = apriori(my_basket_sets, min_support = 0.01,use_colnames = True)\nfrequent_items","bc1433a1":"ass_rule =  association_rules(frequent_items,metric='lift',min_threshold=1)","64e6a1f8":"ass_rule.sort_values(by='confidence',ascending=False)","e1ed69ba":"#### viewing top five rows","1d0952ba":"#### checking the shape of data","1f4d0e00":"#### checking the data type of columns","58232abf":"### **Reading CSV File**","3d596b42":"#### displaying 5 number summary","01669f20":"## importing necessary libries ","b5b41b3a":"#### checking the the unique item count","9234dc09":"#### checking count by peroid_day and displaying percentage by it","95430a53":"#### checking for null values","e774f69d":"#### checking the unique transactions"}}