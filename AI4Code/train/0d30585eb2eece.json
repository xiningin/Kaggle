{"cell_type":{"ab92eef7":"code","0b604c05":"code","d56cfd5b":"code","bdcd3fa7":"code","44045865":"code","5a1c6e71":"code","e6a091c3":"code","51f0a7be":"code","f0d56023":"code","a8b15fc2":"code","106132f6":"markdown"},"source":{"ab92eef7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0b604c05":"import pandas as pd\n\ndataset = pd.read_table('\/kaggle\/input\/fruits-with-colors-dataset\/fruit_data_with_colors.txt')\ndataset.info()","d56cfd5b":"dataset.head(10)","bdcd3fa7":"features = ['mass', 'width', 'height', 'color_score']\ntarget = ['fruit_label']\n\nX = dataset[features]\nY = dataset[target]","44045865":"Y.fruit_label.unique()","5a1c6e71":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(figsize=(20, 20))\nplot = sns.PairGrid(dataset, x_vars=features, y_vars=features, hue='fruit_name')\nplot.map_diag(sns.distplot, kde=False)\nplot.map_offdiag(sns.scatterplot)\n","e6a091c3":"from sklearn.model_selection import train_test_split, cross_val_score\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y)","51f0a7be":"print(X_train.shape, y_train.shape)\nprint(X_valid.shape, y_valid.shape)","f0d56023":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBRFClassifier\nfrom sklearn.pipeline import Pipeline\n\n\nrandom_state=42\nmax_leaf_nodes=10\nn_estimators=10\n\n\ntree_pipeline = Pipeline(steps=[\n    ('model', DecisionTreeClassifier(random_state=random_state, max_leaf_nodes=max_leaf_nodes))\n])\n\nforest_pipeline = Pipeline(steps=[\n    ('model', RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, max_leaf_nodes=max_leaf_nodes))\n])\n\nxgboost_pipeline = Pipeline(steps=[\n    ('model', XGBRFClassifier(random_state=random_state, max_depth=max_leaf_nodes))\n])\n\ntree_scores = cross_val_score(tree_pipeline, X, Y, cv=3, scoring='accuracy', verbose=False)\nforest_scores = cross_val_score(forest_pipeline, X, Y, cv=3, scoring='accuracy', verbose=False)\nxgboost_scores = cross_val_score(xgboost_pipeline, X, Y, cv=3, scoring='accuracy', verbose=False)\n\ntree_mean_acc = tree_scores.mean()\nforest_mean_acc = forest_scores.mean()\nxgboost_mean_acc = xgboost_scores.mean()","a8b15fc2":"print(f'Decision tree accuracy: {tree_mean_acc}')\nprint(f'Random Forest accuracy: {forest_mean_acc}')\nprint(f'XGBoost accuracy: {xgboost_mean_acc}')","106132f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}