{"cell_type":{"4ac4daad":"code","3b6c2fdc":"code","5c1f23e4":"code","ab36d590":"code","67fb2e89":"code","b618bdc5":"code","c3b8891d":"code","6a1430bf":"code","fd9cb8ca":"code","1b6b7576":"code","ed9def8b":"code","94d2d34c":"code","637494dc":"code","81693f81":"code","980a575b":"code","60c2971c":"code","570840a9":"code","4c8d4be8":"code","2036dea2":"code","15a8faa3":"code","f52f36ac":"code","66137b9d":"code","24123fb6":"code","ff104596":"code","4e2e00c9":"code","3a63de33":"code","b2e5c542":"code","96620152":"code","feb5bb26":"code","07a35c67":"code","5c5a9ba5":"code","d15252cb":"code","c8f3f77f":"code","821a9055":"code","c3c6e734":"code","25cefcba":"code","a6397bb5":"code","570cfca9":"code","57481d94":"code","61dbf4ba":"code","8974c2d2":"code","1a3cbff9":"code","f7ab9eee":"code","333b8538":"code","cbb3c87c":"code","70629182":"code","cf6b2231":"code","975a2fce":"code","8f2cb19c":"code","35698655":"code","69df79d0":"code","9617e927":"code","3653aad2":"code","ef7e799c":"code","27e705e2":"code","79284b74":"code","99d141c9":"code","0898cabc":"code","145d6945":"code","ce30d179":"code","3bc0e537":"code","8e8fb29e":"code","d83191ef":"code","ee5838b1":"code","3c70d423":"code","fc1c5122":"code","b482c05b":"code","c0308783":"code","5e861931":"code","019057c3":"code","8cb490d5":"code","dd979517":"code","f106518b":"code","e12c2d12":"code","8cc90e78":"code","13543d1b":"code","189edc53":"code","43b4111e":"code","db3d47b3":"code","8fd0d3bc":"code","e9231d5e":"code","2013a2d5":"code","75fb1189":"code","509a1a96":"code","487a10ef":"code","ba9b5c2b":"code","7183f539":"code","3100d47c":"code","8e56d01a":"code","7f9c211c":"code","d59579dc":"code","169fce52":"code","cb26f539":"code","f2aa9309":"markdown","55dfcbfb":"markdown","8852fa4e":"markdown","e657fa34":"markdown","3e6d8ed2":"markdown","f9ba6fa8":"markdown","07b39bd2":"markdown","6807201a":"markdown","5cfc50a2":"markdown","5e5782fe":"markdown","e3940ae7":"markdown","7ffcdc63":"markdown","33a8a9a5":"markdown","e8ed09d1":"markdown","740f18f7":"markdown","4c1bc78b":"markdown","05afe97c":"markdown","7491258a":"markdown","6208d5cf":"markdown","c34560f8":"markdown","5c0ad8f3":"markdown","6fde281b":"markdown","70aab425":"markdown","e3af8c8c":"markdown","7cc08dba":"markdown","8394d0be":"markdown","aecfe8eb":"markdown","d0e720e0":"markdown","d27bb4c2":"markdown","d7282c21":"markdown","86a47fb2":"markdown","359d7d5a":"markdown","346c2c2e":"markdown"},"source":{"4ac4daad":"# Data Wrangling \nimport numpy as np\nimport pandas as pd \n\n# Data Visualisation \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\n# Machine Learning Tools \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error","3b6c2fdc":"train_data = pd.read_csv('..\/input\/train.txt')\ntest_data = pd.read_csv('..\/input\/test.txt')\ncombine = [train_data, test_data]","5c1f23e4":"train_data.head()","ab36d590":"print(test_data.head())\ntest_sub = test_data.copy()\ntest_sub.head()","67fb2e89":"train_data['Loan_Status'] = train_data['Loan_Status'].map( {'Y' : 1, 'N' : 0} )\ntrain_data.head()","b618bdc5":"train_data.describe(percentiles = [.31, .32 ])\n# train_data.describe(percentiles = [.15, .2 ])","c3b8891d":"train_data.describe(include = 'O')","6a1430bf":"# Dropping Loan_ID\ntrain_data.drop('Loan_ID', axis = 1, inplace = True)\ntest_data.drop('Loan_ID', axis = 1, inplace = True)\ncombine = [train_data, test_data]\ntrain_data.head()","fd9cb8ca":"print(train_data.isnull().sum())\nprint('-' * 50)\nprint(test_data.isnull().sum())","1b6b7576":"# Plotting a correlation heatmap\nsns.heatmap(train_data.corr(), annot = True)","ed9def8b":"print(train_data[['Married', 'ApplicantIncome']].groupby('Married', as_index = False).median())\nprint('\\n')\nprint(train_data[['Married', 'ApplicantIncome']].groupby('Married', as_index = False).mean())","94d2d34c":"print(train_data[['Married', 'CoapplicantIncome']].groupby('Married', as_index = False).median())","637494dc":"train_data[['Married', 'Gender']].groupby('Gender').count()","81693f81":"train_data[train_data['Married'].isnull()]\n","980a575b":"train_data.set_value(435, 'Married', 'Yes')\ntrain_data.set_value(104, 'Married', 'Yes')\ntrain_data.set_value(228, 'Married', 'No')","60c2971c":"train_data[['Loan_Status', 'Gender']].groupby(['Gender']).mean()","570840a9":"train_data.columns","4c8d4be8":"train_data.Married.unique()","2036dea2":"train_data[['Married', 'Gender', 'Loan_Status']].groupby(['Married'], as_index = False).mean()","15a8faa3":"sns.violinplot(x = 'Education', y = 'Loan_Status', data = train_data)","f52f36ac":"train_data[['Property_Area', 'Loan_Status']].groupby(['Property_Area'], as_index = False).mean().sort_values(['Loan_Status'], ascending = False)","66137b9d":"axes = plt.gca()\naxes.set_xlim([0,25000])\nsns.swarmplot(x = 'ApplicantIncome', y = 'Property_Area', data = train_data, hue = 'Loan_Status')","24123fb6":"print(train_data.Dependents.unique())\ntrain_data[['Dependents', 'Loan_Status']].groupby(['Dependents'], as_index = False).mean()","ff104596":"train_data['Dependents'].dtype","4e2e00c9":"# Converting Married to nominal variables. \ncombine = [train_data, test_data]\nfor dataset in combine: \n    dataset['Married'] = dataset['Married'].map({'Yes' : 1, 'No' : 0})\ntrain_data.head()","3a63de33":"train_data[['Married', 'Gender', 'Education']].groupby(['Education', 'Married']).count()","b2e5c542":"combine = [train_data, test_data]","96620152":"train_data.isnull().sum()\n","feb5bb26":"train_data[['Married', 'Dependents', 'Gender']].groupby(['Dependents', 'Gender'], as_index = False).mean() ","07a35c67":"sns.swarmplot(x = 'Dependents', y = 'ApplicantIncome', hue = 'Married', data = train_data)","5c5a9ba5":"train_data[['Married', 'Dependents', 'ApplicantIncome']].groupby('Dependents').median()","d15252cb":"train_data[['Education', 'Dependents', 'Married']].groupby(['Dependents', 'Education'], as_index = False).count()","c8f3f77f":"train_data[['Self_Employed', 'Dependents']].groupby('Dependents', as_index = False).count().pivot(columns = 'Self_Employed', index = 'Dependents')","821a9055":"train_data[['Property_Area', 'Dependents']].groupby(['Dependents'], as_index = False).count()","c3c6e734":"train_data[['Gender', 'Dependents', 'ApplicantIncome']].groupby(['Dependents', 'Gender'], as_index = False).median()","25cefcba":"train_data[train_data['Dependents'].isnull()]","a6397bb5":"train_data.groupby('Dependents')['Dependents'].count()","570cfca9":"# Individual Manual Changes \ntrain_data.set_value(102, 'Dependents','3+')\ntrain_data.set_value(332, 'Dependents', '0')\ntrain_data.set_value(335, 'Dependents', '2')\ntrain_data.set_value(597, 'Dependents', '0')","57481d94":"for dataset in combine:   \n    # For males\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] < 3683.5) & (dataset['Gender'] == 'Male'), 'Dependents'] = '0'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3683.5) & (dataset['ApplicantIncome'] <= 3931.5) & (dataset['Gender'] == 'Male'),'Dependents'] = '1'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3931.5) & (dataset['ApplicantIncome'] <= 4200.0) & (dataset['Gender'] == 'Male'),'Dependents'] = '2'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Male'), 'Dependents'] = '3+'\n    \n    # For Females \n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] < 3416.0) & (dataset['Gender'] == 'Female'), 'Dependents'] = '0'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4608.0) & (dataset['ApplicantIncome'] <= 4200) & (dataset['Gender'] == 'Female'),'Dependents'] = '1'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3427.0) & (dataset['ApplicantIncome'] <= 4608.0) & (dataset['Gender'] == 'Female'),'Dependents'] = '2'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Female'), 'Dependents'] = '3+'\ntrain_data.isnull().sum()","61dbf4ba":"print(test_data.isnull().sum())\nprint(\"\\n\")\ntest_data[test_data['Dependents'].isnull()]","8974c2d2":"freq_gender = train_data.Gender.dropna().mode()[0]\nfreq_gender","1a3cbff9":"for dataset in combine: \n    dataset['Gender'] = dataset['Gender'].fillna(freq_gender)\n    \ntrain_data[['Gender', 'Loan_Status']].groupby('Gender', as_index = False).mean()","f7ab9eee":"for dataset in combine:   \n    # For males\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] < 3683.5) & (dataset['Gender'] == 'Male'), 'Dependents'] = '0'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3683.5) & (dataset['ApplicantIncome'] <= 3931.5) & (dataset['Gender'] == 'Male'),'Dependents'] = '1'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3931.5) & (dataset['ApplicantIncome'] <= 4200.0) & (dataset['Gender'] == 'Male'),'Dependents'] = '2'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Male'), 'Dependents'] = '3+'\n    \n    # For Females \n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] < 3416.0) & (dataset['Gender'] == 'Female'), 'Dependents'] = '0'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4608.0) & (dataset['ApplicantIncome'] <= 4200) & (dataset['Gender'] == 'Female'),'Dependents'] = '1'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 3427.0) & (dataset['ApplicantIncome'] <= 4608.0) & (dataset['Gender'] == 'Female'),'Dependents'] = '2'\n    dataset.loc[(dataset['Dependents'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Female'), 'Dependents'] = '3+'\ntrain_data.isnull().sum()","333b8538":"for dataset in combine: \n    dataset.loc[(dataset['Self_Employed'].isnull()) & (dataset['Education'] == 'Not Graduate'), 'Self_Employed'] = 'No'\ntrain_data.isnull().sum()","cbb3c87c":"train_data['Dependents'] = train_data['Dependents'].map( {'0' : 0, '1' : 1, '2' : 2, '3+' : 3} )\ntrain_data.head(10)","70629182":"test_data['Dependents'] = test_data['Dependents'].map( {'0' : 0, '1' : 1, '2' : 2, '3+' : 3} )\ntest_data.head(10)","cf6b2231":"train_data[['ApplicantIncome', 'Self_Employed']].groupby('Self_Employed', as_index = False).median()","975a2fce":"combine = [train_data, test_data]\nfor dataset in combine: \n    dataset['Self_Employed'] = dataset['Self_Employed'].dropna(0).map({'No' : 0, 'Yes' : 1})\ntrain_data.head(20)","8f2cb19c":"train_data[['Self_Employed', 'Gender']].groupby('Gender', as_index = False).mean()","35698655":"train_data[['Self_Employed', 'Education']].groupby('Education', as_index = False).mean()","69df79d0":"train_data[['Self_Employed', 'Dependents']].groupby('Self_Employed', as_index = False).mean()","9617e927":"train_data[['Self_Employed', 'Married', 'Gender']].groupby(['Married', 'Gender'], as_index = False).mean()","3653aad2":"for dataset in combine:\n    dataset.loc[(dataset['Self_Employed'].isnull()) & (dataset['ApplicantIncome'] < 5809), 'Self_Employed'] = 0\n    dataset.loc[(dataset['Self_Employed'].isnull()) & (dataset['ApplicantIncome'] >= 5809), 'Self_Employed'] = 1\ntrain_data.head()","ef7e799c":"train_data.describe()\n","27e705e2":"plt.figure(figsize = (15, 10))\nsns.heatmap(train_data.corr(), annot = True)","79284b74":"# train_data['IncomeBand'] = pd.cut(train_data['Loan_Amount_Term'], 7)\n# train_data[['IncomeBand', 'Loan_Status']].groupby(['IncomeBand'], as_index = False).mean()","99d141c9":"# for dataset in combine:    \n#     dataset.loc[ dataset['ApplicantIncome'] <= 11700.0, 'ApplicantIncome'] = 0\n#     dataset.loc[(dataset['ApplicantIncome'] > 11700.0) & (dataset['ApplicantIncome'] <= 23250.0), 'ApplicantIncome'] = 1\n#     dataset.loc[(dataset['ApplicantIncome'] > 23250.0) & (dataset['ApplicantIncome'] <= 34800.0), 'ApplicantIncome'] = 2\n#     dataset.loc[(dataset['ApplicantIncome'] > 34800.0) & (dataset['ApplicantIncome'] <= 46350.0), 'ApplicantIncome'] = 3\n#     dataset.loc[(dataset['ApplicantIncome'] > 46350.0) & (dataset['ApplicantIncome'] <= 57900.0), 'ApplicantIncome'] = 4\n#     dataset.loc[(dataset['ApplicantIncome'] > 57900.0) & (dataset['ApplicantIncome'] <= 69450.0), 'ApplicantIncome'] = 5\n#     dataset.loc[ dataset['ApplicantIncome'] > 69450, 'ApplicantIncome'] = 7\n# train_data.tail(20)","0898cabc":"train_data['LoanAmount'].fillna(train_data['LoanAmount'].median(), inplace = True)\ntrain_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median(), inplace = True)\ntest_data['LoanAmount'].fillna(train_data['LoanAmount'].median(), inplace = True)\ntest_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median(), inplace = True)","145d6945":"train_data.isnull().sum()","ce30d179":"train_data[['Credit_History', 'Education']].groupby('Education', as_index = False).mean()","3bc0e537":"train_data[['Credit_History', 'ApplicantIncome']].groupby('Credit_History', as_index = False).mean()","8e8fb29e":"import random\nfor dataset in combine:   \n    # For males\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] < 3683.5) & (dataset['Gender'] == 'Male'), 'Credit_History'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 3683.5) & (dataset['ApplicantIncome'] <= 3931.5) & (dataset['Gender'] == 'Male'),'Credit_History'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 3931.5) & (dataset['ApplicantIncome'] <= 4200.0) & (dataset['Gender'] == 'Male'),'Credit_History'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Male'), 'Credit_History'] = random.randint(0,1)\n    \n    # For Females \n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] < 3416.0) & (dataset['Gender'] == 'Female'), 'Dependents'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 4608.0) & (dataset['ApplicantIncome'] <= 4200) & (dataset['Gender'] == 'Female'),'Credit_History'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 3427.0) & (dataset['ApplicantIncome'] <= 4608.0) & (dataset['Gender'] == 'Female'),'Credit_History'] = random.randint(0,1)\n    dataset.loc[(dataset['Credit_History'].isnull()) & (dataset['ApplicantIncome'] > 4200.0) & (dataset['Gender'] == 'Female'), 'Credit_History'] = random.randint(0,1)\ntrain_data.head(20)","d83191ef":"train_data.isnull().sum()","ee5838b1":"train_data[train_data['Credit_History'].isnull()]","3c70d423":"train_data.set_value(198, 'Credit_History', 1) \ntrain_data.set_value(323, 'Credit_History', 1) \ntrain_data.set_value(473, 'Credit_History', 1) \ntrain_data.set_value(544, 'Credit_History', 0) \ntrain_data.set_value(556, 'Credit_History', 0) \ntrain_data.set_value(600, 'Credit_History', 0) ","fc1c5122":"train_data.isnull().any().any()","b482c05b":"test_data.isnull().sum()","c0308783":"test_data[test_data['Credit_History'].isnull()]","5e861931":"test_data.set_value(177, 'Credit_History', 1) \ntest_data.set_value(259, 'Credit_History', 0) \ntest_data.set_value(336, 'Credit_History', 1) ","019057c3":"print(train_data.isnull().any().any())\nprint(test_data.isnull().any().any())","8cb490d5":"combine = [train_data, test_data]\nfor dataset in combine: \n    dataset['Education'] = dataset['Education'].map( {'Graduate' : 1, 'Not Graduate' : 0} )\n    dataset['Property_Area'] = dataset['Property_Area'].map( {'Rural' : 0, 'Urban' : 2, 'Semiurban' : 1} )\ntrain_data.head()","dd979517":"gender = pd.get_dummies(train_data['Gender'])\ntrain_data = pd.concat([train_data, gender], axis = 1)\ntrain_data.drop('Gender', axis = 1, inplace = True)\ntrain_data.head()","f106518b":"gender = pd.get_dummies(test_data['Gender'])\ntest_data = pd.concat([test_data, gender], axis = 1)\ntest_data.drop('Gender', axis = 1, inplace = True)\ntest_data.head()","e12c2d12":"train_data = train_data.astype(int)\ntrain_data.dtypes","8cc90e78":"train_data['LoanBand'] = pd.cut(train_data['LoanAmount'], 4)\ntrain_data[['LoanBand', 'Loan_Status']].groupby('LoanBand').mean()","13543d1b":"for dataset in combine:    \n    dataset.loc[ dataset['LoanAmount'] <= 181.75, 'LoanAmount'] = 0\n    dataset.loc[(dataset['LoanAmount'] > 181.75) & (dataset['LoanAmount'] <= 354.50), 'LoanAmount'] = 1\n    dataset.loc[(dataset['LoanAmount'] > 354.50) & (dataset['LoanAmount'] <= 527.25), 'LoanAmount'] = 2\n    dataset.loc[ dataset['LoanAmount'] > 700.00, 'LoanAmount'] = 3\ntrain_data.drop('LoanBand', axis = 1, inplace = True)\ntrain_data.head()","189edc53":"X_train = train_data.drop('Loan_Status', axis = 1)\ny_train = train_data['Loan_Status']\nX_test = test_data.copy()\nprint(X_train.shape, y_train.shape, X_test.shape)","43b4111e":"# Logistic Regression \n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nacc_log","db3d47b3":"coeff_data = pd.DataFrame(train_data.columns.delete(0))\ncoeff_data.columns = ['Feature']\ncoeff_data['Correlation'] = pd.Series(logreg.coef_[0])\ncoeff_data.sort_values(by = 'Correlation', ascending = False)","8fd0d3bc":"# Support vector machines \nsvc = SVC()\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, y_train) * 100, 2)\nacc_svc","e9231d5e":"values = {}\nfor val in range(1, 51):\n    knn = KNeighborsClassifier(n_neighbors = val)\n    knn.fit(X_train, y_train)\n    Y_pred = knn.predict(X_test)\n    acc = round(knn.score(X_train, y_train) * 100, 2)\n    values[val] = acc","2013a2d5":"x_values, y_values = [], []\nfor val in values: \n    x_values.append(val)\n    y_values.append(values[val])\nfrom matplotlib import style\nstyle.use('ggplot')\nplt.figure(figsize = (15,8))\nplt.title('Accuracy Score vs Neighbours')\nplt.xlabel('Number of Neighbours')\nplt.ylabel('Accuracy Score')\nplt.legend()\nsns.barplot(x = x_values, y = y_values)","75fb1189":"acc_knn = 0\nfor val in values:\n    if values[val] > acc_knn: \n        acc_knn = values[val]\nacc_knn","509a1a96":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nacc_gaussian","487a10ef":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, y_train) * 100, 2)\nacc_perceptron","ba9b5c2b":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\nacc_linear_svc","7183f539":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\nacc_sgd","3100d47c":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(max_depth = 7)\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\nacc_decision_tree","8e56d01a":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators = 10)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nacc_random_forest","7f9c211c":"pred_values = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\npred_values.sort_values(by='Score', ascending=False)","d59579dc":"submission = pd.DataFrame({\n        \"Loan_ID\": test_sub[\"Loan_ID\"],\n        \"Loan_Status\": y_pred\n    })\n","169fce52":"submission['Loan_Status'].replace(0, 'N',inplace=True) \nsubmission['Loan_Status'].replace(1, 'Y',inplace=True)\n","cb26f539":"submission.to_csv('submission_loan.csv', index=False)","f2aa9309":"#### Convert the variables to ordinal ( Applicant Income ) ","55dfcbfb":"Convert Dependents and Self - Employed People to binary","8852fa4e":"**Inference**\n* We can see that the number of dependents are related to the marital status and their gender.  \n* Graduates have more dependents. \n* People with huge applicant income have higher chances of having a dependent. \n* Self Employed People have more dependents","e657fa34":"Let's run that set of code again so that all the values are filed. ","3e6d8ed2":"Start by converting the nominal variables to binary ","f9ba6fa8":"### Conversion of Categorical variables","07b39bd2":"## Data Wrangling","6807201a":"There are plenty of missing values and some of them are categorical variables so we need to find relations between data and plot data to estimate the missing values more accurately. ","5cfc50a2":"Logistic Regression","5e5782fe":"# Loan Prediction Problem\n\nCompany wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.\n\n","e3940ae7":"#### Inference\n\n* Loan Applicant incomes range from 150 to 81000 \n* Co applicant income 0 ( no - coapplicants ) to 41667. \n* Loan Amount ranges from 9 to 700 \n* 69% of the people get their loans approved\n* 85% of the people have their past credit guidelines met \n* More than half of the people are married ( 398 out of 611 ) \n* Most people are Males and Working in a company. \n* All IDs are unique and randomly alloted. They have no impact on the Loan_Status and can be dropped. \n* Less than half of the population work in semiurban areas but have the highest frequency of appearance. ","7ffcdc63":"Let's plot these values ","33a8a9a5":"#### Filling Self employed Category ","e8ed09d1":"This is done just to increase the randomness","740f18f7":"We can see that Loan ammount depends on applicant income. Let's make income an ordinal variable. ","4c1bc78b":"Higher chance of loan approval if you're married. ","05afe97c":"## Read Data into the dataframe","7491258a":"Let's look at the basic correlations in the data","6208d5cf":"For the married column, there are only 3 missing entries. Let's replace the data with income less than 5000 as unmarried and above 5000 as married. ","c34560f8":"Importing Necessary Libraries\n","5c0ad8f3":"## Building our models\nLet's collect our splits","6fde281b":"We see that people with no co-applicants are in most cases not married. ","70aab425":"#### Filling Loan Amount","e3af8c8c":"Simply taking mean has an std of 65. Let's try to reduce that with groups. ","7cc08dba":"Let's also change the dependents data to make it numeric for further changes. We can have 3+ as 3","8394d0be":"There are a number of dependent column values missing. Let's try and fill them. ","aecfe8eb":"## Conversion of Categorigal Variables","d0e720e0":"There is almost a similar chance of getting your loan approved irrespective of your gender. \n","d27bb4c2":"## Filling Missing Data\n","d7282c21":"Let's manuallly fill these values ","86a47fb2":"A lot of genders are missing in the test and the train data. Let's simply replace them with the mode value. \n","359d7d5a":"Semi - Urban People have higher chances of Loan Approval","346c2c2e":"We will use income as a means of replacing the values"}}