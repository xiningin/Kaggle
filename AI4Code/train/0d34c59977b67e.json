{"cell_type":{"9773fe28":"code","9477915b":"code","5b4838b4":"code","fd4aae0d":"code","e1d0278d":"code","65e1f42b":"code","ef6bb38d":"code","36b0eec9":"code","5891361d":"code","47e77adf":"code","e49352a5":"code","1a37708a":"code","d0874c7d":"code","1329a534":"code","59745723":"code","ae806fc4":"code","724096f0":"code","2e56ea03":"code","577635ae":"code","0ad25713":"code","f8fdae61":"code","f239dea0":"code","33349586":"code","402acd57":"code","58f39817":"code","3aa29b9f":"code","66f12d49":"code","e7c24ac6":"code","ed25ab2e":"code","4f518187":"code","a8f36512":"code","a9d16ae0":"code","992781e5":"code","c4450a95":"code","db757ed8":"code","ac4e7ca6":"code","b49cd113":"code","4443b9a8":"code","32561138":"code","c19502b0":"code","35d05d4d":"code","0233d4b0":"markdown","c7a4bde1":"markdown","c708332a":"markdown","36c2088e":"markdown","1a6d9e82":"markdown","0ae198c2":"markdown","739e21d1":"markdown","c727152d":"markdown","55f8d4ba":"markdown","ca5faf22":"markdown","75eb587b":"markdown","c0183815":"markdown","49766f58":"markdown","8bf5c0cc":"markdown"},"source":{"9773fe28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9477915b":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%notebook inline\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import BaggingRegressor, RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)","5b4838b4":"df = pd.read_csv(\"\/kaggle\/input\/diamonds\/diamonds.csv\")\n\nprint(df.shape)\ndf.head()","fd4aae0d":"df.isna().sum()","e1d0278d":"df.describe()","65e1f42b":"df.info()","ef6bb38d":"sns.set_style(\"darkgrid\")","36b0eec9":"plt.figure(figsize=(10,8))\nsns.countplot(\"cut\", data=df)","5891361d":"plt.figure(figsize=(15,10))\nsns.scatterplot(\"carat\", \"price\", hue= \"cut\", data= df, size=\"price\", sizes=(40,400))\nplt.show()","47e77adf":"plt.figure(figsize=(15,10))\nsns.scatterplot(\"clarity\", \"price\", data= df, size=\"price\", hue=\"clarity\", sizes=(40,400))\nplt.show()","e49352a5":"plt.figure(figsize=(10,6))\nplt.title(\"Price and Clarity\")\nsns.barplot(\"clarity\", \"price\", data=df)","1a37708a":"plt.figure(figsize=(10,6))\nsns.barplot(\"color\", \"price\", data=df)","d0874c7d":"sns.lineplot(\"color\", \"price\", data=df)","1329a534":"sns.lineplot(\"clarity\", \"price\", data=df)","59745723":"df1 = df.drop(\"Unnamed: 0\", axis = 1)","ae806fc4":"for col in df1.select_dtypes(\"object\"):\n    print(col,len(df1[col].unique()), df1[col].unique())\n    print(\"\")","724096f0":"df2 = df1.copy()","2e56ea03":"df2[\"cut\"] = df2.replace({\"Fair\": 0, \"Good\": 1, \"Very Good\": 2, \"Premium\": 3, \"Ideal\": 4})\n\ndf2[\"clarity\"] = df2.replace({\"I1\": 0, \"SI2\": 1, \"SI1\": 2, \"VS2\": 3, \"VS1\": 4, \"VVS2\": 5, \"VVS1\": 6, \"IF\": 7})","577635ae":"df2.head()","0ad25713":"corr = df2.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot = True)","f8fdae61":"models = {\n    \"                    Linear Regression\": LinearRegression(),\n    \"                                Ridge\": Ridge(),\n    \"                                Lasso\": Lasso(),\n    \"                  K Nearest Neighbors\": KNeighborsRegressor(n_neighbors=49),\n    \"                        Random Forest\": RandomForestRegressor(max_depth=5)\n}","f239dea0":"X = df2.drop([\"price\", \"color\", \"table\", \"depth\"], axis = 1)\ny = df2[\"price\"]\n\nsc = StandardScaler()\nX = sc.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 101)","33349586":"error = []\n\nfor i in range(1,50):\n    knn = KNeighborsRegressor(n_neighbors = i )\n    knn.fit(X_train, y_train)\n    pred = knn.predict(X_test)\n    error.append(np.mean(pred != y_test))","402acd57":"plt.figure(figsize=(10,7))\nplt.xlabel(\"K\")\nplt.ylabel(\"Error\")\nplt.plot(range(1,50), error, marker = \"*\")\nplt.xticks(range(1,50,2))\nplt.title(\"K vs Error\")\nplt.show()\n","58f39817":"for name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","3aa29b9f":"for name, model in models.items():\n    print(name)\n    print(\"--------------------\"*3)\n    print(\"Testing Accuracy: {:.5f}\".format(model.score(X_test, y_test)))\n    print(\"Training Accuracy: {:.5f}\".format(model.score(X_train, y_train)))\n    print(\"--------------------\"*3)\n    print('\\n')\n                     ","66f12d49":"bg_model = BaggingRegressor(KNeighborsRegressor(n_neighbors= 25), n_estimators=20, random_state=101, max_samples=0.5)","e7c24ac6":"bg_model.fit(X_train, y_train)","ed25ab2e":"bg_model.score(X_test, y_test)","4f518187":"bg_model.score(X_train, y_train)","a8f36512":"df3 = df.copy()\ndf3.drop(['Unnamed: 0', 'color', 'table', 'cut'], axis=1, inplace=True)","a9d16ae0":"dummies = pd.get_dummies(df3)","992781e5":"dummies.head()","c4450a95":"dummies.drop(dummies.iloc[:,-1], inplace=True)","db757ed8":"X = dummies.drop(\"price\", axis = 1)\ny = dummies[\"price\"]\n\nsc = StandardScaler()\nX = sc.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 101)","ac4e7ca6":"for name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","b49cd113":"for name, model in models.items():\n    print(name)\n    print(\"--------------------\"*3)\n    print(\"Testing Accuracy: {:.5f}\".format(model.score(X_test, y_test)))\n    print(\"Training Accuracy: {:.5f}\".format(model.score(X_train, y_train)))\n    print(\"--------------------\"*3)\n    print('\\n')\n                     ","4443b9a8":"bg_model = BaggingRegressor(KNeighborsRegressor(n_neighbors= 25), n_estimators=30, random_state=101, max_samples=0.3)","32561138":"bg_model.fit(X_train, y_train)","c19502b0":"\nbg_model.score(X_test, y_test)","35d05d4d":"bg_model.score(X_train, y_train)","0233d4b0":"# 2nd approach","c7a4bde1":"# checking categorical data","c708332a":"# generating dummies","36c2088e":"# bagging","1a6d9e82":"# initializing models","0ae198c2":"# splitting data","739e21d1":"# encoding data","c727152d":"# bagging","55f8d4ba":"# splitting data","ca5faf22":"# reading file and checking head ","75eb587b":"cut quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n\ncolor diamond colour, from J (worst) to D (best)\n\nclarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))","c0183815":"# EDA","49766f58":"# training ","8bf5c0cc":"# checking accuracy"}}