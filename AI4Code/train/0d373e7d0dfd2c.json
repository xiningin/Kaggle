{"cell_type":{"f88093a4":"code","bac3406f":"code","6db78cad":"code","d3e2117f":"code","7b3c5d17":"code","2b2b2e5b":"code","37c7b90c":"code","9c0e56dd":"code","315a2032":"code","d0acb4c9":"code","a46e52ef":"code","2a303367":"code","c1343f27":"code","09634239":"code","36bddcdd":"code","4a528de9":"code","7259e8a0":"code","7fcda6dd":"code","7a8c2d26":"code","492e1644":"code","5f207473":"code","7d89b646":"code","c4303f79":"code","d526b2ad":"code","16648d4b":"code","93c4ef39":"code","49b160b3":"code","0b8d115f":"code","ee6e293b":"code","a1b083c3":"code","3b7bfaf8":"code","1e2181db":"code","c82573ab":"code","e81261a0":"code","a8032a97":"code","dcb48679":"code","bb9cac89":"code","4efd567b":"code","305ee298":"code","c38e15ae":"code","057ee351":"code","bfdeee09":"code","d634accc":"code","aa49e7de":"markdown","a3fa5bee":"markdown","9849b43a":"markdown","a4362a5d":"markdown","595426fe":"markdown","ca73d4df":"markdown","5dcf04a3":"markdown","0106e0b0":"markdown","f75d80f2":"markdown","2406bd1e":"markdown","68fd67e3":"markdown","3bafc0c3":"markdown","120657cd":"markdown","423edcd7":"markdown","bb31ee9e":"markdown","855ab573":"markdown","30fa2023":"markdown","67e1332b":"markdown","1822b040":"markdown","18b2aaff":"markdown","edd44e71":"markdown","970437e5":"markdown","a73513cb":"markdown","1afb4545":"markdown","936ba21f":"markdown","22bca37e":"markdown"},"source":{"f88093a4":"# para manipula\u00e7\u00e3o de dados\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom datetime import datetime\nfrom pandas.tseries.offsets import Day, Week, MonthEnd\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom google.cloud import bigquery\nimport os\nfrom io import open\npd.options.display.max_columns = 150\n\n# para visualiza\u00e7\u00e3o de dados\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly\nimport plotly.express as px\nimport plotly.offline as py\nplotly.offline.init_notebook_mode()\nimport plotly.graph_objs as go\nimport plotly.io as pio                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \nimport pytz","bac3406f":"# Salva os dados dos testes em um DataFrame\ndata_big_five = pd.read_csv('..\/input\/big-five-personality-test\/IPIP-FFM-data-8Nov2018\/data-final.csv', sep='\\t')","6db78cad":"data_big_five.head()","d3e2117f":"# removendo colunas que n\u00e3o s\u00e3o as perguntas do question\u00e1rio\ndata = data_big_five.drop(data_big_five.columns[50:110], axis=1, inplace=False)\ndata.head()","7b3c5d17":"# estat\u00edstica descritiva dos dados\npd.options.display.float_format = \"{:.2f}\".format\ndata.describe()","2b2b2e5b":"# verificando quantidade de registros 0 (zero) em cada coluna\ndata[data == 0].count()","37c7b90c":"data = data[data > 0.00]","9c0e56dd":"# conferindo quantidade de registros 0 (zero) em cada coluna ap\u00f3s remo\u00e7\u00e3o\ndata[data == 0].count()","315a2032":"# verificando quantidade de registros NULL em cada coluna\ndata.isna().sum()","d0acb4c9":"# removendo os registros NULL do dataset\ndata = data.dropna()","a46e52ef":"# conferindo quantidade de registros NULL em cada coluna ap\u00f3s remo\u00e7\u00e3o\ndata.isna().sum()","2a303367":"# instalando o pandas profiling\n!pip install https:\/\/github.com\/pandas-profiling\/pandas-profiling\/archive\/master.zip","c1343f27":"# importando o ProfileReport\nimport pandas_profiling\nfrom pandas_profiling import ProfileReport\\","09634239":"# executando o ProfileReport\n# For large datasets, there is a configuration that disables expensive computations (such as correlations and dynamic binning)\nprofile = ProfileReport(data, title='Relat\u00f3rio - Pandas Profiling', html={'style':{'full_width':True}}, minimal = True)","36bddcdd":"# salvando o relat\u00f3rio no disco\nprofile.to_file(output_file=\"Relatorio_ProfileReport.html\")","4a528de9":"# instalando a biblioteca yellowbrik\n!pip install -U yellowbrick","7259e8a0":"# importando o m\u00e9todo KElbowVisualizer e o m\u00e9todo de clusteriza\u00e7\u00e3o K-Means\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer","7fcda6dd":"# criando objeto do tipo KMeand e KElbowVisualizer e definindo um range de valores de K de 2 a 10 para compara\u00e7\u00e3o\nkmeans = KMeans()\nvisualizer = KElbowVisualizer(kmeans, k=(2,10))","7a8c2d26":"# selecionando uma amostra aleat\u00f3ria dos dados com 20000 observa\u00e7\u00f5es\ndata_sample = data.sample(n=20000, random_state=42)","492e1644":"# executando o teste\nvisualizer.fit(data_sample)        # Fit the data to the visualizer\nvisualizer.show()                  # Finalize and render the figure","5f207473":"# carrega novamente o pacote KMeans\nfrom sklearn.cluster import KMeans","7d89b646":"# cria o objeto do tipo KMeans com o par\u00e2metro de clusters igual a 5\nkmeans = KMeans(n_clusters=5)","c4303f79":"# treina o algoritmo\nk_fit = kmeans.fit(data)","d526b2ad":"# calcula os r\u00f3tulos dos clusters para cada registro\npredicoes = k_fit.labels_","16648d4b":"# atribui os resultados em uma nova coluna no dataframe\ndata['clusters'] = predicoes\ndata.head()","93c4ef39":"# quantidade de registros atribu\u00edda a cada cluster\ndata[\"clusters\"].value_counts()","49b160b3":"# utilizando Plotly Express\nfig = px.bar(data, y = data[\"clusters\"].value_counts().index, x = data[\"clusters\"].value_counts(),orientation='h',\n             labels={\"x\": \"Quantidade de registros\",\n                     \"y\": \"Clusters\"})\nfig.show()","0b8d115f":"# Agrupando os registros por grupos\ndata.groupby('clusters').mean()","ee6e293b":"# definindo listas para os conjuntos de colunas de cada tipo de personalidade\ncol_list = list(data)\next = col_list[0:10]\nest = col_list[10:20]\nagr = col_list[20:30]\ncsn = col_list[30:40]\nopn = col_list[40:50]","a1b083c3":"# calculando a m\u00e9dia dos valores das colunas de cada tipo de personalidade\ndata_soma = pd.DataFrame()\ndata_soma['EXTRAVERSION'] = data[ext].sum(axis=1)\/10\ndata_soma['NEUROTICISM'] = data[est].sum(axis=1)\/10\ndata_soma['AGREEABLENESS'] = data[agr].sum(axis=1)\/10\ndata_soma['CONSCIENTIOUSNESS'] = data[csn].sum(axis=1)\/10\ndata_soma['OPENNESS'] = data[opn].sum(axis=1)\/10\ndata_soma['clusters'] = predicoes","3b7bfaf8":"# visualizando as m\u00e9dias por grupo\ndata_soma","1e2181db":"# visualizando a distribui\u00e7\u00e3o dos clusters dentro dos conjuntos de personalidades\nfig = px.scatter_matrix(data_soma, dimensions= ['EXTRAVERSION', 'NEUROTICISM', 'AGREEABLENESS', 'CONSCIENTIOUSNESS', 'OPENNESS'], color=\"clusters\")\nfig.show()","c82573ab":"# calculando os valores m\u00e9dios dos registros para cada tipo de personalidade e visualizando por cluster\ndata_clusters = data_soma.groupby('clusters').mean()\ndata_clusters","e81261a0":"# visualizando as m\u00e9dias de valores dos conjuntos de personalidades em cada cluster\ndata_clusters.plot()","a8032a97":"# instalando a biblioteca Gradio\n!pip install gradio","dcb48679":"# fazendo o import da biblioteca\nimport gradio as gr","bb9cac89":"# o arquivo cont\u00e9m mais dados do que apenas as quest\u00f5es, por isso filtram-se as 50 linhas a partir da 7\u00aa linha\ncodebook = open('..\/input\/big-five-personality-test\/IPIP-FFM-data-8Nov2018\/codebook.txt').read().split(\"\\n\")\ndicio_questions = codebook[7:57]    # apenas o conte\u00fado das perguntas","4efd567b":"# verificando os dados das quest\u00f5es\ndicio_questions","305ee298":"#retorna apenas o que est\u00e1 ap\u00f3s os caracteres \"\\t\" e insere em uma lista\nquestions = []\nfor q in dicio_questions:\n  q = str(q)   # garante que \u00e9 string\n  questions.append(q[q.find(\"\\t\"):].lstrip())","c38e15ae":"questions","057ee351":"# cria lista que vai receber os dados inputados atrav\u00e9s da interface do Gradio e\n# cria objeto no formato de slider com pontua\u00e7\u00e3o m\u00ednima de 1 e m\u00e1xima de 5\ninputs_questions = []\nfor q in questions:\n  obj_input = gr.inputs.Slider(minimum=1,maximum=5,step=1,default=3,label=q)\n  inputs_questions.append(obj_input)","bfdeee09":"# verificando a cria\u00e7\u00e3o dos inputs\ninputs_questions","d634accc":"def cluster_personalities(*outputs_questions):\n    outputs_questions = np.array(outputs_questions).reshape(1, -1)\n    return k_fit.predict(outputs_questions)\n\niface = gr.Interface(\n                    fn = cluster_personalities,\n                    title = \"Big Five Personality Test\",\n                    description = \"Teste para detec\u00e7\u00e3o de tra\u00e7os de personalidade\",\n                    inputs = inputs_questions,\n                    outputs=\"text\")\niface.launch(share=True)","aa49e7de":"# 2: Acessando Fontes de Dados","a3fa5bee":"- Ser\u00e1 utilizada a biblioteca Gradio para publicar uma interface para rodar o modelo e coletar novos dados para uso no modelo.\n- A interface do Gradio pede uma fun\u00e7\u00e3o para a qual o Gradio vai passar os inputs para que seja feito o processamento (nesse caso, para que seja consumido o modelo de clusteriza\u00e7\u00e3o)","9849b43a":"Lendo os dados com as quest\u00f5es do arquivo codebook.txt","a4362a5d":"### Otimiza\u00e7\u00e3o de grupos para clusteriza\u00e7\u00e3o\n\n- Ao deparar com um problema de agrupamento de dados, a primeira pergunta que vem em mente \u00e9: em quantos grupos queremos agrupar os dados?\n- Em primeiro lugar, \u00e9 necess\u00e1rio entender a regra de neg\u00f3cio.\n- Como o teste foi constru\u00eddo em cima da hip\u00f3tese de que existem 5 tipos de perdonalidades diferentes, \u00e9 natural que 5 seja o n\u00famero de grupos diferentes com caracter\u00edsticas que mais se destacam e que o algoritmo \u00e9 capaz de identificar.\n- Entretanto, existem m\u00e9todos estat\u00edsticos que estimam o n\u00famero ideal de clusters baseados na variabilidade dos dados, como o Visualizador KElbow da biblioteca Yellowbrick, que ser\u00e1 usado para fins de confirma\u00e7\u00e3o.","595426fe":"Separando apenas as quest\u00f5es dos c\u00f3digos das quest\u00f5es","ca73d4df":"### K-MEANS \n\n- K-means clustering is a type of Unsupervised Learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K.","5dcf04a3":"Biblioteca yellowbrick\n\n- Facilita a visualiza\u00e7\u00e3o de modelos e ajustes na visualiza\u00e7\u00e3o explorat\u00f3ria de modelos","0106e0b0":"# 7: Deploy","f75d80f2":"Para este problema, usaremos apenas as features correspondentes \u00e0s 50 perguntas:","2406bd1e":"O resultado acima mostra que o valor ideal de clusters para o problema \u00e9 k = 5.","68fd67e3":"* This dataset contains 1,015,342 questionnaire answers collected online by Open Psychometrics.","3bafc0c3":"Tratamento de dados missing e\/ou incoerentes","120657cd":"Distribui\u00e7\u00e3o dos dados em cada grupo","423edcd7":"# 5: Cria\u00e7\u00e3o de Modelos","bb31ee9e":"M\u00e9todo KElbowVisualizer\n\n- Vai ajudar a olhar graficamente como um modelo se comportaria com cada n\u00famero de clusters diferentes para identificar o valor ideal, baseado na variabilidade dos dados.\n- Faz uma an\u00e1lise da vari\u00e2ncia entre as observa\u00e7\u00f5es para cada K.","855ab573":"C\u00e1lculo da m\u00e9dia de cada grupo de quest\u00f5es para verificar um padr\u00e3o","30fa2023":"# 3: Manipulando os datasets","67e1332b":"Criando os inputs din\u00e2micos para o Gradio","1822b040":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# **Big Five Personalities Test Clusterization**\n\nThe Big Five personality traits, also known as the five-factor model (FFM) and the OCEAN model, is a taxonomy, or grouping, for personality traits. When factor analysis (a statistical technique) is applied to personality survey data, some words used to describe aspects of personality are often applied to the same person. For example, someone described as conscientious is more likely to be described as \"always prepared\" rather than \"messy\". This theory is based therefore on the association between words but not on neuropsychological experiments. This theory uses descriptors of common language and therefore suggests five broad dimensions commonly used to describe the human personality and psyche.\n\nThe theory identifies five factors:\n\n- `OPENNESS TO EXPERIENCE` (inventive\/curious vs. consistent\/cautious)\n- `CONSCIENTIOUSNESS` (efficient\/organized vs. extravagant\/careless)\n- `EXTRAVERSION` (outgoing\/energetic vs. solitary\/reserved)\n- `AGREEABLENESS` (friendly\/compassionate vs. critical\/rational)\n- `NEUROTICISM` (sensitive\/nervous vs. resilient\/confident)\n\n(Source: Wikipedia)\n\n","18b2aaff":"Utilizando o Pandas Profiling","edd44e71":"Download do arquivo no Kaggle no link: [Big Five Personality Test](https:\/\/www.kaggle.com\/tunguz\/big-five-personality-test)","970437e5":"# 6: Resultados","a73513cb":"- Verifica-se que o valor m\u00ednimo registrado para as quest\u00f5es \u00e9 0 (zero), o que \u00e9 incoerente com a pontua\u00e7\u00e3o do teste (escala 1 a 5)\n\n- Esses valores precisam ser identificados e removidos","1afb4545":"Criando a interface no Gradio e a fun\u00e7\u00e3o *cluster_personalities*","936ba21f":"# 1: Importando Bibliotecas\n","22bca37e":"# 4: An\u00e1lise Explorat\u00f3ria\n\n"}}