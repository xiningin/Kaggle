{"cell_type":{"4f1312a8":"code","a7566b9f":"code","2e10b629":"code","d79d60dc":"code","55e00343":"code","63eae87f":"code","da0ceb23":"code","480cb80b":"code","0798529e":"code","ef933583":"code","842f2295":"code","25921f9c":"code","c51756a9":"code","5bcf4f97":"code","d74c6506":"code","6d975245":"code","f5fc55da":"code","80a2d2fc":"code","d62e9167":"code","70bbe13d":"markdown","d0831e83":"markdown","25e4c1c5":"markdown","2fed7b5c":"markdown","e6b62c30":"markdown","0c030e8d":"markdown","30f8901d":"markdown","13abfa95":"markdown","20616cee":"markdown","393a1371":"markdown","cbcd1ca3":"markdown","0ebfc34d":"markdown"},"source":{"4f1312a8":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Visual exploratory libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Machine learning related libraries\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n","a7566b9f":"train_df = pd.read_csv(\"\/kaggle\/\/input\/\/tabular-playground-series-oct-2021\/\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv\")\n","2e10b629":"test_df.head()","d79d60dc":"# This Cell Code is adopted  from \"https:\/\/www.kaggle.com\/hrshuvo\/tps-oct-21-xgb-kfold?scriptVersionId=76104876&cellId=7\" -- Due credits to Original Author\n\n# this function will help to reduce momory \n# data will be samller with the same value\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","55e00343":"train_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)","63eae87f":"train_df.shape","da0ceb23":"train_df.dtypes.value_counts()","480cb80b":"print(list(train_df.columns))","0798529e":"#Examine the target column and its distribution graphically\ntrain_df.target.value_counts()","ef933583":"fig = plt.figure(figsize = (20,5))\nsns.countplot(x = 'target', data = train_df)\nplt.show()","842f2295":"# Any Missing Values - No Missing Values\nsum(train_df.isna().sum() >0)","25921f9c":"train_df.duplicated().sum()","c51756a9":"# Remove id, target columns \nX = train_df.drop([\"id\",\"target\"], axis = 'columns', inplace = False).values\ny = train_df['target'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.30, random_state=85)\n#Making testdf data as an array of values\ntest_submit = test_df.drop(\"id\", axis=1).values","5bcf4f97":"import xgboost as xgb\n#from xgboost import XGBClassifier\nxgb_params = {'predictor': 'gpu_predictor',\n              'tree_method':'gpu_hist',\n              'gpu_id': 0,\n              'objective':'binary:logistic'\n             }\n\nmodel = xgb.XGBClassifier(**xgb_params)\nmodel.fit(X_train, y_train)","d74c6506":"pred_test = model.predict(X_test)\npred_test \n","6d975245":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,pred_test)*100)","f5fc55da":"# predict_probabilities are  taken for submission\ny_result= model.predict_proba(test_submit)[:,1]\nprint(y_result)","80a2d2fc":"submission_result = pd.DataFrame(y_result,columns= ['target'])\nsubmission_result['id'] = test_df['id']\nsubmission_result.head()","d62e9167":"submission_result.to_csv(\"submission.csv\",index=False)","70bbe13d":"### 2. Read the train, test, submission files to respective dataframes","d0831e83":"### 6. predicting the X_test Data ","25e4c1c5":"### 4. Data Prep for Machine learning","2fed7b5c":"### 7. Model Accuracy","e6b62c30":"# Tabular Playground Series - OCT 21","0c030e8d":"### 8. Predicting the test.csv file data with the model built","30f8901d":"### 3. Memory reduction function on Data Frames to help avoid Memory exeeding error","13abfa95":"### 9. Preparing the submission file","20616cee":"### 5. XGBOOST Classification Model Building","393a1371":"### 3. Tasks to explore\n* How many Rows and columns -- Rows - 1000000, Col 287\n* What are dtypes - 240 Floats, 46 Integer types\n* Remove id Column - Soon after reading the dataframe\n* What is target column ?? -- Binary (0, 1) -- Binary Classification problem\n* How many classes - 9 Classes\n* Any Missing Values - No Missing Values\n* Any Duplicated Rows ?? - No Duplicated Rows\n* Any Duplicate Columns ?? - No Duplicated columns\n* Remove the id column from the train_df - done\n* What kind of classification can be used here ??. -- XGBoost","cbcd1ca3":"### 1. Import All necessary Libraries","0ebfc34d":"### Comment : Target data is evenly distributed "}}