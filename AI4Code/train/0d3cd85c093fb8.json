{"cell_type":{"f533ac60":"code","7d7720f9":"code","98ee84b9":"code","887fd17e":"code","4ba27ae6":"code","0511e8bc":"code","4f358fe5":"code","60299a48":"code","4df79213":"code","5e515c91":"code","b25c747d":"code","83b3f53a":"code","e9531244":"code","e92e1625":"code","ccde8833":"code","38ed9f11":"code","4bf447ce":"code","7450c7e6":"code","44ff7381":"code","67c2f352":"code","09761b65":"code","a7ac6c80":"code","a014efc9":"code","6d1c86cb":"code","642cc754":"code","d6ec892e":"code","0eecb9f4":"code","ebef3db7":"code","9bd6af9b":"code","8977c6a1":"code","3dd37320":"code","0e8f68e9":"code","180c3b08":"code","6efb98c6":"code","b4ff19ad":"markdown","7a41493c":"markdown","94d1cee4":"markdown","c814e78c":"markdown","cd2d5d92":"markdown","f0e2e9a5":"markdown","7a14eac8":"markdown","1c5c43e5":"markdown","93e03da4":"markdown","90348ee2":"markdown","ba7b5aea":"markdown","b92818b7":"markdown","0d7ffce0":"markdown","1fb0e36b":"markdown","a20ffc37":"markdown","25b32290":"markdown","c6af7569":"markdown","f2180177":"markdown","846fa628":"markdown","548ee362":"markdown","21912f0f":"markdown","70736e6b":"markdown","58311931":"markdown"},"source":{"f533ac60":"import pydicom as dicom\nimport re\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.util import montage as montage2d\n\n\nclass Patient(object):\n    def __init__(self, directory, subdir):\n        # deal with any intervening directories\n        while True:\n            subdirs = next(os.walk(directory))[1]\n            if len(subdirs) == 1:\n                directory = os.path.join(directory, subdirs[0])\n            else:\n                break\n\n        slices = []\n        for s in subdirs:\n            m = re.match(\"sax_(\\d+)\", s)\n            if m is not None:\n                slices.append(int(m.group(1)))\n\n        slices_map = {}\n        first = True\n        times = []\n        for s in slices:\n            files = next(os.walk(os.path.join(directory, \"sax_%d\" % s)))[2]\n            offset = None\n\n            for f in files:\n                m = re.match(\"IM-(\\d{4,})-(\\d{4})\\.dcm\", f)\n                if m is not None:\n                    if first:\n                        times.append(int(m.group(2)))\n                    if offset is None:\n                        offset = int(m.group(1))\n\n            first = False\n            slices_map[s] = offset\n\n        self.directory = directory\n        self.time = sorted(times)\n        self.slices = sorted(slices)\n        self.slices_map = slices_map\n        self.name = subdir\n\n    def _filename(self, s, t):\n        fname = os.path.join(self.directory,\n                                 \"sax_%d\" % s, \n                                 \"IM-%04d-%04d.dcm\" % (self.slices_map[s], t))\n        return fname\n\n    def _read_dicom_image(self, filename):\n        d = dicom.read_file(filename)\n        img = d.pixel_array\n        return np.array(img)\n\n    def _read_all_dicom_images(self):\n        f1 = self._filename(self.slices[0], self.time[0])\n        f2 = self._filename(self.slices[1], self.time[0])\n        \n        d1 = dicom.read_file(f1)\n        d2 = dicom.read_file(f2)\n        \n        (x, y) = d1.PixelSpacing\n        (x, y) = (float(x), float(y))\n        self.col_scaling = x\n        self.row_scaling = y\n        \n        # try a couple of things to measure distance between slices\n        try:\n            dist = np.abs(d2.SliceLocation - d1.SliceLocation)\n        except AttributeError:\n            try:\n                dist = d1.SliceThickness\n            except AttributeError:\n                dist = 8  # better than nothing...\n\n        # 4D image array\n        self.images = np.array([[self._read_dicom_image(self._filename(d, i))\n                                for i in self.time]\n                                for d in self.slices])\n        \n        # Distance between slices in mm\n        self.dist = dist\n        \n        # Calculate depth as distance between slices times no. of slices\n        self.deph_mm = self.dist * (self.images.shape[0] - 1)\n        \n        # Area scaling, mm per pixel\n        self.area_multiplier = x * y\n        \n        # Orientation\n        self.orientation = d1.ImageOrientationPatient\n        \n    def load(self):\n        self._read_all_dicom_images()","7d7720f9":"def load_patient(patient_id, root_dir=None):\n    if not root_dir: \n        root_dir =  os.path.join('..', 'input', 'train', 'train')\n    patient_id = str(patient_id)\n    base_path = os.path.join(root_dir, patient_id)\n    try:\n        tdata = Patient(base_path, patient_id)\n        tdata.load()\n        # If data does not contain 4 dimensions, throw it away\n        if len(tdata.images.shape) == 4:\n            return tdata\n    except (ValueError, TypeError, IndexError, AttributeError, FileNotFoundError):\n        print('Patient %s could not be loaded.' % patient_id)\n        return None\n    \ndef load_multiple_patients(patient_ids=False, root_dir=None, verbose=False):\n    \"\"\"\n    :param patient_ids: ids of patients to load [list of integers]\n    :param root_dir: name of root dir, defaults to Kaggle root directory [string]\n    :param verbose: Whether to print every patient id when loading [boolean]\n    :return: list of [Patient] objects\n    \"\"\"\n    # If no ids are specified load all from 1-500\n    if not patient_ids:\n        patient_ids = range(1, 501)\n    patient_list = []\n    for pid in patient_ids:\n        if verbose:\n            print('Loading patient %i...' % pid)\n        p_data = load_patient(pid, root_dir=root_dir)\n        if p_data:\n            patient_list.append(p_data)\n    return patient_list","98ee84b9":"def plot_patient_slices_3d(patient_slices, title=False, figsize=(20,20)):\n    '''Plots a 2D image per slice in series (3D in total)'''\n    fig, ax = plt.subplots(1,1, figsize=figsize)\n    image = montage2d(patient_slices)\n    if title: ax.set_title(title)\n    ax.imshow(image, cmap = 'bone')\n    \n\ndef plot_patient_data_4d(patient_data, all_slices=False, slices=[0], figsize=(20,20)):\n    '''Plots a 3D image per time step in patient data (4D in total)'''\n    if all_slices: \n        slices = range(patient_data.images.shape[0])\n    for i in slices: \n        plot_patient_slices_3d(patient_data.images[i], \n                               title=('Showing slice %i' % i))","887fd17e":"import numpy as np\n\n# Based on https:\/\/gist.github.com\/ajsander\/fb2350535c737443c4e0#file-tutorial-md\ndef fourier_time_transform_slice(image_3d):\n    '''\n    3D array -> 2D array\n    [slice, height, width] -> [height, width]\n    Returns (width, height) matrix\n    Fourier transform for 3d data (time,height,weight)\n    '''\n    # Apply FFT to get first harmonic mean\n    fft_img_2d = np.fft.fftn(image_3d)[1, :, :]\n    return np.abs(np.fft.ifftn(fft_img_2d))\n\ndef fourier_time_transform(patient_images):\n    '''\n    4D array -> 3D array (compresses time dimension)\n    Concretely, [slice, time, height, width] -> [slice, height, width]\n    Description: Fourier transform for analyzing movement over time.\n    '''\n    ftt_image = np.array([\n        fourier_time_transform_slice(patient_slice)\n        for patient_slice in patient_images\n    ])\n    return ftt_image","4ba27ae6":"import numpy as np\nimport pandas as pd\n\nfrom skimage.morphology import binary_dilation, binary_erosion, binary_opening, binary_closing, disk\nfrom skimage.filters import threshold_otsu\nfrom sklearn.cluster import KMeans\n\n\ndef kmeans_segmentation(patient_img):\n    #Code for kmeans\n    xx, yy = np.meshgrid(np.arange(patient_img.shape[1]),np.arange(patient_img.shape[0]))\n    patient_df = pd.DataFrame(dict(x=xx.ravel(),y=yy.ravel(),intensity=patient_img.ravel()))\n\n    km = KMeans(n_clusters=2, random_state=2018)\n\n    scale_patient_df = patient_df.copy()\n    scale_patient_df.x = scale_patient_df.x\/250\n    scale_patient_df.y = scale_patient_df.y\/250\n    scale_patient_df['group'] = km.fit_predict(scale_patient_df[['x', 'y', 'intensity']].values)\n    seg_pat_img = scale_patient_df['group'].values.reshape(patient_img.shape)\n\n    return seg_pat_img\n    \ndef thresh_segmentation(patient_img):\n    \"\"\"Returns matrix\n    Segmententation of patient_img with threshold\n    \"\"\"\n    thresh = threshold_otsu(patient_img)\n    binary = patient_img > thresh\n    return binary\n\ndef segment_multiple(patient_img):\n    \"\"\"Returns list\n    List of segmented slices with function thresh_segmentation()\n    \"\"\"\n    num_slices, height, width = patient_img.shape\n    segmented_slices = np.zeros((num_slices, height, width))\n\n    for i in range(num_slices):\n        seg_slice = thresh_segmentation(patient_img[i])\n        if seg_slice.sum() > seg_slice.size * 0.5:\n            seg_slice = 1 - seg_slice\n        segmented_slices[i] = seg_slice\n\n    return segmented_slices\n\ndef segment_multiple_kmeans(patient_img):\n    \"\"\"Returns list\n    List of segmented slices with function kmeans_segmentation()\n    \"\"\"\n    num_slices, height, width = patient_img.shape\n    segmented_slices = np.zeros((num_slices, height, width))\n\n    for i in range(num_slices):\n        seg_slice = kmeans_segmentation(patient_img[i])\n        if seg_slice.sum() > seg_slice.size * 0.5:\n            seg_slice = 1 - seg_slice\n        segmented_slices[i] = seg_slice\n\n    return segmented_slices\n\ndef roi_mean_yx(patient_img):\n    \"\"\"Returns mean(y) and mean(x) [double]\n    Mean coordinates in segmented patients slices.\n    This function performs erosion to get a better result.\n    Original: See https:\/\/nbviewer.jupyter.org\/github\/kmader\/Quantitative-Big-Imaging-2019\/blob\/master\/Lectures\/06-ShapeAnalysis.ipynb\n    \"\"\"\n    \n    seg_slices = segment_multiple(patient_img)\n    num_slices = patient_img.shape[0]\n    y_all, x_all = np.zeros(num_slices), np.zeros(num_slices)\n    neighborhood = disk(2)\n    \n    for i,seg_slice in enumerate(seg_slices):\n        # Perform erosion to get rid of wrongly segmented small parts\n        seg_slices_eroded = binary_erosion(seg_slice, neighborhood) \n        \n        # Filter out background of slice, after erosion [background=0, foreground=1]\n        y_coord, x_coord = seg_slices_eroded.nonzero()\n        \n        # Save mean coordinates of foreground \n        y_all[i], x_all[i] = np.mean(y_coord), np.mean(x_coord)\n    \n    # Return mean of mean foregrounds - this gives an estimate of ROI coords.\n    mean_y = int(np.mean(y_all))\n    mean_x = int(np.mean(x_all))\n    return mean_y, mean_x","0511e8bc":"from skimage import exposure\n\ndef histogram_normalize_4d(images, clip_limit=0.03):\n    slices, time, _, _ = images.shape\n    norm_imgs_4d = np.empty(images.shape)\n    for i in range(slices):\n        for j in range(time):\n            norm_imgs_4d[i,j] = exposure.equalize_adapthist(images[i,j].astype(np.uint16), \n                                                            clip_limit=clip_limit)\n    return norm_imgs_4d","4f358fe5":"import cv2\n\ndef rescale_patient_4d_imgs(patient):\n    img_4d = patient.images\n    if len(img_4d.shape) < 4: raise Exception(\"Patient images are not 4D!\")\n    num_slices, time, _, _ = img_4d.shape\n    \n    # Extract scaled DICOM width\/height multipliers\n    # http:\/\/dicom.nema.org\/dicom\/2013\/output\/chtml\/part03\/sect_10.7.html\n    fx, fy = patient.col_scaling, patient.row_scaling\n    \n    # Rescale the first 2d image, in order to find out the resulting dimensions\n    example_img = cv2.resize(src=img_4d[0,0], dsize=None, fx=fx, fy=fy)\n    scaled_height, scaled_width = example_img.shape\n    scaled_imgs = np.zeros((num_slices, time, scaled_height, scaled_width))\n    \n    for i in range(num_slices):\n        for j in range(time):\n            scaled_imgs[i,j] = cv2.resize(src=img_4d[i,j], dsize=None, fx=fx, fy=fy)\n    \n    return scaled_imgs\n\ndef crop_roi(img, dim_y, dim_x, cy, cx):\n    \"\"\"\n    Crops an image from the given coords (cy, cx), such that the resulting img is of\n    dimensions [dim_y, dim_x], i.e. height and width.\n    Resulting image is filled out from top-left corner, and remaining pixels are left black.\n    \"\"\"\n    cy, cx = int(round(cy)), int(round(cx))\n    h, w = img.shape\n    if dim_x > w or dim_y > h: raise ValueError('Crop dimensions larger than image dimension!')\n    new_img = np.zeros((dim_y, dim_x))\n    dx, dy = int(dim_x \/ 2), int(dim_y \/ 2)\n    dx_odd, dy_odd = int(dim_x % 2 == 1), int(dim_y % 2 == 1)\n\n    # Find boundaries for cropping [original img]\n    dx_left = max(0, cx - dx)\n    dx_right = min(w, cx + dx + dx_odd)\n    dy_up = max(0, cy - dy)\n    dy_down = min(h, cy + dy + dy_odd)\n\n    # Find how many pixels to fill out in new image\n    range_x = dx_right - dx_left\n    range_y = dy_down - dy_up\n    \n\n    # Fill out new image from top left corner\n    # Leave pixels outside range as 0's (black)\n    new_img[0:range_y, 0:range_x] = img[dy_up:dy_down, dx_left:dx_right]\n    return new_img\n\ndef crop_heart(images_4d, heart_pixel_size=200):\n    # Find center for cropping\n    ft_imges = fourier_time_transform(images_4d)\n    y, x = roi_mean_yx(ft_imges)\n    \n    # Create new 4d image array\n    num_slices, time, h, w = images_4d.shape\n    heart_cropped_img_4d = np.zeros((num_slices, time, heart_pixel_size, heart_pixel_size))\n    \n    for i in range(num_slices):\n        for j in range(time):\n            heart_cropped_img_4d[i,j] = crop_roi(images_4d[i,j], heart_pixel_size, heart_pixel_size, y, x)\n    \n    return heart_cropped_img_4d\n\ndef rotate_images_210_deg(images_4d, orientation):\n    \"\"\"\n    Return 4d image\n    Params 4d numpy, int\n    Idea from: kaggle.com\/c\/second-annual-data-science-bowl\/discussion\/19378\n    Description: \n                Rotates image if orientation angle is -30 degreees, which ensures\n                that the left ventricle is in the top right corner of the image.\n    \"\"\"\n    angle = np.arctan2(orientation[:3], orientation[:3]) \/ np.pi * 180 - 75\n    rotation_needed = angle[2] > (-210)\n    \n    # Check if rotation needed\n    if rotation_needed:\n        # Calculate resulting dimensions for numpy array\n        slices, time, _, _ = images_4d.shape\n        rot_width, rot_height = np.rot90(images_4d[0,0], k=1).shape\n        rot_images = np.zeros((slices, time, rot_width, rot_height))\n        \n        # Rotate images\n        for i in range(slices):\n            for j in range(time):\n                rot_images[i,j] = np.rot90(images_4d[i,j], k=1)\n        return rot_images\n    \n    # Otherwise if no rotation needed, return original images\n    return images_4d","60299a48":"from skimage.morphology import opening, disk\nfrom scipy.ndimage import distance_transform_edt\nfrom skimage.morphology import watershed\nfrom skimage.feature import peak_local_max\n\n# Code from: https:\/\/nbviewer.jupyter.org\/github\/kmader\/Quantitative-Big-Imaging-2019\/blob\/master\/Lectures\/07-ComplexObjects.ipynb\ndef watershed_img(image):\n    # Distance map\n    image_dmap = distance_transform_edt(image)\n    # Distance peaks\n    image_peaks = label(peak_local_max(image_dmap, indices=False, footprint=np.ones((40, 40)),labels=image, exclude_border=True))\n    # Watershed first once\n    ws_labels = watershed(-image_dmap, image_peaks, mask=image)\n    \n    # Reomve small segments\n    label_area_dict = {i: np.sum(ws_labels == i)for i in np.unique(ws_labels[ws_labels > 0])}\n    clean_label_maxi = image_peaks.copy()\n    lab_areas = list(label_area_dict.values())\n    # Remove 20 percentile\n    area_cutoff = np.percentile(lab_areas, 15)\n    for i, k in label_area_dict.items():\n        if k <= area_cutoff:\n            clean_label_maxi[clean_label_maxi == i] = 0\n    # Watershed again\n    ws_labels = watershed(-image_dmap, clean_label_maxi, mask=image)\n\n    return ws_labels\n\nfrom skimage.measure import label\n\ndef labeled_segmented_images(images, kmeans=False):\n    \"\"\"\n    Returns numpy array (4d)\n    Segments image and used watershed for labeling.\n    \"\"\"\n    \n    num_slices, time, height, width = images.shape\n    segmented_slices = np.zeros((num_slices, time, height, width))\n    \n    # Iterate over all slices and whole timeseries for images\n    for i in range(num_slices):\n        for j in range(time):\n            # Segmentation\n            if kmeans:\n                seg_slice = kmeans_segmentation(images[i,j]).astype(bool)\n            else:\n                seg_slice = thresh_segmentation(images[i,j])\n            \n            # Makes all segmented images same, Only used for Kmeans. (Background = 0)\n            #if seg_slice.sum() > seg_slice.size*0.5:\n            #    seg_slice = 1 - seg_slice\n            \n            # Watershed\n            labels = watershed_img(seg_slice)\n            \n            # Writes labeled segmented object to return images                     \n            segmented_slices[i,j] = labels\n\n    return segmented_slices.astype(np.uint8)\n\nfrom skimage.measure import regionprops\n\ndef find_left_ventricle(images, kmeans=False):\n    \"\"\"\n    Returns numpy array (4d)\n    Finds left ventricle from labeled segmented images\n    \"\"\"\n    \n    num_slices, time, height, width = images.shape\n    segmented_slices = np.zeros((num_slices, time, height, width))\n    \n    all_labels = labeled_segmented_images(images, kmeans)\n    \n    # Iterate over all slices and whole timeseries for images\n    for i in range(num_slices):\n        for j in range(time):\n            \n            labels = all_labels[i,j]\n            min_dist = 75\n            min_dist_label = 0\n            segment_found =  False\n            \n            # Iterate over every label in watershed labels to predict which is the left ventricle.\n            for label in np.unique(labels):\n        \n                # yx coordinates for labaled segmentation\n                yx_coord_labels = np.where(labels == label)\n                \n                # Do not count small or big segmatations (removes dots and background)\n                if len(yx_coord_labels[0]) > 8000 or len(yx_coord_labels[0]) < 100:\n                    continue\n                \n                # Upper right middle coordinates\n                cx = 3*(height\/4)\n                cy = width\/4\n                \n                # Calculates euclidiean distance between mean coordinates for segmentated labels and upper right corner of image\n                euclidiean_dist = np.sqrt((int(cy)-np.mean(yx_coord_labels[0]))**2+(int(cx)-np.mean(yx_coord_labels[1]))**2)\n                \n                # Gets min distance\n                if euclidiean_dist < min_dist:\n                    \n                    # Check if segment shape is round.\n                    regions = regionprops((labels == label).astype(int))\n                    props = regions[0]\n                    y0, x0 = props.centroid\n                    orientation = props.orientation\n                    x1 = x0 + np.cos(orientation) * 0.5 * props.major_axis_length\n                    y1 = y0 - np.sin(orientation) * 0.5 * props.major_axis_length\n                    x2 = x0 - np.sin(orientation) * 0.5 * props.minor_axis_length\n                    y2 = y0 - np.cos(orientation) * 0.5 * props.minor_axis_length\n                \n                    d1_dist = np.sqrt(abs(x0-x1)**2+abs(y0-y1)**2)\n                    d2_dist = np.sqrt(abs(x0-x2)**2+abs(y0-y2)**2)\n                    \n                    # Checks if segment is round.\n                    # This should be d1_dist\/d2_dist instead...\n                    if abs(d1_dist-d2_dist) > 30:\n                        continue\n                    \n                    min_dist_label = label\n                    min_dist = euclidiean_dist\n                    segment_found = True\n            \n            # Checks if we found a image or not\n            if segment_found:\n                # Writes segmented object to return images                     \n                segmented_slices[i,j] = (labels == min_dist_label).astype(int)\n            else:\n                segmented_slices[i,j] = np.zeros(labels.shape)\n                \n    return segmented_slices.astype(np.uint8), all_labels.astype(np.uint8)\n","4df79213":"def preprocess_pipeline(patient, heart_pixel_size=150):\n    \"\"\"\n    [Patient Object] -> [4D np.array] (segmented left ventricle)\n    \n    Preprosessing pipeline for patient:\n        1. Rescale images (1 pixel = 1 mm)\n        2. Histogram Normalize (some images are brighter than others)\n        3. Crop images aroind ROI (identified using Fourier Transform over time)\n        4. Rotate images (such that left ventricle is in top right part of img)\n        5. Segment out left ventricle (for each 2d slice)\n    \"\"\"\n    \n    # Rescale images such that 1 pixel = 1 mm\n    rescaled_imgs = rescale_patient_4d_imgs(patient)\n    \n    # Histogram normalize\n    normalized_imgs = histogram_normalize_4d(rescaled_imgs)\n    \n    # Crop around ROI\n    cropped_imgs = crop_heart(normalized_imgs, heart_pixel_size=heart_pixel_size)\n   \n    # Rotate images\n    rotated_images = rotate_images_210_deg(cropped_imgs, patient.orientation)\n    \n    #return rotated_images\n    \n    # Segment out the left ventricle\n    segmented_left_ventricle_4d, labels = find_left_ventricle(rotated_images)\n    \n    return segmented_left_ventricle_4d","5e515c91":"patient_100 = load_patient(200)","b25c747d":"rescaled_patient_100 = rescale_patient_4d_imgs(patient_100)","83b3f53a":"plot_patient_slices_3d(rescaled_patient_100[5])","e9531244":"plot_patient_slices_3d(rescaled_patient_100[:,2])","e92e1625":"normalized_patient_100 = histogram_normalize_4d(rescaled_patient_100)","ccde8833":"plot_patient_slices_3d(normalized_patient_100[5])\n","38ed9f11":"# This is set after experiments. Could be lowered for shorter runtime\nheart_pixel_size = 150","4bf447ce":"ft_patient_100 = fourier_time_transform(normalized_patient_100)","7450c7e6":"plot_patient_slices_3d(ft_patient_100)","44ff7381":"# Threshold for segmentation + erode for removing \"noise\" + mean coordinates for labels\n# Segmentation is not necessary here? We can erode than just calculate mean coordinates for intensity. \n# This would yeild a better estimate of ROI because the higher intensity the higher movement.\n\ny, x = roi_mean_yx(ft_patient_100)","67c2f352":"num_slices, time, h, w = normalized_patient_100.shape\nheart_cropped_patient_100_4d = np.zeros((num_slices, time, heart_pixel_size, heart_pixel_size))\n\nfor i in range(num_slices):\n        for j in range(time):\n            heart_cropped_patient_100_4d[i,j] = crop_roi(normalized_patient_100[i,j], heart_pixel_size, heart_pixel_size, y, x)\n","09761b65":"plot_patient_slices_3d(heart_cropped_patient_100_4d[5])","a7ac6c80":"rotated_patient_100 = rotate_images_210_deg(heart_cropped_patient_100_4d, patient_100.orientation)","a014efc9":"plot_patient_slices_3d(rotated_patient_100[5])","6d1c86cb":"segmented_left_ventricle_4d, labels = find_left_ventricle(rotated_patient_100,kmeans=False)","642cc754":"kmeans_segmented_left_ventricle_4d, labels = find_left_ventricle(rotated_patient_100,kmeans=True)","d6ec892e":"plot_patient_slices_3d(segmented_left_ventricle_4d[5])","0eecb9f4":"plot_patient_slices_3d(kmeans_segmented_left_ventricle_4d[5])","ebef3db7":"def volume_for_patient(patient_images, slice_dist):\n    \"\"\"\n    Return numpy array\n    Array of total volume at each time for segmented images\n    \"\"\"\n    \n    num_slices, time, height, width = patient_images.shape\n    volume = np.zeros((time))\n    \n    if slice_dist == 0:\n        print(\"WARNING! Slice ditance is: 0 \\n Setting slice distance to 10.\")\n        slice_dist = 10\n    \n    for i in range(time):\n        time_volume = 0\n        for j in range(num_slices):\n            xy_size = np.sum(patient_images[j,i])\n            time_volume = time_volume + xy_size * slice_dist\n            \n        # Volume in ml instead of mm^3\n        volume[i] = time_volume\/1000\n    \n    return volume ","9bd6af9b":"v = volume_for_patient(segmented_left_ventricle_4d, patient_100.dist)","8977c6a1":"plt.plot(v)","3dd37320":"patient_ex = load_patient(20)\nrescaled_patient_ex = rescale_patient_4d_imgs(patient_ex)\nnormalized_patient_ex = histogram_normalize_4d(rescaled_patient_ex)\nplot_patient_slices_3d(normalized_patient_ex[5])","0e8f68e9":"ft_patient_ex = fourier_time_transform(normalized_patient_ex)\ny, x = roi_mean_yx(ft_patient_ex)\n\nnum_slices, time, h, w = normalized_patient_ex.shape\nheart_cropped_patient_ex_4d = np.zeros((num_slices, time, heart_pixel_size, heart_pixel_size))\n\nfor i in range(num_slices):\n        for j in range(time):\n            heart_cropped_patient_ex_4d[i,j] = crop_roi(normalized_patient_ex[i,j], heart_pixel_size, heart_pixel_size, y, x)\n            \nrotated_patient_ex = rotate_images_210_deg(heart_cropped_patient_ex_4d, patient_ex.orientation)\nsegmented_left_ventricle_4d_ex, labels = find_left_ventricle(rotated_patient_ex,kmeans=False)\nplot_patient_slices_3d(segmented_left_ventricle_4d_ex[5])","180c3b08":"patient_ex = load_patient(400)\nrescaled_patient_ex = rescale_patient_4d_imgs(patient_ex)\nnormalized_patient_ex = histogram_normalize_4d(rescaled_patient_ex)\nplot_patient_slices_3d(normalized_patient_ex[5])","6efb98c6":"ft_patient_ex = fourier_time_transform(normalized_patient_ex)\ny, x = roi_mean_yx(ft_patient_ex)\n\nnum_slices, time, h, w = normalized_patient_ex.shape\nheart_cropped_patient_ex_4d = np.zeros((num_slices, time, heart_pixel_size, heart_pixel_size))\n\nfor i in range(num_slices):\n        for j in range(time):\n            heart_cropped_patient_ex_4d[i,j] = crop_roi(normalized_patient_ex[i,j], heart_pixel_size, heart_pixel_size, y, x)\n            \nrotated_patient_ex = rotate_images_210_deg(heart_cropped_patient_ex_4d, patient_ex.orientation)\nsegmented_left_ventricle_4d_ex, labels = find_left_ventricle(rotated_patient_ex,kmeans=False)\nplot_patient_slices_3d(segmented_left_ventricle_4d_ex[5])","b4ff19ad":"# Images for presentation and exam","7a41493c":"# Example patients\n\nWith patients 100, 150, 400","94d1cee4":"> ## Segmentation\n* Here, threshold is used for finding a fitting threshhold for segmentation\n* We also tried k-means but with less good result\n* The image is then segmented using the threshhold, effectively making every pixel either foreground (white = 1) or background (black = 0)\n* Lastly, by using an average of segmented pixel intesities, we identify the region of interest","c814e78c":"## Rescale Patient Images\nPatient data has been gathered on different devices, resulting in different image dimensions across patients. However, all DICOM images contain metadata about the scaling of the images, which we will use to normalize patient images.\nNext, we would like to remove unnecessary data, i.e. everything that is not the heart, since this cuts down on the input size for the data analysis.\n\nThe pre-processing is therefore a 2-step process:\n* Rescale patient images, such that 1 pixel = 1 mm\n* Crop out Region of Interest (Heart)","cd2d5d92":"### 5. Segment out left ventricle\nFor each 2d slice. Uses watershed (go up for implementation). \nAlso tried Threshold, K-means and EM Segmentation with worse result.\nEM segmentation took way to long time. \n\nK-means similar result but way longer time.","f0e2e9a5":"## Fourier Transform","7a14eac8":"### 4. Rotate images \nSuch that left ventricle is in top right part of img\n","1c5c43e5":"## Complete Preproc Pipeline\nHeavily inspired by the this paper: https:\/\/arxiv.org\/pdf\/1809.06247.pdf","93e03da4":"### 3. Crop images aroind ROI \n\nIdentified using Fourier Transform over time","90348ee2":"### 2. Histogram Normalize\nSince some images are brighter than other and we want same contrast over all images we do histogram normalization.\nHere it would be good to check intensity normalization also?\n\nImages seemed to not be noisy and no noise filter was used.\n![image.png](attachment:image.png)**","ba7b5aea":"### Example with other patients","b92818b7":"Plot all time steps for slice 5","0d7ffce0":"Plot all slices for time step 2","1fb0e36b":"## Histogram Normalize\nApply histogram normalization to each 2d image in the 4d image\n\nEqualize_adapthist: (Gave better result) \nAn algorithm for local contrast enhancement, that uses histograms computed over different tile regions of the image. Local details can therefore be enhanced even in regions that are darker or lighter than most of the image. Region = 1\/8 * image size\n\n\n* source: https:\/\/scikit-image.org\/docs\/dev\/auto_examples\/color_exposure\/plot_equalize.html","a20ffc37":"Just one bad segmentation ca lead to patient beeing miss diagnosed since max\/min value where taken.","25b32290":"### 6. Caluculating Volume\nSince every 4d image is scaled 1:1 we sum upp all voxels for each timestep. Then we take max\/min to calculate ejection rate.","c6af7569":"Threshold Segmentation Plot","f2180177":"### Load Patient(s)\n\n","846fa628":"### 1. Rescale images \nRescale images to 1 pixel = 1 mm","548ee362":"## Segmenting the Left Ventricle","21912f0f":"Fourier transform calculating first harmonic mean","70736e6b":"Kmeans Segmentation Plot","58311931":"### Plotting functions"}}