{"cell_type":{"e65bc5bb":"code","7f36562c":"code","65f7a9ff":"code","344daab0":"code","4c555bb1":"code","84d3fe3f":"code","7e812c12":"code","b0c86716":"code","096e73d5":"markdown","5d6b6d4d":"markdown","a4cb175d":"markdown","d929260f":"markdown","6a460489":"markdown"},"source":{"e65bc5bb":"import pandas as pd\nimport numpy as np\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import RepeatedKFold\nfrom datetime import datetime","7f36562c":"nrows=None # ~10k row rapid model iteration\n\ntrain_data = pd.read_csv(\"train\/train.csv\", nrows=nrows)\ntest_data = pd.read_csv(\"test\/test.csv\", nrows=nrows)\nsubmission = pd.read_csv(\"submissions\/sample_submission.csv\", nrows=nrows)\n\ntrain_data.head()","65f7a9ff":"def difference_operator(df, feature):\n    col_name = f\"{feature}_diff\"\n\n    # (next point - previous point) \/ (next time \/ previous time) ~= d\/dt at the point\n    # iterate for further derivatives\n    df[col_name] = (\n        df[feature].shift(-1).fillna(method=\"ffill\")\n        - df[feature].shift(1).fillna(method=\"bfill\")\n    ) \/ (\n        df[\"time_step\"].shift(-1).fillna(method=\"ffill\")\n        - df[\"time_step\"].shift(1).fillna(method=\"bfill\")\n    )\n\n    return df\n\n\ndef add_features(df):\n    # Desc Stats\n    df[\"u_in_mean\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"mean\")\n    df[\"u_in_median\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"median\")\n    df[\"u_in_min\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"min\")\n    df[\"u_in_max\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\n    df[\"u_in_delta\"] = df[\"u_in_max\"] - df[\"u_in_min\"]\n    df[\"first_value_u_in\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"first\")\n    df[\"last_value_u_in\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"last\")\n\n    # Leads and Lags\n    df[\"u_in_lag1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(1).fillna(method=\"bfill\")\n    df[\"u_in_lag_back1\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-1).fillna(method=\"ffill\"))\n    df[\"u_in_lag2\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(2).fillna(method=\"bfill\")\n    df[\"u_in_lag_back2\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-2).fillna(method=\"ffill\"))\n    df[\"u_in_lag3\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(3).fillna(method=\"bfill\")\n    df[\"u_in_lag_back3\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-3).fillna(method=\"ffill\"))\n\n    df[\"time_lag\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(1).fillna(method=\"bfill\"))\n    df[\"time_lag_back\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(-1).fillna(method=\"ffill\"))\n\n    # Derivatives at the point.\n    difference_operator(df, \"u_in\")\n    difference_operator(df, \"u_in_diff\")\n    difference_operator(df, \"u_in_diff_diff\")\n    difference_operator(df, \"u_in_diff_diff_diff\")\n\n    # Area under u_in curve\n    df[\"area\"] = df[\"time_lag_back\"] * df[\"u_in\"]\n    df[\"area_uout_open\"] = df[\"time_lag_back\"] * df[\"u_in\"] * df[\"u_out\"]\n\n    df[\"tot_area\"] = df.groupby([\"breath_id\"])[\"area\"].transform(\"sum\")\n    df[\"tot_area_uout_open\"] = df.groupby([\"breath_id\"])[\"area_uout_open\"].transform(\"sum\")\n    df[\"tot_area_cum_sum\"] = df.groupby([\"breath_id\"])[\"area\"].cumsum()\n\n    # COMBINE R AND C\n    df[\"R__C\"] = df[\"R\"].astype(str) + \"__\" + df[\"C\"].astype(str)\n\n    # One Hot Encoding of R, C and R__C\n    df = df.merge(pd.get_dummies(df[\"R\"], prefix=\"R\"), left_index=True, right_index=True).drop([\"R\"], axis=1)\n    df = df.merge(pd.get_dummies(df[\"C\"], prefix=\"C\"), left_index=True, right_index=True).drop([\"C\"], axis=1)\n    df = df.merge(pd.get_dummies(df[\"R__C\"], prefix=\"R__C\"), left_index=True, right_index=True).drop([\"R__C\"], axis=1)\n\n    # https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\n    df[\"u_in_cumsum\"] = df.groupby([\"breath_id\"])[\"u_in\"].cumsum()\n    return df\n\n\ndef remove_features(df):\n    drop_list = [\"pressure\", \"id\", \"breath_id\", \"u_out\"]\n    drop_list = [feat for feat in drop_list if feat in df.columns]\n    df.drop(drop_list, axis=1, inplace=True)\n    return df\n","344daab0":"targets = train_data[[\"pressure\"]].to_numpy()\n\n# drop some unneeded features\ntrain_df = remove_features(add_features(train_data))\ntest_df = remove_features(add_features(test_data))\n\ntrain_df.head()","4c555bb1":"RS = RobustScaler()\ntrain_df = RS.fit_transform(train_df)\ntest_df = RS.transform(test_df)\n\ntrain_df[:5]","84d3fe3f":"# training params\nn_splits=3\nn_repeats=2\nepochs = 100\n\nkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n\ntest_preds = []","7e812c12":"for fold, fold_indices in enumerate(kf.split(train_df, targets)):\n\n    x_train, x_valid = train_df[fold_indices[0]], train_df[fold_indices[1]]\n    y_train, y_valid = targets[fold_indices[0]], targets[fold_indices[1]]\n\n    start_units = 256 # 128 for rapid model development, 512 seems to be the point of diminishing returns\n    model = keras.models.Sequential(\n        [\n            keras.layers.Dense(units=start_units, input_dim=x_train.shape[1], activation=\"relu\"),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(units=start_units, input_dim=x_train.shape[1], activation=\"relu\"),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(units=start_units \/ 2, activation=\"relu\"),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.1),\n            keras.layers.Dense(units=start_units \/ 2, activation=\"relu\"),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.1),\n            keras.layers.Dense(units=start_units \/ 4, activation=\"relu\"),\n            keras.layers.Dense(units=1, activation=\"linear\"),\n        ],\n        name=f\"fold_{fold}_dnn\",\n    )\n\n    model.summary()\n\n    optimizer = keras.optimizers.Adam()\n\n    model.compile(optimizer=optimizer, loss=\"mean_absolute_error\")\n\n    # save checkpoints from internal epochs\n    checkpoint_name = \"checkpoints\/checkpoints-{epoch:03d}--{val_loss:.5f}.hdf5\"\n    checkpoint = keras.callbacks.ModelCheckpoint(\n        checkpoint_name, \n        monitor=\"val_loss\", \n        verbose=1, \n        save_best_only=True, \n        mode=\"auto\"\n    )\n    callbacks_list = [checkpoint]\n\n    model.fit(\n        x_train,\n        y_train,\n        validation_data=(x_valid, y_valid),\n        epochs=epochs,\n        batch_size=1024,\n        callbacks=callbacks_list,\n        verbose=1,\n    )\n    \n    # save final model\n    model.save(f\"models\/dnn_vp_fold_{fold}_{datetime.now()}\")\n    \n    # save preds from final model for the given fold\n    test_preds.append(model.predict(test_df).squeeze().reshape(-1, 1).squeeze())","b0c86716":"submission[\"pressure\"] = sum(test_preds)\/n_splits\/n_repeats\nsubmission.to_csv(\"submission.csv\", index=False)\n\n\nprint(submission.head())","096e73d5":"## Training Setup - KFold Validation\n","5d6b6d4d":"## Feature Engineering\n\nAdding some additional features, removing unncessary features, and normalizing data using RobustScaler","a4cb175d":"## Building and Training the Model","d929260f":"## Reading in Data","6a460489":"## Building Predictions\n\nBuild and create csv of test submission details"}}