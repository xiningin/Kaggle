{"cell_type":{"8469e24b":"code","fea9281e":"code","a9935594":"code","c174f52a":"code","f46a2e6f":"code","c6e7db4f":"code","01d57a4b":"code","c0e71bbc":"code","216ead31":"code","31677239":"code","e68d01d9":"code","d9212467":"code","54d76c7b":"code","2a5af480":"code","1e1edd5c":"code","bee546cf":"code","967e3678":"code","27e17128":"code","0687a484":"code","5335191e":"code","990e61a2":"code","8c442218":"code","d312d8d5":"code","b06369a8":"code","cdaa4a0e":"code","872172ac":"code","a712857d":"code","4e30a4d2":"code","5255df2f":"code","a3e4a27a":"code","6e0f9b4a":"code","cd8e7983":"code","1dceff90":"code","d5f36459":"code","428b9265":"code","d1714b68":"code","e3b21b55":"code","bcf69b85":"code","d23b3848":"code","4fb7004c":"code","7745ed85":"code","e7be1b74":"code","bf91125a":"code","6ea6dc76":"code","3ccccd07":"code","b256801a":"markdown","4264e8e6":"markdown","cdeef52b":"markdown","58d04110":"markdown","600b7d40":"markdown","39dd40e9":"markdown","39d538f0":"markdown","317e7dbc":"markdown","d4812039":"markdown","4c9b06d2":"markdown","509ef056":"markdown","f1040431":"markdown","9cb3da57":"markdown","8d3f993e":"markdown","3dbf6a77":"markdown","803ab4e0":"markdown","ef0290fb":"markdown","091bd86e":"markdown","8cc98594":"markdown","42f2e842":"markdown","49765357":"markdown","cf0beab9":"markdown","81633ddd":"markdown","0c0363db":"markdown","5e3c3b56":"markdown","36286e28":"markdown","cdd6dd64":"markdown","6af40676":"markdown","d5166e18":"markdown","c39a171f":"markdown","05121b5b":"markdown","6e4845c9":"markdown","ed7d357c":"markdown","e71c9ec3":"markdown","3bdbf55f":"markdown","21254d6d":"markdown","f6311bb8":"markdown","ee648750":"markdown","a57f3258":"markdown","50dfcebf":"markdown","bf70a908":"markdown","5e6711ff":"markdown","76564d14":"markdown","7df6ca67":"markdown","089e12e9":"markdown","baa8b223":"markdown","dda172f2":"markdown"},"source":{"8469e24b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport datetime\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\nimport time\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nstart_time = time.time()\nX = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = 3_000_000)\nX_test = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/test.csv')\nX.head()","fea9281e":"X.info()","a9935594":"X.describe()","c174f52a":"# Correla\u00e7\u00e3o das vari\u00e1veis\ncorrelation = X.corr()\n\nplt.figure(figsize=(8,8))\nsns.heatmap(correlation, annot = True)\nplt.title('Correla\u00e7\u00e3o das Vari\u00e1veis')\n\nplt.show()","f46a2e6f":"missing_val_count_by_column = (X.isnull().sum())\nprint('Features com dados faltantes no DataSet:')\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\n\n\nqtd_inicial, _ = X.shape\nprint('Retirando linhas que possuem valores faltantes')\nX.dropna(inplace=True)\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))\n\n","c6e7db4f":"fig, ((ax1,ax2)) = plt.subplots(figsize = [14,6],nrows = 1, ncols = 2)\nplt.subplots_adjust(left=0, bottom=None, right=1, top=0.5, wspace = 0.8, hspace=None)\nsns.set(style=\"darkgrid\")\n\nax1.boxplot(X['fare_amount'])\nax1.set_title('Boxplot - Pre\u00e7o das corridas')\n\n\nsns.distplot(a=X['fare_amount'], kde=False)\nax2.set_title('Distribui\u00e7\u00e3o do pre\u00e7o das corridas')\nax2.set_xlabel('Pre\u00e7o')\nax2.set_ylabel('Quantidade')\n\n\nplt.tight_layout()\nplt.show()","01d57a4b":"def clean_fare_amount(df):\n    return df[(df.fare_amount > 0) & (df.fare_amount < 200)]\nqtd_inicial, _ = X.shape\nX = clean_fare_amount(X)\n\nprint('Retirando linhas que possuem pre\u00e7os inv\u00e1lidos')\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))\n","c0e71bbc":"# Verificando os outliers nas longitudes e latitudes\nfig, (ax1,ax2) = plt.subplots(figsize = [14, 6],nrows = 1, ncols = 2)\n\nax1.boxplot(X['pickup_latitude'])\nax2.boxplot(X['pickup_longitude'])\n\nax1.set_title('Latitude de partida')\nax2.set_title('Longitude de partida')\n\nax1.set_ylabel('Latitude')\nax2.set_ylabel('Longitude')\n\n\nfig.show()","216ead31":"def clean_locations(df):\n    return df[\n            (df.pickup_longitude > -80) & (df.pickup_longitude < -70) &\n            (df.pickup_latitude > 35) & (df.pickup_latitude < 45) &\n            (df.dropoff_longitude > -80) & (df.dropoff_longitude < -70) &\n            (df.dropoff_latitude > 35) & (df.dropoff_latitude < 45) \n            ]\n","31677239":"qtd_inicial, _ = X.shape\nprint('Retirando linhas que possuem localiza\u00e7\u00f5es inv\u00e1lidas')\nX = clean_locations(X)\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))\n","e68d01d9":"from math import radians, cos, sin, asin, sqrt\ndef generate_distances(df):\n    \"\"\"\n    Calcula e adiciona a dist\u00e2ncia em linha reta e a dist\u00e2ncia de haversine ao dataframe.\n    As dist\u00e2ncias s\u00e3o dadas em km\n    \"\"\"\n    # Pegando as coordenadas (aplicando transforma\u00e7\u00e3o para radiano)\n    pickup_latitude = df['pickup_latitude']*57.2958\n    pickup_longitude = df['pickup_longitude']*57.2958\n    dropoff_latitude = df['dropoff_latitude']*57.2958\n    dropoff_longitude = df['dropoff_longitude']*57.2958\n    \n    # Calculando a dist\u00e2ncia em linha reta\n    \n    straight_distance = (((pickup_latitude - dropoff_latitude)*1.852)**2 + ((pickup_longitude - dropoff_longitude)*1.852)**2)**0.5\n    \n    # Calculando a dist\u00e2ncia de haversine\n    R = 6371\n    phi1 = np.radians(df['pickup_latitude'])\n    phi2 = np.radians(df['dropoff_latitude'])\n    phi_chg = np.radians(df['pickup_latitude'] - df['dropoff_latitude'])\n    delta_chg = np.radians(df['pickup_longitude'] - df['dropoff_longitude'])\n    a = np.sin(phi_chg \/ 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_chg \/ 2)**2\n    haversine_distance = 2*R*np.arcsin(a**0.5)\n   \n    # Adicionando a dist\u00e2ncia em linha reata e a dist\u00e2ncia de harversina ao dataframe\n    df['straight_distance'] = straight_distance\n    df['haversine_distance'] = haversine_distance\n    ","d9212467":"# Implementando vari\u00e1veis de dist\u00e2ncia - conjunto de treino\ngenerate_distances(X)\n\n# Implementando vari\u00e1veis de dist\u00e2ncia - conjunto de teste\ngenerate_distances(X_test)\n\nX.head()","54d76c7b":"X[['straight_distance', 'haversine_distance']].describe()","2a5af480":"fig, ((ax1,ax2)) = plt.subplots(figsize = [14,6],nrows = 1, ncols = 2)\nplt.subplots_adjust(left=0, bottom=None, right=1, top=0.5, wspace = 0.8, hspace=None)\nsns.set(style=\"darkgrid\")\n\nax1.boxplot(X['straight_distance'])\nax1.set_title('Boxplot - Dist\u00e2ncia das corridas')\n\n\nsns.distplot(a=X['straight_distance'], kde=False)\nax2.set_title('Distribui\u00e7\u00e3o da dist\u00e2ncia das corridas')\nax2.set_xlabel('Dist\u00e2ncia percorrida')\nax2.set_ylabel('Quantidade')\n\n\nplt.tight_layout()\nplt.show()","1e1edd5c":"def clean_distance(df):\n    return df[(df.straight_distance > 0.2) & (df.straight_distance < 40)]","bee546cf":"qtd_inicial, _ = X.shape\nprint('Retirando linhas que possuem dist\u00e2ncias inv\u00e1lidas')\nX = clean_distance(X)\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))","967e3678":"# Verificando os outliers nas longitudes e latitudes\nfig, (ax1,ax2) = plt.subplots(figsize = [14, 6],nrows = 1, ncols = 2)\n\nax1.scatter(X['pickup_longitude'],X['pickup_latitude'],alpha=0.8, c = 'b')\nax2.scatter(X['dropoff_longitude'],X['dropoff_latitude'],alpha=0.8, c = 'r')\n\nax1.set_title('Coordenadas de Partida')\nax2.set_title('Coordenadas de Destino')\n\nax1.set_ylabel('Latitude')\nax1.set_xlabel('Longitude')\n\nax2.set_ylabel('Latitude')\nax2.set_xlabel('Longitude')\n\n\nfig.show()\n","27e17128":"def train_cluster_features(df):\n    \"\"\"\n    Usa o dataframe de treino para treinar o algoritmo de clusteriza\u00e7\u00e3o\n    \"\"\"\n    # Clusteriza\u00e7\u00e3o das coordenadas de partida\n    pickup = df[['pickup_longitude', 'pickup_latitude']]\n    pickup_model = KMeans(n_clusters = 4)\n\n    pickup_model.fit(pickup)\n\n    # Clusteriza\u00e7\u00e3o das vari\u00e1veis de destino\n    dropoff = df[['dropoff_longitude', 'dropoff_latitude']]\n    dropoff_model = KMeans(n_clusters = 4)\n\n    dropoff_model.fit(dropoff)\n    \n    return pickup_model, dropoff_model\n\ndef add_cluster_features(df, pickup_model, dropoff_model):\n    \"\"\"\n    Adiciona as features de clusteriza\u00e7\u00e3o ao dataframe (df)\n    \"\"\"\n    # Adicionando as novas features ao dataset\n    pickup = df[['pickup_longitude', 'pickup_latitude']]\n    pickup_labels = pickup_model.predict(pickup)\n    \n    df['cluster'] = pickup_labels\n    pickup_clusters = pd.get_dummies(df['cluster'], prefix = 'pickup_cluster', drop_first = False).iloc[:,1:]\n    df = pd.concat([df, pickup_clusters], axis =1).drop('cluster', axis = 1)\n\n    dropoff = df[['dropoff_longitude', 'dropoff_latitude']]\n    dropoff_labels = dropoff_model.predict(dropoff)\n    df['cluster'] = dropoff_labels\n    dropoff_clusters = pd.get_dummies(df['cluster'], prefix = 'dropoff_cluster', drop_first = False).iloc[:,1:]\n    df = pd.concat([df, dropoff_clusters], axis =1).drop('cluster', axis = 1)\n    \n    return df\n\n","0687a484":"# Recebe os modelos de treinamento dos clusters\npickup_model, dropoff_model = train_cluster_features(X)\n\n# Adiciona as features de clusteriza\u00e7\u00e3o ao conjunto de treino\nX = add_cluster_features(X, pickup_model, dropoff_model)\n\n# Adiciona as features de clusteriza\u00e7\u00e3o ao conjunto de teste\nX_test = add_cluster_features(X_test, pickup_model, dropoff_model)","5335191e":"def dist(pickup_lat, pickup_long, dropoff_lat, dropoff_long):  \n    \"\"\"\n    Calcula a dist\u00e2ncia em linha reta entre dois pontos - auxilia a fun\u00e7\u00e3o airport_feats\n    \"\"\"\n    pickup_lat = pickup_lat*57.2958\n    pickup_long = pickup_long*57.2958\n    dropoff_lat = dropoff_lat*57.2958\n    dropoff_long = dropoff_long*57.2958\n    # Calculando a dist\u00e2ncia em linha reta\n    \n    distance = (((pickup_lat - dropoff_lat)*1.852)**2 + ((pickup_long - dropoff_long)*1.852)**2)**0.5\n    \n    return distance\n\ndef airport_feats(train):\n    \"\"\"\n    Calcula se uma viagem \u00e9 de algum aeroporto ou se \u00e9 para algum aeroporto e adiciona as features ao dataset\n    \"\"\"\n    for data in [train]:\n        nyc = (-74.0063889, 40.7141667)\n        jfk = (-73.7822222222, 40.6441666667)\n        ewr = (-74.175, 40.69)\n        lgr = (-73.87, 40.77)\n        data['picking_at_center'] = (dist(nyc[1], nyc[0],\n                                          data['pickup_latitude'], data['pickup_longitude']) < 2).astype(int)\n        data['dropping_at_center'] = (dist(nyc[1], nyc[0],\n                                          data['dropoff_latitude'], data['dropoff_longitude']) < 2).astype(int)\n        data['picking_at_jfk'] = (dist(jfk[1], jfk[0],\n                                             data['pickup_latitude'], data['pickup_longitude']) < 2).astype(int)\n        data['dropping_at_jfk'] = (dist(jfk[1], jfk[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude']) < 2).astype(int)\n        data['picking_at_ewr'] = (dist(ewr[1], ewr[0], \n                                              data['pickup_latitude'], data['pickup_longitude']) < 2).astype(int)\n        data['dropping_at_ewr'] = (dist(ewr[1], ewr[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude']) < 2).astype(int)\n        data['picking_at_lgr'] = (dist(lgr[1], lgr[0],\n                                              data['pickup_latitude'], data['pickup_longitude']) < 2).astype(int)\n        data['dropping_at_lgr'] = (dist(lgr[1], lgr[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude']) < 2).astype(int)\n    return train","990e61a2":"# Implementando vari\u00e1veis de tempo - conjunto de treino\n\nX = airport_feats(X)\n\n# Implementando vari\u00e1veis de tempo - conjunto de teste\n\nX_test = airport_feats(X_test)\nX.head()","8c442218":"def fare_over_distance(df):\n    \n    df['fare_over_distance'] = df['fare_amount']\/(df['straight_distance']+ 0.0001)\n\ndef fare_over_distance_over_npass(df):\n    df['fare_over_distance_over_npass'] = df['fare_amount']\/(df['straight_distance']*df['passenger_count'] + 0.0001)\n    \nfare_over_distance(X)\nfare_over_distance_over_npass(X)\nX.head()","d312d8d5":"X.fare_over_distance.describe()","b06369a8":"X.fare_over_distance_over_npass.describe()","cdaa4a0e":"fig, ((ax1,ax2)) = plt.subplots(figsize = [14,6],nrows = 1, ncols = 2)\nplt.subplots_adjust(left=0, bottom=None, right=1, top=0.5, wspace = 0.8, hspace=None)\nsns.set(style=\"darkgrid\")\n\nax1.boxplot(X['fare_over_distance'])\nax1.set_title('Boxplot - Dist\u00e2ncia das corridas')\n\n\nsns.distplot(a=X['fare_over_distance'], kde=False)\nax2.set_title('Distribui\u00e7\u00e3o da dist\u00e2ncia das corridas')\nax2.set_xlabel('Dist\u00e2ncia percorrida')\nax2.set_ylabel('Quantidade')\n\n\nplt.tight_layout()\nplt.show()","872172ac":"def clean_fare_over_distance(df):\n    return df[(df.fare_over_distance < 20) & (df.fare_over_distance > 1.5)]","a712857d":"qtd_inicial, _ = X.shape\nprint('Retirando linhas que possuem pre\u00e7o por km muito alto ou muito baixo')\nX = clean_fare_over_distance(X)\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))","4e30a4d2":"def time_features(df):\n\n    df['data'] = df['pickup_datetime'].str.replace(\" UTC\", \"\")\n\n    df['data'] = pd.to_datetime(df['data'], format = '%Y-%m-%d %H:%M:%S')\n    df['hour_of_day'] = df.data.dt.hour\n    df['week'] = df.data.dt.week\n    df['month'] = df.data.dt.month\n    df[\"year\"] = df.data.dt.year\n    df['day_of_year'] = df.data.dt.dayofyear\n    df['week_of_year'] = df.data.dt.weekofyear\n    df[\"weekday\"] = df.data.dt.weekday\n    df[\"quarter\"] = df.data.dt.quarter\n    df[\"day_of_month\"] = df.data.dt.day\n    df.drop('data',inplace= True, axis =1)\n    \n    df['pickup_datetime'] = df.pickup_datetime.apply(\n    lambda x: datetime.datetime.strptime(x[:10], '%Y-%m-%d'))\n\n\n    cal = USFederalHolidayCalendar()\n    holidays = cal.holidays(start='2009-01-01', end='2015-12-31').to_pydatetime()\n\n    df['is_holiday'] = df.pickup_datetime.apply(lambda x: 1 if x in holidays else 0)\n    \n    return df","5255df2f":"# Implementando vari\u00e1veis de tempo - conjunto de treino\nX = time_features(X)\n# Implementando vari\u00e1veis de tempo - conjunto de teste\nX_test = time_features(X_test)","a3e4a27a":"X.head()","6e0f9b4a":"index = X.passenger_count.value_counts().index\nunique_values = X.passenger_count.value_counts()\nplt.title('Quantidade de viagens por n\u00famero de passageiros')\nplt.xlabel('Quantidade de passageiros')\nplt.ylabel('Quantidade de viagens')\nplt.bar(index,unique_values)\n\nplt.show()\n","cd8e7983":"def clean_passenger_count(df):\n    return df[(df['passenger_count'] > 0) & (df['passenger_count'] <10)]\n\n\nqtd_inicial, _ = X.shape\nprint('Retirando linhas que possuem quantidade inv\u00e1lida de passageiros')\nX = clean_passenger_count(X)\nqtd_final, _ = X.shape\nprint('Porcentagem de dados retirados do conjunto: {:.02f}%'.format((1 - qtd_final\/qtd_inicial)*100))\n","1dceff90":"total_time = time.time() - start_time\n\nprint(total_time\/60)","d5f36459":"# Correla\u00e7\u00e3o das vari\u00e1veis\ncorr = X.corr()\nfare_amount_corr = corr.loc['fare_amount']\ngood_features = abs(fare_amount_corr).sort_values(ascending = False)\ngood_features_index = good_features.index\n\n\n# G\u0155afico de barras\nplt.figure(figsize=(10,8))\n\nplt.title(\"M\u00f3dulo da Correla\u00e7\u00e3o entre Features e o Pre\u00e7o da Viagem de Taxi\")\nplt.ylabel(\"Features\")\nplt.xlabel(\"Correla\u00e7\u00e3o\")\n\nsns.barplot(y=good_features_index[1:], x=good_features[1:])\n\nplt.show()","428b9265":"# Agrupamento em rela\u00e7\u00e3o \u00e0s features de data (m\u00eas, ano, dia do m\u00eas, dia da semana, hora do dia)\nmonth = X.groupby('month').agg({'fare_amount':['mean']})\nyear = X.groupby('year').agg({'fare_amount':['mean']})\nday_of_month = X.groupby('day_of_month').agg({'fare_amount':['mean']})\nday_of_week = X.groupby('weekday').agg({'fare_amount':['mean']})\nhour_of_day = X.groupby('hour_of_day').agg({'fare_amount':['mean']})\n\n# Gerando a figura dos resultados\nfig,((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(figsize = [18, 14],nrows = 5, ncols = 1)\n\n\nax1.plot(year, 'b')\nax2.plot(month,'g')\nax3.plot(day_of_month, 'c')\nax4.plot(day_of_week, 'r')\nax5.plot(hour_of_day)\n\n\n\nax1.set_title('Fare by Year', fontsize = 18)\nax2.set_title('Fare by Month of Year', fontsize = 18)\nax3.set_title('Fare by Day of Month', fontsize = 18)\nax4.set_title('Fare by Day of Week', fontsize = 18)\nax5.set_title('Fare by Hour of Day', fontsize = 18)\n\nax1.set_xlabel('Year',fontsize = 18)\nax2.set_xlabel('Month of Year',fontsize = 18)\nax3.set_xlabel('Day of Month',fontsize = 18)\nax4.set_xlabel('Day of Week',fontsize = 18)\nax5.set_xlabel('Hour of Day',fontsize = 18)\n\nax1.set_ylabel('Fare',fontsize = 18)\nax2.set_ylabel('Fare',fontsize = 18)\nax3.set_ylabel('Fare',fontsize = 18)\nax4.set_ylabel('Fare',fontsize = 18)\nax5.set_ylabel('Fare',fontsize = 18)\n\n\nplt.style.use('seaborn')\nplt.tight_layout()\n\nplt.show()","d1714b68":"sns.kdeplot(data=X['straight_distance'], shade=True)\nplt.show()","e3b21b55":"# Agrupamento em rela\u00e7\u00e3o \u00e0s features de data (m\u00eas, ano, dia do m\u00eas, dia da semana, hora do dia)\nmonth = X.groupby('month').agg({'straight_distance':['mean']})\nyear = X.groupby('year').agg({'straight_distance':['mean']})\nday_of_month = X.groupby('day_of_month').agg({'straight_distance':['mean']})\nday_of_week = X.groupby('weekday').agg({'straight_distance':['mean']})\nhour_of_day = X.groupby('hour_of_day').agg({'straight_distance':['mean']})\n\n# Gerando a figura dos resultados\nfig,((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(figsize = [18, 14],nrows = 5, ncols = 1)\n\n\nax1.plot(year, 'b')\nax2.plot(month,'g')\nax3.plot(day_of_month, 'c')\nax4.plot(day_of_week, 'r')\nax5.plot(hour_of_day)\n\nax1.set_title('Distance by Year', fontsize = 18)\nax2.set_title('Distance by Month of Year', fontsize = 18)\nax3.set_title('Distance by Day of Month', fontsize = 18)\nax4.set_title('Distance by Day of Week', fontsize = 18)\nax5.set_title('Distance by Hour of Day', fontsize = 18)\n\nax1.set_xlabel('Year',fontsize = 18)\nax2.set_xlabel('Month of Year',fontsize = 18)\nax3.set_xlabel('Day of Month',fontsize = 18)\nax4.set_xlabel('Day of Week',fontsize = 18)\nax5.set_xlabel('Hour of Day',fontsize = 18)\n\nax1.set_ylabel('Distance',fontsize = 18)\nax2.set_ylabel('Distance',fontsize = 18)\nax3.set_ylabel('Distance',fontsize = 18)\nax4.set_ylabel('Distance',fontsize = 18)\nax5.set_ylabel('Distance',fontsize = 18)\n\n\nplt.style.use('seaborn')\nplt.tight_layout()\n\nplt.show()","bcf69b85":"idx = X[X['straight_distance'] < 10].index[0:1000]\n\n\nplt.scatter(X.straight_distance[idx], X.fare_over_distance[idx], color = 'r')\nplt.xlabel('Distancia em km')\nplt.ylabel('Tarifa por km')\nplt.title('Valor da viagem por km percorrido')\n\nplt.show()","d23b3848":"npass = X.groupby('passenger_count').agg({'fare_amount':['mean','min','max'], 'straight_distance': ['mean', 'min', 'max']})\n\nnpass","4fb7004c":"y = X.fare_amount.copy()\nkey = X_test.key.copy()\nX_test.drop(['pickup_datetime','key'] ,axis = 1, inplace=True)\n\nX_train = X[X_test.columns]","7745ed85":"# Iniciando um objeto de dataset de lgb\ndtrain = lgb.Dataset(X_train, label=y, free_raw_data=False)\n\n# Iniciando a quantiadade de folds para a valida\u00e7\u00e3o cruzada \nfolds = KFold(n_splits=5, shuffle=True, random_state=1)\n\n# A vari\u00e1vel predictions possuir\u00e1 o valor final das predi\u00e7\u00f5es para o conjunto de testes\npredictions = np.zeros(X_test.shape[0])\nparams =  {'task': 'train', 'boosting_type': 'gbdt','objective': 'regression','metric': 'rmse'}\n\n# Vari\u00e1vel que vai guardar o valor do rmse de valida\u00e7\u00e3o a cada \u00e9poca de treinamento\nevals_result = {}\n\n# Realiza\u00e7\u00e3o do treinamento e predi\u00e7\u00e3o\nfor train_index, validation_index in folds.split(X_train):\n    clf = lgb.train(\n        params=params,\n        train_set=dtrain.subset(train_index),\n        valid_sets=dtrain.subset(validation_index),\n        num_boost_round=1000, \n        early_stopping_rounds=125,\n        evals_result=evals_result,\n        verbose_eval=250\n    )\n    predictions = predictions + clf.predict(X_test) \/ folds.n_splits\n\n","e7be1b74":"# Dataframe de submiss\u00e3o\nsubmission = pd.DataFrame(predictions,columns=[\"fare_amount\"],index=X_test.index)\n\n# Colocando de volta a coluna key\nkeys = pd.DataFrame(key, columns = ['key'], index=  X_test.index)\nsubmission = pd.concat([keys, submission], axis = 1)\n\n# Valores iniciais das predi\u00e7\u00f5es\nsubmission.head()\n","bf91125a":"submission.to_csv('submit.csv', index = False)","6ea6dc76":"lgb.plot_metric(evals_result)\nplt.show()","3ccccd07":"lgb.plot_importance(clf)\nplt.show()","b256801a":"Existe tamb\u00e9m o aumento da tarifa de acordo com o dia da semana. O final de semana parece ser o momento de maior tarifa registrada. Podemos observar, tamb\u00e9m, uma sazonalidade do pre\u00e7o da tarifa em rela\u00e7\u00e3o ao m\u00eas do ano. Contudo, n\u00e3o parece existir um padr\u00e3o para o pre\u00e7o da tarifa de acordo com o dia do m\u00eas.","4264e8e6":"Em seguida, devemos refazer o datframe de submiss\u00e3o com o valor das predi\u00e7\u00f5es adquiridos.","cdeef52b":"**2.2 Descri\u00e7\u00e3o geral dos dados**","58d04110":"**3.2.5 Pre\u00e7o da viagem por quil\u00f4metro**\n\nPor fim, uma *feature* adicional ser\u00e1 adicionada ao dataframe, para que possamos compreender melhor a rela\u00e7\u00e3o entre dist\u00e2ncia da viagem e pre\u00e7o final: o pre\u00e7o da viagem por quil\u00f4metro. \u00c9 valido destacar que tal feature n\u00e3o ser\u00e1 utilizada para o treinamento, j\u00e1 que possui dados da label. Ser\u00e1 utilizada apenas para entender melhor a rela\u00e7\u00e3o da dist\u00e2ncia da viagem com o seu pre\u00e7o.\n\nA fun\u00e7\u00e3o a seguir adiciona tanto o pre\u00e7o da viagem por quil\u00f4metro, quanto o pre\u00e7o da viagem por quil\u00f4metro por quantidade de passageiros.","600b7d40":"**3.2.1 Visualiza\u00e7\u00e3o e retirada dos *outliers***\n\n","39dd40e9":"Ao utilizar a biblioteca do lightgbm ([documenta\u00e7\u00e3o](https:\/\/lightgbm.readthedocs.io\/en\/latest\/index.html)), existem duas escolhas a serem feitas: utilizar a API de treino ou a API do scikit-learn. Ambas as APIs geram os mesmos resultados se possu\u00edrem as mesmas configura\u00e7\u00f5es.\n\nPara simplificar a cria\u00e7\u00e3o do modelo, neste trabalho, optou-se por utilizar a API de treino, j\u00e1 que facilita a utiliza\u00e7\u00e3o do *early stop* quando utilizamos fun\u00e7\u00e3o de valida\u00e7\u00e3o cruzada. A desvantagem \u00e9 que dificulta a otimiza\u00e7\u00e3o de hiper-par\u00e2metros para a melhoria do modelo, contudo, devido ao esfor\u00e7o computacional elevado, n\u00e3o realizaremos essa etapa.\n\n\nPara iniciar o modelo, devemos retirar as colunas de pickup_datetime, key e as que relacionam o pre\u00e7o com a dist\u00e2ncia percorrida.","39d538f0":"**3.2.3 Clusteriza\u00e7\u00e3o da partida e do destino**\n\nNova Iorque \u00e9 dividida em 5 grandes zonas: Bronx, Brooklyn, Manhattan, Queens e Staten Island. Al\u00e9m disso, conforme mostrado na introdu\u00e7\u00e3o, existem lugares de partida e de destino especiais que afetam o pre\u00e7o das viagens. Desse modo, podemos aplicar um algoritmo de clusteriza\u00e7\u00e3o para que possamos dividir tanto as coordenadas de destino, quanto as coordenadas de partida em zonas.\n\nEm rela\u00e7\u00e3o \u00e0 vari\u00e1veis cont\u00ednuas, tais como coordenadas geogr\u00e1ficas, um dos quesitos mais importantes para o bom funcionamento de algoritmos de aprendizagem baseados em **\u00e1rvores** \u00e9 o ponto de separa\u00e7\u00e3o de classifica\u00e7\u00e3o de tais vari\u00e1veis, ou ***split points***. Por exemplo, em um dado n\u00f3 de uma \u00e1rvore de decis\u00f5es, pode ser que haja o teste para verificar se *pickup_longitude* > 74.2. De acordo com o livro \"Artificial Intelligence: A modern Approach\", o procedimento de ***splitting*** \u00e9 um dos mais custosos para os algoritmos de decis\u00f5es baseado em \u00e1rvores. Desse modo, realizar separa\u00e7\u00e3o das coordenadas de partida e de chegada em zonas pode ajudar bastante o modelo de aprendizagem.\n\nNesta se\u00e7\u00e3o, utilizaremos o algoritmo de Kmeans para realizar a clusteriza\u00e7\u00e3o e adicionar as zonas ao dataframe.\n\nPrimeiramente, visualizamos a distribui\u00e7\u00e3o das coordenadas geogr\u00e1ficas.","317e7dbc":"**3.2 Pr\u00e9-Processamento das coordenadas geogr\u00e1ficas**\n\nAs vari\u00e1veis de localiza\u00e7\u00e3o s\u00e3o particularmente importantes para a previs\u00e3o das tarifas. Daqui poderemos extrair, de forma aproximada, a dist\u00e2ncia da viagem de taxi, que \u00e9 umas das coisas que mais afetam o pre\u00e7o da viagem. Poderemos extrair, tamb\u00e9m, a zona de partida e de destino, que tamb\u00e9m impactam fortemente o pre\u00e7o. Assim como foi feito com a label, devemos, inicialmente, retirar os *outliers* que atrapalham a capacidade de previs\u00e3o dos modelos.","d4812039":"Ao comparar o gr\u00e1fico acima com o heatmap mostrado na se\u00e7\u00e3o 2.2, podemos ver uma melhora bastante significativa na correla\u00e7\u00e3o das *features*. Inicialmente, a maior correla\u00e7\u00e3o encontrada era de 0.016, com a vari\u00e1vel que representava o n\u00famero de passageiros. Com as novas vari\u00e1veis geradas, a correla\u00e7\u00e3o m\u00e1xima \u00e9 de 0.92 com a vari\u00e1vel de dist\u00e2ncia.","4c9b06d2":"O LightGBM \u00e9 um algoritmo de boosting baseado em \u00e1rvores de decis\u00f5es capaz de realizar a regress\u00e3o linear. Uma grande vantagem desse algoritmo \u00e9 que ele \u00e9 baseado em histogramas que dividem em buckets as vari\u00e1veis cont\u00ednuas, tais como as coordenadas geogr\u00e1ficas. Esse \u00e9 um dos grandes problemas que devem ser resolvidos por tais algoritmos baseados em \u00e1rvores, conforme mencionado na se\u00e7\u00e3o 3.2.3.\n\nUma particularidade do LGBM \u00e9 que esse algoritmo expande as \u00e1rvores de maior profundidade primeiro, em vez dos n\u00f3s de um mesmo n\u00edvel primeiro. A diferen\u00e7a \u00e9 basicamente a mesma entre algoritmos de busca em profundidade e algoritmos de busca em largura. A seguinte imagem denota tal diferen\u00e7a.\n\n","509ef056":"# **5. Modelagem Utilizando LGBM**","f1040431":"# **2. Importa\u00e7\u00e3o e Tratamento Inicial dos Dados**","9cb3da57":"A partir do levantamento estat\u00edstico, podemos perceber que existem outliers em todas as vari\u00e1veis do conjunto, j\u00e1 que os valores m\u00e1ximos s\u00e3o bastante diferentes do *percentile* de 75%. Na se\u00e7\u00e3o 3, realizaremos tal tratamento.","8d3f993e":"![taxi.jpeg](attachment:taxi.jpeg)","3dbf6a77":"**4.3.1 Histograma da dist\u00e2ncia percorrida**\n\n","803ab4e0":"Conforme podemos observar na tabela, o valor m\u00e9dio das tarifas e o valor m\u00e9dio da dist\u00e2ncia percorrida \u00e9 muito parecido, independentemente da quantidade de passageiros no taxi. Na cidade de Nova Iorque, n\u00e3o h\u00e1 um aumento na tarifa de acordo com a quantidade de passageiros dentro do taxi.\n\nPortanto, esse comportamento \u00e9 esperado. Para simplifica\u00e7\u00f5es de modelos de previs\u00e3o, a vari\u00e1vel \"n\u00famero de passageiros\" poderia ser retirada do conjunto de treino e de teste.","ef0290fb":"# **1. Introdu\u00e7\u00e3o**\n\nAs t\u00e9cnicas de aprendizagem de m\u00e1quina atualmente s\u00e3o largamente utilizadas para a resolu\u00e7\u00e3o de problemas complexos. Dizemos que um agente inteligente (representado por um algoritmo computacional) est\u00e1 aprendendo se ele melhora a sua perfomance em tarefas futuras ap\u00f3s realizar observa\u00e7\u00f5es em seu universo. Uma dessas t\u00e9cnicas \u00e9 particularmente interessante: a partir de uma cole\u00e7\u00e3o de entradas e sa\u00eddas (x,y), o agente deve aprender uma fun\u00e7\u00e3o f(x) = y que prev\u00ea a sa\u00edda para novas entradas. Esse procedimento \u00e9 conhecido como aprendizagem supervisionada.\n\nNem sempre \u00e9 poss\u00edvel sabermos se tal fun\u00e7\u00e3o f(x) realmente existe e, se existe, nem sempre \u00e9 poss\u00edvel prev\u00ea-la (fatores como esfor\u00e7o computacional podem impedir isso). Assim, a aprendizagem supervisionada geralmente \u00e9 focada em encontrar uma fun\u00e7\u00e3o de hip\u00f3tese h(x) que se aproxima o m\u00e1ximo poss\u00edvel da fun\u00e7\u00e3o f(x).\n\nDentro desse contexto, podemos utilizar tal t\u00e9cnica para a resolu\u00e7\u00e3o de problemas de previs\u00e3o e de classifica\u00e7\u00e3o de vari\u00e1veis. Este trabalho realiza uma tarefa de previs\u00e3o e \u00e9 voltado para a determina\u00e7\u00e3o de tarifas de corridas de taxis na cidade de Nova Iorque. Podemos imaginar que as tarifas desse servi\u00e7o seguem uma fun\u00e7\u00e3o que de fato existe e que n\u00e3o deve ser muito complexa. De fato, a fun\u00e7\u00e3o que rege o pre\u00e7o das corridas de taxi pode ser encontrada em ([*NY Taxi Rides*](https:\/\/www1.nyc.gov\/site\/tlc\/passengers\/taxi-fare.page)) e os principais pontos s\u00e3o descritos a seguir:\n* Taxa inicial de \\$2.50\n* Acr\u00e9scimo de \\$0.50 a cada 1\/5 de milha  ou a cada 60 segundos\n* Acr\u00e9scimo de \\$0.50 para viagens que acabam em lugares selecionados\n* Acr\u00e9scimo de \\$0.30 para viagens com melhorias\n* Acr\u00e9scimo de \\$0.50 para viagens entre 8pm e 6am\n* Acr\u00e9scimo de \\$1.00 para viagens na hora do rush\n* Pagamento dos ped\u00e1gios por conta dos passaegiros\n* N\u00e3o h\u00e1 acrescimo pelo n\u00famero de passageiros\n\nDesse modo, devemos extrair do conjunto de dados fornecido pelo Kaggle ([*Taxi Fares*](https:\/\/www.kaggle.com\/c\/new-york-city-taxi-fare-prediction\/overview)) *features* que expressam os pontos levantados acima para que possamos utilizar modelos de aprendizagem capazes de prever o pre\u00e7o das corridas finais. Este documento possui a seguinte organiza\u00e7\u00e3o: esta se\u00e7\u00e3o traz uma breve introdu\u00e7\u00e3o ao tema; a se\u00e7\u00e3o 2 realiza a importa\u00e7\u00e3o dos conjuntos de dados de treino e de teste, bem como uma breve visualiza\u00e7\u00e3o dos dados e o tratamento inicial; na se\u00e7\u00e3o 3 todas as vari\u00e1veis de s\u00e3o tratadas de modo a extrair *features* para a previs\u00e3o; a se\u00e7\u00e3o 4 apresenta a visualiza\u00e7\u00e3o dos *insights* e, por fim, a se\u00e7\u00e3o 5 apresenta o treinamento do modelo. ","091bd86e":"Assim como com o pre\u00e7o das tarifas ao longo do tempo, tamb\u00e9m podemos observar uma certa sazonalidade na dist\u00e2ncia das corridas. A correla\u00e7\u00e3o da vari\u00e1vel dist\u00e2ncia com a vari\u00e1vel pre\u00e7o \u00e9 muito grande, assim, \u00e9 de se esperar que seus comportamentos tamb\u00e9m se assemelhem.\n\nDa mesma maneira, podemos ver um aumento das dist\u00e2ncias percorridas ao longo dos anos na cidade de Nova Iorque. Existe, tamb\u00e9m, um momento do dia em que a dist\u00e2ncia percorrida das viagens possui um pico, que \u00e9 quase no mesmo hor\u00e1rio do pico do pre\u00e7o das corridas.","8cc98594":"**3.2.2 Implementa\u00e7\u00e3o da dist\u00e2ncia da viagem**\n\nA fun\u00e7\u00e3o a seguir utiliza 2 m\u00e9todos para o c\u00e1lculo da dist\u00e2ncia entre dois pontos representados por coordenadas geogr\u00e1ficas. O primeiro realiza o c\u00e1lculo da dist\u00e2ncia entre dois pontos em um plano e \u00e9 mais preciso quando os pontos est\u00e3o pr\u00f3ximos entre si, j\u00e1 que despreza a curvatura da terra. O segundo \u00e9 chamado de m\u00e9todo de haversine e leva a curvatura da terra em considera\u00e7\u00e3o.\n\n\u00c9 v\u00e1lido destacar que o valor da corrida dos taxis varia de acordo com a dist\u00e2ncia percorrida pelo taxi e n\u00e3o necessariamente com a dist\u00e2ncia entre os pontos de partida e de destino da viagem. Fatores como as rotas que os ve\u00edculos tomaram entre o in\u00edcio e o fim da corrida importam, mas n\u00e3o s\u00e3o levados em considera\u00e7\u00e3o pelas *features* geradas aqui. Mesmo assim, a dist\u00e2ncia percorrida deve apresentar uma correla\u00e7\u00e3o com o pre\u00e7o final da corrida","42f2e842":"Em seguida, retiramos os valores inv\u00e1lidos do conjunto.","49765357":"# **4. Visualiza\u00e7\u00e3o dos Dados**\n\nNesta se\u00e7\u00e3o, mostraremos as caracter\u00edsticas que descrevem as *features* geradas, bem como suas rela\u00e7\u00f5es com a *label* por meio de gr\u00e1ficos.","cf0beab9":"Mais uma vez, podemos perceber viagens que possuem um pre\u00e7o exorbitante por dist\u00e2ncia percorrida. Provavelmente tais valores s\u00e3o dados incorretos, j\u00e1 que devemos esperar uma monotonicidade crescente quando comparamos tais dados. Isso quer dizer que viagens curtas n\u00e3o devem ter um pre\u00e7o de corrida muito maior que viagens mais longas.\n\nDesse modo, definiremos a seguir uma fun\u00e7\u00e3o para remo\u00e7\u00e3o de linhas que possuem valores discrepantes para a rela\u00e7\u00e3o entre pre\u00e7o da corrida e dist\u00e2ncia percorrida. ","81633ddd":"Observando a primeira linha do *heatmap* de correla\u00e7\u00f5es, podemos perceber que n\u00e3o h\u00e1 uma forte correla\u00e7\u00e3o entre as vari\u00e1veis iniciais e o pre\u00e7o da corrida final. Isso \u00e9 esperado, j\u00e1 que nem coordenadas geogr\u00e1ficas nem data de in\u00edcio da viagem necessariamente expressam as regras descritas na introdu\u00e7\u00e3o deste documento.","0c0363db":"Por fim, podemos visualizar a diminui\u00e7\u00e3o do rmse ao longo das itera\u00e7\u00f5es de treinamento. Al\u00e9m disso, tamb\u00e9m visualizamos as vari\u00e1veis de maior import\u00e2ncia para a constru\u00e7\u00e3o do modelo final.","5e3c3b56":"O valor da tarifa por dist\u00e2ncia percorrida \u00e9 uma vari\u00e1vel particularmente interessante. Como existe um valor inicial a ser pago por toda corrida, independentemente da sua dist\u00e2ncia percorrida, devemos observar uma ass\u00edntota vertical na dist\u00e2ncia de 0km, j\u00e1 que efetuar\u00edamos uma divis\u00e3o por 0.\n\nObservamos, tamb\u00e9m, uma diminui\u00e7\u00e3o do pre\u00e7o por km percorrido quando as corridas come\u00e7am a se tornar muito longas. Isso talvez seja devido ao fato de que nas corridas mais longas, rotas mais livres em rela\u00e7\u00e3o ao tr\u00e2nsito estejam dispon\u00edveis, diminuindo, assim, a raz\u00e3o tempo por km percorrido. Infelizmente n\u00e3o possu\u00edmos uma vari\u00e1vel que indique quanto tempo cada uma das viagens durou para investigar melhor essa hip\u00f3tese.\n\nAl\u00e9m disso, para viagens muito longas, o pre\u00e7o da viagem pode ser combinado entre motorista e passageiro. Desse modo, pode haver um certo desconto no pre\u00e7o por km viajado, explicando porque observamos essa diminui\u00e7\u00e3o","36286e28":"**4.1 Correla\u00e7\u00e3o das *features* geradas**","cdd6dd64":"**4.4 Agrupamento de vari\u00e1veis de acordo com o n\u00famero de passageiros**","6af40676":"A latitude da cidade de Nova Iorque \u00e9 40.730610 e a longitude \u00e9 -73.935242. Conforme podemos ver pelos boxplots, existem valores muito diferentes disso, tanto na partida quanto no destino. A fun\u00e7\u00e3o a seguir foi adaptada de https:\/\/www.kaggle.com\/gunbl4d3\/xgboost-ing-taxi-fares e realiza a retirada de valores discrepantes.","d5166e18":"**4.3 Dist\u00e2ncia percorrida**","c39a171f":"# **5. Conclus\u00f5es**\n\n* Ap\u00f3s realizar a modelagem com o LGBM e a submiss\u00e3o do conjunto de dados de teste, obteve-se um rmse de 3.44801, classificando-se na posi\u00e7\u00e3o 640 do quadro de l\u00edderes. Alguma reflex\u00f5es acerca do trabalho, bem como poss\u00edveis melhorias s\u00e3o indicadas a seguir.\n\n* Conforme p\u00f4de ser observado na explora\u00e7\u00e3o de dados, algumas vari\u00e1veis foram mantidas mesmo n\u00e3o apresentando uma correla\u00e7\u00e3o t\u00e3o forte com a *label*. Para simplificar ainda mais o modelo, poder\u00edamos retirar o n\u00famero de passageiros, por exemplo.\n\n* O algoritmo implementado pelo LGBM realiza a bucketiza\u00e7\u00e3o de vari\u00e1veis cont\u00ednuas na tentativa de encontrar os melhores split points. Pelos resultados do modelo, pudemos observar que as coordenadas geogr\u00e1ficas acabaram tendo um peso mais forte do que as zonas de clusteriza\u00e7\u00e3o desenvolvidas. Como procedimentos alternativos, poder\u00edamos diminuir a quantidade de clusters ou mudar o modelo utilizado. Algoritmos de regress\u00e3o linear n\u00e3o baseados em \u00e1rvores poderiam ser testados.\n\n* Um dos fatores que parece mais afetar a qualidade do modelo desenvolvido \u00e9 o tratamento das vari\u00e1veis mais simples: a dist\u00e2ncia da viagem, os limites aplicados \u00e0 cidade de Nova Iorque e o pre\u00e7o final da viagem. Nesse sentido, poder\u00edamos realizar uma limpeza mais intesiva, diminuindo o threshold para retirada dos outliers (se\u00e7\u00e3o 3.1 e 3.2).\n\n* Conforme observado no documento do governo de Nova Iorque que rege o pre\u00e7o das viagens, o tempo da viagem tamb\u00e9m afeta o pre\u00e7o. Infelizmente n\u00e3o temos tal vari\u00e1vel fornecida no conjunto de dados. Contudo, poder\u00edamos realizar estima\u00e7\u00f5es do tempo da viagem baseado no tr\u00e2nsito no local em que a viagem ocorreu. Para isso, poder\u00edamos calcular a densidade de viagens acontecendo ao mesmo tempo em lugares pr\u00f3ximos.\n\n* A dist\u00e2ncia da viagem \u00e9 uma das *features* mais importantes criadas. Contudo, essa n\u00e3o reflete precisamente a dist\u00e2ncia percorrida pelo ve\u00edculo, j\u00e1 que n\u00e3o leva em considera\u00e7\u00e3o as ruas que foram trafegadas para chegar ao destino. \u00c9 poss\u00edvel utilizar bibliotecas que permitem a realiza\u00e7\u00e3o desse c\u00e1lculo, o que provavelmente melhoraria o desempenho do modelo.","05121b5b":"**3.2.4 Viagens dos aeroportos**\n\nAs viagens para os aeroportos ou dos aeroportos recebem uma tarifa especial. Desse modo, \u00e9 v\u00e1lido adicionar *features* que indicam se uma viagem \u00e9 para algum aeroporto ou se \u00e9 uma viagem que inicia nos aeroportos.\n\nA fun\u00e7\u00e3o a seguir \u00e9 adaptada do notebook https:\/\/www.kaggle.com\/breemen\/nyc-taxi-fare-data-exploration.","6e4845c9":"Podemos observar que o conjunto possui basicamente 6 features, que descrevem a data de in\u00edcio da corrida, as coordenadas de in\u00edcio e de fim da viagem e a quantidade de passageiros transportados. A vari\u00e1vel alvo \u00e9 o valor da corrida.\n\nPodemos perceber, tamb\u00e9m, que existem alguns valores faltantes, contudo, n\u00e3o s\u00e3o significativos. Na pr\u00f3xima subse\u00e7\u00e3o, as linhas com valores faltantes ser\u00e3o retiradas do conjunto de dados.\n\nEm seguida, podemos realizar o levantamento estat\u00edstico das vari\u00e1veis","ed7d357c":"# **3. Pr\u00e9-Processamento das Vari\u00e1veis**\n\nEsta \u00e9 uma das se\u00e7\u00f5es mais importantes do trabalho. Aqui utilizaremos as t\u00e9cnicas de *feature generation*, tratamento *outliers*, *clusteriza\u00e7\u00e3o* para tranformas as vari\u00e1veis de entrada em *features* valiosas para que os modelos possam prever adequadamente o pre\u00e7o das corridas de taxi. As subse\u00e7\u00f5es a seguir tratam cada vari\u00e1vel independentemente. As principais visualiza\u00e7\u00f5es de dados \u00e9 realizada na se\u00e7\u00e3o 4.","e71c9ec3":"![download.png](attachment:download.png)","3bdbf55f":"**3.3 Pr\u00e9-Processamento das vari\u00e1veis de tempo**\n\nAssim como as vari\u00e1veis de coordenadas, as vari\u00e1veis de tempo possuem valiosas informa\u00e7\u00f5es a serem extra\u00eddas. Fatores como hora do dia, dia da semana, m\u00eas do ano, se o dia \u00e9 um feriado ou n\u00e3o, dentre outras, afetam o pre\u00e7o das viagens de taxi.\n\nDesse modo, usamos as bibliotecas do python para a manipula\u00e7\u00e3o de vari\u00e1veis de data. A vari\u00e1vel *pickup_datetime* foi decomposta em diversas vari\u00e1veis que facilitam o uso por parte dos modelos de aprendizagem.","21254d6d":"**4.3.2 Dist\u00e2ncia percorrida ao longo do tempo**","f6311bb8":"Em seguida, definiremos o modelo, implementaremos a valida\u00e7\u00e3o cruzada e realizaremos a predi\u00e7\u00e3o das vari\u00e1veis de teste. \u00e9 necess\u00e1rio configurar os par\u00e2metros do modelo. Aqui, utilizaremos a seguinte configura\u00e7\u00e3o:\n\n* *boosting_type*: default (gradient boosting)\n* *objective*: regress\u00e3o linear\n* *metric*: rmse (root mean squared error) - utilizado para a submiss\u00e3o final do arquivo\n* *num_boost_round*: utilizaremos um valor alto (1000). Contudo, tamb\u00e9m colocaremos um valor mais baixo para o *early_stopping_rounds*, logo, esse n\u00famero de rounds n\u00e3o ser\u00e1 alcan\u00e7ado\n* *early_stopping_rounds*: utilizaremos o valor de 125. Ou seja, passadas 125 \u00e9pocas de treinamento sem altera\u00e7\u00e3o do valor do rmse, o treinamento ser\u00e1 terminado\n* *verbose_eval*: 250. Esse valor indica a cada quantas \u00e9pocas de treinamento deve-se printar o valor do rmse do conjunto de valida\u00e7\u00e3o\n","ee648750":"Al\u00e9m disso, tamb\u00e9m inclu\u00edmos uma *feature* que indica se determinado dia \u00e9 um feriado ou n\u00e3o","a57f3258":"**2.3 Tratamento inicial do conjunto**\n\nRealizamos a remo\u00e7\u00e3o dos dados faltantes do conjunto","50dfcebf":"A maioria das viagens possui uma dist\u00e2ncia percorrida menor do que 5km. Uma quantidade significativa de viagens j\u00e1 foi retirada por apresentar dist\u00e2ncias maiores do que 40km. Esse valor limite \u00e9 um dos par\u00e2metros que pode ser ajustado para melhoria do modelo, contudo, existe um certo esfor\u00e7o computacional para encontrar o valor limite \u00f3timo.\n\nExistem diversas viagens v\u00e1lidas dentro do limite da cidade de Nova Iorque com dist\u00e2ncias percorridas at\u00e9 40km, portanto, esse valor foi mantido.","bf70a908":"**2.1 Importa\u00e7\u00e3o dos dados de treino e de teste**\n\nPrimeiramente, importabos as bibliotecas necess\u00e1rias e os conjuntos de treinamento e de teste","5e6711ff":"**4.2 Valor da tarifa ao longo do tempo**\n\nNos gr\u00e1ficos a seguir, poderemos ver a rela\u00e7\u00e3o do valor da tarifa de acordo com as s\u00e9ries temporais. Como pod\u00edamos esperar, podemos ver um certo aumento na tarifa de acordo com a passagem dos anos, bem como com o hor\u00e1rio do dia.","76564d14":"Em seguida, podemos aplicar o algoritmo de clusteriza\u00e7\u00e3o e adicionar as novas *features ao dataset*. Um detalhe de implementa\u00e7\u00e3o que vale a pena destacar \u00e9 que para totalmente descrever uma vari\u00e1vel que possui k classifica\u00e7\u00f5es, s\u00f3 precisamos de k-1 valores. Por exemplo, para descrever uma vari\u00e1vel bin\u00e1ria (assume dois valores, k = 2), precisamos de apenas uma coluna que assume os valores 0 ou 1.\n\nPor isso, mesmo possuindo 4 zonas de clusteriza\u00e7\u00e3o para cada tipo, apenas 3 colunas para cada tipo s\u00e3o adicionadas ao dataset.","7df6ca67":"As viagens com 0 passageiros talvez possam ser viagens de transporte apenas de carga. De qualquer forma, podemos retir\u00e1-las do conjunto de dados, j\u00e1 que n\u00e3o h\u00e1 uma explica\u00e7\u00e3o comprovada para tal situa\u00e7\u00e3o. Al\u00e9m disso, viagens com mais de 9 passageiros parecem invi\u00e1veis para taxis urbanos e tamb\u00e9m ser\u00e3o retiradas do conjunto.\n\nA fun\u00e7\u00e3o a seguir realiza a limpeza para esse tipo de dado.","089e12e9":"**4.3.3 Valor da tarifa por dist\u00e2ncia percorrida**","baa8b223":"Assim como com as demais vari\u00e1veis, podemos perceber alguns valores estranhos para a dist\u00e2ncia das corridas de taxi. Viagens com exatamente 0 km percorridos talvez possam ser explicadas por viagens que come\u00e7aram e terminaram no mesmo lugar, mas que tiveram paradas em lugares mais distantes. De qualquer maneira, fica dif\u00edcil para modelos de aprendizagem retirarem informa\u00e7\u00f5es valiosas a partir desses dados.Portanto, retiraremos do conjunto de dados corridas que tiveram uma dist\u00e2ncia percorrida menor que 200 metros. Os gr\u00e1ficos a seguir permitem identificar os *outliers* dessa *feature*.\n\nEm rela\u00e7\u00e3o aos valores muito altos de dist\u00e2ncia das viagens, investigaremos mais a fundo se tais dados fazem sentido na subse\u00e7\u00e3o 3.2.5, que trata do pre\u00e7o da viagem por km rodado.","dda172f2":"**3.1 Pr\u00e9-Processamento da label (pre\u00e7o das corridas)**\n\nPrimeiramente, podemos identificar os *outliers* na label. Pre\u00e7os de corridas exorbitantes ou negativos provavelmente s\u00e3o devidos \u00e0 erros na entrada. Esses valores atrapalham o processo de aprendizagem dos modelos e, portanto, devem ser retirados do conjunto. "}}