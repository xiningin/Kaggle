{"cell_type":{"fb8df30c":"code","3dab80b6":"code","6a7bf93b":"code","ddf8e3d3":"code","522816ff":"code","92aee849":"code","b5af4689":"code","0d8bee5f":"code","5f05c6fb":"code","7c3562ca":"code","359e9842":"code","66d3dfbe":"code","639c897e":"code","dfaeac88":"code","ab23a67e":"code","61113687":"code","658bc016":"code","7b24e192":"code","e0084c7c":"code","ec35cf42":"code","d6fe5d8d":"code","e073979c":"code","48f1c50e":"code","55ca664b":"code","d0ab3969":"code","04ab67b8":"code","22c4f4a4":"code","1f4c0378":"code","177d53ce":"code","e84630b7":"code","bf9341f5":"code","cbfb6bc5":"code","368c702d":"code","f8371ccb":"code","f0b60a2f":"code","66ffaa31":"code","dbe3308f":"markdown","b8959838":"markdown","76369731":"markdown","94582390":"markdown","8e0ec112":"markdown","30f3d944":"markdown","60d47a3c":"markdown","8ecb5bdc":"markdown","d4f99e1f":"markdown","69380b60":"markdown","40698d60":"markdown","3a0c6798":"markdown"},"source":{"fb8df30c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mplib\nfrom matplotlib import pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# \/kaggle\/input\/life-expectancy-who\/led.csv","3dab80b6":"data = pd.read_csv(\"..\/input\/life-expectancy-who\/led.csv\")\ndata_df = pd.DataFrame(data)\n","6a7bf93b":"print(data_df.info())\nprint(data_df.describe())\n# data_df.head()\nprint(\"Null values:\\n\", data_df.isnull().sum())\nprint(\"Percent missingness:\\n\", data_df.isnull().sum() \/ data_df.count())\nprint(\"Shape:\\n\", data_df.shape)\nprint(\"Data Types:\\n\", data_df.dtypes)","ddf8e3d3":"corrMatrix = data_df.corr()\ncorrMatrix.style.background_gradient(cmap='plasma', low=.5, high=0).highlight_null('red') # from https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/style.html","522816ff":"df_last5 = data_df[data_df['Year'].isin([2011,2012,2013,2014,2015])]","92aee849":"df_last5_avg = df_last5.groupby(['Country'],as_index=False).mean()","b5af4689":"print(df_last5[df_last5['Country']=='Italy'])\nprint(df_last5_avg[df_last5_avg['Country']=='Italy'])","0d8bee5f":"print('Percent Missingness:\\n', df_last5_avg.isnull().sum()\/df_last5_avg.count())","5f05c6fb":"df_last5_avg.drop(['Population'],1,inplace=True)\ndf_last5_avg.drop(['Year'],1,inplace=True)","7c3562ca":"# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) # this allows you to see the full dataset","359e9842":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['GDP']])\ndf_last5_avg['GDP'] = imp.transform(df_last5_avg[['GDP']])","66d3dfbe":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['Lifeexpectancy']])\ndf_last5_avg['Lifeexpectancy'] = imp.transform(df_last5_avg[['Lifeexpectancy']])","639c897e":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['AdultMortality']])\ndf_last5_avg['AdultMortality'] = imp.transform(df_last5_avg[['AdultMortality']])","dfaeac88":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['Alcohol']])\ndf_last5_avg['Alcohol'] = imp.transform(df_last5_avg[['Alcohol']])","ab23a67e":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['HepatitisB']])\ndf_last5_avg['HepatitisB'] = imp.transform(df_last5_avg[['HepatitisB']])","61113687":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['BMI']])\ndf_last5_avg['BMI'] = imp.transform(df_last5_avg[['BMI']])","658bc016":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['Totalexpenditure']])\ndf_last5_avg['Totalexpenditure'] = imp.transform(df_last5_avg[['Totalexpenditure']])","7b24e192":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['thinness1-19years']])\ndf_last5_avg['thinness1-19years'] = imp.transform(df_last5_avg[['thinness1-19years']])","e0084c7c":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['thinness5-9years']])\ndf_last5_avg['thinness5-9years'] = imp.transform(df_last5_avg[['thinness5-9years']])","ec35cf42":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['Incomecompositionofresources']])\ndf_last5_avg['Incomecompositionofresources'] = imp.transform(df_last5_avg[['Incomecompositionofresources']])","d6fe5d8d":"imp = SimpleImputer(missing_values = np.nan, strategy='median')\nimp = imp.fit(df_last5_avg[['Schooling']])\ndf_last5_avg['Schooling'] = imp.transform(df_last5_avg[['Schooling']])","e073979c":"print(\"Percent missingness:\\n\", df_last5_avg.isnull().sum() \/ df_last5_avg.count())","48f1c50e":"X = df_last5_avg['AdultMortality']\ny = df_last5_avg['Lifeexpectancy']\nplt.scatter(X,y)\nplt.ylabel('Life Expectancy')\nplt.xlabel('Adult Mortality per 1000 pop.')\nplt.show()","55ca664b":"X = df_last5_avg['GDP']\ny = df_last5_avg['Lifeexpectancy']\nplt.scatter(X,y)\nplt.ylabel('Life Expectancy')\nplt.xlabel('GDP')\nplt.show()","d0ab3969":"from sklearn import linear_model\nreg = linear_model.LinearRegression()\nreg.fit(df_last5_avg[['AdultMortality']],df_last5_avg['Lifeexpectancy'])\nprediction_space = np.linspace(min(df_last5_avg['AdultMortality']),max(df_last5_avg['AdultMortality'])).reshape(-1,1)\nplt.scatter(df_last5_avg['AdultMortality'],df_last5_avg['Lifeexpectancy'],color='yellow')\nplt.plot(prediction_space,reg.predict(prediction_space),color='blue',linewidth=3)\nplt.show()","04ab67b8":"correlated_features = set()\ncorrelation_matrix = df_last5_avg.drop('Lifeexpectancy', axis=1).corr()\n\nfor i in range(len(correlation_matrix.columns)):\n    for j in range(i):\n        if abs(correlation_matrix.iloc[i, j]) > 0.8: #.iloc method is used to extract rows\n            colname = correlation_matrix.columns[i]\n            correlated_features.add(colname)\nprint(correlated_features)","22c4f4a4":"df_last5_avg.drop(['Diphtheria'],1,inplace=True)\ndf_last5_avg.drop(['thinness5-9years'],1,inplace=True)\ndf_last5_avg.drop(['under-fivedeaths'],1,inplace=True)\ndf_last5_avg.drop(['Schooling'],1,inplace=True)","1f4c0378":"df_last5_avg.head()\ndf_last5_avg.set_index('Country',inplace=True)","177d53ce":"from sklearn.feature_selection import RFE\n\nX = df_last5_avg.drop('Lifeexpectancy',axis=1)\ny = df_last5_avg['Lifeexpectancy']\n\nlr = linear_model.LinearRegression()\nrfe = RFE(estimator=lr, n_features_to_select=8, step=1)\nrfe.fit(X, y)\n\n#print(rfe.get_support)\nprint(rfe.ranking_)","e84630b7":"from sklearn.model_selection import train_test_split\n#no of features\nnof_list=np.arange(1,13)            \nhigh_score=0\n#Variable to store the optimum features\nnof=0           \nscore_list =[]\nfor n in range(len(nof_list)):\n    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n    model = linear_model.LinearRegression()\n    rfe = RFE(model,nof_list[n])\n    X_train_rfe = rfe.fit_transform(X_train,y_train)\n    X_test_rfe = rfe.transform(X_test)\n    model.fit(X_train_rfe,y_train)\n    score = model.score(X_test_rfe,y_test)\n    score_list.append(score)\n    if(score>high_score):\n        high_score = score\n        nof = nof_list[n]\nprint(\"Optimum number of features: %d\" %nof)\nprint(\"Score with %d features: %f\" % (nof, high_score))","bf9341f5":"cols = list(X.columns)\nmodel = linear_model.LinearRegression()\n#Initializing RFE model\nrfe = RFE(model, 7)             \n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\nmodel.fit(X_rfe,y)             \ntemp = pd.Series(rfe.support_,index = cols)\nselected_features_rfe = temp[temp==True].index\nprint(selected_features_rfe)\n","cbfb6bc5":"coefs = model.fit(X_rfe,y).coef_  \n_ = plt.plot(coefs)\n_ = plt.xticks(np.arange(7),('AdultMortality', 'Alcohol', 'HepatitisB', 'Totalexpenditure',\n       'HIV\/AIDS', 'thinness1-19years', 'Incomecompositionofresources'), rotation=60)\n_ = plt.ylabel('Coefficients')\nplt.show()","368c702d":"coef_dict = dict(enumerate(coefs))\ncoef_dict = {'AdultMortality':coef_dict[0],'Alcohol':coef_dict[1],'HepatitisB':coef_dict[2],\n             'Totalexpenditure':coef_dict[3],'HIV\/AIDS':coef_dict[4],\n             'thinness1-19years':coef_dict[5],'Incomecompositionofresources':coef_dict[6]}\ncoef_dict","f8371ccb":"import seaborn as sns\ncorr = df_last5_avg.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right')","f0b60a2f":"df_regress = df_last5_avg[['AdultMortality', 'Alcohol', 'HepatitisB', 'Totalexpenditure',\n       'HIV\/AIDS', 'thinness1-19years', 'Incomecompositionofresources','Lifeexpectancy']]\nX = df_regress.drop('Lifeexpectancy',axis=1)\ny = df_regress['Lifeexpectancy']\n\nfrom sklearn.linear_model import Ridge\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)\nridge = Ridge(alpha = 0.1, normalize=True)\nridge.fit(X_train,y_train)\nridge_pred=ridge.predict(X_test)\nridge_pred1=ridge.predict(X_train)\nprint(ridge.score(X_train,y_train))\nprint(ridge.score(X_test,y_test))","66ffaa31":"from sklearn.linear_model import Lasso\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)\nlasso = Lasso(alpha = 0.1, normalize=True)\nlasso.fit(X_train,y_train)\nlasso_pred=lasso.predict(X_test)\nlasso.score(X_test,y_test)","dbe3308f":"### Understanding the dataset\nThe focus here is to take a look at the dataset and understand what sort of preprocessing it may need. I am interested to see where values are missing and what kinds of datatypes I will be working with. \n\n#### Metadata \n- Country -                       Country\n\n- Year -                          Year\n\n- Status -                        Developed or Developing status\n\n- Lifeexpectancy -                Life Expectancy in age\n\n- AdultMortality -                Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n\n- infantdeaths -                  Number of Infant Deaths per 1000 population\n\n- Alcohol -                       Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)\n\n- percentageexpenditure -         Expenditure on health as a percentage of Gross Domestic Product per capita(%)\n\n- HepatitisB -                    Hepatitis B (HepB) immunization coverage among 1-year-olds (%)\n\n- Measles -                       Measles - number of reported cases per 1000 population\n\n- BMI -                           Average Body Mass Index of entire population\n\n- under-fivedeaths -              Number of under-five deaths per 1000 population\n\n- Polio -                         Polio (Pol3) immunization coverage among 1-year-olds (%)\n\n- Totalexpenditure -              General government expenditure on health as a percentage of total government expenditure (%)\n\n- Diphtheria -                    Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n\n- HIV\/AIDS -                      Deaths per 1 000 live births HIV\/AIDS (0-4 years)\n\n- GDP -                           Gross Domestic Product per capita (in USD)\n\n- Population -                    Population of the country\n\n- thinness1-19years -             Prevalence of thinness among children and adolescents for Age 10 to 19 (% )\n\n- thinness5-9years -              Prevalence of thinness among children for Age 5 to 9(%)\n\n- Incomecompositionofresources -  Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n\n- Schooling -                     Number of years of Schooling(years)","b8959838":"### Initial thoughts\n\n\n- There are missing values for columns: GDP, Population, Totalexpenditure, HepatitisB, Incomecompositionofresources, and Schooling. I could input missing data or it might be easier to drop some of the columns altogether if they are missing too much data. \n\n\n- After doing some research, with a large dataset, a missingness of up to 40% may even be acceptable. In this case, we may be fine without inputting missing data. \n\n\n- We will be doing linear regression because life expectancy is a continuous number. \n\n","76369731":"### Project Report\n\n1. The first steps I took, were to look at the dataset and then take a look at the amount of missing values.\n2. Next, I wanted to reduce the dataset so that I only had individual countries, which I did by taking data from the  last five years of each country and then averaging it to make a single record.\n3. Next, I wanted to check the amount of missing data again to see if I needed to impute values or drop columns altogether. \n4. After getting a clean dataset, I ran some visualizations to test my intuition and make sure things are working correctly. \n5. Once that was done, I moved on to removing heavily correlated variables and performed feature selection. \n6. Finally, after feature selection, I ran the linear regressions. \n","94582390":"### Take a look at the new dataset information\n\n\nI will use the same method as before to check for missing data. Hopefully by only taking the last 5 years for each country, we will have less missing data. \n\n\nA benefit to selecting and averaging the last 5 years of data for each country is that we will have an easier time running models as their is only one record per country now. ","8e0ec112":"- Since there are such a large number of missing values in the Population column, and the correlation is so low (-0.02), I will drop it instead of imputing values. \n\n\n- However, I will want to impute missing values for the GDP column as it has a higher correlation (0.46). I think its best to take the median value of developing and developed countries and insert based on respective status. ","30f3d944":"### Some Visualization Before Multiple Linear Regression\n\nI would like to run some visualizations just to get a sense of the dataset and to examine if intuitions are correct","60d47a3c":"### Correlation Matrix\nNext, I want to run a correlation matrix with all the variables so I can get an understanding on which variables are most influential.","8ecb5bdc":"### Correlated Variables\n\nBefore I run variable selection, I would like to eliminate variables that already have a high correlation. This step will increase the speed of variable selection. \n\nI will follow the model demonstrated on this page.\n\nhttps:\/\/towardsdatascience.com\/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15","d4f99e1f":"### Final Conclusions\n\nFrom the models we ran, we end up with a very accurate predictions, Ridge R^2 = .89 and Lasso R^2 = .86. By doing feature selection we can also note that the most influential factors on life expectancy are:\n\n{'AdultMortality': -0.04432281224565553,\n 'Alcohol': 0.14676844206224568,\n 'HepatitisB': 0.03433452490962368,\n 'Totalexpenditure': 0.25275165023031065,\n 'HIV\/AIDS': -0.3195821205985184,\n 'thinness1-19years': -0.08129266307963838,\n 'Incomecompositionofresources': 21.411124433259623}\n \n- Adult mortality - Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n- Alcohol - recorded per capita (15+) consumption (in litres of pure alcohol)\n- Hepatitis B - Hepatitis B (HepB) immunization coverage among 1-year-olds (%)\n- total expenditure - General government expenditure on health as a percentage of total government expenditure (%)\n- HIV\/AIDS - Deaths per 1 000 live births HIV\/AIDS (0-4 years)\n- Thinness 1-19 years - Prevalence of thinness among children and adolescents for Age 10 to 19 (% )\n- Income composition of resources - Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n\nOne reason to why our predictive models are so accurate may be because I reduced the dataset considerably to 192 records. Although, there isn't a problem of overfitting because the training accuracy is very similar to the test accuracy.","69380b60":"### Check to make sure data is accurate \n\n\nI will average a variable over the last five years for a random country, Italy for example, and check to make sure I have the same value in my new dataframe, df_last5_avg.","40698d60":"### Linear Regression\n\nI will run two different regression model using Ridge and Lasso","3a0c6798":"### Feature Selection \n#### RFE: Recursive Feature Elimination from SKLearn\n\nhttps:\/\/towardsdatascience.com\/feature-selection-with-pandas-e3690ad8504b\n\nThe next step I wanted to do before running a linear regression was to do variable selection. Variable selection is an important part of machine learning becuase it...\n- reduces the chance of overfitting\n- improves the accuracy of your model\n- improves the speed of training the model \n\n\nWith the guidance provided from the link above I will perform feature selection\n\nIn this procedure, I will first get a ranking of variables just to make sure the feature selection is working correctly. Then, I will have the model tell me what is the optimal amount of variables. Lastly, I will use the rfe.fit_transform method using the number of optimal variables as the amount of variables to select. Once it returns the optimal variables, I will plot the coefficients to get a look at their values. These variables will be selected to run the multiple linear regression. "}}