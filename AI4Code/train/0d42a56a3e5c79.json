{"cell_type":{"57c28a02":"code","37f4dd18":"code","856b8bdb":"code","c2b7af9e":"code","e84d68de":"code","00ed2d4e":"code","96942ea2":"code","128b31d1":"code","f1ebca98":"code","f7d998f6":"code","5775097c":"code","9f5cac19":"code","1ce34c4d":"code","80dfdb03":"code","7098381a":"code","c237f699":"code","7d87e259":"markdown","86f003a0":"markdown","23852ee0":"markdown","afd6095c":"markdown","49fc4dd4":"markdown","729e5052":"markdown","81c23a56":"markdown","5d7375f5":"markdown","c6b1bbd7":"markdown","8818769b":"markdown","c0189adb":"markdown","8acf2d6d":"markdown"},"source":{"57c28a02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom prettytable import PrettyTable\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Any results you write to the current directory are saved as output.","37f4dd18":"X, y = load_breast_cancer(return_X_y=True)\nprint(X.shape)","856b8bdb":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 123)","c2b7af9e":"ss = StandardScaler()\nX_train_ss = ss.fit_transform(X_train)\nX_test_ss = ss.transform(X_test)","e84d68de":"clf = RandomForestClassifier()\nclf.fit(X_train_ss, y_train)\ny_pred = clf.predict(X_test_ss)","00ed2d4e":"def plot_conf_matrix (conf_matrix, dtype):\n    class_names = [0,1]\n    fontsize=14\n    df_conf_matrix = pd.DataFrame(\n            conf_matrix, index=class_names, columns=class_names, \n        )\n    fig = plt.figure()\n    heatmap = sns.heatmap(df_conf_matrix, annot=True, fmt=\"d\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title('Confusion Matrix for {0}'.format(dtype))","96942ea2":"acc_rf = accuracy_score(y_test, y_pred)\nprint(acc_rf)","128b31d1":"plot_conf_matrix(confusion_matrix(y_test, y_pred), \"Test data\")","f1ebca98":"\nestimators = [10, 50, 100, 200, 500] \nmax_depths = [3, 6, 10, 15, 20] \n\ngrid_values = {'n_estimators': estimators, 'max_depth':max_depths}\n\nclf = GridSearchCV(RandomForestClassifier(), grid_values, scoring='roc_auc', n_jobs=-1, verbose=10, cv=3)\nclf.fit(X_train_ss, y_train)\nbest_n_estimators_value = clf.best_params_['n_estimators']\nbest_max_depth_value = clf.best_params_['max_depth']\nbest_score = clf.best_score_","f7d998f6":"max_depth_list = list(clf.cv_results_['param_max_depth'].data)\nestimators_list = list(clf.cv_results_['param_n_estimators'].data)\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,6))\nplt.subplot(1,2,1)\ndata = pd.DataFrame(data={'Estimators':estimators_list, 'Max Depth':max_depth_list, 'AUC':clf.cv_results_['mean_train_score']})\ndata = data.pivot(index='Estimators', columns='Max Depth', values='AUC')\nsns.heatmap(data, annot=True, cmap=\"YlGnBu\").set_title('AUC for Training data')\nplt.subplot(1,2,2)\ndata = pd.DataFrame(data={'Estimators':estimators_list, 'Max Depth':max_depth_list, 'AUC':clf.cv_results_['mean_test_score']})\ndata = data.pivot(index='Estimators', columns='Max Depth', values='AUC')\nsns.heatmap(data, annot=True, cmap=\"YlGnBu\").set_title('AUC for Test data')\nplt.show()","5775097c":"def plot_roc_curve(roc_auc_train, roc_auc_test):\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr_tr, tpr_tr, 'g', label = 'Training AUC = %0.2f' % roc_auc_train)\n    plt.plot(fpr_ts, tpr_ts, 'b', label = 'Testing AUC = %0.2f' % roc_auc_test)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","9f5cac19":"#Best hyper parameter \nclf = RandomForestClassifier(n_estimators=best_n_estimators_value, max_depth=best_max_depth_value)\nclf.fit(X_train_ss, y_train)\n\ny_pred_train = clf.predict_proba(X_train_ss)[:,1]\ny_pred_test = clf.predict_proba(X_test_ss)[:,1]\n\n   \n#train data ROC\nfpr_tr, tpr_tr, threshold = roc_curve(y_train, y_pred_train)\nroc_auc_train = auc(fpr_tr, tpr_tr)\n\n#test data ROC\nfpr_ts, tpr_ts, threshold = roc_curve(y_test, y_pred_test)\nroc_auc_test = auc(fpr_ts, tpr_ts)\n\n#Plot ROC curve\nplot_roc_curve(roc_auc_train, roc_auc_test)","1ce34c4d":"acc_rf_grid = accuracy_score(y_test, clf.predict(X_test_ss))\n\nprint(acc_rf_grid)","80dfdb03":"plot_conf_matrix(confusion_matrix(y_train, clf.predict(X_train_ss)), \"Training data\")","7098381a":"plot_conf_matrix(confusion_matrix(y_test, clf.predict(X_test_ss)), \"Test data\")","c237f699":"# Compare both the models using Prettytable library    \nx = PrettyTable()\n\nx.field_names = [\"Model\", \"n_estimators\", \"max_depth\",\"Accuracy\"]\n\nx.add_row([\"Random Forest w\/o GridSearch\", \"default 10\", \"None\", acc_rf])\nx.add_row([\"Random Forest with GridSearch\", best_n_estimators_value, best_max_depth_value, acc_rf_grid])\n\nprint(x)","7d87e259":"## Random Forest with Grid Search\n\nWe are tuning two hyperparameters of Random Forest classifier here - `n_estimators` and `max_depth`. We will use a list of values for `n_estimators` and a list of values for `max_depth`. Grid Search will search through all possible combinations (in this case it is 5 x 5 = 25 combinations) of hyperparameters to find out the best combination. Grid Search function will use `roc_auc` score here to evaluate validation set. There can be other [scoring functions](https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter) also that can be used based on the use cases. List of values of `n_estimators` and `max_depth` are given as key-value pairs (dictionary). We are also using 3 fold cross validation scheme (`cv = 3`).\n\nOnce the training data is fit into the model, best parameters from the Grid Search can be extracted using their names as keys.","86f003a0":"There are 52 True Negatives, 82 Ttrue Positives, 2 False Positives and 7 False Negatives.","23852ee0":"We will now plot the heatmap of AUC values for all possible combinations of `n_estimators` and `max_depth` values. There will be two heatmaps - one for train data and another for test data.","afd6095c":"## Conclusion","49fc4dd4":"## Random Forest without Grid Search\nFirst we will use `RandomForestClassifier` without Grid Search and with default values of hyperparameters.","729e5052":"In this kernel, we will see how Grid Search works in a simplified manner. We will use `GridSearchCV` from [scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). ","81c23a56":"Now we will make a Random Forest Classifier with the best values of the hyperparameters. Then we will plot the ROC curve.","5d7375f5":"`plot_conf_matrix` is a function to plot a heatmap of confusion matrix.","c6b1bbd7":"Scikit-learn module comes with some popular reference datasets including the methods to load and fetch them easily. We will use the [breast cancer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) wisconsin dataset for binary classification. The breast cancer dataset is a classic and very easy binary classification dataset.\n\n`load_breast_cancer` method loads and returns the breast cancer wisconsin dataset. If `return_X_y` is made true then it returns `(data, target)`.","8818769b":"Use Standard Scalar for preprocessing the data. ","c0189adb":"Lets use `train_test_split` to split the dataset into train and test sets.","8acf2d6d":"`plot_roc_curve` is a function to plot Receiver Operating Characteristic curve from train data and test data. "}}