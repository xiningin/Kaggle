{"cell_type":{"a5e78395":"code","9ad9f90e":"code","fe34e4f8":"code","0722d112":"code","a05dd1b5":"code","f0012e61":"code","6a486154":"code","b20f3c7d":"code","84549741":"code","96b78c8b":"code","bdb09a84":"code","5bc73300":"code","3d685274":"code","343d3beb":"code","e45f1c6f":"code","ca3ee954":"code","9f041348":"code","8ddf93f4":"code","8f62aa16":"markdown"},"source":{"a5e78395":"import numpy as np\nimport pandas as pd\nimport gc\n\ndf = pd.read_csv(\"\/kaggle\/input\/remove-trends-giba\/train_clean_giba.csv\", usecols=[\"signal\",\"open_channels\"], dtype={'signal': np.float32, 'open_channels':np.int32})\ntest_df  = pd.read_csv(\"\/kaggle\/input\/remove-trends-giba\/test_clean_giba.csv\", usecols=[\"signal\"], dtype={'signal': np.float32})\n\ndf.shape, test_df.shape","9ad9f90e":"df['group'] = np.arange(df.shape[0])\/\/500_000\naug_df = df[df[\"group\"] == 5].copy()\naug_df[\"group\"] = 10\n\nfor col in [\"signal\", \"open_channels\"]:\n    aug_df[col] += df[df[\"group\"] == 8][col].values\n\ndf = df.append(aug_df, sort=False).reset_index(drop=True)\ndf.shape\n\ndel aug_df\ngc.collect()","fe34e4f8":"wavenet_oof = (np.load(\"\/kaggle\/input\/into-the-wild-wavenet\/wavenet.npz\")[\"valid\"] + np.load(\"\/kaggle\/input\/into-the-wild-wavenet\/wavenet.npz\")[\"tta\"])\/2\nwavenet_test = np.load(\"\/kaggle\/input\/into-the-wild-wavenet\/wavenet.npz\")[\"test\"]\n\nfor i in range(wavenet_oof.shape[1]):\n    df[\"prob_{}\".format(i)] = wavenet_oof[:, i]\n    test_df[\"prob_{}\".format(i)] = wavenet_test[:, i]\n    \ndf[\"wave_pred\"] = np.argmax(wavenet_oof, axis=1)\ntest_df[\"wave_pred\"] = np.argmax(wavenet_test, axis=1)\n\ndf['noise'] = df['signal'].values - df['wave_pred'].values\ntest_df['noise'] = test_df['signal'].values - test_df['wave_pred'].values","0722d112":"df.sample(5, random_state=0)","a05dd1b5":"def get_margin(x):\n    return np.log(x)\n\nM = get_margin(wavenet_oof)\nM_test = get_margin(wavenet_test)","f0012e61":"from sklearn.metrics import f1_score, log_loss\n\nf1_score(df[\"open_channels\"], df[\"wave_pred\"], average=\"macro\")","6a486154":"log_loss(df[\"open_channels\"], wavenet_oof)","b20f3c7d":"NUM_FOLDS = 5\n\ndf[\"mg\"] = df.index\/\/100_000\ntest_df[\"mg\"] = test_df.index\/\/100_000\n\ndf[\"fold\"] = df[\"mg\"] % NUM_FOLDS","84549741":"for data in [df, test_df]:\n    y_time_since = np.empty((data.shape[0], 11))\n    y_time_till = np.empty((data.shape[0], 11))\n    y_pred = data[\"wave_pred\"].values\n\n    for sec in range(data.shape[0]\/\/100_000):\n        begin, end = sec*100_000, (sec+1)*100_000\n        # print(begin, end)\n\n        last_seen = np.array([np.nan]*11)\n        for index in range(begin, end):\n            y_time_since[index] = index - last_seen\n            last_seen[y_pred[index]] = index\n\n        last_seen = np.array([np.nan]*11)\n        for index in reversed(range(begin, end)):\n            y_time_till[index] = last_seen - index\n            last_seen[y_pred[index]] = index\n\n    for i in range(11):\n        f = \"time_since_{}\".format(i)\n        data[f] = y_time_since[:, i]\n        data[f] = np.clip(data[f].fillna(np.inf), 0, 1_000)\n\n        f = \"time_till_{}\".format(i)\n        data[f] = y_time_till[:, i]\n        data[f] = np.clip(data[f].fillna(np.inf), 0, 1_000)\n    \ntest_df.sample(2).T","96b78c8b":"features = [\"signal\", \"noise\",\n            \"prob_0\", \"prob_1\", \"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\", \"prob_6\", \"prob_7\", \"prob_8\", \"prob_9\", \"prob_10\"]\n\nfor i in range(11):\n    f = \"time_since_{}\".format(i)\n    features.append(f)\n    f = \"time_till_{}\".format(i)\n    features.append(f)","bdb09a84":"import xgboost as xgb\n\nparams = {\"objective\": \"multi:softprob\",\n          \"num_class\": 11,\n          \"learning_rate\" : 0.2,\n          \"max_leaves\": 2**4,\n          \"grow_policy\": \"lossguide\",\n          'min_child_weight': 50,\n          'lambda': 2,\n          'eval_metric': 'mlogloss',\n          \"base_score\": 0,\n          \"tree_method\": 'gpu_hist', \"gpu_id\": 0\n         }\n\n\ntarget = \"open_channels\"\n\ny_oof = np.zeros_like(wavenet_oof)\ny_test = np.zeros_like(wavenet_test)\n\ndel  wavenet_oof, wavenet_test\ngc.collect()\n\nX_test = test_df[features].values\n\nd_test = xgb.DMatrix(X_test)\nd_test.set_base_margin(M_test.flatten())\n\nfor f in range(NUM_FOLDS):\n    train_df, val_df = df[df[\"fold\"] != f].copy(), df[df[\"fold\"] == f].copy()\n    train_ind = np.where(df[\"fold\"].values != f)[0]\n    val_ind = np.where(df[\"fold\"].values == f)[0]\n    \n    X_train, X_val = train_df[features].values, val_df[features].values\n    y_train, y_val = train_df[target].values, val_df[target].values\n    \n    d_train = xgb.DMatrix(X_train, y_train)\n    d_train.set_base_margin(M[train_ind].flatten())\n\n    d_val = xgb.DMatrix(X_val, y_val)\n    d_val.set_base_margin(M[val_ind].flatten())\n    \n    del X_train, X_val, y_train, y_val\n    gc.collect()\n    \n    model = xgb.train(params, d_train, evals=[(d_train, \"train\"), (d_val, \"eval\")], verbose_eval=10, num_boost_round=31)\n    y_oof[val_ind] = model.predict(d_val)\n    y_test += model.predict(d_test)\/NUM_FOLDS\n    print()\n    \ndel d_train, d_val\ngc.collect()","5bc73300":"log_loss(df[\"open_channels\"], y_oof)","3d685274":"df[\"xgb_pred\"] = np.argmax(y_oof, axis=1)\n\nf1_score(df[\"open_channels\"], df[\"xgb_pred\"], average=\"macro\")","343d3beb":"f1_score(df.iloc[:5_000_000][\"open_channels\"], df.iloc[:5_000_000][\"xgb_pred\"], average=\"macro\")","e45f1c6f":"df[\"ensemble_pred\"] = df[[\"wave_pred\", \"xgb_pred\"]].max(axis=1)\n\nf1_score(df[\"open_channels\"], df[\"ensemble_pred\"], average=\"macro\")","ca3ee954":"f1_score(df.iloc[:5_000_000][\"open_channels\"], df.iloc[:5_000_000][\"ensemble_pred\"], average=\"macro\")","9f041348":"test_df[\"xgb_pred\"] = np.argmax(y_test, axis=1)","8ddf93f4":"sample_submission  = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv', dtype={'time': np.float32})\nsample_submission['open_channels'] = test_df[[\"wave_pred\", \"xgb_pred\"]].max(axis=1)\nsample_submission.to_csv(f'submission.csv', index=False, float_format='%.4f')\nprint(sample_submission.open_channels.mean())\ndisplay(sample_submission.head())","8f62aa16":"### This work totally belongs to [Ahmet](https:\/\/www.kaggle.com\/aerdem4), kudos should go to him :)\n#### Clean Dataset;\nI used Giba's clean dataset from a private notebook. You can use Giba's public notebook for the same clean dataset;\nhttps:\/\/www.kaggle.com\/titericz\/remove-trends-giba-explained\n\n#### Scripts to Create OOFs;\n##### https:\/\/www.kaggle.com\/meminozturk\/into-the-wild-rfc-classification\n##### https:\/\/www.kaggle.com\/meminozturk\/into-the-wild-mlp-regression\/\n##### https:\/\/www.kaggle.com\/meminozturk\/into-the-wild-lgb-regression\n\n#### Wavenet Model;\n##### https:\/\/www.kaggle.com\/meminozturk\/into-the-wild-wavenet\/"}}