{"cell_type":{"0a220f5a":"code","099b5a1d":"code","d632ce73":"code","e065618e":"code","263ba309":"code","c7112b49":"code","421dfe57":"code","174d019a":"code","26c2ef93":"code","d50f7195":"code","956921c4":"code","80d94280":"code","ac30797b":"code","185718df":"code","7b7301cd":"code","98a7df38":"code","a1e2cd2c":"code","293f62ae":"code","44d654be":"code","c3750525":"code","99f84a3b":"code","22d6ad6d":"code","46b62b28":"code","237fafa7":"code","63262f6d":"code","52beba5f":"code","8e9a6bf6":"code","5959f2ec":"code","ca828637":"code","a33d5d9f":"code","fe272438":"code","1b4bdb26":"code","7f43e47b":"code","a335e448":"code","f6a8abe0":"code","f4fdb194":"code","163e3e1d":"code","27fc9116":"code","5d56e283":"code","75f6bea5":"code","6e2e6759":"code","22ef2b27":"code","023382c7":"code","2c2eaa62":"code","efad33c6":"code","fb7c9e49":"code","ea3e4046":"code","ea743827":"code","7de4ee6d":"code","4983df3d":"code","ab4f1cbc":"code","1c2899d2":"code","762b9a6c":"code","8980494c":"code","ef68f5b5":"code","1d716c30":"code","352eac89":"code","ab4f1ba1":"code","d5bb12ce":"code","eb2552da":"code","af3cbd46":"code","401c89e5":"code","6ee5860e":"code","1c3ab77e":"code","5dfb5cac":"markdown","d10ea7e0":"markdown","250fafa0":"markdown","5acb3d10":"markdown","f1ca56c4":"markdown","db53f899":"markdown","2646dfbd":"markdown","e1a240aa":"markdown","0798b444":"markdown","521f9718":"markdown","ec2c200b":"markdown","28bd811e":"markdown","7b9896ba":"markdown","2832bd97":"markdown","03f5670e":"markdown","43371e89":"markdown","057c6249":"markdown","bc1ddb59":"markdown","70a801f8":"markdown","28447a58":"markdown","a236a398":"markdown","799028fc":"markdown","49627c8f":"markdown","f41ed619":"markdown","3f1a12d5":"markdown","9a081f6a":"markdown","328501b6":"markdown","51fef072":"markdown","6e4482e2":"markdown","c4e1fba5":"markdown","6aefaa61":"markdown"},"source":{"0a220f5a":"## Import Essential Libraries \n!pip install geocoder\n\nimport os #for file part\nfrom math import * # for mathmatically relations & computation  \nfrom scipy.stats import * # Stat testing\nimport numpy as np # array operations \nimport re # working on text data \nimport pandas as pd # dataframe operations\nimport matplotlib.pyplot as plt # visualisations\nimport seaborn as sns # Viz\nimport geocoder # Geographical Data analysis\nimport geopy # Geographical data\nfrom geopy.geocoders import Nominatim  # Geographical data\n\n# All machine leanring libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error","099b5a1d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d632ce73":"### Load data into a dataframe\ntrain = pd.read_csv('\/kaggle\/input\/rental-price-of-indias-it-capital-pune-mh-ind\/train.csv', encoding = 'utf-8')","e065618e":"train.shape","263ba309":"train.info() # lookin for dtypes , null values inside data","c7112b49":"train.isnull().sum()","421dfe57":"train.describe() # A brief stat of data","174d019a":"df = train.copy() # createing a copy of original data of actual cleaning & feature engineering puppose","26c2ef93":"df.head(3)","d50f7195":"## Warning \/ NOTe\n## few working requied on rent here intial\nprint('shape before', df.shape)\ndf.drop(df[df['rent'] >= 123456789].index, axis = 0, inplace = True) # this values is added by purpose while doing data cleaning \nprint('shape after', df.shape)","956921c4":"df.area.replace(0, np.nan, inplace =  True)\ndf.area.isnull().sum()\n\npd.pivot_table(df, values= 'area', columns='bedroom', aggfunc= 'mean').T\npd.pivot_table(df, values= 'area', columns='bedroom', aggfunc= 'median').T\n\nm1 = df['bedroom']  == 1\nm2 = df['bedroom']  == 2\nm3 = df['bedroom']  == 3\nm4 = df['bedroom']  == 4\nm5 = df['bedroom']  == 5\nm6 = df['bedroom']  == 6\ndf.loc[m1, 'area'] = df.loc[m1,'area'].fillna(df.loc[m1,'area'].median())\ndf.loc[m2, 'area'] = df.loc[m2,'area'].fillna(df.loc[m2,'area'].median())\ndf.loc[m3, 'area'] = df.loc[m3,'area'].fillna(df.loc[m3,'area'].median())\ndf.loc[m4, 'area'] = df.loc[m4,'area'].fillna(df.loc[m4,'area'].median())\ndf.loc[m5, 'area'] = df.loc[m5,'area'].fillna(df.loc[m5,'area'].median())\ndf.loc[m6, 'area'] = df.loc[m6,'area'].fillna(df.loc[m6,'area'].median())\n\n","80d94280":"num_columns = df.describe().columns\ncategorical_cols = df.describe(include= 'object').columns","ac30797b":"# checking for binary data & oridinal & continous_data \nfor i in df.columns:\n    print(len(df[i].unique()), end = '    ')\n# range varies form 2 to  6387\n","185718df":"binary_variables = [i  for i in df.columns  if (len(df[i].unique()) == 2)]","7b7301cd":"ordinal_variables= [i for i in df.columns if ((len(df[i].unique()) > 2 ) and (len(df[i].unique()) <= 25))]","98a7df38":"continous_variable = [i for i in df.columns if ((len(df[i].unique()) > 25))]\n## Remove rent from data\ncontinous_variable = continous_variable[:-1]","a1e2cd2c":"target_variable = 'rent'","293f62ae":"print(binary_variables, end = ' ')\n\n('element in binary category', len(binary_variables))","44d654be":"df.gate_community.value_counts().index","c3750525":"fig, ax = plt.subplots(4,3, figsize = (20,30), sharey = True)\nfig.tight_layout()\nfig.subplots_adjust(top=0.95)\n\nsns.set_style('white')\nfig.suptitle('Binary Variables- Counts', size = 30)\nsns.barplot(ax= ax[0,0], data =df , x = df.gate_community.value_counts().index, y = df.gate_community.value_counts().values,palette= 'muted' )\nax[0,0].set_title('Gate Facility', fontsize = 15)\nsns.barplot(ax= ax[0,1], data =df , x = df.corner_pro.value_counts().index, y = df.corner_pro.value_counts().values,palette= 'pastel' )\nax[0,1].set_title('Conrner Property', fontsize = 15)\nsns.barplot(ax= ax[0,2], data =df , x = df.wheelchairadption.value_counts().index, y = df.wheelchairadption.value_counts().values,palette= 'muted' )\nax[0,2].set_title('Wheel Chair Facility',   fontsize = 15)\nsns.barplot(ax= ax[1,0], data =df , x = df.petfacility.value_counts().index, y = df.petfacility.value_counts().values,palette= 'husl' )\nax[1,0].set_title('Pet Friendly',  fontsize = 15)\nsns.barplot(ax= ax[1,1], data =df , x = df.lightbill.value_counts().index, y = df.lightbill.value_counts().values,palette= 'Set2' )\nax[1,1].set_title('Electricity Bill Included',  fontsize = 15)\nsns.barplot(ax= ax[1,2], data =df , x = df.no_room.value_counts().index, y = df.no_room.value_counts().values,palette= 'flare' )\nax[1,2].set_title('No other rooms',  fontsize = 15)\nsns.barplot(ax= ax[2,0], data =df , x = df.pooja_room.value_counts().index, y = df.pooja_room.value_counts().values,palette= 'ch:s=.25,rot=-.25' )\nax[2,0].set_title('Pooja\/ Holy Room',  fontsize = 15)\nsns.barplot(ax= ax[2,1], data =df , x = df.study_room.value_counts().index, y = df.study_room.value_counts().values,palette= 'muted' )\nax[2,1].set_title('Study_Room',  fontsize = 15)\nsns.barplot(ax= ax[2,2], data =df , x = df.others.value_counts().index, y = df.others.value_counts().values )\nax[2,2].set_title('other Rooms',  fontsize = 15)\nsns.barplot(ax= ax[3,0], data =df , x = df.servant_room.value_counts().index, y = df.servant_room.value_counts().values,palette= 'flare' )\nax[3,0].set_title('Servent Room',  fontsize = 15)\nsns.barplot(ax= ax[3,1], data =df , x = df.store_room.value_counts().index, y = df.store_room.value_counts().values,palette= 'husl' )\nax[3,1].set_title('Store Room',  fontsize = 15)\n# sns.barplot(ax=ax[3,2], x = df.index, y = df.rent)\nfig.delaxes(ax[3][2])\nfig.savefig('my.jpg')","99f84a3b":"target =  'rent'\nfor feature in binary_variables:\n    df.groupby(feature)[target].median().plot.bar()\n    \n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.title('{} vs log({})_median'.format(feature, target))\n    plt.show()","22d6ad6d":"print(ordinal_variables, end = ' ')\n('Number of ordinal features is', len(ordinal_variables))","46b62b28":"### working on oultiers which I found while working on previously on porject\ndf.groupby('bedroom').count()\n# we have more than 6  bedrooms in single homes  so we will drop to reduce outliers  totals around 20\nprint('before shape',df.shape)\ndf.drop(df[df['bedroom']>= 6].index, axis = 0, inplace = True)\nprint('after droping rows the shape is ', df.shape)","237fafa7":"print('before replacement', df.furnishing.unique())\ndf.furnishing.replace('Unfurnishe', 'Unfurnished', inplace = True)\nprint('after replacement', df.furnishing.unique())","63262f6d":"print(ordinal_variables, end = ' ')\n('Number of ordinal features is', len(ordinal_variables))","52beba5f":"fig, ax = plt.subplots(4,3, figsize = (20,30), sharey = False)\nfig.tight_layout(pad= 4.0)\nfig.subplots_adjust(top=0.95)\n\nsns.set_style('white')\nfig.suptitle('Ordinal Variable  vs Target Median', size = 30)\nsns.barplot(ax= ax[0,0], data =df , x = df.groupby('bedroom').median().index, y =df.groupby('bedroom').median().rent,palette= 'muted' )\nax[0,0].set_title('Number of Bedrooms', fontsize = 15)\n\nsns.barplot(ax= ax[0,1], data =df , x = df.groupby('bathrooms').median().index, y =df.groupby('bathrooms').median().rent,palette= 'muted' )\nax[0,1].set_title('Number of bathrooms', fontsize = 15)\n\nsns.barplot(ax= ax[0,2], data =df , x = df.groupby('furnishing').median().index, y =df.groupby('furnishing').median().rent,palette= 'muted' )\nax[0,2].set_title('Furnishsing', fontsize = 15)\n\nsns.barplot(ax= ax[1,0], data =df , x = df.groupby('avalable_for').median().index, y =df.groupby('avalable_for').median().rent,palette= 'muted' )\nax[1,0].set_title('Available for', fontsize = 15)\n\nsns.barplot(ax= ax[1,1], data =df , x = df.groupby('floor_number').median().index, y =df.groupby('floor_number').median().rent,palette= 'muted' )\nax[1,1].set_title('Floor Number', fontsize = 15)\n\nsns.barplot(ax= ax[1,2], data =df , x = df.groupby('facing').median().index, y =df.groupby('facing').median().rent,palette= 'muted' )\nax[1,2].set_title('', fontsize = 15)\n\nsns.barplot(ax= ax[2,0], data =df , x = df.groupby('floor_type').median().index, y =df.groupby('floor_type').median().rent,palette= 'muted' )\nax[2,0].set_title('Floor Type', fontsize = 15)\n\nsns.barplot(ax= ax[2,1], data =df , x = df.groupby('parking').median().index, y =df.groupby('parking').median().rent,palette= 'muted' )\nax[2,1].set_title('Count of Parking', fontsize = 15)\n\nsns.barplot(ax= ax[2,2], data =df , x = df.groupby('aggDur').median().index, y =df.groupby('aggDur').median().rent,palette= 'muted' )\nax[2,2].set_title('Agreement Duration', fontsize = 15)\n\nsns.barplot(ax= ax[3,0], data =df , x = df.groupby('noticeDur').median().index, y =df.groupby('noticeDur').median().rent,palette= 'muted' )\nax[3,0].set_title('Notice Duration', fontsize = 15)\n\nsns.barplot(ax= ax[3,1], data =df , x = df.groupby('powerbackup').median().index, y =df.groupby('powerbackup').median().rent,palette= 'muted' )\nax[3,1].set_title('Power Backup Facility', fontsize = 15)\n\nsns.barplot(ax= ax[3,2], data =df , x = df.groupby('propertyage').median().index, y =df.groupby('propertyage').median().rent,palette= 'muted' )\nax[3,2].set_title('Property Age', fontsize = 15)\n\nfig.savefig('ordinal_variable.jpg', dpi = 100)","8e9a6bf6":"# ['address']\ncat_variable = ['address']\ndf[cat_variable].head(2)","5959f2ec":"locality = []\nfor i in df.address:\n    adds = i.split(',')\n    if len(adds) == 4:\n        locality.append(adds[0])\n    elif len(adds) == 5:\n        locality.append(adds[1])\n    elif len(adds)  == 6:\n        if len(adds[1]) == 1:\n            locality.append(adds[2])\n        else:\n            locality.append(adds[1])\n    elif len(adds) == 7:\n        locality.append(' '.join(adds[2:4]))\n    elif len(adds) == 8:\n        locality.append(adds[2])\n    else:\n        locality.append(adds[4])","ca828637":"df['locality'] = locality\nlocation_summary = df['locality'].value_counts()\nlocations = [i.replace(',', ' ') for i in df.address]\nlen(location_summary.index)\nlocation_summary.to_csv('summary.csv')","a33d5d9f":"# locations = list(df['locality'].value_counts().index)\n# def get_latlng(neighborhood):\n#     # initialize your variable to None\n#     lat_lng_coords = None\n#     # loop until you get the coordinates\n#     while(lat_lng_coords is None):\n#         g = geocoder.arcgis('{} pune maaharashtra india'.format(neighborhood))\n#         lat_lng_coords = g.latlng\n#     return lat_lng_coords\n# coords = list()\n# for neighborhood in df2 [\"Neighborhood\"] .tolist():\n#     coords.append(get_latlng(neighborhood))","fe272438":"# map_data = pd.read_csv('all_location.csv')\n# map_data.drop('Unnamed: 0', axis = 1, inplace =  True)\n# map_data.head()\n# lat_long_pune = [18.516726,73.856255]\n# import folium\n\n# def generateBaseMap(default_location= [18.516726,73.856255], default_zoom_start=11.5):\n#     base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n#     return base_map\n# base_map = generateBaseMap()\n# ## add data to base map\n\n# from folium.plugins import HeatMap\n# base_map = generateBaseMap()\n\n# gradient = {.33: 'black', .5: 'blue', 0.7: 'red'}\n# HeatMap(data=map_data[['Longitude', 'Latitude', 'score']].groupby(['Longitude', 'Latitude']).sum().reset_index().values.tolist(), radius=8, gradient= gradient, max_zoom=13).add_to(base_map)\n# # map_data.columns\n# base_map.save('testmap.html')","1b4bdb26":"# maintenace amt is similar to the mnt_amt & address has more unique values but it comes under categorical columnswe removed\n#  both features & now we have area, brok_amt, deposit_amt & mnt_amount. \n\ncontinous_variable = continous_variable[0:1] +continous_variable[3:]\n","7f43e47b":"for i in continous_variable:\n    print(i, len(df[i].unique()))","a335e448":" plt.plot(df.area) # looking for abnormality ","f6a8abe0":"print('shape before', df.shape)\ndf.drop(df[df['area'] > 15000].index, axis = 0, inplace = True)\nprint('shape after', df.shape)","f4fdb194":"fig, ax =  plt.subplots(2,2, figsize=(20,15) )\nsub = [(i,j)  for i in range(0,2) for j in range(0,2)]\nfor i, j in enumerate(continous_variable):\n    sns.scatterplot(ax = ax[ sub[i][0],  sub[i][1]],  data = df, x = j, y = 'rent', hue= 'bedroom', size = 'bedroom', sizes = (20,300))","163e3e1d":"fig, ax = plt.subplots(1,2, figsize = (20,8), sharey = False)\nfig.tight_layout(pad= 4.0)\nfig.subplots_adjust(top=0.87)\nsns.set_style('white')\nfig.suptitle('Target Varible', size = 30)\nsns.histplot(ax= ax[0], data =df ,x = df.rent, kde =  True, bins = 15)\nax[0].set_title('Kdeplot', fontsize = 15)\nsns.boxplot(ax= ax[1], data =df ,y  = df.rent, palette='muted')\nax[1].set_title('Boxplot', fontsize = 15)\n\nfig.savefig('target.jpg', dpi = 250)","27fc9116":"continous_variable","5d56e283":"just_test = df.describe().columns","75f6bea5":"only_file = [i for i in just_test  if i not in binary_variables]\n(only_file)","6e2e6759":"fig, ax = plt.subplots(11,2, figsize = (20,30))\nfig.tight_layout(pad = 4.0)\nfig.subplots_adjust(top = 0.95)\nfig.suptitle('Variable  Histplo & Box Plot', size = 30)\nsns.kdeplot(ax= ax[0,0], data = df, x = 'bedroom')\nsns.boxplot(ax= ax[0,1], data = df, x = 'bedroom')\nsns.kdeplot(ax= ax[1,0], data = df, x = 'bathrooms')\nsns.boxplot(ax= ax[1,1], data = df, x = 'bathrooms')\nsns.kdeplot(ax= ax[2,0], data = df, x = 'area')\nsns.boxplot(ax= ax[2,1], data = df, x = 'area')\nsns.kdeplot(ax= ax[3,0], data = df, x = 'parking')\nsns.boxplot(ax= ax[3,1], data = df, x = 'parking')\nsns.kdeplot(ax= ax[4,0], data = df, x = 'aggDur')\nsns.boxplot(ax= ax[4,1], data = df, x = 'aggDur')\nsns.kdeplot(ax= ax[5,0], data = df, x = 'noticeDur')\nsns.boxplot(ax= ax[5,1], data = df, x = 'noticeDur')\nsns.kdeplot(ax= ax[6,0], data = df, x = 'powerbackup')\nsns.boxplot(ax= ax[6,1], data = df, x = 'powerbackup')\nsns.kdeplot(ax= ax[7,0], data = df, x = 'brok_amt')\nsns.boxplot(ax= ax[7,1], data = df, x = 'brok_amt')\nsns.kdeplot(ax= ax[8,0], data = df, x = 'deposit_amt')\nsns.boxplot(ax= ax[8,1], data = df, x = 'deposit_amt')\nsns.kdeplot(ax= ax[9,0], data = df, x = 'mnt_amt')\nsns.boxplot(ax= ax[9,1], data = df, x = 'mnt_amt')\nsns.kdeplot(ax= ax[10,0], data = df, x = 'powerbackup')\nsns.boxplot(ax= ax[10,1], data = df, x = 'powerbackup')\n","22ef2b27":"plt.figure(figsize= (20,10))\n\nsns.heatmap(df.corr(), annot = True, cmap = 'PuBu')","023382c7":"df['brok_amt'] = df['brok_amt'] + 1\ndf['deposit_amt'] = df['deposit_amt'] + 1\ndf['mnt_amt'] = df['mnt_amt'] + 1\ndf['rent'] = df['rent'] + 1","2c2eaa62":"len(df[df['area'] == 0])\n# we dont  have any mising data on area","efad33c6":"from scipy import stats\nfitted_area, _ = boxcox(df.area)\nsns.histplot(fitted_area)\ndf['area'] =  fitted_area\n\n## we are not ableo to remove all outliers but we are manage to merge 75  outliers out of 478  data.  Still 403  outliers are present in data\n## Update data to area\n\n","fb7c9e49":"print('before',df.shape)\ndf.drop(['mnt_amt', 'parking'], axis =  True, inplace =  True)\nprint('after',df.shape)\n","ea3e4046":"# APPLY log transformation on brok_amt \ndf['brok_amt'] = np.log(df['brok_amt'])\nsns.boxplot(df.brok_amt)","ea743827":"# APPLY log transformation on deposit \ndf['deposit_amt'] = np.log(df['deposit_amt'])\nsns.boxplot(df.deposit_amt)","7de4ee6d":"df.head(2)","4983df3d":"print('before',df.shape)\ndf.drop(['maintenance_amt', 'address'], axis =  True, inplace =  True)\nprint('after',df.shape)\n","ab4f1cbc":"df.head(2)","1c2899d2":"from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\nlb, le, oe, ms,ss = LabelBinarizer(), LabelEncoder(), OrdinalEncoder, MinMaxScaler, StandardScaler","762b9a6c":"bin_trans = [i for i in binary_variables  if i not in df.describe().columns] # geting binary variables & dtype is object\nfor column in bin_trans:\n    df[column] = lb.fit_transform(df[column])","8980494c":"## before going to further first work on locality\nprint('locality has {} unique values & it is huge'.format(len(df['locality'].unique())))","ef68f5b5":"df.locality.replace('', 'Pune', inplace =  True)\n","1d716c30":"df['address'] = df.locality\ndf['sqrt_depo'] = np.sqrt(df['bedroom'])\ndf.head(2)\n","352eac89":"area_mean = {}\n\nfor area in np.unique(df.address):\n#     print(area)\n    area_mean[area] = df.loc[df['address'] == area]['sqrt_depo'].mean()\n    \ndf['address_num'] = df['address'].map(area_mean)\ndf.head(2)","ab4f1ba1":"print('shape of data  before', df.shape)\ndf.drop(columns=['address', 'sqrt_depo','locality'], inplace =  True)\nprint('shape of data  after', df.shape)","d5bb12ce":"for column in df.describe(include='object').columns:\n    df[column] = le.fit_transform(df[column])","eb2552da":"df.describe().T","af3cbd46":"## After all that we have completed feature engineering task","401c89e5":"plt.figure(figsize = (20,15))\nsns.heatmap(df.corr(), annot = True, cmap= 'BuPu')","6ee5860e":"df.drop(columns = ['bathrooms'], inplace = True)","1c3ab77e":"### Next DAy model Builing ","5dfb5cac":"**Categorical Columns using labelencoder**","d10ea7e0":"We have mostly left skewed data in all continous variables ","250fafa0":"**Area**","5acb3d10":"Based on data following colums has most outliers & mostly left skewed data:\n1. area\n2. parking\n3. brok_amt\n4. seposit_amt\n5. mnt_amt\n\n& Little bit features engineering is needed on \n1. Bedroom\n2. Bathrooms\n3. aggDur\n4. NoticeDur\n\n\n","f1ca56c4":"### Outlier Treatment","db53f899":"## Exploratory Data Analysis ","2646dfbd":"## Feature Engineering ","e1a240aa":"### Start with Binary Variable Visualisation.\n","0798b444":"Based on data shape of data data has around 10884 sample with 30 features. ","521f9718":"**Know more about dataset** ","ec2c200b":"**Now we have a proper dataset copy so we can work on that** ","28bd811e":"**Problem Defination** \n\nPune is IT capital of India  & a city with 10,089,916 population. Pune is one of the larger employment producing city. So Most of peoples are living in rental houses & appartment.  so I'm going to predict the housing rental prices of areas in city.","7b9896ba":"## Exploring dataset\n### Import Libraries","2832bd97":"### Target Varible","03f5670e":"**output of base map**\n![map](map.jpg)","43371e89":"**Based on above plots I found that if Facility is available then rent for home is always higher**","057c6249":"Area has all positive data after apply log, sqrt  tranformation I found that we have positive data we can use boxcox transformation here","bc1ddb59":"**Cleaning messy area & geting proper locality name from this**","70a801f8":"Convert all variable into following categories\n1. Binary variables data\n2. Ordinal Varibles \n3. continous  data\n4. target Variable","28447a58":"**This Summary.csv is a file of locality & based on that we are going to fetch latitude & logitude for those columns.**\n\n\nI used goecoder library to get latitute & longotide for all locations as follows. & stored into a file **all_locations.csv** Which I will import here\n\n\n\n**If you wanted to do all geoding please uncomment below code**","a236a398":"### Continous Variables","799028fc":"you can check my dataset is here :\n\n1. Rental Price Data - [kaggle](https:\/\/www.kaggle.com\/anantsakhare\/rental-price-of-indias-it-capital-pune-mh-ind) \n2. Housing data Scrapper - [github](https:\/\/github.com\/senhorinfinito\/scrappers\/blob\/main\/rental_analysis\/train.csv)","49627c8f":"## Feature_selection ","f41ed619":"First we will look for uniques prices then we will check for missing & random  values \n","3f1a12d5":"# Rental Price Analysis of India's IT Capital - Pune, MH, IND","9a081f6a":"adding one rs amount in all","328501b6":"### Categorical Variables\n","51fef072":"## Few Feature Engineering on Target variables","6e4482e2":"### Ordinal Variables ","c4e1fba5":"**From above visualization we  have concluded following points for higher rent.**\n1. As number of bedroom increased rent also has incresed\n2. As per furnishing concern Furinished has higher pay than unfurnished\n3. Talking about direction if your home has east face your rent is higher as compare with south.\n4. As floor number goes higher Rent Also increased\n5. Wood Floor design(colors ) has higher pay than marble\n6. As per powerbackup facility, if you have full backup == 2  then you need to pay more rent.","6aefaa61":"1. Outliers treatment\n2. Feature transformation\n3. Feature Scaling"}}