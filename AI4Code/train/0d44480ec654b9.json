{"cell_type":{"e207a50f":"code","e8ef52f4":"code","b1c09402":"code","fb95b891":"code","e00dd118":"code","2f5e0f6e":"code","52dbe197":"code","d8461373":"code","79b19450":"code","8c98c7aa":"code","0c4d439a":"code","7e8ddd6c":"code","c2d78d8a":"code","d9eefde4":"code","7a53253b":"code","35a99c09":"code","b506e884":"code","01831540":"code","dae48d9e":"code","56585665":"code","0712b370":"code","a0789810":"code","9b36922c":"code","da44cf78":"code","cf616e9f":"code","3204af2b":"code","c840aa40":"code","18926efd":"code","f09d5d55":"code","372132ca":"code","ff817cd5":"code","e6e24d8d":"code","b2377350":"code","5f1e05ba":"code","53f2cb96":"code","af137628":"code","268bbe4b":"code","605d5d4f":"code","acdb4c59":"code","fa71dd47":"code","c492e9ef":"code","17c4d981":"code","02757094":"code","ce8d345f":"code","5c8cadf2":"code","0fab4462":"code","6b6d005a":"code","aa0664bf":"code","c6727efb":"code","e22b143e":"code","2a652d10":"code","4689fd41":"code","267700b7":"code","7a809da6":"code","3b976b9d":"code","4452b391":"code","02752d26":"code","c43f4fea":"code","8c5c6e37":"code","6cefa421":"code","0cd95e5e":"code","7731dbc9":"code","2a5bd7fc":"code","89f5cd46":"code","69f45e72":"code","9e831c69":"code","1e8490c9":"code","e007662a":"code","c2ffd3aa":"code","1a674dc2":"code","8750f6bb":"code","5ba8260f":"code","b725ba21":"markdown","8f70dca6":"markdown","fa6dc262":"markdown","a8e6e6c0":"markdown","aaf6ef0b":"markdown","8253be85":"markdown","1c88c8ce":"markdown","4d5a4a23":"markdown","055f120f":"markdown","db0cf222":"markdown","ea9876f0":"markdown","4ba9469f":"markdown","89217f26":"markdown","773a2935":"markdown","8e8690f6":"markdown","5758b113":"markdown","817a6026":"markdown","84f8ac3f":"markdown","d8882537":"markdown","9aea70f1":"markdown","091daaec":"markdown","92dc12a7":"markdown","39db7789":"markdown","52f296d9":"markdown","cd7bfad4":"markdown","742ea5a3":"markdown","436edca6":"markdown","64bcb18d":"markdown","3f508e57":"markdown","85d53815":"markdown","6a064632":"markdown","d350d035":"markdown","e38d1505":"markdown","0818a468":"markdown","ffd16f12":"markdown","9af1d37d":"markdown","7b9ca3b2":"markdown","99a4d823":"markdown","2299a3a1":"markdown"},"source":{"e207a50f":"# data processing\nimport numpy as np\nimport pandas as pd \n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n# Model Selection\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler,minmax_scale\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e8ef52f4":"# reading data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","b1c09402":"train_df = train.copy()\ntest_df = test.copy()\ndf = train_df.append(test_df,sort=False)","fb95b891":"train_df.sample(5)","e00dd118":"test_df.sample(5)","2f5e0f6e":"train_df.info()","52dbe197":"test_df.info()","d8461373":"print('train dataset has ' + str(train_df.shape[0]) + ' observations ' + str(train_df.shape[1])+ ' variables.')\nprint('test dataset has ' + str(test_df.shape[0]) + ' observations ' + str(test_df.shape[1])+ ' variables.')","79b19450":"train_df.dtypes","8c98c7aa":"train_df.describe().T","0c4d439a":"test_df.describe().T","7e8ddd6c":"train_df.isnull().sum().sort_values(ascending=False)","c2d78d8a":"def explore_missing_values(df) :\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total,percent], axis=1, keys=['Total','Percent'])\n    sns.barplot(x=missing_data.index,y=missing_data['Percent'])\n    plt.xlabel('Features', fontsize=15)\n    plt.ylabel('Percent of Missing Values')\n    plt.title('PERCENT MISSING DATA BY FEATURE')\n    plt.xticks(rotation='75')\n    plt.show()\n    print(missing_data.head(20))","d9eefde4":"explore_missing_values(train_df)","7a53253b":"explore_missing_values(test_df)","35a99c09":"def create_Title(df):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Rare\",\n        \"Col\":         \"Rare\",\n        \"Major\":       \"Rare\",\n        \"Dr\":          \"Rare\",\n        \"Rev\":         \"Rare\",\n        \"Jonkheer\":    \"Rare\",\n        \"Don\":         \"Rare\",\n        \"Sir\" :        \"Rare\",\n        \"Countess\":    \"Rare\",\n        \"Dona\":        \"Rare\",\n        \"Lady\" :       \"Rare\"\n    }\n    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    df[\"Title\"] = extracted_titles.map(titles)","b506e884":"create_Title(train_df)\ncreate_Title(test_df)","01831540":"train_df.groupby('Title')['Age'].median()","dae48d9e":"df.corr()['Age'].abs().sort_values(ascending=False)","56585665":"train_df.groupby(['Title','Pclass'])['Age'].median()","0712b370":"# Imputing 'Age' features\n\ntrain_df[\"Age\"] =train_df.groupby(['Title','Pclass'])[\"Age\"].apply(lambda x : x.fillna(x.median()))\ntest_df[\"Age\"] = test_df.groupby(['Title','Pclass'])[\"Age\"].apply(lambda x : x.fillna(x.median()))","a0789810":"train_df[train_df['Embarked'].isnull()]","9b36922c":"#Imputing 'Embarked' features\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")","da44cf78":"train_df[train_df['Cabin'].isnull()].head()","cf616e9f":"#Imputing 'Cabin' features\ntrain_df[\"Cabin\"] = train_df[\"Cabin\"].fillna(\"S\")\ntest_df[\"Cabin\"] = test_df[\"Cabin\"].fillna(\"S\")","3204af2b":"df.corr()['Fare'].abs().sort_values(ascending = False)","c840aa40":"test_df[test_df['Fare'].isnull()]","18926efd":"test_df[test_df['Ticket']=='3701']","f09d5d55":"#Imputing 'Fare' features\ntest_df[\"Fare\"] = test_df.groupby(['Pclass'])[\"Fare\"].apply(lambda x : x.fillna(x.median()))","372132ca":"explore_missing_values(train_df)","ff817cd5":"explore_missing_values(test_df)","e6e24d8d":"sns.boxplot(x=train_df['Fare']);","b2377350":"Q1 = train_df['Fare'].quantile(0.05)\nQ3 = train_df['Fare'].quantile(0.95)\nIQR = Q3-Q1","5f1e05ba":"top_border_fare = Q3+1.5*IQR\ntop_border_fare","53f2cb96":"train_df.loc[train_df['Fare'] > top_border_fare,'Fare'] = top_border_fare\ntest_df.loc[test_df['Fare'] > top_border_fare,'Fare'] = top_border_fare","af137628":"sns.boxplot(x=train_df['Fare']);","268bbe4b":"train_df['Survived'].value_counts()","605d5d4f":"train_df['Survived'].describe().T","acdb4c59":"sns.countplot(x='Survived',data=train)","fa71dd47":"train_df.head()","c492e9ef":"categorical_features = ['Pclass','Sex','SibSp','Parch','Embarked']\ncontinuous_features =['Age','Fare']","17c4d981":"def visualize_categorical_columns(df,col_list,hue='Survived'):\n    for col in col_list:\n        # hue='Survived'\n        sns.countplot(x=col,data=df,hue=hue)\n        plt.show()\n    return","02757094":"visualize_categorical_columns(train_df, categorical_features)","ce8d345f":"def visuzalize_continuous_columns(df,col_list):\n    for col in col_list:\n        sns.distplot(df[col])\n        plt.show()\n    return","5c8cadf2":" visuzalize_continuous_columns(train_df, continuous_features )","0fab4462":"corr = train_df.corr()\ncorr","6b6d005a":"sns.heatmap(train_df.corr(), annot = True, fmt='.1g')","aa0664bf":"corr['Survived'].abs().sort_values().abs().sort_values(ascending = False)","c6727efb":"# Binning 'Age' column\ntrain_df['AgeBinCode'] = LabelEncoder().fit_transform(pd.qcut(train_df[\"Age\"],4))\ntest_df['AgeBinCode'] = LabelEncoder().fit_transform(pd.qcut(test_df[\"Age\"],4))\n\ntrain_df['AgeBinCode'].value_counts()","e22b143e":"sns.countplot(x=train_df['AgeBinCode'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","2a652d10":"# Binning 'Fare' column\ntrain_df['FareBinCode'] = LabelEncoder().fit_transform(pd.qcut(train_df[\"Fare\"],5))\ntest_df['FareBinCode'] = LabelEncoder().fit_transform(pd.qcut(test_df[\"Fare\"],5))\n\ntrain_df['FareBinCode'].value_counts()","4689fd41":"sns.countplot(x=train_df['FareBinCode'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","267700b7":"# Creating FamilySize features\ntrain_df['FamilySize'] = train_df['Parch'] + train_df['SibSp']\ntest_df['FamilySize'] = test_df['Parch'] + test_df['SibSp']","7a809da6":"sns.countplot(x=train_df['FamilySize'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","3b976b9d":"# Creating LastName features\ntrain_df['LastName'] = train_df['Name'].apply(lambda x: str.split(x, \",\")[0])\ntest_df['LastName'] =test_df['Name'].apply(lambda x: str.split(x, \",\")[0]) \ndf['LastName'] = df['Name'].apply(lambda x: str.split(x, \",\")[0])","4452b391":"#Creating FamilySurvival features\n\nDEFAULT_SURVIVAL_VALUE = 0.5\n\ndf['FamilySurvival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in df[['Survived', 'Name', 'LastName', 'Fare', 'Ticket', 'PassengerId',\n                            'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['LastName', 'Fare']):\n    \n\n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin == 0.0):\n                df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\",\n      df.loc[df['FamilySurvival'] != 0.5].shape[0])\n\n\n\nfor _, grp_df in df.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['FamilySurvival'] == 0) | (row['FamilySurvival'] == 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 1\n                elif (smin == 0.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 0\n\nprint(\"Number of passenger with family\/group survival information: \"\n      + str(df[df['FamilySurvival'] != 0.5].shape[0]))\n\n\n\ntrain_df['FamilySurvival'] = df['FamilySurvival'][:891]\ntest_df['FamilySurvival'] = df['FamilySurvival'][891:]\n","02752d26":"sns.heatmap(train_df.corr())","c43f4fea":"train_df.corr()['Survived'].abs().sort_values(ascending=False)","8c5c6e37":"features = ['Pclass', 'Sex', 'AgeBinCode', 'FareBinCode', 'FamilySurvival','FamilySize']\ntarget = ['Survived']\n","6cefa421":"# X_train, X_test, y_train\n\nX_train = train_df[features]\ny_train = train_df[target]\nX_test = test_df[features]\n","0cd95e5e":"X_train.head()","7731dbc9":"def create_dummies(df,categorical_features):\n    for column_name in categorical_features:\n        dummies = pd.get_dummies(df[column_name], prefix=column_name, drop_first=True)\n        df = pd.concat([df,dummies],axis=1)\n    return df","2a5bd7fc":"X_train['Sex'] = LabelEncoder().fit_transform(X_train['Sex'])\nX_test['Sex'] = LabelEncoder().fit_transform(X_test['Sex'])","89f5cd46":"X_test.head()","69f45e72":"X_train =StandardScaler().fit_transform(X_train)\ny_train = train_df[target]\nX_test = StandardScaler().fit_transform(X_test)","9e831c69":"models = [\n    ('KNN',KNeighborsClassifier()),\n    ('DT', DecisionTreeClassifier()),\n    ('NB', GaussianNB()),\n    ('SVM',SVC()),\n    ('RF', RandomForestClassifier()),\n]\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n","1e8490c9":"def tuning_model(model,hyperparams_dict):\n    grid = GridSearchCV(model,\n                        param_grid=hyperparams_dict,\n                        cv=10,\n                        n_jobs=-1,\n                        verbose=2)\n    grid.fit(X_train, y_train)\n    best_params = grid.best_params_\n    best_score = grid.best_score_\n  \n    print(\"Best Score: {}\".format(best_score))\n    print(\"Best Parameters: {}\\n\".format(best_params))\n\n    return grid.best_estimator_","e007662a":"knn_hyperparams = { \"n_neighbors\" : list(range(1,30,1)),\n\"algorithm\" : ['auto'],\n\"weights\" : ['uniform', 'distance'],\n\"leaf_size\" : list(range(1,50,5))\n}\n\nknn_tuned = tuning_model(KNeighborsClassifier(),knn_hyperparams)","c2ffd3aa":"rf_hyperparams = {\"n_estimators\": [40, 60, 90],\n\"criterion\": [\"entropy\", \"gini\"],\n\"max_depth\": [2, 5, 10],\n\"max_features\": [\"log2\", \"sqrt\"],\n\"min_samples_leaf\": [1, 5, 8],\n\"min_samples_split\": [2, 3, 5] }\n\nrf_tuned = tuning_model(RandomForestClassifier(), rf_hyperparams)","1a674dc2":"def save_submission_file(model,X_test,filename=\"submission.csv\"):\n    submission_df = {\"PassengerId\": test['PassengerId'],\n                     \"Survived\": model.predict(X_test)}\n    submission = pd.DataFrame(submission_df)\n    submission.to_csv(filename,index=False)","8750f6bb":"save_submission_file(knn_tuned,X_test,filename='knn_submission.csv')","5ba8260f":"save_submission_file(rf_tuned,X_test,filename='rf_submission.csv')","b725ba21":"## 3.1 Binning Continuous Features","8f70dca6":"# Introduction","fa6dc262":"### 2.4.1 Categorical Features","a8e6e6c0":"When I googled that names I learned that they boarded the Titanic in from Southampton. I will fill missing values in 'Embarked' with 'S' representing 'Southampton'.\n\nhttps:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html","aaf6ef0b":"Pclass and Age have high correlation so decided to group the data by Title and Pclass and fill the Age column with the median of each group.","8253be85":"## 2.4 Analyzing Features ","1c88c8ce":"When I look at the statistical summary of the data, I notice a few things :\n* Approximately 38% of the passengers survived. \n* It looks like Fare variable contains outlier observations.\n* The majority of passengers travel alone.\n* The majority of passengers are less than 40 years old\n    \nThese are the things I understand when I first look at the data. I will review the data in more detail later. ","4d5a4a23":"#### 2.1.2 Embarked","055f120f":"# Titanic (End To End ML Workflow)","db0cf222":"## 1.1 Variable Explanations\n\nFirst of all we need to get some information about data.\n \n\n\n * **PassengerId:**  Unique Id for each passenger (it doesn't have any effect on target)\n \n    \n * **Survived(categorical):** Survival (0 : No, 1 : Yes) (*)\n \n \n * **Pclass(categorical-ordinal) :**\tPassenger class (1 : 1st, 2 : 2nd, 3 : 3rd)\n \n \n * **Name:** Passenger name\n \n \n * **Sex(categorical) :** Passenger sex\n \n \n * **Age:** Passenger age\n \n \n * **SibSp:** Sibling - Spouse (**)\t\n \n \n * **Parch:** Parent - Child (***)\n \n \n * **Ticket:** Ticket number\n \n \n * **Fare:** Passenger fare\n \n \n * **Cabin:** Cabin number\n \n \n * **Embarked(categorical):** Port of Embarkation (C \n : Cherbourg, Q : Queenstown, S : Southampton)\n \n\n(*) 'Survived 'is the target variable we are trying to predict. So test data doesn't have 'Survived' column.\n\n\n(**) sibsp: The dataset defines family relations in this way...\n\n           Sibling = brother, sister, stepbrother, stepsister\n\n           Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n(***) parch: The dataset defines family relations in this way...\n\n            Parent = mother, father\n\n            Child = daughter, son, stepdaughter, stepson\n\n            ! Some children travelled only with a nanny, therefore parch=0 for them.","ea9876f0":"# 1. Data Preprocessing","4ba9469f":"Although the 'Cabin' feature has too much missing value, for now, I won't drop the column and I will fill them with 'U0'  representing that they are unknown,  after then I will try to extract useful information from the 'Cabin' column.","89217f26":"## 1.4 Overview of The Data","773a2935":"#### RANDOM FOREST","8e8690f6":"#### KNN","5758b113":"This feature is from Konstantin's kernel. FamilySurvival variable gathers together families and people with the same ticket and gives a ratio about group survival.\nhttps:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83","817a6026":"#### 2.1.3 Cabin","84f8ac3f":"# 4. Modelling","d8882537":"## 2.1 Missing Values","9aea70f1":"## 1.3 Getting Data","091daaec":"## 4.2 Model Tuning","92dc12a7":"## 2.2 Outliers","39db7789":"## 3.5 Feature Transformation (Categoric Variables)","52f296d9":"#### 2.1.4 Fare","cd7bfad4":"## 1.2 Importing Libraries","742ea5a3":"The number of missing values in the Age, Embarked and Fare columns is relatively low compared to the total number of observations. Therefore, missing values in those columns can simply fill with descriptive statistics measurements.But, it is not the right approach for the 'Cabin' column that includes approximately %80 missing values. ","436edca6":"# 3. Feature Engineering","64bcb18d":"## 4.1 Model Training","3f508e57":"## 2.5 Exploring Correlations","85d53815":"## 3.4 Feature Scaling(Continuous Variables)","6a064632":"## 2. Exploratory Data Analysis","d350d035":"# 5. Making A Submission","e38d1505":"## 3.2 Creating New Features","0818a468":"**Titanic: Machine Learning from Disaster** is one of the best Kaggle competitions for improving data science skills, especially, feature engineering skills. The Titanic dataset is a pretty good choice for beginners who want to improve data science skills.\n\nIn this project, I will deal with the end-to-end data science cycle. And this project will include the below sections.\n\n### Table of Contents:\n\n* 1. Preprocessing the data\n    * 1.1 Variable Explanations\n    * 1.2 Importing Libraries\n    * 1.3 Getting Data\n    * 1.4 Overview of The Data\n    \n* 2. Exploratory Data Analaysis\n    * 2.1 Missing Values\n        * 2.1.1 Age \n        * 2.1.2 Embarked\n        * 2.1.3 Cabin\n        * 2.1.4 Fare\n    * 2.2 Outliers    \n    * 2.3 Analyzing Target Variable\n    * 2.4 Analyzing Features\n        * 2.4.1 Categorical Features\n        * 2.4.2 Continuous Features\n    * 2.4 Exploring Correlations\n        \n* 3. Feature Engieering\n    * 3.1 Binning Continuous Features\n    * 3.2 Creating New Features\n    * 3.3 Feature Selecting\n    * 3.4 Feature Scaling(Continuous Variables)\n    * 3.5 Feature Transformation (Categoric Variables)\n    \n* 4. Model Selecting And Model Tuning\n    * 4.1 Model Training\n    * 4.2 Model Tuning\n\n* 5. Making a Submission","ffd16f12":"##  3.3 Feature Selecting","9af1d37d":"\n## 2.3 Exploring Target Variable","7b9ca3b2":"#### 2.1.1 Age\n\nI will create Title feature for imputing Age columns, but I won't use that feature in the model.","99a4d823":"### Fare","2299a3a1":"###  2.4.2 Continuous Features "}}