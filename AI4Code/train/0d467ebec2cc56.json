{"cell_type":{"f6f8f26f":"code","21d3d437":"code","4412e901":"code","2fa3561e":"code","cd707a10":"code","3e64b1d9":"code","3355a37a":"code","4bbad0bf":"code","99140ed4":"markdown","fb8bc510":"markdown","8530be25":"markdown","25a1eaa4":"markdown","f28f265e":"markdown","9ccf443e":"markdown"},"source":{"f6f8f26f":"import sklearn\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import NearestNeighbors\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import classification_report","21d3d437":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","4412e901":"df = pd.read_csv('\/kaggle\/input\/trainred\/Trainred.csv')\ndf.shape\ndf ##Importamos el set de datos preprocesado","2fa3561e":"X=np.array(df[['village','age','children','edu','cons_social','cons_other',\n      'ed_expenses_perkid','durable_investment','nondurable_investment','ent_farmprofit']])\nX = preprocessing.StandardScaler().fit(X).transform(X)\ny=np.array(df['depressed']) \n## Se crea un numpy array con las features que se seleccionaron con el RFE y se normalizan los datos","cd707a10":"model = RandomForestClassifier(n_estimators = 128, random_state = 42)\nmodel.fit(X, y)\nscores = cross_val_score(model, X, y, cv=10)\n##Se construye y ajusta el modelo con 128 \u00e1rboles. \n##Adem\u00e1s, se consigue los scores para la validaci\u00f3n cruzada con 10 K folds. ","3e64b1d9":"print('Cross validated Scores',scores)\npred = cross_val_predict(model, X, y, cv=10)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y, pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y, pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y, pred)))\nprint (classification_report(y, pred))\n##Obtenemos las m\u00e9tricas que se tienen del modelo. ","3355a37a":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Esta funci\u00f3n muestra y dibuja la matriz de confusi\u00f3n.\n    La normalizaci\u00f3n se puede aplicar estableciendo el valor `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Matriz de confusi\u00f3n normalizada\")\n    else:\n        print('Matriz de confusi\u00f3n')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Etiqueta Real')\n    plt.xlabel('Etiqueta Predicha')\nprint(confusion_matrix(y, pred, labels=[1,0]))\n\n## Este c\u00f3digo inicia la construcci\u00f3n de la matriz de confusi\u00f3n para el modelo escogido. ","4bbad0bf":"cnf_matrix = confusion_matrix(y, pred, labels=[1,0])\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Not Depressed','Depressed'],normalize= False,  title='Matriz de confusi\u00f3n')\n##Se construye la matriz de confusi\u00f3n","99140ed4":"### En este Jupyter Notebook se construye un Random Forest de clasificaci\u00f3n y se lo eval\u00faa. Este modelo fue el mejor de todos en el caso de la competencia de Zindi. ","fb8bc510":"Se construye el clasificador de Random Forest","8530be25":"Iniciamos importando las librer\u00edas y el set de datos","25a1eaa4":"Tenemos una sensibilidad alta, lo que nos puede llevar a algunos falsos positivos. No obstante, gran parte de las personas deprimidas fueron identificadas, cumpliendo con el objetivo de la competencia","f28f265e":"# DataSeekers - Random Forest","9ccf443e":"\n\n   ### Camila Revelo\n   ### Christian Ayala\n   ### Alegr\u00eda Carri\u00f3n\n   ### Joel Mar\u00edn"}}