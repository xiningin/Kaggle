{"cell_type":{"3e5baeaf":"code","2ef7d38c":"code","a20eb7d8":"code","1edfeeae":"code","7e891d9c":"code","5312f1c8":"code","209b8482":"code","6888d8b2":"code","cf90dfc6":"code","80d09cfe":"code","92a05555":"code","abaa6465":"code","19b83c1b":"code","16b71d9b":"code","dd963939":"code","8ec8bf51":"code","780f2269":"code","272f2e7b":"code","35747258":"code","d3d7082e":"code","28495f46":"code","f1c6e65e":"code","a79c58d1":"code","9e012745":"code","a0abe798":"code","4e3463b4":"code","c5b759ec":"code","46a4d2c5":"markdown","9c78e529":"markdown","aa06c9a8":"markdown","1e86531a":"markdown","2b41c555":"markdown","634da1b9":"markdown","390b2e3d":"markdown","ea4fb6af":"markdown","2fbb3af2":"markdown","df1df559":"markdown","dbee9b7d":"markdown","107cf5ca":"markdown","b7588af8":"markdown","20c8b1e3":"markdown","05419d73":"markdown","c7b062e1":"markdown"},"source":{"3e5baeaf":"import csv\nimport json\nimport re\nimport numpy as np\nimport pandas as pd\nimport altair as alt\n\nfrom collections import Counter, OrderedDict\nfrom IPython.display import HTML\nfrom  altair.vega import v3","2ef7d38c":"# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))","a20eb7d8":"state_pops = pd.read_csv('..\/input\/historical-state-populations-19002017\/state_pops.csv')\nstate_names = pd.read_csv('..\/input\/us-state-baby-names\/all_states.csv')\nnat_names = pd.read_csv('..\/input\/us-national-baby-names-18802017\/all_national.csv')","1edfeeae":"name_variability = {}\nfor year in range(1880,2018):\n    df = nat_names[nat_names['Year'] == year]\n    variability = sum(df.Count)\/len(df)\n    name_variability[year] = round(variability)","7e891d9c":"name_count = pd.DataFrame({'Year':list(name_variability.keys()), \n                           'Count':list(name_variability.values())})\nyrs = name_count['Year'].astype('str')\nname_count['Year'] = pd.to_datetime(yrs)","5312f1c8":"base = alt.Chart(name_count).encode(\n    x=alt.X('year(Year)', axis=alt.Axis(grid=True), title='Year'),\n    y=alt.Y('Count', axis=alt.Axis(grid=False))\n    ).properties(width=600, title='Average Count Per Name')\n\nline = base.mark_line()\n\npoints = base.mark_point().encode(\n    tooltip=['year(Year)', 'Count'])\n\nchart = line + points\nrender(chart)","209b8482":"#Dictionary containing all names that appeared in national top 10 in any year during a specified decade\n#Split into: M & F\ndef top_10_potential(decade):\n    all_names = {}\n    for sex in ['M','F']:\n        names = []\n        \n        #Adding conditional to avoid error w\/ 2010 decade data (since data only covers 2010-2017)\n        if decade == 2010:\n            span = 8\n        else:\n            span = 10\n            \n        #Extracting top 10 names from each year within a decade\n        for i in range(span):\n            df = nat_names[nat_names['Year'] == decade+i].reset_index(drop=True)\n            df = df[df['Sex'] == sex].reset_index(drop=True)\n            top_10 = list(df.loc[:9, 'Name'])\n            new = [name for name in top_10 if name not in names]\n            names += new\n        #Stores list of potential names in relevant key (M or F) \n        all_names[sex] = names\n    return all_names","6888d8b2":"#Returns list of decade's top 10 names (based on cumulative count)\n#(First parameter should be variable storing output of top_10_potential function- specifying M or F key)\ndef top_10_confirm(decade):\n    potential = top_10_potential(decade)\n    counts = {}\n    \n    #Conditional to avoid error w\/ 2010 decade data (since data only covers 2010-2017)\n    if decade == 2010:\n        span = 8\n    else:\n        span = 10\n        \n    for sex in ['M','F']:\n        names = {}\n        for year in range(decade, decade+span):\n            df = nat_names[nat_names['Year'] == year].reset_index(drop=True)\n            for name in potential[sex]:\n                #Try\/except averts error if name has no count in a particular year\n                try:\n                    count = df['Count'][(df['Sex'] == sex) & (df['Name'] == name)].reset_index(drop=True).iloc[0]\n                except Exception: \n                    count = 0\n                    \n                #Creates key for each name and assigns annual count in names dict \n                #(or increments count value for existing name key, doing this for every year in decade to arrive at total count)\n                if name in list(names.keys()):\n                    names[name] += count\n                else:\n                    names[name] = count\n        #Sorts names dict by values (ascending) and stores keys of top 10 names (corresponding to a particular sex) in counts dict\n        counts[sex] = sorted(names, key=names.get)[-10:]\n    return counts","cf90dfc6":"#Dictionary containing all names that were one of the 10 most popular names nationally in any decade (1910-2020)\n#(not including 1880-1900 since state name data begins from 1910, which this dict was created to examine)\n#(split into M & F)\ntrended = {}\ndecades = list(np.arange(1910, 2020, 10))\nfor sex in ['M','F']:\n    top_10 = []\n    for decade in decades:\n        names = top_10_confirm(decade)\n        new = [name for name in names[sex] if name not in top_10]\n        top_10 += new\n    trended[sex] = top_10","80d09cfe":"#Populating dictionary w\/ names that appeared in top 10 from any year, categorized by sex & decade\n#Name keys are assigned empty values, which I will manually replace w\/ syllable count below\nall_names_decades = {}\ndecades = list(np.arange(1880, 2020, 10))\nfor sex in ['M','F']:\n    names = {}\n    for decade in decades:\n        keys = top_10_potential(decade)[sex] \n        names[decade] = {key: None for key in keys} \n    all_names_decades[sex] = names","92a05555":"#Dictionary containing unique male & female names from all_names_decades dictionary \n#I will manually assign syllable count to names in dict below\nunique_names = {}\ndecades = list(np.arange(1880,2020,10))\nfor sex in ['M','F']:\n    original = []\n    for decade in decades:\n        names = top_10_potential(decade)[sex]\n        new = [name for name in names if name not in original]\n        original += new\n    unique_names[sex] = {key: None for key in original}","abaa6465":"#Copy\/pasted contents of unique_names (above) and manually assigned syllable counts to new dict (original_names)\n#For names whose syllable counts I was unsure about, I assigned a syllable count \n#consistent w\/ popular pronunciation (e.g. Barbara(2), Amelia(3), Brittany(2), Deborah(2))\noriginal_names = {\n'F': {'Abigail': 3, 'Addison': 3,\n  'Alexis': 2,  'Alice': 2, 'Alyssa': 3, 'Amanda': 3, 'Amelia': 3, 'Amy': 2, 'Angela': 3, 'Anna': 2,\n  'Annie': 2, 'Bertha': 2, 'Bessie': 2, 'Clara': 2, 'Edna': 2, 'Ethel': 2, 'Florence': 2, 'Gladys': 2,\n  'Ida': 2, 'Lillian': 3, 'Minnie': 2, 'Ashley': 2, 'Ava': 2, 'Barbara': 2,  'Betty': 2, 'Brenda': 2,  \n  'Brittany': 2, 'Carol': 2, 'Carolyn': 3, 'Charlotte': 2,  'Chloe': 2, 'Crystal': 2,  'Cynthia': 3, \n  'Deborah': 2,  'Debra': 2, 'Donna': 2,  'Doris': 2, 'Dorothy': 3, 'Elizabeth': 4, 'Emily': 3, 'Emma': 2,\n  'Evelyn': 3, 'Frances': 2, 'Hannah': 2, 'Harper': 2, 'Heather': 2, 'Helen': 2, 'Isabella': 4, \n  'Jennifer': 3, 'Jessica': 3, 'Joan': 1, 'Joyce': 1, 'Judith': 2, 'Judy': 2, 'Julie': 2, 'Karen': 2,  \n  'Kathleen': 2, 'Kayla': 2,  'Kelly': 2, 'Kimberly': 3, 'Laura': 2, 'Lauren': 2,  'Linda': 2, 'Lisa': 2,\n  'Lori': 2, 'Madison': 3, 'Margaret': 2, 'Marie': 2, 'Mary': 2, 'Megan': 2, 'Melissa': 3, 'Mia': 2, \n  'Michelle': 2, 'Mildred': 2, 'Nancy': 2, 'Nicole': 2, 'Olivia': 4, 'Pamela': 3, 'Patricia': 3, \n  'Rachel': 2, 'Rebecca': 3, 'Ruth': 1, 'Samantha': 3, 'Sandra': 2, 'Sarah': 2, 'Sharon': 2,'Shirley': 2,\n  'Sophia': 3, 'Stephanie': 3, 'Susan': 2, 'Tammy': 2, 'Taylor': 2, 'Tracy': 2, 'Virginia': 3},\n  \n 'M': {'Aiden': 2, 'Alexander': 4, 'Andrew': 2, 'Anthony': 3, 'Austin': 2, 'Benjamin': 3, 'Brandon': 2, \n  'Brian': 2,'Charles': 2, 'Christopher': 3, 'Daniel': 2, 'David': 2, 'Donald': 2, 'Edward': 2,\n  'Elijah': 3, 'Ethan': 2, 'Frank': 1, 'Gary': 2, 'George': 1, 'Harry': 2, 'Henry': 2, 'Jacob': 2, \n  'James': 1, 'Jason': 2, 'Jayden': 2, 'Jeffrey': 2, 'John': 1, 'Joseph': 2, 'Joshua': 3, 'Justin': 2, \n  'Larry': 2, 'Liam': 2, 'Logan': 2, 'Mark': 1, 'Mason': 2, 'Matthew': 2, 'Michael': 2, 'Nicholas': 3,  \n  'Noah': 2, 'Oliver': 3, 'Richard': 2, 'Robert': 2, 'Ronald': 2, 'Scott': 1, 'Steven': 2, 'Thomas': 2, \n  'Tyler': 2, 'Walter': 2, 'William': 2}}","19b83c1b":"#Transfers syllable count from original_names dict to corresponding names \n#(w\/ empty values) in all_names_decades dict\nfor sex in ['M','F']:\n    decades = np.arange(1880, 2020, 10)\n    for decade in decades:\n        dec = all_names_decades[sex][decade]\n        for name in dec:\n            all_names_decades[sex][decade][name] = original_names[sex][name]\n            \n#Proceeding With New Dict (after syllable count assignment)\ndecade_syllable_counts = all_names_decades.copy()            ","16b71d9b":"#Stores avg syllable count for all names appearing in top 10 for a particular year in each decade\nsyllables_avg = {}\ndecades = np.arange(1880,2020,10)\nfor sex in ['F', 'M']:\n    avgs = {}\n    for decade in decades:\n        data = decade_syllable_counts[sex][decade]\n        avg = np.mean(list(data.values()))\n        avgs[decade] = avg\n    syllables_avg[sex] = avgs","dd963939":"# Dataframe for Altair plot\nmale = pd.DataFrame.from_dict(syllables_avg['M'], orient='index')\nmale['Sex'] = np.full(len(male),'M')\n\nfemale = pd.DataFrame.from_dict(syllables_avg['F'], orient='index')\nfemale['Sex'] = np.full(len(female),'F')\n\ncombined_syllables = pd.concat([male, female])\ncombined_syllables = combined_syllables.reset_index().rename({'index':'Year', 0:'Syllables'}, axis=1)\ncombined_syllables['Syllables'] = combined_syllables['Syllables'].round(2)\n\ncombined_syllables['Year'] = pd.DatetimeIndex(combined_syllables['Year'].astype('str'))","8ec8bf51":"base = alt.Chart(combined_syllables).encode(\n    x=alt.X('year(Year)', axis=alt.Axis(grid=True), title=None),\n    y=alt.Y('Syllables:Q', scale=alt.Scale(zero=False), axis=alt.Axis(grid=False)),\n    color=alt.Color(\n        'Sex', scale=alt.Scale(\n        domain=['F','M'], \n        range=['#de9ed6','#1f77b4']))\n    ).properties(width=600, height=400, title='Average Syllable Count (for popular names)')\n\nlines = base.mark_line()\npoints = base.mark_point().encode(tooltip=['year(Year)','Syllables'])\n\nchart = lines + points\nrender(chart)","780f2269":"#Dictionary storing peak year for each name in trended (for all states)\n#(split into M & F)\n#Need to find faster way to process this (took 2 min 10 sec)\nmale_fem = {}\nstate_abrev = list(state_names.State.unique())\nfor sex in ['M','F']:\n    names = {}\n    for name in trended[sex]:\n        states = {}\n        copy = state_names.copy()\n        copy = copy[(copy['Sex'] == sex) & (copy['Name'] == name)]\n        for state in state_abrev:\n            df = copy[copy['State'] == state]\n            peak = df['Normalized_Count'].max()\n            peak_yr = df['Year'][df['Normalized_Count'] == peak]\n            states[state] = peak_yr.iloc[0]\n        names[name] = states\n    male_fem[sex] = names","272f2e7b":"abigail = male_fem['F']['Abigail']\npoints = pd.DataFrame({'State':list(abigail.keys()), 'Peak':list(abigail.values())})\ndates = points.Peak.astype('str')\npoints['Peak'] = pd.to_datetime(dates)\n\nclick = alt.selection_multi(encodings=['color'])\n\npts = alt.Chart(points).mark_circle(size=80).encode(\n    x=alt.X('State:O', title=''),\n    y=alt.Y('year(Peak)', title='Peak Year'),\n    color=alt.condition(click, 'State', alt.value('lightgray'), legend=None),\n    tooltip=['State', 'year(Peak)']\n).properties(selection=click, width=600, height=500, title='Year of Each State\\'s Peak Popularity for \"Abigail\"')\n\nlegend = alt.Chart(points).mark_circle(size=80).encode(\n    y=alt.Y('State:O', title=''),\n    color=alt.condition(click, 'State', alt.value('lightgray'), legend=None)\n).properties(height=600, selection=click)\n\nchart = pts | legend\nrender(chart)","35747258":"#Dictionary split into M & F#Diction \nstate_counts = {}\nfor sex in ['M','F']:\n    count = {}\n    for name in male_fem[sex]:\n        data = male_fem[sex][name]\n        values = list(data.items())\n        peaks = list(data.values())\n        first_peak = min(peaks)\n        \n        #Identifying trend-setting states whose peaks were within 10 years of median peak\n        median = np.median(peaks)\n        for peak in peaks:\n            if median - first_peak <= 10:\n                trend_setters = [x[0] for x in values if x[1] == first_peak]\n                break\n        #Removing outliers from peaks list & identifying next earliest non-outlier peak\n            else:\n                peaks = list(filter(lambda x: x!= first_peak, peaks))\n                first_peak = min(peaks)\n                continue\n        #Populating counts dict w\/ counts for states that have earliest peak appearance\n        for state in trend_setters:\n            if state in count:\n                count[state] += 1\n            else:\n                count[state] = 1\n        #Storing value of 0 for states w\/ no earliest peak appearances\n        states = [x[0] for x in values]\n        for state in states:\n            if state not in count:\n                count[state] = 0\n    state_counts[sex] = count","d3d7082e":"#Combining counts from M & F sub-dictionaries into combined counts dictionary\nmale = state_counts['M']\nfemale = state_counts['F']\nstate_counts['Combined'] = {x: male.get(x, 0) + female.get(x, 0) \n                            for x in set(male) & set(female)}\n\ncounts = pd.DataFrame({'Boys':state_counts['M'], 'Girls':state_counts['F'], 'Combined':state_counts['Combined']})\ncounts = counts.reset_index().rename({'index':'State'}, axis=1)","28495f46":"#Creating 'Count' series containing 51 'male' & 51 'female' labels (to add to df below)\nmale_state_counts = counts.loc[:,['State','Boys']]\nfemale_state_counts = counts.loc[:,['State','Girls']]\n\nmale_state_counts['Sex'] = np.full(51, 'Boys')\nmale_state_counts.rename({'Boys':'Count'}, axis=1, inplace=True)\nfemale_state_counts['Sex'] = np.full(51, 'Girls')\nfemale_state_counts.rename({'Girls':'Count'}, axis=1, inplace=True)\n\nboth_counts = pd.concat([male_state_counts, female_state_counts]).reset_index(drop=True)\n\n#Creating 'combined_counts_repeat' series (containing combined male+female counts, repeated) \n#to assign to new 'Total' column below\ncombined_counts = both_counts.groupby('State').Count.sum()\ncombined_counts_repeat = pd.concat([combined_counts, combined_counts])\nboth_counts['Total'] = combined_counts_repeat.reset_index(drop=True)","f1c6e65e":"bar = alt.Chart(both_counts).mark_bar().encode(\n    x=alt.X('State', title=None),\n    y=alt.Y('Total', title=None),\n    color=(alt.condition(        \n        alt.datum.Total > 11,\n        alt.value('orange'),\n        alt.value('steelblue'))),\n    tooltip=['State','Total']\n    ).properties(width=700, title='Total # of Earliest Peaks')\n\nrender(bar)","a79c58d1":"bar = alt.Chart(both_counts).mark_bar(opacity=0.9).encode(\n    x=alt.X('State', title=None),\n    y=alt.Y('Count', title=None),\n    tooltip=['State','Count','Total'],\n    color=alt.Color('Sex', \n                    scale = alt.Scale(domain=['Boys', 'Girls'],\n                  range=['#386cb0', '#e377c2']))\n    ).properties(width=650, title='Total # of Earliest Peaks')\n\nrender(bar)","9e012745":"#Storing avg years before\/after national median peak for popular names (for each state)\navg_diff = {}\nfor sex in ['M', 'F']:\n    peaks_diff = {}\n    temp={}\n    data = male_fem[sex]\n    for name in data:\n        peaks = list(data[name].values())\n        median = np.median(peaks)\n        state_peak_pairs = list(data[name].items())\n        for pair in state_peak_pairs:\n            state = pair[0]\n            peak = pair[1]\n            \n#IMPORTANT: Filtering out outliers (States whose peaks were more than 5 years before national median peak)\n#*Tweaking the number below (5) will affect what peak year data is included \n# (since it discards peak years occurring more than 5 yrs before national median)\n\n            if abs(peak-median) > 5:\n                continue\n            #appending median-peak differences to peaks_diff dictionary    \n            elif state in peaks_diff:\n                peaks_diff[state] += [peak-median]\n            else:\n                peaks_diff[state] = [peak-median]\n    #Calculating average peak-median difference for each state \n    #(negative value indicates avg # of years it peaks before median peak)\n    for state in peaks_diff:\n        temp[state] = np.mean(peaks_diff[state])\n    #Storing avg differences for each sex (in avg_diff dict)\n    avg_diff[sex] = temp","a0abe798":"av_dif = pd.DataFrame([avg_diff['M'], avg_diff['F']], index=['Boys','Girls'])\nav_dif = av_dif.transpose()\nav_dif['Combined'] = (av_dif.Boys + av_dif.Girls) \/2\nav_dif = av_dif.round(2)\nav_dif = av_dif.reset_index().rename({'index':'State'}, axis=1)","4e3463b4":"bar = alt.Chart(av_dif).mark_bar().encode(\n    x=alt.X('State', title=None),\n    y=alt.Y('Combined', title='Years'),\n    color=alt.Color('Combined', scale = alt.Scale(range=['indigo', 'teal']), legend=None),\n    tooltip=['State','Boys','Girls', 'Combined']\n    ).properties(width=700, title=\"Avg. Peak Relative to National Median\")\n\nrender(bar)","c5b759ec":"import plotly\nplotly.offline.init_notebook_mode()\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\ndata = dict(\n    type='choropleth',\n    locations=av_dif['State'],\n    locationmode='USA-states',\n    colorscale = 'YlGnBu',\n    z=av_dif['Combined'])\n\nlyt = dict(geo=dict(scope='usa'), title='Avg. Peak Relative To National Median')\nmap = go.Figure(data=[data], layout=lyt)\nplotly.offline.iplot(map)","46a4d2c5":"### Metric #2: Avg. Number of Years a State Peaks Before\/After National Median Peak\n*(Results were similar to metric # 1, but a clearer regional pattern emerged from this approach)*\n\n\\**Interactive: Scroll over bars to view state abrev & years before\/after median (including breakdown of boys & girls names)*","9c78e529":"### Findings:\nSurprising results! Instead of large states like CA or NY being trendsetters (which I hypothesized) states with relatively small populations (ND, VT, ME, NE, UT & WY) made up the top 6 overall. This indicates that trendsetting power in areas like politics (https:\/\/www.cbsnews.com\/news\/california-is-a-political-trendsetter\/) or fashion (https:\/\/pursuitist.com\/new-york-city-leads-worlds-fashion-capital\/) doesn't necessarily spill over to other areas of social life.","aa06c9a8":"## (3) Trendsetting States","1e86531a":"### (Same Chart as Above, Split Into Boy & Girl Counts)","2b41c555":"## Results Sneak Peak:\n(1) At the beginning of the 20th & 21st centuries names were **3 times more unique** than in the middle of the 20th century!\n\n(2) Both boys and girls names **syllable counts increased** by about 0.65 syllables (from 1880-2017)\n\n(3) The **Mountain\/Midwest** regions were **furthest ahead of naming trends**, while the South\/Southwest regions lagged the furthest behind","634da1b9":"### Sample Plot: Year of Each State's Peak Popularity for \"Abigail\"\n*(Vermont was the leader in this instance)*\n\n\\**Interactive:* click on circle (chart or legend) to highlight selected state (can select multiple states by holding 'shift' key and clicking mouse)","390b2e3d":"### Findings:\n(1) The **Mountain & Midwest** regions contain states **most ahead of the curve** (Top 4 = ND, UT, NE, IA)\n\n*North Dakota (1.46 years ahead)\n\n(2) The **South lags behind the most** (Bottom 8 = NV, FL, GA, TX, NM, SC, AL, VA)\n\n*Nevada (1.65 yrs behind)\n\n(3) States consistent w\/ national median peak: AK, MO, NH, NY (no apparent regional pattern)\n\n### *Curious Finding:*\n*Despite Utah being the #2 trendsetter it borders the #1 lagging state (Nevada). Perhaps exploring this odd reality further will reveal some interesting insights about either state.*","ea4fb6af":"### Findings:\n(1) Popular boys & girls names both **increased by about 0.65 syllables** from 1880-2017\n\n(2) On average, popular **girls names contained 0.5 more syllables** than popular boys names\n\n(3) Girls names experienced a significant drop from 1920-1930, before continuing upward trend due to the popularity of several 1 syllable names: *Ruth, Joyce, & Joan*","2fbb3af2":"## Exploring Baby Names Dataset\nI will explore the following three questions not previously addressed in Kaggle's US baby names thread: https:\/\/www.kaggle.com\/kaggle\/us-baby-names\/kernels","df1df559":"### Map of Trendsetters & Laggers (via Plotly)\n\\**Interactive:* Scroll over states to view state abrev and avg. peak years before\/after national median (and can also zoom in\/out)","dbee9b7d":"## (2) Avg. Syllable Counts in Each Decade\n*(based on popular names - i.e. those that appeared in nat'l top 10 in any year during a particular decade)*\n\n\\*Interactive: scroll over points to view year & syllable count\n\n***Note:*** *each year represents the first year of the decade (e.g. 2000 represents data for 2000-2009)*","107cf5ca":"### Metric #1:  Total Number of Earliest Peak Name Popularity Counts\n*Number of times a particular state had the earliest peak popularity compared to other states for a particular name*\n\n\\**Interactive: Scroll over bar to view state name & total count (orange bars are the leading trendsetters)*","b7588af8":"### (1) Name Uniqueness\n*Does the average count per name shift throughout the 20th century?*\n### (2) Syllable Count\n*Do name syllable counts shift throughout the 20th century?*\n### (3) Name Trendsetting Power\n*Are certain states national trendsetters for popular names?*\n\n***I used two methods to answer the third question:***\n* Counting the number of times a popular name reaches it's peak popularity in a state before other states\n* Comparing when states reach peak name popularity on average (for popular names) relative to the median national peak","20c8b1e3":"## (1) Name Uniqueness (1880-2017)\n\\*Comparing the avg. number of times a name was given to a child, annually (1880-2017)\n\n*(Higher values indicate greater conformity in naming, while lower values indicate greater uniqueness)*\n\n\\**Interactive:* scroll over points to view year & count","05419d73":"### Findings:\n(1) **Major spike in name conformity** levels in the middle of the 20th century\n\n\\*Peak year was 1957 (in which names averaged 358 counts)\n\n(2) Curiously **clean bell curve** over data spanning an entire century!","c7b062e1":"## Closing Remark:\n(1) Plotting the data geographically seems to be the most impactful, when possible. Since Altair is not yet fully functional in this regard, Plotly will probably be my go-to library for this."}}