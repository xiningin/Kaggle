{"cell_type":{"b003f012":"code","58dc26cd":"code","5fd0a4fa":"code","81680912":"code","a4e675af":"code","cc4520a6":"code","72330f8d":"code","900eaba3":"code","7f2a7aa9":"code","c0efd204":"code","4069f5d6":"code","a2d91fd8":"code","02932859":"code","857af5b9":"code","5887a25a":"code","fb6a8732":"code","0bd1476f":"code","df359bbb":"code","5a615f1e":"code","a3598d10":"code","71dab156":"code","d50722c1":"code","cf2f4c7f":"code","f2de1e8b":"code","70a9a6f4":"code","bed382c6":"code","4e997bb6":"code","7bbf49dd":"code","f901aa9f":"code","80cc29f5":"code","baf71d13":"code","9431defa":"code","bd16f8d7":"code","040b877c":"code","50bfdb95":"code","88fffe84":"code","7f5289bc":"code","41013bdf":"code","5972590e":"code","e12d3438":"code","4aed7395":"code","498fc7d3":"code","11165e9b":"markdown","4f7aaf6f":"markdown","ccad6aef":"markdown","4d5dd3a1":"markdown","583b7a44":"markdown","e86aa96d":"markdown","8047957e":"markdown","21c479bc":"markdown","f01e953b":"markdown","3e424e5a":"markdown","c921d933":"markdown","5f863952":"markdown","27d9d1c8":"markdown","23d754a6":"markdown","8e8b2fa8":"markdown","ad92344b":"markdown","e58a0f75":"markdown","fae3e03d":"markdown","edb88cb7":"markdown","fdf164d3":"markdown","2565c672":"markdown","9b1c0b13":"markdown","68f01b1c":"markdown","baf552a1":"markdown","128330fc":"markdown","38e4087e":"markdown","c0e27b4b":"markdown","21ba6df1":"markdown","bb8aa0a2":"markdown","ca77a00e":"markdown","7e1ebfee":"markdown","6d0ca274":"markdown","a61724a2":"markdown","b5bacea7":"markdown","e94788ab":"markdown","c9c95967":"markdown","da542c07":"markdown"},"source":{"b003f012":"import pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport missingno as msno\nimport category_encoders as ce\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom plotly.subplots import make_subplots\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline","58dc26cd":"df = pd.read_csv('..\/input\/churn-modelling\/Churn_Modelling.csv')\ndf.head()","5fd0a4fa":"df.shape","81680912":"df.info()","a4e675af":"msno.matrix(df)","cc4520a6":"df = df.drop(columns=['RowNumber', 'CustomerId'])","72330f8d":"df['Surname'].nunique()","900eaba3":"df.describe()","7f2a7aa9":"df.describe(include='object')","c0efd204":"fig = px.histogram(df, x='Exited',\n                   height=400, width=500,\n                   title='Target Feature Distribution')\nfig.update_xaxes(type='category')\nfig.show()","4069f5d6":"df['Exited'].value_counts(normalize=True)*100","a2d91fd8":"fig = make_subplots(rows=2, cols=3)\n\nfig.append_trace(go.Histogram(\n    x=df['CreditScore'], name='Credit Score', nbinsx=50\n), row=1, col=1)\nfig.update_xaxes(title_text='Credit Score', row=1, col=1)\n\nfig.append_trace(go.Histogram(\n    x=df['Age'], name='Age', nbinsx=30\n), row=1, col=2)\nfig.update_xaxes(title_text='Age', row=1, col=2)\n\nfig.append_trace(go.Histogram(\n    x=df['Balance'], name='Balance', nbinsx=20\n), row=1, col=3)\nfig.update_xaxes(title_text='Balance', row=1, col=3)\n\nfor col, feature in enumerate(['Tenure', 'EstimatedSalary']):\n    fig.append_trace(go.Histogram(\n        x=df[feature], name=feature,\n        nbinsx=20\n    ), row=2, col=col+1)\n    fig.update_xaxes(title_text=feature, row=2, col=col+1)\n\nfig.update_layout(\n    height=700, width=1200, \n    title_text='Features Distribution with Histogram'\n)\nfig.show()","02932859":"print('Customer dengan Balance 0:',len(df[df['Balance']==0]))","857af5b9":"fig = px.histogram(\n    df, x='CreditScore', color='Exited',\n    marginal='box', nbins=50,\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barmode='overlay'\n)\n\nfig.update_layout(\n    height=500, width=800, \n    title_text='Credit Score Feature in Detail'\n)\nfig.show()","5887a25a":"fig = px.histogram(\n    df, x='Age', color='Exited',\n    marginal='box', nbins=30,\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barmode='overlay'\n)\n\nfig.update_layout(height=500, width=800, \n                  title_text='Age Feature in Detail')\nfig.show()","fb6a8732":"fig = px.histogram(\n    df, x='Balance', color='Exited',\n    marginal='box', nbins=20,\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barmode='overlay'\n)\n\nfig.update_layout(height=500, width=800, \n                  title_text='Balance Feature in Detail')\nfig.show()","0bd1476f":"fig = px.histogram(\n    df, x='Tenure', color='Exited', marginal='box',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barmode='overlay'\n)\nfig.update_layout(height=500, width=800, \n                  title_text='Tenure Feature in Detail')\nfig.show()","df359bbb":"fig = px.histogram(\n    df, x='Tenure', color='Exited',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    category_orders={'Tenure': [0,1,2,3,4,5,6,7,8,9,10]},\n    barnorm='percent'\n)\n\nfig.update_layout(\n    height=500, width=800, \n    title_text='Tenure Feature in Detail',\n    yaxis_title='Percentage of Churn',\n    yaxis={'ticksuffix':'%'}\n)\nfig.update_xaxes(type='category')\nfig.show()","5a615f1e":"fig = px.histogram(\n    df, x='EstimatedSalary', color='Exited', marginal='box',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barmode='overlay', nbins=20\n)\n\nfig.update_layout(height=500, width=800, \n                  title_text='EstimatedSalary Feature in Detail')\nfig.show()","a3598d10":"fig = make_subplots(rows=2, cols=3)\n\n# For loop for the first row\nfor col, feature in enumerate(['NumOfProducts', 'HasCrCard', 'IsActiveMember']):\n    fig.append_trace(go.Histogram(\n        x=df[feature], name=feature,\n    ), row=1, col=col+1)\n    fig.update_xaxes(title_text=feature, row=1, col=col+1)\n\n# For loop for the second row\nfor col, feature in enumerate(['Geography', 'Gender']):\n    fig.append_trace(go.Histogram(\n        x=df[feature], name=feature,\n    ), row=2, col=col+1)\n    fig.update_xaxes(title_text=feature, row=2, col=col+1)\n\nfig.update_xaxes(type='category', \n                 categoryorder='category ascending')\nfig.update_layout(height=700, width=1200, \n                  title_text='Categorical Features Distribution')\nfig.show()","71dab156":"fig = px.histogram(\n    df, x='NumOfProducts', color='Exited',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barnorm='percent'\n)\nfig.update_layout(\n    height=500, width=800, \n    title_text='NumOfProducts Feature in Detail',\n    yaxis_title='Percentage of Churn',\n    yaxis={'ticksuffix':'%'}\n)\nfig.update_xaxes(\n    type='category',\n    categoryorder='category ascending'\n)\nfig.show()","d50722c1":"fig = px.histogram(\n    df, x='HasCrCard', color='Exited',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barnorm='percent'\n)\nfig.update_layout(height=500, width=800, \n                  title_text='HasCrCard Feature in Detail',\n                  yaxis_title='Percentage of Churn',\n                  yaxis={'ticksuffix':'%'})\nfig.update_xaxes(\n    type='category',\n    categoryorder='category ascending'\n)\nfig.show()","cf2f4c7f":"fig = px.histogram(\n    df, x='IsActiveMember', color='Exited',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'},\n    barnorm='percent'\n)\nfig.update_layout(height=500, width=800, \n                  title_text='IsActiveMember Feature in Detail',\n                  yaxis_title='Percentage of Churn',\n                  yaxis={'ticksuffix':'%'})\nfig.update_xaxes(\n    type='category',\n    categoryorder='category ascending'\n)\nfig.show()","f2de1e8b":"fig = px.histogram(\n    df, x='Geography', color='Exited',\n    barnorm='percent',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'}\n)\nfig.update_yaxes(title_text='Percentage of Churn')\nfig.update_layout(height=500, width=800, \n                  title_text='Exited Percentage by Geography',\n                  yaxis={'ticksuffix':'%'})\nfig.show()","70a9a6f4":"fig = px.histogram(\n    df, x='Gender', color='Exited',\n    barnorm='percent',\n    color_discrete_map={0: '#636EFA', 1: '#EF553B'}\n)\nfig.update_yaxes(title_text='Percent')\n\nfig.update_layout(height=500, width=800, \n                  title_text='Exited Percentage by Gender',\n                  yaxis={'ticksuffix':'%'})\nfig.show()","bed382c6":"encoder = ce.TargetEncoder()\ndf_temp = encoder.fit_transform(df.drop(columns='Exited'), df['Exited'])\ndf_corr = df_temp.join(df['Exited']).corr()\n\nfig = ff.create_annotated_heatmap(\n    z=df_corr.values,\n    x=list(df_corr.columns),\n    y=list(df_corr.index),\n    annotation_text=df_corr.round(2).values,\n    showscale=True, colorscale='Viridis'\n)\nfig.update_layout(height=600, width=800, \n                  title_text='Feature Correlation')\nfig.update_xaxes(side='bottom')\nfig.show()","4e997bb6":"df['BalanceToSalaryRatio'] = df['Balance'] \/ df['EstimatedSalary']","7bbf49dd":"from itertools import combinations\ncat_cols = df.select_dtypes('object').columns\n\nfor col in combinations(cat_cols, 2):\n    df[col[0]+'_'+col[1]] = df[col[0]] + \"_\" + df[col[1]]\n    \ndf.head()","f901aa9f":"df.describe(include='object')","80cc29f5":"encoder = ce.TargetEncoder()\ndf_temp = encoder.fit_transform(df.drop(columns='Exited'), df['Exited'])\ndf_corr = df_temp.join(df['Exited']).corr()\n\nfig = ff.create_annotated_heatmap(\n    z=df_corr.values,\n    x=list(df_corr.columns),\n    y=list(df_corr.index),\n    annotation_text=df_corr.round(2).values,\n    showscale=True, colorscale='Viridis'\n)\nfig.update_layout(height=700, width=900, \n                  title_text='Feature Correlation')\nfig.update_xaxes(side='bottom')\nfig.show()","baf71d13":"df.head()","9431defa":"df.describe(include='object')","bd16f8d7":"X_train, X_test, y_train, y_test = train_test_split(\n    df.drop(columns='Exited'), df['Exited'],\n    test_size=0.2, random_state=0,\n)","040b877c":"# Ratio using for scale_pos_weight to get better recall on imbalance class\nratio = float(np.sum(y_train == 0)) \/ np.sum(y_train == 1)","50bfdb95":"xgb_pipeline = Pipeline([\n    ('one_hot', ce.OneHotEncoder(cols=['Geography', 'Gender', 'Geography_Gender'])),\n    ('catboost', ce.CatBoostEncoder(cols=['Surname', 'Surname_Geography', 'Surname_Gender'])),\n    ('xgb', XGBClassifier(scale_pos_weight=ratio))\n])","88fffe84":"lgb_pipeline = Pipeline([\n    ('one_hot', ce.OneHotEncoder(cols=['Geography', 'Gender', 'Geography_Gender'])),\n    ('catboost', ce.CatBoostEncoder(cols=['Surname', 'Surname_Geography', 'Surname_Gender'])),\n    ('lgb', LGBMClassifier(scale_pos_weight=ratio))\n])","7f5289bc":"cat_pipeline = Pipeline([\n    ('one_hot', ce.OneHotEncoder(cols=['Geography', 'Gender', 'Geography_Gender'])),\n    ('catboost', ce.CatBoostEncoder(cols=['Surname', 'Surname_Geography', 'Surname_Gender'])),\n    ('cat', CatBoostClassifier(scale_pos_weight=ratio, verbose=0))\n])","41013bdf":"import numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n    normalize:     If True, show the proportions for each category. Default is True.\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n    xyticks:       If True, show x and y ticks. Default is True.\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                   \n    title:         Title for the heatmap. Default is None.\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()\/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nPrecision={:0.3f} | Recall={:0.3f}\\nAccuracy={:0.3f} | F1 Score={:0.3f}\".format(\n                precision, recall, accuracy, f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    plt.subplot(1,2,1)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)\n\n\ndef model_eval(model, X_train, y_train, \n               scoring_='roc_auc', cv_=5):\n  \n    model.fit(X_train, y_train)\n\n    train_pred = model.predict(X_train)\n    train_predprob = model.predict_proba(X_train)[:,1]\n           \n    cv_score = cross_val_score(model, X_train, y_train, cv=cv_, scoring=scoring_)\n    print('Model Report on Train and CV Set:')\n    print('--------')\n    print('Train Accuracy: {:0.6f}'.format(metrics.accuracy_score(y_train, train_pred)))\n    print('Train AUC Score: {:0.6f}'.format(metrics.roc_auc_score(y_train, train_predprob)))\n    print('CV AUC Score: Mean - {:0.6f} | Std - {:0.6f} | Min - {:0.6f} | Max - {:0.6f} \\n'.format(\n        np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n\n\n\ndef test_eval(model, X_train, X_test, y_train, y_test):\n    \n    model.fit(X_train, y_train)\n\n    pred = model.predict(X_test)\n    predprob = model.predict_proba(X_test)[:,1]\n    \n    print('Model Report on Test Set:')\n    print('--------')\n    print('Classification Report \\n', metrics.classification_report(y_test, pred))\n\n    conf = metrics.confusion_matrix(y_test, pred)\n    group_names = ['True Negative', 'False Positive', 'False Negtive', 'True Positive']\n    make_confusion_matrix(conf, percent=False, group_names=group_names,\n                          figsize=(14,5), title='Confusion Matrix')\n\n    plt.subplot(1,2,2)\n    fpr, tpr, _ = metrics.roc_curve(y_test, predprob)\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve\\nAUC Score: {:0.3f}'.format(metrics.roc_auc_score(y_test, predprob)))\n    plt.legend()","5972590e":"test_eval(xgb_pipeline, X_train, X_test, y_train, y_test)","e12d3438":"test_eval(lgb_pipeline, X_train, X_test, y_train, y_test)","4aed7395":"test_eval(cat_pipeline, X_train, X_test, y_train, y_test)","498fc7d3":"cat_features = df.select_dtypes('object').columns\n\ncat = CatBoostClassifier(scale_pos_weight=ratio,\n                         verbose=0, cat_features=cat_features)\ntest_eval(cat, X_train, X_test, y_train, y_test)","11165e9b":"There is no significant difference in this feature. Both categories have the same churn rate.","4f7aaf6f":"* Credit Score has a fairly normal distribution but there is an anomaly in customers with a credit score of 840 to 859, which is quite high compared to the previous range.\n* Age has the right-skewed distribution with the largest number of customers in the 35 to 29 year age segment (2308 people)\n* Balance has a normal distribution but there is an anomaly in the Balance with a value of 0 with a total of 3617 people.\n* Tenure and EstimatedSalary have a uniform distribution","ccad6aef":"Customers from Germany have a churn rate of 32.4%, while customers from France are 16.2% and Spain 16.7%.","4d5dd3a1":"#### XGBoost","583b7a44":"Female customers have a higher churn rate (25%) than male customers (16.5%).","e86aa96d":"### Building Pipeline","8047957e":"#### LightGBM","21c479bc":"### Numerical Features","f01e953b":"After performing feature engineering we get a new feature with a higher correlation with the target.","3e424e5a":"#### CatBoost","c921d933":"### Target Feature","5f863952":"For the Surname column, we'll save it first because it might work. <br>\nAssuming the same family has a similar Churn probability.","27d9d1c8":"## Modeling","23d754a6":"The best model is CatBoost (built in categorical encoder) with ROC AUC Score 0.874, and Recall rate 0.76 on positive class.\n\nI will update this notebook with a model after hyperparamete tuning.","8e8b2fa8":"## Visualization","ad92344b":"### Heatmap Correlation","e58a0f75":"Both classes in the Tenure feature have the same distribution and both have no outliers.","fae3e03d":"### Categorical Features","edb88cb7":"Customers with class 0 in the Age feature have a right-skew distribution while those for class 1 have a normal distribution. There are several outliers in class 1 and quite a number of outliers in class 0.\n\nWhen viewed from the median, customers with old age have a higher tendency to churn.","fdf164d3":"The two classes in the EstimatedSalary feature have a uniform distribution, with a slightly higher median value in class 1.","2565c672":"The target distribution on the dataset is unbalanced. But this is normal because this is a customer churn dataset.\n\nIn terms of the dataset, it can be said to be good because there are enough positive classes so that the model will be easier to detect positive class. <br>\nHowever, from a business perspective, it is not good because the Churn rate is quite high.\n\nBecause of this we will use the AUC ROC metric at the modeling stage with focus in higher recall on positive class.","9b1c0b13":"From categories 1 and 2 with the highest number of customers, we can see that customers who only have 1 product have a higher churn rate (27.7%).\n\nMeanwhile, customers with 3 products had a churn rate of 82.7% and the most were customers with 4 products that had a churn rate of 100%.","68f01b1c":"We are removing the first 2 columns because we don't need them for prediction.","baf552a1":"Inactive customers have a higher churn rate with a portion of 26.8% compared to active customers (14.2%).","128330fc":"Customers with class 0 and 1 on the Credit Score feature both have a normal distribution with the anomaly on the right. <br>\nFor class 1 there are several outliers on the left.\n\nThere is a median difference between the two classes but not significant. The median for class 1 is slightly lower. In other words, customers with a low credit score have a higher (but not significant) churn rate.","38e4087e":"### Feature Enginering","c0e27b4b":"There is no significant difference between the churn and the average level is 20%. <br>\nCustomers with a 7 year Tenure had the lowest churn rate (17.2%).","21ba6df1":"Both classes have the same distribution with the anomaly at Balance 0. There are no outliers.\n\nRegardless of the anomaly, the two distributions appear to have the same median. However, due to the anomaly at value 0, the median for class 0 is lower because at value 0 there are more class 0 compared to class 1.","bb8aa0a2":"## Statistic Summary","ca77a00e":"The highest correlation to Target is the Surname feature (0.36), and the second is the Age feature with a value of 0.29.\n\nThe insights that can be obtained from this data are:\n* Customers with higher Age have a higher churn rate\n* There are family names (Surname) whose churn level is higher","7e1ebfee":"Confusion Matrix function credit to [DTrimarchi10](https:\/\/github.com\/DTrimarchi10\/confusion_matrix)","6d0ca274":"### Train Test Split","a61724a2":"## Data Preprocessing","b5bacea7":"Our data is clean and there is no missing value.","e94788ab":"* Our dataset is dominated by customers who have 1 and 2 products. The intensity of customers who have 3 and 4 products is only a few.\n* Customers who have more credit cards (more than 2 times than those who do not)\n* There are quite a lot of inactive members, almost equal to active members.\n* There are far more customers from France than customers from Germany and Spain.\n* There are more male customers","c9c95967":"#### CatBoost (built in categorical encoder)","da542c07":"# Data Exploration"}}