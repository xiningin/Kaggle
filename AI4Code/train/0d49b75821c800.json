{"cell_type":{"908f021b":"code","dedefed3":"code","b217ce2b":"code","0ababf9e":"code","4bc29e1d":"code","0bd4cbd4":"code","ef4a3892":"code","5a4f7324":"code","4509613e":"code","0a937984":"code","7e7eb44e":"code","9aefe22a":"code","fe0bd0cd":"code","d5cf98fc":"code","07aae875":"code","de0dc3c5":"code","70b292ab":"code","982d3b21":"code","b87ddf68":"code","2d64ad7d":"code","87840acd":"code","a142f9f0":"code","f44b6c58":"code","1e77116a":"code","40d83583":"code","b7e163a1":"code","22bd259c":"markdown","2b62c6dd":"markdown","5cd78a53":"markdown","6119e2cc":"markdown","86324ce8":"markdown","d6e944ef":"markdown","d3df053d":"markdown","fefeb478":"markdown","1d3e2f11":"markdown","821d1801":"markdown","0bd9e38d":"markdown"},"source":{"908f021b":"import datetime as dt\nimport numpy as np\nimport pandas as pd\n\nimport itertools\nimport keras\nfrom sklearn import metrics\n\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \nfrom keras import optimizers\nfrom keras.preprocessing import image \n\nimport math  \nimport datetime\nimport time\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\n\nimport os\nimport keras.applications \nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport cv2\nfrom scipy.stats import uniform\n\nfrom tqdm import tqdm\nfrom glob import glob\n\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking, Flatten\nfrom keras.utils import np_utils, to_categorical\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","dedefed3":"#copying the pretrained models to the cache directory\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n\n#copy the Xception models\n!cp ..\/input\/keras-pretrained-models\/xception* ~\/.keras\/models\/\n#show\n!ls ~\/.keras\/models","b217ce2b":"base_folder = '..\/input\/fire-dataset'\ndata_folder = '..\/input\/fire-dataset\/fire_dataset'\n#train_data_folder = '..\/input\/fire-dataset\/fire_dataset\/fire_images'\ntest_folder  = '..\/input\/custom_fire'\n\ncategories = ['fire_images', 'non_fire_images']\nlen_categories = len(categories)","0ababf9e":"image_count = {}\ntrain_data = []\ntest_data = []\n\n\n\nfor i , category in tqdm(enumerate(categories)):\n    class_folder = os.path.join(data_folder, category)\n    label = category\n    image_count[category] = []\n    \n    for path in os.listdir(os.path.join(class_folder)):\n        image_count[category].append(category)\n        train_data.append(['{}\/{}'.format(category, path), i, category])","4bc29e1d":"#show image count\nfor key, value in image_count.items():\n    print('{0} -> {1}'.format(key, len(value)))","0bd4cbd4":"#create a dataframe\ndf = pd.DataFrame(train_data, columns=['file', 'id', 'label'])\ndf.shape\ndf.head()","ef4a3892":"#masking function\ndef create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    lower_hsv = np.array([0,0,250])\n    upper_hsv = np.array([250,255,255])\n    \n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\n#image segmentation function\ndef segment_image(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\/255\n\n#sharpen the image\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp\n\n# function to get an image\ndef read_img(filepath, size):\n    img = image.load_img(os.path.join(data_folder, filepath), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img)\n    return img","5a4f7324":"nb_rows = 3\nnb_cols = 5\nfig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 5));\nplt.suptitle('SAMPLE IMAGES');\nfor i in range(0, nb_rows):\n    for j in range(0, nb_cols):\n        axs[i, j].xaxis.set_ticklabels([]);\n        axs[i, j].yaxis.set_ticklabels([]);\n        axs[i, j].imshow((read_img(df['file'][np.random.randint(1000)], (255,255)))\/255.);\nplt.show();","4509613e":"#get an image\nimg = read_img(df['file'][102],(255,255))\n#mask\nimage_mask = create_mask_for_plant(img)\n#segmentation\nimage_segmented = segment_image(img)\n#sharpen the image\nimage_sharpen = sharpen_image(image_segmented)\n\nfig, ax = plt.subplots(1, 4, figsize=(10, 5));\nplt.suptitle('SAMPLE PROCESSED IMAGE', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIG.', fontsize=12)\nax[1].set_title('MASK', fontsize=12)\nax[2].set_title('SEGMENTED', fontsize=12)\nax[3].set_title('SHARPEN', fontsize=12)\n\n\nax[0].imshow(img\/255);\nax[1].imshow(image_mask);\nax[2].imshow(image_segmented);\nax[3].imshow(image_sharpen);\n\n","0a937984":"INPUT_SIZE=255\n\n##preprocess the input\nX_train = np.zeros((len(df), INPUT_SIZE, INPUT_SIZE, df.shape[1]), dtype='float')\nfor i, file in tqdm(enumerate(df['file'])):\n    #read image\n    img = read_img(file,(INPUT_SIZE,INPUT_SIZE))\n    #masking and segmentation\n    image_segmented = segment_image(img)\n    #sharpen\n    image_sharpen = sharpen_image(image_segmented)\n    x = np.expand_dims(image_sharpen, axis=0)\n    x = xception.preprocess_input(x)\n    X_train[i] = x","7e7eb44e":"print('Train Image Shape: ', X_train.shape)\nprint('Train Image Size: ', X_train.size)","9aefe22a":"y = df['id']\ntrain_x, train_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=101)","fe0bd0cd":"print('FIRE IMAGES ON TRAINING DATA: ',y_train[y_train==0].shape[0])\nprint('NON-FIRE IMAGES ON TRAINING DATA: ',y_train[y_train==1].shape[0])","d5cf98fc":"##get the features\nxception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\nbf_train_x = xception_bf.predict(train_x, batch_size=32, verbose=1)\nbf_train_val = xception_bf.predict(train_val, batch_size=32, verbose=1)","07aae875":"#print shape of feature and size\nprint('Train Shape: ', bf_train_x.shape)\nprint('Train Size: ', bf_train_x.size)\n\nprint('Validation Shape: ', bf_train_val.shape)\nprint('Validation Size: ', bf_train_val.size)","de0dc3c5":"#keras Sequential model\nmodel = Sequential()\nmodel.add(Dense(units = 256 , activation = 'relu', input_dim=bf_train_x.shape[1]))\nmodel.add(Dense(units = 64 , activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","70b292ab":"# plot model \n!pip install pydotplus\n!pip install pydot\nimport pydotplus\nimport pydot\nfrom keras.utils import plot_model\nfrom keras.utils.vis_utils import model_to_dot\nkeras.utils.vis_utils.pydot = pydot\n\nplot_model(model, to_file='networkmodel.png', show_layer_names = True , show_shapes = True, rankdir =\"LR\")","982d3b21":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n%matplotlib inline\n\ndata, labels = bf_train_x, y_train\nopt_names = [\"adam\",\"sgd\", \"rmsprop\", \"adagrad\", \"adamax\"]\n\ndef run_optimizer(opts):\n\n    #categorcial cross entropy loss\n    ccel=[] \n    \n    for opt in opts:\n        \n        model = Sequential()\n        model.add(Dense(units = 256 , activation = 'relu', input_dim=bf_train_x.shape[1]))\n        model.add(Dense(units = 64 , activation = 'relu'))\n        model.add(Dense(units = 1, activation = 'sigmoid'))\n        model.compile(optimizer = opt, loss = 'binary_crossentropy')\n#        callbacks = [EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)]\n        model.fit(data, labels, epochs=35, batch_size=32, verbose=0)\n#        history = model.fit(bf_train_x, y_train, epochs=35, batch_size=32, validation_data = (bf_train_val , y_val), callbacks=callbacks);\n        print(model.optimizer)\n        ccel.append(model.evaluate(bf_train_val,y_val))\n\n    return ccel\n\n\nccel = run_optimizer(opt_names)\nprint(\"optimizer, loss\")\n\nfor i in range(len(opt_names)):\n    print(\"%s: %.2f\" % (opt_names[i], ccel[i]))\n\nimport numpy as np \nimport itertools\nxt = np.arange(5)\nf = plt.figure()\nf.add_subplot(1,2,1)\nplt.title(\"Default\")\nplt.bar(xt, ccel)\nplt.ylabel(\"Binary Cross Entropy Loss\")\nplt.xlabel(\"Optimizers\")\nplt.xticks(xt, ('adam','sgd', 'rmsprop', 'adagrad', 'adamax') , rotation=45)\nplt.legend()\nplt.show()\n\n","b87ddf68":"#train the model @ 50 epochs\nstart = datetime.datetime.now()\n\n# callbacks \ncallbacks = [EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)]\nhistory = model.fit(bf_train_x, y_train, epochs=50, batch_size=32, validation_data = (bf_train_val , y_val), callbacks=callbacks);\n\n(eval_loss, eval_accuracy) = model.evaluate(bf_train_val,y_val, batch_size=32, verbose=1)\n\nprint(\"[INFO] Validation accuracy: {:.2f}%\".format(eval_accuracy * 100))  \nprint(\"[INFO] Validation Loss: {}\".format(eval_loss)) \n\nend= datetime.datetime.now()\nelapsed= end-start\nprint ('Time: ', elapsed)","2d64ad7d":"\n#Graphing training and validation\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\nplt.plot(epochs, acc, color='green' , lw=1.5, label='Training accuracy')\nplt.plot(epochs, val_acc, color = 'salmon' ,lw=1.5, label='Validation accuracy')\nplt.title('Training & validation accuracy')\nplt.ylabel('accuracy')  \nplt.xlabel('epoch')\nplt.legend(loc = 'best')\nplt.figure()\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nplt.plot(epochs, loss, color='green',lw=1.5, label='Training loss')\nplt.plot(epochs, val_loss, color='salmon', lw=1.5,label='Validation loss')\nplt.title('Training & validation loss')\nplt.ylabel('loss')  \nplt.xlabel('epoch')\nplt.legend(loc='best')\nplt.show()","87840acd":"#predict the validation data\npredictions = model.predict_classes(bf_train_val)","a142f9f0":"print(predictions)\n","f44b6c58":"print(classification_report(y_val, predictions))","1e77116a":"confusion_mat = confusion_matrix(y_val, predictions)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion_mat, square=True, annot=True,\n            yticklabels=['FIRE_IMG', 'NON_FIRE_IMG'],\n            xticklabels=['FIRE_IMG', 'NON_FIRE_IMG']);\nplt.title('CONFUSION MATRIX');\nplt.xlabel('Y_TRUE');\nplt.ylabel(\"PREDICTIONS\");","40d83583":"from sklearn.metrics import roc_curve, auc\nn_classes=2\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(2):\n    fpr[i], tpr[i], _ = roc_curve(y_val,predictions)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val.ravel(), predictions.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nplt.figure()\nlw = 2\nplt.plot(fpr[1], tpr[1], color='magenta',\n         lw=lw, label='ROC curve (AOC = %0.2f)' % roc_auc[1])\nplt.plot([0, 1], [0, 1], color='cyan', lw=lw, linestyle='--' ,label='Random chances\/No skill')\nplt.xlim([0.0, 1])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","b7e163a1":"#alternative for testing images 2\n\ntest_folder  = '..\/input\/custom-fire'\npath = '11.png'\n\ndef read_test_img(filepath, size):\n    img = image.load_img(os.path.join(test_folder, path), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img)\n    return img\n\n#read image\nimg_t = read_test_img(path,(INPUT_SIZE,INPUT_SIZE))\n#masking and segmentation\nimage_segmented = segment_image(img_t)\n#sharpen\nimage_sharpen = sharpen_image(image_segmented)\nx_test = np.expand_dims(image_sharpen, axis=0)\nx_test = xception_bf.predict(x_test, batch_size=32, verbose=1)\n\n\nprediction = model.predict_classes(x_test)\nscore = prediction\nprint(\n    \"This image has %.2f percent fire and %.2f percent not.\"\n    % (100 * (1 - score), 100 * score)\n)\n\nprint('label:',score)\nload_img(os.path.join(test_folder, path))","22bd259c":"### DEEP LEARNING MODEL","2b62c6dd":"## OVERVIEW\n---\n* Image Preprocessing with OpenCV\n    * Masking\n    * Segmentation\n    * Image Sharpening\n* Transfer Learning with Keras Pretrained Model\n* Feature Extraction\n* Deep Learning Model to Classify the Images","5cd78a53":"#### CLASSIFICATION REPORT","6119e2cc":"import imblearn\nfrom imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=0)\nX_res, y_res = smote.fit_resample(X,y)\nprint('Resampled dataset shape %s' % y_res.value_counts())\n","86324ce8":"#### SPLIT THE DATA","d6e944ef":"#### CONFUSION MATRIX","d3df053d":"### IMAGE PREPROCESSING","fefeb478":"### SHOW SAMPLE IMAGES","1d3e2f11":"### XCEPTION BOTTLENECK FEATURE EXTRACTION","821d1801":"### LOSS AND ACCURACY","0bd9e38d":"### SHOW SAMPLE PROCESSED IMAGE\n"}}