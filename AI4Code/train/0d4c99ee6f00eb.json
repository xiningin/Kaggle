{"cell_type":{"f60a3206":"code","07407cef":"code","d8200f57":"code","a105a0d7":"code","37d0082b":"code","00755f1e":"code","ab386868":"code","a8089619":"code","f5cdab80":"code","411c9772":"code","14fbc04e":"code","19f48822":"code","8138d941":"code","9b803a49":"code","b5a05458":"code","f60373a0":"code","5e024859":"code","0f2f9b24":"code","b9c80a2f":"code","c865612b":"code","6659cb4b":"code","eba917de":"code","89d0937f":"code","16afa40b":"code","075babad":"code","6fafe5e6":"code","f24e0a51":"code","f3d6f6c0":"code","96f58845":"code","b64733c1":"code","5a3a1a4c":"code","0bc9227b":"code","d1fe5061":"code","563ba844":"code","40b4f3a2":"code","d68142c9":"code","32c4c67a":"code","fb3abec4":"code","42d12b9c":"code","fcbaf5ad":"code","14e5aa7f":"code","d701a3ab":"code","e4baf8ce":"code","74badea9":"code","28b35a7f":"code","57ddcef5":"code","77b4e92e":"code","6434a610":"code","bb6f8b49":"code","d38a9d11":"markdown","63cf6f0e":"markdown","fcab2adc":"markdown","d2e1e00d":"markdown","2a2d66b9":"markdown","9b552dc0":"markdown","3386e386":"markdown","59274dc7":"markdown","3e9d1e84":"markdown","03481574":"markdown","a3f020a4":"markdown","cd253145":"markdown","1904382a":"markdown","91896126":"markdown","7711eb2e":"markdown","bf87be9a":"markdown","6a6894a8":"markdown","69d34f52":"markdown","de57fc2e":"markdown","401b1808":"markdown","69806346":"markdown","1a4dd8e1":"markdown","6051ee62":"markdown"},"source":{"f60a3206":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","07407cef":"train_set =  pd.read_csv('..\/input\/train.csv')\ntrain_set.head()\n# test_set.head()","d8200f57":"train_set.dtypes","a105a0d7":"train_set.corr()","37d0082b":"train_set.describe()","00755f1e":"train_set.info()","ab386868":"train_set.isnull().sum()","a8089619":"plt_survived = train_set.Survived.value_counts().plot('bar')\nplt_survived.set_xlabel(\"Survived\")\nplt_survived.set_ylabel(\"No of passengers\")\nplt_survived.set_title(\"Survivval status of Passengers\"+\" (\"+\"Not survived - 0 and Survived - 1\"+\")\")\nfor p in plt_survived.patches:\n    plt_survived.annotate(str(p.get_height()), (p.get_x() * 1.05, p.get_height() * 1.005))","f5cdab80":"\nfig = plt.figure(figsize=(10,5))\nax = fig.add_subplot(221)\nax1 = fig.add_subplot(222)\n\nmax_value = train_set.Pclass.value_counts().values[0]\nmax_value = (int(max_value\/100)+1)*100\nplt_pclass = train_set.Pclass.value_counts().sort_index().plot(kind = 'bar', ax=ax)\nplt_pclass.set_xlabel(\"Pclass\")\nplt_pclass.set_ylabel(\"No of Passengers\")\nplt_pclass.set_title(\"Total Passengers in each PClass Category\")\n\nfor p in plt_pclass.patches:\n    plt_pclass.annotate(str(p.get_height()), (p.get_x() * 1.05, p.get_height() * 1.005))\n\n# import matplotlib.pyplot as plt\n\n\nsurvived_df = train_set.loc[train_set.Survived==1]\nsurvived_df.head()\n\n\nplt_pclass_survived = survived_df.Pclass.value_counts().sort_index().plot(kind = 'bar', ax=ax1, ylim=[0, max_value])\nplt_pclass_survived.set_xlabel(\"Pclass\")\nplt_pclass_survived.set_ylabel(\"No of Passengers\")\nplt_pclass_survived.set_title(\"Survived Passengers in each PClass Category\")\n\nfor p in plt_pclass_survived.patches:\n    plt_pclass_survived.annotate(str(p.get_height()), (p.get_x() * 1.05, p.get_height() * 1.005))","411c9772":"pclass_count = list(train_set['Pclass'].value_counts().sort_index())\nsurvived_df = train_set[train_set.Survived==1]\nsurvived_count = list(survived_df.Pclass.value_counts().sort_index())\nindex = sorted(train_set.Pclass.unique())\ndf = pd.DataFrame({'Total passengers':pclass_count,'Survived passengers':survived_count},index=index,columns=['Total passengers','Survived passengers'])\nax = df.plot.bar(rot=0)\nax.set_xlabel(\"PClass\")\nax.set_ylabel(\"Passengers count\")\nax.set_title(\"PClass wise Survival status of passengers\")\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.025, p.get_height() * 1.005))","14fbc04e":"plt = train_set[['Embarked', 'Survived']].groupby('Embarked').mean().Survived.plot('bar')\nplt.set_xlabel('Embarked')\nplt.set_ylabel('Survival Probability')\nfor p in plt.patches:\n    plt.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.025, p.get_height() * 1.005))\nplt.set_title(\"Survival probability based on the Embarked\")","19f48822":"plt = train_set[['Sex', 'Survived']].groupby('Sex').mean().Survived.plot('bar')\nfor p in plt.patches:\n    plt.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.025, p.get_height() * 1.005))\nplt.set_title(\"Survival probability based on the Gender\")","8138d941":"plt = train_set.SibSp.value_counts().sort_index().plot('bar')\nplt.set_xlabel('SibSp')\nplt.set_ylabel('Passenger count')\nfor p in plt.patches:\n    plt.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.025, p.get_height() * 1.005))","9b803a49":"plt = train_set[['SibSp', 'Survived']].groupby('SibSp').mean().Survived.plot('bar')\nplt.set_xlabel('SibSp')\nplt.set_ylabel('Survival Probability')\nfor p in plt.patches:\n    plt.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.025, p.get_height() * 1.005))\nplt.set_title(\"Survival probability based on the SibSp\")","b5a05458":"titles_list = train_set.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).tolist()\n# train_set.drop(columns=['Name'], inplace=True)\ntrain_set = train_set.drop(columns=['Name'])\nprint(train_set.columns)\ntrain_set['Title'] = titles_list\nax = train_set.Title.value_counts().plot('bar')\nax.set_title(\"Count of each Titles\")\nax.set_ylabel(\"Count\")\nax.set_xlabel(\"Title\")","f60373a0":"train_set['Title'] = train_set['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Jonkheer', 'Lady', 'Capt', 'Don'], 'Others')\ntrain_set['Title'] = train_set['Title'].replace('Ms', 'Miss')\ntrain_set['Title'] = train_set['Title'].replace('Mme', 'Mrs')\ntrain_set['Title'] = train_set['Title'].replace('Mlle', 'Miss')\nax = train_set.Title.value_counts().plot('bar')\nax.set_title(\"Count of each Titles\")\nax.set_ylabel(\"Count\")\nax.set_xlabel(\"Title\")","5e024859":"plt = train_set[['Title', 'Survived']].groupby('Title').mean().Survived.plot('bar')\nplt.set_xlabel('Title')\nplt.set_ylabel('Survival Probability')\nplt.set_title(\"Survival probability based on the Title\")\nfor p in plt.patches:\n    plt.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.025, p.get_height() * 1.005))","0f2f9b24":"X_train = train_set[train_set.columns.difference(['Survived'])]\nX_train.head()","b9c80a2f":"Y_train = train_set['Survived']\nY_train.head()","c865612b":"c = X_train.Cabin.value_counts()\nprint(\"Values: \",c.size)\ncabin_Nan = X_train.loc[ (pd.isna(X_train['Cabin'])) , 'Cabin' ].shape[0]\nprint(\"Nan :\",cabin_Nan)\nprint(X_train.shape[0])\n\n# thus 'Cabin' may not be an important feature","6659cb4b":"c = X_train.Ticket.value_counts()\nprint(\"Values: \",c.size)\nticket_Nan = X_train.loc[ (pd.isna(X_train['Ticket'])) , 'Ticket' ].shape[0]\nprint(\"Nan :\",ticket_Nan)\nprint(\"Data: \", X_train.shape[0])\nprint(\"Unique: \",len(X_train.Ticket.unique()))\n\n# thus 'Ticket' may not be an important feature","eba917de":"X_train = train_set[train_set.columns.difference(['Cabin','Ticket'])]\n# X_train['Embarked']= X_train['Embarked'].astype(\"category\").cat.codes\n# X_train['Sex']= X_train['Sex'].astype(\"category\").cat.codes\n\nX_train.head()","89d0937f":"X_train.corr()","16afa40b":"X_train = X_train[X_train.columns.difference(['Survived','PassengerId','Ticket'])]\nX_train.head()","075babad":"X_train['Sex'] = X_train['Sex'].map({'male':0, 'female':1})\nX_train['Embarked'] = X_train['Embarked'].map({'C':0, 'Q':1, 'S':2})\nX_train.head()","6fafe5e6":"Y_train.corr(X_train['Pclass'])","f24e0a51":"# X_train['Title']= X_train['Title'].astype(\"category\").cat.codes\nX_train['Title'] = X_train['Title'].map({'Master':0, 'Miss':1, 'Mr':2, 'Mrs':3, 'Others':4})\nX_train.head()","f3d6f6c0":"X_train.isna().any()","96f58845":"X_train.Age.isna().sum()","b64733c1":"X_train['Age'] = X_train['Age'].fillna(X_train['Age'].mean())\nX_train.isna().sum()\n","5a3a1a4c":"X_train['Embarked'] = X_train['Embarked'].fillna(X_train['Embarked'].max())\nX_train.isna().sum()\n","0bc9227b":"test_set =  pd.read_csv('..\/input\/test.csv')","d1fe5061":"test_set.isnull().sum()","563ba844":"test_set = test_set.drop(columns=['Ticket', 'PassengerId', 'Cabin'])","40b4f3a2":"test_set['Title'] = test_set.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_set = test_set.drop(columns='Name')\n\ntest_set['Title'] = test_set['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Jonkheer', 'Lady', 'Capt', 'Don'], 'Others')\ntest_set['Title'] = test_set['Title'].replace('Ms', 'Miss')\ntest_set['Title'] = test_set['Title'].replace('Mme', 'Mrs')\ntest_set['Title'] = test_set['Title'].replace('Mlle', 'Miss')\n\ntest_set['Title'] = test_set['Title'].map({'Master':0, 'Miss':1, 'Mr':2, 'Mrs':3, 'Others':4})\ntest_set.head()\n","d68142c9":"test_set['Age'] = train_set['Age'].fillna(test_set['Age'].mean())\ntest_set.head()","32c4c67a":"test_set.isna().sum()","fb3abec4":"test_set['Fare'] = test_set.Fare.fillna(train_set.Fare.mean())","42d12b9c":"row = test_set[test_set['Title'].isnull()].index\nsex = test_set.iloc[row].Sex.values[0]\nif sex == 'female':\n    test_set['Title'].iloc[row] = 3\nelse:\n    test_set['Title'].iloc[row] = 2\ntest_set[\"Title\"] = test_set['Title'].astype('int64')\ntest_set.isna().sum()","fcbaf5ad":"test_set.head()","14e5aa7f":"test_set['Sex'] = test_set['Sex'].map({'male':0, 'female':1})\ntest_set['Embarked'] = test_set['Embarked'].map({'C':0, 'Q':1, 'S':2})\ntest_set.head()","d701a3ab":"test_cols = sorted(test_set.columns.tolist())\nprint(test_cols)\ntrain_cols = sorted(X_train.columns.tolist())\nprint(train_cols)","e4baf8ce":"X_train.isna().sum()","74badea9":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam","28b35a7f":"X = X_train.values\nY = Y_train.values\nX.shape","57ddcef5":"model = Sequential()\nmodel.add(Dense(15, input_dim=8, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nsgd = Adam(lr=0.01)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])","77b4e92e":"history = model.fit(X, Y, validation_split=0.1, epochs=88, batch_size=10)","6434a610":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","bb6f8b49":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\nX, x, Y, y = train_test_split(X_train, Y_train, test_size=0.1, random_state=1) # 90% training and 10% test\n\n\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\nclf = clf.fit(X,Y)\n\n#Predict the response for test dataset\ny_pred = clf.predict(x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y, y_pred))","d38a9d11":"**Analysis** : \n\n* As we can see, people with 1 or 2 siblings or spouses have higher probability of suriving.\n\n* Also, the survival probabilities for the people with 4-8 siblings or spouses are bitterly low.","63cf6f0e":"> ### **Survival probability based on the Gender**","fcab2adc":"### **Extracting 'Title' from the name as a new feature**","d2e1e00d":"### **Survivval status of the Passengers**","2a2d66b9":"**Analysis** :  Thus the survival probability is in the order: **C>Q>S**","9b552dc0":"<ul>**Analysis** : <p>\n    <li><b>Age<\/b>, <b>Cabin<\/b> and <b>Embarked<\/b> have the above number of null values.<\/li> \n        <li><b>Cabin<\/b> has almost 77% of the values to be null and thus there is no point in imputing them. So we can remove <b>Cabin<\/b>.<\/li>\n    <li>We neeed to impute the missing values of <b>Age<\/b> and <b>Embarked<\/b>.<\/li>\n    <li><b>Ticket<\/b> and <b>PassengerId<\/b> intuitively don't contribute to the target <b>Survived<\/b>. Hence they can be removed.<\/li>\n    <li>We can retrieve special attributes like designition or gender (basically <b>Title<\/b>) from the titles given as part of <b>Names<\/b>. So we can extract the title from the name and create a column like <b>Title<\/b> to put the title.<\/li>\n    <\/ul>","3386e386":"**Analysis** : About 63% of PClass 1, 47% of PClass 2 and 24% of PClass 3 are survived.","59274dc7":"### **Creating Training Set**","3e9d1e84":"# Titanic Dataset Analysis","03481574":"### **Survival probability based on the PClass**","a3f020a4":"**Analysis** : As done for the train data, first we shall drop <b>PassengerId<\/b>, <b>Ticket<\/b> and <b>Cabin<\/b>.","cd253145":"**Analysis** : Encoding <b>Sex<\/b> and <b>Embarked<\/b> with numerical values:","1904382a":"**Analysis** : Thus, Females have higher Survival probability.","91896126":"## Preprocessing Test Data","7711eb2e":"This means <b>Age<\/b>, <b>Cabin<\/b> and <b>Embarked<\/b> have some null values.","bf87be9a":"**Analysis** : Now, let us move on to imputing the missing values.","6a6894a8":"**Analysis** : \nIn accordance with the higher survival probability of females, the survival probability of people with 'Mrs' and 'Miss' are higher.","69d34f52":"##### **Filling Null Values**","de57fc2e":"##### **Converting 'Sex' and 'Embarked' from categorical to numerical data types**","401b1808":"### **Survival probability based on the No of Siblings or Spouses(SibSp)**","69806346":"### **Survival probability based on the Title**","1a4dd8e1":"### **Survival probability based on the Embarked**","6051ee62":"** Analysis: **\n- As the epochs are increasing, the training accuracy becomes constant after 40 of epochs.\n- Accuracy is inversely proportional to loss."}}