{"cell_type":{"8a60e8b4":"code","595a9876":"code","8bd4b2a5":"code","7b191d1c":"code","3ea7f4af":"code","3a768b49":"code","1a7c8062":"code","13c81b30":"code","6bbe7341":"code","93b51f3c":"code","1131705e":"code","69c0bec2":"code","13bfb0b1":"code","c4af4c83":"code","58dfc486":"code","c2177fc0":"code","962da5dc":"code","e48ad7df":"code","bec9ac6d":"code","85b489a9":"code","e4614521":"code","afac44fb":"code","42939036":"code","40c441aa":"code","598f4a82":"code","6e1e83cf":"code","da22575e":"code","f39f36d0":"code","26e8bca9":"code","55a79d33":"code","d15f7856":"code","2162194d":"code","8f7cd937":"code","e40ea668":"code","9bf4c796":"code","dc7c7a29":"code","da907125":"code","16e990b4":"code","849b843a":"code","64409f7e":"code","189aebcc":"code","090ec6f4":"code","08bacc93":"code","e77849ca":"code","725ae107":"code","eea98294":"code","eaa187fb":"code","9ae683b6":"markdown","1ffb127b":"markdown","d1a84b39":"markdown","f10204a1":"markdown","a7d6d52e":"markdown","91874b86":"markdown","6de9b8cb":"markdown","d32f0edd":"markdown","b11fa451":"markdown","8b833936":"markdown","398862bf":"markdown","aa462e00":"markdown","aa44565a":"markdown","1ada9a33":"markdown","dc85322b":"markdown","fca402b3":"markdown","178467b1":"markdown","176a60cc":"markdown","26ada6aa":"markdown","a05286d6":"markdown","29cde5cb":"markdown","922cd78e":"markdown","43476b93":"markdown","4bdf0ef1":"markdown","20067c1e":"markdown","099d1365":"markdown","3f48d1a5":"markdown","155e48a7":"markdown","bae3eeb6":"markdown","d9a428f0":"markdown","2c432d63":"markdown","229c691e":"markdown","4a2fe528":"markdown","28b0c7e4":"markdown"},"source":{"8a60e8b4":"# Data Analysis libraries\n\nimport pandas as pd\nimport numpy as np\n\n# Data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","595a9876":"# Read the data into dataframes\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","8bd4b2a5":"# Combine train and test data\n\ncombine = [train, test]\ntrain.head()","7b191d1c":"# Glance the data\ntrain.describe(include='all')","3ea7f4af":"# List the columns\n\ntrain.columns.values","3a768b49":"# Data info\ntrain.info()\nprint('+-'*20)\ntest.info()","1a7c8062":"# Check for nulls\nprint(pd.isnull(train).sum())","13c81b30":"# Bar plot - Sex vs Survived\nsns.barplot(x=\"Sex\", y=\"Survived\", data= train)\n\n# Printing percentages\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)","6bbe7341":"# Barplot PClass vs Survived\nsns.barplot(x=\"Pclass\", y= \"Survived\", data=train)\n\n#Printing percentages\ntrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)","93b51f3c":"#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\n# Printing Percentages\ntrain[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)","1131705e":"#draw a bar plot for Parch vs. survival\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()\n\ntrain[[\"Parch\",\"Survived\"]].groupby(['Parch'],as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","69c0bec2":"print(train.columns.values)","13bfb0b1":"# We want to extract the designation of names from the combined data set.\ncombine = [train, test]\n\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","c4af4c83":"# Replace the titles with groups\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n","58dfc486":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).sum()    ","c2177fc0":"#map each of the title groups to a numerical value\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","962da5dc":"print(pd.isnull(train).sum())","e48ad7df":"train[\"Age\"] = train[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n# Plot age vs survival\n\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","bec9ac6d":"#draw a bar plot for Parch vs. survival\n\ntrain[\"Cabin_value\"]= pd.notnull(train.loc[:,'Cabin']).astype(int)\nprint(train.columns.values)                             \n\ntest[\"Cabin_value\"]= pd.notnull(test.loc[:,'Cabin']).astype(int)\nprint(test.columns.values) ","85b489a9":"pd.crosstab(train['Cabin_value'], train['Pclass'])","e4614521":"pd.crosstab(train['Cabin_value'], train['Survived'])","afac44fb":"sns.barplot(x=\"Cabin_value\", y=\"Survived\", data=train)\nplt.show()\n\ntrain[[\"Cabin_value\",\"Survived\"]].groupby(['Cabin_value'],as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","42939036":"# See the test data\ntest.describe(include = \"all\")","40c441aa":"# Check for nulls\nprint(pd.isnull(train).sum())","598f4a82":"# Map age to a numerical value and drop the age feature\ncombine = [train, test]\n\ntitle_mapping = {\"Unknown\": 0, \"Baby\": 1, \"Child\": 2, \"Teenager\": 3, \"Student\": 4, \"Young Adult\": 5, \"Adult\": 6, \"Senior\":7}\nfor dataset in combine:\n    dataset['AgeGroup'] = dataset['AgeGroup'].map(title_mapping)\n    dataset['AgeGroup'] = dataset['AgeGroup'].fillna(0)\n\ntrain.head()","6e1e83cf":"# Map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_mapping)\ntest['Sex'] = test['Sex'].map(sex_mapping)\n\ntrain.head()","da22575e":"combine = [train, test]\n\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","f39f36d0":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","26e8bca9":"# fiilling with most occuring value through mode\n\nfreq_port = train.Embarked.dropna().mode()[0]\nfreq_port","55a79d33":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","d15f7856":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","2162194d":"print(train.columns.values)","8f7cd937":"train = train.drop([\"PassengerId\",\"Name\",\"Age\",\"Ticket\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\"], axis=1)","e40ea668":"test = test.drop([\"Name\",\"Age\",\"Ticket\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\"], axis=1)","9bf4c796":"print(train.columns.values)\nprint(test.columns.values)","dc7c7a29":"print(train.info())\nprint('+-'*20)\nprint(test.info())","da907125":"test.head()","16e990b4":"X_train = train.drop(\"Survived\", axis=1)\ny_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, y_train.shape, X_test.shape","849b843a":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nacc_log","64409f7e":"# Support Vector Machines\nfrom sklearn.svm import SVC, LinearSVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nacc_linear_svc = round(svc.score(X_train, y_train) * 100, 2)\nacc_linear_svc","189aebcc":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, y_train) * 100, 2)\nacc_knn","090ec6f4":"from sklearn.naive_bayes import GaussianNB\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nacc_gaussian","08bacc93":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\ny_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\nacc_decision_tree","e77849ca":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nacc_random_forest","725ae107":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_linear_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","eea98294":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })","eaa187fb":"submission.to_csv('titanic.csv', index=False)","9ae683b6":"As predicted, higher the class, higher the survival rate. We need to have this feature in our predictions.","1ffb127b":"### Support Vector Machines","d1a84b39":"- Total number of passengers is 891.\n- Age is missing for ~19.8% of the records. We may want to fill the gaps as age is an important feature.\n- Cabin feature missing for ~ 77% of records, this might be because only specific passengers have cabins allocated to them.\n- Embarked feature is missing for a small % which is okay.\n- Children may have greater chances of survival\n- Women may have greater chances of survival\n- Passengers in 1st class can have greater chances of survival","f10204a1":"### KNeighbours","a7d6d52e":"## Title Feature","91874b86":"> This is a beginner version of titanic disaster ML competition. I have referred to several notebooks on kaggle that helped beginners like me to work on this problem.","6de9b8cb":"we can see that surival rate is higher with non-blank cabin field.","d32f0edd":"## Sex Feature","b11fa451":"Before we drop the features, lets clean the data y filling nulls with data. This has to be done for\n- Age\n- Embarked ","8b833936":" The following features can be dropped\n - Passenger ID\n - Pasenger Name( as we extracted the designations)\n - Age (as we took age group)\n - Ticket\n - Cabin (as we took cabin value)","398862bf":"### Logistic Regression","aa462e00":"## Some observations and Predictions","aa44565a":"# Data Cleansing","1ada9a33":"## Sibsp Feature","dc85322b":"## Modelling","fca402b3":"### Decision Tree","178467b1":"## Cabin Feature","176a60cc":"## New feature for family size","26ada6aa":"We can conclude that \"Babies\" have more chance of survival.","a05286d6":"## Missing Embarked feature","29cde5cb":"As predicted, chances of survival for females is greater than males. We need to have this feature in our predictions.","922cd78e":"# Data Visualization","43476b93":"## Parch feature ","4bdf0ef1":"### Gaussian NB","20067c1e":"# Read and explore your input data","099d1365":"# Import required libraries","3f48d1a5":"We can try and use titles as a factor for age filling\n - Mr. title for \"Adult\"\n - Miss. title for \"Youth\"\n - Mrs. title for \"Adult\"\n - Master title for \"Baby\"\n - Royal title for \"Adult\"\n - Rare title for \"Adult\"\n","155e48a7":" - Numerical features - Passenger ID, Age, Fare, \n - Categorical features - Survived, Sex, Embarked, Passenger Class\n - Integer features - Ticket, Cabin\n - Few features that aren't self-explanatory\n     - SibSp - Sibling or spouse\n     - Parch - Parent or child\n","bae3eeb6":"## Data Cleansing and Feature Dropping","d9a428f0":"### Random Forest","2c432d63":"We can conclude that passengers with higher class have cabin values allocated and passengers with lower class have mostly no cabins allocated. Therefore, we can consider a non-blank cabin value tied to more survival rate.","229c691e":"Cabin feature is available only less than 30% of the records. This might be in relation to the passenger class. ","4a2fe528":"## Age Feature","28b0c7e4":"## Passenger Class Feature"}}