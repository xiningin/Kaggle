{"cell_type":{"b7c9690a":"code","aff2fe0e":"code","409174fe":"code","64be1816":"code","729fcb5e":"code","085f6128":"code","3ba86384":"code","f1b6107f":"code","58d7b833":"code","3a029f1c":"code","b6f5c6b4":"code","d8384cb6":"code","650c6294":"code","68f928e4":"code","f1293104":"code","d2a356ef":"code","95519249":"code","03389830":"code","90ea2115":"markdown","730c5344":"markdown","5416cfd9":"markdown","aab65913":"markdown","4830fc31":"markdown","379f4a9e":"markdown","16efd093":"markdown","441af3b2":"markdown","321778ba":"markdown","10648d0b":"markdown","239857ee":"markdown","f89cbb31":"markdown","cd85696a":"markdown","a26b2fec":"markdown"},"source":{"b7c9690a":"import numpy as np\nimport pandas as pd \n# To ignore warinings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom xgboost import XGBClassifier\nfrom collections import Counter","aff2fe0e":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\n\nTREE_METHOD = \"hist\"\n\nCUT_BASIS = 10\nCUT_NUMBER = 20","409174fe":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","64be1816":"# 1.get train row size \ntrain_len = len(train)\n\n# 2.concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n\n# 3. empty data => np.nan\ndataset = dataset.fillna(np.nan)","729fcb5e":"# 4.column encoding and create new features\n# 4.1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 4.2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 4.3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 4.4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n#     age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n#     if not np.isnan(age_pred) :\n#         dataset['Age'].iloc[i] = age_pred\n#     else :\n#         dataset['Age'].iloc[i] = age_med\n        \n        \n# 5.5.Name         \n# dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n# dataset[\"Title\"] = pd.Series(dataset_title)\n# dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n# dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n# dataset = pd.get_dummies(dataset, columns = [\"Title\"])\n\n# 4.6.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# #4.7.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# #4.8.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 4.9.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 4.10.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)","085f6128":"# 5.cut labelling\nauto_cut_col = []\nfor colname, colvalue in dataset.iteritems():\n    if type(colvalue[1]) != str and colvalue.nunique() >= CUT_BASIS:\n        dataset[colname +\"_cut\"] = pd.cut(dataset[colname],CUT_NUMBER,labels=False,duplicates=\"drop\")\n        auto_cut_col.append(colname +\"_cut\")\n        \nprint(auto_cut_col)","3ba86384":"dataset.columns","f1b6107f":"# 6.devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","58d7b833":"train.head()","3a029f1c":"train[auto_cut_col]","b6f5c6b4":"train[\"Age_cut\"].value_counts()\n","d8384cb6":"train[\"Fare_cut\"].value_counts()","650c6294":"def getLabelCount(df,target):\n    return [( labelValue,len(train.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()]\n\nlabelCount = getLabelCount(train,TARGET)\nlabelCount","68f928e4":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test","f1293104":"model = XGBClassifier(tree_method=TREE_METHOD) \nmodel.fit(X, y)","d2a356ef":"pred_test = model.predict(X_test).astype(int)\npred_test[:5]","95519249":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsubmission[TARGET] = pred_test\nsubmission.to_csv(SUBMISSION_PATH,index=False)\nsubmission.head()","03389830":"submission.tail()","90ea2115":"# preprocess","730c5344":"# check Count","5416cfd9":"# train model","aab65913":"# devide dataset  => train , test ","4830fc31":"# **pandas cut**","379f4a9e":"# Auto Cut Labeling","16efd093":"# submit","441af3b2":"Bin values into discrete intervals.\nUse cut when you need to segment and sort data values into bins","321778ba":"# dataset = train + test ","10648d0b":"# check auto cut labeling columns","239857ee":"# load","f89cbb31":"# predict","cd85696a":"# split input set and target data","a26b2fec":"# import "}}