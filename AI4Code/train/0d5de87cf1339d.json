{"cell_type":{"fa731d4c":"code","f78640fc":"code","d2ed65b7":"code","0100dd6b":"code","bb9b1b26":"code","30c82b58":"code","7518506b":"code","5fbdf82b":"code","a05d65c2":"code","70f56f33":"code","5037557b":"code","4c83327e":"code","f64d297d":"code","e4462f17":"code","3dac720f":"code","3f3b7479":"code","d99e2fa9":"code","217a7f5f":"code","74f99896":"code","23846dfd":"code","c5512c04":"code","e4860cb7":"code","2bf3ac1e":"code","73c29b27":"code","6addbedb":"code","484880e1":"code","b6f13b86":"code","13638bd5":"code","3471673b":"code","b1fa6957":"code","d51bcf9f":"code","0946d9f6":"code","fe9576e0":"code","e823096a":"code","d293d68f":"code","c9ce2b58":"code","77f521a2":"code","3d6e7ce9":"code","29fff499":"code","dde93b72":"code","d2d4e637":"code","5edbde76":"code","61b1ab29":"markdown","669d6d7d":"markdown","20f39ba3":"markdown","e9c9f2bb":"markdown"},"source":{"fa731d4c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,LeakyReLU\nfrom sklearn.metrics import confusion_matrix\n\n# ignore warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n","f78640fc":"# !head -n 2 \/kaggle\/input\/digit-recognizer\/train.csv\ntrain_data = pd.read_csv(\"{}\/train.csv\".format(dirname))\ntest_data = pd.read_csv(\"{}\/test.csv\".format(dirname))","d2ed65b7":"train_data.head()","0100dd6b":"test_data.to_numpy().shape","bb9b1b26":"train_data.to_numpy().shape","30c82b58":"np.max(train_data.to_numpy()[0])","7518506b":"from skimage import feature\nfrom skimage import filters\nfrom skimage.transform import resize\n# resize(heatmap.numpy(),(28,28),)\n\ntrain_label = train_data.label.to_numpy()\n\ndef ArrayFilter(imgarray):\n    img2 = np.array([imgarray,#edge_img,edge_img\n                    ]).transpose(1,2,0)\n    return img2\n\ntrain_image=np.array([ \n        ArrayFilter(img.reshape(28,28))\n    for img in train_data.to_numpy()[0:,1:]\n])\n\ntest_image =np.array([\n        ArrayFilter(img.reshape(28,28))\n    for img in test_data.to_numpy() \n])\n","5fbdf82b":"# \u3053\u306e\u95a2\u6570\u306f\u30011\u884c5\u5217\u306e\u30b0\u30ea\u30c3\u30c9\u5f62\u5f0f\u3067\u753b\u50cf\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3001\u753b\u50cf\u306f\u5404\u5217\u306b\u914d\u7f6e\u3055\u308c\u307e\u3059\u3002\ndef plotImages(images_arr,title_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,10))\n    axes = axes.flatten()\n    for img, ax , title in zip( images_arr, axes,title_arr):\n        ax.set_title(title)\n        ax.imshow(img,\n                  cmap=\"gray\"\n                 )\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n","a05d65c2":"datagen = ImageDataGenerator(\n    rescale=1.\/255, \n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    #horizontal_flip=True,\n    validation_split=0.2)","70f56f33":"train_data_gen=datagen.flow(train_image,train_label, batch_size=294, shuffle=True,subset=\"training\")\nvalid_data_gen=datagen.flow(train_image,train_label, \n                                       batch_size=126, subset=\"validation\")\n\nfor indx in range(0,3):\n    augmented_images = [train_data_gen[indx][0][i] for i in range(10)]\n    plotImages(augmented_images,train_data_gen[indx][1][0:10])","5037557b":"# Hyper parameter\u306efine tune\u3092\u884c\u3046\nimport keras_tuner as kt\nimport IPython","4c83327e":"print(\"shape:\",train_data_gen[0][0][0].shape)\nprint(\"max:\",np.max(train_data_gen[0][0][0]))","f64d297d":"train_image[0].shape","e4462f17":"\n# have completed tune at Version11\ndef model_builder(hp):\n    # input layer\n    hp_input_layer = hp.Int(\"InputParam\",min_value=28, max_value=28,step=4)\n    # layer1\n    hp_drop_rate1 = hp.Choice('drop_rate1', values = [0.2]) \n    hp_layer_units1 = hp.Int('units1', min_value = 28, max_value = 28, step = 4)\n    # hp_layer_units1 = hp.Int('units1', min_value = 28, max_value = 36, step = 4)\n    hp_reg_rate1 = hp.Choice('reg_rate1', values = [ #1e-2,1e-3,\n                                                    1e-4]) \n    # layer2\n    hp_layer_units2 = hp.Int('units2', min_value = 28, max_value = 28, step = 4)\n    # hp_layer_units2 = hp.Int('units2', min_value = 28, max_value = 36, step = 4)\n    hp_reg_rate2 = hp.Choice('reg_rate2', values = [# 1e-2,1e-3,\n                                                    1e-4]) \n\n    model = keras.Sequential([\n        keras.Input(shape=(28,28,1)),\n        Conv2D(hp_input_layer, (4,4), activation='relu',\n               name = \"InputLayer\"),\n        # layer1\n        Conv2D(hp_layer_units1, (4,4),activation='relu',\n          kernel_regularizer=keras.regularizers.l2(hp_reg_rate1)),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        keras.layers.Dropout(hp_drop_rate1),\n\n        # layer2\n        Conv2D(hp_layer_units2,(4,4) ,activation='relu', padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(hp_reg_rate2),name=\"layer2\"),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        keras.layers.Dropout(hp_drop_rate1),\n        keras.layers.AveragePooling2D(pool_size=(2, 2)),\n    ])\n    \n    \"\"\"\n    hp_layer3_flag = hp.Choice('layer3_flag', values = [True,\n                                                        False\n                                                    ]) \n    if hp_layer3_flag:\n        model.add(\n            Conv2D(28,(3,3) , padding=\"same\",name= \"layer3\",\n                   activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n        )\n        model.add(BatchNormalization())\n        model.add(LeakyReLU(0.2))\n    \"\"\"\n    \n    model.add(\n        Conv2D(28,(3,3) , padding=\"same\",name= \"layer3\",\n               activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n    )\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.2))\n\n    model.add(\n        Conv2D(28,(3,3) , padding=\"same\",name= \"lastConvLayer\",\n               activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n    )\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile \n    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2]) \n    model.compile(loss=\"sparse_categorical_crossentropy\",\n                  optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n                  metrics=[\"accuracy\"])\n    return model\n","3dac720f":"!rm -rf .\/my_dir\ntuner = kt.Hyperband(model_builder,\n                     objective = 'val_accuracy', \n                     max_epochs = 50,\n                     directory = 'my_dir',\n                     project_name = 'intro_to_kt')","3f3b7479":"class ClearTrainingOutput(tf.keras.callbacks.Callback):\n    def on_train_end(*args, **kwargs):\n        IPython.display.clear_output(wait = True)\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", \n                                              factor=0.5, patience=5, \n                                              min_lr=1e-8, verbose=1)","d99e2fa9":"tuner.search(train_data_gen,\n             steps_per_epoch=100, \n             epochs=50, \n             validation_data=valid_data_gen, \n             validation_steps=50, \n             callbacks = [ClearTrainingOutput(),\n                          reduce_lr,\n                          early_stop]\n            )","217a7f5f":"# Get the optimal hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n\nfrom pprint import pprint\nprint(\"tuned model parameter----------\")\npprint(best_hps.values)\nprint(\"----------\")\n\nmodel = tuner.hypermodel.build(best_hps)\nmodel.summary()","74f99896":"hist=model.fit(train_data_gen,\n               steps_per_epoch=100, \n               epochs=200, \n               validation_data=valid_data_gen, \n               validation_steps=50, \n               callbacks = [reduce_lr,early_stop],\n               verbose=2\n            )","23846dfd":"results = model.evaluate(valid_data_gen, verbose=2)","c5512c04":"history_dict = hist.history\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\nhist_result = (acc,val_acc),(loss,val_loss) ","e4860cb7":"fig, axes = plt.subplots(1, 2, figsize=(20,8))\naxes = axes.flatten()\n\nfor res, ax,title in zip( hist_result, axes,[\"Accuracy\",\"loss\"]):\n    ax.plot(epochs,res[0], 'b', label='{} {}'.format(\"Training\",title)) \n    ax.plot(epochs,res[1], 'r', label='{} {}'.format(\"Validation\",title)) \n    ax.set_xlabel('Epochs')\n    ax.set_ylabel(title)\n    ax.set_xlim(0,epochs[-1])\n    ax.grid()\n    ax.legend()\nplt.tight_layout()\nplt.show()\n","2bf3ac1e":"data = train_data_gen # train_data_gen\nresults =[ tf.argmax(i) for i in model.predict(data.x, verbose=2)]\nconfusion_mtx = confusion_matrix(data.y, results) \n\nimport seaborn as sns\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"cubehelix\",linecolor=\"gray\", fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","73c29b27":"confusion_mtx","6addbedb":"res = model.predict(test_image[:]\/255)\noutput = pd.DataFrame({'ImageId':[ i+1 for i in range(len(test_image))], \n                       'Label': [ xi.argmax() for xi in res]})\noutput.to_csv('submission_grid.csv', index=False)","484880e1":"offset = 5\nfor i in range(3):\n    print(\"predicted: \",res[i+ offset].argmax())\n    plt.imshow(test_image[i + offset],cmap=\"gray\")\n    plt.show()","b6f13b86":"def show_figure(img_arr,alpha=0.5,pred=None):\n    # print(pred)\n    col = 3\n    if pred is not None:\n        col = 4\n    fig, axes = plt.subplots(1, col, figsize=(20,5))\n    axes = axes.flatten()\n    axes[0].imshow(img_arr[0],cmap=\"gray\")\n    axes[0].imshow(img_arr[1],alpha=alpha)\n    axes[1].imshow(img_arr[0],cmap=\"gray\")\n    axes[2].imshow(img_arr[1])\n    if col == 4:\n        x = [i for i in range(len(pred[0]))]\n        axes[3].bar(x, pred[0])\n        axes[3].set_xticks(x)\n        axes[3].set_yscale('log')\n        axes[3].set_xlabel(\"Class\")\n        axes[3].set_ylabel(\"Score\")\n\n    axes[0].axis('off')\n    axes[1].axis('off')\n    axes[2].axis('off')\n    plt.tight_layout()\n    plt.show()\n","13638bd5":"def get_gradients(img_input,index):\n    images = tf.cast(img_input\/255, tf.float32)\n\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        preds = model(images)\n        class_channel = preds[:, index]\n        index =tf.argmax(preds[0])\n        print(\"index: \",index, \" rate:\",preds[0][index])\n        # preds[0][index] = 0\n    grads = tape.gradient(class_channel, images)\n    # print(grads.shape)\n    glad_img = np.array(grads[0]).reshape(28,28,1)\n    glad_img = (glad_img-np.min(glad_img))*255 \/(np.max(glad_img)-np.min(glad_img))\n    return img_input[0],glad_img","3471673b":"offset = 20\nfor i in range(0,10):\n    num = i\n    pred = model.predict(test_image[i+offset:i+offset+1]\/255)\n    print(\"pledicted result\",pred[0].argmax())\n    img_arr  = get_gradients(test_image[i+offset:i+offset+1],pred[0].argmax())\n    show_figure(img_arr,pred=pred)\n","b1fa6957":"from skimage.transform import resize\n","d51bcf9f":"lastCoveLater = \"lastConvLayer\"\ndef make_gradcam_heatmap(img_array, model, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(lastCoveLater).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array\/255)\n        # print(\"predicted index:\",tf.argmax(preds[0]),\"\\n result: \",preds)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    #print(last_conv_layer_output.shape)\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    # print(heatmap.shape)\n    heatmap = tf.squeeze(heatmap)\n    # print(heatmap.shape)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) \/ tf.math.reduce_max(heatmap)\n    return resize(heatmap.numpy(),(28,28),)\n\n#bottle_resized = resize(bottle, (140, 54), anti_aliasing=True)\n","0946d9f6":"offset = 25000\nnum = 10\nfor i in range(offset,offset +num):\n    num = i\n    pred = model.predict(test_image[num:num+1]\/255)\n    print(\"index:\",pred[0].argmax(), \"labels: \",pred[0])\n    heatmap = make_gradcam_heatmap(test_image[num:num+1],model,pred[0].argmax())\n    arr = [test_image[num],heatmap]\n    show_figure(arr,alpha=0.7,pred=pred)","fe9576e0":"def segImg(imgarray):\n    # use edge filter\n    edge =filters.sobel(imgarray)\n    edge_img = np.array( [edge\/np.max(edge)])\n    \n    edge_img_bn = np.where( edge_img >= 0.5,1,0)\n    return edge_img_bn.transpose(1,2,0)\n\n\ntrain_edge = np.array([ \n        segImg(img.reshape(28,28))\n    for img in train_data.to_numpy()[0:,1:]\n])\n\nprint(train_edge.shape)\nfor i in range(0,3):\n    plt.imshow(train_edge[i]);\n    plt.show()","e823096a":"def make_model():\n    inputs = keras.Input(shape=(28,28,1))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = Conv2D(32, (5,5), padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(1e-4))(inputs)\n    x = LeakyReLU(0.2)(x)\n    x = BatchNormalization()(x)\n\n    # Conv block\n    x = Conv2D(36, (5,5), padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n\n    x = LeakyReLU(0.2)(x)\n    x = BatchNormalization()(x)\n    x = keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # classification layer\n    class_ = Flatten()(x)\n    y = Dense(10, activation='softmax',name=\"class\")(class_)\n\n    # segmentaion layer\n    segmentaion = keras.layers.UpSampling2D(2)(x)\n    segmentaion = Conv2D(2, (4,4), padding=\"same\",activation='softmax',name=\"segment\")(segmentaion)\n\n    model = keras.Model(inputs, [y,segmentaion])\n    return model\n                         \nseg_model = make_model()\nseg_model.summary()\n\nres=seg_model(train_data_gen[0][0][0:1])","d293d68f":"keras.utils.plot_model(seg_model, \"my_model.png\", show_shapes=True)","c9ce2b58":"early_stop = keras.callbacks.EarlyStopping(monitor='class_loss', patience=20)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_class_accuracy', \n                                              factor=0.5, patience=10, \n                                              min_lr=1e-8, verbose=1)\n\nseg_model.compile(loss=[ \"sparse_categorical_crossentropy\" ,\"sparse_categorical_crossentropy\"],\n              loss_weights = [1.0,0.3],\n              optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n              metrics=[\"accuracy\"])\n\n\nhist=seg_model.fit(train_image\/255,\n                   {\"class\":train_label,\"segment\":train_edge},\n                   steps_per_epoch=200, \n                   batch_size=400,\n                   validation_batch_size=200,\n                   validation_split=0.2,\n                   epochs=200,\n                   shuffle=True,\n                   callbacks = [reduce_lr,early_stop],\n                   verbose=2\n            )","77f521a2":"history_dict = hist.history\n\nacc = history_dict['class_accuracy']\nval_acc = history_dict['val_class_accuracy']\nloss = history_dict['class_loss']\nval_loss = history_dict['val_class_loss']\n\nepochs = range(1, len(acc) + 1)\nhist_result = (acc,val_acc),(loss,val_loss) ","3d6e7ce9":"fig, axes = plt.subplots(1, 2, figsize=(20,8))\naxes = axes.flatten()\n\nfor res, ax,title in zip( hist_result, axes,[\"Accuracy\",\"loss\"]):\n    ax.plot(epochs,res[0], 'b', label='{} {}'.format(\"Training\",title)) \n    ax.plot(epochs,res[1], 'r', label='{} {}'.format(\"Validation\",title)) \n    ax.set_xlabel('Epochs')\n    ax.set_ylabel(title)\n    ax.set_xlim(2,epochs[-1])\n    #ax.set_ylim(0.97,1.01)\n    ax.grid()\n    ax.legend()\nplt.tight_layout()\nplt.show()\n","29fff499":"data = train_image\/255 # train_data_gen\nresults =[ tf.argmax(i) for i in seg_model.predict(data)[0]]\nconfusion_mtx = confusion_matrix(train_label, results) \n\nimport seaborn as sns\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"cubehelix\",linecolor=\"gray\", fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","dde93b72":"res = seg_model.predict(test_image[:]\/255)[0]\noutput = pd.DataFrame({'ImageId':[ i+1 for i in range(len(test_image))], \n                       'Label': [ xi.argmax() for xi in res]})\noutput.to_csv('submission_grid2.csv', index=False)","d2d4e637":"!head .\/submission_grid2.csv","5edbde76":"num =0\nfor num in range(num,num+80):\n    fig, axes = plt.subplots(1, 3, figsize=(18,6))\n    axes = axes.flatten()\n\n    img = test_image[num:num+1]\/255\n    res=seg_model.predict(img)\n\n    print(tf.argmax(res[0][0]))\n\n    axes[0].imshow(img[0])\n\n    im=axes[1].imshow(res[1][0][:,:,1])\n    fig.colorbar(im)\n\n    x = [i for i in range(10)]\n    axes[2].bar(x, res[0][0])\n    axes[2].set_xticks(x)\n    axes[2].set_yscale('log')\n    axes[2].set_xlabel(\"Class\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_ylim(1e-2,1)\n    plt.show()","61b1ab29":"---\n\n# Grad-cam \n\nAm I using grad-cam correctly?  \nIf it can be used, is this model training correctly?  \nI would like advice from someone who is familiar with it.","669d6d7d":"# Try using Grad-cam\n\n- Credit\n    - https:\/\/keras.io\/examples\/vision\/integrated_gradients\/\n    - https:\/\/keras.io\/examples\/vision\/grad_cam\/","20f39ba3":"---","e9c9f2bb":"# try image segmentation\n\n## first  make segmentation data set\n"}}