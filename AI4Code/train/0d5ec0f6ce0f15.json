{"cell_type":{"3f0ab763":"code","00d7aedb":"code","828d7c37":"code","685dc7f9":"code","a4556051":"code","2123cf51":"code","c1c64dc4":"code","b87457be":"code","97c53804":"code","3c685fad":"code","af967fae":"code","29a3a93c":"code","a9730f64":"code","f5c91e48":"code","9d476814":"code","addf30ef":"markdown","6b3ac603":"markdown","164b568c":"markdown","2efd244e":"markdown","f823d896":"markdown","2749365d":"markdown","8758e538":"markdown","5229889b":"markdown","025485a1":"markdown","74838897":"markdown","9edee8de":"markdown","677a8e6b":"markdown","a8072f93":"markdown","a0156695":"markdown","4a5e07e3":"markdown","6652ea14":"markdown","c2c719fc":"markdown","ed0de0a0":"markdown","8b514d58":"markdown","90e03a62":"markdown","4f601b15":"markdown","24af58ab":"markdown","d689bffe":"markdown","a7b9e1d6":"markdown","0e66d5bc":"markdown","8c9be10f":"markdown","d1b557a3":"markdown"},"source":{"3f0ab763":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\nimport seaborn as sns\nfrom keras.initializers import RandomNormal\nfrom keras import backend as K\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Activation \nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.utils.np_utils import to_categorical ","00d7aedb":"import matplotlib.pyplot as plt\nimport numpy as np\nimport time\n\ndef plt_dynamic(x, vy, ty, ax, colors=['b']):\n    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n    ax.plot(x, ty, 'r', label=\"Train Loss\")\n    plt.legend()\n    plt.grid()\n    fig.canvas.draw()","828d7c37":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","685dc7f9":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \nX_test = test","a4556051":"X_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","2123cf51":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test  = X_test.values.reshape(-1,28,28,1)","c1c64dc4":"Y_train[100]  # Here the output image is 9. we need to convert it using one-hot encoding.","b87457be":"Y_train = to_categorical(Y_train, num_classes = 10)\nY_train[[100]]","97c53804":"print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\nprint(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))","3c685fad":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=42)","af967fae":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (5,5), activation = 'relu', input_shape = (28,28,1), padding = 'same'))\nmodel.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = 'softmax'))\nmodel.summary()","29a3a93c":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel_fit = model.fit(X_train, Y_train, batch_size = 100, epochs = 10, verbose=1, validation_data = (X_val,Y_val))","a9730f64":"y_pred  = model.predict_classes(X_test)","f5c91e48":"y_pred[:5]","9d476814":"results = pd.Series(y_pred,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"simple_cnn4.csv\",index=False)","addf30ef":"## 2. Data Preparation","6b3ac603":"## 5. Submission","164b568c":"![Kernel%20Image.png](attachment:Kernel%20Image.png)","2efd244e":"Split the data into training data and validation data for validation of accuracy purpose.","f823d896":"## 4. Evaluation","2749365d":"This systematic application of the same filter across an image is a powerful idea. If the filter is designed to detect a specific type of feature in the input, then the application of that filter systematically across the entire input image allows the filter an opportunity to discover that feature anywhere in the image. This capability is commonly referred to as translation invariance, e.g. the general interest in whether the feature is present rather than where it was present.\n\nConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would.\n","8758e538":"\n**Pooling Layers - ** A limitation of the feature map output of convolutional layers is that they record the precise position of features in the input. This means that small movements in the position of the feature in the input image will result in a different feature map. This can happen with re-cropping, rotation, shifting, and other minor changes to the input image. \n\nA common approach to addressing this problem from signal processing is called down sampling. This is where a lower resolution version of an input signal is created that still contains the large or important structural elements, without the fine detail that may not be as useful to the task. \n\nPooling layers are used which extract some features from the feature maps and control the size of weights and biases the network is learning. Pooling mainly helps in extracting sharp and smooth features. \n\nThe function of Pooling is to progressively reduce the spatial size of the input representation. In particular, pooling\n* makes the input representations (feature dimension) smaller and more manageable\n* reduces the number of parameters and computations in the network, therefore, controlling overfitting\n* makes the network invariant to small transformations, distortions and translations in the input image (a small distortion in input will not change the output of Pooling \u2013 since we take the maximum \/ average value in a local neighborhood).\n* helps us arrive at an almost scale invariant representation of our image. This is very powerful since we can detect objects in an image no matter where they are located.\n\n","5229889b":"![CNN%20Image.jpeg](attachment:CNN%20Image.jpeg)","025485a1":"In the above we see that the validation accuracy is at 99.0%.","74838897":"#### Label Encoding\nThe Output in the Y_train is in the number format as [0,1,2,3,4,5,6,7,8,9]. In order input this column for training the model we need to convert this number input into [0 and 1]'s using one-hot encoding. So below we convert the ","9edee8de":"## 3. CNN Model\nWe will develop a simple Convolution Neural Network model in this kernel. We use following functionalities in the below code. \n\n**Convolution Layer - ** As described earlier, convolution layer used to identify the important features by mapping the input image to a transfomed image using the kernel multiplier (K) by doing .dot product. So in the first convolution, we have choosen 32 filters to map the input image into a new tramnsformed image.\n\n**Max Pooling Layer - ** As described earlier, the Maxpool layer does the  downsampling of the Input Image. This will help us to reduce computational cost, and to some extent also reduce overfitting. The advantages of using Maxpooling is already discussed in the beginning.\n\n**Dropout - ** Dropout is mainly used for regulaization technique to avoid the overfitting of Deep Learning models. Dropout is a technique where randomly selected neurons are ignored during training based on the percentage selected in any Layer. They are \u201cdropped-out\u201d randomly. So dropout rate of 0.5 means 50% of the neurons in a given Layer will be dropped out during the training. This way it will avoid the overfitting of model. In this kernel we have used a drop out rate of 0.2.\n\n**Flatten - ** Flatten is used to convert the output of convolution featured map (which can be any dimensional based on kernel size) into a 1D-vector which in turn will be fed into a Fully Connected Network. So in this step we convert all the features we found in Convolution Layer layer and Maxpool Layer into a 1D - Vector. These vectors are trained using ANN as shown below. ","677a8e6b":"Convolutional Neural Networks are a powerful artificial neural network technique. These are developed for object recognition tasks such as handwritten digit recognition. Unlike traditional multilayer perceptron architectures, it uses two operations called \u2018convolution\u2019 and pooling\u2019 to reduce an image into its essential features, and uses those features to understand and classify the image.\n\n**Building Blocks of Convolutional Neural Networks**\n\nThere are three types of layers in a Convolutional Neural Network.\n* Convolutional Layers.\n* Pooling Layers.\n* Fully-Connected Layers\n    \n**Convolutional Layer - ** a \u201cfilter\u201d, sometimes called a \u201ckernel\u201d, is passed over the image, viewing a few pixels at a time (for example, 3X3 or 5X5). The convolution operation is a dot product of the original pixel values with weights defined in the filter. The results are summed up into one number that represents all the pixels the filter observed.\n\n\n\n","a8072f93":"#### Loading Data","a0156695":"#### Normalization\nNormalizing features can mitigate the likelihood of gradients blowing up or vanishing due to the undue influence of a given feature - both of which can slow down model convergence significantly. So it is always important to normalize the data before inputting into the Network. ","4a5e07e3":"We will seperate out the Input columns(X) and the Output columns(Y). ","6652ea14":"## Introduction to Convolutional Neural Networks (CNN)","c2c719fc":"### CNN Implementation in Keras","ed0de0a0":"The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. The MNIST database contains 60,000 training images and 10,000 testing images.\n\nIn this kernel we will train a simple CNN and keep adding the new features like Augmentation in the future. We will run a 20 epoch CNN model on the MNIST data. Before the implementation of the CNN we do the data processing which involves \n\n* Normalization\n* Reshape\n* Label Encoding\n","8b514d58":"![maxpool_animation.gif](attachment:maxpool_animation.gif)","90e03a62":"![convolution-example-matrix.gif](attachment:convolution-example-matrix.gif)","4f601b15":"#### Compile the Model","24af58ab":"We will do the following steps for the implementation of the CNN in Keras.\n1. Introduction\n2. Data Preparation\n3. CNN\n4. Evaluation\n5. Submission","d689bffe":"**Fully-Connected Layers - ** a traditional multilayer perceptron structure. Its input is a one-dimensional vector representing the output of the previous layers. Its output is a list of probabilities for different possible labels attached to the image (e.g. dog, cat, bird). The label that receives the highest probability is the classification decision.\n\nThe output from the convolutional and pooling layers represent high-level features of the input image. The purpose of the Fully Connected layer is to use these features for classifying the input image into various classes based on the training dataset. ","a7b9e1d6":"#### Reshape\nThe data we loaded in train and test are in the .csv format, i.e., in 1D-vector reprsentation for each image in a single row with lenght 784. But to input it into a CNN, in order for CNN to learn the different features like edges, colors or shapes we need the data to be in Image format. So we convert each row (784 columns) into 28x28 matrix format for each row. (similar to 28x28 image pixels format) ","0e66d5bc":"<div align='center'><font size=\"6\" color=\"#FC6306\"> A Simple Tutorial on CNN <\/font><\/div>","8c9be10f":"**References**\n\nhttps:\/\/missinglink.ai\/guides\/convolutional-neural-networks\/convolutional-neural-network-tutorial-basic-advanced\/\n\nhttps:\/\/machinelearningmastery.com\/convolutional-layers-for-deep-learning-neural-networks\/\n\nhttps:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n\nhttps:\/\/medium.com\/@RaghavPrabhu\/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n\nhttps:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network\n\nhttps:\/\/ujjwalkarn.me\/2016\/08\/11\/intuitive-explanation-convnets\/\n\n","d1b557a3":"## 1. Introduction"}}