{"cell_type":{"33dc983e":"code","d93b6816":"code","2a0e403a":"code","f708a497":"code","d098ddb3":"code","8cff721b":"code","f19b5b43":"code","cd3671cf":"code","72c9a059":"code","005b8a84":"code","72869ecc":"code","2b79693e":"code","ca08cb2f":"code","49b838b7":"code","1c449202":"code","5cd97f1f":"code","54c6c6b3":"code","8078f25f":"code","9979e5a5":"code","25fa7702":"code","60e5fdc5":"code","749cf41a":"code","7f7ffeb0":"markdown","efde98fb":"markdown","bb9afdcd":"markdown","ca8ed192":"markdown","c36500b3":"markdown","4b86ca75":"markdown","a8b2aa43":"markdown","d7ae2725":"markdown","603313e9":"markdown","93f1fb32":"markdown","8ddfe585":"markdown","7771a1b7":"markdown","22a88db2":"markdown","cc9e9592":"markdown","94b29c42":"markdown","eb7a079c":"markdown","49e2091e":"markdown","1dd28094":"markdown","c7c1cf4b":"markdown","03d865c2":"markdown","57012f0f":"markdown","55a07b6e":"markdown","a3c9efc1":"markdown","f7a146dd":"markdown","a2c7f990":"markdown","5a6087a2":"markdown","e0835e98":"markdown","2c454e12":"markdown","8730ea58":"markdown","4eddaba2":"markdown","df21bc3a":"markdown","63b3a1d6":"markdown","16c0b31e":"markdown","10d997c1":"markdown","cb032047":"markdown","16c7b972":"markdown","a7402a0b":"markdown","fa585501":"markdown","a9c5a423":"markdown","7d8b740c":"markdown","01a6a8c6":"markdown","311f3f2c":"markdown","4f767109":"markdown","6768d470":"markdown","6fa9c21f":"markdown","68e091a5":"markdown","4e5671c0":"markdown","74c77376":"markdown","57b49229":"markdown","0fb6c7c9":"markdown","6e9b5a21":"markdown","5ab0f90e":"markdown","09e33a5c":"markdown","21d9eb31":"markdown"},"source":{"33dc983e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d93b6816":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\ndata=pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\n\nque=data.iloc[0]\ndata=data.drop(data.index[0])\n","2a0e403a":"data[\"Q4\"].replace({\"Some college\/university study without earning a bachelor\u2019s degree\":\"Not Completed Bachelor's Degree\"}, inplace=True)\ntotal = float(len(data['Q4']))\nplt.figure(figsize=(20,10))\nax=sns.countplot(x='Q4',data=data,order=data['Q4'].value_counts().index, palette=\"rocket\")\n\ntotal = len(data['Q4'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100*p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.5\n        y = p.get_y() + p.get_height()+60\n        ax.annotate(percentage, (x, y),size=12)\n\nplt.xlabel('Education Type ',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Education VS Response',fontsize=20)    \nplt.show()","f708a497":"total = float(len(data['Q1']))\nplt.figure(figsize=(20,10))\nax=sns.countplot(x='Q1',data=data,order=data['Q1'].value_counts().index,palette=\"rocket\")\n\ntotal = len(data['Q1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100*p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.5\n        y = p.get_y() + p.get_height()+60\n        ax.annotate(percentage, (x, y))\n\nplt.xlabel('Age',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=12)\nplt.yticks(size=12)\nplt.title('Age VS Response',fontsize=20)    \n\nplt.show()","d098ddb3":"plt.figure(figsize=(20,40))\nax=sns.countplot(y='Q3',data=data,order=data['Q3'].value_counts().index,palette='rocket')\ntotal = len(data['Q3'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 25\n        y = p.get_y() + p.get_height()\/1.5\n        ax.annotate(percentage, (x, y),size=14)\n        \nplt.title('Country VS Response',size=25)\nplt.xlabel('Number Of Response',size=20)\nplt.ylabel('Countries',size=20)\nplt.xticks(size=14)\nplt.yticks(size=14)\nplt.show()","8cff721b":"plt.figure(figsize=(16,6))\nax=sns.countplot(y='Q5',data=data,order=data['Q5'].value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 25\n        y = p.get_y() + p.get_height()\/1.5\n        ax.annotate(percentage, (x, y))\nplt.title('Occupation VS Response',size=20)\nplt.xlabel('Number of response',size=15)\nplt.ylabel('Number of response',size=15)\nplt.show()","f19b5b43":"plt.figure(figsize=(16,6))\nax=sns.countplot(y='Q6',data=data,order=data['Q6'].value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 20\n        y = p.get_y() + p.get_height()\/1.5\n        ax.annotate(percentage, (x, y))\nplt.title('Coding Experience VS Response',size=20)\nplt.xlabel('Number of Response',size=15)\nplt.ylabel('Coding Experience',size=15)\n\nplt.show()","cd3671cf":"plt.figure(figsize=(20,8))\nax=sns.countplot(x='Q8',data=data,order=data['Q8'].value_counts().index,palette='rocket')\ntotal = len(data['Q8'])\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.4\n        y = p.get_y() + p.get_height()+160\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.xlabel('Number Of Response',size=15)\nplt.ylabel('Programming Languages',size=15)\nplt.xticks(size=12)\nplt.yticks(size=12)\nplt.title('Language Recomendation for a friend who is new to data science field',fontsize=20)    \nplt.show()","72c9a059":"Q7_1=data['Q7_Part_1']\nQ7_2=data['Q7_Part_2']\nQ7_3=data['Q7_Part_3']\nQ7_4=data['Q7_Part_4']\nQ7_5=data['Q7_Part_5']\nQ7_6=data['Q7_Part_6']\nQ7_7=data['Q7_Part_7']\nQ7_8=data['Q7_Part_8']\nQ7_9=data['Q7_Part_9']\nQ7_10=data['Q7_Part_10']\nQ7_11=data['Q7_Part_11']\nQ7_12=data['Q7_Part_12']\nQ7_OTHER=data['Q7_OTHER']\n\nQ7_total=pd.concat([Q7_1,Q7_2,Q7_3,Q7_4,Q7_5,Q7_6,Q7_7,Q7_8,Q7_9,Q7_10,Q7_11,Q7_12,Q7_OTHER],ignore_index=True)\n\ntotal=len(data['Q7_Part_1'])\n\nplt.figure(figsize=(20,8))\nax=sns.countplot(x=Q7_total,data=data,order = Q7_total.value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100*p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/3\n        y = p.get_y() + p.get_height()+60\n        ax.annotate(percentage, (x, y))\n\nplt.title('Popular Coding Language For Data Science',size=20)\nplt.xlabel('Languages',size=15)\nplt.ylabel('Number of response',size=15)\nplt.show()","005b8a84":"Q9_1=data['Q9_Part_1']\nQ9_2=data['Q9_Part_2']\nQ9_3=data['Q9_Part_3']\nQ9_4=data['Q9_Part_4']\nQ9_5=data['Q9_Part_5']\nQ9_6=data['Q9_Part_6']\nQ9_7=data['Q9_Part_7']\nQ9_8=data['Q9_Part_8']\nQ9_9=data['Q9_Part_9']\nQ9_10=data['Q9_Part_10']\nQ9_11=data['Q9_Part_11']\nQ9_OTHER=data['Q9_OTHER']\ntotal_9=pd.concat([Q9_1,Q9_2,Q9_3,Q9_4,Q9_5,Q9_6,Q9_7,Q9_8,Q9_9,Q9_10,Q9_11,Q9_OTHER],ignore_index=True)\ntotal=len(data['Q9_Part_1'])\nplt.figure(figsize=(20,12))\nax=sns.countplot(y=total_9,data=data,order=total_9.value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 25\n        y = p.get_y() + p.get_height()\/1.5\n        ax.annotate(percentage, (x, y),size=15)\nplt.title('integrated development environments (IDE)-Wise Distribution',fontsize=22)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.ylabel('type of IDE\\'s',size=20)\nplt.xlabel('Number of Response',size=20)           \nplt.show()\n","72869ecc":"Q10_1=data['Q10_Part_1']\nQ10_2=data['Q10_Part_2']\nQ10_3=data['Q10_Part_3']\nQ10_4=data['Q10_Part_4']\nQ10_5=data['Q10_Part_5']\nQ10_6=data['Q10_Part_6']\nQ10_7=data['Q10_Part_7']\nQ10_8=data['Q10_Part_8']\nQ10_9=data['Q10_Part_9']\nQ10_10=data['Q10_Part_10']\nQ10_11=data['Q10_Part_11']\nQ10_12=data['Q10_Part_12']\nQ10_13=data['Q10_Part_13']\nQ10_OTHER=data['Q10_OTHER']\ntotal_Q10=pd.concat([Q10_1,Q10_2,Q10_3,Q10_4,Q10_5,Q10_6,Q10_7,Q10_8,Q10_9,Q10_10,Q10_11,Q10_12,Q10_13,Q10_OTHER],ignore_index=True)\n\ntotal=len(Q10_1)\nplt.figure(figsize=(20,12))\nax=sns.countplot(y=total_Q10,data=data,order=total_Q10.value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 25\n        y = p.get_y() + p.get_height()\/1.5\n        ax.annotate(percentage, (x, y),size=15)\nplt.title('hosted notebook products-wise Distribution',size=20)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.xlabel('Number of Reponse',size=18)\nplt.ylabel('hosted notebook products',size=18)\nplt.show()\n","2b79693e":"Q12_1=data['Q12_Part_1']\nQ12_2=data['Q12_Part_2']\nQ12_3=data['Q12_Part_3']\nQ12_OTHER=data['Q12_OTHER']\ntotal_Q12=pd.concat([Q12_1,Q12_2,Q12_3,Q12_OTHER],ignore_index=True)\n\nplt.figure(figsize=(16,8))\nax=sns.countplot(x=total_Q12,order=total_Q12.value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 2.5\n        y = p.get_y() + p.get_height()+100\n        ax.annotate(percentage, (x, y),size=12)\nplt.title('hosted notebook products-wise Distribution',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.xlabel('types of specialized hardware',size=12)\nplt.ylabel('Number of Response',size=12)\nplt.show()\n","ca08cb2f":"Q31_1=data['Q31_A_Part_1']\nQ31_2=data['Q31_A_Part_2']\nQ31_3=data['Q31_A_Part_3']\nQ31_4=data['Q31_A_Part_4']\nQ31_5=data['Q31_A_Part_5']           \nQ31_6=data['Q31_A_Part_6']\nQ31_7=data['Q31_A_Part_7']\nQ31_8=data['Q31_A_Part_8']\nQ31_9=data['Q31_A_Part_9']\nQ31_10=data['Q31_A_Part_10']\nQ31_11=data['Q31_A_Part_11']\nQ31_12=data['Q31_A_Part_12']\nQ31_13=data['Q31_A_Part_13']\nQ31_14=data['Q31_A_Part_14']           \nQ31_OTHER=data['Q29_A_OTHER']\nQ31_total=pd.concat([Q31_1,Q31_2,Q31_3,Q31_4,Q31_5,Q31_6,Q31_7,Q31_8,Q31_9,Q31_10,Q31_11,Q31_12,Q31_13,Q31_14,Q31_OTHER],ignore_index=True)\n\ntotal=len(Q31_1)\nplt.figure(figsize=(18,8))\nax=sns.countplot(y=Q31_total,order=Q31_total.value_counts().index,palette='rocket')\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n    x = p.get_x() + p.get_width() + 15\n    y = p.get_y() + p.get_height()\/1.5\n    ax.annotate(percentage, (x, y),size=12)\nplt.title('BI tools wise Distribution',size=20)\nplt.xlabel('Number of response',size=15)\nplt.ylabel('softwares',size=15)\nplt.show()\n","49b838b7":"Q14_1=data['Q14_Part_1']\nQ14_2=data['Q14_Part_2']\nQ14_3=data['Q14_Part_3']\nQ14_4=data['Q14_Part_4']\nQ14_5=data['Q14_Part_5']\nQ14_6=data['Q14_Part_6']\nQ14_7=data['Q14_Part_7']\nQ14_8=data['Q14_Part_8']\nQ14_9=data['Q14_Part_9']\nQ14_10=data['Q14_Part_10']\nQ14_11=data['Q14_Part_11']\nQ14_OTHER=data['Q14_OTHER']\n\nQ14_total=pd.concat([Q14_1,Q14_2,Q14_3,Q14_4,Q14_5,Q14_6,Q14_7,Q14_8,Q14_9,Q14_10,Q14_11,Q14_OTHER],ignore_index=True)\ntotal=len(Q14_1)\nplt.figure(figsize=(16,8))\nax=sns.countplot(y=Q14_total,order=Q14_total.value_counts().index,palette='rocket')\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n    x = p.get_x() + p.get_width() + 25\n    y = p.get_y() + p.get_height()\/1.5\n    ax.annotate(percentage, (x, y))\nplt.title('Data visualization libraries\/Framework VS Number of response',size=20)\nplt.xlabel('Number of response',size=15)\nplt.ylabel('Libraries',size=15)\nplt.show() ","1c449202":"Q16_1=data['Q16_Part_1']\nQ16_2=data['Q16_Part_2']\nQ16_3=data['Q16_Part_3']\nQ16_4=data['Q16_Part_4']\nQ16_5=data['Q16_Part_5']\nQ16_6=data['Q16_Part_6']\nQ16_7=data['Q16_Part_7']\nQ16_8=data['Q16_Part_8']\nQ16_9=data['Q16_Part_9']\nQ16_10=data['Q16_Part_10']\nQ16_11=data['Q16_Part_11']\nQ16_12=data['Q16_Part_12']\nQ16_13=data['Q16_Part_13']\nQ16_14=data['Q16_Part_14']\nQ16_15=data['Q16_Part_15']\nQ16_OTHER=data['Q16_OTHER']\nQ16_total=pd.concat([Q16_1,Q16_2,Q16_3,Q16_4,Q16_5,Q16_6,Q16_7,Q16_8,Q16_9,Q16_10,Q16_11,Q16_12,Q16_13,Q16_14,Q16_15,Q16_OTHER],ignore_index=True)\n\nplt.figure(figsize=(16,8))\nax=sns.countplot(x=Q16_total,order=Q16_total.value_counts().index,palette='rocket')\nplt.xticks(rotation=15)\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.65\n        y = p.get_y() + p.get_height()+160\n        ax.annotate(percentage, (x, y),size=9)\n        \n        \nplt.xlabel('Types of ML libraries \/ frameworks',size=10)\nplt.ylabel('Number Of Response',size=10)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","5cd97f1f":"Q17_1=data['Q17_Part_1']\nQ17_2=data['Q17_Part_2']\nQ17_3=data['Q17_Part_3']\nQ17_4=data['Q17_Part_4']\nQ17_5=data['Q17_Part_5']\nQ17_6=data['Q17_Part_6']\nQ17_7=data['Q17_Part_7']\nQ17_8=data['Q17_Part_8']\nQ17_9=data['Q17_Part_9']\nQ17_10=data['Q17_Part_10']\nQ17_11=data['Q17_Part_11']\nQ17_OTHER=data['Q17_OTHER']\nQ17_total=pd.concat([Q17_1,Q17_2,Q17_3,Q17_4,Q17_5,Q17_6,Q17_7,Q17_8,Q17_9,Q17_10,Q17_11,Q17_OTHER],ignore_index=True)\ntotal=len(Q17_1)\nplt.figure(figsize=(16,8))\nax=sns.countplot(y=Q17_total,order=Q17_total.value_counts().index,palette='rocket')\nplt.xticks(rotation=15)\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_width()\/total)\n        x = p.get_x() + p.get_width()+100\n        y = p.get_y() + p.get_height()\/1.60\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.xlabel('Types of ML libraries \/ frameworks',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","54c6c6b3":"Q18_1=data['Q18_Part_1']\nQ18_2=data['Q18_Part_2']\nQ18_3=data['Q18_Part_3']\nQ18_4=data['Q18_Part_4']\nQ18_5=data['Q18_Part_5']\nQ18_6=data['Q18_Part_6']\nQ18_OTHER=data['Q18_OTHER']\ntotal=len(Q18_1)\nQ18_total=pd.concat([Q18_1,Q18_2,Q18_3,Q18_4,Q18_5,Q18_6,Q18_OTHER],ignore_index=True)\nplt.figure(figsize=(16,8))\nax=sns.countplot(y=Q18_total,order=Q18_total.value_counts().index,palette='rocket')\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_width()\/total)\n        x = p.get_x() + p.get_width()+20\n        y = p.get_y() + p.get_height()\/1.60\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.xlabel('Types of ML libraries \/ frameworks',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","8078f25f":"Q19_1=data['Q19_Part_1']\nQ19_2=data['Q19_Part_2']\nQ19_3=data['Q19_Part_3']\nQ19_4=data['Q19_Part_4']\nQ19_5=data['Q19_Part_5']\nQ19_OTHER=data['Q19_OTHER']\nQ19_total=pd.concat([Q19_1,Q19_2,Q19_3,Q19_4,Q19_5,Q19_OTHER],ignore_index=True)\n\nplt.figure(figsize=(16,8))\nax=sns.countplot(y=Q19_total,order=Q19_total.value_counts().index,palette='rocket')\ntotal=len(Q19_1)\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_width()\/total)\n        x = p.get_x() + p.get_width()+20\n        y = p.get_y() + p.get_height()\/1.60\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.xlabel('Types of ML libraries \/ frameworks',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","9979e5a5":"Q26_1=data['Q26_A_Part_1']\nQ26_2=data['Q26_A_Part_2']\nQ26_3=data['Q26_A_Part_3']\nQ26_4=data['Q26_A_Part_4']\nQ26_5=data['Q26_A_Part_5']           \nQ26_6=data['Q26_A_Part_6']\nQ26_7=data['Q26_A_Part_7']\nQ26_8=data['Q26_A_Part_8']\nQ26_9=data['Q26_A_Part_9']\nQ26_10=data['Q26_A_Part_10']\nQ26_11=data['Q26_A_Part_11']\nQ26_OTHER=data['Q26_A_OTHER']           \nQ26_total=pd.concat([Q26_1,Q26_2,Q26_3,Q26_4,Q26_5,Q26_6,Q26_7,Q26_8,Q26_9,Q26_10,Q26_11,Q26_OTHER],ignore_index=True)\n               \nplt.figure(figsize=(20,8))\nax=sns.countplot(x=Q26_total,order=Q26_total.value_counts().index,palette='rocket')\nplt.xticks(rotation=15)\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.65\n        y = p.get_y() + p.get_height()+50\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.xlabel('Types of ML libraries \/ frameworks',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","25fa7702":"plt.figure(figsize=(16,8))\nax=sns.countplot(x=data['Q25'],order=data['Q25'].value_counts().index,palette='rocket')\ntotal = len(data['Q25'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100*p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.3\n        y = p.get_y() + p.get_height()+50\n        ax.annotate(percentage, (x, y))\n\nplt.xlabel('Education Type ',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Money Spend VS Response',fontsize=20)\nplt.xlabel('Money spend',size=15)\nplt.ylabel('Response',size=15)\nplt.show()","60e5fdc5":"data[\"Q36_Part_9\"].replace({\"I do not share my work publicly\":\"Don't share work\"}, inplace=True)\n\nQ36_1=data['Q36_Part_1']\nQ36_2=data['Q36_Part_2']\nQ36_3=data['Q36_Part_3']\nQ36_4=data['Q36_Part_4']\nQ36_5=data['Q36_Part_5']\nQ36_6=data['Q36_Part_6']\nQ36_7=data['Q36_Part_7']\nQ36_8=data['Q36_Part_8']\nQ36_9=data['Q36_Part_9']\nQ36_OTHER=data['Q36_OTHER']\n\nQ36_total=pd.concat([Q36_1,Q36_2,Q36_3,Q36_4,Q36_5,Q36_6,Q36_7,Q36_8,Q36_9,Q36_OTHER],ignore_index=True)\nplt.figure(figsize=(16,8))\nax=sns.countplot(Q36_total,order=Q36_total.value_counts().index,palette='rocket')\ntotal = len(Q36_total)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100*p.get_height()\/total)\n        x = p.get_x() + p.get_width()\/2.5\n        y = p.get_y() + p.get_height()+50\n        ax.annotate(percentage, (x, y))\n\nplt.xlabel('Education Type ',size=15)\nplt.ylabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Education-wise Distribution',fontsize=20) \nplt.show()","749cf41a":"Q37_1=data['Q37_Part_1']\nQ37_2=data['Q37_Part_2']\nQ37_3=data['Q37_Part_3']\nQ37_4=data['Q37_Part_4']\nQ37_5=data['Q37_Part_5']\nQ37_6=data['Q37_Part_6']\nQ37_7=data['Q37_Part_7']\nQ37_8=data['Q37_Part_8']\nQ37_9=data['Q37_Part_9']\nQ37_10=data['Q37_Part_10']\nQ37_11=data['Q37_Part_11']\nQ37_OTHER=data['Q37_OTHER']\nQ37_total=pd.concat([Q37_1,Q37_2,Q37_3,Q37_4,Q37_5,Q37_6,Q37_7,Q37_8,Q37_9,Q37_10,Q37_11,Q37_OTHER],ignore_index= True)\n\nplt.figure(figsize=(16,8))\nax=sns.countplot(y=Q37_total,order=Q37_total.value_counts().index,palette='rocket')\ntotal=len(Q37_1)\nfor p in ax.patches:\n        percentage = '{:.0%}'.format(p.get_width()\/total)\n        x = p.get_x() + p.get_width()+20\n        y = p.get_y() + p.get_height()\/1.60\n        ax.annotate(percentage, (x, y),size=12)\n        \n        \nplt.ylabel('Types of ML libraries \/ frameworks',size=15)\nplt.xlabel('Number Of Response',size=15)\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.title('Machine learning libraries \/ framework vs Number of response ',fontsize=18)    \nplt.show()","7f7ffeb0":"<font color='blue'>*Professor Electron : Very well Mr. Kamlesh, then which on coding language should we choose for coding foundation program?*","efde98fb":"<font color='red'>Me: yes professor proton I am ready with my home work so shall we start?","bb9afdcd":"<font color='red'>Me: As you see, tableau and power BI leads the chart and without a doubt, these two are currently the most famous BI tools, I would like to suggest to include it in the curriculum for Bachelor's and master's program. these BI tools are available in the student version which is a free and premium version for business so, according to that select your version. ","ca8ed192":"<font color='blue'>*Prof. Proton: Well Mr. Kamlesh, I think we are done with discussing all the primary requirements for the upcoming degree program. we will talk about this more thoroughly in the next meeting.*","c36500b3":"## Background Storyline:-\n","4b86ca75":"<font color='red'>Me: Yes, Prof. Neutron there are many hosted notebooks products for data science programming the most valuable advantages is that you don't have to download, install and Update the machine learning frameworks and libraries in hosted notebooks products but you have to do it for locally running IDE's like in pycharm, Rstudio, and Jupyter, etc. in your own computer system.","a8b2aa43":"<font color='red'>Me: I am fine with all the rules And I have used the data from one of the trusted source called kaggle which is an online community of data scientists and machine learning practitioners. the data which I used consists of 20037 responses from data science enthusiasts like me and they have answered the same question in this survey which is quite similar to the questions you three have.","d7ae2725":"<font color='red'>Me: Prof. Proton, the pricing of the cloud computing platform depends on many factors like the which type of survices you are using and How long your cloud computing platfrom is running, discount offres and etc., In kaggle survey, kaggle asked the quite similar question to kagglers, that Approximately how much money have you spent on Cloud computing platform in last 5 years? the Answer is as follow.","603313e9":"<font color='red'>Me: Yes,Prof. Proton your are right most of people use GPU's for faster computation and better result as you see in kaggle survey 41.5% people said they use GPU's for advanced data science tasks of deep learning and 4.8% said they use TPU's , TPU's are new in data science community so it is obvious less people use TPU's but in future more people will use TPU's as they are faster than GPU's. TPU's are specially develeped by Google for deep learning tasks. As previously we saw most people said they use hosted notebook platform like kaggle notebook and google colab. both of these two hosted notebook platform provide free GPU's and TPU's access so there is no need to get actual GPU for deep learning task. ","93f1fb32":"<font color='blue'>*Prof. Neutron : we just talked about BI tools, from that I remembered about data visualization, which data visualization libraries\/frameworks we should include in the curriculum?*","8ddfe585":"<font color='red'>Me: Yes Professor Proton you can expexted very good response from overseas studenst also, specially from India, Brazil, Japan, Russia, china, Nigeria, United Kingdom and canada. you can also arrenge some financial aid program and scholarship program for upcoming overseas stuents.","7771a1b7":"<font color='blue'>*Prof. Neutron: along with computer vision we should include NLP also, which NLP methods should we include in the curriculum?* ","22a88db2":"<font color=\"red\">Me: A very good Point Professor Proton as you see in kaggle survey,22.5% of people have coding experience less than 1-2 year , 16.5% have coding experience less than 1 years and 5.6% of people have never written a code which is quite important so its a good idea to organise coding foundation program for this students.\n","cc9e9592":"<font color='red'>Me: In kaggle survey,31.6% people said they use google colab hosted notebook on regular basis and 26.4% said they use kaggle notebook on regular basis for data science task, prof. Neutron you can include these two hosted notebook practices in the course curriculum along with these Binder, Azure notebook and IBM watson studio also got good response you can also think this hosted notebbok platform as second option.","94b29c42":"<font color=\"blue\">*Professor Proton: Professor Proton: As you said Mr. Kamlesh, we can expect students and people from other industry than data science, so Is there any need to organise any coding foundation classes for this students before starting main degree program?*","eb7a079c":"<font color='blue'>*Professor Electron: very fine Mr.kamlesh, but in what number we can expect the applicants in bachelors and masters program?*","49e2091e":"<font color='red'>Me: in the kaggle data science survey, 18% of people said they use transfer learning model like VGG, inception, ResNet, etc. and 11% said they use general-purpose tools like CV2, PIL, etc., you should include both these in masters and bachelors program as these are easy and effective computer vision method. 10% of people said they use YOLO for object detection and 5% said they use GAN for Computer vision use should include in master's program only as these are a little bit advanced methods of computer vision.","1dd28094":"<font color='blue'>*Prof. Electron: As we are talking about machine learning algorithms, Computer vision is one of the best applications of machine learning. I think we should include computer vision in the curriculum, so Mr. Kamlesh what you think which computer vision methods should be included?*","c7c1cf4b":"<font color='blue'>*Professor Electron: rules are simple,*\n    1. We want as much as many Information you can give.\n    2. No complex Graphs Simple Graph that eveyone can understand.\n    3. We dont want lengthy meeting, Our meeting should end in 30 Minutes.\n    4. Data which you used should be from trusted Source.\n","03d865c2":"<font color='red'>Me: In the survey,11% said they use the word embedding technique for NLP you should include this in bachelor's and master's programs, where 8% and 7% of people in the survey said they use encoder-decoder model and transformer language models for NLP resp. you should include these two in the master's program only.","57012f0f":"<font color='blue'>*Prof. Electron: where do data science people publicly share or deploy most of their data analysis or machine learning applications? because we want our students to be part of that environment. getting recognized for your work will give them confidence and also the feedback on their work will improve their work.*","55a07b6e":"<font color='red'>only 9.1% of kagglers said they have spent around 1000-9,999 dollars approx. in the last five years and 8.8 % said they had to spend around 100-999 dollars in last five years on a cloud computing platform and most of Kagglers answered 'NAN' or said zero dollars, so on such little response we can't make a strong prediction but by considering this little response we can approx. predict the course fees between 500-800 dollars for 9 months. ","a3c9efc1":"<font color='red'>Me: 14% of people in the kaggle survey said they use AWS on regular basis and 11% said they use the google cloud platform on regular basis and 9% of people favor Microsoft azure. Any one of these three cloud computing platforms will be best for the curriculum, all of them have their own pros and cons, I think this decision should be taken by students which cloud computing platform they want to learn. you can keep this as an extra optional course in both master's and bachelor's degree programs. ","f7a146dd":"<font color='blue'>*Professor Neutron: And which languages should we include in program curriculum for bachelors and masters program?*","a2c7f990":"<font color='blue'> *Professor Proton: nice to see you too Mr.Kamlesh. so as we discussed in our mail conversation you know why we are here and I hope you are ready with your home work.*","5a6087a2":"<font color='red'>Me: very good queation Prof. Electron , business intelligence is one of the most required thing in data science for business intelligence you will be BI tools, these BI tools are the software which help in BI technologies which provides historical, current, and predictive views of business operations. ","e0835e98":"<font color='red'>Me: In kaggle data science survey,53%, 44%, 29% ,and 26% kagglers said they use linear or logistics regression, Decision tree or random forrest, CNN and Gradient Boosting algorithms respectively, as these are most popular and easy to learn algorithms these should be include in both masters and bachelors program. RNN, DNN ,transformer networks and GAN are the advanced algorithms these should be include in the masters program.","2c454e12":"<font color='blue'>*Prof. Electron: we just discussed which ML \/ DL libraries should be included in the curriculum, now I think we should discuss which Algorithms should we include in both the programs?*","8730ea58":"<font color='blue'>*Professor Proton: Before we start if you don't mind Mr.Kamlesh, Professor Electron have set some ground rules for this discussion as you know Mr. Kamlesh, Electron never bond with other atom easily as they have to follow many rules (professor Proton said this in a witty way)*","4eddaba2":"<font color='red'>Me: 37% prefer Coursera as an online education platform, 23% said Udemy, 12% said Edx, and 10% said Udacity any of this option will be great for your online education courses.","df21bc3a":"<font color='red'>Me: Professor Electron as the number shows, most response are from the age groups 22-24 ,25-29 and 30-34 which is ideal for master degree program in data science, as bachelors degree programs in most of countries students complete by the age of 21. and 17% response are from 18-21 age group which is ideal for bachelors degree and 10% response are from 35-39 age group which is ideal for PhD so we can conclude that, we can expect more admission for masters program and quite good response for bachelors degree program.   ","63b3a1d6":"<font color='blue'>*Prof. Proton: Mr. Kamlesh, I have heard that some of the machine learning applications work fine on CPU but most of the advanced data science tasks like deep learning application require GPU is it true? and I have also heard that GPU costs way more than the CPU. getting GPU in a much larger number will be like Pay top dollar?*","16c0b31e":"<font color='red'>Me : Prof. Neutron, As we can see in kaggle survey, Python is the most popular language for data science and it is easy to learn. so you can include python in both master's and bachelor's programs. SQL is second and R is the third most popular languages which are also easy to learn these two you should include in both masters and bachelors program along with python. C++ is also a popular option which you can include in the bachelor's program and JAVA is more advanced as compared to C++ so you should include it in the master's program. where C, javascript, MatLab, and Bash are also good languages which you can put in an option for students so they can choose any of this according to their interest.","10d997c1":"<font color='red'>Me: Yes, Professor Electron please go ahead.","cb032047":"<font color='blue'>*Prof Neutron: Mr. Kamlesh, our university also wants to start an online certification program in data science, this course will be considered as prerequisites for the actual degree program. for this which online education platform should we choose?*","16c7b972":"<font color='blue'>*Prof Neutron: Mr kamlesh, I heard that other than IDE's there are hosted notebooks products for programming can you throw some light on this?*","a7402a0b":"<font color='red'>Me: 51% people in kaggle survey said they use scikit-learn on regular basis,where 35%, 31%, 21% ,and 20% people use Tensorflow, keras, pytorch ,and xgboost on regular basis. I would suggest to include Scikit-learn, keras(tensorflow 2.0) and XGboost in both masters and bachlors degree program as these are the basic libraries\/ frameworks in Machine learning and deep learning respectively. you can include Pytorch and fast.ai in masters program.","fa585501":"<font color='blue'>*Prof. Proton: Mr. Kamlesh, we want to include cloud computing platforms in the curriculum as well, for that what are the best options?*","a9c5a423":"<font color='blue'>*Prof. Proton: As you said, Mr. Kamlesh, we should be kept the Cloud computing course as an extra course, how much money it will cost students to take part in this extra course? as these extra course fees will be separate from the regular degree course*. ","7d8b740c":"<font color='blue'>*Prof. Electron: very well Mr. Kamlesh, then which IDE's OR Programming Platforms you suggest?*","01a6a8c6":"<font color='blue'>*Professor Neutron: As all the ground rules for meeting are clear let's start, So my first question is which program our university should start Bachelors Or Masters?*","311f3f2c":"<font color='red'>Me: As you see Professor Electron most of the kaggler in survey said Python is best language for a person who is new in data science is python. so you should organize python foundation coding program.","4f767109":"<font color = 'blue'>*Professor Neutron: can we expect admission from people from other domains also who wants to change their career path?*","6768d470":"<font color='blue'>*Professor Proton: can our university expect a good response from overseas students also for the degree program?*","6fa9c21f":"<font color='red'>Me: Prof. Neutron, as expected in the kaggle data science survey Matplotlib, seaborn, plotly, and ggplot got the most number of response these libraries are very good for data visualization you should include all these 4 libraries in the masters and bachelors degree program. ","68e091a5":"<font color='blue'>*Prof. Electron: very well, Mr. Kamlesh, we are pretty clear now about the system infrastructure and softwares , which are needed for the course curriculum. would you like to suggest any other thing related to the system and software which we should include in the curriculum ?*","4e5671c0":"<font color='red'>Me: A good  very goof question Prof. Electron, 56% of people in the kaggle survey said they use Jupyter notebook which is open source so there is no need to take a license to use it. in the survey, 25.4%, 19.1%, 16.4% of people said they Pycharm, Rstudio(for R language), and Spyder respectively. same as of jupyter these all are open source and free to use. VS code which is also a great editor from Microsoft and it is open source as well.","74c77376":"<font color='red'>Me: As you see Professor Neutron, 39% peoples have Master's degree or want to earn masters degree in next two years which is huge and 35% people have Bachelor's Degree or want to earn masters degree in next two years. so your university should plan both masters and bachloers dregree in data science.your university can plan for PhD program also as 11% people have PhD or wants to do PhD which we can't ignore.","57b49229":"<font color='blue'>*Prof Proton: Mr. Kamelsh, you just suggested the data visualization libraries, like that now we would like to know which machine learning libraries\/framework we should include in the curriculum?*","0fb6c7c9":"<font color='red'>Me: Nice to see you Professor Protons, Professor Neutron and Professor Electron. a very warm welcome to Data-X analytic inc. ","6e9b5a21":"<font color='red'>Me: thank you, Prof. Proton, Prof Neutron, and Prof. Electron, thanks for your time. we will meet soon again for the next meeting.","5ab0f90e":"### University of Atomia a very well known University knows Data science is the next big thing after internet and they want to start new degree program in data science at their campus, University of Atomia want help from my company named Data-X Analytic inc. to structure this new degree program. for this university of atomia send the panel of 3 professors, Professor Proton, Professor Neutron and Professor Electron to have some discussion with me on their new dregree program structure. Our Discussion starts as follows.","09e33a5c":"<font color='red'>Me: Yes Professor Neutron, As you see in kaggle survey,Other than 25.8% students, 9.8% of sofware engineers, 4% of businees Analyst have intrest in data science who want to change their career path into a data scientist or data analyst and 8.2% of people are currently unemployeed and they have intrest in data science, a new college degree in data science may increase their chances to get new job in data science field.","21d9eb31":"<font color='red'>Me: as you see most of the data science people share their work on GitHub and after that second most popular choice is kaggle. Github is more of all types of software development and codes related to many languages but kaggle is a pure data science community. I think it's a good idea to encourage your students to share their work publicly on these two platforms. if students want they can choose more options like google colab and personal blog."}}