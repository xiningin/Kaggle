{"cell_type":{"c8d9c2a6":"code","28da8bd1":"code","232280bf":"code","11bec843":"code","d4126e7a":"code","2c67aa79":"code","6a9e60d4":"code","cfb3e822":"code","f2a2c321":"code","61a9e10d":"code","d19cb8d0":"code","515c23f2":"code","32d46e3b":"code","a1c131ef":"code","069e88f5":"code","a91567e6":"code","ef3d79e2":"code","70930079":"code","7e548a55":"code","f1b4b025":"code","29d77006":"code","609bd09a":"code","0d78142a":"code","791d740f":"code","9160852d":"code","ee60fcae":"code","15854b9c":"markdown","ae09d060":"markdown","c52c97a6":"markdown","6b5530c0":"markdown","690535a8":"markdown","4c1ef899":"markdown","d908aa13":"markdown","7e5c8cb6":"markdown","978a78c0":"markdown","6350952f":"markdown","968f4e44":"markdown","b3dc93b5":"markdown"},"source":{"c8d9c2a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#machine learning imports\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\nimport os\nprint(os.listdir(\"..\/input\"))","28da8bd1":"# Read the dataset \nabalone = pd.read_csv('..\/input\/abalone-dataset\/abalone.csv')\nabalone","232280bf":"abalone.columns","11bec843":"abalone.hist(figsize=(20,10),bins=9)","d4126e7a":"plt.figure(figsize=(15,9))\nsns.countplot(x='Sex',data=abalone)","2c67aa79":"ulimit = np.percentile(abalone['Length'].values, 95)\nllimit = np.percentile(abalone['Length'].values, 5)\nfiltered = abalone[(abalone['Length']<ulimit) & (abalone['Length']>llimit)]\n\nfiltered.hist(figsize=(20,10),bins=30)","6a9e60d4":"categorical = ['Sex']\nX = abalone.drop(categorical,axis=1)","cfb3e822":"scaler = StandardScaler()\nlb = LabelBinarizer()\nX = scaler.fit_transform(X)\nX = np.c_[X,lb.fit_transform(abalone['Sex'])]","f2a2c321":"X_train,X_test,y_train,y_test = train_test_split(X,abalone['Rings'])","61a9e10d":"reg = DecisionTreeRegressor()\nreg.fit(X_train,y_train)","d19cb8d0":"reg.score(X_test,y_test)","515c23f2":"orders = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\",parse_dates=[('order_purchase_timestamp'),('order_delivered_customer_date')])\norders","32d46e3b":"orders['purchase_month'] = orders['order_purchase_timestamp'].dt.month\norders","a1c131ef":"plt.figure(figsize=(15,9))\nsns.countplot(x='purchase_month',data=orders)","069e88f5":"reviews = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\nreviews","a91567e6":"order_reviews= orders.merge(reviews, on='order_id')\norder_reviews","ef3d79e2":"avg_score = order_reviews.groupby(\"purchase_month\").mean()['review_score']\navg_score","70930079":"plt.figure(figsize=(15,9))\nsns.barplot(x=avg_score.index,y=avg_score)","7e548a55":"review_dataset=order_reviews.groupby(\"order_status\").size()\nreview_dataset['avg_score'] = order_reviews.groupby(\"order_status\").mean()['review_score']\n\nreview_dataset","f1b4b025":"oproducts = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")\noproducts.head()","29d77006":"pcname = pd.read_csv(\"..\/input\/brazilian-ecommerce\/product_category_name_translation.csv\")\npcname.head()","609bd09a":"joined = oproducts.merge(pcname, on='product_category_name')\njoined.head()","0d78142a":"ooitems = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\nooitems.head()","791d740f":"second_join = ooitems.merge(joined, on='product_id')\nsecond_join.head()","9160852d":"final_join= order_reviews.merge(second_join, on='order_id')\nfinal_join.head()","ee60fcae":"top_ten = final_join.groupby(\"product_category_name_english\").mean()['review_score'].sort_values(ascending=False)[:10]\ntop_ten","15854b9c":"6. Create a bar chart of number (count) of orders placed by month using seaborn.","ae09d060":"4. Use the dataset to predict the 'Rings' column, including encoding 'Sex', scaling the other columns and splitting the data.  Use the imported DecisionTreeRegressor model.  Score the model.","c52c97a6":"7. Read in the \"olist_order_reviews_dataset.csv\" dataset as a dataframe named \"reviews\".  Join this dataset with the \"orders\" dataframe to create one named \"order_reviews\". Create a barchart of the average \"review_score\" by \"purchase_month\".","6b5530c0":"2. Create a barchart with the counts of each of the values in the 'Sex' column","690535a8":"Using the Abalone Dataset:\n1. Create a histogram of the dataset's columns\n2. Create a barchart with the counts of each of the values in the 'Sex' column\n3. Trim the top and bottom 5% of readings for 'Length' and plot a histogram with 30 bins of the remaining, filtered data.\n4. Use the dataset to predict the 'Rings' column, including encoding 'Sex', scaling the other columns and splitting the data.  Use the imported DecisionTreeRegressor model.  Score the model.\n\nUsing the Brazilian E-Commerce Public Dataset:\n5. Read the \"olist_orders_dataset.csv\" file in as a Dataframe called \"orders\".  Parse the \"order_purchase_timestamp\" and \"order_delivered_customer_date\" columns as dates.  Add a column named \"purchase_month\" that is the month in which an order was purchased.  (if the order_purchase_timestamp is \"2017-10-02 10:56:33\" the purchase_month should be \"10\")\n6. Create a bar chart of number (count) of orders placed by month using seaborn.\n7. Read in the \"olist_order_reviews_dataset.csv\" dataset as a dataframe named \"reviews\".  Join this dataset with the \"orders\" dataframe to create one named \"order_reviews\". Create a barchart of the average \"review_score\" by \"purchase_month\".\n8. Create a new dataframe called \"review_dataset\".  It should have one column that lists the count of reviews by \"order_status\" and another that is the average \"review_score\" by \"order_status\".  The index should be the \"order_status\".\n9. Read in the \"olist_products_dataset.csv\" and \"product_category_name_translation.csv\".  Join them so you have a dataset with both the \"product_id\" and the \"product_category_name_english\".  Read in the \"olist_order_items_dataset.csv\" dataset and use it to join the new dataset with \"product_category_name_english\" column to your existing \"order_reviews\" dataset.  Use this final dataset to find the top 10 \"product_category_name_english\" by average \"review_score\".","4c1ef899":"1. Create a histogram of the dataset's columns","d908aa13":"9a. Read in the \"olist_products_dataset.csv\" and \"product_category_name_translation.csv\".  Join them so you have a dataset with both the \"product_id\" and the \"product_category_name_english\".  Read in the \"olist_order_items_dataset.csv\" dataset and use it to join the new dataset with \"product_category_name_english\" column to your existing \"order_reviews\" dataset.  ","7e5c8cb6":"5. Read the \"olist_orders_dataset.csv\" file in as a Dataframe called \"orders\".  Parse the \"order_purchase_timestamp\" and \"order_delivered_customer_date\" columns as dates.  Add a column named \"purchase_month\" that is the month in which an order was purchased.  (if the order_purchase_timestamp is \"2017-10-02 10:56:33\" the purchase_month should be \"10\")","978a78c0":"3. Trim the top and bottom 5% of readings for 'Length' and plot a histogram with 30 bins of the remaining, filtered data.","6350952f":"8. Create a new dataframe called \"review_dataset\".  It should have one column that lists the count of reviews by \"order_status\" and another that is the average \"review_score\" by \"order_status\".  The index should be the \"order_status\".","968f4e44":"9b. Use this final dataset to find the top 10 \"product_category_name_english\" by average \"review_score\".","b3dc93b5":"##  Abalone Age Prediction - Abalone Dataset from Rodolfo Mendes\nDescription- Predicting the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem. \n\n## Brazilian E-Commerce Public Dataset by Olist\nThis dataset has information about the customer and its location. Use it to identify unique customers in the orders dataset and to find the orders delivery location."}}