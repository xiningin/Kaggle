{"cell_type":{"f254954e":"code","b87de603":"code","d0ac2609":"code","7368cf77":"code","37c6c35f":"code","c0b8c3b7":"code","90529e5f":"code","6dfa1bfe":"code","c3131fd0":"code","b2c10d0c":"code","e6291ea7":"code","cfaba21a":"code","75248987":"code","f2279c5b":"code","dc638aaa":"code","3f054258":"code","1729a0b2":"code","47b7057d":"code","b83c89c4":"code","b1547dfb":"code","e5f17910":"code","e0d6a6cb":"code","0219d9ae":"code","c2001f63":"code","16738af5":"code","11c60af9":"code","9aa70fe7":"code","2efd2d19":"code","f058cbaa":"code","b49c52f1":"code","07bb6a39":"code","b84a9977":"code","1921b0bb":"code","cce6bc6c":"code","49df7d2d":"code","c8888982":"code","e2ef893f":"code","000fbfb4":"code","690216a0":"code","47d4c547":"code","a389e9ba":"code","c135fd1f":"markdown","53642b9f":"markdown","56323d67":"markdown","d69a6bd1":"markdown","21a4b761":"markdown","b94fa3d4":"markdown","a93cd892":"markdown","bee4dfec":"markdown"},"source":{"f254954e":"# We need to pip install these two versions because it gives me some errors otherwise\n\n# This can take some time\n\n!pip install \"torch==1.4\" \"torchvision==0.5.0\"","b87de603":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re\n\nfrom PIL import Image\n\nimport time\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom albumentations.pytorch import transforms\n\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\n\nfrom matplotlib import pyplot as plt\n\n\nDIR_INPUT = '\/kaggle\/input\/leaf-detection'\nDIR_TRAIN = f'{DIR_INPUT}\/train'\nDIR_TEST = f'{DIR_INPUT}\/test'\n\n# Loading the device now\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","d0ac2609":"train_df = pd.read_csv(os.path.join(DIR_INPUT,\"train.csv\"))\n","7368cf77":"train_df['x'] = -1\ntrain_df['y'] = -1\ntrain_df['w'] = -1\ntrain_df['h'] = -1\n\ndef expand_bbox(x):\n    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n    if len(r) == 0:\n        r = [-1, -1, -1, -1]\n    return r\n\ntrain_df[['x', 'y', 'w', 'h']] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\ntrain_df.drop(columns=['bbox'], inplace=True)\ntrain_df['x'] = train_df['x'].astype(np.float)\ntrain_df['y'] = train_df['y'].astype(np.float)\ntrain_df['w'] = train_df['w'].astype(np.float)\ntrain_df['h'] = train_df['h'].astype(np.float)","37c6c35f":"image_ids = train_df['image_id'].unique()\nvalid_ids = image_ids[-4:]\nvalid_ids = np.append(valid_ids,image_ids[:4])\ntrain_ids = image_ids[4:-4]\n\nvalid_df = train_df[train_df['image_id'].isin(valid_ids)]\ntrain_df = train_df[train_df['image_id'].isin(train_ids)]\n\nvalid_df.shape, train_df.shape","c0b8c3b7":"class LeafDataset(Dataset):\n\n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n\n        image_id = self.image_ids[index]\n        records = self.df[self.df['image_id'] == image_id]\n\n        image = cv2.imread(f'{self.image_dir}\/{image_id}', cv2.IMREAD_COLOR)                \n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)\n        image = np.reshape(image,image.shape+(1,))\n        image \/= 255.0\n\n        boxes = records[['x', 'y', 'w', 'h']].values\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n\n        # there is only one class\n        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n        \n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n\n        if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n\n        return image, target, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","90529e5f":"# This Albumentation for now it is empty.\ndef transform():\n    return A.Compose([        \n#         A.Cutout(num_holes=10,max_h_size=15,max_w_size=15,p=1),\n            \n#         A.OneOf([\n#             A.RandomSunFlare(src_radius=200,num_flare_circles_lower=6,num_flare_circles_upper=8,p=1),\n#             A.RandomRain(slant_lower=-10,slant_upper=10,drop_length=20,drop_width=1,p=1),\n#             A.RandomFog(fog_coef_lower=0.05, fog_coef_upper=0.1, alpha_coef=0.08, p=1),  \n#         ], p=1),\n#         A.OneOf([\n#             A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, brightness_by_max=True, p=1),\n#             A.RandomGamma(gamma_limit=(80,165),p=1),  \n#         ], p=1),      \n        ToTensorV2(p=1.0),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))","6dfa1bfe":"train_dataset = LeafDataset(train_df, DIR_TRAIN, transform())\nvalid_dataset = LeafDataset(valid_df, DIR_TRAIN, transform())\n\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n","c3131fd0":"class Averager:\n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total \/ self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n","b2c10d0c":"# HELPER FUNCTIONS FOR VIZUALISING \/ PREDICTING\n\ndef get_boxes(tensor,index,score=0.5):\n\n    if index >= len(tensor)  or index<0:\n        return 0\n    \n    temp_boxes = []\n    for i in range(len(tensor[index]['boxes'])):\n        if tensor[index]['scores'][i] > score:\n            temp_boxes.append(tensor[index]['boxes'][i].cpu().detach().numpy().astype(np.int32))    \n        \n    return temp_boxes    \ndef get_sample_image(itr):\n    images, targets, image_ids = next(it)\n    images = list(image.to(device) for image in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n    boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n    sample = images[0].permute(1,2,0).cpu().numpy()\n    sample = np.reshape(sample,(sample.shape[1],sample.shape[1]))\n    \n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    \n    for box in boxes:\n        cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      0, 2)\n\n    ax.set_axis_off()\n    ax.imshow(sample,cmap='gray')\ndef get_validation_image(itr):\n    images, targets, image_ids = next(itr)\n    images = list(img.to(device) for img in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n    \n    boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n    sample = images[0].permute(1,2,0).cpu().numpy()\n    \n    model.eval()\n\n    outputs = model(images)\n    outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n    boxes = get_boxes(outputs,0)\n\n\n    # boxes = outputs[1]['boxes'].cpu().detach().numpy().astype(np.int32)\n\n\n    sample = images[0].permute(1,2,0).cpu().numpy()\n    \n    boxes = get_boxes(outputs,0)\n\n    sample = images[0].permute(1,2,0).cpu().numpy()\n    sample = np.reshape(sample,(sample.shape[1],sample.shape[1]))\n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    \n    for box in boxes:\n        cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      0, 2)\n\n\n    ax.set_axis_off()\n    ax.imshow(sample,cmap='gray')\n    \ndef load_test_dataset():\n    data_path = DIR_TEST\n    test_dataset = torchvision.datasets.ImageFolder(\n        root=data_path,\n        \n        transform=torchvision.transforms.Compose([\n            torchvision.transforms.Grayscale(num_output_channels=1),\n            torchvision.transforms.ToTensor(),]\n    ))\n    \n    test_loader = torch.utils.data.DataLoader(    \n        test_dataset,\n        batch_size=1,\n        num_workers=1,\n        shuffle=False\n    )\n    return test_loader\n\ndef get_test_image(itr,score = 0.5):\n    image, targets= next(itr)\n    sample = image\n    \n    image = image.to(device)\n    model.eval()\n    outputs = model(image)\n    \n    outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]   \n    \n    boxes = get_boxes(outputs,0,score)\n    \n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    print(sample.shape)\n    img = sample[0].permute(1,2,0).cpu().numpy()\n    print(img.shape)\n    \n    \n    img = np.array(img)\n    img = np.reshape(img,(img.shape[1],img.shape[1]))\n    print(img.shape)\n    for box in boxes:\n        x,y,w,h = box\n        \n        cv2.rectangle(np.float32(img),\n                      (int(box[0]), int(box[1])),\n                      (int(box[2]), int(box[3])),\n                      0, 2)\n    ax.set_axis_off()\n    ax.imshow(img,cmap='gray')\n","e6291ea7":"it = iter(train_data_loader)\nget_sample_image(it)","cfaba21a":"get_sample_image(it)","75248987":"get_sample_image(it)","f2279c5b":"get_sample_image(it)","dc638aaa":"get_sample_image(it)","3f054258":"get_sample_image(it)","1729a0b2":"get_sample_image(it)","47b7057d":"get_sample_image(it)","b83c89c4":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\nnum_classes = 2  # 1 class (leaf) + background\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","b1547dfb":"model.to(device)\nprint(\"Model loaded\")","e5f17910":"params = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nlr_scheduler = None\n\nnum_epochs = 15","e0d6a6cb":"loss_hist = Averager()\nitr = 1\n\nprevious_epoch = 1000\nes_rate = 0\n\nes_threshold = 2 # How many epochs without improvement to early stop\n\n\nfor epoch in range(num_epochs):\n    loss_hist.reset()\n    min_loss = 1000\n    \n    for images, targets, image_ids in train_data_loader:\n        \n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n\n        loss_hist.send(loss_value)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        \n        if itr % 50 == 0:\n            print(f\"Iteration #{itr} loss: {loss_value}\")\n        \n        itr += 1\n                \n            \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n    min_loss = loss_hist.value\n    \n    if min_loss < previous_epoch:\n        previous_epoch = min_loss\n        es_rate = 0\n        \n    else:\n        if es_rate < es_threshold:\n            es_rate += 1\n        elif es_rate >= es_threshold:\n            break\n    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")   \n","0219d9ae":"it = iter(valid_data_loader)","c2001f63":"get_validation_image(it)","16738af5":"get_validation_image(it)","11c60af9":"get_validation_image(it)","9aa70fe7":"get_validation_image(it)","2efd2d19":"get_validation_image(it)","f058cbaa":"get_validation_image(it)","b49c52f1":"get_validation_image(it)","07bb6a39":"get_validation_image(it)","b84a9977":"image_list = os.listdir(DIR_TEST+\"\/leaf\")\nprint(image_list)","1921b0bb":"it = iter(load_test_dataset())\n","cce6bc6c":"start = time.time()\nget_test_image(it,0.5)\nprint(time.time()-start)","49df7d2d":"start = time.time()\nget_test_image(it,0.5)\nprint(time.time()-start)","c8888982":"start = time.time()\nget_test_image(it,0.5)\nprint(time.time()-start)","e2ef893f":"start = time.time()\nget_test_image(it,0.5)\nprint(time.time()-start)","000fbfb4":"start = time.time()\nget_test_image(it,0.5)\nprint(time.time()-start)","690216a0":"start = time.time()\nget_test_image(it,0.50)\nprint(time.time()-start)","47d4c547":"start = time.time()\nget_test_image(it,0.50)\nprint(time.time()-start)","a389e9ba":"torch.save(model, 'leaves_fasterrcnn_model.pth')","c135fd1f":"# Testing","53642b9f":"## Conclusion\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" button at the top of the kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!","56323d67":"# Loading ResNet50 trained on COCO","d69a6bd1":"# Validation (On data from Training)","21a4b761":"# Training","b94fa3d4":"# Sample of training data augumented\n","a93cd892":"# Reading and parsing the CSV","bee4dfec":"## Introduction\n\nGot help from this notebook: https:\/\/www.kaggle.com\/pestipeti\/pytorch-starter-fasterrcnn-train\n\nThis is a notebook which can be used to detect the leaves in this dataset. At the end there are 6 test images, and as you can see even with a small dataset, it performs pretty well\n"}}