{"cell_type":{"c44a8e8b":"code","b0ef7353":"code","8cb226a2":"code","4c1812c7":"code","a8bf2059":"code","17e899d0":"code","1aea656f":"code","a47c7072":"code","008b4a95":"code","a6e7c483":"code","3f4c17f9":"code","6ca4c5bc":"code","d22a47c0":"code","bcd39959":"code","1adce2d3":"code","ea9207d1":"code","bfa5d541":"code","cb14058b":"code","2ecae69c":"code","f4f055ed":"code","baf4d2ec":"code","e398e22f":"code","e78f0eac":"code","fa173352":"markdown","060da5fe":"markdown","d892063d":"markdown","b0cd5cd5":"markdown","2374cfbc":"markdown","90b4528a":"markdown","7a44c4f1":"markdown","399d3bde":"markdown","43ad823e":"markdown","afcccac8":"markdown","24937ef6":"markdown","fa3bbf91":"markdown","4f673561":"markdown","0a259db2":"markdown","a5c926a0":"markdown","5fe1e0b7":"markdown","0b86dbbb":"markdown","9219290f":"markdown","ab165b3a":"markdown","eb115408":"markdown","904d84fb":"markdown","942190d0":"markdown"},"source":{"c44a8e8b":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport copy\nimport torch.optim as optim","b0ef7353":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","8cb226a2":"data = pd.read_csv(\"..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/labels.csv\")\ndata.head()","4c1812c7":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(data[\"label\"])\ndata[\"label\"] = le.transform(data[\"label\"])","a8bf2059":"for i in data.index:\n    data[\"path\"].iloc[i] = data[\"path\"].iloc[i].replace(\"\\\\\", \"\/\")","17e899d0":"def split(dt):\n    idx = []\n    a = pd.DataFrame()\n    b = pd.DataFrame()\n    for i in data.index:\n        if data[\"is_validation\"].iloc[i] == 1:\n            a = a.append(dt.iloc[i])\n            idx.append(i)\n        if data[\"is_final_validation\"].iloc[i] == 1:\n            b = b.append(dt.iloc[i])\n            idx.append(i)\n    dt = dt.drop(dt.index[idx])\n    a = a.reset_index()\n    b = b.reset_index()\n    dt = dt.reset_index()\n    return dt,a,b\n        ","1aea656f":"train_df, val_df, test_df = split(data)\nprint(\"Length of train dataset: \", len(train_df))\nprint(\"Length of validation dataset: \" ,len(val_df))\nprint(\"Length of test dataset: \", len(test_df))","a47c7072":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","008b4a95":"val_df.label = val_df.label.astype(np.int64)\ntest_df.label = test_df.label.astype(np.int64)","a6e7c483":"class Bee_Wasp(Dataset):\n    def __init__(self, df:pd.DataFrame, imgdir:str,\n                 transforms=None):\n        self.df = df\n        self.imgdir = imgdir\n        self.transforms = transforms\n    \n    def __getitem__(self, index):\n        im_path = os.path.join(self.imgdir, self.df.iloc[index][\"path\"])\n        x = cv2.imread(im_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n\n        if self.transforms:\n            x = self.transforms(x)\n            \n        y = self.df.iloc[index][\"label\"]\n        return x, y\n    \n    def __len__(self):\n        return len(self.df)","3f4c17f9":"train_data = Bee_Wasp(df=train_df,\n                        imgdir=\"..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\",\n                        transforms=train_transform)\n\nval_data = Bee_Wasp(df=val_df,\n                      imgdir=\"..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\",\n                      transforms=test_transform)\n\ntest_data = Bee_Wasp(df=test_df,\n                       imgdir=\"..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\",\n                       transforms=test_transform)","6ca4c5bc":"train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=32, num_workers=4)\nval_loader = DataLoader(dataset = val_data, shuffle = True, batch_size = 32, num_workers=4)\ntest_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=32, num_workers=4)","d22a47c0":"import os\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(images.shape)\nprint(labels.shape)","bcd39959":"model = torchvision.models.resnet50(pretrained=True, progress=True)","1adce2d3":"for p in model.parameters():\n    p.requires_grad = False","ea9207d1":"model.fc = nn.Sequential(\n    nn.Linear(2048, 1024),\n    nn.ReLU(),\n    nn.Linear(1024,4),\n    nn.LogSoftmax(dim=1)\n)","bfa5d541":"for param in model.parameters():\n    if param.requires_grad:\n        print(param.shape)","cb14058b":"model = model.to(device)\nopt = optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.NLLLoss()","2ecae69c":"def evaluation(dataloader):\n    total, correct = 0,0\n    model.eval()\n    for data in dataloader:\n        inputs, labels = data\n        inputs =inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _ , pred = torch.max(outputs.data, 1 )\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100*correct\/total","f4f055ed":"batch_size = 32\nimport copy\nloss_epoch_arr = []\nmax_epochs = 6\nmin_loss = 1000\nn_iters = np.ceil(50000\/batch_size)\nfor epoch in range(max_epochs):\n    for i,data in enumerate(train_loader):\n        inputs,labels = data\n        inputs = inputs.to(device)\n        labels =  labels.to(device)\n        opt.zero_grad()\n        model.train()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        if min_loss>loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(model.state_dict())\n            print('Min loss %0.2f' % min_loss)\n            del inputs, labels, outputs\n            torch.cuda.empty_cache()\n    loss_epoch_arr.append(loss.item())\n    model.eval()\n    print(\"Epoch %d\/%d, Train acc: %0.2f, Val acc: %0.2f\" %(epoch, max_epochs, evaluation(train_loader), evaluation(val_loader)))","baf4d2ec":"plt.plot(loss_epoch_arr)\nplt.show()","e398e22f":"model.load_state_dict(best_model)\nprint(evaluation(test_loader))","e78f0eac":"classes = ['bee', 'wasp', 'other_insect', 'noninsect']\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n    plt.show()\nimshow(torchvision.utils.make_grid(images[:1]))\nprint(\"Ground_Truth - \")\nprint(classes[labels[0]])\nimages = images.to(device)\noutputs = model(images)\nmax_values, pred_class = torch.max(outputs.data, 1)\nprint(\"Predicted_class - \")\nprint(classes[pred_class[0]])","fa173352":"Made the path column as valid path by replacing '\\' by '\/","060da5fe":"Split the dataframe into train , val and test by using the information in is_validation and is_final_validation column","d892063d":"Defined evaluation function to find accuracy percentage","b0cd5cd5":"Set the optimizer and loss function and transferred model on GPU","2374cfbc":"Defined classes and checked the prediction by loading an image","90b4528a":"The new weights need to be trained","7a44c4f1":"Checked for GPU","399d3bde":"Checked for the shape of images and labels in train_loader. Batch_size is 32.","43ad823e":"Got final three dataloaders ready ","afcccac8":"Loss v\/s Epochs","24937ef6":"Defined a class to form a dataloader","fa3bbf91":"TRAINED!!","4f673561":"Loaded best model and found accuracy on TEST dataset","0a259db2":"No need for weights of resnet to be trained again ao set False","a5c926a0":"Changed last layer to ensure that we have four classes","5fe1e0b7":"Defined transformations required to convert data into dataloader","0b86dbbb":"Encoded labels","9219290f":"Read labels.csv file to know about dataset division","ab165b3a":"Imported necessary libraries","eb115408":"Got train_data, test_data and val_data","904d84fb":"Finally splitted dataframe","942190d0":"Downloaded Resnet Model"}}