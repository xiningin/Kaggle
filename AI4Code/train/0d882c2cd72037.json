{"cell_type":{"170a5eba":"code","d2b78a25":"code","7a1d0360":"code","ef8cfeb1":"code","1c6d239d":"code","f6e9a4b5":"code","b7136413":"code","73d26cc8":"code","aa705326":"code","c286591e":"code","7260bf5d":"code","19ec255a":"code","76147922":"code","ea9f437c":"code","01e96fd8":"code","4ec19677":"code","f171858a":"code","91e156e7":"code","06d63f8e":"code","4c214f12":"code","b497b529":"code","b8dfae10":"code","19e07852":"code","7394f3a3":"code","36293702":"code","c8f94516":"code","01563bc0":"code","03055188":"code","41ef5d4d":"code","3bce93c4":"code","f0d36c85":"code","8c9baea0":"code","c9c57e15":"code","d37e68a2":"code","97a36d95":"code","db499498":"code","d6c76937":"code","ea6dc83a":"code","b9b04c29":"code","72454bd4":"code","d4c57753":"code","9bd3a35a":"markdown","308c096a":"markdown","1abd0d80":"markdown","8f9de79e":"markdown","5be4b29e":"markdown","55d1d8fd":"markdown","c7705ae4":"markdown","7f567ec7":"markdown","1e77078b":"markdown","f165dc78":"markdown","34951fff":"markdown","15534722":"markdown","b96afdf7":"markdown","517f376b":"markdown","d584c2b9":"markdown","1caa8941":"markdown","75932adf":"markdown","fed9955d":"markdown","d80d0288":"markdown","0818115d":"markdown","d4b86cf5":"markdown","1afea240":"markdown","76050a41":"markdown","54200116":"markdown","5a4f3b20":"markdown","51e9c486":"markdown","54a4054c":"markdown","ef791437":"markdown","133f4ff6":"markdown","56604d6e":"markdown","8e2fe0f4":"markdown","962942c0":"markdown","e03a3ec6":"markdown","1c44c780":"markdown","5c434122":"markdown"},"source":{"170a5eba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","d2b78a25":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a1d0360":"import numpy as np\nimport pandas as pd\ndf_Test_url = 'https:\/\/raw.githubusercontent.com\/blessondensil294\/Novartis-Data-Science-Competition\/master\/Data\/Test.csv'\ndf_Train_url = 'https:\/\/raw.githubusercontent.com\/blessondensil294\/Novartis-Data-Science-Competition\/master\/Data\/Train.csv'\ndf_Train = pd.read_csv(df_Train_url)\ndf_Test = pd.read_csv(df_Test_url)","ef8cfeb1":"df_Train.head()","1c6d239d":"df_Train.info()","f6e9a4b5":"df_Train.describe()","b7136413":"df_Train.shape","73d26cc8":"df_Test.shape","aa705326":"df_Train.isnull().sum()","c286591e":"df_Test.isnull().sum()","7260bf5d":"df_Train.columns","19ec255a":"df_Train['MULTIPLE_OFFENSE'].value_counts()","76147922":"df_Train.shape","ea9f437c":"df_Train = df_Train.drop(['INCIDENT_ID', 'DATE'], axis=1)","01e96fd8":"df_Train.drop_duplicates(keep='first', inplace=True)","4ec19677":"df_Train.shape","f171858a":"df_Train['MULTIPLE_OFFENSE'].value_counts()","91e156e7":"df_Train.isnull().sum()","06d63f8e":"df_Train['X_12'] = df_Train['X_12'].ffill()\ndf_Test['X_12'] = df_Test['X_12'].ffill()\ndf_Train['X_12'] = df_Train['X_12'].bfill()\ndf_Test['X_12'] = df_Test['X_12'].bfill()","4c214f12":"df_Train.isnull().sum()","b497b529":"#Convert to integer\ndf_Train['X_12'] = df_Train['X_12'].astype(int)\ndf_Test['X_12'] = df_Test['X_12'].astype(int)","b8dfae10":"df_Train.info()","19e07852":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","7394f3a3":"str_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in df_Train.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n# Get to the numeric columns by inversion            \nnum_list = df_Train.columns.difference(str_list) \n# Create Dataframe containing only numerical features\ntrain_num = df_Train[num_list]\nf, ax = plt.subplots(figsize=(25, 25))\nplt.title('Pearson Correlation of features')\n# Draw the heatmap using seaborn\nsns.heatmap(train_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)","36293702":"df_Train.corr()","c8f94516":"corrmat = df_Train.corr()\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(corrmat, square=True, vmax=.8)","01563bc0":"import statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","03055188":"df_multi = df_Train\ndf_multi = df_multi.drop('MULTIPLE_OFFENSE', axis=1)","41ef5d4d":"# For each X, calculate VIF and save in dataframe\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(df_multi.values, i) for i in range(df_multi.shape[1])]\nvif[\"features\"] = df_multi.columns","3bce93c4":"vif.round(1)","f0d36c85":"x = df_Train\nx = x.drop(['MULTIPLE_OFFENSE'], axis=1)\ny = df_Train['MULTIPLE_OFFENSE']\nx_pred = df_Test\nx_pred = x_pred.drop(['INCIDENT_ID', 'DATE'], axis=1)","8c9baea0":"from imblearn.over_sampling import RandomOverSampler\nsm = RandomOverSampler(random_state=294,sampling_strategy='not majority')\nx_sm, y_sm = sm.fit_resample(x,y)\nx_sm = pd.DataFrame(x_sm)\nx_sm.columns = x.columns","c9c57e15":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=1000, criterion='entropy', n_jobs=-1, random_state=294)","d37e68a2":"rf.fit(x_sm,np.ravel(y_sm))","97a36d95":"y_pred = rf.predict(x_pred)","db499498":"submission_df = pd.DataFrame({'INCIDENT_ID':df_Test['INCIDENT_ID'], 'MULTIPLE_OFFENSE':y_pred})\nsubmission_df.to_csv('Sample Submission RF v1.csv', index=False)","d6c76937":"pip install catboost","ea6dc83a":"from catboost import CatBoostClassifier\ncb_cl = CatBoostClassifier(learning_rate=0.15, n_estimators=500, subsample=0.70, max_depth=5, scale_pos_weight=2.5)","b9b04c29":"cb_cl.fit(x_sm,np.ravel(y_sm))","72454bd4":"y_pred = cb_cl.predict(x_pred)","d4c57753":"submission_df = pd.DataFrame({'INCIDENT_ID':df_Test['INCIDENT_ID'], 'MULTIPLE_OFFENSE':y_pred})\nsubmission_df.to_csv('Sample Submission CB v1.csv', index=False)","9bd3a35a":"Shape of the DataFrame of both Test and Train","308c096a":"# Exploratory Data Analysis","1abd0d80":"### Multi Colinearity of the Data","8f9de79e":"Description of the DataFrame","5be4b29e":"# Novartis Data Science Intrusion Detection","55d1d8fd":"Shape of the Train DataFrame before removing the duplicates","c7705ae4":"# Feature Engineer","7f567ec7":"Drop the columns INCIDENT_ID and DATE. This is to ensure to avoid Unique rows in the columns","1e77078b":"### Correlation of Data","f165dc78":"### Balancing the Train Data using SMOTE Overbalancing","34951fff":"## CatBoost Classification","15534722":"[Novartis Data Science Competition](https:\/\/www.hackerearth.com\/challenges\/hiring\/novartis-data-science-hiring-challenge\/)","b96afdf7":"To Predict if the server will be hacked or not","517f376b":"Shape of the Train DataFrame After removing the duplicates - About 5042 records are removed","d584c2b9":"### Split the Data to x variable and y variable","1caa8941":"Count of the multiple Offence column after removing the Duplicates","75932adf":"# Load the data from Github","fed9955d":"### This is mainly for a practice Notebook for the competition. You can try with various parameters and Boosting algorithm to improve your score to 100%","d80d0288":"Random Forest gave a score of 96.25 Accuracy in the Evaluation.","0818115d":"# Load the Package","d4b86cf5":"### Remove Duplicate Rows in only the Train DataFrame","1afea240":"Count of the Null column after removing the Duplicates","76050a41":"We will use Entropy with 1000 trees to build the models","54200116":"Total count of the Predictor Variable","5a4f3b20":"To find the Null cells in the DataFrame for each columns","51e9c486":"Convert the X_12 from Float64 to Integer64 ","54a4054c":"## Random Forest Model Classification","ef791437":"Drop the Duplicate Rows","133f4ff6":"# Feature Selection","56604d6e":"CatBoost Classification gave a score of 99.42 Accuracy in the Evaluation.","8e2fe0f4":"Column Names of the DataFrame","962942c0":"### Fill Missing Values","e03a3ec6":"To the Train Head of the Dataframe","1c44c780":"# Data Modelling for Prediction","5c434122":"DataFrame Information"}}