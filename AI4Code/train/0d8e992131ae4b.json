{"cell_type":{"236ed71d":"code","c5bc154d":"code","a0b591f1":"code","225ebb33":"code","b94b679d":"code","486e0ec9":"code","94bd9dd7":"code","1e0b8389":"code","ed8f2305":"code","05967e70":"code","9929ac3c":"code","b97b6a37":"code","47a085a0":"code","5f64b219":"code","85c36ab0":"code","9c855cd0":"code","8cfbb16e":"code","b7a124a2":"code","567ad67b":"code","50f808a7":"code","823a73a7":"code","8155b373":"code","dc71dcea":"code","440e50c2":"code","e6c01651":"code","741bb2a7":"code","26538937":"code","e1fbb305":"code","79d0b6f2":"code","3c041f70":"code","8e077ff5":"code","f461fa19":"code","9fc92b61":"code","acf1764c":"code","c88a4543":"code","17aa5c03":"code","39530d35":"code","8ac0fa38":"markdown","d9c7574a":"markdown","85cf2ba8":"markdown","f3ab8350":"markdown","47d95fe6":"markdown","63df136b":"markdown","65beef61":"markdown","7f0413b2":"markdown","43ebd5f0":"markdown","26b30a77":"markdown","e811e98c":"markdown","ae467752":"markdown","99520da1":"markdown","e68af7a4":"markdown","e6aff43d":"markdown","3e7ba1aa":"markdown","fc7588d7":"markdown","cb83ee29":"markdown","879ed021":"markdown","c0f36269":"markdown","0cce7b22":"markdown","f5a5638c":"markdown","80a13bed":"markdown","48f58e1a":"markdown","f110ad55":"markdown","911a28ff":"markdown","54ed3ed3":"markdown","9316bb18":"markdown","b98cd470":"markdown","f0bae9b1":"markdown","a63f6c19":"markdown","ecc2c26e":"markdown","1b0e7e83":"markdown","ba2695b9":"markdown","e76f026e":"markdown","a9518ec6":"markdown","2a2ae624":"markdown","bead8f9c":"markdown","d0104e8d":"markdown","226c32cf":"markdown","2fd022fd":"markdown","a24f548b":"markdown","fa3e53a3":"markdown","934e8b11":"markdown","495e2a26":"markdown","363d42f7":"markdown","da0c0fb8":"markdown","bb79e6c1":"markdown","3086d21b":"markdown","36f36f6d":"markdown","a86d4c9c":"markdown","7308d79f":"markdown","5008b6c1":"markdown","f2c54ea5":"markdown","885ed592":"markdown","0ba12263":"markdown","e880bd8f":"markdown","a5ebfa71":"markdown","6f9d5c0e":"markdown","8ece9c56":"markdown"},"source":{"236ed71d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Pre-Modeling Tasks\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n\n# Evaluation and comparision of all the models\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, precision_recall_fscore_support\nfrom sklearn.metrics import roc_auc_score,auc,f1_score\nfrom sklearn.metrics import precision_recall_curve,roc_curve","c5bc154d":"df = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","a0b591f1":"df['diagnosis'].value_counts()","225ebb33":"df.head()","b94b679d":"df.columns","486e0ec9":"df.shape","94bd9dd7":"df.info()","1e0b8389":"# describing the dataset\n\ndf.describe().T","ed8f2305":"df.isnull().sum()","05967e70":"# Deleting the id and Unnamed column\n\ndf= df.drop(['Unnamed: 32','id'],axis=1)","9929ac3c":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)\nplt.ioff()","b97b6a37":"\npalette ={'B' : 'lightblue', 'M' : 'magenta'}\n\n\nfig = plt.figure(figsize=(12,12))\ndef plot_scatter(a,b,k):\n    plt.subplot(k)\n    sns.scatterplot(x = df[a], y = df[b], hue = \"diagnosis\",\n                    data = df, palette = palette)\n    plt.title(a + ' vs ' + b,fontsize=15)\n    \nplot_scatter('texture_mean','texture_worst',221) \nplot_scatter('area_mean','radius_worst',222) \nplot_scatter('perimeter_mean','radius_worst',223)  \nplot_scatter('perimeter_mean','radius_worst',224) \n","47a085a0":"fig = plt.figure(figsize=(12,12))\n\n  \nplot_scatter('smoothness_mean','texture_mean',221) \nplot_scatter('texture_mean','symmetry_se',222) \nplot_scatter('fractal_dimension_worst','texture_mean',223) \nplot_scatter('texture_mean','symmetry_mean',224)\n  \n","5f64b219":"fig = plt.figure(figsize=(12,12))\nplot_scatter('area_mean','fractal_dimension_mean',221)\nplot_scatter('radius_mean','fractal_dimension_mean',222)\nplot_scatter('area_mean','smoothness_se',223)\nplot_scatter('smoothness_se','perimeter_mean',224)","85c36ab0":"from pylab import rcParams\n\nrcParams['figure.figsize'] = 8,5\n\ncols = ['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean','diagnosis']\n\nsns_plot = sns.pairplot(data=df[cols],hue='diagnosis', palette='bwr')","9c855cd0":"# area_mean vs smoothness_mean\n\nsns.scatterplot(x= 'area_mean', y= 'smoothness_mean', hue= 'diagnosis', data=df, palette='CMRmap')","8cfbb16e":"# texture mean vs radius_mean\n\nsize = len(df['texture_mean'])\n\narea = np.pi * (15 * np.random.rand( size ))**2\ncolors = np.random.rand( size )\n\nplt.xlabel(\"texture mean\")\nplt.ylabel(\"radius mean\") \nplt.scatter(df['texture_mean'], df['radius_mean'], s=area, c= colors, alpha=0.5)","b7a124a2":"# Target variable\n\nsns.countplot(df['diagnosis'],palette='Paired')","567ad67b":"m = plt.hist(df[df[\"diagnosis\"] == \"M\"].radius_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\nb = plt.hist(df[df[\"diagnosis\"] == \"B\"].radius_mean,bins=30, fc = (1,0,0.5), label= \"Bening\")\n\nplt.legend()\nplt.xlabel (\"Radius Mean Values\")\nplt.ylabel (\"Frequency\")\nplt.title(\"Histogram of Radius Mean for Bening and Malignant Tumors\")\nplt.show()","50f808a7":"sns.jointplot(data= df, x='area_mean', y='smoothness_mean', size=5)","823a73a7":"# Label Encoder\n\nLEncoder = LabelEncoder()\n\ndf['diagnosis'] = LEncoder.fit_transform(df['diagnosis'])","8155b373":"X = df.drop('diagnosis',axis=1).values\ny = df['diagnosis'].values","dc71dcea":"random_state = 42\n\nx_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=random_state)","440e50c2":"sc = StandardScaler()\n\nX_train = sc.fit_transform(x_train)\nX_test= sc.transform(x_test)","e6c01651":"# Logistic Regression\n\n\nlogreg= LogisticRegression()\n\nlogreg.fit(X_train, y_train)\n\ny_pred_logreg = logreg.predict(X_test)\n\n\n# Gradient Boosting Classifier\n\n\nGB = GradientBoostingClassifier()\n\nGB.fit(X_train, y_train)\n\ny_pred_GB = GB.predict(X_test)\n\n\n\n# Random Forest Classifier\n\nrf = RandomForestClassifier()\n\nrf.fit(X_train, y_train)\n\ny_pred_rf = rf.predict(X_test)\n\n\n# Decision Tree Classifier\n\ndt = DecisionTreeClassifier()\n\ndt.fit(X_train, y_train)\n\ny_pred_dt = dt.predict(X_test)\n\n\n# KNeighbors Classifier\n\n\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train, y_train)\n\ny_pred_knn = knn.predict(X_test)\n\n\n# XGB Classifier\n\nXGB = XGBClassifier() \n\nXGB.fit(X_train, y_train)\n\ny_pred_XGB = XGB.predict(X_test)\n\n\n\n# Support Vector classifier\n\nsvc = SVC(probability=True)\n\nsvc.fit(X_train,y_train)\n\ny_pred_svc = svc.predict(X_test)\n","741bb2a7":"X_train.shape, y_train.shape,X_test.shape, y_test.shape","26538937":"models = []\n\nZ = [SVC() , DecisionTreeClassifier() , LogisticRegression() , KNeighborsClassifier() ,XGBClassifier(),\n    RandomForestClassifier() , GradientBoostingClassifier()]\n\n\nX = [\"SVC\" , \"DecisionTreeClassifier\" , \"LogisticRegression\" , \"KNeighborsClassifier\" ,\n    \"RandomForestClassifier\" , \"GradientBoostingClassifier\", \"XGB\"]\n\nfor i in range(0,len(Z)):\n    model = Z[i]\n    model.fit( X_train , y_train )\n    pred = model.predict(X_test)\n    models.append(accuracy_score(pred , y_test))   ","e1fbb305":"d = { \"Accuracy\" : models , \"Algorithm\" : X }\ndata_frame = pd.DataFrame(d)\ndata_frame","79d0b6f2":"sns.barplot(data_frame['Accuracy'],data_frame['Algorithm'],palette= \"husl\").set_title('Accuracy of all Algorithms')","3c041f70":"cm = np.array(confusion_matrix(y_test, y_pred_svc, labels=[1,0]))\n\nconfusion_mat= pd.DataFrame(cm, index = ['cancer', 'healthy'],\n                           columns =['predicted_cancer','predicted_healthy'])\n\nconfusion_mat","8e077ff5":"sns.heatmap(cm,annot=True,fmt='g',cmap='Set3')","f461fa19":"print(accuracy_score(y_test, y_pred_svc))","9fc92b61":"print(precision_score(y_test, y_pred_svc))","acf1764c":"print(recall_score(y_test, y_pred_svc))","c88a4543":"print(classification_report(y_test, y_pred_svc))\n","17aa5c03":"\n#plt.style.use('seaborn-pastel')\n\ny_score = svc.decision_function(X_test)\n\nFPR, TPR, _ = roc_curve(y_test, y_score)\nROC_AUC = auc(FPR, TPR)\nprint (ROC_AUC)\n\nplt.figure(figsize =[11,9])\nplt.plot(FPR, TPR, label= 'ROC curve(area = %0.2f)'%ROC_AUC, linewidth= 4)\nplt.plot([0,1],[0,1], 'k--', linewidth = 4)\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.05])\nplt.xlabel('False Positive Rate', fontsize = 18)\nplt.ylabel('True Positive Rate', fontsize = 18)\nplt.title('Receiver operating characteristic example', fontsize= 18)\nplt.show()","39530d35":"roc_auc_score(y_test, y_score)","8ac0fa38":"# Evaluation and comparison of all the models","d9c7574a":"## ScatterPlot","85cf2ba8":"# Modeling","f3ab8350":"How many Benign and Malignant do we have in our dataset?","47d95fe6":"****What is the difference between Malignant and Benign ?****","63df136b":"- The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 \u2013 FPR). As we notice the **svc** Classifier give a curve closer\n\n  to the top-left corner so it indicate a better performance. ","65beef61":"## JointPlot","7f0413b2":"- **Recall** also called Sensitivity, is the ratio of positive instances that are correctly detected by the classifier to the all observations in actual class","43ebd5f0":"# Feature Scaling","26b30a77":"As we can see, we have 212 - Malignant, and 357 - Benign","e811e98c":"Evaluating the machine learning model is a crucial part in any data science project. There are many metrics that helps us to evaluate our model accuracy.\n\n- Classification Accuracy\n\n- Confusion matrix\n\n- Precision\n\n- Recall\n\n- classification_report\n\n- ROC AUC Score\n\n- Area under curve (AUC)","ae467752":"So we have encoded malignan as 1 and benign as 0","99520da1":"## Separating the independant and the dependant variable","e68af7a4":"## Count Plot","e6aff43d":"## Checking for missing values","3e7ba1aa":"# Exploratory Data Analysis","fc7588d7":"## Precision ","cb83ee29":"As we know machine learning algorithms can only read numerical values. It is essential to encoding categorical features into numerical values.","879ed021":"Area Under Curve is a common way to compare classifiers. A perfect classifier will have ROC AUC equal to 1\n\nSckit-Learn provides a function to compute the ROC AUC.","c0f36269":"Machine Learning algorithm generally, cannot work with missing values, so before we launch a machine learning algorithm we must cleaning the dataset, we will remove the features that doesn't affect the model ","0cce7b22":"As we see, from the above table and graph, that SVC classifier works best for this dataset","f5a5638c":"# Look at the dataset","80a13bed":"### Highly correlated pairs","48f58e1a":"\n**True Positive Rate\/Recall\/Sensitivity: How often the model predicts yes(Healthy) when it's actually yes(Healthy)?**\n\n- **True Positive Rate(TPR)** = TP\/TP+FP = 71\/(871+2) = 0.97\n\n\n**False Positive Rate: How often the model predicts yes(Healthy) when it's actually no(Cancer)?**\n\n- **False Positive Rate(FPR)** = FP\/FP+TN = 2\/2+41 = 0.04","f110ad55":"## Confusion Matrix","911a28ff":"  \n- Table of Contents\n\n- First look at the dataset\n\n- EDA\n\n   - Checking for Missing Values\n   \n   - Basic Statistical Details\n  \n   - Correlation Heatmap\n      - Highly correlated pairs\n      - Inverse correlated pairs\n      - Low correlated pairs\n      \n           \n       \n- Data Visualization\n\n    - Feature Pairs\n    - Scatter Plot\n    - Count Plot\n    - Histogram \n    - Joint Plot\n    \n    \n    \n- Pre-Modeling Tasks\n\n   - Separating the independant and the dependant variable\n   - Splitting the dataset \n   - Feature Scaling\n   \n   \n   \n- Modeling\n\n   - Logistic Regression\n   - Gradient Boosting Classifier\n   - Random Forest Classifier\n   - Decision Tree Classifier\n   - KNeighbors Classifier\n   - XGB Classifier\n   - Suport Vector Machine\n   \n   \n- Evaluation and comparision of all the models\n\n  - Classification Accuracy\n\n  - Confusion matrix\n\n  - Precision\n\n  - Recall\n\n  - classification_report\n\n  - ROC AUC Score\n\n  - Area under curve (AUC)\n   \n    \n- Resources","54ed3ed3":"Let\u2019s visualize the confusion matrix, to see how accurate are the results we obtained.","9316bb18":"## Area Under Curve","b98cd470":"- As we can see from the table above:\n\n   - **True Positive(TP)** : Values that the model predicted as yes(Healthy), and is actually yes(Healthy).\n   - **True Negative(TN)** : Values that the model predicted as not(Cancer), and is actually no(Cancer).\n   - **False Positive(FP)**: Values that the model predicted as yes(Healthy), but actually no(Cancer).\n   - **False Negative(FN)**: Values that the model predicted as no (Cancer), but actually yes(Healthy).\n","f0bae9b1":"## PairPlot","a63f6c19":"## Checking for the correlation","ecc2c26e":"## Splitting the dataset","1b0e7e83":"- **Accuracy_Score** is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations\n\n\n(TP + TN)\/total = 0.98245614","ba2695b9":"![Differences Between a Malignant and Benign Tumor](https:\/\/gotalktogetherdotcom.files.wordpress.com\/2016\/05\/cancerbenignmalig1.jpg?w=550)\n\nLoving Biology - WordPress.com","e76f026e":"- True Positive(TP) : 71\n    \n- True Negative(TN) : 41\n    \n- False Positive(FP): 2\n    \n- False Negative(FN): 0","a9518ec6":"![](https:\/\/mlfjqdsf5ptg.i.optimole.com\/iQrIoNc-LQvF_N5U\/w:800\/h:400\/q:69\/https:\/\/nationaldaycalendar.com\/wp-content\/uploads\/2014\/10\/Breast-Cancer-Awareness-Month-October-1.jpg)","2a2ae624":"## The ROC Curve","bead8f9c":"# Loading the libraries and the dataset","d0104e8d":"Now, let's see the performance metrics of svc classifier","226c32cf":"- In this part we'll try differents models of Machine learning: Logistic Regression, Gradient Boosting Classifier,Random Forest,XGB Classifier,\n\n\n  Support Vector Machine, Decision  tree and KNeighbors Model","2fd022fd":"## Classification Report\n","a24f548b":"For this dataset, whenever the model is predicting something as yes, it indicates Absence of cancer cells (Healthy) and for cases when the model predicting no; it indicates existence of cancer cells(Cancer).\n\n","fa3e53a3":"Feature scaling is a method used to standardize the range of independent variables or features of data. Scaling the data is very important to boost the score.\n\nFeature Scaling, is a step of Data Pre Processing which is applied to independent variables or features of data. It basically helps to normalise the data within a particular range.\n\n\nThere are two ways for scaling the dataset:\n \n -Standardization\n \n -Min_Max Scaling\n \n- Standardization : it substract the mean value( so standardized values always have a zero mean), and then it divides by the standard deviation, this method doesn't have a         specific range from 0 to 1, that may cause a problem for many algorithms like Neural Network often expect an input value ranging from 0 to 1. \n \n  Sckit-Learn provides a transformer caller **StandardScaler**. The idea behind **StandardScaler** is that it will transform your data such that its distribution will have a       mean value 0 and standard deviation of 1.\n \n\n- Min_Max : called also Normalization, is the simplest way to scaling data, values are shifted and rescaled again so that the end up ranging from 0 to 1. we do this by             substraction the min value and dividing by the Max minus the Min.\n\n  Sckit-learn provides a transformer callec **MinMaxScaler**.  It have a hyperparameter called \"Feature Range\" to specify the range that you want.","934e8b11":"# Data Visualization","495e2a26":"- [Understanding a Classification Report For Your Machine Learning Model](https:\/\/medium.com\/@kohlishivam5522\/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397)\n\n- [True Positive Rate](https:\/\/www.sciencedirect.com\/topics\/computer-science\/true-positive-rate)\n\n- [How to plot an ROC curve in Python](https:\/\/www.kite.com\/python\/answers\/how-to-plot-an-roc-curve-in-python)","363d42f7":"- A confusion matrix is a table that can be used to measure the performance of an machine learning algorithm, usually a supervised learning one. Each row of the confusion matrix represents the instances of an actual class and each column represents the instances of a predicted class\n\n\nIn a binary classifier, the \"**true**\" class is typically labeled with 1 and the \"**false**\" class is labeled with 0.\n\n  - True Positive: A positive class observation (1) is correctly classified as positive by the model.\n\n  - False Positive: A negative class observation (0) is incorrectly classified as positive.\n\n  - True Negative: A negative class observation is correctly classified as negative.\n\n  - False Negative: A positive class observation is incorrectly classified as negative.","da0c0fb8":"****Check the target variable:****\n\n- Malignant = 1 (indicates prescence of cancer cells)\n\n- Benign = 0 (indicates abscence)","bb79e6c1":"Attribute Information:\n\n- 1) ID number\n\n- 2) Diagnosis (M = malignant, B = benign)\n  \n\nTen real-valued features are computed for each cell nucleus:\n\n- a) radius (mean of distances from center to points on the perimeter)\n- b) texture (standard deviation of gray-scale values)\n- c) perimeter\n- d) area\n- e) smoothness (local variation in radius lengths)\n- f) compactness (perimeter^2 \/ area - 1.0)\n- g) concavity (severity of concave portions of the contour)\n- h) concave points (number of concave portions of the contour)\n- i) symmetry\n- j) fractal dimension (\"coastline approximation\" - 1)","3086d21b":"### Low correlated pairs","36f36f6d":"## Basic Statistical Details","a86d4c9c":"# Encoding categorical data","7308d79f":"## Accuracy_Score","5008b6c1":"## Histogram","f2c54ea5":"# Evaluating The Performance of the model","885ed592":"- **Precision** is the ratio of correctly predicted positive observations to the total predicted positive observations.","0ba12263":"## Recall","e880bd8f":"# Table of Contents","a5ebfa71":"### Inverse correlated pairs","6f9d5c0e":"In Machine learning we must split the dataset into training and testing data:\n\n - the training set called also learning set that we will use to train our model, it has the big part.\n\n - the testing set: is used to evaluate the performance of the model after hypermarameter tuning, It's also useful to get an idea of how different models (SVMs, Neural Networks,    Random forests...) perform against each other.\n\n- So creating the test set is easy, we just select a few rondom rows, in general we give it 10%  or 20%.\n\n- SKit_Learn provides a function of splitting the dataset into multiples subsets. \n\n\n- train_test_split(), is the simplest way wich the same as the function: split_train_test(), the method accepts lists, numpy arrays, scipy sparse matrices or pandas dataframes.\n\n  We will also identify some parameters, like the random_state that allows you to set the random generator seed.\n\n- The ideal split is said to be 80:20 for training and testing. You may need to adjust it depending on the size of the dataset and parameter complexity.","8ece9c56":"# Pre-Modeling Tasks"}}