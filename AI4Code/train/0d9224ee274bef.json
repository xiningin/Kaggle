{"cell_type":{"589f2e3d":"code","ee8d10ba":"code","e7edac12":"code","c34bbada":"code","3f14bd7e":"code","6eb53a51":"code","6588249b":"code","096bb108":"code","23e122f7":"code","a5d782ed":"code","42be9d40":"code","cd4d3740":"code","ffd6ebbb":"code","c37b552e":"code","8db43a0d":"code","7a6df75a":"code","4021fcc2":"code","978a7b15":"code","04e220fd":"code","c6d3f47a":"markdown","f1d66b77":"markdown","875468fd":"markdown","c86f281f":"markdown","d6eb9990":"markdown","1367a888":"markdown","c4c11539":"markdown"},"source":{"589f2e3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ee8d10ba":"Train_data = pd.read_csv('..\/input\/titanic\/train.csv')\n\ny_train = Train_data.Survived\n#check for any missing y values \nprint('are there any missing y Values?', y_train.isnull().any())\n#there aren't any, what a treat\nX_train= Train_data.drop(['Survived'], axis = 1)\n\n\ndef concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndef divide_df(all_data):\n    # Returns divided dfs of training and test set\n    return all_data.loc[:890], all_data.loc[891:]\n\n\nX_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_all = concat_df(X_train, X_test)\n\nx_cols_missing = [col for col in X_train if X_train[col].isnull().any() ]\nprint(x_cols_missing)\nprint(df_all.isnull().sum())\n\nprint(df_all.info())\ndfs = [X_train, X_test]\n\n\n#yikes, so we have 177 missing age values\n#find correllation coefficients \n\ncorr = X_train.corr()\n\ndf_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n\nprint(df_all_corr[df_all_corr['Feature 1'] == 'Age'])\n\n\nprint(x_cols_missing)\n#we have some missing column values, yikes.\n\n#let's use a simple imputer for age\n\n#X.head()\n#next steps: impute values for age but more cleverly using 'miss, mr, etc.'\n#decide what to do with Cabin, maybe make 1,0 for cabin or not, then break down based on cabin, look at layout of ship\n#think about ways embarked could affect things, other than through other variables. Is it IV? ","e7edac12":"total = df_all.isnull().sum().sort_values(ascending = False)\npercent_1 = df_all.isnull().sum()\/(df_all.count()+df_all.isnull().sum())*100\npercent_2 = (round(percent_1,1)).sort_values(ascending = False)\n\ntable = pd.concat([total, percent_2],axis = 1, keys = ['Total', '%'])\ntable","c34bbada":"#building a heatmap \ncmap = sns.diverging_palette(20,220, n = 200)\n\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nax = sns.heatmap(corr, mask = mask,vmin = -1, vmax = 1, center = 0, cmap = cmap, square = True)\n\nax.set_xticklabels( ax.get_xticklabels(),rotation=45,horizontalalignment='right')","3f14bd7e":"#fill in age values by looking at the median age along Pclass and sex. \n\nage_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(df_all['Age'].median()))\n\n# Filling the missing values in Age with the medians of Sex and Pclass groups\ndf_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n","6eb53a51":"#dealing with missing Embarked values\ndf_all[df_all['Embarked'].isnull()]\n#we call the index on the whole data to return the rows. How clever!","6588249b":"df_all['Embarked'] = df_all['Embarked'].fillna('S')","096bb108":"df_all[df_all['Fare'].isnull()]","23e122f7":"med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp','Sex']).Fare.median()[3][0][0]['male']\ndf_all['Fare'] = df_all['Fare'].fillna(med_fare)","a5d782ed":"#drop Cabin column\ndf_all_no_C = df_all.drop('Cabin', axis = 1)\n#mmmm that's better hun\n","42be9d40":"df_all[['Name']]","cd4d3740":"titles = []\nfor name in df_all_no_C['Name']:\n    if 'Mr.' in name:\n        titles.append('Mr.')\n    elif any(x in name for x in ['Mrs.', 'Ms.']):\n        titles.append('Mrs.')\n    elif 'Miss' in name: \n        titles.append('Miss')\n    elif 'Master.' in name:\n        titles.append('Master')\n    elif any(x in name for x in ['Dr', 'Rev']):\n        titles.append('Dr.')\n    elif any(x in name for x in ['Col.', 'Major']):\n        titles.append('Military')\n    else:\n        titles.append('Other')\n\n\n#add new titles column this to that then.\ndf_all_no_C['Title'] = titles\n\n\n#now we can drop the name! Not that handy lool\n\ndf_all_no_CN = df_all_no_C.drop('Name', axis = 1)\ndf_all_no_CN[['Title']]\n","ffd6ebbb":"s = (df_all_no_CN.dtypes == 'object')\n\nobject_cols = list(s[s].index)\nobject_cols","c37b552e":"df_all","8db43a0d":"list_of_tickets = df_all.Ticket.value_counts()\n\ndictionary = dict({})\nfor x in list_of_tickets.keys():\n    count = list_of_tickets[x]\n    if count not in dictionary.keys():\n        dictionary[count] = 1\n    else:\n        dictionary[count] += 1\nsorted_items = sorted(dictionary.items())        \n\nx = pd.DataFrame(sorted_items)\n\nx.columns = ['Number of people per ticket','no. of occurrences']\n\nx","7a6df75a":"cat_features = ['Embarked','Sex','Title']\ndfs = divide_df(df_all_no_CN)\nX_train1 = dfs[0]\nX_test1 = dfs[1]\n\nOH_E = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n\nOH_cols_train = pd.DataFrame(OH_E.fit_transform(X_train1[cat_features]))\nOH_cols_test = pd.DataFrame(OH_E.transform(X_test1[cat_features]))\n\nOH_cols_train.index = X_train1.index\nOH_cols_test.index = X_test1.index\n\nnum_X_train1 = X_train1.drop(cat_features, axis = 1)\nnum_X_test1 = X_test1.drop(cat_features, axis = 1)\n\nOH_X_train = pd.concat([num_X_train1,OH_cols_train], axis = 1)\nOH_X_test = pd.concat([num_X_test1,OH_cols_test], axis = 1)\n\n#change column names!!! \nOH_X_test.rename(columns = {0:'Emb_C', 1:'Emb_Q', 2:'Emb_S',3:'Male',4:'Female',5:'Dr.', 6:'Master',7:'Military',8:'Miss',9:'Mr.',10:'Mrs.',11:'Other'}, inplace = True)\nOH_X_train.rename(columns = {0:'Emb_C', 1:'Emb_Q', 2:'Emb_S',3:'Male',4:'Female',5:'Dr.', 6:'Master',7:'Military',8:'Miss',9:'Mr.',10:'Mrs.',11:'Other'}, inplace = True)\n","4021fcc2":"OH_X_test.drop('Ticket', inplace = True, axis = 1)\nOH_X_train.drop('Ticket', inplace = True, axis = 1)","978a7b15":"OH_X_test\nOH_X_train","04e220fd":"my_regressor = RandomForestClassifier(criterion = 'gini')\nmy_regressor.fit(OH_X_train, y_train)\npredictions = my_regressor.predict(OH_X_test)","c6d3f47a":"Finally we have gotten rid of the missing values! Now let's create some more. ","f1d66b77":"So we fill both of these with 'S'!  ","875468fd":"Let's see what we can do with Tickets. HMMMMM let's explore. ","c86f281f":"There's also only one missing fare value. So we can fill it with the median for the man. ","d6eb9990":"Literally cba with Cabin right now. Think I will come back to it!! ","1367a888":"The table above shows the number of people travelling on each ticket, and the number of times this happens. For example there are 713 people travelling on their own tickets. ","c4c11539":"We are missing only two **embarked** values. These are Mrs. Stone and her (probably) maid, since they're in the same cabin. A cheeky Google shows they left from Southampton. "}}