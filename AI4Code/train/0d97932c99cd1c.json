{"cell_type":{"5334fc60":"code","9f653d98":"code","3f84a688":"code","dff34124":"code","62c8f5a7":"code","defaf45d":"code","f0d4c9a2":"code","a69d2f0c":"code","db5f1f3e":"code","848a3f45":"code","6c3606a2":"code","9810eb67":"code","62158c86":"code","d841f78b":"code","184694b8":"code","df9b26e0":"code","5e482679":"code","bc59aab6":"code","8e1969c1":"code","33d64b37":"code","72def675":"code","7ad4fa87":"code","dbe56d9c":"code","a846f709":"code","5d537937":"code","e3091102":"code","c2e66966":"code","ca48435e":"code","158da001":"markdown","f6791734":"markdown","197f6310":"markdown","7758a2d0":"markdown","6547efe8":"markdown","dc06acd3":"markdown","9d2271e4":"markdown","57765829":"markdown","04af9725":"markdown","0197e955":"markdown","642ce1e7":"markdown","7bd9eb66":"markdown","174d4433":"markdown","0f46de67":"markdown","fa053e62":"markdown","3b55e9ca":"markdown"},"source":{"5334fc60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f653d98":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","3f84a688":"data = pd.read_csv(\"\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\ndata.head()","dff34124":"data.info()","62c8f5a7":"data.describe()","defaf45d":"#Checking for NA's in the data.\nmissing_data = data.isnull().sum()\nmissing_data","f0d4c9a2":"sns.countplot('Gender', hue='Attrition', data=data)","a69d2f0c":"sns.countplot('MaritalStatus', hue='Attrition', data=data)","db5f1f3e":"sns.countplot('NumCompaniesWorked', hue='Attrition', data=data)","848a3f45":"sns.countplot('StockOptionLevel', hue='Attrition', data=data)","6c3606a2":"plt.figure(figsize=(12,12))\nsns.countplot('DistanceFromHome', hue='Attrition', data=data)\nplt.xticks(rotation=45)\nplt.show()","9810eb67":"#Checking variables that could be important\n\nsns.relplot(x= \"YearsAtCompany\", y= \"JobSatisfaction\", hue = \"Attrition\", data = data)","62158c86":"#Continuing comparing variables I think are important\nsns.countplot(x= \"YearsSinceLastPromotion\",  hue = \"Attrition\",data = data)","d841f78b":"sns.countplot('EducationField', hue='Attrition', data=data)\nplt.xticks(rotation=30)\nplt.show()","184694b8":"sns.countplot('PercentSalaryHike', hue='Attrition', data=data)","df9b26e0":"#Checking for collinearity by using a correlation matrix.\n\ncorrelation_heatmap = data.drop(['Attrition'], axis=1).corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(correlation_heatmap,cmap='Blues')\nplt.show()","5e482679":"#Looking at the ratio \ndata['Attrition'].value_counts()","bc59aab6":"data.Attrition.replace({'Yes': 1, 'No': 0}, inplace=True)\ndata.BusinessTravel.replace({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently':2}, inplace=True)\ndata.Department.replace({'Sales': 0, 'Research & Development': 1, 'Human Resources': 2, }, inplace=True)\ndata.Gender.replace({'Female': 0, 'Male': 1}, inplace=True)\ndata.OverTime.replace({'No': 0, 'Yes':1}, inplace=True)\ndata.EducationField.replace({'Life Sciences': 0, 'Medical': 1, 'Marketing': 2, \n                             'Technical Degree': 3, 'Human Resources': 4, 'Other':5}, \n                            inplace=True)\ndata.JobRole.replace({'Sales Executive': 0, 'Research Scientist': 1, 'Laboratory Technician': 2,\n                     'Manufacturing Director': 3, 'Healthcare Representative': 4, 'Manager': 5,\n                     'Sales Representative': 6, 'Research Director': 7, 'Human Resources': 8}, inplace=True)\ndata.MaritalStatus.replace({'Single': 0, 'Married': 1, 'Divorced': 2}, inplace=True)","8e1969c1":"num_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'HourlyRate',\n           'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n           'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',\n           'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance',\n           'YearsatCompany', 'YearsinCurrentRole', 'YearsSinceLastPromotion', 'YearswithCurrManager']\nnum_cols","33d64b37":"cat_cols = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender',\n           'JobRole', 'MartialStatus', 'OverTime']\ncat_cols","72def675":"df1 = data.drop(['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)\ndf2 = pd.get_dummies(df1)\ndf2.head()","7ad4fa87":"X = df2.drop(columns=['Attrition'])\ny = df2['Attrition'] ","dbe56d9c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=137)","a846f709":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_predictions = rf.predict(X_test)\nprint(\"Accurary Score: {}\".format(accuracy_score(y_test, rf_predictions)))\n","5d537937":"from sklearn.ensemble import GradientBoostingClassifier\n\nGBCmodel = GradientBoostingClassifier(n_estimators = 50, max_depth = 4, random_state=137)\n\nGBCmodel.fit(X_train, y_train)\nprint('GBCmodel Training Score is : ', GBCmodel.score(X_train, y_train))\nprint('GBCmodel Test Score is : ', GBCmodel.score(X_test, y_test))\n\ny_pred = GBCmodel.predict(X_test)","e3091102":"from sklearn.metrics import confusion_matrix\n\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\nsns.heatmap(CM, center=True, color = 'rgb')\nplt.show()","c2e66966":"rf.feature_importances_","ca48435e":"from sklearn.inspection import permutation_importance\n\ncol_name = list(X.columns)\n\nplt.figure(figsize=(12,12))\nplt.barh(col_name, rf.feature_importances_)\nplt.show()","158da001":"Quick stats for the columns where it applies.","f6791734":"Beginning the EDA. I want to see if there are any obvious patterns that could tell me if an employee would leave or not.","197f6310":"Looking at the types for each column.","7758a2d0":"Hello! This is a test datast from the wonderful people at IBM. It is my first solo project here on Kaggle that is completed. The dataset is trying to determine some of the causes of attrition among employees or what could cause them to leave. Let's dive in.","6547efe8":"Checking our confusion matrix. As we can see, our model successfully classified people who did not leave the company.","dc06acd3":"Dropping the EmployeeCount, Over18, StandardHours and EmployeeNumber columns are either unique values that do not add anything or are the same values across the entire dataset.","9d2271e4":"I want to see how the target, in this case Attrition is split. It looks like we have a lot more people who are not leaving which is good for this made up company but we could run into the problem of bias in the data.","57765829":"Using GradientBoosting, which is commonly used in decision trees and by extension, randomforests.","04af9725":"After our data has been changed to my satisfaction, I am splitting the data one last time into what will become our test and train sets. The X is all of the variables that I want to use to see how they affect attrition rate within the company. The y is the dependent variable I want to observe from the model.","0197e955":"Splitting into testing and training. Random state for the sake of reproducibility.","642ce1e7":"Looking at feature importance. This can help identify in the future what might cause a person to leave the company.","7bd9eb66":"The accuracy score! Not bad for the model.","174d4433":"Making sure they are no null or NA values.","0f46de67":"I want to organize the columns to see if which are categorical against which are numeric. I changed some of the numeric to categorical to make it easy for our model.","fa053e62":"Bringing in all of our necessary packages!","3b55e9ca":"Reading in our data and taking our first look at it."}}