{"cell_type":{"7f080e20":"code","5ea25e28":"code","191dc281":"code","76293893":"code","b7a4c6b7":"code","3fc05464":"code","344db541":"code","ae6260cb":"code","856f1f23":"code","c6bf47c1":"code","85b32a2f":"code","059e9894":"code","fb218205":"code","4589c0ec":"code","d067c0e6":"code","7d8389a2":"code","6b3ae5f0":"code","984d1fc1":"code","74121385":"code","dca92d1e":"code","a291cf50":"code","e4989a61":"code","5ecefb5e":"code","3152f553":"code","e5efc6be":"code","4e9a2b5f":"code","6dfa9da2":"code","6942706d":"code","60d3b52a":"code","26b80d37":"code","3631cfa3":"code","139aa53e":"code","931d8026":"code","097837af":"markdown","2c350dc7":"markdown","16259eaf":"markdown","6f7ee72b":"markdown","457090fe":"markdown","492a58e3":"markdown","9ffc5766":"markdown","8ec3bc65":"markdown","2dbfb7d8":"markdown","f20fdc97":"markdown","86e921e1":"markdown","cc252857":"markdown"},"source":{"7f080e20":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5ea25e28":"import plotly as py\nfrom statistics import mean\nimport plotly.graph_objects as go\nimport plotly.express as px \nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom umap import UMAP\n\n#Models\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold ,KFold\nfrom sklearn.ensemble import VotingClassifier\n\n\nimport optuna\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","191dc281":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntrain_df.head()","76293893":"test_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\")\ntest_df.head()","b7a4c6b7":"features = train_df.drop([\"id\",\"claim\"],axis=1).columns.tolist()\nprint(features, end =\"\")","3fc05464":" def missing_rate(data):\n    missing_rate = {}\n    for col in data.columns:\n        column_missing_rate = data[col].isna().sum() \/ len(data[col]) * 100\n        missing_rate[col] = round(column_missing_rate,2)\n\n    missing_rate = pd.DataFrame(missing_rate.items(),index=None)\n    return missing_rate\n","344db541":"missing_rate_train = missing_rate(train_df[features])\nmissing_rate_train\nmissing_rate_test = missing_rate(test_df[features])\nmissing_rate_test\ntotal_missing = pd.concat([missing_rate_train,missing_rate_test],axis=1)\ntotal_missing","ae6260cb":"sns.histplot(data=train_df['claim'],palette=\"viridis\",bins=10,color=\"red\")\n","856f1f23":"claim_percentage = pd.DataFrame(train_df[\"claim\"].value_counts() \/ len(train_df.claim))\nclaim_percentage.T","c6bf47c1":"sns.countplot(train_df.claim ,palette=\"Set3\")","85b32a2f":"fig, axes = plt.subplots(nrows= 10 , ncols=6 ,figsize =(30,36))\ncolumn_number = 1\nfor i in range(0,10):\n    for j in range(0,6):\n        subchart = sns.kdeplot(data=train_df , x = str(train_df.columns[column_number]),ax =axes[i,j],color=\"red\",label =\"Train\")\n        subchart = sns.kdeplot(data=test_df , x = str(test_df.columns[column_number]),ax =axes[i,j],color=\"blue\",label =\"Train\")\n        column_number +=1","059e9894":"fig, axes = plt.subplots(nrows= 10 , ncols=6 ,figsize =(30,36))\ncolumn_number = 58\nfor i in range(0,10):\n    for j in range(0,6):\n        subchart = sns.kdeplot(data=train_df , x = str(train_df.columns[column_number]),ax =axes[i,j],color=\"red\",label =\"Train\")\n        subchart = sns.kdeplot(data=test_df , x = str(test_df.columns[column_number]),ax =axes[i,j],color=\"blue\",label =\"Test\")\n        column_number +=1","fb218205":"matrix = np.triu(train_df.drop(\"id\" , axis=1).corr())\nplt.figure(figsize=(20 ,10))\nsns.heatmap(train_df.drop(\"id\", axis=1).corr() , annot= False , cmap=\"icefire\" , mask=matrix , linecolor=\"white\" ,cbar=True ,vmin= - 0.05  , vmax= 0.05 ,linewidths=0.1)\nplt.show()","4589c0ec":"features = train_df.columns.to_list()[1:119]\ntrain_df[\"n_missing\"] = train_df[features].isna().sum(axis=1)\ntest_df[\"n_missing\"] = test_df[features].isna().sum(axis=1)\n\ntrain_df['std'] = train_df[features].std(axis=1)\ntest_df[\"std\"] = test_df[features].std(axis=1)\n\nfeatures += [\"n_missing\" , \"std\"]","d067c0e6":"simple_imputer = SimpleImputer(strategy=\"mean\")\ntrain_df[features] = simple_imputer.fit_transform(train_df[features])\ntest_df[features] = simple_imputer.transform(test_df[features])","7d8389a2":"standard_scaler = StandardScaler()\ntrain_df[features] = standard_scaler.fit_transform(train_df[features])\ntest_df[features] = standard_scaler.transform(test_df[features])","6b3ae5f0":"X = train_df.drop([\"id\",\"claim\"] ,axis=1)\nY = train_df[\"claim\"]\nX_test = test_df.drop(\"id\" , axis=1)","984d1fc1":"def objective(trial , data=X , target= Y):\n    params ={\"max_depth\" :trial.suggest_int(\"max_depth\" ,2,8) , \n          \"learning_rate\" : trial.suggest_float(\"learning_rate\" , 0.005 , 0.2),\n          \"n_estimators\" : trial.suggest_int(\"n_estimators\" , 1000 ,5000),\n          \"min_child_weight\" : trial.suggest_int(\"min_child_weight\" , 1,500),\n          \"gamma\" : trial.suggest_float(\"gamma\" ,0.0001 , 1.0 , log = True),\n          \"alpha\": trial.suggest_float(\"alpha\" , 0.0001 , 10 ,log = True),\n          \"lambda\": trial.suggest_float(\"lambda\" ,0.0001, 10.0 , log = True),\n          \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\" , 0.1 , 0.8), \n          \"subsample\": trial.suggest_float(\"subsample\" , 0.1,0.9),\n          \"tree_method\" : \"gpu_hist\",\n          \"booster\" : \"gbtree\",\n           \"random_state\": 228 ,\n           \"use_label_encoder\" : False,\n           \"eval_metric\" : \"auc\"\n          }\n    model = XGBClassifier(**params)\n    scores = []\n    K = StratifiedKFold(n_splits=4,random_state=228 , shuffle=True)\n    for i ,(train_idx , val_idx) in enumerate(K.split(X,Y)):\n        X_train ,X_val = X.iloc[train_idx],X.iloc[val_idx]\n        Y_train ,Y_val = Y.iloc[train_idx],Y.iloc[val_idx]\n        model.fit(X_train ,Y_train ,eval_set = [(X_val,Y_val)] ,early_stopping_rounds =300 ,verbose = False)\n        \n        train_prediction = model.predict_proba(X_train)[:,1]\n        train_score = roc_auc_score(Y_train ,train_prediction)\n        \n        validate_prediction = model.predict_proba(X_val)[:,1]\n        validate_score = roc_auc_score(Y_val , validate_prediction)\n        scores.append((train_score , validate_score))\n        \n        print(f\"Fold {i+1} | AUC : {validate_score} \")\n        \n    scores = pd.DataFrame(scores ,columns=[\"train Score\" , \"Validation Score\"])\n    return scores[\"Validation Score\"].mean() ","74121385":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective ,n_trials= 20)\nprint(\"Numbers of finished trials : \" , len(study.trials))\nprint(\"Best Trials : \", study.best_trial.params)\nprint(\"Best Values : \" , study.best_value)","dca92d1e":"xgb_params = study.best_trial.params\nxgb_params","a291cf50":"folds = StratifiedKFold(n_splits=5,random_state=228,shuffle=True)\npredictions = np.zeros(len(X_test))\nfor fold,(train_idx,validate_idx) in enumerate(folds.split(X,Y)):\n    X_train,X_validate = X.iloc[train_idx] ,X.iloc[validate_idx]\n    Y_train,Y_validate = Y.iloc[train_idx] ,Y.iloc[validate_idx]\n    xgb_model = XGBClassifier(**xgb_params ,tree_method= \"gpu_hist\",booster = \"gbtree\" ,random_state = 228,use_label_encoder = False ,eval_metric = \"auc\")\n    xgb_model.fit(X_train,Y_train,eval_set = [(X_validate,Y_validate)],verbose =False,early_stopping_rounds =300)\n    predictions += xgb_model.predict_proba(X_test)[:,1] \/folds.n_splits","e4989a61":"submit = pd.DataFrame({\"id\":test_df['id'] , \"claim\": predictions})\nsubmit.to_csv(\"\/kaggle\/working\/xgb_submit.csv\",index=False)","5ecefb5e":"def objective_cb(trial , data=X ,target=Y):\n    params = {\"depth\":trial.suggest_int(\"depth\" ,2,6),\n              \"learning_rate\":trial.suggest_float(\"learning_rate\" ,0.005 ,0.2),\n              \"iterations\":trial.suggest_int(\"iterations\" ,10000 , 50000),\n              \"max_bin\":trial.suggest_int(\"max_bin\" , 1,300),\n              \"min_data_in_leaf\":trial.suggest_int(\"min_data_in_leaf\" , 1,300),\n              \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\" , 0.0001 , 1.0 ,log =True),\n              \"subsample\":trial.suggest_float(\"subsample\" , 0.1 , 0.8 ),\n              \"grow_policy\":trial.suggest_categorical(\"grow_policy\" ,['SymmetricTree', 'Depthwise', 'Lossguide']),\n              \"leaf_estimation_method\":trial.suggest_categorical(\"leaf_estimation_method\" , [\"Newton\" , \"Gradient\"]),\n              \"bootstrap_type\" :\"Bernoulli\",\n              \"random_seed\" : 228 , \n              \"loss_function\":\"Logloss\",\n              \"eval_metric\":\"AUC\",\n              \"task_type\" : \"GPU\"\n             }\n    model  = CatBoostClassifier(**params)\n    scores = []\n    K = StratifiedKFold(n_splits=4,random_state=228 , shuffle=True)\n    for i ,(train_idx , val_idx) in enumerate(K.split(X,Y)):\n        X_train ,X_val = X.iloc[train_idx],X.iloc[val_idx]\n        Y_train ,Y_val = Y.iloc[train_idx],Y.iloc[val_idx]\n        model.fit(X_train ,Y_train ,eval_set = [(X_val,Y_val)] ,early_stopping_rounds =300 ,verbose = False)\n        \n        train_prediction = model.predict_proba(X_train)[:,1]\n        train_score = roc_auc_score(Y_train ,train_prediction)\n        \n        validate_prediction = model.predict_proba(X_val)[:,1]\n        validate_score = roc_auc_score(Y_val , validate_prediction)\n        scores.append((train_score , validate_score))\n        \n        print(f\"Fold {i+1} | AUC : {validate_score} \")\n        \n    scores = pd.DataFrame(scores ,columns=[\"train Score\" , \"Validation Score\"])\n    return scores[\"Validation Score\"].mean()","3152f553":"study_cb = optuna.create_study(direction =\"maximize\")\nstudy_cb.optimize(objective_cb,n_trials=10)\nprint(\"Numbers of finished trials : \" , len(study_cb.trials))\nprint(\"Best Trials : \", study_cb.best_trial.params)\nprint(\"Best Values : \" , study_cb.best_value)","e5efc6be":"cb_params = study_cb.best_trial.params\ncb_params","4e9a2b5f":"folds = StratifiedKFold(n_splits=5,random_state=228,shuffle=True)\npredictions = np.zeros(len(X_test))\nfor fold,(train_idx,validate_idx) in enumerate(folds.split(X,Y)):\n    X_train,X_validate = X.iloc[train_idx] ,X.iloc[validate_idx]\n    Y_train,Y_validate = Y.iloc[train_idx] ,Y.iloc[validate_idx]\n    cb_model = CatBoostClassifier(**cb_params ,bootstrap_type=\"Bernoulli\",random_seed= 228 ,loss_function=\"Logloss\",eval_metric=\"AUC\",task_type= \"GPU\")\n    cb_model.fit(X_train,Y_train,eval_set = [(X_validate,Y_validate)],verbose =False,early_stopping_rounds =300)\n    predictions += cb_model.predict_proba(X_test)[:,1] \/folds.n_splits","6dfa9da2":"submit = pd.DataFrame({\"id\":test_df['id'] , \"claim\": predictions})\nsubmit.to_csv(\"\/kaggle\/working\/catboost_submit.csv\",index=False)\n","6942706d":"def objective_lgbm(trial , data = X ,Target=Y):\n    \n    params = {\"n_estimators\" : trial.suggest_int(\"n_estimators\" , 1000 , 15000),\n             \"max_depth\" : trial.suggest_int(\"max_depth\", 2,4),\n             \"learning_rate\": trial.suggest_float(\"learning_rate\",0.005 ,0.2),\n             \"reg_alpha\": trial.suggest_float(\"reg_alpha\" , 0.001 , 10 ),\n             \"reg_lambda\" : trial.suggest_float(\"reg_lambda\" , 0.001 , 10),\n             \"num_leaves\":trial.suggest_int(\"num_leaves\" , 50 ,500),\n             \"min_data_per_group\":trial.suggest_int(\"min_data_per_group\",50,200),\n             \"min_child_samples\":trial.suggest_int(\"min_child_samples\",5,200),\n             \"colsample_bytree\":trial.suggest_float(\"colsample_bytree\",0.1 ,0.8),\n             \"boosting_type\": \"gbdt\",\n             \"objective\": \"binary\",\n             \"random_state\": 228,\n             \"metric\": \"auc\",\n             \"device\": \"gpu\"\n             }\n    \n    model  = LGBMClassifier(**params)\n    scores = []\n    \n    K = StratifiedKFold(n_splits=4,random_state=228 , shuffle=True)\n    for i ,(train_idx , val_idx) in enumerate(K.split(X,Y)):\n        X_train ,X_val = X.iloc[train_idx],X.iloc[val_idx]\n        Y_train ,Y_val = Y.iloc[train_idx],Y.iloc[val_idx]\n        model.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],early_stopping_rounds=300 , verbose =False)\n        \n        train_prediction = model.predict_proba(X_train)[:,1]\n        train_score = roc_auc_score(Y_train ,train_prediction)\n        \n        validate_prediction = model.predict_proba(X_val)[:,1]\n        validate_score = roc_auc_score(Y_val , validate_prediction)\n        scores.append((train_score , validate_score))\n        \n        print(f\"Fold {i+1} | AUC : {validate_score} \")\n    \n    scores = pd.DataFrame(scores ,columns=[\"train Score\" , \"Validation Score\"])\n    return scores[\"Validation Score\"].mean()","60d3b52a":"study_lgbm = optuna.create_study(direction=\"maximize\")\nstudy_lgbm.optimize(objective_lgbm ,n_trials=10)\nprint(\"Numbers of finished trials : \" , len(study_lgbm.trials))\nprint(\"Best Trials : \", study_lgbm.best_trial.params)\nprint(\"Best Values : \" , study_lgbm.best_value)","26b80d37":"lgbm_params = study_lgbm.best_trial.params\nlgbm_params","3631cfa3":"lgbm_params ={'n_estimators': 6630, 'max_depth': 3, 'learning_rate': 0.053625067203773684,\n              'reg_alpha': 4.618041066261469, 'reg_lambda': 7.9389723810790604, 'num_leaves': 203,\n              'min_data_per_group': 83, 'min_child_samples': 141, 'colsample_bytree': 0.13048987522123276}","139aa53e":"folds = StratifiedKFold(n_splits=5,random_state=228,shuffle=True)\npredictions = np.zeros(len(X_test))\nfor fold,(train_idx,validate_idx) in enumerate(folds.split(X,Y)):\n    X_train,X_validate = X.iloc[train_idx] ,X.iloc[validate_idx]\n    Y_train,Y_validate = Y.iloc[train_idx] ,Y.iloc[validate_idx]\n    lgbm_model = LGBMClassifier(**lgbm_params,boosting_type=\"gbdt\",objective=\"binary\",random_state=228,metric=\"auc\",device=\"gpu\")\n    lgbm_model.fit(X_train,Y_train,eval_set = [(X_validate,Y_validate)],verbose =False,early_stopping_rounds =300)\n    predictions += lgbm_model.predict_proba(X_test)[:,1] \/folds.n_splits","931d8026":"submit = pd.DataFrame({\"id\":test_df['id'] , \"claim\": predictions})\nsubmit.to_csv(\"\/kaggle\/working\/lgbm_submit.csv\",index=False)\n","097837af":"Train Model with optuna","2c350dc7":"# XGBoost Model","16259eaf":"# EDA","6f7ee72b":"# CatBoost","457090fe":"# Import Data","492a58e3":"# LGBM","9ffc5766":"Predict X-test","8ec3bc65":"Train with Optuna ","2dbfb7d8":"# Preproccesing","f20fdc97":"Predict X_test","86e921e1":"Train model with uptuna","cc252857":"Predict X_Test"}}