{"cell_type":{"1a60b67b":"code","a17f2a41":"code","1aff99c9":"code","be018197":"code","a82a4532":"code","9d0e2fe0":"code","ef64ec3b":"code","b7e84e4e":"code","3acdb968":"code","f2ac34ce":"code","5b1b617d":"code","b5a0789f":"code","8c767442":"code","29f79654":"code","6c9d6324":"code","03e2d021":"code","f26dc769":"code","05b21fa9":"code","e6b42a1f":"code","3dcdf9d6":"code","65688877":"code","23b2d8eb":"code","3bd35145":"code","704f72e4":"code","09690900":"code","7280c46c":"code","9b74678e":"code","e16e5996":"markdown","9761f8ce":"markdown","20a5cec6":"markdown","f5abd2c3":"markdown","90ad03d2":"markdown","31e78e59":"markdown","3c617644":"markdown","a837d22f":"markdown","4e4c9dc5":"markdown","8c7d84c2":"markdown","9189ab2c":"markdown","43d9effb":"markdown","bd5b70ad":"markdown","622b4856":"markdown","4829381f":"markdown","d955a227":"markdown","ef581ee2":"markdown","383f78fe":"markdown","2c8d4638":"markdown","bcdeff77":"markdown","15867d73":"markdown","41f52a8f":"markdown","83c8e4c2":"markdown","7c40e534":"markdown"},"source":{"1a60b67b":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time","a17f2a41":"train = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\ntrain.head()","1aff99c9":"test = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\ntest.head()","be018197":"sns.countplot(data=train, x=\"target\")","a82a4532":"# check the detail\nprint(train.shape)\nnum_target_exist = train[\"target\"] == 1\n# count target == 1\nprint(\"exist:{0}\".format(num_target_exist.sum()))\nnum_target_notexist = ~(train[\"target\"] == 1)\nprint(\"not exist:{0}\".format(num_target_notexist.sum()))","9d0e2fe0":"def convert_image_id_2_path(image_id: str, is_train: bool = True) -> str:\n    folder = \"train\" if is_train else \"test\"\n    return \"..\/input\/g2net-gravitational-wave-detection\/{}\/{}\/{}\/{}\/{}.npy\".format(\n        folder, image_id[0],  image_id[1],  image_id[2],  image_id \n    )","ef64ec3b":"# \u306a\u305c\u4e8b\u524d\u306b\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"\u3000\u306e\u9806\u756a\u3060\u3068\u308f\u304b\u3063\u305f\u306e\u304b\uff1f\ndef visualize_sample(_id, target, colors=(\"black\", \"red\", \"green\"), signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")):\n    # visualize_train_data\n    path = convert_image_id_2_path(_id)\n    x = np.load(path)\n    # print(x) # show the source data\n    plt.figure(figsize=(16, 7))\n    for i in range(3):\n        plt.subplot(4, 1, i+1)\n        plt.plot(x[i], color=colors[i])\n        plt.legend([signal_names[i]], fontsize=12, loc=\"lower right\")\n        \n        plt.subplot(4, 1, 4)\n        plt.plot(x[i], color=colors[i])\n    \n    plt.subplot(4, 1, 4)\n    plt.legend(signal_names, fontsize=12, loc=\"lower right\")\n    \n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show","b7e84e4e":"for i in random.sample(train.index.tolist(), 3):\n    _id = train.iloc[i]['id']\n    target = train.iloc[i]['target']\n    visualize_sample(_id, target)","3acdb968":"import librosa\nimport librosa.display","f2ac34ce":"def visualize_sample_spectogram(_id, target, signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        X = librosa.stft(x[i] \/ x[i].max()) # why x[i] \/ x[i].max()?\n        Xdb = librosa.amplitude_to_db(abs(X))\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(Xdb, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-3, vmax=50)\n        plt.colorbar()\n        plt.title(signal_names[i], fontsize=14)\n        \n        \n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","5b1b617d":"for i in random.sample(train.index.tolist(), 3):\n    _id = train.iloc[i]['id']\n    target = train.iloc[i]['target']\n    visualize_sample_spectogram(_id, target)","b5a0789f":"!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2 # \u5b9a\u6570Q\u5909\u63db\u3092\u8a08\u7b97\u3059\u308b\u305f\u3081\u306e\u52b9\u7387\u7684\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0","8c767442":"Q_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(_id, target, signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"), sr=2048):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n        \n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","29f79654":"for i in random.sample(train.index.tolist(), 3):\n    _id = train.iloc[i]['id']\n    target = train.iloc[i]['target']\n    \n    visualize_sample(_id, target)\n    visualize_sample_qtransform(_id, target)","6c9d6324":"!pip install efficientnet_pytorch -qq","03e2d021":"import torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport efficientnet_pytorch\nfrom sklearn.model_selection import StratifiedKFold # \u4ea4\u5dee\u691c\u8a3c \u5206\u5e03\u306b\u5927\u304d\u306a\u4e0d\u5747\u8861\u304c\u3042\u308b\u5834\u5408\u306b\u7528\u3044\u308bKFold,  \u5206\u5e03\u306e\u6bd4\u7387\u3092\u7dad\u6301\u3057\u305f\u307e\u307e\u30c7\u30fc\u30bf\u3092\u8a13\u7df4\u7528\u3068\u30c6\u30b9\u30c8\u7528\u306b\u5206\u5272\u3059\u308b\uff0e","f26dc769":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets):\n        self.paths = paths\n        self.targets = targets\n        \n        self.q_transform = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            waves = x[i] \/ np.max(x[i])\n            waves = torch.from_numpy(waves).float()\n            channel = self.q_transform(waves).squeeze().numpy()\n            image.append(channel)\n        \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        # \u30c7\u30fc\u30bf\u306eindex\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u524d\u51e6\u7406(x: Q-Transform\u3067\u753b\u50cf\u5316, y: \u753b\u50cf\u3092Tensor\u5316)\u3092\u3057\u3066\u8fd4\u3059\n        file_path = convert_image_id_2_path(self.paths[index])\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n        y = torch.tensor(self.targets[index], dtype=torch.float)\n        \n        return {\"X\": image, \"y\": y}","05b21fa9":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_pretrained(\"efficientnet-b7\")\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","e6b42a1f":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, val):\n        self.n += 1\n        # \u2193Whats?  (incremental update)\n        \n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n        \n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update (unfamiliar)\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","3dcdf9d6":"class Trainer:\n    # do train\n    def __init__(self, model, device, optimizer, criterion, loss_meter, score_meter):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0 # early_stopping\u306e\u305f\u3081\u306b\u3001\u6b62\u3081\u308b\u6307\u6a19 (\u4eca\u56de\u306f100epoch\u3067stop)\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n            \n            if True:\n                # if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n            \n                \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            \n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n            \n            self.optimizer.step() # update weight\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}\/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n                   \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n            \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n        \n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_score: {:.5f}' \n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n            \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n        \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n        {\n            \"model_state_dict\" : self.model.state_dict(),\n            \"optimizer_state_dict\" : self.optimizer.state_dict(),\n            \"best_valid_score\" : self.best_valid_score,\n            \"n_epoch\" : n_epoch,\n        },\n        save_path\n        )\n    @staticmethod        \n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","65688877":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nskf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train, train[\"target\"])):\n    # prepare Dataset\n    train_X = train.iloc[train_index]\n    valid_X = train.iloc[valid_index][:20000]  # Reduce calculation time\n    print(train_X.shape, valid_X.shape)\n    \n    train_data_retriever = DataRetriever(\n        train_X[\"id\"].values,\n        train_X[\"target\"].values\n    )\n    valid_data_retriever = DataRetriever(\n        valid_X[\"id\"].values, \n        valid_X[\"target\"].values\n    )\n    \n    train_loader = torch_data.DataLoader(train_data_retriever, batch_size=32, shuffle=True, num_workers=8)\n    valid_loader = torch_data.DataLoader(valid_data_retriever, batch_size=32, shuffle=False, num_workers=8)\n    \n    model = Model()\n    model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n    \n    trainer = Trainer(model, device, optimizer, criterion, LossMeter, AccMeter)\n    \n    # train 1epoch\n    history = trainer.fit(1, train_loader, valid_loader, f\"best-model-{fold}.pth\" ,100)","23b2d8eb":"models = []\nfor i in range(2):\n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(f\"best-model-{i}.pth\")\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","3bd35145":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n\n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        )\n    \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            waves = x[i] \/ np.max(x[i])\n            waves = torch.from_numpy(waves).float() # numpy to tensor\n            channel = self.q_transform(waves).squeeze().numpy() # .numpy() :This implicitly means that the converted tensor will be now processed on the CPU.\n            image.append(channel)\n        \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        file_path = convert_image_id_2_path(self.paths[index], is_train=False)\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n        \n        return {\"X\": image, \"id\": self.paths[index]}","704f72e4":"test_data_retriever = DataRetriever(\n    test[\"id\"].values,\n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=32,\n    shuffle=False,\n    num_workers = 8\n)","09690900":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res \/ 2\n        y_pred.extend(tmp_pred)\n        ids.extend(batch[\"id\"])","7280c46c":"submission = pd.DataFrame({\"id\": ids, \"target\": y_pred})\nsubmission.to_csv(\"model_submission.csv\", index=False)","9b74678e":"submission","e16e5996":"#### \ud83d\udc49  the Goal of this competition is to show probability whether GW in the time serise data","9761f8ce":"# Goal\/ Explanation\n\nIn this competition, you\u2019ll aim to detect GW signals from the mergers of binary black holes. Specifically, you'll build a model to analyze simulated GW time-series data from a network of Earth-based detectors.  \n(\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3067\u306f\u3001\u9023\u661f\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u5408\u4f75\u306b\u3088\u308bGW\u4fe1\u53f7\u306e\u691c\u51fa\u3092\u76ee\u6307\u3057\u307e\u3059\u3002\u5177\u4f53\u7684\u306b\u306f\u3001\u5730\u7403\u30d9\u30fc\u30b9\u306e\u691c\u51fa\u5668\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304b\u3089\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305fGW\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u5206\u6790\u3059\u308b\u305f\u3081\u306e\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b)\n\nThese signals are unimaginably tiny ripples in the fabric of space-time and even though the global network of GW detectors are some of the most sensitive instruments on the planet, the signals are buried in detector noise.\uff08\u8981\u7d04:\u3053\u308c\u3089\u306e\u4fe1\u53f7\u306f\u3068\u3066\u3082\u5c0f\u3055\u306a\u3055\u3056\u306a\u307f\u3067\u3042\u308a\u3001\u304b\u306a\u308a\u7cbe\u5bc6\u306aGW\u691c\u77e5\u6a5f\u3092\u3082\u3063\u3066\u3057\u3066\u3082\u3001\u30ce\u30a4\u30ba\u306b\u57cb\u3082\u308c\u3066\u3057\u307e\u3046)  \n\nIn this competition you are provided with a training set of time series data containing simulated gravitational wave measurements from a network of 3 gravitational wave interferometers (LIGO Hanford, LIGO Livingston, and Virgo).   \n(\u3053\u306e\u30b3\u30f3\u30da\u30c6\u30a3\u30b7\u30e7\u30f3\u3067\u306f\u30013\u3064\u306e\u91cd\u529b\u6ce2\u5e72\u6e09\u8a08\uff08LIGO\u30cf\u30f3\u30d5\u30a9\u30fc\u30c9\u3001LIGO\u30ea\u30d3\u30f3\u30b0\u30b9\u30c8\u30f3\u3001\u304a\u3088\u3073\u30d0\u30fc\u30b4\uff09\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304b\u3089\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f\u91cd\u529b\u6ce2\u6e2c\u5b9a\u5024\u3092\u542b\u3080\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u304c\u63d0\u4f9b\u3055\u308c\u307e\u3059\u3002)\n\nEach time series contains either detector noise or detector noise plus a simulated gravitational wave signal.   \n(\u5404\u6642\u7cfb\u5217\u306b\u306f\u3001\u691c\u51fa\u5668\u30ce\u30a4\u30ba\u307e\u305f\u306f\u691c\u51fa\u5668\u30ce\u30a4\u30ba\u306e\u3044\u305a\u308c\u304b\u3068\u3001\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f\u91cd\u529b\u6ce2\u4fe1\u53f7\u304c\u542b\u307e\u308c\u307e\u3059\u3002)  \nThe task is to identify when a signal is present in the data (target=1).  \u203b\u30b7\u30b0\u30ca\u30eb\u306a\u306e\u3067\u3001\u91cd\u529b\u6ce2\u306e\u6ce2\u5f62\u3092\u305d\u306e\u307e\u307e\u8868\u3057\u3066\u306f\u3044\u306a\u3044\uff1f  \n(\u30bf\u30b9\u30af\u306f\u3001\u4fe1\u53f7\u304c\u30c7\u30fc\u30bf\u306b\u5b58\u5728\u3059\u308b\u3068\u304d\u3092\u8b58\u5225\u3059\u308b\u3053\u3068\u3067\u3059\uff08target = 1\uff09  )\u3000\u21e8 \u5b58\u5728\u3059\u308b\u78ba\u7387\u3092\u51fa\u3059\n\nEach data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.  \n(\u5404\u30c7\u30fc\u30bf\u30b5\u30f3\u30d7\u30eb\uff08npy\u30d5\u30a1\u30a4\u30eb\uff09\u306b\u306f3\u3064\u306e\u6642\u7cfb\u5217\uff08\u5404\u691c\u51fa\u5668\u306b1\u3064\uff09\u304c\u542b\u307e\u308c\u3001\u305d\u308c\u305e\u308c\u304c2\u79d2\u306b\u307e\u305f\u304c\u308a\u30012,048Hz\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u307e\u3059\u3002)\n  \n\u4fe1\u53f7\u5bfe\u96d1\u97f3\u6bd4\uff08SNR\uff09 : \u4fe1\u53f7\u304c\u3069\u306e\u7a0b\u5ea6\u691c\u51fa\u53ef\u80fd\u3067\u3042\u308b\u304b\u3092\u793a\u3059\u6700\u3082\u6709\u76ca\u306a\u5c3a\u5ea6","20a5cec6":"## Competition Metric\nAUC - ROC curve","f5abd2c3":"# EDA","90ad03d2":"### Prepare testdata","31e78e59":"### Look at training_labels.csv","3c617644":"### nnAudio\n* nnAudio is an audio processing toolbox using PyTorch convolutional neural network as its backend.  \n* spectrograms can be generated from audio on-the-fly during neural network training and the Fourier kernels (e.g. or CQT kernels) can be trained","a837d22f":"## Reference\n* [kaggle\u65e5\u672c\u8a9e\u521d\u5fc3\u8005\u53d6\u308a\u7d44\u307f](https:\/\/www.kaggle.com\/tensorchoko\/g2net-gravitational-timm-efn-train#%F0%9F%8E%B5import)\n* [top kaggler Modeling](https:\/\/www.kaggle.com\/ihelon\/g2net-eda-and-modeling)  \n* [Good Tutorial EDA](https:\/\/www.kaggle.com\/andradaolteanu\/g2net-searching-the-sky-pytorch-effnet-w-meta)","4e4c9dc5":"### Signal transformation - Spectogram","8c7d84c2":"#### DataLoader\ndatasets\u304b\u3089\u30d0\u30c3\u30c1\u3054\u3068\u306b\u53d6\u308a\u51fa\u3059  \ndatsets = [\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u5168\u3066]  \nDataloader = [[batch_1], [batch_2], ... [batch_n]]  \nthat is..   \nlen(datasets)=\"\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf\u306e\u6570\"  \nlen(Dataloader)=\"\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u6570\"  ","9189ab2c":"### Look at sample_submission.csv","43d9effb":"#### EfficientNet  \nArrange 3 balance in \"depth\" \/ \"width\" \/ \"resolution\" properly  \u203b not change the Arichitecture  \n(\u30e2\u30c7\u30eb\u306e\u300c\u6df1\u3055\u300d\u3068\u300c\u5e83\u3055\u300d\u3068\u300c\u89e3\u50cf\u5ea6(=\u5165\u529b\u753b\u50cf\u306e\u5927\u304d\u3055)\u300d\u306e3\u3064\u3092\u30d0\u30e9\u30f3\u30b9\u3088\u304f\u8abf\u6574\u3059\u308b \u203b\u30ec\u30a4\u30e4\u30fc\u306e\u30a2\u30fc\u30ad\u30c6\u30a3\u30af\u30c1\u30e3\u81ea\u4f53\u306f\u5909\u3048\u306a\u3044)","bd5b70ad":"* target = 1 GW exist \/ target = 0 GW not exist","622b4856":"### Signal transformation - Q-transform","4829381f":"#### check the detail","d955a227":"Each data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.  ","ef581ee2":"### Inference","383f78fe":"### distribution train","2c8d4638":"### choice best model","bcdeff77":"#### Model Efficientnet","15867d73":"# Model","41f52a8f":"### Library","83c8e4c2":"## Training","7c40e534":"## Submission"}}