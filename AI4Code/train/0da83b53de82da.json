{"cell_type":{"65f76c8c":"code","cfac6953":"code","f59f2962":"code","24896699":"code","caf75b7a":"code","45d7967c":"code","bc887247":"code","7d486a30":"code","7fac1d70":"code","e4aca8ca":"code","8d986c10":"code","fce35570":"code","d7b92c6e":"code","89730775":"code","181a3a59":"code","f0b412d0":"code","7cb2cf5d":"code","b03afb65":"code","5cde6520":"code","bb97e8a0":"code","60e05f3d":"code","0b6bd703":"code","b8b20cd3":"code","2b3cfcde":"code","5faadacd":"code","0d5660b8":"code","317c56ec":"code","a4d2c0fd":"code","38bd3d62":"code","3fde646b":"code","fee96581":"code","2b1de4bd":"code","0184ff44":"code","ab8aefb9":"code","f26862bd":"code","e1f55e1d":"code","08d63545":"code","78adffce":"markdown","e4c774fd":"markdown","fb045607":"markdown","df2db1fa":"markdown"},"source":{"65f76c8c":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns ","cfac6953":"df = pd.read_csv('..\/input\/drug-classification\/drug200.csv')\ndf.head().style.background_gradient(axis=0)","f59f2962":"df.info()","24896699":"df.isnull().sum()","caf75b7a":"# Let's check the Target_feature , and as we see there is imblance data issue we have to solve first before fitting model on this data we have ; b\nplt.figure(figsize = (6,3),dpi = 200)\nsns.countplot(data = df , x = 'Drug')","45d7967c":"plt.figure(figsize = (8,4),dpi = 200)\nsns.scatterplot(data = df , x = 'Age' , y = 'Na_to_K',hue = 'Drug')","bc887247":"plt.figure(figsize = (10,6))\nsns.barplot(x = 'Cholesterol', y = 'Na_to_K', hue = 'Drug', data = df)\nplt.title(\"CH vs NA_to_K\")\nplt.show()","7d486a30":"plt.figure(figsize = (10,6))\nsns.barplot(x = 'Sex', y = 'Age', hue = 'Drug', data = df)\nplt.title(\"CH vs NA_to_K\")\nplt.show()","7fac1d70":"plt.figure(figsize = (10,6))\nsns.boxplot(data = df , x = 'Sex' , y = 'Age',hue = 'Drug')","e4aca8ca":" drug_count = df['Drug'].value_counts().tolist()","8d986c10":"drug_label = df['Drug'].value_counts().index","fce35570":"plt.figure(figsize = (8,4),dpi = 150)\nplt.pie(drug_count , labels = drug_label , autopct = '%1.2f%%',textprops={'fontweight':'bold','size' :13},explode = [0.1,0,0,0,0],startangle= 90,\n       pctdistance = 0.8 , radius = 2)\nplt.show()","d7b92c6e":"plt.figure(figsize = (6,4),dpi = 150)\nsns.heatmap(df.corr(),annot = True)","89730775":"# Divid data to X and y , and also get dummies for all object data \nX = pd.get_dummies(df.drop('Drug', axis = 1), drop_first= True ,prefix_sep = '*')\ny = df['Drug']","181a3a59":"from imblearn import over_sampling , under_sampling\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\nX_resambled , y_resampled = ros.fit_resample(X,y)","f0b412d0":"# Now we are going to make train test split to split the data we have to train data and test data \nfrom sklearn.model_selection import train_test_split","7cb2cf5d":"X_train, X_test, y_train, y_test = train_test_split(X_resambled, y_resampled, test_size=0.20, random_state=101)","b03afb65":"from sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report","5cde6520":"# Now we are going to make for loop to get the best K value : \n\ntest_error_rate = []\n\nfor k in range (1,30): \n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(X_train , y_train)\n    y_pred = knn_model.predict(X_test)\n    \n    test_error = 1 - accuracy_score(y_test , y_pred)\n    test_error_rate.append(test_error)","bb97e8a0":"plt.plot(range(1,30), test_error_rate)\nplt.ylabel('Test_error_rate')\nplt.xlabel('K Value')\nplt.title('Get The Best K Value VS Test_error_Rate')","60e05f3d":"knn_model = KNeighborsClassifier(n_neighbors=1)\nknn_model.fit(X_train,y_train)","0b6bd703":"# Now lets diefine a function that will calculate needed metrics to avoid doing it on the upcoming algorithms D:\n\ndef metrics_needed (model):\n    y_pred = model.predict(X_test)\n    \n    print('\/n')\n    \n    print(classification_report(y_test,y_pred))\n    plot_confusion_matrix(model , X_test , y_test)","b8b20cd3":"metrics_needed(knn_model)","2b3cfcde":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV","5faadacd":"svc = SVC()\nparam_grid = {'C':[0.001,0.01,1]}","0d5660b8":"grid_model = GridSearchCV(svc,param_grid)","317c56ec":"grid_model.fit(X_train,y_train)","a4d2c0fd":"grid_model.best_params_","38bd3d62":"metrics_needed(grid_model)","3fde646b":"from sklearn.tree import DecisionTreeClassifier","fee96581":"tree_model = DecisionTreeClassifier()","2b1de4bd":"tree_model.fit(X_train,y_train)","0184ff44":"metrics_needed(tree_model)","ab8aefb9":"from sklearn.ensemble import RandomForestClassifier","f26862bd":"random_model = RandomForestClassifier(n_estimators=10 , max_features='auto',random_state=101)","e1f55e1d":"random_model.fit(X_train,y_train)","08d63545":"metrics_needed(random_model)","78adffce":"Decision_Tree Algorithm","e4c774fd":"SVM Algorith ","fb045607":"**KNN**","df2db1fa":"**Random_Forest_classifier_Algorithm**"}}