{"cell_type":{"c6c57aa1":"code","78570938":"code","4809d829":"code","3e7b9408":"code","feabcbfd":"code","40cb04f0":"code","87bc1b34":"code","16d1010e":"code","377fd292":"code","804fa597":"code","e4f8a4a0":"code","c926d67b":"code","b8a06329":"code","93bc89e2":"code","2720dd4f":"code","eb254164":"code","ce8d2cfc":"code","20e644ce":"code","22b56fc1":"code","5d3094ab":"code","ae67d5c2":"code","fbfcc0e1":"code","15ac6b5e":"code","f560829a":"code","1dd27abb":"code","9de8c28c":"code","c28b16c5":"code","1c8b2603":"code","9157e235":"code","0403deea":"code","6fe3253b":"code","36d1b872":"code","d9335585":"code","0b9e7817":"code","0c7cc053":"code","0bce7361":"code","7ec2c25f":"code","121df572":"code","14a2a8fb":"code","d2d6c48a":"code","04c420ba":"code","034ed912":"code","958b5cb3":"code","1debcbfc":"code","0c655545":"code","2c7d8f15":"code","cb97e183":"code","e2a0a1bc":"code","39ed769b":"code","deee8c04":"code","c39b3cb3":"code","2dbdca18":"code","23296ed2":"code","32105552":"code","2059dcde":"code","ba143762":"code","ac43218d":"code","2604b686":"code","e12554df":"code","966f7b90":"code","eb4f29be":"code","6753f4c9":"code","dcff5ea0":"code","bc23a20d":"code","f91b018c":"code","cc76c2fc":"code","d3aefc6f":"code","accdd941":"code","df4f481f":"code","2d4b115b":"code","05b895ea":"code","4e658e86":"code","12f55810":"code","f59ea45c":"code","2a56fe1a":"code","dad01468":"code","884be7e0":"code","fcb12f9e":"code","9d7b8a3d":"code","f8b983dc":"code","1d0fa189":"code","cacf55ef":"code","a909d0c7":"code","fe01cabf":"code","0a119f4c":"code","4c50e973":"code","3df790d1":"code","98a3495b":"code","72c9b8de":"code","c4302a46":"code","4cd7f75f":"code","8513ed5b":"code","f1935b34":"markdown","a85854b3":"markdown","b227228e":"markdown","c63da23b":"markdown","77eee463":"markdown","db4afee7":"markdown","dbf981bc":"markdown","2c1f7665":"markdown","a9c385b4":"markdown","436716ae":"markdown","35795ed7":"markdown","1321ebaf":"markdown","6e6dea63":"markdown","827a7c9d":"markdown","543aa110":"markdown","39feea4f":"markdown","ff9e6380":"markdown","df8334af":"markdown","aa23f42c":"markdown","4e1f892b":"markdown","c3a80b71":"markdown","f47c8e70":"markdown","d1867af4":"markdown","d5393b02":"markdown","79e6ba06":"markdown","f19fc9cd":"markdown","e666ad66":"markdown","a30e1205":"markdown","0125e337":"markdown","c25b5f5f":"markdown","d3b36dfa":"markdown","1a088f65":"markdown","acb5d771":"markdown","0995d323":"markdown"},"source":{"c6c57aa1":"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport scipy.stats as stat\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\n#For Neural networdk Keras\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","78570938":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4809d829":"train.shape,test.shape","3e7b9408":"train.info() #to check the type of data int\/float, and the vogue idea about null values","feabcbfd":"test.info()  #to check the type of data int\/float, and the vogue idea about null values","40cb04f0":"train.head(4)","87bc1b34":"test.head(4)","16d1010e":"train.describe()","377fd292":"#quant_features=train.select_dtypes(exclude=['object']).columns\n#cat_features=train.select_dtypes(include=['object']).columns\nquant_feature=['Age','SibSp','Parch','Fare']\ncat_features=['Pclass','Sex','Embarked','Ticket','Cabin','Survived']","804fa597":"for i in cat_features:\n    #sns.countplot(x=i,data=train)\n    sns.countplot(x=i,data=train,hue='Survived')\n    plt.show()\n    sns.barplot(x=i,y='Survived',data=train)\n    plt.show()","e4f8a4a0":"#Check the disturbution of quantiative data and might be required to standardize\/normalize it , ","c926d67b":"for i in quant_feature:\n    sns.histplot(train[i])\n    plt.show()\n    ","b8a06329":"#heatmap to check the correclation between the featues , \n#if it is highly correlated we have to ignore one of the feature\nsns.heatmap(train[quant_feature].corr(),annot=True)  ","93bc89e2":"x=pd.pivot_table(train,index='Survived',values=quant_feature)\nx","2720dd4f":"group_survival=train.groupby(['Survived','Pclass'])","eb254164":"group_survival['Age',].mean()","ce8d2cfc":"\"\"\"\nCreating a new dataset by combining both the test and train data ,which will be easy to preprocess and later just before modeling split it again into train and test \nThis will avoid the tedious process of preprocessing train and test datasets seperately and avoid confusiions lateron \"\"\"\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","20e644ce":"IDtest = test[\"PassengerId\"]\n\"\"\"\nThe passenger id for the test data is required as column name IDtest in future for submission \n\"\"\"","22b56fc1":"dataset.isnull().sum()","5d3094ab":"dataset['Embarked']=dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])  \n#since it is two Nan in Embarked, filled with the mode or maximum occurance","ae67d5c2":"dataset['Fare']=dataset['Fare'].fillna(dataset['Fare'].median()) \n#Nan-Fare values filled with median of the data","fbfcc0e1":"sns.boxplot(x='Sex',y='Age',data=dataset)\n# the distribution of age data (range as well as the mean ) against Gender are amlost same.\n# we can ignore this feature to fill Age Nan.","15ac6b5e":"sns.boxplot(x='Pclass',y='Age',data=dataset)\n#in this we can observe the distribution of Age against different Pclass class is different , \n#so this can be considered to fill Age NaN values","f560829a":"sns.boxplot(x='Parch',y='Age',data=dataset)\n#in this we can observe the distribution of Age against different Parch class is different , \n#so this can be considered to fill Age NaN values","1dd27abb":"sns.boxplot(x='SibSp',y='Age',data=dataset)\n#in this we can observe the distribution of Age against different SibSp class is different , \n#so this can be considered to fill Age NaN values","9de8c28c":"\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) &\n                               (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) &\n                               (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med","c28b16c5":"#total passengers is 1309, but unique ticket count is  only 929, that means there might be more than one passengers in one ticket or same cabin\ndataset.shape ,len(dataset['Ticket'].unique())","1c8b2603":"dataset['Cabin'].unique() #This is to check the non filled nan cabins what string can be used to impute , XX is not in current data so used XX string to impute","9157e235":"\"\"\"Below code is used to fill the Nan cabin values with the exisitng cabin values which have same ticket number of the missing cabin(Nan Cabin)\nBut not much effective since only 14 cabins can be able to fill in that way \nso the remaining cabins considered as a seperate class named XX\n\"\"\"\nindex_NaN_cabin = list(dataset[\"Cabin\"][dataset[\"Cabin\"].isnull()].index)\nfor i in index_NaN_cabin:\n    for j in range(0,len(dataset)):\n        if dataset['Ticket'].iloc[j]==dataset['Ticket'].iloc[i]:\n            dataset['Cabin'].iloc[i]=dataset['Cabin'].iloc[j]\n            continue\n\ndataset['Cabin']=dataset['Cabin'].fillna('XX')","0403deea":"dataset.isnull().sum()","6fe3253b":"\"\"\"\nJust to check the behaviour name data\"\"\"\ndataset['Name'].head(5),dataset['Name'].tail(5)","36d1b872":"title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]","d9335585":"dataset['Title']=pd.Series(title) #added the tittle series to the dataframe \ndataset['Title'].unique() #eheck the unique values","0b9e7817":"group_title=dataset.iloc[:len(train)].groupby('Title')\ngroup_title['Survived'].value_counts(normalize=True)\n","0c7cc053":"\"\"\"\nBy observing above table we can find some inputs about the survival rate among the tittle groups \nso we can group the passengers according to the tittle and its survival rates\"\"\"\n\ngroup1=['Capt','Rev','Jonkheer','Don','Dona'] #grouped based on survival rate\ngroup2=['Dr', 'Major','Col'] #grouped based on survival rate\ngroup3=['the Countess','Countess', 'Sir',] #grouped based on survial rate\ngroup4=['Mr'] #title for men\ngroup5=['Master'] #title for a boys\ngroup6=[ 'Mrs', 'Miss','Mme', 'Ms','Mlle','Lady']# tittle for ladies\n\n\ndataset['Title']=dataset['Title'].replace(group1,'1')\ndataset['Title']=dataset['Title'].replace(group2,'2')\ndataset['Title']=dataset['Title'].replace(group3,'3')\ndataset['Title']=dataset['Title'].replace(group4,'4')\ndataset['Title']=dataset['Title'].replace(group5,'5')\ndataset['Title']=dataset['Title'].replace(group6,'6')\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","0bce7361":"dataset['Title'].unique()","7ec2c25f":"\n\"\"\"\nAfter grouping as above , if we check the groupby again it gives some meaning tittle class\"\"\"\ngroup_title=dataset.iloc[:len(train)].groupby('Title')\ngroup_title['Survived'].value_counts(normalize=True)","121df572":"sns.barplot(x='Title',y='Survived',data=dataset.iloc[:len(train)])\n#This became more meaning full grouping and it obvious that group 3 has highest survival rate and group 1 has least survival rate\n","14a2a8fb":"#So now drop the name colums from the dataset , adn keep title instead\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","d2d6c48a":"# Replace the Cabin number by the type of cabin 'XX' if not\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","04c420ba":"sns.barplot(data=dataset,x='Cabin',y='Survived')","034ed912":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset[\"Ticket\"].head()","958b5cb3":"dataset['Ticket'].unique()","1debcbfc":"dataset['Family']=dataset[\"SibSp\"] + dataset[\"Parch\"] + 1 ","0c655545":"sns.barplot(x='Family',y='Survived',data=dataset)\nplt.show()\nsns.countplot(x='Family',hue='Survived',data=dataset)\nplt.show()","2c7d8f15":"dataset['Family'].head()","cb97e183":"for i in range(0,len(dataset)):\n    if dataset['Family'].iloc[i]== 1:\n        dataset['Family'].iloc[i] = 'Single'\n    elif dataset['Family'].iloc[i] == 2:\n        dataset['Family'].iloc[i] = 'Couple'\n    elif dataset['Family'].iloc[i] >= 3 and dataset['Family'].iloc[i] <=4 :\n        dataset['Family'].iloc[i] = 'SmallFam'\n    elif dataset['Family'].iloc[i] >= 5 and dataset['Family'].iloc[i] <=7 :\n        dataset['Family'].iloc[i] = 'LargeFam'\n    elif dataset['Family'].iloc[i] > 7  :\n        dataset['Family'].iloc[i] = 'BigFam'\n        \n        ","e2a0a1bc":"dataset['Family'].unique()","39ed769b":"dataset.info()","deee8c04":"dataset['Fare'].skew()","c39b3cb3":"sns.histplot(dataset['Fare'],kde='True')\nprint('Skew:',dataset['Fare'].skew())","2dbdca18":"# log norm of fare \ndataset['norm_fare'] = np.log(dataset.Fare)\nsns.histplot(dataset['norm_fare'],kde='True')\nprint('Skew:',dataset['norm_fare'].skew())","23296ed2":"#square root transformation \ndataset['sq_fare'] = dataset['Fare']**(1\/2)\nsns.histplot(dataset['sq_fare'],kde='True')\nprint('Skew:',dataset['sq_fare'].skew())","32105552":"dataset['exp_fare']=dataset['Fare']**(1\/2.7)\nsns.histplot(dataset['exp_fare'],kde='True')\nprint('Skew:',dataset['exp_fare'].skew())","2059dcde":"\n\"\"\"\nBelow is one of the two power transformers  yeo johnson and box cox but we cant use boxcox on 0 \nor negative values so used yeo john transformer here\"\"\"\nimport scipy.stats as stat\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\nptdata=pd.DataFrame(pt.fit_transform(dataset['Fare'].values.reshape(-1,1)),columns=['Fare_YJ'])\nprint('skew',ptdata['Fare_YJ'].skew())\nsns.histplot(ptdata['Fare_YJ'],kde='True')","ba143762":"#Assign the Yj transformed values to dataset\ndataset['Fare_transformed']=ptdata['Fare_YJ']\ndataset.drop(labels = [\"Fare\"], axis = 1, inplace = True) #drop actual Fare feature from the dataset","ac43218d":"dataset.drop(labels = ['norm_fare','exp_fare','sq_fare'], axis = 1, inplace = True) #drop transformed column","2604b686":"dataset['Fare_transformed'].min(),dataset['Fare_transformed'].max()","e12554df":"sns.histplot(dataset['Age'],kde='True')\nprint ('Skew_Age',dataset['Age'].skew())  # Age have very low skew value so not applying the transformation","966f7b90":"sns.histplot(dataset['SibSp'],kde='True')\nprint ('Skew_Sibp',dataset['SibSp'].skew()) ","eb4f29be":"# log norm of Sibsp\ndataset['log_Sib'] = np.log(dataset.SibSp)\nsns.histplot(dataset['log_Sib'],kde='True')\nprint('Skew:',dataset['log_Sib'].skew())","6753f4c9":"ptdata=pd.DataFrame(pt.fit_transform(dataset['SibSp'].values.reshape(-1,1)),columns=['sib_YJ'])\nprint('skew',ptdata['sib_YJ'].skew())\nsns.histplot(ptdata['sib_YJ'],kde='True')","dcff5ea0":"dataset['Sib_norm']=ptdata['sib_YJ'] #Added Yeo-joh transformed Sibsp to the dataset\ndataset.drop(labels = [\"SibSp\"], axis = 1, inplace = True) #drop actual SibSp columns\ndataset.drop(labels = [\"log_Sib\"], axis = 1, inplace = True) #a log transformation created earlier , decicded not to use so deleting it from the dataset","bc23a20d":"sns.histplot(dataset['Parch'],kde='True')\nprint ('Skew_Parch',dataset['Parch'].skew()) ","f91b018c":"# log norm of Parch\ndataset['norm_Par'] = np.log(dataset.Parch)\nsns.histplot(dataset['norm_Par'],kde='True')\nprint('Skew:',dataset['norm_Par'].skew())\ndataset.drop(labels = [\"norm_Par\"], axis = 1, inplace = True) #drop transformed column","cc76c2fc":"dataset.info()","d3aefc6f":"dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],drop_first=True,prefix=\"Pcl\")","accdd941":"dataset[\"Family\"] = dataset[\"Family\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Family\"],drop_first=True,prefix=\"Fam\")","df4f481f":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],drop_first=True,prefix=\"Cabin\")\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"],drop_first=True, prefix=\"T\")","2d4b115b":"dataset = pd.get_dummies(dataset, columns = [\"Title\"],drop_first=True)\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"],drop_first=True, prefix=\"Em\")\ndataset = pd.get_dummies(dataset, columns = [\"Sex\"],drop_first=True, prefix=\"Emb\")","05b895ea":"dataset.info()","4e658e86":"pd.set_option('display.max_columns',80) #this is nothing but to display all the columns in visualization","12f55810":"dataset.describe()\n#Mean std of Age is differnet from the remaining all the features","f59ea45c":"#Apply standard scalar to Age to tranform\nfrom sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\ndataset['Age'] = sc.fit_transform(pd.DataFrame(dataset['Age']))","2a56fe1a":"dataset.describe()","dad01468":"dataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True) #drop irrelevent passenger id","884be7e0":"dataset.head()","fcb12f9e":"train=dataset.iloc[:len(train)] #split \ntest=dataset.iloc[len(train):]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","9d7b8a3d":"train['Survived']=train['Survived'].astype(int)\nY_train=train['Survived']\nX_train=train.drop(columns=['Survived'])","f8b983dc":"x_train,x_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=1)","1d0fa189":"x_train.shape","cacf55ef":"x_train.isnull().sum()","a909d0c7":"keras_model = Sequential()\nkeras_model.add(Dense(units=11,activation='relu'))\nkeras_model.add(Dropout(0.5))\nkeras_model.add(Dense(units=24,activation='relu'))\nkeras_model.add(Dropout(0.5))\nkeras_model.add(Dense(units=1,activation='sigmoid'))\n# For a binary classification problem\nkeras_model.compile(loss='binary_crossentropy', optimizer='adam')","fe01cabf":"y_test=y_test.astype('int32')","0a119f4c":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)","4c50e973":"keras_model.fit(x=x_train, \n          y=y_train, \n          epochs=500,\n          validation_data=(x_test, y_test), verbose=1,callbacks=[early_stop]\n          )","3df790d1":"model_loss = pd.DataFrame(keras_model.history.history)","98a3495b":"model_loss.plot()","72c9b8de":"test_predictions = keras_model.predict(x_test)\ntest_predictions  = predictions > 0.5  \ntest_predictions = predictions.astype(int) ","c4302a46":"predictions = keras_model.predict(test)\npredictions  = predictions > 0.5  \npredictions = predictions.astype(int) \npredictions=predictions.reshape(-1)","4cd7f75f":"submission = pd.DataFrame({'PassengerId': IDtest,'Survived':predictions})\nsubmission.to_csv(\".\/submission.csv\", index=False)","8513ed5b":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Submission CSV file\", filename = \"submission.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a link to download the dataframe\ncreate_download_link(submission)","f1935b34":"## EDA Numerical Features","a85854b3":"Handling NaN : AGE\nFirst need to find which are the other features have influence to age feature\nSo plot other features against Age","b227228e":"### Age","c63da23b":"Feature Extraction from Name columns\nIf we observe the every names have tittle(Mr,Mrs,Rev,Countess etc) which may give the some information \nto group the namesInstead of completley omiting the name column as irrelevent we can check what information \nwe can extract from the name columns\nIf we observe the tittle of the name comes after the surname seperated with a comma.So we can split all the \nnames with respect to comma get into a list and from the list take the second element which is tittle\n","77eee463":"CABIN\nFew of the materials in internet shows that there are decks named A,B,C etc so there is a strong belief that the prefix in the cabin number is nothing but the \ndeck. so in that belief we can extract the initial alphabets and classify it as decks","db4afee7":"for i in range(0,len(dataset)):\n    print (dataset['Family'].iloc[i])","dbf981bc":"## Feature Extraction","2c1f7665":"# Below to Download the CSV from the kernel","a9c385b4":"HANDLE CATAGORICAL FEATURES INTO NUMERICAL ,ONE HOT ENCODING","436716ae":"Age has normally distributed data and very low skew so no need to transform the data","35795ed7":"# 2.FEATURE ENGINEERING","1321ebaf":"## Drop Irrrelevent Data","6e6dea63":"CHECK THE INFO OF THE DATA AND DECIDE WHETHER DO WE NEED TO NORMALIZE ANY FEATURES","827a7c9d":"delete the first index row from the downloaded file(csv) before submission","543aa110":"### SibSp","39feea4f":"So belwo we created a code in to find the age Nan rows having the PClass,Parch,SibSp , have same values eg Row 5,19,\nthen find the rows of same values and fill the with the mean of that group\n\nIf we cant find such group then fill those Nan Ages with Median of the Ages.","ff9e6380":"## Catagorical Data to One-Hot Encoding","df8334af":"SibSp has relatively high skew so need to transform to reduce the skew and make the data normally distributed","aa23f42c":"### Sib \/Parch","4e1f892b":"## Handling Null\/Nan values","c3a80b71":"### Parch","f47c8e70":"FAMILY\nWe can observe that the chance of survival is differnet depends on the size of the family.\nhere the family is the combination of the number of parents \/ children aboard the Titanic and number of siblings \/ spouses aboard the Titanic.\nso we can find the size each family onboard by adding Sibp and Parch + 1(passenger himself)","d1867af4":"### Name","d5393b02":"CHECK THE DATA DISTRUBITION AND SKEW OF EACH NUMERICAL FEATURES\n\nBelow we can check the skew and try different transformers so that the skew will be minimum . among all Yeo john transformer has least skew \nAlso we cant use the box cox transformer since we have some zero values in Fare.","79e6ba06":"# 3. FEATURE SELECTION ","f19fc9cd":"Below plot shows the survial probability based on family class, and the most is with the familyh number 4,\nBut its not necessary that the indivitual traveller will survive , it may be most of the lone travellers are males.\nAlso we can observe that the family size beyond 5 has less chance of survival since the difficulity in mobility altogether.\nby looking below details we can divide the family data into few classes , like single, small family, medium,large,very large","e666ad66":"# 4.NN MODEL CREATION in Keraa","a30e1205":"## Further Normalization of Few Features","0125e337":"## Feature Transformations for Linear models","c25b5f5f":"### Ticket","d3b36dfa":"# 1.EXPLORATORY DATA ANALYSIS (EDA)","1a088f65":"### Fare","acb5d771":"### Cabin","0995d323":"## EDA (Catagorical Features)"}}