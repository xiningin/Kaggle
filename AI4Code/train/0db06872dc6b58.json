{"cell_type":{"30e45f79":"code","1025b487":"code","45ab2e50":"code","92880522":"code","b85fda1b":"code","3703f64e":"code","ccc5c3fa":"code","ba5ecaab":"code","0112f2c2":"code","8e522f9b":"code","0b215113":"code","86498b71":"code","b97d42ed":"code","a22a60f4":"code","f5a5e7e2":"code","6eddfd28":"code","fc966878":"code","f25bd96a":"code","bc3cbf82":"code","0b7d365c":"code","b90e398d":"code","46ff8d74":"code","eeb38c93":"code","7859ceaa":"code","4f21f172":"code","12a3ee28":"code","962416f3":"code","a51d4e27":"code","254e36e0":"code","a1855f3a":"code","d0496805":"code","d43ba3f2":"code","822cd968":"markdown","63ea14ff":"markdown","bd5d2177":"markdown","10136bdf":"markdown","f7ae0218":"markdown","6c0567d0":"markdown","70e47515":"markdown","53dac348":"markdown","2989edb4":"markdown","910e87f3":"markdown","9033308d":"markdown","b0429af1":"markdown","58c7a866":"markdown","3a14de82":"markdown","0626c5bd":"markdown","2ceb4e39":"markdown","83d76fc7":"markdown","e8595a94":"markdown"},"source":{"30e45f79":"import sys\nsys.path.append('..\/input\/torchvisionreferencedetection\/torchvision-reference-derection')","1025b487":"!pip install pycocotools","45ab2e50":"import os\nimport torch\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom engine import train_one_epoch, evaluate\n","92880522":"train_csv_path = \"..\/input\/yolo-animal-detection-small\/train.csv\"\ntest_csv_path = \"..\/input\/yolo-animal-detection-small\/test.csv\"\ntrain_images = \"..\/input\/yolo-animal-detection-small\/yolo-animal-detection-small\/train\"\ntest_images = \"..\/input\/yolo-animal-detection-small\/yolo-animal-detection-small\/test\"","b85fda1b":"train_csv = pd.read_csv(train_csv_path)\ntrain_csv.head()","3703f64e":"train_csv.shape","ccc5c3fa":"test_csv = pd.read_csv(test_csv_path)\ntest_csv.head()","ba5ecaab":"test_csv.shape","0112f2c2":"categories = train_csv[\"class\"].unique()\nprint(categories)","8e522f9b":"class LabelMap:\n    def __init__(self, categories):\n        self.map_dict = {}\n        self.reverse_map_dict={}\n        for i, cat in enumerate(categories):\n            self.map_dict[cat] = i + 1\n            self.reverse_map_dict[i] = cat\n    def fit(self, df, column):\n        df[column] = df[column].map(self.map_dict)\n        return df\n    def inverse(self, df, column):\n        df[column] = df[column].map(self.map_dict)\n        return df","0b215113":"label_map = LabelMap(categories)","86498b71":"train_csv = label_map.fit(train_csv, \"class\")\ntrain_csv.head()","b97d42ed":"test_csv = label_map.fit(test_csv, \"class\")\ntest_csv.head()","a22a60f4":"class AnimalDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_path, categories, transforms=None,**kwargs):\n        super().__init__(**kwargs)\n        self.df = df\n        self.image_path = image_path\n        self.categories = categories\n        self.images = self.df[\"filename\"].unique()\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        image_file = os.path.join(self.image_path, self.images[idx])\n        img = cv2.imread(image_file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32)\n        img = img\/255.0\n        image_data = self.df[self.df['filename'] == self.images[idx]]\n        labels = torch.as_tensor(image_data[\"class\"].values, dtype=torch.int64)\n        xmins = image_data[\"xmin\"].values\n        ymins = image_data[\"ymin\"].values\n        xmaxs = image_data[\"xmax\"].values\n        ymaxs = image_data[\"ymax\"].values\n        boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n        areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n        areas = torch.as_tensor(areas, dtype=torch.float32)\n        image_id = torch.tensor([idx])\n        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = areas\n        target[\"iscrowd\"] = iscrowd\n        if self.transforms is not None:\n            transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n            img = transformed[\"image\"]\n            target[\"boxes\"] = torch.as_tensor(transformed[\"bboxes\"],dtype=torch.float32)\n        return torch.as_tensor(img, dtype=torch.float32), target\n    def get_height_and_width(self, image):\n        image_data = self.df.loc[self.df['filename'] == image]\n        return image_data[\"width\"].values[0], image_data[\"height\"].values[0]","f5a5e7e2":"transform_train = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    ToTensorV2(p=1)\n], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))","6eddfd28":"transform_test = A.Compose([\n    ToTensorV2(p=1)\n], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))","fc966878":"def collate_fn(batch):\n    return tuple(zip(*batch))","f25bd96a":"train_dataset = AnimalDataset(train_csv, train_images, categories, transform_train)\ntest_dataset = AnimalDataset(test_csv, test_images, categories, transform_test)","bc3cbf82":"data_loader_train = torch.utils.data.DataLoader(\n        train_dataset, batch_size=4, shuffle=True, num_workers=4,\n        collate_fn=collate_fn)\n    \ndata_loader_test = torch.utils.data.DataLoader(\n    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n    collate_fn=collate_fn)","0b7d365c":"def plot_images(images, targets):\n    for image, target in zip(images, targets):\n        sample = image.permute(1,2,0).cpu().numpy()\n        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n        boxes = target[\"boxes\"].cpu().numpy().astype(np.int32)\n        for box in boxes:\n            cv2.rectangle(sample,\n                      (box[0], box[1]),\n                      (box[2], box[3]),\n                      (220, 0, 0), 3)\n        ax.set_axis_off()\n        ax.imshow(sample)","b90e398d":"images, targets = next(iter(data_loader_train))","46ff8d74":"plot_images(images, targets)","eeb38c93":"images, targets = next(iter(data_loader_test))","7859ceaa":"plot_images(images, targets)","4f21f172":"detection_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)","12a3ee28":"num_classes = len(categories)+1","962416f3":"in_features = detection_model.roi_heads.box_predictor.cls_score.in_features\ndetection_model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)","a51d4e27":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","254e36e0":"detection_model.to(device)","a1855f3a":"def training(model, train_loader, val_loader, epochs=10):\n    # construct an optimizer\n    params = [p for p in model.parameters() if p.requires_grad]\n    optimizer = torch.optim.SGD(params, lr=0.005,\n                                momentum=0.9, weight_decay=0.0005)\n    # and a learning rate scheduler\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                                   step_size=3,\n                                                   gamma=0.1)\n    for epoch in range(epochs):\n        # train for one epoch, printing every 10 iterations\n        train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n        # update the learning rate\n        lr_scheduler.step()\n        # evaluate on the test dataset\n        evaluate(model, val_loader, device=device)","d0496805":"training(detection_model, data_loader_train, data_loader_test, epochs=10 )","d43ba3f2":"torch.save(detection_model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')","822cd968":"training and validating model in each epoch","63ea14ff":"creating dataloaders from datasets","bd5d2177":"# Training and Validation","10136bdf":"saving model state for further use","f7ae0218":"encoding classes to integers.\n\n- 0 is for background by default","6c0567d0":"# Installing Dependencies","70e47515":"defining augmentations and transforms for training and validation","53dac348":"loading faster rcnn model from torchvision","2989edb4":"Installing pycocotools for evaluation","910e87f3":"appending torchvision reference scripts for detection to path for importing","9033308d":"initiating datsets","b0429af1":"function called after we get data from data loader","58c7a866":"importing required libraries","3a14de82":"changing classification head for fine-tuning based on our dataset including background class","0626c5bd":"creating torch dataset","2ceb4e39":"plotting images from dataloader and verifying","83d76fc7":"# Getting Data ready","e8595a94":"load model to gpu or cpu based on device"}}