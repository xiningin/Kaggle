{"cell_type":{"5e99c3ba":"code","30a29c80":"code","3eed3085":"code","fbaed2df":"code","a144e1d8":"code","1481bf37":"code","0a5c3262":"code","ec775785":"code","d39f6314":"code","93d1aaea":"code","d4f7ba47":"code","d1dfbcee":"code","5f25e0f9":"code","f9aaded7":"code","dd11902a":"code","eb4f4ac5":"code","59a03153":"code","fce93049":"code","cbcb42db":"code","d39c80f5":"code","2f145318":"code","c96694ab":"code","a15d43cd":"code","63eda73e":"code","95d9d025":"code","0adf4ed0":"code","896c6df2":"code","4b4367e5":"code","cb8efad5":"markdown","ecded0e7":"markdown","46e59e74":"markdown","1b08963a":"markdown","d22d4787":"markdown","c266915c":"markdown","94cdeffd":"markdown","bebaa949":"markdown","9eca5d36":"markdown","17d71a52":"markdown","deed88e0":"markdown","44cb4ece":"markdown","3724886a":"markdown","f0b79870":"markdown","5474340a":"markdown","236511c7":"markdown","b819eac1":"markdown"},"source":{"5e99c3ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","30a29c80":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit\nnp.random.seed(42)","3eed3085":"data = pd.read_csv(\"\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/train.csv\")\n","fbaed2df":"data.head()","a144e1d8":"data.describe()","1481bf37":"data.shape","0a5c3262":"data.info()","ec775785":"# get the number of different classes\ndata['y'].value_counts()\ndata['y'].value_counts().plot(kind='bar')","d39f6314":"# how features are correlated with each other\nX = data.copy()\nX.drop(\"ID\",axis=1,inplace=True)\ncorrelation_matrix = X.corr()\n#Visulaize heatmap for correlation matrix\nplt.figure(figsize=(15,8))\nsns.heatmap(correlation_matrix,annot=True)\nplt.show()\n","93d1aaea":"X = data.copy()\nX.drop(\"ID\",axis=1,inplace=True)\ncolumns_to_drop  = ['Area','EquivDiameter','ShapeFactor3','Perimeter','AspectRation'\n                   ,'MinorAxisLength','Compactness','MinorAxisLength']\nX.drop(columns_to_drop,axis=1,inplace=True)\n\n\nX.columns","d4f7ba47":"X.loc[:,'y'].values","d1dfbcee":"# Visualize data distribution\nX.hist(figsize=(10,10))\nplt.show()\n","5f25e0f9":"# Visulaize feature distributions per class\n\nfeatures_to_visulaize = X.iloc[:,:-1].columns.values.reshape(3,3)\nfig, axes = plt.subplots(3, 3, figsize=(15, 15))\nfig.suptitle('KDE of all features')\n\nfor i in range(3):\n    for j in range(3):\n        sns.kdeplot(ax=axes[i, j], data=X, x=features_to_visulaize[i,j], hue='y')\nplt.show()\n\n","f9aaded7":"# Visualize each feature with y \n## first ecode y\nfeatures_to_visulaize = X.iloc[:,:-1].columns.values.reshape(3,3)\nfig, axes = plt.subplots(3, 3, figsize=(25, 15))\nfig.suptitle('striplot of all features')\n\nfor i in range(3):\n    for j in range(3):\n        sns.stripplot(ax=axes[i, j],data=X,x='y',y=features_to_visulaize[i,j])\nplt.show()\n\n","dd11902a":"split = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\ni=0\nfor train_index, test_index in split.split(X, X[\"y\"]):\n   \n    strat_train_set = X.loc[train_index]\n    strat_test_set = X.loc[test_index]\n    if i == 0:\n        break\n    i+=1\n\n\nX_train  = strat_train_set.iloc[:,:-1]\ny_train = strat_train_set.iloc[:,-1]\n\nX_test  = strat_test_set.iloc[:,:-1]\ny_test = strat_test_set.iloc[:,-1]\n\nX_train.head()","eb4f4ac5":"m=3\nn=3\nfeatures_to_visulaize = X_train.columns.values.reshape(m,n)\nfig, axes = plt.subplots(m, n, figsize=(20, 15))\nfig.suptitle('KDE of all features')\n\nfor i in range(m):\n    for j in range(n):\n        sns.kdeplot(ax=axes[i, j], data=X_test ,x=features_to_visulaize[i,j], hue=y_test)\n        sns.color_palette(\"hls\", 8)\n        \nplt.show()\n\n","59a03153":"from sklearn.preprocessing import StandardScaler\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float64))","fce93049":"from sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsOneClassifier\n\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf=OneVsOneClassifier(SVC(kernel='rbf',gamma = 0.1,C=2.5))\nclf.fit(X_train_scaled,y_train)\ny_train_score = cross_val_score(clf, X_train_scaled, y_train, cv=3,scoring=\"f1_micro\")\ny_train_pred = clf.predict(X_train_scaled)\ny_train_score","cbcb42db":"#X_test_poly =poly_transform.transform(X_test)\nX_test_scaled = scaler.transform(X_test.astype(np.float64))\ny_test_pred= clf.predict(X_test_scaled)","d39c80f5":"from sklearn.metrics import f1_score\n\nf1_score(y_test, y_test_pred,average='micro')","2f145318":"y_test.value_counts()","c96694ab":"from sklearn.metrics import confusion_matrix\nconf_mx = confusion_matrix(y_test,y_test_pred)","a15d43cd":"np.unique(y_test,return_counts=True)","63eda73e":"conf_mx","95d9d025":"plt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()","0adf4ed0":"#dataset_path = '\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/'\n#df_test = pd.read_csv(os.path.join(dataset_path, 'test.csv',index=\"ID\"))\ndf_test = pd.read_csv(\"\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/test.csv\")\ndf_test.head()","896c6df2":"columns_to_drop  = ['Area','EquivDiameter','ShapeFactor3','Perimeter','AspectRation'\n                  ,'MinorAxisLength','Compactness','ID']\nmytest = df_test.drop(columns_to_drop,axis=1)\nX_kag_scaled = scaler.transform(mytest.astype(np.float64))\ndf_predictions = clf.predict(X_kag_scaled)\ndf_test[\"y\"] = df_predictions\n","4b4367e5":"df_test[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)\n","cb8efad5":"### Insights form the heatmap\nSome features have correlation = 1 with each other so we can safely drop one of them\n* ConvexArea and Area\n* ShapeFactor 3 and Compactness\n\nSome feature have correlation almost equal to -1 (-0.99,-0.98) , we can also choose to drop one of them or take pca\n\n* AscpectRatio and Compactness\n* AscpectRatio and ShapeFactor 3\n* MajorAxisLength and Perimeter\n* Perimeter and Area\n* EquivDiameter and Area\n* EquivDiameter and Perimeter\n* Eccentricity and ShapeFactor 3","ecded0e7":"It's simple. You are given a set of features extracted from the shape of the beans in images and it's required to predict the type of each bean. There are 7 bean types in this dataset.","46e59e74":"### From the data description above, we can see that:\n* There is non missing data\n* All data are numeric except for the target values which are string\n* The data range of features are either very big or very small\n    ","1b08963a":"We can notice that some feature are able to strongly identify some classes:\n* the shapeFactor 1 of Bombay type is always less than 0.004 anything else is higher\n* the Eccentricity is able to distinguish beans of type SEKER and of type HOROZ\n\nAlso some types have flat curve for specific features which means that we could not use this feature to identify them like the feature Extent with type HOROZ","d22d4787":"The evaluation metric for this competition is accuracy which is calculated as follows.\n\n            accuracy = Ncorrect predictions\/M\n \nWhere M is the number of the examples in the test set.","c266915c":"# Problem Description","94cdeffd":"**Data fields**\n- ID - an ID for this instance\n- Area - (A), The area of a bean zone and the number of pixels within its boundaries.\n- Perimeter - (P), Bean circumference is defined as the length of its border.\n- MajorAxisLength - (L), The distance between the ends of the longest line that can be drawn from a bean.\n- MinorAxisLength - (l), The longest line that can be drawn from the bean while standing perpendicular to the main axis.\n- AspectRatio - (K), Defines the relationship between L and l.\n- Eccentricity - (Ec), Eccentricity of the ellipse having the same moments as the region.\n- ConvexArea - (C), Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\n- EquivDiameter - (Ed), The diameter of a circle having the same area as a bean seed area.\n- Extent - (Ex), The ratio of the pixels in the bounding box to the bean area.\n- Solidity - (S), Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\n- Roundness - (R), Calculated with the following formula: (4piA)\/(P^2)\n- Compactness - (CO), Measures the roundness of an object: Ed\/L\n- ShapeFactor1 - (SF1)\n- ShapeFactor2 - (SF2)\n- ShapeFactor3 - (SF3)\n- ShapeFactor4 - (SF4)\n- y - the class of the bean. It can be any of BARBUNYA, SIRA, HOROZ, DERMASON, CALI, BOMBAY, and SEKER.","bebaa949":"## Read and discover data","9eca5d36":"# Setup","17d71a52":"## Submit Predictions","deed88e0":"## Test data split","44cb4ece":"## Test the model ","3724886a":"#### Insights from kde","f0b79870":"## Evaluation Criteria","5474340a":"# Exploratory Data Analysis","236511c7":"#### We can see that the Beans type \"BOMBAY\" is under represented","b819eac1":"## Train Model using SVM and cross validation"}}