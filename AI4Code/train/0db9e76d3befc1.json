{"cell_type":{"adc92948":"code","aae04d8e":"code","33a4a29f":"code","d6ac1a96":"code","cc0a1f08":"code","dc0677bf":"code","2c15b530":"code","7bf796e0":"code","0621094b":"code","82427e6b":"code","82a4403a":"code","816b0220":"code","0c2ffb99":"markdown","0aff0b63":"markdown","4676f06f":"markdown"},"source":{"adc92948":"#-*- coding: utf-8 -*-\n\nimport json\nimport os\nimport cv2\nimport string\nimport random\nimport numpy as np\nimport pandas as pd\n\nfrom glob import glob\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","aae04d8e":"image_labels = pd.read_csv('..\/input\/nfl-impact-detection\/image_labels.csv')","33a4a29f":"image_labels.head()","d6ac1a96":"def gen_classes(CLASSES):\n    classes = list()      \n    \n    for i, CLASS in enumerate(CLASSES):\n        single_class = {} \n        single_class['id'] = i + 1\n        single_class['name'] = CLASS\n        classes.append(single_class)\n    return classes","cc0a1f08":"CLASSES = list(image_labels['label'].unique())\nclasses = gen_classes(CLASSES)\nclasses","dc0677bf":"classes = classes[0]","2c15b530":"def gen_objs(df, validation_ratio = 0.2, debug = False):\n    \n    if debug:\n        \n        df = df[:int(len(df)*0.05)]\n        \n    \n    img_lists = list(df['image'].unique()) ## gen unique image lists\n    imgs = list()\n    train_objs = list()\n    valid_objs = list() \n    \n    ## gen images information\n    for i in tqdm(range(len(img_lists))):\n        '''\n        \n        I just notice that all images were preprocessed image size 720x1280\n        If you want to check real image size, use this code below\n        \n        img = cv2.imread(os.path.join(data_path, img_lists[i]))\n        \n        single_img_obj = {}\n        single_img_obj['file_name'] = img_lists[i]\n        single_img_obj['height'] = img.shape[0]\n        single_img_obj['width'] = img.shape[1]\n        single_img_obj['id'] = i + 1\n        '''\n        \n        single_img_obj = {}\n        single_img_obj['file_name'] = img_lists[i]\n        single_img_obj['height'] = 720 \n        single_img_obj['width'] = 1280\n        single_img_obj['id'] = i + 1        \n        \n        imgs.append(single_img_obj)\n        \n        \n    ## gen train & val objs information        \n    train_df, valid_df = train_test_split(df, test_size = validation_ratio, random_state=42)\n    train_df = train_df.reset_index()\n    valid_df = valid_df.reset_index()\n    \n    ## gen train objs information    \n    for j in tqdm(range(len(train_df))):\n        single_obj = {}\n        single_obj['id'] = j + 1\n        single_obj['image_id'] = img_lists.index(df['image'][j]) + 1\n        single_obj['category_id'] = 1 # If you wanna set multi-class, set CLASSES.index(df['label'][j]) + 1\n        single_obj['area'] = float(df['width'][j]*df['height'][j])\n        single_obj['bbox'] = [int(df['left'][j]), int(df['top'][j]), int(df['width'][j]), int(df['height'][j])] ## [min_x, min_y, width, height]\n        single_obj['iscrowd'] = 0        \n        \n        train_objs.append(single_obj)\n        \n    ## gen valid objs information\n    for k in tqdm(range(len(valid_df))):\n        single_obj = {}\n        single_obj['id'] = k + 1\n        single_obj['image_id'] = img_lists.index(df['image'][k]) + 1\n        single_obj['category_id'] = 1 # If you wanna set multi-class, set CLASSES.index(df['label'][j]) + 1\n        single_obj['area'] = float(df['width'][k]*df['height'][k])\n        single_obj['bbox'] = [int(df['left'][k]), int(df['top'][k]), int(df['width'][k]), int(df['height'][k])]\n        single_obj['iscrowd'] = 0        \n        \n        valid_objs.append(single_obj)        \n    \n    print(f'images: {len(imgs)}, train objs: {len(train_objs)}, valid objs: {len(valid_objs)}')\n    \n    return imgs, train_objs, valid_objs","7bf796e0":"imgs, train_objs, valid_objs = gen_objs(image_labels)","0621094b":"imgs[:5]","82427e6b":"train_objs[:5]","82a4403a":"def gen_coco(outpath, classes, objs, imgs, train=True):\n    if train:\n        data_dict = {}\n        data_dict['images'] = []\n        data_dict['annotations'] = []\n        data_dict['categories'] = []\n        data_dict['images'].extend(imgs)\n        data_dict['annotations'].extend(objs)\n        data_dict['categories'].extend(classes)\n        \n    else:\n        data_dict = {}\n        data_dict['images'] = []\n        data_dict['categories'] = []\n        \n        data_dict['images'].extend(imgs)\n        data_dict['categories'].extend(classes)   \n\n    with open(outpath, 'w') as f_out:\n        json.dump(data_dict, f_out)\n    print(f'file generate at {outpath}')","816b0220":"gen_coco('train.json', classes, train_objs, imgs, train=True)\ngen_coco('valid.json', classes, valid_objs, imgs, train=True)","0c2ffb99":"# Introduction\n\n**Main Topic**\n\nThis notebook is for **generating coco format json files** using **images** and **image_labels.csv**\n\nBecasue I don't know how to approch this competition well, I'm trying to make Object Detection Model using images and videos first.\n\nSo for the first step, I converted bbox informations to coco json format.\n\nPlease tell me if there is any bug or improvement.\n\nafter this nb you can refer [Detecting Helmet using MMdetection w\/o internet](https:\/\/www.kaggle.com\/jinssaa\/detecting-helmet-using-mmdetection-w-o-internet) to building \n\n`Helmet` detection model\n\n**References**\n\nI just customized this code from my old files, so please refer to me if there is any references code made by below style ","0aff0b63":"I'm not sure but we might customize this classse to kind of {helmet, helmet-impact, shoulder-impact} etc, \n\nor predicting helmet can make some rule-based inference. I will just set `classes` only `Helmet`","4676f06f":"# Set up environment"}}