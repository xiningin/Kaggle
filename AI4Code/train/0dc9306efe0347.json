{"cell_type":{"90dd4a40":"code","3f23b909":"code","020b84ba":"code","93e9f07c":"code","45bbaeed":"code","f6adf0c2":"code","27d247f1":"code","a098cc4d":"code","1f8bd4df":"code","7f27c67d":"code","01980923":"code","fcdf263f":"code","adf0a1ee":"code","f724ed59":"markdown"},"source":{"90dd4a40":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt","3f23b909":"transform = transforms.ToTensor()\n\n# transform = transforms.Compose([\n#     transforms.ToTensor(),\n#     transforms.Normalize((0.5),(0.5))\n# ])\nmnist_data = datasets.MNIST(root='.\/data', train=True, transform=transform, download=True)\n","020b84ba":"data_loader = torch.utils.data.DataLoader(dataset=mnist_data,\n                                          batch_size =64,\n                                          shuffle=True)","93e9f07c":"dataiter = iter(data_loader)\nimages, labels = dataiter.next()\nprint(torch.min(images), torch.max(images))","45bbaeed":"class Autoencoder_linear(nn.Module):\n    def __init__(self):\n        \n        super().__init__()\n        # N = 784\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, 128),\n            nn.ReLU(),\n            nn.Linear(128,64),\n            nn.ReLU(),\n            nn.Linear(64, 12),\n            nn.ReLU(),\n            nn.Linear(12,3) # output size = N * 3\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(3,12),\n            nn.ReLU(),\n            nn.Linear(12,64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128,28*28), # output size = N * 784\n            nn.Sigmoid()\n        )\n        \n        \n    \n    def forward(self, X):\n        encoded = self.encoder(X)\n        decoded = self.decoder(encoded)\n        return decoded","f6adf0c2":"model = Autoencoder_linear()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)","27d247f1":"num_epochs = 10\noutputs = []\n\nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n        img = img.reshape(-1,28*28)\n        recon = model(img)\n        loss = criterion(recon, img)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(epoch+1, \"loss: \", loss.item())\n    outputs.append((epoch, img, recon))","a098cc4d":"for k in range(0, num_epochs, 4):\n    plt.figure(figsize=(9,2))\n    plt.gray()\n    imgs = outputs[k][1].detach().numpy()\n    recon = outputs[k][2].detach().numpy()\n    for i, item in enumerate(imgs):\n        if i>= 9:\n            break\n        plt.subplot(2,9, i+1)\n        item = item.reshape(-1,28,28)\n        plt.imshow(item[0])\n    \n    for i,item in enumerate(recon):\n        if i>=9:\n            break\n        plt.subplot(2,9,9+i+1)\n        item = item.reshape(-1,28,28)\n        plt.imshow(item[0])\n        ","1f8bd4df":"class Autoencoder(nn.Module):\n    def __init__(self):\n        \n        super().__init__()\n        # N 1, 28,28\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=2, padding=1), # N 16, 14, 14\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, stride=2, padding=1), # N, 32, 7,7\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 7) # N, 64, 1, 1\n        )\n        \n        # N, 64, 1,1\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64,32,7), # 32, 7,7\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16,3, stride=2, padding=1, output_padding=1),# N, 16,14,14\n            nn.ReLU(),\n            nn.ConvTranspose2d(16,1,3,stride=2, padding=1, output_padding=1), # N , 1,28,28\n            nn.Sigmoid()\n        )\n        \n        \n    \n    def forward(self, X):\n        encoded = self.encoder(X)\n        decoded = self.decoder(encoded)\n        return decoded\n    \n# maxpool2d -> nn.maxpool2d","7f27c67d":"model = Autoencoder()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)","01980923":"num_epochs = 10\noutputs = []\n\nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n#         img = img.reshape(-1,28*28)\n        recon = model(img)\n        loss = criterion(recon, img)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(epoch+1, \"loss: \", loss.item())\n    outputs.append((epoch, img, recon))","fcdf263f":"for k in range(0, num_epochs, 4):\n    plt.figure(figsize=(9,2))\n    plt.gray()\n    imgs = outputs[k][1].detach().numpy()\n    recon = outputs[k][2].detach().numpy()\n    for i, item in enumerate(imgs):\n        if i>= 9:\n            break\n        plt.subplot(2,9, i+1)\n#         item = item.reshape(-1,28,28)\n        plt.imshow(item[0])\n    \n    for i,item in enumerate(recon):\n        if i>=9:\n            break\n        plt.subplot(2,9,9+i+1)\n#         item = item.reshape(-1,28,28)\n        plt.imshow(item[0])","adf0a1ee":"!nvidia-smi","f724ed59":"from : https:\/\/www.youtube.com\/watch?v=zp8clK9yCro"}}