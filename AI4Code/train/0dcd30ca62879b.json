{"cell_type":{"fc401a8c":"code","db55e902":"code","a0cb2ca7":"code","7262d42c":"code","f641a019":"code","026e9ae7":"code","3294be56":"code","aa344e5a":"code","3c03c4fa":"code","15fb7924":"code","d7c5adeb":"code","105d5cda":"code","f39e64ef":"code","9a977b33":"code","e0447855":"code","0e194a44":"code","a7c046f9":"code","b5f4effe":"code","01dc1991":"code","7bf9474d":"code","54f5ebc3":"code","89c00238":"markdown","96fd639f":"markdown","a1c9c4d6":"markdown","02385185":"markdown","9960e1ba":"markdown","0f6192cd":"markdown"},"source":{"fc401a8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db55e902":"data = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')","a0cb2ca7":"data.head(10)","7262d42c":"# checking for null values\ndata.isnull().sum()","f641a019":"import matplotlib.pyplot as plt\nimport seaborn as sns","026e9ae7":"plt.style.use('seaborn')\nplt.figure(figsize=(9,7))\nsns.barplot(x='RestingECG',y='HeartDisease',data=data,hue='Sex')\nplt.show()","3294be56":"# Age Distribution\nsns.displot(data=data,x='Age')\nplt.show()","aa344e5a":"# Visualizing correlation matrix\ncorr = data.corr()\nplt.figure(figsize=(10,12))\nsns.clustermap(corr,annot=True,fmt='.2f',cmap='Accent')\nplt.show()","3c03c4fa":"X = data.drop(columns=['HeartDisease'])\nY = data['HeartDisease']","15fb7924":"from sklearn.preprocessing import LabelEncoder\nlr = LabelEncoder()\n\nX['Sex'] = lr.fit_transform(X['Sex'])\nX['ChestPainType'] = lr.fit_transform(X['ChestPainType'])\nX['RestingECG'] = lr.fit_transform(X['RestingECG'])\nX['ExerciseAngina'] = lr.fit_transform(X['ExerciseAngina'])\nX['ST_Slope'] = lr.fit_transform(X['ST_Slope'])","d7c5adeb":"X.head(10)","105d5cda":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.33,random_state=20)","f39e64ef":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","9a977b33":"tree_model = DecisionTreeClassifier(criterion='entropy',max_depth=4)\nsvm_model = SVC(kernel='linear',probability=True)\nrf_model = RandomForestClassifier(criterion='entropy',max_depth=4)","e0447855":"#Decision Tree classifier\ntree_model.fit(X_train,Y_train)\ntree_proba = tree_model.predict_proba(X_test)[:,1]\ntree_predict = tree_model.predict(X_test)\n\n#SVM Classifier\nsvm_model.fit(X_train,Y_train)\nsvm_proba = svm_model.predict_proba(X_test)[:,1]\nsvm_predict = svm_model.predict(X_test)\n\n# Random-Forest Classifier\nrf_model.fit(X_train,Y_train)\nrf_proba = rf_model.predict_proba(X_test)[:,1]\nrf_predict = rf_model.predict(X_test)","0e194a44":"from sklearn.metrics import confusion_matrix, accuracy_score,roc_auc_score, precision_score, recall_score","a7c046f9":"# For visualizing confusion matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.grid(False)","b5f4effe":"rf_score = roc_auc_score(Y_test, rf_proba)\nsvm_score = roc_auc_score(Y_test, svm_proba)\ntree_score = roc_auc_score(Y_test,tree_proba)","01dc1991":"print('RandomForest Classifier')\nprint('AUC score : {:.4f}'.format(rf_score))\nprint('Accuracy score : {:.4f}'.format(accuracy_score(Y_test,rf_predict)))\nprint('Precision score : {:.4f}'.format(precision_score(Y_test,rf_predict)))\nprint('Recall score : {:.4f}'.format(recall_score(Y_test,rf_predict)))\nplot_confusion_matrix(confusion_matrix(Y_test, rf_predict),[0,1],cmap=plt.cm.Accent)","7bf9474d":"print('Support Vector Classifier')\nprint('AUC Score : {:.4f}'.format(svm_score))\nprint('Accuracy score : {:.4f}'.format(accuracy_score(Y_test,svm_predict)))\nprint('Precision score : {:.4f}'.format(precision_score(Y_test,svm_predict)))\nprint('Recall score : {:.4f}'.format(recall_score(Y_test,svm_predict)))\nplot_confusion_matrix(confusion_matrix(Y_test, svm_predict),[0,1],cmap=plt.cm.Accent)","54f5ebc3":"print('Decision Tree Classifier')\nprint('AUC score : {:.4f}'.format(tree_score))\nprint('Accuracy score : {:.4f}'.format(accuracy_score(Y_test,tree_predict)))\nprint('Precision score : {:.4f}'.format(precision_score(Y_test,tree_predict)))\nprint('Recall score : {:.4f}'.format(recall_score(Y_test,tree_predict)))\nplot_confusion_matrix(confusion_matrix(Y_test, tree_predict),[0,1],cmap=plt.cm.Accent)","89c00238":"## Model Evaluation","96fd639f":"## Model Training","a1c9c4d6":"## Conclusion\n--> I tried hypertuning the parameters for better result but it didn't impacted much on result for this dataset.\n\n--> Random Forest Classifier performed best for the this dataset.","02385185":"## EDA","9960e1ba":"## Data Loading","0f6192cd":"## Data PreProcessing"}}