{"cell_type":{"559a47f4":"code","72ae7924":"code","949f7ed9":"code","debd69ac":"code","5ff19810":"code","d1986d42":"code","585449d0":"code","d600e1c7":"code","4c3cc7d6":"code","43aa2682":"code","89659320":"code","51d6e90b":"code","48ad2898":"code","88540e3a":"code","793a51af":"code","a1b96501":"code","2fa29e7e":"code","636b6305":"code","394e0019":"code","06d9663e":"code","04a139f3":"code","da1b5149":"code","8335dd07":"code","07b0a65e":"code","e3e907e1":"code","4847966b":"code","638da97a":"code","44318578":"code","d29ffa07":"code","0d5baba6":"code","7f465ca2":"code","d1b34c4c":"code","949210a2":"code","4dd9e18b":"code","c8c6fc01":"code","4d2e764d":"code","4564b20e":"code","be3cf633":"code","1244e304":"code","d426d0eb":"code","8057c40f":"code","b563d40a":"code","cc757949":"code","ee6160e7":"code","5b4e5979":"code","6e28127d":"code","2375a373":"markdown","75deee9c":"markdown","42c00833":"markdown","3a7573b0":"markdown","f330a7f7":"markdown","a1e36317":"markdown","1c171cb8":"markdown","831da1a3":"markdown","af069df0":"markdown","dc09ba91":"markdown","96db2318":"markdown","8697e453":"markdown","043c12be":"markdown","101697c5":"markdown","a81eda71":"markdown","eddb38db":"markdown","4c9bb24d":"markdown"},"source":{"559a47f4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nimport re\nimport string","72ae7924":"df_fake = pd.read_csv(\"..\/input\/fake-news-detection\/Fake.csv\")\ndf_true = pd.read_csv(\"..\/input\/fake-news-detection\/True.csv\")","949f7ed9":"df_fake.head()","debd69ac":"df_true.head(5)","5ff19810":"df_fake[\"class\"] = 0\ndf_true[\"class\"] = 1","d1986d42":"df_fake.shape, df_true.shape","585449d0":"# Removing last 10 rows for manual testing\ndf_fake_manual_testing = df_fake.tail(10)\nfor i in range(23480,23470,-1):\n    df_fake.drop([i], axis = 0, inplace = True)\n    \n    \ndf_true_manual_testing = df_true.tail(10)\nfor i in range(21416,21406,-1):\n    df_true.drop([i], axis = 0, inplace = True)","d600e1c7":"df_fake.shape, df_true.shape","4c3cc7d6":"df_fake_manual_testing[\"class\"] = 0\ndf_true_manual_testing[\"class\"] = 1","43aa2682":"df_fake_manual_testing.head(10)","89659320":"df_true_manual_testing.head(10)","51d6e90b":"df_manual_testing = pd.concat([df_fake_manual_testing,df_true_manual_testing], axis = 0)\ndf_manual_testing.to_csv(\"manual_testing.csv\")","48ad2898":"df_merge = pd.concat([df_fake, df_true], axis =0 )\ndf_merge.head(10)","88540e3a":"df_merge.columns","793a51af":"df = df_merge.drop([\"title\", \"subject\",\"date\"], axis = 1)","a1b96501":"df.isnull().sum()","2fa29e7e":"df = df.sample(frac = 1)","636b6305":"df.head()","394e0019":"df.reset_index(inplace = True)\ndf.drop([\"index\"], axis = 1, inplace = True)","06d9663e":"df.columns","04a139f3":"df.head()","da1b5149":"def wordopt(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) \n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)    \n    return text","8335dd07":"df[\"text\"] = df[\"text\"].apply(wordopt)","07b0a65e":"x = df[\"text\"]\ny = df[\"class\"]","e3e907e1":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)","4847966b":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorization = TfidfVectorizer()\nxv_train = vectorization.fit_transform(x_train)\nxv_test = vectorization.transform(x_test)","638da97a":"from sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\nLR.fit(xv_train,y_train)","44318578":"pred_lr=LR.predict(xv_test)","d29ffa07":"LR.score(xv_test, y_test)","0d5baba6":"print(classification_report(y_test, pred_lr))","7f465ca2":"from sklearn.tree import DecisionTreeClassifier\n\nDT = DecisionTreeClassifier()\nDT.fit(xv_train, y_train)","d1b34c4c":"pred_dt = DT.predict(xv_test)","949210a2":"DT.score(xv_test, y_test)","4dd9e18b":"print(classification_report(y_test, pred_dt))","c8c6fc01":"from sklearn.ensemble import GradientBoostingClassifier\n\nGBC = GradientBoostingClassifier(random_state=0)\nGBC.fit(xv_train, y_train)","4d2e764d":"pred_gbc = GBC.predict(xv_test)","4564b20e":"GBC.score(xv_test, y_test)","be3cf633":"print(classification_report(y_test, pred_gbc))","1244e304":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(random_state=0)\nRFC.fit(xv_train, y_train)","d426d0eb":"pred_rfc = RFC.predict(xv_test)","8057c40f":"RFC.score(xv_test, y_test)","b563d40a":"print(classification_report(y_test, pred_rfc))","cc757949":"def output_lable(n):\n    if n == 0:\n        return \"Fake News\"\n    elif n == 1:\n        return \"Not A Fake News\"\n    \ndef manual_testing(news):\n    testing_news = {\"text\":[news]}\n    new_def_test = pd.DataFrame(testing_news)\n    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt) \n    new_x_test = new_def_test[\"text\"]\n    new_xv_test = vectorization.transform(new_x_test)\n    pred_LR = LR.predict(new_xv_test)\n    pred_DT = DT.predict(new_xv_test)\n    pred_GBC = GBC.predict(new_xv_test)\n    pred_RFC = RFC.predict(new_xv_test)\n\n    return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(output_lable(pred_LR[0]),                                                                                                       output_lable(pred_DT[0]), \n                                                                                                              output_lable(pred_GBC[0]), \n                                                                                                              output_lable(pred_RFC[0])))","ee6160e7":"news = str(input())\nmanual_testing(news)","5b4e5979":"news = str(input())\nmanual_testing(news)","6e28127d":"news = str(input())\nmanual_testing(news)","2375a373":"## Random Shuffling the dataframe","75deee9c":"## Importing Libraries","42c00833":"# Fake News Detection","3a7573b0":"## Inserting a column \"class\" as target feature","f330a7f7":"## Merging True and Fake Dataframes","a1e36317":"## Importing Dataset","1c171cb8":"## Splitting Training and Testing","831da1a3":"## Removing columns which are not required","af069df0":"## Decision Tree Classification","dc09ba91":"## Defining dependent and independent variables","96db2318":"## Creating a function to process the texts","8697e453":"![image.png](attachment:image.png)","043c12be":"## Logistic Regression","101697c5":"## Random Forest Classifier","a81eda71":"## Model Testing","eddb38db":"## Convert text to vectors","4c9bb24d":"## Gradient Boosting Classifier"}}