{"cell_type":{"be87ddd9":"code","cb8fa1c0":"code","e8ecfdd1":"code","fc1d2354":"code","51aec73a":"code","774c02f1":"code","6d43a8a2":"code","026bae85":"code","2fe5065a":"code","c37ad3a9":"code","a21782cb":"code","c2df2b48":"code","d8eb248a":"code","ac2d7174":"code","0e3cc953":"markdown","7ed87080":"markdown"},"source":{"be87ddd9":"#IMPORTING LIBRARIES\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport pandas as pd","cb8fa1c0":"#defining training and testing path for vgg16\ntrain_path = '..\/input\/intel-image-classification\/seg_train\/seg_train'\nvalid_path = '..\/input\/intel-image-classification\/seg_test\/seg_test'","e8ecfdd1":"#to get number of folders in training set\nfrom glob import glob\nfolders = glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/*')","fc1d2354":"from keras.applications.vgg16 import VGG16\nIMAGE_SIZE = [150,150]\n\n#defining vgg16 model\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n#we have to take pre trained weights, we don't want to train the weights again\nfor layer in vgg.layers:\n    layer.trainable = False\n\n#flattening the output of vgg16 for fully connected layer.\nx = tf.keras.layers.Flatten()(vgg.output)\n\n#adding output layer\n#x = Dense(1000, activation='relu')(x) here pretrained model had 1000 neurons but we'll be replacing them by 6(no. of classes)\nprediction = tf.keras.layers.Dense(len(folders), activation='softmax')(x)","51aec73a":"#creating the model and getting the summary\nmodel = tf.keras.models.Model(inputs=vgg.input, outputs=prediction)\nmodel.summary()","774c02f1":"#compiling the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","6d43a8a2":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 150x150, batch of images is kept as 128 and class is defined as 'categorical'.\ntraining_set = train_data.flow_from_directory('..\/input\/intel-image-classification\/seg_train\/seg_train', batch_size = 128, target_size = (150,150), class_mode = 'categorical')","026bae85":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/intel-image-classification\/seg_test\/seg_test', batch_size = 128, target_size = (150,150), class_mode = 'categorical')","2fe5065a":"#fitting the model with 5 epochs\ncnn = model.fit(training_set,validation_data=testing_set,epochs=5,steps_per_epoch=len(training_set),validation_steps=len(testing_set))","c37ad3a9":"#getting indices of training set\nimport numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","a21782cb":"names = np.array(['Buildings', 'Forest' ,'Glacier' ,'Mountain' ,'Sea' ,'Street'])","c2df2b48":"#to create a list with 5 ramdom images from seg_pred directory for prediction\nimport os\npred = os.listdir(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\")\nimport random\nimages = []\nfor i in range(5):\n    images.append(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\"+random.choice(pred))","d8eb248a":"#predicting classes of 5 images from the list\nfor img in images:\n    #importing images\n    test_img = image.load_img(img,target_size = (150,150))\n\n    #converting image to array\n    test_img = image.img_to_array(test_img)\n\n    #we selected a batch size of 150 and it's a single photo, therefore we would be expanding it's dimensions.\n    test_img = np.expand_dims(test_img,axis = 0)\n    result = model.predict(test_img)\n    plt.title('Class:{},Probability:{}'.format(names[result.argmax()],result.max()))\n    \n    #to print the image\n    plt.imshow(image.img_to_array(image.load_img(img, target_size=(150,150)))\/255.)\n    plt.show()","ac2d7174":"plt.plot(cnn.history['accuracy'])\nplt.plot(cnn.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(cnn.history['loss'])\nplt.plot(cnn.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","0e3cc953":"**PREDICTING THE IMAGES IN THE DATASET USING PRE-TRAINED MODEL VGG16**\n\n**THERE ARE 6 CLASSES IN THE DATASET - BUILDING, FOREST, GLACIER, MOUNTAIN, SEA, STREET**","7ed87080":"**I GOT AN ACCURACY OF AROUND 86% BUT HYPERPARAMTER TUNYING MIGHT INCREASE THE ACCURACY.**"}}