{"cell_type":{"3591b835":"code","f82f233c":"code","127cbe1c":"code","ff2164b0":"code","8129a32d":"code","03502687":"code","a77c1da6":"code","05940a2f":"code","7f7e4214":"code","8808d856":"code","cd70b5b8":"code","485e969c":"code","271ce25b":"code","d9bd1f6b":"code","6420b99e":"code","7c01158c":"code","8561cf18":"code","aede1d39":"code","54794c6d":"code","539fad60":"code","76dde1b2":"code","cb44ec03":"code","7e0f8283":"code","b10ee9fd":"code","8eb3503f":"code","95a00a7a":"code","761a7cc6":"code","3d2ed048":"code","8bfbef87":"code","a5beeaf9":"code","b3350410":"code","57416a7d":"code","e9eebcfa":"code","c68496a4":"markdown","b0d4f322":"markdown","72686778":"markdown","e37b0ac6":"markdown","2271a897":"markdown","15ebf8b8":"markdown","c53f4bdf":"markdown","e43c8859":"markdown","bc387919":"markdown","208d377e":"markdown","4114ac95":"markdown","096b9854":"markdown","5e083a77":"markdown","975efb68":"markdown","9d5be1bc":"markdown","f66ab201":"markdown","5cdc3a67":"markdown","f265ca11":"markdown","b87b4fe8":"markdown","8fe2d808":"markdown","389f7b83":"markdown","0e4e37e1":"markdown"},"source":{"3591b835":"import warnings \nwarnings.filterwarnings('ignore')\n\n# basic libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport re\nimport string\nfrom collections import Counter\nimport time\nimport missingno as msno\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\n!pip install pywaffle\nfrom pywaffle import Waffle\n\n%matplotlib inline\ninit_notebook_mode(connected= True)\n\n\n\n# Essentials\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport random\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\npd.set_option('display.max_columns', None)\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\n\n\n\n\n\n","f82f233c":"#reading the data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain.head()","127cbe1c":"test.head()","ff2164b0":"df=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n","8129a32d":"df.info()","03502687":"# stats of categorical data\nround (df.describe(exclude = ['float', 'int64']),2)","a77c1da6":"# stats of numerical data\nround (df.describe(exclude = 'object'), 2)","05940a2f":"color = ['grey','grey','grey','grey','grey','grey','grey','grey','grey','grey','#fe346e','#fe346e']\nfig, ax = plt.subplots(figsize = (12,4), dpi = 70)\nfig.patch.set_facecolor('#f6f5f5')\nax.set_facecolor('#f6f5f5')\n\n\nmsno.bar(df, sort = 'descending', \n         color = color, \n         ax = ax, fontsize =8,\n         labels = 'off',filter = 'top')\n\nax.text(-1,1.35,'Visualization of Nullity of The Dataset',{'font': 'Serif', 'Size': 24,  'color':'black'},alpha = 0.9)\nax.text(-1,1.2,'Most of the data is Missing from Cabin Column and some in Age Column and \\n little bit in Embarked Column ',{'font': 'Serif', 'Size': 12,  'color':'black'}, alpha = 0.7)\n\nax.set_xticklabels(ax.get_xticklabels(),rotation = 90, \n                   ha = 'center', **{'font': 'Serif', 'Size': 14,'weight':'normal','color':'#512b58'}, alpha = 1)\nax.set_yticklabels('')\nax.spines['bottom'].set_visible(True)\n\nfig.show()","7f7e4214":"df[\"Age\"]=df[\"Age\"].fillna(df[\"Age\"].median())\ndf[\"Embarked\"]=df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\ndf.drop(\"Cabin\",axis=1,inplace=True)\ndf.drop('Name',axis=1,inplace=True)\ndf.drop(\"PassengerId\",axis=1,inplace=True)","8808d856":"df.describe(include=\"all\")","cd70b5b8":"x = df['Sex'].value_counts()\nfig, ax = plt.subplots(figsize = (6,6), dpi = 60)\nax.barh([1], x.values[1], height = 0.7, color = 'black', alpha = 0.7)\nplt.text(-300,1, 'Female', {'font': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':'black'}, alpha = 0.7)\nplt.text(350,1, '35.2%',{'font':'Serif', 'weight':'bold','size':'16','color':'black'}, alpha = 0.7)\n\nax.barh([0], x.values[0], height = 0.7, color = '#b20710', alpha = 0.8)\nplt.text(-300,-0.08, 'Male',{'font': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':'#b20710'}, alpha = 0.8)\nplt.text(600,-0.08, '64.8%',{'font':'Serif','weight':'bold' ,'size':'16','color':'#b20710'}, alpha = 0.8)\n\n\nfig.patch.set_facecolor('#f6f5f5')\nax.set_facecolor('#f6f5f5')\n\nplt.text(-300,1.77, '%Age of Male and Female Passengers' ,{'font': 'Serif', 'Size': '25','weight':'bold', 'color':'black'}, alpha = 0.9)\nplt.text(500,1.65, 'Male ', {'font': 'Serif','weight':'bold','Size': '16', 'color':'#b20710'}, alpha = 0.8)\nplt.text(470,1.65, '|', {'color':'black' , 'size':'16', 'weight': 'bold'}, alpha = 0.9)\nplt.text(300,1.65, 'Female', {'font': 'Serif','weight':'bold', 'Size': '16','color':'black'}, alpha = 0.7)\nplt.text(-300,1.5, 'Most of the passengers were Male!', \n       {'font':'Serif', 'size':'12.5','color': 'black'})\n\nax.axes.get_xaxis().set_visible(False)\nax.axes.get_yaxis().set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(True)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)","485e969c":"#numerical_columns=df.select_dtypes(exclude=\"object\").columns\nnumerical_columns=[ 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","271ce25b":"fig = plt.figure(figsize =(10,6), dpi = 80)\nfig.patch.set_facecolor('#f6f5f5')\n\ngs = fig.add_gridspec(2,3)\ngs.update(wspace = 0.2, hspace = 0.2)\n\nback_ground = '#f6f5f5'\nax1 = fig.add_subplot(gs[0,0])\nax2 = fig.add_subplot(gs[0,1])\nax3 = fig.add_subplot(gs[0,2])\nax4 = fig.add_subplot(gs[1,0])\nax5 = fig.add_subplot(gs[1,1])\nax6 = fig.add_subplot(gs[1,2])\n\naxes=[ax1,ax2,ax3,ax4,ax5,ax6]\nfor ax in axes:\n    ax.set_facecolor('#f5f6f6')\n    ax.tick_params(axis='x',\n                   labelsize = 12, which = 'major',\n                   direction = 'out',pad = 2,\n                   length = 1.5)\n    ax.tick_params(axis='y', colors= 'black')\n    ax.axes.get_yaxis().set_visible(False)\n    for loc in ['left','right','top','bottom']:\n        ax.spines[loc].set_visible(False)\n    ax.set_facecolor('#f6f5f5')\ncolors=[\"green\",\"black\",\"red\",\"pink\",\"orange\"]\nsns.distplot(df[numerical_columns[0]],ax=ax1,color=colors[0])\nsns.distplot(df[numerical_columns[1]],ax=ax2,color=colors[1])\nsns.distplot(df[numerical_columns[2]],ax=ax3,color=colors[2])\nsns.distplot(df[numerical_columns[3]],ax=ax4,color=colors[3])\nax5.get_xaxis().set_visible(False)\n#sns.distplot(df[numerical_columns[4]],ax=ax5)\nsns.distplot(df[numerical_columns[4]],ax=ax6,color=colors[4])\n\nfig.text(0.3,1,\"Distribution of Numerical Columns:\", {'font': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':'black'}, alpha = 0.7)\nfig.text(0.13,0.9,\"As we can see the data is not normally distributed \\n Only Age and Fare column has Continious values \\n Rest of the columns have Discrete values.\", {'font': 'Serif','weight':'bold','Size': '12','style':'normal', 'color':'black'}, alpha = 0.7)","d9bd1f6b":"df.head(2)","6420b99e":"categorical=df.select_dtypes(include=\"object\").columns\ncategorical","7c01158c":"s=df[\"Embarked\"].value_counts().reset_index()\npx.pie(s,names=\"index\",values=\"Embarked\",title=\"%AGE OF Passengers With Embarked:\")\n","8561cf18":"y=df[\"Survived\"].value_counts()\nfig,ax=plt.subplots(figsize=(10,6))\nax.barh([1],y.values[0], height = 0.7, color = '#b20710', alpha = 0.7)\nax.barh([2],y.values[1],height = 0.7,color='black',alpha=0.7)\n\nplt.text(-150,1, 'Survived', {'font': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':'black'}, alpha = 0.7)\nplt.text(-150,2, 'Not Survived', {'font': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':'black'}, alpha = 0.7)\n\n\nplt.text(60,2,' Not-Survived Passengers',{'font':'Serif','weight':'bold','size':'16','style':'normal', 'color':'white'},alpha=0.7)\nplt.text(80,1,'Survived Passengers',{'font':'Serif','weight':'bold','size':'16','style':'normal', 'color':'black'},alpha=0.7)\n\n\nplt.text(500,2.5, 'Survived ', {'font': 'Serif','weight':'bold','Size': '16', 'color':'#b20710'}, alpha = 0.8)\nplt.text(470,2.5, '|', {'color':'black' , 'size':'16', 'weight': 'bold'}, alpha = 0.9)\nplt.text(330,2.5, 'Not-Survived', {'font': 'Serif','weight':'bold', 'Size': '16','color':'black'}, alpha = 0.7)\n\n\nplt.text(600,1, '61.8%',{'font':'Serif','weight':'bold' ,'size':'16','color':'#b20710'}, alpha = 0.8)\nplt.text(400,2, '38.38%',{'font':'Serif','weight':'bold' ,'size':'16','color':'#b20710'}, alpha = 0.8)\n\nplt.text(-200,2.7,\"%age of Survival of passengers!\",{'font':'Serif','weight':'bold' ,'size':'16','color':'#b20710'}, alpha = 0.8)\nplt.text(-200,2.4,\"As we can see around 62% of the Passengers Survived \\n and 38% of the Passengers Died\",{'font':'Serif','weight':'bold' ,'size':'12','color':'black'}, alpha = 0.8)\n\nfig.patch.set_facecolor('#f6f5f5')\nax.set_facecolor('#f6f5f5')\n\nax.axes.get_xaxis().set_visible(False)\nax.axes.get_yaxis().set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(True)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)","aede1d39":"df.head(2)","54794c6d":"fig=plt.figure(figsize=(10,6))\nax=sns.countplot(df[\"Sex\"],hue=df[\"Survived\"])\nax.text(0,600,\"%Frequency of survival based on Gender\",{'font':'Serif','weight':'bold' ,'size':'16','color':'#b20710'}, alpha = 0.8)\nax.text(-0.6,550,\"There is high chances of Females to survive.\\n As we can see Ratio of survival in Female is High \",{'font':'Serif','weight':'bold' ,'size':'12','color':'#b20710'}, alpha = 0.8)\n\nfig.patch.set_facecolor('#f6f5f5')\nax.set_facecolor('#f6f5f5')\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(True)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\n\n","539fad60":"train[\"Age\"]=train[\"Age\"].fillna(df[\"Age\"].median())\ntrain[\"Embarked\"]=train[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\ntrain.drop(\"Cabin\",axis=1,inplace=True)\ntrain.drop('Name',axis=1,inplace=True)\ntrain.drop(\"PassengerId\",axis=1,inplace=True)\ntrain.drop(\"Ticket\",axis=1,inplace=True)\n\n\ntest[\"Age\"]=test[\"Age\"].fillna(df[\"Age\"].median())\ntest[\"Embarked\"]=test[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\ntest.drop(\"Cabin\",axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)\ntest.drop(\"PassengerId\",axis=1,inplace=True)\ntest.drop(\"Ticket\",axis=1,inplace=True)","76dde1b2":"train[\"Sex\"]=train[\"Sex\"].map({\"male\":0,\"female\":1})\ntest[\"Sex\"]=test[\"Sex\"].map({\"male\":0,\"female\":1})","cb44ec03":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\ntemp = pd.DataFrame(encoder.fit_transform(train[['Embarked']]).toarray(), columns=['S', 'C', 'Q'])\ntrain = train.join(temp)\ntrain.drop(columns='Embarked', inplace=True)\n\ntemp = pd.DataFrame(encoder.transform(test[['Embarked']]).toarray(), columns=['S', 'C', 'Q'])\ntest = test.join(temp)\ntest.drop(columns='Embarked', inplace=True)","7e0f8283":"train.head()","b10ee9fd":"X=train.drop('Survived',axis=1)\ny=train[\"Survived\"]","8eb3503f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","95a00a7a":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","761a7cc6":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()","3d2ed048":"model.fit(X_train,y_train)","8bfbef87":"pred=model.predict(X_test)","a5beeaf9":"from sklearn.metrics import accuracy_score,confusion_matrix","b3350410":"accuracy_score=accuracy_score(y_test,pred)\naccuracy_score","57416a7d":"sns.heatmap(confusion_matrix(y_test,pred),annot=True)","e9eebcfa":"sns.heatmap(confusion_matrix(y_test,pred),annot=True)","c68496a4":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center \" >Table of Contents<\/h1>\n\n\n* [1. Introduction](#1)\n    * [1.1 Libraries And Utilities](#1.1)\n    * [1.2 Data Preprocessing- loading, Missingvalues, and feature extraction](#1.2)\n* [2. Storytelling With Data - Explinatory Data Analysis](#2)\n    * [2.0 Uni-variate Analysis](#2.0)\n    * [2.1 Bi-variate Analysis](#2.1)\n    * [2.2 Multi-variate Analysis](#2.2)\n* [3. Conclusion](#3)\n* [4. Modeling and results](#4)\n* [5. References](#5)\n","b0d4f322":"<a id = '2'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 2. Stroytelling With Data <\/h2>","72686778":"\n\n<a id = '4'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 4. Modelling: <\/h2>","e37b0ac6":"<a id = '6'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 6. Scaling: <\/h2>","2271a897":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> Statistics of Data: <\/h4>","15ebf8b8":"<a id = '1'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 1. Introduction <\/h2>\n","c53f4bdf":"<a id = '4'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 4. Feature Engineering: <\/h2>","e43c8859":"## Knn:","bc387919":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> Handle Missing Values: <\/h4>","208d377e":"from sklearn.neighbors import KNeighborsClassifier\nmodel=KNeighborsClassifier()\nmodel.fit(X_train,y_train)\npred=model.predict(X_test)\naccuracy_score=accuracy_score(y_test,pred)\n","4114ac95":"<a id = '1.1'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 1.1 Libraries <\/h2>\n","096b9854":"<a id = '2.1'><\/a>\n<h2 style = \"font-family:garamond; font-size:35px; background-color: #f6f5f5; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 2.1 Univariate analysis:<\/h2>","5e083a77":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> Loading data <\/h4>","975efb68":"## logistic regression:","9d5be1bc":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> Statistical Analysis: <\/h4>","f66ab201":"<a id = '5'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 5. Train-Test Split: <\/h2>","5cdc3a67":"###### ","f265ca11":"<a id = '1.2'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight:normal; border-radius: 100px 100px; text-align: center\">1.2 Data Preprocessing <\/h2>","b87b4fe8":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> Checking Missing Values <\/h4>","8fe2d808":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\"> EDA + Prediction<\/h1>\n<br>\n<br>\n<br>\n<div class = 'image'> <img style=\"float:center; border:5px solid grey; width:100%\" align=center src = https:\/\/im-media.voltron.voanews.com\/Drupal\/01live-166\/styles\/892x501\/s3\/2019-04\/ECD0C2AF-BA7E-42C8-8098-901A7AF88D11.png?itok=r_EOMbp1> \n<\/div>\n<br>\n<br>\n\n","389f7b83":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight: normal; border-radius: 75px 150px; text-align: left\"> About Data-Set <\/h4>","0e4e37e1":"<a id = '2.2'><\/a>\n<h2 style = \"font-family:garamond; font-size:35px; background-color: #f6f5f5; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 2.2 Bivariate analysis:<\/h2>"}}