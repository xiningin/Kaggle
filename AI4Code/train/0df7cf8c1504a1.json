{"cell_type":{"72735735":"code","ab874031":"code","4bc60524":"code","4da37c9b":"code","d9e6c72f":"code","83d7f5dd":"code","8e3a5294":"code","08df0d0e":"code","187bce06":"code","62f7669a":"code","87188c8a":"code","c6a7d025":"code","71b86f98":"code","7ccb234e":"code","33e869d4":"code","26d87154":"code","5105a02f":"code","2fc6c5a8":"code","5e9d00b5":"code","867c8a4f":"code","7476b99b":"code","5fafe817":"code","6bd822c6":"code","6872223a":"code","6848992a":"code","e4730e41":"code","cfb37bb7":"code","46911481":"code","06d8c31a":"code","11a83b9c":"code","4c8931c0":"code","190fbc44":"code","5abf0b5b":"markdown","5fd78fde":"markdown","f8c9185c":"markdown","b50d9f45":"markdown","b0dd2055":"markdown","04356c5b":"markdown","8c6ce8a3":"markdown","c6cbbe36":"markdown","40ffd3eb":"markdown","81e065f7":"markdown","67e3b167":"markdown","9f49c758":"markdown","d879f0ad":"markdown","00034f4d":"markdown","89683fd8":"markdown","31a3bee4":"markdown","955648eb":"markdown","b0934e32":"markdown","38feda33":"markdown","0935d5d0":"markdown","41aee481":"markdown","a380db80":"markdown","780e90be":"markdown"},"source":{"72735735":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ab874031":"data=pd.read_csv(\"\/kaggle\/input\/hard-drive-failure-data\/hard_drive_failure_data.csv\")\ndata.head()","4bc60524":"capacities=np.array(data[\"capacity_bytes\"]).astype(int)\nmax(capacities)","4da37c9b":"suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\ndef humansize(nbytes):\n    i = 0\n    while nbytes >= 1024 and i < len(suffixes)-1:\n        nbytes \/= 1024.\n        i += 1\n    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n    return '%s %s' % (f, suffixes[i])","d9e6c72f":"humansize(max(capacities))","83d7f5dd":"humansize(min(capacities))","8e3a5294":"lifure=data[[\"lifetime\",\"failure\"]]\nlifure.corr()","08df0d0e":"print(data[\"failure\"].isna().sum())\nprint(data[\"failure\"].isnull().sum())","187bce06":"set(data[\"failure\"])","62f7669a":"expected=data.failure.shape[0]\nactual=np.array(data[\"failure\"]).astype(int).sum()\nif expected==actual:\n    print(\"All Values is 1\")\nelse:\n    print(\"Something else\")","87188c8a":"del data[\"failure\"]","c6a7d025":"data.head()","71b86f98":"set(data[\"@version\"])","7ccb234e":"del data[\"@version\"]","33e869d4":"data.head()","26d87154":"models=data[\"model\"]\nfor model in models:\n    print(model)","5105a02f":"models2letter=[]\nfor model in models:\n    models2letter.append(model[0:2])\n    ","2fc6c5a8":"set(models2letter)","5e9d00b5":"data[\"newmodels\"]=pd.Series(models2letter)\ndata.head()","867c8a4f":"pd.Series(models2letter)","7476b99b":"%matplotlib inline\nimport seaborn as sns\nsns.countplot(data=data,x=\"newmodels\")","5fafe817":"data.lifetime.describe()","6bd822c6":"lifetime0=data[data[\"lifetime\"]==0]\nlifetime0","6872223a":"sns.countplot(data=lifetime0,x=\"capacity_bytes\")","6848992a":"humancapacities=pd.Series(capacities).apply(humansize)","e4730e41":"data[\"humancapaci\"]=humancapacities\ndata.head()","cfb37bb7":"lifetime0=data[data[\"lifetime\"]==0]\nsns.countplot(data=lifetime0,x=\"humancapaci\")","46911481":"set(lifetime0[\"model\"])","06d8c31a":"bestdrives=data[data[\"lifetime\"]>600]\nbestdrives","11a83b9c":"sns.countplot(data=bestdrives,x=\"newmodels\")","4c8931c0":"#bakalim[5:7]\nmonth=[]\ndates=data[\"date\"]\nfor date in dates:\n    month.append(date[5:7])","190fbc44":"sns.countplot(month)","5abf0b5b":"How many firm in Harddisk Business?","5fd78fde":"\u0130t is interesting","f8c9185c":"Sg Disks has dominated this dataset.\nTO disk is looks best ","b50d9f45":"Also version column is meaningless.","b0dd2055":"5 it is very interesting. ","04356c5b":"My first Harddisk 40GB this smallest disk has twice as many capacity than mines","8c6ce8a3":"First 2 letter is good for recognize numbers. I use it.","c6cbbe36":"Which month hard drive is broken?","40ffd3eb":"## Thanks for reading.","81e065f7":"i think,Some series harddrives have a chronic problem.","67e3b167":"OKay now examine lifetime:","9f49c758":"What a number it's too big. COnvert to G\u0130gabyte\nUse this code: https:\/\/stackoverflow.com\/questions\/14996453\/python-libraries-to-calculate-human-readable-filesize-from-bytes","d879f0ad":"What are best harddrives?","00034f4d":"Best Drives not suprisingly dominated with ST","89683fd8":"I think Lifetime is highly correlated with failure. Examine it:","31a3bee4":"Nearly 11 TB is max.","955648eb":"OO I can't add humanize version of size of drive i added know","b0934e32":"Oh Failure have nans. \u0130t's a problem.","38feda33":"What about model column?","0935d5d0":"Okay Failure is not a meaningful column because all the values is 1","41aee481":"What about version column?","a380db80":"Min is 0. What are this disks other columns???","780e90be":"not have a meaningful difference between months."}}