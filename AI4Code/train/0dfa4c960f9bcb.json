{"cell_type":{"f31d6d36":"code","ab8f181d":"code","eb93f93d":"code","d918010c":"code","d3051480":"code","2efb7fc3":"code","4c9c414f":"code","a40edde9":"code","753df4e1":"code","59e767d1":"code","4a5dc05d":"code","fa288f24":"code","544f73f9":"code","1ec927f1":"code","ca84628d":"code","a72483d4":"code","9524064f":"code","1de9c1a0":"code","3e5cae08":"code","9d1fa527":"code","379af065":"code","77b73914":"code","bfd1f1af":"code","aee9e685":"code","8ac9f7c0":"code","fd3a753e":"code","551ef597":"code","41c00e04":"markdown","57d8e86f":"markdown","1251a862":"markdown","4e6b4300":"markdown"},"source":{"f31d6d36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ab8f181d":"train = pd.read_csv(\"..\/input\/train_E6oV3lV.csv\")\ntest = pd.read_csv(\"..\/input\/test_tweets_anuFYb8.csv\")","eb93f93d":"train.head()","d918010c":"test.head()","d3051480":"train['label'] = train['label'].astype('category')","2efb7fc3":"train.info()","4c9c414f":"from nltk.stem import WordNetLemmatizer\nfrom nltk import tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re","a40edde9":"train['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',' ',text)) for text in lis]) for lis in train['tweet']]\ntest['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',' ',text)) for text in lis]) for lis in test['tweet']]","753df4e1":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(train['text_lem'],train['label'])","59e767d1":"vect = TfidfVectorizer(ngram_range = (1,4)).fit(X_train)","4a5dc05d":"vect_transformed_X_train = vect.transform(X_train)\nvect_transformed_X_test = vect.transform(X_test)","fa288f24":"from sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import f1_score\n","544f73f9":"modelSVC = SVC(C=100).fit(vect_transformed_X_train,y_train)","1ec927f1":"predictionsSVC = modelSVC.predict(vect_transformed_X_test)\nsum(predictionsSVC==1),len(y_test),f1_score(y_test,predictionsSVC)","ca84628d":"modelLR = LogisticRegression(C=100).fit(vect_transformed_X_train,y_train)","a72483d4":"predictionsLR = modelLR.predict(vect_transformed_X_test)\nsum(predictionsLR==1),len(y_test),f1_score(y_test,predictionsLR)","9524064f":"modelNB = MultinomialNB(alpha=1.7).fit(vect_transformed_X_train,y_train)","1de9c1a0":"predictionsNB = modelNB.predict(vect_transformed_X_test)\nsum(predictionsNB==1),len(y_test),f1_score(y_test,predictionsNB)","3e5cae08":"modelRF = RandomForestClassifier(n_estimators=20).fit(vect_transformed_X_train,y_train)","9d1fa527":"predictionsRF = modelRF.predict(vect_transformed_X_test)\nsum(predictionsRF==1),len(y_test),f1_score(y_test,predictionsRF)","379af065":"modelSGD = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3).fit(vect_transformed_X_train,y_train)","77b73914":"predictionsSGD = modelSGD.predict(vect_transformed_X_test)\nsum(predictionsSGD==1),len(y_test),f1_score(y_test,predictionsSGD)","bfd1f1af":"vect = TfidfVectorizer(ngram_range = (1,4)).fit(train['text_lem'])\nvect_transformed_train = vect.transform(train['text_lem'])\nvect_transformed_test = vect.transform(test['text_lem'])","aee9e685":"FinalModel = LogisticRegression(C=100).fit(vect_transformed_train,train['label'])","8ac9f7c0":"predictions = FinalModel.predict(vect_transformed_test)","fd3a753e":"submission = pd.DataFrame({'id':test['id'],'label':predictions})","551ef597":"file_name = 'test_predictions.csv'\nsubmission.to_csv(file_name,index=False)","41c00e04":"## Processing the Tweets\n\n- Remove the special characters, numbers etc. (keep only alphabets)\n- lemmatize the text\n","57d8e86f":"## Reading the dataset","1251a862":"Based on all the above models trained we conclude that the logistic regression(C=100) is the better model amoung them, ergo, we use this model as our final model.","4e6b4300":"### F1 score is used as an evaluation measure as, when the data is skewed like in this case, where the number of hate speech tweets are very less, accuracy cannot be relied upon."}}