{"cell_type":{"0830406c":"code","64bcd98b":"code","acffafdd":"code","4125b2a0":"code","31460e34":"code","9d7d7eab":"code","cabd3c42":"code","541b7f4e":"code","1b983bbd":"code","f54fb78b":"markdown","ad3bb306":"markdown","c1aa1463":"markdown","05e99691":"markdown","9a1f2fb8":"markdown","862b4788":"markdown","4eeda96a":"markdown","723b8e46":"markdown","92b3ccec":"markdown"},"source":{"0830406c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nimport os\nprint(os.listdir(\"..\/input\"))\ninputData=pd.read_csv(r\"..\/input\/BreadBasket_DMS.csv\")\nprint(inputData.info())\nprint(inputData.describe())\nprint(inputData.head())\n","64bcd98b":"mergedDateTime = inputData.Date +' '+inputData.Time\ninputData.index = (pd.to_datetime(mergedDateTime))\ninputData.drop([\"Time\",\"Date\",\"Transaction\"],axis=1,inplace=True)\n","acffafdd":"startDate,endDate = \"2016-10\",\"2016-12\"\ntrainingData = inputData[startDate:endDate]\ntestingData = inputData[endDate:]\nitemName = \"Jam\"","4125b2a0":"#Training Data\ndates = trainingData.rename_axis('Dates').index.floor('H')\ntrainHourlyCount = trainingData.groupby([dates,'Item']).size().reset_index(name='count')\nprint (trainHourlyCount)\n\ndates = trainingData.rename_axis('Dates').index.floor('24H')\ntrain24HourlyCount = trainingData.groupby([dates,'Item']).size().reset_index(name='count')\nprint (train24HourlyCount)\n\n# Calculate the probability\ntotal = train24HourlyCount[train24HourlyCount.Item == itemName][\"count\"].sum()\ntrainProbability = trainHourlyCount[trainHourlyCount.Item == itemName].copy()\ntrainProbability[\"HourlyProbability\"] = trainHourlyCount[trainHourlyCount.Item == itemName][\"count\"]\/total\n\n#Testing Data\ndates = testingData.rename_axis('Dates').index.floor('H')\ntestHourlyCount = testingData.groupby([dates,'Item']).size().reset_index(name='count')\nprint (testHourlyCount)\n\ndates = testingData.rename_axis('Dates').index.floor('24H')\ntest24HourlyCount = testingData.groupby([dates,'Item']).size().reset_index(name='count')\nprint (train24HourlyCount)\n","31460e34":"total = test24HourlyCount[test24HourlyCount.Item == itemName][\"count\"].sum()\ntestProbability = testHourlyCount[testHourlyCount.Item == itemName].copy()\ntestProbability[\"HourlyProbability\"] = testHourlyCount[testHourlyCount.Item == itemName][\"count\"]\/total","9d7d7eab":"fig = plt.figure(figsize = (15,5))\nax = fig.gca()\nx = list(trainProbability.Dates.dt.time)\ny = trainProbability[\"HourlyProbability\"]\nplt.scatter(x,y,label=\"Train\")\n\nx = list(testProbability.Dates.dt.time)\ny = testProbability[\"HourlyProbability\"]\nplt.scatter(x,y,label=\"Test\")\n\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Probability of {} sold during the day'.format(itemName),fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()","cabd3c42":"import statsmodels.api as sm\nfrom statsmodels.tsa.api import Holt, ExponentialSmoothing\n\n# We need datetime index for the analysis\ntrainProbability.set_index(\"Dates\",inplace=True)\ntrainProbability.drop([\"Item\",\"count\"],axis=1,inplace=True)\n\ntestProbability.set_index(\"Dates\",inplace=True)\ntestProbability.drop([\"Item\",\"count\"],axis=1,inplace=True)","541b7f4e":"sm.tsa.seasonal_decompose(trainProbability.HourlyProbability,freq=1).plot()\nresult = sm.tsa.stattools.adfuller(trainProbability.HourlyProbability)\nplt.show()\npredicted = testProbability.copy()\nfit1 = Holt(np.asarray(trainProbability.HourlyProbability)).fit(smoothing_level = 0.3,smoothing_slope = 0.1)\npredicted['Holt_linear'] = fit1.forecast(len(testProbability))\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nplt.scatter(pd.Series(trainProbability.index.time).astype(str),trainProbability.HourlyProbability,label=\"Train\",c='r',marker='.')\nplt.scatter(pd.Series(testProbability.index.time).astype(str),testProbability.HourlyProbability,label=\"Test\",c='g',marker='+')\nplt.scatter(pd.Series(predicted.index.time).astype(str),predicted.Holt_linear,label=\"Predicted\",c='b',marker='*')\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Holt\\'s Linear Forecast',fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\nrms = sqrt(mean_squared_error(testProbability.HourlyProbability, predicted.Holt_linear))\nprint(\"RMS Error:\",rms)\n","1b983bbd":"# Holt-Winters linear trend method\ndel predicted\npredicted = testProbability.copy()\nfit1 = ExponentialSmoothing(np.asarray(trainProbability.HourlyProbability) ,seasonal_periods=6,trend='add', seasonal='add',).fit()\npredicted['Holt_Winters'] = fit1.forecast(len(testProbability))\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nplt.scatter(pd.Series(trainProbability.index.time).astype(str),trainProbability.HourlyProbability,label=\"Train\",c='r',marker='.')\nplt.scatter(pd.Series(testProbability.index.time).astype(str),testProbability.HourlyProbability,label=\"Test\",c='g',marker='+')\nplt.scatter(pd.Series(predicted.index.time).astype(str),predicted.Holt_Winters,label=\"Predicted\",c='b',marker='*')\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Holt-Winters\\'s Forecast',fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\nrms = sqrt(mean_squared_error(testProbability.HourlyProbability, predicted.Holt_Winters))\nprint(\"RMS Error:\",rms)","f54fb78b":"# Visualize the train\/test sets","ad3bb306":"# Forecasting","c1aa1463":"# Calculate the probability","05e99691":"# Program to forecast the probability of an item sold every hour","9a1f2fb8":"# Merge to make a DateTimeIndex","862b4788":"# Holt-Winters linear trend method","4eeda96a":"# Group the data on 1-hourly\/24-hourly spans\n","723b8e46":"# Holt's linear trend method","92b3ccec":"# Split data into train\/test sets"}}