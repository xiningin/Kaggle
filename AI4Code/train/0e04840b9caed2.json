{"cell_type":{"64375eb4":"code","49971238":"code","adbcd81f":"code","ac42fb20":"code","ca73243d":"code","bce0a493":"code","c84d8806":"code","227c1809":"code","6c1e9b1c":"code","dfb8654d":"code","57a74aee":"code","4f63b809":"code","30b9789d":"code","227900b3":"code","0e4c0a4c":"code","f91cbc83":"code","3f79a546":"code","89cb60f9":"code","955f6898":"code","6d767005":"code","36c52b15":"code","664311f6":"code","cc857423":"code","2227067d":"code","e906a69b":"code","b94a73ba":"code","70d29234":"code","8e812684":"code","ee539104":"code","e288818b":"code","29c670a4":"code","c3051f5e":"code","77773c37":"code","1567ea73":"code","3209ac1d":"code","1e03ea5e":"code","6b5161bf":"code","3312e858":"code","c3d1aca7":"code","02732f5b":"code","2b9531a9":"code","6b2a6752":"code","f8151aee":"code","ec7f168d":"code","03810047":"code","4bb0f263":"code","d5ff6850":"code","e0ae7ee9":"code","0f955b7d":"code","cbfb67be":"code","cce9f11a":"code","86f3b3da":"code","a26dc50f":"code","3938c386":"code","b0d561d4":"code","9b6e80c8":"code","5523d50a":"code","48bc3457":"code","c8efa89b":"code","ca4f1f94":"code","add0a5a2":"code","e6890f5f":"code","7b977c24":"code","e8fef57f":"code","78ea514a":"code","28d3ab47":"code","83a6c8de":"code","2213a7b1":"code","87a58431":"code","1be1a0cc":"code","3468d606":"code","7516c2de":"code","bac6f427":"markdown","724c5301":"markdown","c820a53e":"markdown","ba07d3ab":"markdown","edbe1608":"markdown","f26f4bb9":"markdown","e74161e1":"markdown","42845f6f":"markdown","eaa16e61":"markdown","f8018aab":"markdown","447a4030":"markdown","ecad5815":"markdown","bc93f34c":"markdown","0c6b0aab":"markdown","4a78d0ef":"markdown","9ad3df5f":"markdown","b80acc7f":"markdown","f97fdb2a":"markdown","7e9f775b":"markdown","93610eb5":"markdown","61451786":"markdown","a979c60e":"markdown","78c02747":"markdown","1d343f31":"markdown","4aa90415":"markdown","e4dcadba":"markdown","927383d6":"markdown","298c371f":"markdown","a2bc3ace":"markdown","7117f914":"markdown","68899996":"markdown","02bde9a3":"markdown","a7c13967":"markdown"},"source":{"64375eb4":"# Imports\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_curve, roc_auc_score, auc\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier\nimport random","49971238":"df_train = pd.read_csv('\/kaggle\/input\/equipfails\/equip_failures_training_set.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/equipfails\/equip_failures_test_set.csv')","adbcd81f":"df_train.target.value_counts()","ac42fb20":"# analyzing one of the sensors:\nhist_cols = [i for i in df_train.columns if 'sensor7_' in i]\nhist_cols","ca73243d":"df_sen = df_train[hist_cols]","bce0a493":"# # agger 0s\n# for i in range(0, int(len(df_train[df_train.target==0])\/10), 10):\n#     print(df_train.loc[:10])","c84d8806":"# dropping all hists for now\nnon_hist_cols_train = [i for i in df_train.columns if 'histogram' not in i]\nnon_hist_cols_test = [i for i in df_test.columns if 'histogram' not in i]\n\ndf_train = df_train[non_hist_cols_train]\ndf_test = df_test[non_hist_cols_test]","227c1809":"# dealing with the datatypes\ndf_train = df_train.applymap(lambda x: np.nan if x == 'na' else float(x))\ndf_test = df_test.applymap(lambda x: np.nan if x == 'na' else float(x))","6c1e9b1c":"# the number of rows and columns before dropping the nans:\nprint(\"TRAIN: \", \"rows: \", len(df_train), \"cols: \", len(df_train.columns))\nprint(\"TEST: \", \"rows: \", len(df_test), \"cols: \", len(df_test.columns))","dfb8654d":"nan_dist_train = {}\nnan_dist_test = {}\n\nfor i in df_train.columns:    \n    nan_dist_train[i] = df_train[i].isna().sum()\n        \nfor i in df_test.columns:    \n    nan_dist_test[i] = df_test[i].isna().sum()","57a74aee":"# plotting nan dist.\nplt.scatter(range(len(nan_dist_train)), list(nan_dist_train.values()))\nplt.xticks(range(len(nan_dist_train)), list(nan_dist_train.keys()))\nplt.title('NaN vs Column')\nplt.show()","4f63b809":"plt.scatter(range(len(nan_dist_test)), list(nan_dist_test.values()))\nplt.xticks(range(len(nan_dist_test)), list(nan_dist_test.keys()))\nplt.title('NaN vs Column')\nplt.show()","30b9789d":"# drop the column if a percentage of the column (its rows) is na\n# 6 percent\nfor i in df_train.columns:\n    if df_train[i].isna().sum() > 0.06 * len(df_train):\n        df_train.drop(i, axis=1, inplace=True)","227900b3":"# drop the column if a percentage of the column (its rows) is na\n# 6 percent\nfor i in df_test.columns:\n    if df_test[i].isna().sum() > 0.06 * len(df_test):\n        df_test.drop(i, axis=1, inplace=True)","0e4c0a4c":"df_train.fillna(value=0, axis=1, inplace=True)\ndf_test.fillna(value=0, axis=1, inplace=True)","f91cbc83":"# the number of rows and columns after dropping the nans:\nprint(\"rows: \", len(df_train), \"cols: \", len(df_train.columns))\nprint(\"rows: \", len(df_test), \"cols: \", len(df_test.columns))","3f79a546":"# See if there are any nans left:\nprint(df_train.isna().sum().sum())\nprint(df_test.isna().sum().sum())","89cb60f9":"zero_dist_train = {}\nzero_dist_test = {}\n\nfor i in df_train.columns:\n    if 0 in df_train[i].value_counts():    \n        zero_dist_train[i] = df_train[i].value_counts()[0]\n        \nfor i in df_test.columns:\n    if 0 in df_train[i].value_counts():    \n        zero_dist_test[i] = df_train[i].value_counts()[0]","955f6898":"plt.scatter(range(len(zero_dist_train)), list(zero_dist_train.values()))\nplt.xticks(range(len(zero_dist_train)), list(zero_dist_train.keys()))\nplt.title('Number of Zeroes vs Columns')\nplt.show()","6d767005":"plt.scatter(range(len(zero_dist_test)), list(zero_dist_test.values()))\nplt.xticks(range(len(zero_dist_test)), list(zero_dist_test.keys()))\nplt.title('Number of Zeroes vs Columns')\nplt.show()","36c52b15":"# the number of rows and columns before dropping the nans:\nprint(\"TRAIN: \", \"rows: \", len(df_train), \"cols: \", len(df_train.columns))\nprint(\"TEST: \", \"rows: \", len(df_test), \"cols: \", len(df_test.columns))","664311f6":"# the number of rows and columns before dropping the nans:\nprint(\"TRAIN: \", \"rows: \", len(df_train), \"cols: \", len(df_train.columns))\nprint(\"TEST: \", \"rows: \", len(df_test), \"cols: \", len(df_test.columns))","cc857423":"# 50\nzero_index = np.array([i for i in df_train[df_train.target == 0].index])\nzero_index = np.random.choice(zero_index, int(0.50 * len(zero_index)), replace = False)\ndf_train = pd.concat([df_train[df_train.target == 1], df_train.loc[zero_index]])","2227067d":"df_train.target.value_counts()","e906a69b":"d = {}\n\ndf_train_1 = df_train[df_train.target == 1]\n\nfor i in df_train_1.columns:\n    if (i != 'target') or (i != 'id'):\n        mu = df_train_1[i].mean()\n        std = df_train_1[i].std()\n        \n        signal = np.random.normal(mu, std, 4000)\n        \n        d[i] = signal\n\nnew_df = pd.concat([df_train, pd.DataFrame(d)])    ","b94a73ba":"new_df.target.value_counts()","70d29234":"import seaborn as sns\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","8e812684":"df_train_0 = new_df[new_df.target == 0]\nnew_df = new_df[new_df.target == 1]\nnew_df = pd.concat([new_df, df_train_0.groupby(df_train_0.index \/\/ 10).mean()])","ee539104":"# # # sensor61_measure, sensor17_measure, sensor35_measure\n# df_train['sensor35_measure_2'] = df_train.sensor35_measure * df_train.sensor17_measure\n# df_train['sensor35_measure_3'] = df_train.sensor35_measure * df_train.sensor35_measure\n# df_train['sensor35_measure_4'] = df_train.sensor17_measure * df_train.sensor61_measure\n# df_train['sensor35_measure_5'] = df_train.sensor1_measure * df_train.sensor1_measure\n# df_train['sensor35_measure_6'] = df_train.sensor17_measure * df_train.sensor17_measure\n\n# df_train['sensor35_measure_5'] = df_train.sensor1_measure * df_train.sensor1_measure\n# df_train['sensor35_measure_6'] = df_train.sensor1_measure * df_train.sensor35_measure\n# df_train['sensor35_measure_7'] = df_train.sensor16_measure * df_train.sensor35_measure\n\n# df_train['sensor17_measure_2'] = df_train.sensor17_measure * df_train.sensor61_measure\n# df_train['sensor35_measure_2'] = df_train.sensor35_measure * df_train.sensor17_measure","e288818b":"# # Create correlation matrix\n# corr_matrix = df_train.corr().abs()\n\n# # Select upper triangle of correlation matrix\n# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# # Find index of feature columns with correlation greater than 0.95\n# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n# df_train.drop(df_train[to_drop], axis=1, inplace=True)","29c670a4":"# the number of rows and columns before dropping the nans:\nprint(\"TRAIN: \", \"rows: \", len(df_train), \"cols: \", len(df_train.columns))\nprint(\"TEST: \", \"rows: \", len(df_test), \"cols: \", len(df_test.columns))","c3051f5e":"# train set\ny_train = df_train['target']\nids_train = df_train['id']\n\ndf_train.drop('id', axis=1, inplace=True)\ndf_train.drop('target', axis=1, inplace=True)\n\n# print(df_train.head())\n\nX_train = df_train.values\n\n# test set\nids_test = df_test['id']\n# print(df_test.head())\ndf_test.drop('id', axis=1, inplace=True)\n\nX_test = df_test.values","77773c37":"# Scaler models:\n# scaler_model = StandardScaler()\nscaler_model = MinMaxScaler()","1567ea73":"inter = [i for i in df_train.columns if i in df_test.columns]\ndf_train = df_train[inter]\ndf_test = df_test[inter]\nlen(df_test.columns)","3209ac1d":"X_train_internal, X_test_internal, y_train_interal, y_test_interal = train_test_split(X_train, y_train, test_size=0.10, random_state=0)","1e03ea5e":"scaler_model.fit(X_train_internal)\n\nX_train_internal = scaler_model.transform(X_train_internal)\nX_test_internal = scaler_model.transform(X_test_internal)\nX_test = scaler_model.transform(X_test)","6b5161bf":"# ADHOC RF\nfrom sklearn.ensemble import AdaBoostClassifier\nad_hocModel_2 = AdaBoostClassifier()\nad_hocModel_2.fit(X_train_internal, y_train_interal)","3312e858":"y_adhoc_pred = ad_hocModel_2.predict(X_test_internal)\n\nADA_F1 = f1_score(y_pred=y_adhoc_pred, y_true=y_test_interal, average='binary')\n\ndef plot_confusion_matrix(y_true, y_pred,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n#            xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nplot_confusion_matrix(y_test_interal, y_adhoc_pred, normalize=True,\n                      title='Normalized confusion matrix')\n\n\ny_pred_test = ad_hocModel_2.predict(X_test)\ndf_out = pd.DataFrame({'id': ids_test, 'target': y_pred_test}, dtype=int)\ndf_out.to_csv('out.csv', index=None)","c3d1aca7":"# ADHOC RF\nad_hocModel = RandomForestClassifier(max_depth=10, random_state=0)\nad_hocModel.fit(X_train_internal, y_train_interal)","02732f5b":"\ny_adhoc_pred = ad_hocModel.predict(X_test_internal)\n\ndef plot_confusion_matrix(y_true, y_pred,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n#            xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nplot_confusion_matrix(y_test_interal, y_adhoc_pred, normalize=True,\n                      title='Normalized confusion matrix')\n\n\ny_pred_test = ad_hocModel.predict(X_test)\ndf_out = pd.DataFrame({'id': ids_test, 'target': y_pred_test}, dtype=int)\ndf_out.to_csv('out.csv', index=None)","2b9531a9":"import pandas as pd\nfeature_importances = pd.DataFrame(ad_hocModel.feature_importances_,\n                                   index = df_train.columns,\n                                    columns=['importance']).sort_values('importance', ascending=False)\n\nfeature_importances[:10]","6b2a6752":"# plt.scatter(df_train.sensor61_measure, df_train.sensor1_measure, c=y_train_interal)","f8151aee":"pca_train_internal = PCA(n_components=2).fit(X_train_internal)\npca_test_internal = PCA(n_components=2).fit(X_test_internal)\npca_test = PCA(n_components=2).fit(X_test)\n\nX_train_internal_pca = pca_train_internal.transform(X_train_internal)\nX_test_internal_pca = pca_test_internal.transform(X_test_internal)\nX_test_pca = pca_test.transform(X_test)","ec7f168d":"pca_test.explained_variance_ratio_","03810047":"plt.scatter(X_train_internal_pca[:, 0], X_train_internal_pca[:, 1])","4bb0f263":"# model = RandomForestClassifier(max_depth=4)\nmodel = RandomForestClassifier(max_depth=8)\nmodel.fit(X_train_internal_pca, y_train_interal)","d5ff6850":"y_pred_train_interal = model.predict(X_train_internal_pca)\ny_pred_test_interal = model.predict(X_test_internal_pca)","e0ae7ee9":"f1_score(y_pred=y_pred_train_interal, y_true=y_train_interal, average='binary') ","0f955b7d":"F1_RF = f1_score(y_pred=y_pred_test_interal, y_true=y_test_interal, average='binary') \nF1_RF","cbfb67be":"accuracy_score(y_pred=y_pred_train_interal, y_true=y_train_interal)","cce9f11a":"accuracy_score(y_pred=y_pred_test_interal, y_true=y_test_interal)","86f3b3da":"plt.scatter(X_train_internal_pca[:, 0], X_train_internal_pca[:, 1], c=y_train_interal)","a26dc50f":"def plot_confusion_matrix(y_true, y_pred,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n#            xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nplot_confusion_matrix(y_test_interal, y_pred_test_interal, normalize=True,\n                      title='Normalized confusion matrix')\n","3938c386":"y_pred_test = model.predict(X_test_pca)","b0d561d4":"df_out = pd.DataFrame({'id': ids_test, 'target': y_pred_test}, dtype=int)\ndf_out.to_csv('out.csv', index=None)","9b6e80c8":"(y_pred_test == 1).sum()","5523d50a":"y_pred_test_prob = model.predict_proba(X_test_pca)","48bc3457":"y_pred_test_prob","c8efa89b":"import pickle\nfilename = \"RF_model.pkl\"\npickle.dump(model, open(filename, \"wb\"))","ca4f1f94":"np.savetxt(\"test.csv\", X_test_pca, delimiter=\",\")","add0a5a2":"model = MLPClassifier(alpha=0.5)\nmodel.fit(X_train_internal_pca, y_train_interal)","e6890f5f":"y_pred_train_interal = model.predict(X_train_internal_pca)\ny_pred_test_interal = model.predict(X_test_internal_pca)","7b977c24":"f1_score(y_pred=y_pred_train_interal, y_true=y_train_interal, average='binary') ","e8fef57f":"F1_NN = f1_score(y_pred=y_pred_test_interal, y_true=y_test_interal, average='binary') \nF1_NN","78ea514a":"accuracy_score(y_pred=y_pred_train_interal, y_true=y_train_interal)","28d3ab47":"accuracy_score(y_pred=y_pred_test_interal, y_true=y_test_interal)","83a6c8de":"y_pred_test = model.predict(X_test_pca)","2213a7b1":"df_out = pd.DataFrame({'id': ids_test, 'target': y_pred_test}, dtype=int)\ndf_out.to_csv('out.csv', index=None)","87a58431":"(y_pred_test == 1).sum()","1be1a0cc":"def plot_confusion_matrix(y_true, y_pred,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n#            xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nplot_confusion_matrix(y_test_interal, y_pred_test_interal, normalize=True,\n                      title='Normalized confusion matrix')\n","3468d606":"from sklearn.naive_bayes import GaussianNB\n\n# model = RandomForestClassifier(max_depth=4)\nmodel = GaussianNB()\nmodel.fit(X_train_internal_pca, y_train_interal)\n\ny_pred_train_interal = model.predict(X_train_internal_pca)\ny_pred_test_interal = model.predict(X_test_internal_pca)\n\nF1_GNB = f1_score(y_pred=y_pred_test_interal, y_true=y_test_interal, average='binary') \nF1_GNB\n\ny_pred_test = model.predict(X_test_pca)\n\ndf_out = pd.DataFrame({'id': ids_test, 'target': y_pred_test}, dtype=int)\ndf_out.to_csv('out.csv', index=None)\n\ndef plot_confusion_matrix(y_true, y_pred,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n#            xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nplot_confusion_matrix(y_test_interal, y_pred_test_interal, normalize=True,\n                      title='Normalized confusion matrix')\n","7516c2de":"plot_help = list(zip(range(4), [F1_RF, F1_NN, F1_GNB, ADA_F1]))\nplt.bar(['RF', 'NN', 'GNB', 'ADA_BOOST'], [F1_RF, F1_NN, F1_GNB, ADA_F1])\nplt.title(\"F1 Score Comparison\")","bac6f427":"Adding regularization to help with overfitting","724c5301":"The following line makes sure that the same columns are considered in the train and test set","c820a53e":"### plotting the number of zeros vs non-zeros per column","ba07d3ab":"## Exploratory Data Analysis","edbe1608":"# Sampling\nDownsampling to 50% on class 0 because of the class imbalance","f26f4bb9":"Drops all the columns that have correlation larger than 90%. Mitigated with PCA.","e74161e1":"### Finding out the dist. of nans throughout the dataset","42845f6f":"99% of the variance of the data is represented in the first eigenvalue","eaa16e61":"# Model\nBuilding the random forest classifier. Depth was determined by experimentation","f8018aab":"# Plotting Different Models:","447a4030":"Replacing NaNs with 0 since there is no correlation between the rows and columns, and this gives us the best solution.","ecad5815":"# Adding some new features\nAdding new features based on the most important features to introduce non-linearity and help with the predictors. ","bc93f34c":"Models every column as a normal distribution and samples for class 1 since it's underrepresented","0c6b0aab":"Parsa Dastjerdi\nArash Abdollahzadeh\nPrasann Singhal\nXiangyun Liao","4a78d0ef":"How many of class 1 was predicted","9ad3df5f":"The following aggregrates every 10 zero class samples to further help with the imbalance","b80acc7f":"# Export","f97fdb2a":"Counting the values of the target to find out how skewed our data is, we will need to address the imbalance in the dataset later on in the notebook","7e9f775b":"# Scaling\nThrough experimentation, we realized that StandardScaler is not applicable to this problem and MinMaxScaler works much better.","93610eb5":"Change all 'na' to NaN, otherwise make the datatype float. Dealing with wrongly infered datatypes.","61451786":"## PCA\nApplying PCA to deal with noise and help with visualization and prediction","a979c60e":"# Eval","78c02747":"Adhoc model for a quick and dirty way to get some initial results","1d343f31":"# Another Model","4aa90415":"# Train set","e4dcadba":"# Dealing with NaNs","927383d6":"# Dropping the hists","298c371f":"# Understanding the corrs","a2bc3ace":"# Understanding the histograms","7117f914":"Plots a confusion matrix","68899996":"> # Correlation","02bde9a3":"### Finding the dist based on class:\nDropping the column if has more than 6% NaNs. Arrived at this number by experimentation and running the algorithm multiple times (reproducibility) ","a7c13967":"### Train\nThe following plot shows the distribution for each column"}}