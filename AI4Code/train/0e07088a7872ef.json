{"cell_type":{"fea98bae":"code","b8f69120":"code","8bb56f9a":"code","a5c8dd3c":"code","b157e4a9":"code","6a044486":"code","7ee9b831":"code","d853ef64":"code","fcfadcc5":"code","e1fda8da":"code","d4f16ce8":"code","605f5e99":"code","b17bd785":"code","67569588":"code","c3cd5d73":"code","2ae851d1":"code","96f1365e":"code","1420d789":"code","9b08731f":"code","12c36a60":"code","d84fb762":"code","03796ce5":"markdown","ae9daf16":"markdown","b10ca152":"markdown","01ba2a56":"markdown","06a933dc":"markdown","3cb944b5":"markdown","67a82da5":"markdown","8b3d57b4":"markdown"},"source":{"fea98bae":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re \nimport seaborn as sns\nimport string\nimport nltk\nimport warnings \nwarnings.filterwarnings('ignore', category=DeprecationWarning)\npd.options.mode.chained_assignment = None  # default='warn'\n\n%matplotlib inline","b8f69120":"temp = pd.read_csv('..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv')","8bb56f9a":"temp.head()","a5c8dd3c":"temp.info()","b157e4a9":"# create a new dataframe consist of only text and rating\ndf = pd.DataFrame()\ndf[['text', 'rating']] = temp[['reviews.text', 'reviews.rating']]\ndf.head()","6a044486":"# Investigate how many rows of have a Null values\ndf.isnull().sum()","7ee9b831":"# drop the rows with Null values \ndf.dropna(inplace=True)\ndf.info()","d853ef64":"df['label'] = df['rating'].apply(lambda x : 1 if x >= 4 else 0) \n\n# drop the unneeded column of ratings\ndf.drop(labels=['rating'], axis=1, inplace=True)\n\ndf.head()","fcfadcc5":"def remove_pattern(text, pattern):\n    \"\"\"\n    Docstring: \n    \n    remove any pattern from the input text.\n    \n    Parameters\n    ----------\n    text: string input, the text to clean.\n    pattern : string input, the pattern to remove from the text input.\n    \n    Returns\n    -------\n    a cleaned string.\n    \n    \"\"\"\n    \n    # find all the pattern in the input text and return a list of postion indeces \n    r = re.findall(pattern, text)\n    \n    # replace the pattern with an empty space\n    for i in r: text = re.sub(pattern, '', text)\n    \n    return text","e1fda8da":"# lower case every word to ease the upcoming processes \ndf['text'] = df['text'].str.lower()\n\n# tokenize the text to search for any stop words to remove it\ndf['tokenized_text'] = df.text.apply(lambda x : x.split())\n\n# creating a set of stopwords(if you wonder why set cuz it is faster than a list)\nstopWords = set(nltk.corpus.stopwords.words('english'))\ndf['tokenized_text'] = df['tokenized_text'].apply(lambda x : [word for word in x if not word in stopWords])\n\n# create a word net lemma\nlemma = nltk.stem.WordNetLemmatizer()\npos = nltk.corpus.wordnet.VERB\ndf['tokenized_text'] = df['tokenized_text'].apply(lambda x : [lemma.lemmatize(word, pos) for word in x])\n\n# remove any punctuation\ndf['tokenized_text'] = df['tokenized_text'].apply(lambda x : [ remove_pattern(word,'\\.') for word in x])\n\n# rejoin the text again to get a cleaned text\ndf['cleaned_text'] = df['tokenized_text'].apply(lambda x : ' '.join(x))\n\ndf.drop(labels=['tokenized_text'], axis=1, inplace=True)\n\ndf.head()","d4f16ce8":"from sklearn.feature_extraction.text import CountVectorizer\n\n\n# perform vectorization on our cleaned text \nbow_vectorizer = CountVectorizer(max_df=0.9, min_df=2, stop_words='english', max_features=1000)\n\nbow_features = bow_vectorizer.fit_transform(df['cleaned_text'])\n\nbow_df = pd.DataFrame(bow_features.toarray(), columns=bow_vectorizer.get_feature_names())\n\nbow_df.head()","605f5e99":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_Vectorizer = TfidfVectorizer(max_df=0.9, min_df=2, max_features=1000, stop_words='english')\n\ntfidf_features = tfidf_Vectorizer.fit_transform(df['cleaned_text'])\n\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_Vectorizer.get_feature_names())\n\ntfidf_df.head()","b17bd785":"from sklearn.model_selection import train_test_split\n\nX_train_bow, X_metric_bow, y_train_bow, y_metric_bow = train_test_split(bow_df, df['label'], test_size=0.2, random_state=42)\nX_test_bow, X_valid_bow, y_test_bow, y_valid_bow = train_test_split(X_metric_bow, y_metric_bow, test_size=0.5, random_state=42)\n\n\nX_train_tfidf, X_metric_tfidf, y_train_tfidf, y_metric_tfidf = train_test_split(tfidf_df, df['label'], test_size=0.2, random_state=42)\nX_test_tfidf, X_valid_tfidf, y_test_tfidf, y_valid_tfidf = train_test_split(X_metric_tfidf, y_metric_tfidf, test_size=0.5, random_state=42)","67569588":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\n\nclf_bow = clf_tfidf = AdaBoostClassifier(n_estimators=100, learning_rate=0.001)","c3cd5d73":"clf_bow.fit(X_train_bow, y_train_bow)\nclf_tfidf.fit(X_train_tfidf, y_train_tfidf)","2ae851d1":"pred_bow   = clf_bow.predict(X_test_bow)\npred_tfidf = clf_tfidf.predict(X_test_tfidf)","96f1365e":"from colorama import Fore, Style\n\nprint(f'AdaBoost Classifier Results: \\n',\n      f'{Fore.RED}Bag of words{Style.RESET_ALL} \\n',\n      f'Accuracy Socre: {Fore.LIGHTBLUE_EX}%0.2f %%{Style.RESET_ALL} \\n'%(100 * accuracy_score(y_test_bow, pred_bow)))\nprint(classification_report(y_test_bow, pred_bow))\n\nprint(f'{Fore.RED}TF-IDF{Style.RESET_ALL} \\n',\n      f'Accuracy Socre: {Fore.LIGHTBLUE_EX}%0.2f %%{Style.RESET_ALL} \\n'%(100 * accuracy_score(y_test_tfidf, pred_tfidf)))\nprint(classification_report(y_test_tfidf, pred_tfidf))","1420d789":"from sklearn.neighbors import KNeighborsClassifier\n\nclf_bow_knn = clf_tfidf_knn = KNeighborsClassifier()","9b08731f":"clf_bow_knn.fit(X_train_bow, y_train_bow)\nclf_tfidf_knn.fit(X_train_tfidf, y_train_tfidf)","12c36a60":"pred_bow_knn   = clf_bow_knn.predict(X_test_bow)\npred_tfidf_knn = clf_tfidf_knn.predict(X_test_tfidf)","d84fb762":"print(f'KNN Classifier Results: \\n',\n      f'{Fore.RED}Bag of words{Style.RESET_ALL} \\n',\n      f'Accuracy Socre: {Fore.LIGHTBLUE_EX}%0.2f %%{Style.RESET_ALL} \\n'%(100 * accuracy_score(y_test_bow, pred_bow_knn)))\nprint(classification_report(y_test_bow, pred_bow_knn))\n\nprint(f'{Fore.RED}TF-IDF{Style.RESET_ALL} \\n',\n      f'Accuracy Socre: {Fore.LIGHTBLUE_EX}%0.2f %%{Style.RESET_ALL} \\n'%(100 * accuracy_score(y_test_tfidf, pred_tfidf_knn)))\nprint(classification_report(y_test_tfidf, pred_tfidf_knn))","03796ce5":"### Importing the main toolkits","ae9daf16":"## 5- Building a Machine Learning Model ","b10ca152":"## 1- Reading the Dataset ","01ba2a56":"## 4- Dataset Split","06a933dc":"## 3- Features Extraction ","3cb944b5":"### i- Bag of Words Method","67a82da5":"# 2- Text Preprocessing","8b3d57b4":"### ii- TF-IDF Method"}}