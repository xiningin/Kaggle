{"cell_type":{"0b34d7dd":"code","85dc91ed":"code","4c5d523f":"code","f89fc129":"code","6ab0a087":"code","58ac811c":"markdown","9f09477f":"markdown"},"source":{"0b34d7dd":"# importing the libraries needed\nimport os\nimport tensorflow as tf","85dc91ed":"# Define model 1\nmodel1 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(150, 150, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2),\n    tf.keras.layers.Conv2D(128, (3, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2),\n    tf.keras.layers.Conv2D(256, (3, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2),\n    tf.keras.layers.Conv2D(512, (3, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel1.summary()\nmodel1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])","4c5d523f":"train_datgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.\/255,\n                                                              rotation_range = 40,\n                                                              width_shift_range = 0.2,\n                                                              height_shift_range = 0.2,\n                                                              shear_range = 0.2,\n                                                              zoom_range = 0.2,\n                                                              horizontal_flip = True,\n                                                              fill_mode = 'nearest'\n                                                              )\ntrain_generator = train_datgen.flow_from_directory(\n    '..\/input\/waste-classification-data\/DATASET\/TRAIN',\n    target_size=(150, 150),\n    batch_size = 32,\n    class_mode='binary'\n    \n)\ntest_datgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.\/255,\n                                                              )\ntest_generator = test_datgen.flow_from_directory(\n    '..\/input\/waste-classification-data\/DATASET\/TEST',\n    target_size=(150, 150),\n    batch_size = 32,\n    class_mode='binary'\n    \n)","f89fc129":"history = model1.fit_generator(train_generator, epochs=10, validation_data=test_generator)","6ab0a087":"import matplotlib.pyplot as plt \nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","58ac811c":"# In this notebook, we are trying to classify the waste we have into Organic an Recyclable objects. The dataset we will work on is divided into train data (85%) and test data (15%). Training data - 22564 images and  Test data - 2513 images.","9f09477f":"In this notebook, we will have two model that we will compare there results.\nFor the comparison to be logic, we will use 50 epochs for each model even if the model does needed more epochs to converge."}}