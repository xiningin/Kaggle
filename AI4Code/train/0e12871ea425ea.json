{"cell_type":{"4032b150":"code","32efe215":"code","c8d739c1":"code","3a58e2ed":"code","7e7c8d95":"code","794d54e4":"code","f4b64e1e":"code","c8f6a8eb":"code","9a075c44":"code","85312c91":"code","4da8b191":"code","6fc739a6":"code","8259be0c":"code","6bce5b3d":"code","cd655364":"code","d142fcc5":"code","3c4899ec":"code","9354cffb":"code","3b82f79c":"code","691fe572":"code","f6c489ac":"code","150f616c":"code","2e170ccf":"code","9ac2f11b":"code","51c470a3":"code","b5f4c2d3":"code","b8489d74":"code","90763f37":"markdown","0872eec0":"markdown","56c5a996":"markdown","1f99a68b":"markdown","dc7e0221":"markdown","d2270038":"markdown","1ee8205d":"markdown","6f4b32d7":"markdown","148cd926":"markdown","de384944":"markdown","049bcc58":"markdown","d44f4e69":"markdown","c4c42aeb":"markdown"},"source":{"4032b150":"import cuml\nprint('RAPIDS version',cuml.__version__)","32efe215":"import sys\nsys.path.append('..\/input\/efficientnet-keras-dataset\/efficientnet_kaggle')\nfrom efficientnet.tfkeras import *","c8d739c1":"from matplotlib import pyplot as plt\nimport math, os, cv2, gc, re\nimport numpy as np, pandas as pd\nfrom time import time\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import KFold\nimport gc\nfrom operator import itemgetter\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K","3a58e2ed":"DEVICE = 'GPU'\n\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","7e7c8d95":"#basic\nEFFNET = 0\nSEED = 34       \nIMAGE_SIZE = [256, 256]               \nBATCH_SIZE = 16\nFOLDS = 5\nVERBOSE = 1\nTRANSFORM = False\nFIRST_FOLD_ONLY = True\n\n#for KNN training\nFINE_TUNE = True\nFT_EPOCHS = 2\nN_NEIGH = 50\n\n#for t-sne\nPERPLEXITY = 5\n\n#for kmeans\nN_CLUSTERS = 5","794d54e4":"def efficientnet(b, image_size, head=False, LR=5e-4):\n    efns = [EfficientNetB0, EfficientNetB1, EfficientNetB2,\n            EfficientNetB3, EfficientNetB4, EfficientNetB5,\n            EfficientNetB6]\n    with strategy.scope():\n        efficient = efns[b](\n            input_shape=(image_size[0]*3, image_size[1], 3),\n            weights='noisy-student', #imagenet\n            include_top=False\n        )\n        efficient.trainable=True\n        if head:\n            model = tf.keras.Sequential([\n                efficient,\n                tf.keras.layers.GlobalAveragePooling2D(name='pooling'), \n                tf.keras.layers.Dropout(.2), \n                tf.keras.layers.Dense(1, activation='sigmoid')\n            ])\n        else:\n            model = tf.keras.Sequential([\n                efficient,\n                tf.keras.layers.GlobalAveragePooling2D()])          \n    if head: model.compile(optimizer=tf.keras.optimizers.Adam(LR), \n                           loss=tf.keras.losses.BinaryCrossentropy() ,\n                           metrics=['AUC'])\n    return model\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/train\/{}\/{}.npy\".format(image_id[0], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/test\/{}\/{}.npy\".format(image_id[0], image_id)\n\ndef count_data_items(fileids):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) \n         for fileid in fileids]\n    return np.sum(n)\n\ndef max_val(l, i):\n    return max(enumerate(sub[i] for sub in l), key=itemgetter(1))","f4b64e1e":"def read_labeled_tfrecord(example, return_image_ids):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                   : tf.io.FixedLenFeature([], tf.string),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    if return_image_ids:\n        return example['image'], example['target'], example['image_id']\n    else:\n        return example['image'], example['target']\n\n\ndef read_unlabeled_tfrecord(example, return_image_ids):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                   : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    if return_image_ids:\n        return example['image'], example['image_id']\n    else:\n        return example['image']\n\n\ndef prepare_image(img, augment=True, dim=IMAGE_SIZE):    \n    img = tf.image.decode_png(img, channels=3)\n    \n    # converting channel information to spatial information\n    img = tf.concat([img[...,idx] for idx in range(3)], axis=0)\n    img = tf.stack([img for _ in range(3)], axis=-1)\n    img = tf.reshape(img, [dim[0]*3,dim[1], 3])\n    \n    img = tf.cast(img, tf.float32) \/ 255.0\n    \n    if augment:\n        img = transform(img,DIM=dim) if TRANSFORM else img\n        img = tf.image.random_flip_left_right(img)\n        #img = tf.image.random_hue(img, 0.01)\n        img = tf.image.random_saturation(img, sat[0], sat[1])\n        img = tf.image.random_contrast(img, cont[0], cont[1])\n        img = tf.image.random_brightness(img, bri)      \n                      \n    img = tf.reshape(img, [dim[0]*3,dim[1], 3])\n            \n    return img","c8f6a8eb":"def get_dataset(files, augment=False, shuffle=False, repeat=False, \n                labeled=True, return_image_ids=True, batch_size=BATCH_SIZE, dim=IMAGE_SIZE):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(lambda example: read_labeled_tfrecord(example, return_image_ids), \n                    num_parallel_calls=AUTO) \n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), \n                    num_parallel_calls=AUTO)      \n    \n    try:\n        ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n                                                   imgname_or_label), num_parallel_calls=AUTO)\n    except:\n        try:\n            ds = ds.map(lambda img, label, img_id: (prepare_image(img, augment=augment, dim=dim), \n                                                label, img_id), num_parallel_calls=AUTO)\n        except:\n            ds = ds.map(lambda img: prepare_image(img, augment=augment, dim=dim), \n                                                num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    return ds","9a075c44":"FILENAMES =  tf.io.gfile.glob(f'..\/input\/setibl-{IMAGE_SIZE[0]}x{IMAGE_SIZE[0]}-tfrec-dataset' + '\/*.tfrec')\nTRAINING_FILENAMES = [file for file in FILENAMES if 'train' in file]\nTEST_FILENAMES = [file for file in FILENAMES if 'test' in file]","85312c91":"test_ds = get_dataset(TEST_FILENAMES, labeled=False, return_image_ids=False, repeat=False, shuffle=False)\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\npreds_all = []\npreds_model = []\noof_pred = []\noof_labels = []\n\nfor f, (train_index, val_index) in enumerate(skf.split(TRAINING_FILENAMES)):\n    \n    print('#'*30); print('#### FOLD',f+1); print('#'*30); print('')\n    print('Getting datasets...'); print('')\n    \n    train_ds = get_dataset(list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[train_index]['TRAINING_FILENAMES']),\n                                            labeled=True, return_image_ids=False, repeat=False, shuffle=False)\n    val_ds = get_dataset(list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[val_index]['TRAINING_FILENAMES']),\n                                            labeled=True, return_image_ids=False, repeat=False, shuffle=False)\n    train_labs = [target.numpy() for img, target in iter(train_ds.unbatch())]\n    val_labs = [target.numpy() for img, target in iter(val_ds.unbatch())]\n    \n    effnet_ = efficientnet(b=EFFNET, image_size=IMAGE_SIZE, head=FINE_TUNE)\n    \n    if FINE_TUNE:\n        train_ds_ = get_dataset(list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[train_index]['TRAINING_FILENAMES']),\n                                            labeled=True, return_image_ids=False, repeat=True, shuffle=True)\n        \n        print('Fine tuning EfficientNet...'); print('')\n        ct_train = count_data_items(list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[train_index]['TRAINING_FILENAMES']))\n        effnet_.fit(train_ds_, \n                    validation_data=val_ds,\n                    verbose=1, \n                    steps_per_epoch=ct_train\/\/BATCH_SIZE,\n                    epochs=FT_EPOCHS)\n        print('')\n        effnet = tf.keras.Model(inputs=effnet_.input, \n               outputs=effnet_.get_layer('pooling').output)\n\n    else: effnet = effnet_\n\n    print('Getting embeddings...'); print('')\n    embed = effnet.predict(train_ds, verbose=1)\n    embed_val = effnet.predict(val_ds, verbose=1)\n    embed_test = effnet.predict(test_ds, verbose=1)\n    np.save(f'embed_{f}_{IMAGE_SIZE[0]}',embed.astype('float32'))\n    np.save(f'embed_val_{f}_{IMAGE_SIZE[0]}',embed_val.astype('float32'))\n    \n    print('Training KNN...'); print('')\n    model = cuml.neighbors.KNeighborsClassifier(n_neighbors=N_NEIGH)\n    model.fit(embed, np.array(train_labs).astype('float32'))\n    val_preds = model.predict_proba(embed_val)[:, 1]\n    score = roc_auc_score(np.array(val_labs), val_preds)\n    print(''); print(f'Fold {f} AUC: {score}'); print('')\n    \n    preds = model.predict_proba(embed_test)\n    preds_model.append(preds) \n    \n    del effnet_, train_ds, val_ds, embed_test, model; z = gc.collect()\n    \n    if FIRST_FOLD_ONLY:\n        break\n    \npreds_avg = np.stack(preds_model).mean(0)\npreds_all.append(preds_avg)\npreds_all = np.stack(preds_all)","4da8b191":"res = []\nfor k in range(8, 100, 2):\n    model_tt = cuml.neighbors.KNeighborsClassifier(n_neighbors=k)\n    model_tt.fit(embed, np.array(train_labs).astype('float32'))\n    val_preds = model_tt.predict_proba(embed_val)[:, 1]\n    score = roc_auc_score(np.array(val_labs), val_preds)\n    res.append([k, score])\nbest_k, best_score = max_val(res, 1)\nprint(f\"Fold {f} optimized K value: {best_k} with AUC: {best_score}\")","6fc739a6":"train_dummy = get_dataset(TRAINING_FILENAMES, labeled=True,\n                         return_image_ids=True, repeat=False, \n                         shuffle=False)\nnames = np.array([img_name.numpy().decode(\"utf-8\") for img, label, img_name in iter(train_dummy.unbatch())])\nlabels = np.array([label.numpy() for img, label, img_name in iter(train_dummy.unbatch())])","8259be0c":"fresh_effnet = efficientnet(b=EFFNET, image_size=IMAGE_SIZE, head=False)\ntrain_full = get_dataset(TRAINING_FILENAMES, labeled=True,\n                       return_image_ids=False, repeat=False, \n                       shuffle=False)\nembed_full = fresh_effnet.predict(train_full, verbose=1)\nembed_full_tuned = effnet.predict(train_full, verbose=1)","6bce5b3d":"train = pd.DataFrame()\ntrain['image_id'] = names\ntrain['label'] = labels\ntrain['image_id'] = train['image_id'].apply(get_train_file_path)","cd655364":"model = cuml.KMeans(n_clusters=N_CLUSTERS)\nmodel_ = cuml.KMeans(n_clusters=N_CLUSTERS)\nmodel.fit(embed_full)\nmodel_.fit(embed_full_tuned)\ntrain['cluster'] = model.labels_\ntrain['cluster_tuned'] = model_.labels_\ntrain.head()","d142fcc5":"del effnet, fresh_effnet, model, model_; z = gc.collect()","3c4899ec":"names_ = np.array([f\"..\/input\/seti-breakthrough-listen\/train\/{name[0]}\/{name}.npy\" for name in names])\nfor k in range(N_CLUSTERS):\n    print('#'*25);\n    print(f'#### Cluster {k} of similar train images')\n    print('#'*25)\n    df = train.loc[train.cluster==k]\n    plt.figure(figsize=(20,10))\n    for j in range(8):\n        plt.subplot(2,4,j+1)\n        image = np.load(names_[df.index[j]])\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        image = cv2.resize(image, (256, 256))\n        plt.axis('off')\n        plt.title(f\"{names[df.index[j]]}, Target = {df.loc[df.index[j],'label']}\")\n        plt.imshow(image)  \n    plt.show()","9354cffb":"for k in range(N_CLUSTERS):\n    print('#'*25);\n    print(f'#### Cluster {k} of similar train images')\n    print('#'*25)\n    df = train.loc[train.cluster_tuned==k]\n    plt.figure(figsize=(20,10))\n    for j in range(8):\n        plt.subplot(2,4,j+1)\n        image = np.load(names_[df.index[j]])\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        image = cv2.resize(image, (256, 256))\n        plt.axis('off')\n        plt.title(f\"{names[df.index[j]]}, Target = {df.loc[df.index[j],'label']}\")\n        plt.imshow(image)  \n    plt.show()","3b82f79c":"model = cuml.TSNE(perplexity=PERPLEXITY, n_iter=500)\nembed2D = model.fit_transform(embed_full)\ntrain['x'] = embed2D[:,0]\ntrain['y'] = embed2D[:,1]","691fe572":"model_ = cuml.TSNE(perplexity=PERPLEXITY, n_iter=500)\nembed2D_ = model_.fit_transform(embed_full_tuned)\ntrain['x_tuned'] = embed2D_[:,0]\ntrain['y_tuned'] = embed2D_[:,1]","f6c489ac":"del model, model_; z = gc.collect()","150f616c":"plt.figure(figsize=(10,10))\ndf1 = train.loc[train.label==0]\ndf2 = train.loc[train.label==1]\n\nplt.scatter(df1.x,df1.y,c='blue',s=10,label='0')\nplt.scatter(df2.x,df2.y,c='red',s=10,label='1')\nplt.legend();","2e170ccf":"plt.figure(figsize=(10,10))\n\nplt.scatter(df1.x_tuned,df1.y_tuned,c='blue',s=10,label='0')\nplt.scatter(df2.x_tuned,df2.y_tuned,c='red',s=10,label='1')\nplt.legend();","9ac2f11b":"test_dummy = get_dataset(TEST_FILENAMES, labeled=False, return_image_ids=True, repeat=False, shuffle=False)\ntest_ids = np.array([img_id.numpy().decode(\"utf-8\") \n                        for img, img_id in iter(test_dummy.unbatch())])","51c470a3":"submission = pd.DataFrame({'id':test_ids})","b5f4c2d3":"submission[\"target\"] = preds_all[:, :, 1].mean(0)\n#submission = submission.sort_values('id') \nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","b8489d74":"plt.hist(submission.target);","90763f37":"# Submission","0872eec0":"# RAPIDS cuML KMeans","56c5a996":"# Data Loading","1f99a68b":"# RAPIDS cuML T-SNE","dc7e0221":"# Helper Functions","d2270038":"### With ImageNet Weights","1ee8205d":"### After Fine Tuning","6f4b32d7":"# RAPIDS cuML kNN","148cd926":"# SETI RAPIDS kNN\n\nIn this notebook, we will extract image embeddings with a CNN and use them to train a `RAPIDS` KNN model. I first saw this technique done in [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte)'s notebook [here](https:\/\/www.kaggle.com\/cdeotte\/rapids-cuml-knn-find-duplicates) from the Melanoma competition; I encourage you to check it out.\n\nNote that I am using [@awsaf49](https:\/\/www.kaggle.com\/awsaf49)'s TFRecord datasets that can be found [here](https:\/\/www.kaggle.com\/awsaf49\/setibl-256x256-tfrec-dataset). ","de384944":"# Dataset Functions","049bcc58":"### With ImageNet Weights","d44f4e69":"### After Fine Tuning","c4c42aeb":"# CFG"}}