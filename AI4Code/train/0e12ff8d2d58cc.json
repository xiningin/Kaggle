{"cell_type":{"e6d8dd75":"code","7df5ce78":"code","209d0b20":"code","aaa02fe7":"code","0a7ca60e":"code","f685ce67":"code","41657552":"code","f2291c0e":"code","25afa0e0":"markdown","c2a2b0b5":"markdown","1fe03eb6":"markdown","9e251f0f":"markdown","9c6e3366":"markdown","ddb8f530":"markdown","ae90eff5":"markdown","e6a6606e":"markdown"},"source":{"e6d8dd75":"# Packge Imports\nimport tensorflow as tf\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics, utils\nfrom PIL import Image\nimport os\n\n\n%matplotlib inline\n\n\n# create a base path\nBASE_PATH = \"..\/input\/gtsrb-german-traffic-sign\/\"        \n\n# read the Training.csv and Test.csv files into dataframes\ntraining_dataframe = pd.read_csv(BASE_PATH + 'Train.csv')\ntest_dataframe = pd.read_csv(BASE_PATH + 'Test.csv')\n\ntraining_dataframe.head() # show the head of the training dataframe\n","7df5ce78":"NUM_CLASSES = training_dataframe['ClassId'].nunique() # Calculate the number of unique classes\nTRAIN_LEN = training_dataframe['ClassId'].count()\nprint(\"Number of Classes: \", NUM_CLASSES) # debug print, dataset contains 43 classes\n\n\n# lets look at some random images\nsample = plt.subplots(5,5, figsize=(15,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1) # Plot A Random Image\n    plt.imshow(plt.imread(BASE_PATH+training_dataframe[\"Path\"][np.random.randint(TRAIN_LEN)]))\n\nplt.show()","209d0b20":"CLASS_NAMES = { 0:'Speed limit (20km\/h)', 1:'Speed limit (30km\/h)', 2:'Speed limit (50km\/h)', \n            3:'Speed limit (60km\/h)', 4:'Speed limit (70km\/h)', 5:'Speed limit (80km\/h)', \n            6:'End of speed limit (80km\/h)', 7:'Speed limit (100km\/h)', 8:'Speed limit (120km\/h)', 9:'No passing', \n            10:'No passing veh over 3.5 tons', 11:'Right-of-way at intersection', 12:'Priority road', 13:'Yield', \n            14:'Stop', 15:'No vehicles', 16:'Veh > 3.5 tons prohibited', 17:'No entry', \n            18:'General caution', 19:'Dangerous curve left', 20:'Dangerous curve right', \n            21:'Double curve', 22:'Bumpy road', 23:'Slippery road', 24:'Road narrows on the right', \n            25:'Road work', 26:'Traffic signals', 27:'Pedestrians', 28:'Children crossing', \n            29:'Bicycles crossing', 30:'Beware of ice\/snow', 31:'Wild animals crossing', \n            32:'End speed + passing limits', 33:'Turn right ahead', 34:'Turn left ahead', \n            35:'Ahead only', 36:'Go straight or right', 37:'Go straight or left', 38:'Keep right', \n            39:'Keep left', 40:'Roundabout mandatory', 41:'End of no passing', 42:'End no passing veh > 3.5 tons'}\n\ntraining_dataframe['ClassId']=training_dataframe['ClassId'].astype('str') # converting class type to string\n\ntraining_dataframe = pd.concat([training_dataframe['Path'], training_dataframe['ClassId']], axis = 1) # simplify the dataframe by removing ROI and H\/W information.\ntraining_dataframe = utils.shuffle(training_dataframe) # Shuffling the dataframe \ntraining_dataframe.head() # check to ensure dataframe has been shuffled.","aaa02fe7":"# Define hyperparameters for the generators\nBATCH_SIZE = 128\nIMG_SIZE = (32, 32) # Fixing the image size is a required for our Neural Network. This size may be adjusted as needed.\n\n# Create the training and validation generators\nimage_gen =  tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range = 10,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    shear_range = 0.15,\n    zoom_range = 0.15,\n    rescale = 1\/255.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    validation_split= 0.2,\n    fill_mode = 'nearest')\n\n# Training Generator\ntrain_gen = image_gen.flow_from_dataframe(\n    training_dataframe,\n    directory=BASE_PATH,\n    x_col='Path',\n    y_col='ClassId',\n    target_size=IMG_SIZE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    subset=\"training\",\n)\n\n\n# Validation Generator\nval_gen = image_gen.flow_from_dataframe(\n    training_dataframe,\n    directory=BASE_PATH,\n    x_col=\"Path\",\n    y_col='ClassId',\n    target_size=IMG_SIZE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    subset=\"validation\",\n)\n\n# Test Training Generator with a sample\ngen = next(train_gen)\nprint(gen[0].shape) # Confirm BATCH_SIZE, and IMG_SIZE\nplt.imshow(gen[0][0,:,:,:]) # show sample image","0a7ca60e":"# Hyperparameters for the Neural Networks\nKERNEL_SIZE = (3,3)\nPOOL_SIZE = (2,2)\nFILTERS = 16\ndropout = 0.25\nEPOCHS = 15\nimg_shape = (32,32, 3) # Defined above in the generator section. \n\n\n\nclassifier = tf.keras.models.Sequential([    \n    tf.keras.layers.Conv2D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation='relu', input_shape=img_shape),\n    tf.keras.layers.Conv2D(filters=FILTERS*2, kernel_size=KERNEL_SIZE, activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=POOL_SIZE),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    \n    tf.keras.layers.Conv2D(filters=FILTERS*4, kernel_size=KERNEL_SIZE, activation='relu'),\n    tf.keras.layers.Conv2D(filters=FILTERS*8, kernel_size=KERNEL_SIZE, activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=POOL_SIZE),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(dropout),\n    \n    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n])\n\n\n# Plot the classifier model to a .png file \ntf.keras.utils.plot_model (classifier, to_file = 'classifier_structure.png', \n                           show_shapes = True)\n\n# Compile the model using adam optimizer.\nclassifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n            metrics = ['accuracy'])\n\n# Print a summary of the model for quick observation\nprint(classifier.summary())","f685ce67":"history = classifier.fit(x = train_gen, \n               epochs = EPOCHS, \n               validation_data = val_gen, \n               verbose = True)\n\nclassifier.save(\"GTSRB_CNN_Model.h5\")","41657552":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\nplt.show()","f2291c0e":"test_dataframe['ClassId'] = test_dataframe['ClassId'].astype('str')\n\n# Test Generator\ntest_gen = image_gen.flow_from_dataframe(\n    test_dataframe,\n    directory=BASE_PATH,\n    x_col='Path',\n    y_col='ClassId',\n    target_size=IMG_SIZE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n)\n\n# Evaluate the classifier with data from our test generator\nclassifier.evaluate(test_gen)\n","25afa0e0":"We will now build our image generators. We will start by defining a few generator hyperparameters (batch size and image shape) before creating a TensorFlow Image Data Generator (image_gen). We will use image_gen to create a training generator and validation generator, which allows for real time augmentation of training data as used. More information about the ImageDataGenerator can be found in [TensorFlow's API Documentation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator)","c2a2b0b5":"With the generators in place, we are ready to design our Convolutional Neural Network (CNN) classifier. Typically, I like to use the TensorFlow Functional API to build neural networks as it allows flexibility in design, but for this notebook, I will use the Sequential Model. Additional information about the Functional API and Sequential Model can be found here:\n\n[Functional API](https:\/\/www.tensorflow.org\/guide\/keras\/functional) & \n[Sequential Model](https:\/\/www.tensorflow.org\/guide\/keras\/sequential_model)","1fe03eb6":"Next, we will get the number of classes using the Pandas nunique function and store that into the num_classes variable. This will be used later when we build the neural network and are defining the softmax layer. We will also randomly sample a few images to get a feel for what the data looks like.","9e251f0f":"Now that the model has been built, we can go ahead and train it using our generators. As an FYI, the model has been plotted and saved to the file 'classifier_structure.png'.","9c6e3366":"These are pretty good results for a relatively simple CNN. Somewhere in the mid-to-upper 90% accuracy on the validation set is a great starting point. Now, we will want to test model on the official test data. As before, we will use our image_gen generator to build a sample to test with. ","ddb8f530":"First, we will import the needed packages such as Tensorflow, NumPy, Pandas, Seaborn, etc. We will also create a path variable, and the Pandas dataframes for both training and testing. We will create a BASE_PATH to help with keeping track of the data file structure. This notebook takes advantage of the GTSRB dataset posted to Kaggle. For more information about the original dataset, please see the [INI GTSRB webpage.](https:\/\/benchmark.ini.rub.de\/gtsrb_dataset.html)","ae90eff5":"Based on the generated test run, our classifier achieves about 95% accuraucy on the test data. This is pretty good performance, but certainly isn't state of the art compared to some of the published models (links available on the INI website, above). If I were going to further tweak\/tune this model, I would start with modifying the hyperparameters for both the CNN and the generators. Since this is a single pass notebook (with only hand tuning of the results to get something reasonable), I will wrap it up for now. Thank you for taking the time to read through this notebook, I hope that you've found it interesting and\/or helpful.","e6a6606e":"There are 43 classes of images. After searching online for some time, I was able to find a couple of notebooks that had the class names, which will be added in the next section. In addition to adding the class names, we find that the randomly sampled images are of a different shape\/size. This means that we will want to find an appropraite size for our flow_from_dataframe generator, which will be defined in a later section.\n\nIn this next block, in addition to creating a class names dictionary, we will reduce the training_dataframe to the image path and the class id, and will convert the class id to a string type. Based on the organization of the dataset, we will need to shuffle the dataframe to ensure training is more effective."}}