{"cell_type":{"a2a25fa7":"code","2a1ddfef":"code","4aa55784":"code","644257c3":"code","eb9a5945":"code","01187115":"code","baee4568":"code","74d985e7":"code","b8cdec6b":"code","8067f5fb":"code","9579d752":"code","d980532d":"code","57405dea":"code","6e9db116":"code","b590de19":"markdown","635b3f77":"markdown","07c972fe":"markdown","8944ba2e":"markdown","133e5c1f":"markdown","3fabd904":"markdown","774b2fab":"markdown","e480b4bd":"markdown"},"source":{"a2a25fa7":"!pip install fastai --upgrade >\/dev\/null","2a1ddfef":"# order of importing the fastai libraries matters here, possibly due to a namespace conflict\nfrom fastai.medical.imaging import *\nfrom fastai.basics import *\n\nimport glob","4aa55784":"path = Path('..\/input\/rsna-str-pulmonary-embolism-detection')","644257c3":"!ls {path}","eb9a5945":"path_trn = path\/'train'\ndirs_trn = path_trn.ls()\ndirs_trn[:5].attrgot('name')","01187115":"path_tst = path\/'test'\ndirs_tst = path_tst.ls()\nprint(f'Number of training studies: {len(dirs_trn)}')\nprint(f'Number of test studies: {len(dirs_tst)}')","baee4568":"fns_trn = L(glob.glob(f'{path_trn}\/**\/*.dcm', recursive=True))\nfns_trn = fns_trn.map(Path)\nprint(len(fns_trn))\nfns_trn[:5]","74d985e7":"import gc, os\ndel(fns_trn)\ngc.collect();","b8cdec6b":"fns_trn = L()\nfor r, d, f in os.walk(path_trn):\n    if f:\n        fn = Path(f'{r}\/{f[0]}')\n        fns_trn.append(fn)\nprint(len(fns_trn))\nfns_trn[:5]","8067f5fb":"fn = fns_trn[0]\ndcm = fn.dcmread()\ndcm","9579d752":"df_trn = pd.DataFrame.from_dicoms(fns_trn, px_summ=False)\ndf_trn.to_feather('df_trn.fth')\ndf_trn.head()","d980532d":"del(df_trn, fns_trn)\ngc.collect();","57405dea":"path_lbls = path\/'train.csv'\nlbls = pd.read_csv(path_lbls)\nprint(lbls.shape)\nlbls.drop_duplicates(['StudyInstanceUID', 'SOPInstanceUID'], inplace=True)\nprint(lbls.shape)\nlbls.head()","6e9db116":"lbls.to_feather('lbls.fth')","b590de19":"This notebook is the first in a series of notebooks which use the [fast.ai](https:\/\/fast.ai) Medical Imaging API built on top of Pytorch. It is modeled after [Jeremy Howard's notebooks](https:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection\/discussion\/114214) from the 2019 RSNA Intracranial Hemorrhage Detection Kaggle Challenge.\n\nFirst, we need to upgrade the `fastai` library to `version 2.0.x` and import the relevant libraries.","635b3f77":"# Creating a DataFrame of labels\nHere we'll extract the labels from `train.csv` and save them in `feather` format for future use.","07c972fe":"# Exploring the file tree\nWe know from the data overview that the data are split into `train` and _public_ `test` groups of 7,279 and 650 studies, respectively. Each study is organized in standard DICOM format with the top-level directory labeled with the `StudyInstanceUID` and the images organized under a `SeriesInstanceUID` sub-directory with each individual file labeled by the `SOPInstanceUID` in the following path format `<StudyInstanceUID>\/<SeriesInstanceUID>\/<SOPInstanceUID>.dcm`.","8944ba2e":"The [second notebook in the series](https:\/\/www.kaggle.com\/wfwiggins203\/exploring-the-dicom-metadata-images-with-fast-ai) explores the DICOM metadata a little further and looks at a sampling of the images. I try inject some extra domain knowledge from my day job as a radiologist.","133e5c1f":"We'll clean up here before proceeding.","3fabd904":"# Creating a DataFrame of DICOM metadata\nNow we'll proceed to extract the metadata from the DICOM files and put it into a `pandas.DataFrame`, which we'll save in `feather` format for later use.","774b2fab":"Since there are ~1.8 million images in the training dataset, it's impractical to extract metadata for every image...\n\nSo, we'll select one image from each study for inclusion in our DICOM metadata Data Frame.","e480b4bd":"Looks like the labels are in a nice, readable format, so we'll save them in `feather` format."}}