{"cell_type":{"8167a756":"code","a3455911":"code","d5fae3b5":"code","d2a10a4b":"code","beae4f82":"code","328c9183":"code","1d8f76d2":"code","6f21af2c":"code","8cf5435c":"code","478fa8d2":"code","0129c1ae":"code","ee18807b":"code","2bb4f89d":"code","5f06f500":"code","c0b1c4bd":"code","33268f3e":"markdown","ad54d80c":"markdown","3955d47d":"markdown","810eb627":"markdown","c919b000":"markdown","a3d7eb6c":"markdown","38d61fb6":"markdown","5a907f8c":"markdown","caf6b552":"markdown","74f971fd":"markdown"},"source":{"8167a756":"import numpy as np\nimport glob\n\n\nfrom matplotlib import pyplot as plt\n\nimport keras\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split","a3455911":"PATH = '\/kaggle\/input\/pokemons\/pokemons\/imgs\/*'\n\nIMAGE_SIZE = (224, 224)\n\nX = [image.load_img(file, color_mode='rgb', target_size=IMAGE_SIZE, interpolation='nearest') for file in glob.glob(PATH)]\n\nprint(\"Number of pictures of pokemons: {}\".format(len(X)))","d5fae3b5":"X_array = [image.img_to_array(x_, data_format=None, dtype=None) for x_ in X]\nprint(\"Number of pictures: in X_array: {}, and shape of one of the pictures {}: \".format(len(X_array),X_array[7].shape))\n\nX_preprocessed =  [preprocess_input(x_) for x_ in X_array]\nprint(\"The shape of one of the new preprocessed pictures in X_preprocessed: {} \".format(X_preprocessed[7].shape))","d2a10a4b":"pokemons = ['bulbasaur', 'charmander', 'eevee', 'flareon', 'jolteon', 'pikachu', 'squirtle', 'vaporeon']\n\n# path is equal to ..\/input\/pokemons\/imgs\/imgs\/*\ny = [pokemons.index(x.split('\/')[6].split('_')[0].lower()) for x in glob.glob(PATH)]\ny_encoded = tf.keras.utils.to_categorical(y, 8)\nprint(\"The shape of encoded labels: {}, first three of them: \\n{}\".format(y_encoded.shape, y_encoded[:3]))","beae4f82":"X_pred_ndarray = np.array(X_preprocessed, dtype=np.float32)\nprint(\"The shape of images: {}, and type \\n{}\".format(X_pred_ndarray.shape, type(X_pred_ndarray)))","328c9183":"X_train, X_test, y_train, y_test = train_test_split(X_pred_ndarray, y_encoded, train_size=0.9, random_state=42)\nX_train.shape, y_train.shape","1d8f76d2":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nbase_vgg = VGG16(weights=\"imagenet\", include_top = False, input_shape=(224, 224, 3))\nbase_vgg.summary()","6f21af2c":"base_vgg.trainable = False\n\nbase_vgg.summary()","8cf5435c":"input_ = Input(shape=(224, 224, 3))\n\nconcat_ = base_vgg(input_, training=False)\n\nmaxpool_ = MaxPooling2D()(concat_)\n\nflatten_ = Flatten()(maxpool_)\n\ndense_1 = Dense(1024, activation='relu')(flatten_)\ndense_2 = Dense(1024, activation='relu')(dense_1)\n\noutput_ = Dense(8, activation='softmax', name = 'outupt_eight')(dense_2)\n\nmodel_vgg = Model(input_, output_)\nmodel_vgg.summary()","478fa8d2":"model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n\nhistory = model_vgg.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)","0129c1ae":"base_vgg.trainable = True\nfor layer in base_vgg.layers[0:16]:\n    layer.trainable =  False\n    \nbase_vgg.summary()","ee18807b":"model_vgg.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics='acc')\n\nmodel_vgg.summary()\n\nhistory = model_vgg.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)","2bb4f89d":"model_vgg.save_weights('model_vgg-pokemons_on_imgs_weights.hdf5')","5f06f500":"def train_loop():\n    keras.backend.clear_session()\n    tf.random.set_seed(42)\n    np.random.seed(42)\n\n    # 8. Build model\n    input_ = Input(shape=(224, 224, 3))\n\n    concat_ = base_vgg(input_, training=False)\n    maxpool_ = MaxPooling2D()(concat_)\n    flatten_ = Flatten()(maxpool_)\n    dense_1 = Dense(1024, activation='relu')(flatten_)\n    dense_2 = Dense(1024, activation='relu')(dense_1)\n    output_ = Dense(6, activation='softmax', name = 'output_six')(dense_2)\n\n    global model\n    model = Model(input_, output_)\n    model._name = 'train_loop_model'\n    \"\"\"\n    print(\"Model's summary BEFORE loading weights:\") \n    model.summary()\n    print(\"BASE Model's summary BEFORE loading weights:\")\n    base_vgg.summary()\n    \"\"\"\n    # 9. Load weights\n    print('LOADING WEIGHTS . . .')\n    model.load_weights('model_vgg-pokemons_on_imgs_weights.hdf5', by_name = True)\n\n    base_vgg.trainable = False\n    \"\"\"\n    print(\"Model's summary AFTER loading weights: \")\n    model.summary()\n    print(\"BASE Model's summary AFTER loading weights:\")\n    base_vgg.summary()\n    \"\"\"\n    \n    # 10. Build data generators\n    train_data_dir = '\/kaggle\/input\/pokemons\/pokemons\/data_labeled\/train'\n    val_data_dir = '\/kaggle\/input\/pokemons\/pokemons\/data_labeled\/val'\n\n    train_datagen = image.ImageDataGenerator()\n    val_datagen = image.ImageDataGenerator()\n\n    train_generator = train_datagen.flow_from_directory(\n        directory = train_data_dir,\n        target_size=(224, 224),\n        batch_size=16)\n\n    validation_generator = val_datagen.flow_from_directory(\n        directory = val_data_dir,\n        target_size=(224, 224),\n        batch_size=16)\n    print(validation_generator.class_indices)\n    # 11. Fit the model to the data for a few epochs\n    model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics='acc')\n    \n    model.fit_generator(train_generator, validation_data=validation_generator, epochs = 10)","c0b1c4bd":"train_loop()","33268f3e":"### I'm going to perform two model trainings:\n\n\n\n**Training 1:**\n\n  * Initialize the model with the imagenet weights\n  * Freeze all convolution layers\n  * Train the model:\n  \n**Training 2:**\n  * Unfreeze the last two convolutional Blocks\n  * Continue training :","ad54d80c":"Splitting data into test\/val sets\n\nAs I understand I must ensure the input data to the model as numpay.ndarray","3955d47d":"### Loading data for pretraining and applying preprocessing","810eb627":"Freezing weights of the base model","c919b000":"# Building a very basic tensorflow model\n### Overview of the content:\n\n  * Load & preprocess the data from imgs-folder\n  * Load VGG16 model, extend it and pretrain\n  * Train the model on the new data using ImagaDataGenerator","a3d7eb6c":"### All needed imports","38d61fb6":"Unfreezing base-model's few weights and perform training step 2\n\nBase model has 19 layers. The last one in it is MaxPooling and two before MaxPooling are Conv2d - exactly what we must set to trainable","5a907f8c":"Now that I have my initial model I am going to extend it with some more pokemons from *data_labeled* folder, where there ared roughly 6000 images of the following pokemons:\n\n* Blastoise\n* Charizard\n* Charmeleon\n* Ivysaur\n* Venusaur\n* Wartortle\n\nThe folder structure to create our labels and train \/ validation partitions. Inside the folder you will therefore find a 'train' and an 'val' folder, each of them containing subfolders for each class. To then take full advantage of the current way the data is structured, I will use keras data generators in combination with the flow_from_directory to dynamically read the input data and feed it to our model.\n\nFunction train_loop()  creates two data generators (one for training and one for validation) and trains a model for the new Images on features extracted from our current model. To this end you can simply rebuild the structure of the original model, but replace the number of output classes.","caf6b552":"Extending VGG for my own need","74f971fd":"Y values"}}