{"cell_type":{"e7a5dc17":"code","5e18dae5":"code","26b33ed9":"code","bce9155a":"code","0aa93968":"code","c257435d":"code","3cced27e":"code","0c959eba":"code","23af2f58":"code","cab5f82d":"code","9c893d2d":"code","37e3747c":"code","f2e348fb":"code","67abacbe":"code","9e763469":"code","7e01f357":"code","67b196f9":"markdown","8de4f853":"markdown","9d53bcdc":"markdown","c5a3fd66":"markdown","55fb9108":"markdown","180cda23":"markdown","b41f2989":"markdown","c60a9074":"markdown","c7b5eef1":"markdown"},"source":{"e7a5dc17":"import os\nos.mkdir(\".\/working\")\nos.environ['USER'] = 'root'\nos.system('pip install ..\/input\/xlearn\/xlearn\/xlearn-0.40a1\/')\n\nimport xlearn as xl","5e18dae5":"import numpy as np\nimport pandas as pd\nimport scipy\nimport gc,os\nfrom collections import Counter\nfrom sklearn.model_selection import KFold,StratifiedKFold,RepeatedKFold,RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score as auc\nfrom sklearn.linear_model import LogisticRegression\nimport category_encoders as ce\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = 50\nBIN_COL  = [f'bin_{i}' for i in range(5)]\nNOM_COL  = [f'nom_{i}' for i in range(10)]\nORD_COL  = [f'ord_{i}' for i in range(6)]\nNOM_5_9  = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nNOM_0_4  = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\nDATE_COL = ['day','month']\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('\/kaggle\/working\/libffm-binaries'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","26b33ed9":"%%time\n\ndef read_csv():\n    train = pd.read_csv('..\/input\/cat-in-the-dat-ii\/train.csv')\n    test  = pd.read_csv('..\/input\/cat-in-the-dat-ii\/test.csv')\n\n    train_id = train['id']\n    test_id  = test['id']\n    train.drop('id', axis=1, inplace=True)\n    test.drop('id',  axis=1, inplace=True)\n    return train, test, train_id, test_id\n\ntrain, test, train_id, test_id = read_csv()\ndef preprocessing(df):\n    \n    df['bin_missing']  = (df[['bin_0', 'bin_1', 'bin_2', 'bin_4']].isnull().sum(axis=1)>0).replace({True:1, False:0})\n    df['nom_missing']  = (df[NOM_COL].isnull().sum(axis=1)>0).replace({True:1, False:0})\n    df['ord_missing']  = (df[ORD_COL].isnull().sum(axis=1)>0).replace({True:1, False:0})\n    df['date_missing'] = (df[DATE_COL].isnull().sum(axis=1)>0).replace({True:1, False:0})\n    \n    df.day = df.day.replace({3:5,2:6,1:7})\n    df.loc[df.ord_5.notnull(), 'ord_5_1'] = df.loc[df.ord_5.notnull(), 'ord_5'].apply(lambda x: x[0])\n    df.loc[df.ord_5.notnull(), 'ord_5_2'] = df.loc[df.ord_5.notnull(), 'ord_5'].apply(lambda x: x[1])\n    \n    return df\n\ntrain, test, train_id, test_id = read_csv()\ntrain = preprocessing(train)\ntest  = preprocessing(test)\nprint(f'train day unique value:{train.day.unique()}')\nprint(f'test  day unique value:{test.day.unique()}')\n\nfor col in test.columns:\n    if len(set(train[col].dropna().unique().tolist())^ set(test[col].dropna().unique().tolist()))>0:\n        train_only = list(set(train[col].dropna().unique().tolist()) - set(test[col].dropna().unique().tolist()))\n        test_only  = list(set(test[col].dropna().unique().tolist()) - set(train[col].dropna().unique().tolist()))\n        print(col, '(train only)', train_only, '(test only)', test_only) \n        train.loc[train[col].isin(train_only), col] = np.NaN\n        test.loc[test[col].isin(test_only), col]    = np.NaN  \n\ntest.insert(1, 'target', 0)\n\ndrop_cols = ['bin_3', 'ord_5']\ntrain.drop(columns=drop_cols, inplace=True)\ntest.drop(columns=drop_cols,  inplace=True)","bce9155a":"%%time\n\n# Label Encode to ease creation of libffm format\n\nfeatures = [_f for _f in train if _f not in ['id', 'target']]\n\ndef factor_encoding(train, test):\n    \n    assert sorted(train.columns) == sorted(test.columns)\n    \n    full = pd.concat([train, test], axis=0, sort=False)\n    # Factorize everything\n    for f in full:\n        full[f], _ = pd.factorize(full[f])\n        full[f] += 1  # make sure no negative\n        \n    return full.iloc[:len(train)], full.iloc[len(train):]\n\ntrain_f, test_f = factor_encoding(train[features], test[features])\n\nprint(train_f,'-'*20)\nprint(train_f.head(10))\n\nprint(test_f,'-'*20)\nprint(test_f.head(10))\n\nclass LibFFMEncoder(object):\n    def __init__(self):\n        self.encoder = 1\n        self.encoding = {}\n\n    def encode_for_libffm(self, row):\n        txt = f\"{row[0]}\"\n        for i, r in enumerate(row[1:]):\n            \n#             try:\n#                 txt += f' {i+1}:{self.encoding[r]}:1'\n#             except KeyError:\n#                 self.encoding[r] = self.encoder\n#                 self.encoder += 1\n#                 txt += f' {i+1}:{self.encoding[r]}:1'\n            try:\n#                 print(f'key {i} {r}')\n                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n            except KeyError:\n#                 print(f'key error {i} {r}')\n                self.encoding[(i, r)] = self.encoder\n                self.encoder += 1\n                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n                \n        return txt\n\n\nSPLITS = 5\n    \n# Create files for testing and OOF\nfrom sklearn.model_selection import KFold\nfold_ids = [\n    [trn_, val_] for (trn_, val_) in KFold(SPLITS,True,1).split(train)\n]\nfor fold_, (trn_, val_) in enumerate(fold_ids):\n    encoder = LibFFMEncoder()\n    libffm_format_trn = pd.concat([train['target'].iloc[trn_], train_f.iloc[trn_]], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n    )\n    libffm_format_val = pd.concat([train['target'].iloc[val_], train_f.iloc[val_]], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n    )\n    print(train['target'].iloc[trn_].shape, train['target'].iloc[val_].shape, libffm_format_val.shape)\n    \n    libffm_format_trn.to_csv(f'libffm_trn_fold_{fold_+1}.txt', index=False, header=False)\n    libffm_format_val.to_csv(f'libffm_val_fold_{fold_+1}.txt', index=False, header=False)\n    \n# Create files for final model\nencoder = LibFFMEncoder()\nlibffm_format_trn = pd.concat([train['target'], train_f], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n)\nlibffm_format_tst = pd.concat([test['target'], test_f], axis=1).apply(\n    lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n)\n\nlibffm_format_trn.to_csv(f'libffm_trn.txt', index=False, header=False)\nlibffm_format_tst.to_csv(f'libffm_tst.txt', index=False, header=False)","0aa93968":"%%time\n\n# create ffm model\nffm_model = xl.create_ffm() \n\n# import optuna\nfrom sklearn.metrics import log_loss, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\noutputs = []\n\n# define params\nparam = {'task':'binary', \n         'lr':0.2, \n         'k':4,\n         'lambda':0.0002, \n         'metric':'auc',\n         'epoch': 15\n        }\n        \nfor fold_ in range(1, SPLITS+1):\n    print(f'fold: {fold_}')\n    model = f\"libffm_fold_{fold_}_model\"\n    trn_fold_txt = f\"libffm_trn_fold_{fold_}.txt\"\n    val_fold_txt = f\"libffm_val_fold_{fold_}.txt\"\n    val_preds_fold_txt = f\"val_preds_fold_{fold_}.txt\"    \n\n    # set training and validation data\n    ffm_model.setTrain(trn_fold_txt)\n    \n    #xLearn will perform early-stopping by default.     \n    ffm_model.setValidate(val_fold_txt)   \n    \n    print(' fitting...')\n    ffm_model.fit(param, 'model.output')\n\n    print(' make predictions...')\n    ffm_model.setTest(val_fold_txt)\n    ffm_model.setSigmoid()\n    ffm_model.predict(\"model.output\", val_preds_fold_txt)\n    gc.collect()\n    \n    print(' auc score:',\n        roc_auc_score(\n            train['target'].iloc[fold_ids[fold_-1][1]], \n            pd.read_csv(val_preds_fold_txt, header=None).values[:,0]))   \n","c257435d":"gc.collect()","3cced27e":"oof_preds = np.zeros(train.shape[0])\nfor fold_, (_, val_) in enumerate(fold_ids):\n    oof_preds[val_] = pd.read_csv(f'val_preds_fold_{fold_+1}.txt', header=None).values[:, 0]\nprint(roc_auc_score(train['target'], oof_preds))","0c959eba":"sns.distplot(pd.Series(oof_preds))","23af2f58":"%%time\n\n# # define params\n# param = {'task':'binary', \n#          'lr':0.2, \n#          'k':4,\n#          'lambda':0.0002, \n#          'metric':'auc',\n#          'epoch': 15,\n#         }\n\nffm_model = xl.create_ffm() \nffm_model.setTrain(\"libffm_trn.txt\")\nffm_model.fit(param, 'model.output')","cab5f82d":"%%time\n\nffm_model.setTest('libffm_tst.txt')\nffm_model.setSigmoid()\nffm_model.predict('model.output', 'tst_preds.txt')","9c893d2d":"gc.collect()","37e3747c":"# Prepare submission\n\nsubmission = pd.DataFrame()\nsubmission['id'] = test_id#test[['id']].copy()\n# submission = test[['id']].copy()\nsubmission['target'] = pd.read_csv('tst_preds.txt', header=None).values[:,0]\nsubmission.to_csv('xlearn_prediction.csv', index=False)","f2e348fb":"test.shape","67abacbe":"submission[:50]","9e763469":"submission.target.describe()","7e01f357":"sns.distplot(submission.target)","67b196f9":"-------------------","8de4f853":"## Read the data","9d53bcdc":"## install xlearn\n\nref.  \nhttps:\/\/www.kaggle.com\/nadare\/xlearn-model-cv-42-lb\n","c5a3fd66":"# Categorical Feature Encoding Challenge II\n\n## xLearn version\n\nI created this kernel by referring to the following   \n[libffm_model](https:\/\/www.kaggle.com\/ogrellier\/libffm-model)\n\nThanks!\n","55fb9108":"---------------------","180cda23":"## Predict for test set\n","b41f2989":"## Train a xlearn model","c60a9074":"## Compute OOF score","c7b5eef1":"## Run OOF"}}