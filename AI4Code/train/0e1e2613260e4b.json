{"cell_type":{"08b6b43e":"code","c24f40c3":"code","ff200a15":"code","db525414":"code","fdf0434d":"code","0c04951a":"code","7fbef4c7":"code","7be17185":"code","f0efc356":"code","f95e0d19":"code","1c8bc143":"code","a4a12705":"code","075d8cda":"code","3988b272":"code","86ee0578":"code","391a70f8":"code","cc534c2a":"code","64da2b28":"code","885c3de1":"markdown","bcaa7de2":"markdown","b4aadc30":"markdown","645e3a6c":"markdown","c93980ab":"markdown","324eeed5":"markdown","bd0930a4":"markdown","233dd824":"markdown","8218cb1a":"markdown","3279f6b2":"markdown"},"source":{"08b6b43e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c24f40c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge, Lasso,ElasticNet\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom catboost import Pool, CatBoostRegressor, cv\nimport xgboost as xgb\nimport lightgbm as lgb\n","ff200a15":"train = pd.read_csv(\"\/kaggle\/input\/liverpool-ion-switching\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/liverpool-ion-switching\/test.csv\")","db525414":"train.shape","fdf0434d":"train.head()","0c04951a":"train[\"open_channels\"].value_counts().plot(kind = \"bar\")\nplt.xlabel('open Channels')\nplt.ylabel('count')\nplt.title(\"Distribution of Channels\")\nplt.show()","7fbef4c7":"train[\"open_channels\"].value_counts(normalize=True)","7be17185":"print(f\"We have {train.shape[0]\/\/500000} Batches in the training dataset\")","f0efc356":"#for every 500000 values we conconstrct a hist plot\n\nfig, axes = plt.subplots(4,3, figsize=(10, 10))\nfig.subplots_adjust(hspace=0.5)\nfig.suptitle('Distributions of Targets for batches')\nfor ax, i in zip(axes.flatten(),range(0,10)):\n    \n    data = train.iloc[(i * 500000):((i+1) * 500000 + 1)]['open_channels']\n    sns.countplot(data, ax= ax)\n    ax.set(title=f\"Batch-{i}\".upper())","f95e0d19":"#plot of the signal\nplt.figure(figsize=(20, 8))\ntrain.signal.plot()\nplt.title(\"Train data\")","1c8bc143":"trnX = train[['signal']].values\ntrnY = train['open_channels'].values","a4a12705":"from sklearn.linear_model import Ridge\nmodel = Ridge(alpha=0.5)\nmodel.fit(trnX, trnY)","075d8cda":"ridge_predictions = model.predict(trnX)\nridge_arounded = np.rint(ridge_predictions).astype(int)","3988b272":"submission = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv')\ntestX = test[['signal']].values\nridge_prediction = model.predict(testX)\nridge_prediction = np.rint(ridge_prediction).astype(int)\n","86ee0578":"model_lgb = lgb.LGBMRegressor(objective='regression',\n                              num_leaves=4,\n                              learning_rate=0.05, \n                              n_estimators=1080,\n                              max_bin=75, \n                              bagging_fraction=0.80,\n                              bagging_freq=5, \n                              feature_fraction=0.232,\n                              feature_fraction_seed=9, \n                              bagging_seed=9,\n                              min_data_in_leaf=6, \n                              min_sum_hessian_in_leaf=11)","391a70f8":"model_lgb.fit(trnX, trnY)","cc534c2a":"lgb_train_pred_trn = model_lgb.predict(trnX)\nlgb_train_pred = model_lgb.predict(testX)\nlgb_pred = np.rint(lgb_train_pred).astype(int)","64da2b28":"#ensemble\nensemble = ridge_prediction*0.35 + lgb_pred*0.65\nsubmission['open_channels'] = ensemble\nsubmission[submission['open_channels']<0]['open_channels'] = 0\nsubmission.head()\nsubmission.to_csv(\"submission.csv\", index=False)","885c3de1":"Data is Discreate batches of 50seconds each long. lets take a look into Distribution of targets in batches","bcaa7de2":"### LGBRegreessor","b4aadc30":"lets plot one histogram for each batch to see the target distribution","645e3a6c":"Lets take the distribution of channels","c93980ab":"looks like 75% of open channels values are in [0,1,2,3]","324eeed5":"lets look at how the signal look for each batch","bd0930a4":"### Regression","233dd824":"##### lets fit Ridge Regression","8218cb1a":"we can see signal value0. for every 0.0001 second and tells how many number of open channels based on the siginal value.","3279f6b2":"More detailed and clean version is upto come. work in progress.\n"}}