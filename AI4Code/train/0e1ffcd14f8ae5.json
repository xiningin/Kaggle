{"cell_type":{"4bb6ed35":"code","08e4d791":"code","0419b1bd":"code","dd41d51d":"code","28bd02eb":"code","fa1a4e69":"code","bfddcd46":"code","b4f6d0be":"code","49f13d0f":"code","4766ae39":"code","4f388415":"code","8767c5db":"code","cea33e30":"code","1812200f":"code","5b2af6fb":"code","c39ebe2e":"code","1c0e22da":"code","8d9d15ba":"code","524264c5":"code","f5802b22":"markdown","09415b94":"markdown","c9bf359e":"markdown","feabe9ea":"markdown","d7eea86d":"markdown","074287e4":"markdown","f3e37d27":"markdown","0285929f":"markdown","0f42559f":"markdown","94c60f95":"markdown","ce38bef4":"markdown","b03509d2":"markdown","c119d22e":"markdown","0e480fd2":"markdown","e0d4394a":"markdown","4263814a":"markdown","a717df95":"markdown","f715f010":"markdown","b8cab65c":"markdown","a6a988a7":"markdown","929180f5":"markdown"},"source":{"4bb6ed35":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport cv2 \nfrom glob import glob\nimport os","08e4d791":"main_path = \"..\/input\/van-gogh-paintings\"\nstyle_img_paths = []\nfor class_path in [os.path.join(main_path,class_name) for class_name in os.listdir(main_path)]:\n    \n    class_img_paths = glob(class_path+\"\/*\")\n    for class_img_path in class_img_paths:\n        style_img_paths.append(class_img_path)\n\nprint(\"There are {} style images in Van Gogh Paintings Dataset\".format(len(style_img_paths)))","0419b1bd":"main_path = \"..\/input\/natural-images\/natural_images\"\nnormal_image_paths = []\nfor class_path in [os.path.join(main_path,class_name) for class_name in os.listdir(main_path)]:\n    \n    class_img_paths = glob(class_path+\"\/*\")\n    for class_img_path in class_img_paths:\n        normal_image_paths.append(class_img_path)\n\nprint(\"There are {} natural images in the Natural Images Dataset\".format(len(normal_image_paths)))","dd41d51d":"style_images = []\nnormal_images = []\n\nfor style_path in style_img_paths:\n    img = cv2.imread(style_path)\n    img = cv2.resize(img,(128,128))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    style_images.append(img)\n    \nfor normal_path in normal_image_paths:\n    img = cv2.imread(normal_path)\n    img = cv2.resize(img,(128,128))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    normal_images.append(img)\n    \nprint(len(style_images))\nprint(len(normal_images))","28bd02eb":"# converting to float32 \nstyle_images = np.array(style_images,dtype=np.float32)\nnormal_images = np.array(normal_images,dtype=np.float32)\n\n# scaling between -1 and 1\nstyle_images = style_images \/ 127.5 - 1\nnormal_images = normal_images \/ 127.5 - 1\n\n# batching\nstyle_images = tf.data.Dataset.from_tensor_slices(style_images).batch(1)\nnormal_images = tf.data.Dataset.from_tensor_slices(normal_images).batch(1)","fa1a4e69":"plt.figure(figsize=(7,7))\nplt.title(\"Style Images\")\nfor i,image in enumerate(style_images.shuffle(10000).take(16)):\n    plt.subplot(4,4,i+1)\n    plt.imshow(image[0])\n    plt.axis(\"off\")\nplt.show()","bfddcd46":"plt.figure(figsize=(7,7))\nplt.title(\"Natural Images\")\nfor i,image in enumerate(normal_images.shuffle(10000).take(16)):\n    plt.subplot(4,4,i+1)\n    plt.imshow(image[0])\n    plt.axis(\"off\")\nplt.show()","b4f6d0be":"# we need to downsample and upsample the images, so let's write two new layers, Upsample layer and Downsample Layer\nOUTPUT_CHANNELS = len([\"Red\",\"Green\",\"Blue\"])\n\ndef downsample(filters,size,apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n    \n    result = keras.Sequential()\n    result.add(layers.Conv2D(filters,size,strides=2,padding=\"same\",kernel_initializer=initializer,use_bias=False))\n    \n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    result.add(layers.LeakyReLU())\n    \n    return result\n\ndef upsample(filters,size,apply_dropout=False):\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n    \n    result = keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters,size,strides=2,padding=\"same\",kernel_initializer=initializer,use_bias=False))\n    \n    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    \n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n    \n    result.add(layers.ReLU())\n    return result","49f13d0f":"# discriminator\n\ndef Generator():\n    inputs = layers.Input([128,128,3])\n    \n    down_stack = [downsample(128,4), # 64x64x128\n                  downsample(256,4), # 32x32x256\n                  downsample(512,4), # 16x16x512\n                  downsample(512,4), # 8x8x512\n                  downsample(512,4), # 4x4x512\n                  downsample(512,4), # 2x2x512\n                  downsample(512,4), # 1x1x512\n                 ]\n    \n    up_stack = [upsample(512,4,apply_dropout=True), # 2x2\n                upsample(512,4,apply_dropout=True), # 4x4\n                upsample(512,4), # 8x8\n                upsample(256,4), # 16x16\n                upsample(128,4), # 32x32\n                upsample(64,4),  # 64x64\n               ]\n    \n    initializer = tf.random_normal_initializer(0.,0.02)\n    last = last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n                                  strides=2,\n                                  padding='same',\n                                  kernel_initializer=initializer,\n                                  activation='tanh')\n    \n    # we'll create skip connections like a residual network\n    x = inputs\n    \n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n        \n    skips = reversed(skips[:-1])\n    \n    for up,skip in zip(up_stack,skips):\n        x = up(x)\n        x = layers.Concatenate()([x,skip])\n        \n    x = last(x)\n    \n    return keras.Model(inputs=inputs,outputs=x)","4766ae39":"def Discriminator():\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n    \n    inp = layers.Input([128,128,3],name=\"input_image\")\n    \n    x = inp\n    \n    down1 = downsample(64,4,False)(x) # 64x64x64\n    down2 = downsample(128,4,False)(down1) # 32x32x128\n    \n    zero_pad1 = layers.ZeroPadding2D()(down2)\n    \n    conv = layers.Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n    \n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n    \n    leaky_relu = layers.LeakyReLU()(norm1)\n    \n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n    \n    last = layers.Conv2D(1,4,strides=1,kernel_initializer=initializer)(zero_pad2)\n    \n    return keras.Model(inputs=inp,outputs=last)\n\n    ","4f388415":"vangogh_generator = Generator() # generates van gogh paintings using natural images\nphoto_generator = Generator() # generates natural images using van gogh paintings\n\nvangogh_discriminator = Discriminator() # determines whether van gogh painting is real or generated\nphoto_discriminator = Discriminator() # determines whether natural image is real or generated","8767c5db":"class CycleGAN(keras.Model):\n    \n    def __init__(self,\n                 vangogh_generator,\n                 photo_generator,\n                 vangogh_discriminator,\n                 photo_discriminator,\n                 lambda_cycle = 10,\n                ):\n        super(CycleGAN,self).__init__()\n        self.v_gen = vangogh_generator\n        self.p_gen = photo_generator\n        self.v_disc = vangogh_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    \n    def compile(self,\n                v_gen_optimizer,\n                p_gen_optimizer,\n                p_disc_optimizer,\n                gen_loss_fn,\n                disc_loss_fn,\n                cycle_loss_fn,\n                identity_loss_fn,\n                v_disc_optimizer\n               ):\n        super(CycleGAN,self).compile()\n        self.v_gen_optimizer = v_gen_optimizer\n        self.p_gen_optimizer =  p_gen_optimizer\n        self.v_disc_optimizer  = v_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        self.p_disc_optimizer = p_disc_optimizer\n        \n    \n    def train_step(self,batch_data):\n        real_vangogh,real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # photo to vangogh back to photo\n            fake_vangogh = self.v_gen(real_photo,training=True)\n            cycled_photo = self.p_gen(fake_vangogh,training=True)\n            \n            # vangogh to photo back to vangogh\n            fake_photo = self.p_gen(real_vangogh,training=True)\n            cycled_vangogh = self.v_gen(fake_photo,training=True)\n            \n            # generating itself\n            same_photo = self.p_gen(real_photo,training=True)\n            same_vangogh = self.v_gen(real_vangogh,training=True)\n            \n            # checking images using discriminator\n            disc_real_vangogh = self.v_disc(real_vangogh,training=True)\n            disc_real_photo = self.p_disc(real_photo,training=True)\n            \n            disc_fake_vangogh = self.v_disc(fake_vangogh,training=True)\n            disc_fake_photo = self.p_disc(fake_photo,training=True)\n            \n            # computing generator loss\n            vangogh_gen_loss = self.gen_loss_fn(disc_fake_vangogh)\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n            \n            # computing total cycle loss\n            total_cycle_loss = self.cycle_loss_fn(real_vangogh,cycled_vangogh,self.lambda_cycle) + self.cycle_loss_fn(real_photo,cycled_photo,self.lambda_cycle)\n            \n            # computing total loss\n            total_vangogh_gen_loss = vangogh_gen_loss + total_cycle_loss + self.identity_loss_fn(real_vangogh, same_vangogh, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n            \n            # computing discriminator loss\n            vangogh_disc_loss = self.disc_loss_fn(disc_real_vangogh,disc_fake_vangogh)\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo,disc_fake_photo)\n            \n        \n        # calculating gradients of networks\n        vangogh_generator_gradients = tape.gradient(total_vangogh_gen_loss,self.v_gen.trainable_variables)\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,self.p_gen.trainable_variables)\n        \n        vangogh_discriminator_gradients = tape.gradient(vangogh_disc_loss,self.v_disc.trainable_variables)\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,self.p_disc.trainable_variables)\n        \n        self.v_gen_optimizer.apply_gradients(zip(vangogh_generator_gradients,self.v_gen.trainable_variables))\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,self.p_gen.trainable_variables))\n        \n        self.v_disc_optimizer.apply_gradients(zip(vangogh_discriminator_gradients,\n                                                  self.v_disc.trainable_variables))\n\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n                                                  self.p_disc.trainable_variables))\n        \n        return {\n            \"v_gen_loss\": total_vangogh_gen_loss,\n            \"p_gen_loss\": total_photo_gen_loss,\n            \"v_disc_loss\": vangogh_disc_loss,\n            \"p_disc_loss\": photo_disc_loss\n        }\n        \n        ","cea33e30":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\ndef discriminator_loss(real,generated):\n    \n    real_loss = cross_entropy(tf.ones_like(real),real)\n    generated_loss = cross_entropy(tf.zeros_like(generated),generated)\n    \n    total_loss = real_loss + generated_loss\n    \n    return total_loss * 0.5\n    ","1812200f":"def generator_loss(generated):\n    \n    return cross_entropy(tf.ones_like(generated),generated)\n","5b2af6fb":"def cycle_loss(real_image,cycled_image,LAMBDA):\n    \n    return tf.reduce_mean(tf.abs(real_image - cycled_image)) * LAMBDA\n\ndef identity_loss(real_image,same_image,LAMBDA):\n    \n    return tf.reduce_mean(tf.abs(real_image - same_image)) * LAMBDA","c39ebe2e":"# We'll use Adam optimizer\nvangogh_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nphoto_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\nvangogh_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nphoto_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","1c0e22da":"model = CycleGAN(vangogh_generator=vangogh_generator,\n                photo_generator=photo_generator,\n                vangogh_discriminator=vangogh_discriminator,\n                photo_discriminator=photo_discriminator\n                )\n\nmodel.compile(v_gen_optimizer=vangogh_generator_optimizer,\n              p_gen_optimizer=photo_generator_optimizer,\n              p_disc_optimizer=photo_discriminator_optimizer,\n              v_disc_optimizer=vangogh_discriminator_optimizer,\n              gen_loss_fn=generator_loss,\n              disc_loss_fn=discriminator_loss,\n              cycle_loss_fn=cycle_loss,\n              identity_loss_fn=identity_loss\n             )\n\n","8d9d15ba":"#if os.path.exists(\".\/model.h5\"):\n    #model.load_weights(\".\/model.h5\")\n    #print(\"Saved weigths loaded\")\n\n\nmodel.fit(tf.data.Dataset.zip((style_images,normal_images)),\n          epochs=2)\n\nmodel.save_weights(\"model.h5\")","524264c5":"\nplt.figure(figsize=(10,10))\nfor i,image in enumerate(normal_images.shuffle(10000).take(36)):\n    plt.subplot(6,6,i+1)\n    prediction = vangogh_generator(image,training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    plt.imshow(X = prediction)\n    plt.axis(\"off\")\n    if i==36:\n        break\nplt.show()","f5802b22":"* We've determined paths of images, now we can read them.","09415b94":"I know, training looks a bit confusing but don't worry, I will explain\n1. First we created fake photos, same photos, and cycled photos, we'll use them in order to compute loss\n1. Then we computed losses, we'll use these losses in order to compute gradients\n1. Then we computed gradients and applied it to networks.\n","c9bf359e":"# Defining Optimizers And Loss Functions\nIn this section I am going to define optimizers and loss functions.","feabe9ea":"# Training Model\nIn this section I am going to train our CycleGAN model.","d7eea86d":"* Generator is a bit confusing, I know.\n1. First, generator took 128x128x3 image (this will be our natural image) and converted it into 1x1x512 vector.\n1. Then, upsampled that vector to 128x128x3\n1. We created skip connections, they will prevent vanishing gradient problem.\n1. And finally we returned our model.","074287e4":"# Conclusion\nThanks for your attention, if you have any questions in your mind, please ask. I will definetely return.","f3e37d27":"* Our functions are ready, now we can create our generators and discriminators.","0285929f":"* We created our model, let's fit it for 25 epochs.","0f42559f":"# Generating Some Paintings\nIn this section I am going to generate some paintings.","94c60f95":"* But when it comes to compute generator loss, we just use generated (fake) images loss.","ce38bef4":"In discriminator loss, we've computed real images loss and generated images loss and added them.","b03509d2":"# Building CycleGAN Model\nIn this section I am going to build CycleGAN model using our generators and discriminators.\n\nI will create a new class by inheriting the model class.","c119d22e":"* Our model works right, but it needs to train more.\n","0e480fd2":"* Our images are ready, let's check them.","e0d4394a":"# Importing Necessary Libraries\nIn this section I am going to import libraries that I will use.","4263814a":"* I've trained for 4 epoch, each epoch takes 6 minutes.\n* If you try to train 10 epochs, it will be better.","a717df95":"# Introduction\nHello people, welcome to this kernel. In this kernel I am going to generate some new van gogh paintings using van gogh paintings dataset and natural images dataset.\n\nBefore starting, let's take a look at the content of this kernel\n\n# Notebook Content\n1. Importing Necessary Libraries\n1. Loading Data\n1. Building Generator Model\n1. Building Discriminator Model\n1. Building CycleGAN Model\n1. Defining Optimizers and Loss Functions\n1. Training Model\n1. Generating Some Paintings\n1. Conclusion","f715f010":"# Building Generator Model\nIn this section I am going to build the generator networks of the CycleGAN.","b8cab65c":"# Loading Dataset\nIn this section I am going to load images.","a6a988a7":"# Building Discriminator Model\nIn this section I am going to build the discriminator model. This will be easier, because Discriminator is a CNN based classifier. It determines whether image is real or generated.\n","929180f5":"* Thanks to this layers, we can easily create our generator and discriminator."}}