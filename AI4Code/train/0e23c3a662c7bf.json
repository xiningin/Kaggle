{"cell_type":{"6b3255c4":"code","380fb35f":"code","39dac952":"code","5cb2dc34":"code","0017bf36":"code","c66bd408":"code","d8944806":"code","83ab5189":"code","94dfd510":"code","a6cfe408":"code","6a8d79c2":"code","b4609906":"code","305e2eea":"code","25c30e96":"code","f7fff7da":"code","e583ca8c":"code","decc2f52":"code","d3ad4b3f":"code","5ece7bb0":"code","ed3f6bde":"code","b9cad964":"code","1f641dc4":"code","c522c64c":"code","4286c79d":"code","4284c162":"code","a3523b4a":"code","fd12f208":"code","6cc9ba4a":"code","d18499b6":"code","34932ba0":"code","9cb6413b":"code","185f0c0c":"code","eb34b11e":"code","1ca6c4d6":"code","6894c32e":"code","fc462527":"code","60ec5cd2":"code","37f4dfeb":"code","4ba08027":"code","f5e270d4":"code","5f82b50e":"code","372632ba":"code","295d1dbd":"code","e04d57d1":"code","315727aa":"code","febabb26":"code","eebf287b":"code","36303084":"code","0ec63b20":"code","c4533b9d":"code","74907305":"code","716fcd91":"code","bd0bd05d":"code","7a9b790a":"code","d00f1926":"code","0e585a6c":"code","8c5f1c8a":"code","05bcb30e":"code","973934a9":"code","b9a8e84f":"code","f10a52af":"code","608f4253":"code","3bfb8cac":"code","93e77283":"code","34493f5d":"code","67cb9ad2":"code","e2934d07":"code","a059d81c":"code","d03c9a86":"code","617630c8":"code","51328418":"code","1c473a64":"code","09ccb969":"code","83f35c7b":"code","b5c6e3ab":"code","41aafb51":"markdown","4fa28597":"markdown","f1fa6dad":"markdown","55792376":"markdown","614d8d3a":"markdown","97887b73":"markdown","f22a712b":"markdown","430cd407":"markdown","29dd153d":"markdown","2dceeebd":"markdown","bf2c5d92":"markdown","62cf2da5":"markdown","c6d15a90":"markdown","fa69d9ff":"markdown","bfeff79a":"markdown","f8d4acf6":"markdown","2a35d612":"markdown","468789c3":"markdown"},"source":{"6b3255c4":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","380fb35f":"import numpy as np\nimport pandas as pd\nimport unicodedata\nimport string\nimport re\nimport random\nimport torch","39dac952":"data = pd.read_csv(\"..\/input\/ai4d-yorb-machine-translation\/Train.csv\")","5cb2dc34":"data.head()","0017bf36":"## Create a Language class to store  util functions\n## such as index to word and word to index\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {\"<blank>\":0, \"SOS\":1,\"EOS\":2}\n        self.word2count = {}\n        self.index2word = {0:\"<blank>\", 1: \"SOS\", 2: \"EOS\"}\n        self.n_words = 3  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","c66bd408":"# Turn a Unicode string to plain ASCII, thanks to\n# https:\/\/stackoverflow.com\/a\/518232\/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s","d8944806":"zdata = list(zip(data[\"Yoruba\"].values,data[\"English\"])) ##zipped the two language together","83ab5189":"len(zdata)","94dfd510":"zdata[0]","a6cfe408":"## Util function to make it easier to s\n## group the language into output and input\ndef readLang(lang1,lang2,reverse=False):\n    \n    pairs = [[normalizeString(s) for s in dt] for dt in zdata]\n    \n    if reverse:\n        pairs =  [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n        \n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n        \n    return input_lang, output_lang,pairs","6a8d79c2":"MAX_LENGTH = 100\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","b4609906":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLang(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('yo', 'eng')\nprint(random.choice(pairs))","305e2eea":"len(pairs)","25c30e96":"## convert word to their index\ndef tokenize(lang,sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n","f7fff7da":"pairs2 = np.array(pairs) ## convert the pairs to numpy array","e583ca8c":"input_token = list(map(lambda x: tokenize(input_lang,x),pairs2[:,0]))","decc2f52":"## tokenization for output lang\ndef tokenize2(lang,sentence):\n    \n    sent = \"SOS\" + \" \" + sentence + \" \" + \"EOS\"\n    return [lang.word2index[word] for word in sent.split(' ')]","d3ad4b3f":"output_token = list(map(lambda x: tokenize2(output_lang,x),pairs2[:,1]))","5ece7bb0":"pairs2[:,1][0]","ed3f6bde":"input_tokenPad = np.zeros((len(input_token),MAX_LENGTH))\noutput_tokenPad = np.zeros((len(output_token),MAX_LENGTH))","b9cad964":"for i,v in enumerate(input_token):\n    \n    for j, token in enumerate(v):\n        \n        input_tokenPad[i,j] = token","1f641dc4":"for i,v in enumerate(output_token):\n    \n    for j, token in enumerate(v):\n        \n        output_tokenPad[i,j] = token","c522c64c":"output_tokenPad","4286c79d":"## we only want up to 20K rows------cause of batching\ninput_tokenPad1 = input_tokenPad[:20000]\noutput_tokenPad1 = output_tokenPad[:20000]","4284c162":"\nfrom sklearn.model_selection import train_test_split\n","a3523b4a":"#split the dataset into train, test and validation\ntrain_eng, valid_eng,train_yor,valid_yor = train_test_split(input_tokenPad1,output_tokenPad1,test_size=0.2,shuffle=True)","fd12f208":"from torch.utils.data import TensorDataset, DataLoader\n\ntrain_data = TensorDataset(torch.from_numpy(train_eng).long(),torch.from_numpy(train_yor).long())\nvalid_data = TensorDataset(torch.from_numpy(valid_eng).long(),torch.from_numpy(valid_yor).long())\n\nbatch_size = 100\n\ntrain_loader= DataLoader(train_data,shuffle=True,batch_size=batch_size,)\nvalid_loader =DataLoader(valid_data,shuffle=True,batch_size=batch_size,)","6cc9ba4a":"# obtain one batch of training data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint(\"shape of english\", sample_x.device)\n","d18499b6":"import torch.nn as nn\nimport torch.nn.functional as F\nimport math, copy, time\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport seaborn\nseaborn.set_context(context=\"talk\")\n%matplotlib inline","34932ba0":"class EncoderDecoder(nn.Module):\n    \"\"\"\n    A standard Encoder-Decoder architecture. Base for this and many \n    other models.\n    \"\"\"\n    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n        super(EncoderDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.generator = generator\n        \n    def forward(self, src, tgt, src_mask, tgt_mask):\n        \"Take in and process masked src and target sequences.\"\n        return self.decode(self.encode(src, src_mask), src_mask,\n                            tgt, tgt_mask)\n    \n    def encode(self, src, src_mask):\n        return self.encoder(self.src_embed(src), src_mask)\n    \n    def decode(self, memory, src_mask, tgt, tgt_mask):\n        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)","9cb6413b":"class Generator(nn.Module):\n    \"Define standard linear + softmax generation step.\"\n    def __init__(self, d_model, vocab):\n        super(Generator, self).__init__()\n        self.proj = nn.Linear(d_model, vocab)\n\n    def forward(self, x):\n        return F.log_softmax(self.proj(x), dim=-1)","185f0c0c":"def clones(module, N):\n    \"Produce N identical layers.\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])","eb34b11e":"class Encoder(nn.Module):\n    \"Core encoder is a stack of N layers\"\n    def __init__(self, layer, N):\n        super(Encoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, mask):\n        \"Pass the input (and mask) through each layer in turn.\"\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)","1ca6c4d6":"class LayerNorm(nn.Module):\n    \"Construct a layernorm module (See citation for details).\"\n    def __init__(self, features, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.a_2 * (x - mean) \/ (std + self.eps) + self.b_2","6894c32e":"class SublayerConnection(nn.Module):\n    \"\"\"\n    A residual connection followed by a layer norm.\n    Note for code simplicity the norm is first as opposed to last.\n    \"\"\"\n    def __init__(self, size, dropout):\n        super(SublayerConnection, self).__init__()\n        self.norm = LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        \"Apply residual connection to any sublayer with the same size.\"\n        return x + self.dropout(sublayer(self.norm(x)))","fc462527":"class EncoderLayer(nn.Module):\n    \"Encoder is made up of self-attn and feed forward (defined below)\"\n    def __init__(self, size, self_attn, feed_forward, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n        self.size = size\n\n    def forward(self, x, mask):\n        \"Follow Figure 1 (left) for connections.\"\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayer[1](x, self.feed_forward)","60ec5cd2":"class Decoder(nn.Module):\n    \"Generic N layer decoder with masking.\"\n    def __init__(self, layer, N):\n        super(Decoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, memory, src_mask, tgt_mask):\n        for layer in self.layers:\n            x = layer(x, memory, src_mask, tgt_mask)\n        return self.norm(x)","37f4dfeb":"class DecoderLayer(nn.Module):\n    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n        super(DecoderLayer, self).__init__()\n        self.size = size\n        self.self_attn = self_attn\n        self.src_attn = src_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n \n    def forward(self, x, memory, src_mask, tgt_mask):\n        \"Follow Figure 1 (right) for connections.\"\n        m = memory\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n        return self.sublayer[2](x, self.feed_forward)","4ba08027":"def subsequent_mask(size):\n    \"Mask out subsequent positions.\"\n    attn_shape = (1, size, size)\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(subsequent_mask) == 0","f5e270d4":"\nplt.figure(figsize=(5,5))\nplt.imshow(subsequent_mask(20)[0])\nNone","5f82b50e":"def attention(query, key, value, mask=None, dropout=None):\n    \"Compute 'Scaled Dot Product Attention'\"\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n             \/ math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    p_attn = F.softmax(scores, dim = -1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n    return torch.matmul(p_attn, value), p_attn","372632ba":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=0.1):\n        \"Take in model size and number of heads.\"\n        super(MultiHeadedAttention, self).__init__()\n        assert d_model % h == 0\n        # We assume d_v always equals d_k\n        self.d_k = d_model \/\/ h\n        self.h = h\n        self.linears = clones(nn.Linear(d_model, d_model), 4)\n        self.attn = None\n        self.dropout = nn.Dropout(p=dropout)\n        \n    def forward(self, query, key, value, mask=None):\n        \"Implements Figure 2\"\n        if mask is not None:\n            # Same mask applied to all h heads.\n            mask = mask.unsqueeze(1)\n        nbatches = query.size(0)\n        \n        # 1) Do all the linear projections in batch from d_model => h x d_k \n        query, key, value = \\\n            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n             for l, x in zip(self.linears, (query, key, value))]\n        \n        # 2) Apply attention on all the projected vectors in batch. \n        x, self.attn = attention(query, key, value, mask=mask, \n                                 dropout=self.dropout)\n        \n        # 3) \"Concat\" using a view and apply a final linear. \n        x = x.transpose(1, 2).contiguous() \\\n             .view(nbatches, -1, self.h * self.d_k)\n        return self.linears[-1](x)","295d1dbd":"class PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.w_2(self.dropout(F.relu(self.w_1(x))))","e04d57d1":"class Embeddings(nn.Module):\n    def __init__(self, d_model, vocab):\n        super(Embeddings, self).__init__()\n        self.lut = nn.Embedding(vocab, d_model)\n        self.d_model = d_model\n\n    def forward(self, x):\n        return self.lut(x) * math.sqrt(self.d_model)","315727aa":"class PositionalEncoding(nn.Module):\n    \"Implement the PE function.\"\n    def __init__(self, d_model, dropout, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0., max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0., d_model, 2) *\n                             -(math.log(10000.0) \/ d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n        \n    def forward(self, x):\n        x = x + Variable(self.pe[:, :x.size(1)], \n                         requires_grad=False)\n        return self.dropout(x)","febabb26":"plt.figure(figsize=(15, 5))\npe = PositionalEncoding(20, 0)\ny = pe.forward(Variable(torch.zeros(1, 100, 20)))\nplt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\nplt.legend([\"dim %d\"%p for p in [4,5,6,7]])\nNone","eebf287b":"def make_model(src_vocab, tgt_vocab, N=6, \n               d_model=512, d_ff=2048, h=8, dropout=0.1):\n    \"Helper: Construct a model from hyperparameters.\"\n    c = copy.deepcopy\n    attn = MultiHeadedAttention(h, d_model)\n    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n    position = PositionalEncoding(d_model, dropout)\n    model = EncoderDecoder(\n        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n                             c(ff), dropout), N),\n        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n        Generator(d_model, tgt_vocab))\n    \n    # This was important from their code. \n    # Initialize parameters with Glorot \/ fan_avg.\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform(p)\n    return model","36303084":"# Small example model.\ntmp_model = make_model(10, 10, 2)\nNone","0ec63b20":"class Batch:\n    \"Object for holding a batch of data with mask during training.\"\n    def __init__(self, src, trg=None, pad=0):\n        self.src = src\n        self.src_mask = (src != pad).unsqueeze(-2)\n        if trg is not None:\n            self.trg = trg[:, :-1]\n            self.trg_y = trg[:, 1:]\n            self.trg_mask = \\\n                self.make_std_mask(self.trg, pad)\n            self.ntokens = (self.trg_y != pad).data.sum()\n    \n    @staticmethod\n    def make_std_mask(tgt, pad):\n        \"Create a mask to hide padding and future words.\"\n        tgt_mask = (tgt != pad).unsqueeze(-2)\n        tgt_mask = tgt_mask & Variable(\n            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n        return tgt_mask","c4533b9d":"def run_epoch(data_iter, model, loss_compute):\n    \"Standard Training and Logging Function\"\n    start = time.time()\n    total_tokens = 0\n    total_loss = 0\n    tokens = 0\n    for i, data in enumerate(data_iter):\n        \n        src, trg = data\n        batch = Batch(src.cuda(),trg.cuda())\n        out = model.forward(batch.src, batch.trg, \n                            batch.src_mask, batch.trg_mask)\n        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n        total_loss += loss\n        total_tokens += batch.ntokens\n        tokens += batch.ntokens\n        if i % 50 == 1:\n            elapsed = time.time() - start\n            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n                    (i, loss \/ batch.ntokens, tokens \/ elapsed))\n            start = time.time()\n            tokens = 0\n    return total_loss \/ total_tokens","74907305":"class NoamOpt:\n    \"Optim wrapper that implements rate.\"\n    def __init__(self, model_size, factor, warmup, optimizer):\n        self.optimizer = optimizer\n        self._step = 0\n        self.warmup = warmup\n        self.factor = factor\n        self.model_size = model_size\n        self._rate = 0\n        \n    def step(self):\n        \"Update parameters and rate\"\n        self._step += 1\n        rate = self.rate()\n        for p in self.optimizer.param_groups:\n            p['lr'] = rate\n        self._rate = rate\n        self.optimizer.step()\n        \n    def rate(self, step = None):\n        \"Implement `lrate` above\"\n        if step is None:\n            step = self._step\n        return self.factor * \\\n            (self.model_size ** (-0.5) *\n            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n        \ndef get_std_opt(model):\n    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))","716fcd91":"# Three settings of the lrate hyperparameters.\nopts = [NoamOpt(512, 1, 4000, None), \n        NoamOpt(512, 1, 8000, None),\n        NoamOpt(256, 1, 4000, None)]\nplt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\nplt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\nNone","bd0bd05d":"class LabelSmoothing(nn.Module):\n    \"Implement label smoothing.\"\n    def __init__(self, size, padding_idx, smoothing=0.0):\n        super(LabelSmoothing, self).__init__()\n        self.criterion = nn.KLDivLoss(size_average=False)\n        self.padding_idx = padding_idx\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.size = size\n        self.true_dist = None\n        \n    def forward(self, x, target):\n        assert x.size(1) == self.size\n        true_dist = x.data.clone()\n        true_dist.fill_(self.smoothing \/ (self.size - 2))\n        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        true_dist[:, self.padding_idx] = 0\n        mask = torch.nonzero(target.data == self.padding_idx)\n        if mask.dim() > 0:\n            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n        self.true_dist = true_dist\n        return self.criterion(x, Variable(true_dist, requires_grad=False))","7a9b790a":"class SimpleLossCompute:\n    \"A simple loss compute and train function.\"\n    def __init__(self, generator, criterion, opt=None):\n        self.generator = generator\n        self.criterion = criterion\n        self.opt = opt\n        \n    def __call__(self, x, y, norm):\n        x = self.generator(x)\n        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n                              y.contiguous().view(-1)) \/ norm\n        loss.backward()\n        if self.opt is not None:\n            self.opt.step()\n            self.opt.optimizer.zero_grad()\n        return loss.item() * norm","d00f1926":"def greedy_decode(model, src, src_mask, max_len, start_symbol):\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n    for i in range(max_len-1):\n        out = model.decode(memory, src_mask, \n                           Variable(ys), \n                           Variable(subsequent_mask(ys.size(1))\n                                    .type_as(src.data)))\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim = 1)\n        next_word = next_word.data[0]\n        ys = torch.cat([ys, \n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n    return ys","0e585a6c":"pad_idx = output_lang.word2index[\"<blank>\"]\nmodel = make_model(input_lang.n_words,output_lang.n_words,N=6)\nmodel.cuda()\ncriterion = LabelSmoothing(size=output_lang.n_words,padding_idx=pad_idx,smoothing=0.1)\ncriterion.cuda()","8c5f1c8a":"optimizer=torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)","05bcb30e":"model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n\nfor epoch in range(10):\n  model.train()\n  \n    \n  run_epoch(train_loader,model,\n           SimpleLossCompute(model.generator,criterion,model_opt))\n  model.eval()\n  print(run_epoch(valid_loader,model,\n           SimpleLossCompute(model.generator,criterion,None)))","973934a9":"for i, data in enumerate(valid_loader):\n  \n    src,trg = data\n    batch = Batch(src.cuda(),trg.cuda())\n    src = batch.src[:1]\n    src_mask = (src != input_lang.word2index[\"<blank>\"]).unsqueeze(-2)\n    out = greedy_decode(model.cuda(), src, src_mask, \n                        max_len=60, start_symbol=output_lang.word2index[\"SOS\"])\n    for i in range(0, src.size(1)):\n        sym = input_lang.index2word[src[0, i].item()]\n        if sym == \"<blank>\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Translation:\", end=\"\\t\")\n    for i in range(1, out.size(1)):\n        sym = output_lang.index2word[out[0, i].item()]\n        if sym == \"EOS\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Target:\", end=\"\\t\")\n    for i in range(1, batch.trg.size(1)):\n        \n        sym = output_lang.index2word[batch.trg.data[0,i].item()]\n        if sym == \"EOS\": break\n        print(sym, end =\" \")\n    print()\n    break","b9a8e84f":"src[0,1]","f10a52af":"torch.save({\n    \"SRC\" : input_lang,\n    \"TGT\" : output_lang,\n    \"model_state_dict\" : model.state_dict(),\n    \"optimizer_state_dict\" : optimizer.state_dict() },\".\/model.pt\")","608f4253":"path = \"..\/input\/yoruba-translation-model\/AttensionV1.pt\"","3bfb8cac":"model_pt = torch.load(path)\n","93e77283":"input_lang = model_pt['SRC']\n\noutput_lang = model_pt['TGT']","34493f5d":"input_lang.n_words","67cb9ad2":"output_lang.word2index[\"\u1ecdk\u00f9nrin\"]","e2934d07":"model = make_model(input_lang.n_words,output_lang.n_words,N=6)\nmodel.load_state_dict(model_pt['model_state_dict'])\n# optimizer.load_state_dict(model_pt['optimizer_state_dict'])","a059d81c":"type(input_lang)","d03c9a86":"if \"BlaBlaCar\" not in input_lang.word2index:\n    print(\"true\")","617630c8":"test = pd.read_csv(\"..\/input\/ai4d-yorb-machine-translation\/Test.csv\")","51328418":"test[\"Label\"]=\"\"","1c473a64":"len(test.Yoruba)","09ccb969":"from tqdm.notebook import trange, tqdm","83f35c7b":"model.eval()\nm = model.cpu()\nfor x in trange(len(test.Yoruba)): \n    sent = normalizeString(test.Yoruba[x]).split()\n    src = torch.LongTensor([[input_lang.word2index[w] for w in sent if w in input_lang.word2index]])\n    src = Variable(src)\n    src_mask = (src != input_lang.word2index[\"<blank>\"])\n    out = greedy_decode(model, src, src_mask, \n                        max_len=20, start_symbol=output_lang.word2index[\"SOS\"])\n#     print(\"Translation:\", end=\"\\t\")\n    trans = \"\"\n    for i in range(1, out.size(1)):\n        sym = output_lang.index2word[out[0, i].item()]\n        if sym == \"EOS\": break\n        trans += sym + \" \"\n    test[\"Label\"][x] = trans   \n# print(trans)","b5c6e3ab":"test[[\"ID\",\"Label\"]].to_csv(\"submission.csv\",index=False)","41aafb51":"## Inference\nthe model is saved, and the the input lang and output lang is also saved.\n```python\ntorch.save({\n    \"SRC\": input_lang,\n    \"TGT\": output_lang,\n    \"model_state_dict\": model.state_dict(),\n    \n},path)\n```","4fa28597":"**Positional Encoding**","f1fa6dad":"Training begins","55792376":"**Embedding and softmax**","614d8d3a":"**FUll Model**","97887b73":"## Tokenization\nThis section create a Language util class and function to make it easier to tokenize the language, since spacy does not have the tokenizer for the language. Thanks to pytorh [tutorial](https:\/\/pytorch.org\/tutorials\/intermediate\/seq2seq_translation_tutorial.html) , some of their utility function makes it easier","f22a712b":"**Encoder and Decoder Stackss**","430cd407":"**label smoothing**","29dd153d":"**Attention**","2dceeebd":"**Decoder**","bf2c5d92":"# **Training**","62cf2da5":"**optim**","c6d15a90":"Data Loader is created for the dataset to make batching easy","fa69d9ff":"create the input lang `ENglish` tokenization","bfeff79a":"**Position-wise Feed-forward**","f8d4acf6":"**Loss computation**","2a35d612":"the input and out put lang is padded and converted to numpy array","468789c3":"# **Transormer model**\nThis model is as it is from the [**NLP HARVARD** ](https:\/\/pytorch.org\/tutorials\/intermediate\/seq2seq_translation_tutorial.html)tutorial, with just small modification to fit our task"}}