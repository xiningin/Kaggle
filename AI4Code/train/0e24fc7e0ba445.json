{"cell_type":{"184fb099":"code","fb917de0":"code","9c940b98":"code","877624ed":"code","5ff0ea27":"code","a212663c":"code","f052a507":"code","155debcc":"code","534cc56c":"code","dd400b51":"code","d0b1e499":"code","3b08dc06":"code","8b77acb5":"code","b12bb07b":"code","c32f49ab":"code","ab06db8a":"code","4a28a61b":"code","949eed3d":"code","9fe7a49f":"markdown","2c3ca3da":"markdown","ffeaa863":"markdown","07544d07":"markdown","7de71c93":"markdown","a06dc78b":"markdown"},"source":{"184fb099":"import csv\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numba import njit\nimport cudf\nimport cupy\nimport pandas as pd\nimport datatable as dt\nimport pickle\nimport joblib\nimport feather\n#import plotly.express as px\nimport matplotlib.pyplot as plt\n\ndata_path = '\/kaggle\/input\/jane-street-market-prediction\/train.csv'\n# saved_data_path = '..\/input\/name of the netebook\/name of the data file' if you import the data from another notebook\nsaved_data_path = '..\/input\/benchmark-data-loading-speed\/'","fb917de0":"#################################### 1- Python\u2019s Built-in CSV parser ####################################\n# Result : Your notebook tried to allocate more memory than is available. It has restarted.","9c940b98":"#################################### 2- Numpy ####################################\nspeed_np = %timeit -o np.load('..\/input\/benchmark-loading-speed\/data.npy')","877624ed":"#################################### 3- Numba ####################################\n#@njit\n#def numba_data():\n#    return %timeit -o np.load('.\/data.npy')\n\n#speed_np = numba_data()","5ff0ea27":"#################################### 3- Numba ####################################\n#@njit\n#def numba_data():\n#    return %timeit -o np.load('.\/data.npy')\n\n#speed_np = numba_data()","a212663c":"#################################### 4- Pandas ####################################\nspeed_pd =  %timeit -o  pd.read_csv(data_path)","f052a507":"#################################### 5- Datatable ####################################\nspeed_dt =  %timeit -o  dt.fread(data_path)","155debcc":"#################################### 6- cuDF ####################################\nspeed_cu =  %timeit -o  data_cudf = cudf.read_csv(data_path)","534cc56c":"#################################### 7- cuPY ####################################\n#data = cupy.load('\/.\/data_dt.pickle', allow_pickle=False) # if the loaded file is pickled then allow_pickle=True\n# Result : Only load pickled files","dd400b51":"#################################### 8- Pickle + Datatable ####################################\nspeed_pickle =  %timeit -o  pickle.load(open(saved_data_path + 'data_dt.pickle', 'rb'))","d0b1e499":"#################################### 9- Joblib + Datatable ####################################\nspeed_joblib =  %timeit -o  joblib.load(saved_data_path + '\/data_dt.joblib')","3b08dc06":"#################################### 10- Feather + Pandas ####################################\nspeed_feather =  %timeit -o  pd.read_feather(saved_data_path + '.\/data_pd.feather')","8b77acb5":"#################################### 11- Parquet + Pandas ####################################\nspeed_parquet =  %timeit -o  pd.read_parquet(saved_data_path + '.\/data.parquet')","b12bb07b":"#################################### 12- Jay + Datatable ####################################\nspeed_jay =  %timeit -o  dt.fread(saved_data_path + '.\/data_dt.jay')","c32f49ab":"#################################### 13- hdf5 + Pandas ####################################\nspeed_hdf5 =  %timeit -o pd.read_hdf(saved_data_path + '.\/data.h5', \"data\")","ab06db8a":"speed = [\"{:.2f}\".format(speed_np.average) ,\"{:.2f}\".format(speed_pd.average), \"{:.2f}\".format(speed_dt.average), \"{:.2f}\".format(speed_cu.average), \"{:.2f}\".format(speed_pickle.average), \"{:.2f}\".format(speed_joblib.average), \"{:.2f}\".format(speed_feather.average), \"{:.2f}\".format(speed_parquet.average), \"{:.4f}\".format(speed_jay.average), \"{:.2f}\".format(speed_hdf5.average)]\nspeed_name = ['Numpy', 'Pandas', 'Datatable', 'cuDF', 'Pickle', 'Joblib', 'Feather', 'Parquet', 'Jay', 'hdf5']\n\nfor row in range(len(speed)):\n    print(speed_name[row] + ' = ', speed[row], 's')\n    \nspeedy = pd.DataFrame(index=speed_name)\nspeedy[\"Lib name\"] = speed_name\nspeedy[\"Lib speed\"] = list(map(float, speed))\nspeedy.sort_values(by=['Lib speed'], ascending=True, inplace=True)","4a28a61b":"speedy.to_pickle(\".\/speedy.pkl\")\n# pd.read_pickle(\".\/dummy.pkl\")","949eed3d":"# plotly express\n#fig = px.bar(speedy, y='Lib speed', x='Lib name', text='Lib speed', title='Benchmarking Data loading speed in seconds')\n#fig.show() # the fig is not showing\n\n# pandas vis\n#speedy_ax = speedy.plot.bar(rot=90) # bad viz, yet simple\n\n\n# pyplot\nplt.rcdefaults()\nfig, ax = plt.subplots()\n\ny_pos = np.arange(len(speedy[\"Lib name\"]))\nperformance = 3 + 10 * np.random.rand(len(speedy[\"Lib name\"]))\nerror = np.random.rand(len(speedy[\"Lib name\"]))\n\nax.barh(y_pos, speedy[\"Lib speed\"], xerr=error, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(speedy[\"Lib name\"])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Speed in Seconds')\nax.set_title('Benchmarking Data loading speed in seconds')\n\nplt.show()","9fe7a49f":"\ud83d\udca5According to the chart, Jay is the fastest, but it needs datatable.\n\n\ud83d\udca5On the other hand, numpy can both save and load models without using another lib, and it runs on cpu, which can make competitors save gpu computing hours.\n\n\ud83d\udca5All the loaded model, can be converted to Pandas, which is the easiest to use, and it take less than 3seconds to do so.\n\n\ud83d\udca5There are other very fast ways to load data, and can be very useful during data processing that i'll try to add as soon as i finish testing them.\n\nFinally feel free to put in the comment section the code that use for fast data processing =)\n\n\n# Kudos\n\nhttps:\/\/www.kaggle.com\/quillio\/pickling\n\nhttps:\/\/www.kaggle.com\/pedrocouto39\/fast-reading-w-pickle-feather-parquet-jay","2c3ca3da":"# Libs","ffeaa863":"![Benchmark Laoding Speed using](https:\/\/i.imgur.com\/8BBQdvc.jpg)","07544d07":"### Benchmark","7de71c93":"# Load saved data","a06dc78b":"### Original notebook with more detail\n[Benchmark Data Loading Speed](https:\/\/www.kaggle.com\/mouafekmk\/benchmark-data-loading-speed\/)\n\nP.S.\nNotebooks cannot have more than 20GB of saved data, so it was not possible to save all the data with different formats, and load then automatically in this notebook. So Some of the data will be save and loaded in this notebook.<br\/>\nIf this notebook presented an added value to you, please consider voting it up \ud83d\udca5\ud83d\udca5\ud83d\udca5"}}