{"cell_type":{"3605dfa8":"code","5d9522a9":"code","3c4f63e7":"code","cff38a99":"code","b9cc175d":"code","5c4fbfeb":"code","0e5254b0":"code","8864cf5e":"code","dc9e3901":"code","442ace16":"markdown","c8ca2915":"markdown","2a68fbf9":"markdown","4fe1c0f3":"markdown","334b525c":"markdown","d7111971":"markdown","a7787fd8":"markdown","e5277030":"markdown","3324277c":"markdown"},"source":{"3605dfa8":"!pip install efficientnet_pytorch","5d9522a9":"from fastai.vision.all import *\nfrom fastai.vision.core import *\nfrom fastai.callback.fp16 import *\n\nfrom fastai.callback.cutmix import *\nfrom torch.distributions.beta import Beta\n\nfrom fastai.callback.wandb import *\n\nimport pandas as pd\nimport numpy as np\n\nfrom efficientnet_pytorch import EfficientNet\nimport albumentations\nimport wandb","3c4f63e7":"class Config:\n    testing     = False # must be same as create-folds.ipynb\n    image_size  = 512\n    batch_size  = 16\n    epochs      = 17\n    f_epochs    = 1\n    train_folds = ['f4']\n    arch        = 'efficientnet-b4'\n    \ncfg = Config()","cff38a99":"def set_seeds():\n    random.seed(42)\n    np.random.seed(42)\n    torch.manual_seed(42)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nset_seeds()","b9cc175d":"path_str = '..\/input\/cassava-leaf-disease-merged'\n\nimages_path = Path(path_str + '\/train')\ncsv_path = Path(path_str + '\/merged.csv')\nfolds_path = Path('..\/input\/fold-indexes\/folds-merged.csv')\n\nfull_df = pd.read_csv(csv_path)\nfolds_df = pd.read_csv(folds_path)\n\n# drop rows so we get an even number for our folds and remove duplicates\nfull_df = full_df[~full_df['image_id'].isin(['1562043567.jpg', '3551135685.jpg', '2252529694.jpg', '1000015157.jpg', '1000201771.jpg', '100042118.jpg', '1001723730.jpg'])]","5c4fbfeb":"#Insert wandb keys here\nlen(full_df)","0e5254b0":"class AlbumentationsTransform(RandTransform):\n    split_idx,order = None, 2\n    \n    def __init__(self, train_aug, valid_aug): \n        store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)\n\n\ndef get_train_aug(size): \n    return albumentations.Compose([\n            albumentations.RandomResizedCrop(size,size),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)\n])\n\ndef get_valid_aug(size): \n    return albumentations.Compose([\n        albumentations.Resize(size, size),\n        albumentations.CenterCrop(size, size, p=1.),\n], p=1.)\n\ndef get_x(row): return images_path\/row['image_id']\ndef get_y(row): return row['label']","8864cf5e":"def train(dls, fold):\n    \n    model = EfficientNet.from_pretrained(cfg.arch, num_classes=5)\n\n    # define learner\n    learn = Learner(\n        dls=dls,\n        model=model,\n        opt_func=ranger,\n        metrics=accuracy,\n        loss_func=LabelSmoothingCrossEntropy(),\n        cbs=[\n            WandbCallback(log_preds=False, log_model=False, n_preds=10),\n            CutMix(),\n        ]\n    ).to_fp16()\n    \n    lr = 0.001\n    \n    if not cfg.testing:\n        lr_min, lr_steep = learn.lr_find(show_plot=False)\n        lr = round(lr_min, 5)\n        print(f'found lr of({lr_min}): {round(lr_min, 5)}')\n    \n    \n    # start model training\n    learn.fine_tune(\n        cfg.epochs,\n        base_lr=lr,\n        freeze_epochs=cfg.f_epochs,\n    )\n    \n    learn.export(Path(f'model-{fold}.pkl'))\n    \n    return learn","dc9e3901":"for fold in cfg.train_folds:\n    val_index = folds_df[fold].to_numpy()\n    \n    print(f'started training on {fold}')\n    \n    train_block = DataBlock(\n        blocks=(ImageBlock, CategoryBlock),\n        get_x=get_x,\n        get_y=get_y,\n        splitter=IndexSplitter(val_index),\n        item_tfms= [\n            AlbumentationsTransform(\n                get_train_aug(size=cfg.image_size),\n                get_valid_aug(size=cfg.image_size)\n            )\n        ],\n        batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n    )\n\n    dls = train_block.dataloaders(full_df, bs=cfg.batch_size)\n    learn = train(dls, fold)\n\nprint(f'training on {cfg.train_folds} done')","442ace16":"Albumentations, in case you don't know is a fast and efficient augmentation library. Check docs [here](https:\/\/albumentations.ai\/)\nAlthough I won't be going to much in depth, it's very efficient and easy to implement. Give it a shot!\n","c8ca2915":"# Create a test dataset","2a68fbf9":"# Setup","4fe1c0f3":"# Augmentation and train functions","334b525c":"# Imports","d7111971":"## Efficientnet + distillation\n\nThere are private datasets, and this is the first notebook I will be releelasing via cassava competition\n\nThanks to my team Teo and Varun for their hardwork! If you found this useful, feel free to upvote! Would help me and my team a lot from the hardwork and time we put in!\n\nLets get started\n\n**Agenda**\n1. Imports\n2. Setup\n3. dataset\n4. Augmentations\n5. Training loop\n\n**Note** This is the simple notebook, find distillation notebook here\nDistillation Notebook: [Here](https:\/\/www.kaggle.com\/varungadre0910\/cassava-trainin-distillation-final)","a7787fd8":"Only training for fold 4 because training them all would exceed 8 hour run time","e5277030":"# Training\nTrain models on different folds of our data","3324277c":"I know I know.. We are using fastai currently(because it performed the best out of our pytorch and tensorflow models), will be converting this however solely only pytorch"}}