{"cell_type":{"b1687251":"code","8bc4b48b":"code","95bfd726":"code","3393d037":"code","f98e6fe6":"code","7c6cb034":"code","11326326":"code","4bbb4a0d":"code","5d41cb3b":"code","83c20a8e":"code","0e75e5cc":"code","792ff088":"code","b87fd42c":"code","4c5ee41c":"code","28a183b9":"code","4225391f":"code","daee82ac":"code","a5272009":"code","e95cabab":"code","aeb42ae9":"code","2ca58c76":"code","60fef0ac":"code","64df4264":"code","fd9d4fa1":"code","caec20a4":"code","eb0d2aab":"code","717c0b03":"code","5b0ffee7":"code","cf1ec725":"code","78282417":"code","47288440":"code","e89a7d2f":"code","d88d3292":"code","599824aa":"markdown","aabb8ba2":"markdown","fe87135e":"markdown","598c1894":"markdown","de02c2a1":"markdown","17c8d1e6":"markdown","92e0a10f":"markdown","f6e9f666":"markdown","3e4538c3":"markdown"},"source":{"b1687251":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\n\nimport statsmodels.api as sm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bc4b48b":"#read the data\n\ndf= pd.read_csv(r'\/kaggle\/input\/usa-housing\/USA_Housing.csv')","95bfd726":"#check data\ndf.head()","3393d037":"#check shape of data\ndf.shape","f98e6fe6":"#info of dataframe\ndf.info()","7c6cb034":"df.describe()","11326326":"#plotting a pairplot\n\nsns.pairplot(df, diag_kind='kde')","4bbb4a0d":"# plotting heat map for correlations\n\nsns.heatmap(df.corr(), annot=True)\nplt.show()","5d41cb3b":"#dist plot for dependent variable\nsns.distplot(df['Price'])","83c20a8e":"#selecting X and y for Model\nX = df.drop(['Address', 'Price'], axis=1)\ny = df['Price']","0e75e5cc":"#dividing data into train, test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=0)","792ff088":"# train data\nX_train.head()","b87fd42c":"#train data shape\nX_train.shape","4c5ee41c":"#test data shape\nX_test.shape","28a183b9":"#build linear model\n\n#add a constant\nX_train_sm = sm.add_constant(X_train)\n\n#model creation\nlr= sm.OLS(y_train, X_train_sm)","4225391f":"#fit the model\nlr_model= lr.fit()","daee82ac":"#params\nlr_model.params","a5272009":"#summary\nlr_model.summary()","e95cabab":"#dropping 'Avg. Area Number of Bedrooms' as it has high p value. \nX_train= X_train.drop(columns=['Avg. Area Number of Bedrooms'])","aeb42ae9":"#build linear model\n\n#add a constant\nX_train_sm = sm.add_constant(X_train)\n\n#model creation\nlr= sm.OLS(y_train, X_train_sm)","2ca58c76":"#fit the model\nlr_model= lr.fit()","60fef0ac":"#params\nlr_model.params","64df4264":"#summary\nlr_model.summary()","fd9d4fa1":"#building model using sklearn\n\nlm= LinearRegression()\nlm.fit(X_train, y_train)","caec20a4":"#predict y_train\ny_train_cnt = lm.predict(X_train)","eb0d2aab":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_cnt), bins = 20)\n# Plot heading \nfig.suptitle('Error Terms', fontsize = 20) \n# X-label\nplt.xlabel('Errors', fontsize = 18)    \nplt.show()","717c0b03":"#preparing X_test data\n\nX_test= X_test.drop(columns=['Avg. Area Number of Bedrooms'])","5b0ffee7":"#X_test data\n\nX_test.head()","cf1ec725":"# Making predictions using the model\n\ny_pred = lm.predict(X_test)","78282417":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure(figsize=(8, 6))\nplt.scatter(y_test,y_pred)\n# Plot heading \nfig.suptitle('y_test vs y_pred', fontsize=20)\n# X-label\nplt.xlabel('y_test', fontsize=18)\n# Y-label\nplt.ylabel('y_pred', fontsize=16)\nplt.show()","47288440":"#r-square train\nr2_score(y_true= y_train, y_pred= y_train_cnt)","e89a7d2f":"#r-square test\nr2_score(y_true= y_test, y_pred= y_pred)","d88d3292":"#'MAE', 'MSE', 'RMSE' of the model.\n\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","599824aa":"# Step 4: Building the Model","aabb8ba2":"# Step 6: Making Predictions on Test Set","fe87135e":"**Here R2 score of train and test data is almost same. Therefore we can say that model is not overfitted.**","598c1894":"# Step 7: Model Evaluation","de02c2a1":"# **Step 1: Reading Data**","17c8d1e6":"# Step 3: Splitting the Data into Training and Testing Sets","92e0a10f":"# Step 5: Residual analysis","f6e9f666":"* Here p value of 'Avg. Area Number of Bedrooms' is very high, therefore we are dropping it.","3e4538c3":"# Step 2: Exploratory Data Analysis (EDA)"}}