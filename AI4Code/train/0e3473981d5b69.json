{"cell_type":{"ea8fb18a":"code","d703188d":"code","f1df30e0":"code","5accf1fd":"code","0879d540":"code","2be3fb0e":"code","4d0ae90e":"code","fa9fbdf2":"code","c4013d26":"code","b3b6b306":"code","2b3300e9":"code","48a61046":"code","e1ca3a1e":"code","f7127d71":"code","51395c17":"code","8570c5f6":"code","060a9cd1":"code","501b1ce0":"code","15caf485":"code","7fe88a53":"code","8092e346":"code","4e448fcd":"code","e2bea5a9":"code","96fcb44f":"markdown","19d2b5b1":"markdown","2eb015f1":"markdown","ed9f1ee0":"markdown","fe623e4f":"markdown","1a0aaa3d":"markdown","64ce35ae":"markdown","cd30df52":"markdown"},"source":{"ea8fb18a":"import numpy as np\nimport pandas as pd\nimport datetime\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 200)","d703188d":"df_hist_trans = pd.read_csv('..\/input\/dsa-comp4\/transacoes_historicas.csv'\n                            ,parse_dates=['purchase_date']\n                            ,dtype = {\n                                'city_id': np.int16\n                                ,'installments': np.int16\n                                ,'merchant_category_id': np.int16\n                                ,'month_lag': np.int8\n                                ,'purchase_amount': np.float32\n                                ,'state_id': np.int8\n                                ,'subsector_id': np.int8\n                            }) \n\ndf_new_merchant_trans = pd.read_csv('..\/input\/dsa-comp4\/novas_transacoes_comerciantes.csv'\n                            ,parse_dates=['purchase_date']\n                            ,dtype = {\n                                'city_id': np.int16\n                                ,'installments': np.int16\n                                ,'merchant_category_id': np.int16\n                                ,'month_lag': np.int8\n                                ,'purchase_amount': np.float32\n                                ,'state_id': np.int8\n                                ,'subsector_id': np.int8\n                            })   \n\ndf_train = pd.read_csv('..\/input\/competicao-dsa-machine-learning-jun-2019\/dataset_treino.csv'\n                       ,parse_dates=['first_active_month']\n                       ,dtype = {\n                                'feature_1': np.int8\n                                ,'feature_2': np.int8\n                                ,'feature_3': np.int8\n                            })\n\ndf_test = pd.read_csv('..\/input\/competicao-dsa-machine-learning-jun-2019\/dataset_teste.csv'\n                        ,parse_dates=['first_active_month']\n                        ,dtype = {\n                                'feature_1': np.int8\n                                ,'feature_2': np.int8\n                                ,'feature_3': np.int8\n                            })\n\ndf_comerciantes = pd.read_csv('..\/input\/competicao-dsa-machine-learning-jun-2019\/comerciantes.csv')","f1df30e0":"df_hist_trans.head()","5accf1fd":"df_new_merchant_trans.head()","0879d540":"df_train.head()","2be3fb0e":"df_test.head()","4d0ae90e":"df_comerciantes.head()","fa9fbdf2":"pd.DataFrame(df_hist_trans.isnull().sum().sort_values(ascending=False)).head(4)","c4013d26":"pd.DataFrame(df_new_merchant_trans.isnull().sum().sort_values(ascending=False)).head(4)","b3b6b306":"pd.DataFrame(df_train.isnull().sum().sort_values(ascending=False)).head(4)","2b3300e9":"pd.DataFrame(df_test.isnull().sum().sort_values(ascending=False)).head(4)","48a61046":"pd.DataFrame(df_comerciantes.isnull().sum().sort_values(ascending=False)).head(4)","e1ca3a1e":"df_hist_trans['category_2'].value_counts()","f7127d71":"df_new_merchant_trans['category_2'].value_counts()","51395c17":"df_hist_trans['category_3'].value_counts()","8570c5f6":"df_new_merchant_trans['category_3'].value_counts()","060a9cd1":"df_hist_trans['merchant_id'].value_counts().head(5)","501b1ce0":"df_new_merchant_trans['merchant_id'].value_counts().head(5)","15caf485":"for df in [df_train, df_test]:\n    df['year'] = df['first_active_month'].dt.year\n    df['month'] = df['first_active_month'].dt.month\n    df['dayofweek'] = df['first_active_month'].dt.dayofweek","7fe88a53":"df_train.head()","8092e346":"features = ['feature_1', 'feature_2', 'feature_3', 'year', 'month', 'dayofweek']\n\nparam = {\n    'objective': 'reg:linear'\n    ,'booster' : \"gbtree\"\n    ,'eta': 0.01\n    ,'max_depth':10\n    ,'subsample':0.9\n    ,'colsample_bytree':0.7\n    ,'silent' : 1\n    ,'eval_metric': 'rmse'\n    #,'tree_method':'gpu_hist'\n    #,'predictor':'gpu_predictor'\n}\n\nX_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train['target'], test_size = 0.3, random_state = 42)\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndvalid = xgb.DMatrix(X_test, y_test)\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n\n\ngbm = xgb.train(\n            param, \n            dtrain, \n            7000,\n            evals=watchlist,\n            early_stopping_rounds=100, \n            verbose_eval=100\n)","4e448fcd":"predictions = gbm.predict(xgb.DMatrix(df_test[features]))\npredictions","e2bea5a9":"sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv(\"..\/submission.csv\", index=False)","96fcb44f":"## Submit","19d2b5b1":"## TO DO : \n## Melhorar o EDA; fazer cruzamentos com outras tabelas(principalmente hist e novos); fazer agrega\u00e7\u00f5es; adi\u00e7\u00e3o de novas colunas; trazer as novas colunas para os dados de train e test; testar outros modelos como lightgbm... etc...","2eb015f1":"## Head","ed9f1ee0":"## Check NA","fe623e4f":"## Count NA","1a0aaa3d":"## Model","64ce35ae":"## Data Preparation","cd30df52":"## Load Data"}}