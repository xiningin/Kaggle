{"cell_type":{"aee7b0f6":"code","21427014":"code","424a070b":"code","90ce5a2f":"code","b871ca93":"code","01c81876":"code","68ea0229":"code","cc2fb1d1":"code","0051e134":"code","fd3aafc6":"code","86f8f9bc":"code","ed35af62":"code","149917f6":"code","9a68f506":"markdown","a72ffaef":"markdown","bd73d42d":"markdown","b5c08c56":"markdown","233dced6":"markdown","ecb65b05":"markdown","19921e78":"markdown","50b5372e":"markdown"},"source":{"aee7b0f6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *","21427014":"image_size = (48, 48)\nbatch = 32\n\ntrain = keras.preprocessing.image_dataset_from_directory(\n    '..\/input\/chessman-image-dataset\/chessman-image-dataset\/Chessman-image-dataset\/Chess\/',\n    validation_split=.2,\n    subset='training',\n    seed=42,\n    image_size=image_size,\n    batch_size=batch,\n    label_mode='categorical'\n)","424a070b":"validation = keras.preprocessing.image_dataset_from_directory(\n    '..\/input\/chessman-image-dataset\/chessman-image-dataset\/Chessman-image-dataset\/Chess\/',\n    validation_split=.2,\n    subset='validation',\n    seed=42,\n    image_size=image_size,\n    batch_size=batch,\n    label_mode='categorical'\n)","90ce5a2f":"def display_samples(dataset, n_samples, classes_name):\n    plt.figure(figsize=(10, 10))\n    for images, labels in dataset.take(1):\n        for i in range(n_samples):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.title(classes_name[np.argmax(labels[i])])\n            plt.axis(\"off\")","b871ca93":"display_samples(train, 9, train.class_names)\nfor images, labels in train.take(1):\n        for i in range(1):\n            print(images[i].shape)\n            ","01c81876":"display_samples(validation, 9, validation.class_names)","68ea0229":"class_names = train.class_names\nlabels = np.array([])\nfor _, label in train:\n    labels = np.concatenate((labels, np.argmax(label, axis=-1)))\n_, counts = np.unique(labels, return_counts=True)","cc2fb1d1":"total = counts.sum()\nprint(\"Frequ\u00eancia de cada pe\u00e7a\")\nfor i in range(len(counts)):\n    print(f'{class_names[i]}: {counts[i]}({counts[i] \/ total:.2f}%)')","0051e134":"input_shape = (image_size[0], image_size[1], 3)\nreg = keras.regularizers.l2(0.0005)\n\nmodel = keras.Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=image_size + (3,), kernel_regularizer=reg))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(BatchNormalization(axis=3))\n# model.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(BatchNormalization(axis=3))\n# model.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(train.class_names), activation='softmax'))\n\n\nmodel.summary()","fd3aafc6":"model.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=\"adam\",\n    metrics=[\"accuracy\"]\n)\n\nepochs = 40\nmodel.fit(\n    train,\n    epochs=epochs,\n    validation_data=validation\n);","86f8f9bc":"epochs_range = [i+1 for i in range(epochs)]\nplt.plot(epochs_range, model.history.history['accuracy'], '-o', label='Train')\nplt.plot(epochs_range, model.history.history['val_accuracy'], '-x',label='Validation')\n\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\n\nplt.legend();","ed35af62":"y_pred = np.argmax(model.predict(validation), axis=-1)\n\npredictions = np.array([])\nlabels =  np.array([])\nfor x, y in validation:\n    predictions = np.concatenate([predictions, np.argmax(model.predict(x), axis=-1)])\n    labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])","149917f6":"conf = tf.math.confusion_matrix(labels=labels, predictions=predictions)\nsns.heatmap(conf, annot=True, cmap='Blues', yticklabels=class_names, xticklabels=class_names);","9a68f506":"## Constru\u00e7\u00e3o do Modelo","a72ffaef":"## Explorando os dados","bd73d42d":"## Treinamento","b5c08c56":"## Avalia\u00e7\u00e3o do modelo","233dced6":"## Carregando os Dados","ecb65b05":"### Matriz de Confus\u00e3o","19921e78":"### Curvas de Treino e Valida\u00e7\u00e3o","50b5372e":"# Minera\u00e7\u00e3o de Dados - Trabalho Pr\u00e1tico 3\n\n## Objetivos\n1. Desenvolver um projeto para classifica\u00e7\u00e3o de imagens (dada uma imagem seu classificador deve informar se ela pertence a uma classe ou a outra, voc\u00ea tamb\u00e9m pode trabalhar com as probabilidades de uma observa\u00e7\u00e3o pertencer a uma determinada classe) ou para detec\u00e7\u00e3o de objetos em imagens.\n2. Comparar os algoritmos escolhidos com conjuntos de dados reais utilizando m\u00e9tricas de avalia\u00e7\u00e3o vistas ou n\u00e3o na disciplina.\n3. Explicar\/motivar a escolha da arquitetura da CNN escolhida."}}