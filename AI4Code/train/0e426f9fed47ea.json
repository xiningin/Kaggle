{"cell_type":{"92111e61":"code","d06ab262":"code","e38eb5b0":"code","fe484393":"code","cf399f70":"code","f86a3709":"code","fa2344c8":"markdown","bd31d3f0":"markdown","cac5694a":"markdown","8e9b0a17":"markdown","5406d8ee":"markdown","530c3145":"markdown"},"source":{"92111e61":"import bq_helper\nimport pandas as pd\n# create a helper object for our bigquery dataset\nchicago_crime = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"chicago_crime\")","d06ab262":"chicago_crime.list_tables()","e38eb5b0":"chicago_crime.table_schema(\"crime\")","fe484393":"chicago_crime.head(\"crime\")","cf399f70":"chicago_crime.head(\"crime\",selected_columns=[\"unique_key\",\"case_number\",\"date\"],num_rows=10,start_index=2)","f86a3709":"q = \"\"\"select case_number from `bigquery-public-data.chicago_crime.crime` where district = 4 \"\"\"\nchicago_crime.estimate_query_size(q)\nchicago_crime.query_to_pandas(q)","fa2344c8":"## Run the Query\n\n<h4>BigQueryHelper.query_to_pandas(query):<\/h4> This method takes a query and returns a Pandas dataframe.\n\n<h4>BigQueryHelper.query_to_pandas_safe(query, max_gb_scanned=1):<\/h4> This method takes a query and returns a Pandas dataframe only if the size of the query is less than the upperSizeLimit (1 gigabyte by default).\n\nYou can do this with the  <h4>BigQueryHelper.estimate_query_size()<\/h4> method.\nOne way to help avoid this is to estimate how big your query will be before you actually execute it.","bd31d3f0":"## Information about table\nwe're looking at the information on the table called \"crime\". Note that other databases will have different table names, so you will not always use \"crime.\"","cac5694a":"SQL is the primary programming language used with databases, and it is an important skill for any data scientist.\n\nBigQuery is a database that lets you use SQL to work with very large datasets.\n\n1.   You can **import bq_helper** in your kernel with the command.\n\n2 . Create an object  using bq_helper.BigQueryHelper(......)","8e9b0a17":"## Get the selected columns by number of rows and start with specified index.","5406d8ee":"## Get the First couple of rows\n","530c3145":"## Structure of your Dataset\nSchema: A description of how data is organized within a dataset.\n\nBigQuery datasets can be very large, and there are some restrictions on how much data you can access.\n\n#### NOTE : Each Kaggle user can scan 5TB every 30 days for free. If you go over your quota you're going to have to wait for it to reset.\n"}}