{"cell_type":{"4bfee7e7":"code","e27943d8":"code","9facb3b9":"code","dc6f36f4":"code","a53c387b":"code","04c6ef4f":"code","03a693e9":"code","e12af648":"code","f14d2460":"code","2df11cbe":"code","2961413b":"code","16dbece8":"code","4e1d7cc8":"code","ec3a1f0a":"code","247b787c":"code","2f29c926":"code","362bdaf0":"code","ce24c881":"code","f7029700":"code","680e70d6":"code","0a1aa145":"code","b8e00b08":"code","ff517895":"code","fb79de21":"code","06b9731f":"code","49e92a8b":"code","23ea5649":"code","e4796bd2":"code","a7d6b170":"code","595f65e6":"code","1301b49c":"markdown","1621a362":"markdown","0a22e81a":"markdown","e32eb3cf":"markdown","44ddbae3":"markdown","4edb460a":"markdown","0338735d":"markdown","1d39d46a":"markdown","07c6bb5f":"markdown","1f5a4392":"markdown","06354fec":"markdown","e10bbf30":"markdown","685dd7bc":"markdown","fd7c8648":"markdown","d8ab5560":"markdown","00c6fa74":"markdown","746b9b9d":"markdown","a5153f45":"markdown"},"source":{"4bfee7e7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import date, datetime\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nimport os\nprint(os.listdir(\"..\/input\"))\n","e27943d8":"loanData= pd.read_csv('..\/input\/LoanStats.csv',header=1,error_bad_lines=False,skipfooter=2,engine='python')\nloanData.isnull().all()\nloanData.dropna(axis=1,how='all',inplace=True)  # drop all null columns\npd.set_option('display.max_columns', 65)\nloanData.head()","9facb3b9":"loanData.drop(['emp_title','desc','title','application_type'],axis=1,inplace=True) #carries no useful info which can affect loan terms\nloanData['id']=np.arange(1,42537)\n\n","dc6f36f4":"print(loanData.policy_code.unique())  # drop it since it contains only 1 value so doesn't make any impact\nprint(loanData.loan_status.unique())\nprint(loanData.home_ownership.unique())\nprint(loanData.verification_status.unique())\nprint(loanData.pymnt_plan.unique())  ## drop it since it contains only 1 value i.e 'n' , so doesn't make any impact\nprint(loanData.disbursement_method.unique())   # drop it since it contains only 1 value i.e 'Cash' , so doesn't make any impact\nprint(loanData.hardship_flag.unique())         # drop it since it contains only 1 value i.e 'N' , so doesn't make any impact\nprint(loanData.tax_liens.unique())\nprint(loanData.pub_rec_bankruptcies.unique())\nprint(loanData.initial_list_status.unique())   #  drop it since it contains only 1 value i.e 'f' , so doesn't make any impact\n\n\n","a53c387b":"loanData.drop(['policy_code','pymnt_plan','disbursement_method','hardship_flag','initial_list_status'],axis=1,inplace=True) # since contain only 1 type of value so doesn't make any impact\n","04c6ef4f":"loanData['int_rate']=loanData.int_rate.str.extract('(\\d+.\\d+)')\n\nloanData['int_rate']=loanData.int_rate.astype('float64')\nloanData.int_rate.dtype","03a693e9":"loanData.loc[loanData.loan_status.str.contains('Fully Paid',na=False),'loan_status']='Paid'   \nloanData.loc[loanData.loan_status.str.contains('Charged Off',na=False),'loan_status']='ChargedOff'  \nloanData.loan_status.unique()\n","e12af648":"loanData['loan_status'] =loanData.loan_status.astype('category')\nloanData.loan_status.unique()","f14d2460":"loanData.loc[loanData.verification_status.str.contains('Not Verified',na=False),'verification_status']='NotVerify'  \nloanData.loc[loanData.verification_status.str.contains('Verified',na=False),'verification_status']= 'Verify'   \n","2df11cbe":"loanData['verification_status'] =loanData.verification_status.astype('category')\nloanData.verification_status.unique()","2961413b":"loanData['term'] =loanData.term.str.extract('(\\d+)')\nloanData['emp_length'] =loanData.emp_length.str.extract('(\\d+)')\nloanData['revol_util'] =loanData.revol_util.str.extract('(\\d+.\\d+)')\nloanData['sub_grade']=loanData.sub_grade.str.extract('(\\d+)')\n","16dbece8":"loanData.term.dropna(inplace=True)\nloanData['term']=loanData.term.astype('int')\n#loanData['grade']=loanData.grade.astype('category')\nloanData['home_ownership']=loanData.home_ownership.astype('category')\nloanData['revol_util']=loanData.revol_util.astype('float')\n#loanData['sub_grade']=loanData.sub_grade.astype('int')\n","4e1d7cc8":"loanData.emp_length.fillna(0,inplace=True)\nloanData['emp_length']=loanData.emp_length.astype('int')\nloanData.emp_length.unique()","ec3a1f0a":"# handling date columns\n\nloanData['issue_d'] = pd.to_datetime(loanData['issue_d'])\nloanData['earliest_cr_line'] = pd.to_datetime(loanData['earliest_cr_line'])\nloanData['last_pymnt_d'] = pd.to_datetime(loanData['last_pymnt_d'])\nloanData['last_credit_pull_d'] = pd.to_datetime(loanData['last_credit_pull_d'])\nloanData['settlement_date'] = pd.to_datetime(loanData['settlement_date'])\nloanData['debt_settlement_flag_date'] = pd.to_datetime(loanData['debt_settlement_flag_date'])\nloanData['next_pymnt_d'] = pd.to_datetime(loanData['next_pymnt_d'])\n\n             ","247b787c":"loanData.loc[loanData.settlement_amount.notnull(),['loan_amnt','issue_d','loan_status','settlement_status','settlement_amount','settlement_percentage','settlement_term','settlement_date','debt_settlement_flag_date ']]\n","2f29c926":"loanData.drop(['debt_settlement_flag_date','settlement_term','settlement_status','settlement_date','settlement_percentage','settlement_amount'],axis=1,inplace=True) # since doesn't have enough values \n","362bdaf0":"loanData.tax_liens.value_counts()\n","ce24c881":"loanData.drop('tax_liens',axis=1,inplace=True)","f7029700":"df=loanData.loc[:30000,['loan_amnt','funded_amnt','funded_amnt_inv']]\nsns.pairplot(vars=['loan_amnt','funded_amnt','funded_amnt_inv'],data=df)","680e70d6":"df=loanData.groupby('purpose').id.count().reset_index()\ndf.rename(columns={'id':'no_of_loans'},inplace=True)\nplt.figure(figsize=(10,10))\nplt.pie(df.no_of_loans,labels=df.purpose,autopct='%.2f%%');\ndf.plot.bar(x='purpose',y='no_of_loans',figsize=(10,6));\n","0a1aa145":"df=loanData.groupby('addr_state').id.count().sort_values().reset_index()\ndf.plot.bar('addr_state','id',figsize=(15,6))\nplt.title('loan distribution by state')\ndf.head()","b8e00b08":"df=loanData.groupby(loanData.issue_d.dt.year).int_rate.mean()\ndf.plot(kind='line',figsize=(10,6))\nplt.title('Change in Avg. Interest Rate by year');\n\n\n","ff517895":"df=loanData.groupby(loanData.issue_d.dt.year).id.count()\ndf.plot(kind='line',figsize=(10,6))\nplt.title('Total loans taken per year');\nplt.ylabel('No of loans issued')\ndf.head()\n","fb79de21":"df=loanData.groupby(loanData.issue_d.dt.month).id.count().sort_values()\ndf.plot(kind='line',figsize=(8,6));\nplt.title('Total No of loans taken by month ')\nplt.xlabel('Month');\nplt.ylabel('No of loans issued');\n\n# maximum loans are taken during end of the year","06b9731f":"df=loanData.groupby('grade').loan_status.value_counts().unstack()\ndf.plot.bar()\nplt.title('No of loans paid and charged_off according to grade');","49e92a8b":"loanData.pivot_table(index='grade',columns='sub_grade',values='int_rate').plot.bar(figsize=(10,6))\nplt.ylabel('Interest rate');\n\n","23ea5649":"plt.figure(figsize=(10,6))\nsns.boxplot(data=loanData, x='grade',y='int_rate',hue='loan_status')\nplt.title('Interest Rate IQR(range) with grade');","e4796bd2":"df=loanData.groupby('home_ownership').loan_status.value_counts().unstack()\ndf.plot.bar(figsize=(10,6))\nplt.title('No of loans paid and charged off according to home ownership')\ndf","a7d6b170":"sns.countplot(data=loanData,x='verification_status')\nplt.title('Source verification of loans');\n","595f65e6":"plt.figure(figsize=(10,6))\n\nsns.distplot(loanData.loan_amnt.fillna(0))","1301b49c":"### Relation between 'loan_amnt', 'funded_amnt', 'funded_amnt_inv'  fields\n       loan_amnt >= funded_amnt >= funded_amnt_inv","1621a362":"### Geographical distribution of loans by state - CA state receives maximum loans","0a22e81a":"### Data Cleaning and Exploratory Analysis \n\nIn machine learning, you clean up the data and turn raw data into features from which you can derive the pattern. There are methods available to extract features that will be covered in upcoming sessions but it's very important to build the intuition. The process of data cleaning and visualization helps with that. In this assignment, we will try to manually identify the important features in the given dataset. \n\n### Dataset: Lending Club data\n\nhttps:\/\/www.lendingclub.com\/info\/download-data.action\n\nYears of data to download: 2007-2011\n\nLoad the Lending Club data into a pandas dataframe. The data contains 42538 rows and 145 columns. Not all these columns contain meaningful (or any) information so they need to be cleaned. The loans are categorized into different grades and sub-grades. It would be interesting to see whether they have any impact on the interest rates or not.\nThe process should lead us into default prediction, and finding the columns that directly predict how the loan will behave. These would be our most important features.\n\n\n\n\n\n","e32eb3cf":"### total loans paid in each grade","44ddbae3":"### cleaning loan_status and verification_status columns","4edb460a":"### loan status according to home ownership","0338735d":"### Loan Grade and subgrade Distribution (by interest rate)\n     \n     subgrades are distributed according to interest rates for each grade category i.e increase in subgrade with increase in int_rate for a particular grade category ","1d39d46a":"### Trend in Interest Rate by Year\n      \n       highest interest rate average in year 2009 and then great fall till during 2009-10","07c6bb5f":"### handling sparsely populated column having less than 200 values","1f5a4392":"### Extracting useful info from columns by cleaning ","06354fec":"### Number of loans with verified source","e10bbf30":"## Lending Club Loan Data Analysis\n","685dd7bc":"### % of loans for different purposes","fd7c8648":"### int_rate to numeric","d8ab5560":"### handling date columns","00c6fa74":"This is my first ever submission on Kaggle. This was all based on pandas and visualisation library, I am yet to learn machine learning models hope to come with more analysis in near future using different techniques.","746b9b9d":"### Yearly loan distribution\n      \n       # max loans are taken in 2011","a5153f45":"### loan distribution by its amount\n    Maximum loans are taken in range $ 5000-15000 "}}