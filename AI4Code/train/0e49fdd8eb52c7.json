{"cell_type":{"6da29f53":"code","16b945a2":"code","6552dca8":"code","f8ff12f7":"code","b2b8a1c6":"code","e8692fe8":"code","d80744d7":"code","92b4b744":"code","eb38f6dd":"code","51904dd0":"code","64958970":"code","8638c5bd":"code","2dc34b99":"code","1f11a7c6":"code","ae2007b0":"markdown","9616c136":"markdown","78a26700":"markdown"},"source":{"6da29f53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16b945a2":"!pip3 install face_recognition","6552dca8":"import dlib\nimport face_recognition\nimport os\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","f8ff12f7":"ROOT = '..\/input\/5-faces-dataset\/Five_Faces\/'","b2b8a1c6":"# print number of images per class\n\nflds = [ROOT+f for f in os.listdir(ROOT)]\nprint('Number of images per subject')\nprint('Bill Gates',len(os.listdir(flds[0])))\nprint('Jack Ma',len(os.listdir(flds[1])))\nprint('Narendra Modi',len(os.listdir(flds[2])))\nprint('Donald Trump',len(os.listdir(flds[3])))\nprint('Elon Musk',len(os.listdir(flds[4])))","e8692fe8":"face1 = face_recognition.load_image_file(ROOT + 'jack\/jack10.jpg')\nface2 = face_recognition.load_image_file(ROOT + 'gates\/gates1.jpg')\nface3 = face_recognition.load_image_file(ROOT + 'jack\/jack1.jpg')\n\nface_encd1 = face_recognition.face_encodings(face1)[0]\nface_encd2 = face_recognition.face_encodings(face2)[0]\nface_encd3 = face_recognition.face_encodings(face3)[0]\n\nfaces = {'Encoding1': face1, 'Encoding2': face2, 'Predited': face3}\nencd = face_recognition.compare_faces([face_encd1, face_encd2], face_encd3)\nf, axs = plt.subplots(1,3)\nplt.tight_layout()\nfor i, key in enumerate(faces.keys()):\n  axs[i].imshow(faces[key])\n  axs[i].set_title(key)\n  if i ==2: \n     axs[i].set_title(encd)","d80744d7":"# create 5 encodings(1 per subject) and compare with random faces from dataset\n\nface1 = face_recognition.load_image_file(ROOT +'jack\/jack10.jpg')\nface2 = face_recognition.load_image_file(ROOT +'gates\/gates1.jpg')\nface3 = face_recognition.load_image_file(ROOT +'modi\/modi103.jpg')\nface4 = face_recognition.load_image_file(ROOT +'musk\/musk104.jpg')\nface5 = face_recognition.load_image_file(ROOT +'trump\/donald trump speech106.jpg')\n\nrandom_face1 = face_recognition.load_image_file(ROOT +'jack\/jack109.jpg')\nrandom_face2 = face_recognition.load_image_file(ROOT +'gates\/gates123.jpg')\nrandom_face3 = face_recognition.load_image_file(ROOT +'musk\/musk121.jpg')\n\nface_encd1 = face_recognition.face_encodings(face1)[0]\nface_encd2 = face_recognition.face_encodings(face2)[0]\nface_encd3 = face_recognition.face_encodings(face3)[0]\nface_encd4 = face_recognition.face_encodings(face4)[0]\nface_encd5 = face_recognition.face_encodings(face5)[0]\n\nrnd_encd1 = face_recognition.face_encodings(random_face1)[0]\nrnd_encd2 = face_recognition.face_encodings(random_face2)[0]\nrnd_encd3 = face_recognition.face_encodings(random_face3)[0]\n\nfaces = [face_encd1,face_encd2,face_encd3,face_encd4,face_encd5]\n\nencd1 = face_recognition.compare_faces(faces, rnd_encd1)\nencd2 = face_recognition.compare_faces(faces, rnd_encd2)\nencd3 = face_recognition.compare_faces(faces, rnd_encd3)\n\nprint('actual 1',encd1)\nprint('actual 2',encd2)\nprint('actual 4',encd3)","92b4b744":"# create face embeddings for all images\n\nembeddings = [] # store all embeddings\ncl_lm = [] # per class number of embeddings detected\n\nfor fld in flds:\n  for img in os.listdir(fld):\n      try:\n        image = face_recognition.load_image_file(fld+'\/'+img)\n        face_encodings = face_recognition.face_encodings(image)[0] # to 128 encodings of single face\n      except:\n        continue\n      embeddings.append(face_encodings)\n  print(len(embeddings)) # print to indexes of number of images, how many faces we added per class\n  cl_lm.append(len(embeddings)) # make note for making Y","eb38f6dd":"# make y using cl_lm\n\nY = np.zeros(len(embeddings))\nY[:cl_lm[0]] = 1\nY[cl_lm[0]:cl_lm[1]] = 2\nY[cl_lm[1]:cl_lm[2]] = 3\nY[cl_lm[2]:cl_lm[3]] = 4\nY[cl_lm[3]:cl_lm[4]] = 5","51904dd0":"# number of embeddings\n\nprint(len(embeddings))\nprint(len(Y)) ","64958970":"# split the data\n\nX_train, X_test, Y_train, Y_test = train_test_split(embeddings, Y, test_size=0.2)","8638c5bd":"# predict using all embeddings(~700)\n\ncorrect = 0\nyhat = 0\n\ndef predict_results(result):\n  ids = [i for i, val in enumerate(result) if val] \n  values, counts = np.unique(Y[ids], return_counts=True)\n  yhat = values[np.argmax(counts)]\n  return yhat\n\nfor test_embedding, y in zip(X_test, Y_test):\n\n  result = face_recognition.compare_faces(embeddings, test_embedding) # a big bool array of 710\n  yhat = predict_results(result)\n  if yhat == y:\n    correct+=1\nprint('Using all embeddings')\nprint('{0} correct out of {1}'.format(correct, len(Y_test)))","2dc34b99":"len(faces) # reminder","1f11a7c6":"# predict with only 5 embeddings\n\ncorrect = 0\nyhat = 0\n\nfor test_embedding, y in zip(X_test, Y_test):\n\n  result = face_recognition.compare_faces(faces, test_embedding)\n  yhat = [i for i,val in enumerate(result) if val]\n  if yhat:\n    if yhat == y:\n      correct+=1\nprint('using 5 faces embedding')\nprint('{0} correct out of {1}'.format(correct, len(Y_test)))","ae2007b0":"Sample Output","9616c136":"Predict Result","78a26700":"Create 128 size Embeddings and compare images"}}