{"cell_type":{"1bbe4fda":"code","e762c503":"code","f048d6f1":"code","13711b99":"code","2de7479b":"code","14d53ab6":"code","ae8ef981":"code","eb533bff":"code","64329aac":"code","dd96210c":"code","bc184fa9":"code","397873d9":"code","59542e6b":"code","ae458cc1":"code","0d4ff979":"code","5bf688ee":"code","adb865d7":"code","2a163493":"code","d7e1d06e":"code","a296d85d":"code","21b63f07":"code","961bb751":"code","d38b3999":"code","12f38561":"code","752ec884":"code","eba6e82f":"code","a668add3":"code","1a5ee1b9":"code","f6ddff07":"code","acca61d8":"code","f16bef2d":"code","26a6499c":"code","010a22d6":"code","4980cc84":"code","2f460630":"code","a26ae447":"code","507e0807":"code","7a1a68c9":"code","6fa6401e":"code","9c13ebc5":"code","7c2f665d":"code","d7826e83":"markdown"},"source":{"1bbe4fda":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nimport warnings\nfrom sklearn import preprocessing","e762c503":"%matplotlib inline\nwarnings.filterwarnings('ignore')","f048d6f1":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","13711b99":"train.head(2)","2de7479b":"train.shape","14d53ab6":"train.describe()","ae8ef981":"for i in train.columns:\n    print (i + \": \"+str(sum(train[i].isnull()))+\" missing values\")","eb533bff":"for i in test.columns:\n    print (i + \": \"+str(sum(test[i].isnull()))+\" missing values\")","64329aac":"# Looking at categorical values\ndef cat_exploration_train(column):\n    return train[column].value_counts()\ndef cat_exploration_test(column):\n    return test[column].value_counts()","dd96210c":"# Imputing the missing values\ndef cat_imputation_train(column, value):\n    train.loc[train[column].isnull(),column] = value\ndef cat_imputation_test(column, value):\n    test.loc[test[column].isnull(),column] = value","bc184fa9":"# first degree or hnd occurs the most\ncat_exploration_train('Qualification')","397873d9":"# first degree or hnd occurs the most\ncat_exploration_test('Qualification')","59542e6b":"# since first degree or hnd occurs highest, null value = this\ncat_imputation_train('Qualification', 'First Degree or HND')","ae458cc1":"# since first degree or hnd occurs highest, null value = this\ncat_imputation_test('Qualification', 'First Degree or HND')","0d4ff979":"for i in train.columns:\n    print (i + \": \"+str(sum(train[i].isnull()))+\" missing values\")","5bf688ee":"for i in test.columns:\n    print (i + \": \"+str(sum(test[i].isnull()))+\" missing values\")","adb865d7":"cat_exploration_train('Last_performance_score')","2a163493":"cat_exploration_test('Last_performance_score')","d7e1d06e":"train['age'] = 2019 - train['Year_of_birth']\ntrain.drop('Year_of_birth', axis=1)","a296d85d":"test['age'] = 2019 - test['Year_of_birth']\ntest.drop('Year_of_birth', axis=1)","21b63f07":"train.columns","961bb751":"# employee has won both awards and met target\ntrain[\"Target&Award\"] = np.where(((train[\"Targets_met\"]==1) & (train[\"Previous_Award\"]==1)),1,0)\ntest[\"Target&Award\"] = np.where(((test[\"Targets_met\"]==1) & (test[\"Previous_Award\"]==1)),1,0)","d38b3999":"train.columns","12f38561":"test.columns","752ec884":"train_features_eng = train\ntrain_features_eng = train_features_eng.drop(['EmployeeNo','Channel_of_Recruitment','State_Of_Origin','Year_of_birth','No_of_previous_employers'],axis=1) #features that are not needed","eba6e82f":"test_features_eng = test\ntest_features_eng = test_features_eng.drop(['EmployeeNo','Channel_of_Recruitment','State_Of_Origin','Year_of_birth','No_of_previous_employers'],axis=1) #features that are not needed","a668add3":"train_features_eng.head(2)","1a5ee1b9":"test_features_eng.head(2)","f6ddff07":"train[train['Trainings_Attended'] > 5] = 6\ntest[test['Trainings_Attended'] > 5] = 6","acca61d8":"# Encode all categorical features\ntrain_features_eng=pd.get_dummies(train_features_eng, columns=[\"Division\",\"Qualification\", \"Foreign_schooled\", \"Marital_Status\", \"Past_Disciplinary_Action\", \"Previous_IntraDepartmental_Movement\", \"Gender\"], \n                                  prefix=[\"Div\", \"Qua\", \"ForSc\", \"MS\", \"PsDA\", \"PrvID\", \"Gd\"])\ntrain_features_eng.head()","f16bef2d":"# Encode all categorical features\ntest_features_eng=pd.get_dummies(test_features_eng, columns=[\"Division\",\"Qualification\", \"Foreign_schooled\", \"Marital_Status\", \"Past_Disciplinary_Action\", \"Previous_IntraDepartmental_Movement\", \"Gender\"], \n                                  prefix=[\"Div\", \"Qua\", \"ForSc\", \"MS\", \"PsDA\", \"PrvID\", \"Gd\"])\ntest_features_eng.head()","26a6499c":"train_features_eng.info()","010a22d6":"x_train = train_features_eng.drop([\"Promoted_or_Not\"],axis=1)\ny_train = train_features_eng['Promoted_or_Not']","4980cc84":"from sklearn import preprocessing\n# Get column names first\n# names = x_train.columns\n# Create the Scaler object\nstd_scale = preprocessing.StandardScaler().fit(x_train)\nx_train_norm = std_scale.transform(x_train)\n\n\ntraining_norm_col = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns) \nx_train.update(training_norm_col)\nprint (x_train.head())","2f460630":"x_test = test_features_eng","a26ae447":"# Normalize Testing Data by using mean and SD of training set\nx_test_norm = std_scale.transform(x_test)\ntesting_norm_col = pd.DataFrame(x_test_norm, index=x_test.index, columns=x_test.columns) \nx_test.update(testing_norm_col)\nprint (x_test.head())","507e0807":"x_train.head(2) ","7a1a68c9":"x_test.head(2) ","6fa6401e":"xgclass1 = xgb.XGBClassifier(max_depth=9, n_estimators=455, learning_rate=0.015)\nxgclass2 = xgb.XGBClassifier(max_depth=9, base_estimator=xgclass1, n_estimators=455, learning_rate=0.015)\n# xgclass3 = xgb.XGBClassifier(max_depth=9, base_estimator=xgclass2, n_estimators=455, learning_rate=0.015)\nxgclass = xgb.XGBClassifier(max_depth=9, base_estimator=xgclass2, n_estimators=455, learning_rate=0.015)\nxgclass.fit(x_train,y_train)","9c13ebc5":"predictions = xgclass.predict(x_test)","7c2f665d":"predictions = predictions.astype(int)\nsubmission = pd.DataFrame({\n\"EmployeeNo\": test[\"EmployeeNo\"],\n\"Promoted_or_Not\": predictions\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","d7826e83":"# __Data Science Nigeria Staff Promotion Algorithm__"}}