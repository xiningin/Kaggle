{"cell_type":{"b38417e8":"code","419cf0d0":"code","a06b009c":"code","dffbd295":"code","871719e3":"code","04b6d4ba":"code","d6fcb88f":"code","7b3b2da9":"code","f743d546":"code","8dbe65c0":"code","2d664782":"code","bce18860":"code","cfa49cbb":"code","6c1bdc45":"code","c793241e":"code","d08366a8":"code","3044553d":"code","354a966f":"code","6e2c3a73":"code","bd6a1458":"code","71c31d17":"code","f156eb0f":"code","09202462":"markdown","d1c94cea":"markdown","ce502168":"markdown","71d9c00b":"markdown","378a69e8":"markdown","c40e120f":"markdown","d93dff7c":"markdown","521b383d":"markdown"},"source":{"b38417e8":"from piltonumpy_helper import pil_to_numpy\nimport os; import keras; import numpy as np; import pandas as pd; import shutil; from PIL import Image; import cv2\nfrom tqdm import tqdm\nfrom skimage.transform import resize, rescale\n\nimport matplotlib.pyplot as plt; import seaborn as sns;\n\nfrom keras.layers import *\nfrom keras.models import *\n\nfrom tensorflow.keras.layers import Add\nfrom keras.preprocessing.image import ImageDataGenerator","419cf0d0":"DATA_DIR = '\/kaggle\/input\/the-car-connection-picture-dataset'\nLOW_RES = '\/kaggle\/working\/train_lowres'","a06b009c":"os.mkdir('\/kaggle\/working\/train_lowres')","dffbd295":"os.chdir('\/kaggle\/working\/train_lowres')","871719e3":"files = os.listdir(DATA_DIR)","04b6d4ba":"len(files)","d6fcb88f":"files.sort()","7b3b2da9":"import multiprocessing\nfrom multiprocessing import Process","f743d546":"\ndef make_low_res(files):\n    for file in tqdm(files):\n        img = Image.open(DATA_DIR + '\/' + file)\n        img = pil_to_numpy(img)\n        #img = img\/255.0\n        img = cv2.resize(img, (256, 256))\n        img = cv2.resize(cv2.resize(img, None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_CUBIC), None, fx = 2, fy = 2, interpolation = cv2.INTER_CUBIC)\n        im = Image.fromarray(img)\n        im.save(file)\n    ","8dbe65c0":"import time","2d664782":"# Making the low resolution folder in parallel processing\n\nstart = time.time()\n\np1 = Process(target = make_low_res, args = (files[:15000],))\np2 = Process(target = make_low_res, args = (files[15000:30000],))\np3 = Process(target = make_low_res, args = (files[30000:45000],))\np4 = Process(target = make_low_res, args = (files[45000:60000],))\np5 = Process(target = make_low_res, args = (files[60000:],))\n\np1.start()\np2.start()\np3.start()\np4.start()\np5.start()\n\np1.join()\np2.join()\np3.join()\np4.join()\np5.join()\n\nend = time.time()\n\nprint('time elapsed -> ', end - start)","bce18860":"len(os.listdir('\/kaggle\/working\/train_lowres'))","cfa49cbb":"\n\ndef fetch_data_generator(files, batch_size = 64):\n    while True:\n        #\n        batch_files = np.random.choice(files, batch_size)\n        \n        batch_x = [] ; batch_y = [];\n        \n        for file in batch_files:\n            img = cv2.resize(pil_to_numpy(Image.open(DATA_DIR + '\/' + file)).astype(float), (256,256))\n            img_low = pil_to_numpy(Image.open(LOW_RES + '\/' + file)).astype(float)\n            \n            batch_x.append(img_low\/255.0)\n            batch_y.append(img\/255.0)\n        \n                \n        yield np.array(batch_x), np.array(batch_y)","6c1bdc45":"\"\"\"encoder = Sequential()\nencoder.add(Conv2D(64, (3,3) , padding = 'same', activation = 'relu', input_shape = (256, 256, 3)))\nencoder.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu'))\nencoder.add(MaxPooling2D((2,2), padding = 'same'))\nencoder.add(Dropout(0.3))\nencoder.add(Conv2D(128, (3,3), padding = 'same', activation = 'relu'))\nencoder.add(Conv2D(128, (3,3), padding = 'same', activation = 'relu'))\nencoder.add(MaxPooling2D((2,2), padding = 'same'))\nencoder.add(Conv2D(256, (3,3), padding = 'same', activation = 'relu'))\nencoder.summary()\"\"\"","c793241e":"#autoencoder = encoder","d08366a8":"#autoencoder.summary()","3044553d":"# encoder\n\nkeras.backend.set_image_data_format('channels_last')\n\ni1 = Input(shape = (256,256,3))\nl1 = Conv2D(64, (3,3), padding = 'same', activation = 'relu')(i1)\nl2 = Conv2D(64, (3,3), padding = 'same', activation = 'relu')(l1)\nl3 = MaxPooling2D(padding = 'same')(l2)\nl3 = Dropout(0.3)(l3)\nl4 = Conv2D(128, (3,3), padding = 'same', activation = 'relu')(l3)\nl5 = Conv2D(128, (3,3), padding = 'same', activation = 'relu')(l4)\nl6 = MaxPooling2D(padding = 'same')(l5)\nl7 = Conv2D(256, (3,3), padding = 'same', activation = 'relu')(l6)\n\n# decoder\n\nl8 = UpSampling2D()(l7)\nl9 = Conv2D(128, (3,3), padding = 'same', activation = 'relu')(l8)\nl10 = Conv2D(128, (3,3), padding = 'same', activation = 'relu')(l9)\nl11 = Add()([l5, l10])\nl12 = UpSampling2D()(l11)\nl13 = Conv2D(64, (3,3), padding = 'same', activation = 'relu')(l12)\nl14 = Conv2D(64, (3,3), padding = 'same', activation = 'relu')(l13)\nl15 = Add()([l14, l2])\n\n# final layer should have 3 channels which will help to reconstruct the image with better resolution\nl16 = Conv2D(3, (3,3), padding = 'same', activation = 'relu')(l15)\n\nautoencoder = Model(i1, l16)","354a966f":"autoencoder.summary()","6e2c3a73":"autoencoder.compile(optimizer = 'adadelta', loss = 'mean_squared_error')","bd6a1458":"autoencoder.fit_generator(fetch_data_generator(files, 32), steps_per_epoch = len(files)\/\/32, epochs = 10)","71c31d17":"autoencoder.save('trained_10epochs.h5')","f156eb0f":"# Load Model\n# uncomment to load the model with supplied weights & config, i.e., hdf5\n\n#trained_model = keras.models.load_model('my_model.h5')","09202462":"### Make Datagenerators","d1c94cea":"Decoder Network","ce502168":"## Model Creation","71d9c00b":"Encoder Network","378a69e8":"## Data Preprocessing","c40e120f":"the decoder network would be the extension of the encoder ","d93dff7c":"## Training the Model","521b383d":"## Necessary Library Imports"}}