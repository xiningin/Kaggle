{"cell_type":{"111049a1":"code","4838da88":"code","f2d9f693":"code","ce9a5196":"code","ea124897":"code","9620f935":"code","27219bdc":"code","4b41be91":"code","8e7e6227":"code","afdbbf68":"code","63ba1b1d":"code","9e01fa29":"code","6586c089":"code","a65fe5f6":"code","eb8444b6":"code","89395a0c":"code","404a5c39":"code","bbbee5cf":"code","4744f770":"code","552fc58a":"code","76e6db36":"code","3423a466":"code","835c22d2":"code","6cee4773":"code","8b79a36c":"code","71d63c7f":"code","09301bc7":"code","060ac2a8":"code","4f1c67ac":"code","9c711d8c":"code","1ae8ad87":"markdown","df051595":"markdown","a264e6eb":"markdown","554c36db":"markdown","3eafba3a":"markdown","8d8f26ed":"markdown","7d60c975":"markdown","2a68612d":"markdown"},"source":{"111049a1":"!pip install -q efficientnet\n!pip install -q -U albumentations\n!pip install librosa","4838da88":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport efficientnet.tfkeras as efficientnet\n\nimport math\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom albumentations import Compose, RandomBrightness\nfrom albumentations.augmentations import transforms\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\n\nimport albumentations\nimport os\nimport librosa\nimport warnings\nwarnings.filterwarnings('ignore')","f2d9f693":"def extract_features(path):\n    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result=np.hstack((result, zcr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n    \n    return result","ce9a5196":"scaler = StandardScaler()\ntf.random.set_seed(\n    42\n)\nIMAGE_SIZE = 396\nBATCH_SIZE = 8\nINPUT_DIR = '..\/input\/'\nIMG_DIR = '..\/input\/voiceimageall\/VoiceImageAll\/'\nVOICE_DIR = '..\/input\/datavoice\/Data Voice\/'\ndf = pd.read_csv(IMG_DIR + '\/description.csv', index_col=0)\nlabel_mapping = {\n    'neutral': 0,\n    'angry': 1,\n    'happy': 2,\n    'sad': 3\n}\ndf.head()","ea124897":"features = []\nimgs = []\nlabels = []\n\nfor index, item in df.iterrows():\n    filename = item['Filename'].split('.')[0]\n    file_path = VOICE_DIR + item['File_path'].replace('\/content\/drive\/MyDrive\/Data Voice\/', '')\n    \n    feature = extract_features(file_path)\n    features += [feature]\n    \n    img = keras.utils.load_img(IMG_DIR +  filename + '.png', target_size = (IMAGE_SIZE, IMAGE_SIZE))\n    img = keras.utils.img_to_array(img)\n    imgs += [img]\n    \n    label = label_mapping.get(item['Emotion'])\n    labels += [label]\n\n    \nfeatures = np.array(features)\nimgs =  np.array(imgs)\nlabels =  np.array(labels)","9620f935":"figs, axes = plt.subplots(2, 4, figsize=(15, 8))\nfor i in range(2):\n    for j in range(4):\n        axes[i, j].imshow(imgs[i+j]\/255.0)\n        axes[i, j].set_xlabel(\"Class = \" + str(labels[i+j]))\nplt.suptitle(\"QUAN S\u00c1T T\u1eacP D\u1eee LI\u1ec6U\")\nplt.show()","27219bdc":"skf = StratifiedKFold(5, shuffle = True, random_state = 42)\ntrain_id, test_id =  next(skf.split(features, labels))","4b41be91":"plt.figure(figsize=(15, 5))\nplt.hist(x = (labels[train_id], labels[test_id]), stacked=False,label=[\"Train\", \"Test\"], rwidth = 0.9)\nplt.title(\"PH\u00c2N B\u1ed0 D\u1eee LI\u1ec6U \u1ede M\u1ed6I CLASS\")\nplt.xticks([0.15, 1.05, 1.95, 2.85], list(label_mapping.keys()))\nplt.legend()\nplt.ylabel(\"Count\")\nplt.xlabel(\"Class\")\nplt.show()","8e7e6227":"# t\u00e1ch t\u1eadp test v\u00e0 t\u1eadp train\n\ntest_features = features[test_id]\ntest_imgs =  imgs[test_id]\ntest_labels =  labels[test_id]\n\ntrain_features = features[train_id]\ntrain_imgs =  imgs[train_id]\ntrain_labels =  labels[train_id]\n","afdbbf68":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    shear = math.pi * shear \/ 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one\/height_zoom,zero,zero, zero,one\/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))","63ba1b1d":"def transform(image,label, DIM):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n#     DIM = IMAGE_SIZE[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 2. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM\/\/2,-DIM\/\/2,-1), DIM )\n    y = tf.tile( tf.range(-DIM\/\/2,DIM\/\/2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM\/\/2+XDIM+1,DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label","9e01fa29":"def dropout(image, DIM=256, PROBABILITY = 0.75, CT = 8, SZ = 0.2):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image with CT squares of side size SZ*DIM removed\n    \n    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n    if (P==0)|(CT==0)|(SZ==0): return image\n    \n    for k in range(CT):\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        # COMPUTE SQUARE \n        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH\/\/2)\n        yb = tf.math.minimum(DIM,y+WIDTH\/\/2)\n        xa = tf.math.maximum(0,x-WIDTH\/\/2)\n        xb = tf.math.minimum(DIM,x+WIDTH\/\/2)\n        # DROPOUT IMAGE\n        one = image[ya:yb,0:xa,:]\n        two = tf.zeros([yb-ya,xb-xa,3]) \n        three = image[ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n    image = tf.reshape(image,[DIM,DIM,3])\n    return image","6586c089":"def data_preprocessing(feature, img, label):\n    feature = tf.expand_dims(feature, axis=-1)\n    img = tf.cast(img\/255.0, tf.float32)\n    label = tf.one_hot(label, 4)\n    return feature, img, label\n\ndef aug_fn(feature, img, label):   \n    img = tf.image.random_flip_left_right(img, seed=42)\n    img, label = transform(img, label, IMAGE_SIZE)\n    img = dropout(img, IMAGE_SIZE, SZ = 0.15, PROBABILITY=0.75)\n    return feature, img, label","a65fe5f6":"def get_train_dataset(dataset):\n    dataset = dataset.map(data_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.map(aug_fn, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(256, seed=42)\n    \n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset","eb8444b6":"def get_val_dataset(dataset):\n#     dataset = dataset.shuffle(1024)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    dataset = dataset.map(data_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset","89395a0c":"figs, axes = plt.subplots(2, 4, figsize=(15, 8))\nfor i in range(2):\n    for j in range(4):\n        feature, img,  label = data_preprocessing(train_features[i+j], train_imgs[i+j], train_labels[i+j])\n        feature, img,  label = aug_fn(train_features[i+j], train_imgs[i+j], train_labels[i+j])\n\n        axes[i, j].imshow(img\/255.0)\n        axes[i, j].set_xlabel(\"Class = \" + str(label))\nplt.suptitle('QUAN S\u00c1T T\u1eacP D\u1eee LI\u1ec6U SAU AUGMENTATION')\nplt.show()","404a5c39":"class WarmupLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n    def __init__(self, backend_schedule, start_lr, max_lr, end_lr, opt_steps, warmup_steps, lr_scaling):\n\n        self.start_lr = start_lr\n        self.max_lr = max_lr\n        self.end_lr = end_lr\n        self.opt_steps = tf.cast(opt_steps, tf.float32)\n        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n        self.lr_scaling = tf.cast(lr_scaling, tf.float32)\n        self.backend_lr = backend_schedule\n        \n        self.warmup_incremental = (self.max_lr - self.start_lr) \/ tf.math.reduce_max([self.warmup_steps, 1.0]) * tf.cast(self.warmup_steps > 0.0, tf.float32)\n\n    def __call__(self, step):\n\n        is_warmup = tf.cast(step < self.warmup_steps, tf.float32)\n        warmup_lr = self.warmup_incremental * step + self.start_lr\n        decay_lr = self.backend_lr(step - self.warmup_steps)\n        lr = (1.0 - is_warmup) * decay_lr + is_warmup * warmup_lr\n        return lr * self.lr_scaling","bbbee5cf":"warmup_steps, opt_steps = 42*10, 42 * 20\nbackend_lr = tf.keras.optimizers.schedules.ExponentialDecay(3e-5, opt_steps - warmup_steps, decay_rate=(1e-6 \/ 3e-5),)\nlr_rate = WarmupLearningRateSchedule(backend_lr, 1e-6, 3e-5, 1e-6, warmup_steps, opt_steps - warmup_steps, lr_scaling = 1)\n\nsteps = 42 * 30\nplt.figure(figsize=(10, 5))\nlr_over_step = lr_rate(range(steps))\nplt.plot(range(steps), lr_over_step, 'b-')\nplt.xlabel(\"Step\")\nplt.ylabel('LR')\nplt.title(\"LEARNING RATE OVER TIME\")\nplt.show()","4744f770":"class Focal_loss(keras.losses.Loss):\n    def __init__(self, threshold = 2.0, alpha = 1.0):\n        self.threshold = threshold\n        self.alpha = alpha\n\n        \n    def gamma(self, y_pred):\n        return self.threshold\/2 * (K.cos(np.pi*(y_pred-1)) + 1)\n    \n    def __call__(self, y_true, y_pred):\n        CE = - y_true * K.log(y_pred)\n        loss = self.alpha * ((1.-y_pred)**2) * CE\n        return K.sum(loss, axis = -1)","552fc58a":"def create_feature_model():\n    model= keras.Sequential(name='FeatureModel')\n    model.add(keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n    model.add(keras.layers.Dropout(0.5))\n\n    model.add(keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n    model.add(keras.layers.Dropout(0.5))\n\n    model.add(keras.layers.Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n    model.add(keras.layers.Dropout(0.5))\n\n    model.add(keras.layers.Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n    model.add(keras.layers.Dropout(0.5))\n    \n    \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dense(units=128, activation='relu'))\n    \n    return model","76e6db36":"def create_image_model(net_num):\n    eff_nets = [efficientnet.EfficientNetB0, efficientnet.EfficientNetB1, efficientnet.EfficientNetB2, efficientnet.EfficientNetB3, \n                efficientnet.EfficientNetB4, efficientnet.EfficientNetB5, efficientnet.EfficientNetB6, efficientnet.EfficientNetB7]\n    \n    \n    efficient_net = eff_nets[net_num](weights = 'noisy-student', include_top = False)\n    global_average = keras.layers.GlobalAveragePooling2D()\n    dropout = keras.layers.Dropout(0.5)\n    act = keras.layers.Dense(128, activation=\"relu\")\n#     classifier = keras.layers.Dense(4, activation='softmax')\n    \n    \n    model = keras.Sequential(name='ImageModel')\n    model.add(efficient_net)\n    model.add(global_average)\n    model.add(dropout)\n    model.add(act)\n    return model","3423a466":"def create_model(net_num):\n    images = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name='Image input')\n    features = keras.Input(shape=(162, 1), name='Feature input')\n    \n    \n    feature_model = create_feature_model()\n    image_model = create_image_model(net_num)\n    x = feature_model(features)\n    y = image_model(images)\n    z = keras.layers.concatenate([x, y], axis=-1)\n    z = keras.layers.Dense(units=128, activation='relu')(z)\n    output =  keras.layers.Dense(4, activation='softmax')(z)\n    \n    model = keras.Model(inputs = [features, images], outputs=output)\n    return model","835c22d2":"test = create_model(5)\nkeras.utils.plot_model(test)","6cee4773":"def set_up(model_num, train_size, warmup_epochs, opt_epochs, start_lr, max_lr, end_lr):\n    steps_per_epoch = int(train_size \/ BATCH_SIZE) + 1\n    \n    # Set up loss\n    def compute_loss(y_true, y_pred):\n        loss_obj = Focal_loss()\n        per_example_loss = loss_obj(y_true, y_pred)\n        return tf.nn.compute_average_loss(per_example_loss=per_example_loss, global_batch_size=BATCH_SIZE)\n\n    # Set up metrics\n    train_metric = keras.metrics.CategoricalAccuracy(name = 'Train Accuracy')\n    test_metric = keras.metrics.CategoricalAccuracy(name = 'Test Accuracy')\n          \n    # Set up LR\n    warmup_steps, opt_steps = steps_per_epoch*warmup_epochs, steps_per_epoch * opt_epochs\n    backend_lr = tf.keras.optimizers.schedules.ExponentialDecay(max_lr, opt_steps - warmup_steps, decay_rate=(end_lr \/ max_lr),)\n    lr_rate = WarmupLearningRateSchedule(backend_lr, start_lr, max_lr, end_lr, opt_steps, warmup_steps, lr_scaling = 1)\n    \n    # Set up optimizer and model\n    optimizer = keras.optimizers.Adam(1e-5)\n    model = create_model(model_num)\n    return model, compute_loss, optimizer, train_metric, test_metric, steps_per_epoch","8b79a36c":"def training(fold, train_ds, val_ds, epochs, steps_per_epoch, model, compute_loss, optimizer, train_metric, test_metric):\n    def train_step(inputs):\n      features, imgs, labels = inputs\n      with tf.GradientTape() as tape:\n        y_pred = model([features, imgs])\n        loss = compute_loss(labels, y_pred)\n        \n      grad = tape.gradient(loss, model.trainable_variables)\n      optimizer.apply_gradients(zip(grad, model.trainable_variables))\n\n      train_metric.update_state(labels, y_pred)\n\n      return loss\n\n    def test_step(inputs):\n      features, imgs, labels = inputs\n      y_pred = model([features, imgs])\n      loss = compute_loss(labels, y_pred)\n      \n      test_metric.update_state(labels, y_pred)\n      return loss\n\n    @tf.function\n    def dist_train_step(inputs):\n      return train_step(inputs)\n\n    @tf.function\n    def dist_test_step(inputs):\n      return test_step(inputs)\n\n    train_losses = []\n    test_losses = []\n    train_accs = []\n    test_accs = []\n    best_acc = 0.0\n    for epoch in range(epochs):\n      pbar = keras.utils.Progbar(steps_per_epoch+1, 10, stateful_metrics=['Train loss', 'Train acc', 'Test loss', 'Test acc'])\n      print('\\nEpoch {}:'.format(epoch+1))\n\n    #   #------------------------------Train Process--------------------------#\n      train_loss = 0.0\n      train_iter = iter(train_ds)\n      for step in range(steps_per_epoch):\n        inputs = next(train_iter)\n        train_loss += dist_train_step(inputs)\n        values = [('Train loss', train_loss.numpy()\/ (1.0*step + 1.0)), ('Train acc', train_metric.result().numpy())]\n        pbar.update(step+1, values)\n\n      train_loss = train_loss \/ (1.0 * steps_per_epoch)\n      train_losses += [train_loss]\n      train_accs += [train_metric.result().numpy()]\n\n      # -----------------------Test Process----------------------#\n      test_loss = 0.0\n      cnt = 0.0\n      for inputs in val_ds:\n        test_loss += dist_test_step((inputs))\n        cnt += 1.0\n\n      test_loss = test_loss \/ cnt\n      test_losses += [test_loss]\n      test_accs += [test_metric.result().numpy()]\n\n      pbar.update(steps_per_epoch+1, values = [('Test loss', test_loss.numpy()), ('Test acc', test_metric.result().numpy())])\n\n    #   #--------------------------------Update and Reset---------------------------#\n      if test_metric.result().numpy() - best_acc >= 1e-8:\n         print(\"\\nModel saving weights............\")\n         best_acc = test_metric.result().numpy()\n         model.save('.\/fold' + str(fold) + '.h5')\n      elif np.abs(test_metric.result().numpy() - best_acc) <= 1e-8:\n         print(\"\\nModel saving weights............\")\n         best_acc = test_metric.result().numpy()\n         model.save('.\/fold' + str(fold) + '.h5')\n        \n      train_metric.reset_states()\n      test_metric.reset_states()\n    \n    #---------------------------Visualization-----------------------------------#\n    figs, axes = plt.subplots(1, 2, figsize=(20, 5))\n    axes = axes[:]\n    axes[0].plot(range(epochs), train_losses, 'r-', label='Train Loss')\n    axes[0].plot(range(epochs), test_losses, 'b-', label='Test Loss')\n    axes[0].legend()\n    axes[0].title.set_text(\"Loss Over Time - Fold \" + str(fold))\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n\n    axes[1].plot(range(epochs), train_accs, 'r-', label='Train Accuracy')\n    axes[1].plot(range(epochs), test_accs, 'b-', label='Test Accuracy')\n    axes[1].legend()\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Accuracy\")\n    axes[1].title.set_text(\"Accuracy Over Time - Fold \" + str(fold))\n    plt.show()\n    figs.savefig('fold' + str(fold) + '.png', bbox_inches='tight')\n    return best_acc\n","71d63c7f":"fold = 1\nepoch = 30\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\nskf = StratifiedKFold(5, shuffle = True, random_state = 42)\naccs = []\nfor train_index, val_index in skf.split(features, labels):\n    print(\"\\n--------FOLD {}--------\".format(fold))\n    print(\"Number of train set: \", len(train_index))\n    print(\"Number of validation set: \", len(val_index))\n \n    train_ds = tf.data.Dataset.from_tensor_slices((features[train_index], imgs[train_index], labels[train_index]))\n    val_ds = tf.data.Dataset.from_tensor_slices((features[val_index], imgs[val_index], labels[val_index]))\n    \n    \n    train_ds = get_train_dataset(train_ds)\n    val_ds = get_val_dataset(val_ds)\n    \n    \n    model, compute_loss, optimizer, train_metric, test_metric, steps_per_epoch = set_up(6, 320, 10, 20, 1e-6, 3e-5, 1e-6)\n    model.summary()\n    acc = training(fold, train_ds, val_ds, epoch, steps_per_epoch, model, compute_loss, optimizer, train_metric, test_metric)\n    fold += 1\n    accs += [acc]","09301bc7":"y_preds = []\ny_trues = []\nmodel1 = keras.models.load_model('.\/fold1.h5')\nmodel2 = keras.models.load_model('.\/fold2.h5')\nmodel3 = keras.models.load_model('.\/fold3.h5')\nmodel4 = keras.models.load_model('.\/fold4.h5')\nmodel5 = keras.models.load_model('.\/fold5.h5')\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test_features, test_imgs, test_labels))\nfor feature, img, label in test_ds.map(data_preprocessing).batch(1):\n  y_pred1 = model1([feature, img])\n  y_pred2 = model2([feature, img])\n  y_pred3 = model3([feature, img])\n  y_pred4 = model4([feature, img])\n  y_pred5 = model5([feature, img])\n\n  y_pred = y_pred1 + y_pred2 + y_pred3 + y_pred4 + y_pred5\n  y_pred = np.argmax(y_pred)\n  y_true = np.argmax(label.numpy())\n\n  y_preds += [y_pred]\n  y_trues += [y_true]\n","060ac2a8":"print(classification_report(y_trues, y_preds))","4f1c67ac":"f1_score(y_trues, y_preds, average='macro')","9c711d8c":"cf = confusion_matrix(y_trues, y_preds)\nsns.heatmap(cf, cmap='Blues', annot=True)","1ae8ad87":"**TRAINING**\n---","df051595":"**DATA PREPARATION**\n---","a264e6eb":"**SET UP MODEL - LOSS - WARMUP LEARNING RATE**\n---","554c36db":"**MODEL**","3eafba3a":"**DATA PREPROCESSING**\n---","8d8f26ed":"**SET UP**\n","7d60c975":"**WARMUP LEARNING RATE**","2a68612d":"**INFERENCE**\n---"}}