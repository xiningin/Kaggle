{"cell_type":{"0f1464a1":"code","03409ee7":"code","d7ae2e80":"code","bfcb94b9":"code","6ef2542e":"code","772b3748":"code","4423f2ff":"code","febee12e":"code","2b7d6632":"code","04aed2ff":"code","d3748329":"code","dfa9d4f5":"code","b1766aec":"code","07c03c78":"code","874ad654":"code","5f30cb4e":"code","f5b64200":"code","8d60b85d":"code","01801ae0":"code","c9df3046":"code","61227614":"code","f44c45fb":"code","624b6221":"code","9aef2f0f":"code","8811dab5":"code","50db1253":"code","6851f885":"code","4eea19f0":"code","b64a096e":"code","335e9f2f":"code","8ef1bba2":"code","f9f28de4":"code","a3efc816":"code","03579604":"code","f55f202e":"code","0c8ee519":"code","a245dec1":"code","df209f14":"code","e44f6ca0":"code","2ded2ced":"code","b07d0f30":"markdown","734208e3":"markdown","a910c081":"markdown","52ee6345":"markdown","21d1fcdd":"markdown","54236b2e":"markdown","2d359d85":"markdown","8d01909a":"markdown","b5fecb29":"markdown","34ce48b5":"markdown","3bca3ef4":"markdown","b6e88ae6":"markdown","ba3caee1":"markdown","5c2f02f2":"markdown","46327300":"markdown","3b181e7a":"markdown","e1f72ed7":"markdown","df959beb":"markdown","4bc81bfb":"markdown","4e9b63b9":"markdown","43c16e33":"markdown","8fc3ef86":"markdown","45f208b2":"markdown","80a2acd1":"markdown","e9560c6c":"markdown","02e83005":"markdown","554f42f5":"markdown","a024a5ad":"markdown","9c1f87e8":"markdown","b08694a4":"markdown","4da3a76e":"markdown","e0958d34":"markdown","e5a68b29":"markdown","b6586533":"markdown","7a2fcd84":"markdown","5f85b62d":"markdown","d96e3c6c":"markdown","631027bb":"markdown","032f2f18":"markdown","166b3cd3":"markdown","f91b9119":"markdown","304bb2ea":"markdown","7ab95e61":"markdown","81452e00":"markdown","fa9c9446":"markdown","b65ddb0e":"markdown","335e4bf2":"markdown","4ecfc915":"markdown","3a67f92a":"markdown","1be3a3b4":"markdown","00dd94f4":"markdown","a1bcc73d":"markdown","50ff725f":"markdown"},"source":{"0f1464a1":"#Importing the Libraries\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport time\n\n#visualization libraries\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt, numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.colors import ListedColormap\nfrom IPython.display import Image\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport plotly.offline as pyo\nfrom plotly import tools\nimport seaborn as sns\n\n\n#data preprocessing & modelling libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom yellowbrick.cluster import KElbowVisualizer\nimport sklearn.cluster as cluster\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn import metrics\n\npyo.init_notebook_mode()\n\nimport warnings\nimport sys\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nnp.random.seed(42)","03409ee7":"#Loading the dataset\ndata = pd.read_csv(\"..\/input\/customer-personality-analysis\/marketing_campaign.csv\", sep=\"\\t\")\nprint(\"Number of datapoints:\", len(data))\ndata.head()","d7ae2e80":"print(\"Number of customers in the dataset: \",len(data))\nprint(\"Size of the Dataframe:\", data.shape)","bfcb94b9":"total = data.isnull().sum().sort_values(ascending=False)\npercent = ((data.isnull().sum()\/data.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total,percent],axis=1, keys=[\"Total\",\"Percent\"])\nmissing_data[missing_data.Percent>0]","6ef2542e":"data.info()","772b3748":"unique_counts = pd.DataFrame.from_records([(col, data[col].nunique()) for col in data.columns],\n                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\nunique_counts","4423f2ff":"data.dropna(inplace=True)\nprint(\"The total number of data-points after dropping the rows with missing values are:\", len(data))","febee12e":"print(\"Total categories in the feature Marital_Status:\\n\", data[\"Marital_Status\"].value_counts(), \"\\n\")\nprint(\"Total categories in the feature Education:\\n\", data[\"Education\"].value_counts())","2b7d6632":"#astyping Dt_Customer column as datetime object.\ndata[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"])\n\n#age of customer\ndata[\"Age\"]=2021-data.Year_Birth\n\n#Replacing the conflict values in marital status\ndata['Marital_Status'] = data['Marital_Status'].replace(['Married', 'Together'],'Relationship')\ndata['Marital_Status'] = data['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd'],'Single')\n\n#Feature indicating total children living in the household\ndata[\"Children\"]=data[\"Kidhome\"]+data[\"Teenhome\"]\n\n#Feature for total members in the household\ndata[\"Family_Size\"] = data[\"Marital_Status\"].replace({\"Single\": 1, \"Relationship\":2})+ data[\"Children\"]\n\n#Feature pertaining parenthood\ndata[\"Is_Parent\"] = np.where(data.Children> 0, 1, 0)\n\n#Segmenting education levels in three groups\ndata[\"Education\"]=data[\"Education\"].replace({\"Basic\":\"Undergraduate\",\"2n Cycle\":\"Undergraduate\", \"Graduation\":\"Graduate\", \"Master\":\"Postgraduate\", \"PhD\":\"Postgraduate\"})\n\n#For clarity\ndata=data.rename(columns={\"MntWines\": \"Wines\",\"MntFruits\":\"Fruits\",\"MntMeatProducts\":\"Meat\",\"MntFishProducts\":\"Fish\",\"MntSweetProducts\":\"Sweets\",\"MntGoldProds\":\"Gold\"})\n\n#Total spendings\ndata[\"Spent\"] = data[\"Wines\"]+ data[\"Fruits\"]+ data[\"Meat\"]+ data[\"Fish\"]+ data[\"Sweets\"]+ data[\"Gold\"]\n\n#Total Accepted Campaigns\ndata['Accepted_Campaigns'] = data['AcceptedCmp1'] + data['AcceptedCmp2'] + data['AcceptedCmp3'] + data['AcceptedCmp4'] + data['AcceptedCmp5']\n\n#Number of Total Purchases\ndata['Total_Purchases'] = data['NumWebPurchases'] + data['NumCatalogPurchases'] + data['NumStorePurchases'] + data['NumDealsPurchases']\n\n#Marital Status 2\ndef marital_status_2(row):\n    if row[\"Is_Parent\"] == 1:\n        return \"Family with Children\"\n    if row[\"Marital_Status\"] == \"Relationship\" and row[\"Is_Parent\"] == 0:\n        return \"Relationship\"\n    else:\n        return \"Single\"\n\ndata[\"Marital_Status_2\"] = data.apply(lambda row: marital_status_2(row), axis=1)  \n    \n#number of days customer engaged with company\ndata['First_day'] = '01-01-2015'\ndata['First_day'] = pd.to_datetime(data.First_day)\ndata['Day_engaged'] = (data['First_day'] - data['Dt_Customer']).dt.days","04aed2ff":"#Dropping some of the redundant features\nto_drop = [\"Dt_Customer\", \"Z_CostContact\",\"First_day\", \"Z_Revenue\", \"Year_Birth\", \"ID\"]\ndata = data.drop(to_drop, axis=1)","d3748329":"data.describe().transpose()","dfa9d4f5":"#Dropping the outliers by setting a cap on Age and income. \ndata = data[(data[\"Age\"]<90)]\ndata = data[(data[\"Income\"]<600000)]\nprint(\"The total number of data-points after removing the outliers are:\", len(data))","b1766aec":"data.head()","07c03c78":"corr_data= data[[\"Wines\",\"Fruits\",\"Meat\",\"Fish\",\"Sweets\",\"Gold\",\"Income\",\"Spent\",\"Total_Purchases\",\"Is_Parent\",\"Family_Size\",\"Day_engaged\",]]\n\nfig = plt.figure(figsize=(8,6))\nplt.title('Correlation between values')\nsns.heatmap(corr_data.corr(), annot=True, cmap=\"Greens\")","874ad654":"fig = make_subplots(rows=2, cols=2, start_cell=\"bottom-left\",\n                   subplot_titles=(\"Age\", \"Income\", \"Family Size\", \"Children\"))\n\n\nfig.add_trace(go.Box(x=data.Age, name=\"Age\",boxmean=True),row=1,col=1)\n\nfig.add_trace(go.Box(x=data.Income,name=\"Income\",boxmean=True),row=1, col=2)\n\nfig.add_trace(go.Box(x=data.Family_Size,name=\"Family Size\",boxmean=True),row=2, col=1)\n\nfig.add_trace(go.Box(x=data.Children,name=\"Children\",boxmean=True),row=2, col=2)\n\nfig.show()","5f30cb4e":"fig1 = px.box(data, x=\"Marital_Status_2\", y=\"Spent\", color=\"Education\",\n             notched=False, # used notched shape\n             title=\"Total Spent by Marital Status & Education\" # add day column to hover data\n            )\nfig2 = px.box(data, x=\"Marital_Status_2\", y=\"Total_Purchases\", color=\"Education\",\n             notched=False, # used notched shape\n             title=\"Total Purchases by Marital Status & Education\" # add day column to hover data\n            )\n\n\n\nfig1.show()\nfig2.show()\n","f5b64200":"grouping_data = data[[\"Education\",\"Marital_Status_2\",\"Income\",\"Children\",\"Recency\",\"Wines\",\n                     \"Fruits\",\"Meat\",\"Fish\",\"Sweets\",\"Gold\",\"Accepted_Campaigns\",\"Total_Purchases\",\n                     \"Spent\",\"Day_engaged\",'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n                      'NumStorePurchases', 'NumWebVisitsMonth']].groupby(by=[\"Education\",\"Marital_Status_2\"]).mean().reset_index()\ngrouping_data","8d60b85d":"# prepare data\ndata_ = data[[\"Day_engaged\",\"Spent\",\"Total_Purchases\"]]\n# scatter matrix\nfig = ff.create_scatterplotmatrix(data_, diag='box',colormap='Portland',\n                                  colormap_type='cat',\n                                  height=700, width=700)\n\nfig.show()","01801ae0":"# prepare data frames\n\ndf = data.groupby(by=[\"Marital_Status_2\"]).agg({\"Income\":np.mean,\"Spent\":np.mean}).reset_index()\n\ny_income = [round(float(each)) for each in df.Income]\ny_spent  = [round(float(each)) for each in df.Spent]\nx_income = [each for each in df.Marital_Status_2]\nx_spent  = [each for each in df.Marital_Status_2]\n\ntrace0 = go.Bar(\n                x=y_income,\n                y=x_income,\n                marker=dict(color='rgba(171, 50, 96, 0.6)',line=dict(color='rgba(171, 50, 96, 1.0)',width=1)),\n                name='Spent',\n                orientation='h',\n)\ntrace1 = go.Scatter(\n                x=y_spent,\n                y=x_spent,\n                mode='lines+markers',\n                line=dict(color='rgb(63, 72, 204)'),\n                name='Income',\n)\nlayout = dict(\n                title='Income & Total Spent by Marital Status',\n                yaxis=dict(showticklabels=True,domain=[0, 0.85]),\n                yaxis2=dict(showline=True,showticklabels=False,linecolor='rgba(102, 102, 102, 0.8)',linewidth=2,domain=[0, 0.85]),\n                xaxis=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0, 0.42]),\n                xaxis2=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0.47, 1],side='top',dtick=25),\n                legend=dict(x=0.029,y=1.038,font=dict(size=10) ),\n                margin=dict(l=200, r=20,t=70,b=70),\n                paper_bgcolor='rgb(248, 248, 255)',\n                plot_bgcolor='rgb(248, 248, 255)'\n)\n\nannotations = []\ny_s = np.round(y_income, decimals=2)\ny_nw = np.rint(y_spent)\n# Adding labels\nfor ydn, yd, xd in zip(y_nw, y_s, x_income):\n    # labeling the scatter savings\n    annotations.append(dict(xref='x2', yref='y2', y=xd, x=ydn - 4,text='{:,}'.format(ydn),font=dict(family='Arial', size=12,color='rgb(63, 72, 204)'),showarrow=False))\n    # labeling the bar net worth\n    annotations.append(dict(xref='x1', yref='y1', y=xd, x=yd + 3,text=str(yd),font=dict(family='Arial', size=12,color='rgb(171, 50, 96)'),showarrow=False))\n\nlayout['annotations'] = annotations\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=1, cols=2, specs=[[{}, {}]], shared_xaxes=True,\n                          shared_yaxes=False, vertical_spacing=0.001)\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\n\nfig['layout'].update(layout)\n\nfig.show()","c9df3046":"\n# prepare data frames\n\ndf = data.groupby(by=[\"Education\"]).agg({\"Income\":np.mean,\"Spent\":np.mean}).reset_index()\n\ny_income = [round(float(each)) for each in df.Income]\ny_spent  = [round(float(each)) for each in df.Spent]\nx_income = [each for each in df.Education]\nx_spent  = [each for each in df.Education]\n\ntrace0 = go.Bar(\n                x=y_income,\n                y=x_income,\n                marker=dict(color='rgba(171, 50, 96, 0.6)',line=dict(color='rgba(171, 50, 96, 1.0)',width=1)),\n                name='Spent',\n                orientation='h',\n)\ntrace1 = go.Scatter(\n                x=y_spent,\n                y=x_spent,\n                mode='lines+markers',\n                line=dict(color='rgb(63, 72, 204)'),\n                name='Income',\n)\nlayout = dict(\n                title='Income & Total Spent by Education',\n                yaxis=dict(showticklabels=True,domain=[0, 0.85]),\n                yaxis2=dict(showline=True,showticklabels=False,linecolor='rgba(102, 102, 102, 0.8)',linewidth=2,domain=[0, 0.85]),\n                xaxis=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0, 0.42]),\n                xaxis2=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0.47, 1],side='top',dtick=25),\n                legend=dict(x=0.029,y=1.038,font=dict(size=10) ),\n                margin=dict(l=200, r=20,t=70,b=70),\n                paper_bgcolor='rgb(248, 248, 255)',\n                plot_bgcolor='rgb(248, 248, 255)'\n)\n\nannotations = []\ny_s = np.round(y_income, decimals=2)\ny_nw = np.rint(y_spent)\n# Adding labels\nfor ydn, yd, xd in zip(y_nw, y_s, x_income):\n    # labeling the scatter savings\n    annotations.append(dict(xref='x2', yref='y2', y=xd, x=ydn - 4,text='{:,}'.format(ydn),font=dict(family='Arial', size=12,color='rgb(63, 72, 204)'),showarrow=False))\n    # labeling the bar net worth\n    annotations.append(dict(xref='x1', yref='y1', y=xd, x=yd + 3,text=str(yd),font=dict(family='Arial', size=12,color='rgb(171, 50, 96)'),showarrow=False))\n\nlayout['annotations'] = annotations\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=1, cols=2, specs=[[{}, {}]], shared_xaxes=True,\n                          shared_yaxes=False, vertical_spacing=0.001)\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\n\nfig['layout'].update(layout)\n\nfig.show()","61227614":"#Single customers\n\ndata_single = data[data.Marital_Status_2 == \"Single\"]\n\ntrace_single_1 = go.Box(\n    x=data_single.Wines,\n    name = \"Wines\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\ntrace_single_2 = go.Box(\n    x=data_single.Fruits,\n    name = \"Fruits\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\ntrace_single_3 = go.Box(\n    x=data_single.Meat,\n    name = \"Meat\",\n    marker=dict(color='rgba(0, 255, 200, 0.8)'))\ntrace_single_4 = go.Box(\n    x=data_single.Fish,\n    name = \"Fish\",\n    marker=dict(color='rgb(12, 128, 128)'))\ntrace_single_5 = go.Box(\n    x=data_single.Sweets,\n    name = \"Sweets\",\n    marker=dict(color='rgba(255, 255, 128, 0.5)'))\ntrace_single_6 = go.Box(\n    x=data_single.Gold,\n    name = \"Gold\",\n    marker=dict(color='rgba(255, 128, 2, 0.8)'))\n\ndata_single_ = [trace_single_1, trace_single_2, trace_single_3,trace_single_4,trace_single_5,trace_single_6]\nlayout = go.Layout(barmode='overlay',\n                   title=' Amount Spend of Different Products for Singles',\n                   xaxis=dict(title='Amount Spend'),\n                   yaxis=dict( title='Product'),\n)\nfig1 = go.Figure(data=data_single_, layout=layout)\n\n\n#Customers in a relationship\n\ndata_relationship = data[data.Marital_Status_2 == \"Relationship\"]\n\ntrace_relationship_1 = go.Box(\n    x=data_relationship.Wines,\n    name = \"Wines\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\ntrace_relationship_2 = go.Box(\n    x=data_relationship.Fruits,\n    name = \"Fruits\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\ntrace_relationship_3 = go.Box(\n    x=data_relationship.Meat,\n    name = \"Meat\",\n    marker=dict(color='rgba(0, 255, 200, 0.8)'))\ntrace_relationship_4 = go.Box(\n    x=data_relationship.Fish,\n    name = \"Fish\",\n    marker=dict(color='rgb(12, 128, 128)'))\ntrace_relationship_5 = go.Box(\n    x=data_relationship.Sweets,\n    name = \"Sweets\",\n    marker=dict(color='rgba(255, 255, 128, 0.5)'))\ntrace_relationship_6 = go.Box(\n    x=data_relationship.Gold,\n    name = \"Gold\",\n    marker=dict(color='rgba(255, 128, 2, 0.8)'))\n\ndata_relationship_ = [trace_relationship_1, trace_relationship_2, trace_relationship_3,trace_relationship_4,trace_relationship_5,trace_relationship_6]\nlayout2 = go.Layout(barmode='overlay',\n                   title=' Amount Spend of Different Products for Customers in a Relationship',\n                   xaxis=dict(title='Amount Spend'),\n                   yaxis=dict( title='Product'),\n)\nfig2 = go.Figure(data=data_relationship_, layout=layout2)\n\n\n#Customers in a relationship\n\ndata_families = data[data.Marital_Status_2 == \"Family with Children\"]\n\ntrace_families_1 = go.Box(\n    x=data_families.Wines,\n    name = \"Wines\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\ntrace_families_2 = go.Box(\n    x=data_families.Fruits,\n    name = \"Fruits\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\ntrace_families_3 = go.Box(\n    x=data_families.Meat,\n    name = \"Meat\",\n    marker=dict(color='rgba(0, 255, 200, 0.8)'))\ntrace_families_4 = go.Box(\n    x=data_families.Fish,\n    name = \"Fish\",\n    marker=dict(color='rgb(12, 128, 128)'))\ntrace_families_5 = go.Box(\n    x=data_families.Sweets,\n    name = \"Sweets\",\n    marker=dict(color='rgba(255, 255, 128, 0.5)'))\ntrace_families_6 = go.Box(\n    x=data_families.Gold,\n    name = \"Gold\",\n    marker=dict(color='rgba(255, 128, 2, 0.8)'))\n\ndata_families_ = [trace_families_1, trace_families_2, trace_families_3,trace_families_4,trace_families_5,trace_families_6]\nlayout3 = go.Layout(barmode='overlay',\n                   title=' Amount Spend of Different Products for Customers with children',\n                   xaxis=dict(title='Amount Spend'),\n                   yaxis=dict( title='Product'),\n)\nfig3 = go.Figure(data=data_families_, layout=layout3)\n\nfig1.show()\nfig2.show()\nfig3.show()","f44c45fb":"#get list of categorical columns\nmodel_data= data.copy()\n\ncategorical_cols = list((model_data.dtypes == 'object')[(model_data.dtypes == 'object')].index)\n\n#1. Label Encoding\nLE=LabelEncoder()\nfor i in categorical_cols:\n    model_data[i]=model_data[[i]].apply(LE.fit_transform)","624b6221":"model_data.columns","9aef2f0f":"#2.Scaling Features with StandardScaler\ncols_del = ['Marital_Status',\n            'Teenhome',\n            \"Kidhome\",\n            'AcceptedCmp3',\n            'AcceptedCmp4',\n            'AcceptedCmp5',\n            'AcceptedCmp1',\n            'AcceptedCmp2',\n            'Complain',\n            'Response']\n\nmodel_data = model_data.drop(cols_del, axis=1)\n\nscaler = StandardScaler()\nscaler.fit(model_data)\n\nmodel_data_2 = pd.DataFrame(scaler.transform(model_data),columns= model_data.columns )\n","8811dab5":"model_data_2.head()","50db1253":"#3.Dimentionality Reduction with PCA\n\npca = PCA(n_components=3)\npca.fit(model_data_2)\nPCA_ds = pd.DataFrame(pca.transform(model_data_2), columns=([\"col1\",\"col2\", \"col3\"]))\nPCA_ds.describe().T\n\n#Ploting result data\nx =PCA_ds[\"col1\"]\ny =PCA_ds[\"col2\"]\nz =PCA_ds[\"col3\"]\n\n\nfig = go.Figure(data=[go.Scatter3d(\n    x=x,y=y,z=z,mode='markers',\n    marker=dict(size=6,color=x,opacity=0.8))])\n\n# tight layout\nfig.update_layout( title={'text': \"3D scatterplot of size-reduced data\",'y':0.9,\n        'x':0.5,'xanchor': 'center','yanchor': 'top'},\n                  margin=dict(l=200, r=220, b=0, t=0))\nfig.show()\n","6851f885":"#4. Performing Elbow Method to Find Optimum Clusters\n\nelbow_plot = KElbowVisualizer(KMeans(), k=10)\nelbow_plot.fit(PCA_ds)\nelbow_plot.show()","4eea19f0":"plot_kwds = {'alpha' : 0.30, 's' : 50, 'linewidths':0}\nclusters_series = []\n\ndef plot_clusters(data, algorithms, args, kwds, axs):\n    for j, i in enumerate(axs):\n        algorithm = algorithms[j]\n        start_time = time.time()\n        labels = algorithm(*args[j], **kwds[j]).fit_predict(data)\n        end_time = time.time()\n        clusters_series.append(labels)\n        #plotting\n        palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n        colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]        \n        i.scatter(data.iloc[:,0], data.iloc[:,1],c=colors,  **plot_kwds)\n        i.set_title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=14)\n        i.text(-0.5, 0.7, 'Clustering took {:.2f} s'.format(end_time - start_time), fontsize=10)\n    \n    \nfig, axs = plt.subplots(nrows=2, ncols=3, figsize=(16, 10), sharex=True, sharey=True)\naxs = axs.flatten()\ndata_alg = [cluster.MeanShift,cluster.AffinityPropagation , cluster.KMeans, \n           cluster.SpectralClustering, cluster.AgglomerativeClustering,cluster.DBSCAN]\ndata_arg = [(0.475,), (), (), \n           (), (), ()]\ndata_kwd = [{'cluster_all':False}, {'preference':-1.0, 'damping':0.95}, {'n_clusters':4},\n           {'n_clusters':4}, {'n_clusters':4, 'linkage':'ward'}, {'eps':0.605}]\n\nplot_clusters(data=PCA_ds, algorithms=data_alg, \n              args=data_arg, \n              kwds=data_kwd, axs=axs)\n\nPCA_ds[\"clusters_affinity\"], PCA_ds[\"clusters_spectral\"] =  clusters_series[1],clusters_series[3]\nPCA_ds[\"clusters_kmeans\"], PCA_ds[\"clusters_agglom\"] =   clusters_series[2],clusters_series[4]\n\ndata[\"clusters_affinity\"], data[\"clusters_spectral\"] =  clusters_series[1],clusters_series[3]\ndata[\"clusters_kmeans\"], data[\"clusters_agglom\"] =   clusters_series[2],clusters_series[4]","b64a096e":"fig = go.Figure(data=[go.Scatter3d(\n    x=x,y=y,z=z,mode='markers',\n    marker=dict(size=6,color=PCA_ds[\"clusters_spectral\"],colorscale='Viridis',opacity=0.8))])\n\n# tight layout\nfig.update_layout( title={'text': \"3D scatterplot of spectral model clusters\",'y':0.9,\n        'x':0.5,'xanchor': 'center','yanchor': 'top'},\n                  margin=dict(l=200, r=220, b=0, t=0))\nfig.show()","335e9f2f":"fig = go.Figure(data=[go.Scatter3d(\n    x=x,y=y,z=z,mode='markers',\n    marker=dict(size=6,color=PCA_ds[\"clusters_kmeans\"],colorscale='Viridis',opacity=0.8))])\n\n# tight layout\nfig.update_layout( title={'text': \"3D scatterplot of K-means model clusters\",'y':0.9,\n        'x':0.5,'xanchor': 'center','yanchor': 'top'},\n                  margin=dict(l=200, r=220, b=0, t=0))\nfig.show()","8ef1bba2":"plt.figure(figsize=(5,2))\nfig, ax =plt.subplots(1,3)\n\nsns.countplot(x=data[\"clusters_spectral\"], palette= \"husl\", ax=ax[0])\nsns.countplot(x=data[\"clusters_kmeans\"], palette= \"hls\", ax=ax[1])\nsns.countplot(x=data[\"clusters_agglom\"], palette= \"Set2\", ax=ax[2])\n\nfig.suptitle(\"Distribution of Clusters\")\nplt.show()","f9f28de4":"fig, ax = plt.subplots(nrows=3, ncols=1,constrained_layout=True)\n\ncolors = [\"#EC7063\",\"#AF7AC5\",\"#7FB3D5\",\"#1E8449\"]\n\npl = sns.scatterplot(data = data,x=data[\"Spent\"], y=data[\"Income\"],hue=data[\"clusters_agglom\"], ax=ax[0], palette=sns.color_palette(colors))\npl2 = sns.scatterplot(data=data, x=data['Spent'], y=data[\"Income\"],hue=data[\"clusters_spectral\"],ax=ax[1],palette=sns.color_palette(colors))\npl3 = sns.scatterplot(data=data, x=data['Spent'], y=data[\"Income\"],hue=data[\"clusters_kmeans\"],ax=ax[2],palette=sns.color_palette(colors))\nfig.suptitle('Clusters Profile based on Spending')\n\nax[0].set_title(\"Agglomerative Clustering\")\nax[1].set_title(\"Spectral Clustering\")\nax[2].set_title(\"K-Means Clustering\")\n\nax[0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n\nfig.suptitle(\"Cluster Profile based on Income & Spending\")\n\nfig.tight_layout()\nfig.show()","a3efc816":"fig = px.scatter(data, x=\"Spent\", y=\"Income\", color=\"clusters_spectral\", \n                 hover_data=[\"Marital_Status_2\",\"Family_Size\"],color_continuous_scale=colors)\n\nfig.update_layout( title={'text': \"Clusters by Income & Spent of Customers\"})\nfig.show()","03579604":"customer_groups = data[\"clusters_spectral\"].unique().tolist()\ncustomer_groups.sort()\nfig = make_subplots(\n    rows=1,cols=len(customer_groups),\n    subplot_titles=(customer_groups))\n\nfor i, group in enumerate(customer_groups): #enumerate here to get access to i\n    plot_data = data[data.clusters_spectral == group]\n    fig.add_trace(go.Scatter(x=plot_data[\"Spent\"], y=plot_data[\"Income\"],mode='markers',\n                            name=\"Cluster {}\".format(group),fillcolor=colors[i]),\n                  row=1,col=i+1)\n    \n\nfig.update_layout(xaxis1 = dict(range=[0,2000]),xaxis2 = dict(range=[0,2000]),\n                 xaxis3 = dict(range=[0,2000]),xaxis4 = dict(range=[0,2000]),\n                  xaxis = dict(title=\"Spent\"),\n                  yaxis = dict(title=\"Income\"),\n                 title={'text': \"Income & Spending Distribution of Spectral Model Clusters \",'y':0.9,\n        'x':0.5,'xanchor': 'center','yanchor': 'top'})\n\n\n\nfig.show()","f55f202e":"fig = make_subplots(rows=1, cols=3, start_cell=\"bottom-left\",\n                   subplot_titles=(\"Spending for different clusters\",\"Purchase for different clusters\",\n                                  \"Income for different clusters\"))\nclusters=data.clusters_spectral.unique().tolist()\nclusters.sort()\ncolors_border = [\"#CB4335\",\"#8E44AD\",\"#2E86C1\",\"#2ECC71\"]\nfor i, cluster in enumerate(customer_groups):\n    fig.add_trace(go.Box(x=data[data.clusters_spectral==cluster].clusters_spectral, y=data[data.clusters_spectral==cluster].Spent, name=\"Cluster {}\".format(cluster),fillcolor=colors[i],line=dict(color=colors_border[i],width=1.5),boxmean=True),row=1,col=1)\n    fig.add_trace(go.Box(x=data[data.clusters_spectral==cluster].clusters_spectral, y=data[data.clusters_spectral==cluster].Total_Purchases,fillcolor=colors[i],line=dict(color=colors_border[i],width=1.5),showlegend=False,boxmean=True),row=1,col=2)\n    fig.add_trace(go.Box(x=data[data.clusters_spectral==cluster].clusters_spectral, y=data[data.clusters_spectral==cluster].Income,fillcolor=colors[i],line=dict(color=colors_border[i],width=1.5),showlegend=False,boxmean=True),row=1,col=3)\nfig.show()","0c8ee519":"data[\"clusters_spectral\"]=data[\"clusters_spectral\"].astype(\"category\")\n\ng = sns.FacetGrid(data, col='Education',\n                  margin_titles=True, row = 'Marital_Status_2',\n                 hue_kws={'color': colors}, hue=\"clusters_spectral\")\ng.map(sns.countplot, 'clusters_spectral')\n#g.fig.subplots_adjust(top=1.5)\ng.fig.suptitle('Education & Marital Status by clusters', y= 1.01)","a245dec1":"Personal = [ \"Age\", \"Family_Size\",\"Children\"]\n\nfor i in Personal:\n    plt.figure()\n    sns.jointplot(x=data[i], y=data[\"Spent\"], hue =data[\"clusters_spectral\"], kind=\"kde\", palette=colors)\n    plt.show()","df209f14":"#Plotting the number of deals purchased\npl = sns.boxenplot(y=data[\"NumDealsPurchases\"],x=data[\"clusters_spectral\"], palette= colors)\n\n\npl.set_title(\"Number of Deals Purchased\")\nplt.show()","e44f6ca0":"#Plotting total accepted campaigns \npl2 = sns.boxenplot(y=data[\"Accepted_Campaigns\"],x=data[\"clusters_spectral\"], palette= colors)\n\npl2.set_title(\"Number of Total Accepted Promotion\")\nplt.show()","2ded2ced":"summary_df = data.groupby([\"clusters_spectral\"]).agg({\"Education\":\"count\",\"Age\":np.mean,\"Income\":np.median,\"Family_Size\":np.mean, \"Spent\":np.median,\n                                                                        \"NumDealsPurchases\":np.mean,\"NumWebPurchases\":np.mean,\"NumCatalogPurchases\":np.mean,\n                                                                        \"NumStorePurchases\":np.mean,\"Day_engaged\":np.median}).reset_index().rename(columns={\"Education\":\"Customer count\"})\n\nsummary_df.round()","b07d0f30":"When we look deep into the spendings of different products by marital status, we see that the consumption of wine and meat differs at a higher rate than other products. On the other hand, sweet consumption is lowest at customers with children. ","734208e3":"\n1. Importing Libraries \n2.  Loading Data\n3.  Data Cleaning\n4.  Data Preprocessing\n5.  Data Exploration with Visualization\n6.  Dimensionality Reduction\n7.  Performing Clustering \n8.  Model Evaluation\n9.  Profiling\n10. Overall Conclusion\n\n","a910c081":"Observations: \n* Kmeans and Agglomerative Clustering show simular clusters, groupes found by Spectral Clustering differs. It is hard to determine some clusters due to high density, not all algorithms show reasonable results.\n* Spectral clustering performs well (1.89 s).","52ee6345":"We will be having a look at the data in light of clusters via exploratory data analysis and drawing conclusions.","21d1fcdd":"**First Look at Dataframe:**\n* As seen above, there are some missing values in income column (%1)\n* Dt_Customer column is an object column, it should be converted to datetime.\n* There are some categorical columns which should be encoded for modelling step. ","54236b2e":"Observations:\n\n* Cluster 0 : Customers with low spending & low purchasing & mostly middle income\n* Cluster 1 : Customers with low spending & lowest purchasing & mostly low income\n* Cluster 2 : Customers with highest spending & high purchasing & mostly high income\n* Cluster 3 : Customers with high spending & highest purchasing & mostly high income","2d359d85":"As seen above, customers with postgraduate & graduate degree spends more and have higher income than customers with undergraduate degree. ","8d01909a":"As seen above, Spectral Clustering and K-means seems similar. I will be performing clustering via Spectral clustering. Spectral clustering is a hierarchical clustering method. It involves merging examples until the desired number of clusters is achieved.Whenever K-means is appropriate for use then so too is spectral clustering (just use a simple Euclidean distance as the similarity measure). The converse is not true though.","b5fecb29":"# Data Description","34ce48b5":"**If you liked this Notebook, please do upvote.**\n\n**If you have any questions, feel free to comment!**\n \n**Best Wishes!**","3bca3ef4":"**Exploration of Demographic Features**","b6e88ae6":"**Finding Optimal K for Clustering with Elbow Method**","ba3caee1":"# Introduction","5c2f02f2":"**In a business context**, clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment. It helps to better understand customers, in terms of both static demographics and dynamic behaviors.**In a data science context**, clustering algorithm is an unsupervised machine learning algorithm that discovers groups of data points that are closely related. \n\nClustering techniques apply when there is no class to be predicted but rather when the instances are to be divided into natural groups.\n","46327300":"Do note that max-age is 128 years, As I calculated the age that would be today (i.e. 2021) and the data is old. On the other hand, there are some outliers in income column.","3b181e7a":"# 1. Importing Libraries","e1f72ed7":"Observations:\n\nThere is a noticeable difference between medians of total spendings among families and others.\n\nCustomers with postgraduate degree are the customers who spend the most.\n\nWhen we look at the second chart, we can say that the median difference in total purchasing varies less by education and marital status.\n","df959beb":"**Clustering**\n\n> **Mean Shift**\n* It is a centroid-based, like K-Means and Affinity Propagation. \n* It is also known as the Mode-seeking algorithm, assigns the data points to the clusters iteratively by shifting points towards the mode (mode is the highest density of data points in the region, in the context of the Meanshift).\n* Unlike K-Means cluster algorithm, mean-shift does not require specifying the number of clusters in advance. The number of clusters is determined by the algorithm with respect to the data.\n\n> **Affinity Propagation**\n* It is a graph-based approach, each data point sends messages to all other points informing its targets of each target\u2019s relative attractiveness to the sender. Each target then responds to all senders with a reply informing each sender of its availability to associate with the sender, given the attractiveness of the messages that it has received from all other senders. Senders reply to the targets with messages informing each target of the target\u2019s revised relative attractiveness to the sender, given the availability messages it has received from all targets. The message-passing procedure proceeds until a consensus is reached. Once the sender is associated with one of its targets, that target becomes the point\u2019s exemplar. All points with the same exemplar are placed in the same cluster.\n* It does not require to specify the number of clusters. \n* Affinity Propagation has some advantages over K-Means.\n\n> **K-Means**\n* K-Means is fast, easy to understand, and available everywhere. It isn\u2019t a clustering algorithm, it is a partitioning algorithm. That is to say K-means doesn\u2019t \u2018find clusters\u2019 it partitions your dataset into as many (assumed to be globular) chunks as you ask for by attempting to minimize intra-partition distances. \n* You need to specify exactly how many clusters you expect. The another problem is K-Means dependents upon initialization; give it multiple different random starts and you can get multiple different clusterings. This does not engender much confidence in any individual clustering that may result.\n\n> **Spectral**\n* Spectral clustering is another graph-based approach which is flexible and allows us to cluster non graph data as well.\n* It helps us overcome two major problems in clustering: one being the shape of the cluster and the other is determining the cluster centroid.\n* K-means generally assumes that the clusters are spherical or round within k-radius from the cluster centroid. In K means, many iterations are required to determine the cluster centroid. In spectral, the clusters do not follow a fixed shape or pattern. Points that are far away but connected belong to the same cluster and the points which are less distant from each other could belong to different clusters if they are not connected. This implies that the algorithm could be effective for data of different shapes and sizes.\n* it is computationally fast for sparse datasets of several thousand data points. \n\n> **Agglomerative**\n* It is really a suite of algorithms all based on the same idea. The algorithm starts by treating each object as a singleton cluster. Next, pairs of clusters are successively merged until all clusters have been merged into one big cluster containing all objects. The result is a tree-based representation of the objects, named dendrogram.\n\n> **DBSCAN**\n* It is a density-based clustering algorithm. When it comes to arbitrary shaped clusters or detecting outliers, density-based techniques are more efficient. It is able to find arbitrary shaped clusters and clusters with noise\n* The end result is a set of cluster \u2018exemplars\u2019 from which we derive clusters by essentially doing what K-Means does and assigning each point to the cluster of it\u2019s nearest exemplar. Affinity Propagation has some advantages over K-Means.","4bc81bfb":"The **KElbowVisualizer** implements the \u201celbow\u201d method to help selecting the optimal number of clusters by fitting the model with a range of values for K.","4e9b63b9":"# 9- Profiling","43c16e33":"# Table of Content","8fc3ef86":"As seen above, customers who are not parents have higher income and spending than others.\n","45f208b2":"Before perform clustering, customers grouped by education and marital status.","80a2acd1":"In the next step, I am going to create some new features. \n\n* We've changed some qualitative column's dtypes from 'object' to 'category'.\n* Deriving Customer age column from year of birth\n* Updating \"Marital_Status\" feature as the living situation of couples.\n* Creating a feature \"Children\" to indicate total children in a household that is, kids and teenagers.\n* To get further clarity of household, Creating feature indicating \"Family_Size\"\n* Creating a feature \"Is_Parent\" to indicate parenthood status\n* Creating three categories in the \"Education\" by simplifying its value counts.\n* Renaming product names for clarity\n* Creating \"spent\" column (all expenses were summed)\n* Creating \"Accepted_Campaings\" column (all accepted campaigns summed)\n* Creating \"Total_Purchases\" column (all purchases from different channels summed)\n* Creating \"Marital_Status_2\" column to simplify consumption habits by marital status.\n* Creating \"Day_Engaged\" feature which defines the number of days the customers started to shop in the store relative to the last recorded date \n* Dropping some of the redundant features","e9560c6c":"**Observations**\n* There are 2240 entries and 29 columns, one column is an customer's ID.Customer ID is unique identifier of dataset.\n* Since the missing data constitutes 1% of the total data.\n* The columns 'z_costcontact','z_revenue' have zero std. All values are equal, we will drop this columns from the df.\n* No duplicated values and errors (at the first glance).\n* There are some columns, which datatypes are should be changed.\n* Marital status and education are categorical variables and they have over 5 unique values. This is too much to perform clustering.\n","02e83005":"When we looked distribution of clusters for spectral,the clusters seem to be fairly distributed.","554f42f5":"Let's look deeper clusters of spectral clustering in third dimension.","a024a5ad":"# 10 - Conclusion","9c1f87e8":"In this project, I performed spectral clustering to segment customers. I came up with 4 clusters and further used them in profiling customers in clusters according to their demographic features, income and spending.","b08694a4":"# 3-Data Exploration with Visualization","4da3a76e":"Observations:\n\n* Cluster 0 and Cluster 1 are the groups who spent lower than 500.\n* Cluster 2 and Cluster 3 includes customers who spend higher than others.\n* Customers in Cluster 2 and 3 have higher income level relative to others.","e0958d34":"# 5- Dimensionality Reduction","e5a68b29":"**Observations:\n**\n\n* The average household size is 3. Customers with families generally have one child. \n* The average age of customers is 52. Customers are mostly adults over 25. \n* After removing the outliers, the average income value is 52 K, and the median of the income distribution is 51 K.","b6586533":"# 1- Importing Data","7a2fcd84":"Observations:\n\n* Cluster 0 : Mostly parents \n* Cluster 1 : Not parents\n* Cluster 2 : Not parents\n* Cluster 3 : Mostly parents | customers with a relationship","5f85b62d":"<iframe src=\"https:\/\/www.kaggle.com\/embed\/kslarwtf\/eda-clustering-updated?cellIds=1&kernelSessionId=78784487\" height=\"300\" style=\"margin: 0 auto; width: 100%; max-width: 950px;\" frameborder=\"0\" scrolling=\"auto\" title=\"\ud83d\ude4b\ud83d\ude4b\u200d\u2642\ufe0fEDA | CLUSTERING | UPDATED \ud83d\udd25\"><\/iframe>","d96e3c6c":"**ATTRIBUTES**\n\n> **> People**\n> \n> * ***ID***: Customer's unique identifier\n> * ***Year_Birth***: Customer's birth year\n> * ***Education***: Customer's education level\n> * ***Marital_Status***: Customer's marital status\n> * ***Income***: Customer's yearly household income\n> * ***Kidhome***: Number of children in customer's household\n> * ***Teenhome***: Number of teenagers in customer's household\n> * ***Dt_Customer***: Date of customer's enrollment with the company\n> * ***Recency***: Number of days since customer's last purchase\n> * ***Complain***: 1 if the customer complained in the last 2 years, 0 otherwise\n> \n> **> Products**\n> \n> * ***MntWines***: Amount spent on wine in last 2 years\n> * ***MntFruits***: Amount spent on fruits in last 2 years\n> * ***MntMeatProducts***: Amount spent on meat in last 2 years\n> * ***MntFishProducts***: Amount spent on fish in last 2 years\n> * ***MntSweetProducts***: Amount spent on sweets in last 2 years\n> * ***MntGoldProds***: Amount spent on gold in last 2 years\n> \n> **> Promotion**\n> \n> * ***NumDealsPurchases***: Number of purchases made with a discount\n> * ***AcceptedCmp1***: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n> * ***AcceptedCmp2***: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n> * ***AcceptedCmp3***: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n> * ***AcceptedCmp4***: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n> * ***AcceptedCmp5***: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n> * ***Response***: 1 if customer accepted the offer in the last campaign, 0 otherwise\n> \n> **> Place**\n> \n> * ***NumWebPurchases***: Number of purchases made through the company\u2019s website\n> * ***NumCatalogPurchases***: Number of purchases made using a catalogue\n> * ***NumStorePurchases***: Number of purchases made directly in stores\n> * ***NumWebVisitsMonth***: Number of visits to company\u2019s website in the last month","631027bb":"**Removing outliers**","032f2f18":"**Pearson Correlation Between Some Selected Features**","166b3cd3":"**Missing Data**","f91b9119":"**Problem Statement**\n\nCustomer segmentation helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company\u2019s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.The target of this project is to perform clustering to summarize customer segments.\n\nIn this project, I will perform an unsupervised clustering of data on the customer's records from a groceries firm's database. \n\n","304bb2ea":"We have performed clusters. Let us see who all are there in these clusters. Now, we will be profiling the clusters formed. On the basis of the outcomes, I will be arriving at the conclusions.","7ab95e61":"In this section, the data will be preprocessed to perform clustering.\n\n> The following steps are applied:\n> \n* Label encoding the categorical features (LabelEncoder())\n* Scaling the features using the standard scaler (StandardScaler())\n* Creating a subset dataframe for dimensionality reduction (PCA())\n*  Elbow Method to determine the number of clusters in a data set.","81452e00":"# 8-  Model Evaluation","fa9c9446":"**Observations :\n**\n* Income is positively correlated with wine and meat consumption, and also total spent of a customer.\n* Total spent is negatively correlated with parenthood and family size which is unexpected.\n* There is no significant relationship between  number of days that customers started to shop in the store and among other features.","b65ddb0e":"# 7 - Performing Clustering","335e4bf2":"Customer segmentation is the process of dividing customers into groups based on common characteristics so companies can market to each group effectively and appropriately. Segmentation allows marketers to better tailor their marketing efforts to various audience subsets. \n\nCustomer segmentation requires a company to gather specific information -data- about customers to analyze it to identify patterns that can be used to create segments. \n\n![Customer segmentation](https:\/\/5.imimg.com\/data5\/KG\/CD\/XF\/SELLER-762548\/market-and-customer-segmentation-studies-500x500.png)\n\n","4ecfc915":"# 2- Data Preprocessing","3a67f92a":"Observations: \n\nAt first glance, \n\n* Customers with postgraduate degree have the highest income.\n* Recency does not vary by education and marital status.\n* Wine consumption seems like highly correlated with marital status and education. It is highest at customers with postgraduate degree and who are not parents.\n* Meat consumption is seems like related with educational status and income level.","1be3a3b4":"**Cluster 0**\n\n1. The most crowded segment (988 customers).\n2. Middle income\n3. Mostly parents (at the max 5 members in the family, and at least 2)\n4. Low spending\n5. Relatively new customers for company\n5. Primary target audience for deals\n\n\n**Cluster 1**\n1. Smallest group (135 customers)\n2. Low income\n3. Not a parent (at max 2 members in the house)\n4. Low spending\n5. Secondary target audience for deals\n\n**Cluster 2**\n1. includes 494 customers\n2. Relatively older than cluster 0 and 1.\n3. Not a parent (at the max 2 members in the house)\n4. Top spending segment\n6. Highest income\n7. Habit of shopping from both web and catalog\n8. Relatively new customers for company\n9. Target audience for online campaings\n\n**Cluster 3** \n1. second most populous segment (595 customers)\n2. Mostly parents (at the max 5 members in the family, and at least 2)\n3. Relatively older than other segments\n4. Loyal customers for the company\n5. Habit of shopping from web\n6. High income\n7. High spending\n8. Primary target audience for online campaigns","00dd94f4":"As seen above, clusters differs by income and spent features, but there is more. Let's look deeper.","a1bcc73d":"**Feature Engineering**","50ff725f":"For the k-means clustering method, the most common approach for answering this question is the so-called elbow method. It involves running the algorithm multiple times over a loop, with an increasing number of cluster choice and then plotting a clustering score as a function of the number of clusters.\n\nThe score is, in general, a measure of the input data on the k-means objective function i.e. some form of intra-cluster distance relative to inner-cluster distance. In clustering, this means one should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data."}}