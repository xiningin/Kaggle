{"cell_type":{"5eaadfa5":"code","e539a563":"code","02cd7db6":"code","3dddc13e":"code","8ed0338a":"code","c72d05f5":"code","536ca6a0":"code","81f481c8":"code","72205e41":"code","f9106667":"code","25bb267e":"markdown","807cebfc":"markdown","654ee5a8":"markdown","af583649":"markdown","21ab4f27":"markdown","7532ba9e":"markdown","c03a1ecc":"markdown","ef1c1aa5":"markdown","ea846d6e":"markdown","6bf84681":"markdown","96ff46de":"markdown","b350652b":"markdown"},"source":{"5eaadfa5":"#carregando arquivo\nimport pandas as pd\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#prestem aten\u00e7\u00e3o no c\u00f3digo abaixo, tem duas formas de carregar os csvs, esolham a que preferir e comentem a outra pra desativar\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n\n#train_url = \"http:\/\/s3.amazonaws.com\/assets.datacamp.com\/course\/Kaggle\/train.csv\"\n#train = pd.read_csv(train_url)\n\n#test_url = \"http:\/\/s3.amazonaws.com\/assets.datacamp.com\/course\/Kaggle\/test.csv\"\n#test = pd.read_csv(test_url)\n\n\n#Solte os recursos que n\u00e3o usaremos\ntrain = train.drop(['Name','SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\ntest = test.drop(['Name','SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\n\n#Veja as 3 primeiras linhas dos nossos dados de treinamento\ntrain.head(3)","e539a563":"#Converter ['male','female'] para [1,0] para que nossa \u00e1rvore de decis\u00e3o possa ser constru\u00edda\nfor df in [train,test]:\n    df['Sex_binary']=df['Sex'].map({'male':1,'female':0})\n    \n#Preencha os valores de idade ausentes com 0 (presumindo que sejam beb\u00eas se n\u00e3o tiverem uma idade listada)\ntrain['Age'] = train['Age'].fillna(0)\ntest['Age'] = test['Age'].fillna(0)\n\n#Select feature column names and target variable we are going to use for training\nfeatures = ['Pclass','Age','Sex_binary']\ntarget = 'Survived'\n\n#Observe as primeiras 3 linhas (temos mais de 800 linhas no total) dos nossos dados de treinamento. \n#Este \u00e9 o \"input\" que nosso classificador usar\u00e1 como \"input\"\ntrain[features].head(3)","02cd7db6":"train.info()\nprint('_'*40)\ntest.info()\n","3dddc13e":"#Exibe as primeiras 3 vari\u00e1veis de destino\ntrain[target].head(3).values","8ed0338a":"from sklearn.tree import DecisionTreeClassifier\n\n#Criar um objeto classificador com hiperpar\u00e2metros padr\u00e3o\n#clf = DecisionTreeClassifier()  \nclf = DecisionTreeClassifier(max_depth=3,min_samples_leaf=2)\n#Ajuste nosso classificador usando os recursos de treinamento e os valores de meta de treinamento\nclf.fit(train[features],train[target]) ","c72d05f5":"#Create decision tree \".dot\" file\n\n#Remove each '#' below to uncomment the two lines and export the file.\n#from sklearn.tree import export_graphviz\n#export_graphviz(clf,out_file='titanic_tree.dot',feature_names=features,rounded=True,filled=True,class_names=['Survived','Did not Survive'])","536ca6a0":"#Display decision tree\n\n#Blue on a node or leaf means the tree thinks the person did not survive\n#Orange on a node or leaf means that tree thinks that the person did survive\n\n#In Chrome, to zoom in press control +. To zoom out, press control -. If you are on a Mac, use Command.\n\n#Remove each '#' below to run the two lines below.\n#from IPython.core.display import Image, display\n#display(Image('titanic_tree.png', width=1900, unconfined=True))","81f481c8":"#Fa\u00e7a previs\u00f5es usando os recursos do conjunto de dados de teste\npredictions = clf.predict(test[features])\n\n#Exibir nossas previs\u00f5es - elas s\u00e3o 0 ou 1 para cada inst\u00e2ncia de treinamento \n#dependendo se nosso algoritmo acredita que a pessoa sobreviveu ou n\u00e3o.\npredictions","72205e41":"#Crie um DataFrame com os IDs dos passageiros e nossa previs\u00e3o sobre se eles sobreviveram ou n\u00e3o\nsubmission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})\n\n#Visualize as primeiras 5 linhas\nsubmission.head()","f9106667":"#Converter DataFrame em um arquivo csv que pode ser carregado\n#Isso \u00e9 salvo no mesmo diret\u00f3rio do seu notebook\nfilename = 'Titanic Predictions 2.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","25bb267e":"> # 3. Fazer previs\u00f5es\n","807cebfc":"### Prepare os dados para serem lidos pelo nosso algoritmo","654ee5a8":"[](http:\/\/)# 2. Crie e ajuste a \u00e1rvore de decis\u00e3o\n\n\nEsta \u00e1rvore definitivamente vai sobrecarregar nossos dados. Quando chegar ao est\u00e1gio de desafio, voc\u00ea pode retornar aqui e ajustar os hiperpar\u00e2metros nesta c\u00e9lula. Por exemplo, voc\u00ea pode reduzir a profundidade m\u00e1xima da \u00e1rvore para 3 definindo max_depth=3 com o seguinte comando:\n>clf = DecisionTreeClassifier(max_depth=3)\n\nPara alterar v\u00e1rios hiperpar\u00e2metros, separe os par\u00e2metros com uma v\u00edrgula.Por exemplo, para alterar a taxa de aprendizado e amostras \"samples\" m\u00ednimas por folha \"leaf\" e a profundidade m\u00e1xima, preencha os par\u00eanteses com o seguinte:\n>clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf=2)\n\nOs outros par\u00e2metros est\u00e3o listados abaixo.\nVoc\u00ea tamb\u00e9m pode acessar a lista de par\u00e2metros lendo o [documentation](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) \npara classificadores de \u00e1rvore de decis\u00e3o. Outra maneira de acessar os par\u00e2metros \u00e9 colocar o cursor entre os par\u00eanteses e pressionar a tecla shift.\n","af583649":"# Desafios\n\nA \u00e1rvore de decis\u00e3o padr\u00e3o d\u00e1 uma pontua\u00e7\u00e3o de 0,70813 colocando voc\u00ea na posi\u00e7\u00e3o 8,070 de 8.767. Voc\u00ea pode melhorar isso?\n\n### Level 1: First time on Kaggle\n\nN\u00edvel 1a: Voc\u00ea pode tentar dar \u00e0 \u00e1rvore uma profundidade m\u00e1xima para melhorar sua pontua\u00e7\u00e3o?\n\nLevel 1b:  Voc\u00ea pode importar diferentes modelos de \u00e1rvore, como o Random Forest Classifier para ver como isso afeta sua pontua\u00e7\u00e3o? Use a seguinte linha de c\u00f3digo para cri\u00e1-lo. Compare este modelo com uma \u00e1rvore de decis\u00e3o com depth 3.\n> from sklearn.ensemble import RandomForestClassifier<br>\n> clf = RandomForestClassifier() ****\n\n\n### Level 2: Enviado para Kaggle antes\nLevel 2a: Voc\u00ea pode incluir outros recursos que foram descartados para melhorar sua pontua\u00e7\u00e3o? N\u00e3o se esque\u00e7a de lidar com quaisquer dados perdidos.\n<br><br>\nLevel 2b: Voc\u00ea consegue visualizar seus dados usando matplotlib ou seaborn para obter outras ideias de como melhorar suas previs\u00f5es?\n\n### Level 3: Alguma familiaridade com o scikit-learn\nLevel 3a: Voc\u00ea pode usar GridSearchCV de sklearn.model_selection no Random Forest Classifier para ajustar os hyperparameters e melhorar sua pontua\u00e7\u00e3o?\n<br><br>\nLevel 3b: Voc\u00ea pode treinar uma lista de modelos e, em seguida, avaliar cada um usando a fun\u00e7\u00e3o sklearn.metrics train_test_split para ver qual lhe d\u00e1 a melhor pontua\u00e7\u00e3o?\n<br><br>\nLevel 3c: Voc\u00ea pode pegar a lista do desafio 3b e depois ter os melhores modelos da lista votando sobre como cada predi\u00e7\u00e3o deve ser feita?","21ab4f27":"> \nEste tutorial orienta voc\u00ea ao enviar um arquivo \".csv\" de previs\u00f5es para Kaggle pela primeira vez.<br><br>\n\n### Pontua\u00e7\u00e3o e desafios:<br>\n\nSe voc\u00ea simplesmente executar o c\u00f3digo abaixo, sua pontua\u00e7\u00e3o ser\u00e1 bastante baixa. Eu deixei intencionalmente muito espa\u00e7o para melhorias em rela\u00e7\u00e3o ao modelo usado (atualmente um simples classificador de \u00e1rvore de decis\u00e3o). <br> <br> A id\u00e9ia deste tutorial \u00e9 come\u00e7ar e tomar as decis\u00f5es de como melhorar sua pontua\u00e7\u00e3o. Na parte inferior do tutorial, h\u00e1 desafios que, se voc\u00ea segui-los, melhorar\u00e3o significativamente sua pontua\u00e7\u00e3o.\n\n\n\n### Etapas para concluir este tutorial no seu pr\u00f3prio computador:\nO kernel abaixo pode ser executado no navegador. Mas se voc\u00ea quiser executar o c\u00f3digo localmente em seu pr\u00f3prio computador, siga as etapas abaixo.\n1. Crie uma conta Kaggle (https:\/\/www.kaggle.com\/).\n2. Download do conjunto de dados do Titanic (https:\/\/www.kaggle.com\/c\/titanic\/data).<br>\n    a. Download 'train.csv' and 'test.csv'.<br>\n    b. Coloque os dois arquivos em uma pasta chamada 'input'.<br>\n    c. Coloque essa pasta no mesmo diret\u00f3rio do seu notebook.\n3. Instale [Jupyter Notebooks](https:\/\/jupyter.org\/) (Siga minha [installation tutorial](http:\/\/joshlawman.com\/getting-set-up-in-jupyter-notebooks-using-anaconda-to-install-the-jupyter-pandas-sklearn-etc\/)se voc\u00ea est\u00e1 confuso)\n4. Baixe este kernel como um [notebook](https:\/\/github.com\/jlawman\/Meetup\/blob\/master\/11.7%20Meetup%20-%20Decision%20Trees\/Submit%20your%20first%20Kaggle%20prediction%20-%20Titanic%20Dataset.ipynb) with empty cells from my GitHub. If you are new to GitHub go [the repository folder](https:\/\/github.com\/jlawman\/Meetup), clique \"Clone or Download\", \nem seguida, descompacte o arquivo e retire o bloco de anota\u00e7\u00f5es desejado.\n5. Corra cada c\u00e9lula do caderno (except the optional visualization cells).\n6. Envie o arquivo CSV contendo as previs\u00f5es.\n7. Tente melhorar a previs\u00e3o usando as solicita\u00e7\u00f5es de desafio adequadas ao seu n\u00edvel.","7532ba9e":"# 4. Crie o csv para fazer o upload para o Kaggle","c03a1ecc":"****NNote, se voc\u00ea quiser gerar uma nova \u00e1rvore png, voc\u00ea precisa abrir o terminal (ou prompt de comando) depois de executar a c\u00e9lula acima. Navegue at\u00e9 o diret\u00f3rio em que voc\u00ea possui este bloco de notas e digite o seguinte comando\n>dot -Tpng titanic_tree.dot -o titanic_tree.png<br><br>","ef1c1aa5":"****### Visualize a \u00e1rvore padr\u00e3o (opcional)\nEste n\u00e3o \u00e9 um passo necess\u00e1rio, mas mostra qu\u00e3o complexa \u00e9 a \u00e1rvore quando voc\u00ea n\u00e3o a restringe. Para completar esta se\u00e7\u00e3o de visualiza\u00e7\u00e3o, voc\u00ea deve estar passando pelo c\u00f3digo em seu computador.","ea846d6e":"**# 5. Enviar arquivo para o Kaggle\n\nV\u00e1 at\u00e9 [submission section](https:\/\/www.kaggle.com\/c\/titanic\/submit) do concurso Titanic. Arraste seu arquivo do diret\u00f3rio que cont\u00e9m seu c\u00f3digo e fa\u00e7a sua submiss\u00e3o.<br><br> \nParab\u00e9ns - voc\u00ea est\u00e1 no placar!****","6bf84681":"## 1. Process the data\n\n### Load data","96ff46de":"\nNossos dados possuem as seguintes colunas:\n- PassengerId - O id de cada passageiro\n- Survived - Se o passageiro sobreviveu ou n\u00e3o (1 - sim, 0 - n\u00e3o)\n- Pclass - A classe de passageiros: (1 \u00aa classe - 1, 2\u00aa classe - 2, 3\u00aa classe - 3)\n- Sex - Sexo de cada passageiro\n- Age - A idade de cada passageiro","b350652b":"Vamos examinar as tr\u00eas primeiras vari\u00e1veis-alvo correspondentes. Esta \u00e9 a medida de se o passageiro sobreviveu ou n\u00e3o (i.e. o primeiro passageiro(22 de idade do sexo masculino) n\u00e3o sobreviveu, \nmas o segundo passageiro (38 anos de idade do sexo feminino sobreviveram).\n<br><br>\nNosso classificador usar\u00e1 isso para saber qual deve ser a sa\u00edda para cada uma das inst\u00e2ncias de treinamento."}}