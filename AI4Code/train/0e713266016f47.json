{"cell_type":{"4ab9f690":"code","d0e77b0a":"code","7df4a8d4":"code","9e8bc659":"code","2cbb6b0f":"code","b32353de":"code","2e2f1b68":"code","8f9b2457":"code","b400bf1b":"code","f931087c":"code","cd1b9129":"code","d0be51bb":"code","355aeeab":"code","2b6f1227":"code","99e9bc60":"code","9c12681e":"code","71f61e95":"code","a8726cad":"markdown","ac34da62":"markdown","9bf571e1":"markdown","5973f892":"markdown","9a4333d5":"markdown","f3f6a1da":"markdown","521fa2ca":"markdown"},"source":{"4ab9f690":"# system\nimport os, time, datetime\n# data structure\nimport pandas as pd\nimport numpy as np\n\n# model\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.keras.utils.data_utils import Sequence\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import manifold, datasets\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.ticker import NullFormatter\n\n# utilities\nfrom collections import OrderedDict\nfrom functools import partial\nfrom time import time\n","d0e77b0a":"root_dir = '..\/input\/lish-moa\/'\nos.listdir(root_dir)","7df4a8d4":"train_features_dir = root_dir + 'train_features.csv'\ntrain_targets_dir = root_dir + 'train_targets_scored.csv'\ntest_features_dir = root_dir + 'test_features.csv'\ntrain_features = pd.read_csv(train_features_dir)\ntrain_targets = pd.read_csv(train_targets_dir).drop(columns = 'sig_id')\ntest_features = pd.read_csv(test_features_dir)\ntest_id = test_features['sig_id']","9e8bc659":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n    del df['sig_id']\n    return df\ntrain_features = preprocess(train_features)\ntest_features = preprocess(test_features)","2cbb6b0f":"def onlyPositive(X,y):\n    positive_index = y.eq(1).any(1)\n    X = X[y.eq(1).any(1)]\n    y = y[y.eq(1).any(1)]\n    return X,y","b32353de":"feature_names = list(train_features.columns)\ntarget_names = list(train_targets.columns)","2e2f1b68":"MoA_sum = train_targets.sum().to_frame().reset_index(drop=False).rename(columns={\"index\": \"MoA\", 0: \"sum\"}).sort_values(ascending = False, by= 'sum')\n\nfig, ax = plt.subplots()\nplt.barh(MoA_sum.head(20)['MoA'], MoA_sum.head(20)['sum'])\nplt.gca().invert_yaxis()\nplt.title('The count of MoAs')\nplt.show()\nMoA_sum.head(20)","8f9b2457":"n_neighbors = 10\nn_components = 3","b400bf1b":"# Set-up manifold methods\nLLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')\n\nmethods = OrderedDict()\n# methods['LLE'] = LLE(method='standard')\n# methods['LTSA'] = LLE(method='ltsa')\n# methods['Hessian LLE'] = LLE(method='hessian')\n# methods['Modified LLE'] = LLE(method='modified')\nmethods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\nmethods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=1)\nmethods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n                                           n_neighbors=n_neighbors)\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)","f931087c":"frac = 0.2\nprint(train_features.shape, train_targets.shape)\nCP = train_features.iloc[:,0:3].sample(frac = frac, random_state = 0)\nCP_name = list(CP.columns)\nCP = np.array(CP)\nX = train_features.drop(columns = CP_name).sample(frac = frac, random_state = 0)\nX = np.array(X)\ntargets = train_targets.sample(frac = frac, random_state = 0)\ntargets = np.array(targets)\nprint(X.shape, targets.shape)","cd1b9129":"# calculate results\nY = np.empty((len(methods), X.shape[0], 3), dtype=float)\nt = np.empty((len(methods)), dtype=float)\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()\n    Y[i,] = method.fit_transform(X)\n    t[i] = time() - t0\n    print(\"%s: %.2g sec\" % (label, t[i]))\n","d0be51bb":"# show the control feature\nctl_train_features_index = train_features.iloc[:,0].sample(frac = frac, random_state = 0) ==1\nfig = plt.figure(figsize=(18,6))\nfor i, (label, method) in enumerate(methods.items()):\n    Y_ctl = Y[i,][ctl_train_features_index]\n    ax = fig.add_subplot(1,4, 1 + i, projection='3d')\n    ax.scatter(Y_ctl[:, 0], Y_ctl[:, 1], Y_ctl[:, 2], alpha = 0.1)\n    ax.set_title(\"%s\" % (label))\n    ax.xaxis.set_major_formatter(NullFormatter())\n    ax.yaxis.set_major_formatter(NullFormatter())\n    ax.axis('tight')\n#     if i >= 0:\n#         break\nplt.show()","355aeeab":"# Create figure\nfor j in np.arange(3):\n    fig = plt.figure(figsize=(18,6))\n    fig.suptitle(\"Manifold Learning with %i neighbors: %s [index: %s]\" % (n_neighbors, CP_name[j], j), fontsize=14)\n    for i, (label, method) in enumerate(methods.items()):\n        ax = fig.add_subplot(1,4, 1 + i, projection='3d')\n        ax.scatter(Y[i,][:, 0], Y[i,][:, 1], Y[i,][:, 2], c=CP[:,j], cmap=plt.cm.brg, alpha = 0.1)\n        ax.set_title(\"%s\" % (label))\n        ax.xaxis.set_major_formatter(NullFormatter())\n        ax.yaxis.set_major_formatter(NullFormatter())\n        ax.axis('tight')\n#     if i >= 0:\n#         break\n    plt.show()","2b6f1227":"# droping CP col\ntrain_features, train_targets = onlyPositive(train_features, train_targets)\nprint(train_features.shape, train_targets.shape)","99e9bc60":"frac = 0.3\n\nX = train_features.sample(frac = frac, random_state = 0)\nX = np.array(X)\ntargets = train_targets.sample(frac = frac, random_state = 0)\ntargets = np.array(targets)\nprint(X.shape, targets.shape)","9c12681e":"# calculate results\nY = np.empty((len(methods), X.shape[0], 3), dtype=float)\nt = np.empty((len(methods)), dtype=float)\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()\n    Y[i,] = method.fit_transform(X)\n    t[i] = time() - t0\n    print(\"%s: %.2g sec\" % (label, t[i]))\n","71f61e95":"# Create figure\n# n_show = 10\n# n = 0\nfor j in np.array(MoA_sum.reset_index(drop=False)['index']):\n    fig = plt.figure(figsize=(18,6))\n    fig.suptitle(\"Manifold Learning with %i neighbors: %s [index: %s]\" % (n_neighbors, target_names[j], j), fontsize=14)\n    for i, (label, method) in enumerate(methods.items()):\n\n        # 2d plot\n#         ax = fig.add_subplot(1,4, 1 + i)\n#         ax.scatter(Y[i,][:, 0], Y[i,][:, 1], c=targets[:,j], cmap=plt.cm.Spectral)\n        # 3d plot\n        ax = fig.add_subplot(1,4, 1 + i, projection='3d')\n        ax.scatter(Y[i,][:, 0], Y[i,][:, 1], Y[i,][:, 2], c=targets[:,j], cmap=plt.cm.binary, alpha = 0.1)\n        ax.set_title(\"%s\" % (label))\n        ax.xaxis.set_major_formatter(NullFormatter())\n        ax.yaxis.set_major_formatter(NullFormatter())\n        ax.axis('tight')\n#     if i >= 0:\n#         break\n#     n += 1\n#     if n >= n_show:\n#         break\n    plt.show()","a8726cad":"# Manifold Model\n\nIn the following models, we will take a look at how data look like in 3d, by removing the MoAs.","ac34da62":"## visualize by CP","9bf571e1":"# read file","5973f892":"## setup","9a4333d5":"## visualize by MoA","f3f6a1da":"# The count of MoAs","521fa2ca":"# Preprocess"}}