{"cell_type":{"ed9aabee":"code","7b682f6f":"code","ebe7f592":"code","6e4ad8e6":"code","3c2defa4":"code","d2ceea95":"code","efec0fa2":"code","eab9b76c":"code","613bda5b":"code","19a64f52":"code","336d719b":"code","5724a895":"code","ff4fd265":"code","da6784a5":"code","af59b99b":"code","c0224f1f":"code","e0ca3262":"code","612b4309":"code","f1490ecb":"code","de27c77c":"code","fb3fbb29":"code","64dee30b":"code","e5794c9e":"code","b993a5a8":"code","6cdd111d":"code","1776084e":"code","c0ee3e59":"code","3165d377":"code","4ef35def":"code","dbad723b":"code","f56a9ae6":"code","932d90b2":"code","48b632b2":"code","a7c9c029":"code","2b32053a":"code","13d0c2e9":"code","ef6f0de5":"code","96107703":"code","c25f6fe6":"code","ab15a52e":"code","87c1332f":"code","355cf617":"code","291fabe4":"code","10e0672d":"code","64b45081":"code","c7d565d4":"code","781fc41e":"code","1fe16ab8":"code","71adf550":"code","a3de9620":"code","6360305d":"code","02a8090d":"code","597f8f7c":"code","6486bfea":"code","25eb104a":"code","5b83f3b6":"code","cc81e19a":"code","4ffa02b8":"code","af2ac787":"code","b846089e":"code","1fde9553":"code","10cc9276":"code","8b9aedc4":"code","f93719d2":"code","db37a9b1":"markdown","a89c0abf":"markdown","4c51ccb7":"markdown","3604e540":"markdown","5f6cfbf4":"markdown","021ff5ca":"markdown","901ceae9":"markdown","e9c8fc76":"markdown","90f4e1c8":"markdown","8f1c2fba":"markdown","97a7fff7":"markdown","5b54c8e8":"markdown","4886a56b":"markdown","1f59010e":"markdown","1a2084e1":"markdown","8e5265d3":"markdown","ad43a85b":"markdown","fe7d748f":"markdown","ae40516d":"markdown","c889b8fe":"markdown","1182229d":"markdown","e07bac8f":"markdown","94087848":"markdown"},"source":{"ed9aabee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np,gc # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7b682f6f":"cols_t = ['TransactionID', 'TransactionDT', 'TransactionAmt',\n       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n       'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n       'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n       'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8',\n       'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4',\n       'M5', 'M6', 'M7', 'M8', 'M9']\ncols_v = ['V'+str(x) for x in range(1,340)]; types_v = {}\nfor c in cols_v: types_v[c] = 'float32'\ntrain = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv',usecols=cols_t+['isFraud']+cols_v,dtype=types_v)","ebe7f592":"nans_df = train.isna()\nnans_groups={}\ni_cols = ['V'+str(i) for i in range(1,340)]\nfor col in train.columns:\n    cur_group = nans_df[col].sum()\n    try:\n        nans_groups[cur_group].append(col)\n    except:\n        nans_groups[cur_group]=[col]\ndel nans_df; x=gc.collect()\n\nfor k,v in nans_groups.items():\n    print('####### NAN count =',k)\n    print(v)","6e4ad8e6":"Vc = ['dayr','isFraud','TransactionAmt','card1','addr1','D1n','D11n']\nVs = nans_groups[279287]\nVtitle = 'V1 - V11, D11'","3c2defa4":"def make_plots(Vs):\n    col = 4\n    row = len(Vs)\/\/4+1\n    plt.figure(figsize=(20,row*5))\n    idx = train[~train[Vs[0]].isna()].index\n    for i,v in enumerate(Vs):\n        plt.subplot(row,col,i+1)\n        n = train[v].nunique()\n        x = np.sum(train.loc[idx,v]!=train.loc[idx,v].astype(int))\n        y = np.round(100*np.sum(train[v].isna())\/len(train),2)\n        t = 'int'\n        if x!=0: t = 'float'\n        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n        plt.yticks([])\n        h = plt.hist(train.loc[idx,v],bins=100)\n        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n    plt.show()\nmake_plots(Vs)","d2ceea95":"def make_corr(Vs,Vtitle=''):\n    cols = ['TransactionDT'] + Vs\n    plt.figure(figsize=(15,15))\n    sns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n    if Vtitle!='': plt.title(Vtitle,fontsize=14)\n    else: plt.title(Vs[0]+' - '+Vs[-1],fontsize=14)\n    plt.show()\nmake_corr(Vs,Vtitle)","efec0fa2":"grps = [[1],[2,3],[4,5],[6,7],[8,9],[10,11]]\ndef reduce_group(grps,c='V'):\n    use = []\n    for g in grps:\n        mx = 0; vx = g[0]\n        for gg in g:\n            n = train[c+str(gg)].nunique()\n            if n>mx:\n                mx = n\n                vx = gg\n            #print(str(gg)+'-'+str(n),', ',end='')\n        use.append(vx)\n        #print()\n    print('Use these',use)\nreduce_group(grps)","eab9b76c":"Vs = nans_groups[76073]\nmake_plots(Vs)\nmake_corr(Vs)","613bda5b":"grps = [[12,13],[14],[15,16,17,18,21,22,31,32,33,34],[19,20],[23,24],[25,26],[27,28],[29,30]]\nreduce_group(grps)","19a64f52":"Vs = nans_groups[168969]\nmake_plots(Vs)\nmake_corr(Vs)","336d719b":"grps = [[35,36],[37,38],[39,40,42,43,50,51,52],[41],[44,45],[46,47],[48,49]]\nreduce_group(grps)","5724a895":"Vs = nans_groups[77096]\nmake_plots(Vs)\nmake_corr(Vs)","ff4fd265":"grps = [[53,54],[55,56],[57,58,59,60,63,64,71,72,73,74],[61,62],[65],[66,67],[68],[69,70]]\nreduce_group(grps)","da6784a5":"Vs = nans_groups[89164]\nmake_plots(Vs)\nmake_corr(Vs)","af59b99b":"grps = [[75,76],[77,78],[79,80,81,84,85,92,93,94],[82,83],[86,87],[88],[89],[90,91]]\nreduce_group(grps)","c0224f1f":"Vs = nans_groups[314]\nmake_corr(Vs)","e0ca3262":"Vs = ['V'+str(x) for x in range(95,107)]\nmake_plots(Vs)\nmake_corr(Vs)","612b4309":"grps = [[95,96,97,101,102,103,105,106],[98],[99,100],[104]]\nreduce_group(grps)","f1490ecb":"Vs = ['V'+str(x) for x in range(107,124)]\nmake_plots(Vs)\nmake_corr(Vs)","de27c77c":"grps = [[107],[108,109,110,114],[111,112,113],[115,116],[117,118,119],[120,122],[121],[123]]\nreduce_group(grps)","fb3fbb29":"Vs = ['V'+str(x) for x in range(124,138)]\nmake_plots(Vs)\nmake_corr(Vs)","64dee30b":"grps = [[124,125],[126,127,128,132,133,134],[129],[130,131],[135,136,137]]\nreduce_group(grps)","e5794c9e":"Vs = nans_groups[508595]\nmake_plots(Vs)\nmake_corr(Vs)","b993a5a8":"grps = [[138],[139,140],[141,142],[146,147],[148,149,153,154,156,157,158],[161,162,163]]\nreduce_group(grps)","6cdd111d":"Vs = nans_groups[508589]\nmake_plots(Vs)\nmake_corr(Vs)","1776084e":"grps = [[143,164,165],[144,145,150,151,152,159,160],[166]]\nreduce_group(grps)","c0ee3e59":"Vs = [x for x in nans_groups[450909]]\nmake_corr(Vs)","3165d377":"Vs = [x for x in nans_groups[450909] if int(x[1:])<186]\nmake_plots(Vs)\nmake_corr(Vs)","4ef35def":"grps = [[167,168,177,178,179],[172,176],[173],[181,182,183]]\nreduce_group(grps)","dbad723b":"Vs = [x for x in nans_groups[450909] if (int(x[1:])>183)]\nmake_plots(Vs)\nmake_corr(Vs)","f56a9ae6":"grps = [[186,187,190,191,192,193,196,199],[202,203,204,211,212,213],[205,206],[207],[214,215,216]]\nreduce_group(grps)","932d90b2":"Vs = nans_groups[450721]\nmake_plots(Vs)\nmake_corr(Vs)","48b632b2":"grps = [[169],[170,171,200,201],[174,175],[180],[184,185],[188,189],[194,195,197,198],[208,210],[209]]\nreduce_group(grps)","a7c9c029":"Vs = [x for x in nans_groups[460110]]\nmake_corr(Vs)","2b32053a":"Vs = [x for x in nans_groups[460110] if int(x[1:])<240]\nmake_plots(Vs)\nmake_corr(Vs)","13d0c2e9":"grps = [[217,218,219,231,232,233,236,237],[223],[224,225],[226],[228],[229,230],[235]]\nreduce_group(grps)","ef6f0de5":"Vs = [x for x in nans_groups[460110] if (int(x[1:])>237)&(int(x[1:])<263)]\nmake_plots(Vs)\nmake_corr(Vs)","96107703":"grps = [[240,241],[242,243,244,258],[246,257],[247,248,249,253,254],[252],[260],[261,262]]\nreduce_group(grps)","c25f6fe6":"Vs = [x for x in nans_groups[460110] if (int(x[1:])>262)]\nmake_plots(Vs)\nmake_corr(Vs)","ab15a52e":"grps = [[263,265,264],[266,269],[267,268],[273,274,275],[276,277,278]]\nreduce_group(grps)","87c1332f":"Vs = nans_groups[449124]\nmake_plots(Vs)\nmake_corr(Vs)","355cf617":"grps = [[220],[221,222,227,245,255,256,259],[234],[238,239],[250,251],[270,271,272]]\nreduce_group(grps)","291fabe4":"Vs = [x for x in nans_groups[12]]\nmake_corr(Vs)","10e0672d":"Vs = [x for x in nans_groups[12] if int(x[1:])<302]\nmake_plots(Vs)\nmake_corr(Vs)","64b45081":"grps = [[279,280,293,294,295,298,299],[284],[285,287],[286],[290,291,292],[297]]\nreduce_group(grps)","c7d565d4":"Vs = [x for x in nans_groups[12] if int(x[1:])>299]\nmake_plots(Vs)\nmake_corr(Vs)","781fc41e":"grps = [[302,303,304],[305],[306,307,308,316,317,318],[309,311],[310,312],[319,320,321]]\nreduce_group(grps)","1fe16ab8":"Vs = nans_groups[1269]\nmake_plots(Vs)\nVtitle = 'V281 - V315, D1'\nmake_corr(Vs,Vtitle)","71adf550":"grps = [[281],[282,283],[288,289],[296],[300,301],[313,314,315]]\nreduce_group(grps)","a3de9620":"Vs = nans_groups[508189]\nmake_plots(Vs)\nmake_corr(Vs)","6360305d":"grps = [[322,323,324,326,327,328,329,330,331,332,333],[325],[334,335,336],[337,338,339]]\nreduce_group(grps)","02a8090d":"v =  [1, 3, 4, 6, 8, 11]\nv += [13, 14, 17, 20, 23, 26, 27, 30]\nv += [36, 37, 40, 41, 44, 47, 48]\nv += [54, 56, 59, 62, 65, 67, 68, 70]\nv += [76, 78, 80, 82, 86, 88, 89, 91]\nv += [96, 98, 99, 104]\nv += [107, 108, 111, 115, 117, 120, 121, 123]\nv += [124, 127, 129, 130, 136]\nv += [138, 139, 142, 147, 156, 162]\nv += [165, 160, 166]\nv += [178, 176, 173, 182]\nv += [187, 203, 205, 207, 215]\nv += [169, 171, 175, 180, 185, 188, 198, 210, 209]\nv += [218, 223, 224, 226, 228, 229, 235]\nv += [240, 258, 257, 253, 252, 260, 261]\nv += [264, 266, 267, 274, 277]\nv += [220, 221, 234, 238, 250, 271]\nv += [294, 284, 285, 286, 291, 297]\nv += [303, 305, 307, 309, 310, 320]\nv += [281, 283, 289, 296, 301, 314]\nv += [332, 325, 335, 338]","597f8f7c":"print('Reduced set has',len(v),'columns')","6486bfea":"cols = ['TransactionDT'] + ['V'+str(x) for x in v]\ntrain2 = train[cols].sample(frac=0.2)\nplt.figure(figsize=(15,15))\nsns.heatmap(train2[cols].corr(), cmap='RdBu_r', annot=False, center=0.0)\nplt.title('V1-V339 REDUCED',fontsize=14)\nplt.show()","25eb104a":"cols = ['TransactionDT'] + ['V'+str(x) for x in range(1,340)]\ntrain2 = train[cols].sample(frac=0.2)\nplt.figure(figsize=(15,15))\nsns.heatmap(train2[cols].corr(), cmap='RdBu_r', annot=False, center=0.0)\nplt.title('V1-V339 ALL',fontsize=14)\nplt.show()","5b83f3b6":"def make_plots2(Vs):\n    col = 4\n    row = len(Vs)\/\/4+1\n    plt.figure(figsize=(20,row*5))\n    for i,v in enumerate(Vs):\n        plt.subplot(row,col,i+1)\n        idx = train[~train[v].isna()].index\n        n = train[v].nunique()\n        x = np.sum(train.loc[idx,v]!=train.loc[idx,v].astype(int))\n        y = np.round(100*np.sum(train[v].isna())\/len(train),2)\n        t = 'int'\n        if x!=0: t = 'float'\n        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n        plt.yticks([])\n        h = plt.hist(train.loc[idx,v],bins=100)\n        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n    plt.show()\nmake_plots2(['C'+str(x) for x in range(1,15)])","cc81e19a":"cols = ['TransactionDT'] + ['C'+str(x) for x in range(1,15)]\nplt.figure(figsize=(15,15))\nsns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.title('C1-C15')\nplt.show()","4ffa02b8":"cols = ['TransactionDT'] + ['D'+str(x) for x in range(1,16)]\nplt.figure(figsize=(15,15))\nsns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.title('D1-D15')\nplt.show()","af2ac787":"Ms = ['M'+str(x) for x in range(1,10)]\nmp = {'F':0,'T':1,'M0':0,'M1':1,'M2':2}\nfor c in Ms: train[c] = train[c].map(mp)","b846089e":"cols = ['TransactionDT'] + Ms\nplt.figure(figsize=(15,15))\nsns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.title('M1-M9')\nplt.show()","1fde9553":"train_id = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv')\ntrain_id = pd.merge(train_id,train[['TransactionID','TransactionDT']],on='TransactionID',how='left')\nids = ['id_0'+str(x) for x in range(1,10)]+['id_'+str(x) for x in range(10,39)]\nfor c in ids: print (c,train_id[c].unique()[:10])","10cc9276":"booln = ['id_12','id_15','id_16','id_27','id_28','id_29','id_35','id_36','id_37','id_38']\ncats = ['id_23','id_30','id_31','id_33','id_34']\nmp = {'Unknown':0,'NotFound':1,'Found':2,'New':3,'F':0,'T':1}\nfor c in booln: train_id[c] = train_id[c].map(mp)","8b9aedc4":"def make_plots2(Vs):\n    col = 4\n    row = len(Vs)\/\/4+1\n    plt.figure(figsize=(20,row*5))\n    for i,v in enumerate(Vs):\n        plt.subplot(row,col,i+1)\n        idx = train_id[~train_id[v].isna()].index\n        n = train_id[v].nunique()\n        x = np.sum(train_id.loc[idx,v]!=train_id.loc[idx,v].astype(int))\n        y = np.round(100*np.sum(train_id[v].isna())\/len(train_id),2)\n        t = 'int'\n        if x!=0: t = 'float'\n        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n        plt.yticks([])\n        h = plt.hist(train_id.loc[idx,v],bins=100)\n        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n    plt.show()\nmake_plots2([x for x in ids if x not in cats])","f93719d2":"cols = ['TransactionDT'] + [x for x in ids if x not in cats]\nplt.figure(figsize=(15,15))\nsns.heatmap(train_id[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.title('ID1-ID38')\nplt.show()","db37a9b1":"# V281 ~ V315, D1","a89c0abf":"# V143 ~ V166","4c51ccb7":"# C Columns","3604e540":"# V220 ~ V272","5f6cfbf4":"# ID Columns","021ff5ca":"# NAN search\nWe will search all the columns of `train_transaction.csv` to determine which columns are related by the number of NANs present. We see that D1 relates to a subset of V281 thru V315, and D11 relates to V1 thru V11. Also we find groups of Vs with similar NAN structure. And we see that M1, M2, M3 related and M8, M9 related.","901ceae9":"# V169 ~ V210","e9c8fc76":"# D Columns","90f4e1c8":"# V138 ~ V163","8f1c2fba":"# M Columns","97a7fff7":"# V53 - V74","5b54c8e8":"# V All\nWe notice that the first 100 Vs don't correlate much with the last 239 Vs. Also even though the first 100 have 6 different NAN groups there is much correlation between the groups. The latter 239 relate to each other.","4886a56b":"# V322 - V339","1f59010e":"# V35 - V52","1a2084e1":"# V95 - V137","8e5265d3":"# EDA for Columns V and ID\nIn Kaggle's Fraud competition, we used Alijs's great EDA [here][111] for the original 53 columns and first 95 V columns. He did not include the remaining 244 V columns nor the ID columns, so we made the following kernel to analyze the missing V and ID columns. We also display correlation between C, D, and M columns.\n\nThe V columns appear to be redundant and correlated. Therefore for each block of V columns with similar NAN structure, we could find subsets within the block that are correlated (r > 0.75). Then we can replace the entire block with one column from each subset. \n\nFor example in block `V1-V11`, we see that the subsets `[[1],[2,3],[4,5],[6,7],[8,9],[10,11]]` exist and we can choose `[1, 3, 4, 6, 8, 11]` to represent the `V1-V11` block without losing that much information. Alternatively you could apply PCA on each block, but this subset reduce method performed better.\n\n[111]: https:\/\/www.kaggle.com\/alijs1\/ieee-transaction-columns-reference","ad43a85b":"# V167 ~ V216","fe7d748f":"# V Reduced\nWow, even this reduced set still has much internal correlation. These V columns are highly redundant!","ae40516d":"# V279 ~ V321","c889b8fe":"# V217 ~ V278","1182229d":"# V75 - V94","e07bac8f":"# V1-V11, D11","94087848":"# V12 - V34"}}