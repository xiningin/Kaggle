{"cell_type":{"275a998b":"code","c35c792a":"code","93a813d1":"code","c5ee6092":"code","937f2d30":"code","7077baec":"code","0e2e9ed2":"code","511b424d":"code","38dcfe6c":"code","5aa734a6":"code","326d60ae":"code","ee893515":"code","31b5f32d":"code","07b943f8":"code","b45a67f6":"code","44663f60":"code","2651d799":"code","e5eb1e5a":"code","5718540e":"code","05bb2384":"code","e347a593":"code","a72c7cdc":"code","223459fa":"code","b7412269":"code","d2a70314":"code","dd588b76":"code","fd6f85f0":"code","da30cc13":"code","f9d1784b":"code","c64ca1da":"code","0d9275ae":"code","03686fdf":"code","0d7c11c5":"code","016dffe6":"markdown","d44b9ae5":"markdown","2074b117":"markdown","19f41dcd":"markdown","8bb8a347":"markdown","506a665f":"markdown","d05d655b":"markdown","47e18f9c":"markdown","53960ec8":"markdown","af2693d0":"markdown","387e5896":"markdown","a2872336":"markdown","66b37f8d":"markdown","b6de15e3":"markdown","94cb4e07":"markdown","07855e14":"markdown","030383af":"markdown","8f8a79e3":"markdown","4186403e":"markdown","a7458005":"markdown","822ab387":"markdown","c88721a1":"markdown","bfee9025":"markdown","5b39820b":"markdown","20fb6918":"markdown","192136d4":"markdown","bff99d53":"markdown","27e63bee":"markdown","852343b0":"markdown","1c47a8be":"markdown","ca12ee92":"markdown","bc8bc3a3":"markdown","945bdb05":"markdown","1c9f4e8c":"markdown","10410c9b":"markdown","e60a83b1":"markdown","481d092f":"markdown","2482f7eb":"markdown","c23461af":"markdown"},"source":{"275a998b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport warnings\nwarnings.filterwarnings('ignore')","c35c792a":"df = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')\ndf.head()","93a813d1":"df.isnull().sum()","c5ee6092":"df.drop(['Unnamed: 0', 'Title'], axis=1, inplace=True)\ndf.dropna(inplace=True)\ndf.isnull().sum()","937f2d30":"def preprocess(ReviewText):\n    ReviewText = ReviewText.str.replace(\"(<br\/>)\", \"\")\n    ReviewText = ReviewText.str.replace('(<a).*(>).*(<\/a>)', '')\n    ReviewText = ReviewText.str.replace('(&amp)', '')\n    ReviewText = ReviewText.str.replace('(&gt)', '')\n    ReviewText = ReviewText.str.replace('(&lt)', '')\n    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')  \n    return ReviewText\n\ndf['Review Text'] = preprocess(df['Review Text'])","7077baec":"df['Polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)\ndf['word_count'] = df['Review Text'].apply(lambda x: len(str(x).split()))\ndf['review_len'] = df['Review Text'].apply(lambda x: len(str(x)))","0e2e9ed2":"cl = df.loc[df.Polarity == 1, ['Review Text']].sample(5).values\nfor c in cl:\n    print(c[0])","511b424d":"cl = df.loc[df.Polarity == 0, ['Review Text']].sample(5).values\nfor c in cl:\n    print(c[0])","38dcfe6c":"cl = df.loc[df.Polarity <= -0.7, ['Review Text']].sample(5).values\nfor c in cl:\n    print(c[0])","5aa734a6":"features = ['Polarity', 'Age', 'review_len', 'word_count']\ntitles = ['Polarity Distribution', 'Age Distribution', 'Review length Distribution', 'Word Count Distribution']\ncolors = ['#9966ff', '#3399ff', '#00ff00', '#ff6600']\n\nfor feature, title, color in zip(features, titles, colors): \n    sns.distplot(x=df[feature], bins=50, color=color)\n    plt.title(title, size=15)\n    plt.xlabel(feature)\n    plt.show()","326d60ae":"sns.countplot(x = 'Rating', palette='viridis', data=df)\nplt.title('Rating Distribution', size=15)\nplt.xlabel('Ratings')\nplt.show()","ee893515":"sns.countplot(x='Division Name', palette='viridis', data=df)\nplt.title('Division distribution', size=15)\nplt.show()","31b5f32d":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Department Name', palette='viridis', data=df)\nplt.title('Department Name', size=15)\nplt.show()","07b943f8":"plt.figure(figsize=(8, 10))\nsns.countplot(y='Class Name', palette='viridis', data=df)\nplt.title('Class Distribution', size=15)\nplt.show()","b45a67f6":"def get_top_ngrams(corpus, ngram_range, stop_words=None, n=None):\n    vec = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    \n    sum_words = bag_of_words.sum(axis=0)\n    \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n    \n    common_words = words_freq[:n]\n    words = []\n    freqs = []\n    for word, freq in common_words:\n        words.append(word)\n        freqs.append(freq)\n        \n    df = pd.DataFrame({'Word': words, 'Freq': freqs})\n    return df","44663f60":"stop_words = None\nn = 20\nunigrams = get_top_ngrams(df['Review Text'], (1, 1), stop_words, n)\nbigrams = get_top_ngrams(df['Review Text'], (2, 2), stop_words, n)\ntrigrams = get_top_ngrams(df['Review Text'], (3, 3), stop_words, n)","2651d799":"stop_words = 'english'\nn = 20\nunigrams_st = get_top_ngrams(df['Review Text'], (1, 1), stop_words, n)\nbigrams_st = get_top_ngrams(df['Review Text'], (2, 2), stop_words, n)\ntrigrams_st = get_top_ngrams(df['Review Text'], (3, 3), stop_words, n)","e5eb1e5a":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[0], data=unigrams)\nplt.title('Top 20 Unigrams before removing stopwords', size=15)\nplt.show()","5718540e":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[0], data=unigrams_st)\nplt.title('Top 20 Unigrams after removing stopwords', size=15)\nplt.show()","05bb2384":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[1], data=bigrams)\nplt.title('Top 20 Bigrams before removing stopwords', size=15)\nplt.show()","e347a593":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[1], data=bigrams_st)\nplt.title('Top 20 Unigrams after removing stopwords', size=15)\nplt.show()","a72c7cdc":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[3], data=trigrams)\nplt.title('Top 20 trigrams before removing stopwords', size=15)\nplt.show()","223459fa":"plt.figure(figsize=(8, 10))\nsns.barplot(x='Freq', y='Word', color=colors[3], data=trigrams_st)\nplt.title('Top 20 Trigrams after removing stopwords', size=15)\nplt.show()","b7412269":"blob = TextBlob(str(df['Review Text']))\npos_df = pd.DataFrame(blob.tags, columns=['word', 'pos'])\n#top_pos = pd.DataFrame(pos_df['pos'].value_counts(), columns=['pos', 'count'])\ntop_pos = pos_df['pos'].value_counts()","d2a70314":"plt.figure(figsize=(8, 10))\nsns.barplot(y=top_pos.index, x=top_pos.values, color=colors[0])\nplt.title('Part of Speech tagging of Review Text', size=15)\nplt.show()","dd588b76":"plt.figure(figsize=(10, 6))\nsns.boxplot(x='Department Name', y='Polarity', width=0.5, palette='viridis', data=df)\nplt.title('Sentiment Polarity v\/s Department Name', size=15)\nplt.show()","fd6f85f0":"plt.figure(figsize=(10, 6))\nsns.boxplot(x='Department Name', y='Rating', width=0.5, palette='viridis', data=df)\nplt.title('Rating v\/s Department Name', size=15)\nplt.show()","da30cc13":"plt.figure(figsize=(10, 6))\nsns.boxplot(x='Department Name', y='review_len', width=0.5, palette='viridis', data=df)\nplt.title('Review length v\/s Department Name', size=15)\nplt.show()","f9d1784b":"recommended = df.loc[df['Recommended IND'] == 1, 'Polarity']\nnot_recommended = df.loc[df['Recommended IND'] == 0, 'Polarity']\n\nplt.figure(figsize=(8, 6))\nsns.histplot(x=recommended, color=colors[1], label='Recommended')\nsns.histplot(x=not_recommended, color=colors[3], label='Not Recommended')\nplt.title('Distribution of Sentiment polarity of reviews based on Recommendation', size=15)\nplt.legend()\nplt.show()","c64ca1da":"recommended = df.loc[df['Recommended IND'] == 1, 'Rating']\nnot_recommended = df.loc[df['Recommended IND'] == 0, 'Rating']\n\nplt.figure(figsize=(8, 6))\nsns.distplot(x=recommended, color=colors[1], label='Recommended', )\nsns.distplot(x=not_recommended, color=colors[3], label='Not Recommended')\nplt.title('Distribution of Rating of reviews based on Recommendation', size=15)\nplt.legend()\nplt.show()","0d9275ae":"recommended = df.loc[df['Recommended IND'] == 1, 'review_len']\nnot_recommended = df.loc[df['Recommended IND'] == 0, 'review_len']\n\nplt.figure(figsize=(8, 6))\nsns.histplot(x=recommended, color=colors[1], kde=True, label='Recommended', binwidth=8)\nsns.histplot(x=not_recommended, color=colors[3], kde=True, label='Not Recommended', binwidth=8)\nplt.title('Distribution of Review length of reviews based on Recommendation', size=15)\nplt.legend()\nplt.show()","03686fdf":"plt.figure(figsize=(8, 8))\ng = sns.jointplot(x='Rating', y='Polarity', kind='kde', color=colors[3], data=df)\ng.plot_joint(sns.kdeplot, fill=True, color=colors[3], zorder=0, levels=6)\n\nplt.show()","0d7c11c5":"plt.figure(figsize=(10, 8))\ng = sns.jointplot(x='Age', y='Polarity', kind='kde', color=colors[1], data=df)\ng.plot_joint(sns.kdeplot, fill=True, color=colors[1], zorder=0, levels=6)\nplt.show()","016dffe6":"## Unigrams Distribution","d44b9ae5":"## Distribution of Sentiment polarity of reviews based on Recommendation","2074b117":"## Distribution by Division Name","19f41dcd":"### Polarity <= -0.7","8bb8a347":"## Dataset\n\nThis dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n\n* <b>Clothing ID:<\/b> Integer Categorical variable that refers to the specific piece being reviewed.\n* <b>Age:<\/b> Positive Integer variable of the reviewers age.\n* <b>Title:<\/b> String variable for the title of the review.\n* <b>Review Text:<\/b> String variable for the review body.\n* <b>Rating:<\/b> Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n* <b>Recommended IND:<\/b> Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n* <b>Positive Feedback Count:<\/b> Positive Integer documenting the number of other customers who found this review positive.\n* <b>Division Name:<\/b> Categorical name of the product high level division.\n* <b>Department Name:<\/b> Categorical name of the product department name.\n* <b>Class Name:<\/b> Categorical name of the product class name.","506a665f":"## Import required modules","d05d655b":"## Department name v\/s Sentiment Polarity","47e18f9c":"## Distribution of Review length of reviews based on Recommendation","53960ec8":"The highest sentiment polarity score was achieved by all of the six departments except Trend department, and the lowest sentiment polarity score was collected by Tops department. And the Trend department has the lowest median polarity score. If you remember, the Trend department has the least number of reviews. This explains why it does not have as wide variety of score distribution as the other departments.","af2693d0":"## Distribution of Class","387e5896":"Visually representing the content of a text document is one of the most important tasks in the field of text mining. As a data scientist or NLP specialist, not only we explore the content of documents from different aspects and at different levels of details, but also we summarize a single document, show the words and topics, detect events, and create storylines.","a2872336":"Except Trend department, all the other departments\u2019 median rating were 5. Overall, the ratings are high and sentiment are positive in this review data set.","66b37f8d":"**It is obvious that reviews have higher polarity score are more likely to be recommended.**","b6de15e3":"The median review length of Tops & Intimate departments are relative lower than those of the other departments.","94cb4e07":"## Distribution of Rating of reviews based on Recommendation","07855e14":"## 2D Density jointplot of age and sentiment polarity","030383af":"**There were few people are very positive or very negative. People who give neutral to positive reviews are more likely to be in their 30s. Probably people at these age are likely to be more active.**","8f8a79e3":"we will use Womens Clothing E-Commerce Reviews data set, and try to explore and visualize as much as we can, using Plotly\u2019s Python graphing library and Bokeh visualization library. Not only we are going to explore text data, but also we will visualize numeric and categorical features.\nLet\u2019s get started!","4186403e":"## 2D Density jointplot of rating and sentiment polarity","a7458005":"## Bigrams Distribution","822ab387":"1. **Vast majority of the sentiment polarity scores are greater than zero, means most of them are pretty positive.**\n2. **Most reviewers are in their 30s to 40s.**","c88721a1":"## Let's check most Postive, Neutral and Negative polarity reviews","bfee9025":"## Part-of-Speech Tagging (POS)\n\nPart-Of-Speech Tagging (POS) is a process of assigning parts of speech to each word, such as noun, verb, adjective, etc\n\nI am using a simple TextBlob API to dive into POS of our \u201cReview Text\u201d feature in our data set, and visualize these tags.","5b39820b":"![text.jpg](attachment:99f84d3d-c518-4a1a-94b3-e430e2443661.jpg)","20fb6918":"### Polarity == 0","192136d4":"### Polarity == 1","bff99d53":"## Distribution of review ratings","27e63bee":"## Trigrams Distribution","852343b0":"**The ratings are in align with the polarity score, that is, most of the ratings are pretty high at 4 or 5 ranges.**","1c47a8be":"#### Please Upvote this notebook if you find useful and give feedback","ca12ee92":"## Let's remove null values and unnecessary columns","bc8bc3a3":"**Recommended reviews tend to be lengthier than those of not recommended reviews.**","945bdb05":"**General division has the most number of reviews, and Initmates division has the least number of reviews.**","1c9f4e8c":"## Preprocess the data","10410c9b":"## Distribution of review sentiment polarity score","e60a83b1":"Using [TextBlob](https:\/\/textblob.readthedocs.io\/en\/dev\/) to calculate sentiment polarity which lies in the range of [-1,1] where 1 means positive sentiment and -1 means a negative sentiment.\n\nand also calculating word counts and review length. ","481d092f":"## Unigrams, Bigrams and Trigrams\n\nNow we come to \u201cReview Text\u201d feature, before explore this feature, we need to extract N-Gram features. N-grams are used to describe the number of words used as observation points, e.g., unigram means singly-worded, bigram means 2-worded phrase, and trigram means 3-worded phrase. In order to do this, we use scikit-learn\u2019s [CountVectorizer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html) function.\n\nFirst, it would be interesting to compare unigrams before and after removing stop words.","2482f7eb":"# A Complete EDA and Visualization of Text Data","c23461af":"## Departments Name v\/s Rating"}}