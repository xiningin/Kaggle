{"cell_type":{"aadcc4b7":"code","2592b818":"code","fdba7ca0":"code","fb6d6284":"code","3a688161":"code","c4fb4aa7":"code","c1bc7113":"code","13dff3d5":"code","15b23fd0":"code","78e71389":"code","933d8852":"code","7a45adf0":"code","537f027d":"code","0bc39679":"code","4e3e2507":"code","ed777239":"code","7b30d772":"code","4da74b54":"code","3b587622":"code","47336748":"code","fdaf78d7":"code","460ba561":"code","c60a23b3":"code","6f584e4b":"code","9331a429":"code","74fe5294":"code","4da8d66c":"code","b16fd9ca":"code","3439db9e":"code","f35c4b06":"code","0656434f":"code","d28ce7ec":"code","e62ac153":"code","35855c1a":"code","7262ffd6":"code","7a9dcec5":"code","761ac892":"code","fbca3122":"code","3000bed8":"code","4a816b79":"code","3b412678":"code","aefa6b90":"code","d9c1bcc7":"code","13eb112f":"code","e0170246":"code","cae81c28":"code","3ab7d15a":"markdown","76d71883":"markdown","23637dee":"markdown","e6977872":"markdown","4656e243":"markdown","fe15307a":"markdown","dea14650":"markdown","f85405e8":"markdown","68ec1fd1":"markdown","b3ccbc75":"markdown","b0d959d3":"markdown","b15f63ad":"markdown","86e687b1":"markdown","82039ab9":"markdown","f9f93e51":"markdown","030e3b1a":"markdown","04671551":"markdown","47b5622f":"markdown","dce1a0bb":"markdown","73dcf12f":"markdown","d10591a7":"markdown","337dc4ec":"markdown","1d80bc3b":"markdown","59c9ea44":"markdown","479ffe30":"markdown","d29b684a":"markdown","e8366173":"markdown","08c3af12":"markdown","ea850f69":"markdown","7b5fa946":"markdown","a9430806":"markdown","a1a62507":"markdown","d9d402a7":"markdown","7636b289":"markdown","fc863b77":"markdown","8aed0564":"markdown"},"source":{"aadcc4b7":"# Import Python packages\nimport numpy as np \nimport pandas as pd \nimport os\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom IPython.core import display as ICD\nimport warnings\n\n# Bigger than normal fonts\nsns.set(font_scale=1.75)\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 5000)\nbase_dir = '..\/input\/'\n\nfileName = 'multipleChoiceResponses.csv'\nfilePath = os.path.join(base_dir,fileName)\nmcr = pd.read_csv(filePath)\nmcr_data = mcr.loc[1:, :]\n\nfileName = 'freeFormResponses.csv'\nfilePath = os.path.join(base_dir,fileName)\nffr = pd.read_csv(filePath)\nffr_data = ffr.loc[1:, :]\n\nfileName = 'SurveySchema.csv'\nfilePath = os.path.join(base_dir,fileName)\nschema = pd.read_csv(filePath)","2592b818":"# Prepare data types\nmcr_data['Time from Start to Finish (seconds)'] = mcr_data['Time from Start to Finish (seconds)'].astype(int)\n\n# Basic trash filtering\n# 1) remove answers with 'Time from Start to Finish (seconds)' < 120 seconds and > 3600 seconds\nvalid_time_mask =  (mcr_data['Time from Start to Finish (seconds)'] > 120) & \\\n                    (mcr_data['Time from Start to Finish (seconds)'] < 3600)\n\nmcr_data = mcr_data[valid_time_mask].copy().reindex()\n\nis_student = mcr_data['Q6'] == 'Student'","fdba7ca0":"def get_column_names(data, question):\n    cols = data.columns[data.columns.str.contains(question)]\n    new_cols = []\n    for c in cols:\n        n = data[c].dropna().values\n        if len(n) == 0:\n            n = [c]\n        new_cols.append(question.split(\"_\")[0] + \"_\" + n[0])\n    return new_cols    ","fb6d6284":"is_datascientist = mcr_data['Q26'].isin(['Probably yes', 'Definitely yes'])\ndatascientists = mcr_data[is_datascientist]","3a688161":"nb_datascientists_in_world = [len(datascientists), len(mcr_data)]\nnb_cats_datascientists = [len(datascientists[datascientists['Q26'] == 'Definitely yes']), \n                          len(datascientists[datascientists['Q26'] == 'Probably yes'])]\nnb_student_datascientists_in_students = [len(datascientists[is_student]), len(mcr_data[is_student])]\n\nplt.figure(figsize=(25, 4))\nplt.subplot(131)\nsns.barplot(y=nb_datascientists_in_world, x=[\"Data scientists\", \"World\"])\nplt.subplot(132)\nsns.barplot(y=nb_cats_datascientists, x=[\"Sure Data scientists\", \"Probably Data scientists\"])\nplt.subplot(133)\n_ = sns.barplot(y=nb_student_datascientists_in_students, x=[\"Student data scientists\", \"All Students\"], )","c4fb4aa7":"plt.figure(figsize=(20, 20))\nplt.grid(which='both')\nresidence_count = datascientists['Q3'].value_counts().sort_values(ascending=False)\ng = sns.barplot(y=residence_count.index.values, x=residence_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","c1bc7113":"import random\n\nrandom.seed(1)\n\ndef get_mean_age(x):\n    if \"+\" in x:\n        return int(x[:-1])\n    min_max = [int(v)for v in x.split(\"-\")]\n    return random.uniform(min_max[0], min_max[1] + 1)\n\ndatascientists['mean_age'] = datascientists['Q2'].apply(get_mean_age)\n\ntop5_places_datascientists = datascientists[datascientists['Q3'].isin(residence_count.index[:5].values.tolist() + ['Austria', ])]\n\nplt.figure(figsize=(20, 10))\n# Show each observation with a scatterplot\nsns.boxplot(y=\"Q3\", x=\"mean_age\", data=top5_places_datascientists)\n_ = plt.xlabel(\"Mean Age\")\n_ = plt.ylabel(\"Country\")","13dff3d5":"# And the youngest average (precisely, median) data scientist lives in \nres = datascientists.groupby('Q3')['mean_age'].median()\n\"{} {} {} {}\".format(res.argmin(), \"and has age:\", int(res.min()), \"years\")","15b23fd0":"gender_ff = ffr.loc[~ffr['Q1_OTHER_TEXT'].isnull(), 'Q1_OTHER_TEXT'].values[1:].tolist()\ngender_ff = [g.lower() for g in gender_ff]\ngender_ff = list(set(gender_ff))\n\nwordcloud = WordCloud(max_font_size=40).generate(\" \".join(gender_ff))\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\n_ = plt.axis(\"off\")","78e71389":"plt.figure(figsize=(20, 10))\nplt.grid(which='both')\nq6_count = datascientists['Q6'].value_counts().sort_values(ascending=False)\ng = sns.barplot(y=q6_count.index.values, x=q6_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","933d8852":"cols = [c for c in datascientists.columns if 'Q11_Part' in c]\nlist_of_activities = datascientists[cols].values.ravel().tolist()\nlist_of_activities = pd.Series([a for a in list_of_activities if isinstance(a, str)])\nactivities_counts = list_of_activities.value_counts()\n\n\nplt.figure(figsize=(20, 12))\nplt.title(\"Activities\")\nplt.grid(which='both')\ng = sns.barplot(y=activities_counts.index.values, x=activities_counts)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","7a45adf0":"other_activity_ff = ffr.loc[~ffr['Q11_OTHER_TEXT'].isnull(), 'Q11_OTHER_TEXT'].values[1:].tolist()\nother_activity_ff = [g.lower() for g in other_activity_ff]\nother_activity_ff = list(set(other_activity_ff))\n\nwordcloud = WordCloud(max_font_size=40).generate(\" \".join(other_activity_ff))\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\n_ = plt.axis(\"off\")","537f027d":"cols = [c for c in datascientists.columns if 'Q16_Part' in c]\nlist_of_pl = datascientists[cols].values.ravel().tolist()\nlist_of_pl = pd.Series([ide for ide in list_of_pl if isinstance(ide, str)])\npl_counts = list_of_pl.value_counts()\n\nplt.figure(figsize=(20, 10))\nplt.subplot(131)\nplt.title(\"Regular programming language\")\nplt.grid(which='both')\ng = sns.barplot(y=pl_counts.index.values, x=pl_counts)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")\n\nplt.subplot(132)\nplt.title(\"Specific programming language\")\nplt.grid(which='both')\nq17_count = datascientists['Q17'].value_counts().sort_values(ascending=False)\ng = sns.barplot(y=q17_count.index.values, x=q17_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")\n\nplt.subplot(133)\nplt.title(\"Recommended programming language\")\nplt.grid(which='both')\nq18_count = datascientists['Q18'].value_counts().sort_values(ascending=False)\ng = sns.barplot(y=q18_count.index.values, x=q18_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")\n","0bc39679":"cols = [c for c in datascientists.columns if 'Q13_Part' in c]\nlist_of_ide = datascientists[cols].values.ravel().tolist()\nlist_of_ide = pd.Series([ide for ide in list_of_ide if isinstance(ide, str)])\nide_counts = list_of_ide.value_counts()\n\n\nplt.figure(figsize=(20, 10))\nplt.title(\"Prefered IDE\")\nplt.grid(which='both')\ng = sns.barplot(y=ide_counts.index.values, x=ide_counts)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","4e3e2507":"plt.figure(figsize=(20, 10))\nplt.title(\"ML tool\")\nplt.grid(which='both')\nq20_count = datascientists['Q20'].value_counts().sort_values(ascending=False)\ng = sns.barplot(y=q20_count.index.values, x=q20_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","ed777239":"other_ide_ff = ffr.loc[~ffr['Q13_OTHER_TEXT'].isnull(), 'Q13_OTHER_TEXT'].values[1:].tolist()\nother_ide_ff = [g.lower() for g in other_ide_ff]\nother_ide_ff = list(set(other_ide_ff))\n\nwordcloud = WordCloud(max_font_size=40).generate(\" \".join(other_ide_ff))\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\n_ = plt.axis(\"off\")","7b30d772":"rec_pl_ff = ffr.loc[~ffr['Q18_OTHER_TEXT'].isnull(), 'Q18_OTHER_TEXT'].values[1:].tolist()\nrec_pl_ff = [g.lower() for g in rec_pl_ff]\nrec_pl_ff = list(set(rec_pl_ff))\n\nwordcloud = WordCloud(max_font_size=40).generate(\" \".join(rec_pl_ff))\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\n_ = plt.axis(\"off\")\n\n","4da74b54":"def has_phd(x):\n    return \"Yes\" if \"Doctoral\" in x else \"No\"\n\nplt.figure(figsize=(20, 10))\nplt.title(\"Data scientist has a PhD ?\")\nplt.grid(which='both')\nq4_count = datascientists.loc[~is_student, 'Q4'].apply(has_phd).value_counts().sort_values(ascending=False)\ng = sns.barplot(y=q4_count.index.values, x=q4_count)\n_ = plt.xlabel(\"Number of data scientists\")","3b587622":"plt.figure(figsize=(20, 10))\nplt.title(\"Industry hires Data Scientists\")\nplt.grid(which='both')\nq7_count = datascientists['Q7'].value_counts().sort_values(ascending=False)\nq7_count = q7_count.drop(index=\"I am a student\")\ng = sns.barplot(y=q7_count.index.values, x=q7_count)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","47336748":"cols = [c for c in datascientists.columns if 'Q11_Part' in c]\nindustry_gb = datascientists.groupby(\"Q7\")[cols]\n\nindustries = list(industry_gb.groups.keys())\nindustries.remove('I am a student')\nindustry_activity = pd.DataFrame(index=industries, columns=get_column_names(mcr_data, \"Q11_Part\"), dtype=np.float32)\nfor g in industries:\n    industry_activity.loc[g, :] = industry_gb.get_group(g).count().values \/ q7_count[g]\n    \nplt.figure(figsize=(10, 10))\nplt.title(\"Data scientist activity (%) in industry\")\n_ = sns.heatmap(industry_activity, linewidths=.7, square=True, cmap='coolwarm')","fdaf78d7":"cols = [c for c in datascientists.columns if 'Q19_Part' in c]\nindustry_gb = datascientists.groupby(\"Q7\")[cols]\n\nindustries = list(industry_gb.groups.keys())\nindustries.remove('I am a student')\nindustry_activity = pd.DataFrame(index=industries, columns=get_column_names(mcr_data, \"Q19_Part\"), dtype=np.float32)\nfor g in industries:\n    industry_activity.loc[g, :] = industry_gb.get_group(g).count().values \/ q7_count[g]\n\n    \nplt.figure(figsize=(10, 10))\nplt.title(\"ML Frameworks used in industry by data scientists\")\ng = sns.heatmap(industry_activity.T, linewidths=.7, square=True, cmap='coolwarm')","460ba561":"cols = [c for c in datascientists.columns if 'Q38_Part' in c]\nlist_of_media = datascientists[cols].values.ravel().tolist()\nlist_of_media = pd.Series([m for m in list_of_media if isinstance(m, str)])\nmedia_counts = list_of_media.value_counts()\n\n\nplt.figure(figsize=(20, 10))\nplt.title(\"Prefered media sources\")\nplt.grid(which='both')\ng = sns.barplot(y=media_counts.index.values, x=media_counts)\ng.set_xscale('log')\n_ = plt.xlabel(\"Number of data scientists in log10\")","c60a23b3":"kept_columns = []\nfor c in mcr_data.columns:\n    if \"Q\" not in c:\n        continue\n    if mcr_data[c].isin([-1, \"-1\"]).any():\n        continue\n    kept_columns.append(c)\n\ndata = mcr_data[kept_columns]","6f584e4b":"# data.head()\n\nprint(schema.loc[:0, 'Q38'].values)\n# print(schema.loc[:0, 'Q50'].values)\n# print(datascientists['Q38_Part_1'])\nschema.loc[:0, :]","9331a429":"# gender_df = pd.get_dummies(data['Q1'], prefix=\"gender\")\n# age = pd.Series(data['Q2'].apply(get_mean_age), name='mean_age')\n# country_df = pd.get_dummies(data['Q3'], prefix=\"country\")\n\nedu_df = pd.get_dummies(data['Q4'], prefix=\"edu\")\nedu_field_df = pd.get_dummies(data['Q5'], prefix=\"edu_field\")\nwork_field_df = pd.get_dummies(data['Q7'], prefix=\"work_field\")\n\nactivity_df = (~data[data.columns[data.columns.str.contains(\"Q11_Part\")]].isnull()).astype(int)\nactivity_df.columns = get_column_names(data, \"Q11_Part\")\n\nprimary_tool_df = pd.get_dummies(data['Q12_MULTIPLE_CHOICE'], prefix=\"prim_tool\")\nide_df = (~data[data.columns[data.columns.str.contains(\"Q13_Part\")]].isnull()).astype(int)\nide_df.columns = get_column_names(data, \"Q13_Part\")\n\nprog_lang_df = (~data[data.columns[data.columns.str.contains(\"Q16_Part\")]].isnull()).astype(int)\nprog_lang_df.columns = get_column_names(data, \"Q16_Part\")\n\nml_tool_df = pd.get_dummies(data['Q20'], prefix=\"ml_tool\")\n\nml_blackbox_df = pd.get_dummies(data['Q48'], prefix=\"Q48\")\n\nml_metrics_df = (~data[data.columns[data.columns.str.contains(\"Q42_Part\")]].isnull()).astype(int)\nml_metrics_df.columns = get_column_names(data, \"Q42_Part\")\n\nmedia_df = (~data[data.columns[data.columns.str.contains(\"Q38_Part\")]].isnull()).astype(int)\nmedia_df.columns = get_column_names(data, \"Q38_Part\")","74fe5294":"train_test_df = pd.concat([\n#     gender_df, age, \n#     country_df,\n    edu_df, edu_field_df, \n    work_field_df,\n    activity_df,\n    primary_tool_df, ide_df,\n    prog_lang_df, ml_tool_df,\n    ml_blackbox_df, \n    ml_metrics_df,\n    media_df\n], axis=1)\nprint(train_test_df.shape)\ntrain_test_df.head()","4da8d66c":"y = is_datascientist.values.astype(int)\n\"Nb of Data scientists: \", np.sum(y), \"All: \", len(y)","b16fd9ca":"from sklearn.model_selection import StratifiedShuffleSplit \n\nseed = 10\nssplit = StratifiedShuffleSplit(train_size=0.7, random_state=seed)\ntrain_indices, test_indices = next(ssplit.split(train_test_df.values, y))\n\nX_train = train_test_df.values[train_indices]\ny_train = y[train_indices]\nX_test = train_test_df.values[test_indices]\ny_test = y[test_indices]","3439db9e":"from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n\nlog_reg_cv = LogisticRegressionCV(scoring='roc_auc', random_state=seed, \n                                  solver='liblinear', penalty='l2', \n                                  cv=5, n_jobs=10)\nlog_reg_cv.fit(X_train, y_train)\n\nprint(np.mean(log_reg_cv.scores_[1], axis=0), log_reg_cv.C_)\n\nlog_reg = LogisticRegression(C=log_reg_cv.C_[0], random_state=seed, solver='liblinear', penalty='l2')\nlog_reg.fit(X_train, y_train)\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\ny_test_preds = log_reg.predict(X_test)\n\"AUC:\", roc_auc_score(y_test, y_test_preds), \"Accuracy:\", accuracy_score(y_test, y_test_preds)","f35c4b06":"important_coeffs = np.argsort(np.abs(log_reg.coef_), axis=1)[0, ::-1]\ntrain_test_df.columns.values[important_coeffs[:10]].tolist()","0656434f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n\nrf = RandomForestClassifier(random_state=seed)\n\nmax_depth_values = range(5, 10)\nn_estimators_values = range(10, 20, 2)\ntree_params = {'max_depth': max_depth_values,\n               'n_estimators': n_estimators_values}\n\ngs = GridSearchCV(rf, tree_params, scoring='roc_auc', cv=5, n_jobs=10)\ngs.fit(X_train, y_train)\n\ngs.best_params_, gs.best_score_, gs.cv_results_['std_test_score'][gs.best_index_]","d28ce7ec":"rf = RandomForestClassifier(random_state=seed, **gs.best_params_)\nrf.fit(X_train, y_train)\n\ny_test_preds = rf.predict(X_test)\n\"AUC:\", roc_auc_score(y_test, y_test_preds), \"Accuracy:\", accuracy_score(y_test, y_test_preds)","e62ac153":"rf.feature_importances_\nimportant_coeffs = np.argsort(np.abs(rf.feature_importances_))[::-1]\ntrain_test_df.columns.values[important_coeffs[:10]].tolist()","35855c1a":"# This data is just a random stuff :)\ndf = pd.DataFrame(index=[0], columns=train_test_df.columns)\ndf.loc[:, :] = 0\ndf['edu_Doctoral degree'] = 1\ndf['edu_field_Physics or astronomy'] = 1\ndf['work_field_Computers\/Technology'] = 1\ndf['Q11_Build and\/or run a machine learning service that operationally improves my product or workflows'] = 1\ndf['Q11_Build prototypes to explore applying machine learning to new areas'] = 1\ndf['Q11_Do research that advances the state of the art of machine learning'] = 1\ndf['prim_tool_Cloud-based data software & APIs (AWS, GCP, Azure, etc.)'] = 1\ndf['prim_tool_Local or hosted development environments (RStudio, JupyterLab, etc.)'] = 1\ndf['Q13_Jupyter\/IPython'] = 1\ndf['Q13_PyCharm'] = 1\ndf['Q16_Python'] = 1\ndf[['ml_tool_PyTorch', 'ml_tool_Xgboost', 'ml_tool_randomForest', 'ml_tool_Scikit-Learn']] = 1\ndf['Q48_I am confident that I can understand and explain the outputs of many but not all ML models'] = 1\ndf['Q42_Metrics that consider accuracy'] = 1 \nx_me = df.values","7262ffd6":"res1 = log_reg.predict_proba(x_me)\nres2 = rf.predict_proba(x_me)\n\"Probability that I'm a part of this band is : \", 0.5 * (res1[0, 1] + res2[0, 1])","7a9dcec5":"print(schema.loc[:0, 'Q7'].values)\nprint(ffr_data.columns)\nschema.loc[:0, :]","761ac892":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ndef compute_scores(question):\n    q = pd.DataFrame(ffr_data[question].dropna().str.lower())\n    vectorizer = TfidfVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(q[question])\n    q.loc[:, 'tfidf_score'] =  np.array(X.sum(axis=1)).ravel()\n    q = q[q['tfidf_score'] > 1.0]\n    q = q.sort_values('tfidf_score', ascending=False)\n    return q\n\nq11 = compute_scores('Q11_OTHER_TEXT')","fbca3122":"for p, s in q11.head(10).values:\n    print(\"{:.2f} - {} \\n\".format(s, p))","3000bed8":"q11.tail(10)","4a816b79":"mask = (q11['tfidf_score'] > 2.0) & (q11['tfidf_score'] < 3.0)\nfor p, s in q11[mask].head(5).values:\n    print(\"{:.2f} - {} \\n\".format(s, p))","3b412678":"q11[q11['Q11_OTHER_TEXT'].str.contains(\"fu\")]","aefa6b90":"q12 = compute_scores('Q12_OTHER_TEXT')","d9c1bcc7":"for p, s in q12.head(10).values:\n    print(\"{:.2f} - {} \\n\".format(s, p))","13eb112f":"q12.tail(10)","e0170246":"mask = (q12['tfidf_score'] > 2.0) & (q12['tfidf_score'] < 3.0)\nfor p, s in q12[mask].head(5).values:\n    print(\"{:.2f} - {} \\n\".format(s, p))","cae81c28":"q12[q12['Q12_OTHER_TEXT'].str.contains(\"kaggle\")]","3ab7d15a":"Here are bottom-10 answers:","76d71883":"Other activites:","23637dee":"Top-10 the most important features:","e6977872":"Here are top-10 answers:","4656e243":"Some of them has funny genders:","fe15307a":"Here are bottom-10 answers:","dea14650":"Let's train a random forest","f85405e8":"## What industry hires Data Scientists ?\n\n\nObviously, the leader is Computers\/Technology","68ec1fd1":"Some other interesting answers:","b3ccbc75":"### Q12 \"_What is the primary tool that you use at work or school to analyze data?_\"","b0d959d3":"## Which programming language, IDE and ML tool they mostly use:\n\nThe leaders are Python, Jupyter, Scikit-Learn. \n\n- There are 9 persons who recommend an aspiring data scientist to learn first Go","b15f63ad":"### Q11 \"Select any activities that make up an important part of your role at work\"","86e687b1":"Some other interesting answers:","82039ab9":"Let's use TF-IDF vectorizer to assign a score to a phrase and checkout top score and bottom score phrases (ignoring zero scores):","f9f93e51":"## Do they have all a PhD ?","030e3b1a":"Their work almost consists of","04671551":"Take a closer look to industries that do _deep learning_ with Tensorflow, Keras or PyTorch.","47b5622f":"## What are they doing ?\n\nMost of them employed as Data Scientists and Bottom 5 roles:\n- Data journalist\n- Salesperson\n- Developer Advocate\n- Marketing Analyst\n- DBA\/DB Engineer","dce1a0bb":"# Free form responses analysis\n\nLet's explore free answers on questions like:\n- Q11 \"_Select any activities that make up an important part of your role at work_\"\n- Q12 \"_What is the primary tool that you use at work or school to analyze data?_\"\n\n\nIdea is to process the answers to find some extraordinary ones","73dcf12f":"Here are top-10 answers:","d10591a7":"In India, Russia, Chine, there is a lot of young data scientists (as they consider themselves). ","337dc4ec":"Recommended programming languages in free answers:","1d80bc3b":"# Predict a data scientist\nLet's train some simple models to predict who is a data scientist:\n\n- We select fields without `OTHER_TEXT` or similar fields filled by numbers: -1, 1, 2, ...\n- Transform text fields in OHE format\n- Select ~~gender, age, country~~, education, work field, activity, primary tool, ide, programming language, etc","59c9ea44":"Let's consider as data scientist the person who answered the question 26: \"_Do you consider yourself to be a data scientist?_\" by \"Probably yes\" and \"Definitely yes\".","479ffe30":"## Let me test on my data to know who am I :\n","d29b684a":"## Where are living the data scientists ?\n\nTop 5 places:\n- US (~2000)\n- India\n- China\n- Russia\n- _Other_\n\n\n_Did you know:_ In Austria there are only 18 data scientists.","e8366173":"Let's train a linear model","08c3af12":"# What type media they prefer to read ?","ea850f69":"Let's use TF-IDF vectorizer to assign a score to a phrase and checkout top score and bottom score phrases (ignoring zero scores):","7b5fa946":"How much time they spend on various task depending on industry ? For example, in Academia they should mostly do research.","a9430806":"## and how old are they ?\n\nLet's take a look at the age distribution of data scientists from top-5 places + Austria. ","a1a62507":"Top-10 the most important features:","d9d402a7":"and other mentioned IDEs","7636b289":"We have ~70% of accuracy on linear regression or RF. These models are not very descriminative due to selected features.","fc863b77":"And which ML tools they use depending on industry field:","8aed0564":"# Who are they - Data Scientists ?\n\nThe purpose of this kernel is to better understand who are they the \"DataScientists\" or people who think to be a part of that society.\n\n![img](http:\/\/www.themeasurementstandard.com\/wp-content\/uploads\/2015\/06\/data-scientist-as-superman.jpg)\n\nWe will know where are they coming from, what age are they, what are they doing, their favorite tools, IDEs and much more.\n\n- Predict a data scientist : For fun we can try to train a simple model and predict whether a person is a data scientist or not.\n\n- Free form responses analysis : Work in progress\n"}}