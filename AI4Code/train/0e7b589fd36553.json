{"cell_type":{"2ea8d97b":"code","8e5ff4f4":"code","00061af7":"code","c5cb6c09":"code","0eb5c960":"code","3fb3a972":"code","a014cc89":"code","7a6f60dc":"code","d151107c":"code","2d82b638":"code","163f7708":"code","8804a6df":"code","54add61a":"code","6654d2d3":"code","77b1b2cf":"code","ba65c33f":"code","9c20d3b5":"code","af10bacc":"code","b7d4870f":"code","51775896":"code","e5ea5522":"code","936b2ae4":"code","e251c75a":"code","f2265526":"code","15f0181b":"code","be0f38dd":"code","b259c54c":"code","b6b0f7ed":"code","4b24e1bf":"code","fb02e84f":"code","bbecd435":"code","6eda05b8":"code","170045a0":"code","55b8db54":"code","14f06cd7":"code","6b0112f5":"code","3a00b779":"code","c4afece1":"code","517fb8a3":"code","c6480d0c":"markdown","1ad428c9":"markdown","7f771434":"markdown","a0265b84":"markdown","c9c56a6b":"markdown","ed174f05":"markdown","ea14fe62":"markdown","d35dbb7d":"markdown","6b936165":"markdown","2afb4d7b":"markdown","d886299e":"markdown","9c3a9dd5":"markdown","c5fb9b9c":"markdown","fff4d7ca":"markdown","88ef64bc":"markdown","cf453b39":"markdown","af3a136a":"markdown","1e728a89":"markdown","beb92496":"markdown","c5e6ed91":"markdown","15966838":"markdown","5cb95b55":"markdown","5cfe6ee9":"markdown","97924206":"markdown","b3484857":"markdown","40bdad90":"markdown","73950513":"markdown","c7278475":"markdown","358b1b3e":"markdown"},"source":{"2ea8d97b":"#!pip install bayesian-optimization\n#!pip install shap","8e5ff4f4":"import pandas as pd\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_absolute_error, explained_variance_score, median_absolute_error, r2_score, make_scorer\n\n\nfrom scipy import stats\nfrom bayes_opt import BayesianOptimization\nimport shap\n\nfrom typing import Union\nimport warnings\n\nwarnings.filterwarnings('ignore')\nsns.set_style('darkgrid')\n\n%matplotlib inline","00061af7":"def plot_decomposition(est, data: pd.DataFrame, color, dim=2, method='px', hover_data=None, marker=None,\n                       exclude_dtypes=None, drop_color=False,\n                       drop_columns=None, title='', return_estimator=False, show=True, importance=False):\n    _df = data.copy()\n    if drop_columns:\n        _df = _df.drop(columns=drop_columns)\n    if exclude_dtypes:\n        _df = _df.select_dtypes(exclude=exclude_dtypes)\n    _df.loc[:, _df.dtypes == object] = _df.loc[:, _df.dtypes == object].apply(lambda _z: _z.astype('category').cat.codes)\n    color = data[color].copy()\n    _df = _df.drop(columns = [color.name]) if color.name in _df.columns and drop_color else _df\n    \n    if importance:\n        est = est.fit(StandardScaler().fit_transform(_df))\n    _x = est.fit_transform(StandardScaler().fit_transform(_df))\n    \n    if importance:\n        dim_cols = [f'PC{i} : Most Important - {_df.columns[np.abs(est.components_[i-1]).argmax()]}' for i in range(1, dim+1)]\n    else:\n        dim_cols = [f'dim_{i}' for i in range(1, dim+1)]\n    _x = pd.DataFrame(_x[:, :dim], columns=dim_cols)\n    \n    if hover_data:\n        if type(hover_data) == str:\n            hover_data = [hover_data]\n        _x[hover_data] = data[hover_data]\n    else:\n        hover_data = _df.columns\n        _x[hover_data] = data[hover_data]\n\n    _x[color.name] = color\n    \n    if dim == 2:      \n        if method == 'px':\n            fig = px.scatter(_x, x=dim_cols[0], y=dim_cols[1], color=color.name, hover_data=hover_data, symbol=marker)\n        elif method == 'plt':\n            sns.scatterplot(data=_x, x=dim_cols[0], y=dim_cols[1] ,hue=color.name, style=marker, ax=plt.gca())\n\n    elif dim == 3:\n        if method == 'px':\n            fig = px.scatter_3d(_x, x=dim_cols[0], y=dim_cols[1], z=dim_cols[2], color=color.name, \n                                hover_data=hover_data, symbol=marker)\n        elif method == 'plt':\n            ax = plt.axes(projection='3d')\n            cax = ax.scatter(_x[dim_cols[0]], _x[dim_cols[1]], _x[dim_cols[2]], c=color, marker='o')\n            plt.xlabel(dim_cols[0])\n            plt.ylabel(dim_cols[1])\n            ax.set_zlabel(dim_cols[2])\n    if method == 'px':\n        fig.update_layout(\n            title={\n                'text': title,\n                'x': 0.5,\n                'y': 0.95,\n                'xanchor': 'center',\n                'yanchor': 'top'}, coloraxis_colorbar=dict(yanchor=\"top\", x=-0.25,y=1))\n        \n        if show:\n            fig.show()\n    else:\n        plt.title(title)\n        if show:\n            plt.show()\n    if return_estimator:\n        return est\n    \n\ndef plot_clusters(est, data, dim=2, hover_data=None, marker=None, color='clusters', method='px', title='', show=True, \n                  feature_names=None, cols=[0, 1, 2]):\n    _df = data[:, cols[:dim]]\n    dim_cols = feature_names if feature_names is not None else [f'dim_{i}' for i in range(1, dim+1)]\n    _df = pd.DataFrame(data=_df, columns=dim_cols)\n    _df['clusters'] = est.predict(data)\n    _df['clusters'] = _df['clusters'].apply(lambda _t: f'cluster {_t}')\n    if type(hover_data) == pd.DataFrame:\n        _df[hover_data.columns] = hover_data\n        hover_data = hover_data.columns\n                \n    if dim == 2:      \n        if method == 'px':\n            fig = px.scatter(_df, x=dim_cols[0], y=dim_cols[1], color=color, hover_data=hover_data, symbol=marker)\n        elif method == 'plt':\n            sns.scatterplot(data=_df, x=dim_cols[0], y=dim_cols[1] ,hue=color, style=marker)\n    \n    elif dim == 3:\n        if method == 'px':\n            fig = px.scatter_3d(_df, x=dim_cols[0], y=dim_cols[1], z=dim_cols[2], color=color, \n                                hover_data=hover_data, symbol=marker)\n        elif method == 'plt':\n            ax = plt.axes(projection='3d')\n            cax = ax.scatter(_df[dim_cols[0]], _df[dim_cols[1]], _df[dim_cols[2]], c=_df[color], marker='o')\n            plt.xlabel(dim_cols[0])\n            plt.ylabel(dim_cols[1])\n            ax.set_zlabel(dim_cols[2])\n    if method == 'px':\n        fig.update_layout(\n            title={\n                'text': title,\n                'x': 0.5,\n                'y': 0.95,\n                'xanchor': 'center',\n                'yanchor': 'top'}, coloraxis_colorbar=dict(yanchor=\"top\", x=-0.25,y=1))\n        \n        if show:\n            fig.show()\n    else:\n        plt.title(title)\n        if show:\n            plt.show()\n\ndef biplot(est, data, method='plt', show=True):\n    _df = data.copy()\n    _df.loc[:, _df.dtypes == object] = _df.loc[:, _df.dtypes == object].apply(lambda _z: _z.astype('category').cat.codes)\n    feature_names = _df.columns\n    est = est.fit(StandardScaler().fit_transform(_df))\n    loadings = est.components_.T * np.sqrt(est.explained_variance_)\n    \n    for i, (_x, _y) in enumerate(loadings):\n        if method == 'plt':\n            plt.annotate(feature_names[i], (0, 0), (_x , _y), arrowprops = {'arrowstyle': '<-', 'color': 'black'})\n    \n    if method == 'plt':\n        plt.xlabel('$PC_{1}$')\n        plt.ylabel('$PC_{2}$')\n        plt.title('Feature Influence on Each $PC$ (loading)')\n        plt.xlim(-1, 1)\n        plt.ylim(-1, 1)\n        if show:\n            plt.show()\n    \ndef plot_xVarRatio(data, method='plt', show=True):\n    _df = data.copy()\n    _df.loc[:, _df.dtypes == object] = _df.loc[:, _df.dtypes == object].apply(lambda _z: _z.astype('category').cat.codes)\n    feature_names = _df.columns\n    est = PCA(n_components=len(feature_names), svd_solver='full').fit(StandardScaler().fit_transform(_df))\n    # feature_names = [feature_names[k] for k in np.abs(est.components_).argmax(axis=1)]    \n    if method == 'plt':\n        plt.xlabel('number of $PC$s')\n        plt.ylabel('explained variance ratio')\n        plt.title(r'Explained Variance Ratio $\\times$ number of $PC$s')\n        _x = np.arange(0, est.n_components_)\n        plt.plot(_x, est.explained_variance_ratio_, '-o', label='non-cummulative', c='b')\n        plt.plot(_x, est.explained_variance_ratio_.cumsum(), '-o', label='cummulative', c='r')\n        plt.legend(fancybox=True, shadow=True, facecolor='coral', edgecolor='gold')\n        if show:\n            plt.show()\n        \n\ndef plot_reg(y_true, y_pred):\n    _x = np.arange(0, len(y_pred))\n    inds = np.argsort(y_true)\n    plt.plot(_x, np.sort(y_true), '-o',label='$f(x)$')\n    plt.plot(_x, y_pred[inds], '-o', label='$\\hat{f(x)}$')\n    plt.legend()\n    plt.xticks([])\n    plt.show()\n    \n    \ndef plot_important_features(coef, feature_names, top_n=20, ax=None, labels: dict = None, flip=False):\n    if ax is None:\n        ax = plt.gca()\n    top_n = min(top_n, len(coef))\n    inds = np.argsort(np.abs(coef))[-top_n:]\n    important_coefs = coef[inds]\n    sort_sign = np.argsort(important_coefs)\n    _x0 = np.arange(0, top_n, dtype=int)\n    combined_inds = inds[sort_sign]\n    new_c = coef[combined_inds]\n    if labels is None:\n        ax.bar(_x0, new_c)\n    else:\n        colors = ['k', 'g', 'r', 'b', 'y']\n        for i, (k, v) in enumerate(labels.items()):\n            _v = lambda x: eval(v.format('x'))\n            ax.bar(_x0[_v(new_c)], new_c[_v(new_c)], color=colors[i], label=k)\n        ax.legend(shadow=True, fancybox=True)\n    ax.set_xticks(_x0)\n    if flip:\n        ax.set_xticklabels([k[::-1] for k in np.array(feature_names)[combined_inds]], rotation=60, ha=\"right\")\n    else:\n        ax.set_xticklabels([k for k in np.array(feature_names)[combined_inds]], rotation=60, ha=\"right\")\n    ","c5cb6c09":"def split_xy(data: pd.DataFrame, by: str, x: str = None):\n    new_df = []\n    for _val in data[by].unique():\n        if x is not None:\n            new_df.append(data.loc[data[by] == _val, x].copy().reset_index(drop=True))\n        else:\n            new_df.append(data.loc[data[by] == _val].copy().reset_index(drop=True))\n    return new_df","0eb5c960":"def cohens_d_test(data, target, by, title=None):\n    if title is None:\n        title = 'results' \n    _x1, _x2 = split_xy(data, by, target)\n    n1 = len(_x1)\n    n2 = len(_x2)\n    _x1 = _x1.to_numpy()\n    _x2 = _x2.to_numpy()\n    \n    def s2(_x):\n        denum = len(_x) - 1\n        num = np.sum((_x - _x.mean())**2)\n        return num \/ denum\n    \n    s = np.sqrt(((n1 - 1)*s2(_x1) + (n2-1)*s2(_x2)) \/ (n1 + n2))\n    \n    d = abs(_x1.mean() - _x2.mean()) \/ s\n    effects = ['Very Small', 'Small', 'Medium', 'Large', 'Very Large', 'Huge']\n    sizes = np.array([0.01, 0.2, 0.5, 0.8, 1.0, 2.0])\n    res = [len(_x1), len(_x2), _x1.mean(), _x2.mean(), s, d, effects[np.argmin(np.abs(sizes - d))]]\n    for i in range(4):\n        res[i] = round(res[i], 2)\n    \n    return pd.DataFrame(data=np.expand_dims(res, 1), index=[r'size( $x_1$ )',r'size( $x_2$ )','$E[x_1]$', '$E[x_2]$', '$s$', '$d$', 'Effect Size'], columns=[title])\n\n\ndef elbow_method(_K, _inertias):\n    scores = np.zeros_like(_inertias).astype('float16')\n    def get_score(t_k, t_diff):\n        lr = LR().fit(t_k[:, None], t_diff)\n        return RMSE(t_diff, lr.predict(t_k[:, None])) #explained_variance_score(t_diff, lr.predict(t_k[:, None])) \n    for _i in range(len(_K) - 2):\n        scores[_i] = get_score(_K[_i:], _inertias[_i:])\n    #args = scores.argsort()[::-1][:int(len(inertias)**0.5)]\n    args = scores.argsort()[:int(len(inertias)**0.5)]\n    return args.min() - 1, scores\n\ndef RMSE(y_true, y_pred):\n    return np.sqrt(np.mean((y_pred - y_true)**2))\n\ndef regression_summary(y_true, y_pred, title=None):\n    if title is None:\n        title = 'Regression Summary'\n    mets = [RMSE(y_true, y_pred), \n            mean_absolute_error(y_true, y_pred),\n            r2_score(y_true, y_pred), \n            median_absolute_error(y_true, y_pred), \n            explained_variance_score(y_true, y_pred)]\n    \n    names = ['RMSE', 'MAE', '$R^2$', 'MedAE', 'Explained Variance']\n    \n    for i in range(len(mets)):\n        mets[i] = round(mets[i], 3)\n        \n    return pd.DataFrame(data=np.expand_dims(mets, 1), index=names, columns=[title])\n\ndef optimize(estimator, data, target, settings: dict, extra_steps: Union[list, tuple] = None,\n             cv_params: dict = dict(scoring='f1_macro', cv=5), verbose=2,\n             opt_params: dict = dict(n_iter=20),\n             max_min='max'):\n\n    \"\"\"\n    :param estimator: a sklearn\/xgboost trainable object\n    :param data: the training data\n    :param target: the training target\n    :param settings: the model hyperparameters to be tuned with the optimization\n    :param extra_steps: extra pipeline steps, prior to the model being optimized (data transformations)\n    :param cv_params: parameters\/settings for the cross-validation (number of cv, scoring etc.)\n    :param verbose: verbosity level of the bayesian optimization\n    :param opt_params: parameters\/settings for the optimization\n    :param max_min: whether the optimization should maximize or minimize the target metric\n    :return: a sklearn\/xgboost trainable object, set with the optimal parameters found by the optimization\n    \"\"\"\n\n    if extra_steps is not None:\n        if type(extra_steps) == tuple:\n            extra_steps = [extra_steps]\n\n    else:\n        extra_steps = []\n\n    def parse_parameter(_p, val):\n        if 'dtype' not in settings[_p].keys():\n            return val\n        dtype = settings[_p]['dtype']\n        if dtype in [float, int]:\n            val = dtype(val)\n            if 'f' in settings[_p].keys():\n                return settings[_p]['f'](val)\n            return val\n        else:\n            n = len(settings[_p]['space'])\n            val = int(val)\n            if val > n - 1:\n                return settings[_p]['space'][-1]\n            elif val < 0:\n                return settings[_p]['space'][0]\n            else:\n                return settings[_p]['space'][val]\n\n    def get_model(**params):\n        for _p, val in params.items():\n            params[_p] = parse_parameter(_p, val)\n\n        model = estimator(**params)\n        steps = extra_steps.copy()\n        steps.append(('final_model', model))\n        return Pipeline(steps=steps)\n\n    def cv_model(**params):\n        if max_min is 'max':\n            cval = cross_val_score(get_model(**params), data, target, **cv_params, error_score=0).mean()\n            if cval > 1e+6:\n                cval = 0\n        else:\n            cval = cross_val_score(get_model(**params), data, target, **cv_params, error_score=-1e+6).mean()\n            cval = np.max([cval, -1e+6])\n        return cval\n\n    pbounds = {}\n    for k in settings.keys():\n        if type(settings[k]['space']) == tuple:\n            pbounds[k] = settings[k]['space']\n        else:\n            pbounds[k] = (0, len(settings[k]['space']))\n\n    optimizer = BayesianOptimization(\n        f=cv_model,\n        pbounds=pbounds,\n        verbose=verbose\n    )\n    optimizer.maximize(**opt_params)\n    print(\"Final result:\", optimizer.max)\n    return get_model(**optimizer.max['params'])\n","3fb3a972":"df = pd.read_csv('..\/input\/predict-test-scores-of-students\/test_scores.csv')\ndf['lunch'] = df['lunch'].apply(lambda _z: _z if _z == 'Does not qualify' else 'Qualifies')\ndf.head()","a014cc89":"df.describe(include='object')","7a6f60dc":"df = df.drop(columns=['student_id'])","d151107c":"plt.figure(figsize=(15, 6))\nplt.suptitle('Data Distributions')\nfor i, c in enumerate(['gender', 'teaching_method', 'lunch', 'school_setting', 'school_type']):\n    plt.subplot(2, 3, i+1)\n    sns.countplot(df[c])\nplt.tight_layout()\nplt.show()","2d82b638":"plt.figure(figsize=(22, 10))\nplt.suptitle('Splited Data Distributions')\nindex = 1\nfor i, hue in enumerate(['gender', 'teaching_method', 'lunch', 'school_setting', 'school_type']):\n    for j, col in enumerate(['gender', 'teaching_method', 'lunch', 'school_setting', 'school_type']):\n        if j <= i:\n            continue\n        plt.subplot(2, 5, index)\n        index += 1\n        sns.countplot(data=df, x=col, hue=hue)\nplt.show()","163f7708":"df.describe()","8804a6df":"plt.figure(figsize=(15, 6))\nplt.suptitle('Data Distributions')\nfor i, c in enumerate(['n_student', 'pretest', 'posttest']):\n    plt.subplot(2, 3, i+1)\n    sns.histplot(data=df, x=c, kde=True, stat='density', ax=plt.gca())\nplt.tight_layout()\nplt.show()","54add61a":"plt.figure(figsize=(20, 10))\nplt.suptitle('Splited Data Distributions')\nindex = 1\nfor i, hue in enumerate(['gender', 'teaching_method', 'lunch', 'school_setting', 'school_type']):\n    for j, col in enumerate(['n_student', 'pretest', 'posttest']):\n        plt.subplot(5, 3, index)\n        index += 1\n        sns.histplot(data=df, x=col, hue=hue, kde=True, stat='density', ax=plt.gca())\nplt.tight_layout()\nplt.show()","6654d2d3":"sns.heatmap(df[['n_student', 'pretest', 'posttest']].corr(), annot=True)\nplt.title('Pearson Correlation Matrix')\nplt.show()","77b1b2cf":"df = df.drop(columns=['pretest'])","ba65c33f":"plt.figure(figsize=(21, 10))\nplt.subplot(1, 2, 1)\nplt.title('posttest scores x n_student aggregated by average over classes')\n\nt_df = df[['posttest', 'classroom']].groupby('classroom').aggregate(['count', 'mean', 'std'])['posttest']\nt_df = t_df.rename(columns={'count': 'n_student', 'mean': 'posttest_class_average', 'std': 'posttest_class_std'})\n\nsns.set_theme(rc={'figure.figsize':(15,5)})\nsns.barplot(data=t_df,x='n_student',y='posttest_class_average')\n\nplt.subplot(1, 2, 2)\nplt.title('Pearson Correlation Matrix (n_student x posttest_class_average x posttest_class_std)')\nsns.heatmap(t_df.corr(), annot=True)\n\nplt.show()\n\ndel(t_df)\nt_df = None","9c20d3b5":"t_df = df.copy()\nt_df['above 23 students in class'] = t_df['n_student'] > 23\nsns.histplot(data=t_df, x='posttest', hue='above 23 students in class', kde=True, stat='density', ax=plt.gca())\n\ndel(t_df)\nt_df = None\nplt.show()","af10bacc":"plt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nplt.title('posttest scores variance within classes')\nt_df = df.groupby('classroom').var()\nsns.histplot(data=t_df, x='posttest', kde=True, stat='density', ax=plt.gca())\nplt.xlabel('posttest var')\nplt.subplot(1, 2, 2)\nplt.title('posttest scores variance within schools')\nt_df = df.groupby('school').var()\nsns.histplot(data=t_df, x='posttest', kde=True, ax=plt.gca())\nplt.xlabel('posttest var')\n\nplt.show()\n\nt_df = None\ndel(t_df)","b7d4870f":"plt.title(\"Class Maximum Difference in posttest Score\")\nsns.histplot(x=df.groupby('classroom').apply(lambda _x: _x['posttest'].max() - _x['posttest'].min() ), kde=True, stat='count', ax=plt.gca())\nplt.xlabel('$\\max{(d_k)}$: $d_k$ is the distnce matrix of class $k$ scores')\nplt.show()","51775896":"#plt.figure(figsize=(20, 10))\nest = plot_decomposition(est=PCA(n_components=8, svd_solver='full'), data=df, color='posttest', marker='school_type',\n                         return_estimator=True, title='PCA Transformation on Data', dim=2,\n                         drop_columns=['classroom'], drop_color=False, exclude_dtypes=None, method='px', importance=True)","e5ea5522":"plt.figure(figsize=(20, 7))\nplt.subplot(1, 2, 1)\nbiplot(PCA(n_components=2, svd_solver='full'), df.drop(columns=['classroom']), show=False)\nplt.subplot(1, 2, 2)\nplot_xVarRatio(df.drop(columns=['classroom']), show=False)\n\nplt.show()","936b2ae4":"df['n_students>23'] = df['n_student'] > 23\n\npd.concat([cohens_d_test(df, 'posttest', 'gender', 'Gender'), \n           cohens_d_test(df, 'posttest', 'lunch', 'Free Lunch Qualification'), \n           cohens_d_test(df, 'posttest', 'school_type', 'School Type'),\n           cohens_d_test(df, 'posttest', 'n_students>23', 'n_students>23?')], axis=1)","e251c75a":"t = stats.ttest_ind(df.query(\"gender == 'Male'\")['posttest'], df.query(\"gender == 'Female'\")['posttest'])\ndelta = lambda t, alpha: alpha < t.pvalue","f2265526":"plt.figure(figsize=(10, 6))\nalpha = np.linspace(1e-5, 1, 1000)\nplt.plot(alpha, delta(t, alpha)*1, label=r'$\\delta$')\nplt.fill_between(alpha, delta(t, alpha), np.zeros(1000), where=delta(t, alpha)>0, alpha=0.2)\nplt.legend()\nplt.xlabel(r'$\\alpha$')\nplt.ylabel(r'$\\delta$')\nplt.title('t-statistic: {:.3f} ; p-value: {:.3f}'.format(t.statistic, t.pvalue))\nplt.show()","15f0181b":"df = df.drop(columns=['n_students>23'])\nt = stats.ttest_ind(df.query(\"n_student <= 23\")['posttest'], df.query(\"n_student > 23\")['posttest'], alternative='greater')\npd.DataFrame(np.array([[t.statistic, t.pvalue]]).T, index=['t-statistic', 'p-value'], columns=['t-test results'])","be0f38dd":"cat_transformer = make_column_transformer((OrdinalEncoder(), df.select_dtypes(include=['object']).columns.drop('classroom').to_list()), \n                                          remainder='passthrough')\npca_pipe = Pipeline([('trans', cat_transformer), ('PCA', est), ('scale', StandardScaler())])\npca = pca_pipe.fit_transform(df.drop(columns=['classroom']))#[:, :2]","b259c54c":"K = np.arange(2, 30, dtype=int)\ninertias = np.zeros_like(K, dtype='float16')\nfor i, _k in enumerate(K):\n    kmeans = KMeans(n_clusters=_k, max_iter=int(1e+5), algorithm='full').fit(pca)\n    inertias[i] = kmeans.inertia_","b6b0f7ed":"plt.title('Elbow curve')\nplt.plot(K, inertias, 'o-')\nelbow, scores = elbow_method(K, inertias)\nplt.vlines(K[elbow], inertias.min(), inertias.max(), 'r', 'dashdot', label=f'elbow at $K$ = {K[elbow]}')\nplt.legend()\nplt.xlabel('$K$')\nplt.ylabel('inertia')\nplt.xticks(K)\nplt.show()","4b24e1bf":"kmeans = KMeans(n_clusters=23, max_iter=int(1e+5), algorithm='full').fit(pca)","fb02e84f":"plot_clusters(kmeans, pca, hover_data=df, title='K-Means Clusterring of PCA transformation', color='clusters', marker='school', dim=2)","bbecd435":"temp_df = df.copy()\ntemp_df['cluster'] = kmeans.predict(pca)\nstd = temp_df.groupby('cluster').std()\ncount_df = temp_df.groupby('cluster').describe(include='object').loc[:, [(c, 'unique') for c in df.select_dtypes(include=['object']).columns]]\ncount_df = count_df.xs('unique', axis=1, level=1)\ncount_df = count_df.rename(columns={c: c+'_count' for c in count_df.columns})\ncount_df[['n_student_std', 'posttest_std']] = std\ncount_df","6eda05b8":"del(count_df, temp_df, std)","170045a0":"new_df = df[['posttest', 'classroom']].groupby('classroom').aggregate(['count', 'mean'])['posttest']\nnew_df = new_df.rename(columns={'count': 'n_student', 'mean': 'posttest_class_average'})\nnew_df = new_df.reset_index()\nnew_df['school_setting'] = new_df['classroom'].apply(lambda _x: df.query(f\"classroom == '{_x}'\")['school_setting'].unique()[0])\nnew_df['school_type'] = new_df['classroom'].apply(lambda _x: df.query(f\"classroom == '{_x}'\")['school_type'].unique()[0])\nnew_df['teaching_method'] = new_df['classroom'].apply(lambda _x: df.query(f\"classroom == '{_x}'\")['teaching_method'].unique()[0])\nnew_df['male_ratio_in_class']= new_df['classroom'].apply(lambda _x: np.sum(df.query(f\"classroom == '{_x}'\")['gender'] == 'Male') \/ df.query(f\"classroom == '{_x}'\")['n_student'].iloc[0]).fillna(0)\nnew_df['lunch_qual_ratio_in_class'] = new_df['classroom'].apply(lambda _x: np.sum(df.query(f\"classroom == '{_x}'\")['lunch'] == 'Qualifies') \/ df.query(f\"classroom == '{_x}'\")['n_student'].iloc[0]).fillna(0)\nnew_df.head()","55b8db54":"y = new_df['posttest_class_average'].copy()\nnew_df = new_df.drop(columns=['posttest_class_average', 'classroom'])","14f06cd7":"cat_transformer = make_column_transformer((OrdinalEncoder(), new_df.select_dtypes(include=['object']).columns.to_list()), remainder='passthrough')","6b0112f5":"sett = {'C': {'space': (1e-2, 450)},\n        'gamma': {'space': (1e-3, 0.99), 'f': lambda _x: min(abs(_x), 0.99)},\n        'coef0': {'space': (1e-5, 100), 'f': lambda _x: abs(_x)},\n       'epsilon': {'space': (0.001, 3.5), 'f': lambda _x: abs(_x)}}\n\nsvm = optimize(SVR, new_df, y, settings=sett, extra_steps=[('transform', cat_transformer), ('sc', StandardScaler())], \n               cv_params={'scoring': 'neg_mean_absolute_error', 'cv': 5}, opt_params={'n_iter': 100}, max_min='max')","3a00b779":"svm = svm.fit(new_df, y)\nexplainer_2 = shap.KernelExplainer(svm.steps[2][1].predict, svm.steps[1][1].transform(svm.steps[0][1].transform(new_df)))\nshap_values_2 = explainer_2.shap_values(svm.steps[1][1].transform(svm.steps[0][1].transform(new_df)))\nregression_summary(y, svm.predict(new_df), 'Summary for SVM Regressor')","c4afece1":"plt.subplot(1, 2, 1)\nshap.dependence_plot(0, shap_values_2, new_df, show=False,ax=plt.gca())\nplt.subplot(1, 2, 2)\nshap.summary_plot(shap_values_2, new_df, plot_type=\"bar\", show=False, plot_size=(15, 6))\nplt.tight_layout()\nplt.show()","517fb8a3":"plt.figure(figsize=(20, 10))\nplt.suptitle('A sample of prediction explanations')\nn_samples = 6\nindexes = np.random.randint(0, len(y)-1, n_samples)\nfor i, j in enumerate(indexes):\n    plt.subplot(2, 3, i+1)\n    title = 'true score = {:.2f}, Absolute Error = {:.2f}'.format(y.iloc[j], mean_absolute_error(y.iloc[j:j+1], svm.predict(new_df.iloc[j:j+1])))\n    shap.decision_plot(explainer_2.expected_value, shap_values_2[j], new_df.iloc[j], show=False, title=title, auto_size_plot=False)\nplt.tight_layout()\nplt.show()","c6480d0c":"So the difference between the distributions seems quite big, and thats something we're going to have an hypothesis test about later on.\n\nNext, we'd like to see the distributions of posttest grades variances within classrooms and schools, in order to understand whether this features are biased.","1ad428c9":"## Table of Contents:\n* [Useful Functions](#useful-functions)\n    * [Plottings](#Plottings)\n    * [DataFrame Transformations](#DataFrame-Transformations)\n    * [ML, Optimization and Metrics](#mmo)\n* [Part 1: EDA](#eda)\n    * [Categorical Data](#cat)\n    * [Numeric Data](#num)\n    * [Statistical Relationship Analysis](#sra)\n        * [Dimensionality Reduction](#pca)\n* [Part 2: Hypothesis Testing](#hypt)\n    * [Effect Size](#effs)\n    * [Gender x Grades](#ttest)\n    * [Number of Students in Class x Grades](#ttest2)\n\n* [Part 3: Clusterring the Data](#clusters)\n\n* [Part 4: Regression Modelling](#reg)\n    * [Class Scores Average - SVM Regressor](#svm)","7f771434":"#### Dimensionality Reduction <a class=\"anchor\" id=\"pca\"><\/a>\n\n\nAt this part we're gonna use PCA on our data for a few uses:\n- Look out for interesting insights on the scattered data in lower dimension\n- Understand better the statistical relationship between some of our features","a0265b84":"## Part 4: Regression Modelling <a class=\"anchor\" id=\"reg\"><\/a>\nNext, we're gonna run two regression methods, with optimized hyperparameters (using bayesian optimization), in order to modelize two aspects, that we've seen before, coming from the data.","c9c56a6b":"The variance of grades within classes is too low, hence, highly biased, and we'd like to get rid of this feaure in some uses.\nHowever, the variance of grades within schools is mostly fine, so we'll keep it anyway.","ed174f05":"In the following test we're going to perform a _t-test_ on whether the posttest scores of male and female are significantly different.\n\nWe shall formulate the problem:\n\nLet $A = \\{ x_1, x_2, \\dots, x_n \\}$ and $ B = \\{ y_1, y_2, \\dots, y_m \\}$ be two groups of posttest scores, where every $y \\in B$ are iid with mean $\\mu_1$, variance $\\sigma_1^{2}$ and is a posttest score of a female. Also, every $\\forall x \\in A$ are iid with mean $\\mu_2$, variance $\\sigma_2^{2}$ and is a posttest score of a male.\n\n**$\\mathbb{H}_0: \\mu_1 = \\mu_2$** , **$\\mathbb{H}_1: \\mu_1 \\ne \\mu_2$** for some $\\alpha$ (significance level yet to be picked).\n\nOur statistic, in this test, will be a t-statistic, and our test function is defined by:\n\n<center> $\\delta = \\begin{cases}1, & \\text { if } |t| \\leq \\theta \\\\  0, & \\text { if } |t| > \\theta \\end{cases} : \\theta = \\sqrt{2}\\cdot erf^{-1}(1 - \\alpha)$ is the critical value. <\/center>\n\n$\\mathbb{H}_0$ is obviously rejected $\\iff \\delta = 0$.","ea14fe62":"### DataFrame Transformations <a class=\"anchor\" id=\"DataFrame-Transformations\"><\/a>","d35dbb7d":"Based on the tables above, we can basically dismiss the *student_id* feature, as its variety leads to no valuable information to be gained out of it.","6b936165":"### Class Scores Average - SVM Regressor <a class=\"anchor\" id=\"svm\"><\/a>\n\nWe'd like to model the classes' posttest averages, without knowing the schools name (leaked data in the previous model), in order to maybe get a better understanding for the students' grades within each class, which we are potentially able to do, since the variance within classes is low, as we've seen already.","2afb4d7b":"## Part 3: Clusterring the Data <a class=\"anchor\" id=\"clusters\"><\/a>\n\nAt this part we'd like to apply a clusterring method on our data, inorder to maybe find some insights on it. However, our data by itself is not very \"clusterable\", by its very categorical nature. Thus, we're going to apply the K-Means algorithm on the first two components of the PCA transformation form of the data (scaled), as it might also do (we got a clusterable result previously).\n\nFirst, lets find the optimal $k$ for the K-Means algorithm using the elbow method, and we're gonna run from $k = 2$ (number of groups, such as gender, in the data) to $k = 29$ (randomly chosen number, larger than the number of schools in the data).","d886299e":"## Part 1: EDA <a class=\"anchor\" id=\"eda\"><\/a>\nThe following part contains of:\n- Data Visualizations\n- General Statistics of Each Feature\n- Visualizing Relationships Between Features\n- Dimensionality Reduction\n\n### Categorical Data <a class=\"anchor\" id=\"cat\"><\/a>","9c3a9dd5":"### Numeric Data <a class=\"anchor\" id=\"num\"><\/a>","c5fb9b9c":"We can already see differences in some of the features distributions when dividing them into separated groups;\n- School type, divided by teaching method\n- School type, divided by *lunch* feature\n- Genders in different school settings","fff4d7ca":"So the plot suggests that there might be a convergence problem, based on the fact that the number of clusters equals to the number of schools, yet the clusters aren't homogeneous school-wise. However, it seems like the number of students in a class and the school settings are the most common things within each cluster, which interestingly enough are the two most important feature for the first and second principal components of the PCA.","88ef64bc":"## Part 2: Hypothesis Testing <a class=\"anchor\" id=\"hypt\"><\/a>\n\n### Effect Size <a class=\"anchor\" id=\"effs\"><\/a>\n\nNext, we'll question whether the differences, of posttest scores, between some groups in the data, are significant. But first, we're going to use the **Cohen\u2019s $d$ effect size** to determine the effect size, ofcourse, of some features in the data.\n\nThe **Cohen\u2019s $d$ effect size** is mathematically denoted by:\n\n<center> $d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s} $ : $\\bar{x}_1, \\bar{x}_2$ are the averages of each group, and <\/center>\n\n<center> $s = \\sqrt{\\frac{(n_1-1) s_1^2 + (n_2-1) s_2^2}{n_1 + n_2}} $ : $s_1, s_2$ are the standard deviation of each group <\/center>\n\nThe value of $d$ should be interpreted with the following table:\n\n| d | Effect Size |\n| --- | --- |\n| **0.01** | **Very Small** |\n| **0.2** | **Small** |\n| **0.5** | **Medium** |\n| **0.8** | **Large** |\n| **1.0** | **Very Large** |\n| **2.0** | **Huge** |\n\nMore info about the method could be found [here](https:\/\/en.wikipedia.org\/wiki\/Effect_size#Difference_family:_Effect_sizes_based_on_differences_between_means).","cf453b39":"-----------------------------------------","af3a136a":"**XAI conclusions**:\n\nIn the following analysis it is good to keep in mind that the model hasn't converged proparly, probably due to lacking of data.\n\n- Lunch qualification ratio, within class, impact: \n\nThe highly negative impact of this feature on the predition makes some sense, as it has been seen before that students that qualifies for free lunch usually gets lower scores (\"Huge\" effect size).\n\n- Male students ratio, within class, impact: \n\nThe low impact of this feature on the predition makes some sense, as it has been seen before that student's gender is doesn't suppose to effect their posttest score.\n\n\n- School type impact: \n\nThe high impact of this feature is very much related with the lunch qualification ratio impact, as on the 1st part we've seen that within public schools the relative density of free lunch qualified students is higher than the density in non-public schools.","1e728a89":"The summary table shows some not great results, probably due to the small number of samples the model has trained on.","beb92496":"### ML, Optimization and Metrics <a class=\"anchor\" id=\"mmo\"><\/a>","c5e6ed91":"So there are a few interesting things coming up from the plots above:\n- As already been seen in one of the figures above, the PCA shows us that the number of students in a class is negativey effecting the posttest scores in the class.\n- There are many homogeneous clusters scattered over the plot of the components, and the common attribute is seem to be the school (could be seen clearer if the \"marker\" parameter is set to 'school'). \n- Some features are oddly seem correlated with each other(number of students in the class & lunch qualification, posttest & gender).\n- The explained variance ratio figure suggests that there are 1-2 disposable features (almost no gain in the last two). We won't remove any feature anyway, we have only a few of them already.","15966838":"## Useful Functions <a class=\"anchor\" id=\"useful-functions\"><\/a>\n\n### Plottings <a class=\"anchor\" id=\"Plottings\"><\/a>","5cb95b55":"The figure above shows that for any reasonable $\\alpha$ we'd take, $\\mathbb{H}_0$ will be accepted. Hence, the difference between male and female posttest scores **is not** significant.\n\n### Number of Students in Class x Grades <a class=\"anchor\" id=\"ttest2\"><\/a>\nThe following hypothesis test would show whether the differences, in posttest scores, between students in classes with 24 or more students to others, are significant.\n\nFormally:\n\nLet $A = \\{ x_1, x_2, \\dots, x_n \\}$ and $ B = \\{ y_1, y_2, \\dots, y_m \\}$ be two groups of posttest scores, where every $y \\in B$ are iid with mean $\\mu_1$, variance $\\sigma_1^{2}$ and is a posttest score of a student who has 23 or more classmates. Also, every $\\forall x \\in A$ are iid with mean $\\mu_2$, variance $\\sigma_2^{2}$ and is a posttest score of a student who has 22 or less classmates.\n\n**$\\mathbb{H}_0: \\mu_1 = \\mu_2$** , **$\\mathbb{H}_1: \\mu_1 < \\mu_2$** for $\\alpha = 0.05$","5cfe6ee9":"Clearly, the pretest and posttest scores are very highly correlated, almost as if these were the same features to work with.\n","97924206":"The approximation is pretty close to be the number of schools in the data. I'll assume that the optimal number of clusters is infact 23, and there has been an issue of convergence in the algorithm.","b3484857":"The test shows that the difference is highly significant ( $\\mathbb{H}_0$ is rejected ), so we could make out of it the conclusion that a large number of students in a class could negatively affect the posttest scores of those students.","40bdad90":"Another interesting thing to investigate is whether the number of students in a class affects, significantly, the class GPA.","73950513":"The results above pretty much explain themselves, especially with respect to the splitted posttest scores distribution seen above.\n\n### Gender x Grades <a class=\"anchor\" id=\"ttest\"><\/a>","c7278475":"We can see that the GPA of classes with 23 students or less are above 60 (passing grade). However, the coefficient between the two groups seems to be very low. Also, we can see that the standard deviation of scores within classes is **not** affected by the number of students in the class, meaning that any effect the number of students has on the class scores - is collective on the students, and not by a chance of having a 'specifically weak\/strong' students in a class.","358b1b3e":"### Statistical Relationship Analysis <a class=\"anchor\" id=\"sra\"><\/a>"}}