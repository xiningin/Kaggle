{"cell_type":{"a6c87eff":"code","5d639dd7":"code","a69e9c13":"code","8c7d76c6":"code","224b78ed":"code","7b652d53":"code","b8755abb":"code","c4dc8504":"code","01b01a78":"code","e91e5bf9":"code","2063b1d3":"code","d48a983d":"code","57471369":"code","87eee2f5":"code","ce6a5a7f":"code","baccb465":"code","fef8b513":"code","0b55aad2":"code","3917d4aa":"code","760faefa":"code","d3c64380":"code","51ebb161":"code","aa85f177":"code","4d763a1a":"code","06173407":"code","7a384733":"code","37da28e0":"code","dd083ba8":"code","7b17d35e":"code","b3861c70":"code","957acacb":"code","b325faca":"code","ebbe8dc0":"code","2e439246":"code","a7282c9a":"code","2219a4ff":"code","ed1ed1a6":"code","f3032d93":"code","8bc16d2b":"code","278ac808":"code","daa1a1d5":"code","0326f813":"code","bd47ecc5":"markdown","277b37fb":"markdown","025d4ad4":"markdown","2dc4af35":"markdown","d68243fd":"markdown","696e2bf6":"markdown","2712652b":"markdown","ce0d42a6":"markdown","cb13e024":"markdown","9e1a9d36":"markdown","4c453272":"markdown","f00eb00b":"markdown","84e1e92f":"markdown"},"source":{"a6c87eff":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","5d639dd7":"import warnings\nwarnings.filterwarnings('ignore')","a69e9c13":"data = pd.read_csv('..\/input\/water-potability\/water_potability.csv')","8c7d76c6":"data.info()","224b78ed":"data.head()","7b652d53":"data.describe()","b8755abb":"data.isnull().sum()[data.isnull().sum()>0]","c4dc8504":"sns.countplot(data['Potability'])","01b01a78":"data['Potability'].value_counts()","e91e5bf9":"fig = plt.figure(figsize=(18,16))\nfor index,col in enumerate(data.drop('Potability',axis=1).columns):\n    plt.subplot(5,2,index+1)\n    sns.distplot(data.drop('Potability', axis=1).loc[:,col].dropna(), kde=False)\nfig.tight_layout(pad=1.0)","2063b1d3":"fig = plt.figure(figsize=(14,15))\nfor index,col in enumerate(data.drop('Potability', axis=1).columns):\n    plt.subplot(5,2,index+1)\n    sns.boxplot(y=col, data=data.drop('Potability', axis=1).dropna())\nfig.tight_layout(pad=1.0)","d48a983d":"fig = plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(), annot=True, cmap='gray')","57471369":"data['ph'].fillna(data['ph'].mean(),inplace=True)\ndata['Sulfate'].fillna(data['Sulfate'].mean(),inplace=True)\ndata['Trihalomethanes'].fillna(data['Trihalomethanes'].mean(),inplace=True)","87eee2f5":"data.isnull().sum()[data.isnull().sum()>0]","ce6a5a7f":"data = data.sample(frac = 1)","baccb465":"X = data.drop('Potability', axis=1)\nY = data['Potability']","fef8b513":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.25, random_state=42)","0b55aad2":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n","3917d4aa":"from sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","760faefa":"gnb = GaussianNB()\ncv = cross_val_score(gnb,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","d3c64380":"lr = LogisticRegression(max_iter = 2000)\ncv = cross_val_score(lr,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","51ebb161":"knn = KNeighborsClassifier(n_neighbors=4)\ncv = cross_val_score(knn,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","aa85f177":"rf = RandomForestClassifier(random_state = 42)\ncv = cross_val_score(rf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","4d763a1a":"svc = SVC(probability = True)\ncv = cross_val_score(svc,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","06173407":"from xgboost import XGBClassifier\nxgb = XGBClassifier(random_state =1)\ncv = cross_val_score(xgb,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","7a384733":"from sklearn.ensemble import VotingClassifier\nvoting_clf = VotingClassifier(estimators = \n                              [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svc',svc),('xgb',xgb)], voting = 'soft') ","37da28e0":"cv = cross_val_score(voting_clf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","dd083ba8":"from sklearn.metrics import accuracy_score\nvoting_clf.fit(X_train,y_train)\ny_pred_vc_soft = voting_clf.predict(X_test).astype(int)\naccuracy_score(y_pred_vc_soft, y_test)","7b17d35e":"voting_clf = VotingClassifier(estimators = \n                              [('rf',rf),('svc',svc),('xgb',xgb)], voting = 'soft') ","b3861c70":"cv = cross_val_score(voting_clf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","957acacb":"from sklearn.model_selection import RandomizedSearchCV","b325faca":"def performance(classifier, model_name):\n    print(model_name)\n    print('Best Score :' + str(classifier.best_score_))\n    print(\"Best Parameters :\" + str(classifier.best_params_))","ebbe8dc0":"svc = SVC(probability = True)\nparam_grid = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n                                  'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\nclf_svc = RandomizedSearchCV(svc, param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_svc = clf_svc.fit(X_train, y_train)\nperformance(best_clf_svc,'SVC')","2e439246":"best_svc = best_clf_svc.best_estimator_.fit(X_train, y_train)","a7282c9a":"y_pred = best_svc.predict(X_test)\naccuracy_score(y_pred, y_test)","2219a4ff":"xgb = XGBClassifier(random_state = 42)\n\nparam_grid = {\n    'n_estimators': [450,500,550],\n    'colsample_bytree': [0.75,0.8,0.85],\n    'max_depth': [None],\n    'reg_alpha': [1],\n    'reg_lambda': [2, 5, 10],\n    'subsample': [0.55, 0.6, .65],\n    'learning_rate':[0.5],\n    'gamma':[.5,1,2],\n    'min_child_weight':[0.01],\n    'sampling_method': ['uniform']\n}\n\nclf_xgb = RandomizedSearchCV(xgb, param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_xgb = clf_xgb.fit(X_train,y_train)\nperformance(best_clf_xgb,'XGB')","ed1ed1a6":"best_xgb = best_clf_xgb.best_estimator_.fit(X_train, y_train)\ny_pred = best_xgb.predict(X_test)\naccuracy_score(y_pred, y_test)","f3032d93":"rf = RandomForestClassifier(random_state = 42)\nparam_grid =  {'n_estimators': [400,450,500,550],\n               'criterion':['gini','entropy'],\n                                  'bootstrap': [True],\n                                  'max_depth': [15, 20, 25],\n                                  'max_features': ['auto','sqrt', 10],\n                                  'min_samples_leaf': [2,3],\n                                  'min_samples_split': [2,3]}\n                                  \nclf_rf = RandomizedSearchCV(rf, param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_rf = clf_rf.fit(X_train,y_train)\nperformance(best_clf_rf,'Random Forest')","8bc16d2b":"best_rf = best_clf_rf.best_estimator_.fit(X_train, y_train)\ny_pred = best_rf.predict(X_test)\naccuracy_score(y_pred, y_test)","278ac808":"model = VotingClassifier(estimators=[('SVC', best_svc),\n                                     ('XGB', best_xgb),\n                                     ('RF', best_rf),\n                                    ],voting='hard')\n","daa1a1d5":"model.fit(X_train,y_train)","0326f813":"y_pred = model.predict(X_test)\naccuracy_score(y_pred, y_test)","bd47ecc5":"Cannot use GridSearch because it will take too long.","277b37fb":"Exploring the data we see that 3 columns are missing value's, we will have to fix them.","025d4ad4":"Shuffling the data.","2dc4af35":"It is interesting to note that our untuned voting classifier with soft voting give's a slightly better result. Thanks for reading my Notebook, leave a upvote if you find it helpful.","d68243fd":"Final output is a bit unexpected, as i got an accuracy of 70% on local machine.","696e2bf6":"We see that target value is not equally matched, 0 has 720 more values then 1.","2712652b":"No extreme outliers can be seen in boxplot.\n","ce0d42a6":"In this Notebook we will try to predict whether the water quality is safe to drink for a human.","cb13e024":"Most of our data seem to follow the normal curve, except solids nothing seems skewed.","9e1a9d36":"Feature's have very low correlation with target variable, it means the effects of feature's on target variable is minimum.","4c453272":"checking results of differrent models.","f00eb00b":"I filled the missing value's with their mean because they do not have strong correlation with any feature's ","84e1e92f":"Splitting the data."}}