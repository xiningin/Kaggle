{"cell_type":{"8e12b3cf":"code","a5e6dfdb":"code","cc2c3580":"code","74a43d62":"code","b3ded3b9":"code","476eb8a8":"code","dfe50b64":"code","8585bb21":"code","7d8c89b9":"code","3e92222a":"markdown","57c4a42f":"markdown"},"source":{"8e12b3cf":"# Importing the necessary packages\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Listing our available input files\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a5e6dfdb":"# Loading the Train Dataset\ndata = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\n# Dropping Columns that we are guess are irrelevant\ndata = data.drop(['Name', 'Ticket', 'Cabin',\n                  'Embarked'], axis=1)\n\n# Giving Sex a Numerical Value\ndata.loc[data.Sex == 'male', 'Sex'] = 1\ndata.loc[data.Sex == 'female', 'Sex'] = 0\n\n# Combining the Siblings\/Spouse Column and the Parent\/Child Column\ndata['Relatives'] = data['SibSp'] + data['Parch']\n\n# Dropping the Old Siblings\/Spouse Column and the Parent\/Child Column\ndata = data.drop(['SibSp', 'Parch'], axis=1)\n\n# Shifting the Survived Column to the Last Space\ndata.insert(6, 'Survived', data.pop('Survived'))\n\n# Replacing Entries with Missing Elements with The Median\ndata = data.apply(pd.to_numeric, errors='coerce')\ndata['Relatives'] = data['Relatives'].fillna(data.mean())\ndata = data.fillna(data.median())\n\nprint(data.head())","cc2c3580":"# Sorting Input and Output Data\nx = data.iloc[:, 1:-1]\ny = data.iloc[:, -1]\n\n# Split Data Between Training and Testing\nX_train, X_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.2, random_state=69)\n\n# Standardize Input\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n\n# Convert y_train from Pandas Series to Numpy Array\ny_train = y_train.to_numpy()\n\n# Ensure PyTorch is Using our GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# Define the Model Parameters\nEPOCHS = 350\nBATCH_SIZE = len(X_train)\nLEARNING_RATE = (1 \/ EPOCHS)\nLAYER_NODES = 4","74a43d62":"# Define Custom Dataloaders for PyTorch\n# Training Data\n\n\nclass trainData(Dataset):\n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n\n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n\n    def __len__(self):\n        return len(self.X_data)\n\n\ntrain_data = trainData(torch.Tensor(X_train), torch.Tensor(y_train))\n\n# Testing Data\n\n\nclass testData(Dataset):\n    def __init__(self, X_data):\n        self.X_data = X_data\n\n    def __getitem__(self, index):\n        return self.X_data[index]\n\n    def __len__(self):\n        return len(self.X_data)\n\n\ntest_data = testData(torch.FloatTensor(X_test))\n\n# Initialize the Dataloaders\ntrain_loader = DataLoader(\n    dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_data, batch_size=1)","b3ded3b9":"# Define our Neural Network Architecture\n\n\nclass binaryClassification(nn.Module):\n    def __init__(self):\n        super(binaryClassification, self).__init__()\n        # Number of input features is 5.\n        self.layer_1 = nn.Linear(5, LAYER_NODES)\n        self.layer_2 = nn.Linear(LAYER_NODES, LAYER_NODES)\n        self.layer_out = nn.Linear(LAYER_NODES, 1)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.1)\n        self.batchnorm1 = nn.BatchNorm1d(LAYER_NODES)\n        self.batchnorm2 = nn.BatchNorm1d(LAYER_NODES)\n\n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n\n        return x","476eb8a8":"# Initialize our Optimizer and Choose a Loss Function\nmodel = binaryClassification()\nmodel.to(device)\n\n# Optionally Print our Model Architecture\n# print(model)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# Create a Function to Calculate Model Accuracy\n\n\ndef binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n\n    return acc","dfe50b64":"# Begin Training our Model\nmodel.train()\nfor e in range(1, EPOCHS+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n\n        y_pred = model(X_batch)\n\n        loss = criterion(y_pred, y_batch.unsqueeze(1))\n        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss\/len(train_loader):.5f} | Acc: {epoch_acc\/len(train_loader):.3f}')","8585bb21":"# Testing our Model\ny_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n\n# Saving our Model for Future Use\ntorch.save(model, '\/kaggle\/working\/trained_model')\n\n\n# Confusion Matrix\nconfusion_matrix(y_test, y_pred_list)\n\n# Classification Report\nprint(classification_report(y_test, y_pred_list))","7d8c89b9":"# Loading the Test Dataset\ndata = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\nsubmission = data\nsubmission = submission.drop(['Pclass', 'Name', 'Sex', 'Age',\n                              'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\n\n# Dropping Columns that we are guess are irrelevant\ndata = data.drop(['Name', 'Ticket', 'Cabin',\n                  'Embarked'], axis=1)\n\n# Combining the Siblings\/Spouse Column and the Parent\/Child Column\ndata['Relatives'] = data['SibSp'] + data['Parch']\n\n# Dropping the Old Siblings\/Spouse Column and the Parent\/Child Column\ndata = data.drop(['SibSp', 'Parch'], axis=1)\n\n# Giving Sex a Numerical Value\ndata.loc[data.Sex == 'male', 'Sex'] = 1\ndata.loc[data.Sex == 'female', 'Sex'] = 0\n\n# Handle Blank Values\ndata = data.apply(pd.to_numeric, errors='coerce')\ndata['Relatives'] = data['Relatives'].fillna(data.mean())\ndata = data.fillna(data.median())\n\n# Exclude the PassengerId Column\ndata = data.iloc[:, 1:]\n\n# Standardize Input\nscaler = StandardScaler()\ninput = scaler.fit_transform(data)\n\nx = data.iloc[:, 1:-1]\n\n# Ensure PyTorch is Using our GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n\nclass testData(Dataset):\n    def __init__(self, X_data):\n        self.X_data = X_data\n\n    def __getitem__(self, index):\n        return self.X_data[index]\n\n    def __len__(self):\n        return len(self.X_data)\n\n\ntest_data = testData(torch.FloatTensor(input))\n\n# Initialize the Dataloaders\ntest_loader = DataLoader(dataset=test_data, batch_size=1)\n\n# Initialize our Optimizer and Choose a Loss Function\nmodel = torch.load('\/kaggle\/working\/trained_model')\nmodel.to(device)\n\n# Testing our Model\ny_pred_list = []\nmodel.eval()\n\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n\ny_pred_list = [int(a.squeeze().tolist()) for a in y_pred_list]\n\n# Save Our Results into The Submission DataFrame and to CSV\nsubmission.insert(len(submission.columns), 'Survived', y_pred_list)\nsubmission.to_csv('\/kaggle\/working\/Submission.csv', index=False)\nprint(submission.head())\nprint(submission.shape)","3e92222a":"# **Binary Classification**\n\nThe following is an implementation of a binary classification utilizing PyTorch machine learning.\n\nThe results of this model were submitted to the Titanic competition and acheived a score of: 0.77751","57c4a42f":"**Testing our Model Against the Test Dataset**"}}