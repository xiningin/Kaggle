{"cell_type":{"ba74b185":"code","044ae416":"code","ac7cdc07":"code","a8b8a2af":"code","6ecd6b00":"code","caf9528b":"code","2544373d":"markdown"},"source":{"ba74b185":"import cv2\nimport os\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom tqdm import tqdm","044ae416":"TRAIN = '..\/input\/train_v2\/'\nnames = os.listdir(TRAIN)","ac7cdc07":"def get_hash(img):\n    result = []\n    sz = 256 #images are composed of 256x256 overlapping patches\n    for ix in range(0,768,sz):\n        for jx in range(0,768,sz):\n            result.append(hash(img[ix:ix+sz,jx:jx+sz,:].tobytes()))\n    return result","a8b8a2af":"hash_dict = defaultdict(list)\nfor name in tqdm(names):\n    img = cv2.imread(os.path.join(TRAIN,name))\n    hashes = get_hash(img)\n    for h in hashes:\n        hash_dict[h].append(name)","6ecd6b00":"img_dict = {name:list() for name in names}\nfor key,val in hash_dict.items():\n    items = set(val)\n    if(len(items) > 1):\n        for item_i in items:\n            for item_j in items:\n                if item_i == item_j: continue\n                img_dict[item_i].append(item_j)\n                \nduplicate_dict = dict()\nfor key,val in img_dict.items():\n    duplicates = set(val)\n    if len(duplicates) == 0: duplicate_dict[key] = np.nan\n    else: duplicate_dict[key] = ' '.join(duplicates)","caf9528b":"df = pd.DataFrame(pd.Series(duplicate_dict), columns=['duplicates'])\ndf['ImageId'] = df.index\ndf.to_csv('duplicates.csv',index=False)\ndf.head()","2544373d":"### Overview\nTraining data for this competition is generated by cropping a big image into 768x768 patches with 256 step. Therefore, it creates numerous overlaps in the train dataset and does not allow to use a random subset of images for validation. To exclude images that overlap with validation set from train set, I created this kernel. It checks 'train_v2' dataset and creates a file with a list of overlapping images, which can be used during train\/val split."}}