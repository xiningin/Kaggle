{"cell_type":{"a645f54c":"code","95b72609":"code","ad1de4c5":"code","b69da3b6":"code","157b781d":"code","b8a34584":"code","ffec74e8":"code","966b7435":"code","e0df0bb9":"code","c874079a":"code","0f551f76":"code","06839ebe":"code","a71dad1d":"code","6a7c6da8":"markdown","350f0453":"markdown","cfac3483":"markdown","5c946e33":"markdown","ed630858":"markdown","16ffa46c":"markdown","9b625cce":"markdown","80a9d50b":"markdown"},"source":{"a645f54c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt # show graph\n\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom hmmlearn import hmm\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","95b72609":"data = pd.read_csv(\"\/kaggle\/input\/name-entity-recognition-ner-dataset\/NER dataset.csv\", encoding='latin1')\ndata = data.fillna(method=\"ffill\")\ndata = data.rename(columns={'Sentence #': 'sentence'})\ndata.head(5)","ad1de4c5":"tags = list(set(data.POS.values)) #Read POS values\nwords = list(set(data.Word.values))\nlen(tags), len(words)","b69da3b6":"y = data.POS\nX = data.drop('POS', axis=1)\n\ngs = GroupShuffleSplit(n_splits=2, test_size=.33, random_state=42)\ntrain_ix, test_ix = next(gs.split(X, y, groups=data['sentence']))\n\ndata_train = data.loc[train_ix]\ndata_test = data.loc[test_ix]\n\ndata_train","157b781d":"tags = list(set(data_train.POS.values)) #Read POS values\nwords = list(set(data_train.Word.values))\nlen(tags), len(words)","b8a34584":"dfupdate = data_train.sample(frac=.15, replace=False, random_state=42)\ndfupdate.Word = 'UNKNOWN'\ndata_train.update(dfupdate)\nwords = list(set(data_train.Word.values))\n# Convert words and tags into numbers\nword2id = {w: i for i, w in enumerate(words)}\ntag2id = {t: i for i, t in enumerate(tags)}\nid2tag = {i: t for i, t in enumerate(tags)}\nlen(tags), len(words)","ffec74e8":"count_tags = dict(data_train.POS.value_counts())\ncount_tags_to_words = data_train.groupby(['POS']).apply(lambda grp: grp.groupby('Word')['POS'].count().to_dict()).to_dict()\ncount_init_tags = dict(data_train.groupby('sentence').first().POS.value_counts())\n\n# TODO use panda solution\ncount_tags_to_next_tags = np.zeros((len(tags), len(tags)), dtype=int)\nsentences = list(data_train.sentence)\npos = list(data_train.POS)\nfor i in range(len(sentences)) :\n    if (i > 0) and (sentences[i] == sentences[i - 1]):\n        prevtagid = tag2id[pos[i - 1]]\n        nexttagid = tag2id[pos[i]]\n        count_tags_to_next_tags[prevtagid][nexttagid] += 1","966b7435":"mystartprob = np.zeros((len(tags),))\nmytransmat = np.zeros((len(tags), len(tags)))\nmyemissionprob = np.zeros((len(tags), len(words)))\nnum_sentences = sum(count_init_tags.values())\nsum_tags_to_next_tags = np.sum(count_tags_to_next_tags, axis=1)\nfor tag, tagid in tag2id.items():\n    floatCountTag = float(count_tags.get(tag, 0))\n    mystartprob[tagid] = count_init_tags.get(tag, 0) \/ num_sentences\n    for word, wordid in word2id.items():\n        myemissionprob[tagid][wordid]= count_tags_to_words.get(tag, {}).get(word, 0) \/ floatCountTag\n    for tag2, tagid2 in tag2id.items():\n        mytransmat[tagid][tagid2]= count_tags_to_next_tags[tagid][tagid2] \/ sum_tags_to_next_tags[tagid]","e0df0bb9":"model = hmm.MultinomialHMM(n_components=len(tags), algorithm='viterbi', random_state=42)\nmodel.startprob_ = mystartprob\nmodel.transmat_ = mytransmat\nmodel.emissionprob_ = myemissionprob","c874079a":"data_test.loc[~data_test['Word'].isin(words), 'Word'] = 'UNKNOWN'\nword_test = list(data_test.Word)\nsamples = []\nfor i, val in enumerate(word_test):\n    samples.append([word2id[val]])\n    \n# TODO use panda solution\nlengths = []\ncount = 0\nsentences = list(data_test.sentence)\nfor i in range(len(sentences)) :\n    if (i > 0) and (sentences[i] == sentences[i - 1]):\n        count += 1\n    elif i > 0:\n        lengths.append(count)\n        count = 1\n    else:\n        count = 1","0f551f76":"# This code is very slow\npos_predict = model.predict(samples, lengths)\npos_predict","06839ebe":"tags_test = list(data_test.POS)\npos_test = np.zeros((len(tags_test), ), dtype=int)\nfor i, val in enumerate(tags_test):\n    pos_test[i] = tag2id[val]\nlen(pos_predict), len(pos_test), len(samples), len(word_test)","a71dad1d":"def reportTest(y_pred, y_test):\n    print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred))) \n    print(\"The precision is {}\".format(precision_score(y_test, y_pred, average='weighted'))) \n    print(\"The recall is {}\".format(recall_score(y_test, y_pred, average='weighted'))) \n    print(\"The F1-Score is {}\".format(f1_score(y_test, y_pred, average='weighted')))\n\nmin_length = min(len(pos_predict), len(pos_test))\n\nreportTest(pos_predict[:min_length], pos_test[:min_length])","6a7c6da8":"Get the numbers of tags & words inside the whole data. We'll need this in the future.","350f0453":"We cannot split data normally with `train_test_split` because doing that makes some parts of a sentence in the training set while some others in the testing set. Instead, we use `GroupShuffleSplit`.","cfac3483":"Initialize a HMM","5c946e33":"Somehow the output of HMM is in wrong size. Only use the shorter length to check the result.","ed630858":"The number of tags is enough but the number of words is not enough (~29k vs ~35k).\nBecause of that we need to randomly add some UNKNOWN words into the training dataset then we recalculate the word list and create map from them to number.","16ffa46c":"Hidden Markov Models can be trained by using the Baum-Welch algorithm.\nHowever input of the training is just dataset (Words).\nWe cannot map back the states to the POS tag.\n\nThat's why we have to calculate the model parameters for `hmmlearn.hmm.MultinomialHMM` manually by calculating\n- `startprob_`\n- `transmat_`\n- `emissionprob_`","9b625cce":"As some words may never appear in the training set, we need to transform them into `UNKNOWN` first.\nThen we split `data_test` into `samples` & `lengths` and send them to HMM.","80a9d50b":"After checking the data after splitted, it seems to be fine.\nCheck the numbers of tags & words in the training set."}}