{"cell_type":{"72e5b0d5":"code","e92d4945":"code","bcd63b5e":"code","d78bda2e":"code","1687d3cb":"code","65b877d9":"code","b27fdbcb":"code","6f40bfe1":"code","b0dcdfc1":"code","538335f4":"code","62618875":"code","74cd92e8":"code","c678af4b":"code","cdda3b13":"code","b88be233":"code","dd46b254":"code","c0dc3333":"code","1e274bcd":"code","2ceb74c2":"markdown","89f3e10c":"markdown","d31b9b88":"markdown","4828a25d":"markdown","fbb727bd":"markdown","2269f02d":"markdown","df235084":"markdown","cf6a2f2a":"markdown","a765120e":"markdown","67a3f1b4":"markdown","5b6d47b5":"markdown"},"source":{"72e5b0d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e92d4945":"zoo_data = pd.read_csv('..\/input\/zoo.csv')\nclass_data = pd.read_csv('..\/input\/class.csv')","bcd63b5e":"zoo_data.head()","d78bda2e":"zoo_data.info()","1687d3cb":"class_data.head()","65b877d9":"class_data.info()","b27fdbcb":"classes = dict(zip(class_data.Class_Number, class_data.Class_Type))","6f40bfe1":"features = np.array(zoo_data.iloc[:,1:-1])\nlabels = np.array(zoo_data.iloc[:, -1])\n\nlabels = tf.one_hot(labels, depth = len(classes))\nwith tf.Session() as sess:\n    labels = labels.eval(session = sess)\n    \nprint(features.shape)\nprint(labels.shape)","b0dcdfc1":"from sklearn.model_selection import train_test_split\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)","538335f4":"def create_placeholders(n_x, n_y):\n    X = tf.placeholder(tf.float32, (n_x, None), name = 'X')\n    Y = tf.placeholder(tf.float32, (n_y, None), name = 'Y')\n    \n    return X, Y","62618875":"def initialize_weights(layer_dims):\n    seed = 42\n    \n    L = len(layer_dims)\n    parameters = {}\n    for l in range(1, L):\n        parameters['W' + str(l)] = tf.get_variable('W' + str(l), shape = (layer_dims[l], layer_dims[l - 1]), dtype = tf.float32, initializer = tf.contrib.layers.xavier_initializer(seed))\n        parameters['b' + str(l)] = tf.get_variable('b' + str(l), shape = (layer_dims[l], 1), dtype = tf.float32, initializer = tf.zeros_initializer())\n    return parameters","74cd92e8":"def forward_propagation(X, parameters):\n    L = len(parameters) \/\/ 2\n    A = X    \n    for l in range(1, L):\n        Z = tf.matmul(parameters['W' + str(l)], A) + parameters['b' + str(l)]\n        A = tf.nn.relu(Z)\n    \n    Z = tf.matmul(parameters['W' + str(L)], A) + parameters['b' + str(L)]\n    return Z","c678af4b":"def compute_cost(Y_PRED, Y):\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = tf.transpose(Y_PRED), labels = tf.transpose(Y)))\n    return cost","cdda3b13":"def build_optimizer(learning_rate, cost):\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n    return optimizer","b88be233":"def build_model(train_data, test_data, layer_dims, learning_rate = 0.01, epoch = 50, batch_size = 32, print_cost = True):\n    tf.reset_default_graph()\n    \n    (n_x, m) = train_data['data'].T.shape\n    n_y = train_data['labels'].T.shape[0]\n      \n    costs = []\n    \n    X, Y = create_placeholders(n_x, n_y)\n    parameters = initialize_weights(layer_dims)\n    Y_PRED = forward_propagation(X, parameters)\n    cost = compute_cost(Y_PRED, Y)\n    optimizer = build_optimizer(learning_rate, cost)\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n        \n        for epoch in range(epochs):\n            epoch_cost = 0.\n            num_batches = m \/\/ batch_size\n            \n            for i in range(num_batches):\n                offset = (i * batch_size) % (train_data['labels'].shape[0] - batch_size)\n                batch_X = train_data['data'][offset:(offset + batch_size), :]\n                batch_Y = train_data['labels'][offset:(offset + batch_size), :]\n                _, batch_cost = sess.run([optimizer, cost], feed_dict = {X:batch_X.T, Y:batch_Y.T})\n                epoch_cost += batch_cost \/ num_batches\n            \n            if m % batch_size != 0:\n                batch_X = train_data['data'][num_batches * batch_size:m, :]\n                batch_Y = train_data['labels'][num_batches * batch_size:m, :]\n                _, batch_cost = sess.run([optimizer, cost], feed_dict = {X:batch_X.T, Y:batch_Y.T})\n                epoch_cost += batch_cost \/ num_batches\n                \n            if epoch % 50 == 0 and print_cost == True:\n                print('Cost after epoch {}: {}'.format(epoch, epoch_cost))\n            \n            if print_cost == True:\n                costs.append(epoch_cost)\n                \n        plt.figure(figsize = (16,5))\n        plt.plot(np.squeeze(costs), c = 'b')\n        plt.xlim(0, epochs - 1)\n        plt.ylabel('cost')\n        plt.xlabel('epochs')\n        plt.title('Learning Rate: {}'.format(learning_rate))\n        plt.show()\n        \n        parameters = sess.run(parameters)\n        print('Parameters have been trained')\n        \n        predictions = {'classes': tf.argmax(Y_PRED, axis = 0).eval(feed_dict = {X:test_data['data'].T, Y:test_data['labels'].T}),\n                       'probabilities': tf.nn.softmax(Y_PRED).eval(feed_dict = {X:test_data['data'].T, Y:test_data['labels'].T})}\n        \n        correct_preds = tf.equal(tf.argmax(Y_PRED), tf.argmax(Y))\n        accuracy = tf.reduce_mean(tf.cast(correct_preds, 'float'))\n        \n        print('Train Accuracy: ', accuracy.eval({X:train_data['data'].T, Y:train_data['labels'].T}))\n        print('Test Accuracy: ', accuracy.eval({X:test_data['data'].T, Y:test_data['labels'].T}))\n        \n    return parameters, predictions","dd46b254":"train_data = {'data':train_features, 'labels':train_labels}\ntest_data = {'data':test_features, 'labels':test_labels}\nlayer_dims = [train_data['data'].shape[1], 8, len(classes)]\nlearning_rate = 0.001\nepochs = 500\nbatch_size = 8\n\nparameters, predictions = build_model(train_data, test_data, layer_dims, learning_rate, epochs, batch_size)","c0dc3333":"import itertools\n\ndef plot_confusion_matrix(cm, target_names, title = 'Confusion Matrix', cmap = None, normalize = True):\n    accuracy = np.trace(cm)\/ float(np.sum(cm))\n    misclass = 1 - accuracy\n    \n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n        \n    plt.figure(figsize = (8,6))\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation = 45)\n        plt.yticks(tick_marks, target_names)\n        \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis = 1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]), horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh else 'black')\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i,j]), horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh else 'black')\n            \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label\\naccuracy={:0.4f}; misclass = {:0.4f}'.format(accuracy, misclass))\n    \n    plt.show()","1e274bcd":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(np.argmax(test_data['labels'], axis = 1), predictions['classes'])\nplot_confusion_matrix(cm, normalize = False, target_names = classes.values())","2ceb74c2":"**Define cost function**","89f3e10c":"**Inspect our zoo data**","d31b9b88":"**Define optimizer function**","4828a25d":"**Define forward propagation**","fbb727bd":"**Create a dictionary mapping class number to class type**","2269f02d":"**Split our train\/dev sets**","df235084":"**Initialize our weights**","cf6a2f2a":"**Build model**","a765120e":"**Create our placeholders**","67a3f1b4":"**Gather our features and labels**","5b6d47b5":"**Inspect our class data**"}}