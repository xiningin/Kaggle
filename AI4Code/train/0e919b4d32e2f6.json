{"cell_type":{"0b955ad7":"code","4ef20f0c":"code","bb93ae63":"code","ac83d642":"code","0ebbd60c":"code","6b847349":"code","4933876b":"code","1786b652":"code","3be0eb0c":"code","3f438828":"code","6cb38173":"code","ba5cbddb":"code","79603cd3":"code","fb521b46":"code","8aba838f":"code","22a1c005":"code","e8071894":"code","3f5b2732":"code","46955ebc":"code","5651c644":"code","fd9d83f9":"code","0560da67":"code","e1fdab88":"code","e6d78abb":"code","a126a6b2":"code","9ce82779":"code","c641fe14":"code","03122779":"code","1a5d5c4d":"code","d8d045a5":"code","ea8ad2ae":"code","765097a8":"code","b9ac6354":"markdown","43f0647c":"markdown","1cc0d5ea":"markdown","be847bd8":"markdown","9cc34501":"markdown","07d83fdc":"markdown","978f0102":"markdown","9b82a5ea":"markdown","3305391b":"markdown"},"source":{"0b955ad7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ef20f0c":"pip install scikit-learn-extra","bb93ae63":"df=pd.read_csv('\/kaggle\/input\/wine-dataset-for-clustering\/wine-clustering.csv')","ac83d642":"df.head(10)","0ebbd60c":"import matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn_extra.cluster import KMedoids\n\nfrom sklearn.metrics import silhouette_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","6b847349":"df.info()","4933876b":"df.nunique()","1786b652":"df.describe().T","3be0eb0c":"for col in df.columns:\n    print(col)\n    print('Skew :',round(df[col].skew(),2))\n    plt.figure(figsize=(15,4))\n    plt.subplot(1,2,1)\n    df[col].hist(bins=10, grid=False)\n    plt.ylabel('count')\n    plt.subplot(1,2,2)\n    sns.boxplot(x=df[col])\n    plt.show()","3f438828":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, fmt='0.2f')\nplt.show()","6cb38173":"scaler=StandardScaler()\ndf_scaled=pd.DataFrame(scaler.fit_transform(df), columns=df.columns)","ba5cbddb":"df_scaled.head()","79603cd3":"df_scaled_copy = df_scaled.copy(deep=True)","fb521b46":"sse = {} \n\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=1).fit(df_scaled)\n    sse[k] = kmeans.inertia_\n\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()), 'bx-')\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","8aba838f":"kmeans = KMeans(n_clusters=3, max_iter= 1000, random_state=1)\nkmeans.fit(df_scaled)\n \ndf_scaled_copy['Labels'] = kmeans.predict(df_scaled)\ndf['Labels'] = kmeans.predict(df_scaled)","22a1c005":"df.Labels.value_counts()","e8071894":"mean = df.groupby('Labels').mean()\nmedian = df.groupby('Labels').median()\ndf_kmeans = pd.concat([mean, median], axis=0)\ndf_kmeans.index = ['clus_0 Mean', 'clus_1 Mean', 'clus_2 Mean', 'clus_0 Median', 'clus_1 Median', 'clus_2 Median']\ndf_kmeans.T","3f5b2732":"df_scaled_copy.boxplot(by = 'Labels', layout = (3,5),figsize=(20,7))\nplt.show()","46955ebc":"gmm = GaussianMixture(n_components = 3, random_state = 1)\ngmm.fit(df_scaled)\n\ndf_scaled_copy['GmmLabels'] = gmm.predict(df_scaled)\ndf['GmmLabels'] = gmm.predict(df_scaled)","5651c644":"df.GmmLabels.value_counts()","fd9d83f9":"original_features = ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium',\n       'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols',\n       'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline',\n       'Labels']\n\nmean = df.groupby('GmmLabels').mean()\nmedian = df.groupby('GmmLabels').median()\ndf_gmm = pd.concat([mean, median], axis=0)\ndf_gmm.index = ['clus_0 Mean', 'clus_1 Mean', 'clus_2 Mean', 'clus_0 Median', 'clus_1 Median', 'clus_2 Median']\ndf_gmm[original_features].T","0560da67":"features_with_lables = ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium',\n       'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols',\n       'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline',\n       'Labels', 'GmmLabels']\n\ndf_scaled_copy[features_with_lables].boxplot(by = 'GmmLabels', layout = (3,5),figsize=(20,7))\nplt.show()","e1fdab88":"sse = {} \n\nfor k in range(1, 10):\n    kmedo = KMedoids(n_clusters=k, max_iter=1000, random_state=1).fit(df_scaled)\n    sse[k] = kmedo.inertia_\n\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()), 'bx-')\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","e6d78abb":"kmedo = KMedoids(n_clusters = 3, random_state=1)\nkmedo.fit(df_scaled)\n\ndf_scaled_copy['kmedoLabels'] = kmedo.predict(df_scaled)\ndf['kmedoLabels'] = kmedo.predict(df_scaled)","a126a6b2":"df.kmedoLabels.value_counts()","9ce82779":"mean = df.groupby('kmedoLabels').mean()\nmedian = df.groupby('kmedoLabels').median()\ndf_kmedoids = pd.concat([mean, median], axis=0)\ndf_kmedoids.index = ['clus_0 Mean', 'clus_1 Mean', 'clus_2 Mean', 'clus_0 Median', 'clus_1 Median', 'clus_2 Median']\ndf_kmedoids[original_features].T","c641fe14":"features_with_lables = ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium',\n       'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols',\n       'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline',\n       'Labels', 'kmedoLabels']\n\ndf_scaled_copy[features_with_lables].boxplot(by = 'kmedoLabels', layout = (3,5),figsize=(20,7))\nplt.show()","03122779":"comparison = pd.concat([df_kmedoids, df_kmeans], axis=1)[original_features]\ncomparison.T\n# Upperline is KMedoids and Lower line is KMeans","1a5d5c4d":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit(df_scaled)","d8d045a5":"feature = pca.transform(df_scaled)","ea8ad2ae":"plt.figure(figsize=(6, 6))\nplt.scatter(feature[:, 0], feature[:, 1], alpha=0.8, c=list(df.iloc[:, 13]))\nplt.grid()\nplt.title('KMeans')\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.show()","765097a8":"plt.figure(figsize=(6, 6))\nplt.scatter(feature[:, 0], feature[:, 1], alpha=0.8, c=list(df.iloc[:, 15]))\nplt.grid()\nplt.title('KMedoids')\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.show()","b9ac6354":"3)-3 KMedois","43f0647c":"3) Clustering","1cc0d5ea":"2) Visualization","be847bd8":"1) Data Outline","9cc34501":"3)-1 KMeans","07d83fdc":"3)-4 Comparion between KMeans and KMedoids","978f0102":"3)-5 PCA and Mapping of KMeans and KMedoids","9b82a5ea":"3)-2 GaussianMixture","3305391b":"1. Objective of this notebook\n\nThe objective of this notebook is to find new segmentations by using other modeling than kmeans.\n\n2. Approach\n\n1) Data Outlines\n\n2) Visualization\n\n3) Clustering and PCA\n\nFirst, I tried KMmeans. And I also tried GaussianMixture and KMedoids.\n\n3. Insight\n\nI got almost same result from GaussianMixture as KMeans. But I got the different segmentations from KMedoids.\n\n1) In KMeans, I got 65 cluster2s, 63 cluster1s and 51 cluster0s. In KMedoids, I got 73 cluster2s, 54 cluster1s and 51 cluater0s.\n\n2) There are some difference in means and median between KMeans and KMedoids which means I found new segmentation."}}