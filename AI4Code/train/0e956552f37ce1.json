{"cell_type":{"f6166201":"code","061fa21f":"code","b75d79cc":"code","7efcfa5d":"code","f797fc4e":"code","1a0649fc":"code","3e1a890b":"code","4d8c9ecd":"code","7099bf5e":"code","30c118aa":"code","9e37dfc9":"code","66199b7d":"code","d6588d9b":"code","461c6249":"code","eb1c559e":"code","85977f1d":"code","2691e007":"code","b59ef25b":"code","2887ac95":"code","54a0d5af":"code","c2dcd217":"code","0186f7a9":"code","c5de8b89":"code","080bc24d":"code","26489f05":"code","489ee3a5":"code","f321f13a":"code","63cda6c1":"code","99123bef":"code","5c33cd29":"code","a3986f02":"code","8082e6a7":"code","eeb7d975":"code","c42d78e1":"code","5d6db8f8":"code","cb5db559":"code","d39206fd":"code","3bd08ae7":"code","db6b767a":"code","ecea16e6":"code","2c9892c7":"markdown","8929e792":"markdown","9f030823":"markdown","98c413e5":"markdown","48efacec":"markdown"},"source":{"f6166201":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","061fa21f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nwarnings.filterwarnings('ignore')\n%matplotlib inline","b75d79cc":"data=pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndata.head()","7efcfa5d":"print('We have {} rows and {} columns'.format(data.shape[0],data.shape[1]))","f797fc4e":"data.describe()","1a0649fc":"data.info()","3e1a890b":"data.isnull().sum()","4d8c9ecd":"data=data.copy()\ndata.iloc[:,:-1]=data.replace(0,np.NaN)\ndata.head()","7099bf5e":"data.isnull().sum()","30c118aa":"Positives=data[data['Outcome']==1]\nNegatives=data[data['Outcome']==0]","9e37dfc9":"Positives.shape","66199b7d":"Negatives.shape","d6588d9b":"print('The numbet of diabetic is {} humans and number of healthy is {} humans'\n      .format(Positives.shape[0],Negatives.shape[0]))","461c6249":"column=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age']\nfor col in column:\n    Positives[col].fillna(Positives[col].mean(),inplace = True)\nPositives.head()","eb1c559e":"column=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age']\nfor col in column:\n    Negatives[col].fillna(Negatives[col].mean(),inplace = True)\nNegatives.head()","85977f1d":"data=pd.concat([Negatives,Positives])\ndata.sample(5)","2691e007":"plt.figure(figsize=(3,6))\nsns.countplot(data['Outcome'])\nplt.show()","b59ef25b":"plt.figure(figsize=(5,5))\nplt.pie(data['Outcome'].value_counts(),labels=(' negatives', ' positives'),\n        explode = [0.03,0.03],autopct ='%1.1f%%'\n        ,shadow = True, startangle = 270,\n        labeldistance = 1.2, pctdistance =0.5)\nplt.axis('equal')\nplt.show()\n","2887ac95":"ndata = data.hist(figsize = (12,12))","54a0d5af":"sns.pairplot(data=data)","c2dcd217":"p=sns.pairplot(data, hue = 'Outcome')","0186f7a9":"plt.figure(figsize=(9,5))\nsns.heatmap(data.corr().sort_values(by=['Outcome'], ascending=False),annot=True)","c5de8b89":"sns.distplot(data['Glucose'])","080bc24d":"sns.distplot(data['Insulin'])","26489f05":"sns.distplot(data['BMI'])","489ee3a5":"sns.distplot(data['SkinThickness'])","f321f13a":"sns.regplot(x='Glucose', y= 'Insulin' ,data=data)","63cda6c1":"plt.subplots(figsize=(15,6))\nsns.boxplot(x='Age', y='Glucose', data=data)","99123bef":"sns.kdeplot(data['Age'],data['BloodPressure'],shade=True,cmap=\"Reds\", shade_lowest=False)","5c33cd29":"plt.figure(figsize=(8,7))\nsns.boxenplot(y=data[\"Glucose\"])\nplt.show()","a3986f02":"plt.figure(figsize=(19,6))\nsns.pointplot(data['Glucose'], data['Insulin'])\nplt.show()","8082e6a7":"X=data.iloc[:,:-1]\ny=data.iloc[:,-1]","eeb7d975":"scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)","c42d78e1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)","5d6db8f8":"GBRModel = GradientBoostingRegressor(n_estimators=100,max_depth=2,learning_rate = 1.5 ,random_state=33)\nGBRModel.fit(X_train, y_train)\nprint('GBRModel Train Score is : ' , GBRModel.score(X_train, y_train))\nprint('GBRModel Test Score is : ' , GBRModel.score(X_test, y_test))\ny_pred = GBRModel.predict(X_test)","cb5db559":"SVRModel = SVR(C = 1.0 ,epsilon=0.1,kernel = 'rbf') # it also can be : linear, poly, rbf, sigmoid, precomputed\nSVRModel.fit(X_train, y_train)\nprint('SVRModel Train Score is : ' , SVRModel.score(X_train, y_train))\nprint('SVRModel Test Score is : ' , SVRModel.score(X_test, y_test))\ny_pred = SVRModel.predict(X_test)","d39206fd":"DecisionTree = DecisionTreeRegressor( max_depth=3,random_state=33)\nDecisionTree.fit(X_train, y_train)\nprint('DecisionTreeRegressor Train Score is : ' , DecisionTree.score(X_train, y_train))\nprint('DecisionTreeRegressor Test Score is : ' , DecisionTree.score(X_test, y_test))\ny_pred = DecisionTree.predict(X_test)","3bd08ae7":"mlp = MLPClassifier(hidden_layer_sizes=(1000, 300, 300), solver='adam', shuffle=False, tol = 0.0001)\nmlp.fit(X_train, y_train)\nprint('DecisionTreeRegressor Train Score is : ' , mlp.score(X_train, y_train))\nprint('DecisionTreeRegressor Test Score is : ' , mlp.score(X_test, y_test))\ny_pred = mlp.predict(X_test)","db6b767a":"accuracies = {'Model': ['GBRModel', 'SVRModel', 'DecisionTree',  'MLP'],\n     'accuracy' : [GBRModel.score(X_test, y_test), SVRModel.score(X_test, y_test), DecisionTree.score(X_test, y_test),  mlp.score(X_test, y_test)]}\n\nresult = pd.DataFrame(data = accuracies)\nresult","ecea16e6":"result.plot(x='Model', y='accuracy', kind='bar', figsize=(8, 8), title='Diabetes Prediction Accuracy', \n               sort_columns=True)","2c9892c7":"As we see (Glucode,Insulin,BMI and SkinThickness) ,are most correaltion to the \"Ootcome","8929e792":"1. Alot of columns -except Outmome columns- has \"0\" value,which are incorrect data,because it impossibe to be the {Glucose,BloodPressure,SkinThickness,Insulin ,BMI,DiabetesPedigreeFunction and Age} to be 0.So it is possible that these values have been changed or filled with these values manually. We will change zero cells to be empty values.\nOutcome column has real value which are {0,1},so it will not changed\n  ","9f030823":"Now ,after filling the missing values for every part,we concat the two parts ,to be one part,as we get the data set ","98c413e5":"We will fill the missed values with (mean) for every column,but we will divide each column into two parts.The first part for (negative cases) and the other part for the (positive cases), and get the (mean) for every part alone.","48efacec":"As seen above ,after change zeros,we have got the true number of miessed values"}}