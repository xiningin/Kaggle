{"cell_type":{"5d2c6ba1":"code","d1320984":"code","7fabdb53":"code","0a8c2979":"code","58c622ad":"code","c10cda86":"code","79c06446":"code","762afd93":"code","f183cd51":"code","5c018c9d":"code","25d24211":"code","d9062cf2":"code","289ebd2d":"code","8b6ab35e":"code","9a45903b":"code","1232023a":"code","7d2c92d2":"code","2ae6a0c6":"code","5962eac8":"markdown","8e9c34aa":"markdown","e55530c1":"markdown","57baf4df":"markdown","215ddeb3":"markdown","e658432d":"markdown","34d7dcea":"markdown"},"source":{"5d2c6ba1":"import pandas as pd\nimport glob\nimport os\nimport tqdm.notebook as tqdm\nimport json\nimport numpy as np","d1320984":"# Need to have 2 col, filename and label, eg: \"fsjdfal.mp4\", \"0.5678\"\n# Checks total length, matching filenames, in sorted order and predictions in 0-1 range.\ndef checkSubmittable(data, bChange = True):\n    if bChange == False:\n        data_orig = data.copy()\n    nReturn = 0\n    test_dir = \"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\"\n    test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n    nVids = len(test_videos)\n    nPredVids = len(data['filename'])\n    if (nVids != nPredVids):\n        print(\"ERROR - Dataframe Size mismatch\")\n        data = data.iloc[0:0] # erase df\n        data['filename'] = test_videos\n        data['label'] = 0.3 # If in LB score will be obvious\n        nReturn = -1\n    for i in range(nVids):\n        strFn = data.at[i,'filename']\n        fPred = data.at[i,'label']\n        if (strFn != test_videos[i] ):\n            print(\"Filename mismatch, either not ordered or not matching expected!\")\n            data['filename'] = test_videos\n            data['label'] = 0.1 # If in LB score will be obvious\n            nReturn = -1\n        if (fPred < 0.0 ) or (fPred > 1.0):\n            print(\"Prediction value out of range!\")\n            data['filename'] = test_videos\n            data['label'] = 0.2 # If in LB score will be obvious\n            nReturn = -1\n    if nReturn < 0:\n        print(\"************************************************************\")\n        print(\"********** SUMBIT ERROR - Pred = .1 .2 .3 ******************\")\n        print(\"************************************************************\")\n    else:\n        print(\"Pred. Data looks OK, Files = \", nVids)\n        \n    if bChange == False:\n        return data_orig   \n    \n    return data.reset_index(drop=True)\n","7fabdb53":"filenames_train = glob.glob('\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/*.mp4')","0a8c2979":"labels = json.load(open('\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/metadata.json', encoding=\"utf8\"))\n\nlabels = pd.DataFrame(labels).transpose()\nlabels = labels.reset_index()","58c622ad":"dictFake = { 'REAL':0, 'FAKE':1}","c10cda86":"\nlabels['bFake'] = 0\nnCnt = 0\nfor sub in labels['label']:\n    labels.at[nCnt,'bFake'] = int(dictFake[sub])\n    nCnt += 1\n\nlabels.head()","79c06446":"labels.label.value_counts()","762afd93":"\ntest_dir = \"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\"\nfilenames = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"]) # np.zeros((5,), dtype=int)\nfilenames_full = filenames.copy()\nfor i in range(len(filenames_full)):\n    filenames_full[i] = os.path.join(test_dir, filenames_full[i] )\npredictions = np.zeros(len(filenames,),dtype=float)","f183cd51":"\nsubmission_df = pd.DataFrame({\"filename\": filenames, \"label\": predictions})\n\nsubmission_df.label = 0.48\n\nsubmission_df.shape","5c018c9d":"def isVideoFake(filename):\n    return False","25d24211":"# filenames_train\n# labels is the training dataframe data\nnCount1=0\n#labels['bFake']\nfor filename in tqdm.tqdm(filenames_train): ## train data\n    \n    fn = filename.split('\/')[-1]\n    if (nCount1 < 999999):\n        bFakeVideo = isVideoFake(filename)\n    else:\n        bFakeVideo = False\n    \n    if bFakeVideo == True:\n        labels.loc[labels['index']==fn, 'label'] = 0.80\n    else:\n        labels.loc[labels['index']==fn, 'label'] = 0.48\n\n    nCount1 += 1","d9062cf2":"#labels.head(50)\nprint(labels[0:10])","289ebd2d":"nCount=0\n## run Test Here\nfor filename in tqdm.tqdm(filenames_full):\n    \n    fn2 = filename.split('\/')[-1]\n    if (nCount < 999999):\n        bFakeVideo = isVideoFake(filename)\n    else:\n        bFakeVideo = False\n    \n    if bFakeVideo == True:\n        submission_df.at[nCount, 'label'] = 0.80\n        print(\"file Fake = \", fn)\n    else:\n        submission_df.at[nCount, 'label'] = 0.48       \n\n    nCount += 1","8b6ab35e":"submission_df.label.value_counts()","9a45903b":"sub = checkSubmittable(submission_df, bChange=True)","1232023a":"sub.to_csv('submission.csv', index=False)","7d2c92d2":"print(sub)","2ae6a0c6":"print(\"DONE\")","5962eac8":"# Make predictions","8e9c34aa":"# Format for Submission","e55530c1":"# Print to verify it looks good","57baf4df":"# Simple function to test if Dataframe is ready for submission\n\nI trimmed down a full run to just be an outline of a run, but mostly to show the function that test submissions, there are some other helpful items here too.\n\n## After a failed Leader Board submission due to a simple error, I decided I needed a function to let me know if I was about to waste a submission with a dataframe with an easy error.\n\n## So I wrote the function below for myself, but hopefully it will help you too.  Give an upvote if you like it.\n\n- Mark","215ddeb3":"# Check if submittable before exporting to file","e658432d":"# TEST CODE","34d7dcea":"# Function that should catch most submit errors and let you know.\n- if bChange is True for a Submit for Leader Board, it will show a fixed score if the database is not ready for submission (it will waste a submission, but may identify the issue for you.)  The score should be over 8, something like 9 for 0.3,10 for 0.2,12 for 0.1 for each error condition, I haven't done the math, so may be higher.  This should flag you for which type of error you have even if you don't get a print.  "}}