{"cell_type":{"b2f8c21f":"code","ec560611":"code","a2eb9b69":"code","6ea03b56":"code","4b4e4fbe":"code","c5b9c397":"code","2a10a158":"code","2238bd2d":"code","e8141f17":"code","6d00ea69":"code","9fda8dc3":"code","91bba2cd":"code","54884884":"code","abf21d08":"code","95769506":"code","ba0083de":"code","4f8f3bf1":"code","f9ed4dfe":"markdown","bdc4c7a1":"markdown","a73721e0":"markdown","b9aa0271":"markdown","ee454c10":"markdown","eef6aa5e":"markdown","13de9f88":"markdown","407e8ccb":"markdown","df9f2ef1":"markdown","1e74149c":"markdown"},"source":{"b2f8c21f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ec560611":"filename = '\/kaggle\/input\/paysim1\/PS_20174392719_1491204439457_log.csv'\ndata = pd.read_csv(filename)\ndata.head()","a2eb9b69":"data.dtypes","6ea03b56":"data.isnull().sum()","4b4e4fbe":"data.size","c5b9c397":"perFraud = (data[data['isFraud']==1].size\/data.size)*100\nprint(perFraud)","2a10a158":"data.columns","2238bd2d":"predictors = ['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', \n              'newbalanceDest', 'isFlaggedFraud']\n\nXX = data[predictors]\nX = pd.get_dummies(XX)  # one-hot-encoding\nX.describe()","e8141f17":"y = data.isFraud","6d00ea69":"train_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)","9fda8dc3":"clf = DecisionTreeClassifier()\nclf.fit(train_X, train_y)","91bba2cd":"pred_y = clf.predict(test_X)","54884884":"print(confusion_matrix(test_y, pred_y))\nprint(classification_report(test_y, pred_y))","abf21d08":"sc = StandardScaler()\ntrain_X = sc.fit_transform(train_X)\ntest_X = sc.transform(test_X)","95769506":"clf = RandomForestClassifier(n_estimators=20, random_state=0)\nclf.fit(train_X, train_y)","ba0083de":"pred_y = clf.predict(test_X)","4f8f3bf1":"print(confusion_matrix(test_y,pred_y))\nprint(classification_report(test_y,pred_y))\nprint(accuracy_score(test_y,pred_y))","f9ed4dfe":"There are 11 columns. Column 'isFraud' is our target column. Let us check data types of each column.","bdc4c7a1":"Let's try scaling the predictors with Random Forest Classifier.","a73721e0":"Only 0.13% of transactions are fraudulant. It is a highly imbalanced dataset. Hence, we have to be careful in reporting our results and accuracy might not be a good parameter to report for this classification problem. We will look at precision and recall.\n\nAlso, to improve results we might have to apply pre-processing techniques of undersampling the non-fraudulant transactions or oversampling of fradulant transactions while train-test split.\n\nLet us first try a straight forward Decision Tree Classifier.","b9aa0271":"Between the two implemented models, for random forest we see that our recall decreases by 9% from the decision tree results i.e. we missed out on more fraudulant transactions. This is not good! \n\nLet's try to increase our recall by using over-sampling or under-sampling.","ee454c10":"Almost 70M rows! A big dataset! Let's check if it's balanced or not. Meaning, check what percentage of transactions are fraudulant.","eef6aa5e":"Let's check if there are any null values in the dataset.","13de9f88":"No null values found! A rare dataset! Let's check size of the dataset.","407e8ccb":"Load data into a dataframe and have a look at the data.","df9f2ef1":"In this notebook, I am looking at synthetically generated financial fraud data. I want to develop a technique which is able to detect fraud transactions. I plan to achieve this by testing various machine learning models on this data. \n\nLet's start!","1e74149c":"There are three columns with data type 'object'. Let's convert them to 'string'."}}