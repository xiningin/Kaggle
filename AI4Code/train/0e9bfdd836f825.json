{"cell_type":{"d4ba8b21":"code","ecb0e0b1":"code","43d6fd2b":"code","c06efcb8":"code","d7d14d11":"code","398792bf":"code","08382ebe":"code","d404df6d":"code","01318a76":"code","b2d54de2":"code","6743e7ac":"code","8a4d9e65":"code","858cff33":"code","1833c9fc":"code","5a9d20d5":"code","7ad5d565":"code","8310dea0":"code","cce8e82c":"code","2d5e08cb":"code","7e14660d":"code","9575c2f2":"code","caeb6816":"code","8e482d04":"code","399c3871":"code","1fae9b22":"code","fccd4e91":"code","dfcfe5f5":"code","ce35cbd4":"code","e2c2c9d9":"code","f5224a87":"code","887a318d":"code","49a869dd":"code","b38f2de8":"code","b2939aa0":"code","73cecc1b":"code","c25705c2":"code","5815c751":"code","bf734e40":"code","0d9a990b":"code","cae650e8":"code","c090a2da":"code","e3063e27":"code","b537898b":"code","0314b00c":"code","b37b6a2a":"code","e095727d":"code","b2797d5a":"code","dc1d56d0":"code","f296d80e":"code","b8e482d3":"code","289af2a4":"code","d8010ebc":"code","b794739f":"code","3941ae1c":"markdown","e8ad2a0c":"markdown","acf69623":"markdown","f477f020":"markdown","d1fdcd8d":"markdown","f04c9c3d":"markdown","9c4e0a07":"markdown","66bf77ed":"markdown","f52f3c40":"markdown","de971d3c":"markdown","66d042ab":"markdown","6b80a38d":"markdown","0b76e30f":"markdown","debfc833":"markdown","a71beeaa":"markdown","b7deffdc":"markdown","57c44b80":"markdown","6c498ec8":"markdown","08ec315d":"markdown","1a9e062b":"markdown","70766b0a":"markdown","32c03b2b":"markdown","0dcc495f":"markdown","bb8654b7":"markdown","fe712f4f":"markdown","663c1093":"markdown","81e15c89":"markdown","89ccca64":"markdown","6caa778b":"markdown","c8c531e9":"markdown","09a991b6":"markdown","052e8c5b":"markdown","36c7bc25":"markdown","a91a2336":"markdown","448729df":"markdown","84f33b6d":"markdown","888b556c":"markdown","494c1e37":"markdown","15e826e3":"markdown","83a4d233":"markdown","5820af75":"markdown","70f0e4b4":"markdown","0fc0709e":"markdown","badf8084":"markdown","2d551fca":"markdown","7cfe7f63":"markdown"},"source":{"d4ba8b21":"# Data manipulation libraries\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# Avoid Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","ecb0e0b1":"df = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","43d6fd2b":"print(df.shape)\ndf.head()","c06efcb8":"df.drop(['id'],axis=1,inplace=True)","d7d14d11":"#count of missing data\nmissing_values_count = df.isna().sum()\n\n#find the percentage of missing data\ntotal_cells = np.product(df.shape)\ntotal_missing = missing_values_count.sum()\npercent_missing = (total_missing \/ total_cells) * 100\nprint(\"Percentage of missing data from the dataset is : {}%\".format(percent_missing))","398792bf":"plt.figure(figsize = (12,6))\nsns.heatmap(df.isnull())\nplt.show()","08382ebe":"df['bmi'].fillna(df['bmi'].mean(), inplace=True)","d404df6d":"df.info()","01318a76":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\",\"stroke\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]","b2d54de2":"fig,axes = plt.subplots(4,2,figsize = (16,16))\nsns.set_style('darkgrid')\nfig.suptitle(\"Count plot for various categorical features\")\n\nsns.countplot(ax=axes[0,0],data=df,x='gender')\nsns.countplot(ax=axes[0,1],data=df,x='hypertension')\nsns.countplot(ax=axes[1,0],data=df,x='heart_disease')\nsns.countplot(ax=axes[1,1],data=df,x='ever_married')\nsns.countplot(ax=axes[2,0],data=df,x='work_type')\nsns.countplot(ax=axes[2,1],data=df,x='Residence_type')\nsns.countplot(ax=axes[3,0],data=df,x='smoking_status')\nsns.countplot(ax=axes[3,1],data=df,x='stroke')\n\nplt.show()","6743e7ac":"fig = px.box(data_frame = df,\n            x = \"age\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","8a4d9e65":"fig = px.box(data_frame = df,\n            x = \"avg_glucose_level\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","858cff33":"fig = px.box(data_frame = df,\n            x = \"bmi\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","1833c9fc":"age = list(df['age'].values)\n\nhist_data = [age]\ngroup_labels = ['age']\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","5a9d20d5":"avg_glucose_level = list(df['avg_glucose_level'].values)\nhist_data = [avg_glucose_level]\ngroup_labels = ['avg_glucose_level']\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","7ad5d565":"bmi = list(df['bmi'].values)\nhist_data = [bmi]\ngroup_labels = [\"bmi\"]\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","8310dea0":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\",\"stroke\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]","cce8e82c":"cr = df[cont_cols].corr(method='pearson')\nplt.figure(figsize = (6,6))\nsns.heatmap(cr,cmap=\"coolwarm\")\nplt.show()","2d5e08cb":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'age', y = 'avg_glucose_level', hue='stroke')\nplt.show()","7e14660d":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'avg_glucose_level', y = 'bmi', hue='stroke')\nplt.show()","9575c2f2":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'age', y = 'bmi', hue='stroke')\nplt.show()","caeb6816":"plt.figure(figsize=(16,6))\nplt.subplot(1,3,1)\nsns.violinplot(x = 'stroke', y = 'age', data = df)\nplt.subplot(1,3,2)\nsns.violinplot(x = 'stroke', y = 'avg_glucose_level', data = df)\nplt.subplot(1,3,3)\nsns.violinplot(x = 'stroke', y = 'bmi', data = df)\nplt.show()","8e482d04":"plt.figure(figsize = (16,16))\nsns.pairplot(df,hue='stroke')\nplt.show()","399c3871":"df[\"gender\"].value_counts()","1fae9b22":"df.drop(df[df['gender'] == 'Other'].index, inplace = True)\ndf[\"gender\"].value_counts()","fccd4e91":"print(\"The number of people who don't have stroke : \", df['stroke'].value_counts()[0])\nprint(\"The number of people who don't have stroke : \", df['stroke'].value_counts()[1])\ncond1 = df['avg_glucose_level'] > 170\ncond2 = df['stroke'] == 1\nprint(\"The number of outliers in avg_glucose_level with stroke = 1 are : \", df[cond1 & cond2].shape)\ncond3 = df['bmi'] > 47\ncond4 = df['stroke'] == 1\nprint(\"The number of outliers in bmi with stroke = 1 are : \", df[cond3 & cond4].shape)","dfcfe5f5":"print(\"The shape before removing the BMI outliers : \",df.shape)\ndf.drop(df[df['bmi'] > 47].index, inplace = True)\nprint(\"The shape after removing the BMI outliers : \",df.shape)","ce35cbd4":"plt.figure(figsize = (14,5))\nsns.distplot(x=df['bmi'],color='red')\nplt.show()","e2c2c9d9":"df.dtypes","f5224a87":"# Label Encoding the categorical variables\nfrom sklearn.preprocessing import LabelEncoder\nobject_cols = [\"gender\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"]\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    label_encoder.fit(df[col])\n    df[col] = label_encoder.transform(df[col])","887a318d":"# Using SMOTE\nfrom imblearn.over_sampling import SMOTE\nsampler = SMOTE(random_state = 42)\nX = df.drop(['stroke'],axis=1)\ny = df[['stroke']]\nX,y= sampler.fit_resample(X,y['stroke'].values.ravel())\ny = pd.DataFrame({'stroke':y})\nsns.countplot(data = y, x = 'stroke', y= None)\nplt.show()","49a869dd":"# Joining back dataset\ndf = pd.concat([X,y],axis = 1)\ndf.head()","b38f2de8":"# shuffling the dataset before model development\ndf = df.sample(frac = 1)","b2939aa0":"import torch\nimport torch.nn as nn","73cecc1b":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]\ny_col = [\"stroke\"]","c25705c2":"for cat in cat_cols:\n    df[cat] = df[cat].astype('category')","5815c751":"df.dtypes","bf734e40":"# stacking the categorical columns\ncats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\ncats[:5]","0d9a990b":"# converting the stack into tensor\ncats = torch.tensor(cats, dtype = torch.int64)\ncats[:5]","cae650e8":"# stacking the continuous columns & converting to tensor\nconts = np.stack([df[col].values for col in cont_cols], 1)\nconts = torch.tensor(conts, dtype=torch.float)\nconts[:5]","c090a2da":"# converting target variable to tensor and flattening since CrossEntropyLoss expects a 1-d tensor\ny = torch.tensor(df[y_col].values).flatten()\ny[:5]","e3063e27":"print(cats.shape)\nprint(conts.shape)\nprint(y.shape)","b537898b":"cat_szs = [len(df[col].cat.categories) for col in cat_cols]\nemb_szs = [(size, min(50, (size+1)\/\/2)) for size in cat_szs]\nemb_szs","0314b00c":"class TabularModel(nn.Module):\n\n    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        \n        layerlist = []\n        n_emb = sum((nf for ni,nf in emb_szs))\n        n_in = n_emb + n_cont\n        \n        for i in layers:\n            layerlist.append(nn.Linear(n_in,i)) \n            layerlist.append(nn.ReLU(inplace=True))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.Dropout(p))\n            n_in = i\n        layerlist.append(nn.Linear(layers[-1],out_sz))\n            \n        self.layers = nn.Sequential(*layerlist)\n    \n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        for i,e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        x = torch.cat(embeddings, 1)\n        x = self.emb_drop(x)\n        \n        x_cont = self.bn_cont(x_cont)\n        x = torch.cat([x, x_cont], 1)\n        x = self.layers(x)\n        return x","b37b6a2a":"torch.manual_seed(42)\nmodel = TabularModel(emb_szs, conts.shape[1], 2, [400,200,100], p=0.2)\nmodel","e095727d":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","b2797d5a":"batch_size = 9000\ntest_size = 492\n\ncat_train = cats[:batch_size-test_size]\ncat_test = cats[batch_size-test_size:batch_size]\ncon_train = conts[:batch_size-test_size]\ncon_test = conts[batch_size-test_size:batch_size]\ny_train = y[:batch_size-test_size]\ny_test = y[batch_size-test_size:batch_size]","dc1d56d0":"print(len(cat_train))\nprint(len(cat_test))","f296d80e":"import time\nstart_time = time.time()\n\nepochs = 320\nlosses = []\n\nfor i in range(epochs):\n    i+=1\n    y_pred = model(cat_train, con_train)\n    loss = criterion(y_pred, y_train)\n    losses.append(loss)\n    \n    if i%25 == 1:\n        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\nprint(f'epoch: {i:3}  loss: {loss.item():10.8f}') \nprint(f'\\nDuration: {time.time() - start_time:.0f} seconds') ","b8e482d3":"plt.plot(range(epochs), losses)\nplt.ylabel('Cross Entropy Loss')\nplt.xlabel('epoch');","289af2a4":"# TO EVALUATE THE ENTIRE TEST SET\nwith torch.no_grad():\n    y_val = model(cat_test, con_test)\n    loss = criterion(y_val, y_test)\nprint(f'CE Loss: {loss:.8f}')","d8010ebc":"rows = 200\ncorrect = 0\ngroundTruth = []\npredictedValues = []\nprint(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\nfor i in range(rows):\n    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n    predictedValues.append(y_val[i].argmax().item())\n    groundTruth.append(y_test[i])\n    if y_val[i].argmax().item() == y_test[i]:\n        correct += 1\nprint(f'\\n{correct} out of {rows} = {100*correct\/rows:.2f}% correct')","b794739f":"from sklearn.metrics import f1_score\nprint(\"The F1-score is :\", f1_score(groundTruth, predictedValues))","3941ae1c":"**Making different arrays for categorical and continuous features**","e8ad2a0c":"**The feature list and the target variable:**\n\n1. id: unique identifier\n2. gender: \"Male\", \"Female\" or \"Other\"\n3. age: age of the patient\n4. hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n5. heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n6. ever_married: \"No\" or \"Yes\"\n7. work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n8. Residence_type: \"Rural\" or \"Urban\"\n9. avg_glucose_level: average glucose level in blood\n10. bmi: body mass index\n11. smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n12. stroke: 1 if the patient had a stroke or 0 if not\n\nNote: \"Unknown\" in smoking_status means that the information is unavailable for this patient","acf69623":"### Scatter plot for *age vs bmi* with a *Stroke* hue <a id=\"15\"><\/a>","f477f020":"### Box Plot of *bmi* <a id=\"7\"><\/a>","d1fdcd8d":"### Distribution Plot of *age* <a id=\"8\"><\/a>","f04c9c3d":"### Distribution Plot of *bmi* <a id=\"10\"><\/a>","9c4e0a07":"### Violin plot for continuous features <a id=\"16\"><\/a>","66bf77ed":"### Correlation plot of Continuous features <a id=\"12\"><\/a>","f52f3c40":"### Defining loss function and optimizer <a id=\"30\"><\/a>","de971d3c":"# 1. Imports <a id=\"1\"><\/a>","66d042ab":"**Conclusions from EDA**\n\n- Gender feature has some very less number of *Other* gender so it can be removed.\n- There are a lot of outliers in *avg_glucose_level* and *bmi*\n- The outliers make the distribution curve of both the features highly skewed towards right\n- Either the outliers can be removed or the distribution curve can be made less-skewed by mapping the values with a log but both cases will lead to loss of the number of datapoints with *Stroke = 1*\n- *avg_glucose_level* increases with *age* and similarly leads to more chances of stroke\n- The stroke class is highly imbalanced which has to be taken of","6b80a38d":"**The notebook consists of**\n\n1. [Importing libraries](#1)\n2. [Checking for missing data](#2)\n3. [Univariate Analysis](#3)\n    - [Count plot for categorical variables](#4)\n    - [Box plot of age](#5)\n    - [Box plot of avg_glucose_level](#6)\n    - [Box plot of bmi](#7)\n    - [Distribution plot of age](#8)\n    - [Distribution plot of avg_glucose_level](#9)\n    - [Distribution plot of bmi](#10)\n4. [Bivariate Analysis](#11)\n    - [Correlation plot for continuous features](#12)\n    - [Scatter plot for age vs avg_glucose_level with a Stroke hue](#13)\n    - [Scatter plot for avg_glucose_level vs bmi with a Stroke hue](#14)\n    - [Scatter plot for age vs bmi with a Stroke hue](#15)\n    - [Violin plot for continuous features](#16)\n    - [Pairplot of the dataset](#17)\n5. [Data Preprocessing](#18)\n    - [Removing the other from gender](#19)\n    - [Checking the effect of outliers](#20)\n    - [Removing the outliers](#21)\n    - [Re-checking the distributions](#22)\n    - [Handling data imbalance](#23)\n6. [PyTorch Model Development](#24)\n    - [Separate categorical from continuous](#25)\n    - [Categorigy](#26)\n    - [Stacking the columns for embeddings](#27)\n    - [Setting an embedding size](#28)\n    - [Defining the model](#29)\n    - [Defining loss and optimizer](#30)\n    - [Perform train\/test split](#31)\n    - [Training the model](#32)\n    - [Plotting the loss function](#33)\n    - [Model Validation](#34)","0b76e30f":"### Count Plot of Categorical features <a id=\"4\"><\/a>","debfc833":"### Distribution Plot of *avg_glucose_level* <a id=\"9\"><\/a>","a71beeaa":"**This is the F1-score for the first 200 values of the testing set.**","b7deffdc":"### If you like the notebook, consider giving an upvote.\nCheck out my other notebooks\n\n1. https:\/\/www.kaggle.com\/namanmanchanda\/heart-attack-eda-prediction-90-accuracy\n2. https:\/\/www.kaggle.com\/namanmanchanda\/asl-detection-99-accuracy\n3. https:\/\/www.kaggle.com\/namanmanchanda\/pytorch-101\n4. https:\/\/www.kaggle.com\/namanmanchanda\/pima-indian-diabetes-eda-and-prediction\n5. https:\/\/www.kaggle.com\/namanmanchanda\/rnn-in-pytorch","57c44b80":"### Scatter plot for *avg_glucose_level vs bmi* with a *Stroke* hue <a id=\"14\"><\/a>","6c498ec8":"**Just re-writing the arrays again**","08ec315d":"### Checking the distribution of *bmi* again which should have been made less skewed now <a id=\"22\"><\/a>","1a9e062b":"### Setting an embedding size <a id=\"28\"><\/a>","70766b0a":"### Categorify <a id=\"26\"><\/a>","32c03b2b":"**Filling the missing data in *bmi* column with mean**","0dcc495f":"<h1 align=\"center\">Stroke - EDA and ANN Prediction<\/h1>","bb8654b7":"### Stacking the columns for the embeddings <a id=\"27\"><\/a>","fe712f4f":"# 5. Data preprocessing <a id=\"18\"><\/a>","663c1093":"### Removing the other from *gender* <a id=\"19\"><\/a>","81e15c89":"### Model Validation <a id=\"34\"><\/a>","89ccca64":"### Seperate categorical from continuous <a id=\"25\"><\/a>","6caa778b":"### Scatter plot for *age vs avg_glucose_level* with a *Stroke* hue <a id=\"13\"><\/a>","c8c531e9":"# 2. Checking for missing data <a id=\"2\"><\/a>","09a991b6":"### Scatter-matrix of the dataset <a id=\"17\"><\/a>","052e8c5b":"### Plotting the loss function <a id=\"33\"><\/a>","36c7bc25":"### Box Plot of *age* <a id=\"5\"><\/a>","a91a2336":"### Performing train\/test split <a id=\"31\"><\/a>","448729df":"**Dropping the *id* column as it's just an identifier**","84f33b6d":"### Defining the tabular model <a id=\"29\"><\/a>","888b556c":"# 6. PyTorch Model Development <a id=\"24\"><\/a>","494c1e37":"### Checking the effect of outliers on the reduction of dataset <a id=\"20\"><\/a>","15e826e3":"### Handling data imbalance <a id=\"23\"><\/a>\n\n**Now since the stroke is highly imbalanced, the 2 ways to deal with it are :**\n- **the majority class can either be undersampled using Tomek Links**\n- **the minority class can be oversampled using SMOTE**\n\n**I'll be using SMOTE for this. For using SMOTE, all the cateogrial variables must be converted into int. I'll be Label Encoding all of them because later I'll make a *PyTorch* model using *Embeddings*, and that's why I won't be One-Hot-Encoding them.**","83a4d233":"# 4. Bivariate analysis <a id=\"11\"><\/a>","5820af75":"**It's quite clear that the data has been completely balanced.**","70f0e4b4":"**Plotting a heatmap to check for missing data features**","0fc0709e":"### Training the model <a id=\"32\"><\/a>","badf8084":"# 3. Univariate analysis <a id=\"3\"><\/a>","2d551fca":"### Box Plot of *avg_glucose_level* <a id=\"6\"><\/a>","7cfe7f63":"**There are 83 outliers in the *avg_glucose_level* which have a *stroke=1* which comprises of a large quantity of data. Removing them will lead to loss of data. I'll rather remove the outliers in *bmi* because the number of outliers with stroke are just 3 which won't effect the dataset much.**\n\n### Removing the outliers in *bmi* <a id=\"21\"><\/a>"}}