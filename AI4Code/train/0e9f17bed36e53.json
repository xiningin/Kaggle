{"cell_type":{"8014fbe9":"code","80dc4158":"code","fc2d27d1":"code","9f20e3b1":"code","c1c537b5":"code","d8dd2cf0":"code","9b447f21":"code","f350afb1":"code","4b679b45":"code","d8a2920f":"code","5889f70c":"code","1b6cb4a9":"code","a56b7b0d":"code","3b2e3ae1":"code","d06c1c89":"code","d3b56496":"code","74134c91":"code","adf7f96b":"markdown","8f2b9c16":"markdown","2eea53be":"markdown","e00e0c10":"markdown","ebeba232":"markdown","9c30b9c9":"markdown","fb0d7b8c":"markdown","00639ba1":"markdown"},"source":{"8014fbe9":"import pandas as pd\nimport seaborn as sns\nimport plotly.express as xp\nimport plotly.graph_objects as go\nimport numpy as np\nfrom datetime import datetime\nimport missingno\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.impute import SimpleImputer\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = ['#00008B',\"#0000FF\",\"#ADD8E6\"]\nsns.palplot(palette)\n\ntrain_data = pd.read_csv(\"..\/input\/mymusicalprefrences\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/mymusicalprefrences\/test.csv\")\ndescription = yaml.load(open(\"..\/input\/mymusicalprefrences\/Description.yaml\",'r'),Loader=yaml.FullLoader)\n\n\n\ndataset = pd.concat([train_data,test_data]).reset_index(drop=True)\n\ntr_mask = ~dataset.Category.isna()\n\ndataset.columns = [i.strip() for i in dataset.columns]\nprint(dataset.size)\ndataset.head()\n\n\n","80dc4158":"#copying the code for splitting to onehot\n\ndef split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded\n\ndef plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=palette[i])))\n    fig.show()","fc2d27d1":"print(dataset['Category'].unique())\n\ndataset[\"Category\"] = dataset[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})\n\ndataset['Category'].unique()\n","9f20e3b1":"def label_fix_category(value):\n    if value=='dislike':\n        return 0\n    elif value=='like':\n        return 1\n    elif value=='none':\n        return 2","c1c537b5":"print(dataset['Version'])\nprint(dataset['Version'].count())\n#only 129 data have some value (!= NaN)\n\n#replacing nan with NA string \ndataset[\"Version\"] = dataset[\"Version\"].fillna(\"NA\")\n\nlabel_encoder = LabelEncoder()\ndataset.Version = label_encoder.fit_transform(dataset.Version)\n\ndataset['Version'].unique()","d8dd2cf0":"dataset['Album_type'].unique()\nprint(dataset['Album_type'].count())\n# 212 data have some value (!= NaN)\n\n#replacing nan with NA string \ndataset[\"Album_type\"] = dataset[\"Album_type\"].fillna(\"NA\")\n\nlabel_encoder = LabelEncoder()\ndataset.Album_type = label_encoder.fit_transform(dataset.Album_type)\n\ndataset['Album_type'].unique()\nprint(dataset['Album_type'].count())\n#now we can use all the samples ","9b447f21":"dataset[list(set(dataset[\"Key\"].values))] = OneHotEncoder().fit_transform(dataset[[\"Key\"]]).toarray()\n#dataset = dataset.drop(\"Key\", axis=1)\nprint(dataset[\"Key\"].unique())\nprint(dataset[\"Key\"].count())\n#all data have some value (!= NaN)\n\nlabel_encoder = LabelEncoder()\ndataset.Key = label_encoder.fit_transform(dataset.Key)\ndataset = dataset.drop(\"Key\", axis=1)\ndataset.columns","f350afb1":"print(dataset['Vocal'].unique())\nprint(dataset['Vocal'].count())\n\n#replacing nan with NA string \ndataset[\"Vocal\"] = dataset[\"Vocal\"].fillna(\"NAN\")\n\nprint(dataset['Vocal'].unique())","4b679b45":"def label_fix_vocal(value):\n    if value=='NAN':\n        return 0\n    elif value=='M':\n        return 1\n    elif value=='F':\n        return 2\n    elif value=='F|M':\n        return 3\n    elif value=='N':\n        return 4","d8a2920f":"\ndataset['Vocal'] = dataset['Vocal'].apply(label_fix_vocal)\ndataset['Vocal'].unique()","5889f70c":"from sklearn.impute import SimpleImputer  # Imputer is for missing values\n\n# Fill in the lines below: imputation\nmy_imputer = SimpleImputer()\ndatasetClean = pd.DataFrame(my_imputer.fit_transform(dataset[['Energy', 'Happiness', 'Dancebility','BPM']]))\n\ndataset[['Energy', 'Happiness', 'Dancebility','BPM']] = dataset[['Energy', 'Happiness', 'Dancebility','BPM']].fillna(0)\n\nprint(dataset['Energy'].count())\nprint(dataset['Happiness'].count())\nprint(dataset['Dancebility'].count())\n#all data are filled\n","1b6cb4a9":"print(dataset.columns)","a56b7b0d":"print(dataset['Artists_Genres'].count())\n#there is no NaN data\n\nartist_genres_onehot = split_to_onehot(dataset, \"Artists_Genres\")\n#print(artist_genres_onehot)\n\nartist_genres_onehot = artist_genres_onehot.drop(\"Category\", axis=1)\n\ndataset = pd.concat([dataset,artist_genres_onehot], axis=1)\ndataset =dataset.drop(\"Artists_Genres\", axis=1)\n\nprint(dataset.columns)","3b2e3ae1":"artists_encoder = LabelEncoder()\ndataset[\"Track\"] = artists_encoder.fit_transform(dataset[\"Track\"])\n\ncountry_encoder = LabelEncoder()\ndataset.Country = dataset.Country.fillna(\"NA\")\n\ndataset[\"Country\"] = country_encoder.fit_transform(dataset[\"Country\"])\n\n#country_onehot = split_to_onehot(dataset, \"Country\")\n\n\nartist_encoder = LabelEncoder()\ndataset.Artists = dataset.Artists.fillna(\"NA\")\n\ndataset[\"Artists\"] = artist_encoder.fit_transform(dataset[\"Artists\"])\n\nalbum_encoder = LabelEncoder()\ndataset.Album = dataset.Album.fillna(\"NA\")\n\ndataset[\"Album\"] = album_encoder.fit_transform(dataset[\"Album\"])\n\nlabel_encoder = LabelEncoder()\ndataset.Labels = dataset.Labels.fillna(\"NA\")\n\ndataset[\"Labels\"] = label_encoder.fit_transform(dataset[\"Labels\"])\n","d06c1c89":"#dataset = dataset.drop(dataset['Category'])\ndataset","d3b56496":"X, y = dataset.loc[tr_mask].iloc[:,2:], dataset.loc[tr_mask,\"Category\"]\ndeploy = dataset.loc[~tr_mask].iloc[:,2:]\n\nfrom sklearn.svm import SVC\n\n\nmodel = SVC()\nsvclassifier = SVC(kernel='sigmoid')\n\n\nsvclassifier.fit(X_train, y_train)\n\n\ny_pred = svclassifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n\n","74134c91":"sample = pd.read_csv(\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = svclassifier.predict(deploy)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample.to_csv(\"deploy.csv\", index=False)\n\n","adf7f96b":"Now I'm trying simplifying the Vocal column and adding some int values insted of string values","8f2b9c16":"**PREPROCESSING**\n\n\nThe method label_fix_category is used to simplify the Category column. \nIn this part the category column is simplified to values 0, 1, 2","2eea53be":"Now I'm trying simplifying the Version column and adding some int values insted of string values","e00e0c10":"Solving Artists Gender column ","ebeba232":"For the key part I decided to take the all possible values from the key column and to create new column for each value. And at the end delete the key value ","9c30b9c9":"Now I'm trying simplifying the Album_type column and adding some int values insted of string values","fb0d7b8c":"Filling the missing values for Energy, Happiness, BPM and Dancebility","00639ba1":"**MODEL SELECTION AND TEST**"}}