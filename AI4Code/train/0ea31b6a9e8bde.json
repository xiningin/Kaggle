{"cell_type":{"600d649d":"code","4f9583ef":"code","11fdf276":"code","8bda5c93":"code","7287a080":"code","2ea89e92":"code","b7bc4a9f":"code","32a6daf5":"code","627bc926":"code","4b3ff5e8":"code","17914e20":"code","1e59b055":"code","ea5c4ab2":"code","78865832":"code","b8261bc1":"code","2f7d1491":"code","24494bfd":"code","edec56c6":"code","0faaf714":"code","8b110c44":"code","71214ff6":"code","1f62fc4a":"code","2a83e1a5":"code","fe8a9325":"code","cd4eb434":"code","9ee48f4b":"code","44153730":"code","6af9b52c":"code","63f96614":"code","62459079":"code","031838dd":"markdown","999c6902":"markdown","5176e111":"markdown","eb34a2a8":"markdown","09f9dc36":"markdown","702b49ee":"markdown","0a38fafd":"markdown","d2e0a280":"markdown","0ab3ec6b":"markdown","3f2d0481":"markdown","8e989836":"markdown","d5704006":"markdown","4819689c":"markdown","fd0b8b3b":"markdown"},"source":{"600d649d":"import os\nimport random\nimport cv2\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nfrom PIL import Image","4f9583ef":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)","11fdf276":"train_images_path = '\/kaggle\/input\/classification-with-limited-data\/food\/train\/images'\ntrain_labels_path = '\/kaggle\/input\/classification-with-limited-data\/food\/train\/train.csv'\ntest_images_path = '\/kaggle\/input\/classification-with-limited-data\/food\/test\/images'\nworking_path = '\/kaggle\/working'\ndf = pd.read_csv(train_labels_path)","8bda5c93":"num_classes = np.unique(df['Expected']).size\nnum_classes","7287a080":"random_file = random.choice(os.listdir(train_images_path))","2ea89e92":"df['global_contrast'] = np.nan\ndf['mean_val'] = np.nan\nfor filename in os.listdir(train_images_path):\n    img = cv2.imread(os.path.join(train_images_path, filename))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    df.loc[df['Id'] == filename, 'global_contrast'] = (np.max(img) - np.min(img)) \/ 255\n    df.loc[df['Id'] == filename, 'mean_val'] = np.mean(img)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.title(\"Global contrast distribution\")\ndf['global_contrast'].plot.kde()\nplt.subplot(1, 2, 2)\nplt.title(\"Mean color value distribution\")\ndf['mean_val'].plot.kde()\nplt.show()","b7bc4a9f":"random_img = cv2.imread(os.path.join(train_images_path, random_file))\nrandom_img = cv2.cvtColor(random_img, cv2.COLOR_BGR2RGB) \n\nclassForImage = df[df['Id'] == random_file]['Expected'].values[0]\n\nprint(\"Image shape:\", random_img.shape)\nprint(\"Minimum color value\", random_img.min())\nprint(\"Maximum color value\", random_img.max())\n\nri_channels = np.empty((random_img.shape[0], random_img.shape[1] * 3))\nfor channel in range(3):\n    ri_channels[:, (random_img.shape[1] * channel):(random_img.shape[1] * (channel+1))] = random_img[:, :, channel] * (channel+1)\n\nhist = np.histogram(ri_channels, bins=255 * 3)[0]\nhist = hist \/ np.sum(hist)\n\nplt.figure()\nplt.title(\"Histogram over color values for random sample\")\nplt.bar(np.arange(255 * 3), hist, color='black')\nplt.axvspan(0, 255, color='red', alpha=.2, zorder=0)\nplt.axvspan(255, 255 * 2, color='green', alpha=.2, zorder=0)\nplt.axvspan(255 * 2, 255 * 3, color='blue', alpha=.2, zorder=0)\nplt.show()","32a6daf5":"plt.figure()\nplt.title(\"Example image with class %d\" % classForImage)\nplt.imshow(random_img)\nplt.show()","627bc926":"# validate, that the examples are equally distributed\nplt.figure()\ndf['Expected'].plot.hist(bins=num_classes)\nplt.show()","4b3ff5e8":"mean_mean = np.mean(df['mean_val'])\nmean_std = np.std(df['mean_val'])\n\nplt.figure()\nplt.title(\"Histogram over image mean values\")\nhist = plt.hist(df['mean_val'], bins=255, density=True, color='black')\nplt.axvline(mean_mean, color='blue', linewidth=2)\nplt.axvline(mean_mean + mean_std, color='green', linewidth=2)\nplt.axvline(mean_mean - mean_std, color='green', linewidth=2)\nplt.show()","17914e20":"hists = []\nfor filename in os.listdir(train_images_path):\n    img = cv2.imread(os.path.join(train_images_path, filename))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    channels = np.empty((img.shape[0], img.shape[1] * 3))\n    for channel in range(3):\n        channels[:, (img.shape[1] * channel):(img.shape[1] * (channel+1))] = img[:, :, channel] * (channel+1)\n    hist = np.histogram(channels, bins=255 * 3)[0]\n    hist = hist \/ np.sum(hist)\n    hists.append(hist)\nhitsts = np.array(hists)\nmean_hist = np.mean(hists, axis=0)\n\nplt.figure()\nplt.title(\"Mean histogram over pixel color values\")\nplt.bar(np.arange(255 * 3), mean_hist, color='black')\nplt.axvspan(0, 255, color='red', alpha=.2, zorder=0)\nplt.axvspan(255, 255 * 2, color='green', alpha=.2, zorder=0)\nplt.axvspan(255 * 2, 255 * 3, color='blue', alpha=.2, zorder=0)\nplt.show()","1e59b055":"augment_factor = 9\nseed = 42\nclear_first = True\n\naugment_path = os.path.join(working_path, 'augmented')\naug_images_path = os.path.join(augment_path, 'images')\n\nif not os.path.exists(working_path):\n    os.mkdir(working_path)\n    os.mkdir()\nif not os.path.exists(augment_path):\n    os.mkdir(augment_path)\nif not os.path.exists(aug_images_path):\n    os.mkdir(aug_images_path)\n    \nif clear_first:\n    for filename in os.listdir(aug_images_path):\n        os.remove(os.path.join(aug_images_path, filename))\n        \ndef augment_image(image):\n    crop_factor = 5\/6\n    thresh = .5\n    aug = tf.convert_to_tensor(np.copy(image), dtype=tf.float32)\n\n    if np.random.rand() < thresh:\n        aug = tf.image.random_flip_left_right(aug, seed)\n    if np.random.rand() < thresh:\n        aug = tf.image.random_flip_up_down(aug, seed)\n    if np.random.rand() < thresh:\n        aug = tf.image.resize(tf.image.random_crop(aug, [int(aug.shape[0] * crop_factor), int(aug.shape[1] * crop_factor), aug.shape[2]], seed), aug.shape[:-1])\n    if np.random.rand() < thresh:\n        aug = tf.image.rot90(aug, k=np.random.randint(4))\n\n    return aug.numpy()\n\nfor filename in os.listdir(train_images_path):\n    for i in range(augment_factor):\n        aug_image_path = os.path.join(aug_images_path, str(i) + \"-\" + filename)\n        if not os.path.exists(aug_image_path):\n            # Here the images needs to stay in BGR encoding, because it will be fed to the network along with the original BGR images!\n            image = cv2.imread(os.path.join(train_images_path, filename)) \/ 255.\n\n            image = (augment_image(image) * 255.).astype(np.uint8)\n\n            cv2.imwrite(aug_image_path, image)\n            df.loc[len(df)] = [os.path.basename(aug_image_path), df.loc[df['Id'] == filename, 'Expected'].values[0], 0, 0]","ea5c4ab2":"from keras.utils import Sequence\nfrom skimage import util\n\nclass LabeledDataGenerator(Sequence):\n    \n    def __init__(self, image_filepaths, batch_size, augment_factor=3, seed=42):\n        self.image_filepaths = image_filepaths\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return (np.ceil(len(self.image_filepaths) \/ float(self.batch_size))).astype(np.int)\n    \n    def __getitem__(self, idx):\n        batch_x = self.image_filepaths[idx * self.batch_size: (idx+1) * self.batch_size]\n        \n        if os.path.basename(filename.split(\"-\")[-1]) not in df['Id'].values:\n            print(\"Entry for\", os.path.basename(filename.split(\"-\")[-1]), \"does not exist!\")\n        \n        images = np.array([\n            cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB) \/ 255. for filename in batch_x\n        ], dtype=np.float32)\n        \n        labels = np.array([df.loc[df['Id'] == os.path.basename(filename), 'Expected'].values[0] for filename in batch_x], dtype=np.float32)\n        \n        labels = tf.one_hot(labels, depth=num_classes)\n        \n        return images, labels","78865832":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nbatch_size = 16\ntrain_size_max = len(os.listdir(train_images_path)) * (augment_factor + 1)\ntrain_size = train_size_max\n\ntrain_images_filenames = os.listdir(train_images_path)\ntrain_images_filepaths = [os.path.join(train_images_path, filename) for filename in train_images_filenames]\naug_images_filepaths = [os.path.join(aug_images_path, filename) for filename in os.listdir(aug_images_path)]\ntrain_images_filepaths += aug_images_filepaths\ntrain_images_filepaths_shuffled = shuffle(train_images_filepaths)\ntrain_images_filepaths_t, train_images_filepaths_v = train_test_split(\n    train_images_filepaths_shuffled, test_size=1\/3, random_state=1)\n\ntrain_batch_gen_t = LabeledDataGenerator(train_images_filepaths_t[:train_size], batch_size, seed=42)\ntrain_batch_gen_v = LabeledDataGenerator(train_images_filepaths_v[:train_size], batch_size)","b8261bc1":"test_df = pd.DataFrame(columns=[\"Min\", \"Mean\", \"Max\", \"dtype\"])\n\nfor img in train_batch_gen_t[0][0][:batch_size]:\n    test_df.loc[len(test_df)] = [np.min(img), np.mean(img), np.max(img), img.dtype]\ntest_df","2f7d1491":"example_img = train_batch_gen_t[7][0][13]\nprint(len(train_batch_gen_t[0][1]))\nprint(test_df.loc[0])\nprint(example_img.shape)\nprint(\"Label\", train_batch_gen_t[0][1][0])\nplt.figure()\nplt.subplot(1, 2, 1)\nplt.imshow(example_img)\nplt.subplot(1, 2, 2)\nplt.hist(example_img.mean(axis=-1))\nplt.show()","24494bfd":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.regularizers import l2\n\nfrom tensorflow.keras.applications import Xception, xception\nbackbone = Xception(\n    weights = \"imagenet\",\n    include_top = False\n)\nbackbone.trainable = True\n\ninputs = Input(shape=example_img.shape)\nx = xception.preprocess_input(inputs)\nx = backbone(x)\nx = Flatten()(x)\nx = Dropout(.25)(x)\nx = Dense(128, activation='sigmoid')(x)\noutputs = Dense(num_classes, activation='softmax')(x)\n\nclassifier = Model(inputs=inputs, outputs=outputs, name=\"food_classifier\")\nclassifier.compile(optimizer=Adam(learning_rate=.0001), loss=CategoricalCrossentropy(), metrics=[CategoricalAccuracy()])\nclassifier.summary()","edec56c6":"from tensorflow.keras.callbacks import LearningRateScheduler\nfrom datetime import datetime\n\nn_epochs = 10\n\ntf.keras.backend.clear_session()\n\ntrain_start = datetime.now()\n\ndef scheduler(epoch, lr):\n  if epoch < n_epochs * 2\/3:\n    return lr\n  else:\n    return lr * tf.math.exp(-0.1)\n\nclass_history = classifier.fit(\n    x = train_batch_gen_t,\n    epochs = n_epochs,\n    verbose = 1,\n    validation_data = train_batch_gen_v,\n    callbacks=[LearningRateScheduler(scheduler)]\n)\n\nprint(\"Training finished.\")\nprint(\"Needed training time:\", str(datetime.now() - train_start))\n\n#classifier.save_weights(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '_classifier.h5')","0faaf714":"plt.figure(figsize=(9,6))\nplt.title(\"Training progress of classifier\")\nplt.subplot(1, 2, 1)\nplt.title(\"Loss\")\nplt.plot(class_history.history['loss'])\nplt.plot(class_history.history['val_loss'])\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.subplot(1, 2, 2)\nplt.title(\"Accuracy\")\nplt.plot(class_history.history['categorical_accuracy'])\nplt.plot(class_history.history['val_categorical_accuracy'])\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","8b110c44":"def get_predictions(img):\n    return classifier(img).numpy().reshape(-1)\n\ndef get_prediction(img):\n    return np.argmax(get_predictions(img))","71214ff6":"train_eval_df = pd.DataFrame(columns=[\"Id\", \"Prediction\", \"Expected\", \"Confidence\"])\ntrain_predictions_df = pd.DataFrame([])\n\nfor path in train_images_filepaths_t[:train_size]:\n    \n    file = os.path.basename(path)\n    \n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \/ 255.\n    img = np.array([img], dtype=np.float32)\n    label = df.loc[df['Id'] == file, 'Expected'].values[0]\n    \n    predictions = pd.Series(get_predictions(img), name=file)\n    train_predictions_df = train_predictions_df.append(predictions)\n    \n    predictedClass = np.argmax(predictions)\n    \n    train_eval_df.loc[len(train_eval_df)] = [file, predictedClass, label, predictions[predictedClass]]","1f62fc4a":"# accuracy for train data\nm = tf.keras.metrics.Accuracy()\nm.update_state(train_eval_df[\"Expected\"].to_numpy().astype(np.int), train_eval_df[\"Prediction\"].to_numpy().astype(np.int))\nm.result().numpy()","2a83e1a5":"valid_eval_df = pd.DataFrame(columns=[\"Id\", \"Prediction\", \"Expected\", \"Confidence\"])\nvalid_predictions_df = pd.DataFrame([])\n\nfor path in train_images_filepaths_v[:train_size]:\n    \n    file = os.path.basename(path)\n    \n    # only consider non-augmented images\n    if file in os.listdir(train_images_path):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \/ 255.\n        img = np.array([img], dtype=np.float32)\n        label = df.loc[df['Id'] == file, 'Expected'].values[0]\n\n        predictions = pd.Series(get_predictions(img), name=file)\n        valid_predictions_df = train_predictions_df.append(predictions)\n\n        predictedClass = np.argmax(predictions)\n\n        valid_eval_df.loc[len(valid_eval_df)] = [file, predictedClass, label, predictions[predictedClass]]","fe8a9325":"# accuracy for validation data\nm = tf.keras.metrics.Accuracy()\nm.update_state(valid_eval_df[\"Expected\"].to_numpy().astype(np.int), valid_eval_df[\"Prediction\"].to_numpy().astype(np.int))\nm.result().numpy()","cd4eb434":"test_eval_df = pd.DataFrame(columns=[\"Id\", \"Expected\", \"Confidence\"])\n\nfor file in os.listdir(test_images_path):\n    \n    img = cv2.imread(os.path.join(test_images_path, file))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \/ 255.\n    img = np.array([img], dtype=np.float32)\n    \n    predictions = get_predictions(img)\n    predictedClass = np.argmax(predictions)\n    test_eval_df.loc[len(test_eval_df)] = [file, predictedClass, predictions[predictedClass]]","9ee48f4b":"test_eval_df","44153730":"plt.figure(figsize=(10,10))\nplt.subplot(3, 1, 1)\nplt.xlim(0.8, 1.05)\nplt.title(\"Confidence histogram training data\")\ntrain_eval_df['Confidence'].plot.hist(bins=50)\ntrain_eval_df['Confidence'].plot.density()\nplt.axvline(np.mean(train_eval_df['Confidence']), color='red', linewidth=2)\nplt.subplot(3, 1, 2)\nplt.xlim(0.8, 1.05)\nplt.title(\"Confidence histogram validation data\")\nvalid_eval_df['Confidence'].plot.hist(bins=50)\nvalid_eval_df['Confidence'].plot.density()\nplt.axvline(np.mean(valid_eval_df['Confidence']), color='red', linewidth=2)\nplt.subplot(3, 1, 3)\nplt.xlim(0.8, 1.05)\nplt.title(\"Confidence histogram test data\")\ntest_eval_df['Confidence'].plot.hist(bins=50)\ntest_eval_df['Confidence'].plot.density()\nplt.axvline(np.mean(test_eval_df['Confidence']), color='red', linewidth=2)\nplt.show()","6af9b52c":"plt.figure(figsize=(10, 10))\nplt.subplot(3, 1, 1)\nplt.title(\"Train class histogram: prediction\")\ntrain_eval_df['Prediction'].plot.hist()\nplt.subplot(3, 1, 2)\nplt.title(\"Train class histogram: expected\")\ntrain_eval_df['Expected'].plot.hist()\nplt.subplot(3, 1, 3)\nplt.title(\"Test class histogram: prediction\")\ntest_eval_df['Expected'].plot.hist()\nplt.show()","63f96614":"plt.figure(figsize=(10,15))\ntest_uncertainities_df = test_eval_df[(1 > test_eval_df[\"Confidence\"]) & (test_eval_df[\"Confidence\"] > 0)].sort_values(by=\"Confidence\", ascending=True)[:9]\ni = 1\nfor index, row in test_uncertainities_df.iterrows():\n    img = cv2.imread(os.path.join(test_images_path, row[\"Id\"]))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.subplot(3, 3, i)\n    plt.title(\"P: %d; C: %f\" % (row[\"Expected\"], row[\"Confidence\"]))\n    plt.imshow(img)\n    i += 1\n\nplt.show()","62459079":"test_eval_df.drop(columns=['Confidence']).to_csv(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '_predictions.csv', index = False)","031838dd":"# Model","999c6902":"Source for the generator: [medium.com](https:\/\/medium.com\/@mrgarg.rajat\/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71)","5176e111":"# **Submitting results to competition**\nEverything runs smoothly, but the problem is you can't see your file anywhere in this page, nor in your Profile, Kernels tab, nowhere! This is because you haven't commited your notebook yet. To do that, click the Save Version button - as I write it, this is a light-blue button in the top-right corner of my notebook page, in the main pane. Click Save and Run All. It may take a minute for the Kaggle server to publish your notebook.\n\nWhen this operation is done, you can click the version number in the top right. Click the Notebook version, and then click the menu (...). Then click \"Submit to Competition\".","eb34a2a8":"## Classifier","09f9dc36":"## Classifier","702b49ee":"# Data analysis","0a38fafd":"I use four augmentation techniques each of them applied to an independent probability. The probability of an image being modified in the augmentation process at least once is given by: $$P(X \\geq 1) = \\operatorname{Binomial}(k \\geq 1, N = 4, \\theta = \\text{tresh})$$\n\nE. g.:  $$P(X \\geq 1) = \\operatorname{Binomial}(k \\geq 1, N = 4, \\theta = 0.5) \\approx 0.94 $$","d2e0a280":"# Training","0ab3ec6b":"# Evaluation on training data","3f2d0481":"## Classifier","8e989836":"## Augmentation","d5704006":"# Dataset Preparation and Augmentation","4819689c":"# Generating csv file for submission","fd0b8b3b":"# Niklas D. Food Classification"}}