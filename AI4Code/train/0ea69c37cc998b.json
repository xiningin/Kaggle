{"cell_type":{"4e45ea39":"code","b286af68":"code","80f849a1":"code","49613038":"code","d13acf5c":"code","3ea3b803":"code","061b9c56":"code","5728ebc0":"code","bf9f1d6b":"code","2d098b11":"code","8e20ea66":"code","9521ee7d":"code","34f944af":"code","0e447ff1":"code","7299c27b":"code","ad421d26":"code","d175765d":"code","47b4aed7":"code","67f63868":"code","ced51aaf":"code","e2257432":"code","bec4af7c":"code","d5ab2b6f":"code","38b9b4aa":"code","fc9abea7":"code","ef222500":"code","3a7d0f00":"code","b58abd4b":"code","cf105a4e":"code","104e8f91":"markdown","a7752575":"markdown","b973222b":"markdown","9d984c02":"markdown","1b9a8930":"markdown","2fd3b76f":"markdown","ca79572d":"markdown","8794dc86":"markdown","9601ad78":"markdown","f539dcde":"markdown","f78780bb":"markdown","8a5ad7d4":"markdown","d1bb446c":"markdown","33e0ce94":"markdown","becbe88c":"markdown","dab81997":"markdown","bbb8bff3":"markdown","5082ec97":"markdown","37873535":"markdown","5836e37d":"markdown","1a3cb8c7":"markdown","0b5dd1f7":"markdown"},"source":{"4e45ea39":"import numpy as np\nimport re\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.max_rows\", None)\n%matplotlib inline","b286af68":"ts_confirmed_new = pd.read_csv(\"..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_confirmed.csv\")","80f849a1":"ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"France\"]","49613038":"fig, axs = plt.subplots(2, 1, sharex=True, figsize=(10, 10))\n\naxs[0].plot(ts_confirmed_new.sum()[2:])\naxs[0].set_ylabel(\"Cases\")\naxs[1].set_ylabel(\"Cases\")\naxs[1].set_xlabel(\"time\")\n# axs[1].grid(True)\n# axs[1].set_yscale(\"log\")\n# axs[0].set_yscale(\"log\")\n\naxs[1].plot(ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] != \"China\"].sum()[2:])\nfig.tight_layout()","d13acf5c":"f_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"France\"].iloc[0][\n    4:\n]\n\ni_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"Italy\"].sum(\n    axis=0\n)[4:]\n\nc_confirmed = ts_confirmed_new[\n    ts_confirmed_new[\"Country\/Region\"] == \"Mainland China\"\n].sum(axis=0)[4:]\nsg_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"Singapore\"].sum(\n    axis=0\n)[4:]\nger_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"Germany\"].sum(\n    axis=0\n)[4:]\nsp_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"Spain\"].sum(\n    axis=0\n)[4:]\nskorea_confirmed = ts_confirmed_new[\n    ts_confirmed_new[\"Country\/Region\"] == \"Korea, South\"\n].sum(axis=0)[4:]\n\ntaiwan_confirmed = ts_confirmed_new[\n    ts_confirmed_new[\"Country\/Region\"] == \"Taiwan*\"\n].sum(axis=0)[4:]\n\nf_confirmed.index = pd.to_datetime(f_confirmed.index)\ni_confirmed.index = pd.to_datetime(i_confirmed.index)\nc_confirmed.index = pd.to_datetime(c_confirmed.index)\nsg_confirmed.index = pd.to_datetime(sg_confirmed.index)\nsp_confirmed.index = pd.to_datetime(sp_confirmed.index)\nger_confirmed.index = pd.to_datetime(ger_confirmed.index)\nskorea_confirmed.index = pd.to_datetime(skorea_confirmed.index)\ntaiwan_confirmed.index = pd.to_datetime(taiwan_confirmed.index)","3ea3b803":"fig = plt.figure(figsize=(10, 20))\nax = fig.add_subplot(2, 1, 1)\nax.set_yscale(\"log\")\n\nf_confirmed.plot(label=\"France\", marker=\"^\")\ni_confirmed.plot(label=\"Italy\")\nc_confirmed.plot(label=\"China\")\nsg_confirmed.plot(label=\"Singapore\")\nsp_confirmed.plot(label=\"Spain\")\nskorea_confirmed.plot(label=\"South Korea\")\nger_confirmed.plot(label=\"Germany\")\ntaiwan_confirmed.plot(label=\"Taiwan\")\n\nplt.legend(loc=\"best\")","061b9c56":"def growth(serie):\n    g = []\n    index = []\n    for i in range(len(f_confirmed) - 2):\n        if serie.diff()[i] == 0:\n            g.append(0)\n        else:\n            g.append(serie.diff()[i + 1] \/ serie.diff()[i])\n        index.append(serie.index[i])\n    return pd.Series(data=g, index=index).replace([np.inf, -np.inf], np.nan).fillna(0)","5728ebc0":"fig, ax = plt.subplots(2, 1, figsize=(6, 6))\n\ngrowth(f_confirmed).plot(ax=ax[0], label=\"France\")\ngrowth(i_confirmed).plot(ax=ax[1], label=\"Italie\")\n\n# growth(c_confirmed).pct_change().plot(label='China')\n# growth(sg_confirmed).pct_change().plot(label=\"Singapore\")\n\nax[0].legend(loc=\"best\")\nax[1].legend(loc=\"best\")","bf9f1d6b":"f_confirmed_new = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"France\"].sum(axis=0)[10:]\nf_confirmed_new.index = pd.to_datetime(f_confirmed_new.index)\n","2d098b11":"def ratio_change(serie):\n    g = []\n    index = []\n    for i in range(len(serie) - 1):\n        if i == 0:\n            g.append(1)\n        else:\n            g.append(serie[i] \/ serie[i - 1])\n        index.append(serie.index[i])\n    return pd.Series(data=g, index=index).replace([np.inf, -np.inf], np.nan).fillna(0)","8e20ea66":"sns.boxplot(\n    ratio_change(\n        ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] != \"China\"].sum()[10:]\n    )\n)\nprint(\n    ratio_change(\n        ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] != \"China\"].sum()[10:]\n    ).describe()\n)","9521ee7d":"sns.boxplot(ratio_change(f_confirmed_new[10:]))\nprint(ratio_change(f_confirmed_new[10:]).describe())","34f944af":"dates = []\nserie = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] != \"China\"].sum()[2:]\nserie.index = pd.to_datetime(serie.index)\nfor i in range(len(serie) - 1):\n    j = i\n    while (serie[j] < 2 * serie[i]) & (j < len(serie) - 1):\n        j = j + 1\n    if j > i + 1:\n        dates.append(serie.index[j] - serie.index[i])\nprint(\"Moyenne pour doubler le chiffre est de \", np.mean(dates))","0e447ff1":"ilist = i_confirmed.where(i_confirmed > 30).dropna().tolist()\nflist = f_confirmed.where(f_confirmed > 40).dropna().tolist()\n\nfig = plt.figure(figsize=(15, 15))\nax = fig.add_subplot(2, 1, 1)\n# ax.set_yscale(\"log\")\nax.plot(ilist, \"g--\", label=\"Italy\")\nax.plot(flist, \"b--\", label=\"France\")","7299c27b":"import math\nfrom datetime import timedelta\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import mean_squared_error","ad421d26":"# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix > len(sequence) - 1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.asarray(X), np.asarray(y)","d175765d":"f_confirmed = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"France\"].sum(axis=0)[10:]\nf_confirmed.index = pd.to_datetime(f_confirmed.index)\n\n# define input sequence\n# choose a number of time steps ( equivalent to # of features)\nn_steps = 4\n\nX, y = split_sequence(f_confirmed[:'2020-03-14'], n_steps)","47b4aed7":"n_features = 1\n\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n\n# define model\nmodel = Sequential()\nmodel.add(LSTM(10, activation=\"relu\", input_shape=(n_steps, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\", loss=\"mse\")\n\n\n# fit model\nhistory = model.fit(X, y, epochs=200, verbose=0)\n\n# history for loss\nplt.plot(history.history[\"loss\"])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","67f63868":"fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\npred = model.predict(X)\npred_serie = pd.Series(data=pred.flatten(), index=f_confirmed[4:].index)\n\npred_serie.plot(ax=ax, label=\"prediction\")\nf_confirmed[4:].plot(ax=ax, label=\"training\")\n\nax.legend(loc=\"best\")","ced51aaf":"n = 30\nindex30 = pd.date_range(f_confirmed[:'2020-03-11'].index[-1] + timedelta(days=1), periods=n, freq=\"D\")\nlast_values = f_confirmed[:'2020-03-11'][-n_steps:].values\nprediction30 = []","e2257432":"for i in range(n):\n    x_input = last_values[-n_steps:]\n    x_input = x_input.reshape((1, n_steps, n_features))\n    y_pred = model.predict(x_input)\n    prediction30.append(int(y_pred[0][0]))\n    last_values = np.append(last_values, int(y_pred[0][0]))\n\nserie30_france = pd.Series(data=prediction30, index=index30)","bec4af7c":"fig = plt.figure(figsize=(15, 15))\nax = fig.add_subplot(2, 1, 1)\n\nax.set_yscale(\"log\")\n\nf_confirmed_new = ts_confirmed_new[ts_confirmed_new[\"Country\/Region\"] == \"France\"].sum(\n    axis=0\n)[4:]\nf_confirmed_new.index = pd.to_datetime(f_confirmed_new.index)\n\n\nf_confirmed.plot(ax=ax, label=\"france_new\", marker=\"o\", linestyle=\"\")\nf_confirmed[:'2020-03-11'].plot(ax=ax, label=\"france\")\n# c_confirmed.plot(ax=ax, c=\"red\", label=\"China\")\n\nserie30_france.plot(ax=ax, c=\"grey\", linestyle=\"--\", label=\"predition for 30 days\")","d5ab2b6f":"# define input sequence\n# choose a number of time steps ( equivalent to # of features)\nn_steps = 3\n\nX, y = split_sequence(skorea_confirmed[:-1], n_steps)\n\nn_features = 1\n\n# scaler = StandardScaler()\n# trainX = scaler.fit_transform(X)\n#\n# trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], n_features))\n\nX = X.reshape((X.shape[0], X.shape[1], n_features))","38b9b4aa":"# define model\nmodel = Sequential()\nmodel.add(LSTM(10, activation=\"relu\", input_shape=(n_steps, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\", loss=\"mse\")\n\n\n# fit model\nhistory = model.fit(X, y, epochs=250, verbose=0)\n\n# history for loss\nplt.plot(history.history[\"loss\"])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","fc9abea7":"n = 100\nindex30 = pd.date_range(f_confirmed.index[-1] + timedelta(days=1), periods=n, freq=\"D\")\nlast_values = f_confirmed[-n_steps:].values\nprediction30 = []\n\n\nfor i in range(n):\n    x_input = last_values[-n_steps:]\n    x_input = x_input.reshape((1, n_steps))\n    x_input = x_input.reshape((1, n_steps, n_features))\n    y_pred = model.predict(x_input)\n    prediction30.append(int(y_pred[0][0]))\n    last_values = np.append(last_values, int(y_pred[0][0]))\n\nserie30 = pd.Series(data=prediction30, index=index30)","ef222500":"fig = plt.figure(figsize=(15, 30))\nax = fig.add_subplot(2, 1, 1)\n\nax.set_yscale(\"log\")\n\nf_confirmed[:'2020-03-11'].plot(ax=ax, label=\"Train data France\")\nf_confirmed_new.plot(ax=ax, label=\"france_new\", marker=\"o\", linestyle=\"\")\nskorea_confirmed[10:].plot(ax=ax, marker=\"^\", label=\"Cor\u00e9e du Sud\")\n\nserie30.plot(\n    ax=ax, c=\"grey\", linestyle=\"--\", label=\"prediction en suivant la cor\u00e9e du sud\"\n)\n\n\nserie30_france.plot(\n    ax=ax, c=\"red\", linestyle=\"--\", label=\"predition suivant la progression france\"\n)\n\n\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Cases\")\nax.legend(loc=\"best\")","3a7d0f00":"hosp = f_confirmed_new.apply(lambda x: x * 0.05)\nhosp_france = serie30_france.apply(lambda x: x * 0.05)\nhosp_ks = serie30.apply(lambda x: x * 0.05)","b58abd4b":"fig = plt.figure(figsize=(10, 20))\nax = fig.add_subplot(2, 1, 1)\nax.set_yscale(\"log\")\n\nhosp.plot(ax=ax, c=\"grey\", linestyle=\"--\", label=\"cas hospitalis\u00e9\")\nhosp_ks.plot(\n    ax=ax, c=\"blue\", linestyle=\"--\", label=\"prediction en suivant la cor\u00e9e du sud\"\n)\nhosp_france.plot(\n    ax=ax, c=\"red\", linestyle=\"--\", label=\"predition suivant la progression france\"\n)\n\nax.set_ylabel(\"# Hospitalis\u00e9s\")\nax.set_xlabel(\"Time\")\nax.legend(loc=\"best\")\nax.axhline(y=5000, linewidth=3, color=\"black\", alpha=0.5)","cf105a4e":"print(\n    \"Date de saturation du syst\u00e8me hospitalien Francais dans le pire sc\u00e9nario :\"\n    + hosp_france.where(hosp_france >= 5000).dropna().index[0].strftime(\"%d\/%m\/%Y\")\n)\nprint(\n    \"Date de saturation du syst\u00e8me hospitalien Francais dans le meilleur sc\u00e9nario :\"\n    + hosp_ks.where(hosp_ks >= 5000).dropna().index[0].strftime(\"%d\/%m\/%Y\")\n)","104e8f91":"##\u00a0Analyse de l'\u00e9volution des cas de COVID19 la France vs le reste du monde","a7752575":"\nEn d\u00e9calant les deux courbes pour avoir le m\u00eame d\u00e9but, nous remarquons que les courbes ont la m\u00eame forme exponentiel, la France a pu retarder l'\u00e9volution des cas de COVID19 un peu plus longtemps de l'Italie mais la progression du virus est visuellement la m\u00eame;\n\n**Comme annonc\u00e9 par le pr\u00e9sident de la r\u00e9publique Macron, l'\u00e9pid\u00e9mie en France ne fait que commencer.**","b973222b":"## De combien de jours l'avancement des cas en France est en retard par rapport \u00e0 l'Italie\n","9d984c02":"## Prediction","1b9a8930":"##\u00a0Model","2fd3b76f":"Le facteur de changement de la courbe est \u00e9gale au ratio de nouveaux cas d\u00e9t\u00e9ct\u00e9s entredeux jours. Autrement dit, c'est le ratio de la diff\u00e9rence de nombres de cas d\u00e9tect\u00e9s entre deux jours successifs","ca79572d":"\nSachant que la france dispose de 5000 lits sur le territoire et que **5% des cas contamin\u00e9s par le COVID19 n\u00e9cessitent un prise en charge hospitali\u00e8re critique** (source : https:\/\/jamanetwork.com\/journals\/jama\/fullarticle\/2762996).","8794dc86":"## Ratio de changement ","9601ad78":"Pr\u00e9dire l'\u00e9volution des cas de COVID19 en France sur le prochains 30 jours","f539dcde":"Nous remarquons un ratio de changement variant de 1.16 \u00e0 1.22 dans le monde, un ratio de 1.18 en moyenne en France (avec une plus grande variance : 0.27)\nCeci pourrait s'expliquer par le manque de tests g\u00e9n\u00e9ralis\u00e9s en France.","f78780bb":"# LSTM trained on french data","8a5ad7d4":"# Prediction de la date de saturation des h\u00f4pitaux","d1bb446c":"## Prediction","33e0ce94":"## Construction des series temporels des cas confirm\u00e9s \n","becbe88c":"# LSTM used for South korea","dab81997":"**Source :**\n\nReport of the WHO-China Joint Mission on Coronavirus Disease 2019 : https:\/\/www.who.int\/docs\/default-source\/coronaviruse\/who-china-joint-mission-on-covid-19-final-report.pdf\nCare for Critically Ill Patients With COVID-19 : https:\/\/jamanetwork.com\/journals\/jama\/fullarticle\/2762996\nDaily time series : https:\/\/github.com\/opencovid19-fr\/data CSSE at Johns Hopkins University : https:\/\/github.com\/CSSEGISandData\/COVID-19","bbb8bff3":"### Remarques","5082ec97":"On remarque clairement que  le reste du monde entre dans une phase **exponentiel** alors que la Chine n'est plus dans cette phase.","37873535":"## Facteur de changement","5836e37d":"## Temps pour doubler ","1a3cb8c7":"## Saturation des lits de r\u00e9animation dans les h\u00f4pitaux","0b5dd1f7":"## Prepare train data"}}