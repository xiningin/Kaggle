{"cell_type":{"7ca8d188":"code","c9857068":"code","ea4d8e32":"code","b423131a":"code","75a5e329":"markdown"},"source":{"7ca8d188":"from numpy.random import seed\nfrom numpy.random import normal\nfrom numpy import arange\nfrom numpy import mean\nfrom numpy import std\nfrom scipy.stats import mode\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot","c9857068":"# create a test set for a row of real data with an unknown label\ndef create_test_set(row, n_cases=3, feature_scale=0.2):\n\ttest_set = list()\n\ttest_set.append(row)\n\t# make copies of row\n\tfor _ in range(n_cases):\n\t\t# create vector of random gaussians\n\t\tgauss = normal(loc=0.0, scale=feature_scale, size=len(row))\n\t\t# add to test case\n\t\tnew_row = row + gauss\n\t\t# store in test set\n\t\ttest_set.append(new_row)\n\treturn test_set","ea4d8e32":"# make predictions using test-time augmentation\ndef test_time_augmentation(model, X_test, noise):\n\t# evaluate model\n\ty_hat = list()\n\tfor i in range(X_test.shape[0]):\n\t\t# retrieve the row\n\t\trow = X_test[i]\n\t\t# create the test set\n\t\ttest_set = create_test_set(row, feature_scale=noise)\n\t\t# make a prediction for all examples in the test set\n\t\tlabels = model.predict(test_set)\n\t\t# select the label as the mode of the distribution\n\t\tlabel, _ = mode(labels)\n\t\t# store the prediction\n\t\ty_hat.append(label)\n\treturn y_hat","b423131a":"# evaluate different number of synthetic examples created at test time\nnoise = arange(0.01, 0.31, 0.01)\nresults = list()\nfor i,n in enumerate(noise):\n\t# initialize numpy random number generator\n\tseed(1)\n\t# create dataset\n\tX, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n\t# prepare the cross-validation procedure\n\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)\n\tscores = list()\n\tfor train_ix, test_ix in cv.split(X, y):\n\t\t# split the data\n\t\tX_train, X_test = X[train_ix], X[test_ix]\n\t\ty_train, y_test = y[train_ix], y[test_ix]\n\t\t# fit model\n\t\tmodel = LogisticRegression()\n\t\tmodel.fit(X_train, y_train)\n\t\t# make predictions using test-time augmentation\n\t\ty_hat = test_time_augmentation(model, X_test, n)\n\t\t# calculate the accuracy for this iteration\n\t\tacc = accuracy_score(y_test, y_hat)\n\t\t# store the result\n\t\tscores.append(acc)\n\t# report performance\n\tprint('%3d) noise=%.3f, acc: %.3f (%.3f)' % (i+1, n, mean(scores), std(scores)))\n\tresults.append(mean(scores))\n# plot the results\npyplot.plot(noise, results)\npyplot.show()","75a5e329":"# Test Time Augmentation"}}