{"cell_type":{"5703f2f3":"code","6281797a":"code","1361d82e":"code","5f59544e":"code","f9f2cb41":"code","0b36d3d1":"code","5b570033":"code","caebb3d2":"code","0afece18":"code","c05a7813":"code","61802181":"code","aed6d50d":"code","6e4b3dd0":"code","39c0e4f8":"code","8f53db68":"code","fabedb66":"code","1d4785bf":"code","5aec4239":"code","7752e2db":"code","af80aeb8":"code","8019cd03":"code","28bdc4ad":"code","35441d92":"code","8eada361":"code","06663f95":"code","a1d4da61":"code","313d685d":"code","320199dc":"code","5e451b80":"code","31d62110":"code","b32af52f":"code","3ddf3e8f":"code","43b293f6":"code","501358a7":"code","dc2fc12a":"code","1f281c97":"code","f625de68":"code","a8d169e8":"code","fad238d6":"code","5c203466":"code","10e97538":"code","601a1ea8":"code","281e247f":"code","fcc4ced7":"code","f55a05c5":"code","a4104a85":"code","68423a37":"code","f7c709b8":"code","3eb59ca1":"code","99330832":"code","9eb062cd":"code","73953e98":"code","d92efa52":"code","5f3a6b46":"code","278869a4":"code","7872c508":"code","384ce20c":"code","ff2eae34":"code","6e552da2":"code","25039c54":"code","6f98a215":"code","c80b4d99":"code","94a7afd9":"code","ca9478b4":"code","fb3be0c7":"code","90aa389e":"code","4ffd544a":"code","f5537de5":"code","9cc96a76":"code","c7594447":"code","6975490a":"code","396cafe2":"code","c3d460d0":"code","08ffcf8c":"code","154675e4":"code","57fc0526":"code","abdec75f":"code","0324cb7e":"code","b4565e7f":"code","713a113a":"code","e433623a":"code","aa3cd87f":"code","dad01776":"code","e145b197":"code","f3d3d744":"code","a22563cf":"code","3493fc3f":"code","ccbe0137":"code","4dfc7a7f":"code","34491f78":"code","b5e461c3":"code","231fcdd3":"code","8330aea9":"code","cf0ed561":"code","a77d3ddf":"code","493406fc":"code","eb2d1950":"code","abdfac89":"code","e7ebb819":"code","f7964cc8":"code","cc65eba3":"code","7b169d77":"code","6a50eab2":"code","ddea280b":"code","4d0bd323":"code","97606980":"code","3c4deab5":"code","4d7c6cd2":"code","9320cd8b":"code","e6d874d4":"code","d00555f3":"code","4fd991f3":"code","d4c0ec4e":"code","9ce693e5":"code","8bd5dd4d":"code","d6e5b0dd":"markdown","02d34035":"markdown","b5b73d0e":"markdown","01a11e93":"markdown","c74d4a20":"markdown","b04f3426":"markdown","831f0349":"markdown","d46d70f2":"markdown","98e00af1":"markdown","7f53a836":"markdown","ed219aaf":"markdown","78145381":"markdown","8cc1090d":"markdown","1f8e1904":"markdown","dc29c2f6":"markdown","b2c394cd":"markdown","0522f477":"markdown","a9081ba6":"markdown","ddf6326f":"markdown","208d3145":"markdown","e746b00d":"markdown","ebb91a21":"markdown","c40df529":"markdown","df14110a":"markdown","4090383e":"markdown","7887cf47":"markdown","f310565c":"markdown","b93c1dda":"markdown","aed6d48e":"markdown","3bf91f8e":"markdown","0312c04f":"markdown","cf3e1c7e":"markdown","4fa9e606":"markdown","3b673582":"markdown","6035c6d2":"markdown","798a5373":"markdown"},"source":{"5703f2f3":"# Loading libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold\nfrom sklearn.metrics import make_scorer, fbeta_score, accuracy_score\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom lightgbm import LGBMRegressor","6281797a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1361d82e":"# Loading train_data\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-dataset\/train.csv')\npd.set_option('display.max_columns', 82)\ntrain.head()","5f59544e":"# Loading test_data\ntest = pd.read_csv('\/kaggle\/input\/house-prices-dataset\/test.csv')\ntest.head()","f9f2cb41":"print('The train data has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\nprint('The test data has {} rows and {} columns'.format(test.shape[0],test.shape[1]))","0b36d3d1":"train.info()","5b570033":"# Checking for the null values\ntrain.isnull().sum()","caebb3d2":"train.columns[train.isnull().any()]","0afece18":"# Missing values percentage\nmiss=train.isnull().sum()\/len(train)\nmiss=miss[miss>0]\nmiss.sort_values(inplace=True)\nmiss","c05a7813":"# Numerical variables\nnum=train.select_dtypes(include=np.number)\nprint(num.columns)\nprint('No. of Numerical variables are {}'.format(len(num.columns)))","61802181":"# Categorical variables\ncat_data=train.select_dtypes(exclude=np.number)\nprint(cat_data.columns)\nprint('No. of Categorical variables are {}'.format(len(cat_data.columns)))","aed6d50d":"num=num.drop('Id',axis=1)","6e4b3dd0":"# Checking the distribution of target variable\nsns.distplot(train['SalePrice'])\nplt.xticks(rotation=45)\nplt.show()","39c0e4f8":"plt.figure(figsize=(10,10))\nmatrix=np.triu(num.corr())\nsns.heatmap(num.corr(),mask=matrix,cmap='coolwarm')\nplt.show()","8f53db68":"corr=num.corr()\nprint (corr['SalePrice'].sort_values(ascending=False)[:15], '\\n') #top 15 values\nprint ('----------------------')\nprint (corr['SalePrice'].sort_values(ascending=False)[-5:]) #last 5 values","fabedb66":"plt.figure(figsize=(16,6))\ncorr['SalePrice'].sort_values(ascending=False)[1:].plot(kind='bar')","1d4785bf":"train['OverallQual'].unique()","5aec4239":"#let's check the mean price per quality and plot it.\npivot = train.pivot_table(index='OverallQual', values='SalePrice', aggfunc=np.median) # median because target is right skewed.\npivot.sort_values(by='SalePrice')","7752e2db":"pivot.plot(kind='bar')\nplt.show()","af80aeb8":"#GrLivArea variable\nsns.jointplot(x=train['GrLivArea'], y=train['SalePrice'])\nplt.show()","8019cd03":"fig, ax = plt.subplots(ncols=2, nrows = 2, figsize=(12,10))\nsns.scatterplot(x='GarageCars',y='SalePrice', data=train, ax=ax[0,0])\nsns.scatterplot(x='GarageArea', y='SalePrice', data=train, ax=ax[0,1])\nsns.scatterplot(x='TotalBsmtSF', y='SalePrice', data=train, ax=ax[1,0])\nsns.scatterplot(x='YearBuilt', y='SalePrice', data=train, ax=ax[1,1])\nplt.show()","28bdc4ad":"sns.scatterplot(x='LotFrontage', y='SalePrice', data=train)\nplt.show()","35441d92":"import scipy.stats as stats","8eada361":"cat = [f for f in train.columns if train.dtypes[f] == 'object']\ndef anova(frame):\n    anv = pd.DataFrame()\n    anv['features'] = cat\n    pvals = []\n    for c in cat:\n        samples = []\n        for cls in frame[c].unique():\n            s = frame[frame[c] == cls]['SalePrice'].values\n            samples.append(s)\n        pval = stats.f_oneway(*samples)[1]\n        pvals.append(pval)\n    anv['pval'] = pvals\n    return anv.sort_values('pval')","06663f95":"cat_data['SalePrice'] = train.SalePrice.values\nk = anova(cat_data) \nk['disparity'] = np.log(1\/k['pval'].values) \nprint(k)","a1d4da61":"plt.figure(figsize=(10,6))\nsns.barplot(data=k, x = 'features', y='disparity') \nplt.xticks(rotation=90) \nplt.show()","313d685d":"#dropping id column from both train and test datsets.\ntrain=train.drop('Id',axis=1)\ntest=test.drop('Id',axis=1)","320199dc":"#dropping outliers from GrLivArea\ntrain=train[train['GrLivArea']<4000]\ntrain.reset_index(drop=True,inplace=True)","5e451b80":"#dropping outliers from TotalBsmtSF\ntrain.drop(train[train['TotalBsmtSF']>4000].index,inplace=True)","31d62110":"#dropping outliers from LotFrontage\ntrain.drop(train[train['LotFrontage']>250].index,inplace=True)\ntrain.reset_index(drop=True,inplace=True)","b32af52f":"#Now combining test and tarin datasets\ntrain['DataType']='train'\ntest['DataType']='test'\ntest['SalePrice']=np.nan","3ddf3e8f":"data=pd.concat([train,test],sort=False)\ndata.info()","43b293f6":"print(data.columns[data.isnull().any()])","501358a7":"# Missing values percentage\nmiss=data.isnull().sum()\/len(data)\nmiss=miss[miss>0]\nmiss.sort_values(inplace=True)\nmiss","dc2fc12a":"miss_col=data[['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Electrical', 'BsmtFullBath',\n       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n       'SaleType']]\nfor i in miss_col.columns:\n    print(miss_col[i].value_counts())","1f281c97":"data['MSSubClass'] = data['MSSubClass'].apply(str)\ndata.groupby('MSSubClass')['MSZoning']","f625de68":"data['MSZoning'] = data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","a8d169e8":"# imputing LotFrontage by the median of neighborhood\ndata['LotFrontage']=data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median))","fad238d6":"data=data.drop(['Alley','Utilities'],axis=1)","5c203466":"data['Exterior1st']=data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd']=data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])","10e97538":"data['MasVnrArea']=data['MasVnrArea'].fillna(0)","601a1ea8":"data['MasVnrType']=data.groupby('MasVnrArea')['MasVnrType'].transform(lambda x:x.fillna(x.mode()[0]))","281e247f":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    data[col] = data[col].fillna('None')","fcc4ced7":"for col in ('BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF'):\n    data[col] = data[col].fillna(0)","f55a05c5":"data['Electrical']=data['Electrical'].fillna(data['Electrical'].mode()[0])","a4104a85":"for col in ('BsmtHalfBath','BsmtFullBath'):\n    data[col] = data[col].fillna(0)","68423a37":"for col in ('KitchenQual', 'Functional', 'FireplaceQu'):\n    data[col]=data[col].fillna(data[col].mode()[0])\n    \nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    data[col] = data[col].fillna(0)\n\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    data[col] = data[col].fillna('None')","f7c709b8":"data=data.drop(['PoolQC', 'Fence', 'MiscFeature'],axis=1)","3eb59ca1":"data['SaleType']=data['SaleType'].fillna(data['SaleType'].mode()[0])","99330832":"data.columns[data.isnull().any()]","9eb062cd":"data['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['has2ndfloor'] = data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasbsmt'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","73953e98":"data['Total_sqr_footage'] = (data['BsmtFinSF1'] + data['BsmtFinSF2'] +\n                                 data['1stFlrSF'] + data['2ndFlrSF'])\n\ndata['Total_Bathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) +\n                               data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))\n\ndata['Total_porch_sf'] = (data['OpenPorchSF'] + data['3SsnPorch'] +\n                              data['EnclosedPorch'] + data['ScreenPorch'] +\n                              data['WoodDeckSF'])","d92efa52":"data=data[['SalePrice','OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','YearBuilt',\n           'YearRemodAdd','GarageYrBlt','MasVnrArea','Fireplaces','BsmtFinSF1','YrSold','OverallCond','MSSubClass',\n           'EnclosedPorch','KitchenAbvGr','Neighborhood','ExterQual','KitchenQual','Foundation','HeatingQC','SaleCondition',\n           'Exterior1st','Exterior2nd','SaleType','MSZoning','HouseStyle','LotShape','CentralAir','PavedDrive','RoofStyle',\n           'haspool','has2ndfloor','hasgarage','hasbsmt','hasfireplace','Total_sqr_footage','Total_Bathrooms','Total_porch_sf','DataType']]","5f3a6b46":"cat_cols=data.select_dtypes(['object']).columns\ncat_cols","278869a4":"cat_cols=cat_cols[:-1]\ncat_cols","7872c508":"# Doing dummification\nfor col in cat_cols:\n    freqs=data[col].value_counts()\n    k=freqs.index[freqs>20][:-1]\n    for cat in k:\n        name=col+'_'+cat\n        data[name]=(data[col]==cat).astype(int)\n    del data[col]\n    print(col)","384ce20c":"data.shape","ff2eae34":"data_train=data[data['DataType']=='train']\ndel data_train['DataType']\ndata_test=data[data['DataType']=='test']\ndata_test.drop(['SalePrice','DataType'],axis=1,inplace=True)","6e552da2":"print('Train Shape',data_train.shape)\nprint('Test Shape',data_test.shape)","25039c54":"del data","6f98a215":"data_train['SalePrice']=np.log(data_train['SalePrice'])","c80b4d99":"X=data_train.drop('SalePrice',axis=1)\ny=data_train['SalePrice']","94a7afd9":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.22,random_state=1)","ca9478b4":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","fb3be0c7":"dt=DecisionTreeRegressor()\nparameters = {'max_depth':range(1,10)},{'min_samples_split': (0.1,0.2,0.3,0.4,0.5)},\n{'min_samples_leaf': range(1,10)},{'min_weight_fraction_leaf': (0.0,0.1,0.2)}\ngrid_obj = GridSearchCV(dt, param_grid = parameters)\ngrid_fit = grid_obj.fit(X_train,y_train)\n\nbest_dt = grid_fit.best_estimator_\nbest_dt","90aa389e":"dt1=DecisionTreeRegressor(criterion='mse', max_depth=6, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=None, splitter='best')\ndt1.fit(X_train,y_train)\nprint('Decision Tree Training Score :',dt1.score(X_train,y_train))\nprint('Decision Tree Testing Score :',dt1.score(X_test,y_test))","4ffd544a":"y_pred=np.floor(np.exp(dt1.predict(data_test)))","f5537de5":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","9cc96a76":"score = []\nfor k in range(1,100):   # running for different K values to know which yields the max accuracy. \n    clf = KNeighborsRegressor(n_neighbors = k,  weights = 'distance', p=1)\n    clf.fit(X_train, y_train)\n    score.append(clf.score(X_test, y_test ))","c7594447":"k_max = score.index(max(score))+1\nprint( \"At K = {}, Max Accuracy = {}\".format(k_max, max(score)*100))","6975490a":"knn=KNeighborsRegressor(n_neighbors=7,weights='distance')\nknn.fit(X_train,y_train)\nprint('KNN Training Score :',knn.score(X_train,y_train))\nprint('KNN Testing Score :',knn.score(X_test,y_test))","396cafe2":"rfg=RandomForestRegressor(random_state=1)","c3d460d0":"estimators = np.arange(10, 200, 2)\nscores = []\nfor n in estimators:\n    rfg.set_params(n_estimators=n)\n    rfg.fit((X_train), y_train)\n    scores.append(rfg.score((X_test), y_test))\nprint(scores)","08ffcf8c":"estimators[scores.index(max(scores))]","154675e4":"param_dist = {'n_estimators': [48,64],'max_depth': [2, 3, 4,10],'bootstrap': [True, False],\n              'max_features': ['auto', 'sqrt', 'log2', None],\n              'criterion': ['mse', 'mae']}\n\ncv_rf = GridSearchCV(rfg, cv = 5 ,param_grid=param_dist, n_jobs = 3)\ncv_rf.fit(X_train,y_train)\nprint('RF Training Score :',cv_rf.score(X_train,y_train))\nprint('RF Testing Score :',cv_rf.score(X_test,y_test))","57fc0526":"y_pred=np.floor(np.exp(cv_rf.predict(data_test)))","abdec75f":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","0324cb7e":"learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingRegressor(n_estimators=100, learning_rate = learning_rate, max_depth = 2, random_state = 1)\n    gb.fit(X_train, y_train)\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n    print()","b4565e7f":"gb = GradientBoostingRegressor(n_estimators=100, learning_rate = 0.1, max_depth = 2, random_state = 1)\ngb.fit(X_train, y_train)\nprint('RF Training Score :',gb.score(X_train,y_train))\nprint('RF Testing Score :',gb.score(X_test,y_test))","713a113a":"y_pred=np.floor(np.exp(gb.predict(data_test)))","e433623a":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","aa3cd87f":"from xgboost import XGBRegressor","dad01776":"xgb=XGBRegressor(max_depth=5)\nxgb.fit(X_train,y_train)\nprint('XGB Training Score :',xgb.score(X_train,y_train))\nprint('XGB Testing Score :',xgb.score(X_test,y_test))","e145b197":"y_pred=np.floor(np.exp(xgb.predict(data_test)))","f3d3d744":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","a22563cf":"lambdas=np.linspace(0.001,2,100)\nparams={'alpha':lambdas}\nls=Lasso(fit_intercept=True)","3493fc3f":"grid_search=GridSearchCV(ls,param_grid=params,cv=10,scoring='neg_mean_squared_error')\ngrid_search.fit(X_train,y_train)\n\nlasso=grid_search.best_estimator_\nlasso","ccbe0137":"lasso.fit(X_train,y_train)","4dfc7a7f":"print('Lasso Training Score :',lasso.score(X_train,y_train))\nprint('Lasso Testing Score :',lasso.score(X_test,y_test))","34491f78":"y_pred=np.floor(np.exp(lasso.predict(data_test)))","b5e461c3":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","231fcdd3":"rg=Ridge(fit_intercept=True)\ngrid_search=GridSearchCV(rg,param_grid=params,cv=10,scoring='neg_mean_squared_error')\ngrid_search.fit(X_train,y_train)\n\nridge=grid_search.best_estimator_\nridge","8330aea9":"ridge.fit(X_train,y_train)","cf0ed561":"print('Ridge Training Score :',ridge.score(X_train,y_train))\nprint('Ridge Testing Score :',ridge.score(X_test,y_test))","a77d3ddf":"y_pred=np.floor(np.exp(ridge.predict(data_test)))","493406fc":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","eb2d1950":"rcv=RidgeCV(alphas=np.arange(0.001,1,0.001),store_cv_values=True)\nrcv.fit(X_train,y_train)\nprint('RidgeCV Training Score :',rcv.score(X_train,y_train))\nprint('RidgeCV Testing Score :',rcv.score(X_test,y_test))","abdfac89":"lightgbm = LGBMRegressor(objective='regression', num_leaves=6,learning_rate=0.01, n_estimators=7000,max_bin=200, \n                         bagging_fraction=0.8,bagging_freq=4, bagging_seed=8,feature_fraction=0.2,feature_fraction_seed=8,\n                         min_sum_hessian_in_leaf = 11,verbose=-1,random_state=42)\nlightgbm.fit(X_train,y_train)","e7ebb819":"print('LGBM Training Score :',lightgbm.score(X_train,y_train))\nprint('LGBM Testing Score :',lightgbm.score(X_test,y_test))","f7964cc8":"y_pred=np.floor(np.exp(lightgbm.predict(data_test)))","cc65eba3":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","7b169d77":"from mlxtend.regressor import StackingCVRegressor","6a50eab2":"stregr = StackingCVRegressor(regressors=(ridge,lasso,lightgbm,xgb,gb), \n                           meta_regressor=lasso,use_features_in_secondary=True)\n","ddea280b":"stregr.fit(X_train,y_train)","4d0bd323":"print('StackGen Training Score :',stregr.score(np.array(X_train),np.array(y_train)))\nprint('StackGen Testing Score :',stregr.score(np.array(X_test),np.array(y_test)))","97606980":"y_pred=np.floor(np.exp(stregr.predict(np.array(data_test))))","3c4deab5":"#sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':y_pred})\n#sub.to_csv('submission.csv',index=False)","4d7c6cd2":"def blended_predictions(data_test):\n    return ((0.2 * ridge.predict(data_test)) + \\\n            (0.3 * lasso.predict(data_test)) + \\\n            (0.05 * lightgbm.predict(data_test)) + \\\n            (0.05 * xgb.predict(data_test)) + \\\n            (0.05 * gb.predict(data_test)) + \\\n            (0.05 * cv_rf.predict(data_test)) + \\\n            (0.3 * stregr.predict(np.array(data_test))))","9320cd8b":"np.exp(blended_predictions(X))","e6d874d4":"sub = pd.DataFrame({'Id':np.arange(1461,2920), 'SalePrice':np.floor(np.exp(blended_predictions(data_test)))})\nsub.to_csv('submission.csv',index=False)","d00555f3":"submission = pd.read_csv(\"submission.csv\")\nsubmission.shape","4fd991f3":"q1 = submission['SalePrice'].quantile(0.0045)\nq2 = submission['SalePrice'].quantile(0.99)","d4c0ec4e":"submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\nsubmission.to_csv(\"submission1.csv\", index=False)","9ce693e5":"submission['SalePrice'].head()","8bd5dd4d":"#ScAle Predictions\n\n#submission['SalePrice'] *= 1.001619\n#submission.to_csv(\"submission2.csv\", index=False)","d6e5b0dd":"**Inferences :**\n* Here we see that the OverallQual feature is 79% correlated with the target variable. Overallqual feature refers to the overall material and quality of the materials of the completed house.\n* GrLivArea is 70% correlated with the target variable. GrLivArea refers to the living area (in sq ft.) above ground.\n* The following variables show people also care about if the house has a garage, the area of that garage, the size of the basement area, etc. ","02d34035":"From the last row, we can notice the correlation of all variables against SalePrice.Here a numeric correlation score will help us understand.","b5b73d0e":"## Featutre Engineering :","01a11e93":"We can say that it is overfit model.","c74d4a20":"From the Statistical Analysis, we select those columns which are significant in predecting our target .","b04f3426":"## Data Pre-Processing :","831f0349":"The train and test data contains approximately equal number of rows. Since SalePrice is our target variable, there is no SalePrice column in test data.","d46d70f2":"Lets check for the correlation behavior of numerical variables.","98e00af1":"## EDA :","7f53a836":"### Blending Models :","ed219aaf":"## Model Building :","78145381":"### Gradient Boosting Regressor :","8cc1090d":"From the above hypothesis testing we can conclude that above features having diparity factor greater than 1 are statistically important.","1f8e1904":"### KNN Regressor :","dc29c2f6":"There are 38 numeric and 43 categorical columns in the train data. We should remove the Id variable from numeric data. ","b2c394cd":"### XG Boost :","0522f477":"**Transforming Target variable**","a9081ba6":"### Decision Tree :","ddf6326f":"Here, we see a direct correlation of living area with sale price.Outliers play a significant role in spoiling a model's performance. Hence, we'll get rid of it.","208d3145":"### RidgeCV :","e746b00d":"# HOUSE PRICES :","ebb91a21":"As the overall quality of a house increases, its sale price also increases.Let's visualize the next correlated variable GrLivArea and understand their behavior. ","c40df529":"### Lasso :","df14110a":"### Outlier Prdeictions :","4090383e":"### Lightgbm : ","7887cf47":"Out of 81 features, 19 features have missing values. Let's check the percentage of missing values in these columns. ","f310565c":"### Stacking :","b93c1dda":"While using ANOVA, our hypothesis is as follows: \n\n* Ho - There exists no significant difference between the groups. \n* Ha - There exists a significant difference between the groups.\n\nNow, we'll define a function which calculates p values. From those p values, we'll calculate a disparity score. Higher the disparity score, better the feature in predicting sale price. ","aed6d48e":"### SalePrice:","3bf91f8e":"We see that the target variable SalePrice has a right-skewed distribution. We'll need to log transform this variable so that it becomes normally distributed.","0312c04f":"### Random Forest Regressor :","cf3e1c7e":"Before performing the exploratory data analysis,lets check for the details of category and numerical variables.","4fa9e606":"From above plots we can infere that the features 'LotFronatge','GrLivArea' and 'TotalBsmtSF' consists outliers.","3b673582":"We can infer that the variable PoolQC has 99.5% missing values followed by MiscFeature, Alley, and Fence. ","6035c6d2":"Lets check for the details of OverallQual variable.","798a5373":"### Ridge :"}}