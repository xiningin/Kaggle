{"cell_type":{"97dcff07":"code","228fa9b1":"code","dc294b5c":"code","22a1e658":"code","785f4954":"code","58af2a33":"code","be1e49c3":"code","2b9be06c":"code","592e4f11":"code","544eed7f":"code","90282c2e":"code","af1378f2":"code","e2c7f688":"markdown","d5565e90":"markdown","6f6609ab":"markdown","4a9378e9":"markdown","0e7c7963":"markdown","8d4548c0":"markdown","f730d411":"markdown","32e17b9f":"markdown","f3527dd8":"markdown","0d49f942":"markdown","edca2634":"markdown","bff2cbed":"markdown"},"source":{"97dcff07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","228fa9b1":"df = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv')\ndf = df.iloc[:, :2]","dc294b5c":"df.head()","22a1e658":"df.info()","785f4954":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer=WordNetLemmatizer()\n\nfrom nltk.stem import PorterStemmer\nstemmer=PorterStemmer()","58af2a33":"stop_words = set(stopwords.words('english'))\n","be1e49c3":"# Stemming\ndf['v2'] = df['v2'].apply( lambda x: ' '.join( [ stemmer.stem(i) for i in x.split() if i.lower() not in stop_words ] ) )","2b9be06c":"#Lemmitization\ndf['v3'] = df['v2'].apply( lambda x: ' '.join( [ lemmatizer.lemmatize(i) for i in x.split() if i.lower() not in stop_words ] ) )","592e4f11":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix","544eed7f":"def modalPredictor (data, col):\n    # Sentances\n    corpus = data[col].values\n    \n    # Bag Of Words\n    bow = CountVectorizer().fit_transform(corpus).toarray()\n    \n    # Data distribution\n    X_train, X_test, y_train, y_test = train_test_split(bow, data['v1'])\n    \n    # Model initilization\n    model = MultinomialNB()\n    \n    # Training model\n    model.fit(X_train, y_train)\n    \n    # predicting the test data\n    y_pred = model.predict(X_test)\n    \n    # Accuracy and Confussion Matrix\n    print(\"Accuray: \",accuracy_score(y_test, y_pred),'\\n\\nConfusin Matrix:\\n', confusion_matrix(y_test, y_pred))\n    ","90282c2e":"modalPredictor(df.drop('v2',axis=1), \"v3\")","af1378f2":"modalPredictor(df.drop('v3',axis=1), \"v2\")","e2c7f688":"### Getting Data","d5565e90":"#### To find which is best one among stemming and lemmitization, we will run on both of them. The function **modelPredictor** will run twice, one for stemming data and one for lemmitizing data.","6f6609ab":"#### So this is the proccess for classifing SPAM or HAM SMS.","4a9378e9":"### Stemming","0e7c7963":"### Filtering data","8d4548c0":"### Lemmitizatio","f730d411":"#### In this project we, are going to predict the mssages we got as spam or ham(not spam). To do that we will be going through filtering the SMS first, then we will train the model to classify spam SMS.","32e17b9f":"# Spam Ham SMS ","f3527dd8":"#### Both of them were almost close and pretty accurate in our case. They are almost reached to ***99%***.  ","0d49f942":"### Creating a model for prediction","edca2634":"### Now we will remove verbs from the words, like going will be come go. There are two ways in this, **Stemming** and **Lemmitization**. ","bff2cbed":"#### We will first remove stop words like is, a, the, etc.., from all the SMS"}}