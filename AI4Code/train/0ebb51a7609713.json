{"cell_type":{"b8068983":"code","1d9cabfe":"code","687db688":"code","503de61b":"code","12cc7c77":"code","8655f16a":"code","3f13e876":"code","57119669":"code","0bfff4e8":"code","eb03492b":"code","40450b75":"code","d85bc069":"code","b4dcaa05":"code","1f0d34d6":"code","97732153":"code","029f2542":"code","ee4771e9":"code","cf0a9f0b":"code","ae6d522e":"code","e87b6cba":"code","638509c0":"code","8b34edb9":"code","a267d97d":"markdown","928dddb7":"markdown","a8d87324":"markdown","4b67cd44":"markdown","e69c346d":"markdown","ca31153c":"markdown","15dcddfc":"markdown","afb53fde":"markdown","fdc59743":"markdown","f17a523f":"markdown","83cc2747":"markdown","0e046439":"markdown","c8b78d32":"markdown"},"source":{"b8068983":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.options.display.float_format = '{:20,.2f}'.format\n!jupyter nbextension enable --py --sys-prefix widgetsnbextension\nimport os\nimport ast\nimport scipy.spatial\nfrom ipywidgets import interact\nfrom ipywidgets import interact\nimport ipywidgets as widgets\nimport pandas as pd\nfrom IPython.display import display\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef world_cloud(wc,species='species'):\n    mpl.rcParams['figure.figsize']=(12.0,18.0)    #(6.0,4.0)\n    mpl.rcParams['font.size']=16                #10 \n    mpl.rcParams['savefig.dpi']=100            #72 \n    mpl.rcParams['figure.subplot.bottom']=.1 \n\n\n    stopwords = set(STOPWORDS)\n\n\n    wordcloud = WordCloud(\n                              background_color='red',\n\n                              max_words=100,\n                              max_font_size=50, \n                              random_state=0\n                             ).generate(str(wc))\n\n    print(wordcloud)\n    fig = plt.figure(1)\n    plt.imshow(wordcloud)\n    plt.title(species)\n    plt.axis('off')\n    plt.show()\n\n\nfrom IPython.display import display, HTML\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words('english'))\nfrom nltk import tokenize\ndef preprocess_sentence(text):\n    text = text.replace('\/', ' \/ ')\n    text = text.replace('.-', ' .- ')\n    text = text.replace('.', ' . ')\n    text = text.replace('\\'', ' \\' ')\n    text = text.lower()\n\n    tokens = [token for token in word_tokenize(text) if token not in punctuation and token not in stop_words]\n\n    return ' '.join(tokens)","1d9cabfe":"!pip install -U sentence-transformers","687db688":"from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n#model = SentenceTransformer('bert-base-uncased')\n","503de61b":"base_comment=pd.read_csv(\"\/kaggle\/input\/nyt-comments\/CommentsMay2017.csv\",low_memory=False)\n","12cc7c77":"base_comment.parentID.unique().shape","8655f16a":"base_comment_sample=base_comment.sample(1000)\nbase_comment_sample['summary_preprocessed']=base_comment_sample['commentBody'].apply(lambda x:tokenize.sent_tokenize(x))","3f13e876":"base_comment_sample.parentID.unique().shape","57119669":"new_data_sent=base_comment_sample['summary_preprocessed'].apply(pd.Series).reset_index().melt(id_vars='index').dropna()[['index', 'value']].set_index('index')\nnew_data_sent.shape","0bfff4e8":"\nnew_data_sent=new_data_sent.merge(base_comment_sample,right_index=True,left_index=True,how='left')\nnew_data_sent['wrd_cnt']=new_data_sent['value'].str.split().str.len()\nprint(\"Total \" + str(new_data_sent.shape[0]))\nnew_data_sent_strip=new_data_sent[new_data_sent['wrd_cnt']>6]\nprint(\"wrd cnt > 6 \" + str(new_data_sent_strip.shape[0]))\nnew_data_sent_strip=new_data_sent_strip[new_data_sent_strip['wrd_cnt']<300]\nprint(\"wrd cnt < 300 \" + str(new_data_sent_strip.shape[0]))\nnew_data_sent_strip=new_data_sent_strip.reset_index(drop=True)","eb03492b":"corpus=new_data_sent_strip.value.values.tolist()\ncommentID_co=new_data_sent_strip.commentID.values.tolist()\n\nlen(corpus)","40450b75":"%%time\ncorpus_embeddings = model.encode(corpus,show_progress_bar=False)","d85bc069":"new_data_sent_strip['emb']=corpus_embeddings","b4dcaa05":"queries= [\"Stunning visuals effects\",\"This comment is toxic and bad\",\"wonderful editorial\",\"air pollution\",\"politics\"]","1f0d34d6":"# query_embeddings = model.encode([queries[0]],show_progress_bar=False)[0]\n# distances = scipy.spatial.distance.cdist([query_embeddings], new_data_sent_strip.emb.values, \"cosine\")[0]\n# new_data_sent_strip['emb']=distances\n# results = zip(range(len(distances)),commentID_co, distances)\n# results = sorted(results, key=lambda x: x[2])\n\n\n# for idx, commentID,distance in results[0:6]:\n#     sc=\"(Score: %.4f)\" % (1-distance)\n#     display(HTML(corpus[idx].strip()  +sc))\n#     display((new_data_sent_strip[new_data_sent_strip.commentID.isin([commentID])][['commentBody','commentID','parentID']]))\n# new_data_sent_strip[new_data_sent_strip.commentID.isin([idx for idx, distance in results[:6]])]","97732153":"def search_display(df,query,parent=None,model=model,corpus=corpus,closest_n=5):\n    if parent is not None:\n        df=df[df['parentID'].isin(parent)].copy()\n\n    query_embeddings = model.encode([query],show_progress_bar=False)[0]\n    distances = scipy.spatial.distance.cdist([query_embeddings], df.emb.values.tolist(), \"cosine\")[0]\n    df['distances']=distances\n    df=df.sort_values(by=['distances'],ascending=True)\n\n    df=df.drop_duplicates('commentID')\n\n    #display(df[['commentBody','commentID','parentID','value','distances']].head(closest_n))\n    display(HTML(df[['commentBody','commentID','parentID','value','distances']].head(closest_n).style.set_properties(subset=['value'], \\\n            **{'font-weight': 'bold','font-size': '12pt','text-align':\"left\",'background-color': 'lightgrey','color': 'black'}).set_table_styles(\\\n                    [dict(selector='th', props=[('text-align', 'left'),('font-size', '12pt'),('background-color', 'pink'),('border-style','solid'),('border-width','1px')])]).hide_index().render()))\n    return df[['commentBody','commentID','parentID','value','distances']].head(closest_n)\n        \n\ndef search_utility(df,mode,parent=None,queries=[\"search\"],model=model,corpus=corpus,closest_n=5):\n    if mode.lower() =='input':\n        while True:\n            query = input('your question: ')\n            if query.lower()  in [\"exit\",'break','quit']:\n                break\n            return search_display(df,query,parent,model,corpus,closest_n)\n    elif mode.lower() =='list_search':\n        for query in queries:\n            display(HTML('your question: '+str(query)))\n            return search_display(df,query,parent,model,corpus,closest_n)\n            ","029f2542":"json_res=[]\njson_res_eval=[]\nfor quey in queries:\n    ck2=search_utility(new_data_sent_strip,mode='list_search',queries=[quey],model=model,corpus=corpus,closest_n=5)\n    json_res.append(ck2.to_json())\n    json_res_eval.append(ast.literal_eval(ck2.to_json()))","ee4771e9":"json_res[0]","cf0a9f0b":"json_res_eval[0]","ae6d522e":"\njson_res=[]\njson_res_eval=[]\nfor quey in queries:\n    ck2=search_utility(new_data_sent_strip,mode='list_search',parent=[0],queries=queries,model=model,corpus=corpus,closest_n=5)\n    json_res.append(ck2.to_json())\n    json_res_eval.append(ast.literal_eval(ck2.to_json()))\n    ","e87b6cba":"#search_utility(mode='input',queries=queries,model=model,corpus=corpus,closest_n=5)","638509c0":"new_data_sent_strip['value_edit']=new_data_sent_strip['value'].apply(lambda x:preprocess_sentence(x))","8b34edb9":"wc=new_data_sent_strip['value_edit'].values.tolist()\nwc=\" \".join(wc)\nworld_cloud(wc,species='base')","a267d97d":"# Try to use smaller model if search is not extensive\n## using this roberta-base-nli-stsb-mean-tokens over roberta-large-nli-stsb-mean-tokens gives huge time boost in non gpu enviorment with similar accuracy","928dddb7":"## Taking sample","a8d87324":"# Queries to search","4b67cd44":"# converting to list","e69c346d":"## Install sentence transformers package","ca31153c":"# word cloud on comment","15dcddfc":"# Clean data for word cloud\n\n","afb53fde":"## Search functions","fdc59743":"# Creating Encoding for comments","f17a523f":"## First download a pretrained model\n\n* Model\tSTS benchmark\tSentEval\n* Avg. GloVe embeddings\t58.02\t81.52\n* BERT-as-a-service avg. embeddings\t46.35\t84.04\n* BERT-as-a-service CLS-vector\t16.50\t84.66\n* InferSent - GloVe\t68.03\t85.59\n* Universal Sentence Encoder\t74.92\t85.10\n* Sentence Transformer Models\t\t\n* bert-base-nli-mean-tokens\t77.12\t86.37\n* bert-large-nli-mean-tokens\t79.19\t87.78\n* bert-base-nli-stsb-mean-tokens\t85.14\t86.07\n* bert-large-nli-stsb-mean-tokens\t85.29\t86.66\n\nTrained on NLI data\n\nThese models were trained on SNLI and MultiNLI dataset to create universal sentence embeddings. For more details, see: nli-models.md.\n\n* bert-base-nli-mean-tokens: BERT-base model with mean-tokens pooling. Performance: STSbenchmark: 77.12\n* bert-large-nli-mean-tokens: BERT-large with mean-tokens pooling. Performance: STSbenchmark: 79.19\n* roberta-base-nli-mean-tokens: RoBERTa-base with mean-tokens pooling. Performance: STSbenchmark: 77.49\n* roberta-large-nli-mean-tokens: RoBERTa-base with mean-tokens pooling. Performance: STSbenchmark: 78.69\n* distilbert-base-nli-mean-tokens: DistilBERT-base with mean-tokens pooling. Performance: STSbenchmark: 76.97\nTrained on STS data\n\nThese models were first fine-tuned on the AllNLI datasent, then on train set of STS benchmark. They are specifically well suited for semantic textual similarity. For more details, see: sts-models.md.\n\n* bert-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.14\n* bert-large-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.29\n* roberta-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.44\n* roberta-large-nli-stsb-mean-tokens: Performance: STSbenchmark: 86.39\n* distilbert-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 84.38\nMultilingual Models\n* The following models can be used for languages other than English. The vector spaces for the included languages are aligned, i.e., two sentences are mapped to the same point in vector space independent of the language. The models can be used for cross-lingual tasks. For more details see multilingual-models.md.\n\n* distiluse-base-multilingual-cased: Supported languages: Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, Turkish. Performance on the extended STS2017: 80.1\n\nhttps:\/\/github.com\/UKPLab\/sentence-transformers","83cc2747":"# Filter on parentid","0e046439":"# Read comments data\n\n## If reading is slow please make low_memory=True","c8b78d32":"## Two modes are available\n\n### mode='list_search' search for a list of query provided in queries\n\n### mode='input' gives a user input dialog box\n\n#### json_res captures json as string variable\n\n#### json_res_eval captures json as python dict\n\nfor [api](https:\/\/stackoverflow.com\/questions\/51378617\/convert-dataframe-to-be-returned-as-application-json-in-flask-python)\n\nfrom flask import Response\n@app.route(\"\/dfjson\")\ndef dfjson():\n    \"\"\"\n    return a json representation of the dataframe\n    \"\"\"\n    df = get_dataframe_from_somewhere()\n    return Response(df.to_json(orient=\"records\"), mimetype='application\/json')"}}