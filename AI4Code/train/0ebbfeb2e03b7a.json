{"cell_type":{"f3719b61":"code","58ae03a0":"code","1919625e":"code","fc7a23a8":"code","282160b5":"code","58036bc6":"code","a56378c7":"code","4d0bcbd9":"code","1f097f3b":"code","8cf7f3aa":"code","bd29adbf":"code","9984e12c":"code","c69c3c95":"code","3d0d3134":"code","32b3f0a9":"code","4defdff2":"code","280dc149":"code","3ea5c235":"code","63fee112":"code","07a6dc83":"code","d46d4b65":"code","96e55f77":"code","96ad3ba7":"code","3140da5e":"code","ce83f1b1":"code","61e46545":"code","60feeae8":"code","59ae5d06":"code","56c24b3b":"code","3192afdf":"code","1895d9b7":"code","28f09f40":"code","605b843a":"markdown","bb14b476":"markdown","9c24ec2c":"markdown","46c16db3":"markdown","9ab3fb98":"markdown","7826d45a":"markdown","0d4ce2c8":"markdown","36308504":"markdown","de816352":"markdown","3a9532c0":"markdown","1bc761f2":"markdown","5c290084":"markdown","9ecdf198":"markdown","cfbd8387":"markdown","f14c6402":"markdown","5300212d":"markdown","2f0f967c":"markdown","9975501e":"markdown","b59f702e":"markdown"},"source":{"f3719b61":"%matplotlib inline\nimport os\nimport cv2\nimport csv\nimport glob\nimport pandas as pd\nimport numpy as np\nimport random\nimport itertools\nfrom collections import Counter\nfrom math import ceil\nimport matplotlib.pyplot as plt\n\n#Descobrir autilidade\nfrom tqdm.notebook import tqdm\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n","58ae03a0":"def skip_csv_header(file):\n    has_header = csv.Sniffer().has_header(file.read(1024))\n    file.seek(0)\n    if has_header:\n        next(file)\n\n\ndef total_image_list(image_folder_path):\n    total_img_list = [os.path.basename(img_path_name) for img_path_name in glob.glob(os.path.join(image_folder_path, \"*.jpg\"))]\n    return total_img_list\n\ndef draw_rect(img, bboxes, color=None):\n    img = img.copy()\n    bboxes = bboxes[:, :4]\n    bboxes = bboxes.reshape(-1, 4)\n    for bbox in bboxes:\n        pt1, pt2 = (bbox[0], bbox[1]), (bbox[2], bbox[3])\n        pt1 = int(pt1[0]), int(pt1[1])\n        pt2 = int(pt2[0]), int(pt2[1])\n        img = cv2.rectangle(img.copy(), pt1, pt2, color, int(max(img.shape[:2]) \/ 200))\n    return img\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=ceil(len(img_matrix_list) \/ ncols), ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()","1919625e":"train = pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/train.csv\")  \nimage_folder_path = \"\/kaggle\/input\/global-wheat-detection\/train\/\"","fc7a23a8":"bboxes = np.stack(train['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x_min', 'y_min', 'width', 'height']):\n    train[column] = bboxes[:,i]\n    \ntrain[\"x_max\"] = train.apply(lambda col: col.x_min + col.width, axis=1)\ntrain[\"y_max\"] = train.apply(lambda col: col.y_min + col.height, axis = 1)\ntrain.drop(columns=['bbox'], inplace=True)","282160b5":"# Obeservar dados \ntrain.head()","58036bc6":"train[train[\"x_max\"] > 1024]\ntrain[train[\"y_max\"] > 1024]\ntrain[train[\"x_min\"] < 0]\ntrain[train[\"y_min\"] < 0]","a56378c7":"x_max = np.array(train[\"x_max\"].values.tolist())\ny_max = np.array(train[\"y_max\"].values.tolist())\ntrain[\"x_max\"] = np.where(x_max > 1024, 1024, x_max).tolist()\ntrain[\"y_max\"] = np.where(y_max > 1024, 1024, y_max).tolist()","4d0bcbd9":"del train[\"width\"]\ndel train[\"height\"]\ndel train[\"source\"]\ntrain.head()","1f097f3b":"train[\"class\"] = \"1\"\ntrain.head()","8cf7f3aa":"def check_file_type(image_folder_path):\n    extension_type = []\n    file_list = os.listdir(image_folder_path)\n    \n    for file in file_list:\n        extension_type.append(file.rsplit(\".\", 1)[1].lower())\n    print(Counter(extension_type).keys())\n    print(Counter(extension_type).values())\n    \ncheck_file_type(image_folder_path)","bd29adbf":"train[\"image_id\"] = train[\"image_id\"].apply(lambda x: str(x) + \".jpg\")\ntrain.head()","9984e12c":"train[\"image_id\"] = train[\"image_id\"].astype(\"str\")\ntrain.to_csv(\"wheat.csv\", index=False)","c69c3c95":"def check_image_size(image_folder_path):\n    total_img_list = glob.glob(os.path.join(image_folder_path,\"*\"))\n    counter = 0\n    for image in tqdm(total_img_list, desc = \"Checking in progress\"):\n        try:\n            img = cv2.imread(image)\n            height, width = img.shape[1], img.shape[0]\n            if not (height == 1024 and width == 1024):\n                counter = counter + 1\n        except:\n            print(\"This {} is problematic.\".format(image))\n    return counter ","3d0d3134":"check_image_size(image_folder_path)","32b3f0a9":"wheat = pd.read_csv(\"wheat.csv\") \nimage_folder_path = \"\/kaggle\/input\/global-wheat-detection\/train\/\"\nimage_annotation_file = \"wheat.csv\"\nwheat.head()","4defdff2":"def sanity_tally(image_folder_path, image_annotation_file):\n    img_dict = {}\n    with open(image_annotation_file, \"r\") as file:\n        skip_csv_header(file)\n        for row in file:\n            try:\n                image_name, x_min, y_min, x_max, y_max, class_idx = row.split(\",\")\n                if image_name not in img_dict:\n                    img_dict[image_name] = list()\n                img_dict[image_name].append(\n                    [float(x_min), float(y_min), float(x_max), float(y_max), int(class_idx)]\n                )\n            except ValueError:\n                print(\"Could not convert float to string, likely that your data has empty values.\")\n        \n    img_annotation_list = [*img_dict]\n    total_img_list = total_image_list(image_folder_path)\n    if set(img_annotation_list) == set(total_img_list):\n        print(\"Sanity Check Status: True\")\n    else:\n        print(\"Sanity Check Status: Failed. \\nThe elements in wheat\/train.csv but not in the train image folder is {}. \\nThe elements in train image folder but not in wheat\/train.csv is {}\".format(\n                set(img_annotation_list) - set(total_img_list), set(total_img_list) - set(img_annotation_list)))\n        return list(set(img_annotation_list) - set(total_img_list)), list(set(total_img_list) - set(img_annotation_list))","280dc149":"set_diff1, set_diff2 = sanity_tally(image_folder_path, image_annotation_file = image_annotation_file)\n\nprint(\"There are {} images without annotations in the train\/wheat.csv\".format(len(set_diff2)))","3ea5c235":"def plot_random_images(image_folder_path, image_annotation_file, num = 12):\n    img_dict = {}\n    with open(image_annotation_file, \"r\") as file:\n        skip_csv_header(file)\n        for row in file:\n            try:\n                image_name, x_min, y_min, x_max, y_max, class_idx = row.split(\",\")\n                if image_name not in img_dict:\n                    img_dict[image_name] = list()\n                img_dict[image_name].append(\n                    [float(x_min), float(y_min), float(x_max), float(y_max), int(class_idx)]\n                )\n            except ValueError:\n                print(\"Could not convert float to string, likely that your data has empty values.\")\n\n    # randomly choose 12 images to plot\n    img_files_list = np.random.choice(list(img_dict.keys()), num)\n    print(\"The images' names are {}\".format(img_files_list))\n    img_matrix_list = []\n    \n    for img_file in img_files_list:\n        image_file_path = os.path.join(image_folder_path, img_file)\n        img = cv2.imread(image_file_path)[:,:,::-1]  \n        img_matrix_list.append(img)\n\n    \n    return plot_multiple_img(img_matrix_list, title_list = img_files_list, ncols = 4, main_title=\"Wheat Images\")","63fee112":"plot_random_images(image_folder_path, image_annotation_file, num = 12)","07a6dc83":"def random_bbox_check(image_folder_path, image_annotation_file, num = 12):\n    img_dict = {}\n    labels = [\"wheat\", \"no wheat\"]\n    with open(image_annotation_file, \"r\") as file:\n        skip_csv_header(file)\n        for row in file:\n            try:\n                image_name, x_min, y_min, x_max, y_max, class_idx = row.split(\",\")\n                if image_name not in img_dict:\n                    img_dict[image_name] = list()\n                img_dict[image_name].append(\n                    [float(x_min), float(y_min), float(x_max), float(y_max), int(class_idx)]\n                )\n            except ValueError:\n                print(\"Could not convert float to string, likely that your data has empty values.\")\n\n    # randomly choose 12 image.\n    img_files_list = np.random.choice(list(img_dict.keys()), num)\n    print(\"The images' names are {}\".format(img_files_list))\n    image_file_path_list = []\n\n    bbox_list = []\n    img_matrix_list = []\n    random_image_matrix_list = []\n    \n    for img_file in img_files_list:\n        image_file_path = os.path.join(image_folder_path, img_file)\n        img = cv2.imread(image_file_path)[:,:,::-1]  \n        height, width, channels = img.shape\n        bbox_list.append(img_dict[img_file])\n        img_matrix_list.append(img)\n\n    \n    final_bbox_list = []\n    for bboxes, img in zip(bbox_list, img_matrix_list):\n        final_bbox_array = np.array([])\n        #bboxes is a 2d array [[...], [...]]\n        for bbox in bboxes:\n            bbox = np.array(bbox).reshape(1,5)\n            final_bbox_array = np.append(final_bbox_array, bbox)\n        final_bbox_array = final_bbox_array.reshape(-1,5)\n        random_image = draw_rect(img.copy(), final_bbox_array.copy(), color = (255,0,0))\n        random_image_matrix_list.append(random_image)\n    plot_multiple_img(random_image_matrix_list, title_list = img_files_list, ncols = 4, main_title=\"Bounding Box Wheat Images\")","d46d4b65":"#Aplicar\nrandom_bbox_check(image_folder_path, image_annotation_file)","96e55f77":"# Albumentations\nimport albumentations as A","96ad3ba7":"image_folder_path = \"\/kaggle\/input\/global-wheat-detection\/train\/\"\nchosen_image = cv2.imread(os.path.join(image_folder_path, \"1ee6b9669.jpg\"))[:,:,::-1]\nplt.imshow(chosen_image)","3140da5e":"chosen_image_dataframe = wheat.loc[wheat[\"image_id\"]==\"1ee6b9669.jpg\",[\"x_min\",\"y_min\",\"x_max\",\"y_max\",\"class\"]]\nbbox_array_of_chosen_image = np.array(chosen_image_dataframe.values.tolist())\nbbox_array_of_chosen_image.shape","ce83f1b1":"draw_chosen_image = draw_rect(chosen_image.copy(), bbox_array_of_chosen_image.copy(), color = (255,0,0))\nplt.imshow(draw_chosen_image)","61e46545":"albumentation_list = [A.RandomSunFlare(p=1), A.RandomFog(p=1), A.RandomBrightness(p=1),\n                      A.RandomCrop(p=1,height = 512, width = 512), A.Rotate(p=1, limit=90),\n                      A.RGBShift(p=1), A.RandomSnow(p=1),\n                      A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.RandomContrast(limit = 0.5,p = 1),\n                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]\n\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"RandomSunFlare\",\"RandomFog\",\"RandomBrightness\",\n               \"RandomCrop\",\"Rotate\", \"RGBShift\", \"RandomSnow\",\"HorizontalFlip\", \"VerticalFlip\", \"RandomContrast\",\"HSV\"]\n\n##reminder of helper function\ndef plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title=\"Different Types of Augmentations\")","60feeae8":"chosen_image = cv2.imread(os.path.join(image_folder_path, \"1ee6b9669.jpg\"))[:,:,::-1]\nchosen_image_dataframe = wheat.loc[wheat[\"image_id\"]==\"1ee6b9669.jpg\",[\"x_min\",\"y_min\",\"x_max\",\"y_max\"]]\nbbox_array_of_chosen_image = np.array(chosen_image_dataframe.values.tolist())\nlabels_of_chosen_image = np.ones((len(bbox_array_of_chosen_image),))","59ae5d06":"def draw_rect_with_labels(img, bboxes,class_id, class_dict, color=None):\n    img = img.copy()\n    bboxes = bboxes[:, :4]\n    bboxes = bboxes.reshape(-1, 4)\n    for bbox, label in zip(bboxes, class_id):\n        pt1, pt2 = (bbox[0], bbox[1]), (bbox[2], bbox[3])\n        pt1 = int(pt1[0]), int(pt1[1])\n        pt2 = int(pt2[0]), int(pt2[1])\n        class_name = class_dict[label]\n        ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1) \n        img = cv2.rectangle(img.copy(), pt1, pt2, color, int(max(img.shape[:2]) \/ 200))\n        img = cv2.putText(img.copy(), class_name, (int(bbox[0]), int(bbox[1]) - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color = (255,255,255), lineType=cv2.LINE_AA)\n    return img","56c24b3b":"ver_flip = A.Compose([\n        A.VerticalFlip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n\nver_flip_annotations = ver_flip(image=chosen_image, bboxes=bbox_array_of_chosen_image, labels=labels_of_chosen_image)\nver_flip_annotations['bboxes'] = [list(bbox) for bbox in ver_flip_annotations['bboxes']]","3192afdf":"ver_flip = A.Compose([\n        A.VerticalFlip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n\nver_flip_annotations = ver_flip(image=chosen_image, bboxes=bbox_array_of_chosen_image, labels=labels_of_chosen_image)\nver_flip_annotations['bboxes'] = [list(bbox) for bbox in ver_flip_annotations['bboxes']]","1895d9b7":"hor_flip = A.Compose([\n        A.HorizontalFlip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n\nhor_flip_annotations = hor_flip(image=chosen_image, bboxes=bbox_array_of_chosen_image, labels=labels_of_chosen_image)\nhor_flip_annotations['bboxes'] = [list(bbox) for bbox in hor_flip_annotations['bboxes']]\n\n\nhor_flip_img = draw_rect_with_labels(img = hor_flip_annotations['image'], bboxes = np.array(hor_flip_annotations['bboxes']),\n                          class_id = hor_flip_annotations['labels'], class_dict = {0: \"background\",1: \"wheat\"}, color=(255,0,0))\n    \nimg_matrix_list = [draw_chosen_image, hor_flip_img]\ntitles_list = [\"Original\", \"HorizontalFlipped\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 2,main_title=\"Horizontal Flip\")","28f09f40":"transform = A.Compose([\n    A.CoarseDropout(max_height=100, max_width=100, p = 1),\n    A.RandomBrightnessContrast(p=0.9),\n    A.HueSaturationValue(\n                        hue_shift_limit=0.2,\n                        sat_shift_limit=0.2,\n                        val_shift_limit=0.2,\n                        p=0.9,\n                        )\n])\nchosen_image = cv2.imread(os.path.join(image_folder_path, \"1ee6b9669.jpg\"))[:,:,::-1]\naugmented_image = transform(image=chosen_image)['image']\nplt.imshow(augmented_image)","605b843a":"# 3. Verifique se h\u00e1 imagens corrompidas e se todas as imagens s\u00e3o 1.024 por 1.024","bb14b476":"Como podemos ver acima, existem 49 imagens sem anota\u00e7\u00f5es de caixa delimitadora porque elas n\u00e3o t\u00eam trigos na imagem e, portanto, n\u00e3o aparecem no train.csv. Pode ser uma ideia colocar essas 49 imagens dentro do train.csv e rotul\u00e1-las como 0.","9c24ec2c":"# 1.Ler e carregar o conjunto de dados","46c16db3":"# 2. Verifique se as extens\u00f5es de imagem s\u00e3o todas jpg\n\nPrimeiro, verificamos se todas as imagens da pasta train est\u00e3o no formato .jpg. \u00c9 melhor verificar porque se houver uma mistura de tipos de imagem, podemos enfrentar problemas mais tarde.","9ab3fb98":"## 1.2. Verifica\u00e7\u00e3o de alcance nas coordenadas das bounding boxes\n\nVerifica\u00e7\u00e3o de intervalo na coordenada da caixa delimitadora Al\u00e9m disso, devido aos problemas internos de flutua\u00e7\u00e3o do python, pode haver valores estranhos como valores negativos ou que somam mais de 1024 em x_max, y_max. Precisamos ter cuidado aqui.\n\nEste \u00e9 um problema s\u00e9rio que pode ocorrer quando voc\u00ea normaliza a caixa delimitadora, pode exceder 1 e isso causar\u00e1 um erro, especialmente se voc\u00ea decidir aumentar as imagens tamb\u00e9m.","7826d45a":"\u00d3timo, na verdade todas as nossas imagens t\u00eam tamanho de 1024 x 1024. E o bom \u00e9 que esse c\u00f3digo tamb\u00e9m nos ajuda a verificar se h\u00e1 imagens corrompidas, portanto, se houver uma imagem corrompida, com certeza ir\u00e1 mostrar que o contador \u00e9 diferente de zero. E a partir da\u00ed voc\u00ea pode verificar qual imagem est\u00e1 causando o problema.","0d4ce2c8":"Aqui vemos uma bela grade de 12 imagens plotadas.","36308504":"Neste kernel, apresento algumas fun\u00e7\u00f5es utilit\u00e1rias para fazer uma verifica\u00e7\u00e3o de sanidade em imagens, bem como algumas fun\u00e7\u00f5es que voc\u00ea pode reutilizar para projetos futuros quando quiser plotar v\u00e1rias imagens em uma grade. Uma pr\u00e9via de como um gr\u00e1fico de caixa delimitadora m\u00faltipla \u00e9 assim:\n\n![](https:\/\/i.ibb.co\/9GXMpWT\/img.png)","de816352":"# Bibliotecas","3a9532c0":"## 1.1. Bounding boxes","1bc761f2":"Bom, parece que todas as nossas imagens na pasta est\u00e3o no formato .jpg. Em seguida, \u00e9 melhor anexar .jpg atr\u00e1s de todo o image_id no dataframe. Isso nos tornar\u00e1 mais f\u00e1cil manipular os dados posteriormente.","5c290084":"A \u00fanica raz\u00e3o pela qual, por exemplo, a linha 31785 tem x_max mais de 1024, \u00e9 devido \u00e0 rotulagem do conjunto de dados original. Vejamos as respectivas linhas problem\u00e1ticas. Por exemplo, na linha 31785, o x_min fornecido \u00e9 873,200012, e quando voc\u00ea adiciona isso \u00e0 largura de 150,800003, fornece 1024,000015, que j\u00e1 excede o tamanho da imagem. Ent\u00e3o voc\u00ea tem que arredondar para baixo. E, tanto quanto eu sinto, as caixas delimitadoras, quando desnormalizadas, devem ser em n\u00fameros inteiros. Mas esta \u00e9 apenas a minha opini\u00e3o. Vamos mudar esses valores problem\u00e1ticos para 1024","9ecdf198":"Podemos deletar colunas de largura e altura porque n\u00e3o precisamos delas, pode ser facilmente retirado das pr\u00f3prias imagens.","cfbd8387":"# 6. Plotagem de v\u00e1rias imagens com caixas delimitadoras\n\nNa detec\u00e7\u00e3o de objetos com caixas delimitadoras, \u00e9 sempre uma boa ideia plotar aleatoriamente algumas imagens com suas caixas delimitadoras para verificar as coordenadas incorretas da caixa delimitadora. Embora eu deva dizer que nesta competi\u00e7\u00e3o em particular, h\u00e1 muitas imagens com muitas caixas delimitadoras e, portanto, voc\u00ea deve examinar claramente.","f14c6402":"# Fun\u00e7\u00f5es \u00fateis","5300212d":"# 8. Caixas delimitadoras com albumenta\u00e7\u00f5es\n\nLembre-se de que estamos usando nossa imagem escolhida como exemplo, por conveni\u00eancia, vou lembr\u00e1-lo da matriz de imagem de imagens escolhidas e suas coordenadas de caixas delimitadoras abaixo. Mas h\u00e1 uma advert\u00eancia aqui, minha matriz de caixas delimitadoras tem a forma [N, 5], onde o \u00faltimo elemento s\u00e3o os r\u00f3tulos. Mas quando voc\u00ea quiser usar Albumentations para plotar caixas delimitadoras, use bboxes no formato de pascal_voc que \u00e9 [x_min, y_min, x_max, y_max]; ele tamb\u00e9m leva em label_fields que s\u00e3o os r\u00f3tulos de cada caixa delimitadora. Portanto, ainda precisamos fazer um pr\u00e9-processamento simples abaixo.","2f0f967c":"# 4. Verifica\u00e7\u00e3o de sanidade entre o csv do trem e as imagens do treino \nWe will write a function to check if the number of unique image_ids match the number of unique images in the folder.","9975501e":"# 5. Plotando v\u00e1rias imagens\nHere we define a nice function that is useful not only for this competition, but for similar project as well. Note that we used our utility function here to plot them. One can tune the parameters accordingly.","b59f702e":"# 7. Aumentos\n\nO aumento \u00e9 uma t\u00e9cnica importante para aumentar artificialmente o tamanho dos dados. Em particular, quando o conjunto de dados \u00e9 pequeno, o aumento antes do treinamento do modelo ajudar\u00e1 a rede a aprender melhor."}}