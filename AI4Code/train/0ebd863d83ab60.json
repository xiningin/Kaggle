{"cell_type":{"4091f240":"code","6fe66b66":"code","6e3a7c42":"code","7f9d9a1f":"code","7b9ce23d":"code","adb04090":"code","3a607e43":"code","a329a2d1":"code","204d3cfb":"code","fbeff750":"code","d6c89acd":"code","6f495669":"code","9c747e62":"markdown"},"source":{"4091f240":"import os\nimport cv2\nimport numpy as np \nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt \nfrom random import shuffle , seed\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg19 import VGG19 \nfrom tensorflow.keras.applications   import EfficientNetB3\nfrom tensorflow.keras.applications.densenet import DenseNet201 \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input ,concatenate, Dense,Flatten ,Conv2D ,Dropout ,MaxPool2D ,GlobalAveragePooling2D","6fe66b66":"classes=[\"WithMask\",\"WithoutMask\"]\nclasses.sort()\nprint(classes)","6e3a7c42":"classes={\n0:\"WithMask\",\n1:\"WithoutMask\",\n\n}\n\n\n#function to get code by name \ndef get_code(name):\n    for key , value in classes.items():\n        if value ==name:\n            break\n    return key\n\n\n#function to get name by code\ndef get_class(key):\n    return classes[key]\n\n\n#test\nprint(\"WithMask:\", get_code(\"WithMask\"))\nprint(\"0 :\" ,get_class(0))\n\n\n","7f9d9a1f":"image_size=224\n\ngenerator=ImageDataGenerator(\n       rescale=1.\/255.0,\n      rotation_range=40,\n      width_shift_range=0.1,\n      height_shift_range=0.1,\nvertical_flip=True,\n    zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest'\n)\n\nbatch_size=32                                               \ntrain_generator=generator.flow_from_directory(\n    \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\",\n    target_size=(image_size, image_size),\n    batch_size=32,\n    shuffle=True,\n\n)\n\n\nval_generator=ImageDataGenerator(rescale=1.\/255.0).flow_from_directory(\n    \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\",\n     \n\n    target_size=(image_size, image_size),\n\n    batch_size=32,\n    shuffle=True,\n\n)\n\ntest_generator=ImageDataGenerator(rescale=1.\/255.0).flow_from_directory(\n    \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\",\n     \n\n    target_size=(image_size, image_size),\n\n    batch_size=32,\n    shuffle=True,\n\n)","7b9ce23d":"#function to show images\ndef image_show(data, labels , number_of_image ):\n    #to generate a random numbers\n    numbers=np.random.randint(0,len(data),number_of_image)\n    plt.figure(figsize=(30,20))\n    j = number_of_image\/10\n    for _,i in enumerate(numbers):\n        plt.subplot(j+1,8,_+1)\n        plt.imshow(data[i])\n        plt.title(get_class(labels[i])+\"\\n\"+f\"size {data[i].shape}\")\n        #to remove the number that appear around image\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n","adb04090":"# np.argmax(train_labels , axis=1)","3a607e43":"\n#get data for generator\ntrain_images=train_generator.__getitem__(0)[0]\ntrain_labels=train_generator.__getitem__(0)[1]\n#get the label number\nlab=np.argmax(train_labels, axis=1)\n#show train generator\nimage_show(train_images,lab,40)","a329a2d1":"\ndenenet_model=VGG19(weights=\"imagenet\", include_top=False , input_shape=(image_size,image_size,3) )\n\n    \n    \ndenenet_model.summary()\n\n\n\nx=GlobalAveragePooling2D()(denenet_model.output)\nx=Dense(1024, activation=\"relu\")(x)\n\n\nx=Dense(256, activation=\"relu\")(x)\n\nx=Dense(128, activation=\"relu\")(x)\n\nx=Dense(64, activation=\"relu\")(x)\n\noutput=Dense(2, activation=\"softmax\")(x)\n\nmodel=Model(inputs=denenet_model.input, outputs=output)\nmodel.summary()\n\n# #plot model\n# from tensorflow.python.keras.utils.vis_utils import plot_model\n# plot_model(model, show_shapes=True, show_layer_names=True , to_file=\"model.png\")\n\n","204d3cfb":"#callbacks\ncallbacks_denseNet=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=5, verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(\"faceMakModel.h5\" , save_best_only=True, verbose=1),\n#  lr_rate\n    ]\n\n\n\n#training Densenet Model\n\n# check t batch size is 32\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001 , epsilon=1e-07) , \n              loss=tf.keras.losses.binary_crossentropy , \n              metrics=[\"accuracy\"])\n\nDenseNet_history=model.fit(\n          train_generator  , \n          epochs=5   , \n#           steps_per_epoch=x_train.shape[0]\/batch_size ,\n          validation_data=val_generator,\n          verbose=1 ,\n          callbacks=callbacks_denseNet\n               )\n","fbeff750":"print(\"- the Accuracy and Loss for Vgg16 Model With 10 Epochs\")\nplt.figure(figsize=(40,20))\n# summarize history for accuracy \nplt.subplot(5,5,1)\nplt.plot(DenseNet_history.history['accuracy'])\nplt.plot(DenseNet_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','validation'], loc='upper left')\n\n\n\n# summarize history for loss\nplt.subplot(5,5,2)\nplt.plot(DenseNet_history.history['loss'])\nplt.plot(DenseNet_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','loss'], loc='upper left')\nplt.show()","d6c89acd":"#evaluate \nprint('evaluate')\nmodel.evaluate(train_generator ), model.evaluate( val_generator), model.evaluate( test_generator)","6f495669":"#to download output files \nimport os\nos.chdir(r'..\/working')\nfrom IPython.display import FileLink\nFileLink(r'.\/faceMakModel.h5')","9c747e62":"with 99 acuracy"}}