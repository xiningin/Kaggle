{"cell_type":{"e543e308":"code","17131d95":"code","834d3f08":"code","40d00ff6":"code","e71b3203":"code","bf40b736":"code","0b744270":"code","4a6e3f2b":"code","44fd2e4f":"code","73be8fe0":"code","2a70ee98":"code","5953b922":"code","5824e590":"code","f41f0f03":"code","5b8055e1":"code","199da210":"code","be0e1b72":"code","76835fb1":"code","ace19f9e":"code","cd317b8a":"code","28761d7b":"code","080001b9":"code","56b5fd5c":"code","e8418d77":"code","6b452a49":"code","b2ca7aa4":"code","66ff2ece":"code","c8a38302":"code","589f8992":"code","0ceeb4a0":"code","35526338":"code","a7bb1c8d":"code","89930dc4":"code","1a2d52f6":"code","2464020d":"code","74311e5b":"code","2d2e00e2":"code","caf26e6f":"code","90248560":"code","b7b49f52":"code","e8dca3b8":"code","61a4ed23":"code","452b1551":"code","666aa05b":"code","d7cb7a51":"code","b16a1d4e":"code","1bc65d26":"code","3676189b":"code","8ea728f6":"markdown","dae91620":"markdown","92e17e50":"markdown","0fbf4d2f":"markdown","0781334f":"markdown","5c561f05":"markdown"},"source":{"e543e308":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17131d95":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport warnings\nfrom sklearn import preprocessing\nwarnings.filterwarnings(\"ignore\")\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.linear_model import LinearRegression\n","834d3f08":"df = pd.read_csv('..\/input\/car-mileage-prediction\/mtcars.csv', error_bad_lines=False, engine ='python')\ndf","40d00ff6":"\ndf.shape","e71b3203":"df.skew()","bf40b736":"df.duplicated().sum()","0b744270":"df.columns","4a6e3f2b":"df.describe()","44fd2e4f":"df.isnull().sum()","73be8fe0":"df.corr()","2a70ee98":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        ","5953b922":" def Head(value=5):\n            print('\\033[1m'+'displaying the', value, 'rows'+'\\033[0m')\n            a=df.head(value)\n            return a\n            print(\"--------------------------------------------------------------------------\")\nHead()","5824e590":"def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()","f41f0f03":"def Column_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    c=df.columns\n    print(c,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nColumn_names()","5b8055e1":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","199da210":"def Size():\n    print('\\033[1m'+\"The size of dataset is :\"+'\\033[0m')\n    siz=df.size\n    print(siz,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nSize()","be0e1b72":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()","76835fb1":"def ISNULL():\n    print('\\033[1m'+\"Detection of missing values\"+'\\033[0m')\n    co2=df.isnull().sum()\n    print(co2,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nISNULL()","ace19f9e":"def Ndim():\n    print('\\033[1m'+\"The dimensions of data set are:\"+'\\033[0m')\n    co4=df.ndim\n    print(co4,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNdim()","cd317b8a":"def Nunique():\n    print('\\033[1m'+\"Total number of unique values are:\"+'\\033[0m')\n    co5=df.nunique()\n    print(co5,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNunique()","28761d7b":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","080001b9":"def Duplicated():\n    print('\\033[1m'+\"Total number of duplicate rows\"+'\\033[0m')\n    co7=df.duplicated().count()\n    return(co7)\n    print(\"--------------------------------------------------------------------------\")\nDuplicated()","56b5fd5c":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","e8418d77":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","6b452a49":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","b2ca7aa4":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     ","66ff2ece":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","c8a38302":"df.columns","589f8992":"#taking only numerical columns in list x for plotting distribution plot\nk=df.drop(['C_name'],axis=1)","0ceeb4a0":"for i in k.columns:\n    sns.distplot(df[i],kde=True)\n    plt.show()","35526338":"\nsns.histplot(data=k)\nplt.show()","a7bb1c8d":"print(k.columns)\nfor i in k.columns:\n    sns.boxplot(data=k,x=i)\n    plt.show()","89930dc4":"plt.figure(figsize=(10,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","1a2d52f6":"for i in k.columns:\n    x= df['C_name']\n    y= df[i]\n    data = go.Bar(x= x,y= y)\n    layout = go.Layout(title = 'CARS DATA')\n    fig = go.Figure(data=data,layout=layout)\n    fig.show()","2464020d":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    # label_encoder object knows how to understand word labels.\n    label_encoder = preprocessing.LabelEncoder()\n \n    # Encode labels in column 'species'.\n    df[c1]= label_encoder.fit_transform(df[c1])\n \n    df[c1].unique()\n    return df","74311e5b":"df.columns","2d2e00e2":"LABEL_ENCODING('C_name')","caf26e6f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df)","90248560":"feature=df\nfeature=feature.drop('mpg',axis=1)","b7b49f52":"label=df['mpg']","e8dca3b8":"X_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)","61a4ed23":"print(X_train.shape,y_train.shape)","452b1551":"print(X_test.shape,y_test.shape)","666aa05b":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","d7cb7a51":"forest= RandomForestRegressor(n_estimators =40, random_state = 0)","b16a1d4e":"forest.fit(X_train,y_train)  ","1bc65d26":"y_pred = forest.predict(X_test)\n","3676189b":"forest.score(X_test,y_test)","8ea728f6":"# Exploratoray Data Analysis","dae91620":"# Data VISUALIZATION","92e17e50":"\n* Toyota Corolla has more miles per gallon than any other car\n* Hornet sportabout,Duster 360,Merc 450sl,Merc 450se,Merc 450sll,Cadillac fleetwood,Lincoln continental,Chrysler,Dodge Challenger,AMCJavellin,Camaro,Pontiac Firebird,Maserati Bora have same number of cylinders\n* Cadilliac has more displacement than any other cars\n* Maserati bora has more horespower than any other cars\n* Honda civic has more rear axle ratio than any other cars\n* Lincoln Continental has more weight than any other cars\n* Merc 230 has best qsec performance than any other cars\n* Maserati bora has more number of carburetors than any other cars\n\n","0fbf4d2f":"# Data Preproccessing","0781334f":"# RELATION PLOTS","5c561f05":"# Data Modelling and Feature Selection"}}