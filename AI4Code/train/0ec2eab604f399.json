{"cell_type":{"96b9664e":"code","647d164f":"code","ed213f16":"code","caeacd5f":"code","17d6213a":"code","d36f7fc5":"code","6f868a23":"code","7f43f2dc":"code","dd17df22":"code","66e6eb3b":"code","1e94ae60":"code","19d17106":"code","70bc066e":"code","368c4d70":"code","6e92063f":"code","4938faab":"code","5df24c15":"code","e2006823":"code","e4f5b1e9":"code","8d462b9b":"code","c0e1e80b":"code","9440b981":"code","171ba42c":"code","0cc7b64f":"code","c952dab5":"code","45ea35d2":"code","d0ebcde4":"code","88c55791":"code","c75aec48":"code","0271f591":"code","18448798":"code","9c9f37cb":"code","0ddd53c5":"code","a08bb479":"code","d7c032f0":"code","e8411e45":"code","6e4ff73f":"code","94ab4589":"code","3e4724ec":"code","8825247a":"code","edcb3a89":"code","999f1293":"code","62557243":"code","ca5af970":"code","078e9d4a":"code","ec64155d":"code","85ede643":"code","1da96895":"code","7159e140":"code","bb66923c":"markdown","ff215c26":"markdown","c7fae501":"markdown","1a5b717a":"markdown","369c9d69":"markdown","8e29d2d5":"markdown","8455f3f9":"markdown","e27afbd8":"markdown","b6ee52ef":"markdown","4c940052":"markdown","dc0b4ded":"markdown","81a06455":"markdown","855d21fd":"markdown","82876368":"markdown","d0aab868":"markdown","8092935a":"markdown","1bba4905":"markdown","7751e5dd":"markdown","4fb14a87":"markdown","dea66150":"markdown","3a420ae0":"markdown","94760f8d":"markdown","a875a7ed":"markdown","4378d882":"markdown","22e1076b":"markdown","6fcf5948":"markdown","fbdbdb0d":"markdown","bf29e335":"markdown","60aba9dd":"markdown","f550b510":"markdown","1b69ad30":"markdown","5f24d53f":"markdown","d741b398":"markdown","1e0ca303":"markdown","9be33b01":"markdown","72dcea83":"markdown","6c7760a4":"markdown","1527ac15":"markdown","0558e7e2":"markdown","61f8e862":"markdown","066f0d6c":"markdown","0ce38a1b":"markdown","f3b0b515":"markdown","74438cc6":"markdown","cea96591":"markdown","c891432d":"markdown","69e08f33":"markdown","bbed784b":"markdown","46022f00":"markdown","e77e6332":"markdown","0c0a387d":"markdown","419ed5a7":"markdown","8d5be6e8":"markdown","f1fb6dd8":"markdown","8c9733f0":"markdown","62eadfe0":"markdown","c5ff6fc6":"markdown","d8e86478":"markdown","88840456":"markdown","65b95871":"markdown","0c7c8572":"markdown","1674365f":"markdown","72205dc6":"markdown","f6043b98":"markdown","23502888":"markdown","07e48d01":"markdown","a4951800":"markdown","d197a736":"markdown"},"source":{"96b9664e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","647d164f":"df_train = pd.read_csv(\"..\/input\/train.tsv\", sep='\\t')\ndf_train.head()","ed213f16":"df_test = pd.read_csv(\"..\/input\/test.tsv\", sep='\\t')\ndf_test.head()","caeacd5f":"df_train.Sentiment.value_counts()","17d6213a":"df_train.info()","d36f7fc5":"df_train_1 = df_train.drop(['PhraseId','SentenceId'],axis=1)\ndf_train_1.head()","6f868a23":"df_train_1['phrase_len'] = [len(t) for t in df_train_1.Phrase]\ndf_train_1.head(4)","7f43f2dc":"fig,ax = plt.subplots(figsize=(5,5))\nplt.boxplot(df_train_1.phrase_len)\nplt.show()","dd17df22":"df_train_1[df_train_1.phrase_len > 100].head()","66e6eb3b":"df_train_1[df_train_1.phrase_len > 100].loc[0].Phrase","1e94ae60":"neg_phrases = df_train_1[df_train_1.Sentiment == 0]\nneg_words = []\nfor t in neg_phrases.Phrase:\n    neg_words.append(t)\nneg_words[:4]","19d17106":"neg_text = pd.Series(neg_words).str.cat(sep=' ')\nneg_text[:100]","70bc066e":"for t in neg_phrases.Phrase[:300]:\n    if 'good' in t:\n        print(t)","368c4d70":"pos_phrases = df_train_1[df_train_1.Sentiment == 4] ## 4 is positive sentiment\npos_string = []\nfor t in pos_phrases.Phrase:\n    pos_string.append(t)\npos_text = pd.Series(pos_string).str.cat(sep=' ')\npos_text[:100]\n    ","6e92063f":"from wordcloud import WordCloud\nwordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_text)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","4938faab":"wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(pos_text)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","5df24c15":"from sklearn.feature_extraction.text import CountVectorizer\ncvector = CountVectorizer(min_df = 0.0, max_df = 1.0, ngram_range=(1,2))\ncvector.fit(df_train_1.Phrase)","e2006823":"len(cvector.get_feature_names())","e4f5b1e9":"neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 0].Phrase)\nsom_neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 1].Phrase)\nneu_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 2].Phrase)\nsom_pos_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 3].Phrase)\npos_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 4].Phrase)\n","8d462b9b":"neg_words = neg_matrix.sum(axis=0)\nneg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nneg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])","c0e1e80b":"neg_tf.head()","9440b981":"neg_tf_df = neg_tf.set_index('Terms')\nneg_tf_df.head()","171ba42c":"\nsom_neg_words = som_neg_matrix.sum(axis=0)\nsom_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nsom_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\nsom_neg_tf_df = som_neg_tf.set_index('Terms')\nsom_neg_tf_df.head()","0cc7b64f":"\nneu_words = neu_matrix.sum(axis=0)\nneu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nneu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\nneu_words_tf_df = neu_words_tf.set_index('Terms')\nneu_words_tf_df.head()","c952dab5":"\nsom_pos_words = som_pos_matrix.sum(axis=0)\nsom_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nsom_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\nsom_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\nsom_pos_words_tf_df.head()","45ea35d2":"\npos_words = pos_matrix.sum(axis=0)\npos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\npos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\npos_words_tf_df = pos_words_tf.set_index('Terms')\npos_words_tf_df.head()","d0ebcde4":"term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)","88c55791":"term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n                                 +  term_freq_df['positive'] \nterm_freq_df.sort_values(by='total', ascending=False).head(20)","c75aec48":"y_pos = np.arange(500)\nplt.figure(figsize=(10,8))\ns = 1\nexpected_zipf = [term_freq_df.sort_values(by='total', ascending=False)['total'][0]\/(i+1)**s for i in y_pos]\nplt.bar(y_pos, term_freq_df.sort_values(by='total', ascending=False)['total'][:500], align='center', alpha=0.5)\nplt.plot(y_pos, expected_zipf, color='r', linestyle='--',linewidth=2,alpha=0.5)\nplt.ylabel('Frequency')\nplt.title('Top 500 phrases in movie reviews')","0271f591":"from pylab import *\ncounts = term_freq_df.total\ntokens = term_freq_df.index\nranks = arange(1, len(counts)+1)\nindices = argsort(-counts)\nfrequencies = counts[indices]\nplt.figure(figsize=(8,6))\nplt.ylim(1,10**6)\nplt.xlim(1,10**6)\nloglog(ranks, frequencies, marker=\".\")\nplt.plot([1,frequencies[0]],[frequencies[0],1],color='r')\ntitle(\"Zipf plot for phrases tokens\")\nxlabel(\"Frequency rank of token\")\nylabel(\"Absolute frequency of token\")\ngrid(True)\nfor n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n                 verticalalignment=\"bottom\",\n                 horizontalalignment=\"left\")","18448798":"from sklearn.feature_extraction.text import CountVectorizer\ncvec = CountVectorizer(stop_words='english',max_features=10000)\ncvec.fit(df_train_1.Phrase)","9c9f37cb":"neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 0].Phrase)\nsom_neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 1].Phrase)\nneu_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 2].Phrase)\nsom_pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 3].Phrase)\npos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 4].Phrase)\n\nneg_words = neg_matrix.sum(axis=0)\nneg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nneg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])\n\nneg_tf_df = neg_tf.set_index('Terms')\n\n\nsom_neg_words = som_neg_matrix.sum(axis=0)\nsom_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nsom_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\nsom_neg_tf_df = som_neg_tf.set_index('Terms')\n\nneu_words = neu_matrix.sum(axis=0)\nneu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nneu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\nneu_words_tf_df = neu_words_tf.set_index('Terms')\n\nsom_pos_words = som_pos_matrix.sum(axis=0)\nsom_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nsom_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\nsom_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\n\npos_words = pos_matrix.sum(axis=0)\npos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\npos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\npos_words_tf_df = pos_words_tf.set_index('Terms')\n\nterm_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)\n\nterm_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n                                 +  term_freq_df['positive'] \n        \nterm_freq_df.sort_values(by='total', ascending=False).head(15)","0ddd53c5":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df.sort_values(by='negative', ascending=False)['negative'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df.sort_values(by='negative', ascending=False)['negative'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 negative tokens')\nplt.title('Top 50 tokens in negative movie reviews')","a08bb479":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df.sort_values(by='positive', ascending=False)['positive'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df.sort_values(by='positive', ascending=False)['positive'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 positive tokens')\nplt.title('Top 50 tokens in positive movie reviews')","d7c032f0":"phrase = np.array(df_train_1['Phrase'])\nsentiments = np.array(df_train_1['Sentiment'])\n# build train and test datasets\n\nfrom sklearn.model_selection import train_test_split    \nphrase_train, phrase_test, sentiments_train, sentiments_test = train_test_split(phrase, sentiments, test_size=0.2, random_state=4)","e8411e45":"cv1 = CountVectorizer()\nx_traincv = cv1.fit_transform([\"Hi How are you How are you doing\",\"Hi what's up\",\"Wow that's awesome\"])","6e4ff73f":"x_traincv_df = pd.DataFrame(x_traincv.toarray(),columns=list(cv1.get_feature_names()))\nx_traincv_df","94ab4589":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n## Build Bag-Of-Words on train phrases\ncv = CountVectorizer(stop_words='english',max_features=10000)\ncv_train_features = cv.fit_transform(phrase_train)","3e4724ec":"\n# build TFIDF features on train reviews\ntv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n                     sublinear_tf=True)\ntv_train_features = tv.fit_transform(phrase_train)","8825247a":"# transform test reviews into features\ncv_test_features = cv.transform(phrase_test)\ntv_test_features = tv.transform(phrase_test)","edcb3a89":"print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\nprint('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)","999f1293":"####Evaluation metrics\n\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import clone\nfrom sklearn.preprocessing import label_binarize\nfrom scipy import interp\nfrom sklearn.metrics import roc_curve, auc \n\n\ndef get_metrics(true_labels, predicted_labels):\n    \n    print('Accuracy:', np.round(\n                        metrics.accuracy_score(true_labels, \n                                               predicted_labels),\n                        4))\n    print('Precision:', np.round(\n                        metrics.precision_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('Recall:', np.round(\n                        metrics.recall_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('F1 Score:', np.round(\n                        metrics.f1_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n                        \n\ndef train_predict_model(classifier, \n                        train_features, train_labels, \n                        test_features, test_labels):\n    # build model    \n    classifier.fit(train_features, train_labels)\n    # predict using model\n    predictions = classifier.predict(test_features) \n    return predictions    \n\n\ndef display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n    \n    total_classes = len(classes)\n    level_labels = [total_classes*[0], list(range(total_classes))]\n\n    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n                                  labels=classes)\n    cm_frame = pd.DataFrame(data=cm, \n                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n                                                  labels=level_labels), \n                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n                                                labels=level_labels)) \n    print(cm_frame) \n    \ndef display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n\n    report = metrics.classification_report(y_true=true_labels, \n                                           y_pred=predicted_labels, \n                                           labels=classes) \n    print(report)\n    \n    \n    \ndef display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n    print('Model Performance metrics:')\n    print('-'*30)\n    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n    print('\\nModel Classification report:')\n    print('-'*30)\n    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n                                  classes=classes)\n    print('\\nPrediction Confusion Matrix:')\n    print('-'*30)\n    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n                             classes=classes)\n\n\ndef plot_model_decision_surface(clf, train_features, train_labels,\n                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n                                markers=None, alphas=None, colors=None):\n    \n    if train_features.shape[1] != 2:\n        raise ValueError(\"X_train should have exactly 2 columnns!\")\n    \n    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                         np.arange(y_min, y_max, plot_step))\n\n    clf_est = clone(clf)\n    clf_est.fit(train_features,train_labels)\n    if hasattr(clf_est, 'predict_proba'):\n        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n    else:\n        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n    Z = Z.reshape(xx.shape)\n    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n    \n    le = LabelEncoder()\n    y_enc = le.fit_transform(train_labels)\n    n_classes = len(le.classes_)\n    plot_colors = ''.join(colors) if colors else [None] * n_classes\n    label_names = le.classes_\n    markers = markers if markers else [None] * n_classes\n    alphas = alphas if alphas else [None] * n_classes\n    for i, color in zip(range(n_classes), plot_colors):\n        idx = np.where(y_enc == i)\n        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n                    label=label_names[i], cmap=cmap, edgecolors='black', \n                    marker=markers[i], alpha=alphas[i])\n    plt.legend()\n    plt.show()\n\n\ndef plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n    \n    ## Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    if hasattr(clf, 'classes_'):\n        class_labels = clf.classes_\n    elif label_encoder:\n        class_labels = label_encoder.classes_\n    elif class_names:\n        class_labels = class_names\n    else:\n        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n    n_classes = len(class_labels)\n    y_test = label_binarize(true_labels, classes=class_labels)\n    if n_classes == 2:\n        if hasattr(clf, 'predict_proba'):\n            prob = clf.predict_proba(features)\n            y_score = prob[:, prob.shape[1]-1] \n        elif hasattr(clf, 'decision_function'):\n            prob = clf.decision_function(features)\n            y_score = prob[:, prob.shape[1]-1]\n        else:\n            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n        \n        fpr, tpr, _ = roc_curve(y_test, y_score)      \n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n                                 ''.format(roc_auc),\n                 linewidth=2.5)\n        \n    elif n_classes > 2:\n        if hasattr(clf, 'predict_proba'):\n            y_score = clf.predict_proba(features)\n        elif hasattr(clf, 'decision_function'):\n            y_score = clf.decision_function(features)\n        else:\n            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        ## Compute micro-average ROC curve and ROC area\n        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n        ## Compute macro-average ROC curve and ROC area\n        # First aggregate all false positive rates\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(n_classes):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n        # Finally average it and compute AUC\n        mean_tpr \/= n_classes\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        ## Plot ROC curves\n        plt.figure(figsize=(6, 4))\n        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n                 label='micro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n\n        for i, label in enumerate(class_labels):\n            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                           ''.format(label, roc_auc[i]), \n                     linewidth=2, linestyle=':')\n    else:\n        raise ValueError('Number of classes should be atleast 2 or more')\n        \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()","62557243":"from sklearn.linear_model import SGDClassifier, LogisticRegression\n\nlr = LogisticRegression(penalty='l2', max_iter=100, C=1)\nsgd = SGDClassifier(loss='hinge', n_iter=100)","ca5af970":"# Logistic Regression model on BOW features\nlr_bow_predictions = train_predict_model(classifier=lr, \n                                             train_features=cv_train_features, train_labels=sentiments_train,\n                                             test_features=cv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_bow_predictions,\n                                      classes=[0,1,2,3,4])\n                                    ","078e9d4a":"# Logistic Regression model on TF-IDF features\nlr_tfidf_predictions = train_predict_model(classifier=lr, \n                                               train_features=tv_train_features, train_labels=sentiments_train,\n                                               test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","ec64155d":"# SGD model on Countvectorizer\nsgd_bow_predictions = train_predict_model(classifier=sgd, \n                                             train_features=cv_train_features, train_labels=sentiments_train,\n                                             test_features=cv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_bow_predictions,\n                                      classes=[0,1,2,3,4])","85ede643":"# SGD model on TF-IDF\nsgd_tfidf_predictions = train_predict_model(classifier=sgd, \n                                                train_features=tv_train_features, train_labels=sentiments_train,\n                                                test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","1da96895":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_jobs=-1)","7159e140":"# RandomForest model on TF-IDF\nrfc_tfidf_predictions = train_predict_model(classifier=rfc, \n                                                train_features=tv_train_features, train_labels=sentiments_train,\n                                                test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=rfc_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","bb66923c":"Now, in case of CountVectorizer, we are just counting the number of words in the document and many times it happens that some words like \"are\",\"you\",\"hi\",etc are very large in numbers and that would dominate our results in machinelearning algorithm.","ff215c26":"## <a id='1.5.3'>1.5.3 Term Frequency for 'neutral' sentiments<\/a>","c7fae501":"## <a id='2.3.4'>2.3.4 SGD model on TF-IDF<\/a>","1a5b717a":"## <a id='1.4'>1.4 Creating Word Cloud of negative and positive movie reviews<\/a>","369c9d69":"Found the answer to this question in Stackoverflow forum which you may find useful.","8e29d2d5":"We can clearly see that words like \"the\", \"in\",\"it\", etc are much higher in frequency but has been ranked less as they don't have any significance regarding the sentiment of the movie review. On the other hand, some words like \"downbeat laughably\" have been given higher rank as they are very less frequent in the document and seems to be significant related to the sentiment of a movie.","8455f3f9":"## <a id='1.4.1'>1.4.1 Filtering out positive and negative movie reviews<\/a>","e27afbd8":"## <a id='1.1'>1.1 Distribution of reviews in each sentiment category<\/a>","b6ee52ef":"## <a id='1.4.3'>1.4.3 Word Cloud for positively classified movie reviews<\/a>","4c940052":"## <a id='1'>1. Initial Look at the Data<\/a>","dc0b4ded":"## <a id='2.3.2'>2.3.2 Logistic Regression model on TF-IDF features<\/a>\n","81a06455":"\nConsider the below sample table which gives the count of terms(tokens\/words) in two documents.\n\n![](https:\/\/i.imgur.com\/iVOI1TQ.png)\n\nNow, let us define a few terms related to TF-IDF.\n\n**TF (Term Frequency)** :\nDenotes the contribution of the word to the document i.e. words relevant to the document should be frequent. \n\n            TF = (Number of times term t appears in a document)\/(Number of terms in the document)\n\nSo, TF(This,Document1) = 1\/8\n\nTF(This, Document2)=1\/5\n\n**IDF (Inverse Document Frequency)** :\nIf a word has appeared in all the document, then probably that word is not relevant to a particular document. \nBut, if it has appeared in a subset of documents then probably the word is of some relevance to the documents it is present in.\n\n\n           IDF = log(N\/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n\nSo, IDF(This) = log(2\/2) = 0.\nIDF(Messi) = log(2\/1) = 0.301.\n\n\nNow, let us compare the TF-IDF for a common word \u2018This\u2019 and a word \u2018Messi\u2019 which seems to be of relevance to Document 1.\n\nTF-IDF(This,Document1) = (1\/8) * (0) = 0\n\nTF-IDF(This, Document2) = (1\/5) * (0) = 0\n\nTF-IDF(Messi, Document1) = (4\/8) * 0.301 = 0.15\n\nSo,  for Document1 , TF-IDF method heavily penalises the word \u2018This\u2019 but assigns greater weight to \u2018Messi\u2019. So, this may be understood as \u2018Messi\u2019 is an important word for Document1 from the context of the entire corpus.\n\n\n## \"Rare terms are more informative than frequent terms\"\n\nThe graphic below attempts to express this intuition. Note that the TF-IDF weight is a relative measurement, so the values in red on the axis are not intended to be taken as absolute weights.\n\n![](https:\/\/i.imgur.com\/pmjduLZ.png)\n\n\n\n","855d21fd":"\n* min_df : While building the vocabulary, it will ignore terms that have a document frequency strictly lower than the given threshold. In our case, threshold for min_df = 0.0\n\n* max_df : While building the vocabulary, it ignore terms that have a document frequency strictly higher than the given threshold. For us, threshold for max_df = 1.0\n\n* ngram_range : A tuple of lower and upper boundary of the range of n-values for different n-grams to be extracted. \n\n\n![](https:\/\/i.imgur.com\/Gld6LGz.png)\n\n\n\n","82876368":"As we all know, all machine learning algorithms are good with numbers; we have to extract or convert the text data into numbers without losing much of the information.\nOne way to do such transformation is Bag-Of-Words (BOW) which gives a number to each word but that is very inefficient.\nSo, a way to do it is by **CountVectorizer**: it counts the number of words in the document i.e it converts a collection of text documents to a matrix of the counts of occurences of each word in the document. ","d0aab868":"Some of the big words can be interpreted quite neutral, such as \"movie\",\"film\", etc. We can see some of the words in smaller size make sense to be in negative movie reviews like \"bad cinema\", \"annoying\", \"dull\", etc.\n\nHowever, there are some words like \"good\" is also present in the negatively classified sentiment about the movie.\nLet's go deeper into such words\/texts:","8092935a":"![](https:\/\/i.imgur.com\/85dZ0io.png)","1bba4905":"So, TF-IDF (stands for **Term-Frequency-Inverse-Document Frequency**) weights down the common words occuring in almost all the documents and give more importance to the words that appear in a subset of documents.\nTF-IDF works by penalising these common words by assigning them lower weights while giving importance to some rare words in a particular document. ","7751e5dd":"## <a id='2.1'>2.1 Feature Engineering<\/a>","4fb14a87":"## <a id='1.5.2'>1.5.2 Term Frequency for 'some negative' sentiments<\/a>","dea66150":"Here, the training dataset has dominating neutral phrases from the movie reviews followed by somewhat positive and then somewhat negative.","3a420ae0":"## <a id='1.2'>1.2 Dropping insignificant columns<\/a>","94760f8d":"Let's check the phrase length of each of the movie reviews.","a875a7ed":"## <a id='1.5.5'>1.5.5 Term Frequency for 'positive' sentiments<\/a>\n","4378d882":"Below is the step by step methodology that we will be following :\n\n- <a href='#1'>1. Initial Look at the Data<\/a>\n    - <a href='#1.1'>1.1 Distribution of reviews in each sentiment category<\/a>\n    - <a href='#1.2'>1.2 Dropping insignificant columns<\/a>\n    - <a href='#1.3'>1.3 Overall Distribution of the length of the reviews under each sentiment class<\/a>\n    - <a href='#1.4'>1.4 Creating Word Cloud of negative and positive movie reviews<\/a>\n        - <a href='#1.4.1'>1.4.1 Filtering out positive and negative movie reviews<\/a>\n        - <a href='#1.4.2'>1.4.2 Word Cloud for negatively classified movie reviews<\/a>\n        - <a href='#1.4.3'>1.4.3 Word Cloud for positively classified movie reviews<\/a>\n    - <a href='#1.5'>1.5 Term Frequencies of each Sentiment class<\/a>\n        - <a href='#1.5.1'>1.5.1 Term Frequency for 'negative' sentiments<\/a>\n        - <a href='#1.5.2'>1.5.2 Term Frequency for 'some negative' sentiments<\/a>\n        - <a href='#1.5.3'>1.5.3 Term Frequency for 'neutral' sentiments<\/a>\n        - <a href='#1.5.4'>1.5.4 Term Frequency for 'some positive' sentiments<\/a>\n        - <a href='#1.5.5'>1.5.5 Term Frequency for 'positive' sentiments<\/a>\n    - <a href='#1.6'>1.6 Total Term Frequency of all the 5 sentiment classes<\/a>\n    - <a href='#1.7'>1.7 Frequency plot of top frequent 500 phrases in movie reviews<\/a>\n    - <a href='#1.8'>1.8 Plot of Absolute frequency of phrases against their rank<\/a>\n    - <a href='#1.9'>1.9 Movie Reviews Tokens Visualisation<\/a>\n        - <a href='#1.9.1'>1.9.1 Plot of top frequently used 50 phrases in negative movie reviews<\/a>\n        - <a href='#1.9.2'>1.9.2 Plot of top frequently used 50 phrases in positive movie reviews<\/a>\n- <a href='#2'>2. Traditional Supervised Machine Learning Models<\/a>\n    - <a href='#2.1'>2.1 Feature Engineering<\/a>\n    - <a href='#2.2'>2.2 Implementation of CountVectorizer & TF-IDF\n        - <a href='#2.2.1'>2.2.1 CountVectorizer<\/a>\n        - <a href='#2.2.2'>2.2.2 How is TF-IDF different from CountVectorizer?<\/a>\n        - <a href='#2.2.3'>2.2.3 How exactly does TF-IDF work?<\/a>\n        - <a href='#2.2.4'>2.2.4 Understanding the parameters of TfidfVectorizer<\/a>\n        - <a href='#2.2.5'>2.2.5 Setting the parametrs of CountVectorizer<\/a>\n    - <a href='#2.3'>2.3 Model Training, Prediction and Performance Evaluation<\/a>\n        - <a href='#2.3.1'>2.3.1 Logistic Regression model on CountVectorizer<\/a>\n        - <a href='#2.3.2'>2.3.2 Logistic Regression model on TF-IDF features<\/a>\n        - <a href='#2.3.3'>2.3.3 SGD model on Countvectorizer<\/a>\n        - <a href='#2.3.4'>2.3.4 SGD model on TF-IDF<\/a>\n        - <a href='#2.3.5'>2.3.5 RandomForest model on TF-IDF<\/a>","22e1076b":"## <a id='1.6'>1.6 Total Term Frequency of all the 5 sentiment classes<\/a>","6fcf5948":"Again I see some neutral words in big size, \"movie\",\"film\", but positive words like \"good\", \"best\", \"fascinating\" also stand out.","fbdbdb0d":"**\"Given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\"**\n\nIn other words, the rth most frequent word has a frequency f(r) that scales according to $${f(r)} \\propto \\frac{1}{r^\\alpha}$$ for $$\\alpha \\approx {1}$$\n\n\nLet's see how the movie review tokens and their frequencies look like on a plot.","bf29e335":"## <a id='2.3.1'>2.3.1 Logistic Regression model on CountVectorizer<\/a>","60aba9dd":"## <a id='2.2'>2.2 Implementation of CountVectorizer & TF-IDF","f550b510":"## <a id='2.2.5'>2.2.5 Setting the parameters of CountVectorizer<\/a>","1b69ad30":"**pandas.Series.str.cat ** : Concatenate strings in the Series\/Index with given separator. Here we give a space as separator, so, it will concatenate all the strings in each of the index separated by a space.","5f24d53f":"## <a id='2.3.5'>2.3.5 RandomForest model on TF-IDF<\/a>","d741b398":"## <a id='1.5.1'>1.5.1 Term Frequency for 'negative' sentiments<\/a>","1e0ca303":"* sublinear_tf : Sublinear tf scaling addresses the problem that 20 occurrences of a word is probably not 20 times more important than 1 occurrence.\n\n![](https:\/\/i.imgur.com\/ZzspOIQ.png)\n","9be33b01":"Next, we will try to see how different are the tokens in 4 different classes(positive,some positive,neutral, some negative, negative). ","72dcea83":"We can see some negative words like \"bad\", \"worst\", \"dull\" are some of the high frequency words. But, there exists few neutral words like \"movie\", \"film\", \"minutes\" dominating the frequency plots.\n\nLet's also take a look at top 50 positive tokens on a bar chart.","6c7760a4":"On the X-axis is the rank of the frequency from highest rank from left up to 500th rank to the right. Y-axis is the frequency observed in the corpus.\n\nAnother way to plot this is on a log-log graph, with X-axis being log(rank), Y-axis being log(frequency). By plotting on the log-log scale the result will yield roughly linear line on the graph.","1527ac15":"Next, let's explore about how different the tokens in two different classes(positive, negative).","0558e7e2":"# Intro to Movie Review Sentiment Analysis\n\n\n![](https:\/\/i.imgur.com\/WNgxr2I.png)\n\n\nFor the movie review sentiment analysis, we will be working on The Rotten Tomatoes movie review dataset from Kaggle. \nHere, we'll have to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive based on the sentiment of the movie reviews.\n\nThe dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short\/common words) are only included once in the data.\n\nThe sentiment labels are:\n\n* 0 - *negative*\n* 1 - *somewhat negative*\n* 2 - *neutral*\n* 3 - *somewhat positive*\n* 4 - *positive*\n\n\n\n\n\n\n\n**Any suggestions for improvement or comments are highly appreciated!**\n\nPlease upvote(like button) and share this kernel if you like it so that more people can learn from it. \n\n","61f8e862":"## <a id='1.9'>1.9 Movie Reviews Tokens Visualisation<\/a>","066f0d6c":"### Word Cloud","0ce38a1b":"We also want to understand how terms are distributed across documents. This helps us to characterize the properties of the algorithms for compressing phrases.\n\nA commonly used model of the distribution of terms in a collection is Zipf's law . It states that, if $t_1$ is the most common term in the collection, $t_2$ is the next most common, and so on, then the collection frequency $cf_i$ of the $i$th most common term is proportional to $1\/i$: \n\n$\\displaystyle cf_i \\propto \\frac{1}{i}.$\t\n\n\nSo if the most frequent term occurs $cf_1$ times, then the second most frequent term has half as many occurrences, the third most frequent term a third as many occurrences, and so on. The intuition is that frequency decreases very rapidly with rank.\nThe above equation is one of the simplest ways of formalizing such a rapid decrease and it has been found to be a reasonably good model.\n","f3b0b515":"We need the Term Frequency data to see what kind of words are used in the movie reviews and how many times have been used.\nLet's proceed with CountVectorizer to calculate term frequencies:\n","74438cc6":"## <a id='1.4.2'>1.4.2 Word Cloud for negatively classified movie reviews<\/a>","cea96591":"## <a id='2.2.2'>2.2.2 How is TF-IDF different from CountVectorizer?<\/a>","c891432d":"## <a id='1.3'>1.3 Overall Distribution of the length of the reviews under each sentiment class<\/a>","69e08f33":"## <a id='1.7'>1.7 Frequency plot of top frequent 500 phrases in movie reviews<\/a>","bbed784b":"## <a id='1.9.2'>1.9.2 Plot of top frequently used 50 phrases in positive movie reviews<\/a>","46022f00":"## <a id='2.2.1'>2.2.1 CountVectorizer<\/a>\n\n","e77e6332":"When your corpus (or Structured set of texts) is large, TfIdf is the best option.\n\nNow, let's get back to our problem:","0c0a387d":"It looks like count vectorizer has extracted 94644 words out of the corpus.\nGetting term frequency for each class can be obtained with the below code block.","419ed5a7":"\n## <a id='2.3.3'>2.3.3 SGD model on Countvectorizer<\/a>","8d5be6e8":"Once again, there are some neutral words like \"film\", \"movie\", are quite high up in the rank.","f1fb6dd8":"From the above box plot, some of the reviews are way more than 100 chracters long.","8c9733f0":"## <a id='1.5.4'>1.5.4 Term Frequency for 'some positive' sentiments<\/a>","62eadfe0":"## <a id='2.2.3'>2.2.3 How exactly does TF-IDF work?<\/a>","c5ff6fc6":"## <a id='2.2.4'>2.2.4 Understanding the parameters of TfidfVectorizer<\/a>","d8e86478":"**Logistic Regression on TF-IDF is outperforming other machine learning algorithms**. \n\n","88840456":"For Example: If we have a collection of 3 text documents as below, then CountVectorizer converts that into individual counts of occurences of each of the words in the document as below:\n\n\n","65b95871":"## <a id='2'>2. Traditional Supervised Machine Learning Models<\/a>\n","0c7c8572":"**For CountVectorizer**\nThis time, the stop words will not help much, because of the same high-frequency words, such as \"the\", \"to\", will equally frequent in both classes. If these stop words dominate both of the classes, I won't be able to have a meaningful result. So, I decided to remove stop words, and also will limit the max_features to 10,000 with countvectorizer.","1674365f":"## <a id='1.5'>1.5 Term Frequencies of each Sentiment class<\/a>","72205dc6":"** Why is log used when calculating term frequency weight and IDF, inverse document frequency in sublinear_tf transformation?**","f6043b98":"## <a id='2.3'>2.3 Model Training, Prediction and Performance Evaluation<\/a>","23502888":"## <a id='1.9.1'>1.9.1 Plot of top frequently used 50 phrases in negative movie reviews<\/a>","07e48d01":"So, we can very well see, even if the texts contain words like \"good\", it is a negative sentiment because it indicates that the movie is **NOT** a good movie. ","a4951800":"\nA word cloud is a graphical representation of frequently used words in a collection of text files. The height of each word in this picture is an indication of frequency of occurrence of the word in the entire text. Such diagrams are very useful when doing text analytics.\n\nIt provides a general idea of what kind of words are frequent in the corpus, in a sort of quick and dirty way.\n\nLet's start doing some EDA on text data by Word Cloud.","d197a736":"## <a id='1.8'>1.8 Plot of Absolute frequency of phrases against their rank<\/a>"}}