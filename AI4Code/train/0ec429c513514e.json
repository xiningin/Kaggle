{"cell_type":{"0b3cde7a":"code","f0d1d2a4":"code","b6f8033e":"code","8cf04309":"code","906854aa":"code","c6735fd3":"code","ec332228":"code","5625f3ea":"code","1fb29d5e":"code","2e87faf9":"code","17aca91f":"code","34f207c7":"code","a9d82ea3":"code","140c0b38":"code","f378d642":"code","be358803":"code","adae0509":"code","8fc6d776":"code","e9ee1fbd":"code","dd721f13":"code","89e82789":"code","965ee902":"code","17cbfdbe":"code","af5c9958":"code","2efd5e80":"code","3b9cfb8d":"code","dcfd138c":"code","ba2d59cf":"code","e8ba963c":"code","ccd57356":"markdown"},"source":{"0b3cde7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0d1d2a4":"import matplotlib.pyplot as plt\n%matplotlib inline","b6f8033e":"from subprocess import check_output\ndata = pd.read_csv('..\/input\/imdb-5000-movie-dataset\/movie_metadata.csv')","8cf04309":"print(data.shape)\ndata.count()","906854aa":"df =data.drop(['gross','budget'],axis=1).dropna(axis=0)","c6735fd3":"import seaborn as sns\nax = plt.subplots(figsize=(15,15)) \nsns.heatmap(data=data.corr(),annot=True)\ndata.loc[data.color == ' Black and White'].title_year.mean()","ec332228":"df = pd.concat([df,data.loc[df.index,['gross','budget']]],axis=1)","5625f3ea":"df.head(5)","1fb29d5e":"df.reset_index(drop=True,inplace=True)","2e87faf9":"df.columns","17aca91f":"sns.boxplot(x=\"color\", y=\"title_year\", data=df, palette=\"PRGn\")","34f207c7":"cut = pd.cut(df.imdb_score, bins=list(np.arange(1,11)))\n\ncut2 = pd.cut(df.title_year, bins=list(5*(np.arange(380,405))))\n\ncut3 = pd.cut(df.imdb_score, bins=list([0,4,6,7,8,10]))\ndf['imdb_score_bin'] =cut\n\ndf['year_range'] =cut2\ndf['pc_imdb'] = cut3\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['pc_imdb']= le.fit_transform(df['pc_imdb'])","a9d82ea3":"fig, ax = plt.subplots(figsize=(10,10))\nplt.xticks(rotation=45)\nsns.barplot(df['year_range'],df['budget'],ci=None)\nsns.barplot(df['year_range'],df['budget'],ci=None)","140c0b38":"fig, ax = plt.subplots(figsize=(10,10))\nplt.xticks(rotation=45)\nsns.barplot(df['year_range'],df['budget'],ci=None)\nsns.barplot(df['year_range'],df['gross'],ci=None)","f378d642":"sns.barplot(df['imdb_score_bin'],df['gross'],ci=None)","be358803":"sns.boxplot(data=df,x='imdb_score_bin',y='gross')","adae0509":"mean_chart = pd.DataFrame(df.groupby(by=['year_range'])['budget'].mean())","8fc6d776":"mean_chart = pd.DataFrame(df.groupby(by=['year_range'])['budget'].mean())\n\ndf = pd.merge(df,mean_chart,left_on='year_range',right_index=True)\n\ndf.columns\n\ndf['budget_x'].fillna(df['budget_y'],inplace=True)\ndf['budget_x'].count()","e9ee1fbd":"df2=df","dd721f13":"from sklearn.preprocessing import LabelEncoder\nvar_mod=['imdb_score_bin','year_range']\nle = LabelEncoder()\nfor i in var_mod:\n    df2[i] = le.fit_transform(df2[i])","89e82789":"from sklearn.tree import DecisionTreeRegressor\n\nclf= DecisionTreeRegressor()\n\n#df.budget.fillna(0,inplace =True)\n\nclf.fit(df[df['gross'].notnull()][['imdb_score_bin','year_range']],df['gross'].dropna(axis=0))\n\npred = clf.predict(df[df['gross'].isnull()][['imdb_score_bin','year_range']])\n\ndf[df['gross'].isnull()][['imdb_score_bin','year_range']].index\n\nj=0\nfor i in df[df['gross'].isnull()][['imdb_score_bin','year_range']].index :\n    df['gross'][i] = pred[j]\n    j=j+1","965ee902":"df_genre=df['genres'].str.split('|',expand=True).stack().str.get_dummies().sum(level=0)\n\nfig, ax = plt.subplots(figsize=(10,10))\nplt.xticks(rotation=45)\nk=pd.DataFrame(df_genre.sum(),columns=['sum'])\nsns.barplot(y='sum',x=k.index,data=k,orient='v')","17cbfdbe":"df['age'] = 2017 - df.title_year","af5c9958":"k=df.groupby(by='director_name',sort=False).director_facebook_likes.mean()\nl=df.groupby(by='director_name',sort=False).imdb_score.sum()\nm=df.groupby(by='director_name',sort=False).age.max()\npd.DataFrame(df['director_name'].value_counts())\ndir_ran = pd.concat([k,l,m],axis=1)","2efd5e80":"col_5 =list(df['director_name'].value_counts().index[:5])\ncol_5","3b9cfb8d":"pp = df.loc[(df.director_name == col_5[0])|(df.director_name == col_5[1])|(df.director_name == col_5[2])|(df.director_name == col_5[3])|(df.director_name == col_5[4])]\n\nsns.boxplot(x='director_name',y='imdb_score',data=pp)","dcfd138c":"str_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in df.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)          \nnum_list = df.columns.difference(str_list)  \nX=df[num_list]\nX.shape","ba2d59cf":"from sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(X)\n\n\nfrom sklearn.decomposition import PCA as sklearnPCA\nsklearn_pca = sklearnPCA(n_components=20)\nY_sklearn = sklearn_pca.fit_transform(X_std)\n\ncum_sum = sklearn_pca.explained_variance_ratio_.cumsum()\n\nsklearn_pca.explained_variance_ratio_[:10].sum()\n\ncum_sum = cum_sum*100\n\nfig, ax = plt.subplots(figsize=(8,8))\nplt.bar(range(20), cum_sum, label='Cumulative _Sum_of_Explained _Varaince', color = 'b',alpha=0.5)","e8ba963c":"from sklearn.decomposition import PCA as sklearnPCA\nsklearn_pca = sklearnPCA(n_components=3)\nX_reduced  = sklearn_pca.fit_transform(X_std)\nY=df['pc_imdb']\nfrom mpl_toolkits.mplot3d import Axes3D\nplt.clf()\nfig = plt.figure(1, figsize=(8, 6))\nax = Axes3D(fig, elev=-150, azim=110)\nax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=Y,cmap=plt.cm.Paired)\nax.set_title(\"First three PCA directions\")\nax.set_xlabel(\"1st eigenvector\")\nax.w_xaxis.set_ticklabels([])\nax.set_ylabel(\"2nd eigenvector\")\nax.w_yaxis.set_ticklabels([])\nax.set_zlabel(\"3rd eigenvector\")\nax.w_zaxis.set_ticklabels([])\n\nplt.show()","ccd57356":"Perform data preprocessing on movie_metadata.csv file. (You can download the dataset from the shared datasets folder on Google drive of your class.) Perform the following operations on this dataset:\ni. Importing the libraries required for preprocessing from sklearn.\n\nii. Importing the Dataset from the above link.\n\niii. Use the necessary function to handling the missing data.\n\niv. Perform data visualizations using matplotlib or seaborn libraries.\n\nv. Use the necessary function for handling of categorical data if any.\n\nvi. Splitting the dataset into training and testing datasets\n\nvii. Perform feature Scaling."}}