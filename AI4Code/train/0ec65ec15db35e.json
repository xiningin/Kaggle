{"cell_type":{"4ea89a67":"code","15a32d7b":"code","393c727b":"code","75bc4772":"code","e9c16262":"code","a7ed8d7f":"code","77b9f930":"code","4cd00d31":"code","102ba620":"code","a8d56d7b":"code","d7899196":"code","02905a8e":"code","e57a8a10":"code","d07de41d":"code","e4d21a35":"code","02002cce":"code","a00d5f82":"code","0c08c3a2":"code","4bdecf84":"code","758fe95d":"code","aa4ba6b7":"code","508443f8":"code","0819573f":"code","e3170d42":"markdown","5edd00d3":"markdown","9122cd43":"markdown","da670c3e":"markdown"},"source":{"4ea89a67":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# import lightgbm as lgb\n# import xgboost as xgb\nimport catboost as cb\nfrom catboost import Pool, cv, CatBoostClassifier\nfrom sklearn import ensemble, preprocessing, tree, model_selection, feature_selection, pipeline, metrics\nfrom sklearn.model_selection import StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","15a32d7b":"spending_score_dict = {\"Low\":0,\"Average\":1,\"High\":2 }","393c727b":"train = pd.read_csv('\/kaggle\/input\/janatahack-customer-segmentation\/Train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-customer-segmentation\/Test.csv')","75bc4772":"train[\"missings_count\"] = train.isna().sum(axis=1)\ntest[\"missings_count\"] = test.isna().sum(axis=1)\n\ntrain[\"Spending_Score\"] = train[\"Spending_Score\"].map(spending_score_dict)\ntest[\"Spending_Score\"] = test[\"Spending_Score\"].map(spending_score_dict)\n\ntrain[\"exp_div_age\"] = train[\"Work_Experience\"].div( train[\"Age\"])\ntest[\"exp_div_age\"] = test[\"Work_Experience\"].div(test[\"Age\"])\n\ntrain[\"odd_experience\"] = (train[\"Graduated\"]!=\"Yes\") & (train[\"Profession\"].isin(['Healthcare',  'Engineer', 'Doctor', 'Lawyer',\n       'Executive', 'Marketing'])).astype(int)\ntest[\"odd_experience\"] = ((test[\"Graduated\"]!=\"Yes\") & (test[\"Profession\"].isin(['Healthcare',  'Engineer', 'Doctor', 'Lawyer',\n       'Executive', 'Marketing']))).astype(int)","e9c16262":"train","a7ed8d7f":"train.columns","77b9f930":"test","4cd00d31":"train.describe()","102ba620":"test.describe()","a8d56d7b":"train[\"Profession\"].value_counts(normalize=True)","d7899196":"train[\"Var_1\"].value_counts(normalize=True)","02905a8e":"categorical_cols = ['Gender', 'Ever_Married',  'Graduated', 'Profession','Var_1']","e57a8a10":"X_train = train.drop([\"Segmentation\"],axis=1)\nX_train[categorical_cols] = X_train[categorical_cols].fillna('\"\"')","d07de41d":"X_train.isna().sum()","e4d21a35":"# !pip install --upgrade catboost","02002cce":"train_pool = Pool(\n    X_train, \n    train[\"Segmentation\"], \n    cat_features=categorical_cols,\n\n)\n\n# eval_pool = Pool(\n#     X_test, \n#     y_test, \n#     cat_features=categorical_cols,\n# )\n\ncatboost_params = {\n    'iterations': 1800,\n#     'learning_rate': 0.1,\n#     \"depth\": 2,\n#     'eval_metric': ['Logloss',\"Accuracy\"],\n     \"loss_function\":'MultiClass',\n    \n    'task_type': 'GPU',\n    'early_stopping_rounds': 15,\n#     'use_best_model': True,\n#     'verbose': 100,\n    \"silent\":True,\n#     \"verbose\": False,\n}\n\n# model = CatBoostClassifier(**catboost_params)\n\n\n# model.fit(train_pool,plot=True)","a00d5f82":"###### scores = cv(train_pool,\n#             catboost_params,\n#             fold_count=4, \n#             plot=\"True\")","0c08c3a2":"model = CatBoostClassifier(**catboost_params)\n\n# grid = {'learning_rate': [0.03, 0.07],\n#         'depth': [4, 6, 10],\n#         'l2_leaf_reg': [1, 3, 5, 7]}\n\n# randomized_search_result = model.randomized_search(grid,\n#                                                    train_pool,\n# #                                                    X=train_data,\n# #                                                    y=train_labels,\n#                                                    n_iter=12,\n#                                                    plot=True)\n\n\n# randomized_search_result['params'] ### {'depth': 4, 'l2_leaf_reg': 1, 'learning_rate': 0.03}","4bdecf84":"# model = CatBoostClassifier(**catboost_params)\n\n# grid = {'learning_rate': [0.02],\n#         'depth': [2,4, 6,8],\n#         'l2_leaf_reg': [ 1, 3],\n#        \"min_data_in_leaf\":[1,3],\n# #        \"max_leaves\":[31,61], ## cuda errors when searching this as well\n#        \"rsm\":[1,0.8]\n#        }\n\n# grid_search_result = model.grid_search(grid,\n#                                                    train_pool,\n# #                                                    n_iter=12,\n# #                                              cv=4,\n#                                                    plot=True\n#                                       )\n\n\n\n# grid_search_result['params'] \n\n# #  {'rsm': 1,\n# #  'min_data_in_leaf': 3,\n# #  'depth': 6,\n# #  'l2_leaf_reg': 3,\n# #  'learning_rate': 0.02}","758fe95d":"\nbest_params = {'iterations': 1600,\n    'learning_rate': 0.02,\n'min_data_in_leaf': 2, \n 'depth': 6,\n 'l2_leaf_reg': 3,\n#     'eval_metric': ['Logloss',\"Accuracy\"],\n     \"loss_function\":'MultiClass',\n    'task_type': 'GPU',\n    'early_stopping_rounds': 12,\n#     'use_best_model': True,\n\n    \"silent\":True,}\n\nmodel = CatBoostClassifier(**best_params)\n\nmodel.fit(train_pool)","aa4ba6b7":"test[categorical_cols] = test[categorical_cols].fillna('\"\"')\npreds = model.predict(test)\n","508443f8":"test[\"Segmentation\"] = preds\n\ndisplay(test)\n","0819573f":"test[[\"ID\",\"Segmentation\"]].to_csv(\"output_preds_catboost_v3.csv\",index=False)","e3170d42":"* So - best result after lots of grid searching is what I'd do anyway+- : default params, lower learning rate, and + min data in leaf..\n    * {'rsm': 1,\n 'min_data_in_leaf': 3,\n 'depth': 6,\n 'l2_leaf_reg': 3,\n 'learning_rate': 0.02}\n \nWe'lltrain a final model with these params and submit results","5edd00d3":"#### We see that all the cateogircal variables have very low cardinality\/dimensionality, so there's probably no point in transforming them directly much.\n* We could stil look at feature interactions \/ combinations of them\n\n\n### CatBoost model\n\n\n* default params list - https:\/\/catboost.ai\/docs\/concepts\/python-reference_parameters-list.html#python-reference_parameters-list","9122cd43":"* hyperparameter search\n* by not using a validatio nset, we risk overfitting","da670c3e":"* more indepth hyperparam search - e.g. \n    * https:\/\/www.kaggle.com\/shivampanwar\/catboost-and-hyperparameter-tuning-using-bayes\n    * https:\/\/github.com\/lmassaron\/kaggledays-2019-gbdt\/blob\/master\/Kaggle%20Days%20Paris%20-%20Skopt%20%2B%20CatBoost%20solution.ipynb\n\n"}}