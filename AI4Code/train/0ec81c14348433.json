{"cell_type":{"749cd7ff":"code","ace51d92":"code","b083f1d4":"code","a442faef":"code","b35c162b":"code","8cafa4da":"code","f822cd10":"code","5bc87a2c":"code","39dda309":"code","931a22b8":"code","6b5f87f4":"code","625dab65":"code","a51932c1":"code","2e783f12":"code","8d988654":"code","83c5ff0a":"code","d47f9056":"code","7316da5e":"code","95502d3a":"code","9e945606":"code","80071272":"code","cd3cb3d4":"code","c72d1d52":"code","e482b308":"code","04de2270":"code","020d59ab":"markdown","a55ac29a":"markdown","8c586989":"markdown","c35515f9":"markdown","9af983fa":"markdown","856cec4e":"markdown"},"source":{"749cd7ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ace51d92":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf ","b083f1d4":"df = pd.read_csv('\/kaggle\/input\/star-type-classification\/Stars.csv')","a442faef":"df.describe()","b35c162b":"df.head()","8cafa4da":"# Checking for null values\n\n# Column wise\nprint(df.isna().sum())\n\n# Row wise\nprint(df.isna().sum(axis=0))","f822cd10":"# Helper functions to plot columns of the dataframw against each other\n\ndef linear_plot(x_axis, y_axis, x_label = \"X axis\", y_label = \"Y axis\", title = \"Linear Plot\"):\n    %matplotlib inline\n    plt.plot(x_axis,y_axis)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.show()\n    \n    \ndef scatter_plot(x_axis, y_axis, x_label = \"X axis\", y_label = \"Y axis\", title = \"Scatter Plot\", color_provided = \"#ff0000\"):\n    %matplotlib inline\n    plt.scatter(x_axis,y_axis,color = color_provided)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.show()\n    \n    ","5bc87a2c":"# Correlation Matrix\n\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')\n","39dda309":"temp_cols_list = [\"A_M\", \"Type\"]\ntemp_df_1 = df[temp_cols_list]","931a22b8":"scatter_plot(temp_df_1[\"A_M\"],temp_df_1[\"Type\"], x_label = \"A_M\", y_label = \"Type\")","6b5f87f4":"df.sample(5)","625dab65":"df.columns","a51932c1":"# Taking the relevant columns for training and testing\n\ntrain_df_columns = df.columns.drop(\"Type\")\n\nprint(train_df_columns)","2e783f12":"train_df = df[train_df_columns]\ntest_df = df[\"Type\"]","8d988654":"# Encoding text data into numeric values - as Logistic Regression needs numeric values\n\ndef encode_dict(list_of_vals) -> dict :\n    d = {}\n    idx = 0\n    for i in list_of_vals:\n        if i not in d:\n            d[i] = idx\n            idx += 1 \n    return d","83c5ff0a":"for i in train_df_columns:\n    print(f\"Data type of {i} is {train_df[i].dtypes} \\n\")","d47f9056":"colour_dict = encode_dict(train_df['Color'])","7316da5e":"train_df['colour_encoded'] = train_df['Color'].apply(lambda x : colour_dict[x]) ","95502d3a":"spectral_class_dict = encode_dict(train_df['Spectral_Class']) ","9e945606":"train_df['spectral_class_encoded'] = train_df['Spectral_Class'].apply(lambda x: spectral_class_dict[x])","80071272":"train_df.drop([\"Color\",\"Spectral_Class\"],axis=1,inplace=True)\n\ntrain_df.sample(5)","cd3cb3d4":"from sklearn.model_selection import train_test_split\n\na_train, a_test, b_train, b_test = train_test_split(train_df, test_df, test_size = 0.20, random_state=42)","c72d1d52":"%timeit\n\nfrom sklearn.linear_model import LogisticRegressionCV\n","e482b308":"# Getting the best-fitting logistic regression model\n\ndef getBestClassifier(cv_param = 5, num_class = 6, step_size = 500):\n    for i in range(num_class):\n        num_iter = 1000 + i*step_size\n        clf = LogisticRegressionCV(cv = cv_param, random_state=42, max_iter= num_iter, verbose=False).fit(a_train,b_train)\n        accr = clf.score(a_test,b_test)\n        print(f\"With {num_iter} iterations, we have an accuracy of {accr} \\n\")","04de2270":"getBestClassifier()","020d59ab":"# Logistic Regression\n\n# Steps involved:\n* Preprocessing\n* Train-test split\n* Training the model\n* Performance Analysis","a55ac29a":"It would seem that we can just check the A_M values and more or less call it a day.\n\nOr night.\n\nMostly night.\n\nThis was expected after seeing the -0,95 correlation score between the two.","8c586989":"We can see that we have an accuracy of about $0,96$\n\n\nThis can be improved by using another classifier, or more rigorous feature extraction, or hyperparameter tuning","c35515f9":"# Reading in the dataset\n\n## Link to the dataset used: [Star Type Classification](https:\/\/www.kaggle.com\/brsdincer\/star-type-classification)","9af983fa":"## Splitting the data and performing Logistic Regression","856cec4e":"# Preprocessing and Data Analysis"}}