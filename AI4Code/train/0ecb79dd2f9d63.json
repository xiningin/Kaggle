{"cell_type":{"6e5c3fcc":"code","7efecf34":"code","85007c05":"code","2799dd2a":"code","072fc8c2":"code","424ce5e6":"code","7f8955a2":"code","5521618d":"code","10af093e":"code","4b50a500":"code","90687f33":"code","b0be11d1":"code","783f97fb":"code","20dc3eb0":"markdown","d99feea7":"markdown","9bd515d2":"markdown","47d8445e":"markdown","2d0d2630":"markdown"},"source":{"6e5c3fcc":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport shutil\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nimport gc \nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n","7efecf34":"df = pd.read_csv('..\/input\/cassava-leaf-disease-merged\/merged.csv')\ndf_images = df['image_id']\ndf_labels = df['label']\n","85007c05":"df.head()","2799dd2a":"df = df.sample(frac=1).reset_index(drop=True)","072fc8c2":"skf = StratifiedKFold(n_splits=5,shuffle=True)\n\nFOLDS_LIST=[]\na = 0\nfor train_index,test_index in skf.split(df_images,df_labels):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    df_images_train, df_images_test = df_images[train_index], df_images[test_index]\n    df_labels_train, df_labels_test = df_labels[train_index], df_labels[test_index]\n    df_train = pd.concat([df_images_train,df_labels_train],axis=1)\n    df_test = pd.concat([df_images_test,df_labels_test],axis=1)\n    \n    df_test.to_csv('fold_'+str(a)+'.csv')\n    a+=1\n    \n    FOLDS_LIST.append(df_test)\n    \n","424ce5e6":"\nIMG_SIZE = 299\n","7f8955a2":"pair_list = []\ndf1 = df.sample(frac=1).reset_index(drop=True)  #Shuffle dataframe\ndf2 = df.sample(frac=1).reset_index(drop=True)  #Shuffle dataframe\nfor i in range(len(df1)):\n    pair_list.append(((df1['image_id'][i],df1['label'][i]),(df2['image_id'][i],df2['label'][i])))","5521618d":"\n@tf.function\ndef resize_image(image):\n    return tf.image.resize(image,[IMG_SIZE,IMG_SIZE])\n","10af093e":"#@tf.function\ndef read_img(image_name):\n    filepath = '..\/input\/cassava-leaf-disease-merged\/train\/'+image_name\n    image = tf.io.decode_jpeg(tf.io.read_file(filepath))\n    \n    return tf.cast(image,tf.float32)\n\n#@tf.function\n# def image_generator(image_name):\n#     img = read_img(image_name)\n#     img = augment_img_randomly(img)\n#     return img\n\ndef image_generator(idx):\n    (image1,label1),(image2,label2) = pair_list[int(idx)]\n    img,label = mixup((read_img(image1),tf.one_hot(label1,5)),(read_img(image2),tf.one_hot(label2,5)))\n    return img,label","4b50a500":"#@tf.function\ndef get_augment_list():\n    return np.array(list(map(lambda x:x<1,np.random.randint(2, size=7))),dtype='bool')\n\n\n@tf.function\ndef gaussian_blur(image, kernel_size=23, padding='SAME'):\n\tsigma = tf.random.uniform((1,))* 1.9 + 0.1\n\n\tradius = tf.cast(kernel_size \/ 2, tf.int32)\n\tkernel_size = radius * 2 + 1\n\tx = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n\tblur_filter = tf.exp(\n\t\t-tf.pow(x, 2.0) \/ (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n\tblur_filter \/= tf.reduce_sum(blur_filter)\n\t# One vertical and one horizontal filter.\n\tblur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n\tblur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n\tnum_channels = tf.shape(image)[-1]\n\tblur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n\tblur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n\texpand_batch_dim = image.shape.ndims == 3\n\tif expand_batch_dim:\n\t\timage = tf.expand_dims(image, axis=0)\n\tblurred = tf.nn.depthwise_conv2d(\n\t\timage, blur_h, strides=[1, 1, 1, 1], padding=padding)\n\tblurred = tf.nn.depthwise_conv2d(\n\t\tblurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n\tif expand_batch_dim:\n\t\tblurred = tf.squeeze(blurred, axis=0)\n\treturn blurred\n\n\ndef mixup(a, b):\n  alpha = [0.2]\n\n  (image1, label1), (image2, label2) = a, b\n\n  dist = tfd.Beta(alpha, alpha)\n  l = dist.sample(1)[0][0]\n  \n  img = l*image1+(1-l)*image2\n  lab = l*label1+(1-l)*label2\n\n  return img, lab\n    \n    \n@tf.function\ndef augment_img_randomly(img):\n    '''\n    Augmentaions to be used: (use stateless versions of these)\n    \n    Random hue (0.2)\n    Random brightness (0.3)\n    Random saturation (0.7,1.3)\n    Random contrast  (0.8,1.2)\n    ''' \n    augment_list = get_augment_list()\n    image = resize_image(img)\n     #(32,512,512,3)\n    \n    if augment_list[0]:\n        image = tf.image.random_saturation(image,0.7,1.3)\n    if augment_list[1]:\n        image = tf.image.random_contrast(image,0.8,1.2)\n    if augment_list[2]:\n        image = tf.image.random_brightness(image,0.3)\n    if augment_list[3]:\n        image = tf.image.random_hue(image,0.2)\n    if augment_list[4]:\n        image = tf.image.random_flip_left_right(image)\n    if augment_list[5]:\n        image = tf.image.random_flip_up_down(image)\n    if augment_list[6]:\n        image = gaussian_blur(image)\n    \n    \n    \n    image = tf.math.divide(image,255)\n    del augment_list,img\n    gc.collect()\n        \n    return image","90687f33":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef generate_example(image_name,fold_df):\n    img = augment_img_randomly(read_img(image_name))\n    label = fold_df[fold_df['image_id']==image_name]['label']\n    \n    \n    feature={\n        'image':_bytes_feature(img.numpy().tobytes()),\n        'target':_int64_feature(int(label)),\n        'image_id':_bytes_feature(bytes(image_name,encoding='utf8'))\n    }\n    #del img,label\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n","b0be11d1":"for i in range(len(FOLDS_LIST)):\n    record_file = 'fold_'+str(i)+'.tfrecords'\n    \n    print('Writing ',record_file)\n    \n    image_names = list(FOLDS_LIST[i]['image_id'])\n    \n    fold_df = FOLDS_LIST[i]\n    \n    a=1\n    num_files = len(list(image_names))\n    \n    with tf.io.TFRecordWriter(record_file) as writer:\n      for k in image_names:\n        \n        print('Writing image ',a,' of ',num_files)\n        proto_example = generate_example(k,fold_df)\n        writer.write(proto_example)\n        del proto_example\n        gc.collect()\n        a+=1\n    del writer\n    gc.collect()\n    ","783f97fb":"# record_file = 'images.tfrecords'\n# with tf.io.TFRecordWriter(record_file) as writer:\n#   for filename, label in image_labels.items():\n#     image_string = open(filename, 'rb').read()\n#     tf_example = image_example(image_string, label)\n#     writer.write(tf_example.SerializeToString())","20dc3eb0":"So, we have coded for the following things:\n    1. Take image \n    2. Augment\n    3. Make a example protobuf\n\nNow we need to take all images in a FOLDS_LIST[i] and put them in a single TFRec. Same for its validation. \nIn this way, we will get 5 folds and all will have different images. Note that validation images will be augmented, and we\nwill be using TTA\n\n","d99feea7":"## Cassava Stratified K Folds TFRecords maker\n\n### Version history:\n\nVersion 6: First Successful Augmented TFRecords   \nVersion 10: Save description files along with TFRecords   \nVersion 11: Merged images","9bd515d2":"### Augmentations","47d8445e":"### Writing TFRecords\n","2d0d2630":"### Image generator\n\nMake a provision such that images are provided and written to TFrecords without too much RAM consumption. "}}