{"cell_type":{"cdff4142":"code","9de6633b":"code","0406ccb7":"code","333eeff5":"code","be7918bb":"code","bc86f59b":"code","c7ff12a1":"code","8d72bfd9":"code","99da8453":"code","8e62d849":"code","098f95bc":"code","951568d2":"code","3d64afbe":"code","08996ca6":"code","c3e0c26c":"code","dfa88019":"code","ee54327c":"code","4ade762e":"code","e2a62e9c":"code","0b88a5b3":"code","0a9423e3":"code","d7f72cbd":"code","1de013ad":"code","2ccebe7a":"code","42f405fb":"code","df37253b":"code","e5c714e8":"code","1158a764":"markdown","b78fef3d":"markdown","de2f6168":"markdown"},"source":{"cdff4142":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9de6633b":"import seaborn as sns\nimport matplotlib.pyplot as plt","0406ccb7":"df_titanic_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col = 'PassengerId')\ndf_titanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col = 'PassengerId')\ndf_result_format = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","333eeff5":"print(df_titanic_train.info())\nprint(df_titanic_test.info())\n","be7918bb":"# Check missing values\nmissing_values_count = df_titanic_train.isnull().sum()\nprint(missing_values_count)\n## Age, Cabin and Emabarked has Missing Values","bc86f59b":"# Drop Embarked NAs, since it is too less and it doesn't make sense to impute\ndf_titanic_train = df_titanic_train[df_titanic_train['Embarked'].notna()]\ndf_titanic_test = df_titanic_test[df_titanic_test['Embarked'].notna()]","c7ff12a1":"len(df_titanic_test)","8d72bfd9":"## Age\ng = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","99da8453":"# Pclass\ng = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'Pclass', bins=20)","8e62d849":"# Sex\ng = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'Sex', bins=20)","098f95bc":"#Parch - # of parents \/ children aboard the Titanic\ng = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'Parch', bins=20)","951568d2":"#SibSp: # of siblings \/ spouses aboard the Titanic\nprint(df_titanic_train.SibSp.unique())\nprint(df_titanic_train.groupby(['SibSp','Survived']).Name.count())\ng = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'SibSp', bins=20)","3d64afbe":"g = sns.FacetGrid(df_titanic_train, col='Survived')\ng.map(plt.hist, 'Embarked', bins=20)","08996ca6":"## Drop Ticket and Cabin, since we are not using it\ndf_titanic_train.drop(columns=['Ticket','Cabin','Name'], inplace = True)\ndf_titanic_test.drop(columns=['Ticket','Cabin', 'Name'], inplace = True)","c3e0c26c":"# Impute Age\ndf_titanic_train.Age.fillna(df_titanic_train.Age.mean(), inplace = True)\ndf_titanic_test.Age.fillna(df_titanic_train.Age.mean(), inplace = True)","dfa88019":"from sklearn.model_selection import train_test_split\n\nX_train = df_titanic_train.drop('Survived', axis = 1)\ny_obsv = df_titanic_train['Survived']\n\nX_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X_train,y_obsv,test_size=0.2,random_state=1)","ee54327c":"categorical_cols = [col_names for col_names in df_titanic_train.columns if df_titanic_train[col_names].dtype == 'object']","4ade762e":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier","e2a62e9c":"# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[('cat', categorical_transformer, categorical_cols)])\n\n# Define model\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n# Preprocessing of training data, fit model \nclf.fit(X_train_80, y_train_80)\n\n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_test_20)","0b88a5b3":"conf_mat = pd.crosstab(preds, y_test_20, \n            rownames=['pred'], \n            colnames=['Actual'])\nconf_mat","0a9423e3":"# True Positives\nTP = conf_mat[1][1]\nprint('True Positives: ', TP)\n\n# True Negatives\nTN = conf_mat[0][0]\nprint('True Negatives: ', TN)\n\n# False Positives\nFP = conf_mat[0][1]\nprint('False Positives: ', FP)\n\n# False Negatives\nFN = conf_mat[1][0]\nprint('False Negatives: ', FN)\n\nprint('---------')\n\nPrecision = round((TP\/(TP+FP))*100,2)\nRecall = round((TP\/(TP+FN))*100,2)\n\nprint(f'Precision is {Precision}%')\nprint(f'Recall is {Recall}%')","d7f72cbd":"df_result_format.head()","1de013ad":"preds_new = clf.predict(df_titanic_test)","2ccebe7a":"df_titanic_test['Survived'] = preds_new","42f405fb":"df_titanic_test1 = df_titanic_test.reset_index()\ndf_titanic_test2 = df_titanic_test1[['PassengerId','Survived']]","df37253b":"len(df_titanic_test2)","e5c714e8":"df_titanic_test2.to_csv('final_result.csv')","1158a764":"### Pipeline","b78fef3d":"## Exploration","de2f6168":"Notes:\n1. Not using Features - Ticket, Cabin and Name\n2. Impute Emabarked - 'S'\n3. Impute Age with Mean. \n4. One hot encoding needed: Pclass, Sex"}}