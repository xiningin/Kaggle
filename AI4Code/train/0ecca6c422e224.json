{"cell_type":{"aa9c19b4":"code","0bd53bfd":"code","cd450f0c":"code","d6287cb2":"code","3a81509c":"code","b5d3c0a9":"code","5fc25f1a":"code","fd7ada88":"code","2f86f55c":"code","05d79e80":"code","ee1a66c8":"code","d7ea7c6f":"code","37655577":"code","ee442a05":"code","a4e30d5d":"code","cff174d1":"code","0005289d":"code","888f0199":"markdown","3000ad12":"markdown","a77478df":"markdown","a7152688":"markdown","7cd5901f":"markdown","9883861d":"markdown","797f08c0":"markdown","86cf3db2":"markdown"},"source":{"aa9c19b4":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, make_scorer, recall_score, roc_auc_score\nfrom xgboost import XGBClassifier, plot_importance\nfrom pdpbox import pdp, get_dataset, info_plots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","0bd53bfd":"df = pd.read_csv('..\/input\/bank-customers\/Churn Modeling.csv')\ndf.head()","cd450f0c":"df.info()","d6287cb2":"print(df.columns)","3a81509c":"df.drop(df.columns[[0,1]], axis=1, inplace=True)\n\nunique_vals = {}\nprint('Unique values for each feature:\\n')\nfor column in df.columns:\n    unique_vals[column]=df[column].unique()\n    print(len(unique_vals[column]), 'unique values of ', column)","b5d3c0a9":"fig, axes = plt.subplots(4, 3, figsize=(15,15))\nsns.histplot(ax=axes[0, 0], data=df, x=\"CreditScore\", hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[0, 1], data=df, x='Age', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[0, 2], data=df, x='Tenure', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 0], data=df, x='Balance', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 1], data=df, x='NumOfProducts', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 2], data=df, x='EstimatedSalary', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 0], data=df, x='Geography', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 1], data=df, x='Gender', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 2], data=df, x='HasCrCard', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[3, 0], data=df, x='IsActiveMember', hue=\"Exited\", multiple=\"stack\")","5fc25f1a":"cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Exited']\nsns.pairplot(df[cols], hue='Exited', kind='hist', height=2)\nplt.show();","fd7ada88":"# encode the categorical features\ncat_features = ['Geography', 'Gender']\nohe = OneHotEncoder(sparse=False, dtype='int64', drop='if_binary')\ncat_encoded = ohe.fit_transform(df[cat_features])\ncolumn_name = ohe.get_feature_names(cat_features)\nohe_frame =  pd.DataFrame(cat_encoded, columns= column_name)\ndf = pd.concat([df.select_dtypes(exclude='object'), ohe_frame], axis=1)\n#df.info()","2f86f55c":"corrmatrix = df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax = sns.heatmap(corrmatrix, vmax=.8, square=True, annot=True, cmap=\"YlGnBu\")","05d79e80":"X = df.drop(['Exited'], axis=1)\ny = df['Exited']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n\nparam_grid = {'max_depth':range(3,15),'criterion':['gini','entropy']}\nrf = RandomForestClassifier(random_state=4)\nmodel_rf = GridSearchCV(rf, param_grid=param_grid)\nmodel_rf.fit(X_train, y_train)\npred_test = model_rf.predict(X_test)\nprint('Classification Report of RandomForestClassifier: \\n', classification_report(y_test, pred_test))\n#scores = cross_val_score(model_rf, X, y, scoring='roc_auc')\n#roc_auc_score(y_test, model_rf.predict_proba(X_test)[:, 1], average='weighted')\n#print ('cross validation score of RandomForestClassifier: %.8f'%scores.mean())","ee1a66c8":"rf1 = model_rf.best_estimator_\nimportances1 = rf1.feature_importances_\nfeature_importances = pd.Series(importances1, index=X.columns)\nfeature_importances.nlargest(12).plot(kind='barh')","d7ea7c6f":"rf2 = RandomForestClassifier(random_state=4, class_weight={0:1,1:5})\n# For imbalanced sample: less 'Exited'=1 present, give 'Exited'=1 more weight. \nscorer = make_scorer(recall_score)\nmodel_rf2 = GridSearchCV(rf2, param_grid=param_grid, scoring=scorer)\nmodel_rf2.fit(X_train, y_train)\npred_test = model_rf2.predict(X_test)\nprint('Classification Report of RandomForestClassifier: \\n', classification_report(y_test, pred_test))","37655577":"best_rf = model_rf2.best_estimator_\nimportances = best_rf.feature_importances_\nfeature_importances = pd.Series(importances, index=X.columns)\nfeature_importances.nlargest(12).plot(kind='barh')","ee442a05":"for target_feature in ['Age', 'NumOfProducts', 'IsActiveMember']:\n    pdp_i = pdp.pdp_isolate(model=best_rf, dataset=X, model_features=X.columns, feature=target_feature)\n    pdp.pdp_plot(pdp_i, target_feature, figsize=(8,5))","a4e30d5d":"xgb = XGBClassifier()\n\"\"\"\nparam_grid = {'learning_rate': [0.01, 0.05], \n#        'min_child_weight': [1, 5],\n#        'subsample': [0.6, 0.8],\n#        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [5, 8],\n#        'n_estimators': [100, 500]\n        }\n\nmodel_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='roc_auc')\n\"\"\"\nxgb.fit(X_train, y_train)\npred_test = xgb.predict(X_test)\nprint('Classification Report of XGBClassifier: \\n', classification_report(y_test, pred_test))\n#scores = cross_val_score(model_xgb, X, y, scoring='roc_auc')\n#print ('cross validation score of XGBClassifier: %.8f'%scores.mean())","cff174d1":"xgb = XGBClassifier(scale_pos_weight=5)\nxgb.fit(X_train, y_train)\npred_test = xgb.predict(X_test)\nprint('Classification Report of XGBClassifier: \\n', classification_report(y_test, pred_test))","0005289d":"plot_importance(xgb)","888f0199":"Something interesting: Balance of customers from different countries varies a lot. ","3000ad12":"The dataset is from kaggle [data](https:\/\/www.kaggle.com\/santoshd3\/bank-customers)   ","a77478df":"Let's try another model:","a7152688":"We can see the recall is not good, meaning a lot of false negatives. Let's try to improve that if we don't want to miss potentially positive cases. ","7cd5901f":"It seems we achieve a good recall though the accuracy is relatively low. We need to tune the model according to our business objectives, like intervening before the exiting happens. In such cases, we may be willing to sacrifice accuracy for recall.","9883861d":"We can see generally, customers from the following groups are more likely to exit: \n1. Over the age of 40.\n2. From Germany.\n3. Female.\n\nCustomers from the following groups are less likely to exit: \n1. Having 2 products.\n2. Active members. ","797f08c0":"We can see there are no missing values. The datatypes are all good. ","86cf3db2":"No replicated CustomerId. Numbers of unique values of Gender, HasCrCard, IsActiveMember, Exited are legit."}}