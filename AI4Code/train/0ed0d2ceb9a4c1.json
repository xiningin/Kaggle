{"cell_type":{"ded28697":"code","af36b953":"code","9cb3d9b3":"code","07e9b2c3":"code","c8bfca8f":"code","0ecc7ad0":"code","3df512f4":"code","1206fc12":"code","0d93f566":"markdown","fcddc1ba":"markdown"},"source":{"ded28697":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nml.style.use('fivethirtyeight')\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,accuracy_score,recall_score,f1_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af36b953":"data = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndata.head(10)","9cb3d9b3":"data.info()","07e9b2c3":"data.describe()","c8bfca8f":"X = np.array(data.iloc[:,:-1].values)\nY = np.array(data.iloc[:,-1].values)\ntrainx,testx,trainy,testy = train_test_split(X,Y,test_size=0.2,random_state=0)\n# Scaling\nsc = StandardScaler()\ntrainx,testx = sc.fit_transform(trainx),sc.fit_transform(testx)\n\nprint(\"For X : Training : {} ; Testing : {}\".format(trainx.shape,testx.shape))\nprint(\"\\nFor Y : Training : {} ; Testing : {}\".format(trainy.shape,testy.shape))\n\nsns.pairplot(data,hue='Outcome')\nplt.show()","0ecc7ad0":"# RBF Kernel\nm=50\naccuracy,recall,f1 = [],[],[]\nx_axis = [i for i in range(1,m)]\nfor i in range(1,m):\n    svm_c = SVC(kernel='rbf',C=i,gamma='auto')\n    svm_c.fit(trainx,trainy)\n    y_pred_i = svm_c.predict(testx)\n    accuracy.append(accuracy_score(testy,y_pred_i))\n    recall.append(recall_score(testy,y_pred_i))\n    f1.append(f1_score(testy,y_pred_i))\n    print(\"For C = {},\".format(i),\"confusion matrix : \\n\",confusion_matrix(testy,y_pred_i),\"\\n\")","3df512f4":"plt.figure(figsize=(20,10))\nplt.plot(x_axis,accuracy,color='red',marker='o',label='Accuracy')\nplt.plot(x_axis,recall,color='blue',marker='x',label='Recall score')\nplt.plot(x_axis,f1,color='green',marker='x',label='F1 score')\nplt.legend()\nplt.xlabel(\"Value of C\")\nplt.ylabel(\"Metric score\")\nplt.title(\"Comparison plot\")\nplt.show()","1206fc12":"print(\"METRIC : ACCURACY\\nHighest accuracy is obtained for C = {}, and the accuracy is = {}\".format(np.argmax(accuracy)+1,accuracy[np.argmax(accuracy)]))\nprint(\"\\nMETRIC : RECALL SCORE\\nHighest accuracy is obtained for C = {}, and the accuracy is = {}\".format(np.argmax(recall)+1,accuracy[np.argmax(recall)]))\nprint(\"\\nMETRIC : F1 SCORE\\nHighest accuracy is obtained for C = {}, and the accuracy is = {}\".format(np.argmax(f1)+1,accuracy[np.argmax(f1)]))","0d93f566":"### Clearly, the best value of C is = 1, for which accuracy = 0.8051","fcddc1ba":"### Building the model"}}