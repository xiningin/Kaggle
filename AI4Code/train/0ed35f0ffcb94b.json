{"cell_type":{"cde63a10":"code","58941028":"code","845fae0f":"code","e6e7dfee":"code","bd5511fc":"code","6f208ee1":"code","93604269":"code","58573bb1":"code","698d942d":"markdown"},"source":{"cde63a10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split #create training and test data sets\nfrom sklearn.tree import DecisionTreeClassifier #create a decision tree \nfrom sklearn import tree #for visualization of the decision tree\nfrom matplotlib import pyplot as plt #vis tool\nimport seaborn as sns #vis tool\nfrom sklearn.feature_selection import SelectFromModel #feature selection\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58941028":"#load training data\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()\n\n","845fae0f":"#load test data\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","e6e7dfee":"#df information\ntrain_data.info()\ntrain_data.describe()","bd5511fc":"#missing data\nprint(train_data.isna().sum())","6f208ee1":"#exploratory data anyalysis\nplt.figure(figsize = (16, 12))\nsns.heatmap(df.isna(), cmap = 'plasma', yticklabels = False)\nplt.title(\"Visualizing the Missing Data\", fontsize = 20)\nplt.xticks(rotation = 45, fontsize = 12)\nplt.show()\n","93604269":"#remove all missing data\ntrain_dropNA = train_data.dropna()\nage_y = train_dropNA['Age']\nage_X = train_dropNA.drop(['Age'])\n#feature selection technique.\n","58573bb1":"### Decision Tree prediction model.\n\n#create target variable\ny = train_data['Survived']\n\nfeatures = ['Pclass','Sex']\n#get_dummies converts to categorical data to 0's and 1's\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\n#create and train model then predict the test data\nclassifier = DecisionTreeClassifier()\nclassifier.fit(X, y)\npredictions = classifier.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\n\nprint(\"Your submission was successfully saved!\")","698d942d":"#### Due to the overwhelming amount of missing data, we will not be using the cabin feature.\nWe also need to deal with the missing data in the age and embarked features.\nTo do this, we will try to find which features best predict age, and use this predictions to fill in the missing data."}}