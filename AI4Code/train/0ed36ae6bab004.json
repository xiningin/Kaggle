{"cell_type":{"ef21555f":"code","75f3126c":"code","26f5d324":"code","7a1714e2":"code","2fae4854":"code","d78de1c5":"code","82c50bc0":"code","de985026":"code","5f4a3ae3":"code","fe4bfb06":"code","43350ae7":"code","8a2fd5f9":"code","5b83fbf8":"code","0f64ed5d":"code","f126be63":"code","a6e8a27b":"code","8079c9bb":"code","bc70f3a2":"code","6b187c0b":"code","a8c08bf1":"code","5acac849":"code","a4186901":"code","fb4a41e1":"code","946ee7e6":"code","229f700e":"code","94882518":"code","b4c4ec67":"code","50d7369b":"code","6e91c926":"code","1867272f":"code","f8694507":"code","82136571":"code","6e9a6877":"code","c77d237d":"code","87dbe1de":"code","ca833673":"code","bf56d2b0":"code","c3090e5d":"code","6415b5d1":"code","1244e82f":"code","4e2c89e7":"code","fb7a8f50":"code","3aa3d5f8":"code","ad59187c":"code","3126de30":"code","b08cfa97":"code","e8e1bb66":"code","67859358":"code","e727c1ef":"code","cb7db024":"code","f3de8bc4":"markdown","9c528e00":"markdown","422e0e1c":"markdown","7a36342e":"markdown","aa2fddac":"markdown","71332d6c":"markdown","36cd721e":"markdown","6a0a1620":"markdown","68577ab6":"markdown","ace88ec3":"markdown","de0f0fae":"markdown"},"source":{"ef21555f":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import decode_predictions\nfrom keras.layers import Dense\nfrom keras import Model\nfrom keras import optimizers\nfrom keras.layers import Input, Lambda, Dense, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\nfrom IPython.display import Image\n\nimport tensorflow as tf\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","75f3126c":"model = VGG16()","26f5d324":"def predictImg(url):\n    img = load_img(url, target_size=(224, 224))\n    img = img_to_array(img) \n    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n    img = preprocess_input(img)\n    y = model.predict(img)\n    print('Top 3 :', decode_predictions(y, top=3)[0])\n    display(Image(filename=url))","7a1714e2":"predictImg('..\/input\/yelp-photos\/photos\/--N1ios0yLK3XssOp_r6jQ.jpg')","2fae4854":"predictImg('..\/input\/yelp-photos\/photos\/--6rjtLUfrLdtvFMWRbOzw.jpg')","d78de1c5":"predictImg('..\/input\/yelp-photos\/photos\/--M6sLAJI7U9cudouOLeAg.jpg')","82c50bc0":"predictImg('..\/input\/yelp-photos\/photos\/--CUXjT1g85E9V1CSDS2Jg.jpg')","de985026":"nbPictures = 10000\nchunks = pd.read_json('..\/input\/yelp-photos\/photos.json', lines=True, chunksize = nbPictures)","5f4a3ae3":"%%time\ndf = pd.DataFrame(columns=['photo_id', 'label'])\nx = 0\nfor chunk in chunks:\n    if(x == 0):\n        if ((chunk.iloc[0].label == 'drink') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])   \n            x = x + 1\n    if(x == 1):    \n        if ((chunk.iloc[0].label == 'food') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 2):    \n        if ((chunk.iloc[0].label == 'interior') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 3):    \n        if ((chunk.iloc[0].label == 'outside') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 4):    \n        if ((chunk.iloc[0].label == 'menu') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 5):\n        break\ndf","fe4bfb06":"df = df.assign(photo_id=lambda x: x + '.jpg')","43350ae7":"df_train = df.sample(round(5*nbPictures*(4\/5)),random_state=42)","8a2fd5f9":"df_test = df.merge(df_train, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']","5b83fbf8":"print(df_train.shape)\ndf_train.head()","0f64ed5d":"print(df_test.shape)\ndf_test.head()","f126be63":"train_datagen = ImageDataGenerator(\n        rescale=1 \/ 255.0,\n        rotation_range=20,\n        zoom_range=0.05,\n        width_shift_range=0.05,\n        height_shift_range=0.05,\n        shear_range=0.05,\n        horizontal_flip=True,\n        fill_mode=\"nearest\",\n        validation_split=0.20)\n\nvalid_datagen = ImageDataGenerator(\n        rescale=1 \/ 255.0,\n        validation_split=0.20\n)","a6e8a27b":"batch_size=64","8079c9bb":"PATH = '..\/input\/yelp-photos\/photos\/'\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=PATH,\n    x_col='photo_id',\n    y_col='label',\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset='training',\n    shuffle=True,\n    seed=42\n)\nvalid_generator  = valid_datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=PATH,\n    x_col='photo_id',\n    y_col='label',\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset='validation',\n    shuffle=True,\n    seed=42\n)","bc70f3a2":"model_ft = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))","6b187c0b":"for layer in model_ft.layers:\n    layer.trainable = False","a8c08bf1":"out = model_ft.output\n\nx = Flatten()(out)\nx = Dropout(0.5)(x)\nx = Dense(5, activation='softmax')(x)\n     \nmodel_ft = Model(inputs=model_ft.input, outputs=x)\nmodel_ft.compile(loss=\"categorical_crossentropy\",\n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n     \nmodel_ft.summary()","5acac849":"es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc= ModelCheckpoint('\/kaggle\/working\/vgg16.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\ncallbacks=[es,mc]","a4186901":"epochs = 30\n \nhistory = model_ft.fit(\n    train_generator,\n    validation_data = train_generator,\n    steps_per_epoch = train_generator.n\/\/train_generator.batch_size,\n    validation_steps = valid_generator.n\/\/valid_generator.batch_size,\n    epochs=epochs,\n    callbacks=callbacks\n)","fb4a41e1":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","946ee7e6":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","229f700e":"score = model_ft.evaluate_generator(valid_generator)\nprint('val loss:', score[0])\nprint('val accuracy:', score[1])","94882518":"result = [(0, 'drink'),(1, 'food'),(2, 'interior'), (3, 'menu'), (4, 'outside')]\nresult = pd.DataFrame(columns=['id', 'label'], data=result)\n\nresult","b4c4ec67":"def predictImgTL(url, model):\n    #Predict image using transfert learning model\n    img = load_img(PATH + url, target_size=(224, 224))\n\n    #Rescale 1\/255\n    img = np.asarray(img)\n    img = img.astype('float32')\n    img \/= 255.0\n\n\n    \n#    img = img_to_array(img)     \n    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n\n    #Predict\n    y_label = model.predict(img)\n    y_argmax = np.argmax(y_label)\n    print('## Predicted label is :', result.loc[result.id == y_argmax].label.values[0])\n    print('Rates :', y_label, '\\n')\n    \n    display(Image(filename=PATH + url, width=150))","50d7369b":"predictImgTL('--M6sLAJI7U9cudouOLeAg.jpg', model_ft)","6e91c926":"predictImgTL('--CUXjT1g85E9V1CSDS2Jg.jpg', model_ft)","1867272f":"predictImgTL('--6rjtLUfrLdtvFMWRbOzw.jpg', model_ft)","f8694507":"predictImgTL('--N1ios0yLK3XssOp_r6jQ.jpg', model_ft)","82136571":"predictImgTL('Un_Og6jfhazVn7CxszkKEw.jpg', model_ft)","6e9a6877":"df_test","c77d237d":"test_result = df_test[['photo_id', 'label']]\ntest_result['predicted'] = ''\ntest_result = test_result.reset_index(drop=True)","87dbe1de":"def predictLabel(url, model):\n    img = load_img(PATH + url, target_size=(224, 224))\n\n    #Rescale 1\/255\n    img = np.asarray(img)\n    img = img.astype('float32')\n    img \/= 255.0\n    \n    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n   \n    y_label = model.predict(img)\n    y_argmax = np.argmax(y_label)\n    y = result.loc[result.id == y_argmax].label.values[0]\n    return y","ca833673":"%%time\nfor i, val in test_result.iterrows():\n    test_result.loc[i].predicted = predictLabel(val.photo_id, model_ft)","bf56d2b0":"test_result['score'] = ''\nfor i, val in test_result.iterrows():\n    if(val.label == val.predicted):\n        test_result.loc[i].score = 1\n    else:\n        test_result.loc[i].score = 0","c3090e5d":"test_result.score.value_counts(normalize=True)","6415b5d1":"test_result[test_result.score == 0]","1244e82f":"result.label","4e2c89e7":"for label in result.label:\n    print(test_result[test_result.label == label].score.mean())","fb7a8f50":"predictImgTL('W6XVk8sj_OHyxl10yJhlCw.jpg', model_ft)","3aa3d5f8":"predictImgTL('gsE91km5SI6xi8jsp5M2rg.jpg', model_ft)","ad59187c":"# Unfreeze the base model\nfor layer in model_ft.layers:\n    layer.trainable = True\n\nmodel_ft.compile(loss=\"categorical_crossentropy\",\n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n\n\nhistory2 = model_ft.fit(\n    train_generator,\n    validation_data = train_generator,\n    steps_per_epoch = train_generator.n\/\/train_generator.batch_size,\n    validation_steps = valid_generator.n\/\/valid_generator.batch_size,\n    epochs=epochs,\n    callbacks=callbacks\n)","3126de30":"plt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","b08cfa97":"plt.plot(history2.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e8e1bb66":"test_result2 = df_test[['photo_id', 'label']]\ntest_result2['predicted'] = ''\ntest_result2 = test_result2.reset_index(drop=True)","67859358":"%%time\nfor i, val in test_result2.iterrows():\n    test_result2.loc[i].predicted = predictLabel(val.photo_id, model_ft)","e727c1ef":"test_result2['score'] = ''\nfor i, val in test_result2.iterrows():\n    if(val.label == val.predicted):\n        test_result2.loc[i].score = 1\n    else:\n        test_result2.loc[i].score = 0","cb7db024":"test_result2.score.value_counts(normalize=True)","f3de8bc4":"## Fine tuning","9c528e00":"The hardest test : is this some food or what ?\n![t\u00e9l\u00e9chargement (55).jpg](attachment:2843afb1-b2b2-4b40-a476-cc696313b6de.jpg)","422e0e1c":"## Preparing VGG16 for transfert learning","7a36342e":"## Transfert learning results","aa2fddac":"### **Import result down here**\nAccuracy score is the number next to 1 on the cell below","71332d6c":"## Fine tuning results","36cd721e":"## More testing","6a0a1620":"## Data Generators","68577ab6":"## Transfert learning VGG 16","ace88ec3":"## Preparing data","de0f0fae":"## Classifying pictures using default VGG-16"}}