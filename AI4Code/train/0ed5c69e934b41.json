{"cell_type":{"8fcb53e6":"code","6a339730":"code","52d8efe6":"code","e157f1da":"code","907d8e1a":"code","0d8816d7":"code","48505ccb":"code","61b77c1c":"code","8e7ae339":"code","730f82b6":"code","1722e94f":"code","53e03328":"code","0e735776":"code","c5956693":"code","bf8139d0":"code","13b6bd31":"code","152d1bce":"code","b0483e1b":"code","d4aa5ea1":"code","b468c365":"code","d11ae1be":"code","6668dd0c":"code","8849fcd6":"code","3cbf1673":"code","f63d4e19":"code","159a9075":"code","e4e2ddf2":"code","582d87b7":"code","5dd1b8fb":"code","fc4ca076":"code","62eac3be":"code","06139802":"code","74805c8e":"code","1235c39a":"code","d21bebc6":"code","7c8a0034":"code","88322526":"code","5187308e":"code","8f03b498":"code","e9c56162":"code","3787b0b5":"code","66356a62":"code","aa255eae":"code","f07127da":"code","d7ea6dd0":"code","1760da06":"code","16667fbc":"code","d3448735":"code","fa258c45":"code","3a5a305c":"code","193a7fe5":"code","8efc2e21":"code","a8b27933":"code","abb5158e":"code","a2a5acba":"code","0cf8cc8e":"code","7d067911":"code","dd6d4aee":"code","92464fd1":"code","69c11fa5":"code","f8e09911":"code","d545b6e7":"code","7e5729d2":"code","d720ce4c":"code","b65b9f1c":"code","36a6f866":"code","eef2fb5d":"code","9c0b600c":"code","2189fff1":"code","beaf7e8b":"code","09f52768":"code","c3ee75e1":"markdown","ec946095":"markdown","056daf82":"markdown","725beb72":"markdown","93d7c0af":"markdown","b78aed93":"markdown","07c8254b":"markdown","b9c06502":"markdown","3f79793a":"markdown","00b88261":"markdown","94ed0da5":"markdown","bb418d09":"markdown","b7ccc56f":"markdown","d4a8bb11":"markdown","cf25990f":"markdown"},"source":{"8fcb53e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpcful packages to load\nimport os \nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport random\nimport csv\nimport cv2\nimport math\nimport PIL\nfrom collections import namedtuple, OrderedDict\nimport io\nfrom PIL import Image\nfrom collections import namedtuple, OrderedDict\n\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a339730":"DATA_DIR = '..\/input\/airbus-ship-detection\/' \nROOT_DIR = '\/kaggle\/working'\nos.chdir(ROOT_DIR)","52d8efe6":"train_v2_list = os.listdir(DATA_DIR + 'train_v2')","e157f1da":"train_df = pd.read_csv(DATA_DIR + \"train_ship_segmentations_v2.csv\")\ntrain_df","907d8e1a":"train_df['ShipCount'] = train_df.groupby('ImageId')['ImageId'].transform('count')\ntrain_df.loc[train_df['EncodedPixels'].isnull().values,'ShipCount'] = 0","0d8816d7":"train_df","48505ccb":"count_df = train_df.groupby('ShipCount').count()\ncount_df","61b77c1c":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(count_df.index.values.tolist(), list(count_df['ImageId']))\nplt.show()","8e7ae339":"sampleList = ['001aee007.jpg','001234638.jpg','001f04ca3.jpg','000d26c17.jpg']\nsampleImgList = []\nfor x in sampleList:\n    sampleImgList.append(mpimg.imread(DATA_DIR + 'train_v2\/' + x))","730f82b6":"fig = plt.figure(1,figsize=(20,10))\nfor i in range(len(sampleImgList)):\n    image_tmp = sampleImgList[i]\n    ax = fig.add_subplot(1,4,i+1)\n    ax.imshow(image_tmp)","1722e94f":"from skimage.feature import canny\nfrom skimage.filters import scharr, unsharp_mask\nfrom skimage import exposure\nfrom skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value","53e03328":"fig = plt.figure(1,figsize=(20,20))\nfor i in range(len(sampleImgList)):\n    image_tmp = sampleImgList[i]\n    ax = fig.add_subplot(2,4,i+1)\n    ax.imshow(image_tmp)\n    image_tmp = unsharp_mask(sampleImgList[i], radius=4, amount=2)\n    sampleImgList[i] = image_tmp\n    ax = fig.add_subplot(1,4,i+1)\n    ax.imshow(image_tmp)","0e735776":"def rle_to_pixels(rle_code):\n    '''\n    Transforms a RLE code string into a list of pixels of a (768, 768) canvas\n    '''\n    rle_code = [int(i) for i in rle_code.split()]\n#     pixels = [(pixel_position % 768, pixel_position \/\/ 768) \n#                  for start, length in list(zip(rle_code[0:-1:2], rle_code[1::2])) \n#                  for pixel_position in range(start, start + length)]\n    \n    pixels = []\n    for start, length in list(zip(rle_code[0:-1:2], rle_code[1::2])):\n        for pixel_position in range(start, start + length):\n            pixels.append((pixel_position % 768, pixel_position \/\/ 768))\n            #if pixel_position < 0 or pixel_position > 768:\n                #print(pixel_position)\n    \n    return pixels\n\ndef get_all_masks(image_id):\n    ret = []\n    s = train_df[train_df['ImageId'] == image_id]['EncodedPixels']\n    if not s.isnull().values.any():\n        for x in s:\n            ret.append(rle_to_pixels(x))\n    return ret\n\ndef show_masks(image_id):\n    canvas = np.zeros((768, 768))\n    masks = get_all_masks(image_id)\n    for x in masks:\n       canvas[tuple(zip(*x))] = 1\n    return canvas\n\ndef find_bounding_box(pixels):\n    xmin = 767\n    xmax = 1\n    ymin = 767\n    ymax = 1\n    for p in pixels:\n        px = p[0]\n        py = p[1]\n        if px !=0 and py != 0 and px !=768 and py != 768:\n            if px < xmin:\n                xmin = px\n            if px > xmax:\n                xmax = px\n            if py < ymin:\n                ymin = py\n            if py > ymax:\n                ymax = py\n    return xmin, ymin, xmax, ymax\n\ndef get_all_boxes(image_id):\n    ret = []\n    masks = get_all_masks(image_id)\n    for x in masks:\n        ret.append(find_bounding_box(x))\n    return ret\n\ndef show_bounding_box(image_id):\n    canvas = np.array(PIL.Image.open(DATA_DIR + 'train_v2\/' + image_id))\n    boxes = get_all_boxes(image_id)\n    for x in boxes:\n        xmin, ymin, xmax, ymax = x[0],x[1], x[2], x[3]\n        canvas[xmin][ymin : ymax] = [0,255,0]\n        canvas[xmax][ymin : ymax] = [0,255,0]\n        canvas[:,ymin][xmin : xmax] = [0,255,0]\n        canvas[:,ymax][xmin : xmax] = [0,255,0]\n    return canvas","c5956693":"fig = plt.figure(1,figsize=(20,20))\nfor i in range(len(sampleList)): \n    image_tmp = show_masks(sampleList[i])\n    ax = fig.add_subplot(1,4,i+1)\n    ax.imshow(image_tmp)\n    image_tmp = show_bounding_box(sampleList[i])\n    ax = fig.add_subplot(2,4,i+1)\n    ax.imshow(image_tmp)","bf8139d0":"!pip uninstall -y tensorflow\n!pip uninstall -y tensorflow-gpu\n!pip uninstall -y tensorflow-estimator","13b6bd31":"#Change TF version\n!pip list | grep tensorflow\n!pip install tensorflow-gpu==1.15 #1.15\n# !pip uninstall -y tensorflow==2.2\n# !pip list | grep tensorflow\n!pip install tensorflow-estimator==1.15\n!pip list | grep tensorflow","152d1bce":"import os\nos.getcwd()","b0483e1b":"import tensorflow as tf\ntf.__version__","d4aa5ea1":"from tensorflow.python.client import device_lib \nprint(device_lib.list_local_devices())","b468c365":"tf.test.is_gpu_available(\n    cuda_only=False, min_cuda_compute_capability=None\n)","d11ae1be":"!pip install tensorflow-object-detection-api==0.1.0 --no-dependencies","6668dd0c":"os.chdir(ROOT_DIR)\n!git clone https:\/\/github.com\/tensorflow\/models.git\n#!git clone https:\/\/github.com\/tensorflow\/models\/archive\/v2.2.0.zip\n# !wget  https:\/\/github.com\/tensorflow\/models\/archive\/v2.2.0.zip","8849fcd6":"os.chdir(ROOT_DIR)","3cbf1673":"ls","f63d4e19":"!apt-get -y install protobuf-compiler\n!pip install Cython\n!pip install pillow\n!pip install lxml\n!pip install jupyter\n!pip install matplotlib\n!pip install tf_slim","159a9075":"os.chdir(ROOT_DIR+\"\/models\/research\/\")\n!protoc object_detection\/protos\/*.proto --python_out=.\n!export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`\/slim\nos.environ['PYTHONPATH'] += ':\/kaggle\/working\/models\/research\/:\/kaggle\/working\/models\/research\/slim\/:\/kaggle\/working\/models'","e4e2ddf2":"os.getcwd()","582d87b7":"#Test if set up is successful\n!python .\/models\/research\/object_detection\/builders\/model_builder_test.py\n# !python object_detection\/builders\/model_builder_tf2_test.py","5dd1b8fb":"os.chdir(ROOT_DIR)","fc4ca076":"with open(ROOT_DIR+'\/labelmap.pbtxt', 'w+') as the_file:\n    the_file.write('item\\n')\n    the_file.write('{\\n')\n    the_file.write('id :{}'.format(int(1)))\n    the_file.write('\\n')\n    the_file.write(\"name :'{0}'\".format('ship'))\n    the_file.write('\\n')\n    the_file.write('}\\n')\n    the_file.close()","62eac3be":"import xml.etree.cElementTree as ET\ndef generate_xml(imageId):\n    annotation = ET.Element(\"annotation\")\n    ET.SubElement(annotation, \"folder\").text = \"train_v2\"\n    ET.SubElement(annotation, \"filename\").text = imageId\n    source = ET.SubElement(annotation, \"source\")\n    ET.SubElement(source, \"database\").text = \"Unknown\"\n    size = ET.SubElement(annotation, \"size\")\n    ET.SubElement(size, \"width\").text = \"768\"\n    ET.SubElement(size, \"height\").text = \"768\"\n    ET.SubElement(size, \"depth\").text = \"3\"\n    ET.SubElement(annotation, \"segmented\").text = \"0\"\n    \n    boxes = get_all_boxes(imageId)\n    for b in boxes:\n        object1 = ET.SubElement(annotation, \"object\")\n        ET.SubElement(object1, \"name\").text = \"ship\"\n        ET.SubElement(object1, \"name\").text = \"ship\"\n        ET.SubElement(object1, \"pose\").text = \"Unspecified\"\n        ET.SubElement(object1, \"truncated\").text = \"0\"\n        ET.SubElement(object1, \"difficult\").text = \"0\"\n        bndbox = ET.SubElement(object1, \"bndbox\")\n        xmin, ymin, xmax, ymax = b\n        ET.SubElement(bndbox, \"xmin\").text = str(xmin)\n        ET.SubElement(bndbox, \"ymin\").text = str(ymin)\n        ET.SubElement(bndbox, \"xmax\").text = str(xmax)\n        ET.SubElement(bndbox, \"ymax\").text = str(ymax)\n\n    tree = ET.ElementTree(annotation)\n    tree.write(\"test.xml\")","06139802":"data = []\n###############################################DEBUG\nfor x in train_df['ImageId'][:100]:\n    boxes = get_all_boxes(x)\n    for b in boxes:\n        xmin, ymin, xmax, ymax = b\n        data.append((x, 768, 768, 'ship', xmin, ymin, xmax, ymax))\ncolumns_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\nTFRcords_df = pd.DataFrame(data=data, columns=columns_name)\nTFRcords_df","74805c8e":"#A naive way to split for code testing\n\ntrain_set = TFRcords_df[0:20]\nvalid_set = TFRcords_df[21:25]","1235c39a":"# pip install tf-nightly","d21bebc6":"sys.path.append(\"..\")\nfrom models.research.object_detection.utils import dataset_util\nfrom models.research.object_detection.utils import label_map_util","7c8a0034":"# Function to group data and return the same\n# Group by imagefile name\ndef make_groups(df, field=None):\n    if field==None:\n        field = 'filename'\n\n    data = namedtuple('object', ['filename', 'info'])\n    grouped = df.groupby(field)\n\n    grouped_data = []\n    for filename, x in zip(grouped.groups.keys(), grouped.groups):\n        grouped_data.append(data(filename, grouped.get_group(x)))\n\n    return grouped_data\n","88322526":"# Creating a tf record sample\ndef create_tf_example(group, img_path, label_map_dict):\n    # Read the imagefile. This will be used in features later \n    with tf.io.gfile.GFile(os.path.join(img_path, '{}'.format(group.filename)), 'rb') as f:\n        img_file = f.read()\n\n        # Encode to bytes and read using PIL. Could be done directly too\n        encoded_img = io.BytesIO(img_file)\n        # Read the image using PIL\n        img = Image.open(encoded_img)\n        width, height = img.size\n\n      # Encode the name of the img file\n        filename = group.filename.encode('utf8')\n\n      # Define the format of the image file\n        img_format = b'jpg'   # The name will be in bytes\n\n\n      # Define the variables that you need as features\n        xmins = []\n        xmaxs = []\n        ymins = []\n        ymaxs = []\n        classes_text = []\n        classes = []\n\n      # Iterate over the namedtuple object\n        for index, row in group.info.iterrows():\n            xmins.append(row['xmin'] \/ width)   # store normalized values for bbox\n            xmaxs.append(row['xmax'] \/ width)\n            ymins.append(row['ymin'] \/ height)\n            ymaxs.append(row['ymax'] \/ height)\n            classes_text.append(row['class'].encode('utf8'))\n            classes.append(label_map_dict[row['class']])\n\n        tf_example = tf.train.Example(features=tf.train.Features(feature={\n          'image\/height': dataset_util.int64_feature(height),\n          'image\/width': dataset_util.int64_feature(width),\n          'image\/filename': dataset_util.bytes_feature(filename),\n          'image\/source_id': dataset_util.bytes_feature(filename),\n          'image\/encoded': dataset_util.bytes_feature(img_file),\n          'image\/format': dataset_util.bytes_feature(img_format),\n          'image\/object\/bbox\/xmin': dataset_util.float_list_feature(xmins),\n          'image\/object\/bbox\/xmax': dataset_util.float_list_feature(xmaxs),\n          'image\/object\/bbox\/ymin': dataset_util.float_list_feature(ymins),\n          'image\/object\/bbox\/ymax': dataset_util.float_list_feature(ymaxs),\n          'image\/object\/class\/text': dataset_util.bytes_list_feature(classes_text),\n          'image\/object\/class\/label': dataset_util.int64_list_feature(classes),}))\n\n        return tf_example","5187308e":"# Path where all the images are present\nimg_path = DATA_DIR + 'train_v2'\n# Label map\nlabel_map_dict = label_map_util.get_label_map_dict(ROOT_DIR + '\/labelmap.pbtxt')\n\nwriter = tf.compat.v1.python_io.TFRecordWriter('.\/train.record')\n\n# create groups in the df. One image may contain several instances of an object hence the grouping thing\nimg_groups = make_groups(train_set, field='filename')\n# Iterate over the samples in each group create a TFRecord\nfor group in img_groups:\n    tf_example = create_tf_example(group, img_path, label_map_dict)\n    writer.write(tf_example.SerializeToString())\n# close the writer\nwriter.close()\nprint(\"TFRecords for training data  created successfully\")\n\n\nwriter = tf.compat.v1.python_io.TFRecordWriter('.\/valid.record')\n# create groups \nimg_groups = make_groups(valid_set, field='filename')\n# Iterate over the samples in each group create a TFRecord\nfor group in img_groups:\n    tf_example = create_tf_example(group, img_path, label_map_dict)\n    writer.write(tf_example.SerializeToString())\n# close the writer\nwriter.close()\nprint(\"TFRecords for validation data created successfully\")","8f03b498":"#!cp \/kaggle\/working\/models\/research\/object_detection\/samples\/configs\/ssd_inception_v2_coco.config \/kaggle\/working\n\n#!cp \/kaggle\/working\/models\/research\/object_detection\/samples\/configs\/faster_rcnn_inception_v2_coco.config \/kaggle\/working\n!cp \/kaggle\/working\/models\/research\/object_detection\/samples\/configs\/faster_rcnn_inception_resnet_v2_atrous_coco.config \/kaggle\/working","e9c56162":"#!wget download.tensorflow.org\/models\/object_detection\/ssd_inception_v2_coco_2017_11_17.tar.gz\n#!wget download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\n#!wget download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n!wget http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz","3787b0b5":"#!tar -xzf ssd_inception_v2_coco_2017_11_17.tar.gz\n#!tar -xzf faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\n!tar -xzf faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n","66356a62":"#!mv ssd_inception_v2_coco_2017_11_17 mymodel\n#!mv faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8 mymodel\n!mv faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8 mymodel","aa255eae":"!pip install Cython\n!git clone https:\/\/github.com\/pdollar\/coco.git\nos.chdir('coco\/PythonAPI')\n!make\n!make install\n!python setup.py install\nos.chdir(ROOT_DIR)","f07127da":"os.chdir(ROOT_DIR)\nos.getcwd()","d7ea6dd0":"# Configures the .config automatically\n#fin = open(\"ssd_inception_v2_coco.config\", \"rt\")\n#fin = open(\"faster_rcnn_inception_v2_coco.config\", \"rt\")\nfin = open(\"faster_rcnn_inception_resnet_v2_atrous_coco.config\", \"rt\")\n\nfout = open(\"configfile.config\", \"wt\")\n\n\nfor line in fin:\n    if 'num_classes:' in line:\n        fout.write('\\t\\tnum_classes: 1\\n')\n    else:\n        line = line.replace('PATH_TO_BE_CONFIGURED\/model.ckpt', '\/kaggle\/working\/mymodel\/model.ckpt')\n        line = line.replace('PATH_TO_BE_CONFIGURED\/mscoco_train.record-?????-of-00100', '\/kaggle\/working\/train.record')\n        line = line.replace('PATH_TO_BE_CONFIGURED\/mscoco_label_map.pbtxt', '\/kaggle\/working\/labelmap.pbtxt')\n        line = line.replace('PATH_TO_BE_CONFIGURED\/mscoco_val.record-?????-of-00010','\/kaggle\/working\/valid.record')\n        line = line.replace('num_steps: 200000','num_steps: 5000')\n        fout.write(line)\n\nfin.close()\nfout.close()","1760da06":"!mkdir checkpoints\n!cp \/kaggle\/working\/models\/research\/object_detection\/legacy\/train.py \/kaggle\/working\n!cp \/kaggle\/working\/models\/research\/object_detection\/legacy\/eval.py \/kaggle\/working\n!cp \/kaggle\/working\/models\/research\/object_detection\/export_inference_graph.py \/kaggle\/working\n!cp \/kaggle\/working\/models\/research\/object_detection\/model_main.py \/kaggle\/working","16667fbc":"tf.__version__","d3448735":"os.chdir(ROOT_DIR)","fa258c45":"os.mkdir(\"Output_point\")","3a5a305c":"#run the training\n# import tensorflow.compat.v2 as tf\n# !python train.py --logtostderr --train_dir=\/kaggle\/working\/checkpoints\/ --pipeline_config_path=\/kaggle\/working\/configfile.config\n!python model_main.py  --logtostderr --model_dir=\/kaggle\/working\/Output_point\/ --pipeline_config_path=\/kaggle\/working\/configfile.config","193a7fe5":"!pip list | grep tensorflow","8efc2e21":"!mkdir \/kaggle\/working\/trained","a8b27933":"# os.listdir(\"\/kaggle\/working\/checkpoints\/\")\nos.listdir(\"\/kaggle\/working\/Output_point\/\")","abb5158e":"!python export_inference_graph.py --input_type image_tensor --pipeline_config_path \/kaggle\/working\/configfile.config --trained_checkpoint_prefix .\/Output_point\/model.ckpt-50 --output_directory \/kaggle\/working\/trained","a2a5acba":"!ls -al \/kaggle\/working\/trained","0cf8cc8e":"# !tar -cvzf \/kaggle\/working\/trained_model.tar \/kaggle\/working\/trained\n# !gzip -y \/kaggle\/working\/trained_model.tar","7d067911":"test_v2_list = os.listdir(DATA_DIR + 'test_v2')","dd6d4aee":"test_df = pd.read_csv(DATA_DIR + \"sample_submission_v2.csv\")","92464fd1":"test_df","69c11fa5":"print(os.getcwd())\n!ls","f8e09911":"# # List of the strings that is used to add correct label for each box.\n# PATH_TO_LABELS = '\/kaggle\/working\/labelmap.pbtxt'\n# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)","d545b6e7":"def clmpc(label_map, max_num_classes,use_display_name=True):\n    categories = []\n    list_of_ids_already_added = []\n    if not label_map:\n        label_id_offset = 1\n        for class_id in range(max_num_classes):\n            categories.append({\n                'id': class_id + label_id_offset,\n                'name': 'category_{}'.format(class_id + label_id_offset)})\n        return categories\n    for item in label_map.item:\n        if not 0 < item.id <= max_num_classes:\n#             logging.info('Ignore item %d since it falls outside of requested ''label range.', item.id)\n            continue\n        if use_display_name and item.HasField('display_name'):\n            name = item.display_name\n        else:\n            name = item.name\n        if item.id not in list_of_ids_already_added:\n            list_of_ids_already_added.append(item.id)\n            categories.append({'id': item.id, 'name': name})\n    return categories","7e5729d2":"# What model to download.\nMODEL_NAME = 'trained'\n\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\nPATH_TO_FROZEN_GRAPH = MODEL_NAME + '\/frozen_inference_graph.pb'\n\n# List of the strings that is used to add correct label for each box.\nPATH_TO_LABELS = '\/kaggle\/working\/labelmap.pbtxt'\n\nNUM_CLASSES = 1","d720ce4c":"detection_graph = tf.Graph()\nwith detection_graph.as_default():\n    od_graph_def = tf.GraphDef()\n    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n        serialized_graph = fid.read()\n        od_graph_def.ParseFromString(serialized_graph)\n        tf.import_graph_def(od_graph_def, name='')","b65b9f1c":"label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = clmpc(label_map,max_num_classes=NUM_CLASSES)\n\ncategory_index = label_map_util.create_category_index(categories)","36a6f866":"print(category_index)","eef2fb5d":"def clmpc(label_map, max_num_classes,use_display_name=True):\n    categories = []\n    list_of_ids_already_added = []\n    if not label_map:\n        label_id_offset = 1\n        for class_id in range(max_num_classes):\n            categories.append({\n                'id': class_id + label_id_offset,\n                'name': 'category_{}'.format(class_id + label_id_offset)})\n        return categories\n    for item in label_map.item:\n        if not 0 < item.id <= max_num_classes:\n#             logging.info('Ignore item %d since it falls outside of requested ''label range.', item.id)\n            continue\n        if use_display_name and item.HasField('display_name'):\n            name = item.display_name\n        else:\n            name = item.name\n        if item.id not in list_of_ids_already_added:\n            list_of_ids_already_added.append(item.id)\n            categories.append({'id': item.id, 'name': name})\n    return categories","9c0b600c":"def load_image_into_numpy_array(image):\n  (im_width, im_height) = image.size\n  return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)","2189fff1":"PATH_TO_TEST_IMAGES_DIR = '..\/input\/airbus-ship-detection\/test_v2\/'\nTEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR,i ) for i in test_df['ImageId'][10:20]]\n\n# Size, in inches, of the output images.\nIMAGE_SIZE = (12, 8)\nprint(TEST_IMAGE_PATHS)","beaf7e8b":"def run_inference_for_single_image(image, graph):\n    with graph.as_default():\n        with tf.Session() as sess:\n            # Get handles to input and output tensors\n            ops = tf.get_default_graph().get_operations()\n            all_tensor_names = {output.name for op in ops for output in op.outputs}\n            tensor_dict = {}\n            for key in ['num_detections', 'detection_boxes', 'detection_scores','detection_classes', 'detection_masks']:\n                tensor_name = key + ':0'\n                if tensor_name in all_tensor_names:\n                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n            if 'detection_masks' in tensor_dict:\n                # The following processing is only for single image\n                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n                detection_masks_reframed = tf.cast(\n                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n                    # Follow the convention by adding back the batch dimension\n                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n\n            # Run inference\n            output_dict = sess.run(tensor_dict,\n                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n\n          # all outputs are float32 numpy arrays, so convert types as appropriate\n            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n        if 'detection_masks' in output_dict:\n            output_dict['detection_masks'] = output_dict['detection_masks'][0]\n    return output_dict","09f52768":"from object_detection.utils import visualization_utils as vis_util\nfor image_path in TEST_IMAGE_PATHS:\n    image = Image.open(image_path)\n    # the array based representation of the image will be used later in order to prepare the\n    # result image with boxes and labels on it.\n    image_np = load_image_into_numpy_array(image)\n    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n    # Actual detection.\n    output_dict = run_inference_for_single_image(image_np, detection_graph)\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n      image_np,\n      output_dict['detection_boxes'],\n      output_dict['detection_classes'],\n      output_dict['detection_scores'],\n      category_index,\n      instance_masks=output_dict.get('detection_masks'),\n      use_normalized_coordinates=True,\n      line_thickness=8)\n    plt.figure(figsize=IMAGE_SIZE)\n    plt.imshow(image_np)","c3ee75e1":"\n# Configure the model config file","ec946095":"# LabelMap","056daf82":"# Train the model","725beb72":"# Tensorflow Object Detection API setup","93d7c0af":"# Training & validation split","b78aed93":"## Generate dataframe for TFRecords","07c8254b":"# **Training data**","b9c06502":"# Decoding the pixels","3f79793a":"# Test Data\n","00b88261":"# Generate annotations","94ed0da5":"## Generate xml files","bb418d09":"# Prediction","b7ccc56f":"## Create TFRecord Files","d4a8bb11":"# Import the model","cf25990f":"# Image Enhancement"}}