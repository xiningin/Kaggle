{"cell_type":{"c1bc5fd6":"code","1bb14435":"code","de571270":"code","618bf49f":"code","eb326254":"code","fc5f2406":"code","229c7829":"code","5c6d48fd":"code","1de38aa6":"code","486d817a":"code","9e595912":"code","a9db9aec":"code","60ce2635":"code","fa09aa19":"code","cf6251ad":"code","7201bf99":"code","afb0bb44":"code","45658522":"code","7dde2378":"code","0720e15d":"code","5b3eae06":"code","b71e8042":"code","ad8367d7":"code","b3043de6":"markdown"},"source":{"c1bc5fd6":"!pip install -q -U git+https:\/\/github.com\/mljar\/mljar-supervised.git@master\n!pip install -q -U matplotlib==3.1.3 ","1bb14435":"from supervised import AutoML","de571270":"import pandas as pd\nimport numpy as np\n\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nimport os\nfrom tqdm.notebook import tqdm\nimport gc\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns; sns.set()\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import accuracy_score,mean_squared_error,auc\nfrom sklearn import metrics","618bf49f":"TARGET_COL = \"diabetes_mellitus\"\ndf = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nprint(test.shape)\ndf['label']='train'\ntest['label']='test'\nframes = [df,test]\njoin_df = pd.concat(frames, keys=['x', 'y'])\nassert len(join_df) == len(df) + len(test)\nlst = join_df.isna().sum()\/len(join_df)\np = pd.DataFrame(lst)\np.reset_index(inplace=True)\np.columns = ['a','b']\nlow_count = p[p['b']>0.8]\ntodelete=low_count['a'].values\njoin_df.drop(todelete,axis=1,inplace=True)\njoin_df.head()","eb326254":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","fc5f2406":"join_df.drop(['Unnamed: 0','encounter_id'],inplace=True,axis=1)\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnewdf = join_df.select_dtypes(include=numerics)\nnumeric_cols = newdf.columns\n\n# Need to do column by column due to memory constraints\ncategorical_cols =  ['elective_surgery','hospital_id','icu_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type','aids','cirrhosis','hepatic_failure','immunosuppression',\n 'leukemia','lymphoma','solid_tumor_with_metastasis','elective_surgery','apache_post_operative','arf_apache','fio2_apache','gcs_unable_apache','gcs_eyes_apache',\n 'gcs_motor_apache','gcs_verbal_apache','intubated_apache','ventilated_apache','solid_tumor_with_metastasis']\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = join_df[v].fillna(join_df[v].value_counts().index[0])\nfor i, v in tqdm(enumerate([numeric_cols])):\n    join_df[v] =join_df.groupby(['ethnicity','gender'], sort=False)[v].apply(lambda x: x.fillna(x.mean()))\njoin_df[categorical_cols].isna().sum()","229c7829":"from sklearn.preprocessing import OrdinalEncoder\n\n# In loop to minimize memory use\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = OrdinalEncoder(dtype=\"int\").fit_transform(join_df[[v]])\n    \n\ngc.collect()\n\ntrain = join_df[join_df['label']==\"train\"]\npredict = join_df[join_df['label']=='test']\n\ntrain.reset_index(inplace=True)\ntrain.drop(['level_0','level_1','label'],inplace=True,axis =1 )\n\npredict.reset_index(inplace=True)\npredict.drop(['level_0','level_1','diabetes_mellitus','label'],inplace=True,axis=1)\nfeatures = train.columns\nnum_feature = [col for col in features if col not in categorical_cols]\n","5c6d48fd":"num_feature = [col for col in features if col not in categorical_cols and train[col].dtype != 'object']\ndrop_columns=[]\ncorr = train[num_feature].corr()\n# Drop highly correlated features \ncolumns = np.full((corr.shape[0],), True, dtype=bool)\n\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >=0.999 :\n            if columns[j]:\n                columns[j] = False\n                print('FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(train[num_feature].columns[i] , train[num_feature].columns[j], corr.iloc[i,j]))\n        elif corr.iloc[i,j] <= -0.995:\n            if columns[j]:\n                columns[j] = False","1de38aa6":"drop_columns = train[num_feature].columns[columns == False].values\nprint('drop_columns',len(drop_columns),drop_columns)","486d817a":"train.drop(drop_columns,inplace=True,axis =1 )\npredict.drop(drop_columns,inplace=True,axis =1 )\ntrain[TARGET_COL].value_counts()\/len(train)","9e595912":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\ndf_majority = train[train['diabetes_mellitus']==0]\ndf_minority = train[train['diabetes_mellitus']==1]\n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=83798,    # to match majority class\n                                 random_state= 303) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.diabetes_mellitus.value_counts()\ntrain = df_upsampled","a9db9aec":"X_train, X_test, y_train, y_test = train_test_split(\n     train[[c for c in train if TARGET_COL != c]], train[TARGET_COL], test_size=0.20, random_state=42)\nprint(X_train.shape,X_test.shape)","60ce2635":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","fa09aa19":"X_train.head()","cf6251ad":"X=train[[c for c in train if TARGET_COL != c]]\ny=train[TARGET_COL]\nautoml = AutoML(mode=\"Perform\",total_time_limit=4*3600)\nautoml.fit(X_train, y_train)","7201bf99":"predict","afb0bb44":"Final=automl.predict_all(predict)\n","45658522":"Final","7dde2378":"Final['prediction_0']","0720e15d":"test[TARGET_COL] = Final['prediction_1']\ntest[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission.csv\",index=False)","5b3eae06":"predictions = automl.predict_all(X_valid)\n","b71e8042":"print(\"Test MSE:\", mean_squared_error(y_valid, predictions['prediction_1'],squared=False))","ad8367d7":"automl.report()","b3043de6":"# Fast AutoMlJar"}}