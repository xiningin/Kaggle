{"cell_type":{"e299741f":"code","d7d9ebda":"code","94a02a3d":"code","217d9036":"code","04776a12":"code","2d1472f6":"code","54861001":"code","b0423530":"code","f57be974":"code","49cb3310":"code","76754341":"code","d0690c6d":"code","ae1947eb":"code","33100d4e":"code","a7d7b789":"code","7362f53d":"code","ef6c9837":"code","d035854b":"code","0be83060":"code","1462b8c6":"code","a08d2137":"code","d2a4779c":"code","8b3378d5":"code","3a59fb79":"code","35f22457":"code","530729a4":"code","323d6f92":"code","3ceda313":"markdown"},"source":{"e299741f":"from fastai.vision.all import *","d7d9ebda":"set_seed(2021)","94a02a3d":"path = Path(\"..\/input\/plant-pathology-2021-fgvc8\")\npath.ls()","217d9036":"train_df = pd.read_csv(path\/\"train.csv\")\ntrain_df.head()","04776a12":"train_df.shape","2d1472f6":"train_df[\"labels\"].value_counts()","54861001":"item_tfms = [RandomResizedCrop(128, min_scale=0.75, ratio=(1., 1.))]\nbatch_tfms = [*aug_transforms(size=128, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n\ndls = ImageDataLoaders.from_df(\n    df = train_df,\n    folder = \"..\/input\/resized-plant2021\/img_sz_512\",\n    item_tfms = item_tfms,\n    batch_tfms = batch_tfms,\n    splitter = RandomSplitter(valid_pct=0.1),\n    label_delim = \" \",\n    bs=256\n)","b0423530":"# if you are a big fan of DataBlock API, you can use this code below\n\n# db = DataBlock(\n#     blocks=(ImageBlock, MultiCategoryBlock),\n#     get_x=ColReader(\"image\", pref=\"..\/input\/resized-plant2021\/img_sz_640\/\"),\n#     get_y=ColReader(\"labels\", label_delim=\" \"),\n#     splitter=RandomSplitter(valid_pct=0.1),\n#     item_tfms=item_tfms,\n#     batch_tfms=batch_tfms\n# )\n# dls = db.dataloaders(train_df)","f57be974":"dls.show_batch()","49cb3310":"!mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\n# !cp ..\/input\/resnet18\/resnet18.pth \/root\/.cache\/torch\/hub\/checkpoints\/resnet18-5c106cde.pth\n!cp ..\/input\/resnet50\/resnet50.pth \/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth","76754341":"learn = cnn_learner(\n    dls,\n    resnet50,\n    metrics=[accuracy_multi, F1ScoreMulti()]\n).to_fp16()","d0690c6d":"learn.lr_find()","ae1947eb":"learn.fine_tune(\n    7,\n    1e-1,\n    cbs=[\n        SaveModelCallback(),\n        EarlyStoppingCallback(patience=3),\n    ],\n    freeze_epochs=3\n)","33100d4e":"learn.recorder.plot_loss()","a7d7b789":"learn.show_results()","7362f53d":"interp = ClassificationInterpretation.from_learner(learn)","ef6c9837":"interp.plot_top_losses(9)","d035854b":"interp.plot_confusion_matrix()","0be83060":"submission_df = pd.read_csv(path\/\"sample_submission.csv\")\nsubmission_df.head()","1462b8c6":"test_image_path_series = submission_df[\"image\"].apply(lambda x: f\"..\/input\/plant-pathology-2021-fgvc8\/test_images\/{x}\")\ntest_image_path_series.head()","a08d2137":"test_dl = learn.dls.test_dl(test_image_path_series)\npreds, _ = learn.tta(dl=test_dl)","d2a4779c":"preds","8b3378d5":"vocab = learn.dls.vocab\nvocab","3a59fb79":"threshold = 0.5\n\ndef pred_to_labels(pred):\n    labels = []\n    for i, probability in enumerate(pred):\n        if probability > threshold:\n            labels.append(vocab[i])\n            \n    return \" \".join(labels)","35f22457":"labels_list = [pred_to_labels(pred) for pred in preds]\nlabels_list","530729a4":"submission_df[\"labels\"] = labels_list\nsubmission_df.head()","323d6f92":"submission_df.to_csv(\"submission.csv\", index=False)","3ceda313":"I use this [resized dataset](https:\/\/www.kaggle.com\/ankursingh12\/resized-plant2021) to save my time.  \nWithout this, it takes too much time to resizing images...\ud83d\ude05"}}