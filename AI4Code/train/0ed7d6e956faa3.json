{"cell_type":{"827a4ce1":"code","2ab6f530":"code","7ca0c0fb":"code","a9438d76":"code","a83b0084":"code","bd4a9e45":"code","fdf84481":"code","bd3b3c17":"code","af922bf6":"code","89f982bb":"code","c5dff5cb":"code","ff89faf6":"code","62b540aa":"code","acc9bf0f":"code","483c481c":"code","c456cfe1":"code","5c4d42cc":"code","0c94776b":"code","1e91b02d":"code","1e8de35c":"code","15168a4a":"code","300a7b2b":"code","0ee791a1":"code","0f453644":"code","c864af46":"code","bd88041e":"code","9d47b34e":"code","e7229f97":"code","6fb4ec2b":"code","3092a88f":"code","d52e2fca":"code","b2b9b3c1":"code","83c8b5ff":"code","2994e459":"code","54b0fa93":"code","b25e5374":"code","d9c4a549":"code","2d1f490d":"code","82c46a6c":"code","a997d9d4":"code","f6c9a2b5":"code","9956fd78":"code","a6b20bd1":"markdown","6f074780":"markdown","629aa197":"markdown","c0d8783a":"markdown","a8b6d607":"markdown","9949bbc5":"markdown","aef9b467":"markdown","54a7f6fb":"markdown","99c8c4a4":"markdown","970526aa":"markdown","83a5c496":"markdown","1fbb64b2":"markdown","a0cbe330":"markdown","05d14455":"markdown","03d9e4e2":"markdown","d048eef0":"markdown"},"source":{"827a4ce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ab6f530":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.io as pio\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.decomposition import PCA, NMF\nfrom sklearn.feature_selection import SelectKBest, chi2, SelectFromModel, f_classif\nfrom sklearn.preprocessing import LabelEncoder","7ca0c0fb":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.metrics import accuracy_score","a9438d76":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col = 'PassengerId')\ndf.head()","a83b0084":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\", index_col = 'PassengerId')\ntest_data.head()","bd4a9e45":"y = df['Survived']","fdf84481":"df.info()","bd3b3c17":"test_data.info()","af922bf6":"women = df.loc[df.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","89f982bb":"men = df.loc[df.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","c5dff5cb":"plt.hist(df['Age'])","ff89faf6":"def cabin(x):\n    x = x.fillna('Unknown')\n    x = x.str[0]\n    return x","62b540aa":"def data(x):\n    x['Pclass'] = x['Pclass'].astype('category')\n    \n    # Calculating family members\n    x['Fam'] = x['SibSp']+x['Parch']\n    \n    # Filling nans in Age, fare, and Embarked\n    k = x['Age'].median()\n    x['Age'] = x['Age'].fillna(k)\n    x['Fare'] = x['Fare'].fillna(x['Fare'].median())\n    x['Embarked'].fillna('S', inplace = True)\n    \n    # Passengers travelling on the same ticket must be together\n    count = x.groupby(['Ticket'], as_index = True).count()['Pclass'].rename('count')\n    tp = x.set_index('Ticket', append = True).join(count).reset_index('Ticket', drop = True)\n    tp['Travelled_alone'] = np.where(tp['count']>1, 0, 1)\n    x = tp.drop(axis = 1, labels='count')\n    \n    x['Embarked'] = x['Embarked'].astype('category')\n\n    le = LabelEncoder()\n    le.fit(x['Embarked'])\n    x['Embarked'] = le.transform(x['Embarked'])\n    \n    def bin(n):\n        if n<10:\n            return 'child'\n        elif n<18:\n            return 'teen'\n        elif n<40:\n            return 'young'\n        else:\n            return 'old'\n    \n    x['age_bin'] = x['Age'].apply(bin)\n    x['Cabin'] = cabin(x['Cabin'])\n    \n    x['Fam'] = x['Fam'].astype('category')\n    return x","acc9bf0f":"df.head()","483c481c":"df = data(df.copy())\ntest_data = data(test_data.copy())\n\ndf['mask']= 'train'\ntest_data['mask'] = 'test'","c456cfe1":"pd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='Travelled_alone', aggfunc = lambda X: np.mean(X)*100)","5c4d42cc":"per = lambda X: np.mean(X)*100\npd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='Embarked', aggfunc = [per, 'count'])","0c94776b":"pd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='Pclass', aggfunc = [per, 'count'])","1e91b02d":"pd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='Cabin', aggfunc = [per, 'count'])","1e8de35c":"pd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='Fam', aggfunc = [per, 'count'])","15168a4a":"print(pd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='age_bin', aggfunc = 'count'))\npd.pivot_table(data = df, values = 'Survived', index = 'Sex', columns='age_bin', aggfunc = lambda X: np.mean(X)*100)","300a7b2b":"big_df = pd.concat([df, test_data], axis = 0)\nbig_df.shape","0ee791a1":"# features = [\"Pclass\", \"Sex\", , \"Age\", 'Embarked',]\n# features = [\"Pclass\", \"Sex\", 'Travelled_alone', 'Embarked', 'age_bin', 'SibSp', 'Parch', 'Cabin', 'Fare']\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", 'Parch', 'Age', 'Fare']","0f453644":"final_df = pd.get_dummies(big_df[features])\nfinal_df.shape","c864af46":"final_df.head()","bd88041e":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nss = StandardScaler()\nnum = ['Fare', 'Age']\nfinal_df[num] = ss.fit_transform(final_df[num])","9d47b34e":"X = final_df.loc[big_df['mask'] == 'train']\ntest_X = final_df.loc[big_df['mask'] == 'test']","e7229f97":"test_X.head()","6fb4ec2b":"train_X, val_X, train_y, val_y = train_test_split(X,y)","3092a88f":"clf = Pipeline([\n  ('classification', RandomForestClassifier(min_samples_split= 20, n_estimators= 105, criterion= 'gini'))\n])\nclf.fit(train_X, train_y)\npred_y = clf.predict(val_X)\nscore = clf.score(train_X, train_y)\nprint('model score: ', score)\nprint('accuracy score: ', accuracy_score(pred_y, val_y))","d52e2fca":"gbc = GradientBoostingClassifier(max_depth = 4, learning_rate=0.1, min_samples_leaf=2,)\ngbc.fit(train_X, train_y)\npredictions = gbc.predict(val_X)\nscore = gbc.score(train_X, train_y)\nprint('model score: ', score)\nprint('accuracy score: ', accuracy_score(predictions, val_y))","b2b9b3c1":"lr = LogisticRegression(max_iter=1000)\nlr.fit(train_X, train_y)\npredictions = lr.predict(val_X)\nscore = lr.score(train_X, train_y)\nprint('model score: ', score)\nprint('accuracy score: ', accuracy_score(predictions, val_y))","83c8b5ff":"svc = SVC()\nsvc.fit(train_X, train_y)\npred_y = svc.predict(val_X)\nscore = svc.score(train_X, train_y)\nprint('model score: ', score)\nprint('accuracy score: ', accuracy_score(pred_y, val_y))","2994e459":"svc.fit(X, y)","54b0fa93":"gender = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\", index_col='PassengerId')\nprint('Gender columns:', gender.columns.tolist())","b25e5374":"female_X = test_X.loc[test_X['Sex_female'] == 1]\nfemale_X.head()","d9c4a549":"female_survival = pd.merge(female_X, gender, on='PassengerId')\nfemale_survival.head()","2d1f490d":"test_y = female_survival[\"Survived\"]","82c46a6c":"y_pred = svc.predict(female_X)","a997d9d4":"from sklearn.metrics import accuracy_score\naccuracy_score(test_y, y_pred)","f6c9a2b5":"predictions = svc.predict(test_X)","9956fd78":"output = pd.DataFrame({'PassengerId': test_data.index, 'Survived': predictions})\noutput.to_csv('rf.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a6b20bd1":"*It is evident from the above values that Sex is an important aspect in predicting the survival of passengers. Females are more likely to survive than males*","6f074780":"\n# Exploratory Data Analysis","629aa197":"## Saving the results","c0d8783a":"# Import Gender data\n### now we can check the accuracy of the female data predictions against actual survival rate","a8b6d607":"# Parameters of pipelines can be set using \u2018__\u2019 separated parameter names:\nparam_grid = {\n    'loss': ['exponential', 'deviance'],\n    'max_depth' : [3, 4, 5, 6, 7], \n    'learning_rate': [0.1, 0.09, 0.95, 0.099, 0.097, 1.05] ,\n    'min_samples_leaf': [2,3,4,5,6,7],\n    'n_estimators': [100, 105,110,115,120,125],\n    'max_features' : ['auto', 'sqrt', 'log2'],\n\n}\nsearch = GridSearchCV(GradientBoostingClassifier(), param_grid, n_jobs=-1)\nsearch.fit(train_X, train_y)\nprint(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_params_)","9949bbc5":"# Titanic- Machine Learning from Disaster\n\n#### Predicting survival of passengers in the Titanic shipwreck using Machine Learning algorithms.\n\n\n\n> The sinking of the Titanic is one of the most infamous shipwrecks in history.\n> On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n>\n\n\n*While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. Our job here is to find the likelihood of survival of some people than others*","aef9b467":"### Saving the Target Variable","54a7f6fb":"# Read Data","99c8c4a4":"## Splitting again the final_df to test and train dataset","970526aa":"## Predicting test_data values","83a5c496":"# Scaling numeric features","1fbb64b2":"# Feature Transformation","a0cbe330":"# Import Libraries","05d14455":"### We find that SVC gives the best accuracy\nLet's train the model on full data","03d9e4e2":"# Merging Test and Train data\n### To get dummies later so that any values absent in train and pressent in test_data do not cause problem later","d048eef0":"<img src = \"https:\/\/akm-img-a-in.tosshub.com\/indiatoday\/titanic_647_041416113640.jpg?IWI8WJ3owRLPfIO2GUMAyyypPfwvvcRV&size=770:433\" width=\"1200\" height=\"200\" \/>"}}