{"cell_type":{"142a86a8":"code","ad52a595":"code","f6b8557f":"code","6cfcad40":"code","dd4f802f":"code","9bf88bbc":"code","a2b8de48":"code","3d5e74b4":"code","b2c9ab93":"code","cc44b1d2":"code","2b790ca0":"code","36cb200b":"code","9e5345da":"code","a933a798":"code","fb94604c":"code","04c7c322":"code","4479b21f":"code","8d8357b6":"code","c7c506a4":"code","9c3e4953":"code","f04d2c40":"code","1bf07c38":"code","0e8bc3cf":"code","32b79946":"code","ef6dc102":"code","5ac70765":"code","18ee03d0":"code","5555d4b8":"code","0e5b1a8f":"code","e012f298":"code","7d64f189":"code","9c57efaa":"code","3a05e3b1":"code","14cbded0":"code","22fb8b8d":"code","f7dacc17":"code","54368baa":"code","b2ec503f":"code","333346ea":"code","64f8bcde":"code","993c017e":"code","5e5f0a81":"code","123d2599":"code","48ffb8e1":"code","97098a13":"code","6e88d204":"code","9df647b5":"code","fb9355c2":"code","3d251bc5":"code","039f5ab5":"code","f942ba91":"markdown","6e7895e3":"markdown","971c74b7":"markdown","c4d7fd50":"markdown","ca47d51e":"markdown","2b7341fc":"markdown","74df5e7d":"markdown","cb0695c4":"markdown","8632767e":"markdown","edaf1c80":"markdown","055ee391":"markdown","8686d50e":"markdown","5ab131b7":"markdown","2028f700":"markdown","6cb166e2":"markdown","79b87bdb":"markdown","e94c9a6c":"markdown","b99f9fc2":"markdown","4a305e90":"markdown","80faec83":"markdown","34b9a52d":"markdown","a88f8e0b":"markdown","8e56001c":"markdown","007fd589":"markdown","2f01955a":"markdown","cb40223b":"markdown","cb284c13":"markdown","93c5e9a3":"markdown","e9efc9a1":"markdown","9b13d09c":"markdown","3a64dd71":"markdown","b7512b42":"markdown","95290bf7":"markdown","143d98e3":"markdown","97060133":"markdown","0b21bbe6":"markdown","c71171c8":"markdown","0ceab0c1":"markdown","f5611e31":"markdown","7fe5b067":"markdown"},"source":{"142a86a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad52a595":"test_submission = pd.read_csv('\/kaggle\/input\/customer-churn-prediction-2020\/sampleSubmission.csv')\ntest_submission.head()","f6b8557f":"# Libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport category_encoders as ce\nfrom sklearn.preprocessing import OneHotEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom xgboost import XGBClassifier","6cfcad40":"# load the dataset\ntrain = pd.read_csv('\/kaggle\/input\/customer-churn-prediction-2020\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/customer-churn-prediction-2020\/test.csv')\nprint('Train shape {}'.format(train.shape))\nprint('Test shape {}'.format(test.shape))","dd4f802f":"# display the all columns \npd.set_option('display.max_columns',None)","9bf88bbc":"# Display the head of the data\ntrain.head()","a2b8de48":"# Checking the missing values \ntrain.info()","3d5e74b4":"# describe the five points of statistics of numericals data\ntrain.describe()","b2c9ab93":"# Describe the string data\ntrain.describe(include='O')","cc44b1d2":"# function for display the percentage\ndef with_per(total, axis):\n    for p in axis.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='center')","2b790ca0":"# extract the categorical variables\ncat_var = [ feature for feature in train.columns if train[feature].dtypes=='O']\nprint('List of categorical variables {}'.format(cat_var))","36cb200b":"#display the all the categorical variable \nfor feature in cat_var:\n    sns.set(style = 'whitegrid')\n    plt.figure(figsize=(20,5))\n    total = len(train)\n    ax = sns.countplot(x = train[feature], data = train)\n    #plt.title(feature)\n    with_per(total, ax)\n    plt.show()","9e5345da":"#Extract the numerical features from the dataset\nnum_var = [feature for feature in train.columns if train[feature].dtypes != 'O']\nprint('List of Numerical featues {}'.format(num_var))","a933a798":"# Density plot of all the numerical features\nfor feature in num_var:\n    sns.distplot(train[feature])\n    plt.xlabel(feature)\n    plt.ylabel('Density')\n    plt.show()","fb94604c":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'account_length').add_legend()\nplt.title('Churn rate VS account_length')","04c7c322":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'number_vmail_messages').add_legend()\nplt.title('Churn rate VS number_vmail_messages')\nplt.show()","4479b21f":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_day_minutes').add_legend()\nplt.title('Churn rate VS total day minutes')\nplt.show()","8d8357b6":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_day_calls').add_legend()\nplt.title('Churn rate VS total day calls')\nplt.show()","c7c506a4":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_day_charge').add_legend()\nplt.title('Churn rate VS total day charge')\nplt.show()","9c3e4953":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_eve_minutes').add_legend()\nplt.title('Churn rate VS total evening minutes')\nplt.show()","f04d2c40":"sns.FacetGrid(train, hue='churn',size=5).map(sns.distplot, 'total_eve_calls').add_legend()\nplt.title('Churn rate VS total evening calls')\nplt.show()","1bf07c38":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_eve_charge').add_legend()\nplt.title('Churn rate VS total evening charges')\nplt.show()","0e8bc3cf":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_night_minutes').add_legend()\nplt.title('Churn rate VS total night minutes')\nplt.show()","32b79946":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_night_calls').add_legend()\nplt.title('Churn rate VS total night calls')\nplt.show()","ef6dc102":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_night_charge').add_legend()\nplt.title('Churn rate VS total night charge')\nplt.show()","5ac70765":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_intl_minutes').add_legend()\nplt.title('Churn rate VS total international minutes')\nplt.show()","18ee03d0":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_intl_calls').add_legend()\nplt.title('Churn rate VS total international calls')\nplt.show()","5555d4b8":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'total_intl_charge').add_legend()\nplt.title('Churn rate VS total international charge')\nplt.show()","0e5b1a8f":"sns.FacetGrid(train, hue='churn',size=7).map(sns.distplot, 'number_customer_service_calls').add_legend()\nplt.title('Churn rate VS Number of customer service calls')\nplt.show()","e012f298":"for feature in num_var:\n    if feature != 'churn':\n        sns.boxplot(x ='churn', y = feature, data = train)\n        plt.title(feature)\n        plt.show()","7d64f189":"#functions for removing outliers\ndef remove_outliers(train,labels):\n    for label in labels:\n        q1 = train[label].quantile(0.25)\n        q3 = train[label].quantile(0.75)\n        iqr = q3 - q1\n        upper_bound = q3 + 1.5 * iqr\n        lower_bound = q1 - 1.5 * iqr\n        train[label] = train[label].mask(train[label]< lower_bound, train[label].median(),axis=0)\n        train[label] = train[label].mask(train[label]> upper_bound, train[label].median(),axis=0)\n\n    return train","9c57efaa":"train = remove_outliers(train, num_var)","3a05e3b1":"for feature in num_var:\n    if feature != 'churn':\n        sns.boxplot(x ='churn', y = feature, data = train)\n        plt.title(feature)\n        plt.show()","14cbded0":"hash_state = ce.HashingEncoder(cols = 'state')\ntrain = hash_state.fit_transform(train)\ntest = hash_state.transform(test)\ntrain.head()","22fb8b8d":"test.head()","f7dacc17":"# replace no to 0 and yes to 1\ntrain.international_plan.replace(['no','yes'],[0,1],inplace = True)\ntrain.voice_mail_plan.replace(['no','yes'],[0,1],inplace=True)\ntrain.churn.replace(['no','yes'],[0,1],inplace = True)\ntest.international_plan.replace(['no','yes'],[0,1],inplace = True)\ntest.voice_mail_plan.replace(['no','yes'],[0,1],inplace = True)\ntrain.head()","54368baa":"# converting the area_code to numerical variable using one-hot encoder\nonehot_area = OneHotEncoder()\nonehot_area.fit(train[['area_code']])\n\n# Train\nencoded_values = onehot_area.transform(train[['area_code']])\ntrain[onehot_area.categories_[0]] = encoded_values.toarray()\ntrain = train.drop('area_code', axis=1)\n\n# Test\nencoded_values = onehot_area.transform(test[['area_code']])\ntest[onehot_area.categories_[0]] = encoded_values.toarray()\ntest = test.drop('area_code', axis=1)","b2ec503f":"train.head()","333346ea":"\ntest.head()","64f8bcde":"# showing the imbalanced class\nsns.countplot(x = 'churn', data = train)\nplt.show()","993c017e":"x = train.drop('churn',axis=1).values\ny = train.churn.values\nid_submission = test.id\ntest = test.drop('id', axis=1)\n# spliting the data into test and train\nx_train, x_test , y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=0)","5e5f0a81":"print('Before upsampling count of label 0 {}'.format(sum(y_train==0)))\nprint('Before upsampling count of label 1 {}'.format(sum(y_train==1)))\n# Minority Over Sampling Technique\nsm = SMOTE(sampling_strategy = 1, random_state=1)   \nx_train_s, y_train_s = sm.fit_resample(x_train, y_train.ravel())\n                                         \nprint('After upsampling count of label 0 {}'.format(sum(y_train_s==0)))\nprint('After upsampling count of label 1 {}'.format(sum(y_train_s==1)))","123d2599":"# creating the object of minmax scaler\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\ntest = scaler.transform(test)","48ffb8e1":"svc = SVC(kernel='rbf', decision_function_shape='ovr')\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\nprint('Accuracy: ')\nprint('{}'.format(accuracy_score(y_test, y_pred)))\nprint('Classification report: ')\nprint('{}'.format(classification_report(y_test, y_pred)))\nprint('Confusion Matrix')\nprint('{}'.format(confusion_matrix(y_test, y_pred)))\nprint('Cohen kappa score: ')\nprint('{}'.format(cohen_kappa_score(y_test, y_pred)))","97098a13":"rfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)\ny_pred = rfc.predict(x_test)\nprint('Accuracy: ')\nprint('{}'.format(accuracy_score(y_test, y_pred)))\nprint('Classification report: ')\nprint('{}'.format(classification_report(y_test, y_pred)))\nprint('Confusion Matrix')\nprint('{}'.format(confusion_matrix(y_test, y_pred)))\nprint('Cohen kappa score: ')\nprint('{}'.format(cohen_kappa_score(y_test, y_pred)))","6e88d204":"clf = XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.7, \n                        subsample=0.8, nthread=10, learning_rate=0.01)\nclf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\nprint('Accuracy: ')\nprint('{}'.format(accuracy_score(y_test, y_pred)))\nprint('Classification report: ')\nprint('{}'.format(classification_report(y_test, y_pred)))\nprint('Confusion Matrix')\nprint('{}'.format(confusion_matrix(y_test, y_pred)))\nprint('Cohen kappa score: ')\nprint('{}'.format(cohen_kappa_score(y_test, y_pred)))","9df647b5":"y_pred_sub = clf.predict(test)","fb9355c2":"submit = pd.DataFrame({'id':id_submission, 'churn':y_pred_sub})\nsubmit.head()","3d251bc5":"# replace 0 to no and 1 to yes\nsubmit.churn.replace([0,1],['no','yes'], inplace=True)","039f5ab5":"submit.to_csv('churn_submit.csv',index=False)","f942ba91":"### Handling the Imbalanced dataset","6e7895e3":"### Building the model","971c74b7":"### BiVariate Analysis","c4d7fd50":"* 1. Number_customer_service_calls, total_internation_call and Number_voice_mail_messages are not a normal distribuation so we can covert into normal distribution in featuer engineering step.\n* 2. Other than the obove features all look like a normal distribuation.","ca47d51e":"* churn rate is high when total international minutes lies between 9 to 12.","2b7341fc":"#### 1. Countinous Features","74df5e7d":"* customers account length between 60 to 120 has more churn rate","cb0695c4":"* churn rate is high when total day charge is lies between 40 to 50.","8632767e":"### Univariate Analysis","edaf1c80":"### Scalling the dataset","055ee391":"#### Removing the outliers","8686d50e":"* every features has a outliers so we need to remove the outliers.\n* outlies contains the some usefull information.\n* so we have to replace the outliers with some meaning full values. so we should replace the outliers with meadin values","5ab131b7":"### Outlier Detection","2028f700":"* See the above plot\n* 1. 90.7% customers didn't have international plan\n* 2. 73.8%  customers didn't have voice mail plan\n* 3. 49.6% customers are living in the area code area_code_415.\n* 4. only 14.1% customers are churn","6cb166e2":"### XGBClassifier","79b87bdb":"* churn rate is high when total evening calls lies between 90 to 115.","e94c9a6c":"* There are not missing values in any features.","b99f9fc2":"## Data Exploration ","4a305e90":"### Submission","80faec83":"### Handling the Categorical Variable","34b9a52d":"#### Support Vector Classification","a88f8e0b":"* churn rate is high when the total evening charge is lies between 15 to 18","8e56001c":"* after apply the upsampling technique the number of samples of both classes are same","007fd589":"* churn rate is high when number of customer service calls is 1.","2f01955a":"train and test set has same numbers of features but the test set is not contain the target features ( churn ) it contain 'ID' feature which will be required for submission.","cb40223b":"* after removing the outliers we have to see the outliers","cb284c13":"#### Random Forest Classifier","93c5e9a3":"* churn rate is high when the total evening minutes is lies between 180 min to 220 min.","e9efc9a1":"* churn rate is high lies between 85 to 115.","9b13d09c":"* state feature has 51 different category so we can't converted into onehot encoder that is it create 51 different features so it leads to overfitting so I will use the hashing encoding for state featuer.\n*","3a64dd71":"* Churn rate is high when the total_night_minutes is lies between 190 to 220 min","b7512b42":"* churn rate is high when total international charge is 2.5 to 3.","95290bf7":"* Churn rate is high when the total_day_minutes is lies between 210 min to 300 min.","143d98e3":"* churn rate is high when total_nigh_calls lies between 90 to 110.","97060133":"* churn rate is high when total international calls is 1.","0b21bbe6":"* churn rate is high when total_night_charge lies between 7.5 to 10.","c71171c8":"* More churn rate when the number_vamil_messages is 0","0ceab0c1":"#### 1. Categorical Variables","f5611e31":"#### 2. Numerical Variables\n","7fe5b067":"* 0 represent the no churn and 1 represent the churn so there are huge difference in the class. so we need to balanced the dataset\n* We have to use upsampling for handling the dataset"}}