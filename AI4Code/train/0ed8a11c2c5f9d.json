{"cell_type":{"7e8f1cc5":"code","47380a5a":"code","3fca7287":"code","f2b5db40":"code","df0b4966":"code","bf0790c7":"code","726d9fb2":"code","e16ffcc4":"code","651a03ab":"code","db75ab2c":"code","f77900cb":"code","efe042ab":"code","0dcb69a3":"code","d8dc6526":"code","231dbf6e":"code","85f405e8":"code","a8bb020f":"code","cd0cc643":"code","b2c33671":"code","6a36335e":"code","8446924f":"code","1a109577":"code","f33c90ae":"code","89f29e3e":"code","ff584dc5":"code","da52e0d5":"code","7de8aded":"code","38ac99d1":"code","3022d32d":"code","97f67667":"code","b89e58a7":"code","aad99931":"code","b8972743":"code","f51b913e":"code","05b3517d":"code","420357f9":"code","f6509b36":"code","869f4877":"code","e6dc9564":"code","763c1798":"code","bb4cea9d":"code","2f5f75b0":"code","c268893d":"code","055c021a":"markdown"},"source":{"7e8f1cc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47380a5a":"from numpy.random import seed\nseed(22)\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport math\nimport gc\nfrom scipy.stats.stats import kendalltau\nfrom pylab import rcParams\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, RobustScaler, PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn import linear_model\nfrom sklearn.pipeline import Pipeline\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import plot_importance as lgb_importance\n\nimport datetime\nfrom datetime import datetime","3fca7287":"train_data = pd.read_csv('\/kaggle\/input\/predict-number-of-upvotes\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/predict-number-of-upvotes\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/predict-number-of-upvotes\/sample_submission.csv')\ntrain_data.columns = train_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\nfor col in train_data.columns[~train_data.columns.isin(['tag'])]:\n    train_data[col] = train_data[col].apply(lambda x: int(x))\nfor col in test_data.columns[~test_data.columns.isin(['tag'])]:\n    test_data[col] = test_data[col].apply(lambda x: int(x))","f2b5db40":"test_data.loc[(test_data['id'] == 121644)]","df0b4966":"train_data.head(10)","bf0790c7":"print('Train Data shape: ', train_data.shape)\ntrain_data.describe()","726d9fb2":"train_data.isnull().sum()","e16ffcc4":"train_data.nunique()","651a03ab":"train_data.dtypes","db75ab2c":"test_data.head()","f77900cb":"plt.figure(figsize = (10, 5))\nsns.barplot(train_data['tag'], train_data['upvotes'])\nplt.title('Upvotes by question category')\nplt.show()","efe042ab":"plt.figure(figsize = (10, 5))\nsns.barplot(train_data['tag'], train_data['views'])\nplt.title('Views by question category')\nplt.show()","0dcb69a3":"plt.figure(figsize = (10, 5))\nsns.lineplot(train_data['answers'], train_data['upvotes'])\nsns.despine()","d8dc6526":"plt.figure(figsize = (16, 10))\nsns.scatterplot(x = 'upvotes', y = 'views', data = train_data)\nsns.despine()","231dbf6e":"plt.figure(figsize = (16, 5))\nsns.scatterplot(x = 'upvotes', y = 'answers', data = train_data)\nsns.despine()","85f405e8":"plt.figure(figsize = (16, 5))\nsns.scatterplot(x = 'views', y = 'answers', data = train_data)\nsns.despine()","a8bb020f":"#4118\ntrain_data.loc[(train_data['views'] > 3000000)]\ntrain_data.loc[(train_data['upvotes'] > 400000)]","cd0cc643":"#train_data = train_data.loc[(train_data['upvotes'] < 400000)]\ntrain_data = train_data.loc[(train_data['views'] < 3000000)]","b2c33671":"train_data.head()","6a36335e":"train_data.hist(figsize = (16, 20), bins = 50, xlabelsize = 8, ylabelsize = 8)","8446924f":"user_rep = (train_data['username'].astype(str) + \"_\" + train_data['reputation'].astype(str)).unique()\nprint(len(user_rep))\nusers = (train_data['username'].astype(str)).unique()\nprint(len(users))","1a109577":"max(users)","f33c90ae":"users = train_data.username.unique().tolist() + list(set(train_data.username.unique().tolist()) - set(test_data.username.unique().tolist()))\nusers = pd.DataFrame({'username': users})","89f29e3e":"user_counts = pd.DataFrame(train_data.groupby('username')['id'].count()).reset_index()\nuser_counts.columns = ['username', 'questions_train']\nuser_counts_test = pd.DataFrame(test_data.groupby('username')['id'].count()).reset_index()\nuser_counts_test.columns = ['username', 'questions_test']\nusers = users.merge(user_counts_test, on = 'username', how = 'left')\nusers = users.merge(user_counts, on = 'username', how = 'left')\nusers['diff'] = abs(users['questions_test'] - users['questions_train'])\nusers.sort_values(by = ['diff'], ascending = False)","ff584dc5":"users.loc[(users['questions_test'] <= 100000) & (users['questions_train'].isnull())]","da52e0d5":"users.loc[(users['questions_train'] <= 20) & (users['diff'] >= 20)]","7de8aded":"train_data['rep_ans_vw_avg'] = (train_data['reputation'] + train_data['answers'] + train_data['views'])\/3\ntest_data['rep_ans_vw_avg'] = (test_data['reputation'] + test_data['answers'] + test_data['views'])\/3\ntrain_data['rep_ans_vw_avg'] = train_data['rep_ans_vw_avg'].apply(lambda x: int(x))\ntest_data['rep_ans_vw_avg'] = test_data['rep_ans_vw_avg'].apply(lambda x: int(x))\n\nprint('Train Data shape: ', train_data.shape)\nprint('Test Data shape: ', test_data.shape)\n\ntrain_data.head(30)","38ac99d1":"train_data.loc[(train_data['upvotes'] >= 5000)]","3022d32d":"fig, ax = plt.subplots(figsize=(8, 8))  # Sample figsize in inches\nsns.heatmap(train_data[train_data.columns[~train_data.columns.isin(['id', 'username'])]].corr(), annot = True, square = True, vmin = -1, vmax = 1)","97f67667":"kendallcorr = train_data.corr(method = 'kendall')\nfig, ax = plt.subplots(figsize = (8, 8))  # Sample figsize in inches\nsns.heatmap(kendallcorr, xticklabels = kendallcorr.columns.values, yticklabels = kendallcorr.columns.values, cmap = \"YlGnBu\", annot = True)","b89e58a7":"le = LabelEncoder()\ntrain_data['tag'], test_data['tag'] = le.fit_transform(train_data['tag']), le.fit_transform(test_data['tag'])\n\nX = train_data[train_data.columns[~train_data.columns.isin(['upvotes','username', 'id'])]]\ny = train_data['upvotes']\n#X['tag'] = X['tag'].astype('category')\n#test_data['tag'] = test_data['tag'].astype('category')\n#scale_features = X.columns[~X.columns.isin(['tag'])]","aad99931":"scale_features = X.columns[~X.columns.isin(['tag'])]\nss = StandardScaler()\nX = ss.fit_transform(X)\ntestIDs = test_data['id']\ntest_data = test_data[test_data.columns[~test_data.columns.isin(['username', 'id'])]]\ntest_data = ss.fit_transform(test_data)\nprint(X.shape, test_data.shape)","b8972743":"\"\"\"rs = RobustScaler().fit(X)\nX = rs.transform(X)\ntestIDs = test_data['id']\ntest_data = test_data[test_data.columns[~test_data.columns.isin(['username', 'id'])]]\nrs = RobustScaler().fit(test_data)\ntest_data = rs.transform(test_data)\nprint(X.shape, test_data.shape)\n\n#y = np.log1p(y)\n\"\"\"","f51b913e":"pd.set_option('display.max_columns', None)\ntrain_data[train_data.columns[~train_data.columns.isin(['upvotes','username', 'id'])]]","05b3517d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 22)","420357f9":"poly_reg = PolynomialFeatures(degree = 4, interaction_only = False, include_bias = True)  #using polynomial funtion of degree 4, as there are 4 features in given datasets.\nX_poly = poly_reg.fit_transform(X_train)\npoly_reg.fit(X_train, y_train)\ntestData = poly_reg.fit_transform(test_data)","f6509b36":"lin_reg = linear_model.LassoLars(alpha = 0.021, max_iter = 200)\nlin_reg.fit(X_poly, y_train)\ny_pred = lin_reg.predict(poly_reg.fit_transform(X_test))\n\nprint('Linear Model RMSE score is', math.sqrt(mean_squared_error(y_test, y_pred)))\npredictions_lin = lin_reg.predict(testData)","869f4877":"lgb = LGBMRegressor(n_estimators = 200, random_state = 22, learning_rate = 0.01)\nlgb.fit(X_poly, y_train)\ny_pred = lgb.predict(poly_reg.fit_transform(X_test))\n\n#y_pred = np.expm1(y_pred)\n#y_test = np.expm1(y_test)\n\nprint('LGB RMSE score is', math.sqrt(mean_squared_error(y_test, y_pred)))\npredictions = lgb.predict(testData)\n#predictions = lgb.predict(poly_reg.fit_transform(test_data))\n\n#predictions = np.expm1(predictions)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nlgb_importance(lgb, ax = ax, height = 0.5)\nplt.show()","e6dc9564":"xgb = XGBRegressor(n_estimators = 100, random_state = 22)\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\n\n#y_pred = np.expm1(y_pred)\n#y_test = np.expm1(y_test)\n\nprint('XGB RMSE score is', math.sqrt(mean_squared_error(y_test, y_pred)))\n\npredictions_xgb = xgb.predict(test_data)\n\n#predictions_xgb = np.expm1(predictions_xgb)","763c1798":"fig, ax = plt.subplots(figsize = (10, 10))\nplot_importance(xgb, ax = ax, height = 0.5)\nplt.show()","bb4cea9d":"gbr = GradientBoostingRegressor(n_estimators = 200, random_state = 22)\ngbr.fit(X_train, y_train)\ny_pred = gbr.predict(X_test)\n\n#y_pred = np.expm1(y_pred)\n#y_test = np.expm1(y_test)\n\nprint('GBR RMSE score is', math.sqrt(mean_squared_error(y_test, y_pred)))\n\npredictions_gbr = gbr.predict(test_data)\n\n#predictions_gbr = np.expm1(predictions_gbr)","2f5f75b0":"submission.head()","c268893d":"sub_df1 = pd.DataFrame({'ID': testIDs, 'Upvotes': np.round(predictions)})\nsub_df2 = pd.DataFrame({'ID': testIDs, 'Upvotes': np.round(predictions_xgb)})\nsub_df3 = pd.DataFrame({'ID': testIDs, 'Upvotes': np.round(predictions_gbr)})\nsub_df4 = pd.DataFrame({'ID': testIDs, 'Upvotes': np.round(predictions_lin)})\nsub_df1.to_csv('upvotes_lgb_v4.csv', index = False)\nsub_df2.to_csv('upvotes_xgb_v4.csv', index = False)\nsub_df3.to_csv('upvotes_gbr_v5.csv', index = False)\nsub_df4.to_csv('upvotes_poly_v1.csv', index = False)","055c021a":"There seems to be outliers in the data, with upvotes as large as 100000"}}