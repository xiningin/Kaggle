{"cell_type":{"115b7311":"code","07680a99":"code","0437320c":"code","236c279e":"code","af045fab":"code","4fec329a":"code","025a92d4":"code","48b22f9b":"code","4443827f":"code","7a251186":"markdown","07962484":"markdown"},"source":{"115b7311":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","07680a99":"import IPython.display as ipd\nimport wave","0437320c":"train_curated_files = os.listdir('..\/input\/freesound-audio-tagging-2019\/train_curated')","236c279e":"ipd.Audio('..\/input\/freesound-audio-tagging-2019\/train_curated\/' + train_curated_files[0])","af045fab":"train_noisy = pd.read_csv(\n    '..\/input\/freesound-audio-tagging-2019\/train_noisy.csv', index_col='fname')\ntrain_curated = pd.read_csv(\n    '..\/input\/freesound-audio-tagging-2019\/train_curated.csv', index_col='fname')\nsubmission = pd.read_csv(\n    '..\/input\/freesound-audio-tagging-2019\/sample_submission.csv', index_col='fname')\n\nlabels = submission.columns.tolist()","4fec329a":"for label in labels:\n    train_noisy[label] = 0\n    train_curated[label] = 0 ","025a92d4":"for row in tqdm_notebook(train_noisy.index):\n    row_labels = train_noisy.loc[row, 'labels'].split(',')\n    for label in row_labels:\n        train_noisy.loc[row, label] = 1\n\nfor row in tqdm_notebook(train_curated.index):\n    row_labels = train_curated.loc[row, 'labels'].split(',')\n    for label in row_labels:\n        train_curated.loc[row, label] = 1\n        \n        \ntrain_noisy['num_labels'] = train_noisy[labels].sum(axis=1)\ntrain_curated['num_labels'] = train_curated[labels].sum(axis=1)","48b22f9b":"label_count = train_noisy[labels].sum(axis=0) + train_curated[labels].sum(axis=0)\nlabel_pred = label_count \/ label_count.sum()\n\nsubmission.loc[:,:] = label_pred.values[:, None].ravel()","4443827f":"submission.to_csv('submission.csv')","7a251186":"### Let's make a naive prediction!","07962484":"### Let's listen to an audio clip!"}}