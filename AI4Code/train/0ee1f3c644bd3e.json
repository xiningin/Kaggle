{"cell_type":{"416426b5":"code","458c15c1":"code","78d9078c":"code","6f4c5a84":"code","8704c145":"code","0260aa49":"code","787158d5":"code","fd4fe17c":"code","42749b5c":"code","171a362c":"code","171ceaea":"code","1efbf82d":"code","0e006eaf":"code","7c9d67c7":"code","209ac454":"code","7027e739":"code","edb9bed4":"code","a4734294":"code","3f389738":"code","460b264d":"code","a681683c":"code","75df9ad6":"code","75851a6d":"code","769b3e09":"markdown","643133c2":"markdown","084721d0":"markdown","0632955c":"markdown","5b389ff7":"markdown","5eb032c4":"markdown","7a66aa21":"markdown","7ed09b64":"markdown","7e0d288d":"markdown","0655f5ca":"markdown","5d8f3616":"markdown","18cc4c08":"markdown","19eb85fd":"markdown","efb786ef":"markdown","81e542f0":"markdown","c7de39c5":"markdown","822d18a7":"markdown","21a27af4":"markdown","9602d97e":"markdown","9a43686d":"markdown","58c68cb6":"markdown","5bf1a2b7":"markdown","e25f78ed":"markdown","95d2a800":"markdown","4ba62949":"markdown","a2dc8ab9":"markdown","68688d7b":"markdown","008de514":"markdown","cb382900":"markdown","a9663f41":"markdown","2bf46ccc":"markdown","f3428a6d":"markdown","8b16ef45":"markdown"},"source":{"416426b5":"# import data processing and visualisation libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import image processing libraries\nimport cv2\nimport skimage\nfrom skimage.transform import resize\n\n# import tensorflow and keras\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\n\nprint(\"Packages imported...\")","458c15c1":"batch_size = 64\nimageSize = 64\ntarget_dims = (imageSize, imageSize, 3)\nnum_classes = 29\n\ntrain_len = 87000\ntrain_dir = '\/kaggle\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/'\n\ndef get_data(folder):\n    X = np.empty((train_len, imageSize, imageSize, 3), dtype=np.float32)\n    y = np.empty((train_len,), dtype=np.int)\n    cnt = 0\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['A']:\n                label = 0\n            elif folderName in ['B']:\n                label = 1\n            elif folderName in ['C']:\n                label = 2\n            elif folderName in ['D']:\n                label = 3\n            elif folderName in ['E']:\n                label = 4\n            elif folderName in ['F']:\n                label = 5\n            elif folderName in ['G']:\n                label = 6\n            elif folderName in ['H']:\n                label = 7\n            elif folderName in ['I']:\n                label = 8\n            elif folderName in ['J']:\n                label = 9\n            elif folderName in ['K']:\n                label = 10\n            elif folderName in ['L']:\n                label = 11\n            elif folderName in ['M']:\n                label = 12\n            elif folderName in ['N']:\n                label = 13\n            elif folderName in ['O']:\n                label = 14\n            elif folderName in ['P']:\n                label = 15\n            elif folderName in ['Q']:\n                label = 16\n            elif folderName in ['R']:\n                label = 17\n            elif folderName in ['S']:\n                label = 18\n            elif folderName in ['T']:\n                label = 19\n            elif folderName in ['U']:\n                label = 20\n            elif folderName in ['V']:\n                label = 21\n            elif folderName in ['W']:\n                label = 22\n            elif folderName in ['X']:\n                label = 23\n            elif folderName in ['Y']:\n                label = 24\n            elif folderName in ['Z']:\n                label = 25\n            elif folderName in ['del']:\n                label = 26\n            elif folderName in ['nothing']:\n                label = 27\n            elif folderName in ['space']:\n                label = 28           \n            else:\n                label = 29\n            for image_filename in os.listdir(folder + folderName):\n                img_file = cv2.imread(folder + folderName + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n                    img_arr = np.asarray(img_file).reshape((-1, imageSize, imageSize, 3))\n                    \n                    X[cnt] = img_arr\n                    y[cnt] = label\n                    cnt += 1\n    return X,y\nX_train, y_train = get_data(train_dir)\nprint(\"Images successfully imported...\")","78d9078c":"print(\"The shape of X_train is : \", X_train.shape)\nprint(\"The shape of y_train is : \", y_train.shape)","6f4c5a84":"print(\"The shape of one image is : \", X_train[0].shape)","8704c145":"plt.imshow(X_train[0])\nplt.show()","0260aa49":"X_data = X_train\ny_data = y_train\nprint(\"Copies made...\")","787158d5":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3,random_state=42,stratify=y_data)","fd4fe17c":"# One-Hot-Encoding the categorical data\nfrom tensorflow.keras.utils import to_categorical\ny_cat_train = to_categorical(y_train,29)\ny_cat_test = to_categorical(y_test,29)","42749b5c":"# Checking the dimensions of all the variables\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\nprint(y_cat_train.shape)\nprint(y_cat_test.shape)","171a362c":"# This is done to save CPU and RAM space while working on Kaggle Kernels. This will delete the specified data and save some space!\nimport gc\ndel X_data\ndel y_data\ngc.collect()","171ceaea":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\nprint(\"Packages imported...\")","1efbf82d":"model = Sequential()\n\nmodel.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(29, activation='softmax'))\n\nmodel.summary()","0e006eaf":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)","7c9d67c7":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","209ac454":"model.fit(X_train, y_cat_train,\n          epochs=50,\n          batch_size=64,\n          verbose=2,\n          validation_data=(X_test, y_cat_test),\n         callbacks=[early_stop])","7027e739":"metrics = pd.DataFrame(model.history.history)\nprint(\"The model metrics are\")\nmetrics","edb9bed4":"metrics[['loss','val_loss']].plot()\nplt.show()","a4734294":"metrics[['accuracy','val_accuracy']].plot()\nplt.show()","3f389738":"model.evaluate(X_test,y_cat_test,verbose=0)","460b264d":"predictions = model.predict_classes(X_test)\nprint(\"Predictions done...\")","a681683c":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test,predictions))","75df9ad6":"plt.figure(figsize=(12,12))\nsns.heatmap(confusion_matrix(y_test,predictions))\nplt.show()","75851a6d":"# from keras.models import load_model\n# model.save('ASL.h5')\nprint(\"Model saved successfully...\")","769b3e09":"Early Stopping is done to make sure the model fitting stops at the most optimized accuracy point. After the early stopping point, the model might start overfitting. For testing purposes, this step can be skipped and complete training can be done.","643133c2":"#### 5.7 Saving the model <a id=18><\/a>","084721d0":"#### 5.2 Building model <a id=13><\/a>","0632955c":"<h2><center>American Sign Language Detection<\/center><\/h2>","5b389ff7":"##### 5.6.1 Classification report","5eb032c4":"#### 5.4 Model fitting <a id=15><\/a>","7a66aa21":"### 5. Modeling <a id=11><\/a>","7ed09b64":"#### 5.1 Importing packages <a id=12><\/a>","7e0d288d":"#### 2.2 Checking the shape of one image <a id=4><\/a>","0655f5ca":"#### 3.1 Train\/test split <a id=7><\/a>","5d8f3616":"##### 5.3.2 Compiling","18cc4c08":"Table of contents <a id=19><\/a>\n1. [Importing packages](#1)\n2. [Importing the dataset from training directory](#2)\n    - 2.1 [Checking the shape of data](#3)\n    - 2.2 [Checking the shape of one image](#4)\n    - 2.3 [Viewing the image](#5)\n3. [Data processing](#6)\n    - 3.1 [Train\/test split](#7)\n    - 3.2 [One-Hot-Encoding](#8)\n    - 3.3 [Dimension Check of variables](#9)\n4. [Garbage Collection](#10)\n5. [Modeling](#11)\n    - 5.1 [Importing packages](#12)\n    - 5.2 [Building the model](#13)\n    - 5.3 [Early Stopping & Compiling](#14)\n    - 5.4 [Model fitting](#15)\n    - 5.5 [Model metrics](#16)\n    - 5.6 [Predictions](#17)\n    - 5.7 [Saving the model](#18)","19eb85fd":"### 3. Data processing <a id=6><\/a>","efb786ef":"#### 5.6 Predictions <a id=17><\/a>","81e542f0":"***I've added the final model as a dataset link. Since running this notebook requires GPU consumtion and it's quite time consuming, if you just want the model, you may get it from here https:\/\/www.kaggle.com\/namanmanchanda\/american-sign-language-model-99-accuracy.***","c7de39c5":"#### 5.3 Early Stopping and Compiling <a id=14><\/a>","822d18a7":"##### 2.3.1 Making copies of original data","21a27af4":"### 2. Importing the dataset from training directory <a id=2><\/a>","9602d97e":"#### 2.1 Checking the shape of data <a id=3><\/a>","9a43686d":"### 1. Importing packages <a id=1><\/a>","58c68cb6":"#### 2.3 Viewing the image <a id=5><\/a>","5bf1a2b7":"#### 3.3 Dimension Check of variables <a id=9><\/a>","e25f78ed":"##### 5.5.3 Plotting the testing loss","95d2a800":"[back to top](#19)","4ba62949":"##### 5.3.1 Early Stopping","a2dc8ab9":"### If you liked the notebook, consider giving an upvote.\n\nCheck my other notebooks\n1. https:\/\/www.kaggle.com\/namanmanchanda\/rnn-in-pytorch\n2. https:\/\/www.kaggle.com\/namanmanchanda\/pytorch-101\n3. https:\/\/www.kaggle.com\/namanmanchanda\/red-wine-eda-and-classification\n4. https:\/\/www.kaggle.com\/namanmanchanda\/heart-attack-eda-prediction-90-accuracy","68688d7b":"##### 5.5.4 Model evaluation","008de514":"#### 5.5 Model metrics <a id=16><\/a>","cb382900":"#### 3.2 One-Hot-Encoding <a id=8><\/a>","a9663f41":"##### 5.6.2 Confusion matrix heatmap","2bf46ccc":"### 4. Garbage Collection <a id=10><\/a>","f3428a6d":"##### 5.5.1 Metrics from model history","8b16ef45":"##### 5.5.2 Plotting the training loss"}}