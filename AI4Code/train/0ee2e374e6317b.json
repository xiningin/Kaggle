{"cell_type":{"7cb3b73b":"code","dbe99c24":"code","ded03e21":"code","a640cbeb":"code","328675e1":"code","76b69c1a":"code","bd9468be":"code","1b9d2463":"code","15fe8bb1":"code","04fff5d9":"code","d8af8863":"code","dc6bf475":"code","36feac70":"markdown","6f667035":"markdown","44e15b3d":"markdown","9dd73b46":"markdown","58c3387d":"markdown","0503735e":"markdown","0b345a18":"markdown","064b3347":"markdown","14653915":"markdown","b1aaebe8":"markdown","83e51a73":"markdown","24d41c75":"markdown","58eab250":"markdown","126f4c34":"markdown","39162a60":"markdown","2fe17366":"markdown","18ddca32":"markdown","5bf4cd4f":"markdown","33eeff9c":"markdown"},"source":{"7cb3b73b":"# Set your own project id here\nPROJECT_ID = 'bqml-exercise'# a string, like 'kaggle-bigquery-240818'\n\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID, location=\"US\")\ndataset = client.create_dataset('model_dataset', exists_ok=True)\n\nfrom google.cloud.bigquery import magics\nfrom kaggle.gcp import KaggleKernelCredentials\nmagics.context.credentials = KaggleKernelCredentials()\nmagics.context.project = PROJECT_ID","dbe99c24":"%load_ext google.cloud.bigquery","ded03e21":"# You can write your notes here\n## Splitting the data base on date, using historical data to predict outcome for later events\n#They should be from same distribution in train and test set!Train data and test data as following\n# Split in 80:20 for train:test\n# 80:20 for train:validation (holdout) \n# Test on data unseen to model ","a640cbeb":"# create a reference to our table\ntable = client.get_table(\"bigquery-public-data.austin_bikeshare.bikeshare_trips\")\n\n# look at five rows from our dataset\nclient.list_rows(table, max_results=5).to_dataframe()","328675e1":"%%bigquery \nSELECT start_station_name,TIMESTAMP_TRUNC(start_time, HOUR) as start_hour, COUNT(*) as num_rides\nFROM `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE start_time < '2018-01-01'\nGROUP BY start_station_name, start_hour\nLIMIT 10\n","76b69c1a":"%%bigquery\nCREATE OR REPLACE MODEL`model_dataset.bike_trips`\nOPTIONS(model_type='linear_reg', optimize_strategy = 'batch_gradient_descent') AS \nSELECT \n    COUNT(*) AS label,\n    TIMESTAMP_TRUNC(start_time, HOUR) as start_hour, \n    start_station_name\n    \nFROM `bigquery-public-data.austin_bikeshare.bikeshare_trips`   \nWHERE DATE(start_time) < '2018-01-01'\nGROUP BY start_station_name, start_hour\n","bd9468be":"%%bigquery\nSELECT\n  *\nFROM\n  ML.TRAINING_INFO(MODEL `model_dataset.bike_trips`)\nORDER BY iteration ","1b9d2463":"\n%%bigquery\nSELECT\n  *\nFROM ML.EVALUATE(MODEL `model_dataset.bike_trips`, (\n    SELECT\n    COUNT(*) AS label,\n    TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n    start_station_name\nFROM `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE DATE(start_time) >= '2018-01-01'\nGROUP BY start_station_name, start_hour))","15fe8bb1":"## Thought question answer here\n##Data before 2018 and after 2018 does not correlated\n","04fff5d9":"%%bigquery\nSELECT\n    AVG(predicted_label), AVG(label)\nFROM \n    ML.PREDICT(MODEL `model_dataset.bike_trips`, (\n        SELECT\n        COUNT(trip_id) AS label,\n        TIMESTAMP_TRUNC(start_time, HOUR) AS start_hour,\n        start_station_name\nFROM `bigquery-public-data.austin_bikeshare.bikeshare_trips`\nWHERE   start_time >= '2018-01-01' AND start_time < '2019-01-01' \n        AND start_station_name = '22nd & Pearl'\nGROUP BY start_station_name, start_hour))","d8af8863":"%%bigquery \n\nWITH num_daily_rides AS (\n    SELECT COUNT(*) AS num_rides,\n           start_station_name,\n           EXTRACT(DAYOFYEAR from start_time) AS day,\n           EXTRACT(YEAR from start_time) AS year\n    FROM `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    GROUP BY start_station_name, day, year ORDER BY year\n), \nstation_avg AS (\n    SELECT AVG(num_rides) AS avg_riders, \n            start_station_name, \n            year\n    FROM num_daily_rides\n    GROUP BY start_station_name, year\n)\nSELECT avg(avg_riders) AS avg_daily_rides_per_station, year\nFROM station_avg\nGROUP BY year\nORDER BY year","dc6bf475":"## Thought question answer here\n## Yes. The model is falling because number of riders was much more in 2018 than in 2019","36feac70":"Write your query below:","6f667035":"What you should see here is that the model is underestimating the number of rides by quite a bit. \n\n## 7) Exercise: Average daily rides per station\n\nEither something is wrong with the model or something surprising is happening in the 2018 data. \n\nWhat could be happening in the data? Write a query to get the average number of riders per station for each year in the dataset and order by the year so you can see the trend. You can use the `EXTRACT` method to get the day and year from the start time timestamp. (You can read up on EXTRACT [in this lesson in the Intro to SQL course](https:\/\/www.kaggle.com\/dansbecker\/order-by)). ","44e15b3d":"### This exercise is designed to pair with [this tutorial](https:\/\/www.kaggle.com\/rtatman\/bigquery-machine-learning-tutorial). If you haven't taken a look at it yet, head over and check it out first. (Otherwise these exercises will be pretty confusing!) -- Rachael ","9dd73b46":"## 3) Exercise: Create and train the model\n\nBelow, write your query to create and train a linear regression model on the training data.","58c3387d":"## Training data\n\nFirst, you'll write a query to get the data for model-building. You can use the public Austin bike share dataset from the `bigquery-public-data.austin_bikeshare.bikeshare_trips` table. You predict the number of rides based on the station where the trip starts and the hour when the trip started. Use the `TIMESTAMP_TRUNC` function to truncate the start time to the hour.","0503735e":"# 9) Next steps\n\nGiven what you've learned, what improvements do you think you could make to your model? Share your ideas on the [Kaggle Learn Forums](https:\/\/www.kaggle.com\/learn-forum)! (I'll pick a couple of my favorite ideas & send the folks who shared them a Kaggle t-shirt. :)","0b345a18":"## 4) Exercise: Model evaluation\n\nNow that you have a model, evaluate it's performance on data from 2018. \n\n\n> Note that the ML.EVALUATE function will return different metrics depending on what's appropriate for your specific model. You can just use the regular ML.EVALUATE funciton here. (ROC curves are generally used to evaluate binary problems, not linear regression, so there's no reason to plot one here.)","064b3347":"## Model creation\n\nNow it's time to turn this data into a model. You'll use the `CREATE MODEL` statement that has a structure like: \n\n```sql\nCREATE OR REPLACE MODEL`model_dataset.bike_trips`\nOPTIONS(model_type='linear_reg') AS \n-- training data query goes here\nSELECT ...\n    column_with_labels AS label\n    column_with_data_1 \n    column_with_data_2\nFROM ... \nWHERE ... (Optional)\nGROUP BY ... (Optional)\n```\n\nThe `model_type` and `optimize_strategy` shown here are good parameters to use in general for predicting numeric outcomes with BQML.\n\n**Tip:** Using ```CREATE OR REPLACE MODEL``` rather than just ```CREATE MODEL``` ensures you don't get an error if you want to run this command again without first deleting the model you've created.","14653915":"Write your query below:","b1aaebe8":"Write your query below:","83e51a73":"## Linear Regression\n\nYour dataset is quite large. BigQuery is especially efficient with large datasets, so you'll use BigQuery-ML (called BQML) to build your model. BQML uses a \"linear regression\" model when predicting numeric outcomes, like the number of riders.\n\n## 1) Training vs testing\n\nYou'll want to test your model on data it hasn't seen before (for reasons described in the [Intro to Machine Learning Micro-Course](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning). What do you think is a good approach to splitting the data? What data should we use to train, what data should we use for test the model?","24d41c75":"You'll want to inspect your data to ensure it looks like what you expect. Run the line below to get a quick view of the data, and feel free to explore it more if you'd like (if you don't know how to do that, the [Pandas micro-course](https:\/\/www.kaggle.com\/learn\/pandas)) might be helpful.","58eab250":"Write your query below:","126f4c34":"## 6) Exercise: Looking at predictions\n\nA good way to figure out where your model is going wrong is to look closer at a small set of predictions. Use your model to predict the number of rides for the 22nd & Pearl station in 2018. Compare the mean values of predicted vs actual riders.","39162a60":"## 8) What do your results tell you?\n\nGiven the daily average riders per station over the years, does it make sense that the model is failing?","2fe17366":"# Stocking rental bikes\n\n![bike rentals](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/a0\/Bay_Area_Bike_Share_launch_in_San_Jose_CA.jpg\/640px-Bay_Area_Bike_Share_launch_in_San_Jose_CA.jpg)\n\nYou stock bikes for a bike rental company in Austin, ensuring stations have enough bikes for all their riders. You decide to build a model to predict how many riders will start from each station during each hour, capturing patterns in seasonality, time of day, day of the week, etc.\n\nTo get started, create a project in GCP and connect to it by running the code cell below. Make sure you have connected the kernel to your GCP account in Settings.","18ddca32":"You should see that the r^2 score here is negative. Negative values indicate that the model is worse than just predicting the mean rides for each example.\n\n## 5) Theories for poor performance\n\nWhy would your model be doing worse than making the most simple prediction based on historical data?","5bf4cd4f":"Write your query below:","33eeff9c":"## 2) Exercise: Query the training data\n\nWrite the query to retrieve your training data. The fields should be:\n1. The start_station_name\n2. A time trips start, to the nearest hour. Get this with `TIMESTAMP_TRUNC(start_time, HOUR) as start_hour`\n3. The number of rides starting at the station during the hour. Call this `num_rides`.\nSelect only the data before 2018-01-01 (so we can save data from 2018 as testing data.)"}}