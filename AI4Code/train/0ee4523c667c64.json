{"cell_type":{"b98a1bda":"code","dcece03a":"code","f3d9f2af":"code","1135c8d1":"code","2a793877":"code","5c794497":"code","11501042":"code","25f415a5":"code","08ec4d0a":"code","e1938125":"code","47b22b62":"code","8d664ef3":"markdown","d890fafa":"markdown","53f2fdf1":"markdown","3d13be54":"markdown"},"source":{"b98a1bda":"import numpy as np\nimport pandas as pd\nimport os\nimport json","dcece03a":"json_folder_path = \"\/kaggle\/input\/iwildcam2021-fgvc8\/metadata\"\nlist_of_files = list(os.listdir(json_folder_path))\n\nfor file_name in list_of_files:\n    json_path = os.path.join(json_folder_path, file_name)\n    print(f\"Current json processed: {file_name}\")\n    with open(json_path) as json_file:\n        # read each json\n        json_data = json.load(json_file)\n        # for each item in the json\n        for item in json_data.items():\n            # prepare the dataframe name\n            file_name_split = file_name.split(\".\")[0]\n            file_name_split = file_name_split.split(\"_\")\n            file_name_str = file_name_split[1] + \"_\" + file_name_split[2]\n            print(f\"\\tCurrent json item processed: {item[0]} length: {len(item[1])}\")\n            data_frame_name = f\"{file_name_str}_{item[0]}_df\"\n            print(f\"\\tDynamic dataframe created: {data_frame_name}\")\n            # dynamic creation of a dataframe, using vars()[data_frame_name]\n            vars()[data_frame_name] = pd.json_normalize(json_data.get(item[0]))\n            # output the dataframe\n            vars()[data_frame_name].to_csv(f\"{data_frame_name}\", index=False)","f3d9f2af":"print(megadetector_results_images_df.shape)\nmegadetector_results_images_df.head()","1135c8d1":"megadetector_results_images_df['detections_count'] = megadetector_results_images_df[\"detections\"].apply(lambda x: len(x))","2a793877":"print(f\"Max detections: {max(megadetector_results_images_df['detections_count'] )}\")","5c794497":"print(megadetector_results_info_df.shape)\nmegadetector_results_info_df.head()","11501042":"print(megadetector_results_detection_categories_df.shape)\nmegadetector_results_detection_categories_df.head()","25f415a5":"print(test_information_images_df.shape)\ntest_information_images_df.head()","08ec4d0a":"print(train_annotations_images_df.shape)\ntrain_annotations_images_df.head()","e1938125":"print(train_annotations_annotations_df.shape)\ntrain_annotations_annotations_df.head()","47b22b62":"print(train_annotations_categories_df.shape)\ntrain_annotations_categories_df.head()","8d664ef3":"We will keep this data in this format for now.","d890fafa":"# Data ingestion and processing\n\n\nWe will do all data ingestion and processing into a single loop.","53f2fdf1":"# Introduction\n\nThe various metainformation for this competition is stored in json format.\n\nWe would like to process these jsons so that we can easily build our training matrices.\n\nFor this, we will process all jsons and extract dataframes, by normalizing the json data.","3d13be54":"Let's further process `megadetector_results_images_df.detections`\n\nLet's find what is the maximum number of  detections from all data."}}