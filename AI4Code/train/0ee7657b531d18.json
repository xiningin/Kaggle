{"cell_type":{"ec46ae01":"code","1374af47":"code","ba74179e":"code","ed312a46":"code","2979c441":"code","03e241c8":"code","debd78af":"code","07c87759":"code","9c9fdb90":"code","66866921":"code","c1776ff1":"code","daf86afd":"code","2170b70b":"code","181fae2b":"code","a5fc0bd3":"code","cfd84dc0":"code","e5b79671":"code","fb38f4c8":"code","f9bccc53":"code","2672c163":"code","21aa48a8":"code","ed96d5f0":"code","b9954640":"code","1a601a87":"code","0576ffb2":"code","ad16bba9":"code","a7a92235":"code","233883bc":"markdown","b59e5c38":"markdown","4c5be42e":"markdown","de4a49c8":"markdown","cf2ff625":"markdown","3a41aefd":"markdown","dd8c1307":"markdown","a3f30baa":"markdown","e1a8d3a8":"markdown","57605993":"markdown","420d257d":"markdown","3897c3d8":"markdown","0b6d0c31":"markdown","a50591a4":"markdown","bed34e29":"markdown","46dd3920":"markdown","a1ab6d64":"markdown","7f1e31b2":"markdown","9474ca77":"markdown","3985f8c6":"markdown"},"source":{"ec46ae01":"# Basic Torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torchvision\nfrom torch.utils.data import TensorDataset\nfrom torch.optim import Adam, SGD\n\n# Basic Numeric Computation\nimport numpy as np\nimport pandas as pd\n\n# Look at data\nfrom matplotlib import pyplot\n\n# Easy way to split train data\nfrom sklearn.model_selection import train_test_split\n\n# Looking at directory\nimport os\nbase_dir = \"..\/input\"\nprint(os.listdir(base_dir))\n\ndevice = torch.device(\"cpu\")# if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice\nepochs=12","1374af47":"train = pd.read_csv(base_dir + '\/train.csv')\ntest = pd.read_csv(base_dir + '\/test.csv')","ba74179e":"train.head()","ed312a46":"# Convert Dataframe into format ready for training\ndef createImageData(raw: pd.DataFrame):\n    y = raw['label'].values\n    y.resize(y.shape[0],1)\n    x = raw[[i for i in raw.columns if i != 'label']].values\n    x = x.reshape([-1,1, 28, 28])\n    y = y.astype(int).reshape(-1)\n    x = x.astype(float)\n    return x, y\n\n## Convert to One Hot Encoding\ndef one_hot_embedding(labels, num_classes=10):\n    y = torch.eye(num_classes) \n    return y[labels] ","2979c441":"x_train, y_train = createImageData(train)\n#x_train, x_val, y_train, y_val = train_test_split(x,y, test_size=0.02)\n\n#x_train.shape, y_train.shape, x_val.shape, y_val.shape\nx_train.shape, y_train.shape","03e241c8":"# Normalization\nmean = x_train.mean()\nstd = x_train.std()\nx_train = (x_train-mean)\/std\n#x_val = (x_val-mean)\/std\n\n# Numpy to Torch Tensor\nx_train = torch.from_numpy(np.float32(x_train)).to(device)\ny_train = torch.from_numpy(y_train.astype(np.long)).to(device)\ny_train = one_hot_embedding(y_train)\n#x_val = torch.from_numpy(np.float32(x_val))\n#y_val = torch.from_numpy(y_val.astype(np.long))","debd78af":"# Convert into Torch Dataset\ntrain_ds = TensorDataset(x_train, y_train)\n#val_ds = TensorDataset(x_val,y_val)","07c87759":"# Make Data Loader\ntrain_dl = DataLoader(train_ds, batch_size=64)","9c9fdb90":"index = 1\npyplot.imshow(x_train.cpu()[index].reshape((28, 28)), cmap=\"gray\")\nprint(y_train[index])","66866921":"# Helper Functions\n\n## Initialize weight with xavier_uniform\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.01)\n\n## Flatten Later\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\n# Train the network and print accuracy and loss overtime\ndef fit(train_dl, model, loss, optim, epochs=10):\n    model = model.to(device)\n    print('Epoch\\tAccuracy\\tLoss')\n    accuracy_overtime = []\n    loss_overtime = []\n    for epoch in range(epochs):\n        avg_loss = 0\n        correct = 0\n        total=0\n        for x, y in train_dl: # Iterate over Data Loder\n    \n            # Forward pass\n            yhat = model(x) \n            l = loss(y, yhat)\n            \n            #Metrics\n            avg_loss+=l.item()\n            \n            # Backward pass\n            optim.zero_grad()\n            l.backward()\n            optim.step()\n            \n            # Metrics\n            _, original =  torch.max(y, 1)\n            _, predicted = torch.max(yhat.data, 1)\n            total += y.size(0)\n            correct = correct + (original == predicted).sum().item()\n            \n        accuracy_overtime.append(correct\/total)\n        loss_overtime.append(avg_loss\/len(train_dl))\n        print(epoch,accuracy_overtime[-1], loss_overtime[-1], sep='\\t')\n    return accuracy_overtime, loss_overtime\n\n# Plot Accuracy and Loss of Model\ndef plot_accuracy_loss(accuracy, loss):\n    f = pyplot.figure(figsize=(15,5))\n    ax1 = f.add_subplot(121)\n    ax2 = f.add_subplot(122)\n    ax1.title.set_text(\"Accuracy over epochs\")\n    ax2.title.set_text(\"Loss over epochs\")\n    ax1.plot(accuracy)\n    ax2.plot(loss, 'r:')\n\n# Take an array and show what model predicts \ndef predict_for_index(array, model, index):\n    testing = array[index].view(1,28,28)\n    pyplot.imshow(x_train[index].reshape((28, 28)), cmap=\"gray\")\n    print(x_train[index].shape)\n    a = model(testing.float())\n    print('Prediction',torch.argmax(a,1))","c1776ff1":"# Define the model\n\nff_model = nn.Sequential(\n    Flatten(),\n    nn.Linear(28*28, 100),\n    nn.ReLU(),\n    nn.Linear(100, 10),\n    nn.Softmax(1),\n).to(device)","daf86afd":"# Initialize model with xavier initialization which is recommended for ReLu\nff_model.apply(init_weights)","2170b70b":"optim = Adam(ff_model.parameters())\nloss = nn.MSELoss()\noutput = fit(train_dl, ff_model, loss, optim, epochs)\nplot_accuracy_loss(*output)","181fae2b":"index = 4\npredict_for_index(x_train, ff_model, index)","a5fc0bd3":"# A too simple NN taken from pytorch.org\/tutorials\nclass Mnist_CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n\n    def forward(self, xb):\n        xb = xb.view(-1, 1, 28, 28)\n        xb = F.relu(self.conv1(xb))\n        xb = F.relu(self.conv2(xb))\n        xb = F.relu(self.conv3(xb))\n        xb = F.avg_pool2d(xb, 4)\n        return xb.view(-1, xb.size(1))\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)\n        self.average1 = nn.AvgPool2d(2, stride=2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n        self.average2 = nn.AvgPool2d(2, stride=2)\n        self.conv3 = nn.Conv2d(16, 120, kernel_size=4, stride=1)\n        \n        self.flatten = Flatten()\n        \n        self.fc1 = nn.Linear(120, 82)\n        self.fc2 = nn.Linear(82,10)\n\n    def forward(self, xb):\n        xb = xb.view(-1, 1, 28, 28)\n        xb = F.tanh(self.conv1(xb))\n        xb = self.average1(xb)\n        xb = F.tanh(self.conv2(xb))\n        xb = self.average2(xb)\n        xb = F.tanh(self.conv3(xb))\n        xb = xb.view(-1, xb.shape[1])\n        xb = F.relu(self.fc1(xb))\n        xb = F.relu(self.fc2(xb))\n        return xb","cfd84dc0":"conv_model = LeNet5()\nconv_model.apply(init_weights)\nloss = nn.MSELoss()\noptim = SGD(conv_model.parameters(), lr=0.1, momentum=0.9)\nplot_accuracy_loss(*fit(train_dl, conv_model,loss,optim,epochs))","e5b79671":"x_test = test.values\nx_test = x_test.reshape([-1, 28, 28]).astype(float)\nx_test = (x_test-mean)\/std\nx_test = torch.from_numpy(np.float32(x_test))\nx_test.shape","fb38f4c8":"index = 7\npredict_for_index(x_test, ff_model, index)\npredict_for_index(x_test, conv_model, index)","f9bccc53":"# Export data to CSV in format of submission\ndef export_csv(model_name, predictions, commit_no):\n    df = pd.DataFrame(prediction.tolist(), columns=['Label'])\n    df['ImageId'] = df.index + 1\n    file_name = f'submission_{model_name}_v{commit_no}.csv'\n    print('Saving ',file_name)\n    df[['ImageId','Label']].to_csv(file_name, index = False)","2672c163":"test.head()","21aa48a8":"# just to make output easier to read\ncommit_no = 17","ed96d5f0":"ff_test_yhat = ff_model(x_test.float())\nprediction = torch.argmax(ff_test_yhat,1)\nprint('Prediction',prediction)\nexport_csv('ff_model',prediction, commit_no=commit_no)","b9954640":"cn_train_yhat = conv_model(x_test)\nprediction = torch.argmax(cn_train_yhat,1)\nyo = torch.argmax(y_train,1)\nexport_csv('lenet_model',prediction, commit_no=commit_no)","1a601a87":"models = []\noptims = []\nloss = nn.MSELoss()\nensembles = 15\nimport sys\nfor i in range(ensembles):\n    sys.stdout.write(f'Ensemble No {i+1}\\n')\n    model = LeNet5()\n    model.apply(init_weights)\n    #optim = Adam(model.parameters())\n    optim = SGD(model.parameters(), lr=0.1, momentum=0.9)\n\n    accuracy, _ = fit(train_dl, model,loss,optim,epochs)\n    if accuracy[-1] > 95:\n        models.append(model)\n        optims.append(optim)","0576ffb2":"ensemble = cn_train_yhat\n\nfor model in models:\n    ensemble+=model(x_test)\n\nensemble_one_hot = torch.argmax(ensemble,1) # Find argmax\nexport_csv(f'ensemble_{ensembles}_LeNets',ensemble_one_hot, commit_no=commit_no)","ad16bba9":"ensemble_one_hot","a7a92235":"ensemble = ff_test_yhat + cn_train_yhat # Add probabilities of individual predictions\nensemble_one_hot = torch.argmax(y_train,1) # Find argmax\nexport_csv('ensemble',ensemble_one_hot, commit_no=commit_no)","233883bc":"## Looking at prediction\n","b59e5c38":"# Preparing Data\n## Extract Transform Load (ETL)","4c5be42e":"## Exporting Data for Submission","de4a49c8":"# Imports","cf2ff625":"# Ensemble\n\nEnsemble is a popular technique using usually in competition which allow combining results of different models to product higher accuracy.\n\nIn this particular case, it seems like LeNet was much better than the feed-forward network that is why the accuracy of the ensemble on test data is the same as LeNet5 \u2013 **0.98942**","3a41aefd":"> # Explore Data\n\nIt is always benifition to look at your data before building your model. This helps to understand what the model will be dealing with and removes assumptions you might have induce unknowingly into your model","dd8c1307":"### 1. Extract","a3f30baa":"# Looking at prediction the model makes","e1a8d3a8":"A feed forward neural network is not ideal for Image Classification. The reason is: **Parameters are not shared**.\n\nAlso, if you increase epoch beyond 10, you will find the model quickly overfits.\n\nInitially, I made a dumb model and focused on just getting through the complete flow. This is because Deep Learning is a iterative process and spending too much time on building the perfect model can lead to a lot of wasted time with no output.\n\nI will be making Convolutional NN later which will require better hyperparameter setting.\n\nThe input to this feed forward NN is 784 features. The target labels to predict is 10. I choose 100 as number of hidden units in layer intuitively for being a middle ground between 784 and 10.\n\n(m, 784) -> (m, 100) -> (m,10)\n\nm: number of items in mini-batch","57605993":"### 2. Transform","420d257d":"Define Hyperparameters and Train","3897c3d8":"## Convolutional NN","0b6d0c31":"**Normalization**: We need to normalize with the same values used to normalize train data else it will lead to uneven distribution between train and test set.","a50591a4":"### 3. Load","bed34e29":"A CNN is perfect for images because the parameters used to detect something in one part of image are same as once used in other part of the image.\n\nInitially, I started with a simple CNN which was not accurate and would often overfit. I had to rewatch videos from Andrew Ng's Convolutional Neural Network Course and re-learned that it is always better to take inspiration from other successful models.\n\nThis model has accuracy of **0.98942**.\n\n![image.png](attachment:image.png)\n\nSources for creating model:\n- [LeNet-5 \u2013 A Classic CNN Architecture](https:\/\/engmrk.com\/lenet-5-a-classic-cnn-architecture\/) (Image Reference)\n- [DeepLearning.ai-Summary \/ Convolutional Neural Networks](https:\/\/github.com\/mbadry1\/DeepLearning.ai-Summary\/tree\/master\/4-%20Convolutional%20Neural%20Networks#classic-networks)","46dd3920":"## Model\n\nBelow are helper functions. \nInitially these were written as normal Pytorch functions but latter abstracted to make code clean and easily reuse later.","a1ab6d64":"# Preparing Test Data","7f1e31b2":"## Feed Forward Neural Network with 2 hidden layers","9474ca77":"MNIST is a classic toy dataset for image recognition. The dataset consists of handwritten images that have served as the basis for benchmarking classification algorithms\n\n**Table of Contents**:\n\n- Imports\n- Preparing Data\n- Explore Data\n- Model\n    - Simple Feed Forward NN (Test Accuracy of 96%)\n    - **CNN based on LeNet5** (Test Accuracy of 98%)\n- Preparing Test Data\n- Looking at Prediction\n- Exporting Data\n- Ensembles (Test Accuracy of 98%)\n- Commit History","3985f8c6":"# Commit History\n\n**v3:** Corrected Input Shape: There was different shape between y and yhat\n\n**v4:** Changed output layer to Softmax: It was previously LogSoftmax. I knew it was wrong but for some reason code was not working then with Softmax.\n\n**v5:** Clean Code using Helper functions and plotting\n\n**v6:** Bug fixes\n\n**v7:** Adding Documentation. Verbose saving.\n\n**v9:** Implementation of LeNet5 architecture.\n\n**v10:** Updating results from LeNet5. Table of Contents. And LetNet5 architecture and link to sources.\n\n**v11:** Ensemble 15 LeNets\n\n**v12:** Trying out a suggestion (via comment) by using learning rate of 0.001. Instead of directly changing LR, switching to Adam.\n\n**v13:** Some ensembles were not even fit to training set well.\n\nv14: Reverting to using SGD\n\nv17: Lr 0.1\n\n***\n\nIf you have any tips, suggestion or any interesting dataset, you can get in touch with the comment section below."}}