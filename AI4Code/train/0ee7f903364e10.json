{"cell_type":{"bd8120bb":"code","9df77f2b":"code","7c673294":"code","2d0bf30d":"code","a2707c85":"code","4479be3b":"code","92c71004":"code","1337a8eb":"code","291405bf":"code","5b2e3878":"code","0154351e":"code","d778f28b":"code","3174d779":"code","bca11e5b":"code","af371ada":"code","2a9850e6":"code","9a87cfd2":"code","7606e376":"code","d77788f6":"code","4b6f458f":"code","f2f4b547":"code","9aefd778":"code","38236e79":"code","a32163e9":"code","8cb74ab5":"code","722570cf":"code","fb52e177":"code","4b322025":"code","601f8b6d":"code","3cbfbf01":"code","f54308ac":"code","c2edc90d":"code","9ba12b28":"code","cd906636":"code","fa34743e":"code","d8f6fbbb":"code","88650767":"code","866baa93":"code","c0699440":"code","bb497c4f":"code","df13256f":"code","f696a2cd":"code","a6ffb79a":"code","042b0dd1":"code","6b2e4423":"code","5c6f5909":"code","454ae636":"code","8a6dad4d":"code","15cc873c":"code","6f2741d1":"code","b2176e24":"code","f61fdf84":"code","bdec617c":"code","958d3cd7":"code","1646bb33":"code","a4ae83c5":"code","3bdc3f6c":"code","e02f0d0f":"markdown","1fe58883":"markdown","c58dc702":"markdown","fc851fda":"markdown","d2ae4c67":"markdown","33cae479":"markdown","9a7dba14":"markdown","fb4ca91f":"markdown","bbbfc2ac":"markdown","0816adaa":"markdown","0ee2a583":"markdown","eff428da":"markdown","7a560f3a":"markdown","9e624744":"markdown"},"source":{"bd8120bb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# data visualization\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))","9df77f2b":"#read data\ndata_train = pd.read_csv(\"..\/input\/train.csv\")\ndata_test = pd.read_csv(\"..\/input\/test.csv\")","7c673294":"#train sample\ndata_train.sample(5)","2d0bf30d":"#test sample\ndata_test.sample(5)","a2707c85":"data_train.info()\nprint(\"---------------------------------\")\ndata_test.info()","4479be3b":"#train columns\ndata_train.columns","92c71004":"#test column\ndata_test.columns","1337a8eb":"data_train.describe(include=\"all\")","291405bf":"data_test.describe(include=\"all\")","5b2e3878":"#missing values\nprint(pd.isnull(data_train).sum())\nprint(\"-------------------------\")\nprint(pd.isnull(data_test).sum())","0154351e":"# train survived count\nsurvived = data_train.Survived\nplt.figure(figsize=(7,5))\nsns.countplot(survived)\nplt.title(\"Survived\",color='blue',fontsize=15)\nplt.show()","d778f28b":"passanger_class = data_train.Pclass\nplt.figure(figsize=(7,5))\nsns.countplot(passanger_class)\nplt.title(\"data_train Passanger Class\",color = 'blue',fontsize=15)\nplt.show()","3174d779":"passanger_class = data_test.Pclass\nplt.figure(figsize=(7,5))\nsns.countplot(passanger_class)\nplt.title(\"data_test Passanger Class\",color = 'blue',fontsize=15)\nplt.show()","bca11e5b":"data_train['Title'] = data_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ndata_train['Title'] = data_train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ndata_train['Title'] = data_train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ndata_train['Title'] = data_train['Title'].replace('Mlle', 'Miss')\ndata_train['Title'] = data_train['Title'].replace('Ms', 'Miss')\ndata_train['Title'] = data_train['Title'].replace('Mme', 'Mrs')\n\npassanger_name = data_train.Title\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_name)\nplt.title(\"data_train Passanger Name\",color = 'blue',fontsize=15)\nplt.show()","af371ada":"data_test['Title'] = data_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ndata_test['Title'] = data_test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ndata_test['Title'] = data_test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ndata_test['Title'] = data_test['Title'].replace('Mlle', 'Miss')\ndata_test['Title'] = data_test['Title'].replace('Ms', 'Miss')\ndata_test['Title'] = data_test['Title'].replace('Mme', 'Mrs')\n\npassanger_name = data_test.Title\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_name)\nplt.title(\"data_test Passanger Name\",color = 'blue',fontsize=15)\nplt.show()","2a9850e6":"gender = data_train.Sex\nplt.figure(figsize=(7,5))\nsns.countplot(gender)\nplt.title(\"data_train Gender\",color = 'blue',fontsize=15)\nplt.show()","9a87cfd2":"gender = data_test.Sex\nplt.figure(figsize=(7,5))\nsns.countplot(gender)\nplt.title(\"data_test Gender\",color = 'blue',fontsize=15)\nplt.show()","7606e376":"data_train['AgeGroup'] = [\"Baby\" if (i>=0 and i<5) else \"Child\" if (i>=5 and i<12) else \"Teenager\" if (i>=12 and i<18) \n                          else \"Student\" if(i>=18 and i<24) else \"Young Adult\" if(i>=24 and i<35) \n                          else \"Adult\" if(i>=35 and i<60) else \"Senior\" if(i>=60) else \"Unknown\" \n                          for i in data_train.Age ]\n\npassanger_ageGroup = data_train.AgeGroup\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_ageGroup)\nplt.title(\"data_train Passanger AgeGroup\",color = 'blue',fontsize=15)\nplt.show()","d77788f6":"data_test['AgeGroup'] = [\"Baby\" if (i>=0 and i<5) else \"Child\" if (i>=5 and i<12) else \"Teenager\" if (i>=12 and i<18) \n                          else \"Student\" if(i>=18 and i<24) else \"Young Adult\" if(i>=24 and i<35) \n                          else \"Adult\" if(i>=35 and i<60) else \"Senior\" if(i>=60) else \"Unknown\" \n                          for i in data_test.Age ]\n\npassanger_ageGroup = data_test.AgeGroup\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_ageGroup)\nplt.title(\"data_test Passanger AgeGroup\",color = 'blue',fontsize=15)\nplt.show()","4b6f458f":"passanger_sibsp = data_train.SibSp\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_sibsp)\nplt.title(\"data_train Passanger SibSp\")\nplt.show()","f2f4b547":"passanger_sibsp = data_test.SibSp\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_sibsp)\nplt.title(\"data_test Passanger SibSp\")\nplt.show()","9aefd778":"passanger_parch = data_train.Parch\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_parch)\nplt.title(\"data_train Passanger Parch\")\nplt.show()","38236e79":"passanger_parch = data_test.Parch\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_parch)\nplt.title(\"data_test Passanger Parch\")\nplt.show()","a32163e9":"data_train.Fare.describe()","8cb74ab5":"passanger_fare = ['above100$' if i>=100 else '32between100$' if (i<100 and i>=32) else 'Free' if i==0 else 'below32$' for i in data_train.Fare]\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_fare)\nplt.title(\"data_train Passanger Fare\",color = 'blue',fontsize=15)\nplt.show()","722570cf":"data_test.Fare.describe()","fb52e177":"passanger_fare_test = ['above100$' if i>=100 else '35between100$' if (i<100 and i>=35) else 'Free' if i==0 else 'below35$' for i in data_test.Fare]\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_fare_test)\nplt.title(\"data_test Passanger Fare\",color = 'blue',fontsize=15)\nplt.show()","4b322025":"passanger_embarked = data_train.Embarked\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_embarked)\nplt.title(\"data_train Passanger Embarked\",color = 'blue',fontsize=15)\nplt.show()","601f8b6d":"passanger_embarked = data_test.Embarked\nplt.figure(figsize=(10,7))\nsns.countplot(passanger_embarked)\nplt.title(\"data_test Passanger Embarked\",color = 'blue',fontsize=15)\nplt.show()","3cbfbf01":"data_train.head()","f54308ac":"data_test.head()","c2edc90d":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\ndata_train['Title'] = data_train['Title'].map(title_mapping)\ndata_train['Title'] = data_train['Title'].fillna(0)\n\ndata_test['Title'] = data_test['Title'].map(title_mapping)\ndata_test['Title'] = data_test['Title'].fillna(0)\n\n#data_test.Title.head()\n#data_train.Title.head()","9ba12b28":"data_train.Sex = [0 if i==\"male\" else 1 for i in data_train.Sex]\ndata_test.Sex = [0 if i==\"male\" else 1 for i in data_test.Sex]\ndata_test.Sex.head()\ndata_train.Sex.head()","cd906636":"data_train['Age'] = data_train['Age'].fillna(0)\ndata_test['Age'] = data_test['Age'].fillna(0)\nprint(\"Missing train age value count:\",pd.isnull(data_test.Age).sum())\nprint(\"Missing test age value count:\",pd.isnull(data_train.Age).sum())","fa34743e":"title_mapping_age = {\"Baby\":1, \"Child\":2, \"Teenager\":3, \"Student\":4, \"Young Adult\":5, \"Adult\":6, \"Senior\":7, \"Unknow\":0}\ndata_train['AgeGroup'] = data_train['AgeGroup'].map(title_mapping_age)\ndata_train['AgeGroup'] = data_train['AgeGroup'].fillna(0)\ndata_test['AgeGroup'] = data_test['AgeGroup'].map(title_mapping_age)\ndata_test['AgeGroup'] = data_test['AgeGroup'].fillna(0)\n#data_test.AgeGroup.head()\n#data_train.AgeGroup.head()","d8f6fbbb":"#train\ndata_train['FamilySize'] = data_train['SibSp'] + data_train['Parch']\ndata_train['IsAlone'] = [0 if i==0 else 1 for i in data_train['FamilySize']]# 0 equals alone 1 equals family\ndata_train[\"CabinBool\"] = (data_train[\"Cabin\"].notnull().astype('int'))\ndata_train['FareBand'] = [4 if i=='above100$' else 3 if i=='32between100$' else 2 if i=='Free' else 1 for i in passanger_fare]\ndata_train.Embarked = [0 if i==\"S\" else 1 if i==\"C\" else 2 if i==\"Q\" else 0 for i in data_train.Embarked]\ndata_train['Embarked'] = data_train['Embarked'].fillna(0)\nprint(pd.isnull(data_train.Embarked).sum())\n\n#test\ndata_test['FamilySize'] = data_test['SibSp'] + data_test['Parch']\ndata_test['IsAlone'] = [0 if i==0 else 1 for i in data_test['FamilySize']]# 0 equals alone 1 equals family\ndata_test[\"CabinBool\"] = (data_test[\"Cabin\"].notnull().astype('int'))\ndata_test['FareBand'] = [4 if i=='above100$' else 3 if i=='35between100$' else 2 if i=='Free' else 1 for i in passanger_fare_test]\n\ndata_test.Embarked = [0 if i==\"S\" else 1 if i==\"C\" else 2 if i==\"Q\" else 0 for i in data_test.Embarked]\nprint(pd.isnull(data_test.Embarked).sum())\n\ndata_train.head()","88650767":"data_train_x = data_train.drop(['PassengerId','Survived','Name','Cabin','SibSp','Parch','Age','Fare','Ticket'],axis=1)\ndata_train_y = data_train.Survived\ndata_train_x.head()","866baa93":"data_test_x = data_test.drop(['PassengerId','Name','Cabin','SibSp','Parch','Age','Fare','Ticket'],axis=1)\ndata_test_x.head()","c0699440":"#normalization\ndata_train_x = (data_train_x - np.min(data_train_x))\/(np.max(data_train_x)-np.min(data_train_x)).values\ndata_train_x.head()","bb497c4f":"#normalization\ndata_test_x = (data_test_x - np.min(data_test_x))\/(np.max(data_test_x)-np.min(data_test_x)).values\ndata_test_x.head()","df13256f":"from sklearn.model_selection import train_test_split \nx_train, x_test, y_train, y_test = train_test_split(data_train_x,data_train_y,test_size=0.2,random_state=42)\ncolumn = [\"Logistic Regression\",\"KNN\",\"SVM\",\"Native Bayes\",\"Decision Tree\",\"Random Forest\"]\naccuracy_list = []\npredict_list = []","f696a2cd":"from sklearn.linear_model import LogisticRegression\nreg = LogisticRegression()\nreg.fit(x_train,y_train)\nprint(\"test accuracy {}\".format(reg.score(x_test,y_test)))\naccuracy_list.append(reg.score(x_test,y_test))","a6ffb79a":"#Estimated number of survivors\ny_pred = reg.predict(x_test)\ny_true = y_test\n\n#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2))\n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","042b0dd1":"from sklearn.neighbors import KNeighborsClassifier\n# find best k value \nscore_list = []\nfor each in range(1,15):\n    knn = KNeighborsClassifier(n_neighbors = each)\n    knn.fit(x_train,y_train)\n    score_list.append(knn.score(x_test,y_test))\n \nplt.figure(figsize=(10,7))\nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","6b2e4423":"knn = KNeighborsClassifier(n_neighbors = 8)\nknn.fit(x_train,y_train)\nprint(knn.score(x_test,y_test))\naccuracy_list.append(knn.score(x_test,y_test))","5c6f5909":"#Estimated number of survivors\ny_pred = knn.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2))\n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","454ae636":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)\nprint(\"print accuracy of svm algo: \",svm.score(x_test,y_test))\naccuracy_list.append(svm.score(x_test,y_test))","8a6dad4d":"#Estimated number of survivors\ny_pred = svm.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2))\n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","15cc873c":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint(\"print accuracy of naive bayes algo: \",nb.score(x_test,y_test))\naccuracy_list.append(nb.score(x_test,y_test))","6f2741d1":"#Estimated number of survivors\ny_pred = nb.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2)) \n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","b2176e24":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprint(\"score: \", dt.score(x_test,y_test))\naccuracy_list.append(dt.score(x_test,y_test))","f61fdf84":"#Estimated number of survivors\ny_pred = dt.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2))\n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","bdec617c":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 200,random_state = 42)\nrf.fit(x_train,y_train)\nprint(rf.score(x_test,y_test))\naccuracy_list.append(rf.score(x_test,y_test))","958d3cd7":"#Estimated number of survivors\ny_pred = rf.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\npredict_list.append(cm.item(0)+cm.item(2))\n\n#cm visualization\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","1646bb33":"#Classifier Accuracy\nf,ax = plt.subplots(figsize = (15,7))\nsns.barplot(x=accuracy_list,y=column,palette = sns.cubehelix_palette(len(accuracy_list)))\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Classifier\")\nplt.title('Classifier Accuracy')\nplt.show()","a4ae83c5":"#Classifier Predict Survived Count\nf,ax = plt.subplots(figsize = (15,7))\nsns.barplot(x=predict_list,y=column,palette = sns.cubehelix_palette(len(accuracy_list)))\nplt.xlabel(\"Predict Survived Count\")\nplt.ylabel(\"Classifier\")\nplt.title('Classifier Predict Survived Count')\nplt.show()","3bdc3f6c":"#set ids as PassengerId and predict survival \nids = data_test['PassengerId']\npredict = knn.predict(data_test_x)\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predict})\noutput.to_csv('submission.csv', index=False)\n","e02f0d0f":"I've given a number to classify.","1fe58883":"<a id=\"3.2\"><\/a>\n### K-Nearest Neighbour (KNN) Algorithm","c58dc702":"<a id=\"3.6\"><\/a> \n### Random Forest Algorithm","fc851fda":"I've splitted according to prefix of name. I've added them becoming a new column. ","d2ae4c67":"I've created age groups. I've added them becoming a new column. ","33cae479":"<a id=\"1\"><\/a>\n### 1. Exploratory Data Analysis","9a7dba14":"<a id=2><\/a>\n### Cleaning Data","fb4ca91f":"## Survived Predict with Classification Algorithms\n\nHello :) I'm recently learning data science and machine learning algorithms. I'm working making practice what I learn. I used python language and Titanic Disaster dataset. I hope it's benefit for you. Please consider upvoting if this is useful to you! :) \n\n### CONTENTS:\n[1. Exploratory Data Analysis](#1) <br\/>\n[2. Cleaning Data](#2) <br\/>\n[3. Classification Algorithms](#3) <br\/>\n&nbsp;&nbsp;&nbsp; [A. Logistic Regression Algorithm](#3.1) <br\/>\n&nbsp;&nbsp;&nbsp; [B. K-Nearest Neighbour (KNN) Algorithm](#3.2) <br\/>\n&nbsp;&nbsp;&nbsp; [C. Support Vector Machine (SVM) Algorithm](#3.3) <br\/>\n&nbsp;&nbsp;&nbsp; [D. Naive Bayes Algorithm](#3.4) <br\/>\n&nbsp;&nbsp;&nbsp; [E. Decision Tree Algorithm](#3.5) <br\/>\n&nbsp;&nbsp;&nbsp; [F. Random Forest Algorithm](#3.6) <br\/>\n&nbsp;&nbsp;&nbsp; [G. Evaluation Classification Models](#3.7) <br\/>","bbbfc2ac":"<a id=\"3.7\"><\/a>\n### Evaluation Classification Models","0816adaa":"<a id=\"3.4\"><\/a>\n### Naive Bayes Algorithm","0ee2a583":"<a id=3.1><\/a>\n###  Logistic Regression Algorithm","eff428da":"<a id=\"3.3\"><\/a>\n### Support Vector Machine (SVM) Algorithm","7a560f3a":"I found passengers, which joined with their family or alone, by picking up counts of sibsp and parch.","9e624744":"<a id=\"3.5\"><\/a>\n### Decision Tree Algorithm"}}