{"cell_type":{"92ba7fa1":"code","b43206ec":"code","23977eaa":"code","968cce5c":"code","4cbe4066":"code","4afc0e74":"code","fde894aa":"code","b7cdff6b":"code","28b83ae2":"code","e54ceb0d":"code","7759306c":"code","983ac2bb":"code","c41e05fe":"code","aeb7b00a":"code","3c17466c":"code","3d534910":"code","d52adc97":"code","a79c4449":"code","c398860c":"code","2a66e46c":"code","741424eb":"code","51583a30":"code","e5c80138":"code","a80d12f2":"code","b0702369":"code","f0a2c56c":"code","f417a448":"code","53a96e0b":"code","a4f14d97":"code","cd9d3224":"code","6ff1b85b":"code","146c0893":"code","11746908":"code","9b9c6a68":"code","fb45e95b":"code","d86563cf":"code","9707d5cd":"code","1d697431":"code","a1922d12":"code","193bca9c":"code","61278325":"code","cfaddeb0":"code","42d89135":"code","9af0a95c":"code","6dfac0bc":"code","df2d36ee":"code","cdb17602":"code","2cdfd3c2":"code","af4d4aa6":"markdown","8f3d4cf0":"markdown","1257f382":"markdown","8e9cf936":"markdown","cf0792a8":"markdown"},"source":{"92ba7fa1":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC  \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport missingno\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b43206ec":"traindata = pd.read_csv(\"..\/input\/mymusicalpref\/train.csv\")\ntestdata = pd.read_csv(\"..\/input\/mymusicalpref\/test.csv\")\n\nmusic_dataset = pd.concat([traindata, testdata]).reset_index(drop=True)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = ['#2596be',\"#e28743\",\"#80391e\"]\nsns.palplot(palette)","23977eaa":"music_dataset.head()","968cce5c":"music_dataset.size","4cbe4066":"missingno.bar(music_dataset, color=palette, figsize=(30,6))","4afc0e74":"testdata.columns = [i.strip() for i in testdata.columns]\ntraindata.columns = [i.strip() for i in traindata.columns]","fde894aa":"print(testdata.columns)","b7cdff6b":"print(traindata.columns)","28b83ae2":"raw1 = traindata.drop(['Id'],axis=1)","e54ceb0d":"raw1.info()","7759306c":"testdata.info()","983ac2bb":"raw1.describe()","c41e05fe":"raw2 = raw1.drop(['Album_type','Version'],axis=1)\ntestdata=testdata.drop(['Album_type','Version'],axis=1)\ntestdata['Vocal'].fillna('N',inplace=True)\nraw2 = raw2.reset_index(drop=True)","aeb7b00a":"raw3 = raw2.dropna()\nraw3","3c17466c":"print(raw3.columns.values)","3d534910":"resort_columns=['Category','Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nresort_columns_t=['Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nraw4=raw3[resort_columns]\ntestdata=testdata[resort_columns_t]","d52adc97":"y_train=raw4['Category']\nraw4=pd.concat([raw4.drop(['Category'],axis=1),testdata],axis=0)","a79c4449":"print('Artists:',len(raw4['Artists'].unique()))\nprint('Track:',len(raw4['Track'].unique()))\nprint('Key:',len(raw4['Key'].unique()))\nprint('Artists_Genres:',len(raw4['Artists_Genres'].unique()))\nprint('Vocal:',raw4['Vocal'].unique())\nprint('Country:',len(raw4['Country'].unique()))","c398860c":"print(raw4['Track'].value_counts())\nprint(raw4['Artists'].value_counts())\nprint(raw4['Vocal'].value_counts())","2a66e46c":"raw4 = raw4.drop(['Track'],axis=1)","741424eb":"raw4[\"isMajor\"], raw4[\"Key\"] = raw4[\"Key\"].apply(lambda x: x.split(\" \")[1]), raw4[\"Key\"].apply(lambda x: x.split(\" \")[0])\nraw4.loc[:,\"Key\"] = raw4[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\nraw4.loc[:,\"isMajor\"] = (raw4[\"isMajor\"]==\"Major\").astype(int)","51583a30":"keydum = pd.get_dummies(raw4[\"Key\"])\nkeydum = keydum.reset_index(drop=True)","e5c80138":"def key2dum(key):\n    list_h=[]\n    list_l=[]\n    list_M=[]\n    for i in range(len(key)):\n        if '#' in key[i]:\n            list_h.extend([1])\n        else:\n            list_h.extend([0])\n        if '\u266d' in key[i]:\n            list_l.extend([1])\n        else:\n            list_l.extend([0])\n        # see major or not\n        if 'Major' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n    dummydummy=pd.DataFrame({'#':list_h,'b':list_l,'Major or not':list_M})   \n    return dummydummy","a80d12f2":"raw4 = raw4.reset_index(drop=True)\nkeydum = key2dum(raw4['Key'])\nkeydum","b0702369":"raw4 = raw4.reset_index(drop=True)\ndef voc2dum(key):\n    list_F=[]\n    list_M=[]\n    list_N=[]\n    for i in range(len(key)):\n        if 'F' in key[i]:\n            list_F.extend([1])\n        else:\n            list_F.extend([0])\n        # see major or not\n        if 'M' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n        if 'N' in key[i]:\n            list_N.extend([1])\n        else:\n            list_N.extend([0])\n    dummydummy=pd.DataFrame({'VF':list_F,'VM':list_M,'VM':list_N})   \n    return dummydummy","f0a2c56c":"vocdum=voc2dum(raw4['Vocal'])\nvocdum","f417a448":"unique = []\nfor i in raw4.index:\n    unique.extend(raw4.loc[i,'Artists_Genres'].split(\"|\"))\n\nSuni = pd.Series(unique)\nprint(len(Suni.unique()))\nSuni = Suni.unique()","53a96e0b":"def style2dum(form,col):\n    data=np.zeros((len(col),len(form)))\n    for i in range(len(form)):\n        for j in range(len(col)):\n            if form[i] in col[j]:\n                data[j][i]=1\n    quasidum = pd.DataFrame(data )\n    return quasidum","a4f14d97":"stydum = style2dum(Suni,raw4['Artists_Genres'])\nstydum.columns = Suni\nstydum.columns","cd9d3224":"stydum","6ff1b85b":"den = stydum.sum(axis=1)\nimport math\n\nfor i in range(946):\n    for j in Suni:\n        stydum.loc[i,j]\/=math.sqrt(den[i])","146c0893":"embedding = TSNE(n_components = 2, init = \"pca\")\nesd = embedding.fit_transform(stydum)\nesd = pd.DataFrame(esd, columns = [\"sty_tsne1\",\"sty_tsne2\"])","11746908":"extdum = pd.get_dummies(raw4['Country'])\nembedding1 = TSNE(n_components=2, init=\"pca\")\nesd1 = embedding1.fit_transform(extdum)\nesd1 = pd.DataFrame(esd1,columns=[\"con_tsne1\",\"con_tsne2\"])\n","9b9c6a68":"namedum = pd.get_dummies(raw4['Artists'])\nembedding2 = TSNE(n_components=3, init=\"pca\")\nesd2 = embedding1.fit_transform(namedum)\nesd2 = pd.DataFrame(esd1,columns=[\"name_tsne1\",\"name_tsne2\"])","fb45e95b":"raw5 = pd.concat([raw4,esd,esd1,vocdum,keydum],axis=1)\nraw5 = raw5.drop(['Artists_Genres','Key','Vocal','Country','Artists','Album','Labels'],axis = 1)\nraw5","d86563cf":"scaler = MinMaxScaler()\nscaler.fit(raw5)\n\nraw5 = pd.DataFrame(data=scaler.transform(raw5),columns = raw5.columns,index=raw5.index)\n\nraw5.to_csv('clean_data.csv',index=0)\n\nX_train=raw5[raw5.index<len(y_train)]\nX_test =raw5[raw5.index>=len(y_train)]\n\nXt_train, Xt_test, yt_train, yt_test = train_test_split(X_train, y_train, test_size = 0.20,random_state=5467)","9707d5cd":"svclassifier = SVC(kernel='poly')\nfitted = svclassifier.fit(Xt_train, yt_train)\ny_pred = svclassifier.predict(Xt_test)\n\nsvclassifierl = SVC(kernel='linear')\nfittedl = svclassifierl.fit(Xt_train, yt_train)\ny_predl = svclassifierl.predict(Xt_test)","1d697431":"KN = KNeighborsClassifier()\nKN.fit(Xt_train,yt_train)\nKN_pred = KN.predict(Xt_test)","a1922d12":"rf = RandomForestClassifier()\nrf.fit(Xt_train,yt_train)\nrf_pred = rf.predict(Xt_test)","193bca9c":"gd = GradientBoostingClassifier()\ngd.fit(Xt_train,yt_train)\ngd_pred = gd.predict(Xt_test)","61278325":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(Xt_train,yt_train)\ntree_pred = decision_tree.predict(Xt_test)","cfaddeb0":"regr = LogisticRegression() \nregr.fit(Xt_train, yt_train)\nLog_pred = regr.predict(Xt_test)","42d89135":"print('Logistic_Regression:',accuracy_score(yt_test, Log_pred)*100,'%')\nprint('Decision Tree:', accuracy_score(yt_test, tree_pred)*100,'%') # to summarize all\nprint('Random Forest:', accuracy_score(yt_test, rf_pred)*100,'%')\nprint('Gradient Boost:', accuracy_score(yt_test, gd_pred)*100,'%')\nprint('KNeighbors:',accuracy_score(yt_test, KN_pred)*100,'%')\nprint('SVM_p:',accuracy_score(yt_test, y_pred)*100,'%')\nprint('SVM_l:',accuracy_score(yt_test, y_predl)*100,'%')","9af0a95c":"gd_scored = cross_val_score(gd,X_train,y_train,cv=5)\nprint(gd_scored)\nprint(confusion_matrix(yt_test,gd_pred))\nprint(classification_report(yt_test,gd_pred))","6dfac0bc":"rf_scored=cross_val_score(rf,X_train,y_train,cv=5)\nprint(rf_scored)\nprint(confusion_matrix(yt_test,rf_pred))\nprint(classification_report(yt_test,rf_pred))","df2d36ee":"final_pred = gd.predict(X_test)\nfinal_pred","cdb17602":"final_pred=pd.DataFrame({'Id':np.linspace(665,964,300,dtype=np.int16),'Category':final_pred})\nfinal_pred.to_csv('submission.csv',index=0)","2cdfd3c2":"final_pred.head()","af4d4aa6":"We can see that Random Forest and Gradient Boost. Let's go to see how good they are more precisely.\n","8f3d4cf0":"The same song with different key or other things is a problem \\\nWe assume that the name is less important than the other features, so we'll just drop it.","1257f382":"Then first I will make a linear model for testing, that is, assume that the effects are linearly added.","8e9cf936":"Listing all unique Artists_Genres","cf0792a8":"We decide to drop irrelated columns, after that we will delete all line with null-value "}}