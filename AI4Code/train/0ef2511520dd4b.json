{"cell_type":{"0b2f286e":"code","792b63dd":"code","2447739a":"code","5284ea35":"code","142673a8":"code","5aeb4ae6":"code","efec6877":"code","81900f0f":"code","659bbeb9":"code","1a494986":"code","4307a247":"code","de6aebac":"code","5611bc89":"markdown","3dff42fa":"markdown"},"source":{"0b2f286e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tpot import TPOTRegressor\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom dateutil import relativedelta\nimport dask\nimport time\nimport re","792b63dd":"df = pd.read_excel('..\/input\/timeseries-data\/Data.xlsx')","2447739a":"df=df[['Date','Key','Volume','avg_T','precipitation']]","5284ea35":"df.columns","142673a8":"#holiday variables....\ndf.Date = pd.to_datetime(df.Date,format='%d-%m-%Y')\n#Brand_list = df.Key.unique()\nBrand_list = ['B','C']","5aeb4ae6":"df.dropna(inplace=True)","efec6877":"final = pd.DataFrame()\nfor brand_name in Brand_list:\n    start_time = time.time()\n    print(\"start_time\",time.time())\n    print(brand_name)\n    brand_df = df.loc[df.Key == brand_name]\n    brand_df.set_index('Date',inplace=True)\n    brand_df = brand_df[:'2019-12-01']\n    tmp = []\n    forecast = pd.DataFrame()\n    Actuals = pd.DataFrame()\n    for i in range(7,0,-1):\n        train_date = brand_df.index.max() - relativedelta.relativedelta(months=i)\n        test_date = train_date + relativedelta.relativedelta(months=1)\n\n        x = brand_df.drop(columns=['Volume','Key'])\n        y = brand_df[['Volume']]\n        train_x = x[:train_date]\n        train_y = y[:train_date][['Volume']]\n        test_x = x[test_date:]\n        test_y = y[test_date:][['Volume']]\n        \n        model = TPOTRegressor(n_jobs=-1,verbosity=2,max_time_mins=2)\n        model.fit(np.array(train_x),np.array(train_y))\n#         #forecast for next month....\n        forecast[str(brand_name)+str('_')+str(test_date.month)] = model.predict(np.array(test_x[test_date:test_date])).reshape(1,)\n        Actuals[str(brand_name)+str('_')+str(test_date.month)] = test_y[test_date:test_date].values[0]\n        print(\"Elasped_time\",time.time() - start_time)\n        \n    if (len(forecast)>0 & len(Actuals>0)):\n        forecast=forecast.T.reset_index()\n        forecast.columns=[\"Brand\",\"Forecast_values\"]\n        Actuals=Actuals.T.reset_index()\n        Actuals.columns=[\"Brand\",\"Actual_values\"]\n        brand_wise_merge = forecast.merge(Actuals,on=\"Brand\",how=\"left\")\n        final = final.append(brand_wise_merge,ignore_index=True)\n    else:\n        print(\"doesn't match with TPOT\")","81900f0f":"plt.figure(figsize=(15,8))\nplt.plot(final.Actual_values,label='Actual value')\nplt.plot(final.Forecast_values,label='Forecasted value')\nplt.legend()\nplt.show()","659bbeb9":"final['Error']=np.abs(final['Forecast_values']-final['Actual_values'])\nfinal[['Brandname','leMonth']] = final.Brand.str.split(\"_\",expand=True)\nfinal","1a494986":"Agg_accuracy = final.groupby(by=['leMonth']).sum()[['Error','Actual_values']]\nAgg_accuracy['Accuracy'] = np.round((1-(Agg_accuracy['Error']\/Agg_accuracy['Actual_values']))*100,2)\nAgg_accuracy","4307a247":"Agg_accuracy_brand = final.groupby(by=['leMonth','Brandname']).sum()[['Error','Actual_values']]\nAgg_accuracy_brand['Accuracy'] = np.round((1-(Agg_accuracy_brand['Error']\/Agg_accuracy_brand['Actual_values']))*100,2)\nAgg_accuracy_brand","de6aebac":"final.to_excel('TPOT_Forecast.xlsx')","5611bc89":"For modelling we follow differnt steps:\n\n1. iterate over all brands and take out single brand each time.\n2. provide train and test date based on requirement.\n3. divide train and test data as le cycle works for whole year. ex apr is start so (3+9,4+8 etc..) each 4. time upto december we have to complete, start date could be any.\n5. Select all those indepent regressor\n6. Set the hyperparameter as max time to run. currently i used 2 min but as if you increase time, it will work around n number of algorithms and gives optimal one,but need high computational power\n7. save the result and iterate till end.","3dff42fa":"The Tree-Based Pipeline Optimization Tool (**TPOT**) was one of the very first AutoML methods and open-source software packages developed for the data science community"}}