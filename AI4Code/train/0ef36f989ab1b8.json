{"cell_type":{"ac3ad245":"code","9f36da2c":"code","10133361":"code","03ca9aab":"code","14b92597":"code","4fb40f2a":"code","d6b70d71":"code","ca063ce1":"code","c12f97cb":"code","ef1e3780":"code","40a2887a":"code","4caba0a5":"code","82ef3816":"code","1b98a257":"code","3caa62b4":"code","95635f39":"code","40c45342":"code","cbfdda0b":"code","a3176e13":"code","635978ae":"code","3e8750a6":"code","618954d5":"code","bdb06662":"code","66b410dd":"code","51bcc545":"code","58c27a25":"code","c08694aa":"code","600136b3":"code","eb4f2afc":"code","0b3a1513":"code","9adf9295":"code","cd016640":"code","24696332":"code","22973f84":"code","a6a16425":"code","a087e9b6":"code","8340d9df":"code","82c8562b":"code","2dff5c91":"code","f21df820":"code","31dfabde":"code","c5fdcc22":"markdown","b5a9ca5b":"markdown","d521a803":"markdown","5765cfde":"markdown","6f4d6aeb":"markdown","6ac85cac":"markdown","2a30787f":"markdown","67f07951":"markdown","4d9fdb7d":"markdown","7c3934da":"markdown","f9b8f005":"markdown"},"source":{"ac3ad245":"import numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import rankdata\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nN_Splits = 25\nSEED = 2020","9f36da2c":"train = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/test.csv')\ntest.insert(1, 'target', 0)","10133361":"features = [_f for _f in train if _f not in ['id', 'target']]\n\ndef factor_encoding(train, test):\n    \n    assert sorted(train.columns) == sorted(test.columns)\n    \n    full = pd.concat([train, test], axis=0, sort=False)\n    # Factorize everything\n    for f in full:\n        full[f], _ = pd.factorize(full[f])\n        full[f] += 1  # make sure no negative\n        \n    return full.iloc[:train.shape[0]], full.iloc[train.shape[0]:]\n\ntrain_f, test_f = factor_encoding(train[features], test[features])","03ca9aab":"class LibFFMEncoder(object):\n    def __init__(self):\n        self.encoder = 1\n        self.encoding = {}\n\n    def encode_for_libffm(self, row):\n        txt = f\"{row[0]}\"\n        for i, r in enumerate(row[1:]):\n            try:\n                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n            except KeyError:\n                self.encoding[(i, r)] = self.encoder\n                self.encoder += 1\n                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n\n        return txt\n\n# Create files for testing and OOF\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfold_ids = [\n    [trn_, val_] for (trn_, val_) in StratifiedKFold(N_Splits,True,SEED).split(train, train['target'])\n]\nfor fold_, (trn_, val_) in enumerate(fold_ids):\n\n    # Fit the encoder\n    encoder = LibFFMEncoder()\n    libffm_format_trn = pd.concat([train['target'].iloc[trn_], train_f.iloc[trn_]], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n    )\n    # Encode validation set\n    libffm_format_val = pd.concat([train['target'].iloc[val_], train_f.iloc[val_]], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n    )\n    libffm_format_tst = pd.concat([test['target'], test_f], axis=1).apply(\n        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n    )\n    print(train['target'].iloc[trn_].shape, train['target'].iloc[val_].shape, libffm_format_tst.shape)\n    \n    libffm_format_trn.to_csv(f'libffm_trn_fold_{fold_+1}.txt', index=False, header=False)\n    libffm_format_val.to_csv(f'libffm_val_fold_{fold_+1}.txt', index=False, header=False)\n    libffm_format_tst.to_csv(f'libffm_tst_fold_{fold_+1}.txt', index=False, header=False)\n\n    \n\n","14b92597":"!cp \/kaggle\/input\/libffm-binaries\/ffm-train .\n!cp \/kaggle\/input\/libffm-binaries\/ffm-predict .\n!chmod u+x ffm-train\n!chmod u+x ffm-predict","4fb40f2a":"from sklearn.metrics import log_loss, roc_auc_score\n\n!.\/ffm-train -p libffm_val_fold_1.txt -r 0.05 -l 0.0002 -k 50 --auto-stop libffm_trn_fold_1.txt libffm_fold_1_model\n!.\/ffm-predict libffm_val_fold_1.txt libffm_fold_1_model val_preds_fold_1.txt\n!.\/ffm-predict libffm_tst_fold_1.txt libffm_fold_1_model tst_preds_fold_1.txt\nos.remove('libffm_val_fold_1.txt')\nos.remove('libffm_trn_fold_1.txt')\nos.remove('libffm_fold_1_model')\nos.remove('libffm_tst_fold_1.txt')\n\n(\n    log_loss(train['target'].iloc[fold_ids[0][1]], pd.read_csv('val_preds_fold_1.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[0][1]], pd.read_csv('val_preds_fold_1.txt', header=None).values[:,0])\n)\n","d6b70d71":"!.\/ffm-train -p libffm_val_fold_2.txt -r 0.05 -l 0.00002 -k 50  --auto-stop libffm_trn_fold_2.txt libffm_fold_2_model\n!.\/ffm-predict libffm_val_fold_2.txt libffm_fold_2_model val_preds_fold_2.txt\n!.\/ffm-predict libffm_tst_fold_2.txt libffm_fold_2_model tst_preds_fold_2.txt\nos.remove('libffm_val_fold_2.txt')\nos.remove('libffm_trn_fold_2.txt')\nos.remove('libffm_fold_2_model')\nos.remove('libffm_tst_fold_2.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[1][1]], pd.read_csv('val_preds_fold_2.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[1][1]], pd.read_csv('val_preds_fold_2.txt', header=None).values[:,0])\n)\n","ca063ce1":"!.\/ffm-train -p libffm_val_fold_3.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_3.txt libffm_fold_3_model\n!.\/ffm-predict libffm_val_fold_3.txt libffm_fold_3_model val_preds_fold_3.txt\n!.\/ffm-predict libffm_tst_fold_3.txt libffm_fold_3_model tst_preds_fold_3.txt\nos.remove('libffm_val_fold_3.txt')\nos.remove('libffm_trn_fold_3.txt')\nos.remove('libffm_fold_3_model')\nos.remove('libffm_tst_fold_3.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[2][1]], pd.read_csv('val_preds_fold_3.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[2][1]], pd.read_csv('val_preds_fold_3.txt', header=None).values[:,0])\n)\n","c12f97cb":"!.\/ffm-train -p libffm_val_fold_4.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_4.txt libffm_fold_4_model\n!.\/ffm-predict libffm_val_fold_4.txt libffm_fold_4_model val_preds_fold_4.txt\n!.\/ffm-predict libffm_tst_fold_4.txt libffm_fold_4_model tst_preds_fold_4.txt\nos.remove('libffm_val_fold_4.txt')\nos.remove('libffm_trn_fold_4.txt')\nos.remove('libffm_fold_4_model')\nos.remove('libffm_tst_fold_4.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[3][1]], pd.read_csv('val_preds_fold_4.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[3][1]], pd.read_csv('val_preds_fold_4.txt', header=None).values[:,0])\n)\n","ef1e3780":"!.\/ffm-train -p libffm_val_fold_5.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_5.txt libffm_fold_5_model\n!.\/ffm-predict libffm_val_fold_5.txt libffm_fold_5_model val_preds_fold_5.txt\n!.\/ffm-predict libffm_tst_fold_5.txt libffm_fold_5_model tst_preds_fold_5.txt\nos.remove('libffm_val_fold_5.txt')\nos.remove('libffm_trn_fold_5.txt')\nos.remove('libffm_fold_5_model')\nos.remove('libffm_tst_fold_5.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[4][1]], pd.read_csv('val_preds_fold_5.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[4][1]], pd.read_csv('val_preds_fold_5.txt', header=None).values[:,0])\n)\n","40a2887a":"!.\/ffm-train -p libffm_val_fold_6.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_6.txt libffm_fold_6_model\n!.\/ffm-predict libffm_val_fold_6.txt libffm_fold_6_model val_preds_fold_6.txt\n!.\/ffm-predict libffm_tst_fold_6.txt libffm_fold_6_model tst_preds_fold_6.txt\nos.remove('libffm_val_fold_6.txt')\nos.remove('libffm_trn_fold_6.txt')\nos.remove('libffm_fold_6_model')\nos.remove('libffm_tst_fold_6.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[5][1]], pd.read_csv('val_preds_fold_6.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[5][1]], pd.read_csv('val_preds_fold_6.txt', header=None).values[:,0])\n)\n","4caba0a5":"!.\/ffm-train -p libffm_val_fold_7.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_7.txt libffm_fold_7_model\n!.\/ffm-predict libffm_val_fold_7.txt libffm_fold_7_model val_preds_fold_7.txt\n!.\/ffm-predict libffm_tst_fold_7.txt libffm_fold_7_model tst_preds_fold_7.txt\nos.remove('libffm_val_fold_7.txt')\nos.remove('libffm_trn_fold_7.txt')\nos.remove('libffm_fold_7_model')\nos.remove('libffm_tst_fold_7.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[6][1]], pd.read_csv('val_preds_fold_7.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[6][1]], pd.read_csv('val_preds_fold_7.txt', header=None).values[:,0])\n)\n","82ef3816":"!.\/ffm-train -p libffm_val_fold_8.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_8.txt libffm_fold_8_model\n!.\/ffm-predict libffm_val_fold_8.txt libffm_fold_8_model val_preds_fold_8.txt\n!.\/ffm-predict libffm_tst_fold_8.txt libffm_fold_8_model tst_preds_fold_8.txt\nos.remove('libffm_val_fold_8.txt')\nos.remove('libffm_trn_fold_8.txt')\nos.remove('libffm_fold_8_model')\nos.remove('libffm_tst_fold_8.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[7][1]], pd.read_csv('val_preds_fold_8.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[7][1]], pd.read_csv('val_preds_fold_8.txt', header=None).values[:,0])\n)\n","1b98a257":"!.\/ffm-train -p libffm_val_fold_9.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_9.txt libffm_fold_9_model\n!.\/ffm-predict libffm_val_fold_9.txt libffm_fold_9_model val_preds_fold_9.txt\n!.\/ffm-predict libffm_tst_fold_9.txt libffm_fold_9_model tst_preds_fold_9.txt\nos.remove('libffm_val_fold_9.txt')\nos.remove('libffm_trn_fold_9.txt')\nos.remove('libffm_fold_9_model')\nos.remove('libffm_tst_fold_9.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[8][1]], pd.read_csv('val_preds_fold_9.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[8][1]], pd.read_csv('val_preds_fold_9.txt', header=None).values[:,0])\n)\n","3caa62b4":"!.\/ffm-train -p libffm_val_fold_10.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_10.txt libffm_fold_10_model\n!.\/ffm-predict libffm_val_fold_10.txt libffm_fold_10_model val_preds_fold_10.txt\n!.\/ffm-predict libffm_tst_fold_10.txt libffm_fold_10_model tst_preds_fold_10.txt\nos.remove('libffm_val_fold_10.txt')\nos.remove('libffm_trn_fold_10.txt')\nos.remove('libffm_fold_10_model')\nos.remove('libffm_tst_fold_10.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[9][1]], pd.read_csv('val_preds_fold_10.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[9][1]], pd.read_csv('val_preds_fold_10.txt', header=None).values[:,0])\n)\n","95635f39":"!.\/ffm-train -p libffm_val_fold_11.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_11.txt libffm_fold_11_model\n!.\/ffm-predict libffm_val_fold_11.txt libffm_fold_11_model val_preds_fold_11.txt\n!.\/ffm-predict libffm_tst_fold_11.txt libffm_fold_11_model tst_preds_fold_11.txt\nos.remove('libffm_val_fold_11.txt')\nos.remove('libffm_trn_fold_11.txt')\nos.remove('libffm_fold_11_model')\nos.remove('libffm_tst_fold_11.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[10][1]], pd.read_csv('val_preds_fold_11.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[10][1]], pd.read_csv('val_preds_fold_11.txt', header=None).values[:,0])\n)\n","40c45342":"!.\/ffm-train -p libffm_val_fold_12.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_12.txt libffm_fold_12_model\n!.\/ffm-predict libffm_val_fold_12.txt libffm_fold_12_model val_preds_fold_12.txt\n!.\/ffm-predict libffm_tst_fold_12.txt libffm_fold_12_model tst_preds_fold_12.txt\nos.remove('libffm_val_fold_12.txt')\nos.remove('libffm_trn_fold_12.txt')\nos.remove('libffm_fold_12_model')\nos.remove('libffm_tst_fold_12.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[11][1]], pd.read_csv('val_preds_fold_12.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[11][1]], pd.read_csv('val_preds_fold_12.txt', header=None).values[:,0])\n)\n","cbfdda0b":"!.\/ffm-train -p libffm_val_fold_13.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_13.txt libffm_fold_13_model\n!.\/ffm-predict libffm_val_fold_13.txt libffm_fold_13_model val_preds_fold_13.txt\n!.\/ffm-predict libffm_tst_fold_13.txt libffm_fold_13_model tst_preds_fold_13.txt\nos.remove('libffm_val_fold_13.txt')\nos.remove('libffm_trn_fold_13.txt')\nos.remove('libffm_fold_13_model')\nos.remove('libffm_tst_fold_13.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[12][1]], pd.read_csv('val_preds_fold_13.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[12][1]], pd.read_csv('val_preds_fold_13.txt', header=None).values[:,0])\n)\n","a3176e13":"!.\/ffm-train -p libffm_val_fold_14.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_14.txt libffm_fold_14_model\n!.\/ffm-predict libffm_val_fold_14.txt libffm_fold_14_model val_preds_fold_14.txt\n!.\/ffm-predict libffm_tst_fold_14.txt libffm_fold_14_model tst_preds_fold_14.txt\nos.remove('libffm_val_fold_14.txt')\nos.remove('libffm_trn_fold_14.txt')\nos.remove('libffm_fold_14_model')\nos.remove('libffm_tst_fold_14.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[13][1]], pd.read_csv('val_preds_fold_14.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[13][1]], pd.read_csv('val_preds_fold_14.txt', header=None).values[:,0])\n)\n","635978ae":"!.\/ffm-train -p libffm_val_fold_15.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_15.txt libffm_fold_15_model\n!.\/ffm-predict libffm_val_fold_15.txt libffm_fold_15_model val_preds_fold_15.txt\n!.\/ffm-predict libffm_tst_fold_15.txt libffm_fold_15_model tst_preds_fold_15.txt\nos.remove('libffm_val_fold_15.txt')\nos.remove('libffm_trn_fold_15.txt')\nos.remove('libffm_fold_15_model')\nos.remove('libffm_tst_fold_15.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[14][1]], pd.read_csv('val_preds_fold_15.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[14][1]], pd.read_csv('val_preds_fold_15.txt', header=None).values[:,0])\n)\n","3e8750a6":"!.\/ffm-train -p libffm_val_fold_16.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_16.txt libffm_fold_16_model\n!.\/ffm-predict libffm_val_fold_16.txt libffm_fold_16_model val_preds_fold_16.txt\n!.\/ffm-predict libffm_tst_fold_16.txt libffm_fold_16_model tst_preds_fold_16.txt\nos.remove('libffm_val_fold_16.txt')\nos.remove('libffm_trn_fold_16.txt')\nos.remove('libffm_fold_16_model')\nos.remove('libffm_tst_fold_16.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[15][1]], pd.read_csv('val_preds_fold_16.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[15][1]], pd.read_csv('val_preds_fold_16.txt', header=None).values[:,0])\n)\n","618954d5":"!.\/ffm-train -p libffm_val_fold_17.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_17.txt libffm_fold_17_model\n!.\/ffm-predict libffm_val_fold_17.txt libffm_fold_17_model val_preds_fold_17.txt\n!.\/ffm-predict libffm_tst_fold_17.txt libffm_fold_17_model tst_preds_fold_17.txt\nos.remove('libffm_val_fold_17.txt')\nos.remove('libffm_trn_fold_17.txt')\nos.remove('libffm_fold_17_model')\nos.remove('libffm_tst_fold_17.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[16][1]], pd.read_csv('val_preds_fold_17.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[16][1]], pd.read_csv('val_preds_fold_17.txt', header=None).values[:,0])\n)\n","bdb06662":"!.\/ffm-train -p libffm_val_fold_18.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_18.txt libffm_fold_18_model\n!.\/ffm-predict libffm_val_fold_18.txt libffm_fold_18_model val_preds_fold_18.txt\n!.\/ffm-predict libffm_tst_fold_18.txt libffm_fold_18_model tst_preds_fold_18.txt\nos.remove('libffm_val_fold_18.txt')\nos.remove('libffm_trn_fold_18.txt')\nos.remove('libffm_fold_18_model')\nos.remove('libffm_tst_fold_18.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[17][1]], pd.read_csv('val_preds_fold_18.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[17][1]], pd.read_csv('val_preds_fold_18.txt', header=None).values[:,0])\n)\n\n","66b410dd":"!.\/ffm-train -p libffm_val_fold_19.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_19.txt libffm_fold_19_model\n!.\/ffm-predict libffm_val_fold_19.txt libffm_fold_19_model val_preds_fold_19.txt\n!.\/ffm-predict libffm_tst_fold_19.txt libffm_fold_19_model tst_preds_fold_19.txt\nos.remove('libffm_val_fold_19.txt')\nos.remove('libffm_trn_fold_19.txt')\nos.remove('libffm_fold_19_model')\nos.remove('libffm_tst_fold_19.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[18][1]], pd.read_csv('val_preds_fold_19.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[18][1]], pd.read_csv('val_preds_fold_19.txt', header=None).values[:,0])\n)\n\n","51bcc545":"!.\/ffm-train -p libffm_val_fold_20.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_20.txt libffm_fold_20_model\n!.\/ffm-predict libffm_val_fold_20.txt libffm_fold_20_model val_preds_fold_20.txt\n!.\/ffm-predict libffm_tst_fold_20.txt libffm_fold_20_model tst_preds_fold_20.txt\nos.remove('libffm_val_fold_20.txt')\nos.remove('libffm_trn_fold_20.txt')\nos.remove('libffm_fold_20_model')\nos.remove('libffm_tst_fold_20.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[19][1]], pd.read_csv('val_preds_fold_20.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[19][1]], pd.read_csv('val_preds_fold_20.txt', header=None).values[:,0])\n)\n","58c27a25":"!.\/ffm-train -p libffm_val_fold_21.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_21.txt libffm_fold_21_model\n!.\/ffm-predict libffm_val_fold_21.txt libffm_fold_21_model val_preds_fold_21.txt\n!.\/ffm-predict libffm_tst_fold_21.txt libffm_fold_21_model tst_preds_fold_21.txt\nos.remove('libffm_val_fold_21.txt')\nos.remove('libffm_trn_fold_21.txt')\nos.remove('libffm_fold_21_model')\nos.remove('libffm_tst_fold_21.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[20][1]], pd.read_csv('val_preds_fold_21.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[20][1]], pd.read_csv('val_preds_fold_21.txt', header=None).values[:,0])\n)\n","c08694aa":"!.\/ffm-train -p libffm_val_fold_22.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_22.txt libffm_fold_22_model\n!.\/ffm-predict libffm_val_fold_22.txt libffm_fold_22_model val_preds_fold_22.txt\n!.\/ffm-predict libffm_tst_fold_22.txt libffm_fold_22_model tst_preds_fold_22.txt\nos.remove('libffm_val_fold_22.txt')\nos.remove('libffm_trn_fold_22.txt')\nos.remove('libffm_fold_22_model')\nos.remove('libffm_tst_fold_22.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[21][1]], pd.read_csv('val_preds_fold_22.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[21][1]], pd.read_csv('val_preds_fold_22.txt', header=None).values[:,0])\n)\n","600136b3":"!.\/ffm-train -p libffm_val_fold_23.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_23.txt libffm_fold_23_model\n!.\/ffm-predict libffm_val_fold_23.txt libffm_fold_23_model val_preds_fold_23.txt\n!.\/ffm-predict libffm_tst_fold_23.txt libffm_fold_23_model tst_preds_fold_23.txt\nos.remove('libffm_val_fold_23.txt')\nos.remove('libffm_trn_fold_23.txt')\nos.remove('libffm_fold_23_model')\nos.remove('libffm_tst_fold_23.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[22][1]], pd.read_csv('val_preds_fold_23.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[22][1]], pd.read_csv('val_preds_fold_23.txt', header=None).values[:,0])\n)\n","eb4f2afc":"!.\/ffm-train -p libffm_val_fold_24.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_24.txt libffm_fold_24_model\n!.\/ffm-predict libffm_val_fold_24.txt libffm_fold_24_model val_preds_fold_24.txt\n!.\/ffm-predict libffm_tst_fold_24.txt libffm_fold_24_model tst_preds_fold_24.txt\nos.remove('libffm_val_fold_24.txt')\nos.remove('libffm_trn_fold_24.txt')\nos.remove('libffm_fold_24_model')\nos.remove('libffm_tst_fold_24.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[23][1]], pd.read_csv('val_preds_fold_24.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[23][1]], pd.read_csv('val_preds_fold_24.txt', header=None).values[:,0])\n)\n","0b3a1513":"!.\/ffm-train -p libffm_val_fold_25.txt -r 0.05 -l 0.00002 -k 50 --auto-stop libffm_trn_fold_25.txt libffm_fold_25_model\n!.\/ffm-predict libffm_val_fold_25.txt libffm_fold_25_model val_preds_fold_25.txt\n!.\/ffm-predict libffm_tst_fold_25.txt libffm_fold_25_model tst_preds_fold_25.txt\nos.remove('libffm_val_fold_25.txt')\nos.remove('libffm_trn_fold_25.txt')\nos.remove('libffm_fold_25_model')\nos.remove('libffm_tst_fold_25.txt')\n(\n    log_loss(train['target'].iloc[fold_ids[24][1]], pd.read_csv('val_preds_fold_25.txt', header=None).values[:,0]),\n    roc_auc_score(train['target'].iloc[fold_ids[24][1]], pd.read_csv('val_preds_fold_25.txt', header=None).values[:,0])\n)\n","9adf9295":"oof_preds = np.zeros(train.shape[0])\nfor fold_, (_, val_) in enumerate(fold_ids):\n    oof_preds[val_] = pd.read_csv(f'val_preds_fold_{fold_+1}.txt', header=None).values[:, 0]\noof_score = roc_auc_score(train['target'], oof_preds)\nprint(oof_score)","cd016640":"test_preds = np.zeros((test.shape[0], N_Splits))\nfor fold_ in range(N_Splits):\n    test_preds[:, fold_] = pd.read_csv(f'tst_preds_fold_{fold_+1}.txt', header=None).values[:, 0]\n\ntest_preds_avg = test_preds.mean(axis=1)","24696332":"submission = test[['id']].copy()\nsubmission['target'] = test_preds_avg\nsubmission.to_csv('libffm_sub_531.csv', index=False)","22973f84":"np.save('test_preds_libffm.npy', test_preds_avg)\nnp.save('oof_preds_libffm.npy', oof_preds)","a6a16425":"subs = [\n    '\/kaggle\/input\/bestpublicscores\/sub_623.csv',\n    '\/kaggle\/input\/bestpublicscores\/sub_634.csv',\n    '\/kaggle\/input\/bestpublicscores\/sub_626.csv',\n    '\/kaggle\/input\/bestpublicscores\/sub_600.csv',\n    '\/kaggle\/input\/bestpublicscores\/sub_590.csv',\n    '\/kaggle\/input\/otherbestpublicscores\/sub_659.csv',\n    '\/kaggle\/input\/otherbestpublicscores\/sub_606.csv',\n    '\/kaggle\/input\/otherbestpublicscores\/sub_563.csv',\n    '\/kaggle\/input\/otherbestpublicscores\/sub_620.csv',\n    '\/kaggle\/input\/bestpublicscores3\/sub_589.csv',\n    'libffm_sub_531.csv'\n       ]\n","a087e9b6":"predictions = pd.concat([pd.read_csv(sub, index_col='id') for sub in subs], axis=1).reset_index(drop=True)\npredictions.columns = ['sub_'+str(i) for i in range(11)]\npredictions","8340d9df":"for col in predictions.columns:\n    predictions[col]=predictions[col].rank()\/predictions.shape[0]","82c8562b":"corr = predictions.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(corr, mask=mask, cmap='Blues', vmin=0.95, center=0, linewidths=1, annot=True, fmt='.4f')\nplt.show()","2dff5c91":"coefs = [0.1, 0.075, 0.1, 0.05, 0.025, 0.375, 0.1, 0.05, 0.05, 0.05, 0.025]\ndef blend_subs(df, coefs=coefs):\n    blend = np.zeros(df.shape[0])\n    for idx, column in enumerate(df.columns):\n        blend += coefs[idx] * (df[column].values)\n    return blend\n\nblend = blend_subs(predictions)","f21df820":"blend","31dfabde":"submission['target'] = blend\nsubmission.to_csv('TopPublicBlend.csv',index=False)\nsubmission.head()","c5fdcc22":"**Blend-Part**","b5a9ca5b":"0.7839462564075135","d521a803":"## Read the data","5765cfde":"## Prepare submission","6f4d6aeb":"The Public submission files are from following kernels:\n\n[deepfm-model](https:\/\/www.kaggle.com\/siavrez\/deepfm-model)\n\n[keras-r-embeddings-baseline](https:\/\/www.kaggle.com\/springmanndaniel\/keras-r-embeddings-baseline)\n\n[same-old-entity-embeddings](https:\/\/www.kaggle.com\/abhishek\/same-old-entity-embeddings)\n\n[catboost-in-action-with-dnn](https:\/\/www.kaggle.com\/lucamassaron\/catboost-in-action-with-dnn)\n\n[oh-my-plain-logreg](https:\/\/www.kaggle.com\/superant\/oh-my-plain-logreg)\n\n[complicated](https:\/\/www.kaggle.com\/scirpus\/complicated)\n\n[let-s-overfit-some](https:\/\/www.kaggle.com\/ccccat\/let-s-overfit-some)","6ac85cac":"## Compute OOF score","2a30787f":"## Label Encode to ease creation of libffm format","67f07951":"## Make ffm-train and ffm-predict excutable","4d9fdb7d":"## Run OOF","7c3934da":"## Introduction\nIt's just some minor changes to the great kernel [libffm-model](https:\/\/www.kaggle.com\/ogrellier\/libffm-model) with predicting test data in each fold. Please Upvote the original kernel. Last part is a blend of some of best scoring public kernels with libffm predictions.\n\n[Field-Aware Factorization](https:\/\/www.csie.ntu.edu.tw\/~cjlin\/libffm) is a powerful representation learning.\n\n[Github here.](https:\/\/github.com\/ycjuan\/libffm)\n ","f9b8f005":"## Create LibFFM files\n\n\nThe data format of LIBFFM has a very special format (taken from [libffm page](https:\/\/github.com\/ycjuan\/libffm)):\n```\n<label> <field1>:<feature1>:<value1> <field2>:<feature2>:<value2> ...\n.\n.\n.\n```\n\n`field` and `feature` should be non-negative integers.\n\nIt is important to understand the difference between `field` and `feature`. For example, if we have a raw data like this:\n\n| Click | Advertiser | Publisher |\n|:-----:|:----------:|:---------:|\n|    0 |       Nike |       CNN |\n|    1 |       ESPN |       BBC |\n\nHere, we have \n \n - 2 fields: Advertiser and Publisher\n - 4 features: Advertiser-Nike, Advertiser-ESPN, Publisher-CNN, Publisher-BBC\n\nUsually you will need to build two dictionares, one for field and one for features, like this:\n    \n    DictField[Advertiser] -> 0\n    DictField[Publisher]  -> 1\n    \n    DictFeature[Advertiser-Nike] -> 0\n    DictFeature[Publisher-CNN]   -> 1\n    DictFeature[Advertiser-ESPN] -> 2\n    DictFeature[Publisher-BBC]   -> 3\n\nThen, you can generate FFM format data:\n\n    0 0:0:1 1:1:1\n    1 0:2:1 1:3:1\n\nNote that because these features are categorical, the values here are all ones.\n\nThe class defined below go through all features and rows and update a python dicts as new values are encountered."}}