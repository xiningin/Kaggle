{"cell_type":{"84d63047":"code","645ccc54":"code","3d41665e":"code","073caa22":"code","b3417285":"code","da2a2ca4":"code","0a118100":"code","efd28880":"code","64d611b3":"code","1eb0008f":"code","4ee5d5b6":"code","96ff945e":"code","32f26b1a":"code","3476e92e":"code","6785beb9":"code","e41c10ed":"code","572f2222":"code","c455a962":"code","19efd54f":"code","1ac8293c":"code","5afef71d":"code","59bbe21b":"code","9dc72c2c":"code","9b787a32":"code","535bd32c":"code","f060fb85":"code","de3a0e4c":"code","f4c6f9f4":"code","8b29215f":"code","e04f0bca":"code","a335334b":"code","78b16160":"code","fd9dbbf0":"code","b36b4cbe":"code","841c94c9":"code","5f2ea426":"markdown","1a90f78f":"markdown","98174f42":"markdown","ca5a861e":"markdown","c1170bb1":"markdown","f342214b":"markdown","c9f378fa":"markdown","38b5bb0c":"markdown","91982ded":"markdown","f8f52a5a":"markdown","9cd6e09d":"markdown","b3658cc3":"markdown","476fcd70":"markdown","2ea8a948":"markdown","0d70a5a0":"markdown","69708010":"markdown","470d5c1f":"markdown","bca38bd1":"markdown","90e5038d":"markdown","540d9a00":"markdown","95891684":"markdown","17e8230b":"markdown","9327701b":"markdown"},"source":{"84d63047":"!pip install scispacy\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.3.0\/en_core_sci_lg-0.3.0.tar.gz","645ccc54":"import numpy as np\nimport pandas as pd\nimport gensim\nimport re\nimport scispacy\nimport spacy\nimport en_core_sci_lg\nfrom sklearn.neighbors import NearestNeighbors\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","3d41665e":"data = pd.read_csv('..\/input\/cord19-dataset\/cord19_minified.csv')\ndata = data[['cord_uid','title','abstract','body_text','publish_year','is_covid19']]\ndata.head()","073caa22":"data.isnull().sum()","b3417285":"# Dropping all rows containing any null value.\ndata.dropna(inplace=True)","da2a2ca4":"start_time = time.process_time()\ncount = {}\nfor i in range(len(data)):\n    year = data.iloc[i].publish_year\n    if year < 2010:\n        continue\n    if year in count.keys():\n        count[year] += 1\n    else:\n        count[year] = 1\nyears = []\npapers_published = []\nfor year in sorted(count):\n    years.append(year)\n    papers_published.append(count[year])\nx_coord = np.arange(0,len(years))\nplt.figure(figsize=(15,5))\nplt.bar(x_coord,papers_published,width=0.5,label=\"Current Year\", tick_label=years)\nplt.title(\"Publication Year v\/s Number of Papers Published in Last Decade\")\nplt.xlabel(\"Publication Year\")\nplt.ylabel(\"Number of Papers Published\")\nplt.show()\nprint(time.process_time() - start_time, 'seconds')","0a118100":"covid_paper = 0\ntotal = len(data)\nfor i in range(total):\n    if data.iloc[i]['is_covid19']:\n        covid_paper += 1\nterms = np.array(['Papers based on Covid19','Others'])\nweigtage = np.array([covid_paper,total - covid_paper])\nplt.figure(figsize=(5,5))\nplt.pie(weigtage,labels=terms, autopct=\"%1.1f%%\")\nplt.title('Comparison of Papers based on Covid19 and others')\nplt.show()","efd28880":"start_time = time.process_time()\ndataset = []\nfor i in range(len(data)):\n    paper_len = len(re.findall(r\"(?i)\\b[a-z]+\\b\", data.iloc[i]['body_text']))\n    dataset.append(paper_len)\nplt.figure(figsize=(15,5))\nplt.hist(dataset, bins = [0,1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000,11000, 12000]) \nplt.xlabel('Paper Length')\nplt.ylabel('Number of Papers Published')\nplt.title('Histogram of Paper Length v\/s Paper Published')\nplt.show()\nprint(time.process_time() - start_time, 'seconds')","64d611b3":"nlp = en_core_sci_lg.load(disable=[\"tagger\", \"parser\", \"ner\"])\n","1eb0008f":"def tokenize(text):\n    return gensim.parsing.preprocess_string(str(nlp.make_doc(text.lower())))\n\ndef read_corpus(df, column, tokens_only=False):\n    for i, line in enumerate(df[column]):\n        \n        if pd.isna(line):\n            continue\n\n        tokens = tokenize(line)\n        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])","4ee5d5b6":"start_time = time.process_time()\ndf = data[data['body_text'].apply(lambda x: len(re.findall(r\"(?i)\\b[a-z]+\\b\", x))) > 100]\ndf.reset_index(inplace=True, drop=True)\ndf.head(n=3)\nprint(time.process_time() - start_time, 'seconds')","96ff945e":"train_df = df.copy()","32f26b1a":"start_time = time.process_time()\ntrain_corpus = (list(read_corpus(train_df, 'abstract')))\nprint(time.process_time() - start_time, 'seconds')","3476e92e":"start_time = time.process_time()\nmodel = gensim.models.doc2vec.Doc2Vec(dm=1, vector_size=32, min_count=10, dm_mean=1, epochs=20, seed=16, workers=6)\nmodel.build_vocab(train_corpus)\nmodel.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\nprint(time.process_time() - start_time, 'seconds')","6785beb9":"def get_query_vector(task):\n    tokens = tokenize(task.lower())\n    return model.infer_vector(tokens)","e41c10ed":"body_text_vectors = model.docvecs.vectors_docs\ntrain_df['body_vector'] = [vec for vec in body_text_vectors]\ntrain_df['body_vector'] = train_df['body_vector'].dropna()","572f2222":"body_text_vectors.shape","c455a962":"train_df = train_df[train_df['abstract'].apply(lambda x: not pd.isna(x) and len(re.findall(r\"(?i)\\b[a-z]+\\b\", x))) > 30]\ntrain_df.head()","19efd54f":"query1 = \"What is known about transmission, incubation, and environmental stability of COVID-19?\"\nquery2 = \"What do we know about COVID-19 risk factors? What have we learned from epidemiological studies?\"\nquery3 = \"What do we know about virus genetics, origin, and evolution?\"","1ac8293c":"queries = [query1,query2,query3]\nall_queries = [get_query_vector(query) for query in queries]","5afef71d":"train_array = train_df['body_vector'].values.tolist()","59bbe21b":"ball_tree = NearestNeighbors(algorithm='ball_tree', leaf_size=20).fit(train_array)","9dc72c2c":"kd_tree = NearestNeighbors(algorithm='kd_tree', leaf_size=20).fit(train_array)","9b787a32":"brute = NearestNeighbors().fit(train_array)","535bd32c":"distances, indices = brute.kneighbors(all_queries, n_neighbors=3)","f060fb85":"for i, info in enumerate(queries):\n    print(\"=\"*80, f\"\\n\\nTask = {info[:100]}\\n\", )\n    df =  train_df.iloc[indices[i]]\n    abstracts = df['abstract']\n    titles = df['title']\n    dist = distances[i]\n    for l in range(len(dist)):\n        print(f\" Text index = {indices[i][l]} \\n Distance = {distances[i][l]} \\n Title: {titles.iloc[l]} \\n Abstract extract: {abstracts.iloc[l][:200]}\\n\\n\")","de3a0e4c":"def find_search_papers(query,k=5,k_near=ball_tree):\n    print(\"Query =\",query[:200],'\\n')\n    query_vector = get_query_vector(query)\n    distance , index = k_near.kneighbors([query_vector],n_neighbors=k)\n    distance, index = distance[0], index[0]\n    results = train_df.iloc[index]\n    print(\"Results \\n\")\n    for i in range(len(distance)):\n        print(i+1, \"score=\",distance[-1]-distance[i])\n        print(\"Title:\",results['title'].iloc[i])\n        print(\"Abstract: \", results['abstract'].iloc[i][:200],'\\n')","f4c6f9f4":"individual_query = \"\"\"What do we know about vaccines and therapeutics? What has been published concerning research and development and evaluation efforts of vaccines and therapeutics?\nEffectiveness of drugs being developed and tried to treat COVID-19 patients.\nClinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication.\nMethods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients.\nExploration of use of best animal models and their predictive value for a human vaccine.\nCapabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents.\nAlternative models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics as production ramps up. This could include identifying approaches for expanding production capacity to ensure equitable and timely distribution to populations in need.\nEfforts targeted at a universal coronavirus vaccine.\nEfforts to develop animal models and standardize challenge studies\nEfforts to develop prophylaxis clinical studies and prioritize in healthcare workers\nApproaches to evaluate risk for enhanced disease after vaccination\nAssays to evaluate vaccine immune response and process development for vaccines, alongside suitable animal models [in conjunction with therapeutics]\"\"\"","8b29215f":"find_search_papers(individual_query,k=10,k_near=kd_tree)","e04f0bca":"import ipywidgets as widgets\nfrom ipywidgets import interact, Layout, HBox, VBox, Box\nfrom IPython.display import clear_output\n\ndef Cord_Search_Engine():    \n    textW = widgets.Textarea(\n        value='',\n        placeholder='Type something',\n        description='',\n        disabled=False,\n        layout=Layout(width='60%', height='200px')\n    )\n\n    button = widgets.Button(description=\"Search\")\n\n    display(VBox([HBox([], layout=Layout(width='60%', justify_content='space-around')),\n        textW, button], layout=Layout(align_items='center')))\n\n    def on_button_clicked(b):\n        clear_output()\n        display(VBox([HBox([], layout=Layout(width='60%', justify_content='space-around')),\n            textW, button], layout=Layout(align_items='center')))        \n        find_search_papers(textW.value)\n\n    button.on_click(on_button_clicked)","a335334b":"Cord_Search_Engine()","78b16160":"topics = pd.read_csv('..\/input\/cord-topic\/final_topics.csv')\ntopics = topics.drop(['Unnamed: 0'],axis=1)\ntopics.head()","fd9dbbf0":"def evaluate(topics_query_vec,k_neigh=ball_tree):\n    results = []\n    distances, indices = k_neigh.kneighbors(topics_query_vec, n_neighbors=10)\n    for i in range(len(topics_query_vec)):\n        df =  train_df.iloc[indices[i]]\n        for j in range(len(distances[i])):\n            index = indices[i][j]\n            distance = distances[i][j]\n            results.append([i+1,df['cord_uid'].iloc[j],distance])\n    results_df = pd.DataFrame(results,columns=['topic-id','cord-id','distance'])\n    return results_df","b36b4cbe":"topics_query_vec = [get_query_vector(query) for query in topics['final_query']]\nfinal_df = evaluate(topics_query_vec)\nfinal_df.head()","841c94c9":"final_df.to_csv('submission2.csv',index=False)","5f2ea426":"<h2>Eliminating the Outliers<h2>\n<h3><center>We wanted to include authentic research papers in this so we kept the criteria of an authentic research paper as a paper having more than 30 words in abstract and more than 100 words in the body text as anything smaller than that puts a doubt on the authenticity of its work<\/center><h3>","1a90f78f":"              \n<h1><center>CORD19-Doc2Vec Search Engine<\/center><\/h1>\n<img src='https:\/\/miro.medium.com\/max\/1200\/0*Frvr1oieAqwoLje7' width=\"800\"><\/img>","98174f42":"<h1><center>Function for Individual Query Search<\/center><\/h1>","ca5a861e":"<center><h2>Loading the Dataset<\/center><\/h2>","c1170bb1":"<h2>Preparation of the Sample Queries<\/h2>","f342214b":"<h1><center>Distribution of Paper Length over the Dataset<\/center><\/h1>","c9f378fa":"<h1><center>Post Training Pre-Processing of the Model<\/center><\/h1>\n\n<h2><center>Now our model has been created we can now pass query strings in it which it would then be able to successfully convert into vectorial form of numerical representation but for that we would need additional helper functions<\/center><\/h2>","38b5bb0c":"## Creating the training array to pass down to the Nearest Neigbour Algorithm","91982ded":"<h2><center>Pie Chart on Papers based on Covid19<\/center><\/h2>","f8f52a5a":"<h2><center>In our final dataframe, we are taking additional precautions to eliminate outliers by removing elements having abstract size of less than 30<\/center><\/h2>","9cd6e09d":"<h1><center>Individual Query Search Results<\/center><\/h1>","b3658cc3":"<h2>Tokenizer,Lemenitization & Tagging of the Corpus<\/h2>\n\n<h3><center> Here we have used SciSpacy which contains spacy models to process biomedical and scientific texts.Since this dataset is mainly a collection of research papers so we felt that using this model for pre-processing the dataset would yield result that facilitate the model to learn the insights of the corpus.<\/center><\/h3>","476fcd70":"<h1><center>Sample Results<\/center><\/h1>","2ea8a948":"<h2><center>Papers Published in Last Decade<\/center><\/h2>","0d70a5a0":" <h1><center>References<\/center><\/h1>\n \nhttps:\/\/medium.com\/kaggle-blog\/gaining-a-sense-of-control-over-the-covid-19-pandemic-a-winners-interview-with-daniel-wolffram-1320fb2717c4\nhttps:\/\/www.kaggle.com\/c\/trec-covid-information-retrieval\/data?select=sample_submission.csv\nhttps:\/\/towardsdatascience.com\/submitted-solution-for-kaggle-covid-19-open-research-dataset-challenge-cord-19-138eced43985\nhttps:\/\/www.kaggle.com\/luisblanche\/cord-19-use-doc2vec-to-match-articles-to-tasks\nhttps:\/\/www.quantmetry.com\/blog\/kaggle-covid-19-open-research-dataset-challenge-cord-19\/\nhttps:\/\/www.kaggle.com\/danielwolffram\/topic-modeling-finding-related-articles\n\n","69708010":"## Loading Libraries","470d5c1f":"<h1><center>Interactive UI For CORD Search<\/center><\/h1>","bca38bd1":"<h2>Checking for Null values<\/h2>","90e5038d":"<h1><center>Data Exploration and Visualization<\/center><\/h1>\n\n<h3><center>Here we would we exploring the dataset to get the insights that would help us in selecting our model and approprite hyperparameter while at the same time increasing our knowledge of the dataset.<\/center><\/h3>\n","540d9a00":" <h1><center>Evaluation<\/center><\/h1>","95891684":"<h1><center>Ball Tree & KD Tree Implementation<\/center><\/h1>","17e8230b":"<h1><center>Training of the Model<\/center><\/h1>\n\n<h2><center>Here we have used the Gensim Library to implement the Doc2Vec Model<\/center><\/h2>","9327701b":"<h1><center>Data Preprocessing<\/center><\/h1>"}}