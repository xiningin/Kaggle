{"cell_type":{"af42d59b":"code","1e511671":"code","ee2b59fa":"code","e2d86994":"code","e357a3b0":"code","9aa0d068":"code","d06b7552":"code","d8ef1731":"code","99c8bd00":"code","bf7afddc":"code","3d9bcfc2":"code","adb1b39e":"code","7b019f71":"code","6ba0c21b":"code","b48ff08d":"code","1c8eb5a4":"code","7c9ebce0":"code","9f568fd8":"code","591e8419":"code","62ea91a6":"code","d9ae812d":"code","73575ee9":"code","34d6ae17":"code","6137862f":"code","b55b4212":"code","2f605b9f":"code","c4584bc2":"code","4b9cabc6":"code","ef75fb62":"code","7aeb154b":"code","a3f9fd18":"code","307514a8":"code","43cbacaf":"code","aca1ca21":"code","1a54293c":"code","73c1d27a":"code","2df074b1":"code","73ca80b2":"code","95ca2e87":"code","6f1a7704":"code","cd55a554":"code","d95657ff":"code","d6e8f544":"code","174c9104":"code","dc4291ff":"code","86682f8a":"code","b19f39c8":"code","f98eb937":"code","e3ffabba":"code","5b7bcdc8":"code","ce1d39d7":"code","17e1f037":"code","1ac6d564":"code","bafdbd02":"code","0a93e188":"code","f4ad483b":"code","76c53283":"code","8b154509":"code","569c9129":"code","d096024d":"code","7afa26ce":"code","159dc42b":"code","e16179c0":"code","16dec882":"code","1e42b852":"code","61d4d627":"code","7d5bd507":"code","b29d4708":"code","3482efb1":"code","fa4e04f5":"code","6d5aefb4":"code","933faaf6":"code","2a089eba":"code","bef89b61":"code","3ab4790a":"code","7814b94f":"code","80b53987":"code","0c9f68a6":"code","1350ba11":"code","9518bcab":"markdown","2396e2ac":"markdown","c19057b5":"markdown","eadb1fc7":"markdown","a64dd8dc":"markdown","1a044238":"markdown","32fde32b":"markdown","9bf09f66":"markdown","765ecae6":"markdown","4a3f7176":"markdown","5ccbb733":"markdown","d73f4259":"markdown","18bb34c8":"markdown","db69c100":"markdown","a1f6e85e":"markdown","fc242851":"markdown","23471ae0":"markdown","a875d359":"markdown","38983f21":"markdown","30578cc3":"markdown","8fbf2644":"markdown","d0f29ae0":"markdown","dd5b6d44":"markdown","bd343c3c":"markdown","bd7ca1d8":"markdown","3b1b5f7c":"markdown","5515b266":"markdown","a8ae735d":"markdown","5e0c1b53":"markdown","7cafaedd":"markdown","5cb8f09f":"markdown","2e68f52c":"markdown","9073fede":"markdown"},"source":{"af42d59b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e511671":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\nsns.set_style('darkgrid')","ee2b59fa":"from sklearn.model_selection import train_test_split                                 # split data into training and testing sets\nfrom sklearn.ensemble import RandomForestRegressor                                   # this will make a Random Forest Regression\nfrom xgboost import XGBRegressor, plot_importance\nfrom lightgbm import LGBMRegressor, plot_importance\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV                 # this will do cross validation","e2d86994":"mtcars = pd.read_csv(\"\/kaggle\/input\/mt-cars\/Lesson 3 Practice\/mtcars.csv\")","e357a3b0":"# Check the first 5 rows\nmtcars.head()","9aa0d068":"# Check the last 5 rows\nmtcars.tail()","d06b7552":"# Check dimensions\nmtcars.shape","d8ef1731":"# print the column labels\nmtcars.columns","99c8bd00":"mtcars_original = mtcars.copy()","bf7afddc":"display(mtcars.info())","3d9bcfc2":"# To get a quick statistical summary\nmtcars.describe()","adb1b39e":"mtcars['maker'] = mtcars.model.apply(lambda x: x.split()[0])\nmtcars['maker']","7b019f71":"mtcars.head()","6ba0c21b":"av_mpg = mtcars.groupby('maker').mpg.mean()\nav_mpg","b48ff08d":"pd.crosstab(mtcars.am, mtcars.cyl, margins=True, margins_name=\"Total\").style.background_gradient(cmap='summer_r')","1c8eb5a4":"display(mtcars.isnull().sum())","7c9ebce0":"# Pearson Correlation\nplt.figure(figsize=(18,10))\nsns.heatmap(mtcars.corr(method='pearson'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, square=True, cmap='coolwarm');","9f568fd8":"# Spearman Correlation\nplt.figure(figsize=(18,12))\nsns.heatmap(mtcars.corr(method='spearman'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, square=True, cmap='coolwarm');","591e8419":"fig, ax = plt.subplots(figsize=(18, 12))\ncorr = mtcars.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nax.text(-1.1, -0.7, 'Correlation between the Features', fontsize=20, fontweight='bold', fontfamily='serif')\nsns.heatmap(corr, mask=mask, annot=False, fmt='.2f', linewidth=0.2, cbar=True, cmap='coolwarm');","62ea91a6":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(17 , 5))\n\nfeature_lst = ['model', 'mpg', 'disp','cyl', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb', 'maker']\n\ncorr = mtcars[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(mtcars[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.1f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","d9ae812d":"mtcars.corr()['hp'].sort_values(ascending=False)","73575ee9":"a = mtcars.drop(['hp'], axis=1)\na.corrwith(mtcars['hp']).plot(kind='bar', figsize=(18,11), color=['salmon'])\nplt.title('Correlation b\/n target and Independant features')\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","34d6ae17":"dpal = sns.choose_colorbrewer_palette('diverging', as_cmap=True)","6137862f":"plt.figure(figsize=(18,15))\nplt.matshow(mtcars[['mpg', 'wt', 'hp', 'qsec', 'disp']].corr(), cmap=dpal)\nax = plt.gca()\nax.tick_params(axis='both', which='both',length=0);\nplt.title(\"Correlation Matrix\")\nplt.xticks(range(4), ['mpg', 'wt', 'hp', 'qsec', 'disp'])\nplt.yticks(range(4), ['mpg', 'wt', 'hp', 'qsec', 'disp']);","b55b4212":"# Heatmap\nfig = plt.figure(figsize=(18, 12))\nax = sns.heatmap(mtcars[['mpg', 'disp', 'hp', 'drat', 'wt', 'qsec']])\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","2f605b9f":"plt.figure(figsize=(16,20))\nsns.boxplot(data=mtcars, orient=\"h\");","c4584bc2":"plt.figure(figsize=(25,13))\nsns.boxplot(data=mtcars)\n\nplt.title(\"Mtcars\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","4b9cabc6":"fig = plt.figure(figsize=(10, 8))\nsns.boxplot(x=\"vs\", y='wt', data=mtcars)\n\nplt.xlabel('VS', fontsize=15, fontweight='bold')\nplt.ylabel('wt', fontsize=15, fontweight='bold')\n\nplt.title(\"Engine (0 = V-shaped, 1 = straight) Vs Weight\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","ef75fb62":"mtcars.skew()","7aeb154b":"mtcars[\"mpg\"].skew()","a3f9fd18":"mtcars[\"mpg\"].kurt()","307514a8":"plt.figure(figsize=(25,10))\nsns.countplot(mtcars['model'])\n\nplt.xlabel('Model', fontsize=15, fontweight='bold')\nplt.ylabel('count', fontsize=15, fontweight='bold')\n\nplt.title('Model Vs Count', fontsize=18, fontweight='bold')\n\nplt.xticks(rotation=60)\nplt.show()","43cbacaf":"mtcars['model'].nunique()","aca1ca21":"mtcars['model'].value_counts()","1a54293c":"plt.figure(figsize=(25,10))\nsns.countplot(mtcars['hp'])\n\nplt.xlabel('hp', fontsize=15, fontweight='bold')\nplt.ylabel('count', fontsize=15, fontweight='bold')\n\nplt.title('hp Vs Count', fontsize=18, fontweight='bold')\n\nplt.xticks(rotation=0)\nplt.show()\n\nprint(mtcars['hp'].value_counts())","73c1d27a":"mtcars['hp'].nunique()","2df074b1":"plt.figure(figsize=(10,7))\nsns.countplot(mtcars['cyl'])\n\nplt.xlabel('cyl', fontsize=15, fontweight='bold')\nplt.ylabel('count', fontsize=15, fontweight='bold')\n\nplt.title('cyl Vs Count', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=13, rotation=0)\nplt.show()\n\nprint(mtcars['cyl'].value_counts())","73ca80b2":"mtcars['cyl'].nunique()","95ca2e87":"plt.figure(figsize=(10,7))\nsns.countplot(mtcars['gear'])\n\nplt.xlabel('gear', fontsize=15, fontweight='bold')\nplt.ylabel('count', fontsize=15, fontweight='bold')\n\nplt.title('gear Vs Count', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=13, rotation=0)\nplt.show()\n\nprint(mtcars['gear'].value_counts())","6f1a7704":"plt.figure(figsize=(10,7))\nsns.countplot(mtcars['carb'])\n\nplt.xlabel('carb', fontsize=15, fontweight='bold')\nplt.ylabel('count', fontsize=15, fontweight='bold')\n\nplt.title('Carburator Vs Count', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=13, rotation=0)\nplt.show()\n\nprint(mtcars['carb'].value_counts())","cd55a554":"sns.distplot(mtcars['hp'], kde=True)","d95657ff":"sns.distplot(mtcars['cyl'], kde=True)","d6e8f544":"sns.distplot(mtcars['mpg'])","174c9104":"# Bar Plot\nplt.figure(figsize=(10,7))\nsns.barplot(mtcars['cyl'], mtcars['carb'])\n\nplt.xlabel('cyl', fontsize=15, fontweight='bold')\nplt.ylabel('carb', fontsize=15, fontweight='bold')\n\nplt.title('cyl Vs carb', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()\n\nprint(mtcars['carb'].value_counts())","dc4291ff":"mtcars_group = mtcars.groupby(\"cyl\").count().reset_index()\nmtcars_group","86682f8a":"fig = plt.figure(figsize=(12, 8))\nax = sns.barplot(x=\"cyl\", y=\"mpg\", data = mtcars_group)\nax.set(xlabel='Cylinders', ylabel='Number of Cars for Each Cylinder')\nplt.show()","b19f39c8":"# Scatter Plot\nplt.figure(figsize=(15,10))\nsns.scatterplot(data=mtcars, x = \"drat\", y = \"qsec\", hue='am')\nsns.set(style='whitegrid',)\n\nplt.xlabel('drat', fontsize=15, fontweight='bold')\nplt.ylabel('qsec', fontsize=15, fontweight='bold')\n\nplt.title('drat Vs qsec', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","f98eb937":"# Scatter Plot\nplt.figure(figsize=(15,10))\nsns.scatterplot(data=mtcars, x='cyl', y='hp', hue=\"model\")\n\nplt.xlabel('cyl', fontsize=15, fontweight='bold')\nplt.ylabel('hp', fontsize=15, fontweight='bold')\n\nplt.title('Cylinder Vs Horse Power', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","e3ffabba":"# Catplot\nplt.figure(figsize=(25,13))\nsns.catplot(x='hp', col='cyl', kind='count', data=mtcars)\nplt.show()","5b7bcdc8":"plt.figure(figsize=(18, 13))\nsns.boxplot(x='cyl', y='hp', data=mtcars, hue='am')\n\nplt.xlabel('cyl', fontsize=15, fontweight='bold')\nplt.ylabel('hp', fontsize=15, fontweight='bold')\n\nplt.title(\"Cylinder Vs HP\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","ce1d39d7":"plt.figure(figsize=(15,9))\nsns.lmplot(x = \"cyl\", y = \"hp\", data = mtcars, hue=\"gear\")\nplt.show()","17e1f037":"plt.figure(figsize=(15,9))\nax = sns.regplot(x=\"wt\", y=\"mpg\", data=mtcars)\nplt.show()","1ac6d564":"plt.figure(figsize=(15,9))\nsns.violinplot(x=\"vs\", y='wt', data=mtcars)\n\nplt.xlabel('vs', fontsize=15, fontweight='bold')\nplt.ylabel('wt', fontsize=15, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","bafdbd02":"## Checking for pairplot\nsns.pairplot(mtcars, diag_kind=\"kde\")","0a93e188":"# Independant variable\nX = mtcars[['cyl']]                       # All rows & columns exclude Target features\n\n# Dependant variable\ny = mtcars['hp'].values                   # Only target feature","f4ad483b":"# split  data into training and testing sets of 70:30 ratio\n# 20% of test size selected\n# random_state is random seed\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)","76c53283":"# shape of X & Y test \/ train\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","8b154509":"from scipy import stats\nfrom scipy.stats import f_oneway\nfrom scipy.stats import ttest_ind","569c9129":"import statsmodels.api as sms\nmodel = sms.OLS(y,X).fit()\nmodel.summary()","d096024d":"import xgboost\nreg_xgb = XGBRegressor()\nreg_xgb.fit(X_train,y_train)","7afa26ce":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","159dc42b":"xgb = XGBRegressor(random_state=42, tree_method='gpu_hist', use_label_encoder=True)\n\n# A parameter grid for XGBoost\nparams = {'learning_rate': [0.01, 0.1],\n          'max_depth': [3, 5, 7, 10],\n          'min_child_weight': [1, 3, 5],\n          'subsample': [0.5, 0.7],\n          'colsample_bytree': [0.5, 0.7],\n          'n_estimators' : [100, 200, 500],\n          'objective': ['reg:squarederror']\n        }\n\nrandom_cv = GridSearchCV(estimator = xgb,\n                         param_grid = params,\n                         cv=5,\n                         n_jobs = -1,\n                         verbose = 1\n                        )\nrandom_cv.fit(X_train,y_train)","e16179c0":"# best parameter \nrandom_cv.best_params_","16dec882":"xgb = XGBRegressor(colsample_bytree= 0.5,\n                   learning_rate = 0.01,\n                   max_depth = 3,\n                   min_child_weigh= 5,\n                   n_estimators= 500,\n                   objective= 'reg:squarederror'\n                  )\n                   \nxgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)], verbose=False)","1e42b852":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(xgb.score(X_train,y_train),xgb.score(X_test,y_test)))","61d4d627":"y_pred_xgb = xgb.predict(X_test)\n\nmae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n\nprint(\"MAE: \", mae_xgb)","7d5bd507":"plot_importance(xgb, max_num_features = 15)\nplt.show()","b29d4708":"rfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)   # train the model","3482efb1":"# predicting X_test\ny_pred_rfr = rfr.predict(X_test)","fa4e04f5":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rfr.score(X_train, y_train),rfr.score(X_test, y_test)))","6d5aefb4":"print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Random Forest Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_rfr)),\n            mean_squared_error(y_test, y_pred_rfr),\n            mean_absolute_error(y_test, y_pred_rfr),\n            r2_score(y_test, y_pred_rfr)))\n\nplt.scatter(y_test, y_pred_rfr)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.title(\"Random Forest Regressor\")\n\nplt.show()","933faaf6":"print(\"Best Parameters:\",gridcv_rfr.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv_rfr.score(X_train,y_train),gridcv_rfr.score(X_test,y_test)))","2a089eba":"rf = RandomForestRegressor(max_depth= 100, min_samples_leaf= 4, min_samples_split= 5, n_estimators= 200)\nrf.fit(X_train, y_train)","bef89b61":"# predicting X_test\ny_pred_rf = rf.predict(X_test)","3ab4790a":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rf.score(X_train, y_train),rf.score(X_test, y_test)))","7814b94f":"print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Random Forest Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n            mean_squared_error(y_test, y_pred_rf),\n            mean_absolute_error(y_test, y_pred_rf),\n            r2_score(y_test, y_pred_rf)))\n\nplt.scatter(y_test, y_pred_rf)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.title(\"Random Forest Regressor\")\n\nplt.show()","80b53987":"rf.feature_importances_","0c9f68a6":"feature_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n\n# Creating a bar plot\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","1350ba11":"# get importance\nimportance = rf.feature_importances_\n\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","9518bcab":"## LM Plot (Regression)","2396e2ac":"## d) gear","c19057b5":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 3.2.1) The correlation between the continuos variables <\/h1>\n\na. Pearson Correlation\n\nb. Spearman Correlation\n\nc. kendall","eadb1fc7":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left;\"> 3.4) Skew and Kurtosis <\/h1>","a64dd8dc":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.4.1) Hyperparameter Tuning <\/h1>","1a044238":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 5) Data Visualization <\/h1>","32fde32b":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 3.2.2) The correlation between this continuos features and the target <\/h1>","9bf09f66":"- from above graph identified as **'mpg', 'hp', 'wt', 'qsec' and 'carb'** these features have outliers. ","765ecae6":"- The output shows that mtars has **32 rows and 12 columns.**","4a3f7176":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 4) Data Preprocessing <\/h1>","5ccbb733":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.4) Random Forest Regressor <\/h1>","d73f4259":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 1) Load Required Liabriaries <\/h1>","18bb34c8":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.3.1) Hyperparameter Tuning <\/h1>","db69c100":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.3) XGBoost Regressor <\/h1>","a1f6e85e":"## Violinplot","fc242851":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left;\"> 3.2) Relation between Features <\/h1>","23471ae0":"## c. Multivariate Analysis\n### Pair Plot\n- A pairs plot allows us to see both __distribution of single variables__ and **relationships between two variables**\n\n\n- The default pairs plot in seaborn __only plots numerical columns__ later we will __use categorical variables for coloring__\n\n\n- The pairs plot builds on two basic figures, __the histogram and the scatter plot__.\n\n           \n-       a. The __histogram on the diagonal allows us to see the distribution of a single variable__.\n\n\n-       b. while the __scatter plots on the upper and lower triangles show the relationship between two variables__. ","a875d359":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 3) EDA(Exploratory Data Analysis) <\/h1>","38983f21":"### b. Bivariate Analysis","30578cc3":"#### Tuning Hyperparameter of Random Forest Regressor\n#### Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n\n#### Maximum number of levels in tree\nmax_depth = list(range(10,110,10))\n\n#### Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n\n#### Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n\nrf = RandomForestRegressor(random_state=42)\n\nparams = {'n_estimators':n_estimators,\n          'max_depth':max_depth,\n          'min_samples_split':min_samples_split,\n          'min_samples_leaf':min_samples_leaf}\n\ngridcv_rfr = GridSearchCV(rf, param_grid = params, n_jobs=-1)\ngridcv_rfr.fit(X_train, y_train)","8fbf2644":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.1) Splitting into Train and Test <\/h1>","d0f29ae0":"## a) Model","dd5b6d44":"### a. Univariate Analysis","bd343c3c":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 6) Model building and Evaluation <\/h1>","bd7ca1d8":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 2) Read Data <\/h1>","3b1b5f7c":"<h1 style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:left;\"> 6.2) Hypothesis Testing <\/h1>","5515b266":"## b) hp","a8ae735d":"## e.carb","5e0c1b53":"## c) cyl","7cafaedd":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left;\"> 3.3) Find Outliers <\/h1>","5cb8f09f":"- The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973\u201374 models).\n\n- A data frame with **32 observations** on **11 (numeric) variables.**\n\n|Feature     |Description                                   |\n|------------|----------------------------------------------|\n|mpg         |Miles\/(US) gallon                             |                           \n|cyl         |Number of cylinders                           |\n|disp        |Displacement (cu.in.)                         |\n|hp          |Gross horsepower                              |\n|drat        |Rear axle ratio                               |\n|wt          |Weight (1000 lbs)                             |\n|qsec        |1\/4 mile time                                 |\n|vs          |Engine (0 = V-shaped, 1 = straight)           |\n|am          |Transmission (0 = automatic, 1 = manual)      |\n|gear        |Number of forward gears                       |\n|carb        |Number of carburetors                         |","2e68f52c":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:160%; text-align:left;\"> 3.1) Missing Values <\/h1>","9073fede":"<h2 style=color:green align=left> Table of Content <\/h2>\n\n1) Load Required Liabriaries\n\n2) Read Data\n\n3) EDA(Exploratory Data Analysis) \n\n    3.1) Missing Values \n    \n    3.2) Relation between Features\n    \n           3.2.1) The correlation between the continuos variables\n           \n           3.2.2) The correlation between this continuos features and the target\n           \n    3.3) Find Outliers\n    \n    3.4) Skew and Kurtosis\n    \n4) Data Preprocessing\n\n5) Data Visualization\n\n6) Model building and Evaluation\n\n    6.1) XGBoost\n    \n    6.2) Random Forest Regressor\n"}}