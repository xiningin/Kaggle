{"cell_type":{"4d9cfe89":"code","81bd5a59":"markdown"},"source":{"4d9cfe89":"library(forecast) # forecast package has auto-arima method that automatically figures out ACF, PACF and other parameters \nlibrary(parallel) # this is used to enhance computation speed as R uses single thread only.\n\n# reading the train input file\ndf = read.csv('..\/input\/train.csv')\n\n# reading test input file\ndf_test = read.csv('..\/input\/test.csv')\n\n# converting datetime column to datetime format\ndf[,1] = as.POSIXct(df[,1])\n\n# initializing available cores form the system  \ncl = makeCluster(getOption('cl.cores', 7))\n\n# spliting data w.r.t store and item and stored in list\nl_store_item = split(df, list(df$store, df$item))\n\n# storing models in list that is applied on input data on chunks of store and item combinations\nl_models = clusterMap(cl, function(x){library(forecast);auto.arima(x$sales)}, l_store)\n\n# applying forecast method to predict next 90 days. You must be wondering why 90 days.\n# As test data has 45000 rows. Now lets devide it by 10 stores and 50 items then each\n# each buckets would be having 90 rows only so predicting 90 rows.\nl_forecast = clusterMap(cl, function(x){library(forecast);\n                        as.data.frame(forecast(x,90))},\n                        l_models)\n# appending all results to get back test size\nresult = do.call('rbind', l_forecast)\n\n# adding id from test data and output to get final result for submission\ndf_result = cbind(df_test['id'], 'sales'=result[,1])\n\n# freeing clusters \nstopCluster(cl)\n\n# output for submission\nwrite.csv(df_result, 'output_forecast_arima.csv', row.names = F)\nhead(df_result)","81bd5a59":"Lets begin, I have used **forecast** package to apply arima model and leveraged the use of **parallel** package to enhance cumputation. \n"}}