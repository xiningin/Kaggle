{"cell_type":{"616b30e4":"code","a7f662d5":"code","2d283df1":"code","4f3e5d2c":"code","f1ac07ec":"code","51e4d983":"code","35fcbb42":"code","91757d2f":"code","57deb90f":"code","686f3d1f":"code","916adfe6":"code","c3c26d6f":"code","63a4471b":"code","236add2b":"code","e6f51c76":"code","68e4c0a8":"code","e5481310":"code","5d26d1b5":"code","315794c1":"code","1749f808":"code","716099fe":"code","b860b3a6":"markdown","18a39896":"markdown","11699e47":"markdown","f259bbfe":"markdown","0edb6adb":"markdown","5c3dfd66":"markdown","c1b21116":"markdown","5e721461":"markdown","0c465d45":"markdown"},"source":{"616b30e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a7f662d5":"import pandas as pd\ndata = pd.read_csv(\"..\/input\/hotel-booking-demand\/hotel_bookings.csv\")","2d283df1":"data.head()","4f3e5d2c":"data.describe()","f1ac07ec":"data.info()","51e4d983":"print(\"Nan in each columns\" , data.isna().sum(), sep='\\n')","35fcbb42":"data = data.drop(['company'], axis = 1)\ndata = data.dropna(axis = 0)","91757d2f":"data.nunique()","57deb90f":"data['hotel'] = data['hotel'].map({'Resort Hotel':0, 'City Hotel':1})\ndata['hotel'].unique()","686f3d1f":"data['arrival_date_month'] = data['arrival_date_month'].map({'January':1, 'February': 2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7,\n                                                            'August':8, 'September':9, 'October':10, 'November':11, 'December':12})\ndata['arrival_date_month'].unique()","916adfe6":"# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column. \ndata['customer_type']= label_encoder.fit_transform(data['customer_type']) \ndata['assigned_room_type'] = label_encoder.fit_transform(data['assigned_room_type'])\ndata['deposit_type'] = label_encoder.fit_transform(data['deposit_type'])\ndata['reservation_status'] = label_encoder.fit_transform(data['reservation_status'])\ndata['meal'] = label_encoder.fit_transform(data['meal'])\ndata['country'] = label_encoder.fit_transform(data['country'])\ndata['distribution_channel'] = label_encoder.fit_transform(data['distribution_channel'])\ndata['market_segment'] = label_encoder.fit_transform(data['market_segment'])\ndata['reserved_room_type'] = label_encoder.fit_transform(data['reserved_room_type'])\ndata['reservation_status_date'] = label_encoder.fit_transform(data['reservation_status_date'])\n  \n","c3c26d6f":"from sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.ensemble import AdaBoostRegressor","63a4471b":"X = data.drop(['previous_cancellations'], axis = 1)\ny = data['previous_cancellations']","236add2b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nregressor = LinearRegression()  \nregressor.fit(X_train, y_train) #training the algorithm\ny_pred = regressor.predict(X_test)\n\nprint('Mean Absolute Error_lng:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_lng:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_lng:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_lng:', r2_score(y_test, y_pred).round(3))\n\n## Linear Regression above##","e6f51c76":"ridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train) #training the algorithm\n\ny_pred = ridge.predict(X_test)\n\nprint('Mean Absolute Error_ridge:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_ridge:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_ridge:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_ridge:', r2_score(y_test, y_pred).round(3))\n\n## Ridge Regression above##","68e4c0a8":"clf = Lasso(alpha=0.1)\n\nclf.fit(X_train, y_train) #training the algorithm\n\ny_pred = clf.predict(X_test)\n\nprint('Mean Absolute Error_lasso:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_lasso:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_lasso:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_lasso:', r2_score(y_test, y_pred).round(3))\n\n## Lasso Regression above##","e5481310":"logreg = LogisticRegression(solver = 'lbfgs')\n# fit the model with data\nlogreg.fit(X_train,y_train)\ny_pred=logreg.predict(X_test)\n\nprint('Mean Absolute Error_logreg:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_logreg:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_logreg:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_logreg:', r2_score(y_test, y_pred).round(3))\n\n## Logistics Regression above ##","5d26d1b5":"# Ridge Regression with Gridsearch ##\nfrom sklearn.model_selection import GridSearchCV\n\nparameters= {'alpha':[50,75,100,200, 230, 250], 'random_state':[5,10,20,50,], 'max_iter':[0.1,0.5,1,2,3,5]}\n\ngrid = GridSearchCV(ridge, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint (\"Best_Score_Ridge : \", grid.best_score_)\nprint('best_para_Ridge:', grid.best_params_)","315794c1":"# Lasso Regression with Gridsearch ##\nfrom sklearn.model_selection import GridSearchCV\n\nparameters= {'alpha':[200, 230, 250,265, 270, 275, 290, 300], 'random_state':[2,5,10,20,50,], 'max_iter':[5,10,15,20,30,50,100]}\n\ngrid = GridSearchCV(clf, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint (\"Best_Score_Lasso : \", grid.best_score_)\nprint('best_para_Lasso:', grid.best_params_)","1749f808":" # create regressor object \nrfe = RandomForestRegressor(n_estimators = 100, random_state = 42) \n  \n# fit the regressor with x and y data \nrfe.fit(X, y)   \ny_pred=rfe.predict(X_test)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('r2_score_RFE:', r2_score(y_test, y_pred).round(3))","716099fe":"ABR = AdaBoostRegressor(n_estimators = 100, random_state = 42) \n  \n# fit the regressor with x and y data \nABR.fit(X, y)   \ny_pred=ABR.predict(X_test)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('r2_score_ABR:', r2_score(y_test, y_pred).round(3))","b860b3a6":"Now we have 31 columns with equal data i.e. 102894","18a39896":"Country Has 488 missing Values, Agent has 16340 missing value & company has 112593 missing value","11699e47":"As company has maximum missing data lets drop that column\nAslo drop all the rows that have NaN in them as per above code","f259bbfe":"Let's now use Regression modles to check the best one.","0edb6adb":"Lets now check the unique values in each column","5c3dfd66":"with the above code line we have converted object values to integer values of 0 & 1\nWith below codes we will convert all the object type data into integer values which machine can read","c1b21116":"Our Target is y with previous_cancellations, & X contains all the data except previous_cancellation\nwith below codes we will train_test_split the data","5e721461":"Agent, Company, country  have some missing data, ","0c465d45":"We have converted strings and object data into machine readable format"}}