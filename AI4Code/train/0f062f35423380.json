{"cell_type":{"376d9ffa":"code","e57ef61d":"code","5c3c509d":"code","39f9a4c7":"code","a3ad979b":"code","5113e52e":"code","317c8002":"code","66c257dd":"code","6efef03c":"code","aaae6575":"code","b0812232":"code","744f2587":"code","eab82168":"code","073d2ed5":"code","89e73117":"code","a2e93db4":"code","8c3d1701":"code","206604f5":"code","d5b477c8":"code","1173015c":"code","24b3f48c":"code","0e41df61":"code","dbc6d2c1":"code","d90cad8c":"code","3785d554":"code","7e26e4f9":"code","7bdd2d4c":"code","2895e016":"code","73c0ccba":"code","f53f4437":"code","8f547b85":"code","eaf6ac92":"code","8f7700bb":"code","d6bb5d3b":"code","2d7d7a0d":"code","c4ec1fa3":"code","c9043482":"code","db26aa11":"code","9afcae55":"code","fd117ba9":"code","45ab4281":"code","7a37bcd6":"code","2f8c0df0":"code","668e9f89":"markdown","08732c76":"markdown","133d1c4a":"markdown","150ebc5b":"markdown","d8432596":"markdown","cc8c9ef2":"markdown","0b339553":"markdown","41fdbba8":"markdown","a3b66b22":"markdown","7249d8e0":"markdown","5007696e":"markdown","df60bc85":"markdown","b47e4f93":"markdown","c0eb42b4":"markdown","532ab830":"markdown","6b257a1a":"markdown","603a33ee":"markdown","fe1473f5":"markdown","3d84582f":"markdown","bc2a3503":"markdown","f52f597d":"markdown","9cb6cb3e":"markdown","972cf780":"markdown","2ae5574b":"markdown"},"source":{"376d9ffa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e57ef61d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5c3c509d":"data3=pd.read_csv('..\/input\/big-mart-sales-prediction\/Train.csv')\ndata1=pd.read_csv('..\/input\/big-mart-sales-prediction\/Test.csv')\nprint(data3)\nprint(data1)","39f9a4c7":"data3.isnull().sum()","a3ad979b":"data3.describe()","5113e52e":"corr_matrix=data3.corr()\ncorr_matrix['Item_Outlet_Sales']","317c8002":"data3.Item_Fat_Content=data3.Item_Fat_Content.replace('LF','Low Fat')\ndata3.Item_Fat_Content=data3.Item_Fat_Content.replace('reg','Regular')\ndata3.Item_Fat_Content=data3.Item_Fat_Content.replace('low fat','Low Fat')\n","66c257dd":"data3['Item_Weight'].fillna(data3['Item_Weight'].mean(), inplace=True)","6efef03c":"data3['Outlet_Size']=data3['Outlet_Size'].replace(np.nan,'Medium' )","aaae6575":"data3.isnull().sum()","b0812232":"fig,axes=plt.subplots(1,1,figsize=(12,8))\nsns.scatterplot(x='Item_MRP',y='Item_Outlet_Sales',hue='Item_Fat_Content',size='Item_Weight',data=data3)","744f2587":"fig,axes=plt.subplots(3,1,figsize=(15,12))\nsns.scatterplot(x='Item_Visibility',y='Item_Outlet_Sales',hue='Item_MRP',ax=axes[0],data=data3)\nsns.boxplot(x='Item_Type',y='Item_Outlet_Sales',ax=axes[1],data=data3)\nsns.boxplot(x='Outlet_Identifier',y='Item_Outlet_Sales',ax=axes[2],data=data3)","eab82168":"fig,axes=plt.subplots(2,2,figsize=(15,12))\nsns.boxplot(x='Outlet_Establishment_Year',y='Item_Outlet_Sales',ax=axes[0,0],data=data3)\nsns.boxplot(x='Outlet_Size',y='Item_Outlet_Sales',ax=axes[0,1],data=data3)\nsns.boxplot(x='Outlet_Location_Type',y='Item_Outlet_Sales',ax=axes[1,0],data=data3)\nsns.boxplot(x='Outlet_Type',y='Item_Outlet_Sales',ax=axes[1,1],data=data3)","073d2ed5":"from sklearn.preprocessing import LabelEncoder \n  \nle = LabelEncoder() \nle1=  LabelEncoder()\ndata3['Item_Fat_Content']= le.fit_transform(data3['Item_Fat_Content']) \ndata3['Item_Type']=le.fit_transform(data3['Item_Type'])\ndata3['Outlet_Identifier']=le.fit_transform(data3['Outlet_Identifier'])\ndata3['Outlet_Location_Type']=le.fit_transform(data3['Outlet_Location_Type'])\ndata3['Outlet_Type']=le.fit_transform(data3['Outlet_Type'])\ndata3['Item_Identifier']= le.fit_transform(data3['Item_Identifier']) \ndata3['Outlet_Size']= le1.fit_transform(data3['Outlet_Size']) ","89e73117":"plt.figure(figsize=(16,6))\nsns.heatmap(data3.corr(), annot=True)","a2e93db4":"data3","8c3d1701":"y=data3['Item_Outlet_Sales']\ny","206604f5":"x=data3.drop(columns=['Item_Outlet_Sales'])\nx","d5b477c8":"Outlet_Type_pivot = data3.pivot_table(index='Item_Fat_Content', values=\"Item_Outlet_Sales\", aggfunc=np.sum)\nOutlet_Type_pivot.plot(kind='bar', color='GREEN',figsize=(5,5))\nplt.xlabel(\"Item_Fat_Content \")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Impact of Item_Fat_Content on Item_Outlet_Sales\")\nplt.xticks(rotation=0)\nplt.ticklabel_format(axis=\"y\", style=\"plain\")\nplt.show()","1173015c":"plt.figure(figsize=(10,5))\ntype2=data3.groupby(['Outlet_Type'])['Item_Outlet_Sales'].sum()\nstore_types=['Grocery Store', 'Supermarket Type1', 'Supermarket Type2', 'Supermarket Type3']\nplt.bar(store_types,type2, width=0.3,color='BLUE')\nplt.ticklabel_format(axis=\"y\", style=\"plain\")\nplt.xlabel('Outlet_Type')\nplt.ylabel('Item_Outlet_Sales')\nplt.title('Outlet Type vs Outlet Sales')\nplt.show()","24b3f48c":"plt.figure(figsize=(10,5))\ntype3 = data3.groupby(['Outlet_Size'])['Item_Outlet_Sales'].sum()\nsize = ['High', 'Medium', 'Small']\nplt.bar(size, type3, color='RED',width=0.3)\nplt.ticklabel_format(axis=\"y\", style=\"plain\")\nplt.xlabel('Outlet_Size')\nplt.ylabel('Item_Outlet_Sales')\nplt.title('Outlet Type vs Outlet Sales')\nplt.show()","0e41df61":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test=train_test_split(x,y, test_size=0.25)","dbc6d2c1":"X_train.shape , X_test.shape","d90cad8c":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(X_train,Y_train)","3785d554":"from sklearn.metrics import mean_squared_error\npredict_lr=lr.predict(X_test)\nmse=mean_squared_error(Y_test,predict_lr)\nlr_score=np.sqrt(mse)\nlr_score","7e26e4f9":"from sklearn.linear_model import Ridge\nr=Ridge(alpha=0.05,solver='cholesky')\nr.fit(X_train,Y_train)\npredict_r=r.predict(X_test)\nmse=mean_squared_error(Y_test,predict_r)\nr_score=np.sqrt(mse)\nr_score","7bdd2d4c":"from sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor()\ndtr.fit(X_train,Y_train)\npredict_r=dtr.predict(X_test)\nmse=mean_squared_error(Y_test,predict_r)\ndtr_score=np.sqrt(mse)\ndtr_score","2895e016":"from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf.fit(X_train,Y_train)\npredict_r=rf.predict(X_test)\nmse=mean_squared_error(Y_test,predict_r)\nrf_score=np.sqrt(mse)\nrf_score","73c0ccba":"from sklearn.ensemble import GradientBoostingRegressor\ngbr=GradientBoostingRegressor()\ngbr.fit(X_train,Y_train)\np=gbr.predict(X_test)\ngb_score=mean_squared_error(Y_test,p)\ngb_score=np.sqrt(gb_score)\ngb_score","f53f4437":"name=['Linear Regression','Ridge Regression',\n     'Decision Tree Regression','Random Forest',\n     'Gradient Boost']","8f547b85":"go=pd.DataFrame({'RMSE':[lr_score,r_score,dtr_score,rf_score,gb_score]},index=name)","eaf6ac92":"\ngo.RMSE.sort_values()","8f7700bb":"sns.regplot(Y_test, p)","d6bb5d3b":"data1.isnull().sum()","2d7d7a0d":"data1.Item_Fat_Content=data1.Item_Fat_Content.replace('LF','Low Fat')\ndata1.Item_Fat_Content=data1.Item_Fat_Content.replace('reg','Regular')\ndata1.Item_Fat_Content=data1.Item_Fat_Content.replace('low fat','Low Fat')\ndata1['Item_Weight'].fillna(data1['Item_Weight'].mean(), inplace=True)\ndata1['Outlet_Size']=data1['Outlet_Size'].replace(np.nan,'Medium' )\ndata1.isnull().sum()","c4ec1fa3":"data1['Item_Fat_Content']= le.fit_transform(data1['Item_Fat_Content']) \ndata1['Item_Type']=le.fit_transform(data1['Item_Type'])\ndata1['Outlet_Identifier']=le.fit_transform(data1['Outlet_Identifier'])\ndata1['Outlet_Location_Type']=le.fit_transform(data1['Outlet_Location_Type'])\ndata1['Outlet_Type']=le.fit_transform(data1['Outlet_Type'])\ndata1['Item_Identifier']= le.fit_transform(data1['Item_Identifier']) \ndata1['Outlet_Size']= le1.fit_transform(data1['Outlet_Size']) ","c9043482":"data1","db26aa11":"predict=gbr.predict(data1)\npredict","9afcae55":"sample=pd.read_csv('..\/input\/big-mart-sales-prediction\/Submission.csv')","fd117ba9":"sample.head()","45ab4281":"del sample['Item_Outlet_Sales']","7a37bcd6":"df=pd.DataFrame({'Item_Outlet_Sales':predict})\ncorr_ans=pd.concat([sample,df],axis=1)\ndel corr_ans['Unnamed: 0']\ncorr_ans","2f8c0df0":"submit=corr_ans.to_csv('correct.csv',index=None)","668e9f89":"**WE SORT UP THE RMSE VALUES OF ALL THE MODELS USED**","08732c76":"**RANDOM FOREST REGRESSOR**","133d1c4a":"**HEATMAP**","150ebc5b":"# LET'S UNDERSTAND TRAINING DATA****","d8432596":"**FROM ABOVE WE FIND OUT THAT GRADIEN BOOSTING REGRESSOR GIVES THE LOWEST RMSE**","cc8c9ef2":"***WE CAN SEE Item_MRP IS CORRELATED TO Item_Outlet_Sales AND REST OTHERS DOES NOT MATTER MUCH***","0b339553":"**WE PLOT REGRESSION LINE **","41fdbba8":"**THERE MUST BE SOME KIND OF TYPO IN tem_Fat_Content AS SAME THING IS WRITTEN IN DIFFERENT WAYS  **","a3b66b22":"**DECISION TREE REGRESSOR**","7249d8e0":"**SPLITTING OF TRAIN AND TEST DATA WITH TEST SIZE OF 25%**","5007696e":"**RIDGE**","df60bc85":"CHECK FOR NULL VALUES","b47e4f93":"**AS WE CAN SEE THAT Item_Weight  AND Outlet_size CONTAINS NULL VALUES, WE NEED TO GET RID OF IT**","c0eb42b4":"**IMPACT OF OUTLET TYPE ON SALES**","532ab830":"**NOW WE EXPLORE OTHER COLUMNS**","6b257a1a":"**AS MODEL CAN TAKE INTEGERS AS INPUT, WE CAN DO LABEL ENCODING FOR THE COLUMNS CONTAINING STRING VALUES**","603a33ee":"**GRADIENT BOOSTING REGRESSOR**","fe1473f5":"**IMPACT OF OUTLET SIZE ON OUTLET SALES**","3d84582f":"**FIRTS WE USE LINEAR REGRESSION MODEL**","bc2a3503":"**IMPACT OF Item_Fat_Content ON OUTLET SALES**","f52f597d":"# STATISTICAL DESCRIPTION OF DATA****","9cb6cb3e":"**SINCE ITEM WEIGHT IS HIGHLY CORRELATED WITH TARGET VARIABLE WE EXPLORE IT GRAPHICALLY**","972cf780":"**WE REPLACE NULL VALUES IN Item_Weight WITH MEAN AND Outlet_Size WITH MEDDIUM**","2ae5574b":"**NOW WE APPLY THE MODEL TO THE TSET DATA PROVIDED BUT WE NEED TO DO ALL FORMS OF PREPROCESSING AS WE DID IN THE TRAIN DATA PROVIDED**"}}