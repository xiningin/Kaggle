{"cell_type":{"1e683005":"code","81aca51e":"code","5a1d48cf":"code","ef077937":"code","016040b7":"code","89972fe5":"code","74e35495":"code","927ba714":"code","c4574b4c":"code","5d4cb84f":"code","1930353f":"code","8af57b69":"code","2e3a6ddf":"code","ffbb26cf":"code","eb03719e":"code","77b14932":"code","c5fdd152":"code","abd82eba":"code","c1139fdb":"code","7abf523a":"code","df6083f9":"code","33f64559":"code","e64a3b1e":"code","20e172f6":"code","19e14f39":"code","9ebdf8b9":"code","01e1cd1d":"code","752d9670":"code","441a97c7":"code","214294bc":"code","2105fd0c":"code","35649129":"code","b2d0fcca":"code","6efc0484":"code","8a64a276":"code","647d9415":"code","06f844f2":"code","44e4daa6":"code","d4bd21db":"code","6d3ce470":"code","5f067635":"code","1745aea7":"code","f9ff4abe":"code","9a97e4ea":"code","f00766a8":"code","9ad950be":"code","30934c32":"code","8317ef4a":"code","ef17483d":"code","c09a5342":"code","1a930f4e":"code","7061e7ad":"code","371c76bd":"code","7a00912e":"code","8e52b8f9":"code","c1752107":"code","ae398c76":"code","d697e603":"code","b88795f8":"code","7ab9301b":"code","780a07e1":"code","bf613c43":"code","44d40890":"code","b1cbb5ec":"code","9e7dfaa6":"code","ae4901fc":"code","66e077aa":"code","b49a4d53":"code","f694a88b":"code","d00f4356":"code","6681d8ff":"code","e267eeb8":"code","39ed0ea5":"code","9459c969":"markdown","84a5f3bf":"markdown","c0ed6738":"markdown","20ea249a":"markdown","e4adbc8d":"markdown","58089c1b":"markdown","68632bcb":"markdown","461fe55f":"markdown","966e2fd3":"markdown","80129047":"markdown","e700be6d":"markdown","ff6e7b7e":"markdown","d36c6a4b":"markdown","8f2aaeb8":"markdown","d33de3c4":"markdown","ec7aa577":"markdown","a0b626a2":"markdown","1095656e":"markdown","e59d7324":"markdown","fe95a4ab":"markdown","ff5dd300":"markdown","38bec65a":"markdown","75f31204":"markdown","6c003b44":"markdown","ce237ccc":"markdown","a4e04749":"markdown","617ecfff":"markdown","8978053d":"markdown"},"source":{"1e683005":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81aca51e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn import manifold\n\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\nfrom sklearn import decomposition\n\n\n\n\n%matplotlib inline","5a1d48cf":"train = pd.read_csv('..\/input\/prudential-life-insurance-assessment\/train.csv.zip')\ntest = pd.read_csv('..\/input\/prudential-life-insurance-assessment\/test.csv.zip')","ef077937":"# fonction donn\u00e9es manquantes\ndef missing(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Pourcent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return tt\nmissing(train)['Pourcent'].sort_values(ascending=False)\n# suppression des features donn\u00e9es manquantes\ntrain_modified = train[train.columns[train.isnull().mean() <= 0.75]]","016040b7":"# drop donn\u00e9es non renseign\u00e9es\ncols_with_missing = [col for col in train_modified.columns \n                                 if train_modified[col].isnull().any()]","89972fe5":"data = train_modified.copy()","74e35495":"train.head()","927ba714":"print(len(train.Product_Info_2.unique()))\ntrain.Product_Info_2.unique()","c4574b4c":"# encodage pour la variable cat\u00e9gorielle\nencoded_train = pd.get_dummies(train_modified)\nencoded_train.sample(2)","5d4cb84f":"# suppression des colonnes donn\u00e9es manquantes\ntrain_modified = encoded_train.drop(cols_with_missing, axis=1)","1930353f":"# selection de la variable cible pour la mod\u00e9lisation\ny=train_modified.Response","8af57b69":"# imputation des donn\u00e9es manquantes\nmy_imputer = SimpleImputer()\nimputed_data_train = my_imputer.fit_transform(train_modified)","2e3a6ddf":"# s\u00e9lection des variables pour la mod\u00e9lisation\ndf_features = train_modified.loc[:, train_modified.columns != 'Response']","ffbb26cf":"# formalisation et v\u00e9rification des dimensions avant mod\u00e9lisation\nfeatures=list(df_features.columns)\nX=train_modified[features]\nprint(X.shape)\nprint(y.shape)","eb03719e":"# configuation du mod\u00e8le\nBayes = MultinomialNB()\nBayes.fit(X,y)","77b14932":"# affichage comparatif\npredict_df=pd.DataFrame(data=Bayes.predict(X))\npredict_df.rename(columns={0:'Predicted'}, inplace=True)\npredict_df['Response']=y\npredict_df","c5fdd152":"# nombre des valeurs pour la variable pr\u00e9dite\npredict_df.Predicted.value_counts()","abd82eba":"# valeur des pr\u00e9dictions\nsns.countplot(data=predict_df, x='Predicted').set_title(\"Pr\u00e9diction pour chaque cat\u00e9gorie\")\n","c1139fdb":"# Comparaison pr\u00e9diction avec les valeurs r\u00e9elles\nfig, axes = plt.subplots(1,2,figsize=(16,6))\nfig.suptitle('Comparaison classes pr\u00e9dites vs classes r\u00e9elles')\nsns.countplot(ax=axes[0], data=predict_df, x='Predicted')\nsns.countplot(ax=axes[1], data=predict_df, x='Response')\nplt.show()","7abf523a":"#predict_df.countplot(x='predict_df', y=['Predicted','Response'], figsize=(10,5), grid=True)","df6083f9":"\"\"\"width = 0.3\nfig, ax = plt.subplots(figsize=(12,8))\nrects1 = ax.bar(x - width\/2, predict_df['Response'], width)\nrects2 = ax.bar(x + width\/2, predict_df['Predicted'], width)\n\nplt.title('Comparaison Response\/Predicted', fontsize = 20)\nplt.xlabel('Nombre', fontsize = 15)\nplt.ylabel('Cat\u00e9gories', fontsize = 15)\n\nax.set_ylim(top=1)\n\nplt.xticks(x, results_df.index)\nax.legend()\nplt.grid(linestyle='dotted')\nplt.show()\"\"\"","33f64559":"# diff\u00e9rence entre la variable pr\u00e9dite et Response\npredict_df['diff']=abs(predict_df.Predicted-predict_df.Response)\npredict_df.sample(5)","e64a3b1e":"# diff\u00e9rence de classe entre pr\u00e9diction et Response\npredict_df['diff'].value_counts()","20e172f6":"# quantit\u00e9 de donn\u00e9es diff\u00e9rence classes pr\u00e9diction\/r\u00e9elles\nsns.countplot(data=predict_df, x='diff').set_title(\"Classes d'\u00e9cart entre valeurs pr\u00e9dites et valeurs r\u00e9elles\")\n","19e14f39":"predict_df['diff'].value_counts(normalize=True)","9ebdf8b9":"data.head()","01e1cd1d":"data = data.drop('Product_Info_2', axis=1)","752d9670":"data.head()","441a97c7":"# suppression des donn\u00e9es non renseign\u00e9es\ncols_with_missing = [col for col in data.columns \n                                 if data[col].isnull().any()]","214294bc":"data = data.drop(cols_with_missing, axis=1)","2105fd0c":"y=data.Response","35649129":"features=list(data.columns)\nX=data[features]\nprint(X.shape)\nprint(y.shape)","b2d0fcca":"Bayes2 = MultinomialNB()\nBayes2.fit(X,y)","6efc0484":"# affichage comparatif\npredict2=pd.DataFrame(data=Bayes2.predict(X))\npredict2.rename(columns={0:'Predicted'}, inplace=True)\npredict2['Response']=y\npredict2","8a64a276":"# nombre des valeurs pour la variable pr\u00e9dite\npredict_df.Predicted.value_counts() ","647d9415":"# valeur des pr\u00e9dictions\nsns.countplot(data=predict2, x='Predicted').set_title(\"Pr\u00e9diction pour chaque cat\u00e9gorie\")\nplt.grid(linestyle='dotted')\nplt.show()","06f844f2":"# comparaison du mod\u00e8le avec la valeurs r\u00e9elles\nfig, axes = plt.subplots(1,2,figsize=(16,6))\nfig.suptitle('Comparaison classes pr\u00e9dites vs classes r\u00e9elles')\nsns.countplot(ax=axes[0], data=predict2, x='Predicted')\nsns.countplot(ax=axes[1], data=predict2, x='Response')\nplt.show()","44e4daa6":"# diff\u00e9rence entre la variable pr\u00e9dite et Response\npredict2['diff']=abs(predict2.Predicted-predict2.Response)\npredict2.sample(5)","d4bd21db":"# diff\u00e9rence de classe entre pr\u00e9diction et Response\npredict2['diff'].value_counts()","6d3ce470":"# quantit\u00e9 de donn\u00e9es diff\u00e9rence classes pr\u00e9diction\/r\u00e9elles\nsns.countplot(data=predict2, x='diff').set_title(\"classes d'\u00e9cart entre valeurs pr\u00e9dites et valeurs r\u00e9elles\")\nplt.grid(linestyle='dotted')\nplt.show()","5f067635":"# pourcentage de classes \u00e9cart entre pr\u00e9diction et 'Response'\npredict2['diff'].value_counts(normalize=True)\n","1745aea7":"# affichage pourcentage camenbert\n#predict2.plot(kind='pie', y = 'diff', legend = True)","f9ff4abe":"#plot = predict2.plot.pie(subplots=True, figsize=(8, 8))\n","9a97e4ea":"# matrice de confusion\nconfusion_matrix=confusion_matrix(predict2.Response, predict2.Predicted)","f00766a8":"print(confusion_matrix)","9ad950be":"# affichage du rapport de la matrice de confusion\nprint(classification_report(predict2.Response, predict2.Predicted))","30934c32":"y_actu=predict2.Response\ny_pred=predict2.Predicted","8317ef4a":"y_actu=pd.Series(predict2.Response, name='R\u00e9elle')\ny_pred=pd.Series(predict2.Predicted, name='Pr\u00e9dite')\ndf_confusion=pd.crosstab(y_actu, y_pred)","ef17483d":"df_confusion","c09a5342":"# normalisation de la matrice de confusion\ndf_conf_norm = df_confusion \/ df_confusion.sum(axis=1)\ndf_conf_norm","1a930f4e":"def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.Reds):\n    plt.matshow(df_confusion, cmap=cmap)\n    plt.title('Matrice de confusion')\n    plt.colorbar()\n    tick_marks = np.arange(len(df_confusion.columns))\n    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n    plt.yticks(tick_marks, df_confusion.index)\n    #plt.tight_layout()\n    plt.ylabel(df_confusion.index.name)\n    plt.xlabel(df_confusion.columns.name)\n    plt.show()","7061e7ad":"# heatmap matrice de confusion\nplot_confusion_matrix(df_confusion)","371c76bd":"# heatmap matrice de confusion normalis\u00e9e\nplot_confusion_matrix(df_conf_norm)","7a00912e":"# cr\u00e9ation d'un pipeline: \u00e9vite la fuite de donn\u00e9es\ndef define_preprocessor(X):\n   \n    # Pipeline features cat\u00e9gorielles\n    categorical_transformer = Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), # simple imputation \n            ('target_encoder', TargetEncoder()), \n            ('scaler', StandardScaler()), # standardizsation apres encodage\n            ])\n    \n    # pipeline features num\u00e9riques\n    numeric_transformer = Pipeline(steps=[\n            ('imputer', IterativeImputer(max_iter=10)), \n            ('scaler', StandardScaler()), # standardisation\n             ])\n\n    # pipelines features num\u00e9riques et cat\u00e9gorielles\n    preprocessor = ColumnTransformer(transformers=[\n            ('cat', categorical_transformer, list(X.select_dtypes(include=['category', 'bool']).columns)),\n            ('num', numeric_transformer, list(X.select_dtypes(include='number').columns)),\n            ])\n    \n    return preprocessor","8e52b8f9":"# fonction pr\u00e9processing pour le SNE\ndef preprocessing_tSNE(dataframe, target_name='TARGET'):\n    \n    X = dataframe.copy()\n\n    # suppression lignes ou il manque la valeur cible\n    X = X.dropna(subset=[target_name])\n\n    # d\u00e9finition variable cible\n    y = X[target_name]\n\n    #\u00a0retire variable cible des feautures interpr\u00e9t\u00e9es\n    X = X.drop(columns=[target_name])\n\n    #\u00a0applique la fonction de pr\u00e9processing\n    preprocessor = define_preprocessor(X)\n\n    #\u00a0applique process\n    X_std = preprocessor.fit_transform(X, y)\n    \n    return (X_std, y)","c1752107":"# fonction SNE, permet aussi l'affichage\ndef tSNE(dataframe, target_name='TARGET'):\n    \n    # tritement pour tSNE\n    (X_std, y) = preprocessing_tSNE(dataframe, target_name)\n\n    # Instanciation tSNE\n    tsne = manifold.TSNE(n_components=2,\n                         perplexity=30,\n                         n_iter=300,\n                         init='pca', # initialisation avec une PCA\n                         random_state=0\n                        )\n\n    # Applying tSNE\n    X_projected = tsne.fit_transform(X_std) \n    \n    # Affichage\n    plt.figure(figsize=(14,8))\n\n    # limites graphe\n    plt.xlim(X_projected[:,0].min()*1.1, X_projected[:,0].max()*1.1)\n    plt.ylim(X_projected[:,1].min()*1.1, X_projected[:,1].max()*1.1)\n\n    # d\u00e9finition des axes\n    plt.title(\"t-SNE\\n\", fontsize=20)\n    plt.xlabel(\"t-SNE feature 1\")\n    plt.ylabel(\"t-SNE feature 2\")\n\n    # Def nuages de points\n    sc = plt.scatter(X_projected[:,0], # x\n                 X_projected[:,1], #y\n                 c=y,\n                 cmap=plt.cm.get_cmap('RdYlGn_r'), # couleur\n                 marker='.'\n        )\n    \n    # configuration et \u00e9chelle\n    cbar = plt.colorbar(sc)\n    cbar.ax.get_yaxis().set_ticks([])\n    cbar.ax.get_yaxis().labelpad = 15\n    cbar.set_label(target_name, rotation=90)","ae398c76":"# affichage\ntSNE(data, target_name='Response')","d697e603":"# Preprocessing  ACP\ndataframe = data\ntarget_name = 'Response'\n(X_std, y) = preprocessing_tSNE(dataframe, target_name)\n\n# Calcul des composantes principales\n\nn_components=2\npca = decomposition.PCA(n_components=n_components)\npca.fit(X_std)\n\nprint(\"Pourcentage variance expliqu\u00e9e par composante:\", pca.explained_variance_ratio_)\nprint(\"Pourcentage total variance expliqu\u00e9e:\", pca.explained_variance_ratio_.sum()) #  somme cumul\u00e9e ","b88795f8":"# repr\u00e9sentation de l'ACP avec deux composantes\npca=PCA(n_components=2)\ncomponents=pca.fit_transform(X_std)\nfig = px.scatter(components, x=0, y=1, color=data.Response, title='Repr\u00e9sentation PCA 2 components')\nfig.show()","7ab9301b":"\nimport plotly.graph_objects as go\ncomponents=pca.fit_transform(X_std)\nfig=go.Scattergl(components, x=0, y=1, color=data.Response, title='Repr\u00e9sentation PCA 2 components')\n","780a07e1":"# repr\u00e9sentation de l'ACP avec 3 composantes\npca = PCA(n_components=3)\ncomponents = pca.fit_transform(X_std)\ntotal_var = pca.explained_variance_ratio_.sum() * 100\nfig = px.scatter_3d(\n    components, x=0, y=1, z=2, color=data.Response,\n    title='PCA avec 3 composantes\\nTotal Explained Variance: {}%'.format(total_var),\n    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n)\nfig.show()","bf613c43":"# fonction explicative des valeur propres pour PCA\ndef display_scree_plot(X_std):\n    pca = decomposition.PCA()\n    pca.fit(X_std)\n    scree = pca.explained_variance_ratio_*100\n    \n    plt.bar(np.arange(len(scree))+1, scree)\n    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n    plt.xlabel(\"Quantit\u00e9 de composantes\")\n    plt.ylabel(\"pourcentage de variance cumul\u00e9e\")\n    plt.title(\"Etude du seuil de variance en fonction du nombre de composantes pour la PCA\", fontsize=15)\n    plt.grid(linestyle='dotted')\n    plt.show(block=False)","44d40890":"# affichage valeurs propres PCA\ndisplay_scree_plot(X_std)","b1cbb5ec":"# fonction donne les composantes principales de l'ACP, jusqu'au seuil de variance\ndef PCA_features_reduction(X_std, var_threshold=0.9): \n    # PCA\n    pca = decomposition.PCA()\n    pca.fit(X_std)\n    \n    # ratio de variance expliqu\u00e9 pour chaque composante principale\n    scree = pca.explained_variance_ratio_\n    # rend le nombre de composants principaux pour atteindre les seuils de variance\n    mask = scree.cumsum() > var_threshold\n    nb_selected_features = len(scree[~mask]) + 1\n    print(\"Nombre de features selectionn\u00e9es:\", nb_selected_features)\n    \n    #\u00a0Calcul du ratio\n    explained_variance_sum = scree.cumsum()[nb_selected_features-1]\n    print(\"Valeur cumul\u00e9e de variance expliqu\u00e9e:  {:.2f}%\".format(explained_variance_sum*100))\n    \n    # projection sur les 1ers composant\n    X_projected = pca.transform(X_std)[:,:nb_selected_features]\n    \n    return X_projected","9e7dfaa6":"X_projected = PCA_features_reduction(X_std, var_threshold=0.9)\nX_projected.shape","ae4901fc":"train_modified2 = train[train.columns[train.isnull().mean() <= 0.75]]\ntrain_modified2 = train.drop(cols_with_missing, axis=1)\n\ntrain_modified2 = train_modified2.loc[:, train_modified2.columns != 'Response']\ntrain_modified2 = train_modified2.loc[:, train_modified2.columns != 'Product_Info_2']\n","66e077aa":"train_modified2","b49a4d53":" df_features2 = train_modified2.loc[:, train_modified2.columns != 'Response']","f694a88b":"features2=list(df_features2.columns)\nX2=train_modified2[features2]\nprint(X2.shape)\nprint(y.shape)","d00f4356":"'''Bayes2 = MultinomialNB()\nBayes2.fit(X2,y)'''","6681d8ff":"from sklearn.mixture import BayesianGaussianMixture\nBayes_mix = BayesianGaussianMixture()\nBayes_mix.fit(X,y)\n\n","e267eeb8":"Bayes_mix.fit_predict((X,y))","39ed0ea5":"predict_mix=pd.DataFrame(data=Bayes_mix.fit_predict(X))\npredict_mix.rename(columns={0:'Predicted'}, inplace=True)\npredict_mix['Response']=y\npredict_mix","9459c969":"<a id=\"1\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Import des librairies","84a5f3bf":"L'objectif de ce notebook est de tester l'efficacit\u00e9 d'un mod\u00e8le Bay\u00e9sien pour pr\u00e9dire la cat\u00e9gorie \u00e0 laquelle une personne sera associ\u00e9e en fonction des information qui le caract\u00e9risent.\n<br>\nCe notebook fait suite a l'analyse exploratoire faite au lien suivant: https:\/\/www.kaggle.com\/alexdarge\/approche-bay-sienne","c0ed6738":"# Tests","20ea249a":"<a id=\"9\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Tests infructueux","e4adbc8d":"<a id=\"4\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## S\u00e9lection des variables pour la mod\u00e9lisation","58089c1b":"# R\u00e9duction avec SNE\/ACP","68632bcb":"<a id=\"6\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Mod\u00e8le sans la variable Product_Info_2","461fe55f":"<a id=\"2\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Nettoyage des donn\u00e9es","966e2fd3":"# Pr\u00e9paration avant mod\u00e9lisation","80129047":"<a id=\"8\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## t-SNE","e700be6d":"t-SNE est un algorithme de r\u00e9duction de dimensions bas\u00e9 sur de l'apprentissage non supervis\u00e9. Il est utilis\u00e9 pour de la visualisation de donn\u00e9es ayant beaucoup de descripteurs.\n\nIl permet de repr\u00e9senter les donn\u00e9es dans un nouvel espace interpr\u00e9table (2 ou 3 dimensions)\nLes donn\u00e9es proches dans l'espace original auront une probabilit\u00e9 \u00e9lev\u00e9e d'avoir une repr\u00e9sentation proche dans le nouvel espace et \u00e0 l'inverse les donn\u00e9es \u00e9loign\u00e9es ont une faible probabilit\u00e9 d'avoir une repr\u00e9sentation proche dans le nouvel espace.","ff6e7b7e":"Le seuil de 90% de variance expliqu\u00e9e est atteint avec 78 composantes principales.\nOn avait initialement pr\u00e8s de 120 variables.","d36c6a4b":"On souhaite pr\u00e9dire les valeurs de Response avec un mod\u00e8le Bay\u00e9sien","8f2aaeb8":"<a id=\"3\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Encodage de la variable cat\u00e9gorielle","d33de3c4":"# Feuille de route\n## Fait:\n* Bay\u00e9sien naif sur l'ensemble des variables\n* Bay\u00e9sien sur les variables num\u00e9riques\n* R\u00e9duction dimensionnelle avec PCA et t-SNE\n* Repr\u00e9sentation \n\n## A faire:\n* Identifier une m\u00e9trique de contr\u00f4le afin de comparer avec d'autres mod\u00e8les pr\u00e9dictifs\n* Pr\u00e9diction avec les features r\u00e9duites\n* Am\u00e9liorer la performance du mod\u00e8le","ec7aa577":"<a id=\"5\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Un premier r\u00e9sultat","a0b626a2":"On n'obtient que 30% de r\u00e9sultat exact.\nOn peut expliquer cela \u00e0 cause de l'encodage de la variable cat\u00e9gorielle qui cr\u00e9\u00e9 beaucoup de variables num\u00e9rique et qui peut biaiser la pr\u00e9diction.\n<br>\nOn constate cependant qu'en cumul\u00e9 on obtient pr\u00e8s de 72% de pr\u00e9cision \u00e0 deux classes d'\u00e9cart et 48% \u00e0 une classe d'\u00e9cart.\n\nOn ne prendra pas en consid\u00e9ration cette variable dans le test suivant.","1095656e":"#### Bayes Gaussian Mixture","e59d7324":"On a r\u00e9ussi \u00e0 am\u00e9liorer la performance de notre pr\u00e9diction, en effet elle \u00e9tait de 30% dans notre premier r\u00e9sultat et est dor\u00e9navent de 36%.\n<br>\nDe plus en cumul\u00e9 \u00e0 deux classe d'\u00e9cart on obtient 83% de pr\u00e9cision. C'est pr\u00e8s de 11 points de pourcentage de plus que dans le mod\u00e8le pr\u00e9c\u00e9dent.","fe95a4ab":"On souhaite conna\u00eetre ces 78 composantes identifi\u00e9es par la PCA afin de refaire un mod\u00e8le pr\u00e9dictif sur celles-ci.","ff5dd300":"<a id=\"7\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Matrice de confusion","38bec65a":"On voit que la variable Product_Info_2 est cat\u00e9gorielle, on s'y int\u00e9resse en vue de l'encoder num\u00e9riquement","75f31204":"On veut d\u00e9terminer un nombre minimal de composantes \u00e0 partir duquel on peut consid\u00e9rer que l'\u00e9tude pr\u00e9dictive est fiable \u00e0 partir d'un certain seuil (que je d\u00e9finis ici \u00e0 90%).\nIl est important de normaliser les donn\u00e9es pour faire une PCA (pour la conservation de la distance vectorielle).\nLes donn\u00e9es fournies ont d\u00e9ja \u00e9t\u00e9 normalis\u00e9e il n'est donc pas n\u00e9cessaire de le faire ici. \n\nIl faudra n\u00e9anmoins faire attention aux outliers.","6c003b44":"# Plan\n<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Sommaire<\/h3>\n    \n<font size=+1><b>Feuille de route<\/b><\/font>\n    \n<font size=+1><b>Chargement des donn\u00e9es<\/b><\/font>\n* [Import des fichiers](#0)\n* [Import des librairies](#1)\n\n<font size=+1><b>Pr\u00e9paration avant mod\u00e9lisation<\/b><\/font>\n* [Nettoyage de donn\u00e9es](#2)\n* [Encodage de la variable cat\u00e9gorielle](#3)\n* [S\u00e9lection des variables pour mod\u00e9lisation](#4)\n\n    \n<font size=+1><b>Bay\u00e9sien na\u00eff<\/b><\/font>\n* [Une 1\u00e8re pr\u00e9diction](#5)\n* [Mod\u00e8le sans la variable Product_Info_2](#6)\n* [Matrice de confusion sur le 2\u00e8me mod\u00e8le](#7)\n \n        \n<font size=+1><b>R\u00e9duction dimensionnelles<\/b><\/font>\n* [t-SNE](#8)\n* [ACP](#9)\n\n    \n<font size=+1><b>Tests<\/b><\/font>\n* [Tests infructueux](#10)\n","ce237ccc":"# Bay\u00e9sien na\u00eff","a4e04749":"<a id=\"8\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## ACP","617ecfff":"<a id=\"0\"><\/a>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Sommaire<\/a>\n## Import des fichiers","8978053d":"On voit que la variable Product_Info_2 est d\u00e9finie comme une cat\u00e9gorie, elle prend 19 valeurs diff\u00e9rentes. Ces valeurs sont l'association d'une lettre et d'un chiffre. Pour l'interpr\u00e9ter num\u00e9riquement on doit l'encoder c'est \u00e0 dire cr\u00e9er des features suppl\u00e9mentaires (pour chacune des 19 valeurs). Ce variables seront des bool\u00e9ens qui indiquent quelle valeur de Product_Info_2 la personne a indiqu\u00e9.\n<br>\nPar exemple un si une personne est caracteris\u00e9e par la variable Product_Info_2 renseign\u00e9e comme: 'D3', alors l'encodage des variables encod\u00e9e sera comme suit: Product_Info_2_D3 vaudra 1 et tous les autres vaudront 0."}}