{"cell_type":{"f8c1ca24":"code","028ffe61":"code","3149f4f4":"code","81030393":"code","c51d39d3":"code","59cd9941":"markdown","c7b1e6d7":"markdown","8d9de560":"markdown","80e8959d":"markdown","173770b7":"markdown"},"source":{"f8c1ca24":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\nfrom keras.models import Model,Sequential\nfrom keras.layers import Dense,InputLayer,LeakyReLU\nfrom keras import backend as K\nfrom keras.optimizers import Optimizer\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.util.tf_export import tf_export\nfrom tensorflow import set_random_seed\n\nnp.random.seed(666)\nset_random_seed(666)","028ffe61":"def sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives \/ (possible_positives + K.epsilon())\n\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives \/ (possible_negatives + K.epsilon())\n\ndef binary_focal_loss(gamma=2., alpha=.6):\n    def binary_focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n        epsilon = K.epsilon()\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n    return binary_focal_loss_fixed\n\nclass Yogi(Optimizer):\n    def __init__(self,\n               lr=0.001,\n               beta_1=0.9,\n               beta_2=0.999,\n               epsilon=None,\n               decay=0.00000001,\n               amsgrad=False,\n               **kwargs):\n        super(Yogi, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.amsgrad = amsgrad\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [state_ops.assign_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (  # pylint: disable=g-no-augmented-assignment\n                1. \/ (1. + self.decay * math_ops.cast(self.iterations,\n                                                    K.dtype(self.decay))))\n\n        t = math_ops.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (\n            K.sqrt(1. - math_ops.pow(self.beta_2, t)) \/\n            (1. - math_ops.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1) for _ in params]\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            #v_t = (self.beta_2 * v) + (1. - self.beta_2) * math_ops.square(g) # from amsgrad\n            v_t = v - (1-self.beta_2)*K.sign(v-math_ops.square(g))*math_ops.square(g)\n            p_t = p - lr_t * m_t \/ (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(state_ops.assign(m, m_t))\n            self.updates.append(state_ops.assign(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(state_ops.assign(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {\n            'lr': float(K.get_value(self.lr)),\n            'beta_1': float(K.get_value(self.beta_1)),\n            'beta_2': float(K.get_value(self.beta_2)),\n            'decay': float(K.get_value(self.decay)),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad\n            }\n        base_config = super(Yogi, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n# callbacks\nmodel_ckpt = ModelCheckpoint('Pulstar_weights.hdf5',save_weights_only=True)\nreduce_lr = ReduceLROnPlateau(patience=6,factor=0.6,min_lr=1e-12,verbose=0)\nearly_stop = EarlyStopping(patience=16,verbose=0)","3149f4f4":"X = pd.read_csv('..\/input\/heart.csv')\ny = X.pop('target')\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.05)","81030393":"def build_model():\n    K.clear_session()\n    model = Sequential()\n    model.add(InputLayer(input_shape=(X.shape[1],)))\n    model.add(Dense(710, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss=binary_focal_loss(),optimizer=Yogi(lr=1e-4,epsilon=0.01),metrics=['accuracy',sensitivity,specificity])\n    return model\n\nmodel = build_model()\nmodel.fit(X_train, y_train, validation_split=0.4, batch_size=32, epochs=666,\n          callbacks=[model_ckpt,reduce_lr,early_stop],shuffle=False,verbose=0)","c51d39d3":"# isolated test data\npreds = model.predict(X_test)[:,0]\nroc_auc_score(y_test,preds)","59cd9941":"## data","c7b1e6d7":"## result","8d9de560":"# Probability of heart disease\nBased on 76 attributes.","80e8959d":"## imports","173770b7":"## neural network"}}