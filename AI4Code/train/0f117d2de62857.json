{"cell_type":{"1408fc74":"code","95fea38b":"code","1e796712":"code","daa40305":"code","4b2cb738":"code","fd9e68d4":"code","4b76cf07":"code","ca8c018a":"code","3ce07d71":"code","4136498e":"code","f767664a":"code","db784874":"code","4141b044":"code","3d5ab478":"code","b0016858":"code","a2e48803":"code","470f347c":"code","99e79087":"code","e2538cad":"code","cde1601f":"code","6737acd4":"code","3595bc13":"code","608bc1d7":"code","7790f5b7":"code","779919e3":"code","1382b01f":"code","9f1b0a6e":"markdown","05cab92c":"markdown","01ea9774":"markdown","6eaaea49":"markdown","5056b16b":"markdown","30489dbf":"markdown","f79e0671":"markdown","4fb707d9":"markdown","b625607e":"markdown","9b7a4ad8":"markdown","69ff1da9":"markdown","c0251c77":"markdown","c82fce01":"markdown","dee63491":"markdown","9ce754d2":"markdown","29887413":"markdown"},"source":{"1408fc74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\nimport shap\n\nfrom numpy import interp\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, classification_report, precision_recall_curve\nfrom sklearn.impute import SimpleImputer\nfrom termcolor import colored\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom statsmodels.stats.contingency_tables import mcnemar\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","95fea38b":"# Function to plot a histogram that shows the number of NaN values for each column.\ndef plot_hist_nan(df):\n    \n    nan_df = pd.DataFrame(df.isna().sum().tolist(), df.columns.tolist()).reset_index()\n    nan_df.columns = ['column_name', 'total_nan']\n    nan_df['nan_perc'] = 100*round(nan_df['total_nan']\/len(df),3)\n    nan_df = nan_df.sort_values('total_nan', ascending=False)\n    \n    plt.figure(figsize=(20,15))\n    step = 25\n    j = 0\n    t_plots = math.ceil(len(nan_df) \/ step)\n\n    fig, axes = plt.subplots(t_plots, 1, figsize=(20,20))\n\n    for i in range(0,len(nan_df), step):\n        sns.barplot(x=\"nan_perc\", y=\"column_name\", data=nan_df[i:i+step], ax=axes[j])    \n        axes[j].set_ylabel('Columns', fontsize = 15)\n        axes[j].set_xlabel('NaN %', fontsize = 15)\n        axes[j].set_xticks([0,10,20,30,40,50,60,70,80,90,100], minor=False)\n        j = j + 1    \n        if j == t_plots:\n            break","1e796712":"# Function to plot a chart that shows the class distribution.\ndef plot_class_distribution(df: pd.DataFrame):\n    \n    values = df.groupby('SARS-Cov-2 exam result')['SARS-Cov-2 exam result'].count()\n    n_samples = df.shape[0]\n    \n    plt.figure(figsize=(10,6))\n    labels = ['Negative', 'Positive']\n    explode = (0, 0.0) \n    colors = ['#66b3ff','#ff9999']\n\n    plt.pie(values, colors = colors, autopct='%1.1f%%',\n        startangle=90, pctdistance=0.85, explode=explode)\n\n    plt.legend(labels,loc=1)\n\n    centre_circle = plt.Circle((0,0),0.20,fc='white')\n    fig = plt.gcf()\n    fig.gca().add_artist(centre_circle)  \n    plt.tight_layout()\n\n    fig.text(0.42, 0.5, \"{} samples\".format(n_samples), style='italic', fontsize=10)\n    plt.show()","daa40305":"# Function to plot a chart that shows ROC Curve.\ndef plot_roc_curve(results):\n        \n    plt.figure(figsize=(10,8))\n    mean_fpr = np.linspace(0, 1, 100)\n    tprs = []\n    i = 0\n    \n    colors = ['r','b','g']\n    \n    for idx,result in enumerate(results):\n    \n        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n        mean_tpr = np.mean(result.tprs, axis=0)\n        mean_tpr[-1] = 1.0\n        mean_auc = auc(mean_fpr, mean_tpr)\n        std_auc = np.std(result.aucs)\n        \n        plt.plot(mean_fpr, mean_tpr, color=colors[idx], label=result.model_name + ' (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n        \n        std_tpr = np.std(result.tprs, axis=0)\n        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n        \n        if i == 0:\n            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[idx], alpha=.2)\n        else:\n            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[idx], alpha=.2)\n        i = i + 1\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Chance', alpha=.8)\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate', size=12)\n    plt.ylabel('True Positive Rate', size=12)\n    plt.title('ROC CURVE')\n    plt.legend(loc=\"lower right\")    \n    plt.show()","4b2cb738":"# Function to plot the confusion matrix.\ndef plot_confusion_matrix(results):\n        \n    sns.set(font_scale = 1.6)\n    plt.figure(figsize=(12,10))\n    threshold = 0.5\n    index = 0\n        \n    for result in results:\n                            \n        cm = confusion_matrix(result.y_pred, result.y_test)\n        \n        labels = ['Negative', 'Positive']\n        ax = plt.subplot(2, 2, index+1)\n        sns.set_palette(\"PuBuGn_d\")\n        \n        if index == 0 or index == 2:\n            show_scale = False\n        else:\n            show_scale = True\n            \n        sum_0 =  cm.sum(axis=1)[0]\n        sum_1 = cm.sum(axis=1)[1]\n        \n        cm_aux = np.zeros((2,2))\n\n        cm_aux[0][0] = (cm[1][1]) #\/ sum_1\n        cm_aux[0][1] = (cm[1][0])\n        cm_aux[1][0] = (cm[0][1])\n        cm_aux[1][1] = (cm[0][0])\n        \n        sns.heatmap(cm_aux, annot=True, ax = ax, fmt=\"\", cmap=\"Blues\", cbar=False)\n        #sns.heatmap(cm_aux, annot=True, ax = ax, cmap=\"Blues\", cbar=False)\n        \n        ax.set_title(result.model_name)\n        ax.yaxis.set_ticklabels(['Positive', 'Negative'])\n        ax.xaxis.set_ticklabels(['Positive', 'Negative'])\n        \n        if index == 0 or index == 1:\n            ax.set_xlabel('');\n        else:\n            ax.set_xlabel('Predicted labels');\n            \n        if index == 1 or index == 3:\n            ax.set_ylabel(''); \n        else:\n            ax.set_ylabel('True labels')\n            \n        index = index + 1\n    \n    plt.show()","fd9e68d4":"def evaluate_model(model, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.DataFrame, y_test: pd.DataFrame):\n    \"\"\"\n    Used to evaluate a given model. Just an API wrapper.    \n    Returns the fitted model along with the predictions generated for the test set\n    \"\"\"\n    model.fit(X_train, y_train)\n    y_preds = model.predict(X_test)\n    y_preds_proba = model.predict_proba(X_test)\n    return model, y_preds, y_preds_proba","4b76cf07":"def generate_performance_stats(y_test, y_pred):    \n    target_names = ['Negative', 'Positive'] \n    cm = confusion_matrix(y_test, y_pred)        \n    print(\"Accuracy: {}\\n\".format(metrics.accuracy_score(y_test,y_pred)))\n    print(\"Confusion Matrix: \\n{}\\n\".format(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])))\n    print(\"Classification Report: \\n{}\\n\".format(classification_report(y_test, y_pred, target_names=target_names)))","ca8c018a":"# Function to perform K-fold Cross Validation.\ndef permoform_cv(df: pd.DataFrame, target: pd.DataFrame, models):\n        \n    results = []\n    mean_fpr = np.linspace(0, 1, 100)\n    models_predictions = {}\n\n    for model_alias in models:\n    \n        print(\"Model: {}\\n\".format(model_alias))\n        tprs = []\n        aucs = []\n        thresholds = []\n        y_preds = []\n        y_preds_prob = []\n        y_tests = []\n        model = models[model_alias]\n\n        i = 0\n        kf = KFold(n_splits=n_folds, random_state=13, shuffle=True)\n        model_predicted = []\n        model_gt = []\n    \n        for index in kf.split(df):\n\n            print(\"Fold[{}]\\n\".format(i+1))\n\n            X_train, X_test, y_train, y_test = df.iloc[index[0]], df.iloc[index[1]], target.iloc[index[0]], target.iloc[index[1]]            \n            model_fit, y_pred, y_pred_proba = evaluate_model(model, X_train, X_test, y_train, y_test)\n            \n            y_pred = y_pred_proba[:,1] > thresh\n            y_pred = y_pred.astype(int)  \n            model_predicted = np.concatenate((np.array(model_predicted),y_pred))\n            model_gt = np.concatenate((np.array(model_gt),y_test))\n            \n            generate_performance_stats(y_test, y_pred)                    \n\n            # Compute ROC curve and area the curve\n            fpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\n            prec, rec, tre = precision_recall_curve(y_test, y_pred_proba[:,1])\n            \n            tprs.append(interp(mean_fpr, fpr, tpr))\n            tprs[-1][0] = 0.0\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            thresholds.append(threshold)\n            \n            y_preds = np.append(y_preds, y_pred)\n            y_preds_prob = np.append(y_preds_prob, y_pred_proba[:,1])\n            y_tests = np.append(y_tests, y_test)\n            \n            i = i + 1\n    \n        generate_performance_stats(model_gt, model_predicted)\n\n        result = RESULT(model_alias, tprs, aucs, thresholds, y_preds, y_preds_prob, y_tests)\n        results.append(result)\n        models_predictions[model_alias] = (model_predicted,model_gt)\n        print(\"########################################################\\n\")\n    \n    return results, models_predictions","3ce07d71":"class RESULT(object):\n    \n    def __init__(self, model_name, tprs, aucs, thresholds, y_pred, y_pred_prob, y_test):\n        self.model_name = model_name\n        self.tprs = tprs\n        self.aucs = aucs\n        self.thresholds = thresholds\n        self.y_pred = y_pred\n        self.y_pred_prob = y_pred_prob\n        self.y_test = y_test","4136498e":"# Importing raw dataset\ndf_all = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')","f767664a":"print(\"The dataset has {} many rows and {} columns\".format(df_all.shape[0], df_all.shape[1]))","db784874":"# Look at the data\ndf_all.head(5)","4141b044":"df_filt = df_all.loc[((df_all['SARS-Cov-2 exam result'] == 'positive')\n                         | (df_all['Hematocrit'].notnull())\n                         | (df_all['Urine - Density'].notnull()))]","3d5ab478":"plot_hist_nan(df_filt)","b0016858":"# It will be maintaned the features with less than 90% of the missing values.\ndf = df_filt.loc[:, df_filt.isnull().mean() <= .9]","a2e48803":"print(\"The new dataset has {} many rows and {} columns\".format(df.shape[0], df.shape[1]))","470f347c":"# Class distribution for the SARS-Cov-2 exam result\nplot_class_distribution(df)","99e79087":"# The new dataset will only have numerical features. The target feature is converted to 0 or 1.\n\ndf_numeric = df.copy()\ndf_numeric = df_numeric.replace({'positive': '1', 'negative': '0', \n    'detected': '1', 'not_detected': '0',\n    'absent':'0', 'not_done': '9', 'present':'1',\n    'normal':'0','<1000':'1',\n    'clear':'1', 'cloudy':'2', 'altered_coloring':'3', 'lightly_cloudy':'4', 'N\u00e3o Realizado':'9',\n    'Ausentes':'0', 'Urato Amorfo --+': '1', 'Urato Amorfo +++':'2', 'Oxalato de C\u00e1lcio -++':'3', 'Oxalato de C\u00e1lcio +++':'4',\n    'light_yellow':'0', 'yellow':'1', 'orange':'3', 'citrus_yellow':'4'\n})\n\ndf_numeric = df_numeric.drop(['Patient ID'], axis=1)\ndf_numeric = df_numeric.astype(str).astype(float)","e2538cad":"# Drop the target columns related to task 2\ncols_task2 = ['Patient addmited to regular ward (1=yes, 0=no)', 'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n              'Patient addmited to intensive care unit (1=yes, 0=no)']\n\ndf_numeric = df_numeric.drop(cols_task2, axis = 1)","cde1601f":"# Predictive models\nmodels = {\n    'XGBoost': XGBClassifier(),\n    'RF': RandomForestClassifier(n_estimators=100,criterion='gini'),\n    'Logistic': LogisticRegression(),\n}","6737acd4":"cols = df_numeric.columns\ndf_numeric[cols] = df_numeric.filter(cols).fillna(df_numeric.mode().iloc[0])","3595bc13":"# Getting the target column and drop 'Patient ID' column\ny_train = df_numeric['SARS-Cov-2 exam result']\ndf_numeric = df_numeric.drop(['SARS-Cov-2 exam result'], axis = 1)","608bc1d7":"#K-Fold parameters\nthresh = 0.5\nk_fold_seed = 13\nn_folds = 10\nresults, models_predictions = permoform_cv(df_numeric, y_train, models)","7790f5b7":"plot_roc_curve(results)","779919e3":"plot_confusion_matrix(results)","1382b01f":"\nfor result in results:\n    print(\"Model: {}\\n\".format(result.model_name))\n    generate_performance_stats(result.y_pred, result.y_test)\n    print(\"###########################################################\\n\")","9f1b0a6e":"After the pre-processing, the data set become balanced.","05cab92c":"\n\n## Imports <a id='imports'><\/a>","01ea9774":"### Perform k-fold cross validation","6eaaea49":"### Confusion Matrix plot","5056b16b":"# CONTENTS\n* [Imports](#imports)\n* [Functions Definition](#functions_definition)\n* [Data Preprocess](#data_pre)\n* [K-Fold Cross Validation](#kfold_cv_baldata)","30489dbf":"It seems there are several features with NaN values. It will be checked the amount of missing data in each column.","f79e0671":"Most of the predictive models to be created do not handle missing values. Therefore, it will be used the simple inputation method.","4fb707d9":"### Class distribution for the SARS-Cov-2 exam result","b625607e":"## Data Preprocess <a id='data_pre'><\/a>","9b7a4ad8":"### ROC curve plot","69ff1da9":"## Main Contributions\n\n* The mais contribution of this kernel is to present a high precision in classifing both classes (positive\/negative) for the three machine learned techniques (Xgboost, Random Forest e Logistic Regression).\n\n* This is achived filtering the records of the patients that have values to the features relative to the blood and\/or urine exams.\n\n* This filtering resulted in a data base that contain 1091 records, being that 558 are positive and 533 are negative. Therefore, the created set is already balanced. \n\n","c0251c77":"### Performance stats for models","c82fce01":"## Functions definition <a id='functions_definition'><\/a>","dee63491":"The following code perform the registers filtering of the patients that contain values to the features relative to the blood and\/or urine exams, even as all the positive records.","9ce754d2":"## K-Fold Cross Validation<a id='kfold_cv_baldata'><\/a>","29887413":"All the created models obtain a high precision in classifing both classes (positive\/negative). This would really help identifying positive covid patients and also making sure that the hospital beds are available do to the great precision in identifying negative cases.\n"}}