{"cell_type":{"d88f5f68":"code","615679a5":"code","7ff70323":"code","853c82be":"code","e3c4f376":"code","a57c6aa4":"code","8a83f3e1":"code","329a2ed5":"code","3c1e2ec4":"code","4916d6a7":"code","b97d677b":"code","e1088b1e":"code","02c44273":"code","52337577":"code","4bd1de8c":"markdown","ddf05040":"markdown","64e4e01d":"markdown"},"source":{"d88f5f68":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport gc\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\n\nfrom keras.models import Model\n","615679a5":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission = submission.set_index('id')\n","7ff70323":"targets = pd.get_dummies(train['target'])","853c82be":"def custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss\n\ncce = tf.keras.losses.CategoricalCrossentropy()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=1e-05, patience=8, verbose=0,\n    mode='min', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.7, patience=2, verbose=0)","e3c4f376":"def get_model():\n    inputs = layers.Input(shape = (75,))\n    \n    embed = layers.Embedding(360, 8)(inputs)\n    embed = layers.Flatten()(embed)\n    \n    hidden = layers.Dropout(0.2)(embed)\n    hidden = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='selu', kernel_initializer=\"lecun_normal\"))(hidden)\n    \n    output = layers.Dropout(0.2)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='relu'))(output) \n    \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden, output]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(output) \n    output = layers.Dense(9, activation = 'softmax')(output)\n    \n    model = keras.Model(inputs=inputs, outputs=output, name=\"res_nn_model\")\n    \n    return model","a57c6aa4":"def model_NN_by_column():\n    inp3 = layers.Input(shape = (75,))\n    b = layers.Reshape((-1,1))(inp3)\n    b = layers.Embedding(360, 8,input_length = 75)(b)\n    b = layers.Flatten()(b)\n    b = layers.Dense(150, \n                    activation='relu', \n                    kernel_initializer='random_uniform',\n                    bias_initializer=initializers.Constant(0.1))(b)\n    b = layers.Dropout(0.3)(b)\n    b = layers.Dense(100, activation = 'relu')(b)\n    b = layers.Dropout(0.3)(b)\n    b = layers.Dense(50, activation = 'relu')(b)\n    output3 = layers.Dense(9, activation = 'softmax')(b)\n    model_by_col = Model(inp3,output3)\n    \n    return model_by_col","8a83f3e1":" def model_NN_by_row():\n    inp4 = layers.Input(shape = (75,))\n    c = layers.Embedding(360, 8, input_length = 256)(inp4)\n    c = layers.Flatten()(c)\n    c = layers.Dense(150, \n                       activation='relu',\n                       kernel_initializer='random_uniform',\n                       bias_initializer=initializers.Constant(0.1))(c)\n    c = layers.Dropout(0.3)(c)\n    c = layers.Dense(100, activation='relu')(c)\n    c = layers.Dropout(0.3)(c)\n    c = layers.Dense(50, activation = 'relu')(c)\n    output4 = layers.Dense(9, activation = 'softmax')(c)\n    model_by_r = Model(inp4,output4)\n    \n    return model_by_r","329a2ed5":"oof_NN_a = np.zeros((train.shape[0],9))\npred_NN_a = np.zeros((test.shape[0],9))\n\noof_NN_h = np.zeros((train.shape[0],9))\npred_NN_h = np.zeros((test.shape[0],9))\n\noof_NN_v = np.zeros((train.shape[0],9))\npred_NN_v = np.zeros((test.shape[0],9))\n\nNN_h_train_preds = []\nNN_h_test_preds = []\n\nNN_v_train_preds = []\nNN_v_test_preds = []\n\nNN_a_train_preds = []\nNN_a_test_preds = []\n\nN_FOLDS = 10\nSEED = 2021\nEPOCH = 50\n\n\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train,train.iloc[:,-1])):\n    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n\n    X_train = train.iloc[:,1:-1].iloc[tr_idx]\n    y_train = targets.iloc[tr_idx]\n    X_test = train.iloc[:,1:-1].iloc[ts_idx]\n    y_test = targets.iloc[ts_idx]\n\n    K.clear_session()\n\n    #================= NN ATTENTION MODEL =========\n    print(\"\\n-----Attention NN model Training----\\n\")\n\n    model_attention = get_model()\n\n    model_attention.compile(loss='categorical_crossentropy', \n                            optimizer = keras.optimizers.Adam(learning_rate=2e-4), \n                            metrics=custom_metric)\n    model_attention.fit(X_train, y_train,\n              batch_size = 256, epochs = EPOCH,\n              validation_data=(X_test, y_test),\n              callbacks=[es, plateau],\n              verbose = 0)\n\n    #================= NN MODELS ==================\n\n    print(\"\\n-----By column NN model Training----\\n\")\n\n    model_by_col = model_NN_by_column()\n\n    model_by_col.compile(loss='categorical_crossentropy', \n                         optimizer = keras.optimizers.Adam(learning_rate=2e-4), \n                         metrics=custom_metric)\n\n    model_by_col.fit(X_train,y_train,\n            validation_data=(X_test,y_test),\n            epochs=EPOCH,\n            verbose=0,\n            batch_size = 256,\n            callbacks=[es,plateau])\n\n    print(\"\\n-----By row NN model Training----\\n\")\n\n    model_by_r = model_NN_by_row()\n\n    model_by_r.compile(loss='categorical_crossentropy', \n                        optimizer = keras.optimizers.Adam(learning_rate=2e-4), \n                        metrics=custom_metric)\n\n    model_by_r.fit(X_train,y_train,\n            validation_data=(X_test,y_test),\n            epochs=EPOCH,\n            verbose=0,\n            batch_size = 256,\n            callbacks=[es,plateau])\n\n    #--------By row NN ATTENTION Model prediction----\n\n    pred_a = model_attention.predict(X_test) \n    oof_NN_a[ts_idx] += pred_a \n    score_NN_a = log_loss(y_test, pred_a)\n    print(f\"\\nFOLD {fold} Score NN Attention model: {score_NN_a}\\n\")\n    pred_NN_a += model_attention.predict(test.iloc[:,1:]) \/ N_FOLDS \n\n    #----------By row NN Model prediction------------ \n\n    pred_row = model_by_r.predict(X_test)\n    oof_NN_h[ts_idx] = pred_row \n    score_NN_h = log_loss(y_test, pred_row)\n    print(f\"\\nFOLD {fold} Score by row NN model: {score_NN_h}\\n\")\n    pred_NN_h += model_by_r.predict(test.iloc[:,1:]) \/ N_FOLDS \n\n    #----------By column NN Model  prediction----------\n\n    pred_col = model_by_col.predict(X_test)\n    oof_NN_v[ts_idx] = pred_col \n    score_NN_v = log_loss(y_test,  pred_col)\n    print(f\"\\nFOLD {fold} Score by column NN model: {score_NN_v}\\n\")\n    pred_NN_v += model_by_col.predict(test.iloc[:,1:]) \/ N_FOLDS \n\n    # =========PREPROCESSING FOR FUTURE OPTIMIZATION===========\n    NN_a_train_preds.append(oof_NN_a[ts_idx])\n    NN_a_test_preds.append(model_attention.predict(test.iloc[:,1:]))\n\n    NN_h_train_preds.append(oof_NN_h[ts_idx])\n    NN_h_test_preds.append(model_by_r.predict(test.iloc[:,1:]))\n\n    NN_v_train_preds.append(oof_NN_v[ts_idx])\n    NN_v_test_preds.append(model_by_col.predict(test.iloc[:,1:]))\n    \n    # ==========================================================\n\nscore_a = log_loss(targets, oof_NN_a)\nprint(f\"\\n=== FINAL SCORE ATTENTION MODEL : {score_a}===\\n\") \n    \nscore_NN_h = log_loss(targets, oof_NN_h)\nprint(f\"\\n=== FINAL SCORE BY ROW NN MODEL : {score_NN_h}===\\n\") \n\nscore_NN_v = log_loss(targets, oof_NN_v)\nprint(f\"\\n=== FINAL SCORE BY COLUMN NN MODEL : {score_NN_v}===\\n\") ","3c1e2ec4":"# From Ryan Barretto notebook :\ntrain_features = train.drop(['target', 'id'], axis=1).values\ntest_features = test.drop('id', axis=1).values\ntarget = train['target'].values","4916d6a7":"def class_to_num(classes):\n    return [int(word[-1]) for word in classes]\n\ndef num_to_class(nums):\n    return ['Class_' + str(num) for num in nums]\n\nlabels = np.array(class_to_num(target))\n\nlabels = pd.DataFrame(labels)","b97d677b":"y_valids = []\nfor fold, (train_index, test_index) in enumerate(skf.split(train_features, labels)):\n        \n    y_valid = labels.iloc[test_index]\n    y_valids.append(y_valid)","e1088b1e":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom scipy.optimize import minimize\nscores = []\nweights = []\nfor y, NN_v_pred, NN_h_pred, NN_a_pred in zip(y_valids, \n                                        NN_v_train_preds, \n                                        NN_h_train_preds, \n                                        NN_a_train_preds,\n                                        ):\n    preds = []\n    preds.append(NN_v_pred)\n    preds.append(NN_h_pred)\n    preds.append(NN_a_pred)\n    \n    def log_weight_loss(weights):\n        weighted_pred = (weights[0]*preds[0]) + (weights[1]*preds[1]) + (weights[2]*preds[2])\n        return log_loss(y, weighted_pred)\n    starting_values = [0.4]*len(preds) \n    cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n    bounds = [(0,1)]*len(preds) \n    res = minimize(log_weight_loss, starting_values, method='Nelder-Mead', bounds=bounds, constraints=cons)\n    \n    weights.append(res['x'])\n    print(res['fun'])\n    scores.append(res['fun'])","02c44273":"folds = N_FOLDS\nfinal_weights = sum(weights)\/folds\nweighted_preds = np.array((final_weights[0] * sum(np.array(NN_v_test_preds)\/folds))\n                           +(final_weights[1] * sum(np.array(NN_h_test_preds)\/folds))\n                           +(final_weights[2] * sum(np.array(NN_a_test_preds)\/folds)))","52337577":"submission[['Class_1', 'Class_2', 'Class_3', 'Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']] = weighted_preds\nsubmission.to_csv('submission_NN_blending3.csv')","4bd1de8c":"<h3> From Alexander Ryzhkov python translation of Oscar Villarreal Escamilla Notebook and Optimization from Ryan Barretto Notebook","ddf05040":"![image.png](attachment:cf0bfae2-ac8f-4fa7-9344-b1ba48826be6.png)","64e4e01d":"<h2> Optimization (minimization) process"}}