{"cell_type":{"e74d386e":"code","631ea00d":"code","c18a9c9d":"code","4bb72da9":"code","f27007e5":"code","5ee8649b":"code","22fe3672":"code","0e481851":"code","7a9a78f9":"code","6d01324f":"code","83ca5c43":"code","5f7c4443":"code","7c33b4d0":"code","119c4210":"code","06543a27":"code","97a949c0":"code","113a2271":"code","62b1ed78":"code","ded81932":"code","1995ba11":"code","77eec8c6":"code","bba19bd9":"code","82dbb593":"code","1f735454":"code","feb0db13":"code","0ea6da92":"code","83662166":"code","4a7374ad":"code","17463948":"code","2d7766c0":"code","9bcca2ba":"code","eabdbda6":"code","4d27001e":"code","dbb76fa7":"code","e6bcf0fd":"markdown","6e7b987d":"markdown"},"source":{"e74d386e":"from IPython.display import Image, display\nimport numpy as np\nimport os\nfrom os.path import join\nfrom PIL import ImageFile\nimport pandas as pd\nfrom matplotlib import cm\nimport seaborn as sns\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn import svm\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.isotonic import IsotonicRegression\nimport re\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nplt.style.use('fivethirtyeight')\n%matplotlib inline","631ea00d":"# import car images from natural images\ntrain_img_dir_n = \"..\/input\/fruits\/fruits-360\/Training\"\ntrain_img_paths_n = [join(train_img_dir_n,filename) for filename in os.listdir(train_img_dir_n)]\n","c18a9c9d":"# import car images from stanford cars\ntrain_img_dir_s = \"..\/input\/fruits\/fruits-360\/Training\"\nall_train_img_paths_s = [join(train_img_dir_s,filename) for filename in os.listdir(train_img_dir_s)]\n\n# split cars data into train, test, and val\ntrain_img_paths, test_img_paths_car = train_test_split(all_train_img_paths_s+train_img_paths_n, test_size=0.25, random_state=42)\ntrain_img_paths, val_img_paths_car = train_test_split(train_img_paths, test_size=0.25, random_state=42)\n","4bb72da9":"#  import ~car images\nnatural_images_path = \"..\/input\/fruits\/fruits-360\/Training\/\"\ntest_img_paths_no_car = []\nfor d in [d for d in os.listdir(\"..\/input\/fruits\/fruits-360\/Training\") if d!= \"Apple\"]:\n    test_img_dir_na = natural_images_path+d\n    test_img_paths_no_car.append([join(test_img_dir_na,filename) for filename in os.listdir(test_img_dir_na)])\n    \ntest_img_paths_no_car_flat = [item for sublist in test_img_paths_no_car for item in sublist]\ntest_img_paths_no_car, val_img_paths_no_car = train_test_split(test_img_paths_no_car_flat, test_size = 0.25, random_state = 42)","f27007e5":"def natural_img_dir(image_path):\n    path_regex = r\"Training\\\/(\\w*)\"\n    if 'Training' in image_path:\n        return re.findall(path_regex,image_path,re.MULTILINE)[0].strip()\n    else:\n        return 'Apple'","5ee8649b":"# create test dataframe\nall_test_paths = test_img_paths_car+test_img_paths_no_car\ntest_path_df = pd.DataFrame({\n    'path': all_test_paths,\n    'is_car': [1 if path in test_img_paths_car else 0 for path in all_test_paths]\n})\ntest_path_df = shuffle(test_path_df,random_state = 0).reset_index(drop = True)\ntest_path_df['image_type'] = test_path_df['path'].apply(lambda x: natural_img_dir(x))\nall_test_paths = test_path_df['path'].tolist()","22fe3672":"print(test_path_df['image_type'].value_counts())","0e481851":"# create val dataframe\n\nall_val_paths = val_img_paths_car+val_img_paths_no_car\nval_path_df = pd.DataFrame({\n    'path': all_val_paths,\n    'is_car': [1 if path in val_img_paths_car else 0 for path in all_val_paths]\n})\nval_path_df = shuffle(val_path_df,random_state = 0).reset_index(drop = True)\nval_path_df['image_type'] = val_path_df['path'].apply(lambda x: natural_img_dir(x))\nall_val_paths = val_path_df['path'].tolist()\n","7a9a78f9":"print('Distribution of Image Types in Validation Set')\nprint(val_path_df['image_type'].value_counts())","6d01324f":"# prepare images for resnet50\nimage_size = 10\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    #output = img_array\n    output = preprocess_input(img_array)\n    return(output)\n\nX_train = read_and_prep_images(train_img_paths)\nX_test = read_and_prep_images(all_test_paths)\nX_val = read_and_prep_images(all_val_paths)","83ca5c43":"X_train.shape","5f7c4443":"X_test.shape","7c33b4d0":"X_val.shape","119c4210":"X_train=X_train.reshape((-1, 1))","06543a27":"X_test=X_test.reshape((-1, 1))","97a949c0":"X_val=X_val.reshape((-1, 1))","113a2271":"# Train classifier and obtain predictions for OC-SVM\noc_svm_clf = svm.OneClassSVM(gamma=0.001, kernel='rbf', nu=0.08)  # Obtained using grid search\nif_clf = IsolationForest(contamination=0.08, max_features=1.0, max_samples=1.0, n_estimators=40)  # Obtained using grid search\n\noc_svm_clf.fit(X_train)\nif_clf.fit(X_train)\n\noc_svm_preds = oc_svm_clf.predict(X_test)\nif_preds = if_clf.predict(X_test)\n\n# Further compute accuracy, precision and recall for the two predictions sets obtained","62b1ed78":"svm_if_results=pd.DataFrame({\n  'path': all_test_paths,\n  'oc_svm_preds': [0 if x == -1 else 1 for x in oc_svm_preds],\n  'if_preds': [0 if x == -1 else 1 for x in if_preds]\n})\n\n\nsvm_if_results=svm_if_results.merge(test_path_df)\nsvm_if_results.head()","ded81932":"print('roc auc score: if_preds')\nif_preds=svm_if_results['if_preds']\nactual=svm_if_results['is_car']\nprint(roc_auc_score(actual, if_preds))\nprint(classification_report(actual, if_preds))\nsns.heatmap(confusion_matrix(actual, if_preds),annot=True,fmt='2.0f')\nplt.show()","1995ba11":"print('roc auc score: oc_svm_preds')\noc_svm_preds=svm_if_results['oc_svm_preds']\nactual=svm_if_results['is_car']\nprint(roc_auc_score(actual, oc_svm_preds))\nprint(classification_report(actual, oc_svm_preds))\nsns.heatmap(confusion_matrix(actual, oc_svm_preds),annot=True,fmt='2.0f')\nplt.show()","77eec8c6":"def getYourFruits(fruits, data_type, print_n=False, k_fold=False):\n    images = []\n    labels = []\n    val = ['Training', 'Test']\n    if not k_fold:\n        path = \"..\/input\/*\/fruits-360\/\" + data_type + \"\/\"\n        for i,f in enumerate(fruits):\n            p = path + f\n            j=0\n            for image_path in glob.glob(os.path.join(p, \"*.jpg\")):\n                image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n                image = cv2.resize(image, (dim, dim))\n                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n                images.append(image)\n                labels.append(i)\n                j+=1\n            if(print_n):\n                print(\"There are \" , j , \" \" , data_type.upper(), \" images of \" , fruits[i].upper())\n        images = np.array(images)\n        labels = np.array(labels)\n        return images, labels\n    else:\n        for v in val:\n            path = \"..\/input\/*\/fruits-360\/\" + v + \"\/\"\n            for i,f in enumerate(fruits):\n                p = path + f\n                j=0\n                for image_path in glob.glob(os.path.join(p, \"*.jpg\")):\n                    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n                    image = cv2.resize(image, (dim, dim))\n                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n                    images.append(image)\n                    labels.append(i)\n                    j+=1\n        images = np.array(images)\n        labels = np.array(labels)\n        return images, labels\n    \ndef getAllFruits():\n    fruits = []\n    for fruit_path in glob.glob(\"..\/input\/*\/fruits-360\/Training\/*\"):\n        fruit = fruit_path.split(\"\/\")[-1]\n        fruits.append(fruit)\n    return fruits\n    ","bba19bd9":"# Select Fruits\n\nApple_train = [\"Apple Golden 1\"]\nApple_test = [\"Apple Golden 1\"]\n\n\n\n#Get Images and Labels \nX_t, y_train =  getYourFruits(Apple_train, 'Training', print_n=True, k_fold=False)\nX_test, y_test = getYourFruits(Apple_test, 'Test', print_n=True, k_fold=False)\n\n#Get data for k-fold\nX,y = getYourFruits(Apple_train+Apple_test, '', print_n=True, k_fold=True)\n\n#Scale Data Images\nscaler = StandardScaler()\nX_train = scaler.fit_transform([i.flatten() for i in X_t])\nX_test = scaler.fit_transform([i.flatten() for i in X_test])\nX = scaler.fit_transform([i.flatten() for i in X])","82dbb593":"def plot_image_grid(images, nb_rows, nb_cols, figsize=(15, 15)):\n    assert len(images) == nb_rows*nb_cols, \"Number of images should be the same as (nb_rows*nb_cols)\"\n    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=figsize)\n    \n    n = 0\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            axs[i, j].axis('off')\n            axs[i, j].imshow(images[n])\n            n += 1        ","1f735454":"print(Apple_train[y_train[0]])\nplot_image_grid(X_t[0:100], 10, 10)","feb0db13":"svm = OneClassSVM(\n                      kernel='sigmoid', \n                      degree=3, gamma='scale', \n                      \n                     )\nsvm.fit(X_train) \ny_pred = svm.predict(X_test)\n\n#Evaluation\nprecision = metrics.accuracy_score(y_pred, y_test) * 100\nprint(\"Accuracy with SVM: {0:.2f}%\".format(precision))\n\n\n","0ea6da92":"# knn = KNeighborsClassifier(n_neighbors=2)\n# knn.fit(X_train, y_train)\n# y_pred = knn.predict(X_test)\n# #Evaluation\n# precision = metrics.accuracy_score(y_pred, y_test) * 100\n# print(\"Accuracy with K-NN: {0:.2f}%\".format(precision))\n\n\n# # calculate the FPR and TPR for all thresholds of the classification\n# probs = knn.predict_proba(X_test)\n# probs = probs[:, 1]\n# knn_fpr, knn_tpr, thresholds = metrics.roc_curve(y_test, probs)\n# knn_auc = metrics.roc_auc_score(y_test, probs)\n","83662166":"# #ROC CURVE\n# plt.title('ROC Curve')\n# plt.plot([0, 1], [0, 1], linestyle='--')\n# plt.plot(svm_fpr, svm_tpr, 'b', marker='.', label = 'SVM = %0.3f' % svm_auc )\n# plt.plot(knn_fpr, knn_tpr, 'g', marker='.', label = 'K-NN = %0.3f' % knn_auc)\n# plt.legend(loc = 'lower right')\n# plt.ylabel('True Positive Rate')\n# plt.xlabel('False Positive Rate')\n# plt.show()","4a7374ad":"\ndef getClassNumber(y):\n    v =[]\n    i=0\n    count = 0\n    for index in y:\n        if(index == i):\n            count +=1\n        else:\n            v.append(count)\n            count = 1\n            i +=1\n    v.append(count)        \n    return v\n\ndef plotPrincipalComponents(X, dim):\n    v = getClassNumber(y_train)\n    colors = 'b', 'g', 'r', 'c', 'm', 'y', 'k', 'grey', 'orange', 'purple'\n    markers = ['o', 'x' , 'v', 'd']\n    tot = len(X)\n    start = 0 \n    if(dim == 2):\n        for i,index in enumerate(v):\n            end = start + index\n            plt.scatter(X[start:end,0],X[start:end,1] , color=colors[i%len(colors)], marker=markers[i%len(markers)], label = fruits[i])\n            start = end\n        plt.xlabel('PC1')\n        plt.ylabel('PC2')\n    \n    if(dim == 3):\n        fig = plt.figure(figsize = [16,16])\n        ax = fig.add_subplot(111, projection='3d')\n        for i,index in enumerate(v):\n            end = start + index\n            ax.scatter(X[start:end,0], X[start:end,1], X[start:end,2], color=colors[i%len(colors)], marker=markers[i%len(markers)], label = fruits[i])\n            start = end\n        ax.set_xlabel('PC1')\n        ax.set_ylabel('PC2')\n        ax.set_zlabel('PC3')\n\n\n    plt.legend(loc='lower left')\n    plt.xticks()\n    plt.yticks()\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = unique_labels(y_true, y_pred)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    fig, ax = plt.subplots(figsize = (8,9))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=fruits, yticklabels=fruits,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return cm,ax","17463948":"cm , _ = plot_confusion_matrix(y_test, y_pred,classes=y_train, normalize=True, title='Normalized confusion matrix')\nplt.show()","2d7766c0":"fruits_test = [\"Banana\"]\n\n#Get Images and Labels\n# X, y =  getYourFruits(fruits, 'Training')\nX_test1, y_test1 = getYourFruits(fruits_test, 'Test')\n\n#Scale Data Images\nscaler2 = StandardScaler()\n# X_train = scaler.fit_transform([i.flatten() for i in X])\nX_test1 = scaler.fit_transform([i.flatten() for i in X_test1])","9bcca2ba":"y_pred1 = svm.predict(X_test1)\nprecision1 = metrics.accuracy_score(y_pred1, y_test1) * 100\n","eabdbda6":"print(\"Accuracy with SVM: {0:.2f}%\".format(precision1))","4d27001e":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","dbb76fa7":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image SIZExSIZE with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, kernel_size=2, activation='relu', input_shape=X_train, padding='same'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, kernel_size=2, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, kernel_size=2, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, kernel_size=2, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.SpatialDropout2D(0.3),\n    tf.keras.layers.Flatten(),\n    # 150 neuron hidden layer\n    tf.keras.layers.Dense(150, activation='relu'),\n    tf.keras.layers.Dense(131, activation='softmax')\n])\n\n#model.build((SIZE, SIZE))\nmodel.summary()\nmodel.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","e6bcf0fd":"> CNN","6e7b987d":"#### LINEAR SVM"}}