{"cell_type":{"786b152a":"code","e04e4595":"code","bfc73bb3":"code","f125dc37":"code","6e26d2ed":"code","4705d0a6":"code","da2bb4be":"code","630254a1":"code","ea6a55a0":"code","30340af9":"code","2c90192a":"code","927b971f":"code","98807aee":"code","fd834979":"code","b2cc9d81":"code","2d755b6a":"code","3b09496b":"code","5d86b90e":"code","31e037a3":"code","7f4e6b12":"code","e06d0f9e":"code","5fc78366":"code","ac46bc56":"code","d49d168e":"code","90adfe0d":"code","724d3047":"code","841642cb":"code","df6389e6":"code","733c9205":"code","19716289":"code","9fb79f74":"code","416b1d2c":"markdown","9968cf08":"markdown","a330eb68":"markdown","66949a09":"markdown","5de5558f":"markdown","2bd0411d":"markdown","e9804b87":"markdown","44053f69":"markdown","25a3d2e7":"markdown","0aca7b30":"markdown","fce9b7b2":"markdown","24254416":"markdown","fc4021cc":"markdown","dd0dd3f3":"markdown"},"source":{"786b152a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics, preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split","e04e4595":"from sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","bfc73bb3":"from xgboost.sklearn import XGBClassifier","f125dc37":"data = pd.read_csv(\"..\/input\/data.csv\")","6e26d2ed":"data.sample(10)","4705d0a6":"del data['id']\ndel data['Unnamed: 32']","da2bb4be":"data.sample(10)","630254a1":"data.info()","ea6a55a0":"data['diagnosis'].unique()","30340af9":"data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})","2c90192a":"data.sample(10)","927b971f":"sns.countplot(data.diagnosis, label='Count')","98807aee":"print(list(data.columns))","fd834979":"features_mean = list(data.columns[1:11])\nfeatures_se = list(data.columns[11:21])\nfeatures_worst =list(data.columns[21:31])\nprint(\"---------------- features_mean -------------------------------------------------------\")\nprint(features_mean)\nprint(\"\\n---------------- features_se (Standard Error) -------------------------------------------------------\")\nprint(features_se)\nprint(\"\\n---------------- features_worst --------------------------------------------------------\")\nprint(features_worst)","b2cc9d81":"corr = data[features_mean].corr().abs()\nlower_right_ones = np.tril(np.ones(corr.shape, dtype='bool'), k=-1)\ncorrelations = corr.where(lower_right_ones)\ncorrelations","2d755b6a":"plt.figure(figsize=(12,12))\nsns.heatmap(correlations, annot=True, cmap='RdBu_r', fmt= '.2f', vmax=1, vmin=-1)\nplt.xticks(rotation=60)","3b09496b":"THRESHOLD_VALUE = 0.85\nlist(i for i in (correlations[correlations.gt(THRESHOLD_VALUE)].stack().index) if i[0] is not i[1])","5d86b90e":"correlations[correlations.gt(THRESHOLD_VALUE)].stack().sort_values(ascending = False)","31e037a3":"corr = data[features_se].corr().abs()\nlower_right_ones = np.tril(np.ones(corr.shape, dtype='bool'), k=-1)\ncorrelations = corr.where(lower_right_ones)\nplt.figure(figsize=(12,12))\nsns.heatmap(correlations, annot=True, cmap='RdBu_r', fmt= '.2f', vmax=1, vmin=-1)\nplt.xticks(rotation=60)","7f4e6b12":"THRESHOLD_VALUE = 0.85\ncorrelations[correlations.gt(THRESHOLD_VALUE)].stack().sort_values(ascending = False)","e06d0f9e":"corr = data[features_worst].corr().abs()\nlower_right_ones = np.tril(np.ones(corr.shape, dtype='bool'), k=-1)\ncorrelations = corr.where(lower_right_ones)\nplt.figure(figsize=(12,12))\nsns.heatmap(correlations, annot=True, cmap='RdBu_r', fmt= '.2f', vmax=1, vmin=-1)\nplt.xticks(rotation=60)","5fc78366":"THRESHOLD_VALUE = 0.85\ncorrelations[correlations.gt(THRESHOLD_VALUE)].stack().sort_values(ascending = False)","ac46bc56":"to_remove = [\n    'concave points_meanr', 'compactness_mean', 'perimeter_mea', 'area_mean',\n    'concave points_worst', 'compactness_worst', 'perimeter_worst', 'area_worst',\n    'perimeter_se', 'area_se'\n]\nto_use = [e for e in data.columns if e not in to_remove]\nprint(to_use)","d49d168e":"reduced_data = data[to_use]\nreduced_data.sample(10)","90adfe0d":"X = reduced_data.loc[:, 'radius_mean': 'fractal_dimension_worst']\nY = reduced_data['diagnosis']","724d3047":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, shuffle=True)\nX_train.shape, X_test.shape, Y_train.shape, Y_test.shape","841642cb":"sc = preprocessing.StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","df6389e6":"pca = PCA(.95)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","733c9205":"svc = SVC()\ngaussian_nb = GaussianNB()\ndecision_tree_classifier = DecisionTreeClassifier()\nrandom_forest_classifier = RandomForestClassifier()\nlogistic_regression = LogisticRegression()\nk_neighbors_classifier = KNeighborsClassifier()","19716289":"svc.fit(X_train,Y_train)\ngaussian_nb.fit(X_train,Y_train)\ndecision_tree_classifier.fit(X_train,Y_train)\nrandom_forest_classifier.fit(X_train,Y_train)\nlogistic_regression.fit(X_train,Y_train)\nk_neighbors_classifier.fit(X_train,Y_train)","9fb79f74":"print(\"svc - {0:.3f}\".format(svc.score(X_test, Y_test)))\nprint(\"gaussian_nb - {0:.3f}\".format(gaussian_nb.score(X_test, Y_test)))\nprint(\"decision_tree_classifier - {0:.3f}\".format(decision_tree_classifier.score(X_test, Y_test)))\nprint(\"random_forest_classifier - {0:.3f}\".format(random_forest_classifier.score(X_test, Y_test)))\nprint(\"logistic_regression - {0:.3f}\".format(logistic_regression.score(X_test, Y_test)))\nprint(\"k_neighbors_classifier - {0:.3f}\".format(k_neighbors_classifier.score(X_test, Y_test)))\n","416b1d2c":"# Import Statements","9968cf08":"# Info given on data - \n\n#### Attribute Information:\n\n    - column 1 : ID number\n    - column 2 : Diagnosis (M = malignant, B = benign)\n    - column 3-32 : Ten real-valued features are computed for each cell nucleus:\n\n        a) radius (mean of distances from center to points on the perimeter)\n        b) texture (standard deviation of gray-scale values)\n        c) perimeter\n        d) area\n        e) smoothness (local variation in radius lengths)\n        f) compactness (perimeter^2 \/ area - 1.0)\n        g) concavity (severity of concave portions of the contour)\n        h) concave points (number of concave portions of the contour)\n        i) symmetry\n        j) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.","a330eb68":"# Further exploration in the feature set\n\nSo we know that there are 10 attributes for which **mean**, **standard error (se)**, **worst** have been calculated. These become the features. <br>\nTherefore, **10 x 3 = 30 Features**!\n\nLet's divide the attributes into groups.","66949a09":"###### Looking at the sample dataset, we can  infer -\n\n1. Result is the **diagnosis** column. It should be used as labels.\n2. Columns **id**, **Unnamed: 32** don't have any significance in the dataset.\n3. The other columns left can be used as features.","5de5558f":"### We can conclude - \n\n 1. **radius_mean**, **perimeter_mean** and **area_mean** are highly correlated. Hence, we will use **radius_mean** only.\n 2. **concavity_mean**, **concave points_mean** and **compactness_mean** are highly correlated. Hence, we will use **concavity_mean** only.","2bd0411d":"# Using Models","e9804b87":"*Except for diagnosis column, every column is float64. Let's convert diagnosis too.*","44053f69":"### We can conclude - \n\n 1. **radius_worst**, **perimeter_worst** and **area_worst** are highly correlated. Hence, we will use **radius_worst** only.\n 2. **concavity_worst**, **concave points_worst** and **compactness_worst** are highly correlated. Hence, we will use **concavity_worst** only.","25a3d2e7":"## Frequency of different diagnosis","0aca7b30":"# Data Transformation","fce9b7b2":"# Feature Selection\n\nUsing a correlation graph to see if we can remove any columns from the feature set.","24254416":"------------------------------------\n\nLet's do the same for features_se, features_worst too.","fc4021cc":"### Now we know what columns to use.","dd0dd3f3":"### We can conclude - \n\n 1. **radius_se**, **perimeter_se** and **area_se** are highly correlated. Hence, we will use **radius_se** only."}}