{"cell_type":{"859e01e5":"code","c6fc3c88":"code","a741a551":"code","4cedf303":"code","fe59ad8a":"code","c8d1dd18":"code","e0ecfbff":"code","4bf68860":"code","0098d411":"code","04a9368f":"code","d9434322":"code","13845b39":"code","52ef9c0a":"code","5c387667":"code","03303a8c":"code","c641ddeb":"code","55f55918":"code","ca8e1ec9":"code","51ed6738":"code","85ebadb7":"code","0b5d9f62":"code","ec787228":"code","48b55969":"code","d9b89b09":"code","d42cd450":"code","ec280802":"code","cfb3bc5a":"code","e4bba67d":"code","6e941bf6":"code","cd513c5e":"code","8bb62151":"markdown","d4b1076c":"markdown","52ce494c":"markdown","a979a59f":"markdown","0abf4049":"markdown","bd5df00c":"markdown","0601b6b7":"markdown","7a5b7d4a":"markdown","0c229fc3":"markdown","78b146da":"markdown","cd603ce3":"markdown","9c07b9d6":"markdown","5262912a":"markdown","80d5adc2":"markdown","bb05645a":"markdown","b9f3668b":"markdown","faa12cd2":"markdown","84b18dd8":"markdown","febfa4f7":"markdown","084cd89f":"markdown","f46fa8f8":"markdown","532afb17":"markdown","65aee29a":"markdown","52f12452":"markdown","f51791d9":"markdown","77cfecb3":"markdown","cbb44452":"markdown","7480636e":"markdown","579bbe5b":"markdown","94d54f50":"markdown"},"source":{"859e01e5":"# import EDA library\nimport pandas as pd\nimport numpy as np","c6fc3c88":"# import sklearn library\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","a741a551":"# import stats library\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","4cedf303":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fe59ad8a":"# read the data\ndf = pd.read_csv('\/kaggle\/input\/student-grade-prediction\/student-mat.csv')\ndf2 = pd.read_csv('\/kaggle\/input\/student-grade-prediction\/student-mat.csv')","c8d1dd18":"# display the first 5 rows of the data\ndf.head()","e0ecfbff":"# simple data checking - get dataframe general information\ndf.info()","4bf68860":"df.drop(df[df['G3'] < 1].index, inplace = True)","0098d411":"df2['Gavg']= round((df['G1']+df['G2']+df['G3'])\/3, 2)","04a9368f":"df = pd.get_dummies(df, drop_first=True)\ndf.head()","d9434322":"out = df['G3']\ninp = df.drop(['G3'], axis=1) ","13845b39":"# split the data into train and test by 80:20\nx_train, x_test, y_train, y_test = train_test_split(inp, out, test_size=0.2, random_state=29)","52ef9c0a":"# load the algorithm\nmodel = LinearRegression()","5c387667":"# train the data\nmodel.fit(x_train, y_train)","03303a8c":"# predict the y using trained model\ny_train_pred = model.predict(x_train)\ny_test_pred = model.predict(x_test)","c641ddeb":"# model result\nprint('Coefficients:\\n',model.coef_)\nprint('\\n')\nprint('Intercept:',model.intercept_)","55f55918":"# MSE and R^2\nprint(\"MSE :\", metrics.mean_squared_error(y_test,y_test_pred))\nprint(\"R squared :\", metrics.r2_score(y_test,y_test_pred))","ca8e1ec9":"# - Test prediction\nperformance = pd.DataFrame(y_test_pred, columns=['Prediction'])\n# - Target data\ny_test = y_test.reset_index(drop=True)\nperformance['Target'] = y_test\n# - The difference in %\nperformance['Difference (%)']= np.absolute((performance['Target'] \n                                            - performance['Prediction'])\/\n                                           performance['Target']*100)\nperformance.head()","51ed6738":"# check the summary statistics\nperformance.describe()","85ebadb7":"# make a new target value, which is Passed\ndf2['Passed']= np.where(df2['Gavg'] > 10, 1, 0)\ndf2.head()","0b5d9f62":"# choose column for each x dan y\ny = df2['Passed']\nx = (df2._get_numeric_data()).drop(['Gavg','Passed'], axis=1)\n\n# split the data into test and train\nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=29)\n\n# load the algorithm\nmodel = LogisticRegression(max_iter=1000)\n\n# train the data\nmodel.fit(x_train, y_train)\n\n# predict the y using trained model\ny_train_pred = model.predict(x_train)\ny_test_pred = model.predict(x_test)","ec787228":"# evaluate classification model - accuracy\naccuracy_test = metrics.accuracy_score(y_test,y_test_pred)\nprint('Accuracy Test Data: {}'.format(accuracy_test))","48b55969":"# classification report\nprint(classification_report(y_test,y_test_pred))","d9b89b09":"corr = df2.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","d42cd450":"# indicate which variables to compute VIF\nnew_x = x\n\n# add intercept\nnew_x['intercept'] = 1\n\n# compute VIF\nvif = pd.DataFrame()\nvif[\"variables\"] = new_x.columns\nvif[\"VIF\"] = [variance_inflation_factor(new_x.values, i) for i in range(new_x.shape[1])]\n\n# output\nvif","ec280802":"# drop the columns\ndf2.drop(columns=['G2','G3'], inplace=True)\ndf2.head()","cfb3bc5a":"y = df2['Passed']\nx = (df2._get_numeric_data()).drop(['Gavg','Passed'], axis=1)","e4bba67d":"# split the data into test and train\nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=29)\n\n# load the algorithm\nmodel = LogisticRegression(max_iter=1000)\n\n# train the data\nmodel.fit(x_train, y_train)\n\n# predict the y using trained model\ny_train_pred = model.predict(x_train)\ny_test_pred = model.predict(x_test)","6e941bf6":"# evaluate classification model - accuracy\naccuracy_test = metrics.accuracy_score(y_test,y_test_pred)\nprint('Accuracy Test Data: {}'.format(accuracy_test))","cd513c5e":"# classification report\nprint(classification_report(y_test,y_test_pred))","8bb62151":"## Do the classification: Logistic Regression","d4b1076c":"## Make dummy variable","52ce494c":"## Check the result","a979a59f":"## Check our model's performance\nI will make a new dataframe that consist of:\n* Test prediction (our result)\n* Target data (real result)\n* Difference in %","0abf4049":"# 2. Reading the data","bd5df00c":"The data has 395 rows and 33 columns without any null values.","0601b6b7":"A little bit worse than before, $92.4\\%$.","7a5b7d4a":"We get a perfect result, because our accuracy is $100\\%$. Wait what?!","0c229fc3":"## Drop the columns which have VIF > 5","78b146da":"## Multicollinearity\n\nThe reason for the absurdity of our results is multicollinearity.\n\nMulticollinearity is the occurrence of high intercorrelations among two or more independent variables in a multiple regression model. Multicollinearity can lead to skewed or misleading results when a researcher or analyst attempts to determine how well each independent variable can be used most effectively to predict or understand the dependent variable in a statistical model [(source)](https:\/\/www.investopedia.com\/terms\/m\/multicollinearity.asp).","cd603ce3":"# 6. Classification - but with Multicollinearity","9c07b9d6":"For classification, we need the average score.","5262912a":"# Student Grade Prediction\n\n* Name: Ikhwanul Muslimin\n\n* Dataset: [Student Grade Prediction - Kaggle](https:\/\/www.kaggle.com\/dipam7\/student-grade-prediction)\n\n* Dataset information:\n<p> This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school-related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary\/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).<\/p>\n\n* Relevant papers: [P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.](http:\/\/www3.dsi.uminho.pt\/pcortez\/student.pdf).","80d5adc2":"Our mean difference result is only $7.69\\%$.","bb05645a":"To do the regression, we have to eliminate target that have the value 0 so our <code>Difference<\/code> is not <code>Inf<\/code>.","b9f3668b":"<code>df<\/code> for regression and <code>df2<\/code> for classification.","faa12cd2":"## Check the result","84b18dd8":"## Make target value","febfa4f7":"# 1. Import Libraries","084cd89f":"# 5. Classification","f46fa8f8":"## Correlation between column","532afb17":"## Is our model correct?\n\nI think there is something wrong with our model, maybe because we are using all of the features of our data? So, there are some variables that highly correlated with each other.","65aee29a":"We get a good result, because our $R^2 \\approx 0.92$.","52f12452":"# Conclusion\nWe already have done the linear regression with $R^2 \\approx 0.92$ and the classification twice using Logistic Regression, the first one got $100\\%$ accuracy! However, in that case we have not taken into account the multicollinearity effect. After taking that into accout, our model is performed worse than before ($100\\%$ to around $92.4\\%$, but this result has increased the reliability of our model.","f51791d9":"## Do the regression\n\nI will choose <code>G3<\/code> as output variable and the others for the input.","77cfecb3":"# 3. Exploring the data","cbb44452":"## Check the Variance Inflation Factor (VIF)\n\nVariance inflation factor (VIF) is a measure of the amount of multicollinearity in a set of multiple regression variables. Mathematically, the VIF for a regression model variable is equal to the ratio of the overall model variance to the variance of a model that includes only that single independent variable [(source)](https:\/\/www.investopedia.com\/terms\/v\/variance-inflation-factor.asp).","7480636e":"## Check the result","579bbe5b":"## Do the classification: Logistic Regression","94d54f50":"# 4. Regression"}}