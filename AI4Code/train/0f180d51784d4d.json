{"cell_type":{"c837858b":"code","af4518bc":"code","ccb2cb5b":"code","95609e12":"code","7967ffc4":"code","1c543c1d":"code","7fca4f80":"code","c5ec8058":"code","63eb59e2":"code","bb26ca4d":"code","a06d830b":"code","6c2a1b73":"code","9c848c35":"code","586b13b2":"code","134349de":"code","ae1e9946":"code","26c5737f":"code","1b76de7d":"code","4aef69ea":"code","8f4af457":"code","ab38cddc":"code","a067bc96":"code","4bf0e46a":"code","dfbc1fd7":"code","939f8dbe":"code","78b041d2":"code","a10975a1":"code","75fa96e0":"markdown","65332bff":"markdown","fd59c022":"markdown","2b904f47":"markdown","c5300e65":"markdown","8e7b0b0c":"markdown","5c90e08d":"markdown","167bc9ac":"markdown","cff39ecb":"markdown","30b77b6a":"markdown"},"source":{"c837858b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.regression import linear_model\n","af4518bc":"dat = pd.read_csv('\/kaggle\/input\/chicago-divvy-bicycle-sharing-data\/data.csv')","ccb2cb5b":"dat.head()","95609e12":"dat_s = dat.sample(n=int(dat.shape[0]*0.2), random_state=1)","7967ffc4":"dat_s.shape","1c543c1d":"# Visualize the missing values as a bar chart \nmsno.bar(dat_s) ","7fca4f80":"# based on the week number, derive weekend and weekday flag var. We suppose the trip distribution is different in weekday and weekend \ndat_st['weekend_flag'] = dat_st.apply(lambda row: 1 if row.day== 5 or row.day==6 else 0, axis=1)","c5ec8058":"# based on the hour, we derive rush hour \/ none rush hour \ndat_st['rush_hour_flag'] = dat_st.apply(lambda row: 1 if row.hour == 8 or row.hour == 9 or row.hour == 12 or row.hour == 17 or row.hour == 18 else 0, axis=1)","63eb59e2":"# trip freq by usertype, gender, events\n\ntrip_usertype = dat_st.groupby('usertype').trip_id.count().reset_index()\ntrip_gender = dat_st.groupby('gender').trip_id.count().reset_index()\ntrip_events = dat_st.groupby('events').trip_id.count().reset_index()","bb26ca4d":"trip_events['pct'] = trip_events['trip_id']\/trip_events['trip_id'].sum();trip_events","a06d830b":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n\nax1.bar(trip_usertype.usertype, trip_usertype.trip_id)\nax1.set_title('User type distribution')\nax1.set_xlabel('User type')\nax1.set_ylabel('Freq')\nax1.yaxis.grid()\n\nax2.bar(trip_gender.gender, trip_gender.trip_id)\nax2.set_title('Gender distribution')\nax2.set_xlabel('Gender')\nax2.set_ylabel('Freq')\nax2.yaxis.grid()\n\nax3.bar(trip_events.events, trip_events.trip_id)\nax3.set_title('Events distribution')\nax3.set_xlabel('Events')\nax3.set_ylabel('Freq')\nplt.xticks(rotation=45)\nax3.yaxis.grid()","6c2a1b73":"dat_st['temper_round'] = round(dat_st.temperature)","9c848c35":"momth_temp_trip = dat_st.groupby(['temper_round','month']).trip_id.count().reset_index()","586b13b2":"fig, ([ax1,ax2],[ax3, ax4],[ax5,ax6],[ax7,ax8], [ax9,ax10], [ax11,ax12]) = plt.subplots(nrows=6, ncols=2, figsize=(30,10))\n\nax1.bar(momth_temp_trip[momth_temp_trip.month==1].temper_round, momth_temp_trip[momth_temp_trip.month==1].trip_id)\n# ax1.set_title('Jan')\nax1.set_xlabel('Temperature')\nax1.set_ylabel('Jan Freq')\nax1.yaxis.grid()\nax1.set_xlim([-10, 90])\n\nax2.bar(momth_temp_trip[momth_temp_trip.month==2].temper_round, momth_temp_trip[momth_temp_trip.month==2].trip_id)\n# ax2.set_title('Feb')\nax2.set_xlabel('Temperature')\nax2.set_ylabel('Feb Freq')\nax2.yaxis.grid()\nax2.set_xlim([-10, 90])\n\nax3.bar(momth_temp_trip[momth_temp_trip.month==3].temper_round, momth_temp_trip[momth_temp_trip.month==3].trip_id)\n# ax3.set_title('Mar')\nax3.set_xlabel('Temperature')\nax3.set_ylabel('Mar Freq')\nax3.yaxis.grid()\nax3.set_xlim([-10, 90])\n\nax4.bar(momth_temp_trip[momth_temp_trip.month==4].temper_round, momth_temp_trip[momth_temp_trip.month==4].trip_id)\n# ax4.set_title('Apr')\nax4.set_xlabel('Temperature')\nax4.set_ylabel('Apr Freq')\nax4.yaxis.grid()\nax4.set_xlim([-10, 90])\n\nax5.bar(momth_temp_trip[momth_temp_trip.month==5].temper_round, momth_temp_trip[momth_temp_trip.month==5].trip_id)\n# ax5.set_title('May')\nax5.set_xlabel('Temperature')\nax5.set_ylabel('May Freq')\nax5.yaxis.grid()\nax5.set_xlim([-10, 90])\n\nax6.bar(momth_temp_trip[momth_temp_trip.month==6].temper_round, momth_temp_trip[momth_temp_trip.month==6].trip_id)\n# ax6.set_title('June')\nax6.set_xlabel('Temperature')\nax6.set_ylabel('June Freq')\nax6.yaxis.grid()\nax6.set_xlim([-10, 90])\n\nax7.bar(momth_temp_trip[momth_temp_trip.month==7].temper_round, momth_temp_trip[momth_temp_trip.month==7].trip_id)\n# ax7.set_title('July')\nax7.set_xlabel('Temperature')\nax7.set_ylabel('July Freq')\nax7.yaxis.grid()\nax7.set_xlim([-10, 90])\n\nax8.bar(momth_temp_trip[momth_temp_trip.month==8].temper_round, momth_temp_trip[momth_temp_trip.month==8].trip_id)\n# ax8.set_title('Aug')\nax8.set_xlabel('Temperature')\nax8.set_ylabel('Aug Freq')\nax8.yaxis.grid()\nax8.set_xlim([-10, 90])\n\nax9.bar(momth_temp_trip[momth_temp_trip.month==9].temper_round, momth_temp_trip[momth_temp_trip.month==9].trip_id)\n# ax9.set_title('Sep')\nax9.set_xlabel('Temperature')\nax9.set_ylabel('Sep Freq')\nax9.yaxis.grid()\nax9.set_xlim([-10, 90])\n\nax10.bar(momth_temp_trip[momth_temp_trip.month==10].temper_round, momth_temp_trip[momth_temp_trip.month==10].trip_id)\n# ax10.set_title('Oct')\nax10.set_xlabel('Temperature')\nax10.set_ylabel('Oct Freq')\nax10.yaxis.grid()\nax10.set_xlim([-10, 90])\n\nax11.bar(momth_temp_trip[momth_temp_trip.month==11].temper_round, momth_temp_trip[momth_temp_trip.month==11].trip_id)\n# ax11.set_title('Nov')\nax11.set_xlabel('Temperature')\nax11.set_ylabel('Nov Freq')\nax11.yaxis.grid()\nax11.set_xlim([-10, 90])\n\nax12.bar(momth_temp_trip[momth_temp_trip.month==12].temper_round, momth_temp_trip[momth_temp_trip.month==12].trip_id)\n# ax12.set_title('Dec')\nax12.set_xlabel('Temperature')\nax12.set_ylabel('Dec Freq')\nax12.set_xlim([-10, 90])\nax12.yaxis.grid()","134349de":"def season_derive(month):\n    if month>=12 or month <=2:\n        return 'winter'\n    if month >=3 and month <=6:\n        return 'spring'\n    if month >=7 and month <=9:\n        return 'summer'\n    else:\n        return 'fall'","ae1e9946":"dat_st['season'] = dat_st.apply(lambda row: season_derive(row.month), axis=1)","26c5737f":"dim = ['year', 'month', 'day', 'hour', 'usertype', 'gender', 'events', 'weekend_flag', 'season']\ndat_agg = dat_st.groupby(dim).aggregate({'temperature': 'mean',\n                                         'tripduration': 'mean',\n                                         'trip_id': 'count'\n                                         }).reset_index()","1b76de7d":"dat_agg2 = dat_agg.groupby(['season', 'hour']).aggregate({'tripduration': 'mean'}).reset_index()","4aef69ea":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,10))\n\nax.plot(dat_agg2[dat_agg2.season=='summer'].hour, dat_agg2[dat_agg2.season=='summer'].tripduration, label='summer')\nax.plot(dat_agg2[dat_agg2.season=='winter'].hour, dat_agg2[dat_agg2.season=='winter'].tripduration, label='winter')\nax.plot(dat_agg2[dat_agg2.season=='spring'].hour, dat_agg2[dat_agg2.season=='spring'].tripduration, label='spring')\nax.plot(dat_agg2[dat_agg2.season=='fall'].hour, dat_agg2[dat_agg2.season=='fall'].tripduration, label='fall')\n\nax.legend(loc='lower right')\nax.set_title('Average trip duration by season and hour')\nax.set_xlabel('hour')\nax.set_ylabel('trip duration mean')\n\nax.yaxis.grid()\n","8f4af457":"day_hour_trip = dat_st.groupby(['day', 'hour']).trip_id.count().reset_index()","ab38cddc":"fig, ([ax1,ax2], [ax3,ax4],[ax5,ax6],[ax7, ax8]) = plt.subplots(nrows=4, ncols=2, figsize=(25,15))\n\nax1.bar(day_hour_trip[day_hour_trip.day==0].hour, day_hour_trip[day_hour_trip.day==0].trip_id)\nax1.set_title('Monday')\nax1.set_xlabel('Hour')\nax1.set_ylabel('Freq')\nax1.yaxis.grid()\n\nax2.bar(day_hour_trip[day_hour_trip.day==1].hour, day_hour_trip[day_hour_trip.day==1].trip_id)\nax2.set_title('Tuesday')\nax2.set_xlabel('Hour')\nax2.set_ylabel('Freq')\nax2.yaxis.grid()\n\nax3.bar(day_hour_trip[day_hour_trip.day==2].hour, day_hour_trip[day_hour_trip.day==2].trip_id)\nax3.set_title('Wednesday')\nax3.set_xlabel('Hour')\nax3.set_ylabel('Freq')\nax3.yaxis.grid()\n\nax4.bar(day_hour_trip[day_hour_trip.day==3].hour, day_hour_trip[day_hour_trip.day==3].trip_id)\nax4.set_title('Thursday')\nax4.set_xlabel('Hour')\nax4.set_ylabel('Freq')\nax4.yaxis.grid()\n\nax5.bar(day_hour_trip[day_hour_trip.day==4].hour, day_hour_trip[day_hour_trip.day==4].trip_id)\nax5.set_title('Friday')\nax5.set_xlabel('Hour')\nax5.set_ylabel('Freq')\nax5.yaxis.grid()\n\nax6.bar(day_hour_trip[day_hour_trip.day==5].hour, day_hour_trip[day_hour_trip.day==5].trip_id)\nax6.set_title('Saturday')\nax6.set_xlabel('Hour')\nax6.set_ylabel('Freq')\nax6.yaxis.grid()\n\nax7.bar(day_hour_trip[day_hour_trip.day==6].hour, day_hour_trip[day_hour_trip.day==6].trip_id)\nax7.set_title('Sunday')\nax7.set_xlabel('Hour')\nax7.set_ylabel('Freq')\nax7.yaxis.grid()\n","a067bc96":"dat_daily = dat_st.groupby(['year','month', 'week', 'day']).agg({'temperature': 'mean', 'events': lambda x:x.value_counts().index[0],\n                                                      'trip_id': 'count', 'tripduration':'sum'}).reset_index()","4bf0e46a":"dat_daily['avg_duration'] = dat_daily['tripduration']\/ dat_daily['trip_id']","dfbc1fd7":"dat_daily.head()","939f8dbe":"dat_daily['year'] = dat_daily['year'].astype(str)\ndat_daily['month'] = dat_daily['month'].astype(str)\ndat_daily['week'] = dat_daily['week'].astype(str)\ndat_daily['day'] = dat_daily['day'].astype(str)\n\ndat_daily_dummy = pd.get_dummies(dat_daily, prefix=['year', 'month', 'week', 'day', 'events'])","78b041d2":"dat_daily","a10975a1":"x = dat_daily_dummy.drop(['trip_id', 'avg_duration'], axis=1)\ny = dat_daily_dummy['trip_id']\n\nmodel = linear_model.OLS(y,x).fit()\nmodel.summary()","75fa96e0":"## 1.1 Clean missing values\n#### As the bar chart below shown, the random sample dat_s doesn't contain any missing value, we are good to go","65332bff":"## 2.3 Month, Temperature and trip duration correlation\n\n* Seasonality effect: the summer season has the highest average trip duration, and winter has the lowest\n* Hour and season mixed effect: in winter and fall, we observe obvious dip in the early hour, but in spring and summer,we observe spike in the early hour. The duration lines increase by hour in all season lines and have a peak at around the afternoon (hour = 15)","fd59c022":"## 1.2 Derive new feature based on hypothesis","2b904f47":"## 2.2 Month, Temperature and trip frequency correlation\n\n* The trip frequency by temperature distributions are different in different seasons\n\n\n* Basically, we can observe three patterns:\n\n\n1. **Winter Season**\n\n   The trip by temperature distribution can be approximated to a **normal with mean around 40**. The temperature range is relatively large in this season thus the variance of the trip freq is also large (**long tails**)\n   \n\n2. **Spring and Fall Season**\n\n   Moderate temperature in these two seasons. The trip by temperature distributions are still normal but the mean peaks are less obvious than winter and summer.\n   \n\n3. **Summer season**\n\n   The hottest season and the temperature range is relatively small. The trip by temperature distribution can also be approximated by **Normal distribution, with a mean around 75**, and the variance is much smaller than the winter's (**short tails**)","c5300e65":"## 2.1 Categorical var distribution and correlation \n\n* In this 20% sample data, more than 99% users are 'subscriber' user type. They pay the fee by year.\n\n* For all the customers, 75% are male, 25% are female.\n\n* More than 89% of trips happened in the event of 'cloudy', which implies the cloudy weather is a good timing for biking.\n\n* The start station popularity is moderate positively correlated with the dpcapacity.\n","8e7b0b0c":"# Randomly sample 20% of the original dataset","5c90e08d":"# 3. Trip duration prediction\n\nWe built a multiple linear regression to predict the trip count by temperature, tripduration, year, month, week, day, and events. All the categorical features are tranformed to dummy variables. \n\n* The model summary shows a R square as 0.983 and R square adjusted as 0.982, which means our independent variables explain the trip count variantion very well. \n\n* The Significant variables (risk level = 0.05) include temperature, tripduration, year_2015 to 2017, month1, 4, 5, 6, 7, 11, 12 (the winter and summer season months), events_clear, events_cloudy, events_rain or snow. ","167bc9ac":" # 2. Data distribution EDA","cff39ecb":"## 2.4 Weekday, hour and trip Frequency correlation\n\n* The Monday to Friday hour by trip frequency distributions are following similar pattern, having two peaks in two rush hours \n* Saturday and Sunday distributions are different from the week days', no obvious peak hour, it has an exponential increase rate from 6AM and have a platuea between 11 AM amd 5PM, after 5PM the volume drops continuously","30b77b6a":"# 1. Preprocess feature and feature engineer"}}