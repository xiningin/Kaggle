{"cell_type":{"5cd1d549":"code","edceb62f":"code","d529481e":"code","ce5aa57c":"code","03994652":"code","2a99cbdb":"code","2545580d":"code","16147467":"code","b133d7bf":"code","23cf216d":"code","a726bd59":"code","222cf0eb":"code","1fca7e68":"code","6cbe19c8":"code","b6c744e4":"code","7a4129f8":"code","a03229d3":"code","bd68786e":"code","a0a483d3":"code","cb9273fe":"code","edf17764":"code","3fbcafe8":"code","38e4a1c7":"code","b13ae686":"code","84b7362a":"code","08c5cf7b":"code","a69da6d2":"code","176cbeb5":"code","631de6cf":"code","844a1b9a":"code","f3e4938c":"code","584254c5":"code","ce387657":"code","a8cc46ef":"code","ca10cef8":"code","2a6ee744":"code","bfbf5889":"code","b1bcef1e":"code","912acf5c":"code","172816a5":"code","025f00e2":"code","c62a585b":"code","2b7fa138":"code","80090a89":"code","f9f88f6e":"code","35a8d851":"code","c5479d66":"code","01a10c3e":"code","f1084fca":"code","48d7a3e2":"code","85fc8147":"code","11e54fcd":"code","76848313":"code","625ced60":"code","b3f85109":"code","4846401d":"code","47cb18d9":"code","ee55ed23":"code","c10d71df":"code","649f6cfc":"code","c6959785":"code","019579d1":"code","8297474f":"code","0cf6d34d":"code","6e4d7926":"code","c7767387":"code","99944907":"code","80f7f2d2":"code","764f02dd":"code","c3c3f1f3":"code","4bb0f819":"code","bb4d8d3e":"code","83c38108":"code","61fd38ee":"code","610ade12":"code","a011d2f2":"code","28d91529":"code","e2b9580a":"code","3689fd71":"code","b2b1f69d":"code","faf11995":"code","32079914":"code","afdd1d24":"code","0d570d1f":"code","8a505ae3":"code","f115aa74":"code","23936a3b":"code","e278b979":"code","b2a7d899":"code","f69c84c1":"code","6f0630c1":"code","864cc66e":"code","157a2ed1":"code","fed2d23c":"code","89c3e7d7":"code","49bc0e03":"code","8aaf9abb":"code","5359d6a3":"code","e75ce0e3":"code","7b52f08c":"code","30ca8461":"code","98058f63":"code","19374384":"code","2fca2b89":"code","fcf43166":"code","81ba1bcb":"code","fee755f9":"code","6de0cd9f":"code","7cb0d572":"code","4bc13db9":"code","8693c317":"code","2c975bc7":"code","719c6660":"code","78b381b7":"code","3e5dd9ab":"code","afbdb599":"code","20de5085":"code","d40a4ada":"code","568ffb91":"code","625fd904":"code","129ae666":"code","1a258e0e":"code","3dc213eb":"code","ccbb6be8":"code","a384e1cd":"code","aee49811":"code","e7738be9":"code","8d498e5d":"code","d62800ce":"code","854acd5b":"code","5a7ba943":"code","81813e49":"code","7c9638d4":"code","4a1ba6ea":"code","286ecd33":"code","e3b9b061":"code","af2f240c":"code","816812fe":"code","6b37a4f4":"code","545a50b8":"code","71a47b5e":"code","be4b7fcf":"code","e881fbd4":"code","5414e367":"code","97f4609a":"code","6e24fb10":"code","3fe1d4ab":"code","f7f9cadf":"code","7df71873":"code","6b1f4593":"code","56b8f386":"code","39d773fc":"markdown","e7f4c9d9":"markdown","810ad761":"markdown","a7b5e3c2":"markdown","59e65d81":"markdown","4090ccdf":"markdown","5e4d16f1":"markdown","bd759a8a":"markdown","72001ce2":"markdown","4047cba4":"markdown","38e9b49a":"markdown","1bb3da84":"markdown","f2dc0ea9":"markdown","4122187c":"markdown","36627df2":"markdown","2698643f":"markdown","d4b11102":"markdown","5864f4cc":"markdown","73a59574":"markdown","6d5dcc5a":"markdown","5decc3c8":"markdown","fee16190":"markdown","9173b550":"markdown","5a613cb3":"markdown","6591cced":"markdown","8da4e4b3":"markdown","a8e2d10b":"markdown","7cd8e130":"markdown","1ed998c3":"markdown","9b872d25":"markdown","9bd4c220":"markdown","6fb01707":"markdown","edde0277":"markdown","d1650b7c":"markdown","054fec84":"markdown","41b09951":"markdown","46217f40":"markdown","725819bc":"markdown","c193d0a3":"markdown","980a09f3":"markdown","7f45ae09":"markdown","60e22599":"markdown","4f54ddfc":"markdown","3f499125":"markdown","1008da37":"markdown","e06c3a4d":"markdown","632920fd":"markdown","07ee1883":"markdown","f4104f46":"markdown","8a9cde5c":"markdown","390f209d":"markdown","4b155a81":"markdown","a9cdd62e":"markdown"},"source":{"5cd1d549":"from sklearn.preprocessing import LabelEncoder, StandardScaler\nimport lightgbm\nfrom lightgbm import LGBMClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc,os,sys\nimport random\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nRANDOM_SEED = 2021\nPROBAS = True\nFOLDS = 5\nN_ESTIMATORS = 1000\n\nTARGET = 'Survived'\n    \n\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 300)\npd.set_option('display.max_colwidth', 30)","edceb62f":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest= pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\n\ntrain.shape, test.shape, sample_submission.shape","d529481e":"train.head()","ce5aa57c":"test.head()","03994652":"sample_submission.head()","2a99cbdb":"train.dtypes[train.dtypes != 'object'].index.tolist()","2545580d":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\nprint(mpl.__version__)","16147467":"from cycler import cycler\n\nmpl.rcParams['figure.dpi'] = 120\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False\n# mpl.rcParams['font.family'] = 'serif'\n\nraw_light_palette = [\n    (0, 122, 255), # Blue\n    (255, 149, 0), # Orange\n    (52, 199, 89), # Green\n    (255, 59, 48), # Red\n    (175, 82, 222),# Purple\n    (255, 45, 85), # Pink\n    (88, 86, 214), # Indigo\n    (90, 200, 250),# Teal\n    (255, 204, 0)  # Yellow\n]\n\nlight_palette = np.array(raw_light_palette)\/255\n\n\nmpl.rcParams['axes.prop_cycle'] = cycler('color',light_palette)\n\nsurvived_palette = ['#dddddd', mpl.colors.to_hex(light_palette[2])]\n\nsex_palette = [light_palette[0], light_palette[3]]","b133d7bf":"fig = plt.figure(figsize=(15, 11))\n\ngs = fig.add_gridspec(3, 4) # row size * column size \ud615\ud0dc\uc758 1\ucc28\uc6d0 \uc5b4\ub808\uc774, subplot \uc0ac\uc774\uc988 \uc870\uc808. \ud55c \ud654\uba74\uc744 3 x 4 \ud615\ud0dc\ub85c \ubd84\ud560\ud55c\ub2e4\uace0 \uc0dd\uac01\ud558\uba74 \ub428.\n\n\n\n\nax_sex_survived = fig.add_subplot(gs[:2,:2])\nsns.countplot(x='Sex',hue='Survived', data=train, ax=ax_sex_survived, \n              palette=survived_palette)\n\nax_survived_sex = fig.add_subplot(gs[:2,2:4], sharey=ax_sex_survived)\nsns.countplot(x='Survived',hue='Sex', data=train, ax=ax_survived_sex,\n              palette=sex_palette\n             )\n\n# ax_survived_sex.set_yticks([])\nax_survived_sex.set_ylabel('')\n\nax_pie_male = fig.add_subplot(gs[2, 0])\nax_pie_female = fig.add_subplot(gs[2, 1])\nax_pie_notsurvived = fig.add_subplot(gs[2, 2])\nax_pie_survived = fig.add_subplot(gs[2, 3])\n\n# Sex\nmale = train[train['Sex']=='male']['Survived'].value_counts().sort_index()\nax_pie_male.pie(male, labels=male.index, autopct='%1.1f%%',explode = (0, 0.1), startangle=90,\n               colors=survived_palette\n               )\n\n\nfemale = train[train['Sex']=='female']['Survived'].value_counts().sort_index()\nax_pie_female.pie(female, labels=female.index, autopct='%1.1f%%',explode = (0, 0.1), startangle=90,\n                colors=survived_palette\n                 )\n\n# Survived\nnotsurvived = train[train['Survived']==0]['Sex'].value_counts()[['male', 'female']]\nax_pie_notsurvived.pie(notsurvived, labels=notsurvived.index, autopct='%1.1f%%',startangle=90,\n                      colors=sex_palette, textprops={'color':\"w\"}\n                      )\n\nsurvived = train[train['Survived']==1]['Sex'].value_counts()[['male', 'female']]\nax_pie_survived.pie(survived, labels=survived.index, autopct='%1.1f%%', startangle=90,\n                    colors=sex_palette, textprops={'color':\"w\"}\n                   )\n\nfig.suptitle('[Sex & Survived] Conditional Distribution', fontweight='bold', fontsize=20)\nfig.text(s='''Gender and survival are the most important features of the existing Titanic problem.\\nLook at each conditional probability and think of the minimum score''', \n         x=0.5, y= 0.94, ha='center', va='top')\n\nplt.show()","23cf216d":"def age_band(num):\n    for i in range(1, 100):\n        if num < 10*i : return f'{(i-1) * 10} ~ {i*10}'\n        \n        \ntrain['Age band'] = train['Age'].apply(age_band)\ntitanic_age = train[['Age band', 'Survived']].groupby('Age band')['Survived'].value_counts().sort_index().unstack()\ntitanic_age['Survival rate'] = titanic_age[1] \/ (titanic_age[0] + titanic_age[1]) * 100\nage_band = train['Age band'].value_counts().sort_index()\nprint(age_band)","a726bd59":"from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n\nfig = plt.figure(figsize=(15, 10))\ngs = fig.add_gridspec(3, 4)\nax = fig.add_subplot(gs[:-1,:])\n\ncolor_map = ['#d4dddd' for _ in range(9)]\ncolor_map[2] = light_palette[3]\ncolor_map[8] = light_palette[2]\n\n\nbars = ax.bar(titanic_age['Survival rate'].index, titanic_age['Survival rate'], \n       color=color_map, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"left\"].set_visible(False)\nax.bar_label(bars, fmt='%.2f%%')\n\n\n# mean line + annotation\nmean = train['Survived'].mean() *100\nax.axhline(mean ,color='black', linewidth=0.4, linestyle='dashdot')\nax.annotate(f\"mean : {mean :.4}%\", \n            xy=('20 ~ 30', mean + 4),\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='#efe8d1', linewidth=0))\n    \n\n\nax.set_yticks(np.arange(0, 81, 20))\nax.grid(axis='y', linestyle='-', alpha=0.4)\nax.set_ylim(0, 85)\n\n\nax_bottom = fig.add_subplot(gs[-1,:])\nbars = ax_bottom.bar(age_band.index, age_band, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax_bottom.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax_bottom.bar_label(bars, fmt='%d', label_type='center', color='white')\nax_bottom.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Title & Subtitle    \nfig.text(0.1, 1, 'Age Band & Survival Rate', fontsize=15, fontweight='bold', fontfamily='serif', ha='left')\nfig.text(0.1, 0.96, 'Unlike before, the survival rate of infants and toddlers is very low.', fontsize=12, fontweight='light', fontfamily='serif', ha='left')\n\nplt.show()","222cf0eb":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16,5))\n\n# \uae30\ubcf8 \uadf8\ub798\ud504\nsns.heatmap(train.corr(), ax=ax[0])\nax[0].set_title('Basic Correlation Heatmap', pad = 12)\n\n# \uc0c1\uad00\uad00\uacc4 \uc218\uce58 \uadf8\ub798\ud504\nsns.heatmap(train.corr(), vmin=-1, vmax=1, annot=True, ax=ax[1])\nax[1].set_title('Correlation Heatmap with Number', pad = 12)\n\nplt.show()","1fca7e68":"def get_category_fare_age(fare_age):\n    cat = ''\n    if fare_age <= -1: cat = 'Unknown'\n    elif fare_age <= 5000: cat = 'Low'\n    elif fare_age <= 10000: cat = 'Middle '\n    elif fare_age <= 20000: cat = 'High'\n    elif fare_age <= 40000: cat = 'Very High'\n    else : cat = 'Ultra High'\n    \n    return cat","6cbe19c8":"train['Age'].fillna(train['Age'].mean(), inplace=True)\ntrain['Fare'].fillna(train['Fare'].mean(), inplace=True)\n\ntrain['Fare*Age'] = train['Age'] * train['Fare']\ntrain['Fare*Age'] = train['Fare*Age'].apply(lambda x : get_category_fare_age(x))\ntitanic_fare_age = train[['Fare*Age', 'Survived']].groupby('Fare*Age')['Survived'].value_counts().sort_index().unstack()\ntitanic_fare_age['Survival rate'] = titanic_fare_age[1] \/ (titanic_fare_age[0] + titanic_fare_age[1]) * 100\n\nFare_Age = train['Fare*Age'].value_counts().sort_index()","b6c744e4":"from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n\nfig = plt.figure(figsize=(15, 10))\ngs = fig.add_gridspec(3, 4)\nax = fig.add_subplot(gs[:-1,:])\n\ncolor_map = ['#d4dddd' for _ in range(5)]\ncolor_map[1] = light_palette[3]\ncolor_map[3] = light_palette[2]\n\n\nbars = ax.bar(titanic_fare_age['Survival rate'].index, titanic_fare_age['Survival rate'], \n       color=color_map, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax.bar_label(bars, fmt='%.2f%%')\n\n\n# mean line + annotation\nmean = train['Survived'].mean() *100\nax.axhline(mean ,color='black', linewidth=0.4, linestyle='dashdot')\nax.annotate(f\"mean : {mean :.4}%\", \n            xy=('Low', mean + 4),\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='#efe8d1', linewidth=0))\n    \n\n\n\nax.set_yticks(np.arange(0, 100, 20))\nax.grid(axis='y', linestyle='-', alpha=0.4)\nax.set_ylim(0, 100)\n\n\nax_bottom = fig.add_subplot(gs[-1,:])\nbars = ax_bottom.bar(Fare_Age.index, Fare_Age, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax_bottom.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax_bottom.bar_label(bars, fmt='%d', label_type='center', color='white')\nax_bottom.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Title & Subtitle    \nfig.text(0.1, 1, 'Fare x Age & Survival Rate', fontsize=15, fontweight='bold', fontfamily='serif', ha='left')\nfig.text(0.1, 0.96, 'the survival rate of Low is very low.', fontsize=12, fontweight='light', fontfamily='serif', ha='left')\n\nplt.show()","7a4129f8":"num_columns = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","a03229d3":"def show_hist_by_target(df, columns):\n    cond_1 = (df['Survived'] == 1)\n    cond_0 = (df['Survived'] == 0)\n\n    for column in columns:\n        fig, axs = plt.subplots(figsize=(12, 4), nrows=1, ncols=2, squeeze=False)\n        sns.violinplot(x='Survived', y=column, data=df, ax=axs[0][0])\n        sns.distplot(df[cond_1][column], label='1', color='red', ax=axs[0][1])\n        sns.distplot(df[cond_0][column], label='0', color='blue', ax=axs[0][1])  ","bd68786e":"show_hist_by_target(train, num_columns)","a0a483d3":"\ndef get_category_age(age):\n    cat = ''\n    if age <= -1: cat = 'Unknown'\n    elif age <= 5: cat = 'Baby'\n    elif age <= 12: cat = 'Child'\n    elif age <= 60: cat = 'Adult'\n    else : cat = 'Elderly'\n    \n    return cat","cb9273fe":"train['Age'].fillna(train['Age'].mean(), inplace=True)\ntrain['Age'] = train['Age'].apply(lambda x : get_category_age(x))","edf17764":"def get_category_fare(fare):\n    cat = ''\n    if fare <= -1: cat = 'Unknown'\n    elif fare <= 40: cat = 'Lower Class'\n    elif fare < 150: cat = 'Middle Class'\n    elif fare <= 500: cat = 'Rich'\n    else : cat = 'Super Rich'\n    \n    return cat","3fbcafe8":"train['Fare'].fillna(train['Fare'].mean(), inplace=True)\ntrain['Fare'] = train['Fare'].apply(lambda x : get_category_fare(x))","38e4a1c7":"def get_category_name(name):\n    cat = ''\n    if name <= -1: cat = 'Unknown'\n    elif name <= 2: cat = 'highly rare'\n    elif name <= 5: cat = 'rare'\n    elif name <= 50: cat = 'slightly common'\n    elif name <= 500: cat = 'common'\n    elif name <= 1000: cat = 'moderately common'\n    else : cat = 'highly common'\n    \n    return cat","b13ae686":"train['FamName'] = train['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\nFamName = train['FamName'].value_counts()\nFamName = FamName.apply(lambda x : get_category_name(x))\ntrain['FamName'] = train['FamName'].apply(lambda x: FamName[x])\nprint(train['FamName'].value_counts())","84b7362a":"def get_category_family(family):\n    cat = ''\n    if family <= -1: cat = 'Unknown'\n    elif family <= 1: cat = 'Alone'\n    elif family <= 2: cat = 'Couple'\n    elif family <= 5: cat = 'Small'\n    elif family <= 8: cat = 'Medium'\n    elif family <= 12: cat = 'Big'\n    else : cat = 'Very Big'\n    \n    return cat","08c5cf7b":"train['FamSize'] = train['SibSp'] + train['Parch'] + 1\ntrain['FamSize'] = train['FamSize'].apply(lambda x : get_category_family(x))","a69da6d2":"train['Ticket'] = train['Ticket'].apply(lambda x: x[0] if type(x) == str else 'Missing')","176cbeb5":"train['Cabin'] = train['Cabin'].apply(lambda x: x[0] if type(x) == str else 'Missing')","631de6cf":"train.info()","844a1b9a":"train.dtypes[train.dtypes == 'object'].index.tolist()","f3e4938c":"object_columns = ['Age','FamName','FamSize','Cabin','Ticket','Fare']","584254c5":"def show_category_by_target(df,columns):\n    for column in columns:\n        print('column name:',column)\n        chart = sns.catplot(x=column, col='Survived', data=df, kind='count')\n        chart.set_xticklabels(rotation=65)\n\nshow_category_by_target(train, object_columns)","ce387657":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest= pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\n\ntrain.shape, test.shape, sample_submission.shape","a8cc46ef":"print(train['Embarked'].value_counts())","ca10cef8":"Survived_0 = (train['Survived'] == 0)\nSurvived_1 = (train['Survived'] == 1)\n\n# Embarked\uc5d0 \ub530\ub978 \uc0ac\ub9dd \ube44\uc728\nprint('_'*20)\nprint('Embarked\uc5d0 \ub530\ub978 \uc0ac\ub9dd \ube44\uc728') \nprint('S :',train[Survived_0 & (train['Embarked'] == 'S')]['Embarked'].count() \/ train[Survived_0].shape[0])\nprint('C :',train[Survived_0 & (train['Embarked'] == 'C')]['Embarked'].count() \/ train[Survived_0].shape[0])\nprint('Q :',train[Survived_0 & (train['Embarked'] == 'Q')]['Embarked'].count() \/ train[Survived_0].shape[0])\n\n# Embarked\uc5d0 \ub530\ub978 \uc0ac\ub9dd \ube44\uc728\nprint('_'*20)\nprint('Embarked\uc5d0 \ub530\ub978 \uc0dd\uc874 \ube44\uc728') \nprint('S :',train[Survived_0 & (train['Embarked'] == 'S')]['Embarked'].count() \/ train[Survived_0].shape[0])\nprint('C :',train[Survived_0 & (train['Embarked'] == 'C')]['Embarked'].count() \/ train[Survived_0].shape[0])\nprint('Q :',train[Survived_0 & (train['Embarked'] == 'Q')]['Embarked'].count() \/ train[Survived_0].shape[0])\n\n\n# S : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728\nprint('_'*20)\nprint('S : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728')\nprint('\uc0ac\ub9dd \ube44\uc728 : ',train[Survived_0 & (train['Embarked'] == 'S')]['Embarked'].count() \/ train[train['Embarked'] == 'S'].shape[0])\nprint('\uc0dd\uc874 \ube44\uc728 : ',train[Survived_1 & (train['Embarked'] == 'S')]['Embarked'].count() \/ train[train['Embarked'] == 'S'].shape[0])\n\n# C : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728\nprint('_'*20)\nprint('C : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728')\nprint('\uc0ac\ub9dd \ube44\uc728 : ',train[Survived_0 & (train['Embarked'] == 'C')]['Embarked'].count() \/ train[train['Embarked'] == 'C'].shape[0])\nprint('\uc0dd\uc874 \ube44\uc728 : ',train[Survived_1 & (train['Embarked'] == 'C')]['Embarked'].count() \/ train[train['Embarked'] == 'C'].shape[0])\n\n# Q : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728\nprint('_'*20)\nprint(' Q : \uc0ac\ub9dd \ube44\uc728 \/ \uc0dd\uc874 \ube44\uc728')\nprint('\uc0ac\ub9dd \ube44\uc728 : ',train[Survived_0 & (train['Embarked'] == 'Q')]['Embarked'].count() \/ train[train['Embarked'] == 'Q'].shape[0])\nprint('\uc0dd\uc874 \ube44\uc728 : ',train[Survived_1 & (train['Embarked'] == 'Q')]['Embarked'].count() \/ train[train['Embarked'] == 'Q'].shape[0])","2a6ee744":"# Embarked\uac00 S\uc77c \uacbd\uc6b0 Fare\uc758 \ud3c9\uade0\uac12\nprint(train[train['Embarked'] == 'S']['Fare'].mean())\n# Embarked\uac00 C\uc77c \uacbd\uc6b0 Fare\uc758 \ud3c9\uade0\uac12 \nprint(train[train['Embarked'] == 'C']['Fare'].mean())\n# Embarked\uac00 Q\uc77c \uacbd\uc6b0 Fare\uc758 \ud3c9\uade0\uac12\nprint(train[train['Embarked'] == 'Q']['Fare'].mean())","bfbf5889":"titanic_embarked = train[['Embarked', 'Survived']].groupby('Embarked')['Survived'].value_counts().sort_index().unstack()\ntitanic_embarked['Survival rate'] = titanic_embarked[1] \/ (titanic_embarked[0] + titanic_embarked[1]) * 100\n\nembarked = train['Embarked'].value_counts().sort_index()","b1bcef1e":"from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n\nfig = plt.figure(figsize=(15, 10))\ngs = fig.add_gridspec(3, 4)\nax = fig.add_subplot(gs[:-1,:])\n\ncolor_map = ['#d4dddd' for _ in range(3)]\n#color_map[2] = light_palette[2]\n\n\nbars = ax.bar(titanic_embarked['Survival rate'].index, titanic_embarked['Survival rate'], \n       color=color_map, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax.bar_label(bars, fmt='%.2f%%')\n\n\n# mean line + annotation\nmean = train['Survived'].mean() *100\nax.axhline(mean ,color='black', linewidth=0.4, linestyle='dashdot')\nax.annotate(f\"mean : {mean :.4}%\", \n            xy=('S', mean + 4),\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='#efe8d1', linewidth=0))\n    \n\n\n\nax.set_yticks(np.arange(0, 100, 20))\nax.grid(axis='y', linestyle='-', alpha=0.4)\nax.set_ylim(0, 100)\n\n\nax_bottom = fig.add_subplot(gs[-1,:])\nbars = ax_bottom.bar(embarked.index, embarked, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax_bottom.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax_bottom.bar_label(bars, fmt='%d', label_type='center', color='white')\nax_bottom.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Title & Subtitle    \nfig.text(0.1, 1, 'Embarked & Survival Rate', fontsize=15, fontweight='bold', fontfamily='serif', ha='left')\nfig.text(0.1, 0.96, 'the survival rate of Southamton is very low.', fontsize=12, fontweight='light', fontfamily='serif', ha='left')\n\nplt.show()","912acf5c":"set(train.Ticket.map(lambda x: str(x).split()[0] if len(str(x).split()) > 1 else 'XX'))","172816a5":"train['TicketType'] = train.Ticket.fillna('XX')\ntrain['TicketType'] = train.TicketType.map(lambda x: str(x).split()[0] if len(str(x).split()) > 1 else 'XX')\nprint(set(train.TicketType))","025f00e2":"train['TicketType'] = train['TicketType'].str.lower()\n\nimport re\ntrain['TicketType'] = train.TicketType.map(lambda x : re.sub(\"[^\\w\\s]+\",\"\",x))\nset(train.TicketType.to_list())","c62a585b":"train.TicketType.value_counts()\/train.shape[0]\nprint(train['TicketType'].unique().shape)","2b7fa138":"titanic_ticket_type = train[['TicketType','Survived']].groupby('TicketType')['Survived'].value_counts().sort_index().unstack()\ntitanic_ticket_type['Survival rate'] = titanic_ticket_type[1] \/ (titanic_ticket_type[0] + titanic_ticket_type[1]) * 100\nticket_type = train['TicketType'].value_counts().sort_index()\nprint(titanic_ticket_type.shape)","80090a89":"from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n\nfig = plt.figure(figsize=(15, 10))\ngs = fig.add_gridspec(2, 3)\nax = fig.add_subplot(gs[:-1,:])\n\ncolor_map = ['#d4dddd' for _ in range(35)]\ncolor_map[28] = light_palette[2]\ncolor_map[13] = light_palette[3]\n\n\nbars = ax.bar(titanic_ticket_type['Survival rate'].index, titanic_ticket_type['Survival rate'], \n       color=color_map, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax.bar_label(bars, fmt='%.2f%%', label_type='edge')\n\n\n# mean line + annotation\nmean = train['Survived'].mean() *100\nax.axhline(mean ,color='black', linewidth=0.4, linestyle='dashdot')\nax.xaxis.set_tick_params(rotation=45) # x\ucd95 \uac01\ub3c4 \uc870\uc808\nax.annotate(f\"mean : {mean :.4}%\", \n            xy=('xx', mean + 5),\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='#efe8d1', linewidth=0))\n    \n\n\n\nax.set_yticks(np.arange(0, 100, 20))\nax.grid(axis='y', linestyle='-', alpha=0.4)\nax.set_ylim(0, 100)\n\n\nax_bottom = fig.add_subplot(gs[-1,:])\nbars = ax_bottom.bar(ticket_type.index, ticket_type, width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax_bottom.spines[[\"top\",\"right\",\"left\"]].set_visible(False)\nax_bottom.bar_label(bars, fmt='%d', label_type='edge', color='black')\nax_bottom.grid(axis='y', linestyle='-', alpha=0.4)\nax_bottom.xaxis.set_tick_params(rotation=45)\n\n# Title & Subtitle    \nfig.text(0.1, 1, 'TicketType & Survival Rate', fontsize=15, fontweight='bold', fontfamily='serif', ha='left')\nfig.text(0.1, 0.96, 'the survival rate of stono is very low.', fontsize=12, fontweight='light', fontfamily='serif', ha='left')\n\nplt.show()","f9f88f6e":"print(pd.crosstab(index = train.TicketType, columns=train.Pclass, normalize='index'))","35a8d851":"num_1_ratio = pd.crosstab(index = train.TicketType, columns = train.Pclass, normalize='index')[1].mean(axis=0)\nnum_2_ratio = pd.crosstab(index = train.TicketType, columns = train.Pclass, normalize='index')[2].mean(axis=0)\n\nupper_class_ratio = num_1_ratio + num_2_ratio","c5479d66":"pd.crosstab(index = train.TicketType, columns = train.Pclass, normalize = 'index').sort_values(by = 1).plot.bar(figsize = (15 ,7), stacked = True)\n\nplt.axhline(y = upper_class_ratio, color = 'r', linestyle = '-')","01a10c3e":"pd.crosstab(index = train.TicketType, columns = train.Survived, normalize = 'index').sort_values(by=1).plot.bar(figsize=(15, 7), stacked = True)\n\ndeath_mean_rate = 1 - train['Survived'].mean()\n\nplt.axhline(y = death_mean_rate ,color = 'r', linestyle = '-')","f1084fca":"train['TT_bucket'] = train.TicketType.map(lambda x:0 if x == 'pc' else 3 if x in ['stono', 'stono2', 'sotono2', 'stonoq', 'aq3', 'a', 'a5', 'sotonoq', 'fa', 'ca'] \\\n                                          else 2 if x in ['fcc', 'scow', 'caston', 'wc', 'c', 'wep', 'swpp', 'ppp', 'scah', 'soc', 'sopp'] else 1)\n\ntrain['TT_bucket'].value_counts()","48d7a3e2":"pd.crosstab(index = train.TT_bucket, columns = train.Survived, normalize = 'index').sort_values(by = 1).plot.bar(figsize = (15, 7), stacked = True)","85fc8147":"print(train.Fare.describe())","11e54fcd":"sns.boxplot(x = train.Pclass, y = np.log(1+train.Fare))","76848313":"FareByClass = pd.crosstab(index = train.Pclass, columns = 'MedianFare', values = np.log(1+train.Fare), aggfunc = 'median').to_dict()['MedianFare']\n\nFareByClass","625ced60":"train['LnFare'] = np.log(1 + train['Fare'])\n\ntrain['LnFare'].fillna(train.Pclass.map(FareByClass), inplace=True)\n\n# \uacb0\uce21\uce58\uac00 Pclass \uc911\uc704\uac12\uc73c\ub85c \ub300\uccb4\ub418\uc5c8\ub2e4.\ntrain.loc[:,['Fare','LnFare']][train.Fare.isna()]","b3f85109":"fig, axs = plt.subplots(figsize = (12, 4), nrows=1, ncols=1, squeeze=False)\nsns. distplot(train['LnFare'], color='blue', ax=axs[0][0])","4846401d":"train_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\n\npseudo_labels = pd.read_csv('..\/input\/pseudo-label-file\/pseudo_label.csv')\ntest_df[TARGET] = pseudo_labels[TARGET]\n\ntrain_df.shape, test_df.shape, sample_submission.shape","47cb18d9":"temp = pd.concat([train_df, test_df]).reset_index(drop=True)","ee55ed23":"temp['Age'] = temp['Age'].fillna(temp['Age'].median())","c10d71df":"temp[\"Age_bucket\"] = pd.cut(temp['Age'], 9,\n                            labels = [\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80-89\"])","649f6cfc":"temp['Embarked'] = temp['Embarked'].fillna('N')","c6959785":"# Cabin\uc774 \ud560\ub2f9\ub41c \uc0ac\ub78c\ub4e4\uacfc \uadf8\ub807\uc9c0 \uc54a\uc740 \uc0ac\ub78c\ub4e4\uc744 \uad6c\ubd84\ud558\uae30 \uc704\ud55c \ubcc0\uc218\ntemp['CabinNotAlloted'] = temp.Cabin.isna().astype(int)\nprint(temp['CabinNotAlloted'].value_counts()\/temp.shape[0])","019579d1":"temp['Cabin'] = temp.Cabin.str[:1]\ntemp['Cabin'].fillna('X')","8297474f":"set(temp.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'XX'))","0cf6d34d":"temp['TicketType'] = temp.Ticket.fillna('XX')\ntemp['TicketType'] = temp.TicketType.map(lambda x: str(x).split()[0] if len(str(x).split()) > 1 else 'XX')\nprint(set(temp.TicketType))","6e4d7926":"temp['TicketType'] = temp['TicketType'].str.lower()\n\nimport re\ntemp['TicketType'] = temp.TicketType.map(lambda x: re.sub(\"[^\\w\\s]+\",\"\",x))\nset(temp.TicketType.to_list())","c7767387":"temp['TT_bucket'] = temp.TicketType.map(lambda x:0 if x == 'pc' else 3 if x in ['stono', 'stono2', 'sotono2', 'stonoq', 'aq3', 'a', 'a5', 'sotonoq', 'fa', 'ca'] \\\n                                          else 2 if x in ['fcc', 'scow', 'caston', 'wc', 'c', 'wep', 'swpp', 'ppp', 'scah', 'soc', 'sopp'] else 1)","99944907":"FareByClass = pd.crosstab(index = temp.Pclass, columns = 'MedianFare', values = np.log(1+temp.Fare), aggfunc = 'median').to_dict()['MedianFare']\nFareByClass","80f7f2d2":"temp['LnFare'] = np.log(1+temp['Fare'])\n\ntemp['LnFare'].fillna(temp.Pclass.map(FareByClass), inplace = True)","764f02dd":"temp['FamilySize'] = temp['SibSp'] + temp['Parch'] + 1","c3c3f1f3":"def family_size(x):\n    if x == 1:\n        return \"alone\"\n    else:\n        return \"notalone\"","4bb0f819":"temp['Group'] = temp['FamilySize'].apply(family_size)\nprint(temp['Group'].value_counts())","bb4d8d3e":"temp.columns","83c38108":"temp.select_dtypes(exclude=['float64','int64','bool']).columns","61fd38ee":"np.where((temp.dtypes != 'float64')&(temp.dtypes != 'int64')&(temp.dtypes != 'bool'))[0].tolist()","610ade12":"categorical_feature = np.where((temp.dtypes != 'float64')&(temp.dtypes != 'int64')&(temp.dtypes != 'bool'))[0].tolist()\ncategorical_feature_columns = temp.select_dtypes(exclude=['float64','int64','bool']).columns","a011d2f2":"# label = LabelEncoder()\n# for column in categorical_feature_columns:\n#     temp[column] = label.fit_transform(temp[column].astype(str))\n","28d91529":"temp.columns","e2b9580a":"label_cols = ['Sex','CabinNotAlloted', 'TT_bucket', 'Cabin','Group']\nonehot_cols = ['Age_bucket','Embarked']\nnumerical_cols = ['LnFare','Age','Pclass']","3689fd71":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c.astype(str))","b2b1f69d":"#scaler = StandardScaler()\n\nonehot_encoded_df = pd.get_dummies(temp[onehot_cols])\nlabel_encoded_df = temp[label_cols].apply(label_encoder)\nnumerical_df = pd.DataFrame(temp[numerical_cols], columns=numerical_cols)\ntarget_df = temp['Survived']\n\nall_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)","faf11995":"X = all_df.drop([TARGET], axis = 1)\ny = all_df[TARGET]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = RANDOM_SEED)","32079914":"test = all_df[len(train):].drop([TARGET], axis = 1)","afdd1d24":"import sklearn\nprint(sklearn.__version__)","0d570d1f":"!pip install bayesian-optimization==1.1.0","8a505ae3":"from bayes_opt import BayesianOptimization","f115aa74":"bayes_x,bayes_x_test,bayes_y,bayes_y_test = train_test_split(X, y, test_size=0.2, random_state=0)","23936a3b":"from sklearn.ensemble import RandomForestClassifier","e278b979":"# rf_params ={\n#     'max_depth': (3, 10),\n#     'min_samples_leaf': (5,30),\n#     'min_samples_split': (5, 30)\n# }","b2a7d899":"# def rf_roc_eval(max_depth, min_samples_split, min_samples_leaf):\n    \n#     params = {\n#         'n_estimators' : 1000,\n#         'max_depth' : int(round(max_depth)),\n#         'min_samples_split' : int(round(min_samples_split)),\n#         'min_samples_leaf' : int(round(min_samples_leaf)),\n#     }\n#     rf_model = RandomForestClassifier(**params)\n#     rf_model.fit(bayes_x, bayes_y)\n#     valid_proba = rf_model.predict_proba(bayes_x_test)[:,1]\n#     roc_preds = roc_auc_score(bayes_y_test, valid_proba)\n    \n#     return roc_preds","f69c84c1":"# BO_rf = BayesianOptimization(rf_roc_eval, rf_params, random_state=2121)","6f0630c1":"# BO_rf.maximize(init_points=5, n_iter=10)","864cc66e":"# BO_rf.max ","157a2ed1":"# rf_parameters = {\n#   'max_depth': 10,\n#   'min_samples_leaf': int(round(10.898930640403934)),\n#   'min_samples_split': 30}","fed2d23c":"# rf_test_pred = np.zeros(len(test))\n# n_splits = 5\n\n# skfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# rf_acc=[]\n# rf_auc=[]\n\n# for train_index, valid_index in skfold.split(X, y):\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n#     rf_wrapper = RandomForestClassifier(**rf_parameters)\n\n#     rf_wrapper.fit(X_train, y_train)\n\n\n#     rf_test_pred += rf_wrapper.predict_proba(test_df)[:,1]\/n_splits\n#     rf_auc.append(roc_auc_score(y_valid, rf_wrapper.predict_proba(X_valid)[:,1]))\n#     rf_acc.append(accuracy_score(y_valid, (rf_wrapper.predict_proba(X_valid)[:,1] > 0.5).astype(int)))\n\n# print(f'AUC: {np.mean(rf_auc)}')\n# print(f'ACC: {np.mean(rf_acc)}')","89c3e7d7":"# from sklearn.ensemble import GradientBoostingClassifier\n","49bc0e03":"# gbc_params = {\n#     'max_features' : (0.1,1),\n#     'max_depth' : (3, 10),\n#     'min_samples_split' : (2, 10),\n#     'min_samples_leaf' : (100, 150),\n# }","8aaf9abb":"# def gbc_roc_eval(max_features, max_depth, min_samples_split, min_samples_leaf):\n    \n#     params = {\n#         'loss' : 'deviance',\n#         'n_estimators' : 1000,\n#         'learning_rate':0.01,\n#         'max_features' : max_features,\n#         'max_depth' : int(round(max_depth)),\n#         'min_samples_split' : int(round(min_samples_split)),\n#         'min_samples_leaf' : int(round(min_samples_leaf)),\n#     }\n#     gbc_model = GradientBoostingClassifier(**params)\n#     gbc_model.fit(bayes_x, bayes_y)\n#     valid_proba = gbc_model.predict_proba(bayes_x_test)[:,1]\n#     roc_preds = roc_auc_score(bayes_y_test, valid_proba)\n    \n#     return roc_preds","5359d6a3":"# BO_gbc = BayesianOptimization(gbc_roc_eval, gbc_params, random_state=2121)","e75ce0e3":"# BO_gbc.maximize(init_points=5, n_iter=5)","7b52f08c":"# BO_gbc.max ","30ca8461":"# gbc_parameters = {'max_depth': int(round(7.18465375161774)),\n#   'max_features': 0.4861929134696539,\n#   'min_samples_leaf': int(round(113.13022692803058)),\n#   'min_samples_split': int(round(8.386778166939953))}","98058f63":"# gbc_test_pred = np.zeros(len(test))\n# n_splits = 5\n\n# skfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# gbc_acc=[]\n# gbc_auc=[]\n\n# for train_index, valid_index in skfold.split(X, y):\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n#     gbc_wrapper = GradientBoostingClassifier(**gbc_parameters)\n\n#     gbc_wrapper.fit(X_train, y_train)\n\n\n#     gbc_test_pred += gbc_wrapper.predict_proba(test_df)[:,1]\/n_splits\n#     gbc_auc.append(roc_auc_score(y_valid, gbc_wrapper.predict_proba(X_valid)[:,1]))\n#     gbc_acc.append(accuracy_score(y_valid, (gbc_wrapper.predict_proba(X_valid)[:,1] > 0.5).astype(int)))\n\n# print(f'AUC: {np.mean(gbc_auc)}')\n# print(f'ACC: {np.mean(gbc_acc)}')","19374384":"lgb_params = {\n    'num_leaves': (2, 50),\n    'colsample_bytree':(0.1, 1), \n    'subsample': (0.1, 1),\n    'max_depth': (1, 50),\n    'reg_alpha': (0, 0.5),\n    'reg_lambda': (0, 0.5), \n    'min_split_gain': (0.001, 0.1),\n    'min_child_weight':(0, 50),\n    'subsample_freq': (2, 50),\n    'max_bin': (5,200),\n}","2fca2b89":"def lgb_roc_eval(num_leaves, colsample_bytree, subsample, max_depth, reg_alpha, reg_lambda, min_split_gain, min_child_weight, subsample_freq, max_bin):\n    \n    params = {\n        'learning_rate':0.01,\n        'num_leaves': int(round(num_leaves)),   #  \ud638\ucd9c \uc2dc \uc2e4\uc218\ud615 \uac12\uc774 \ub4e4\uc5b4\uc624\ubbc0\ub85c \uc815\uc218\ud615 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub294 \uc815\uc218\ud615\uc73c\ub85c \ubcc0\uacbd \n        'colsample_bytree': colsample_bytree, \n        'subsample': subsample,\n        'max_depth': int(round(max_depth)),\n        'reg_alpha': reg_alpha,\n        'reg_lambda': reg_lambda, \n        'min_split_gain': min_split_gain,\n        'min_child_weight': min_child_weight,\n        'subsample_freq': int(round(subsample_freq)),\n        'max_bin': int(round(max_bin)),\n    }\n    lgb_model = LGBMClassifier(**params)\n    lgb_model.fit(bayes_x, bayes_y, eval_set=[(bayes_x_test, bayes_y_test)], early_stopping_rounds=100, eval_metric=\"auc\", verbose=False)\n    valid_proba = lgb_model.predict_proba(bayes_x_test, num_iteration=10)[:,1]\n    roc_preds = roc_auc_score(bayes_y_test, valid_proba)\n    \n    return roc_preds","fcf43166":"BO_lgb = BayesianOptimization(lgb_roc_eval, lgb_params, random_state=2121)","81ba1bcb":"BO_lgb.maximize(init_points=5, n_iter=10)\n\n\nBO_lgb.max \n","fee755f9":"lgbm_parameters = {'colsample_bytree': 1.0,\n  'max_bin': int(round(96.7766796372883)),\n  'max_depth': int(round(42.05282337818611)),\n  'min_child_weight': 21.27282313847847,\n  'min_split_gain': 0.001,\n  'num_leaves': 50,\n  'reg_alpha': 0.5,\n  'reg_lambda': 0.0,\n  'subsample': 0.16553781580032617,\n  'subsample_freq': int(round(7.597521726169598))}\n\n","6de0cd9f":"lgbm_parameters['objective'] = 'binary'\nlgbm_parameters['n_estimators'] = 1000","7cb0d572":"# lgbm_test_pred = np.zeros(len(test))\n# n_splits = 5\n\n# skfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# lgbm_acc=[]\n# lgbm_auc=[]\n\n# for train_index, valid_index in skfold.split(X, y):\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n#     lgbm_wrapper = LGBMClassifier(**lgbm_parameters)\n\n#     evals = [(X_valid, y_valid)]\n#     lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"binary_logloss\", \n#                     eval_set=evals, verbose=False)\n\n\n#     lgbm_test_pred += lgbm_wrapper.predict_proba(test_df)[:,1]\/n_splits\n#     lgbm_auc.append(roc_auc_score(y_valid, lgbm_wrapper.predict_proba(X_valid)[:,1]))\n#     lgbm_acc.append(accuracy_score(y_valid, (lgbm_wrapper.predict_proba(X_valid)[:,1] > 0.5).astype(int)))\n\n# print(f'AUC: {np.mean(lgbm_auc)}')\n# print(f'ACC: {np.mean(lgbm_acc)}')\n\n\n","4bc13db9":"# plt.rcParams[\"figure.figsize\"] = (6, 4)\n# lightgbm.plot_importance(lgbm_wrapper,max_num_features = 16,height=.9)","8693c317":"# xgb_params = {\n#     'colsample_bytree':(0.1, 1),\n#     'colsample_bynode':(0.1, 1),\n#     'subsample': (0.5, 1),\n#     'max_depth': (3, 10),\n#     'min_child_weight':(0, 50),\n#     'max_bin': (5,200),\n#     'learning_rate': (0.01, 0.2)\n# }","2c975bc7":"# def xgb_roc_eval(colsample_bytree, colsample_bynode, subsample, max_depth, min_child_weight, max_bin, learning_rate):\n    \n#     params = {\n#         'n_estimators' : 1000,\n#         'colsample_bytree' : colsample_bytree,\n#         'colsample_bynode' : colsample_bynode,\n#         'subsample':subsample,\n#         'max_depth':int(round(max_depth)),\n#         'min_child_weight':min_child_weight,\n#         'max_bin': int(round(max_bin)),\n#         'learning_rate' : learning_rate}\n    \n#     xgb_model = XGBClassifier(**params)\n#     xgb_model.fit(bayes_x, bayes_y, eval_set=[(bayes_x_test, bayes_y_test)], early_stopping_rounds=100, eval_metric=\"auc\", verbose=False )\n#     valid_proba = xgb_model.predict_proba(bayes_x_test)[:,1]\n#     roc_preds = roc_auc_score(bayes_y_test, valid_proba)\n\n#     return roc_preds\n    \n    \n\n    ","719c6660":"# BO_xgb = BayesianOptimization(xgb_roc_eval,xgb_params, random_state= SEED)","78b381b7":"# BO_xgb.maximize(init_points=5, n_iter=10)","3e5dd9ab":"# BO_xgb.max","afbdb599":"# xgb_parameters = {'colsample_bynode': 0.2816652230511576,\n#   'colsample_bytree': 0.6123746062455153,\n#   'learning_rate': 0.04706823512500192,\n#   'max_bin': int(round(118.8222831831757)),\n#   'max_depth': int(round(6.3341943151448135)),\n#   'min_child_weight': 25.890720015058704,\n#   'subsample': 0.9115493169826735}","20de5085":"# xgb_parameters['objective'] = 'binary:logistic'\n# xgb_parameters['n_estimators'] = 15000\n# xgb_parameters['booster'] ='gbtree'","d40a4ada":"# xgb_test_pred = np.zeros(len(test))\n# n_splits = 10\n\n# skfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# xgb_acc = []\n# xgb_auc = []\n\n# for train_index, valid_index in skfold.split(X,y):\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n#     xgb_wrapper = XGBClassifier(**xgb_parameters)\n    \n#     evals = [(X_valid, y_valid)]\n#     xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='auc', eval_set=evals, verbose=False)\n    \n#     xgb_test_pred += xgb_wrapper.predict_proba(test_df)[:,1]\/n_splits\n#     xgb_acc.append(accuracy_score(y_valid, xgb_wrapper.predict(X_valid)))\n#     xgb_auc.append(roc_auc_score(y_valid, (xgb_wrapper.predict_proba(X_valid)[:,1] > 0.5).astype(int)))\n    \n#     print(f'AUC: {np.mean(xgb_auc)}')\n#     print(f'ACC: {np.mean(xgb_acc)}')\n    ","568ffb91":"import catboost as ctb\nprint(ctb.__version__)\n\nfrom catboost import CatBoostClassifier","625fd904":"cat_params = {\n    'bagging_temperature': (0, 1000),\n    'depth':(5, 10),\n    'learning_rate' : (0.001, 0.1),\n    'min_data_in_leaf': (1, 6),\n    'border_count': (5, 255)\n}","129ae666":"def cat_eval(bagging_temperature, depth, learning_rate, min_data_in_leaf, border_count):\n    \n    params = {\n        'iterations' : 1000,\n        'bootstrap_type': 'Poisson',\n        'loss_function': 'Logloss',\n        'eval_metric': 'Logloss',\n        'random_seed' : 2021,\n        'learning_rate': learning_rate,\n        'min_data_in_leaf' : int(round(min_data_in_leaf)),\n        'depth' : int(round(depth)),\n        'border_count' : int(round(border_count)),\n        'bagging_temperature' : int(round(bagging_temperature)),\n    }\n    \n\n    cat_model = ctb.CatBoostClassifier(**params , \n                             task_type = \"GPU\" , \n                             leaf_estimation_iterations = 10,\n                             use_best_model=True,\n                             od_type=\"Iter\",\n                             logging_level='Silent',\n                            )\n        \n    cat_model.fit(bayes_x, bayes_y, eval_set=[(bayes_x_test, bayes_y_test)], early_stopping_rounds=100, verbose=False )\n    valid_proba = cat_model.predict_proba(bayes_x_test)[:,1]\n    roc_preds = roc_auc_score(bayes_y_test, valid_proba)\n    \n    return roc_preds\n\n    ","1a258e0e":"BO_cat = BayesianOptimization(cat_eval, cat_params, random_state= 2021)","3dc213eb":"init_round=5\nopt_round = 10\nBO_cat.maximize(init_points=init_round, n_iter=opt_round)\n","ccbb6be8":"BO_cat.max ","a384e1cd":"cat_parameters =  {'bagging_temperature': 336.423722456227,\n  'border_count': int(round(162.7138405985893)),\n  'depth': int(round(6.9435686140283925)),\n  'learning_rate': 0.07481852543291631,\n  'min_data_in_leaf': 1.8238200222157603}","aee49811":"# feature_importances = pd.DataFrame()\n# cat_test_pred = np.zeros(len(test))\n# n_splits = 5\n\n# skfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# cat_acc = []\n# cat_auc = []\n\n# for train_index, valid_index in skfold.split(X,y):\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n#     cat_model = ctb.CatBoostClassifier(**cat_parameters)\n    \n#     evals = [(X_valid, y_valid)]\n#     cat_model.fit(X_train, y_train, early_stopping_rounds=100,eval_set=evals, verbose=False)\n    \n#     cat_test_pred += cat_model.predict_proba(test_df)[:,1]\/n_splits\n#     cat_acc.append(accuracy_score(y_valid, cat_model.predict(X_valid)))\n#     cat_auc.append(roc_auc_score(y_valid, (cat_model.predict_proba(X_valid)[:,1] > 0.5).astype(int)))\n    \n#     fi_tmp = pd.DataFrame()\n#     fi_tmp[\"feature\"] = X_valid.columns.to_list()\n#     fi_tmp[\"importance\"] = cat_model.get_feature_importance()\n#     feature_importances = feature_importances.append(fi_tmp)\n\n    \n#     print(f'AUC: {np.mean(cat_auc)}')\n#     print(f'ACC: {np.mean(cat_acc)}')","e7738be9":"# just to get ideas to improve\n# order = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n# plt.figure(figsize=(10, 10))\n# sns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\n# plt.title(\"{} importance\".format(\"CatBoostClassifier\"))\n# plt.tight_layout()","8d498e5d":"# def create_submission(model, X_test, test_passenger_id, model_name):\n#     y_pred_test = model.predict_proba(test_df)[:, 1]\n#     submission = pd.DataFrame(\n#         {\n#             'PassengerId': test_passenger_id, \n#             'Survived': (y_pred_test >= 0.5).astype(int),\n#         }\n#     )\n#     submission.to_csv(f\"submission_{model_name}.csv\", index=False)\n    \n#     return y_pred_test","d62800ce":"# test_for_passengerId = temp.iloc[100000:, :] #100000\uac1c~ \n# print(test_for_passengerId.columns)\n\n# test = all_df.iloc[100000:,:]\n# print(test.columns)\n\n# X_test=all_df.drop('Survived',axis=1)\n# print(X_test.head())","854acd5b":"# test_pred_lightgbm = create_submission(\n#     lgbm_wrapper, X_test, test_for_passengerId[\"PassengerId\"], \"lightgbm\"\n# )\n\n# test_pred_catboost = create_submission(\n#     cat_model, X_test, test_for_passengerId[\"PassengerId\"], \"lightgbm\"\n# )\n\n# test_pred_gbc = create_submission(\n#      gbc_wrapper, X_test, test_for_passengerId[\"PassengerId\"], \"lightgbm\"\n#  )\n\n# test_pred_rf = create_submission(\n#      rf_wrapper, X_test, test_for_passengerId[\"PassengerId\"], \"lightgbm\"\n#  )","5a7ba943":"# test_pred_merged = (\n\n#     test_pred_lightgbm +\n#     test_pred_catboost +\n#     test_pred_rf\n    \n# )\n# test_pred_merged = np.round(test_pred_merged \/ 3)","81813e49":"# submission = pd.DataFrame(\n#     {\n#         'PassengerId': test_for_passengerId[\"PassengerId\"], \n#         'Survived': test_pred_merged.astype(int),\n#     }\n# )\n# submission.to_csv(f\"submission_merged2.csv\", index=False)","7c9638d4":"# from sklearn.ensemble import VotingClassifier","4a1ba6ea":"# clf = VotingClassifier(estimators=[('lgbm',lgbm_wrapper),('cat',cat_model)], voting = 'soft')\n# clf.fit(X, y)","286ecd33":"# y_pred = clf.predict(X_test).astype(int)","e3b9b061":"# submission = pd.DataFrame(\n#     {\n#         'PassengerId': test[\"PassengerId\"], \n#         'Survived': y_pred,\n#     }\n# )\n# submission.to_csv(f\"submission_soft_voting.csv\", index=False)","af2f240c":"#pip install shap","816812fe":"# import shap\n\n# model = lightgbm.LGBMRegressor().fit(X,y)\n\n# explainer = shap.Explainer(model)\n# shap_values = explainer(X)\n\n# shap.plots.waterfall(shap_values[0])\n\n# shap.plots.bar(shap_values)","6b37a4f4":"from sklearn.linear_model import LogisticRegression\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn import model_selection\nfrom sklearn import metrics","545a50b8":"cl1 = CatBoostClassifier(**cat_parameters, verbose = None, logging_level = 'Silent')\ncl2 = LGBMClassifier(**lgbm_parameters)","71a47b5e":"mlr = LogisticRegression()","be4b7fcf":"scl = StackingCVClassifier(classifiers = [cl1, cl2],\n                          meta_classifier = mlr,\n                          use_probas = PROBAS,\n                          random_state = RANDOM_SEED)\n\nNUM_CLAS = 3\n\nclassifiers = {'CatBoost' : cl1,\n               'LGBM': cl2,\n               'Stacked' : scl}","e881fbd4":"print(\">>>> Training started <<<<\")\nfor key in classifiers:\n    classifier = classifiers[key]\n    scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=FOLDS, scoring='accuracy')\n    print(\"[%s] = accuracy: %0.2f\" % (key, scores.mean()))\n    classifier.fit(X_train, y_train)\n    \n    classifiers[key] = classifier","5414e367":"preds = pd.DataFrame()\n\nfor key in classifiers:\n    y_pred = classifiers[key].predict_proba(X_test)[:,1]\n    preds[f\"{key}\"] = y_pred\n    auc = metrics.roc_auc_score(y_test, y_pred)\n    print(f\"{key} --> AUC: {auc:.3f}\")\n    \npreds[TARGET] = pd.DataFrame(y_test).reset_index(drop=True)","97f4609a":"test_preds = classifiers['Stacked'].predict_proba(test)[:,1]","6e24fb10":"threshold = pd.Series(test_preds).sort_values(ascending = False).head(34911).values[-1]\nprint(f\"Current threshold is: {threshold}\")","3fe1d4ab":"sample_submission['submit_1'] = (test_preds > threshold).astype(int)\nsample_submission['submit_1'].mean()","f7f9cadf":"sample_submission['submit_2'] = pd.read_csv(\"..\/input\/pseudo-label-file\/another.csv\")[TARGET]\nsample_submission['submit_3'] = pseudo_labels[TARGET]","7df71873":"sample_submission[[col for col in sample_submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()","6b1f4593":"sample_submission[TARGET] = (sample_submission[[col for col in sample_submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)\nsample_submission[TARGET].mean()","56b8f386":"sample_submission[['PassengerId', TARGET]].to_csv(\"submission.csv\", index = False)","39d773fc":"- Dataset will be divided into two groups - categorical variables and numerical variables\n","e7f4c9d9":"Embarked \ubcc0\uc218 \uc804\ucc98\ub9ac","810ad761":"<a id='split_data'><\/a>\n### (5) Split Data\n- Based on Feature Engineering, the final task is to re-split all data into independent variables and dependent variables. \n\n\n\n","a7b5e3c2":"\ub098\uc774\uac00 \ub9ce\uace0 \uc694\uae08\uc744 \ub9ce\uc774 \ub0b8 \uc2b9\uac1d\uc758 \uc0dd\uc874\ud655\ub960\uc774 \ub192\uc744 \uac83\uc774\ub77c\ub294 \uac00\uc815\ud558\uc5d0\uc11c \uc2b9\uac1d\ub4e4\uc774 \ub0b8 \uc694\uae08\uacfc \ub098\uc774\ub97c \uacf1\ud558\uc5ec \ubcc0\uc218\ub97c \ub9cc\ub4e4\uc5c8\uace0 \ud2b9\uc815 \uad6c\uac04\ubcc4\ub85c \ubc94\uc8fc\ub97c \ub098\ub204\uc5b4 \uc0dd\uc874\ud655\ub960\uc744 \ubd84\uc11d\ud55c \uadf8\ub798\ud504","59e65d81":"[ \uc815 \ubcf4 ]\n\n1\ub4f1\uc2e4 : (\uc751\uc811\uc2e4\uc774 \ub538\ub9b0 \uc2a4\uc704\ud2b8 \ub8f8) $4,350\n\n1\ub4f1\uc2e4 : (\uce68\uc2e4\uce78) $150\n\n2\ub4f1\uc2e4 : 60$\n\n3\ub4f1\uc2e4 : 15~40$\n\n\uc774 \ub370\uc774\ud130 \uc14b\uc5d0\uc11c\ub294 \ucd5c\uc18c \uc694\uae08\uc774 0.68$, \ucd5c\ub300 \uc694\uae08\uc774 744.66$","4090ccdf":"- \ube68\uac04\uc120\uc740 \ud3c9\uade0 \uc0ac\ub9dd \ube44\uc728\uc744 \ub098\ud0c0\ub0b8\ub2e4.\n\n- 1, 2\ub4f1\uae09 \ud074\ub798\uc2a4 \ube44\uc728\uc774 \ub192\uc740 \ud2f0\ucf13 \uc885\ub958\ub4e4\uc740 1, 2\ub4f1\uae09 \ud074\ub798\uc2a4 \ube44\uc728\uc774 \ub0ae\uc740 \ud2f0\ucf13 \uc885\ub958\ub4e4\uc758 \ube44\ud574 \uc0ac\ub9dd\ub960\uc774 \ub0ae\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.\n\n- \uc774\ub97c \ud1b5\ud574 \ubd80\uc720\ud55c \uc0ac\ub78c\ub4e4\uc758 \uc0dd\uc874\ub960\uc774 \uac00\ub09c\ud55c \uc0ac\ub78c\ub4e4\uc758 \uc0dd\uc874\ub960 \ubcf4\ub2e4 \ub192\ub2e4\ub294 \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud574\ub0bc \uc218 \uc788\ub2e4.","5e4d16f1":"\ub85c\uadf8 \ubcc0\ud658\ud55c Fare \ubcc0\uc218 \uc804\ucc98\ub9ac","bd759a8a":"\uadf8\ub798\ud504\ub97c \ubcf4\uba74 \uc0dd\uc874\ub960\uc774 \ub192\uc740 \ud2f0\ucf13 \uc885\ub958\ub4e4\uacfc \uc0dd\uc874\ub960\uc774 \ub0ae\uc740 \ud2f0\ucf13 \uc885\ub958\ub4e4\uc774 \uc788\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4. \uc0dd\uc874\ub960\uc758 \ucc28\uc774\uc5d0 \ub300\ud55c \uc6d0\uc778\uc744 \ube48\ubd80 \uaca9\ucc28\ub77c\uace0 \uac00\uc815\ud558\uace0 \ud2f0\ucf13 \uc885\ub958\ubcc4 Pclass\uc758 \ube44\uc728\uc744 \ubd84\uc11d\ud574\ubcf4\uc558\ub2e4.","72001ce2":"<a id=\"overview\"><\/a>\n## Overview\n- This is my personal tutorial sharing with my students as example. \n- The whole processes will be shared from EDA to Modeling and Evaluation, Finally Submission. \n    + Let's Check My [EDA Code](https:\/\/www.kaggle.com\/j2hoon85\/2021-april-play-ground-eda-for-kaggle-newbies)\n- The well-known notebooks shared will be enough for students to learn Kaggle as an entry level. \n\n> Happy to Code","4047cba4":"**catboost**","38e9b49a":"Family Size","1bb3da84":"<a id=\"scikit_learn\"><\/a>\n## Scikit Learn\n- Let's make simple model based on Scikit Learn Framework.\n- URL: https:\/\/scikit-learn.org\/stable\/\n\n![](https:\/\/scikit-learn.org\/stable\/_images\/scikit-learn-logo-notext.png)","f2dc0ea9":"- expand = True --> \ub370\uc774\ud130 \ud504\ub808\uc784\uc73c\ub85c \ubc18\ud658\ud55c\ub2e4\n- expand = False --> \uc2dc\ub9ac\uc988 \ub610\ub294 \uc778\ub371\uc2a4\ub85c \ubc18\ud658\ud55c\ub2e4.\n- '([A-Za-z]+)\\,'\ub294 \uc815\uaddc\ud45c\ud604\uc2dd\uc73c\ub85c\uc368, \uacf5\ubc31\uc73c\ub85c \uc2dc\uc791\ud558\uace0 ','\ub85c \ub05d\ub098\ub294 \ubb38\uc790\uc5f4\uc744 \ucd94\ucd9c\ud560 \ub54c \uc0ac\uc6a9 ","4122187c":"Drop the unnecessary columns","36627df2":"<a id='feature_encoding'><\/a>\n### (4) Feature Encoding\n- Let's check each column's data type","2698643f":"BaysianOptimization","d4b11102":"\uc5f0\ub839\ub300\ubcc4 \uc0dd\uc874 \ud655\ub960\uc744 \ub098\ud0c0\ub0b8 \uadf8\ub798\ud504","5864f4cc":"Cabin \ubcc0\uc218 \uc804\ucc98\ub9ac","73a59574":"### (3)Data visualization","6d5dcc5a":"**xgboost**","5decc3c8":"pd.cut(X, bins, labels) \ub97c \uc774\uc6a9\ud55c \uc5f0\uc18d\ud615 \ubcc0\uc218\uc758 \uc5ec\ub7ec\uac1c \uad6c\uac04\ubcc4 \ubc94\uc8fc\ud654 ","fee16190":"<a id=\"limitation\"><\/a>\n### (6) Limitation\n- What I missed here is not to create new variable so-called wealthy class and others, yet. My assumption is wealthy people were more survived than other group. This will be compared baseline model with the more upgraded model, reflecting new feature. If some readers get this idea, then please implement it. Hope to see a better model. ","9173b550":"<a id=\"feature_engineering\"><\/a>\n## Feature Engineering\n- After EDA, it's time to conduct Feature Engineering. \n- If you are not familiar with this concept, then please read a book\n\n![Feature Engineering for Machine Learning](https:\/\/learning.oreilly.com\/library\/cover\/9781491953235\/250w\/)\n    \n- And If you need a short summary about feature engineering, then please check this article as well. \n    + [@Chris Deotte Feature Engineering Techniques](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/108575)","5a613cb3":"**Fare**","6591cced":"\ubcc0\uc218 \uac04 \uc0c1\uad00\uad00\uacc4\ub97c \ub098\ud0c0\ub0b8 \uadf8\ub798\ud504","8da4e4b3":"**Ticket**","a8e2d10b":"**RandomForest**","7cd8e130":"**\ud2f0\ucf13 \ubcc0\uc218 \uc804\ucc98\ub9ac**","1ed998c3":"### (2)Matplotlib Color & Default Setting","9b872d25":"Maltin also said that more third-class passengers died than first or second-class passengers because anyone over the age of 13 was classed as an adult in 1912, meaning that teenage boys only made it onto the lifeboats after women and children.\nhttps:\/\/www.irishcentral.com\/roots\/history\/new-documentary-debunking-titanic-myths","9bd4c220":"- \ud2f0\ucf13 \uc885\ub958\ubcc4 pclass\uc758 \ube44\uc728 \ubd84\ud3ec\ub3c4\ub97c \ub098\ud0c0\ub0b4\ub294 \uadf8\ub798\ud504\n\n- \ube68\uac04\uc0c9 \uc120\uc740 1\ub4f1\uae09 + 2\ub4f1\uae09 \ud074\ub798\uc2a4\uc758 \ud3c9\uade0 \ube44\uc728\uc744 \ub098\ud0c0\ub0b8\ub2e4.\n","6fb01707":"<a id='data_import'><\/a>\n### (1) Data Import\n- Let's get datasets","edde0277":"Age \ubcc0\uc218 \uc804\ucc98\ub9ac","d1650b7c":"Southampton\uc5d0\uc11c \uc2b9\uc120\ud55c \uc2b9\uac1d\ub4e4\uc774 \ub300\uccb4\ub85c \ud0d1\uc2b9 \uc694\uae08\uc774 \uc801\ub2e4\ub294 \ubd80\ubd84\uc5d0\uc11c \uc774\ub4e4\uc758 \ub300\ubd80\ubd84\uc774 3\ub4f1\uc2e4\uc5d0 \ud0d4\uc744 \uac83\uc774\ub77c\uace0 \uc608\uce21\ud560 \uc218 \uc788\ub2e4.","054fec84":"<a id='etiquette'><\/a>\n### Etiquette\n- When students get codes and ideas from other notebooks, then please make sure to leave a reference and upvote it as well. \ud83d\udc46\ud83d\udc46\ud83d\udc46","41b09951":"\uc131\ubcc4\uc5d0 \ub530\ub978 \uc0dd\uc874 \ube44\uc728\uc744 \ub098\ud0c0\ub0b8 \uadf8\ub798\ud504","46217f40":"- 1\ub4f1\uae09 \ube44\uc728\uc744 \uae30\uc900\uc73c\ub85c \ud558\uc5ec \ubc94\uc8fc\ud654\ub97c \ud588\uc2b5\ub2c8\ub2e4.\n\n- 0 \uc5d0\uc11c 3\uc73c\ub85c \uac08\uc218\ub85d 3\ub4f1\uae09 \ud074\ub798\uc2a4\uc758 \ube44\uc728\uc774 \ub192\uc740 \uac12\uc785\ub2c8\ub2e4.\n\n- 0 \uc5d0\uc11c 3\uc73c\ub85c \uac08\uc218\ub85d \uc0dd\uc874\ub960\uc774 \ub0ae\uc74c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n- 1\ub4f1\uae09 \ube44\uc728\uc774 \ub192\uc740 \ud2f0\ucf13\uc77c\uc218\ub85d \uc0dd\uc874\ub960\uc774 \ub192\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uace0 \uc774\ub97c \ud1b5\ud558\uc5ec \ubd80\uc720\ud55c \uc0ac\ub78c\ub4e4\uc758 \uc0dd\uc874\ub960\uc774 \ub192\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.","725819bc":"\ubc15\uc2a4 \ud50c\ub86f \uadf8\ub798\ud504\ub97c \ud655\uc778\ud558\uba74 \uc694\uae08\uc740 pclass\uc5d0 \uc758\ud574 \uacb0\uc815\ub428\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.","c193d0a3":"**Embarked**","980a09f3":"\uac01\uac01\uc758 \ubcc0\uc218 \uc548\uc5d0 \ud2b9\uc815 \uac12\uc774 \uc0dd\uc874\ub960\uc5d0 \uc5b4\ub5a0\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \uc9c1\uad00\uc801\uc73c\ub85c \ud30c\uc545\ud558\uae30 \uc704\ud55c \uadf8\ub798\ud504","7f45ae09":"\ud2f0\ucf13 \uc885\ub958\ubcc4 1,2\ub4f1\uae09\uc758 \ud3c9\uade0 \ube44\uc728","60e22599":"n_estimators\n- \uacb0\uc815\ud2b8\ub9ac\uc758 \uac2f\uc218\ub97c \uc9c0\uc815\n- Default = 10\n- \ubb34\uc791\uc815 \ud2b8\ub9ac \uac2f\uc218\ub97c \ub298\ub9ac\uba74 \uc131\ub2a5 \uc88b\uc544\uc9c0\ub294 \uac83 \ub300\ube44 \uc2dc\uac04\uc774 \uac78\ub9b4 \uc218 \uc788\uc74c\n\nmin_samples_split\n- \ub178\ub4dc\ub97c \ubd84\ud560\ud558\uae30 \uc704\ud55c \ucd5c\uc18c\ud55c\uc758 \uc0d8\ud50c \ub370\uc774\ud130\uc218 -> \uacfc\uc801\ud569\uc744 \uc81c\uc5b4\ud558\ub294\ub370 \uc0ac\uc6a9\n- Default = 2 \u2192 \uc791\uac8c \uc124\uc815\ud560 \uc218\ub85d \ubd84\ud560 \ub178\ub4dc\uac00 \ub9ce\uc544\uc838 \uacfc\uc801\ud569 \uac00\ub2a5\uc131 \uc99d\uac00\n\nmin_samples_leaf\n- \ub9ac\ud504\ub178\ub4dc\uac00 \ub418\uae30 \uc704\ud574 \ud544\uc694\ud55c \ucd5c\uc18c\ud55c\uc758 \uc0d8\ud50c \ub370\uc774\ud130\uc218\n- min_samples_split\uacfc \ud568\uaed8 \uacfc\uc801\ud569 \uc81c\uc5b4 \uc6a9\ub3c4\n- \ubd88\uade0\ud615 \ub370\uc774\ud130\uc758 \uacbd\uc6b0 \ud2b9\uc815 \ud074\ub798\uc2a4\uc758 \ub370\uc774\ud130\uac00 \uadf9\ub3c4\ub85c \uc791\uc744 \uc218 \uc788\uc73c\ubbc0\ub85c \uc791\uac8c \uc124\uc815 \ud544\uc694\n\nmax_features\n- \ucd5c\uc801\uc758 \ubd84\ud560\uc744 \uc704\ud574 \uace0\ub824\ud560 \ucd5c\ub300 feature \uac1c\uc218\n- Default = 'auto' (\uacb0\uc815\ud2b8\ub9ac\uc5d0\uc11c\ub294 default\uac00 none\uc774\uc5c8\uc74c)\n- int\ud615\uc73c\ub85c \uc9c0\uc815 \u2192\ud53c\ucc98 \uac2f\uc218 \/ float\ud615\uc73c\ub85c \uc9c0\uc815 \u2192\ube44\uc911\n- sqrt \ub610\ub294 auto : \uc804\uccb4 \ud53c\ucc98 \uc911 \u221a(\ud53c\ucc98\uac1c\uc218) \ub9cc\ud07c \uc120\uc815\n- log : \uc804\uccb4 \ud53c\ucc98 \uc911 log2(\uc804\uccb4 \ud53c\ucc98 \uac1c\uc218) \ub9cc\ud07c \uc120\uc815\n\nmax_depth\n- \ud2b8\ub9ac\uc758 \ucd5c\ub300 \uae4a\uc774\n- default = None\n\n\u2192 \uc644\ubcbd\ud558\uac8c \ud074\ub798\uc2a4 \uac12\uc774 \uacb0\uc815\ub420 \ub54c \uae4c\uc9c0 \ubd84\ud560\n\ub610\ub294 \ub370\uc774\ud130 \uac1c\uc218\uac00 min_samples_split\ubcf4\ub2e4 \uc791\uc544\uc9c8 \ub54c\uae4c\uc9c0 \ubd84\ud560\n\n- \uae4a\uc774\uac00 \uae4a\uc5b4\uc9c0\uba74 \uacfc\uc801\ud569\ub420 \uc218 \uc788\uc73c\ubbc0\ub85c \uc801\uc808\ud788 \uc81c\uc5b4 \ud544\uc694\n\nmax_leaf_nodes\n\ub9ac\ud504\ub178\ub4dc\uc758 \ucd5c\ub300 \uac1c\uc218","4f54ddfc":"### \ud559\uc2b5 \ucd08\ubaa8\uc218\n- objective [\uae30\ubcf8\uc124\uc815\uac12=reg:linear]: \uc9c0\ub3c4\ud559\uc2b5 \uc190\uc2e4 \ucd5c\uc18c\ud654 \ud568\uc218\ub97c \uc815\uc758\n- binary:logistic: \uc774\ud56d \ubd84\ub958 \ubb38\uc81c \ub85c\uc9c1\uc2a4\ud2f1 \ud68c\uadc0\ubaa8\ud615\uc73c\ub85c \ubc18\ud658\uac12\uc774 \ud074\ub798\uc2a4\uac00 \uc544\ub2c8\ub77c \uc608\uce21 \ud655\ub960.\n- multi:softmax: \ub2e4\ud56d \ubd84\ub958 \ubb38\uc81c\uc758 \uacbd\uc6b0 \uc18c\ud504\ud2b8\ub9e5\uc2a4(Softmax)\ub97c \uc0ac\uc6a9\ud574\uc11c \ubd84\ub958\ud558\ub294\ub370 \ubc18\ud690\ub418\ub294 \uac12\uc774 \uc608\uce21\ud655\ub960\uc774 \uc544\ub2c8\ub77c \ud074\ub798\uc2a4\uc784. \ub610\ud55c num_class\ub3c4 \uc9c0\uc815\ud574\uc57c\ud568.\n- multi:softprob: \uac01 \ud074\ub798\uc2a4 \ubc94\uc8fc\uc5d0 \uc18d\ud558\ub294 \uc608\uce21\ud655\ub960\uc744 \ubc18\ud658\ud568.\n    - eval_metric: \uc124\uc815\ud55c objective\ubcc4\ub85c \uae30\ubcf8\uc124\uc815\uac12\uc774 \uc9c0\uc815\ub418\uc5b4 \uc788\uc74c.\n    - rmse: root mean square error\n    - mae: mean absolute error\n    - logloss: negative log-likelihood\n    - error: Binary classification error rate (0.5 threshold)\n    - merror: Multiclass classification error rate\n    - mlogloss: Multiclass logloss\n    - auc: Area under the curve\n    - seed [\uae30\ubcf8\uc124\uc815\uac12: 0]: \uc7ac\ud604\uac00\ub2a5\ud558\ub3c4\ub85d \ub09c\uc218\ub97c \uace0\uc815\uc2dc\ud0b4.\n\n### \uc77c\ubc18 \ucd08\ubaa8\uc218\n- booster: \uc758\uc0ac\uacb0\uc815 \uae30\ubc18 \ubaa8\ud615(gbtree), \uc120\ud615 \ubaa8\ud615(linear)\n- mthread: \ubcd1\ub82c\ucc98\ub9ac\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ucf54\uc5b4\uc218, \ud2b9\uc815\uac12\uc744 \uc9c0\uc815\ud558\uc9c0 \uc54a\ub294 \uacbd\uc6b0 \uc790\ub3d9\uc73c\ub85c \uc2dc\uc2a4\ud15c \ucf54\uc5b4\uc218\ub97c \ud0d0\uc9c0\ud558\uc5ec \ubcd1\ub82c\ucc98\ub9ac\uc5d0 \ub3d9\uc6d0\ud568.\n\n### \ubd80\uc2a4\ud305 \ucd08\ubaa8\uc218\n- eta [\uae30\ubcf8\uc124\uc815\uac12: 0.3]: GBM\uc5d0 \ud559\uc2b5\uc728\uacfc \uc720\uc0ac\ud558\uace0 \uc77c\ubc18\uc801\uc73c\ub85c 0.01 ~ 0.2 \uac12\uc774 \uc0ac\uc6a9\ub428\n- min_child_weight [\uae30\ubcf8\uc124\uc815\uac12: 1]: \uacfc\uc801\ud569(overfitting)\uc744 \ubc29\uc9c0\ud560 \ubaa9\uc801\uc73c\ub85c \uc0ac\uc6a9\ub418\ub294\ub370, \ub108\ubb34 \ub192\uc740 \uac12\uc740 \uacfc\uc18c\uc801\ud569(underfitting)\uc744 \uc57c\uae30\ud558\uae30 \ub54c\ubb38\uc5d0 CV\ub97c \uc0ac\uc6a9\ud574\uc11c \uc801\uc808\ud55c \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4\uc57c \ud55c\ub2e4.\n- max_depth [\uae30\ubcf8\uc124\uc815\uac12: 6]: \uacfc\uc801\ud569 \ubc29\uc9c0\ub97c \uc704\ud574\uc11c \uc0ac\uc6a9\ub418\ub294\ub370 \uc5ed\uc2dc CV\ub97c \uc0ac\uc6a9\ud574\uc11c \uc801\uc808\ud55c \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4\uc57c \ud558\uace0 \ubcf4\ud1b5 3-10 \uc0ac\uc774 \uac12\uc774 \uc801\uc6a9\ub41c\ub2e4.\n- max_leaf_nodes: max_leaf_nodes \uac12\uc774 \uc124\uc815\ub418\uba74 max_depth\ub294 \ubb34\uc2dc\ub41c\ub2e4. \ub530\ub77c\uc11c \ub450\uac12 \uc911 \ud558\ub098\ub97c \uc0ac\uc6a9\ud55c\ub2e4.\n- max_delta_step [\uae30\ubcf8\uc124\uc815\uac12: 0]: \uc77c\ubc18\uc801\uc73c\ub85c \uc798 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc74c.\n- subsample [\uae30\ubcf8\uc124\uc815\uac12: 1]: \uac1c\ubcc4 \uc758\uc0ac\uacb0\uc815\ub098\ubb34 \ubaa8\ud615\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uc784\uc758 \ud45c\ubcf8\uc218\ub97c \uc9c0\uc815. \ubcf4\ud1b5 0.5 ~ 1 \uc0ac\uc6a9\ub428.\n- colsample_bytree [\uae30\ubcf8\uc124\uc815\uac12: 1]: \uac1c\ubcc4 \uc758\uc0ac\uacb0\uc815\ub098\ubb34 \ubaa8\ud615\uc5d0 \uc0ac\uc6a9\ub420 \ubcc0\uc218\uac2f\uc218\ub97c \uc9c0\uc815. \ubcf4\ud1b5 0.5 ~ 1 \uc0ac\uc6a9\ub428.\n- colsample_bylevel [\uae30\ubcf8\uc124\uc815\uac12: 1]: subsample, colsample_bytree \ub450 \ucd08\ubaa8\uc218 \uc124\uc815\uc744 \ud1b5\ud574\uc11c \uc774\ubbf8 \uc758\uc0ac\uacb0\uc815\ub098\ubb34 \ubaa8\ud615 \uac1c\ubc1c\uc5d0 \uc0ac\uc6a9\ub420 \ubcc0\uc218\uac2f\uc218\uc640 \uad00\uce21\uc810 \uac2f\uc218\ub97c \uc0ac\uc6a9\ud588\ub294\ub370 \ucd94\uac00\ub85c colsample_bylevel\uc744 \uc9c0\uc815\ud558\ub294 \uac83\uc774 \ud2b9\ubcc4\ud55c \uc758\ubbf8\ub97c \uac16\ub294\uc9c0 \uc758\ubb38\uc774 \ub4e6.\n- lambda [\uae30\ubcf8\uc124\uc815\uac12: 1]: \ub2a5\uc120 \ud68c\uc26c(Ridge Regression)\uc758 L2 \uc815\uaddc\ud654(regularization) \ucd08\ubaa8\uc218. \uadf8\ub2e4\uc9c0 \ub9ce\uc774 \uc0ac\uc6a9\ub418\uace0 \uc788\uc9c0\ub294 \uc54a\uc74c.\n- alpha [\uae30\ubcf8\uc124\uc815\uac12: 0]: \ub77c\uc3d8 \ud68c\uadc0(Lasso Regression)\uc758 L1 \uc815\uaddc\ud654(regularization) \ucd08\ubaa8\uc218\ub85c \ucc28\uc6d0\uc774 \ub192\uc740 \uacbd\uc6b0 \uc54c\uace0\ub9ac\uc998 \uc18d\ub3c4\ub97c \ub192\uc77c \uc218 \uc788\uc74c.\n- scale_pos_weight [\uae30\ubcf8\uc124\uc815\uac12: 1]: \ud074\ub798\uc2a4 \ubd88\uade0\ud615\uc774 \uc2ec\ud55c \uacbd\uc6b0 0\ubcf4\ub2e4 \ud070 \uac12\uc744 \uc9c0\uc815\ud558\uc5ec \ud6a8\uacfc\ub97c \ubcfc \uc218 \uc788\uc74c.","3f499125":"**GradientBoosting**","1008da37":"- lgb_params\uc740 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c Key\ub85c, \ud574\ub2f9 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uc5d0 \uc785\ub825\ub420 \uac12\uc758 \ubc94\uc704\ub97c \ud29c\ud50c \ud615\ud0dc\ub85c \uac00\uc9c0\uace0\uc788\uc74c.\n- \uc608\ub97c \ub4e4\uc5b4 num_leaves: (24, 45)\ub294 24 ~45\uae4c\uc9c0\uc758 \uac12\uc744 num_leaves\uc5d0 \uc785\ub825.\n- \uc774 \ub54c \uc720\uc758\ud560 \uc810\uc740 \uc815\uc218\uac00 \uc544\ub2cc \uc2e4\uc218\ud615 \uac12\uc744 \uc785\ub825\ud55c\ub2e4\ub294 \uac83\uc784.\n- \uc989 24.4, 24, 5\uac00 \uc785\ub825 \ub420 \uc218 \uc788\uc73c\ubbc0\ub85c \uc774\ub97c \uc785\ub825 \ubc1b\ub294 \uc131\ub2a5 \ud3c9\uac00 \ud568\uc218\uc778 lgb_roc_eval \ub0b4\uc5d0\uc11c \uc774\ub4e4\uc744 \uc815\uc218\uac12\uc73c\ub85c \ubcc0\ud658\ud574\uc57c \ud568.\n- \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub9c8\ub2e4 \uc815\uc218\ud615\uacfc \uc2e4\uc218\ud615\uc774 \ub098\ub220\uc838 \uc788\uc74c","e06c3a4d":"\ubcc0\uc218\ub4e4\uc758 \uac12\uc5d0 \ub300\ud55c \ubc94\uc8fc\ub97c \ub098\ub208 \uc0c1\ud0dc\uc5d0\uc11c \uc0ac\ub9dd\ud55c \uc0ac\ub78c\ub4e4\uacfc \uc0dd\uc874\ud55c \uc0ac\ub78c\ub4e4\uc758 \ubd84\ud3ec\ub97c \ud655\uc778\ud558\uae30 \uc704\ud55c \uadf8\ub798\ud504 ","632920fd":"> Important note: When conducting feature encoding, Newbies must understand difference between ordinal encoding, label encoding, and one-hot encoding. See. https:\/\/machinelearningmastery.com\/one-hot-encoding-for-categorical-data\/\n","07ee1883":"- [Overview](#overview)\n    - [Etiquette](#etiquette)\n    \n- [Feature Engineering](#feature_engineering)\n    - [(1) Data Import](#data_import)\n    - [(2) Matplotlib Color & Default Setting](#data_combine)\n    - [(3) Data Visualization](#handling_missing_values)\n    - [(4) Feature Encoding](#feature_encoding)\n    - [(5) Split Data](#split_data)\n    - [(6) Limitation](#limitation)\n    \n- [Scikit Learn](#scikit_learn)\n    - [(1) Data Split](#data_split)\n    - [(2) Base Model - Decision Tree](#base_model_tree)\n    - [(3) Create Helper Class and Submission Function](#helper_class)\n        * [(A) DecisionTreeClassifier](#DecisionTreeClassifier)\n        * [(B) RandomForestClassifier](#RandomForestClassifier)\n        * [(C) LightGBM](#lightgbm)\n        * [(D) Feature Importance](#feature_importance)\n        * [(E) Submission](#submission) ","f4104f46":"**Lightgbm**","8a9cde5c":"- \\w - \ubb38\uc790+\uc22b\uc790(alphanumeric)\uc640 \ub9e4\uce58\n- \\s - whitespace \ubb38\uc790\uc640 \ub9e4\uce58\n- \ubb38\uc790 \ud074\ub798\uc2a4 \uc548\uc5d0 ^ \uba54\ud0c0 \ubb38\uc790\ub97c \uc0ac\uc6a9\ud560 \uacbd\uc6b0\uc5d0\ub294 \ubc18\ub300(not)\ub77c\ub294 \uc758\ubbf8\ub97c \uac16\ub294\ub2e4.\n- replace('[^\\w\\s]','') --> \ubb38\uc790+\uc22b\uc790+\uacf5\ubc31\ubb38\uc790\ub97c \uc81c\uc678\ud55c \ubb38\uc790\ub97c \uacf5\ubc31\uc73c\ub85c \ubc14\uafbc\ub2e4.","390f209d":"<a id='handling_missing_values'><\/a>\n### (3) Handling Missing Values\n- Let's fill with some value in each column.\n> *Important Note:* This idea is from [TPS Apr 2021 LightGBM CV](https:\/\/www.kaggle.com\/jmargni\/tps-apr-2021-lightgbm-cv). Thank you. \n","4b155a81":"Fare \uac12\uc758 \ubd84\ud3ec\ub97c \ud655\uc778\ud558\uba74 \ube44\ub300\uce6d \ub370\uc774\ud130\uc14b\uc774\ub77c\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc694\uae08\uc774 Pclass\uc5d0 \ub530\ub77c \ub2ec\ub77c\uc9c0\ub294\uc9c0 \ud655\uc778\ud55c \ud6c4 \uc2b9\uac1d \ub4f1\uae09\uc5d0 \ub530\ub77c \ub204\ub77d\ub41c \uac12\uc744 \ucc98\ub9ac\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\ub610\ud55c \ub450\uaebc\uc6b4 \uaf2c\ub9ac(heavy tail) \ubd84\ud3ec\uc640 \uc774\uc0c1\uce58\ub85c \uc778\ud55c \uc694\uae08 \ubcc0\ub3d9\uc744 \uc81c\uc5b4\ud558\uae30 \uc704\ud574 \ub85c\uadf8 \ubcc0\ud658\uc744 \uc218\ud589\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\uadf8\ub9ac\uace0 \uc694\uae08\uc5d0\ub294 \uc77c\ubd80 \uac12\uc774 1\ubcf4\ub2e4 \uc791\uc740 \uac12\uc774 \uc788\uc73c\ubbc0\ub85c ln(fare)\uc744 \uc218\ud589\ud560 \uc2dc \uc74c\uc218\uac00 \ub420 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 ln(1 + Fare) \ubcc0\ud658\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.","a9cdd62e":"\ub85c\uadf8 \ubcc0\ud658\uc744 \ud1b5\ud574 \uc65c\ub3c4\ub97c \uc81c\uac70\ud55c \ub2e4\uc74c \uacb0\uce21\uce58 \uc81c\uac70\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. \uac01\uac01\uc758 \uacb0\uce21\uce58\uc758 Pclass\uac12\uc5d0 \ub530\ub77c\uc11c \uadf8 \uac12\uc5d0 \uc77c\uce58\ud558\ub294 Pclass \uc911\uc704\uac12\uc73c\ub85c \ub300\uccb4\ud558\ub294 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4."}}