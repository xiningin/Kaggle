{"cell_type":{"f0c08c29":"code","0c5e5cdb":"code","69ca9b8b":"code","235388cb":"code","214e5603":"code","2187b8b2":"code","cd75dd23":"code","1244e398":"code","98245014":"code","d25c2481":"code","70202b1f":"markdown","60221778":"markdown","7c2b36df":"markdown","8b5978f3":"markdown","f846d59f":"markdown","2dd9bed5":"markdown","e54959d3":"markdown","8cf4c62a":"markdown","562ef2d0":"markdown","b81aaacc":"markdown"},"source":{"f0c08c29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn.utils # Shuffle Pandas data frame\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0c5e5cdb":"#2: Read data\ndata_path = \"\/kaggle\/input\/learn-together\/train.csv\"\ndata = pd.read_csv(data_path)\ndata = sklearn.utils.shuffle(data)\nprint('data readed successfully :)')","69ca9b8b":"#3: Data Explor\n\n#first 5 rows in data\nprint(data.head())\n\n#describe data\nprint(data.describe())\n\n#data dimintionality [rows x columns]\nprint(data.shape)\n#number of classes in target column\nnum_of_classes = len(data['Cover_Type'].unique())\nprint(num_of_classes)","235388cb":"#4 Prepare data for training and cross-validation purpose\n\n#drop Id column\ndata.drop('Id', axis=1, inplace=True)\n\n#add ones column\ndata.insert(0,'ones',1)\ntrain_data = data\n\n#split train data to featuers and target \nX_train_data = train_data.iloc[ : , 0:train_data.shape[1]-1]\ny_train_data = train_data.iloc[ : , train_data.shape[1]-1:]\n\nprint('data preparepared successfully :)')","214e5603":"#5 Hyper parameters\nthetas = np.zeros((num_of_classes,X_train_data.shape[1]))\nalpha = 1e-22","2187b8b2":"#6 Sigmoid function\ndef sigmoid(z):\n    return 1 \/ (1 + np.exp(-z))\n\nprint('Sigmoid function created :)')","cd75dd23":"#7 Cost Function\ndef computeCost(theta,X, y,alpha):\n    theta = np.matrix(theta)\n    X = np.matrix(X)\n    y = np.matrix(y)\n\n    firstTerm  = np.multiply(y, np.log(sigmoid(X * theta.T)))\n    secondTerm = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n    reg        = (alpha \/ 2*len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]],2))\n    cost         = -np.sum(firstTerm + secondTerm) \/ len(X) + reg\n    return cost\n\nprint('Cost Function created :)')","1244e398":"#8: Gradient function\ndef gradient(theta, X, y, alpha): \n    theta = np.matrix(theta)\n    X  = np.matrix(X)\n    y  = np.matrix(y)\n   \n    error = sigmoid(X * theta.T) - y\n    #refere to gradient value\n    grad = ((X.T*error) \/ len(X)).T + ((alpha \/ len(X)) * theta)\n    grad[0,0] = np.sum(np.multiply(error,X[:,0])) \/ len(X)\n        \n    return np.array(grad).ravel()\n\nprint('Gradient function created :)')","98245014":"#9 one_vs_all function\nfrom scipy.optimize import minimize\n\ndef one_vs_all(X,y,number_of_classes,alpha):\n    \n    rows = X.shape[0]\n    columns = X.shape[1]\n    all_thetas = np.zeros((num_of_classes,columns))\n    \n    for i in range (1,num_of_classes+1):\n        theta = np.zeros(columns)\n        y_i = np.array([ 1 if target == i else 0 for target in y['Cover_Type'] ])\n        y_i = np.reshape(y_i,(rows,1))\n        \n        func_min = minimize(fun = computeCost, x0 = theta , args = (X,y_i,alpha) , method='TNC' , jac=gradient)\n        all_thetas[i-1,:] = func_min.x\n        \n    return all_thetas\n\nall_thetas = one_vs_all(X_train_data,y_train_data,num_of_classes,alpha)\nprint(all_thetas)","d25c2481":"#10 Predict all function\ndef predictAll(X,all_thetas):   \n    X = np.matrix(X)\n    all_thetas = np.matrix(all_thetas)\n    result = sigmoid(X * all_thetas.T)\n    res_argmax = np.argmax(result , axis = 1)\n    res_argmax = res_argmax + 1\n    return res_argmax\n\ntest_data_path = \"\/kaggle\/input\/learn-together\/test.csv\"\ntest_data = pd.read_csv(test_data_path,index_col='Id')\n\ntest_data_id = test_data.index\ntest_data.insert(0,'ones',1)\n\ny_test_predict = predictAll(test_data,all_thetas)\n\ny_test_predict = np.array(y_test_predict)\ny_test_predict = y_test_predict.T\ny_test_predict = y_test_predict.ravel() \n\noutput = pd.DataFrame({\n        'Id':test_data_id,\n        'Cover_Type':y_test_predict\n        })\n\noutput.to_csv('submission.csv', index=False)  \nprint('Go :)')","70202b1f":"**Prepare Environment**","60221778":"**Prediction And Submition**","7c2b36df":"**Gradient Function**","8b5978f3":"**OVA Model**","f846d59f":"**Read Data**","2dd9bed5":"**Explor Data**","e54959d3":"**Data Preperation**","8cf4c62a":"**Hyper Parameters**","562ef2d0":"**Sigmoid Function**","b81aaacc":"**Cost Function**"}}