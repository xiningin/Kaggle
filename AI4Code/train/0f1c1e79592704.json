{"cell_type":{"83d2f678":"code","da696ce1":"code","6a850782":"code","0e2951e8":"code","3198444b":"code","ff375221":"code","76008dc2":"code","8812ab87":"code","f5802ee6":"code","654097e9":"code","65dc5379":"code","8c518895":"code","c949e9c1":"code","1b1804af":"code","ffff1412":"code","5c967e4a":"code","8ee1d0be":"code","cb4b6276":"code","723294ae":"code","f0180dd5":"code","7420b671":"code","25c1f29b":"code","6bdacf2d":"code","38b066aa":"code","5c6dafde":"code","9fcbb0cf":"code","3574cd39":"code","e82a8ba9":"code","cef15c52":"code","3e2e7b23":"code","f87ebed3":"code","2f805a37":"code","5a07b708":"code","f735b053":"code","7ec572f9":"code","c60b700d":"code","7ee0f1dd":"code","2503bee8":"code","515348aa":"code","8d5e1306":"code","6a2182c9":"code","bee49c05":"code","21e65cc3":"code","67badcf7":"code","c3af353f":"code","7c6d27eb":"code","574e5182":"code","97f63e1d":"code","18aaccbd":"code","00389030":"code","758853c0":"code","197f5d84":"code","9fee5231":"code","a14f8c61":"code","ef92498a":"code","8bf60eed":"code","41e1e892":"code","9cee06f5":"code","86754379":"code","2ce112d4":"code","d222897e":"code","3f9a74fb":"code","ea9ae308":"code","7b7cf3fd":"code","f4f5308c":"code","af3a13f7":"code","b589c137":"code","84a64dd7":"code","958dffd5":"code","ab684b33":"code","f4777606":"code","e4fdd4aa":"code","0b61df9d":"code","997f8f30":"code","6c5cbb00":"code","63877afe":"code","1771edb9":"code","bc1649ed":"code","a5baaedf":"code","446c4ec1":"code","af0ef9b8":"code","b88279cf":"code","95a9ba51":"code","ab23b481":"code","d8484389":"code","7abc0daa":"code","db33b277":"code","7dd83513":"code","ad863818":"code","1e2af4fd":"code","ca777480":"code","c2cbee4e":"code","a4837bb9":"code","1f1c2267":"code","8d48f38e":"code","9e9fd5a5":"code","b5933646":"code","ab684e92":"markdown","48e964d7":"markdown","d91ecfaf":"markdown","7a73fa75":"markdown","d9ab6b64":"markdown","4ef2b114":"markdown","d1ff90e4":"markdown","6ec39587":"markdown","a2137688":"markdown","164801df":"markdown","08df96fa":"markdown","7a522c34":"markdown","b0e58621":"markdown","8551a225":"markdown","5a6b3cca":"markdown","567b3ade":"markdown","569d2a4d":"markdown","744a270b":"markdown","8b07533a":"markdown","afdb71e0":"markdown","39ac375f":"markdown","666f8d88":"markdown","213425fd":"markdown","24615973":"markdown","79989c75":"markdown","60f6e6ab":"markdown","8dc13891":"markdown"},"source":{"83d2f678":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","da696ce1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6a850782":"H = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nH_T = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nH.head()","0e2951e8":"H.shape","3198444b":"H.info()","ff375221":"H[H.duplicated()]\n#No duplicates","76008dc2":"H[H.loc[:,~H.columns.isin(['SalePrice'])].duplicated()]\n#No duplicates","8812ab87":"Unique_data = H.apply(pd.Series.nunique)\nUnique_data[Unique_data == 1]\n#No single unique values in the dataset","f5802ee6":"Sum = H.isnull().sum().sort_values(ascending = False)\nPercent = ((H.isnull().sum()*100)\/H.count()[0]).sort_values(ascending = False)\nNullValues = pd.concat([Sum, Percent], axis = 1, keys = [\"Sum\", \"Percent\"])\nNullValues[NullValues.Sum > 0]","654097e9":"#Deleting columns that have more than 20% missing values and Id column\nH.drop(['Id','Alley', 'PoolQC', 'Fence','MiscFeature','MiscVal','FireplaceQu','LotFrontage'], axis = 1, inplace = True)","65dc5379":"Sum = H.isnull().sum().sort_values(ascending = False)\nPercent = ((H.isnull().sum()*100)\/H.count()[0]).sort_values(ascending = False)\nNullValues = pd.concat([Sum, Percent], axis = 1, keys = [\"Sum\", \"Percent\"])\nNullValues[NullValues.Sum > 0]","8c518895":"H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]\n\n# Missing values exist as there is no garage for these homes","c949e9c1":"H.fillna({'GarageType': 'NoGarage', 'GarageYrBlt': 0, 'GarageFinish': 'NoGarage', 'GarageQual': 'NoGarage','GarageCond': 'NoGarage'} , inplace = True)\n\n#Filling appropriate values for nulls ","1b1804af":"H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]","ffff1412":"H[H['TotalBsmtSF'] == 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()\n\n# Missing values exist as there is no basement for these homes","5c967e4a":"H[H['TotalBsmtSF'] > 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()\n\n# BsmtExposure and BsmtFinType2 have missing values though these homes have a basement","8ee1d0be":"mode = H['BsmtExposure'].mode()[0]\nH.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtExposure'].isnull()), 'BsmtExposure'] = mode\n\nmode = H['BsmtFinType2'].mode()[0]\nH.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtFinType2'].isnull()), 'BsmtFinType2'] = mode\n\n#Filling these nulls with mode","cb4b6276":"H.fillna({'BsmtQual': 'NoBasement', 'BsmtCond': 'NoBasement','BsmtExposure': 'NoBasement', 'BsmtFinType1': 'NoBasement', 'BsmtFinType2': 'NoBasement'} , inplace = True)\n\n\n#Filling appropriate values for other nulls ","723294ae":"mode = H['Electrical'].mode()[0]\nH['Electrical'].fillna(mode, inplace = True)\nmode = H['MasVnrType'].mode()[0]\nH['MasVnrType'].fillna(mode, inplace = True)\nmedian = H['MasVnrArea'].median()\nH['MasVnrArea'].fillna(median, inplace = True)\n\n# Filling missing values in MasVnrArea,MasVnrType,Electrical with mode","f0180dd5":"Sum = H.isnull().sum().sort_values(ascending = False)\nPercent = ((H.isnull().sum()*100)\/H.count()[0]).sort_values(ascending = False)\nNullValues = pd.concat([Sum, Percent], axis = 1, keys = [\"Sum\", \"Percent\"])\nNullValues[NullValues.Sum > 0]\n\n#No null values","7420b671":"H[\"AgeOfHouse\"] = 2011 - H[\"YearBuilt\"]\nH[\"AgeOfRemod\"] = 2011 - H[\"YearRemodAdd\"]\nH['AgeOfSell'] = 2011 - H['YrSold']\nH['AgeOfGarage'] = 2011 - H['GarageYrBlt']\nH.loc[H['AgeOfGarage'] > 100 , 'AgeOfGarage'] = 0\nH.drop(['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt'], axis = 1, inplace = True)\n\n#Using age instead of year for better intution and ease","25c1f29b":"H['BsmtBath'] = H['BsmtFullBath'] + (0.5 * H['BsmtHalfBath'])\nH['Bath'] = H['FullBath'] + (0.5 * H['HalfBath'])","6bdacf2d":"H['TotalPorchArea'] = H['OpenPorchSF'] + H['EnclosedPorch'] + H['3SsnPorch'] + H['ScreenPorch']","38b066aa":"numerical_columns = ['SalePrice','LotArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']\ncategorical_columns = ['BsmtBath','Bath','BedroomAbvGr','BldgType','BsmtHalfBath','BsmtFullBath','Condition1','Condition2','Electrical','Exterior1st','Exterior2nd','Fireplaces','Foundation','FullBath','Functional','GarageCars','GarageFinish','GarageType','HalfBath','Heating','HouseStyle','KitchenAbvGr','LandContour','LandSlope','LotConfig','LotShape','MSSubClass','MSZoning','MasVnrType','MoSold','Neighborhood','PavedDrive','RoofMatl','RoofStyle','SaleCondition','SaleType','Street','TotRmsAbvGrd','Utilities']\nordinal_columns = [ \"OverallQual\",\"OverallCond\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",'BsmtCond',\"BsmtExposure\",\"HeatingQC\",\"KitchenQual\",\"GarageQual\",\"GarageCond\", 'BsmtFinType1', 'BsmtFinType2','CentralAir']","5c6dafde":"H[ordinal_columns]","9fcbb0cf":"H['ExterQual'] = H['ExterQual'].map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['ExterCond'] = H['ExterCond'].map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['BsmtQual'] = H['BsmtQual'].map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['BsmtCond'] = H['BsmtCond'].map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['BsmtExposure'] = H['BsmtExposure'].map({'Gd' : 4, 'Av' : 3, 'Mn' : 2, 'No' : 1, 'NoBasement' : 0})\nH['HeatingQC'] = H['HeatingQC'].map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['KitchenQual'] = H['KitchenQual'].map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['GarageQual'] = H['GarageQual'].map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['GarageCond'] = H['GarageCond'].map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})\nH['BsmtFinType1'] = H['BsmtFinType1'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})\nH['BsmtFinType2'] = H['BsmtFinType2'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})\nH['CentralAir'] = H['CentralAir'].map({'N' : 0, 'Y' : 1})","3574cd39":"H[ordinal_columns].head(5)","e82a8ba9":"H[ordinal_columns].isnull().sum()","cef15c52":"H[categorical_columns].dtypes","3e2e7b23":"for i in range(0, len(categorical_columns)):\n    if (H[categorical_columns[i]].dtype == 'int64') | (H[categorical_columns[i]].dtype == 'float64'):\n        H[categorical_columns[i]] = H[categorical_columns[i]].apply(str)\n        \n#Changing data type to string\/object","f87ebed3":"H[categorical_columns].head()","2f805a37":"H[\"BsmtBath\"].value_counts()","5a07b708":"H.loc[H[\"BsmtBath\"] == '3.0', 'BsmtBath'] = '2.0'\n\n#Merging 3 baths to 2 as there is only 1 record","f735b053":"H[\"BedroomAbvGr\"].value_counts()","7ec572f9":"H.loc[H[\"BedroomAbvGr\"] == '8', 'BedroomAbvGr'] = '6'\n#Merging 8 to closer one 6","c60b700d":"H[\"BsmtFullBath\"].value_counts()","7ee0f1dd":"H.loc[H[\"BsmtFullBath\"] == '3', 'BsmtFullBath'] = '2'\n#Merging 3 to closer one 2","2503bee8":"H[\"Condition1\"].value_counts()\n# Not merging as they seem to have an importance","515348aa":"H[\"Condition2\"].value_counts()","8d5e1306":"H.loc[H[\"Condition2\"].isin(['PosA','RRAn','RRAe']), 'Condition2'] = 'PosA_RRAn_RRAe'\n#Merging 'PosA','RRAn','RRAe' to one field","6a2182c9":"H[\"Electrical\"].value_counts()\n# Not merging as they seem to have some importance","bee49c05":"H[\"Exterior1st\"].value_counts()","21e65cc3":"H.loc[H[\"Exterior1st\"].isin(['Stone','BrkComm','CBlock','AsphShn','ImStucc']), 'Exterior1st'] = 'Other'\n#Renaming 'Stone','BrkComm','CBlock','AsphShn','ImStucc' to other","67badcf7":"H[\"Exterior2nd\"].value_counts()","c3af353f":"H.loc[H[\"Exterior2nd\"].isin(['Stone','Brk Cmn','CBlock','AsphShn','ImStucc','Other']), 'Exterior2nd'] = 'Other'\n# Renaming 'Stone','BrkComm','CBlock','AsphShn','ImStucc' to Other","7c6d27eb":"H[\"Utilities\"].value_counts()","574e5182":"H.drop(['Utilities'], axis = 1, inplace = True)\ncategorical_columns.remove('Utilities')\n\n#Droping Utilities as it has 99% data as 1 unique value","97f63e1d":"H[\"Heating\"].value_counts()","18aaccbd":"H.loc[H[\"Heating\"] == 'Floor', 'Heating'] = 'OthW'\n#Merging 'Floor' to 'OthW'","00389030":"H[\"RoofMatl\"].value_counts()","758853c0":"H.loc[H[\"RoofMatl\"].isin(['Roll','Membran','Metal','ClyTile']), 'RoofMatl'] = 'Other'\n#Clubbing 'Roll','Membran','Metal','ClyTile' to other","197f5d84":"H[\"TotRmsAbvGrd\"].value_counts()","9fee5231":"H.loc[H[\"TotRmsAbvGrd\"] == '2', 'TotRmsAbvGrd'] = '3'\nH.loc[H[\"TotRmsAbvGrd\"] == '14', 'TotRmsAbvGrd'] = '12'\n#Merging outliers to closer values","a14f8c61":"numerical_columns_1 = ['SalePrice','LotArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']\nplt.figure(figsize=(15,60))\nfor i in range(0, len(numerical_columns_1)):\n    plt.subplot(12,2,(i+1))\n    sns.distplot(H[numerical_columns_1[i]])","ef92498a":"from scipy import stats\n\n# correcting target variable\nH['SalePrice'], fitted_lambda = stats.boxcox(H['SalePrice'])\n\n#Correcting some normally distributed but skewed numerical data\nH['LotArea'], fitted_lambda = stats.boxcox(H['LotArea'])\nH['1stFlrSF'], fitted_lambda = stats.boxcox(H['1stFlrSF'])\nH['GrLivArea'], fitted_lambda = stats.boxcox(H['GrLivArea'])\n\n","8bf60eed":"H['TotalBsmtSF'].describe()","41e1e892":"sns.distplot(H['1stFlrSF'])","9cee06f5":"sns.distplot(H['GrLivArea'])","86754379":"plt.figure(figsize=(15,15))\ncorrelation = H[numerical_columns].corr()\nsns.heatmap(correlation, annot = True)","2ce112d4":"plt.figure(figsize=(15,60))\nfor i in range(0, len(categorical_columns)):\n    plt.subplot(20,2,(i+1))\n    sns.boxplot(data = H, x = categorical_columns[i], y = 'SalePrice'  )\n\n#Plotting all categorical with box plot to ponder and check for any obvious issues with data    ","d222897e":"plt.figure(figsize=(15,60))\nfor i in range(0, len(numerical_columns)):\n    plt.subplot(12,2,(i+1))\n    sns.scatterplot(data = H, x = numerical_columns[i], y = 'SalePrice'  )\n    \n#Ploting all numerical data in scatter plots to ponder","3f9a74fb":"plt.figure(figsize=(15,35))\nfor i in range(0, len(ordinal_columns)):\n    plt.subplot(7,2,(i+1))\n    sns.barplot(data = H, x = ordinal_columns[i], y = 'SalePrice'  )\n    \n#Ploting all ordinal values with Sala price in a bar graph \n# Sale price doesnt seem to change much with any ordinal data","ea9ae308":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn import linear_model, metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\n","7b7cf3fd":"y = H['SalePrice']\n\nX = H.drop(['SalePrice'], axis = 1)","f4f5308c":"X.shape","af3a13f7":"House_Dummies = pd.get_dummies(H[categorical_columns], drop_first = True)\nHouse_Dummies.head()","b589c137":"len(categorical_columns)","84a64dd7":"X = X.drop(categorical_columns, axis = 1)\nX = pd.concat([X, House_Dummies], axis=1)","958dffd5":"X.shape","ab684b33":"X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 100)","f4777606":"scaler = StandardScaler()\nnumerical_columns.remove('SalePrice')\nX_train[numerical_columns+ordinal_columns] = scaler.fit_transform(X_train[numerical_columns+ordinal_columns])\nX_test[numerical_columns+ordinal_columns] = scaler.transform(X_test[numerical_columns+ordinal_columns])","e4fdd4aa":"X_train.shape","0b61df9d":"X_test.shape","997f8f30":"params = {'alpha': [0.00001,0.00005,0.0001, 0.0005,0.001,0.01, 0.02]}\n#arams = {'alpha': [0.1, 1,10,100,200,300,500,1000]}\n\n\nlasso = Lasso()\n\n\nfolds = 5\n#Taking 5 folds for Cross validation\n\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train)","6c5cbb00":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","63877afe":"alpha =0.001\nlasso = Lasso(alpha=alpha)  \nlasso.fit(X_train, y_train) ","1771edb9":"Lasso_coef = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":lasso.coef_})\nLasso_coef[Lasso_coef['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()\n\n#Feature selection is done by Lasso and features narrowed down to 46","bc1649ed":"y_test_lasso_predict = lasso.predict(X_test)\ny_train_lasso_predict = lasso.predict(X_train)","a5baaedf":"print(metrics.r2_score(y_true=y_test, y_pred=y_test_lasso_predict))\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_lasso_predict))","446c4ec1":"\nparams = {'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5, 2, 10, 100, 1000]}\n\n\nridge = Ridge()\n\n# cross validation with 5 folds\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train, y_train) ","af0ef9b8":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","b88279cf":"alpha =100\nridge = Ridge(alpha=alpha)  \nridge.fit(X_train, y_train) ","95a9ba51":"y_test_ridge_predict = ridge.predict(X_test)\ny_train_ridge_predict = ridge.predict(X_train)","ab23b481":"print(metrics.r2_score(y_true=y_test, y_pred=y_test_ridge_predict))\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_ridge_predict))","d8484389":"Ridge_coef = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":ridge.coef_})\nRidge_coef[Ridge_coef['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()\n#No feature selection happened","7abc0daa":"params = {'alpha': [0,0.0001, 0.0005, 0.001, 0.01]}\n\nelasticnet = ElasticNet()\n\n# cross validation\nmodel_cv = GridSearchCV(estimator = elasticnet, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","db33b277":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","7dd83513":"alpha =0.001\nelasticnet = ElasticNet(alpha=alpha)  \nelasticnet.fit(X_train, y_train) ","ad863818":"y_test_elasticnet_predict = elasticnet.predict(X_test)\ny_train_elasticnet_predict = elasticnet.predict(X_train)","1e2af4fd":"print(metrics.r2_score(y_true=y_test, y_pred=y_test_elasticnet_predict))\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_elasticnet_predict))","ca777480":"elasticnet_coef = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":elasticnet.coef_})\nelasticnet_coef[elasticnet_coef['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()\n#Feature selection happened but not as good as Lasso","c2cbee4e":"Lasso_coef = Lasso_coef[Lasso_coef['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).reset_index()","a4837bb9":"Lasso_coef.drop(['index'], axis = 1, inplace = True)","1f1c2267":"Lasso_coef.head(10)","8d48f38e":"Lasso_coef.tail(10)","9e9fd5a5":"Lasso_coef['Feature'].to_list()","b5933646":"\nplt.figure(figsize=(15,15))\nsns.barplot(x=\"Coefficients\", y=\"Feature\", data=Lasso_coef, palette=\"vlag\")\nplt.xlabel(\"Feature Importance\")\nplt.tight_layout()","ab684e92":"### Deriving new features","48e964d7":"#### Attempt to correct skewedness with box cox","d91ecfaf":"Execution Plan\n    -Understanding Data\n    -Data Cleaning\n    -Exploratory Data Analysis\n    -Model building\n    -Model Evaluation\n    -Inferences","7a73fa75":"#### alpha as 0.0005. That is where the test and train score are closer before both going down together at constant rate","d9ab6b64":"### Filling ordinal columns with appropriate values","4ef2b114":"### Inference with ElasticNet regression\n\n#### Train R2_score : 0.89\n\n#### Test R2 Score : 0.92\n\n#### Optimal alpha : 0.001\n\n#### Features : 70","d1ff90e4":"### Feature Importance","6ec39587":"#### Dealing with missing values in Garage","a2137688":"### Inference with Lasso regression\n\n#### Test R2_score : 0.88\n\n#### Train R2 Score : 0.90\n\n#### Optimal alpha : 0.001\n\n#### Features : 46","164801df":"### Null value treatment","08df96fa":"### Standardining all numerical values","7a522c34":"#### alpha as 100. That is where the test and train score are closer before train going down with test error","b0e58621":"### Splitting data into train and test dataset","8551a225":"## Lasso regression","5a6b3cca":"### Inference with Ridge regression\n\n#### Test R2_score : 0.89\n\n#### Train R2 Score : 0.91\n\n#### Optimal alpha : 10\n\n#### Features : 245","567b3ade":"# Ridge Regression","569d2a4d":"### Segregation of columns by their nature","744a270b":"### Dealing with outliers in Categorical variables ","8b07533a":"#### alpha as 0.001. That is where the test and train score are closer and higher before both going down together","afdb71e0":"### Dealing with datatypes of categorical columns","39ac375f":"# ElasticNet Regression","666f8d88":"#### Dealing with missing values in Basement","213425fd":"### Checking numerical values of skewedness","24615973":"#### Plotting Negative Mean Absolute Error for Lasso to select appropriate alpha value","79989c75":"#### Sale Price negatively correlated with age of house and age of remodeling\n#### Total Basement area, 1st floor surface area, Garage living area, Garage area have high positive correlation with sale price ","60f6e6ab":"### Dummy creation","8dc13891":"# Modeling\n\n### Data Preparation for modelling "}}