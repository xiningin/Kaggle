{"cell_type":{"c0d5bbfd":"code","232401f0":"code","3443e53d":"code","d26f2bcd":"code","cf0dcbd3":"code","5cb5cf26":"code","5517fed5":"code","9b6cfc3b":"code","aa68e89e":"code","3ff78644":"code","cc3cbbc7":"code","e46b6195":"code","76787097":"code","370fa7c1":"code","ad78026d":"code","467977fc":"code","6558eb8f":"code","bebacb66":"code","51f63eb4":"markdown","d89b8ec5":"markdown","38106cf9":"markdown","b8557e49":"markdown","3602b05f":"markdown","4847c689":"markdown","b4004668":"markdown","f77df8b0":"markdown","846ee907":"markdown","3368cc12":"markdown","5fc5aa7a":"markdown"},"source":{"c0d5bbfd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","232401f0":"\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#setting up our enviroment\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","3443e53d":"#importing libraries\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nimport os\nimport pandas as pd\nimport numpy as np","d26f2bcd":"x  = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\npath = Path(x)\npath.ls()\n","cf0dcbd3":"\nnp.random.seed(40)\ndata = ImageDataBunch.from_folder(path, train = '.', valid_pct=0.2,\n                                  ds_tfms=get_transforms(), size=224,\n                                  num_workers=4).normalize(imagenet_stats)","5cb5cf26":"data.show_batch(rows=3, figsize=(7,6),recompute_scale_factor=True)","5517fed5":"data","9b6cfc3b":"\nprint(data.classes)\nlen(data.classes),data.c","aa68e89e":"learn = cnn_learner(data, models.resnet18, metrics=[accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"))\n","3ff78644":"learn.lr_find()\nlearn.recorder.plot(suggestions=True)","cc3cbbc7":"lr1 = 1e-3\nlr2 = 1e-1\nlearn.fit_one_cycle(4,slice(lr1,lr2))","e46b6195":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","76787097":"learn.unfreeze()","370fa7c1":"learn.lr_find()\nlearn.recorder.plot()","ad78026d":"lr = 1e-4\nlearn.fit_one_cycle(5,lr)","467977fc":"img = open_image('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/person100_bacteria_475.jpeg')\nprint(learn.predict(img)[0])\nimg","6558eb8f":"learn.export(file = Path(\"\/kaggle\/working\/export.pkl\"))\n","bebacb66":"learn.model_dir = \"\/kaggle\/working\"\nlearn.save(\"stage-1\",return_path=True)","51f63eb4":"# **Deploying your model**\n\nWhen you are ready to put your model in production, export the minimal state of your Learner with:","d89b8ec5":"# **Print Classes present in the data**","38106cf9":"# **Test your model on untrained images**","b8557e49":"# **Training the model**\n\n* We now use a pre-trained ResNet18 Convolutional Neural Net model, and use transfer learning to learn weights of only the last layer of the network.\n\n\n* Why Transfer learning? Because with transfer learning, you begin with an existing (trained) neural network used for image recognition \u2014 and then tweak it a bit (or more) here and there to train a model for your particular use case. And why do we do that? Training a reasonable neural network would mean needing approximately 300,000 image samples, and to achieve really good performance, we\u2019re going to need at least a million images.\n\n* In our case, we have approximately 2500 images in our training set \u2014 you have one guess to decide if that would have been enough if were to train a neural net from scratch.\n\n* We use the **create_cnn()** function for loading a pre-trained ResNet18 network, that was trained on around a million images from the ImageNet database.\n","3602b05f":"# **Data Explorations**\nOur image dataset is stored as .jpg files in 2 different folders, with each folder bearing the name of model of the images contained in the folder. We use the ImageDataBunch.from_folder() function to load the images and assign labels the images based on the name of the folder they\u2019re read from.","4847c689":"# **Setting up path for training data**\n\nFun Fact: Number of elements in a list of path is same as number of classes you have\n","b4004668":"# **Import necessary modules**\nLet us begin by importing the necessary modules for our Computer Vision problem:\n****\n**from fastai.vision import ***\n\nThere\u2019s probably gonna be a bunch of Pythonistas who are waiting to throw eggs at me because of my usage of import * above, but that\u2019s pretty much all you need for this post. The library has a lot of functionality packed in it, and you\u2019ll realize the ease of using it as we dive deeper into the data exploration.","f77df8b0":"data.c \u2014 How many classes are there in our dataset?\n\nlen(data.train_ds) \u2014 What is the size of our training dataset?\n\nlen(data.valid_ds) \u2014 What is the size of our validation dataset?\n\n\n","846ee907":"# **Training Neural Network**\n\nTo find the perfect learning rates we can use the lr_find and recorder.plot methods which create a plot that relates the learning rate with the loss.","3368cc12":"# **Let's evaluate the performance using Confusion matrix**","5fc5aa7a":"# **Data Loading For training**\nthings to be remember:\n* Decide validation percentage ( 0.2 => 20% )\n* Provide path for training data\n* Decide augmentations criteria (optional)\n* Decide image size (which is 224 in my case)"}}