{"cell_type":{"3ca5041d":"code","7eb3db5a":"code","8f2f441d":"code","2ac09fab":"code","2676d3bf":"code","44fb58cc":"code","05298c6c":"code","fab2dc3d":"code","87d60f92":"code","ffdc6128":"code","08855c66":"code","2ec31c0a":"code","13fe5d24":"code","3a50f851":"code","8163f3e7":"code","aee73884":"code","fe8ad26b":"code","58d332a7":"code","7c9cd21d":"code","5e098feb":"code","cadef8ce":"code","01dc2d98":"code","d79fac4e":"markdown","5b984e35":"markdown","c11d1443":"markdown","299eeb6a":"markdown","26c87bb3":"markdown","f111da6c":"markdown","96fa0a0e":"markdown","8e481e37":"markdown","7d0a63fe":"markdown","07f5313c":"markdown","16eb8d53":"markdown","e87e3cc4":"markdown","2bd5b838":"markdown","3e8749cf":"markdown","1f04874b":"markdown","3d3c18b9":"markdown","74a5a360":"markdown","d01bbbc4":"markdown","a28753a5":"markdown","03e2d0f9":"markdown"},"source":{"3ca5041d":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.utils import to_categorical\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix","7eb3db5a":"data = pd.read_csv(\"..\/input\/az-handwritten-alphabets-in-csv-format\/A_Z Handwritten Data.csv\")","8f2f441d":"data.head() ","2ac09fab":"X = data.drop('0',axis = 1) # axis=1 for dropping column\ny = data['0']","2676d3bf":"X.head()","44fb58cc":"y.head() ","05298c6c":"X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2)","fab2dc3d":"X_train = np.reshape(X_train.values, (X_train.shape[0], 28,28))\nX_test = np.reshape(X_test.values, (X_test.shape[0], 28,28))","87d60f92":"encode = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}","ffdc6128":"y_int = np.int0(y) \ncount = np.zeros(26, dtype='int') \nfor i in y_int:\n    count[i] +=1 \n\nalphabets = []\nfor i in encode.values():\n    alphabets.append(i) \n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.barh(alphabets, count)\n\nplt.xlabel(\"Number of elements \")\nplt.ylabel(\"Alphabets\")\nplt.grid()\nplt.show()","08855c66":"X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1) #RGB =>Channel of 1\nprint(\"New shape of train data: \", X_train.shape)\n\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1) #RGB =>Channel of 1\nprint(\"New shape of train data: \", X_test.shape)","2ec31c0a":"train_yOHE = to_categorical(Y_train, num_classes = 26, dtype='int')\nprint(\"New shape of train labels: \", train_yOHE.shape)\n\ntest_yOHE = to_categorical(Y_test, num_classes = 26, dtype='int')\nprint(\"New shape of test labels: \", test_yOHE.shape)","13fe5d24":"model = Sequential()\n#CNN\n# input -> conv -> maxpool -> conv -> maxpool ......->flattened vector-> \n#.                        hidden layer -> hidden layer -> softmax layer\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64,activation =\"relu\"))\nmodel.add(Dense(128,activation =\"relu\"))\n\nmodel.add(Dense(26,activation =\"softmax\"))","3a50f851":"model.summary()","8163f3e7":"model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","aee73884":"history = model.fit(X_train, train_yOHE, epochs=1,  validation_data = (X_test,test_yOHE))","fe8ad26b":"predictions = model.predict(\n      x=X_test\n    , batch_size=30\n    , verbose=0\n)","58d332a7":"rounded_predictions = np.argmax(predictions, axis=-1)","7c9cd21d":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","5e098feb":"cm = confusion_matrix(y_true=Y_test, y_pred=rounded_predictions)","cadef8ce":"cm_plot_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']","01dc2d98":"plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","d79fac4e":"# Splitting the Data into Images and Labels","5b984e35":"# Reshaping the data into the format of Images","c11d1443":"# Reading the Data","299eeb6a":"# Converting the Values to Categorical Variables","26c87bb3":"**SO, ACCORDING TO THE CONFUSION MATRIX, OUR MODEL WORKED PRETTY WELL ON THE TEST DATASET THAT WE CREATED TO TEST IT.**","f111da6c":"# Getting Summary of the Model Created","96fa0a0e":"# Creating the CNN","8e481e37":"# Importing Required Libraries","7d0a63fe":"# Plotting the Confusion Matrix","07f5313c":"# Making Predictions","16eb8d53":"# Creating Confusion Matrix","e87e3cc4":"Here,we will try to classify English Alphabets as shown above with the help of a powerful Convolutional Neural Network.","2bd5b838":"# Starting the Training","3e8749cf":"![image.png](attachment:cfff3547-d484-47ea-9825-37bad6d8cfa0.png)!","1f04874b":"\n# **LetsGrowMore Data Science Internship (VIP)**\n**Preeti Sahani**\n\n**Title: Develop A Neural Network That Can Read Handwriting**","3d3c18b9":"# Compiling the Model","74a5a360":"# Getting to know about the Number of Alphabets present in the Data","d01bbbc4":"# Making the data suitable for the CNN","a28753a5":"# Encoding English Alphabets to Number from 0-25","03e2d0f9":"# Splitting the Data into Train and Test Sets"}}