{"cell_type":{"6c8bd75b":"code","445f38be":"code","592397d1":"code","2d7ff013":"code","33d19fd9":"code","853bc0b8":"code","51c18b92":"code","c2c255d9":"code","94daa263":"code","3f6ec449":"code","46b9b3cb":"code","03397db4":"code","426bfc54":"code","911c6350":"code","2f3f852a":"code","0fdd19ee":"code","663b9ff8":"code","24945c29":"code","b36cbb6e":"code","93c588d3":"markdown"},"source":{"6c8bd75b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","445f38be":"import re\nimport nltk\nnltk.download(\"stopwords\")\nnltk.download('punkt')\nfrom nltk import word_tokenize,sent_tokenize\nnltk.download('wordnet')\nimport nltk as nlp","592397d1":"df = pd.read_csv('..\/input\/covid19-tweets\/covid19_tweets.csv',encoding='utf8')\ndf.head()","2d7ff013":"cult_list=[]\n\nfor cult in df.text:\n    cult=re.sub(\"[^a-zA-z]\",\" \",cult)\n    cult=cult.lower()\n    cult=nltk.word_tokenize(cult)\n    lemma=nlp.WordNetLemmatizer()\n    cult=[lemma.lemmatize(word) for word in cult]\n    cult=\" \".join(cult)\n    cult_list.append(cult)","33d19fd9":"from sklearn.feature_extraction.text import CountVectorizer\n\nmax_features=800\ncount_vectorizer=CountVectorizer(max_features=max_features,stop_words=\"english\")\nsparce_matrix=count_vectorizer.fit_transform(cult_list).toarray()","853bc0b8":"sparce_matrix.shape ","51c18b92":"sparce_matrix","c2c255d9":"print(\"Top {} the most used words: {}\".format(max_features,count_vectorizer.get_feature_names()))","94daa263":"data = pd.DataFrame(count_vectorizer.get_feature_names(),columns=[\"Words\"])\ndata[0:10]","3f6ec449":"from wordcloud import WordCloud \nimport matplotlib.pyplot as plt\n\nplt.subplots(figsize=(10,10))\nwordcloud=WordCloud(background_color=\"black\",width=1024,height=768).generate(\" \".join(data.Words[0:100]))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","46b9b3cb":"X=sparce_matrix[0:20000]\ny0=df.user_favourites[0:20000]\n\ny1=[]\nfor item in y0:\n    y1+=[int(np.log1p(item))]\ny=pd.Series(y1)\n\nprint(X.shape)\nprint(y.shape)","03397db4":"print(y.value_counts())","426bfc54":"from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report,log_loss,precision_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score,roc_curve\n\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","911c6350":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","2f3f852a":"lgbm_model = LGBMClassifier()\nlgbm_model.fit(X_train,y_train)\ny_pred = lgbm_model.predict(X_test)","0fdd19ee":"print(\"Accuracy:\",accuracy_score(y_test,y_pred))","663b9ff8":"df1=df[['user_favourites','text']].copy()\ndf1","24945c29":"df2=df1.sort_values(by=['user_favourites'],ascending=False).reset_index()\ndf2","b36cbb6e":"for i in range(5):\n    print(df2['text'][i])","93c588d3":"NLTK is a leading platform for building Python programs to work with human language data.\nhttps:\/\/www.nltk.org\/"}}