{"cell_type":{"87c3a7a7":"code","694dcf3d":"code","b9f4cffa":"code","792f566e":"code","bb55c17c":"code","48fd61cf":"code","036bd1c7":"code","a2574d00":"code","9bc1ebc6":"code","852a5078":"code","cefd009e":"code","f77ce35f":"code","0ab29766":"code","1141448c":"code","0782ea03":"code","d4712e3b":"code","9977ff5d":"code","f17c3895":"code","e920d5ed":"code","55b56197":"code","b50ac5c5":"code","5efb4ca8":"code","79fef0ca":"code","6ab00d55":"code","52fdbcad":"code","940ceb3b":"code","95a041a3":"code","ddf4f9de":"code","175f6845":"code","48eb188d":"code","e05e74e2":"code","bf46161f":"code","363bcae7":"code","c81af2e1":"code","dd2faa74":"code","7b975765":"code","8b81e2c3":"code","6ab1ee0a":"code","f1d58cc8":"code","36100eeb":"code","10406f2c":"code","b24a1e88":"code","280092bd":"code","c92ac027":"code","a9fb3033":"code","1e9910c2":"code","50329970":"code","9743db88":"code","64d413e2":"code","55886fed":"code","fb18be18":"code","9261ebcb":"code","8fc45f1b":"code","9d00222f":"code","656da73d":"code","56789bbd":"code","37f047d1":"code","cd4f5931":"code","b5564634":"code","27e89c86":"code","4f783f17":"code","49d5d106":"code","a8779526":"code","5c81a4d5":"code","58de4169":"code","7ef29838":"code","85b565b4":"code","d6c119a7":"code","2f5e9ec6":"code","5c976e72":"code","3a0dfaab":"code","b2a6e56f":"code","e424fa74":"code","9e304379":"code","1daa18bc":"code","d0678b87":"code","f7dad2d3":"code","ca528b73":"code","facb7ae6":"code","e8a13d70":"markdown","af0f8f4a":"markdown","5568ab4b":"markdown","5196dc72":"markdown","d4c89279":"markdown","1b796cc3":"markdown","d68ad3fb":"markdown","83a065cf":"markdown","1cc1fc31":"markdown","0ec564c1":"markdown","bf8e2b07":"markdown","4c194c3c":"markdown","3bb647a5":"markdown","48ec833e":"markdown","0d9c8ed6":"markdown","f781187f":"markdown","d4ce17ac":"markdown","16deaeb6":"markdown","55a4af7a":"markdown","6e6b3641":"markdown","179aa2db":"markdown","bece9383":"markdown","ed1cfefa":"markdown","a210a0b1":"markdown","159ab51c":"markdown","ead60d8e":"markdown","2cedce06":"markdown","51141de4":"markdown","3c6bb84e":"markdown","e9dbe964":"markdown","4ef67cf6":"markdown","f4b92454":"markdown","929d1223":"markdown","748bdf34":"markdown","9947638c":"markdown","5fd5baf4":"markdown","32473ac7":"markdown","10724721":"markdown","62db81fb":"markdown","df65da14":"markdown","3318ecd1":"markdown","0288cad4":"markdown","9b64dfd5":"markdown","3770c8f6":"markdown","0437e525":"markdown","69b2fbba":"markdown","e8f793ac":"markdown","7af48ba3":"markdown","c7df63b5":"markdown","67a1f72d":"markdown","ffd9dfee":"markdown","bb5e1c2e":"markdown","0429bf9f":"markdown","430b4635":"markdown","d3b45fc8":"markdown","0e6d4733":"markdown","7c1646fa":"markdown","74c68391":"markdown"},"source":{"87c3a7a7":"import math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import mode\n\n%matplotlib inline\nsns.set(style='white', context='notebook', palette='deep')\nplt.rcParams[\"figure.figsize\"] = (15,7) # plot size","694dcf3d":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","b9f4cffa":"print('Train shape: ' + str(train.shape) + '.')\nprint('Test shape: ' + str(test.shape) + '.')","792f566e":"pd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)","bb55c17c":"print('Missing values in the train set: ' + str(train.isnull().sum().sum()) + '.')\nprint('Missing values in the test set: ' + str(test.isnull().sum().sum()) + '.')","48fd61cf":"train['dataset'] = 'train'   # identify this as the train dataset\ntest['dataset'] = 'test'     # identify this as the train dataset\ndataset = train.append(test, sort = False, ignore_index = True) # merge both datasets\ndel train, test              # free some memory.","036bd1c7":"dataset.shape","a2574d00":"dataset.dataset.value_counts()","9bc1ebc6":"dataset.columns","852a5078":"stats = dataset.describe().T\nfor i in range(len(dataset.columns)):\n    stats.loc[dataset.columns[i], 'mode'], stats.loc[dataset.columns[i], 'mode_count'] = mode(dataset[dataset.columns[i]])\n    stats.loc[dataset.columns[i], 'unique_values'] = dataset[dataset.columns[i]].value_counts().size\n    stats.loc[dataset.columns[i], 'NaN'] = dataset[dataset.columns[i]].isnull().sum()\n    if np.isnan(stats.loc[dataset.columns[i], 'count']): \n        stats.loc[dataset.columns[i], 'count'] = dataset.shape[0] - stats.loc[dataset.columns[i], 'NaN']\nstats = stats[['count', 'NaN', 'unique_values', 'mode', 'mode_count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\nstats.index.name = 'variable'\nstats.reset_index(inplace = True)\nstats","cefd009e":"variables = list(stats[stats['NaN'] > 0].sort_values(by = ['NaN'], ascending = False).variable)\nsns.barplot(x = 'variable', y='NaN', data = stats[stats['NaN'] > 0], order = variables)\nplt.xticks(rotation=45)\nstats[stats['NaN'] > 0].sort_values(by = ['NaN'], ascending = False)[['variable', 'NaN']]","f77ce35f":"dataset['MiscFeature'].fillna('NA', inplace = True)\ndataset['Alley'].fillna('NA', inplace = True)\ndataset['Fence'].fillna('NA', inplace = True)\ndataset['FireplaceQu'].fillna('NA', inplace = True)\ndataset['GarageFinish'].fillna('NA', inplace = True)\ndataset['GarageQual'].fillna('NA', inplace = True)\ndataset['GarageCond'].fillna('NA', inplace = True)\ndataset['GarageType'].fillna('NA', inplace = True)\ndataset['BsmtExposure'].fillna('NA', inplace = True)\ndataset['BsmtCond'].fillna('NA', inplace = True)\ndataset['BsmtQual'].fillna('NA', inplace = True)\ndataset['BsmtFinType1'].fillna('NA', inplace = True)\ndataset['BsmtFinType2'].fillna('NA', inplace = True)\ndataset['BsmtFullBath'].fillna(0.0, inplace = True)\ndataset['BsmtHalfBath'].fillna(0.0, inplace = True)\ndataset['BsmtFinSF1'].fillna(0.0, inplace = True)\ndataset['BsmtFinSF2'].fillna(0.0, inplace = True)\ndataset['BsmtUnfSF'].fillna(0.0, inplace = True)\ndataset['TotalBsmtSF'].fillna(0.0, inplace = True)","0ab29766":"dataset.PoolQC.value_counts()","1141448c":"pd.crosstab(dataset.PoolArea, dataset.PoolQC)","0782ea03":"dataset[(pd.isna(dataset['PoolQC'])) & (dataset['PoolArea'] > 0)].PoolArea.value_counts()","d4712e3b":"indexes = dataset[(pd.isna(dataset['PoolQC'])) & (dataset['PoolArea'] > 0)].index\ndataset.loc[indexes, 'PoolQC'] = 'TA'\ndataset['PoolQC'].fillna('NA', inplace = True)","9977ff5d":"#fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\nax1 = plt.subplot(212)\nax2 = plt.subplot(221)\nax3 = plt.subplot(222)\n#plt.subplots_adjust(hspace = 0.5)\n\nsns.scatterplot(y = 'LotFrontage', x = 'LotArea', data = dataset, ax = ax1, palette = 'rainbow')\nsns.boxplot(y = 'LotFrontage', x = 'LotShape', data = dataset, ax = ax2, palette = 'rainbow')\nsns.boxplot(y = 'LotFrontage', x = 'LotConfig', data = dataset, ax = ax3, palette = 'rainbow')","f17c3895":"pearsonr(dataset.LotFrontage.dropna(), dataset[pd.notna(dataset['LotFrontage'])].LotArea)","e920d5ed":"pearsonr(dataset.LotFrontage.dropna(), np.power(dataset[pd.notna(dataset['LotFrontage'])].LotArea, 1\/2))","55b56197":"pearsonr(dataset.LotFrontage.dropna(), np.power(dataset[pd.notna(dataset['LotFrontage'])].LotArea, 1\/4))","b50ac5c5":"ax = sns.distplot(np.power(dataset[pd.notna(dataset['LotFrontage'])].LotArea, 1\/4))\nax.set(xlabel = 'Fourth root of LotArea')","5efb4ca8":"ax = sns.regplot(y=dataset.LotFrontage.dropna(), x=np.power(dataset[pd.notna(dataset['LotFrontage'])].LotArea, 1\/4))\nax.set(xlabel = 'Fourth root of LotArea')","79fef0ca":"X = np.power(dataset[pd.notna(dataset['LotFrontage'])].LotArea, 1\/4)\nX = sm.add_constant(X)\nmodel = sm.RLM(dataset.LotFrontage.dropna(), X)\nresults = model.fit()","6ab00d55":"index = dataset[pd.isna(dataset['LotFrontage'])].index\nX_test = np.power(dataset.loc[index, 'LotArea'], 1\/4)\nX_test = sm.add_constant(X_test)\ndataset.loc[index, 'LotFrontage'] = results.predict(X_test)","52fdbcad":"ax = sns.scatterplot(y=dataset.LotFrontage, x=np.power(dataset.LotArea, 1\/4))\nax.set(xlabel = 'Fourth root of LotArea')","940ceb3b":"pearsonr(dataset.GarageYrBlt.dropna(), dataset[pd.notna(dataset['GarageYrBlt'])].YearBuilt)","95a041a3":"sns.regplot(y = dataset.GarageYrBlt.dropna(), x = dataset[pd.notna(dataset['GarageYrBlt'])].YearBuilt)","ddf4f9de":"index = dataset[dataset['GarageYrBlt'] > 2200].index\ndataset.loc[index, 'GarageYrBlt'] = np.nan","175f6845":"# Fits the Regression Model.\nX = dataset[pd.notna(dataset['GarageYrBlt'])]['YearBuilt']\nX = sm.add_constant(X)\nmodel = sm.OLS(dataset.GarageYrBlt.dropna(), X)\nresults = model.fit()","48eb188d":"# Fill in the NaN values.\nindex = dataset[pd.isna(dataset['GarageYrBlt'])].index\nX_test = dataset.loc[index, 'YearBuilt']\nX_test = sm.add_constant(X_test)\nX_test\ndataset.loc[index, 'GarageYrBlt'] = round(results.predict(X_test),0).astype(int)","e05e74e2":"dataset[(dataset['GarageYrBlt'] < dataset['YearBuilt'])][['GarageYrBlt', 'YearBuilt']]","bf46161f":"dataset['GarageYrBlt'] = np.where((dataset['GarageYrBlt'] >= 2000) & (dataset['GarageYrBlt'] == dataset['YearBuilt'] - 4), dataset['YearBuilt'], dataset['GarageYrBlt'])","363bcae7":"dataset[(pd.notna(dataset['MasVnrArea'])) & (pd.isna(dataset['MasVnrType']))][['MasVnrArea', 'MasVnrType']]","c81af2e1":"dataset.groupby('MasVnrType', as_index = False)['MasVnrArea'].median()","dd2faa74":"index = dataset[(pd.notna(dataset['MasVnrArea'])) & (pd.isna(dataset['MasVnrType']))].index\ndataset.loc[index, 'MasVnrType'] = 'Stone'","7b975765":"dataset['MasVnrType'].fillna('NA', inplace = True)\ndataset['MasVnrArea'].fillna(0, inplace = True)","8b81e2c3":"# LotArea and MSSubClass of the observations with NaN in the MSZoning variable.\ndataset[pd.isna(dataset['MSZoning'])][['MSSubClass', 'LotArea']]","6ab1ee0a":"# median LotArea grouped by MSZoning and MSSubClass.\ntemp = dataset.groupby(['MSSubClass', 'MSZoning'], as_index=False)['LotArea'].median()\ntemp[temp['MSSubClass'].isin([20, 30, 70])]","f1d58cc8":"# Makes the substitutions.\nindexes = dataset[(pd.isna(dataset['MSZoning'])) & (dataset['MSSubClass'] == 30)].index\ndataset.loc[indexes, 'MSZoning'] = 'C (all)'\nindexes = dataset[pd.isna(dataset['MSZoning'])].index\ndataset.loc[indexes, 'MSZoning'] = 'RL'","36100eeb":"dataset['MSZoning'].value_counts()","10406f2c":"dataset['Utilities'].value_counts()","b24a1e88":"dataset['Utilities'].fillna('AllPub', inplace = True)","280092bd":"dataset['Functional'].value_counts()","c92ac027":"dataset['Functional'].fillna('Typ', inplace = True)","a9fb3033":"dataset['GarageArea'].value_counts()","1e9910c2":"dataset[pd.isna(dataset['GarageArea'])]","50329970":"dataset[dataset['GarageType'] == 'Detchd'].GarageArea.describe()","9743db88":"dataset['GarageArea'].fillna(399, inplace = True)","64d413e2":"dataset['GarageCars'].value_counts()","55886fed":"dataset[pd.isna(dataset['GarageCars'])]","fb18be18":"temp = dataset.groupby(['GarageType', 'GarageCars'], as_index=False)['GarageArea'].median()\ntemp[temp['GarageType'] == 'Detchd']","9261ebcb":"dataset['GarageCars'].fillna(1, inplace = True)","8fc45f1b":"dataset[pd.isna(dataset['Exterior2nd'])]","9d00222f":"pd.crosstab(dataset['Exterior1st'], dataset['ExterCond'])","656da73d":"pd.crosstab(dataset['Exterior2nd'], dataset['ExterCond'])","56789bbd":"len(dataset[dataset['Exterior1st'] == dataset['Exterior2nd']])","37f047d1":"dataset['Exterior1st'].fillna('VinylSd', inplace = True)\ndataset['Exterior2nd'].fillna('VinylSd', inplace = True)","cd4f5931":"dataset[pd.isna(dataset['KitchenQual'])]","b5564634":"dataset[dataset['KitchenAbvGr'] ==  1].KitchenQual.value_counts()","27e89c86":"dataset['KitchenQual'].fillna('TA', inplace = True)","4f783f17":"dataset['Electrical'].value_counts()","49d5d106":"dataset['Electrical'].fillna('SBrkr', inplace = True)","a8779526":"dataset[pd.isna(dataset['SaleType'])]","5c81a4d5":"dataset[dataset['SaleCondition'] == 'Normal'].SaleType.value_counts()","58de4169":"dataset['SaleType'].fillna('WD', inplace = True)","7ef29838":"sns.distplot(dataset.SalePrice.dropna())","85b565b4":"sns.distplot(np.log(dataset.SalePrice.dropna()), hist=True)","d6c119a7":"index = dataset[pd.notna(dataset['SalePrice'])].index\ndataset.loc[index, 'SalePriceLog'] = np.log(dataset.loc[index, 'SalePrice'])","2f5e9ec6":"stats = dataset.describe().T\nfor i in range(len(dataset.columns)):\n    stats.loc[dataset.columns[i], 'mode'], stats.loc[dataset.columns[i], 'mode_count'] = mode(dataset[dataset.columns[i]])\n    stats.loc[dataset.columns[i], 'unique_values'] = dataset[dataset.columns[i]].value_counts().size\n    stats.loc[dataset.columns[i], 'NaN'] = dataset[dataset.columns[i]].isnull().sum()\n    if np.isnan(stats.loc[dataset.columns[i], 'count']): \n        stats.loc[dataset.columns[i], 'count'] = dataset.shape[0] - stats.loc[dataset.columns[i], 'NaN']\nstats = stats[['count', 'NaN', 'unique_values', 'mode', 'mode_count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\nstats.index.name = 'variable'\nstats.reset_index(inplace = True)\nstats","5c976e72":"dataset['MoSold'] = dataset['MoSold'].astype(str)\ndataset['MSSubClass'] = dataset['MSSubClass'].astype(str)\ndataset['OverallCond'] = dataset['OverallCond'].astype(str)\ndataset['OverallQual'] = dataset['OverallQual'].astype(str)","3a0dfaab":"dataset['LotFrontageLog'] = np.log(dataset['LotFrontage'])\ndataset['LotAreaLog'] = np.log(dataset['LotArea'])\ndataset['1stFlrSFLog'] = np.log(dataset['1stFlrSF'])\ndataset['GrLivAreaLog'] = np.log(dataset['GrLivArea'])","b2a6e56f":"ax1 = plt.subplot(221)\nax2 = plt.subplot(222)\nax3 = plt.subplot(223)\nax4 = plt.subplot(224)\n\nsns.distplot(dataset['LotFrontageLog'], ax = ax1)\nsns.distplot(dataset['LotAreaLog'], ax = ax2)\nsns.distplot(dataset['1stFlrSFLog'], ax = ax3)\nsns.distplot(dataset['GrLivAreaLog'], ax = ax4)","e424fa74":"dataset['2ndFlrDummy'] = np.where(dataset['2ndFlrSF'] > 0, 1, 0)\ndataset['3SsnPorchDummy'] = np.where(dataset['3SsnPorch'] > 0, 1, 0)\ndataset['AlleyDummy'] = np.where(dataset['Alley'] != 'NA', 1, 0)\ndataset['EnclosedPorchDummy'] = np.where(dataset['EnclosedPorch'] > 0, 1, 0)\ndataset['FireplaceDummy'] = np.where(dataset['FireplaceQu'] != 'NA', 1, 0)\ndataset['LowQualFinDummy'] = np.where(dataset['LowQualFinSF'] > 0, 1, 0)\ndataset['OpenPorchDummy'] = np.where(dataset['OpenPorchSF'] > 0, 1, 0)\ndataset['PoolDummy'] = np.where(dataset['PoolQC'] != 'NA', 1, 0)\ndataset['ScreenPorchDummy'] = np.where(dataset['ScreenPorch'] > 0, 1, 0)\ndataset['PorchDummy'] = np.where(dataset['3SsnPorchDummy'] + dataset['EnclosedPorchDummy'] + dataset['OpenPorchDummy'] + dataset['ScreenPorchDummy'] > 0, 1, 0)\ndataset['BsmtDummy'] = np.where(dataset['TotalBsmtSF'] > 0, 1, 0)\ndataset['DeckDummy'] = np.where(dataset['WoodDeckSF'] > 0, 1, 0)","9e304379":"sns.heatmap(dataset.corr(), cmap=\"Blues\", linewidths = .2)","1daa18bc":"dataset.corr()['SalePrice'].sort_values(ascending = False)","d0678b87":"variables = list(dataset.columns)[1:80] + list(dataset.columns)[83:]\n\nwhile len(variables) >= 8:\n    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3)\n    plt.subplots_adjust(hspace = 0.5)\n    ax = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9]\n    for i in range(9):\n        if type(dataset[variables[i]][0]) in [np.int64, np.float64]:\n            sns.scatterplot(y = 'SalePriceLog', x = variables[i], data = dataset, ax = ax[i])\n        else:\n            sns.boxplot(y = 'SalePriceLog', x = variables[i], data = dataset, palette = 'rainbow', ax = ax[i])\n    variables = variables[9:]    \n\nfig, ((ax1, ax2, ax3), (ax4, ax5, _)) = plt.subplots(2, 3, figsize=(15, 4.5))\nplt.subplots_adjust(hspace = 0.5)\nsns.boxplot(y = 'SalePriceLog', x = variables[0], data = dataset, ax = ax1, palette = 'rainbow')\nsns.boxplot(y = 'SalePriceLog', x = variables[1], data = dataset, ax = ax2, palette = 'rainbow')\nsns.boxplot(y = 'SalePriceLog', x = variables[2], data = dataset, ax = ax3, palette = 'rainbow')\nsns.boxplot(y = 'SalePriceLog', x = variables[3], data = dataset, ax = ax4, palette = 'rainbow')\nsns.boxplot(y = 'SalePriceLog', x = variables[4], data = dataset, ax = ax5, palette = 'rainbow')","f7dad2d3":"train = dataset[dataset['dataset'] == 'train'].copy()\ntrain['dataset'] = None\ntest = dataset[dataset['dataset'] == 'test'].copy()\ntest['dataset'] = None","ca528b73":"print('training set shape: ' + str(train.shape))\nprint('test set shape: ' + str(test.shape))","facb7ae6":"train.to_csv('train_mod.csv', index = False)\ntest.to_csv('test_mod.csv', index = False)","e8a13d70":"Since we already have more than 80 columns in the training set, I'll adjust the display to show up to 100 rows and columns. This can help us better visualize some data that will be generated.","af0f8f4a":"<h2>Checking the datasets<\/h2>","5568ab4b":"First things first. Let's see the datasets dimensions.","5196dc72":"<h2>Feature Engineering<\/h2>","d4c89279":"The missing values will be fit on the regression line presented next in the scatterplot:","1b796cc3":"<h2>Train and Test Set<\/h2>\n\nSince there is no more modifications that I would like to make to the dataset, it's time to separate it into train and test set again.","d68ad3fb":"The fourth root of Lot Area is closer related to LotFrontage and for this reason I'll use it to fill in the missing values in LotFrontage.\n\nBelow I present the distribution of the fourth root of LotArea:","83a065cf":"Now that we have the same number of *NaN* in both variables, we can set them equal to *NA* and zero.","1cc1fc31":"<h4>The following variables required some kind of additional evaluation before I could transform the missing values.<\/h4>\n\n<h3>PoolQC<\/h3>\n\nWe can see in the stats dataset that PoolQC has 2909 missing values, but PoolArea has only 2906 zero values. So the 3 observations mismatched are real missing values. I'll check how is the crosstabulation between these two variables before decide what to do. ","0ec564c1":"<h3>SaleType<\/h3>","bf8e2b07":"It seems reasonable to assume that the GarageArea is equal to 1 or 2. I'll be pragmatic here and choose the one with the median Area closer to 399.","4c194c3c":"<h1>House Prices Project - Part 1: Feature Engineering and Data Transformation<\/h1>\n\nIn this notebook, I present my data preparation and my analysis of the House Prices Project dataset.\n\nHere you'll find feature engineering techniques and some visualizations that help us have a good idea of how this dataset is structured.\n\nI create additional variables keeping in mind that I don't have a pre-selected regression model that I intend to use. So some variables may be more or less useful depending on the regression model adopted in the future. The model and variable selection techniques I'll present in my next notebook on the House Prices Project. ","3bb647a5":"The numbers don't change very much from one table to the other. This suggests that there must be many cases in which both variables have the same values. Let's see if this is true: ","48ec833e":"Ok. So it's no brainer in which category the missing values should be classified in.","0d9c8ed6":"<h3>Functional<\/h3>\n\nLet's check the distribution of this variable.","f781187f":"<h3>Visualizations<\/h3>\n\nSome variables didn't appear in the previous correlation analysis because they are categorical.\nTo have an ideia of how they interact with the dependent variable I'll plot scatterplots of the numerical variables and scatterplots of the categorical variables. The Y axis is always SalePriceLog (the same visualizations can be generated to SalePrice by only replacing SalePriceLog by it in the code below).","d4ce17ac":"Finally, I create dummy variables to indicate the presence\/absence of some features in the houses.","16deaeb6":"<h2>Final look at the data<\/h2>\n\nThis is a final look at the dataset before implementing the regression models.\n\nHere I try to have an idea of how each variable interact with the dependent variable of my future models: SalePriceLog.","55a4af7a":"<h3>KitchenQual<\/h3>","6e6b3641":"<h3>GarageCars<\/h3>","179aa2db":"This is it. The next step is the regression analysis, but since this notebook is already very long, I'll leave it to my next notebook.\n\nPlease, feel free to make comments and suggestions. I'm open to new ways of improving this notebook. :)","bece9383":"Comparing both distributions we can see that the log transformed variable seems closer to a normal distribution than the original data and for this reason I'm going to work with the log transformed variable in my regression models.","ed1cfefa":"<h2>Loading libraries and datasets<\/h2>","a210a0b1":"<h3>Exterior1st and Exterior2nd<\/h3>","159ab51c":"The previous correlations and visualizations suggests that some variables that would be interresting to have in a regression model are: \n- 1stFlrSFLog;\n- BsmtCond;\n- BsmtDummy;\n- BsmtExposure;\n- BsmtFinSF1;\n- BsmtQual;\n- CentralAir;\n- ExterQual;\n- Fireplaces;\n- FireplaceQu;\n- FullBath;\n- GarageArea;\n- GarageCars;\n- GarageFinish;\n- GarageQual;\n- GarageYrBlt;\n- GrLivAreaLog;\n- HeatingQC;\n- KitchenQual;\n- LotAreaLog;\n- LotFrontage;\n- MasVnrArea;\n- OpenPorchDummy;\n- OverallQual;\n- TotalBsmtSF;\n- TotRmsAbvGrd;\n- YearBuilt;\n- YearRemodAdd.","ead60d8e":"<h3>SalePrice - Variable Transformation<\/h3>\n\nThis variable statistics in the stats table strongly suggest that this variable is skewed to the left. Being this the case, it is recommended to log-transform SalePrice so that its distribution become more like a normal distribution, helping our dependent variable meet some assumptions made in inferential statistics.\n\nLet's check SalePrice distribution as it is:","2cedce06":"<h3>Electrical<\/h3>","51141de4":"<h3>Correlation Matrix<\/h3>\n\nI'll start by checking for some correlations to have an idea of which variables are more likely to contribute to a regression model and which aren't. ","3c6bb84e":"Great! We can visualize the strong relation in the data and yet we see that there is a mislabelled observation in GarageYrBlt (the one with GarageYrBlt > 2200). To avoid that the mislabelled observation in GarageYrBlt insert a bias in the model, I'm going to replace it with a *NaN* value and then I'm going to create a linear model to predict the values in all the *NaN* observations in the GarageYrBlt variable.","e9dbe964":"Looking at the variables we see that LotArea seems to be closer related to LotFrontage than the other variables. Yet, this relation doens't seem to be linear. I'll check it's correlation with this variable as it is, with its square root and with its fourth roth to see which of these transformations are more related to LotFrontage.","4ef67cf6":"<h3>MSZoning<\/h3>\n\nAccording to the description file, there should be no *NaN* in this variable. To fix this, I'll compare the values in this variable with the values in MSSubClass and in LotArea (since the lot area may be influenced by the zoning classification of the sale). I'll choose the MSZoning value according to the category in MSSubClass of the observations with *NaN* values in the variable MSZoning and according to the LotArea closer to the median of LotArea of the observations grouped by MSSubClass.","f4b92454":"<h3>Direct transformation of NaN values into NA or into 0<\/h3>\n\nFor this reason, the following variables had their *NaN* values transformed:\n\n- Alley, \n- BsmtCond, \n- BsmtExposure, \n- BsmtFinSF1, \n- BsmtFinSF2,\n- BsmtFinType1, \n- BsmtFinType2, \n- BsmtFullBath,\n- BsmtHalfBath,   \n- BsmtQual, \n- BsmtUnfSF \n- Fence, \n- FireplaceQu, \n- GarageCond, \n- GarageFinish, \n- GarageQual, \n- GarageType,\n- MiscFeature, \n- TotalBsmtSF.","929d1223":"<h3>Dealing with NaN Values<\/h3>\n\nLet's treat all these missing data. First of all, lets check how many observations in each variable are missing values.","748bdf34":"<h3>MasVnrType and MasVnrArea<\/h3>\n\nThere is one more observation in the MasVnrType variable counting as *NaN* then there is in the MasVnrArea variable. So that observation is very likely to be mislabelled. To fix it, I'll check what are the means of the MasVnrArea variable when grouped by the categories in MasVnrType and I'll choose the category with the median in MasVnrArea closest to the value in the observation with mislabelled data.","9947638c":"First I'll convert the above mentioned variables into string types.","5fd5baf4":"Now I make the log transformation of the following variables: *LotFrontage, LotArea, 1stFlrSF* and *GrLivArea*.","32473ac7":"Since these variables have a strong correlation, lets plot them together:","10724721":"Let's check for missing values.","62db81fb":"Indeed, in most of the cases both variables have the same value. Since 'VinylSd' is the the most common value for both variables, I'm setting the missing value in both variables equal to 'VinylSd'.","df65da14":"Ok. I guess it's reasonable to classify the missing values as 'Typ'.","3318ecd1":"Since there are many variables in the dataset, I think an easier way of checking for correlations with the dependent variable its to just check the column SalePriceLog in the correlation matrix.","0288cad4":"<h3>Utilities<\/h3>\n\nLet's check the distribution of this variable.","9b64dfd5":"<h3>GarageArea<\/h3>\n\nLet's check this variable.","3770c8f6":"Some observations based on the table presented previously:\n- The variables *MoSold, MSSubClass, OverallCond* and *OverallQual* may work better in a regression model if coded as **categorical variables**. For this reason I'll change them to be treated as categorical;\n- Some variables with no values equal to zero could perform better in a regression model if **log transformed** since they are skewed and a transformation could help prevent problems of multicolinearity: \n    - MSSubClass; \n    - LotFrontage; \n    - LotArea; \n    - 1stFlrSF; \n    - GrLivArea.\n- Some other variables can be used to generate new **dummy variables** indicating the presence\/absence of certain features:\n    - 2ndFlrSF;\n    - 3SsnPorch;\n    - Alley;\n    - EnclosedPorch;\n    - Fence;\n    - FireplaceQu;\n    - GarageQual;\n    - LowQualFinSF;\n    - MasVnrType;\n    - MiscFeature;\n    - MiscVal;\n    - PoolQC;\n    - OpenPorchSF;\n    - ScreenPorch\n    - TotalBsmtSF;\n    - WoodDeckSF.","0437e525":"Ok. Is easy to see when the model filled the missing values. These observations, in recent years, are the ones where GarageYrBlt is equal to YearBuilt minus 4. In these cases, I'll make GarageYrBlt equal to YearBuilt. I'm calling 'recent years' anything that came after 2000 (counting the year 2000).   ","69b2fbba":"That's it.","e8f793ac":"The regression line in the previous plot suggests that in the more recent years GarageYrBlt might have a smaller value than YearBuilt. I'll check it:","7af48ba3":"Checking the variables we can see that the range between each classification in PoolQC doesn't quite match the range of these missing values. Checking the description file we see that there is another category that is not present in this classification: 'TA' meaning 'Average\/Typical'. We have no rule of thumb here. It seems reasonable to me to assume that the missing labes are 'TA' and for this reason I'm coding these three values as 'TA', but another acceptable approach would be to take the median of the PoolArea variable of each category in PoolQC and assign the missing observations to the category in PoolQC that is closer to its median value in PoolArea. In the end, the most important thing here is to don't mislabel these three cases as *NA*.","c7df63b5":"<h3>GarageYrBlt<\/h3>\n\nSince this is a numeric variable, if I just fill in its *NaN* values with a *zero* I can end up inserting a serious bias in the variable. It seems more reasonable to find another variable that is correlated with GarageYrBlt and see how I can manipulate both so I can fill in these gaps without harming my future models. For this reason, I'm checking its correlation with the YearBuilt variable.","67a1f72d":"<h2>Data Transformations<\/h2>\n\nThe distribution of some variables suggest us that some transformations may be adequate to the regression models, depending on the model we choose to work with. Whith this in mind I'll update the stats dataset and I'll use it to help me decide which variables should be transformed, or created.","ffd9dfee":"<h3>LotFrontage<\/h3>\n\nLotFrontage is going to need some manipulation since it is a numerical variable with several *NaN* values. Luckily it is related to other variables with characteristics of the lot. Let's check:\n- LotArea;\n- LotShape;\n- LotConfig.","bb5e1c2e":"I'll set this *NaN* observation equal to the median value of the variable GarageArea when the GarageType is equal to 'Detchd'.","0429bf9f":"Lets check its distribution after log transformation:","430b4635":"It will be necessary to work on this missing values. Since there are several missing values in the train and test sets, is more efficient to join both datasets and work on the missing values than to do it separately.","d3b45fc8":"Ok. So I'll use a robust regression model to predict the values in the missing observations.","0e6d4733":"Both missing values of both variables are in the same line. I'll check some crosstabulations:","7c1646fa":"Checking all the columns in the dataset and getting some statistics.","74c68391":"Having detailed information about which variables have missing values and how many they are, we can treat these cases and replace the *NaN* values for other values that may be more adequate. Some things that I would like to highlight:\n\n- One thing to notice is that the SalePrice variable has 1459 *NaN* values (the same number of rows in the test set). This is so because these are the values that we have to predict in this competition, so we are not dealing with those missing values now, they are our final goal;\n- Checking the data_description.txt file we can see that most of these missing values actually indicates that the house doesn't have that feature. i.e. Missing values in the variable FireplaceQu indicates that the house doesn't have a fireplace. With this in mind I'll replace the missing values with a *NA* when in case of a categorical variable or I'll replace it with a *0* otherwise."}}