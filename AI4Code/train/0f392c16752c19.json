{"cell_type":{"985adddb":"code","89fa5d6c":"code","85c483d1":"code","1df21fa7":"code","391b41b7":"code","02887de9":"code","ea9b8e32":"code","f117c8b3":"code","15779c96":"code","07e864a9":"code","26660b86":"code","e50b9d0a":"code","f0860d27":"code","fb38d4c5":"code","68cd0938":"code","01d232d7":"code","f2419106":"code","45eddde3":"markdown","971997b0":"markdown","cf28f560":"markdown","736e678a":"markdown","25cb6b73":"markdown","627325f8":"markdown","e6893c0a":"markdown","ba561f32":"markdown","9a5c9cf7":"markdown","209885ce":"markdown","5b9f879c":"markdown"},"source":{"985adddb":"!pip -q install gdcm","89fa5d6c":"import os\nimport random\nimport pydicom\nfrom pathlib import Path\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2\nfrom skimage import exposure\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport warnings\nwarnings.filterwarnings('ignore')","85c483d1":"# Some color settings for the output plots.\nLABEL2COLOR = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\nCOLOR_PALETTE = [\"#F9C00C\", \"#00B9F1\", \"#7200DA\", \"#F9320C\"]","1df21fa7":"# Reading the input data\nBASE_DATA_PATH = Path(\"..\/input\/siim-covid19-detection\/\")\n!ls {BASE_DATA_PATH}\n\ndf_train_img = pd.read_csv(BASE_DATA_PATH \/ \"train_image_level.csv\")\ndf_train_study = pd.read_csv(BASE_DATA_PATH \/ \"train_study_level.csv\")\ndf_sub = pd.read_csv(BASE_DATA_PATH \/ \"sample_submission.csv\")","391b41b7":"# Bbox labels per image.\ndf_train_img.head()","02887de9":"# Labels of the studies\ndf_train_study.head()","ea9b8e32":"CLASS_MAP = {\n    0: \"Negative for Pneumonia\",\n    1: \"Typical Appearance\",\n    2: \"Indeterminate Appearance\",\n    3: \"Atypical Appearance\"\n}\n\n# Create a label column.\ndf_train_study[\"class_id\"] = df_train_study.iloc[:, 1:].values.argmax(1)\n\n# Remove the study part from the ids.\ndf_train_study[\"StudyInstanceUID\"] = df_train_study[\"id\"].apply(lambda x: x[:-6])\ndf_train_study = df_train_study[[\"StudyInstanceUID\", \"class_id\"]]\n\n# Merge the two train csvs together.\ndf_train = pd.merge(df_train_img, df_train_study, on=\"StudyInstanceUID\")\n\n# Map the class ids to original names for plotting.\ndf_train[\"class_label\"] = df_train[\"class_id\"].map(CLASS_MAP)\n\n# Generating the image paths from given StudyInstanceUID.\ntrain_dir = BASE_DATA_PATH \/ \"train\"\ndf_train[\"path\"] = df_train[\"StudyInstanceUID\"].apply(lambda s_id: glob(os.path.join(train_dir, s_id + \"\/*\/*\"))[0])","f117c8b3":"df_train.head()","15779c96":"df_train[\"class_id\"].value_counts()","07e864a9":"plt.figure(figsize=(21, 10))\ndf_train[\"label\"]\nax = sns.countplot(x=\"class_label\", data=df_train, palette=COLOR_PALETTE)\nplt.title('Percentage of the Classes', fontsize=20)\n\ntotal = len(df_train)\n\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n    x = p.get_x() + p.get_width() \/ 3\n    y = p.get_height() + 10\n    ax.annotate(percentage, (x, y), weight=\"bold\", fontsize=20)\n\nplt.show()","26660b86":"bbox_counts = df_train.label.str.count(\"opacity\")\nopacity_count = (bbox_counts > 0).sum()\nnone_count = len(df_train) - opacity_count\n\ndf_bbox_counts = pd.DataFrame({\"label\": [\"opacity\", \"none\"], \"count\": [opacity_count, none_count]})\ndf_bbox_counts","e50b9d0a":"plt.figure(figsize=(14, 8))\nsns.barplot(data=df_bbox_counts, x=\"count\", y=\"label\");","f0860d27":"plt.figure(figsize=(14, 8))\nsns.histplot(bbox_counts);","fb38d4c5":"print(f\"Minimum number of bboxes per image: {min(bbox_counts)}\")\nprint(f\"Maximum number of bboxes per image: {max(bbox_counts)}\")","68cd0938":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, labels=None, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    if labels is None: labels = [None] * len(imgs)\n        \n    for i, (img, label) in enumerate(zip(imgs, labels)):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n        if label is not None:\n            plt.title(label)\n    plt.suptitle(title)\n    plt.show()","01d232d7":"imgs = [dicom2array(path) for path in df_train[\"path\"][:4]]\nplot_imgs(imgs)","f2419106":"img_ids = df_train['id'].values\nclass_ids = df_train['class_id'].unique()\n\nscale = 5\nthickness = 7\n\npaths = df_train[\"path\"]\nall_boxes = df_train.label.apply(lambda x: [x.split()[idx:idx+6] for idx in range(0, len(x.split()), 6)])\n\nimgs, labels = [], []\n\nfor i in np.random.choice(range(len(df_train)), 8):\n    img = dicom2array(path=paths[i])\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    boxes = all_boxes[i]\n    img_labels = [df_train.class_id[i]] * len(boxes)\n    for label_id, box in zip(img_labels, boxes):\n        color = LABEL2COLOR[label_id]\n        img = cv2.rectangle(\n            img,\n            (int(float(box[2]) \/ scale), int(float(box[3]) \/ scale)),\n            (int(float(box[4]) \/ scale), int(float(box[5]) \/ scale)),\n            color, thickness\n    )\n    img = cv2.resize(img, (500, 500))\n    imgs.append(img)\n    labels.append(CLASS_MAP[label_id])\n    \nplot_imgs(imgs, labels, cmap=None)","45eddde3":"# Plotting X-ray Images","971997b0":"# Plotting the Bounding Boxes","cf28f560":"# BBox Distribution per Image","736e678a":"# SIIM-FISABIO-RSNA COVID-19 Detection\n\n> **Identify and localize COVID-19 abnormalities on chest radiographs**\n\nIn this competition, you\u2019ll identify and localize COVID-19 abnormalities on chest radiographs. In particular, you'll categorize the radiographs as negative for pneumonia or typical, indeterminate, or atypical for COVID-19. You and your model will work with imaging data and annotations from a group of radiologists.\n","25cb6b73":"# Bbox Distributions","627325f8":"# Imports","e6893c0a":"# Class Distributions","ba561f32":"# Merging the Image and Study CSVs","9a5c9cf7":"# Helper Functions","209885ce":"### To be continued...","5b9f879c":"**If you liked this notebook, please feel free to upvote. It is too much appreciated.**"}}