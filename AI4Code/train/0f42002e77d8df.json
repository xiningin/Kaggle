{"cell_type":{"4686861f":"code","20bf30e0":"code","be5b82cf":"code","44526cd4":"code","f434148b":"code","d3ba976b":"code","f84f64e3":"code","0dd08459":"code","181d7d64":"code","45064ef9":"code","201d031b":"code","ea467624":"code","ca41221d":"code","90969fde":"code","55a7e56b":"code","55d9c5ae":"code","531a463a":"code","2ab595b3":"code","1b727d80":"code","9d0dc823":"code","c6b287ee":"code","167c9dcc":"code","6775c23b":"code","aa3ee27a":"code","06afba52":"markdown","562a315b":"markdown","04d88248":"markdown","2a801ebb":"markdown","1b095d9a":"markdown","d7a1114d":"markdown","39053465":"markdown","5722b0f0":"markdown","2466f875":"markdown","7beb43cb":"markdown","d6a633e9":"markdown","5b50ab4f":"markdown","c553835a":"markdown","20b0e4d5":"markdown","478f8019":"markdown","e2beb7f3":"markdown","a4b99593":"markdown","56f4ac94":"markdown","a42d06eb":"markdown","afeeec52":"markdown"},"source":{"4686861f":"import os,shutil,random\nimport numpy as np\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","20bf30e0":"# path of data set\nDATASET_DIR = '..\/input\/flowers-recognition\/flowers\/flowers'\n# path of spilted data\nNEW_DIR = \"data\"\n# ratio of test set\nnum_test = 0.2","be5b82cf":"def shuffle_all_files(dataset_dir, new_dir, num_test):\n    if not os.path.exists(new_dir):\n        pass\n    else:\n        shutil.rmtree(new_dir)\n    os.makedirs(new_dir)\n    train_dir = os.path.join(new_dir, 'train')\n    os.makedirs(train_dir)\n    test_dir = os.path.join(new_dir, 'test')\n    os.makedirs(test_dir)\n    directories = []\n    train_directories = [] \n    test_directories = [] \n    class_names = []\n    for filename in os.listdir(dataset_dir):\n        path = os.path.join(dataset_dir, filename)\n        train_path = os.path.join(train_dir, filename)\n        test_path = os.path.join(test_dir, filename)\n        if os.path.isdir(path):\n            directories.append(path)\n            train_directories.append(train_path)\n            os.makedirs(train_path)\n            test_directories.append(test_path)\n            os.makedirs(test_path)\n            class_names.append(filename)\n    print('class_list',class_names)\n    \n    for i in range(len(directories)):\n        photo_filenames = []\n        train_photo_filenames = []\n        test_photo_filenames = []\n        for filename in os.listdir(directories[i]):\n            path = os.path.join(directories[i], filename)\n            train_path = os.path.join(train_directories[i], filename)\n            test_path = os.path.join(test_directories[i], filename)\n            photo_filenames.append(path)\n            train_photo_filenames.append(train_path)\n            test_photo_filenames.append(test_path)\n        # list to array\n        photo_filenames = np.array(photo_filenames)\n        train_photo_filenames = np.array(train_photo_filenames)\n        test_photo_filenames = np.array(test_photo_filenames)\n        # shuffle the index\n        index = [i for i in range(len(photo_filenames))] \n        random.shuffle(index)\n        photo_filenames = photo_filenames[index]\n        train_photo_filenames = train_photo_filenames[index]\n        test_photo_filenames = test_photo_filenames[index]\n        test_sample_index = int((1-num_test) * float(len(photo_filenames)))\n        for j in range(test_sample_index, len(photo_filenames)):\n            shutil.copyfile(photo_filenames[j], test_photo_filenames[j])\n        for j in range(0, test_sample_index):\n            shutil.copyfile(photo_filenames[j], train_photo_filenames[j])","44526cd4":"class_list = shuffle_all_files(DATASET_DIR, NEW_DIR, num_test)\nprint(class_list)","f434148b":"from tensorflow.keras.models import load_model\nfrom PIL import Image\nimport matplotlib.pyplot as plt","d3ba976b":"n = 10\nfile_name = os.listdir('data\/train\/')\nfor i in file_name:\n    path = 'data\/train\/' + str(i) +'\/'\n    img = path + os.listdir(path)[n]\n    print(img)\n    image = Image.open(img)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()","f84f64e3":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.layers import Dropout,Flatten,Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport json\nimport numpy as np","0dd08459":"num_class = 5\nbatch_size = 32\nepochs = 100\nimage_size = 224\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range= 0.1,\n    rescale=1\/255.,\n    shear_range= 10,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    brightness_range=(0.7,1.3),\n    fill_mode='nearest'\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1\/255.\n)","181d7d64":"train_generator = train_datagen.flow_from_directory(\n    'data\/train',\n    target_size=(image_size,image_size),\n    batch_size=batch_size\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    'data\/test',\n    target_size =(image_size,image_size),\n    batch_size=batch_size\n)","45064ef9":"labels = train_generator.class_indices\nprint(labels)","201d031b":"labels = dict(zip(labels.values(),labels.keys()))\nlabels","ea467624":"file = open('labels_flower.json','w',encoding='utf-8')\njson.dump(labels,file)","ca41221d":"vgg16 = VGG16(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","90969fde":"# define full layers by ourself\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\ntop_model.add(Dense(256,activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(num_class,activation='softmax'))\n\n# connect full layers and convolution layers(VGG16)\nmodel = Sequential()\nmodel.add(vgg16)\nmodel.add(top_model)","55a7e56b":"# compile the mode\nmodel.compile(optimizer=SGD(1e-3,momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])","55d9c5ae":"# add early stopping\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)","531a463a":"# traing the model\nhistory = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callbacks=[early_stopping])","2ab595b3":"model.save('pretrained_vgg16.h5')","1b727d80":"val_acc =history.history['val_accuracy']\ntrain_acc = history.history['accuracy']\n\nplt.plot(np.arange(len(val_acc)),val_acc,c='y',label='val_accuracy')\nplt.plot(np.arange(len(train_acc)),train_acc,c='b',label='train_accuracy')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.show()","9d0dc823":"from tensorflow.keras.models import load_model","c6b287ee":"model = load_model('pretrained_vgg16.h5')","167c9dcc":"img_for_test = Image.open('..\/input\/flowers\/rose-peach.jpg')\nimg_for_test = np.array(img_for_test.resize((224,224)))\nplt.imshow(img_for_test)\nplt.axis('off')\nplt.show()","6775c23b":"image = img_for_test.reshape(-1,224,224,3)\nimage = tf.cast(image, tf.float32)","aa3ee27a":"prediction_index = model.predict_classes(image)\nprediction = labels[int(prediction_index)]\nprint(prediction_index)\nprint(prediction)","06afba52":"Pick 1 picture from each flower category","562a315b":"### print out the result","04d88248":"# Data Classification Procedure","2a801ebb":"### image enhacement\uff1a","1b095d9a":"### import libraries\uff1a","d7a1114d":"### modeling","39053465":"### use matplotlib function show the train_accuracy & validation_accuracy","5722b0f0":"### BINGO!!!","2466f875":"Observed from the above results. There should be no problem with our data.","7beb43cb":"### get labels","d6a633e9":"# Summary\n- Goal: Through deep learning training on existing pictures, it can accurately identify the types of flowers.\n- Observing our data set, we can find that there is no training set and test set in the data set. \n- First, we need to manually sort out the training set and the validation set.\n- Second use graphical enhancements in tensorflow to improve our prediction accuracy.\n- Third use the VGG16 model to train the model.\n- In the end\uff0cgoolge a picture, and then test the accuracy of our model.","5b50ab4f":"# Modeling","c553835a":"\nAfter processing, we get the training set and test set. The ratio between the training set and the test set is 80% and 20%","20b0e4d5":"# Check Classified Files & Image","478f8019":"### Load the trained model for classification","e2beb7f3":"### resize the image shape and make sure it can fit our model","a4b99593":"- reverse \u2018keys\u2019 and 'values' and make a list\n- In this way, when we are doing picture prediction, we can directly output the type of flower through the result of the classification","56f4ac94":"### data processing","a42d06eb":"## save the model","afeeec52":"![1](https:\/\/hips.hearstapps.com\/hmg-prod.s3.amazonaws.com\/images\/birth-flower-1558461020.jpg)"}}