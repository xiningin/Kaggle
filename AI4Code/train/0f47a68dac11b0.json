{"cell_type":{"162506cb":"code","1cef7c68":"code","c411793b":"code","fc4b2dc7":"code","5827c468":"code","31bc5666":"code","8fb07db5":"code","88345eee":"code","97e74f41":"code","cf0413ac":"code","49db100c":"code","35b54ce4":"code","ae16ff81":"code","dcd2bbf4":"code","272cb674":"code","58865199":"code","a1690e4c":"code","1285ed71":"code","69ae980c":"code","b12acb3e":"code","b1291fbf":"code","67b20bf9":"code","697fdd71":"code","45773fbf":"code","d841c00a":"code","7115bd3a":"markdown","b2dae84f":"markdown","6703edb4":"markdown","7d40f93c":"markdown","f4c698ca":"markdown","ecbc0ae2":"markdown","72a2b3b6":"markdown","05279a37":"markdown"},"source":{"162506cb":"# https:\/\/www.kaggle.com\/t88take\/gsdc-phones-mean-prediction\n# import library\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2, venn2_circles   #\u30d9\u30f3\u56f3\u3092\u4f5c\u308c\u308b\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport pathlib\nimport plotly  # \u52d5\u7684\u306a\u30b0\u30e9\u30d5\u3092\u4f5c\u308b\u3053\u3068\u304c\u3067\u304d\u308b https:\/\/qiita.com\/inoory\/items\/12028af62018bf367722\nimport plotly.express as px  #\u3000\u4e0a\u8a18\u306e\u9032\u5316\u7248","1cef7c68":"def calc_vincenty_formula(lat1, lon1, lat2, lon2):  # \u7d4c\u5ea6:longitude, \u7def\u5ea6:latitude\n    \"\"\"Calculates the great circle distance between two points\n    on the earth. Inputs are array-like and specified in decimal degrees.\n    \"\"\"\n    #\u7403\u9762\u4e0a\u306e2\u70b9\u9593\u306e\u9577\u3055\u304c\u6700\u77ed\u3068\u306a\u308b\u8ddd\u96e2(\u5927\u9060\u8ddd\u96e2\u3092\u91cf\u308b)\n    RADIUS = 6_367_000\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = (np.cos(lat2)*np.sin(dlon))**2 + (np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(dlon))**2\n    b = (a**0.5)\/(np.sin(lat1)*np.sin(lat2) + np.cos(lat1)*np.cos(lat2)*np.cos(dlon))\n    dist = np.arctan(b)\n    return dist","c411793b":"def visualize_trafic(df, center, zoom=9):\n    # px.scatter_mapbox: \u52d5\u7684\u306a\u5730\u56f3\u306e\u4f5c\u6210\u306b\u6709\u52b9  https:\/\/plotly.com\/python\/scattermapbox\/\n    fig = px.scatter_mapbox(df,    \n                            \n                            # Here, plotly gets, (x,y) coordinates\n                            lat=\"latDeg\",\n                            lon=\"lngDeg\",\n                            \n                            #Here, plotly detects color of series\n                            color='phoneName',\n                            labels='phoneName',\n                            \n                            zoom=zoom,\n                            center=center,\n                            height=600,\n                            width=800)\n    fig.update_layout(mapbox_style='stamen-terrain')    # \u8868\u793a\u3059\u308b\u5730\u56f3\u306e\u7a2e\u985e\u3092\u6307\u5b9a\n    fig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n    fig.update_layout(title_text='GPS trafic')\n    fig.show()\n    \ndef visualize_collection(df, collection):\n    target_df = df[df['collectionName']==collection].copy()\n    lat_center = target_df['latDeg'].mean()\n    lng_center = target_df['lngDeg'].mean()\n    center = {'lat':lat_center, 'lon':lng_center}\n    \n    visualize_trafic(target_df, center)","fc4b2dc7":"INPUT = '..\/input\/google-smartphone-decimeter-challenge'","5827c468":"base_train = pd.read_csv(INPUT + '\/' + 'baseline_locations_train.csv')\nbase_test = pd.read_csv(INPUT + '\/' + 'baseline_locations_test.csv')\nsample_sub = pd.read_csv(INPUT + '\/' + 'sample_submission.csv')","31bc5666":"# ground_truth\np = pathlib.Path(INPUT)\ngt_files = list(p.glob('train\/*\/*\/ground_truth.csv'))\nprint('ground_truth.csv count : ', len(gt_files))\n\ngts = []\nfor gt_file in tqdm(gt_files):   # tqdm\uff1a\u3000\u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u8868\u793a\n    gts.append(pd.read_csv(gt_file))\nground_truth = pd.concat(gts)    # dataFrame\u3092\u4e00\u3064\u306b\u307e\u3068\u3081\u308b\n\ndisplay(ground_truth.head())","8fb07db5":"def add_distance_diff(df):\n    df['latDeg_prev'] = df['latDeg'].shift(1)\n    df['latDeg_next'] = df['latDeg'].shift(-1)\n    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n    df['phone_prev'] = df['phone'].shift(1)\n    df['phone_next'] = df['phone'].shift(-1)\n    \n    df['dist_prev'] = calc_vincenty_formula(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])  #\u73fe\u5728\u5730\u3068\u524d\u306e\u5730\u70b9\u3067\u8ddd\u96e2\u3092\u8a08\u7b97\n    df['dist_next'] = calc_vincenty_formula(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])  #     \u3068\u6b21\u306e\n    \n    df.loc[df['phone'] != df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan    #\u73fe\u5728\u3068\u524d\u306e\u643a\u5e2f\u304c\u9055\u3046\u3082\u306e\u306b\u5909\u308f\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3072\u3068\u3064\u524d\u306e\u30c7\u30fc\u30bf\u306f\u5225\u306e\u643a\u5e2f\u306e\u3082\u306e\u306a\u306e\u3067\u3001\u305d\u306e\u30c7\u30fc\u30bf\u3092\u6d88\u3059\u3002\n    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan      #\u73fe\u5728\u3068\u6b21\u306e                                   \u5f8c\u306e\n    \n    return df","88345eee":"# reject outlier\ntrain_ro = add_distance_diff(base_train)\nth = 50\ntrain_ro.loc[((train_ro['dist_prev'] > th) & (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan   #50\u3092\u57fa\u6e96\u3068\u3057\u3066\u3001\u6b20\u640d\u5024\u3092\u9664\u3044\u3066\u3044\u308b(\u884c\u306f\u6e1b\u3089\u3057\u3066\u3044\u306a\u3044\u3001\u5024\u306e\u307f)","97e74f41":"train_ro","cf0413ac":"!pip install simdkalman","49db100c":"import simdkalman","35b54ce4":"T = 1.0\nstate_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\nprocess_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9  # np.diag(): \u2460\u884c\u5217\u306e\u5bfe\u89d2\u6210\u5206\u3092\u4e00\u6b21\u5143\u914d\u5217\u3067\u53d6\u5f97\u3059\u308b \u2461\u4e00\u6b21\u5143\u914d\u5217\u3092\u3092\u5f15\u6570\u306b\u6e21\u3059\u3068\u305d\u306e\u5f15\u6570\u306e\u5bfe\u89d2\u884c\u5217\u3092\u751f\u6210\n\nobservation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\nobservation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9    #np.ones((a,b)): [a,b]\u306e\u3059\u3079\u30661\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u884c\u5217\u3092\u751f\u6210\u3059\u308b\u3002 \n\nkf = simdkalman.KalmanFilter(    # https:\/\/simdkalman.readthedocs.io\/en\/latest\/\n        state_transition = state_transition,   # A\n        process_noise = process_noise,      # Q\n        observation_model = observation_model,  # H\n        observation_noise = observation_noise)  # R\n\ndef apply_kf_smoothing(df, kf_=kf):\n    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()   #drop_duplicates(): \u91cd\u8907\u3057\u305f\u3068\u3053\u308d\u3092\u843d\u3068\u3059  collectioname\u3068phonename\u306e\u30da\u30a2\u306e\u7a2e\u985e\u3092\u4fdd\u5b58\n    for collection, phone in unique_paths:\n        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)  #np.logical_and: \u8ad6\u7406\u7a4d  \u3088\u3046\u306f&\n        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n        data = data.reshape(1, len(data), 2)  # (\u30c6\u30f3\u30bd\u30eb\u3001\u884c\u3001\u5217)\n        smoothed = kf_.smooth(data)   #\u30ab\u30eb\u30de\u30f3\u30d5\u30a3\u30eb\u30bf\u306b\u304b\u3051\u308b\n        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n    return df","ae16ff81":"cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']\ntrain_ro_kf = apply_kf_smoothing(train_ro[cols])","dcd2bbf4":"def make_lerp_data(df):    #lerp\u3068\u306f\u30012\u70b9\u9593\u306e\u6570\u5024\u3092\u8fd1\u4f3c\u7684\u306b\u6c42\u3081\u308b\u3053\u3068\u3002\n    '''\n    Generate interpolated lat,lng values for different phone times in the same collection.\n    '''\n    org_columns = df.columns\n    \n    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n    \n    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n    \n    # linear interpolation\n    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n    # Leave only records to be interpolated\n    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n    # calc lerp\n    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) \/ (lerp_df['time_next'] - lerp_df['time_prev']))) \n    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) \/ (lerp_df['time_next'] - lerp_df['time_prev']))) \n    \n    # Leave only the data that has a complete set of previous and next data.\n    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]     #\u6b20\u640d\u5024\u3092\u542b\u3080\u884c\u3092\u9664\u5916\n    \n    return lerp_df[org_columns]","272cb674":"def calc_mean_pred(df, lerp_df):\n    '''\n    Make a prediction based on the average of the predictions of phones in the same collection.\n    '''\n    add_lerp = pd.concat([df, lerp_df])\n    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n    return mean_pred_df","58865199":"train_lerp = make_lerp_data(train_ro_kf)\ntrain_mean_pred = calc_mean_pred(train_ro_kf, train_lerp)    # \u6642\u9593\u304c\u30c0\u30d6\u3063\u3066\u3044\u308b\u3068\u3053\u308d\u3092\u3072\u3068\u307e\u3068\u3081\u306b\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u305f\u304c\u3001\u3082\u3068\u3082\u3068\u6574\u7406\u6574\u9813\u3055\u308c\u3066\u3044\u305f\u30c7\u30fc\u30bf\u3060\u3063\u305f\u306e\u3067\u3001\u7d50\u679c\u306ftrain_ro_kf\u3068\u4e00\u7dd2","a1690e4c":"train_ro_kf","1285ed71":"train_lerp","69ae980c":"train_mean_pred","b12acb3e":"ground_truth","b1291fbf":"tmp1 = train_ro_kf.copy()\ntmp2 = train_mean_pred.copy()\ntmp2['phoneName'] = tmp2['phoneName'] + '_MEAN'\ntmp3 = ground_truth.copy()\ntmp3['phoneName'] = tmp3['phoneName'] + '_GT'\ntmp = pd.concat([tmp1, tmp2, tmp3])\nvisualize_collection(tmp, '2020-05-14-US-MTV-1')","67b20bf9":"def percentile50(x):\n    return np.percentile(x, 50)\ndef percentile95(x):\n    return np.percentile(x, 95)","697fdd71":"def get_train_score(df, gt):\n    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n    # calc_distance_error\n    df['err'] = calc_vincenty_formula(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n    # calc_evaluate_score\n    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) \/ 2\n    score = res['p50_p90_mean'].mean()\n    return score","45773fbf":"print('kf + reject_outlier : ', get_train_score(train_ro_kf, ground_truth))\nprint('+ phones_mean_pred : ', get_train_score(train_mean_pred, ground_truth))","d841c00a":"base_test = add_distance_diff(base_test)\nth = 50\nbase_test.loc[((base_test['dist_prev'] > th) & (base_test['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n\ntest_kf = apply_kf_smoothing(base_test)\n\ntest_lerp = make_lerp_data(test_kf)\ntest_mean_pred = calc_mean_pred(test_kf, test_lerp)\n\nsample_sub['latDeg'] = test_mean_pred['latDeg']\nsample_sub['lngDeg'] = test_mean_pred['lngDeg']\nsample_sub.to_csv('submission.csv', index=False)","7115bd3a":"\u30ab\u30eb\u30de\u30f3\u30d5\u30a3\u30eb\u30bf\uff1a\u3000\u89b3\u6e2c\u5024\u3084\u524d\u306e\u72b6\u614b\u304b\u3089\u73fe\u5728\u306e\u72b6\u614b\u3092\u63a8\u6e2c\u3059\u308b\u305f\u3081\u306e\u3082\u306e","b2dae84f":"# phones mean prediction","6703edb4":"# data prep","7d40f93c":"# evaluate train score","f4c698ca":"# kalman filter\nEN: https:\/\/www.kaggle.com\/emaerthin\/demonstration-of-the-kalman-filter\nJP: https:\/\/logics-of-blue.com\/kalman-filter-concept\/","ecbc0ae2":"# reject outlier","72a2b3b6":"# make submission","05279a37":"# Utils"}}