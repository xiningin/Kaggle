{"cell_type":{"2b83f862":"code","368af9f0":"code","7cce392d":"code","ad3473e3":"code","47bd5ae9":"code","b6d442a2":"code","4786ed9a":"code","41e0ebe8":"code","5f831ce4":"code","844dfed0":"code","6234da34":"code","e519bb7c":"code","2d517bd2":"code","b1e1044d":"code","ab2e79c3":"code","b375d69a":"markdown","0a313549":"markdown","2ba5d1d0":"markdown","1436ae05":"markdown","bf2df700":"markdown","c9773b17":"markdown","95ff5394":"markdown","f689fc4d":"markdown","57eb7d42":"markdown","d106325c":"markdown","c1a0d3aa":"markdown"},"source":{"2b83f862":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport cv2# data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.spatial import distance\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","368af9f0":"face_model = cv2.CascadeClassifier('..\/input\/haar-cascades-for-face-detection\/haarcascade_frontalface_default.xml')\n","7cce392d":"\nimport matplotlib.pyplot as plt\n#implementing on the sample image\nimg = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss244.png')\n#converting in greyscale because more convinient to work in greyscale\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n#returns a list of (x,y,w,h) tuples\nimg_2 = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #converted to colored o\/p image\nfor (x,y,w,h) in faces:\n    cv2.rectangle(img_2,(x,y),(x+w,y+h),(0,0,250),2)\n    \nplt.figure(figsize=(12,12))\nplt.imshow(img_2)\n\n\n","ad3473e3":"MIN_DISTANCE = 130\n#we have to check for pair or greater\nif len(faces)>=2:\n    label = [0 for i in range (len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2], faces[j][:2])#calculating the distance between people \n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n                \n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    for i in range(len(faces)):\n        (x,y,w,h)=faces[i]\n        if label[i]==1:\n            cv2.rectangle(new_img,(x,y), (x+w, y+h),(255,0,0),1)#if distance<MIN_DISTANCE then red box showing violation of social distancing\n        else:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)#else green box showing Social distancing followed\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n    \nelse:\n    print(\"No. of faces detected is less than 2\")\n            ","47bd5ae9":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.layers import Flatten, Dense\nfrom keras import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\n","b6d442a2":"#loading the test and the training data\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\ntrain_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","4786ed9a":"#data agumentation\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip = True,zoom_range=0.2, shear_range=0.2)\ntrain_generator=train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode = 'categorical', batch_size=32)\nval_datagen = ImageDataGenerator(rescale=1.0\/255)\nval_generator=val_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode = 'categorical', batch_size=32)\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator= test_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode = 'categorical', batch_size=32)","41e0ebe8":"vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='sigmoid'))\nmodel.summary()","5f831ce4":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=\"accuracy\")","844dfed0":"history = model.fit_generator(generator=train_generator, \n                             steps_per_epoch=len(train_generator)\/\/32,\n                              epochs = 20, validation_data = val_generator,\n                              validation_steps = len(val_generator)\/\/32)\n                             ","6234da34":"sample_mask = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\/1565.png')\nsample_mask = cv2.resize(sample_mask,(128,128))\nplt.imshow(sample_mask)\nsample_mask = np.reshape(sample_mask,[1,128,128,3])\nsample_mask = sample_mask\/255.0","e519bb7c":"model.predict(sample_mask)","2d517bd2":"model.save('masknet.h5')","b1e1044d":"mask_label = {0:'MASK', 1:'NO MASK'}\ndist_label = {0:(0,255,0), 1:(255,0,0)}\n","ab2e79c3":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n    \nelse:\n        print('no of faces is less than 2')\n        \n    ","b375d69a":"![https:\/\/www.gstatic.com\/education\/formulas2\/355397047\/en\/euclidean_distance.svg](http:\/\/)","0a313549":"the model is capable of classifying if a person is wearing a mask or not","2ba5d1d0":"We'll predict the model on sample_mask image","1436ae05":"RED SHOWS VIOLATION OF SOCIAL DISTANCING AND GREEN SHOWS FOLLOWING SOCIAL DISTANCING NORMS","bf2df700":"BUILDING VGG19 TRASFER LEARNING MODEL","c9773b17":"we now take crops of faces detected in the image and use the model trained in the above section to determine whether the individual faces have mask on or not.","95ff5394":"NOW IMPLEMENTING ON A SAMPLE IMAGE","f689fc4d":"**USING VGG19 FOR MASK DETECTION**","57eb7d42":"**INTEGRATING WITH HAAR CASCADE**","d106325c":"CALCULATING\/ CHECKING THE SOCIAL DISTANCING VIOLATION \nWe have to see if the distance between two people is not less than the MIN_DISTANCE. The MIN_DISTANCE is calculated keeping in mind the practical minimum distance(for instance, 6ft in India). This is mainly done by iterating over coordinates of faces and calculating the distance between each possible pair","c1a0d3aa":"opening the haarcascade face-mask-detection.xml"}}