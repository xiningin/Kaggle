{"cell_type":{"972b8d0f":"code","9f277d80":"code","8ba65ace":"code","3e87803d":"code","33dcb311":"code","97bfd8b2":"code","27993475":"markdown"},"source":{"972b8d0f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv).\nimport random\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, MaxPooling2D, concatenate, Conv2DTranspose\nimport tqdm\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f277d80":"#since the dataset isn't organized, we can't rely on existing keras datagenerator objects. Getting the filenames lets us match input\/output for batch generation\noutput_files = []\ninput_files = []\nfiles=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/source'):\n    for filename in filenames:\n        #input_files.append(os.path.join(dirname, filename))\n        files.append(filename)\n\n        \nnum_files = len(files)\nprint(num_files)\n\n#split files into training, validation, testing (without bothering to restructure file structure)\n\nrandom.shuffle(files)\n\ntraining_files = files[:int(num_files*.8)]\nvalidation_files = files[int(num_files*.8):int(num_files*.9)]\ntest_files = files[int(num_files*.9):]\n\n\n\nprint(len(training_files) + len(validation_files) + len(test_files)) #should be the same as num_files\n\n","8ba65ace":"def dataGrab(input_path,output_path,files):\n    input = []\n    for file in tqdm.tqdm(files):\n        im = Image.open(os.path.join(input_path,file))\n        im = im.resize((256,256)) #needed to stop running out of RAM\n        data = np.asarray(im).astype('float32')\/255.0\n        input.append(data)\n            \n    \n    output = []\n    for file in tqdm.tqdm(files):\n        im = Image.open(os.path.join(output_path,file))\n        im = im.resize((256,256))\n        data = np.asarray(im).astype('float32')\/255.0\n        output.append(data)\n    \n    return input, output\n            \n\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,files,input_path,output_path,batch_size = 32):\n        self.files = files\n        self.batch_size = batch_size\n        #self.dim = dim\n        self.input_path = input_path\n        self.output_path  = output_path\n        self.indexes = np.arange(len(self.files))\n        \n        #Here is where we load in all the data\n        self.input_data,self.output_data = dataGrab(self.input_path,self.output_path,self.files)\n        \n        \n    def __len__(self):\n        #Gives number of batches per epoch\n        return int(np.floor(len(self.files)\/self.batch_size))\n    \n    def on_epoch_end(self):\n        random.shuffle(self.indexes)\n        \n        \n    \n    def __getitem__(self,index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        \n        X = np.zeros((self.batch_size,256,256,1))\n        y = np.zeros((self.batch_size,256,256,1))\n        \n        for i, ID in enumerate(indexes):\n            X[i,:,:,0] = self.input_data[ID]\n            y[i,:,:,0] = self.output_data[ID]\n            \n        return X,y\n    \n    ","3e87803d":"\ntraining_generator = DataGenerator(training_files,\n                             input_path = '\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/source',\n                             output_path = '\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/target')\n                             \nval_generator = DataGenerator(validation_files,\n                             input_path = '\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/source',\n                             output_path = '\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/target')","33dcb311":"#No idea to create a U-Net, but let's try\n#borrowed from https:\/\/www.kaggle.com\/eduardomineo\/u-net-lung-segmentation-montgomery-shenzhen#3.-Segmentation-training\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return tf.keras.Model(inputs=[inputs], outputs=[conv10])\n\nmodel = unet()\nfilepath = \"epoch-{epoch:02d}-{val_loss:.2f}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\nmodel.compile(optimizer =\"adam\",loss=\"mse\")\nmodel.summary()","97bfd8b2":"model.fit(training_generator,validation_data=val_generator,epochs=20,callbacks = [checkpoint,tf.keras.callbacks.TensorBoard(\"logs\"),tf.keras.callbacks.CSVLogger(\"training_loss.csv\")])\n#model.fit(val_generator,epochs=3)","27993475":"\nmodel = tf.keras.models.Sequential([\n    Input(shape=(256,256,1)),\n    Conv2D(64, kernel_size=(7,7), activation='elu',padding=\"same\"),\n    Conv2D(32, kernel_size=(5,5), activation='elu',padding=\"same\"),\n    Conv2D(32, kernel_size=(5,5), activation='elu',padding=\"same\"),\n    Conv2D(32, kernel_size=(3,3), activation='elu',padding=\"same\"),\n    Conv2D(32, kernel_size=(3,3), activation='elu',padding=\"same\"),\n    Conv2D(1, kernel_size=3, activation='relu',padding=\"same\"),  \n])\nfilepath = \"epoch-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nmodel.compile(optimizer =\"adam\",loss=\"mse\",metrics = [\"Accuracy\"])\nmodel.summary()"}}