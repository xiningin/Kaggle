{"cell_type":{"ca875002":"code","e05d29ff":"code","26f13b7e":"code","70d9c52b":"code","68efe102":"code","6edcaa8c":"code","507f78a9":"markdown","69e9234a":"markdown","e44a0069":"markdown","857a9c25":"markdown"},"source":{"ca875002":"!pip install lm-dataformat #Library for easy retrieval of The pile data from jsonl.zstd files\n!pip install transformers #Library for easy interaction with gpt-neo-1.3B model","e05d29ff":"from transformers import GPTNeoForCausalLM, GPT2Tokenizer\nmodel = GPTNeoForCausalLM.from_pretrained(\"EleutherAI\/gpt-neo-1.3B\").cuda()\ntokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI\/gpt-neo-1.3B\")","26f13b7e":"import lm_dataformat\npile = lm_dataformat.Reader('..\/input\/the-pile-train-00-dataset\/the-eye.eu\/public\/AI\/pile\/train\/29.jsonl.zst')","70d9c52b":"docsiter = iter(pile.stream_data())\ndocs = []\nfrom tqdm import tqdm \nwith tqdm(total=10000, position=0, leave=True) as pbar:\n    for i in range(10000):\n        docs.append(next(docsiter))\n        pbar.update()","68efe102":"import numpy as np\nimport torch\nacc = [[],[],[]]\nfrom sklearn.metrics import accuracy_score\nwith tqdm(total=10000, position=0, leave=True) as pbar:\n    for idx in range(10000):\n        doc = docs[idx]\n        input_ids = tokenizer(doc, return_tensors=\"pt\").input_ids\n        \n        if(input_ids.shape[1] < 40):\n            acc[0].append(idx)\n            acc[1].append(input_ids.shape[1])\n            acc[2].append(np.nan) #Input tokens are less than 40, append nan as logit\n            continue\n        \n        length = 20 #Length of subsequent tokens, the tokens utilized to calculate number of correctly predicted tokens\n        \n        gen_tokens = model.generate(input_ids[:,:20].cuda(), do_sample=True, temperature=0.1,pad_token_id=50256,eos_token_id=50256,\n                                    min_length=20+length,max_length=40+length).cpu()[0] #Generating tokens from the model\n        \n        score = torch.sum(input_ids[0,20:length+20] == gen_tokens[20:length+20]).item() #Calculating the number of correctly predicted tokens \n        \n        \n        #Appending the document index, length of input tokens and the score to the logit array, @param acc\n        acc[0].append(idx)\n        acc[1].append(input_ids.shape[1])\n        acc[2].append(score)\n        \n        idx+=1 #Temporary index, keeps count of current iteration\n        pbar.update()","6edcaa8c":"import joblib\njoblib.dump(acc,'data29.pkl') #Saving @param acc","507f78a9":"* LM_Dataformat allows for retrieval of data by providing an iterator method \"stream_data\"","69e9234a":"* Creating the array @param docs, which contains the first 10,000 documents of THE PILE dataset","e44a0069":"* Creating the @param model using Huggingface api","857a9c25":"# About This Notebook\n* This notebook evaluates the number of tokens generated by the model EleutherAI\/gpt-neo-1.3B with The Pile data\n* The Evaluation is done by the following methodology\n\n* Select documents within THE PILE 29 dataset with more than or equal to 40 tokens, replace the skipped logits with np.nan\n* Utilize the first 20 tokens of each document as input to the model and use the subsequent 20 tokens to calculate the number of correctly predicted tokens\n* Correctly predicted tokens are found by comparing the tokens in range 20..40 of the input document with the tokens in range 20--40 of generated document\n* This data is stored in the array acc and saved in the file 'data29.pkl'"}}