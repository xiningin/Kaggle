{"cell_type":{"02e7ba00":"code","58aa0739":"code","47a7642d":"code","c4e00648":"code","df258ea6":"code","adb2518f":"code","e7e6a7a3":"code","907f9d98":"code","c2124461":"code","08deffa0":"code","32bf9e6a":"code","e22a3152":"code","06f9f52c":"code","a4dd82d5":"code","bd95ee51":"code","39abf155":"code","9f580596":"code","c785d127":"code","5ef04457":"code","0da675e2":"code","9dc44ff9":"code","728d11fb":"code","49fa6c41":"code","364335bd":"code","ee8a8081":"code","447d6417":"code","feb34fa7":"code","ae15d72a":"code","c4769a0c":"code","e3334986":"code","864018e0":"code","e8767225":"code","a4ea3ba1":"code","732ac27e":"code","954394db":"markdown","b976ba3d":"markdown","dc29081f":"markdown","a1eb7732":"markdown","4a963f20":"markdown","aa1bb358":"markdown","5d1143a6":"markdown","a215622a":"markdown","05c43958":"markdown","23817a47":"markdown","bb3fa6ea":"markdown","a38daf93":"markdown","2300545a":"markdown","47c52bce":"markdown","ce56fe12":"markdown","d46f538a":"markdown","6ffd2fc5":"markdown","187c0211":"markdown","7a30708a":"markdown","4c773c1e":"markdown","c7632548":"markdown"},"source":{"02e7ba00":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn","58aa0739":"df=pd.read_csv('..\/input\/airlines-customer-satisfaction\/Invistico_Airline.csv')\ndf.head()","47a7642d":"#df.info()","c4e00648":"df.isna().sum()","df258ea6":"df['Arrival Delay in Minutes'].describe()","adb2518f":"df_c=df.copy()\ndf.dropna(inplace=True)","e7e6a7a3":"category = [\"satisfaction\", \"Gender\", \"Customer Type\", \"Type of Travel\", \"Class\"]\nfor c in category:\n    print (\"{} \\n\".format(df[c].value_counts()))\ndf['satisfaction']=df['satisfaction'].map({'satisfied':1,'dissatisfied':0})","907f9d98":"sn.countplot(x=\"satisfaction\", data=df)\nplt.title('Airlines Customer satisfaction Count')\nplt.xticks([0,1],['Dissatisfied',\"Satisfied\"])\nplt.show()","c2124461":"fig,axs = plt.subplots(2,2,figsize=(14, 14))\ncols=['Gender', 'Customer Type', 'Type of Travel', 'Class']\nc=0\nfor i in range(2):\n  for j in range(2):\n    sn.countplot(data=df,x=cols[c],hue='satisfaction',ax=axs[i][j])\n    axs[i][j].set_title('Customer Satisafaction as per {}'.format(cols[c]))\n    axs[i][j].legend(['Dissatisfied',\"Satisfied\"])\n    c+=1","08deffa0":"fg=sn.displot(df,x='Age',binwidth=0.55,hue='satisfaction')\nfg.fig.set_figwidth(24.27)\nfg.fig.set_figheight(14.7)\nplt.show()","32bf9e6a":"fig, ax = plt.subplots(figsize=(15,8))\nsn.heatmap(df.corr(),cmap='gist_earth',annot=True)\nplt.show()","e22a3152":"df.drop(['Flight Distance','Departure\/Arrival time convenient','Gate location','Departure Delay in Minutes','Arrival Delay in Minutes'],axis=1,inplace=True)","06f9f52c":"df.head()","a4dd82d5":"df.shape","bd95ee51":"X = df.iloc[:,1:].values\ny = df.iloc[:,0].values\nX.shape","39abf155":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer([('encoder',OneHotEncoder(),[0,1,3,4])],remainder='passthrough')\nX = np.array(ct.fit_transform(X),dtype=np.float)","9f580596":"X.shape","c785d127":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score\nX_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.9, random_state=0)\n\nsc_X  = StandardScaler()\nX_train_sc = sc_X.fit_transform(X_train)\nX_test_sc = sc_X.transform(X_test)\n\nmin_max_scaler = MinMaxScaler()\nX_train_minmax = min_max_scaler.fit_transform(X_train)\nX_test_minmax = min_max_scaler.fit_transform(X_test)","5ef04457":"#function to plot learning curve for any classifier\nfrom sklearn.model_selection import learning_curve, validation_curve\ndef plotLearningCurves(X_train, y_train, classifier, title):\n    train_sizes, train_scores, test_scores = learning_curve(\n            classifier, X_train, y_train, cv=5, scoring=\"accuracy\")\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.plot(train_sizes, train_scores_mean, label=\"Training Error\")\n    plt.plot(train_sizes, test_scores_mean, label=\"Cross Validation Error\")\n    \n    plt.legend()\n    plt.grid()\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.xlabel('Train Sizes', fontsize = 14)\n    plt.ylabel('Score', fontsize = 14)\n    plt.tight_layout()","0da675e2":"from sklearn.linear_model import LogisticRegression","9dc44ff9":"log_reg1=LogisticRegression(max_iter=2500)\nlog_reg1.fit(X_train_sc,y_train)\npred_log1=log_reg1.predict(X_test_sc)\n\nprint('Confusion Matrix is\\n',confusion_matrix(y_test,pred_log1))\nprint('Accuracy is', accuracy_score(y_test,pred_log1))","728d11fb":"log_reg3=LogisticRegression(max_iter=2500)\nlog_reg3.fit(X_train,y_train)\npred_log3=log_reg3.predict(X_test)\n\nprint(\"Test Scores\")\nprint('Confusion Matrix is\\n',confusion_matrix(y_test,pred_log3))\nprint('Accuracy is\\n', accuracy_score(y_test,pred_log3))\n\n'''\npred_log_train=log_reg3.predict(X_train)\nprint(\"Train Scores\")\nprint('Confusion Matrix is\\n',confusion_matrix(y_train,pred_log_train))\nprint('Accuracy is', accuracy_score(y_train,pred_log_train))\n'''","49fa6c41":"log_reg2=LogisticRegression(max_iter=2500)\nlog_reg2.fit(X_train_minmax,y_train)\npred_log2=log_reg2.predict(X_test_minmax)\n\nprint('Confusion Matrix is\\n',confusion_matrix(y_test,pred_log2))\nprint('Accuracy is', accuracy_score(y_test,pred_log2))","364335bd":"plt.figure(figsize = (16,5))\ntitle = 'Logistic Regression Learning Curve'\nplotLearningCurves(X_train_minmax, y_train, log_reg2,title)\n","ee8a8081":"from sklearn.neighbors import KNeighborsClassifier","447d6417":"for k in range(10,18):\n  knn = KNeighborsClassifier(n_neighbors=k,metric='minkowski',p=2) \n  knn.fit(X_train_sc,y_train)\n  pred_knn = knn.predict(X_test_sc)\n\n  print(\"k=\",k)\n  print('Confusion Matrix is ',confusion_matrix(y_test,pred_knn))\n  print('Accuracy is', accuracy_score(y_test,pred_knn))\n  print('\\n')","feb34fa7":"knn = KNeighborsClassifier(n_neighbors=11,metric='minkowski',p=2) \nknn.fit(X_train_sc,y_train)\n\nknn_train = knn.predict(X_train_sc)\nknn_test= knn.predict(X_test_sc)\n\nprint(\"For Test\")\nprint('Confusion Matrix is \\n',confusion_matrix(y_test,knn_test))\nprint('Accuracy is', accuracy_score(y_test,knn_test))\nprint('\\n')\n\nprint(\"For Train\")\nprint('Confusion Matrix is\\n ',confusion_matrix(y_train,knn_train))\nprint('Accuracy is', accuracy_score(y_train,knn_train))\nprint('\\n')","ae15d72a":"plt.figure(figsize = (16,5))\ntitle = 'kNeighbours Learning Curve'\nplotLearningCurves(X_train, y_train, knn,title)","c4769a0c":"from sklearn.tree import DecisionTreeClassifier","e3334986":"for d in range(20,30):\n  dtc = DecisionTreeClassifier(criterion='entropy', max_depth=d,max_leaf_nodes=1000)\n  dtc.fit(X_train,y_train)\n  pred_dtc=dtc.predict(X_test)\n  print(\"d=\",d)\n  print(accuracy_score(y_test,pred_dtc))","864018e0":"dtc_best=DecisionTreeClassifier(criterion='entropy', max_depth=25,max_leaf_nodes=1000)\ndtc_best.fit(X_train,y_train)\n#pred_dtc=dtc.predict(X_test)\nplt.figure(figsize = (16,5))\ntitle = 'Decision Tree Learning Curve'\nplotLearningCurves(X_train, y_train, dtc_best,title)","e8767225":"from sklearn.ensemble import RandomForestClassifier","a4ea3ba1":"rfc = RandomForestClassifier(n_estimators=40, criterion='entropy', max_depth=40,max_leaf_nodes=4100)\n\nrfc.fit(X_train_sc, y_train)\n\npred_rfc = rfc.predict(X_test_sc)\nrfc_train= rfc.predict(X_train_sc)\nprint('Test Score:',accuracy_score(y_test,pred_rfc))\nprint('Train Score:',accuracy_score(y_train,rfc_train))\n\nprint('Confusion Matrix for test set  \\n',confusion_matrix(y_test,pred_rfc))\n\n#0.9477466379221846\n#0.9887918518192618","732ac27e":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve'\nplotLearningCurves(X_train, y_train, rfc,title)","954394db":"Customers of age group between 38 to 60 are more satisfied than customers of other age group.","b976ba3d":"## Decision Tree","dc29081f":"We can see that as train sizes increases cross validation score and training score are converging. But still there is some deviation between them.","a1eb7732":"## KNeighbours Classifier","4a963f20":"## Random Forest","aa1bb358":"In our data, number of both satisfied and dissatisfied cutomer are almosrt equal. So, our datasetr is balanced.","5d1143a6":"The factors like Flight Distance, Departure\/Arrival time convenient,Gate location,Departure Delay in Minutes and Arrival Delay in Minutes have very low impact on customer satisfaction. So, we are going to drop those columns to reduce model complexity.","a215622a":"## Model Selection","05c43958":"# Airlines Customer satisfaction\n\nThis data given by an airline organization. The actual name of the company is not given due to various purposes that's why the name Invistico airlines.\n\nThe dataset consists of the details of customers who have already flown with them. The feedback of the customers on various context and their flight data has been consolidated.\n\nThe main purpose of this dataset is to predict whether a future customer would be satisfied with their service given the details of the other parameters values.\n\nAlso the airlines need to know on which aspect of the services offered by them have to be emphasized more to generate more satisfied customers.\n\nDataset: https:\/\/www.kaggle.com\/sjleshrac\/airlines-customer-satisfaction\/","23817a47":"There are some null values in the columbn 'Arrival Delay in Minutes'.","bb3fa6ea":"## Conclusion\n\nIn our proble to classify customers as satisfied or dissatisfied, best accuracy was achieved using RandomForest Classifier. The best train score and test score achieved are 0.98 and 0.95 respectively. ","a38daf93":"As train size increase, trainining score and cross validation score are converging which means less deviation in accuracy.","2300545a":"Rows containing null values are dropped because there are few such rows in compared to total numvber of entries.","47c52bce":"Knn algortihm performed best when value of k_neighjbours equals 11. So let's find the model's performance on both training and test sets.\nPerformance was bettwe with scaled data scaled using StandardScaler.","ce56fe12":"Sacled data using MinMax scaling performed better than other scaling methods and unscaled data.","d46f538a":"From the abovce charts, we can conbclude that:\n* Comparitively, female customers are more satisfied than male customers.\n* Loyal Customers are more satisfied than disloyal ones.\n* People who travel for business purpose are more satisfied than ones who travel for personal purpose.\n* More number of people travel in Business class and are also comparitively more satisfied than customers travelling in economy or economy plus class.","6ffd2fc5":"Decision Tree classifier performed best when max_depth is set to 25, max_leaf_nodes to 1000 and using entropy as criterion. ","187c0211":"## EDA and Visualization","7a30708a":"## Importing Libraries and Dataset","4c773c1e":"## Logistic Regression","c7632548":"Cross validation score is increasing with increase in train size and also converging with training score. It means our model is learning well."}}