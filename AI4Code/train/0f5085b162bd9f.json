{"cell_type":{"26de2870":"code","abafd994":"code","9db372a1":"code","915c5fa5":"code","b3997758":"code","ea4ac09f":"code","bea3beef":"code","193ded88":"code","26d5143e":"code","89ed0820":"code","c64b5d73":"code","9286af7c":"code","7c33555c":"code","482f5015":"code","df82ba35":"code","e01f058b":"code","b4ace58c":"code","89f52d21":"code","ea028836":"code","30535230":"code","0b19bb2c":"code","5e014f74":"code","ebff8874":"code","0162cdc2":"code","bcf8dff0":"code","f26834ed":"code","66bd06c5":"markdown","94934c42":"markdown","45123d14":"markdown","9760542f":"markdown","ef3a2651":"markdown","6780066a":"markdown","0d7ab662":"markdown","635cf9ff":"markdown","c174577b":"markdown","55802da3":"markdown"},"source":{"26de2870":"import numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, MeanShift, estimate_bandwidth, SpectralClustering\nfrom sklearn.cluster import AgglomerativeClustering, OPTICS, cluster_optics_dbscan, Birch, MiniBatchKMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn import metrics\nfrom sklearn.mixture import GaussianMixture\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","abafd994":"# Read dataset\n\ndf = pd.read_csv(\"..\/input\/iris-flower-dataset\/IRIS.csv\")\ndf.shape","9db372a1":"df.sample(5)","915c5fa5":"df.groupby('species').size().plot.bar()\nplt.show()","b3997758":"X = df.copy()\nX = X.drop('species', axis=1)\nX.describe()","ea4ac09f":"# Normalize X\n\nmms = MinMaxScaler()\nmms.fit(X)\nXnorm = mms.transform(X)\nXnorm.shape","bea3beef":"# Not knowing the number of clusters (3) we try a range such 1,10\n# For the ELBOW method check with and without init='k-means++'\n\nSum_of_squared_distances = []\nfor k in range(1,10):\n    km = KMeans(n_clusters=k, init='k-means++')\n    km = km.fit(Xnorm)\n    Sum_of_squared_distances.append(km.inertia_)","193ded88":"plt.plot(range(1,10), Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","26d5143e":"# Knowing from the ELBOW method that k=3 ...\n\nkmeans3 = KMeans(n_clusters=3, init='k-means++').fit(Xnorm) \n\nKM_clustered = Xnorm.copy()\nKM_clustered = pd.DataFrame(KM_clustered)\nKM_clustered.loc[:,'Cluster'] = kmeans3.labels_ # append labels to points\n\nframes = [df['species'], KM_clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\nprint(result.shape)\nresult.sample(5)\n","89ed0820":"for ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","c64b5d73":"# Check performance of classification to 3 clusters\n\nprint('K-Means performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","9286af7c":"# Compute DBSCAN\n# played with eps and min samples ... till I got num clustrers = 3 and lowest number of noise (114 ?!?)\n\ndb = DBSCAN(eps=0.078).fit(Xnorm)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)\n","7c33555c":"af = AffinityPropagation(preference=-3).fit(Xnorm)\ncluster_centers_indices = af.cluster_centers_indices_\nlabels = af.labels_\n\nn_clusters_ = len(cluster_centers_indices)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = af.labels_ # append labels to points\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","482f5015":"# Check performance of classification to 3 clusters\n\nprint('Affinity propagation performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","df82ba35":"# Compute clustering with MeanShift\n\n# The following bandwidth can be automatically detected using\nbandwidth = estimate_bandwidth(Xnorm, quantile=0.2) # Manually set the quantile to get num clusters = 3\n\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(Xnorm)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = ms.labels_ # append labels to points\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)","e01f058b":"for ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","b4ace58c":"# Check performance of classification to 3 clusters\n\nprint('Mean shift performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","89f52d21":"# Compute clustering with SpectralClustering\n\nsc = SpectralClustering(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = ms.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","ea028836":"# Check performance of classification to 3 clusters\n\nprint('Spectral clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","30535230":"# Agglomerative Clustering\n\nsc = AgglomerativeClustering(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","0b19bb2c":"# Check performance of classification to 3 clusters\n\nprint('Agglomerative clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","5e014f74":"# Gaussian Mixture clustering\n\nsc = GaussianMixture(n_components=3, covariance_type='full')\ny_pred = sc.fit_predict(Xnorm)\nprint(\"number of estimated clusters : %d\" % len(set(y_pred)))\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = y_pred # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])\n","ebff8874":"# Check performance of classification to 3 clusters\n\nprint('Gaussian mixture clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","0162cdc2":"sc = Birch(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\n","bcf8dff0":"\n# Mini Batch K-Means Clustering\n\nsc = MiniBatchKMeans(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","f26834ed":"# Check performance of classification to 3 clusters\n\nprint('Mini Batch K-Means clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct\/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","66bd06c5":"# Mean Shift","94934c42":"# Spectral Clustering","45123d14":"# Assigning a label to each cluster\n* As there's no relation between a cluster number and the true label we need to map a cluster to the one label which appears most in that cluster\n\n* These corrected predicted labels are needed below to calculate model performance vs the the true labels","9760542f":"# ELBOW method for finding the optimal # of clusters k","ef3a2651":"# Gaussian mixture\n\n* Tried w covariance_type='tied' acc = 0.9, 'full' DEFAULT acc = 0.97,  'diag' acc = 0.93,  'spherical' acc = 0.89","6780066a":"# Affinity Propagation","0d7ab662":"# Birch","635cf9ff":"# DBSCAN","c174577b":"# Compare various clustering algorithms on the iris dataset\n\n* **k-Means and Mini Batch k-Means**\naccuracy: 0.89 ... \nsilhouette:  0.696\n\n* **DBSCAN and Optics**\naccuracy: with 3 clusters there are 114 outliers with DBSCAN and similar w OPTICS (?!)\n\n* **Affinity Propagation**\naccuracy: 0.90 ... \nsilhouette:  0.696\n\n* **Mean Shift**\naccuracy: 0.79 ... \nsilhouette:  0.635\n\n* **Spectral Clustering**\naccuracy: 0.84 ... \nsilhouette:  0.661\n\n* **Agglomerative Clustering**\naccuracy: 0.89 ... \nsilhouette:  0.688\n\n* **Gaussian Mixture Clustering**\naccuracy: 0.97 ... \nsilhouette:  0.606\n\n* **Birch**\nfinds only 2 clusters\n\n\n* Based on https:\/\/scikit-learn.org\/stable\/modules\/clustering.html\n","55802da3":"# Mini Batch K-Means"}}