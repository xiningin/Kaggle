{"cell_type":{"35382290":"code","ceb45c16":"code","928ece5f":"code","83687a9f":"code","bb0b2d36":"code","af059d09":"code","3f22d34d":"code","fb353417":"code","27774550":"code","4686bd04":"code","22204da9":"code","99c8d74d":"code","6daf918e":"code","0150335e":"code","469a4de1":"code","1d9c55d8":"code","23439073":"code","614e4e9f":"code","ace30b3e":"code","918bf717":"code","d7cde360":"code","e5eac289":"code","3ea332c3":"code","0b24f709":"code","ef64596c":"code","f9349598":"code","9b4bc41b":"code","d2ad3831":"code","436bdd04":"code","b83abb16":"code","c4c093ce":"markdown"},"source":{"35382290":"# \u5b57\u6bb5\t\u542b\u4e49\n# SK_ID_CURR\t\u6b64\u6b21\u7533\u8bf7\u7684ID\n# TARGET\t\u7533\u8bf7\u4eba\u672c\u6b21\u7533\u8bf7\u7684\u8fd8\u6b3e\u98ce\u9669\uff1a1-\u98ce\u9669\u8f83\u9ad8\uff1b0-\u98ce\u9669\u8f83\u4f4e\n# NAME_CONTRACT_TYPE\t\u8d37\u6b3e\u7c7b\u578b\uff1acash(\u73b0\u91d1)\u8fd8\u662frevolving(\u5468\u8f6c\u91d1\uff0c\u4e00\u6b21\u7533\u8bf7\uff0c\u591a\u6b21\u5faa\u73af\u63d0\u53d6)\n# CODE_GENDER\t\u7533\u8bf7\u4eba\u6027\u522b\n# FLAG_OWN_CAR\t\u7533\u8bf7\u4eba\u662f\u5426\u6709\u8f66\n# FLAG_OWN_REALTY\t\u7533\u8bf7\u4eba\u662f\u5426\u6709\u623f\n# CNT_CHILDREN\t\u7533\u8bf7\u4eba\u5b50\u5973\u4e2a\u6570\n# AMT_INCOME_TOTAL\t\u7533\u8bf7\u4eba\u6536\u5165\u72b6\u51b5\n# AMT_CREDIT\t\u6b64\u6b21\u7533\u8bf7\u7684\u8d37\u6b3e\u91d1\u989d\n# AMT_ANNUITY\t\u8d37\u6b3e\u5e74\u91d1\n# AMT_GOODS_PRICE\t\u5982\u679c\u662f\u6d88\u8d39\u8d37\u6b3e\uff0c\u6539\u5b57\u6bb5\u8868\u793a\u5546\u54c1\u7684\u5b9e\u9645\u4ef7\u683c\n# NAME_TYPE_SUITE\t\u7533\u8bf7\u4eba\u6b64\u6b21\u7533\u8bf7\u7684\u966a\u540c\u4eba\u5458\n# NAME_INCOME_TYPE\t\u7533\u8bf7\u4eba\u6536\u5165\u7c7b\u578b\n# NAME_EDUCATION_TYPE\t\u7533\u8bf7\u4eba\u53d7\u6559\u80b2\u7a0b\u5ea6\n# NAME_FAMILY_STATUS\t\u7533\u8bf7\u4eba\u5a5a\u59fb\u72b6\u51b5\n# NAME_HOUSING_TYPE\t\u7533\u8bf7\u4eba\u5c45\u4f4f\u72b6\u51b5\uff08\u79df\u623f\uff0c\u5df2\u8d2d\u623f\uff0c\u548c\u7236\u6bcd\u4e00\u8d77\u4f4f\u7b49\uff09\n# REGION_POPULATION_RELATIVE\t\u7533\u8bf7\u4eba\u5c45\u4f4f\u5730\u4eba\u53e3\u5bc6\u5ea6\uff0c\u5df2\u6807\u51c6\u5316\n# DAYS_BIRTH\t\u7533\u8bf7\u4eba\u51fa\u751f\u65e5\uff08\u8ddd\u79bb\u7533\u8bf7\u5f53\u65e5\u7684\u5929\u6570\uff0c\u8d1f\u503c\uff09\n# DAYS_EMPLOYED\t\u7533\u8bf7\u4eba\u5f53\u524d\u5de5\u4f5c\u7684\u5de5\u4f5c\u5e74\u9650\uff08\u8ddd\u79bb\u7533\u8bf7\u5f53\u65e5\u7684\u5929\u6570\uff0c\u8d1f\u503c\uff09\n# DAYS_REGISTRATION\t\u7533\u8bf7\u4eba\u6700\u8fd1\u4e00\u6b21\u4fee\u6539\u6ce8\u518c\u4fe1\u606f\u7684\u65f6\u95f4\uff08\u8ddd\u79bb\u7533\u8bf7\u5f53\u65e5\u7684\u5929\u6570\uff0c\u8d1f\u503c\uff09\n# DAYS_ID_PUBLISH\t\u7533\u8bf7\u4eba\u6700\u8fd1\u4e00\u6b21\u4fee\u6539\u7533\u8bf7\u8d37\u6b3e\u7684\u8eab\u4efd\u8bc1\u660e\u6587\u4ef6\u7684\u65f6\u95f4\uff08\u8ddd\u79bb\u7533\u8bf7\u5f53\u65e5\u7684\u5929\u6570\uff0c\u8d1f\u503c\uff09\n# FLAG_MOBIL\t\u7533\u8bf7\u4eba\u662f\u5426\u63d0\u4f9b\u4e2a\u4eba\u7535\u8bdd\uff081-yes\uff0c0-no\uff09\n# FLAG_EMP_PHONE\t\u7533\u8bf7\u4eba\u662f\u5426\u63d0\u4f9b\u5bb6\u5ead\u7535\u8bdd\uff081-yes\uff0c0-no\uff09\n# FLAG_WORK_PHONE\t\u7533\u8bf7\u4eba\u662f\u5426\u63d0\u4f9b\u5de5\u4f5c\u7535\u8bdd\uff081-yes\uff0c0-no\uff09\n# FLAG_CONT_MOBILE\t\u7533\u8bf7\u4eba\u4e2a\u4eba\u7535\u8bdd\u662f\u5426\u80fd\u62e8\u901a\uff081-yes\uff0c0-no\uff09\n# FLAG_EMAIL\t\u7533\u8bf7\u4eba\u662f\u5426\u63d0\u4f9b\u7535\u5b50\u90ae\u7bb1\uff081-yes\uff0c0-no\uff09\n# OCCUPATION_TYPE\t\u7533\u8bf7\u4eba\u804c\u52a1\n# REGION_RATING_CLIENT\t\u672c\u516c\u53f8\u5bf9\u7533\u8bf7\u4eba\u5c45\u4f4f\u533a\u57df\u7684\u8bc4\u5206\u7b49\u7ea7\uff081,2,3\uff09\n# REGION_RATING_CLIENT_W_CITY\t\u5728\u8003\u8651\u6240\u5728\u57ce\u5e02\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u516c\u53f8\u5bf9\u7533\u8bf7\u4eba\u5c45\u4f4f\u533a\u57df\u7684\u8bc4\u5206\u7b49\u7ea7\uff081,2,3\uff09\n# WEEKDAY_APPR_PROCESS_START\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u65e5\u662f\u661f\u671f\u51e0\n# HOUR_APPR_PROCESS_START\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u7684hour\n# REG_REGION_NOT_LIVE_REGION\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u6c38\u4e45\u5730\u5740\u548c\u8054\u7cfb\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u533a\u57df\u7ea7\u522b\u7684\uff09\n# REG_REGION_NOT_WORK_REGION\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u6c38\u4e45\u5730\u5740\u548c\u5de5\u4f5c\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u533a\u57df\u7ea7\u522b\u7684\uff09\n# LIVE_REGION_NOT_WORK_REGION\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u8054\u7cfb\u5730\u5740\u548c\u5de5\u4f5c\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u533a\u57df\u7ea7\u522b\u7684\uff09\n# REG_CITY_NOT_LIVE_CITY\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u6c38\u4e45\u5730\u5740\u548c\u8054\u7cfb\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u57ce\u5e02\u7ea7\u522b\u7684\uff09\n# REG_CITY_NOT_WORK_CITY\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u6c38\u4e45\u5730\u5740\u548c\u5de5\u4f5c\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u57ce\u5e02\u7ea7\u522b\u7684\uff09\n# LIVE_CITY_NOT_WORK_CITY\t\u7533\u8bf7\u4eba\u63d0\u4f9b\u7684\u7684\u8054\u7cfb\u5730\u5740\u548c\u5de5\u4f5c\u5730\u5740\u662f\u5426\u5339\u914d\uff081-\u4e0d\u5339\u914d\uff0c2-\u5339\u914d\uff0c\u57ce\u5e02\u7ea7\u522b\u7684\uff09\n# ORGANIZATION_TYPE\t\u7533\u8bf7\u4eba\u5de5\u4f5c\u6240\u5c5e\u7ec4\u7ec7\u7c7b\u578b\n# EXT_SOURCE_1\t\u5916\u90e8\u6570\u636e\u6e901\u7684\u6807\u51c6\u5316\u8bc4\u5206\n# EXT_SOURCE_2\t\u5916\u90e8\u6570\u636e\u6e902\u7684\u6807\u51c6\u5316\u8bc4\u5206\n# EXT_SOURCE_3\t\u5916\u90e8\u6570\u636e\u6e903\u7684\u6807\u51c6\u5316\u8bc4\u5206\n# APARTMENTS_AVG <----> EMERGENCYSTATE_MODE\t\u7533\u8bf7\u4eba\u5c45\u4f4f\u73af\u5883\u5404\u9879\u6307\u6807\u7684\u6807\u51c6\u5316\u8bc4\u5206\n# OBS_30_CNT_SOCIAL_CIRC LE <----> DEF_60_CNT_SOCIAL_CIRCLE\t\u8fd9\u90e8\u5206\u5b57\u6bb5\u542b\u4e49\u6ca1\u770b\u61c2\n# DAYS_LAST_PHONE_CHANGE\t\u7533\u8bf7\u4eba\u6700\u8fd1\u4e00\u6b21\u4fee\u6539\u624b\u673a\u53f7\u7801\u7684\u65f6\u95f4\uff08\u8ddd\u79bb\u7533\u8bf7\u5f53\u65e5\u7684\u5929\u6570\uff0c\u8d1f\u503c\uff09\n# FLAG_DOCUMENT_2 <----> FLAG_DOCUMENT_21\t\u7533\u8bf7\u4eba\u662f\u5426\u989d\u5916\u63d0\u4f9b\u4e86\u6587\u4ef62,3,4. . .21\n# AMT_REQ_CREDIT_BUREAU_HOUR\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d1\u4e2a\u5c0f\u65f6\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570\n# AMT_REQ_CREDIT_BUREAU_DAY\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d\u4e00\u5929\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570\n# AMT_REQ_CREDIT_BUREAU_WEEK\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d\u4e00\u5468\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570\n# AMT_REQ_CREDIT_BUREAU_MONTH\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d\u4e00\u4e2a\u6708\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570\n# AMT_REQ_CREDIT_BUREAU_QRT\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d\u4e00\u4e2a\u5b63\u5ea6\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570\n# AMT_REQ_CREDIT_BUREAU_YEAR\t\u7533\u8bf7\u4eba\u53d1\u8d77\u7533\u8bf7\u524d\u4e00\u5e74\u4ee5\u5185\uff0c\u88ab\u67e5\u8be2\u5f81\u4fe1\u7684\u6b21\u6570","ceb45c16":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline ","928ece5f":"PATH=\"..\/input\/home-credit-default-risk\"","83687a9f":"application_train = pd.read_csv(PATH+\"\/application_train.csv\")\napplication_test = pd.read_csv(PATH+\"\/application_test.csv\")\nbureau = pd.read_csv(PATH+\"\/bureau.csv\")\nbureau_balance = pd.read_csv(PATH+\"\/bureau_balance.csv\")\ncredit_card_balance = pd.read_csv(PATH+\"\/credit_card_balance.csv\")\ninstallments_payments = pd.read_csv(PATH+\"\/installments_payments.csv\")\nprevious_application = pd.read_csv(PATH+\"\/previous_application.csv\")\nPOS_CASH_balance = pd.read_csv(PATH+\"\/POS_CASH_balance.csv\")","bb0b2d36":"bureau[['SK_ID_CURR','DAYS_CREDIT_UPDATE', 'CREDIT_ACTIVE', 'DAYS_CREDIT', 'DAYS_CREDIT_ENDDATE']]","af059d09":"print(\"application_train -  rows:\",application_train.shape[0],\" columns:\", application_train.shape[1])\nprint(\"application_test -  rows:\",application_test.shape[0],\" columns:\", application_test.shape[1])\nprint(\"bureau -  rows:\",bureau.shape[0],\" columns:\", bureau.shape[1])\nprint(\"bureau_balance -  rows:\",bureau_balance.shape[0],\" columns:\", bureau_balance.shape[1])\nprint(\"credit_card_balance -  rows:\",credit_card_balance.shape[0],\" columns:\", credit_card_balance.shape[1])\nprint(\"installments_payments -  rows:\",installments_payments.shape[0],\" columns:\", installments_payments.shape[1])\nprint(\"previous_application -  rows:\",previous_application.shape[0],\" columns:\", previous_application.shape[1])\nprint(\"POS_CASH_balance -  rows:\",POS_CASH_balance.shape[0],\" columns:\", POS_CASH_balance.shape[1])","3f22d34d":"sns.boxplot(x='TARGET', y='EXT_SOURCE_1', data=application_train)","fb353417":"sns.boxplot(x='TARGET', y='EXT_SOURCE_2', data=application_train)","27774550":"sns.boxplot(x='TARGET', y='EXT_SOURCE_3', data = application_train)","4686bd04":"sns.barplot(x='TARGET', y='REGION_POPULATION_RELATIVE', data=application_train)","22204da9":"temp = application_train[\"TARGET\"].value_counts()\ndf = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values\n                  })\nplt.figure(figsize = (6,6))\nplt.title('Application loans repayed - train dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x='labels', y=\"values\", data=df)\nlocs, labels = plt.xticks()\nplt.show()","99c8d74d":"df","6daf918e":"def plot_stats(feature, label_rotation=False, horizontal_layout=True):\n    temp = application_train[feature].value_counts()\n    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})\n\n    # Calculate the percentage of target=1 per category value\n    cat_perc = application_train[[feature, 'TARGET']].groupby([feature], as_index=False).mean()\n    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n    \n    if horizontal_layout:\n        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n    else:\n        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n    sns.set_color_codes(\"pastel\")\n    s = sns.barplot(ax=ax1, x=feature, y=\"Number of contracts\", data=df1)\n    \n    if label_rotation:\n        s.set_xticklabels(s.get_xticklabels(), rotation=90)\n    s = sns.barplot(ax=ax2, x=feature, y='TARGET', order=cat_perc[feature], data=cat_perc)\n    \n    if label_rotation:\n        s.set_xticklabels(s.get_xticklabels(), rotation=90)\n    plt.ylabel('Percent of target with value 1 [%]', fontsize=10)\n    plt.tick_params(axis='both', which='major', labelsize=10)\n    plt.show()","0150335e":"plot_stats('NAME_CONTRACT_TYPE')","469a4de1":"plot_stats('CODE_GENDER')","1d9c55d8":"plot_stats('FLAG_OWN_CAR')","23439073":"plot_stats('NAME_FAMILY_STATUS', True, True)","614e4e9f":"import numpy as np\nimport pandas as pd\nimport gc\nimport time\nimport re\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","ace30b3e":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","918bf717":"# One-hot encoding for categorical columns with get_dummies\ndef one_hot_encoder(df, nan_as_category = True):\n    original_columns = list(df.columns)\n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n    new_columns = [c for c in df.columns if c not in original_columns]\n    return df, new_columns","d7cde360":"# Preprocess application_train.csv and application_test.csv\ndef application_train_test(num_rows = None, nan_as_category = False):\n    # Read data and merge\n    df = pd.read_csv(PATH+'\/application_train.csv', nrows= num_rows)\n    test_df = pd.read_csv(PATH+'\/application_test.csv', nrows= num_rows)\n    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n    df = df.append(test_df).reset_index()\n    \n    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n    df = df[df['CODE_GENDER'] != 'XNA']\n    \n    # \u662f\u5426\u63d0\u4f9b\u5f80\u989d\u5916\u7684\u6587\u6863\u8d44\u6599\u6807\u8bc6\n    docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n    \n    # \u4e2a\u4eba\u751f\u6d3b\u4fe1\u606f\u7684\u8d44\u6599\u6807\u8bc6\n    live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n    \n    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n\n    # \u6309\u7167\u5de5\u4f5c\u7c7b\u578b\u8ba1\u7b97\u6bcf\u7c7b\u5de5\u4f5c\u7684\u6536\u5165\u4e2d\u4f4d\u6570\n    inc_by_org = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n    df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(inc_by_org)\n    \n    # \u8d37\u6b3e\u7684\u4fe1\u7528\u989d\u5ea6 \/ \u8d37\u6b3e\u5e74\u91d1\n    df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_ANNUITY']\n    \n    # \u8d37\u6b3e\u7684\u4fe1\u7528\u989d\u5ea6 \/ \u8d37\u6b3e\u5546\u54c1\u4ef7\u683c\n    df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_GOODS_PRICE']\n    \n    # \u6587\u6863\u8d44\u6599\u7684\u5cf0\u5ea6\n    df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n    # \u751f\u6d3b\u8d44\u6599\u7684\u6c42\u548c\n    df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n    \n    # \u5e73\u5747\u6bcf\u4e2a\u5b69\u5b50\u5e73\u5206\u7684\u6536\u5165\n    df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] \/ (1 + df['CNT_CHILDREN'])\n    \n    # DAYS_EMPLOYED\u4e3a\u7533\u8bf7\u8d37\u6b3e\u524d\u5f00\u59cb\u5f53\u524d\u5de5\u4f5c\u7684\u65f6\u95f4\n    df['NEW_EMPLOY_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] \/ df['DAYS_BIRTH']\n    \n    # \u4fe1\u7528\u5c40\u4fe1\u7528\u5e74\u91d1 \/ \u603b\u6536\u5165\n    df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] \/ (1 + df['AMT_INCOME_TOTAL'])\n    \n    df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n    df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n    df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n    df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n    \n    df['NEW_CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_BIRTH']\n    df['NEW_CAR_TO_EMPLOY_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_EMPLOYED']\n    df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] \/ df['DAYS_BIRTH']\n    df['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = df['DAYS_LAST_PHONE_CHANGE'] \/ df['DAYS_EMPLOYED']\n    df['NEW_CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_INCOME_TOTAL']\n    \n    # Categorical features with Binary encode (0 or 1; two categories)\n    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n    # Categorical features with One-Hot encode\n    df, cat_cols = one_hot_encoder(df, nan_as_category)\n    dropcolum=['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4',\n    'FLAG_DOCUMENT_5','FLAG_DOCUMENT_6','FLAG_DOCUMENT_7',\n    'FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', \n    'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13',\n    'FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16',\n    'FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19',\n    'FLAG_DOCUMENT_20','FLAG_DOCUMENT_21']\n    df= df.drop(dropcolum,axis=1)\n    del test_df\n    gc.collect()\n    return df","e5eac289":"# Preprocess bureau.csv and bureau_balance.csv\ndef bureau_and_balance(num_rows = None, nan_as_category = True):\n    bureau = pd.read_csv(PATH+'\/bureau.csv', nrows = num_rows)\n    bb = pd.read_csv(PATH+'\/bureau_balance.csv', nrows = num_rows)\n    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n    \n    # Bureau balance: Perform aggregations and merge with bureau.csv\n    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n    for col in bb_cat:\n        bb_aggregations[col] = ['mean']\n    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n    del bb, bb_agg\n    gc.collect()\n    \n    # Bureau and bureau_balance numeric features\n    num_aggregations = {\n        'DAYS_CREDIT': [ 'mean', 'var'],\n        'DAYS_CREDIT_ENDDATE': [ 'mean'],\n        'DAYS_CREDIT_UPDATE': ['mean'],\n        'CREDIT_DAY_OVERDUE': ['mean'],\n        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n        'AMT_CREDIT_SUM': [ 'mean', 'sum'],\n        'AMT_CREDIT_SUM_DEBT': [ 'mean', 'sum'],\n        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n        'AMT_ANNUITY': ['max', 'mean'],\n        'CNT_CREDIT_PROLONG': ['sum'],\n        'MONTHS_BALANCE_MIN': ['min'],\n        'MONTHS_BALANCE_MAX': ['max'],\n        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n    }\n    # Bureau and bureau_balance categorical features\n    cat_aggregations = {}\n    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n    \n    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n    \n    # Bureau: Active credits - using only numerical aggregations\n    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n    del active, active_agg\n    gc.collect()\n    \n    # Bureau: Closed credits - using only numerical aggregations\n    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n    del closed, closed_agg, bureau\n    gc.collect()\n    return bureau_agg","3ea332c3":"# Preprocess previous_applications.csv\ndef previous_applications(num_rows = None, nan_as_category = True):\n    prev = pd.read_csv(PATH+'\/previous_application.csv', nrows = num_rows)\n    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n    \n    # Days 365.243 values -> nan\n    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    \n    # Add feature: value ask \/ value received percentage\n    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] \/ prev['AMT_CREDIT']\n    \n    # Previous applications numeric features\n    num_aggregations = {\n        'AMT_ANNUITY': [ 'max', 'mean'],\n        'AMT_APPLICATION': [ 'max','mean'],\n        'AMT_CREDIT': [ 'max', 'mean'],\n        'APP_CREDIT_PERC': [ 'max', 'mean'],\n        'AMT_DOWN_PAYMENT': [ 'max', 'mean'],\n        'AMT_GOODS_PRICE': [ 'max', 'mean'],\n        'HOUR_APPR_PROCESS_START': [ 'max', 'mean'],\n        'RATE_DOWN_PAYMENT': [ 'max', 'mean'],\n        'DAYS_DECISION': [ 'max', 'mean'],\n        'CNT_PAYMENT': ['mean', 'sum'],\n    }\n    \n    # Previous applications categorical features\n    cat_aggregations = {}\n    for cat in cat_cols:\n        cat_aggregations[cat] = ['mean']\n    \n    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n    \n    # Previous Applications: Approved Applications - only numerical features\n    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n    \n    # Previous Applications: Refused Applications - only numerical features\n    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n    \n    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n    del refused, refused_agg, approved, approved_agg, prev\n    gc.collect()\n    return prev_agg","0b24f709":"# Preprocess POS_CASH_balance.csv\ndef pos_cash(num_rows = None, nan_as_category = True):\n    pos = pd.read_csv(PATH+'\/POS_CASH_balance.csv', nrows = num_rows)\n    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n    # Features\n    aggregations = {\n        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n        'SK_DPD': ['max', 'mean'],\n        'SK_DPD_DEF': ['max', 'mean']\n    }\n    for cat in cat_cols:\n        aggregations[cat] = ['mean']\n    \n    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n    \n    # Count pos cash accounts\n    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n    del pos\n    gc.collect()\n    return pos_agg","ef64596c":"# Preprocess installments_payments.csv\ndef installments_payments(num_rows = None, nan_as_category = True):\n    ins = pd.read_csv(PATH+'\/installments_payments.csv', nrows = num_rows)\n    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n    \n    # Percentage and difference paid in each installment (amount paid and installment value)\n    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] \/ ins['AMT_INSTALMENT']\n    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n    \n    # Days past due and days before due (no negative values)\n    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n    # Features: Perform aggregations\n    aggregations = {\n        'NUM_INSTALMENT_VERSION': ['nunique'],\n        'DPD': ['max', 'mean', 'sum','min','std' ],\n        'DBD': ['max', 'mean', 'sum','min','std'],\n        'PAYMENT_PERC': [ 'max','mean',  'var','min','std'],\n        'PAYMENT_DIFF': [ 'max','mean', 'var','min','std'],\n        'AMT_INSTALMENT': ['max', 'mean', 'sum','min','std'],\n        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum','std'],\n        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum','std']\n    }\n    for cat in cat_cols:\n        aggregations[cat] = ['mean']\n    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n    # Count installments accounts\n    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n    del ins\n    gc.collect()\n    return ins_agg","f9349598":"# Preprocess credit_card_balance.csv\ndef credit_card_balance(num_rows = None, nan_as_category = True):\n    cc = pd.read_csv(PATH+'\/credit_card_balance.csv', nrows = num_rows)\n    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n    # General aggregations\n    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n    cc_agg = cc.groupby('SK_ID_CURR').agg([ 'max', 'mean', 'sum', 'var'])\n    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n    # Count credit card lines\n    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n    del cc\n    gc.collect()\n    return cc_agg","9b4bc41b":"# LightGBM GBDT with KFold or Stratified KFold\n# Parameters from Tilii kernel: https:\/\/www.kaggle.com\/tilii7\/olivier-lightgbm-parameters-by-bayesian-opt\/code\ndef kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n    # Divide in training\/validation and test data\n    train_df = df[df['TARGET'].notnull()]\n    test_df = df[df['TARGET'].isnull()]\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    del df\n    gc.collect()\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=47)\n    else:\n        folds = KFold(n_splits=num_folds, shuffle=True, random_state=47)\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n\n        # LightGBM parameters found by Bayesian optimization\n        clf = LGBMClassifier(\n            nthread=4,\n            #is_unbalance=True,\n            n_estimators=10000,\n            learning_rate=0.02,\n            num_leaves=32,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.04,\n            reg_lambda=0.073,\n            min_split_gain=0.0222415,\n            min_child_weight=40,\n            silent=-1,\n            verbose=-1,\n            #scale_pos_weight=11\n            )\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric= 'auc', verbose=1000, early_stopping_rounds=200)\n\n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] \/ folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n    # Write submission file and plot feature importance\n    if not debug:\n        test_df['TARGET'] = sub_preds\n        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index=False)\n    display_importances(feature_importance_df)\n    return feature_importance_df","d2ad3831":"# Display\/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances01.png')","436bdd04":"def main(debug = False):\n    num_rows = 10000 if debug else None\n    df = application_train_test(num_rows)\n    with timer(\"Process bureau and bureau_balance\"):\n        bureau = bureau_and_balance(num_rows)\n        print(\"Bureau df shape:\", bureau.shape)\n        df = df.join(bureau, how='left', on='SK_ID_CURR')\n        del bureau\n        gc.collect()\n    with timer(\"Process previous_applications\"):\n        prev = previous_applications(num_rows)\n        print(\"Previous applications df shape:\", prev.shape)\n        df = df.join(prev, how='left', on='SK_ID_CURR')\n        del prev\n        gc.collect()\n    with timer(\"Process POS-CASH balance\"):\n        pos = pos_cash(num_rows)\n        print(\"Pos-cash balance df shape:\", pos.shape)\n        df = df.join(pos, how='left', on='SK_ID_CURR')\n        del pos\n        gc.collect()\n    with timer(\"Process installments payments\"):\n        ins = installments_payments(num_rows)\n        print(\"Installments payments df shape:\", ins.shape)\n        df = df.join(ins, how='left', on='SK_ID_CURR')\n        del ins\n        gc.collect()\n    with timer(\"Process credit card balance\"):\n        cc = credit_card_balance(num_rows)\n        print(\"Credit card balance df shape:\", cc.shape)\n        df = df.join(cc, how='left', on='SK_ID_CURR')\n        del cc\n        gc.collect()\n    with timer(\"Run LightGBM with kfold\"):\n        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n        feat_importance = kfold_lightgbm(df, num_folds=7, stratified=False, debug=debug)","b83abb16":"if __name__ == \"__main__\":\n    submission_file_name = \"submission.csv\"\n    with timer(\"Full model run\"):\n        main()","c4c093ce":"# CODE WITH LIGHTGBM"}}