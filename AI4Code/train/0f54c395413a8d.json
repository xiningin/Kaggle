{"cell_type":{"3a3089ca":"code","3a3de122":"code","db50c390":"code","e6b6bf2c":"code","51ff1eb8":"code","9f510656":"code","4cc104c8":"code","aad58136":"code","bab0157a":"code","205c3521":"code","b710ccb6":"code","b02ce1d0":"code","14f04e9b":"code","e0b256d5":"code","07a354d7":"code","0729b081":"code","662123de":"code","7dd7927b":"code","5a510ebb":"markdown","e30e9db7":"markdown","3c72d073":"markdown","c9d5a6d1":"markdown","4b2ae689":"markdown","700b730b":"markdown","bc8a456b":"markdown","84271b37":"markdown","1b8f9359":"markdown","ee71f3c9":"markdown","f7adacf3":"markdown","91ab1dc1":"markdown","3d13bba7":"markdown"},"source":{"3a3089ca":"import numpy as np\nimport tensorflow as tf\nimport keras \nfrom keras import layers\nfrom keras.layers import LeakyReLU, Dropout, BatchNormalization, Dense, UpSampling2D, MaxPool2D, Conv2D,Reshape,Activation\nimport time\nimport matplotlib.pyplot as plt\nimport os","3a3de122":"# To generate GIFs\n!pip install -q imageio","db50c390":"latent_dim = 100\nBATCH_SIZE = 64\n\nfrom keras.datasets import mnist\n(x_train, _),(y_train, _) = mnist.load_data()\n#concatenate data\ndata = np.concatenate([x_train, y_train])\ndata = data.reshape(data.shape[0],28,28,1).astype('float32')\n#normalize data to [-1,1]\ndata = (data - data.max() \/ 2) \/ (data.max()\/2)\n#shuffling our data \ndataset = tf.data.Dataset.from_tensor_slices(data)\ndataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)","e6b6bf2c":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n","51ff1eb8":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(28*28*1, use_bias=False, input_shape=(latent_dim,)))\n    model.add(layers.Reshape((28,28,1)))\n    model.add(layers.Conv2D(filters = 128, kernel_size = (2,2), strides = 2 ))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2D(filters = 256, kernel_size = (2,2), strides = 2 ))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n   \n    model.add(layers.Conv2DTranspose(filters = 256, kernel_size = (2,2), strides = 2))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.2))\n    \n    model.add(layers.Conv2DTranspose(filters = 128, kernel_size = (2,2), strides = 2))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.2))\n\n\n    model.add(layers.Conv2D(1,(2,2),1, padding='same', use_bias=False, activation='tanh'))\n  \n\n    return model\n\n    ","9f510656":"discriminator = make_discriminator_model()\ndiscriminator.summary()\n\n","4cc104c8":"generator = make_generator_model()\ngenerator.summary()","aad58136":"noise = np.random.normal(-1,1,(1,100))\nimg = generator(noise)\nplt.imshow(img[0,:,:,0])","bab0157a":"print('Predicted value: ', discriminator.predict(generator.predict(noise)))","205c3521":"#loss function\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n# optimizer\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","b710ccb6":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_avg_loss = 0.5 * (real_loss + fake_loss)\n    return total_avg_loss","b02ce1d0":"def train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, latent_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n    \n     \n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","14f04e9b":"test_image = tf.random.normal([25,100])\ndef plot_and_save_generated_images(epoch):\n  plt.figure(figsize = (10,10))\n  img = generator(test_image)\n  for i in range(img.shape[0]):\n    plt.subplot(5,5,i+1)\n    \n    plt.imshow(img[i,:,:,0])\n    \n    plt.axis('off')\n  plt.savefig('images_{:01d}.png'.format(epoch))  ","e0b256d5":"\ndef train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n   \n    for image_batch in dataset:\n      \n      train_step(image_batch)\n\n\n    print ('Epoch:{}   Time:{} sec \\n'.format(epoch + 1, np.round((time.time()-start), 2)))\n   \n    plot_and_save_generated_images(epoch+15)   \n    \n    \n    \n","07a354d7":"EPOCHS = 15\ntrain(dataset, EPOCHS)","0729b081":"import imageio\nimport glob\ngif_file = 'dcgan.gif'\n\nwith imageio.get_writer(gif_file, mode='I') as writer:\n  filenames = glob.glob('images_*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)","662123de":"!pip install -q git+https:\/\/github.com\/tensorflow\/docs","7dd7927b":"import tensorflow_docs.vis.embed as embed\nembed.embed_file(gif_file)","5a510ebb":"## To plot and save the generated images","e30e9db7":"# Thank You","3c72d073":"# Training Funcion defination","c9d5a6d1":"# Defining Loss and Optimizers\n\n#### I have defined binary cross entropy as loss function, which will be common loss function for both models generator and discriminator \n#### Similarly I have used Adam as optimizer for both generator and discriminator","4b2ae689":"## Importing necessary libraries","700b730b":"### Let's visual some random image generated by generator","bc8a456b":"## Training our model ","84271b37":"# Generator","1b8f9359":"# Load data\nHere, I have load data and concatenate both training and testin data. After concatenating I have reshaped data and finally has normalize data. \nAfter normalizing I have shuffle data and create a batch of data of size 64","ee71f3c9":"# Defining function to calculate loss for both models\n### Since dicriminator is trained on both real and generate images so it has two loss and we have to take mean of these two losses \n### generator only has one loss","f7adacf3":"## Training Steps","91ab1dc1":"## To create GIFs","3d13bba7":"# Discriminator"}}