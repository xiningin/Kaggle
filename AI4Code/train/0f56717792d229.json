{"cell_type":{"035767a0":"code","7c3dbe27":"code","8c9c496a":"code","9d404a3e":"code","b35037a3":"code","89100041":"code","35a1c901":"code","fdc03363":"code","ac29dce7":"code","867dfeab":"code","0acbaeb4":"code","7f9f16cf":"code","73597b92":"code","45223f96":"code","6e2f382b":"code","e22e3b0b":"code","0e996754":"code","234c3b2e":"code","83ba3cb8":"code","11271315":"code","e656bb76":"code","f2323b2f":"code","6b363213":"code","953090c0":"code","69d12ec9":"code","9a1f77ad":"code","c05a94f4":"code","26bbf6a5":"code","eed81b6e":"code","bd4119e5":"markdown","be39fac9":"markdown","052b2a92":"markdown","e83bcc4a":"markdown","7b86dfb4":"markdown","6c0a3a43":"markdown","ec43dc3e":"markdown","5a491221":"markdown","88ef4b83":"markdown","50873f72":"markdown","21e3d477":"markdown"},"source":{"035767a0":"# Installing PyCaret which is an open-source, low-code machine learning library & end-to-end model management tool. \n#%%capture #suppresses the displays\n# install the full version\n!pip install pycaret[full]","7c3dbe27":"# Installing Gradio\n!pip install gradio","8c9c496a":"#Step 3: Prepare Data for Consumption\n## 3.1 Importing the necessary libraries\n\nimport numpy  as np\nimport pandas as pd\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n# from pandas.tools.plotting import scatter_matrix\n%matplotlib inline\n\n#Common Model Algorithms\nimport sklearn\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\nplt.style.use('fivethirtyeight')\nplt.rcParams.update({'font.size': 16})\n#from datetime import datetime\n#from datetime import timedelta\n\nfrom pycaret.regression import *\nprint(\"Setup complete\")","9d404a3e":"# 3.11 Loading & reading the data for getting a quick and dirty overview of variable datatypes \ntrain=pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv', index_col='row_id')\ntest=pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv', index_col='row_id')","b35037a3":"print('Training data df shape:',train.shape)\nprint('Test data df shape:',test.shape)","89100041":"train.head()","35a1c901":"test.head()","fdc03363":"train.info()","ac29dce7":"train.isnull().sum()","867dfeab":"test.isnull().sum()","0acbaeb4":"train.describe().T","7f9f16cf":"train.describe(include=['O'])","73597b92":"# The frequency distribution of the categorical variables country, store, product\ntrain['country'].value_counts()","45223f96":"train['store'].value_counts()\n","6e2f382b":"train['product'].value_counts()","e22e3b0b":"# timeframe\nprint('Training data:')\nprint('Min date', train['date'].min())\nprint('Max date', train['date'].max())\nprint('\\n')\nprint('Test data:')\nprint('Min date', test['date'].min())\nprint('Max date', test['date'].max())\n","0e996754":"plt.figure(figsize  = (10,5))\nfig = train.groupby(['date','store']).agg(num_sold=('num_sold','sum'))\nsns.lineplot(data=fig, x='date', y='num_sold', hue='store')\n\nplt.title('num_sold by each Store')\n  ","234c3b2e":"count_sell = train.groupby(['country']).num_sold.sum()\nprint(count_sell.to_string())\nsns.barplot(x = count_sell.index, y = count_sell.values)\nplt.title('Sales per country')\nplt.xlabel('country')\nplt.ylabel('No. of Sales')\n\nsns.set(color_codes=True)\npal = sns.color_palette(\"Blues\", 9)\nsns.set_palette('dark')","83ba3cb8":"plt.pie(count_sell.values, labels = count_sell.index,  autopct='%0.1d%%')\nplt.title('Percentage of Sales for each Country')","11271315":"#Store sales by country\nfig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\nKR=train[train.store=='KaggleRama']\nKM=train[train.store=='KaggleMart']\nbb=KR.groupby(['date','country']).agg(num_sold=('num_sold','sum'))\ncc=KM.groupby(['date','country']).agg(num_sold=('num_sold','sum'))\n\n# Lineplots\nax1=sns.lineplot(ax=axes[0], data=bb, x='date', y='num_sold', hue='country')\nax2=sns.lineplot(ax=axes[1], data=cc, x='date', y='num_sold', hue='country')\n\n# Aesthetics\nax1.title.set_text('KaggleRama')\nax2.title.set_text('KaggleMart')","e656bb76":"#Store sales by product type\nfig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\n# Groupby\ndd=KR.groupby(['date','product']).agg(num_sold=('num_sold','sum'))\nee=KM.groupby(['date','product']).agg(num_sold=('num_sold','sum'))\n\n# Lineplots\nax1=sns.lineplot(ax=axes[0], data=dd, x='date', y='num_sold', hue='product')\nax2=sns.lineplot(ax=axes[1], data=ee, x='date', y='num_sold', hue='product')\n\n# Aesthetics\nax1.title.set_text('KaggleRama')\nax2.title.set_text('KaggleMart')","f2323b2f":"def pre_process(df):\n    \n    df['date'] = pd.to_datetime(df['date'])\n    df['week']= df['date'].dt.week\n    df['year'] = 'Y'+df['date'].dt.year.astype(str)\n    df['quarter'] = 'Q'+df['date'].dt.quarter.astype(str)\n    df['day'] = df['date'].dt.day\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df.loc[(df.date.dt.is_leap_year) & (df.dayofyear >= 60),'dayofyear'] -= 1\n    df['weekend'] = df['date'].dt.weekday >=5\n    df['weekday'] = 'WD' + df['date'].dt.weekday.astype(str)\n    df.drop(columns=['date'],inplace=True)   \n    \npre_process(train)\npre_process(test)","6b363213":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","953090c0":"# Getting started with model building and inference with pycaret iniialize setup.\n\nreg = setup(data = train,\n            target = 'num_sold',\n            normalize=True,\n            normalize_method='robust',\n            transform_target = True,\n            data_split_shuffle = False, \n            create_clusters = False,\n            use_gpu = True,\n            silent = True,\n            fold=10,\n            n_jobs = -1)","69d12ec9":"# Compare models\nadd_metric('SMAPE', 'SMAPE', SMAPE, greater_is_better = False)\ntop = compare_models(sort = 'SMAPE', n_select = 10)\ncompare_model_results = pull()","9a1f77ad":"blend = blend_models(top)\npredict_model(blend);","c05a94f4":"final_blend = finalize_model(blend)\npredict_model(final_blend);","26bbf6a5":"plot_model(blend)","eed81b6e":"#Make predictions on test data\npreds = predict_model(final_blend, data=test)\n\n#New_data is pd dataframe\nsub = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\nsub.to_csv('submission.csv', index = False)\nprint(sub)#.head(),sub.describe())\n\n","bd4119e5":"# EDA","be39fac9":"# Tabular Playground Series - Jan 2022: A simple average model\nI made the first version of my notebook based on my little experience in data science field, which include part of exploratory data analysis. Then I decied to expand my knowledge and learning from the solutions of other people to build in my self. Therefore I would like to thank all of these people for their valuable experience that added to me.\n\nThis notebook builds on the approach in https:\/\/www.kaggle.com\/mfedeli\/tabular-playground-series-jan-2022 - thanks for sharing!\n(1) Detailed EDA and Vizualizations [TPS January 2022] https:\/\/www.kaggle.com\/nishantdhingra\/detailed-eda-and-vizualizations-tps-january-2022#1.-Which-countries-buys-most-?\n(2) Tabular Playground Series - Jan 2022 https:\/\/www.kaggle.com\/mfedeli\/tabular-playground-series-jan-2022\/comments\n\nAcknolegments to :-\n(1)A Data Science Framework: To Achieve 99% Accuracy\nhttps:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy\n(2)Comprehensive data exploration with Python https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n(3) \n\n","052b2a92":"The train data contains 5 columns, four of them are objects, and one is numeric which is the target variable.","e83bcc4a":"From the above, there are two stores, that selling three products, which are exist in three countries.","7b86dfb4":"We see that both stores sell Hats the most, then Mugs and finally Stickers the least.\nSales of stickers is fairly constant throughout the year, whereas hat (especially) and mug sales is more affected by seasonality.","6c0a3a43":"#A Data Science Framework\n##(1) Defining the problem\nIn the Tabular Playground Series - Jan 2022 competition we are tasked with develop an algorithm to predict the sales [Numeric values] for two different stores (KaggleMart, & KaggleRama) that sell three different products (the Kaggle Mug, the Kaggle Hat and the Kaggle Sticker, all highly sought-after products) in three different countries (Finland, Sweden and Norway) for the year 2019. We are provided with training data for four years from 2015 to 2018. The features that are available in the data to use are date, country, store, & product. \n\nAs this problem is one of predictive analysis that predict sales based on existing data, therefore the analytical techniques that can be used continuous (such as liner regression , Decision tree, Forest model, Boosted model) or Time Based (ARIMA or ETS).  \n\n## Step 2: Importing the Data\n   The data is already provided by kaggle.https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\n    ","ec43dc3e":"Initial thoughts:\n- The train and test dataset have no null values.\n-Country, store and product features are not currently numeric, categorical variables.","5a491221":"The data is equally distributed.","88ef4b83":"Kaggle Rama is consistently selling more products than Kaggle Mart.\nThe number of products sold for both companies oscillates depending on the time of year (season) and fluctuates rapidly (this is probably due to weekday vs weekend sales).\nThere are big spikes towards the end of each year (likely due to christmas) and also some other smaller seasonal spikes (perhaps easter holidays etc).","50873f72":"In data analysis step, we will try to answr these questions to understand\n- which store sell more?\n- which store sell more products in each country\n- how much store sales by product type.","21e3d477":"From the above visualization, it is clear that Norway has a biggest sales of kaggle swags by 43%, and finland has a smallest percentage of the total sales with 26.3%."}}