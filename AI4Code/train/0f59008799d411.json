{"cell_type":{"3ba99716":"code","46062f3d":"code","3794ce07":"code","82b05e92":"code","9b466090":"code","fdffb705":"code","e5f8cebe":"code","0a24bcfd":"code","4485ae98":"code","5610fa92":"code","18b17ecd":"code","e74c89fc":"code","b92a3c43":"code","f4de77f1":"code","36afbbb3":"code","cd3152f4":"code","3158e8ca":"code","2fd47d80":"code","b4dba818":"code","7cfc0c81":"markdown","a21bb221":"markdown","2ad6f3b5":"markdown","41b67cca":"markdown"},"source":{"3ba99716":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46062f3d":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv\")","3794ce07":"sample_submission.shape","82b05e92":"train.shape","9b466090":"test.shape","fdffb705":"data = pd.concat([train, test], sort = False)\ndata.shape","e5f8cebe":"data.info()","0a24bcfd":"data.head()","4485ae98":"null_cols = [col for col in data.iloc[: , : -1].columns if data[col].isnull().sum() != 0]\nnull_cols","5610fa92":"float_cols = [col for col in data.iloc[: , 1 : -1].columns if data[col].dtype == \"float64\"]\nlen(float_cols)","18b17ecd":"int_cols = [col for col in data.iloc[: , 1 : -1].columns if data[col].dtype == \"int64\"]\nlen(int_cols)","e74c89fc":"cols_binary = [col for col in data[int_cols].columns if np.all(data[col].unique() == [0, 1]) | np.all(data[col].unique() == [1, 0])]\nint_cols == cols_binary","b92a3c43":"del data","f4de77f1":"from sklearn.model_selection import train_test_split\n\nX = train.copy()\ny = X.pop('target')\nX_test = test.copy()\n\ndel train, test\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3,\n                                                      random_state =0, stratify = y)","36afbbb3":"import optuna\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_curve, auc\n\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature = cols_binary)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference = lgb_train, categorical_feature = cols_binary)\n\ndef objective(trial):\n    params = {\n        'metric': 'auc',\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.02),\n        'max_bin': trial.suggest_int('max_bin', 300, 600),\n        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n    }\n    \n    lgb_train = lgb.Dataset(X_train, y_train,\n                            categorical_feature = cols_binary)\n    lgb_eval = lgb.Dataset(X_valid, y_valid,\n                           reference = lgb_train, categorical_feature = cols_binary)\n\n    model = lgb.train(params,\n                      lgb_train,\n                      valid_sets = [lgb_train, lgb_eval],\n                      verbose_eval = 10,\n                      num_boost_round = 1000,\n                      early_stopping_rounds = 10)\n    y_pred_valid = model.predict(X_valid, num_iteration = model.best_iteration)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_valid, y_pred_valid)\n    score = auc(false_positive_rate, true_positive_rate)\n    return score\n\nstudy = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0))\nstudy.optimize(objective, n_trials = 20)","cd3152f4":"study.best_params","3158e8ca":"params = {\n    'metric': 'auc',\n    'learning_rate': study.best_params['learning_rate'],\n    'num_leaves': study.best_params['num_leaves'],\n    'max_bin': study.best_params['max_bin'],\n}\n\n\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature = cols_binary)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference = lgb_train, categorical_feature = cols_binary)\n\n\nmodel = lgb.train(params,\n                  lgb_train,\n                  valid_sets = [lgb_train, lgb_eval],\n                  verbose_eval = 10,\n                  num_boost_round = 2000,\n                  early_stopping_rounds = 10)\n\n\ny_pred = model.predict(X_test, num_iteration = model.best_iteration)","2fd47d80":"sub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")\nsub['target'] = y_pred\nsub.to_csv('submission_1st_trial.csv', index = False)","b4dba818":"sub.head()","7cfc0c81":"## Data concatenation","a21bb221":"# Data Preparation\n\n## Data extraction","2ad6f3b5":"## Discrete features definition","41b67cca":"## Null value check"}}