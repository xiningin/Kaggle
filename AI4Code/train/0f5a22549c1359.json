{"cell_type":{"0687cbed":"code","c1dc9a35":"code","640ebfab":"code","fc0e4289":"code","61fd2337":"code","a92db7ee":"code","4f2e644f":"code","deefbe17":"code","9f1c068d":"code","08ee871d":"code","e95149e2":"code","56cf006e":"code","27c92bdc":"code","2f26d9be":"code","5a37bc7d":"code","c49e7367":"code","02b4ae6f":"code","a7d682f6":"code","463a2382":"code","471a51b7":"code","231832a2":"code","9e6f5764":"code","ee77485e":"code","58c5aade":"code","ca50814b":"code","3f4f7155":"code","f0519906":"code","933fb2f9":"code","e0294d4c":"code","cb6b3256":"code","38bdece0":"code","826d5e5f":"code","c104f63d":"code","0eb1f0a8":"code","dce6d745":"code","2d279d2b":"code","2343a430":"code","20a850a7":"code","3228e297":"code","02ec1b5d":"code","4c1904a4":"code","d3915cbd":"code","13d7543b":"code","06d710fb":"code","79d09755":"code","619e7ee3":"code","f83720c6":"code","aae55a1c":"code","d9d25ae6":"code","e02886d1":"code","63a02869":"code","55be2f01":"code","dda0929d":"code","91d1e712":"code","eb689ff9":"code","ed726b32":"code","90969751":"code","628879d3":"code","db532cc3":"code","fbe30140":"code","bc0a517a":"markdown","104ebb3c":"markdown","984e3914":"markdown"},"source":{"0687cbed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1dc9a35":"#Reading Required Data\n\ndata_train = pd.read_csv(\"\/kaggle\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv\",encoding=\"utf-8\", delimiter=',')\ndata_train.head()","640ebfab":"# importing the libraries\nimport numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\", 100)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fc0e4289":"data_train.head()","61fd2337":"## Removing customerID and Row Number\n\ndata_train2 = data_train.drop(['RowNumber','CustomerId','Surname'],axis=1)\ndata_train2.shape","a92db7ee":"data_train2.info()","4f2e644f":"data_train2.head()","deefbe17":"data_train2.describe()","9f1c068d":"## Lets findout the distribution of Churn: Yes and Nos First\n\n# Good Practice: Always check if data set is balance or imbalance.\nsns.set_style('whitegrid')\nsns.countplot(x='Exited',data=data_train2,palette='RdBu_r')","08ee871d":"## There are some outliers in Balance and Estimated Salry. 1. Balance (min to 25%) is 0; while Estimated salary is \n## 11.58 rupees as minimum","e95149e2":"## Lets see this through dist plot\n\nplt.hist(data_train2.EstimatedSalary, bins=5\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.show()","56cf006e":"plt.hist(data_train2.EstimatedSalary, bins=7\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","27c92bdc":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train2['EstimatedSalary'].quantile(0.999)\nMaxThershold","2f26d9be":"MinThershold = data_train2['EstimatedSalary'].quantile(0.015)\nMinThershold","5a37bc7d":"data_train3 = data_train2[(data_train2.EstimatedSalary < MaxThershold) & (data_train2.EstimatedSalary > MinThershold)]\ndata_train3.head()","c49e7367":"data_train3.shape","02b4ae6f":"10000-9540","a7d682f6":"## Detecting outlier in Balance\n\n## Lets see this through dist plot\n\nplt.hist(data_train3.Balance, bins=5\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.show()","463a2382":"plt.hist(data_train3.Balance, bins=7\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","471a51b7":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train3.Balance.quantile(0.999)\nMaxThershold","231832a2":"MinThershold = data_train3.Balance.quantile(0.370)\nMinThershold","9e6f5764":"data_train4 = data_train3[(data_train3.Balance < MaxThershold) & (data_train3.Balance > MinThershold)]\ndata_train4.head()","ee77485e":"data_train4.shape","58c5aade":"data_train4.dtypes","ca50814b":"#Lets seperate all as numerical\/Categorical\n# Findout Missing Value %age\n\nstatistics_of_data = []\nfor col in data_train4.columns:\n  statistics_of_data.append((col,\n                             data_train4[col].isnull().sum()*100\/data_train4.shape[0],\n                             data_train4[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'missing_val', 'type'])","3f4f7155":"stats_df.sort_values('missing_val', ascending=False)","f0519906":"##No missing Values Found","933fb2f9":"## Seperate out Numerical\/Int Variables.\nnumerical_features = [feature for feature in data_train4.columns if data_train4[feature].dtypes != 'O' ]\nprint(len(numerical_features))\ndata_train4[numerical_features].head()","e0294d4c":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature = [feature for feature in numerical_features if len(data_train4[feature].unique())<25]\nprint(len(discrete_feature))\ndiscrete_feature","cb6b3256":"## Continous Features\n\n\ncontinous_feature = [feature for feature in numerical_features if feature not in discrete_feature]\nprint(\"Continuous feature Count {}\".format(len(continous_feature)))\ndata_train4[continous_feature].head()","38bdece0":"def print_unique_col_values(df):\n    i=1\n    for column in df:\n        str = \"{i}. {a} column have {b} unique values\"\n        print(str.format(i=i,a=column,b=df[column].unique()))\n        i=i+1","826d5e5f":"print_unique_col_values(data_train4[discrete_feature])","c104f63d":"# Now lets create visuals for comparison of continous\/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\ntenure_churn_no = data_train4[data_train4.Exited==0].Tenure\ntenure_churn_yes = data_train4[data_train4.Exited==1].Tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","0eb1f0a8":"# Now lets create visuals for comparison of continous\/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\nAge_churn_no = data_train4[data_train4.Exited==0].Age\nAge_churn_yes = data_train4[data_train4.Exited==1].Age\n\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Age_churn_yes, Age_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","dce6d745":"##Exited: 0 -> No,1 ->Yes\nBalance_churn_no = data_train4[data_train4.Exited==0].Balance\nBalance_churn_yes = data_train4[data_train4.Exited==1].Balance\n\nplt.xlabel(\"Balance\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Balance_churn_yes, Balance_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","2d279d2b":"#EstimatedSalary\n##Exited: 0 -> No,1 ->Yes\nEstimatedSalary_churn_no = data_train4[data_train4.Exited==0].EstimatedSalary\nEstimatedSalary_churn_yes = data_train4[data_train4.Exited==1].EstimatedSalary\n\nplt.xlabel(\"EstimatedSalary\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([EstimatedSalary_churn_yes, EstimatedSalary_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","2343a430":"#Now lets seperate our categorical features so that we can add other transformation uopn them\ncategoricalVariable = [feature for feature in data_train4.columns if data_train3[feature].dtype == 'O' ]\nlen(categoricalVariable)","20a850a7":"data_train4[categoricalVariable].head()","3228e297":"#Male->1, Female 0\ndata_train4['Gender'].replace({'Female':1,'Male':0},inplace=True)","02ec1b5d":"#Lets apply One hot encoding for categorical column Geography\n\ndata_train5 = pd.get_dummies(data=data_train4, columns=['Geography'])\ndata_train5.columns","4c1904a4":"data_train5.shape","d3915cbd":"data_train5.sample(5)","13d7543b":"#Data Scaling of continous data\n\ncontinous_feature","06d710fb":"### Data Scaling -->>Continous data only\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_train5[continous_feature] = scaler.fit_transform(data_train5[continous_feature])","79d09755":"ij=1\nfor col in data_train5:\n    str = \"{ij}. {a} column have {b} unique values\"\n    print(str.format(ij = ij,a=col,b=data_train5[col].unique()))\n    ij=ij+1","619e7ee3":"### Train Test Split:::\n\nX = data_train5.drop('Exited',axis='columns')\ny = data_train5['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)","f83720c6":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","aae55a1c":"len(X_train.columns)","d9d25ae6":"import tensorflow as tf\nfrom tensorflow import keras","e02886d1":"model_ChurnPred = keras.Sequential([\n    keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n    keras.layers.Dense(15, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])","63a02869":"model_ChurnPred.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","55be2f01":"model_ChurnPred.fit(X_train, y_train, epochs=200)","dda0929d":"## So we got 85% Accuracy, Now Save this model\n\n# save model and architecture to single file\nmodel_ChurnPred.save(\"model_ChurnPred.h5\")\nprint(\"Saved model to disk\")","91d1e712":"##Now Loading a Model\nfrom keras.models import load_model\n \n# load model\nModel_Reloaded = load_model('model_ChurnPred.h5',compile=True)","eb689ff9":"yp = Model_Reloaded.predict(X_test)\nyp[:10]","ed726b32":"y_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","90969751":"y_pred[:10]","628879d3":"from sklearn.metrics import confusion_matrix , classification_report\n\nprint(classification_report(y_test,y_pred))","db532cc3":"import seaborn as sn\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","fbe30140":"####################### ********** THE END ********************** ############################################","bc0a517a":"### Now we are Builiding a Deep Learning Model (ANN) On keras\/Tensorflow","104ebb3c":"#### Observations: \n\n- This is imbalanced dataset, There are different ways to cater it, But for the sake of learning deep learning, We can ignore it for now. ","984e3914":"## Bank Turnover Dataset\n#### Can you predict if bank customers will turnover next cycle ?"}}