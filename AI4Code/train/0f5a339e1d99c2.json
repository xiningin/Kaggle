{"cell_type":{"73bc9fa2":"code","77b6d6e2":"code","afcdc790":"code","31c8c53a":"code","1add25d2":"code","23700bdb":"code","26134562":"code","e395466a":"code","da4151ce":"code","eebe5c1b":"code","5d0e734a":"code","4fac2806":"code","8b763a49":"code","6eb7ef9b":"code","1cad97a6":"code","ff9998f5":"code","a2b8fd5d":"code","3f69c039":"code","c7c70627":"code","bb08e003":"code","32258d85":"code","4a44ded3":"code","251ad284":"code","e72aedd5":"code","d389e219":"code","2dc14d71":"code","2e7e69b6":"code","9074addf":"code","e7fe5233":"code","400ce530":"markdown","5cd16c52":"markdown","4f7163ac":"markdown","ec2c3995":"markdown","0354e450":"markdown","418706fb":"markdown","6aa16580":"markdown","44dd9aaa":"markdown","02d4e086":"markdown","e6d7869d":"markdown","50b63c8f":"markdown","ed268525":"markdown","e6ac3074":"markdown"},"source":{"73bc9fa2":"import os\nimport re\nimport pandas as pd\nimport numpy as np\n\nfrom nltk.corpus import stopwords\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n","77b6d6e2":"!ls","afcdc790":"DATASET_PATH = \"..\/input\/fake-news-challenge\/\"","31c8c53a":"print(os.listdir(DATASET_PATH))","1add25d2":"train_bodies = pd.read_csv(os.path.join(DATASET_PATH,'train_bodies.csv'))\ntrain_bodies.head()","23700bdb":"print('The number of rows ',train_bodies.shape[0])\nprint('The number of columns',train_bodies.shape[1])","26134562":"train_bodies.info()","e395466a":"train_stance = pd.read_csv(os.path.join(DATASET_PATH,'train_stances.csv'))\ntrain_stance.head()","da4151ce":"print('The number of rows ',train_stance.shape[0])\nprint('The number of columns',train_stance.shape[1])","eebe5c1b":"train_stance.info()","5d0e734a":"# the output signifies that each body id is associated to multiple headlines\ntrain_stance['Body ID'].value_counts()","4fac2806":"#Run commented code to combine the two csv file{train_bodies.csv,train_stances.csv} into data_combined.csv file\nfrom tqdm.notebook import tqdm\ncount=0\nfor i in tqdm(range(train_stance.shape[0])):\n    for j in range(train_bodies.shape[0]):\n        if train_bodies.loc[j,'Body ID']==train_stance.loc[i,'Body ID']:\n            train_stance.loc[i,'articleBody'] = train_bodies.loc[j,'articleBody']\n#     if i%100==0:\n#         count+=1\n#         print(count,end=' ')\n\ntrain_stance.to_csv('data_combined.csv',index=False)","8b763a49":"data = pd.read_csv('data_combined.csv')\ndata.head()","6eb7ef9b":"data['stance_cat'] = data['Stance'].map({'agree':0,'disagree':1,'discuss':2,'unrelated':3}).astype(int)\ndata['Stance'].value_counts()","1cad97a6":"stopwords_english = set(stopwords.words('english'))\ndata['Headline'] = data.Headline.apply(lambda x:str(x))\ndata.loc[:,'Headline'] = data['Headline'].apply(lambda x : str.lower(x))\ndata.loc[:,'Headline'] = data['Headline'].apply(lambda x:' '.join(re.findall('[\\w]+',x)))\ndata.loc[:,'articleBody'] = data['articleBody'].apply(lambda x : str.lower(x))\ndata.loc[:,'articleBody'] = data['articleBody'].apply(lambda x:' '.join(re.findall('[\\w]+',x)))\n\n\ndef remove_stopwords(s):\n    return ' '.join(word for word in s.split() if word not in stopwords_english)\n\ndata['Headline'] = data['Headline'].apply(lambda x:remove_stopwords(x))\ndata['articleBody'] = data['articleBody'].apply(lambda x:str(x))\ndata['articleBody'] = data['articleBody'].apply(lambda x:remove_stopwords(x))","ff9998f5":"data['stance_base'] = data.loc[data.loc[:,'Stance']=='unrelated','Stance']\ndata['stance_base'] = data['stance_base'].fillna(\"related\")\nprint(data['stance_base'].value_counts())","a2b8fd5d":"data.head()","3f69c039":"def jaccard_similarity(list1, list2):\n    s1 = set(list1)\n    s2 = set(list2)\n    return len(s1.intersection(s2)) \/ len(s1.union(s2))","c7c70627":"def add_jaccard_similarity(data):\n    count=0\n    for i in tqdm(range(data.shape[0])):\n        jaccard_lis=[];eps=0.001\n        sentence = data.loc[i,'articleBody'].split('.') #per sentence scorer\n        for j in range(len(sentence)):\n            jaccard_lis.append(jaccard_similarity(data.loc[i,'Headline'].split(' '),sentence[j].split(' ')))\n        max_jaccard_similarity = max(jaccard_lis)\n        avg_jaccard_similarity = sum(jaccard_lis)\/len(jaccard_lis)\n        min_jaccard_similarity = min(jaccard_lis)\n        data.loc[i,'jaccard_similarity'] = (max_jaccard_similarity+min_jaccard_similarity)\/(max_jaccard_similarity-min_jaccard_similarity+eps)\n#         if i%1000==0:\n#             count+=1\n#             print(\"Processed {0} Headlines\".format(count*1000))\nadd_jaccard_similarity(data)    ","bb08e003":"data['stance_base'].value_counts()","32258d85":"x = data.iloc[:,-1]\ny = data['stance_base']\n\n\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1)\n\nrg = RandomForestClassifier(n_estimators=100,n_jobs=-1)","4a44ded3":"print('X Training shape',xtrain.shape)\nprint('Y Training shape',ytrain.shape)\nxtrain = xtrain.values.reshape(-1,1)\nxtest = xtest.values.reshape(-1,1)","251ad284":"rg.fit(xtrain,ytrain)\nypred = rg.predict(xtest)\n\nprint('Accuracy score on two class agree and disagree ',accuracy_score(ypred,ytest))\n\n","e72aedd5":"accuracy = accuracy_score(ypred,ytest)\nprint('Accuracy: %f' % accuracy)\n# precision tp \/ (tp + fp)\nprecision = precision_score(ypred,ytest,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp \/ (tp + fn)\nrecall = recall_score(ypred,ytest,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1 = f1_score(ypred,ytest,average='weighted')\nprint('F1 score: %f' % f1)","d389e219":"data['Stance'].value_counts()","2dc14d71":"x = data.iloc[:,-1]\ny = data['Stance']\n\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1)\n\nrg = RandomForestClassifier(n_estimators=100,n_jobs=-1)","2e7e69b6":"print('X Training shape',xtrain.shape)\nprint('Y Training shape',ytrain.shape)\nxtrain = xtrain.values.reshape(-1,1)\nxtest = xtest.values.reshape(-1,1)","9074addf":"rg.fit(xtrain,ytrain)\nypred = rg.predict(xtest)\n\n\n# print('Accuracy score on Four class {agree,disagree,discuss,unrelated}',accuracy_score(ypred,ytest))","e7fe5233":"accuracy = accuracy_score(ypred,ytest)\nprint('Accuracy: %f' % accuracy)\n# precision tp \/ (tp + fp)\nprecision = precision_score(ypred,ytest,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp \/ (tp + fn)\nrecall = recall_score(ypred,ytest,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1 = f1_score(ypred,ytest,average='weighted')\nprint('F1 score: %f' % f1)","400ce530":"**train_bodies.csv** contains body id and article body for training  \n**train_stances.csv** contains headlines corresponding to body id and associated labelled stance with it\n","5cd16c52":"## Preparing Data for Classification","4f7163ac":"## Dataset understanding \n\n1. The train_bodies contain the entries for the body id and associated article Body\n2. The train_stances contain the entries for the headlines associated with the particular body id and its labelled stance\n3. One body present in train_bodies can have multiple associated headlines present in train_stances and it's corresponding stance label\n4. 1683 :- Number of article Body present\n5. 49972 number of total headlines present for the 1683 different article body","ec2c3995":"## Four Class Classification\n\nWe are now doing the four class classification into categories \n\n1. unrelated  \n2. discuss  \n3. agree  \n4. disagree  \n","0354e450":"1. We are given a dataset consisting of two csv files train_bodies.csv which contains the set of news articles bodies,while train-stances.csv resembles the articles for each of these bodies being identified using the body id.\n\n2. After training from these samples we need to detect whether the given headline agrees,disagrees,discusses,unrelated with the body id\n","418706fb":"## Data Preprocessing","6aa16580":"## Classifying Two Classes Related\/Unrelated\n\n","44dd9aaa":"## Baseline Model For Two Class","02d4e086":"# Loading the dataset","e6d7869d":"**Please upvote the notebook if you found it usefull**  \nThanks ","50b63c8f":"# Combining the CSV\n\nI am preparing a final csv in each row will correspond to a unique entry\ni.e each row will correspond to a unique combination of headline,bodyid and article body \n\nThe above is needed for making simplicity in further data preparation steps we need to execute\n","ed268525":"### Creating the two class dataset of related\/unrelated\n\n\nFor a baseline classification we are simplifying the classification problem to a two class classification by first taking only strong divergent classes related\/unrelated ","e6ac3074":"# Problem Statement"}}