{"cell_type":{"70d98d06":"code","e9261b94":"code","d39918ea":"code","02cfb279":"code","d4c57606":"code","748fd2f4":"code","8a8785f2":"code","bdafcc3d":"code","e15cd211":"code","cecae3f5":"code","e0f032d1":"code","495fc9f5":"code","19cb5820":"code","a02b7c47":"code","529f4162":"code","a877eb57":"code","2f0ce1a6":"code","7d13214e":"code","0bcd63ef":"code","3cb72fc4":"code","777c35c1":"code","580c891a":"code","50dcfaec":"code","2b86eee9":"code","261bfa3e":"code","8bf34ab7":"code","64d8b4a5":"code","88340c07":"code","05f03c80":"code","66eac9ed":"code","7d768e1d":"code","c7c9ad1b":"code","79fb46f2":"code","e7f8e291":"code","0b6ab400":"code","dae9e867":"code","430f6a59":"code","b9e0ea40":"code","0cf37884":"code","c14f2fce":"code","275d07ad":"code","77311dfd":"code","f0e2f7a3":"code","9b8d030a":"code","267665fb":"code","c54f9d67":"code","9b66c7ef":"code","7525292f":"code","6e831cf2":"code","cd4e59d1":"code","f4b4a6ae":"code","955f562a":"code","c3caf8cf":"code","3bd337bb":"code","3adb03ce":"code","502a9955":"markdown","85e5eab5":"markdown","1436f27f":"markdown","c3df2ab4":"markdown","64d54bf8":"markdown","58e81f6e":"markdown","22b67737":"markdown","03675b56":"markdown","72c4871c":"markdown","cd0b0e3a":"markdown","1a6f7ed4":"markdown","dff912b5":"markdown","dc655424":"markdown","17001d16":"markdown","da8f8547":"markdown","cd44df6b":"markdown","0b24a974":"markdown","028e820d":"markdown","64e7658e":"markdown","cca2e667":"markdown","0fe0e907":"markdown","abe9eeb7":"markdown","cdc76497":"markdown","0c1a7dee":"markdown","93f57a3a":"markdown","92a8b25b":"markdown","3c801d79":"markdown","ef7359eb":"markdown","6adc623d":"markdown","f9b18c20":"markdown"},"source":{"70d98d06":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline  \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e9261b94":"df = pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")\ndf.head()","d39918ea":"del df['id']","02cfb279":"# 1) Leave the first 8 characters\ndf['date'] = df['date'].apply(lambda x: x[:8])\n# 2) Convert str to datetime type\ndf['date'] = df['date'].astype('datetime64[ns]')\n# 3) Convert the date to a day from the beginning of the year\ndf['date'] = df['date'].apply(lambda x: x.timetuple().tm_yday)","d4c57606":"df.head()","748fd2f4":"# number of null values\ndf.isnull().sum().max()","8a8785f2":"# general statistics df\ndf.describe()","bdafcc3d":"h = df.hist(bins=25,figsize=(16,16),xlabelsize='10',ylabelsize='10',xrot=-15)\nsns.despine(left=True, bottom=True)\n[x.title.set_size(12) for x in h.ravel()];\n[x.yaxis.tick_left() for x in h.ravel()];","e15cd211":"f = plt.figure(figsize=(16, 10))\ncorr = df.iloc[:,1:].corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot=True, annot_kws={'size':10})\nplt.title('\u041c\u0430\u0442\u0440\u0438\u0446\u0430 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438', fontsize=12);","cecae3f5":"with sns.plotting_context(\"notebook\",font_scale=2.5):\n    g = sns.pairplot(df[['price','sqft_living','sqft_above','sqft_living15',\n                         'bathrooms','bedrooms','sqft_basement','lat', 'grade']], \n                 hue='grade', palette='tab20', size=6)\ng.set(xticklabels=[]);","e0f032d1":"ax = sns.lmplot(x=\"sqft_living\", y=\"price\", data=df, hue=None)","495fc9f5":"ax = sns.lmplot(x=\"sqft_living\", y=\"price\", data=df, hue=\"grade\", palette='tab20')","19cb5820":"ax = sns.lmplot(x=\"sqft_living\", y=\"price\", data=df, palette='tab20', hue=\"grade\", col=\"grade\", col_wrap=3, height=4)","a02b7c47":"df_lg = df.copy()\ndf_lg[['price','sqft_living','sqft_above','sqft_living15']] = np.log10(df[['price','sqft_living','sqft_above','sqft_living15']])\n   \ndf_lg.head()","529f4162":"data = df_lg[['price','sqft_living','sqft_above','sqft_living15']]\n\nh = data.hist(bins=20,figsize=(12,10),xlabelsize='10',ylabelsize='10')\nsns.despine(left=True, bottom=True)\n[x.title.set_size(12) for x in h.ravel()];\n[x.yaxis.tick_left() for x in h.ravel()];","a877eb57":"sns.set(style=\"whitegrid\")\nax = sns.lmplot( x=\"long\", y=\"lat\", data=df, fit_reg=False, hue='grade', \n                legend=False, palette=\"Blues\", height=8.27, aspect=1.4)\nplt.legend(loc='lower right')\nplt.show()","2f0ce1a6":"from sklearn.model_selection import train_test_split","7d13214e":"# divide the data into a training set for data in its original form\ntrain, test = train_test_split(df,train_size = 0.8, random_state = 42)\n\n# for data on a logarithmic scale\ntrain_lg, test_lg = train_test_split(df_lg,train_size = 0.8, random_state = 42)","0bcd63ef":"x_train = train.drop(['price'], axis=1)\ny_train = train.price\n\nx_test = test.drop(['price'], axis=1)\ny_test = test.price\n\n\nx_train_lg = train_lg.drop(['price'], axis=1)\ny_train_lg = train_lg.price\n\nx_test_lg = test_lg.drop(['price'], axis=1)\ny_test_lg = test_lg.price","3cb72fc4":"print('Average price (y_train):', np.mean(y_train))\nprint('Average price (y_test):', np.mean(y_test))\nprint('Average price (y_train_lg):', 10 ** np.mean(y_train_lg))\nprint('Average price (y_test_lg):', 10 ** np.mean(y_test_lg))","777c35c1":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","580c891a":"name = 'Linear Regression'\ndetails = '-'\n\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)","50dcfaec":"print('Quality of the model R2: train -', \"%.3f\" %  model.score(x_train, y_train), \n      'test -', \"%.3f\" %  model.score(x_test, y_test))","2b86eee9":"coef = pd.DataFrame(zip(['intercept'] + x_train.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n                    columns=['predictor', 'coef'])\ncoef","261bfa3e":"from scipy import stats\n\ndef regression_coef(model, X, y):\n    coef = pd.DataFrame(zip(['intercept'] + X.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n                    columns=['predictor', 'coef'])\n    X1 = np.append(np.ones((len(X),1)), X, axis=1)\n    b = np.append(model.intercept_, model.coef_)\n    MSE = np.sum((model.predict(X) - y) ** 2, axis=0) \/ float(X.shape[0] - X.shape[1])\n    var_b = MSE * (np.linalg.inv(np.dot(X1.T, X1)).diagonal())\n    sd_b = np.sqrt(var_b)\n    t = b \/ sd_b\n    coef['pvalue'] = [2 * (1 - stats.t.cdf(np.abs(i), (len(X1) - 1))) for i in t]\n    return coef","8bf34ab7":"regression_coef(model, x_test, y_test)","64d8b4a5":"stat_sign = ['sqft_living','sqft_above','sqft_basement']\n\nx_train_st = x_train[stat_sign]\nx_test_st = x_test[stat_sign]\n\nx_train_lg_st = x_train_lg[stat_sign]\nx_test_lg_st = x_test_lg[stat_sign]","88340c07":"table = pd.DataFrame(columns=['Regressor', 'Details', 'R^2 (train)', 'R^2 (test)', \n                              'mae (train)', 'mae (test)', 'rmse (train)', 'rmse (test)'])\ntable_lg = pd.DataFrame(columns=['Regressor', 'Details', 'R^2 (train)', 'R^2 (test)',\n                                 'mae (train)', 'mae (test)', 'rmse (train)', 'rmse (test)'])","05f03c80":"# creating a list with quality metrics\ndef model_quality(model, x_train, y_train, x_test, y_test):\n    k = list()\n    k.append(model.score(x_train, y_train))\n    k.append(model.score(x_test, y_test))\n    k.append(mean_absolute_error(model.predict(x_train), y_train))\n    k.append(mean_absolute_error(model.predict(x_test), y_test))\n    k.append(np.sqrt(mean_squared_error(model.predict(x_train), y_train)))\n    k.append(np.sqrt(mean_squared_error(model.predict(x_test), y_test)))\n    return k\n\n# for values on a logarithmic scale\ndef model_quality_lg(model, x_train, y_train, x_test, y_test):\n    k = list()\n    k.append(model.score(x_train, y_train))\n    k.append(model.score(x_test, y_test))\n    k.append(mean_absolute_error(10 ** model.predict(x_train), 10 ** y_train))\n    k.append(mean_absolute_error(10 ** model.predict(x_test), 10 ** y_test))\n    k.append(np.sqrt(mean_squared_error(10 ** model.predict(x_train), 10 ** y_train)))\n    k.append(np.sqrt(mean_squared_error(10 ** model.predict(x_test), 10 ** y_test)))\n    return k\n\n# print metric values\ndef print_quality(k):\n    print ('R2 - train:', \"%.3f\" % k[0], 'test:', \"%.3f\" % k[1])\n    print ('mae - train:', \"%.3f\" % k[2], 'test:', \"%.3f\" % k[3])\n    print ('rmse - train:', \"%.3f\" % k[4], 'test:', \"%.3f\" % k[5])\n    \ndef add_to_table(table, name, details, k):\n    table.loc[len(table)] = [name, details, k[0], k[1], k[2], k[3], k[4], k[5]]","66eac9ed":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_lr = 'Multiple'\ndetails_lr = '-'\nlr = LinearRegression()\nlr.fit(x_train, y_train)\nk_lr = model_quality(lr, x_train, y_train, x_test, y_test)\nadd_to_table(table, name_lr, details_lr, k_lr)\nprint('MODEL: ', name_lr, details_lr)\nprint_quality(k_lr)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_lr_st = 'Multiple'\ndetails_lr_st = 'stat. sign. coef.'\nlr_st = LinearRegression()\nlr_st.fit(x_train_st, y_train)\nk_lr_st = model_quality(lr_st, x_train_st, y_train, x_test_st, y_test)\nadd_to_table(table, name_lr_st, details_lr_st, k_lr_st)\nprint('\\nMODEL: ', name_lr_st, details_lr_st)\nprint_quality(k_lr_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_lr_lg = 'Multiple'\ndetails_lr_lg = '-'\nlr_lg = LinearRegression()\nlr_lg.fit(x_train_lg, y_train_lg)\nk_lr_lg = model_quality_lg(lr_lg, x_train_lg, y_train_lg, x_test_lg, y_test_lg)\nadd_to_table(table_lg, name_lr_lg, details_lr_lg, k_lr_lg)\nprint('\\nMODEL: ', name_lr_lg, details_lr_lg)\nprint_quality(k_lr_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_lr_lg_st = 'Multiple'\ndetails_lr_lg_st = 'stat. sign. coef.'\nlr_lg_st = LinearRegression()\nlr_lg_st.fit(x_train_lg_st, y_train_lg)\nk_lr_lg_st = model_quality_lg(lr_lg_st, x_train_lg_st, y_train_lg, x_test_lg_st, y_test_lg)\nadd_to_table(table_lg, name_lr_lg_st, details_lr_lg_st, k_lr_lg_st)\nprint('\\nMODEL: ', name_lr_lg_st, details_lr_lg_st)\nprint_quality(k_lr_lg_st)\n##############################################################################################","7d768e1d":"print(\"For original data:\")\ntable","c7c9ad1b":"print(\"For logarithmic data\")\ntable_lg","79fb46f2":"from sklearn.preprocessing import PolynomialFeatures","e7f8e291":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_poly2 = 'Polynomial 2'\ndetails_poly2 = '-'\n#############\npolyfeat_p2 = PolynomialFeatures(degree=2)\nx_train_p2 = polyfeat_p2.fit_transform(x_train)\nx_test_p2 = polyfeat_p2.fit_transform(x_test)\n#############\npoly2 = LinearRegression()\npoly2.fit(x_train_p2, y_train)\nk_poly2 = model_quality(poly2, x_train_p2, y_train, x_test_p2, y_test)\nadd_to_table(table, name_poly2, details_poly2, k_poly2)\nprint('MODEL: ', name_poly2, details_poly2)\nprint_quality(k_poly2)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_poly2_st = 'Polynomial 2'\ndetails_poly2_st = 'stat. sign. coef.'\n#############\npolyfeat_p2_st = PolynomialFeatures(degree=2)\nx_train_p2_st = polyfeat_p2.fit_transform(x_train_st)\nx_test_p2_st = polyfeat_p2.fit_transform(x_test_st)\n#############\npoly2_st = LinearRegression()\npoly2_st.fit(x_train_p2_st, y_train)\nk_poly2_st = model_quality(poly2_st, x_train_p2_st, y_train, x_test_p2_st, y_test)\nadd_to_table(table, name_poly2_st, details_poly2_st, k_poly2_st)\nprint('\\nMODEL: ', name_poly2_st, details_poly2_st)\nprint_quality(k_poly2_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_poly2_lg = 'Polynomial 2'\ndetails_poly2_lg = '-'\n#############\npolyfeat_p2_lg = PolynomialFeatures(degree=2)\nx_train_p2_lg = polyfeat_p2.fit_transform(x_train_lg)\nx_test_p2_lg = polyfeat_p2.fit_transform(x_test_lg)\n#############\npoly2_lg = LinearRegression()\npoly2_lg.fit(x_train_p2_lg, y_train_lg)\nk_poly2_lg = model_quality_lg(poly2_lg, x_train_p2_lg, y_train_lg, x_test_p2_lg, y_test_lg)\nadd_to_table(table_lg, name_poly2_lg, details_poly2_lg, k_poly2_lg)\nprint('\\nMODEL: ', name_poly2_lg, details_poly2_lg)\nprint_quality(k_poly2_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_poly2_lg_st = 'Polynomial 2'\ndetails_poly2_lg_st = 'stat. sign. coef.'\n#############\npolyfeat_p2_lg_st = PolynomialFeatures(degree=2)\nx_train_p2_lg_st = polyfeat_p2_lg_st.fit_transform(x_train_lg_st)\nx_test_p2_lg_st = polyfeat_p2_lg_st.fit_transform(x_test_lg_st)\n#############\npoly2_lg_st = LinearRegression()\npoly2_lg_st.fit(x_train_p2_lg_st, y_train_lg)\nk_poly2_lg_st = model_quality_lg(poly2_lg_st, x_train_p2_lg_st, y_train_lg, x_test_p2_lg_st, y_test_lg)\nadd_to_table(table_lg, name_poly2_lg_st, details_poly2_lg_st, k_poly2_lg_st)\nprint('\\nMODEL: ', name_poly2_lg_st, details_poly2_lg_st)\nprint_quality(k_poly2_lg_st)\n##############################################################################################","0b6ab400":"print(\"For original data:\")\ntable","dae9e867":"print(\"For logarithmic data\")\ntable_lg","430f6a59":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_poly3 = 'Polynomial 3'\ndetails_poly3 = '-'\n#############\npolyfeat_p3 = PolynomialFeatures(degree=3)\nx_train_p3 = polyfeat_p3.fit_transform(x_train)\nx_test_p3 = polyfeat_p3.fit_transform(x_test)\n#############\npoly3 = LinearRegression()\npoly3.fit(x_train_p3, y_train)\nk_poly3 = model_quality(poly3, x_train_p3, y_train, x_test_p3, y_test)\nadd_to_table(table, name_poly3, details_poly3, k_poly3)\nprint('MODEL: ', name_poly3, details_poly3)\nprint_quality(k_poly3)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_poly3_st = 'Polynomial 3'\ndetails_poly3_st = 'stat. sign. coef.'\n#############\npolyfeat_p3_st = PolynomialFeatures(degree=3)\nx_train_p3_st = polyfeat_p3.fit_transform(x_train_st)\nx_test_p3_st = polyfeat_p3.fit_transform(x_test_st)\n#############\npoly3_st = LinearRegression()\npoly3_st.fit(x_train_p3_st, y_train)\nk_poly3_st = model_quality(poly3_st, x_train_p3_st, y_train, x_test_p3_st, y_test)\nadd_to_table(table, name_poly3_st, details_poly3_st, k_poly3_st)\nprint('\\nMODEL: ', name_poly3_st, details_poly3_st)\nprint_quality(k_poly3_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_poly3_lg = 'Polynomial 3'\ndetails_poly3_lg = '-'\n#############\npolyfeat_p3_lg = PolynomialFeatures(degree=3)\nx_train_p3_lg = polyfeat_p3.fit_transform(x_train_lg)\nx_test_p3_lg = polyfeat_p3.fit_transform(x_test_lg)\n#############\npoly3_lg = LinearRegression()\npoly3_lg.fit(x_train_p3_lg, y_train_lg)\nk_poly3_lg = model_quality_lg(poly3_lg, x_train_p3_lg, y_train_lg, x_test_p3_lg, y_test_lg)\nadd_to_table(table_lg, name_poly3_lg, details_poly3_lg, k_poly3_lg)\nprint('\\nMODEL: ', name_poly3_lg, details_poly3_lg)\nprint_quality(k_poly3_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_poly3_lg_st = 'Polynomial 3'\ndetails_poly3_lg_st = 'stat. sign. coef.'\n#############\npolyfeat_p3_lg_st = PolynomialFeatures(degree=3)\nx_train_p3_lg_st = polyfeat_p3_lg_st.fit_transform(x_train_lg_st)\nx_test_p3_lg_st = polyfeat_p3_lg_st.fit_transform(x_test_lg_st)\n#############\npoly3_lg_st = LinearRegression()\npoly3_lg_st.fit(x_train_p3_lg_st, y_train_lg)\nk_poly3_lg_st = model_quality_lg(poly3_lg_st, x_train_p3_lg_st, y_train_lg, x_test_p3_lg_st, y_test_lg)\nadd_to_table(table_lg, name_poly3_lg_st, details_poly3_lg_st, k_poly3_lg_st)\nprint('\\nMODEL: ', name_poly3_lg_st, details_poly3_lg_st)\nprint_quality(k_poly3_lg_st)\n##############################################################################################","b9e0ea40":"print(\"For original data:\")\ntable","0cf37884":"print(\"For logarithmic data\")\ntable_lg","c14f2fce":"from sklearn.neighbors import KNeighborsRegressor","275d07ad":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_knnr = 'k-NN'\ndetails_knnr = 'k=12'\nknnr = KNeighborsRegressor(n_neighbors=12)\nknnr.fit(x_train, y_train)\nk_knnr = model_quality(knnr, x_train, y_train, x_test, y_test)\nadd_to_table(table, name_knnr, details_knnr, k_knnr)\nprint('MODEL: ', name_knnr, details_knnr)\nprint_quality(k_knnr)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_knnr_st = 'k-NN'\ndetails_knnr_st = 'stat. sign. coef., k=12'\nknnr_st = KNeighborsRegressor(n_neighbors=12)\nknnr_st.fit(x_train_st, y_train)\nk_knnr_st = model_quality(knnr_st, x_train_st, y_train, x_test_st, y_test)\nadd_to_table(table, name_knnr_st, details_knnr_st, k_knnr_st)\nprint('\\nMODEL: ', name_knnr_st, details_knnr_st)\nprint_quality(k_knnr_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_knnr_lg = 'k-NN'\ndetails_knnr_lg = 'k=12'\nknnr_lg = KNeighborsRegressor(n_neighbors=12)\nknnr_lg.fit(x_train_lg, y_train_lg)\nk_knnr_lg = model_quality_lg(knnr_lg, x_train_lg, y_train_lg, x_test_lg, y_test_lg)\nadd_to_table(table_lg, name_knnr_lg, details_knnr_lg, k_knnr_lg)\nprint('\\nMODEL: ', name_knnr_lg, details_knnr_lg)\nprint_quality(k_knnr_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_knnr_lg_st = 'k-NN'\ndetails_knnr_lg_st = 'stat. sign. coef., k=12'\nknnr_lg_st = KNeighborsRegressor(n_neighbors=12)\nknnr_lg_st.fit(x_train_lg_st, y_train_lg)\nk_knnr_lg_st = model_quality_lg(knnr_lg_st, x_train_lg_st, y_train_lg, x_test_lg_st, y_test_lg)\nadd_to_table(table_lg, name_knnr_lg_st, details_knnr_lg_st, k_knnr_lg_st)\nprint('\\nMODEL: ', name_knnr_lg_st, details_knnr_lg_st)\nprint_quality(k_knnr_lg_st)\n##############################################################################################","77311dfd":"print(\"For original data:\")\ntable","f0e2f7a3":"print(\"For logarithmic data\")\ntable_lg","9b8d030a":"from sklearn.ensemble import RandomForestRegressor","267665fb":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_rf = 'Random Forest'\ndetails_rf = 'n_jobs=-1, n_estimators=55'\nrf = RandomForestRegressor(n_jobs=-1, n_estimators=55)\nrf.fit(x_train, y_train)\nk_rf = model_quality(rf, x_train, y_train, x_test, y_test)\nadd_to_table(table, name_rf, details_rf, k_rf)\nprint('MODEL: ', name_rf, details_rf)\nprint_quality(k_rf)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_rf_st = 'Random Forest'\ndetails_rf_st = 'stat. sign. coef., n_jobs=-1, n_estimators=55'\nrf_st = RandomForestRegressor(n_jobs=-1, n_estimators=55)\nrf_st.fit(x_train_st, y_train)\nk_rf_st = model_quality(rf_st, x_train_st, y_train, x_test_st, y_test)\nadd_to_table(table, name_rf_st, details_rf_st, k_rf_st)\nprint('\\nMODEL: ', name_rf_st, details_rf_st)\nprint_quality(k_rf_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_rf_lg = 'Random Forest'\ndetails_rf_lg = 'n_jobs=-1, n_estimators=55'\nrf_lg = RandomForestRegressor(n_jobs=-1, n_estimators=55)\nrf_lg.fit(x_train_lg, y_train_lg)\nk_rf_lg = model_quality_lg(rf_lg, x_train_lg, y_train_lg, x_test_lg, y_test_lg)\nadd_to_table(table_lg, name_rf_lg, details_rf_lg, k_rf_lg)\nprint('\\nMODEL: ', name_rf_lg, details_rf_lg)\nprint_quality(k_rf_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_rf_lg_st = 'Random Forest'\ndetails_rf_lg_st = 'stat. sign. coef., n_jobs=-1, n_estimators=55'\nrf_lg_st = RandomForestRegressor(n_jobs=-1, n_estimators=55)\nrf_lg_st.fit(x_train_lg_st, y_train_lg)\nk_rf_lg_st = model_quality_lg(rf_lg_st, x_train_lg_st, y_train_lg, x_test_lg_st, y_test_lg)\nadd_to_table(table_lg, name_rf_lg_st, details_rf_lg_st, k_rf_lg_st)\nprint('\\nMODEL: ', name_rf_lg_st, details_rf_lg_st)\nprint_quality(k_rf_lg_st)\n##############################################################################################","c54f9d67":"print(\"For original data:\")\ntable","9b66c7ef":"print(\"For logarithmic sets\")\ntable_lg","7525292f":"from xgboost import XGBRegressor","6e831cf2":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_xgbr = 'XGboost'\ndetails_xgbr = 'max_depth=4'\nxgbr = XGBRegressor(max_depth=4)\nxgbr.fit(x_train, y_train)\nk_xgbr = model_quality(xgbr, x_train, y_train, x_test, y_test)\nadd_to_table(table, name_xgbr, details_xgbr, k_xgbr)\nprint('MODEL: ', name_xgbr, details_xgbr)\nprint_quality(k_xgbr)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_xgbr_st = 'XGboost'\ndetails_xgbr_st = 'stat. sign. coef., max_depth=4'\nxgbr_st = XGBRegressor(max_depth=4)\nxgbr_st.fit(x_train_st, y_train)\nk_xgbr_st = model_quality(xgbr_st, x_train_st, y_train, x_test_st, y_test)\nadd_to_table(table, name_xgbr_st, details_xgbr_st, k_xgbr_st)\nprint('\\nMODEL: ', name_xgbr_st, details_xgbr_st)\nprint_quality(k_xgbr_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_xgbr_lg = 'XGboost'\ndetails_xgbr_lg = 'max_depth=4'\nxgbr_lg = XGBRegressor(max_depth=4)\nxgbr_lg.fit(x_train_lg, y_train_lg)\nk_xgbr_lg = model_quality_lg(xgbr_lg, x_train_lg, y_train_lg, x_test_lg, y_test_lg)\nadd_to_table(table_lg, name_xgbr_lg, details_xgbr_lg, k_xgbr_lg)\nprint('\\nMODEL: ', name_xgbr_lg, details_xgbr_lg)\nprint_quality(k_xgbr_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_xgbr_lg_st = 'XGboost'\ndetails_xgbr_lg_st = 'stat. sign. coef., max_depth=4'\nxgbr_lg_st = XGBRegressor(max_depth=4)\nxgbr_lg_st.fit(x_train_lg_st, y_train_lg)\nk_xgbr_lg_st = model_quality_lg(xgbr_lg_st, x_train_lg_st, y_train_lg, x_test_lg_st, y_test_lg)\nadd_to_table(table_lg, name_xgbr_lg_st, details_xgbr_lg_st, k_xgbr_lg_st)\nprint('\\nMODEL: ', name_xgbr_lg_st, details_xgbr_lg_st)\nprint_quality(k_xgbr_lg_st)\n##############################################################################################","cd4e59d1":"print(\"For original data:\")\ntable","f4b4a6ae":"print(\"For logarithmic data\")\ntable_lg","955f562a":"from lightgbm import LGBMRegressor","c3caf8cf":"# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\nname_lgbmr = 'LightGBM'\ndetails_lgbmr = '-'\nlgbmr = LGBMRegressor()\nlgbmr.fit(x_train, y_train)\nk_lgbmr = model_quality(lgbmr, x_train, y_train, x_test, y_test)\nadd_to_table(table, name_lgbmr, details_lgbmr, k_lgbmr)\nprint('MODEL: ', name_lgbmr, details_lgbmr)\nprint_quality(k_lgbmr)\n##############################################################################################\n\n# \u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_lgbmr_st = 'LightGBM'\ndetails_lgbmr_st = 'stat. sign. coef.'\nlgbmr_st = LGBMRegressor()\nlgbmr_st.fit(x_train_st, y_train)\nk_lgbmr_st = model_quality(lgbmr_st, x_train_st, y_train, x_test_st, y_test)\nadd_to_table(table, name_lgbmr_st, details_lgbmr_st, k_lgbmr_st)\nprint('\\nMODEL: ', name_lgbmr_st, details_lgbmr_st)\nprint_quality(k_lgbmr_st)\n##############################################################################################\n\n\n# Regression for logarithmic sets\n\n# \u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430\u043c\u0438\nname_lgbmr_lg = 'LightGBM'\ndetails_lgbmr_lg = '-'\nlgbmr_lg = LGBMRegressor()\nlgbmr_lg.fit(x_train_lg, y_train_lg)\nk_lgbmr_lg = model_quality_lg(lgbmr_lg, x_train_lg, y_train_lg, x_test_lg, y_test_lg)\nadd_to_table(table_lg, name_lgbmr_lg, details_lgbmr_lg, k_lgbmr_lg)\nprint('\\nMODEL: ', name_lgbmr_lg, details_lgbmr_lg)\nprint_quality(k_lgbmr_lg)\n##############################################################################################\n\n# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b\nname_lgbmr_lg_st = 'LightGBM'\ndetails_lgbmr_lg_st = 'stat. sign. coef.'\nlgbmr_lg_st = LGBMRegressor()\nlgbmr_lg_st.fit(x_train_lg_st, y_train_lg)\nk_lgbmr_lg_st = model_quality_lg(lgbmr_lg_st, x_train_lg_st, y_train_lg, x_test_lg_st, y_test_lg)\nadd_to_table(table_lg, name_lgbmr_lg_st, details_lgbmr_lg_st, k_lgbmr_lg_st)\nprint('\\nMODEL: ', name_lgbmr_lg_st, details_lgbmr_lg_st)\nprint_quality(k_lgbmr_lg_st)\n##############################################################################################","3bd337bb":"print(\"For original data:\")\ntable","3adb03ce":"print(\"For logarithmic data\")\ntable_lg","502a9955":"We have 3 statistically significant features: `` sqft_living``, `` sqft_above`` and `` sqft_basement``. The value of the coefficient says how much the signal value will increase when the predictor increases by one unit.\n\n- `` `sqft_living``` - Living area sq. ft.\n- `` `sqft_above``` - Above area sq. ft.\n- `` `sqft_basement``` - Basement area sq. ft.","85e5eab5":"Delete the column 'id', it will not be needed.","1436f27f":"### Polynomial 2 degrees","c3df2ab4":"We determine the statistical significance of the regression coefficients.","64d54bf8":"## Multiple Regression","58e81f6e":"### Polynomial 3 degrees","22b67737":"We consider the quality of the model.","03675b56":"## Lognormal Distributions","72c4871c":"** Histograms **","cd0b0e3a":"** Correlation matrix **","1a6f7ed4":"** Dependence of the price on the living space of the house **","dff912b5":"## Data Distributions and Correlations","dc655424":"## XGBoost","17001d16":"Now we\u2019ll only model the statistically significant features.","da8f8547":"## Polynomial regression","cd44df6b":"** Classification of houses **","0b24a974":"**Functions**","028e820d":"## LightGBM","64e7658e":"## Houses on the map","cca2e667":"# Data analysis and visualization\n## General information","0fe0e907":"## Random Forest","abe9eeb7":"# Predicting house prices","cdc76497":"# House price predictions\n## Creating training and test sets","0c1a7dee":"Download the file and see what is in it.","93f57a3a":"We derive the regression coefficients from the method `` model.coef_`` and the free term from the method `` model.intercept_``.","92a8b25b":"## Linear coefficient analysis","3c801d79":"\u0414\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e \u0431\u044b \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0432 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0435 \u0434\u0430\u0442\u0443 \u043f\u0440\u043e\u0434\u0430\u0436\u0438 \u0434\u043e\u043c\u0430 - \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0435\u0435 \u0432 \u0434\u0435\u043d\u044c \u043e\u0442 \u043d\u0430\u0447\u0430\u043b\u0430 \u0433\u043e\u0434\u0430.","ef7359eb":"In this laptop, various regressors will be tested in order to determine how accurate they are for determining the price of houses.\n\n<b> Content: <\/b>\n\n<b> I. Data Analysis and Visualization <\/b>\n1. General information\n2. Data distribution and correlation\n3. Lognormal distributions\n\n<b> II. Houses on the map <\/b>\n\n<b> III. House Price Predictions <\/b>\n\n1. Creation of training and test sets\n2. Analysis of linear coefficients\n3. Multiple Regression\n4. Polynomial regression\n    * 4.1. 2nd degree polynomial\n    * 4.2. 3rd degree polynomial\n5. k-NN regression\n6. Random Forest\n7. XGBoost\n8. LightGBM","6adc623d":"## k-NN","f9b18c20":"** Tables **\n\nCreate tables in which we will record information for each regressor."}}