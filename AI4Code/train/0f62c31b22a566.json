{"cell_type":{"f8017adb":"code","343defd6":"code","ae2a0b38":"code","adeae2af":"code","25f9a02c":"code","1c0a1d26":"code","2a0c0da9":"code","1500cb09":"code","bf15bcd4":"code","b8ef031e":"code","8f39cf22":"code","27834ec1":"code","bf9f7f4b":"code","7ec994b3":"code","1dabbf3a":"code","d11f6923":"code","b28e6c33":"code","64d794f1":"code","01c5b852":"markdown","2c7fdebf":"markdown","658f72db":"markdown","844a957b":"markdown","4bf57ac3":"markdown","dc51f033":"markdown","697247b2":"markdown","7f7157a0":"markdown","71676883":"markdown"},"source":{"f8017adb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","343defd6":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","ae2a0b38":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_label = train_data.pop('label')\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","adeae2af":"train_label.value_counts().plot.bar()","25f9a02c":"print(train_data.shape)\ntrain_data = train_data.values.reshape(train_data.shape[0], 28, 28)\ntrain_data = train_data \/ 255.0\n\ntest_data = test_data.values.reshape(test_data.shape[0], 28,28)\ntest_data = test_data \/ 255.0","1c0a1d26":"fig = plt.figure(figsize=(6,8))\nfor i in range(1, 10):\n    fig.add_subplot(3,3,i)\n    plt.imshow(train_data[i],cmap='gray')\n    plt.grid(False)\n    plt.title(train_label[i])","2a0c0da9":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(128, activation = \"relu\"),\n    tf.keras.layers.Dense(10, activation = \"softmax\")\n])\nmodel.compile(optimizer = \"adam\", loss = tf.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\nhist = model.fit(train_data, train_label, epochs = 10)","1500cb09":"def plot_training(history):\n    fig, axs = plt.subplots(1,2,figsize=(16,5)) \n    axs[0].plot(history.history['accuracy'], 'c') \n    axs[0].set_title('Model Accuracy') \n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch') \n    axs[0].legend(['train', 'validate'], loc='upper left') \n    \n    axs[1].plot(history.history['loss'], 'c') \n    axs[1].set_title('Model Loss') \n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch') \n    axs[1].legend(['train', 'validate'], loc='upper right') \n    plt.show()\n","bf15bcd4":"print(hist.history)\nplot_training(hist)","b8ef031e":"test_result = model.predict_classes(test_data)\nfig = plt.figure(figsize=(6,8))\nfor i in range(1, 10):\n    image = test_data[i+10]\n    label = test_result[i+10]\n    fig.add_subplot(3,3,i)\n    plt.imshow(image,cmap='gray')\n    plt.grid(False)\n    plt.title(label)","8f39cf22":"train_data_cnn = train_data.reshape(-1, 28,28,1)\ntest_data_cnn = test_data.reshape(-1, 28,28,1)\n\ntrain_x, eval_x, train_y, eval_y = train_test_split(train_data_cnn,train_label,test_size=0.3,random_state=0)","27834ec1":"datagen = ImageDataGenerator(\n        rotation_range=10,\n        zoom_range=0.20,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n\n\ntrain_datagen = datagen.flow(train_x,train_y,batch_size=50)\neval_datagen = datagen.flow(eval_x,eval_y,batch_size=50) ","bf9f7f4b":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3,3), activation='relu', input_shape = (28,28,1)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPooling2D(2,2))\n\n\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPooling2D(2,2))\n\n\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPooling2D(2,2))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax')) ","7ec994b3":"model.summary()","1dabbf3a":"from tensorflow.keras.callbacks import EarlyStopping\nearlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')","d11f6923":"model.compile(optimizer = \"adam\", \n              loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])\nhist = model.fit(train_x, train_y, validation_data=(eval_x, eval_y), epochs=20, callbacks = [earlyStopping])","b28e6c33":"print(hist.history)\n","64d794f1":"test_result = model.predict_classes(test_data_cnn)\n\nlabels = []\nfor i in range(28000):\n    labels.append(test_result[i])\nindex = [i for i in range(1,28001)]\ndf = pd.DataFrame({'ImageId': index, 'Label': labels})\ndf.to_csv('\/kaggle\/working\/answer.csv', index = False)","01c5b852":"Model training visualization","2c7fdebf":"Using CNN","658f72db":"Simple Neural Network for MNIST:\n\n1. Read the train and test data\n2. Data Preprocessing\n3. Data Visualization\n4. Model Creation\n5. Model Training\n6. Model Evaluation\n7. Evaluation result visualization\n8. Create a CNN model\n9. Train the model\n8. Submission","844a957b":"Model creation\n1. input size (28 X 28)","4bf57ac3":"Generate the submission csv","dc51f033":"Data Visualization using matplotlib\n- title is the label","697247b2":"test evaluation and visualization","7f7157a0":"pre processing the data","71676883":"Read the csv\ncreate train and test data."}}