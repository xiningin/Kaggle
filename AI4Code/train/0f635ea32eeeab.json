{"cell_type":{"d0750e7f":"code","d12524c1":"code","2720f77a":"code","b3b20def":"code","cc373834":"code","eaf7ea3c":"markdown"},"source":{"d0750e7f":"# for cpu and gpu\n! pip install --upgrade tensorflow","d12524c1":"%load_ext tensorboard\nimport os\nfrom glob import glob\nimport time\nimport random\n\nimport IPython.display as display\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nimport PIL\nfrom PIL import Image\nimport imageio\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import Input\nfrom keras.layers import (Activation, BatchNormalization, Concatenate, Dense, Dropout,\n                          Embedding, Flatten, Input, multiply, Reshape, ZeroPadding2D)\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers.advanced_activations import LeakyReLU, ReLU\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom sklearn.preprocessing import OrdinalEncoder\n%matplotlib inline","2720f77a":"tf.__version__","b3b20def":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","cc373834":"class CGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.n_classes = 10\n        self.noise_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.make_discriminator_model()\n        self.discriminator.compile(loss=['binary_crossentropy'],\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.make_generator_model()\n\n        # The generator takes noise and the target label as input\n        # and generates the corresponding digit of that label\n        noise = Input(shape=(self.noise_dim,))\n        label = Input(shape=(1,))\n        img = self.generator([noise, label])\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated image as input and determines decision\n        # and the label of that image\n        real = self.discriminator([img, label])\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains generator to fool discriminator\n        self.combined = Model([noise, label], real)\n        self.combined.compile(loss=['binary_crossentropy'],\n            optimizer=optimizer)\n\n    def make_generator_model(self):\n\n        model = Sequential()\n\n        model.add(Dense(256, input_dim=self.noise_dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n\n        model.summary()\n\n        noise = Input(shape=(self.noise_dim,))\n        label = Input(shape=(1,), dtype='int32')\n        label_embedding = Flatten()(Embedding(self.n_classes, self.noise_dim)(label))\n\n        model_input = multiply([noise, label_embedding])\n        img = model(model_input)\n\n        return Model([noise, label], img)\n\n    def make_discriminator_model(self):\n\n        model = Sequential()\n\n        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n\n        img = Input(shape=self.img_shape)\n        label = Input(shape=(1,), dtype='int32')\n\n        label_embedding = Flatten()(Embedding(self.n_classes, np.prod(self.img_shape))(label))\n        flat_img = Flatten()(img)\n\n        model_input = multiply([flat_img, label_embedding])\n\n        decision = model(model_input)\n\n        return Model([img, label], decision)\n\n    def train(self, epochs, batch_size=128, sample_interval=50):\n\n        # Load the dataset\n        (train_image, train_label), (_, _) = tf.keras.datasets.mnist.load_data()\n\n        # Configure input\n        train_image = (train_image.astype(np.float32) - 127.5) \/ 127.5\n        train_image = np.expand_dims(train_image, axis=3)\n        train_label = train_label.reshape(-1, 1)\n\n        # Adversarial ground truths\n        real = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, train_image.shape[0], batch_size)\n            imgs, labels = train_image[idx], train_label[idx]\n\n            # Sample noise as generator input\n            noise = np.random.normal(0, 1, (batch_size, 100))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict([noise, labels])\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch([imgs, labels], real)\n            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Condition on labels\n            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch([noise, sampled_labels], real)\n\n            # Plot the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save generated image samples\n            if epoch % sample_interval == 0:\n                self.sample_images(epoch)\n\n    def sample_images(self, epoch):\n        r, c = 2, 5\n        noise = np.random.normal(0, 1, (r * c, 100))\n        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n\n        gen_imgs = self.generator.predict([noise, sampled_labels])\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n                axs[i,j].set_title(\"Digit: {}\".format(sampled_labels[cnt]))\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"images{}.png\".format(epoch))\n        plt.close()\n\n\nif __name__ == '__main__':\n    cgan = CGAN()\n    cgan.train(epochs=50000, batch_size=32, sample_interval=5000)","eaf7ea3c":"# Please give an upvoe if you feel it is useful\n\n### plaese check other notebooks \n\n* [DCGAN with MNIST ](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-gp-with-mnist-for-absolute-beginners)\n\n* [DCGAN with Cifar10](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-cifar10-for-absolute-beginners)\n\n* [DCGAN with fashion MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-fashion-mnist-for-absolute-beginners)\n\n* [DCGAN with parasitized cell images](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-medical-images-for-absolute-beginners)\n\n* [WGAN with MNIST](http:\/\/https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-with-fashion-mnist-for-absolute-beginners)\n\n* [WGAN-GP with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-gp-with-mnist-for-absolute-beginners)\n\n* This one is a copied-and-modified version of works by Erik Linder-Nor\u00e9n of Apple"}}