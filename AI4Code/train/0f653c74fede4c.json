{"cell_type":{"508a2d7a":"code","92bc740f":"code","22a47c3c":"code","7f318c45":"code","903564ec":"code","ef693c13":"code","0a2cdb5f":"code","fb1fa975":"code","817c398e":"code","7caa1963":"code","feccef36":"code","c2f50d20":"code","f6584539":"code","2c4ca389":"code","73a7422e":"code","0a67088a":"code","356eb22f":"code","ca9e3e0a":"markdown","edb13172":"markdown","6d02d123":"markdown","4b3aef28":"markdown","a8966533":"markdown","a02f7dbf":"markdown","702f8b6a":"markdown","ed1db0e8":"markdown","51c2fdfb":"markdown"},"source":{"508a2d7a":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","92bc740f":"sonar_data = pd.read_csv(\"..\/input\/mines-vs-rocks\/sonar.all-data.csv\", header=None)","22a47c3c":"sonar_data.head()","7f318c45":"sonar_data.describe()","903564ec":"sonar_data[60].value_counts()","ef693c13":"X = sonar_data.iloc[:,:-1].values\ny = sonar_data.iloc[:,-1].values\n\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)","0a2cdb5f":"print(\"Features:\\n\", X, \"\\n\")\nprint(\"Labels:\\n\", y, \"\\n\")","fb1fa975":"X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, random_state=0, test_size=0.15, stratify=y)\n\nprint(\"Training Set Size:\", len(X_train))\nprint(\"Testing Set Size:\", len(X_test))","817c398e":"models = {\n    \"svm_linear\": {\n        \"instance\": SVC(probability=True, gamma=\"auto\"),\n        \"params\": {\n            \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n            \"kernel\": [\"linear\"]\n        }\n    },\n    \"svm_rbf\": {\n        \"instance\": SVC(probability=True),\n        \"params\": {\n            \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n            \"kernel\": [\"rbf\"],\n            \"gamma\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n        }\n    },\n    \"logistic_regression\": {\n        \"instance\": LogisticRegression(max_iter=500),\n        \"params\": {\n            \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n        }\n    },\n    \"random_forest\": {\n        \"instance\": RandomForestClassifier(),\n        \"params\": {\n            \"n_estimators\": [1, 10, 100, 1000]\n        }\n    }\n}","7caa1963":"scores = []\nbest_estimators = {}\n\nfor model_name, config in models.items():\n    print(\"Training\", model_name)\n    classifier = GridSearchCV(\n        estimator=config[\"instance\"],\n        param_grid=config[\"params\"],\n        cv=5,\n        scoring=\"accuracy\"\n    )\n    \n    classifier.fit(X_train, y_train)\n    \n    scores.append({\n        \"model\" : model_name,\n        \"train_score\" : classifier.best_score_,\n        \"test_score\" : classifier.best_estimator_.score(X_test, y_test),\n        \"params\" : classifier.best_params_\n    })\n    \n    best_estimators[model_name] = classifier.best_estimator_","feccef36":"result = pd.DataFrame(scores, columns=[\"model\", \"train_score\", \"test_score\", \"params\"])\nresult.head()","c2f50d20":"result[\"average_score\"] = (result[\"test_score\"] + result[\"train_score\"]) \/ 2\nresult.head()","f6584539":"model = best_estimators[\"svm_rbf\"]","2c4ca389":"print(\"ACCURACY SCORE\")\nprint(\"Training Set:\", accuracy_score(y_true=y_train, y_pred=model.predict(X_train)))\nprint(\"Testing Set:\", accuracy_score(y_true=y_test, y_pred=model.predict(X_test)))","73a7422e":"print(\"CLASSIFICATION REPORT\")\nprint(classification_report(y_true=y_test, y_pred=model.predict(X_test)))","0a67088a":"matrix = confusion_matrix(y_true=y_test, y_pred=model.predict(X_test))\n\nplt.figure(figsize=(8,6))\nplt.xlabel(\"PREDICTED\")\nplt.ylabel(\"TRUTH\")\nsns.heatmap(matrix, annot=True)\nplt.show()","356eb22f":"predictions = pd.DataFrame(X_test)\n\npredictions[\"Real Type\"] = encoder.inverse_transform(y_test)\npredictions[\"Predicted Type\"] = encoder.inverse_transform(model.predict(X_test))\n\npredictions.to_csv(\"test_prediction_result.csv\", index=False)\n\npredictions.head(10)","ca9e3e0a":"### Model selection and hyper-parameter tuning using GridSearchCV","edb13172":"### Preparing training and testing set","6d02d123":"### Loading and analysing dataset","4b3aef28":"### Making predictions","a8966533":"### Model selection and evaluation","a02f7dbf":"SVM with RBF kernel, C as 10, and gamma as 0.3 happens to have the highest average score among the other models so we will select that as our model and proceed with further evalutation.","702f8b6a":"### Extracting features and labels","ed1db0e8":"### Machine Learning  Project #2 - Rock vs Mine Prediction","51c2fdfb":"### Importing Libraries"}}