{"cell_type":{"d9f23389":"code","03646200":"code","bf691a83":"code","ce149aae":"code","dd71b945":"code","54188eb5":"code","1eb8db12":"code","7cc7b8f0":"code","68b6d007":"code","6c348cf2":"code","18b091aa":"code","992058af":"code","8a3763ea":"code","8d07cdff":"code","14fcd7c6":"code","7811fb0d":"code","7e75911b":"code","a45f5d65":"code","00355ca7":"code","e51a83b2":"code","e7109d57":"code","f54c91f5":"markdown"},"source":{"d9f23389":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03646200":"df = pd.read_csv('..\/input\/fake-news\/train.csv')","bf691a83":"df.head()","ce149aae":"df.isnull().sum()","dd71b945":"df.dropna(axis=0, inplace=True)","54188eb5":"df.shape","1eb8db12":"df.reset_index(inplace=True)","7cc7b8f0":"X = df.drop('label', axis=1)\ny = df['label']","68b6d007":"message = X.copy()","6c348cf2":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nnltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer","18b091aa":"corpus = []\nfor i in range(0, len(message)): \n    review = re.sub('[^a-zA-Z0-9]', ' ', message.text[i])\n    review = review.lower()\n    review = review.split()\n    lem = WordNetLemmatizer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')\n    review = [lem.lemmatize(word) for word in review if not word in set(all_stopwords)]\n    review = ' '.join(review)\n    corpus.append(review)","992058af":"corpus[:10]","8a3763ea":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=7500)\nX_new = cv.fit_transform(corpus).toarray()","8d07cdff":"X_new","14fcd7c6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.25, random_state=2)","7811fb0d":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()","7e75911b":"clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred))","a45f5d65":"print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\nprint('ROC_AUC_Score:', metrics.roc_auc_score(y_test, y_pred))","00355ca7":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test, y_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, y_pred))\nprint('ROC_AUC_Score:', metrics.roc_auc_score(y_test, y_pred))","e51a83b2":"print('Training Score:', clf.score(X_train, y_train))\nprint('Test Score:', clf.score(X_test, y_test))","e7109d57":"from sklearn.linear_model import PassiveAggressiveClassifier\nclf_1 = PassiveAggressiveClassifier()\nclf_1.fit(X_train, y_train)\ny_pred = clf_1.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test, y_pred))\n\nprint('Accuracy:', metrics.accuracy_score(y_test, y_pred))\nprint('ROC_AUC_Score:', metrics.roc_auc_score(y_test, y_pred))\n\nprint('Training Score:', clf_1.score(X_train, y_train))\nprint('Test Score:', clf_1.score(X_test, y_test))","f54c91f5":"#### The Model is performing great with Passive Aggressive Classifier\n## The Model has overfit a very little here. But, that is still fine. \n'''[[2429  138]\n    [ 132 1873]]\nAccuracy: 0.9409448818897638\nROC_AUC_Score: 0.9402026682417447\nTraining Score: 0.9999270764967549\nTest Score: 0.9409448818897638'''"}}