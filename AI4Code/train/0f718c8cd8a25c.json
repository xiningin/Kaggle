{"cell_type":{"fbd54bdc":"code","be690a31":"code","3f596721":"code","0258f3a9":"code","9c9812b4":"code","a49d5e26":"code","7977718c":"code","16722ca6":"code","8de47de1":"code","52aa24ee":"code","87d1813a":"code","062968a1":"code","c4e53836":"code","7a349ab2":"code","b4cffbbe":"code","bbcff034":"code","c4aaa0e2":"code","12f91e57":"code","67adb7b9":"code","1eb0648b":"code","eeb62840":"code","7c025310":"code","e97abd8c":"code","16bc7a98":"code","a8d510c0":"code","bb2069c7":"code","93885b6a":"code","7d733ca6":"code","e0686fc2":"code","1f0e7847":"markdown","ac265555":"markdown","f23de17b":"markdown","004da39e":"markdown","0b8af41b":"markdown","717f0567":"markdown","a13983db":"markdown","d3a334ad":"markdown","1b7661be":"markdown","646788ec":"markdown","93beacd6":"markdown","54a46d2b":"markdown","50fe8c90":"markdown","90177c8d":"markdown","ceca3cf0":"markdown","81554b43":"markdown","4edc9233":"markdown","3bd7bd55":"markdown","bbc19790":"markdown","bdf96f5e":"markdown","9d35fba6":"markdown"},"source":{"fbd54bdc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","be690a31":"# Load in the train and test datasets\ndef readData():\n    train = pd.read_csv('..\/input\/titanic\/train.csv')\n    test = pd.read_csv('..\/input\/titanic\/test.csv')\n    print('Training size: ' , train.shape)\n    print('Test size: ' , test.shape)\n    \n    return train, test\n\ndef create_df(df,df2):\n    df = df.append(df2, ignore_index=True, sort=False)\n    print('df size: ' , df.shape)\n    return df\n\ntrain, test = readData()\n# Get some useful info \npas_id = test['PassengerId']\ny = train['Survived']\n\n# apand train and test\ndf = create_df(train,test)\ndf.head()","3f596721":"# Explore Target\ndef target_info(y):\n    sns.catplot(data=train,kind='count',x='Survived',hue='Survived')\n    print('Percentance of Survivors: ' , (sum(y) \/ len(y)) *100 , '%') \n    \ntarget_info(train.Survived)","0258f3a9":"# Missing values by columns\ndef missing_values_info(df,which_dataset):\n    print(\"Percentance of Missing Values Per Columns in \" + which_dataset + \" dataset.\")\n    print(\"------------------------------------------\")\n    print((df.isnull().sum() \/ df.shape[0]) * 100)\nmissing_values_info(train,\"train\")\nmissing_values_info(test,\"test\")\nmissing_values_info(df,\"all_data\")","9c9812b4":"# What about Survived with non nan Cabin values\ndef cabin_process1(df): # Feature Engineering\n    # Create a new feature with only the first letter of Cabin\n    df['Cabin'] = df['Cabin'].astype(str).str[0]\n    return df\n    \ndef plot_Cabin1(df):\n    # Plot new Cabin\n    sns.catplot(data=df,kind='count',x='Cabin',hue='Survived')\n    print('Cabin equal to \"n\" are the nan values of Cabin')\n\n    \ndf = cabin_process1(df)\nplot_Cabin1(df)\n","a49d5e26":"def cabin_process2(df): # Feature Engineering\n    # Create a new feature Cobin \/ Not Cabin\n    df['Cabin_or_not'] = np.where(df['Cabin'] == 'n', 0, 1)\n    return df\n\ndef plot_Cabin2(df):\n    # Plot new Cabin\n    sns.catplot(data=df,kind='count',x='Cabin_or_not',hue='Survived')\n\ndf = cabin_process2(df)\nplot_Cabin2(df)\ndel df['Cabin']","7977718c":"# Hanndle Age Missing values with 2 different ways:\n# 1. Replace by mean\/median of the same class\n# 2. Regression\ndef process_age(df):\n\n    df['Age'] = df['Age'].fillna(100)\n    return df\ndf = process_age(df)\ndf.groupby(\"Survived\").Age.hist(alpha=0.6)\n","16722ca6":"df.Embarked.describe()","8de47de1":"# fill Nan with most important values\ndef Embarked_process(df):\n    df.Embarked = df.Embarked.fillna(df.Embarked.value_counts().idxmax())\n    return df\ndf = Embarked_process(df)\n# See Embarked based on target\nsns.catplot(data=df,kind='count',x='Embarked',hue='Survived')","52aa24ee":"# Same tickets\ndef create_same_tickets(df):\n    df['same_ticket'] = df.groupby(['Ticket'])['PassengerId'].transform(\"count\")\n    df['same_ticket'] = np.where( df['same_ticket'] == 1 , 0, 1)\n    return df\ndf = create_same_tickets(df)\nsns.catplot(data=df,kind='count',x='same_ticket',hue='Survived')","87d1813a":"\n\ndef process_Ticket1(train):\n\n    train['Ticket_as_str'] = train.Ticket.str.replace('\\d+', '')\n\n\n    train.Ticket_as_str = np.where( (train.Ticket_as_str == 'SOTON\/O.Q. ') | \n                                   (train.Ticket_as_str == 'STON\/O. ') | \n                                   (train.Ticket_as_str == 'STON\/O . ') | \n                                   (train.Ticket_as_str == 'S.O.C. ') |\n                                   (train.Ticket_as_str == 'SO\/C ') |\n                                   (train.Ticket_as_str == 'STON\/OQ. ') |\n                                   (train.Ticket_as_str == 'CA ') |\n                                    (train.Ticket_as_str == 'CA. ') | \n                                   (train.Ticket_as_str == 'C.A.\/SOTON ') |\n                                   (train.Ticket_as_str == 'C ') |\n                                   (train.Ticket_as_str == 'C.A. ') |\n                                   (train.Ticket_as_str == 'SOTON\/O '), 'SOTON\/OQ ', train.Ticket_as_str)\n\n    train.Ticket_as_str = np.where( (train.Ticket_as_str == 'A\/. ') | \n                                   (train.Ticket_as_str == 'A.\/. ') | \n                                   (train.Ticket_as_str == 'A.. ') | \n                                   (train.Ticket_as_str == 'A\/S ') | \n                                   (train.Ticket_as_str == 'AQ\/. ') | \n                                   (train.Ticket_as_str == 'AQ\/ ') |\n                                   (train.Ticket_as_str == 'A. . ') | \n                                   (train.Ticket_as_str == 'A\/ '), 'A. ', train.Ticket_as_str)\n\n\n    train.Ticket_as_str = np.where((train.Ticket_as_str == 'PC ') | (train.Ticket_as_str == 'F.C.C. ') | (train.Ticket_as_str == 'Fa '), 'F.C. ', train.Ticket_as_str)\n\n    train.Ticket_as_str = np.where((train.Ticket_as_str == 'W.\/C. ') \n                                   | (train.Ticket_as_str == 'WE\/P ') |\n                                   (train.Ticket_as_str == 'W.E.P. '), 'W\/C ', train.Ticket_as_str)\n\n    train.Ticket_as_str = np.where( (train.Ticket_as_str == 'S.C.\/A.. ') | \n                                   (train.Ticket_as_str == 'SC\/AH Basle ') |\n                                   (train.Ticket_as_str == 'SC\/AH ') |\n                                   (train.Ticket_as_str == 'S.C.\/PARIS ') | \n                                   (train.Ticket_as_str == 'SC\/Paris ') |\n                                   (train.Ticket_as_str == 'SC\/PARIS ') |\n                                   (train.Ticket_as_str == 'SC\/A ') |\n                                   (train.Ticket_as_str == 'SC\/A. ') |\n                                   (train.Ticket_as_str == 'SCO\/W ') |\n                                    (train.Ticket_as_str == 'SC' ) |\n                                   (train.Ticket_as_str == 'S.O.\/P.P. ') | \n                                   (train.Ticket_as_str == 'SW\/PP ') |\n                                   (train.Ticket_as_str == 'S.W.\/PP ') |\n                                   (train.Ticket_as_str == 'S.P. ') | \n                                    (train.Ticket_as_str == 'SC ') | \n                                   (train.Ticket_as_str == 'P\/PP ') |\n                                   (train.Ticket_as_str == 'LP ') |\n                                   (train.Ticket_as_str == 'S.O.P. '), 'PP ', train.Ticket_as_str)\n\n\n    return df\n\ndf = process_Ticket1(df)\nprint(df.Ticket_as_str.unique())\nax = sns.catplot(data=df,kind='count',x='Ticket_as_str',hue='Survived', height=5.27, aspect=11.7\/8.27)\n","062968a1":"def process_Ticket2(train):\n\n\n    train.Ticket_as_str = np.where( (train.Ticket_as_str == 'A. ') | \n                                   (train.Ticket_as_str == 'PP ') | \n                                   (train.Ticket_as_str == 'W\/C ') | \n                                   (train.Ticket_as_str == 'LINE'), 'SOTON\/OQ ', train.Ticket_as_str)\n    \n    return df\n\ndf = process_Ticket2(df)\nprint(df.Ticket_as_str.unique())\nax = sns.catplot(data=df,kind='count',x='Ticket_as_str',hue='Survived', height=5.27, aspect=11.7\/8.27)","c4e53836":"def process_Ticket3(train):\n    train.Ticket_as_str = np.where((train.Ticket_as_str == ''), 'SOTON\/OQ ', train.Ticket_as_str)\n    return df\n\ndf = process_Ticket3(df)\nprint(df.Ticket_as_str.unique())\nax = sns.catplot(data=df,kind='count',x='Ticket_as_str',hue='Survived', height=5.27, aspect=11.7\/8.27)","7a349ab2":"#Name \ndef process_name(df):\n    #Keep only surname\n    df['newName'] = df.Name.str.split(',').str[0]\n    # fit with ticket in order to find the family members\n    df['family_members'] = df.groupby(['newName','Ticket'])['PassengerId'].transform(\"count\")\n    del df['newName']\n    del df['Name']\n    del df['Ticket']\n    return df\ndf = process_name(df)\n# SibSp\nsns.catplot(data=df ,kind='count',x='family_members',hue='Survived')","b4cffbbe":"#Name \ndef process_name(df):\n    #Keep only surname\n    # fit with ticket in order to find the family members\n    df['family_members'] = np.where(df['family_members'] == 1, 0,df['family_members'])\n    df['family_members'] = np.where(df['family_members'] > 4, 5,df['family_members'])\n    df['family_members'] = np.where((df['family_members'] > 0) & (df['family_members'] < 5), 1,df['family_members'])\n    df['family_members'] = df['family_members'].map({0:'Alone', 1:'Family', 5:'Big_Family'})\n    return df\ndf = process_name(df)\n# SibSp\nsns.catplot(data=df ,kind='count',x='family_members',hue='Survived')","bbcff034":"def process_SibSp(df):    \n    df['SibSp_more_survivors'] = np.where(df['SibSp'] == 1 , 1 , 0)\n    df['SibSp_more_survivors'].describe()\n    del df['SibSp']\n    return df\ndf = process_SibSp(df)\n# SibSp\nsns.catplot(data=df ,kind='count',x='SibSp_more_survivors',hue='Survived')","c4aaa0e2":"def process_parch(df):\n    df['Parch_more_survivors'] = np.where((df['Parch'] == 1) | (df['Parch']  == 2 ), 1 , 0)\n    df['Parch_more_survivors'].describe()\n    del df['Parch']\n    return df\n\ndf = process_parch(df)\n# Parch\nsns.catplot(data=df ,kind='count',x='SibSp_more_survivors',hue='Survived')","12f91e57":"#Map Sex\ndef process_sex(df):\n    df['Sex'] = df['Sex'].map({'male':1,'female':0})\n    return df\ndf = process_sex(df)\nsns.catplot(data=df ,kind='count',x='Sex',hue='Survived')","67adb7b9":"# Replace Missing Ages with mean\ndef replace_with_avg_fare(df):\n    df['Fare'] = df['Fare'].fillna(0)\n    return df\n\ndf = replace_with_avg_fare(df)\ndf.groupby(\"Survived\").Fare.hist(alpha=0.6)\n","1eb0648b":"del df['PassengerId']\ndf = pd.get_dummies(df)","eeb62840":"def normalize(df):\n    features = df.columns.values\n    for feature in features:\n        mean, std = df[feature].mean(), df[feature].std()\n        df[feature] = (df[feature] - mean) \/ std \n    return df\n\ndf = normalize(df)","7c025310":"#Data Model\ntrain = df[df.Survived.notnull()]\ntest = df[df.Survived.isnull()]\ndel train['Survived']\ndel test['Survived']","e97abd8c":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor_df = df\ncor_df['y'] = y\ncor = cor_df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","16bc7a98":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(train)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\n\nfinalDf = pd.concat([principalDf, y], axis = 1)\n\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 19)\nax.set_ylabel('Principal Component 2', fontsize = 19)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [1, 0]\ncolors = ['r', 'g']\nfor target, color in zip(targets,colors):\n    indicesToKeep = finalDf['Survived'] == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n               , finalDf.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","a8d510c0":"from sklearn.linear_model import LassoCV\n\nreg = LassoCV()\nreg.fit(train, y)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(train,y))\ncoef = pd.Series(reg.coef_, index = train.columns)\n\nimp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","bb2069c7":"best_features = ['Sex', 'Pclass','family_members_Big_Family','Age','Embarked_S','Parch_more_survivors','Fare','Cabin_or_not','family_members_Family']\ntrain = train[best_features]\ntest = test[best_features]","93885b6a":"\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\ndepth = []\npreds = []\npreds_tr = []\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.4)\nmin_depth = 1\nmax_depth = 30\nfor i in range(min_depth,max_depth):\n    clf = DecisionTreeClassifier(max_depth=i)\n    clf = clf.fit(X_train,y_train)\n    depth.append((i,clf.score(X_test,y_test)))\n    preds.append(clf.predict(X_test).astype(int))\n    preds_tr.append(clf.predict(X_train).astype(int))\n\n# Error Analysis\nfrom sklearn.metrics import f1_score\n\nx_axis_cv = []\nx_axis_tr = []\ny_axis_cv = []\ny_axis_tr = []\nmax_score = 0\nd = -1\nfor i in range(len(preds)):\n    f1_cv = f1_score(y_test, preds[i], average='macro')\n    f1_tr = f1_score(y_train, preds_tr[i], average='macro')\n    if (f1_cv > max_score):\n        d = depth[i][0]\n        max_score = f1_cv\n    x_axis_cv.append(depth[i][0])\n    x_axis_tr.append(depth[i][0])\n    y_axis_cv.append(f1_cv)\n    y_axis_tr.append(f1_tr)\n \nplt.plot(x_axis_cv,y_axis_cv, 'g-',label='cross validation')\nplt.plot(x_axis_tr,y_axis_tr, 'r-',label='training')\nplt.xlabel ('depth')\nplt.ylabel ('f1 Score')\nplt.title('F1 score based on \"max_depth\" hyperparameter')\nplt.legend()\n\n# Final Run\ndtree = DecisionTreeClassifier(max_depth=d)\ndtree.fit(train,y)\ndt_predictions = dtree.predict(test).astype(int)\n\n#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':pas_id,'Survived':dt_predictions})\n\n#Visualize the first 5 rows\nsubmission.head()\n\nfilename = 'dt_predictions.csv'\n\nsubmission.to_csv(filename,index=False)","7d733ca6":"#SVM\nfrom sklearn.svm import SVC\n\nc_hyper = []\npreds = []\npreds_tr = []\n\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.4)\n\nmin_c = 1\nmax_c = 100\nfor i in range(min_c,max_c):\n    clf = SVC(gamma=0.05,C = i\/20)\n    clf = clf.fit(X_train,y_train)\n    c_hyper.append((i\/20,clf.score(X_test,y_test)))\n    preds.append(clf.predict(X_test).astype(int))\n    preds_tr.append(clf.predict(X_train).astype(int))\n\n# Error Analysis\nfrom sklearn.metrics import f1_score\n\nx_axis_cv = []\ny_axis_cv = []\nx_axis_tr = []\ny_axis_tr = []\nmax_score = 0\nc = -1\nfor i in range(len(preds)):\n    f1_cv = f1_score(y_test, preds[i], average='macro')\n    f1_tr = f1_score(y_train, preds_tr[i], average='macro')\n    if (f1_cv > max_score):\n        c = c_hyper[i][0]\n        max_score = f1_cv\n    x_axis_cv.append(c_hyper[i][0])\n    y_axis_cv.append(f1_cv)\n    x_axis_tr.append(c_hyper[i][0])\n    y_axis_tr.append(f1_tr)\n    \n \nplt.plot(x_axis_cv,y_axis_cv, 'g-',label='cross validation')\nplt.plot(x_axis_tr,y_axis_tr, 'r-',label='training')\nplt.xlabel ('C')\nplt.ylabel ('f1 Score')\nplt.title('F1 score based on \"C \" hyperparameter')\nplt.legend()\n\n\n\n# Final Run\nclf = SVC(gamma=0.05,C = c)\nclf = clf.fit(train,y)\nsvm_predictions = clf.predict(test).astype(int)\n\n#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':pas_id,'Survived':svm_predictions})\n\n#Visualize the first 5 rows\nsubmission.head()\n\nfilename = 'svm_predictions.csv'\n\nsubmission.to_csv(filename,index=False)","e0686fc2":"#XGBoost\nimport xgboost as xgb\n\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.4)\nl_hyper = []\npreds = []\npreds_tr = []\n\nmin_c = 1\nmax_c = 100\nfor i in range(min_c,max_c):\n    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42,learning_rate=i\/100, n_estimators=500)\n    xgb_model.fit(X_train, y_train)\n    l_hyper.append((i\/100,xgb_model.score(X_test,y_test)))\n    preds.append(xgb_model.predict(X_test).astype(int))\n    preds_tr.append(xgb_model.predict(X_train).astype(int))\n\n# Error Analysis\nfrom sklearn.metrics import f1_score\n\nx_axis_cv = []\ny_axis_cv = []\nx_axis_tr = []\ny_axis_tr = []\nmax_score = 0\nl = -1\nfor i in range(len(preds)):\n    f1_cv = f1_score(y_test, preds[i], average='macro')\n    f1_tr = f1_score(y_train, preds_tr[i], average='macro')\n    if (f1_cv > max_score):\n        l = l_hyper[i][0]\n        max_score = f1_cv\n    x_axis_cv.append(l_hyper[i][0])\n    y_axis_cv.append(f1_cv)\n    x_axis_tr.append(l_hyper[i][0])\n    y_axis_tr.append(f1_tr)\n    \n \nplt.plot(x_axis_cv,y_axis_cv, 'g-',label='cross validation')\nplt.plot(x_axis_tr,y_axis_tr, 'r-',label='training')\nplt.xlabel ('learning rate')\nplt.ylabel ('f1 Score')\nplt.title('F1 score based on \"lambda regularization \" hyperparameter')\nplt.legend()\n\n\n\n# Final Run\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42,learning_rate=l, n_estimators=500)\nxgb_model.fit(train, y)\nxgboost_predictions = clf.predict(test).astype(int)\n\n#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':pas_id,'Survived':xgboost_predictions})\n\n#Visualize the first 5 rows\nsubmission.head()\n\nfilename = 'xgboost_predictions.csv'\n\nsubmission.to_csv(filename,index=False)","1f0e7847":"### Embarked","ac265555":"#### AGE","f23de17b":"#### Fare","004da39e":"## XGBoost","0b8af41b":"#### Ticket","717f0567":"### Data Normalization","a13983db":"### Target","d3a334ad":"### PCA - Visualize the Data","1b7661be":"### Lasso for Feature Selection","646788ec":"\n## Decission Tree\n","93beacd6":"#### SibSp","54a46d2b":"### Read The Data","50fe8c90":"## SVM","90177c8d":"#### Name","ceca3cf0":"### Pearson Correlation","81554b43":"### Handle Missing Values","4edc9233":"#### Parch","3bd7bd55":"### Data Model","bbc19790":"#### Sex","bdf96f5e":"# Predict Survived Using Decision Tree, SVM, XGBoost","9d35fba6":"#### Cabin"}}