{"cell_type":{"f20b385a":"code","1a35661e":"code","c3188f7a":"code","931d69ea":"code","6044370a":"code","472c44c1":"code","d8f6fdb2":"code","4f6e473b":"code","978334bb":"code","8ccd59dc":"code","9d042c90":"code","75056af3":"code","cbf099eb":"code","d24b2a8f":"code","d690d38d":"code","68d7514a":"code","ed2fb0a2":"code","2fb406fe":"code","05ba1b32":"code","587cfb47":"code","1641531c":"code","af036144":"code","fd33fd5b":"code","ce5dc579":"code","f4a87ab5":"code","2a209d37":"code","4223df0f":"code","aa7b2117":"code","5fc82747":"markdown","ec1ea824":"markdown","79c949cc":"markdown","54b05bcd":"markdown","354b0a23":"markdown","b3e62984":"markdown","e851bd42":"markdown","05796c93":"markdown","1c00cc6c":"markdown","8a10818a":"markdown","4f26423a":"markdown","405326fe":"markdown","c74f2af4":"markdown","66e12e2a":"markdown","55968dd7":"markdown","de72ac25":"markdown","07b335ae":"markdown","ae93c14e":"markdown","51db31c1":"markdown","8380098a":"markdown","567f449f":"markdown","693fd625":"markdown","89e61a44":"markdown","009737c8":"markdown","401e00e7":"markdown","13b1ffa2":"markdown","bb6ece15":"markdown","37288324":"markdown","5061f7f5":"markdown","bc366b2a":"markdown","e4129dbe":"markdown","7385aa20":"markdown","8d7cd28a":"markdown"},"source":{"f20b385a":"import os\nimport pandas as pd\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1a35661e":"# view first rows of stories table\nfrom google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# Construct a reference to the \"stories\" table\ntable_ref_stories = dataset_ref.table(\"stories\")\n\n# API request - fetch the table\ntable_stories = client.get_table(table_ref_stories)\n\n# Preview the first five lines of the \"stories\" table\nclient.list_rows(table_stories, max_results=5).to_dataframe()","c3188f7a":"table_stories.schema","931d69ea":"# Construct a reference to the \"comments\" table\ntable_ref_comments = dataset_ref.table(\"comments\")\n\n# API request - fetch the table\ntable_comments = client.get_table(table_ref_comments)\n\n# Preview the first five lines of the \"comments\" table\nclient.list_rows(table_comments, max_results=5).to_dataframe()","6044370a":"table_comments.schema","472c44c1":"# look at the parent_id column in the comments table\n# then search for parent_ids who does not represent a comment_id in the comments table\n# if this results are no empty, it means parent column represent parend comment id and one another id\nquery_for_id_selection = \"\"\" \n                            SELECT DISTINCT(parent)\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            WHERE parent NOT IN (\n                                                    SELECT id\n                                                    FROM `bigquery-public-data.hacker_news.comments`)\n            \n\"\"\"\n# set quota not to exceed limits\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n\n# create job to execute query\nquery_for_id_selection_job = client.query(query_for_id_selection, job_config=safe_config)\n\n#load results into a dataframe\nquery_for_id_result = query_for_id_selection_job.to_dataframe()\n\n# turn dataframe to a a series, then list, then list of strings to use in the query\nnon_comment_ids = \",\".join(map(str,query_for_id_result.head(20).parent.tolist()))","d8f6fdb2":"# function to write query results to a dataframe\n# without exceeding the 1 GB quota per query\ndef query_to_dataframe(query_name):\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n    query_name_job = client.query(query_name, job_config=safe_config)\n    return query_name_job.to_dataframe()","4f6e473b":"print(\"Number of parent_ids that are not comment_ids:\", query_for_id_result.parent.nunique())","978334bb":"non_comment_ids","8ccd59dc":"# are parent_ids that does not represent a comment_id, do they belong to a story?\nnon_comment_id_query = \"\"\" \n                            SELECT *\n                            FROM `bigquery-public-data.hacker_news.stories` AS stories\n                            WHERE id IN ({})\n                    \"\"\".format(non_comment_ids)\n\n# print query results\nquery_to_dataframe(non_comment_id_query).head()","9d042c90":"# look at parent id row 4318042 to see how many comments are dependant on it\n# in the stories table, number of  descendants are 113\nquery_number_of_comments = \"\"\"\n                            SELECT *\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            WHERE parent = 4318042\n\"\"\"\n\nprint(\"Number of comments that story 4318042 has:\", len(query_to_dataframe(query_number_of_comments)))\n# it did not give 122 rows because of the tree structure.\n# it only give the first level comment id which is 12.","75056af3":"id_query = \"\"\" \n                SELECT id\n                FROM `bigquery-public-data.hacker_news.stories`\n                WHERE id IN (\n                            SELECT id\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            )\n\"\"\"\n\nquery_to_dataframe(id_query)","cbf099eb":"# to have a look we are going to count the number of comments and posts created \n# for not deleted and dead ones\nactive_users_query = \"\"\"\n                        WITH active_users_from_stories AS (\n                            SELECT author,\n                                COUNT(*) AS number_of_stories\n                            FROM `bigquery-public-data.hacker_news.stories`\n                            WHERE deleted IS NOT TRUE AND dead IS NOT TRUE\n                            GROUP BY author\n                            ORDER BY number_of_stories DESC\n                        ),\n                        active_users_from_comments AS (\n                            SELECT author,\n                                COUNT(*) AS number_of_comments\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            WHERE deleted IS NOT TRUE AND dead IS NOT TRUE\n                            GROUP BY author\n                            ORDER BY number_of_comments DESC\n                        )\n                        SELECT active_users_from_comments.author,\n                            number_of_stories,\n                            number_of_comments\n                        FROM active_users_from_stories\n                        FULL JOIN active_users_from_comments\n                         ON active_users_from_stories.author = active_users_from_comments.author\n                        ORDER BY number_of_stories DESC\n                        LIMIT 10\n\"\"\"\n# if you change last ORDER BY clause to number_of_comments will list the users who commented most\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nactive_users_query_job = client.query(active_users_query, job_config=safe_config)\nactive_users_query_result = active_users_query_job.to_dataframe()\nactive_users_query_result","d24b2a8f":"# look at the total number of stories in the whole hackernews which is not dead or deleted\ntotal_stories = \"\"\"\n                    SELECT COUNT(id)\n                    FROM `bigquery-public-data.hacker_news.stories`\n                    WHERE deleted IS NOT TRUE AND dead IS NOT TRUE\n\"\"\"\ntotal_stories_df = client.query(total_stories).result().to_dataframe()\n\npercentage = active_users_query_result.number_of_stories.sum()\/total_stories_df.f0_.iloc[0]\n\nprint(\"Most active users in terms of number of stories created have created the {} of the whole stories\"\n      .format(round(percentage,2)))","d690d38d":"# before providing an answer to this question investigate and understand full table\n\n# Construct a reference to the \"full\" table\ntable_ref_full = dataset_ref.table(\"full\")\n\n# API request - fetch the table\ntable_full = client.get_table(table_ref_full)\n\n# Preview the first five lines of the \"full\" table\nclient.list_rows(table_full, max_results=5).to_dataframe()","68d7514a":"# if those keywords occur in the full table's text or title column we can say they got covered\ncoverage_query = \"\"\"WITH startup_ranking_score AS (\n                    SELECT CASE \n                        WHEN title LIKE \"%Airbnb%\" OR text LIKE \"%Airbnb%\" THEN \"Airbnb\"\n                        WHEN title LIKE \"%Stripe%\" OR text LIKE \"%Stripe%\" THEN \"Stripe\"\n                        WHEN title LIKE \"%Dropbox%\" OR text LIKE \"%Dropbox%\" THEN \"Dropbox\"\n                        WHEN title LIKE \"%Zapier%\" OR text LIKE \"%Zapier%\" THEN \"Zapier\"\n                        WHEN title LIKE \"%Reddit%\" OR text LIKE \"%Reddit%\" THEN \"Reddit\"\n                        END AS popular_startup_name,\n                    ranking,\n                    score\n                    FROM `bigquery-public-data.hacker_news.full`\n                                                                )\n                    SELECT popular_startup_name,\n                        SUM(ranking) AS total_ranking,\n                        SUM(score) AS total_score\n                    FROM startup_ranking_score\n                    GROUP BY popular_startup_name\n                    ORDER BY total_score DESC\n\"\"\"\nquery_to_dataframe(coverage_query)","ed2fb0a2":"# to look at this first total number of comments generated per day will be investigated\n# then the average of the year will be aggregated\naverage_daily_comments_per_year = \"\"\" WITH total_comments_generated_per_day AS (\n                                        SELECT EXTRACT(DAYOFYEAR FROM time_ts) AS day,\n                                            EXTRACT(YEAR FROM time_ts) AS year,\n                                            COUNT(id) AS total_comments\n                                        FROM `bigquery-public-data.hacker_news.comments`\n                                        GROUP BY year, day\n                                        )\n                                        SELECT year, \n                                            AVG(total_comments) AS average_daily_comments\n                                        FROM total_comments_generated_per_day\n                                        GROUP BY year\n                                        ORDER BY year\n\"\"\"\nquery_to_dataframe(average_daily_comments_per_year)","2fb406fe":"# this question will be investigated in the full table \nnumber_of_users = \"\"\"\n                    SELECT EXTRACT(YEAR FROM timestamp) AS year,\n                        COUNT(DISTINCT f.by) AS number_of_users\n                    FROM `bigquery-public-data.hacker_news.full` AS f\n                    WHERE timestamp IS NOT NULL\n                    GROUP BY year\n                    ORDER BY year     \n\"\"\"\nquery_to_dataframe(number_of_users)","05ba1b32":"# to answer this question stories and comments tables will be joined and \n# and timedifference of the time_ts will be investigated\ntime_to_receive_comment = \"\"\"\n                            WITH time_difference AS (\n                                SELECT stories.id AS story_id,\n                                    MIN(TIMESTAMP_DIFF(comments.time_ts, stories.time_ts, SECOND)) AS second\n                                FROM `bigquery-public-data.hacker_news.stories` AS stories\n                                LEFT JOIN `bigquery-public-data.hacker_news.comments` AS comments\n                                    ON stories.id = comments.parent\n                                GROUP BY story_id\n                                ORDER BY second ASC)\n                            SELECT *\n                            FROM time_difference\n                            WHERE second >= 0\n\"\"\"\nquery_to_dataframe(time_to_receive_comment).head(10)","587cfb47":"print(\"Average number of hours passed for a story to receive a comment:\",\n      round(query_to_dataframe(time_to_receive_comment).second.mean()\/3600,2))","1641531c":"# to answer this question we are going to look at the ratio of \n# comments receiving subcomments to all comments\n\n# total number of comments in the comments table\ntotal_num_comments = \"\"\"\n                        SELECT COUNT(DISTINCT id)\n                        FROM `bigquery-public-data.hacker_news.comments`\n                    \"\"\"\n\n# total number of comments having sub_comments in the comments table\ntotal_num_comments_w_sub_comments = \"\"\" WITH comments_w_subcomment_list AS (\n                                            SELECT id,\n                                                CASE\n                                                    WHEN id IN (\n                                                        SELECT DISTINCT(parent)\n                                                        FROM `bigquery-public-data.hacker_news.comments`) \n                                                            THEN 1\n                                                    ELSE 0\n                                                END AS is_commented\n                                            FROM `bigquery-public-data.hacker_news.comments`)\n                                        SELECT SUM(is_commented)\n                                        FROM comments_w_subcomment_list\n\"\"\"","af036144":"percent_of_commented_comments = 100 * (query_to_dataframe(total_num_comments_w_sub_comments).f0_.iloc[0] \n                                      \/ query_to_dataframe(total_num_comments).f0_.iloc[0])\n\nprint(\"Percentage of comments with replies {}\".format(round(percent_of_commented_comments,2)))","fd33fd5b":"# we are going to investigate this question in the union of comments and stories table\n# with necessary attributes\nuser_and_creation_date = \"\"\" WITH authors_creation_times AS (\n                                SELECT author, \n                                    time_ts,\n                                        CASE\n                                            WHEN author IS NOT NULL THEN \"story\"\n                                                ELSE NULL\n                                        END AS type\n                                FROM `bigquery-public-data.hacker_news.stories` AS stories\n                                UNION ALL\n                                SELECT author,\n                                    time_ts,\n                                        CASE\n                                            WHEN author IS NOT NULL THEN \"comment\"\n                                                ELSE NULL\n                                    END AS type\n                                FROM `bigquery-public-data.hacker_news.comments` AS comments),\n                            first_creation_date AS (\n                                SELECT author,\n                                    type,\n                                    MIN(time_ts) AS first_activity_time\n                                FROM authors_creation_times\n                                GROUP BY author, type)\n                            SELECT type,\n                                COUNT(author) AS number_of_users\n                            FROM first_creation_date\n                            GROUP BY type        \n\"\"\"\nquery_to_dataframe(user_and_creation_date)","ce5dc579":"# to answer this question\n# first users who make their first activity on HackerNews on January 2014 will be identified\n# then their activity will be matched from full table\n# to make the query more efficient CTEs will be used rather than joining multiple tables at once\n\nusers_w_first_activity_2014_01 = \"\"\"WITH users_from_2014_01 AS (\n                                        SELECT f.by AS author,\n                                            MIN(timestamp) AS first_activity\n                                        FROM `bigquery-public-data.hacker_news.full` AS f\n                                        WHERE timestamp >= '2014-01-01' AND timestamp < '2014-02-01'\n                                        GROUP BY f.by)\n                                    SELECT users_from_2014_01.author,\n                                        users_from_2014_01.first_activity,\n                                        f.type\n                                    FROM users_from_2014_01\n                                    LEFT JOIN `bigquery-public-data.hacker_news.full` AS f\n                                    ON users_from_2014_01.author = f.by \n                                        AND users_from_2014_01.first_activity = f.timestamp   \n                                \"\"\"\nquery_to_dataframe(users_w_first_activity_2014_01).head(10)","f4a87ab5":"# before answering this question lets look at the first rows of full_201510 table\n# Construct a reference to the \"full\" table\ntable_ref_full = dataset_ref.table(\"full_201510\")\n\n# API request - fetch the table\ntable_full = client.get_table(table_ref_full)\n\n# Preview the first five lines of the \"full\" table\nclient.list_rows(table_full, max_results=5).to_dataframe()","2a209d37":"# to answer this we are going to use full_201510 table\nusers_posted_201510 = \"\"\" \n                        SELECT COUNT(DISTINCT f.by) AS number_of_users\n                        FROM `bigquery-public-data.hacker_news.full_201510` AS f\n                     \"\"\"\nquery_to_dataframe(users_posted_201510)","4223df0f":"# number of posts created temporary table will be created using full table\n# and then moving averages per date and post category will be calculated\n# using analytic functions\nmoving_average_query = \"\"\" WITH num_posts_per_day_type AS ( \n                            SELECT EXTRACT(DATE FROM timestamp) AS date,\n                                type,\n                                COUNT(id) AS num_posts\n                            FROM `bigquery-public-data.hacker_news.full` \n                            WHERE timestamp >= \"2018-01-01\"\n                            GROUP BY date, type\n                            )\n                          SELECT date,\n                            type,\n                            AVG(num_posts) OVER (\n                                PARTITION BY type\n                                ORDER BY num_posts\n                                ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS moving_average\n                          FROM num_posts_per_day_type\n                          ORDER BY date\n\"\"\"\nquery_to_dataframe(moving_average_query).head(10)","aa7b2117":"# scores will be grouped and order per day created from scores table\n# and a rank will be assigned using analytic functions\nscores_query = \"\"\"\n                    SELECT id,\n                        score,\n                        EXTRACT(DATE FROM time_ts) AS date,\n                        RANK() OVER(\n                            PARTITION BY EXTRACT(DATE FROM time_ts)\n                            ORDER BY score) AS score_rank\n                    FROM `bigquery-public-data.hacker_news.stories`\n                    WHERE score >= 0   \n\"\"\"\nquery_to_dataframe(scores_query).head(10)","5fc82747":"It takes only seconds a story to receive a comment.","ec1ea824":"## c) What is the average number of daily comments created per day?","79c949cc":"## a) Recent studies have found that many forums tend to be dominated by a very small fraction of users. Is this true of Hacker News?\n* number of posts created\n* number of comments created\n\nshows a sign of being a active and dominated user in the HackerNews.\n","54b05bcd":"Looks like popularity of HackerNews increased constantly and dramatically from 2006 to 2015.","354b0a23":"**Conclusion 4:** Ids are globally unique among stories and comments table.","b3e62984":"## Stories Table - First Rows","e851bd42":"## How much of comments does a story has, which column represents it?","05796c93":"People tend to comment first in the HackerNews. However, there is no significant difference between number of users first created a comment or story.","1c00cc6c":"## e) How long does it take for a post to receive comment?","8a10818a":"**Stories**\n* `id` is the unique key of the story.\n* `descendants` is the number of all comments that a story has.\n* Points of a story is represented as score in the table.","4f26423a":"## Stories Table - Attributes and Field Data Types","405326fe":"**Conclusion 2:** Some of the non_comment_ids are story_ids.","c74f2af4":"## Comments Table - First Rows","66e12e2a":"## Parent column in the `comments` table, what does it represent?","55968dd7":"## Are id columns in the stories and comments globally unique ?","de72ac25":"YCombinator startups got covered by HackerNews. However, most of the stories belong to other subjects showing there is no bias towards those most popular startups.","07b335ae":"## j) What is the moving average (within the 15 day window) of number of posts created from 2018 and onwards, in each post category? ","ae93c14e":"## d) What is the number of users that HackerNews had over years?","51db31c1":"First activities of the users who discovered HackerNews on January 2914, is to create a job post or pollopt.","8380098a":"## f) How many of the comments receive sub-comments ?","567f449f":"Number of users constantly growed, supports the idea of the increasing popularity of HackerNews.","693fd625":"## i) How many distinct users posted on October, 2015?","89e61a44":"## g) Is it more common for users to first create post or provide comments ?","009737c8":"## Comments Table - Attributes and Field Data Types","401e00e7":"## k) What is the rank of the stories based on scores, created in the same day ?","13b1ffa2":"## h) For the users who joined the site in January 2014, When did they post their first story or comment, if ever?","bb6ece15":"# HackerNews Dataset Analysis\nThis dataset contains all stories and comments from [HackerNews](https:\/\/news.ycombinator.com\/news)  from its launch in 2006. Each story contains a story id, the author that made the post, when it was written, and the number of points the story received. <br>\nHacker News is a social news website focusing on computer science and entrepreneurship. It is run by Paul Graham's investment fund and startup incubator, Y Combinator. In general, content that can be submitted is defined as \"anything that gratifies one's intellectual curiosity\". <br>\n\nThere are 4 tables in this public dataset:\n- stories (a.k.a posts)\n- comments\n- full\n- full_2015 <br>\n<br>\n* An example [post](https:\/\/news.ycombinator.com\/item?id=8596682) from HackerNews.\n* An example of a [comment](https:\/\/news.ycombinator.com\/item?id=8597333) from HackerNews.\n* A post can have many comments.\n* A comment can have many comments.\n* Posts can have scores.\n* Posts have rankings showing their popularity.\n\n\nSo the structure is:\n* Story\n  * comment\n    * comment\n      * comment\n\n**Now the question is, how this structure represented in the tables ?**","37288324":"## b) Hacker News has received complaints that the site is biased towards Y Combinator startups. Do the data support this?\n\nHere are some of the most popular YCombinator startups:\n\n* AirBnB\n* Stripe\n* Dropbox\n* Zapier\n* Reddit\nand so on..","5061f7f5":"Number of posts created in story and comment category have a significantly higher moving averages than job, poll and pollopt category.","bc366b2a":"# 2) With the conclusions in mind, some interesting questions to ask:\n* Recent studies have found that many forums tend to be dominated by a very small fraction of users. Is this true of Hacker News?\n* Hacker News has received complaints that the site is biased towards Y Combinator startups. Do the data support this?\n* What is the average number of daily comments created per day?\n* What is the number of users that HackerNews had over years?\n* How long does it take for a post to receive comment?\n* How many of the comments receive sub-comments ?\n* Is it more common for users to first create post or provide comments?\n* For the users who joined the site in January 2014. When did they post their first story or comment, if ever?\n* How many distinct users posted on October, 2015?\n* What is the moving average (within the 15 day window) of number of posts created in each post category? \n* What is the rank of the stories based on scores, created in the same day ?\n","e4129dbe":"**Conclusion 1:** There are 485055 parent_ids that does not represent to a comment_id. Lets have a look at some of them.","7385aa20":"# 1) Understanding the structure between *stories* and *comments* tables\nBefore diving deeper in the queries lets understand the structure of the tables by investigating following questions:\n* Parent_id column in the comments table: \n  * what do they represent? \n  * do they only represent parent id of the comment or the parent id of the story?\n* How much of a comments does a story has, which column represents it?\n* Are the comment and story ids globally unique?","8d7cd28a":"* When number of descendants were 113, number of comments belong to that story is 53.\n* This is an expected result because of the tree structure that post and comments have.\n* 53 is the number of first level comments created for that story, 113 is the number of all sub-comments that a story has. <br>\n\n**Conclusion 3:** Descendants attribute are the total number of comments including sub-comments that a story has."}}