{"cell_type":{"146bb2d0":"code","40d216e1":"code","2d703709":"code","a8abc869":"code","36507877":"code","17c7aa1e":"code","90cf41d9":"code","06be6988":"code","94a24749":"code","20753961":"code","3492e165":"code","aec3eaa8":"code","47361753":"code","228b33ce":"code","7140dc54":"code","cb21cf2c":"code","cbda99b8":"code","0540c064":"code","abec6b96":"code","4fcc0e87":"code","3ce3dfc8":"code","c931f91a":"code","3431b461":"code","e2d711ce":"code","2c1a9b80":"code","76e7114f":"code","6e834a55":"code","82d70fa6":"code","9227f89f":"code","ae2ca5ba":"code","fce61146":"code","0f80cf1f":"code","0974d26e":"code","13abdf4c":"code","07d47875":"code","6825ca7c":"code","173b50b7":"code","1620ac5f":"code","a0151d86":"markdown","69b99faf":"markdown","78416fa8":"markdown","bda6d8ea":"markdown","e03a6064":"markdown","9f672057":"markdown","a58f7a30":"markdown","d9db5bb7":"markdown","0367b4cb":"markdown","dc279b64":"markdown","4e6b31bd":"markdown","adddeceb":"markdown","df3a7d5f":"markdown","24086528":"markdown","e25f2bed":"markdown"},"source":{"146bb2d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40d216e1":"# Import Libraries:\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime as dt\nfrom datetime import timedelta\n\n# Setting Configurations:\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n# Import Warnings:\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=DeprecationWarning)\n\n\n# Import helpers Module\n\nfrom shutil import copyfile\ncopyfile(src = \"..\/input\/helpers\/eda.py\", dst = \"..\/working\/eda.py\")\ncopyfile(src = \"..\/input\/helpers\/data_prep.py\", dst = \"..\/working\/data_prep.py\")\n\nfrom data_prep import *\nfrom eda import *\n","2d703709":"# Import Data:\n\ndf = pd.read_csv(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/Year 2010-2011.csv\")\n\ndf.head()","a8abc869":"check_df(df)","36507877":"# Categorical \/ Numerical \/ Cardinal Features: \n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\nnum_cols = [col for col in num_cols if (\"ID\" not in col) and (\"Date\" not in col) ]","17c7aa1e":"# Let's observe  numerical columns: \n\nfor col in num_cols:\n    num_summary(df,col)","90cf41d9":"# Missing Values:\n\nmissing_values_table(df)","06be6988":"# Drop NA values:\n\ndf.dropna(inplace=True)\nmissing_values_table(df)","94a24749":"# Let's remove the returned product transactions (negative values -> Invoice Id contains value \"C\")\n\ndf_Invoice = pd.DataFrame({\"Invoice\":[row for row in df[\"Invoice\"].values if \"C\"  not in str(row)]})\ndf_Invoice.head()\ndf_Invoice = df_Invoice.drop_duplicates(\"Invoice\")\n\n# The transactions except returned product transactions\ndf = df.merge(df_Invoice, on = \"Invoice\")\n","20753961":"# Delete values less than or equal to 0 in the variables Quantity and Price\n\ndf = df[df[\"Quantity\"] > 0]\ndf = df[df[\"Price\"] > 0]","3492e165":"# Let's only observe outlier values but we don't need to handle outliers as a problem, because we'll be scoring the dataset.\n\nfor col in num_cols:\n    grab_outliers(df,col)\n ","aec3eaa8":"# Unique Number of Products (with Description)\n\ndf.Description.nunique()","47361753":"# Unique Number of Products (with StockCode)\n\ndf.StockCode.nunique()","228b33ce":"# The unique values of these 2 variables (Description & StockCode) should be equal, because each stock code represents a product.\n\n# 1st Step\ndf_product = df[[\"Description\",\"StockCode\"]].drop_duplicates()\ndf_product = df_product.groupby([\"Description\"]).agg({\"StockCode\":\"count\"}).reset_index()\n\n\ndf_product.rename(columns={'StockCode':'StockCode_Count'},inplace=True)\ndf_product.head()","7140dc54":"df_product = df_product.sort_values(\"StockCode_Count\", ascending=False)\ndf_product = df_product[df_product[\"StockCode_Count\"]>1]\n\ndf_product.head()","cb21cf2c":"# Let's delete products with more than one stock code \n\ndf = df[~df[\"Description\"].isin(df_product[\"Description\"])]\n\nprint(df.StockCode.nunique())\nprint(df.Description.nunique())","cbda99b8":"# 2nd Step\n\ndf_product = df[[\"Description\",\"StockCode\"]].drop_duplicates()\ndf_product = df_product.groupby([\"StockCode\"]).agg({\"Description\":\"count\"}).reset_index()\ndf_product.rename(columns={'Description':'Description_Count'},inplace=True)\ndf_product = df_product.sort_values(\"Description_Count\", ascending=False)\ndf_product = df_product[df_product[\"Description_Count\"] > 1] \n\n\ndf_product.head()\n","0540c064":"# Let's delete stock codes that represent multiple products\n\ndf = df[~df[\"StockCode\"].isin(df_product[\"StockCode\"])]","abec6b96":"# Now each stock code represents a single product\n\nprint(df.StockCode.nunique())\nprint(df.Description.nunique())","4fcc0e87":"# The post statement in the stock code shows the postage cost, let's delete it as it is not a product\n\ndf = df[~df[\"StockCode\"].str.contains(\"POST\", na=False)]","3ce3dfc8":"# Calculating Total Price:\n\ndf['TotalPrice'] = df['Quantity'] * df['Price']","c931f91a":"df.head()","3431b461":"df.info()","e2d711ce":"# Let's observe the last transaction date.\n# So we can determine the performans\/measurement date for calculating how recent a customer's latest purchase was.\n\ndf['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\ndf['InvoiceDate'].max()","2c1a9b80":"# Assign \"performans_date\" as 2 days after the last transaction date of purchase:\n\nperformans_date = df[\"InvoiceDate\"].max() + timedelta(days=2)\nperformans_date","76e7114f":"rfm_df = df.groupby(\"Customer ID\").agg \\\n                                    ({\"InvoiceDate\" : lambda InvoiceDate :(performans_date - InvoiceDate.max()).days,  # Recency\n                                     \"Invoice\" : lambda Invoice: Invoice.nunique(),  # Frequency\n                                     \"TotalPrice\":  lambda Total_Price: Total_Price.sum()})    # Monetary\n","6e834a55":"rfm_df.head()","82d70fa6":"# Replace column names with Recency, Frequency and Monetary:\n\nrfm_df.columns = ['recency', 'frequency', 'monetary']\n\nrfm_df.head()","9227f89f":"# Let's check if the values inclued any NaN values:\n\ncheck_df(rfm_df)","ae2ca5ba":"rfm_df[\"Recency_Score\"]  = pd.qcut(rfm_df['recency'], 5, [5, 4, 3, 2, 1])\nrfm_df[\"Frequency_Score\"]  = pd.qcut(rfm_df['frequency'].rank(method=\"first\"), 5, [1, 2, 3, 4, 5])\nrfm_df[\"Monetary_Score\"]  = pd.qcut(rfm_df['monetary'], 5, [1, 2, 3, 4, 5])","fce61146":"\nrfm_df[\"RFM_SCORE\"] = (rfm_df['Recency_Score'].astype(str) +\n                    rfm_df['Frequency_Score'].astype(str))\n\nrfm_df.head() ","0f80cf1f":"rfm_df['Segment'] = rfm_df['RFM_SCORE']\nrfm_df.head()","0974d26e":"seg_map = {\n    r'[1-2][1-2]': 'hibernating',\n    r'[1-2][3-4]': 'at_Risk',\n    r'[1-2]5': 'cant_loose',\n    r'3[1-2]': 'about_to_sleep',\n    r'33': 'need_attention',\n    r'[3-4][4-5]': 'loyal_customers',\n    r'41': 'promising',\n    r'51': 'new_customers',\n    r'[4-5][2-3]': 'potential_loyalists',\n    r'5[4-5]': 'champions'\n}","13abdf4c":"rfm_df['Segment'] = rfm_df['Segment'].replace(seg_map, regex=True)\nrfm_df.reset_index(inplace=True)\nrfm_df.head()","07d47875":"rfm_df.groupby('Segment').agg({\"Customer ID\":\"count\"}).sort_values(\"Customer ID\",ascending=False)","6825ca7c":"colors  = (\"darkorange\", \"darkseagreen\", \"orange\", \"cyan\", \"cadetblue\", \"hotpink\", \"lightsteelblue\", \"coral\",  \"mediumaquamarine\",\"palegoldenrod\")\nexplodes = [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n\nrfm_df[\"Segment\"].value_counts(sort=False).plot.pie(colors=colors,\n                                                 textprops={'fontsize': 12}, \n                                                 autopct = '%4.1f',\n                                                 startangle= 90, \n                                                 radius =2, \n                                                 rotatelabels=True,\n                                                 shadow = True, \n                                                 explode = explodes)\nplt.ylabel(\"\");\n","173b50b7":"rfm_df[[\"recency\", \"frequency\", \"monetary\"]].agg([\"mean\"])","1620ac5f":"rfm_df[[\"Segment\",\"recency\", \"frequency\", \"monetary\"]].groupby(\"Segment\").agg([\"mean\", \"count\",\"sum\"])","a0151d86":"Let's create a new df called as rfm_df by calculating the Recency, Frequency and Monetary values.\n\n* Recency : the number of days between performans_date and the last purchase date of  each customers\n* Frequency: the number of transactions (unique invoices) of each customers\n* Monetary : the sum of TotalPrice of each customers.","69b99faf":"***Dataset Story***\n\n* The data set named Online Retail - II includes the sales of an online store between 01\/12\/2009 - 09\/12\/2011.\n\n* The product catalog of this company includes souvenirs.\n\n* The majority of the company's customers are corporate customers.\n\nBuilding of CRM strategies that overlap with customers\u2019 expectations and needs and also adopt the insight of right customer, right product, right time, right offer is one of the most important approach to deepen customer relationships.\n\nFor this purpose, you want to build customer-oriented strategies. You aim to contact your customers with different campaigns, fictions and attractive messages. So which customer will you contact with which strategy? In summary, do you know the answers to the following questions?\n\n* How recent was a customer's latest purchase? (Recency)\n\n* How often a customer makes a purchase? (Frequency)\n\n* How much money a customer spends on? (Monetary)\n\nAt this point, the most effective way of identifying your customers is to combine CRM with Analytics. \u200b\u201cRFM Analysis\u201d is an indispensable application of CRM Analytics which answers these questions and ensure to get deeply insights about customer habits.\n\nIn this study, below topics have been handled:\n\nCalculating R, F, M values ,\nDivide into groups according to RFM Scores\nPersonalize of marketing strategies for relevant segments.","78416fa8":"* **Champions:**\n\nThis segment constitutes 15% of the customer portfolio and also it includes 641 customers who have made their last purchases within the last week and generate an average turnover of 6000 TL. Because of this segment consists of customers  most frequently spends and can easily  adopt to new products and services, cross-sales strategies can be taken for this segment.\n\n","bda6d8ea":"***Assigning RFM Scores***\n\n*  RFM analysis numerically scale each of these three categories for each customer 1 to 5. This is the higher the number, the better the result. The \"Best\" customer would receive a top score in every category whereas for Receny score, this is the opposite, because the most valueable customer is that has recently made purchasing so Recency score is labeled as 1.\n\n* The max number of Frequency and Monetary metrics mean that the customer is purchasing frequently and spending more money, so the highest score should be given as 5 to represent best customers.\n","e03a6064":"* **Loyal Customers:**\n\nThere are 818 customers in this segment, and while the purchasing frequency is 4 on average in all customer segments, it has been seen that average purchases are 2 times higher in this segment (average of frequency is 8). The average monetary value of this segment is 50% above the general average. \n\nAs a conclusion,  in order to ensure customer loyalty sustainable, cross-sell communications in line with customer expectations and needs can be organized for this segment.\n\n\n\n\n","9f672057":"***Exploratory Data Analysis***","a58f7a30":"***Calculating RFM Metrics***","d9db5bb7":"***Variables Description:***\n\n* InvoiceNo : The number of the invoice, unique per each purchase. Refund invoice numbers contain \"C\"\n\n* StockCode : Unique code per each item\n\n* Description : Name of the item\n\n* Quantity : The number of items within the invoice\n\n* InvoiceDate : Date and time of the purchase\n\n* UnitPrice : Price of a single item, as of Sterlin\n\n* CustomerID : Unique id number per each customer\n\n* Country : The country where the customer is living\n","0367b4cb":"* **Need_Attention:**\n\n\nThere are 184 customers that last purchased nearly 2 months ago in this segment. Although they dont make purchase frequently,  total transaction amounts of these customers contribute to profitability. \n\nAs a result, Cashback and bonus campaigns can be organized for this segment to retain customers and even move them to a segment that makes more purchases. In fact, discounted product offers and campaigns based on gift coupons can be planned  by observing  habits of other customers with similar behaviors, and analyzing according product association rules.","dc279b64":"* **Can't_loose:** \n\nCustomers of Can't_Loose segment have a higher transaction frequency, even though their spending amounts are close to the loyal customer segment. However, since these customers are nearly lost customers that made last purchases nearly 4 months ago.\n\nSo, new campaign strategies based on rewards, discounts, and other special incentives as a way to attract and retain customers can be planned in order to make them feel special and loyal again. ","4e6b31bd":"***Build Marketing Strategies***","adddeceb":"***Generating Segments Based on RFM Scores***\n\nWe can assign the segments by using  Receny & Frequency Grid frequently seen in the literature.","df3a7d5f":"****Business Problem & Goal:****\n \nAn e-commerce company thinks that doing marketing activities based on customer segments with common behaviors will increase income. For this reason, it is aimed to divide customers into segments and determine marketing strategies according to these segments.","24086528":"Now, let's focus on some segments which can be critically important for marketing strategies\n\n* champions\n* loyal_customers\n* cant_loose\n* need_attention \n\n","e25f2bed":"The dataset includes 8 features in which there're 3 numerical columns and 5 categorical columns. But there is no column which has high cardinality"}}