{"cell_type":{"19a84248":"code","6c797349":"code","4ad99119":"code","7cf97f3c":"code","81287aa4":"code","96d1772a":"code","593bd789":"code","5923932e":"code","1183c5c5":"code","44c0de9e":"code","18ff2d20":"code","005bc82d":"code","3f82ee88":"code","ed821ca7":"code","f67559cf":"code","db5e461a":"code","f9aecc3d":"code","003885d8":"code","21f60d31":"code","9f15b066":"code","c9791a00":"code","c9669691":"code","42934f9f":"code","f200f985":"code","5307a9e6":"code","b30a15c0":"code","451df5cf":"code","0101edf9":"code","78a97845":"code","2e938761":"code","5b3e2d75":"code","e4b23157":"code","10b99ee1":"code","da0e83ea":"code","b760f900":"code","014559d0":"code","10be8204":"code","b6053d3f":"code","6666d570":"code","0d97e02d":"code","1cbb9f4f":"code","70b1c192":"code","83b2e6b8":"code","41366701":"code","5f51e6b0":"code","e08e881e":"code","c495b2ab":"code","9ebf9cab":"code","7b9446b9":"code","892fca03":"code","f046eea8":"code","f8f1bc93":"markdown","140adb19":"markdown","fe41202e":"markdown","818a325e":"markdown","5958a813":"markdown","677b19b4":"markdown","c6750043":"markdown","471ba734":"markdown","fb132614":"markdown","be4f1776":"markdown","e3590f33":"markdown"},"source":{"19a84248":"from IPython.display import YouTubeVideo\nYouTubeVideo(id=\"hdtQPawYm2k\",width=1000,height=500)","6c797349":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ad99119":"import pandas as pd  \nimport numpy as np\nimport joblib \nimport operator\nimport seaborn as sns\nimport plotly.express as px \nfrom plotly.subplots import make_subplots \nimport plotly.graph_objects as go  \nfrom matplotlib import pyplot as plt\nimport warnings \nwarnings.filterwarnings(\"ignore\")","7cf97f3c":"from sklearn.metrics import precision_score \nfrom sklearn.metrics import recall_score \nfrom sklearn.metrics import f1_score \nfrom sklearn.metrics import roc_auc_score","81287aa4":"# For metrics Calculation \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import classification_report  \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve \nfrom sklearn.metrics import auc","96d1772a":"from sklearn.model_selection import train_test_split #splitting train and testing data \nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.linear_model import LogisticRegression # to build a model that will be able to classify the response is 1 or 0 based on input attributes\nfrom sklearn.model_selection import  StratifiedKFold,KFold # for splitting the data into five parts  \nfrom sklearn.preprocessing import LabelEncoder # for labeling some of the categorical Variables i.e 0,1,2,3.....","593bd789":"df=pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\") \ndf1=pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/test.csv\")","5923932e":"print(\"Shape of training dataset\") \nprint(\"=================================================\")\nprint(\"Number of rows :\"+str(df.shape[0])) \nprint(\"Number of columns : \"+str(df.shape[1]))","1183c5c5":"print(\"shape of testing data set\")  \nprint(\"=======================================\")\nprint(\"Number of rows :\"+str(df1.shape[0])) \nprint(\"Number of columns : \"+str(df1.shape[1]))","44c0de9e":"Gender=df[\"Gender\"].value_counts().to_frame().reset_index().rename(columns={'index':'Gender',\"Gender\":'Count'})","18ff2d20":"fig=go.Figure(go.Bar(x=Gender[\"Gender\"],y=Gender[\"Count\"],text=Gender[\"Count\"],textposition=\"outside\")) \nfig.update_layout(title=\"Gender\") \nfig.show()","005bc82d":"fig=px.pie(df,names=\"Gender\",title=\"Gender\",hole=0.4,color_discrete_map={'Male':'royalblue','Female':'blue'}) \nfig.show()","3f82ee88":"fig=px.histogram(df,x=\"Age\",nbins=50,title=\"Distribution of Ages\") \nfig.show()","ed821ca7":"fig=px.pie(df,names=\"Driving_License\",title=\"Driving_License\",hole=0.3) \nfig.show()","f67559cf":"fig=px.pie(df,names=\"Previously_Insured\",title=\"Previously_insured\",hole=0.8) \nfig.show()","db5e461a":"fig=px.pie(df,names=\"Vehicle_Damage\",title=\"Vehicle Damage\",hole=0.3,color_discrete_sequence=[\"springgreen\",\"aqua\"])\nfig.show()","f9aecc3d":"fig=px.pie(df,names=\"Vehicle_Age\",title=\"Vehicle_Age\",hole=0.7,color_discrete_sequence=[\"royalblue\",\"blue\",\"green\"]) \nfig.show()","003885d8":"fig=px.pie(df,names=\"Response\",title=\"Response\",hole=0.5,color_discrete_sequence=[\"skyblue\",\"yellow\"]) \nfig.show()","21f60d31":"plt.figure(figsize=(20,10))\nsns.violinplot(df[\"Annual_Premium\"])","9f15b066":"fig=px.histogram(df,\"Vintage\",color=\"Response\") \nfig.show()","c9791a00":"Driving=df.groupby([\"Gender\",\"Driving_License\"])[\"Driving_License\"].count().unstack(\"Driving_License\") \nDriving","c9669691":"#plotting the graph betweeen gender and driving_license i.e having male and female having license or not \nDriving.plot(kind=\"barh\",stacked=True,figsize=(10,5),colormap=\"Spectral\") \nplt.title(\"Difference having Gender whose having Driving License or not\",color=\"blue\",fontsize=10,loc=\"center\")","42934f9f":"Vehicle_Age=df.groupby([\"Gender\",\"Vehicle_Age\"])[\"Vehicle_Age\"].count().unstack(\"Vehicle_Age\")\nVehicle_Age","f200f985":"#Here We can see the bar chart between gender with respective Vehicle Age \nVehicle_Age.plot(kind=\"barh\",stacked=True,figsize=(10,5),fontsize=10,colormap=\"rainbow\") \nplt.title(\"Gender comparision With Vehicle Age\",color=\"green\")","5307a9e6":"Vehicle_damage=df.groupby([\"Gender\",\"Vehicle_Damage\"])[\"Vehicle_Damage\"].count().unstack(\"Vehicle_Damage\")","b30a15c0":"Vehicle_damage.plot(kind=\"barh\",stacked=True,figsize=(10,5),colormap=\"cool\") \nplt.title(\"Gender comparision with Vehicle_damage i.e caused by accident or not \")","451df5cf":"Response=df.groupby([\"Gender\",\"Response\"])[\"Response\"].count().unstack(\"Response\")","0101edf9":"Response.plot(kind=\"barh\",stacked=True,figsize=(10,5),colormap=\"Set1\")","78a97845":"Previously_insured=df.groupby([\"Gender\",\"Previously_Insured\"])[\"Previously_Insured\"].count().unstack(\"Previously_Insured\") \nPreviously_insured","2e938761":"Previously_insured.plot(kind=\"barh\",stacked=True,figsize=(10,5),colormap=\"Oranges_r\")","5b3e2d75":"plt.figure(figsize=(12,8)) \nsns.heatmap(df.drop(\"id\",axis=1).corr(),annot=True,cmap=\"cool\")","e4b23157":"#converting Categorical columns into numerical columns by Label Encoder in training dataset\nle=LabelEncoder() \ndf[\"Gender\"]=le.fit_transform(df[\"Gender\"]) \ndf[\"Vehicle_Damage\"]=le.fit_transform(df[\"Vehicle_Damage\"]) \ndf[\"Vehicle_Age\"]=le.fit_transform(df[\"Vehicle_Age\"])","10b99ee1":"#converting Categorical columns into numerical columns by lable encoder in Testing dataset\nle=LabelEncoder() \ndf1[\"Gender\"]=le.fit_transform(df1[\"Gender\"]) \ndf1[\"Vehicle_Damage\"]=le.fit_transform(df1[\"Vehicle_Damage\"]) \ndf1[\"Vehicle_Age\"]=le.fit_transform(df1[\"Vehicle_Age\"])","da0e83ea":"X=df.drop(\"Response\",axis=1) \ny=df[\"Response\"]","b760f900":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=12)","014559d0":"lr=LogisticRegression()","10be8204":"lr.fit(x_train,y_train)","b6053d3f":"y_pred=lr.predict(x_test)","6666d570":"accuracy=accuracy_score(y_pred,y_test) \nprint(\"accuracy Score : \"+str(accuracy))","0d97e02d":"from sklearn.model_selection import cross_val_score \nscore=cross_val_score(lr,X,y,cv=10) \nscore","1cbb9f4f":"print(f'Accuracy Score : {score.mean()}')","70b1c192":"from sklearn.model_selection import KFold","83b2e6b8":"kfold=KFold(n_splits=5) \nresults=cross_val_score(lr,X,y,cv=kfold)  \nresults","41366701":"print(\"Accuracy Score : \"+str(results.mean()*100))","5f51e6b0":"y_pred=lr.predict(x_test)","e08e881e":"sns.heatmap(confusion_matrix(y_pred,y_test),annot=True,cmap=\"cool\") \nplt.ylabel(\"Actual Values\") \nplt.xlabel(\"Predicted Values\")","c495b2ab":"print(\"Precision Score : \"+str(precision_score(y_pred,y_test))) \nprint(\"Recall Score : \"+str(recall_score(y_pred,y_test))) \nprint(\"F1_ Score : \"+str(f1_score(y_pred,y_test)))","9ebf9cab":"print(\"Classification metrics :\") \nprint(classification_report(y_pred,y_test))","7b9446b9":"testing=lr.predict(df1) \ntesting.shape","892fca03":"roc_auc_score_list=[]\nfor i in range(10):\n    x_train,x_test,y_train,y_test = train_test_split(df.drop('Response', axis=1), \n                                              df['Response'], test_size=.3)\n    roc_auc_score_list.append(roc_auc_score(y_test, lr.predict_proba(x_test)[:, 1]))\n    fpr, tpr, _ = roc_curve(y_test, lr.predict_proba(x_test)[:, 1])\n    plt.plot(fpr, tpr)\nprint(f'Mean roc_auc_score: {np.mean(roc_auc_score_list)}')","f046eea8":"print(\"submission Task\") \nprint(\"=\"*50)\ntest_submission = pd.DataFrame() \ntest_submission[\"testid\"]=x_test[\"id\"] \ntest_submission[\"Response\"]=y_pred \ntest_submission.reset_index(inplace=True) \ntest_submission.drop(\"index\",axis=1,inplace=True)\ntest_submission.rename(columns={\"testid\":\"id\"})  \ntest_submission.head()","f8f1bc93":"<h1> Introduction : <\/h1> \n\n\nA Health insurance policy is a contract between the insurance company and the policyholder, wherein the insurer pays for the medical expenses incurred by the life insured.The insurer will either provide a reimbursement for your medical expenses or ensure you are eligible for cashless treatment for injuries or illnesses covered under the policy at one of the network hospitals. You can also get tax deductions on the premiums paid towards health insurance under Section 80D of the Income Tax Act, 1961.","140adb19":"<a id=\"1\"><\/a>\n<h1 style='background:purple; color:white'><center>Uni Variate Analysis<center><h1>","fe41202e":"<h1>Task : <\/h1> \n\n\n<b>Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful \nfor the company because it can then accordingly plan its communication strategy to reach out to\nthose customers and optimise its business model and revenue.<\/b>","818a325e":"<center> <img src=\"http:\/\/www.nbn.org.il\/wp-content\/uploads\/2014\/01\/insurance_20096929_1908.jpg\" width=1000 height=500 ><\/center>","5958a813":"<a id=\"3\" ><\/a>\n<h2 style='background:purple; border:0; color:white'><center>Multi Variate Analysis<center><h2>","677b19b4":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:purple; border:0' role=\"tab\" aria-controls=\"home\"><center>1.Uni Variate Analysis<\/center><\/h3>","c6750043":"<h1><center>Health Insurance and Exploratory Data Analysis,Data modeling <\/center><\/h1> \n<center><img src=\"https:\/\/www.gannett-cdn.com\/-mm-\/f54b687485826f619e5c91d5d40295e984fd9a43\/c=0-10-580-336&r=x1683&c=3200x1680\/local\/-\/media\/2016\/10\/15\/USATODAY\/usatsports\/gettyimages-462882603_large.jpg\"><\/center>","471ba734":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:purple; border:100' role=\"tab\" aria-controls=\"home\"><center>Exploratory data Analysis<\/center><\/h3>\n\n* [1. UniVariate Analysis ](#1) \n* [2. Null Values ](#2)\n* [3. MultiVariate Analysis](#3)\n","fb132614":"# Validation : \n    This process of deciding whether the numerical results quantifying hypothesized relationships between \n    variables, are acceptable as descriptions of the data, is known as validation","be4f1776":"# Stratified k-fold Cross Validation : \n    In some cases, there may be a large imbalance in the response variables. For example, in dataset concerning price of houses,\n    there might be large number of houses having high price. Or in case of classification, there might be several times more \n    negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made,\n    such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case \n    of prediction problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold.","e3590f33":"# K - Fold Cross Validation : \n    As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting.\n    By reducing the training data, we risk losing important patterns\/ trends in data set, which in turn increases error induced by bias. \n    So, what we require is a method that provides sample data for training the model and also leaves sample data for validation.\n    K Fold cross validation does exactly that. \n    \n    In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, \n    one of the k subsets is used as the test set\/ validation set and the other k-1 subsets are put together to form a \n    training set. \n    \n    The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting,\n    and also significantly reduces variance as most of the data is also being used in validation set. \n    Interchanging the training and test sets also adds to the effectiveness of this method. As a general rule \n    and empirical evidence, K = 5 or 10 is generally preferred, but nothing\u2019s fixed and it can take any value."}}