{"cell_type":{"afc9992d":"code","4f1ae1d5":"code","77e179af":"code","0ef709d5":"code","1b7dddb3":"code","b48cad58":"markdown","06b5f303":"markdown","f224590e":"markdown","860d8e60":"markdown"},"source":{"afc9992d":"!pwd","4f1ae1d5":"import os\nimport pandas as pd\n\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\ndata_dir = '..\/input\/'\n\ntrain_path = os.path.join(data_dir, 'train.csv')\ntest_path = os.path.join(data_dir, 'test.csv')\n\n# 1. load data\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\n\nprint(len(train), len(test))\n\ny_train = train['label']\nx_train = train.drop(labels=['label'], axis=1)\n\ndel train\n\n# 2. check for null and missing values\n# print(x_train.isnull().any())\n# print(test.isnull().any())\n\n# 3. normalization\nx_train \/= 255.\ntest \/= 255.\n\n# 4. reshape\nx_train = x_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)\n\n# 5. label encoding\ny_train = to_categorical(y_train)\n\n# 6. split training and validation set\nrandom_seed = 2\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=random_seed)\n\nx_train, y_train\n","77e179af":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import losses\n\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n                            activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n                            activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n                            activation='relu'))\nmodel.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n                            activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation=\"relu\"))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation=\"softmax\"))\n\noptimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-8, decay=0.0)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=losses.categorical_crossentropy,\n    metrics=['acc'])\n\nmodel.summary()\n","0ef709d5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n# data augmentation\ndatagen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False)\ndatagen.fit(x_train)\n\n# annealing method\nlearning_rate_reduction = ReduceLROnPlateau(\n    monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=1e-5)\n\n# fit\nepochs = 10\nbatch_size = 86\nhistory = model.fit_generator(\n    datagen.flow(x_train, y_train, batch_size=batch_size),\n    epochs=epochs,\n    validation_data=(x_val, y_val),\n    verbose=2,\n    steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n    callbacks=[learning_rate_reduction])\n\n# plot\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title(\"Training and validation accuracy\")\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title(\"Training and validation loss\")\nplt.legend()","1b7dddb3":"# predict results\nresults = model.predict(test)\n\n# select the index with the maximum probability\nresults = np.argmax(results, axis=1)\n\nresults = pd.Series(results, name=\"Label\")\n\nsubmission = pd.concat(\n    [pd.Series(range(1, len(test) + 1), name=\"ImageId\"), results], axis=1)\n\nsubmission.to_csv(\"results.csv\", index=False)\n","b48cad58":"# build model","06b5f303":"# data preparation","f224590e":"# predict","860d8e60":"# train and predict"}}