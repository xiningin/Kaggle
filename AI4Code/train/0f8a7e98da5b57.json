{"cell_type":{"d0268f74":"code","f4ebe7b4":"code","fbde9745":"code","7524a074":"code","a5c26852":"code","45ae5343":"code","4918e2a9":"code","e155ddf1":"code","2317f2af":"code","100038b7":"code","9244241e":"code","3a9123e7":"code","465e5cfd":"code","d169ee1b":"code","4cafdf36":"code","34e6c717":"markdown"},"source":{"d0268f74":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nimport cv2\nfrom numpy import random as rng\nfrom sklearn.utils import shuffle\nimport pickle\nimport time\n\nfrom tensorflow.keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, Dense, Flatten, Activation, Dropout\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import backend as K","f4ebe7b4":"image_train_dir = '\/kaggle\/input\/omniglot\/images_background'\nimage_eval_dir = '\/kaggle\/input\/omniglot\/images_evaluation'","fbde9745":"def load_data(dir_path):\n    X = []\n    y = []\n    lang_dict = {}\n    classNo = 0\n    for alphabet in tqdm(sorted(os.listdir(dir_path))):\n        lang_dict[alphabet] = [classNo,None]\n        alpha_path = os.path.join(dir_path,alphabet)\n        for letter in sorted(os.listdir(alpha_path)):\n            cat_images= []\n            for img in sorted(os.listdir(os.path.join(alpha_path,letter))):\n                img_path = os.path.join(alpha_path,letter,img)\n                cat_images.append(cv2.cvtColor(cv2.imread(img_path),cv2.COLOR_BGR2GRAY))\n                y.append(classNo)\n            classNo += 1\n            X.append(cat_images)\n            lang_dict[alphabet][1] = classNo-1\n    X = np.array(X)\n    y = np.array(y)\n#     print(X.shape,y.shape)\n    return X, y, lang_dict","7524a074":"trainImages,trainLabels,lang_dict = load_data(image_train_dir)\nvalImages,valLabels,lang_dictVal = load_data(image_eval_dir)","a5c26852":"trainImages.shape, trainLabels.shape","45ae5343":"def get_batch(batch_size,dset='train'):\n    if dset == 'train':\n        X = trainImages\n    else:\n        X = valImages\n    n_classes, n_examples, w, h = X.shape\n    cat = rng.choice(n_classes, size=batch_size, replace=False)\n    targets = np.zeros((batch_size,))\n    targets[batch_size\/\/2:] = 1\n    pairs = [np.zeros((batch_size,w,h,1)) for _ in range(2)]\n    for i in range(batch_size):\n        ex_no = rng.randint(n_examples)\n        pairs[0][i,:,:,:] = X[cat[i],ex_no,:,:].reshape(w,h,1)\n        cat2 = 0\n        if i >= batch_size \/\/ 2:\n            cat2 = cat[i]\n        else:\n            cat2 = (cat[i] + rng.randint(1,n_classes)) % n_classes\n        ex_no2 = rng.randint(n_examples)\n        pairs[1][i,:,:,:] = X[cat2,ex_no2,:,:].reshape(w,h,1)\n    return pairs,targets","4918e2a9":"# def generate(batch_size=16,dset='train'):\n#     while True:\n#         pairs,targets = get_batch(batch_size,dset)\n#         yield (pairs,targets)","e155ddf1":"def make_one_shot_task(N,dset='val'):\n    if dset == 'train':\n        X = trainImages\n    else:\n        X = valImages\n    n_classes, n_examples, w, h = X.shape\n    cats = rng.choice(n_classes,size=(N,))\n    indices = rng.choice(n_examples,size=(N,))\n    true_cat = cats[0]\n    ex1 = rng.randint(n_examples)\n    test_image = np.array([X[true_cat,ex1]]*N).reshape(N,w,h,1)\n    support_set = X[cats,indices].reshape(N,w,h,1)\n    targets = np.zeros((N,))\n    targets[0] = 1\n    \n    test_image,support_set,targets = shuffle(test_image,support_set,targets)\n    \n    return [test_image,support_set], targets","2317f2af":"def test_one_shot(model,N,k,dset='val'):\n    n_correct = 0\n    for _ in range(k):\n        inputs, outputs = make_one_shot_task(N,dset)\n        preds = model.predict(inputs)\n        if np.argmax(outputs) == np.argmax(preds):\n            n_correct += 1\n    return n_correct \/ k","100038b7":"def get_siamese(input_shape):\n    left_input = Input(input_shape)\n    right_input = Input(input_shape)\n    \n    model = Sequential()\n    model.add(Conv2D(64,(5,5),input_shape=input_shape,kernel_regularizer='l2'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128,(5,5),kernel_regularizer='l2'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128,(5,5),kernel_regularizer='l2'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(512,activation='sigmoid',kernel_regularizer='l2'))\n    \n    left_emb = model(left_input)\n    right_emb = model(right_input)\n    \n    L1_Layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n    L1_Dist = L1_Layer([left_emb,right_emb])\n    OP = Dense(1,activation='sigmoid',kernel_regularizer='l2')(L1_Dist)\n    \n    siamese_net = Model(inputs=[left_input,right_input],outputs=OP)\n    \n    return siamese_net","9244241e":"num_iterations = 7000\nbatch_size = 128\n\nevaluateEvery = 100\n# Calculate 250 20-way validation testing\nk = 250\nN = 20\n\nn_classes, n_examples, w, h = trainImages.shape\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.05,\n    decay_steps=3000,\n    decay_rate=0.0000001)\nopt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\nmodel = get_siamese((w, h, 1))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\nmodel.summary()","3a9123e7":"lossArr = []\ntrainAccArr = []\nvalAccArr = []\ncurrTime = time.time()\nfor i in range(0,num_iterations+1):\n    x,y = get_batch(batch_size)\n    loss = model.train_on_batch(x,y)\n    if i % evaluateEvery == 0:\n        lossArr.append(loss[0])\n        trainAcc = round(test_one_shot(model,N,k,'train') * 100,2)\n        valAcc = round(test_one_shot(model,N,k,'val') * 100,2)\n        trainAccArr.append(trainAcc)\n        valAccArr.append(valAcc)\n        print('Iteration',i,'('+str(round(time.time() - currTime,1))+'s) - Loss:',loss[0],'Acc:',round(loss[1],2),'',end='')\n        print(k,str(N)+'-way train accuracy:', trainAcc,'%, ',end='')\n        print(k,str(N)+'-way val accuracy:', valAcc,'%')\n        currTime = time.time()","465e5cfd":"epochs_range = [i*evaluateEvery for i in range(1, len(trainAccArr) + 1)]\n\nplt.figure(figsize=(5,5))\n\nplt.plot(epochs_range, trainAccArr, label='Train Set')\nplt.plot(epochs_range, valAccArr, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Iterations')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.tight_layout()\nplt.show()","d169ee1b":"print('Final Validation Accuracy using 250 20-Way One Shot Learning:', round(test_one_shot(model,N,k,'val') * 100,2))","4cafdf36":"model.save('omniglot-siamese.h5')","34e6c717":"# Siamese Network"}}