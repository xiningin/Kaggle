{"cell_type":{"21cc006b":"code","0e79b8f6":"code","abb29fcc":"code","919ffa6c":"code","a353effe":"code","d2780adf":"code","d1f507c1":"code","6a4fa69a":"code","22f9bb9c":"code","2f1d52a7":"code","0e3e1fc9":"code","7e39a558":"code","c0bf1c55":"code","44b4bc41":"code","3507af99":"code","8884a001":"code","62ae8f3d":"code","a4359dc5":"code","38545a92":"code","9ab28ccf":"code","f8cf45d4":"code","56b84814":"code","95a46bd2":"code","3ba73991":"code","dccb566c":"code","0b068d03":"code","751b2185":"code","4e72576f":"code","4ef6f29f":"code","0415d061":"code","3e0e6962":"code","79cf08e1":"code","e8b1bcd1":"code","a92d6792":"code","b4ff8e6e":"code","2ec09207":"code","9fa0ac0a":"code","825a2b37":"markdown","8812f6e8":"markdown"},"source":{"21cc006b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd \nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport re, os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","0e79b8f6":"df = pd.read_csv('\/kaggle\/input\/suspicious-tweets\/suspicious tweets.csv')","abb29fcc":"df.groupby('label').describe()","919ffa6c":"df['length'] = df['message'].apply(len)\ndf.head()","a353effe":"df_labels = df['label']\ndf_labels.head(11)","d2780adf":"count_Class = pd.value_counts(df.label, sort = True)\n\n# Data to Plot\nlabels = '0', '1'\nsizes = [count_Class[0], count_Class[1]]\ncolors = ['red', 'skyblue']\nexplode = (0.1, 0.1)\n\n# Plot\nplt.pie(sizes, explode = explode, labels = labels, colors = colors,\n        autopct = '%1.1f%%', shadow = True, startangle = 90)\nplt.axis('equal')\nplt.show()","d1f507c1":"def preprocess_text(sen):\n    sentence = re.sub('(https?:\\\/\\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\\/\\w \\.-]*)',' ',sen) # Removing html tags\n    sentence = re.sub('[^a-zA-Z]', ' ', sentence) # Remove punctuations and numbers\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) # Single character removal\n    sentence = re.sub(r'\\s+', ' ', sentence) # Removing multiple spaces\n    sentence = sentence.replace(\"ain't\", \"am not\").replace(\"aren't\", \"are not\")\n    sentence = ' '.join(text.lower() for text in sentence.split(' ')) # Lowering cases\n    sw = stopwords.words('english')\n    sentence = ' '.join(text for text in sentence.split() if text not in sw) #removing stopwords\n    #sentence = ' '.join(text.lemmatize() for text in sentence.split()) #lemmatization\n    return sentence\n       ","6a4fa69a":"df['message'] = df.message.apply(preprocess_text)","22f9bb9c":"df['message'] = df['message'].apply(nltk.word_tokenize)","2f1d52a7":"stemmer = PorterStemmer()\ndf['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])","0e3e1fc9":"show = df['message']\nshow.head()","7e39a558":"df['message'] = df['message'].apply(lambda x: ' '.join(x))\ncount_vect = CountVectorizer()\ncounts = count_vect.fit_transform(df['message']);","c0bf1c55":"transformer = TfidfTransformer().fit(counts)\ncounts = transformer.fit_transform(counts)","44b4bc41":"X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.3, random_state=69)","3507af99":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","8884a001":"# implementing naive bayes\nNB = MultinomialNB().fit(X_train, y_train)","62ae8f3d":"predicted = NB.predict(X_test)\n\nprint(np.mean(predicted == y_test))","a4359dc5":"print(classification_report(y_test,predicted))","38545a92":"print(confusion_matrix(y_test, predicted))","9ab28ccf":"# implementing SVM\nsv = SVC().fit(X_train, y_train)","f8cf45d4":"predicted = sv.predict(X_test)\n\nprint(np.mean(predicted == y_test))","56b84814":"print(classification_report(y_test,predicted))","95a46bd2":"print(confusion_matrix(y_test, predicted))","3ba73991":"# implementing disession tree\n\ndt = DecisionTreeClassifier().fit(X_train, y_train)","dccb566c":"predicted = dt.predict(X_test)\n\nprint(np.mean(predicted == y_test))","0b068d03":"print(classification_report(y_test,predicted))","751b2185":"print(confusion_matrix(y_test, predicted))","4e72576f":"# implementing adabost \nab = AdaBoostClassifier().fit(X_train, y_train)","4ef6f29f":"predicted = ab.predict(X_test)\n\nprint(np.mean(predicted == y_test))","0415d061":"print(classification_report(y_test,predicted))","3e0e6962":"print(confusion_matrix(y_test, predicted))","79cf08e1":"# converting content to lower case\npred = (df['message'].str.lower())\n# printing predictions made by model\nprint(\"prediction: {}\". format(dt.predict(count_vect.transform(pred.values.astype('U')))))\n# saving predictions in a variable\nmy_pred = dt.predict(count_vect.transform(pred.values.astype('U')))\n# saving predicted labels in .csv file\ndf['autotag'] = my_pred\ndf.to_csv('\/kaggle\/input\/suspicious-tweets\/suspicious tweets.csv',index = False)","e8b1bcd1":"# getting the number of -ve , +ve  predictions \npositive = 0\nnegative = 0\n\nfor v in my_pred:\n if (v == 1):\n  positive += 1\n elif (v == 0):\n  negative += 1","a92d6792":"# function for quality measurement (can be set to required parameters)\ndef quality(pos,total):\n    if((pos*100)\/total >= 0 and (pos*100)\/total <=24 ):\n        print('Quality: Very Negative')\n    elif((pos*100)\/total >= 25 and (pos*100)\/total <=49 ):\n        print('Quality: Negative')\n    elif((pos*100)\/total >= 50 and (pos*100)\/total <=74 ):\n        print('Quality: Positive')\n    elif((pos*100)\/total >= 75 and (pos*100)\/total <=100 ):\n        print('Quality: Very Positive')\n","b4ff8e6e":"# importing library to plot charts\nimport matplotlib.pyplot as plt \n  \n# x-coordinates of left sides of bars  \nleft = [100, 200 ] \n  \n# heights of bars \nheight = [positive,negative] \n  \n# labels for bars \ntick_label = ['Positive', 'Negative'] \n  \n# plotting a bar chart \nplt.bar(left, height, tick_label = tick_label, width = 80, color = ['green','blue']) \n  \n# naming the x-axis \nplt.xlabel('Sentiment') \n# naming the y-axis \nplt.ylabel('Reviews') \n# plot title \nplt.title('Sentiment Analysis') \n  \n# function to show the plot \nplt.show() \nprint (\"Sentiment Analysis - Positive: \"+str(positive)+\", Negative: \"+str(negative))\nquality(positive,(positive+negative))","2ec09207":"# getting negativity \nnegativeity = (negative*100)\/(positive+negative)\npositivity = (positive*100)\/(positive+negative)","9fa0ac0a":"# importing library to plot charts\nimport matplotlib.pyplot as plt \n  \n# x-coordinates of left sides of bars  \nleft = [20 , 80] \n  \n# heights of bars \nheight = [negativeity,positivity] \n\n  \n# labels for bars \ntick_label = ['negativeity','positivity'] \n\n  \n# plotting a bar chart \nplt.bar(left, height, tick_label = tick_label, width = 50, color = ['red','green']) \n\n  \n\n# plot title \nplt.title('negativeity of tweets') \n  \n# setting y-axis limit\nplt.ylim(0,100)\n# setting x-axis limit\nplt.xlim(0,100)\n# function to show the plot \nplt.show() \nprint (\"negativeity: \"+str(round(negativeity,2))+ \" %  \" + \"Positivity: \"+str(round(positivity,2))+\" %\")","825a2b37":"objective : detecting suspicious communication specificly (cyber bulling, threatning, terirosim ) from any type of txt data","8812f6e8":"***prediction***\ncreate a new column name of auto tag in wich we write our realtime prediction"}}