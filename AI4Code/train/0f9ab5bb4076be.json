{"cell_type":{"a8e12752":"code","ec3ff95e":"code","bab93342":"code","303c0f49":"code","15f80cc8":"code","3619c1c0":"code","aec29a09":"code","ec3e8b83":"code","d42a7262":"code","b0f83cb3":"code","0206f5c3":"code","b4e85fbc":"code","8e1f0525":"code","7be9a365":"code","d5c93d35":"code","637ac6cc":"code","0c793a0d":"code","e3e0ee61":"code","b912946d":"code","fc340125":"code","1b7f9e90":"code","d090efbc":"code","acef1994":"code","53ae5ca0":"code","e1854033":"code","6d2fb7f0":"code","f5dc3bd2":"code","4d9ef452":"code","0e780d61":"code","79bcd0ff":"code","b3761e88":"code","7dd53210":"code","5f9d91a3":"code","b5feffed":"code","4abe6863":"code","d1977146":"code","1c77031c":"code","3bf0762b":"code","e6fa0376":"code","bf5bae12":"code","d1659de4":"code","af1429e5":"code","9720a72f":"code","5aff25ba":"code","dc64c57d":"code","aabd10c2":"code","4d352c0b":"code","cd18e3b8":"code","15e3a235":"markdown","6dd8a5e0":"markdown","c9b7fedd":"markdown","7634df9e":"markdown","54297b45":"markdown","b7ded9b3":"markdown","f817495a":"markdown","1a08d96f":"markdown","2a52c6a9":"markdown","f4660017":"markdown","af1366b4":"markdown","dd15c12b":"markdown","f7ce05bc":"markdown","c883ff39":"markdown","da57d7d1":"markdown","0dafece1":"markdown","ac8cba65":"markdown","2dbe186b":"markdown","22c0e16e":"markdown","a74946a3":"markdown","4444a6e9":"markdown","ff259102":"markdown","68d7f461":"markdown","ac3675ac":"markdown","cc4e46d5":"markdown","3814a54b":"markdown","948c7a0d":"markdown","6c29a093":"markdown","07889355":"markdown","83e80295":"markdown","e299a5bb":"markdown","6dfb648b":"markdown","bfeeb351":"markdown","1b177de8":"markdown","7ccb20ff":"markdown","efc2883e":"markdown","3230bd1b":"markdown","66b2dd72":"markdown","f2b616d6":"markdown","d08f80e2":"markdown","02a62911":"markdown","118b471c":"markdown","89450485":"markdown","9199dbb3":"markdown","89b2376c":"markdown","c72a6c04":"markdown","40da7f15":"markdown"},"source":{"a8e12752":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\nfrom sklearn import metrics\n\nfrom imblearn.over_sampling import SMOTE \nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.dummy import DummyClassifier\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()\n","ec3ff95e":"column_names = df.columns\nprint(column_names)","bab93342":"df['Class'].value_counts()","303c0f49":"height = df['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#00F4FC', '#FF007B'])\nplt.xticks(y_pos, bars)\n \nplt.show()","15f80cc8":"df['Class'].value_counts(normalize = True)\n","3619c1c0":"df.info()","aec29a09":"amount = df['Amount'].values\namount_distplot = sns.distplot(amount, color='#EF7261')\namount_distplot.set_title('Verteilung der H\u00f6he  des Geldbetrages aller Transaktionen', fontsize=14)\namount_distplot.set_xlim([min(amount), max(amount)])\n","ec3e8b83":"df[['Time','Amount']].describe()","d42a7262":"time = df['Time'].values\ntime_distplot = sns.distplot(time, color='#21FF95')\ntime_distplot.set_title('Verteilung der Transaktionen entlang einer Zeitaxe in Sekunden', fontsize=14)\ntime_distplot.set_xlim([min(time), max(time)])\nprint(max(time))","b0f83cb3":"df_randomised= df.sample(frac=1, random_state = 100)\ndf_fraudulent = df_randomised.loc[df['Class'] == 1]\ndf_non_fraudulent = df_randomised.loc[df['Class'] == 0][:492]\ndf_undersampling  = pd.concat([df_fraudulent, df_non_fraudulent])","0206f5c3":"height = df_undersampling['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#00F4FC', '#FF007B']) \nplt.xticks(y_pos, bars)\nplt.show()","b4e85fbc":"plt.figure(figsize = (10,10))\nplt.title('Die Korelation zwischen Features des Datensatzes df')\ncorr = df.corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"coolwarm_r\")\nplt.show()","8e1f0525":"plt.figure(figsize = (10,10))\nplt.title('Die Korelation zwischen Features des Datensatzes df_undersampling')\ncorr = df_undersampling.corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"coolwarm_r\")\nplt.show()","7be9a365":"train_undersampling, test_undersampling = train_test_split(df_undersampling, test_size=0.3, random_state = 100)\n\nX_train_undersampling = train_undersampling.drop('Class', axis=1)\ny_train_undersampling = train_undersampling['Class']\n\nX_test_undersampling = test_undersampling.drop('Class', axis=1)\ny_test_undersampling = test_undersampling['Class']\n","d5c93d35":"df_randomised = df.sample(frac=1, random_state = 100)\n\ndf_non_fraudulent = df_randomised.loc[df['Class'] == 0]\ndf_fraudulent = df_randomised.loc[df['Class'] == 1]\n\ndf_random_fraudulent_oversampling = df_fraudulent.sample(n= len(df_non_fraudulent) ,replace = True, random_state = 100)\n\ndf_random_oversampling = pd.concat([df_random_fraudulent_oversampling, df_non_fraudulent])\n\n\n#Visualisierung:\n#===============================================================\nheight = df_random_oversampling['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#61A1FF', '#61FFBF'])\n \nplt.xticks(y_pos, bars)\n \nplt.show()","637ac6cc":"df_randomised = df.sample(frac=1, random_state = 100)\n\ntrain_oversampling, test_oversampling = train_test_split(df_randomised, test_size=0.3, random_state = 100, stratify = df_randomised['Class'])\n\n#Visualisierung:\n#===============================================================\nheight = train_oversampling['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#61A1FF', '#61FFBF'])\n \nplt.xticks(y_pos, bars)\n \nplt.show()","0c793a0d":"train_non_fraudulent = train_oversampling.loc[df['Class'] == 0]\ntrain_fraudulent = train_oversampling.loc[df['Class'] == 1]\ntrain_fraudulent_oversampling = train_fraudulent.sample(n= len(train_non_fraudulent) ,replace = True, random_state = 100)\n\ntrain_oversampling = pd.concat([train_non_fraudulent, train_fraudulent_oversampling])\n\nX_train_oversampling = train_oversampling.drop('Class', axis=1)\ny_train_oversampling = train_oversampling['Class']\n\nX_test_oversampling = test_oversampling.drop('Class', axis=1)\ny_test_oversampling = test_oversampling['Class']\n\n#Visualisierung:\n#===============================================================\nheight = train_oversampling['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#61A1FF', '#61FFBF'])\n \nplt.xticks(y_pos, bars)\n \nplt.show()","e3e0ee61":"df_randomised = df.sample(frac=1, random_state = 100)\n\ntrain_smot, test_smot = train_test_split(df_randomised, test_size=0.3, random_state = 100, stratify = df_randomised['Class'])\n\n#Visualisierung:\n#===============================================================\nheight = train_smot['Class'].value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#2C3E50', '#61FFBF'])\n \nplt.xticks(y_pos, bars)\n \nplt.show()\n\nprint(train_smot['Class'].value_counts())","b912946d":"X_train_smot = train_smot.drop('Class', axis=1)\ny_train_smot = train_smot['Class']\n\nX_test_smot = test_smot.drop('Class', axis=1)\ny_test_smot = test_smot['Class']\n\n\nsm = SMOTE(random_state=100, sampling_strategy= 1.0)\nX_train_smot, y_train_smot = sm.fit_sample(X_train_smot, y_train_smot)\n\n\n#Visualisierung:\n#===============================================================\nheight = y_train_smot.value_counts()\nbars = ('non-fraudulent', 'fraudulent')\ny_pos = np.arange(len(bars))\n \nplt.bar(y_pos, height, color=['#2C3E50', '#61FFBF'])\n \nplt.xticks(y_pos, bars)\n \nplt.show()\n\nprint(y_train_smot.value_counts())","fc340125":"train, test = train_test_split(df, test_size=0.3, random_state = 100)\n\nX_train = train.drop('Class', axis=1)\ny_train = train['Class']\n\nX_test = df.drop('Class', axis=1)\ny_test = df['Class']\n\n","1b7f9e90":"rfc_undersampling = RandomForestClassifier(n_estimators=10).fit(X_train_undersampling, y_train_undersampling)\n\nrfc_undersampling_pred = rfc_undersampling.predict(X_test_undersampling)\n\nprint(metrics.classification_report(y_test_undersampling, rfc_undersampling_pred, digits=3))\n","d090efbc":"metrics.plot_confusion_matrix(rfc_undersampling, X_test_undersampling, y_test_undersampling, cmap='Greens')\nplt.grid(False)\nplt.show()","acef1994":"rfc_undersampling_pred2 = rfc_undersampling.predict(X_test)\nprint(metrics.classification_report(y_test, rfc_undersampling_pred2, digits=3))","53ae5ca0":"rfc_oversampling = RandomForestClassifier(n_estimators=10).fit(X_train_oversampling, y_train_oversampling)\n\nrfc_oversampling_pred = rfc_oversampling.predict(X_test_oversampling)\n\nprint(metrics.classification_report(y_test_oversampling, rfc_oversampling_pred, digits=3))","e1854033":"metrics.plot_confusion_matrix(rfc_oversampling, X_test_oversampling, y_test_oversampling, cmap='Blues')\nplt.grid(False)\nplt.show()","6d2fb7f0":"rfc_oversampling_pred2 = rfc_oversampling.predict(X_test)\nprint(metrics.classification_report(y_test, rfc_oversampling_pred2, digits=3))","f5dc3bd2":"rfc_smot = RandomForestClassifier(n_estimators=10).fit(X_train_smot, y_train_smot)\n\nrfc_smot_pred = rfc_smot.predict(X_test_smot)\n\nprint(metrics.classification_report(y_test_smot, rfc_smot_pred, digits=3))\n","4d9ef452":"metrics.plot_confusion_matrix(rfc_smot, X_test_smot, y_test_smot, cmap='Reds')\nplt.grid(False)\nplt.show()","0e780d61":"rfc_smot_pred2 = rfc_smot.predict(X_test)\nprint(metrics.classification_report(y_test, rfc_smot_pred2, digits=3))","79bcd0ff":"tdc_undersampling = DecisionTreeClassifier().fit(X_train_undersampling, y_train_undersampling)\n\ntdc_undersampling_pred = tdc_undersampling.predict(X_test_undersampling)\n\nprint(metrics.classification_report(y_test_undersampling, tdc_undersampling_pred, digits=3))","b3761e88":"metrics.plot_confusion_matrix(tdc_undersampling, X_test_undersampling, y_test_undersampling, cmap='Greens')\nplt.grid(False)\nplt.show()","7dd53210":"tdc_undersampling_pred2 = tdc_undersampling.predict(X_test)\nprint(metrics.classification_report(y_test, tdc_undersampling_pred2, digits=3))","5f9d91a3":"tdc_oversampling = DecisionTreeClassifier().fit(X_train_oversampling, y_train_oversampling)\n\ntdc_oversampling_pred = tdc_oversampling.predict(X_test_oversampling)\n\nprint(metrics.classification_report(y_test_oversampling, tdc_oversampling_pred, digits=3))","b5feffed":"metrics.plot_confusion_matrix(tdc_oversampling, X_test_oversampling, y_test_oversampling, cmap='Blues')\nplt.grid(False)\nplt.show()","4abe6863":"tdc_oversampling_pred2 = tdc_oversampling.predict(X_test)\nprint(metrics.classification_report(y_test, tdc_oversampling_pred2, digits=3))","d1977146":"tdc_smot = DecisionTreeClassifier().fit(X_train_smot, y_train_smot)\n\ntdc_smot_pred = tdc_smot.predict(X_test_smot)\n\nprint(metrics.classification_report(y_test_smot, tdc_smot_pred, digits=3))","1c77031c":"metrics.plot_confusion_matrix(tdc_smot, X_test_smot, y_test_smot, cmap='Reds')\nplt.grid(False)\nplt.show()","3bf0762b":"tdc_smot_pred2 = tdc_smot.predict(X_test)\nprint(metrics.classification_report(y_test, tdc_smot_pred2, digits=3))","e6fa0376":"rob_scaler = RobustScaler()\n\nX_train_undersampling_scaled = X_train_undersampling.drop(columns=['Time','Amount'])\nX_train_undersampling_scaled['scaled_amount'] = rob_scaler.fit_transform(X_train_undersampling['Amount'].values.reshape(-1,1))\nX_train_undersampling_scaled['scaled_time'] = rob_scaler.fit_transform(X_train_undersampling['Time'].values.reshape(-1,1))\n\nX_test_undersampling_scaled = X_test_undersampling.drop(columns=['Time','Amount'])\nX_test_undersampling_scaled['scaled_amount'] = rob_scaler.fit_transform(X_test_undersampling['Amount'].values.reshape(-1,1))\nX_test_undersampling_scaled['scaled_time'] = rob_scaler.fit_transform(X_test_undersampling['Time'].values.reshape(-1,1))","bf5bae12":"knc_undersampling = KNeighborsClassifier(n_neighbors=3).fit(X_train_undersampling_scaled, y_train_undersampling)\n\nknc_undersampling_pred = knc_undersampling.predict(X_test_undersampling_scaled)\n\nprint(metrics.classification_report(y_test_undersampling, knc_undersampling_pred, digits=3))","d1659de4":"metrics.plot_confusion_matrix(knc_undersampling, X_test_undersampling_scaled, y_test_undersampling, cmap='Greens')\nplt.grid(False)\nplt.show()","af1429e5":"knc_undersampling_pred2 = knc_undersampling.predict(X_test)\nprint(metrics.classification_report(y_test, knc_undersampling_pred2, digits=3))","9720a72f":"rob_scaler = RobustScaler()\n\nX_train_oversampling_scaled = X_train_oversampling.drop(columns=['Time','Amount'])\nX_train_oversampling_scaled['scaled_amount'] = rob_scaler.fit_transform(X_train_oversampling['Amount'].values.reshape(-1,1))\nX_train_oversampling_scaled['scaled_time'] = rob_scaler.fit_transform(X_train_oversampling['Time'].values.reshape(-1,1))\n\nX_test_oversampling_scaled = X_test_oversampling.drop(columns=['Time','Amount'])\nX_test_oversampling_scaled['scaled_amount'] = rob_scaler.fit_transform(X_test_oversampling['Amount'].values.reshape(-1,1))\nX_test_oversampling_scaled['scaled_time'] = rob_scaler.fit_transform(X_test_oversampling['Time'].values.reshape(-1,1))","5aff25ba":"knc_oversampling = KNeighborsClassifier(n_neighbors=3, n_jobs=-1).fit(X_train_oversampling_scaled, y_train_oversampling)\n\nknc_oversampling_pred = knc_oversampling.predict(X_test_oversampling_scaled)\n\nprint(metrics.classification_report(y_test_oversampling, knc_oversampling_pred, digits=3))","dc64c57d":"metrics.plot_confusion_matrix(knc_oversampling, X_test_oversampling_scaled, y_test_oversampling, cmap='Blues')\nplt.grid(False)\nplt.show()","aabd10c2":"rob_scaler = RobustScaler()\n\nX_train_smot_scaled = X_train_smot.drop(columns=['Time','Amount'])\nX_train_smot_scaled['scaled_amount'] = rob_scaler.fit_transform(X_train_smot['Amount'].values.reshape(-1,1))\nX_train_smot_scaled['scaled_time'] = rob_scaler.fit_transform(X_train_smot['Time'].values.reshape(-1,1))\n\nX_test_smot_scaled = X_test_oversampling.drop(columns=['Time','Amount'])\nX_test_smot_scaled['scaled_amount'] = rob_scaler.fit_transform(X_test_smot['Amount'].values.reshape(-1,1))\nX_test_smot_scaled['scaled_time'] = rob_scaler.fit_transform(X_test_smot['Time'].values.reshape(-1,1))","4d352c0b":"knc_smot = KNeighborsClassifier(n_neighbors=3, n_jobs=-1).fit(X_train_smot_scaled, y_train_smot)\n\nknc_smot_pred = knc_oversampling.predict(X_test_smot_scaled)\n\nprint(metrics.classification_report(y_test_smot, knc_smot_pred, digits=3))","cd18e3b8":"metrics.plot_confusion_matrix(knc_smot, X_test_smot_scaled, y_test_smot, cmap='Reds')\nplt.grid(False)\nplt.show()","15e3a235":"# Quellen: \n\n* Plots: https:\/\/python-graph-gallery.com\/barplot\/\n* Colors: https:\/\/color.adobe.com\/create\/color-wheel\n* Pandas: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/index.html\n* Over- and Undersampling: https:\/\/machinelearningmastery.com\/combine-oversampling-and-undersampling-for-imbalanced-classification\/\n* SMOT: https:\/\/www.kaggle.com\/residentmario\/oversampling-with-smote-and-adasyn\n* SMOT: https:\/\/aktuar.de\/unsere-themen\/fachgrundsaetze-oeffentlich\/2019-09-19_Ergebnisbericht_Big-Data-Leben_final.pdf\n* Train Test Split: https:\/\/towardsdatascience.com\/3-things-you-need-to-know-before-you-train-test-split-869dfabb7e50","6dd8a5e0":"* Der Nachteil an Randome undersampling ist, dass durch eine Reduktion der non-fraudulent transactions von **284315** auf **492**, sehr viele Informationen verloren gehen. \n* Dieser Datensatz k\u00f6nnte nun durch einen Split in Tainings- und Testdaten fuer verschiedene Machine learning Modelle angewendet werden. Allerdings sollte ueberlegt werden, ob nicht ein Kreuzvalidierungsverfahren angewendet werden sollte, da der Datensatz vergleichsweise klein ist und bei einem einfachen Train Test Split mit z.B. einer Verteilung von 70\/30 der Test Datensatz nur noch 295 Transaktionen enthalten w\u00fcrde.\n* Dies koennte zur Folge haben, dass ein Machine learning Modelle schlicht und ergreifend zu wenig Daten hat, um innerhalb des Datensatzes Muster zu erkennen und somit nicht im Stande sein sollte, mit einer performanten Loesung aufzuwarten. \n* **Hypothese 1**: Die Anwendung dieser Methode auf verschiedene Mashinelearning Modelle wird zu einem Underfitting f\u00fchren.  ","c9b7fedd":"# 2.3 **Decision Tree** (SMOT)","7634df9e":"# 1. **Undersampling:**\n\n   * Mit der Methode **.loc[df['Class'] == 1]** wird eine **Teilmenge** aus dem Datensatz **df_randomised** erstellt, in welcher alle Spalten, die in der Reihe **\"Class\"** den Wert **\"1\"** besitzen, enthalten sind. Diese Teilmenge wird in **df_fraudulent** gespeichert und enth\u00e4lt dann, wie der name suggeriert, alle **fraudulent** transactions, die df beinhaltet. \n    * Mit der Methode **.loc[df['Class'] == 0][:492]** wird eine **Teilmenge** aus dem Datensatz **df_randomised** erstellt, in welcher die **ersten 492 Spalten** des Datensatzes, die in der Reihe **\"Class\"** den Wert **\"0\"** besitzen, enthalten sind. Da es sich hierbei um ein **Random** undersampling handeln soll, wird der Datensatz df zuvor mit der Methode **.sample(frac=1, random_state = 100)** zuf\u00e4llig gemischt und in **df_randomised** gespeichert. Mit dem Parameter **frac** kann f\u00fcr die Methode **.sample()** festgelegt werden, wie gro\u00df die neue Teilmenge sein soll. Ein Wert von 0.25 w\u00fcrde 25% entsprechen. Der Wert 1 steht dementsprechend fuer 100%. \n    * Der Parameter **random_state = 100** fungiert beim ziehen der **transactions** wie ein Seed (auch bekannt aus Computerspielen wie Minecraft, zur Generierung von zuf\u00e4lligen Welten) und sorgt f\u00fcr eine Reproduzierbarkeit des Ergebnisses. \n    * Zuletzt werden die Datens\u00e4tze df_fraudulent und df_non_fraudulent miteinander konkateniert. ","54297b45":"# 2.1 **Decision Tree** (Undersampling)","b7ded9b3":"1. Random Forest  \n    * mit Undersampling\n    * mit Oversampling\n    * mit SMOT\n    \n    \n2. Entscheidungsbaum\n    * mit Undersampling\n    * mit Oversampling\n    * mit SMOT\n    \n    \n3. K-N\u00e4chste-Nachbarn (KNN)\n    * mit Undersampling\n    * mit Oversampling\n    * mit SMOT\n    \n    \n    \n    \n    ","f817495a":"* F\u00fcr die gleiche Methode kann der Paramter **\"Normalize\"** auf **True** gesetzt werden, wodruch f\u00fcr die beiden Klassen **non-fraudulent** und **fraudulent** jeweils der **Prozentuale Anteil** an der **Gesamtmenge** ausgegeben wird. ","1a08d96f":"* Um eine Auswertung der Modelle fuer das Geschaeftsproblem vorzunehmen, sollten zunaechst die Evaluierungsmetriken erl\u00e4utert werden: ","2a52c6a9":"* In dem Datensatz befinden sich **284315** \"non-fraudulent transactions\" und **492** \"fraudulent\" transactions. ","f4660017":"# Datenaufbereitung\n\n* Im n\u00e4chsten Schritt wird der Datensatz aufbereitet. \n* Am Output **38** ist zu sehen, dass der Datensatz **df** unsausgeglichen ist. \n* Um auf dem Datensatz zu trainieren, sollte dieser jedoch bez\u00fcglich der Anteile an **fraudulent** und **non-fraudulent** transactions m\u00f6glichst ausgeglichen sein, da sonst die Gefahr einer \u00dcberanpassung (overfitting) besteht. Z.B. k\u00f6nnte ein Machine learning Algorithmus, der auf einem unausgeglichenen Test- und Trainingsdatensatz angewendet wird, alle transactions mit non-fraudulent labeln und w\u00fcrde immer noch eine sehr hohe Genauigkeit (accuracy) erreichen. \n\n* Es gibt verschiedene Methoden, um aus dem Datensatz df einen ausgeglichenen Testdatensatz zu generieren. \n    1. Unterabtastung (undersampling)\n        * Random undersampling\n    2. \u00dcberabtastung (oversampling)\n        * Random oversampling\n        * SMOT (Synthetic Minority Oversampling Technique)\n    \n    \n* Im weiteren Verlauf werden verschiedene dieser Methoden auf den Datensatz **df** angewendet und f\u00fcr verschiedene Machine learning Modelle jeweils miteinadern verglichen. \n","af1366b4":"# 3.1 **KNeighbors** (Undersampling)","dd15c12b":"# Modellbildung","f7ce05bc":"* Dieser Datensatz k\u00f6nnte nun auf ein Machine learning Modell angewendet werden. \n* Allerdings besteht weiterhin der Nachteil bzw. die Gefahr eines Overfittings, da die Transaktionen der kleineren Klasse lediglich dupliziert wurden. Daher ist anzunehmen, dass Machine learning Modelle die Features derer fraudalent transactions schwerer gewichten w\u00fcrde, die lediglich durch Zufall \u00f6fters kopiert wurden.\n* **Hypothese 2:** Die Anwendung dieser Methode auf verschiedene Mashinelearning Modelle wird zu einem Overfitting f\u00fchren.","c883ff39":"# Modellevaluierung","da57d7d1":"# 3.3 **KNeighbors** (SMOT)","0dafece1":"2. **Analyse von fehlenden Daten**\n\n    * Mit Hilfe der Methode **info()** wird der Datensatz auf **NULL_Werte** untersucht.","ac8cba65":"# Allgemeine Informationen:\n\n1. Liste aller teilnehmenden Studierenden\n    * Carl Krogmann \n    * Jan Kanz     \n\n\n2. Name des verwendeten Datensatzes\n    * Credit Card Fraud Detection\n    * https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n    \n    ","2dbe186b":"1. Verteilung der H\u00f6he  des Geldbetrages aller Transaktionen:","22c0e16e":"* Mit Hilfe von **df['Class'].value_counts()** l\u00e4sst sich die Anzahl an \"**fraudulent transactions**\" und \"**non-fraudulent transactions**\" in dem Datensatz ermitteln. \n* Dabei wird gez\u00e4hlt, wie viele Geldtransaktionen in der Spalte **\"Class\"** eine **1** und wie viele eine **0** aufweisen. ","a74946a3":"#  M\u00f6glicher Gesch\u00e4ftseinsatz\n\n * Verbraucher f\u00fchren jedes Jahr Milliarden an bargeldlosen Transaktionen durch und werden damit zum Hauptziel von Cyberkriminellen. Das BKA verweist in seinem Bundeslagebild Cybercrime 2014 auf fast 50.000 bekannte F\u00e4lle von Cyberkriminalit\u00e4t.\n * H\u00e4ndler und Finanzinstitute sind davon am meisten betroffen, da sie das verlorene Geld oft R\u00fcckerstatten m\u00fcssen. An dieser Stelle kommen Algorithmen ins Spiel. Welchen Algorithmus man ausw\u00e4hlt ist eine Kostenfrage bzw. eine Frage der Abw\u00e4gung, da jede Sichtung einer transaction durch einen Mitarbeiter mit Kosten verbunden ist. \n * Die Frage ist, m\u00f6chte man wirklich jede fraudulent transaction durch ein Mashine Learning Modell erkennen lassen und ggf. Gefahr laufen, sehr viele non-fraudulent (falsch positiv) transactions \u00fcberpr\u00fcfen zu m\u00fcssen? Oder pr\u00e4feriert das jeweilige Kreditinstitut, dass man lediglich einen Teil der fraudulent transactions aufdecken l\u00e4sst, daf\u00fcr aber nicht zu viele non-fraudulent transactions falsch klassifiziert. \n * Eine weitere L\u00f6sung w\u00e4re, dass man transactions, deren Betrag nidriger ist, als die Kosten, die mit einer Sichtung durch einen Mitarbeiter verbunden sind, garnicht pruefen least. Dies h\u00e4tte den Vorteil, dass man sichergehen k\u00f6nnte, dass die Kosten f\u00fcr die manuelle Sichtung der jeweiligen Daten niemals die Transaktionssumme \u00fcbersteigen w\u00fcrde. \n * Systeme und Services f\u00fcr Credit Card Fraud Detection k\u00f6nnen zwar nicht jeden einzelnen Betrugsversuch erkennen, senken aber die Risiken f\u00fcr H\u00e4ndler und Finanzinstitute erheblich und erh\u00f6hen den Schutz f\u00fcr die Verbraucher.","4444a6e9":"2. Verteilung der Transaktionen entlang einer Zeitaxe in Sekunden:","ff259102":"**Achtung!:** Oversampling sollte in der Regel immer erst nach dem Split in Train und Testdaten erfolgen, da die jeweilige Oversampling Methode lediglich auf die Trainingsdatensaetze angewendet werden soll. Wird der Datensatz erst nach dem oversampling in Train und Test Daten aufgespalten, l\u00e4uft man Gefahr, identische Transaktionen in beiden Datens\u00e4tzen zu erhalten, was der Grundlegenden Idee wiederspricht, mit neuen Daten bzw. anderen Daten zu testen, als urspr\u00fcnglich trainiert wurde.  ","68d7f461":"# 2.2 **Decision Tree** (Oversampling)","ac3675ac":"* Nun kommt SMOTE in Spiel. \n* SMOTE erstellt nun weitere synthetische fraudalent transactions, indem aus zwei im feature space naheliegenden Punkten ein Vektor gebildet wird. Anschliessend werden auf diesem Vektor zwischen den beiden Punkten neue Punkte bzw. systhetische fraudalent transactions generiert. Dies hat zur Folge, dass keine Duplicate erstellt werden muessen. ","cc4e46d5":"# Gesch\u00e4ftsverst\u00e4ndnis:\n\nUns wurde ein anonymisierter Datensatz gegeben, der Kreditkartentransaktionen beinhaltet die als betr\u00fcgerisch oder echt gekennzeichnet wurden. Unserem Modell sollte es m\u00f6glich sein, legitime Transaktionen automatisiert von Betrugsf\u00e4llen zu unterscheiden. \n\nDies h\u00e4tte den Vorteil, dass man aus einer gro\u00dfen Menge von Transaktionen direkt alle verd\u00e4chtigen Transaktionen herausfiltern k\u00f6nnte. \n\nNat\u00fcrlich m\u00fcsste jede verd\u00e4chtige Transaktion noch manuell gepr\u00fcft werden. Trotzdem w\u00fcrde dies eine enorme Zeitersparnis f\u00fcr den jeweiligen Mitarbeiter bedeuten. Zus\u00e4tzlich k\u00f6nnte das Unternehmen mit der automatisierten Betrugsfallerkennung werben, was bei z.B. Kunden ein Gef\u00fchl von Sicherheit und Vertrauen ausl\u00f6sen k\u00f6nnte.","3814a54b":"* Zu sehen ist die Verteilung der H\u00f6he des Geldbetrages aller Transaktionen. \n* In Output 67 ist zu sehen, dass der Median bei 88,34 liegt. Daher ist anzunehmen, dass es einige wenige Transaktionen gibt, bei welchen sehr hohe Geldbetr\u00e4ge abgehoben wurden und an dieser Stelle den Graphen verzerren. Diese sollten in der weiteren Analyse beachtet werden.","948c7a0d":"# 1.2 **Random Forest** (Randome Oversampling)","6c29a093":"# 1.3 **Random Forest** (SMOT)","07889355":"* Im Folgende werden die Mashine Learning Modelle Random Forest, Entscheidungsbaum und K-N\u00e4chste-Nachbarn jeweils mit den drei zuvor erstellten Train Test Splits trainiert. ","83e80295":"# Datenverst\u00e4ndnis:\n\n* Der Datensatz **creditcard.csv** wird mit Hilfe der pandas Methode **read_csv()** in eine Tabelle **df** geladen\n* Anschliessend werden die ersten 5 Rows dieser Tabelle mit Hilfe der Methode **head()** ausgegeben. ","e299a5bb":"# 2.2 **Oversampling (Random Oversampling after Train Test Split)**\n\n* Der Datensatz **df_randomised** wird mit Hilfe von **train_test_split()** gesplittet. Dabei wird durch den Parameter **test_size=0.3** festgelegt, dass der Testdatensatz **70%** des Datensatzes **df_randomised** enth\u00e4lt und der Testdatensatz die restlichen **30%**. \n* der Parameter **random_state = 100** sorgt, wie bereits beschrieben, fuer die **Reproduzierbarkeit**. \n* Mit dem Parameter **stratify = df_randomised['Class']** wird verhindert, dass ein Split entsteht, bei welchem sich alle fraudalent transactions entweder nur in dem TestDatensatz oder nur in dem Trainingsdatensatz befinden. Durch das setzen des Parameters auf **df_randomised['Class']** bleibt die prozentuale Verteilung von **non-fraudalent** und **fraudalent** transactions auf beiden Seiten des Splits gleich. ","6dfb648b":"1. **Beschreibung des Datensatzes**\n\n    * Der Datensatz besteht aus **31 Column** und **284807 Rows**.\n    * **Time** (Column 1) beinhaltet die Zeit (Anzahl an Sekunden die verstrichen sind zwischen der Transaktion und der ersten Transaktion des Datensets). Zwischen der ersten und der letzten Transaktion vergehen **47,997 Stunden**\n    * **Amount** (Column 30) beinhaltet den Geldbetrag der jeweiligen Geldtransaktion in Dollar.\n    * **Class** (Column 31) gibt an, ob bei der Transaktion ein Betrug (fraudulent) vorlag oder nicht (non-fraudulent). Diese Spalte dient als Kontrollinstanz.\n    * Die Beschreibung der Daten zeigt, dass die restlichen Columns (V1-V28) durch die **Hauptkomponentenanalyse (Principal Component Analysis(PCA)**) transformiert wurden. Diese dient dazu, umfangreiche Datens\u00e4tze zu strukturieren, indem man sie zu einer geringen Anzahl an m\u00f6glichst aussagekr\u00e4ftigen **Linearkombinationen** zusammenf\u00fchrt.\n    \n    \n    ","bfeeb351":"* Zu sehen ist die Verteilung der Transaktionen entlang einer Zeitaxe in Sekunden\n* Dabei entspricht das Intervall 48 Stunden. \n* Die Verteilungskurve knickt an zwei Stellen ein. Dies ist durch eine geringere Aktivit\u00e4t der Kunden in der Nacht zu erkl\u00e4ren. ","1b177de8":"3. **Daten-Visualisierung**\n\n    1. Verteilung der H\u00f6he  des Geldbetrages aller Transaktionen\n    2. Verteilung der Transaktionen entlang einer Zeitaxe in Sekunden\n","7ccb20ff":"# Zusammenfassung: \n\nUndersampling:\n\n* Wir haben festgestellt, dass die Anwendung des Undersampling Datensatzes auf alle Modelle keine guten Ergebnisse liefert, da sich unsere Hypothese 1. bestaetigt hat. Schaut man bei allen drei Modellen (undersampling) auf die Werte von precision,recall und f1-score fuer die fraudulent transactions, ist zu sehen, dass die Werte zunaechst sehr vielversprechend erscheinen. Wendet man den trainierten Algorithmus jedoch auf den gesamten Datensatz an, offenbart sich das Problem. Die Clasifizierung ist nicht im Stande, auch nur einen bruchteil der fraudualent transactions zu erkennen. (underfitting)\n\n* hier koennte, wie bereits genannt, ein Kreuzvalidierungsverfahren helfen, allerdings empfeheln wir eher, alle Datenpunkte mit einzubeziehen und daher einen der anderen Methoden zur Ausgleichung der Klassen zu nutzen. \n\nOversampling und SMOT: \n\n* Zwischen Oversampling und SMOT konnten wir keine alzu grossen Unterschiede zwischen den beiden Methoden erkennen, allerdings rechnen wir weiterhin mit einem overfitting bei den random Oversampling Daten. Zu sehen ist dies an dem Ergebnis der Anwendung von Random Oversampling auf Random Forest bei dem gesamten Datensatz. In den eigenen Tests sind SMOT und Random Oversampling bei random forest realtiv gleich, allerdings schneidet random oversampling auf dem ganzen Datensatz deutlich besser ab, was auf ein Overfitting hindeutet. \n\n* Random Forest schneidet in jedem Fall besser ab als Decision Tree, was unseren Erwartungen entsprach. \n* Die Entscheidung zwischen KNeighbors und Random Forest ist schwieriger ausgefallen. Hier ist die Entscheidung eine Ermessensfrage des Kunden. Ist ein Modell gewuenscht, dass moeglichst sicher alle fraudulent transactions erkennt, dann muessen wir anhand unserer Ergebnisse KNeighbors mit SMOT empfehlen. Ist jedoch ein Modell gewuenscht, welches au\u00dferdem moeglichst wenige non-fraudulent transactions f\u00e4lschlicherweise als fraudulent erkennt und somit fuer weniger unnoetigen Arbeitsaufwand sorgt, ist Random Forest mit SMOT das zu empfehlende Modell. \n\n* Zum Gewinner k\u00fcren wir dennoch Random Forest mit SMOT, da die Laufzeit, ein KNeighbors Modell zu trainieren, linear mit der Menge an Daten und mit den zu pruefenden neighbors skaliert. Dies hat bereits bei uns zu langen Laufzeiten gef\u00fchrt und erschwert die weitere Hyperparameteroptimierung. \n\n","efc2883e":"**Korrelationsmatrizen**\n\n* Korrelationsmatrizen sind das A und O, um die Daten zu verstehen. Man versucht herauszufinden, ob es Features gibt, die trotz PCA einen starken Einfluss darauf haben, ob eine bestimmte Transaktion ein Betrug ist.\n\n* Zusammenfassung und Erl\u00e4uterung: Wie erwartet, gibt es keine nennenswerte Korrelation zwischen den Merkmalen V1-V28\n\n* Negative Korrelationen: V10, V12, V14 und V17 korrelieren negativ mit Class. Beachten Sie, dass je niedriger diese Werte sind, desto wahrscheinlicher es ist, dass das Endergebnis eine Betrugstransaktion ist.\n\n* Positive Korrelationen: V2, V4, V11 und V19 korrelieren positiv mit Class. Beachten Sie, dass je h\u00f6her diese Werte sind, desto wahrscheinlicher es ist, dass das Endergebnis eine betr\u00fcgerische Transaktion ist.\n\n\n","3230bd1b":"* Wir stellen fest, dass in dem Datensatz ein sehr grosses **Ungleichgewicht** zwischen den zwei zu gruppierenden Eigenschaften **non-fraudulent** und **fraudulent** besteht. ","66b2dd72":"* Es wird festgestellt, dass in **keiner** Spalte **NULL-Werte** vorhanden sind, daher ist anzunehmen, dass der Datensatz vollst\u00e4ndig ist. Ob der urspr\u00fcnglich Datensatz vollst\u00e4ndig gewesen ist, l\u00e4sst sich an dieser Stelle auf Grund der zuvor durchgef\u00fchrten Hauptkomponentenanalyse nicht mehr beurteilen. ","f2b616d6":"# 2.3 **Oversampling (SMOT)**","d08f80e2":"* Das Ergebnis ist ein ausgeglichener Datensatz mit gleich vielen fraudalent wie non-fraudalent transactions. Im Gegensatz zu der Undersampling Methode verzichtet dieser Ansatz jedoch nicht auf ca. 90% des urspr\u00fcnglichen Datensatzes und sollte die Mashine learning Modelle mit ausreichend Daten versorgen. \n* Doch durch die einfache Kopierung von fraudalent transactions ergibt sich ein neues Problem. Wird mit diesem Datensatz nun ein Train Test Split durchgef\u00fchrt, ist nicht ausgeschlossen, dass sich identische transactions sowohl in der Test Menge als auch in der Train Menge befinden. Daher gilt:  ","02a62911":"* Genauigkeit (Precision): Gibt das Verh\u00e4ltnis zwischen richtig positiv vorhergesagten Werten und allen positiv vorhergesagten Werten an . Ein Beispiel hierf\u00fcr w\u00e4re, wie viele Menschen mit einem positiven Testergebniss auch wirklich krank sind. \n* Precision= richtig positiv\/(richtig positiv + falsch positiv) \n\n* Die Genauigkeit ist nicht die beste Metrik zur Auswertung von unausgewogenen Datens\u00e4ten. Z.b. k\u00f6nnte ein Machine learning Algorithmus, der auf einem unausgeglichenen Test- und Trainingsdatensatz angewendet wird, alle transactions mit non-fraudulent labeln und w\u00fcrde immer noch eine sehr hohe Genauigkeit (accuracy) erreichen. Dies ist allerdings nicht gew\u00fcnscht, daher wird auf folgende Bewertungsmetriken zur\u00fcck gegriffen.\n\n\n* Konfusionsmatrix: Ein spezifisches Table-Layout, das es einem erm\u00f6glicht, die Performance eines Algorithmus zu visualisieren. Wird meistens f\u00fcr supervised Learning-Algorithmen verwendet. \n\n* Es ist klar geworden, dass die Konfusionsmatrix kein gutes Werkzeug ist, um die Ergebnisse im Fall von unausgewogenen Datens\u00e4tzen darzustellen. Sie dient dennoch dazu, leicht zu erkennen, wie viele der fraudulent Transaktionen erkannt wurden. \n\n* Trefferquote (Recall): Gibt die Wahrscheinlichkeit an, mit der ein positives Ergebnis richtig klassifiziert wird. Bsp. wie wahrscheinlich ist es, dass ein Corona infizierter Mensch durch einen Test tatsaechlich als Corona-Infizierter erkannt wird.  \n\n* F-Ma\u00df: Kombiniert Genauigkeit und Trefferquote mithilfe des harmonischen Mittels [F= 2((PR)\/(P+R))]\n\n\n* F1-Ma\u00df: F(\u03b1) = (1+\u03b1\u00b2) * ((PR)\/( \u03b1\u00b2P+R)) Durch die Anpassung von \u03b1 passt man die Gewichtung an.\n* Bsp.:    F(2)= Trefferquote 4 x mehr Gewichtet als Genauigkeit  F(0,5)= Genauigkeit 4 mal mehr gewichtet als Trefferquote","118b471c":"* Mit Hilfe von **df.columns** werden die Spaltennamen in **column_names** gespeichert und anschliessend ausgegeben.","89450485":"# 3.2 **KNeighbors** (Oversampling)","9199dbb3":"* train_smot enth\u00e4lt nun 199364 Transaktionen. \n* Dabei wurden durch Zufall 344 fraudalent Transaktions und 199020 non-fraudalent Transaktions gezogen. ","89b2376c":"* Da die Oversampling Methode SMOT nur auf den Trainings Datensatz angewendet werden soll und nicht auf den Test Datensatz, wird zun\u00e4chst ein Train Test Split durchgef\u00fchrt.\n* Dabei wird mit dem Parameter **test_size** ein Trainings Datensatz **train.smot** erstellt, der 70% der Transaktionen von df enth\u00e4lt.\n","c72a6c04":"# 1.1 **Random Forest** (Undersampling)","40da7f15":"# 2.1 **Oversampling (Random Oversampling)**\n\n   1. **Random Oversampling**\n        * Analog zu der Undersampling Methode wird mit **.sample(frac=1, random_state = 100)** eine zuf\u00e4llige gleich gro\u00dfe Menge aus dem Datensatz **df** erstellt und in **df_randomised** gespeichert.\n        * Anschliessend werden alle Transaktionen der Menge **df_randomised**, die als **Klassifikator** den Wert **0** besitzen, in dem Datensatz **df_non_fraudulent** gespeichert. \n        * Anschliessend werden alle Transaktionen der Menge **df_randomised**, die als **Klassifikator** den Wert **1** besitzen, in dem Datensatz **df_fraudulent** gespeichert. \n        * Mit der Methode **.sample()** werden zuf\u00e4llige Transaktionen aus dem zuvor erstellten Datensatz der **fraudulent transactions** gezogen, wobei der Parameter **replace = True** dafuer sorgt, dass beim Ziehen immer wieder zurueck gelegt wird. Der Paramter **n** legt die Anazahl an Werten fest, die gezogen werden sollen. Dabei gibt **len(df_non_fraudulent)** die Anzahl an Rows des Datensatzes **df_non_fraudulent** zureuck, um sicher zu stellen, dass **df_random_fraudulent_oversampling** die gleiche Gr\u00f6\u00dfe hat wie **df_non_fraudulent**.\n        * Zuletzt werden die Datens\u00e4tze **df_random_fraudulent_oversampling** und **df_non_fraudulent** miteinander **konkateniert**"}}