{"cell_type":{"76de4e54":"code","3e768199":"code","efc9d2a0":"code","707b372f":"code","b6f07afc":"code","f8756ebc":"code","695ec257":"code","0630bc9c":"code","3629887c":"code","ddc0baf0":"code","d6eaaa82":"code","5d763520":"code","bcfecac7":"code","a00fcb29":"code","1332ac20":"code","7d880289":"code","c72cbc35":"code","b479c95d":"code","fc4374b2":"code","668cc095":"code","da456d54":"markdown","a1443daf":"markdown"},"source":{"76de4e54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3e768199":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier","efc9d2a0":"df = pd.read_csv(\"\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")\ndf.head()","707b372f":"df.columns","b6f07afc":"df.isna().any()","f8756ebc":"df = df.fillna(0)","695ec257":"df1 = df.copy()","0630bc9c":"df.info()","3629887c":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\noh = OneHotEncoder()\n\ndf['gender'] = le.fit_transform(df['gender'])\ndf['status'] = le.fit_transform(df['status']) \ndf['workex'] = le.fit_transform(df['workex'])\ndf['ssc_b'] = le.fit_transform(df['ssc_b'])\ndf['hsc_b'] = le.fit_transform(df['hsc_b'])\ndf['hsc_s'] = le.fit_transform(df['hsc_s'])\ndf['degree_t'] = le.fit_transform(df['degree_t'])\ndf['hsc_b'] = le.fit_transform(df['hsc_b'])\ndf['specialisation'] = le.fit_transform(df['specialisation'])\n","ddc0baf0":"#df['ssc_b'] = oh.fit_transform(df['ssc_b'])\n#df['hsc_b'] = oh.fit_transform(df['hsc_b'])","d6eaaa82":"#for col in df.columns:\n #   le.fit_transform(df.columns)\ndf.head()","5d763520":"X  = df.drop(['sl_no', 'mba_p',], axis = 1)\ny= df['mba_p']","bcfecac7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)","a00fcb29":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train, y_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","1332ac20":"#from sklearn.preprocessing import LabelEncoder\n#le = LabelEncoder()\n#le.fit(X, y)\n#le.fit(y)","7d880289":"classifier=RandomForestClassifier(n_estimators=100)\nmodel = classifier.fit(X_train, y_train.astype('int'))","c72cbc35":"y_pred = model.predict(X_test)\n","b479c95d":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf","fc4374b2":"from sklearn import metrics\nfrom sklearn.metrics import r2_score\n","668cc095":"\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score:', r2_score(y_test, y_pred).round(3))\nprint('Accuracy:', metrics.accuracy_score(y_test.astype('int'), y_pred).round(3))","da456d54":"# Don't forget to vote. Thanks","a1443daf":"***Random Forest has very poor accuracy score, hence this model cannot be used***"}}