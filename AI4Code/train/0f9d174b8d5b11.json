{"cell_type":{"00fe26e8":"code","5d0fec43":"code","91cb0bc5":"code","17661355":"code","c6075cf3":"code","43416dd5":"code","7d25b935":"code","773aa666":"code","eccb199a":"code","6ab22376":"code","dd3037b3":"code","d7ff961f":"code","a4400fe1":"code","baf39b98":"code","c70bd1e0":"code","36a29ec1":"code","92d79e89":"code","413a1e11":"code","7c673d05":"code","1df439b3":"code","d6fc6fe3":"code","9657c35a":"code","815c165c":"code","7e6b076f":"code","e500a867":"code","b263ec93":"code","731897bd":"code","1b69bd61":"code","b7b6a107":"code","e06d8927":"code","d28606e0":"code","eebd462c":"code","3b0a4d55":"code","bedc7a7a":"code","05ae11ac":"code","5c3ef5df":"code","3f635aeb":"code","8f4e5131":"code","1d2240cb":"code","ffe7c1e3":"code","952ecc63":"code","8fc3648c":"code","9201969f":"code","4f87c079":"code","db5cc301":"code","931d1326":"code","41d7a11f":"code","d3220481":"code","6f437cc3":"code","1425c28d":"code","734fbac7":"code","b7577e27":"code","26d0fd47":"code","2605de4a":"code","8c90ddc5":"code","7ddf8d4f":"code","dc6eae84":"markdown","88df1bb5":"markdown","6c3b55f7":"markdown","121adcc2":"markdown","00fa07c0":"markdown","ba3b00ea":"markdown","512366aa":"markdown","6f36742a":"markdown","91938c81":"markdown","f4a49685":"markdown","74cd173f":"markdown","0740d585":"markdown","9aa90029":"markdown","e0da54e8":"markdown","5d18b5de":"markdown","4de57c48":"markdown","5f140cd8":"markdown","1b3709fc":"markdown","0be0c0c6":"markdown","5b454c88":"markdown","56284b17":"markdown","0dc45f28":"markdown","7a3bd6ad":"markdown","aba920cd":"markdown","80f0ec15":"markdown"},"source":{"00fe26e8":"pip install xgboost","5d0fec43":"import numpy as np #Mengolah matrix\nimport pandas as pd #Read structured data\nimport matplotlib.pyplot as plt #Data plot visualization\nimport seaborn as sns\n\n#Machine Learning\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler  #Feature Scaling\nfrom sklearn.model_selection import train_test_split #Data Partition\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import  RandomForestClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\n#ensembling\nfrom sklearn.ensemble import VotingClassifier","91cb0bc5":"eshop = pd.read_csv('..\/input\/eshop-clothing-dataset\/e-shop clothing 2008.csv', delimiter=',')","17661355":"eshop.shape","c6075cf3":"eshop","43416dd5":"# filter vriable page\npage = eshop[(eshop['page']==2)]\npage","7d25b935":"# filter vriable page\npage3 = eshop[(eshop['page']==3)]\npage3","773aa666":"harga_no = eshop[(eshop['price 2']==2)]\nharga_no","eccb199a":"harga_yes = eshop[(eshop['price 2']==1)]\nharga_yes","6ab22376":"numerik= eshop.select_dtypes(exclude='O')\nbaju = eshop.select_dtypes(include='O')","dd3037b3":"baju.columns","d7ff961f":"# encoding for categorical data\nfrom sklearn.preprocessing import OrdinalEncoder","a4400fe1":"oe = OrdinalEncoder()\nenkode = oe.fit_transform(baju)\nenkode","baf39b98":"dat_cat = pd.DataFrame(enkode,columns=baju.columns).astype('int')\ndat_cat","c70bd1e0":"# reconstruct data\neshop2 = pd.concat([numerik,dat_cat],axis=1)\neshop2","36a29ec1":"harga_yes2 = eshop2[(eshop2['price 2']==1)]\nharga_yes2","92d79e89":"harga_no2 = eshop2[(eshop2['price 2']==2)]\nharga_no2","413a1e11":"beige = eshop2[(eshop2['colour']==1)]\nbeige","7c673d05":"eshop2.info()","1df439b3":"cols= [\"#C2C4E2\",\"#EED4E5\"]\nplt.figure(figsize=(10,10))\nsns.countplot(x= eshop2['price 2'], palette = 'Blues')\n\nplt.show()","d6fc6fe3":"cols= [\"#C2C4E2\",\"#EED4E5\"]\nplt.figure(figsize=(10,10))\nsns.barplot(x= eshop2['page 1 (main category)'], y= eshop2['price'],palette = 'Blues')\nplt.xlabel('Kategori Pakaian')\nplt.ylabel('Harga (Dalam Dollar)')\nplt.show()","9657c35a":"plt.figure(figsize=(15,15))\nsns.barplot(x=eshop2['country'],y=eshop2['colour'])\nplt.show()","815c165c":"plt.figure(figsize=(10,10))\nsns.countplot(x=beige['country'])\nplt.show()","7e6b076f":"corr = eshop2.corr(method = 'pearson')","e500a867":"colormap = plt.cm.PuBu \nplt.figure(figsize=(15,5)) \nplt.title(\"Person Correlation of Features\", y = 1, size = 20) \nsns.heatmap(corr.astype(float).corr(), linecolor = \"white\", cmap = colormap, annot = True)","b263ec93":"eshop2.isnull().sum()","731897bd":"eshop.describe()","1b69bd61":"sns.boxplot(eshop2[\"day\"])","b7b6a107":"sns.boxplot(eshop2[\"session ID\"])","e06d8927":"sns.boxplot(eshop2[\"page 1 (main category)\"])","d28606e0":"sns.boxplot(eshop2[\"page 2 (clothing model)\"])","eebd462c":"sns.boxplot(eshop2[\"colour\"])","3b0a4d55":"sns.boxplot(eshop2[\"price\"])","bedc7a7a":"sns.boxplot(eshop2[\"page\"])","05ae11ac":"#Data 'price' diisi dengan median\nfill=eshop2[\"price\"].median()\neshop2[\"price\"]=eshop2[\"price\"].fillna(fill)","5c3ef5df":"#lihat outlier observasi pada variabel 'price'\nQ1 =eshop2[\"price\"].quantile(0.25)\nQ3 =eshop2[\"price\"].quantile(0.75)    \nIQR=Q3-Q1\nlower_range = Q1 -(1.5 * IQR)\nupper_range = Q3 +(1.5 * IQR)\neshop2.loc[(eshop2[\"price\"]>upper_range),:]","3f635aeb":"#Ganti outlier observations dengan upper bound dan lower bound\neshop2.loc[(eshop2[\"price\"]>upper_range),\"price\"]=upper_range","8f4e5131":"sns.boxplot(eshop2[\"price\"])","1d2240cb":"#Data 'page' diisi dengan median\nfill=eshop2[\"page\"].median()\neshop2[\"page\"]=eshop2[\"page\"].fillna(fill)","ffe7c1e3":"#lihat outlier observasi pada variabel 'page'\nQ1 =eshop2[\"page\"].quantile(0.25)\nQ3 =eshop2[\"page\"].quantile(0.75)    \nIQR=Q3-Q1\nlower_range = Q1 -(1.5 * IQR)\nupper_range = Q3 +(1.5 * IQR)\neshop2.loc[(eshop2[\"page\"]>upper_range),:]","952ecc63":"#Ganti outlier observations dengan upper bound dan lower bound\neshop2.loc[(eshop2[\"page\"]>upper_range),\"page\"]=upper_range","8fc3648c":"sns.boxplot(eshop2[\"page\"])","9201969f":"eshop2.duplicated()","4f87c079":"\ny = eshop2[\"price 2\"]\nX = eshop2.drop('price 2',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.20, random_state = 0)","db5cc301":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n#https:\/\/www.megabagus.id\/feature-scaling\/","931d1326":"m1 = 'Logistic Regression'\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\nprint(classification_report(y_test,lr_predict))","41d7a11f":"m2 = 'Naive Bayes'\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nnbpred = nb.predict(X_test)\nnb_conf_matrix = confusion_matrix(y_test, nbpred)\nnb_acc_score = accuracy_score(y_test, nbpred)\nprint(\"confussion matrix\")\nprint(nb_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Naive Bayes model:\",nb_acc_score*100,'\\n')\nprint(classification_report(y_test,nbpred))","d3220481":"m3 = 'Random Forest Classfier'\nrf = RandomForestClassifier(n_estimators=20, random_state=12,max_depth=5)\nrf.fit(X_train,y_train)\nrf_predicted = rf.predict(X_test)\nrf_conf_matrix = confusion_matrix(y_test, rf_predicted)\nrf_acc_score = accuracy_score(y_test, rf_predicted)\nprint(\"confussion matrix\")\nprint(rf_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\nprint(classification_report(y_test,rf_predicted))","6f437cc3":"m4 = 'K-NeighborsClassifier'\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\nknn_predicted = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predicted)\nknn_acc_score = accuracy_score(y_test, knn_predicted)\nprint(\"confussion matrix\")\nprint(knn_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of K-NeighborsClassifier:\",knn_acc_score*100,'\\n')\nprint(classification_report(y_test,knn_predicted))","1425c28d":"m5 = 'DecisionTreeClassifier'\ndt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)\ndt.fit(X_train, y_train)\ndt_predicted = dt.predict(X_test)\ndt_conf_matrix = confusion_matrix(y_test, dt_predicted)\ndt_acc_score = accuracy_score(y_test, dt_predicted)\nprint(\"confussion matrix\")\nprint(dt_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of DecisionTreeClassifier:\",dt_acc_score*100,'\\n')\nprint(classification_report(y_test,dt_predicted))","734fbac7":"m6 = 'Support Vector Classifier'\nsvc =  SVC(kernel='rbf', C=2)\nsvc.fit(X_train, y_train)\nsvc_predicted = svc.predict(X_test)\nsvc_conf_matrix = confusion_matrix(y_test, svc_predicted)\nsvc_acc_score = accuracy_score(y_test, svc_predicted)\nprint(\"confussion matrix\")\nprint(svc_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Support Vector Classifier:\",svc_acc_score*100,'\\n')\nprint(classification_report(y_test,svc_predicted))","b7577e27":"model = XGBClassifier()\nmasuk = model.fit(X,y)\nprint(model.feature_importances_)","26d0fd47":"plot_importance(model)\nplt.show()","2605de4a":"model_ev = pd.DataFrame({'Model': ['Logistic Regression','Naive Bayes','Random Forest',\n                    'K-Nearest Neighbour','Decision Tree','Support Vector Machine'], 'Accuracy': [lr_acc_score*100,\n                    nb_acc_score*100,rf_acc_score*100,knn_acc_score*100,dt_acc_score*100,svc_acc_score*100]})\nmodel_ev","8c90ddc5":"colors = ['red','green','blue','purple','yellow','orange',]\nplt.figure(figsize=(12,5))\nplt.title(\"barplot Represent Accuracy of different models\")\nplt.xlabel(\"Accuracy % \\n\")\nplt.ylabel(\"Algorithms \\n\")\nplt.bar(model_ev['Model'],model_ev['Accuracy'],color = colors)\nplt.show()","7ddf8d4f":"m1 = LogisticRegression()\nm2 = GaussianNB()\nm3 = RandomForestClassifier()\nm4 = KNeighborsClassifier()\nm5 = DecisionTreeClassifier()\nm6 = SVC()\n\nmodel = VotingClassifier(estimators\n    =[('lr', m1), ('nb', m2), ('rf', m3),\n      ('knn', m4), ('dt', m5), ('svc', m6)], voting='hard')\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","dc6eae84":"# CONCLUSION","88df1bb5":"Normalization \/ Feature Scaling\n\nMembuat tiap fitur memiliki nilai rata-rata 0 dan variansi 1.","6c3b55f7":"***DATA DESCRIPTIONS***\n\nIndependent Variables (x):\n1. year : (2008)\n\n2. month : from April (4) to August (8)\n\n3. day : day number of the month\n\n4. order : sequence of clicks during one session\n\n5. country : \n\n1-Australia\n2-Austria\n3-Belgium\n4-British Virgin Islands\n5-Cayman Islands\n6-Christmas Island\n7-Croatia\n8-Cyprus\n9-Czech Republic\n10-Denmark\n11-Estonia\n12-unidentified\n13-Faroe Islands\n14-Finland\n15-France\n16-Germany\n17-Greece\n18-Hungary\n19-Iceland\n20-India\n21-Ireland\n22-Italy\n23-Latvia\n24-Lithuania\n25-Luxembourg\n26-Mexico\n27-Netherlands\n28-Norway\n29-Poland\n30-Portugal\n31-Romania\n32-Russia\n33-San Marino\n34-Slovakia\n35-Slovenia\n36-Spain\n37-Sweden\n38-Switzerland\n39-Ukraine\n40-United Arab Emirates\n41-United Kingdom\n42-USA\n43-biz (.biz) 44-com (.com)\n45-int (.int) 46-net (.net)\n47-org (*.org)\n\n6. session ID :\n\n7. page 1 (main category) : \n\n1-trousers \n\n2-skirts\n\n3-blouses\n\n4-sale \n\n8. page 2 (clothing model 1) : contains information about the code for each product (217 products)\n\n9. colour : \n\n1-beige\n\n2-black\n\n3-blue\n\n4-brown\n\n5-burgundy\n\n6-gray\n\n7-green\n\n8-navy blue\n\n9-of many colors\n\n10-olive\n\n11-pink\n\n12-red\n\n13-violet\n\n14-white\n\n10. location : \n\n1-top left\n\n2-top in the middle\n\n3-top right\n\n4-bottom left\n\n5-bottom in the middle\n\n6-bottom right\n\n11. model photography : 1-en face, 2-profile\n\n12. price : price in US dollars\n\n13. page : page number within the e-store website (from 1 to 5)\n\n\n\nDependent Variable (y):\n\n14. target : price 2 (1-yes, 2-no)","121adcc2":"# E-SHOP CLOTHING 2008\n***DATA UNDERSTANDING***\n\nPrediksi terhadap e-store website untuk mengetahui harga pakaian yang diatas harga rata-rata berdasarkan variable-variable penentunya.","00fa07c0":"Max Voting","ba3b00ea":"# MODEL EVALUATION","512366aa":"-> price","6f36742a":"-> page","91938c81":"Dataset yang akan saya gunakan yaitu data mengenai e-shop website pada tahun 2008 berisikan tanggal, model pakaian, negara, dan lain-lain yang saya unduh langsung pada kaggle https:\/\/www.kaggle.com\/adityawisnugrahas\/eshop-clothing-dataset","f4a49685":"Langkah selanjutnya adalah memperoleh pengetahuan tentang statistik ringkasan data dasar menggunakan metode .describe(), yang menghitung nilai count, mean, standar deviasi, minimum, maksimum dan persentil (25, 50 dan 75). Ini membantu kita mendeteksi anomali apa pun dalam kumpulan data kita. Seperti variabel dengan varians tinggi atau data yang sangat miring.","74cd173f":"# LOADING LIBRARIES AND DATA SET","0740d585":"Fill Missing Values\n\n-> Dataset hasn't any missing value.","9aa90029":"Outlier Finding","e0da54e8":"1. Serangkaian model yang beragam cenderung membuat keputusan yang lebih baik dibandingkan dengan dengan model tunggal.\n2. Data yang paling besar pengaruhnya terhadap harga rata-rata diantaranya adalah price, page 1(main category), page 2(clothing model), location, colour, page.","5d18b5de":"Finding Duplicate Data","4de57c48":"Negara Polandia adalah negara yang paling banyak membeli pakaian berwarna beige","5f140cd8":"# DATA PREPARATION\n\nMissing Value Checking","1b3709fc":"# MODEL FITTING\n\nDi sini saya mengambil Algoritma Machine Learning yang berbeda dan mencoba menemukan algoritma yang memprediksi secara akurat.\n\n>1. Logistic Regression\n2. Naive Bayes\n3. Random Forest Classifier\n4. K-Nearest Neighbour\n5. Decision Tree\n6. Support Vector Machine","0be0c0c6":">Dari tabel korelasi dapat dilihat bahwa age mempunyai hubungan linear positif yang sangat kuat dengan target jika dibandingkan yang lain. Nilai korelasi variabel lain hampir mendekati nol yang menandakan bahwa variable2 tersebut kurang berpengaruh terhadap nilai target.","5b454c88":">Sebelum menerapkan algoritma kita harus memeriksa apakah data dibagi rata atau tidak, karena jika data tidak dibagi rata akan menyebabkan masalah ketidakseimbangan data\n\nTrain and Test Split\n\nSeluruh kumpulan data umumnya dibagi menjadi 80% train dan 20% kumpulan data uji (aturan umum). Data latih 80% digunakan untuk pelatihan model, sedangkan 20% sisanya digunakan untuk memeriksa bagaimana model digeneralisasikan pada kumpulan data yang tidak terlihat.","56284b17":"Mengidentifikasi tipe data dan keberadaan nilai yang hilang","0dc45f28":"# ENSEMBLING\n>In order to increase the accuracy of the model we use ensembling. Here I use Max Voting technique (BASIC).\n\nMetode max voting umumnya digunakan untuk masalah klasifikasi. Dalam teknik ini, beberapa model digunakan untuk membuat prediksi untuk setiap titik data. Prediksi oleh masing-masing model dianggap sebagai 'suara'. Prediksi yang didapatkan dari sebagian besar model digunakan sebagai prediksi akhir.","7a3bd6ad":"# EXPLORATORY AND VISUAIZATION DATA ANALISYS","aba920cd":"Outlier Fixing (price, page)","80f0ec15":"Plot warna pakaian beige paling banyak di negara mana?"}}