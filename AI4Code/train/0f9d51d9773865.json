{"cell_type":{"d4d864f2":"code","94b89e5e":"code","aa59487c":"code","1b71353d":"code","f06aae3b":"code","6e1541bf":"code","64faeaa2":"code","e9cd66d0":"code","c6329864":"code","798aa655":"code","56a0d458":"code","6dffa073":"code","a4c7e7af":"code","20539cf4":"code","e00275e3":"code","374474da":"code","c47b6501":"code","cb0c9cae":"code","3616363d":"code","ce4385bf":"code","01f17523":"code","b30b61ff":"markdown","81380569":"markdown","09bf3483":"markdown","4dc7a253":"markdown","6d0c215e":"markdown"},"source":{"d4d864f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94b89e5e":"import re\nimport math\nimport random\nfrom collections import Counter, defaultdict\n\n#import nltk\nfrom nltk.corpus import stopwords, movie_reviews","aa59487c":"df = pd.read_csv('\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv')\npd.to_datetime(df['date'])","1b71353d":"df.shape","f06aae3b":"df.head()","6e1541bf":"df.date.value_counts().sort_index()","64faeaa2":"#df.text[0].split(' ')[0]\nall_words = []\nhashtags_in_text = []\n\nstop = stopwords.words('english')\n\nfor i in df.text[:500]:\n    for j in i.split(' '):\n        if j.lower() not in stop:\n            if '#' not in j and 'https' not in j:\n                all_words.append(j.lower())\n            elif '#' in j:\n                hashtags_in_text.append(j)\n        \nall_words_dict = Counter(all_words)\nhashtags_in_text_dict = Counter(hashtags_in_text)","e9cd66d0":"all_words_dict.most_common(5)","c6329864":"hashtags_in_text_dict.most_common(5)","798aa655":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom PIL import Image","56a0d458":"def text_size(total):\n    return 30 + ((total \/ 200) * 40)\n\nmost_common = []\nstr_common = ''\nstopwords = set(STOPWORDS)\n\nfor word, value in all_words_dict.most_common(40):\n    most_common.append(word)\n\nstr_common += ' '.join(most_common)\n\nplt.figure(figsize = (15, 8), facecolor = None)\n\n\nwordcloud = WordCloud(width = 800, height = 800, \n                    background_color ='white',\n                    stopwords = stopwords,\n                    min_font_size = 10, mode=\"RGBA\").generate(str_common)\nplt.imshow(wordcloud)\nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show()","6dffa073":"def text_size(total):\n    return 30 + ((total \/ 200) * 40)\n\nmost_common = []\nstr_common = ''\nstopwords = set(STOPWORDS)\n\nfor word, value in hashtags_in_text_dict.most_common(40):\n    most_common.append(word)\n\nstr_common += ' '.join(most_common)\n\nplt.figure(figsize = (15, 8), facecolor = None)\n\nwordcloud = WordCloud(width = 800, height = 800, \n                    background_color ='white',\n                    stopwords = stopwords,\n                    min_font_size = 10, mode=\"RGBA\").generate(str_common)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show()","a4c7e7af":"df.head(2)","20539cf4":"df.text.values[0]","e00275e3":"tweet = df['text'][0].lower()\nall_words = re.findall(\"[a-z0-9']+\", tweet)\nall_words","374474da":"for i, j in zip(df.text.values, df.user_verified.values):\n    print(i, j)\n    break","c47b6501":"def tokenize(tweet):\n    tweet = tweet.lower()\n    all_words = re.findall(\"[a-z0-9']+\", tweet)\n    return set(all_words)","cb0c9cae":"def count_UV(training_set):\n    counts = defaultdict(lambda: [0, 0])\n    for tweet, is_verified in training_set:\n        for word in tokenize(tweet):\n            if is_verified:\n                counts[word][0] += 1\n            else:\n                counts[word][1] += 1\n    return counts","3616363d":"def word_probs(total_verified, total_non_verified, counts, k = 1.0):\n    probs = []\n    for word, (verified, not_verified) in counts.items():\n        verified_prob = (k + verified) \/ (2 * k + total_verified)\n        not_verified_prob = (k + not_verified) \/ (2 * k + total_non_verified)\n        probs.append((word, verified_prob, not_verified_prob))\n    return probs","ce4385bf":"def verified_prob(probs, tweet):\n    tweet_words = tokenize(tweet)\n    log_prob_if_verified = 0.0\n    log_prob_if_not_verified = 0.0\n    \n    for word, prob_if_verified, prob_if_not_verified in probs:\n        if word in tweet_words:\n            log_prob_if_verified += math.log(prob_if_verified)\n            log_prob_if_not_verified += math.log(prob_if_not_verified)\n        else:\n            log_prob_if_verified += math.log(1.0 - prob_if_verified)\n            log_prob_if_not_verified += math.log(1.0 - prob_if_not_verified)\n            \n    prob_if_verified = math.exp(log_prob_if_verified)\n    prob_if_not_verified = math.exp(log_prob_if_not_verified)\n    return prob_if_verified \/ (prob_if_verified + prob_if_not_verified)","01f17523":"class NaiveBayesClassifier:\n    \n    def __init__(self, k=0.5):\n        self.k = k\n        self.word_probs = []\n        \n    def train(self, training_set):\n        num_verified = len([is_verified\n                            for message, is_verified in training_set\n                            if is_verified])\n        num_non_verified = len(training_set) - num_verified\n        \n        word_counts = count_UV(training_set)\n        self.word_probs = verified_prob(word_counts)","b30b61ff":"# Naive Bayes","81380569":"****-------------------------- UNDER CONSTRUCTION ---------------------------****","09bf3483":"# Word cloud","4dc7a253":"I use Naive Bayes theorem to find out whether a tweet is from a verified account or not. The following is the algorithm.","6d0c215e":"# Naive Bayes"}}