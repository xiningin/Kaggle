{"cell_type":{"7c541131":"code","bb8b8372":"code","f99b35a6":"code","cd583882":"code","93d958de":"code","4b6e4a9c":"code","f057e99d":"code","b5939c5d":"code","cc15f4cf":"code","cd9b6b1f":"code","9050794e":"code","5b8014d5":"code","f1ecdf3d":"code","42904ba4":"code","02550f6f":"code","e999c971":"code","ebf16efe":"code","1c985022":"code","4e039f40":"code","e3f7773b":"code","91b10251":"code","816d2637":"code","19c75cd9":"code","1e330b8f":"code","7ff75c6c":"code","b86c1c97":"code","c5a5669f":"code","9d09a0fc":"code","805da9aa":"code","610e0192":"code","5105d0f4":"code","7eb3999c":"code","43c222fc":"code","6ebaaf79":"code","c45d3222":"code","b57cdfd0":"code","df2652f0":"markdown","520a2c00":"markdown"},"source":{"7c541131":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb8b8372":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\npd.set_option('display.max_columns', 26)","f99b35a6":"df = pd.read_csv('..\/input\/ckdisease\/kidney_disease.csv')\ndf.head()","cd583882":"df.shape\ndf.drop('id', axis = 1, inplace = True)","93d958de":"df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n              'aanemia', 'class']","4b6e4a9c":"df.head()","f057e99d":"df.info()","b5939c5d":"######Cenverting necessary coluns to nurmaric type\n\ndf['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'],errors=\"coerce\")\ndf['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'],errors=\"coerce\")\ndf['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'],errors=\"coerce\")","cc15f4cf":"df.info()","cd9b6b1f":"##extracting numaric and categorical data \n\nnum_cols = [col for col in df.columns if df[col].dtype != 'object']\ncat_cols = [col for col in df.columns if df[col].dtype == 'object']\n\n","9050794e":"num_cols\n","5b8014d5":"#####check unique values in the categorical data \n\nfor col in cat_cols:\n    print(f\"{col} has {df[col].unique()} values\\n\")","f1ecdf3d":"### As you can see there are some type in the data need to be fixed","42904ba4":"df['diabetes_mellitus'].replace(to_replace={'\\tno' :'no' ,'\\tyes' :'yes' , ' yes' :'yes'},inplace=True)\ndf['coronary_artery_disease'].replace(to_replace='\\tno' , value='no',inplace=True)\ndf['class'].replace(to_replace=\"ckd\\t\" ,value=\"ckd\",inplace=True) ","02550f6f":"for col in cat_cols:\n    print(f\"{col} has {df[col].unique()} values\\n\")","e999c971":"###plotting displot to see how the disptripution the data is \n\nplt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor column in num_cols:\n    if plotnumber <= 14:\n        ax = plt.subplot(3, 5, plotnumber)\n        sns.distplot(df[column])\n        plt.xlabel(column)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","ebf16efe":"#####to handel the skewness in the data \ndef handel_outlier(col):\n    df[col] =np.log1p(df[col])","1c985022":"\nhandel_outlier('blood_urea')\nhandel_outlier('sodium')\nhandel_outlier('potassium')\nhandel_outlier('serum_creatinine')\nhandel_outlier('sugar')","4e039f40":"###plotting displot to see how the disptripution the data is \n\nplt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor column in num_cols:\n    if plotnumber <= 14:\n        ax = plt.subplot(3, 5, plotnumber)\n        sns.distplot(df[column])\n        plt.xlabel(column)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","e3f7773b":"##that explins why soe data still skeness although we to process on it  , becaus it stil has null data \ndf.isna().sum()","91b10251":"#filling null values, we will use two methods, random sampling for higher null values and \n# mean\/mode sampling for lower null values\ndef random_value_imputation(feature):\n    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n    random_sample.index = df[df[feature].isnull()].index\n    df.loc[df[feature].isnull(),feature] =random_sample\n    \ndef impute_mode(feature):\n    mode = df[feature].mode()[0]\n    df[feature] =df[feature].fillna(mode)","816d2637":"###filling num columns null values uysing rando sampling method\n\nfor col in num_cols:\n    random_value_imputation(col)","19c75cd9":"df[num_cols].isnull().sum()","1e330b8f":"# random_value_imputation('red_blood_cells')\n# random_value_imputation('pus_cell')\nfor col in cat_cols:\n    impute_mode(col)","7ff75c6c":"df[cat_cols].isnull().sum()","b86c1c97":"###label encoding for categorical data \nfrom sklearn.preprocessing  import LabelEncoder\n\nencode = LabelEncoder()\n\nfor col in cat_cols:\n    df[col]=encode.fit_transform(df[col])","c5a5669f":"df.head()","9d09a0fc":"### splitting the data\nX = df.drop(columns ='class' , axis=1)\nY = df['class']","805da9aa":"##model selection \nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.feature_selection import SelectFromModel\n\nfeture_el_model  = SelectFromModel(Lasso(alpha=0.005 ,random_state =42))\n\nfeture_el_model.fit(X,Y)\nfeture_el_model.get_support()","610e0192":"cols= X.columns\nselected_feature = cols[feture_el_model.get_support()]","5105d0f4":"print('total_features {}' .format(X.shape[1]))\nprint('total_features {}' .format(len(selected_feature)))","7eb3999c":"X= X[selected_feature]","43c222fc":"from sklearn.model_selection import train_test_split\n\nx_train , x_test , y_train , y_test = train_test_split(X,Y,test_size=.3,random_state=42)","6ebaaf79":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix ,accuracy_score\n\nmodels = []\nmodels.append(('LogisticRegression',LogisticRegression(solver='liblinear')))\nmodels.append(('Naive bayes' ,GaussianNB()))\nmodels.append(('RandomForest' ,RandomForestClassifier()))\nmodels.append(('Decision Tree ' ,DecisionTreeClassifier()))\nmodels.append (('KNN' ,KNeighborsClassifier()))","c45d3222":"for name , model in models :\n    print(name)\n    model.fit(x_train , y_train)\n    \n    prediction = model.predict(x_test)\n    \n    from sklearn.metrics import confusion_matrix\n    \n    print(confusion_matrix(prediction,y_test))\n    print('\\n')\n    print(accuracy_score(prediction,y_test))\n    print('\\n')","b57cdfd0":"model = RandomForestClassifier()\nprint('RandomForest')\nmodel.fit(x_train , y_train)\nprediction = model.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\n    \nprint(confusion_matrix(prediction,y_test))\nprint('\\n')\nprint(accuracy_score(prediction,y_test))\nprint('\\n')","df2652f0":"**As you can see that soem of the data are objects , however they are numaric**","520a2c00":"**Building ML Models**"}}