{"cell_type":{"f28e57b5":"code","68acac11":"code","348eeb52":"code","3d3c2f5f":"code","23ace693":"code","1ab95bdb":"code","ab3754da":"code","bb9089d3":"code","34a5e3ef":"code","2e992110":"code","d0cd9a09":"code","97489bc9":"code","eaddb02f":"code","ec253180":"code","6f2d4371":"code","85e67080":"code","cb1807ea":"code","1b2eea67":"code","35aafbf5":"code","8becb5e4":"markdown","73cda0cb":"markdown","b6a2cdc9":"markdown","d38739ce":"markdown","7a530699":"markdown","277f0399":"markdown","98ac4be9":"markdown","71abee34":"markdown","28a0226e":"markdown","f535e7e3":"markdown","a4371bf7":"markdown","b3ea821b":"markdown","40334614":"markdown","2eb7c5b6":"markdown"},"source":{"f28e57b5":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras import backend as K\nwarnings.filterwarnings(action='ignore')\n\nK.image_data_format()","68acac11":"# path \ubaa9\ub85d\nMODEL_PATH = '..\/input\/kakr3rdxception\/kakr-3rd-xception'\nFOLD_DATA_PATH = '..\/input\/3rd-ml-df-folds\/3rd_ml_df_folds\/'\nDATA_PATH = '..\/input\/carimagesegcrop\/car-image-segcropping'\n\n# CSV \ud30c\uc77c \uacbd\ub85c\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","348eeb52":"# Xception : (299, 299)\nIMAGE_WIDTH, IMAGE_HEIGHT = (299, 299)\nclasses = df_class['id'].values.astype('str').tolist()\n\nBATCH_SIZE = 32\nEPOCHS = 30\nK_FOLDS = 5\nPATIENCE = 6","3d3c2f5f":"epochs = EPOCHS\nbatch_size = BATCH_SIZE\n\ndef get_total_batch(num_samples, batch_size):\n    if (num_samples % batch_size) > 0:\n        return (num_samples \/\/ batch_size) + 1\n    else:\n        return num_samples \/\/ batch_size","23ace693":"def recall(y_target, y_pred):\n    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max \uc774\uc678 \uac00\uc7a5\uc790\ub9ac\ub97c \uae4e\uc544 \ub0b8\ub2e4\n    # round : \ubc18\uc62c\ub9bc\ud55c\ub2e4\n    y_target_yn = K.round(K.clip(y_target, 0, 1)) # \uc2e4\uc81c\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # \uc608\uce21\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n\n    # True Positive\ub294 \uc2e4\uc81c \uac12\uacfc \uc608\uce21 \uac12\uc774 \ubaa8\ub450 1(Positive)\uc778 \uacbd\uc6b0\uc774\ub2e4\n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n\n    # (True Positive + False Negative) = \uc2e4\uc81c \uac12\uc774 1(Positive) \uc804\uccb4\n    count_true_positive_false_negative = K.sum(y_target_yn)\n\n    # Recall =  (True Positive) \/ (True Positive + False Negative)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    recall = count_true_positive \/ (count_true_positive_false_negative + K.epsilon())\n\n    # return a single tensor value\n    return recall\n\n\ndef precision(y_target, y_pred):\n    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max \uc774\uc678 \uac00\uc7a5\uc790\ub9ac\ub97c \uae4e\uc544 \ub0b8\ub2e4\n    # round : \ubc18\uc62c\ub9bc\ud55c\ub2e4\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # \uc608\uce21\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n    y_target_yn = K.round(K.clip(y_target, 0, 1)) # \uc2e4\uc81c\uac12\uc744 0(Negative) \ub610\ub294 1(Positive)\ub85c \uc124\uc815\ud55c\ub2e4\n\n    # True Positive\ub294 \uc2e4\uc81c \uac12\uacfc \uc608\uce21 \uac12\uc774 \ubaa8\ub450 1(Positive)\uc778 \uacbd\uc6b0\uc774\ub2e4\n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n\n    # (True Positive + False Positive) = \uc608\uce21 \uac12\uc774 1(Positive) \uc804\uccb4\n    count_true_positive_false_positive = K.sum(y_pred_yn)\n\n    # Precision = (True Positive) \/ (True Positive + False Positive)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    precision = count_true_positive \/ (count_true_positive_false_positive + K.epsilon())\n\n    # return a single tensor value\n    return precision\n\n\ndef f1score(y_target, y_pred):\n    _recall = recall(y_target, y_pred)\n    _precision = precision(y_target, y_pred)\n    # K.epsilon()\ub294 'divide by zero error' \uc608\ubc29\ucc28\uc6d0\uc5d0\uc11c \uc791\uc740 \uc218\ub97c \ub354\ud55c\ub2e4\n    _f1score = ( 2 * _recall * _precision) \/ (_recall + _precision+ K.epsilon())\n    \n    # return a single tensor value\n    return _f1score","1ab95bdb":"from sklearn.model_selection import StratifiedKFold, KFold\nskfold = StratifiedKFold(n_splits=K_FOLDS, random_state=1993)","ab3754da":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen_train = ImageDataGenerator(\n    rescale = 1.\/255,               \n    featurewise_center = False,              # set input mean to 0 over the dataset\n    samplewise_center = False,               # set each sample mean to 0\n    featurewise_std_normalization = False,   # divide inputs by std of the dataset\n    samplewise_std_normalization = False,    # divide each input by its std\n    zca_whitening = False,                   # apply ZCA whitening\n    rotation_range = 20,                     # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1,                        # randomly zoom range\n    width_shift_range = 0.1,                 # randomly zoom images horizontally (fraction of total width)\n    height_shift_range = 0.1,                # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,                  # randomly flip images\n    vertical_flip = False,                   # randomly flip images\n    preprocessing_function = preprocess_input\n)\n\n# validation, test\uc14b \uc774\ubbf8\uc9c0\ub294 augmentation\uc744 \uc801\uc6a9\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\ndatagen_val = ImageDataGenerator(\n    rescale = 1.\/255     \n#     featurewise_center = False,              # set input mean to 0 over the dataset\n#     samplewise_center = False,               # set each sample mean to 0\n#     featurewise_std_normalization = False,   # divide inputs by std of the dataset\n#     samplewise_std_normalization = False,    # divide each input by its std\n#     zca_whitening = False,                   # apply ZCA whitening\n#     rotation_range = 20,                     # randomly rotate images in the range (degrees, 0 to 180)\n#     zoom_range = 0.1,                        # randomly zoom range\n#     width_shift_range = 0.1,                 # randomly zoom images horizontally (fraction of total width)\n#     height_shift_range = 0.1,                # randomly shift images vertically (fraction of total height)\n#     horizontal_flip = True,                  # randomly flip images\n#     vertical_flip = False,                   # randomly flip images\n#     preprocessing_function = preprocess_input\n)\n\ndf_train['class'] = df_train['class'].astype('str')   # \uc548\ud574\uc8fc\uba74 Error \ubc1c\uc0dd.","bb9089d3":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n\nmodels = {}\n\ndef get_model(base_model):\n    base_model = base_model(weights='imagenet', include_top = False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n    \n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(196, activation='softmax', kernel_initializer='he_normal'))          # 196\uac1c\uc758 class\ub97c \ubd84\ub958\ud574\uc57c\ud558\ubbc0\ub85c \ud65c\uc131\ud654 \ud568\uc218\ub85c\ub294 softmax, \n    model.summary()\n    \n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc', f1score])\n    \n    return model\n\n__models = {\"Xception\" : Xception}","34a5e3ef":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n\ndef get_callbacks(model_save_filename, patience):\n    # \ub354 \uc774\uc0c1 \uac1c\uc120\uc758 \uc5ec\uc9c0\uac00 \uc5c6\uc744 \ub54c \ud559\uc2b5\uc744 \uc885\ub8cc\uc2dc\ud0a4\ub294 \uc5ed\ud560.\n    es = EarlyStopping(monitor = 'val_f1score', \n                       min_delta = 0,                   # \uac1c\uc120\ub418\uace0 \uc788\ub2e4\uace0 \ud310\ub2e8\ud558\uae30 \uc704\ud55c \ucd5c\uc18c \ubcc0\ud654\ub7c9.\n                       patience = patience, \n                       verbose = 1,                     # \uc9c4\ud589\uc0ac\ud56d \ucd9c\ub825\uc5ec\ubd80 \ud45c\uc2dc.\n                       mode = 'max'                     # \uad00\ucc30\ud558\uace0 \uc788\ub294 \ud56d\ubaa9\uc774 \uc99d\uac00\ub418\ub294 \uac83\uc744 \uba48\ucd9c \ub54c \uc885\ub8cc\ud569\ub2c8\ub2e4.\n                       )  \n    \n    # \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\ub294 \uacbd\uc6b0, learning rate\ub97c \uc904\uc5ec\uc8fc\ub294 \uc5ed\ud560.\n    rr = ReduceLROnPlateau(monitor = 'val_f1score', \n                           factor = 0.5,                # \ucf5c\ubc31\uc774 \ud638\ucd9c\ub418\uba74 \ud559\uc2b5\ub960\uc744 \uc904\uc774\ub294 \uc815\ub3c4.\n                           patience = patience \/ 2,\n                           min_lr = 0.000001,\n                           verbose = 1,\n                           mode = 'max'\n                           )\n    \n    # Keras\uc5d0\uc11c \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c\ub9c8\ub2e4 \uc911\uac04\uc911\uac04\uc5d0 \ucf5c\ubc31 \ud615\ud0dc\ub85c \uc54c\ub824\uc8fc\ub294 \uc5ed\ud560.\n    mc = ModelCheckpoint(filepath = model_save_filename, \n                         monitor = 'val_f1score', \n                         verbose = 1, \n                         save_best_only = True,         # \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uac00 \ucd5c\uace0\uac12\uc744 \uac31\uc2e0\ud588\uc744 \ub54c\ub9cc \uc800\uc7a5\ud558\ub3c4\ub85d \ud558\ub294 \uc635\uc158.\n                         mode = 'max'\n                         )\n    \n    return [es, rr, mc]","2e992110":"import ssl\nfrom keras.models import model_from_json\n\n# ssl \uc5d0\ub7ec\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud568.\nssl._create_default_https_context = ssl._create_unverified_context\nhistory_list = {}\nfor _m in __models:\n    print(\"Model : \", _m)\n    \n    # \ubbf8\ub9ac fold\ub97c \ub098\ub204\uc5b4 \uc0dd\uc131\ud574 \ub454 dataframe \ud30c\uc77c\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n    for fold_index in range(K_FOLDS):\n        os.system(\"training : model %s fold %d\" % (_m, fold_index))\n\n        # Model \uc0dd\uc131.\n        model = get_model(__models[_m])\n        \n        # \ub9c8\ucc2c\uac00\uc9c0\ub85c \ubbf8\ub9ac \uc0dd\uc131\ud574\ub454 weight \ud30c\uc77c\uc744 \ubd88\ub7ec\uc640\uc11c MODEL_PATH\uc5d0 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n        model_save_filename = (\"%s_%d.h5\" % (_m , fold_index))\n        model_save_filepath = os.path.join(MODEL_PATH, model_save_filename)\n        \n        # \ub098\ub220\uc9c4 dataframe\uc744 load.\n        df_train_filename = (\"fold_%d_train.csv\" % fold_index)\n        df_val_filename = (\"fold_%d_val.csv\" % fold_index)\n\n        dataframe_train = pd.read_csv(os.path.join(FOLD_DATA_PATH, df_train_filename))\n        dataframe_val = pd.read_csv(os.path.join(FOLD_DATA_PATH, df_val_filename))\n        \n        # \uc544\ub798 \uc548\ud574\uc8fc\uba74 \uc5d0\ub7ec\ub0a8. categorical\uc774\uc5b4\uc11c \uae30\uc900 col\uc774 \uc22b\uc790\uac12\uc774\uba74 \uc548\ub418\ub294 \uac83\uc778\ub4ef.\n        dataframe_train['class'] = dataframe_train['class'].astype('str')\n        dataframe_val['class'] = dataframe_val['class'].astype('str')\n\n        # ImageDataGenerator \uc0dd\uc131(train\/val)\n        datagen_train_flow = datagen_train.flow_from_dataframe(dataframe=dataframe_train,\n                                                   directory=os.path.join(DATA_PATH, \"train_segcrop\"),\n                                                   x_col='img_file',\n                                                   y_col=\"class\",\n                                                   classes = classes,\n                                                   target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n                                                   color_mode='rgb',\n                                                   class_mode='categorical',\n                                                   batch_size=batch_size,\n                                                   seed=1993)\n\n        datagen_val_flow = datagen_val.flow_from_dataframe(dataframe=dataframe_val,\n                                                   directory=os.path.join(DATA_PATH, \"train_segcrop\"),\n                                                   x_col='img_file',\n                                                   y_col=\"class\",\n                                                   classes = classes,\n                                                   target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n                                                   color_mode='rgb',\n                                                   class_mode='categorical',\n                                                   batch_size=batch_size,\n                                                   seed=1993)\n        \n        # \ub3d9\uc77c \uc774\ub984\uc758 weight \ud30c\uc77c\uc774 \uc788\uc73c\uba74 \ub118\uc5b4\uac04\ub2e4\ub294 \uc758\ubbf8.\n        if os.path.exists(model_save_filepath) == True:\n            print(\">>>\", model_save_filepath, \" already trained... skip!\")\n            continue\n        \n        train_steps = get_total_batch(dataframe_train.shape[0], batch_size)\n        val_steps = get_total_batch(dataframe_val.shape[0], batch_size)\n            \n        history = model.fit_generator(datagen_train_flow,\n            epochs=epochs,\n            steps_per_epoch = train_steps,\n            validation_data = datagen_val_flow,\n            validation_steps = val_steps,\n            callbacks = get_callbacks(model_save_filepath, PATIENCE),\n            verbose=1)\n        \n        history_list[model_save_filename] = history","d0cd9a09":"fig, ax = plt.subplots(1, 1, figsize=(12,8 * len(__models)))\nfrom cycler import cycler\n\n# set color cycle : \uadf8\ub798\ud504 \uc0c9\uae54\uc744 \uc54c\uc544\uc11c cycling\ud574\uc900\ub2e4.\nx = np.linspace(0, 1, 10)\nnumber = 5\ncmap = plt.get_cmap('gnuplot')\ncolors = [cmap(i) for i in np.linspace(0, 1, number)]\nax.set_prop_cycle(cycler('color', colors))\n\nfor hname in history_list:\n    history = history_list[hname]\n    plot_label = \"val_score : \" + hname\n    ax.plot(history.history['val_f1score'], label=plot_label)        \nax.legend()        \nplt.show()","97489bc9":"datagen_submit = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n# \uc55e\uc11c \uc800\uc7a5\ud55c 5\uac1c\uc758 sub-model\uc744 loading\ud558\ub294 \ud568\uc218.\ndef load_sub_models():\n    sub_models = []\n    for _m in __models:\n        print(\"Model \", _m, \" : \")\n        for _, _, filenames in os.walk(MODEL_PATH):\n            for fname in filenames:\n                if fname.find(_m) >= 0 and fname.find(\".h5\") >= 0:        \n                    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> loading \", fname)\n                    model = get_model(__models[_m])\n\n                    # model\uc5d0 \ub370\uc774\ud130\ud30c\uc77c\uc744 \uc62c\ub9b0\ub2e4.\n                    # model \uba85\uc774 \uc788\ub294 \uac83\ub4e4 \uc911\uc5d0\uc11c\ub9cc \uc62c\ub9b0\ub2e4.\n                    fpath = os.path.join(MODEL_PATH, fname)\n                    print(\"model weight fpath:\", fpath)\n                    model.load_weights(fpath)\n\n                    sub_models.append(model)\n    return sub_models\n\nsubmodels = load_sub_models()","eaddb02f":"from numpy import dstack     # \uac01 sub-model\uc758 \uc608\uce21 \uacb0\uacfc\ub97c dataset\uc73c\ub85c \uc0dd\uc131\ud558\uae30 \uc704\ud55c dstack.\n\ndef make_meta_learner_dataset(submodels, df, imgdirname):\n    datagen_submit = ImageDataGenerator(preprocessing_function=preprocess_input)\n    stackX = None\n    for model in submodels:\n\n        # make prediction\n        datagen_metalearner_flow = datagen_submit.flow_from_dataframe(\n            dataframe=df,\n            directory=os.path.join(DATA_PATH, imgdirname),\n            x_col='img_file',\n            y_col=None,\n            target_size= (IMAGE_WIDTH, IMAGE_HEIGHT),\n            color_mode='rgb',\n            class_mode=None,\n            batch_size=batch_size,\n            shuffle=False)\n\n        datagen_metalearner_flow.reset()\n        pred = model.predict_generator(generator = datagen_metalearner_flow,\n                                       steps = get_total_batch(df.shape[0], batch_size),\n                                       verbose=1)\n        \n        if stackX is None:\n            stackX = pred\n        else:\n            stackX = dstack((stackX, pred))\n   \n    print(\"stackX.shape = \", stackX.shape)\n        \n    # flatten predictions to [rows, members x probabilities]\n    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n    \n    return stackX\n    # 5\uac1c\uc758 sub-model\uc5d0 \ub300\ud574 \uac01 \uc608\uce21 \uacb0\uacfc\ub97c dstack\ud558\uba74 (9960, 196, 5)\uc758 shape\ub97c \uac00\uc9c0\uac8c \ub41c\ub2e4.\n    # \uc774\ub97c meta learner\uc758 training dataset\uc73c\ub85c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574 (9960, 196*5) \ubaa8\uc591\uc73c\ub85c reshape\ud55c\ub2e4.","ec253180":"import keras\nfrom keras import layers, models\n\ndef make_meta_learner_model(input_shape, output_class_count, dropout):\n    print(input_shape)\n    print(output_class_count)\n    print(dropout)\n    print(input_shape[1] * 2)\n    \n    model = Sequential()\n    model.add(layers.Dense(units=input_shape[1] * 2, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(dropout))\n    \n    print(\"01\")\n    \n    model.add(layers.Dense(units=int(input_shape[1] \/ 2), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(dropout))\n    \n    print(\"02\")\n    \n    model.add(layers.Dense(units=output_class_count, activation='softmax', kernel_initializer='he_normal'))\n    \n    print(\"03\")\n    \n    #print(model.summary())\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy', f1score])\n    \n    return model","6f2d4371":"from keras.utils import to_categorical\n\nprint(\"Build dataset for meta-learner...\")\nmeta_train_X = make_meta_learner_dataset(submodels, df_train, \"train_segcrop\")\nprint(\"meta_train_X.shape=\", meta_train_X.shape)","85e67080":"# \ubaa8\ub378\uc774 \ud6c8\ub828\ub41c label\uac12\uc5d0 \ub9de\uac8c Y\uac12\uc744 \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4.\n\nlabels = (datagen_train_flow.class_indices)\nmeta_train_Y = df_train['class'].values\nmeta_train_Y = [labels[x] for x in meta_train_Y]\nmeta_train_Y = to_categorical(meta_train_Y)\nprint(\"meta_train_Y.shape=\", meta_train_Y.shape)","cb1807ea":"def train_meta_learner(X, Y):\n    \n    print(\"Training meta-learner model...\")\n    meta_learner_model = make_meta_learner_model(X.shape, len(classes), dropout=0.2)\n    meta_learner_model.fit(X, Y, epochs=5, verbose=1, batch_size=128)\n\n    return meta_learner_model\n\nmeta_learner_model = train_meta_learner(meta_train_X, meta_train_Y)","1b2eea67":"meta_submit_X = make_meta_learner_dataset(submodels, df_test, \"test_segcrop\")\npred = meta_learner_model.predict(meta_submit_X, batch_size=32)\n\nsubmit_Y = np.argmax(pred, axis=1)\nlabels = (datagen_train_flow.class_indices)\nlabels = dict((v,k) for k, v in labels.items())\n\npredictions = [labels[k] for k in submit_Y]\n\nsubmission = pd.DataFrame()\nsubmission['img_file'] = df_test['img_file']\nsubmission[\"class\"] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)","35aafbf5":"from IPython.display import FileLinks\nFileLinks('.') # input argument is specified folder","8becb5e4":"## Model Stacking\uc744 \ud1b5\ud55c ensemble & submission - weight averaged model\n\nvh1951\ub2d8\uaed8\uc11c \uc124\uba85\ud574\uc8fc\uc2e0 \ub0b4\uc6a9\uc785\ub2c8\ub2e4.\n\nhttps:\/\/inspiringpeople.github.io\/data%20analysis\/Ensemble_Stacking\/ \ub97c \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.\n\n<br>\n\nk-fold\ub85c \uc5ec\ub7ec \ub2e4\ub978 \ub370\uc774\ud130\ub85c train\ud55c K\uac1c \ub9cc\ud07c\uc758 \ubaa8\ub378\uc744 \uc5bb\uc740 \ud6c4, test \ub370\uc774\ud130\ub97c \uac01\uac01 \ubaa8\ub378\ub85c \ub3cc\ub9b0 \uacb0\uacfc\uac12\uc744 \ud3c9\uade0\ud574\uc11c \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc9c0\ub9cc, \uac01\uac01\uc758 \ubaa8\ub378\uc758 \ucd9c\ub825\uc744 \uc785\ub825\uc73c\ub85c \ud558\ub294 \ubcc4\ub3c4\uc758 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4\uc11c predict\ud55c \uacb0\uacfc\ub97c \ub9cc\ub4dc\ub294 \ubc29\ubc95\uc744 weight averaged model\uc774\ub77c\uace0 \ud569\ub2c8\ub2e4.\n(\uac01\uac01\uc758 \ubaa8\ub378\uc758 predict \uacb0\uacfc\ubb3c\uc744 \ub3d9\ub4f1\ud558\uc9c0 \uc54a\uac8c weight\ub97c \ubd80\uc5ec\ud558\uc5ec \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95).\n\n- meta-learner \ubaa8\ub378\uc744 \uc0dd\uc131.\n- \uac01\uac01\uc758 fold \ubaa8\ub378\ub85c train \ub370\uc774\ud130\ub97c predict\ud55c \uac83\uc744 \ud569\uccd0\uc11c dataset1\uc744 \ub9cc\ub4e0\ub2e4.\n- dataset1\uc73c\ub85c meta-learner \ubaa8\ub378\uc744 train\ud55c\ub2e4. (train \ub370\uc774\ud130\uc774\ubbc0\ub85c label\uc774 \uc788\uc5b4\uc11c \ud6c8\ub828 \uac00\ub2a5.)\n- \uac01\uac01\uc758 fold \ubaa8\ub378\ub85c test \ub370\uc774\ud130\ub97c predict\ud574\uc11c dataset2\uc744 \ub9cc\ub4e0\ub2e4.\n- meta-learner\uc5d0 dataset2\ub97c \uc785\ub825\uc73c\ub85c \ud574\uc11c \ub098\uc628 \uacb0\uacfc\ub97c \uc81c\ucd9c\ud55c\ub2e4.","73cda0cb":"## Model \uc815\uc758","b6a2cdc9":"---","d38739ce":"# 2019 3rd ML month with KaKR\n### \uc790\ub3d9\ucc28 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc744 \uc774\uc6a9\ud55c \uc790\ub3d9\ucc28 \ucc28\uc885 \ubd84\ub958\n\n## Introduction\n\n\uc548\ub155\ud558\uc138\uc694. Titanic\uc73c\ub85c kaggle\uc5d0 \uc785\ubb38\ud558\uc790\ub9c8\uc790 \ubb34\uc791\uc815 3\ucc28 \ub300\ud68c\uc5d0 \ub6f0\uc5b4\ub4e0 \uce90\uae00 \ucd08\ubcf4\uc790\uc785\ub2c8\ub2e4. <br>\n\uc81c\uac00 \uc774\ub807\uac8c Notebook\uc744 \uc62c\ub9ac\ub294 \uc774\uc720\ub294 \ub2e4\ub978 \uace0\uc218\ubd84\ub4e4\uc758 Notebook\uacfc \ube44\uad50\ud558\uba74 \ubd80\ub044\ub7ec\uc6b4 \uc218\uc900\uc774\uc9c0\ub9cc \uc81c \uc2a4\uc2a4\ub85c \ub300\ud68c \uae30\uac04\ub3d9\uc548 \uace0\ubbfc\ud558\uba74\uc11c \uacf5\ubd80\ud55c \uacfc\uc815\ub4e4\uc744 \n\ubcf5\uae30\ud558\uae30 \uc704\ud568\uc785\ub2c8\ub2e4. <br>\n\ub610\ud55c \ub525\ub7ec\ub2dd \uc9c0\uc2dd\uc774 \uc804\ubb34\ud558\ub2e4\uc2dc\ud53c \ud588\ub358 \uc800\uc758 \uacbd\ud5d8\uc744 \uacf5\uc720\ud558\uba74\uc11c \ucd94\ud6c4\uc5d0 \ub300\ud68c\ub97c \uc2dc\uc791\ud558\ub294 \ucd08\ubcf4\uc790\ubd84\ub4e4\uaed8 \uc870\uae08\uc774\ub098\ub9c8 \ub3c4\uc6c0\uc774 \ub410\uc73c\uba74 \ud558\ub294 \ubc14\ub78c\uc785\ub2c8\ub2e4.\n\n\n<br>\n\n\n## Reference\n- Image Segmentation Crop (Steve Jang\ub2d8 notebook) <br>\n  https:\/\/www.kaggle.com\/cruiserx\/3rd-ml-month-car-image-segmentation-crop\n  \n- Keras \/ Xception (vh1981\ub2d8 notebook) <br>\n  https:\/\/www.kaggle.com\/vh1981\/kakr-3rd-keras-xception \n  \n- Pretrained Model (Daehun Gwak\ub2d8 notebook) <br>\n  https:\/\/www.kaggle.com\/daehungwak\/keras-how-to-use-pretrained-model\n  \n- Xception (Jang\ub2d8 notebook) <br>\n  https:\/\/www.kaggle.com\/janged\/3rd-ml-month-car-model-classification-xception\n\n\nReference Notebook\uc744 \uac04\ub2e8\ud558\uac8c 4\uac1c\ub85c \ucd94\ub824\uc11c \uc62c\ub838\uc9c0\ub9cc \ub2e4\ub978 \ubd84\ub4e4\uaed8\uc11c \uc62c\ub824\uc8fc\uc2e0 Notebook, Discussion\ub4e4\uc744 \uc804\ubd80 \ubd24\ub2e4\uace0\ud574\ub3c4 \uacfc\uc5b8\uc774 \uc544\ub2d0 \uc815\ub3c4\ub85c\n\uafb8\uc900\ud788 \ucc38\uace0\ud558\uba74\uc11c \ub9ce\uc740 \ub3c4\uc6c0\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4. \uacf5\uc720\ud574\uc8fc\uc2e0 \ubaa8\ub4e0 \ubd84\ub4e4\uaed8 \uac10\uc0ac\ub4dc\ub9bd\ub2c8\ub2e4!\n\n\n<br>\n\n\n## Process\n\n\uc81c\uac00 \ub300\ud68c\ub97c \uc900\ube44\ud558\uba74\uc11c \uacaa\uc740 \uacfc\uc815\ub4e4\uc785\ub2c8\ub2e4.\n\n### 1. \ud544\uc0ac\ud558\uae30.\n - \ud0dc\uc9c4\ub2d8\uaed8\uc11c \uc62c\ub824\uc8fc\uc2e0 Baseline\uc744 \uae30\ubc18\uc73c\ub85c \ud544\uc0ac\ud558\uba74\uc11c \uc548\uc5d0 \ub2f4\uae34 \uc774\ub860\ub4e4\uacfc Keras\ub97c \uacf5\ubd80\ud588\uc2b5\ub2c8\ub2e4.\n - Jang\ub2d8\uaed8\uc11c \uc62c\ub824\uc8fc\uc2e0 Xception \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c Notebook\uc744 \ud544\uc0ac\ud558\uba74\uc11c Pre-Trained Model, Transfer Learning\uc744 \uacf5\ubd80\ud588\uc2b5\ub2c8\ub2e4.\n - \ub3d9\uc2dc\uc5d0 Daehun Gwak\ub2d8\uaed8\uc11c \uc62c\ub824\uc8fc\uc2e0 How to use pretrained model Notebook\ub3c4 \ub9ce\uc774 \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.\n\n### 2. \ub098\ub9cc\uc758 Baseline\uc744 \ub9cc\ub4e4\uae30.\n - \uc5ec\ud0dc\uae4c\uc9c0 \ud544\uc0ac\ud558\uba74\uc11c \uacf5\ubd80\ud55c \uc790\ub8cc\ub85c Xception \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c Baseline\uc744 \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.\n - \uadf8 \ub54c\uc758 Public Score\ub294 0.90003\uc774\uc5c8\uace0 \uc810\uc218\ub97c \uc62c\ub9ac\uae30 \uc704\ud574 Stratified KFold, \uc559\uc0c1\ube14 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud574\uc57c\uaca0\ub2e4\uace0 \uc0dd\uac01\ud588\uc2b5\ub2c8\ub2e4.\n - \ub610\ud55c Private Score\ub97c \uc798 \ubc1b\uae30 \uc704\ud574\uc11c\ub294 Overfitting\uc744 \ub9c9\uae30 \uc704\ud55c \uc77c\ubc18\ud654\uac00 \ud544\uc218\ub77c\ub294 \uac83\uc744 \ubc30\uc6e0\uc2b5\ub2c8\ub2e4.\n \n### 3. \ucd5c\uc885 Modeling\n - Stratified KFold\ub97c \uc0ac\uc6a9\ud574\uc11c 5\uac1c\uc758 fold\ub97c \ub9cc\ub4e4\uc5c8\uace0 \uc774\ub97c \uac01\uac01\uc758 Notebook\uc73c\ub85c \ubd88\ub7ec\uc640\uc11c model\uc744 \ub9cc\ub4dc\ub294 \ubc95\uc744 \ubc30\uc6e0\uc2b5\ub2c8\ub2e4.\n - \ub610\ud55c Steve Jang\ub2d8\uc758 Segmentation crop\ubc29\ubc95\uc744 \uc774\uc6a9\ud55c dataset\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. (bounding box\ub85c crop\ud55c dataset\ubcf4\ub2e4 \ub354 \uc88b\uc740 \uc131\ub2a5\uc774 \ub098\uc62c \uac83\uc774\ub77c\uace0 \uc608\uc0c1\ud588\uc2b5\ub2c8\ub2e4.)\n - vh1981\ub2d8\uc758 https:\/\/www.kaggle.com\/vh1981\/kakr-3rd-keras-xception \uc744 \uae30\ubc18\uc73c\ub85c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.\n - \uc704\uc5d0\uc11c \ub9cc\ub4e0 Segmentation dataset\uacfc 5\uac1c\uc758 fold file, model\ub4e4\uc744 \ud558\ub098\uc758 \ucee4\ub110\ub85c \ubd88\ub7ec\uc654\uace0 Stacking\uc744 \ud1b5\ud55c \uc559\uc0c1\ube14 \uae30\ubc95 \uc911 \ud558\ub098\ub85c weight average model\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n\n\n<br>\n\n\n## Result\n\n\uc800\ub294 Private LB \uae30\uc900\uc73c\ub85c 0.93668\uc758 Score\ub97c \ubc1b\uc544 61\ub4f1\uc73c\ub85c \ub300\ud68c\ub97c \ub9c8\ucce4\ub294\ub370\uc694, \uac1c\uc778\uc801\uc73c\ub85c\ub294 \uacf5\ubd80\ub9cc \ud558\ub2e4\ubcf4\ub2c8 \uc81c\ucd9c\uc744 \ub9ce\uc774 \ubabb\ud588\ub358 \uc810\uc774 \uc544\uc26c\uc6e0\uc2b5\ub2c8\ub2e4. <br>\nSteve Jang\ub2d8\uc758 Solution Notebook\uc744 \ubcf4\uc2dc\uba74 Segmentation crop Dataset\uc744 \uc0ac\uc6a9\ud588\uc744\ub54c \uc810\uc218\uac00 \uc624\ud788\ub824 \uc548\ub098\uc654\ub2e4\uace0 \ub9d0\uc500\ud574\uc8fc\uc168\ub294\ub370\uc694. <br>\n\uc774\ub97c \ubcf4\uace0 \uc800\ub3c4 Dataset\uc744 \ud5c8\ud0dc\uba85\ub2d8\uaed8\uc11c \uc62c\ub824\uc8fc\uc2e0 Bounding box\ub85c crop\ud55c dataset\uc744 \uc0ac\uc6a9\ud574\uc11c \ub2e4\uc2dc \uc2dc\ub3c4\ud574\ubd24\ub354\ub2c8 0.93668\uc5d0\uc11c 0.94930\ub85c \uc624\ub978 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \uc810\ub3c4 \uc544\uc27d\uae34 \ud558\uc9c0\ub9cc \uc88b\uc740 \uc811\uadfc\uc774\uc5c8\ub2e4\uace0 \uc0dd\uac01\ud569\ub2c8\ub2e4.","7a530699":"#### Model \ud6c8\ub828\uc2dc \uc0ac\uc6a9\ud560 callback \ubaa9\ub85d\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.","277f0399":"## File load","98ac4be9":"#### training history \uacfc\uc815\uc5d0 \ub300\ud574 \uadf8\ub798\ud504\ub97c \uadf8\ub824\ubcf4\ub294 \uacfc\uc815\uc785\ub2c8\ub2e4. (\uc774 \ucee4\ub110\uc5d0\uc11c\ub294 weight \ud30c\uc77c\uc744 \ubd88\ub7ec\uc654\uc73c\ubbc0\ub85c \ube48 \uadf8\ub9bc\uc774 \ub098\uc634)","71abee34":"## Load library","28a0226e":"#### \uc774\ubc88 competition\uc758 \ud3c9\uac00 \uc9c0\ud45c\uac00 F1 Score\uc774\ubbc0\ub85c \uc774\ub97c \uc815\uc758\ud574\uc90d\ub2c8\ub2e4.\n#### http:\/\/blog.naver.com\/PostView.nhn?blogId=wideeyed&logNo=221226716255 \uc758 \uae00\uc744 \ucc38\uace0\ud558\uc2dc\uba74 \uc88b\uc744\uac83 \uac19\uc2b5\ub2c8\ub2e4.","f535e7e3":"#### train \/ validation\uc5d0 \uc0ac\uc6a9\ud560 ImageDataGenerator\ub97c \uc0dd\uc131\ud574\uc90d\ub2c8\ub2e4.","a4371bf7":"#### \uc0ac\uc6a9\ud560 constant \ubcc0\uc218\ub4e4\uc744 \uc815\uc758\ud574\uc90d\ub2c8\ub2e4.","b3ea821b":"#### Model\uc744 train \ud574\uc90d\ub2c8\ub2e4. (\uc544\ub798\uc640 \uac19\uc740 \uacfc\uc815\uc73c\ub85c Model\uc744 train\ud588\uace0 \uc774\ub97c \ubd88\ub7ec\uc634)","40334614":"#### \uc804\uccb4 \ub370\uc774\ud130\uc5d0\uc11c\uc758 class \uac04 \ube44\uc728\uc744 fold\uc5d0\uc11c\ub3c4 \ub3d9\uc77c\ud558\uac8c \uc720\uc9c0\ud558\uae30 \uc704\ud574 StratifiedKFold\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.","2eb7c5b6":"#### train\uc774 \uc644\ub8cc\ub41c \ubaa8\ub378\ub85c test dataset\uc744 predict\ud574\uc11c submission\uc744 \ub9cc\ub4e0\ub2e4."}}