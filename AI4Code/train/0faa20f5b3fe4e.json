{"cell_type":{"ed1fe649":"code","4905777e":"code","a1b5ba24":"code","782d1b6b":"code","f4d55dde":"code","b92ad9b3":"code","7a34d94d":"code","c0fd1fe5":"code","24a12430":"code","4066b5e7":"code","d830f5b4":"code","e10d94be":"code","ead57fe1":"code","e81e29c7":"code","493299fd":"code","169d9db6":"code","4b571fdb":"code","9235c435":"code","4930d5e5":"code","a2671100":"code","98853e8e":"code","1a12e7e0":"code","650da2ed":"code","3f0d50e1":"code","9f2fbc89":"code","35c3e5d2":"code","fde4b447":"code","c9ab6fa0":"code","2d465099":"code","4496450d":"code","8d0fee9c":"code","ffce8997":"code","269c16b6":"code","a7c77448":"code","b5b281e8":"code","c93bea1c":"code","ff22ca0b":"code","80259870":"code","a3163d3a":"code","bd9fc383":"code","4614f446":"code","0be81bac":"code","8521f904":"markdown","c5304aab":"markdown","9f2df48e":"markdown","efcfd037":"markdown","e9919d32":"markdown","410ea43f":"markdown","e5798c14":"markdown","0d3f45e2":"markdown","3f03566f":"markdown","675beca5":"markdown","a8c78b6a":"markdown","7119150a":"markdown","02bb9d70":"markdown","be38b909":"markdown","d192240b":"markdown","3fc9ae59":"markdown","d4ea373a":"markdown","1794a45f":"markdown","c2d3b3fc":"markdown","1d9028d5":"markdown","a26dc40e":"markdown","39215329":"markdown","44ff0eb6":"markdown","359d9031":"markdown","dc357147":"markdown","e391440d":"markdown","686c8553":"markdown","e4941468":"markdown","a5d5f1a9":"markdown","a1f2776b":"markdown","4b699e89":"markdown","e4e37ce0":"markdown","71be0027":"markdown","6bf28bc4":"markdown"},"source":{"ed1fe649":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4905777e":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample_submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\npseudo = pd.read_csv('..\/input\/house-price-prediction\/result-with-best.csv')","a1b5ba24":"train.head()","782d1b6b":"test.head()","f4d55dde":"train.shape, test.shape","b92ad9b3":"test['SalePrice'] = pseudo['SalePrice']","7a34d94d":"train.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","c0fd1fe5":"sns.pairplot(train[[\"SalePrice\", 'GrLivArea']])","24a12430":"train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)","4066b5e7":"train_number = train.shape[0]\ntest_number = test.shape[0]\nfull_data = pd.concat((train, test)).reset_index(drop=True)\ny = full_data.SalePrice.values\nfull_data.drop(['SalePrice'], axis=1, inplace=True)\nfull_data.shape","d830f5b4":"full_data_na = (full_data.isnull().sum() \/ len(full_data)) * 100\nfull_data_na = full_data_na.drop(full_data_na[full_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :full_data_na})\nmissing_data.head(20)","e10d94be":"full_data[\"PoolQC\"] = full_data[\"PoolQC\"].fillna(\"None\")\nfull_data[\"MiscFeature\"] = full_data[\"MiscFeature\"].fillna(\"None\")\nfull_data[\"Alley\"] = full_data[\"Alley\"].fillna(\"None\")\nfull_data[\"Fence\"] = full_data[\"Fence\"].fillna(\"None\")\nfull_data[\"FireplaceQu\"] = full_data[\"FireplaceQu\"].fillna(\"None\")\nfull_data['MSSubClass'] = full_data['MSSubClass'].fillna(\"None\")\nfull_data[\"Functional\"] = full_data[\"Functional\"].fillna(\"Typ\")\nfull_data[\"MasVnrType\"] = full_data[\"MasVnrType\"].fillna(\"None\")\nfull_data[\"MasVnrArea\"] = full_data[\"MasVnrArea\"].fillna(0)\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    full_data[col] = full_data[col].fillna('None')\n    \nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    full_data[col] = full_data[col].fillna(0)\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    full_data[col] = full_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    full_data[col] = full_data[col].fillna('None')","ead57fe1":"full_data[\"LotFrontage\"] = full_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","e81e29c7":"full_data['MSZoning'] = full_data['MSZoning'].fillna(full_data['MSZoning'].mode()[0])\nfull_data['Electrical'] = full_data['Electrical'].fillna(full_data['Electrical'].mode()[0])\nfull_data['KitchenQual'] = full_data['KitchenQual'].fillna(full_data['KitchenQual'].mode()[0])\nfull_data['Exterior1st'] = full_data['Exterior1st'].fillna(full_data['Exterior1st'].mode()[0])\nfull_data['Exterior2nd'] = full_data['Exterior2nd'].fillna(full_data['Exterior2nd'].mode()[0])\nfull_data['SaleType'] = full_data['SaleType'].fillna(full_data['SaleType'].mode()[0])","493299fd":"full_data = full_data.drop(['Utilities'], axis=1)","169d9db6":"full_data['MSSubClass'] = full_data['MSSubClass'].apply(str)\n\nfull_data['OverallCond'] = full_data['OverallCond'].astype(str)\n\nfull_data['YrSold'] = full_data['YrSold'].astype(str)\nfull_data['MoSold'] = full_data['MoSold'].astype(str)","4b571fdb":"from sklearn.preprocessing import LabelEncoder","9235c435":"cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in cols:\n    enc = LabelEncoder() \n    enc.fit(list(full_data[c].values)) \n    full_data[c] = enc.transform(list(full_data[c].values))","4930d5e5":"full_data['TotalSF'] = full_data['TotalBsmtSF'] + full_data['1stFlrSF'] + full_data['2ndFlrSF']","a2671100":"full_data = pd.get_dummies(full_data)","98853e8e":"full_data.shape","1a12e7e0":"test = full_data[train_number:]","650da2ed":"!pip install scikit-learn-intelex -q --progress-bar off","3f0d50e1":"from sklearnex import patch_sklearn\npatch_sklearn()","9f2fbc89":"from sklearn.model_selection import train_test_split","35c3e5d2":"x_train, x_val, y_train, y_val = train_test_split(full_data, y, test_size = 0.1, random_state=0)","fde4b447":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler_x = MinMaxScaler()\nscaler_y = StandardScaler()","c9ab6fa0":"scaler_x.fit(x_train)\nx_train = scaler_x.transform(x_train)\nx_val = scaler_x.transform(x_val)\ntest = scaler_x.transform(test)","2d465099":"scaler_y.fit(y_train.reshape(-1, 1))\ny_train = scaler_y.transform(y_train.reshape(-1, 1)).ravel()\ny_val = scaler_y.transform(y_val.reshape(-1, 1)).ravel()","4496450d":"from sklearn.svm import NuSVR\nfrom sklearn.metrics import mean_squared_error\nimport optuna","8d0fee9c":"def objective_svr(trial):\n    params ={\n        'C': trial.suggest_float('C', 0.0001, 5.0),\n        'nu':  trial.suggest_float('nu', 0.0, 1.0),\n    }\n    model = NuSVR(**params).fit(x_train, y_train)\n    y_pred = model.predict(x_val)\n    loss = np.sqrt(mean_squared_error(y_val, y_pred))\n    return loss","ffce8997":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","269c16b6":"%%time\nstudy.optimize(objective_svr, n_trials=250)","a7c77448":"full_x = np.concatenate((x_train, x_val), axis=0)\nfull_y = np.concatenate((y_train, y_val), axis=0)","b5b281e8":"%%time\nfinal_model = NuSVR(**study.best_params).fit(full_x, full_y)","c93bea1c":"y_pred = final_model.predict(test)\ny_pred = scaler_y.inverse_transform(y_pred)","ff22ca0b":"sample_submission['SalePrice'] = y_pred\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","80259870":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","a3163d3a":"from sklearn.svm import NuSVR","bd9fc383":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","4614f446":"%%time\nstudy.optimize(objective_svr, n_trials=250)","0be81bac":"%%time\nfinal_model = NuSVR(**study.best_params).fit(full_x, full_y)","8521f904":"<big><strong>Feature engineering<\/strong><\/big><br><br>\n<big>Combine train and test into one dataset.<\/big>","c5304aab":"<big>Delete Utilities feature because it's useless.<\/big>","9f2df48e":"# Installing Intel(R) Extension for Scikit-learn\n\n<big>Use Intel\u00ae Extension for Scikit-learn* for fast compute Scikit-learn estimators.<\/big>","efcfd037":"# Now we use the same algorithms with original scikit-learn\n<big>Let\u2019s run the same code with original scikit-learn and compare its execution time with the execution time of the patched by Intel(R) Extension for Scikit-learn.<\/big>","e9919d32":"<big>Let's see the execution time.<\/big>","410ea43f":"# Split data into train and test sets","e5798c14":"<big>MSZoning, KitchenQual, Exterior1st, Exterior2nd, SaleType and Electrical: Fill in missing values with most common value.<\/big>","0d3f45e2":"![out1.PNG](attachment:2076f588-5bbd-4ede-b4de-792f2fe24f48.PNG)","3f03566f":"<h2>Conclusions<\/h2>\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel\u00ae Extension for Scikit-learn. Noted that Intel\u00ae Extension for Scikit-learn gives you opportunities to:<\/big>\n\n* <big>Use your Scikit-learn code for training and inference without modification.<\/big>\n* <big>Speed up selection of parameters <strong>from 20 minutes to 5 minutes.<\/strong><\/big>\n* <big>Get predictions of the similar quality.<\/big>\n","675beca5":"<big>Transforming some numerical variables that are really categorical<\/big>","a8c78b6a":"<big>As we can see, two examples have a very large GrLivArea and a too low price. We can delete it.<\/big>","7119150a":"# Prediction","02bb9d70":"# Preprocessing","be38b909":"<big>Patch original scikit-learn.<\/big>","d192240b":"<big><strong>Select parameters<\/strong><\/big>","3fc9ae59":"<big><strong>Outliers<\/strong><\/big><br><br>\n<big>Explore outliers.<\/big>","d4ea373a":"<big>The file says that NA means no feature.<\/big>","1794a45f":"![out2.PNG](attachment:c1f9c7b4-2e33-4e50-9040-13d9df4edaef.PNG)","c2d3b3fc":"<big>Let's look at the number of missing values.<\/big>","1d9028d5":"<big>Let's add a feature with a total area.<\/big>","a26dc40e":"<big><strong>Filling missing values.<\/strong><\/big><br><br>\n<big>In order to fill in the missing values we will use \"data_description.txt\".<\/big>","39215329":"# Importing data","44ff0eb6":"<big><strong>Pseudodating<\/strong><\/big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.<\/big>","359d9031":"<big>Let's drod \"Id\" feature.<\/big>","dc357147":"<big>Select parameters.<\/big>","e391440d":"<big>Getting dummy features.<\/big>","686c8553":"<big>Let's normalize data<\/big>","e4941468":"# Training the model with the selected parameters","a5d5f1a9":"<big>LotFrontage: Fill in missing values by the median LotFrontage of the neighborhood.<\/big>","a1f2776b":"<big>Save the results in 'submission.csv'.<\/big>","4b699e89":"<big>Let's see the execution time without patch.<\/big>","e4e37ce0":"<big><strong>Label encoding.<\/strong><\/big>","71be0027":"# Using optuna to select parameters for nuSVR\n<big>Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. The advantage of support vector machines is effective in high dimensional spaces.<\/big><br>\n\n<big>NuSVR similar to SVR, but uses a parameter nu to control the number of support vectors. Nu replaces the parameter epsilon of epsilon-SVR<\/big><br><br>\n<big>We adjust hyperparameters for the best result.<\/big><br><br>\n<big>Parameters that we select:<\/big><br>\n<big>* <code>C<\/code> -  Parameter inverse to the regularization coefficient<br><\/big>\n<big>* <code>nu<\/code> -  An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.<br><\/big><br>","6bf28bc4":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but\u202fit\u202fsometimes works for hours.<\/big><br><br>\n\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, <strong>\u202f<a href='https:\/\/github.com\/intel\/scikit-learn-intelex'>Intel\u00ae Extension for Scikit-learn*<\/a><\/strong>.<\/big><br><br>\n\n<big>I will show you how to <strong>speed up your kernel in 4 times<\/strong> without changing your code!<\/big><big>"}}