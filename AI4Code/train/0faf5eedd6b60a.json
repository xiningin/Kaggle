{"cell_type":{"df771e61":"code","c763b4af":"code","495d701f":"code","5f6a0d81":"code","5ecbad61":"code","11020e3a":"code","b908e3da":"code","a6fe1ca6":"code","81a58ce6":"code","f292b32f":"code","76550582":"code","b771c1ef":"code","8bd255e4":"code","95dcda28":"code","f9998891":"code","264f7b4a":"code","cc6b0b2a":"code","3b45a33b":"code","89745387":"code","1ecbd7ec":"code","c7ad2663":"code","63dff880":"code","9001d345":"code","6aa069f9":"markdown","c1f7c641":"markdown","478246b4":"markdown","0a799ca7":"markdown","0776b7ce":"markdown","42c90230":"markdown","793a3572":"markdown","58e0bda2":"markdown","365d64a7":"markdown","1e2cbe6f":"markdown","02ea9ff4":"markdown","419d217e":"markdown","039e1da6":"markdown","3f4a280d":"markdown","d7962a54":"markdown","66189ed4":"markdown","dce10147":"markdown","255964af":"markdown","0a71a4e9":"markdown","d745ede0":"markdown","3eff60e5":"markdown","321deacc":"markdown","c13c9849":"markdown","99b5c652":"markdown"},"source":{"df771e61":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\n%matplotlib inline","c763b4af":"# load music dataset\nsongs = pd.read_csv('..\/input\/spotify-songs-data\/Song.csv', encoding=\"latin\")\nsongs.info()\nsongs.head()","495d701f":"songs.describe()","5f6a0d81":"# eda with numeric variables\nX_con = songs.iloc[:,2:]\ncmap = cm.get_cmap('gnuplot')\nscatter = pd.plotting.scatter_matrix(X_con, marker = 'o', s=40, hist_kwds={'bins':15}, figsize=(15,15), cmap=cmap)","5ecbad61":"# audio features\naud = ['Beats.Per.Minute', 'Valence.', 'Energy', 'Speechiness.']\nX_aud = songs[aud]\ncmap = cm.get_cmap('gnuplot')\nscatter = pd.plotting.scatter_matrix(X_aud, marker = 'o', s=40, hist_kwds={'bins':15}, figsize=(15,15), cmap=cmap)","11020e3a":"# idea: cluster songs by genre and compare w\/ actual genres","b908e3da":"# data cleaning - remove outliers","a6fe1ca6":"# data cleaning - remove duplicates","81a58ce6":"# data cleaning - impute null values","f292b32f":"# feature extraction","76550582":"# combine into topics by LDA","b771c1ef":"# dimensionality reduction by PCA\nX = np.array(songs.iloc[:,2:])\npca = PCA(n_components=5)\npca.fit(X)\nX = pca.transform(X)\n#pca.fit_transform(X)\nX.shape","8bd255e4":"# training set\nfeatures = ['Beats.Per.Minute', 'Valence.', 'Energy', 'Speechiness.']\nX = np.array(songs[features])\nX[:5]","95dcda28":"# feature scaling and normalization\nX_norm = StandardScaler().fit_transform(X)\nX_norm[:5]","f9998891":"# dimensionality reduction by PCA\npca = PCA(n_components=2).fit(X_norm)\nX_pca = pca.transform(X_norm)\nX.shape, X_pca.shape","264f7b4a":"# cross-validation: find optimal number of clusters k by mean silouette score\nscores = []\nfor k in range(2,15):\n    kmeans = KMeans(n_clusters=k, random_state=7)\n    kmeans.fit(X_pca)\n    score = silhouette_score(X_pca, kmeans.labels_, metric='euclidean')\n    print(k, score)","cc6b0b2a":"# determine best clustering solution by mean silhouette score\nsilhouette_score(X_pca, kmeans.labels_, metric='euclidean')","3b45a33b":"# model training by k-means clustering\nkmeans = KMeans(n_clusters=2, random_state=7)\nkmeans.fit(X_pca)","89745387":"# visualize clusters on principle components\nplt.title('K-Means Clustering Results w\/ K=2')\nplt.scatter(X_pca[:,0], X_pca[:,1], s=40, c=kmeans.labels_, cmap=plt.cm.prism)\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker='+', s=100, c='k', linewidth=2)\n\n#use for loop to add annotations to each point in plot \nfor i, txt in enumerate(songs['Artist.Name'].values):\n    plt.annotate(txt, (X_pca[i,0], X_pca[i,1]))\n    \nplt.gcf().set_size_inches(18.5, 10.5)","1ecbd7ec":"# Plotting the magnitude of each feature value for the first two principal components\nfig = plt.figure(figsize=(8, 4))\nplt.imshow(pca.components_, interpolation = 'none', cmap = 'plasma')\nfeature_names = list(features)\n\nplt.gca().set_xticks(np.arange(-.5, len(feature_names)));\nplt.gca().set_yticks(np.arange(0.5, 2));\nplt.gca().set_xticklabels(feature_names, rotation=90, ha='left', fontsize=12);\nplt.gca().set_yticklabels(['First PC', 'Second PC'], va='bottom', fontsize=12);\n\nplt.colorbar(orientation='horizontal', ticks=[pca.components_.min(), 0, \n                                              pca.components_.max()], pad=0.65);","c7ad2663":"songs['Labels'] = kmeans.labels_\nsongs.head()","63dff880":"sns.pairplot(songs[features + ['Labels']], hue='Labels')","9001d345":"sns.pairplot(songs[['Labels', 'Popularity', 'Speechiness.', 'Beats.Per.Minute']], hue='Labels')","6aa069f9":"It looks clear that PC1 reflects very high tempo and high amounts of Speechiness (rap \/ hip-hop) with low Valence (melancholy) while PC2 is a mix between strong Valence (positivity \/ major chords) and high Energy (high intensity rock) with Moderate tempo (slow songs) and Speechiness. My guess is that cluster 1 (green) which has mainly high PC1 are mostly hip-hop songs, while cluster 2 (red) with low PC1 are mostly mainstream pop tunes, or in Chinese this would be a case of \u5feb\u6b4c vs \u6162\u6b4c","c1f7c641":"Let's visualize the clusters seperately and their correlation to our selected audio features (blue=0, orange=1). We would expect to see strong clustering of cluster 1 songs at high Tempo and high Speechiness, and the opposite for cluster 0 songs, while there wouldn't be much variation for Valence and Energy.","478246b4":"The data set is clean and does not require significant pre-processing.","0a799ca7":"Googling \"artist name + genre\" resulted in the following wikipedia descriptions for cluster 1:\n\n- Grande's music is generally described as pop and R&B with elements of EDM, hip hop, and trap, the latter first appearing prominently on her Christmas & Chill extended play.\n\n- The Baffler described Eilish's sound as fitting into the \"streambait\" genre\n\n- Lizzo's music primarily incorporates hip hop. Her music also incorporates genres such as soul, R&B and funk-pop.\n\n- Tyler-Justin Anthony Sharpe (born August 26, 2002), known professionally as Lil Tecca, is an American rapper, singer and songwriter. \n\n- Benito Antonio Mart\u00ednez Ocasio (born March 10, 1994), known by his stage name Bad Bunny, is a Puerto Rican singer, rapper, and songwriter.\n\n- Though his music is primarily reggaeton, J Balvin has experimented with a variety of musical genres in his work, including electronica, house music, trap, and R&B.\n\n- Carlos Isa\u00edas Morales Williams (born December 3, 1993), better known as Sech, is a Panamanian singer. Genre \u00b7 Reggaeton ... \n\n\nWith the exception of the eccentric Billie Eilish, who doesn't conform to a particular sound, it turns out that the rest of the artists here are all directly classified as hip-hop (rap) or have belong to a hip-hop subgenre e.g. Raggaeton, in other words 8\/10 songs followed the same genre as predicted above in writing. Pretty cool results considering that our kmeans algorithm only looked at a reduced set of 4 audio features, which were further reduced to 2 dimensions by PCA, and finally tuned to k=2 clusers only by sillhoutte score!","0776b7ce":"With this in mind, we shold be able to label cluster 1 songs as fast hip-hop songs that are slightly more popular than cluster 0 songs which are slow general pop songs. Both types of songs are popular with fast hip-hop having a slight edge. Note that we have also just uncovered another interesting cluster along the Speechiness-Tempo dimensions showing that hip-hop songs tend be fast and wordy to which our current unsupervised kmeans k=2 clusters agrees with.","42c90230":"It's not surprising that a systematic grid-search returned k=2 clusters as the optimal number using the silhouette score as the model performance metric.","793a3572":"To test my theory, I'd like to see what how Popularity (unused feature) varies by cluster. First we need to label the original dataset with the kmeans labels [0,1]","58e0bda2":"## Modelling","365d64a7":"## Data Exploration","1e2cbe6f":"With more time to spare I would attempt the following:\n- call the Spotify API to gather more training examples of songs I'd actually listen to \n- attempt to break songs down by musical properties a la Mauch\n- conversely approach this problem as an anomaly detection exercise and see if it correctly identifies the Lady Gaga song as the only listenable one out of the lot!","02ea9ff4":"I must admit that I have not explored any new songs in recent years (Kendrick Lamar's A.D.H.D and jazz hop was probably the last new frontier for me). While I am a die hard music lover and I appreciate the fact that the creative trend has largely switched away from rock bands to fruity loops, I tend to stay within my comfort zone of 90's alt rock classics, as evident from the last live concert I had attended was my first (and only) chance to see my childhood heroes The Red Hot Chilli Peppers perform at the Singapore F1 2019. It was thus excruciating to grind through this list of 50 songs on youtube and to realize they are some of today's most viral music videos with the majority showing above 1 billion views, and to conclude to my surprise that the Lady Gaga song was the most normal of them all while I personally wouldn't label the rest of the songs music by any stretch of the definition... Rock 'n Roll never dies!","419d217e":"The approach I will take here references a research publication I'd read back in 2016 when I first discovered machine learning and the sexiest job of the 21st century - Data Scientist. Credit to Matthias Mauch at Queen Mary University of London for the framework of clustering pop music.","039e1da6":"## Variable Analysis","3f4a280d":"Let's explore the numerical features and ignore the song names and artists so that we can come up with a model based purely on a song's audio properties.","d7962a54":"## Data pre-processing","66189ed4":"In order to search for the most optimum number of cluster k, and knowing that k-means will converge given a large enough number of random intitializations of the centroids, we proceed to perform the following pseudo grid search to tune for the hyperparemeter k=2,3,...,14","dce10147":"It looks like this dataset came from the Spotify API. We get the following feature descriptions from their official documentation and my own  interpretation below:\n\nAcousticness: acoustic vs electric  \nDanceability  \nEnergy: intensity, fast, noisy... e.g. death metal  \nInstrumentalness: vocals vs instrumental e.g. rap vs classical  \nLiveness: was it recorded live?  \nLoudness: -60 to 0 dB  \nSpeechiness: lot's of spoken word e.g. rap  \nValence: positivity e.g. worship?  \nTempo: BPM  ","255964af":"Let's break down each of the principal components by the subset of interesting audio-only features we selected earlier. The goal is to quantify the principal components in terms of these underlying features.","0a71a4e9":"## Conclusions","d745ede0":"There is some interesting variation i.e. multi-modal distributions on the audio features Tempo, Energy, Valence, Speechiness. The audio features Danceability, Liveliness, Acousticness are heavily skewed. The features Length, Popularity, Loudness appear to be uniformly distributed and will will drop these as they don't in general offer any insight into the timbre or harmonic properties of a song. ","3eff60e5":"The Silhouette score measures how close each example in the cluster is to the points in the neighboring cluster. The closer it is to +1 the better the clusters are, and so we have a pretty high score indicating our examples belong to quite distinct groups. Let's proceed to train our kmeans model with k=2","321deacc":"It is evident the smaller green cluster consists of more female artists and vice versa for the larger red cluster and they are linearly separated. The same artist's songs appear within the same cluster e.g. Ariana Granda, Billie Ellish, Sech in the green clusterm and Lil Nas, Ed Sheeran, Post Malone in the red cluster. This makes sense as all of the songs are relatively recent (2019-) and the artists' musical styles wouldn't have changed significantly in the time period.","c13c9849":"Let's use the reduced number of features based on the previous analysis of the temporal and harmonic audio featues as a starting point for model training. We will also perform feature scaling and normalization using the standard scaler.","99b5c652":"Let's visualize the clusters and label them by artist along the principal components in 2-D"}}