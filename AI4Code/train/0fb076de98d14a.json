{"cell_type":{"c03e76fa":"code","85449003":"code","c15714d3":"code","6edabff9":"code","3bb2efb2":"code","06ce214a":"code","164eb439":"code","e882f349":"code","34ed3d62":"code","8eaf21c4":"code","f9aec515":"code","419bb2cd":"code","0726b26d":"code","13840c7b":"code","652bf474":"code","9012b40f":"code","55d4dcb2":"code","892de543":"code","12adc1cf":"code","071a5c35":"code","cc20d3d3":"code","402401e2":"code","b4a98b4a":"code","7a22c51d":"code","ad0bafc5":"markdown","2d9a4476":"markdown","fda2c86b":"markdown","6435e95e":"markdown","f4a0ef2f":"markdown","6ed8aeac":"markdown","3c6e256d":"markdown","a26778c1":"markdown","059fdb5b":"markdown"},"source":{"c03e76fa":"import os\nimport numpy as np\nimport pandas as pd\nimport math\nimport shutil\nimport csv\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix, plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, MaxPooling2D, BatchNormalization, Activation\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, preprocess_input, decode_predictions\n# from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n# from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler","85449003":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nelse:\n    print('Found GPU at: {}'.format(device_name))\n    physical_devices = tf.config.list_physical_devices('GPU')\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)","c15714d3":"path = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\ndestination = '.\/'\n\nwith open('.\/train.csv', 'w+', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['image_path', 'label'])\n    for s in ['train\/','val\/']:\n        for root, dirs, files in os.walk(path + s):\n            for f in files:\n                fullpath = os.path.join(root, f)\n                \n                if fullpath.split('\/')[-2] == 'NORMAL':\n                    label = '0'\n                else:\n                    label = '1'\n                    \n                writer.writerow([fullpath, label])\n                \nwith open('.\/test.csv', 'w+', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['image_path', 'label'])\n    for s in ['test\/']:\n        for root, dirs, files in os.walk(path + s):\n            for f in files:\n                fullpath = os.path.join(root, f)\n                \n                if fullpath.split('\/')[-2] == 'NORMAL':\n                    label = '0'\n                else:\n                    label = '1'\n                    \n                writer.writerow([fullpath, label])\n\nprint(\"done\")","6edabff9":"data_dir = \".\/\"\nlabels = ['NORMAL','PNEUMONIA']\nBATCH_SIZE = 16\nIMG_SIZE = (150, 150)","3bb2efb2":"pd.set_option('max_colwidth', 800)\ndf = pd.read_csv('.\/train.csv')\ntest_df = pd.read_csv('.\/test.csv')\n\ndf.head(3)","06ce214a":"df['label'] = df['label'].astype('str')\ntest_df['label'] = test_df['label'].astype('str')","164eb439":"neg, pos = np.bincount(df['label'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","e882f349":"train_df, valid_df = train_test_split(df, test_size=0.20, random_state=13, stratify=df['label'])\nlen(train_df), len(valid_df)","34ed3d62":"neg, pos = np.bincount(train_df['label'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","8eaf21c4":"weight_for_0 = (1 \/ neg) * (total \/ 2.0)\nweight_for_1 = (1 \/ pos) * (total \/ 2.0)\n\nclass_weights = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","f9aec515":"bool_train_labels = train_df['label']!='0'\n\npos_features = train_df['image_path'][bool_train_labels]\nneg_features = train_df['image_path'][~bool_train_labels]\n\npos_labels = train_df['label'][bool_train_labels]\nneg_labels = train_df['label'][~bool_train_labels]\n\nlen(pos_features), len(neg_features)","419bb2cd":"ids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[pos_features.index[choices]]\nres_pos_labels = pos_labels[pos_labels.index[choices]]\n\nres_pos_features.head(3)","0726b26d":"resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_data = {'image_path': resampled_features,\n        'label': resampled_labels\n        }\n\nresampled_df = pd.DataFrame(resampled_data, columns = ['image_path', 'label'])\nresampled_df.head(3)","13840c7b":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n#     preprocessing_function=preprocess_input,\n    rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n    brightness_range=[0.6, 1.3],\n    shear_range=0.3,\n    zoom_range=[0.8, 1.0],\n    horizontal_flip=True,\n#     vertical_flip=True,\n    fill_mode='constant'\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n#     preprocessing_function=preprocess_input,\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                                        dataframe=train_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)\n\nvalidation_generator = test_datagen.flow_from_dataframe(\n                                        dataframe=valid_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        shuffle=False,\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)\n\ntest_generator = test_datagen.flow_from_dataframe(\n                                        dataframe=test_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        shuffle=False,\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)","652bf474":"fig, axes = plt.subplots(1, 3)\nfig.tight_layout()\n\nfor i in range(3):\n    img, label = train_generator.next()\n    axes[i].set_title(label[0])  \n    axes[i].imshow(img[0])","9012b40f":"IMG_SHAPE = IMG_SIZE + (3,)\ndr = 0.5\n\nmodel = Sequential([\n    Conv2D(16, kernel_size=(3, 3), activation=\"relu\", input_shape=IMG_SHAPE),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n#     Flatten(),\n    GlobalAveragePooling2D(),\n    \n    Dense(1, activation='sigmoid'),\n])\n\nmodel.summary()","55d4dcb2":"metrics = [\n    tf.keras.metrics.BinaryAccuracy(name=\"binary_acc\"),\n    tf.keras.metrics.AUC(name=\"AUC\"),\n    tf.keras.metrics.Precision(name=\"precision\"),\n    tf.keras.metrics.Recall(name=\"recall\"),\n]\n\nmodel.compile(optimizer=Adam(learning_rate=1e-3),\n              loss=BinaryCrossentropy(),\n              metrics=metrics)","892de543":"callbacks = [\n#              ModelCheckpoint(\"model_at_epoch_{epoch}.h5\"),\n#              ReduceLROnPlateau(monitor='val_loss',\n#                             patience=2,\n#                             verbose=1,\n#                             factor=0.07,\n#                             min_lr=1e-9),\n#              EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n]\n\nhistory = model.fit(train_generator, \n                    epochs=15,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks,\n                    validation_data=validation_generator,\n                    class_weight=class_weights\n)","12adc1cf":"def plot_metrics(history, name, bot=0.0, top=0.0):\n    plt.plot(history.history[name])\n    plt.plot(history.history['val_'+name])\n    plt.title('Model '+name)\n    plt.ylabel(name)\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    if top != 0.0:\n        plt.ylim([bot, top])\n    plt.show()\n    \nplot_metrics(history, 'loss')\nfor i in range(len(metrics)):\n    plot_metrics(history, metrics[i].name, 0.5, 1.0)","071a5c35":"model.evaluate(test_generator, batch_size=BATCH_SIZE)","cc20d3d3":"Y_pred = model.predict(test_generator, batch_size=BATCH_SIZE)\n\ny_pred = np.rint(Y_pred)","402401e2":"conf_matrix = confusion_matrix(test_generator.classes, y_pred)\n\nplt.matshow(conf_matrix, cmap=plt.cm.Blues)\nfor (i, j), z in np.ndenumerate(conf_matrix):\n    plt.text(j, i, z, ha='center', va='center')","b4a98b4a":"print('Classification Report')\ntarget_names = ['0','1']\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","7a22c51d":"def plot_top_losses(actual, pred, k=9, figsize=(10,10)):\n    loss = BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n    loss_values = loss(actual, pred).numpy()\n    top_k = loss_values.argsort()[-k:][::-1]\n    cols = math.ceil(math.sqrt(k))\n    rows = math.ceil(k\/cols)\n    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n    fig.suptitle('Prediction\/Actual\/Loss\/Prediction_Probability', weight='bold', size=14)\n    fig.tight_layout()\n    for i, index in enumerate(top_k):\n        image = validation_generator[int(index\/16)][0][index%16]\n        actual = validation_generator.classes[index]\n        loss_value = loss_values[index]\n        predicted = np.argmax(pred[index])\n        prob = pred[index][predicted]\n        title = f'{predicted}\/{actual}\/{loss_value:.2f}\/{prob:.2f}'\n        ax = axes.flat[i]\n        ax.imshow(image)\n        ax.set_title(title)\n        \nplot_top_losses(test_generator.classes, Y_pred, 9)","ad0bafc5":"## Plot Confusion Matrix","2d9a4476":"# Evaluate Model","fda2c86b":"# Data Preprocessing","6435e95e":"# Make CSV","f4a0ef2f":"# Oversampling (Optional)","6ed8aeac":"# Calculate Class Weight (Optional)","3c6e256d":"# Build and Train Model","a26778c1":"# Image Data Generator","059fdb5b":"## Plot Top Losses"}}