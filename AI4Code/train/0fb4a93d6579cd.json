{"cell_type":{"a7231c26":"code","b2ae55cb":"code","14cb5256":"code","8394eb05":"code","9361699c":"code","a04b32fa":"code","29df5266":"code","978c313f":"code","b2966944":"code","b77bce35":"code","582068b6":"code","82b92623":"code","3f86c934":"code","a4b4b6bd":"code","a379c37a":"code","ab142944":"code","49a11664":"code","c3953ef6":"code","bf175941":"code","9c7ccf21":"code","eb555fde":"code","d652ad72":"code","befc8cc6":"code","2116e4dd":"code","26b05494":"code","17cad45f":"code","4ecd147a":"code","aded5471":"code","207dde75":"code","4a3753e9":"code","22d419ed":"code","e0cd6ab2":"code","76b0f868":"code","d81ba861":"code","e2a6802f":"code","802a541f":"code","43da00be":"code","3b00bcb8":"code","6cfe3fed":"code","caa85959":"code","a63a2a1b":"code","2ae9c1cc":"code","f54b5930":"code","fb4bf6b6":"code","b61787f6":"code","5d494b3c":"code","4fdebbd9":"code","7e79c61e":"code","92598a92":"code","41f63e52":"code","c90d93de":"code","843a113c":"code","05c4ab95":"code","1764bb94":"code","75788403":"code","073831fc":"code","0361bf65":"code","9f1a1fb7":"code","c0b95332":"code","d6a081a5":"code","923800cd":"code","bf13fc7b":"code","da059bc9":"code","a07dcb7f":"code","32461ae1":"code","dbf5d5d5":"code","a806adfb":"code","435b7479":"code","853614ca":"code","0545d5bf":"code","1163aaa0":"code","5aa8073e":"code","4cefe6ca":"code","e1fb62e0":"code","8e3b67bd":"code","695deea2":"code","016d82cc":"code","9ff6de8b":"code","d166cbcb":"code","c8ac6955":"code","e68c4943":"code","cf3d2847":"code","7a84e512":"code","86ae9701":"code","a9ee9db2":"code","7b9f4b34":"code","29e7cc8a":"code","8f9d05c8":"code","ccbebac8":"code","693e7593":"code","dd9b932c":"code","5d08aa01":"code","b9ed37cf":"code","b7203acc":"code","ca047202":"code","931e8fca":"code","e54475d2":"code","6ce3cc23":"code","d6771d43":"code","f7437a09":"code","d6b1fc94":"code","f34679d9":"code","a2c40b83":"code","f3a389a2":"code","2b9d8b3f":"code","96897f85":"code","9c98cce8":"code","58354bf1":"code","874309dc":"code","5f8ce838":"code","8fffa486":"code","503851d9":"markdown","15d43e0e":"markdown","1116dd09":"markdown","0622e0ef":"markdown","7ad8dc27":"markdown","f1f8769f":"markdown","9834c378":"markdown","88efa110":"markdown"},"source":{"a7231c26":"!gdown --id 1e7ZEW0oQql4e4x_yVgNGyhJnCiA7V-qj\n!unzip \/content\/wazzadu.zip","b2ae55cb":"import pandas as pd\nimport numpy as np\nimport requests\nimport os\nfrom tqdm.notebook import tqdm","14cb5256":"train_df = pd.read_csv('\/content\/train.csv')\ntrain_df","8394eb05":"train_df","9361699c":"cat_df = pd.read_csv('\/content\/dim_cat_subcat_tag_key.csv')\ncat_df = pd.DataFrame(cat_df.to_records())\ncat_df.iloc[0,:]\ncat_df.columns = cat_df.iloc[0,:]\ncat_df = cat_df.iloc[1:,:]\ncat_df = cat_df.reset_index(drop = True)\ncat_df","a04b32fa":"tag_to_key_df = cat_df[['subcate_name','tag','key']][cat_df[['subcate_name','tag','key']]['tag'] != 'nan']\ntag_to_key_dict = tag_to_key_df.set_index('tag')['key'].to_dict()\ntag_to_key_dict\n\nsubcate_id_to_key_df = cat_df[['subcate_id','key']]\nsubcate_id_to_key_dict = subcate_id_to_key_df.set_index('subcate_id')['key'].to_dict()\nsubcate_id_to_key_dict\n\nkey_to_subcate_name_df = cat_df[['subcate_name','key']]\nkey_to_subcate_name_dict = key_to_subcate_name_df.set_index('key')['subcate_name'].to_dict()\nkey_to_subcate_name_dict\n\ndef create_label(subcategory_id,tag_id,tag_name):\n    if tag_name in tag_to_key_dict:\n        return tag_to_key_dict[tag_name]\n    elif str(subcategory_id) in subcate_id_to_key_dict:\n        return subcate_id_to_key_dict[str(subcategory_id)]\n\ndef label_to_subcate_name(label):\n    return key_to_subcate_name_dict[label]\n    ","29df5266":"train_df['label'] = train_df.apply(lambda x:create_label(x['subcategory_id'],x['tag_id'],x['tag_name']),axis = 1)\ntrain_df['subcate_name'] = train_df['label'].apply(label_to_subcate_name)","978c313f":"train_df","b2966944":"train_df[['label','subcate_name']].value_counts()","b77bce35":"train_df.to_csv('\/content\/train_label.csv')","582068b6":"def download_img(img_link):\n    r = requests.get(img_link)\n    file_name = img_link.split('\/')[-1]\n    file_path = os.path.join(img_dest_path,file_name) \n    with open(file_path, 'wb') as f:\n        # for chunk in r.iter_content(chunk_size = 128):\n        #     f.write(chunk)\n        f.write(r.content)\n","82b92623":"import concurrent.futures\n\nimg_dest_path = 'img'\nos.makedirs(img_dest_path, exist_ok = True)\n\ndef run(f, my_iter):\n    l = len(my_iter)\n    with tqdm(total=l) as pbar:\n        # let's give it some more threads:\n        with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n            futures = {executor.submit(f, arg): arg for arg in my_iter}\n            results = {}\n            for future in concurrent.futures.as_completed(futures):\n                arg = futures[future]\n                results[arg] = future.result()\n                pbar.update(1)\nrun(download_img,train_df['image_path'])","3f86c934":"# !zip -r \/content\/img.zip \/content\/img","a4b4b6bd":"train_df = pd.read_csv('\/content\/train_label.csv')\ntrain_df","a379c37a":"train_df['image_path'].str.split('\/').str[-1]","ab142944":"file_path_to_label_df = pd.DataFrame(train_df[['image_path', 'label']])\nfile_path_to_label_df['image_path'] = file_path_to_label_df['image_path'].str.split('\/').str[-1]","49a11664":"file_path_to_label_dict = file_path_to_label_df.set_index('image_path')['label'].to_dict()","c3953ef6":"import shutil\nsrc_folder = '\/content\/img'\ndest_folder = '\/content\/training_folder'\ntraining_folder = 'training_folder'\nos.makedirs(training_folder, exist_ok = True)\nfor folder_name in list(set(file_path_to_label_dict.values())):\n    os.makedirs(os.path.join(training_folder, folder_name), exist_ok = True)\n\nfor file_name in tqdm(file_path_to_label_dict):\n    if file_path_to_label_dict[file_name] in os.listdir('\/content\/training_folder'):\n        shutil.copyfile(os.path.join(src_folder, file_name), os.path.join(dest_folder, file_path_to_label_dict[file_name], file_name))\n","bf175941":"os.makedirs('\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu')","9c7ccf21":"!cp -r \/content\/training_folder \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder","eb555fde":"!zip -r \/content\/training_folder.zip \/content\/training_folder","d652ad72":"!cp -r \/content\/training_folder.zip \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder.zip","befc8cc6":"!gdown --id 1SJFXVnwARiyHOksae1CBDhtsBGD9fqYD","2116e4dd":"# !rm -r \/content\/training_folder\n!unzip training_folder.zip -d \/","26b05494":"# duplicate remover\nimport hashlib\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nimport time\nimport numpy as np\nimport hashlib, os\nfrom PIL import Image\n\ndef delete_duplicate_imgs(folder_path):\n    def file_hash(filepath):\n        with open(filepath, 'rb') as f:\n            return md5(f.read()).hexdigest()\n\n    try:\n        original_path = os.getcwd()\n\n        os.chdir(folder_path)\n        file_list = os.listdir()\n\n        \n        duplicates = []\n        hash_keys = dict()\n        for index, filename in  enumerate(os.listdir('.')):  #listdir('.') = current directory\n            if os.path.isfile(filename):\n                with open(filename, 'rb') as f:\n                    filehash = hashlib.md5(f.read()).hexdigest()\n                if filehash not in hash_keys: \n                    hash_keys[filehash] = index\n                else:\n                    duplicates.append((index,hash_keys[filehash]))\n        print(len(duplicates))\n        # for file_indexes in duplicates[:30]:\n        #     try:\n            \n        #         plt.subplot(121),plt.imshow(Image.open(file_list[file_indexes[1]]))\n        #         plt.title(file_indexes[1]), plt.xticks([]), plt.yticks([])\n\n        #         plt.subplot(122),plt.imshow(Image.open(file_list[file_indexes[0]]))\n        #         plt.title(str(file_indexes[0]) + ' duplicate'), plt.xticks([]), plt.yticks([])\n        #         plt.show()\n            \n        #     except OSError as e:\n        #         continue\n\n        for index in duplicates:\n            os.remove(file_list[index[0]])\n\n    finally:\n        os.chdir(original_path)\n        \n                    \n                    ","17cad45f":"def delete(target_folder):\n    for folder in os.listdir(target_folder):\n        current_folder = os.path.join(target_folder, folder)\n        print(current_folder)\n        delete_duplicate_imgs(current_folder)","4ecd147a":"delete('\/content\/training_folder')","aded5471":"!rm -r \/content\/training_folder_no_duplicate","207dde75":"# !zip -r \/content\/training_folder_no_duplicate.zip \/content\/training_folder_no_duplicate","4a3753e9":"# !rm \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder_no_duplicate.zip\n# !rm -r \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder_no_duplicate\n","22d419ed":"# !cp \/content\/training_folder_no_duplicate.zip -d \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\n# !cp -r \/content\/training_folder_no_duplicate -d \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu","e0cd6ab2":"# !rm -r \/content\/train_test_split","76b0f868":"# !unzip  \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder_no_duplicate -d \/","d81ba861":"!unzip  \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/training_folder -d \/","e2a6802f":"import os\nimport shutil\nimport numpy as np\n\n# main_folder = 'train_test_split'\n# os.makedirs(main_folder, exist_ok = True)\n\n\n# test_folder = os.path.join(main_folder,'test_folder')\n# os.makedirs(test_folder, exist_ok = True)\n\n\n# src_folder = 'training_folder'\n\n# training_folder = os.path.join(main_folder,src_folder)\n# os.makedirs(training_folder, exist_ok = True)\n\n\n\n\n\ndef split_train_test(src_folder, test_ratio, destination_path = '.'):\n\n    main_folder_path = os.path.join(destination_path,'train_test_split')\n    os.makedirs(main_folder_path, exist_ok = True)\n\n    training_folder_path = os.path.join(main_folder_path, 'training_folder')\n    os.makedirs(training_folder_path, exist_ok = True)\n\n    test_folder_path = os.path.join(main_folder_path, 'test_folder')\n    os.makedirs(test_folder_path, exist_ok = True)\n\n    for folder in os.listdir(src_folder):\n\n        folder_path_src = os.path.join(src_folder, folder)\n\n        file_list = os.listdir(folder_path_src)\n        file_count = len(file_list)\n\n        split_point = test_ratio # split with fix number instead of ratio\n        # split_point = round(test_ratio * file_count)\n\n        np.random.shuffle(file_list)\n        \n        training_list = file_list[split_point:]\n        test_list = file_list[:split_point]\n        print(len(training_list), len(test_list))\n\n        folder_path_dest_test = os.path.join(test_folder_path, folder)\n        os.makedirs(folder_path_dest_test, exist_ok = True)\n\n        folder_path_dest_train = os.path.join(training_folder_path, folder)\n        os.makedirs(folder_path_dest_train, exist_ok = True)    \n        for file_name in test_list:\n            shutil.copyfile(os.path.join(src_folder,folder, file_name), os.path.join(folder_path_dest_test, file_name))\n\n        for file_name in training_list:\n            shutil.copyfile(os.path.join(src_folder,folder, file_name), os.path.join(folder_path_dest_train, file_name))","802a541f":"# !rm -r \/content\/train_test_split\nratio = 30\nsplit_train_test('\/content\/training_folder', ratio)","43da00be":"# !zip -r \/content\/train_test_split.zip \/content\/train_test_split\n# !cp \/content\/train_test_split.zip \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\n# !cp -r \/content\/train_test_split \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\n# !cp -r \/content\/train_test_split -d \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified","3b00bcb8":"!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/Gypsum board\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p8-8-gyps'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/Veneer decorative\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p7-146-vene'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/armchair\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p1-327-chai-armc'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/artificial decorative plant\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p2-80-arti'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/curtain close up\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p3-3-curt'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/decorative chandelier\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p4-266-chan'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/decorative desk lamp\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p4-261-tabl'\n!cp -a '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/scraped_image_1000_more_class\/stoolchair\/.' '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/training_folder\/p1-327-chai-stoo'","6cfe3fed":"main_folder = '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_modified\/test_folder'\nfor folder in os.listdir(main_folder):\n    current_folder = os.path.join(main_folder,folder)\n    print(len(os.listdir(current_folder)))","caa85959":"main_folder = '\/content\/training_folder'\nfor folder in os.listdir(main_folder):\n    current_folder = os.path.join(main_folder,folder)\n    print(folder, len(os.listdir(current_folder)))","a63a2a1b":"main_folder = '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split\/training_folder'\nfor folder in os.listdir(main_folder):\n    current_folder = os.path.join(main_folder,folder)\n    print(folder, len(os.listdir(current_folder)))","2ae9c1cc":"import requests\nfrom bs4 import BeautifulSoup\nimport re\n\ndef get_img_urls(query_text, n_pics):\n    \n    number = 0\n    query_text = query_text.replace(' ', '+')\n\n    total_img_links = []\n    while number <= n_pics:\n        MAIN_URL = f'https:\/\/th.images.search.yahoo.com\/search\/images?norw=1&ei=UTF-8&fr=sfp&fr2=p%3As%2Cv%3Ai&o=js&p={query_text}&tmpl=&nost=1&b={number}&iid=Y.6&ig=0af185d75d2e4fb88600000000d23bd5&rand=1613516875071'\n        # MAIN_URL = f'https:\/\/th.images.search.yahoo.com\/search\/images?ei=UTF-8&fr=sfp&fr2=sb-top-th.images.search&o=js&p={query_text}&tmpl=&nost=1&b={number}&iid=Y.6&ig=0af0253438b54cd79000000000867a90&rand=1613506083391'\n        r = requests.get(MAIN_URL)\n        soup = BeautifulSoup(r.content,'lxml')\n        results = soup.find_all('img',{'src':re.compile('.*')})\n        img_links = [x['src'].replace(\"\\\\\", \"\") for x in results]\n        total_img_links = total_img_links + img_links\n        number += 60\n    return total_img_links","f54b5930":"import pandas as pd\nimport numpy as np\nimport requests\nimport os\nfrom tqdm.notebook import tqdm\nimport concurrent.futures\n\nimport random\nimport string\n\n\ndef get_random_string(length):\n    # choose from all lowercase letter\n    letters = string.ascii_lowercase\n    result_str = ''.join(random.choice(letters) for i in range(length))\n    return result_str\n\n\noriginal_dir = '\/content'\nos.chdir(original_dir)\ndef download_img(img_link):\n    r = requests.get(img_link)\n    file_name = get_random_string(20) + '.jpg'\n    # file_path = os.path.join(img_dest_path,file_name) \n    with open(file_name, 'wb') as f:\n        # for chunk in r.iter_content(chunk_size = 128):\n        #     f.write(chunk)\n        f.write(r.content)\n\ndef scrape_and_download_imgs(search_queries_dict, n_pics = 100):\n    original_dir = os.getcwd()\n    try:\n        \n        main_folder = 'scraped_image'\n        os.makedirs(main_folder, exist_ok = True)\n        for query in tqdm(search_queries_dict):\n            os.chdir(original_dir)\n            current_folder = os.path.join(main_folder, search_queries_dict[query])\n            os.makedirs(current_folder, exist_ok = True)\n            os.chdir(current_folder)\n\n            img_link = get_img_urls(query,n_pics = n_pics)\n            \n            with concurrent.futures.ThreadPoolExecutor() as executor:\n                executor.map(download_img, img_link)\n\n    finally:\n        os.chdir(original_dir)","fb4bf6b6":"search_queries_dict = {'double knuckle baluster balcony':'p12-365-rail',\n                       'dining chair':'p1-327-chai-dini',\n                       'office ergonimic chair':'p1-327-chai-work',\n                       'armchair':'p1-327-chai-armc',\n                       'gypsum board':'p8-8-gyps',\n                       'stoolchair':'p1-327-chai-stoo',\n                       'desk lamp':'p4-261-tabl',\n                       'veneer board':'p7-146-vene',\n                       'chandelier design':'p4-266-chan',\n                       'solid wood':'p7-34-wood',\n                       'sofa': 'p1-328-sofa',\n                       'small decorative model item': 'p2-341-mode',\n                       'wall tile':'p7-175-tile',\n                       'uv glass film texture':'p7-228-film',\n                       'home wall stone':'p7-187-ston',\n                       'artificial plant flower':'p2-80-arti',\n                       '3d convex wall texture':'p7-109-magi',\n                       'door':'p11-353-door-door',\n                       'wooden floor':'p6-348-wood',\n                       'curtain close up':'p3-3-curt',\n                       'bathroom floor texture':'p6-108-tile',\n                       }","b61787f6":"search_queries_dict = {'interior curtain wall':'p9-36-glas',\n 'gypsum board ceiling':'p8-8-gyps',\n }","5d494b3c":"\nscrape_and_download_imgs(search_queries_dict, n_pics = 1000)\n","4fdebbd9":"main_folder = '\/content\/scraped_image'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","7e79c61e":"delete('\/content\/scraped_image')","92598a92":"main_folder = '\/content\/scraped_image'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","41f63e52":"!zip -r \/content\/scraped_image_glass_gypsum.zip \/content\/scraped_image","c90d93de":"!cp \/content\/scraped_image_glass_gypsum.zip \/content\/drive\/Shareddrives\/SuperAI\/Wan","843a113c":"delete('\/content\/train_test_split\/training_folder')","05c4ab95":"# !cp -r \/content\/scraped_image \/content\/drive\/Shareddrives\/SuperAI\/Wan","1764bb94":"!rsync -a \/content\/scraped_image\/ \/content\/train_test_split\/training_folder","75788403":"!zip -r \/content\/train_test_split_scraped_new_final.zip \/content\/train_test_split","073831fc":"!cp \/content\/train_test_split_scraped_new_final.zip \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu","0361bf65":"!cp -r \/content\/train_test_split -d \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_scraped_new_final","9f1a1fb7":"main_folder = '\/content\/train_test_split\/training_folder'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","c0b95332":"main_folder = '\/content\/train_test_split\/training_folder'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","d6a081a5":"main_folder = '\/content\/training_folder'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","923800cd":"main_folder = '\/content\/scraped_image'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","bf13fc7b":"!gdown --id 1ggM1vZuxBMnCo6QgOlBjOBlQzX10h295","da059bc9":"!unzip \/content\/train_test_split_scraped.zip -d \/","a07dcb7f":"import os\n\nmain_folder = '\/content\/train_test_split\/test_folder'\nfor folder in os.listdir(main_folder):\n    print(folder, len(os.listdir(os.path.join(main_folder,folder))))","32461ae1":"!pip install efficientnet","dbf5d5d5":"import tensorflow as tf\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nimport efficientnet.keras as enet\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16') # \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a Nvidia GPU\n","a806adfb":"from keras.backend import sigmoid\n\nclass SwishActivation(Activation):\n    \n    def __init__(self, activation, **kwargs):\n        super(SwishActivation, self).__init__(activation, **kwargs)\n        self.__name__ = 'swish_act'\n\ndef swish_act(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nget_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n","435b7479":"INPUT_SHAPE = 224\n\nmodel = enet.EfficientNetB0(include_top=False, input_shape=(INPUT_SHAPE,INPUT_SHAPE,3), pooling='avg', weights='noisy-student')\n\n# model.trainable = True\n\n# set_trainable = False\n# for layer in model.layers:\n#     if layer.name == 'multiply_16':\n#         set_trainable = True\n#     if set_trainable:\n#         layer.trainable = True\n#     else:\n#         layer.trainable = False\n\ndef unfreeze_model(model):\n    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-20:]:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n\n\nunfreeze_model(model)\n\n\n# Adding 2 fully-connected layers to B0.\nx = model.output\n\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Dense(128)(x)\nx = BatchNormalization()(x)\nx = Activation(swish_act)(x)\nx = Dropout(0.5)(x)\n\nx = Dense(64)(x)\nx = BatchNormalization()(x)\nx = Activation(swish_act)(x)\nx = Dropout(0.5)(x)\n\nx = Dense(32)(x)\nx = BatchNormalization()(x)\nx = Activation(swish_act)(x)\n\n# Output layer\npredictions = Dense(24, activation=\"softmax\",dtype='float32')(x)\n\nmodel_final = Model(inputs = model.input, outputs = predictions)\n\nmodel_final.summary()\n","853614ca":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 \/ 255,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory('\/content\/train_test_split\/training_folder',\n                                                    target_size = (INPUT_SHAPE,INPUT_SHAPE),\n                                                    batch_size = BATCH_SIZE,\n                                                    class_mode = 'categorical',\n                                                    shuffle=True)\nvalidation_generator = test_datagen.flow_from_directory(\n        '\/content\/train_test_split\/test_folder',\n        target_size=(INPUT_SHAPE,INPUT_SHAPE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical')","0545d5bf":"from sklearn.utils import class_weight\nimport numpy as np\n\nclass_weights = class_weight.compute_class_weight(\n           'balanced',\n            np.unique(train_generator.classes), \n            train_generator.classes)\nclass_weights","1163aaa0":"class_weights = {key:value for key, value in zip(np.unique(train_generator.classes),class_weights)}","5aa8073e":"from google.colab import drive\ndrive.mount('\/content\/drive')","4cefe6ca":"!pip install adabelief-tf","e1fb62e0":"from adabelief_tf import AdaBeliefOptimizer\nimport os","8e3b67bd":"# model_final.compile(loss='categorical_crossentropy',\n#               optimizer=AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-7, rectify=False),\n#               metrics=['acc','mse'])\n\n# os.makedirs('\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/best_weights',exist_ok = True)\n# mcp_save = ModelCheckpoint('\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/best_weights\/EnetB0_CIFAR10_TL.h5', save_best_only=True, monitor='val_acc',verbose=1)\n# reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\n\n# #print(\"Training....\")\n# model_final.fit(train_generator,\n#               batch_size=32,\n#               epochs=10,\n#               validation_data = validation_generator,\n#               class_weight=class_weights, \n#               callbacks=[mcp_save, reduce_lr],\n#               shuffle=True,\n#               verbose=1,\n#               max_queue_size=100,\n#               workers = 10 ,# (set a proper value > 1)\n              \n# )\n\n","695deea2":"model_final.compile(loss='categorical_crossentropy',\n              optimizer=AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-7, rectify=False),\n              metrics=['acc','mse'])\n\nweight_folder_path = '\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/best_weights'\nos.makedirs(weight_folder_path,exist_ok = True)\nfilepath = os.path.join(weight_folder_path,\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\")\n# # checkpoint\n\n# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n# callbacks_list = [checkpoint]\n\n\nmcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_acc',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\n\n#print(\"Training....\")\nmodel_final.fit(train_generator,\n              batch_size=32,\n              epochs=10,\n              validation_data = validation_generator,\n              class_weight=class_weights, \n              callbacks=[mcp_save, reduce_lr],\n              shuffle=True,\n              verbose=1,\n              max_queue_size=100,\n              workers = 10 ,# (set a proper value > 1)\n              \n)\n\n\n","016d82cc":"model_final.fit(train_generator,\n              batch_size=32,\n              epochs=10,\n              validation_data = validation_generator, \n              callbacks=[mcp_save, reduce_lr],\n              shuffle=True,\n              verbose=1,\n              max_queue_size=100,\n              workers = 10 ,# (set a proper value > 1)\n              \n)\n","9ff6de8b":"# retrain the model around 50 epochs until the val_accuracy reach ~ 0.98\n\nmodel_final.fit(train_generator,\n              batch_size=32,\n              epochs=10,\n              validation_data = validation_generator, \n              callbacks=[mcp_save, reduce_lr],\n              shuffle=True,\n              verbose=1,\n              max_queue_size=100,\n              workers = 10 ,# (set a proper value > 1)\n              \n)","d166cbcb":"# download the new scraped dataset (mostly new gypsum and glass) to finetune the current model\n\nos.makedirs('finetune dataset',exist_ok = True)\nos.makedirs('finetune_dataset',exist_ok = True)\n!unzip \/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/train_test_split_scraped_new_final.zip -d \/content\/finetune_dataset\/\n","c8ac6955":"finetune_train_generator = train_datagen.flow_from_directory('\/content\/finetune_dataset\/content\/train_test_split\/training_folder',\n                                                    target_size = (INPUT_SHAPE,INPUT_SHAPE),\n                                                    batch_size = BATCH_SIZE,\n                                                    class_mode = 'categorical',\n                                                    shuffle=True)","e68c4943":"from sklearn.utils import class_weight\nimport numpy as np\n\nclass_weights = class_weight.compute_class_weight(\n           'balanced',\n            np.unique(finetune_train_generator.classes), \n            finetune_train_generator.classes)\nclass_weights\nclass_weights = {key:value for key, value in zip(np.unique(finetune_train_generator.classes),class_weights)}","cf3d2847":"model_final.fit(finetune_train_generator,\n              batch_size=32,\n              epochs=10,\n              validation_data = validation_generator,\n              class_weight=class_weights, \n              callbacks=[mcp_save, reduce_lr],\n              shuffle=True,\n              verbose=1,\n              max_queue_size=100,\n              workers = 10 ,# (set a proper value > 1)\n              \n)","7a84e512":"# # gdown csv\n# !gdown --id 13UprfqKTxQ9C0XbhvZMER6EVeNFDq742\n!gdown --id 17y6qbV_-lroxEFTib_HVm1htTSr4WyqK","86ae9701":"import pandas as pd\ntest_df = pd.read_csv('\/content\/test.csv')\ntest_df['image_name'] = test_df['url'].str.split('\/').str[-1] \n\n","a9ee9db2":"# test_dict = test_df.set_index('image_name')['url'].to_dict()\n# test_download_list = list(test_dict.keys())","7b9f4b34":"import pandas as pd\nimport numpy as np\nimport requests\nimport os\nimport concurrent\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\ntest_path = 'test_path'\nos.makedirs(test_path, exist_ok = True)\n\ndef download_img(img_link):\n    r = requests.get(img_link)\n    file_name = img_link.split('\/')[-1]\n    file_path = os.path.join(test_path,file_name) \n    with open(file_path, 'wb') as f:\n        # for chunk in r.iter_content(chunk_size = 128):\n        #     f.write(chunk)\n        f.write(r.content)\n\ndef run(f, my_iter):\n    l = len(my_iter)\n    with tqdm(total=l) as pbar:\n        # let's give it some more threads:\n        with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n            futures = {executor.submit(f, arg): arg for arg in my_iter}\n            results = {}\n            for future in concurrent.futures.as_completed(futures):\n                arg = futures[future]\n                results[arg] = future.result()\n                pbar.update(1)\nrun(download_img,test_df['url'])\n","29e7cc8a":"# test_df[test_df['image_name'] == '2013121108393181a54efbdd3c691ac2dba02df73c4a86.jpg']","8f9d05c8":"# (test_df['image_name']).value_counts()","ccbebac8":"# !rm -r \/content\/test_path_cropped","693e7593":"test_path_cropped = '\/content\/test_path_cropped'\nos.makedirs('test_path_cropped', exist_ok = True)\n\ndef crop_img(sample_row):\n    left = sample_row['tl_x']\n    right = sample_row['tr_x']\n    top = sample_row['tl_y']\n    bottom = sample_row['br_y']\n\n\n\n    im = Image.open(os.path.join(test_path,sample_row['image_name'])) \n    width, height = im.size\n\n    left = left * width\n    top = top * height\n    right = right * width\n    bottom = bottom * height\n\n    im1 = im.crop((left, top, right, bottom)) \n    im1.save(os.path.join(test_path_cropped, sample_row['image_name']))\n\n\ntest_df.apply(crop_img, axis = 1);","dd9b932c":"len(os.listdir('\/content\/test_path_cropped'))","5d08aa01":"# load model\n","b9ed37cf":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","b7203acc":"main_test_folder = 'test_folder'\nos.makedirs(main_test_folder,exist_ok = True)\n!mv  \/content\/test_path_cropped \/content\/test_folder\/","ca047202":"!pip install efficientnet","931e8fca":"from adabelief_tf import AdaBeliefOptimizer\nimport tensorflow as tf\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nimport efficientnet.keras as enet\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16') # \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a Nvidia GPU\nimport efficientnet.tfkeras\nfrom tensorflow.keras.models import load_model\n\n\nfrom keras.backend import sigmoid\n\n\nclass SwishActivation(Activation):\n    \n    def __init__(self, activation, **kwargs):\n        super(SwishActivation, self).__init__(activation, **kwargs)\n        self.__name__ = 'swish_act'\n\ndef swish_act(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nget_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n","e54475d2":"\n\n!gdown --id 1ggM1vZuxBMnCo6QgOlBjOBlQzX10h295\n!unzip \/content\/train_test_split_scraped.zip -d \/\n\nINPUT_SHAPE = 224\nBATCH_SIZE = 32\n\n# INPUT_SHAPE = 331 # Karn\n# BATCH_SIZE = 32\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 \/ 255,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n)\n\n\ntrain_generator = train_datagen.flow_from_directory('\/content\/train_test_split\/training_folder',\n                                                    target_size = (INPUT_SHAPE,INPUT_SHAPE),\n                                                    batch_size = BATCH_SIZE,\n                                                    class_mode = 'categorical')\n\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = test_datagen.flow_from_directory(\n        '\/content\/test_folder',\n        target_size=(INPUT_SHAPE,INPUT_SHAPE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle = False)","6ce3cc23":"model = load_model('\/content\/drive\/Shareddrives\/SuperAI\/Wan\/Wazzadu\/best_weights\/weights-improvement-06-0.97.hdf5',custom_objects={'AdaBeliefOptimizer':AdaBeliefOptimizer})","d6771d43":"probabilities = model.predict(validation_generator, verbose = 1)\n","f7437a09":"probabilities.shape","d6b1fc94":"answer = np.argmax(probabilities,axis =1)","f34679d9":"answer_to_number_dict = train_generator.class_indices\nnumber_to_answer_dict = {key: value for value, key in answer_to_number_dict.items()}","a2c40b83":"answer_map = {key.split('\/')[-1]: value for key, value in zip(validation_generator.filenames,answer)}","f3a389a2":"test_df[\"Answer\"] = test_df['image_name'].map(answer_map)","2b9d8b3f":"test_df['Answer'] = test_df['Answer'].map(number_to_answer_dict)","96897f85":"answer_df = test_df[['id','Answer']]\nanswer_df","9c98cce8":"answer_dict = test_df.set_index('image_name')['Answer'].to_dict()","58354bf1":"# visualize prediction\n\nimport matplotlib.pyplot as plt\n\nmain_folder_path = '\/content\/test_folder\/test_path_cropped'\nfor file_name in answer_dict:\n    current_file = os.path.join(main_folder_path,file_name)\n\n    img = Image.open(current_file)\n    plt.figure()\n    plt.imshow(img)\n    plt.title(answer_dict[file_name])\n    plt.axis('off')\n","874309dc":"dummy_df = pd.DataFrame({'id':range(1,1218)})\nanswer_df = pd.merge(answer_df, dummy_df, how ='outer', on = 'id')","5f8ce838":"answer_df","8fffa486":"answer_df.to_csv('submission_karn5555.csv',index = False)","503851d9":"# Create main training folder","15d43e0e":"# Download image","1116dd09":"# Webscraping","0622e0ef":"# Split train test folder","7ad8dc27":"# Create labels","f1f8769f":"# Train model","9834c378":"# Test Pipeline","88efa110":"# Load preprocessed data"}}