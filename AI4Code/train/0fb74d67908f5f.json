{"cell_type":{"2e9771f3":"code","90d3b682":"code","c20faa94":"code","2a6a7617":"code","02c6a18b":"code","13a925da":"code","80d48752":"code","eac1a564":"code","cb65d6e4":"code","4e921402":"code","8135f607":"code","94ca2d40":"code","e97458a0":"code","17b05dcb":"code","ff216df8":"code","5815d394":"code","62adfe86":"code","28c6a264":"code","6c34f25c":"code","173ebf78":"code","ff220310":"code","30c871c8":"code","c65a98ef":"code","3446a2c5":"code","ccb5ce79":"code","21c2ad41":"code","11cba1af":"code","4a607c31":"code","d356528c":"code","62216898":"code","b0a5051e":"code","4d8b698c":"code","8b27a1d8":"code","1af6f316":"code","69db9f2b":"code","37437d35":"code","997fbcee":"code","4951ecac":"code","614d3298":"code","b4735a9e":"code","76071e19":"code","5e1e710d":"code","f7b323db":"code","accaa414":"code","d66d699c":"code","a95013af":"code","2a253dc2":"code","ce395993":"code","1b8dede3":"code","5befe2a8":"code","abe31c50":"code","8c762e21":"code","8390d870":"markdown","4aa49b3e":"markdown","45a23795":"markdown","19ea40d4":"markdown","4067ed50":"markdown","73ed0225":"markdown","6507cd94":"markdown","950bace7":"markdown","eaeff50c":"markdown","7ee6d2fd":"markdown","1e0b9e6a":"markdown","3cc42cbe":"markdown","95fb5d88":"markdown","de78be8b":"markdown","e91cf278":"markdown","e78d916a":"markdown","b211634a":"markdown","632c6199":"markdown","b8c9e931":"markdown","aae4657d":"markdown","4e82902a":"markdown","d69743f6":"markdown","01c53685":"markdown","e1f56ed3":"markdown","11ab457a":"markdown","05cd312d":"markdown","840479c4":"markdown","6673d6ba":"markdown","f3a4fb5b":"markdown","8b327f64":"markdown","c4ce5125":"markdown","e46a4002":"markdown","2d20feb2":"markdown","8d2f9f40":"markdown","f1c64013":"markdown","d798ab9b":"markdown","76701485":"markdown","32902c03":"markdown","205d9eff":"markdown","ecfdfba0":"markdown","628a91dd":"markdown","a1c8e33e":"markdown","1de0a3ad":"markdown","1e627d3e":"markdown"},"source":{"2e9771f3":"import numpy as np\nimport os\nimport pandas as pd\nfrom fastai.vision.all import *","90d3b682":"dataset_path = Path('..\/input\/cassava-leaf-disease-classification')\nos.listdir(dataset_path)","c20faa94":"train_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df.head()","2a6a7617":"with open(os.path.join(dataset_path, \"label_num_to_disease_map.json\")) as file:\n    map_classes = json.loads(file.read())\n    classes=[]\n    for k, v in map_classes.items():        \n        classes.append([int(k), v])\n        \nclasses_df = pd.DataFrame(classes, columns=['Label', 'Label Details'])\nprint(classes_df.to_string(index=False))","02c6a18b":"train_0_df = train_df[train_df['label']==0]\ntrain_1_df = train_df[train_df['label']==1]\ntrain_2_df = train_df[train_df['label']==2]\ntrain_3_df = train_df[train_df['label']==3]\ntrain_4_df = train_df[train_df['label']==4]","13a925da":"picture_path = Path('..\/input\/cassava-leaf-disease-classification\/train_images\/')","80d48752":"from PIL import Image\nimage_0 = Image.open(picture_path\/train_0_df.loc[train_0_df.index[0]]['image_id'])\nimage_1 = Image.open(picture_path\/train_1_df.loc[train_1_df.index[0]]['image_id'])\nimage_2 = Image.open(picture_path\/train_2_df.loc[train_2_df.index[0]]['image_id'])\nimage_3 = Image.open(picture_path\/train_3_df.loc[train_3_df.index[0]]['image_id'])\nimage_4 = Image.open(picture_path\/train_4_df.loc[train_4_df.index[0]]['image_id'])","eac1a564":"image_0 #\"Cassava Bacterial Blight (CBB)\"","cb65d6e4":"image_1 #\"Cassava Brown Streak Disease (CBSD)\"","4e921402":"image_2 #\"Cassava Green Mottle (CGM)\"","8135f607":"image_3 #\"Cassava Mosaic Disease (CMD)\"","94ca2d40":"image_4 #\"Healthy\"","e97458a0":"print(f\"Cassava Bacterial Blight (CBB): {len(train_0_df)}\")\nprint(f\"Cassava Brown Streak Disease (CBSD): {len(train_1_df)}\")\nprint(f\"Cassava Green Mottle (CGM): {len(train_2_df)}\")\nprint(f\"Cassava Mosaic Disease (CMD): {len(train_3_df)}\")\nprint(f\"Healthy: {len(train_4_df)}\")","17b05dcb":"import numpy as np\nimport matplotlib.pyplot as plt\n \nlabel = [\"CBB\", \"CBSD\", \"CGM\", \"CMD\", \"Healthy\"]\nnumbers = np.array([len(train_0_df), \n                   len(train_1_df), \n                   len(train_2_df), \n                   len(train_3_df), \n                   len(train_4_df)]\n                 )\n\nplt.bar(label, numbers)","ff216df8":"import tensorflow as tf\nimport tensorflow_datasets as tfds","5815d394":"all_image_paths=[]\nfor i in range(len(train_df)):\n    all_image_paths.append(str(picture_path\/train_df.loc[i]['image_id']))","62adfe86":"all_image_paths[:10]","28c6a264":"all_image_labels = np.array(train_df['label'])\n\nprint(\"First 10 labels indices: \", all_image_labels[:10])","6c34f25c":"img_path = all_image_paths[0]","173ebf78":"Image.open(img_path)","ff220310":"img_raw = tf.io.read_file(img_path)\nprint(repr(img_raw)[:100]+\"...\")","30c871c8":"img_tensor = tf.image.decode_image(img_raw)\n\nprint(img_tensor.shape)\nprint(img_tensor.dtype)","c65a98ef":"img_final = tf.image.resize(img_tensor, [64, 64])\nimg_final = img_final\/255.0\nprint(img_final.shape)\nprint(img_final.numpy().min())\nprint(img_final.numpy().max())","3446a2c5":"def preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [64, 64])\n    image \/= 255.0  # normalize to [0,1] range\n\n    return image","ccb5ce79":"import IPython.display as display\nimport pathlib\nimport matplotlib.pyplot as plt\n\ndef load_and_preprocess_image(path):\n    image = tf.io.read_file(path)\n    return preprocess_image(image)\n\nimage_path = all_image_paths[0]\nlabel = all_image_labels[0]\n\nplt.imshow(load_and_preprocess_image(img_path))\nplt.grid(False)\nplt.show()","21c2ad41":"path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\nprint(path_ds)","11cba1af":"image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)","4a607c31":"for image in image_ds.take(1):\n    new_image=image.numpy()\n    print(new_image.shape)\n    print(new_image)","d356528c":"new_image=[]\nfor image in image_ds:#.take(1)\n    new_image.append(image.numpy())\nX = np.array(new_image)\nprint(X.shape)","62216898":"import matplotlib.pyplot as plt\n\nfor n,image in enumerate(image_ds.take(4)):\n    plt.figure(figsize=(8,8))\n    plt.subplot(2,2,n+1)\n    plt.imshow(image)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.show()","b0a5051e":"label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))","4d8b698c":"for label in label_ds.take(10):\n    print(label.numpy())","8b27a1d8":"new_label=[]\nfor label in label_ds:#.take(1)\n    new_label.append(label.numpy())\ny = np.array(new_label)\nprint(y.shape)","1af6f316":"from sklearn.preprocessing import OneHotEncoder","69db9f2b":"print(y.shape)\nenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\ny_one_hot = enc.fit_transform(y[:, np.newaxis])\n\nprint(y.shape)\nprint(y_one_hot.shape)","37437d35":"from sklearn.model_selection import train_test_split","997fbcee":"X_train, X_val, y_train, y_val = train_test_split(X, y_one_hot, test_size=0.2)\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","4951ecac":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\n\nnum_classes = 5\n\n#input image dimensions\nimg_rows, img_cols = 64, 64\ninput_shape = (img_rows, img_cols, 3)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(384, activation='relu'))#128\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(lr=0.001),#lr=0.01,\n              metrics=['accuracy'])","614d3298":"model.summary()","b4735a9e":"history = model.fit(X_train, \n                    y_train,\n                    batch_size=32,# 20, 32, 64\n                    epochs=100,# 50\n                    validation_data=(X_val,y_val))","76071e19":"# \u30c7\u30fc\u30bf\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\n#print(history.history)","5e1e710d":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n","f7b323db":"y_pred = model.predict(X_val)#, batch_size=1, verbose=0\nprint(f\"y_pred.shape:{y_pred.shape}\")\n\ny_pred_label = np.argmax(y_pred, axis=1)\nprint(f\"y_pred_label:\\n{y_pred_label}\")","accaa414":"picture_path = Path('..\/input\/cassava-leaf-disease-classification\/test_images\/')\nos.listdir(picture_path)\n# \u4e00\u3064\u3057\u304b\u306a\u3044","d66d699c":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\nsample_df.head()","a95013af":"#all_image_paths_test=[]\n#path_tmp = str(picture_path\/sample_df.loc[0]['image_id'])\n#all_image_paths_test.append(path_tmp)\n#\n#print(all_image_paths_test)","2a253dc2":"all_image_paths_test=[]\nfor i in range(len(sample_df)):\n    all_image_paths_test.append(str(picture_path\/sample_df.loc[i]['image_id']))","ce395993":"path_ds_test = tf.data.Dataset.from_tensor_slices(all_image_paths_test)\nprint(path_ds_test)\n\nimage_ds_test = path_ds_test.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\nprint(image_ds_test)","1b8dede3":"new_image_test=[]\nfor image in image_ds_test:#.take(1)\n    new_image_test.append(image.numpy())\nX_test = np.array(new_image_test)\nprint(X_test.shape)\n","5befe2a8":"y_pred_test = model.predict(X_test)#, batch_size=1, verbose=0\nprint(f\"y_pred_test.shape:{y_pred_test.shape}\")\n\ny_pred_label_test = np.argmax(y_pred_test, axis=1)\nprint(f\"y_pred_label_test:\\n{y_pred_label_test}\")","abe31c50":"# Submission dataframe\nsubmit_ID = sample_df.loc[:]['image_id']\nsubmit_TARGET = pd.DataFrame(y_pred_label_test)\n\nsubmission_df = pd.concat([submit_ID, submit_TARGET], axis=1)\nsubmission_df.columns = ['image_id','label']\n\nsubmission_df","8c762e21":"submission_df.to_csv('submission.csv',index=False)","8390d870":"## Cassava Leaf Disease Classification  \n\u3053\u306e\u30b3\u30f3\u30da\u306f\u30ad\u30e3\u30c3\u30b5\u30d0\u306e21367\u679a\u306e\u30e9\u30d9\u30eb\u4ed8\u304d\u753b\u50cf\u3092\u4f7f\u3063\u3066\u3001\u30ad\u30e3\u30c3\u30b5\u30d0\u3092\uff14\u3064\u306e\u75c5\u6c17\uff08\u307e\u305f\u306f\u5065\u5eb7\u72b6\u614b\uff09\u306b\u5206\u985e\u3059\u308b\u30b3\u30f3\u30da\u3067\u3059\u3002\n","4aa49b3e":"#### Label\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8","45a23795":"### Keras\u3067\u8a13\u7df4\u3059\u308b","19ea40d4":"Submit\u30d5\u30a1\u30a4\u30eb\u306e\u6e96\u5099","4067ed50":"#### \u5199\u771f\u3092\u898b\u308b","73ed0225":"\u30e2\u30c7\u30eb\u306b\u5408\u308f\u305b\u3066\u30ea\u30b5\u30a4\u30ba\u3057\u307e\u3059\u3002","6507cd94":"\u751f\u306e\u753b\u50cf\u3092\u53d6\u308a\u8fbc\u307f\u307e\u3059\u3002","950bace7":"### \u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f\u3068\u6574\u5f62","eaeff50c":"## OverView\uff08Summary\uff09","7ee6d2fd":"## \u8a13\u7df4","1e0b9e6a":"### Next Action  \n\u904e\u5b66\u7fd2\u3055\u305b\u306a\u3044\u305f\u3081\u306e\u5de5\u592b\u3092\u691c\u8a0e\u3059\u308b  \n- \u5199\u771f\u30c7\u30fc\u30bf\u3092\u62e1\u5f35\u3057\u305f\u3089\u3069\u3046\u306a\u308b\u304b\n- \u7279\u5fb4\u304c\u308f\u304b\u308a\u3084\u3059\u3044\u753b\u50cf\u3092\u9078\u3093\u3060\u308a\u3001\u30ce\u30a4\u30ba\u306b\u306a\u308a\u305d\u3046\u306a\u753b\u50cf\u3092\u9664\u5916\u3057\u3066\u5b66\u7fd2\u3055\u305b\u305f\u3089\u3069\u3046\u306a\u308b\u304b\n- \u679a\u6570\u306e\u5dee\u3092\u8abf\u6574\u3057\u305f\u3089\u3069\u3046\u306a\u308b\u304b\n- \u753b\u50cf\u306e\u8a72\u5f53\u7b87\u6240\u3060\u3051\u629c\u304d\u51fa\u3057\u3066\u5b66\u7fd2\u3055\u305b\u308b\u65b9\u6cd5\u306f\u306a\u3044\u304b","3cc42cbe":"### Time Line  \n- 2021\u5e742\u670811\u65e5 -\u30a8\u30f3\u30c8\u30ea\u30fc\u7de0\u3081\u5207\u308a\u3002\u7af6\u6280\u3059\u308b\u306b\u306f\u3001\u3053\u306e\u65e5\u4ed8\u3088\u308a\u524d\u306b\u7af6\u6280\u898f\u5247\u306b\u540c\u610f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n- 2021\u5e742\u670811\u65e5 -\u30c1\u30fc\u30e0\u5408\u4f75\u306e\u7de0\u3081\u5207\u308a\u3002\u3053\u308c\u306f\u3001\u53c2\u52a0\u8005\u304c\u30c1\u30fc\u30e0\u306b\u53c2\u52a0\u307e\u305f\u306f\u7d71\u5408\u3067\u304d\u308b\u6700\u5f8c\u306e\u65e5\u3067\u3059\u3002\n\n- 2021\u5e742\u670818\u65e5 -\u6700\u7d42\u63d0\u51fa\u671f\u9650\u3002","95fb5d88":"### Submission","de78be8b":"\u753b\u50cf\u306e\u8868\u793a","e91cf278":"\u3053\u306e\u3042\u3068\u8907\u6570\u306e\u753b\u50cf\u3092\u307e\u3068\u3081\u3066\u51e6\u7406\u3059\u308b\u306e\u3067\u3001\u7c21\u5358\u306a\u95a2\u6570\u306b\u307e\u3068\u3081\u307e\u3059\u3002","e78d916a":"#### \u8003\u5bdf\n\u5b66\u7fd2\u73870.001\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba32\u304f\u3089\u3044\u3067\u5b66\u7fd2\u3055\u305b\u308b\u3068train\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306f\u7cbe\u5ea6\u304c\u4e0a\u304c\u308b\u3002  \n\u3057\u304b\u3057\u3001\u3044\u304f\u3089\u8a66\u3057\u3066\u3082test\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306e\u7cbe\u5ea6\u304c\u4e0a\u304c\u3089\u305a\u3001\u6c4e\u5316\u6027\u80fd\u306f\u4f4e\u3044\u3002","b211634a":"### \u63a8\u5b9a","632c6199":"tf.data.Dataset\u306f\u305d\u306e\u307e\u307eKeras\u3067\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u304c\u3001\u3084\u308a\u65b9\u304c\u308f\u304b\u3089\u306a\u3044\u306e\u3067numpy\u306b\u5909\u63db\u3057\u307e\u3059\u3002","b8c9e931":"### Code Requirements\n\u3053\u308c\u306f**`\u30b3\u30fc\u30c9\u30b3\u30f3\u30c6\u30b9\u30c8`**\u3067\u3059  \n\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3078\u306e\u63d0\u51fa\u306f\u3001**`\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u901a\u3058\u3066\u884c\u3046`**\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002  \n\u30b3\u30df\u30c3\u30c8\u5f8c\u306b[\u30b3\u30f3\u30c6\u30b9\u30c8\u306b\u9001\u4fe1]\u30dc\u30bf\u30f3\u3092\u30a2\u30af\u30c6\u30a3\u30d6\u306b\u3059\u308b\u306b\u306f\u3001\u6b21\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n- CPU\u30ce\u30fc\u30c8\u30d6\u30c3\u30af<= 9\u6642\u9593\u306e\u5b9f\u884c\u6642\u9593  \n- GPU\u30ce\u30fc\u30c8\u30d6\u30c3\u30af<= 9\u6642\u9593\u306e\u5b9f\u884c\u6642\u9593  \n- TPU\u306f\u3001\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3078\u306e\u63d0\u51fa\u306b\u306f\u5229\u7528\u3067\u304d\u307e\u305b\u3093\u3002\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u5f15\u304d\u7d9a\u304d\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002TPU\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u3001GPU\u3067\u63a8\u8ad6\/\u9001\u4fe1\u3092\u5b9f\u884c\u3059\u308b\u65b9\u6cd5\u306e\u30a6\u30a9\u30fc\u30af\u30b9\u30eb\u30fc\u306b\u3064\u3044\u3066\u306f\u3001TPU\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\n- \u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u30a2\u30af\u30bb\u30b9\u304c\u7121\u52b9\n- \u4e8b\u524d\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3092\u542b\u3080\u3001\u7121\u6599\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u5916\u90e8\u30c7\u30fc\u30bf\u304c\u8a31\u53ef\u3055\u308c\u307e\u3059\n- \u9001\u4fe1\u30d5\u30a1\u30a4\u30eb\u306b\u306f\u300csubmission.csv\u300d\u3068\u3044\u3046\u540d\u524d\u3092\u4ed8\u3051\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059","aae4657d":"### tf.data.Dataset\u306e\u69cb\u7bc9  \ntf.data.Dataset \u3092\u69cb\u7bc9\u3059\u308b\u3082\u3063\u3068\u3082\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001from_tensor_slices \u30e1\u30bd\u30c3\u30c9\u3092\u4f7f\u3046\u3053\u3068\u3067\u3059\u3002","4e82902a":"#### \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6e96\u5099","d69743f6":"### Train_Test_Split","01c53685":"### Evalution\n\u63d0\u51fa\u7269\u306f\u3001**`\u5206\u985e\u306e\u6b63\u78ba\u3055`**\u306b\u57fa\u3065\u3044\u3066\u8a55\u4fa1\u3055\u308c\u307e\u3059\u3002\n\n### Format\n\u30b3\u30f3\u30c6\u30b9\u30c8\u306e\u63d0\u51fa\u5f62\u5f0f\u306f\u3001\u6b21\u306e\u5f62\u5f0f\u306ecsv\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002\n\nimage_id,label  \n1000471002.jpg,4  \n1000840542.jpg,4  \netc.","e1f56ed3":"#### reference  \nhttps:\/\/www.tensorflow.org\/tutorials\/load_data\/images?hl=ja","11ab457a":"### \u30b5\u30d6\u30df\u30c3\u30c8\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210","05cd312d":"## Files  \n- **train.csv**\n\n    - image_id the image file name.\n\n    - label the ID code for the disease.\n\n\n- **sample_submission.csv**  \nA properly formatted sample submission, given the disclosed test set content.\n\n    - image_id the image file name.\n\n    - label the predicted ID code for the disease.","840479c4":"\u4ee5\u4e0a","6673d6ba":"\u7528\u610f\u3055\u308c\u305f\u753b\u50cf\u306fjpg\u5f62\u5f0f\u306e\u305f\u3081\u3001\u30e2\u30c7\u30eb\u306b\u901a\u3059\u306b\u306f\u5f62\u5f0f\u3092\u5909\u63db\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002","f3a4fb5b":"### One Hot Encording","8b327f64":"#### reference  \nhttps:\/\/www.kaggle.com\/bugraokcu\/cnn-with-keras","c4ce5125":"### \u6e96\u5099","e46a4002":"#### \u5404\u753b\u50cf\u306e\u30e9\u30d9\u30eb\u3092\u629c\u304d\u51fa\u3059","2d20feb2":"#### \u753b\u50cf\u306e\u30d1\u30b9","8d2f9f40":"## \u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f","f1c64013":"\u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\u3057\u307e\u3059\u3002","d798ab9b":"#### reference\n- https:\/\/www.kaggle.com\/tanlikesmath\/cassava-classification-eda-fastai-starter\n- https:\/\/www.kaggle.com\/ihelon\/cassava-leaf-disease-exploratory-data-analysis","76701485":"numpy\u306b\u5909\u63db\u3057\u307e\u3059\u3002","32902c03":"\u4e00\u679a\u306e\u753b\u50cf\u3092\u4f7f\u3063\u3066\u6d41\u308c\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002","205d9eff":"### Label\u306e\u8868\u793a","ecfdfba0":"#### Training\u7528\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8","628a91dd":"### Discription\uff08Summary\uff09  \n- \u30ad\u30e3\u30c3\u30b5\u30d0\u306f\u30a2\u30d5\u30ea\u30ab\u30672\u756a\u76ee\u306b\u5927\u304d\u306a\u70ad\u6c34\u5316\u7269\u306e\u4f9b\u7d66\u8005\u3067\u3042\u308a\u3001\u591a\u304f\u306e\u5bb6\u5ead\u8fb2\u5834\u3067\u683d\u57f9\u3055\u308c\u3066\u3044\u308b\u304c**`\u30a6\u30a4\u30eb\u30b9\u6027\u75be\u60a3\u304c\u4f4e\u53ce\u91cf\u306e\u4e3b\u306a\u539f\u56e0`**\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u306e\u52a9\u3051\u3092\u501f\u308a\u308c\u3070\u3001\u75c5\u6c17\u3092\u7279\u5b9a\u3057\u3066\u6cbb\u7642\u3067\u304d\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002  \n- \u75c5\u6c17\u3092\u691c\u51fa\u3059\u308b\u65e2\u5b58\u306e\u65b9\u6cd5\u306b\u306f\u8fb2\u696d\u5c02\u9580\u5bb6\u306e\u52a9\u3051\u3092\u501f\u308a\u3066\u3001\u8996\u899a\u7684\u306b\u691c\u67fb\u304a\u3088\u3073\u8a3a\u65ad\u3059\u308b\u65b9\u6cd5\u304c\u3042\u308b\u3002\u3057\u304b\u3057\u3001\u3053\u308c\u306f\u52b4\u50cd\u96c6\u7d04\u7684\u3067\u3001\u4f9b\u7d66\u304c\u5c11\u306a\u304f\u3001\u8cbb\u7528\u304c\u304b\u304b\u308b\u3068\u3044\u3046\u554f\u984c\u304c\u3042\u308b\u3002\n- \u307e\u305f\u3001\u8ffd\u52a0\u306e\u8ab2\u984c\u3068\u3057\u3066\u3001\u30a2\u30d5\u30ea\u30ab\u306e\u8fb2\u5bb6\u306f\u4f4e\u54c1\u8cea\u306a\u30ab\u30e1\u30e9\u3057\u304b\u6301\u3063\u3066\u3044\u306a\u3044\u305f\u3081\u3001\u305d\u306e\u5236\u7d04\u306e\u3082\u3068\u3067\u3046\u307e\u304f\u6a5f\u80fd\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n- \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3001\u8fb2\u5bb6\u304c\u64ae\u5f71\u3057\u3001\u30de\u30b1\u30ec\u30ec\u5927\u5b66\u306eAI\u30e9\u30dc\u3068\u56fd\u7acb\u4f5c\u7269\u8cc7\u6e90\u7814\u7a76\u6240\uff08NaCRRI\uff09\u304c\u6ce8\u91c8\u3092\u3064\u3051\u305f**`21,367\u679a\u306e\u30e9\u30d9\u30eb\u4ed8\u304d\u753b\u50cf`**\n- \u3042\u306a\u305f\u306e\u4ed5\u4e8b\u306f\u5404\u30ad\u30e3\u30c3\u30b5\u30d0\u306e\u753b\u50cf\u3092**`4\u3064\u306e\u75c5\u6c17\u306e\u30ab\u30c6\u30b4\u30ea\u307e\u305f\u306f\u5065\u5eb7\u306a\u8449\u3092\u793a\u30595\u756a\u76ee\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5206\u985e\u3059\u308b`**\u3053\u3068","a1c8e33e":"## EDA","1de0a3ad":"#### \u30af\u30e9\u30b9\u306e\u4ef6\u6570","1e627d3e":"### Train\u30c7\u30fc\u30bf\u306e\u8868\u793a"}}