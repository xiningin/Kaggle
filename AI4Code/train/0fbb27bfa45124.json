{"cell_type":{"84b85e6c":"code","e455da41":"code","1823db76":"code","69c4684e":"code","368e1e13":"code","8fcb2d02":"code","1d58bb3e":"code","758c9364":"code","56f846f6":"code","9d4a64a9":"code","4c9371bb":"code","5214b1bf":"code","bc59a2dd":"code","c850ede7":"code","1317e7b7":"code","edb7e2be":"code","34f7952d":"code","19d0bdfb":"code","fa3ee832":"code","b622d7ec":"code","9709adde":"code","a6fec7b4":"code","8f44a206":"code","262bc0d4":"code","84dab5cf":"code","455e8532":"code","6516642f":"code","80eeddff":"code","a30b5df8":"code","d3ba24ee":"code","aca35d47":"code","2b7a8062":"markdown","aae6c039":"markdown","12d30fea":"markdown","076d0f4c":"markdown","ebb761db":"markdown","7ecad237":"markdown"},"source":{"84b85e6c":"import os\nimport glob\nimport pandas as pd\n\nseed = 73\n\narr = []\npath = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/\"\n\nfor strat in os.listdir(path):\n    for label in os.listdir(path+\"\/\"+strat):\n        for image in glob.glob(path+strat+\"\/\"+label+\"\/\"+\"*.png\"):\n            arr.append({\"path\": image, \"label\": label, \"strat\": strat})\n \n \nframe = pd.DataFrame(arr).sample(frac=1, random_state=seed)\nprint('> WithoutMask:', frame.value_counts(\"label\")[0])\nprint('> WithMask:', frame.value_counts(\"label\")[1])\n\nframe","e455da41":"IMG_SIZE = 128\ninput_shape=(IMG_SIZE, IMG_SIZE, 3)","1823db76":"from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\ndatagen = ImageDataGenerator(rescale = 1.\/255,\n                             horizontal_flip=True,\n                             brightness_range=[1.1, 1.3],\n                             rotation_range=30,\n                             #vertical_flip=True,\n                             zoom_range=0.15\n                             )","69c4684e":"def get_generator(frame_):\n    generator = datagen.flow_from_dataframe(\n                          dataframe=frame_,\n                          directory=\"..\/input\", \n                          x_col=\"path\",\n                          y_col=\"label\",\n                          batch_size=64,\n                          seed=seed,\n                          shuffle=False,\n                          class_mode=\"binary\",\n                          target_size=(IMG_SIZE,IMG_SIZE))\n    return generator","368e1e13":"train_df = frame[frame[\"strat\"] == \"Train\"].sample(frac=1, random_state=seed)\ntrain_generator = get_generator(train_df)","8fcb2d02":"valid_df = frame[frame[\"strat\"] == \"Validation\"].sample(frac=1, random_state=seed)\nvalid_generator = get_generator(valid_df)","1d58bb3e":"test_df = frame[frame[\"strat\"] == \"Test\"].sample(frac=1, random_state=seed)\ntest_generator = get_generator(test_df)","758c9364":"from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, add\nfrom tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\n\nfinal_activation = 'sigmoid'\nentropy = 'binary_crossentropy'","56f846f6":"def FCLayers(baseModel):\n    baseModel.trainable = True\n    headModel = baseModel.output\n    \n    headModel = Dense(units=256)(headModel)\n    headModel = BatchNormalization()(headModel)    \n    headModel = Activation('relu')(headModel)\n    headModel = Dropout(0.6, seed=73)(headModel)    \n    \n    headModel = Dense(1, activation=final_activation)(headModel)\n    model = Model(inputs = baseModel.input, outputs = headModel)\n    \n    return model","9d4a64a9":"def separable_conv_block(x, filters, block_num, conv_num, pre_activation=None):\n    name = 'block{}_sepconv{}_'.format(block_num, conv_num)\n\n    if pre_activation is True:\n        x = Activation('relu', name=name+'act')(x)\n\n    x = SeparableConv2D(filters, (3,3), padding='same', use_bias=False, \n                        name=name)(x)\n    \n    x = BatchNormalization(name=name+'bn')(x)\n\n    if pre_activation is False:\n        x = Activation('relu', name=name+'act')(x)\n        \n    return x","4c9371bb":"def middle_flow_block(x, filters, block_num):\n    residual = x\n\n    x = separable_conv_block(x, filters, block_num=block_num, \n                             conv_num='1', pre_activation=True)\n    \n    x = separable_conv_block(x, filters, block_num=block_num, \n                             conv_num='2', pre_activation=True)\n    \n    x = separable_conv_block(x, filters, block_num=block_num, \n                             conv_num='3', pre_activation=True)\n\n    return add([x, residual])","5214b1bf":"def xception_block(x, filters, block_num, pre_activation=True):\n    block = 'block{}_'.format(block_num)\n    filter_conv1, filter_conv2 = filters\n\n    residual = Conv2D(filter_conv2, (1, 1), strides=(2, 2), \n                      padding='same', use_bias=False)(x)\n    \n    residual = BatchNormalization()(residual)\n\n    x = separable_conv_block(x, filter_conv1, block_num=block_num, \n                             conv_num='1', pre_activation=pre_activation)\n    \n    x = separable_conv_block(x, filter_conv2, block_num=block_num, \n                             conv_num='2', pre_activation=True)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name=block+'pool')(x)\n\n    return add([x, residual])","bc59a2dd":"def conv_block(x, filters, block_num, conv_num, strides=(1,1)):\n    name = 'block{}_conv{}_'.format(block_num, conv_num)\n    \n    x = Conv2D(filters, (3,3), strides=strides, use_bias=False, name=name)(x)\n    x = BatchNormalization(name=name+'bn')(x)\n    x = Activation('relu', name=name+'act')(x)\n\n    return x\n\ndef Xception_Model():\n    \n    img_input = Input(shape=input_shape)\n\n    x = conv_block(img_input, 32, block_num='1', \n                   conv_num='1', strides=(2,2))\n    \n    x = conv_block(x, 64, block_num='1', conv_num='2')\n\n    x = xception_block(x, (128, 128), '2', pre_activation=False)\n\n    x = xception_block(x, (256, 256), '3')\n\n    x = xception_block(x, (728, 728), '4')\n\n\n    for i in range(8):\n        block_num = str(5+i)\n        x = middle_flow_block(x, 728, block_num)\n\n    x = xception_block(x, (728, 1024), '13')\n\n    x = separable_conv_block(x, 1536, block_num='14', \n                             conv_num='1', pre_activation=False) \n    \n    x = separable_conv_block(x, 2048, block_num='14',\n                             conv_num='2', pre_activation=False)\n    \n    x = GlobalAveragePooling2D(name='avg_pool')(x)\n    \n    model = Model(inputs=img_input, outputs=x, name='xception')\n\n    model = FCLayers(model)\n    \n    model.summary()\n    return model\n\n\nmodel = Xception_Model()","c850ede7":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nearly_stopping = EarlyStopping(patience = 3, monitor='val_loss',\n                                 mode='min', restore_best_weights=True, \n                                 verbose = 1)\n\nmodel_checkpoints = ModelCheckpoint(\"XceptionModel.h5\", \n                                    save_best_only=True, verbose = 1)\n\n\ncallbacks = [model_checkpoints, early_stopping]","1317e7b7":"model.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n\n\nhistory = model.fit(train_generator,validation_data  = valid_generator, epochs = 50, \n                              steps_per_epoch=(len(train_generator.labels) \/ 80) ,\n                              validation_steps=(len(valid_generator.labels) \/ 80), \n                              callbacks = callbacks)","edb7e2be":"from tensorflow.keras.models import load_model\nmodel = load_model(\"XceptionModel.h5\")","34f7952d":"model.evaluate(test_generator, verbose=1)","19d0bdfb":"predictions = model.predict(test_generator, verbose = 1).round()","fa3ee832":"from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\ntarget_names = ['Has Mask','No Mask']","b622d7ec":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef print_results():\n    print(classification_report(test_generator.labels, predictions, target_names=target_names))\n    plt.figure(figsize = (8,5))\n    sns.heatmap(confusion_matrix(test_generator.labels, predictions), annot = True, \n                fmt=\"d\",cmap = \"Purples\")\n    plt.show()\n    \n    roc_acc = roc_auc_score(test_generator.labels, predictions)\n    print('> ROC Accuracy: {}'.format(roc_acc.round(4)))","9709adde":"print_results()","a6fec7b4":"import cv2\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')\n\ndef getFaces(img):\n    gray_img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    faces = face_model.detectMultiScale(gray_img, scaleFactor=1.1, \n                                        minNeighbors=8)\n    return faces","8f44a206":"import PIL\n\ndef newSize(width, height):\n    if width < 600:\n        return newSize(width * 1.12 , height * 1.12)\n    \n    if width >= 1200:\n        return newSize(width \/ 1.12 , height \/ 1.12)\n        \n    return int(width), int(height)\n        \ndef AdjustSize(f):\n    img = PIL.Image.open(f)\n    width, height = img.size\n    new_width, new_height = newSize(width, height)\n    \n    return (new_width, new_height)        ","262bc0d4":"import numpy as np\n\n\ndef Draw(img, face):\n    (x,y,w,h) = face\n    mask_label = {0:'Has Mask!',1:'No Mask'}\n    label_color = {0: (0,255,0), 1: (255,0,0)}\n    \n    crop = img[y:y+h,x:x+w]\n    \n    crop = cv2.resize(crop,(IMG_SIZE, IMG_SIZE))\n    crop = np.reshape(crop,[1,IMG_SIZE,IMG_SIZE,3]) \/ 255.0\n    \n    mask_result = model.predict(crop)\n            \n    pred_label = round(mask_result[0][0])\n            \n    cv2.putText(img,mask_label[pred_label],\n                (x, y+90), cv2.FONT_HERSHEY_SIMPLEX,\n                0.5, label_color[pred_label], 2)\n            \n    cv2.rectangle(img,(x,y),(x+w,y+h), \n                label_color[pred_label],1)\n    \n    return img","84dab5cf":"from io import BytesIO\nfrom skimage import io\nfrom scipy.spatial import distance\nimport requests\n\nMIN_DISTANCE = 0\n    \ndef MaskDetection(imgUri):    \n    response = requests.get(imgUri)\n    f = BytesIO(response.content)\n    \n    img = io.imread(f)\n    resize = AdjustSize(f)\n    img = cv2.resize(img, resize)\n    faces = getFaces(img)\n    \n    if len(faces)>=1:\n        label = [0 for i in range(len(faces))]\n        \n        for i in range(len(faces)-1):\n            for j in range(i+1, len(faces)):\n                dist = distance.euclidean(faces[i][:2], \n                                          faces[j][:2])\n                if dist < MIN_DISTANCE:\n                    label[i] = 1\n                    label[j] = 1\n                \n        for i in range(len(faces)):\n            Draw(img, faces[i])\n                        \n        plt.figure(figsize=(16,14))\n        plt.imshow(img)\n            \n    else:\n        print(\"No Face!\")","455e8532":"MaskDetection(\"https:\/\/lh3.googleusercontent.com\/xx2yn_8a0rQMqcib1BcZRAnzt70OjX2o8RnaoSx3L-RpgBd229jAAmTfCeRgmDwarCfTsglYWTldswEmsHehJvX2YW8dnKVNXw=w1200-h630-rj-pp-e365\")","6516642f":"MaskDetection(\"https:\/\/images.theconversation.com\/files\/326038\/original\/file-20200407-18916-1p3qplf.jpg?ixlib=rb-1.1.0&rect=17%2C0%2C5734%2C3837&q=45&auto=format&w=926&fit=clip\")","80eeddff":"MaskDetection(\"https:\/\/www.ctvnews.ca\/polopoly_fs\/1.4986740.1592334933!\/httpImage\/image.jpg_gen\/derivatives\/landscape_960\/image.jpg\")","a30b5df8":"MaskDetection(\"https:\/\/specials-images.forbesimg.com\/imageserve\/1227664783\/960x0.jpg?fit=scale\")","d3ba24ee":"MaskDetection(\"https:\/\/media.fromthegrapevine.com\/assets\/images\/2020\/3\/coronavirus-mask-vatican-0302.jpg.824x0_q71_crop-scale.jpg\")","aca35d47":"from IPython.display import FileLink\nFileLink(r'.\/XceptionModel.h5')","2b7a8062":"## **Face detection Model with Haar Cascade**","aae6c039":"## **Xception Model**\n**Reference**: https:\/\/stephan-osterburg.gitbook.io\/coding\/coding\/ml-dl\/tensorfow\/ch3-xception\/implementation-of-xception-model\n\n![](https:\/\/miro.medium.com\/max\/2961\/1*hOcAEj9QzqgBXcwUzmEvSg.png)","12d30fea":"## **Model Training**","076d0f4c":"## **Model Evaluation**","ebb761db":"## **Data preprocessing**","7ecad237":"## **References and Credit : https:\/\/www.kaggle.com\/sahintiryaki\/face-mask-detection**"}}