{"cell_type":{"5cf6345a":"code","971d1d5c":"code","aa39c36b":"code","e80c6296":"code","3e9e0a59":"code","1277c69b":"code","514c6264":"code","8ec8f9cd":"code","11aa8301":"code","3f10ba7a":"code","d081d362":"code","82bc8a5b":"code","dad72e17":"code","66ab1345":"code","b5543419":"code","0a9ad86f":"code","c2e0e303":"markdown","7ccc21bd":"markdown","dc283044":"markdown","0767bacb":"markdown","e0a78d5e":"markdown","3120c833":"markdown"},"source":{"5cf6345a":"!pip install python-box timm pytorch-lightning==1.4.0 ","971d1d5c":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\nwarnings.filterwarnings(\"ignore\")","aa39c36b":"torch.autograd.set_detect_anomaly(True)\nseed_everything(2021)\n\ntrain = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntrain[\"Id\"] = train[\"Id\"].apply(lambda x: '\/kaggle\/input\/petfinder-pawpularity-score\/train\/'+ x + \".jpg\")\n\ntest = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\ntest[\"Id\"] = test[\"Id\"].apply(lambda x: '\/kaggle\/input\/petfinder-pawpularity-score\/test\/'+ x + \".jpg\")","e80c6296":"train.shape","3e9e0a59":"train.info()","1277c69b":"len(train[train.duplicated()])","514c6264":"print('Min = ',train.Pawpularity.min())\nprint('Max = ', train.Pawpularity.max())","8ec8f9cd":"for col in train.columns[1:-1] :\n    plt.figure(figsize = (10, 5))\n    sns.countplot(x = col, data = train)","11aa8301":"for col in train.columns[1:-1] :\n    v1 = train[col].value_counts().index[0]\n    v2 = train[col].value_counts().index[1]\n    val1 = train[train[col] == v1]\n    val2 = train[train[col] == v2]\n    plt.figure(figsize = (10, 5))\n    sns.histplot(val1.Pawpularity, label = v1, color = 'green')\n    sns.histplot(val2.Pawpularity, label = v2, color = 'pink')\n    plt.title(col)\n    plt.legend()","3f10ba7a":"for col in train.columns[1:-1] :\n    plt.figure()\n    sns.violinplot(y = 'Pawpularity', x = col, data = train)\n    plt.title(col)","d081d362":"config = {'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms'\n          },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)","82bc8a5b":"class PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        label = self._y[idx]\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image","dad72e17":"class PetfinderDataModule(LightningDataModule):\n    def __init__(self, train_df, val_df):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n\n    def __create_dataset(self, train=True):\n        return (\n            PetfinderDataset(self._train_df, 224)\n            if train\n            else PetfinderDataset(self._val_df, 224)\n        )\n    \n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, \n              batch_size= 64,\n              shuffle= True,\n              num_workers= 4,\n              pin_memory= False,\n              drop_last= True)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, \n              batch_size= 64,\n              shuffle=False,\n              num_workers= 4,\n              pin_memory= False,\n              drop_last= False)\n","66ab1345":"# augmentation\ndef get_default_transforms():\n    transform = T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ]\n        )\n    return transform","b5543419":"class Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() \/ 100.0\n        images = self.transform(images)\n        \n        logits = self.forward(images).squeeze(1)\n        loss = self._criterion(logits, labels)\n        \n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')    \n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n\n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optimizer.name)(\n            self.parameters(), **self.cfg.optimizer.params\n        )\n        scheduler = eval(self.cfg.scheduler.name)(\n            optimizer,\n            **self.cfg.scheduler.params\n        )\n        return [optimizer], [scheduler]","0a9ad86f":"skf = StratifiedKFold(\n    n_splits=5, shuffle=True, random_state=2021\n)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train[\"Id\"], train[\"Pawpularity\"])):\n    train_df = train.loc[train_idx].reset_index(drop=True)\n    val_df = train.loc[val_idx].reset_index(drop=True)\n    datamodule = PetfinderDataModule(train_df, val_df)\n    model = Model(config)\n    earystopping = EarlyStopping(monitor=\"val_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        filename=\"best_loss\",\n        monitor=\"val_loss\",\n        save_top_k=1,\n        mode=\"min\",\n        save_last=False,\n    )\n    logger = TensorBoardLogger(config.model.name)\n    \n    trainer = pl.Trainer(\n        logger=logger,\n        max_epochs=2,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n        **config.trainer,\n    )\n    trainer.fit(model, datamodule=datamodule)","c2e0e303":"## Dataset Class :","7ccc21bd":"## Import Libraries \/ Load Data :","dc283044":"We recognize that there are no significant differences between the distributions over the values of a column! Which means our tabular data (metadata) will not bring value to our model, so we decide to ignore it during this competition.\n\nLet's work just on images to extract meaningfull insights from it ;)","0767bacb":"## config","e0a78d5e":"## EDA on Tabular Data \/ Value Check :","3120c833":"## Modeling and Trainig : "}}