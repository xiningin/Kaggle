{"cell_type":{"bb1ddf1b":"code","df403930":"code","fa1883ba":"code","7684c68f":"code","936b4db0":"code","ca3b02b6":"code","b47d46c6":"code","a5e32adb":"code","c6ea31ba":"code","1a318661":"code","fd95901a":"code","3da591c3":"code","887e8e6d":"code","17c65d18":"code","7724dae4":"code","66e397c4":"code","f5fdfdb4":"code","fa16ce69":"code","e4956968":"code","45cdaf41":"code","8432934d":"code","f09191e9":"code","d12b7e2d":"code","299d5b12":"code","84a4b94a":"code","706514e4":"code","44e1e1a4":"markdown","19899da5":"markdown","00514345":"markdown","37bbb288":"markdown","c7b505b6":"markdown","3d18e534":"markdown","3f5266c1":"markdown","4c3f9093":"markdown","cceab6e7":"markdown","b0ae4469":"markdown","d70cae4d":"markdown","ca6b7b2e":"markdown","a70b3580":"markdown","1c0dfa67":"markdown","8cdd4c0a":"markdown","d30f47eb":"markdown"},"source":{"bb1ddf1b":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout ,Flatten, Conv2D , MaxPool2D\nfrom keras.utils import to_categorical\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","df403930":"train_dataset=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntrain_dataset.head()","fa1883ba":"x=train_dataset.drop([\"label\"],axis=1).values.reshape(42000,28,28,1)\ny=train_dataset.label.values.reshape(-1,1)","7684c68f":"print(\"x shape :\",x.shape)\nprint(\"y shape :\",y.shape)","936b4db0":"img=train_dataset.iloc[0,1:].values\nimg_size=28\nplt.imshow(img.reshape(img_size,img_size))\nplt.axis(\"off\")\nplt.title(train_dataset.iloc[0,0])\nplt.show()","ca3b02b6":"sns.countplot(train_dataset.label)\nplt.xlabel(\"numbers\")\nplt.ylabel(\"count\")\nplt.show()","b47d46c6":"y=to_categorical(y,num_classes=10)\nprint(\"new y shape :\",y.shape)","a5e32adb":"x=x\/255.0","c6ea31ba":"x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.1,random_state=2)\nprint(\"x_train shape :\",x_train.shape)\nprint(\"x_val shape :\",x_val.shape)\nprint(\"y_train shape :\",y_train.shape)\nprint(\"y_val shape :\",y_val.shape)","1a318661":"model = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","fd95901a":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","3da591c3":"datagen = ImageDataGenerator(\n        rotation_range=0.01,  \n        zoom_range = 0.01, \n        width_shift_range=0.5,  \n        height_shift_range=0.5, \n        ) \n\ndatagen.fit(x_train)","887e8e6d":"epochs=100\nbatch_size=250","17c65d18":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val), steps_per_epoch=x_train.shape[0] \/\/ batch_size)","7724dae4":"print(history.history.keys())","66e397c4":"plt.figure(figsize=(10,10))\nplt.plot(history.history[\"loss\"],color=\"green\",label=\"Train Loss\")\nplt.plot(history.history[\"val_loss\"],color=\"blue\",label=\"Val Loss\")\nplt.legend()\nplt.title(\"Train and Validation Loss Plot\")\nplt.show()","f5fdfdb4":"plt.figure(figsize=(10,10))\nplt.plot(history.history[\"accuracy\"],color=\"red\",label=\"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"],color=\"cyan\",label=\"Val Accuracy\")\nplt.legend()\nplt.title(\"Train and Validation Accuracy Plot\")\nplt.show()","fa16ce69":"y_prediction=model.predict(x_val)","e4956968":"y_prediction_int=np.argmax(y_prediction,axis=1)\ny_true=np.argmax(y_val,axis=1)","45cdaf41":"print(\"y prediction int shape :\",y_prediction_int.shape)\nprint(\"y true shape :\",y_true.shape)","8432934d":"y_prediction_int","f09191e9":"cfm=confusion_matrix(y_true,y_prediction_int)","d12b7e2d":"f,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(cfm,annot=True,cmap=\"coolwarm\",linewidths=1,linecolor=\"black\",fmt=\".1f\",ax=ax)\nplt.title(\"Evaluation Error Plot\")\nplt.show()","299d5b12":"prediction=model.predict(x_val[1].reshape(1,28,28,1))","84a4b94a":"prediction=np.argmax(prediction,axis=1)\nprediction","706514e4":"y_val[1]","44e1e1a4":"### I observed the labels and I took the answers.\n### How many have different numbers the data and what are theirs frequency","19899da5":"### I got train accuracy %80 and val accuracy %97 above.","00514345":"### I determined some parameters","37bbb288":"### I started to work my model","c7b505b6":"###                                  Prediction Images","3d18e534":"### I showed an image for having knowledge about the data","3f5266c1":"### I categorized my label data","4c3f9093":"### I observed x and y variables' shapes","cceab6e7":"### I imported necessary libraries ","b0ae4469":"### I loaded train.csv dataset into train_dataset variable","d70cae4d":"### I created new images here thanks to Data Augmentation","ca6b7b2e":"### I reserved as train and validation dataset","a70b3580":"### I normalized my features beacuse the machine learn better than old","1c0dfa67":"### I created my model here","8cdd4c0a":"### I compiled my model ","d30f47eb":"### I seperated the data as images' features and their labels and I reshaped four dimension the features for learning the machine"}}