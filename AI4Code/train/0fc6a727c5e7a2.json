{"cell_type":{"eecf6398":"code","afdf1bcf":"code","0009883c":"code","0bc60a13":"code","0bb63a77":"code","e55566a1":"code","fd1bf3c8":"code","8071174f":"code","6d2002e6":"code","4ebe49a4":"code","0b1485b0":"code","6f6fe1c2":"code","cf06fdf7":"code","255a66d3":"code","bccbb908":"code","0ff186dc":"code","cfce7485":"code","c5352be4":"markdown","cb7220c0":"markdown","52ba347c":"markdown","325526a8":"markdown","a9efc19e":"markdown","acfce2f1":"markdown","e3dfbe80":"markdown","e5162a88":"markdown","f80d60c9":"markdown","ff3c2a1a":"markdown","cd684882":"markdown","22e85c94":"markdown","e0f7c8bd":"markdown","14c65325":"markdown","e57ce809":"markdown","48d6cc24":"markdown","26f20acc":"markdown","42c5c6e4":"markdown","54db8864":"markdown","7747474b":"markdown","b822533a":"markdown","721a3362":"markdown","af5528ab":"markdown","7b4b7722":"markdown","6030637b":"markdown"},"source":{"eecf6398":"import os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pathname = os.path.join(dirname, filename)\n        print(f\"{pathname}\\t{os.path.getsize(pathname)\/\/1024\/1024:.3f} MB\")","afdf1bcf":"import pandas as pd\n\nTRAIN_FILE = '\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv'\nTEST_FILE = '\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv'\n\ntrain = pd.read_csv(TRAIN_FILE)\ntest = pd.read_csv(TEST_FILE)","0009883c":"train.head()","0bc60a13":"from matplotlib import pyplot as plt\n\nTEXT_LABELS = [\n    't-shirt',\n    'trouser',\n    'pullover',\n    'dress',\n    'coat',\n    'sandal',\n    'shirt',\n    'sneaker',\n    'bag',\n    'ankle boot'\n]\nIMG_WIDTH=28\nIMG_HEIGHT=28\n\ndef plot_images(X, y, y_predicted=None, img_width=IMG_WIDTH, img_height=IMG_HEIGHT, ncols=4, figsize=None):\n    \"\"\"Plot a set of images along with their labels.\n    \n    Keyword arguments:\n    X -- A set of images to be plotted\n    y -- The labels of the images\n    y_predicted -- If specified, displays another label for the prediction.\n                   This will be used toward the end of this notebook when\n                   we start using the trained network to make predictions.\n    img_width -- The width of each image. Default to 28, the width of images in the dataset.\n    img_height -- The height of each image. Default to 28, the height of images in the dataset.\n    ncols -- The number of images to display in each row of the grid. Default to 4.\n    figsize -- The overall size of the grid. Leave None for auto calculation.\n    \n    \"\"\"\n    # Find the number of images to be plotted.\n    image_count = X.shape[0]\n    nrows = (image_count + ncols - 1) \/\/ ncols\n\n    MAX_IMAGE_COUNT = 30\n    if image_count > MAX_IMAGE_COUNT:\n        raise ValueError(f\"Trying to plot too many images. The maximum is {MAX_IMAGE_COUNT}\")\n    \n    MAX_NCOLS = 5\n    if ncols > MAX_NCOLS:\n        raise ValueError(f\"Too many column. The maximum is {MAX_NCOLS}\")    \n\n    if figsize is None:\n        figsize = (ncols*4, nrows*5) # for each row, we leave space for the text\n\n    if y_predicted is None:\n        y_predicted = [None] * len(y)\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, squeeze=False)\n    for ax, image, label, predicted_label in zip(axes.reshape(-1), X.reshape(-1, img_height, img_width), y, y_predicted):\n        ax.imshow(image, cmap='gray')\n        if predicted_label is not None:\n            ax.set_title(\"Real: %s\\nPrediction: %s\" % (\n                TEXT_LABELS[label], TEXT_LABELS[predicted_label]))\n        else:\n            ax.set_title(TEXT_LABELS[label])\n        ax.title.set_fontsize(20)\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    # Turn off unused subplots at the end.\n    for ax in axes.reshape(-1)[image_count:]:\n        ax.axis('off')\n    plt.show()\n\nsample_count = 12\nX_sample = train.iloc[0:sample_count,1:].to_numpy()\ny_sample = train.iloc[0:sample_count,0].to_numpy()\nplot_images(X_sample, y_sample)\n","0bb63a77":"train_mean = (train.iloc[:, 1:]\/255).mean().mean()\ntrain_std = (train.iloc[:, 1:]\/255).std().std()\n(train_mean, train_std)","e55566a1":"from mxnet import nd as nd\n\nX_train = nd.array(train.iloc[:, 1:].to_numpy().reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)) # gray scale image, so just one channel\ny_train = nd.array(train.iloc[:,0].to_numpy())\ntype(X_train), X_train.shape, type(y_train), y_train.shape","fd1bf3c8":"X_test = nd.array(test.iloc[:, 1:].to_numpy().reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)) # gray scale image, so just one channel\ny_test = nd.array(test.iloc[:, 0].to_numpy())\ntype(X_test), X_test.shape, type(y_test), y_test.shape","8071174f":"from mxnet.gluon.data.vision import transforms\n\ndef create_transformer():\n    # Create a transformer that tensorize and normalize the images.\n    tensorize = transforms.ToTensor()\n    normalize = transforms.Normalize(train_mean, train_std)\n    return transforms.Compose([tensorize, normalize])\n\n# Let's try the transformer out.\ntrans = create_transformer()\ntrans(X_train[0])","6d2002e6":"from mxnet.gluon.data import ArrayDataset, DataLoader\nimport mxnet.gluon\nfrom mxnet import gpu, cpu\n\nctx = gpu() # This context will be used later. It tells MXNet to use\n            # the GPU instead of the CPU to achieve faster training\n            # and prediction time.\n\nBATCH_SIZE = 100\n# Use the transformer above to transform the images to the format required by LeNet.\n# Notice that our dataset is a zipping of the images and their labels, since later on\n# during training, we need to give the neural network a set of images to train on\n# along with their labels.\n# Also notice the transform is only applied to the image; notice the use of\n# transform_first() method instead of transform().\ntrain_loader = DataLoader(ArrayDataset(list(zip(X_train, y_train))).transform_first(trans),\n                          BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(ArrayDataset(list(zip(X_test, y_test))).transform_first(trans),\n                         BATCH_SIZE, shuffle=True)","4ebe49a4":"for batch in train_loader:\n    print(batch)\n    break","0b1485b0":"import mxnet as mx\nfrom mxnet.gluon import nn, HybridBlock\n\nclass LeNet(HybridBlock):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        with self.name_scope():\n            self.conv1 = nn.Conv2D(channels=6, kernel_size=5, activation='relu')\n            self.pool1 = nn.MaxPool2D(pool_size=2, strides=2)\n            self.conv2 = nn.Conv2D(channels=16, kernel_size=3, activation='relu')\n            self.pool2 =  nn.MaxPool2D(pool_size=2, strides=2)\n            self.hidden1 = nn.Dense(120, activation='relu')\n            self.hidden2 = nn.Dense(84, activation='relu')\n            self.out = nn.Dense(10)\n    \n    def hybrid_forward(self, F, x):\n        x = self.conv1(x)\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = self.pool2(x)\n        x = x.reshape((0, -1))\n        x = self.hidden1(x)\n        x = self.hidden2(x)\n        x = self.out(x)\n        return x\n        \n\nnet = LeNet()\nnet.initialize(mx.init.Xavier())\nnet.hybridize()\nnet","6f6fe1c2":"from datetime import datetime\nfrom mxnet import gluon, autograd\n\ndef accuracy(output, label):\n    # output: (batch, num_output) float32 ndarray\n    # label: (batch, ) int32 ndarray\n    acc = (output.argmax(axis=1) == label.astype('float32'))\n    return acc.mean().asscalar()\n\ndef train_lenet(iters = 7, learning_rate = 0.1, ctx=ctx):\n    net = LeNet()\n    net.initialize(mx.init.Xavier(), ctx=ctx)\n    net.hybridize()\n\n    losses, train_accuracies, test_accuracies = [], [], []\n\n    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n    trainer = gluon.Trainer(net.collect_params(), 'sgd',\n                            {'learning_rate': learning_rate})\n\n    X_train_trans = trans(X_train).as_in_context(ctx)\n    X_test_trans = trans(X_test).as_in_context(ctx)\n    \n    print(\"N | Elapsed Time   | Loss  | Training | Test\")\n    print(\"----------------------------------------------\")\n    start_time = datetime.now()\n    for i in range(iters):\n        for _, (X, y) in enumerate(train_loader):\n            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                y_hat = net(X)\n                loss = loss_fn(y_hat, y)\n            loss.backward()\n            trainer.step(X.shape[0])\n\n        # TODO: do this in batches to avoid loading a huge amount\n        # of data into the GPU and potentially running out of\n        # GPU memory\n        y_hat_train = net(X_train_trans)\n        y_hat_test = net(X_test_trans)\n        # TODO: Avoid repeatedly calling as_in_context().\n        loss = nd.mean(loss_fn(y_hat_train, y_train.as_in_context(ctx))).asscalar()\n        train_accuracy = accuracy(y_hat_train, y_train.as_in_context(ctx))\n        test_accuracy = accuracy(y_hat_test, y_test.as_in_context(ctx))\n        print(\" | \".join([f\"{i+1}\",\n                          str(datetime.now() - start_time),\n                          f\"{loss:.3f}\",\n                          f\"{train_accuracy*100:.2f}%  \",\n                          f\"{test_accuracy*100:.2f}%\"]))\n        losses.append(loss)\n        train_accuracies.append(train_accuracy)\n        test_accuracies.append(test_accuracy)\n    return net, losses, train_accuracies, test_accuracies\n","cf06fdf7":"net, losses, train_accuracies, test_accuracies = train_lenet(ctx=gpu())","255a66d3":"def plot_stuff(losses, train_accuracies, test_accuracies):\n    plt.figure(num=None,figsize=(8, 6))\n    plt.plot(losses)\n    plt.xlabel('Epoch',fontsize=14)\n    plt.ylabel('Mean loss',fontsize=14)\n\n    plt.figure(num=None,figsize=(8, 6))\n    plt.plot(range(len(train_accuracies)), train_accuracies, range(len(test_accuracies)), test_accuracies)\n    plt.xlabel('Epoch',fontsize=14)\n    plt.ylabel('Accuracy',fontsize=14)\n    plt.legend(['train accuracy', 'test accuracy'])\n    plt.ylim([0, 1])\n    \nplot_stuff(losses, train_accuracies, test_accuracies)","bccbb908":"# The following values were randomly generated and then hard coded \n# to ensure that the same samples are used regardless of the\n# machine configuration.\nrandom_samples = [1787,\n    6944,\n    3792,\n    5969,\n    1244,\n    7577,\n    596,\n    786,\n    3548,\n    2195,\n    4346,\n    6370,\n    3817,\n    3603,\n    1239,\n    1106,\n    6058,\n    328,\n    5325,\n    8843]\nsample_size = len(random_samples)\n\nX_test_sample = X_test[random_samples]\ny_test_sample = y_test.astype('int32')[random_samples]\ny_test_sample_prediction = net(trans(X_test_sample).as_in_context(ctx)).asnumpy().argmax(axis=1)\n\nplot_images(X_test_sample.asnumpy(),\n            y_test_sample.asnumpy(),\n            y_test_sample_prediction)\n","0ff186dc":"net, losses, train_accuracies, test_accuracies = train_lenet(iters=20, ctx=gpu())","cfce7485":"plot_stuff(losses, train_accuracies, test_accuracies)","c5352be4":"# Dataset Preprocessing\n\nBefore we can use the dataset to train a neural network, we need to do some preprocessing. In particular, we need to do the following:\n\n1. tensorize the input, meaning convert images from a matrix of dimensions `H x W`, with each value between 0 and 255, to a tensor of the form `C x H x W` (`C=1` here, since there is one channel). This is a requirement for the LeNet network.\n2. normalize the color values according to the mean and standard deviation found above. This is a typical step in every Machine Learning preprocessing to put the values in scale.","cb7220c0":"# Creating a Dataset Loader\n\nNow let's create a batch data loader so we can use it to fetch the training data into the neural network. For the kind of dataset we are dealing with in this notebook which is very small, this is probably an unnecessary step, because we simply loaded the whole dataset into the memory and we could also easily load it into the GPU memory. However, for much larger datasets, it is generally not easy to load all the data into the GPU memory or even the CPU memory (assuming it is larger than the GPU memory), so it is good to get into the habit of processing datasets in batches:","52ba347c":"As we can see, the neural network got 18 out of 20 images right, which is what we should expect from the 89% achieved test accuracy. It seems that the mismatch is mostly around identifying a t-shirt or a pullover as a short, which is even difficult for a human being for such a small-sized images. In fact, according to the [benchmark](https:\/\/github.com\/zalandoresearch\/fashion-mnist) in Fashion MNIST dataset on GitHub, a crowd-soured evaluation of human with no fashion expertise achieved only 83.5% accuracy.","325526a8":"# Training a LeNet Network\n\nFor this dataset, we will be training a LeNet-5 dataset which was designed by Lecun et al. in 1998 (see References section below). I won't go into the details of this neural network; the reader is encouraged to read about the network if he or she is not familiar with it.","a9efc19e":"Let's do the same with the testing data:","acfce2f1":"Let's see how the data looks like:","e3dfbe80":"The Fashion MNIST dataset is available as a Kaggle dataset: [Fashion MNIST](https:\/\/www.kaggle.com\/zalando-research\/fashionmnist). It is already added as a dependency of this notebook, so let's walk the input directory to see the available files:","e5162a88":"As we can see from the table above, even though the training accuracy increased, the test accuracy is not going much beyond what we achieved earlier with less number of iterations, suggesting with more iterations we are only over-training the network which might not be desirable. Let's plot the graphs from this training:","f80d60c9":"The test accuracy is pretty good, so we can go ahead and use the network to make predictions.","ff3c2a1a":"Having trained the network, let's plot the retrieved loss function, training accuracies, and testing accuracies:","cd684882":"# Introduction\n\nIn this notebook, I will train a LeNet neural network on the Fashion MNIST dataset. Fashion MNIST dataset is similar to MNIST in nature, but the goal is to classify images of cloths instead of numbers, hence \"Fashion\" MNIST. The goal of the dataset is to offer a replacement for MNIST since the latter is well known to be easy to crack even using simple Machine Learning algorithms on even using traditional Machine Learning techniques (99% accuracy is normal). More information about the dataset can be found in [this Github repository](https:\/\/github.com\/zalandoresearch\/fashion-mnist) and [the paper](https:\/\/arxiv.org\/abs\/1708.07747) by Xiao et al., the author of the dataset.","22e85c94":"Let's try out the data loader to make sure it produces the expected results:","e0f7c8bd":"As can be seen easily from this graph, after some point, the training accuracy is increasing but the test accuracy is almost fixed, hence we will not benefit much from increasing the number of iterations.","14c65325":"# Loading the Dataset","e57ce809":"# Using the Network\n\nLet's try the network we just trained on the test data. We will select a use a sample of 20 random images and use the network to predict what the images contain.","48d6cc24":"# Can We Achieve Better Accuracy With More Training Iterations","26f20acc":"# Mean and Standard Deviation of the Images\n\nBefore we start training a neural network on these images, let's try to generate some stats about them. To be specific, we need to find the mean and standard deviation across all images. These statistical values will be needed in the processing step to normalize the images before starting the training.","42c5c6e4":"If you go through the output above, you will notice that it is a tuple of `<NDArray 100x1x28x28 @cpu(0)>` and `<NDArray 100x1 @cpu(0)>]`. The first is a 100-image batch in the form `C x H x W` and the second is a 100-label batch. This is indeed what we need for the training, so we are ready to start the training now.","54db8864":"# Creating MXNet's NDArrays\n\nMXNet has its own version of NumPy's arrays called NDArray. They are very similar, though the latter misses some of the features that NumPy provides. Why do we use them if they have less features? Well, because they have an extra feature which is essential for deep learning, which is the ability to put the array in the GPU for faster processing. In the code below, we are going to generate NDArrays for the training and testing data:","7747474b":"# References\n* Fashion MNIST dataset on GitHub: https:\/\/github.com\/zalandoresearch\/fashion-mnist\n* Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11): 2278\u20132324, 1998.\n* H. Xiao, K. Rasul, R. Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms","b822533a":"As we can see, the first column is the label of the picture, while each of the rest columns represent one pixel in the image. Fashion MNIST dataset is in gray scale hence why there is one channel by pixel. \n\nLet's display the first few images:","721a3362":"As we can see, the training and test data are pretty small, so we can load everything into the memory. Notice that MXNet offers a [functionality](https:\/\/mxnet.apache.org\/api\/python\/docs\/api\/gluon\/data\/vision\/datasets\/index.html) to load this dataset as part of its `vision.datasets` namespace. However, I am loading it manually using `pandas` to understand the loading process thoroughly. If you want to use the MXNet provided dataset instead, you can try the following:\n\n```Python\ntrain = gluon.data.vision.FashionMNIST(train=True)\ntest = gluon.data.vision.FashionMNIST(train=False)\n```\n\nObviously, the return value is not a `pandas` DataFrame so you will have to make the required changes accordingly.","af5528ab":"Now let's start the training:","7b4b7722":"In the training above, we only did 7 iterations and we managed to achieve around 89% accuracy. A question that arises is can we achieve better than that with more training iterations? Let's try that:","6030637b":"A few notes about the code above:\n\n* There are multiple hard-coded values, like the number of channels, kernel size, etc. These are all dictated by the architecture of LeNet, for which you are encouraged to read the 1998 paper by LeCun et al. (see References section).\n* The network's weights are initialized using [Xavier](https:\/\/beta.mxnet.io\/api\/gluon-related\/_autogen\/mxnet.initializer.Xavier.html) initialization.\n* Notice the call to `hybridize()` method. This is a feature of MXNet to improve performance. More on this [here](https:\/\/beta.mxnet.io\/guide\/packages\/gluon\/hybridize.html)."}}