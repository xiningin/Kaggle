{"cell_type":{"9901a7b9":"code","9865cbf9":"code","dc5d8f47":"code","c586ab84":"code","756ac049":"code","51add94a":"code","acdeaa1f":"code","ed579794":"code","934fbd34":"code","c0cbc55e":"code","9256b5ee":"code","2aaac6a3":"code","e8845cf9":"markdown","098c53e6":"markdown","78a90b88":"markdown","17ee5637":"markdown","31ba2aee":"markdown","b1e944af":"markdown","2f173b61":"markdown","ddeca412":"markdown","9d4ff486":"markdown","4f5c13f7":"markdown","6afa899d":"markdown","0748e421":"markdown","296a8c7a":"markdown","9c77bd3c":"markdown","fe0d4dd6":"markdown","d7b2a364":"markdown","92a034f4":"markdown","da3835e9":"markdown","afe80aee":"markdown","5ae8d00c":"markdown","01adce16":"markdown"},"source":{"9901a7b9":"#import panda library to be able to load the dataset\nimport pandas as pd\n#read the dataset\ndata=pd.read_csv('https:\/\/raw.githubusercontent.com\/Omarsawan\/Feature-construction-and-Categorical-features-tutorial\/master\/data\/ks-projects-201801.csv',parse_dates=['deadline', 'launched'], encoding='latin-1')\n#show the first 7 rows\ndata.head(7)","9865cbf9":"#make a data series with index equal to the column name and the value of the index is whether this column is of type object\nindicesObjects=(data.dtypes=='object')\n#make a data series with index equal to the column name and the value of the index is whether this column is of type datetime\nindicesDate=(data.dtypes=='datetime64[ns]')\n\n#make a data series with columns that have true only\nobjectColumns=indicesObjects[indicesObjects]\ndateColumns=indicesDate[indicesDate]\n\n#show only the index (which is the column name of categorical features)\nobjectsList=list(objectColumns.index)\ndatetimeList=list(dateColumns.index)\n\ncategoricalFeatures=(objectsList+datetimeList)\n\nprint('Columns with data type object: ',objectsList)\nprint('Columns with data type datetime: ',datetimeList)\nprint('Categorical features are',categoricalFeatures)\nprint('Count of Categorical features is',len(categoricalFeatures))","dc5d8f47":"dropCategorical=data.select_dtypes(exclude='object').select_dtypes(exclude='datetime64[ns]')\ndropCategorical.head(7)","c586ab84":"from sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabel_data = data.copy()\n\n# Apply label encoder to column 'name'\nlabel_encoder = LabelEncoder()\nlabel_data['name'] = label_encoder.fit_transform(label_data['name'])\nlabel_data.head(7)","756ac049":"#lets count the number of unique values in each column\nuniqueCount ={}\nfor col in categoricalFeatures:\n    curCol=data.filter([col]).iloc[:,0]\n    uniqueCount[col]=len(curCol.unique())\nprint(uniqueCount)","51add94a":"from sklearn.preprocessing import OneHotEncoder\n\ncols=['state','currency']\n\n# Make copy to avoid changing original data \nOH_data = data.copy()\n\n# Apply one-hot encoder to the columns we have choosen\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(OH_data[cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols.index = OH_data.index\n\n# Remove categorical columns (will be replaced with one-hot encoding)\nnum_X = OH_data.drop(cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X = pd.concat([num_X, OH_cols], axis=1)\n\nOH_X.head(7)","acdeaa1f":"# Make copy to avoid changing original data \ndata_copy = data.copy()\n\n#add the four columns\ndata_copy=data_copy.assign(hour=data_copy.launched.dt.hour,\n                           day=data_copy.launched.dt.day,\n                           month=data_copy.launched.dt.month,\n                           year=data_copy.launched.dt.year)\n#remove the launched column\ndata_copy=data_copy.drop(['launched'], axis=1)\n\ndata_copy.head(7)","ed579794":"# Make copy to avoid changing original data \ndata_copy = data.copy()\n#make new feature\ninteractions = data['category'] + \"_\" + data['country']\n#give this new column a name\ninteractions.name='category-country'\n#add the column to the data\ndataInteraction=pd.concat([interactions, data_copy], axis=1)\n\n#remove the category and country columns\ndataInteraction=dataInteraction.drop(['category','country'], axis=1)\n\ndataInteraction.head(7)","934fbd34":"# First, create a Series with a timestamp index and the values in the series are the original index of rows\n# then sort it by the timestamp index\nlaunched = pd.Series(data.index, index=data.launched, name=\"count_last_week\").sort_index()\nlaunched.head(20)","c0cbc55e":"count_last_week = launched.rolling('7d').count() - 1\ncount_last_week.head(20)","9256b5ee":"#now that we have the counts, we need to adjust the index so we can join it with the other training data.\ncount_last_week.index = launched.values\ncount_last_week = count_last_week.reindex(data.index)\ncount_last_week.head(20)","2aaac6a3":"#now join the new feature with the other data again using .join since we've matched the index.\ndata.join(count_last_week).head(10)","e8845cf9":"Scikit-learn has a LabelEncoder class that can be used to get label encodings. We apply the label encoder separately to each column.","098c53e6":"### 3 - One-Hot Encoding\n\nThe third approach is to use One-Hot Encoding , it creates new columns indicating the presence (or absence) of each possible value in the original data. \nFor example if we have a column color which has only 3 categories : (RED,YELLOW,BLUE) , it converts it into 3 columns and if some row has the value 'RED' , then its encoding will be (1,0,0) , and if another row has the value 'YELLOW' then its encoding will be (0,1,0).\nSo  the corresponding one-hot encoding contains one column for each possible value, and one row for each row in the original dataset .\n\nIn contrast to label encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). So this method can work with nominal and ordinal variables.\n\nOne-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values).\n","78a90b88":"### 1 - Dropping features\n\nThe first and easiest approach is to just remove this variables from the data set .This approach will only work well if the columns did not contain useful information.","17ee5637":"### 2 - Label encoding\n\nThe second approach is Label encoding ,it assigns each unique value to a different integer.\nThis approach assumes that the features that will be encoded are ordinal features.\nThis assumption makes sense in some examples but other examples may not make sense , in our data set we can see that column 'name' caould be considered ordinal feature if we want to consider the values in lexicographically order . But the other features are nominal features so this method isn't suitable to encode them . So we will encode only column 'name' .","31ba2aee":"### 2 - Nominal features\n\nThey are features which has values that fall into some categories but also can't be ordered or there is no relative order between the categories , like asking about car brands , and the possible categories are \"HONDA\" , \"FORD\" , \"TOYOTA\" , they fall into categories but we can't order them as they don't have an intrinsic ranking.","b1e944af":"So lets make one hot encoding only in columns state and currency to be able to visualize them.","2f173b61":"# Feature construction\n\nCreating new features from the raw data is one of the best ways to improve your model , it can be done with the encoding methods which we introduced two of them and also can be done through different methods.","ddeca412":"The world is filled with categorical data. You will be a much more effective data scientist if you know how to use this common data type!","9d4ff486":"# Introduction\n\nIn this tutorial , We are going to talk about categorical features and using original features of the data set to construct new features. Often in a data set, the given set of features in their raw form do not provide enough, or the most optimal, information to train a good performant model. In some cases model performance may be improved if we transform one or more features into a different representation to provide better information to the model , this is known as feature construction .","4f5c13f7":"Lets consider our column 'launched' which is of timedate type , so instead of encoding it using different encoding methods , we can simply replace it with 4 columns which are the hour , day , month , year .","6afa899d":"So we can consider that categorical features are features with data type equal to object or date since we know that these data types don't have continuous values .","0748e421":"Using a time series as the index allows us to define the rolling window size in terms of hours, days, weeks , you can use .rolling() to select time periods as the window. For example launched.rolling('7d') creates a rolling window that contains all the data in the previous 7 days. The window contains the current record, so if we want to count all the previous projects but not the current one, we'll need to subtract 1.","296a8c7a":"# Types of categorical features\n\nWe can classify the categorical features into two types , ordinal features and nominal features .","9c77bd3c":"# Examples\n\nFirst I will import the data set to show examples about categorical features .\nOur dataset is a collections of some information about projects that are launched at specific date , at specific category and other features to predict the state of the project if it succeeded or failed or something else .","fe0d4dd6":"# Categorical features\n\nA categorical feature takes only a limited number of values , it doesn't have continous values .A categorical variable can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group or category. \nConsider a survey that asks how often you eat breakfast and provides four options: \"Never\", \"Rarely\", \"Most days\", or \"Every day\". In this case, the data is categorical, because responses fall into a fixed set of categories.\nIf people responded to a survey about which brand of car they owned, the responses would fall into categories like \"Honda\", \"Toyota\", and \"Ford\". In this case, the data is also categorical.","d7b2a364":"# Approaches to handle categorical features\n\nYou will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first.So there are many approaches that you can use to prepare your categorical data .","92a034f4":"So we can say that our dataset has 8 categorical features .","da3835e9":"Now we constructed a new feature .","afe80aee":"One of the easiest ways to create new features is by combining categorical variables. For example, if one record has the country \"CA\" and category \"Music\", you can create a new value \"CA_Music\". This is a new categorical feature that can provide information about correlations between categorical variables. This type of feature is typically called an interaction.\nIn general, you would build interaction features from all pairs of categorical features. You can make interactions from three or more features as well, but you'll tend to get diminishing returns.\n\nPandas lets us simply add string columns together like normal Python strings.","5ae8d00c":"Also we can make a new feature only by observing our dataset and its initial features to make a new feature which can enhance our model performance, we can see in our dataset that we can make a new feature which is the count of the number of projects launched in the last week , maybe this count can affect our model and its performance , since we have the launched date of each project , we can count the number of projects launched in the last week.","01adce16":"### 1 - Ordinal features\n\nThey are features which has values can be ordered , like asking about the frequency of doing something , the answer would be one of the following :\n\"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3) .\nSo this type of features have values that are classified into categories but can be ordered ."}}