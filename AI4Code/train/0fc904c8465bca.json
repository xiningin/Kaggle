{"cell_type":{"29de1dc0":"code","7e9f14b7":"code","411a2680":"code","a8e02b53":"code","a5d8d97e":"code","0f00876d":"code","788ebcb6":"code","62437ffa":"code","f33b4975":"code","174cf6f2":"code","d4340336":"code","375214f6":"code","619f31d9":"code","c74e0b8c":"code","c3fefa51":"code","5e5d28f4":"markdown","92273fdf":"markdown","90f377fd":"markdown","5a536acf":"markdown","c39d0d1d":"markdown","df003e01":"markdown","6c312296":"markdown","a58824d1":"markdown"},"source":{"29de1dc0":"import numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf.head()","7e9f14b7":"import re\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nstops = set(stopwords.words('english'))\nstemmer = SnowballStemmer('english')\n\ndef clean_question(question):\n    question = question.translate(string.punctuation)\n    \n    words = question.lower().split()\n    question = [w for w in words if w not in stops and len(w) >= 3]\n    question = ' '.join(words)\n    \n    question = re.sub(r'[^A-Za-z0-9^,!.\\\/\\'+-=]', ' ', question)\n    question = re.sub(r'what\\'s', 'what is', question)\n    question = re.sub(r'\\'s', ' ', question)\n    question = re.sub(r'\\'ve', ' have', question)\n    question = re.sub(r'n\\'t', ' not', question)\n    question = re.sub(r'i\\'m', 'i am', question)\n    question = re.sub(r'\\'re', ' are', question)\n    question = re.sub(r'\\'d', ' would', question)\n    question = re.sub(r'\\'ll', ' will', question)\n    \n    # remove morphological affixes\n    words = question.split()\n    stemmed_words = [stemmer.stem(w) for w in words]\n    question = ' '.join(stemmed_words)\n    \n    return question\n\ndf['question_text'] = df['question_text'].map(lambda q: clean_question(q))\ndf_test['question_text'] = df_test['question_text'].map(lambda q: clean_question(q))\ndf.head()","411a2680":"# loading embedding: https:\/\/www.kaggle.com\/sudalairajkumar\/a-look-at-different-embeddings\nEMBEDDING_FILE = '..\/input\/embeddings\/glove.840B.300d\/glove.840B.300d.txt'\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n\n'Loaded %s word vectors' % len(embeddings_index)","a8e02b53":"embedding_matrix = np.zeros((vocabulary_size, 300))\nfor word, index in tokenizer.word_index.items():\n    if index <= vocabulary_size - 1:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index] = embedding_vector","a5d8d97e":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n\nvocabulary_size = 20000\ntokenizer = Tokenizer(num_words=vocabulary_size)\ntokenizer.fit_on_texts(df['question_text'].append(df_test['question_text']))\n\nsequences = tokenizer.texts_to_sequences(df['question_text'])\npadded_data = pad_sequences(sequences, maxlen=50)\n\npadded_data.shape","0f00876d":"from keras.models import Sequential\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Dropout, Conv1D, MaxPooling1D, LSTM, Dense\n\n\nmodel = Sequential()\nmodel.add(Embedding(vocabulary_size, 300, input_length=50,\n                    weights=[embedding_matrix], trainable=False))\nmodel.add(Dropout(0.2))\nmodel.add(Conv1D(64, 5, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=4))\nmodel.add(LSTM(300))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","788ebcb6":"labels = df['target']\nmodel.fit(padded_data, np.array(labels), validation_split=0.4, epochs=3)","62437ffa":"sequences = tokenizer.texts_to_sequences(df_test['question_text'])\npadded_test = pad_sequences(sequences, maxlen=50)\n\npadded_test.shape","f33b4975":"predicted = model.predict(padded_test, batch_size=1024, verbose=1)","174cf6f2":"sample = df.sample(int(len(df) * 0.2))\nsample_label = sample['target']\n\nsample_sequences = tokenizer.texts_to_sequences(sample['question_text'])\npadded_sample = pad_sequences(sample_sequences, maxlen=50)\n\npadded_sample.shape","d4340336":"predicted_sample = model.predict(padded_sample, batch_size=1024, verbose=1)","375214f6":"from sklearn.metrics import f1_score\n\n\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    print('F1 score at threshold {} is {}'.format(thresh, f1_score(sample_label,\n                                                             (predicted_sample > thresh).astype(int))))","619f31d9":"output = (predicted > 0.31).astype(int)\noutput","c74e0b8c":"df_test['prediction'] = output\nsubmission = df_test.drop(columns=['question_text'])\nsubmission.head()","c3fefa51":"submission.to_csv('submission.csv', index=False)","5e5d28f4":"# Building the Model","92273fdf":"# Reading the data","90f377fd":"# Cleaning question text\n\nUsing [Dieter's kernel](https:\/\/www.kaggle.com\/christofhenkel\/how-to-preprocessing-when-using-embeddings), the cleaning has to be changed:","5a536acf":"# Building the embedding","c39d0d1d":"## Preparing submission","df003e01":"## Predicting and adjusting","6c312296":"## Training the model","a58824d1":"## Tokenizing"}}