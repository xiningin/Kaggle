{"cell_type":{"003a533b":"code","8ec87306":"code","7d03a94a":"code","1337572b":"code","57a7e173":"code","acc42e72":"code","b19a8fae":"code","c3b0afcb":"code","73628bb8":"code","d643e2d7":"code","73126b50":"markdown","9ed76766":"markdown","8a95aa29":"markdown","f0f5dccb":"markdown","c2a1c7b5":"markdown","6c04bb66":"markdown","88b21828":"markdown","1979bd9c":"markdown","d5b090de":"markdown","cb59bd60":"markdown","36450368":"markdown","4483f1fa":"markdown","0cbbb38e":"markdown","f1ca2a13":"markdown","0911c380":"markdown","75b60353":"markdown","4577945d":"markdown","8ed3180e":"markdown","5eeba359":"markdown","4267c5fd":"markdown"},"source":{"003a533b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import *\nimport os\nimport matplotlib.image as mpimg\nimport glob\nfrom PIL import Image ","8ec87306":"# Given Data\ntpr_thresholds = [0.0, 0.4, 1.0]\nweights =        [       2,   1]\n\ndef weighted_auc(labels, preds, plot = False):\n    # Calculating ROC curve\n    fpr, tpr, _ = roc_curve(labels, preds, pos_label=1)\n    # data labels, preds\n    area = np.array(tpr_thresholds)[1:] - np.array(tpr_thresholds)[:-1]\n    area_normalized = np.dot(area, np.array(weights).T)  # For normalizing AUC\n    fscore = 0\n    for index, weight in enumerate(weights):\n        ymin = tpr_thresholds[index]    \n        ymax = tpr_thresholds[index + 1]\n\n        mask = (tpr > ymin) & (tpr < ymax)\n        x = np.concatenate([fpr[mask], np.linspace(fpr[mask][-1], 1, 100)])\n        y = np.concatenate([tpr[mask], [ymax] * 100])\n        y = y #(taking y as origin)\n        score = auc(x, y-ymin)\n        # Multiply score with weight\n        weighted_score = score * weight\n\n        fscore += weighted_score\n        color = [\"red\", \"green\"]\n        label = [\"x \u2208 [0, 1], y \u2208 [0, 0.4]\", \"x \u2208 [0, 1], y \u2208 [0.4, 1.0]\"]\n        \n        if plot:\n            plt.title(\"Separate plots for x \u2208 [0, 1], y \u2208 [0, 0.4] and x \u2208 [0, 1], y \u2208 [0.4, 1.0]\")\n            plt.plot(x, y, color = color[index], label = label[index])\n            plt.xlabel(\"False Positive rate\")\n            plt.ylabel(\"True Positive rate\")\n            plt.legend(loc = 2)\n#             plt.plot()\n\n    # Normalizing score\n    final_score = fscore\/area_normalized\n    return final_score\n    \n    ","7d03a94a":"# Initializing random labels and prediction to simulate the metric\nnp.random.seed(42)\n\nsignal = np.random.random(1000)\nlabels = (signal > 0.5).astype(int)\npreds = np.random.random(1000) + (signal - 0.5) * 0.3","1337572b":"weighted_auc(labels, preds, plot = True)","57a7e173":"# path to images\nBASE_PATH = \"..\/input\/alaska2-image-steganalysis\"\ntrain_images_name = os.listdir(BASE_PATH + \"\/Cover\")\ntest_images_name = os.listdir(BASE_PATH + \"\/Test\")\ntrain_images_name.sort(), test_images_name.sort()\nprint(f\"Number of images in train set are {len(train_images_name)}\")\nprint(f\"Number of images in test set are {len(test_images_name)}\")","acc42e72":"cover_image = mpimg.imread(os.path.join(BASE_PATH, \"Cover\/00004.jpg\"))\nJMiPOD_image = mpimg.imread(os.path.join(BASE_PATH, \"JMiPOD\/00004.jpg\"))\nJUNIWARD_image = mpimg.imread(os.path.join(BASE_PATH, \"JUNIWARD\/00004.jpg\"))\nUERD_image = mpimg.imread(os.path.join(BASE_PATH, \"UERD\/00004.jpg\"))","b19a8fae":"plt.figure(1, figsize = (10, 10))\nplt.subplot(221)\nplt.title(\"cover_image\")\nplt.imshow(cover_image)\n\nplt.subplot(222)\nplt.imshow(JMiPOD_image)\nplt.title(\"JMiPOD_image\")\n\nplt.subplot(223)\nplt.imshow(JUNIWARD_image)\nplt.title(\"JUNIWARD_image\")\n\nplt.subplot(224)\nplt.imshow(UERD_image)\nplt.title(\"UERD_image\")\nplt.show()","c3b0afcb":"plt.figure(1, figsize = (10, 10))\nplt.subplot(221)\nplt.title(\"cover_image\")\nplt.imshow(cover_image - cover_image)\n\nplt.subplot(222)\nplt.imshow(JMiPOD_image - cover_image)\nplt.title(\"JMiPOD_image\")\n\nplt.subplot(223)\nplt.imshow(JUNIWARD_image - cover_image)\nplt.title(\"JUNIWARD_image\")\n\nplt.subplot(224)\nplt.imshow(UERD_image - cover_image)\nplt.title(\"UERD_image\")\nplt.show()","73628bb8":"! git clone https:\/\/github.com\/dwgoon\/jpegio\n!pip install jpegio\/.\nimport jpegio as jio","d643e2d7":"coverDir = \"\/kaggle\/input\/alaska2-image-steganalysis\/Cover\/00001.jpg\"\nJMiPODDir = \"\/kaggle\/input\/alaska2-image-steganalysis\/JMiPOD\/00001.jpg\"\nJUNIWARDDir = \"\/kaggle\/input\/alaska2-image-steganalysis\/JUNIWARD\/00001.jpg\"\nUERDDir = \"\/kaggle\/input\/alaska2-image-steganalysis\/UERD\/00001.jpg\"\n\n\n\n#imgList = sorted(os.listdir(coverDir))\n# imgList = os.listdir(coverDir)[:20]\n# random.shuffle(imgList)\nplt.figure(1, figsize = (10, 10))\nplt.subplot(221)\nplt.title(\"cover_image\")\nc_struct=jio.read(coverDir)\ncoverDCT = np.zeros([512,512,3])\ncoverDCT[:,:,0] = c_struct.coef_arrays[0]\ncoverDCT[:,:,1] = c_struct.coef_arrays[1]\ncoverDCT[:,:,2] = c_struct.coef_arrays[2]\ncoverQTbl = c_struct.quant_tables[0]\nplt.imshow( abs(coverDCT) )\n\nplt.subplot(222)\nplt.title(\"JMiPOD_image\")\nc_struct=jio.read(JMiPODDir)\nJMiPODDirDCT = np.zeros([512,512,3])\nJMiPODDirDCT[:,:,0] = c_struct.coef_arrays[0]\nJMiPODDirDCT[:,:,1] = c_struct.coef_arrays[1]\nJMiPODDirDCT[:,:,2] = c_struct.coef_arrays[2]\nJMiPODDirQTbl = c_struct.quant_tables[0]\nplt.imshow( abs(JMiPODDirDCT) )\n\nplt.subplot(223)\nplt.title(\"JUNIWARD_image\")\nc_struct=jio.read(JUNIWARDDir)\nJUNIWARDDirDCT = np.zeros([512,512,3])\nJUNIWARDDirDCT[:,:,0] = c_struct.coef_arrays[0]\nJUNIWARDDirDCT[:,:,1] = c_struct.coef_arrays[1]\nJUNIWARDDirDCT[:,:,2] = c_struct.coef_arrays[2]\nJUNIWARDDirQTbl = c_struct.quant_tables[0]\nplt.imshow( abs(JUNIWARDDirDCT) )\n\n\nplt.subplot(224)\nplt.title(\"UERD_image\")\nc_struct=jio.read(UERDDir)\nUERDDirDCT = np.zeros([512,512,3])\nUERDDirDCT[:,:,0] = c_struct.coef_arrays[0]\nUERDDirDCT[:,:,1] = c_struct.coef_arrays[1]\nUERDDirDCT[:,:,2] = c_struct.coef_arrays[2]\nUERDDirQTbl = c_struct.quant_tables[0]\nplt.imshow( abs(UERDDirDCT) )","73126b50":"**Let's make evaluation metric**\nLogic for making evaluation metric:\nFirst keeping 0.4 True positive rate as threshold i will calculate area under the curve (x \u2208 [0, 1], y \u2208 [0, 0.4]), 0.4 being a horizontal line. Multiply the AUC with the weight (2X), Similarly from (x \u2208 [0, 1], y \u2208 [0.4, 1.0]), taking y = 0.4 as origin i will calculate the area under the curve. Multiply the AUC with weight (1X). After this i will add both AUC and divide by 1.4 (0.4 * 2 + 0.6 * 1) for normalizing.","9ed76766":"Here the evaluation metric is weighted AUC. In other words, the area between the true positive rate of 0 and 0.4 is weighted 2X, the area between 0.4 and 1 is now weighed (1X). The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1. \n\n![inbox_1951250_f250ff6a4e04bac332fa14d539ed813e_Kaggle%20%281%29.png](attachment:inbox_1951250_f250ff6a4e04bac332fa14d539ed813e_Kaggle%20%281%29.png)","8a95aa29":"As per the discussion:\nhttps:\/\/www.kaggle.com\/c\/alaska2-image-steganalysis\/discussion\/147494\n\n**Data is hidden in DCT coefficients not in the pixels. There are some changes in pixel values which is only due to embedding of message. Below i have plotted the difference between pixel values in cover and stego images. Let's have a look\n**","f0f5dccb":"# 4. Image Analysis","c2a1c7b5":"Here is the visual example of stegnograpy. Same image viewed by white, blue green and red shows different numbers.\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/9\/9c\/Steganography.png\/310px-Steganography.png)\n\nImage Source: Wikipedia","6c04bb66":"# 3. Evaluation Metric","88b21828":"You can refer this tutorial on Github for DCT\n\nhttps:\/\/github.com\/dwgoon\/jpegio\/blob\/master\/examples\/jpegio_tutorial.ipynb","1979bd9c":"# 2. About the Dataset","d5b090de":"**Well above all images look exactly similar but except the first image all the other images have secret code, SCARY**\n\nLet's analyse each image","cb59bd60":"**In this competition we are provided with embedded images having different embedding techniques like JMiPOD, JUNIWARD, UERD. We have to look for what knind of changes these algorithms make to original images by analysing RGB values of Cover images and embedded images. Let's look at the first image in Cover, JMiPOD, JUNIWARD, UERD directories**","36450368":"If you find my work helpful then do upvote. Let's start","4483f1fa":"# 5. DCT (Discrete Cosine Transform) coefficients","0cbbb38e":"**This notebook helped me a lot in evaluation metric calculation. Please upvote this kernel also**\nhttps:\/\/www.kaggle.com\/anokas\/weighted-auc-metric-updated","f1ca2a13":"# 1. What is Stegnography","0911c380":"This dataset contains a large number of unaltered images, called the \"Cover\" image, as well as corresponding examples in which information has been hidden using one of three steganography algorithms (JMiPOD, JUNIWARD, UERD). The goal of the competition is to determine which of the images in the test set (Test\/) have hidden messages embedded.\n\nNote that in order to make the competition more realistic the length of hidden messages (the payload) will not be provided. The only available information on the test set is:\n\n1. Each embedding algorithm is used with the same probability.\n2. The payload (message length) is adjusted such that the \"difficulty\" is approximately the same regardless the content of the image. Images with smooth content are used to hide shorter messages while highly textured images will be used to hide more secret bits. The payload is adjusted in the same manner for testing and training sets.\n3. The average message length is 0.4 bit per non-zero AC DCT coefficient.\n4. The images are all compressed with one of the three following JPEG quality factors: 95, 90 or 75.\n\n\n75k images are povided in each of Cover, JMiPOD, JUNIWARD, UERD directories. 5k images are provided in test data.\n\n1. Cover\/ contains 75k unaltered images meant for use in training.\n2. JMiPOD\/ contains 75k examples of the JMiPOD algorithm applied to the cover images.\n3. JUNIWARD\/contains 75k examples of the JUNIWARD algorithm applied to the cover images.\n4. UERD\/ contains 75k examples of the UERD algorithm applied to the cover images.\n5. Test\/ contains 5k test set images. These are the images for which you are predicting.\n6. sample_submission.csv contains an example submission in the correct format.","75b60353":"### Table of content\n1. What is Stegnography\n2. About the Dataset\n3. Evaluation Metric\n4. Image Analysis\n5. DCT Coefficients","4577945d":"Let'a apply DCT to input images","8ed3180e":"**Steganography is the technique of hiding secret data within an ordinary, non-secret, file or message in order to avoid detection; the secret data is then extracted at its destination. The use of steganography can be combined with encryption as an extra step for hiding or protecting data. In most of the cases hidden messages are concealed within the lowest bits of noisy images. For example if a color is represented in 8 bits then first 6 bits can be used for image and last 2 bits can be used to embed hidden message**","5eeba359":"We can see that there is change in pixel values in each of the embedded image when compared with cover image","4267c5fd":"So What is DCT?\n\nTo understand DCT first you need to understand about spatial domain and frequency domain.\nSpatial Domain and Frequency Domain are image enhancement techniques. Let's talk about each of them.\n\nSpatial Domain: Spatial Domain techniques deals with image pixels. The pixel values are manipulated to achieve desired enhancements.\n\nFrequency Domain: These techniques are based on the manipulation of orthogonal transform of image rather than image itself for e.g change in phase, amplitude.\n\nIn DCT, Image from spatial domain is converted to frequency domain\n\n![](https:\/\/users.cs.cf.ac.uk\/Dave.Marshall\/Multimedia\/fig2.gif)\n\nIn the above diagram spatial domain image f(i, j) is converted to frequency domain F(u, v) using DCT\n\nThe formuls for DCT is given below:\n![](https:\/\/users.cs.cf.ac.uk\/Dave.Marshall\/Multimedia\/img28.gif)\nWhere:\n![](https:\/\/users.cs.cf.ac.uk\/Dave.Marshall\/Multimedia\/img29.gif)\n                                                    N, M are dimensions of imput image in 2d\n                                                    \n                                                    \n                                                    \nFor more details you can use below link:\n\nhttps:\/\/users.cs.cf.ac.uk\/Dave.Marshall\/Multimedia\/node231.html"}}