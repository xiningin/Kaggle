{"cell_type":{"9eeaa934":"code","4f9b15bb":"code","62d20115":"code","abd3d1c0":"code","f8ad4c05":"code","23193df0":"markdown","ad66d142":"markdown","ec14cc4b":"markdown"},"source":{"9eeaa934":"# ==================\n# Library\n# ==================\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nimport glob\nimport transformers\nfrom transformers import BertTokenizer\nimport torch","4f9b15bb":"# ==================\n# Constant\n# ==================\nTRAIN_PATH = '..\/input\/used-car-price-forecasting\/train.csv'\nTEST_PATH = '..\/input\/used-car-price-forecasting\/test.csv'\nSAVE_PATH = \"bert_train.npy\"","62d20115":"# ====================\n# Function\n# ====================\n\n\nclass BertSequenceVectorizer:\n    def __init__(self):\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.model_name = 'bert-base-uncased'\n        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n        self.bert_model = transformers.BertModel.from_pretrained(self.model_name)\n        self.bert_model = self.bert_model.to(self.device)\n        self.max_len = 512\n            \n\n    def vectorize(self, sentence : str) -> np.array:\n        inp = self.tokenizer.encode(sentence)\n        len_inp = len(inp)\n\n        if len_inp >= self.max_len:\n            inputs = inp[:self.max_len]\n            masks = [1] * self.max_len\n        else:\n            inputs = inp + [0] * (self.max_len - len_inp)\n            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n\n        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n        \n        seq_out, pooled_out = self.bert_model(inputs_tensor, masks_tensor)\n\n        if torch.cuda.is_available():    \n            return seq_out[0][0].cpu().detach().numpy() # 0\u756a\u76ee\u306f [CLS] token, 768 dim \u306e\u6587\u7ae0\u7279\u5fb4\u91cf\n        else:\n            return seq_out[0][0].detach().numpy()","abd3d1c0":"# ====================\n# Main\n# ====================\n\n\ntrain_df = pd.read_csv(TRAIN_PATH)\n\nbert = np.zeros((len(train_df),768))\nBSV = BertSequenceVectorizer()\nfor n,description in tqdm_notebook(enumerate(train_df[\"description\"]), total=len(train_df)):\n    bert[n,:] = BSV.vectorize(train_df[\"description\"].iloc[n])","f8ad4c05":"np.save(SAVE_PATH,bert)","23193df0":"BERT\u3092\u4f7f\u3063\u3066\u3001text\u3092\u30d9\u30af\u30c8\u30eb\u306b\u3059\u308b\u65b9\u6cd5\u3067\u3059\u3002  \u4e0b\u8a18github\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002  \nhttps:\/\/github.com\/osuossu8\/Utils\/blob\/master\/text_preprocess\/bert_sentence_vectorizer.py\n\nSettings\u3067\u4e0b\u8a18\u8a2d\u5b9a\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\n- Accelerator\u3092GPU\n- Internet\u3092ON","ad66d142":"\u203b\u4eca\u56de\u306ftrain data\u3060\u3051\u3092\u5bfe\u8c61\u306b\u3057\u3066\u3044\u307e\u3059\u3002test data\u306f\u540c\u69d8\u306e\u65b9\u6cd5\u3067\u5bfe\u5fdc\u304f\u3060\u3055\u3044\u3002  \n   &nbsp;\u307e\u305fbatch\u3054\u3068\u306e\u51e6\u7406\u306b\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u6642\u9593\u304b\u304b\u308a\u307e\u3059\u3002  \n   &nbsp;\u305d\u306e\u305f\u3081\u4eca\u56de\u306enotebook\u3067\u306foutput\u51fa\u3057\u3066\u306a\u304f\u3001\u30b3\u30fc\u30c9\u3060\u3051\u306e\u30b7\u30a7\u30a2\u3067\u3059\u3002\n   \u3054\u4e86\u627f\u304f\u3060\u3055\u3044\u3002","ec14cc4b":"# \u6587\u66f8\u30d9\u30af\u30c8\u30eb\u306f\u3001\u305d\u306e\u307e\u307e\u3001\u3082\u3057\u304f\u6b21\u5143\u524a\u6e1b\u3057\u3066LightGBM\u306a\u3069\u306e\u7279\u5fb4\u91cf\u306b\u3057\u3066\u304f\u3060\u3055\u3044!"}}