{"cell_type":{"f4791fbb":"code","1ac41e5a":"code","7aff6e57":"code","161bb092":"code","6555b87d":"code","68b2e25c":"code","9dc13908":"code","28c33012":"code","32e4175a":"code","89cdb4d8":"code","85cd0a12":"code","164cb517":"code","77978a0c":"code","7bcb93b6":"code","b13241a7":"code","796bbfb0":"code","dc2c0595":"code","ffec9ff2":"code","a87744a5":"code","47c9e478":"markdown","f69f3e69":"markdown","06ae9525":"markdown","b19b2c54":"markdown","482a3c2b":"markdown","c6b31d1f":"markdown","6f61582e":"markdown","969e1849":"markdown","631f3418":"markdown"},"source":{"f4791fbb":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow as tf\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split","1ac41e5a":"positive_dir = Path('..\/input\/surface-crack-detection\/Positive')\nnegative_dir = Path('..\/input\/surface-crack-detection\/Negative')","7aff6e57":"def generate_df(image_dir, label):\n    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n    labels = pd.Series(label, name='Label', index=filepaths.index)\n    df = pd.concat([filepaths, labels], axis=1)\n    return df","161bb092":"positive_df = generate_df(positive_dir, label=\"POSITIVE\")\nnegative_df = generate_df(negative_dir, label=\"NEGATIVE\")\n\ndf = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\ndf","6555b87d":"train_df, test_df = train_test_split(df,train_size=0.7,shuffle=True,random_state=42)","68b2e25c":"train_df.shape","9dc13908":"test_df.shape","28c33012":"train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,validation_split=0.2)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","32e4175a":"train_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training')","89cdb4d8":"val_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation')","85cd0a12":"test_data = train_gen.flow_from_dataframe(\n    test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42)","164cb517":"inputs = tf.keras.Input(shape=(120, 120, 3))\nx = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\nx = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\nprint(model.summary())","77978a0c":"history = model.fit(train_data,validation_data=val_data,epochs=10,\n            callbacks=[tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True)])","7bcb93b6":"fig = px.line(\n    history.history,\n    y=['loss', 'val_loss'],\n    labels={'index': \"Epoch\", 'value': \"Loss\"},\n    title=\"Training and Validation Loss Over Time\")\nfig.show()","b13241a7":"fig = px.line(\n    history.history,\n    y=['accuracy', 'val_accuracy'],\n    labels={'index': \"Epoch\", 'value': \"Accuracy\"},\n    title=\"Training and Validation Accuracy Over Time\")\nfig.show()","796bbfb0":"def evaluate_model(model, test_data):\n    \n    results = model.evaluate(test_data, verbose=0)\n    loss = results[0]\n    acc = results[1]\n    \n    print(\"    Test Loss: {:.5f}\".format(loss))\n    print(\"Test Accuracy: {:.2f}%\".format(acc * 100))","dc2c0595":"evaluate_model(model, test_data)","ffec9ff2":"y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))\ncm = confusion_matrix(test_data.labels, y_pred)\nclr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n    \nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='viridis', cbar=False)\nplt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\nplt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","a87744a5":"print(\"Classification Report:\\n----------------------\\n\", clr)","47c9e478":"**We got 11749 correct predictions out of 12000 records in test set.**","f69f3e69":"**Fitting the model**","06ae9525":"**flow_from_dataframe checks the path available on the dataframe and then automatically search for the image in train directory. Then it make the desired preprocessing steps available in ImageDataGenerator**","b19b2c54":"**Training the model**","482a3c2b":"**At the end of 10th epoch we are getting an accuracy of 0.9793 and validation accuracy of 0.9759**","c6b31d1f":"**For more insights check the tensorflow official documentation https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator**","6f61582e":"**Test accuracy is 97.91% and Test loss is 0.05720**","969e1849":"**Image Data Generator generates batches of tensor image data with real-time data augmentation.**","631f3418":"**More insights can be found from this article https:\/\/vijayabhaskar96.medium.com\/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1**"}}