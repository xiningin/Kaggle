{"cell_type":{"ce4aff24":"code","182cb8e9":"code","aebad4a5":"code","cdc0de82":"code","411cced3":"code","d94e1da6":"code","90f60cd2":"code","647793e2":"code","36516a26":"code","067e6b49":"code","189e3f6d":"code","8dfba371":"code","8dae73d8":"code","e6c73a2d":"code","82302110":"code","f534dfd3":"code","4dd56270":"code","5f7efe26":"code","42ae4b4a":"code","f77320b0":"code","0dcdd2fb":"code","aea5c166":"markdown","fdac7643":"markdown","d4b90a09":"markdown","1271d143":"markdown","014c91b0":"markdown","dfc321d6":"markdown","5e052cc0":"markdown","52850c89":"markdown","7e577be9":"markdown","2ad8a714":"markdown","89368319":"markdown","1a3aec27":"markdown","59eeb0e8":"markdown","a4d21411":"markdown","f0c4f6b1":"markdown","2a0a3602":"markdown","818dbb7f":"markdown","ef0d503e":"markdown","5061b9aa":"markdown","a7b5cad2":"markdown","281b96a3":"markdown","29866c42":"markdown","67df6857":"markdown","bee46727":"markdown","d9cd940c":"markdown","e60f104f":"markdown"},"source":{"ce4aff24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","182cb8e9":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import LinearSVC\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import TimeSeriesSplit\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport math\nfrom sklearn.metrics import fbeta_score, make_scorer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n","aebad4a5":"train = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-02\/train.csv\")\ntest = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-02\/eval.csv\")","cdc0de82":"print(train.columns)\nprint(test.columns)","411cced3":"print(train[\"esrb_rating\"].unique())\ntrain.describe()","d94e1da6":"print(train.isnull().sum().sum())","90f60cd2":"id_column_test = test[\"id\"]\ntrain = train.drop(\"id\",axis=1)\ntrain = train.drop(\"title\",axis=1)\ntest = test.drop(\"id\",axis=1)\n","647793e2":"def esrbConversion(rating):\n    if(rating==\"E\"):\n        return 1\n    elif(rating==\"ET\"):\n        return 2\n    elif(rating==\"T\"):\n        return 3\n    else:\n        return 4","36516a26":"def numToEsrb(rating):\n    if(rating==1):\n        return \"E\"\n    elif(rating==2):\n        return \"ET\"\n    elif(rating==3):\n        return \"T\"\n    else:\n        return \"M\"","067e6b49":"train['esrb_rating'] = train[\"esrb_rating\"].apply(esrbConversion)","189e3f6d":"print(train[\"console\"].corr(train[\"esrb_rating\"]))","8dfba371":"train","8dae73d8":"X = train.drop(\"esrb_rating\",axis=1)\ny = train[\"esrb_rating\"]\n","e6c73a2d":"def createValidationResults(X,y,model):\n    iterations=100\n    results=[]\n    for x in range(iterations):\n        X_train,X_test,y_train,y_test = train_test_split (X,y,test_size=.33,random_state=42)\n        model.fit(X_train,y_train)\n        scores= cross_val_score(estimatormodel,X,y,cv=5)\n        results.append(s)\n","82302110":"def returnBestModelDistribution(model,X,y):\n    best_model","f534dfd3":"\nlog_params= {\n             'solver':('saga','lbfgs'),\n             'random_state':[1,5,66,7,88,9],\n            }\nlog_model = RandomizedSearchCV(LogisticRegression(),log_params)\nlog_model.fit(X,y)\nlog_model_score = cross_val_score(LogisticRegression().set_params(**log_model.best_params_),X,y,cv=20)\nsns.histplot(log_model_score,bins=10)\nlog_df= pd.Series(log_model_score)\nlog_df.describe()","4dd56270":"\nsvm_params= {\n             'kernel':('linear','poly','rbf','sigmoid'),\n             'degree':[2,3,4],\n             'random_state':[1,5,66,7,88,9]\n            }\nsvm_model = RandomizedSearchCV(svm.SVC(),svm_params)\nsvm_model.fit(X,y)\nsvm_model_score = cross_val_score(svm.SVC().set_params(**svm_model.best_params_),X,y,cv=20)\nsns.histplot(svm_model_score,bins=10)\nsvm_df = pd.Series(svm_model_score)\nsvm_df.describe()","5f7efe26":"dt_params= {\n             'criterion':('gini','entropy'),\n             'max_depth':[100,200,300],\n             'max_features':('auto','sqrt','log2'),\n             'random_state':[1,5,66,7,88,9],\n            }\ndt_model = RandomizedSearchCV(DecisionTreeClassifier(),dt_params)\ndt_model.fit(X,y)\ndt_model_score = cross_val_score(DecisionTreeClassifier().set_params(**dt_model.best_params_),X,y,cv=20)\nsns.histplot(dt_model_score,bins=10)\ndt_df = pd.Series(dt_model_score)\ndt_df.describe()\n","42ae4b4a":"rf_params= {\n             'n_estimators':[100,200,300],\n             'max_features':('auto','sqrt','log2'),\n             'criterion':('gini','entropy')\n            }\nrf_model = RandomizedSearchCV(RandomForestClassifier(),rf_params)\nrf_model.fit(X,y)\nrf_model_score = cross_val_score(RandomForestClassifier().set_params(**rf_model.best_params_),X,y,cv=20)\nrf_df=pd.Series(rf_model_score)\nsns.histplot(rf_model_score,bins=10)\nrf_df.describe()\n","f77320b0":"knn_params= {\n             'n_neighbors':[4,5,6,7,10],\n             'weights':('uniform','distance'),\n             'algorithm':('auto','ball_tree','kd_tree','brute'),\n             'p':[1,2]\n            }\nknn_model = RandomizedSearchCV(KNeighborsClassifier(),knn_params)\nknn_model.fit(X,y)\nknn_model_score = cross_val_score(KNeighborsClassifier().set_params(**knn_model.best_params_),X,y,cv=20)\nsns.histplot(knn_model_score,bins=10)\nknn_df = pd.Series(knn_model_score)\nknn_df.describe()","0dcdd2fb":"prediction_df = pd.DataFrame()\nprediction_df['id']= id_column_test\nprediction_df['esrb_rating']= svm_model.predict(test)\nprediction_df[\"esrb_rating\"]= prediction_df[\"esrb_rating\"].apply(numToEsrb)\nprediction_df.to_csv(\"submission.csv\",index=False)\nprint(prediction_df.to_string())","aea5c166":"### Unique Values for ratings","fdac7643":"## Imports","d4b90a09":"# Initial Steps","1271d143":"# Exploratory Data Analysis and Cleaning","014c91b0":"### ","dfc321d6":"### Drop not useful columns\nHere we drop title and id, however we save the id column for the end","5e052cc0":"# K Nearest Neighbors Model","52850c89":"# Preparing data For Models","7e577be9":"### CHECKING FOR MISSING VALUES","2ad8a714":"# Support Vector Machine","89368319":"## Changing Ratings to Numerical values \nHere we change the string ratings into numerical values for our model to be able to give predictions.","1a3aec27":"### Basic Stuff","59eeb0e8":"# Decision Tree Model","a4d21411":"# MODELS","f0c4f6b1":"Seems like there are no missing values in this dataset.","2a0a3602":"## Data Info","818dbb7f":"# MODEL SUBMISSION\nBest model was SVM so lets turn that one in","ef0d503e":"## Cleaning","5061b9aa":"## Plots","a7b5cad2":"## Logistic Regression","281b96a3":"## ","29866c42":"## Read In Data","67df6857":"# Random Forest Model","bee46727":"## Outliers\nConsidering that there are no missing values, and that our data is discrete and categorical, there are no outliers.","d9cd940c":"### Function to convert back to Strings","e60f104f":"### Function to do the conversion"}}