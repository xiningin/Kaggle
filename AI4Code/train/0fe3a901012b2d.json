{"cell_type":{"ed4ab253":"code","4c169d7e":"code","d2b5b834":"code","8366862d":"code","133eb73f":"code","47c1b069":"code","a068b5c8":"code","c7f832ed":"code","4d354948":"code","085da504":"code","74ca8d51":"code","4ac7d0b6":"code","052178a7":"code","1fe43c66":"code","4549bd24":"code","a20eb3a0":"code","edc2ba14":"code","309c5851":"code","0dbf4bc2":"code","794df0b0":"code","ea6b0b1b":"code","5daa65a0":"code","c865cc3e":"code","f961bd5f":"code","12811a72":"code","909ce112":"code","ad8dedb0":"code","8cba0903":"code","ef4367df":"code","9f750914":"code","b0f4935e":"code","1d42952d":"code","5db59f26":"code","3b15cee5":"code","f613f2b2":"code","d045b8c4":"code","965e021a":"code","578776a0":"code","311dacab":"code","045d7aa4":"code","020112f6":"markdown","7214943a":"markdown","8fbe3a32":"markdown","2703c41c":"markdown","27ef9d53":"markdown","1dc948c3":"markdown","6dfb552a":"markdown","9c155a88":"markdown","758e506d":"markdown","b8fc36a9":"markdown","466f386b":"markdown","d97cbef1":"markdown","53a1af9d":"markdown","cd49a72c":"markdown","0aabf323":"markdown","f0295757":"markdown","dccd5ac8":"markdown","4593199a":"markdown","00951dac":"markdown","05cd1ff6":"markdown","468da8eb":"markdown","7e315c29":"markdown","9234bddc":"markdown","9c345105":"markdown"},"source":{"ed4ab253":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\nimport scipy\nimport matplotlib.gridspec as gridspec\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nimport matplotlib.style as style\nwarnings.filterwarnings('ignore')","4c169d7e":"train_csv = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv'\ntest_csv = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv'\n\ndf_train = pd.read_csv(train_csv)\ndf_test = pd.read_csv(test_csv)\n","d2b5b834":"def target_analysis(target):\n    fig = plt.figure(constrained_layout=True, figsize=(14,10))\n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n    ax1 = fig.add_subplot(grid[0, :2])\n    ax1.set_title('Histogram')\n    sns.distplot(target,norm_hist=True,ax=ax1)\n    ax2 = fig.add_subplot(grid[1, :2])\n    ax2.set_title('Q-Q Plot')\n    stats.probplot(target,plot=ax2)\n    ax3 = fig.add_subplot(grid[:,2])\n    ax3.set_title('Box Plot')\n    sns.boxplot(target,orient='v',ax=ax3)\n    print(f'skweness is { target.skew()}')\n    plt.show()","8366862d":"target_analysis(df_train['SalePrice'])","133eb73f":"target_analysis(np.log1p(df_train['SalePrice']))","47c1b069":"num_cols_tr = df_train.select_dtypes('number').columns.tolist()\nnum_cols_te = df_test.select_dtypes('number').columns.tolist()\n\nprint(f'There are {len(num_cols_tr)} numeric columns in train data')\ndf_num = df_train[num_cols_tr]\ndf_test_num = df_test[num_cols_te]\n\nprint('Train\/test numeric shapes')\nprint(df_num.shape)\nprint(df_test_num.shape)","a068b5c8":"df_num.dtypes","c7f832ed":"df_num = df_num.drop(columns=['Id'])\ndf_test_num = df_test_num.drop(columns=['Id'])","4d354948":"corr = df_num.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr,cmap=sns.diverging_palette(20,220,n=200))\nplt.show()","085da504":"multicoll_pairs = ['GarageArea','GarageCars',\n        'GarageYrBlt','YearBuilt','TotRmsAbvGrd','GrLivArea',\n                   '1stFlrSF','TotalBsmtSF']\n\nfig,axes = plt.subplots(4,2,figsize=(15,20))\n\ndef plot_two(feat,i,j):\n    sns.regplot(x=df_num[feat], y=df_num['SalePrice'], ax=axes[i,j])\n    sns.scatterplot(y=df_num['SalePrice'],x=df_num[feat],color=('orange'),ax=axes[i,j])   \n    fig.tight_layout(pad=5.0)\n    \n\nfor i,feat in enumerate(multicoll_pairs):\n    j = i%2 #0 or 1\n    plot_two(feat,i\/\/2,j)","74ca8d51":"df_num.corr()['SalePrice'].sort_values(ascending=False)","4ac7d0b6":"df_num = df_num.drop(columns = ['1stFlrSF','GarageArea','TotRmsAbvGrd','GarageYrBlt'])\ndf_test_num = df_test_num.drop(columns = ['1stFlrSF','GarageArea','TotRmsAbvGrd','GarageYrBlt'])","052178a7":"fig,axes = plt.subplots(16,2,figsize=(15,60))\n\nlinear_num_cols = df_num.select_dtypes(include='number').columns.tolist() \nlinear_num_cols.remove('SalePrice')\n\ndef plot_two(feat,i,j):\n    sns.regplot(x=df_num[feat], y=df_num['SalePrice'], ax=axes[i,j])\n    sns.scatterplot(y=df_num['SalePrice'],x=df_num[feat],color=('orange'),ax=axes[i,j])   \n    fig.tight_layout(pad=5.0)\n    \n\nfor i,feat in enumerate(linear_num_cols):\n    j = i%2 #0 or 1\n    plot_two(feat,i\/\/2,j)","1fe43c66":"df_num = df_num.drop(columns=['OverallCond','LowQualFinSF', 'MiscVal'])\ndf_test_num = df_test_num.drop(columns=['OverallCond','LowQualFinSF', 'MiscVal'])\nprint('Train\/test numeric shapes')\nprint(df_num.shape)\nprint(df_test_num.shape)","4549bd24":"df_num = df_num[df_num['LotFrontage'] < 300]\ndf_num = df_num[df_num['BsmtFinSF1'] < 5000]\ndf_num = df_num[df_num['TotalBsmtSF'] < 6000]\ndf_num = df_num[df_num['GrLivArea'] < 4600]\ndf_num = df_num[df_num['SalePrice'] < 700000]\nprint(df_num.shape)","a20eb3a0":"non_linear_cat_cols = ['YrSold','MoSold','PoolArea','BsmtFullBath',\n            'BsmtHalfBath','HalfBath','BedroomAbvGr','Fireplaces']\n\ndf_num = df_num.drop(columns = non_linear_cat_cols)\ndf_test_num = df_test_num.drop(columns = non_linear_cat_cols)\n\nfor col in non_linear_cat_cols:\n    df_train[col] = df_train[col].astype(object)\n    df_test[col] = df_train[col].astype(object)\n    \nprint(df_num.shape)\nprint(df_test_num.shape)","edc2ba14":"df_num.head(3)","309c5851":"# missing values in numeric features\ndef missing_cols(df):\n    cols = df.columns[df.isna().any()].tolist()\n    print(f'Columns | Percentage missing')\n    for column in cols:\n        percent = round((sum(df[column].isnull())\/df.shape[0])*100,2)\n        print(f'{column} : {percent}%')","0dbf4bc2":"missing_cols(df_num)","794df0b0":"missing_cols(df_test_num)","ea6b0b1b":"# lets convert the target variable and keep\ntarget = np.log1p(df_num['SalePrice'])","5daa65a0":"# helper functions\ndef categories_plot(df,col,xlabel='Values',size=(8,4)):\n    y_train = df[col].value_counts().values\n    x_train = df[col].value_counts().index.tolist()\n    plt.figure(figsize=size)\n    plt.title(col)\n    sns.barplot(x_train,y_train)\n    plt.xlabel(xlabel)\n    plt.xticks(rotation=90, ha='right')\n    plt.ylabel('count')\n    plt.show()","c865cc3e":"num_idx = df_num.index.to_list()\ncat_cols = df_train.select_dtypes(exclude=[np.number]).columns.tolist()\n\ndf_cat = df_train.loc[num_idx][cat_cols]\ndf_cat_test = df_test[cat_cols]\nprint('Train\/test categoric shapes')\nprint(df_cat.shape)\nprint(df_cat_test.shape)","f961bd5f":"missing_cols(df_cat)","12811a72":"missing_cols(df_cat_test)","909ce112":"df_cat = df_cat.drop(columns=['Alley','MiscFeature','PoolQC','Fence'])\ndf_cat_test = df_cat_test.drop(columns=['Alley','MiscFeature','PoolQC','Fence'])","ad8dedb0":"df_cat.describe()","8cba0903":"categories_plot(df_cat,'MSZoning')","ef4367df":"modified_cols = ['PoolArea','Street','MasVnrType','RoofMatl','Utilities']\n\nfor col in modified_cols:\n    categories_plot(df_cat,col)","9f750914":"# some feature engineering on cat features\n\nmodified_cols = ['PoolArea','Street','MasVnrType','RoofMatl']\n\n\ndf_cat = df_cat.drop(columns = ['Utilities'])\ndf_cat_test = df_cat_test.drop(columns = ['Utilities'])\n\ndf_cat['PoolArea'] = df_cat['PoolArea'].apply(lambda x: 'Y' if x>1 else 'N') \ndf_cat_test['PoolArea'] = df_cat_test['PoolArea'].apply(lambda x: 'Y' if x>1 else 'N')\n\ndf_cat['Street'] = df_cat['Street'].apply(lambda x: 'Pave' if x == 'Pave' else 'No Pave')\ndf_cat_test['Street'] = df_cat_test['Street'].apply(lambda x: 1 if x == 'Pave' else 0)\n\ndf_cat['MasVnrType'] = df_cat['MasVnrType'].apply(lambda x: 'N' if x == 'None' else 'Y')\ndf_cat_test['MasVnrType'] = df_cat_test['MasVnrType'].apply(lambda x: 'N' if x == 'None' else 'Y')\n\ndf_cat['RoofMatl'] = df_cat['RoofMatl'].apply(lambda x: 'CompShg' if x == 'CompShg' else 'Other')\ndf_cat_test['RoofMatl'] = df_cat_test['RoofMatl'].apply(lambda x: 'CompShg' if x == 'CompShg' else 'Other')","b0f4935e":"# saving coumn names\ncat_cols = df_cat.columns.to_list()\nnum_cols = df_num.columns.to_list()\n\ndf_test_num = df_test_num.reset_index(drop=True)\ndf_num = df_num.reset_index(drop=True)\ndf_cat = df_cat.reset_index(drop=True)\ndf_test_cat = df_cat_test.reset_index(drop=True)\n\nfinal_train = pd.concat([df_num,df_cat],axis=1)\nfinal_test = pd.concat([df_test_num,df_test_cat],axis=1)\n\nprint('Final shapes:')\nprint(final_train.shape)\nprint(final_test.shape)","1d42952d":"# apply box cox transform to features having skweness > 0.5\ndef sqrt_skew(df):\n    \n    sk_feats = df.apply(lambda x: stats.skew(x)).sort_values(ascending=False)\n    high_skew = sk_feats[abs(sk_feats) > 0.5].index\n    for feat in high_skew:\n#         df[feat] = boxcox1p(df[feat], boxcox_normmax(df[feat] + 1))\n          df[feat] = np.sqrt(df[feat])\n        \n    return df","5db59f26":"Y = target.values\nX = final_train\nx_test = final_test.copy()\nx_train,x_cv,y_train,y_cv = train_test_split(X,Y,train_size=0.7,random_state=100)\nprint('Train cv data shape')\nprint(x_train.shape)\nprint(x_cv.shape)\nprint(x_test.shape)","3b15cee5":"# imputing numeric values\n# Featurization of numeric data\n# df_num = df_num.drop(columns=['SalePrice'])\n\nnum_cols_in = df_num.columns.to_list()\nnum_cols_in.remove('SalePrice')\n\nimputer = SimpleImputer(strategy='median')\nx_train_num = imputer.fit_transform(x_train[num_cols_in])\nx_cv_num = imputer.transform(x_cv[num_cols_in])\nx_test_num = imputer.transform(x_test[num_cols_in])","f613f2b2":"#Normalizing\nscaler = RobustScaler()\nx_train_num = scaler.fit_transform(x_train_num)\nx_cv_num = scaler.transform(x_cv_num)\nx_test_num = scaler.transform(x_test_num)\n\ndf_num = pd.DataFrame(x_train_num, columns=num_cols_in)\ndf_cv_num = pd.DataFrame(x_cv_num, columns=num_cols_in)\ndf_test_num = pd.DataFrame(x_test_num, columns=num_cols_in)","d045b8c4":"# cat_cols = df_cat.columns.to_list()\n\n# # missing values in df\n# imputer = SimpleImputer(strategy='constant', fill_value='MISSING')\n# df_cat = imputer.fit_transform(df_cat[cat_cols])\n# df_cat_test = imputer.transform(df_cat_test[cat_cols])\n\n# df_cat = pd.DataFrame(df_cat, columns=cat_cols)\n# df_cat_test = pd.DataFrame(df_cat_test, columns=cat_cols)\n\nx_train_cat = x_train[cat_cols]\nx_cv_cat = x_cv[cat_cols]\nx_test_cat = x_test[cat_cols]\n\nfor col in cat_cols:\n    val = x_train_cat[col].mode()[0]\n    x_train_cat[col] = x_train_cat[col].fillna(val)\n    x_cv_cat[col] = x_cv_cat[col].fillna(val)\n    x_test_cat[col] = x_test_cat[col].fillna(val)","965e021a":"df_cat_dummy = pd.get_dummies(x_train_cat, columns=cat_cols,drop_first=True)\ndf_cv_cat_dummy = pd.get_dummies(x_cv_cat, columns=cat_cols,drop_first=True)\ndf_test_cat_dummy = pd.get_dummies(x_test_cat, columns=cat_cols,drop_first=True)\nprint(df_cat_dummy.shape)\nprint(df_cv_cat_dummy.shape)\nprint(df_test_cat_dummy.shape)\n\ndf_cat, df_cat_cv = df_cat_dummy.align(df_cv_cat_dummy, join='left', axis=1) \ndf_cat, df_cat_test = df_cat_dummy.align(df_test_cat_dummy, join='left', axis=1) \ndf_cat_test = df_cat_test.fillna(0)\ndf_cat_cv = df_cat_cv.fillna(0)\n\nprint('dummy categorical data shapes after aligning with train data')\nprint(df_cat.shape)\nprint(df_cat_cv.shape)\nprint(df_cat_test.shape)","578776a0":"# reseting index\ndf_cat_dummy = df_cat.reset_index(drop=True)\ndf_cv_cat_dummy = df_cat_cv.reset_index(drop=True)\ndf_test_cat_dummy = df_cat_test.reset_index(drop=True)\ndf_num = df_num.reset_index(drop=True)\ndf_cv_num = df_cv_num.reset_index(drop=True)\ndf_test_num = df_test_num.reset_index(drop=True)\n\nfinal_train = pd.concat([df_num,df_cat_dummy],axis=1)\nfinal_cv = pd.concat([df_cv_num,df_cv_cat_dummy],axis=1)\nfinal_test = pd.concat([df_test_num,df_test_cat_dummy],axis=1)\n\nprint('Final shapes:')\nprint(final_train.shape)\nprint(final_cv.shape)\nprint(final_test.shape)","311dacab":"x_train = final_train.copy()\nx_cv = final_cv.copy()\nx_test = final_test.copy()","045d7aa4":"linear = LinearRegression()\nlinear.fit(x_train,y_train)\n\ny_pred_train = linear.predict(x_train)\ny_pred_cv = linear.predict(x_cv)\n\n\nprint('Root Mean Square Error train = ' + str(np.sqrt(mean_squared_error(y_train, y_pred_train))))\nprint('Root Mean Square Error test = ' + str(np.sqrt(mean_squared_error(y_cv, y_pred_cv)))) \nprint('R2 score = ' + str(r2_score(y_cv,y_pred_cv)))","020112f6":"Missing values in numeric features","7214943a":"Normalization because:\n1. MSE is prone to outliers\n2. Normalization helps faster convergence\n3.Helps remove skewness","8fbe3a32":"Let us find continuous variables in these datasets. These play important role","2703c41c":"Importing Libraries","27ef9d53":"Function for plotting histogram, Q-Q Plot, Box-plot for checking skewness of target variable and features","1dc948c3":"Test Train Split","6dfb552a":"Linear Regression","9c155a88":"EDA on Catrgorical Features","758e506d":"Concating numeric and categorical features","b8fc36a9":"To make our target variable symmetric, we can apply log to it","466f386b":"('GarageArea','GarageCars'),('GarageYrBlt','YearBuilt')('TotRmsAbvGrd','GrLivArea'),('1stFlrSF','TotalBsmtSF');\nThese features are multicollinear. We will keep only one in each pair. For deciding which one to remove, we will check realation with SalePrice.","d97cbef1":"Convert numeric variables to categorical","53a1af9d":"Checking linearity with Independent Variables","cd49a72c":"Checking missing values","0aabf323":"ML Models","f0295757":"Removing columns with more than 80% missing values","dccd5ac8":"Let's remove the outliers","4593199a":"Loading the Data","00951dac":"Corelation matrix and removing multicollinearity","05cd1ff6":"Checking missing values in numeric columns","468da8eb":"Onehot encoding categories","7e315c29":"So let us drop 'GarageArea','TotRmsAbvGrd' and 'GarageYrBlt','1stFlrSF'.","9234bddc":"Non linear features that can be converted to categorical: 'YrSold','MSSold','PoolArea','BsmtFullBath','BsmtHalfBath','Halfbath','BedroomAbvGvr','Fireplaces'\n\nNon-linear features that we will drop 'OverallCond','LowQualFinSF', 'MiscVal',","9c345105":"Missing values in categoric features"}}