{"cell_type":{"45e6732e":"code","0a9fefa2":"code","78540096":"code","7b7d3954":"code","636a2beb":"code","770c9e97":"code","b97f3ea1":"code","89443242":"code","fe77fd1e":"code","930a4b38":"code","e2986d7a":"code","b725a808":"code","e04bf9bc":"code","4b491e0f":"code","d8fd9068":"code","308ef8fc":"code","ef32c85f":"code","c8fa2656":"code","c798907b":"code","7c371a46":"code","bdaf3401":"code","3081fbb3":"code","31e8116f":"code","fb42c1bd":"code","400c6f3b":"code","b2ecbb23":"code","27f5f31e":"code","be43fb2b":"code","1bee32c9":"code","73bcd292":"markdown","0d3b29c8":"markdown","25d16ac4":"markdown","740c8eee":"markdown","525f30b2":"markdown","a246cbea":"markdown","74235a4e":"markdown","6cac5147":"markdown","bbc3f074":"markdown","f6843ca8":"markdown"},"source":{"45e6732e":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all' #this helps to full output and not only the last lines of putput\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport scipy.sparse\n\nimport warnings\nwarnings.simplefilter('ignore')","0a9fefa2":"data = pd.read_csv('..\/input\/restaurant-data-with-consumer-ratings\/rating_final.csv')\ndata.head()","78540096":"data.info()","7b7d3954":"#Summary statistics\ndata.describe(include = 'all').transpose()","636a2beb":"#No.of unique users, restaurants, no. of ratings, food_ratings, service_ratings\nprint('Unique users: ', data['userID'].nunique())\nprint('Unique restaurant: ', data['placeID'].nunique())\nprint('Total no.of ratings given: ', data['rating'].count())\nprint('Total no.of food ratings given: ', data['food_rating'].count())\nprint('Total no.of service ratings given: ', data['service_rating'].count())","770c9e97":"# How many times has a user rated\nmost_rated_users = data['userID'].value_counts()\nmost_rated_users","b97f3ea1":"#How many times has a restaurant been rated\nmost_rated_restaurants = data['placeID'].value_counts()\nmost_rated_restaurants","89443242":"#What's the rating distribution\nplt.figure(figsize = (8,5))\nsns.countplot(data['rating'])","fe77fd1e":"#What's the food rating distribution\nplt.figure(figsize = (8,5))\nsns.countplot(data['food_rating'])","930a4b38":"#What's the service rating distribution\nplt.figure(figsize = (8,5))\nsns.countplot(data['service_rating'])","e2986d7a":"#How many users have rated more than n places ?\nn = 3\nuser_counts = most_rated_users[most_rated_users > n]\nlen(user_counts)\nuser_counts","b725a808":"#No. of ratings given\nuser_counts.sum()","e04bf9bc":"#Retrieve all ratings given by the above users from the full data\ndata_final = data[data['userID'].isin(user_counts.index)]\ndata_final","4b491e0f":"final_ratings_matrix = data_final.pivot(index = 'userID', columns = 'placeID', values = 'rating').fillna(0)\nfinal_ratings_matrix.head()","d8fd9068":"#Lets calculate the density of the matrix. This is to see how many possible ratings could be given and exactly how many ratings were given \n\n#No. of ratings given\ngiven_num_of_ratings = np.count_nonzero(final_ratings_matrix)\nprint('given_num_of_ratings: ', given_num_of_ratings)\n\n#Total no. of ratings that could have been given \npossible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\nprint('possible_num_of_ratings: ', possible_num_of_ratings)\n\n#Calculate matrix density\ndensity = (given_num_of_ratings \/ possible_num_of_ratings) * 100\nprint('density: {:4.2f}%'.format(density))","308ef8fc":"#No. of users who have rated a resto\ndata_grouped = data.groupby('placeID').agg({'userID':'count'}).reset_index()\ndata_grouped.rename(columns = {'userID': 'score'}, inplace = True )\ndata_sort = data_grouped.sort_values(['score','placeID'], ascending = False)\ndata_sort.head()","ef32c85f":"#Let's rank them based on scores\ndata_sort['Rank'] = data_sort['score'].rank(ascending = 0, method = 'first')\npop_recom = data_sort\npop_recom.head()","c8fa2656":"print('Here are the most popular restaurants')\npop_recom[['placeID','score','Rank']].head()","c798907b":"#Transform the data into a pivot table -> Format required for colab model\npivot_data = data_final.pivot(index = 'userID', columns = 'placeID', values = 'rating').fillna(0)\npivot_data.shape\npivot_data.head()","7c371a46":"#Create a user_index column to count the no. of users -> Change naming convention of user by using counter\npivot_data['user_index'] = np.arange(0, pivot_data.shape[0],1)\npivot_data.head()","bdaf3401":"pivot_data.set_index(['user_index'], inplace = True)\npivot_data.head()","3081fbb3":"#Applying SVD method on a large sparse matrix -> To predict ratings for all resto that weren't rated by a user\n\nfrom scipy.sparse.linalg import svds\n\n#SVD\nU,s, VT = svds(pivot_data, k = 10)\n\n#Construct diagonal array in SVD\nsigma = np.diag(s)\n\n#Applying SVD would output 3 parameters namely\nprint(\"U = \",U) #Orthogonal matrix\nprint('************************************************')\nprint(\"S = \",s) #Singular values\nprint('************************************************')\nprint(\"VT = \", VT) #Transpose of Orthogonal matrix","31e8116f":"#Predict ratings for all restaurants not rated by a user using SVD\nall_user_predicted_ratings = np.dot(np.dot(U,sigma), VT)\n\n#Predicted ratings\npred_data = pd.DataFrame(all_user_predicted_ratings, columns = pivot_data.columns)\npred_data.head()","fb42c1bd":"#Recommend places with the highest predicted ratings\n\ndef recommend_places(userID, pivot_data, pred_data, num_recommendations):\n    user_index  = userID-1 #index starts at 0\n\n    sorted_user_ratings = pivot_data.iloc[user_index].sort_values(ascending = False) #sort user ratings\n\n    sorted_user_predictions = pred_data.iloc[user_index].sort_values(ascending = False)#sorted_user_predictions\n    \n    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis = 1)\n    temp.index.name = 'Recommended Places'\n    temp.columns = ['user_ratings', 'user_predictions']\n    \n    temp = temp.loc[temp.user_ratings == 0]\n    temp = temp.sort_values('user_predictions', ascending = False)\n    print('\\n Below are the recommended places for user(user_id = {}):\\n'. format(userID))\n    print(temp.head(num_recommendations))","400c6f3b":"#Recommend places based on userID, past ratings, predicted ratings, num of places \n\nuserID = 12\nnum_recommedations = 5\nrecommend_places(userID, pivot_data, pred_data, num_recommedations)","b2ecbb23":"#Actual ratings given by the users\nfinal_ratings_matrix.head()\n\n#Average actual rating for each place\n\nfinal_ratings_matrix.mean().head()","27f5f31e":"#Predicted ratings for a place\npred_data.head()\n\n#Average predicted rating for each place\npred_data.mean().head()","be43fb2b":"#Calculate RMSE\n\nrmse_data = pd.concat([final_ratings_matrix.mean(), pred_data.mean()], axis = 1)\nrmse_data.columns = ['Avg_actual_ratings','Avg_predicted_ratings']\nprint(rmse_data.shape)\nrmse_data['place_index'] = np.arange(0, rmse_data.shape[0],1)\nrmse_data.head()","1bee32c9":"RMSE = round((((rmse_data.Avg_actual_ratings - rmse_data.Avg_predicted_ratings) ** 2).mean() ** 0.5),5)\nprint('\\n RMSE SVD Model = {}\\n'.format(RMSE))","73bcd292":"**Note that for sparse matrices, you can use the sparse.linalg.svds() function to perform the decomposition. SVD is useful in many tasks, such as data compression, noise reduction similar to Principal Component Analysis and Latent Semantic Indexing (LSI), used in document retrieval and word similarity in Text mining**","0d3b29c8":"# Import packages and dataset","25d16ac4":"Many ratings are 0 so we are not sure if they are really 0 or users haven't rated them.\n\n# Popularity based Recommender Model\n\nAs the name suggests it recommends based on what is currently trending\/ popular across the site. This is particularly useful when you don't have past data as a reference to recommend product to the user. It is not tailor fit for any particular group of audience or movie.\n\n*For a better understanding you can refer to kernel -> [Popularity based Movie Recommender](https:\/\/www.kaggle.com\/sasha18\/popularity-based-movie-recommendation)*\n\n**Things to do:**\n* No. of users who have rated a resto\n* Rank them based on scores\n* Recommend most popular places","740c8eee":"**As this is a popularity based recommendation, it is not personalized hence the recommendation remain the same for all the users.**\n\n# Collaborative filtering model\n\nUsing Model based Collaborative filtering: Singular Value Decomposition\n\n**Things to do:**\n* Transform the data into a pivot table -> Format required for colab model\n* Create a user_index column to count the no. of users -> Change naming convention of user by using counter\n* Apply SVD method on a large sparse matrix -> To predict ratings for all resto that weren't rated by a user\n* Predict ratings for all restaurants not rated by a user using SVD\n* Wrap it all into a function","525f30b2":"# Recommend top restaurants based on consumer preference using popularity and collaborative recommender systems\n\n![image.png](attachment:image.png)\n\nRecommender\/recommendation system is a subclass of information filtering system that seeks to predict the rating\/ preference a user would give to an item.\n\nThey are primarily used in applications where a person\/ entity is involved with a product\/ service. To further improve their experience with this product, we try to personalize it to their needs. For this we have to look up at their past interactions with this product.\n\nIn one line -> **Specialized content for everyone.**\n\nFor further info, [Wiki](https:\/\/en.wikipedia.org\/wiki\/Recommender_system)\n\n**Types of Recommender System**\n\n* 1). [Popularity Based](https:\/\/www.kaggle.com\/sasha18\/popularity-based-movie-recommendation)\n* 2). Classification Based\n* 3). [Content Based](https:\/\/www.kaggle.com\/sasha18\/recommend-books-using-count-tfidf-on-titles)\n* 4). Collaborative Based\n* 5). [Hybrid Based (Content + Collaborative)](https:\/\/www.kaggle.com\/sasha18\/recommend-top-restaurants-based-on-preference)\n* 6). [Association Based Rule Mining](https:\/\/www.kaggle.com\/sasha18\/perform-market-basket-analysis-with-e-comm-data)\n\nWe use 'rating_final' dataset to recommend restaurants based on popularity & based on Collaborative that is the ratings given by other users.","a246cbea":"# Exploratory Data Analytics\n\nTo understand the dataset in detail, its important to perform EDA.\n\n**Let's answer few questions:**\n* No.of unique users, unique restaurants, no. of ratings, food_ratings, service_ratings\n* How many times has a user rated\n* How many times has a restaurant been rated\n* What's the rating distribution for food, service","74235a4e":"# Evaluate model using RMSE\n\nRMSE is the square root of the average of squared errors. The effect of each error on RMSE is proportional to the size of the squared error; thus larger errors have a disproportionately large effect on RMSE. Consequently, RMSE is sensitive to outliers.\n\n***For more info -> [Wiki](https:\/\/en.wikipedia.org\/wiki\/Root-mean-square_deviation)***\n\n**Things to do:**\n* Actual ratings given by user\n* Predicted ratings for a place\n* Calculate RMSE","6cac5147":"**With this EDA, we can infer:**\n* All 130 restaurants were rated minimum 3 times on a scale of 0 to 2\n* All 138 users have rated minimum 3 times\n* As for the rating distribution, users were quite satisfied with restaurants as significant no. of users have rated 1,2\n\nTotal no. of ratings were 1161, however if each of the user would have rated all the restaurants it would have been a total of 138 * 130 = 17940 ratings\n\n**For a recommendation system model to recommend top prefered restaurants, we need to have each of the users rating all the restaurants. As this is not possible, we have to predict ratings that a user would give to a restaurant.**\n\n**Let's build a dataset containing users who have actively rated atleast n times.**","bbc3f074":"**Summarise your insights.**\n\nPopularity-based recommender system is non-personalised and the recommendations are based on frequency counts, which may not be suitable to the user. Popularity based model will recommend the same 5 places to all users but Collaborative Filtering based model has recommended entire different list based on the user ratings.\n\nModel-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior\/ interaction of the user and it is not dependent on any additional information. In this case we had ratings which showed interaction.","f6843ca8":"**Wrapping into all into a function**\n\n**Things to do**\n* Create a function to recommend places with highest predicted ratings\n* Use the function to recommend places based on userID, past ratings, predicted ratings, num of places "}}