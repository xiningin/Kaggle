{"cell_type":{"7758ec33":"code","be1a95af":"code","c5f6e7b6":"code","b33edff2":"code","a7e971b0":"code","2842fe5f":"code","4dd62336":"code","88b30b02":"code","04ea0cf4":"code","3a47961c":"code","3a48becd":"markdown","5b10717a":"markdown","e1d885d8":"markdown","72e8ce85":"markdown","3479f278":"markdown","8750de7b":"markdown","275300f1":"markdown"},"source":{"7758ec33":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib, typing, pathlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches as mpatches","be1a95af":"train   = pd.read_csv(\"..\/input\/mnist-in-cv\/mnist_classification\/train.csv\")\n\ntrain_y = train[\"label\"]\ntrain_x = train.drop(labels = [\"label\"],axis = 1) \ntrain_x = train_x.values.reshape(-1,28,28,1)\n\ntrain_x.shape, train_y.shape","c5f6e7b6":"plt.figure(figsize=(10, 10))\nfor i in range(1, 10):\n    plt.subplot(330 + i)\n    plt.imshow(train_x[i], cmap=plt.get_cmap('gray'))\n    plt.title(train_y[i])","b33edff2":"colors = [\"blue\", \"green\", \"cyan\", \"red\", \"yellow\", \n          \"magenta\", \"peru\", \"azure\", \"slateblue\", \"plum\"]\n\ndef plot_bbox(bbox_xyxy, label):\n    xmin, ymin, xmax, ymax = bbox_xyxy\n    plt.plot(\n        [xmin, xmin, xmax, xmax, xmin],\n        [ymin, ymax, ymax, ymin, ymin],\n        color=colors[label], \n        label=str(label))\n\ndef read_labels(label_path: pathlib.Path) -> typing.Tuple[np.ndarray]:\n    assert label_path.is_file()\n    labels = []\n    bboxes = []\n    with open(label_path, \"r\") as fp:\n        for line in list(fp.readlines())[1:]:\n            label, xmin, ymin, xmax, ymax = [int(_) for _ in line.split(\",\")]\n            labels.append(label)\n            bboxes.append([xmin, ymin, xmax, ymax])\n    return np.array(labels), np.array(bboxes)","a7e971b0":"train_images = pathlib.Path('..\/input\/mnist-in-cv\/mnist_localization\/train\/images').glob(\"*.png\")\ntrain_labels = pathlib.Path('..\/input\/mnist-in-cv\/mnist_localization\/train\/labels')\n\nfor i, impath in enumerate(train_images):\n    label_path = train_labels.joinpath(\n        f\"{impath.stem}.txt\"\n    )\n    labels, bboxes_xyxy = read_labels(label_path)\n    im = plt.imread(str(impath))\n    plt.imshow(im, cmap=\"gray\")\n    for bbox, label in zip(bboxes_xyxy, labels):\n        plot_bbox(bbox, label)\n    plt.show()\n    if i == 3: break","2842fe5f":"train_images = pathlib.Path('..\/input\/mnist-in-cv\/mnist_detection\/train\/images').glob(\"*.png\")\ntrain_labels = pathlib.Path('..\/input\/mnist-in-cv\/mnist_detection\/train\/labels')\n\nfor i, impath in enumerate(train_images):\n    label_path = train_labels.joinpath(\n        f\"{impath.stem}.txt\"\n    )\n    labels, bboxes_xyxy = read_labels(label_path)\n    im = plt.imread(str(impath))\n    plt.imshow(im, cmap=\"gray\")\n    for bbox, label in zip(bboxes_xyxy, labels):\n        plot_bbox(bbox, label)\n    plt.show()\n    if i == 4: break","4dd62336":"train_set = np.load('..\/input\/mnist-in-cv\/mnist_moving\/mnist_test_seq.npy')\ntrain_set = np.swapaxes(train_set, 0, 1)\ntrain_set = np.expand_dims(train_set, axis=-1)\n\n# ref: https:\/\/keras.io\/examples\/vision\/conv_lstm\/\n# Construct a figure on which we will visualize the images.\nfig, axes = plt.subplots(4, 5, figsize=(15, 10))\n# Plot each of the sequential images for one random data example.\ndata_choice = np.random.choice(range(len(train_set)), size=1)[0]\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(np.squeeze(train_set[data_choice][idx]), cmap=\"gray\")\n    ax.set_title(f\"Frame {idx + 1}\")\n    ax.axis(\"off\")\n\n# Print information and display the figure.\nprint(f\"Displaying frames for example {data_choice}.\")\nplt.show()","88b30b02":"train_images = np.load('..\/input\/mnist-in-cv\/mnist_segmentation\/train_images.npy')\ntrain_masks  = np.load('..\/input\/mnist-in-cv\/mnist_segmentation\/train_masks.npy')\n\ntrain_images.shape, train_masks.shape","04ea0cf4":"def display_grayscale_array(array: np.ndarray, \n                            title: str = '', \n                            ax: matplotlib.axes.Axes = None) -> None:\n    \"\"\"Display the grayscale input image.\n    Parameters:\n        image: This can be either an input digit from MNIST of a input image\n            from the extended dataset.\n        title: If provided, this will be added as title of the plot.\n    \"\"\"\n    ax = ax or plt.gca()\n\n    if len(array.shape) == 3:\n        array = array[..., 0]\n   \n    ax.imshow(array, cmap=plt.cm.binary)\n    ax.axes.set_yticks([])\n    ax.axes.set_xticks([])\n\n    if title:\n        ax.set_title(title)\n\n    if not ax:\n        plt.show()\n\n\ndef display_segmented_image(y: np.ndarray, threshold: float = 0.5,\n                            input_image: np.ndarray = None,\n                            alpha_input_image: float = 0.2,\n                            title: str = '',\n                            ax: matplotlib.axes.Axes = None) -> None:\n    \"\"\"Display segemented image.\n\n    This function displays the image where each class is shown in particular color.\n    This is useful for getting a rapid view of the performance of the model\n    on a few examples.\n\n    Parameters:\n        y: The array containing the prediction.\n            Must be of shape (image_shape, num_classes)\n        threshold: The threshold used on the predictions.\n        input_image: If provided, display the input image in black.\n        alpha_input_image: If an input_image is provided, the transparency of\n            the input_image.\n    \"\"\"\n    ax = ax or plt.gca()\n\n    base_array = np.ones(\n        (y.shape[0], y.shape[1], 3)) * 1\n    legend_handles = []\n\n    for i in range(y.shape[-1]):\n        # Retrieve a color (without the transparency value).\n        colour = plt.cm.jet(i \/ y.shape[-1])[:-1]\n        base_array[y[..., i] > threshold] = colour\n        legend_handles.append(mpatches.Patch(color=colour, label=str(i)))\n\n    ax.imshow(base_array)\n    ax.legend(handles=legend_handles, bbox_to_anchor=(1, 1), loc='upper left')\n    ax.set_yticks([])\n    ax.set_xticks([])\n    ax.set_title(title)\n\n    if input_image is not None:\n        ax.imshow(input_image[..., 0],\n                   cmap=plt.cm.binary, alpha=alpha_input_image)\n\n    if not ax:\n        plt.show()\n\n\ndef plot_class_masks(y_true: np.ndarray, \n                     y_predicted: np.ndarray = None, title='') -> None:\n    \"\"\"Plot a particular view of the true vs predicted segmentation.\n\n    This function separates each class into its own image and\n    does not perform any thresholding.\n\n    Parameters:\n        y_true: True segmentation (image_shape, num_classes).\n        y_predicted: Predicted segmentation (image_shape, num_classes).\n            If y_predicted is not provided, only the true values are displayed.\n    \"\"\"\n    num_rows = 2 if y_predicted is not None else 1\n\n    num_classes = y_true.shape[-1]\n    fig, axes = plt.subplots(num_rows, num_classes, \n                             figsize=(num_classes * 4, num_rows * 4))\n    axes = axes.reshape(-1, num_classes)\n    fig.suptitle(title)\n    plt.tight_layout()\n\n    for label in range(num_classes):\n        axes[0, label].imshow(y_true[..., label], cmap=plt.cm.binary)\n        axes[0, label].axes.set_yticks([])\n        axes[0, label].axes.set_xticks([])\n\n        if label == 0:\n            axes[0, label].set_ylabel(f'Target')\n\n        if y_predicted is not None:\n            if label == 0:\n                axes[1, label].set_ylabel(f'Predicted')\n\n            axes[1, label].imshow(y_predicted[..., label], cmap=plt.cm.binary)\n            axes[1, label].set_xlabel(f'Label: {label}')\n            axes[1, label].axes.set_yticks([])\n            axes[1, label].axes.set_xticks([])\n        else:\n            axes[0, label].set_xlabel(f'Label: {label}')\n\n    plt.show()","3a47961c":"i = np.random.randint(len(train_images))\n\ndisplay_grayscale_array(array=train_images[i])\nplot_class_masks(train_masks[i])\ndisplay_segmented_image(train_masks[i])","3a48becd":"## Classification\n\n- Create classification model. \n    - ..can experiment with logit and softamx output\n    - ..can experiment with sparse and hot target\n- It's a 10 digit classification dataset. But it can be modified to predict even\/odd number and modeling in such way.\n- Some [starters](https:\/\/www.kaggle.com\/c\/digit-recognizer\/code). ","5b10717a":"## Semantic Segmentation\n\n- Each training image contains different number of MNISTs. \n- Build segmentation model.\n- Check [this tutorials](https:\/\/keras.io\/examples\/vision\/deeplabv3_plus\/) on multi-class segmentation modeling with DeepLabV3+. ","e1d885d8":"[**utils - ref of the following cell**](https:\/\/github.com\/LukeTonin\/simple-deep-learning\/blob\/main\/simple_deep_learning\/mnist_extended\/semantic_segmentation.py)","72e8ce85":"## Video Representation\n\n- A sequence of frames of MNIST digits.\n- Check this code example, [NextFrame Video Prediction-ConvLSTM](https:\/\/keras.io\/examples\/vision\/conv_lstm\/) in keras on this dataset.","3479f278":"# DataSet: [MNIST in CV](https:\/\/www.kaggle.com\/ipythonx\/mnist-in-cv)\n\nA small scale extention of the MNIST for the following CV task, ([description](https:\/\/www.kaggle.com\/ipythonx\/mnist-in-cv)). Small dataset for quick test! The following demonstrations is mainly for beginners in machine learning who are passing their days with MNIST. The demonstration is simply highlighting the common computer vision tasks with simple dataset, MNIST.\n\n- Image Classification\n- Detection\n- Localization\n- Video-Sequence Representation\n- Semantic Segmentation.\n- (to-do): Instance Segmentation (part-of-the-dight - CapsuleNet).\n- (to-do): Keypoint Detection.","8750de7b":"## Localization\n\n- Use classification model and visualize the activation function of each of your model's layers.\n- Create bounding box from the heatmap. \n- Compare the predicted bounding box with groung truth boxes.\n\n[utils - ref of the following cell](https:\/\/github.com\/hukkelas\/MNIST-ObjectDetection\/blob\/master\/visualize_dataset.py)","275300f1":"## Detection\n\n- Build a model with two output: one for classification and another for regression (4 unit). \n\n[utils - ref of the following cell](https:\/\/github.com\/hukkelas\/MNIST-ObjectDetection\/blob\/master\/visualize_dataset.py)"}}