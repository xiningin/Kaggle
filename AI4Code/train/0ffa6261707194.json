{"cell_type":{"3719df84":"code","9e80219c":"code","b83fb887":"code","eeb219c7":"code","96f46bba":"markdown","2a26c0a9":"markdown","c2ae8e31":"markdown"},"source":{"3719df84":"# Import necessary libraries\nfrom copy import deepcopy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt","9e80219c":"# Set three centers, the model should predict similar results\ncenter_1 = np.array([1,1])\ncenter_2 = np.array([5,5])\ncenter_3 = np.array([8,1])\n\n# Generate random data and center it to the three centers\ndata_1 = np.random.randn(200, 2) + center_1\ndata_2 = np.random.randn(200,2) + center_2\ndata_3 = np.random.randn(200,2) + center_3\n\ndata = np.concatenate((data_1, data_2, data_3), axis = 0)\n\nplt.scatter(data[:,0], data[:,1], s=7)","b83fb887":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","eeb219c7":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\nplt.scatter(data[:,0], data[:,1], s=7, c=clusters)\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='+', c='red', s=150)\nplt.show()\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\n    \n    plt.scatter(data[:,0], data[:,1], s=7, c=clusters)\n    plt.scatter(centers_new[:,0], centers_new[:,1], marker='+', c='red', s=150)\n    plt.show()\n    \ncenters_new    ","96f46bba":"# Generate Random Data\nGenerate random data normally distributed around 3 centers, with a noise.","2a26c0a9":"# K-Means Clustering\nThis work is based on Mubaris' great work (\nhttps:\/\/mubaris.com\/2017\/10\/01\/kmeans-clustering-in-python\/).\n\nA description of the algorithm can be found:\nhttps:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/cs229-notes7a%202.pdf\n\n![](https:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/k4XcapI.gif?raw=true)","c2ae8e31":"# Create K-Means Algorithm\nGenerate random data normally distributed around 3 centers, with a noise."}}