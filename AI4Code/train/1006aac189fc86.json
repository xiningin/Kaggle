{"cell_type":{"16d60dd1":"code","dd51c95b":"code","b7e8f54c":"code","0f4caae9":"code","59c70555":"code","cc53577c":"code","f8630f0d":"code","9b49f4c2":"code","44c4cc8d":"code","3f5c1fd4":"code","b72c67c5":"code","47f3cf60":"code","e17e3391":"code","50d335ad":"code","c84798a2":"code","195ce0db":"code","93ba69ea":"code","68dcede0":"code","aa8cf402":"code","f3b27439":"code","4a78bb2b":"code","8a3b640b":"code","fe94293d":"code","ebee3424":"code","c2f13f7d":"code","4b81bbc2":"code","dcd1e29c":"code","71794e27":"code","7f5d4203":"code","90d697ea":"code","b40695af":"code","def218fc":"code","41ff0ab6":"code","38c5fa76":"code","2a317db9":"code","851cb44d":"code","b10666e2":"code","a095b33d":"code","0edeeda5":"code","ee9410a7":"code","15103115":"code","81c528ad":"code","0081b219":"code","3e34432e":"code","9a507940":"code","d2376050":"code","5809198d":"code","97be2acd":"code","2c6407b0":"code","cea056c3":"code","7dcfe153":"code","d24d67f9":"code","d99ca765":"code","591692aa":"code","6decc7ab":"code","c810341e":"code","a1ef1dd9":"code","c6820e98":"code","5d9bffb7":"code","0cb10a81":"code","4638fb55":"markdown","156c1134":"markdown","0131a7a2":"markdown","6ee9f9d8":"markdown","433d1775":"markdown"},"source":{"16d60dd1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dd51c95b":"#Import required Library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n## Display all the columns of the dataframe\n\npd.pandas.set_option('display.max_columns',None)","b7e8f54c":"train = pd.read_csv('..\/input\/house-price-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/house-price-prediction\/test.csv')\ntrain.shape, test.shape","0f4caae9":"# To find number of Missing Values\n\nfeature_na = [feature for feature in train.columns if train[feature].isnull().sum() >= 1]\n\nfor value in feature_na:\n    print(value, np.round(train[value].isnull().mean(),3),  \" missing values present\")","59c70555":"# replacing Missing value of categorical variable with New Class Median\n\ncat_na = [feature for feature in train.columns if train[feature].isnull().sum() > 1 and train[feature].dtypes == \"O\"]\ncat_na","cc53577c":"def cat_missing_imputation(data, cat_na):\n    df = data.copy()\n    df[cat_na] = df[cat_na].fillna('NA')\n    return df","f8630f0d":"train = cat_missing_imputation(train, cat_na)","9b49f4c2":"test = cat_missing_imputation(test, cat_na)","44c4cc8d":"test[cat_na].isnull().sum()","3f5c1fd4":"# Replacing missing values of Numeric columns with Median\n\nnum_na = [feature for feature in train.columns if train[feature].isnull().sum() > 1 and train[feature].dtypes != \"O\"]\nnum_na","b72c67c5":"for value in num_na:\n    train[value].fillna(train[value].median(), inplace = True)\n    test[value].fillna(test[value].median(), inplace = True)","47f3cf60":"test[num_na].isnull().sum()","e17e3391":"# Extract Numeric variables & Categorical Variables\n\nnumeric = [feature for feature in train.columns if train[feature].dtypes != \"O\"]\nobject = [feature for feature in train.columns if train[feature].dtypes == \"O\"]","50d335ad":"print(len(numeric))\nprint(len(object))","c84798a2":"# Extract Date COlumns from numeric \n\ndate_ft = [f for f in numeric if 'Yr' in f or 'Year' in f]\ndate_ft","195ce0db":"# subtract all year value from YrSold variable, to get meaningful insights\n\nfor value in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n    train[value] = train['YrSold'] - train[value]\n    test[value] = test['YrSold'] - test[value]","93ba69ea":"test[date_ft].head()","68dcede0":"# Lets identify Discrete Numeric Variables\n\ndiscrete = [f for f in numeric if len(train[f].unique()) < 30 and f not in date_ft]\ndiscrete","aa8cf402":"for value in discrete:\n    train.groupby(value)['SalePrice'].median().plot.barh()\n    plt.xlabel(value)\n    plt.title(value)\n    plt.show()","f3b27439":"# Continuous Numeric Variables\n\ncontinuous = [f for f in numeric if len(train[f].unique()) > 30 and f not in date_ft and f not in ['Id', 'SalePrice']]\ncontinuous","4a78bb2b":"# Analysis of Continuous Numeric variables\n\nfor value in continuous:\n    train[value].hist(bins = 25)\n    plt.xlabel(value)\n    plt.show()","8a3b640b":"for feature in continuous:\n    df = train.copy()\n    if 0 in train[feature].unique():\n        pass\n    \n    else:\n        train[feature] = np.log(train[feature])\n        test[feature] = np.log(test[feature])\n        df['SalePrice'] = np.log(df['SalePrice'])\n        plt.scatter(train[feature], df['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel(\"SalePrice\")\n        plt.show()\n        ","fe94293d":"train[['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea']].describe()","ebee3424":"test[['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea']].describe()","c2f13f7d":"for feature in object:\n    \n    temp=train.groupby(feature)['SalePrice'].count()\/train.shape[0]\n    temp_df=temp[temp>0.01].index\n    train[feature]=np.where(train[feature].isin(temp_df),train[feature],'Rare_var')\n    test[feature]=np.where(test[feature].isin(temp_df),test[feature],'Rare_var')","4b81bbc2":"train.shape, test.shape","dcd1e29c":"for feature in object:\n    labels = train.groupby(feature)['SalePrice'].mean().sort_values().index\n    order = {k:i for i, k in enumerate(labels, 0)}\n    train[feature] = train[feature].map(order)\n    test[feature] = test[feature].map(order)","71794e27":"train.head()","7f5d4203":"test.head()","90d697ea":"# Separating Dependent and Independent variable\n\nx = train.drop(['Id', 'SalePrice'], axis = 1)\ny = train[['SalePrice']]\n\ntest_new = test.drop('Id', axis = 1)\n\nx.shape, test_new.shape","b40695af":"# Feature Scaling\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()","def218fc":"xscale = scaler.fit_transform(x)\ntest_scale = scaler.transform(test_new)","41ff0ab6":"xscale.shape, test_scale.shape","38c5fa76":"x_final = pd.DataFrame(xscale, columns = x.columns)\ntest_final = pd.DataFrame(test_scale, columns = test_new.columns)","2a317db9":"x_final.head()","851cb44d":"test_final.head()","b10666e2":"x_final.shape, test_final.shape","a095b33d":"## for feature slection\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\n# to visualise al the columns in the dataframe\npd.pandas.set_option('display.max_columns', None)","0edeeda5":"y = np.log(train['SalePrice'])\ny.head()","ee9410a7":"# Apply feature Selection\n\nfeature = SelectFromModel(Lasso(alpha = 0.001, random_state = 0))\nfeature.fit(x_final, y)","15103115":"feature.get_support()","81c528ad":"selected_feat = x_final.columns[(feature.get_support())]","0081b219":"len(selected_feat)","3e34432e":"x_select = x_final[selected_feat]\ntest_select = test_final[selected_feat]\nx_select.shape, test_select.shape","9a507940":"x_select.head()","d2376050":"test_select.head()","5809198d":"import xgboost\nregressor=xgboost.XGBRegressor()","97be2acd":"booster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1]","2c6407b0":"## Hyper Parameter Optimization\n\n\nn_estimators = [100, 500, 900, 1100, 1500]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\n\n\n# Define the grid of hyperparameters to search\nparam_grid = {\n    'n_estimators': n_estimators,\n    'learning_rate':learning_rate,\n    'booster':booster,\n    'base_score':base_score\n    }","cea056c3":" #Set up the random search with 4-fold cross validation\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=param_grid,\n            cv=3, n_iter=20,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","7dcfe153":"random_cv.fit(x_select, y)","d24d67f9":"random_cv.best_estimator_","d99ca765":"regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n       max_depth=2, min_child_weight=1, missing=1, n_estimators=900,\n       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n       silent=True, subsample=1)","591692aa":"regressor.fit(x_select, y)","6decc7ab":"test_select['BsmtUnfSF'].fillna(test_select['BsmtUnfSF'].median(), inplace = True)","c810341e":"test_select['BsmtFullBath'].fillna(test_select['BsmtFullBath'].median(), inplace = True)\ntest_select['KitchenQual'].fillna(test_select['KitchenQual'].median(), inplace = True)\ntest_select['GarageCars'].fillna(test_select['GarageCars'].median(), inplace = True)","a1ef1dd9":"test_select.isnull().sum()","c6820e98":"prediction = regressor.predict(test_select)","5d9bffb7":"final = np.exp(prediction)\nfinal","0cb10a81":"prediction = pd.DataFrame(final, columns = ['predict'])\nprediction.to_csv('final output.csv')","4638fb55":"# Data Study and Feature Engineering","156c1134":"All continuous variables are Skewed hence performing Natural Log transformation to convert all into Normal Distribution","0131a7a2":"# Data Preprocessing","6ee9f9d8":"# Model Building","433d1775":"Feature Selection"}}