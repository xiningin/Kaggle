{"cell_type":{"34fd5d6c":"code","dfb0e491":"code","c3e1b9d5":"code","bc257153":"code","e37e5deb":"code","e944feed":"code","cfe7eb5b":"code","d1cc806c":"code","8cc0488f":"code","b23da411":"code","5d66ea10":"code","2899564c":"code","093dd5f8":"code","2db198d3":"code","b32e9840":"code","347f86f6":"code","60ee5c01":"code","2929ec9c":"code","2a1084dc":"code","f790ef39":"code","20a00fae":"code","f3437311":"code","3b974ca0":"code","8288042d":"code","5649631d":"code","51796f6a":"code","8ff4c702":"code","28a92b23":"code","bc11bd07":"code","94bbafc8":"code","1dc8c9d7":"code","0b40e03b":"code","9f071046":"code","1f7de06d":"code","3866992a":"code","5cf96688":"code","19c38bb9":"code","14f098ac":"code","bac8a4f1":"code","ddf0e11e":"markdown","f728f78a":"markdown","0750baf9":"markdown","a3046b17":"markdown","609adcec":"markdown","24783a10":"markdown","65c3d24c":"markdown","4a1ab662":"markdown","ca70ac13":"markdown","2df42ea5":"markdown","1a300abb":"markdown","cac16360":"markdown","ec130d79":"markdown","2ce75f43":"markdown","eef68d80":"markdown","dcf52ead":"markdown","d400b9ea":"markdown","e98dcd6b":"markdown","9c8241a2":"markdown","606ac4a3":"markdown","05cbe88a":"markdown","1d88548a":"markdown","9fe48791":"markdown","1e6202d0":"markdown","3c82b15b":"markdown","e7cc82fd":"markdown","726e3b4d":"markdown","d65f1794":"markdown","3cfc4b8a":"markdown","29bb9a07":"markdown"},"source":{"34fd5d6c":"#Import data manipulation tools \nimport numpy as np \nimport pandas as pd\n\n#Import data visualization tools \nimport seaborn as sns \nimport matplotlib.pyplot as plt","dfb0e491":"#Read train and test data\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nalldata = [train_df,test_df]\n\nprint(train_df.columns)\nprint(test_df.columns)","c3e1b9d5":"train_df.info()\ntest_df.info()","bc257153":"train_df.describe()","e37e5deb":"test_df.describe()","e944feed":"survived = train_df[\"Survived\"]\nsur_gender = train_df.loc[train_df[\"Survived\"]==1, \"Sex\"]\ndeaths_gender = train_df.loc[train_df[\"Survived\"]==0, \"Sex\"]\nf, ax = plt.subplots(1, 3, figsize=(15,4))\ndef autopct_surv(values):\n    def surv(pct):\n        total = len(values)\n        val = int(round(pct*total\/100.0))\n        return '{p:.1f}%\\n{v:d}'.format(p=pct,v=val)\n    return surv\nsurvived.value_counts().plot.pie(autopct=autopct_surv(survived), ax=ax[0], label='', labels= ['died', 'survived'], title='Survival %', colors=[\"red\", \"green\"], startangle=15)\nsur_gender.value_counts().plot.pie(autopct=autopct_surv(sur_gender), ax=ax[1], label='', title='Survivors by gender', colors=[\"orchid\", \"deepskyblue\"], startangle=0)\ndeaths_gender.value_counts().plot.pie(autopct=autopct_surv(deaths_gender), ax=ax[2], label='', title='Deaths by gender', colors=[\"deepskyblue\",\"orchid\"], startangle=150)","cfe7eb5b":"age = train_df[\"Age\"]\nsur_age = train_df.loc[train_df[\"Survived\"]==1, \"Age\"]\ndeaths_age = train_df.loc[train_df[\"Survived\"]==0, \"Age\"]\n\nagebins = pd.cut(age, [0,10, 20, 30, 40, 50, 60, 70, 80])\nsurbins = pd.cut(sur_age, [0,10, 20, 30, 40, 50, 60, 70, 80])\ndagebins = pd.cut(deaths_age, [0,10, 20, 30, 40, 50, 60, 70, 80])\n\nage_groups = age.groupby(agebins).agg(['count', 'sum'])\nsurage_groups = sur_age.groupby(surbins).agg(['count', 'sum'])\ndage_groups = deaths_age.groupby(dagebins).agg(['count','sum'])\n\nagelist = age_groups['count'].tolist()\nsurlist = surage_groups['count'].tolist()\ndeagelist = dage_groups['count'].tolist()\n\nage_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80']\n\nbarwidth = 0.25\nr1 = np.arange(len(agelist))\nr2 = [x + barwidth for x in r1]\nr3 = [x + barwidth for x in r2]\nplt.figure(figsize=(12, 5))\n \nplt.bar(r1, agelist, color='#7f6d5f', width=barwidth, edgecolor='white', label='All passengers by age')\nplt.bar(r2, surlist, color='forestgreen', width=barwidth, edgecolor='white', label='Survived passengers by age')\nplt.bar(r3, deagelist, color='red', width=barwidth, edgecolor='white', label='Death passengers by age')\n \nplt.xlabel('Passengers by age', fontsize=14)\nplt.xticks([r + barwidth for r in range(len(agelist))], age_labels)\n\ndef agelabels(i, x):\n    for index,data in enumerate(x):\n        if i == 0:\n            index = index-0.1\n        elif i == 1:\n            index = index+0.18\n        else:\n            index = index+0.4\n        plt.text(x=index , y =data+1 , s=f\"{data}\" , fontdict=dict(fontsize=10))\n\nallagelists = [agelist,surlist,deagelist]\nfor i, x in enumerate(allagelists):\n    agelabels(i, x)\n    \n# Create legend & Show graphic\nplt.legend()\nplt.show()","d1cc806c":"fare = train_df[\"Fare\"]\nsurfare = train_df.loc[train_df[\"Survived\"]==1, \"Fare\"]\ndeathsfare = train_df.loc[train_df[\"Survived\"]==0, \"Fare\"]\n\nfarebins = pd.cut(fare, [-1, 1,10, 20,30, 60, 513])\nsurbins = pd.cut(surfare, [-1, 1,10, 20,30, 60, 513])\ndbins = pd.cut(deathsfare, [-1, 1,10, 20,30, 60, 513])\n\nfare_groups = fare.groupby(farebins).agg(['count', 'sum'])\nsurfare_groups = surfare.groupby(surbins).agg(['count', 'sum'])\ndfare_groups = deathsfare.groupby(dbins).agg(['count', 'sum'])\n\nprint(fare_groups['sum'], fare_groups['count'])\nprint(fare.mean(), surfare.mean(), deathsfare.mean())\n\nfaregrouplist = fare_groups['count'].tolist()\nsfgrouplist = surfare_groups['count'].tolist()\ndfgrouplist = dfare_groups['count'].tolist()\nfare_labels = ['0$', '1-10$', '11-20$', '21-30$', '31-60$', '61-513$']\n\nf, ax = plt.subplots(1, 3, figsize=(15,4))\ndef autopct_fare(values):\n    def farepct(pct):\n        total = sum(values)\n        val = int(round(pct*total\/100.0))\n        return '{p:.1f}%\\n{v:d}'.format(p=pct,v=val)\n    return farepct\nfare_groups['count'].plot.pie(labels=fare_labels, autopct=autopct_fare(faregrouplist), ax=ax[0], title='Share of ticket fare ranges\\nMean: 32.20$', label='', startangle=15)\nsurfare_groups['count'].plot.pie(labels=fare_labels, autopct=autopct_fare(sfgrouplist), ax=ax[1], title='Ticket fare group share of survivors\\nMean: 48.40$', label='', startangle=50)\ndfare_groups['count'].plot.pie(labels=fare_labels, autopct=autopct_fare(dfgrouplist), ax=ax[2], title='Ticket fare group share of deaths\\nMean: 21.12$', label='')\nplt.show()","8cc0488f":"parchbins = pd.cut(train_df['Parch'], np.arange(-1,9))\nsibbins = pd.cut(train_df['SibSp'], np.arange(-1,9))\n\np_groups = train_df['Parch'].groupby(parchbins).agg(['count', 'sum'])\ns_groups = train_df['SibSp'].groupby(sibbins).agg(['count', 'sum'])\n\nparlist = p_groups['count'].tolist()\nsiblist = s_groups['count'].tolist()\n\n#####\nlabels = ['0','1','2','3','4','5','6','7','8']\nx = np.arange(len(labels))\nwidth = 0.35  \n\nfig, ax = plt.subplots(figsize=(10,5))\nrects1 = ax.bar(x - width\/2, parlist, width, label='# of parents \/ children each passenger had aboard')\nrects2 = ax.bar(x + width\/2, siblist, width, label='# of siblings \/ spouses each passenger had aboard')\n\n\nax.set_title('Passengers with relatives aboard', fontsize=14)\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n\nautolabel(rects1)\nautolabel(rects2)\n\nfig.tight_layout()\n\nplt.show()\n\n###\n\ntrain_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\ntrain_df['Family'].loc[train_df['Family'] > 0] = 1\ntrain_df['Family'].loc[train_df['Family'] == 0] = 0\n\ntest_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\ntest_df['Family'].loc[test_df['Family'] > 0] = 1\ntest_df['Family'].loc[test_df['Family'] == 0] = 0\n\nfig, ax = plt.subplots(1,2,sharex=True,figsize=(10,5))\nsns.countplot(x='Family', data=train_df, order=[1,0], ax=ax[0])\nfamily_surv = train_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\nsns.barplot(x='Family', y='Survived', data=family_surv, order=[1,0], ax=ax[1])\nax[0].set(xlabel=\"With family = 1\\n Alone = 0\", ylabel = \"# of passengers\")\nytix = [\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\"]\nax[1].set(xlabel=\"With family = 1\\n Alone = 0\", ylabel = \"Survived\", yticklabels=ytix)","b23da411":"ytix2 = [\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\"]\nemb = train_df[['Embarked', 'Survived']].groupby(['Embarked']).mean().plot(kind='barh')\nemb.set(xlabel=\"Survived\", ylabel = \"Embarked\", xticklabels=ytix2)\nemb.plot()","5d66ea10":"#Edit unique titles for both train and test dataframe\nfor dataframe in alldata:\n    dataframe['Titled_name'] = dataframe.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n    dataframe['Titled_name'] = dataframe['Titled_name'].replace(['Lady', 'the Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Unique')\n    dataframe['Titled_name'] = dataframe['Titled_name'].replace('Mlle', 'Miss')\n    dataframe['Titled_name'] = dataframe['Titled_name'].replace('Ms', 'Miss')\n    dataframe['Titled_name'] = dataframe['Titled_name'].replace('Mme', 'Mrs')\n\n#train_df['Titled_name'].value_counts()\nfig, ax =plt.subplots(1,2,sharex=True,figsize=(12,6))\ntrain_df['Titled_name'].value_counts().sort_index(ascending=False).plot(kind='bar', ax=ax[0])\n#titled_surv = train_df[['Titled_name', 'Survived']].groupby(['Titled_name'], as_index=False).mean()\ntrain_df[['Titled_name', 'Survived']].groupby(['Titled_name']).mean().plot(kind='bar', ax=ax[1])\nytix2 = [\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\"]\nax[0].set(xlabel=\"Name title\", ylabel = \"# of passengers\")\nax[1].set(xlabel=\"Name title\", ylabel = \"Survived\", yticklabels=ytix2)\n#ax1.set_xticks(['Master', 'Miss', 'Mr', 'Mrs', 'Unique'])\nprint(train_df['Titled_name'].value_counts())\n#sns.barplot(x='Titled_name', y='Survived', data=titled_surv, ax=ax[1])\n#ytix = [\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\"]","2899564c":"#Drop passenger id from train_df, so it doesn't affect for accuracy:\ntrain_df = train_df.drop(['PassengerId'], axis=1)","093dd5f8":"train_df = train_df.drop(['Name','Ticket','Cabin'], axis=1)\ntest_df = test_df.drop(['Name','Ticket','Cabin'], axis=1)","2db198d3":"print(train_df[\"Embarked\"].value_counts())\ntrain_df['Embarked'] = train_df['Embarked'].fillna(\"S\")","b32e9840":"train_df[\"Embarked\"] = train_df[\"Embarked\"].replace( {'C': 0, 'Q': 1, 'S': 2} ).astype(int)\ntest_df[\"Embarked\"] = test_df[\"Embarked\"].replace( {'C': 0, 'Q': 1, 'S': 2} ).astype(int) ","347f86f6":"print(train_df[\"Embarked\"].head())","60ee5c01":"train_df[\"Sex\"] = train_df[\"Sex\"].replace( {'male': 0, 'female': 1} ).astype(int) \ntest_df[\"Sex\"] = test_df[\"Sex\"].replace( {'male': 0, 'female': 1} ).astype(int) ","2929ec9c":"print(train_df[\"Sex\"].head())","2a1084dc":"train_df['Age'].fillna(train_df['Age'].dropna().mean(), inplace=True)\ntest_df['Age'].fillna(test_df['Age'].dropna().mean(), inplace=True)","f790ef39":"train_df['Age'].round(decimals=0).astype(int)\ntest_df['Age'].round(decimals=0).astype(int)","20a00fae":"train_df = train_df.astype({\"Age\": int})\ntest_df = test_df.astype({\"Age\": int})","f3437311":"test_df.info()\ntrain_df.info()","3b974ca0":"test_df['Fare'].fillna(test_df['Fare'].dropna().mean(), inplace=True)\nfareranges = [-1, 10, 20,30, 60, np.inf]\ntrain_df['FareRange'] = pd.cut(train_df['Fare'], fareranges, labels=np.arange(5))\ntest_df['FareRange'] = pd.cut(test_df['Fare'], fareranges, labels=np.arange(5))","8288042d":"train_df['FareRange'].head()","5649631d":"test_df[\"Titled_name\"] = test_df[\"Titled_name\"].replace( {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Unique': 4} ).astype(int) \ntrain_df[\"Titled_name\"] = train_df[\"Titled_name\"].replace( {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Unique': 4} ).astype(int) ","51796f6a":"train_df.head()","8ff4c702":"test_df.head()","28a92b23":"#drop fare\ntrain_df = train_df.drop('Fare', axis=1)\ntest_df = test_df.drop('Fare', axis=1)","bc11bd07":"#drop Parch and SibSp, because we have Family column\ntrain_df = train_df.drop(['Parch', 'SibSp'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp'], axis=1)","94bbafc8":"#Change FareRange to int\ntrain_df = train_df.astype({\"FareRange\": int})\ntest_df = test_df.astype({\"FareRange\": int})","1dc8c9d7":"corr=train_df.corr()\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, linewidths=0.03,\n            square=True,annot=True,cmap='viridis',linecolor=\"white\")\nplt.title('Correlation between columns');","0b40e03b":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","9f071046":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(X_train, Y_train)\nY_pred = gnb.predict(X_test)\nacc_gnb = round(gnb.score(X_train, Y_train) * 100, 2)\nacc_gnb","1f7de06d":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","3866992a":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 1)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","5cf96688":"from sklearn import svm\n\nsvc = svm.SVC(kernel='linear')\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","19c38bb9":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis()\nlda.fit(X_train, Y_train)\nY_pred = lda.predict(X_test)\nacc_lda = round(lda.score(X_train, Y_train) * 100, 2)\nacc_lda","14f098ac":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(n_estimators=7,learning_rate=1.1)\ngbc.fit(X_train,Y_train)\nY_pred = gbc.predict(X_test)\nacc_gbc = round(gbc.score(X_train, Y_train) * 100, 2)\nacc_gbc","bac8a4f1":"classifierlist = [f\"Gaussian Naive Bayes: {acc_gnb}\", f\"Decisision Tree Classifier: {acc_decision_tree}\", f\"K-Nearest Neighbours: {acc_knn}\", \n                  f\"Support Vector Machines: {acc_svc}\" ,f\"Linear Discriminant Analysis: {acc_lda}\", f\"Gradient Boosting Classifier: {acc_gbc}\"]\nfor x in classifierlist:\n    print(x)","ddf0e11e":"### Drop columns from train and test data\nName doens't have affect for analyse.  \nTicket is mixed alphanumerical, not good for analyzing.  \nCabin has so many missing values in both datasets, so it isn't good for analyse.  ","f728f78a":"### Name title to int","0750baf9":"### K-Nearest Neighbours","a3046b17":"### Change letters of Embarked port to numerical \nTraining dataset has 2 missing values, so I have to figure out the most common embarked port to fill these missing values with most common value.  \nThe most common value is S, so I fill missing values with S.","609adcec":"### Embarked - Did port of departure had impact on survival?  \nPassengers who were boarded from Cherbourg had better better probability to survive than mean. Passengers from port of Queenstown had around mean chance to survive and passengers from Southampton and the worst chance to survive.","24783a10":"### Fare - Did rich people survive?\nOver half of the training dataset passengers paid 20 or less fare. 15 passengers had a free trip according of training data. \n769\/891 passengers paid 60 or less. 122\/891 passengers paid more than 60 fare and sum of their fares were more than those 769 passengers who paid 60 or less fare.\nThose who paid more than 60 fare were only who had better chance to survive than die.","65c3d24c":"### Name titles - Did passengers with unique title in name survive?\nPeople with female title had the best chance to survive, like I compared earlier (male\/female). For men those had Master in title had much better chance to survive than those who were Mr. Passengers or crew who had unique title had about mean chance to survive.","4a1ab662":"## **Overview for train & test data**\nMost of the values are numerical (int or float), only 5 string values (object).   \nTrain data Age column has 177 missing values.  \nTrain data Cabin column has 687 missing values out of 891 values total, so I think it can't be used for analyzing.   \nTest data has 86 missing values in Age column and 327 missing values in Cabin column.  \nIn both datasets Age column has many missing values, so it may cause some negative correlation between train and test datasets.  \nCabin has so many missing values in both datasets that I think it can't be used at all.   \nEmbarked has only 2 missing values in training data, which can be filled with some values.  ","ca70ac13":"### Support Vector Machines","2df42ea5":"### Age - How did age matter for surviving?\nAge group between 0 and 10 was only age group which had more *survivors* than deaths.  \nThe worst survival rate was in age group 71-80, only 1\/5 survived. 61-70 years old had almost just as bad chance to surivive (23,5%).","1a300abb":"### Age - Fill missing values with mean values in test and train data, round age and convert to int.","cac16360":"The test dataset seems not having insuperable big differences to train dataset.","ec130d79":"### Sex - Converting gender to 0 = male, 1 = female","2ce75f43":"# Titanic - My first data science project","eef68d80":"### Linear Discriminant Analysis","dcf52ead":"### Fare - Fill one missing value in test data, change fares to faregroups 1: 0-10 2: 11-20 3: 21-30 4: 31-60 5: 60<","d400b9ea":"### **Survived - Were men better survivers than women?** \nMore than 60% of the people in training data died, 85% of them were male.","e98dcd6b":"### Gradient Boosting Classifier","9c8241a2":"## **Train and test dataset columns**\n   PassengerId is only the index value for passenger in the list.   \n   Name value is passenger's name.  \n      \nNumerical columns:  \n    Age: Age of passenger  \n    Fare: Passenger fare \n    Parch: # of parents \/ children aboard the Titanic  \n    Sibsp: # of siblings \/ spouses aboard the Titanic  \n  \nCategorical columns:  \n    Sex: male\/female  \n    Ticket: ticket number  \n    Cabin: cabin number  \n    Survived: 0 died \/ 1 survived (Only in train data)  \n    Pclass: 1st, 2nd, 3rd  \n    Embarked: Port of embarkation C = Cherbourg, Q = Queenstown, S = Southampton  ","606ac4a3":"As my first project I succeeded pretty well. Almost 94% accuracy on training set with Decission Tree Classifier.  \nI spent too much time for making nice looking charts at start, things can be done much more easily.  \nI think the key to get accurate score from test is to find similarities between train and test data.","05cbe88a":"Changing train and test datasets Embarked ports to numerical","1d88548a":"### Decisision Tree Classifier","9fe48791":"## Testing for training data","1e6202d0":"## Editing data to numerical\nI think in this dataset it is a good idea to try to make the data look the same for each column to gain good accuracy in final test. Also important to delete those columns which I think might have negative impart on final result. ","3c82b15b":"### Correlation test for new columns","e7cc82fd":"## **Train data description**  \n38,4% of people in training data survived. The survival rate of all passengers was 32,5% (1502 out of 2224) according [Kaggle description](http:\/\/www.kaggle.com\/c\/titanic\/overview).  \nThe mean age in train data is 29.7 years, min age is 0.4 years and max age is 80 years.  \nThe mean fare was 32.2, minimum fare 0.0 and maximum fare 512.3.  ","726e3b4d":"### Gaussian Naive Bayes","d65f1794":"## Introduction\n\nBefore I started doing my first data analysis project I was trying to figure out what would be the best project to start with. At first, I thought it would be good to try to stand out from the rest. However, I ended up making Kaggle\u2019s most popular project, Titanic, because it seemed clear to understand, interesting, and suitably challenging for a beginner. I thought it was good to leave time for the analyzes as well, and I didn\u2019t want to spend forever doing one project to get the most diverse experience possible. I hope a lot of comments and advice to improve my work.","3cfc4b8a":"### Parch & Siblings - how well people with families survived compared to the lonely passengers?\nMost of the people in the cruise travelled alone. Those who were aboard with family had around 50% chance to survive and those who were alone had only around 30% chance to survive.","29bb9a07":"## Final thoughts - Make it simple and remember the test accuracy is the most important"}}