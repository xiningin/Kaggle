{"cell_type":{"95141468":"code","7c0c91ab":"code","9aa5f73f":"code","49b9e880":"code","37c176c7":"code","4d4b5eda":"code","8a7a2763":"code","be91a368":"code","8130d4d6":"code","d1176aa5":"code","80bc27ef":"code","189ff1f7":"code","f70148eb":"code","c319aabe":"code","85e4fa27":"code","a9233482":"code","3460d78e":"code","66aeb5bf":"code","f2709a91":"code","51f9052c":"code","d03ee994":"code","6304aa50":"code","cbc12551":"code","ac166898":"code","d591fc30":"code","670aceae":"code","158ef766":"code","f97da4be":"code","690f96ce":"code","9ef81a74":"code","690e8d0f":"code","98552f88":"code","1446dc91":"code","102195aa":"code","06dfd32e":"code","583ca609":"code","ddd4a050":"code","ee588597":"code","37b90695":"code","5de726c6":"code","95d0d16b":"code","c8d2890a":"code","c6e90548":"code","1db06571":"markdown","fa021b05":"markdown","2cb90596":"markdown","6aef4eac":"markdown","eccb1fd8":"markdown","5a992da6":"markdown","45701873":"markdown","18cfeaab":"markdown","34a83bc7":"markdown","9106c3c8":"markdown","71dc9c7b":"markdown","ff4515ff":"markdown","b1a8ec6f":"markdown","056b674d":"markdown","845613a9":"markdown","52fa045e":"markdown","873fb627":"markdown","d6f7e36f":"markdown","b52e4447":"markdown","3cb18c61":"markdown","553dbdb9":"markdown","85f962a0":"markdown","98b7d3d9":"markdown","e8e93d78":"markdown","c8743ae7":"markdown","37cb85d5":"markdown","0ed1c194":"markdown"},"source":{"95141468":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime as dt\n\n# map creation\nimport cartopy.crs as ccrs\nimport cartopy\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n\n# data visualization \nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\n# stat on data\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n# feature reduction\nfrom sklearn.decomposition import PCA\n\n#--- data clustering\nfrom sklearn import cluster\n\n#---- Machine learning\n# data preparation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n# model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\n\n# hyperparameter tunnig\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# Import necessary modules for neutral network\nimport keras\nfrom keras.layers import Dense, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, History\n# Model evaluation\nimport math\nfrom sklearn import metrics\nfrom statsmodels.graphics.api import abline_plot","7c0c91ab":"# Load the seismic catalog \ncatalogue = pd.read_csv(r'..\/input\/oklahoma-earthquakes-and-saltwater-injection-wells\/okQuakes.csv')\ncatalogue.head(3)","9aa5f73f":"plt.figure(figsize=(10,10))\n\nax1 = plt.axes(projection=ccrs.PlateCarree())\nax1.set_extent([-105, -93, 29,41], crs=ccrs.PlateCarree())\n\n# add color\nax1.add_feature(cfeature.OCEAN.with_scale('10m'))\nax1.add_feature(cfeature.LAND)\nax1.add_feature(cfeature.STATES)\nax1.add_feature(cfeature.RIVERS)\nax1.coastlines()\n\n# add grid\ngl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='darkgray', alpha=0.5, linestyle='--')\ngl.top_labels = False\ngl.right_labels = False\ngl.xlocator = mticker.FixedLocator([-102,-99,-96])\ngl.ylocator = mticker.FixedLocator([33, 36,39])\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\ngl.xlabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\ngl.ylabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\n\n#\nax1 = sns.scatterplot(x =catalogue['longitude'], y=catalogue['latitude'], hue =catalogue['mag'],size =catalogue['mag'])\n\n# set title\nax1.set_title('seismic events in catalogue',size=15)\n\nplt.show()","49b9e880":"# select seismic event around Oklahoma \ncatalogue_ok = catalogue[(catalogue['longitude']>=-102)&(catalogue['longitude']<=-94.5)&\n                        (catalogue['latitude']>=33)&(catalogue['latitude']<=39)]\ncatalogue_ok.head(2)","37c176c7":"plt.figure(figsize=(10,10))\n\n# SHOW LOCATION OF THE GEYSER GEOTHERMAL FIELD\nax1 = plt.axes(projection=ccrs.PlateCarree())\nax1.set_extent([-105, -93, 29,41], crs=ccrs.PlateCarree())\n\n# add color\nax1.add_feature(cfeature.OCEAN.with_scale('10m'))\nax1.add_feature(cfeature.LAND)\nax1.add_feature(cfeature.STATES)\nax1.add_feature(cfeature.RIVERS)\nax1.coastlines()\n\n# add grid\ngl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='darkgray', alpha=0.5, linestyle='--')\ngl.top_labels = False\ngl.right_labels = False\ngl.xlocator = mticker.FixedLocator([-102,-99,-96])\ngl.ylocator = mticker.FixedLocator([33, 36,39])\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\ngl.xlabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\ngl.ylabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\n\n# Selected earthquakes\nax1 = sns.scatterplot(x =catalogue_ok['longitude'], y=catalogue_ok['latitude'], hue =catalogue_ok['mag'],size =catalogue_ok['mag'])\n\n# set title\nax1.set_title('Selected seismic events',size=15)\n\nplt.show()","4d4b5eda":"catalogue_ok['time'] = pd.to_datetime(catalogue_ok['time'])\ncatalogue_ok = catalogue_ok.set_index('time')\ncatalogue_ok.tail(2)","8a7a2763":"# finction to visualize missing value\ndef get_percentage_nan_values(data, thresh=20, color='black', edgecolor='black', width=15, height=3):\n    \"\"\"\n    visualize the percentage of missing values in each columns\n    SOURCE: https:\/\/www.kaggle.com\/amiiiney\/price-prediction-regularization-stacking\n    \"\"\"\n    \n    plt.figure(figsize=(width,height))\n    percentage=(data.isnull().mean())*100\n    percentage.sort_values(ascending=False).plot.bar(color=color, edgecolor=edgecolor)\n    plt.axhline(y=thresh, color='r', linestyle='-')\n    plt.title('Missing values percentage per column', fontsize=20, weight='bold' )\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh+12.5, f'Columns with more than {thresh}% missing values', fontsize=12, color='crimson',\n         ha='left' ,va='top')\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh - 5, f'Columns with less than {thresh} missing values', fontsize=12, color='green',\n         ha='left' ,va='top')\n    plt.xlabel('Columns', size=15, weight='bold')\n    plt.ylabel('Missing values percentage')\n    plt.yticks(weight ='bold')\n    \n    return plt.show()","be91a368":"# show percentage and distribution missing values per columns\nget_percentage_nan_values(catalogue_ok, 20, color=sns.color_palette('Reds',15))","8130d4d6":"# drop columns with more than 20% of missing value\ncatalogue_ok = catalogue_ok.dropna(thresh=len(catalogue_ok)*0.8, axis=1)","d1176aa5":"catalogue_ok.isnull().sum()","80bc27ef":"# replace missing value by mean columns\ncatalogue_ok = catalogue_ok.fillna(catalogue_ok.mean())","189ff1f7":"# used countplot to see the dominant category for magType\nsns.countplot(x='magType',data=catalogue_ok)\nplt.show()","f70148eb":"# replace nan value in 'magType' by the dominant category: 'ml'\ncatalogue_ok['magType'] = catalogue_ok['magType'].replace(np.nan,'ml')","c319aabe":"fig = plt.figure(figsize=(10,5))\n\n# Selected earthquakes\nax1 = sns.scatterplot(x =catalogue_ok.index, y=catalogue_ok['mag'], hue =catalogue_ok['depth'])\nax1 = plt.axvline(dt(2008,1,1), ymin=0, ymax=6,color=\"black\", linestyle=\"--\")\n\n# set title\nplt.title('number of seismic event from 1975 to 2018',size=15)\nplt.show() ","85e4fa27":"def ecdf(data):\n    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n    # Number of data points: n\n    n = len(data)\n    # x-data for the ECDF: x \n    x = np.sort(data)\n    # y-data for the ECDF: y  The y data of the ECDF go from 1\/n to 1 in equally spaced increments. \n    y = np.arange(1,n+1) \/ n\n    \n    return x, y","a9233482":"# Get magnitudes before and after 2008\nbefore_2008 = catalogue_ok[catalogue_ok.index < '2008-01-01']\nafter_2008  =  catalogue_ok[catalogue_ok.index >= '2008-01-01']","3460d78e":"# define figure size\nfig = plt.figure(figsize=(7,5))\n\n# figure title\nfig.suptitle('Empirical Cumulative Distribution Function', fontsize=18)\n\nmags_before_2008 = before_2008['mag']\nmags_after_2008 = after_2008['mag']\n# get number event and max magnitude before and after 2008\nmax_before_2008 = before_2008['mag'].max() \nnb_before_2008 = len(before_2008['mag'])\nmax_after_2008 = after_2008['mag'].max() \nnb_after_2008 = len(after_2008['mag'])\n\n# plot ECDF\nax1 = plt.plot(*ecdf(mags_before_2008),marker='.',linestyle = 'none',label='before 2008')\nax2 = plt.plot(*ecdf(mags_after_2008),marker='.',linestyle = 'none',label='after 2008')\nax1 = plt.xlabel('magnitude')\nax1 = plt.ylabel('ECDF')\n\nax1 = plt.text(2.6, 0.0, 'max mag after 2008: {}'.format(max_after_2008),fontsize=12)\nax1 = plt.text(2.6, 0.1, 'Nb. events after 2008: {}'.format(nb_after_2008),fontsize=12)\n\nax1 = plt.text(-0.05, 0.65, 'max mag before 2008: {}'.format(max_before_2008),fontsize=12)\nax1 = plt.text(-0.05, 0.75, 'Nb. events before 2008: {}'.format(nb_before_2008),fontsize=12)\n\nplt.legend(fontsize=14)\nplt.show()","66aeb5bf":"# define the fonction needed for statistical analysis:\ndef bootstrap_replicate_1d(data, func):\n    \"\"\"Generate bootstrap replicate of 1D data.\"\"\"\n    bs_sample = np.random.choice(data, len(data))\n    return func(bs_sample)\n\ndef draw_bs_reps(data, func, size=1):\n    \"\"\"Draw bootstrap replicates.\"\"\"\n\n    # Initialize array of replicates: bs_replicates\n    bs_replicates = np.empty(size)\n\n    # Generate replicates\n    for i in range(size):\n        bs_replicates[i] = bootstrap_replicate_1d(data,func)\n\n    return bs_replicates\n\n# define fonction to compute b-value with confident interval\ndef b_value(mags, mt, perc=[2.5, 97.5], n_reps=None):\n    \"\"\"Compute the b-value and optionally its confidence interval.\"\"\"\n    # Extract magnitudes above completeness threshold: m\n    m = mags[mags >= mt]\n\n    # Compute b-value: b\n    b = (np.mean(m)-mt)*np.log(10)\n\n    # Draw bootstrap replicates\n    if n_reps is None:\n        return b\n    else:\n        m_bs_reps = draw_bs_reps(m, np.mean, n_reps)\n\n        # Compute b-value from replicates: b_bs_reps\n        b_bs_reps = (m_bs_reps - mt) * np.log(10)\n\n        # Compute confidence interval: conf_int\n        conf_int = np.percentile(b_bs_reps, [2.5, 97.5])\n    \n        return b, conf_int\n    \ndef draw_perm_reps(data_1, data_2, func, size=1):\n    \"\"\"Generate multiple permutation replicates.\"\"\"\n\n    # Initialize array of replicates: perm_replicates\n    perm_replicates = np.empty(size)\n\n    for i in range(size):\n        # Generate permutation sample\n        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n\n        # Compute the test statistic\n        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n\n    return perm_replicates\n\ndef diff_of_means(data_3, data_4):\n    \"\"\"Difference in means of two arrays.\"\"\"\n\n    # The difference of means of data_1, data_2: diff\n    diff = np.mean(data_3)-np.mean(data_4)\n\n    return diff\n\ndef permutation_sample(data1, data2):\n    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n\n    # Concatenate the data sets: data\n    data = np.concatenate([data1,data2])\n\n    # Permute the concatenated array: permuted_data\n    permuted_data = np.random.permutation(data)\n\n    # Split the permuted array into two: perm_sample_1, perm_sample_2\n    perm_sample_1 = permuted_data[:len(data1)]\n    perm_sample_2 = permuted_data[len(data1):]\n\n    return perm_sample_1, perm_sample_2","f2709a91":"mt = 2.8\n# Compute b-value and confidence interval for pre-2010\nb_pre, conf_int_pre = b_value(mags_before_2008, mt, perc=[2.5, 97.5], n_reps=10000)\n\n# Compute b-value and confidence interval for post-2010\nb_post, conf_int_post = b_value(mags_after_2008, mt, perc=[2.5, 97.5], n_reps=10000)\n\n# Report the results\nprint(\"\"\"\nBefore 2008:\nb-value: {0:.2f}\n95% conf int: [{1:.2f}, {2:.2f}]\n\nAfter 2008\nb-value: {3:.2f}\n95% conf int: [{4:.2f}, {5:.2f}]\n\"\"\".format(b_pre, *conf_int_pre, b_post, *conf_int_post))\n","51f9052c":"mt = 3\n\n# step 1: select only magnitudes above completeness threshold\nmags_before_2008 = mags_before_2008[mags_before_2008 >= 2.5]\nmags_after_2008 = mags_after_2008[mags_after_2008 >= 2.5]\n\n# step 2: Observed difference in mean magnitudes: diff_obs\ndiff_obs = np.mean(mags_before_2008 ) - np.mean(mags_after_2008)\n\n# Generate permutation replicates: perm_reps\nperm_reps = draw_perm_reps(mags_after_2008, mags_before_2008, diff_of_means, size=10000)\n\n# Compute and print p-value\np_val = np.sum(perm_reps < diff_obs) \/ 10000\nprint('p =', p_val)","d03ee994":"# create df with features to be used for clustering\ndf_for_cluster = catalogue_ok[['latitude','longitude']]","6304aa50":"numClusters = [10,18,19,20,21,22,23,24,25,30,40,50,80]\nSSE = []\nfor k in numClusters:\n    k_means = cluster.KMeans(n_clusters=k)\n    k_means.fit(df_for_cluster)\n    SSE.append(k_means.inertia_)\n\nplt.plot(numClusters, SSE,'-o')\nplt.xlabel('Number of Clusters')\nplt.ylabel('SSE')\nplt.grid()\nplt.show()\n","cbc12551":"# create 20 clusters and assign cluster id to catalogue_ok\nk_means_meq = cluster.KMeans(n_clusters=20, random_state=1)\nk_means_meq.fit(df_for_cluster) \nlabels = k_means_meq.labels_\ncentroids = k_means_meq.cluster_centers_\ndf_label = pd.DataFrame(labels, index=df_for_cluster.index, columns=['Cluster ID'])\ndf_centroid = pd.DataFrame(centroids,columns=['latitude','longitude'])\n\ncatalogue_ok = pd.concat([catalogue_ok,df_label],axis=1)","ac166898":"plt.figure(figsize=(8,8))\n\n# SHOW LOCATION OF THE GEYSER GEOTHERMAL FIELD\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-105, -93, 29,41], crs=ccrs.PlateCarree())\n\n# add color\nax.add_feature(cfeature.OCEAN.with_scale('10m'))\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.STATES)\nax.add_feature(cfeature.RIVERS)\nax.coastlines()\n\n# add grid\nax = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='darkgray', alpha=0.5, linestyle='--')\nax.top_labels = False\nax.right_labels = False\nax.xlocator = mticker.FixedLocator([-102,-99,-96])\nax.ylocator = mticker.FixedLocator([33, 36,39])\nax.xformatter = LONGITUDE_FORMATTER\nax.yformatter = LATITUDE_FORMATTER\nax.xlabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\nax.ylabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\n\n# define color\nqualitative_colors = sns.color_palette(\"Set2\", 20)\n\n# Selected earthquakes\nax = sns.scatterplot(x = catalogue_ok['longitude'], y= catalogue_ok['latitude'],hue = catalogue_ok['Cluster ID'],\n                      palette = qualitative_colors,legend= False)\n# plot centroid\nax = sns.scatterplot(x = df_centroid['longitude'], y= df_centroid['latitude'],\n                      hue = df_centroid.index, palette = qualitative_colors,s=100,marker='^',edgecolor = 'k')\n\n# set title\nax.set_title('cluster seismic events',size=15)\nplt.show()","d591fc30":"# calculate b-value in each cluster after 2008\nmt = 2.8\nlist_b_value_cluster = []\nfor i in range(20):\n    df_c = pd.DataFrame()\n    df_c = catalogue_ok[(catalogue_ok.index >= '2008-01-01')&(catalogue_ok['Cluster ID']==i)]\n    b = b_value(df_c['mag'], mt, perc=[2.5, 97.5])\n    list_b_value_cluster.append((i,b))\n    \nb_value_cluster = pd.DataFrame(list_b_value_cluster,columns=['clusterid','b-value']) ","670aceae":"cluster_attributes = catalogue_ok.groupby('Cluster ID').median()\ncluster_attributes = pd.concat([cluster_attributes,b_value_cluster],axis=1)\ncluster_attributes = cluster_attributes.drop(columns=['clusterid'],axis=1)","158ef766":"corr = cluster_attributes.corr(method='pearson')\n\nfig, axes = plt.subplots(1,figsize=(8,8))\nax0 = plt.subplot(1,1,1)\nsns.heatmap(corr,annot=True,linewidths=.5, annot_kws={\"size\": 10},vmin=-1.0, vmax=1.0,square=True,cbar=True)\nax0.set_title('correlations between numerical variables',size=18,y=1.05)\nax0.set_yticklabels(ax0.get_yticklabels(), rotation=0,size=14) \nax0.set_xticklabels(ax0.get_xticklabels(), rotation=90,size=14) \nplt.show()","f97da4be":"# step1: Load the lists all active saltwater injection wells in the state of Oklahoma.\ndf_inj_well = pd.read_csv(r'..\/input\/oklahoma-earthquakes-and-saltwater-injection-wells\/InjectionWells.csv')\ndf_inj_well.head(3)","690f96ce":"df_inj_well.describe()","9ef81a74":"df_inj_well = df_inj_well[(df_inj_well['LONG']>-105)&(df_inj_well['LONG']<-93)&\n                         (df_inj_well['LAT']>29)&(df_inj_well['LAT']<41)]","690e8d0f":"# show percentage and distribution missing values per columns\nget_percentage_nan_values(df_inj_well, 20, color=sns.color_palette('Reds',15))","98552f88":"# drop columns with more than 20% of missing value\ndf_inj_well = df_inj_well.dropna(thresh=len(catalogue_ok)*0.8, axis=1)","1446dc91":"columns_to_drop = ['Operator ID','OrderNumbers','ZONE','QQQQ','County','Sec','Twp','Rng','WellName','WellNumber']\ndf_inj_well = df_inj_well.drop(columns_to_drop,axis=1)\ndf_inj_well.tail()","102195aa":"# drop last row:\ndf_inj_well = df_inj_well[:-1]\n# define API number as string\ndf_inj_well['API#'] = df_inj_well.loc[:'API#'].astype(str)\n# check nan values\nprint(\"number of wells: {}\".format(df_inj_well.shape[0]))\ndf_inj_well.isnull().sum()","06dfd32e":"df_inj_well.head(2)","583ca609":"df_inj_well.dtypes","ddd4a050":"# define string as number\ndf_inj_well['PSI'] = pd.to_numeric(df_inj_well['PSI'], errors='coerce')\ndf_inj_well['BBLS'] = pd.to_numeric(df_inj_well['BBLS'], errors='coerce')\ndf_inj_well = df_inj_well.dropna()","ee588597":"plt.figure(figsize=(8,8))\n\n# SHOW LOCATION OF THE GEYSER GEOTHERMAL FIELD\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-105, -93, 29,41], crs=ccrs.PlateCarree())\n\n# add color\nax.add_feature(cfeature.OCEAN.with_scale('10m'))\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.STATES)\nax.add_feature(cfeature.RIVERS)\nax.coastlines()\n\n# add grid\nax = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='darkgray', alpha=0.5, linestyle='--')\nax.top_labels = False\nax.right_labels = False\nax.xlocator = mticker.FixedLocator([-102,-99,-96])\nax.ylocator = mticker.FixedLocator([33, 36,39])\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\ngl.xlabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\ngl.ylabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\n\n# Selected earthquakes\nax1 = sns.scatterplot(x =df_inj_well['LONG'], y=df_inj_well['LAT'], hue =df_inj_well['PSI'],size =df_inj_well['PSI'])\n\n# set title\nax1.set_title('location injection wells',size=15)\n\nplt.show()","37b90695":"# create df with features to be used for clustering\ndf_inj_well_for_cluster = df_inj_well[['LAT','LONG']]","5de726c6":"# calculate b-value in each cluster after 2008\nnumClusters = [10,18,19,20,21,22,23,24,25,30,40,50,80]\nSSE = []\nfor k in numClusters:\n    k_means = cluster.KMeans(n_clusters=k)\n    k_means.fit(df_inj_well_for_cluster)\n    SSE.append(k_means.inertia_)\n\nplt.plot(numClusters, SSE,'-o')\nplt.xlabel('Number of Clusters')\nplt.ylabel('SSE')\nplt.grid()\nplt.show()\n","95d0d16b":"# create 20 clusters and assign cluster id to catalogue_ok\nk_means = cluster.KMeans(n_clusters=20, random_state=1)\nk_means.fit(df_inj_well_for_cluster) \nlabels = k_means.labels_\ncentroids = k_means.cluster_centers_\ndf_label = pd.DataFrame(labels, index=df_inj_well.index, columns=['Cluster ID'])\ndf_centroid_inj = pd.DataFrame(centroids,columns=['latitude','longitude'])\n\ndf_inj_well = pd.concat([df_inj_well,df_label],axis=1)","c8d2890a":"plt.figure(figsize=(8,8))\n\n# SHOW LOCATION OF THE GEYSER GEOTHERMAL FIELD\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-105, -93, 29,41], crs=ccrs.PlateCarree())\n\n# add color\nax.add_feature(cfeature.OCEAN.with_scale('10m'))\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.STATES)\nax.add_feature(cfeature.RIVERS)\nax.coastlines()\n\n# add grid\nax = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='darkgray', alpha=0.5, linestyle='--')\nax.top_labels = False\nax.right_labels = False\nax.xlocator = mticker.FixedLocator([-102,-99,-96])\nax.ylocator = mticker.FixedLocator([33, 36,39])\nax.xformatter = LONGITUDE_FORMATTER\nax.yformatter = LATITUDE_FORMATTER\nax.xlabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\nax.ylabel_style = {'size': 13, 'color': 'gray', 'weight': 'bold'}\n\n# define color\nqualitative_colors = sns.color_palette(\"Set2\", 20)\nh = .02\n\n# Selected earthquakes\nax = sns.scatterplot(x = df_inj_well['LONG'], y= df_inj_well['LAT'],hue = df_inj_well['Cluster ID'],\n                      palette = qualitative_colors,legend= False)\n# plot centroid\nax = sns.scatterplot(x = df_centroid['longitude'], y= df_centroid['latitude'],s=100,marker='o',edgecolor = 'k')\nax = sns.scatterplot(x = df_centroid_inj['longitude'], y= df_centroid_inj['latitude'],\n                      hue = df_centroid_inj.index, palette = qualitative_colors,s=100,marker='^',edgecolor = 'k')\n\n\n\n\n# set title\nax.set_title('centroids meq cluster vs centroids inj well location cluster',size=15)\nplt.show()","c6e90548":"catalogue_ok['count'] = 1\ncatalogue_ok['cumsum'] = catalogue_ok['count'].cumsum()\ncatalogue_ok.drop('count',axis = 1,inplace = True)\n\ndf_inj_well['count'] = 1\ndf_inj_well['cumsum'] = df_inj_well['count'].cumsum()\ndf_inj_well.drop('count',axis = 1,inplace = True)\n\nplt.plot(catalogue_ok.index, catalogue_ok['cumsum'])\nplt.plot(df_inj_well.index, df_inj_well['cumsum'])\n","1db06571":"#### Functions used to compute and compare b-values","fa021b05":"### 1.4.3: computing b-values","2cb90596":"## <a id=\"1\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#7ca4cd; border:0' role=\"tab\" aria-controls=\"home\"><center>1: SEISMIC DATA<\/center><\/h3>\n","6aef4eac":"Interesting correlations between:\n- latitude and mag\/rms,\n- depth and longitude,\n- depth and b-value\n\n- horizontal and depth errors with mag and rms (may highlight the influence of the seismic network (location of the seismic stations) on the seismic catalogue?)","eccb1fd8":"#### 1.3.2: Verify and replace missing values","5a992da6":"## <a id=\"2\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#7ca4cd; border:0' role=\"tab\" aria-controls=\"home\"><center>3: comparison earthquake - injection<\/center><\/h3>","45701873":"no clear relation between earthquake location and eartquake location","18cfeaab":"### 1.4.2: Plot the ECDF of the Earthquake magnitudes","34a83bc7":"Both curves seem to follow the Gutenberg-Richter Law, but with different completeness thresholds, probably due to improvements in sensing capabilities in more recent years.","9106c3c8":"## 1.4: Statistical analyses\n### 1.4.1: Evolution over time","71dc9c7b":"The minimal latitude is '0'....","ff4515ff":"## 1.2: Plot earthquakes locations","b1a8ec6f":"## 1.5: Earthquakes clustering\n### 1.5.1: cluster creation ","056b674d":"### MEQ properties","845613a9":"# Oklahoma Earthquakes and Saltwater Injection Wells\n## Earthquakes in Oklahoma region and Oil and Gas fluid byproduct data.\n\n#### in progress...","52fa045e":"## 3.2: comparison evolution MEQ and number of injection wells","873fb627":"### EDA","d6f7e36f":"## <a id=\"2\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#7ca4cd; border:0' role=\"tab\" aria-controls=\"home\"><center>2: INJECTION DATA<\/center><\/h3>","b52e4447":"### 1.5.2: cluster properties \n#### b-values","3cb18c61":"## 3.1: earthquake' locations vs injection wells location","553dbdb9":"The p-value is about 1.0, suggesting we should reject the null hypothesis that the b-value has not changed.","85f962a0":"#### 1.3.1: set date as index","98b7d3d9":"### 1.3: Clean the dataframe","e8e93d78":"We observed a strong increase in seismicity after ~2008.\nWe also observed one earthquake at a depth of 56 km","c8743ae7":"#### Is the b-value in Oklahoma before 2008 is really different from the one after 2008?\nTo answer this question we will:\n- include earthquakes that have magnitudes above the completeness threshold. A value of 3 is reasonable.\n- perform a permutation test because asserting a null hypothesis that the b-values are the same implicitly assumes that the magnitudes are identically distributed, specifically Exponentially, by the Gutenberg-Richter Law.\n- plook at the difference between the mean post-2008 magnitude and the mean pre-2008 magnitude.","37cb85d5":"## 1.1: Load the seismic data","0ed1c194":"### Injection wells clustering"}}