{"cell_type":{"22dcd3a3":"code","a5999b4a":"code","fe651bf1":"code","8989a87b":"code","e07752ce":"code","85c570a9":"code","e525f91d":"code","27c32e9d":"markdown","fc474325":"markdown"},"source":{"22dcd3a3":"'''Unzipping'''\n\nfrom zipfile import ZipFile\n# Create a ZipFile Object and load sample.zip in it\nwith ZipFile('..\/input\/oxford-102-flower-pytorch\/flower_data.zip', 'r') as zipObj:\n   # Extract all the contents of zip file in current directory\n   zipObj.extractall()","a5999b4a":"\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\n\n\nplt.ion()   # interactive mode\n\n# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((230,230)),\n        transforms.RandomRotation(30,),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n    ]),\n}\n\ndata_dir = '.\/flower_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'valid']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n                                             shuffle=True, num_workers=0)\n              for x in ['train', 'valid']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)#, title=[class_names[x] for x in classes])\n\n#model_ft = models.vgg19_bn(pretrained=True)\n#num_ftrs = model_ft.classifier[0].in_features\n\nmodel_ft = models.resnext50_32x4d(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\nhalf_in_size = round(num_ftrs\/2)\nlayer_width = 102 #Small for Resnet, large for VGG\nNum_class=102","fe651bf1":"''' Changing the fully connected layer'''\n\n\nMultilayer_fc = nn.Sequential(\n            nn.Linear(num_ftrs, layer_width*2),\n            nn.ReLU(inplace=True),\n            nn.Linear(layer_width*2, layer_width*2),\n            nn.ReLU(inplace=True),\n            nn.Linear(layer_width*2, Num_class)\n        )\n\n\n#model_ft.fc = nn.Linear(num_ftrs, 10)\nmodel_ft.fc = Multilayer_fc#SpinalNet_ResNet() #SpinalNet_VGG # testing the effect of multilayer","8989a87b":"'''The Training Function'''\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                time_elapsed = time.time() - since\n                print('Time from Start {:.0f}m {:.0f}s'.format(\n                    time_elapsed \/\/ 60, time_elapsed % 60))\n                \n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","e07752ce":"model_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\nmodel_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=10)","85c570a9":"'''Training again with lower lr'''\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)      \nmodel_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=30)","e525f91d":"import shutil\nshutil.rmtree('.\/flower_data')","27c32e9d":"This script presents a PyTorch transfer learning example.\n\nThis simulation is a part of our paper: \n\nKabir, H.M., Abdar, M., Jalali, S.M.J., Khosravi, A., Atiya, A.F., Nahavandi, S., and Srinivasan, D., 2020. SpinalNet: Deep Neural Network with Gradual Input. arXiv preprint arXiv:2007.03347.\n\nFor more codes:\nhttps:\/\/github.com\/dipuk0506\/SpinalNet","fc474325":"Deleting data after use to avoid figures at the bottom."}}