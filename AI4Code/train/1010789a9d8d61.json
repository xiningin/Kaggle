{"cell_type":{"7dfff8c3":"code","5a9c03be":"code","102c4ed1":"code","311d2c44":"code","ee67a01c":"code","3823226f":"code","2428f1c3":"code","8beb3dda":"code","94472454":"code","e1dca2f0":"code","cd2f50d3":"code","bb8fc7bd":"code","1e80ac9a":"code","1088bd1f":"code","6a91c0d1":"code","89373ec4":"code","9e9f6609":"code","0f0a3d35":"code","6160b4c0":"code","2552ffa2":"code","2668d3d9":"code","81e7c2b4":"markdown","dba1a9dc":"markdown","42fb26fa":"markdown","c8e1be19":"markdown","de2c14e1":"markdown","93aec52e":"markdown","6368f971":"markdown","b87ee236":"markdown","1d9cbbe0":"markdown","3cbfa62c":"markdown","b5d6bf4b":"markdown","7da8b302":"markdown","5d2906ab":"markdown","aa019ba6":"markdown","9e1975bb":"markdown","4a941618":"markdown","1690b7fa":"markdown","610dfc55":"markdown","6b925a9f":"markdown"},"source":{"7dfff8c3":"import os\nimport pandas as pd\nimport numpy as np\nfrom subprocess import check_output\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB","5a9c03be":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","102c4ed1":"train.head()","311d2c44":"train.tail()","ee67a01c":"test.head()","3823226f":"test.head()","2428f1c3":"print('Train data shape: ',train.shape)","8beb3dda":"print('Test data shape: ',test.shape)","94472454":"train.isnull().sum()","e1dca2f0":"print(train.info())","cd2f50d3":"print(\"Length of unique id's in train: \",len(np.unique(train['id'])))\nprint(\"Length of train dataframe is: \",len(train))\nid = test['id'].copy()\ntrain = train.drop('id', axis = 1)","bb8fc7bd":"train['author'] = train.author.map({'EAP':0,'HPL':1,'MWS':2})\ntrain.head()","1e80ac9a":"x = train['text'].copy()\ny = train['author'].copy()\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42)\n\nprint(x.head())\nprint(y.head())","1088bd1f":"# Example\n# In short it returns the count of each word in row under consideration.\n\ntext = [\"My name is Bhagwat Chate Bhagwat Chate\"]\ntoy  = CountVectorizer(lowercase=False, token_pattern = r'\\w+|\\,')\ntoy.fit_transform(text)\n\nprint (toy.vocabulary_)\nmatrix = toy.transform(text)\n\nprint(matrix[0,0])\nprint(matrix[0,1])\nprint(matrix[0,2])\nprint(matrix[0,3])\nprint(matrix[0,4])","6a91c0d1":"vect = CountVectorizer(lowercase=False, token_pattern=r'\\w+|\\,')\n\nx_v = vect.fit_transform(x)\nx_train_v = vect.transform(x_train)\nx_test_v = vect.transform(x_test)\n\nprint (x_train_v.shape)","89373ec4":"model = MultinomialNB()\nmodel.fit(x_train_v, y_train)","9e9f6609":"print('Naive Bayes accuracy: ',round(model.score(x_test_v, y_test)*100,2),'%')","0f0a3d35":"x_test=vect.transform(test[\"text\"])","6160b4c0":"model = MultinomialNB()\nmodel.fit(x_v, y)\n\npredicted_result = model.predict_proba(x_test)\n\npredicted_result.shape","2552ffa2":"result=pd.DataFrame()\n\nresult[\"id\"]  = test['id']\nresult[\"EAP\"] = predicted_result[:,0]\nresult[\"HPL\"] = predicted_result[:,1]\nresult[\"MWS\"] = predicted_result[:,2]\n\nresult.head()","2668d3d9":"result.to_csv(\"Result.csv\", index=False)","81e7c2b4":"Let's fit the model","dba1a9dc":"train data: Check the top 5 entries. How the data looks like","42fb26fa":"Now, till here we are ready with nthe test & train data. The real real fun game begins here. Let's 'Vectorize' the data rows","c8e1be19":"Check the train data shape","de2c14e1":"We see that we got a result with 8392 rows presenting each text and 3 columns each column representing probability of\\\neach author.","93aec52e":"Till now we understood the shape and size of the train and test data i.e. dimensions","6368f971":"Check is there any blank values in train data","b87ee236":"The Accuracy of the model is","1d9cbbe0":"Let's save the result into Excel file name 'Result.csv'","3cbfa62c":"Now lets split the 'train' data into x & y","b5d6bf4b":"### Text Classification: Naive Bayes Algorithm","7da8b302":"Check the test data shape","5d2906ab":"Check the information about the train data","aa019ba6":"For training purpose what we did is we split the train dataset into 'training' & 'testing'. We have seperate dataset for \\\n'testing' lets work with the 'test' dataset ptovided in this question.","9e1975bb":"test data: Check the bottom 5 entries. How the data looks like","4a941618":"Now by just looking at the top 4 entries, it must be clear that does id have any role in determining who the author is? \nNo. Id is just used as a identifier for text NOT for author. So one thing is clear over here, that id is useless and \nwould not help in any way to our model to learn.\n\nOR\n\nCheck out the unique count of 'id' i.e. 19579 also the length of dataframe is 19579. It clears that it is not useful for \nclassification purpose so remove it.","1690b7fa":"Now we have successfully vectorized the data given by kaggle Now we fit the whole training data without any split \\\ninto our Naive Bayes Model Next we give it the testing vectorized data to predict the probabilities","610dfc55":"train data: Check the bottom 5 entries. How the data looks like","6b925a9f":"Test data: Check the top 5 entries. How the data looks like"}}