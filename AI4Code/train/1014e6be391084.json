{"cell_type":{"71a29e3f":"code","fdb6d3da":"code","49d71506":"code","9d1da894":"code","1e8f64eb":"code","31167e61":"code","5d55875e":"code","2cbd8b51":"code","85a2bbe9":"code","d596b8a6":"code","a956634d":"code","9bd02614":"code","9fa88fdb":"code","f243a31d":"code","2712bd17":"code","5f8e95e8":"code","7dd73c1f":"code","cee44ff0":"code","b683660e":"code","80685b76":"code","f158798e":"code","0681ba32":"code","4536c881":"code","688000f4":"code","fdcad974":"code","042530c4":"code","3b884c81":"code","370a5d8d":"code","adaeb896":"code","d5a9a978":"code","edf3f7a4":"code","aeef3e16":"code","a694365c":"code","d842b262":"code","a1c792ad":"code","2f64c503":"code","5d62a07a":"code","1469be63":"code","ffad1861":"code","8954e346":"code","27c8e444":"code","24fd75ae":"code","6b842948":"code","111d6142":"code","3f564364":"code","bfea931a":"code","900a7f26":"code","e222474c":"code","b69ccd7b":"code","3c8f17a7":"code","f61fe312":"code","b40d3e83":"code","d88abd25":"code","247c9e7a":"code","cf4f1edc":"markdown","a1615f57":"markdown","ea5f1ce1":"markdown","d5fe6751":"markdown","4afef818":"markdown","644a7614":"markdown","6afc6c06":"markdown","f0e35250":"markdown","1824f984":"markdown","d5c2f624":"markdown","a6acc709":"markdown","8d4fecdb":"markdown","41b52c65":"markdown","2b2fed82":"markdown","d3989187":"markdown","9f553d4f":"markdown","a7e3bf04":"markdown","1f3c1f10":"markdown"},"source":{"71a29e3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdb6d3da":"import numpy as np\nimport pandas as pd\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nimport math\nimport datetime\nimport seaborn as sns\ndf=pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","49d71506":"df.info()","9d1da894":"df[['Amount', 'Time']].describe().T","1e8f64eb":"df['Class'].value_counts().plot(kind='pie', figsize=[8,8], autopct='%1.1f%%')\nplt.legend(['Genuine', 'Fraud'])","31167e61":"df.shape","5d55875e":"df=df.drop_duplicates()\ndf.shape\n#Removing duplicates, we get a new DataFrame of new 283726 rows","2cbd8b51":"df[(df['Amount']==0)&(df['Class']==0)]['Class'].count()","85a2bbe9":"df[(df['Amount']==0)&(df['Class']==1)]['Class'].count()","d596b8a6":"df.drop(df[df['Amount']==0].index, inplace=True)","a956634d":"df[df['Amount']==0].count()#All the rows with Amount 0 is removed","9bd02614":"df.reset_index(inplace=True)#to reset the index numbers","9fa88fdb":"plt.figure(figsize=(10,10))\nsns.distplot(df['Amount'], bins=100)","f243a31d":"plt.figure(figsize=(10,10))\nsns.distplot(df[df['Class']==0]['Amount'], bins=100)","2712bd17":"plt.figure(figsize=(10,10))\nsns.distplot(df[df['Class']==1]['Amount'], bins=100)","5f8e95e8":"print(df[df['Class']==1]['Amount'].value_counts().head(10))\nprint(df[df['Class']==1]['Amount'].max())\nprint(df[df['Class']==1]['Amount'].min())","7dd73c1f":"np.percentile(df[df['Class']==1]['Amount'], (25,50, 75))","cee44ff0":"#For the fraud transactions, we can see that the difference between 75%ile and  50%ile is much greater than 50%ile and 25%ile","b683660e":"sns.boxplot(x='Class', y='Amount', data=df)","80685b76":"sns.boxplot(x='Class', y='Time', data=df)","f158798e":"#Distribution as per time\nplt.figure(figsize=(10,10))\nsns.distplot(df['Time'])","0681ba32":"df['Time_Hr']=df['Time'].apply(lambda sec: (sec\/3600))\ndf.shape\ndf.head()","4536c881":"plt.figure(figsize=(10,10))\nsns.distplot(df[(df['Time_Hr']<=24)]['Time_Hr'])\nsns.distplot(df['Time_Hr'])","688000f4":"#Checking only the fraud transactions within 24 hrs and 48 hrs\nplt.figure(figsize=(10,10))\nsns.distplot(df[(df['Class']==1)&(df['Time_Hr']<=24)]['Time_Hr'])","fdcad974":"sns.distplot(df[(df['Class']==1)&(df['Time_Hr']>24)]['Time_Hr'])","042530c4":"df['Class'].value_counts(normalize=True)","3b884c81":"q1,q3=np.percentile(df['Amount'], (25,75))\niqr=q3-q1\nlower_bound=q1-(1.5*iqr)\nupper_bound=q3+(1.5*iqr)\nprint(lower_bound)\nprint(upper_bound)\nprint(q1)\nprint(q3)\nprint(iqr)","370a5d8d":"outlier_amount=df[(df['Amount']<lower_bound)|(df['Amount']>upper_bound)]['Amount']\nfraud_transaction=df[(df['Class']==1)&((df['Amount']>lower_bound)&(df['Amount']>upper_bound))]\ngenuine_transactions=df[(df['Class']==0)&((df['Amount']>lower_bound)&(df['Amount']<upper_bound))]\nprint('total count of outliers is: ', outlier_amount.count())\nprint('total count of fraud transactions is:', fraud_transaction.count())\nprint('total count of genuine transactions is:', genuine_transactions.count())","adaeb896":"df_new=df.drop(outlier_amount.index)","d5a9a978":"df_new.reset_index(inplace=True)","edf3f7a4":"print(df_new.shape)\nprint(df_new['Class'].value_counts())\nprint(df_new['Class'].value_counts(normalize=True))","aeef3e16":"print(df.shape)\nprint(df['Class'].value_counts())\nprint(df['Class'].value_counts(normalize=True))","a694365c":"df_new=df[(df['Amount']>=lower_bound)&(df['Amount']<=upper_bound)]\nsns.boxplot(x='Class', y='Amount', data=df_new)","d842b262":"df_new['Class'].value_counts(normalize=True)","a1c792ad":"df_new['Class'].value_counts()","2f64c503":"sns.distplot(df_new['Amount'])","5d62a07a":"sns.distplot(df_new[df_new['Class']==1]['Amount'], bins=10)\nsns.distplot(df_new[df_new['Class']==0]['Amount'], bins=10)","1469be63":"np.percentile((df_new[df_new['Class']==1]['Amount']), (75,100))","ffad1861":"sns.heatmap(df_new[['Time', 'Amount', 'Class']].corr(), linewidth=0.5, vmax=1, square=True, cmap='viridis', annot=True)","8954e346":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Time_Hr', y='Amount', data=df_new, hue='Class')","27c8e444":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\ndf_new['ScaledAmount']=scaler.fit_transform(df_new[['Amount']])\ndf_new['ScaledAmount']","24fd75ae":"df_new['log_transformed_amt']=np.log(df_new.Amount+0.01)","6b842948":"sns.boxplot(x='Class', y='log_transformed_amt', data=df_new)","111d6142":"df_new.shape","3f564364":"from sklearn.model_selection import train_test_split\ny=df_new['Class'].values\nx=df_new.drop(columns=['Time', 'Time_Hr', 'Amount', 'log_transformed_amt']).values\nxTrain, xTest, yTrain, yTest=train_test_split(x,y, test_size=0.3, random_state=0)","bfea931a":"from sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(xTrain, yTrain)","900a7f26":"ypred=logreg.predict(xTest)\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(ypred,yTest))","e222474c":"from sklearn.metrics import confusion_matrix","b69ccd7b":"from sklearn.metrics import roc_auc_score, roc_curve, auc\nroc_auc_score(yTest, ypred)","3c8f17a7":"import sklearn.metrics as metric\nprint(confusion_matrix(yTest, ypred))","f61fe312":"from sklearn import metrics\nfpr, tpr, thresholds=metrics.roc_curve(yTest, ypred, pos_label=2)","b40d3e83":"class_name=[0,1]\nfig, ax=plt.subplots()\ntick_marks=np.arange(len(class_name))\nplt.xticks(tick_marks, class_name)\nplt.yticks(tick_marks, class_name)\nsns.heatmap(pd.DataFrame(confusion_matrix(yTest, ypred)), annot=True, cmap='viridis', fmt='g', linewidth=0.5)\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.5)\nplt.ylabel('Actial Label')\nplt.xlabel('Predicted Label')","d88abd25":"print(\"Accuracy:\", metrics.accuracy_score(yTest, ypred))\nprint(\"Precision:\", metrics.precision_score(yTest, ypred))\nprint(\"Recall:\", metrics.recall_score(yTest, ypred))","247c9e7a":"y_pred_prob=logreg.predict_proba(xTest)[::,1]\nfpr, tpr, threshold=metrics.roc_curve(yTest, y_pred_prob)\nauc=metrics.roc_auc_score(yTest, y_pred_prob)\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area=50.2f)')\nplt.plot([0,1], [0,1], color='navy', linestyle='--')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","cf4f1edc":"None of the variables shows high correlation with each other","a1615f57":"Removing outliers","ea5f1ce1":"Creating Confusion martix and calculating accuracy, precision, recall","d5fe6751":"1.Checking Null Values","4afef818":"Distribution of the amount","644a7614":"The above shown scatter plot does not show any kind of proper pattern for the Fraud transactions","6afc6c06":"Removing the rows with Amount==0","f0e35250":"Distribution of the Amount as per Class","1824f984":"Removing duplicates","d5c2f624":"# Splitting the model into training and testing part","a6acc709":"The time does not show any particular pattern on the distribution of the transactions","8d4fecdb":"# Explanatory Data Analysis****","41b52c65":"# Drawing confusion matrix and AUC ROC curve","2b2fed82":"Checking 0 transaction for each Class","d3989187":"Data desciption","9f553d4f":"The log transformed data of Amount will be used for further analysis since the Fraud cases have no outliers and the genuine transactions have lesser outliers compared to other charts","a7e3bf04":"Generating AUC ROC curve","1f3c1f10":"# Feature Engineering"}}