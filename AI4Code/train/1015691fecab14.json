{"cell_type":{"475daae3":"code","45929a52":"code","feb486a9":"code","7b871b83":"code","b77f0a71":"code","e1ec8505":"code","4ab7be7e":"code","c43e6cab":"code","2a61c80b":"code","84fd88af":"code","48d0be81":"code","82ce088e":"code","7dda3b98":"code","05f75d2b":"code","48693bac":"code","cb3bc2f7":"code","4b2bb974":"code","d5d6f81d":"code","bb963d28":"markdown","3d45d39b":"markdown","8d65a78c":"markdown","baf5290d":"markdown","f7154dda":"markdown","f8f5abe4":"markdown","1f96d77c":"markdown","03fabfa4":"markdown","2c88566e":"markdown","75fe217f":"markdown"},"source":{"475daae3":"import os\nimport torch\n!git clone https:\/\/github.com\/AIStream-Peelout\/flow-forecast.git -b trans2\nos.chdir('flow-forecast')\n!pip install -r requirements.txt\n!python setup.py develop","45929a52":"meta_embedding_config = {                 \n    \"model_name\": \"BasicAE\",\n    \"model_type\": \"PyTorch\",\n    \"model_params\": {\n       \"input_shape\":33,\n       \"out_features\":128\n     }, \n    \"n_targets\":33,\n    \"dataset_params\":\n    {  \"class\": \"AutoEncoder\",\n       \"training_path\": \"acs2015_census_tract_data.csv\",\n       \"validation_path\": \"acs2015_census_tract_data.csv\",\n       \"test_path\": \"acs2017_county_data.csv\",\n       \"batch_size\":4,\n       \"train_end\": 6000,\n       \"valid_start\":6001,\n       \"valid_end\": 7000,\n       \"test_start\":0,\n       \"relevant_cols\": ['TotalPop', 'Men', 'Women',\n       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n       'Income', 'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n       'WorkAtHome', 'MeanCommute', 'Employed', 'PrivateWork', 'PublicWork',\n       'SelfEmployed', 'FamilyWork', 'Unemployment'],\n       \"Scaling\":\"StandardScaler\",\n       \"interpolate\": False\n    },\n    \"training_params\":\n    {\n       \"criterion\":\"MSE\",\n       \"optimizer\": \"Adam\",\n       \"lr\": 0.3,\n       \"epochs\": 4,\n       \"batch_size\":4,\n       \"optim_params\":\n       {\n       }\n    \n    },\n    \"GCS\": False,\n    \n    \"wandb\": {\n       \"name\": \"flood_forecast_circleci\",\n       \"project\": \"repo-flood_forecast\",\n       \"tags\": [\"auto_encoder\", \"circleci\"]\n    },\n   \"metrics\":[\"MSE\"],\n\n   \"inference_params\":{\n      \"hours_to_forecast\":1\n\n   }   \n}\nimport os\n# os.environ['MODEL_BUCKET'] = \"coronaviruspublicdata\"\n# os.environ[\"ENVIRONMENT_GCP\"] = \"GCP\"\n# os.environ[\"GCP_PROJECT\"] = \"gmap-997\"","feb486a9":"import json\nwith open(\"meta_config.json\", \"w+\") as j:\n    json.dump(meta_embedding_config, j)","7b871b83":"import wandb \nimport torch\n# Uncomment this to login manually\nwandb.login()","b77f0a71":"import pandas as pd\ndef format_pd(file_path=\"..\/..\/input\/us-census-demographic-data\/acs2015_census_tract_data.csv\"):\n    df = pd.read_csv(file_path)\n    df[\"full_county\"] = df[\"County\"] + \"_\" + df[\"State\"]\n    df.dropna().to_csv(file_path.split(\"\/\")[-1])\nformat_pd()\nformat_pd(\"..\/..\/input\/us-census-demographic-data\/acs2017_county_data.csv\")\n","e1ec8505":"from flood_forecast.meta_train import train_function \ntrained_model = train_function(\"PyTorch\", meta_embedding_config)","4ab7be7e":"print(\"The model was trained using\")\nprint(trained_model.training[1][1])\nprint(trained_model.training[1][0])","c43e6cab":"from torch.utils.data import DataLoader\ndef get_add_embeddings_df(model, relevant_cols, original_file_path=\"acs2017_county_data.csv\"):\n    \"\"\"\n    Function to return a given data-frame\n    with all the embeddings.\n    \"\"\"\n    df = pd.read_csv(original_file_path)\n    model.test_data.df[\"simple_embeddings\"] = model.test_data.df[relevant_cols].apply(lambda x: torch.from_numpy(x[relevant_cols].to_numpy()).float().unsqueeze(0), axis=1)\n    model.test_data.df[\"model_embeddings\"] = model.test_data.df[\"simple_embeddings\"].map(lambda x: model.model.generate_representation(x))\n    model.test_data.df[\"county\"] = df[\"County\"] + \"_\" + df[\"State\"]\n    model.test_data.df[\"State\"] = df[\"State\"]\n    return model\n\ntrained_model.model.eval()\ntrained_model = get_add_embeddings_df(trained_model, trained_model.params[\"dataset_params\"][\"relevant_cols\"])","2a61c80b":"def get_most_similar_counties(df, county_name, column=\"model_embeddings\"):\n    embedding = df[df[\"county\"]==county_name].iloc[0][column]\n    cos = torch.nn.CosineSimilarity()\n    df[\"similarity_to_\" + county_name] = df[column].map(lambda x: cosine_similarity(embedding.detach(), x.detach()))\n    return df.sort_values(by=\"similarity_to_\"+county_name, ascending=False)","84fd88af":"from sklearn.metrics.pairwise import cosine_similarity\nget_most_similar_counties(trained_model.test_data.df, \"New York County_New York\")","48d0be81":"get_most_similar_counties(trained_model.test_data.df, \"Chase County_Kansas\")","82ce088e":"!pip install umap-learn\nimport umap\nreducer = umap.UMAP()\n","7dda3b98":"from bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\nfrom bokeh.palettes import Spectral10, Category20c\nfrom bokeh.palettes import magma\nimport pandas as pd\noutput_notebook()","05f75d2b":"def make_and_fit_reducer(df, reducer, embeddings_col, sorting_column, number_to_fit, name_col=\"county\", ascending=False):\n    df = df.sort_values(sorting_column, ascending=ascending)\n    the_embeddings = df[embeddings_col].map(lambda x: x.squeeze(0).detach().numpy())[:number_to_fit].to_list()\n    plottable_embeddings = reducer.fit_transform(the_embeddings)\n    return plottable_embeddings, df[name_col][:number_to_fit], df[:number_to_fit]","48693bac":"largest_counties_embeddings, largest_counties_names, df = make_and_fit_reducer(trained_model.test_data.df, reducer, \n                                                                          \"model_embeddings\", \"TotalPop\", 150)","cb3bc2f7":"def make_plot(red, title_list, number=200, color = True, df=None, other_cols=None, color_mapping_cat=None, color_cats = None, bg_color=\"white\"):   \n    digits_df = pd.DataFrame(red, columns=('x', 'y'))\n    if color_mapping_cat:\n        digits_df['colors'] = color_mapping_cat\n    digits_df['digit'] = title_list\n    for col in other_cols:\n        digits_df[col] = list(df[col])\n    datasource = ColumnDataSource(digits_df)\n    plot_figure = figure(\n    title='County Embedding Map',\n    plot_width=890,\n    plot_height=600,\n    tools=('pan, wheel_zoom, reset'),\n    background_fill_color = bg_color\n    )\n    plot_figure.legend.location = \"top_left\",\n    plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n    <div>\n    <div>\n        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'\/>\n    <\/div>\n    <div>\n        <span style='font-size: 10px; color: #224499'><\/span>\n        <span style='font-size: 10px'>@digit<\/span>\n        <p><\/p>\n        <span style='font-size: 10px'> Perecentage White: @White<\/span>\n        <p><\/p>\n        <span style='font-size: 10px'> Perecentage Black: @Black<\/span>\n        <p><\/p>\n        <span style='font-size: 10px'> Median Income: @Income<\/span>\n        \n                        \n    <\/div>\n    <\/div>\n    \"\"\"))\n    if color:   \n        color_mapping = CategoricalColorMapper(factors=title_list, palette=magma(number))\n        plot_figure.circle(\n            'x',\n            'y',\n            source=datasource,\n            color=dict(field='digit', transform=color_mapping),\n            line_alpha=0.6,\n            fill_alpha=0.6,\n            size=7\n        )\n        show(plot_figure)\n    elif color_mapping_cat:\n        color_mapping = CategoricalColorMapper(factors=color_cats, palette=magma(len(color_cats)+2)[2:])\n        plot_figure.circle(\n            'x',\n            'y',\n            source=datasource,\n            color=dict(field='colors', transform=color_mapping),\n            line_alpha=0.6,\n            fill_alpha=0.6,\n            size=8,\n            legend_field='colors'\n        )\n        show(plot_figure)\n    else:\n        \n        plot_figure.circle(\n            'x',\n            'y',\n            source=datasource,\n            color=dict(field='digit'),\n            line_alpha=0.6,\n            fill_alpha=0.6,\n            size=7\n        )\n        show(plot_figure)\n\nmake_plot(largest_counties_embeddings, list(largest_counties_names), number=150, df=df, other_cols=[\"White\", \"Black\", \"Hispanic\", \"Income\"], color_mapping_cat=True, color_cats=df[\"State\"])","4b2bb974":"smallest_county_embeddings, smallest_counties_names, df = make_and_fit_reducer(trained_model.test_data.df, reducer, \n                                                                          \"model_embeddings\", \"TotalPop\", 100, ascending=True)\nmake_plot(smallest_county_embeddings, list(smallest_counties_names), number=100, df=df, other_cols=[\"White\", \"Black\", \"Hispanic\", \"Income\"], color_mapping_cat=True, color_cats=df[\"State\"])","d5d6f81d":"!ls model_save","bb963d28":"## Stashing Weights and config for Part II\n[We will now upload our model weights and config file to GCS for use in part two](https:\/\/www.kaggle.com\/isaacmg\/auto-forecast-2).","3d45d39b":"Let's do something similar for the smallest ones.","8d65a78c":"## III. Train the model\n\nIf you are interested in the model architecture you can view it [here](https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/blob\/master\/flood_forecast\/meta_models\/basic_ae.py). It is essentially just a very basic autoencoder with one hidden layer in both the encoder and decoder. Before training the model there is a little house keeping we have to do on the data and upgrade pandas. After that we will train the model and the results will be logged to Wandb. ","baf5290d":"**Viewing the embeddings of largest counties**:\n\nWe now look at what the embeddings of the largest counties look like plotted on the map. This will help us understand how well the auto-encoder is group the relevant counties.","f7154dda":"## II. Meta-Embedding Config file\nWith all flow models we need to create a config file. The meta model is pretty similar to the time series models with a few subtle differences.","f8f5abe4":"## IV. Examining embeddings\n\nWe will now examien the embeddings using Bokeh charts.","1f96d77c":"## I. Download and Install dependencies ","03fabfa4":"**Qualitatively Examining Performance**:\n\nWe can see the auto-encoder did fairly well at learning county representations. The most similar counties to Manhattan are generally also large and have relatively similar demographics. Similarly Chase County in Kansas (a relatively rural county) the auto-encoder finds most similar counties also in Kansas and Nebraska. ","2c88566e":"# Leveraging Meta-Data in Time Series Forecasts\n\n### [A CoronaWhy Task-Time Series Project](https:\/\/github.com\/CoronaWhy\/task-ts)\n\nIn this tutorial we will utilize [Flow Forecast](https:\/\/github.com\/AIStream-Peelout\/flow-forecast) (a multivariate time series forecasting library in PyTorch) new meta-data auto-encoder module to create an embedding of county information. Then we will incorporate this county in our time series forecasts in order to improve performance at forecasting COVID-19 based on the county information. \n\nThis is is currently a work in progress and will be updated periodically as features are added to the main flow-forecast repo. \n\nSummary steps:\n1. Download and install relevant dependencies.\n2. Define a meta data embeddding configuration file.\n3. Train the meta-data embedding module. \n4. Create qualativative analysis of embeddings.\n\nSteps 5-7 are now being moved to a [seperate notebook due to an issue running Wandb.init()]()\n5. Define a time series forecast synthesis configuration file. \n6. Define a Wandb sweep file.\n7. Train the time series forecasting module both and w\/o the meta-data embedding ","75fe217f":"### Visualizing County Embeddings \nNow that we have the county embeddings will work to visualize them to see how accurately they reflect demographic information. "}}