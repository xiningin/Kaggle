{"cell_type":{"d5c10303":"code","70f016bf":"code","75a9c606":"code","b83edfb6":"code","012a076a":"code","60ca81b1":"code","b23518e2":"code","7b597985":"code","84ec0aaa":"code","0775b40a":"code","ce3c1fa8":"code","7c657568":"code","60cbaa79":"code","1277677b":"code","2c1dd022":"code","63f02134":"code","ef1b632f":"code","4400e339":"markdown","cb2084c1":"markdown","12740268":"markdown","7e9481e8":"markdown","64186a24":"markdown","7e472fa1":"markdown","64dcc987":"markdown"},"source":{"d5c10303":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\ndata=pd.read_csv(\"..\/input\/Iris.csv\")\n\n# Any results you write to the current directory are saved as output.","70f016bf":"# data frames from dictionary\ncountry=[\"Franche\",\"England\"]\npopulation=[\"25\",\"28\"]\nlist_label=[\"Country\",\"Population\"]\nlist_col=[country,population]\nzipped=list(zip(list_label,list_col))\ndata_dict=dict(zipped)\ndb=pd.DataFrame(data_dict)\nprint(db)","75a9c606":"#adding new column\ndb[\"newcol\"]=[3,5]\ndb","b83edfb6":"print(db)\ndb[\"newcol\"]=0\nprint(db)\ndata","012a076a":"#plotting all data (confused)\ndata1 = data.loc[:,[\"SepalLengthCm\",\"PetalLengthCm\"]]\ndata1.plot()\nplt.show()","60ca81b1":"#subplots\ndata1.plot(subplots=True)\nplt.show()","b23518e2":"data1.plot(kind=\"scatter\",x = \"SepalLengthCm\",y = \"PetalLengthCm\")\nplt.show()","7b597985":"#hist plot\ndata1.plot(kind=\"hist\",bins=50,y=\"SepalLengthCm\",range=(0,8),normed=True)\nplt.show()","84ec0aaa":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"SepalLengthCm\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"PetalLengthCm\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt\n","0775b40a":"data.describe()","ce3c1fa8":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1]))\ndatetime_object=pd.to_datetime(time_list)\nprint(type(datetime_object))","7c657568":"# In order to practice lets take head of Ir\u0131s data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object=pd.to_datetime(date_list)\ndata2[\"date\"]=datetime_object\ndata2=data2.set_index(\"date\")\ndata2","60cbaa79":"# Now we can select according to our date index\n#print(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])\n#print(data2)","1277677b":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()\n","2c1dd022":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","63f02134":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","ef1b632f":"data2.resample(\"M\").mean().interpolate(\"linear\")","4400e339":"a.Review of pandas\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","cb2084c1":"### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","12740268":"1. [Pandas Foundation](#25)\n    1. [Review of pandas](#26)\n    1. [Building data frames from scratch](#27)\n    1. [Visual exploratory data analysis](#28)\n    1. [Statistical explatory data analysis](#29)\n    1. [Indexing pandas time series](#30)\n    1. [Resampling pandas time series](#31)","7e9481e8":"### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","64186a24":"### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","7e472fa1":"### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","64dcc987":"### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n"}}