{"cell_type":{"cbacd0ac":"code","35fb47ff":"code","fcd4150b":"code","464cb975":"code","a373ed31":"code","f5b91623":"code","0b28dc4e":"code","7cb6f9cd":"code","ac498c42":"code","8b158b76":"code","be59559b":"code","3cc539e1":"code","0de73638":"code","e89eb732":"code","a7bf54eb":"code","3a44f269":"code","03af3ac3":"code","20554f9e":"code","d8eec9d7":"code","05b8bd70":"code","b799b72f":"code","015d8be0":"code","b5bf3446":"code","6f1b00e8":"code","d3a19258":"code","fcefe702":"code","ed2a8aff":"code","f5894e30":"code","2ca0bf37":"code","a0d1b62e":"code","35b89af7":"code","432cc3aa":"code","92d9dfc0":"code","f70b2462":"code","77baa438":"code","2ddddbf6":"code","aa07410c":"code","f5072407":"code","35521094":"code","7960561c":"code","ed5a5262":"code","32c50676":"code","146f8208":"code","4b0cd669":"code","085bf393":"code","d90b3a41":"code","fb5cd443":"code","cb48c484":"code","bac5d36e":"code","753b24c4":"code","089b5951":"code","6ea27e10":"code","3a5c6f51":"code","b14e1fa9":"code","233b8d41":"code","fd2dd597":"code","ae38f2e0":"code","3001e3ff":"code","659c3198":"code","af20186a":"code","3a919cf0":"code","553e161e":"code","02f92c5f":"code","4bacdcd4":"code","ea7ef5ae":"code","9c9c3963":"code","b8d86fd4":"code","6fe02a25":"code","eff4d3bc":"code","4da1c0b7":"code","e2efb42c":"code","febaf69e":"code","61230e64":"code","d0a552c7":"code","234985c0":"code","7be4f204":"code","f809e3fe":"code","97a670b1":"code","bc07848c":"code","6cc3e33a":"code","80818edb":"code","f23eb15a":"code","5540f05d":"code","0c193536":"code","dd7b4301":"code","e3e2b2b8":"code","e1ed7b97":"code","590a8432":"code","f3189d94":"code","ff76aca6":"code","d5cd43ab":"code","1d58a267":"code","d9b4ef6a":"code","42c7ea4e":"code","cc040888":"code","b29846bd":"code","1e33a2b0":"code","973d04f6":"code","d2d9df98":"code","b31c72c4":"code","441f6380":"code","d7abdf8a":"code","44a79fd4":"code","225e31b5":"code","81723ef0":"code","5c3c05df":"code","546d904c":"code","7595bcbd":"code","37f281ba":"code","9306316f":"code","471dc391":"code","650bfc2b":"code","787c2009":"code","b78a1f78":"code","cea1a71f":"code","cc49a727":"code","42c8d6e5":"code","3d1eef57":"code","370fb947":"code","7729d9cf":"code","1d856dbd":"code","63b0a7d6":"code","b8d96d7b":"code","0a90fe2a":"code","49641961":"code","b310a917":"code","c4e47dfc":"code","22997188":"code","30a17393":"code","aeceec96":"code","05bb87a5":"code","81392dc0":"code","64cc59d9":"code","07c91ff9":"code","eef32669":"code","e34e8807":"code","21851ba7":"code","7c133a94":"code","bb3e5b57":"code","b5b98e93":"code","ea26de55":"code","8052fb48":"code","a8af5279":"code","7096516b":"code","9cd0be21":"code","02aa6406":"code","a999eed8":"code","9ddc980f":"code","100ba83c":"code","d301b8e8":"code","2db908a8":"markdown","a4e53727":"markdown","326ca978":"markdown","9c644559":"markdown","b50b96b5":"markdown","bd1c37d1":"markdown","3dcdbd5f":"markdown","bd297001":"markdown","3778e719":"markdown","09b55754":"markdown","59e6d6f4":"markdown","87f4acd2":"markdown","210d8ae1":"markdown","7c513258":"markdown","8498cdd5":"markdown","3dc89249":"markdown","0f736dc0":"markdown","ccd77a7e":"markdown","fdedbfaf":"markdown","68ba0bd9":"markdown","2920b695":"markdown","5da75140":"markdown","fcbc9970":"markdown","72b62dfa":"markdown","6c401b4b":"markdown","a6edfd95":"markdown","23fff307":"markdown","1fa835b6":"markdown","4ce2ea03":"markdown","ac9589c9":"markdown","956be8fb":"markdown","fa885e4f":"markdown","f67a2da1":"markdown","68227d1e":"markdown","04fce1eb":"markdown","9546e572":"markdown","2d4d9b31":"markdown","853712e1":"markdown","23d264a7":"markdown","de224473":"markdown","f54fbe15":"markdown","9ae3c8a6":"markdown","991dc65f":"markdown","0e07a8e4":"markdown","e6f49937":"markdown","3cf821cc":"markdown","caf491e1":"markdown","5f112979":"markdown","a1beb412":"markdown","096dc617":"markdown","203d9adb":"markdown","674a0f11":"markdown","7964e59b":"markdown","9fce10ab":"markdown","84cb9b14":"markdown","dc0803d8":"markdown","12e8a755":"markdown","0bf0cfce":"markdown","d1412b46":"markdown","4c512935":"markdown","7c40623d":"markdown","4a341654":"markdown","81ba784a":"markdown","37262840":"markdown","c12af875":"markdown","79c5d732":"markdown"},"source":{"cbacd0ac":"#import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","35fb47ff":"#import the data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","fcd4150b":"import missingno as msno\nmsno.matrix(train)","464cb975":"msno.bar(train)","a373ed31":"#analysis of the cabin \ntrain[(train['Cabin'].isnull()) & train['Survived'] == 1]\nprint(f\"Persons with Missing Cabin that survived {len(train[(train['Cabin'].isnull()) & train['Survived'] == 1])}\")\n\n\ntrain[(train['Cabin'].isnull()) & train['Survived'] == 0]\nprint(f\"Persons with Missing Cabin that didn\\'t survived {len(train[(train['Cabin'].isnull()) & (train['Survived'] == 0)])}\")","f5b91623":"#indicator variable \ntrain['Cabin_missing'] = np.where(train['Cabin'] == '#',1,0)\ntest['Cabin_missing'] = np.where(test['Cabin'] == '#',1,0)","0b28dc4e":"#Delete 'Cabin' column as it has a a lot of missing values\ndel train['Cabin']\ndel test['Cabin']","7cb6f9cd":"#analysis of the missing persons\ntrain[(train['Age'].isnull()) & train['Survived'] == 1]\nprint(f\"Persons with Missing Age that survived {len(train[(train['Age'].isnull()) & train['Survived'] == 1])}\")\n\ntrain[(train['Age'].isnull()) & train['Survived'] == 0]\nprint(f\"Persons with Missing Age that didn\\'t survived {len(train[(train['Age'].isnull()) & (train['Survived'] == 0)])}\")","ac498c42":"train['Age_missing'] = np.where(train['Age'].isnull(),1,0)\ntest['Age_missing'] = np.where(test['Age'].isnull(),1,0)","8b158b76":"train['Embarked'].value_counts()","be59559b":"#repalce the missing values 'Embarked' column with the highest occuring frequency.\ntrain['Embarked'] = train['Embarked'].fillna('S') \ntest['Embarked'] = test['Embarked'].fillna('S') ","3cc539e1":"def extract_ticket_length(x):\n    try:\n        return len(x.split(' ')[1])        \n    except IndexError:\n        return len(x.split(' ')[0])","0de73638":"train['Ticket_length'] = train['Ticket'].apply(lambda x: extract_ticket_length(x))\ntest['Ticket_length'] = test['Ticket'].apply(lambda x: extract_ticket_length(x))","e89eb732":" train.describe().T","a7bf54eb":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (9,9))\nsns.countplot(x=\"Survived\", data=train)\n#annotatinos\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")","3a44f269":"fig = px.pie(train,values=\"Survived\",names=\"Sex\",template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Sex composition of Survive Passengers',\n           layout_showlegend=False)","03af3ac3":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Pclass\", data=train,ax = ax[0])\nsns.countplot(x=\"Pclass\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","20554f9e":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.countplot(x=\"Pclass\",hue = 'Sex',data=train)\nfig.suptitle('Composition of passenger classs', fontsize =15)\n#annotations\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","d8eec9d7":"ax = sns.catplot(x ='Pclass', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs Ticket class ')","05b8bd70":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Pclass\",hue = 'Survived',data=train[train['Sex'] == 'male'],ax = ax[0])\nsns.countplot(x=\"Pclass\",hue = 'Survived', data=train[train['Sex'] == 'female'],ax = ax[1])\nax[0].set_title('Male')\nax[1].set_title('Female')\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")\nfig.suptitle('Sex Composition of passenger classs', fontsize =15)   ","b799b72f":"fig,ax = plt.subplots(figsize = (15,6))\nax = sns.boxplot(y=\"Pclass\", x=\"Age\",orient=\"h\", data=train)\nfig.suptitle('Age distribution of passenger classs', fontsize=15)","015d8be0":"fig = px.pie(train,\n             values=\"Fare\",\n             names=\"Pclass\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Percentage of Fare collected through Pclass',\n           layout_showlegend=False)\nfig.show()","b5bf3446":"print('Total Passengers by Pclass')\nprint(train['Pclass'].value_counts())","6f1b00e8":"print('Total Survived Passengers by Pclass')\nprint(train[train['Survived'] == 1]['Pclass'].value_counts())","d3a19258":"print('Percentage of  Survived Passengers by Pclass')\ntrain[train['Survived'] == 1]['Pclass'].value_counts() \/ train['Pclass'].value_counts()","fcefe702":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Sex\", data=train,ax = ax[0])\nsns.countplot(x=\"Sex\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 3,height ,ha=\"center\")","ed2a8aff":"fig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train)\nfig.suptitle('Distribution of passenger\\'s age', fontsize=15)","f5894e30":"print('Passengers composition by Sex')\ntrain['Sex'].value_counts()","2ca0bf37":"print('Survived Passengers composition by Sex')\ntrain[train['Survived'] == 1]['Sex'].value_counts()","a0d1b62e":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x=train['Age'],color = '#6edb00')","35b89af7":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True ,data=train,ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train,ax = ax[1])","432cc3aa":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x = train[train['Age'] <=18.0]['Age'],color = '#d9003d')\nfig.suptitle('Age distribution of minors', fontsize=15)","92d9dfc0":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['Age'] <=18.0],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['Age'] <=18.0],ax = ax[1])\nfig.suptitle('Age distribution of minors', fontsize=15)","f70b2462":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Age'] <=18.0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Age'] <=18.0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Survival percenatge of minors', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","77baa438":"print('Total minors Sex-wise')\ntrain[train['Age'] <=18.0]['Sex'].value_counts()","2ddddbf6":"#extract the initial title of the name\ntrain['Name_prefix'] = train['Name'].apply(lambda x : x.split(',')[1].split('.')[0])\ntest['Name_prefix'] = test['Name'].apply(lambda x : x.split(',')[1].split('.')[0])","aa07410c":"fig,ax = plt.subplots(figsize = (15,6))\nax = sns.countplot(x = 'Name_prefix',data = train)\n#annotations\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,height ,ha=\"center\")\nfig.suptitle('Count of Prefix name of Passengers', fontsize=15)","f5072407":"frequent_initial_names = train['Name_prefix'].value_counts().head(4).index","35521094":"def rare_names(x):\n    if x in frequent_initial_names:\n        return x\n    else:\n        return 'Rare'","7960561c":"#replace all the uncommon names with 'Rare'\ntrain['Name_prefix'] = train['Name_prefix'].apply(lambda x: rare_names(x))\ntest['Name_prefix'] = test['Name_prefix'].apply(lambda x: rare_names(x))","ed5a5262":"train['Name_prefix'] = train['Name_prefix'].str.replace('Ms','Miss')\n#Mlle means 'Miss' in french\ntrain['Name_prefix'] = train['Name_prefix'].str.replace('Mlle','Miss')\n#Mme means 'Mrs' in french\ntrain['Name_prefix'] = train['Name_prefix'].str.replace('Mme','Mrs')\n\ntest['Name_prefix'] = test['Name_prefix'].str.replace('Ms','Miss')\n#Mlle means 'Miss' in french\ntest['Name_prefix'] = test['Name_prefix'].str.replace('Mlle','Miss')\n#Mme means 'Mrs' in french\ntest['Name_prefix'] = test['Name_prefix'].str.replace('Mme','Mrs')","32c50676":"fig,ax = plt.subplots(figsize = (9,9))\nax = plt.pie(x=train['Name_prefix'].value_counts(), autopct=\"%.1f%%\", labels = train['Name_prefix'].value_counts().index,pctdistance=0.5)\nfig.suptitle('Compositon of prefix name', fontsize=15)","146f8208":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"SibSp\", data=train,ax = ax[0])\nsns.countplot(x=\"SibSp\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor p in ax[0].patches:\n    height = p.get_height()\n    ax[0].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")","4b0cd669":"ax = sns.catplot(x ='SibSp', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs sibling \/ spouce abord ')","085bf393":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['SibSp'] >= 1],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['SibSp'] >= 1],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with one or more siblings \/ spouce', fontsize=15)","d90b3a41":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] >= 1],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] >= 1],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least one siblings \/ spouce', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","fb5cd443":"print('Gender distribution of Passengers who travelled with one or more siblings\/spouce')\ntrain[(train['SibSp'] >= 1)]['Sex'].value_counts()","cb48c484":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['SibSp'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['SibSp'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with no siblings \/ spouce', fontsize=15)","bac5d36e":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] == 0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] == 0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least no siblings \/ spouce', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","753b24c4":"print('Gender distribution of Passengers who travelled with no siblings')\ntrain[(train['SibSp'] == 0)]['Sex'].value_counts()","089b5951":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nax[0] = sns.countplot(x=\"Parch\", data=train,ax = ax[0])\nax[1] = sns.countplot(x=\"Parch\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(1):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","6ea27e10":"ax = sns.catplot(x ='Parch', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs Parent \/ child abord ')","3a5c6f51":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['Parch'] >= 1],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['Parch'] >= 1],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with one or more siblings \/ spouce', fontsize=15)","b14e1fa9":"print('Age description of passengers who travelled with one or more parents \/ children')\ntrain[train['Parch'] >= 1]['Age'].describe()","233b8d41":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Parch'] >= 1],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Parch'] >= 1],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least one parents \/ children', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","fd2dd597":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['Parch'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['Parch'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with no parent \/ child', fontsize=15)","ae38f2e0":"print('Age description of passengers who travelled with no parent \/ child')\ntrain[train['Parch'] == 0]['Age'].describe()","3001e3ff":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Parch'] == 0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Parch'] == 0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least no parent \/ child', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","659c3198":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled without family', fontsize=15)","af20186a":"print('Age description of passengers who travelled without family')\ntrain[(train['Parch'] == 0) & (train['SibSp'] == 0)]['Age'].describe()","3a919cf0":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled without family', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","553e161e":"# train['Without_family'] = np.where((train['Parch'] == 0) & (train['SibSp'] == 0),1,0)\n# test['Without_family'] = np.where((test['Parch'] == 0) & (test['SibSp'] == 0),1,0)","02f92c5f":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x=train['Fare'],color = '#ff7a70')","4bacdcd4":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True, data=train,ax = ax[0])\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data=train,ax = ax[1])","ea7ef5ae":"for i in np.arange(1,4):\n    fig,ax = plt.subplots(figsize = (15,6))\n    sns.histplot(x=\"Fare\",hue = 'Survived',kde = True,data = train[train['Pclass'] == i])\n    fig.suptitle(f'Distribution of {i} class Fare', fontsize=15)\n","9c9c3963":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data = train[train['Fare'] >= 100 ])\nfig.suptitle('Passengers whose Fare is more than \u00a3 100', fontsize=15)","b8d86fd4":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nax[0] = sns.countplot(x=\"Survived\", data = train[train['Fare'] >= 100 ],ax = ax[0])\nax[1] = sns.countplot(x=\"Survived\", data = train[train['Fare'] >= 100 ],hue = 'Sex',ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")\n        \nfig.suptitle('Survival of Passengers whose Fare is more than \u00a3 100', fontsize=15) ","6fe02a25":"print('Survived passengers whose ticket costs more than \u00a3 100')\ntrain[train['Fare'] >= 100 ]['Survived'].value_counts()","eff4d3bc":"print('Sex composition survived passengers whose ticket costs more than \u00a3 100')\ntrain[(train['Fare'] >= 100) & train['Survived'] == 1]['Sex'].value_counts()","4da1c0b7":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data = train[train['Fare'] <= 50 ])\nfig.suptitle('Passengers whose Fare is less than \u00a3 50', fontsize=15)","e2efb42c":"fig,ax = plt.subplots(figsize = (9,6))\nax = sns.countplot(x=\"Survived\", data = train[train['Fare'] <= 50 ])\n#annotatinos\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\nfig.suptitle('Survival of Passengers whose Fare is less than \u00a3 50', fontsize=15)    ","febaf69e":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Embarked\",data=train,ax = ax[0])\nsns.countplot(x=\"Embarked\",hue = 'Survived', data=train,ax = ax[1])\n#annnotations\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\n#add title\nfig.suptitle('Passengers count', fontsize=15)","61230e64":"fig = px.pie(train,\n             values=\"Fare\",\n             names=\"Embarked\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Percentage of Fare collected through Embarked',\n           layout_showlegend=False)\nfig.show()\n","d0a552c7":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Embarked\",hue = 'Pclass',data=train,ax = ax[0])\nsns.countplot(x=\"Embarked\",hue = 'Sex', data=train,ax = ax[1])\n#annnotations\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\n#add title\nfig.suptitle('Ticket Class and Sex composition', fontsize=15)","234985c0":"train.skew()","7be4f204":"train.kurt()","f809e3fe":"for i in train.columns[1:]:\n    if train[i].dtype != 'object':\n        print(i)\n        print('IQR: ',train[i].quantile(.75) - train[i].quantile(.25))\n        print('')\n","97a670b1":"train.corr()","bc07848c":"plt.figure(figsize=(9,9))\nsns.heatmap(train.drop(['PassengerId','Cabin_missing', 'Age_missing',\n       'Ticket_length', 'Name_prefix',],axis = 1).corr(), vmax=1, square=True,annot=True,cmap='RdBu')\nplt.title('Correlation between different attributes')\nplt.show()","6cc3e33a":"sns.pairplot(train.drop(['PassengerId','Cabin_missing', 'Age_missing',\n       'Ticket_length', 'Name_prefix', ],axis = 1), hue=\"Survived\")","80818edb":"test.columns","f23eb15a":"train.columns","5540f05d":"#grab the ids of the passenger's id of the test data\nids = test['PassengerId']","0c193536":"cols_to_drop = ['PassengerId','Name','Ticket']","dd7b4301":"train = train.drop(['PassengerId','Name','Ticket'],axis = 1)\ntest = test.drop(['PassengerId','Name','Ticket'],axis = 1)","e3e2b2b8":"from sklearn.model_selection import train_test_split","e1ed7b97":"# separate intro train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop('Survived', axis=1),  # just the features\n    train['Survived'],  # the target\n    test_size=0.3,  # the percentage of obs in the test set\n    random_state=0)  # for reproducibility\n\nX_train.shape, X_test.shape","590a8432":"#impute the misssing values with median\nX_test['Age'] = X_test['Age'].fillna(X_train['Age'].median())\nX_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())","f3189d94":"#impute the misssing values with median in the test\ntest['Age'] = test['Age'].fillna(X_train['Age'].median())\ntest['Fare'] = test['Fare'].fillna(X_train['Fare'].median())","ff76aca6":"print('Check the missing values of test')\ntest.isnull().sum()","d5cd43ab":"pip install feature_engine","1d58a267":"from feature_engine.encoding import OneHotEncoder as fe_OneHotEncoder","d9b4ef6a":"ohe_enc = fe_OneHotEncoder(\n    top_categories=None,\n    drop_last=True) ","42c7ea4e":"ohe_enc.fit(X_train)","cc040888":"X_train = ohe_enc.transform(X_train)\nX_test = ohe_enc.transform(X_test)\ntest = ohe_enc.transform(test)","b29846bd":"#scale the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_std = scaler.transform(X_train)\nX_test_std = scaler.transform(X_test)\ntest_std = scaler.transform(test)","1e33a2b0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics","973d04f6":"logisticRegr = LogisticRegression(penalty='l1', solver='liblinear')\n#fit the model\nlogisticRegr.fit(X_train_std, y_train)","d2d9df98":"#predictions and score\npredictions = logisticRegr.predict(X_test_std)\nprint(f\"The score on the Test-dataset is {logisticRegr.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticRegr.score(X_train_std, y_train)}\")","b31c72c4":"def plot_condution_metrics(y_test,predictions):\n    #condusion metrics\n    cm = metrics.confusion_matrix(y_test, predictions)\n    score = np.mean([y_test == predictions])\n    #plot\n    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=1, square = True,cbar = False);\n    plt.ylabel('Actual label');\n    plt.xlabel('Predicted label');\n    all_sample_title = 'Accuracy Score: {0}'.format(score)\n    plt.title(all_sample_title, size = 15);","441f6380":"#confusion metrics\nplot_condution_metrics(y_test,predictions)","d7abdf8a":"#cross-val score\nscore = cross_val_score(logisticRegr, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","44a79fd4":"#store the cv-score\nmodel_performance = {}\nmodel_performance['Logistic Regression(Lasso)'] = score.mean()","225e31b5":"logisticRegr = LogisticRegression(penalty='l2', solver='liblinear')\n#fit the model\nlogisticRegr.fit(X_train_std, y_train)","81723ef0":"#predictions and score\npredictions = logisticRegr.predict(X_test_std)\nprint(f\"The score on the Test-dataset is {logisticRegr.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticRegr.score(X_train_std, y_train)}\")","5c3c05df":"plot_condution_metrics(y_test,predictions)","546d904c":"#cross-val score\nscore = cross_val_score(logisticRegr, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","7595bcbd":"model_performance['Logistic Regression(Ridge)'] = score.mean()","37f281ba":"from sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\n\n#trasform into polynomial features\nX_train_p = poly.fit_transform(X_train)\nX_test_p = poly.fit_transform(X_test)\n\n#standard scale\nscaler = StandardScaler()\nscaler.fit(X_train_p)\nX_train_std_poly = scaler.transform(X_train_p)\nX_test_std_poly = scaler.transform(X_test_p)","9306316f":"#fit the model\nlogisticPolyRegr = LogisticRegression(solver='liblinear')\nlogisticPolyRegr.fit(X_train_std_poly, y_train)\n\n#predictions and score\npredictions = logisticPolyRegr.predict(X_test_std_poly)\nprint(f\"The score on the Test-dataset is {logisticPolyRegr.score(X_test_std_poly, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticPolyRegr.score(X_train_std_poly, y_train)}\")","471dc391":"plot_condution_metrics(y_test,predictions)","650bfc2b":"#cross-val score\nscore = cross_val_score(logisticPolyRegr, X_train_std_poly, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","787c2009":"model_performance['Polynomial Logistic Regression'] = score.mean()","b78a1f78":"poly_degrees = [2,3,4]\ndegree_loop_values = []\nfor degree in poly_degrees:\n    poly = PolynomialFeatures(degree = degree)\n\n    #trasform into polynomial features\n    X_train_p = poly.fit_transform(X_train)\n    X_test_p = poly.fit_transform(X_test)\n\n    #standard scale\n    scaler = StandardScaler()\n    scaler.fit(X_train_p)\n    X_train_std_poly = scaler.transform(X_train_p)\n    X_test_std_poly = scaler.transform(X_test_p)\n    \n    logisticPolyRegr = LogisticRegression(solver='liblinear')\n    logisticPolyRegr.fit(X_train_std_poly, y_train)\n\n    score = cross_val_score(logisticPolyRegr, X_train_std_poly, y_train, cv=10,scoring='accuracy')\n    degree_loop_values.append([degree,score.mean(),np.std(score)])","cea1a71f":"pd.DataFrame(degree_loop_values,columns = ['Degree','Mean_cv','Std_cv'],)","cc49a727":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\ngnb = GaussianNB()\npredictions = gnb.fit(X_train_std, y_train).predict(X_test_std)","42c8d6e5":"print(f\"The score on the Test-dataset is {gnb.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {gnb.score(X_train_std, y_train)}\")","3d1eef57":"plot_condution_metrics(y_test,predictions)","370fb947":"#cross-val score\nscore = cross_val_score(gnb, X_train, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","7729d9cf":"model_performance['Naive Bayes (gausian)'] = score.mean()","1d856dbd":"from sklearn.svm import SVC","63b0a7d6":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n    {\n        \"C\" : [0.01,1,5],\n        \"gamma\" : ['scale',0.09,0.1,0.5],\n        \"kernel\" : ['rbf']\n        \n    },\n]\noptimat_parameters = GridSearchCV(\n    SVC(),\n    param_grid,\n    cv = 9,\n    scoring = 'accuracy',\n    verbose = 0\n)\noptimat_parameters.fit(X_train_std,y_train)\nprint(optimat_parameters.best_params_)","b8d96d7b":"from sklearn import svm\nclf_svm = svm.SVC(C =  1, gamma = 0.1,kernel = 'rbf',random_state = 42)\npredictions = clf_svm.fit(X_train_std, y_train).predict(X_test_std)","0a90fe2a":"print(f\"The score on the Test-dataset is {clf_svm.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_svm.score(X_train_std, y_train)}\")","49641961":"plot_condution_metrics(y_test,predictions)","b310a917":"#cross-val score\nscore = cross_val_score(clf_svm, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","c4e47dfc":"model_performance['SVM (rbf)'] = score.mean()","22997188":"from sklearn.tree import DecisionTreeClassifier,plot_tree\n\nclf_dt = DecisionTreeClassifier(random_state=42)","30a17393":"#build a preliminary tree\npredictions = clf_dt.fit(X_train, y_train).predict(X_test)","aeceec96":"fig,ax = plt.subplots(figsize = (25,12))\nax = plot_tree(\n    clf_dt,\n    filled = True,\n    rounded = True,\n    class_names = ['Not Survived',\"Survived\"],\n    feature_names = X_train.columns\n    \n)","05bb87a5":"print(f\"The score on the Test-dataset is {clf_dt.score(X_test, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_dt.score(X_train, y_train)}\")","81392dc0":"plot_condution_metrics(y_test,predictions)","64cc59d9":"#cross-val score\nscore = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","07c91ff9":"path = clf_dt.cost_complexity_pruning_path(X_train,y_train)\nccp_alphas = path.ccp_alphas\nccp_alphas = ccp_alphas[:-1]\n\ncct_dts = []\n\nfor ccp_alpha in ccp_alphas:\n    clf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = ccp_alpha)\n    clf_dt.fit(X_train,y_train)\n    cct_dts.append(clf_dt)\n    \n","eef32669":"train_scores = [clf.score(X_train, y_train) for clf in cct_dts]\ntest_scores = [clf.score(X_test, y_test) for clf in cct_dts]\n\nfig, ax = plt.subplots(figsize = (12,9))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","e34e8807":"#looking at the figure and 'eye-balling' we see the alpha of 0.00375 could be a bette value\n# using K-fold CV\nclf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = 0.00375)\nscores = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\n#plot \ndf_cv = pd.DataFrame(data = {'tree' : range(9),'accuracy':scores})\ndf_cv.plot(x = 'tree',y = 'accuracy',marker = 'o',linestyle = '--')","21851ba7":"alpha_loop_values = []\n\nfor ccp_alpha in ccp_alphas:\n    clf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = ccp_alpha)\n    scores = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\n    alpha_loop_values.append([ccp_alpha,np.mean(scores),np.std(scores)])\n    \n#storing in a pandas datframe\nalpha_df = pd.DataFrame(alpha_loop_values,columns = ['alpha','mean_Score','std_score'])\n\n#plot df\nalpha_df.plot(x = 'alpha',y = 'mean_Score',marker = 'o',linestyle = '--')","7c133a94":"print('alpha values with cv score > .8')\nalpha_df[alpha_df['mean_Score'] > .8 ].sort_values(by = 'mean_Score',ascending = False)","bb3e5b57":"ideal_alpha = 0.008865","b5b98e93":"clf_dt_prune = DecisionTreeClassifier(random_state=42,ccp_alpha = ideal_alpha)\npredictions = clf_dt_prune.fit(X_train, y_train).predict(X_test)","ea26de55":"fig,ax = plt.subplots(figsize = (25,9))\nax = plot_tree(\n    clf_dt_prune,\n    filled = True,\n    rounded = True,\n    class_names = ['Not Survived',\"Survived\"],\n    feature_names = X_train.columns\n    \n)","8052fb48":"print(f\"The score on the Test-dataset is {clf_dt_prune.score(X_test, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_dt_prune.score(X_train, y_train)}\")","a8af5279":"plot_condution_metrics(y_test,predictions)","7096516b":"#cross-val score\nscore = cross_val_score(clf_dt_prune, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","9cd0be21":"model_performance['Decison Tree'] = score.mean()","02aa6406":"model_performance","a999eed8":"model_df = pd.DataFrame.from_dict(model_performance,orient = 'index',columns = ['Mean CV Score'])\nmodel_df = model_df.sort_values(by ='Mean CV Score',ascending = False)\nmodel_df","9ddc980f":"gig,ax = plt.subplots(figsize = (12,6))\nsns.barplot(x=\"Mean CV Score\", y=model_df.index, data=model_df,color = '#fc8a26')","100ba83c":"#scale the test data\npredictions = clf_svm.predict(test_std)","d301b8e8":"output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","2db908a8":"## Titanic Survial Prediction\n\n![](https:\/\/i.imgur.com\/aQANpYt.gif)\n\n* I made it into a full-featured web app. You can visit it here [Titanic Survival Prediction](https:\/\/dibkb-titanic.herokuapp.com\/)\n* The code for the Web app in available on [Github](https:\/\/github.com\/dibkb\/Titanic-Survival)","a4e53727":"##### Analysis of passengers whose fare is less than \u00a3 50","326ca978":"#### Column : Survived\n","9c644559":"#### Column: Fare\n<br>","b50b96b5":"#### <li>About 74.2 % (233) of the total Female passengers (314) survived.\n#### <li>About 18.89 % (109) of the total Male passengers (577) survived.","bd1c37d1":"Since more people with missing Cabin didn't survive, It is not missing at random.Let's explore this further","3dcdbd5f":" As we see on one split i returns a very low accuracy of about 73%. So this value of alpha may not be the best\n So we use K-fold CV on all the values of alpha to find the optimum parameter","bd297001":"##### Passengers travelling with no parent  \/ child.","3778e719":"#### Cost-complxity prunnig the decison tree","09b55754":"Create a new feature 'Ticket Length'","59e6d6f4":"#### Column : SibSp (Number of Siblings \/ Spouses Aboard)\n<br>","87f4acd2":"Since some of the initial names contains rare features let's convert them into an umbrella category 'Rare'","210d8ae1":"##### Passengers travelling with one or more siblings \/ spouce.","7c513258":"#### One Hot Encoding","8498cdd5":"### Model Preparation","3dc89249":"Looking at the figure and 'eye-balling' we see the alpha of 0.00375 could be a bette value","0f736dc0":"#### <li>About 55.1 % (491) of the total passengers (891) booked 3rd class ticket.\n#### <li>About 62.96 % (136) of the total 1st classs passengers (184) survived.\n#### <li>Only 24.23% (119) of the total 3rd classs passengers (491) survived.  ","ccd77a7e":"Missing Age could be an important feature.","fdedbfaf":"#### <li>About 60.26% (537) of the passengers (891) travelled without family.\n#### <li>About 84.42% (347) of the male passengers (411) who travelled without family couldn\\'t survive","68ba0bd9":"### Explanatory Data Analysis","2920b695":"##### Passengers travelling with one or more parents \/ children.","5da75140":"#### Support Vector Machine","fcbc9970":"#### Polynomial Logistic Regression","72b62dfa":"#### Column : Name\n<br>","6c401b4b":"#### <li>About 15.60% (139) of the total passengers (891) were minors. \n#### <li>About 50.35% (70) of the minor passengers (139) survived. \n#### <li>About 67.64% (46) of the female-minor passengers (68) survived.","a6edfd95":"#### <li>About 46.64% (132) of the total passengers (283) survived who travelled with one or more siblings \/ spouce. \n#### <li>About 44.58% (140) of the total female-passengers (314) travelled with one or more siblings \/ spouce. \n#### <li>About 68.57% (96) of the total female-passengers (140) survived who travelled with one or more siblings \/ spouce.\n#### <li>Only 25.17% (36) of the total male-passengers (143) survived who travelled with one or more siblings \/ spouce. ","23fff307":"#### Column : Pclass\n<br>","1fa835b6":"#### <li>About 34.36% (109) of the total passengers (678) survived who travelled with one or more parent \/ child. \n#### <li>About 48.72% (153) of the total female-passengers (314) survived travelled with one or more parent \/ child. \n ","4ce2ea03":"#### Kurtosis","ac9589c9":"#### Visualizing the model performance","956be8fb":"#### Cabin Missing Column","fa885e4f":"#### As we can see the Support Vector Machine with the 'rbf' kernel gives the best result","f67a2da1":"##### Fare Vs Passengers class","68227d1e":"#### <li>Only about 38.38 % (342) of the total passengers (891) survived.","04fce1eb":"#### IQR (Inter Quartile Range)","9546e572":"#### Logistic Regression(Lasso)","2d4d9b31":"#### <li>About 82.04% (731) of the total passenger's (891) fare was less than \u00a3 50. \n#### <li>Only 31.87% (233) of those survived (731) survived.","853712e1":"##### Passengers travelling with no siblings\/spouce","23d264a7":"#### Builing the optimam SVM model","de224473":"#### Check for missing values","f54fbe15":"The best-fit polynomial degree is 2","9ae3c8a6":"#### Building the best tree","991dc65f":"#### Logistic Regression(Ridge)","0e07a8e4":"#### <li>About 5.94% (53) of the total passenger's (891) fare was more than \u00a3 100. \n#### <li>About 73.58% (39) of those passengers (53) survived. \n#### <li>About 82.05% (32) of those survived (39) were females.","e6f49937":"#### <li>About 62.968 % (136) of the 1st classs passengers (216) survived.\n#### <li>Only 24.23% (119) of the 3rd classs passengers (491) survived.","3cf821cc":"#### Making Submissions\n","caf491e1":"### Data Preprocessing","5f112979":"##### Analysis of passengers whose fare is more than \u00a3 100","a1beb412":"#### One-hot encoding","096dc617":"#### Column : Embarked (C = Cherbourg; Q = Queenstown; S = Southampton)\n<br>","203d9adb":"#### Grid-Search CV to find the optimum parameters","674a0f11":"##### Passengers travelling without family (without parnent \/ child or sibling \/ spouce)","7964e59b":"#### Column : Sex\n<br>","9fce10ab":"#### <li>About 51.17% (109) of the total passengers (213) survived who travelled with one or more parents \/ children. \n#### <li>About 38.21% (120) of the total female-passengers (314) survived travelled with one or more parents \/ children. \n#### <li>About 66.66% (80) of the total female-passengers (120) survived who travelled with one or more parents \/ children.\n#### <li>About 38.18% (29) of the total male-passengers (93) survived who travelled with one or more parents \/ children. ","84cb9b14":"#### Column : Age\n<br>","dc0803d8":"#### Impute the missing values","12e8a755":"#### <li>About 96.68 % (91) of the female 1st classs passengers (94) survived.\n#### <li>Only 13.54% (47) of the male 3rd classs passengers (347) survive","0bf0cfce":"#### Cross validation to find the optimal value of alpha","d1412b46":"#### Column : Parch (Number of Parents\/Children Aboard)\n<br>","4c512935":"#### <li>Only 34.53% (210) of passengers (610) survived who travelled with no siblings.\n#### <li>About 55.51% (174) of the total female-passengers (314) survived travelled with no siblings.     \n#### <li>About 78.73% (137) of female-passengers (174) survived who travelled with no siblings.\n#### <li>Only 16.62% (73) of male-passengers (434) survived who travelled with no siblings.    ","7c40623d":"#### Cross-validation and Hypeer-parameter tuning","4a341654":"#### Skewness","81ba784a":"#### Let's See the Correlation among these attributes","37262840":"#### Naive Bayes","c12af875":"#### Decision Trees","79c5d732":"#### Analysis of minor-passengers"}}