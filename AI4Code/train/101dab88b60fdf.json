{"cell_type":{"d4d17a33":"code","d2b1bde0":"code","b0ea78e8":"code","3614fc63":"code","31115ee3":"code","47c951f8":"code","1234bef9":"code","30476b28":"code","3ace4721":"code","eb16fe3c":"code","9e4ffa00":"code","bd030b65":"code","d13b185a":"code","eba3c43b":"code","2f63b2d0":"code","d45cfe49":"code","55bfd2a2":"code","b665c1a5":"code","93c9f07e":"code","6d4fb38d":"code","73545d1a":"code","795ea337":"code","fe1c4118":"code","2eb33e2e":"code","f36f1784":"code","9741be20":"code","c121bf9f":"code","21b9688a":"code","6e450768":"markdown","7cc4d195":"markdown","db6dda15":"markdown","b7917c00":"markdown","a8e20084":"markdown","6c833bf4":"markdown","d1dac227":"markdown","6a8c8c16":"markdown","db7bd08f":"markdown","7bb1a05f":"markdown","03ac48f0":"markdown","8c06edb2":"markdown","c787a442":"markdown","40cec245":"markdown","6de63c75":"markdown","ca55b6f5":"markdown","5ff3893b":"markdown","7129284a":"markdown","02448215":"markdown","a3572b6b":"markdown","148028f5":"markdown","a2a3a246":"markdown","0c645ef9":"markdown","12dc2f31":"markdown","2a23a682":"markdown","c317b39a":"markdown","1b657678":"markdown"},"source":{"d4d17a33":"# library imports\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# printing list of files available to us\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d2b1bde0":"bib = pd.read_csv(\"\/kaggle\/input\/hindi-bible\/Hindi_bible_with_authors.csv\")\nbib = bib.drop('Unnamed: 0', axis=1)\nbib.head()","b0ea78e8":"with open(\"\/kaggle\/input\/hindi-bible\/hindi_bible_books.txt\",mode='r', encoding='utf-8-sig') as f:\n    books = f.read()\nbooks = books.split('\\n')\nNT_books = [i.strip('\"') for i in books[39:66]]\nprint(NT_books)","3614fc63":"df = pd.DataFrame(bib.groupby(\"Book Name\").size()\/(len(bib))*100, columns=[\"% occurrences\"])\ndf[\"Testament\"] = df.index.to_series().map(lambda x: 1 if x in NT_books else 0)\ndf = df.sort_values(\"% occurrences\",ascending=False)\ndf.head()","31115ee3":"from matplotlib.font_manager import FontProperties\nimport matplotlib.patches as mpatches\nhindi_font = FontProperties(fname = \"\/kaggle\/input\/hindi-bible\/Nirmala.ttf\")\ncolors = {0:'red', 1:'blue'}\nred_patch = mpatches.Patch(color='red',alpha=0.5, label='Old Testament')\nblue_patch = mpatches.Patch(color='blue',alpha=0.5, label='New Testament')\nplt.grid()\nplt.bar(df.index, df[\"% occurrences\"], align='center', alpha=0.5, color=df['Testament'].apply(lambda x: colors[x]))\nplt.xticks(df.index, color=\"b\", fontproperties=hindi_font, rotation=90, fontsize = 12)\nplt.yticks(fontsize = 15)\nplt.ylabel('% occurrences',fontsize = 20)\nplt.title('Percentage Book wise portions',fontsize = 20)\nplt.legend(handles=[red_patch,blue_patch])\nplt.gca().margins(x=0)\nplt.gcf().canvas.draw()\ntl = plt.gca().get_xticklabels()\nmaxsize = max([t.get_window_extent().width for t in tl])\nm = 0.5 # inch margin\ns = maxsize\/plt.gcf().dpi*55+2*m\nmargin = m\/plt.gcf().get_size_inches()[0]\n\nplt.gcf().subplots_adjust(left=margin, right=1.-margin)\nplt.gcf().set_size_inches(s, plt.gcf().get_size_inches()[1])","47c951f8":"df = pd.DataFrame(bib.groupby(\"Authors\").size()\/(len(bib))*100, columns=[\"% occurrences\"])\ndf = df.sort_values(\"% occurrences\",ascending=False)\ndf.head()","1234bef9":"plt.bar(df.index, df[\"% occurrences\"], align='center', alpha=0.5)\nplt.xticks(df.index, color=\"b\", rotation=90, fontsize = 12)\nplt.yticks(fontsize = 15)\nplt.ylabel('% occurrences',fontsize = 15)\nplt.title('Percentage portions of authors',fontsize = 15);\nplt.gca().margins(x=0)\nplt.gcf().canvas.draw()\ntl = plt.gca().get_xticklabels()\nmaxsize = max([t.get_window_extent().width for t in tl])\nm = 0.5 # inch margin\ns = maxsize\/plt.gcf().dpi*55+2*m\nmargin = m\/plt.gcf().get_size_inches()[0]\nplt.gcf().subplots_adjust(left=margin, right=1.-margin)\nplt.gcf().set_size_inches(s, plt.gcf().get_size_inches()[1])","30476b28":"set(bib[bib[\"Authors\"]==\"unknown\"][\"Book Name\"])","3ace4721":"df_O = pd.DataFrame(bib[bib['Testament Code']==0].groupby(\"Authors\").size()\/(len(bib[bib['Testament Code']==0]))*100, columns=[\"% occurrences\"])\ndf_O = df_O.sort_values(\"% occurrences\",ascending=False)\ndf_N = pd.DataFrame(bib[bib['Testament Code']==1].groupby(\"Authors\").size()\/(len(bib[bib['Testament Code']==1]))*100, columns=[\"% occurrences\"])\ndf_N = df_N.sort_values(\"% occurrences\",ascending=False)\n\nf, axes = plt.subplots(1, 2,figsize=(13,4), gridspec_kw={'width_ratios': [3, 1]})\naxes[0].bar(df_O.index, df_O[\"% occurrences\"], align='center', alpha=0.5)\nplt.sca(axes[0])\nplt.xticks(df_O.index, color=\"b\", rotation=90, fontsize = 12)\nplt.title('Authors of Old Testament')\nplt.ylabel('% occurences')\n\naxes[1].bar(df_N.index, df_N[\"% occurrences\"], align='center', alpha=0.5, color='r')\nplt.sca(axes[1])\nplt.xticks(df_N.index, color=\"b\", rotation=90, fontsize = 12)\nplt.title('Authors of New Testament')\nplt.tight_layout();","eb16fe3c":"with open(\"\/kaggle\/input\/hindi-bible\/Hindi_StopWords.txt\",encoding='utf-8') as f:\n    stopword= f.read().strip('\\ufeff')\nstopword = stopword.split(\", \")\nstopword = [i.strip(\"'\") for i in stopword]\nprint(stopword)","9e4ffa00":"with open(\"\/kaggle\/input\/hindi-bible\/Full_text_Bible.txt\", mode='r', encoding='utf-8-sig') as f:\n    text= f.read()\nfrom wordcloud import WordCloud\nfrom nltk.tokenize import word_tokenize\n%matplotlib inline\nstopwords = set(stopword)\nwordcloud = WordCloud(font_path=\"\/kaggle\/input\/hindi-bible\/Nirmala.ttf\",width = 800, height = 800, \nbackground_color ='white', \nstopwords = stopwords, \nmin_font_size = 10).generate(text) \n\n# plot the WordCloud image \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis('off') \nplt.tight_layout(pad = 0) \n\nplt.show()","bd030b65":"def generate_stem_words(word):\n    suffixes = {\n    2: [u\"\u0915\u0930\",u\"\u093e\u0913\",u\"\u093f\u090f\",u\"\u093e\u0908\",u\"\u093e\u090f\",u\"\u0928\u0940\",u\"\u0928\u093e\",u\"\u0924\u0947\",u\"\u0924\u0940\",u\"\u093e\u0901\",u\"\u093e\u0902\",u\"\u094b\u0902\",u\"\u0947\u0902\"],\n    3: [u\"\u093e\u0915\u0930\",u\"\u093e\u0907\u090f\",u\"\u093e\u0908\u0902\",u\"\u093e\u092f\u093e\",u\"\u0947\u0917\u0940\",u\"\u0947\u0917\u093e\",u\"\u094b\u0917\u0940\",u\"\u094b\u0917\u0947\",u\"\u093e\u0928\u0947\",u\"\u093e\u0928\u093e\",u\"\u093e\u0924\u0947\",u\"\u093e\u0924\u0940\",u\"\u093e\u0924\u093e\",u\"\u0924\u0940\u0902\",u\"\u093e\u0913\u0902\",u\"\u093e\u090f\u0902\",u\"\u0941\u0913\u0902\",u\"\u0941\u090f\u0902\",u\"\u0941\u0906\u0902\"],    4: [u\"\u093e\u090f\u0917\u0940\",u\"\u093e\u090f\u0917\u093e\",u\"\u093e\u0913\u0917\u0940\",u\"\u093e\u0913\u0917\u0947\",u\"\u090f\u0902\u0917\u0940\",u\"\u0947\u0902\u0917\u0940\",u\"\u090f\u0902\u0917\u0947\",u\"\u0947\u0902\u0917\u0947\",u\"\u0942\u0902\u0917\u0940\",u\"\u0942\u0902\u0917\u093e\",u\"\u093e\u0924\u0940\u0902\",u\"\u0928\u093e\u0913\u0902\",u\"\u0928\u093e\u090f\u0902\",u\"\u0924\u093e\u0913\u0902\",u\"\u0924\u093e\u090f\u0902\",u\"\u093f\u092f\u093e\u0901\",u\"\u093f\u092f\u094b\u0902\",u\"\u093f\u092f\u093e\u0902\"],\n    5: [u\"\u093e\u090f\u0902\u0917\u0940\",u\"\u093e\u090f\u0902\u0917\u0947\",u\"\u093e\u090a\u0902\u0917\u0940\",u\"\u093e\u090a\u0902\u0917\u093e\",u\"\u093e\u0907\u092f\u093e\u0901\",u\"\u093e\u0907\u092f\u094b\u0902\",u\"\u093e\u0907\u092f\u093e\u0902\"],\n}\n    for L in 5, 4, 3, 2:\n        if len(word) > L + 1:\n            for suf in suffixes[L]:\n                if word.endswith(suf):\n                    return word[:-L]\n    return word","d13b185a":"import collections\nwordcount = {}\n# To eliminate duplicates, we will split by punctuation, and use case demiliters.\nfor word in text.split():\n    word = word.replace(\".\",\"\")\n    word = word.replace(\",\",\"\")\n    word = word.replace(\":\",\"\")\n    word = word.replace(\";\",\"\")\n    word = word.replace(\"\\\"\",\"\")\n    word = word.replace(\"!\",\"\")\n    word = generate_stem_words(word)\n    if word not in stopwords:\n        if word not in wordcount:\n            wordcount[word] = 1\n        else:\n            wordcount[word] += 1\n# most common word\nword_counter = collections.Counter(wordcount)\nfreq_word={}\nfor word, count in word_counter.most_common(20):\n    freq_word[word]=count\nprint(freq_word)\nfreq_df=pd.DataFrame(list(freq_word.items()), index=range(20), columns=['word', 'freq']) \nfig, ax = plt.subplots(figsize=(25,10))\nax.barh(freq_df['word'], freq_df['freq'], align='center')\nax.set_xlabel('Word frequencies', fontsize = 20)\nax.set_title('Top 20 most frequent words in Hindi Bible', fontsize = 20)\nplt.yticks(range(len(freq_word.keys())),list(freq_word.keys()), fontproperties=hindi_font, fontsize = 20);","eba3c43b":"from string import punctuation\nfrom nltk.probability import FreqDist\ntokens = word_tokenize(text)\ncustomStopWords = set(list(stopwords) + list(punctuation+'\u0964'+'\u0965'))\nwordsWOstopwords = [word for word in tokens if word not in customStopWords]\n#removing numeric digits from list of words\nwordsWOstopwords = [i for i in wordsWOstopwords if not i.isdigit()]\nfreq = FreqDist(wordsWOstopwords)\n\ndef freq_finder(word):\n    \"\"\"\n    Input any Hindi word it will return how many times it appears in HHBD version of Bible.\n    \"\"\"\n    return freq[word]\nprint(\"\u092a\u094d\u0930\u0947\u092e appears for {} times while \u0921\u0930 appears for {} times in HHBD Hindi Bible.\".format(freq_finder('\u092a\u094d\u0930\u0947\u092e'),freq_finder('\u0921\u0930')))","2f63b2d0":"wrds = ['\u092f\u0940\u0936\u0941','\u092e\u0938\u0940\u0939','\u0909\u0926\u094d\u0927\u093e\u0930\u0915\u0930\u094d\u0924\u093e','\u0909\u0926\u094d\u0927\u093e\u0930','\u0915\u094d\u0930\u0942\u0938' ]\nEwrds = ['Jesus','Christ', 'Saviour','Salvation','Cross']\nwrds_dict ={}\nn=0\nfor i in wrds:\n    wrds_dict[i+\" \"+\"(\"+Ewrds[n]+\")\"]= freq_finder(i)\n    n+=1\nprint(wrds_dict)","d45cfe49":"freq.pop('\u0930\u093e\u091c\u093e', None)\nfreq","55bfd2a2":"sents =[]\nfor i in text.split(\"\u0965\"):\n    sents.append(i.split('\u0964'))\nsents = [item for sublist in sents for item in sublist]","b665c1a5":"from collections import defaultdict\nranking = defaultdict(int)\nfor i,sent in enumerate(sents):\n    for w in word_tokenize(sent):\n        if w in freq:\n            ranking[i] += freq[w]        ","93c9f07e":"from heapq import nlargest\nsents_indx = nlargest(1, ranking, key=ranking.get)\nsummary = [sents[j] for j in sorted(sents_indx)]\nsummary","6d4fb38d":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.cluster.hierarchy import ward, dendrogram\n#define vectorizer parameters\ntfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n                                 min_df=0.2, stop_words=stopwords,\n                                 use_idf=True, tokenizer=word_tokenize, ngram_range=(1,3))\ntfidf_matrix = tfidf_vectorizer.fit_transform(sents[:10])\n\ndist = 1 - cosine_similarity(tfidf_matrix)\nlinkage_matrix = ward(dist)\ntitles=['\u092a\u0930\u092e\u0947\u0936\u094d\u0935\u0930','\u092a\u0943\u0925\u094d\u0935\u0940','\u0909\u091c\u093f\u092f\u093e\u0932\u093e','\u0905\u0928\u094d\u0927\u093f\u092f\u093e\u0930\u0947','\u0926\u093f\u0928','\u0938\u093e\u0902\u091d','\u092a\u0939\u093f\u0932\u093e','\u091c\u0932','\u090a\u092a\u0930','\u0906\u0915\u093e\u0936']\nfig, ax = plt.subplots(figsize=(6, 5)) # set size\n\nax = dendrogram(linkage_matrix, orientation=\"left\", labels=titles);\n\nplt.tick_params(\\\n    axis= 'x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom='off',      # ticks along the bottom edge are off\n    top='off',         # ticks along the top edge are off\n    labelbottom='off')\nplt.grid()\nplt.yticks(fontproperties=hindi_font,fontsize = 15)\nplt.tight_layout() #show plot with tight layout\nplt.show();","73545d1a":"colnames=[\"POS TAG\",\"HWN ID\",\"+ve score\",\"-ve score\",\"Related words\"]\ndata = pd.read_csv(\"\/kaggle\/input\/hindi-bible\/HSWN_WN.txt\", delimiter=' ',names=colnames,header=None)\ndata.head()","795ea337":"words_dict = {}\nfor i in data.index:\n    words = data[\"Related words\"][i].split(',')\n    for word in words:\n        words_dict[word] = (data[\"POS TAG\"][i], data[\"+ve score\"][i], data[\"-ve score\"][i])\nprint(\"The size of the Hindi SentiWordNet: {} words\".format(len(words_dict)))","fe1c4118":"from textblob import TextBlob\npos_data = pd.read_csv(\"\/kaggle\/input\/hindi-bible\/hindi word list.csv\", header=None, names=[\"Hindi\",\"English\"])\npos_list = pos_data['English'].tolist()\npol_list=[]\nfor i in pos_list:\n    blob =TextBlob(i)\n    pol_list.append(blob.sentiment.polarity) \npos_data[\"polarity\"] = pol_list\npos_data.head()","2eb33e2e":"senti_resource = set(list(words_dict.keys())+list(pos_data['Hindi']))\nprint(\"We have {} unique words without stopwords in Hindi Bible\".format(len(set(wordsWOstopwords))))\nprint(\"And we have total {} unique words in our sentiment resources\".format(len(senti_resource)))\nremaining = [i for i in set(wordsWOstopwords) if i not in senti_resource]\nprint(\"The remaining\u00a0words i.e. total unique words - (senti_resource): {} words\".format(len(set(remaining))))","f36f1784":"def sentiment(text):\n    words = word_tokenize(text)\n    words = [i for i in words if i not in customStopWords]\n    pos_polarity = 0\n    neg_polarity = 0\n    #adverbs, nouns, adjective, verb are only used\n    allowed_words = ['a','v','r','n']\n    for word in words:\n        if word in words_dict:\n            #if word in dictionary, it picks up the positive and negative score of the word\n            pos_tag, pos, neg = words_dict[word]\n            if pos_tag in allowed_words:\n                if pos > neg:\n                    pos_polarity += pos\n                elif neg > pos:\n                    neg_polarity += neg\n        elif word in pos_data['Hindi']:\n            polarity = pos_data[pos_data['Hindi']== word][\"polarity\"]\n            if polarity >= 0:\n                pos_polarity += polarity\n            elif polarity < 0:\n                neg_polarity += polarity\n\n    #calculating the no. of positive and negative words in total in a review to give class labels\n    if pos_polarity > neg_polarity:\n        return 1, pos_polarity\n    else:\n        return 0, -neg_polarity\nprint(\"Overall sentiment and it's polarity of statment: \u092e\u0948\u0902 \u0907\u0938 \u0909\u0924\u094d\u092a\u093e\u0926 \u0938\u0947 \u092c\u0939\u0941\u0924 \u0916\u0941\u0936 \u0939\u0942\u0901 is {}\".format(sentiment(\"\u092e\u0948\u0902 \u0907\u0938 \u0909\u0924\u094d\u092a\u093e\u0926 \u0938\u0947 \u092c\u0939\u0941\u0924 \u0916\u0941\u0936 \u0939\u0942\u0901\")))","9741be20":"full_list = []\nbook_flag = range(66)\nfor j in book_flag:\n    Chapter_txt=[]\n    for i in bib.index:\n        if bib[\"Book\"][i]==book_flag[j]:\n            Chapter_txt.append(bib[\"Text\"][i])\n    Chapter_str = \"\".join(Chapter_txt)\n    full_list.append(Chapter_str)\nprint(\"Length of the resulting list: {}\".format(len(full_list)))   ","c121bf9f":"Books = [i.strip('\"') for i in books[0:66]]\nprint(Books)","21b9688a":"pol_list=[]\nfor i in full_list:\n    polarity = sentiment(i)[1]\n    pol_list.append(polarity)  \nPolarity_dict = dict(zip(Books, pol_list))\npol_df = pd.DataFrame(\n    {'Book': list(Polarity_dict.keys()),\n     'Polarity': list(Polarity_dict.values())\n    })\nfig, ax = plt.subplots(figsize=(12,23))\nax.barh(pol_df[\"Book\"],pol_df[\"Polarity\"] , color='r');\nax.set_xlabel('Sentiment Scores', fontsize = 15)\nax.set_ylabel('Book Name', fontsize = 15)\nax.set_title('Cumulative Sentiment Score for each book', fontsize = 20)\nplt.yticks(list(Polarity_dict.keys()), fontproperties=hindi_font, fontsize = 15);","6e450768":"It gives Joshua (\u092f\u0939\u094b\u0936\u0942) chapter 22, verses 21-27 as the most significant verses in the Hindi Bible.","7cc4d195":"As expected and discussed, this sentiment result of each book is not satisfactory as it is showing first three Gospel books also as having negative sentiment, which is certainly not the case.<br> Thanks for reading, I will be updating the notebook in the future hopefully with good sentiment results. Suggestions and feedbacks are most welcome.\n## References\n[1] Gabrel Preda, Kaggle notebook: https:\/\/www.kaggle.com\/gpreda\/explore-king-james-bible-books\u00a0<br>\n[2] Jeffrey Kranz, overviewbible.com: https:\/\/overviewbible.com\/authors-who-wrote-bible\/<br>\n[3] Brandon Rose's Blog: http:\/\/brandonrose.org\/clustering<br>\n[4] Lohit Parmar, Github project: https:\/\/github.com\/Lohit13\/HindiSentimentAnalysis<br>\n[5] A Framework for Sentiment Analysis in Hindi using\nHSWN: https:\/\/pdfs.semanticscholar.org\/cfd2\/d189c5613c85077125f41c0d79d22f4d30c4.pdf","db6dda15":"# Exploratory Visualization\nWe will first classify the book titles from `hindi_bible_books.txt` to the New Testament and Old Testament for classification purpose in our incoming visualizations. Below is a classified list of New Testament books.","b7917c00":"`freq` dictionary contains frequency of each word, we are taking frequency as a score of a particular word's importance. \n> *I have intentionally removed word '\u0930\u093e\u091c\u093e' so that our algorithm won't give significance to verses containing lineages of various Kings*","a8e20084":"Moses tops the chart among the known traditional authors and the difference is huge (around 12%) between his contribution and the immediate next contributor Luke's (This comparisions would be least of their concern though). It's interesting to note that Paul's and Ezra's contribution is almost equal and differ just by a margin of 0.03%.<br> \n> P.S. A word of clarification: When I say contribution I mean the contribution of mere no. of verses not the contribution in doctrinal or conceptual aspects. \n#### List of books having unknown authors \nThere is a total of 11 books with uncredited authors, interestingly enough, out of all of them, there is only one book (\u0907\u092c\u094d\u0930\u093e\u0928\u093f\u092f\u094b\u0902, Hebrews) with unknown author from the New Testament books. ","6c833bf4":"### Text split on books\nMaking a list of 66 strings having separate full texts belonging to each book. ","d1dac227":"For general purpose Hindi WordNet is sufficient to use for sentiment analysis tasks (I have shown an example below with a sample statement) but Bible text is so rich in its content that Hindi WordNet is not enough as we can see in the above result that no. of unique words used in Bible are huge compared to our resources.<br><br>\nIn `Code`, `sentiment` function determines sentiment of a given text. it returns 1 if the text is a positive sentence and 0 if it is a negative sentence along with their respective polarities.","6a8c8c16":"## Natural Language Processing on Hindi Bible text\n\n# Introduction\nWe will analyze Hindi Bible text of HHBD version from Bible Society of India (BSI) with NLP techniques. We will seek to perform sentiment analysis on all of the Bible books while also bringing to the surface some interesting findings like which is the most significant verse based on the occurrence of frequent words, Who wrote most of the New Testament, etc. Lastly, this notebook will serve as a walkthrough of how the [dataset](https:\/\/www.kaggle.com\/kapilverma\/hindi-bible) I created can be used.<br>\nJust a word of caution before we start: It's a purely quantitative analysis and not a qualitative analysis. With this in mind, let's dive in.\n#### Preprocessing of Data\nThe data was parsed from a JSON format to a CSV format. Most of the details like Book no., Chapter No. etc. were extracted from `Verseid` field in the JSON file and some details like \"book names in Hindi\" and \"authors' names\" were added from external sources. If you are interested to follow full process of data preprocessing please go through [this link](https:\/\/github.com\/kapil-verma\/NLP-on-Hindi-Text).\n> I have hidden most of the code in this notebook if you wish to see the code of any section, just toggle the button `Code`.","db7bd08f":"For you curious ones out there, here's a dictionary of words with their frequencies that might interest you.","7bb1a05f":"We will use all of the above files in our analysis. Starting with our main file `Hindi_bible_with_authors.csv`, imported as `bib`.","03ac48f0":"Clearly, this small amount of words won't be enough.\n### Using Machine Translation to improve our sentiment resource\n`hindi word list.csv` is just a list of Hindi words and their Hindi Translations, translated using Google's translation API. We're using *TextBlob* to get sentiment polarity of these translated Hindi words. This way we have more Hindi words to check sentiment polarity from.","8c06edb2":"## Abstract Extraction by significance score\nLet\u2019s further prepare the input text from our corpus for further processing, by removing punctuation and stopwords (custom made list). In this section, we'll try to find most significant verses in Hindi Bible.<br>\n#### A simple word-frequency finder\nWe have to find the frequency of each word also to derive significance. While we are at it, It will be useful to have a function which can find the frequency of any word we search for. Our function `freq_finder` does the same, there are examples given below for words: \u092a\u094d\u0930\u0947\u092e (Love) and \u0921\u0930 (Fear).\n> This is specific to HHBD version only.","c787a442":"List of books to be used in the below graph.\n### Sentiment of each book\nWell, there's going to be a little to no sense to this section as Bible text is very subjective and sentence carrying negative sentiments can turn out to be positive! E.g. Matthew 11:12 (*And from the days of John the Baptist until now the kingdom of heaven suffers violence, and the violent take it by force*) is a fairly negative sentence by the look of it but on the contrary, Jesus is giving here a graphic picture of the enthusiasm and excitement generated among people to enter the kingdom of God, that they are not caring about the difficulties and persecution they might have to endure along the way.<br>\nStill, let's give it a try.","40cec245":"We will be using `Nirmala.ttf` font to show Hindi text on our graphs. Although the library that we are using named `Matplotlib`, its graphs do not render Hindi text properly but they are still recognizable.","6de63c75":"### Most frequent words in Hindi Bible","ca55b6f5":"## Exploring Traditional Authorship\nAuthorship details are borrowed from this [article](https:\/\/overviewbible.com\/authors-who-wrote-bible\/). <br>As discussed above this is also based on the no. of verses. We will calculate percentage portions of each author into a dataframe using *.groupby()* function.","5ff3893b":"# Resource-based Sentiment Analysis\n#### Hindi WordNet\nHindi WordNet (developed by IIT Bombay) is a similar resource like the WordNet in English, which captures lexical and semantic relations between Hindi words. Here we're only concerned with sentiments so I am using **SentiWordNet**, which contain sentiment polarity of Hindi words while clubbing their synonyms also.<br>\nReading text file `HSWN_WN.txt` containing Hindi SentiWordNet into a Pandas Dataframe **data**.","7129284a":"In the above code, We split our full bible text by *Puran Virams* & *Ardh Virams* i.e. '\u0965' & '\u0964' and stored the resulted sentences in a flattened list `sents`. Next, we're ranking these sentences based on significance scores of their constituting words, in dictionary `ranking`.","02448215":"It can be easily seen here that relatively recent New Testament Books have lesser unknown writers (4%) as compared to the Old Testament (28%). <br>\nWe get an interesting finding here that to the contrary of popular belief, it is not Paul who has written most of the new testament but it is Luke. Sure, Paul has written more books but volume-wise(no. of verses), It is Luke who gave maximum contribution. [Original manuscripts](https:\/\/apologika.blogspot.com\/2014\/05\/who-wrote-most-of-new-testament.html) also support this fact.","a3572b6b":"*Though WordCloud messes up with Matras of Hindi Words and the WordCloud function doesn't do well to remove stopwords but still we can see that words like \u092a\u0930\u092e\u0947\u0936\u094d\u0935\u0930,\u092e\u0928 etc. are more prominent than others. <br>Next, we'll do stemming.*\n\n**Stemming** is the process of reducing words to their word base or root form. E.g., in English, stem word for playing, player, played etc. will be \"play\". This below functionality to generating Hindi stem words has been taken from [here](https:\/\/github.com\/taranjeet\/hindi-tokenizer\/blob\/master\/HindiTokenizer.py). We'll use stemming to accurately arrive on most frequent words in Hindi Bible so that our program won't count words like \u0932\u094b\u0917 and \u0932\u094b\u0917\u094b\u0902 as two different words.","148028f5":"## Starting Text Analysis\n**Stopwords** are generally the most common words in a language and for our purpose of analysis, they have to be eliminated from the text. `Hindi_StopWords.txt` is a custom made list of 270 stopwords.","a2a3a246":"# WordCloud\nWe are using `Full_text_Bible.txt` which is a compilation of whole Hindi text of the Bible to make the WordCloud.  ","0c645ef9":"## Exploring the length of each book\n Calculating percentage portions (% occurrences) of each book in the bible and saving it in a Pandas DataFrame (`df`).\n> * While our Hindi text cannot represent the actual length of each book, the reason it being a translated text, so we would stick to the no. of verses in each book for comparison. ","12dc2f31":"As it is evident with the color-coding that the majority of the Bible is occupied by Old Testament Books. We can see that Psalms (\u092d\u091c\u0928 \u0938\u0902\u0939\u093f\u0924\u093e) book is the largest book in the Bible while the 2nd Epistle from John (2 \u092f\u0942\u0939\u0928\u094d\u0928\u093e) is the smallest of all the books in the Bible.<br>\n> *Note: This calculation is based upon the number of verses of each book, if we go by counting each word then 3rd Epistle of John (3 \u092f\u0942\u0939\u0928\u094d\u0928\u093e) is the smallest book of the Bible.*","2a23a682":"### Hierarchical Clustering\nHere, I have done hierarchical Clustering on the first 10 sentences of Bible i.e Genesis (\u0909\u0924\u094d\u092a\u0924\u094d\u0924\u093f) 1:1-10. Sentences (denoted by a title words '\u091c\u0932', '\u090a\u092a\u0930', '\u0906\u0915\u093e\u0936' etc.) are clustered based on their cosine distances and their hierarchy is found out by Ward's method which merges cluster based on their cosine distances. <sub>(Cosine distance = 1- cosine similarity)<\/sub> <br><br>Cosine distance  is opposite to cosine similarity which calculates similarity between two vectors based on the cosine ratio of the angle made between them two. See, if you can make sense of below dendrogram.","c317b39a":"### A Separate look on the authorship of Old Testament and New Testament books","1b657678":"We'll use these ranking to arrive at significant sentences as per the ranking calculated above."}}