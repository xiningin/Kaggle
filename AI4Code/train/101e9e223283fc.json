{"cell_type":{"2f5ce11b":"code","1ba1db7f":"code","10c66a27":"code","653e55a0":"code","e6351b1d":"code","f2f268bc":"code","68dc94d6":"code","831e992c":"code","c2fdbc13":"code","ccf08ec0":"code","1e7236a9":"code","aecfeef6":"code","f30c8af5":"code","5571a81c":"markdown","7c3cd11d":"markdown","c8e7f2af":"markdown","d2360fc8":"markdown","9d623872":"markdown","f0d30361":"markdown","460d8707":"markdown"},"source":{"2f5ce11b":"#load the dataseat from sklearn.datasets module\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()","1ba1db7f":"#showing a concise description of the digit dataset\nprint(digits.DESCR)","10c66a27":"#number of samples and features\ndigits.data.shape","653e55a0":"digits.target.shape","e6351b1d":"from sklearn.model_selection import train_test_split\n\n#splitting of dataset with 25% for testing\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n                                                    random_state=11,test_size=0.25)","f2f268bc":"#checking testing and training set sizes\nprint(f'The training set sizes: {X_train.shape}.')\nprint(f'The testing set sizes: {X_test.shape}.')","68dc94d6":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\n\n#training the model\nknn.fit(X_train, y_train)\n\n#predicting the Digit CLasses\npredicted = knn.predict(X_test)\nexpected = y_test\n\n#let's check predicted vs expected\nprint(f'The predicted digits for the first 15 samples: {predicted[:15]}\\n')\nprint(f'The expected digits for the first 15 samples: {expected[:15]}\\n')","831e992c":"#checking the list of wrong predictions for the entire test with list comprehension\n\ncheck = [(p,e) for (p,e) in zip(predicted, expected) if p!= e]\ncheck","c2fdbc13":"#using classification report and confusion matrix\nprint(f'{knn.score(X_test, y_test):.2%}\\n')\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nconfusion = confusion_matrix(expected, predicted)\nprint(f'The confusion matrix: \\n{confusion}\\n\\n')\n\nprint(f'Classification Report: \\n{classification_report(expected, predicted)}')","ccf08ec0":"#using seaborn to visualize the confusion matrix\nimport seaborn as sns\n\nsns.heatmap(confusion, annot=True, cmap='nipy_spectral_r')","1e7236a9":"from sklearn.model_selection import KFold, cross_val_score\n\nkfold = KFold(n_splits=10, random_state=11, shuffle=True)\n\nscores = cross_val_score(estimator=knn, X=digits.data,y=digits.target, cv=kfold)\n\nprint(f'Scores: \\n {scores}\\n')\nprint(f'Mean accuracy: \\n{scores.mean():.2%}\\n')\nprint(f'Accuracy standard deviation: \\n{((scores.std())* 100):.2%}')\n","aecfeef6":"from sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\n#setting names for the estimators\nestimators = {'KNeighborsClassifier': knn,\n              'SVC': SVC(gamma='scale'),\n              'GaussianNB': GaussianNB()}\n\nfor estimator_name, estimator_object in estimators.items():\n    kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n    scores = cross_val_score(estimator=estimator_object,\n    X=digits.data, y=digits.target, cv=kfold)\n    print(f'{estimator_name:>20}: ' +\n    f'mean accuracy={scores.mean():.2%}; ' +\n    f'standard deviation={scores.std():.2%}')","f30c8af5":"for k in range(1, 20, 2):\n    kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(estimator=knn,\n    X=digits.data, y=digits.target, cv=kfold)\n    print(f'k={k:<2}; mean accuracy={scores.mean():.2%}; ' +\n    f'standard deviation={scores.std():.2%}')","5571a81c":"# Splitting data for Training and Testing","7c3cd11d":"# K-Fold and Cross Validation","c8e7f2af":"# Checking the Model Accuracy ","d2360fc8":"# Creating the Model","9d623872":"# Displaying Descriptions\n","f0d30361":"# Hyperparameter Tuning","460d8707":"# Finding the Best Model"}}