{"cell_type":{"5064a62e":"code","e55877cb":"code","d4f80b0b":"code","88ca0352":"code","38cf32cd":"code","c9df0dcc":"code","1b8c4a29":"code","b2c682d5":"code","d46281c6":"code","7bc16a78":"code","fcf8f212":"code","694b1cbb":"code","50eb8565":"code","6a8eba61":"code","de9d9ea9":"code","2fb875d6":"code","073d8b1e":"code","a28d1dc5":"code","a00e785b":"code","c022653c":"code","89b6450c":"code","6f7b3271":"code","0de06fb5":"code","fd14f8ad":"code","70b1366b":"code","4f64012a":"code","302ef5c9":"code","ef419f41":"code","94c3e4aa":"code","b5effb6d":"code","a6b1383b":"code","0d28c58b":"code","4fb886ad":"code","0c2cebe8":"code","22fe12b2":"code","304e96af":"code","5afaa31b":"code","664127db":"code","7fa9eda5":"code","b039866f":"code","f69fc1a0":"code","8135ef4b":"code","476a538b":"code","c1862015":"code","bc8eae13":"markdown","801c2441":"markdown","2f970005":"markdown","1ef02801":"markdown","9b45eaa9":"markdown","b2fbfd07":"markdown","602aa289":"markdown","9e6658fb":"markdown","150bf788":"markdown","8fa2bccd":"markdown","60999cc9":"markdown","45e5d96b":"markdown","e8c25ea7":"markdown","d41fd1c2":"markdown","5779dee6":"markdown","c925329d":"markdown","bf0f60b4":"markdown","ec9ff64f":"markdown","52b89b0f":"markdown","bb950839":"markdown","e6c9a3e9":"markdown","3af82b93":"markdown","69a9751d":"markdown","d70f796a":"markdown","cd627c67":"markdown"},"source":{"5064a62e":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import FeatureUnion\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","e55877cb":"trd = pd.read_csv(\"..\/input\/titanic\/train.csv\")","d4f80b0b":"ted = pd.read_csv(\"..\/input\/titanic\/test.csv\")","88ca0352":"trd.head()","38cf32cd":"trd.info()","c9df0dcc":"plt.figure(figsize=(10,5))\nsns.heatmap(trd.isnull() , yticklabels = False , cmap='viridis')\nplt.title('Null Values in Training Set');","1b8c4a29":"trd.describe()","b2c682d5":"trd[\"Survived\"].value_counts()","d46281c6":"sns.countplot(trd.Survived)\nplt.title(  \"Number of passengers Survived\")\n","7bc16a78":"sns.countplot(x = \"Survived\" , hue = \"Sex\" , data = trd)\nplt.title('Number of passenger Survived based on Gender');","fcf8f212":"trd[\"Pclass\"].value_counts()","694b1cbb":"sns.countplot(x=\"Survived\", hue=\"Pclass\", data=trd)\nplt.title('Number of passenger Survived based on Class');","50eb8565":"pclass1 = trd[trd.Pclass == 1]['Survived'].value_counts(normalize=True).values[0]*100\npclass2 = trd[trd.Pclass == 2]['Survived'].value_counts(normalize=True).values[1]*100\npclass3 = trd[trd.Pclass == 3]['Survived'].value_counts(normalize=True).values[1]*100\n\nprint(\"There are \" + str(pclass1 ) +\"% of people survived from class 1\" )\nprint(\"There are \" + str(pclass2) +\"% of people survived from class 2\")\nprint(\"There are \" + str(pclass3) +\"% of people survived from class 3\")","6a8eba61":"trd[\"Sex\"].value_counts()","de9d9ea9":"trd['Age'].hist(bins=40)\nplt.title('Age Distribution');","2fb875d6":"plt.figure(figsize=(10,10))\nsns.displot(trd.Age, bins = 50,kde = True)\nplt.title('Distrubution of passengers age',fontsize= 14)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n","073d8b1e":"plt.figure(figsize=(15, 4))\n\nsns.boxplot(y = 'Survived', x = 'Age', data = trd,\n     palette=[\"#3f3e6fd1\", \"#85c6a9\"], fliersize = 0, orient = 'h')\n\nsns.stripplot(y = 'Survived', x = 'Age', data = trd,\n     linewidth = 0.6, palette=[\"#3f3e6fd1\", \"#85c6a9\"], orient = 'h')\n\n\nplt.yticks( np.arange(2), ['drowned', 'survived'])\nplt.title('Age distribution grouped by surviving status (train data)',fontsize= 14)\nplt.ylabel('Passenger status after the tragedy')\nplt.tight_layout()","a28d1dc5":"class DataFrameSelector (BaseEstimator , TransformerMixin):\n  def __init__(self , attribute_names):\n    self.attribute_names = attribute_names\n  def fit(self,X,y=None):\n    return self\n  def transform(self,X):\n    return X[self.attribute_names]","a00e785b":"num_pipeline = Pipeline([(\"select_numeric\" , \n                          DataFrameSelector([\"Age\" , \"SibSp\" \n                                             , \"Parch\" , \"Fare\"])) ,\n                        (\"imputer\" , SimpleImputer(strategy=\"median\"))])","c022653c":"num_pipeline.fit_transform(trd)","89b6450c":"trd","6f7b3271":"class MostFrequentImputer(BaseEstimator,TransformerMixin):\n  def fit(self,X,y = None):\n    self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n                                    index = X.columns)\n    return self\n  def transform (self , X , y = None):\n    return X.fillna(self.most_frequent_)\n","0de06fb5":"cat_pipeline = Pipeline([\n        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n        (\"imputer\", MostFrequentImputer()),\n        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n    ])","fd14f8ad":"cat_pipeline.fit_transform(trd)","70b1366b":"preprocess_pipeline = FeatureUnion(transformer_list=[\n                          (\"num_pipeline\" , num_pipeline),\n                          (\"cat_pipeline\" , cat_pipeline)\n                                                     \n])","4f64012a":"X_train = preprocess_pipeline.fit_transform(trd)\nX_train","302ef5c9":"y_train = trd[\"Survived\"]","ef419f41":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train)\n","94c3e4aa":" sgd_scores= cross_val_score(sgd_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n","b5effb6d":"sgd_scores.mean()","a6b1383b":"forest_clf = RandomForestClassifier(n_estimators=100 , random_state=42)","0d28c58b":"scores = cross_val_score(forest_clf , X_train , y_train , cv = 10)","4fb886ad":"scores.mean()","0c2cebe8":"from sklearn.neighbors import KNeighborsClassifier\nknclassifier = KNeighborsClassifier(n_neighbors=3)\nknclassifier.fit(X_train, y_train)","22fe12b2":"Kn_scores = cross_val_score(knclassifier , X_train, y_train , cv = 10 )\nKn_scores.mean()","304e96af":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(random_state=1, max_iter=300)\nmlp.fit(X_train, y_train)","5afaa31b":"mlp_scores = cross_val_score(mlp , X_train, y_train , cv = 10  )\nmlp_scores.mean()","664127db":"from sklearn.gaussian_process import GaussianProcessClassifier\ngpc = GaussianProcessClassifier()\ngpc.fit(X_train,y_train)","7fa9eda5":"gpc_scores = cross_val_score(gpc , X_train, y_train , cv = 10 )\ngpc_scores.mean()","b039866f":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(X_train , y_train)","f69fc1a0":"dtc_scores = cross_val_score(dtc , X_train, y_train , cv = 10 )\ndtc_scores.mean()","8135ef4b":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=100, random_state=0)\nada.fit(X_train, y_train)","476a538b":"ada_scores =  cross_val_score(ada , X_train, y_train , cv = 10 )\nada_scores.mean()","c1862015":"plt.figure(figsize=(18, 8))\nplt.plot([1]*10, sgd_scores, \"*\")\nplt.plot([2]*10, scores, \"*\")\nplt.plot([3]*10, Kn_scores, \"*\")\nplt.plot([4]*10, mlp_scores, \"*\")\nplt.plot([5]*10, gpc_scores, \"*\")\nplt.plot([6]*10, dtc_scores, \"*\")\nplt.plot([7]*10, ada_scores, \"*\")\nplt.boxplot([sgd_scores, scores , Kn_scores , mlp_scores , gpc_scores , dtc_scores , ada_scores],\n            labels=(\"SGD\",\"Random Forest\",\"KnNeighbours\",\"Mlp\",\"GaussianProcess\",\"DescisionTree\" ,\"AdaBoostClassifier\"))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.title(\"Accuracy of different classifiers\")\nplt.show()","bc8eae13":"*That's 81% accuracy . comment me if it is good*","801c2441":"*As we can see Random forest classifier dominates the rest of them .*","2f970005":"*From the above table we can observe that only 38% has survived*\n\n*Let's check the target*","1ef02801":"*Instead of just looking at the mean accuracy across the 10 cross-validation folds, let's plot all 10 scores for each model, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores*","9b45eaa9":"*Let's try with some other classifiers*","b2fbfd07":"*Now let's take a quick look at all the categorical attributes*","602aa289":"*According to the above graph we have more number of non-survived people and females are more likely to survived than male!.*","9e6658fb":"*Let's get more info to see how much data is missing:*","150bf788":"*Let's built pipeline for numerical attributes*","8fa2bccd":"*The age , cabin , embarked attributes are sometimes null (they are less than 891) in which cabin has most null values . The age attribute can be replaced with median ages*\n\n*Let's vizualize the null Values*","60999cc9":"*From the above all classifiers Random forest classifier and AdaBoostClassifier works quite well .*","45e5d96b":"*Age by surviving status*","e8c25ea7":"*Now we can build the pipeline for the categorical attributes:*","d41fd1c2":"\n\n\n*   trd = train_data\n*   ted = test_data\n\n\n\n\n","5779dee6":"*oh No !!! It's too bad*","c925329d":"*Number of passengers survived based on Gender*","bf0f60b4":"**Now let's build our preprocessing pipelines.**\n\n*Let's built a class called Dataframe Selector to select specific attributes from the DataFrame:*","ec9ff64f":"*As we can see the \"Age\" , \"SibSp\" , \"Parch\" , \"Fare\" columns has no null values . They were filled by median of their respective columns.*\n\n*We will also need an imputer for the string categorical columns (the regular SimpleImputer does not work on those):*","52b89b0f":"*Let's import necessary libraries and Data*\n\n\n\n\n\n\n","bb950839":"*Age column has non-uniform data and many outliers*\n\n*Let's  plot a univariate distribution of Age observations*","e6c9a3e9":"*Finally, let's join the numerical and categorical pipelines :*","3af82b93":"*Let's train our data with stochastic Gradient descent classifier .*","69a9751d":"**The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.**","d70f796a":"*Let's train our data with Random forest classifier .*","cd627c67":"*I hope it's useful Kindly upvote .*"}}