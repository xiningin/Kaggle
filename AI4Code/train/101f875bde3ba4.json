{"cell_type":{"471f955e":"code","3ac3c099":"code","01c6a9f0":"code","5a78be9d":"code","41b477b3":"code","d6db9ba5":"code","0fadb71a":"code","1b34dfb3":"code","fb6301fe":"code","2cf55f2c":"code","68e21080":"code","e0473d2a":"code","a0f934f6":"code","4b27049f":"code","a36a2ec0":"code","7ad80ea8":"code","5560e584":"code","5f72f730":"code","66d27fbe":"code","615925a4":"code","1f620780":"code","dde19c33":"code","cc6a6acb":"code","d2ef7a40":"code","b3da40e5":"code","e8b064be":"code","0795f838":"code","56f032d1":"code","6dff856f":"code","20706a2c":"code","1ff556e0":"code","34fe4e74":"code","9dee36dd":"code","214d0a7b":"code","5f59a9da":"code","2f357fa4":"code","7d66dcdc":"code","111edad4":"code","0f7a72d4":"code","2550c941":"code","ad244245":"code","6f60b2c3":"code","d349471a":"code","4c8b1be0":"code","6697e4a6":"code","0b84e6c4":"code","1350a4bd":"code","ae5c3e62":"code","8c0103ba":"code","a8b85837":"code","80760dc8":"code","59fac377":"code","9bdd3f18":"code","3c3f7fc1":"code","67061079":"markdown","86345959":"markdown","b6ca2141":"markdown","40e4ead6":"markdown","f4a9445d":"markdown","8cfd5ccb":"markdown","e1e71bf9":"markdown","16e145f0":"markdown","b39cfb5b":"markdown","c73a538d":"markdown","76006b91":"markdown","367722e0":"markdown","870815e8":"markdown","d342df27":"markdown","341ed8a5":"markdown","10d676c7":"markdown","b681f7c0":"markdown","a920a283":"markdown","715d5757":"markdown","1a6e4660":"markdown","323d7fe7":"markdown","8df7b12d":"markdown","ebaca515":"markdown","a79bbd3f":"markdown","36cc425f":"markdown","6b3658a7":"markdown","a368fa5a":"markdown","81980a1c":"markdown","aebce11f":"markdown","35a30047":"markdown","bede0e28":"markdown","61548045":"markdown","358271c4":"markdown","05281549":"markdown","b679deea":"markdown","10759f99":"markdown","fa32b601":"markdown","66801a9a":"markdown","49af4639":"markdown","acd9efdc":"markdown","b5412d3b":"markdown","1aebad16":"markdown","bcb95c2f":"markdown","6f6597bf":"markdown","e01f7849":"markdown","1cf62a9b":"markdown","9b8fa9ad":"markdown","076336cc":"markdown","7f33b0ef":"markdown","355d2d51":"markdown","a6f5b563":"markdown","b1247360":"markdown","f13a08ac":"markdown","2bc6f9da":"markdown","14b57c56":"markdown","8b0be338":"markdown","2e644105":"markdown","25fbb3e1":"markdown","589fa8ad":"markdown","2ff73ed7":"markdown","3a82fa4a":"markdown","15856a41":"markdown","c55d9ef0":"markdown","649917e9":"markdown","2f097d94":"markdown","6eb6b31f":"markdown","b0d2736f":"markdown","0cab0e56":"markdown","dc7ccd25":"markdown","1589a3ef":"markdown","26064afc":"markdown","e1770dea":"markdown","fb5a111b":"markdown","c0369afa":"markdown","d062058c":"markdown","38664224":"markdown","d5941ae9":"markdown","5df27747":"markdown","25140f80":"markdown","b6321e60":"markdown","6c713432":"markdown","17b22293":"markdown","d4551e76":"markdown","13b7b1c3":"markdown","2000094e":"markdown","0aae8cec":"markdown","97b3c39a":"markdown","52f93722":"markdown","ae52a2a1":"markdown","7570428e":"markdown","c02bec69":"markdown","bb578449":"markdown","4ce0ae70":"markdown","d516ff34":"markdown","4be3c635":"markdown","3649a69d":"markdown","ebb74f3e":"markdown","39fc31c2":"markdown","a7682226":"markdown","960e6fca":"markdown","6dabdfe8":"markdown","b140d634":"markdown","99396300":"markdown","04ee733b":"markdown","e0f84eee":"markdown","f9b7e64d":"markdown","e49bb576":"markdown","bc06b83c":"markdown","fab74de5":"markdown","6fd6eac6":"markdown","18043150":"markdown","3a859e41":"markdown","e0d8b53f":"markdown","78d3901f":"markdown","f58b508f":"markdown","5cc286c9":"markdown","382eb8ea":"markdown","ea3a6ed4":"markdown"},"source":{"471f955e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os as os\nimport sys\nimport warnings\nimport time\nwarnings.filterwarnings('ignore')\n\nsns.set(style='white', context='notebook', palette='deep')\nnp.random.seed(2)\nfrom IPython.display import Image\n\n# From Matplotlib\nfrom matplotlib.colors import ListedColormap\n\n# From Scikit Learn\nfrom sklearn import preprocessing, decomposition, tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom astropy.table import Table, Column\nfrom sklearn.preprocessing import LabelEncoder\nimport itertools\n\n# Set DEBUG = True to produce debug results\nDEBUG = False","3ac3c099":"print(\"The Python version is %s.%s.%s.\" % sys.version_info[:3])","01c6a9f0":"%pwd","5a78be9d":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%time digit_train = pd.read_csv(\"..\/input\/train.csv\", header=0, sep=\",\")\n%time digit_test = pd.read_csv(\"..\/input\/test.csv\", header=0, sep=\",\")","41b477b3":"digit_train.describe()","d6db9ba5":"digit_test.describe()","0fadb71a":"# Source: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.dropna.html\ndigit_train = digit_train.dropna(axis = 0, how = 'all')\ndigit_test = digit_test.dropna(axis = 0, how = 'all')\nif DEBUG:\n    #Dimensions of dataset\n    print(\"Shape of Data\", digit_train.shape)\n    print(\"Shape of Data\", digit_test.shape)\n    #Colum names\n    print(\"Colums Names\", digit_train.columns)\n    print(\"Colums Names\", digit_test.columns)\n    #See bottol few rows of dataset\n    print(digit_train.tail())","1b34dfb3":"# designate target variable name\ntargetName = 'label'\ntargetSeries = digit_train[targetName]\n#remove target from current location and insert in collum 0\ndel digit_train[targetName]\ndigit_train.insert(0, targetName, targetSeries)\n#reprint dataframe and see target is in position 0\ndigit_train.head()","fb6301fe":"digit_train.info()","2cf55f2c":"sns.countplot(digit_train['label'])","68e21080":"print(digit_train['label'].describe())","e0473d2a":"if DEBUG:\n    print(digit_train.dtypes)","a0f934f6":"digit_train['label'] = digit_train['label'].astype(str)\nif DEBUG:\n    print(digit_train['label'].describe())","4b27049f":"#digit_train.fillna(digit_train.median(), inplace=True)\n#print(digit_train.describe())","a36a2ec0":"#if DEBUG:\n#    print(digit_train.shape)\n#    print(digit_train.info())\n#    print(digit_train.head())","7ad80ea8":"features_train = digit_train.iloc[:,1:]\ntarget_train = digit_train.iloc[:,0]\nfeatures_test = digit_test.iloc[:,0:]","5560e584":"# pixel values are gray scale between 0 and 255\n# normalize inputs from 0-255 to 0-1\nfeatures_train = features_train\/255.0\nfeatures_test = features_test\/255.0","5f72f730":"if DEBUG:\n    print(features_train)","66d27fbe":"start_time = time.perf_counter()\ntrain_results = []\ntest_results = []\n# search for an optimal value of k for KNN MOdel\nk_range = list(range(1,5))\nk_scores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1, algorithm='ball_tree', leaf_size=40, weights='uniform')\n    scores = cross_val_score(knn, features_train, target_train, cv=10, scoring='accuracy', n_jobs=-1)\n    k_scores.append(scores.mean())\nif DEBUG:\n    print(k_scores) \nprint(time.perf_counter() - start_time, \"seconds\")","615925a4":"if DEBUG:\n    scores = pd.DataFrame(k_scores)\n    print(scores)","1f620780":"# plot the value of K (x-axis) versus the cross-validated accuracy (y-axis)\nplt.plot(k_range, k_scores)\nplt.xlabel('K Value for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.title('KNN Model for Accuracy')","dde19c33":"# changing to misclassification error\nMSE = [1 - x for x in k_scores]\n\n# determining best k\noptimal_k = k_range[MSE.index(min(MSE))]\n\n# plot misclassification error vs k\nplt.plot(k_range, MSE)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.title('KNN Model for Misclassification Error')\nplt.show()","cc6a6acb":"print(\"The optimal number of neighbors is %d.\" % optimal_k)","d2ef7a40":"start_time = time.perf_counter()\n#KNN train model. Call up my model and name it clf_knn\nclf_knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1, algorithm='ball_tree', leaf_size=40, weights='uniform')\n#Call up the model to see the parameters you can tune (and their default setting)\nprint(clf_knn)\n#Fit clf to the training data\nclf_knn = clf_knn.fit(features_train, target_train)\n#Predict clf_knn model again test data\ntarget_predicted_knn = clf_knn.predict(features_test)\nprint(time.perf_counter() - start_time, \"seconds\")","b3da40e5":"start_time = time.perf_counter()\n#verify KNN with Cross Validation\nscores_knn = cross_val_score(clf_knn, features_train, target_train, cv=10, scoring='accuracy', n_jobs=-1)\nprint(\"Cross Validation Score for each K\",scores_knn)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores_knn.mean(), scores_knn.std() * 2))\nprint(time.perf_counter() - start_time, \"seconds\")","e8b064be":"digit_test['Label'] = pd.Series(target_predicted_knn)\ndigit_test['ImageId'] = pd.Series(range(1,28001))","0795f838":"digit_test.to_csv('submission_knn.csv', columns=[\"ImageId\",\"Label\"], index=False)","56f032d1":"start_time = time.perf_counter()\nfrom sklearn.neural_network import MLPClassifier\n# Multi-layer Perceptron train model. Call up my model and name it clf_mlp\nclf_mlp = MLPClassifier(hidden_layer_sizes=(784,), warm_start=True)\n#Call up the model to see the parameters you can tune (and their default setting)\nprint(clf_mlp)\n#Fit clf_NN to the training data\nclf_mlp = clf_mlp.fit(features_train, target_train)\n#Predict clf_NN model again test data\ntarget_predicted_mlp = clf_mlp.predict(features_test)\nprint(time.perf_counter() - start_time, \"seconds\")","6dff856f":"start_time = time.perf_counter()\n#verify RF with Cross Validation\nscores_mlp = cross_val_score(clf_mlp, features_train, target_train, cv=10, n_jobs=-1, scoring='accuracy')\nprint(\"Cross Validation Score for MLP\",scores_mlp)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores_mlp.mean(), scores_mlp.std() * 2))\nprint(time.perf_counter() - start_time, \"seconds\")","20706a2c":"digit_test['Label'] = pd.Series(target_predicted_mlp)\ndigit_test['ImageId'] = pd.Series(range(1,28001))","1ff556e0":"digit_test.to_csv('submission_mlp.csv', columns=[\"ImageId\",\"Label\"], index=False)","34fe4e74":"from IPython.lib.display import YouTubeVideo\nvid = YouTubeVideo('j_pJmXJwMLA', autoplay=0)\ndisplay(vid)","9dee36dd":"# From Keras for TensorFlow Model\nimport keras as keras\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","214d0a7b":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = features_train.values.reshape(-1,28,28,1)\ntest = features_test.values.reshape(-1,28,28,1)","5f59a9da":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(target_train, num_classes = 10)","2f357fa4":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=0)","7d66dcdc":"g = plt.imshow(X_train[10][:,:,0])","111edad4":"clf_keras = Sequential()","0f7a72d4":"clf_keras.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same', strides=1, activation ='relu', \n                     input_shape = (28,28,1)))\nclf_keras.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same', activation ='relu'))\nclf_keras.add(keras.layers.BatchNormalization())\nclf_keras.add(keras.layers.MaxPooling2D(pool_size=(2,2)))","2550c941":"clf_keras.add(Conv2D(filters = 64, kernel_size = (3,3), strides=2, padding = 'same', activation ='relu'))\nclf_keras.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation ='relu'))\nclf_keras.add(keras.layers.BatchNormalization())\nclf_keras.add(keras.layers.MaxPooling2D(pool_size=(2,2)))","ad244245":"clf_keras.add(Dropout(rate = 0.5))","6f60b2c3":"clf_keras.add(Flatten())","d349471a":"clf_keras.add(Dense(10, activation = \"softmax\"))","4c8b1be0":"# Define the optimizer\noptimizer = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)","6697e4a6":"# Compile the model\nclf_keras.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","0b84e6c4":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.00001, verbose=1)","1350a4bd":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.10, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","ae5c3e62":"epochs = 30","8c0103ba":"batch_size = 86","a8b85837":"start_time = time.perf_counter()\n# Fit the model \nhistory = clf_keras.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), epochs = epochs, \n                                  validation_data = (X_val,Y_val), verbose = 2, \n                                  steps_per_epoch=features_train.shape[0] \/\/ batch_size, \n                                  callbacks=[learning_rate_reduction], \n                                  use_multiprocessing=True)\nprint(time.perf_counter() - start_time, \"seconds\")","80760dc8":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","59fac377":"# predict results\nresults = clf_keras.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","9bdd3f18":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)","3c3f7fc1":"submission.to_csv(\"submission_keras.csv\",index=False)","67061079":"[Siraj Raval](https:\/\/www.youtube.com\/channel\/UCWN3xxRkmTPmbKwht9FuE5A) from [The School of AI](https:\/\/www.theschool.ai\/) posted an excellent YouTube video explaining Keras. I've embedded this below.","86345959":"### Label Encoding","b6ca2141":"[MLP](https:\/\/scikit-learn.org\/stable\/modules\/neural_networks_supervised.html) is a supervised learning algorithm that learns a function by training on a dataset, where m is the number of dimensions for input and o is the number of dimensions for output. Given a set of features X = x1,x1,...,xm and a target y, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Figure 1 shows a one hidden layer MLP with scalar output.","40e4ead6":"I split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.","f4a9445d":"## Missing Value Replacement (NaN)","8cfd5ccb":"## Grayscale Normalization","e1e71bf9":"### Dropout","16e145f0":"## K-Nearest Neighbors Model","b39cfb5b":"![CNN](https:\/\/cdn-images-1.medium.com\/max\/800\/1*22R-AyQ-oXb8Flod9PsyNw.png)","c73a538d":"## Multi-layer Perceptron Classifier","76006b91":"The **digit_train** dataset does not contain any NaN values. That being said, I can use the [pandas.DataFrame.fillna](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.fillna.html) method to fill any NA\/NaN values using the specified method (median). ","367722e0":"The [ReduceLROnPlateau](https:\/\/keras.io\/callbacks\/#reducelronplateau) callback reduces learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","870815e8":"[Keras](https:\/\/keras.io\/) is a high-level neural networks API, written in Python and capable of running on top of [TensorFlow](https:\/\/www.tensorflow.org\/), [CNTK](https:\/\/docs.microsoft.com\/en-us\/cognitive-toolkit\/), or [Theano](http:\/\/deeplearning.net\/software\/theano\/). It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.","d342df27":"## Check Present Working Directory","341ed8a5":"The mean score and the 95% confidence interval of the score estimate for the KNN Model is 97% with a variance of 1%.","10d676c7":"### Callbacks","b681f7c0":"To start my analysis, I first ran the code below to determine the best value for k. I set **n_jobs=-1** to use all processors for the parallel jobs to run for neighbors search. I also used the [ball tree](https:\/\/scikit-learn.org\/stable\/modules\/neighbors.html#ball-tree) algorithm. To address the inefficiencies of KD Trees in higher dimensions, the ball tree data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.","a920a283":"The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.","715d5757":"### Dense Layer and Activations","1a6e4660":"Train and test images (28px x 28px) have been stock into [pandas.Dataframe](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.html) as 1D vectors of 784 values. I reshaped all data to 28x28x1 3D matrices.","323d7fe7":"### Fit Generator","8df7b12d":"### Flatten","ebaca515":"For the first input layer, I used a [Conv2D](https:\/\/keras.io\/layers\/convolutional\/#conv2d) layer, a 2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. I also added [BatchNormalization](https:\/\/keras.io\/layers\/normalization\/) after each Conv2D layer. This normalizes the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. Lastly, I added the [MaxPooling2D](https:\/\/keras.io\/layers\/pooling\/) layer for max pooling operation for spatial data.","a79bbd3f":"## Keras Model","36cc425f":"My submission of my Multi-layer Perceptron Model produced an accuracy score of 98.000%, much better than my KNN Model.","6b3658a7":"Building this model was slightly faster than the KNN model.","a368fa5a":"References\n- [Digit Recognizer - Introduction to Kaggle Competitions](https:\/\/towardsdatascience.com\/digit-recognizer-introduction-to-kaggle-competitions-with-image-classification-task-0-995-268fa2b90e13)\n- [Introduction to CNN Keras - Acc 0.997 (top 8%)](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)","81980a1c":"Arguments\n- **rate**: float between 0 and 1. Fraction of the input units to drop.\n- **noise_shape**: 1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input. For instance, if your inputs have shape  (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features).\n- **seed**: A Python integer to use as random seed.","aebce11f":"### Reshape","35a30047":"Arguments\n- **data_format**: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. The purpose of this argument is to preserve weight ordering when switching a model from one data format to another.  channels_last corresponds to inputs with shape  (batch, ..., channels) while channels_first corresponds to inputs with shape (batch, channels, ...). It defaults to the image_data_format value found in your Keras config file at ~\/.keras\/keras.json. If you never set it, then it will be \"channels_last\".","bede0e28":"Convolutional Neural Networks are part of deep, feed forward artificial neural networks that can perform a variety of task with even better time and accuracy than other classifiers, in different applications of image and video recognition, recommender system and natural language processing.","61548045":"### Compilation","358271c4":"Per the Kaggle discussion [How to score 97%, 98%, 99%, and 100%](https:\/\/www.kaggle.com\/c\/digit-recognizer\/discussion\/61480) the best design is to add another convolution and pooling layer.","05281549":"Using the [pandas.DataFrame.dropna](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.dropna.html) method with the **how = 'all'** parameter, I removed all observations where all features were **NaN**.","b679deea":"This returns a History object. Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).","10759f99":"The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).","fa32b601":"# Exploratory Data Analysis","66801a9a":"### Image Preprocessing","49af4639":"The advantages of Multi-layer Perceptron are:\n- Capability to learn non-linear models.\n- Capability to learn models in real-time (on-line learning) using partial_fit.","acd9efdc":"Since the train and test data sets are provided, I used the code below to map values from the datasets.","b5412d3b":"Using the [pandas.DataFrame.describe](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.describe.html) method, I generated descriptive statistics that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values. This helps me analyzes both numeric and object series, as well as DataFrame column sets of mixed data types.","1aebad16":"An [optimizer](https:\/\/keras.io\/optimizers\/) is one of the two arguments required for compiling a Keras model. I chose the [Nesterov Adam](http:\/\/cs229.stanford.edu\/proj2015\/054_report.pdf) optimizer. Much like Adam is essentially RMSprop with momentum, Nadam is Adam RMSprop with Nesterov momentum. Default parameters follow those provided in the paper. It is recommended to leave the parameters of this optimizer at their default values. More information can be found in the whitepaper [\"On the importance of initialization and momentum in deep learning\"](http:\/\/www.cs.toronto.edu\/~fritz\/absps\/momentum.pdf).","bcb95c2f":"The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).","6f6597bf":"![Model Building](https:\/\/cdn-images-1.medium.com\/max\/800\/1*uaE9vcY1M2-RTCpurKr9lg.png)","e01f7849":"### Optimizers","1cf62a9b":"From the analysis above, we can see that the target feature **label** has a data type of **float64**. Since we are predicting a class versus a numerical value, I converted this feature to a string.","9b8fa9ad":"## Target Feature Designation","076336cc":"Per scikit-learn documentation, neural network models in scikit are not intended for large-scale applications. In particular, scikit-learn offers no GPU support.","7f33b0ef":"### Core Layers","355d2d51":"## Import Dataset","a6f5b563":"Now that our model is ready, we use fit_generator to train the model on data generated batch-by-batch by a Python generator (or an instance of Sequence). The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU. The use of keras.utils.Sequence guarantees the ordering and guarantees the single use of every input per epoch when using use_multiprocessing=True.","b1247360":"Our data is almost ready and we could start our training right now but there is one more thing that we could do to improve our classifier - data augmentation.","f13a08ac":"Since my target is a 10 class categorical class, I chose the 'categorical_crossentropy' loss function.","2bc6f9da":"Arguments\n- **monitor**: quantity to be monitored.\n- **factor**: factor by which the learning rate will be reduced. new_lr = lr * factor\n- **patience**: number of epochs with no improvement after which learning rate will be reduced.\n- **verbose**: int. 0: quiet, 1: update messages.\n- **mode**: one of {auto, min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n- **min_delta**: threshold for measuring the new optimum, to only focus on significant changes.\n- **cooldown**: number of epochs to wait before resuming normal operation after lr has been reduced.\n- **min_lr**: lower bound on the learning rate.","14b57c56":"![Figure 1 : One hidden layer MLP.](https:\/\/scikit-learn.org\/stable\/_images\/multilayerperceptron_network.png)","8b0be338":"MLP utilizes a supervised learning technique called [backpropagation](https:\/\/en.wikipedia.org\/wiki\/Backpropagation) for training. More precisely, it trains using some form of gradient descent and the gradients are calculated using backpropagation. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron in that it can distinguish data that is not linearly separable.","2e644105":"In this section, I will focus on basic data preparation steps like loading the dataset, imputing missing values, treating categorical variables, normalizing data and creating a validation set. I will follow the same steps for the KNN, MLP, and Keras models.","25fbb3e1":"MaxPooling2D Arguments\n- **pool_size**: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n- **strides**: Integer, tuple of 2 integers, or None. Strides values. If None, it will default to pool_size.\n- **padding**: One of \"valid\" or \"same\" (case-insensitive).\n- **data_format**: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.  channels_last corresponds to inputs with shape  (batch, height, width, channels) while channels_first corresponds to inputs with shape  (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~\/.keras\/keras.json. If you never set it, then it will be \"channels_last\".","589fa8ad":"The [ImageDataGenerator](https:\/\/keras.io\/preprocessing\/image\/) class generates batches of tensor image data with real-time data augmentation. The data will be looped over (in batches). The idea behind data augmentation is that we can artificially enlarge our training dataset (thus reducing overfitting) by its augmentation.","2ff73ed7":"# Model Instantiation, Fitting, and Analysis","3a82fa4a":"## Import Libraries","15856a41":"## Summary","c55d9ef0":"Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","649917e9":"Using [pandas.DataFrame.info](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.info.html), I printed a concise summary of the **digit_train** DataFrame. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.","2f097d94":"My submission of my KNN Model produced a 96.857% accuracy score. This is a good baseline to compare against other models.","6eb6b31f":"[Activations](https:\/\/keras.io\/layers\/core\/#activation) can either be used through an **Activation** layer, or through the **activation** argument supported by all forward layers. Below I used the Softmax activation function.","b0d2736f":"An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.","0cab0e56":"### Keras Model Kaggle Submission","dc7ccd25":"For this type of machine learning problem, [scikit-learn](https:\/\/scikit-learn.org\/stable\/) is not the best Python library to use. Scikit-learn is not capable of utilizing a GPU for computational processing which leads to extremely long model training. When working with large datasets and convolutional neural networks, the [Keras](https:\/\/keras.io\/) and [TensorFlow](https:\/\/www.tensorflow.org\/) API libraries proved to be much better and processing the data and producing excellent results.","1589a3ef":"### Convolutional Layers","26064afc":"Using the code below, I set the **label** feature as the target feature and moved this to the beginning of my DataFrame.","e1770dea":"Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called **overfitting**. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a **test set**: X_test, y_test. The simplest way to use cross-validation is to call the [cross_val_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) helper function on the estimator and the dataset.","fb5a111b":"Use Keras if you need a deep learning library that:\n- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n- Runs seamlessly on CPU and GPU.\n","c0369afa":"### KNN Model Kaggle Submission","d062058c":"While simple and intuitive, and though it can even obtain very good accuracy in certain situations, the KNN algorithm has a number of drawbacks. The first is that it doesn\u2019t actually \u201clearn\u201d anything \u2014 if the algorithm makes a mistake, it has no way to \u201ccorrect\u201d and \u201cimprove\u201d itself for later classifications. Secondly, without specialized data structures, the KNN algorithm scales linearly with the number of data points, making it a questionable choice for large datasets.","38664224":"Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time. This is a [simple way to prevent neural networks from overfitting](http:\/\/www.jmlr.org\/papers\/volume15\/srivastava14a\/srivastava14a.pdf).","d5941ae9":"Arguments\n- **x**: Input tensor.\n- **axis**: Integer, axis along which the softmax normalization is applied.","5df27747":"Conv2D Arguments\n- **filters**: is the number of desired feature maps.\n- **kernel_size**: is the size of the convolution kernel. A single number 5 means a 5x5 convolution.\n- **strides**: the new layer maps will have a size equal to the previous layer maps divided by strides. Leaving this blank results in strides=1.\n- **padding**: is either 'same' or 'valid'. Leaving this blank results in padding='valid'. If padding is 'valid' then the size of the new layer maps is reduced by kernel_size-1. For example, if you perform a 5x5 convolution on a 28x28 image (map) with padding='valid', then the next layer has maps of size 24x24. If padding is 'same', then the size isn't reduced.\n- **activation**: is applied during forward propagation. Leaving this blank results in no activation.","25140f80":"![EDA](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*jXfdWyIAF-nymLFnQEkHNA.png)","b6321e60":"### Train\/Val Split","6c713432":"Below is a count plot of all the instances of digits 0-9 in the **digit_train** dataset.","17b22293":"From the information above, we can see that we have **int64** data types in our dataframe.","d4551e76":"In this [Kaggle competition](https:\/\/www.kaggle.com\/c\/digit-recognizer\/overview), my goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. This notebook allows me to experiment with different algorithms to learn first-hand what works well and how techniques compare.","13b7b1c3":"As you can see, this code took a very long time to run, primarily due to the size of the training dataset. The scikit-learn library is not optimized for large datasets and only utilizes the CPU for computational work.","2000094e":"Using the [sklearn.neural_network.MLPClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) library, I created three Multi-layer Perceptron Classification Model. This model optimizes the log-loss function using LBFGS or stochastic gradient descent. MLP is a class of [feedforward](https:\/\/en.wikipedia.org\/wiki\/Feedforward_neural_network) [artificial neural network](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network) that consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function.","0aae8cec":"I noticed gradual improvements as the models progressed from K-Nearest Neighbors to Multi-layer Perceptron to Keras. While KNN and MLP produced good results and was easy to implement, the process to gain these results was computationally expensive. The Keras Model produced the best accuracy of the three models and the time to run the model was considerably less than the KNN and MLP models. That being said, there is a bit of a learning curve when implementing a Keras deep learning model.","97b3c39a":"[Dense](https:\/\/keras.io\/layers\/core\/#dense) implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).","52f93722":"### Training History Visualizaton","ae52a2a1":"### Model Buidling","7570428e":"To begin building my model, I created a Sequential model. This is a linear stack of layers. The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. There are several possible ways to do this:\n- Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected). In input_shape, the batch dimension is not included.\n- Some 2D layers, such as Dense, support the specification of their input shape via the argument input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n- If you ever need to specify a fixed batch size for your inputs (this is useful for stateful recurrent networks), you can pass a batch_size argument to a layer. If you pass both batch_size=32 and input_shape=(6, 8) to a layer, it will then expect every batch of inputs to have the batch shape (32, 6, 8).","c02bec69":"Batch size is the number of samples per evaluation step. ","bb578449":"The mean score and the 95% confidence interval of the score estimate for the Multi-layer Perceptron Classifier Model is 98% with a variance of 1%. This is an improvement on the KNN Model with similar variance.","4ce0ae70":"The parameter below [flattens](https:\/\/keras.io\/layers\/core\/#flatten) the input. Does not affect the batch size.","d516ff34":"Below is an example of one of the images rendered from the pixel data.","4be3c635":"[Cross-validation](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html), sometimes called out-of-sample testing, is any of various similar model validation techniques for assessing how the results of a statistical analysis will generalize to an independent data set. Cross-validation can be used to compare the performances of different predictive modeling procedures.","3649a69d":"## Train Test Split","ebb74f3e":"A [callback](https:\/\/keras.io\/callbacks\/) is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or  Model classes. The relevant methods of the callbacks will then be called at each stage of the training.","39fc31c2":"The disadvantages of Multi-layer Perceptron (MLP) include:\n- MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.\n- MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.\n- MLP is sensitive to feature scaling.","a7682226":"## Target Feature Conversion to Categorical","960e6fca":"### KNN Model Evaluation","6dabdfe8":"## Check Python Version","b140d634":"### Multi-layer Perceptron Classifier Model Cross Validation","99396300":"The submission of my Keras Model produced a 99.571% accuracy score. This is a significant boost over my KNN and MLP Models.","04ee733b":"### KNN Model Cross Validation","e0f84eee":"### Multi-layer Perceptron Model Evaluation","f9b7e64d":"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic [dataset of handwritten images](https:\/\/en.wikipedia.org\/wiki\/MNIST_database) has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.","e49bb576":"In this section, I will define my convolutional neural network model, compile it, and fit it against the digits datasets.","bc06b83c":"### Multi-layer Perceptron Classifier Model Kaggle Submission","fab74de5":"The fit() method on a Keras Model returns a History object. The History.history attribute is a dictionary recording training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable). ","6fd6eac6":"Using the [sklearn.neighbors.KNeighborsClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html) library, I created a K-Nearest Neighbors model. The code below interated over a k-range of 1 to 5. The KNN algorithm classifies unknown data points by comparing the unknown data point to each data point in the training set. This comparison is done using a distance function or similarity metric. Then, from the k most similar examples in the training set, we accumulate the number of \u201cvotes\u201d for each label. The category with the highest number of votes \u201cwins\u201d and is chosen as the overall classification.","18043150":"The pixel values for each image are gray scaled between 0 and 255. KNN and Multi-layer Perceptron models are sensitive to feature scaling. For my analysis, I normalized these values from 0-255 to 0-1.","3a859e41":"The leftmost layer, known as the input layer, consists of a set of neurons {xi|x1,x2,...,xm} representing the input features. Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation w1x1+w2x2+...+wmxm, followed by a non-linear activation function g(.) : R -> R - like the hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values. I chose to set **hidden_layer_sizes=(784,)** as I have 784 input features.","e0d8b53f":"### Keras Model Evaluation","78d3901f":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]). This is also required as I used [categorical_crossentropy](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/backend\/categorical_crossentropy) as my loss function.","f58b508f":"Using the [pandas.read_csv](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html) method, I read the Digit Recognizer Train and Test datasets. The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.","5cc286c9":"This algorithm, by default, has **leaf_size=40**. This parameter is the number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples \/ leaf_size.","382eb8ea":"# MINST Digit Recognizer: Comparing KNN, MLP, and Keras Model Performance\n- [Rockhurst University](https:\/\/www.rockhurst.edu\/)\n- Predictive Modeling (BIA 6303) - Final Project\n- [Chris Tan](https:\/\/www.linkedin.com\/in\/christan\/)\n- 5\/12\/2019","ea3a6ed4":"Before training my model, I need to configure the learning process, which is done via the compile method. It receives three arguments:\n- An **optimizer**. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class. See: [optimizers](https:\/\/keras.io\/optimizers\/).\n- A **loss** function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. See: [losses](https:\/\/keras.io\/losses\/).\n- A list of **metrics**. For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."}}