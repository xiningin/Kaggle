{"cell_type":{"c5803510":"code","184d2e37":"code","692cb8fb":"code","50cd8896":"code","ceaf948f":"code","1befe439":"code","b155d482":"code","7b332a16":"code","7bcb8c91":"code","8a68db1d":"code","c8c421c7":"code","2b01ca83":"code","52b44721":"code","5665cff5":"code","696096d7":"code","805cdce9":"code","9144577e":"code","3ef8408b":"code","d66fa7bb":"code","3dcca31d":"code","08ac0e31":"code","fef7480c":"code","2f8c19ad":"markdown","537ebd1f":"markdown","12c56920":"markdown","83f2d31a":"markdown","04094f6e":"markdown","b2a9bac7":"markdown","6223ae79":"markdown","7b9f6c84":"markdown","8611343d":"markdown","d7060b3a":"markdown","7b1428a3":"markdown","e1ab5bec":"markdown","98ebde0e":"markdown","fba1f107":"markdown","666c91e1":"markdown","a170b264":"markdown","29ace364":"markdown","0f47e3f2":"markdown","76e0e9d2":"markdown","7f103edd":"markdown","35dde0fd":"markdown","d5c72479":"markdown"},"source":{"c5803510":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, AvgPool2D, MaxPool2D , Flatten , Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport cv2\nimport os\n\nprint(tf.__version__)","184d2e37":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        diag= \"\"\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                if \"bacteria\" in img:\n                    diag = [1,0,0] \n                elif \"virus\" in img:\n                    diag = [0,1,0] \n                else:\n                    diag = [0,0,1]              \n                data.append([resized_arr, class_num, diag])\n            except Exception as e:\n                print(img, e)\n    return np.array(data)","692cb8fb":"train = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\nval = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')\ntest = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')","50cd8896":"def display_set(one_set, order = [\"pneumonia bacteria\", \"pneumonia virus\", \"normal\"]):\n    l = []\n    for i in one_set:\n        if i[2] == [1,0,0]:\n            diag = \"pneumonia bacteria\"\n        elif i[2] == [0,1,0]:\n            diag = \"pneumonia virus\"\n        else:\n            diag = \"normal\"\n        l.append(diag)\n    sns.set_style('darkgrid')\n    sns.countplot(l, order = order)  ","ceaf948f":"display_set(train)","1befe439":"display_set(val)","b155d482":"display_set(test)","7b332a16":"x_data = []\ny_data = []\n\nfor feature, label, diag in train:\n    x_data.append(feature)\n    y_data.append(diag)\n\nfor feature, label, diag in test:\n    x_data.append(feature)\n    y_data.append(diag)\n    \nfor feature, label, diag in val:\n    x_data.append(feature)\n    y_data.append(diag)\n\ny_class_num = [np.where(np.asarray(r)==1)[0][0] for r in y_data]\nsns.countplot(y_class_num).set_title('All data')","7bcb8c91":"\n\nsamples = pd.DataFrame(y_class_num, columns = ['class_num'])\nsamples['diag'] = y_data\nsamples['img'] = x_data\n\nsmallest_diag_count = samples['class_num'].value_counts().min()\nprint(\"number of sampels per category\", smallest_diag_count)\n\nclass0 = samples[samples['class_num'] == 0].sample(smallest_diag_count)\nclass1 = samples[samples['class_num'] == 1].sample(smallest_diag_count)\nclass2 = samples[samples['class_num'] == 2].sample(smallest_diag_count)\n\nsamples_under = pd.concat([class0, class1, class2], axis=0)\n\nx = samples_under['img'].tolist()\ny = samples_under['diag'].tolist()\nsns.countplot(samples_under['class_num']).set_title('Final Test data')\n","8a68db1d":"# Lets shuffle the samples to have matching ditributions regarding the differents sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\nsns.countplot([np.where(np.asarray(r)==1)[0][0] for r in y_train]).set_title('Training data')","c8c421c7":"x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, shuffle=False)\nsns.countplot([np.where(np.asarray(r)==1)[0][0] for r in y_val]).set_title('Validation data')","2b01ca83":"sns.countplot([np.where(np.asarray(r)==1)[0][0] for r in y_test]).set_title('Test data')","52b44721":"# Normalize the data\nx_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/ 255\nx_test = np.array(x_test) \/ 255","5665cff5":"# resize data for deep learning \nx_train = x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)","696096d7":"# With data augmentation to prevent overfitting and handling the imbalance in dataset\n\ntrain_datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ntrain_datagen.fit(x_train)\n\nvalid_datagen = ImageDataGenerator()\n\ntest_datagen = ImageDataGenerator()\n\n\ntrain_generator = train_datagen.flow(\n    x_train,\n    y_train,\n    batch_size = 32)\n\nvalidation_generator = valid_datagen.flow(\n    x_val,\n    y_val)\n\ntest_generator = test_datagen.flow(\n    x_test,\n    y_test)\n","805cdce9":"opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\nmodel = Sequential()\nmodel.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\nmodel.add(AvgPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Flatten())\nmodel.add(Dense(units = 128 , activation = 'relu'))\nmodel.add(Dense(units = 3 , activation = 'softmax'))\nmodel.compile(optimizer = opt , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","9144577e":"# When publishing this notebook, there is a bug in the fit function which exists after the first epoch\n# I workaround it with a simple loop\n\nclass_weight = {0: 3, 1: 3, 2: 1}\nloops = 20\nhistory = []\n\nfor x in range(loops):\n    history.append(model.fit(\n            train_generator,\n            steps_per_epoch=97,\n            epochs=1,\n            validation_data=test_generator,\n            validation_steps=100,\n            class_weight=class_weight))","3ef8408b":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0]*100)\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","d66fa7bb":"print(history[0].history)","3dcca31d":"epochs = [i for i in range(loops)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = []\ntrain_loss = []\nval_acc = []\nval_loss = []\nfor h in history:\n    train_acc.append(h.history['accuracy'])\n    train_loss.append(h.history['loss'])    \n    val_acc.append(h.history['val_accuracy'])\n    val_loss.append(h.history['val_loss'])\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Training & Validation Loss\")\nplt.show()","08ac0e31":"predictions = model.predict_classes(x_test)\ny_test_num = [np.where(r==1)[0][0] for r in y_test]\nnames = ['Pneumonia Bacteria', 'Pneumonia Virus','Normal']\n\n\nprint(classification_report(y_test_num, predictions, target_names = names))","fef7480c":"cm = confusion_matrix(y_test_num,predictions)\ncm = pd.DataFrame(cm , index = names , columns = names)\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'\n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm.to_numpy().flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm.to_numpy().flatten()\/np.sum(cm.to_numpy())]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(3,3)\n\nplt.figure(figsize = (10,10))\nsns.heatmap(cm,\n            annot=labels,\n            cmap= \"coolwarm\",\n            linecolor = 'black',\n            linewidth = 1,\n            fmt='')","2f8c19ad":"**We will now even the number of examples of each categories, in order to train our model with balanced classes even it means losing some examples with a simple under sizing**","537ebd1f":"**We perform a grayscale normalization to reduce the effect of illumination's differences.Moreover the CNN converges faster on [0..1] data than on [0..255].**","12c56920":"# Redistributing Samples\nI'd rather redistribute the sets to able to monitor how effective the model learning is when training, validating and testing","83f2d31a":"**After some epochs the accuray stalls, but we can see that the validation is good and we are not overfitting thanks to data augmentation.\nKernels who use the original sets just show random values for validation making it impossible to have this information.**","04094f6e":"I'm reducing the values from the forked project.\n\nFor the data augmentation, i choosed to :\n1. Randomly rotate some training images by 1 degrees \n2. Randomly Zoom by 10% some training images\n3. Randomly shift images horizontally by 10% of the width \n4. Randomly shift images vertically by 10% of the height \nOnce our model is ready, we fit the training dataset.","b2a9bac7":"**Lets split into 70% train, 15% validation and 15% test**","6223ae79":"**We train with standard fit method, but we want to miss few positive pneumonia diagnosys.\nIn order to do so, we increase weights on pneumonia classes versus normal class.**","7b9f6c84":"# Data Augmentation\n**In order to avoid overfitting problem, we need to expand artificially our dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations.\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.**","8611343d":"# Importing the necessary libraries","d7060b3a":"# Training the Model\n\n**We will output 3 classes.**","7b1428a3":"**Validation set has the same profile as test set and is balanced**","e1ab5bec":"**Confusion matrix shows that the model is strong at identifying normal cases, but the virus form causes many misclassification.\nThis is not a problem since my first goal was to miss few Pneumonia cases: cases that are predicted normal but actual Virus or Bacteria, this comes at the cost of moderate false postives**","98ebde0e":"**Validation partition is very small and has no virus example**","fba1f107":"# Loading the Dataset","666c91e1":"**Test set matches validation set size and balance**","a170b264":"**The distribution of tests data does not match, the training which could explains why many kernels have poor score on validation**","29ace364":"**The training data seems imbalanced**","0f47e3f2":"**New test set is balanced**","76e0e9d2":"# Analysis after Model Training","7f103edd":"# Fork\n\nI forked [Madz2000](https:\/\/www.kaggle.com\/madz2000) kernel because of the following points:\n* his code is minimal and easy to read\n* he used a grayscale model. Most people take an RGB general pretrained model which leads to some computationel waste (Xray images are grayscaled).","35dde0fd":"# Data Visualization","d5c72479":"# Description of the Pneumonia Dataset\n**The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\nSome of the files indicate bateria and virus in filename, I'm going to make use of this information for a 3 class classification which will be one_hot_encoded**"}}