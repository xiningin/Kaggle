{"cell_type":{"c941235d":"code","031ec870":"code","0bc19463":"code","fc94c414":"code","098bc05e":"code","5f9bc776":"code","91456d94":"code","2eadc454":"code","5ac71cf6":"code","2f56e725":"code","0226d7f0":"code","f6e1f998":"code","f2f3b347":"code","a62d58ce":"code","7d2ed4e4":"code","5a458394":"code","c5122605":"code","8533ff95":"code","e6599696":"code","807dbd93":"code","bb047991":"code","52377fdf":"code","bac21828":"code","f43fea7e":"code","88c3b12c":"code","cb0d537f":"code","1bbeffd9":"code","d9433606":"code","4652df76":"code","7600d21e":"code","5d306a24":"code","5e5d2a26":"code","930997e2":"code","660f72b8":"code","019a45f8":"code","db34469a":"code","b05073df":"code","f7febeb2":"code","6044b9ab":"markdown","f6504d4d":"markdown","ff4c2301":"markdown","d38f75e2":"markdown","4860c3db":"markdown","ab93a7da":"markdown","655edab5":"markdown","ddc84006":"markdown","17e1ec9c":"markdown","d28b1415":"markdown","af50bf9c":"markdown"},"source":{"c941235d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn as sk\nimport scipy as sp\nimport seaborn as sns\nimport scipy.stats as stats\nimport pylab\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","031ec870":"\ntrain_df1=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_df1=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\n\n\n","0bc19463":"print(train_df1.shape)","fc94c414":"print(test_df1.shape)","098bc05e":"print(train_df1.head())","5f9bc776":"print(train_df1.describe())","91456d94":"#Merging the train and test data\ndf1=pd.concat([train_df1,test_df1],axis=0)","2eadc454":"Missing_df=pd.DataFrame(df1.isnull().sum().sort_values(ascending=False)\/len(df1))\nMissing_df.head(40)","5ac71cf6":"#Dropping the columns having missing values greater than 50 percent\ndf1.drop(['PoolQC','MiscFeature','Alley','Fence'],axis=1,inplace=True)","2f56e725":"#Other categorical and numerial features has nearly Zero percent missing values Imputing with mode and median.\ncat_features_list=df1.select_dtypes(exclude=np.number).columns.tolist()\nnum_features_list=df1.select_dtypes(include=np.number).columns.tolist()\n        \n        ","0226d7f0":"#Handling Categorical Features\nfor feature in cat_features_list:\n    df1[feature].fillna(df1[feature].mode()[0],inplace=True)\n","f6e1f998":"#Handling Numerical Features\nnum_features_list.remove('SalePrice')\nfor feature in num_features_list:\n    df1[feature].fillna(df1[feature].median(),inplace=True)","f2f3b347":"#Ensuring all missing value are handled properly\ndf1.isnull().sum().sort_values(ascending=False).head(50)","a62d58ce":"\n#Derving new Features\ndf1['YearsOld']=df1['YrSold']-df1['YearBuilt']","7d2ed4e4":"#Checking for the top correlated features\ncorr_matrix=df1.corr()\nmost_corr_features=corr_matrix.index[abs(corr_matrix['SalePrice']>0.5)]\nplt.figure(figsize=(10,10))\nsns.heatmap(df1[most_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","5a458394":"\ndf1.skew().sort_values(ascending=False)","c5122605":"#Treating the Variables  with skewness greater than 1 \nskewed_fearures=df1.skew().sort_values(ascending=False).head(20).index.tolist()\nskewed_fearures.remove('SalePrice')\ndf1[skewed_fearures]=np.log1p(df1[skewed_fearures])","8533ff95":"# Checking the Target Variable\n\nsns.distplot(train_df1['SalePrice'])\nfig=plt.figure()\nplot_1=stats.probplot(train_df1['SalePrice'],dist='norm', plot=pylab)","e6599696":"#The Target variable is  rightly skewed .Transforming it.\ntrain_df1['SalePrice']=np.log(train_df1['SalePrice']+1)\nsns.distplot(train_df1['SalePrice'])\nfig=plt.figure()\nplot_2 = stats.probplot(train_df1['SalePrice'],dist='norm',plot=pylab)\n\n\n","807dbd93":"#Encoding Categorical Features\n#One Hot Encoding\ndf2=pd.get_dummies(df1[cat_features_list],drop_first=True)\ndf1.drop(cat_features_list,axis=1,inplace=True)\n","bb047991":"#Merging the transformed dataframes\ndf3=pd.concat([df1,df2],axis=1)\n#Removing the duplicated columns\n\nd3 = df3.loc[:,~df3.columns.duplicated()]","52377fdf":"#Dropping the Id Feature\ndf3.drop(['Id'],axis=1,inplace=True)\ndf3.shape","bac21828":"\n#Splitting the data into train and test data\nX=df3.drop('SalePrice',axis=1)\nY=df3['SalePrice']\nX_train=X.iloc[:1460]\nX_test=X.iloc[1460:,]\nY_train=Y.iloc[:1460]\nY_test=Y.iloc[1460:]\n\nY_train=np.log1p(Y_train)","f43fea7e":"#Training the Base  Model\nfrom sklearn.linear_model import LinearRegression\nlr_model=LinearRegression()\nlr_model.fit(X_train,Y_train)\nY_pred_lr=lr_model.predict(X_test)\nY_lr_train=lr_model.predict(X_train)","88c3b12c":"#Root Mean Sqaured Error\n#Evaludating the model\nfrom sklearn.metrics import mean_squared_error\nMSE=np.sqrt(mean_squared_error(Y_train,Y_lr_train))\nprint(\"RMSE of the Linear Regression Model is :\",np.sqrt(MSE))\n","cb0d537f":"r2_score=lr_model.score(X_train,Y_train)\nprint(\"R2_score of Liner Regression\",r2_score)","1bbeffd9":"\n#Lets check Adjusted R_Squared \nadj_r2 = (1 - (1 - r2_score) * ((X_train.shape[0] - 1) \/ \n          (X_train.shape[0] - X_train.shape[1] - 1)))\nprint(\"Adjusted R_Sqaured of Linear Regression Model is :\",adj_r2 )","d9433606":"#Training Xgboost Model \nimport xgboost\nclassifier=xgboost.XGBRegressor()\nbooster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1]","4652df76":"\n\n\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","7600d21e":"# Set up the random search with 5-fold cross validation\nrandom_cv = RandomizedSearchCV(estimator=classifier,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_squared_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","5d306a24":"random_cv.fit(X_train,Y_train)","5e5d2a26":"random_cv.best_estimator_","930997e2":"regressor=xgboost.XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.15, max_delta_step=0, max_depth=2,\n             min_child_weight=3, monotone_constraints='()',\n             n_estimators=500, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","660f72b8":"regressor.fit(X_train,Y_train)","019a45f8":"Y_pred_xgb=regressor.predict(X_test)\nY_xgb_train=regressor.predict(X_train)","db34469a":"from sklearn.metrics import mean_squared_error\nprint(\"RMSE of XgBosst Model is\",np.sqrt(mean_squared_error(Y_train,Y_xgb_train)))","b05073df":"r2_score=lr_model.score(X_train,Y_train)\nprint(\"R2_score of XgBosst Model is \",r2_score)","f7febeb2":"#Submission\nsub_df=pd.DataFrame(data={'Id':test_df1['Id'].values,'SalePrice':np.exp(Y_pred_xgb)})\nsub_df.to_csv('submission.csv',index=False)","6044b9ab":"Splitting the train and test data","f6504d4d":"Getting the shape and summary of data","ff4c2301":"\n# Basic Feature Engineering and Modelling on Advanced Regression Techniques","d38f75e2":"# Feature Transformation","4860c3db":"# Data Visualization","ab93a7da":"# Handling Missing Values","655edab5":"Hyper Parameter Optimization\n","ddc84006":"Handling Categorical Variables","17e1ec9c":"#Evaluation the model trhough different metrics","d28b1415":"#  Training the Model and Making Predictions","af50bf9c":"# Loading the Required Libraries and Data"}}