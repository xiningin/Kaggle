{"cell_type":{"e614a3f3":"code","db16c6b4":"code","5d9c41a9":"code","8eb3142c":"code","6095f8ad":"code","e766c865":"code","4ea4999c":"code","c61724d7":"code","3c35f64a":"code","3e36ecac":"code","59f30d2a":"code","1801012b":"code","d0e22f35":"code","87d567d6":"code","349ab2c9":"code","9467cf04":"code","84c03d7c":"code","d81694de":"code","593c5baf":"code","f8099fbd":"code","474d6134":"code","4953ea8a":"code","d81cdef1":"code","04340bcb":"code","d9a6664f":"code","9557dcc6":"markdown","5e9211a3":"markdown","14332d05":"markdown","2805145d":"markdown","9fd6210c":"markdown","8b0d419c":"markdown","83fcf8b6":"markdown","6cf49678":"markdown","3ee9c799":"markdown","56db3780":"markdown","7a046cc7":"markdown","d5154ed2":"markdown","8c4f056d":"markdown","8025054f":"markdown","a26e98a3":"markdown","4f8a7c23":"markdown","7b1e1d7b":"markdown","434c7ec8":"markdown","ddc235af":"markdown","34b4ee45":"markdown"},"source":{"e614a3f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db16c6b4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score,RepeatedStratifiedKFold,RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, recall_score, f1_score,classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA","5d9c41a9":"train_df = pd.read_csv(\"..\/input\/mobile-price-classification\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/mobile-price-classification\/test.csv\")\ntrain_df.head()","8eb3142c":"train_df.info()","6095f8ad":"print(\"Bluetooth\\n\",train_df.blue.value_counts())\nprint(\"Dual sim\\n\",train_df.dual_sim.value_counts())\nprint(\"4G\\n\",train_df.four_g.value_counts())\nprint(\"Number of Cores\\n\",train_df.n_cores.value_counts())\nprint(\"3G\\n\",train_df.three_g.value_counts())\nprint(\"Touch Screen\\n\",train_df.touch_screen.value_counts())\nprint(\"Wifi\\n\",train_df.wifi.value_counts())","e766c865":"train_df.describe().T","4ea4999c":"train_df.shape","c61724d7":"test_df.shape","3c35f64a":"plt.figure(figsize=(14,10))\nsns.heatmap(train_df.corr(), annot=True, fmt=\".2f\");","3e36ecac":"plt.figure(figsize=(15,6));\nsns.barplot( x= \"n_cores\", y = \"battery_power\" ,hue=\"price_range\", data=train_df)\nplt.xticks(rotation=90);","59f30d2a":"sns.pointplot(y=\"ram\", x=\"price_range\", data=train_df)","1801012b":"sns.catplot(x=\"price_range\",y=\"ram\",data=train_df)\nplt.xticks(rotation=90);","d0e22f35":"sns.pointplot(y=\"int_memory\", x=\"price_range\", data=train_df)","87d567d6":"sns.pointplot(y=\"talk_time\", x=\"price_range\", data=train_df)","349ab2c9":"total = float(len(train_df))\nax = sns.countplot(train_df[\"four_g\"]);\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\"); ","9467cf04":"labels = [\"Wifi-supported\",'Not supported']\nvalues=train_df['wifi'].value_counts().values\nfig1, ax1 = plt.subplots()\nax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)\nplt.show()","84c03d7c":"labels = [\"0\",'1',\"2\",\"3\"]\nvalues=train_df['price_range'].value_counts().values\nfig1, ax1 = plt.subplots()\nax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)\nplt.show()","d81694de":"def OutliersBox(df, nameOfFeature):\n    trace0 = go.Box(y = df[nameOfFeature],\n                    name = \"All Points\",\n                    jitter = 0.3,\n                    pointpos = -1.8,\n                    boxpoints = \"all\")\n    trace1 = go.Box(y = df[nameOfFeature],\n                    name = \"Only Whiskers\",\n                    boxpoints = False)\n    trace2 = go.Box(y = df[nameOfFeature],\n                    name = \"Suspected Outliers\",\n                    boxpoints = \"suspectedoutliers\",\n                    marker = dict(color = 'rgb(8,81,156)',\n                                outliercolor = 'rgba(219, 64, 82, 0.6)', line = dict(outliercolor = 'rgba(219, 64, 82, 0.6)',\n                                                                                   outlierwidth = 2)),\n                    line = dict(color = 'rgb(8,81,156)') )\n    trace3 = go.Box(y = df[nameOfFeature],\n                    name = \"Whiskers and Outliers\",\n                    boxpoints = \"outliers\")\n    \n    data_ = [trace0, trace1, trace2, trace3]\n    layout_ = go.Layout(\n        title = \"{} Outliers\".format(nameOfFeature)\n    )\n    fig = go.Figure(data=data_, layout = layout_)\n    py.iplot(fig, filename = \"Outliers\")","593c5baf":"OutliersBox(train_df,\"talk_time\")","f8099fbd":"X = train_df.drop([\"price_range\"], axis=1)\ny = train_df[\"price_range\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1, random_state=42)","474d6134":"def ml_model(model, parameters):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n    random_search = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1, verbose=2 )\n    #grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=2)\n    pipe = make_pipeline(StandardScaler(), PCA(n_components=0.95),random_search)\n    pipe.fit(X_train, y_train)\n    \n    print('                 Classification report \\n')\n\n    print(classification_report(y_test, pipe.predict(X_test)))","4953ea8a":"log_reg = LogisticRegression()\nlog_reg_params = {\"C\" : [1,2,3,0.01,0.001, 2.5, 1.5],\n                  \"max_iter\" : range(100,800,100)}\nml_model(log_reg, log_reg_params)","d81cdef1":"tree = DecisionTreeClassifier()\ndecTree_params = {\"max_depth\" : [5,10,15,20,25,30],\n                  \"min_samples_split\" : np.arange(2,50),\n                  \"min_samples_leaf\" : np.arange(1,50)}\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\nrandom_search = RandomizedSearchCV(tree, decTree_params, cv=cv, random_state=1, n_jobs=-1, verbose=2 )\n#grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=2)\npipe = make_pipeline(random_search)\npipe.fit(X_train, y_train)\n    \nprint('                 Classification report \\n')\n\nprint(classification_report(y_test, pipe.predict(X_test)))","04340bcb":"knn = KNeighborsClassifier()\nknn_params = {\"n_neighbors\" : np.arange(1,50),\n              \"leaf_size\" : np.arange(1,50)}\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\nrandom_search = RandomizedSearchCV(knn, knn_params, cv=cv, random_state=1, n_jobs=-1, verbose=2 )\n#grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=2)\npipe = make_pipeline(random_search)\npipe.fit(X_train, y_train)\nprint('                 Classification report \\n')\n\nprint(classification_report(y_test, pipe.predict(X_test)))","d9a6664f":"forest = RandomForestClassifier()\nrandomForest_params = {\"n_estimators\" : [100,500,1000,2000],\n                       \"min_samples_split\" : np.arange(2,30),\n                       \"min_samples_leaf\" : np.arange(1,50),\n                       \"max_features\" : np.arange(1,7)}\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\nrandom_search = RandomizedSearchCV(forest, randomForest_params, cv=cv, random_state=1, n_jobs=-1, verbose=2 )\n#grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=2)\npipe = make_pipeline(random_search)\npipe.fit(X_train, y_train)\nprint('                 Classification report \\n')\n\nprint(classification_report(y_test, pipe.predict(X_test)))","9557dcc6":"# Data Visualization","5e9211a3":"## Correlation \nCorrelation is a term that is a measure of the strength of a linear relationship between two quantitative variables.Correlation coefficient has a value that must fall between -1.0 and +1.0.\n* The closer correlation coefficient is to zero, the weaker the linear relationship.\n* Positive correlation coefficient values indicate a positive correlation, where the values of both variables tend to increase together.\n* Negative correlation coefficient values indicate a negative correlation, where the values of one variable tend to increase when the values of the other variable decrease.","14332d05":"## Talk Time vs Price Range","2805145d":"## ML Model Function","9fd6210c":"## KNN","8b0d419c":"# Machine Learning Model","83fcf8b6":"## Distribution of Phones Supporting 4G","6cf49678":"# Project Information\n## Data Information\nIn this data:\n* id:ID\n* battery_power:Total energy a battery can store in one time measured in mAh\n* blue:Has bluetooth or not\n* clock_speed:speed at which microprocessor executes instructions\n* dual_sim:Has dual sim support or not\n* fc:Front Camera mega pixels\n* four_g:Has 4G or not\n* int_memory:Internal Memory in Gigabytes\n* m_dep:Mobile Depth in cm\n* mobile_wt:Weight of mobile phone\n* n_cores:Number of cores of processor\n* pc:Primary Camera mega pixels\n* px_height:Pixel Resolution Height\n* px_width:Pixel Resolution Width\n* ram:Random Access Memory in Megabytes\n* sc_h:Screen Height of mobile in cm\n* sc_w:Screen Width of mobile in cm\n* talk_time:longest time that a single battery charge will last when you are\n* three_g:Has 3G or not\n* touch_screen:Has touch screen or not\n* wifi:Has wifi or not\n\n## Project Aim\nIn this project, a price range estimation will be made using basic phone features.","3ee9c799":"## Distribution of Phones Supporting Wifi","56db3780":"## RAM vs Price Range","7a046cc7":"## Distribution of Price Range","d5154ed2":"## Logistic Regression","8c4f056d":"When the graph above is examined, it is seen that there is a high correlation between RAM and Price Range variables.","8025054f":"## Price range according to the number of processor cores and battery power","a26e98a3":"## Random Forest","4f8a7c23":"## Decision Tree","7b1e1d7b":"## Internal Memory in Gigabytes vs Price Range","434c7ec8":"## Visualization For Outliers","ddc235af":"## Splitting Data\nAbove, we first gave all variables except the \"price_range\" variable to the X variable and gave the variable \"price_range\" to the y variable. Then we split the data into train and test data. X_train and y_train show the dependent and independent variables to be used to test the model, while X_test and y_test are used to develop the model. Test_size specifies how many of data (10%) will be used for testing. Random_state is used to see the same distinction every time we run the program.","34b4ee45":"# Loading and Examining the Data"}}