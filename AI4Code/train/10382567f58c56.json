{"cell_type":{"050f013c":"code","c89c2a56":"code","9f583cb8":"code","e0bcfa7c":"code","37826c1f":"code","27cbabe5":"code","9ef3ddf9":"code","e1567e37":"code","3ed41947":"code","48badc04":"code","1e4ec96f":"code","16c9a217":"code","89401b74":"code","62275306":"code","d1d71b15":"code","e894ec1f":"code","8418ea0a":"code","85fc45f1":"code","516c9c88":"code","9ab070a4":"code","550c7677":"code","0d807931":"code","739595b7":"code","da91d151":"code","6125a99f":"markdown"},"source":{"050f013c":"import xgboost as xgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","c89c2a56":"train0 = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/test.csv\")","9f583cb8":"train0.head()","e0bcfa7c":"test.head()","37826c1f":"n=len(train0)\nprint(n)\nN=list(range(n))\nrandom.seed(2021)\nrandom.shuffle(N)","27cbabe5":"train=train0.iloc[N[0:10000],:]","9ef3ddf9":"target = train['target']\ndata = train.drop(['target','id'],axis=1)\ntest = test.drop('id',axis=1)","e1567e37":"print(len(data))\nprint(len(train))\nprint(len(test))","3ed41947":"columns=data.columns.to_list()\nprint(columns)","48badc04":"def objective(trial,data=data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n        'objective': trial.suggest_categorical('objective',['reg:logistic','reg:tweedie']), \n        'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  # 'gpu_hist','hist'\n        'lambda': trial.suggest_loguniform('lambda',1e-3,10.0),\n        'alpha': trial.suggest_loguniform('alpha',1e-3,10.0),\n        'colsample_bytree': trial.suggest_loguniform('colsample_bytree',1e-3,1.0),\n        'subsample': trial.suggest_loguniform('subsample', 1e-3,1.0),\n        'n_estimators': trial.suggest_int('n_estimators', 2,200),\n        'max_depth': trial.suggest_int('max_depth', 2,10),\n        'learning_rate': trial.suggest_loguniform('learning_rate',1e-1,1.0),\n        'random_state': trial.suggest_int('random_state', 2,2021),\n        'min_child_weight': trial.suggest_int('min_child_weight',1,300),\n        'use_label_encoder': trial.suggest_categorical('use_label_encoder',[False])\n    }\n    model = xgb.XGBClassifier(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","1e4ec96f":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=8)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","16c9a217":"study.trials_dataframe()","89401b74":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","62275306":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","d1d71b15":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","e894ec1f":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['learning_rate','colsample_bytree','n_estimators','min_child_weight'])","8418ea0a":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","85fc45f1":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","516c9c88":"Best_trial=study.best_trial.params\nprint(Best_trial)","9ab070a4":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")\nsample","550c7677":"preds = np.zeros((sample.shape[0]))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor trn_idx, test_idx in kf.split(train[columns],target):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n    model = xgb.XGBClassifier(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(test[columns])\/kf.n_splits   ###### predict_proba\n    rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n    print(rmse)","0d807931":"model","739595b7":"print(preds.shape)","da91d151":"subm = sample\nsubm['target'] = np.where(preds<0.5,0,1).astype(int)\nsubm.to_csv('submission.csv',index=False)\nsubm","6125a99f":"# XGBoost Prediction with Optuna tuning\n* doc: https:\/\/github.com\/optuna\/optuna"}}