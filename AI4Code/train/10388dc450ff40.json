{"cell_type":{"09d965bc":"code","42b83ff4":"code","37de308a":"code","cca194cb":"code","692885a1":"code","886082c4":"code","ee9c7108":"code","52b487ac":"code","d3b8167a":"code","1284adce":"code","aa8a244d":"code","9ae3cc57":"code","21ce929b":"code","2b4d5c1d":"code","2a5c3168":"code","80e0fedd":"code","db97cb1f":"code","7b95e9ab":"code","e0b347c1":"code","da9aaba0":"code","c48605ee":"code","bc68a41d":"code","758c1366":"code","4ea873db":"code","ae88791b":"code","fed27189":"code","acdf8d58":"code","fd174885":"code","d9fcac49":"code","0e072481":"markdown","fd6fa2af":"markdown","87167966":"markdown","418fe530":"markdown","2b6ed4d8":"markdown","8fdb0bb0":"markdown","cf125ea0":"markdown","d5751482":"markdown","07e67d8e":"markdown","2bc16c9b":"markdown","45bcb334":"markdown","b0ebc61a":"markdown","e597361d":"markdown","c9bf2a97":"markdown","7633589e":"markdown","3252a228":"markdown","6aff31ae":"markdown","bebf0187":"markdown","9bbd3a28":"markdown","a1e061b7":"markdown"},"source":{"09d965bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42b83ff4":"\n!pip install albumentations","37de308a":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport random\nimport math\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport torch.nn as nn\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler, Adam, SGD\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n# for evaluating the model\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport time\nimport os\nimport copy\n\nimport random\n\nimport cv2\n\nimport albumentations as A\nfrom IPython.display import Image\n\nimport cv2\nfrom PIL import Image","cca194cb":"def visualize(image):\n    plt.figure(figsize=(5, 5))\n    plt.axis('off')\n    plt.imshow(image)","692885a1":"mean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.25, 0.25, 0.25])\n\ndata_transforms = {\n    'training_set': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'test_set': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}","886082c4":"data_dir = '\/kaggle\/input\/dogs-cats-images\/dog vs cat\/dataset'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['training_set', 'test_set']}\n","ee9c7108":"print(image_datasets['training_set'][0][0].shape)\nexample = image_datasets['training_set'][7000]\nimage = example[0]\nlabel = example[1]\nt = image.numpy().transpose((1, 2, 0))\nvisualize(t)\nprint(label)","52b487ac":"dataloaders = {\n    'train' : torch.utils.data.DataLoader(image_datasets['training_set'], batch_size=16,\n                                             shuffle=True, num_workers=0),\n    'val'  : torch.utils.data.DataLoader(image_datasets['test_set'], batch_size=16,\n                                             shuffle=True, num_workers=0),\n}\ndataset_sizes = {'train' : len(image_datasets['training_set']),\n                 'val' : len(image_datasets['test_set'])\n                }\nclass_names = image_datasets['training_set'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(class_names)","d3b8167a":"def imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    plt.title(title)\n    plt.show()\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","1284adce":"import shutil\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    f_path = checkpoint_path\n    torch.save(state, f_path)\n    if is_best:\n        best_fpath = best_model_path\n        shutil.copyfile(f_path, best_fpath)","aa8a244d":"#,\".\/checkpoint\/current_checkpoint.pt\", \".\/best_model\/best_model.pt\"","9ae3cc57":"!mkdir .\/best_model\n!mkdir .\/checkpoint","21ce929b":"ls","2b4d5c1d":"def train_model(n_epochs, valid_loss_min_input, loaders, model, optimizer, criterion, use_cuda, \n                checkpoint_path, best_model_path,scheduler):\n    since = time.time()\n\n    #best_model_wts = copy.deepcopy(model.state_dict())\n    valid_best_acc = 0.0\n    best_loss = 0.0\n    # initialize tracker for minimum validation loss\n    valid_loss_min = valid_loss_min_input \n\n    for epoch in range(n_epochs):\n        print('Epoch {}\/{}'.format(epoch, n_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                if use_cuda:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val':\n                valid_acc = epoch_acc\n                valid_loss = epoch_loss\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n                ###############################################################################################################\n                checkpoint = {\n                    'epoch': epoch + 1,\n                    'valid_loss_min': valid_loss,\n                    'state_dict': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                    'scheduler' : scheduler.state_dict()\n                }\n                save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n                ## TODO: save the model if validation loss has decreased\n                if valid_loss <= valid_loss_min:\n                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n                    save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n                    valid_loss_min = valid_loss\n                    valid_best_acc = valid_acc\n                    #best_model_wts = copy.deepcopy(model.state_dict())\n                ################################################################################################################\n\n        print()\n        \n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(valid_best_acc))\n    print('Min val Loss: {:4f}'.format(valid_loss_min))\n\n    # load best model weights\n    #model.load_state_dict(best_model_wts)\n    return model","2a5c3168":"use_cuda = torch.cuda.is_available()\n#### ConvNet as fixed feature extractor ####\n# Here, we need to freeze all the network except the final layer.\n# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\nmodel_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)","80e0fedd":"trained_model = train_model(10, np.Inf, dataloaders, model_conv, optimizer_conv, criterion, use_cuda\n                            ,\".\/checkpoint\/current_checkpoint.pt\", \".\/best_model\/best_model.pt\",scheduler=exp_lr_scheduler)","db97cb1f":"def load_ckp(checkpoint_fpath, model, optimizer,scheduler):\n    checkpoint = torch.load(checkpoint_fpath)\n    #loading model with the saved parameters\n    model.load_state_dict(checkpoint['state_dict'])\n    #setting optimizer to the saved stage\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    #setting scheduler to the saved stage\n    scheduler.load_state_dict(checkpoint['scheduler'])\n    \n    valid_loss_min = checkpoint['valid_loss_min']\n    \n    return model, optimizer,scheduler, valid_loss_min,checkpoint['epoch'], ","7b95e9ab":"%pwd\n%ls","e0b347c1":"model = trained_model\n# move model to GPU if CUDA is available|\nif use_cuda:\n    model = model.cuda()\n\nprint(model)","da9aaba0":"optimizer = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\nscheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\nckp_path = \".\/checkpoint\/current_checkpoint.pt\"\n\nmodel , optimizer, scheduler, valid_loss_min, epoch = load_ckp(ckp_path, model, optimizer,scheduler)\n#This Model's State_dict is set to the state of the model when it was finished with trainning\nprint(f'No of Epoch on which the Model was trained: {epoch}')","c48605ee":"ckp_path = \".\/best_model\/best_model.pt\"\nbest_model , optimizer, scheduler, valid_loss_min, epoch = load_ckp(ckp_path, model, optimizer,scheduler)\n#This Model's State_dict is set to the state of the model when it was finished with trainning\nprint(f'No of Epoch on which the Model was trained: {epoch}')\nprint(f'Valid Loss: {valid_loss_min}')","bc68a41d":"further_trained_model = train_model(3, valid_loss_min , dataloaders, best_model, optimizer, criterion, use_cuda\n                            ,\".\/checkpoint\/current_checkpoint.pt\", \".\/best_model\/best_model.pt\",scheduler)","758c1366":"final_model , optimizer, scheduler, valid_loss_min, epoch = load_ckp(ckp_path, further_trained_model, optimizer,scheduler)","4ea873db":"final_model = final_model.eval()","ae88791b":"def predict(image_path):\n    image = cv2.imread(image_path) #using the direct image and converting it to array\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    visualize(image)\n    transform  = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    k = Image.open('.\/image.jpeg')\n    transformed_test_image = transform(k)\n    \n    output = final_model(transformed_test_image.unsqueeze(0).cuda())\n    pred = nn.Softmax(-1)(output)\n\n    index = torch.argmax(pred, dim=-1).item()\n    print(f\"The image is of a {class_names[index][:-1].upper()}\")\n    ","fed27189":"import requests  \nfile_url = \"https:\/\/i.insider.com\/5df126b679d7570ad2044f3e?width=1100&format=jpeg&auto=webp\"\n    \nr = requests.get(file_url, stream = True)  \n  \nwith open(\".\/image.jpeg\", \"wb\") as file:  \n    for block in r.iter_content(chunk_size = 1024): \n         if block:  \n             file.write(block)","acdf8d58":"predict('.\/image.jpeg')","fd174885":"import requests  \nfile_url = \"https:\/\/english.mathrubhumi.com\/polopoly_fs\/1.1844474.1588749145!\/image\/image.jpg_gen\/derivatives\/landscape_1080_600\/image.jpg\"\n    \nr = requests.get(file_url, stream = True)  \n  \nwith open(\".\/image.jpeg\", \"wb\") as file:  \n    for block in r.iter_content(chunk_size = 1024): \n         if block:  \n             file.write(block)","d9fcac49":"predict('.\/image.jpeg')","0e072481":"## The Best Model","fd6fa2af":"#### Visualising a Image","87167966":"### Defining Transformers","418fe530":"#### Creating directories for Model Checkpoints","2b6ed4d8":"### Defining the Paths for Checkpoints","8fdb0bb0":"## Importing Data\n#### Datasets","cf125ea0":"## Importing Libraries","d5751482":"### Importing ResNet15\nWe are usung resnet18. We are adding a Linear layer with output = num_classes for our dataset.\nInitialising Optimizer, Criterion, Scheduler.","07e67d8e":"# Loading the model","2bc16c9b":"# Predicting for a Image","45bcb334":"#### Visualisation","b0ebc61a":"### Downloading a Dog Image","e597361d":"### Training the Model\nWe are training the model for 3 Epochs only","c9bf2a97":"## DATALOADERS","7633589e":"#### Installing Albumentations library for Image Augmentations","3252a228":"### Downloading a Cat Image","6aff31ae":"We can train above model further and achieve better results. For that, we have to give \"valid_loss_min\" in the training function.","bebf0187":"# MODEL","9bbd3a28":"###### Function to Visualize the images","a1e061b7":"### Training Function"}}