{"cell_type":{"88ec7fcd":"code","61a4150b":"code","8b968822":"code","788f79b7":"code","2f1001f0":"code","4af3f72b":"code","9c45a4ee":"code","7273b588":"code","6822f73c":"code","6e71e1bb":"code","8bccbedd":"code","800c4387":"code","b37870d9":"code","cdf5e120":"code","ff7b169f":"code","ed6cfbb3":"code","141a98e0":"code","6ade27ef":"code","a0af6649":"code","33260f87":"code","b6508748":"code","8fcd5d73":"code","4f679134":"code","ccec383b":"code","febd3ce9":"code","e6ee7a0b":"code","c6012281":"code","83d50cea":"code","4cd7070d":"code","2b7dbed9":"code","fbfb57e0":"code","7344c66a":"code","19c44e3c":"code","da8d86cc":"code","9f7ec604":"code","d6af85fa":"code","b090b2ff":"code","cf2e1a46":"code","adeadbe3":"code","84d5a5ac":"code","c313c589":"code","dc16c0a8":"code","439b9941":"code","c2b979ff":"code","bc68fc70":"code","f6d15476":"code","d0ec1c1c":"code","47e70153":"code","00898a10":"code","0cd667ee":"code","2dedcb07":"code","5ef16c67":"code","fad15a2a":"code","cc9fbc3e":"code","ffe96da2":"code","ac92c33e":"code","1fb1381e":"code","6edf16b7":"code","22999a2d":"code","a154d78c":"code","0771d717":"code","b2cecef7":"code","fcdb42de":"code","f0b73ad1":"code","a35f5162":"code","9a392795":"code","1de84ecb":"code","487f2672":"code","f88bd4c1":"code","921114f2":"markdown","381db46a":"markdown","9a411005":"markdown","3b5c5615":"markdown","c075a201":"markdown","7d284ffe":"markdown","64b1715e":"markdown","5c965cf2":"markdown","4932fb19":"markdown","bb7e16b4":"markdown","8d3b5183":"markdown","29c5eba4":"markdown","7180ef11":"markdown","44446f09":"markdown","5a27df2e":"markdown","dcfc4587":"markdown","c9aee3be":"markdown","ea7e83de":"markdown","21755fa0":"markdown","3be6a6bf":"markdown","7d118c53":"markdown"},"source":{"88ec7fcd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","61a4150b":"df_train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_gender_submission=pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","8b968822":"df_train.head()","788f79b7":"df_train.info()","2f1001f0":"df_train.shape","4af3f72b":"df_train.describe()","9c45a4ee":"df_train['Age'].fillna(df_train['Age'].median(),inplace=True)","7273b588":"df_train['Died'] = 1-df_train['Survived']","6822f73c":"df_train.groupby('Sex').agg('sum')[['Survived','Died']].plot(kind='bar', figsize=(5, 5),\n                                                          stacked=True, color=['b','r']);","6e71e1bb":"df_train.groupby('Sex').agg('mean')[['Survived','Died']].plot(kind='bar', figsize=(5, 5),\n                                                          stacked=True, color=['g','r']);","8bccbedd":"fig = plt.figure(figsize=(5, 5))\nsns.violinplot(x='Sex', y='Age', \n               hue='Survived', data=df_train, \n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );","800c4387":"figure = plt.figure(figsize=(20, 7))\nplt.hist([df_train[df_train['Survived'] == 1]['Fare'], df_train[df_train['Survived'] == 0]['Fare']], \n         stacked=True, color = ['g','r'],\n         bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend();","b37870d9":"plt.figure(figsize=(20, 7))\nax = plt.subplot()\n\nax.scatter(df_train[df_train['Survived'] == 1]['Age'], df_train[df_train['Survived'] == 1]['Fare'], \n           c='green', s=df_train[df_train['Survived'] == 1]['Fare'])\nax.scatter(df_train[df_train['Survived'] == 0]['Age'], df_train[df_train['Survived'] == 0]['Fare'], \n           c='red', s=df_train[df_train['Survived'] == 0]['Fare']);","cdf5e120":"ax = plt.subplot()\nax.set_ylabel('Average fare')\ndf_train.groupby('Pclass').mean()['Fare'].plot(kind='bar', figsize=(20, 7), ax = ax);","ff7b169f":"def merge_train_test_data():\n    # reading train data\n    train = pd.read_csv('..\/input\/titanic\/train.csv')\n    \n    # reading test data\n    test = pd.read_csv('..\/input\/titanic\/test.csv')\n\n    # extracting and then removing the targets from the training data \n    targets = train.Survived\n    train.drop(['Survived'], 1, inplace=True)\n    \n\n    # merging train data and test data for future feature engineering\n    # we'll also remove the PassengerID since this is not an informative feature\n    merged_data_frame = train.append(test)\n    merged_data_frame.reset_index(inplace=True)\n    merged_data_frame.drop(['index', 'PassengerId'], inplace=True, axis=1)\n    \n    return merged_data_frame","ed6cfbb3":"merged_df = merge_train_test_data()","141a98e0":"merged_df.shape","6ade27ef":"merged_df.head()","a0af6649":"merged_df['Name'][1].split(',')[1].strip().split('.')[0].strip()","33260f87":"merged_df['Title'] = merged_df['Name'].map(lambda str_name:str_name.split(',')[1].strip().split('.')[0].strip())","b6508748":"merged_df['Title'].unique()","8fcd5d73":"title_dict={'Mr':'Mr',\n           'Mrs':'Mrs',\n           'Ms':'Mrs',\n           'Mme':'Miss',\n           'Miss':'Miss',\n           'Mlle':'Miss',\n           'Master':'Master',\n            'Col':'Defence_Officer',\n            'Major':'Defence_Officer',\n            'Capt':'Defence_Officer',\n            'Dr':'Dr',\n            'Jonkheer':'Jonkheer',\n            'Don':'Don',\n            'Rev':'Rev',\n            'Lady':'Lady',\n            'Sir':'Sir',\n            'the Countess':'the Countess',\n            'Dona':'Dona'\n           }","4f679134":"merged_df['Title'] = merged_df['Title'].map(title_dict)","ccec383b":"merged_df['Title'].unique()","febd3ce9":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Title'], drop_first=True,prefix='Title')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Title',axis=1,inplace=True)","e6ee7a0b":"merged_df.drop('Name',axis=1,inplace=True)","c6012281":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Pclass'].astype('category'), drop_first=True,prefix='Pclass')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Pclass',axis=1,inplace=True)","83d50cea":"sex_dict = {'male':1,\n           'female':0}\nmerged_df['Sex'] = merged_df['Sex'].map(sex_dict)","4cd7070d":"merged_df['Cabin'] = merged_df['Cabin'].str[0]","2b7dbed9":"merged_df['Cabin'].unique()","fbfb57e0":"merged_df['Cabin'].fillna('U',inplace=True)","7344c66a":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Cabin'], drop_first=True,prefix='Cabin')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Cabin',axis=1,inplace=True)","19c44e3c":"merged_df.groupby('Embarked').count()['Sex']","da8d86cc":"merged_df['Embarked'].isnull().sum()","9f7ec604":"#Replacing the value of Embarked with 'S' based on the frequency\nmerged_df['Embarked'].fillna('S',inplace=True)","d6af85fa":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(merged_df['Embarked'], drop_first=True,prefix='Embarked')\n# Adding the results to the master dataframe\nmerged_df = pd.concat([merged_df, dummy1], axis=1)\nmerged_df.drop('Embarked',axis=1,inplace=True)","b090b2ff":"merged_df['Age'].isnull().sum()","cf2e1a46":"def age_groups(num_age):\n    if num_age>=0 and num_age <=2:\n        return 'infant'\n    elif num_age>=3 and num_age<=15:\n        return 'kids'\n    else:\n        return 'adult'","adeadbe3":"merged_df['age_group']=merged_df['Age'].map(lambda age:age_groups(age))","84d5a5ac":"age_group=merged_df.groupby('age_group').median()['Age'].reset_index()","c313c589":"age_group","dc16c0a8":"age_group[age_group['age_group']=='adult']['Age'][0]","439b9941":"def age(row):\n    if row['age_group']=='adult':\n        return age_group[age_group['age_group']=='adult']['Age'][0]\n    elif row['age_group']=='infant':\n        return age_group[age_group['age_group']=='infant']['Age'][0]\n    else:\n        return age_group[age_group['age_group']=='kids']['Age'][0]","c2b979ff":"merged_df['Age']=merged_df.apply(lambda row: age(row) if np.isnan(row['Age']) else row['Age'], axis=1)","bc68fc70":"merged_df.head()","f6d15476":"merged_df.drop('age_group',axis=1,inplace=True)","d0ec1c1c":"merged_df['traveller_cnt'] = merged_df['SibSp'] + merged_df['Parch']+1","47e70153":"merged_df.drop('Ticket',axis=1,inplace=True)","00898a10":"def get_train_test_target():\n    targets = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Survived'])['Survived'].values\n    train = merged_df.iloc[:891]\n    test = merged_df.iloc[891:]\n    \n    return train, test, targets","0cd667ee":"train, test, targets = get_train_test_target()","2dedcb07":"train.head()","5ef16c67":"test.isnull().sum()","fad15a2a":"test['Fare'].fillna(test['Fare'].mean(),inplace=True)","cc9fbc3e":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nrf = rf.fit(train, targets)","ffe96da2":"features = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = rf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)","ac92c33e":"features.plot(kind='barh', figsize=(25, 25))","1fb1381e":"from sklearn.feature_selection import SelectFromModel\nmodel = SelectFromModel(rf, prefit=True)\ntrain_reduced = model.transform(train)\nprint(train_reduced.shape)","6edf16b7":"test_reduced = model.transform(test)\nprint(test_reduced.shape)","22999a2d":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\n#logreg_cv = LogisticRegressionCV()\nrf = RandomForestClassifier()\n#gboost = GradientBoostingClassifier()\n#models = [logreg, logreg_cv, rf, gboost]\nmodels = [logreg, rf]","a154d78c":"from sklearn.model_selection import cross_val_score\ndef compute_score(rf, X, y, scoring='accuracy'):\n    xval = cross_val_score(rf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)","0771d717":"for model in models:\n    print('Cross-validation of : {0}'.format(model.__class__))\n    score = compute_score(rf=model, X=train_reduced, y=targets, scoring='accuracy')\n    print('CV score = {0}'.format(score))\n    print('****')","b2cecef7":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n# turn run_gs to True if you want to run the gridsearch again.\nrun_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(n_splits=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation,\n                               verbose=1,\n                               n_jobs=-1\n                              )\n\n    grid_search.fit(train, targets)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n    \nelse: \n    parameters = {'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 50, \n                  'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train, targets)","fcdb42de":"test.head()","f0b73ad1":"predictions = model.predict(test)","a35f5162":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(predictions)","9a392795":"y_pred_1.head()","1de84ecb":"# Renaming the column \ny_pred_1= y_pred_1.rename(columns={ 0 : 'Survived'})","487f2672":"df_gender_submission['Survived'] = y_pred_1['Survived'] ","f88bd4c1":"df_gender_submission.head()","921114f2":"### Random Forest","381db46a":"### Visualizations","9a411005":"The size of the circles is proportional to the ticket fare.\n\nOn the x-axis, we have the ages and the y-axis, we consider the ticket fare.\n\nWe can observe different clusters:\n\n1. Large green dots between x=20 and x=45: adults with the largest ticket fares\n2. Small red dots between x=10 and x=45, adults from lower classes on the boat\n3. Small green dots between x=0 and x=7: these are the children that were saved","3b5c5615":"### Name Column","c075a201":"## Data Cleansing ","7d284ffe":"From the above it is clear that\n1. The less number of passengers who are young [age less than 10] are died it means that children travelling were saved first\n2. Passengers whose age between 20-30 are died so it is irrespective of Sex of the passenger","64b1715e":"### Cabin Column","5c965cf2":"Now it is clear from the above that passengers with low fare are less survived","4932fb19":"We can see that there is NULL values in the age. Lets replace NULL values in the age with median value of this column","bb7e16b4":"### SibSp and Parch Columns","8d3b5183":"### Sex Column","29c5eba4":"## Making Final Submisson File","7180ef11":"This plot says that fare for class 1 was highest followed by class 2 and class 3","44446f09":"#### PClass Column","5a27df2e":"### Ticket Column","dcfc4587":"### Embarked Column","c9aee3be":"So it is clear from the above that more females were survided as compare to males. Now let's again visualize this as percentage","ea7e83de":"Lets assign a character U-unassigned for the records which have NULL values","21755fa0":"As the pepople with different age were travelling together lets replace the age as per their age group","3be6a6bf":"### Age Column","7d118c53":"### Getting the Train and Test Dataset"}}