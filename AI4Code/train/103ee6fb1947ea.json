{"cell_type":{"ebf74d9a":"code","9c7fd34e":"code","bc2f65de":"code","9c254ace":"code","1ab1c0c5":"code","bb0361a5":"code","704100e7":"code","eb1cd434":"code","bd1ad05b":"code","7284b7fe":"code","28f4f89b":"code","ca419aca":"code","29b8a059":"code","2621ebaa":"code","3f0d0fb5":"code","4b843d67":"code","773e64e9":"code","d800e516":"code","4248866e":"code","a9859c4b":"code","bda06b13":"code","782cc592":"code","39ebe48e":"code","ff174d9a":"code","1369fb88":"code","18f43198":"code","31b50ec2":"code","c763d05b":"code","07c66df0":"code","c8115fcd":"code","7cd5baf8":"code","48680410":"code","73dae046":"code","81eb9b79":"markdown"},"source":{"ebf74d9a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Data report\nfrom pandas_profiling import ProfileReport\n\n#Splitting+Scaling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n\n#Classifiers\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n#Accuracy score + model selection\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score,r2_score,mean_squared_error,classification_report\nfrom sklearn.model_selection import GridSearchCV,cross_val_score\n\n#Neural Networks\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n#Paramater Hypertuning\nfrom hyperopt import hp, fmin, tpe, Trials,space_eval\nfrom hyperopt.pyll.base import scope\n\n#Warnings\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)\nimport warnings\nwarnings.filterwarnings('ignore')","9c7fd34e":"df=pd.read_csv(\"..\/input\/diabetes-data-set\/diabetes.csv\") #reading data\ndf","bc2f65de":"df.info() #columns type","9c254ace":"report = ProfileReport(df) #detailed data report\ndisplay(report)","1ab1c0c5":"#replace 0 with NaN\ndf['SkinThickness'].replace(0, np.nan,inplace=True)\ndf['BloodPressure'].replace(0, np.nan,inplace=True)\ndf['Insulin'].replace(0, np.nan,inplace=True)\ndf['Glucose'].replace(0, np.nan,inplace=True)\ndf['BMI'].replace(0, np.nan,inplace=True)\n","bb0361a5":"for col in df.columns: #fill misssing vlaues according to outcome\n    df.loc[(df[\"Outcome\"]==0) & (df[col].isnull()),col] = df[df[\"Outcome\"]==0][col].median()\n    df.loc[(df[\"Outcome\"]==1) & (df[col].isnull()),col] = df[df[\"Outcome\"]==1][col].median()","704100e7":"#change numeric data to categorical\ndf['Glucose'] = pd.cut(x=df['Glucose'], bins=[0,139,200,1000],labels = [1,2,3]) \ndf['BMI'] = pd.cut(x=df['BMI'], bins=[0,18.5,24.9,29.9,100],labels = [1,2,3,4])\ndf['BloodPressure'] = pd.cut(x=df['BloodPressure'], bins=[0,79,89,119,500],labels = [1,2,3,4])\n","eb1cd434":"X=df.drop(\"Outcome\",axis=1) #dropping target value\ny=df[[\"Outcome\"]] #keeping target value\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25) #splitting data\n\nscaler=StandardScaler() #scale data\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","bd1ad05b":"#RandomForestClassifier\nrandomforest_classifier=RandomForestClassifier()\nrandomforest_classifier.fit(X_train,y_train)\npred=randomforest_classifier.predict(X_test)\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_randomforest = model_selection.cross_validate(estimator=randomforest_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_randomforest = model_selection.cross_validate(estimator=randomforest_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_randomforest['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_randomforest['test_score'].mean()*100)","7284b7fe":"#LogisticRegressor\nlogistic_regressor = LogisticRegression() #initialising logistic regression\nlogistic_regressor.fit(X_train,y_train) #fitting the data\ny_pred = logistic_regressor.predict(X_test) #predict the result\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_logistic_regressor = model_selection.cross_validate(estimator=logistic_regressor , X=X_train , y= y_train , cv = 10)\ntest_accuracy_logistic_regressor = model_selection.cross_validate(estimator=logistic_regressor , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_logistic_regressor['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_logistic_regressor['test_score'].mean()*100)","28f4f89b":"#KNeighborsClassifier\nkneighbors_classifier = KNeighborsClassifier() #initialising the kneighbors algorithm\nkneighbors_classifier.fit(X_train, y_train) #fitting the data\n\nprint(\"Accuracy with cross validation\")\ntrain_accuracy_kneighbors = model_selection.cross_validate(estimator=kneighbors_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_kneighbors = model_selection.cross_validate(estimator=kneighbors_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_kneighbors['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_kneighbors['test_score'].mean()*100)","ca419aca":"#GNB Classifier\ngnb_classifier=GaussianNB()\ngnb_classifier.fit(X_train , y_train)\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_gnb = model_selection.cross_validate(estimator=gnb_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_gnb = model_selection.cross_validate(estimator=gnb_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_gnb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_gnb['test_score'].mean()*100)","29b8a059":"#SVC Classifier\nsvc_classfier=SVC()\ntrain_accuracy_svc = model_selection.cross_validate(estimator=svc_classfier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_svc = model_selection.cross_validate(estimator=svc_classfier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_svc['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_svc['test_score'].mean()*100)","2621ebaa":"#XGB Classifier\nxgb_classifier = XGBClassifier()\nxgb_classifier.fit(X_train , y_train)\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_xgb = model_selection.cross_validate(estimator=xgb_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_xgb = model_selection.cross_validate(estimator=xgb_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_xgb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_xgb['test_score'].mean()*100)","3f0d0fb5":"#LGBM Classifier\nlgbm_classifier =LGBMClassifier()\nlgbm_classifier.fit(X_train , y_train)\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_lgbm = model_selection.cross_validate(estimator=lgbm_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_lgbm = model_selection.cross_validate(estimator=lgbm_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_lgbm['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_lgbm['test_score'].mean()*100)","4b843d67":"ann_classifier=tf.keras.models.Sequential()\nann_classifier.add(tf.keras.layers.Dense(units = 32 , activation='relu')) \nann_classifier.add(tf.keras.layers.Dense(units = 1 , activation='sigmoid'))\nann_classifier.compile(optimizer='adam', loss='binary_crossentropy' , metrics= ['accuracy'] )\n\nearly_stopping = EarlyStopping(\n  monitor='accuracy', min_delta=0.0001,\n  patience=20,restore_best_weights=True)\nann_classifier.fit(X_train , y_train, batch_size= 32 , epochs= 2000,callbacks=[early_stopping])","773e64e9":"score, acc = ann_classifier.evaluate(X_train, y_train)\nprint(acc)","d800e516":"prediction=ann_classifier.predict(X_test)\n","4248866e":"score, acc = ann_classifier.evaluate(X_test, y_test)\nprint(acc)","a9859c4b":"prediction = (prediction > 0.5).astype(int)\nflat_list = []\nfor sublist in prediction:\n    for item in sublist:\n        flat_list.append(item)","bda06b13":"prediction = flat_list\nprint(\"Testing accuracy\",round(accuracy_score(prediction,y_test)*100, 2))","782cc592":"d={\"RandomForest\":[train_accuracy_randomforest['test_score'].mean()*100],\n    \"Logistic Regressor\":[train_accuracy_logistic_regressor['test_score'].mean()*100],\n    \"KNeighbors\":[train_accuracy_kneighbors['test_score'].mean()*100],\n    \"GaussianNB\":[train_accuracy_gnb['test_score'].mean()*100],\n    \"SVC\":[train_accuracy_svc['test_score'].mean()*100],\n    \"XGB\":[train_accuracy_xgb['test_score'].mean()*100],\n    \"LGBM\":[train_accuracy_xgb['test_score'].mean()*100],\n    \"ANN\":[acc]}\nbaselinedf= pd.DataFrame(data=d)\nbaselinedf","39ebe48e":"param_grid = {\n    'max_depth': [10, 50,100],\n    'n_estimators': [200, 400]}\nclf_lr = GridSearchCV(randomforest_classifier, param_grid = param_grid, cv = 5)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\ntrain_accuracy_randomforest = model_selection.cross_validate(estimator=best_clf_lr , X=X_train , y= y_train , cv = 5)\ntest_accuracy_randomforest = model_selection.cross_validate(estimator=best_clf_lr , X=X_test , y= y_test , cv = 5)\nprint(\"Training accuracy:\",train_accuracy_randomforest['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_randomforest['test_score'].mean()*100)","ff174d9a":"param_grid = {'max_iter' : [100, 1000,2500, 5000],\n              'penalty' : ['l1', 'l2'],\n              'C' : np.logspace(-4, 4, 20),\n              'solver' : ['lbfgs','newton-cg','liblinear','sag','saga']}\n\n\nclf_lr = GridSearchCV(logistic_regressor, param_grid = param_grid, cv = 5)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\ntrain_accuracy_logistic_regressor = model_selection.cross_validate(estimator=best_clf_lr , X=X_train , y= y_train , cv = 5)\ntest_accuracy_logistic_regressor = model_selection.cross_validate(estimator=best_clf_lr , X=X_test , y= y_test , cv = 5)\nprint(\"Training accuracy:\",train_accuracy_xgb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_xgb['test_score'].mean()*100)","1369fb88":"param_grid = {'n_neighbors':[5,6,7,8,9,10,12,15,17,20,23,25,27,30],\n          'leaf_size':range(1,10,2),\n\n          }\n\nclf_lr = GridSearchCV(kneighbors_classifier, param_grid = param_grid, cv = 5)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\ntrain_accuracy_kneighbors = model_selection.cross_validate(estimator=best_clf_lr , X=X_train , y= y_train , cv = 5)\ntest_accuracy_kneighbors  = model_selection.cross_validate(estimator=best_clf_lr , X=X_test , y= y_test , cv = 5)\nprint(\"Training accuracy:\",train_accuracy_kneighbors['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_kneighbors['test_score'].mean()*100)","18f43198":"param_grid={'var_smoothing': np.logspace(0,-9, num=100)}\nclf_lr = GridSearchCV(gnb_classifier, param_grid = param_grid, cv = 5)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\ntrain_accuracy_gnb = model_selection.cross_validate(estimator=best_clf_lr , X=X_train , y= y_train , cv = 5)\ntest_accuracy_gnb  = model_selection.cross_validate(estimator=best_clf_lr , X=X_test , y= y_test , cv = 5)\nprint(\"Training accuracy:\",train_accuracy_gnb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_gnb['test_score'].mean()*100)","31b50ec2":"param_grid = {'C': [0.001, 0.01, 0.1, 1,1.5,2,2.5,3,4,5, 10], 'gamma' : [0.0001,0.001, 0.01, 0.1, 1]}\nclf_lr = GridSearchCV(svc_classfier, param_grid = param_grid, cv = 5)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\ntrain_accuracy_svc = model_selection.cross_validate(estimator=best_clf_lr , X=X_train , y= y_train , cv = 5)\ntest_accuracy_svc  = model_selection.cross_validate(estimator=best_clf_lr , X=X_test , y= y_test , cv = 5)\nprint(\"Training accuracy:\",train_accuracy_svc['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_svc['test_score'].mean()*100)","c763d05b":"def hyperopt_xgb_score(params):\n    clf = XGBClassifier(verbosity = 0,**params)\n    current_score = cross_val_score(clf, X_train,y_train, cv=10).mean()\n    print(current_score, params)\n    return current_score \n\nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0.2,0.5,0.05),\n            'n_estimators': hp.choice('n_estimators', range(50, 400)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.001),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 5, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            \n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=50)\nprint('best:')\nprint(best)","07c66df0":"params = space_eval(space_xgb, best)\nprint(params)","c8115fcd":"XGB_classifier = XGBClassifier(**params)\nXGB_classifier.fit(X_train, y_train)\nprint(X_test)\npred = XGB_classifier.predict(X_test)\nprint(pred)\ntrain_accuracy_xgb = model_selection.cross_validate(estimator=XGB_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_xgb = model_selection.cross_validate(estimator=XGB_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_xgb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_xgb['test_score'].mean()*100) ","7cd5baf8":"def hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, X_train, y_train, cv=5).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)","48680410":"params = space_eval(space_lgb, best)\nparams","73dae046":"LGBM_classifier = LGBMClassifier(**params)\nLGBM_classifier.fit(X_train, y_train)\npred =  LGBM_classifier.predict(X_test)\ntest_accuracy_lgbm = model_selection.cross_validate(estimator=LGBM_classifier , X=X_test , y= y_test , cv = 5)\nprint(\"Testing accuracy:\",test_accuracy_lgbm['test_score'].mean()*100) ","81eb9b79":"<h3><center>Model Building (Baseline Validation Performance)<\/center><\/h3>"}}