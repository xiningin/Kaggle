{"cell_type":{"05b18542":"code","85d0b6de":"code","976cb485":"code","95381bba":"code","97ba28a8":"code","9e820373":"code","00b32ceb":"code","4f2346ce":"code","eddf6961":"code","2b99d812":"code","a280676c":"code","451c5179":"code","1cc9175c":"code","757036c0":"code","92faf921":"code","c8f13010":"code","fc07bc78":"code","250ccd6a":"code","ca7428b0":"code","0cf4945a":"code","5f658c44":"code","604899d9":"code","dbc445f3":"code","e694cd9a":"code","347e61c0":"code","1485aa09":"code","254c6aad":"code","3e9df375":"code","7128c44a":"code","2451a5c7":"code","5d63d3cf":"code","665d2116":"code","a14a205f":"code","057ea48b":"code","391dfdec":"code","dd31ce95":"markdown","33510c74":"markdown","90489ef7":"markdown","8e4d2d49":"markdown","2523a379":"markdown","9c3f6b75":"markdown","9b755d2b":"markdown","b8753afc":"markdown","c07f627a":"markdown","598e6b91":"markdown","0c09b3c8":"markdown","ea37181c":"markdown","88cfb5ab":"markdown","68c1c82d":"markdown","37ec24c6":"markdown","c18ca3d4":"markdown"},"source":{"05b18542":"import sklearn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfrom PIL import  Image\n%matplotlib inline\nimport itertools\nimport io\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization","85d0b6de":"dataset = pd.read_csv('..\/input\/weatherAUS.csv')","976cb485":"dataset.head()","95381bba":"dataset.info()","97ba28a8":"dataset.apply(lambda column: sum(column.isnull()))","9e820373":"dataset = dataset.dropna()","00b32ceb":"dataset.apply(lambda column: sum(column.isnull()))","4f2346ce":"dataset['Date'] = pd.to_datetime(dataset['Date'])","eddf6961":"dataset['Year'] = dataset['Date'].dt.year","2b99d812":"dataset['Month'] = dataset['Date'].dt.month","a280676c":"dataset['Day'] = dataset['Date'].dt.day","451c5179":"dataset.head()","1cc9175c":"#change object to numeric dtype\ndataset[\"Date\"] = pd.to_numeric(dataset[\"Date\"])\n\n#Separating rain and non rain customers\nrain     = dataset[dataset[\"RainTomorrow\"] == \"Yes\"]\nnot_rain = dataset[dataset[\"RainTomorrow\"] == \"No\"]\n\n#Separating columns\nId_col     = ['Date']\ntarget_col = [\"RainTomorrow\"]\ncat_cols   = dataset.nunique()[dataset.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in dataset.columns if x not in cat_cols + target_col + Id_col]","757036c0":"dataset.info()","92faf921":"#labels\nlab = dataset[\"RainTomorrow\"].value_counts().keys().tolist()\n#values\nval = dataset[\"RainTomorrow\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Rain Tomorrow data\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)","c8f13010":"#function  for pie plot for rain tomorrow attrition types\ndef plot_pie(column) :\n    \n    trace1 = go.Pie(values  = rain[column].value_counts().values.tolist(),\n                    labels  = rain[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Rain Tomorrow\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    hole    = .6\n                   )\n    trace2 = go.Pie(values  = not_rain[column].value_counts().values.tolist(),\n                    labels  = not_rain[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"Non Rain Tomorrow\" \n                   )\n\n\n    layout = go.Layout(dict(title = column + \" distribution in Rain Tomorrow  \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"Rain Tomorrow\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5),\n                                           dict(text = \"Non Rain Tomorrow\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .88,y = .5\n                                               )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)\n\n\n#function  for histogram for rain tomorrow  attrition types\ndef histogram(column) :\n    trace1 = go.Histogram(x  = rain[column],\n                          histnorm= \"percent\",\n                          name = \"Rain Tomorrow\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 \n                         ) \n    \n    trace2 = go.Histogram(x  = not_rain[column],\n                          histnorm = \"percent\",\n                          name = \"Non Rain Tomorrow\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in Rain Tomorrow \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"percent\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n    fig  = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n\n#for all categorical columns plot pie\nfor i in cat_cols :\n    plot_pie(i)\n\n#for all categorical columns plot histogram    \nfor i in num_cols :\n    histogram(i)\n","fc07bc78":"dataset.nunique()","250ccd6a":"dataset = dataset[['MinTemp', 'MaxTemp', 'Evaporation',\n        'Sunshine', 'WindGustSpeed','WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n       'Temp3pm', 'RainTomorrow']].reset_index(drop=True)\n\n## change the data\n## Risk_MM\n\n## object \n## Date, Location, WindGustDir(object) , WindDir9am(object) , WindDir3pm(object), Year, Month, Day ","ca7428b0":"dataset.head()","0cf4945a":"weather = dataset","5f658c44":"weather.RainTomorrow.replace(('Yes', 'No'), (1, 0), inplace=True)","604899d9":"weather.head()","dbc445f3":"weather_of_AUS = len(weather)\nnumber_of_rain = len(weather[weather['RainTomorrow'] == 1])\nnumber_of_no_rain = len(weather[weather['RainTomorrow'] == 0])\nprint('Number of Weater in AUS', weather_of_AUS)\nprint('Number of rain :%d (%.2f %%)' % (number_of_rain,number_of_rain\/weather_of_AUS*100))\nprint('Number of no rain :%d (%.2f %%)' % (number_of_no_rain,number_of_no_rain\/weather_of_AUS*100))","e694cd9a":"#correlation\ncorrelation = weather.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Viridis\",\n                   colorbar   = dict(title = \"Pearson Correlation coefficient\",\n                                     titleside = \"right\"\n                                    ) ,\n                  )\n\nlayout = go.Layout(dict(title = \"Correlation Matrix for variables\",\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                      ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9))\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","347e61c0":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold\n#splitting train and test data \ntrain,test = train_test_split(weather,test_size = .25 ,random_state = 111)\n    \n##seperating dependent and independent variables\ncols    = [i for i in weather.columns if i not in Id_col + target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X  = test[cols]\ntest_Y  = test[target_col]\n\n#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\n    \ndef weather_rain_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Not Rain\",\"Rain\"],\n                        y = [\"Not Rain\",\"Rain\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n        \nlogit  = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nweather_rain_prediction(logit,train_X,test_X,train_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n\n","1485aa09":"print(train_X.shape,test_X.shape)","254c6aad":"from imblearn.over_sampling import SMOTE\n\ncols    = [i for i in weather.columns if i not in Id_col+target_col]\n\nsmote_X = weather[cols]\nsmote_Y = weather[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n###\n\n\n\nlogit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nweather_rain_prediction(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n","3e9df375":"print(os_smote_X.shape,os_smote_Y.shape)\nprint(test_X.shape,test_Y.shape)","7128c44a":"def weather_rain_prediction_alg(algorithm,training_x,testing_x,\n                                 training_y,testing_y,threshold_plot = True) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy Score   : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n     \n    #plot roc curve\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix ,x = [\"Not Rain\",\"Rain\"],\n                        y = [\"Not Rain\",\"Rain\"],\n                        showscale  = False,colorscale = \"Blues\",name = \"matrix\",\n                        xaxis = \"x2\",yaxis = \"y2\"\n                       )\n    \n    layout = go.Layout(dict(title=\"Model performance\" ,\n                            autosize = False,height = 500,width = 800,\n                            showlegend = False,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(title = \"false positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         domain=[0, 0.6],\n                                         ticklen=5,gridwidth=2),\n                            yaxis = dict(title = \"true positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         zerolinewidth=1,\n                                         ticklen=5,gridwidth=2),\n                            margin = dict(b=200),\n                            xaxis2=dict(domain=[0.7, 1],tickangle = 90,\n                                        gridcolor = 'rgb(255, 255, 255)'),\n                            yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                           )\n                  )\n    data = [trace1,trace2,trace3]\n    fig = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n\n    \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\nweather_rain_prediction_alg(knn,os_smote_X,test_X,\n                             os_smote_Y,test_Y,threshold_plot = True)","2451a5c7":"from sklearn.ensemble import RandomForestClassifier\n\n#function attributes\n#columns  - column used\n#nf_estimators   - The number of trees in the forest.\n#estimated_tree  - tree number to be displayed\n#maximum_depth   - depth of the tree\n#criterion_type  - split criterion type [\"gini\" or \"entropy\"]\n#Model performance - prints performance of model\n\ndef randomforest(cols,nf_estimators,\n                           estimated_tree,maximum_depth,\n                           criterion_type,model_performance = None) :\n    \n    dataframe = weather[cols + target_col].copy()\n    \n    #train and test datasets\n    rf_x     = dataframe[[i for i in cols if i not in target_col]]\n    rf_y     = dataframe[target_col]\n    \n    #random forest classifier\n    rfc   = RandomForestClassifier(n_estimators = nf_estimators,\n                                   max_depth = maximum_depth,\n                                   criterion = criterion_type,\n                                  )\n    rfc.fit(rf_x,rf_y)\n    \n    #model performance\n    if model_performance == True :\n        weather_rain_prediction(rfc,\n                                 rf_x,test_X,\n                                 rf_y,test_Y,\n                                 cols,\"features\",threshold_plot = True)\n        \n\ncols1 = [ i for i in train_X if i not in target_col + Id_col] \nrandomforest(cols1,100,99,3,\"entropy\",True)","5d63d3cf":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n#gives model report in dataframe\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    roc_auc      = roc_auc_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    kappa_metric = cohen_kappa_score(testing_y,predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"Area_under_curve\": [roc_auc],\n                      })\n    return df\n\n#outputs for every model\nmodel1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n                      \"LogReg(Baseline)\")\nmodel2 = model_report(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"LogReg(SMOTE)\")\nmodel3 = model_report(knn,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"KNN Classifier\")\nrfc = RandomForestClassifier(n_estimators = 1000,\n                             random_state = 123,\n                             max_depth = 9,\n                             criterion = \"gini\")\nmodel4 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n                      \"Random Forest\")\n\n#concat all models\nmodel_performances = pd.concat([model1,model2,model3,model4],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","665d2116":"model_performances\ndef output_tracer(metric,color) :\n    tracer = go.Bar(y = model_performances[\"Model\"] ,\n                    x = model_performances[metric],\n                    orientation = \"h\",name = metric ,\n                    marker = dict(line = dict(width =.7),\n                                  color = color)\n                   )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Model performances\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\n\n\ntrace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\ntrace2  = output_tracer('Recall_score',\"red\")\ntrace3  = output_tracer('Precision',\"#33CC99\")\ntrace4  = output_tracer('f1_score',\"lightgrey\")\n\ndata = [trace1,trace2,trace3,trace4]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","a14a205f":"lst    = [logit,logit_smote,knn,rfc]\n\nlength = len(lst)\n\nmods   = ['LogReg (Baseline_model)','LogReg (SMOTE)','KNN Classifier','Random Forest']\n\nfig = plt.figure(figsize=(13,15))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    plt.subplot(4,3,j+1)\n    predictions = i.predict(test_X)\n    conf_matrix = confusion_matrix(predictions,test_Y)\n    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n                xticklabels=[\"not rain\",\"rain\"],\n                yticklabels=[\"not rain\",\"rain\"],\n                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n    plt.title(k,color = \"b\")\n    plt.subplots_adjust(wspace = .3,hspace = .3)","057ea48b":"lst    = [logit,logit_smote,knn,rfc]\n\nlength = len(lst)\n\nmods   = ['LogReg (Baseline_model)','LogReg (SMOTE)','KNN Classifier','Random Forest']\n\nplt.style.use(\"dark_background\")\nfig = plt.figure(figsize=(12,16))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    fpr,tpr,thresholds = roc_curve(test_Y,probabilities[:,1])\n    plt.plot(fpr,tpr,linestyle = \"dotted\",\n             color = \"royalblue\",linewidth = 2,\n             label = \"AUC = \" + str(np.around(roc_auc_score(test_Y,predictions),3)))\n    plt.plot([0,1],[0,1],linestyle = \"dashed\",\n             color = \"orangered\",linewidth = 1.5)\n    plt.fill_between(fpr,tpr,alpha = .4)\n    plt.fill_between([0,1],[0,1],color = \"k\")\n    plt.legend(loc = \"lower right\",\n               prop = {\"size\" : 12})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xticks(np.arange(0,1,.3))\n    plt.yticks(np.arange(0,1,.3))","391dfdec":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\nlst    = [logit,logit_smote,knn,rfc]\n\nlength = len(lst)\n\nmods   = ['LogReg (Baseline_model)','LogReg (SMOTE)','KNN Classifier','Random Forest']\n\n\nfig = plt.figure(figsize=(13,17))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    \n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    recall,precision,thresholds = precision_recall_curve(test_Y,probabilities[:,1])\n    plt.plot(recall,precision,linewidth = 1.5,\n             label = (\"avg_pcn : \" + \n                      str(np.around(average_precision_score(test_Y,predictions),3))))\n    plt.plot([0,1],[0,0],linestyle = \"dashed\")\n    plt.fill_between(recall,precision,alpha = .2)\n    plt.legend(loc = \"lower left\",\n               prop = {\"size\" : 10})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xlabel(\"recall\",fontsize =7)\n    plt.ylabel(\"precision\",fontsize =7)\n    plt.xlim([0.25,1])\n    plt.yticks(np.arange(0,1,.3))\n    ","dd31ce95":"## Correlation Matrix","33510c74":"## Resampling using SMOTE","90489ef7":"## Baseline model","8e4d2d49":"## Model Performance","2523a379":"## Remove Null","9c3f6b75":"## Import Modul","9b755d2b":"## Compare Model","b8753afc":"## Random Forest","c07f627a":"## Precision recall curves","598e6b91":"## KNN","0c09b3c8":"## Confusion matrices for models","ea37181c":"## ROC - Curves for models","88cfb5ab":"## EDA","68c1c82d":"**## Change Column RainTomorrow to Number ","37ec24c6":"## PREDICTION RAIN TOMORROW","c18ca3d4":"## Change Datetime"}}