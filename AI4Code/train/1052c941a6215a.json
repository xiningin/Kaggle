{"cell_type":{"e65d7457":"code","de3f2d6d":"code","176bf333":"code","29e8dd2d":"code","3300f473":"code","9149f279":"code","fa93dc0d":"code","d7afc992":"code","47bcedc8":"code","411370a8":"code","87931d8b":"code","fffbcb14":"code","51f5545a":"code","2e16edeb":"code","0d8bbdde":"code","3d86abb7":"markdown","caf68a79":"markdown","eae7b7d7":"markdown","425982c7":"markdown","174873e2":"markdown","4b7462b0":"markdown","0e5c6a7f":"markdown","e51246c1":"markdown","cab4802f":"markdown","ac448fbc":"markdown"},"source":{"e65d7457":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.ensemble import GradientBoostingRegressor","de3f2d6d":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","176bf333":"train.head()","29e8dd2d":"train.describe()","3300f473":"train['SalePrice'].describe()","9149f279":"HIST_BINS = np.linspace(-4, 4, 100)\ndef prepare_animation(bar_container):\n\n    def animate(frame_number):\n        # simulate new data coming in\n        data = np.random.randn(1000)\n        n, _ = np.histogram(data, HIST_BINS)\n        for count, rect in zip(n, bar_container.patches):\n            rect.set_height(count)\n        return bar_container.patches\n    return animate\n\n\nfig, ax = plt.subplots()\n_, _, bar_container = ax.hist(train['SalePrice'], HIST_BINS, lw=1,\n                              ec=\"yellow\", fc=\"green\", alpha=0.5)\nax.set_ylim(top=55)\n\nani = animation.FuncAnimation(fig, prepare_animation(bar_container), 50,\n                              repeat=False, blit=True)\nplt.show()","fa93dc0d":"del train['Alley']\ntrain.info()","d7afc992":"train.columns","47bcedc8":"train.isnull().sum()","411370a8":"#Ignoring content types\nfor label, content in train.items():\n    if pd.api.types.is_string_dtype(content):\n        del train[label]\n","87931d8b":"for label, content in train.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            train[label+ '_is_missing'] = pd.isnull(content)\n            train[label] = content.fillna(content.median())","fffbcb14":"train.isnull().sum()","51f5545a":"del train['Id']\nX = (train.drop('SalePrice', axis=1)).values\ny = (train['SalePrice']).values\n\nscore = []\nrs = ShuffleSplit(n_splits=10, test_size=.25, random_state=0)\nfor train_index, test_index in rs.split(X, y):\n    x_train, x_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    model = GradientBoostingRegressor(loss='ls',\n                                      learning_rate=0.025,\n                                      n_estimators=100,\n                                      max_depth=10)\n\n    model.fit(x_train, y_train)\n    score.append(model.score(x_test, y_test))","2e16edeb":"plt.plot(score)","0d8bbdde":"np.mean(score)","3d86abb7":"### 2.1.1 Overl informaion of the input","caf68a79":"# 3. Model training","eae7b7d7":"## 2.3.Dealing with noncategorical and missing values","425982c7":"# 2.Data preparation","174873e2":"# Table of contents\n\n* **1. Importing libraries**\n* **2. Data preparation**\n    * 2.1 Checking dataset\n        * 2.1.1 Overl informaion of the input\n        * 2.1.2 Target distribution\n    * 2.2.checking for missing values\n    * 2.3.Dealing with noncategorical and missing values\n* **3. Model training**","4b7462b0":"## 1.Importing libraries","0e5c6a7f":"#### Check if we still have a null value!","e51246c1":"## 2.2.checking for missing values","cab4802f":"### 2.1.2 Target distribution","ac448fbc":"## 2.1. Checking dataset"}}