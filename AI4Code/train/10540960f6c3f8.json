{"cell_type":{"44802693":"code","32f2db94":"code","5879ed6e":"code","97a81df9":"code","7031e3a8":"code","1d7563b9":"code","0f86a149":"code","b056c938":"code","662abb60":"code","287ea7d1":"code","edeecdf1":"code","d27d55a9":"code","5daf9485":"code","3aca3767":"code","251281e9":"code","22f88d51":"code","a2611d67":"code","8bcd5470":"code","f231dd2a":"code","f220b61b":"code","78f2c495":"code","f208e976":"code","3751a060":"code","501896e0":"code","b3fd0cd6":"code","2abeecaa":"code","36139ee0":"code","d3a0a5ac":"code","1e72edb6":"code","4e3680d2":"code","01e504b0":"markdown","07359e5c":"markdown","ce4566a2":"markdown","daa03530":"markdown","21b67d3e":"markdown","e407ada5":"markdown","98d7d71d":"markdown","50881e9d":"markdown","67d29a90":"markdown","768f1eff":"markdown","4f494e45":"markdown","bf93f229":"markdown","5005d803":"markdown","bd18ed2d":"markdown","46bbb6bf":"markdown","52f3e3b8":"markdown","97a132d0":"markdown","a7a05fd1":"markdown","edcdd40a":"markdown","e7cf1d82":"markdown","c671040a":"markdown","b20b3ca8":"markdown"},"source":{"44802693":"%%capture\nimport os\nfor dirname, _, filename in os.walk(\"..\/input\"):\n  for files in filename:\n    print(os.path.join(dirname, files))","32f2db94":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n%matplotlib inline\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm","5879ed6e":"train_data = pd.DataFrame(pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/train.csv\"))\ntest_data = pd.DataFrame(pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/test.csv\"))","97a81df9":"print(\"Training data shape : = {}\".format(train_data.shape))\nprint(\"Test data shape : = {}\".format(test_data.shape))","7031e3a8":"test_data.head()","1d7563b9":"image_folder_path = \"..\/input\/plant-pathology-2020-fgvc7\/images\/\"","0f86a149":"arr = train_data[\"image_id\"]\ntrain_images = [i for i in arr]  \n\narr = test_data[\"image_id\"]\ntest_images = [i for i in arr]","b056c938":"def load_image(image_id) : \n  image_path = image_folder_path +image_id +\".jpg\"\n  image = cv2.imread(image_path) \n  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  return image\n\ndef resize(image):\n  image = cv2.resize(image, (800, 800))\n  return image","662abb60":"def extract_classes(s):\n  \"\"\"\n  s can be either of the four classes mentioned above.\n  \"\"\" \n  t = train_data[train_data[s] == 1] \n  arr = t[\"image_id\"]\n  images = [i for i in tqdm(arr)]\n  train_images = [load_image(i) for i in tqdm(images)]\n  return train_images\n\nclasses = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"] ","287ea7d1":"count_healthy = len(train_data[train_data[\"healthy\"] == 1])\ncount_diseased = len(train_data[train_data[\"multiple_diseases\"] == 1])\ncount_rust = len(train_data[train_data[\"rust\"] == 1])\ncount_scab = len(train_data[train_data[\"scab\"] == 1])\n\nprint(count_healthy)\nprint(count_diseased)\nprint(count_rust)\nprint(count_scab)\nprint(count_healthy + count_diseased + count_rust +  count_scab)","edeecdf1":"# observe number of cases present in each class\nlabels = [\"Healthy\", \"Multiple Diseased\", \"Rust\", \"Scab\"]\ncounts = [count_healthy, count_diseased, count_rust, count_scab]\nexplode = (0.05, 0.05, 0.05, 0.05)\nfig, ax = plt.subplots(figsize = (20, 12))\nax.pie(counts, explode = explode, labels = labels, shadow = True, startangle = 90)\nax.axis(\"equal\") # equal aspect ratio ensures pie graph is drawn as circle","d27d55a9":"red , green, blue = [], [], []","5daf9485":"healthy = extract_classes(\"healthy\")\nfor image in healthy :\n    mean_red = np.mean(image[:,:,0])\n    mean_green = np.mean(image[:,:,1])\n    mean_blue = np.mean(image[:,:,2])\n    \n    red.append(mean_red)\n    green.append(mean_green)\n    blue.append(mean_blue)\n    \nhealthy_image_1 = healthy[100]\nhealthy_image_2 = healthy[200]\nhealthy_image_3 = healthy[300]\ndel healthy # free memory\n\nmd = extract_classes(\"multiple_diseases\")\nfor image in md : \n    mean_red = np.mean(image[:,:,0])\n    mean_green = np.mean(image[:,:,1])\n    mean_blue = np.mean(image[:,:,2])\n    \n    red.append(mean_red)\n    green.append(mean_green)\n    blue.append(mean_blue)\nmd_image_1 = md[1]\nmd_image_2 = md[5]\nmd_image_3 = md[10]\ndel md # free memory\n\nrust = extract_classes(\"rust\")\nfor image in rust : \n    mean_red = np.mean(image[:,:,0])\n    mean_green = np.mean(image[:,:,1])\n    mean_blue = np.mean(image[:,:,2])\n    \n    red.append(mean_red)\n    green.append(mean_green)\n    blue.append(mean_blue)\nrust_image_1 = rust[10]\nrust_image_2 = rust[20] \nrust_image_3 = rust[30]\ndel rust # free memory\n\nscab = extract_classes(\"healthy\")\nfor image in scab : \n    mean_red = np.mean(image[:,:,0])\n    mean_green = np.mean(image[:,:,1])\n    mean_blue = np.mean(image[:,:,2])\n    \n    red.append(mean_red)\n    green.append(mean_green)\n    blue.append(mean_blue)\nscab_image_1 = scab[10]\nscab_image_2 = scab[20]\nscab_image_3 = scab[30] \ndel scab # free memory\n\nimage_collection = [healthy_image_1, healthy_image_2, healthy_image_3, \n                   md_image_1, md_image_2, md_image_3,\n                   rust_image_1, rust_image_2, rust_image_3,\n                   scab_image_1, scab_image_2, scab_image_3]   ","3aca3767":"fig, ax = plt.subplots(nrows = 4, ncols = 3, figsize = (25, 15))\nfor i in range(12):\n    ax[i\/\/3, i%3].imshow(image_collection[i]) ","251281e9":"# red channel plot\nrange_of_spread = max(red) - min(red)\nplt.figure(figsize = (12, 8))\nplt.rc('font', weight='bold')\nsns.set_style(\"whitegrid\")\nfig = sns.distplot(red,  hist = True, kde = True, label = \"Red Channel intensities\", color = \"r\")\nfig.set(xlabel = \"Mean red channel intensities observed in each image (Sample size = 1000)\", ylabel = \"Probability Density\")\nplt.legend()\nprint(\"The range of spread = {:.2f}\".format(range_of_spread))","22f88d51":"# Green channel plot\nrange_of_spread = max(green) - min(green)\nplt.figure(figsize = (12, 8))\nplt.rc('font', weight='bold')\nsns.set_style(\"whitegrid\")\nfig = sns.distplot(green,  hist = True, kde = True, label = \"Green Channel intensities\", color = \"g\")\nfig.set(xlabel = \"Mean green channel intensities observed in each image (Sample size = 1000)\", ylabel = \"Probability Density\")\nplt.legend()\nprint(\"The range of spread = {:.2f}\".format(range_of_spread))","a2611d67":"# Blue channel plot\nrange_of_spread = max(blue) - min(blue)\nplt.figure(figsize = (12, 8))\nplt.rc('font', weight='bold')\nsns.set_style(\"whitegrid\")\nfig = sns.distplot(blue,  hist = True, kde = True, rug = False, label = \"Blue Channel intensities\", color = \"b\")\nfig.set(xlabel = \"Mean blue channel intensities observed in each image (Sample size = 1000)\", ylabel = \"Probability Density\")\nplt.legend()\nprint(\"The range of spread = {:.2f}\".format(range_of_spread))","8bcd5470":"sample_image = rust_image_1\nplt.figure(figsize = (12, 8))\nplt.imshow(sample_image)","f231dd2a":"def non_local_means_denoising(image) : \n    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n    return denoised_image","f220b61b":"denoised_image = non_local_means_denoising(sample_image)\n\nplt.figure(figsize = (12, 8))\nplt.subplot(1,2,1)\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Normal Image\")\n\nplt.subplot(1,2,2)  \nplt.imshow(denoised_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Denoised image\")    \n# Automatically adjust subplot parameters to give specified padding.\nplt.tight_layout()","78f2c495":"def sobel_edge_detection(image):\n  \"\"\"\n  Using Sobel filter\n\n  Sobel filter takes the following arguments : \n  1. Original Image\n  2. Depth of the destination image\n  3. Order of derivative x\n  4. Order of derivative y\n  5. Kernel size for convolutions\n\n  f(Image, depth, order_dx, order_dy, kernel_size) \n  \"\"\"\n  sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = 5)\n  sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = 5)\n  return sobel_x, sobel_y","f208e976":"s_img_x, s_img_y = sobel_edge_detection(denoised_image)\n\nplt.figure(figsize = (12, 8))\nplt.subplot(2,2,1)\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sample Image\")\n\nplt.subplot(2,2,2)\nplt.imshow(denoised_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Denoised Image\")\n\nplt.subplot(2,2,3)\nplt.imshow(s_img_x, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sobel X filtered Image\")\n\nplt.subplot(2,2,4)\nplt.imshow(s_img_y, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sobel Y filtered Image\")\n\n# Automatically adjust subplot parameters to give specified padding.\nplt.tight_layout()","3751a060":"from collections import deque\ndef canny_edge_detection(image):\n  edges = cv2.Canny(image, 170, 200) \n  return edges\n\ndef primary_roi(original_image, edge_image):\n  edge_coordinates = deque()\n  for i in tqdm(range(edge_image.shape[0])):\n    for j in range(edge_image.shape[1]):\n      if edge_image[i][j] != 0 :\n        edge_coordinates.append((i, j))\n  \n  min_row = edge_coordinates[np.argsort([coordinate[0] for coordinate in edge_coordinates])[0]][0]\n  max_row = edge_coordinates[np.argsort([coordinate[0] for coordinate in edge_coordinates])[-1]][0]\n  min_col = edge_coordinates[np.argsort([coordinate[1] for coordinate in edge_coordinates])[0]][1]\n  max_col = edge_coordinates[np.argsort([coordinate[1] for coordinate in edge_coordinates])[-1]][1]\n  \n  new_image = original_image.copy()\n  new_edge_image = edge_image.copy()\n  \n  new_image[min_row - 10 : min_row + 10, min_col : max_col] = [255, 0, 0]\n  new_image[max_row - 10 : max_row + 10, min_col : max_col] = [255, 0, 0]\n  new_image[min_row : max_row , min_col - 10 : min_col + 10] = [255, 0, 0]\n  new_image[min_row : max_row , max_col - 10 : max_col + 10] = [255, 0, 0]\n\n  new_edge_image[min_row - 10 : min_row + 10, min_col : max_col] = [255]\n  new_edge_image[max_row - 10 : max_row + 10, min_col : max_col] = [255]\n  new_edge_image[min_row : max_row , min_col - 10 : min_col + 10] = [255]\n  new_edge_image[min_row : max_row , max_col - 10 : max_col + 10] = [255]\n\n  roi_image = new_image[min_row : max_row, min_col : max_col]\n  edge_roi_image = new_edge_image[min_row : max_row, min_col : max_col]\n  \n  \n  return roi_image, edge_roi_image","501896e0":"plt.figure(figsize = (12, 8))\nplt.subplot(1,2,1)\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Denoised Image\")\n\nedge_image = canny_edge_detection(sample_image) \n\nplt.subplot(1,2,2)\nplt.imshow(edge_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Canny Edge Image\")\n# Automatically adjust subplot parameters to give specified padding.\nplt.tight_layout()","b3fd0cd6":"roi_image, edge_roi_image = primary_roi(sample_image, edge_image)\n\nplt.figure(figsize = (12, 8))\nplt.subplot(1,2,1)\nplt.imshow(roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"ROI Image\")\n\nplt.subplot(1,2,2)\nplt.imshow(edge_roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Edge ROI Image\")  \n# Automatically adjust subplot parameters to give specified padding.\nplt.tight_layout()","2abeecaa":"def histogram_equalization(roi_image):\n  image_ycrcb = cv2.cvtColor(roi_image, cv2.COLOR_RGB2YCR_CB)\n  y_channel = image_ycrcb[:, :, 0] # apply histogram equalization on this channel\n  cr_channel = image_ycrcb[:, :, 1]\n  cb_channel = image_ycrcb[:, :, 2]\n  # local histogram equalization\n  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n  equalized = clahe.apply(y_channel)\n  equalized_image = cv2.merge([equalized, cr_channel, cb_channel])\n  equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_YCR_CB2RGB)\n  return equalized_image","36139ee0":"equalized_roi_image = histogram_equalization(roi_image)\n\nplt.figure(figsize = (12, 8))\nplt.subplot(1,2,1)\nplt.imshow(roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"ROI Image\")\n\nplt.subplot(1,2,2)\nplt.imshow(equalized_roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Histogram Equalized ROI Image\")  \n# Automatically adjust subplot parameters to give specified padding.\nplt.tight_layout()","d3a0a5ac":"otsu_threshold, otsu_image = cv2.threshold(cv2.cvtColor(equalized_roi_image, cv2.COLOR_RGB2GRAY), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\nplt.figure(figsize = (12, 8))\nplt.subplot(1,2,1)\nplt.imshow(equalized_roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"equalized_roi_image\")\n\nplt.subplot(1,2,2)\nplt.imshow(otsu_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Otsu's Thresholded Image\")  \n# Automatically adjust subplot parameters to give specified padding.\n\nplt.tight_layout()","1e72edb6":"def segmentation(image, k, attempts) : \n    vectorized = np.float32(image.reshape((-1, 3)))\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n    res , label , center = cv2.kmeans(vectorized, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n    center = np.uint8(center)\n    res = center[label.flatten()]\n    segmented_image = res.reshape((image.shape))\n    return segmented_image","4e3680d2":"plt.figure(figsize = (12, 8))\nplt.subplot(2,2,1)\nplt.imshow(equalized_roi_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Histogram Equalized Image\")\n\nsegmented_image = segmentation(equalized_roi_image, 3, 10) # k = 3, attempt = 10\nplt.subplot(2,2,2)\nplt.imshow(segmented_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Segmented Image with k = 3\")\n\nsegmented_image = segmentation(equalized_roi_image, 4, 10) # k = 4, attempt = 10\nplt.subplot(2,2,3)\nplt.imshow(segmented_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Segmented Image with k = 4\")\n\nsegmented_image = segmentation(equalized_roi_image, 5, 10) # k = 5, attempt = 10\nplt.subplot(2,2,4)\nplt.imshow(segmented_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Segmented Image with k = 5\")","01e504b0":"Clearly, there is a class imbalance problem which needs to be addressed during the deep learning model construction.","07359e5c":"# Exploratory Data Analysis\n\nWhen we\u2019re getting started with a machine learning (ML) project, one critical principle to keep in mind is that data is everything. It is often said that if ML is the rocket engine, then the fuel is the (high-quality) data fed to ML algorithms. However, deriving truth and insight from a pile of data can be a complicated and error-prone job. To have a solid start for our ML project, it always helps to analyze the data up front.\n\nDuring EDA, it\u2019s important that we get a deep understanding of:\n\n* The properties of the data, such as schema and statistical properties;\n* The quality of the data, like missing values and inconsistent data types;\n* The predictive power of the data, such as correlation of features against target.","ce4566a2":"### Noise Reduction : \n\nOne way to get rid of the noise on the image, is by applying Gaussian blur to smooth it. To do so, image convolution technique is applied with a Gaussian Kernel (3x3, 5x5, 7x7 etc\u2026). The kernel size depends on the expected blurring effect. Basically, the smallest the kernel, the less visible is the blur. \n\n### Gradient Calculation : \n\nThe Gradient calculation step detects the edge intensity and direction by calculating the gradient of the image using edge detection operators.\n\nThe result is almost the expected one, but we can see that some of the edges are thick and others are thin. Non-Max Suppression step will help us mitigate the thick ones.\n\n### Non-Maximum Supression : \n\nIdeally, the final image should have thin edges. Thus, we must perform non-maximum suppression to thin out the edges.\n\n\n### Double Threshold : \n\nThe double threshold step aims at identifying 3 kinds of pixels: strong, weak, and non-relevant:\n\n* Strong pixels are pixels that have an intensity so high that we are sure they contribute to the final edge.\n\n* Weak pixels are pixels that have an intensity value that is not enough to be considered as strong ones, but yet not small enough to be considered as non-relevant for the edge detection.\n\n* Other pixels are considered as non-relevant for the edge.\n\nTherefore, the significance of having two values in double threshold : \n\n* High threshold is used to identify the strong pixels (intensity higher than the high threshold)\n\n* Low threshold is used to identify the non-relevant pixels (intensity lower than the low threshold)\n\n* All pixels having intensity between both thresholds are flagged as weak and the Hysteresis mechanism (next step) will help us identify the ones that could be considered as strong and the ones that are considered as non-relevant.\n\n\n\n### Hysteresis : \n\nBased on the threshold results, the hysteresis consists of transforming weak pixels into strong ones, if and only if at least one of the pixels around the one being processed is a strong one. \n\nWe will be using OpenCV's implementation of Canny edge detection. This was the theory involved behind the entire process. \n\nFurther information can be found on OpenCV's documentation : https:\/\/docs.opencv.org\/trunk\/da\/d22\/tutorial_py_canny.html ","daa03530":"**Inference** : \n\n* Red channel has positive skew, meaning the values are more concentrated at intensities lower than mean(somewhere around 90).\n* Green channel is negative skew, meaning the values are more concentrated at intentities higher than mean(somewhere in the range 130-150). This also means that green channel is more pronounced than red in the sample image set; and thereby the whole data set as they come from the same distribution. This makes sense as images are that of leaves!\n* Similarily, blue channel has a slight positive skew and is very well distributed.\n* The distribution of red and green color channels appears to be mesokurtic, aka normally distributed having k = 0 whereas the blue one appears to be relatively platykurtic having k < 0. Therefore out of the three colors, blue channel appears to be the most different one(relative outlier in the RGB color space). ","21b67d3e":"# Edge detection Using Sobel filter : \nEdge detection is one of the fundamental operation in image processing. Using this, we can reduce the amount of pixels while maintaining the structural aspect of the images. This can be done using :\n\n* First derivative based Sobel filter(for thicker edges)\n* Second derivative based Laplacian filter(for finer edges)\n\nHere, we want to consider the area containing only the leaf, while ignoring the background green. Hence, we use Sobel filter to identify the prominent edge of the leaf.","e407ada5":"**Inference** : \n* Rust leaves has brownish- yellowish patches\n* Scab leaves have brown stains.","98d7d71d":"# Histogram Equalization in ROI section of the whole image\n### First of all, why can we not apply histogram equalization directly to an RGB image?\nHistogram equalization is a non-linear process. Channel splitting and equalizing each channel separately is incorrect. Equalization involves intensity values of the image, not the color components. So for a simple RGB color image, histogram equalization cannot be applied directly on the channels. It needs to be applied in such a way that the intensity values are equalized without disturbing the color balance of the image. So, the first step is to convert the color space of the image from RGB into one of the color spaces that separates intensity values from color components. Some of the possible options are HSV\/HLS, YUV, YCbCr, etc. YCbCr is preferred as it is designed for digital images. Perform histogram equalization on the intensity plane Y. Now convert the resultant YCbCr image back to RGB.\n\n(Excerpt taken from :\n\nhttps:\/\/prateekvjoshi.com\/2013\/11\/22\/histogram-equalization-of-rgb-images\/ )","50881e9d":"# Image Denoising :\n\nMany image smoothing techniques like Gaussian Blurring, Median Blurring etc were good to some extent in removing small quantities of noise. In those techniques, we took a small neighbourhood around a pixel and performed some operations like gaussian weighted average, median of the values etc to replace the central element. In short, noise removal at a pixel was local to its neighbourhood.\n\nThere is a property of noise. Noise is generally considered to be a random variable with zero mean.\n\nSuppose we hold a static camera to a certain location for a couple of seconds. This will give us plenty of frames, or a lot of images of the same scene. Then averaging all the frames, we compare the final result and first frame. Reduction in noise would be easily observed.\n\nSo idea is simple, we need a set of similar images to average out the noise. Considering a small window (say 5x5 window) in the image, chance is large that the same patch may be somewhere else in the image. Sometimes in a small neighbourhood around it. Hence, using these similar patches together averaging them can lead to an efficient denoised image.\n\nThis method is Non-Local Means Denoising. It takes more time compared to blurring techniques, but the result are very satisfying.\n\nDenoising illustration :\n\n![image.png](attachment:image.png)","67d29a90":"![image.png](attachment:image.png)   ","768f1eff":"# Data Reading","4f494e45":"Using sobel filter we found the edges, however for further pre-processing we aim to consider only the area of the leaf, that is the fine textured area we see in the gradient images. For that, we will use a much powerful inbuilt function of open-CV called Canny(). This function will return the edge coordinates.\n\nEntire read is available on the OpenCV webpage :\n\nhttps:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_canny\/py_canny.html#canny","bf93f229":"K-means is mostly useful for applications like image compression or object recognition, because for these types of applications, it is inefficient to process the whole image.\n\n### K-Means Segmentation Approach Using OpenCV\n\n* `samples` : It should be of np.float32 data type, and each feature should be put in a single column. Here we have 3 channels, so every channel features have to be in one column. So, total columns we have are 3, while we don't care about the number of rows, hence -1. So, shape : (-1, 3).\n\n* `nclusters(K)` : Number of clusters required at end.\n\n* `criteria` : It is the iteration termination criteria. When this criteria is satisfied, algorithm iteration stops. Actually, it should be a tuple of 3 parameters. They are ( type, max_iter, epsilon )\n\nType of termination criteria. It has 3 flags as below:\n\n* `cv.TERM_CRITERIA_EPS` - stop the algorithm iteration if specified accuracy, epsilon, is reached.\n* `cv.TERM_CRITERIA_MAX_ITER` - stop the algorithm after the specified number of iterations, max_iter.\n* `cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER` - stop the iteration when any of the above condition is met.\n* `max_iter` - An integer specifying maximum number of iterations. epsilon - Required accuracy\n\n1. `attempts` : Flag to specify the number of times the algorithm is executed using different initial labellings. The algorithm returns the labels that yield the best compactness. This compactness is returned as output.\n\n2. `flags` : This flag is used to specify how initial centers are taken. Normally two flags are used for this : cv.KMEANS_PP_CENTERS and cv.KMEANS_RANDOM_CENTERS.\n\n*Output parameters :\n\n`compactness` : It is the sum of squared distance from each point to their corresponding centers.\n\n`labels` : This is the label array (same as 'code' in previous article) where each element marked '0', '1'.....\n\n`centers` : This is array of centers of clusters.*","5005d803":"###### train_data.head()","bd18ed2d":"# Kurtosis :\n\nKurtosis is the characteristics of being flat or peaked. It is a measure whether data is heavy- tailed or light-tailed in a normal distribution\n\nA large kurtosis value often mean that the tails of the distributions are getting toward more extreme values than the tails of normal distributions. This may lead to a length of 6 or 7 standard deviation from the mean. Similarly, If the kurtosis value is very low, then the tails of the distributions will be less lengthier than the those of a normal distribution (less than 3 standard deviation).\n\n![image.png](attachment:image.png)\n\nA large value of kurtosis is often considered as more risky because data may tend to give an outlier value as outcome with greater distance from the mean if applied to any machine learning algorithm.","46bbb6bf":"## OpenCV implementation of the aforementioned approach :\n\ncv2.fastNlMeansDenoisingColored() - Works on Colored images cv2.fastNlMeansDenoising() - Works on graysacle images\n\nCommon arguments are:\n\nh : parameter deciding filter strength. Higher h value removes noise better, but removes details of image also. (10 is ok)\nhForColorComponents : same as h, but for color images only. (normally same as h)\ntemplateWindowSize : should be odd. (recommended 7)\nsearchWindowSize : should be odd. (recommended 21)","52f3e3b8":"# Skewness in EDA :\n\nSkewness is the measure of symmetry or asymmetry of a data distribution. A distribution or data set is said to be symmetric if it looks same to the left and right point of the center.\n\nTypes of Skewness :\n\nSkewness is generally classified into 2 broad categories-\n\n* Right skewness or Positive skewness\n* Left skewness or Negative skewness\n\n![image.png](attachment:image.png)\n\nIt is very difficult to interpret and analyse the data which is skewed.","97a132d0":"# Image Segmentation(Half-Toned Images) : Otsu's Binarization\n\nIn global thresholding, we used an arbitrary chosen value as a threshold. In contrast, Otsu's method avoids having to choose a value and determines it automatically. \n\nWe will apply Otsu's binarization segmentation method on the histogram equalized image obtained in the previous stage.","a7a05fd1":"# Analysing the color channel distribution in each Image ","edcdd40a":"It's evident that all values of k do an amazing job in clustering the image into different segments. K= 5 appears to be the best upon closer inspection.","e7cf1d82":"# Canny Edge Detector : \n\nThe Canny filter is a multi-stage edge detector. It uses a filter based on the derivative of a Gaussian in order to compute the intensity of the gradients.The Gaussian reduces the effect of noise present in the image. Then, potential edges are thinned down to 1-pixel curves by removing non-maximum pixels of the gradient magnitude. Finally, edge pixels are kept or removed using hysteresis thresholding on the gradient magnitude. \n\nThe Canny has three adjustable parameters: the width of the Gaussian (the noisier the image, the greater the width), and the low and high threshold for the hysteresis thresholding. ","c671040a":"# Image Segmentation(Colored Images) : K-means Clustering\n\nIn the previous section we explored image segmentation using Otsu's Binarization. However, this is applied normally on half toned, that is binary(black and white) images. In this section, we will explore a Machine Learning technique called K-means clustering to segment the different areas of the image.\n\nOnce again, the operation will be performed on the histogram equalized image of plant leaf.","b20b3ca8":"The Canny edge detection algorithm is composed of 5 steps:\n\n* Noise reduction;\n* Gradient calculation;\n* Non-maximum suppression;\n* Double threshold;\n* Edge Tracking by Hysteresis."}}