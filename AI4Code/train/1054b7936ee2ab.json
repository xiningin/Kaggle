{"cell_type":{"7a66256c":"code","03c1a5d9":"code","d7d5413d":"code","24199375":"code","227601b2":"code","02370510":"code","6666dd93":"code","5154c2e0":"code","5de42cb3":"code","25551e85":"markdown","428f7353":"markdown","a85fc68f":"markdown","f299453e":"markdown","5b21948d":"markdown","854ad110":"markdown","134dc142":"markdown"},"source":{"7a66256c":"import glob\n\n# \u4e86\u89e3\u6570\u636e\u96c6\u7684\u7ec4\u6210\n\ntrain_files = glob.glob('\/kaggle\/input\/dogs-vs-cats\/train\/train\/*')\ntest_files = glob.glob('\/kaggle\/input\/dogs-vs-cats\/test1\/test1\/*')\n\ntrain_cat_files = [file_name for file_name in train_files if 'cat' in file_name]\ntrain_dog_files = [file_name for file_name in train_files if 'dog' in file_name]\n\nprint('train samples of cat:', len(train_cat_files))\nprint('train samples of dog:', len(train_dog_files))","03c1a5d9":"import numpy as np\nfrom random import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.preprocessing import LabelEncoder\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d61500\u5f20\u8bad\u7ec3\u6837\u672c\ncat_train = list(np.random.choice(train_cat_files, size=5000, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d61500\u5f20\u8bad\u7ec3\u6837\u672c\ndog_train = list(np.random.choice(train_dog_files, size=5000, replace=False))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u8bad\u7ec3\u6837\u672c\ntrain_cat_files = list(set(train_cat_files) - set(cat_train))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u8bad\u7ec3\u6837\u672c\ntrain_dog_files = list(set(train_dog_files) - set(dog_train))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6821\u9a8c\u6837\u672c\ncat_val = list(np.random.choice(train_cat_files, size=1000, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6821\u9a8c\u6837\u672c\ndog_val = list(np.random.choice(train_dog_files, size=1000, replace=False))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u6821\u9a8c\u6837\u672c\ntrain_cat_files = list(set(train_cat_files) - set(cat_val))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u6821\u9a8c\u6837\u672c\ntrain_dog_files = list(set(train_dog_files) - set(dog_val))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6d4b\u8bd5\u6837\u672c\ncat_test = list(np.random.choice(train_cat_files, size=1000, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6d4b\u8bd5\u6837\u672c\ndog_test = list(np.random.choice(train_dog_files, size=1000, replace=False))\n\n# \u5408\u5e76\u732b\u72d7\u8bad\u7ec3\u96c6\ntrain_files = cat_train + dog_train\n# \u5408\u5e76\u732b\u72d7\u6821\u9a8c\u96c6\nval_files = cat_val + dog_val\n# \u5408\u5e76\u732b\u72d7\u6d4b\u8bd5\u96c6\ntest_files = cat_test + dog_test\n\n# \u968f\u673a\u5316\u732b\u72d7\u8bad\u7ec3\u96c6\nshuffle(train_files)\n\n# \u6837\u672c\u5c3a\u5bf8\nIMG_DIM = (160, 160)\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u8bad\u7ec3\u96c6\nx_train = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in train_files])\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u6821\u9a8c\u96c6\nx_val = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in val_files])\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u6d4b\u8bd5\u96c6\nx_test = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in test_files])\n\n# \u5c06\u8bad\u7ec3\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_train = np.array(x_train)\n# \u5c06\u6821\u9a8c\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_val = np.array(x_val)\n# \u5c06\u6d4b\u8bd5\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_test = np.array(x_test)\n\n# \u6807\u7b7e\u7f16\u7801\ntrain_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in train_files]\nval_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in val_files]\ntest_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in test_files]\nle = LabelEncoder()\nle.fit(train_labels)\ny_train = le.transform(train_labels)\ny_val = le.transform(val_labels)\ny_test = le.transform(test_labels)\n\n\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('x_validate shape:', x_val.shape)\nprint('y_validate shape:', y_val.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_test shape:', y_test.shape)","d7d5413d":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, \n                                   zoom_range=0.3, \n                                   rotation_range=50,\n                                   width_shift_range=0.2, \n                                   height_shift_range=0.2, \n                                   shear_range=0.2, \n                                   horizontal_flip=True, \n                                   fill_mode='nearest')\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\nimg_id = 3\ngenerator = train_datagen.flow(x_train[img_id:img_id+1], train_labels[img_id:img_id+1])\nimages = [next(generator) for i in range(0,5)]\nfig, ax = plt.subplots(1,5, figsize=(16, 6))\nprint('Labels:', [item[1][0] for item in images])\nl = [ax[i].imshow(images[i][0][0]) for i in range(0,5)]","24199375":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.models import Model\nimport pandas as pd\n\n\ninput_shape = (160, 160, 3)\nmobilenet_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n#output = mobilenet.layers[-1].output\n#output = Flatten()(output)\n#mobilenet_model = Model(mobilenet.input, output)\n\nmobilenet_model.trainable = True\n#fine_tune_at = 100\n# Freeze all the layers before the `fine_tune_at` layer\n#for layer in mobilenet_model.layers[:fine_tune_at]:\n#    layer.trainable =  False\n\nmobilenet_model.summary()","227601b2":"layers = [(layer, layer.name, layer.trainable) for layer in mobilenet_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  ","02370510":"print(x_train.shape[0])","6666dd93":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers\n\nBATCH_SIZE = 32\nTRAIN_SAMPLE_NUMBER = x_train.shape[0]\nVAL_SAMPLE_NUMBER = x_val.shape[0]\nsteps_per_epoch = TRAIN_SAMPLE_NUMBER \/\/ BATCH_SIZE\nepochs = 20\nvalidation_steps = VAL_SAMPLE_NUMBER \/\/ BATCH_SIZE\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\nval_generator = val_datagen.flow(x_val, y_val, batch_size=BATCH_SIZE)\n\nmodel = Sequential()\nmodel.add(mobilenet_model)\nmodel.add(GlobalAveragePooling2D())\n'''\nmodel.add(Dense(512, activation='relu', input_dim=input_shape))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\n'''\nmodel.add(Dense(units=2, activation='softmax'))\n\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['accuracy'])\n              \nhistory = model.fit_generator(train_generator, \n                              steps_per_epoch=steps_per_epoch, \n                              epochs=epochs,\n                              validation_data=val_generator, \n                              validation_steps=validation_steps, \n                              verbose=1)    ","5154c2e0":"import matplotlib.pyplot as plt\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Pre-trained MobileNetV2 Transfer Learn with Fine-Tuning & Image Augmentation Performance ', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,21))\nax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\nax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 21, 1))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch #')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history.history['loss'], label='Train Loss')\nax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, 21, 1))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch #')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","5de42cb3":"model.save('Cats_Dogs_MobileNetV2_Fine_Tuning_Transfer_Learning.h5')","25551e85":"### \u4e00\u3001\u4e86\u89e3\u6570\u636e\u96c6\n\n\u3000\u3000\u8be5\u6570\u636e\u96c6\u4e3a\u732b\u72d7\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u96c6\u753150000\u5f20\u7167\u7247\uff08\u5176\u4e2d\u732b25000\u5f20\uff0c\u72d725000\u5f20\uff09\uff0c\u6d4b\u8bd5\u96c625000\u5f20\u7167\u7247\uff08\u5176\u4e2d\u5176\u4e2d\u732b12500\u5f20\uff0c\u72d712500\u5f20\uff09\u3002","428f7353":"### \u4e03\u3001\u4fdd\u5b58\u6a21\u578b\n\u3000\u3000\u4fdd\u5b58\u6a21\u578b\u4ee5\u4fbf\u540e\u9762\u6211\u4eec\u7528\u6d4b\u8bd5\u96c6\u5bf9\u8be5\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u8bc4\u4f30\u3002","a85fc68f":"### \u56db\u3001\u8bbe\u7f6eMobileNetV2\u7f51\u7edc","f299453e":"### \u4e94\u3001\u5b9a\u4e49\u8fc1\u79fb\u5b66\u4e60\u7f51\u7edc\u6a21\u578b","5b21948d":"### \u4e8c\u3001\u6784\u5efa\u5c0f\u6570\u636e\u96c6\n\n\u3000\u3000\u73b0\u5728\u6211\u4eec\u6784\u9020\u4e00\u4e2a\u5c0f\u578b\u6570\u636e\u96c6\uff0c\u5373\u8bad\u7ec3\u56fe\u50cf\u5305\u542b10000\u5f20\u56fe\u7247\uff0c\u6821\u9a8c\u56fe\u50cf\u5305\u542b2000\u5f20\u56fe\u7247\uff0c\u6d4b\u8bd5\u56fe\u50cf\u5305\u542b2000\u5f20\u56fe\u7247\uff08\u6bcf\u7c7b\u4e2d\u732b\u72d7\u56fe\u7247\u6570\u91cf\u76f8\u540c\uff09\u3002","854ad110":"### \u4e09\u3001\u6570\u636e\u589e\u5f3a","134dc142":"### \u516d\u3001\u7ed8\u5236\u6a21\u578b\u8bad\u7ec3\u7684\u51c6\u786e\u5ea6\u548c\u635f\u5931\u56fe"}}