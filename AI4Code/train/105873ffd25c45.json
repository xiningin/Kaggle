{"cell_type":{"b041f1d5":"code","665229d0":"code","5e792df7":"code","f7e6a25d":"code","40246271":"code","e474e1f0":"code","4e8d747e":"code","dfc6f6aa":"code","b710f56c":"code","854b826c":"code","223f4bc8":"code","96d520d6":"code","75b03c90":"code","ef3be9dd":"code","b3c3923f":"code","442bbddf":"code","1c5a064f":"code","a09fd2a9":"code","918bbeb5":"code","9779f623":"code","50d788d4":"code","b1a41a12":"code","8670fcd2":"code","5ef37fa2":"code","9ed57447":"code","3abddce5":"code","261a02d7":"code","0432adca":"code","e96af25c":"code","f7088e3c":"code","9c4d55d7":"code","0b76a14b":"code","d8b42d6e":"code","79d4dd4c":"code","795de198":"code","ec6225cd":"code","e69ddaf9":"code","3889a0ec":"code","f2f726ce":"code","ffb2514c":"code","e0e2b58c":"code","507af46d":"code","105868bd":"code","878ca9b4":"code","2bc6c01e":"code","fa70e011":"code","213ab951":"code","8a3e8237":"code","2c63795b":"code","2e6ce126":"code","a9120498":"code","98780bf1":"code","030e984c":"code","8fadb462":"code","7bce2240":"code","88a5c584":"code","2bf14571":"code","a9d8467c":"code","1da5e7aa":"code","c554afa0":"code","14c9bd36":"code","d7c07c85":"code","e07657b9":"code","a0f130a7":"code","5ce35a20":"code","8d495bb4":"code","f497c2fc":"code","e4d8ddf5":"code","fafa5c81":"code","bf291660":"code","309830af":"code","3acd80c2":"code","43f38d01":"code","ef735c57":"code","63b4e568":"code","42460e0d":"code","4712bda0":"code","438ce4be":"code","356ce7e6":"code","3b17946e":"code","917f81db":"code","17e203e5":"code","a8ba716e":"code","a1069d7e":"code","7589db24":"code","fcc865b2":"code","b241d0d8":"code","1bbc219a":"code","450be569":"code","68973fd9":"code","58dfadd1":"code","0077b150":"code","368098bf":"code","aebba23a":"code","2fc26a8a":"code","cd72e6f5":"code","e60da5e6":"code","6f2cc6d2":"code","ad3d75fc":"code","41883fe1":"code","d786ba09":"code","c3f6532c":"code","4ef67fe9":"code","1c993fc4":"code","f2653100":"markdown","485b6535":"markdown","c0f077bc":"markdown","12dff157":"markdown","0c70ca17":"markdown","c68a3cf1":"markdown","38f232be":"markdown","3586b693":"markdown","68e58dc9":"markdown","770e884a":"markdown","d859aa5e":"markdown","7c4d2b48":"markdown","1e04aca0":"markdown","0b1f80f5":"markdown","35177b9d":"markdown","3dd931c3":"markdown","c9c2fd07":"markdown","bb1644ab":"markdown","da0c3084":"markdown","33c413f5":"markdown","6d601e9a":"markdown","bdbdf44d":"markdown","451ca82b":"markdown","4e906fea":"markdown","3602707c":"markdown","0fc4d6e1":"markdown","d9c40eab":"markdown","e4df1a3a":"markdown","4bc49861":"markdown","2b85accb":"markdown","b3104553":"markdown","652a4921":"markdown","7b51947a":"markdown","fd8dfb85":"markdown","24557338":"markdown","3b07a7bd":"markdown","a64d0a50":"markdown","b20b8c94":"markdown"},"source":{"b041f1d5":"import pandas as pd\nimport numpy as np\nfrom numpy import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Lasso","665229d0":"train = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-1\/train.csv\", low_memory = False)\ntest = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-1\/test.csv\", low_memory = False)\nsubmission = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-1\/sample_submission.csv', low_memory = False)","5e792df7":"train.head()","f7e6a25d":"test.head()","40246271":"submission.head()","e474e1f0":"group = train['Group']\nmonth = train['Month']\nyear = train['Year']\nmmwr = train['MMWR Week']\nhhs = train['HHS Region']\nrace = train['Race and Hispanic Origin Group']\nage = train['Age Group']\ncovid_deaths = train['COVID-19 Deaths']\ntotal_deaths = train['Total Deaths']\nfootnote = train['Footnote']","4e8d747e":"group_test = test['Group']\nmonth_test = test['Month']\nyear_test = test['Year']\nmmwr_test = test['MMWR Week']\nhhs_test = test['HHS Region']\nrace_test = test['Race and Hispanic Origin Group']\nage_test = test['Age Group']\ntotal_deaths = test['Total Deaths']","dfc6f6aa":"group.unique()","b710f56c":"group_test.unique()","854b826c":"month.unique()","223f4bc8":"month_test.unique()","96d520d6":"year.unique()","75b03c90":"year_test.unique()","ef3be9dd":"mmwr.unique()","b3c3923f":"mmwr_test.unique()","442bbddf":"hhs.unique()","1c5a064f":"hhs_test.unique()","a09fd2a9":"race.unique()","918bbeb5":"race_test.unique()","9779f623":"age.unique()","50d788d4":"age_test.unique()","b1a41a12":"year.unique()","8670fcd2":"year_test.unique()","5ef37fa2":"footnote.unique()","9ed57447":"train['Data As Of'].unique()","3abddce5":"test['Data As Of'].unique()","261a02d7":"sns.relplot(x = 'Start Date', y = 'COVID-19 Deaths', data = train, ci = None , kind = 'line')","0432adca":"sns.relplot(x = 'Start Date', y = 'Total Deaths', data = train, ci = None , kind = 'line')","e96af25c":"ax = sns.relplot(x = 'Race and Hispanic Origin Group', y = 'Total Deaths', data = train, ci = None , kind = 'line')\nplt.xticks(rotation=90)","f7088e3c":"train.dtypes","9c4d55d7":"test.dtypes","0b76a14b":"train_data = train.loc[train['Group'] == 'By Week']\ntest_data = test.loc[test['Group'] == 'By Week']","d8b42d6e":"sns.relplot(x = 'Year', y = 'COVID-19 Deaths', data = train, ci = None , kind = 'line')","79d4dd4c":"sns.set_theme(style=\"whitegrid\")\nsns.boxplot(x = train_data['COVID-19 Deaths'])","795de198":"sns.scatterplot(x = 'Start Date', y = 'COVID-19 Deaths' , data = train_data, hue = 'Age Group', legend = 'auto')","ec6225cd":"train_data.isnull().sum()","e69ddaf9":"test_data.isnull().sum()","3889a0ec":"#drop useless columns in training data set\n#Footnote has no useful data\n#Week Ending data has same information as End \"datetime .txt\"\n#Date as of is he same through out the file so has no bearing on the result\n\nuseless = ['Week-Ending Date', 'Footnote', 'Data As Of', 'Total Deaths', 'id', 'Start Date', 'Group']\n\ntrain_data = train_data.drop(useless, axis = \"columns\")","f2f726ce":"#storing test data id's for the submisison file\ntest_id = test_data['id']","ffb2514c":"useless = ['Data As Of', 'Week-Ending Date', 'Total Deaths', 'id', 'Start Date', 'Group']\n\ntest_data = test_data.drop(useless, axis = \"columns\")","e0e2b58c":"train_data['End Date']   = pd.to_datetime(train_data['End Date'], format = '%Y-%m-%d')","507af46d":"test_data['End Date']  = pd.to_datetime(test_data['End Date'], format = '%Y-%m-%d')","105868bd":"train_data.head()","878ca9b4":"test_data.head()","2bc6c01e":"train_data['Week Number'] = train_data['End Date'].dt.isocalendar().week\ntest_data['Week Number'] = test_data['End Date'].dt.isocalendar().week","fa70e011":"train_data['Month'] = train_data['End Date'].dt.month\ntest_data['Month'] = test_data['End Date'].dt.month","213ab951":"test_data = test_data.drop('End Date', axis = 'columns')\ntrain_data = train_data.drop('End Date', axis = 'columns')","8a3e8237":"year = train_data['Year'] == '2021'","2c63795b":"year.unique","2e6ce126":"train_data.loc[year, 'MMWR Week'] = train_data['MMWR Week'] + 53","a9120498":"test_data['MMWR Week'] = test_data['MMWR Week'] + 53","98780bf1":"train_data['MMWR Week'].unique","030e984c":"train_data = train_data.loc[train['HHS Region'] == 'United States']\ntest_data = test_data.loc[test['HHS Region'] == 'United States']","8fadb462":"test_data.head(2)\n","7bce2240":"train_data.head(2)","88a5c584":"train_data.isnull().sum()","2bf14571":"test_data.isnull().sum()","a9d8467c":"useless = ['HHS Region']\n\ntest_data = test_data.drop(useless, axis = \"columns\")\ntrain_data = train_data.drop(useless, axis = 'columns')","1da5e7aa":"train_data.head(2)","c554afa0":"test_data.head(2)","14c9bd36":"train_data['MMWR Week'] = train_data['MMWR Week'].astype('int')\ntest_data['MMWR Week'] = test_data['MMWR Week'].astype('int')","d7c07c85":"train_data = train_data.replace({'Year': {'2019\/2020' : 'A', '2020': 'B', '2020\/2021': 'C', '2021': 'D'}})\ntest_data = test_data.replace({'Year': {'2019\/2020' : 'A', '2020': 'B', '2020\/2021': 'C', 2021: 'D'}})","e07657b9":"#creating dummies for train data set\ncolumns = ['Race and Hispanic Origin Group', 'Age Group', 'Year']\nfor column in columns:\n    temp = pd.get_dummies(train_data[column])\n    train_data = train_data.join(temp)\n    train_data = train_data.drop(column, axis = 'columns')","a0f130a7":"#creating dummies for test data set\ncolumns = ['Race and Hispanic Origin Group', 'Age Group', 'Year']\nfor column in columns:\n    temp = pd.get_dummies(test_data[column])\n    test_data = test_data.join(temp)\n    test_data = test_data.drop(column, axis = 'columns')","5ce35a20":"test_data['A'] = 0\ntest_data['B'] = 0\ntest_data['C'] = 0\n","8d495bb4":"\ncovid = train_data['COVID-19 Deaths'] > 0\n\ntrain_data.loc[covid, 'COVID-19 Deaths'] = np.log10(train_data['COVID-19 Deaths'])\n#This sometimes produces a Runtimewarning: divide by zero but I have loooked at the documentation and it just sets the value at zero, which is what we want here in such a case.\n# The program runs fine with the warning.","f497c2fc":"train_data.dtypes","e4d8ddf5":"test_data.dtypes","fafa5c81":"train_data.head(2)","bf291660":"test_data.head(2)","309830af":"X = train_data.drop('COVID-19 Deaths', axis = 'columns')","3acd80c2":"X.head()","43f38d01":"y = train_data['COVID-19 Deaths']","ef735c57":"y.head()","63b4e568":"X.shape","42460e0d":"y.shape","4712bda0":"X.dtypes","438ce4be":"y.dtypes","356ce7e6":"ridge = Ridge()\ntscv = TimeSeriesSplit(n_splits = 5)\n\nparam = {'alpha': [1.0, 0.1, 0.5, 10],'fit_intercept':[True, False], 'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg','sag' , 'saga' ] , 'copy_X': [True, False], 'max_iter':[1000, 5000, 10000, 20000], 'tol': [0.1, 1, 10]}\n\nclf = GridSearchCV(ridge, param, cv = tscv)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\n","3b17946e":"print(clf.best_score_)\nprint(clf.best_params_)","917f81db":"linear = LinearRegression()\ntscv = TimeSeriesSplit(n_splits = 10)\n\nparam = {'fit_intercept': [True, False], 'n_jobs':[1, 10, 20], 'copy_X': [True, False]}\nclf = GridSearchCV(linear, param, cv = tscv)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\n","17e203e5":"print(clf.best_score_)\nprint(clf.best_params_)","a8ba716e":"elastic = ElasticNet()\ntscv = TimeSeriesSplit(n_splits = 5)\n\nparam = {'alpha': [1.0, 0.01, 0.1, 0.5], 'l1_ratio': [0.5, 0.1, 1],'copy_X': [True, False], 'max_iter':[1000, 5000, 10000, 20000], 'tol': [0.1, 1], 'warm_start':[True, False], 'selection':['cyclic', 'random']  }\nclf = GridSearchCV(elastic, param, cv = tscv)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\n","a1069d7e":"print(clf.best_score_)\nprint(clf.best_params_)","7589db24":"lasso = Lasso()\ntscv = TimeSeriesSplit(n_splits = 5)\n\nparam = {'alpha': [ 0.001, 0.01, 1.0, 0.1, 0.5], 'copy_X': [True, False], 'max_iter':[1000, 5000, 10000, 20000], 'tol': [0.1, 1, 10], 'warm_start':[True, False], 'selection':['cyclic', 'random']  }\nclf = GridSearchCV(lasso, param, cv = tscv)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\n","fcc865b2":"print(clf.best_score_)\nprint(clf.best_params_)","b241d0d8":"time_kfold = TimeSeriesSplit(n_splits = 5)\nridge_model = Ridge(alpha = 1.2 ,copy_X= False,fit_intercept = True, max_iter= 5000, solver= 'sag', tol= 0.1)\n\n\nscore_list = []\nfor train_index, test_index in time_kfold.split(X):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    ridge_model.fit(X_train, y_train)\n    \n    predictions = ridge_model.predict(X_test)\n    \n    rmse = mean_squared_error(y_test, predictions, squared = False)\n    print('RMSE: ' + str(rmse))\n    \n    score_list.append(rmse)\n\nprint(np.median(score_list))\n","1bbc219a":"score = pd.Series(score_list)\nscore.describe()","450be569":"df = pd.DataFrame(score_list)\ndf['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","68973fd9":"output = ridge_model.predict(test_data)\noutput = pd.DataFrame({'id': test_id, 'COVID-19 Deaths': output})\n\nzero = output['COVID-19 Deaths'] < 1\noutput.loc[zero, 'COVID-19 Deaths'] = 0\n\nnon_zero = output['COVID-19 Deaths'] >= 1\noutput.loc[non_zero, 'COVID-19 Deaths'] = ( 10 ** (output['COVID-19 Deaths']) )\n\noutput['COVID-19 Deaths'] = output['COVID-19 Deaths'].astype('int')\n","58dfadd1":"time_kfold = TimeSeriesSplit(n_splits = 5)\nlinear_model = LinearRegression(copy_X = False, fit_intercept = True, n_jobs = 1)\n\n\nscore_list = []\nfor train_index, test_index in time_kfold.split(X):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    linear_model.fit(X_train, y_train)\n    \n    predictions = linear_model.predict(X_test)\n    \n    rmse = mean_squared_error(y_test, predictions, squared = False)\n    print('RMSE: ' + str(rmse))\n    \n    score_list.append(rmse)\n\nprint(np.median(score_list))\n","0077b150":"score = pd.Series(score_list)\nscore.describe()","368098bf":"df = pd.DataFrame(score_list)\ndf['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","aebba23a":"linear_model.fit(X, y)\noutput = linear_model.predict(test_data)\noutput = pd.DataFrame({'id': test_id, 'COVID-19 Deaths': output})\n\nzero = output['COVID-19 Deaths'] < 1\noutput.loc[zero, 'COVID-19 Deaths'] = 0\n\nnon_zero = output['COVID-19 Deaths'] >= 1\noutput.loc[non_zero, 'COVID-19 Deaths'] =  ( 10 ** (output['COVID-19 Deaths']) ) \n\noutput['COVID-19 Deaths'] = output['COVID-19 Deaths'].astype('int')\n","2fc26a8a":"time_kfold = TimeSeriesSplit(n_splits = 5)\nelastic_model = ElasticNet(alpha = 0.01, copy_X = False, l1_ratio = 0.4, max_iter = 10000, selection = 'random', tol = 0.1, warm_start = True)\n\n\nscore_list = []\nfor train_index, test_index in time_kfold.split(X):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    elastic_model.fit(X_train, y_train)\n    \n    predictions = elastic_model.predict(X_test)\n    \n    rmse = mean_squared_error(y_test, predictions, squared = False)\n    print('RMSE: ' + str(rmse))\n    \n    score_list.append(rmse)\n\nprint(np.median(score_list))\n","cd72e6f5":"score = pd.Series(score_list)\nscore.describe()","e60da5e6":"df = pd.DataFrame(score_list)\ndf['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","6f2cc6d2":"output = elastic_model.predict(test_data)\noutput = pd.DataFrame({'id': test_id, 'COVID-19 Deaths': output})\n\nzero = output['COVID-19 Deaths'] < 1\noutput.loc[zero, 'COVID-19 Deaths'] = 0\n\nnon_zero = output['COVID-19 Deaths'] >= 1\noutput.loc[non_zero, 'COVID-19 Deaths'] = ( 10 ** (output['COVID-19 Deaths']) ) \n\noutput['COVID-19 Deaths'] = output['COVID-19 Deaths'].astype('int')\n","ad3d75fc":"time_kfold = TimeSeriesSplit(n_splits = 5)\nlasso_model = Lasso(alpha = 0.0078, copy_X = False, max_iter = 50000, selection = 'cyclic', tol = 1000000, warm_start = True)\n\n\nscore_list = []\nfor train_index, test_index in time_kfold.split(X):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    lasso_model.fit(X_train, y_train)\n    \n    predictions = lasso_model.predict(X_test)\n    \n    rmse = mean_squared_error(y_test, predictions, squared = False)\n    print('RMSE: ' + str(rmse))\n    \n    score_list.append(rmse)\n\nprint(np.median(score_list))\n","41883fe1":"score = pd.Series(score_list)\nscore.describe()","d786ba09":"df = pd.DataFrame(score_list)\ndf['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","c3f6532c":"output = lasso_model.predict(test_data)\noutput = pd.DataFrame({'id': test_id, 'COVID-19 Deaths': output})\n\nzero = output['COVID-19 Deaths'] < 1\noutput.loc[zero, 'COVID-19 Deaths'] = 0\n\nnon_zero = output['COVID-19 Deaths'] >= 1 \noutput.loc[non_zero, 'COVID-19 Deaths'] =  ( 10 ** (output['COVID-19 Deaths']) ) \n\noutput['COVID-19 Deaths'] = output['COVID-19 Deaths'].astype('int')\n","4ef67fe9":"print(output.to_string())","1c993fc4":"output.to_csv('submisison.csv', index=False)\n\nprint('Output Sucessful')","f2653100":"**Elastic Net Regression Model GridSerachCV**","485b6535":"# **Processing Data**","c0f077bc":"**Since we only need the HHS region of 'United States'as per the test data so we can isolate them only.**","12dff157":"**Creating a new week index to compensate for the missing values in Weeks. Weeks are based on 'End Date'. Fill up the Month index using the 'End Date'.**\n","0c70ca17":"**Since all the lines follow a normal bell curve, there are no outliers present. But we need to adjust the scale of the covid deaths for regression models**","c68a3cf1":"# **Analysis:**\n1. In the test data we are only generating prediction on the 'By Week' value. So, the rest of the categories i.e. 'By Month' and 'By Year' are not needed.\n2. In the test data, the 'HHS Region' only has 'United States' so it makes sense to only use that region for the training data set. We can omit the other regions. \n3. The 'Footnote' feature does not provide any meaningful information so that feature can also be omitted.\n4. We can see that the 'Data As Of' column in both train and test data has only one date so that can be omittted.\n5. In the 'Total Deaths' feature we can see that there is 24,158 missing rows. Since we do not have any other information about total deaths, we will not be able to accuratly fill in those data, and since we are more interested in COVID -19 deaths as per the test.csv file; they can be omitted. Also, the total deaths while so show some corealtion with Covid deaths, the total deaths increase by a factor of 10 in the same time period which cannot be accounted by the rise in Covid deaths.\n6. Also analysis shows that the 'End Date' and the 'Week-Ending Date' are the same so we can remove the 'Week-Ending Date'. \n7. Month \n8. The dates are object types. So converting them to datetime objects would be very helpful in manipulating dates.\n9. Since the data represents a reasonable normal\/bell curve with the older population showing more deaths with the progression of time. We can estimate that there are no outlier in the data set.\n10. The 'COVID-19 Deaths' have a large range of values which is not good for a regression model and can lead to negative RMSE error, so we need to scale those to reasonable range.\n11. The null values in both the test and train file are for other regions than 'United States' and for other group than 'By Week' so we do not need to handle null values. \n","38f232be":"**Creating a map to convert the categorical labels in Year for clearer one hot encoding later.**","3586b693":"**Checking for null values**","68e58dc9":"**Building a training a Lasso Regression model**","770e884a":"**Since test data only has year 2021 we will create new columns with values 0 for the other years present in train data, but not in test data.**","d859aa5e":"**Since the Lasso model gives us the best score on average, we will select that for grading.**","7c4d2b48":"**Building a training a Oridany Least Squar Regression model**","1e04aca0":"# Imporitng Modules and Loading Data","0b1f80f5":"**The MMWR Week is used as a counter and represents the number of weeks since the start of the data collection. Adjust the values for train and test data accordingly**","35177b9d":"**Checking for outliers**","3dd931c3":"**Removing useless columns**","c9c2fd07":"**checking for null values** ","bb1644ab":"# **Submit for grading**","da0c3084":"**Ordinary Least Square Model GridSerachCV**","33c413f5":"**Building a training a Elastic Net Regression model**","6d601e9a":"**Ridge Regression Model GridSerachCV**","bdbdf44d":"**Converting dates to date time for easy manipulation**","451ca82b":"**The covid death numbers have a very large range and not good for regression models. So will scale the range by log10 to make it more suitable for linear regression models**","4e906fea":"**Checking for unique values in each column**","3602707c":"**Lasso Model GridSerachCV**","0fc4d6e1":"**Building a training a Ridge regression model**","d9c40eab":"**Genrating Cross Validation Score**","e4df1a3a":"Name: Crason Shrestha\n\nFinal Model.","4bc49861":"**One hot endcoding categorical data**","2b85accb":"# Building Models and Calculating Scores","b3104553":"**Casting the 'MMWR Week' as an int as weeks can only be whole numbers and data is collected every 7 days. It was a float.**","652a4921":"**Genrating Cross Validation Score**","7b51947a":"**Since the test data only has'By Week' data, isolate those rows only**","fd8dfb85":"**Generating Cross Validation Score**","24557338":"#  **Exploratory Data Analysis**","3b07a7bd":"**Generating Cross Validation Score**","a64d0a50":"# **Machine Learning Models**","b20b8c94":"**Since we islolated data based on HHS Region = 'United States' we can remove the HHS Region**"}}