{"cell_type":{"be237e6c":"code","a250b93b":"code","91f6f674":"code","464df52a":"code","4ffb31b7":"code","8aab3299":"code","cfd69215":"code","7c91ba49":"code","66f1c305":"code","4b84f509":"code","2403673f":"code","7f567ee7":"code","2004068f":"code","cf7dcabf":"code","8e9f4a4a":"code","555f429a":"code","48e314e3":"code","9d572b3e":"markdown","d5365cad":"markdown","7fcd5288":"markdown","a446fb07":"markdown","22df3e0d":"markdown","eade0461":"markdown","304f9187":"markdown","d1f816f6":"markdown","e07ddac1":"markdown","66b703b1":"markdown","e0f37ca5":"markdown","9c6c8728":"markdown","60f1f153":"markdown","c85bc1b0":"markdown"},"source":{"be237e6c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a250b93b":"# Load data set\nx = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\ny = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')","91f6f674":"print(\"x shape\",x.shape)\nprint(\"y shape\",y.shape)","464df52a":"plt.figure(figsize=(30,7))\nimg_size = 64\nplt.subplot(1, 7, 1)\nplt.imshow(x[371].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 2)\nplt.imshow(x[900].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 3)\nplt.imshow(x[2002].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 4)\nplt.imshow(x[700].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 5)\nplt.imshow(x[51].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 6)\nplt.imshow(x[519].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 7, 7)\nplt.imshow(x[1732].reshape(img_size, img_size))\nplt.axis('off')\nplt.show()","4ffb31b7":"x","8aab3299":"y","cfd69215":"# Reshape data\nx = x.reshape(-1,64,64,1)\nprint(\"x shape: \",x.shape)","7c91ba49":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.1, random_state=42)\nprint(\"x_train shape\",X_train.shape)\nprint(\"X_val shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"Y_val shape\",Y_val.shape)","66f1c305":"# Some examples\nplt.imshow(X_train[2][:,:,0])\nplt.show()","4b84f509":"# \nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\n# fully connected\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation = 'softmax'))\n\nmodel.summary()","2403673f":"epochs = 200  # for better result increase the epochs\nbatch_size = 10","7f567ee7":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","2004068f":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","cf7dcabf":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=10,  # randomly rotate images\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","8e9f4a4a":"\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0]\/\/batch_size) # \"X_train.shape[0] \/\/ batch_size\" floor division = tam de\u011fer fonksiyonu","555f429a":"plt.figure(figsize=(24,8))\n\nplt.subplot(1,2,1)\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\", c=\"red\", linewidth=4,alpha = 0.65)\nplt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\", c=\"blue\", linewidth=4,alpha = 0.65)\nplt.legend()\n\n\nplt.subplot(1,2,2)\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\", c=\"red\", linewidth=4,alpha = 0.65)\nplt.plot(history.history[\"loss\"], label=\"Training Loss\", c=\"blue\", linewidth=4,alpha = 0.65)\nplt.legend()\n\nplt.suptitle(\"ACCURACY \/ LOSS\",fontsize=18)\n\nplt.show()","48e314e3":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","9d572b3e":"<a id=\"7\"><\/a>\n### Epochs and Batch Size","d5365cad":"# Prediction Sign Language Digits with CNN\n<font color='blue'>\n<br>Content: \n\n* [Loading the Data Set](#1)\n    * [What we learned about data ](#2)\n* [Normalization, Reshape and Label Encoding ](#3)\n* [Train Test Split](#4)\n* [Convolutional Neural Network](#5)\n    * [Create Convolutional Neural Network Model with Keras](#6)\n        * [Epochs and Batch Size](#7)\n        * [Define Optimizer](#8)\n        * [Compile Model](#9)\n        * [Data Augmentation](#10)\n        * [Model Training](#11)\n        * [Visualizing The Results](#12)\n* [Conclusion](#13)","7fcd5288":"<a id=\"8\"><\/a>\n### Define the optimizer","a446fb07":"<a id=\"10\"><\/a>\n### Data Augmentation","22df3e0d":"<a id=\"4\"><\/a>\n## Train Test Split\n* We split the data into train and test sets.\n* test size is 10%.\n* train size is 90%.","eade0461":"<a id=\"2\"><\/a>\n### What we learned about data\n* We have 2062 samples.\n* Image size 64x64.\n* Number of classes 10.\n* Number of participant students: 218\n* Number of samples per student: 10\n* ***Data is normalized and encoded labels so we just need to reshape data.***","304f9187":"<a id=\"9\"><\/a>\n### Compile the model","d1f816f6":"<a id=\"5\"><\/a>\n## Convolutional Neural Network \n* CNN is used for image classification, object detection \n<a href=\"https:\/\/ibb.co\/QK7jnrz\"><a href=\"https:\/\/ibb.co\/QK7jnrz\"><img src=\"https:\/\/i.ibb.co\/YL4T8pY\/lenet-5-png.webp\" alt=\"lenet-5-png\" border=\"0\" \/><\/a>","e07ddac1":"<a id=\"3\"><\/a>\n## Normalization, Reshape and Label Encoding \n* Normalization\n    * We perform a grayscale normalization to reduce the effect of illumination's differences.\n    * If we perform normalization, CNN works faster.\n* Reshape\n    * Train and test images (64 x 64) \n    * We reshape all data to 64x64x1 3D matrices.\n    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel.\n* Label Encoding  \n    * Encode labels to one hot vectors.\n    * For example:\n        * 2 => [0,0,1,0,0,0,0,0,0,0]\n        * 4 => [0,0,0,0,1,0,0,0,0,0]","66b703b1":"<a id=\"13\"><\/a>\n### Conclusion\n* I think final model accuracy and test results on validation data seems valuable.\n* Please let me know if you have any suggestions or ideas on how to improve the model and results.\n* Thanks for reading. ","e0f37ca5":"<a id=\"11\"><\/a>\n### Model Training","9c6c8728":"<a id=\"12\"><\/a>\n### Visualizing The Results","60f1f153":"<a id=\"6\"><\/a>\n### Create Convolutional Neural Network Model","c85bc1b0":"<a id=\"1\"><\/a>\n## Loading the Data Set\n* In this part we load and visualize the data."}}