{"cell_type":{"70cee69b":"code","9c2e7599":"code","876b75a7":"code","093297d1":"code","bf18413b":"code","bffe59a5":"code","90b3ec89":"code","6b25d81f":"code","5b1fee8c":"code","8b629f5a":"code","49b89f19":"code","6bc4c05b":"code","8a707927":"code","f969fbad":"code","ffe51693":"code","77c393af":"code","01c8f80d":"code","fd1e8fea":"code","918d6bb5":"code","f5dea94a":"code","1f49f268":"code","21a603eb":"code","9ad89e55":"code","86953c2c":"code","a6fb9ba8":"code","169c3ce6":"code","7ec4c3c3":"code","309c7793":"code","b7612e58":"code","e6a46a30":"code","92a5a574":"code","cd62a52b":"code","f277065f":"code","eedbc337":"code","d42f6848":"code","87453df2":"code","d43b3778":"markdown","c1d7b571":"markdown","612fdb25":"markdown","013ce3db":"markdown"},"source":{"70cee69b":"from fastai.vision.core import *\nfrom fastai.vision.data import *\nfrom fastai.vision.all import *\nfrom fastai.vision import *\nimport fastai\n\nimport matplotlib.pyplot as plt","9c2e7599":"# Making sure we are using correct version of FastAI\nfastai.__version__","876b75a7":"# The function to input the image name and get path of corresponding mask image\n\ndef label_func(x): return f'..\/input\/dataset\/train_gt\/train_gt\/{x.stem}.png'","093297d1":"# Creating batches of images with their correspoding mask \n#..\/input\/dataset\/test_images\/test_images\/image_0.jpg\nsrc = SegmentationDataLoaders.from_label_func(\"\",  # the path of the folders \n                                              get_image_files('..\/input\/dataset\/test_images\/test_images'), # get image files in train_images folder\n                                              label_func,  # get the correspsong mask\n                                              batch_tfms=aug_transforms(do_flip=True, # Data Argumentation\n                                                                        flip_vert=True, \n                                                                        max_rotate=360.0, \n                                                                        min_zoom=1.0, max_zoom=5, \n                                                                        max_lighting=0.2, max_warp=0.2, \n                                                                        p_affine=0.75, p_lighting=0.75), \n                                              \n                                              codes=np.array(['Background','Water']), # there are two classes, background and water\n                                              bs=4,# set batch size to 4\n                                              valid_pct=0.05, # seeting 5% of data to validation ( i know it's low!)\n                                              num_workers=0, # if on windows, don't change this!\n                                              shuffle_train=False)","bf18413b":"# Swowing a batch of images\n\nsrc.show_batch(max_n=9, vmin=1, vmax=30)","bffe59a5":"# Getting one batch of images and labels\n\n#x,y = src.one_batch()\n#x, y","90b3ec89":"# Setting the first image from the X\n\n#plt.imshow(x.cpu().numpy()[1,0,:,:])","6b25d81f":"# Seiing the first label from Y\n\n#plt.imshow(y.cpu().numpy()[1,:,:])","5b1fee8c":"# Using a Unet model for our image segmentation task and using mixed precision for faster training. \n\nlearn = unet_learner(src, xresnet34_deep)#.to_fp16()","8b629f5a":"# Finding a good learning rate\n\nlearn.lr_find()","49b89f19":"# Setting up WandB callback\n\nimport wandb\nfrom fastai.callback.wandb import *\n\n# 1. Start a new run\nwandb.init(project=\"water segmentation\", name  ='water segmentation reduce on plateau')\n","6bc4c05b":"# Using One Cycle Learning Rate Policy for training  \n\nlearn.fit_one_cycle(10, cbs=[WandbCallback(), \n                            SaveModelCallback(), # saving model with every new lowest val loss \n                            ReduceLROnPlateau(monitor='valid_loss', min_delta=0.2, patience=2) # Reduce lr when validation loss stops decreasing\n                            ])","8a707927":"# Saving the model\n\nlearn.export()","f969fbad":"learn = load_learner(\"..\/input\/waterdetectpickle\/export.pkl\")\n#learn.show_results()","ffe51693":"import re\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport cv2","77c393af":"# Predicting all images\n\nall_pred = []\n#img =Image.open('..\/input\/dataset\/test_images\/test_images\/image_20.jpg')\n\n#for i in img_path:\npredictions = learn.predict('..\/input\/dataset\/test_images\/test_images\/image_20.jpg')\n#predictions\nall_pred.append((predictions[0]).numpy().flatten())\n#img.show(y=predictions[0])\n\n","01c8f80d":"#img = Image.fromarray(main_array_flat, 'RGB')\n#img.save('test.png')\n#img.show()\n","fd1e8fea":"#%matplotlib inline ","918d6bb5":"#from matplotlib import pyplot as plt\n#from PIL import Image as im\n#temp = np.asarray(temp)\n\n#img = im.fromarray(temp, 'RGB')\n#plt.imshow('..\/input\/dataset\/test_images\/test_images\/image_10.jpg')\n#plt.imshow(img.reshape(400,400))#,cmap=\"gray\")\n#img.save('my.png')\n#plt.imshow(data, interpolation='nearest')\n#plt.show()","f5dea94a":"# Converting all_pred to numpy array\n\n#main_array = np.asarray(all_pred)\n\n#main_array.shape\n#img = Image.fromarray(main_array_flat, 'RGB')\n#img.save('test.png')\n#img.show()\n","1f49f268":"# Reshaping the array\n\n#main_array_flat = np.reshape(main_array,(-1))\n#array=main_array_flat\n#array.shape","21a603eb":"#print(type(main_array_flat))\n#main_array_flat.shape","9ad89e55":"#array=np.reshape(array, (400, 400))\n#print(array.shape)","86953c2c":"image_path='..\/input\/dataset\/test_images\/test_images\/image_20.jpg'\ninputimage=Image.open(image_path)\ninputimage\ntype(inputimage)\ninputimage.shape","a6fb9ba8":"\n#img =Image.open('..\/input\/dataset\/test_images\/test_images\/image_20.jpg')\npredictions = learn.predict(image_path)\n","169c3ce6":"all_pred = []\nall_pred.append((predictions[0]).numpy())\nall_pred","7ec4c3c3":"all_pred = np.asarray(all_pred)\n","309c7793":"inputimage.show(learn.predict(image_path)[0])","b7612e58":"think_np = np.array(predictions[0])\nthink_np.shape = (400,400)\nthink_np = think_np.astype(int)\nthink_np[think_np > 0] = 255\nthink_im = Image.fromarray((think_np).astype('uint8'), mode='L')\nthink_im","e6a46a30":"def generate_output(image,gt_np_array):\n   #image = image*255\n    print(image.shape)\n   # image = image.astype('uint8')\n    gt_road = gt_np_array[:,:,1]\n    gt_not_road = gt_np_array[:,:,0]\n    mask_bits = np.zeros(gt_road.shape)\n    mask_bits[gt_road > gt_not_road] = 1\n    green = np.asarray([0,255,0,127])\n    mask = np.outer(mask_bits,green).reshape(mask_bits.shape[0],-1,len(green))\n    mask = mask.astype('uint8')\n    mask = Image.fromarray(mask)\n    #image = Image.fromarray(image)\n    image.paste(mask,mask = mask)\n    image = np.array(image)\n    return image","92a5a574":"plt.figure()\nplt.imshow(generate_output(inputimage,all_pred))","cd62a52b":"inputimage","f277065f":"test_path='..\/input\/testimages\/test3_64.jpg'\ntestimage=Image.open(test_path)\ntestimage","eedbc337":"predictions1 = learn.predict(test_path)","d42f6848":"print(testimage.shape)","87453df2":"test_np = np.array(predictions1[1])\nprint(test_np)\ntest_np.shape = (1210,1465)\ntest_np = test_np.astype(int)\ntest_np[test_np > 0] = 255\ntest_im = Image.fromarray((test_np).astype('uint8'), mode='L')\ntest_im","d43b3778":"# Importing Libraries","c1d7b571":"# Making the Model","612fdb25":"# Making Predictions","013ce3db":"# Making the Dataloader\n\nIn this section, we will load all our dataset to put into the unet model"}}