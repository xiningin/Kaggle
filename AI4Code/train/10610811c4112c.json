{"cell_type":{"0730d886":"code","062527b9":"code","0f8ff320":"code","310e0a3c":"code","43d2a312":"code","5251e640":"code","84705f77":"code","3b8e1c69":"code","caf906d9":"code","5efd6357":"code","cc60cce9":"code","a55d0f08":"code","b0347c35":"code","196215be":"code","aac8b95a":"markdown","13b43d66":"markdown","f537c362":"markdown","48469e72":"markdown","4272f8ad":"markdown","360a1ae1":"markdown","310c4aad":"markdown","fd5419b5":"markdown"},"source":{"0730d886":"!pip install ..\/input\/efficientnet-pytorch\n!pip install \"..\/input\/pretrained-models\/pretrained-models.pytorch-master\"\n","062527b9":"from fastai.vision.all import *\nfrom efficientnet_pytorch import EfficientNet\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\n#import torchvision.models as pretrainedmodels","0f8ff320":"class SubmissionConfig:\n    n_tta       = 1\n    beta        = 0.25\n    models      = ['model-f0.pkl', 'model-f1.pkl', 'model-f2.pkl', 'model-f3.pkl', 'model-f4.pkl']\n    \ncfg = SubmissionConfig()","310e0a3c":"# this is only for submissions\npath_str = '..\/input\/cassava-leaf-disease-classification'\n\nsubmission_df = pd.read_csv(f'{path_str}\/sample_submission.csv')\n\nmodels_path = '..\/input\/effnetmodels\/'\ntest_images_path = f'{path_str}\/test_images\/'\ntest_data_path = submission_df['image_id'].apply(lambda x: test_images_path+x)","43d2a312":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2\n\n\nall_album = [albumentations.Resize(512,512),albumentations.Transpose(p=1.),albumentations.HorizontalFlip(p=1.),\n            albumentations.VerticalFlip(p=1.),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=1.\n            ), albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),]","5251e640":"len(all_album)-1","84705f77":"final_predictions = 0\nfor i in range(6):\n    class AlbumentationsTransform(RandTransform):\n        split_idx,order = None, 2\n    \n        def __init__(self, train_aug, valid_aug): \n            store_attr()\n    \n        def before_call(self, b, split_idx):\n            self.idx = split_idx\n    \n        def encodes(self, img: PILImage):\n            if self.idx == 0:\n                aug_img = self.train_aug(image=np.array(img))['image']\n            else:\n                aug_img = self.valid_aug(image=np.array(img))['image']\n            return PILImage.create(aug_img)\n    \n    def get_train_aug(size): \n        return albumentations.Compose([\n                all_album[0],all_album[i+1]\n    ], p=1.)\n    def get_valid_aug(size): \n        return albumentations.Compose([\n            albumentations.Resize(size, size),\n            albumentations.CenterCrop(size, size, p=1.),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n    ], p=1.), \n\n\n    def get_x(row): return images_path\/row['image_id']\n    def get_y(row): return row['label']\n    \n    \n    predictions = 0\n\n    for model in cfg.models:\n        learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n        learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n        learn.cbs.pop(3) # remove wandb\n        learn.cbs.pop(3) # remove cutmix\n        learn.cbs.pop(3) # remove savemodel callback\n    \n        learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n        predictions += learn_predictions[0]\n\n    \n\n    predictions = predictions \/ len(cfg.models)\n    final_predictions += predictions\n    \nfinal_predictions = final_predictions\/(len(all_album)-1)\n\n    \n    ","3b8e1c69":"path_str = '..\/input\/cassava-leaf-disease-classification'\n\nmodels_path = '..\/input\/resnextmodels\/'\ntest_images_path = f'{path_str}\/test_images\/'\n#test_data_path = submission_df['image_id'].apply(lambda x: test_images_path+x)","caf906d9":"final_predictions_resnext = 0\nfor i in range(4):\n    class AlbumentationsTransform(RandTransform):\n        split_idx,order = None, 2\n    \n        def __init__(self, train_aug, valid_aug): \n            store_attr()\n    \n        def before_call(self, b, split_idx):\n            self.idx = split_idx\n    \n        def encodes(self, img: PILImage):\n            if self.idx == 0:\n                aug_img = self.train_aug(image=np.array(img))['image']\n            else:\n                aug_img = self.valid_aug(image=np.array(img))['image']\n            return PILImage.create(aug_img)\n    \n    def get_train_aug(size): \n        return albumentations.Compose([\n                all_album[0],all_album[i+1]\n    ], p=1.)\n    def get_valid_aug(size): \n        return albumentations.Compose([\n            albumentations.Resize(size, size),\n            albumentations.CenterCrop(size, size, p=1.),\n    ], p=1.)\n\n\n    def get_x(row): return images_path\/row['image_id']\n    def get_y(row): return row['label']\n    \n    \n    predictions = 0\n\n    for model in cfg.models:\n        learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n        learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n        learn.cbs.pop(3) # remove wandb\n        learn.cbs.pop(3) # remove cutmix\n        learn.cbs.pop(3) # remove savemodel callback\n    \n        learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n        predictions += learn_predictions[0]\n\n    \n\n    predictions = predictions \/ len(cfg.models)\n    final_predictions_resnext += predictions\n    \nfinal_predictions_resnext = final_predictions_resnext\/(len(all_album)-1)\n    ","5efd6357":"final_final_predictions = 0.5*final_predictions + 0.5*final_predictions_resnext\n\n","cc60cce9":"\"\"\"\nclass AlbumentationsTransform(RandTransform):\n    split_idx,order = None, 2\n    \n    def __init__(self, train_aug, valid_aug): \n        store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)\n    \ndef get_train_aug(size): \n    return albumentations.Compose([\n            albumentations.RandomResizedCrop(size,size),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n], p=1.)\ndef get_valid_aug(size): \n    return albumentations.Compose([\n        albumentations.Resize(size, size),\n        albumentations.CenterCrop(size, size, p=1.),\n], p=1.)\n\n\ndef get_x(row): return images_path\/row['image_id']\ndef get_y(row): return row['label']\n\"\"\"","a55d0f08":"\"\"\"\npredictions = 0\n\nfor model in cfg.models:\n    learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n    learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n    learn.cbs.pop(3) # remove wandb\n    learn.cbs.pop(3) # remove cutmix\n    learn.cbs.pop(3) # remove savemodel callback\n    \n    learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n    predictions += learn_predictions[0]\n\n    \n# average the predictions\npredictions = predictions \/ len(cfg.models)\n\"\"\"","b0347c35":"submission_df['label'] = np.argmax(final_final_predictions, axis=1)\nsubmission_df.to_csv('submission.csv', index=False)","196215be":"submission_df","aac8b95a":"# Augmentations for inference ","13b43d66":"## For Resext\n","f537c362":"## For Efficient Net","48469e72":"# Submit","4272f8ad":"# Prediction loop","360a1ae1":"# Submission setup\n\nCreating paths and CFG for use","310c4aad":"# Inference notebook (only for submissions)","fd5419b5":"# ALL COMBINED[](http:\/\/)"}}