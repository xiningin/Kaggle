{"cell_type":{"fd1f9390":"code","3f6cc816":"code","29021f95":"code","a39c3eb7":"code","3d084274":"code","9aa9ada7":"code","8f30995e":"code","285c17a5":"code","d5d0ef3e":"code","014d3339":"code","f06133b8":"code","3ac58374":"code","b91b4b50":"code","c4d6e4cc":"code","b8b3740b":"code","c64d8aa2":"code","7e66fe31":"code","ca7556eb":"code","2b022b6b":"code","db50203f":"code","94628e53":"code","b9f28000":"code","8d6f7186":"code","392ddbdb":"code","e35efb9c":"code","d2c02be3":"code","14258b62":"code","65e856ad":"code","d919f754":"code","a1389f3c":"code","51c840c6":"code","c7f73ae1":"code","aefed529":"code","412845d7":"code","ff0d99f8":"code","a2066e51":"markdown","39736c68":"markdown","e1943245":"markdown","08d5ec9d":"markdown","6b6648cf":"markdown","544c6a04":"markdown","43aba93d":"markdown","3911fb1a":"markdown","152444b8":"markdown","2745d671":"markdown"},"source":{"fd1f9390":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing","3f6cc816":"raw_data = pd.read_csv('..\/input\/life-expectancy-who\/Life Expectancy Data.csv')\nraw_data.head()","29021f95":"raw_data.describe(include='all')","a39c3eb7":"raw_data.isnull().sum()","3d084274":"# Checking why and which countries has null value for alcohol\nnull_alcohol = raw_data[raw_data[\"Alcohol\"].isnull()]\n#alcohol_na = raw_data.query('Alcohol == 0')\n#alcohol_na\nnull_alcohol","9aa9ada7":"null_bmi = raw_data[raw_data[\" BMI \"].isnull()]\nnull_bmi","8f30995e":"## Turns out only Sudan and South Sudan do not report the BMI. We can use imputation for Monaco and San Marino from\n## previous years because only one year missing from those countries. I will drop Sudan and South Sudan from the data","285c17a5":"## Question: Does Life Expectancy have positive or negative relationship with drinking alcohol?\n## Data is missing for almost every country in 2015, so I will drop the 2015 from the data\nis_2015 = raw_data[raw_data[\"Year\"]==2015].index\nis_2015\ndata_wo_2015 = raw_data.drop(is_2015)\ndata_wo_2015","d5d0ef3e":"## South Sudan does not have any Alcohol data, so I will drop South Sudan completely\nis_s_sudan = data_wo_2015[data_wo_2015[\"Country\"]==\"South Sudan\"].index\nis_s_sudan\ndata_alcohol = data_wo_2015.drop(is_s_sudan)\ndata_alcohol","014d3339":"data_alcohol.isnull().sum()","f06133b8":"data_1 = data_alcohol[data_alcohol['Life expectancy '].isnull()].index\ndata_1","3ac58374":"data_2 = data_alcohol.drop(data_1) \ndata_2","b91b4b50":"na_bmi = data_2[data_2[\" BMI \"].isnull()].index\nna_bmi","c4d6e4cc":"data_3 = data_2.drop(na_bmi)\ndata_3","b8b3740b":"data_3.isnull().sum()","c64d8aa2":"data_4 = data_3[data_3['Alcohol'].isnull()].index\ndata_4","7e66fe31":"data_clean = data_3.drop(data_4)\ndata_clean.isnull().sum()","ca7556eb":"data_clean['Status'].unique()","2b022b6b":"# Transform to categorical data to numerical data, 1 stands for \"Developed countries, and 0 for \"developing countries\ndata_clean[\"Status\"] = data_clean[\"Status\"].map({'Developed':1,'Developing':0})","db50203f":"data_clean['Status'].unique()","94628e53":"## Dropping multiple columns at the same time. I do not need year info for my DL model, no need for county name either","b9f28000":"to_drop = ['Country','Year', \"Hepatitis B\", \"Polio\", \"Total expenditure\", \"Diphtheria \", \"GDP\", \"Population\", \"Income composition of resources\",\"Schooling\"]\ndata_clean.drop(to_drop, inplace=True, axis=1)\n\n#passing in the inplace parameter as True and the axis parameter as 1. This tells Pandas that we want the changes to be made directly in our object and that it should look for the values to be dropped in the columns of the object.","8d6f7186":"#include='all' shows all the data not only numerical\ndata_clean.describe(include='all')","392ddbdb":"data_clean.isnull().sum()","e35efb9c":"targets_csv = data_clean['Life expectancy ']\ninputs_csv = data_clean.drop(['Life expectancy '], axis=1)","d2c02be3":"targets_csv.head()","14258b62":"inputs_csv.head()","65e856ad":"targets_csv.to_csv('target_csv.csv',header=False,index=False)","d919f754":"inputs_csv.to_csv('inputs_csv.csv',header=False,index=False)","a1389f3c":"unscaled_inputs = np.loadtxt(\"inputs_csv.csv\", delimiter = ',')\ntargets = np.loadtxt(\"target_csv.csv\", delimiter=',')","51c840c6":"print(targets.shape[0])\nprint(unscaled_inputs.shape[0])","c7f73ae1":"scaled_inputs = preprocessing.scale(unscaled_inputs)","aefed529":"shuffled_indicies = np.arange(scaled_inputs.shape[0])\nnp.random.shuffle(shuffled_indicies)\n\nshuffled_inputs = scaled_inputs[shuffled_indicies]\nshuffled_targets = targets[shuffled_indicies]","412845d7":"samples_count = shuffled_inputs.shape[0]\ntrain_samples_count = int(0.8*samples_count)\nvalidation_samples_count = int(0.1*samples_count)\ntest_samples_count = samples_count - train_samples_count - validation_samples_count\n\ntrain_inputs = shuffled_inputs[:train_samples_count]\ntrain_targets = shuffled_targets[:train_samples_count]\n\nvalidation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\nvalidation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n\ntest_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\ntest_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n\n## Check if we seperated them correctly\n\nprint(samples_count)\nprint(train_samples_count)\nprint(validation_samples_count)\nprint(test_samples_count)\n","ff0d99f8":"np.savez('life_expectancy_data_train',inputs= train_inputs, targets=train_targets)\nnp.savez('life_expectancy_data_validation', inputs=validation_inputs, targets=validation_targets)\nnp.savez('life_expectancy_data_test',inputs=test_inputs,targets=test_targets)","a2066e51":"### Split the data into train, validation and test","39736c68":" #Checking why there are 34 missing data in BMI","e1943245":"## Life Expectancy Multilinear Regression","08d5ec9d":"### Standardize the inputs\n","6b6648cf":"### Saving the three datasets in *.npz","544c6a04":"### Cleaning the data","43aba93d":"### Upload the dataset","3911fb1a":"### Upload data","152444b8":"### Shuffle the data","2745d671":"### Saving the cleaned data set as csv "}}