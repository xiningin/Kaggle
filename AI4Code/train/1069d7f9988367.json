{"cell_type":{"f3e9ccab":"code","6c89b1a2":"code","af90517f":"code","f2ce8759":"code","67b1d012":"code","5c865a24":"code","af0ac896":"code","21f2656d":"code","718c9eb6":"code","36797790":"code","16c4a8f7":"markdown","21d02b8d":"markdown","fde274b7":"markdown","86f62d68":"markdown","624b05b6":"markdown","81bcc377":"markdown","f3b353c0":"markdown","1c69b006":"markdown","807b9f61":"markdown"},"source":{"f3e9ccab":"!pip install faiss-cpu\n!pip install -U sentence-transformers","6c89b1a2":"import numpy as np\nimport torch\nimport os\nimport pandas as pd\nimport faiss\nimport time\nfrom sentence_transformers import SentenceTransformer","af90517f":"documents = [\n    \"Pet Store\",\n    \"food store\",\n    \"cat Store\"\n]","f2ce8759":"model = SentenceTransformer('sentence-transformers\/all-MiniLM-L6-v2')","67b1d012":"model","5c865a24":"encoded_data = model.encode(documents)","af0ac896":"index = faiss.IndexIDMap(faiss.IndexFlatIP(model.get_sentence_embedding_dimension()))\nindex.add_with_ids(encoded_data, np.array(range(0, len(documents))))","21f2656d":"# Serializing Index to export it across different host\nfaiss.write_index(index, 'sample_documents')\n# De-serializing the index\nindex = faiss.read_index('sample_documents')","718c9eb6":"def search(query):\n    t=time.time()\n    query_vector = model.encode([query])\n    # Search for top k results\n    k = 1\n    top_k = index.search(query_vector, k)\n    print('totaltime: {}'.format(time.time()-t))\n    return [documents[_id] for _id in top_k[1].tolist()[0]]","36797790":"query=\"Dog store\"\nresults=search(query)\nprint('results :')\nfor result in results:\n    print('\\t',result)","16c4a8f7":"# Introduction\n\nSemantic search means search with meaning or context. It is useful in sentence\/phrase matching application at scale. Usually, Inference is requested for single sentence or in batches but, it still doesn't beat the purpose of matching a phrase with existing corpus of million (let's say) documents.\n\nJust imagine, How troublesome that inference would be! That's why, in this article, we are going to implement a semantic search using HuggingFace [sentence-transformers](https:\/\/www.sbert.net\/) model ([all-MiniLM-L6-v2](https:\/\/huggingface.co\/sentence-transformers\/all-MiniLM-L6-v2)) and [FAISS](https:\/\/pypi.org\/project\/faiss\/)\n\n\n**About FIASS**\n\nFaiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python\/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed by Facebook AI Research.","21d02b8d":"# Implementation","fde274b7":"## 4. Loading the pre-trained model\n\n[Usage Guide](https:\/\/huggingface.co\/sentence-transformers\/all-MiniLM-L6-v2#usage-sentence-transformers) for reference","86f62d68":"## 2. Imports","624b05b6":"## 7. Search from index","81bcc377":"## 3. Create or Load a corpus","f3b353c0":"## 6. Perform semantic similarity","1c69b006":"## 5. Create index for your corpus\n[Guidelines to choose an index](https:\/\/github.com\/facebookresearch\/faiss\/wiki\/Guidelines-to-choose-an-index). Create index and add your corpus\/data to it.","807b9f61":"## 1. Installed required libraries"}}