{"cell_type":{"309780f1":"code","03c63750":"code","4a720bb8":"code","629c8452":"code","42e3a995":"code","d77e3318":"code","665c5684":"code","142f85e9":"code","c5a7a425":"code","fc9429fb":"code","63398561":"code","51bb48e6":"code","9a0e46ef":"code","ebd10c04":"code","68e6218f":"code","fbfb4175":"code","83c6262f":"code","5e2ec595":"markdown","a03888f6":"markdown"},"source":{"309780f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03c63750":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report,accuracy_score\nwarnings.filterwarnings(\"ignore\")","4a720bb8":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf.head()","629c8452":"df.isna().sum()","42e3a995":"df.duplicated().sum()","d77e3318":"plt.figure(figsize=(20,15))\nsns.boxplot(data=df)\nplt.show()","665c5684":"df.describe()","142f85e9":"sns.displot(df['age'],kde=True,color='orange',label=\"Total\")","c5a7a425":"male = df[df['sex']==1]\nfemale = df[df['sex']==0]\nmale_survived = male[df['DEATH_EVENT']==1]\nmale_unsurvived = male[df['DEATH_EVENT']==0]\nfemale_survived = female[df['DEATH_EVENT']==1]\nfemale_unsurvived = female[df['DEATH_EVENT']==0]\nlabels = ['male_survived','male_not','female_survived','female_not']\nfeature = [len(male_survived),len(male_unsurvived),len(female_survived),len(female_unsurvived)]\nplt.pie(feature,labels=labels,autopct='%.0f%%',startangle=0,pctdistance=1.2,labeldistance=1.4)\nplt.title(\"Survival percentage - Gender wise\")\nplt.show()","fc9429fb":"Features = ['time','ejection_fraction','serum_creatinine','age','diabetes']\nX = df[Features]\ny = df['DEATH_EVENT']","63398561":"plt.figure(figsize=(20,15))\nsns.set(style=\"dark\")\ncorr = df.corr()\nmask = np.zeros_like(corr,dtype=np.bool)\nsns.heatmap(corr,mask=mask,vmax=3,center=0,square=True,linewidths=0.5,annot=True)\nplt.show()","51bb48e6":"accuracy_list=[]\nmodels=[]\ndef model_fit(X,y,algorithm,gridSearchParams,cv):\n  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n  grid = GridSearchCV(estimator = algorithm,param_grid=gridSearchParams,cv=cv,scoring=\"accuracy\",verbose=1,n_jobs=-1)\n  gridresult = grid.fit(X_train,y_train)\n  best_params = gridresult.best_params_\n  pred = gridresult.predict(X_test)\n  print(\"Classification Report :\", classification_report(y_test,pred))\n  model_acc = accuracy_score(y_test,pred)\n  accuracy_list.append(100*model_acc)","9a0e46ef":"#Logistic Regression\npenalty = ['l1','l2']\nC = np.logspace(0,4,10)\nhyperparameters = dict(C=C,penalty=penalty)\nmodel_fit(X,y,LogisticRegression(),hyperparameters,cv=5)","ebd10c04":"#RandomForestClassifier\nparam = {\n    'n_estimators':[100,500,1000,2000]\n    ,\n}\nmodel_fit(X,y,RandomForestClassifier(),param,cv=5)","68e6218f":"#SupportVectorMachine\nparam = {\n    'C':[0.1,1,10,100],\n    'gamma':[1,0.1,0.01,0.001,0.0001],\n}\nmodel_fit(X,y,SVC(),param,cv=5)","fbfb4175":"#KNN\nparams = {'n_neighbors':[4,5,6,7],\n              'leaf_size':[1,3,5],\n              'algorithm':['auto', 'kd_tree'],\n              'n_jobs':[-1]}\nmodel_fit(X,y,KNeighborsClassifier(),params,cv=5)","83c6262f":"#Comparison\nmodels=['LogisticRegression','RandomForestClassifier','SupportVectorMachine','KNN']\nplt.figure(figsize=(15,6))\nax=sns.barplot(x=models, y=accuracy_list, palette = \"husl\", saturation =2.0)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.xlabel(\"Classifiers\")\nplt.ylabel(\"Percentages\")\nplt.title(\"Classifier Algorithm comparison\")\nfor i in ax.patches:\n    width, height = i.get_width(), i.get_height()\n    x, y = i.get_xy() \n    ax.annotate(f'{round(height,2)}%', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()\nplt.show()","5e2ec595":"EDA","a03888f6":"Model Fitting"}}