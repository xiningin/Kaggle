{"cell_type":{"25094e23":"code","e4ac5e6a":"code","4374f5e2":"code","56b2c88f":"code","96c7aa50":"code","dba918ab":"code","48a4618e":"code","b8fd29d7":"code","3fbb5cdf":"code","5614bb24":"code","87d0de40":"code","1d6ce3c2":"code","dd547847":"code","715fb73c":"code","931c3f17":"code","a1d21ec4":"code","75b6fd77":"code","0cdfb589":"code","ce9e76b4":"code","84247bfa":"code","203267f0":"code","837f26df":"code","f462d0b9":"code","482913cd":"code","0ae5330d":"code","db5369ef":"code","fe367c1e":"code","391d08c5":"code","042f43bf":"code","0099c8ad":"code","76129e08":"code","d4a59adc":"code","e7e72086":"code","c713f99e":"code","18961192":"code","fd357916":"code","59946c4f":"code","0ec7aefd":"markdown","c65e932f":"markdown","bcdad04a":"markdown","1d08f4a7":"markdown","8d996308":"markdown","f0d91110":"markdown","52d2b3cd":"markdown","ff825218":"markdown","fa9e2b18":"markdown","05945277":"markdown","9df27db0":"markdown","2bcf29fb":"markdown","eaa202b4":"markdown","7e98e0e0":"markdown","ac84e35d":"markdown","ebce1ef9":"markdown","673a72af":"markdown","fcb9d52f":"markdown","ce9cf942":"markdown","877695e0":"markdown","becb0f19":"markdown","329fad76":"markdown","5b8af99c":"markdown","d95d3818":"markdown","432b3045":"markdown","1bfa2b82":"markdown","7c66b3a4":"markdown"},"source":{"25094e23":"!pip install tensorflow-gpu -q","e4ac5e6a":"import tensorflow as tf\ntf.__version__","4374f5e2":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv\n\nnp.set_printoptions(precision=7)\n%matplotlib inline\n\nimport tensorflow_datasets as tfds\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom collections import Counter\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing import image\n\nfrom PIL import Image","56b2c88f":"import os\nimport errno\n\n\ntry:\n    data_dir = 'dataset'\n    os.mkdir(data_dir)\nexcept OSError as e:\n    if e.errno == errno.EEXIST:\n        print('Directory  created.')\n    else:\n        raise","96c7aa50":"dataset_name = \"cifar10\"\n","dba918ab":"(train_set, test_set), dataset_info =  tfds.load( \n              name=dataset_name, \n              split=[\"train\", \"test\"], \n              with_info=True, \n              data_dir=data_dir\n          )","48a4618e":"print(dataset_info)","b8fd29d7":"class_names =  dataset_info.features[\"label\"].names\n\nprint('image shape    :', dataset_info.features['image'].shape)\nprint('image dtype    :', dataset_info.features['image'].dtype)\nprint()\nprint('num class      : ',dataset_info.features[\"label\"].num_classes)\nprint('class label    :', dataset_info.features[\"label\"].names)\nprint()\nprint('num train data :', dataset_info.splits[\"train\"].num_examples)\nprint('num test data  :', dataset_info.splits[\"test\"].num_examples)","3fbb5cdf":"fig = tfds.show_examples(train_set, dataset_info)","5614bb24":"input_shape = (80, 80, 3)","87d0de40":"X_train = []\ny_train = []\n\nfor example in tfds.as_numpy(train_set):\n    new_img = example['image']\n    new_img = cv.resize(new_img, input_shape[:2],interpolation = cv.INTER_AREA) \n    X_train.append(new_img)\n    y_train.append(example['label'])\n\ndel train_set","1d6ce3c2":"X_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\n\nprint('X_train.shape =',X_train.shape)\nprint('y_train.shape =',y_train.shape)","dd547847":"X_test = []\ny_test = []\n\nfor example in tfds.as_numpy(test_set):\n    new_img = example['image']\n    new_img = cv.resize(new_img, input_shape[:2],interpolation = cv.INTER_AREA) \n    X_test.append(new_img)\n    y_test.append(example['label'])\n\ndel test_set","715fb73c":"X_test = np.asarray(X_test)\ny_test = np.asarray(y_test)\n\nprint('X_test.shape =',X_test.shape)\nprint('y_test.shape =',y_test.shape)","931c3f17":"X_val   = X_train[-300:]\ny_val   = y_train[-300:]\n\nX_train = X_train[:-300]\ny_train = y_train[:-300]","a1d21ec4":"print('X_train.shape =',X_train.shape)\nprint('y_train.shape =',y_train.shape)\n\nprint('\\nX_val.shape  =',X_val.shape)\nprint('y_val.shape  =',y_val.shape)\n\nprint('\\nX_test.shape  =',X_test.shape)\nprint('y_test.shape  =',y_test.shape)","75b6fd77":"y_train_hot = to_categorical(y_train, 102)\ny_val_hot   = to_categorical(y_val, 102)\ny_test_hot  = to_categorical(y_test, 102)\n\nprint('y_train_hot.shape =',y_train_hot.shape)\nprint('y_val_hot.shape   =',y_val_hot.shape)\nprint('y_test_hot.shape  =',y_test_hot.shape)","0cdfb589":"model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(80, 80, 3))","ce9e76b4":"x = model.layers[-1].output\nx = GlobalAveragePooling2D() (x)\npredictions = Dense(102, activation='softmax') (x)\n\nmyModel = Model(inputs=model.input, outputs=predictions)","84247bfa":"myModel.summary()","203267f0":"plot_model(model, show_shapes=True,\n    show_layer_names=False,\n    rankdir='LR',\n    expand_nested=False,\n    dpi=60\n)","837f26df":"myModel.compile(\n      loss='categorical_crossentropy',\n      optimizer=tf.keras.optimizers.Adam(), \n      metrics=['accuracy']\n  )","f462d0b9":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    channel_shift_range=0.1,\n    horizontal_flip=True\n)","482913cd":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\ndef lr_schedule(epoch):\n    lr = 1e-3\n    if (epoch > 30):\n        lr *= 0.01\n    elif (epoch > 20):\n        lr *= 0.1\n    return lr\n\nlr_callback = LearningRateScheduler(lr_schedule)\n\nmyCheckpoint = ModelCheckpoint(filepath='.\/dataset\/my_model.h5', \n                               monitor='val_accuracy',\n                               save_best_only=True,\n                              )","0ae5330d":"history_all = []","db5369ef":"batch_size = 64\nepochs = 12","fe367c1e":"augmented_train = datagen.flow(\n    X_train, y_train_hot, batch_size\n)\n\nhistory = myModel.fit(\n    augmented_train,\n    validation_data=(X_val, y_val_hot),\n    epochs=epochs, \n    steps_per_epoch=len(X_train)\/64,\n    callbacks=[lr_callback, myCheckpoint],\n    verbose=2)\n\nhistory_all.append(history)","391d08c5":"plt.rcParams['figure.figsize'] = [7, 5]\n\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='val')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n","042f43bf":"hist_train = []\nhist_val = []\n\nfor h in history_all:\n    hist_train.append(h.history['accuracy'][1:])\n    hist_val.append(h.history['val_accuracy'][1:])","0099c8ad":"hist_train = np.array(hist_train).reshape(-1)\nhist_val = np.array(hist_val).reshape(-1)","76129e08":"plt.rcParams['figure.figsize'] = [7, 5] \n\nplt.plot(hist_train, label='train')\nplt.plot(hist_val, label='val')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n","d4a59adc":"myModel.load_weights('.\/dataset\/my_model.h5')\nscores = myModel.evaluate(X_test, y_test_hot)","e7e72086":"print('Test loss    :', scores[0])\nprint('Test accuracy: %.2f%%' % (scores[1]*100))","c713f99e":"train_scores = myModel.evaluate(X_train, y_train_hot)\ntest_scores  = myModel.evaluate(X_test, y_test_hot)\nval_scores   = myModel.evaluate(X_val, y_val_hot)","18961192":"print('Train Loss: %.5f with Accuracy: %.1f%%' % (train_scores[0], (train_scores[1]*100)))\nprint('Test  Loss: %.5f with Accuracy: %.1f%%' % (test_scores[0], (test_scores[1]*100)))\nprint('Val   Loss: %.5f with Accuracy: %.1f%%' % (val_scores[0], (val_scores[1]*100)))","fd357916":"!wget -O 'data_test_0.jpg' 'https:\/\/scx1.b-cdn.net\/csz\/news\/800\/2018\/2-dog.jpg' \n!wget -O 'data_test_1.jpg' 'https:\/\/static.toiimg.com\/thumb\/msid-67586673,width-800,height-600,resizemode-75,imgsize-3918697,pt-32,y_pad-40\/67586673.jpg'\n!wget -O 'data_test_2.jpg' 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/0c\/Green_tree_frog.jpg\/799px-Green_tree_frog.jpg'\n!wget -O 'data_test_3.jpg' 'https:\/\/bsmedia.business-standard.com\/_media\/bs\/img\/article\/2019-10\/15\/full\/1571086349-8577.jpg'\n!wget -O 'data_test_4.jpg' 'https:\/\/www.om.org\/img\/h55955_42-62.jpg'","59946c4f":"for i in range(5):\n  new_img = Image.open('data_test_'+str(i)+'.jpg')\n  new_img = np.array(new_img)\n  new_img2 = cv.resize(new_img, input_shape[:2], interpolation=cv.INTER_AREA)\n  plt.imshow(new_img2)\n  plt.axis('off')\n  plt.show()\n\n  new_img2 = np.expand_dims(new_img2,0).astype(np.float64)\n  pred = myModel.predict(new_img2)\n  class_id = np.argmax(pred)\n  print('predicted id',class_id)\n  print('class prediction', class_names[class_id])","0ec7aefd":"# Import Libraries","c65e932f":"\n## Import other libraries\n","bcdad04a":"\n## Install TensorFlow 2\n","1d08f4a7":"---\n# Test the image from the internet \n","8d996308":"# Preprocess Image\n\nConvert and Resize Dataset to Numpy","f0d91110":"### Detailed Information","52d2b3cd":"## Create Directory for Dataset","ff825218":"# Re-Evaluate Model\n","fa9e2b18":"\n## Download Dataset\n","05945277":"## Plot Current History Training","9df27db0":"## Choose Dataset Cifar10","2bcf29fb":"---\n# Data Augmentation","eaa202b4":"### Convert Data Train","7e98e0e0":"## Create Model\n\n Using inception-resnet-v2","ac84e35d":"## Visualize Model","ebce1ef9":"# Train the Model","673a72af":"## Show Images","fcb9d52f":"---\n# Classification Model","ce9cf942":"# Evaluate Model\n","877695e0":"## Compile Model\n\n","becb0f19":"#  Callbacks\n* Checkpoint\n* Learning Rate Annealing","329fad76":"## Dataset Information","5b8af99c":"# One hot y labels","d95d3818":"---\n# TFDS Datasets\n","432b3045":"### Convert Data Test","1bfa2b82":"## Split Data Train into Train and Val","7c66b3a4":"## Plot All History Training"}}