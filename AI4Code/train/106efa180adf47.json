{"cell_type":{"ee33a357":"code","84f70bcb":"code","fa4e57ae":"code","667e6d99":"code","d772f46f":"code","c3e31fc5":"code","9514fe89":"code","1a7eac75":"code","8c555476":"code","0e7a30a8":"code","0d9535b0":"code","6b2b79a5":"code","fcfd746b":"code","98ca8fa3":"code","20c86800":"code","851a26e3":"code","b621cef5":"code","000d45f6":"code","22889c19":"code","6beddf5a":"code","bd3f110d":"code","806edb7b":"code","6814fa39":"code","aa3b2e1d":"code","4c6359f2":"code","4f89347a":"code","0375cf20":"code","d29b23ef":"code","e2a744bb":"code","ec7e6742":"code","f92ca4f7":"code","2e8b95bd":"code","120a9506":"code","1f55ffdf":"code","f1a47e68":"markdown","d66572ef":"markdown","cab497ba":"markdown","5bf4abe9":"markdown","c5a4c690":"markdown","5ffd516c":"markdown","247fa392":"markdown","3d2d121b":"markdown","f68bf77e":"markdown","5528abfd":"markdown","785fd041":"markdown","4a15fb6e":"markdown","0c8b4165":"markdown","15e220d8":"markdown","51ddace6":"markdown","4a2b1118":"markdown","401853c8":"markdown","7bf6abcd":"markdown","0881fe69":"markdown","4688ad49":"markdown","efdbb184":"markdown","1205d8bd":"markdown","b11cd621":"markdown","3bbe578c":"markdown","e58d75fd":"markdown","1f8d7058":"markdown","6fb06662":"markdown","28a8207d":"markdown","6c272a9e":"markdown","a3f17c95":"markdown","d20a6eb1":"markdown","1c0856fc":"markdown","70308126":"markdown","f6cae08b":"markdown","51f2827f":"markdown"},"source":{"ee33a357":"# Import libraries and packages\nimport numpy as np\nimport pandas as pd\n\n# Machine Learning and Plotting\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\n# Library to handle JSON files\nimport json\nimport requests \nfrom pandas.io.json import json_normalize\n\n# Maps visualization\nimport folium\n\n# Address to geographical data\nfrom geopy.geocoders import Nominatim\n\n# Web Scraping and Reading HTML files\nfrom bs4 import BeautifulSoup\n\n# Used with lists\nimport itertools\n\n# To add delay between quries\nimport time\n\n# Useful packages that we will use while clustering neighbourhoods\nfrom scipy.spatial.distance import cdist\nfrom sklearn import metrics\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.colors as colors\n\n# To Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"IMPORT STATUS:\\t DONE.\")","84f70bcb":"# Get HTML file of Berlin Neighbourhoods\nBerlin_neighbourhoods_html = requests.get('https:\/\/en.wikipedia.org\/wiki\/Boroughs_and_neighborhoods_of_Berlin').text\npage = BeautifulSoup(Berlin_neighbourhoods_html, 'lxml')\n\n# Check Webpage Title\nprint('1. Webpage Title: \\n----------------------\\n{} \\n \\n'.format(page.title.text))\n\n# Find the first table in the webpage\ntable = page.find('table')\n\n# Create a DataFrame for Boroughs in Berlin\nBerlin_boroughs = pd.DataFrame()\n\n# Assign the retrived table to a list\ndata_list = pd.read_html(str(table))\n\n# Copy retrived data to the Berlin_boroughs DataFrame\nBerlin_boroughs = data_list[0]\n\n# Rename Columns and drop the Map column\nBerlin_boroughs.drop(['Map'], axis =1, inplace=True)\nBerlin_boroughs.columns = ['Boroughs', 'Population', 'Area', 'Density']\n\nprint('2. DataFrame Shape:\\n----------------------\\n', Berlin_boroughs.shape,'\\n \\n')\nBerlin_boroughs","fa4e57ae":"# In order to search for Borough Coordinates\ngeolocator = Nominatim(user_agent=\"Berlin_Maps\")\n\n# Create empty lists to store lonitude and latitude values\nlat = []\nlng = []\n\n# Add Latitude and Longitude values of each Borough to the DataFrame\nfor borough in Berlin_boroughs.itertuples():\n    Berlin_location = geolocator.geocode('{}, Berlin'.format(Berlin_boroughs['Boroughs'][borough.Index]))\n    lat.insert(borough.Index, Berlin_location.latitude)\n    lng.insert(borough.Index, Berlin_location.longitude)\n    \nBerlin_boroughs['Latitude'] = lat\nBerlin_boroughs['Longitude'] = lng\n\nBerlin_boroughs.head()","667e6d99":"# Get all table titles from the page\nall_names = page.find_all('dt')\nall_tables = page.find_all('table')\n\n# Create a DataFrame for all Neighbourhoods\nBerlin_neighbourhoods = pd.DataFrame()\n\n# Create a DataFrame for all Neighbourhoods in Berlin\nfor boroughs in Berlin_boroughs.itertuples():\n    index = boroughs.Index\n    # Get the Borough Name, and remove the first word from the string\n    Borough_name = str(all_names[index].text).split(' ')[1]\n\n    # Create a temp list of DataFrames and add the Neighbourhood data to it\n    temp_list = pd.read_html(str(all_tables[index + 2]))\n    temp_list[0]['Borough'] = Borough_name\n    Berlin_neighbourhoods = Berlin_neighbourhoods.append(temp_list[0], ignore_index=True)\n\n# Check DataFrame Size \nprint('DataFrame Shape:\\n----------------------\\n{}\\n\\n'.format(Berlin_neighbourhoods.shape))\n\n# Check the first 10 Neighbourhoods\nBerlin_neighbourhoods.head(10)","d772f46f":"# First, drop the Map Column\nBerlin_neighbourhoods.drop(['Map'], axis =1, inplace=True)\n\n# Rename columns\nBerlin_neighbourhoods.columns = ['Neighbourhood', 'Area', 'Population', 'Density', 'Borough']\n\n# Remove brackets in Neighbourhood names\nfor name in Berlin_neighbourhoods.itertuples():\n    index = int(name.Index)\n    Berlin_neighbourhoods.at[index, 'Neighbourhood'] = str(Berlin_neighbourhoods.at[index, 'Neighbourhood']).split(' ')[1]\n    \n# Check the first 5 Neighbourhoods\nBerlin_neighbourhoods.head()","c3e31fc5":"# Add Latitude and Longitude to the DataFrame\n\n# In order to search for Borough Coordinates\ngeolocator = Nominatim(user_agent=\"Berlin_Data\")\n\n# Create empty lists for lat, lng values\nlat = []\nlng = []\n\n\n# Add Latitude and Longitude values of each Borough to the DataFrame\nfor neighbourhood in Berlin_neighbourhoods.itertuples():\n    # Set index\n    index = int(neighbourhood.Index)\n    \n    try:\n        # Get address and save it, use Borough name as well instead of neighbourhood only\n        Berlin_location = geolocator.geocode('{},{}, Berlin'.format(Berlin_neighbourhoods.at[index, 'Neighbourhood'],\n                                                                    Berlin_neighbourhoods.at[index, 'Borough']))\n    except: \n        print('This generally occurs due to a timeout error from geolocator side, try again.')\n        \n    \n    # Insert new data\n    lat.insert(index, Berlin_location.latitude)\n    lng.insert(index, Berlin_location.longitude)\n\n# Add New columns with extracted values\nBerlin_neighbourhoods['Latitude'] = lat\nBerlin_neighbourhoods['Longitude'] = lng\n\n# Examine the data\nBerlin_neighbourhoods.head()","9514fe89":"# @hidden_cell\n\nCLIENT_ID = 'HIE5ISYEZQEQPNSVGQGRWCJMXA43OC3MBRHICDU01GF1P0EA' # your Foursquare ID\nCLIENT_SECRET = 'DK3E0ME2RXUUXAOX54VSSULBVYBUJWUD4BRVAQIJMV2ZIG54' # your Foursquare Secret\nVERSION = '20190701' # Foursquare API version","1a7eac75":"# Returns a DataFrame with Venue details\ndef getNearbyVenues(names, latitudes, longitudes, radius, LIMIT):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        # create the API request URL\n        url = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighbourhood', \n                  'Neighbourhood Latitude', \n                  'Neighbourhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)","8c555476":"# Returns a DataFrame with top venues based on a threshold\ndef return_top_venues(row, maximum_venues):\n    \n    # Select all except neighbourhood column\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0: maximum_venues]","0e7a30a8":"# Try to fetch Berlin Venues data\ntry:\n    Berlin_venues = getNearbyVenues(Berlin_neighbourhoods['Neighbourhood'],\n                                        Berlin_neighbourhoods['Latitude'],\n                                        Berlin_neighbourhoods['Longitude'],\n                                        radius=2000,\n                                        LIMIT=100)\nexcept:\n    print('Error fetching data, could be caused by exceeding Forsquare maximum calls\/ day.')\n\n# View the DataFrame\nBerlin_venues.head()","0d9535b0":"print('Total venues found:\\n----------------------\\n\\t{}'.format(Berlin_venues.shape[0]))\nprint('\\nTotal unique categories:\\n----------------------\\n\\t{}'.format(Berlin_venues['Venue Category'].unique().shape[0]))","6b2b79a5":"# View unique categories of all venues\nBerlin_venues['Venue Category'].unique()","fcfd746b":"# Get dummy variables from Venue Category\nBerlin_onehot = pd.get_dummies(Berlin_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# Add Neighbourhood Column\nBerlin_onehot['Neighbourhood'] = Berlin_venues['Neighbourhood']\n\n# Rearrange columns\ncolumns = [Berlin_onehot.columns[-1]] + list(Berlin_onehot.columns[:-1])\nBerlin_onehot = Berlin_onehot[columns]\n\n# Column names that I think won't be useful in our analysis, so we drop them\nBerlin_onehot.drop(columns=['Stationery Store', 'Salon \/ Barbershop', 'Drugstore', 'Grocery Store', \n                            'Supermarket', 'IT Services', 'Building', 'Farmers Market', 'Metro Station',\n                            'Cemetery', 'Paper \/ Office Supplies Store', 'Tram Station', 'Bus Stop', \n                            'Post Office', 'Light Rail Station', 'Gas Station', 'Bank', 'Intersection', \n                            'Airport Service', 'Airport Lounge', 'Rental Car Location', 'Duty-free Shop',\n                            'Neighborhood', 'Print Shop', 'Train Station',\n                            'Tunnel', 'Windmill', 'Credit Union', 'Road', 'Insurance Office'], \n                   inplace=True)\n\n# Create a DataFrame where Category is represented by venue frequency\nBerlin_groups = Berlin_onehot.groupby('Neighbourhood').mean().reset_index()\n\nBerlin_groups.head()","98ca8fa3":"# Check if the venue is a resturant or not\ncols_list = ['Neighbourhood']\n\n# Loop through all columns\/categories\nfor col in range(1, Berlin_groups.columns.shape[0]):\n    \n    # Check if the string contains specific words\n    if 'Restaurant'in Berlin_groups.columns[col]:\n        cols_list.append(Berlin_groups.columns[col])\n    if 'BBQ' in Berlin_groups.columns[col]:\n         cols_list.append(Berlin_groups.columns[col])\n    if 'Pizza' in Berlin_groups.columns[col]:\n         cols_list.append(Berlin_groups.columns[col])\n    if 'Food' in Berlin_groups.columns[col]:\n         cols_list.append(Berlin_groups.columns[col])\n    if 'Steakhouse' in Berlin_groups.columns[col]:\n         cols_list.append(Berlin_groups.columns[col])\n            \n            \nBerlin_restaurants = Berlin_groups[cols_list]\nBerlin_restaurants.head()","20c86800":"# Restaurants\nprint(\"Restaurants in Berlin:\\n----------------------\\n\\n\",Berlin_restaurants.columns)\n\nprint(\"\\nTotal Restaurants:\\n----------------------\\n\", Berlin_restaurants.shape[0])\n\nprint(\"\\nTotal Categories:\\n----------------------\\n\", Berlin_restaurants.shape[1])","851a26e3":"# Create a Dataframe with top 5 common restaurant types for each neighbourhood\nmaximum_venues = 5\nindicators = ['st', 'nd', 'rd']\n\n# Create Column Names\ncolumns = ['Neighbourhood']\nfor ind in np.arange(maximum_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n        \n# Create a new DataFrame that will contain top 10 restaurants based on frequency\nBerlin_top = pd.DataFrame(columns = columns)\nBerlin_top['Neighbourhood'] = Berlin_groups['Neighbourhood']\n\nfor index in np.arange(Berlin_groups.shape[0]):\n    Berlin_top.iloc[index, 1:] = return_top_venues(Berlin_restaurants.iloc[index, :], maximum_venues)\n    \nBerlin_top.head(10)","b621cef5":"# Get the GeoJSON file for Berlin's Boroughs\n!wget --quiet https:\/\/raw.githubusercontent.com\/funkeinteraktiv\/Berlin-Geodaten\/master\/berlin_bezirke.geojson -O berlin_bezirke.geojson\n\nprint('--- GeoJSON files downloaded ---')","000d45f6":"# Read the GeoJSON file  \nboroughs_JSON = r'berlin_bezirke.geojson'\n\n# Create a Map for Berlin\nBerlin_coordinates = geolocator.geocode('Berlin, Germany')\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], \n                        zoom_start=10)\n\n# Create a Choropleth map for each Borough and respective population in 2010\nBerlin_map.choropleth(\n    geo_data = boroughs_JSON,\n    data =  Berlin_boroughs,\n    columns = ['Boroughs','Population'],\n    key_on = 'feature.properties.name',\n    fill_color='YlOrBr',\n    fill_opacity = 0.8,\n    line_opacity = 0.8,\n    legend_name = 'Berlin Boroughs Population')\n\n# In the below part, we create an overlay to add Popups to the map that displays \n# Borough name and Total Population\n\n# Open GeoJSON data and assign it\nwith open(boroughs_JSON) as f:\n    data = json.load(f)\n\n# Add GeoJSON overlay with Html Popups, Just creating a GeoJSON for each borough and adding it to\n# the map, and setting it's style to something that's almost transparent. Probably not the best implementation\n# but, it's a work-around that I did.\n\nfor boroughs in Berlin_boroughs.itertuples():\n    # Set current Index and assign borough name\n    index = boroughs.Index\n    \n    # Get the borough data from the data GeoJSON we improted earlier\n    borough_data = data['features'][index]['geometry']\n    borough_name = data['features'][index]['properties']['name']\n    \n    # Get the Population\n    borough_population = int(Berlin_boroughs.loc[Berlin_boroughs['Boroughs'] == borough_name].Population.values)\n    \n    # Create a HTML label for PopUp feature\n    label = '<h3> {} <\/h3><p>Poplation: {:,}<\/p>'.format(borough_name, borough_population)\n    \n    # Create a GeoJSON with the data we read and set its style to something we can't see\n    borough_gj = folium.GeoJson(data= borough_data, style_function=lambda feature: {\n        'fillColor': '#000000',\n        'color': 'white',\n        'weight': 0,\n        'fillOpacity': 0\n    })\n    borough_gj.add_child(folium.Popup(label))\n    borough_gj.add_to(Berlin_map)\n\n# View the map\nBerlin_map","22889c19":"# Read the GeoJSON file  \nboroughs_JSON = r'berlin_bezirke.geojson'\n\n# Create a Map for Berlin\nBerlin_coordinates = geolocator.geocode('Berlin, Germany')\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], \n                        zoom_start=10)\n\n# Create a Choropleth map for each Borough and respective population in 2010\nBerlin_map.choropleth(\n    geo_data = boroughs_JSON,\n    data =  Berlin_boroughs,\n    columns = ['Boroughs','Density'],\n    key_on = 'feature.properties.name',\n    fill_color='YlOrBr',\n    fill_opacity = 0.8,\n    line_opacity = 0.8,\n    legend_name = 'Berlin Population Density')\n\n# In the below part, we create an overlay to add Popups to the map that displays \n# Borough name and Total Population\n\n# Open GeoJSON data and assign it\nwith open(boroughs_JSON) as f:\n    data = json.load(f)\n\n# Add GeoJSON overlay with Html Popups, Just creating a GeoJSON for each borough and adding it to\n# the map, and setting it's style to something that's almost transparent. Probably not the best implementation\n# but, it's a work-around that I did.\n\nfor boroughs in Berlin_boroughs.itertuples():\n    # Set current Index and assign borough name\n    index = boroughs.Index\n    \n    # Get the borough data from the data GeoJSON we improted earlier\n    borough_data = data['features'][index]['geometry']\n    borough_name = data['features'][index]['properties']['name']\n    \n    # Get the Population\n    borough_density = int(Berlin_boroughs.loc[Berlin_boroughs['Boroughs'] == borough_name].Density.values)\n    \n    # Create a HTML label for PopUp feature\n    label = '<h3> {} <\/h3><p>Density: {:,}<\/p>'.format(borough_name, borough_density)\n    \n    # Create a GeoJSON with the data we read and set its style to something we can't see\n    borough_gj = folium.GeoJson(data= borough_data, style_function=lambda feature: {\n        'fillColor': '#000000',\n        'color': 'white',\n        'weight': 0,\n        'fillOpacity': 0\n    })\n    borough_gj.add_child(folium.Popup(label))\n    borough_gj.add_to(Berlin_map)\n\n# View the map\nBerlin_map","6beddf5a":"# Plot different Neighbourhoods on a map\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], zoom_start=10)\n\n# Create a map with circle markers on each neighbourhood\nfor lat, lng, neighbourhood, borough in zip(Berlin_neighbourhoods['Latitude'], Berlin_neighbourhoods['Longitude'],\n                                  Berlin_neighbourhoods['Neighbourhood'], Berlin_neighbourhoods['Borough']):\n    label = '<h4>  {}, {}  <\/h4>'.format(neighbourhood, borough)\n    label = folium.Popup(label)\n    folium.CircleMarker(\n        [lat, lng],\n        radius = 6,\n        popup=label,\n        fill=True,\n        fill_color='blue',\n        fill_opcaity = 0.9,\n        parse_html=False).add_to(Berlin_map)\n    \n# View the map\nBerlin_map","bd3f110d":"# Create a Bar chart to plot each Borough's population\nax1 = Berlin_boroughs.sort_values(by='Population', ascending=False).plot(kind='bar', \n                                                         x='Boroughs', y='Population', figsize=(15, 3));\n# Title and axis labels\nax1.set_title(\"Borough Population in Berlin (2010)\");\nax1.set_xlabel(\"Borough\");\nax1.set_ylabel(\"Total Population in 2010\");\n\n\n# Create a Bar chart to plot each Borough's Density\nax2 = Berlin_boroughs.sort_values(by='Density', ascending=False).plot(kind='bar', \n                                                         x='Boroughs', y='Density', figsize=(15, 3));\n# Title and axis labels\nax2.set_title(\"Borough Density in Berlin (2010)\");\nax2.set_xlabel(\"Borough\");\nax2.set_ylabel(\"Total Density in 2010\");","806edb7b":"# Plot Neigbourhood Population as of 2008\nax1 = Berlin_neighbourhoods.sort_values(by='Population', ascending=False).plot(kind='bar', \n                                                         x='Neighbourhood', y='Population', figsize=(20, 5));\n\n# Title and axis labels\nax1.set_title(\"Neighbourhoods Population in Berlin (2008)\");\nax1.set_xlabel(\"Neighbourhood\");\nax1.set_ylabel(\"Total Population in 2008\");\n\n# Plot Neigbourhood Population as of 2008\nax2 = Berlin_neighbourhoods.sort_values(by='Density', ascending=False).plot(kind='bar', \n                                                         x='Neighbourhood', y='Density', figsize=(20, 5));\n\n# Title and axis labels\nax2.set_title(\"Neighbourhoods Density in Berlin (2008)\");\nax2.set_xlabel(\"Neighbourhood\");\nax2.set_ylabel(\"Total Density in 2008\");","6814fa39":"# Create an empty list for Neighbourhoods of Interest: \nneighbourhoods_of_interest = []\n\n# Boroughs list that we choose from looking at the map\/graphs\nboroughs_list = ['Pankow', 'Tempelhof-Sch\u00f6neberg', 'Mitte', 'Friedrichshain-Kreuzberg']\n\nfor boroughs in boroughs_list:\n    neighbourhoods_of_interest.append(Berlin_neighbourhoods.loc[Berlin_neighbourhoods['Borough'] == boroughs]['Neighbourhood'])\n\n# Convert into a 1D list\nneighbourhoods_of_interest = list(itertools.chain.from_iterable(neighbourhoods_of_interest))\n\n# Examine the data\nneighbourhoods_of_interest","aa3b2e1d":"# Different competitor categories\ncompetitors_category = ['BBQ Joint', 'Steakhouse', 'American Restaurant', 'New American Restaurant',\n                        'Food Truck', 'Kebab Restaurant', 'Doner Restaurant', 'Turkish Restaurant']\n\n# Create a new Competitors DataFrame\ncompetitors = pd.DataFrame(columns = Berlin_venues.columns)\n\n# Add items to the competitors DataFrame\nfor restaurant in competitors_category:\n    competitors = competitors.append(Berlin_venues.loc[Berlin_venues['Venue Category'] == str(restaurant)],\n                                     ignore_index=True)\n\ncompetitors.head(10)","4c6359f2":"# Plot different Competitors on a map\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], zoom_start=10)\n\n# Create a map with circle markers on each neighbourhood\nfor neighbourhood, venue, lat, lng, category in zip(competitors['Neighbourhood'], competitors['Venue'],\n                                                   competitors['Venue Latitude'], competitors['Venue Longitude'],\n                                                   competitors['Venue Category']):\n    label = '<h4>  {}, {}  <\/h4>'.format(category, venue)\n    label = folium.Popup(label)\n    folium.CircleMarker(\n        [lat, lng],\n        radius = 8,\n        popup=label,\n        color='red',\n        fill=True,\n        fill_color='red',\n        fill_opcaity = 1,\n        parse_html=False).add_to(Berlin_map)\n    \n# View the map\nBerlin_map","4f89347a":"# Initial trial for Clustering Neighbourhoods, random guess for K=10\nk = 12\n\nBerlin_clusters = Berlin_restaurants.drop('Neighbourhood', 1)\n\nkmeans = KMeans(n_clusters=k, random_state=42).fit(Berlin_clusters)\nkmeans.labels_[0:50]","0375cf20":"# Add Cluster labels to the DataFrame\nBerlin_top.insert(0, 'Cluster Group', kmeans.labels_)\n\n# Sort values of Berlin_top10 DataFrame by 'Neighbourhood' Column\nBerlin_top.sort_values(by='Neighbourhood', ascending=True, inplace=True)\n\n# Sort values of Berlin_neighbourhoods DataFrame by 'Neighbourhood' Column\nBerlin_neighbourhoods.sort_values(by='Neighbourhood', ascending=True, inplace=True)\n\n# Now both DataFrames should have matching Neighbourhood \n# Columns, as they were sorted to the same criteria\n\n# Join DataFrames together\nBerlin_top = Berlin_neighbourhoods.join(Berlin_top.set_index('Neighbourhood'), on='Neighbourhood')\nBerlin_top.reset_index(drop=True, inplace=True)\n\n# Check the DataFrame\nBerlin_top.head()","d29b23ef":"# Optimal K-values using two different methods: Elbow and Silhoutte Method.\n\n# Maximum K value\nk_max = range(2, 14)\ndistortions = []\n\n# Optimum K using elbow method\nfor k in k_max:\n    kmeans = KMeans(n_clusters=k, init= 'k-means++', max_iter=500, random_state=42).fit(Berlin_clusters)\n    # Add distorion value to distortions list\n    distortions.append(sum(np.min(cdist(Berlin_clusters, \n                                        kmeans.cluster_centers_, \n                                        'euclidean'), axis=1)) \/ Berlin_clusters.shape[0])\n# Plot Distortion Vs. K values\nplt.figure(figsize=(15,5))\nplt.plot(k_max, distortions, 'rx-')\nplt.xlabel('K-Cluster Groups')\nplt.ylabel('Distortions')\nplt.title('Optimal number of clusters (Elbow Method)')\nplt.show()\n\n# Silhoutte Score Computation\ns_val = []\nfor k in k_max:\n    clusterer = KMeans(n_clusters=k, init='k-means++', max_iter=500, random_state=42)\n    preds = clusterer.fit_predict(Berlin_clusters)\n    centers = clusterer.cluster_centers_\n    score = silhouette_score (Berlin_clusters, preds, metric='euclidean')\n    s_val.append(score)\n    \n# Plot silhoutte score graph\nplt.figure(figsize=(15,5))\nplt.plot(k_max, s_val, 'rx-')\nplt.xlabel('K-Cluster Groups')\nplt.ylabel('Sihloutte Score')\nplt.title('Optimal Number of Clusters (Sihloutte Method)')\nplt.show()","e2a744bb":"# Run K-means with optimum K, based on elbow method.\nk = 6\nkmeans = KMeans(n_clusters=k, init='k-means++', max_iter=500, random_state=42).fit(Berlin_clusters)\n\n# Add Clusters to DataFrame \nBerlin_top['Cluster Group'] = kmeans.labels_\n\n# Visualizate Neighbourhood clusters on a map\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], zoom_start=10)\n\n# Color Scheme for Clusters\nx = np.arange(k)\nys = [i + x + (i*x)**2 for i in range(k)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\nfor lat, lng, neighbourhood, cluster in zip(Berlin_top['Latitude'], Berlin_top['Longitude'],\n                                            Berlin_top['Neighbourhood'], Berlin_top['Cluster Group']):\n    label = '<h2> {}<\/h2> <p><em>Cluster Group: {}<\/em><\/p>'.format(neighbourhood, cluster)\n    label = folium.Popup(label)\n    folium.CircleMarker(\n    [lat, lng],\n    radius = 8,\n    popup=label,\n    color=rainbow[int(cluster)],\n    fill = True,\n    fill_color = rainbow[int(cluster)],\n    fill_opacity=1).add_to(Berlin_map)\n\n# View map\nBerlin_map","ec7e6742":"# Sort Berlin_top10 DataFrame\nBerlin_top.sort_values(by= 'Cluster Group', ascending=True, inplace=True)\nBerlin_top.reset_index(drop=True, inplace=True)\n\nBerlin_top.groupby(by=['Cluster Group'])['Cluster Group'].count()","f92ca4f7":"# Create empty list to store values\nval = []\n\n# Add cluster groups of neighbourhoods of interest to the values list\nfor n in range(0, len(neighbourhoods_of_interest)):\n    val.append(int(Berlin_top.loc[Berlin_top['Neighbourhood'] == neighbourhoods_of_interest[n]]['Cluster Group']))\n\nv = np.array(val)\nfor values in np.unique(v): print('Category Group: {}, Count: {}'.format(values, val.count(values)))\n    \nprint('Most common Cluster Category within neighbourhoods_of_interest: {}'.format(max(val, key=val.count)))","2e8b95bd":"# Cluster Group 0\nCluster0 = Berlin_top.loc[Berlin_top['Cluster Group'] == 0]\nCluster0.reset_index(drop=True)\n\n# Cluster Group 1\nCluster1 = Berlin_top.loc[Berlin_top['Cluster Group'] == 1]\nCluster1.reset_index(drop=True)\n\n# Cluster Group 3\nCluster3 = Berlin_top.loc[Berlin_top['Cluster Group'] == 3]\nCluster3.reset_index(drop=True)\n\n# Cluster Group 4\nCluster4 = Berlin_top.loc[Berlin_top['Cluster Group'] == 4]\nCluster4.reset_index(drop=True)\n\nCluster1","120a9506":"# 1st Common Venue Cluster 0\nax0 = Cluster0.groupby(['1st Most Common Venue'], as_index=False).count().plot(kind='bar', \n                                                                         x='1st Most Common Venue', y='Cluster Group',\n                                                                         figsize = (15,3));\nax0.set_title('1st Most Common Venue Count in Cluster Group 0');\nax0.set_xlabel('1st Most Common Venue');\nax0.set_ylabel('Count of Venues');\n\n\n# 1st Common Venue Cluster 1\nax1 = Cluster1.groupby(['1st Most Common Venue'], as_index=False).count().plot(kind='bar', \n                                                                         x='1st Most Common Venue', y='Cluster Group',\n                                                                         figsize = (15,3));\nax1.set_title('1st Most Common Venue Count in Cluster Group 1');\nax1.set_xlabel('1st Most Common Venue');\nax1.set_ylabel('Count of Venues');\n\n# 1st Common Venue Cluster 3\nax3 = Cluster3.groupby(['1st Most Common Venue'], as_index=False).count().plot(kind='bar', \n                                                                         x='1st Most Common Venue', y='Cluster Group',\n                                                                         figsize = (15,3));\nax3.set_title('1st Most Common Venue Count in Cluster Group 3');\nax3.set_xlabel('1st Most Common Venue');\nax3.set_ylabel('Count of Venues');\n\n# 1st Common Venue Cluster 4\nax4 = Cluster4.groupby(['1st Most Common Venue'], as_index=False).count().plot(kind='bar', \n                                                                         x='1st Most Common Venue', y='Cluster Group',\n                                                                         figsize = (15,3));\nax4.set_title('1st Most Common Venue Count in Cluster Group 4');\nax4.set_xlabel('1st Most Common Venue');\nax4.set_ylabel('Count of Venues');","1f55ffdf":"# Plot different Competitors on a map\nBerlin_map = folium.Map(location = [Berlin_coordinates.latitude, Berlin_coordinates.longitude], zoom_start=10)\n\n# Create a Choropleth map for each Borough and respective Density\nBerlin_map.choropleth(\n    geo_data = boroughs_JSON,\n    data =  Berlin_boroughs,\n    columns = ['Boroughs','Density'],\n    key_on = 'feature.properties.name',\n    fill_color='YlOrBr',\n    fill_opacity = 0.4,\n    line_opacity = 0.5,\n    legend_name = 'Berlin Population Density')\n\n# Create a map with circle markers on each neighbourhood\nfor neighbourhood, venue, lat, lng, category in zip(competitors['Neighbourhood'], competitors['Venue'],\n                                                   competitors['Venue Latitude'], competitors['Venue Longitude'],\n                                                   competitors['Venue Category']):\n    label = '<h4>  {}, {}  <\/h4>'.format(category, venue)\n    label = folium.Popup(label)\n    folium.CircleMarker(\n        [lat, lng],\n        radius = 8,\n        popup=label,\n        color='red',\n        fill=True,\n        fill_color='red',\n        fill_opcaity = 1,\n        parse_html=False).add_to(Berlin_map)\n    \nfor neighbourhood, lat, lng in zip(Cluster1['Neighbourhood'], Cluster1['Latitude'], Cluster1['Longitude']):\n    label = '<h4>  {}  <\/h4>'.format(neighbourhood)\n    label = folium.Popup(label)\n    folium.CircleMarker(\n        [lat, lng],\n        radius = 8,\n        popup=label,\n        color=rainbow[1],\n        fill=True,\n        fill_color=rainbow[1],\n        fill_opcaity = 1,\n        parse_html=False).add_to(Berlin_map)\n    \n# View the map\nBerlin_map","f1a47e68":"So, we have managed to scrape data from the Wikipedia page, and create two separate DataFrames. The first DataFrame is `Berlin_boroughs` which contains different borough data. The second DataFrame, contains scraped data about neighbourhoods and named `Berlin_neighbourhoods`.","d66572ef":"These neighbourhoods, are so far the ones with the highest potential to be selected as a restaurant location. This conclusion is only based on demographics.\n\nFurthermore, lets view all the restaurants that are considered as competitors.","cab497ba":"# Choosing Restaurant Location in Berlin\n\nThis Notebook, is the Capstone project that I have worked on towards earning the [IBM Data Science Professional Certficate](https:\/\/www.coursera.org\/professional-certificates\/ibm-data-science).\n\nIn this Notebook, we will be trying to perform multiple analysis in order to choose the most appropriate location for opening a restaurant in Berlin.","5bf4abe9":" Lets define some helper functions that will ease the process of the things coming ahead.\n \n We define `getNearbyVenues()` which returns a DataFrame with all nearby venues from a specific point using Forsquare API. it returns venue name, category, and coordinates.","c5a4c690":"# 6. References\n\n1. [Restaurant: Choosing a Location](https:\/\/www.gourmetmarketing.net\/restaurant-essentials\/choosing-a-restaurant-location)\n2. [Boroughs and Neighbourhoods of Berlin](https:\/\/en.wikipedia.org\/wiki\/Boroughs_and_neighborhoods_of_Berlin)\n3. [Berlin Boroughs Geographical Data](https:\/\/github.com\/funkeinteraktiv\/Berlin-Geodaten)","5ffd516c":"Even though both method's output may seem a bit vauge, I decided to go for `k=6` after some trial and error.","247fa392":"# Contents\n\n** 1. Introduction **\n\n** 2. Getting and Cleaning the Data **\n\n** 3. Visualizing and Understanding the Data **\n\n** 4. Segmenting Neighbourhoods**\n\n** 5. Analyzing Clusters **\n\n** 6. References **","3d2d121b":"Based on the `Berlin_venues` DataFrame, lets create a one hot vector based on the different categories of venues. Then group the venues based on their mean.\n\nAlso, I decided to hand-pick some venue categories and remove them.","f68bf77e":"We will use `KMeans` algorithm in order to cluster similar Berlin neighbourhoods. This will help us identify similar neighbourhoods that share similar venues. Which can come into play if we are looking for a similar neighbourhood from `neighbourhoods_of_interest`, as a subsituite.\n\nWe start off, by importing some important packages that we will use.","5528abfd":"## 2.2. Getting Venue Data with Forsquare API\n\nNow we have acquired all information about Boroughs and Neighbourhoods of Berlin, into two separate DataFrames with all geographical information. \n\nSince, we are trying to open a restaurant. We also need to know the restaurants in Berlin, this can be done using the Forsquare API, which will be demonstrated below.","785fd041":"# 3. Visualizing and Understanding the Data\n\nSo we have scraped the tables from Wikipedia page, and fetched all venue information from Berlin neighbourhoods. Lets visualize some of the data that we have. Such as Boroughs, and Neighbourhoods location as well as population based on the data we acquired earlier. This will help us understand what we have so far.\n\nFirst of, in order to visualize geographical location with boundaries for Boroughs\/Neighbourhoods, we need a `GeoJson` file that defines the location data we want to plot. We will also use the `folium` library for creating maps. \n\nSo lets download the `GeoJSON` file.","4a15fb6e":"# 4. Clustering Neighbourhoods","0c8b4165":"From the above maps\/graphs, if we neglect the fact that one is measured in 2008 and the other in 2010. We can *colclude* the following demographics that can impact our choice of neighbourhood\/ location.\n\n**1. Boroughs that we should consider, based on population count:**\n   > Pankow, Tempelhof-Sch\u00f6neberg, and Mitte.\n\n**2. Boroughs that we should consider, based on population density:**\n   > Friedrichshain-Kreuzberg, Mitte, and Tempelhof-Sch\u00f6neberg.\n   \n**3. Neighburhoods we should consider, based on population:**\n   > Neuk\u00f6lln, Kreuzberg, Sch\u00f6neberg\n   \nLets inspect all the neighbourhoods within the above mentioned group. Actually the above neighbourhoods in bullet number `4` exist within the above selected boroughs.\n\nWe can also note that, Friedrichshain-Kreuzberg and Pankow are the most Populated\/dense boroughs. Thus reflecting an high indicator of a high foot traffic. Moreover, we should also consider Mitte and Tempelhof-Sch\u00f6neberg as they have appeared in our consedirations multiple times.","15e220d8":"Out of our `neighbourhoods_of_interest`, they mostly belong to `Cluster Group 1`. So narrowing down our search, we will consider neighbourhoods from this cluster group only.\n\nLets further inspect all other clusters with a bit of tendancy towards `Cluster Group 1`. Also, neglecting `Cluster Group 2` and `Cluster Group 5`, because of the demographics of the neighbourhoods of these areas, they don't belong to a lively area or a densly populated area.","51ddace6":"Now, lets add the geographical coordinates to the `Berlin_boroughs` DataFrame.","4a2b1118":"# 5. Choosing a Location\n\nSo we have acquired our data, visualized it and understood some of the demographics aspects. Then we have realised all of our competitors, and clustered all neighbourhoods which have similar restaurants to each other to help us decide on alternatives. Lets do some analysis on our clusters and start to choose a proper location for the new restaurant.\n\nLets see how our `neighbourhoods_of_interest` belong to the different clusters of all neighbourhoods in Berlin.","401853c8":"Now, lets scrape the rest of the tables in the [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Boroughs_and_neighborhoods_of_Berlin) page. And create the `Berlin_neighbourhoods` DataFrame.","7bf6abcd":"Lets use FORSQUARE API to fetch venue data for each Neighbourhood in Berlin. We wll search for venues in a 2 km raduis around each neighbourhood, and limit the query to 100 results.","0881fe69":"Now, we will add the cluster labels to our `Berlin_top10` DataFrame, and to simplify things more, we will join the `Berlin_neighbourhoods` along with the `Berlin_top10` DataFrame, so we have all information about each neighbourhood, from coordinates to top 10 venues and cluster group.","4688ad49":"It's a good practice to visualize the location data we have fetched for the Neighbourhoods. This is to check nothing weird is happening. Lets visualize the Neighbourhoods and draw circle markers over each neighbourhood.","efdbb184":"# 1. Introduction\n\nBerlin is the capital and largest city of Germany, in terms of both area and population. As of 2018, its 3,748,148 inhabitants made it the most populous city in Europe after London. Berlin is a world city of culture, politics, media and science. Its economy is based on high-tech firms and the service sector, encompassing a diverse range of creative industries, research facilities, media corporations and convention venues. Berlin serves as a continental hub for air and rail traffic and has a highly complex public transportation network. The metropolis is a popular tourist destination.\n\nTherefore, I have chosen Berlin to be my scope for the *'IBM Data Science Professional'* certificate. Because of the personal connection, as well as its position within the EU, and the diversity of the city.\n\n\n## 1.1. Problem Description\n\nIt's especially important before starting any project, is to set up clear goals. In order to keep a clear path towards the end goal. \n\nIn this project, our main problem can be phrased in the following question:\n> **Where to set-up a new BBQ restaurant in Berlin?** \n\nLocation is extremely important, because the more populated the location, then more customers to will visit the restaurant. Yet, one also wants to avoid setting up business in a wrong location, or where a lot of competitors exist.\n\nThe restaurant is a Texas Style BBQ, and they decided to bring business outside the US, to Berlin- Germany. They are very good with smoking meat, and serving brisket, sausage, pork, and many other sides. However, smoked brisket is their speciality. \n\nDoing some research, I have found that the following things should be taken in mind while choosing a resaturant location:\n1. **Visibility**, having your restaurant in a visible location impacts your success. Having a restaurant tucked in behind building will be of a disadvantage.\n2. **Foot Traffic**, busy sideways with high foot traffic allows your restaurant to be noticed. On the contrary, of having a restaurant near a highway where it might go unnoticed.\n3. **Demographics**, from population density to population categories. These points will impact the success of the restaurant.\n4. **Affordability of Space**, if rent prices are too high around the neighbourhood, this will impact the type of people in the neighbourhood. As well as it will impact the rent price for the restaurant itself.\n\nThe above mentioned items, are some of the things that impact the location of a restaurant. Moreover, many other factors exist, such as history of location, parking and accessability, property condition, and many more. However, the above mentioned are the ones that I think we can work with at the moment.\n## 1.2. Data Sources\n\nData is the core of this project, we will be scraping information off Wikipedia that contains data about Berlin Boroughs and Neighbourhoods. Then we will work around the data we have and utilize Forsquare API to look for restaurants and other venues all around Berlin. Furthermore, housing prices can be an important indicator of how expensive the area is, so we might also consider AirBnB listings and respective prices, just as an indicator of how expensive the area is. \n\n\n**Enough talking, lets start out!**\n\nWe start out by importing all core packages\/libraries that we will need throughout this notebook.","1205d8bd":"Let's visualize the density of inhabitants as well on a similar interactive map.","b11cd621":"We also define `return_top_venues()`, which returns the most common venues by sorting a specific row.","3bbe578c":"Now, lets visualize the population of each borough as a bar chart, based on largest to the smallest one. \n\nSo we sort it in descending order, and visualize it.","e58d75fd":"We can note, that from the neighbourhoods we considered earlier, and at the same time does not have much competitoirs in the area are:\n\n1. Friedrichshain\n2. Mitte\n3. Prenzlauer","1f8d7058":"Now, we read the `.geojson` file, and use the `folium` package we imported earlier to view a map of Berlin Boroughs. Lets use a Chloropeth map to visualize total Population of each and every Borough.\n\nOne thing to know, if we only use the `.choropleth()` function, it only plots a choropleth map without any interatcion apart from the legend. In the second part of the below code, I do a small workaround by replotting the boroughs as a `GeoJSON` over the map with a transparent style and adding `HTML` pop-ups for each object created.","6fb06662":"Lets inspect, on the same overlay of a map. `Cluster Group 1`, `competitors` and `Population Density`. ","28a8207d":"The DataFrame needs some data cleaning. We will drop the `Map` Column, and remove the codes before the `Locality`, also renaming the Columns won't do any harm.\n\n> NOTE: Population in the `Berlin_neighbourhoods` DataFrame is collected in 2008, not as the `Berlin_boroughs` which is collected in 2010.\n\nThis cell would take some time to run, because of the delay that I have added.","6c272a9e":"One should note, that density is calculated as follows:\n\n$$Density = \\frac{Population}{Area}$$\n\nWhich we should know that, not all neighbourhoods\/boroughs have equal area. So for example in `Berlin Population Map` we can see that `Pankow` is the most inhabited borough. While in the `Berlin Population Density Map` we see that Friedrichshain-Kreuzberg is the most dense borough. So in choosing the location, we need to attribute to such factor, and not get caught by the fact that the area is just dense.","a3f17c95":"If we look through the map, with the competitors location in mind, we can conclude that the ideal location is one of those neighbourhoods:\n\n1. **Tiergarten**, which is well known for Middle eastern restaurants.\n2. **Mitte**, which is known for italian restaurants.\n3. **Prenzlauerberg**, which is known for Vietnamese Restaurant.\n4. **Friedrichshain**, Falafel Restaurant.\n\nThis is because, they have high density and not so much competitors around the area, and also their proximity to city center. ","d20a6eb1":"# 2. Getting and Cleaning the Data\n\nAfter we have imported all of our core packages. It's about time to get the data that we will be using in this Notebook.\n\nThis section is split into two parts:\n\n**1. Getting the Boroughs\/Neighbourhoods informaton using Web Scraping (BeautifulSoup)**\n\n**2. Getting Neighbourhood venues informaton using Forsquare API**\n\n## 2.1. Getting Berlin data using BeautifulSoup\n\nOur data is scraped from this [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Boroughs_and_neighborhoods_of_Berlin) page. We will be using `BeautifulSoup` to read the page. Then we will use the `find()` method to look for the Boroughs table, which luckly is the first table in the page. After scraping off the Boroughs table data, we will assign it to our main DataFrame `Berlin_boroughs`. \n\nLater on, we will also scrape all Neighbourhood\/ Localities data. Add it to a DataFrame called `Berlin_neighbourhoods`, then we will search for geographical coordinates of each neighbourhood and add it to that DataFrame.","1c0856fc":"Print out the entries we have retrived.","70308126":"We do the same thing, for the Neighbourhood data we have.","f6cae08b":"In `KMeans` its hard to decide the optimal number of clusters. Thus, we will try two methods that may give us a better insight about the number of clusters that we should use.\n\nWe will use the Elbow method as well as the Silhoutte Score.","51f2827f":"Since we are only interested in restaurants, lets remove all other categories, to ease the process."}}