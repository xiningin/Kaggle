{"cell_type":{"0d7fc199":"code","a7529b9b":"code","ded66215":"code","d404a267":"code","486b9128":"code","7d817e14":"code","5eec2361":"code","b7bc4318":"code","80200305":"code","a7f6e2ee":"code","b0c11ad8":"code","eb515705":"code","aa59370a":"code","146735b5":"code","a8fb3279":"code","83c87768":"code","67fe7bbd":"code","a1ebb49c":"code","28077d27":"code","1d2a834c":"code","de0c00e9":"code","58d19994":"code","1b48f752":"code","1347e822":"code","d474a5d3":"code","5829900c":"code","cca8bf10":"code","904c8220":"code","e775e6b4":"code","1a40d26b":"code","3ede36e8":"code","413913fc":"code","acd98be2":"code","97696a9b":"code","cf72c23d":"code","e0a27d05":"code","cb70f537":"code","8dc50810":"code","5c90e6af":"code","37493585":"code","59512731":"code","3c0c4dc8":"markdown","29c8ab4a":"markdown","8374aa0c":"markdown","098f13fe":"markdown","bbd75835":"markdown","2d9607ec":"markdown","7002a692":"markdown","f4274b85":"markdown","862759a9":"markdown","3db67476":"markdown","bbcdc9b0":"markdown","94c38c8e":"markdown"},"source":{"0d7fc199":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","a7529b9b":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch\n","ded66215":"data = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/train.csv\")\ndf = pd.DataFrame(data)","d404a267":"df.head()","486b9128":"df.describe()\n","7d817e14":"col = df.columns  #getting list of column names","5eec2361":"# showing column wise %ge of NaN values they contains \n\nfor i in col:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n","b7bc4318":"num_df = df.select_dtypes(exclude=['object'])\ncat_df= df.drop(num_df, axis=1)","80200305":"num_df.head()","a7f6e2ee":"num_df.describe()","b0c11ad8":"num_df = num_df.drop([\"id\"], axis = 1)   #Since Id does not has any role in price prediction of houses","eb515705":"cormap = num_df.corr()\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(cormap, annot = True)","aa59370a":"cat_df.head()","146735b5":"cat_df.describe()","a8fb3279":"from sklearn.preprocessing import LabelEncoder\n\ncat_col = cat_df.columns\nfor i in cat_col:\n  enc = LabelEncoder()\n  cat_df[i] = enc.fit_transform(cat_df[i].astype('str'))","83c87768":"cat_df.head()\n","67fe7bbd":"cat_df['target'] = df['target']  # to get coreltion with target attribute","a1ebb49c":"cormat = cat_df.corr()\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cormat, annot = True)","28077d27":"final_df = pd.concat([ cat_df.drop(['target'], axis=1), num_df], axis = 1, sort=False)\nfinal_df.head()","1d2a834c":"X = final_df.drop(['target'], axis=1)\ny = final_df['target']","de0c00e9":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\nX.head()","58d19994":"print(X.shape, y.shape)","1b48f752":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","1347e822":"def build_model(hp):\n    model = keras.Sequential()\n    \n    model.add(layers.Dense(24, activation='relu'))\n    \n    for i in range(hp.Int('num_layers', 2, 20)):\n        model.add(layers.Dense(units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n                               activation = 'relu'))\n        model.add(layers.Dropout(0.5))\n        \n    model.add(layers.Dense(1, activation='linear'))\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n        loss='mean_absolute_error',\n        metrics=['mean_absolute_error'])\n    return model","d474a5d3":"tuner = RandomSearch(\n    build_model,\n    objective='mean_absolute_error',\n    max_trials=10,\n    executions_per_trial=1)","5829900c":"tuner.search(X_train, y_train, epochs=5)\n","cca8bf10":"# Choosing model with least Mean Absolute Error\n\nreg = tuner.get_best_models(num_models=1)[0]","904c8220":"reg.fit(X_train, y_train, epochs=20, validation_split=0.1, initial_epoch=5)","e775e6b4":"reg.summary()","1a40d26b":"# Prediction\n\ny_pred = reg.predict(X_test)\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\npred_df.head()","3ede36e8":"#Evaluating the Model\n\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","413913fc":"# Here we ready the Test Data\ntest_data = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/test.csv\")\ntest_df = pd.DataFrame(test_data)\ntest_df.head()","acd98be2":"num_test_df = test_df.select_dtypes(exclude=['object'])\ncat_test_df= test_df.drop(num_test_df, axis=1)","97696a9b":"Id = num_test_df['id']\nnum_test_df = num_test_df.drop([\"id\"], axis = 1)","cf72c23d":"# Let's Encode the test categorical dataset also\n\nfor i in cat_test_df.columns:\n    enc = LabelEncoder()\n    cat_test_df[i] = enc.fit_transform(cat_test_df[i].astype('str'))\n\ncat_test_df.head()","e0a27d05":"final_test_df = pd.concat([ cat_test_df, num_test_df], axis = 1, sort=False)\nfinal_test_df.head()","cb70f537":"X = pd.DataFrame(scaler.transform(final_test_df), columns=final_test_df.columns)\nX.head()","8dc50810":"Y_pred = reg.predict(X)","5c90e6af":"final_df = pd.DataFrame({'id': Id, 'target': Y_pred.flatten()})","37493585":"final_df.head()","59512731":"final_df.to_csv('.\/submission.csv', index=False)","3c0c4dc8":"> Since data does'nt contain any null values, we can move further","29c8ab4a":"> Since the given dataset contains both categorical and numerical dataset we have to separate them for further analysis. ","8374aa0c":"> As we can see that the value of root mean squared error is 0.879, which is slightly lesser than 15% of the mean value.","098f13fe":"> Now let's analyse the categorical part of dataset.\n\n","bbd75835":"### Data Information","2d9607ec":"> Using Random Search for itereating over parameters","7002a692":"> Let's first encode the categorical data into numerical for futher analysis","f4274b85":"> Since range of data in different columns veries significantly we need to scale the independent variable i.e. X. For this we will use _Min-Max Scaling_.\n","862759a9":"*****","3db67476":"> Now start analysis with numerical data.","bbcdc9b0":"### ANN","94c38c8e":"> Here to determine no of hidden layers and no of neurons in each layer, I'm using [Keras Tuner](https:\/\/www.tensorflow.org\/tutorials\/keras\/keras_tuner). Keras Tuner can be proved very helpful for hyperparameter tunning of neural networks."}}