{"cell_type":{"bde13f18":"code","82145794":"code","4947d71e":"code","c01c56f7":"code","e4d88beb":"markdown","f5f284d1":"markdown","b283f477":"markdown"},"source":{"bde13f18":"from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '\/kaggle\/input\/forest-fire\/Dataset\/Dataset\/train_set\/',\n    target_size=(150, 150),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    '\/kaggle\/input\/forest-fire\/Dataset\/Dataset\/test_set\/',\n    target_size=(150, 150),\n    batch_size=batch_size,\n    class_mode='binary'\n)","82145794":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='rmsprop',\n    metrics=['acc']\n)\n\nmodel.summary()","4947d71e":"model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)","c01c56f7":"import matplotlib.pyplot as plt\n\nval_imgs, val_labels = val_generator.__getitem__(0)\n\npreds = model.predict(val_imgs)\n\nfig, axes = plt.subplots(4, 4, figsize=(16, 16))\n\nfor img, label, pred, ax in zip(val_imgs, val_labels, preds, axes.flatten()):\n    ax.imshow(img)\n    ax.set_title('GT %d, Pred %.2f' % (label, pred))\n    ax.set_axis_off()","e4d88beb":"# Build Model","f5f284d1":"# Train","b283f477":"# DataGenerator"}}