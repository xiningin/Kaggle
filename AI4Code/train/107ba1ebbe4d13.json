{"cell_type":{"99596b01":"code","d70ee9be":"code","8ce7c54d":"code","882f1b15":"code","f4e7c020":"code","8f90280c":"code","ac7f7aa8":"code","d17d1e70":"code","6bdb2435":"code","7f192ca4":"code","0f2777e6":"code","12c2ba15":"code","3e74a9e2":"code","7fa01564":"code","37d82a5c":"code","71d3349d":"code","40e18da5":"code","97a46dd2":"code","830f0800":"code","0c3e3411":"code","d21caec3":"code","03331665":"code","c640723a":"code","5cf952d5":"code","0ff26580":"code","ee971353":"code","a1b5b2b1":"code","645ec848":"code","2fdeba44":"code","c0be6892":"code","f2c09c0a":"code","daed8f7d":"code","bd983147":"code","6ac3bcd4":"code","e124bbee":"code","203999bf":"code","6acaadb9":"code","813ef2d8":"code","90a84c23":"code","018647ba":"code","91dbd435":"code","242d053a":"markdown","e2b78035":"markdown","e85c0f32":"markdown","f1388f74":"markdown","ddf24cd5":"markdown","5a6e7985":"markdown","a1d6f381":"markdown","8e7f856d":"markdown","3e1515eb":"markdown","accc27fb":"markdown","72691968":"markdown","ff127c08":"markdown"},"source":{"99596b01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set()\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d70ee9be":"train = pd.read_csv('\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_train.csv',parse_dates = ['Date'])\ntest = pd.read_csv('\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_submission.csv')","8ce7c54d":"train.head()","882f1b15":"train.info()","f4e7c020":"date_data = train['Date']\nconfirmed_cases = train['ConfirmedCases']\nplt.figure(figsize=(10,8))\nplt.plot(date_data,confirmed_cases)\nplt.xticks(rotation=90)\nplt.title('Time Series Analysis for the confirmed Cases')\nplt.show()","8f90280c":"date_data = train['Date']\nFatalities = train['Fatalities']\nplt.figure(figsize=(10,8))\nplt.plot(date_data,Fatalities)\nplt.xticks(rotation=90)\nplt.title('Time Series Analysis for Fatalities')\nplt.show()","ac7f7aa8":"train.head()","d17d1e70":"train['Province\/State'].value_counts()","6bdb2435":"plt.figure(figsize=(20,5))\nsns.countplot(y = train['ConfirmedCases'])\nplt.title('Count for confirmed cases')\nplt.show()","7f192ca4":"plt.title('Count for confirmed cases')\nsns.distplot(train['ConfirmedCases'],kde = False,bins=20)","0f2777e6":"train_new = train[train['ConfirmedCases'] > 0]\ntrain_new","12c2ba15":"plt.figure(figsize=(10,8))\nsns.barplot(x='Date',y='ConfirmedCases',data=train_new)\nplt.xticks(rotation=45)\nplt.title('Confirmed cases as per Date')\nplt.show()","3e74a9e2":"plt.figure(figsize=(10,8))\nsns.barplot(x='Date',y='Fatalities',data=train_new)\nplt.xticks(rotation=45)\nplt.title('Confirmed Death as per Date')\nplt.show()","7fa01564":"train_new.head()","37d82a5c":"train_new['Week'] = train_new['Date'].dt.week\ntrain_new['Day'] = train_new['Date'].dt.day\ntrain_new['DayOfWeek'] = train_new['Date'].dt.dayofweek\ntrain_new['DayOfYear'] = train_new['Date'].dt.dayofyear\ntrain_new.head()","71d3349d":"df = train_new[['Date','Week','Day','DayOfWeek','DayOfYear','ConfirmedCases','Fatalities']]\ndf.head()","40e18da5":"from sklearn.linear_model import LinearRegression,Lasso\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score,roc_auc_score\nfrom sklearn.model_selection import train_test_split","97a46dd2":"X = df.drop(['Date','ConfirmedCases','Fatalities'],axis=1)\ny = df[['ConfirmedCases','Fatalities']]","830f0800":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)","0c3e3411":"print(f'Size of X_train : {X_train.shape}')\nprint(f'Size of X_test : {X_test.shape}')\nprint(f'Size of y_train : {y_train.shape}')\nprint(f'Size of y_test : {y_test.shape}')","d21caec3":"X_train.head()","03331665":"y_train.head()","c640723a":"def predict_confirmed_cases(regression_algo):\n    r = regression_algo()\n    r.fit(X_train,y_train['ConfirmedCases'])\n    y_pred = r.predict(X_test)\n    rSquare = r2_score(y_test['ConfirmedCases'],y_pred)\n    confirmed_cases.append(rSquare)\n\ndef predict_confirmed_deths(algos):\n    r = algos()\n    r.fit(X_train,y_train['Fatalities'])\n    y_pred = r.predict(X_test)\n    rSquare = r2_score(y_test['Fatalities'],y_pred)\n    confirmed_death.append(rSquare)\n    \nmodels = [KNeighborsRegressor,LinearRegression,RandomForestRegressor,DecisionTreeRegressor,BayesianRidge,\n          GradientBoostingRegressor,Lasso]\n\nconfirmed_cases = []\nconfirmed_death = []","5cf952d5":"for i in models:\n    predict_confirmed_cases(i)","0ff26580":"for j in models:\n    predict_confirmed_deths(j)","ee971353":"confirmed_cases","a1b5b2b1":"confirmed_death","645ec848":"models = pd.DataFrame({\n    'Model': [\"KNeighborsRegressor\",\"LinearRegression\",\"RandomForestRegressor\",\"DecisionTreeRegressor\",\"BayesianRidge\",\n          \"GradientBoostingRegressor\",\"Lasso\"],\n    'ConfirmedCase_r2': confirmed_cases,\n    'Fatalities_r2' : confirmed_death\n})","2fdeba44":"models","c0be6892":"test.head()","f2c09c0a":"test.info()","daed8f7d":"test_data = test[['ForecastId','Date']]\ntest_data.head()","bd983147":"test_data['Date'] = pd.to_datetime(test_data['Date'])\ntest_data['Week'] = test_data['Date'].dt.week\ntest_data['Day'] = test_data['Date'].dt.day\ntest_data['DayOfWeek'] = test_data['Date'].dt.dayofweek\ntest_data['DayOfYear'] = test_data['Date'].dt.dayofyear\ntest_data.head()","6ac3bcd4":"Kneighbour = KNeighborsRegressor()\nKneighbour.fit(X_train,y_train['ConfirmedCases'])","e124bbee":"decisiontree = GradientBoostingRegressor()\ndecisiontree.fit(X_train,y_train['Fatalities'])","203999bf":"test_data['ConfirmedCases'] = Kneighbour.predict(test_data.drop(['Date','ForecastId'],axis=1))","6acaadb9":"test_data['Fatalities'] = decisiontree.predict(test_data.drop(['Date','ForecastId','ConfirmedCases'],axis=1))","813ef2d8":"test_data.head()","90a84c23":"test_data = test_data[['ForecastId','ConfirmedCases','Fatalities']]","018647ba":"test_data.head()","91dbd435":"test_data.to_csv('submission.csv',index=False)","242d053a":"As we can see in the above result by using **KNeighborsRegressor** and **GradientBoostingRegressor** we are getting best result","e2b78035":"# **EDA FOR THE DATASET**","e85c0f32":"**Now let's do some Feature Engineering**","f1388f74":"First Convert the Date in Train dataset for the further analysis and you can do this by using the .to_datetime function or you can use parse_date at the time of reading the csv file.as I used at the reading of the file","ddf24cd5":"So, as we can see as we incresed the confrimed_cases gov also incerased the Falaliets","5a6e7985":"# **Feature Engineering**","a1d6f381":"Now, drop the all other columns as they having the similer data and not going to hamper on our model","8e7f856d":"Split the train and test dataset","3e1515eb":"Create the model to fit on test dataset","accc27fb":"It's time for using models and fitting our dataset for obtaining the results. We will use few models for the same.","72691968":"# **Load the Data**","ff127c08":"We will concentrate only those columns which having confirmed cases as greater than zero"}}