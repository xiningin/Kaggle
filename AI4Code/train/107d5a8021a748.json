{"cell_type":{"de307907":"code","eee68269":"code","f1cdb303":"code","9cf92dcb":"code","37dbb21d":"code","d73b4a45":"code","013da459":"code","c6298819":"code","b965e33c":"code","287a7380":"code","1ff37cc7":"code","9c8db30a":"code","05c187b3":"code","892794d3":"code","d73b4b47":"code","2244be6d":"code","1e037071":"code","48a52345":"code","4876f76c":"code","16da852c":"code","79aa736b":"code","d4e84341":"code","3f5e16a2":"code","80863505":"code","440314ab":"code","20d29c18":"code","6059703c":"code","4eca62d4":"code","7b779c42":"code","a38a9c34":"code","e7f3081a":"code","8c60eb29":"code","6733d579":"code","ae0c8ad5":"code","591fb7de":"code","58aa42c7":"code","74416652":"code","22e25836":"code","20b2e14d":"code","58dc5391":"code","0a46b48a":"code","9c61cef3":"code","ee18a088":"code","ddda1ec9":"code","78f7c3a8":"code","f177dfd0":"code","f19aea76":"code","66138255":"code","769acb88":"code","1b6c64c9":"code","84b1ddd2":"code","19b3bf15":"code","0979c300":"code","0e55e833":"code","6c2c3544":"code","c333a119":"code","3e5804f6":"code","46a46c56":"markdown","396578e4":"markdown","a4e064ae":"markdown","24c90792":"markdown","5395389e":"markdown","b4e9f437":"markdown","6f03c2ff":"markdown","f1d0db3e":"markdown","0340646c":"markdown","2739b453":"markdown","4d4ccabf":"markdown","b7e75d91":"markdown","c861c7a6":"markdown","d8d0cccc":"markdown","26d8af36":"markdown","f00b9504":"markdown","8c211579":"markdown","c0a1ba37":"markdown","c7ed1e05":"markdown","fe84937f":"markdown","24e5c985":"markdown","09bc4fa3":"markdown","e15e1f6d":"markdown","07b10751":"markdown","f890b6e4":"markdown","91638f92":"markdown","235ba1a9":"markdown","d8b68eac":"markdown","a67a3c9a":"markdown","9b6e1825":"markdown","f9da9894":"markdown","bbd98afd":"markdown","0c00ac86":"markdown","adf8cd0c":"markdown","a9f706d6":"markdown","4eb39f41":"markdown","36a9030c":"markdown","1931b20a":"markdown","dd4d0420":"markdown","db642175":"markdown","343f3b0e":"markdown","d92f8d81":"markdown","779b2771":"markdown","1a838036":"markdown","3c142c05":"markdown","08b47beb":"markdown","e2b8a7d3":"markdown","8eba605a":"markdown","e405688d":"markdown","59568f0c":"markdown","7ecdf5d0":"markdown","d87154b6":"markdown","6cc7cb18":"markdown","99d1c276":"markdown","6f089024":"markdown","ab4d192f":"markdown","b4b8b837":"markdown"},"source":{"de307907":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # even more plotting\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder # preprocessing\nfrom sklearn.preprocessing import StandardScaler # more preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","eee68269":"training_set = pd.read_csv('..\/input\/train.csv')\ntraining_set.head()","f1cdb303":"training_set.info()","9cf92dcb":"training_set[training_set.Age.isnull()]","37dbb21d":"age = training_set.Age\nsns.distplot(age.dropna())","d73b4a45":"print(age.mean())\nprint(age.median())\nprint(age.mode())\nprint(age.std())","013da459":"age = age.fillna(int(training_set.Age.median()))","c6298819":"sns.distplot(age)","b965e33c":"print(age.mean())\nprint(age.median())\nprint(age.mode())\nprint(age.std())","287a7380":"age = training_set.Age.interpolate()","1ff37cc7":"sns.distplot(age)","9c8db30a":"print(age.mean())\nprint(age.median())\nprint(age.mode())\nprint(age.std())","05c187b3":"age = training_set.Age.interpolate(method = 'polynomial', order = 2)","892794d3":"sns.distplot(age)","d73b4b47":"print(age.mean())\nprint(age.median())\nprint(age.mode())\nprint(age.std())","2244be6d":"age[age < 0]","1e037071":"training_set.Age = training_set.Age.interpolate()","48a52345":"training_set.info()","4876f76c":"training_set[training_set.Embarked.isnull()]","16da852c":"training_set.Embarked = training_set.Embarked.fillna('S')\ntraining_set.info()","79aa736b":"training_set[training_set.Cabin.isnull()].head()","d4e84341":"(1 - 204\/891)*100","3f5e16a2":"training_set[training_set.Cabin.isnull() == False].head()","80863505":"training_set.Cabin.value_counts().head(10)","440314ab":"training_set = training_set.drop('Cabin', 1)\ntraining_set.info()","20d29c18":"corr = training_set.corr()\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","6059703c":"corr","4eca62d4":"test_set = pd.read_csv('..\/input\/test.csv')\ntest_set.head()","7b779c42":"test_set.info()","a38a9c34":"test_set.Age = test_set.Age.interpolate()\ntest_set = test_set.drop('Cabin', 1)\ntest_set.info()","e7f3081a":"test_set[test_set.Fare.isnull()]","8c60eb29":"sns.distplot(test_set.Fare[test_set.Pclass == 3].dropna())\nprint(test_set.Fare[test_set.Pclass == 3].mode())","6733d579":"test_set.Fare = test_set.Fare.fillna(7.75)\ntest_set.info()","ae0c8ad5":"sns.distplot(training_set.Survived)","591fb7de":"corr.Survived","58aa42c7":"sns.countplot(x = 'Pclass', hue = 'Survived', data = training_set)\nplt.ylabel('Passenger Count')","74416652":"age = pd.qcut(training_set.Age, 8)\nplt.figure(figsize = (8, 5))\nsns.countplot(x = age, hue = training_set.Survived)","22e25836":"sns.countplot(x = 'Sex', hue = 'Survived', data = training_set)\nplt.ylabel('Passenger Count')","20b2e14d":"plt.figure(figsize = (10, 5))\nplt.subplot(1, 2, 1)\nsns.countplot(x = 'Parch', hue = 'Survived', data = training_set)\nplt.ylabel('Passenger Count')\nplt.xlabel('No. of parents\/children')\nplt.subplot(1, 2, 2)\nsns.countplot(x = 'SibSp', hue = 'Survived', data = training_set)\nplt.ylabel('Passenger Count')\nplt.xlabel('Siblings\/Spouse')\nplt.tight_layout()","58dc5391":"training_set.Ticket.value_counts().head(10)","0a46b48a":"training_set['Ticket_Frequency'] = training_set.groupby('Ticket')['Ticket'].transform('count')\nsns.countplot(x = 'Ticket_Frequency', hue = 'Survived', data = training_set)","9c61cef3":"test_set['Ticket_Frequency'] = test_set.groupby('Ticket')['Ticket'].transform('count')","ee18a088":"training_set = training_set.drop(['Name', 'PassengerId'], 1)\ntraining_set.info()","ddda1ec9":"test_set = test_set.drop(['Name', 'PassengerId'], 1)\ntest_set.info()","78f7c3a8":"training_set = training_set.drop('Ticket', 1)\ntest_set = test_set.drop('Ticket', 1)","f177dfd0":"label_encoder = LabelEncoder()\ntraining_set.Sex = label_encoder.fit_transform(training_set.Sex)\ntest_set.Sex = label_encoder.transform(test_set.Sex)","f19aea76":"label_encoder = LabelEncoder()\ntraining_set.Embarked = label_encoder.fit_transform(training_set.Embarked)\ntest_set.Embarked = label_encoder.transform(test_set.Embarked)","66138255":"training_set['Pclass1'] = pd.get_dummies(training_set.Pclass)[1]\ntraining_set['Pclass2'] = pd.get_dummies(training_set.Pclass)[2]\n\ntraining_set['Embarked0'] = pd.get_dummies(training_set.Embarked)[0]\ntraining_set['Embarked1'] = pd.get_dummies(training_set.Embarked)[1]\n\ntraining_set.head()","769acb88":"test_set['Pclass1'] = pd.get_dummies(test_set.Pclass)[1]\ntest_set['Pclass2'] = pd.get_dummies(test_set.Pclass)[2]\n\ntest_set['Embarked0'] = pd.get_dummies(test_set.Embarked)[0]\ntest_set['Embarked1'] = pd.get_dummies(test_set.Embarked)[1]\n\ntest_set.head()","1b6c64c9":"training_set = training_set.drop(columns = ['Pclass', 'Embarked'], axis = 1)","84b1ddd2":"test_set = test_set.drop(columns = ['Pclass', 'Embarked'], axis = 1)","19b3bf15":"X_train = training_set.iloc[:, 1:]\ny_train = training_set.Survived\nX_test = test_set","0979c300":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","0e55e833":"X_train","6c2c3544":"model = RandomForestClassifier(criterion='gini', \n                            n_estimators=1100,\n                            max_depth=5,\n                            min_samples_split=4,\n                            min_samples_leaf=5,\n                            max_features='auto',\n                            n_jobs=-1,\n                            verbose=1)","c333a119":"model.fit(X_train, y_train)","3e5804f6":"model.score(X_train, y_train)","46a46c56":"Since most third class passengers had bought the tickets for 7.75 pounds. So, lets put that same price for Thomas Storey as well.\n![Titanic Ticket Prices](https:\/\/qphs.fs.quoracdn.net\/main-qimg-5ab46f31803d2242e89996144a228ab1-c)","396578e4":"## Embarked","a4e064ae":"## Cabin","24c90792":"Lets also look at the gender factor.","5395389e":"77.1% of data is missing for the `Cabin` feature. That is more than 3\/4 of the data. Lets see if we can decipher any information from the non missing values","b4e9f437":"`SibSp` and `Parch` are significantly positively correlated. That is obvious because `SibSp` refers to the number of siblings or spouse(s) on board and `Parch` refers to the number of parents or children on board. So, both of the features signify the family size in some way.\n\n`Parch` and `Fare` are also positively correlated. This is natural since more the number of family members (in the form of parents or children) more will be the fare.\n\nHowever, `Fare` and `Pclass` are negatively correlated, perhaps because the 1st class passengers paid the most, followed by the 2nd class, and the least fare was for the 3rd class passengers.","6f03c2ff":"# Machine Learning","f1d0db3e":"So, it seems like a maximum of 4 people could stay in a single cabin. In these cabin names, the first character signifies the deck in which the passenger was staying. The A, B and C decks were for the first class passengers; D and E were for everyone; and F and G were for second and third class passengers. [G\u00fcne\u015f Evitan](https:\/\/www.kaggle.com\/gunesevitan) in his [kernel](https:\/\/www.kaggle.com\/gunesevitan\/advanced-feature-engineering-tutorial-with-titanic) has done a full in depth analysis of decks and survival rates. However, since the available information is so less, we are better off dropping the feature altogether.","0340646c":"The passenger name is a great indicator of marital status and class. But both of these features are available to us. Moreover, one must realise that during 1912, hierarchical classes based on family history and inheritance were becoming obsolete. A lot of people were working in areas where their parents did not. So, predicting if a person belonged to a higher or lower class based on his\/her name, while a good indicator for earlier decades, would not be accurate for this era. So we can safely drop the names and Passenger IDs.","2739b453":"Now that the training set is analysed, lets look at the test set and replicate these changes.","4d4ccabf":"Many more males died in the tragedy that females. This suggests a rescue strategy of females and children first. This leads to another question: did the family size affect survival?","b7e75d91":"The RMS Titanic was a British passenger liner that started its journey in Southampton on April 10, 1912. It would have gone to New York City, had it not sank in the Atlantic Ocean, after colliding with an iceberg on April 15, 1912. The Titanic sank early in the morning of April 15, 1912. At the time of sinking, over a thousand passengers were on board since it was the largest ocean liner at the time. The lifeboat system in Titanic was designed to ferry passengers to nearby rescue vessels, and not to hold everyone on board simultaneously. This resulted in chaos and death of a lot more people.\n![](http:\/\/www.historicmysteries.com\/wp-content\/uploads\/2015\/05\/RMS-Olympic-1024x705.jpg)","c861c7a6":"# Exploratory Data Analysis","d8d0cccc":"And we replicate this with the test set as well","26d8af36":"Now that everything is numerical, we can go ahead and one hot encode the non-binary categorical features. These are `Pclass` and `Embarked`.","f00b9504":"`X_train` will be the data in which the model will train, `y_train` will be the ground truths or labels, and `X_test` will be the test data whose predictions will be generated by the model.","8c211579":"This provides a lot of information about the victims and survivors whose ages are missing from the records. [Mr. James Moran](https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/daniel-james-moran.html) for example, who could be the same person as Daniel J. Moran (as in the records) was born on July 07, 1883. He boarded the Titanic with his sister [Bertha Moran](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/bertha-bridget-moran.html) who survived the tragedy. However, his body was never recovered or identified. Moreover, the details for both of these people don't show that they were travelling with a sibling which makes the things more tricky. So, it would not be clever to conclude anything.\n![Daniel James Moran](https:\/\/www.encyclopedia-titanica.org\/images\/daniel-moran-uniform-H.jpg)","c0a1ba37":"## Age","c7ed1e05":"What features were the most correlated with survival?","fe84937f":"In order to get a better idea on how the age is distributed, lets take a look at the probability distribution of the `Age` feature.","24e5c985":"This clearly did not help since everyone whose age was not recorded is being assumed to be 28 years old at the time of the tragedy (which is a huge number), which is unrealistic. So, maybe interpolating might help in keeping the Gaussian distribution intact.","09bc4fa3":"The model learns with 84.28% accuracy. On further fine tuning we can get a better training accuracy. For the sake of this demonstration, this kernel focuses largely on the data cleaning, EDA and preprocessing parts. I have only taken some defaults and generated the results.","e15e1f6d":"In this stage, we prepare the data for computation.","07b10751":"Did a passenger's ticket affect his\/her survival?","f890b6e4":"The above heat map can be seen in the form of a dataframe (matrix) as well","91638f92":"# Cleaning the Data","235ba1a9":"The non-numerical categorical data features are `Sex`, and `Embarked`. So, we go ahead and enncode these features","d8b68eac":"If we look at survival and age, these have a negative correlation. This meant that the likelihood of survival for an older passenger was less than that of a younger passenger.","a67a3c9a":"For exploratory data analysis, we can ask several questions and seek to answer these questions by studying patterns from the data itself. How did age affect the survival rate? Or, did gender or class affect the survival of passengers? But first, we take a look at the distribution of passengers who survived and didn't survive.","9b6e1825":"[Thomas Storey](https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/thomas-storey.html), as the data suggests, was a third class passenger. So, it is fair to assume that his fare price must be in the range of fare prices for other third class passengers.","f9da9894":"Now that the training set is cleaned, lets look at how every feature is correlated with every other feature.","bbd98afd":"So, if a passenger was not travelling with a family member, his\/her chance of survival was lower.","0c00ac86":"Only among the first class passengers, the number of survived passengers is greater than the passengers who died. Among the third class passengers, this disparity is huge, with the numer of survived passengers much lower than those who couldn't survive.","adf8cd0c":"The test set is successfully cleaned as well!","a9f706d6":"I am preparing a model predictor using Random Forests.","4eb39f41":"The features `Age`, `Cabin` and `Embarked` have missing values. Let's look at all these features more closely.","36a9030c":"Polynomial interpolation introduced negative ages which is absurd. So, the best method seems to be linear interpolation.","1931b20a":"# Data Preprocessing","dd4d0420":"Missing ages have been successfully filled! Now lets look at the `Embarked` feature.","db642175":"# Importing the Relevant Libraries","343f3b0e":"Here, just like in the training set, `Age` and `Cabin` have missing values.","d92f8d81":"Now, we must scale the data for uniformity. This makes the model learn faster.","779b2771":"This shows that there were a maximum of 7 people travelling with the same ticket. This is important because not everyone was travelling with family. As we saw before, some upper class women did travel with maids. There might be friends that travelled together. So, it is much better if we look at the frequency of these tickets.","1a838036":"The class and fare prices seem to be very correlated with survival. If one paid a more expensive price, and\/or belonged to a higher class, one was more likely to survive the tragedy.","3c142c05":"In this kernel, we seek to study patterns of which passengers were more likely to survive. In the commotion of the tragedy, we will see if any rescue strategies were involved. Since the data is more than 100 years old, it is inevitable that some records were lost. So, this kernel also demonstrates how to regenerate lost data and how to handle the missing values.","08b47beb":"On digging a little deep, we find that [Amelie Icard](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/amelia-icard.html) boarded the Titanic as maid to [Mrs. George Nelson Stone](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html). So, both of these passengers boarded together in first class. They also survived the tragedy, possibly because they were upper class females and were rescued first. From the records, it shows that Mrs. George Nelson Stone boarded the ship along with Amelie, her maid, from Southampton (S).\n![Martha Stone](https:\/\/www.encyclopedia-titanica.org\/images\/martha-stone.jpg)","e2b8a7d3":"`Fare` has one missing value.","8eba605a":"The probability distribution of passenger ages resembles closely to a Gaussian distribution. So, lets fill the missing values with the median and see what happens.","e405688d":"Since we have the `Ticket_Frequency` feature, which is a much more effective way of quantifying the `Ticket` feature, we can get rid of the latter as well.","59568f0c":"This resembles a Bernoulli distribution. Moreover, we see that more prople died in the tragedy than those who survived.","7ecdf5d0":"So, if a ticket was shared among 2 or 3 passengers, their chance of survival was higher than their chance of death. We replicate the same procedure in test set.","d87154b6":"Linear interpolation seems to be better, but lets try the polynomial interpolation as well, just to compare.","6cc7cb18":"## Fare","99d1c276":"So, if a passenger was in the category of 0 to 16 years of age, he\/she was more likely to survive. In all the other categories, lower nnumber of people survived. Furthermore, if a passenger was between 16 and 21 years of age, he\/she was most likely to die in the tragedy.","6f089024":"And now, we are only left with the `Cabin` feature!","ab4d192f":"Now, if we have a look at our training data, it is in the form of an array with scaled information.","b4b8b837":"Now that we have the one hot encoded features, we can get rid of the original `Pclass` and `Embarked` features."}}