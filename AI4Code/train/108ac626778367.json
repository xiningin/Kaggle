{"cell_type":{"bb9f8414":"code","509973d7":"code","13b369a3":"code","14968cb3":"code","f248be4b":"code","8e359e52":"code","e0d20018":"code","4bc302d0":"code","0caedf99":"code","8084e48d":"code","5b5bbb0e":"code","69c456c0":"code","0c3561b7":"code","5fd38fad":"code","13acb934":"code","4a51d55a":"code","4520a71e":"code","0ca22779":"code","3585a225":"code","be6a8a58":"code","a2d0888e":"code","496433b7":"markdown","3b7805cb":"markdown","96158b55":"markdown","2330787b":"markdown","b0ad4ecd":"markdown","6444a47d":"markdown"},"source":{"bb9f8414":"%matplotlib inline\nimport os\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nDATA_DIR = '..\/input\/20180706181348\/'\n!ls {DATA_DIR}","509973d7":"# point cloud stuff\nfrom collections import defaultdict\nimport sys\nsys_byteorder = ('>', '<')[sys.byteorder == 'little']\nply_dtypes = dict([\n    (b'int8', 'i1'),\n    (b'char', 'i1'),\n    (b'uint8', 'u1'),\n    (b'uchar', 'b1'),\n    (b'uchar', 'u1'),\n    (b'int16', 'i2'),\n    (b'short', 'i2'),\n    (b'uint16', 'u2'),\n    (b'ushort', 'u2'),\n    (b'int32', 'i4'),\n    (b'int', 'i4'),\n    (b'uint32', 'u4'),\n    (b'uint', 'u4'),\n    (b'float32', 'f4'),\n    (b'float', 'f4'),\n    (b'float64', 'f8'),\n    (b'double', 'f8')\n])\nvalid_formats = {'ascii': '', 'binary_big_endian': '>',\n                 'binary_little_endian': '<'}\n\ndef read_ply(filename):\n    with open(filename, 'rb') as ply:\n\n        if b'ply' not in ply.readline():\n            raise ValueError('The file does not start whith the word ply')\n        # get binary_little\/big or ascii\n        fmt = ply.readline().split()[1].decode()\n        # get extension for building the numpy dtypes\n        ext = valid_formats[fmt]\n\n        line = []\n        dtypes = defaultdict(list)\n        count = 2\n        points_size = None\n        mesh_size = None\n        while b'end_header' not in line and line != b'':\n            line = ply.readline()\n\n            if b'element' in line:\n                line = line.split()\n                name = line[1].decode()\n                size = int(line[2])\n                if name == \"vertex\":\n                    points_size = size\n                elif name == \"face\":\n                    mesh_size = size\n\n            elif b'property' in line:\n                line = line.split()\n                # element mesh\n                if b'list' in line:\n                    mesh_names = ['n_points', 'v1', 'v2', 'v3']\n\n                    if fmt == \"ascii\":\n                        # the first number has different dtype than the list\n                        dtypes[name].append(\n                            (mesh_names[0], ply_dtypes[line[2]]))\n                        # rest of the numbers have the same dtype\n                        dt = ply_dtypes[line[3]]\n                    else:\n                        # the first number has different dtype than the list\n                        dtypes[name].append(\n                            (mesh_names[0], ext + ply_dtypes[line[2]]))\n                        # rest of the numbers have the same dtype\n                        dt = ext + ply_dtypes[line[3]]\n\n                    for j in range(1, 4):\n                        dtypes[name].append((mesh_names[j], dt))\n                else:\n                    if fmt == \"ascii\":\n                        dtypes[name].append(\n                            (line[2].decode(), ply_dtypes[line[1]]))\n                    else:\n                        dtypes[name].append(\n                            (line[2].decode(), ext + ply_dtypes[line[1]]))\n            count += 1\n\n        # for bin\n        end_header = ply.tell()\n\n    data = {}\n\n    if fmt == 'ascii':\n        top = count\n        bottom = 0 if mesh_size is None else mesh_size\n\n        names = [x[0] for x in dtypes[\"vertex\"]]\n\n        data[\"points\"] = pd.read_csv(filename, sep=\" \", header=None, engine=\"python\",\n                                     skiprows=top, skipfooter=bottom, usecols=names, names=names)\n\n        for n, col in enumerate(data[\"points\"].columns):\n            data[\"points\"][col] = data[\"points\"][col].astype(\n                dtypes[\"vertex\"][n][1])\n\n        if mesh_size is not None:\n            \n            top = count + points_size\n\n            names = [x[0] for x in dtypes[\"face\"]][1:]\n            usecols = [1, 2, 3]\n\n            data[\"mesh\"] = pd.read_csv(\n                filename, sep=\" \", header=None, engine=\"python\", skiprows=top, usecols=usecols, names=names)\n\n            for n, col in enumerate(data[\"mesh\"].columns):\n                data[\"mesh\"][col] = data[\"mesh\"][col].astype(\n                    dtypes[\"face\"][n + 1][1])\n\n    else:\n        with open(filename, 'rb') as ply:\n            ply.seek(end_header)\n            points_np = np.fromfile(ply, dtype=dtypes[\"vertex\"], count=points_size)\n            if ext != sys_byteorder:\n                points_np = points_np.byteswap().newbyteorder()\n            data[\"points\"] = pd.DataFrame(points_np)\n            if (mesh_size is not None) and False:\n                print('reading mesh', mesh_size)\n                mesh_np = np.fromfile(ply, dtype=dtypes[\"face\"], count=mesh_size)\n                print('mesh', mesh_np.shape)\n                if ext != sys_byteorder:\n                    mesh_np = mesh_np.byteswap().newbyteorder()\n                data[\"mesh\"] = pd.DataFrame(mesh_np)\n                data[\"mesh\"].drop('n_points', axis=1, inplace=True)\n\n    return data\ndef read_ply_points(c_file, **kwargs):\n    out_df = read_ply(c_file)['points']\n    for k,v in kwargs.items():\n        out_df[k] = v\n    return out_df","13b369a3":"ply_path = glob(os.path.join(DATA_DIR, '*.ply'))[0]\npng_path = glob(os.path.join(DATA_DIR, '*.png'))[0]\nply_data = read_ply_points(ply_path)\nimg_data = imread(png_path)\n\nprint(ply_data.keys(), img_data.shape)\nplt.imshow(img_data)\nply_data.sample(4)","14968cb3":"ply_data.sample(5000).plot.scatter('x', 'y')","f248be4b":"ply_data.sample(5000).plot.scatter('x', 'z')","8e359e52":"temp_df = ply_data.sample(1000)\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.quiver(temp_df['x'], temp_df['y'], temp_df['nx'], temp_df['ny'])","e0d20018":"from mpl_toolkits.mplot3d import axes3d\ntemp_df = ply_data.sample(5000)\nfig = plt.figure(figsize = (10, 10))\nax = fig.gca(projection='3d')\nax.quiver(temp_df['x'], temp_df['y'], temp_df['z'], \n          temp_df['nx'], temp_df['ny'], temp_df['nz'],\n         length=0.1,\n         normalize=True)\nax.view_init(-45, 30)","4bc302d0":"RAW_DIR = '..\/input\/d45cd2dd-beaf-22aa-8529-9777b10721f4\/'\n!cat {os.path.join(RAW_DIR, 'depth00', 'camera.yaml')}","0caedf99":"# decompress depth images and read them in\n!unzip -qq {os.path.join(RAW_DIR, 'depth00', 'depth_images.zip')}\nall_depth_maps = {int(os.path.splitext(k)[0].split('_')[-1]): imread(k) for k in glob('*.pnm')}\nprint('Map Shape', next(iter(all_depth_maps.values())).shape, 'Maps', len(all_depth_maps))\n!rm *.pnm","8084e48d":"fig, m_axs = plt.subplots(3, 3, figsize = (15, 15))\nfor (k, v), c_ax in zip(all_depth_maps.items(), m_axs.flatten()):\n    c_ax.imshow(v)\n    c_ax.set_title('Timestamp: {}'.format(k))\n    c_ax.axis('off')","5b5bbb0e":"print('Camera Info')\n!cat {os.path.join(RAW_DIR, 'color00', 'camera.yaml')}\nprint('\\nTime Data')\ntime_df = pd.read_table(os.path.join(RAW_DIR, 'color00', 'timestamps.txt'), header=None, names = ['Timestamp'])\ntime_df['Frame'] = time_df.index\nprint(time_df.shape[0])\ntime_df.sample(3)","69c456c0":"import cv2 # use opencv\ndef read_video_segment(in_path, vid_seg = None, seg_frames = 4):\n    cap = cv2.VideoCapture(in_path)\n    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n    frames = []\n    if cap.isOpened() and video_length > 0:\n        frame_ids = [0]\n        if seg_frames<0:\n            frame_ids = range(video_length+1)\n        else:\n            if vid_seg is None:\n                vid_seg = np.linspace(0, 1, seg_frames)\n            else:\n                vid_seg = np.clip(vid_seg, 0, 1)\n\n            frame_ids = np.clip(video_length*vid_seg, 0, video_length-1).astype(int)\n        count = 0\n        success, image = cap.read()\n        print('Loaded', video_length, 'frames video', image.shape, 'resolution.', 'Extracting', len(frame_ids), 'frames')\n        while success:\n            if count in frame_ids:\n                frames.append(image)\n            success, image = cap.read()\n            count += 1\n    return frames\ncolor_frames = read_video_segment(os.path.join(RAW_DIR, 'color00', 'color_images.mp4'), seg_frames = -1)","0c3561b7":"fig, m_axs = plt.subplots(3, 3, figsize = (15, 15))\nfor v, c_ax in zip(color_frames, m_axs.flatten()):\n    c_ax.imshow(v[:, :, ::-1]) # opencv uses BGR\n    c_ax.axis('off')","5fd38fad":"time_df['color'] = time_df['Frame'].map(lambda i: color_frames[i])\ndepth_df = pd.DataFrame([{'Timestamp': k, 'depth': v} for k,v in all_depth_maps.items()])","13acb934":"combined_df = pd.merge(time_df, depth_df, how='outer', on='Timestamp').sort_values('Timestamp').drop('Frame', 1)\ncombined_df.sample(3)","4a51d55a":"combined_df['back_depth'] = combined_df['depth'].fillna(method='bfill')\ncombined_df['forward_depth'] = combined_df['depth'].fillna(method='ffill')\ncombined_df['avg_depth'] = combined_df.apply(lambda x: 0.5*x['back_depth']+0.5*x['forward_depth'], 1) # interpolate depth maps\nclean_df = combined_df[['Timestamp', 'color', 'avg_depth', 'back_depth']].dropna()\nprint(clean_df.shape[0], 'completed frames')\nclean_df.sample(3)","4520a71e":"fig, m_axs = plt.subplots(3, 5, figsize = (24, 15))\nfor (_, c_row), (c_ax, d_ax, f_ax) in zip(clean_df.sample(9).iterrows(), m_axs.T):\n    depth = c_row['avg_depth']\n    c_img = c_row['color'][:, :, ::-1].swapaxes(0, 1)\n    c_ax.imshow(c_img) # opencv uses BGR\n    c_ax.set_title('{Timestamp}'.format(**c_row))\n    c_ax.axis('off')\n    d_ax.imshow(depth)\n    d_ax.set_aspect(3)\n    d_ax.set_title('Average Depth')\n    \n    f_ax.imshow(c_row['back_depth'])\n    f_ax.set_aspect(3)\n    f_ax.set_title('Last Depth')","0ca22779":"from skimage.transform import resize as imresize\nfrom skimage.filters import gaussian\n_, test_row = next(clean_df.sample(1, random_state = 2015).iterrows())\ndepth = test_row['avg_depth']\nc_img = test_row['color'][:, :, ::-1].swapaxes(0, 1)\nprint(depth.shape, c_img.shape)\nraw_shape = (c_img.shape[0]\/\/3, c_img.shape[1]\/\/3)\nn_color_img = imresize(c_img, raw_shape+(3,), order = 2, mode = 'reflect')\ndef process_depth(in_img):\n    return np.sqrt(gaussian(imresize(in_img, raw_shape, order = 2, mode = 'reflect'), 4))\n\nn_depth_img = process_depth(depth)\nl_depth_img = process_depth(test_row['back_depth'])\n\nprint(n_color_img.shape, n_depth_img.shape)\nfig, (c_ax, d_ax, f_ax) = plt.subplots(1, 3, figsize = (20, 4))\nc_ax.imshow(c_img) # opencv uses BGR\nc_ax.set_title('{Timestamp}'.format(**test_row))\nc_ax.axis('off')\nd_ax.imshow(n_depth_img)\nd_ax.set_title('Average Depth')\n\nf_ax.imshow(l_depth_img)\nf_ax.set_title('Last Depth')","3585a225":"fig = plt.figure(figsize = (10, 10))\nax = fig.gca(projection='3d')\nxx,yy = np.meshgrid(range(raw_shape[1]),range(raw_shape[0]))\nax.plot_surface(xx,yy,n_depth_img, \n                rstride=1, cstride=1, \n                facecolors=n_color_img.astype(np.float32),\n                linewidth=0, antialiased=True)\nax.view_init(90, 90)","be6a8a58":"ax.view_init(0, 90)\nfig","a2d0888e":"ax.view_init(-45, 90)\nfig","496433b7":"# Get Raw Camera Data","3b7805cb":"# Get Color Data\nHere I try a very lazy approach to calculate the color by creating independent clouds and then making voxel grids and stacking them but we see that they dont line up (expected)","96158b55":"# Overview\nUsing the Constructor Developer Tool for Project Tango Phones (https:\/\/play.google.com\/store\/apps\/details?id=com.projecttango.constructor&hl=en) you can collect 3d scenes. This notebook goes through some of the data collected like the final reconstructed point clouds and surface normals and the raw collected images and depth maps. The data are quite messy and so require a fair amount of work to even start to see what they could be showing.","2330787b":"# Show Points\nHere we can show the points in the $xy$ and $xz$ planes to get a feel for the data","b0ad4ecd":"# Plot with Surface Normals","6444a47d":"# Combine Color and Depth Images\nHere we combine the color and depth images and see that they line up poorly so none of the images have the same stamp"}}