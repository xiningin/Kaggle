{"cell_type":{"9e9a67f7":"code","4b24d415":"code","d02f7c4f":"code","24199922":"code","d08eab19":"code","45c9fad6":"code","f016ab35":"code","f0b85d0a":"code","d1747420":"code","e5a1710c":"code","0227e699":"code","3b67ed4e":"code","74071bfb":"code","767cda44":"code","6305f627":"code","a1f51446":"code","597afd67":"code","80120950":"code","61f87a0c":"code","07333791":"code","a6a406bd":"code","c264a7b2":"code","e55f809f":"code","a8fc3a4e":"code","d5414b57":"code","90c01dac":"code","5af16862":"code","a35dc811":"code","c9d73761":"code","755c7e42":"code","a69aac44":"code","093e9d60":"code","1338229d":"code","4d20392f":"code","c1957e11":"code","96eb8f2c":"code","b4e60936":"code","87e85a54":"code","2a4baf5f":"code","087deb3e":"code","848d5916":"code","1fc06ca5":"code","1cca5e76":"code","e9869afd":"code","a0f62747":"code","2ec1032f":"markdown","7e43056a":"markdown"},"source":{"9e9a67f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b24d415":"base_dir = '\/kaggle\/input\/100-bird-species\/'\n\nimport os\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'valid')\ntest_dir = os.path.join(base_dir, 'test')","d02f7c4f":"train_lstnames = os.listdir(train_dir)\nvalid_lstnames = os.listdir(validation_dir)\ntest_lstnames = os.listdir(test_dir)","24199922":"train_species_dir = []\nfor idx, spec_name in enumerate(train_lstnames):\n    spec_dir = os.path.join(train_dir, spec_name)\n    train_species_dir.append(spec_dir)\n\nvalid_species_dir = []\nfor idx, spec_name in enumerate(valid_lstnames):\n    spec_dir = os.path.join(validation_dir, spec_name)\n    valid_species_dir.append(spec_dir)\n\ntest_species_dir = [] \nfor idx, spec_name in enumerate(test_lstnames):\n    spec_dir = os.path.join(test_dir, spec_name)\n    test_species_dir.append(spec_dir)","d08eab19":"train_species_dir","45c9fad6":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","f016ab35":"number_per_species = {}\n\nfor idx, train_spec_dir in enumerate(train_species_dir):\n    num_spec = len(os.listdir(train_spec_dir))\n    spec_name = train_lstnames[idx]\n    number_per_species[spec_name] = num_spec","f0b85d0a":"spec_number_df = pd.DataFrame(data=[number_per_species[i] for i in number_per_species.keys()], index=number_per_species.keys(), columns=['Quantity'])","d1747420":"spec_number_df","e5a1710c":"spec_number_df['Quantity'].sum()","0227e699":"spec_number_df.plot(kind = 'bar', x = None, y = 'Quantity', figsize = (50, 10), title = 'Number of bird species', fontsize = 10)","3b67ed4e":"spec_number_df.describe()","74071bfb":"def generate_random_bird(train_lstnames, number_random_species, number_random_per_kind, train_species_dir, df):\n    species_idx = np.random.choice(np.arange(len(train_lstnames)), number_random_species, replace = False)\n\n    next_bird = {}\n    for idx in species_idx:\n        label = train_lstnames[idx]\n        lst_name = os.listdir(train_species_dir[idx])\n        random_idxs = np.random.choice(int(df.loc[df.index.values[idx]].values), number_random_per_kind, replace = False)\n        choose_bird = []\n        for bird_idx in random_idxs:\n            bird_name = os.path.join(train_species_dir[idx], lst_name[bird_idx])\n            choose_bird.append(bird_name)\n        next_bird[label] = choose_bird\n        \n    return next_bird","767cda44":"def plot_image(number_random_species, number_random_per_kind, image_size, next_bird, class_names = None, model  = None, get_prediction = False):\n    fig = plt.gcf()\n\n    nrows = number_random_species\n    ncols = number_random_per_kind\n\n    fig.set_size_inches(image_size*nrows, image_size*ncols)\n    \n    if not get_prediction:\n        model = None\n        class_names = None\n    else:\n        inverse_class_names = {}\n        for k, v in class_names.items():\n            inverse_class_names[int(v)] = k\n            \n#         print(inverse_class_names)\n        \n    count = 0\n    for label, img_paths in next_bird.items():\n        for img_path in img_paths:\n            sb = plt.subplot(nrows, ncols, count + 1)\n            img = mpimg.imread(img_path)\n            sb.set_title(f'{label}', color = 'r')\n            \n            if get_prediction:\n                from tensorflow.keras.preprocessing.image import img_to_array\n                import cv2\n                new_img = cv2.resize(img, (224, 244))\n                new_img = img_to_array(img)\n                new_img = np.expand_dims(img, axis = 0)\n#                 print('Shape', new_img.shape)\n                std_img = new_img \/ 255.0\n                pred = model.predict(std_img)\n                print('Prediction', np.argmax(pred))\n                pred_name = inverse_class_names[int(np.argmax(pred))]\n                sb.set_title(f'Predicted: {pred_name} \\nGround True: {label}', color = 'r', fontsize = 10)\n                \n            sb.axis('Off')\n            \n            plt.imshow(img)\n            count += 1\n    plt.show()","6305f627":"import numpy as np\nimport matplotlib.image as mpimg","a1f51446":"number_random_species = 5\nnumber_random_per_kind = 4\n\nnext_bird = generate_random_bird(train_lstnames, number_random_species, number_random_per_kind, train_species_dir, spec_number_df)\nplot_image(number_random_species, number_random_per_kind, 4, next_bird)","597afd67":"input_shape = (224, 224, 3)","80120950":"import tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model","61f87a0c":"model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\nmodel.summary()","07333791":"for layer in model.layers:\n    layer.trainable = False\n    \n# last_layer = model.get_layer('mixed8')\n\n# last_output = last_layer.output","a6a406bd":"from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, BatchNormalization, Activation, Dense\n\nnum_classes = len(train_lstnames)\n\n\nx = GlobalAveragePooling2D()(model.output)\n\nx = Dense(units = 512, kernel_initializer='he_normal')(x)\nx = BatchNormalization(axis = -1)(x)\nx = Activation('relu')(x)\nx = Dropout(0.2)(x)\n# x = Dense(units = 1024, activation = 'elu', kernel_initializer='he_normal')(x)\n# x = Dropout(0.4)(x)\nx = Dense(units = num_classes, activation = 'softmax')(x)\n\nfinal_model = Model(inputs = [model.input], outputs = [x])\n\nfinal_model.summary()","c264a7b2":"from tensorflow.keras.optimizers import Adam\n\nfinal_model.compile(loss = 'sparse_categorical_crossentropy', optimizer=Adam(lr = 0.2), metrics = ['accuracy'])","e55f809f":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0\/255,\n    rotation_range=10,\n    zoom_range=0.2,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalid_datagen = ImageDataGenerator(rescale = 1.0\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n            train_dir,\n            batch_size=512,\n            class_mode='sparse',\n            shuffle=True,\n            target_size = (224, 224)\n)\n\nvalid_generator = valid_datagen.flow_from_directory(\n            validation_dir,\n            batch_size=128,\n            class_mode='sparse',\n            shuffle=True,\n            target_size = (224, 224)\n)\n\ntest_generator = test_datagen.flow_from_directory(\n            test_dir,\n            batch_size=128,\n            class_mode='sparse',\n            shuffle=True,\n            target_size = (224, 224)\n)","a8fc3a4e":"import os\nroot_logdir = os.path.join('\/kaggle\/working', \"my_logs\")\n\ndef get_run_logdir():\n  import time\n  run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n  return os.path.join(root_logdir, run_id)\n\nrun_logdir = get_run_logdir()","d5414b57":"from tensorflow.keras.callbacks import TensorBoard\ntensorboard_cb = TensorBoard(run_logdir)","90c01dac":"history = final_model.fit(train_generator, epochs = 5, validation_data=valid_generator, steps_per_epoch=27503\/512, \n                                    validation_steps=1000\/128, verbose = 1, callbacks=[tensorboard_cb])","5af16862":"trainableIdx = 0\nfor layer in final_model.layers:\n    print(f'{layer.name} is trainable {layer.trainable}')\n    if layer.trainable:\n        trainableIdx += 1","a35dc811":"for layer in model.layers[-28 : ]:\n    layer.trainable = True","c9d73761":"for layer in final_model.layers:\n    print(f'{layer.name} is trainable {layer.trainable}')","755c7e42":"from tensorflow.keras.optimizers import Adam\n\nfinal_model.compile(loss = 'sparse_categorical_crossentropy', optimizer=Adam(lr = 0.001), metrics = ['accuracy'])","a69aac44":"import tensorflow as tf","093e9d60":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n\ndef exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0*0.1**(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(lr0=0.01, s = 10)\nlr_scheduler = LearningRateScheduler(exponential_decay_fn)\nmodel_checkpoint = ModelCheckpoint('my_checkpoint.h5', save_best_only=True)\nearly_stop = EarlyStopping(patience = 10, restore_best_weights=True)\n\nclass StopTraining(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs):\n        if logs.get('val_accuracy') >= 0.95:\n            print('Reach the desirable accuracy')\n            self.model.stop_training = True\n            \nstopTrain = StopTraining()","1338229d":"%load_ext tensorboard\n%tensorboard --logdir=.\/my_logs --port 6006","4d20392f":"history = final_model.fit(train_generator, epochs = 20, validation_data=valid_generator, steps_per_epoch=27503\/512, \n                                    validation_steps=1000\/128, verbose = 1, callbacks=[lr_scheduler, model_checkpoint, early_stop, stopTrain, tensorboard_cb])","c1957e11":"final_model.save('\/kaggle\/working\/BirdNet.h5')","96eb8f2c":"final_model.evaluate(test_generator)","b4e60936":"class_names = train_generator.class_indices\nclass_names","87e85a54":"number_per_species_test = {}\n\nfor idx, test_spec_dir in enumerate(test_species_dir):\n    num_spec = len(os.listdir(test_spec_dir))\n    spec_name = test_lstnames[idx]\n    number_per_species_test[spec_name] = num_spec\n    \nspec_number_df_test = pd.DataFrame(data=[number_per_species_test[i] for i in number_per_species_test.keys()], index=number_per_species_test.keys(), columns=['Quantity'])\n\nnumber_random_species = 5\nnumber_random_per_kind = 3\nimage_size = 4\n\nnext_bird = generate_random_bird(test_lstnames, number_random_species, number_random_per_kind, test_species_dir, spec_number_df_test)\n\nplot_image(number_random_species, number_random_per_kind, image_size, next_bird, class_names = class_names, model  = final_model, get_prediction = True)","2a4baf5f":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = history.epoch\n\nplt.plot(epoch, acc, label = 'Training accuracy', color = 'r')\nplt.plot(epoch, val_acc, label = 'Validation accuracy', color = 'b')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.figure()\n\n\nplt.plot(epoch, loss, label = 'Training loss', color = 'r')\nplt.plot(epoch, val_loss, label = 'Validation loss', color = 'b')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","087deb3e":"number_per_species_test = {}\n\nfor idx, test_spec_dir in enumerate(test_species_dir):\n    num_spec = len(os.listdir(test_spec_dir))\n    spec_name = test_lstnames[idx]\n    number_per_species_test[spec_name] = num_spec","848d5916":"spec_number_df_test = pd.DataFrame(data=[number_per_species_test[i] for i in number_per_species_test.keys()], index=number_per_species_test.keys(), columns=['Quantity'])","1fc06ca5":"number_random_species = 1\nnumber_random_per_kind = 1\n\nnext_bird = generate_random_bird(test_lstnames, number_random_species, number_random_per_kind, test_species_dir, spec_number_df_test)","1cca5e76":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\n\nimg = image.load_img(list(next_bird.values())[0][0], target_size = (224, 224))\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis = 0)\n\nimg_tensor \/= 255.0\n\nlayer_outputs = [layer.output for layer in final_model.layers[: -6]]\nactivation_model = Model(inputs = final_model.input, outputs = layer_outputs)\nactivations = activation_model.predict(img_tensor)\n\nlayer_names = []\nfor layer in final_model.layers[-15: -6]:\n    layer_names.append(layer.name)\n    \nimage_per_row = 16\n\nfor layer_name, layer_activation in zip(layer_names, activations):\n    n_features = layer_activation.shape[-1]\n    \n    size = layer_activation.shape[1]\n    \n    n_cols = n_features \/\/ image_per_row\n    display_grid = np.zeros((size * n_cols, image_per_row *size))\n    \n    for col in range(n_cols):\n        for row in range(image_per_row):\n            channel_image = layer_activation[0, :, :, col*image_per_row + row]\n            channel_image -= channel_image.mean()\n            channel_image \/= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col *size : (col +1)*size, row*size : (row+1)*size] = channel_image\n    scale = 1.\/size\n    plt.figure(figsize = (scale*display_grid.shape[1], scale*display_grid.shape[0]))\n    \n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect = 'auto', cmap = 'viridis')","e9869afd":"!pip install tensorflowjs","a0f62747":"!tensorflowjs_converter --input_format=keras  {'\/kaggle\/working\/BirdNet.h5'} .\/kaggle\/working\/","2ec1032f":"Deep Learning models are often said like a black box that they are difficult to understand what actually being learned during the training process, that is why we call layers between input and output layer are hidden layers. In fact, this is true for certain types of Deep Learning models, but it's definitely not true for ConvNet. \n\n> **The representations learned by convnets are highly amenable to visualization, in large part because they\u2019re representations of visual concepts.**<br>\n> <i>Deep Learning with Python-FRAN\u00c7OIS CHOLLET<\/i>\n","7e43056a":"## Visualizing what is learned by hidden layers "}}