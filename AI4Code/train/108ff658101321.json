{"cell_type":{"ea9963bb":"code","6a98bac3":"code","70691948":"code","9f2f1e5e":"code","4a7b27a6":"code","c9894cbd":"code","617999ea":"code","4617d17b":"code","bc03c6a3":"code","c45698c4":"code","72579bab":"code","6c487383":"code","12a2c9d2":"code","c24d9d4b":"code","711c718d":"code","71c6be95":"code","919c1b3d":"code","ccf951c0":"code","2891bde6":"code","8e03330c":"code","ec47c94a":"code","6a0609fa":"code","374b3346":"code","efbe47c3":"code","d23da54b":"markdown"},"source":{"ea9963bb":"!cp -a ..\/input\/dcgan-for-celebfaces-models-and-checkpoints\/. .\/","6a98bac3":"import os\nimport time\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.train import Checkpoint, CheckpointManager\nfrom tensorflow.data import Dataset\nfrom tensorflow.data.experimental import AUTOTUNE\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import Mean\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import TruncatedNormal, RandomNormal\nfrom tensorflow.keras.layers import Input, Dense, Reshape, BatchNormalization, Conv2D, Conv2DTranspose, \\\n        LeakyReLU, Flatten, SpatialDropout2D, Dropout, MaxPool2D, GlobalAvgPool2D, Concatenate, LayerNormalization\n\nfrom IPython import display\n\nprint(tf.__version__)","70691948":"tf.get_logger().setLevel('ERROR')","9f2f1e5e":"BASE_PATH = r'..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba'\nRANDOM_STATE = 7\nSHUFFLE_BUFFER = 32_000\nIMAGE_SIZE = (192, 160)\nBATCH_SIZE = 64\nGEN_NOISE_SHAPE = (6, 5, 8)\nPREDICT_COUNT = 9","4a7b27a6":"GEN_LR = 4e-6\nGEN_BETA_1 = 0.5\nDISC_LR = 1e-6\nDISC_BETA_1 = 0.9\nGEN_RELU_ALPHA = 0.2\nDISC_RELU_ALPHA = 0.3\nEPOCHS = 50\nDISC_LABEL_SMOOTHING = 0.25\nPLOTS_DPI = 150\nRETRAIN = os.path.isfile('.\/ckpt\/checkpoint')","c9894cbd":"%%time\n\nimage_names = Dataset.list_files(os.path.join(BASE_PATH, '*.jpg'), seed = RANDOM_STATE)\nimage_count = image_names.cardinality().numpy()\nprint(f\"\\nTotal number of image files: {image_count}\\n\")","617999ea":"def load_image_data(filename):\n    img = tf.io.read_file(filename)\n    img = tf.io.decode_jpeg(img, channels = 3)\n    img = tf.image.resize(img, IMAGE_SIZE)\n    return (img - 127.5)\/127.5\n\ntrain_ds = image_names.cache() \\\n        .shuffle(SHUFFLE_BUFFER) \\\n        .map(load_image_data, num_parallel_calls = AUTOTUNE) \\\n        .batch(BATCH_SIZE, drop_remainder = True) \\\n        .prefetch(buffer_size = AUTOTUNE)\n\ntrain_ds","4617d17b":"fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (9, 11))\n\nsample_images = [i for i in train_ds.take(1)][0].numpy()\n\nfor i, ax in enumerate(axes.flatten()):\n    ax.imshow((sample_images[i] * 0.5) + 0.5)\n    ax.axis(False)\n    ax.grid(False)\n\nplt.tight_layout()","bc03c6a3":"tf.random.set_seed(RANDOM_STATE)\nseed_noise = tf.random.normal([PREDICT_COUNT, *GEN_NOISE_SHAPE], seed = RANDOM_STATE)\n\nfig, axes = plt.subplots(nrows = PREDICT_COUNT, ncols = GEN_NOISE_SHAPE[2], figsize = (10, 14))\n\nfor i in range(PREDICT_COUNT):\n    for j in range(GEN_NOISE_SHAPE[2]):\n        axes[i][j].imshow(seed_noise[i, :, :, j], cmap = 'gray')\n        axes[i][j].axis(False)\n        axes[i][j].grid(False)\n        axes[i][j].set_title(f\"Img {i + 1}, Ch {j + 1}\")\n        \nplt.suptitle(f'Input Seed data. Shape: {seed_noise.shape}', fontsize = 20)\nplt.tight_layout()","c45698c4":"def generator_model():\n    weight_init = TruncatedNormal(mean = 0.0, stddev = 0.02)\n\n    input_layer = Input(shape = GEN_NOISE_SHAPE, name = 'Gen_Input')\n    flatten = Flatten(name = 'Gen_Flatten')(input_layer)\n    dense = Dense(6 * 5 * 512, use_bias = False, kernel_initializer = weight_init, \n                activation = LeakyReLU(GEN_RELU_ALPHA), name = 'Gen_Dense')(flatten)\n    reshape = Reshape((6, 5, 512), name = 'Gen_Reshape')(dense)\n    sp_dropout_1 = SpatialDropout2D(0.2, name = 'Gen_SD_1')(reshape)\n\n\n    conv_T_1 = Conv2DTranspose(512, (3, 3), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_1')(sp_dropout_1) \n    conv_T_2 = Conv2DTranspose(256, (3, 3), padding = 'same', strides = (2, 2), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_2')(conv_T_1)\n    bn_1 = BatchNormalization(name = 'Gen_BN_1')(conv_T_2)\n    lr_1 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_1')(bn_1)   \n\n\n    conv_T_3 = Conv2DTranspose(128, (4, 4), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_3')(lr_1) \n    conv_T_4 = Conv2DTranspose(64, (4, 4), padding = 'same', strides = (2, 2), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_4')(conv_T_3)\n    bn_2 = BatchNormalization(name = 'Gen_BN_2')(conv_T_4)\n    lr_2 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_2')(bn_2)\n    sp_dropout_2 = SpatialDropout2D(0.2, name = 'Gen_SD_2')(lr_2)\n\n\n    conv_T_5 = Conv2DTranspose(16, (5, 5), padding = 'same', strides = (2, 2), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_5')(sp_dropout_2)\n    bn_3 = BatchNormalization(name = 'Gen_BN_3')(conv_T_5)\n    lr_3 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_3')(bn_3)   \n    sp_dropout_3 = SpatialDropout2D(0.15, name = 'Gen_SD_3')(lr_3)\n\n\n    conv_T_6 = Conv2DTranspose(8, (6, 6), padding = 'same', strides = (2, 2), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_6')(sp_dropout_3)\n    bn_4 = BatchNormalization(name = 'Gen_BN_4')(conv_T_6)\n    lr_4 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_4')(bn_4)\n    sp_dropout_4 = SpatialDropout2D(0.15, name = 'Gen_SD_4')(lr_4)\n\n\n    conv_T_7 = Conv2DTranspose(8, (7, 7), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False,\n                               kernel_initializer = weight_init, strides = (2, 2), name = 'Gen_Conv_T_7')(sp_dropout_4)\n    conv_T_8 = Conv2DTranspose(3, (5, 5), padding = 'same', kernel_initializer = weight_init, use_bias = False,\n                               activation = 'tanh', name = 'Gen_Conv_T_8')(conv_T_7)\n    \n    return Model(inputs = input_layer, outputs = conv_T_8, name = 'Generator')\n    \ngenerator = generator_model()\ngenerator.summary()","72579bab":"plot_model(generator, to_file = 'Generator.jpg', show_shapes = True, dpi = PLOTS_DPI)","6c487383":"def discriminator_model():\n    input_layer = Input(shape = (*IMAGE_SIZE, 3), name = 'Disc_Input')\n    \n    conv_1 = Conv2D(32, (4, 4), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_1')(input_layer)\n    max_pool_1 = MaxPool2D(2, name = 'Disc_MP_1')(conv_1)\n    conv_2 = Conv2D(64, (4, 4), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_2')(max_pool_1)\n    max_pool_2 = MaxPool2D(2, name = 'Disc_MP_2')(conv_2)\n    global_pool_1 = GlobalAvgPool2D(name = 'Disc_GAP_1')(max_pool_2)\n    \n    sp_dropout_1 = SpatialDropout2D(0.2, name = 'Disc_SD_1')(max_pool_2)\n    conv_3 = Conv2D(128, (3, 3), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_3')(sp_dropout_1)\n    max_pool_3 = MaxPool2D(2, name = 'Disc_MP_3')(conv_3)\n    conv_4 = Conv2D(256, (3, 3), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_4')(max_pool_3)\n    max_pool_4 = MaxPool2D(2, name = 'Disc_MP_4')(conv_4)\n    global_pool_2 = GlobalAvgPool2D(name = 'Disc_GAP_2')(max_pool_4)\n    \n    sp_dropout_2 = SpatialDropout2D(0.2, name = 'Disc_SD_2')(max_pool_4)\n    conv_5 = Conv2D(512, (2, 2), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_5')(sp_dropout_2)\n    max_pool_5 = MaxPool2D(2, name = 'Disc_MP_5')(conv_5)\n    global_pool_3 = GlobalAvgPool2D(name = 'Disc_GAP_3')(max_pool_5)\n    \n    concat = Concatenate(name = 'Disc_Concat')([global_pool_1, global_pool_2, global_pool_3])\n    dropout = Dropout(0.2, name = 'Disc_Dropout')(concat)\n    dense_1 = Dense(32, activation = LeakyReLU(DISC_RELU_ALPHA), name = 'Disc_Dense_1')(dropout)\n    dense_2 = Dense(1, name = 'Disc_Dense_2')(dense_1)\n    \n    return Model(inputs = input_layer, outputs = dense_2, name = 'Discriminator')\n    \ndiscriminator = discriminator_model()\ndiscriminator.summary()","12a2c9d2":"plot_model(discriminator, to_file = 'Discriminator.jpg', show_shapes = True, dpi = PLOTS_DPI)","c24d9d4b":"cross_entropy = BinaryCrossentropy(from_logits = True)\ngen_mean_loss = Mean(name = \"Generator mean loss\")\ndisc_mean_loss = Mean(name = \"Discriminator mean loss\")\ngenerator_optimizer = Adam(GEN_LR, beta_1 = GEN_BETA_1)\ndiscriminator_optimizer = Adam(DISC_LR, beta_1 = DISC_BETA_1)","711c718d":"checkpoint_dir = '.\/ckpt'\n\ncheckpoint = Checkpoint(\n    step = tf.Variable(1),\n    generator_optimizer = generator_optimizer,\n    discriminator_optimizer = discriminator_optimizer,\n    generator = generator,\n    discriminator = discriminator)\n\nckpt_manager = CheckpointManager(checkpoint, checkpoint_dir, max_to_keep = 5)\n\nEPOCH_START = 1\nif RETRAIN:\n    checkpoint.restore(ckpt_manager.latest_checkpoint)\n    EPOCH_START = checkpoint.step.numpy()\n\nprint(f\"Starting training from Epoch {EPOCH_START}\")","71c6be95":"def generate_images(seed, save = False, epoch = None):\n    pred = generator(seed, training = False)\n\n    fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (9, 11))\n\n    for i, ax in enumerate(axes.flatten()):\n        ax.imshow((pred[i] * 0.5) + 0.5)\n        ax.axis(False)\n        ax.grid(False)\n\n    plt.suptitle('Generator Predictions', fontsize = 20)\n    \n    plt.tight_layout()\n\n    if save:\n        plt.savefig(f'Pred_Epoch_{epoch:04d}.png', dpi = PLOTS_DPI, facecolor = 'white', \n                transparent = False, bbox_inches = 'tight')\n        plt.close()\n    \ngenerate_images(seed_noise)","919c1b3d":"discriminator(generator(seed_noise, training = False), training = False).numpy()","ccf951c0":"def discriminator_loss(real_output, fake_output):\n    pos_labels = tf.ones_like(real_output) - (tf.random.uniform(real_output.shape) * DISC_LABEL_SMOOTHING)\n    neg_labels = tf.zeros_like(fake_output) + (tf.random.uniform(fake_output.shape) * DISC_LABEL_SMOOTHING)\n    real_loss = cross_entropy(pos_labels, real_output)\n    fake_loss = cross_entropy(neg_labels, fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","2891bde6":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, *GEN_NOISE_SHAPE])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training = True)\n\n        real_output = discriminator(images, training = True)\n        fake_output = discriminator(generated_images, training = True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gen_mean_loss(gen_loss)\n    disc_mean_loss(disc_loss)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","8e03330c":"gen_losses = []\ndisc_losses = []\n\ndef train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        gen_mean_loss.reset_states()\n        disc_mean_loss.reset_states()\n        \n        print(f\"\\nTraining Epoch {epoch + EPOCH_START}\\n\")\n        \n        for batch_ind, image_batch in enumerate(dataset):\n            train_step(image_batch)\n\n            if (batch_ind + 1) % 10 == 0:\n                print(\". \", end = '')\n            if (batch_ind + 1) % 250 == 0:\n                print(f\"{batch_ind + 1}\")\n        \n        checkpoint.step.assign_add(1)\n\n        display.clear_output(wait = True)\n        \n        generate_images(seed_noise, True, epoch + EPOCH_START)\n\n        if (epoch + EPOCH_START) % 5 == 0:\n            ckpt_manager.save()\n            \n        gen_losses.append(gen_mean_loss.result())\n        disc_losses.append(disc_mean_loss.result())\n\n        print(f\"\\nEpoch: {epoch + EPOCH_START}\\n\")\n        print(f'Generator Loss: {gen_mean_loss.result():.4f}')\n        print(f'Discriminator Loss: {disc_mean_loss.result():.4f}')\n        print (f'Time elapsed: {time.time() - start:.2f} s')\n\n    display.clear_output(wait = True)","ec47c94a":"%%time\n\ntrain(train_ds, EPOCHS)\n\nprint(f'Final Generator Loss: {gen_mean_loss.result()}')\nprint(f'Final Discriminator Loss: {disc_mean_loss.result()}')","6a0609fa":"generate_images(seed_noise)","374b3346":"epoch_range = range(EPOCH_START, EPOCHS + EPOCH_START)\nplt.figure(figsize = (20, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(epoch_range, gen_losses)\nplt.xticks(epoch_range)\nplt.title('Generator loss', fontsize = 18)\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_range, disc_losses)\nplt.xticks(epoch_range)\nplt.title('Discriminator loss', fontsize = 18)\n\nplt.suptitle('Loss per epoch', fontsize = 24)\nplt.show()","efbe47c3":"generator.save(\"generator\")\ndiscriminator.save(\"discriminator\")","d23da54b":"## Deep Convolutional Generative Adversarial Network"}}