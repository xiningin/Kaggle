{"cell_type":{"ba9f42ed":"code","6c4802e9":"code","300a78df":"code","7caf3833":"code","680af0a1":"code","10768db6":"code","157a966b":"code","c188860d":"code","7c81becd":"code","037e7a1c":"code","9e69c13a":"markdown","72f6e0f0":"markdown"},"source":{"ba9f42ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c4802e9":"df = pd.read_csv('..\/input\/arabic-twitter-sentiment-analysis\/Arabic_tweets_positive_20190413.tsv', sep='\\t', error_bad_lines=False)\ndf.head()","300a78df":"df1 = pd.read_csv('..\/input\/arabic-twitter-sentiment-analysis\/Arabic_tweets_negative_20190413.tsv', sep='\\t', error_bad_lines=False)\ndf1.head()","7caf3833":"import tensorflow as tf\nimport sklearn\nfrom tqdm import tqdm","680af0a1":"# Loading the BERT Classifier and Tokenizer along with Input module\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nmodel = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","10768db6":"# changing positive and negative into numeric values\n\ndef cat2num(value):\n    if value=='positive': \n        return 1\n    else: \n        return 0\n    \ndf['pos']  =  df['pos'].apply(cat2num)\ntrain = df[:45000]\ntest = df[45000:]","157a966b":"# But first see BERT tokenizer exmaples and other required stuff!\n\nexample='\ud83c\udf40 \u0648\u0639\u0646 \u0630\u0643\u0631 \u0627\u0644\u0644\u0647 \u0644\u0627 \u062a\u063a\u0641\u0644\u0648\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0644\u0627 \u0625\u0644... Sentiment analysis using BERT with Huggingface'\ntokens=tokenizer.tokenize(example)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\nprint(tokens)\nprint(token_ids)","c188860d":"def convert_data_to_examples(train, test, review, sentiment): \n    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n                                                          text_a = x[\u0639\u0644\u064a\u064a\u0643 \u0627\u0644\u0644\u0647 \u0642\u0641\u0644 \u0645\u064a\u062a\u064a\u0646\u0643 \u2764], \n                                                          label = x[pos]), axis = 1)\n\n    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n                                                          text_a = x[\u0639\u0644\u064a\u064a\u0643 \u0627\u0644\u0644\u0647 \u0642\u0641\u0644 \u0645\u064a\u062a\u064a\u0646\u0643 \u2764], \n                                                          label = x[pos]), axis = 1,)\n  \n    return train_InputExamples, validation_InputExamples\n\ntrain_InputExamples, validation_InputExamples = convert_data_to_examples(train,  test, '\u0639\u0644\u064a\u064a\u0643 \u0627\u0644\u0644\u0647 \u0642\u0641\u0644 \u0645\u064a\u062a\u064a\u0646\u0643 \u2764',  'pos')","7c81becd":"pred_sentences = ['\u0639\u0644\u0645\u0647\u0645 \u062a\u0643\u0641\u0649 \u062d\u0633\u0628\u064a \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647\u0645 \ud83d\ude42', '\u0644\u064a\u0634 \u0639\u0645 \u062a\u0633\u0628\u0646\u0627 \u064a\u0627\u0645\u062e\u0631\u0641 \ud83d\ude21']","037e7a1c":"#tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')   # we are tokenizing before sending into our trained model\n#tf_outputs = model(tf_batch)                                  \n#tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)       # axis=-1, this means that the index that will be returned by argmax will be taken from the *last* axis.\nlabels = ['Positive', 'Negative']\n#label = tf.argmax(tf_predictions, axis=1)\n#label = label.numpy()\n#for i in range(len(pred_sentences)):\n    # print(pred_sentences[i], \": \", labels[label[i]])\nprint(pred_sentences, \": \", labels)","9e69c13a":"#Since I can change the name of the column above I reduced the number of snippets.","72f6e0f0":"#Codes by Satyam Prasad Tiwari https:\/\/www.kaggle.com\/satyampd\/imdb-sentiment-analysis-using-bert-w-huggingface\/notebook"}}