{"cell_type":{"dc396d52":"code","6fb7b78a":"code","afaeee65":"code","80672481":"code","c0a42e3e":"code","f90cf840":"code","6c5859d6":"code","80c4ff71":"code","f60de1f7":"code","21f00907":"code","38c45289":"code","5387b507":"code","7d546272":"code","cf315757":"code","562199a0":"code","f8440495":"code","2c3dcb7d":"code","7bbecd64":"code","578643aa":"code","630a9a4c":"code","42cd4279":"code","621744e1":"code","3e919979":"code","0a0c9347":"code","1396809f":"code","5fadd7f7":"code","1e2234b6":"code","3b3da89b":"code","736809af":"code","5dcd7059":"code","7a9833a9":"markdown","a0ae4edb":"markdown","78316709":"markdown","6d2b723c":"markdown","61b959e0":"markdown","e6ad0420":"markdown","29eb4307":"markdown","7df53b31":"markdown","3cf8b107":"markdown","be36b155":"markdown","18d6aa1d":"markdown","491e0a94":"markdown","580bd802":"markdown","37f3ecd5":"markdown","54da6ae8":"markdown","44319f8c":"markdown","6d1e9620":"markdown","7e7b76b8":"markdown","ffd0b5bb":"markdown","9a7f8e59":"markdown"},"source":{"dc396d52":"!pip install torchsummary -q","6fb7b78a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport time\nimport random # for torch seed\nimport os # for torch seed\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam, AdamW, RMSprop # optmizers\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau # Learning rate schedulers\nfrom torchsummary import summary # model summary\n\nimport albumentations as A\n# from albumentations.pytorch import ToTensorV2","afaeee65":"# Load the data\nINPUT_PATH = '..\/input\/digit-recognizer\/'\nOUTPUT_PATH = '.\/'\n\ntrain = pd.read_csv(INPUT_PATH + \"train.csv\")\ntest = pd.read_csv(INPUT_PATH + \"test.csv\")","80672481":"print(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)\n\nprint(\"\\nTrain dataset:\")\ndisplay(train)\nprint(\"\\nTest dataset:\")\ndisplay(test)","c0a42e3e":"# check missing values\nprint(\"Missing values in train dataset: \", train.isnull().any().sum())\nprint(\"Missing values in test dataset: \", test.isnull().any().sum())","f90cf840":"class CFG:\n  DEBUG = False\n\n  ### input: not configurable\n  IMG_HEIGHT = 28\n  IMG_WIDTH = 28\n  N_CLASS = len(np.unique(train['label']))\n\n  ### split train and validation sets\n  split_fraction = 0.95\n\n  ### training\n  print_freq = 100\n  BATCH_SIZE = 1024\n  N_EPOCHS = 30\n\n  ### set only one to True\n  save_best_loss = False\n  save_best_accuracy = True\n\n  ### optimizer\n  # optimizer = 'adam'\n  # optimizer = 'adamw'\n  optimizer = 'rmsprop'\n  LEARNING_RATE = 1e-3\n  weight_decay = 0.1 # for adamw\n  l2_penalty = 0.01 # for RMSprop\n  rms_momentum = 0 # for RMSprop\n\n  ### learning rate scheduler (LRS)\n  scheduler = 'ReduceLROnPlateau'\n  # scheduler = 'CosineAnnealingLR'\n  plateau_factor = 0.5\n  plateau_patience = 3\n  cosine_T_max = 4\n  cosine_eta_min = 1e-8\n  verbose = True\n\n  ### train and validation DataLoaders\n  shuffle = False\n\n  ### albumentations\n  probability = 0.6\n\n  random_seed = 42","6c5859d6":"if CFG.DEBUG:\n  CFG.N_EPOCHS = 10\n  train = train.sample(frac = 0.5).reset_index(drop=True) # n = 10_000\n  CFG.N_CLASS = len(np.unique(train['label']))","80c4ff71":"print(\"DEBUG?: \", CFG.DEBUG)\nprint(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)\n\nprint(f\"\\nImage shape (H, W): ({CFG.IMG_HEIGHT},{CFG.IMG_WIDTH})\")\nprint(\"Number of classes in train dataset: \", CFG.N_CLASS)","f60de1f7":"# detect and define device \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","21f00907":"# for reproducibility\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed = CFG.random_seed)","38c45289":"# class distribution\ntrain['label'].hist(bins = CFG.N_CLASS);","5387b507":"print('Before split:')\nprint('train shape: ', train.shape)\n\n### simple split\n# split = int(CFG.split_fraction * len(train))\n# valid_df = train[split:].reset_index(drop = True)\n# train_df = train[:split].reset_index(drop = True)\n\n### random split\ntrain_df, valid_df = train_test_split(train, test_size=(1-CFG.split_fraction), random_state=CFG.random_seed)\n\nprint('\\nAfter split:')\nprint('train_df shape: ', train_df.shape)\nprint('valid_df shape: ', valid_df.shape)","7d546272":"### for training and validation\nclass DigitDataset(Dataset):\n    def __init__(self, df, X_col, y_col, augmentations = None):\n        self.features = df[X_col].values\/255 # scale (greyscale) only features. do not scale target\n        self.targets = df[y_col].values.reshape((-1, 1))\n        self.augmentations = augmentations \n\n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((1, 28, 28))\n        label = self.targets[idx]\n\n        if self.augmentations is not None:\n          augmented = self.augmentations(image=image)   \n          return torch.FloatTensor(augmented['image']), torch.FloatTensor(label)\n        else:\n          return torch.FloatTensor(image), torch.FloatTensor(label)\n\n\n### for inference\nclass DigitInferenceDataset(Dataset):\n    def __init__(self, df, augmentations = None): # for inference we only have the features dataframe\n        self.features = df.values\/255 # scale (greyscale) features\n        self.augmentations = augmentations \n\n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((1, 28, 28))\n        return torch.FloatTensor(image)","cf315757":"transform_train = A.Compose([\n                  # A.Resize(CFG.IMG_HEIGHT - 20, CFG.IMG_WIDTH - 20, p=CFG.probability),\n                  # A.HorizontalFlip(p=CFG.probability), # 0.2\n                  # A.VerticalFlip(p=CFG.probability), # 0.5\n                  # A.CenterCrop(23, 23, p=CFG.probability),\n                  # A.RandomCrop(width=23, height=23, p=CFG.probability),                  \n                  # A.MotionBlur(p=CFG.probability), # 0.2\n                  # A.Normalize(p=CFG.probability)                  \n                  # A.Affine(p=CFG.probability),                  \n                  # A.Equalize(p=CFG.probability),                  \n                  # A.CLAHE(p=CFG.probability),                  \n                  # ToTensorV2(),\n\n\n                  A.Rotate(limit=40, p=CFG.probability), \n                  A.ShiftScaleRotate(rotate_limit=40, p=CFG.probability),\n                  # A.IAASharpen(p=CFG.probability),\n                  A.Downscale(scale_min=0.7, scale_max=0.7, p=CFG.probability)\n])\n\n\ntransform_valid = A.Compose([\n                  # A.Resize(CFG.IMG_HEIGHT, CFG.IMG_WIDTH, p=CFG.probability),\n                  # ToTensorV2(),\n\n])","562199a0":"# check if Dataset class is working\n# check some augmentations\ny_col = \"label\"\nX_col = [c for c in train.columns if c != 'label']\n\nfig, ax = plt.subplots(5, 2, figsize = (6, 12))\nfig.suptitle('Checking some augmentations', fontsize = 18)\n\n# instantiate Dataset class\ntd = DigitDataset(train, X_col, y_col, augmentations = None) # no augmentation\ntd_aug = DigitDataset(train, X_col, y_col, augmentations = transform_train) # with data augmentation\n\n# DataLoaders\ntl = DataLoader(td, batch_size = CFG.BATCH_SIZE, shuffle = True) # no augmentation\ntl_aug = DataLoader(td_aug, batch_size = CFG.BATCH_SIZE, shuffle = True) # with data augmentation\n\nprint('Length train_dataset (td): ', len(td))\nprint('Length train_dataloader (tl): ', len(tl))\nprint('Batch size: ', CFG.BATCH_SIZE)\n\n\n# range to visualize augmented images\nbegin = 40\nend = begin + 5\n\nfor i in range(begin, end):\n  for j in range(0,1):\n    # we can access and get data with index by __getitem__(index)\n    img, lab = td.__getitem__(begin + i) # no augmentation\n    img_aug, lab_aug = td_aug.__getitem__(begin + i) # with data augmentation\n\n    # plot original image\n    label = str(lab.item())\n    ax[i - begin, j].set_title(\"Label: \" + label, color=\"red\") # write label in each image title\n    ax[i - begin, j].imshow(np.squeeze(img), cmap='gray') # plot image\n    ax[i - begin, j].axis('off')\n\n    # plot augmented image\n    ax[i - begin, j+1].set_title(\"Aug Label: \" + label, color=\"red\") # write label in each image title\n    ax[i - begin, j+1].imshow(np.squeeze(img_aug), cmap='gray') # plot image\n    ax[i - begin, j+1].axis('off')","f8440495":"class DigitModel(nn.Module):\n    def __init__(self):\n        super(DigitModel, self).__init__()\n        \n        # Convolution to detect features and create feature maps: kernel = feature detector = filter\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5), padding=0) # 128\n        \n        # activation\n        self.actv = nn.LeakyReLU() # ReLU, LeakyReLU, PReLU, ELU, SELU, Tanh\n\n        # Batch normalization 1\n        self.batchnorm1 = nn.BatchNorm2d(32)\n        \n        # Max pool: down sample the detected features in feature maps\n        self.maxpool = nn.MaxPool2d(kernel_size=(2,2)) # 2\n\n        # Dropout\n        self.dropout = nn.Dropout(0.25) \n     \n        # Convolution\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5,5), padding=0) # 64\n\n        # Batch normalization 2\n        self.batchnorm2 = nn.BatchNorm2d(64)        \n\n        # flatten the feature map: reduce dimensionality\n        self.flatten = nn.Flatten()\n\n        # Fully connected\n        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n\n        # Batch normalization 3\n        self.batchnorm3 = nn.BatchNorm1d(256)  # 1 D because it is called after the flatten layer\n\n        # The last fully connected layer must output the number of classes\n        self.classifier = nn.Linear(256, CFG.N_CLASS)\n    \n    def forward(self, x):\n        # conv1 block\n        x = self.conv1(x)\n        x = self.actv(x)\n        x = self.batchnorm1(x)\n        x = self.maxpool(x)\n        # x = self.dropout(x) #  not using dropout because it is causing instability in validation curve \n\n        # conv2 block\n        x = self.conv2(x)\n        x = self.actv(x)\n        x = self.batchnorm2(x)\n        x = self.maxpool(x)\n        # x = self.dropout(x) #  not using dropout because it is causing instability in validation curve \n\n        # flatten\n        x = self.flatten(x)\n\n        # print(x.size())\n        \n        # Linear functions\n        x = self.fc1(x)\n        x = self.batchnorm3(x)\n#         x = self.dropout(x) #  not using dropout because it is causing instability in validation curve \n        out = self.classifier(x)\n        \n        return out ","2c3dcb7d":"def get_optimizer(lr = CFG.LEARNING_RATE):\n\n  if CFG.optimizer == 'adam':\n      optimizer = Adam(model.parameters(), lr=lr, weight_decay = CFG.weight_decay, amsgrad = False)\n\n  elif CFG.optimizer == 'adamw':\n    optimizer = AdamW(model.parameters(), lr = lr, weight_decay = CFG.weight_decay)\n\n  elif CFG.optimizer == 'rmsprop':\n    optimizer = RMSprop(model.parameters(), lr = lr, weight_decay = CFG.l2_penalty, momentum = CFG.rms_momentum)\n\n  else:\n    print('Optimizer is not defined')      \n\n  return optimizer","7bbecd64":"summary(DigitModel().cuda(), input_size=(1, 28, 28), batch_size = CFG.BATCH_SIZE)","578643aa":"def get_scheduler(optimizer):\n\n  if CFG.scheduler=='ReduceLROnPlateau':\n    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor = CFG.plateau_factor, patience = CFG.plateau_patience, verbose = CFG.verbose)\n\n  elif CFG.scheduler=='CosineAnnealingLR':\n    scheduler = CosineAnnealingLR(optimizer, T_max = CFG.cosine_T_max, eta_min = CFG.cosine_eta_min)\n\n  else:\n    print('LR Scheduler is not defined')\n\n  return scheduler ","630a9a4c":"def train_fn(train_loader, model, criterion, optmizer, device):\n\n  size = len(train_loader.dataset)\n  num_batches = len(train_loader)\n\n  loss, correct = 0, 0\n\n  ################################# train #################################\n\n  # switch to train mode\n  model.train()\n\n  for batch, (X, y) in enumerate(train_loader):\n\n    start = time.time()\n\n    device = torch.device(device)\n    X, y = X.to(device), y.to(device)  \n\n    # compute predictions and loss\n    optimizer.zero_grad()\n    pred = model(X)\n    loss = criterion(pred, y.long().squeeze()) \n    current = batch * len(X)\n\n    # Backpropagation: only in train function, not done in validation function\n    loss.backward()\n    optimizer.step()\n\n    # sum correct predictions\n    y_pred, y_true = torch.argmax(pred, axis=1), y.long().squeeze()\n    correct += (y_pred == y_true).type(torch.float).sum().item()\n\n    end = time.time()\n    time_delta = np.round(end - start, 3)\n\n    # log\n    loss, current = np.round(loss.item(), 5), batch * len(X)\n    # if batch % (CFG.print_freq) == 0:\n    #   print(f\"Train Batch: {current:>5d}\/{size:>5d}: loss: {loss:>5f} Elapsed Time: {time_delta} s\")\n  \n  # metrics: calculate accuracy and loss for epoch (all batches)\n  correct \/= size # epoch accuracy\n  loss \/= num_batches # epoch loss\n\n  print(f\"Train: Accuracy: {(100*correct):>0.2f}%, Avg loss: {loss:>5f} \\n\")\n\n  return loss, correct","42cd4279":"def valid_fn(valid_loader, model, criterion, device):\n\n  size = len(valid_loader.dataset)\n  num_batches = len(valid_loader)\n\n  loss, correct = 0, 0\n\n  ################################# validation #################################\n\n  with torch.no_grad(): # disable gradients\n    for batch, (X, y) in enumerate(valid_loader):\n\n      start = time.time()\n\n      device = torch.device(device)\n      X, y = X.to(device), y.to(device)\n\n      # compute predictions and loss\n      pred = model(X)\n      loss = criterion(pred, y.long().squeeze()) \n      current = batch * len(X)\n      \n      # sum correct predictions\n      y_pred, y_true = torch.argmax(pred, axis=1), y.long().squeeze()\n      correct += (y_pred == y_true).type(torch.float).sum().item()\n\n      end = time.time()\n      time_delta = np.round(end - start, 3)\n      \n      # log\n      loss, current = np.round(loss.item(), 5), batch * len(X)\n      # if batch % (CFG.print_freq) == 0:\n      #   print(f\"Valid Batch: {current:>5d}\/{size:>5d}: loss: {loss:>5f} Elapsed Time: {time_delta} s\")\n\n  # metrics: calculate accuracy and loss for epoch (all batches)\n  correct \/= size # epoch accuracy\n  loss \/= num_batches # epoch loss\n\n  print(f\"Valid: Accuracy: {(100*correct):>0.2f}%, Avg loss: {loss:>5f} \\n\")\n\n  return loss, correct #correct","621744e1":"start = time.time()\n\n# define loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# instantiate model and move it to GPU before constructing optimizers for it \nmodel = DigitModel().to(device)\n\n# define optimizer\noptimizer = get_optimizer(lr = CFG.LEARNING_RATE)\n\n# define scheduler\nscheduler = get_scheduler(optimizer)\n\n# prepare dataset\ny_col = \"label\"\nX_col = [c for c in train.columns if c != 'label']\n\ntrain_dataset = DigitDataset(train_df, X_col, y_col, augmentations=transform_train) # data augmentation. set augmentations = None to disable augmentations\nvalid_dataset = DigitDataset(valid_df, X_col, y_col, augmentations=transform_valid) # data augmentation. set augmentations = None to disable augmentations\n\ntrain_dataloader = DataLoader(train_dataset,\n                              batch_size = CFG.BATCH_SIZE,\n                              shuffle = CFG.shuffle)\n\nvalid_dataloader = DataLoader(valid_dataset,\n                              batch_size = CFG.BATCH_SIZE,\n                              shuffle = CFG.shuffle)\n\n\ntrain_loss_history = []\ntrain_acc_history = []\nvalid_loss_history = []\nvalid_acc_history = []\nLR_history = []\n\nbest_loss = np.inf\nbest_epoch_loss = 0\nbest_acc = 0\nbest_epoch_acc = 0\n\nprint('Starting Training...\\n')\n\nstart_train_time = time.time()\n\nfor epoch in range(0, CFG.N_EPOCHS):\n  print(f\"\\n-------------------------------   Epoch {epoch + 1}   -------------------------------\\n\")\n  start_epoch_time = time.time()\n\n  # train\n  train_loss, train_acc = train_fn(train_dataloader, model, loss_fn, optimizer, device)\n  train_loss_history.append(train_loss)\n  train_acc_history.append(train_acc)\n\n  # validation\n  valid_loss, valid_acc = valid_fn(valid_dataloader, model, loss_fn, device)\n  valid_loss_history.append(valid_loss)\n  valid_acc_history.append(valid_acc)\n\n  # apply LR scheduler after each epoch\n  if isinstance(scheduler, ReduceLROnPlateau):\n      scheduler.step(valid_loss)\n\n  elif isinstance(scheduler, CosineAnnealingLR):\n      scheduler.step()\n\n  # save LR value to plot later\n  for param_group in optimizer.param_groups:\n    LR_history.append(param_group['lr'])\n\n  # save validation loss if it was improved (reduced)\n  if valid_loss < best_loss:\n    best_epoch_loss = epoch + 1\n    best_loss = valid_loss\n    if CFG.save_best_loss:\n      # save the model's weights and biases only if CFG.save_best_loss == True\n      torch.save(model.state_dict(), OUTPUT_PATH + f\"DigitModel_ep{best_epoch_loss}.pth\")\n\n  # save validation accuracy if it was improved (increased)\n  if valid_acc > best_acc:\n    best_epoch_acc = epoch + 1\n    best_acc = valid_acc\n    if CFG.save_best_accuracy:\n      # save the model's weights and biases only if CFG.save_best_accuracy == True\n      torch.save(model.state_dict(), OUTPUT_PATH + f\"DigitModel_ep{best_epoch_acc}.pth\")    \n\n  end_epoch_time = time.time()\n  time_delta = np.round(end_epoch_time - start_epoch_time, 3)\n  print(\"\\n\\nEpoch Elapsed Time: {} s\".format(time_delta))\n\nend_train_time = time.time()\nprint(\"\\n\\nTotal Elapsed Time: {} min\".format(np.round((end_train_time - start_train_time)\/60, 3)))\nprint(\"Done!\")  ","3e919979":"print('Best loss: ', best_loss)\nprint('Best epoch (loss criteria): ', best_epoch_loss)\nprint('\\n')\nprint('Best accuracy: ', best_acc)\nprint('Best epoch (accuracy criteria): ', best_epoch_acc)","0a0c9347":"fig = plt.figure(figsize = (18, 8))\nfig.suptitle('Epoch Results', fontsize = 18)\n\nabscissa = np.arange(1, CFG.N_EPOCHS + 1, 1)\n\n# x_ticks according to CFG.N_EPOCHS for better visuailzation\nif CFG.N_EPOCHS <= 20:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, 1)\nelse:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, int(CFG.N_EPOCHS\/20) + 1)\n\n# Loss plot\nax1 = plt.subplot(1, 2, 1)\nax1.plot(abscissa, train_loss_history, label='Training', color = 'black')\nax1.plot(abscissa, valid_loss_history, label='Validation', color = 'red')\nplt.xticks(x_ticks)\nplt.axhline(0, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(\"Loss\")\nax1.legend(frameon=False);\n\n# Accuracy plot\nax2 = plt.subplot(1, 2, 2)\nax2.plot(abscissa, train_acc_history, label='Training', color = 'black')\nax2.plot(abscissa, valid_acc_history, label='Validation', color = 'red')\nplt.xticks(x_ticks)\nplt.axhline(0.99, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(\"Accuracy\")\nax2.legend(frameon=False);","1396809f":"fig = plt.figure(figsize = (14, 8))\n\nabscissa = np.arange(1, CFG.N_EPOCHS + 1, 1)\n\n# x_ticks according to CFG.N_EPOCHS for better visuailzation\nif CFG.N_EPOCHS <= 20:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, 1)\nelse:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, int(CFG.N_EPOCHS\/20) + 1)\n\n# LR plot\nplt.plot(abscissa, LR_history, label='LR', color = 'orange')\nplt.xticks(x_ticks)\nplt.axhline(CFG.LEARNING_RATE, linestyle = 'dashed', color = 'grey')\nplt.axhline(0, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(f\"Learning Rate vs Epochs: {CFG.scheduler}\", fontsize = 16, color = 'orange')\nplt.legend(frameon=False);","5fadd7f7":"def softmax(x):\n    return np.exp(x)\/np.sum(np.exp(x), axis=1)[:, None]\n\ndef inference(test_loader, model):\n\n    predictions = []\n\n    size = len(test_loader.dataset)\n    num_batches = len(test_loader)    \n\n    model = DigitModel().to(device)\n\n    if CFG.save_best_loss: # load model with best validation loss\n      model.load_state_dict(torch.load(OUTPUT_PATH + f\"DigitModel_ep{best_epoch_loss}.pth\"))\n    else: # load model with best validation accuracy\n      model.load_state_dict(torch.load(OUTPUT_PATH + f\"DigitModel_ep{best_epoch_acc}.pth\"))\n\n    # disable gradients for inference\n    with torch.no_grad():\n      for batch, X in enumerate(test_loader):\n        \n        ################################# inference #################################\n        start = time.time()\n        current = batch * len(X)\n\n        X = X.to(device)\n\n        # compute predictions\n        pred = model(X)       \n        # softmax\n        y_pred = softmax(pred.detach().cpu().numpy()) # convert tensor to numpy and apply softmax \n        y_pred = np.argmax(y_pred, axis = 1) # take the indice of the max value (higher probability: predicted class)\n\n        # store results\n        predictions.append(y_pred)\n\n        # log\n        end = time.time()\n        time_delta = np.round(end - start, 5)\n\n        # if batch % (CFG.print_freq) == 0:\n        #   print(f\"Inference Batch: {current:>5d}\/{size:>5d}: Elapsed Time: {time_delta} s\")          \n\n    test_predictions = np.concatenate(predictions, axis = 0) # join sequence of arrays along axis 0\n    return test_predictions","1e2234b6":"# instantiate Inference Dataset class (create inference Dataset)\ninference_dataset = DigitInferenceDataset(test, augmentations=None)\n\n# create Inference DataLoader object from Dataset class object\ninference_dataloader = DataLoader(inference_dataset,\n                                  batch_size = CFG.BATCH_SIZE,\n                                  shuffle = False)","3b3da89b":"# run inference\npredictions = inference(inference_dataloader, model)\npredictions","736809af":"submission = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\nsubmission[\"Label\"] = predictions\n\nsubmission.to_csv(OUTPUT_PATH + 'submission.csv', index = False)\nsubmission.head()","5dcd7059":"# check some predictions\n\nfig = plt.figure(figsize = (12, 12))\nfig.suptitle('Visualizing Predictions', fontsize = 24)\n\n# define a range of predictions to plot\nbegin = 120\nend = begin + 20\n\nfor i in range(begin, end):\n\n  img = np.array(test.iloc[i, :]).reshape(1, 1, 28, 28) # reshape to image dimensions\n  plt.subplot(4, 5, i + 1 - begin) # 4 rows and 5 columns plot \n  label = str(submission.loc[i, 'Label'])\n  plt.title(\"Predicted label: \" + label, color=\"red\") # write label in each image title\n  plt.imshow(np.squeeze(img), cmap='gray') # plot image\n  plt.axis('off')","7a9833a9":"The image below shows the pooling process, used to down sample the created feature maps and summarize the presence of the detected features. It is useful to reduce computation time, but some information is also lost in the process. \n\nThe example below shows a MaxPooling operation, which extracts the max value on the sub-region of the image in which the kernel size (2,2) is at.\n\n<img src=https:\/\/austingwalters.com\/wp-content\/uploads\/2019\/01\/max-pooling.png width=\"480px\">","a0ae4edb":"# Validation function\n\n[torch.no_grad documentation](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.no_grad.html)\n\nUse it when you are sure you will not call Tensor.backward(). It reduces memory and time consumption.","78316709":"# LR Scheduler\n\n[torch LRS documentation](https:\/\/pytorch.org\/docs\/stable\/optim.html#how-to-adjust-learning-rate)\n\nFunction to get the Learning Rate Scheduler to be used (can be tuned in CFG class).\n\ntorch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs. \n\ntorch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic learning rate reducing based on some validation measurements.\n\nLearning rate scheduling should be applied after optimizer\u2019s update.","6d2b723c":"# Model\n\n[torch.nn documentation](https:\/\/pytorch.org\/docs\/stable\/nn.html)","61b959e0":"# Optimizer\n\n[torch optimizer documentation](https:\/\/pytorch.org\/docs\/stable\/optim.html#)\n\nFunction to get the optimizer to be used (can be tuned in CFG class).","e6ad0420":"# Dataset class\n\n[torch Dataset and DataLoader documentation](https:\/\/pytorch.org\/tutorials\/beginner\/basics\/data_tutorial.html#creating-a-custom-dataset-for-your-files)\n\nA custom Dataset class must implement three functions: __init__, __len__, and __getitem__. \n\n- The __init__ function is run once when instantiating the Dataset object. We initialize the variable X_col (features columns), and the variable y_col ('label' column).\n\n- The __len__ function returns the number of samples in our dataset.\n\n- The __getitem__ function returns a sample from the dataset at the given index idx. Based on the index, it retrieves the image\u2019s features and label on the csv file and then converts that to a tensor.\n\nWhen performing inference, we obviously don't have the label values.\n\nThe Dataset class retrieves our dataset\u2019s features and labels one sample at a time. While training a model, we typically want to pass samples in \u201cminibatches\u201d, and DataLoader is an iterable that abstracts this complexity for us in an easy API.","29eb4307":"# Plot Epochs\n\nPlot Train and Validation Loss and Accuracy for each Epoch.","7df53b31":"# Submission","3cf8b107":"# Importing","be36b155":"# Check predictions","18d6aa1d":"![image.png](attachment:6f35c588-8e9b-41a0-a46e-d4db349e64b8.png)","491e0a94":"# Train function","580bd802":"# Inference","37f3ecd5":"# Data Augmentation\n\nSet parameter p (probability of applying the transformation) to 1 to make sure you will visualize the augmentations.\n\n[Albumentations Demo](https:\/\/albumentations-demo.herokuapp.com\/)\n\n[Albumentations docs](https:\/\/albumentations.ai\/docs\/getting_started\/transforms_and_targets\/)\n\n[Albumentations transforms](https:\/\/albumentations.ai\/docs\/getting_started\/transforms_and_targets\/)","54da6ae8":"In the gif below it is shown how a convolution works. \n\nConvolution is the process of adding each element of the image to its local neighbors, weighted by the kernel.\n\nThe kernel (in yellow), also known as filter or detector, is a two-dimensional matrix that slides through the input image performing these calculations on the image's pixel values. This process extracts features and creates feature maps. The resulting matrix has the same dimensions as the kernel.\n\nHere, the kernel navigates through the image by a step of 1. This step is called stride.\n\n<img src=\"https:\/\/glassboxmedicine.files.wordpress.com\/2019\/07\/convgif.gif?w=616\" width=\"700px\">","44319f8c":"Upvote if you found value in this notebook! \ud83d\ude00","6d1e9620":"# About this notebook\n\n- pytorch\n- data augmentation with Albumentations\n- links for documentations\n- convolutions\n- learning curves plots\n- predictions (~99% accuracy)","7e7b76b8":"# Split","ffd0b5bb":"# CFG\n\nThis class enables easy configuration to simulate and understand results.\n\nYou can tweak some parameters and see how they impact on the metrics, plots, and predictions.","9a7f8e59":"# Run training"}}