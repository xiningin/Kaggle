{"cell_type":{"c23ac82f":"code","ba2b248a":"code","af227c84":"code","f806f405":"code","b834bcf7":"code","6a743791":"code","4ca25720":"code","c2c31ab0":"code","eadebd65":"code","1a5caf3d":"code","c7769841":"code","c520748d":"code","c117867c":"code","1c357d87":"code","53f2ca23":"code","25c75cb6":"markdown","8192e022":"markdown","3df4561c":"markdown"},"source":{"c23ac82f":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ba2b248a":"url = \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\"\n# OR you can also download the dataset from same link and upload in data.\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n\ndata = pd.read_csv(url, names=names)\n","af227c84":"data.head()","f806f405":"X = data.iloc[:, :-1].values\ny = data.iloc[:, 4].values","b834bcf7":"plt.plot(X,y)","6a743791":"plt.plot(X)","4ca25720":"plt.plot(y)","c2c31ab0":"# Train-test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","eadebd65":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","1a5caf3d":"#training and predictions\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train, y_train)","c7769841":"y_pred = classifier.predict(X_test)","c520748d":"plt.plot(y_test,y_pred)","c117867c":"# Evaluation\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","1c357d87":"# error\nerror = []\n\n# Calculating error for K values between 1 and 40\nfor i in range(1, 40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error.append(np.mean(pred_i != y_test))","53f2ca23":"plt.figure(figsize=(12, 6))\nplt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n         markerfacecolor='blue', markersize=10)\nplt.title('Error Rate K Value')\nplt.xlabel('K Value')\nplt.ylabel('Mean Error')","25c75cb6":"# K NEAREST NEIGHBOURS","8192e022":"------------------------- D O N E -------------------------------------------","3df4561c":"This is instance based algorithm. It is simple and most used classification algorithm."}}