{"cell_type":{"c66a935f":"code","5e1e7a3e":"code","e745b8e4":"code","b6528a43":"code","280e6fba":"code","b6530826":"code","7ba744bb":"code","676dec11":"code","6503245b":"code","78bb6442":"code","b199b690":"code","f2694ca6":"code","0b8921a8":"code","476d1c2c":"code","8c186640":"code","180376a5":"code","f54208d0":"code","759b6254":"code","41884208":"code","92b8382f":"code","497a5406":"code","2afd534b":"code","629648b6":"code","a6bf0a09":"code","00881fea":"code","117128b9":"code","7736a3d9":"code","b3c86fff":"code","5eaacd1e":"code","f7f72d06":"code","087b7592":"code","0496e184":"code","073ca746":"code","9ddf49c6":"code","4b4bb84b":"code","30f4c6b8":"code","2268643d":"code","bc5b8fcf":"code","bfd55868":"code","00d1a800":"code","b79ea9f2":"code","8bf74f47":"code","98fc57d4":"code","f9934990":"code","da07c259":"code","fc50160e":"code","9c27ef82":"code","0e6b8c62":"code","e69d466d":"code","8b354723":"code","5c9b5d13":"code","a5b9f3c4":"code","a13ed4f7":"code","bb888252":"code","7da6b5ba":"code","948534d8":"code","6bf8acf2":"code","c1c91d72":"code","7015b41b":"code","bae6c1ce":"code","3ac321ef":"code","57324fa4":"code","63184acc":"code","0b46402f":"code","5a5ee569":"code","530ae936":"code","6034bf59":"code","cc192e23":"code","e0a03aac":"code","4f081509":"code","34c27076":"code","97bc52da":"code","9407f10a":"code","cf0296c3":"code","a6a89824":"code","70f8cd8c":"code","c3f6976a":"code","5b86f11a":"code","0c577a7d":"code","ddb864e5":"code","e2ded4a7":"code","2ecba1a5":"code","8f60a4c8":"code","d427126a":"code","2cc002c3":"code","74699e64":"code","fce4b3f9":"code","f3fef7aa":"code","6a75cf49":"code","81891180":"code","0bc7d471":"code","546d9db0":"code","a4427b6f":"code","762f60de":"code","811be54c":"code","22086db0":"code","336eb05a":"code","0fc4e250":"code","39f4229a":"code","dc71435b":"code","d19c2543":"code","b8a38129":"code","590a8bfc":"code","5110f49b":"code","cfe6be11":"code","3ddfe876":"code","85db6dc8":"code","5d4e7baa":"code","b632ecf0":"code","1e828137":"markdown","910eaa44":"markdown","ae37ccd3":"markdown","3bd41050":"markdown","283e89ed":"markdown","bf00cb9c":"markdown","12a23423":"markdown","02b66f7d":"markdown","0a12ad60":"markdown","02bffd8a":"markdown","1f68950e":"markdown","d3088c2c":"markdown","3740d944":"markdown","e4bed94c":"markdown","af71b718":"markdown","7de3523f":"markdown","87ee48d4":"markdown","bd739ee4":"markdown","5e3765e3":"markdown","e41c4283":"markdown","7a2dd351":"markdown","81425586":"markdown","a6d63073":"markdown","557ad1de":"markdown","d25eec21":"markdown","1cf11138":"markdown","ad22f5e6":"markdown","a1701672":"markdown","764aa818":"markdown"},"source":{"c66a935f":"pip install researchpy","5e1e7a3e":"# importing all important libraries \n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n\n# import plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport matplotlib.pyplot as plt\n# import plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n","e745b8e4":"data=pd.read_csv('..\/input\/covid19-rorschach-test-dataset\/rap_dataset.tsv', sep='\\t')\ndata.head()","b6528a43":"data.isnull().sum()","280e6fba":"data.shape","b6530826":"data_prep = data.groupby('Protocol')['R'].count()\npd.DataFrame(data_prep)","7ba744bb":"proc_less_than_7 = data[data['R'] < 7]['Protocol'].unique()\nproc_less_than_7","676dec11":"# drop protocol with less than 7 responses\n\ndata_new = data[~data.Protocol.isin(proc_less_than_7)]\ndata_new","6503245b":"#check\ndata_new[data_new['R'] < 7]","78bb6442":"# Exclude 2019 protocols from Ukraine\ndata_new[['Country', 'TestDate']]\ndata_new[data_new['Country'] == 'Ukraine']","b199b690":"import datetime as dt\ndata_updt_excl = data_new.loc[~(data_new['Country'] == 'Ukraine') & ~(pd.to_datetime(data_new['TestDate']).dt.year == 2019)]","f2694ca6":"data_updt_excl","0b8921a8":"data_updt_excl[pd.to_datetime(data_updt_excl['TestDate']).dt.year == 2019]","476d1c2c":"data_updt_excl[data_updt_excl['Country'] == 'Ukraine']","8c186640":"data_updt_excl","180376a5":"pd.to_datetime(data_new['TestDate'])","f54208d0":"data_new.head()","759b6254":"# Handle missing values and drop values that cannot be scaled\ndata_new.isnull().sum()","41884208":"cat_col = ['PQLevel', 'Gender', 'Country', 'Location', 'DevelopmentalQuality', 'FormQuality','Determinants']","92b8382f":"for i in data_new.select_dtypes(include='object').columns:\n    print(i,len(data_new[i].unique()))","497a5406":"# need to split these values \ndata_new.Contents","2afd534b":"dfcopy = data_new.copy()","629648b6":"# checking shape\ndfcopy.shape","a6bf0a09":"# Now i'm going to split data where coded variables contains more than one code\ndfcopy = dfcopy.drop('Contents', axis=1).join(dfcopy['Contents'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('Contents'))\n","00881fea":"dfcopy.Contents","117128b9":"for i in dfcopy.select_dtypes(include='object').columns:\n    print(i,len(data_new[i].unique()))","7736a3d9":"dfcopy = dfcopy[data_new.columns]\ndfcopy.shape","b3c86fff":"# Now i'm going to split data where coded variables contains more than one code in DevelopmentalQuality\ndfcopy = dfcopy.drop('DevelopmentalQuality', axis=1).join(dfcopy['DevelopmentalQuality'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('DevelopmentalQuality'))\nfor i in dfcopy.select_dtypes(include='object').columns:\n    print(i,len(data_new[i].unique()))\ndfcopy = dfcopy[data_new.columns]\ndfcopy.shape","5eaacd1e":"# Now i'm going to split data where coded variables contains more than one code in Determinants\ndfcopy = dfcopy.drop('FormQuality', axis=1).join(dfcopy['FormQuality'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('FormQuality'))\nfor i in dfcopy.select_dtypes(include='object').columns:\n    print(i,len(data_new[i].unique()))\ndfcopy = dfcopy[data_new.columns]\ndfcopy.shape","f7f72d06":"# Now i'm going to split data where coded variables contains more than one code in Determinants\n#dfcopy = dfcopy.drop('SpecialScores', axis=1).join(dfcopy['SpecialScores'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('SpecialScores'))\n#for i in dfcopy.select_dtypes(include='object').columns:\n  #  print(i,len(data_new[i].unique()))\n#dfcopy = dfcopy[data_new.columns]\n#dfcopy.shape","087b7592":"# Now i'm going to split data where coded variables contains more than one code in Determinants\n#dfcopy = dfcopy.drop('Determinants', axis=1).join(dfcopy['Determinants'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('Determinants'))\n#for i in dfcopy.select_dtypes(include='object').columns:\n    #print(i,len(data_new[i].unique()))\n#dfcopy = dfcopy[data_new.columns]\n#dfcopy.shape","0496e184":"numdf = dfcopy.select_dtypes(include='number')\nnumdf.isnull().sum()","073ca746":"# check shape before processing coded values and after coded values\nprint('shape of data before processing',dfcopy.shape)\nprint('shape of data after processing',data_new.shape)","9ddf49c6":"# Spilt data into pre & post pandemic\n# pre_pandemic = Jan 1, 2017 - Feb 29, 2020\n# post_pandemic = Mar 1, 2020 - Sep 15, 2020\n\nmask = (pd.to_datetime(dfcopy['TestDate']) > '2017-01-01') & (pd.to_datetime(dfcopy['TestDate']) <= '2020-02-29')\n\npre_pandemic = dfcopy.loc[mask]\npre_pandemic","4b4bb84b":"mask2 = (pd.to_datetime(dfcopy['TestDate']) > '2020-03-01') & (pd.to_datetime(dfcopy['TestDate']) <= '2020-09-15')\n\npost_pandemic = dfcopy.loc[mask2]\npost_pandemic","30f4c6b8":"pre_pandemic['LocationNumber'].unique()","2268643d":"pre_pandemic.info()","bc5b8fcf":"# split features into Categorical and Numerical from entire dataset\ncatogrical = [x for x in dfcopy.columns if dfcopy[x].dtype == \"object\"]\nnumeric = [x for x in dfcopy.columns if dfcopy[x].dtype == \"float64\"]","bfd55868":"# let's move into deep dive\ndfcopy[catogrical].describe()","00d1a800":"# split features into Categorical and Numerical from pre_pandemic dataset\npre_catogrical = [x for x in pre_pandemic.columns if pre_pandemic[x].dtype == \"object\"]\npre_numeric = [x for x in pre_pandemic.columns if pre_pandemic[x].dtype == \"float64\"]","b79ea9f2":"pre_pandemic[pre_catogrical].describe()","8bf74f47":"pre_pandemic[pre_numeric].describe()","98fc57d4":"# split features into Categorical and Numerical from post_pandemic dataset\npost_catogrical = [x for x in post_pandemic.columns if post_pandemic[x].dtype == \"object\"]\npost_numeric = [x for x in post_pandemic.columns if post_pandemic[x].dtype == \"float64\"]","f9934990":"post_pandemic[post_catogrical].describe()","da07c259":"post_pandemic[post_numeric].describe()","fc50160e":"print('ZCode in pre_pandemic')\nprint(pre_pandemic['ZCode'].value_counts())","9c27ef82":"print('ZCode in post_pandemic')\nprint(post_pandemic['ZCode'].value_counts())","0e6b8c62":"print('FormQuality in pre_pandemic')\nprint(pre_pandemic['FormQuality'].value_counts())","e69d466d":"print('FormQuality in post_pandemic')\nprint(post_pandemic['FormQuality'].value_counts())","8b354723":"plt.figure(figsize=(8,6))\nsns.countplot(x='FormQuality',hue='Gender',data=post_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by FormQuality in Post_pandemic\")","5c9b5d13":"plt.figure(figsize=(8,6))\nsns.countplot(x='FormQuality',hue='Gender',data=pre_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by FormQuality in pre_pandemic\")","a5b9f3c4":"print('Contents pre_pandemic')\nprint(pre_pandemic['Contents'].value_counts())","a13ed4f7":"print('Contents in post_pandemic')\nprint(post_pandemic['Contents'].value_counts())","bb888252":"print('DevelopmentalQuality in pre_pandemic')\nprint(pre_pandemic['DevelopmentalQuality'].value_counts())","7da6b5ba":"print('DevelopmentalQuality in post_pandemic')\nprint(post_pandemic['DevelopmentalQuality'].value_counts())","948534d8":"plt.figure(figsize=(8,6))\nsns.countplot(x='DevelopmentalQuality',hue='Gender',data=post_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by DevelopmentalQuality\")","6bf8acf2":"plt.figure(figsize=(8,6))\nsns.countplot(x='DevelopmentalQuality',hue='Gender',data=pre_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by DevelopmentalQuality in pre_pandemic\")","c1c91d72":"print('Country in pre_pandemic')\nprint(pre_pandemic['Country'].value_counts())","7015b41b":"print('Country in post_pandemic')\nprint(post_pandemic['Country'].value_counts())","bae6c1ce":"print('Gender in pre_pandemic')\nprint(pre_pandemic['Gender'].value_counts())","3ac321ef":"# let's check Gender pre pandemic and post pandemic\n\nsns.countplot(pre_pandemic['Gender'],palette='viridis')\nplt.title(\"Gender in Pre_pandemic\")\n","57324fa4":"# let's check Gender pre pandemic and post pandemic\n\nsns.countplot(post_pandemic['Gender'],palette='viridis')\nplt.title(\"Gender in Post_pandemic\")\n","63184acc":"print('Gender in post_pandemic')\nprint(post_pandemic['PQLevel'].value_counts())","0b46402f":"# let's check PQlevel pre pandemic and post pandemic\n\nsns.countplot(pre_pandemic['PQLevel'],palette='viridis')\nplt.title(\"PQlevel in Pre_pandemic\")\n","5a5ee569":"print('PQLevel in pre_pandemic')\nprint(pre_pandemic['PQLevel'].value_counts())","530ae936":"plt.figure(figsize=(8,6))\nsns.countplot(x='PQLevel',hue='Gender',data=post_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by PQLevel\")","6034bf59":"plt.figure(figsize=(8,6))\nsns.countplot(x='Contents',hue='Gender',data=post_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by Contents in post_pandemic\")","cc192e23":"print('PQLevel in post_pandemic')\nprint(post_pandemic['PQLevel'].value_counts())","e0a03aac":"\nplt.figure(figsize=(8,6))\nsns.countplot(x='PQLevel',hue='Gender',data=pre_pandemic,palette='viridis')\nplt.title(\"Distribution of Gender  by PQLevel\")","4f081509":"sns.countplot(post_pandemic['PQLevel'],palette='viridis')\nplt.title(\"PQlevel in Post_pandemic\")","34c27076":"# prepare data\npre_Age=pre_pandemic.Age\npost_Age=post_pandemic.Age\n\ntrace1 = go.Histogram(\n    x=pre_Age,\n    opacity=0.75,\n    name = \"Pre_Pandemic Age\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\ntrace2 = go.Histogram(\n    x=post_Age,\n    opacity=0.75,\n    name ='Post_pandemic Age',\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\nlayout = go.Layout(title=' Distribution of Age pre and post pandemic',\n                   xaxis=dict(title='Age'),\n                   yaxis=dict( title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","97bc52da":"\n\n\n# first line plot\n#trace1 = go.Scatter(\n   # x=pre_pandemic.Age,\n    #y=pre_pandemic.ResponseOrder,\n   # name = \"ResponseOrder\",\n    #marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n#)\n\n\n#data = trace1\n#layout = go.Layout(\n    #xaxis2=dict(\n       # domain=[0.6, 0.95]\n                \n   # ),\n    #yaxis2=dict(\n      #  domain=[0.6, 0.95]\n   # ),\n    #title = 'Income and Teaching vs World Rank of Universities'\n\n#)\n\n#fig = go.Figure(data=data, layout=layout)\n#iplot(fig)","9407f10a":"post_pandemic.describe()","cf0296c3":"pre_pandemic.describe()","a6a89824":"ax=sns.kdeplot(post_pandemic[\"R\"],label=\"Post_pandemic R\")\nsns.kdeplot(pre_pandemic[\"R\"],label=\"Pore_pandemic.R\")\nplt.xlabel(\"R\", fontsize=14)\nplt.ylabel('count', fontsize=14)\n\n","70f8cd8c":"ax=sns.kdeplot(post_pandemic[\"Protocol\"],label=\"Post_pandemic Protocol\")\nsns.kdeplot(pre_pandemic[\"Protocol\"],label=\"Pore_pandemic Protocol\")\nplt.xlabel(\"Protocol\", fontsize=14)\nplt.ylabel('count', fontsize=14)","c3f6976a":"ax=sns.kdeplot(post_pandemic[\"ResponseOrder\"],label=\"ResponseOrder\")\nsns.kdeplot(pre_pandemic[\"ResponseOrder\"],label=\"ResponseOrder\")\nplt.xlabel(\"ResponseOrder\", fontsize=14)\nplt.ylabel('count', fontsize=14)","5b86f11a":"ax=sns.kdeplot(post_pandemic[\"LocationNumber\"],label=\"Post_pandemic LocationNumber\")\nsns.kdeplot(pre_pandemic[\"LocationNumber\"],label=\"Pore_pandemic LocationNumber\")\nplt.xlabel(\"LocationNumber\", fontsize=14)\nplt.ylabel('count', fontsize=14)","0c577a7d":"ax=sns.kdeplot(post_pandemic[\"Pair\"],label=\"Pair\")\nsns.kdeplot(pre_pandemic[\"Pair\"],label=\"Pair\")\nplt.xlabel(\"Pair\", fontsize=14)\nplt.ylabel('count', fontsize=14)","ddb864e5":"ax=sns.distplot(post_pandemic[\"ZScore\"],label=\"PopularPopular\")\nsns.distplot(pre_pandemic[\"ZScore\"],label=\"Popular\")\nplt.xlabel(\"ZScore\", fontsize=14)\nplt.ylabel('count', fontsize=14)","e2ded4a7":"#np.cov(X, Y)[0][1]\n# (bias = True - Covariance sample), (None - Covariance population)\npre_pandemic.cov()","2ecba1a5":"post_pandemic.cov()","8f60a4c8":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport researchpy as rp\n","d427126a":"l=post_pandemic[\"Location\"].unique()\nfor i in l:\n    print(f\"for post Location=={i}\\n\",rp.summary_cont(post_pandemic[\"Location\"]==i),f\"\\n for pre Location=={i}\\n\",rp.summary_cont(pre_pandemic[\"Location\"]==i))\n","2cc002c3":"l=post_pandemic[\"DevelopmentalQuality\"].unique()\nfor i in l:\n    print(f\"for post DevelopmentalQuality=={i}\\n\",rp.summary_cont(post_pandemic[\"DevelopmentalQuality\"]==i),f\"\\n for pre DevelopmentalQuality=={i}\\n\",rp.summary_cont(pre_pandemic[\"DevelopmentalQuality\"]==i))","74699e64":"l=post_pandemic[\"Determinants\"].unique()\nfor i in l:\n    print(f\"for postDeterminants=={i}\\n\",rp.summary_cont(post_pandemic[\"Determinants\"]==i),f\"\\n for pre Determinants=={i}\\n\",rp.summary_cont(pre_pandemic[\"Determinants\"]==i))\n","fce4b3f9":"l=post_pandemic[\"FormQuality\"].unique()\nfor i in l:\n    print(f\"for postFormQuality=={i}\\n\",rp.summary_cont(post_pandemic[\"FormQuality\"]==i),f\"\\n for pre FormQuality=={i}\\n\",rp.summary_cont(pre_pandemic[\"FormQuality\"]==i))\n","f3fef7aa":"l=post_pandemic[\"SpecialScores\"].unique()\nfor i in l:\n    print(f\"for postSpecialScores=={i}\\n\",rp.summary_cont(post_pandemic[\"SpecialScores\"]==i),f\"\\n for pre SpecialScores=={i}\\n\",rp.summary_cont(pre_pandemic[\"SpecialScores\"]==i))\n","6a75cf49":"l=post_pandemic[\"ResponseOrder\"].unique()\nfor i in l:\n    print(f\"for post ResponseOrder=={i}\\n\",rp.summary_cont(post_pandemic[\"ResponseOrder\"]==i),f\"\\n for pre ResponseOrder=={i}\\n\",rp.summary_cont(pre_pandemic[\"ResponseOrder\"]==i))\n","81891180":"l=post_pandemic[\"PQLevel\"].unique()\nfor i in l:\n    print(f\"for post PQLevel=={i}\\n\",rp.summary_cont(post_pandemic[\"PQLevel\"]==i),f\"\\n for pre PQLevel=={i}\\n\",rp.summary_cont(pre_pandemic[\"PQLevel\"]==i))\n","0bc7d471":"l=post_pandemic[\"ZScore\"].unique()\nfor i in l:\n    print(f\"for post ZScore=={i}\\n\",rp.summary_cont(post_pandemic[\"ZScore\"]==i),f\"\\n for pre ZScore=={i}\\n\",rp.summary_cont(pre_pandemic[\"ZScore\"]==i))\n","546d9db0":"l=post_pandemic[\"Contents\"].unique()\nfor i in l:\n    print(f\"for post Contents=={i}\\n\",rp.summary_cont(post_pandemic[\"Contents\"]==i),f\"\\n for pre Contents=={i}\\n\",rp.summary_cont(pre_pandemic[\"Contents\"]==i))\n","a4427b6f":"data_copy.info()","762f60de":"data_encoded=dfcopy","811be54c":"## dropp unsignificant features & columns with alot missing data\ndata_encoded=data_encoded.drop([\"User\",\"Client\",\"Protocol\",\"TestDate\",'FQText',\"ZScore\",'ZCode','Contents2','Contents3','Contents4','Contents5','Contents6','Contents7','PQLevel'],axis=1)","22086db0":"data_cat = [x for x in data_encoded if data_encoded[x].dtype == \"object\"]\ndata_cat","336eb05a":"# one hot encoding\nfrom sklearn.preprocessing import OneHotEncoder\n\n# creating instance of one-hot-encoder\ndata_encoded = pd.get_dummies(data_encoded, columns=data_cat)","0fc4e250":"data_encoded","39f4229a":"# Work with Missing Data\n\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='most_frequent')\ndata_encoded = imputer.fit_transform(data_encoded)","dc71435b":"# scalling\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\ndata_encoded= ss.fit_transform(data_encoded)","d19c2543":"from sklearn.cluster import KMeans","b8a38129":"# choose the best number of clusters (K Value) using Elbow Method\nscores = []\nfor i in range(1, 11):\n    model = KMeans(n_clusters=i)\n    model.fit(data_encoded)\n    scores.append(model.inertia_)\nplt.plot(range(1, 11), scores)\nplt.title(\"Elbow Method\")\nplt.xlabel(\"num of clusters\")\nplt.ylabel(\"Score\")","590a8bfc":"model = KMeans(n_clusters=2)\ny_labels = model.fit_predict(data_encoded)\ny_labels","5110f49b":"model.inertia_","cfe6be11":"def data_prep(dataset):\n    dataset.drop([\"User\",\"Client\",\"Protocol\",\"TestDate\",'FQText',\"ZScore\",'ZCode','Contents2','Contents3','Contents4','Contents5','Contents6','Contents7','PQLevel'],axis=1,inplace=True)\n    cat_col = ['Gender','Country','Location','DevelopmentalQuality','FormQuality','Contents','Contents1','SpecialScores','Determinants']\n\n    dataset = pd.get_dummies(dataset, columns=cat_col)\n    \n    imputer = SimpleImputer(strategy='most_frequent')\n    dataset = imputer.fit_transform(dataset)\n    \n    normalize = StandardScaler()\n    dataset_scale = normalize.fit_transform(dataset)\n    return dataset_scale","3ddfe876":"pre_pandemic_c=data_prep(pre_pandemic)","85db6dc8":"post_panademic_c=data_prep(post_pandemic)","5d4e7baa":"pre_pandemic_model=model.fit_predict(pre_pandemic_c)\npost_pandemic_model=model.fit_predict(post_panademic_c)","b632ecf0":"ax=sns.kdeplot(pre_pandemic_model,label=\"pre_pandemic\")\nsns.kdeplot(post_pandemic_model,label=\"post_pandemic\")\nplt.xlabel(\"Pair\", fontsize=14)\nplt.ylabel('count', fontsize=14)\nax.set_xlabel('cluster')\nax.set_title('Proportions per cluster for pre vs post pandemic user');","1e828137":"# <center>COVID-19 Rorschach test dataset<\/center>\n   <center>Responses to the Rorschach test before and after COVID-19 <\/center>\n   \n   ![Rorschach](https:\/\/gitlab.com\/SKJNR\/covid-19-rorschach-test-dataset-analysis\/-\/raw\/master\/awe.png)\n   \n   \n<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Blue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h3>","910eaa44":"### ZCode in Pre_Pandemic vs Post_pandemic","ae37ccd3":"![](https:\/\/gitlab.com\/SKJNR\/covid-19-rorschach-test-dataset-analysis\/-\/raw\/master\/awe34.png)","3bd41050":"### Data Preparation\n* Protocol with less thatn 7 responses should be excluded from the analysis\n* Exclude all 2019 protocol from Ukraine","283e89ed":"## Special Scores","bf00cb9c":"# ANOVA (ANalysis Of VAriance)","12a23423":"From here we can observe that LocationNumber , FQText , Zcode,Zscore,SpecialScores contain more null or missing values .\n\nIt's better to drop those features , so first i am going to analyze data","02b66f7d":"Submission details \nFirst Phase:\n1. Preparing and presenting the split data samples to be used in the analysis.\n2. Perform between-subject statistical analysis (covariance & clustering) of all the sample variables, to detect changes between pre and post pandemic responses to the Rorschach test.\n3. Run cluster analysis on the significantly different variables.\n4. Present an ML initial model for further exploratory analysis of the dataset.","0a12ad60":"## Zscore","02bffd8a":"### Data Description :\n\n1. User                    : User Id number\n2. PQlevel                 : Professional qualifications levels are based on the  \n3. Clinet                  : Client Id number\n4. Age                     : Client age in Years\n5. Gender                  : Client Gender\n6. Country                 : Client Country\n7. Protocol                : Protocol Id Number\n8. Test Date               : The Date the RAP3 protocol was created \n9. R                       : The total number of the responses associated with the protocol \n10. ResponseOrder          : The order of responses in the protocol\n11. CardId                 : Rorschach cardnumber 1 to 10 \n12. Location               : Indicated to which area of the blot the responses referred to \n13. LocationNumber         : The location Normative Number\n14. Developmental Quality  : The quality of processing that has been involved in the formation of the responses\n15. Determinants           : All the visual stimulli in the blot that shaped the reported objects in the response . \n16. Pair                   : Two identical objects are reported , based on the symmetry of the blot\n17. Form Quality           : Indicates how good is the fitness between the area of blot being used and the form requirements of the object specified in the response \n18. FQtext                 : The form quality associated Normative Text \n19. Contents               : Content Coding is consisting of abbrevations for the category to which the responded object Belongs\n20. Popular                : Responses that occur with a high frequency with a normative sample .\n21. ZCode                  : ZCode is coded in responses that involve organizational activity of relationships between distinct blot areas .\n22. ZScore                 : A Numerical value assigned to responses in which such Organizational activity occurs .\n23. Special Scores         : Indicate the presence of special features in the response \n24. Rejection              : The number of card rejections in the Protocol .","1f68950e":"## Contents","d3088c2c":"From above we can see summary for the entire categorical dataset.","3740d944":"## Response Order","e4bed94c":"## Form Quality","af71b718":"## Determinants","7de3523f":"From above we can observe that ZW and ZA was hap","87ee48d4":"* [1. Introduction](#1)\n* [2. Data Reading and Analysis](#2)\n* [3. Data Processing and Cleansing](#3) \n* [4. Model Training](#5) <br>\n\n<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Introduction<\/center><a id=1><\/a><\/h3>\n    \nThe Rorschach inkblot test, a commonly used psychological test, is often utilized to assess personality and emotional functioning. The Rorschach Assistant Program (RAP) is a free online application for the Rorschach testers\u2019 community. The program has been used by professionals all over the world, for coding and analyzing the verbal responses to the ambiguous inkblots.\n    \n  ","bd739ee4":"## PQ Level","5e3765e3":"## looping through diff vars.","e41c4283":"\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Processing and Cleansing<\/center><a id=3><\/a><\/h3>","7a2dd351":"> as we can sea identcal right squeed plot (pre&post) pandemic","81425586":"The \u2018COVID-19 Rorschach test dataset\u2019 is a sample of protocols and responses, from 2017-01-01 to 2020-09-15. It includes some demographics related variables and the codes of the Comprehensive System (Exner, 2001). The dataset contains more than 500,000 coded responses to the test inkblots stimuli.\n\n\n### Objectives\n\n1. Preparing and presenting the split data samples to be used in the analysis.\n2. Perform between-subject statistical analysis (covariance & clustering) of all the sample variables, to detect changes between pre and post pandemic responses to the Rorschach test.\n3. Run cluster analysis on the significantly different variables.\n4. Present an ML initial model for further exploratory analysis of the dataset.","a6d63073":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Reading and Analysis<\/center><a id=2><\/a><\/h3>","557ad1de":"### Observations :\n1. LocationNumber contains many missing or null values , we have to treat them \n2. FQText also contains Missing and Null values \n3. Zcode,Zscore and SpecialScores contains many null or missing values .\n > Overall compare to all other missing features FQtext contains many null or missing values .","d25eec21":"# Clustering","1cf11138":"### DevelopmentalQuality","ad22f5e6":"### Observations :\n* For pre-pandemic, User and protocol had a positive linear relationship but post pandemic, user and protocol had a negative linear relationship\n* Pre-pandemic, User and rejection had a postive linear relationship while post pandemic, they had a negative linear relationship\n* Age and Response show a negative linear relationship pre and post pandemic\n* Protocol and Response showed a postive linear relationship pre-pandemic while a negative linear relationship was noticed post-pandemic\n* Pair and Protocol showed a positive linear relationship pre-pandemic while a negative linear relationship post pandemic\n\nNote: positive linear relationship means an increase in one variable results in an increase in another while negative relationship means an increase in one variable results in a decrease in another","a1701672":"### Location","764aa818":"## Covariance Analysis"}}