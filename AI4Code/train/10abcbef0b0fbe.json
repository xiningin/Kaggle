{"cell_type":{"2c918cf7":"code","56278465":"code","7a0036dd":"code","54723cfe":"code","959d0c84":"code","62d7c1d8":"code","98e14142":"code","b559f4ad":"code","d1a2fa7d":"code","611bb98a":"code","0f355a96":"code","540d8df4":"code","a29bfff9":"code","5d88c40e":"code","5b3895c2":"code","a3484435":"code","f9463561":"code","4472f585":"code","3bfd73b5":"code","192344d7":"code","a5043e73":"code","697160fa":"code","f655791c":"code","d09c6aeb":"code","7f23ea29":"code","bcec230b":"code","a1649f4d":"markdown","2b2dce23":"markdown","e2959e53":"markdown","e8e46339":"markdown","ef0a2b32":"markdown","ecdd873e":"markdown"},"source":{"2c918cf7":"import pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","56278465":"df = pd.read_csv('\/kaggle\/input\/spam-mails-dataset\/spam_ham_dataset.csv')","7a0036dd":"df.head(10)\n","54723cfe":"from nltk.tokenize import RegexpTokenizer","959d0c84":"def clean_str(string, reg = RegexpTokenizer(r'[a-z]+')):\n    string = string.lower()\n    tokens = reg.tokenize(string)\n    return \" \".join(tokens)","62d7c1d8":"print(\"Before Cleaning\")\ndf['text'][0]","98e14142":"df['text'] = df['text'].apply(lambda string: clean_str(string))","b559f4ad":"df.head()","d1a2fa7d":"df['text'][0]","611bb98a":"x = df['text']\ny = df.label_num","0f355a96":"from sklearn.model_selection import train_test_split\n\nx_train, x_test , y_train, y_test = train_test_split(x,y , test_size = 0.3, random_state = 20)\nx_train[0]","540d8df4":"y_train.shape","a29bfff9":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(x_train)","5d88c40e":"word_index = tokenizer.word_index","5b3895c2":"len(word_index)","a3484435":"vocab_size = len(word_index)+1000","f9463561":"vocab_size","4472f585":"x_seq=tokenizer.texts_to_sequences(x_train)","3bfd73b5":"len(x_seq[5])","192344d7":"from keras.preprocessing.sequence import pad_sequences\n\nx_train = pad_sequences(x_seq, maxlen= 50)\nx_test = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen = 50)\n\n","a5043e73":"len(x_test[0])","697160fa":"print(\"Training X Shape:\",x_train.shape)\nprint(\"Testing X Shape:\",x_test.shape)","f655791c":"from keras.models import Sequential\nfrom keras.layers import Dense, Embedding , Bidirectional, LSTM\nfrom keras.layers import Flatten\nembedding_dim_length = 16\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim_length, input_length= 50))\nmodel.add(Bidirectional(LSTM(200, dropout= 0.2, return_sequences=True)))\nmodel.add(Flatten())\n#model.add(Dense(16, activation = 'relu'))\n#model.add(Dense(16, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])\n","d09c6aeb":"history = model.fit(x_train, y_train, validation_data= (x_test, y_test) , epochs = 30, batch_size = 125)","7f23ea29":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nmetrics = pd.DataFrame(history.history)\n# Rename column\nmetrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy',\n                         'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\ndef plot_graphs1(var1, var2, string):\n    metrics[[var1, var2]].plot()\n    plt.title('Training and Validation ' + string)\n    plt.xlabel ('Number of epochs')\n    plt.ylabel(string)\n    plt.legend([var1, var2])\n# Plot\nplot_graphs1('Training_Loss', 'Validation_Loss', 'loss')\nplot_graphs1('Training_Accuracy', 'Validation_Accuracy', 'accuracy')","bcec230b":"scores =model.evaluate(x_test, y_test)\n\nscores\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","a1649f4d":"# Transformation","2b2dce23":"# Cleaning data","e2959e53":"# Splitting Data","e8e46339":"# Prediction","ef0a2b32":"# Model training \n","ecdd873e":"#                                            #Practice Project\n#                                             # Email spam "}}