{"cell_type":{"91dc15ae":"code","0bd2c75b":"code","8c82044e":"code","56599530":"code","a66897b6":"code","1ea06241":"code","514581e8":"code","d8ee11d9":"code","d14f8d0b":"code","b5c4b560":"code","2c8ac224":"code","cbfd5109":"code","b953e452":"code","71ccc664":"code","1755b2bf":"code","0f003b4c":"code","1bbe3ff0":"code","1ba2d2b5":"code","eb9e09ae":"code","6f119b73":"code","69542acc":"code","83128664":"code","e2fc8d4c":"code","10bb8304":"code","ef251f17":"code","aeb489e3":"code","40085cd0":"code","4d66120c":"markdown","4e7279cb":"markdown","66122af9":"markdown","d997d0e3":"markdown","6a4baf6d":"markdown","2c942d0d":"markdown"},"source":{"91dc15ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0bd2c75b":"original_data = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')","8c82044e":"features = ['neighbourhood_group',\n'room_type',\n'latitude',\n'longitude',\n'price',\n'minimum_nights',\n'number_of_reviews',\n'reviews_per_month',\n'calculated_host_listings_count',\n'availability_365']\ndata = original_data[features]\ndata = data.fillna(0)\ndata","56599530":"data.neighbourhood_group.mode()","a66897b6":"from sklearn.model_selection import train_test_split \ndata_full_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\ndata_train, data_val = train_test_split(data_full_train, test_size = 0.25, random_state = 42)","1ea06241":"data_train = data_train.reset_index(drop=True)\ndata_val = data_val.reset_index(drop=True)\ndata_test = data_test.reset_index(drop=True)","514581e8":"y_train = pd.DataFrame(data_train.price, columns = ['price'])\ny_val = pd.DataFrame(data_val.price, columns = ['price'])\ny_test = pd.DataFrame(data_test.price, columns = ['price'])\n\ndel data_train['price']\ndel data_val['price']\ndel data_test['price']","d8ee11d9":"# We'll need this for question 6, therefore I'm doing this first \ny_train_copy = y_train.copy()\ny_val_copy = y_val.copy()\ny_test_copy = y_test.copy()","d14f8d0b":"import seaborn as sns \nsns.heatmap(data_train.corr())","b5c4b560":"y_train['above_average'] = (y_train.price >= 152).astype(int)\ny_val['above_average'] = (y_val.price >= 152).astype(int)\ny_test['above_average'] = (y_test.price >= 152).astype(int)\n\ndel y_train['price']\ndel y_val['price']\ndel y_test['price']","2c8ac224":"from sklearn.metrics import mutual_info_score\ncategorical = ['neighbourhood_group', 'room_type']\nfor column in categorical:\n    print('The MI score for ' + column + ' is: ' + str(round(mutual_info_score(data_train[column], y_train.above_average),2)))","cbfd5109":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction import DictVectorizer\ndv = DictVectorizer(sparse = False)","b953e452":"numerical = ['latitude', 'longitude','minimum_nights', \n 'number_of_reviews', 'reviews_per_month',\n 'calculated_host_listings_count', 'availability_365']","71ccc664":"train_dict = data_train[categorical + numerical].to_dict(orient= 'records')\nX_train = dv.fit_transform(train_dict)\n\nval_dict = data_val[categorical + numerical].to_dict(orient = 'records')\nX_val = dv.fit_transform(val_dict)","1755b2bf":"X_train.shape","0f003b4c":"y_train.shape","1bbe3ff0":"model = LogisticRegression(solver='liblinear', C=1.0, random_state=42)","1ba2d2b5":"model.fit(X_train, y_train)","eb9e09ae":"y_pred = model.predict_proba(X_val)[:, 1]\ny_pred","6f119b73":"above_average_decision = (y_pred >= 0.5)\nabove_average_decision","69542acc":"y_val = np.array(y_val)\noriginal_accuracy = (y_val == above_average_decision).mean()\nrounded_accuracy = round(original_accuracy,2)\nrounded_accuracy","83128664":"# We already trained a model with all features as seen above; no need to train again\n\nfeatures = list(data_train.columns)\n\nfor feature in features:\n    copy = features.copy()\n    copy.remove(feature)\n    \n    train_dict = data_train[copy].to_dict(orient= 'records')\n    X_train = dv.fit_transform(train_dict)\n\n    val_dict = data_val[copy].to_dict(orient = 'records')\n    X_val = dv.fit_transform(val_dict)\n    \n    model = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict_proba(X_val)[:, 1]\n    \n    above_average_decision = (y_pred >= 0.5)\n    \n    y_val = np.array(y_val)\n    accuracy = str(abs((y_val == above_average_decision).mean() - original_accuracy))\n    \n    print('For the model without the feature ' + feature + ': the difference in accuracy  is: ' + accuracy)","e2fc8d4c":"y_train = np.log1p(y_train_copy)","10bb8304":"from sklearn.linear_model import Ridge\nmodel = Ridge()\nmodel.fit(X_train, y_train)","ef251f17":"from sklearn.metrics import mean_squared_error\ndef rmse(y, y_pred):\n    return mean_squared_error(y, y_pred) ** 0.5","aeb489e3":"y_pred = model.predict(X_val)\nrmse(y_val, y_pred)","40085cd0":"values = [0, 0.01, 0.1, 1, 10]\nfor value in values:\n    model = Ridge(alpha = value)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    rmse_value = round(rmse(y_val, y_pred), 3)\n    print('The rmse for the alpha value ' + str(value) + ' is: ' + str(rmse_value))","4d66120c":"Answer for question 6: alpha value of 10, since it gives 4.455 as compared to the other values. ","4e7279cb":"Answer to Question 2: reviews_per_month & number_of_reviews","66122af9":"Qn 4: Closest to 0.58 is 0.60, therefore answer is 0.60.","d997d0e3":"Ans to Qn 1: Manhattan","6a4baf6d":"We have to look at the certain features (neighbourhood_group, room_type, number_of_reviews and reviews_per_month) for the accuracy.\n\nOut of the 4, number_of_reviews has the smallest difference in accuracy with a value of 0.000119\n\nAnswer for question 5: Number of Reviews","2c942d0d":"Question 3: Room Type has a bigger MI score."}}