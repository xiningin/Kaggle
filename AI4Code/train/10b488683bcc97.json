{"cell_type":{"d694fdf1":"code","721d3f1f":"code","65e97515":"code","29e42af7":"code","af0b4235":"code","4a8eabbc":"code","0fadd272":"code","4a9b6fbe":"code","d92eb4ea":"code","36d3cb42":"code","f2b923ac":"code","8b660e62":"code","caafc7d0":"code","86908734":"code","260430d3":"code","cdb6742e":"code","7a5c3d1f":"code","9081207f":"code","a9a12b69":"code","bc40a586":"code","84dd78ef":"code","01582feb":"code","fa58f062":"code","2ea48e80":"code","db4b11fb":"code","8e8a8b02":"code","50cd2c78":"code","1cb7dda1":"code","2c4ebc2c":"code","2b90970d":"code","2d956873":"code","2f021105":"code","4a787ce5":"code","569df75e":"code","de343d0e":"code","0ff22dc4":"code","4686799c":"code","10dd52ff":"markdown"},"source":{"d694fdf1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt # data visualization\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","721d3f1f":"# load training and test data sets into pandas dataframes\n#training = pd.read_csv(\"train.csv\")\n#test = pd.read_csv(\"test.csv\")\ntraining = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","65e97515":"training['train_test'] = 1\ntest['train_test'] = 0\ntest['Survived'] = np.NaN\nall_data = pd.concat([training, test])","29e42af7":"# see columns, counts, data types\ntraining.info()","af0b4235":"# describes numeric columns\ntraining.describe()","4a8eabbc":"# look at numeric and categorical values separately \ntraining_num = training[['Age','SibSp','Parch','Fare']]\ntraining_cat = training[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","0fadd272":"# See histograms for numeric columns\nfor i in training_num.columns:\n    plt.hist(training_num[i])\n    plt.title(i)\n    plt.show()","4a9b6fbe":"print(training_num.corr())\nsns.heatmap(training_num.corr())","d92eb4ea":"# compare survival rate against the numeric columns\npd.pivot_table(training, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","36d3cb42":"# show counts for the categorical columns\nfor i in training_cat.columns:\n    sns.barplot(x=training_cat[i].value_counts().index,y=training_cat[i].value_counts()).set_title(i)\n    plt.show()","f2b923ac":"# Compare survival rate for each of the categorical variables \nprint(pd.pivot_table(training, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(training, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(training, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","8b660e62":"# let's try to fill in some of the missing age values\nprint(training.Age.mean())\n#training['Age'] = training['Age'].fillna(training.Age.mean())","caafc7d0":"# generate new column containing name titles\ntraining['name_title'] = training.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntraining.name_title.value_counts()","86908734":"# shows the titles for people missing Age\ntraining.name_title[pd.isnull(training['Age'])].value_counts()","260430d3":"# People with \"Master\" in the name tend to have much lower age\nprint(training[training['name_title']=='Master'].Age.mean())","cdb6742e":"# Passenger ID 710 is Moubarek, Master. Halim Gonios (\"William George\"), missing Age\nprint(training.Age[training['PassengerId']==710])\nprint(training.Age[training['PassengerId']==48])\ntraining['Age'] = training.apply(lambda x: training[training['name_title']==x['name_title']].Age.mean() if pd.isna(x['Age']) else x['Age'], axis=1)\nprint(training.Age[training['PassengerId']==710])\nprint(training.Age[training['PassengerId']==48])","7a5c3d1f":"# see columns, counts, data types\ntraining.info()","9081207f":"plt.hist(training['Fare'])\nplt.show()","a9a12b69":"# we want to use normalized fare\ntraining['norm_fare'] = np.log(training.Fare+1)\nplt.hist(training['norm_fare'])\nplt.show()","bc40a586":"# we expect the Captain to go down with the ship...\ntraining['free_fare'] = training.Fare.apply(lambda x: 1 if x == 0 else 0)\npd.pivot_table(training,index='Survived',columns='free_fare', values = 'Fare', aggfunc='count')","84dd78ef":"training['surname'] = training.Name.apply(lambda x: x.split(',')[0])","01582feb":"import math\n\n# cascading calulcation of rate of survival of similar groups \n# we start with passengers with the same ticket number, then surname, then title, then gender\ndef get_group_survival_rate(passenger_id, ticket, surname, name_title, sex):\n    group_survival_rate = training[(training['Ticket']==ticket) & (training['PassengerId']!=passenger_id)].Survived.mean()\n    \n    if math.isnan(group_survival_rate):\n        group_survival_rate = training[(training['surname']==surname) & (training['PassengerId']!=passenger_id)].Survived.mean()\n\n    if math.isnan(group_survival_rate):\n        group_survival_rate = training[(training['name_title']==name_title) & (training['PassengerId']!=passenger_id)].Survived.mean()\n    \n    if math.isnan(group_survival_rate):\n        group_survival_rate = training[(training['Sex']==sex) & (training['PassengerId']!=passenger_id)].Survived.mean()\n    \n    return group_survival_rate\n \ntraining['group_survival_rate'] = training.apply(lambda row: get_group_survival_rate(row.PassengerId, row.Ticket, row.surname, row.name_title, row.Sex), axis=1)","fa58f062":"# Cabin prefix\ntraining['cabin_prefix'] = training.Cabin.apply(lambda x: 'U' if pd.isnull(x) else str(x)[0])\npd.pivot_table(training,index='Survived',columns='cabin_prefix', values = 'Name', aggfunc='count')","2ea48e80":"# apply feature engineering discussed above\nall_data['name_title'] = all_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\nall_data['Age'] = all_data.apply(lambda x: training[training['name_title']==x['name_title']].Age.mean() if pd.isna(x['Age']) else x['Age'], axis=1)\n\nall_data['Fare'] = all_data.apply(lambda x: training[training['Pclass']==x['Pclass']].Fare.mean() if pd.isna(x['Fare']) else x['Fare'], axis=1)\nall_data['norm_fare'] = np.log(all_data.Fare+1)\nall_data['free_fare'] = all_data.Fare.apply(lambda x: 1 if x == 0 else 0)\n\n# Pclass is really a category, not a numeric\nall_data.Pclass = all_data.Pclass.astype(str)\n\n# these two passengers embarked at Southampton, per https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html\nall_data.loc[all_data.PassengerId == 62, 'Embarked'] = 'S'\nall_data.loc[all_data.PassengerId == 830, 'Embarked'] = 'S'\n\nall_data['surname'] = all_data.Name.apply(lambda x: x.split(',')[0])\nall_data['group_survival_rate'] = all_data.apply(lambda row: get_group_survival_rate(row.PassengerId, row.Ticket, row.surname, row.name_title, row.Sex), axis=1)\nall_data['cabin_prefix'] = all_data.Cabin.apply(lambda x: 'U' if pd.isnull(x) else str(x)[0])\n\nall_dummies = pd.get_dummies(all_data[['Pclass','Sex','Age','SibSp','Parch','Ticket','norm_fare','free_fare','Cabin','cabin_prefix','Embarked','name_title','group_survival_rate','train_test']])\nx_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis =1)\nx_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis =1)\n\ny_train = all_data[all_data.train_test==1].Survived\ny_train.shape","db4b11fb":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nall_dummies_scaled = all_dummies.copy()\n#all_dummies_scaled[['Age','SibSp','Parch','Fare']]= scale.fit_transform(all_dummies_scaled[['Age','SibSp','Parch','Fare']])\nall_dummies_scaled[['Age','SibSp','Parch','norm_fare','group_survival_rate']]= scale.fit_transform(all_dummies_scaled[['Age','SibSp','Parch','norm_fare','group_survival_rate']])\nall_dummies_scaled\n\nx_train_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 1].drop(['train_test'], axis =1)\nx_test_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 0].drop(['train_test'], axis =1)\n\ny_train = all_data[all_data.train_test==1].Survived","8e8a8b02":"from sklearn.model_selection import cross_val_score\n#from sklearn.naive_bayes import GaussianNB\n#from sklearn.linear_model import LogisticRegression\n#from sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n#from sklearn.svm import SVC\n#from xgboost import XGBClassifier","50cd2c78":"knn = KNeighborsClassifier(5)\ncv = cross_val_score(knn,x_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","1cb7dda1":"knn_scaled = KNeighborsClassifier(5)\ncv = cross_val_score(knn_scaled,x_train_scaled,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","2c4ebc2c":"rf = RandomForestClassifier(random_state = 1)\ncv = cross_val_score(rf,x_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","2b90970d":"rf_scaled = RandomForestClassifier(random_state = 1)\ncv = cross_val_score(rf,x_train_scaled,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","2d956873":"from sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import RandomizedSearchCV \n\ndef clf_performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ' + str(classifier.best_score_))\n    print('Best Parameters: ' + str(classifier.best_params_))","2f021105":"knn = KNeighborsClassifier()\nparam_grid = {'n_neighbors' : [7,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n              'p' : [1,2]}\nclf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_knn = clf_knn.fit(x_train_scaled,y_train)\nclf_performance(best_clf_knn,'KNN')","4a787ce5":"rf = RandomForestClassifier(random_state = 1)\nparam_grid =  {'n_estimators': [100,300,500],\n               'criterion':['gini'],\n               'bootstrap': [True],\n               'max_depth': [None,10],\n               'max_features': ['auto','sqrt', 10],\n               'min_samples_leaf': [1,2,3],\n               'min_samples_split': [2,3]}                                  \nclf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_rf = clf_rf.fit(x_train_scaled,y_train)\nclf_performance(best_clf_rf,'Random Forest')","569df75e":"best_rf = best_clf_rf.best_estimator_.fit(x_train_scaled,y_train)\nfeature_importances = pd.Series(best_rf.feature_importances_, index=x_train_scaled.columns)\nfeature_importances.nlargest(20).plot(kind='barh')","de343d0e":"#predictions = best_clf_knn.best_estimator_.predict(x_test_scaled).astype(int)\npredictions = best_clf_rf.best_estimator_.predict(x_test_scaled).astype(int)","0ff22dc4":"print(predictions)\nprint(sum(predictions))","4686799c":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('submission_rf_v11.csv', index=False)\nprint(\"Your submission was successfully saved!\")","10dd52ff":"I am just experimenting; thanks to Ken Jee for the headstart in this video - (https:\/\/www.youtube.com\/watch?v=I3FBJdiExcg)"}}