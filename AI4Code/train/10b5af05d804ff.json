{"cell_type":{"93d206aa":"code","f934c655":"code","38aebb20":"code","c41a3d4d":"code","01fd36ad":"code","bcba289b":"code","132d0244":"code","fa2ae90c":"code","b2fb4fb1":"code","c6c8439e":"code","09c98a46":"code","5f2f1570":"code","9292f208":"code","3fe1ee17":"code","295d19bd":"code","c9da0953":"code","142092d4":"code","70341e17":"code","299b7bb2":"markdown","c7d16c63":"markdown","73b2816a":"markdown","afcb58f6":"markdown","8123859c":"markdown","893599b6":"markdown","1dd4893a":"markdown","74fa33e1":"markdown","354898a8":"markdown","9e8fbb01":"markdown","d1d45962":"markdown","ed773d54":"markdown","79572163":"markdown","3a2a82c2":"markdown","2c34c655":"markdown","4e31d188":"markdown","93df5055":"markdown","006ef8ed":"markdown"},"source":{"93d206aa":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nimport os","f934c655":"train_data = pd.DataFrame(data=np.array([[100,0,0,200,1],[0,300,400,500,0]]), columns=['f1','f2', 'f3', 'f4', 'target'])\ntrain_data","38aebb20":"test_data = pd.DataFrame(data=np.array([[0,200,100,0,'?'],[400,500,0,300,'?']]), columns=['f1','f2', 'f3', 'f4', 'target'])\ntest_data","c41a3d4d":"train_data_mirror = pd.DataFrame(data=train_data[['f3','f4', 'f1', 'f2', 'target']].values, columns=['f1','f2', 'f3', 'f4', 'target'])\ntrain_data_mirror.target = 1- train_data.target\ntrain_data_double = pd.concat([train_data,train_data_mirror], axis=0, sort=False)\ntrain_data_double","01fd36ad":"PATH_TO_DATA = '..\/input\/mlcourse-dota2-win-prediction\/'\ndf_train= pd.read_csv(PATH_TO_DATA + 'train_features.csv', index_col='match_id_hash')\ndf_train['target']= pd.read_csv(PATH_TO_DATA + 'train_targets.csv', index_col='match_id_hash').radiant_win.astype('int')\ndf_train.head(5)","bcba289b":"d_xy_cols = ['d'+str(i)+'_x' for i in range(1,6)] + ['d'+str(i)+'_y' for i in range(1,6)]\ndf_train[d_xy_cols] = 256 - df_train[d_xy_cols]\n# Now they are equal.","132d0244":"r_pref = ['r'+str(i)+'_' for i in range(1,6)]\nd_pref = ['d'+str(i)+'_' for i in range(1,6)]\nteam_fts = [c[3:] for c in df_train.columns if c[:3]=='r1_']\nfor ft in team_fts:\n    r_fts = [pref + ft for pref in r_pref]\n    d_fts = [pref + ft for pref in d_pref]\n    df_train['r_' + ft+'_mean'] = df_train[r_fts].mean(1)\n    df_train['d_' + ft+'_mean'] = df_train[d_fts].mean(1)\n    df_train.drop(r_fts+d_fts, axis=1, inplace=True)","fa2ae90c":"df_train.columns","b2fb4fb1":"# We have several columns for our magic mirror...\n# Let's mark them.\nr_cols = [c for c in df_train.columns if c[:2]=='r_']\nd_cols = [c for c in df_train.columns if c[:2]=='d_']","c6c8439e":"change_col_dict  = dict(zip(r_cols + d_cols, d_cols+r_cols))","09c98a46":"df_train['is_mirror']=0 \ndf_train_mirror = df_train.copy()\ndf_train_mirror.columns = df_train.columns.map(lambda x: change_col_dict.get(x, x)) # We are changing our columns\ndf_train_mirror['target'] = 1- df_train['target'] # We are flipping our targets\ndf_train_mirror['is_mirror'] = 1 # It could be useful to let our model know, that it is synthetic data\ndf_train_mirror.index = df_train.index.map(lambda x: x+'_wv') # We are making new index for mirror rows","5f2f1570":"df_train_double = pd.concat([df_train, df_train_mirror], axis=0, sort=False)\ndf_train.shape, df_train_double.shape # So we have new train dataset. It has double count of different instances.","9292f208":"df_train.shape","3fe1ee17":"n=len(df_train)*2 \/\/ 3\nX_train, y_train, X_valid, y_valid = df_train.drop('target', axis=1)[:n].values, df_train.target[:n].values, df_train.drop('target', axis=1)[n:].values, df_train.target[n:].values\nmodel = LogisticRegression(solver='lbfgs', random_state=1, max_iter=5000)\nmodel.fit(X_train, y_train)\nscore_train = roc_auc_score( y_valid, model.predict( X_valid))\nprint('Plain dataset score', score_train)","295d19bd":"df_train_double.shape","c9da0953":"X_train, y_train, X_valid, y_valid = pd.concat([df_train.drop('target', axis=1)[:n],df_train_mirror.drop('target', axis=1)[:n]], axis=0, sort=False).values, \\\n                                     pd.concat([df_train.target[:n],df_train_mirror.target[:n]], axis=0, sort=False).values, \\\n                                     pd.concat([df_train.drop('target', axis=1)[n:],df_train_mirror.drop('target', axis=1)[n:]], axis=0, sort=False).values, \\\n                                     pd.concat([df_train.target[n:],df_train_mirror.target[n:]], axis=0, sort=False).values\nmodel = LogisticRegression(solver='lbfgs', random_state=1, max_iter=5000)\nmodel.fit(X_train, y_train)\nscore_train_double = roc_auc_score( y_valid, model.predict( X_valid))\nprint('Double dataset score', score_train_double)","142092d4":"print('Plain dataset score', score_train)\nprint('Double dataset score', score_train_double)\nprint('Growth +{0:10.2f}%%'.format((score_train_double\/score_train-1)*100))","70341e17":"0.86428\/(score_train_double\/score_train)","299b7bb2":"# Get +12 on LB on Dota2 with a magic mirror","c7d16c63":"## So, we have mirror. But where magic is? Let's see a score!","73b2816a":"### Plain dataset","afcb58f6":"**Waw!!!! Our magic mirror can get us +12 improvement on the leaderboard in Dota2!!! It's really magic!!! **","8123859c":"We have 0.48% better result! Is it big improvement? Let's see on leaderbord! The 1st place has 0.86428, minus 0.48%...is...  ","893599b6":"Please predict target for this test data:","1dd4893a":"## An example:","74fa33e1":"But our model does not have this information.\n\nSo, the idea is to make mirror train data for our model. Then our train will be like this:","354898a8":"Do not give thanks ... Although..","9e8fbb01":"You have some data like this:","d1d45962":"**The main idea is that we have not one but two train data sets to fit our models!**","ed773d54":"Now our model can predict our test target easy!","79572163":".. is 0.0.86011... It is the 13d place!","3a2a82c2":"### Double dataset","2c34c655":"Be carefully! We can't mirror x and y features. Because our teams are in different corners. Let's prepare new x and y for d-team.","4e31d188":"Let's make team features\/","93df5055":"Do you know target? Of course you don't! We didn't see combination like these in the train data!\n\nNow. I say that 'f1' and 'f2' are 'gold' and 'xp' of the team0,  'f3' and 'f4' are the same features but for the team1. And target shows that the team0 is winner.\n\nSo! In the first match we see that the team0 with gold=0 and xp=100 win the team1 with gold=200 and xp=0.\n\nBut teams are equal! So it means that any team with 0,100 ussually win any team with 200,0.\n\nObviosly, target of **[0,200 against 100,0]** is 0 (fault), because target of it's mirror in train data **[100,0 against 0,200]** is 1 (win).\n\nAnd now we have very confident answers for test data!","006ef8ed":"## So, let's do it for our base features in Dota"}}