{"cell_type":{"72ea1bc7":"code","f5a96438":"code","0909cc90":"code","cfd4d15c":"code","755c809b":"code","1a54dff1":"code","a4aa3010":"code","0a1f31a3":"code","a3631354":"code","14faeb20":"code","16ab91a4":"code","306a59c8":"code","5054f73c":"markdown","5d8e8cc1":"markdown","fa712f16":"markdown","72c6b5c7":"markdown","0cc50c11":"markdown","a4be75d3":"markdown","1f6e1d8a":"markdown","b3e6bc46":"markdown"},"source":{"72ea1bc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5a96438":"# data import\ntrain = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\nsampleSubmission = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/sampleSubmission.csv')\ntest = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')\n\ntrain.head()","0909cc90":"train.corr()","cfd4d15c":"train.isnull().sum()","755c809b":"# datetime \uceec\ub7fc\uc744 datetime type\uc73c\ub85c \ubcc0\uacbd\ntrain['datetime'] = pd.to_datetime(train['datetime'])\n\n# datetime \uad00\ub828 \uc0c8\ub85c\uc6b4 feature \uc0dd\uc131\ntrain['year'] = train['datetime'].apply(lambda x : x.year)\ntrain['month'] = train['datetime'].apply(lambda x : x.month)\ntrain['day'] = train['datetime'].apply(lambda x : x.day)\ntrain['hour'] = train['datetime'].apply(lambda x : x.hour)\n\n# weather \uc640 season\uc744  one-hot encording\ud654 \nweather=pd.get_dummies(train['weather'],prefix='weather')\ntrain=pd.concat([train,weather],axis=1)\n\nseason = pd.get_dummies(train['season'], prefix='season')\ntrain=pd.concat([train, season], axis=1)\ntrain.head()","1a54dff1":"# test \ub370\uc774\ud130 \uc14b\uc5d0\ub3c4 \ub3d9\uc77c\ud558\uac8c \uc801\uc6a9\ntest['datetime'] = pd.to_datetime(test['datetime'])\ntest['year'] = test['datetime'].apply(lambda x : x.year)\ntest['month'] = test['datetime'].apply(lambda x : x.month)\ntest['day'] = test['datetime'].apply(lambda x : x.day)\ntest['hour'] = test['datetime'].apply(lambda x : x.hour)\n\nweather=pd.get_dummies(test['weather'],prefix='weather')\ntest=pd.concat([test,weather],axis=1)\n\nseason = pd.get_dummies(test['season'], prefix='season')\ntest=pd.concat([test, season], axis=1)\ntest.head()\n","a4aa3010":"train.columns","0a1f31a3":"train_label = train.columns\ndroped_train_label = train_label.drop(['datetime', 'season', 'weather', 'casual', 'registered', 'count'])\nprint(droped_train_label)\n\nX = df[droped_train_label]\ny = df['count']\nprint(X.shape)\nprint(y.shape)\n","a3631354":"from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators= 500, random_state=42)","14faeb20":"\nrf.fit(X, y)","16ab91a4":"# \uc608\uce21\uc744 \ud574\ubd05\uc2dc\ub2e4.\npredictions = rf.predict(test_df[droped_train_label])","306a59c8":"sampleSubmission['count'] = predictions\ndisplay(predictions)\nprint(sampleSubmission)\nsampleSubmission.to_csv('pre0.csv', index=False)","5054f73c":"## \ub370\uc774\ud130 \uc14b \uc900\ube44\n- Train X\uc5d0 \ud544\uc694 \uc5c6\ub294 features\ub97c drop\n- train y\ub294 count\ub9cc \uc0ac\uc6a9\n- \uc5ec\uae30\uc5d0\uc11c\ub294 \ud2b9\ubcc4\ud558\uac8c \ub370\uc774\ud130\ub97c drop \ud558\uc9c0 \uc54a\uc558\uc9c0\ub9cc \uc0c1\uad00\uad00\uacc4\ub098 \uadf8\ub798\ud504\ub97c \uadf8\ub824 \uc774\uc0c1\uce58\ub098 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 feature\ub97c \uc81c\uac70\ud558\uba74 \uc131\ub2a5\uc774 \uc62c\ub77c\uac08 \uac83\uc774\ub77c\uace0 \uc0dd\uac01\ub429\ub2c8\ub2e4.","5d8e8cc1":"## \uc0c1\uad00\uad00\uacc4 \ubd84\uc11d","fa712f16":"## \uacb0\uce21\uce58 \ud655\uc778","72c6b5c7":"## \uacb0\uacfc \uc81c\ucd9c","0cc50c11":"## \ubaa8\ub378 \uc0dd\uc131\n- RandomForestRegressor \ub97c \uc0ac\uc6a9\n- n_estimators: \uc0dd\uc131\ud560 Tree\uc758 \uac1c\uc218\ub97c \ub73b\ud568\n- random_state: \ub3d9\uc77c\ud55c \ubaa8\ub378\uc744 \uc0dd\uc131\ud560 \uc2dc\uc5d0 \uac19\uc740 \uacb0\uacfc\uac12\uc744 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud568","a4be75d3":"\uacb0\uce21\uce58 \uc5c6\uc74c","1f6e1d8a":"# Bike sharing demand \n\uc790\uc804\uac70 \uc218\uc694\ub97c RandomForestRegressor \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\ud574 \ubd05\uc2dc\ub2e4.  \n                                                       _jinjae lee_ \ub9cc\ub4ec\n","b3e6bc46":"## \ub370\uc774\ud130 \ucd94\uac00"}}