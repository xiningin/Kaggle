{"cell_type":{"ac1702d8":"code","bbfa2e9d":"code","064398bd":"code","a0b4caf5":"code","a68d8752":"code","6e9a0536":"code","64789304":"code","a0ef1250":"code","5c99482b":"code","8e541550":"code","9ae8f7b3":"code","9bea0802":"code","ca8b5b26":"code","fdec3335":"code","f47ea188":"code","227ef39f":"code","1c4a9c2e":"code","1bfabbbb":"code","598d42f3":"code","40169dff":"code","e97339b2":"code","627cea46":"code","39892cfa":"code","c4bdcc16":"code","39ab5fc8":"markdown","70e23a71":"markdown","c3044c46":"markdown","ca5a56e8":"markdown","f794b483":"markdown","6e9cf0ef":"markdown","6f0b4830":"markdown","a7aa1c14":"markdown","7ba6d883":"markdown","aff2b60b":"markdown","b5af59df":"markdown","1eade0b4":"markdown","37a61e35":"markdown","c259f38d":"markdown","a78eec83":"markdown","9fdecc6f":"markdown"},"source":{"ac1702d8":"#IMPORT NECESSARY LIBRARIES \nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Dropout, Flatten ,BatchNormalization , MaxPool2D\nfrom keras.layers.convolutional import Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","bbfa2e9d":"train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nmy_submission=pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","064398bd":"train.shape,test.shape,my_submission.shape","a0b4caf5":"train.head()","a68d8752":"test.head()","6e9a0536":"train.isnull().sum()","64789304":"test.isnull().sum()","a0ef1250":"# check out the target variable if the classes are balanced. \ntrain['label'].value_counts()","5c99482b":"sns.set(rc={'figure.figsize':(12,8)})\nsns.countplot(train['label'])","8e541550":"# split data \ndf_train=train.copy()\ny=df_train['label']\nX=df_train.drop(['label'],axis=1)\n# transform data labels to one hotencoder\ny = to_categorical(y,num_classes=10)\nX.shape,y.shape","9ae8f7b3":"# normalizing train data and test data  \nX=X\/255.0\ntest=test\/255.0","9bea0802":"# reshaping our data into 3 dimensions (height = 28px, width = 28px , canal = 1)\nX = np.array(X).reshape(-1,28,28,1)\ntest = np.array(test).reshape(-1,28,28,1)\n#show shapes \nprint(X.shape)\nprint(test.shape )","ca8b5b26":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=4)\nX_train.shape,y_train.shape,X_test.shape,y_test.shape","fdec3335":"fig, axis = plt.subplots(3, 3, figsize=(20, 20))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train[i].reshape(28,28))\n    ax.axis('off')\n    ax.set(title = f\"Real Number is {y_train[i].argmax()}\")","f47ea188":"## Our CNN neural network archiecture is prsented as follows :\n ##1 convlution layer\n ##2 relu layer\n ##3 pooling layer\n ##4 fully connected\n\nmodel = Sequential()\n# First Layer \nmodel.add(Conv2D(filters = 64, kernel_size = (3,3) ,activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 56, kernel_size = (3,3),activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Second Layer \nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),activation ='relu'))\nmodel.add(Conv2D(filters = 48, kernel_size = (3,3),activation ='relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Third Layer \nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.4))\n\n#Output Layer \nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","227ef39f":"model.summary()","1c4a9c2e":"\nhistory = model.fit(X_train,y_train, batch_size=128,\n                              epochs = 5, validation_data = (X_test,y_test),\n                              verbose = 2)","1bfabbbb":"# Plot training loss vs validation loss \nsns.set_style('whitegrid')\nplt.figure()\nfig,(ax1, ax2)=plt.subplots(1,2,figsize=(19,8))\nax1.plot(history.history['loss'])\nax1.plot(history.history['val_loss'])\nax1.legend(['Training','Validation'])\nax1.set_title('Loss')\nax1.set_xlabel('epochs')\n## plot training accuracy vs validation accuracy \nax2.plot(history.history['accuracy'])\nax2.plot(history.history['val_accuracy'])\nax2.legend(['Training','Validation'])\nax2.set_title('Acurracy')\nax2.set_xlabel('epochs')","598d42f3":"## show scores \nscores =model.evaluate(X_test,y_test,verbose=0)\nprint('Loss : {:.3f}'.format(scores[0]))\nprint('Test Accuracy: {:.3f}'.format(scores[1]))","40169dff":"preds=model.predict(X_test)\nX_test_ = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(3, 3, figsize=(20, 20))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test_[i])\n    ax.axis('off')\n    ax.set(title = f\"Real Number : {y_test[i].argmax()}\\n Predicted Number : {preds[i].argmax()}\");","e97339b2":"#now that we evaluated our model accuracy, let's  predict the classes [numbers on the images] for test dataframe \npredictions=model.predict(test)\n#print some predicted classes\npredictions","627cea46":"my_submission.head()","39892cfa":"#get the classes by the argmax function from numpy \nclasses = np.argmax(predictions,axis = 1)\n\n# predicted Values \npredicted_digits = pd.Series(classes)\n# create a submission dataframe \nmy_submission['Label'] = predicted_digits\n# save to a csv file \nmy_submission.to_csv('my_mnist_submission.csv', index=False)\nprint(\" Submission  successfully saved!\")","c4bdcc16":"#save the model for further use. \nmodel.save('mnist_model.h5')","39ab5fc8":"### Normalizing data ","70e23a71":"#### As you can see from the plot above, there is a 100 % match  between real numbers and recognized values with our model. And that's a great result. Al least in this sample. ","c3044c46":"### Splitting data into labels and variables","ca5a56e8":"### Loading the datasets ","f794b483":"### Train Test Split for training data ","6e9cf0ef":"### Training the model for 5 epochs","6f0b4830":"### Submit our Results ","a7aa1c14":"### Plot the accuracy history and loss function","7ba6d883":"### Building our CNN Model","aff2b60b":"### Reshaping data ","b5af59df":"#### As we can see from the plot above, our data is likely balanced. so we can move on t the next step and prepare our data for training ","1eade0b4":"### Make predictions on test data ","37a61e35":"### Comparing our predictions with real test data (y_test) on a plot ","c259f38d":"### Evaluating our Model","a78eec83":"### Imports","9fdecc6f":"### Let's show some images "}}