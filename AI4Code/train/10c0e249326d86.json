{"cell_type":{"2ac228a8":"code","18adfeef":"code","54afca28":"code","28041f3d":"code","fb8127da":"code","00541261":"code","5f117e91":"code","13b110c1":"code","74ffa86d":"code","209f3d51":"code","0bd8d614":"code","a41dae2f":"code","ac75a1c8":"code","2ef0667f":"code","28b5624f":"code","377d79fb":"code","b9604017":"code","c1b0a4d8":"code","7ee9fd19":"code","c0bfdde3":"code","0db9f0ea":"code","3a7ba5fb":"code","714a0eb0":"code","ec4dc421":"markdown","6cec767c":"markdown","489a6926":"markdown","c51695e4":"markdown","5f4649d4":"markdown","ef49f9e6":"markdown","bc1e14b4":"markdown","5ccffcff":"markdown","2aebbfda":"markdown","e3121935":"markdown","7fd37e7c":"markdown","4f083414":"markdown","aa0f0093":"markdown","e067e271":"markdown","e33970e0":"markdown","441ddec2":"markdown","34a4e844":"markdown","fac90fed":"markdown","0ec876c4":"markdown","6081fc18":"markdown"},"source":{"2ac228a8":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\n\nimport torchvision\nimport torchvision.transforms as transforms","18adfeef":"# * We'll use this class to control the things.\nclass InvalidDatasetException(Exception):\n    \n    def __init__(self,len_of_paths,len_of_labels):\n        super().__init__(\n            f\"Number of paths ({len_of_paths}) is not compatible with number of labels ({len_of_labels})\"\n        )","54afca28":"transform = transforms.Compose([transforms.ToTensor()])","28041f3d":"class AnimalDataset(Dataset):\n    \n    def __init__(self,img_paths,img_labels,size_of_images):\n        self.img_paths = img_paths\n        self.img_labels = img_labels\n        self.size_of_images = size_of_images\n        if len(self.img_paths) != len(self.img_labels):\n            raise InvalidDatasetException(self.img_paths,self.img_labels)\n        \n    \n    # We need to override __len__ special method\n    def __len__(self):\n        return len(self.img_paths)\n    \n    # Also we need to override __getitem__ special method\n    # This method should return the image and its label from index given.\n    def __getitem__(self,index):\n        PIL_IMAGE = Image.open(self.img_paths[index]).resize(self.size_of_images)\n        # In pytorch we use torch tensors, ToTensor transform transforms the PIL image \n        # to Torch tensor.\n        TENSOR_IMAGE = transform(PIL_IMAGE)\n        label = self.img_labels[index]\n        \n        return TENSOR_IMAGE,label","fb8127da":"paths = []\nlabels = []\nlabel_map = {0:\"Cat\",\n             1:\"Dog\",\n             2:\"Wild\"\n            }\n\nfor cat_path in glob(\"..\/input\/animal-faces\/afhq\/train\/cat\/*\") + glob(\"..\/input\/animal-faces\/afhq\/val\/cat\/*\"):\n    paths.append(cat_path)\n    labels.append(0)\n    \nfor dog_path in glob(\"..\/input\/animal-faces\/afhq\/train\/dog\/*\") + glob(\"..\/input\/animal-faces\/afhq\/val\/dog\/*\"):\n    paths.append(dog_path)\n    labels.append(1)\n    \nfor wild_path in glob(\"..\/input\/animal-faces\/afhq\/train\/wild\/*\") + glob(\"..\/input\/animal-faces\/afhq\/val\/wild\/*\"):\n    paths.append(wild_path)\n    labels.append(2)\n    \nprint(len(paths))\nprint(len(labels))","00541261":"dataset = AnimalDataset(paths,labels,(250,250))","5f117e91":"from sklearn.model_selection import train_test_split\n\n# dataset_indices = [0,1,2,3,..len(dataset)-1]\ndataset_indices = list(range(0,len(dataset)))\n\ntrain_indices,test_indices = train_test_split(dataset_indices,test_size=0.2,random_state=42)\nprint(\"Number of train samples: \",len(train_indices))\nprint(\"Number of test samples: \",len(test_indices))","13b110c1":"train_sampler = SubsetRandomSampler(train_indices)\ntest_sampler = SubsetRandomSampler(test_indices)","74ffa86d":"BATCH_SIZE = 128\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n                                                sampler=test_sampler)","209f3d51":"dataset[1][0].shape","0bd8d614":"images,labels = next(iter(train_loader))\ntype(labels)","a41dae2f":"images,labels = iter(train_loader).next()\n\nfig, axis = plt.subplots(3, 5, figsize=(15, 10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        npimg = images[i].numpy()\n        npimg = np.transpose(npimg, (1, 2, 0))\n        label = label_map[int(labels[i])]\n        ax.imshow(npimg)\n        ax.set(title = f\"{label}\")\n        ","ac75a1c8":"class CNN(nn.Module):\n    \n    def __init__(self):\n        super(CNN,self).__init__()\n        # First we'll define our layers\n        self.conv1 = nn.Conv2d(3,32,kernel_size=3,stride=2,padding=1)\n        self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1)\n        self.batchnorm1 = nn.BatchNorm2d(64)\n        \n        self.conv3 = nn.Conv2d(64,128,kernel_size=3,stride=2,padding=1)\n        self.batchnorm2 = nn.BatchNorm2d(128)\n        \n        self.conv4 = nn.Conv2d(128,256,kernel_size=3,stride=2,padding=1)\n        self.batchnorm3 = nn.BatchNorm2d(256)\n        \n        self.maxpool = nn.MaxPool2d(2,2)\n        \n        self.fc1 = nn.Linear(256 * 2 * 2,512)\n        self.fc2 = nn.Linear(512,3)\n        \n    \n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.batchnorm1(x)\n        x = self.maxpool(x)\n        x = F.relu(self.conv3(x))\n        x = self.batchnorm2(x)\n        x = self.maxpool(x)\n        x = F.relu(self.conv4(x))\n        x = self.batchnorm3(x)\n        x = self.maxpool(x)\n        x = x.view(-1, 256 * 2 * 2)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = F.log_softmax(x,dim=1)\n        return x\n        \n        ","2ef0667f":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","28b5624f":"device","377d79fb":"model = CNN().to(device)","b9604017":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(),lr=1e-4)","c1b0a4d8":"EPOCH_NUMBER = 5\nTRAIN_LOSS = []\nTRAIN_ACCURACY = []\n\nfor epoch in range(1,EPOCH_NUMBER+1):\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    for data_,target_ in train_loader:\n        # We have to one hot encode our labels.\n        target_ =target_.to(device)\n        data_ = data_.to(device)\n        \n        # Cleaning the cached gradients if there are\n        optimizer.zero_grad()\n        \n        # Getting train decisions and computing loss.\n        outputs = model(data_)\n        loss = criterion(outputs,target_)\n        \n        # Backpropagation and optimizing.\n        loss.backward()\n        optimizer.step()\n        \n        # Computing statistics.\n        epoch_loss = epoch_loss + loss.item()\n        _,pred = torch.max(outputs,dim=1)\n        correct = correct + torch.sum(pred == target_).item()\n        total += target_.size(0)\n    \n    # Appending stats to the lists.\n    TRAIN_LOSS.append(epoch_loss)\n    TRAIN_ACCURACY.append(100 * correct \/ total)\n    print(f\"Epoch {epoch}: Accuracy: {100 * correct\/total}, Loss: {epoch_loss}\")\n        ","7ee9fd19":"plt.subplots(figsize=(6,4))\nplt.plot(range(EPOCH_NUMBER),TRAIN_LOSS,color=\"blue\",label=\"Loss\")\nplt.legend()\nplt.show()\n\nplt.subplots(figsize=(6,4))\nplt.plot(range(EPOCH_NUMBER),TRAIN_ACCURACY,color=\"green\",label=\"Accuracy\")\nplt.legend()\nplt.show()","c0bfdde3":"total_val_loss = 0.0\ntotal_true = 0\ntotal = len(test_sampler)\n\n# When we're not working with gradients and backpropagation\n# we use torch.no_grad() utility.\nwith torch.no_grad():\n    model.eval()\n    for data_,target_ in validation_loader:\n        data_ = data_.to(device)\n        target_ = target_.to(device)\n        \n        outputs = model(data_)\n        loss = criterion(outputs,target_).item()\n        _,preds = torch.max(outputs,dim=1)\n        total_val_loss += loss\n        true = torch.sum(preds == target_).item()\n        total_true += true\n\nvalidation_accuracy = round(100 * total_true \/ total,2)\nprint(f\"Validation accuracy: {validation_accuracy}%\")\nprint(f\"Validation loss: {round(total_val_loss,2)}%\")","0db9f0ea":"for param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())","3a7ba5fb":"torch.save(model.state_dict(),\"model.pt\")\n","714a0eb0":"loaded_model = CNN()\nloaded_model.load_state_dict(torch.load(\"model.pt\"))\n","ec4dc421":"* And as you guess, we can just save and load this state dict.","6cec767c":"* Now we can create our model object. \n* But before we need to create our GPU variable, we'll send our model to the gpu that way.","489a6926":"* And now all we need to do is giving these indices lists to our samplers.","c51695e4":"# Preparing Dataset\nPytorch offers advanced tools for reading,batching and preparing image data and today we'll use those tools.\n\nIn general, preparing data in pytorch have 3 steps.\n\n**1. Preparing Dataset Class**\n\n**2. Preparing Sampler**\n\n**3. Preparing Data Loader**\n\n\n### 1. Preparing Dataset Class\nFirst, we'll create a dataset class by inheriting our class Pytorch's abstract Dataset class. There are some special functions we must override. We'll see them in the code.","5f4649d4":"# Conclusion\nThanks for your attention. If you have a question, plase share it with me. It's a pleasure for me to help you. Have a good day!","ef49f9e6":"# Neural Network Modeling\nOur dataset is ready, now we can build our deep convolutional neural network. In Pytorch, when we build a model, we create a class inherited Pytorch's nn.Module abstract class.\n\nThen we need to write forward function which includes forward propagation.","bc1e14b4":"* If we want briefly explain what does this class do, it reads the image and convert it to a Torch tensor. Then it returns the image and the label of the image.","5ccffcff":"# Final Test\nAnd now we'll test our model using our test loader.","2aebbfda":"# Introduction\nHey people, welcome to this kernel. In this kernel I'm gonna show you how to build a convolutional neural network using Pytorch.\n\nI used to work with Tensorflow, but recently I decided to change my main deep learning library as Pytorch. I've researched both Tensorflow and Pytorch (really) detailed and Pytorch seems better for me.\n\nSo let's start! ","e3121935":"**We've trained our model, and now we can take a look at the stats and after that we can evaluate our model by using test set.**","7fd37e7c":"# Training Model\nOur model and dataset are ready, now we can train our model.","4f083414":"Also as you know, in deep learning we use an optimization algorithm to apply gradients and a loss function to compute gradients. In this kernel we're going to use cross entropy loss and RMSProp optimizer.","aa0f0093":"# How to Save A Pytorch Model\nWe trained our model and we might want to use it in our real life. And in order to use it regularly we need to save it.\n\nThere are lots of way to save a model in Pytorch but today we'll use the best way: saving state dict.\n\n\nState dictionary is a python dictionary which includes layer names as keys and layer weights as items. If we take a look at the state dict we can fully understand it.","e067e271":"* And in order to load model we need to create a new object from the class and load the state dict.","e33970e0":"* And boom, our model is ready to use!","441ddec2":"* Let's create our object. ","34a4e844":"* Everything is ready about data. Let's move on to the neural network modeling.\n\n\nBut before, let's take a look at our images.","fac90fed":"### 2. Preparing Sampler Objects","0ec876c4":"### 3. Preparing Data Loader Objects\nEverything is ready to combine. We have a dataset we can read images and labels. We have samplers which will help us to randomly choose samples. And now we need a data loader which will create batches using the dataset and samplers.","6081fc18":"* We've completed the hardest part of preparing data. Now we'll create our sampler object.\n* Basically sampler shows how we'll choose the data.\n* We'll create two random samplers: Train Random Sampler and Test Random Sampler.\n* These random samplers will randomly choose indices from the list given. You'll definitely understand when you see. Let's code it."}}