{"cell_type":{"15f3fe7d":"code","f7c6f8bc":"code","d451e8de":"code","c6b6afb1":"code","425037fd":"code","c09b22f3":"code","454139c0":"code","fcf8aa3f":"code","e604a433":"code","b0346157":"code","75639fd3":"code","437a1b35":"code","89b2cc12":"code","c7c5d7ad":"code","866629de":"code","5a8ddec7":"code","e7800eb9":"code","3dcdb855":"code","2b4b9a31":"code","304def00":"code","370cb9d0":"code","379e1a59":"code","6b09a21b":"code","0a2c5e26":"code","1d53c8ee":"code","c73e482e":"code","6b4b36e4":"markdown","dbe5a326":"markdown","422e6ae9":"markdown","c93e7952":"markdown","f557d100":"markdown","5cc47e01":"markdown","88c70f9c":"markdown","df311dcb":"markdown","0ec9223c":"markdown","e45aef26":"markdown","e0a10ccf":"markdown","01566786":"markdown","789a5bfc":"markdown","c4356a33":"markdown","b062db85":"markdown","938f210c":"markdown","9449c629":"markdown","c26f16bd":"markdown","0fb3bef5":"markdown","dad69c83":"markdown","1c9cadd4":"markdown","06a3c2ad":"markdown","25f6c412":"markdown","d806dd2a":"markdown"},"source":{"15f3fe7d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_curve,auc,classification_report\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout  \nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom random import shuffle\nfrom tqdm import tqdm  \nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport random\nimport os\nprint(os.listdir(\"..\/input\"))\n","f7c6f8bc":"# setting path of directory\nPARA_DIR = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/\"\nNORM_DIR =  \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/\"\n\n# storing all the files from directories PARA_DIR and NORM_DIR to Pimages and Nimages for accessing images directly\nPimages = os.listdir(PARA_DIR)\nNimages = os.listdir(NORM_DIR)","d451e8de":"sample_parasite = random.sample(Pimages,6)\nf,ax = plt.subplots(2,3,figsize=(15,9))\n\nfor i in range(0,6):\n    im = cv2.imread('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/'+sample_parasite[i])\n    ax[i\/\/3,i%3].imshow(im)\n    ax[i\/\/3,i%3].axis('off')\nf.suptitle('Parasite infected blood sample images',fontsize=20)\nplt.show()","c6b6afb1":"sample_normal = random.sample(Nimages,6)\nf,ax = plt.subplots(2,3,figsize=(15,9))\n\nfor i in range(0,6):\n    im = cv2.imread('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/'+sample_normal[i])\n    ax[i\/\/3,i%3].imshow(im)\n    ax[i\/\/3,i%3].axis('off')\nf.suptitle('Normal Blood Sample Images (Un-infected)', fontsize=20)\nplt.show()","425037fd":"data=[]\nlabels=[]\nParasitized=os.listdir(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/\")\nfor a in Parasitized:\n    try:\n        image=cv2.imread(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/\"+a)\n        image_from_array = Image.fromarray(image, 'RGB')\n        size_image = image_from_array.resize((50, 50))\n        data.append(np.array(size_image))\n        labels.append(0)\n    except AttributeError:\n        print(\"\")\n\nUninfected=os.listdir(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/\")\nfor b in Uninfected:\n    try:\n        image=cv2.imread(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/\"+b)\n        image_from_array = Image.fromarray(image, 'RGB')\n        size_image = image_from_array.resize((50, 50))\n        data.append(np.array(size_image))\n        labels.append(1)\n    except AttributeError:\n        print(\"\")","c09b22f3":"# segregating data and labels\nCells=np.array(data)\nlabels=np.array(labels)\n\nnp.save(\"Cells\",Cells)\nnp.save(\"labels\",labels)","454139c0":"# loading data of cell images and labels of images\nCells=np.load(\"Cells.npy\")\nlabels=np.load(\"labels.npy\")","fcf8aa3f":"s=np.arange(Cells.shape[0])\nnp.random.shuffle(s)\nCells=Cells[s]\nlabels=labels[s]\n\nnum_classes=len(np.unique(labels))\nlen_data=len(Cells)","e604a433":"# splitting cells images into 90:10 ratio i.e., 90% for training and 10% for testing purpose\n(x_train,x_test)=Cells[(int)(0.1*len_data):],Cells[:(int)(0.1*len_data)]\n\n(y_train,y_test)=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]","b0346157":"x_train = x_train.astype('float32')\/255 # As we are working on image data we are normalizing data by divinding 255.\nx_test = x_test.astype('float32')\/255\ntrain_len=len(x_train)\ntest_len=len(x_test)","75639fd3":"#Doing One hot encoding as classifier has multiple classes\ny_train=keras.utils.to_categorical(y_train,num_classes)\ny_test=keras.utils.to_categorical(y_test,num_classes)","437a1b35":"# Set random seed\nnp.random.seed(0)\n\n#creating sequential model\nmodel=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \nmodel.summary()","89b2cc12":"# compile the model with loss as categorical_crossentropy and using adam optimizer you can test result by trying RMSProp as well as Momentum\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","c7c5d7ad":"callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n             ModelCheckpoint('.mdl_wts.hdf5', monitor='val_loss', save_best_only=True)]","866629de":"#Fit the model with min batch size as 32 can tune batch size to some factor of 2^power ] \nh=model.fit(x_train,y_train,batch_size=32,callbacks=callbacks, validation_data=(x_test,y_test),epochs=20,verbose=1)","5a8ddec7":"# saving the weight of model\nfrom numpy import loadtxt\nfrom keras.models import load_model\nmodel = load_model('.mdl_wts.hdf5')\n\n#checking the score of the model\nscore=model.evaluate(x_test,y_test)\nprint(score)","e7800eb9":"# checking the accuracy of thr \naccuracy = model.evaluate(x_test, y_test, verbose=1)\nprint('\\n', 'Test_Accuracy:-', accuracy[1])","3dcdb855":"from sklearn.metrics import confusion_matrix\npred = model.predict(x_test)\npred = np.argmax(pred,axis = 1) \ny_true = np.argmax(y_test,axis = 1)\n\n#creating confusion matrix\nCM = confusion_matrix(y_true, pred)\nfrom mlxtend.plotting import plot_confusion_matrix\n# plotting confusion matrix\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\nplt.show()","2b4b9a31":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()","304def00":"plot_model_history(h)","370cb9d0":"print('{}'.format( \n                           classification_report(y_true , pred)))","379e1a59":"fpr_keras, tpr_keras, thresholds = roc_curve(y_true.ravel(), pred.ravel())\nauc_keras = auc(fpr_keras, tpr_keras)\nauc_keras","6b09a21b":"def plot_roc_curve(fpr, tpr):\n    plt.figure(figsize=(10,6))\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","0a2c5e26":"plot_roc_curve(fpr_keras, tpr_keras)","1d53c8ee":"y_hat = model.predict(x_test)\n\n# define text labels \nmalaria_labels = ['Parasitized','Uninfected']","c73e482e":"# plot a random sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=12, replace=False)):\n    ax = fig.add_subplot(4,4, i+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_hat[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(malaria_labels[pred_idx], malaria_labels[true_idx]),\n                 color=(\"blue\" if pred_idx == true_idx else \"orange\"))","6b4b36e4":"## Step 4: Data Preprocessing (Labeling & Resizing of images)<a id='step-4'><\/a>","dbe5a326":"### Printing Classification report","422e6ae9":"### Computing Area Under Curve (AUC)","c93e7952":"## Step 12: Model Evaluation<a id='step-12'><\/a>","f557d100":"## Conclusion & Future Improvements <a id='conc-fut'><\/a>","5cc47e01":"## Step 13: Plotting ROC AUC Curve<a id='step-13'><\/a>\nIn this step we will first compute Are Under Curve (AUC) based on which we plot ROC curve","88c70f9c":"**Observation:**\n- As we can see normal images are clear with no mark to show.","df311dcb":"## Step 5: Train- Test Split<a id='step-5'><\/a>","0ec9223c":"## Step 1: Importing Essential Libraries<a id='step-1'><\/a>","e45aef26":"## Key Facts of Malaria\n- Malaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes. It is preventable and curable.\n- In 2017, there were an estimated **219 million** cases of malaria in **87 countries**.\n- The estimated number of malaria deaths stood at **435 000** in 2017.\n- The WHO African Region carries a disproportionately high share of the global malaria burden. In 2017, the region was home to **92%** of malaria cases and **93%** of malaria deaths.\n- Total funding for malaria control and elimination reached an estimated **US dollar 3.1billion** \n\nMalaria is caused by **Plasmodium parasites.** The parasites are spread to people through the bites of infected female Anopheles mosquitoes, called **\"malaria vectors.**\" There are 5 parasite species that cause malaria in humans, and 2 of these species \u2013 **P. falciparum** and **P. vivax** \u2013 pose the greatest threat.\n[source](https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/malaria)\n\n![](https:\/\/i.ibb.co\/QdQPJkY\/malar1.jpg)\nsource: **thegreatcoursesdaily.com**","e0a10ccf":"## Step 3: EDA -> Checking sample images<a id='step-3'><\/a>\nIn this step we will check the actual sample images of both infected and normal blood sample","01566786":"## Step 14: Plotting Sample Prediction (Groundtruth vs Predicted)<a id='step-14'><\/a>\nIn this step we will test our model by plotting 12 random prediction in which ground truth is in brackets and predicted value is outside the bracket if both match then the color will be blue whereas incorrect or misclassified instances will show in orange color.","789a5bfc":"## Step 11: Model Fitting<a id='step-11'><\/a>","c4356a33":"## Step 6: Normalizing Data<a id='step-6'><\/a>","b062db85":"## Step 9: Compiling the model<a id='step-9'><\/a>","938f210c":"### Confusion Matrix","9449c629":"In this kernel, I have shown the stepwise process of creating Convolution Neural Network Model using keras library for classifying images of Normal and Malaria parasite infected human blood sample. \n\nApart from that, I have also deployed a flask based web app. The link for **LIVE WEB APP** : [Malaria Detection Web App ](https:\/\/malaria-detection-app.herokuapp.com\/).Github repo :[malaria_detector](https:\/\/github.com\/sid321axn\/malaria-detection-app)   .Below is the snapshot of the web app deployed over internet.\n![](https:\/\/i.ibb.co\/gM7qfp4\/malaria.png)\n\n## Stepwise Approach\nFollowing steps have been followed while building the CNN based model\n1. [Step 1 : Importing Essential Libraries](#step-1)\n2. [Step 2 : Loading data](#step-2)\n3. [Step 3: EDA -> Checking sample of Infected and Uninfected images](#step-3)\n4. [Step 4: Data Preprocessing (Labeling & Resizing of images)](#step-4)\n5. [Step 5: Train Test Split](#step-5)\n6. [Step 6: Normalization](#step-6)\n7. [Step 7: Label Encoding](#step-7)\n8. [Step 8 : Model Building: CNN](#step-8)\n9. [Step 9: Compiling the model](#step-9)\n10. [Step 10: Setting Callbacks](#step-10)\n11. [Step 11: Model Fitting](#step-11)\n12. [Step 12: Model Evaluation (Testing accuracy, confusion matrix, classification report)](#step-12)\n13. [Step 13: Plotting ROC-AUC Curve](#step-13)\n14. [Step 14: Plotting Sample Prediction (Groundtruth vs Prediction)](#step-14)\n15. [Conclusion & Future Improvements](#conc-fut)\n","c26f16bd":"## Step 10: Setting Callbacks<a id='step-10'><\/a>","0fb3bef5":"### Plotting History of Model's Accuracy ","dad69c83":"## Step 7: Label Encoding<a id='step-7'><\/a>","1c9cadd4":"**Observation:**\n- As we can see from above images that in infected sample there is small dot in almost every image which may be the critical mark while recognizing the imfected image. the model has to learn this pattern during training stage.","06a3c2ad":"## Step 8: Model Building: CNN<a id='step-8'><\/a>","25f6c412":"- As we have seen our model is giving approx 96% recall and auc of around 96.36 which is good overall.\n- Further, we can also do data augmentation to increase the dataset and improve the accuracy\n- The only misclassified instance shown in our random sample plotting has seems to have a small mark but in real its not which our model errorneously understand as a mark and therefore predicted as infected sample.\n- I have deployed this model as a web app where we can upload the blood sample image and the model will predict status of sample whether it is infected or normal.\n\n\n## If Like please hit UPVOTE !!!!","d806dd2a":"## Step 2: Loading Data<a id='step-2'><\/a>\nIn this step we will first create separate directory to store Parasitized and Normal images (Uninfected)"}}