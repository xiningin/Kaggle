{"cell_type":{"812f14cf":"code","158ecc54":"code","65b12d41":"code","d663a766":"code","b1efbfa7":"code","f7c954b5":"code","f4baacc0":"code","f7dba86b":"code","75ff81cb":"code","41fb466e":"code","60766c54":"code","72acc916":"code","31e42d2c":"code","470b68c0":"code","78733478":"code","dc5f7cc1":"code","6d8f9d99":"code","4d2e1df8":"code","abdb3b3f":"code","3e4f983f":"code","da496194":"code","1303f64c":"code","153019a6":"code","9f645c58":"markdown","fac0e521":"markdown","6a18511d":"markdown","73fafcac":"markdown","6c49f1c4":"markdown","81aebdfd":"markdown"},"source":{"812f14cf":"data_path = \"..\/input\/instacart-market-basket-analysis\/\"","158ecc54":"start, end = [int(x) for x in input(\"\ub3cc\ub824\ubcf4\uace0 \uc2f6\uc740 \ud074\ub7ec\uc2a4\ud130 \uac1c\uc218\uc758 \uc2dc\uc791\uacfc \ub05d \ubc94\uc704\ub97c \uc785\ub825\ud574\uc8fc\uc138\uc694 : \").split(\",\")]\ncluster_model = input(\"\uc0ac\uc6a9\ud560 \ud074\ub7ec\uc2a4\ud130\ub9c1 \ubaa8\ub378\uc744 \uc785\ub825\ud558\uc138\uc694(kmeans\/hac\/dbscan\/spectral) : \")\ncolumn_level = input(\"user matrix\uc5d0 \uc0ac\uc6a9\ud560 column\uc744 \uc785\ub825\ud558\uc138\uc694(department\/aisle\/product_name) : \")\nPCA_mode = True\nif PCA_mode:\n    n_components = int(input(\"PCA\uc5d0 \uc0ac\uc6a9\ud560 n_components \uac1c\uc218\ub97c \uc785\ub825\ud558\uc138\uc694 : \"))\n    \nquick_test = False\nK = list(range(start, end+1))","65b12d41":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\norders = pd.read_csv(data_path + \"orders.csv\")\nif quick_test: prior = pd.read_csv(data_path + \"order_products__prior.csv\")[:10000]\nelse : prior = pd.read_csv(data_path + \"order_products__prior.csv\")\ntrain = pd.read_csv(data_path + \"order_products__train.csv\")\nproducts = pd.read_csv(data_path + \"products.csv\")\naisle = pd.read_csv(data_path + \"aisles.csv\")\ndepartment = pd.read_csv(data_path + \"departments.csv\")","d663a766":"# \ubd88\ub7ec\uc628 \ubaa8\ub4e0 \ud14c\uc774\ube14\uc744 \ud569\uce69\ub2c8\ub2e4.\ntemp = pd.merge(prior, products, on=[\"product_id\"])\ntemp = pd.merge(temp, orders, on=[\"order_id\"])\ntemp = pd.merge(temp, aisle, on=[\"aisle_id\"])\ndata = pd.merge(temp, department, on=[\"department_id\"])\ndel temp\ndata","b1efbfa7":"# \uac70\ub798\ub0b4\uc5ed\uc5d0 \ub300\ud574\uc11c \uac01 \ubb3c\ud488\uc744 \uc5bc\ub9c8\ub098 \uc0c0\uc744\uae4c?\nif quick_test:\n    display(data.product_name.value_counts()[:10]) # top10","f7c954b5":"# \uace0\uac1d\uc758 \uc0b0 \ubb3c\uac74\uc758 \uc218\nif quick_test:\n    display(data.user_id.value_counts()[:10])","f4baacc0":"# \uac70\ub798\ub0b4\uc5ed\uc5d0 \ud3ec\ud568\ub41c \uc18c\ubd84\ub958\ubcc4 \uac1c\uc218\nif quick_test:\n    display(data.aisle.value_counts()[:10])","f7dba86b":"# \uac70\ub798\ub0b4\uc5ed\uc5d0 \ud3ec\ud568\ub41c \ub300\ubd84\ub958\ubcc4 \uac1c\uc218\nif quick_test:\n    display(data.department.value_counts()[:10])","75ff81cb":"columns = [\"product_name\", \"user_id\", \"aisle\", \"department\"] #data.columns\ncolumns = np.array(columns)\ncolumns = np.setdiff1d(data.columns, columns) # \ucc28\uc9d1\ud569 \uad6c\ud558\ub294 \ud568\uc218.\ndata.drop(columns=columns, inplace=True)","41fb466e":"if column_level == \"department\": user_matrix = pd.crosstab(data.user_id, data.department) # 21d\nelif column_level == \"aisle\" :  user_matrix = pd.crosstab(data.user_id, data.aisle) # 134d\nelse: user_matrix = pd.crosstab(data.user_id, data.product_name) #csr_matrix ## sparse matrix\nuser_matrix","60766c54":"X = user_matrix.values\nprint(X.shape)\n\nif quick_test:\n    from sklearn.manifold import TSNE\n\n    # tSNE : \uc2dc\uac01\ud654\uc6a9\ub3c4\uc758 \ucc28\uc6d0\uac10\uc18c \uae30\ubc95. (2\ucc28\uc6d0\uc73c\ub85c \ubcc0\ud658\ud574\uc8fc\ub294 \uae30\ubc95)\n    tsne = TSNE(n_components=2)\n    #tsne.fit()\n    #tsne.transform()\n    reduced_data = tsne.fit_transform(X)\n    reduced_data","72acc916":"if quick_test:\n    # 206209 x 2\n    plt.figure(figsize=(12, 12))\n    #sns.scatterplot(data=reduced_data)\n    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=5, alpha=0.3)\n    plt.show()","31e42d2c":"from sklearn.metrics import silhouette_score\n#from sklearn.cluster import KMeans\nfrom sklearn.cluster import MiniBatchKMeans\nfrom tqdm import tqdm_notebook\n\ndef find_optimal_clusters(data, K):\n\n\n    scores = [] # initialization\n\n    for n_cluster in tqdm_notebook(K):\n        #model = KMeans(n_clusters=n_cluster) # 2~10\n        model = MiniBatchKMeans(n_clusters=n_cluster, batch_size=1024)\n        pred = model.fit_predict(data)\n\n        score = silhouette_score(data, pred)\n        scores.append(score)\n        \n    optimal_K = np.array(scores).argmax() + K[0] # K\n    best_pred = KMeans(n_clusters=optimal_K).fit_predict(data)\n    if quick_test:\n        return best_pred, scores\n    else:\n        return best_pred","470b68c0":"# Find optimal K\n# 1) elbow method  -> yellowbrick    # \uc124\uce58 \uc774\uc288.\n# from yellowbrick.cluster import elbow\n\n#     elbow()\n\n# 2) Silhouette score   # sklearn\nif quick_test:\n    best_pred, scores = find_optimal_clusters(X, K)\nelse:\n    best_pred = find_optimal_clusters(X, K)\nprint(\"Find optimal K.\")","78733478":"# \ud074\ub7ec\uc2a4\ud130 \uac1c\uc218\ubcc4 \uc2e4\ub8e8\uc5e3 \uc9c0\uc218\ub97c \uadf8\ub824\uc8fc\ub294 \uadf8\ub798\ud504.\nif quick_test:\n    plt.figure(figsize=(8, 4))\n    plt.title(\"Silhouette Score in range %d-%d\" % (K[0], K[-1]), fontsize=14)\n    plt.xlabel(\"Number of Clusters\")\n    plt.ylabel(\"Silhouette Score\")\n    plt.plot(K, scores)\n    plt.show()","dc5f7cc1":"if quick_test:\n    # \ud074\ub7ec\uc2a4\ud130\ubcc4 \uc0c9\uce60 \uacf5\ubd80\n    plt.figure(figsize=(8, 8))\n    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=10, alpha=0.3, c=best_pred)\n    plt.show()","6d8f9d99":"if quick_test:\n    # \uc2e4\ub8e8\uc5e3 \uacc4\uc0b0\n    print(\"Silhouette score : %.4f\" % silhouette_score(X, best_pred)) # [-1, 1]","4d2e1df8":"# \ucc28\uc6d0\uc774 \ud070 \uacbd\uc6b0\uc5d4?\n# \ucc28\uc6d0\uc758 \uc800\uc8fc \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574\uc11c \ucc28\uc6d0 \uac10\uc18c \uae30\ubc95\uc778 PCA\ub97c \uc801\uc6a9\ud574\ubd05\ub2c8\ub2e4.\nif PCA_mode:\n    from sklearn.decomposition import PCA\n\n    # tsne\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n    # 1) n_components\uac00 int\uba74, \ud574\ub2f9 \ucc28\uc6d0\uc73c\ub85c \uac10\uc18c. # 2) n_components\uac00 float\uba74 \ud574\ub2f9 \ube44\uc728\ub9cc\ud07c \ubcf4\uc874\ud558\ub294 \ucc28\uc6d0\uc73c\ub85c \uac10\uc18c.\n    pca = PCA(n_components=n_components)\n    reduced_pca = pca.fit_transform(X)\n    print(reduced_pca.shape)\n    \n    pca_columns = [f\"PC_{n}\" for n in range(1, n_components+1)]\n\n    pca_df = pd.DataFrame(data=reduced_pca, columns=pca_columns)\n    display(pca_df)","abdb3b3f":"# pca\ub41c \ub370\uc774\ud130\ub85c optimal_K\ub97c \ucc3e\uc544\ubcf4\uc138\uc694.\n\nif PCA_mode:\n    # Find optimal K\n    best_pred_pca, scores_pca = find_optimal_clusters(reduced_pca, K)","3e4f983f":"if quick_test:\n# \ud074\ub7ec\uc2a4\ud130 \uac1c\uc218\ubcc4 \uc2e4\ub8e8\uc5e3 \uc9c0\uc218\ub97c \uadf8\ub824\uc8fc\ub294 \uadf8\ub798\ud504.\n\n    plt.figure(figsize=(8, 4))\n    plt.title(\"Silhouette Score in range %d-%d\" % (K[0], K[-1]), fontsize=14)\n    plt.xlabel(\"Number of Clusters\")\n    plt.ylabel(\"Silhouette Score\")\n    plt.plot(K, scores_pca)\n    plt.show()","da496194":"if PCA_mode:\n    # PCA\ub97c \uc801\uc6a9\ud55c \ubaa8\ub378\uc5d0 \uc2e4\ub8e8\uc5e3 \uacc4\uc0b0\n    print(\"Silhouette score : %.4f\" % silhouette_score(reduced_pca, best_pred_pca)) # [-1, 1]","1303f64c":"if cluster_model == \"hac\":\n    from sklearn.cluster import AgglomerativeClustering\n\n    model = AgglomerativeClustering(n_clusters=4, affinity=\"euclidean\", linkage=\"average\")\n    if PCA_mode:\n        pred_hac = model.fit_predict(reduced_pca)\n        print(\"Silhouette score : %.4f\" % silhouette_score(reduced_pca, pred_hac)) # [-1, 1]\n    else:\n        pred_hac = model.fit_predict(X)\n        print(\"Silhouette score : %.4f\" % silhouette_score(X, pred_hac)) # [-1, 1]","153019a6":"# with open(f\"result_{model}_{optimal_K}_{custom_no}.txt\", \"w\") as f:\n#     f.write(str(score))\n#     f.write(~~)\n#     ..\n#     ....","9f645c58":"## 1. Data Preparation","fac0e521":"### 2. \ub370\uc774\ud130 \uc804\ucc98\ub9ac\n\n- \ub370\uc774\ud130\ub97c transaction \ub2e8\uc704\ub85c \ubcc0\uacbd\ud569\ub2c8\ub2e4.\n\n- \uac01\uc790\uc758 \ubc29\ubc95\ub300\ub85c \ub370\uc774\ud130\uc758 \ub2e8\uc704\ub97c \uc815\ud574\ubd05\uc2dc\ub2e4.\n\n- \uacb0\uce21\uce58\ub97c \ucc98\ub9ac\ud558\uace0, \uc815\uaddc\ud654\ub3c4 \uc9c4\ud589\ud574\ubd05\ub2c8\ub2e4.\n\n- \ud544\uc694\ud558\uba74 PCA\ub098 SVD\ub97c \uc0ac\uc6a9\ud574\ub3c4 \uc0c1\uad00\uc5c6\uc2b5\ub2c8\ub2e4.\n\n\n> User \ub2e8\uc704\ub85c \uc5b4\ub5a4 \ubb3c\ud488\uc744 \uad6c\ub9e4\ud588\ub294\uc9c0\uc758 \uc815\ubcf4\ub9cc \uac00\uc9c0\ub294 feature vector\ub85c \ubcc0\ud658\ud55c\ub2e4. e.g. pd.crosstab, CountVectorizer","6a18511d":"### Data Description\n\nSource : https:\/\/www.kaggle.com\/c\/instacart-market-basket-analysis","73fafcac":"### 1. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 ","6c49f1c4":"## Task. Customer Segmentation\n\n- \ub370\uc774\ud130\ub97c \uc815\uc81c\ud574\uc11c, \uace0\uac1d\ubcc4\ub85c \uc7ac\uc815\ub82c\uc774 \ud544\uc694\ud569\ub2c8\ub2e4. (aggregation)\n\n\n- row\uac00 \uace0\uac1d\ubcc4 \ub370\uc774\ud130\ub85c \ubb36\uc774\uace0 \ub09c \ub2e4\uc74c, \uace0\uac1d\ub4e4\uc744 \uc720\ud615\ubcc4\ub85c \ub098\ub220\ubd05\ub2c8\ub2e4.\n\n\n- \uc5ec\ub7ec \uac00\uc9c0 \ud074\ub7ec\uc2a4\ud130\ub9c1 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec, \uacb0\uacfc\ub97c \ud14c\uc2a4\ud2b8\ud574\ubd05\ub2c8\ub2e4.\n\n\n- \ud074\ub7ec\uc2a4\ud130\ub9c1\uc744 \uc704\ud55c \uc804\ucc98\ub9ac\ubd80\ud130, \ud3c9\uac00\uae4c\uc9c0 \ubaa8\ub4e0 \ud56d\ubaa9\uc744 \ud558\ub098\ud558\ub098 \uc0b4\ud3b4\ubcf4\uba74\uc11c \ub370\uc774\ud130\ub97c \ub72f\uc5b4\ubd05\ub2c8\ub2e4.","81aebdfd":"### 3. \ud074\ub7ec\uc2a4\ud130\ub9c1 \ubaa8\ub378 \uc801\uc6a9\ud558\uae30\n\n- \uc0ac\uc6a9\ud558\ub294 \ud074\ub7ec\uc2a4\ud130\ub9c1 \ubaa8\ub378\uc740 KMeans\uc640 AgglomerativeClustering\uc73c\ub85c \ud569\ub2c8\ub2e4.\n\n(\uc6d0\ud558\uc2dc\uba74 DBSCAN\uc774\ub098 SpectralClustering\uc744 \uc0ac\uc6a9\ud574\ubcf4\uc154\ub3c4 \ub429\ub2c8\ub2e4. \ub2e8, \uc2dc\uac04\uc774 \ub9e4\uc6b0\ub9e4\uc6b0 \uc624\ub798 \uac78\ub9b4\uc218 \uc788\uc73c\ub2c8 \uc8fc\uc758\ud558\uc138\uc694..)\n\n**[K-Means]**\n\n- Elbow method\ub97c \uc774\uc6a9\ud558\uc5ec \ucd5c\uc801\uc758 K\uac12\uc744 \ucc3e\uc544\ubcf4\uc138\uc694.\n\n\n- sparse\ud55c \ud2b9\uc9d5\uc744 \uac00\uc9c0\ub294 \ub370\uc774\ud130\ub97c \ud074\ub7ec\uc2a4\ud130\ub9c1 \ud558\uae30 \uc704\ud574\uc11c\ub294 \uc5b4\ub5a4 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud574\uc57c \ud560\uae4c\uc694?\n\n\n- \ud074\ub7ec\uc2a4\ud130\ub9c1 \uacb0\uacfc\ub97c \uc2dc\uac01\ud654\ud574\ubcf4\uace0, \uc2e4\ub8e8\uc5e3 \uc9c0\uc218\ub3c4 \uacc4\uc0b0\ud574\ubd05\uc2dc\ub2e4.\n\n\n\n**[Hierarchical Clustering]**\n\n- \ud074\ub7ec\uc2a4\ud130 \uac1c\uc218\ub97c 4\ub85c \uc9c0\uc815\ud558\uace0, linkage\uc640 affinity\ub97c \ubc14\uafd4\uac00\uba74\uc11c \uc2e4\ud5d8\ud574\ubcf4\uc138\uc694.\n\n\n- \uc5b4\ub5a4 linkage\uc640 affinity\ub97c \uc4f8\uc9c0 \uace0\ubbfc\ud558\ub824\uba74, \uc5b4\ub5a4 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud574\ubcf4\uba74 \uc88b\uc744\uae4c\uc694?\n\n\n- \ud074\ub7ec\uc2a4\ud130\ub9c1 \uacb0\uacfc\ub97c \uc2dc\uac01\ud654\ud574\ubcf4\uace0, \uc2e4\ub8e8\uc5e3 \uc9c0\uc218\ub3c4 \uacc4\uc0b0\ud574\ubd05\uc2dc\ub2e4."}}