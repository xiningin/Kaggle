{"cell_type":{"8616c3b1":"code","06e2e9be":"code","1df82e49":"code","68ef6133":"code","6801d05e":"code","cc5d7513":"code","95eca11f":"code","84667cae":"code","b83f9c20":"code","bba11367":"code","31598df3":"code","67b107f7":"code","7d60d454":"code","c0c78651":"code","554793df":"code","ea6433bc":"code","fee990fd":"code","83a5c0e9":"code","8e86c3c3":"code","d5347f4b":"code","91972e09":"code","4738917f":"code","8acb2cef":"code","1d0f114d":"code","1b1d2877":"code","866b5172":"code","25bad134":"code","03461fc5":"code","969ca236":"code","91ce2aef":"code","3f4913e2":"code","39f1468d":"code","b840559f":"code","d0bbd1fe":"code","45534f7b":"code","6d2e1309":"code","4a475439":"code","98439f48":"code","c21dcb88":"code","d155c18f":"code","3b1d4d0c":"code","a8dbca39":"code","510b01d9":"code","eef4953c":"code","e36e1740":"code","a96d993c":"code","00e24783":"code","fb142439":"code","bd75e10e":"code","182adf0b":"code","a833c0b2":"code","69be41aa":"code","d6cba1e4":"code","b06aa413":"code","37c08ca1":"code","e3b60d4c":"code","8b58f547":"code","55f76178":"code","9ed0fcba":"code","8988a52a":"code","0491a9bb":"code","d90cfa72":"code","78d43c48":"markdown","d7851534":"markdown","92f179a2":"markdown","bab2c065":"markdown","3ed2c222":"markdown","0c2bfb90":"markdown","dcb88d92":"markdown","9c7c59fd":"markdown","956c080f":"markdown","cb3592da":"markdown","d919522e":"markdown","ee7d459f":"markdown","205320dc":"markdown","27c17780":"markdown","581acb7b":"markdown","edcc6276":"markdown","47725025":"markdown","c0ad3da5":"markdown","769238ff":"markdown","78e4d21e":"markdown","b674fa65":"markdown","9b483d32":"markdown","345bc5e9":"markdown","76b2c35f":"markdown","541a53f3":"markdown","3159187f":"markdown","1a6911e6":"markdown","cd5359e8":"markdown","236b8324":"markdown","ff19f892":"markdown","5b780e57":"markdown","75ad0dea":"markdown","85f3597b":"markdown","83a1af68":"markdown","751245d8":"markdown","9d12dbc0":"markdown","65e1b8ff":"markdown","646f92ec":"markdown","8912cce9":"markdown","b54f5439":"markdown","07861e93":"markdown","6a069767":"markdown","ce1e338f":"markdown","8c331f6d":"markdown","29f78241":"markdown","1b21a960":"markdown","2aab4c17":"markdown"},"source":{"8616c3b1":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","06e2e9be":"# Read data out into train and test dataframes\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col='PassengerId')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col='PassengerId')","1df82e49":"# Print out the top 5 rows of the training data\ntrain.head()","68ef6133":"# Look at the columns present in both training and test data to see if any columns are different between them\nprint('Train data columns: ', train.columns)\nprint('Test data columns: ', test.columns)","6801d05e":"# look at the datatypes and null values for the training data\ntrain.info()","cc5d7513":"train = train.drop('Cabin', axis=1)","95eca11f":"ax = train[\"Age\"].hist(bins=15, color='#34495e', alpha=0.9)\nax.set(xlabel='Age', ylabel='Count')\nplt.show()","84667cae":"train['Age'] = train['Age'].fillna(train['Age'].median())\ntrain['Age'].describe()","b83f9c20":"ax = train[\"SibSp\"].hist(bins=20, color='#34495e', alpha=0.9, label='SibSp')\nax = train[\"Parch\"].hist(bins=20, color='yellow', alpha=0.9, label='Parch')\nax.set(xlabel='No of sibling\/spouse or children\/parents', ylabel='Count')\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, labels)\nplt.show()","bba11367":"def if_alone(row):\n    if (row['SibSp'] == 0) and (row['Parch'] == 0):\n        return 1\n    return 0\n\ntrain['Alone'] = train.apply(if_alone, axis='columns')\ntrain['Alone'][0:5]","31598df3":"def family_size(row):\n    if row['Alone'] == 0:\n        return row['SibSp'] + row['Parch'] + 1\n    return 0\n\ntrain['FamilySize'] = train.apply(family_size, axis='columns')\ntrain['FamilySize'].describe()","67b107f7":"train.groupby('Survived').Fare.hist(legend=True)  # 0 == Died, 1 == Survived","7d60d454":"x = train.groupby('Survived').Fare.describe()","c0c78651":"ax2 = train.plot.scatter(x='Age',\n                      y='Fare',\n                      c='Survived',\n                      colormap='viridis')","554793df":"train.groupby('Survived').Age.hist(legend=True, alpha=0.7) # 0 == Died, 1 == Survived","ea6433bc":"children_data = train[train['Age'] < 16]\nchildren_data.groupby('Survived').Age.hist(legend=True, alpha=0.7) # 0 == Died, 1 == Survived","fee990fd":"sns.countplot(x='Survived',hue='Pclass',data=children_data)","83a5c0e9":"sns.countplot(x='Sex',hue='Survived',data=train)","8e86c3c3":"print(train.groupby(['Sex', 'Pclass']).mean()['Survived'])\nprint(train.groupby(['Sex', 'Pclass']).std()['Survived'])","d5347f4b":"#Number of Female passengers\nfemale_passengers = train.loc[train['Sex'] == 'female']\nprint('Number of female passengers in training data: ', len(female_passengers))\n\n# Number of female passengers under 18\nfemale_passengers_under_18 = female_passengers.loc[female_passengers['Age'] < 18]\nprint('Number of female passengers under 18 in training data: ', len(female_passengers_under_18))\n\n# Number of female passengers over 60\nfemale_passengers_over_60 = female_passengers.loc[female_passengers['Age'] > 60]\nprint('Number of female passengers over 60 in training data: ', len(female_passengers_over_60))\n\n# Number of female passengers traveling alone\nfemale_passengers_parch = female_passengers.loc[female_passengers['Alone'] == 1]\nprint('Number of female passengers traveling alone in training data: ', len(female_passengers_parch))\n\n# Number of female passengers traveling with a parent or child\nfemale_passengers_parch = female_passengers.loc[female_passengers['Parch'] >= 1]\nprint('Number of female passengers traveling with a parent or child in training data: ', len(female_passengers_parch))\n\n# Number of female passengers traveling with a sibling or spouse\nfemale_passengers_with_sibsp = female_passengers.loc[female_passengers['SibSp'] >= 1]\nprint('Number of female passengers traveling with a sibling or spouse in training data: ', len(female_passengers_with_sibsp))\n\n# Number of female passengers who surrived\nfemale_passengers_that_survived = female_passengers.loc[female_passengers['Survived'] == 1]\nprint('Number of female passengers that survived in training data: ', len(female_passengers_that_survived))\n\n# Percentage of female passengers that surived f'{x:.0%}'\nprint('Precentage of female passengers that survived in training data: ', f'{len(female_passengers_that_survived)\/len(female_passengers)*100:.1f}%')","91972e09":"sns.countplot(x='Survived',hue='Pclass',data=train)","4738917f":"train['Survival'] = train.Survived.map(lambda t: 'Survived' if t == 1 else 'Died')\ntrain['Class'] = train.Pclass.map(lambda t: '1st class' if t == 1 else ('2nd class' if t == 2 else '3rd class'))\n\n(train\n.groupby(['Survival', 'Class', 'Sex'])\n.Class\n.count()\n.plot(kind='bar')\n)","8acb2cef":"sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=train, hue=\"Embarked\", palette=\"Set1\");","1d0f114d":"sns.countplot(x='FamilySize',hue='Survived',data=train)","1b1d2877":"sns.countplot(x='Alone',hue='Survived',data=train)","866b5172":"# Extract surname into separate column\ntrain['Surname'] = train['Name'].map(lambda x: x.split(',')[0])\nprint(train['Surname'][0:5])","25bad134":"surnames_count = (\n train\n .groupby(['Surname', 'Survived', 'Pclass'])\n [['Surname']]\n .count()\n .sort_values(ascending=False, by='Survived')\n)\n\nsurnames_count = surnames_count.loc[surnames_count['Surname'] > 1] # filter out only surnames with more than one passenger\n\nsurnames_count.reset_index(level=1, inplace=True) # move the survived index to a column so we can plot it\nsurnames_count = surnames_count.rename(columns={\"Surname\": \"No of passenger with same surname\"}, errors=\"raise\")\n\nsns.countplot( x='No of passenger with same surname', data=surnames_count, hue='Survived', palette=\"Set1\")","03461fc5":"surnames_count.reset_index(level=1, inplace=True) # move the survived index to a column so we can plot it\nsns.countplot( x='No of passenger with same surname', data=surnames_count, hue='Pclass', palette=\"Set1\")","969ca236":"# Extract first name into separate column\ntrain['First_names'] = train['Name'].map(lambda x: x.split('.')[1].split('(')[0].strip())\nprint(train['First_names'][0:5])","91ce2aef":"(train\n.groupby(['Survived', 'First_names'])\n.First_names\n.count()\n.sort_values(ascending=False)\n[:10]\n)","3f4913e2":"len(train.loc[train['First_names'] == 'John'])","39f1468d":"# Extract title into separate column\ntrain['Title'] = train['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain['Title'] = train['Title'].map(lambda x: 'Countess' if x == 'the Countess' else x)\nfor title in train['Title'].unique():\n    print(title, train.loc[(train['Title'] == title)].Title.count())","b840559f":"plt.title('Title distribution of those who died on the Titanic')\n(train[train.Survived == 0]\n.groupby(['Title'])\n.Title\n.count()\n.plot(kind='bar')\n)","d0bbd1fe":"plt.title('Title distribution of those who survived on the Titanic')\n(train[train.Survived == 1]\n.groupby(['Title'])\n.Title\n.count()\n.plot(kind='bar')\n)","45534f7b":"# Extract the ticket type (assuming potentially where they bought the ticket) from the ticket value\ntrain['Ticket_type'] = train['Ticket'].map(lambda x: x.split()[0] if any(c.isalpha() for c in x.split()[0]) else 'Unknown')\nprint(train['Ticket_type'].unique())\n\nprint(train['Ticket_type'].describe())\nunknown_ticket_type = train[train['Ticket_type'] == 'Unknown']['Ticket_type'].count()\nprint('No of unknown ticket type', unknown_ticket_type)\nprint('Percentage of unknown ticket type', f'{(unknown_ticket_type\/ 891)*100:.1f}%')","6d2e1309":" train[train['Ticket_type'] == 'Unknown'].groupby(['Survived'])['Ticket_type'].count().plot(kind='bar', rot=0)","4a475439":" train[train['Ticket_type'] != 'Unknown'].groupby(['Survived'])['Ticket_type'].count().plot(kind='bar', rot=0)","98439f48":"train = train.drop('Ticket_type', axis=1)\ntrain = train.drop('Ticket', axis=1)\ntrain.columns","c21dcb88":"# Put feature columns into X_train dataframe\nbase_features = ['Pclass', 'Sex', 'Age', 'Alone', 'FamilySize', 'Fare', 'Embarked', 'Title']\nX_train = train[base_features].copy()\nX_train.index = train.index\n# Put survival value into y\ny = train['Survived']\n\nprint(y.head())\nX_train.head()","d155c18f":"# Look at what data is categorical data\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(object_cols)","3b1d4d0c":"# Update the Embarked column to replace nan values with unknown\nX_train['Embarked'] = X_train['Embarked'].fillna('unknown')\n\nprint(X_train['Embarked'].unique())","a8dbca39":"# Update the Age column to replace nan values with the mean value\nX_train['Age'].fillna(X_train['Age'].mean(), inplace=True)","510b01d9":"# Check cardinality of categorical variables\nobject_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n# Print in ascending order\nsorted(d.items(), key=lambda x: x[1])\n\n# We can conclude that for those with low cardinality we can use one-hot encoding and for the time being I am dropping those with high cardinality","eef4953c":"# Assign categorical data columns to low or high cardinality lists\nlow_cardinality = ['Title', 'Sex', 'Embarked']","e36e1740":"# from sklearn.preprocessing import LabelEncoder\n# label_encoder = LabelEncoder()\n# for col in high_cardinality:\n#     X_train[col] = label_encoder.fit_transform(X_train[col])\n\nX_train.head()\nX_train.info()","a96d993c":"from sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality]))\nOH_cols_train.columns = OH_encoder.get_feature_names()\nprint('OH_cols_train: ', OH_cols_train.columns.tolist(), ' shape ', OH_cols_train.shape)\nnon_oh_encoded = X_train.drop(low_cardinality, axis=1)\nOH_cols_train.index = X_train.index\nprint('non_oh_encoded: ', non_oh_encoded.columns.tolist(), ' shape ', non_oh_encoded.shape)\nOH_X_train = pd.concat([non_oh_encoded, OH_cols_train], axis=1)\nOH_X_train.index = X_train.index\nprint('OH_X_train: ', OH_X_train.columns.tolist(), ' shape ', OH_X_train.shape)\nOH_X_train.columns","00e24783":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(OH_X_train, y, random_state = 0)","fb142439":"val_X.dropna(axis=0, how='any', inplace=True)","bd75e10e":"print(train_X.columns)","182adf0b":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=0)\nrf_model.fit(train_X, train_y.values.ravel())","a833c0b2":"predictions = rf_model.predict(val_X)","69be41aa":"print(predictions[0:5])\nprint(val_y[0:5])\nprint(f'Accuracy: {rf_model.score(val_X, val_y):.2f}%')","d6cba1e4":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf_model, random_state=1).fit(val_X, val_y)\n\neli5.show_weights(perm, feature_names=val_X.columns.tolist())","b06aa413":"from pdpbox import pdp, get_dataset, info_plots\n\nimportant_features = ['Pclass', 'x1_female', 'x1_male', 'Age', 'FamilySize', 'Fare', 'x0_Mr', 'x0_Mrs']\n\nfor feature_name in important_features:\n    pdp_goals = pdp.pdp_isolate(model=rf_model, dataset=val_X, model_features=val_X.columns.tolist(), feature=feature_name)\n    pdp.pdp_plot(pdp_goals, feature_name)\n    plt.show()","37c08ca1":"inter1 = pdp.pdp_interact(model=rf_model, dataset=val_X, model_features=val_X.columns.tolist(), features=important_features)\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=val_X.columns.tolist(), plot_type='contour')\nplt.show()","e3b60d4c":"row_to_show = 5\ndata_for_prediction = val_X.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nrf_model.predict_proba(data_for_prediction_array)","8b58f547":"import shap\nexplainer = shap.TreeExplainer(rf_model)\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\ndata_for_prediction = val_X.iloc[1]\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction) # looking at values for those that surrived\n#  Shap values show how much a given feature changed our prediction (compared to if we made that prediction at some baseline value of that feature).","55f76178":"# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(rf_model)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(val_X)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[1], val_X)","9ed0fcba":"# make plot.\nshap.dependence_plot('Age', shap_values[1], val_X, interaction_index=\"Pclass\")","8988a52a":"from sklearn.model_selection import train_test_split\ntrain_reduced_features_X, val_reduced_features_X, train_reduced_features_y, val_reduced_features_y = train_test_split(OH_X_train[important_features], y, random_state = 0)\nval_X.dropna(axis=0, how='any', inplace=True)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf_reduced_features_model = RandomForestClassifier(random_state=0)\nrf_reduced_features_model.fit(train_reduced_features_X, train_reduced_features_y.values.ravel())\n\npredictions = rf_reduced_features_model.predict(val_reduced_features_X)\n\nprint('Predictions: ', predictions[0:5])\nprint('Y Values: ', val_reduced_features_y[0:5])\nprint(f'Accuracy: {rf_reduced_features_model.score(val_reduced_features_X, val_reduced_features_y):.2f}%')","0491a9bb":"pd.options.display.max_rows\npd.set_option('display.max_rows', None)\ntest_character = pd.DataFrame([val_reduced_features_X.iloc[3]], columns=important_features)\nprint(test_character)","d90cfa72":"prediction = rf_reduced_features_model.predict(test_character)\nif prediction[0] == 0:\n    print('Sorry you died')\nelse:\n    print('You survived!')","78d43c48":"### Looking at the relationship class and sex has on survival on the Titanic","d7851534":"## Evaluating our model","92f179a2":"# Building a survival model for the Titanic Kaggle competition","bab2c065":"We can see most people travelled alone with no children, parents, siblings or spouse on board. Lets create some features from this information, starting with a column to denote if a passenger was traveling alone or not.","3ed2c222":"Looking at this graph the age is slightly skewed so we would be better to replace the missing values with the median not the mean.","0c2bfb90":"## Training our model and making predictions","dcb88d92":"### Survival and Class on the Titanic","9c7c59fd":"Let's go a head an make a column for family size which sums the siblings, spouse, children, parents plus the passenger.","956c080f":"### Just a name? Is there any correlation between a passengers name their chances of survival?","cb3592da":"## Exploring survival on the Titanic","d919522e":"### 2D Partial Dependance Plots","ee7d459f":"This chart matches quite well the one we have for families, this is not suprising as they are the one's most likley to share a surname. Again we can summise that those in larger groups were less likely to be in the group which survived.","205320dc":"If we look at the surnames that were shared with the most passengers we can see they are predominently 3rd class, which points to larger family groups travelling together. This may indirectly be the reason that more popular surnames (ie those that more passengers had) were in the group which died.","27c17780":"Generally the distribution is similar between the passengers how survived and those who didn't when it comes to location of embarkment. There is however slightly more of the people who embarked at C in the group which survived which perhaps suggests some advantage. Again it could be indirect, perhaps those that joined there were part of the 1st class for example.","581acb7b":"### Passengers travelling with family members","edcc6276":"### Passenger Title","47725025":"We see here that there are slightly more survivers in the group who were traveling alone and only a few survivors who were traveling in a larger family group. Pointing towards this as a potentially important feature for our model.","c0ad3da5":"The largest group from the Titanic by far was 3rd class males who died by quite a gap. We can also see that females in 1st and 2nd class more often survived than died but females from 3rd class appear to be split in half between those which survived and those who did not.","769238ff":"Here we see that more female passengers surrived in this data in comparison to male passengers. We can also conclude that in general the ratio of male passengers who survived compared to the total amount of male passengers aboard the titanic is very low where as a higher percentage of the female passengers survived. Below we explore the data regarding the female passengers.","78e4d21e":"## Refining our model","b674fa65":"## Exploring the data","9b483d32":"### Survival and Sex of passengers","345bc5e9":"## Building a prediction function ","76b2c35f":"### Age of Passengers on the Titanic","541a53f3":"We do see that the spread is rather wide but there is a peak in the group aged 0-10 which could confrim the aledged policy of Women & children first.","3159187f":"Most families were rather small but there was at least one with 11 family members onboard!","1a6911e6":"This chart suggests that survival was fairly spread out when it came to age, let's check that.","cd5359e8":"Let's start building a model with the features we have identified as being important.","236b8324":"### Ticket Type","ff19f892":"Those who paid a very low fare are more represented in the group which did not survive. In the group of those who survived we see a wider spread of fares and all the higher fares are from passengers who survived. On average those who survived had paid more on their fare than those who did not. This is also represented in the chart below where we plot the fare against age. ","5b780e57":"### Survival and travelling with relatives on the Titanic","75ad0dea":"We certainly see more of the titels that belong to females in the survived group.","85f3597b":"### SHAP Values\nbreak down a prediction to show the impact of each feature.","83a1af68":"* Mlle     == Mademoiselle.\n* Don      == A head, tutor, or fellow at a college of Oxford or Cambridge. Or title for males in spanish speaking areas.\n* Mme      == Madam.\n* Jonkheer == An honorific in the Low Countries denoting the lowest rank within the nobility.\n\nIt may be worth grouping some of these unless they had significant affect on whether someone was in the survived group but as we've seen in previous analysis it appears Sex was the more important feature.","751245d8":"While it remains unlikely someone's first name would play a role in their survival on the Titanic interesting all of the passengers in the training data called John died. This isn't statistically so suprising as they were most likely male passengers and we've already discovered male passengers were predominently in the group which died. It may point to patterns in the names given to different classes if indeed such a thing existed.","9d12dbc0":"### Survival and Fare paid","65e1b8ff":"Here we can see many more 3rd class passengers died than 1st class passengers.","646f92ec":"### Permutation importance of features","8912cce9":"With such a large about of the ticket type being unknown it's unlikley this column will be a useful feature and we can drop it. Let's check this first by ploting the unknow tickets and the known ones by survival.","b54f5439":"By taking only the most important features we have slightly improved the accuracy of our model.","07861e93":"From this information we can see that most columns have complete values. The cabin column appears to have the most values missing with only 204 out of 891 that have a non-null value. For this reason we should drop this column. The column for Age seems to have a number of value missing. Here we may want to use the average age to fill these empty entries if we deem this an important feature. Age and Fare are both Float values.\n\nCategorical columns:  ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']  Surived is also a categorical column as it's values are 1 for survived and 0 for died.\n    \n    ","6a069767":"Interestingly 'Alone' does not appear here, suggesting it has much less importance than previously thought.","ce1e338f":"### Survival and where passengers embarked on the Titanic","8c331f6d":"## Creating a model","29f78241":"## Importing the data","1b21a960":"### Handling categorical data","2aab4c17":"### Partial dependence plots"}}