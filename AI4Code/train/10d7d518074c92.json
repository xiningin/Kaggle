{"cell_type":{"22129e40":"code","572162bc":"code","36014f6c":"code","a0a12466":"code","cc87b396":"code","5ec3fd7d":"code","c10e25f6":"code","fe4f0fe8":"code","82fad090":"code","301a989a":"code","8cbc75b0":"code","483a74e4":"code","7fb73262":"code","f897b2e7":"code","aa765073":"code","95405ded":"code","a5b6a836":"code","8d8d85b1":"code","b1eb6c78":"code","498b9b0d":"code","44d4a379":"code","94fcdb39":"code","35727b79":"code","a7b7a1ec":"code","6765ed95":"code","de9a13d0":"code","d5cd6468":"markdown","b396c6e0":"markdown","bc9b37c2":"markdown","44bb7d85":"markdown","203cc67e":"markdown","5c70ef1b":"markdown","72d27e53":"markdown","67fa5a1b":"markdown","e42b2d0b":"markdown","8ff30f17":"markdown","e96affa3":"markdown","accb8bce":"markdown","f9c6b55a":"markdown","968fc0a9":"markdown","9ae8511c":"markdown","555306dd":"markdown","37167220":"markdown","a7f45045":"markdown","dde35054":"markdown","91ba5090":"markdown","ac04d7f3":"markdown","97b81935":"markdown","e3fc2898":"markdown","4d55fbd3":"markdown"},"source":{"22129e40":"import pandas as pd \nimport numpy as np  \nimport matplotlib\nimport matplotlib.pyplot as plt \nimport seaborn as sns           \ncolor = sns.color_palette()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\n\nimport cufflinks as cf\ncf.go_offline()\n\n# Venn diagram\nfrom matplotlib_venn import venn2\nimport re\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\neng_stopwords = stopwords.words('english')\nimport gc\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nimport os\nimport nilearn as nl","572162bc":"path = '\/kaggle\/input\/trends-assessment-prediction'\nprint(os.listdir(path))","36014f6c":"df_loading           = pd.read_csv(path +'\/loading.csv')\ndf_train             = pd.read_csv(path +'\/train_scores.csv')\ndf_sample_submission = pd.read_csv(path +'\/sample_submission.csv')","a0a12466":"print('Tamanho de df_loading', df_loading.shape)\nprint('Tamanho de df_train', df_train.shape)\nprint('Tamanho de sample_submission', df_sample_submission.shape)\nprint('test tamanho:', len(df_sample_submission)\/5)\n","cc87b396":"df_train.head()","5ec3fd7d":"df_train.info()","c10e25f6":"df_sample_submission.head()","fe4f0fe8":"display(df_loading.head())\ndisplay(df_loading.describe())","82fad090":"display(df_train.head())\ndisplay(df_train.describe())","301a989a":"df_sample_submission.head()","8cbc75b0":"targets = list(df_train.columns[1:])\ntargets","483a74e4":"# checking missing data\ntotal   = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum() \/ train_data.isnull().count() * 100).sort_values(ascending = False)","7fb73262":"df_missing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\ndf_missing_train_data.head()","f897b2e7":"# checking missing data\ntotal   = df_loading.isnull().sum().sort_values(ascending = False)\npercent = (df_loading.isnull().sum() \/ df_loading.isnull().count()*100).sort_values(ascending = False)\n\ndf_missing_test  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\ndf_missing_test.head()","aa765073":"def distributionTarget(df, type):\n\n    targets   = df.columns[1:]\n    fig, axes = plt.subplots(6, 5, figsize=(18, 15))\n    fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n   \n    axes = axes.ravel()\n    \n    if type == 1:\n        bins = np.linspace(-0.05, 0.05, 20) \n    else: \n        bins = np.linspace(0, 100, 20) \n\n    for i, col in enumerate(targets):\n        ax = axes[i]\n        sns.distplot(df[col], label = col, kde = False, bins = bins, ax = ax)\n\n    plt.tight_layout()\n    plt.show()\n    plt.close()","95405ded":"distributionTarget(df_loading, 1)","a5b6a836":"distributionTarget(df_train, 2)","8d8d85b1":"def load_subject(filename, mask_niimg):\n    \"\"\"\n    Carrega os dados salvo no formato .mat com\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 o sinalizador da vers\u00e3o 7.3. Retornar os dados \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 em niimg, usando uma m\u00e1scara niimg como modelo\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 para cabe\u00e7alhos nifti.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0 Args:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 filename <str> o nome do arquivo .mat para os dados do \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 objeto mask_niimg niimg o objeto mask niimg usado para cabe\u00e7alhos nifti         \n    \"\"\"\n    subject_data = None\n\n    with h5py.File(subject_filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n        \n    # \u00c9 necess\u00e1rio reorientar os eixos, pois o h5py vira a ordem dos eixos\n    \n    subject_data  = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    \n    return subject_niimg","b1eb6c78":"path_fMRI_mat = '\/kaggle\/input\/trends-assessment-prediction\/fMRI_train\/'","498b9b0d":"import h5py\nimport nilearn.plotting as nlplt","44d4a379":"mask_filename    = '\/kaggle\/input\/trends-assessment-prediction\/fMRI_mask.nii'\nsubject_filename = '..\/input\/trends-assessment-prediction\/fMRI_train\/10015.mat'\nsmri_filename    = 'ch2better.nii'\nmask_niimg       = nl.image.load_img(mask_filename)","94fcdb39":"subject_niimg = load_subject(subject_filename, mask_niimg)","35727b79":"print(\"Image shape is %s\" % (str(subject_niimg.shape)))\nnum_components = subject_niimg.shape[-1]\nprint(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n","a7b7a1ec":"!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","6765ed95":"nlplt.plot_prob_atlas(subject_niimg, \n                      bg_img     = smri_filename, \n                      view_type  = 'filled_contours', \n                      draw_cross = False, \n                      title      = 'All %d spatial maps' % num_components, \n                      threshold  = 'auto')\n","de9a13d0":"grid_size = int(np.ceil(np.sqrt(num_components)))\nfig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*10, grid_size*10))\n[axi.set_axis_off() for axi in axes.ravel()]\n\n\n\nfor i, cur_img in enumerate(nl.image.iter_img(subject_niimg)):\n    col = i % grid_size\n    if col == 0:\n        row += 1\n    nlplt.plot_stat_map(cur_img, bg_img=smri_filename, title=\"IC %d\" % i, axes=axes[row, col], threshold=3, colorbar=False)","d5cd6468":"Observamos que temos valores nulos nas vari\u00e1veis: \n- domain1_var1 \n- domain1_var2\n- domain2_var1\n- domain2_var2 ","b396c6e0":"## <a id='5-2'> 5.2 Distribui\u00e7\u00e3o de vari\u00e1veis de entrada em df_loading<\/a>","bc9b37c2":"**df_sample_submission**","44bb7d85":"## <a id='5-3'> 5.3 Explorar mapas espaciais de fMRI <\/a>\nEm geral, os mapas espaciais s\u00e3o salvos como tensores 4-D\n\n$$\\mathcal{X}_i \\in \\mathbb{R}^{X \\times Y \\times Z \\times K}$$\n\nonde $ X $, $ Y $ e $ Z $ s\u00e3o as tr\u00eas dimens\u00f5es espaciais do volume e $ K $ \u00e9 o n\u00famero de componentes.\n\n## Formato de arquivo\nOs mapas espaciais do assunto foram salvos em arquivos `.mat` usando o sinalizador` v7.3`; portanto, eles devem ser carregados como conjuntos de dados `h5py`,e um arquivo nifti deve ser usado para definir os cabe\u00e7alhos para fins de exibi\u00e7\u00e3o. Inclu\u00edmos a fun\u00e7\u00e3o `load_subject`, que leva um nome de arquivo `.mat` do assunto e a imagem nilearn carregada a ser usada para definir os cabe\u00e7alhos.","203cc67e":"## <a id='5'> 5. Explora\u00e7\u00e3o de dados<\/a>","5c70ef1b":"## Exibindo todos os componentes em um atlas de probabilidades\nPrimeiro, exibiremos os 53 mapas espaciais em um atlas completo usando a fun\u00e7\u00e3o nilearn `plot_prob_atlas`. Estes\nos mapas ser\u00e3o sobrepostos em um modelo estrutural de RM.","72d27e53":" ## Download da imagem do modelo ch2better para exibi\u00e7\u00e3o","67fa5a1b":"**Verifica\u00e7\u00e3o de dados ausentes em df_train**","e42b2d0b":"\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1537731%2Fa5fdbe17ca91e6713d2880887232c81a%2FScreen%20Shot%202019-12-09%20at%2011.25.31%20AM.png?generation=1575920121028151&alt=media)\n","8ff30f17":"# <a id='3'> 3. Visualiza\u00e7\u00e3o dos dados<\/a>","e96affa3":"## <a id='5-3-1'> 5.3.1 Exibindo mapas de componentes individuais<\/a>\nAl\u00e9m disso, podemos exibir separadamente cada um dos 53 mapas para obter uma vis\u00e3o mais completa\nda estrutura de componentes individuais.","accb8bce":"# <a id='2'> 2. Carregar dados <\/a>","f9c6b55a":"## <a id='2-1'> 2.2 Ler os dados<\/a>","968fc0a9":"![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1095143%2F47c74960e6540f11287e1e271438e029%2FTReNDS.png?generation=1587603283379241&alt=media)","9ae8511c":"O Tri-Institucional Universidade Estadual da Ge\u00f3rgia \/ Instituto de Tecnologia da Ge\u00f3rgia \/ Centro Emory University de Pesquisa Translacional em Neuroimagem e Ci\u00eancia de Dados (TReNDS) utiliza imagens avan\u00e7adas do c\u00e9rebro para promover pesquisas sobre a sa\u00fade do c\u00e9rebro. A organiza\u00e7\u00e3o est\u00e1 focada no desenvolvimento, aplica\u00e7\u00e3o e compartilhamento de abordagens anal\u00edticas avan\u00e7adas e ferramentas de neuroinform\u00e1tica. Entre seus projetos de software est\u00e3o as caixas de ferramentas de neuroimagem GIFT e FIT, o sistema de gerenciamento de dados COINS e o kit de ferramentas COINSTAC para aprendizado federado, todos destinados a apoiar cientistas de dados e outros pesquisadores de neuroimagem.\n\nDar o salto da pesquisa para a aplica\u00e7\u00e3o cl\u00ednica \u00e9 particularmente dif\u00edcil na sa\u00fade do c\u00e9rebro. Para traduzir para contextos cl\u00ednicos, os resultados da pesquisa devem ser reproduzidos de forma consistente e validados em casos fora da amostra. O problema \u00e9 particularmente adequado para a ci\u00eancia de dados, mas as abordagens atuais geralmente n\u00e3o se generalizam. Com esse grande conjunto de dados e competi\u00e7\u00e3o, seus esfor\u00e7os podem abordar diretamente uma \u00e1rea importante da pesquisa do c\u00e9rebro.","555306dd":"## <a id='3-2'> 3.2 Vis\u00e3o geral estat\u00edstica dos dados<\/a>","37167220":"## <a id='3-1'> 3.1 Vis\u00e3o geral das tabelas<\/a>","a7f45045":" # <a id='1'> 1. Introdu\u00e7\u00e3o <\/a>\nA pesquisa do c\u00e9rebro humano est\u00e1 entre as \u00e1reas de estudo mais complexas para os cientistas. Sabemos que a idade e outros fatores podem afetar sua fun\u00e7\u00e3o e estrutura, mas s\u00e3o necess\u00e1rias mais pesquisas sobre o que ocorre especificamente no c\u00e9rebro. Com grande parte da pesquisa usando exames de resson\u00e2ncia magn\u00e9tica, os cientistas de dados est\u00e3o bem posicionados para apoiar id\u00e9ias futuras. Em particular, especialistas em neuroimagem procuram marcadores mensur\u00e1veis \u200b\u200bde comportamento, sa\u00fade ou dist\u00farbio para ajudar a identificar regi\u00f5es cerebrais relevantes e sua contribui\u00e7\u00e3o para efeitos t\u00edpicos ou sintom\u00e1ticos.\n\n\nNesta competi\u00e7\u00e3o, voc\u00ea ir\u00e1 prever v\u00e1rias avalia\u00e7\u00f5es mais a idade dos recursos de resson\u00e2ncia magn\u00e9tica cerebral multimodal. Voc\u00ea estar\u00e1 trabalhando com os resultados existentes de outros cientistas de dados, realizando o importante trabalho de validar a utilidade dos recursos multimodais em uma popula\u00e7\u00e3o normativa de indiv\u00edduos n\u00e3o afetados. Devido \u00e0 complexidade do c\u00e9rebro e \u00e0s diferen\u00e7as entre os scanners, abordagens generalizadas ser\u00e3o essenciais para impulsionar efetivamente a pesquisa de neuroimagem multimodal adiante.","dde35054":"- <a href='#1'>1. Introdu\u00e7\u00e3o<\/a>  \n- <a href='#2'>2. Carregar dados<\/a>\n     - <a href='#2-1'>2.1 Carregar bibliotecas<\/a>\n     - <a href='#2-2'>2.2 Ler os dados<\/a>\n- <a href='#3'>3. Visualiza\u00e7\u00e3o dos dados<\/a>\n     - <a href='#3-1'>3.1 Vis\u00e3o geral das tabelas<\/a>\n     - <a href='#3-2'>3.2 Vis\u00e3o geral estat\u00edstica dos dados<\/a>\n- <a href='#4'>4. Verifica\u00e7\u00e3o de dados ausentes<\/a>\n- <a href='#5'>5. Explora\u00e7\u00e3o de dados<\/a>\n    - <a href='#5-1'>5.1 Distribui\u00e7\u00e3o de vari\u00e1veis de entrada em loading_data<\/a>\n    - <a href='#5-2'>5.2 Distribui\u00e7\u00e3o das vari\u00e1veis-alvo nos dados do treino<\/a>\n    - <a href='#5-3'>5.3 Explorar mapas espaciais de fMRI<\/a>\n        - <a href='5-3-1'> 5.3.1 Exibindo mapas de componentes individuais<\/a>\n- <a href='#6'>6. Amostras de envios (submissions)<\/a>\n    - <a href='#6-1'>6.1 Baseline submission<\/a>\n    - <a href='#6-2'>6.2 M\u00e9dia de submission<\/a>","91ba5090":"**df_train_data**\n> ##### Na verdade, s\u00e3o apenas os valores de destino para o conjunto de dados de treinamento. Os dados reais de treinamento est\u00e3o no carregamento de dados (parcialmente). Ent\u00e3o, vou me concentrar apenas nesse arquivo.","ac04d7f3":"**Vari\u00e1veis alvo**","97b81935":"## <a id='2-1'> 2.1 Carregar bibliotecas <\/a>","e3fc2898":"## <a id='5-1'> 5.1 Distribui\u00e7\u00e3o de vari\u00e1veis de entrada em loading_data<\/a>","4d55fbd3":"**Verifica\u00e7\u00e3o de dados ausentes em df_loading**"}}