{"cell_type":{"c898f89f":"code","53d57bc2":"code","19ccd6c8":"code","799fa51b":"code","2d1d88b4":"code","8d3f53e4":"code","d1722e90":"code","09f4d88b":"code","706096b9":"code","cbb45369":"code","205802da":"code","f54e7d95":"code","23003cd1":"code","87ad4be9":"code","d46b6b11":"code","d4fdfb7c":"code","82ca51c8":"code","f2c2e2a7":"code","37542879":"code","34cd902f":"code","0e4605a9":"markdown","05b9913e":"markdown","13441df5":"markdown","9377b7d8":"markdown","80c72a8c":"markdown","a269a9da":"markdown","6847143e":"markdown","7ceffd2b":"markdown","29813bba":"markdown","83d461af":"markdown","33984ab8":"markdown","aeede0df":"markdown","a3fb5c1d":"markdown","426a19b4":"markdown"},"source":{"c898f89f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n\n# Any results you write to the current directory are saved as output.","53d57bc2":"df_train = pd.read_csv('\/kaggle\/input\/equipfails\/equip_failures_training_set.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/equipfails\/equip_failures_test_set.csv')","19ccd6c8":"df = df_train.replace('na',np.nan)\ndft = df_test.replace('na', np.nan)","799fa51b":"non_hist = []\n\nlabels = df.columns[2:]\n\nfor l in labels:\n    if 'histogram' in l:\n        non_hist.append(l)\n    if (df[l].isna().sum()\/df.shape[0]*100) > 25:\n        df.drop(l, inplace=True, axis=1)\n        dft.drop(l, inplace=True, axis=1)\n        #print(l)\n    #print(l, df[l].isna().sum()\/df.shape[0]*100)\n\n","2d1d88b4":"df.drop(non_hist, inplace=True, axis=1)","8d3f53e4":"dft.drop(non_hist, inplace=True, axis=1)","d1722e90":"df.shape","09f4d88b":"# Class count\ncount_class_0, count_class_1 = df.target.value_counts()\n\n# Divide by class\ndf_class_0 = df[df['target'] == 0]\ndf_class_1 = df[df['target'] == 1]","706096b9":"\ndf_class_0_under = df_class_0.sample(count_class_1)\ndf_train_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\n#print('Random under-sampling:')\n#print(df_train_under.target.value_counts())\n\n#df_train_under.target.value_counts().plot(kind='bar', title='Count (target)');","cbb45369":"df_train_under.fillna(0, inplace=True)\n#df.fillna(0, inplace=True)\ndft.fillna(0, inplace=True)\n\n# Remove 'id' and 'target' columns\nlabels = df_train_under.columns[2:]\n#labels = df.columns[2:]\n\nX = df_train_under[labels]\n#X = df[labels]\ny = df_train_under['target']\n#y = df['target']\nXt = dft[labels]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","205802da":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(criterion='entropy', n_estimators=4000, random_state=12345, min_samples_leaf=2, min_samples_split=5, max_depth=150)\n\nclf.fit(X_train,y_train)","f54e7d95":"clf.predict(Xt)","23003cd1":"clf.predict_proba(Xt)","87ad4be9":"turnin = clf.predict(Xt)","d46b6b11":"dft['target'] = turnin","d4fdfb7c":"final = dft[['id','target']]","82ca51c8":"final.to_csv('output.csv', index=False)","f2c2e2a7":"import pickle\n\npickle.dump(clf, open('ensemble.pkl','wb'))","37542879":"def display_confusion(conf_mat):\n    if len(conf_mat) != 2:\n        raise RuntimeError(\"  Call to display_confustion invalid\"+\\\n           \" Argument is not a 2x2 Matrix.\")\n        sys.exit()\n    TP = int(conf_mat[1][1])\n    TN = int(conf_mat[0][0])\n    FP = int(conf_mat[0][1])\n    FN = int(conf_mat[1][0])\n    n_neg  = TN + FP\n    n_pos  = FN + TP\n    n_pneg = TN + FN\n    n_ppos = FP + TP\n    n_obs  = n_neg + n_pos\n    print(\"\\nModel Metrics\")\n    print(\"{:.<27s}{:10d}\".format('Observations', n_obs))\n    acc = np.nan\n    pre = np.nan\n    tpr = np.nan\n    tnr = np.nan\n    f1  = np.nan\n    misc = np.nan\n    miscc = [np.nan, np.nan]\n    if n_obs>0:\n        acc = (TP+TN)\/n_obs\n    print(\"{:.<27s}{:10.4f}\".format('Accuracy', acc))\n    if (TP+FP)>0:\n        pre = TP\/(TP+FP)\n    print(\"{:.<27s}{:10.4f}\".format('Precision', pre))\n    if (TP+FN)>0:\n        tpr = TP\/(TP+FN)\n    print(\"{:.<27s}{:10.4f}\".format('Recall (Sensitivity)', tpr))\n    if (TN+FP)>0:\n        tnr = TN\/(TN+FP)\n    print(\"{:.<27s}{:10.4f}\".format('Recall (Specificity)', tnr))\n    if (2*TP+FP+FN)>0:\n        f1 = 2*TP\/(2*TP + FP + FN)\n    print(\"{:.<27s}{:10.4f}\".format('F1-Score', f1))\n\n    if n_obs>0:\n        misc = 100*(FN + FP)\/n_obs\n    print(\"{:.<27s}{:9.1f}{:s}\".format(\\\n            'MISC (Misclassification)', misc, '%'))\n    if n_neg>0 and n_pos>0:\n        miscc = [100*conf_mat[0][1]\/n_neg, 100*conf_mat[1][0]\/n_pos]\n    lrcc  = [0, 1]\n    for i in range(2):\n        print(\"{:s}{:.<16.0f}{:>9.1f}{:<1s}\".format(\\\n              '     class ', lrcc[i], miscc[i], '%'))      \n\n    print(\"\\n\\n     Confusion\")\n    print(\"       Matrix    \", end=\"\")\n    for i in range(2):\n        print(\"{:>7s}{:<3.0f}\".format('Class ', lrcc[i]), end=\"\")\n    print(\"\")\n    for i in range(2):\n        print(\"{:s}{:.<6.0f}\".format('Class ', lrcc[i]), end=\"\")\n        for j in range(2):\n            print(\"{:>10d}\".format(int(conf_mat[i][j])), end=\"\")\n        print(\"\")\n         ","34cd902f":"from sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_true=y, y_pred=clf.predict(X))\nconf_train = confusion_matrix(y_true=y_train, y_pred=clf.predict(X_train))\nconf_test = confusion_matrix(y_true=y_test, y_pred=clf.predict(X_test))\ndisplay_confusion(conf_mat)\ndisplay_confusion(conf_train)\ndisplay_confusion(conf_test)","0e4605a9":"### Define a confusion matrix printing function\n\nCreated a confusion matrix printing function with f1 scores because that is the validation metric that is used in this particular type of problem.","05b9913e":"# Prediction Probability\n### We check the prediction probability to see how well it's determining failures... We might adjust the weighting or cutoff value of a classification if it's closer to a coin-flip than a higher confidence.","13441df5":"Save the model for production predictions.\n\nAfter storing the model in a pickle file, you can bring it back up in its currently trained state and use it in production.\n\nIt might be wise to create a feedback loop or a timed process that would recreate the model every evening with relevant data.","9377b7d8":"# ConocoPhillips \n Predicting surface and downhole equipment failures in a West Texas conventional field.\n \n A rare event classification problem.\n\n## Team Name: \n Pregler Mann\n## Members:\n Seth Pregler\n \n Craig Mann","80c72a8c":"Add the series to the test dataframe.","a269a9da":"## Sampling Technique\n\n#### To alleviate class imbalance which results in a serious bias towards the majority class and increases the number of false negatives, Under-Sampling is used, thus imroving precision and recall.\n","6847143e":"## Final Thoughts\n\n#### Having temporal data could lead to better predictions via higher sampling of the data leading up to an equipment failure vs randomly sampling from the entire set\n\n## Things we could have done but didn't have time for...\n\nThere was potentially an opportunity to figure out the histogram data, however we opted to drop it outright with other columns that were greater than 25% missing values.  We think that if we were able to turn the histogram into a vector of some sort and use that as a variable, that might have made it score better in the holdout set.","7ceffd2b":"## Model Selection\n\n#### Random Forest Classification chosen because ensemble model is more robust, a large number of trees operating in a forest will outperform any of the individual constituent models.\n\nIn another kernel, we also tested a GridSearch cross validation with many parameters that took too long to run, so we took the results from that grid search and applied it to our RandomForestClassifier.\n\nBetween criterion['gini','entropy'], n_estimators [300,500,1000,4000], min_samples_split [2,3,4,5,6], min_samples_leaf [2,3,4,5], test_size [0.2,0.3], we ended up with the parameters below.","29813bba":"## Read in Data\n\n#### We read in both of the data sets to prepare for the ","83d461af":"Output the predicted targets to a csv for submission in the competition.","33984ab8":"### Print Results\n\nVisualize the results in a printed output to validate the model and see what might need to improve.","aeede0df":"# Visualize\n\n### Take a quick look to check that the predictions are looking okay.","a3fb5c1d":"Add predictions to a series to join to the test set dataframe.","426a19b4":"Create a final dataframe with the format required for submission."}}