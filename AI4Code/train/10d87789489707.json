{"cell_type":{"c55cd939":"code","87e22e51":"code","a06d64f3":"code","d846ed38":"code","c02de20c":"code","f993a8d2":"code","1b08b2a9":"code","fdd11799":"code","1c9d7c83":"code","04e144e1":"code","74222f56":"code","23fb5582":"code","4336767f":"code","ed5f2b13":"code","53893ed5":"code","0797a203":"code","85909c01":"code","ff13ff24":"code","2ebb8b37":"code","60aa9eff":"code","bd8e5b6b":"code","9954506f":"code","d1960856":"code","4f2feed9":"code","c0b0c993":"code","cf00d871":"code","7aed9397":"code","6f71eee0":"code","ce7f45aa":"code","20e4e3f2":"code","0d8ae4db":"code","74d9a92d":"code","44ea9409":"code","1a0a77ce":"code","6f480374":"code","b5a5805c":"code","8c8ca1b6":"code","43199c78":"markdown","14eebc6b":"markdown","64110d5d":"markdown","8dcd8c7f":"markdown","83a192e2":"markdown","c1a80673":"markdown","8b9d86bc":"markdown","b34cb702":"markdown","fa731899":"markdown","dac1b9f1":"markdown","8e2020d2":"markdown","1eb2c23c":"markdown"},"source":{"c55cd939":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom pandas_profiling import ProfileReport\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier","87e22e51":"data=pd.read_csv(\"..\/input\/mushroom-classification-updated-dataset\/mushroomsupdated.csv\")\ndata.head()","a06d64f3":"data.shape","d846ed38":"list(data.columns)","c02de20c":"data.isnull().sum()","f993a8d2":"for i in data.columns:\n  print(i, data[i].unique())","1b08b2a9":"# In the results, we notice that there is an unknown value called \u201cc\u201d, and I do not know to what basis it belongs.\ndata['cap-shape'].value_counts()    ","fdd11799":"# What does \"non\" mean? Does it denote a missing or empty value or that there is no biological loop? There is no reliable source, my friend.\ndata[\"ring-number\"].value_counts()","1c9d7c83":"# What does the question mark indicate? It is clear that it is influential because it is spread in a not small percentage in the data.\ndata[\"stalk-root\"].value_counts()","04e144e1":"# same thing \ndata[\"ring-type\"].value_counts()","74222f56":"profile=ProfileReport(data, title=\"Mushroom Dataset Report\")\nprofile","23fb5582":"object_1=LabelEncoder()\n# During the conversion process, we used the first projection.\nfor i in data.columns:\n    data[i] = object_1.fit_transform(data[i])","4336767f":"data.head()","ed5f2b13":"for i in data.columns:\n  print(i, data[i].unique())","53893ed5":"plt.hist(data[\"class\"])\nplt.show() ","0797a203":"msno.matrix(data)","85909c01":"# Here we have deleted one of the columns that has no connection with the rest of the data.\ndata.drop(['veil-type'], axis=1, inplace=True)\n# Now we will draw a heat map.\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)\nplt.show()\n","ff13ff24":"corr_1=data.corr()\nmost_effect=corr_1.nlargest(10,\"class\")\nmost_effect","2ebb8b37":"sns.scatterplot(x='cap-shape', y='cap-surface', data=data)","60aa9eff":"data.hist(figsize=(18,10))\nplt.show()","bd8e5b6b":"most_effect.hist(figsize=(18,10))\nplt.show()","9954506f":"sns.distplot(data['cap-shape'], color = 'b', label = 'Solids')","d1960856":"target= data[\"class\"].values\nfeature= data.drop([\"class\"],axis=1)","4f2feed9":"scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(feature)","c0b0c993":"x_train, x_test, y_train, y_test = train_test_split(X,target, test_size=0.2, random_state=11)","cf00d871":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","7aed9397":"SVCModel=SVC(C=0.5, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True,\n                probability=False, tol=0.001, cache_size=101, class_weight=None,verbose=False,\n                max_iter=-1, decision_function_shape='ovr', random_state=0)\nSVCModel.fit(x_train, y_train)\n","6f71eee0":"#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(x_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(x_test, y_test))\n#Calculating Prediction\ny_pred = SVCModel.predict(x_test)\nprint('Predicted Value for SVCModel is : ' , y_pred[:20])\nprint(\"target values y_test........ is : \" , y_test[:20])","ce7f45aa":"#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()","20e4e3f2":"DecisionTreeClassifierModel=DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5,min_samples_split=5,\n                                    min_samples_leaf=3,max_features=None,\n                                    random_state=0, max_leaf_nodes=3)\nDecisionTreeClassifierModel.fit(x_train, y_train)","0d8ae4db":"#Calculating Details\nprint('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(x_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(x_test, y_test))\nprint('DecisionTreeClassifierModel Classes are : ' , DecisionTreeClassifierModel.classes_)\nprint('DecisionTreeClassifierModel feature importances are : ' , DecisionTreeClassifierModel.feature_importances_)\n","74d9a92d":"#Calculating Prediction\ny_pred = DecisionTreeClassifierModel.predict(x_test)\ny_pred_prob = DecisionTreeClassifierModel.predict_proba(x_test)\nprint('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:10])\nprint(\"real values of y_test                           is : \" , y_test[:10] )\nprint('Prediction Probabilities Value for DecisionTreeClassifierModel is : ' , y_pred_prob[:10])\n","44ea9409":"#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n ","1a0a77ce":"RandomForestClassifierModel=RandomForestClassifier(n_estimators=30, criterion='gini', max_depth=7,\n                                min_samples_split=3, min_samples_leaf=1,min_weight_fraction_leaf=0.0,\n                                max_features='auto',max_leaf_nodes=7,min_impurity_decrease=0.0,\n                                min_impurity_split=None, bootstrap=True,oob_score=False, n_jobs=1,\n                                random_state=0)\nRandomForestClassifierModel.fit(x_train, y_train)\n","6f480374":"#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(x_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(x_test, y_test))\nprint('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)\n","b5a5805c":"#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(x_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(x_test)\nprint('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\nprint(\"real values of target colunm y_test             is : \" , y_test[:10])\nprint('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])\n","8c8ca1b6":"#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n ","43199c78":"<h1 align=\"center\"> Mushroom Dataset Classification with ML<\/h1>\n<center><img src=\"https:\/\/drugsandbadideas.com\/images\/articles\/intros\/sacred-magic-mushroom-tea.jpg\" width=\"60%\" >\n","14eebc6b":"> **In order to get more details about the data, we call one of the powerful functions.**","64110d5d":"**In that software page, we will try to deal with the data that we have in several ways, and as soon as one of the methods succeeds, we will succeed.**\n> **This data I have dealt with before, but the first time I used deep learning so this time I will try several algorithms from machine learning with it.\nLet's continue.......**","8dcd8c7f":"We have now finished putting some algorithms in machine learning, some of them are good algorithms and some are good algorithms to some extent.\n> Of course, we could have improved the results we obtained, but with the success of some algorithm in reaching high rates, it is okay.","83a192e2":"# Read our data","c1a80673":"> **The previous charts show \/ confirm what we obtained in the previous report.**","8b9d86bc":"# Now let's start with the data partitioning process","b34cb702":"One of the sweet things that we have is to keep the data as it is and start the process of transformation and data processing in order to enter into the algorithms.","fa731899":"Previous code prompts us to take faster steps in dealing with data","dac1b9f1":"# In the end, thank you for your time, and if you have any modification or suggestion let me know, bye.","8e2020d2":"**The results we obtained from the decision tree algorithm were not good.**","1eb2c23c":"> **In the random jungle algorithm, we obtained reasonable and very good accuracy, far from overfitting.**"}}