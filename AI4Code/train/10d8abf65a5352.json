{"cell_type":{"9b43c91e":"code","ecc01cac":"code","bbcbd484":"code","8ef08df1":"code","aa0332b0":"code","b4491708":"code","c1278070":"code","53021344":"code","0c1a904c":"code","494c1780":"code","466df1fa":"code","c13dc22f":"code","2c745370":"code","17099d8b":"code","3d557b65":"code","0d85374c":"code","5bcc8797":"code","fbea91c3":"code","c1f4eb93":"code","9ee168a4":"code","f3b5b15c":"code","5c72f00c":"code","9870124a":"code","059f361b":"code","982cc043":"markdown","b773cb4a":"markdown","6763c529":"markdown","8875d135":"markdown","bea580e5":"markdown","664e487e":"markdown","a57a9da1":"markdown","88d532dc":"markdown","d45d1260":"markdown","8c2fd735":"markdown","57bf238f":"markdown","2af8faa3":"markdown","05d679bc":"markdown","817bc9d5":"markdown","64fe3d28":"markdown","f8394857":"markdown","eb27cbab":"markdown","4b1e2f9f":"markdown","132736b2":"markdown","051db4f9":"markdown","3043826d":"markdown","79c78a8f":"markdown","1a5ac133":"markdown","1eda7574":"markdown","5c67936a":"markdown","5f32819e":"markdown"},"source":{"9b43c91e":"pip install vaderSentiment","ecc01cac":"#After the successful installation of vaderSentiment, call the SentimentIntensityAnalyser object.\n\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\n#Let us analyze some statements using VADER now. We are using the polarity_scores() method to calculate the sentiment score for given sentences.\n\nanalyser.polarity_scores(\"I am getting bored in the quarantine.\")\n\n#You see the output like in the form of a dictionary,","bbcbd484":"pip install tweepy","8ef08df1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport time\nimport tweepy\nimport re","aa0332b0":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()","b4491708":"consumer_key = \"YOUR KEY HERE.\"\nconsumer_secret = \"YOUR KEY HERE.\"\naccess_key = \"YOUR KEY HERE.\"\naccess_secret = \"YOUR KEY HERE.\"\n\ndef initialize():\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_key, access_secret)\n    api = tweepy.API(auth, parser = tweepy.parsers.JSONParser())\n    return api\n\napi = initialize()","c1278070":"comp_searches = (\"@Google\", \"@IBM\", \"@Microsoft\", \"@Tesla\", \"@amazon\")","53021344":"# Array to hold sentiment\nsentiments = []\n\n# Iterate through all the comp_searches\nfor search in comp_searches:\n       \n    # Bring out the 100 tweets\n    comp_tweets = api.user_timeline(search, count=100)\n    \n    # Loop through the 100 tweets\n    for tweet in comp_tweets:\n        text = tweet[\"text\"]\n        \n     # Add each value to the appropriate array\n        sentiments.append({\"User\": search,\n                           \"text\":text,\n                       \"Date\": tweet[\"created_at\"] \n                        })\n    \n    ","0c1a904c":"#convert array to dataframe\ndf = pd.DataFrame.from_dict(sentiments)\ndf.head(10)\n#df.shape","494c1780":"#to see tweets for specific User name \ndf_tesla = df[ df['User'] == '@Tesla']\ndf_tesla.head()","466df1fa":"#cleaning the tweets\n\ndef remove_pattern(input_txt, pattern):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, '', input_txt)        \n    return input_txt\n\ndef clean_tweets(tweets):\n    # remove twitter Return handles (RT @xxx:)\n    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n    \n    # remove twitter handles (@xxx)\n    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n    \n    # remove URL links (httpxxx)\n    tweets = np.vectorize(remove_pattern)(tweets, \"https?:\/\/[A-Za-z0-9.\/]*\")\n    \n    # remove special characters, numbers, punctuations (except for #)\n    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n    \n    return tweets","c13dc22f":"df['text'] = clean_tweets(df['text'])\ndf['text'].head()","2c745370":"scores = []\n\n# Declare variables for scores\ncompound_list = []\npositive_list = []\nnegative_list = []\nneutral_list = []\n\nfor i in range(df['text'].shape[0]):\n    #print(analyser.polarity_scores(sentiments_pd['text'][i]))\n    compound = analyzer.polarity_scores(df['text'][i])[\"compound\"]\n    pos = analyzer.polarity_scores(df['text'][i])[\"pos\"]\n    neu = analyzer.polarity_scores(df['text'][i])[\"neu\"]\n    neg = analyzer.polarity_scores(df['text'][i])[\"neg\"]\n    \n    scores.append({\"Compound\": compound,\n                       \"Positive\": pos,\n                       \"Negative\": neg,\n                       \"Neutral\": neu\n                  })","17099d8b":"sentiments_score = pd.DataFrame.from_dict(scores)\ndf = df.join(sentiments_score)","3d557b65":"df.head(10)","0d85374c":"#Collect the compound values for each news source\nscore_table = df.pivot_table(index='User',  values=\"Compound\", aggfunc=np.mean)\nscore_table","5bcc8797":"sns.barplot(x='User', y='Compound', data=df)","fbea91c3":"#Collect the compound values for each news source\nneg_score_table = df.pivot_table(index='User',  values=\"Negative\", aggfunc=np.mean)\nneg_score_table","c1f4eb93":"sns.barplot(x='User', y='Negative', data=df)","9ee168a4":"HT_positive = []\ndef hashtag_extract(x):\n    hashtags = []\n    # Loop over the words in the tweet\n    for i in x:\n        ht = re.findall(r\"#(\\w+)\", i)\n        hashtags.append(ht)\n    return hashtags\n# extracting hashtags from positive tweetsHT_positive = hashtag_extract(df_tws['text'][df_tws['sent'] == 1])\n# extracting hashtags from  tweets\nHT_positive = hashtag_extract(df['text'][df['Compound'] > 0.5])\n#Just to see the closest tweets near negative category\nHT_negative = hashtag_extract(df['text'][df['Compound'] < -0.1])\n# unnesting list\nHT_positive = sum(HT_positive,[])","f3b5b15c":"HT_positive","5c72f00c":"HT_negative = sum(HT_negative,[])\nHT_negative","9870124a":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\ndef word_cloud(wd_list):\n    stopwords = set(STOPWORDS)\n    all_words = ' '.join([text for text in wd_list])\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        width=1600,\n        height=800,\n        random_state=1,\n        colormap=\"Oranges_r\",\n        max_words=80,\n        max_font_size=200).generate(all_words)\n                \n    plt.figure(figsize=(12, 10))\n    plt.axis('off')\n    plt.imshow(wordcloud, interpolation=\"bilinear\");","059f361b":"word_cloud(df['text'])","982cc043":"**Now looking for the organization who posted a maximum number of negative tweets,**","b773cb4a":"**If you want to see the tweets from a specific user, you can write the above code and get it.**","6763c529":"**Whenever a user wants to share his opinion regarding any trending topic on social media, we try to find the sentiment score of that expressed opinion using sentiment analysis. Twitter is the most widely used micro-blogging social media platform, having nearly 145 million daily active users. Nowadays, the user posts the tweets using hashtags, emoticons, abbreviations, and puns, which gets challenging to analyze the tweet and formulate sentiment scores.**","8875d135":"* By analyzing the output above, we can state that our given statement is 74% neutral, 26% negative, and 0%positive. On the overall, our statement falls under the neutral category.\n\n* The Compound score is a metric that has been scaled between -1 as the most extreme negative score and +1 as the most extreme positive score. You can refer to the compound score methodology below.","bea580e5":"![Compound Score methodology](https:\/\/miro.medium.com\/max\/1166\/0*pXbijuZ7--OdVSgn.png)","664e487e":"**Converting the scores dictionary containing the scores into the data frame, then join the sentiments_score data frame with the df data frame.**","a57a9da1":"# Plotting Wordcloud\n**Wordcloud is used to display the keywords that are most actively present in your document or text dataset. Wordcloud is the informative visual representation of text datasets, highlighting the most popular and trending keywords in text datasets based on the frequency of occurrence and importance.\nFrom above wordcloud Tesla, Thank, Hi, happy, help, see, let are the words that appear in most frequent time in the tweets dataset.**","88d532dc":"# VADER Installation\n\nWe install Vader by using pip command:","d45d1260":"# What is Tweepy?\n\n**Tweepy is the most easy-to-use Python library for accessing the functionalities provided by the Twitter API.**\n\nThe simplest way to install tweepy is to use pip command:\n","8c2fd735":"**After getting authorization, we are ready to pull out the tweets. But before that, we have to define the competitor searches. As I told you, this twitters sentimental analysis model is for the market research purpose, so we have to take the global organizations in the information technology field. Here for evaluation, I took five global organizations, namely as Google, IBM, Microsoft, Tesla, and Amazon. These organizations continuously update their followers about their latest products and services in the world. So this is the best way to analyze their tweets and gather some meaningful insights using VADER.**","57bf238f":"# References:\n1. [Twitter Sentiment Analysis using Vader & Tweepy](https:\/\/medium.com\/python-in-plain-english\/twitter-sentiment-analysis-using-vader-tweepy-b2a62fba151e)\n2. [VADER-Sentiment-Analysis](https:\/\/github.com\/cjhutto\/vaderSentiment#about-the-scoring)\n3. [Comprehensive Hands on Guide to Twitter Sentiment Analysis with dataset and code.](https:\/\/www.analyticsvidhya.com\/blog\/2018\/07\/hands-on-sentiment-analysis-dataset-python\/)","2af8faa3":"> Now, after defining organizations, we are ready to extract the tweets. From the below code, we are extracting 100 tweets from each organization twitter feed.","05d679bc":"From this plot, you can visualize the overall sentiments of the latest 100 tweets from each organization. @amazon has the highest compound score among these five organizations so you can analyze that total tweets posted by this organization are mostly positive.\n# Polarity_score Visualization\nLet's look at the bar-plot for the overall sentiment analysis for tweets,","817bc9d5":"# Getting Credentials\n\nNow to extract the tweets from twitter, we need to fill the consumer_key, consumer_secret, access_key, and access_secret as I told you earlier how to create an app and obtain these credentials in Authentication.","64fe3d28":"# Cleaning the twitter data\n\nWell, we fetched real-time tweets from twitter, but now we have to extract meaningful insights from the tweet\u2019s data. For that, we have to clean data because it contains lots of URLs, numbers, and user_ids, which get challenging to analyze tweets.","f8394857":"**Finding scores for tweets\nNow, using polarity_scores() we, will find all the positive, negative, and neutral scores for each tweet.**","eb27cbab":"**In this notebook, I tried to perform Vader sentiment analysis along with tweepy on twitter data, which is a Python-based approach. This twitter sentiment analysis is basically for the market research, how it is ? you will get when you read it thoroughly.**\n\n**Look at my medium article [here.](https:\/\/medium.com\/python-in-plain-english\/twitter-sentiment-analysis-using-vader-tweepy-b2a62fba151e)**\n","4b1e2f9f":"For fetching the real-time data from twitter, the sentiment model must require all requests to use OAuth for Authentication. Tweepy provides functionalities in a more straightforward way for Authentication. To design the VADER sentiment model, we need to register our client application with Twitter. If you are not aware of it then no problem, follow the below authentication process.\n\n# Authentication:\n\n* Open https:\/\/developer.twitter.com\/apps and click on the button: \u2018Create New App.\u2019\n* Fill all the required application details.\n* Once the app is created, you will be redirected to the app page.\n* Open the \u2018Keys and Access Tokens\u2019 tab.\n* Copy \u2018Consumer Key\u2019, \u2018Consumer Secret\u2019, \u2018Access token\u2019, and \u2018Access Token Secret\u2019.\n* You can also regenerate Key, and Token clicked on the Regenerate button.\n\nOnce Tweepy is installed, and the twitter client app is registered, let\u2019s get the hands dirty.\n\n**Importing necessary libraries**\n\nWe have to import all the required libraries. I hope that you are fully aware of the python necessary libraries required for data collection, data preprocessing work like Pandas, NumPy, Matplotlib.","132736b2":"**Now you can see the scores associated with the respective tweets and analyze where the tweet is positive, neutral, or negative.**\n\n# Collecting Hashtags\nNow we have to collect the positive hashtags from the tweets data.","051db4f9":"**If you find it useful for a beginner then please upvote it and share with your tech-circle.**","3043826d":"> We stored all the tweets in sentiments dictionary along with User and date when the tweet get posted.\n\nAs the tweets data is in the dictionary, we convert it into a data frame for further processing. Now you can see the data pulled out from twitter with tweets, User along with post-date.","79c78a8f":"# Conclusion\n* Using VADER sentiment analysis, the derived outcomes helps us to understand the opinions of the users and classify them in positive, negative, neutral category according to the formulated sentiment scores. For the social media type text data, performing sentimental analysis using VADER is quite an exciting task to accomplish.\n\n* To understand the emotions or opinions of the customers regarding any company\u2019s product or services and to maintain the branding in the market, sentimental analysis is necessary.","1a5ac133":"# Beginner's guide to Twitter Sentiment Analysis for Market Research using VaderSentiment and tweepy.","1eda7574":"# Observations\n* All organization's (Google, IBM, Microsoft, Tesla, Amazon) posted tweets are predicted as positive.\n* Among the positive tweets, @amazon has the highest compound score, while @Tesla has the least positive score.\n* Considering negative tweets, @Microsoft posted the most number of negative tweets, and @IBM has a less negative score.","5c67936a":"# Pivot table design\nWe design a pivot table for evaluating the mean compound score of all the organization\u2019s tweets, and you can see the result also.","5f32819e":"**What is VADER?**\n\nVADER stands for Valence Aware Dictionary and sEntiment Reasoner. Vader performs well for the analysis of sentiments expressed in social media. These sentiments must be present in the form of comments, tweets, retweets, or post descriptions, and it works well on texts from other domains also.VADER is a lexicon and rule-based analysis tool.\nThere are different types of sentiment analysis techniques available for extracting meaning insights from the text data, but the VADER sentiment performs well mainly on social media data. Later on, we design our VADER sentiment model, which extracts features from twitter data, formulate the sentiment score, and classifies them in positive, negative, neutral classes."}}