{"cell_type":{"489745d9":"code","2828a3e2":"code","fcac894b":"code","44e0d8f0":"code","8e001ffb":"code","f540d0a2":"code","167d495a":"code","ce6190b9":"code","020ecf8c":"code","30f69cde":"code","23eedec9":"code","a1add70f":"code","25f878dd":"code","39d6708f":"code","874bd083":"code","27e8e4d3":"code","05bc8f8e":"markdown","0851b84a":"markdown","36895e54":"markdown","a00381b1":"markdown","28b3d1f5":"markdown","e04a2f05":"markdown"},"source":{"489745d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2828a3e2":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity=\"all\"\nimport matplotlib.pyplot as plt\nimport datetime as dt\nfrom datetime import date, timedelta","fcac894b":"df=pd.read_csv(\"\/kaggle\/input\/home-credit\/application_train.csv\")","44e0d8f0":"def MemoryManagement(df):\n    '''This function saves memory by converting & allocating datatype required for each column data.'''\n    print(\"Shape of data set\", df.shape)\n    Initial_Memory= df.memory_usage().sum() \/(1024*1024)\n    print (\"Intial memory of the dataset in MB\",df.memory_usage().sum() \/(1024*1024))\n\n    for i in df.describe().columns:\n        if str(df[i].dtypes)[0:3]=='int':\n            if df[i].max()<np.iinfo('int8').max:\n                df[i]= df[i].astype('int8') ### one form of datatype to other\n            elif df[i].max()<np.iinfo('int16').max:\n                df[i]= df[i].astype('int16')\n            elif df[i].max()<np.iinfo('int32').max:\n                df[i]= df[i].astype('int32')\n        else:\n            if df[i].max()<np.finfo('float16').max:\n                df[i]= df[i].astype('float16') ### one form of datatype to other\n            elif df[i].max()<np.finfo('float32').max:\n                df[i]= df[i].astype('float32')\n            elif df[i].max()<np.finfo('float64').max:\n                df[i]= df[i].astype('float64')\n\n    print (\"After processing memory of the dataset in MB\",df.memory_usage().sum() \/(1024*1024))\n    new_memory =df.memory_usage().sum() \/(1024*1024)\n    print(\"Memory Saved: \",((Initial_Memory-new_memory)\/Initial_Memory)*100)\n\n    \ndef GarbageValueRemoval(df):\n    '''This function to remove garbage value from dataset.'''\n    for i in df.columns:\n        df[i].replace(regex=True, to_replace=r'[^0-9a-zA-Z.\\-]',value=r'', inplace=True) #remove special Char\n        df[i].replace(regex=True,to_replace=r'^\\s*$', value=np.nan, inplace=True)        #replace empty with NAN\n\ndef ColumnTypeIdentification(df,threshold=33):\n    '''This function to segregate numeric & char columns and furher segregate into continuous and descrete based upon given theshold.'''\n    import pandas as pd\n    #Numerical columns\n    numerical_columns=df.describe().columns\n    print('Numerical Columns:\\n', numerical_columns)\n    \n    # Charecter Columns\n    char_columns=df.describe(include='object').columns\n    print('Charecter Columns:\\n', char_columns)\n    \n    print('Length of numerical columns: ', len(numerical_columns))\n    print('Length of charecter columns: ', len(char_columns))\n    \n    # Making all the values as pandas table\n    table_information_numerical=[]\n    for i in df[numerical_columns]:\n        table_information_numerical.append([i,df[i].nunique()])\n    table_information_char=[]\n    for i in df[char_columns]:\n        table_information_char.append([i,df[i].nunique()])\n    \n    table_information_numerical=pd.DataFrame(table_information_numerical)\n    table_information_char=pd.DataFrame(table_information_char)\n\n    \n    # Sperarating numerical continuous columns\n    numerical_cont=table_information_numerical[table_information_numerical[1]>threshold][0].values\n    print('Total numerical continuous columns: ', len(numerical_cont))\n    print(numerical_cont)\n    \n    # Separating numerical class columns\n    numerical_class=table_information_numerical[table_information_numerical[1]<=threshold][0].values\n    print('Total numerical class columns: ', len(numerical_class))\n    print(numerical_class)\n    \n    # Sperarating categorical continuous columns\n    categorical_cont=table_information_char[table_information_char[1]>threshold][0].values\n    print('Total categorical continuous columns: ', len(categorical_cont))\n    print(categorical_cont)\n    \n    # Separating categorical descrete columns\n    categorical_class=table_information_char[table_information_char[1]<=threshold][0].values\n    print('Total categorical class columns: ', len(categorical_class))\n    print(categorical_class)\n    \n    return numerical_cont, numerical_class, categorical_cont, categorical_class\n\n\n","8e001ffb":"def NullValueTreatment(df,threshold=30):\n    '''This function is to revmoe or null values from data set'''\n    print(\"Null columns before treatment: \", df.isna().sum().sum())\n    \n    #Count the null value for each column\n    null_value_cnt=df.isna().sum()\n    \n    #Seperate the non null value columns and null value columns\n    null_columns=null_value_cnt[null_value_cnt>0]\n    non_null_columns=null_value_cnt[null_value_cnt==0]\n    \n    null_value_percent=(null_columns\/df.shape[0])*100\n    \n    retain_null_col=null_value_percent[null_value_percent<threshold].index\n    drop_null_col=null_value_percent[null_value_percent>=threshold].index\n\n    print('Retainable Columns',retain_null_col.shape[0])\n    print('Dropable Columns',drop_null_col.shape[0])\n    \n    df.drop(drop_null_col,axis=1,inplace=True)\n    \n    # Seperate the Discrete and Continuous columns within numeric and char\n    numerical_cont, numerical_class, categorical_cont, categorical_class = ColumnTypeIdentification(df,33)\n    \n    for i in categorical_class:\n        df[i].fillna(df[i].mode().values[0],inplace=True)\n    for i in numerical_cont:\n        df[i].fillna(df[i].median(),inplace=True)\n    for i in numerical_class:\n        df[i].fillna(df[i].mode().values[0],inplace=True)\n    for i in categorical_cont:\n        df[i].fillna(df[i].mode().values[0],inplace=True)\n        \n    print(\"Null columns after treatment: \", df.isna().sum().sum())\n\n","f540d0a2":"def OutliersTreatment(df):\n    '''This function is to remove outliers from the data'''\n    for i in df.describe().columns:\n        Q1=df.describe().at['25%',i]\n        Q3=df.describe().at['75%',i]\n        IQR=Q3 - Q1\n        LTV=Q1 - 1.5 * IQR\n        UTV=Q3 + 1.5 * IQR\n        x=np.array(df[i])\n        p=[]\n        for j in x:\n            if j < LTV or j>UTV:\n                p.append(df[i].median())\n            else:\n                p.append(j)\n        df[i]=p\n    ","167d495a":"\ndef StandardScaling(df):\n    '''This function is to apply Standard Scalar on the given data and return scaled dataset'''\n    from sklearn.preprocessing import StandardScaler\n    for i in df.columns:\n        le=StandardScaler()\n        le.fit(df[i].values.reshape(-1, 1))\n        x=le.transform(df[i].values.reshape(-1, 1))\n        df[i]=x\n    return df\n\n\n# In[50]:\n\n\ndef MinMaxScaling(df):\n    '''This function is to apply Standard Scalar on the given data and return scaled dataset'''\n    from sklearn.preprocessing import MinMaxScaler\n    for i in df.columns:\n        le=MinMaxScaler()\n        le.fit(df[i].values.reshape(-1, 1))\n        x=le.transform(df[i].values.reshape(-1, 1))\n        df[i]=x\n    return df","ce6190b9":"\ndef UnivariateVisual(df,cont):\n    '''This function is to plot histogram for contenuous column'''\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    for i in cont:\n        plt.figure(figsize=(20,5))\n        sns.distplot(df[i],kde=False)\n        #plt.savefig(i+'plot.png') \n    return plt\n\n\n\n\n\ndef ContenuousBivariateVisual(df,cont):\n    '''This function is plot scatter plot between two contenuous columns'''\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    for i in cont:\n        for j in cont:\n            plt.figure(figsize=(20,5))\n            sns.scatterplot(df[i], df[j])\n            plt.xlabel(i)\n            plt.ylabel(j)\n    return plt\n       \n\n\n\n\ndef ContDescBivariateVisual(df,cont,desc):\n    '''This function is plot box plot between one and one descrete contenuous columns'''\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    for i in cont:\n        for j in desc:\n            plt.figure(figsize=(20,5))\n            sns.boxplot(df[i], df[j])\n            plt.xlabel(i)\n            plt.ylabel(j)\n    return plt\n       \n","020ecf8c":"df.head()","30f69cde":"MemoryManagement(df)","23eedec9":"df.head()","a1add70f":"numerical_cont, numerical_class, categorical_cont, categorical_class = ColumnTypeIdentification(df)","25f878dd":"numerical_cont\nnumerical_class\ncategorical_cont\ncategorical_class","39d6708f":"df['ORGANIZATION_TYPE'].unique()\n","874bd083":"UnivariateVisual(df,numerical_cont)","27e8e4d3":"d","05bc8f8e":"Iterpretation: \n* Only orgnization type is categorical continues column has 58 unique values. This can used to forecast customer belongs to organization who can repay the loan.\n* This column needs to converted using label encoder to make it numeric for better visualization.","0851b84a":"### Contenuos columns plotting ****","36895e54":"#### First display some data from dataset and idetify columns types","a00381b1":"#### Steps to perform EDA before preprocessing ","28b3d1f5":"#### Visualization Functions","e04a2f05":"#### Functions for EDA & Preprocessing"}}