{"cell_type":{"adf1b15c":"code","a2e2c1a7":"code","432a84b4":"code","c23521ca":"code","c27726c6":"code","1ff8d945":"code","2c1b2848":"code","0b8386c2":"code","83b52a7b":"code","aaaf1dd0":"code","695fb9b3":"code","3b3412d0":"markdown","9e502575":"markdown","88fef054":"markdown","db2b6ade":"markdown","bd1f2d40":"markdown","453bc5dd":"markdown","912e4d7f":"markdown","120c5eba":"markdown","b650c2ac":"markdown","ebf9df14":"markdown","5cf17bd7":"markdown","6543aee9":"markdown","40f09e9c":"markdown"},"source":{"adf1b15c":"import numpy as np\na = np.array([[1,2,3],[4,5,6]])\nprint(\"a:\\n{}\".format(a))","a2e2c1a7":"from scipy import sparse\n#eye function makes diagonal value 1 and others 0\ndia1 = np.eye(4)\nprint(\"Numpy Array:\\n\",dia1)\n#find the index of non zero values by using csr\nspaMat = sparse.csr_matrix(dia1)\nprint(\"Scipy sparse CSR matrix:\\n\",spaMat)","432a84b4":"import matplotlib.pyplot as plt\nx = np.linspace(-10,10,100) #-10 to 10 and 100 = total points in between\ny = np.sin(x)\nplt.plot(x,y,marker='+')","c23521ca":"import pandas as pd\n#dataset\nds = {\n    'Name': ['Rodrygo', 'Kroos', 'Valverde', 'Isco'],\n    'Location': ['Brazil', 'Germany', 'Uruguay', 'Spain'],\n    'Age': ['18', '30', '21','28']\n}\ndf = pd.DataFrame(ds)\ndisplay(df) #display all the data\ndisplay(df[df.Name =='Isco']) #select the specific one","c27726c6":"from sklearn.datasets import load_iris\niris_dataset = load_iris()\nprint(\"Keys:\\n\",iris_dataset.keys())\nprint(\"\\nFeature Names:\\n\",iris_dataset['feature_names'][:193])\nprint(\"\\nTarget Names:\\n\",iris_dataset['target_names'])\nprint(\"\\nData Shape:\\n\",iris_dataset['data'].shape)\nprint(\"\\nData(first five cloumns):\\n\",iris_dataset['data'][:5])\nprint(\"\\nTarget:\\n\",iris_dataset['target'])","1ff8d945":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)\nprint(\"X train shape:\\n\", X_train.shape)\nprint(\"y train:\\n\", y_train[:5])","2c1b2848":"!pip install mglearn","0b8386c2":"from pandas.plotting import scatter_matrix\nimport mglearn \nirisdf = pd.DataFrame(X_train, columns= iris_dataset.feature_names)\n#display(X_train[:5])\n#display(irisdf)\n# create a scatter matrix\ngr = scatter_matrix(irisdf, c=y_train, marker='o',figsize=(15,15),hist_kwds={'bins':20},s=60, alpha=.8, cmap=mglearn.cm3)","83b52a7b":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 1)\nknn.fit(X_train, y_train)","aaaf1dd0":"#create a new data with np array\nX_new = np.array([[8,4.5, 4, 4.8]]) #scikit always expect 2d array\nprint(\"Shape of new data: \",X_new.shape)\n#make a prediction for this new data\nprediction = knn.predict(X_new)\nprint(\"This is the data of-\",iris_dataset['target_names'][prediction])","695fb9b3":"y_pred = knn.predict(X_test)\nprint(iris_dataset['target_names'][y_pred])\nprint(\"test data accuracy: \",np.mean(y_pred==y_test))","3b3412d0":"**KNN model**\n\n---\n<p align = 'justify'>\nWe have just started. That's why, we are using 'k-nearest neighbors algorithm' to make a model easily. This is a very is a non-parametric, lazy learning algorithm. We have already split our data and get our training data. By using the traing data, we will build the model. To make a prediction for a new data point, the algorithm\nfinds the point in the training set that is closest to the new point. Then it assigns the\nlabel of this training point to the new data point.\n\nFind out details from here: [KNN Algorithm](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html)","9e502575":"**Look at the data**\n\n---\n<p align ='justify'>\nBefore building a machine learning model you have to inspect the data, to see if the task is easily solvable without machine learning, or if the desired information might not be contained in the data. For that you can convert your data into a dataframe. As I have informed eariler that dataframe is great way to view your data and get the proper knowledge clearly.\n\nHere we have also used pandas plotting function 'scatter_matrix' and inside  the 'scatter_matrix' we have used mglearn.\nWe can see that the three classes seem to be relatively well separated\nusing the sepal and petal measurements. This means that a machine learning model\nwill likely be able to learn to separate them.\n\nFind out detaits about [Scatter Matrix](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.plotting.scatter_matrix.html)\n<\/p>","88fef054":"**MatPlotLib**\n\n---\nMatplotlib provides functions\nfor making publication quality visualizations such as line charts, histograms, scatter\nplots, and so on. Visualizing the data and different aspects of analysis can give\nus important insights.\n\nFind out more from here: [Matplotlib Documentation](https:\/\/matplotlib.org\/contents.html)\n","db2b6ade":"**Sci-Py**\n\n---\nSciPy is a collection of functions for scientific calculations and it provides\namong other functionality, advanced linear algebra routines, mathematical function\noptimization, signal processing, special mathematical functions, and statistical distributions.\n\nFind out more from here: [SciPy dodcumentation](https:\/\/www.scipy.org\/docs.html)\n","bd1f2d40":"# **A Few Basics to Start Your Exploration Journey**","453bc5dd":"**Evaluating the model**\n\n---\nAt the very last, we can use our test dataset to test our model to find out our expected result for the model.","912e4d7f":"**Numpy**\n\n---\n<p align='justify'>\nThe core functionality of NumPy is the ndarray class, a\nmultidimensional (n-dimensional) array. All elements of the array must be of the\nsame type. In Python we have lists that serve the purpose of arrays, but they are slow to process. NumPy aims to provide an array object that is up to 50x faster than traditional Python lists.\n\nFind out more from here: \n[Numpy documentation](https:\/\/numpy.org\/doc\/stable\/)\n\n","120c5eba":"**First Application:** \n\n---\nIris Dataset: Here we have used the famous iris dataset to build our first applicaion. You will be able to find it in the scikit learn library which features various algorithms like support vector machine, random forests, and k-neighbours.\n\nFind out more: [Scikit learn Documentation](https:\/\/scikit-learn.org\/stable\/getting_started.html)","b650c2ac":"**Split Train and Test Data**\n\n---\n\n<p align='justify'>\nIf we have just a set of data, we can split it into two part. One part is for training the model and another one part of testing our model. 75 percent of total data will go to the training dataset and 25 percentage will go to the testing dataset. We can do it just using 'train_test_split()' function.","ebf9df14":"><p align ='justify'> I have learned a lot of python libraries and algorithms but I didn't get some proper knowledge about where to start and how to start and how much knowledge do I need to start my journey towards machine learning. That's why I have decided to share my point of view to start and what knowledges are enough to start.\n<\/p>","5cf17bd7":"**Making New Prediction**\n\n---\nHere, we can create a dataset randomly by ourselves. And predict the result from our data and assuring that the model will work for any random data.\n","6543aee9":"Reference book: **Introduction to Machine Learning with Python** by **Andreas C. M\u00fcller** && **Sarah Guido**.","40f09e9c":"**Pandas**\n\n---\nData is unavoidably messy in real world. And Pandas is seriously a game changer when it comes to cleaning, transforming, manipulating and analyzing data. It converts data into the dataframe which is great and clean view of data.\n\nFind out more: [Pandas Documentation](https:\/\/pandas.pydata.org\/getting_started.html)"}}