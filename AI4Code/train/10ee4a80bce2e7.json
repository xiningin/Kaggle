{"cell_type":{"2e0d73d5":"code","ac0d3001":"code","0f68b1e0":"code","f6e627c9":"code","07034d68":"code","2b996aa4":"code","577d47c8":"code","39289c6b":"code","a03a4e50":"code","60f04569":"code","6dca3ca5":"code","7b90842a":"code","93617837":"code","7093ebc8":"code","ba97a3e5":"code","fec18ea1":"code","9630cdda":"code","f1290098":"code","de54cc82":"code","7f960b2f":"code","42810733":"code","57d2a5d1":"code","7da727ad":"code","169e24a5":"code","f2f8a752":"code","0f60acd3":"code","75dcf0cf":"code","68928534":"code","43a060c5":"code","20171f09":"code","204cee7f":"code","b6e57441":"code","7db5af62":"code","b969819d":"code","96156aeb":"code","0174eb54":"code","39fe226c":"code","a2cf25e0":"code","9d8a4194":"code","ac8bfa30":"code","416daa6e":"code","b6deb808":"code","6e5fb8ad":"code","5498129b":"code","ce6ace1e":"code","928346e4":"code","2ea7c679":"code","81ccbbc9":"code","181fed3b":"code","3e7410d8":"code","baeb8170":"code","97f2c3c8":"code","8d1d1817":"code","2f1e32b3":"code","238dbeb0":"code","9035c813":"markdown","d2e65a9e":"markdown","19a0755a":"markdown","6608a6a0":"markdown"},"source":{"2e0d73d5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom joblib import dump, load\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score,recall_score\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport matplotlib.pyplot as plt\n\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom itertools import cycle\nimport seaborn as sns\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport sklearn.metrics as metrics\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ac0d3001":"#Loading training set into dataframe\ndf = pd.read_csv('..\/input\/nslkdd\/nsl-kdd\/KDDTrain+.txt', header=None)\ndf.head()","0f68b1e0":"df.shape","f6e627c9":"#Loading testing set into dataframe\nqp = pd.read_csv('..\/input\/nslkdd\/nsl-kdd\/KDDTest+.txt', header=None)\nqp.head()","07034d68":"qp.shape","2b996aa4":"#Reset column names for training set\ndf.columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n'num_access_files', 'num_outbound_cmds', 'is_host_login',\n'is_guest_login', 'count', 'srv_count', 'serror_rate',\n'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n'dst_host_srv_count', 'dst_host_same_srv_rate','dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n'dst_host_srv_rerror_rate', 'class', 'difficulty_level']\ndf.head()\n","577d47c8":"#Reset column names for testing set\nqp.columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n'num_access_files', 'num_outbound_cmds', 'is_host_login',\n'is_guest_login', 'count', 'srv_count', 'serror_rate',\n'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n'dst_host_srv_count', 'dst_host_same_srv_rate','dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n'dst_host_srv_rerror_rate', 'class', 'difficulty_level']\nqp.head()","39289c6b":"#accessing names of training columns\nlst_names = df.columns # returns a list of column names\nlst_names\n","a03a4e50":"#accessing names of testing columns\ntestlst_names = qp.columns\ntestlst_names","60f04569":"df.isnull().values.any()\n","6dca3ca5":"qp.isnull().values.any()","7b90842a":"df['class']","93617837":"qp['class']","7093ebc8":"#defining col list\ncols = ['protocol_type','service','flag']\ncols","ba97a3e5":"#One-hot encoding\ndef one_hot(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode\n    @return a DataFrame with one-hot encoding\n    \"\"\"\n    for each in cols:\n        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(each, 1)\n    return df\n","fec18ea1":"#Merging train and test data\ncombined_data = pd.concat([df,qp],sort= False)","9630cdda":"#Applying one hot encoding to combined data\ncombined_data = one_hot(combined_data,cols)","f1290098":"#Splitting the combined data back into training and testing\nnew_train_df = combined_data.iloc[:125973]\nnew_test_df = combined_data.iloc[125973:]","de54cc82":"\"\"\"\n# Function to calculate VIF\ndef calculate_vif(data):\n    vif_df = pd.DataFrame(columns = ['Var', 'Vif'])\n    x_var_names = data.columns\n    for i in range(0, x_var_names.shape[0]):\n        y = data[x_var_names[i]]\n        x = data[x_var_names.drop([x_var_names[i]])]\n        r_squared = sm.OLS(y,x).fit().rsquared\n        vif = round(1\/(1-r_squared),2)\n        vif_df.loc[i] = [x_var_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis = 0, ascending=False, inplace=False)\n\nX=df.drop(['Salary'],axis=1)\ncalculate_vif(X)\n\"\"\"","7f960b2f":"#df = df.drop(df.columns[[0]], axis=1)#\n#calculate_vif(new_train_df)","42810733":"new_train_df","57d2a5d1":"new_train_df.shape","7da727ad":"new_test_df.shape","169e24a5":"new_test_df.head()","f2f8a752":"#Dropping subclass column for training set\ntmp = new_train_df.pop('class')","0f60acd3":"classlist = []\ncheck1 = (\"apache2\",\"back\",\"land\",\"neptune\",\"mailbomb\",\"pod\",\"processtable\",\"smurf\",\"teardrop\",\"udpstorm\",\"worm\",\n         \"ipsweep\",\"mscan\",\"nmap\",\"portsweep\",\"saint\",\"satan\",\n         \"buffer_overflow\",\"loadmodule\",\"perl\",\"ps\",\"rootkit\",\"sqlattack\",\"xterm\",\n         \"ftp_write\",\"guess_passwd\",\"httptunnel\",\"imap\",\"multihop\",\"named\",\"phf\",\"sendmail\",\"Snmpgetattack\",\"spy\",\"snmpguess\",\"warezclient\",\"warezmaster\",\"xlock\",\"xsnoop\")\n","75dcf0cf":"for item in tmp:\n    if item in check1:\n        classlist.append(1)\n    else:\n        classlist.append(0)\n\n        \n        ","68928534":"#Appending Class column to testing set\nnew_train_df[\"Class\"] = classlist","43a060c5":" new_train_df.head()","20171f09":"#Dropping class column for training set\ntesttmp = new_test_df.pop('class')","204cee7f":"#Fixing labels for testing\ntestclasslist = []\ntestcheck1 = (\"apache2\",\"back\",\"land\",\"neptune\",\"mailbomb\",\"pod\",\"processtable\",\"smurf\",\"teardrop\",\"udpstorm\",\"worm\",\n             \"ipsweep\",\"mscan\",\"nmap\",\"portsweep\",\"saint\",\"satan\",\n             \"buffer_overflow\",\"loadmodule\",\"perl\",\"ps\",\"rootkit\",\"sqlattack\",\"xterm\",\n              \"ftp_write\",\"guess_passwd\",\"httptunnel\",\"imap\",\"multihop\",\"named\",\"phf\",\"sendmail\",\"Snmpgetattack\",\"spy\",\"snmpguess\",\"warezclient\",\"warezmaster\",\"xlock\",\"xsnoop\")\n\n\n","b6e57441":"\nfor item in testtmp:\n    if item in testcheck1:\n        testclasslist.append(1)\n    else:\n        testclasslist.append(0)\n","7db5af62":"#Appending Class column to testing set\nnew_test_df[\"Class\"] = testclasslist","b969819d":"new_test_df\n","96156aeb":"\n#Function to min-max normalize\ndef normalize(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode\n    @return a DataFrame with normalized specified features\n    \"\"\"\n    result = df.copy() # do not touch the original df\n    for feature_name in cols:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        if max_value > min_value:\n            result[feature_name] = (df[feature_name] - min_value) \/ (max_value - min_value)\n    return result","0174eb54":"#Normalizing training set\ntrain_df = normalize(new_train_df,new_train_df.columns)\ntrain_df.head()","39fe226c":"#Normalizing training set\ntest_df = normalize(new_test_df,new_test_df.columns)\ntest_df.head()","a2cf25e0":"#Preparing X_train, Y_train\ntrainingdata = new_train_df.values\nx_train = trainingdata[:,:-1]\ny_train = trainingdata[:,-1]","9d8a4194":"#Preparing X_test, Y_test\ntestingdata = new_test_df.values\nx_test = testingdata[:,:-1]\ny_test = testingdata[:,-1]","ac8bfa30":"#Logistic Regression\nclf = LogisticRegression (solver='liblinear', multi_class='auto') # use all default parameters\n# predication and performance evaluation are the same as Perceptron\nclf.fit(x_train, y_train) # fit data\n#############use and evaluate model##################\ntrain_acc = clf.score(x_train, y_train) # mean acc on train data\ntest_acc = clf.score(x_test, y_test) # mean acc on test data\ny_pred = clf.predict(x_test) # make prediction\nprint(\"Training accuracy is:\", train_acc )\nprint(\"Testing accuracy is:\", test_acc)","416daa6e":"#Logistic Regression performance metrics\nLogistic_f1 = f1_score(y_test, y_pred, average=\"macro\")\nLogistic_precision = precision_score(y_test, y_pred, average=\"macro\")\nLogistic_recall = recall_score(y_test, y_pred, average=\"macro\")\nLogistic_accuracy = accuracy_score(y_test, y_pred)","b6deb808":"\nimport tensorflow as tf\n\"\"\"\nfrom tensorflow.python.framework import ops\n\"\"\"\n","6e5fb8ad":"\"\"\"\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\"\"\"","5498129b":"shape = x_train.shape","ce6ace1e":"\"\"\"\n# Hyperparameters\nlearning_rate = 0.5\ntraining_epochs = 30\nbatch_size = 256\n\n# Architecture\nn_features = shape[1]\nn_classes = 2\n\"\"\"\n","928346e4":"\"\"\"\ndef create_placeholders(n_H0, n_W0, n_C0, n_y):\n   \n    ### START CODE HERE ### (\u22482 lines)\n    X = None\n    Y = None\n    ### END CODE HERE ###\n    \n    return X, Y\n\"\"\"    ","2ea7c679":"#conda remove tensorflow-gpu tensorflow tensorflow-base","81ccbbc9":"#conda install tensorflow","181fed3b":"#x_train.shape\ntrainX = np.dstack(x_train)\ntrainy = np.dstack(y_train)\ntestX = np.dstack(x_test)\ntestY = np.dstack(y_test)\n","3e7410d8":"print(trainX.shape)\nprint(trainy)","baeb8170":"import tensorflow as tf\ntrainX = tf.reshape(x_train,[125973,123, 1]).numpy()\ntrainY = tf.reshape(y_train,[125973,1, 1]).numpy()\ntestX = tf.reshape(x_test,[22544,123, 1]).numpy()\ntestY = tf.reshape(y_test,[22544,1, 1]).numpy()\n#print(trianX)\n#trainX.shape","97f2c3c8":"import tensorflow as tf\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras import layers\ndef evaluate_model(trainX, trainy, testX, testy):\n    verbose, epochs, batch_size = 0, 10, 64\n    #input_shape = (256,125973,123)\n    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n    model = Sequential()\n    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu',input_shape=(n_timesteps, n_features)))\n    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(100, activation='relu'))\n    model.add(tf.keras.layers.Dense(n_outputs, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    # fit network\n    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n    # evaluate model\n    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n    return accuracy","8d1d1817":"print(evaluate_model(trainX,trainY,testX,testY))","2f1e32b3":"import tensorflow as tf\ninput_size = 123\nBATCH_SIZE = 256\n\ntrain_generator = train_datagen.flow_from_directory(\n    x_train,\n    target_size=(input_size, input_size),\n    batch_size=BATCH_SIZE, \n    shuffle=True,\n   \tclass_mode='categorical')\n\nval_generator = test_datagen.flow_from_directory(\n    ,\n    target_size=(input_size, input_size),\n    batch_size=BATCH_SIZE,\n    shuffle=True, \n    class_mode='categorical')","238dbeb0":"def load_dataset(prefix=''):\n\t# load all train\n\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset\/')\n\tprint(trainX.shape, trainy.shape)\n\t# load all test\n\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset\/')\n\tprint(testX.shape, testy.shape)\n\t# zero-offset class values\n\ttrainy = trainy - 1\n\ttesty = testy - 1\n\t# one hot encode y\n\ttrainy = to_categorical(trainy)\n\ttesty = to_categorical(testy)\n\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n\treturn trainX, trainy, testX, testy\n ","9035c813":"**Logistic Regression**","d2e65a9e":"# conv2d****","19a0755a":"# one hot encoding","6608a6a0":"**Softmax Regression**"}}