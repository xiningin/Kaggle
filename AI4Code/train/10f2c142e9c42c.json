{"cell_type":{"ec4e7182":"code","7f5e221a":"code","171b5ab5":"code","122fb95a":"code","f6e57a31":"code","258112c8":"code","5eeb75b5":"code","782acfcf":"code","8513e51d":"code","a3f5852d":"code","1553ea24":"code","a6c157dc":"code","e3614715":"code","a4953135":"code","1d271ad7":"code","b0803335":"code","676912b6":"code","16c18be9":"code","cedac08c":"code","d779cfcc":"code","0ebeaeeb":"code","3bfde4b4":"code","58a3d82b":"code","97608b7e":"code","c2c1f1f1":"code","1c54a2f9":"code","b950ee67":"code","584074c7":"code","3096b3e6":"code","9bcd8e7e":"code","37929b6b":"code","d662ffb1":"code","ceb0772f":"code","44d8a8e9":"code","40e7821d":"code","a996d179":"markdown","636458e9":"markdown","63734d58":"markdown","a43aced5":"markdown","98d03464":"markdown","92ba4af9":"markdown","9cb2a8d5":"markdown","2a33187c":"markdown","91a6e63d":"markdown","053bddd9":"markdown","2b5f6b92":"markdown","f54e999d":"markdown","01d06902":"markdown","be3231ac":"markdown","e78fd934":"markdown","23ba1856":"markdown","c4cfce47":"markdown","7a947220":"markdown"},"source":{"ec4e7182":"! pip install -q kaggle","7f5e221a":"from google.colab import files\nfiles.upload()","171b5ab5":"! mkdir ~\/.kaggle\n! cp kaggle.json ~\/.kaggle\/","122fb95a":" ! chmod 600 ~\/.kaggle\/kaggle.json","f6e57a31":"!kaggle datasets download -d alxmamaev\/flowers-recognition","258112c8":"!unzip flowers-recognition.zip","5eeb75b5":"from google.colab import drive\ndrive.mount(\"\/content\/gdrive\", force_remount=True)","782acfcf":"%cd \/content\/gdrive\/MyDrive\/flower","8513e51d":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport pickle","a3f5852d":"dir = '\/content\/gdrive\/MyDrive\/flower\/flowers'\nclasses = ['daisy','dandelion','rose','sunflower','tulip']\nvalues = []\ntotal_images = 0\nfor c in classes :\n  flower_path = os.path.join(dir,c)\n  count = 0\n  for path in os.listdir(flower_path):\n      count+=1\n  values.append(count)\n  total_images +=count\nprint(values)\n\nfig = plt.figure(figsize = (10, 5))\n \n# creating the bar plot\nplt.bar(classes, values, color ='maroon',\n        width = 0.4)\n \nplt.xlabel(\"Categories\")\nplt.ylabel(\"No of images\")\nplt.title(\"Total number of images in each category\")\nplt.show()","1553ea24":"def prepare_dataset():\n    record = []\n    for c in classes :\n        path = os.path.join(dir,c)\n        label = classes.index(c)\n\n        for img_name in os.listdir(path):\n            image_path = os.path.join(path,img_name)\n            image = cv2.imread(image_path)\n\n            try :\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image,(224,224))\n\n                image = np.array(image,dtype=np.float32)\n                record.append([image,label])\n\n            except Exception as e :\n                pass\n\n    pik = open('data.pickle','wb')\n    pickle.dump(record,pik)\n    pik.close()","a6c157dc":"prepare_dataset()","e3614715":"def load_dataset():\n    pick = open('data.pickle','rb')\n    data = pickle.load(pick)\n    pick.close()\n\n    np.random.shuffle(data)\n\n    feature = []\n    labels = []\n\n    for img,label in data :\n        feature.append(img)\n        labels.append(label)\n\n    feature = np.array(feature,dtype=np.float32)\n    labels = np.array(labels)\n\n    feature = feature\/255.0\n\n    return [feature,labels]","a4953135":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random as rn\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","1d271ad7":"(feature,labels) = load_dataset()\nX_train, X_test, Y_train, Y_test = train_test_split(feature,labels,test_size = 0.1,random_state=42)\nclasses = ['daisy','dandelion','rose','sunflower','tulip']","b0803335":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=rn.randint(0,len(X_test))\n        ax[i,j].imshow(X_test[l])\n        ax[i,j].set_title('Flower: '+classes[Y_test[l]])\n        \nplt.tight_layout()","676912b6":"input_layer = tf.keras.layers.Input([224,224,3])\n\nconv1 = tf.keras.layers.Conv2D(filters = 32,kernel_size=(5,5),padding='Same',activation='relu')(input_layer)\npool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv1)\n\nconv2 = tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3),padding='Same',activation='relu')(pool1)\npool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv2)\n\nconv3 = tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3),padding='Same',activation='relu')(pool2)\npool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv3)\n\nconv4 = tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3),padding='Same',activation='relu')(pool3)\npool4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv4)\n\nflt1 = tf.keras.layers.Flatten()(pool4)\n\ndn1 = tf.keras.layers.Dense(512,activation='relu')(flt1)\noutput_layer = tf.keras.layers.Dense(5,activation='softmax')(dn1)","16c18be9":"model = tf.keras.Model(input_layer,output_layer)","cedac08c":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","d779cfcc":"model.summary()","0ebeaeeb":"model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])","3bfde4b4":"batch_size = 100\nepochs = 20\n\nHistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,Y_test),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","58a3d82b":"model.save('flower_pred_updated.h5')","97608b7e":"model = tf.keras.models.load_model('flower_pred_updated.h5')\n\nmodel.evaluate(X_test,Y_test,verbose = 1)","c2c1f1f1":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","1c54a2f9":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","b950ee67":"predictions = model.predict(X_test)\nplt.figure(figsize=(9,9))\n\nfor i in range(9) :\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[i])\n    plt.xlabel('Actual:'+classes[Y_test[i]]+'\\n'+'Predicted : '+classes[np.argmax(predictions[i])])\n    plt.xticks([])\nplt.show()","584074c7":"pred_image_path = '\/content\/gdrive\/MyDrive\/flower\/images.png'\npred_image = cv2.imread(pred_image_path)\npred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\npred_image = cv2.resize(pred_image,(224,224))\n\n# print(pred_image)\n\npred_image = np.array(pred_image,dtype=np.float32)\n\nfeat = []\nlab = []\nfeat.append(pred_image)\nlab.append('rose')\n\nfeat = np.array(feat,dtype=np.float32)\nlab = np.array(lab)\nfeat = feat\/255.0\npreds = model.predict(feat)\nprint(preds)\nplt.figure(figsize=(9,9))\nplt.imshow(feat[0])\nplt.xlabel('Predicted : '+classes[np.argmax(preds)])\nprint(np.argmax(preds))\n\n\n","3096b3e6":"values = []\nfor i in preds[0] :\n  values.append(float(i))\nplt.bar(classes,values, color ='maroon', width = 0.4)\n \nplt.xlabel(\"Categories\")\nplt.ylabel(\"Predictions\")\nplt.title(\"Predictions in each class for the random image\")\nplt.show()","9bcd8e7e":"## Model Evaluation\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport pandas as pd\nimport seaborn as sns","37929b6b":"model = tf.keras.models.load_model('flower_pred_updated.h5')","d662ffb1":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('Truth')\n    plt.xlabel('Prediction')","ceb0772f":"predictions = model.predict(X_test)\n\nobtained = []\ntruth = []\nfor i in range(len(predictions)) : \n    obtained.append(classes[np.argmax(predictions[i])])\n    truth.append(classes[Y_test[i]])\n\n\ncm = confusion_matrix(truth,obtained)\n","44d8a8e9":"print_confusion_matrix(cm,['daisy','dandelion','rose','sunflower','tulip'])","40e7821d":"print(classification_report(truth,obtained))","a996d179":"Using sklearn's **train_test_split** to divide the data into training and testing samples.","636458e9":"## **Step 3 : Model Preparation, Training and Testing**\n\n\n1.   Split the data into training and testing samples.\n2.   Reviewing the training data.\n3.   Preparing convolutional and pooling layers in the model.\n4.   Precautionary steps to avoid overfitting.\n5.   Training the model.\n6.   Saving the model in google drive.\n\n","63734d58":"We need to convert the images into nd-arrays .The next step is to combine all the image numpy arrays with their labels, into a common file, so as to make the training and testing process easier.\"","a43aced5":"Adding the input layer to the model, followed by layers of 2D convolutional neural netorks and max pooling. Finsihing with an output layer at the end after the dense layer.","98d03464":"Normalize the image arrays to prepare it for training.","92ba4af9":"## **Step 1 : Importing the dataset**\n\n\n1.   Importing kaggle to directly fetch the datatset into google colab notebook.\n2.   Downloading the dataset, using the kaggle command.\n3.   Unzipping the dataset, to make it ready to use.\n\n","9cb2a8d5":"Plotting the confusion matrix based on the results obtained from evaluating the test dataset.","2a33187c":"## **Step 2 : Data Preprocessing**\n\n\n1.   Exploring the dataset, to gain knowledge about the same.\n2.   Coverting images to nd-array, then combining them with their labels and dumping it into a single file.\n3.   Normalizing the nd-array images.\n\n","91a6e63d":"We need the kaggle.json file for executing this step, which can be downloaded by navigating to your kaggle account. Now, you need to go to the API section and click on create new API token, which will trigger the file download.","053bddd9":"## **Step 4 : Model Evaluation**\n\n\n1.   Evaluating the model's accuracy on the testing dataset.\n2.   Viewing the model's results for some random data from the testing split.\n3.   Checking model's performance on a random image from the internet.\n4.   Calculating accuracy, precision, recall, f1 score and plotting the confusion matrix for the model. \n\n\n","2b5f6b92":"Training the model on the training dataset, for 20 epochs and a batch_size of 100.","f54e999d":"Performing data augmentation to avoid model overfitting.","01d06902":"Testing the model's accuracy on a random image from the internet.","be3231ac":"Classification report providing with the precision, recall and f1-score for the model.","e78fd934":"Making predictions on the test dataset and plotting the results to verify.","23ba1856":"Below is the command to download the dataset from kaggle.","c4cfce47":"Viewing some of the data samples from the training split, to ensure proper working without errors.","7a947220":"Unzipping the dataset, to make it accessible."}}