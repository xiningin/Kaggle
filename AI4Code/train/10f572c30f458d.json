{"cell_type":{"fd7fd307":"code","0a97004a":"code","0be68121":"code","53523950":"code","e6cbdae6":"code","97b13691":"code","55d1ccf3":"code","420c9fa3":"code","fa4623b7":"code","45478de7":"code","217bf601":"code","35d76908":"code","c49467e2":"code","625f9d61":"code","a78e5b57":"markdown","a4140c88":"markdown","f0578a19":"markdown","f6d1e8e8":"markdown","c34f7f6a":"markdown"},"source":{"fd7fd307":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","0a97004a":"#Importing the dataset, df stands for dataframe\niris_df = pd.read_csv('..\/input\/iris\/Iris.csv')","0be68121":"#get dummies is used to converts categorical data into dummy or indicator variables.\niris_df = pd.get_dummies(iris_df, columns=['Species'])\niris_df.head()","53523950":"#X are the inputs and y are the labels\/output\nX = iris_df.values[:, 1:5]\ny = iris_df.values[:, 5:8]","e6cbdae6":"#Normalize input data to get on a same scale between 0 and 1\ndef normalize(array):\n    arr_min = array.min(axis=(0, 1))\n    arr_max = array.max(axis=(0, 1))\n    return (array - arr_min) \/ (arr_max - arr_min)","97b13691":"X = normalize(X)","55d1ccf3":"#Split dataset into train and test set, test is equal to 10% of the dataset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","420c9fa3":"from keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras.optimizers import Adam ","fa4623b7":"#Defining the model\ndef create_network():\n    model = Sequential()\n    model.add(Dense(7, input_shape=(4,), activation='relu')) #Input layer, input 4 values -> output 7 values using relu\n    model.add(Dense(8, activation='relu')) #Hidden layer, input 7 values (output of first layer) -> output 8 values using relu\n    model.add(Dense(3, activation='softmax')) #Output layer, input 8 values -> output 3 values (3 are the classes) using softmax\n        \n        #Layers are fully connected that means output of one layer is fully connected to the each node of next layer\n        \n        \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy']) #categorical_crossentropy Computes the crossentropy loss between the labels and predictions. Using the optimizer Adam.\n    return model","45478de7":"model = create_network()","217bf601":"#Training the model, by providing input values, output labels, number of epochs, batch size define how much data should be picked up in one iteration, and defining the test data as the validation data\nresults = model.fit(X_train,y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test))","35d76908":"#Plotting the loss of training data and validation data\nplt.figure(figsize=(5, 5))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"training_loss\")\nplt.plot(results.history[\"val_loss\"], label=\"validation_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","c49467e2":"model.predict(X_test[:5])","625f9d61":"y_test[:5]","a78e5b57":"One-hot labels by get_dummies() method","a4140c88":"# A Simple Neural Network working on Iris flower dataset","f0578a19":"# Load dataset","f6d1e8e8":"# Build NN with Keras","c34f7f6a":"This is results of prediction on 5 samples and the below is real labels"}}