{"cell_type":{"32298a96":"code","1eddf330":"code","5e001a84":"code","28d7ac23":"code","96e52d0b":"code","68ab36c7":"code","06f51abe":"code","025f73d7":"code","d7fccc4e":"code","41748450":"code","35abf3e2":"code","736c698e":"code","c4beb519":"code","abd6af20":"code","ee840009":"code","81c41a9d":"code","2c922d37":"code","4e0c2299":"markdown","2712c06a":"markdown","4ff1bee6":"markdown","e08edb3a":"markdown","60bbf27c":"markdown","7980ca42":"markdown","67d3df49":"markdown","d8b2ba21":"markdown"},"source":{"32298a96":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer","1eddf330":"import os\nos.listdir(\"..\/input\/movielens-20m-dataset\")\nos.chdir(\"..\/input\/movielens-20m-dataset\/\")","5e001a84":"genome_tags = pd.read_csv(\"genome_tags.csv\")\n\n# We drop this dataset, since this doesn't have any useful features for predictions\nlink = pd.read_csv(\"link.csv\")\ngenome_scores = pd.read_csv(\"genome_scores.csv\")\n\n# For efficiency and compatability We pick top 5000 rows\nmovies = pd.read_csv(\"movie.csv\",nrows=5000)\nrating = pd.read_csv(\"rating.csv\")\ntag = pd.read_csv(\"tag.csv\")\n","28d7ac23":"# Dataset shape\nprint(\"genome_tags shape is {}\".format(genome_tags.shape))\nprint(\"genome_scores shape is {}\".format(genome_scores.shape))\nprint(\"movies shape is {}\".format(movies.shape))\nprint(\"rating shape is {}\".format(rating.shape))\nprint(\"tag shape is {}\".format(tag.shape))","96e52d0b":"print(genome_scores.columns)\nprint(movies.columns)\nprint(rating.columns)\nprint(tag.columns)","68ab36c7":"# genome_scores dataset has relevance feature which says that how much a tag is relevant to the movie and\n# it's value range from 0 to 1, we'll consider only the value which has more than 0.5 relevance. So this gives better \n# predicrion. And We'll merge the tag with genome_scores dataset.\ngenome_scores = genome_scores[genome_scores['relevance']> 0.5].merge(genome_tags,on='tagId',how='left') \n\n# concatenating all the tag that belongs to a movie and forming a tag collection for each movie\ngenome_scores = genome_scores.groupby('movieId')['tag'].apply(' '.join).reset_index()","06f51abe":"final_dataset = pd.merge(movies,genome_scores,on='movieId',how='left')","025f73d7":"# renaming tag as keywords\ntag = tag.rename(columns = {\"tag\":\"keywords\"})\ntag['keywords'].fillna('',inplace=True)\ntag = tag.groupby('movieId')['keywords'].apply(' '.join).reset_index()","d7fccc4e":"final_dataset = pd.merge(final_dataset,tag,on='movieId',how='left')","41748450":"final_dataset['genres'].head()","35abf3e2":"final_dataset['keywords'] = final_dataset['keywords'] + \" \" +final_dataset['tag'] +  \" \" + \\\n    final_dataset['genres'].str.replace(\"|\",\" \")\nfinal_dataset['keywords'].fillna(\"\",inplace=True)","736c698e":"# rating will be used for collabarative filtering, so we'll skip this now\n# final_dataset = pd.merge(final_dataset,rating,on='movieId',how='left')","c4beb519":"# Both tag and genres values has added to keywords so we drop this \nfinal_dataset.drop(['tag','genres'],inplace=True,axis=1)","abd6af20":"# stop words will remove the common english words like a,an,the,i,me,my etc which increase the words count and \n# create noise in our model \n\nc_vect = TfidfVectorizer()\nX = c_vect.fit_transform(final_dataset['keywords'])","ee840009":"# There are other similiary distance metric available which are euclidean distance,manhattan distance, \n# Pearson coefficient etc. But for sparse matrix cosine similarity works better\ncosine_sim = cosine_similarity(X)","81c41a9d":"def get_movie_recommendation(movie_name):\n    idx = final_dataset[final_dataset['title'].str.contains(movie_name)].index\n    if len(idx):\n        movie_indices = sorted(list(enumerate(cosine_sim[idx[0]])), key=lambda x: x[1], reverse=True)[1:11]\n        movie_indices = [i[0] for i in movie_indices]\n        return movie_indices\n    else : \n        return []","2c922d37":"title = \"Toy Story 2\"\nrecommended_movie_list = get_movie_recommendation(title)\nmovies.iloc[recommended_movie_list].set_index('movieId')","4e0c2299":"I'm writing my other kernel for collabarative filtering. Will update once it is completed.\n\n**Please upvote it if you like it. Thanks**","2712c06a":"Our system predicts exactly the similar movies of Toy story\n\nMajor drawback of this approach is that it predicts the same lists of movie for all the user who search Toy story irrespective of their interest and their likes. So we need an algorithm to predict based on User behaviour for that We'll use collabrative filtering.","4ff1bee6":"### Power of Recommendation Engine\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Suppose You're planning to buy a laptop without any idea about the right configuration. So You would check with Your friends and colleagues for recommendation and they suggests laptops based on Your requirement , their knowledge and trending one. The same way Recommendation engine works. For instance, Amazon recommends You a laptop based on Your previous search , popularity and keeps on showing the best recommendation and tempt You to buy a laptop even if You drop the plan. All the major company has recommendation in their products such as Youtube shows recommendations based on Your interests and activity.\n\nWe'll explore how to implement it, before that there are two types of Recommendation Engine\n\n1. **Content Based Filtering**\n2. **Collabarative Based Filtering**\n\n#### Content Based Filtering\nThis algorithm recommends products which are similar to the ones that a user has liked in the past.\n\n#### Collabaratvie Based Filtering\nThe collaborative filtering algorithm uses \u201cUser Behavior\u201d for recommending items.","e08edb3a":"movieId feature is common in all dataset, using that we'll combine all the dataset into final_dataset","60bbf27c":"*In this Kernel, we shall look at Content Based Filtering implementation*","7980ca42":"**Our task is When User search a movie, We'll recommend the top 10 similar movies**","67d3df49":"Implementation is so simple, We're going to combine tags,keywords,genre and create a bulk of keywords for each movie from the multiple given datasets and find similarity between each movie and popup the top similar movies","d8b2ba21":"All keywords are in english. Our model can understand only numbers so We'll convert the keywords into sparse matrix form using either CountVectorizer or TfidfVectorizer. CountVectorizer just counts the words appear, there is a high chances that missing the rare words which could have helped for predicting the model effectively. So We'll use TfidfVectorizer which counts the frequency of the words and normalize them and this is mostly recommended."}}