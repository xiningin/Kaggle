{"cell_type":{"6e80b32a":"code","d6dab949":"code","77827c84":"code","15c8bac1":"code","6436a4e8":"code","fc55adea":"code","d5b2ecee":"code","abfbf3e6":"code","638fc778":"code","a2f905b6":"code","979d9b31":"code","beb8a792":"code","9a60b011":"markdown"},"source":{"6e80b32a":"!pip install tushare\n\nimport tushare as ts\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport datetime\nfrom datetime import timedelta\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport sys, os\nimport matplotlib.pylab as plt","d6dab949":"#####################################################\n## get all stocks list\nall_codes = ts.get_today_all()['code']\ncodes_df = pd.DataFrame(all_codes)\ncodes_df[\"prefix\"] = codes_df[\"code\"].str.slice(0,3)\ncodes_df.groupby([\"prefix\"])[\"code\"].count().sort_values(ascending=False)\n\n## only contains code prefix in 002,600,603,000,601\ncodes_df = codes_df[codes_df[\"prefix\"].isin((\"002\",\"600\",\"603\",\"000\",\"601\"))]\ncodes_df = codes_df.drop_duplicates()\ncodes_df.groupby([\"prefix\"])[\"code\"].count().sort_values(ascending=False)","77827c84":"####################################################\n## get all history data\nall_hist_df = pd.DataFrame()\ncnt = 0\nfor curr_code in codes_df[\"code\"]:\n    #if cnt > 10: break\n    tmp_df = ts.get_hist_data(curr_code)\n    if not (tmp_df is None):\n        try:\n            tmp_df[\"code\"] = curr_code\n            tmp_df[\"prefix\"] = tmp_df[\"code\"].str.slice(0,3)\n            all_hist_df = pd.concat([all_hist_df, tmp_df])\n            cnt += 1\n        except:\n            continue\n\n## add column date\nall_hist_df[\"date\"] = all_hist_df.index.values","15c8bac1":"######################################################\n#generate basic features from http:\/\/tushare.org\/fundamental.html\nbasic_data = ts.get_stock_basics()\nbasic_data.reset_index(inplace=True)\n\n#time to market -> datediff between time to market and now \nbasic_data = basic_data[basic_data[\"timeToMarket\"] > 0] #del NA\nbasic_data[\"timeToMarket\"] = pd.to_datetime(basic_data[\"timeToMarket\"].apply(str), format = \"%Y%m%d\").apply(lambda x: x.strftime('%Y-%m-%d'))\n\nbasic_features = [\"industry\",\"area\",\"pe\",\"outstanding\",\"totals\",\"totalAssets\",\"liquidAssets\",\"fixedAssets\",\"reserved\",\n                  \"reservedPerShare\",\"esp\",\"bvps\",\"pb\",\"undp\",\"perundp\",\"rev\",\"profit\",\"gpr\",\"npr\",\"holders\"]\nbasic_data = basic_data[basic_features + [\"code\",\"timeToMarket\"]]\nbasic_data = basic_data.drop_duplicates()\nall_hist_df = pd.merge(all_hist_df, basic_data, left_on = [\"code\"], right_on = [\"code\"], suffixes=('', '_basic'))\nall_hist_df[\"timeToMarketInterval\"] = (pd.to_datetime(all_hist_df[\"date\"]) - pd.to_datetime(all_hist_df[\"timeToMarket\"])).apply(lambda x: x.days)\n\nprint(all_hist_df[\"timeToMarketInterval\"].describe())\nall_hist_df = all_hist_df[all_hist_df[\"timeToMarketInterval\"] > 30] # del new stocks (timeToMarketInterval <= 30)\nall_hist_df = all_hist_df[(all_hist_df[\"open\"] != all_hist_df[\"high\"]) | (all_hist_df[\"open\"] != all_hist_df[\"close\"])] # del daily limit stocks","6436a4e8":"#########################################################\n#feature combine & encode\nfeatures = [\"open\",\"close\",\"high\",\"low\",\"ma5\",\"ma10\",\"ma20\",\"v_ma5\",\"v_ma10\",\"v_ma20\",\"prefix\"] + basic_features\nall_hist_df = all_hist_df[features + [\"code\",\"date\"]]\ncategorical = [\"prefix\", \"industry\", \"area\"]\n\nfor feature in categorical:\n    print(f'Transforming {feature}...')\n    encoder = LabelEncoder()\n    encoder.fit(all_hist_df[feature])\n    all_hist_df[feature] = encoder.transform(all_hist_df[feature].astype(str))","fc55adea":"#########################################################\n# test set: stocks data on yesterday\nyesterday = max(all_hist_df[\"date\"])\nall_yesterday_df = all_hist_df[all_hist_df[\"date\"]==yesterday]\n\n# label: price diff after 7 days\nlabel = [\"price_diff\"]\nseven_days = timedelta(days=7)\nall_hist_df[\"date_7d\"] = (pd.to_datetime(all_hist_df[\"date\"]) + seven_days).apply(lambda x: x.strftime('%Y-%m-%d'))\nall_hist_df = pd.merge(all_hist_df, all_hist_df[[\"code\",\"close\",\"date\"]], left_on = [\"code\",\"date_7d\"], \n                       right_on = [\"code\",\"date\"], suffixes=('', '_groundtruth'))\nall_hist_df.drop([\"date_7d\"], axis = 1, inplace=True)\nall_hist_df = all_hist_df[all_hist_df[\"close_groundtruth\"].isna()==False]\nall_hist_df[\"price_diff\"] = (all_hist_df[\"close_groundtruth\"] - all_hist_df[\"high\"]) \/ all_hist_df[\"high\"]\nall_hist_df = all_hist_df[all_hist_df[\"price_diff\"].isna()==False]\nall_hist_df[[\"price_diff\"]].describe()\nprint(all_hist_df.shape)","d5b2ecee":"###############################################################\n#training params\nparams = {\n    'objective' : 'regression',\n    'metric' : 'rmse',\n    'num_leaves' : 32,\n    'max_depth': -1,\n    'learning_rate' : 0.02,\n    'feature_fraction' : 0.7,\n    'verbosity' : -1\n}\nall_hist_df = all_hist_df.sample(frac=1) #shuffle\nVALID_RATIO = 0.2\ntrain = all_hist_df[:int(all_hist_df.shape[0] * (1 - VALID_RATIO))] #training set \nvalid = all_hist_df[int(all_hist_df.shape[0] * (1 - VALID_RATIO)):] #valid set\nprint(train.shape)\nprint(valid.shape)\ntrain.head()","abfbf3e6":"################################################################\n# lgb training\nlgtrain = lgb.Dataset(train[features], train[label],feature_name=list(train[features].columns),categorical_feature = categorical)\nlgtest = lgb.Dataset(valid[features], valid[label],feature_name=list(valid[features].columns),categorical_feature = categorical)\nwatchlist = [lgtrain,lgtest]\nlgb_clf = lgb.train(params,lgtrain,num_boost_round=1000,verbose_eval=100,valid_sets=watchlist,early_stopping_rounds=50)\n\n\n# top 100 history score\ny_test_pred_log = lgb_clf.predict(valid[features])\nvalid[\"score\"] = y_test_pred_log\nvalid = valid.sort_values(\"score\",ascending=False)\nvalid[:100]","638fc778":"#################################################################\n# feature importance\nplt.figure(figsize=(12,6))\nlgb.plot_importance(lgb_clf, max_num_features=30)\nplt.title(\"Featurertances\")\nplt.show()","a2f905b6":"#################################################################\n# predict data from yesterday\npredict_value = lgb_clf.predict(all_yesterday_df[features])\nall_yesterday_df[\"score\"] = predict_value\nall_yesterday_df = all_yesterday_df.sort_values(\"score\",ascending=False)\n\n# top 100 score \nall_yesterday_df[:100]","979d9b31":"#guanglianda\nall_yesterday_df[all_yesterday_df[\"code\"]==\"002410\"]","beb8a792":"#zijinkuangye\nall_yesterday_df[all_yesterday_df[\"code\"]==\"601899\"]","9a60b011":"With data from package *tushare*, we want to build a *stock ranking model* of Chinese stock market. The aim of the model is to predict which stock we should buy now, in order to get profit in a short term (e.g. 7 days). We only use history prices and fundamental metrics of each company, which can be imporove in future."}}