{"cell_type":{"8cc2d784":"code","3144c605":"code","9dfffc77":"code","0973cf82":"code","3605c629":"code","5620b9f9":"code","ed6512b3":"code","2dc9e29f":"code","59b2a5f2":"code","25a6fa81":"code","7dcce276":"code","50537506":"code","f6c5a2a2":"code","b549eef3":"code","fd9e5d44":"code","9a5ffd2a":"code","f3e6cbba":"code","354827ab":"code","6abf7d14":"code","505545da":"code","1ddae12f":"code","c3d61b0e":"code","d8217db5":"code","9a91c97b":"code","dadaee75":"code","146e1059":"code","eba34ca3":"code","7085fd14":"code","2cbec47c":"code","40845afd":"code","1e047a19":"code","1896dcea":"code","2e3ab047":"code","717dba90":"code","ef7d0c74":"code","4cd1a570":"code","39afcc06":"code","1049a28d":"code","b500811e":"code","87e22353":"code","136cf8f1":"code","bd28f838":"code","33029ac6":"code","67723a41":"code","f51470f3":"code","c7b5eb65":"code","9d916bb1":"code","7d3c1d60":"code","ba2336b9":"code","e2ad9878":"code","9aac5cde":"code","bc296879":"code","3b7f05c4":"code","f2a806e7":"code","61ff2a5d":"code","1921be03":"code","98795c78":"code","da27f8e0":"code","e9cff41e":"code","1fa3fd84":"code","42da28bc":"code","ceab1c4f":"code","0fba9669":"code","1aad05dc":"code","ed4650f5":"code","1f23466a":"code","62e09b36":"code","58aeeb52":"code","7bfb9c23":"code","fbfab4e8":"code","1c190729":"code","ef40b3c4":"code","33a50f36":"markdown","2e217ac9":"markdown","0fec806d":"markdown","846aa7c7":"markdown","7dd3cd5e":"markdown","ca6f1454":"markdown","0642c78b":"markdown","7a64f20c":"markdown","8cfad046":"markdown","828513a1":"markdown","f809fa60":"markdown","7e68b379":"markdown","17c5590c":"markdown","1cddec96":"markdown","765d913c":"markdown","80a6da59":"markdown","6174d779":"markdown","59e99f41":"markdown","7aa9a66c":"markdown","106c8600":"markdown","abc06fa3":"markdown","1e617127":"markdown","5065540f":"markdown","d6225353":"markdown","a020abe8":"markdown","550fbdae":"markdown","5b6836de":"markdown"},"source":{"8cc2d784":"import pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize","3144c605":"df = pd.read_csv(\"..\/input\/1429_1.csv\")","9dfffc77":"df.head()","0973cf82":"df.info() #trying to understand all the column available in the dataset","3605c629":"data = df[[\"id\",\"reviews.text\",\"reviews.rating\"]]\n# the id has been chosen because under name there are more missing values. \n# from the description the ID represents a device sold by Amazon","5620b9f9":"data.head() ","ed6512b3":"data.describe(include=[\"O\"])","2dc9e29f":"data.info()","59b2a5f2":"data = data.dropna()","25a6fa81":"rt = data['reviews.text']\nwordcloud = WordCloud(background_color='white',\n                      width=1000,\n                      height=400\n                     ).generate(\" \".join(rt))\nplt.figure(figsize=(10,5))\nplt.imshow(wordcloud)\nplt.title('All Words in the Reviews\\n',size=20)\nplt.axis('off')\nplt.show()","7dcce276":"words = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\nrt = \" \".join(data['reviews.text'])","50537506":"diz = {}\nfor word in rt.split(\" \"):\n    if word in words:\n        diz[word] = diz.get(word,0)+1\n        ","f6c5a2a2":"wordcloud = WordCloud(background_color='white',\n                      width=1000,\n                      height=400\n                     ).generate_from_frequencies(diz)\nplt.figure(figsize=(10,5))\nplt.imshow(wordcloud)\nplt.title('Sentiment Words\\n',size=20)\nplt.axis('off')\nplt.show()","b549eef3":"plt.figure(figsize=(10,5))\nsns.countplot(data['reviews.rating'])\nplt.title('Count ratings')\nplt.show()","fd9e5d44":"data1 = data.groupby(\"id\").mean().reset_index()","9a5ffd2a":"data1 = data1.sort_values(['reviews.rating']).reset_index()","f3e6cbba":"plt.figure(figsize=(10,8))\nsns.barplot(x=data1[\"reviews.rating\"], y=data1[\"id\"])\nplt.title('Count ratings')\nplt.show()","354827ab":"df2 = pd.read_csv(\"..\/input\/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\ndf3 = pd.read_csv(\"..\/input\/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")","6abf7d14":"data2 = df2[[\"id\",\"reviews.text\",\"reviews.rating\"]]\ndata3 = df3[[\"id\",\"reviews.text\",\"reviews.rating\"]]","505545da":"data2 = data2[data2[\"reviews.rating\"]<=3]\ndata3 = data3[data3[\"reviews.rating\"]<=3]","1ddae12f":"len(data2), len(data3)","c3d61b0e":"plt.figure(figsize=(10,5))\nsns.countplot(data2['reviews.rating'])\nplt.title('Count ratings')\nplt.show()","d8217db5":"plt.figure(figsize=(10,5))\nsns.countplot(data3['reviews.rating'])\nplt.title('Count ratings')\nplt.show()","9a91c97b":"frames = [data, data2, data3]\nfinal = pd.concat(frames)","dadaee75":"plt.figure(figsize=(10,5))\nsns.countplot(final['reviews.rating'])\nplt.title('Count ratings')\nplt.show()","146e1059":"final.head()","eba34ca3":"#lower case all text\nfinal[\"reviews.text\"]=final[\"reviews.text\"].str.lower() \n\n#tokenization of words\nfinal['reviews.text'] = final.apply(lambda row: word_tokenize(row['reviews.text']), axis=1) \n\n#only alphanumerical values\nfinal[\"reviews.text\"] = final['reviews.text'].apply(lambda x: [item for item in x if item.isalpha()]) \n\n#lemmatazing words\nfinal['reviews.text'] = final['reviews.text'].apply(lambda x : [WordNetLemmatizer().lemmatize(y) for y in x])\n\n#removing useless words\nstop = stopwords.words('english')\nfinal['reviews.text'] = final['reviews.text'].apply(lambda x: [item for item in x if item not in stop])\n","7085fd14":"final[\"reviews.text\"] = final[\"reviews.text\"].apply(lambda x: str(' '.join(x))) #joining all tokens","2cbec47c":"final.head()","40845afd":"sentiment = {1: 0,\n            2: 0,\n            3: 0,\n            4: 1,\n            5: 1}\n\nfinal[\"sentiment\"] = final[\"reviews.rating\"].map(sentiment)","1e047a19":"final.head()","1896dcea":"len(final[final[\"sentiment\"]==0]),len(final[final[\"sentiment\"]==1])","2e3ab047":"# building tfidf matrix to train models \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer =TfidfVectorizer(max_df=0.9)\ntext = vectorizer.fit_transform(final[\"reviews.text\"])","717dba90":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(text, final[\"sentiment\"], test_size=0.3, random_state=1)\n\n","ef7d0c74":"# try logistic regression first\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=1)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)\n","4cd1a570":"print('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","39afcc06":"from sklearn.metrics import classification_report\nprint(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","1049a28d":"# Random Forests\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)\n\n","b500811e":"print('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","87e22353":"print(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","136cf8f1":"from sklearn.model_selection import GridSearchCV\nparameters = {\"n_estimators\": [10,50,100,200],\n             \"criterion\":(\"gini\",\"entropy\")}\nclassifier = RandomForestClassifier()\nclf = GridSearchCV(classifier, parameters, cv=5)\nclf.fit(x_train, y_train)","bd28f838":"#Viewing best parameters in Grid Search\nbest_parameter = clf.best_params_\nbest_accuracy = clf.best_score_ #best cros validated mean\nprint('Best parameter: ' + str(best_parameter))\nprint('Best accuracy: ' + str(best_accuracy))","33029ac6":"classifier = RandomForestClassifier(criterion = best_parameter[\"criterion\"], \n                                    n_estimators = best_parameter[\"n_estimators\"])\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)\nprint('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","67723a41":"print(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","f51470f3":"sentiment = {1: 0,\n            2: 0,\n            3: 1,\n            4: 2,\n            5: 2}\n\nfinal[\"sentiment\"] = final[\"reviews.rating\"].map(sentiment)","c7b5eb65":"final.head()","9d916bb1":"len(final[final[\"sentiment\"]==0]),len(final[final[\"sentiment\"]==1]),len(final[final[\"sentiment\"]==2])","7d3c1d60":"# building tfidf matrix to train models \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer =TfidfVectorizer(max_df=0.9)\ntext = vectorizer.fit_transform(final[\"reviews.text\"])","ba2336b9":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(text, final[\"sentiment\"], test_size=0.3, random_state=1)\n\n","e2ad9878":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=1)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)\n","9aac5cde":"print('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","bc296879":"from sklearn.metrics import classification_report\nprint(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","3b7f05c4":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)\n\n","f2a806e7":"print('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","61ff2a5d":"print(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","1921be03":"parameters = {\"n_estimators\": [10,50,100,200],\n             \"criterion\":(\"gini\",\"entropy\")}\nclassifier = RandomForestClassifier()\nclf = GridSearchCV(classifier, parameters, cv=5)\nclf.fit(x_train, y_train)\n","98795c78":"#Viewing best parameters in Grid Search\nbest_parameter = clf.best_params_\nbest_accuracy = clf.best_score_ #best cros validated mean\nprint('Best parameter: ' + str(best_parameter))\nprint('Best accuracy: ' + str(best_accuracy))","da27f8e0":"classifier = RandomForestClassifier(criterion = best_parameter[\"criterion\"] , \n                                    n_estimators = best_parameter[\"n_estimators\"])\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_pred_tr = classifier.predict(x_train)","e9cff41e":"print('Test accuracy', sum(y_test == y_pred)\/len(y_test))\nprint('Train accuracy', sum(y_train == y_pred_tr)\/len(y_train))","1fa3fd84":"print(\"Classification Report(Train)\")\nprint(classification_report(y_train, y_pred_tr))\nprint(\"Classification Report(Test)\")\nprint(classification_report(y_test, y_pred))","42da28bc":"from keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, GRU, Dropout, LSTM\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam","ceab1c4f":"t = Tokenizer()","0fba9669":"t.fit_on_texts(final[\"reviews.text\"])","1aad05dc":"max_length = max([len(s.split()) for s in final[\"reviews.text\"] ])\nmax_legth=max_length #the max length is aroun 1000 character. I would keep it shorter. ","ed4650f5":"vocab_size = len(t.word_index)+1","1f23466a":"X_train, X_test, y_train, y_test = train_test_split(final[\"reviews.text\"], final[\"sentiment\"], test_size=0.25)\n","62e09b36":"X_train = t.texts_to_sequences(X_train)\nX_test = t.texts_to_sequences(X_test)","58aeeb52":"X_train = pad_sequences(X_train, maxlen=max_length, padding = \"post\",truncating = \"post\")\nX_test = pad_sequences(X_test, maxlen=max_length, padding = \"post\", truncating = \"post\")","7bfb9c23":"X_train = X_train[0:28290]\ny_train = y_train[0:28290]\nX_test = X_test[0:9430]\ny_test = y_test[0:9430]\nlen(y_test),len(X_test),len(X_train),len(y_train)","fbfab4e8":"from keras.utils import np_utils #converting to categorical\ny_train = np_utils.to_categorical(y_train, num_classes=3)\ny_test = np_utils.to_categorical(y_test, num_classes=3)","1c190729":"embedding_dim = 200\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\nmodel.add(LSTM(units = 32))\nmodel.add(Dense(3,activation=\"softmax\")) #since converted to categorical we will have three output nodes. softmax\n                                         # assigns a probability distribution\n    \nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\nmodel.fit(X_train, y_train, batch_size=10, epochs=3)","ef40b3c4":"model.evaluate(x=X_test, y=y_test, batch_size=10)\n","33a50f36":"We can see how there are a total of 42 products (from the ID). Meaning that for every product we will have a mix of reviews (positive, neutral or negative).","2e217ac9":"The situation hasn't improved a lot but hopefully it will make a difference when training the model later on. A further approach could be to undersample the positive reviews. ","0fec806d":"Again we can see how it is heavily biased towards the positive sentiment. ","846aa7c7":"We can see how the data is heavily biased to positive sentiments. One way to fix this would be to undersample the positive sentiments. Beofre doing this I would like to verify how the model will perform with these values.","7dd3cd5e":"Now that all three datasets are available I will concatenate them together.","ca6f1454":"The dataset has been obtained by the following kaggle link: https:\/\/www.kaggle.com\/datafiniti\/consumer-reviews-of-amazon-products\n\nThis dataset is provided by Datafiniti's Product Database and it includes product information, rating and reviews for all products.\n\nI have tried to implement a sentiment analysis based on the ratings and the reviews.","0642c78b":"Verifying if the data is a little bit less biased","7a64f20c":"Since we are only provided with the ratings of the products we will try to assign a sentiment to all of the ratings. To do so we will consider a positive sentiment (1) when the ratings are 4 and 5. On the other hand, a negative sentiment (0) when the rating is 1,2 and 3. \n\nEventually we will add an additional neutral sentiment.\n","8cfad046":"# Exploratory Data Analysis\n\nWe will start be veryfing what are the most common words used in the text reviews using a word cloud. However, since we haven't done the preprocessing before we might view some words that give little meaning to the sentiment of the text. ","828513a1":"# Model Selection","f809fa60":"# Conclusions","7e68b379":"We can clearly see how the reviews are heavily biased towards positive reviews. 4 and 5 ratings are extremely high and the averages are all above 3. To try and balance things out I will upload the other two csv files and get only the reviews that have ratings lower or equal to 3. So we are trying to oversample the lower rating reviews.","17c5590c":"# RNN\n\nSentiment analysis can obtain wonderful results using RNN. Please find the code below with the training process uncomplete.","1cddec96":"# 3 Labels\nTrying with neutral, negative and positive","765d913c":"As expected there are words that have have no importance with the sentiment of the comment, such as: use, device, time etc. \nNow I will perform a word count of certain words that could describe the sentiment in a better way.","80a6da59":"The overall performance has improved. We can see that the precision of the 0 label as increased, and so did the f1 score\n\nWe can say that the overall performance is satisfactory and we can proceed by trying to add a third label, the neutral sentiment value.\n","6174d779":"Test and train accuracies are high, however, we must consider that the data is heavily biased towards positive reviews. Thus, the accuracies might not reflect if the model has learnt how to detect negative sentiments.","59e99f41":"Very low F1 score for the test data set for the undersampled data sets. We'll try with the Randm Forest algorithm again.","7aa9a66c":"There is a slight improvement with the random forest compared to the logit model. Let's try increasing the scores by using the grid search one more time and tune the parameters. ","106c8600":"We can observe a small improvement in the different scores.","abc06fa3":"From the columns presented what we are really interested in working with to complete the sentiment analysis would be the reviews.text and reviews.rating. ","1e617127":"We can see how one review.text is missing, hence no analysis can be done on this sample. We can then remove it. Furthermore, there are 32 missing values for the ratings. Due to the low number of missing values in the rating column it is possible to substitute the NaN with the mean of the others or we could simply remove those samples. Since we would have many samples anyway they can be simply removed.","5065540f":"Most of the comments seem positive.\nNow one thing that can be done is to view the average rating for every product. Unfortunately, the products are not well defined with a name due to the decision previously taken, but I will use the ID of the dataframe to represent the different products. ","d6225353":"We can see an improvement in the precision, recall and f1 score for both classes. Even though the negative sentiment in the test data set has  a score of 0.71 for the f1 score, which is still an improvement from before\n\nLet's try to improve this by using a 5-fold cross validation for parameter tuning.","a020abe8":"From the models evaluated we can say that the three label sentiment analysis provieds good enough results. However, it can be improved by balancing the dataset. Either increasing the number of negative and neutral labels or by decreasing the positive labels. The f1, precision and recall overall score of the latest Random Forest model has good results. ","550fbdae":"By using the precision, recall and f1-score on every label we can verify how well the model has learnt to classify each label. The test and train scores are not that good for the negative reviews. We will try then to use another model, Random Forests.\n\nThey are extremely powerful for non linear data, furthermore they are extremely useful with unbalanced data sets. This is because they try to minimize the error rate. Lastly, they are less likely to overfitting as it is an ensemlbe algorithm.  ","5b6836de":"# Preprocessing Text"}}