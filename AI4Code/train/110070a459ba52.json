{"cell_type":{"f197d8ea":"code","a70abb5c":"code","f1ba03d4":"code","3330f341":"code","ce5dcb85":"code","83db51fe":"code","1ee6873c":"code","bacc73ac":"code","db94cc26":"code","e829339f":"code","6eca851c":"code","7f4599e3":"code","7a489ce1":"code","e8ad06c1":"markdown","acb3d6af":"markdown","f6a88c30":"markdown","ce851974":"markdown","fee7b37b":"markdown","e8ddb03b":"markdown","9da83b47":"markdown","0796afc7":"markdown","c8c4eac2":"markdown","d9ad5783":"markdown","84241fb9":"markdown","9eca1fff":"markdown","464c34a2":"markdown"},"source":{"f197d8ea":"import numpy as np \nimport pandas as pd \n\nfrom sklearn import ensemble\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","a70abb5c":"SEED = 42 \nNFOLDS = 5 \nTARGET = \"Survived\"","f1ba03d4":"class SklearnHelper(object):\n    def __init__(self, clf, seed = 0, params = None):\n        params['random_state'] = seed\n        self.clf = clf(**params) \n        \n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n        \n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self, x, y):\n        return self.clf.fit(x, y)\n    \n    def feature_importances(self, x, y):\n        print(self.clf.fit(x, y).feature_importances_)\n        \ndef get_oof(clf, x_train, y_train, x_test,ntrain,ntest):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n    \n    kf = KFold(n_splits=NFOLDS, random_state=SEED) \n    \n    for i, (train_index, val_index) in enumerate(kf.split(x_train)):\n        x_train_part = x_train[train_index]\n        y_train_part = y_train[train_index]\n        x_val_part = x_train[val_index]\n       \n        clf.fit(x_train_part, y_train_part)\n        \n        oof_train[val_index] = clf.predict(x_val_part)\n        oof_test_skf[i, :] = clf.predict(x_test)\n        \n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","3330f341":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","ce5dcb85":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","83db51fe":"ntrain = train.shape[0]\nntest = test.shape[0]\n\ny_train = train[TARGET]\ntrain = train.drop([TARGET], axis=1)\nx_train = train.values \nx_test = test","1ee6873c":"rf_params = {\n    'n_jobs': -1,\n    'n_estimators': 1000,\n    'warm_start': True,\n    'max_depth': 5,\n    'max_features': 'sqrt',\n    'verbose': 1\n}\n\net_params = {\n    'n_jobs': -1,\n    'n_estimators': 1000,\n    'max_depth': 5,\n    'verbose': 1\n}\n\n\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)","bacc73ac":"et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test,ntrain,ntest) \nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test,ntrain,ntest) ","db94cc26":"x_train = np.concatenate((et_oof_train, rf_oof_train), axis = 1)\nx_test = np.concatenate((et_oof_test, rf_oof_test), axis = 1)","e829339f":"gbm = xgb.XGBClassifier(\n    n_estimators = 2000,\n    max_depth = 4,\n    objective = 'binary:logistic'\n).fit(x_train, y_train)","6eca851c":"y_train_pred = cross_val_predict(gbm, x_train, y_train, cv=3)\nprint( confusion_matrix(y_train, y_train_pred) )\n\nprint(\"\")\n\nprint(\"precision_score1:\",precision_score(y_train, y_train_pred) )\ncm = confusion_matrix(y_train, y_train_pred)\nprint(\"precision_score2:\",cm[1, 1] \/ (cm[0, 1] + cm[1, 1]) )\n\nprint(\"\")\n\nprint(\"recall_score1:\",recall_score(y_train, y_train_pred))\nprint(\"recall_score2:\",cm[1, 1] \/ (cm[1, 0] + cm[1, 1]) )\n\nprint(\"\")\n\nprint(\"f1_score1:\",f1_score(y_train, y_train_pred))\nprint(\"f1_score2:\", cm[1, 1] \/ (cm[1, 1] + (cm[1, 0] + cm[0, 1]) \/ 2) )\n\nprint(\"\")\n\nprint(\"roc_auc score\",roc_auc_score(y_train, y_train_pred) )","7f4599e3":"predictions = gbm.predict(x_test)","7a489ce1":"sub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsub[\"Survived\"] = predictions\nsub.to_csv('submission.csv', index=False)\nsub.head()","e8ad06c1":"# common variables","acb3d6af":"# import libraries","f6a88c30":"# Evaluate Model","ce851974":"# define element models","fee7b37b":"# preprocess","e8ddb03b":"# common functions","9da83b47":"# predict test data using stacking one model","0796afc7":"# get oof using element models ","c8c4eac2":"# submission","d9ad5783":"# split data","84241fb9":"# build model by new train data and new test data ","9eca1fff":"# make new train data,test data by stacking process","464c34a2":"# load data"}}