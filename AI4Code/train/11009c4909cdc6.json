{"cell_type":{"d3dc976b":"code","15320617":"code","57e12ba6":"code","a5f326e1":"code","615b3852":"code","e7e67983":"code","ecaf369c":"code","690e8c50":"code","375bcf3b":"code","22d06542":"code","4c2b851a":"code","65126b93":"code","34e9500c":"code","44dbcb84":"code","4abd04ec":"code","2690dd66":"code","41658fbb":"code","8732a688":"code","1792976b":"code","813f428b":"code","dc7e51e9":"code","062bcfa1":"code","7c6d84fc":"code","88fe2792":"code","2e16351f":"code","53927111":"code","2cc775fe":"code","df16562e":"code","176bdea8":"code","e5018442":"code","01cc38a8":"code","325855fc":"code","e0b688f0":"code","bcd873bb":"code","a4cef512":"code","f1d4bbb2":"code","e7b8a130":"markdown","bb1ded7b":"markdown","5415ba5b":"markdown","d3653de8":"markdown","73044283":"markdown","02bc24f2":"markdown","abbd6bc9":"markdown","9a6614d3":"markdown","58a1b36f":"markdown","0c89078e":"markdown","d32ab0f1":"markdown","1a9df8a9":"markdown","c9918061":"markdown","fc2dbe32":"markdown","f1c73f68":"markdown","db0b097e":"markdown","425ce7e3":"markdown","aceefae9":"markdown","9bdc68c9":"markdown","5ebfcf1c":"markdown","98bff760":"markdown","090de712":"markdown","df03a280":"markdown","ec1b0a27":"markdown","a56f99d3":"markdown","3a191461":"markdown","9bc9850b":"markdown","0478487d":"markdown","2c501c09":"markdown"},"source":{"d3dc976b":"import numpy as np\nimport pandas as pd\nimport sqlite3\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tqdm.auto import tqdm\n\ntfd = tfp.distributions\ntfb = tfp.bijectors\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('max_columns', 50)\n\nimport warnings\nwarnings.filterwarnings('ignore')","15320617":"# data is stored in SQL DB, so we need to establish a connection with it\n# let's use SQLite3 and Pandas for it\n\n# create engine for connection\nengine = sqlite3.connect('..\/input\/soccer\/database.sqlite')\n\n# connect and get dfs\nmatches = pd.read_sql_query('SELECT * FROM Match', con=engine)\nteams = pd.read_sql_query('SELECT * FROM Team', con=engine)\ncountries = pd.read_sql_query('SELECT * FROM Country', con=engine)","57e12ba6":"matches.head()","a5f326e1":"teams.head()","615b3852":"countries.head()","e7e67983":"# let's merge all dataframes\ndf = pd.merge(matches, teams, left_on=['home_team_api_id'], right_on=['team_api_id'])\ndf = df.merge(teams, left_on=['away_team_api_id'], right_on=['team_api_id'],\n              suffixes=('_home', '_away'))\ndf = df.merge(countries, left_on=['country_id'], right_on=['id'])\n\ndf.sample(5)","ecaf369c":"def get_league_year_data(df, season, country):\n    mask_league = df.season == season\n    mask_country = df.name == country\n    return df.loc[mask_league & mask_country].reset_index(drop=True)","690e8c50":"# params\nseason = '2015\/2016'\ncountry = 'Italy'\ndf_italy = get_league_year_data(df, season, country)\n\ndf_italy.sample(5)","375bcf3b":"def get_training_data(df_season, stage):\n    mask_stage = df_season.stage <= stage\n    return df_season.loc[mask_stage]\n\n# params\ntraining_stage = 19\ndf_train = get_training_data(df_italy, training_stage)\n\n# check max stage\ndf_train.stage.max() # 19","22d06542":"# let's have a look at partial standings up to stage 19\ndef get_standing(df_season, partial=None):\n    '''function to calculate (partial) standings.\n    If `partial` params is passed, then the standing is calculated up to that stage.\n    \n    Win: 3pts\n    Draw: 1pt\n    Lose: 0pt\n    '''\n    aux = df_season.copy()\n    if partial is not None:\n        aux = aux.loc[aux.stage <= partial]\n    # create flag for each results, home and away\n    aux['home_win'] = aux['home_team_goal'] > aux['away_team_goal'] # home win\n    aux['draw'] = aux['home_team_goal'] == aux['away_team_goal'] # draw\n    aux['away_win'] = aux['home_team_goal'] < aux['away_team_goal'] # away win\n    \n    # columns for standings\n    # we will groupby team and count home and away performance\n    rename_home = {\n        'team_long_name_home': 'Team',\n        'home_team_goal': 'H-GF', # home goals for\n        'away_team_goal': 'H-GA', # home goals against\n        'home_win': 'H-W',        # home wins\n        'draw': 'H-D',            # home draws\n        'away_win': 'H-L',        # home losses\n        'stage': 'H-Played',      # home played\n    }\n    # away is inverted\n    rename_away = {\n        'team_long_name_away': 'Team',\n        'home_team_goal': 'A-GA', # away goals for\n        'away_team_goal': 'A-GF', # away goals against\n        'home_win': 'A-L',        # away wins\n        'draw': 'A-D',            # away draws\n        'away_win': 'A-W',        # away losses\n        'stage': 'A-Played',      # away played\n    }\n    # agg to calculate (all sums except played that is count)\n    home_agg = {col: 'sum' for col in rename_home.values() \n                if 'Played' not in col \n                if 'Team' not in col}\n    home_agg['H-Played'] = 'count'\n    away_agg = {col: 'sum' for col in rename_away.values() \n                if 'Played' not in col \n                if 'Team' not in col}\n    away_agg['A-Played'] = 'count'\n    # generating DFs\n    home_tmp = aux.rename(columns=rename_home).groupby('Team').agg(home_agg).astype(int)\n    away_tmp = aux.rename(columns=rename_away).groupby('Team').agg(away_agg).astype(int)\n    # adding partial results\n    standings = pd.concat([home_tmp, away_tmp], axis=1)\n    # get overall stats\n    standings['Played'] = standings['H-Played'] + standings['A-Played']\n    standings['W'] = standings['H-W'] + standings['A-W']\n    standings['D'] = standings['H-D'] + standings['A-D']\n    standings['L'] = standings['H-L'] + standings['A-L']\n    # goals\n    standings['GF'] = standings['H-GF'] + standings['A-GF']\n    standings['GA'] = standings['H-GA'] + standings['A-GA']\n    # goals diff\n    standings['H-GD'] = standings['H-GF'] + standings['H-GA']\n    standings['A-GD'] = standings['A-GF'] + standings['A-GA']\n    standings['GD'] = standings['H-GD'] + standings['A-GD']\n    # points\n    standings['H-Pts'] = standings['H-W'] * 3 + standings['H-D'] * 1\n    standings['A-Pts'] = standings['A-W'] * 3 + standings['A-D'] * 1\n    standings['Pts'] = standings['H-Pts'] + standings['A-Pts']\n    # sort by pts, then Wins, then GF\n    cols_order = ['Pts', 'Played', 'W', 'D', 'L', 'GF', 'GA', 'GD',\n                  'H-Pts', 'H-Played', 'H-W', 'H-D', 'H-L', 'H-GF', 'H-GA', 'H-GD',\n                  'A-Pts', 'A-Played', 'A-W', 'A-D', 'A-L', 'A-GF', 'A-GA', 'A-GD',]\n    return standings.sort_values(by=['Pts', 'W', 'GF'], ascending=False)[cols_order]","4c2b851a":"get_standing(df_italy, 19)","65126b93":"# we should first label encode the teams\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(np.concatenate((df_train['team_long_name_home'].unique(), \n                       df_train['team_long_name_away'].unique())))\n\ndf_train['home_team_new_id'] = le.transform(df_train['team_long_name_home'])\ndf_train['away_team_new_id'] = le.transform(df_train['team_long_name_away'])","34e9500c":"home_team = df_train['home_team_new_id'].values\naway_team = df_train['away_team_new_id'].values\nhome_score = tf.cast(df_train['home_team_goal'], tf.float32)\naway_score = tf.cast(df_train['away_team_goal'], tf.float32)\nscores = (home_score, away_score)\nnum_home_teams = df_train['team_long_name_home'].nunique()\nnum_away_teams = df_train['team_long_name_away'].nunique()","44dbcb84":"# thanks for Junpeng Lao's help (https:\/\/github.com\/tensorflow\/probability\/issues\/601)\n\nRoot = tfd.JointDistributionCoroutine.Root\ndef model():  # <== need to be a model with no input and no return\n    # Home attack rate\n    attack_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n    attack_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n    attack_rate_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n    attack_rate = attack_hyper + attack_rate_nc * attack_hyper_sd\n    # Away defense rate\n    defense_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n    defense_rate_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_away_teams))\n    defense_rate = defense_rate_nc * defense_hyper_sd\n    # Home attack advantage\n    home_attack_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n    home_attack_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n    home_attack_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n    home_attack_advantage = home_attack_hyper + home_attack_nc * home_attack_hyper_sd\n    # Home defense advantage\n    home_defense_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n    home_defense_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n    home_defense_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n    home_defense_advantage = home_defense_hyper + home_defense_nc * home_defense_hyper_sd\n    # Likelihood\n    home_diff = tf.gather(attack_rate, home_team, axis=-1) - \\\n              tf.gather(defense_rate, away_team, axis=-1) + \\\n              tf.gather(home_attack_advantage, home_team, axis=-1)\n\n    away_diff = tf.gather(attack_rate, away_team, axis=-1) - \\\n              tf.gather(defense_rate, home_team, axis=-1) - \\\n              tf.gather(home_defense_advantage, home_team, axis=-1)\n    home_goals = yield tfd.Independent(tfd.Poisson(log_rate=home_diff), 1)\n    away_goals = yield tfd.Independent(tfd.Poisson(log_rate=away_diff), 1)\n  \nmodel_jd = tfd.JointDistributionCoroutine(model)","4abd04ec":"# we need log prob for running MCMC chains\nunnomarlized_log_prob = lambda *args: model_jd.log_prob(list(args) + [\n    home_score[tf.newaxis, ...], away_score[tf.newaxis, ...]])\n\n# number of parallel chains\nnum_chains = 5\n\n# initial states (random samples from model)\ninitial_state = model_jd.sample(num_chains)[:-2] # except last two, which we are estimating","2690dd66":"# space constraints\n# identity (no constraint) for all rate params\n# exp for standard deviations params (tau), since it must be positive\nunconstraining_bijectors = [\n  tfb.Identity(),\n  tfb.Exp(),\n  tfb.Identity(),\n  tfb.Exp(),\n  tfb.Identity(),\n  tfb.Exp(),\n  tfb.Identity(),\n  tfb.Identity(),\n  tfb.Exp(),\n  tfb.Identity(),\n  tfb.Identity(),\n]","41658fbb":"@tf.function(autograph=False)\ndef run_chain(init_state, step_size, number_of_steps=1000, burnin=50):\n\n  def trace_fn(_, pkr):\n    return (\n        pkr.inner_results.inner_results.target_log_prob,\n        pkr.inner_results.inner_results.leapfrogs_taken,\n        pkr.inner_results.inner_results.has_divergence,\n        pkr.inner_results.inner_results.energy,\n        pkr.inner_results.inner_results.log_accept_ratio\n    )\n  unrolled_kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n      tfp.mcmc.TransformedTransitionKernel(\n          inner_kernel=tfp.mcmc.NoUTurnSampler(\n              target_log_prob_fn=unnomarlized_log_prob,\n              step_size=step_size),\n          bijector=unconstraining_bijectors),\n    num_adaptation_steps=burnin,\n    step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(  # pylint: disable=g-long-lambda\n        inner_results=pkr.inner_results._replace(step_size=new_step_size)\n    ),\n    step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n    log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,\n    )\n\n  # Sampling from the chain.\n  mcmc_trace, sampler_stats = tfp.mcmc.sample_chain(\n      num_results=number_of_steps,\n      num_burnin_steps=burnin,\n      current_state=init_state,\n      kernel=unrolled_kernel,\n      trace_fn=trace_fn)\n  return mcmc_trace, sampler_stats","8732a688":"%%time\n# params\nnchain_adapt = 100\ninitial_state = list(model_jd.sample(num_chains)[:-2])\n\nnumber_of_steps = 2000\nburnin = 500\ninit_step_size = [tf.ones_like(x) for x in initial_state]\n\n# mcmc\nmcmc_trace, sampler_stats = run_chain(initial_state, init_step_size, \n                                      number_of_steps, burnin)","1792976b":"# forest plots\ndef forest_plot(num_chains, num_vars, var_name, var_labels, samples):\n    fig, axes = plt.subplots(\n        1, 2, figsize=(12, 15), sharey=True, gridspec_kw={'width_ratios': [3, 1]})\n    for var_idx in range(num_vars):\n        values = samples[..., var_idx]\n        rhat = tfp.mcmc.diagnostic.potential_scale_reduction(values).numpy()\n        meds = np.median(values, axis=-2)\n        los = np.percentile(values, 5, axis=-2)\n        his = np.percentile(values, 95, axis=-2)\n\n        for i in range(num_chains):\n            height = 0.0 + var_idx + 0.05 * i\n            axes[0].plot([los[i], his[i]], [height, height], 'C0-', lw=2, alpha=0.5)\n            axes[0].plot([meds[i]], [height], 'C0o', ms=1.5)\n        axes[1].plot([rhat], [height], 'C0o', ms=4)\n\n    axes[0].set_yticks(np.arange(0, num_vars))\n    axes[0].set_ylim(0, num_vars)\n    axes[0].grid(which='both')\n    axes[0].invert_yaxis()\n    axes[0].set_yticklabels(var_labels)\n    axes[0].xaxis.set_label_position('top')\n    axes[0].set(xlabel='95% Credible Intervals for {}'.format(var_name))\n\n    axes[1].set_xticks([1, 2])\n    axes[1].set_xlim(0.95, 2.05)\n    axes[1].grid(which='both')\n    axes[1].set(xlabel='R-hat')\n    axes[1].xaxis.set_label_position('top')\n\n    plt.show()","813f428b":"forest_plot(num_chains, len(le.classes_), 'Attack Rate NC', le.classes_, mcmc_trace[2])","dc7e51e9":"forest_plot(num_chains, len(le.classes_), 'Defense Rate NC', le.classes_, mcmc_trace[4])","062bcfa1":"forest_plot(num_chains, len(le.classes_), 'Home Attack Advantage NC', le.classes_, mcmc_trace[7])","7c6d84fc":"forest_plot(num_chains, len(le.classes_), 'Home Defense Advantage NC', le.classes_, mcmc_trace[10])","88fe2792":"# we need a df with future matches and properly encoded teams\ndf_future = df_italy.loc[df_italy.stage > 19]\n\n# encode\ndf_future['home_team_new_id'] = le.transform(df_future['team_long_name_home'])\ndf_future['away_team_new_id'] = le.transform(df_future['team_long_name_away'])\n\n# bookkeeping\nhome_team_future = df_future['home_team_new_id'].values\naway_team_future = df_future['away_team_new_id'].values","2e16351f":"# future model\n# we only need to change the last two parameters, which now receive future matches home and away team codes\n\ndef future_model():  # <== need to be a model with no input and no return\n  # Home attack rate\n  attack_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n  attack_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n  attack_rate_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n  attack_rate = attack_hyper + attack_rate_nc * attack_hyper_sd\n  # Away defense rate\n  defense_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n  defense_rate_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_away_teams))\n  defense_rate = defense_rate_nc * defense_hyper_sd\n  # Home attack advantage\n  home_attack_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n  home_attack_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n  home_attack_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n  home_attack_advantage = home_attack_hyper + home_attack_nc * home_attack_hyper_sd\n  # Home defense advantage\n  home_defense_hyper_sd = yield Root(tfd.Sample(tfd.Gamma(concentration=2., rate=2.), 1))\n  home_defense_hyper = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), 1))\n  home_defense_nc = yield Root(tfd.Sample(tfd.Normal(loc=0., scale=1.), num_home_teams))\n  home_defense_advantage = home_defense_hyper + home_defense_nc * home_defense_hyper_sd\n  # Likelihood (this is what is changed, so that tf.gather works as expected)\n  home_diff = tf.gather(attack_rate, home_team_future, axis=-1) - \\\n              tf.gather(defense_rate, away_team_future, axis=-1) + \\\n              tf.gather(home_attack_advantage, home_team_future, axis=-1)\n\n  away_diff = tf.gather(attack_rate, away_team_future, axis=-1) - \\\n              tf.gather(defense_rate, home_team_future, axis=-1) - \\\n              tf.gather(home_defense_advantage, home_team_future, axis=-1)\n  home_goals = yield tfd.Independent(tfd.Poisson(log_rate=home_diff), 1)\n  away_goals = yield tfd.Independent(tfd.Poisson(log_rate=away_diff), 1)\n  \nfuture_model_jd = tfd.JointDistributionCoroutine(future_model)","53927111":"%%time\n# posterior predictive given mcmc trace\ndists, _ = future_model_jd.sample_distributions(value=mcmc_trace)\n# take only the last two (home and away goals)\nhome_goals_future, away_goals_future = dists[-2], dists[-1]","2cc775fe":"# sample from taken distributions\n# the shape from a single sample() pass is shape=(2000, 5, 190)\n# so, we essentially have 2k * 5 = 10k samples for each of the remaining 190 matches (10 matches per round * 19 rounds)\nhome_goals_pred = home_goals_future.sample()\naway_goals_pred = away_goals_future.sample()","df16562e":"home_goals_pred.shape","176bdea8":"# generate dataframe with results\nfrom scipy import stats\n\n# probability of each result (mean over all chains, which)\ndf_future['proba_home'] = (tf.sign(home_goals_pred - away_goals_pred) == 1).numpy().mean(axis=(0, 1))\ndf_future['proba_draw'] = (tf.sign(home_goals_pred - away_goals_pred) == 0).numpy().mean(axis=(0, 1))\ndf_future['proba_away'] = (tf.sign(home_goals_pred - away_goals_pred) == -1).numpy().mean(axis=(0, 1))","e5018442":"cols_to_display = ['stage', 'date', \n                   'team_long_name_home',\n                   'team_long_name_away',\n                   'proba_home', 'proba_draw', 'proba_away']\ndf_future[cols_to_display].head(10)","01cc38a8":"# get numpy preds\nhome_goals_pred_np = home_goals_pred.numpy().reshape(-1, 190)\naway_goals_pred_np = away_goals_pred.numpy().reshape(-1, 190)","325855fc":"# example of simulated competition \ndef get_simulated_competition(df_1, df_2, preds, simulation_ix=10):\n    # re\n    df_1_nodup = df_1.loc[:,~df_1.columns.duplicated()]\n    df_2_nodup = df_2.loc[:,~df_2.columns.duplicated()]\n    # stage preds\n    df_2_nodup['home_team_goal'] = preds[0][simulation_ix] # home\n    df_2_nodup['away_team_goal'] = preds[1][simulation_ix] # away\n    \n    full_df = pd.concat([df_1_nodup, df_2_nodup], axis=0, \n                        ignore_index=True, sort=False)\n    final_standing = get_standing(full_df)\n    \n    return final_standing\n\nget_simulated_competition(df_train, df_future, (home_goals_pred_np, away_goals_pred_np))","e0b688f0":"def get_simulated_standing_dist(df_1, df_2, preds, n_simulations=10):\n    # placeholder\n    sim_results = pd.DataFrame()\n    for sim in tqdm(range(n_simulations)):\n        # get standing\n        final_standing_sim = get_simulated_competition(\n            df_1, df_2, preds, simulation_ix=sim)\n        final_standing_sim['position'] = np.arange(1, len(le.classes_)+1) # positions in order\n        final_standing_sim['sim_number'] = sim                            # sim_number\n        # concat with results df by index\n        sim_results = sim_results.append(final_standing_sim[['position', 'sim_number']])\n    \n    return sim_results","bcd873bb":"simulations = get_simulated_standing_dist(\n    df_train, df_future, (home_goals_pred_np, away_goals_pred_np),\n    n_simulations=10000)","a4cef512":"# source: http:\/\/gijskoot.nl\/bayesian\/sports\/soccer\/predictions\/pymc3\/2018\/02\/07\/knvb-model.html\nrankings_agg = simulations.reset_index().groupby('Team').position.value_counts(normalize=True).unstack(1).fillna(0)\nrankings_agg = rankings_agg.assign(expected=rankings_agg @ np.arange(len(le.classes_) + 1, 1, -1))\\\n    .sort_values(\"expected\", ascending=False).drop(\"expected\", axis = \"columns\")\n\nplt.figure(figsize=(12, 8))\nsns.heatmap(rankings_agg, annot=True, fmt=\".0%\", cbar=False, cmap=\"hot\", square=True)\nplt.title('Predictions | As of round 19');","f1d4bbb2":"get_standing(df_italy)","e7b8a130":"### MCMC","bb1ded7b":"**Example of simulated competition**","5415ba5b":"Now that we are satisfied with our estimated parameters, let's run predictions from all remaining games.\n\nIt is worth noticing that is a prediction with estimated parameters up to round 19, but in practice, the parameters should be updated at every match or round and so the predictions.","d3653de8":"## Analysis","73044283":"## Coding","02bc24f2":"## Create \"Future Model\"  \nthis model is just the workaround to run posterior predictive, i.e. generate future match results given the trace previously estimated","abbd6bc9":"(results are ok, validated [here](https:\/\/www.worldfootball.net\/schedule\/ita-serie-a-2015-2016-spieltag\/19\/))\n\nWe expect, intuitively, that the teams with most Goal For (`GF`) get higher estimated attack rate than those with fewer goals scored. The same (inverted) logic applied for defense rate, i.e. teams with least goals against should have stronger defense rate.\n\nFor home advantage, we should see Fiorentina and Roma, for example, with stronger estimated parameters for both attack and defense at home.","9a6614d3":"The rankings probabilities are very spread out, as expected, since there is half tournament to go.","58a1b36f":"### Read SQL Data ","0c89078e":"---\nPlease feel free to reach me out in case of any doubts and for any suggestion.  ","d32ab0f1":"# Multilevel Bayesian Model for Soccer Match Predictions","1a9df8a9":"Our training data will be first leg of each match, i.e. up to round 19 (or stage 19)","c9918061":"## Results","fc2dbe32":"# Modelling","f1c73f68":"## Posterior Predictive","db0b097e":"### Model with TFP","425ce7e3":"### Selecting a league to work on","aceefae9":"### Label Encode","9bdc68c9":"---\nThe basically idea of this multilevel model is to model each team, home and away, probability density of score a goal. The final result of the match is, therefore, the difference between scored home and away goals.  \n\nThe framework starts by modelling attacking and defense rate for each team, but tries to consider a home advantage for the home team. Therefore, the model assumptions are the following:\n\nThe purpose of this work is to model the posterior distribution of home and away goals for each match as follows:\n\n**likelihoods**\n\\begin{align}\nhomegoals &\\sim Poisson(\\exp{(homediff)}) \\\\\nawaygoals &\\sim Poisson(\\exp{(awaydiff)})\n\\end{align}\n\n\n**priors**\n\\begin{align}\nhomediff &= AttRate_{home} - DefRate_{away} + HomeAttAdvantage_{home} \\\\\nawaydiff &= AttRate_{away} - DefRate_{home} - HomeDefAdvantage_{home} \\\\\n\\end{align}  \n\n\n**atack rate**\n\\begin{align}\nAttRate_i &= BaseAtt + AttRate_{i, non-centered} * \\tau^{att}_i \\\\\nBaseAtt &\\sim Normal(0, 1) \\\\\nAttRate_i &\\sim Normal(0, 1) \\\\\n\\tau^{att}_i &\\sim Gamma(2, 2) \\\\\n\\end{align} \n\n**defense rate**\n\\begin{align}\nDefRate_i &= DefRate_{i, non-centered} * \\tau^{def}_i \\\\\nDefRate_i &\\sim Normal(0, 1) \\\\ \n\\tau^{def}_i &\\sim Gamma(2, 2) \\\\\n\\end{align} \n\n**home attacking advantage**\n\\begin{align}\nHomeAttAdvantage_{home} &= BaseHomeAtt + HomeAttRate_{i, non-centered} * \\tau^{HomeAtt}_i \\\\\nBaseHomeAtt &\\sim Normal(0, 1) \\\\\nHomeAttRate_i &\\sim Normal(0, 1) \\\\\n\\tau^{HomeAtt}_i &\\sim Gamma(2, 2) \\\\\n\\end{align} \n\n**home defense advantage**\n\\begin{align}\nHomeDefAdvantage_{home} &= BaseHomeDef + HomeDefRate_{i, non-centered} * \\tau^{HomeDef}_i \\\\\nBaseHomeDef &\\sim Normal(0, 1) \\\\\nHomeDefRate_i &\\sim Normal(0, 1) \\\\\n\\tau^{HomeDef}_i &\\sim Gamma(2, 2) \\\\\n\\end{align}\n\nwhere $i = 1, \\dots, n$, where $n$ is the number of teams playing the league (usually 20)\n\n---","5ebfcf1c":"## Inference Prep","98bff760":"## Partial standings","090de712":"Let's select Italian's Serie A League, season 2015\/2016, just to illustrate how the model works.\n\nWe will model the 1st leg of each match (i.e. 19 rounds\/matches) and predict the second. Of course the model and final standings can be predicted match by match (and perhaps that's the more intuitive way to understand bayesian update) but we will stick with this approach just for illustration purpose.","df03a280":"### Map \"future\" matches","ec1b0a27":"Let's plot the parameters that are non-centered and the ones that are actually not pooled, i.e. each team has its own estimated parameter and are indepentend (somehow).\n\nFrom the plots below, we can conclude that a few teams have strong attacking rates: Napoli, Juventus, Fiorentina and Roma. This is great, since they are, up to round 19, the teams which scored the most goals.\n\nThe defense rate also is pretty fair estimated, since we have Juventus, Inter and Napoli as with highest estimated parameters - and from the standings we see that they are the teams with least goals against. It is interesting to notive that Frosinone has the lowest estimated defense rate and in fact they concealed the most goals.\n\nRegarding home advantages, it is a bit more uniform, but we can see Roma, as expected, with a slightest home advantage (on both attacking and defense).","a56f99d3":"**Actual final standing**","3a191461":"### Bookkeeping","9bc9850b":"This kernel introduces multilevel bayesian modelling with [TensorFlow Probability](https:\/\/www.tensorflow.org\/probability) applied to soccer match predictions.  \n\nIt may be seen as an extension of a [previous kernel](https:\/\/www.kaggle.com\/fernandoramacciotti\/bayesian-model-using-greta) that I built using the [R's package called greta](https:\/\/greta-stats.org) and it is essentially based on a [PyMC3](https:\/\/docs.pymc.io\/) model, explained in detail in this [article by Gijs Koot](http:\/\/gijskoot.nl\/bayesian\/sports\/soccer\/predictions\/pymc3\/2018\/02\/07\/knvb-model.html).\n\nOn top of it, I would like to acknowledge [Junpeng Lao](https:\/\/junpenglao.xyz\/)'s help to understand better TensorFlow Probability's features as well as translating the model (as in this [GitHub's issue](https:\/\/github.com\/tensorflow\/probability\/issues\/601))","0478487d":"We essentially have 10k competitions simulated. Let's what are the final standings distributions.","2c501c09":"## Predictions"}}