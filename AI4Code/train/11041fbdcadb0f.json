{"cell_type":{"a5ea78cb":"code","39b2dc60":"code","b54ea07c":"code","a05f3b36":"code","99db46d0":"code","06e521a7":"code","aa0c602d":"code","a52b6cfd":"code","684d5d3a":"code","7d837904":"code","51f7f795":"code","f2854b97":"code","278f05e9":"code","f33ae2b7":"markdown","d9c2f5a2":"markdown"},"source":{"a5ea78cb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport gc\nimport os\nprint(os.listdir(\"..\/input\"))","39b2dc60":"data_train = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ndata_test = pd.read_csv('..\/input\/fashion-mnist_test.csv')\n\nprint('train:', data_test.shape)\nprint('test:', data_train.shape)\n\nclass_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nimg_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\ndata = np.array(data_train.iloc[:, 1:])\nlabels = np.array(data_train.iloc[:, 0])\ntest_data = np.array(data_test.iloc[:, 1:])\ntest_labels = np.array(data_test.iloc[:, 0])","b54ea07c":"train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.3, random_state=2019)\n\ntrain_data = train_data.reshape(train_data.shape[0], img_rows, img_cols, 1)\nval_data = val_data.reshape(val_data .shape[0], img_rows, img_cols, 1)\ntest_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, 1)\n\ntrain_data = train_data.astype('float32')\nval_data = val_data.astype('float32')\ntest_data = test_data.astype('float32')\ntrain_data \/= 255\nval_data \/= 255\ntest_data \/= 255\n\nprint('train shape:', train_data.shape, train_labels.shape)\nprint('valid shape:',val_data.shape, val_labels.shape)\nprint('test shape:', test_data.shape, test_labels.shape)","a05f3b36":"def display(i):\n    plt.imshow(train_data[i, :, :, 0])\n    plt.colorbar()\n    plt.grid(False)\n    plt.title(class_names[train_labels[i]])\n    plt.show()\n\n    \ndisplay(2)\ndisplay(4)\ndisplay(5)","99db46d0":"def plot_history_vs_epoch(histories, key):\n    plt.figure(figsize=(16, 10))\n\n    for name, history in histories:\n        val = plt.plot(history.epoch, history.history['val_' + key], '.-', label=name.title()+' - Val')\n        plt.plot(history.epoch, history.history[key], '--', color=val[0].get_color(), label=name.title()+' - Train')\n\n    plt.xlabel('Epochs')\n    plt.ylabel(key.replace('_', ' ').title())\n    plt.legend()\n\n    plt.xlim([0, max(history.epoch)])","06e521a7":"# CNN model.\ndef create_model():\n    model = keras.Sequential([\n        keras.layers.Conv2D(filters=32, kernel_size=[5, 5], padding=\"same\", activation='relu', input_shape=(28, 28, 1)),\n        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),\n        keras.layers.Dropout(0.4),\n\n        keras.layers.Conv2D(filters=64, kernel_size=[5, 5], padding=\"same\", activation='relu'),\n        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),\n        keras.layers.Dropout(0.4),\n\n        keras.layers.Flatten(),\n        keras.layers.Dense(256, activation='relu'),\n        keras.layers.Dropout(0.4),\n        keras.layers.Dense(10, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy', 'sparse_categorical_crossentropy']\n    )\n    return model\n\ncnn_dt_model = create_model()\ncnn_dt_model.summary()","aa0c602d":"ckpt = keras.callbacks.ModelCheckpoint(\n    f'weights.h5',\n    save_best_only=True,\n    save_weights_only=True,\n    verbose=1,\n    monitor='acc',\n    mode='max'\n)\n\n# Train the model.\ncnn_dt_history = cnn_dt_model.fit(\n    train_data,\n    train_labels,\n    validation_data=(val_data, val_labels),\n    batch_size=32,\n    epochs=60,\n    verbose=2,\n    # callbacks=[ckpt]\n)","a52b6cfd":"summ_list = [\n    ('M1', cnn_dt_history)\n]\n\nplot_history_vs_epoch(summ_list, key='sparse_categorical_crossentropy')\nplot_history_vs_epoch(summ_list, key='acc')\n\nprint('Acc:', max(cnn_dt_history.history['val_acc']))","684d5d3a":"model = cnn_dt_model\nval_pred_prob = folds_metrics\nval_pred_labels = np.argmax(val_pred_prob, axis=-1)\nprint('Valid ACC:', accuracy_score(val_labels, val_pred_labels))\n\n# Evaluating test.\ntest_pred_prob = model.predict(test_data)\ntest_pred_labels = np.argmax(test_pred_prob, axis=-1)\nprint(test_pred_labels)\nprint('Test ACC:', accuracy_score(test_labels, test_pred_labels))","7d837904":"data_ = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ndata_test_ = pd.read_csv('..\/input\/fashion-mnist_test.csv')\n\nprint('train:', data_test.shape)\nprint('test:', data_train.shape)\n\nclass_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nimg_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\ndata = np.array(data_.iloc[:, 1:])\nlabels = np.array(data_.iloc[:, 0])\ntest_data = np.array(data_test_.iloc[:, 1:])\ntest_labels = np.array(data_test_.iloc[:, 0])\n\ndel data_, data_test_\ngc.collect()","51f7f795":"data = data.reshape(data.shape[0], img_rows, img_cols, 1)\ntest_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, 1)\n\ndata = data.astype('float32')\ntest_data = test_data.astype('float32')\ndata \/= 255\ntest_data \/= 255\n\nprint('train shape:', data.shape, labels.shape)\nprint('test shape:', test_data.shape, test_labels.shape)","f2854b97":"# K-fold Cross-validation.\nN_SPLITS = 5\nBATCH_SIZE = 32\nEPOCHS = 60\n\ndata_index = np.array(range(data.shape[0]))\nsplits = list(KFold(n_splits=N_SPLITS, random_state=0, shuffle=True).split(data_index))\n\nmodels = []\npredicts_prob = []\nfolds_acc = []\n\nfor n, (train_index, val_index) in enumerate(splits):\n    print(f'Fold: {n}')\n    print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n    train_data, val_data = data[train_index, :], data[val_index, :]\n    train_labels, val_labels = labels[train_index], labels[val_index]\n\n    # It is basically an early stopping.\n    ckpt = keras.callbacks.ModelCheckpoint(f'weights_fold-{n}.h5', save_best_only=True, save_weights_only=True, verbose=1, monitor='acc', mode='max')\n    \n    model = create_model()\n    \n    history = model.fit(\n        train_data,\n        train_labels,\n        validation_data=(val_data, val_labels),\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        verbose=2,\n        callbacks=[ckpt]\n    )\n\n    model.load_weights(f'weights_fold-{n}.h5')\n    \n    test_pred_prob = model.predict(test_data, batch_size=512)\n    predicts_prob.append(test_pred_prob)\n\n    test_pred_labels = np.argmax(test_pred_prob, axis=-1)\n    acc = accuracy_score(test_labels, test_pred_labels)\n    print(f\"Fold's ACC: {acc}\")\n    folds_acc.append(acc)\n\n# 1) Average ACC and  2) average probabilities and calculate one accuracy in the end. Both might be informative. \n\n# 1)\nprint(f'Avg ACC: {np.sum(folds_acc) \/ len(folds_acc)}')\n\n# 2)\n# Average prob and calculate 1 accuracy.\n\n    \n# preds_val = np.concatenate(preds_val)[...,0]\n# y_val = np.concatenate(y_val)\n# preds_val.shape, y_val.shape\n","278f05e9":"# TODO: Data augmentation.","f33ae2b7":"\nK-fold cross validation.\n\n","d9c2f5a2":"Classifying images of the MNIST dataset with tensorflow."}}