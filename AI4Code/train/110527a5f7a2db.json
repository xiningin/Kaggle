{"cell_type":{"51b36e91":"code","a08fe172":"code","0a7207b6":"code","44c67129":"code","0c7906c1":"code","be8d6431":"code","1bdf6bf4":"code","8ea1a06a":"code","ff59734d":"code","69a47607":"code","0ca5140b":"code","807be88d":"code","de7cfbee":"markdown","206f3679":"markdown","c76fb818":"markdown","8b0a2479":"markdown","ce35b579":"markdown","1a5acbc7":"markdown","dcd549f1":"markdown","86769488":"markdown","384f6a71":"markdown","d51f6126":"markdown","50f4018b":"markdown","f6a772d4":"markdown","f97f3917":"markdown","5337959c":"markdown","6d390f34":"markdown","66ce7415":"markdown"},"source":{"51b36e91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a08fe172":"place = pd.read_csv('..\/input\/recruitment-data\/Placement_Data_Full_Class.csv')","0a7207b6":"print(place.shape)\nplace.head(20)\nprint(place.isna().any())\n#place = place.set_index('sl_no')\nplace.head()","44c67129":"print(place.describe())","0c7906c1":"pv1 = place.pivot_table(index = 'gender', columns = 'status',values = 'ssc_p' )\n\nx = np.arange(len(pv1.index))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize = (5,5))\nrects1 = ax.bar(x - width\/2, pv1['Not Placed'] , width, label='Not Placed')\nrects2 = ax.bar(x + width\/2, pv1['Placed'] , width, label='Placed')\n\nax.spines[\"top\"].set_color(\"None\")\nax.spines[\"right\"].set_color(\"None\")\nax.set_ylabel('Scores')\nax.set_title('Average Senior secondary percentage by Gender')\nax.set_xticks(x)\nax.set_ylim(0,100)\nax.set_xticklabels(pv1.index)\nax.legend()\nplt.show()\n","be8d6431":"pv2 = place.pivot_table(index = 'gender', columns = 'status',values = 'etest_p' )\n\nx = np.arange(len(pv2.index))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize = (5,5))\nrects1 = ax.bar(x - width\/2, pv2['Not Placed'] , width, label='Not Placed')\nrects2 = ax.bar(x + width\/2, pv2['Placed'] , width, label='Placed')\n\nax.spines[\"top\"].set_color(\"None\")\nax.spines[\"right\"].set_color(\"None\")\nax.set_ylabel('Scores')\nax.set_title('Average Employability test scores by Gender')\nax.set_xticks(x)\nax.set_ylim(0,100)\nax.set_xticklabels(pv1.index)\nax.legend()\nplt.show()","1bdf6bf4":"pv3 = place.pivot_table(index = 'gender', columns = 'status',values = 'mba_p' )\n\nx = np.arange(len(pv3.index))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize = (5,5))\nrects1 = ax.bar(x - width\/2, pv3['Not Placed'] , width, label='Not Placed')\nrects2 = ax.bar(x + width\/2, pv3['Placed'] , width, label='Placed')\n\nax.spines[\"top\"].set_color(\"None\")\nax.spines[\"right\"].set_color(\"None\")\nax.set_ylabel('Scores')\nax.set_title('Average MBA percentage by Gender')\nax.set_xticks(x)\nax.set_ylim(0,100)\nax.set_xticklabels(pv1.index)\nax.legend()\nplt.show()","8ea1a06a":"pv4 = place.pivot_table(index = 'degree_t', columns = 'status', values = 'gender', aggfunc = 'count')\nprint(pv4)\nx = np.arange(len(pv4.index))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize = (5,5))\nrects1 = ax.bar(x - width\/2, pv4['Not Placed'] , width, label='Not Placed')\nrects2 = ax.bar(x + width\/2, pv4['Placed'] , width, label='Placed')\n\nax.spines[\"top\"].set_color(\"None\")\nax.spines[\"right\"].set_color(\"None\")\nax.set_ylabel('Count')\nax.set_title('Count of placement status of students by degree')\nax.set_xticks(x)\nax.set_ylim(0,110)\nax.set_xticklabels(pv4.index)\nax.legend()\nplt.show()","ff59734d":"pv5 = place.pivot_table(index = 'specialisation', columns = 'status', values = 'gender', aggfunc = 'count')\npv5","69a47607":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\n\nplace_new = place.drop('salary',axis = 1).reset_index()\nplace_new = place_new.replace(['Placed','Not Placed'],[1,0])\n# print(place_new,'place_new')\nplace_cat = place_new[['gender','ssc_b','hsc_b','hsc_s','degree_t','workex','specialisation']]\nplace_num = place_new[['ssc_p','hsc_p','degree_p','etest_p','mba_p']]\n\nX = place_new.drop(['status'],axis = 1).reset_index().drop(['sl_no'],axis = 1)\ny = place_new.iloc[:,-1]\n","0ca5140b":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(place_num)\ncat_attribs = list(place_cat)\n# print(num_attribs,\"***num_Attribs***\")\n# print(cat_attribs,\"***cat_attribs***\")\nnum_transformer = Pipeline(steps = [('scaler', StandardScaler())])\n\ncat_transformer = Pipeline(steps = [('onehot',OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers = [('num',num_transformer, num_attribs),\n                                                 ('cat',cat_transformer,cat_attribs)])\n\nparam_grid = [{'n_estimators':[100,500],'max_features': [8, 10, 12]},\n              {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}]\n\nforest_clf = RandomForestClassifier()\n\n\nclf = Pipeline(steps = [('preprocessor',preprocessor),('grid_search',GridSearchCV(forest_clf, param_grid, cv=5,\nscoring='roc_auc',return_train_score=True))])\n\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n\nfor train_index, test_index in split.split(X,y):\n    #print(train_index,(test_index))\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\nclf.fit(X_train,y_train)\n\ny_pred = clf.predict(X_test)\n#print(y_pred)\n\n\nfrom sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test, y_pred))\n\nprint(\"model score: %.3f\" % clf.score(X_test, y_test))\n","807be88d":"print(clf.named_steps['grid_search'].best_params_)","de7cfbee":"## Explanation:<a id=\"5\"><\/a> <br> \n* I created 'num_attribs' and 'cat_attribs' and I created Pipeline for data preprocessing for both Numeric and Categorical data.\n* Then I combined the two using Column transfer and created a combined variable 'preprocessor' which can be used directly in a pipeline later on.\n* Created a 'param_grid' which is the combined list of parameters to be tested for grid search.\n* Using Forest Classifier for prediction.\n* Performing grid search cross validation with Forest Classifier with scoring as 'roc_auc' using pipeline and storing it as clf.\n* Applying stratified shuffle split which will create a test set that is a complete representative of the data for example the gender ratio will remain constant for the test set as well.\n* Finally fitting the data set on the classifier\n* Creating y_pred to create a list of predicted variable\n* Using confusion matrix to find the false negetives and false positives.\n* Finally getting the roc_auc score.","206f3679":"Using Pipeline and ColumnTransfer I have combined all the data processing and prediction algorithms for both numerical and categorical data. ","c76fb818":"## Basic Analysis <a id=\"2\"><\/a> <br>\n\nLet's have a look at the Null values and the overall look at the data","8b0a2479":"As we can see the best parameters for Grid Search are max_features = 8 and n_estimators = 500. I might try to tune it even finer in future iterations.","ce35b579":"Surprisingly not much clear difference in terms of placement.","1a5acbc7":"## Contents of the notebook\n\n[Yash Dalsaniya](https:\/\/www.kaggle.com\/yashdalsaniya)\n\n- [1 - Data Import](#1)\n- [2 - Basic Analysis](#2)\n- [3 - Exploratory Data Analysis](#3)\n- [4 - Prediction](#4)\n- [5 - Explanation](#5)\n- [6 - Conclusion](#6)","dcd549f1":"## Prediction <a id=\"4\"><\/a> <br>\n\nImporting all libraries and creating the test and train dataset. Also separating the numerical and the categorical attributes to apply different data processing techniques.\n","86769488":"We see that students with Commerce and Management degree have more placements although the placements percentage is more for Science & technology","384f6a71":"In terms of 'specialization' students got placed much more in 'Market and Finance'.","d51f6126":"## Exploratory Data Analysis <a id=\"3\"><\/a> <br>\n\nLooking at the numerical values of the data set","50f4018b":"### I have referred the book 'Hands-on Machine Learning with scikit-Learn, Keras, and Tensorflow' by Aur\u00e9lien G\u00e9ron and applied on this dataset. I highly recommend it if you are a beginner. If you have a question or feedback, do not hesitate to write and if you find this kernal helpful, please do not forget to **UPVOTE** \ud83d\ude42","f6a772d4":"# Conclusion<a id=\"6\"><\/a> <br>\n\nThis is one of my initial attempts on EDA and prediction.\nDo let me know if there are any feedback\/comments\/suggestions :) \nI would to know how I can improve further and make even better predictions.","f97f3917":"Conclusion : We get a clear picture that senior secondary percentage is higher for students that got placed","5337959c":"Not much difference of scores here as well.","6d390f34":"Let's have a visualisation of different aspects of the dataset to get an idea of it and also get an intuition of the important parameters with respect to target variable 'Status'","66ce7415":"## Data import <a id=\"1\"><\/a> <br>"}}