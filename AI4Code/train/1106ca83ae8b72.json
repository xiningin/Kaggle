{"cell_type":{"68806dca":"code","4d9de460":"code","22aa4f99":"code","aa0d8cef":"code","14218672":"code","8eacfe4c":"code","7f2bbe7b":"code","a4d01995":"code","9d99560e":"code","71086e03":"code","5110ea7c":"code","7d6d2b8c":"code","5e40244a":"code","c74ad9cc":"code","fb0cdc3b":"code","c405c048":"code","cb3829c8":"code","c95b86cd":"code","6d589469":"code","ff545bdb":"code","bc822d81":"code","3c04f678":"code","013b8a9b":"code","bcb592d4":"code","0e5d88a7":"markdown","c00e2cad":"markdown","6b7f60c0":"markdown","4857e9fb":"markdown","91f34b70":"markdown","8d7b0a6f":"markdown","73c5e162":"markdown","a633dccd":"markdown","0ff659c1":"markdown","72554cb1":"markdown","9575d3db":"markdown","91bec615":"markdown","098fd46c":"markdown","e99ad943":"markdown","430d111c":"markdown","04abaa06":"markdown","b1051687":"markdown","cef20e16":"markdown","cef68f12":"markdown","7ba8d050":"markdown"},"source":{"68806dca":"!pip install pycaret","4d9de460":"import pandas as pd\nimport numpy as np\nfrom pycaret.regression import *\nimport seaborn as sns\nimport category_encoders as ce\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report,mean_squared_error,confusion_matrix\nimport pandas_profiling as pp\nfrom sklearn import ensemble","22aa4f99":"def checkIsNull(df):\n    return [(i,df[i].isnull().sum()) for i in df]\n\ndef one_hot_encoding(df,column):\n    one_hot_encoder=ce.OneHotEncoder(cols=column,return_df=True,use_cat_names=True)\n    df_final = one_hot_encoder.fit_transform(df)\n    return df_final\n\ndef valueCounts(df):\n    for i in df:\n        print(i,df[i].value_counts())","aa0d8cef":"dfTrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndfTest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","14218672":"dfTrain","8eacfe4c":"report = pp.ProfileReport(dfTrain)\nreport","7f2bbe7b":"valueCounts(dfTrain)","a4d01995":"checkIsNull(dfTrain)","9d99560e":"dfTrain.dtypes","71086e03":"dfTrain['Age'].fillna(dfTrain['Age'].median(), inplace=True)\ndfTrain['Embarked'].fillna(dfTrain['Embarked'].mode()[0], inplace=True)\ndfTrain = one_hot_encoding(dfTrain,\"Sex\")\ndfTrain = one_hot_encoding(dfTrain,\"Embarked\")\ndfTrain.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","5110ea7c":"checkIsNull(dfTrain)","7d6d2b8c":"dfTrain.dtypes","5e40244a":"dfTrain.corr()","c74ad9cc":"experiment = setup(dfTrain,target=\"Survived\",imputation_type='iterative')","fb0cdc3b":"compare_models()","c405c048":"dfTest","cb3829c8":"valueCounts(dfTest)","c95b86cd":"checkIsNull(dfTest)","6d589469":"dfTest['Age'].fillna(dfTest['Age'].median(), inplace=True)\ndfTest['Fare'].fillna(dfTest['Fare'].median(), inplace=True)\ndfTest = one_hot_encoding(dfTest,\"Sex\")\ndfTest = one_hot_encoding(dfTest,\"Embarked\")\nPassengerId=dfTest[\"PassengerId\"]\ndfTest.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","ff545bdb":"checkIsNull(dfTest)","bc822d81":"dfTest.dtypes","3c04f678":"X_train= dfTrain.iloc[:, 1:]\ny_train= dfTrain['Survived'].values.reshape(-1,1)","013b8a9b":"params = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\n\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\ny_pred = reg.predict(dfTest)\nprint(reg)","bcb592d4":"submission= pd.DataFrame({'PassengerId' : PassengerId, 'Survived': [int(j\/0.5) for j in y_pred] })\nprint(submission.head())\nfilename= 'titanic predictions.csv'\nsubmission.to_csv(filename, index=False)","0e5d88a7":"# Data preprocessing by handling NAs and encoding categorical columns","c00e2cad":"<h1 style=\"text-align:center;font-weight:bold;font-size:2em\">TITANIC PASSENGER SURVIVAL PREDICTION<\/h1>","6b7f60c0":"# Functions to check null, encode and describe the values stored in each columns","4857e9fb":"# Fitting the train data into pycaret regressor model","91f34b70":"# Checking for null after data preprocessing","8d7b0a6f":"# Checking for the presence of categorical variable","73c5e162":"# Correlation matrix (inorder remove variables that cause mutlicollinearity)","a633dccd":"# Data preprocessing of test data","0ff659c1":"# Finding the model with maximum R^2 Value","72554cb1":"# Knowing the datatype of the columns","9575d3db":"# Fitting the train data into Gradient Boosting Regressor and predicting test values","91bec615":"# Read the test and train data from csv","098fd46c":"<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRWDgteV-sNXVRkc0xwyodmJt18ImebZ1UcKA&usqp=CAU\">","e99ad943":"# Displaying the kind of date stored on every column in the dataset","430d111c":"# Checking for null values","04abaa06":"# EDA using Pandas Profiling","b1051687":"I hope you had a good time reading my notebook. Pls do support and comment! \ud83d\ude0e","cef20e16":"# Splitting the train data into target and dependent variables (X & Y)","cef68f12":"# Importing the required libraries","7ba8d050":"# Creating a csv file for submission with Passenger Id and Survied attributes"}}