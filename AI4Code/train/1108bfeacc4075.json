{"cell_type":{"16cfc707":"code","460b02a2":"code","8cc5fef2":"code","d98ba5fe":"code","d69dd74e":"code","1fc55eca":"code","a87fa07f":"code","fa7d2731":"code","30bf8705":"code","50e3b429":"code","4af6ffd1":"code","ad8b9be0":"markdown"},"source":{"16cfc707":"'''Load librarires'''\nimport time\nimport random\nimport ntpath\nimport glob\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nimport torchvision\nfrom torchvision import datasets, models, transforms, utils\n\n!pip install -U skorch\nfrom skorch import NeuralNetClassifier\nfrom skorch.helper import predefined_split\nfrom skorch.callbacks import LRScheduler, Checkpoint, Freezer\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","460b02a2":"class CFG:\n\n    '''Store all hyperparameters here.''' \n\n    SEED = 420\n    TEST_SIZE = 0.2\n    VAL_SIZE = 0.25\n    \n    #transforms\n    TRAIN_TRANSFORMS = transforms.Compose([\n        #Rotate the image by given angle.\n        transforms.RandomRotation(5),\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Horizontally flip the given PIL Image randomly with a given probability.\n        transforms.RandomHorizontalFlip(p = 0.2),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\n    VAL_TRANSFORMS = transforms.Compose([\n        #Rotate the image by given angle.\n        transforms.RandomRotation(5),\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Horizontally flip the given PIL Image randomly with a given probability.\n        transforms.RandomHorizontalFlip(p = 0.2),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    \n    TEST_TRANSFORMS = transforms.Compose([\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    \n    #model\n    CRITERION = nn.CrossEntropyLoss\n    OPTIMIZER = optim.SGD\n    MOMENTUM = 0.9\n    LR = 0.03\n    BATCH_SIZE = 32\n    EPOCHS = 50\n    #callbacks\n    LRSCHEDULER = LRScheduler(policy='StepLR', step_size=5, gamma=0.75)\n    CHECKPOINT = Checkpoint(f_params='best_model.pt', monitor='valid_acc_best')\n    FREEZER = Freezer(lambda x: not x.startswith('model.fc'))\n    CALLBACKS = [LRSCHEDULER, CHECKPOINT, FREEZER]\n    \n    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print('You are using ->', DEVICE)    ","8cc5fef2":"def seed_everything(seed):\n    '''Make the results reproducible'''\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True  # type: ignore\n\nseed_everything(CFG.SEED)","d98ba5fe":"'''Store image paths and their labels in pandas dataframe. Will be used to create pytorch datasets. '''\n\npaths = glob.glob('..\/input\/grapevine-leaves\/data\/*\/*' )\nmeta = pd.DataFrame([(path, ntpath.basename(ntpath.dirname(path))) for path in paths], columns = ['path','variety'])\nmeta.head()","d69dd74e":"'''Split data into train, validation and test sets'''\n\nX = meta.path\ny = meta.variety\n\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=CFG.TEST_SIZE, \n                                                    random_state=CFG.SEED, \n                                                    stratify=y) #stratified split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train,\n                                                  y_train,\n                                                  test_size=CFG.VAL_SIZE,\n                                                  random_state=CFG.SEED,\n                                                  stratify=y_train) #stratified split\n\nprint(f'Train length -> {len(X_train)}')\nprint(f'Val length -> {len(X_val)}')\nprint(f'Test length -> {len(X_test)}')","1fc55eca":"'''Custom pytorch dataset implementation.'''\nclass LeafDataset(Dataset):\n    def __init__(self,X,y, transform=None):\n        self.X = X.reset_index().drop('index',axis=1).path\n        self.y = torch.tensor(y.reset_index().drop('index',axis=1).variety.astype('category').cat.codes, dtype=torch.long)\n        self.transform = transform\n\n        assert len(self.X) == len(self.y), f'X and y have different lengths -> {len(self.X)} != {len(self.y)} '\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self,idx):\n        img_path = self.X[idx]\n        img = Image.open(img_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        label = self.y[idx]\n\n        return (img,label) \n\n    def show_img(self,idx):\n        '''Plot image'''\n        img,label = self.__getitem__(idx)\n        img = img.numpy().transpose((1, 2, 0))\n        plt.figure(figsize=(16, 8))\n        plt.axis('off')\n        plt.imshow(img)\n        plt.title(label)\n        plt.pause(0.001)","a87fa07f":"'''Instantiate pytorch train, validation and test sets'''\nTRAIN = LeafDataset(X_train,y_train, CFG.TRAIN_TRANSFORMS)\nVAL = LeafDataset(X_val,y_val, CFG.VAL_TRANSFORMS)\nTEST = LeafDataset(X_test,y_test, CFG.TEST_TRANSFORMS)","fa7d2731":"'''Get the pretrained model for transfer learning'''\nclass PretrainedModel(nn.Module):\n    def __init__(self, output_features):\n        super().__init__()\n        model = models.resnet34(pretrained=True) # ResNet34\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, output_features)\n        self.model = model\n        \n    def forward(self, x):\n        return self.model(x)","30bf8705":"'''Instantiate Model'''\nmodel = NeuralNetClassifier(\n    PretrainedModel, \n    criterion=CFG.CRITERION,\n    lr=CFG.LR,\n    batch_size=CFG.BATCH_SIZE,\n    max_epochs=CFG.EPOCHS,\n    module__output_features=11, # NUMBER OF CLASSES\n    optimizer=CFG.OPTIMIZER,\n    optimizer__momentum=CFG.MOMENTUM,\n    train_split=predefined_split(VAL),\n    callbacks=CFG.CALLBACKS,\n    device=CFG.DEVICE\n)","50e3b429":"'''Train the model'''\nmodel.fit(TRAIN,y=None)","4af6ffd1":"'''Get test accuracy'''\n\ny_pred = model.predict(TEST)\ny_test = TEST.y\n\nprint(f'Test Accuracy -> {accuracy_score(y_test, y_pred)}')","ad8b9be0":"# Grapevine Leaf Classifier"}}