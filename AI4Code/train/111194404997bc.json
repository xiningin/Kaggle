{"cell_type":{"1a017ce0":"code","de31b634":"code","7f3d2a27":"code","badd298e":"code","d6c1ab61":"code","e5bcdfb7":"code","55ee29e4":"code","178c4e10":"code","1cbbda39":"code","ce58fd6e":"code","8efd1302":"code","f24b0ac6":"code","999aa2c0":"code","302efcf4":"code","ea1fc732":"code","68133840":"code","b4dda5e7":"code","0d14ba39":"code","4f6d97de":"code","b5664314":"code","396db110":"code","f2c19ec9":"code","0ebd537b":"code","ce1ffc98":"code","eb2192ed":"code","825a5419":"code","de94965b":"code","73fabb2f":"code","f65d73ac":"code","48562345":"code","f8dff598":"code","07e6b10d":"code","da575665":"code","3cef9775":"code","83686748":"code","a42446ae":"code","66dacb56":"code","7b53e3cc":"code","882ec16c":"code","2e4a6ea9":"code","7ecfa2c1":"code","8dfce843":"code","b8bde8ed":"markdown","250d01a8":"markdown","272b7afd":"markdown","f696d6d2":"markdown","a7219733":"markdown","8b48ba25":"markdown","dd852d65":"markdown","bf78ed0c":"markdown","df9c1f27":"markdown"},"source":{"1a017ce0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","de31b634":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nimport datetime\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","7f3d2a27":"path = '..\/input\/competitive-data-science-predict-future-sales\/'\n\nos.listdir(path)","badd298e":"items = pd.read_csv(path + 'items.csv')\nitem_categories = pd.read_csv(path + 'item_categories.csv')\ntrain = pd.read_csv(path + 'sales_train.csv')\nshop = pd.read_csv(path + 'shops.csv')\ntest = pd.read_csv(path + 'test.csv')","d6c1ab61":"print('The information of the dataset'.center(50, '-'))\nprint('The shape of the dataset is {}'.format(items.shape))\nprint('The number of the goods {}'.format(items.item_id.nunique()))\nprint('The category of the goods {}'.format(items.item_category_id.nunique()))\nitems.sample(4)","e5bcdfb7":"# The missing value of the dataset\ntotal = items.isnull().sum()\npercentage = total \/ items.shape[0]\ntypes = items.dtypes\npd.concat([total, percentage, types], axis = 1, keys = ['Total', 'Percentage', 'Types'])","55ee29e4":"print('The information of the dataset'.center(50, '-'))\nprint('The shape of the dataset is {}'.format(train.shape))\nprint('The number of the goods {}'.format(train.item_id.nunique()))\ntrain.sample(4)\n# the numner of the goods 21807 mean that some goods hasn't sale at all.","178c4e10":"train['date'] = train['date'].apply(lambda x: datetime.datetime.strptime(x, '%d.%m.%Y'))","1cbbda39":"# The missing value of the dataset\ntotal = train.isnull().sum()\npercentage = total \/ train.shape[0]\ntypes = train.dtypes\npd.concat([total, percentage, types], axis = 1, keys = ['Total', 'Percentage', 'Types'])","ce58fd6e":"print('The information of the shop dataset'.center(50, '-'))\nprint('The shape of the shop dataset {}'.format(shop.shape))\nprint('The shop information {} and the colums {}'.format(shop.nunique(), shop.columns))","8efd1302":"print('The information of the item_categories dataset'.center(80, '-'))\nprint('The shape of the shop dataset {}'.format(item_categories.shape))\nprint('The shop information {} and the colums {}'.format(item_categories.nunique(), item_categories.columns))","f24b0ac6":"salesData = pd.merge(train, items, how = 'inner', on = 'item_id')\nsalesData = pd.merge(salesData, shop, how = 'inner', on = 'shop_id')\nsalesData = pd.merge(salesData, item_categories, how = 'inner', on = 'item_category_id')","999aa2c0":"temp_shop_name = salesData['shop_name']\nsalesData.drop('shop_name', axis = 1, inplace = True)\nsalesData.insert(3, 'shop_name', temp_shop_name)","302efcf4":"test.sample(4)","ea1fc732":"# It mean that the test data samples less than train data\nprint(train['shop_id'].nunique() is test['shop_id'].nunique())\ntemp_shop_id = test['shop_id'].unique()\ntemp_item_id = test['item_id'].unique()\ntrain_lk = salesData[salesData['shop_id'].isin(temp_shop_id)]\ntrain_lk = train_lk[train_lk['item_id'].isin(temp_item_id)]\nprint('Before'.center(50, '-'))\nprint('The shape of the train {}'.format(train.shape))\nprint('After'.center(50, '-'))\nprint('The shape ot the train_lk {}, and the leakage samples are {}'.format(train_lk.shape, train.shape[0] - train_lk.shape[0]))","68133840":"salesData.isnull().sum()","b4dda5e7":"print(items['item_id'].nunique() - train['item_id'].nunique())","0d14ba39":"train_item_id = train['item_id'].unique()\n# ~ mean that turn the false to true\nitems_lk = items[~items['item_id'].isin(train_item_id)]\ntemp_items_lk = items_lk['item_id']\ntest_lk = test[test['item_id'].isin(temp_items_lk)]\nprint('The shape of the test_lk is {}, and the predicted value of this sample can be set to 0'.format(test_lk.shape[0]))","4f6d97de":"test.shape","b5664314":"salesData.sample(4)","396db110":"train_monthly = train_lk[['date', 'date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'item_cnt_day']]","f2c19ec9":"train_monthly = train_monthly.loc[train_monthly['item_price'] > 0]","0ebd537b":"train_monthly = train_monthly.sort_values(by = 'date').groupby(['date_block_num', 'shop_id', 'item_category_id', 'item_id']).agg({'item_price': ['sum', 'mean'], 'item_cnt_day': ['sum', 'mean', 'count']}).reset_index()","ce1ffc98":"train_monthly.columns = ['date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'mean_item_price', 'item_cnt', 'mean_item_cnt', 'transactions']","eb2192ed":"train_monthly.sample(4)","825a5419":"def handleMonth(date):\n    if date < 12:\n        month = date + 1\n    elif date % 12 == 0:\n        month = 12\n    else:\n        month = (date % 12) + 1\n    return month","de94965b":"train_monthly['year'] = train_monthly['date_block_num'].apply(lambda x: ((x\/\/12) + 2013))\ntrain_monthly['month'] = train_monthly['date_block_num'].apply(handleMonth)","73fabb2f":"train_monthly.sample(4)","f65d73ac":"month_mean = train_monthly.groupby(['month'])['item_cnt'].mean().reset_index()\nmonth_sum = train_monthly.groupby(['month'])['item_cnt'].sum().reset_index()\n\nmonth_data = pd.merge(month_mean, month_sum, how = 'inner', on = 'month')\n\ncategory_mean = train_monthly.groupby(['item_category_id'])['item_cnt'].mean().reset_index()\ncategory_sum = train_monthly.groupby(['item_category_id'])['item_cnt'].sum().reset_index()\n\ncategory_data = pd.merge(category_mean, category_sum, how = 'inner', on = 'item_category_id')\n\nshop_mean = train_monthly.groupby(['shop_id'])['item_cnt'].mean().reset_index()\nshop_sum = train_monthly.groupby(['shop_id'])['item_cnt'].sum().reset_index()\n\nshop_data = pd.merge(shop_mean, shop_sum, how = 'inner', on = 'shop_id')","48562345":"month_data.sample(4)","f8dff598":"fig, axes = plt.subplots(1, 2, figsize = (22, 4))\nsns.set_style('whitegrid')\nax1 = sns.pointplot(x = 'month', y = 'item_cnt_x', data = month_data, linestyles = '-', ax = axes[0])\nax2 = sns.pointplot(x = 'month', y = 'item_cnt_y', data = month_data, linestyles = '-', ax = axes[1])\nax1.set(title = 'mothly mean', ylabel = 'item_cnt')\nax2.set(title = 'mothly sum', ylabel = 'item_cnt')","07e6b10d":"category_data.sample(4)","da575665":"fig, axes = plt.subplots(2, 1, figsize = (18, 8))\nsns.set_style('whitegrid')\nax1 = sns.barplot(x = 'item_category_id', y = 'item_cnt_x', data = category_data, ax = axes[0])\nax2 = sns.barplot(x = 'item_category_id', y = 'item_cnt_y', data = category_data, ax = axes[1])\nax1.set(title = 'category mean', ylabel = 'item_cnt')\nax2.set(title = 'category sum', ylabel = 'item_cnt')","3cef9775":"shop_data.sample(4)","83686748":"fig, axes = plt.subplots(2, 1, figsize = (18, 8), sharex = True)\nsns.set_style('whitegrid')\nax1 = sns.barplot(x = 'shop_id', y = 'item_cnt_x', data = shop_data, ax = axes[0], palette = 'mako')\nax2 = sns.barplot(x = 'shop_id', y = 'item_cnt_y', data = shop_data, ax = axes[1], palette = 'mako')\nax1.set(title = 'shop mean', ylabel = 'item_cnt')\nax2.set(title = 'shop sum', ylabel = 'item_cnt')","a42446ae":"train_monthly = train_monthly.loc[train_monthly['item_cnt'] >= 0].loc[train_monthly['item_cnt'] <= 20].loc[train_monthly['item_price'] < 400000]\n# tht following code much better than the above\n# train_monthly = train_monthly.query('item_cnt >= 0 and item_cnt <= 20 and item_price < 400000')","66dacb56":"train_monthly['item_price_unit'] = train_monthly['item_price'] \/\/ train_monthly['item_cnt']","7b53e3cc":"gp_item_price = train_monthly.sort_values('date_block_num').groupby(['item_id']).agg({'item_price':[np.min, np.max]}).reset_index()\ngp_item_price.columns = ['item_id', 'hist_min_item_price', 'hist_max_item_price']\n\ntrain_monthly = pd.merge(train_monthly, gp_item_price, on='item_id', how='inner')","882ec16c":"train_monthly['price_increase'] = train_monthly['item_price'] - train_monthly['hist_min_item_price']\ntrain_monthly['price_decrease'] = train_monthly['hist_max_item_price'] - train_monthly['item_price']","2e4a6ea9":"# Min value\nf_min = lambda x: x.rolling(window=3, min_periods=1).min()\n# Max value\nf_max = lambda x: x.rolling(window=3, min_periods=1).max()\n# Mean value\nf_mean = lambda x: x.rolling(window=3, min_periods=1).mean()\n# Standard deviation\nf_std = lambda x: x.rolling(window=3, min_periods=1).std()\n\nfunction_list = [f_min, f_max, f_mean, f_std]\nfunction_name = ['min', 'max', 'mean', 'std']\n\nfor i in range(len(function_list)):\n    train_monthly[('item_cnt_%s' % function_name[i])] = train_monthly.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].apply(function_list[i])\n\n# Fill the empty std features with 0\ntrain_monthly['item_cnt_std'].fillna(0, inplace=True)","7ecfa2c1":"print('The shape of the dataset {}'.format(train_monthly.shape))\ntrain_monthly.sample(4)","8dfce843":"# maybe some added some codes later","b8bde8ed":"- The dataset of train","250d01a8":" - to be continue","272b7afd":" - The dataset of shop","f696d6d2":" - Handled the train data and test data","a7219733":"- The dataset of item_categories","8b48ba25":"### This means that some items have never been sold in three years, and the predicted value of this sample in test can be set to 0","dd852d65":"### Feature engineering","bf78ed0c":"- The dataset of items","df9c1f27":" - The dataset after merged"}}