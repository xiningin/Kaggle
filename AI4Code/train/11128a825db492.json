{"cell_type":{"b8e343a2":"code","cc07ab0e":"code","6949fb20":"code","5d6bc0a1":"code","b0d240b3":"code","c7431745":"code","337c8e5a":"code","92869f19":"code","f863fc4b":"code","df0630ac":"code","8a0c9066":"code","755708e4":"code","6b4b6fa4":"code","b29fbf51":"code","1d51add7":"code","555b15be":"code","6b3f0867":"markdown","9a04eb8d":"markdown","5c947631":"markdown","d1707330":"markdown","9be7304f":"markdown","3f4e2a7a":"markdown","b6c83229":"markdown","a2f64a92":"markdown","7803a342":"markdown","f425ec5b":"markdown","ff15d3bd":"markdown","5fceffe2":"markdown","d37ce482":"markdown"},"source":{"b8e343a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cc07ab0e":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","6949fb20":"col = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\ndataset = pd.read_csv('..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv', header=None, encoding='ISO-8859-1', names = col, skiprows=795000, nrows = 10000)","5d6bc0a1":"dataset.head()","b0d240b3":"dataset.shape","c7431745":"dataset.isnull().sum()","337c8e5a":"# target\nsns.countplot(x='target', data=dataset)","92869f19":"# choose only columns we use\ndf = dataset[['text','target']]","f863fc4b":"# Handle Categories variable\ndf['target'] = df['target'].replace(4,1)","df0630ac":"# recheck\ndf['target']","8a0c9066":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\ncorpus = []\nfor i in range(0, int(df.shape[0])):\n    text = re.sub('[^a-zA-z]', ' ', df['text'][i])\n    text = text.lower()\n    text = text.split()\n    ps = PorterStemmer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')\n    text = [ps.stem(word) for word in text if not word in set(all_stopwords)]\n    text = ' '.join(text)\n    corpus.append(text)","755708e4":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 10000)\nX = cv.fit_transform(corpus).toarray()\ny = df.target","6b4b6fa4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","b29fbf51":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 42)\nclassifier.fit(X_train, y_train)","1d51add7":"y_pred = classifier.predict(X_test)","555b15be":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(\"accuracy score : \" , accuracy_score(y_test, y_pred))","6b3f0867":"## Explore the dataset","9a04eb8d":"## Handle missing values","5c947631":"## Cleaning the texts","d1707330":"# Twitter Sentiment Analysis","9be7304f":"## Splitting the dataset into the Training set and Test set","3f4e2a7a":"## Import the dataset","b6c83229":"## Creating the Bag of words model","a2f64a92":"## Import the libraries","7803a342":"## Data Preparation","f425ec5b":"## Training the Logistic Regression model on the Training set","ff15d3bd":"## Visualising the data","5fceffe2":"## Predicting the Test set results","d37ce482":"Twitter Sentiment Analysis by using NLP and Logistic Regression"}}