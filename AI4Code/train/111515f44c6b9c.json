{"cell_type":{"3538958e":"code","40db4a41":"code","b0adcf0e":"code","ff0b3226":"code","a0777755":"code","70d3ffb3":"code","5b648179":"code","339483ee":"markdown","0a9d6e0b":"markdown","a403fad9":"markdown","2c709de3":"markdown","5fe5ce81":"markdown","1287f8eb":"markdown","2ca2af4a":"markdown","67fe56a3":"markdown","a0936ffe":"markdown"},"source":{"3538958e":"# Setup plotting\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('animation', html='html5')\n\n# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning_intro.ex6 import *","40db4a41":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\nhotel = pd.read_csv('..\/input\/dl-course-data\/hotel.csv')\n\nX = hotel.copy()\ny = X.pop('is_canceled')\n\nX['arrival_date_month'] = \\\n    X['arrival_date_month'].map(\n        {'January':1, 'February': 2, 'March':3,\n         'April':4, 'May':5, 'June':6, 'July':7,\n         'August':8, 'September':9, 'October':10,\n         'November':11, 'December':12}\n    )\n\nfeatures_num = [\n    \"lead_time\", \"arrival_date_week_number\",\n    \"arrival_date_day_of_month\", \"stays_in_weekend_nights\",\n    \"stays_in_week_nights\", \"adults\", \"children\", \"babies\",\n    \"is_repeated_guest\", \"previous_cancellations\",\n    \"previous_bookings_not_canceled\", \"required_car_parking_spaces\",\n    \"total_of_special_requests\", \"adr\",\n]\nfeatures_cat = [\n    \"hotel\", \"arrival_date_month\", \"meal\",\n    \"market_segment\", \"distribution_channel\",\n    \"reserved_room_type\", \"deposit_type\", \"customer_type\",\n]\n\ntransformer_num = make_pipeline(\n    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n    StandardScaler(),\n)\ntransformer_cat = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n    OneHotEncoder(handle_unknown='ignore'),\n)\n\npreprocessor = make_column_transformer(\n    (transformer_num, features_num),\n    (transformer_cat, features_cat),\n)\n\n# stratify - make sure classes are evenlly represented across splits\nX_train, X_valid, y_train, y_valid = \\\n    train_test_split(X, y, stratify=y, train_size=0.75)\n\nX_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)\n\ninput_shape = [X_train.shape[1]]","b0adcf0e":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# YOUR CODE HERE: define the model given in the diagram\nmodel = keras.Sequential([\n    layers.BatchNormalization(),\n    layers.Dense(256, activation='relu', input_shape=input_shape),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid')\n])\n\n# Check your answer\nq_1.check()","ff0b3226":"# YOUR CODE HERE\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\n# Check your answer\nq_2.check()","a0777755":"# Lines below will give you a hint or solution code\n#q_2.hint()\n#q_2.solution()","70d3ffb3":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=200,\n    callbacks=[early_stopping],\n)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")","5b648179":"# View the solution (Run this cell to receive credit!)\nq_3.check()","339483ee":"Finally, run this cell to train the model and view the learning curves. It may run for around 60 to 70 epochs, which could take a minute or two.","0a9d6e0b":"First, load the *Hotel Cancellations* dataset.","a403fad9":"**This notebook is an exercise in the [Intro to Deep Learning](https:\/\/www.kaggle.com\/learn\/intro-to-deep-learning) course.  You can reference the tutorial at [this link](https:\/\/www.kaggle.com\/ryanholbrook\/binary-classification).**\n\n---\n","2c709de3":"# 2) Add Optimizer, Loss, and Metric #\n\nNow compile the model with the Adam optimizer and binary versions of the cross-entropy loss and accuracy metric.","5fe5ce81":"# 3) Train and Evaluate #\n\n\nWhat do you think about the learning curves? Does it look like the model underfit or overfit? Was the cross-entropy loss a good stand-in for accuracy?","1287f8eb":"# Conclusion #\n\nCongratulations! You've completed Kaggle's *Introduction to Deep Learning* course!\n\nWith your new skills you're ready to take on more advanced applications like computer vision and sentiment classification. What would you like to do next?\n\nWhy not try one of our *Getting Started* competitions?\n\n- Classify images with TPUs in [**Petals to the Metal**](https:\/\/www.kaggle.com\/c\/tpu-getting-started)\n- Create art with GANs in [**I'm Something of a Painter Myself**](https:\/\/www.kaggle.com\/c\/gan-getting-started)\n- Classify Tweets in [**Real or Not? NLP with Disaster Tweets**](https:\/\/www.kaggle.com\/c\/nlp-getting-started)\n- Detect contradiction and entailment in [**Contradictory, My Dear Watson**](https:\/\/www.kaggle.com\/c\/contradictory-my-dear-watson)\n\nUntil next time, Kagglers!","2ca2af4a":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/191966) to chat with other Learners.*","67fe56a3":"# Introduction #\n\nIn this exercise, you'll build a model to predict hotel cancellations with a binary classifier.","a0936ffe":"# 1) Define Model #\n\nThe model we'll use this time will have both batch normalization and dropout layers. To ease reading we've broken the diagram into blocks, but you can define it layer by layer as usual.\n\nDefine a model with an architecture given by this diagram:\n\n<figure style=\"padding: 1em;\">\n<img src=\"https:\/\/i.imgur.com\/V04o59Z.png\" width=\"400\" alt=\"Diagram of network architecture: BatchNorm, Dense, BatchNorm, Dropout, Dense, BatchNorm, Dropout, Dense.\">\n<figcaption style=\"textalign: center; font-style: italic\"><center>Diagram of a binary classifier.<\/center><\/figcaption>\n<\/figure>\n"}}