{"cell_type":{"ac00bd70":"code","b5f89b45":"code","4178ffb7":"code","6348fcb1":"code","29b91cc9":"code","caafc9d2":"code","90bc2a74":"code","613cbd11":"code","ea57b51f":"code","8e90d877":"markdown","c4faecef":"markdown","34fbd8b7":"markdown","dcfb9e45":"markdown","09061bac":"markdown","588e6fd7":"markdown","09075b20":"markdown","000c4def":"markdown","6d697f3c":"markdown","e3f5daf4":"markdown","513f3803":"markdown"},"source":{"ac00bd70":"#import the necessary packages\nfrom imutils import paths\nimport argparse\nimport imutils\nimport cv2\nimport os\nimport sys\n\n#Parse the arguments\nap=argparse.ArgumentParser()\nap.add_argument(\"-i\",\"--input\",required=True,help=\"path to input directory of images\")\nap.add_argument(\"-a\",\"--annot\",required=True,help=\"path to output directory of annotations\")\nargs=vars(ap.parse_args())","b5f89b45":"#grab the image paths and initialize the dictionary of character counts\n\nimagePaths=list(paths.list_images(args[\"input\"]))\ncounts={}","4178ffb7":"#loop over image paths \nfor (i,imagePath) in enumerate(imagePaths):\n    #display an update\n    print(f\"[PROCESSING IMAGES]Currently processing {i+1}\/{len(imagePaths)}\")\n    try:\n         #loading the images and converting them to grayscale\n         #add a border to ensure the digits on the border of the image are retained\n         image=cv2.imread(imagePath)\n         gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n         gray=cv2.copyMakeBorder(gray,8,8,8,8,cv2.BORDER_REPLICATE)","6348fcb1":"#threshold image \n         thresh=cv2.threshold(gray,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]","29b91cc9":" #find contours in the image,keeping only the four largest ones\n         cnts=cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n         cnts=cnts[0]\n         cnts=sorted(cnts,key=cv2.contourArea,reverse=True)[:4]\n      \n","caafc9d2":" #Loop over the contours\n         for c in cnts:\n             x,y,w,h=cv2.boundingRect(c)\n             roi=gray[y-5:y+h+5,x-5:x+w+5]\n             #display the character and then wait for keypress\n             cv2.imshow(\"ROI\",imutils.resize(roi,width=100))\n             key=cv2.waitKey(0)","90bc2a74":"#if the '`' (tilde)key is pressed then the ROI is ignored\nif key==ord(\"~\"):\n                 print(\"[INFO] IGNORING....\")\n                 continue\n             #grab the key that was pressed and construct the path to output directory\n             key=chr(key).upper()\n             dirPath=os.path.sep.join([args[\"annot\"],key])\n             #if the directory is not present then create it\n             if not os.path.exists(dirPath):\n                 os.makedirs(dirPath)","613cbd11":"#writing to file   \n             count=counts.get(key,1)\n             p=os.path.sep.join([dirPath,f\"{str(count).zfill(6)}.png\"])\n             cv2.imwrite(p,roi)\n             #increment the count for the current key\n             counts[key]=count+1","ea57b51f":"    #Handles the keyboard interrupt when we want to stop annotation         \n    except KeyboardInterrupt:\n        print(\"[INFO]Ugh I dont want to do this anymore....that's what she said\")\n        break\n    #catch the unexpected exception and print its type and line number\n    except Exception as e:\n        exception_type,exception_object,exception_traceback=sys.exc_info()\n        line_number=exception_traceback.tb_lineno\n        print(\"Exception type:\",exception_type)\n        print(\"Line Number\",line_number)\n        print(\"[INFO] skipping image......\")\n    \ncv2.destroyAllWindows()      ","8e90d877":"Now we loop over the contours and extract them by computing their bounding box. We loop over each of the contours found in the thresholded image. We call cv2.boundingRect to compute the bounding box (x, y)-coordinates of the digit region. This region of interest (ROI) is then extracted from the grayscale image.\nROI is then displayed and then it waits for a keypress, we have to be careful while pressing the key because this key will be used to label your ROI(you can pre-decide a key which represents a category in your image dataset).","c4faecef":"Our final code blocks handles if we want to quit the script or an unexpected error occurs.\nIf we want to exit the script then the first line in this code block detects this and allows us to exit the program gracefully. The last block catches all other exceptions, prints the type of exception and the line number and then ignores them to let us continue with the labelling process.","34fbd8b7":"# Annotating your image data efficiently\nWhile creating your own dataset for a project, the hardest part is annotating the data, infact once you are done with the annotation, the battle is half won. If you are also looking for a way to quickly get done with the boring and yet the most important part of your project, then follow along.\n(P.S.-This is my first Kaggle notebook, so please take the time to point out my mistakes, it will help me get familiar with Kaggle)\n\nIn this notebook, I will be using basic image processing techniques available inside OpenCV to help annotate our images dataset for tasks like classification fairly easily and efficiently.\n## Dependencies\nBefore proceeding, I want to lay out the required packages and libraries:\n1. OpenCV\n2. imutils(this is a set of convenience function by Adrian Rosebrock, and saves a lot of time)\n\nI used this to annotate the captcha images which I had downloaded while working on a project. The captcha images consisted of four numeric digits each. With a little tweaking it can be used to annotate your own image dataset.\nLet's get started,\n","dcfb9e45":"First, we import the necessary packages and then parse our command line arguments(the arguments provided at the time of running the script). This script requires two arguments:\n* --input: The input path to our raw images\n* --annot:The output path \n","09061bac":"Next we find contours in the image, to detect objects in the image. In my case, this happened to be four digits, therefore I sort the contours on the basis of their area and keep the four largest ones which will represent the digits, in case more contours are detected in the image owing to noise present in the image.","588e6fd7":"We loop over each individual image paths. For each image, we load it from the disk, convert it to grayscale and then pad the borders of the image. We pad the image to prevent any loss of information from the border edges while processing the images further.","09075b20":"We convert the image to binary by thresholding it, to separate the foreground from the background.","000c4def":"This code block grabs the paths to all images in the --input directory and initializes a\ndictionary named counts that will store the total number of times a given key has been pressed.","6d697f3c":"If the tilde(~) key is pressed then the object(ROI) is ignored, this may happen if our script accidentally detects noise. Otherwise we assume that the key pressed was the label and the key is used to construct the directory path of our output label.\nFor example if I pressed the *key 'C'* and the --annot argument was dataset, then dirPath would be:\n*dataset\/C*\nSince in my case I had to label digits,\nIf I pressed the *key 1*, then all the images containing the digit \"1\" would be stored in the *dataset\/1* sub directory.\nThen, it is checked if the dirPath directory exists, if it doesn't then we create the directory.","e3f5daf4":"Now that you have your labelled dataset, what is topping you from training your own network.\n\n### If you have reached this far, please leave an upvote for a wider reach.\nAny and all questions and suggestions are always welcome in the comments.\n#### Thank You !\n\n\n\nP.S.-(This notebook is based on my understanding of a chapter by Adrian Rosebrock)","513f3803":"The first line in the above code block grabs the total number of examples written to disk thus far for the current key. We then construct the output path using the dirPath. We then write to the output path p and the last line updates the counter for the current key.\nSay we are building the cats and dogs classifier wherein C represents a Cat in the image then after writing the image the output path p will look like:\n*dataset\/C\/000001.png*\nNow you see, how all the images containing cats will be stored in the subdirectory *dataset\/C*  this is an easy, convenient way to organize your datasets when labeling images."}}