{"cell_type":{"a5c554ab":"code","34838b70":"code","1dc9c237":"code","78e86644":"code","27fe548d":"code","ff012c84":"code","44e53e9c":"code","ba803034":"code","5dba2f6b":"code","70eee972":"code","56a4e8ad":"code","a92f7679":"code","c5962b56":"code","e02b410e":"code","c59cacb4":"code","d1be1fa7":"code","f68c4791":"code","bf8a8dd9":"code","766b8b34":"code","99a046be":"code","78ca0c35":"code","3997159a":"code","2837eb54":"code","bfa661ac":"code","037e210d":"code","a9fbea79":"code","125609e9":"code","7ae2651b":"code","3eed3aee":"code","6f97876f":"code","747edaad":"code","41e0d556":"code","8669e429":"code","4d72457f":"code","83c993d3":"code","6f641c74":"code","70993199":"code","fe9144d3":"code","85637e55":"code","2206934d":"code","dc1bfd2e":"code","87571407":"code","dcbdbb35":"code","52ea0adb":"code","335864d6":"code","b67a8bc9":"code","df1e3225":"code","33c8ab41":"code","7aedb8c3":"code","aef86681":"code","df40d11d":"code","8dac30b8":"code","f97800b4":"code","c9de857c":"code","ebc7394f":"code","62f9af13":"code","817ec7b7":"code","f6046ac4":"code","8328c676":"code","e9fbfa97":"code","ba617d61":"code","20046d9f":"code","e92131e0":"code","5873afe1":"code","19f850bf":"code","a1481a53":"markdown","e24c2c18":"markdown","feff88a3":"markdown","dccab69c":"markdown","48756165":"markdown","88d39fc1":"markdown","7277a9bf":"markdown","dbd3180d":"markdown","7889f86e":"markdown","156f6933":"markdown","63942848":"markdown","ce3ed56d":"markdown","a78953f7":"markdown","93437132":"markdown","f636558c":"markdown","98bb762c":"markdown","0201284f":"markdown","82860edd":"markdown","d13c2c15":"markdown","d9d7f8f1":"markdown","1729944c":"markdown","b4d5369c":"markdown","e854df88":"markdown","16d033cc":"markdown","74b207e4":"markdown","e5bffcc6":"markdown","447fc036":"markdown","dc0dadbf":"markdown"},"source":{"a5c554ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34838b70":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","1dc9c237":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","78e86644":"# Lecture des donn\u00e9es d'apprentissage et de test\nt = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","27fe548d":"t.head()","ff012c84":"display(t.info(),t.head())","44e53e9c":"t.count()","ba803034":"diabetes = t.fillna(value = {'Glucose':t.Glucose.mean()})","5dba2f6b":"plt.hist(diabetes.Glucose, bins=80)","70eee972":"diabetes.count()","56a4e8ad":"diabetes1 = diabetes.fillna(value = {'SkinThickness':t.SkinThickness.mean()})","a92f7679":"plt.hist(diabetes1.SkinThickness, bins=80)","c5962b56":"diabetes1.count()","e02b410e":"diabetes2 = diabetes1.fillna(value = {'BloodPressure':t.BloodPressure.mean()})","c59cacb4":"plt.hist(diabetes2.BloodPressure, bins=80)","d1be1fa7":"diabetes2.count()","f68c4791":"diabetes3 = diabetes2.fillna(value = {'Insulin':t.Insulin.mean()})","bf8a8dd9":"plt.hist(diabetes3.Insulin, bins=80)","766b8b34":"diabetes3.count()","99a046be":"diabetes4 = diabetes3.fillna(value = {'BMI':t.BMI.mean()})","78ca0c35":"plt.hist(diabetes4.BMI, bins=80)","3997159a":"diabetes4.count()","2837eb54":"sns.distplot(diabetes4.Insulin, color='blue')","bfa661ac":"diabetes4['log_Insulin'] = np.log(diabetes4.Insulin+1)","037e210d":"sns.kdeplot(diabetes4.log_Insulin, color='blue')","a9fbea79":"diabetes4[['Age','log_Insulin']].describe()","125609e9":"sns.kdeplot(diabetes4.log_Insulin, color='blue')\nsns.kdeplot(diabetes4.Age, color='red')","7ae2651b":"from sklearn import preprocessing","3eed3aee":"minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndiabetes4[['Age', 'log_Insulin']] = minmax.fit_transform(diabetes4[['Age', 'log_Insulin']])","6f97876f":"sns.distplot(diabetes4.log_Insulin, color='blue')\nsns.distplot(diabetes4.Age, color='red')","747edaad":"scaler = preprocessing.StandardScaler()\ndiabetes4[['Age', 'log_Insulin']] = scaler.fit_transform(diabetes4[['Age', 'log_Insulin']])","41e0d556":"sns.kdeplot(diabetes4.log_Insulin, color='blue')\nsns.kdeplot(diabetes4.Age, color='red')","8669e429":"X = diabetes4.drop(['Outcome'], axis=1)\ny = diabetes4.Outcome","4d72457f":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","83c993d3":"print(X_train.shape)\nprint(X_test.shape)","6f641c74":"from sklearn.linear_model import LogisticRegression","70993199":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","fe9144d3":"y_lr = lr.predict(X_test)","85637e55":"from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","2206934d":"print(confusion_matrix(y_test,y_lr))","dc1bfd2e":"print(accuracy_score(y_test,y_lr))","87571407":"print(classification_report(y_test, y_lr))","dcbdbb35":"probas = lr.predict_proba(X_test)","52ea0adb":"print(probas)","335864d6":"dfprobas = pd.DataFrame(probas,columns=['proba_0','proba_1'])\ndfprobas['y'] = np.array(y_test)","b67a8bc9":"dfprobas","df1e3225":"plt.figure(figsize=(10,10))\nsns.distplot(1-dfprobas.proba_0[dfprobas.y==0], bins=50)\nsns.distplot(dfprobas.proba_1[dfprobas.y==1], bins=50)\n","33c8ab41":"false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","7aedb8c3":"plt.figure(figsize=(12,12))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')        \nplt.plot([0,0,1],[0,1,1],'g:')     \nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n","aef86681":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","df40d11d":"print(classification_report(y_test, y_rf))","8dac30b8":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","f97800b4":"rf1 = ensemble.RandomForestClassifier(n_estimators=10, min_samples_leaf=10, max_features=3)\nrf1.fit(X_train, y_train)\ny_rf1 = rf.predict(X_test)\nprint(classification_report(y_test, y_rf1))","c9de857c":"from sklearn.model_selection import validation_curve\nparams = np.arange(1, 300,step=30)\ntrain_score, val_score = validation_curve(rf, X, y, 'n_estimators', params, cv=7)\nplt.figure(figsize=(12,12))\nplt.plot(params, np.median(train_score, 1), color='blue', label='training score')\nplt.plot(params, np.median(val_score, 1), color='red', label='validation score')\nplt.legend(loc='best')\nplt.ylim(0, 1)\nplt.xlabel('n_estimators')\nplt.ylabel('score');","ebc7394f":"from sklearn import model_selection","62f9af13":"param_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)","817ec7b7":"rf_gs.fit(X_train, y_train)","f6046ac4":"print(rf_gs.best_params_)","8328c676":"rf2 = rf_gs.best_estimator_","e9fbfa97":"y_rf2 = rf2.predict(X_test)","ba617d61":"print(classification_report(y_test, y_rf2))","20046d9f":"importances = rf2.feature_importances_\nindices = np.argsort(importances)","e92131e0":"plt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","5873afe1":"!pip install xgboost","19f850bf":"import xgboost as XGB\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\nprint(classification_report(y_test, y_xgb))","a1481a53":"Utilisation du XGBoost :","e24c2c18":"predict_proba donne un tableau de couples de probabilit\u00e9s :[probabilit\u00e9 de pr\u00e9diction 0, probabilit\u00e9 de pr\u00e9diction 1]","feff88a3":"On s\u00e9pare le dataset en deux parties (80% pour l'apprentissage et 20% pour le test) :","dccab69c":"Cr\u00e9ation de jeux d'apprentissage et de test :","48756165":"La m\u00e9thode GridSearchCV permet de tester plusieurs combinaisons de param\u00e8tres (list\u00e9s dans une grille de param\u00e8tres) et de s\u00e9lectionner celle qui donne la meilleure pertinence","88d39fc1":"Interpr\u00e9tation des param\u00e8tres :\nPregnancies = nombre de grossesse \/ Glucose = taux de glucose \/ BloodPressure = Pression dans le sang \/ SkinThickness = Epaisseur de la peau \/ Insulin = insulin \/ BMI = IMC \/ DiabetesPedigreeFunction = l'h\u00e9r\u00e9dit\u00e9 \/ Age = age \/ Outcome = R\u00e9sultat (0= pas de diab\u00e8te, 1 = diab\u00e8te)","7277a9bf":"On pose les valeurs de probabilit\u00e9s 1 dans un dataframe :","dbd3180d":"L'entrainement est lanc\u00e9 :","7889f86e":"Voici le score :","156f6933":"**Donn\u00e9es manquantes :**\n\nGr\u00e2ce \u00e0 la fonction fillna, on peut compl\u00e9ter les donn\u00e9es manquantes :","63942848":"Skin Thickness ","ce3ed56d":"BMI","a78953f7":"Insulin","93437132":"StandardScaler pour ramener la moyenne \u00e0 0 et l'\u00e9cart type \u00e0 1","f636558c":"Le meilleur estimateur :","98bb762c":"Mesure du nombre de bonnes pr\u00e9dictions sur le nombre total d'observations :","0201284f":"Faisons une r\u00e9gression logique afin de classifier l'ensemble test :","82860edd":"Test des for\u00eats al\u00e9atoires (Random Forest) :","d13c2c15":"Passons \u00e0 l'importation de m\u00e9thodes de mesure de performance :","d9d7f8f1":"Pour am\u00e9liorer l'\u00e9quilibre, on peut utiliser une transformation log :","1729944c":"Certaines distributions sont d\u00e9s\u00e9quilibr\u00e9es et s'\u00e9loignent d'une loi normale :","b4d5369c":"Normaliser les valeurs min et \u00e0 max (valeurs ramen\u00e9es entre 0 et 1)","e854df88":"Blood Pressure","16d033cc":"Importance des caract\u00e9ristiques :","74b207e4":"On affiche la distribution des probabilit\u00e9s de pr\u00e9diction de 1, et celle des non probabilit\u00e9s de pr\u00e9diction de 0 :","e5bffcc6":"Matrice de confusion :","447fc036":"La validation_curve permet de tracer la courbe du score sur un ensemble d'apprentissage et sur un ensemble de test (cross validation), en faisant varier un param\u00e8tre, par exemple n_estimators","dc0dadbf":"Glucose"}}