{"cell_type":{"f1d64724":"code","83673afc":"code","274150d7":"code","048d61e6":"code","3d0a8362":"code","76a08503":"code","06bfac32":"code","a4e3885a":"code","ecce3712":"code","7a2d847e":"code","c8e4b39e":"code","f8ea1b9d":"code","48fa3887":"code","7075add1":"markdown","135150b7":"markdown","0d0d5655":"markdown","965a037e":"markdown","0e0723c1":"markdown","5dc9519a":"markdown","a5f383bd":"markdown","509334c4":"markdown","e77ce3f2":"markdown","b27f05df":"markdown","cdc63584":"markdown","da4a4325":"markdown","c7201aab":"markdown"},"source":{"f1d64724":" \n# Import statements\n \nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n","83673afc":" \n# Split dataset into Train, Validation & Test sets\n \nsize = 224   # Resize all images to (size,size)\nbs = 32      # Batch size\n\n\n# Data augmentation on train dataset only\ntrain_data_gen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, zoom_range=0.1, shear_range=0.1, brightness_range=[0.8,1.2], validation_split=0.15, preprocessing_function=preprocess_input)\ntrain_data = train_data_gen.flow_from_directory(parent_folder, class_mode='categorical', target_size=(size,size), color_mode='rgb', batch_size=bs, seed=42, subset='training')\n\nvalidation_data_gen = ImageDataGenerator(validation_split=0.15, preprocessing_function=preprocess_input)\nvalidation_data = validation_data_gen.flow_from_directory(parent_folder, class_mode='categorical', target_size=(size,size), color_mode='rgb', batch_size=bs, seed=42, subset='validation')\n\ntest_data_gen = ImageDataGenerator(validation_split=0.10, preprocessing_function=preprocess_input)\ntest_data = test_data_gen.flow_from_directory(parent_folder, class_mode='categorical', target_size=(size,size), color_mode='rgb', subset='validation', shuffle=False)\n","274150d7":"\n# Assign essential variables\n\nshape = train_data.image_shape                 # Shape of train images (height,width,channels)\nprint(shape)\nk = train_data.num_classes                     # Total number of labels or classes\ntrain_samples = train_data.samples             # Total number of images in train set\nvalidation_samples = validation_data.samples   # total number of images in validation set\n","048d61e6":"# Build the model\n\n \ninput = Input(shape=shape)\n \nbasemodel = InceptionV3(include_top=False, weights='imagenet', input_shape=shape, pooling='avg')   # Basemodel is InceptionV3 with pretrained weights trained on imagenet dataset\nbasemodel.trainable = False                                                                        # Freeze the weights in all layers of the CNN\n \nx = basemodel(input)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.2)(x)\noutput = Dense(k, activation='softmax')(x)\n \nmodel = Model(input,output)\n ","3d0a8362":"\n# Compile the model\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","76a08503":" \n# Initialize callbacks\n \nstop = EarlyStopping(monitor='val_loss', patience=4, mode='min', restore_best_weights=True)                                             # Stops training early to prevent overfitting\ncheckpoint = ModelCheckpoint(filepath='{val_loss:.4f}-weights-{epoch:02d}.hdf5', monitor='val_loss', mode='min', save_best_only=True)   # Saves the model for every best val_loss\n","06bfac32":"\n# Model Summary\n\nmodel.summary()\n","a4e3885a":"\n# Train the model\n\nep = 50                      # Number of epochs\nspe = train_samples\/bs       # Steps per epoch\nvs = validation_samples\/bs   # Validation steps\n \nr = model.fit(train_data, validation_data=validation_data, steps_per_epoch=spe, validation_steps=vs, epochs=ep, callbacks=[stop,checkpoint])\n","ecce3712":" \n# Evaluate the model\n \nmodel.evaluate(validation_data)\n","7a2d847e":"\n# Plot training history\n \nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()\nplt.show()\nplt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.show()\n","c8e4b39e":"\n# Predictions on the test data\n\npred = model.predict(test_data).argmax(axis=1)\nlabels = list(train_data.class_indices.keys())\n","f8ea1b9d":"\n# Get the F1 score on test data prediction\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(test_data.classes, pred))\n","48fa3887":"\n# Visualize random predictions on the test data\n\nrand = np.random.randint(low=0, high=test_data.samples, size=5)\n\nfor n in rand:\n  true_index = test_data.classes[n]\n  predicted_index = pred[n]\n  img = cv2.imread(test_data.filepaths[n])\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  plt.imshow(img)\n  plt.title('True label={}  Predicted label={}'.format(labels[true_index], labels[predicted_index]))\n  plt.show()\n","7075add1":"# **Visualize predictions on test data**","135150b7":"# **Assign essential variables**","0d0d5655":"# **Model summary**","965a037e":"# **Callbacks**","0e0723c1":"# **Plot training history**","5dc9519a":"# **Import Statements**","a5f383bd":"# **Evaluate the model**","509334c4":"# **Predict on the test data**","e77ce3f2":"# **Build the model**","b27f05df":"# **Compile the model**","cdc63584":"# **Train the model**","da4a4325":"# **Split dataset into Train, Validation & Test sets**","c7201aab":"# **F1 Score**"}}