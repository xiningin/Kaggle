{"cell_type":{"6795d562":"code","86379caf":"code","ec16b48b":"code","e81cd110":"code","fdc03792":"code","b25a385c":"code","5433d063":"code","a2463900":"code","6e9ef64f":"code","2961117f":"code","2f39d870":"code","b316a8e5":"code","42605510":"code","f33abef5":"code","38df0cd5":"code","b2366897":"code","7b1ec12d":"code","84685879":"code","67600c7a":"code","db1103d9":"code","6b96e1ce":"code","32d83b85":"code","480abf5e":"code","7eb47b51":"code","91c05430":"code","ab7f5401":"markdown","c9146e31":"markdown","95f7c81c":"markdown","d8e50c9e":"markdown","9d7bd9df":"markdown","2e1cddcb":"markdown","a278d727":"markdown","32d6c5f3":"markdown","f1e27422":"markdown","70658bdf":"markdown","c347479d":"markdown","33705ef2":"markdown","751d3312":"markdown","0f434934":"markdown","fb2aadf4":"markdown","5dff9c84":"markdown"},"source":{"6795d562":"from keras.layers import Conv2D, Input\nfrom keras.models import Model\n\ninp = Input(shape=(8, 8, 256))\nx = Conv2D(256, (5, 5))(inp)\n\nmodel = Model(inp, x)\nmodel.summary()","86379caf":"from keras.layers import Conv2D, Input\nfrom keras.models import Model\n\ninp = Input(shape=(8, 8, 256))\nx = Conv2D(128, (1, 1))(inp)\nx = Conv2D(256, (5, 5))(x)\n\nmodel = Model(inp, x)\nmodel.summary()","ec16b48b":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Flatten, GlobalAvgPool2D, Dropout, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint\n\nfrom keras.applications.resnet import ResNet50, preprocess_input as resnet_preproc\nfrom keras.applications.vgg16 import VGG16, preprocess_input as vgg_preproc\n\nimport matplotlib.pyplot as plt","e81cd110":"train_data_path = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/'\ntest_data_path = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/'","fdc03792":"test_size = 0.3\nbatch_size = 32\ninput_shape = (256, 256)\nseed = 1\nnum_epoch = 4\nlearning_rate = 0.001\nnum_classes = 29","b25a385c":"data_gen = ImageDataGenerator(\n#     preprocessing_function=lambda x: x \/ 255.0,\n    preprocessing_function=resnet_preproc,\n    validation_split=test_size\n)\n\n\ntrain_gen = data_gen.flow_from_directory(\n    directory=train_data_path,\n    target_size=input_shape,\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode='categorical',\n    seed=seed,\n    subset='training'\n)\n\nval_gen = data_gen.flow_from_directory(\n    directory=train_data_path,\n    target_size=input_shape,\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode='categorical',\n    seed=seed,\n    subset='validation'\n)","5433d063":"# https:\/\/github.com\/keras-team\/keras-applications\/blob\/master\/keras_applications\/imagenet_utils.py\n\nfor X, y in train_gen:\n    print(X.shape, y.shape)\n    plt.imshow(X[0])\n    break","a2463900":"base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(input_shape[0], input_shape[1], 3))\nbase_model.summary()","6e9ef64f":"# x = Flatten()(base_model.output)\nx = GlobalAvgPool2D()(base_model.output)\nx = Dense(512, activation='relu')(x)\nx = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\nmodel.summary()","2961117f":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","2f39d870":"results = model.evaluate(val_gen, verbose=1, steps=100)\n\nprint(f\"Test Loss: {results[0]:.5f}\")\nprint(f\"Test Accuracy: {results[1] * 100:.2f}%\")","b316a8e5":"import keras\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nimport numpy as np\n\n\noptimizer = Adam(learning_rate=0.001) \nloss_fn = keras.losses.CategoricalCrossentropy()\n\n\ndef train_model(model=None, epochs=None, train_gen=train_gen, steps_per_epoch=100):\n    grad_log=[]\n    for epoch in range(epochs): \n\n        for step, (x_batch, y_batch) in enumerate(train_gen): \n            if step > steps_per_epoch:\n                break\n            \n            with tf.GradientTape() as tape:\n                preds = model(x_batch) \n\n                # \u0412\u044b\u0447\u0438\u0441\u043b\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u0442\u0435\u0440\u044c \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0431\u0430\u0442\u0447\u0430\n                loss_value = loss_fn(y_batch, preds)\n\n                # \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c gradient tape \u0434\u043b\u044f \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0438\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u044f \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \n                # \u043e\u0431\u0443\u0447\u0430\u0435\u043c\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u043e\u0442\u0435\u0440\u044c\n                grads = tape.gradient(loss_value, model.trainable_weights) \n            \n                g_g = []\n                # \u043f\u0438\u0448\u0435\u043c \u043b\u043e\u0433\u0438 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u0430 \u0438 \u0432\u0435\u0441\u0430 \u043f\u043e \u043e\u0434\u043d\u043e\u0439 \u0446\u0435\u043f\u0438 \n                for g_s in grads:   \n                    if len(g_s.numpy().shape)==1:\n                        g_g.append(g_s.numpy()[0])\n                    if len(g_s.numpy().shape) == 2:\n                        g_g.append(g_s.numpy()[0, 0]) \n                    if len(g_s.numpy().shape) == 3:\n                        g_g.append(g_s.numpy()[0, 0, 0]) \n                    if len(g_s.numpy().shape) == 4:\n                        g_g.append(g_s.numpy()[0, 0, 0, 0]) \n\n                # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0442\u0435\u043a\u0443\u0449\u0438\u0435 \u043b\u043e\u0433\u0438 \u043f\u043e \u0441\u043b\u043e\u044f\u043c \u043a \u043e\u0431\u0449\u0435\u0439 \u0437\u0430\u043f\u0438\u0441\u0438\n                grad_log.append(g_g)\n        \n                # \u0412\u044b\u043f\u043e\u043b\u043d\u0438\u043c \u043e\u0434\u0438\u043d \u0448\u0430\u0433 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0430 \u043e\u0431\u043d\u043e\u0432\u0438\u0432 # \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u044e\u0449\u0438\u0445 \u043f\u043e\u0442\u0435\u0440\u0438. \n                optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n                if step % (steps_per_epoch \/\/ 2) == 0: \n                    print(f'\u042d\u043f\u043e\u0445\u0430 {epoch + 1}\/{epochs}', end='. ')\n                    print(f'\u0428\u0430\u0433 {step}. \u041b\u043e\u0441\u0441 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (\u0434\u043b\u044f \u043e\u0434\u043d\u043e\u0433\u043e \u0431\u0430\u0442\u0447\u0430) \u043d\u0430 \u0448\u0430\u0433\u0435: {loss_value}') \n                    print(f'\u0423\u0436\u0435 \u0443\u0432\u0438\u0434\u0435\u043b\u0438: {(step + 1) * batch_size} \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432')\n                    \n    grad_log=np.array(grad_log)\n    return grad_log, model","42605510":"grad_log, models = train_model(model, 2, train_gen, steps_per_epoch=50)","f33abef5":"def visual_grad(grad_log=None, numb_layer=-1):\n    s_g = grad_log.shape\n\n    plt.figure(figsize=(16, 5))\n    plt.title('\u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u043f\u043e \u0441\u043b\u043e\u044f\u043c')\n    plt.xlabel('\u2116 layer')\n    plt.ylabel('grad')\n    plt.grid()\n    plt.plot(np.abs(grad_log[0, :numb_layer]),\n             label='step 0')\n    plt.plot(np.abs(grad_log[s_g[0] \/\/ 10, :numb_layer]),\n             label=f'step {str(s_g[0] \/\/ 10)}')\n    plt.plot(np.abs(grad_log[s_g[0] \/\/ 3, :numb_layer]),\n             label=f'step {str(s_g[0] \/\/ 3)}')\n    plt.plot(np.abs(grad_log[s_g[0]-1 , :numb_layer]),\n             label=f'step {str(s_g[0] )}')\n    plt.legend()\n    plt.show()","38df0cd5":"visual_grad(grad_log=grad_log, numb_layer=300)","b2366897":"for layer in model.layers[:-3]:\n    layer.trainable = False\n    \nmodel.summary()","7b1ec12d":"history = model.fit(\n                train_gen,\n                epochs=num_epoch,\n                steps_per_epoch=50,\n                validation_data=val_gen,\n                validation_steps=10,\n                callbacks=[\n                    ModelCheckpoint(\n                        filepath='best_model_{epoch}ep_{val_accuracy:.2f}',\n                        save_best_only=True\n                    )\n                ]\n            )","84685879":"base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(input_shape[0], input_shape[1], 3))\nbase_model.trainable = False\nbase_model.summary()","67600c7a":"x = GlobalAvgPool2D()(base_model.output)\nx = Dropout(0.1)(x)\nx = BatchNormalization()(x)\nx = Dense(512, activation='relu')(x)\nx = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\nmodel.summary()","db1103d9":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","6b96e1ce":"history = model.fit(\n                train_gen,\n                epochs=num_epoch,\n                steps_per_epoch=50,\n                validation_data=val_gen,\n                validation_steps=10,\n                callbacks=[\n                    ModelCheckpoint(\n                        filepath='best_model_{epoch}ep_{val_accuracy:.2f}',\n                        save_best_only=True\n                    )\n                ]\n            )","32d83b85":"import pandas as pd\npd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","480abf5e":"results = model.evaluate(val_gen, verbose=1, steps=100)\n\nprint(f\"Test Loss: {results[0]:.5f}\")\nprint(f\"Test Accuracy: {results[1] * 100:.2f}%\")","7eb47b51":"from pathlib import Path\nimport cv2\n\n\ndef show_predictions(preprocess_input, test_path):\n    imgs = sorted(list(Path(test_path).glob('*.jpg')))\n    print(len(imgs))\n\n    columns = 7\n    row = round(len(imgs) \/ columns)\n\n    fig, ax = plt.subplots(row, columns, figsize=(columns * row, row * columns))\n    plt.subplots_adjust(wspace=0.1, hspace=0.2)\n\n    i, j = 0, 0\n\n    for img_path in imgs:\n        origin_img = cv2.imread(str(img_path))\n        origin_img = cv2.cvtColor(origin_img, cv2.COLOR_BGR2RGB)\n        label = img_path.parts[-1].split('_')[0]\n        \n        img = cv2.resize(origin_img, (256, 256))\n        img = preprocess_input(img)\n\n        prediction = model.predict(img[None])\n\n        labels = (train_gen.class_indices)\n        labels = dict((v,k) for k,v in labels.items())\n        \n        ax[i][j].imshow(origin_img)\n        ax[i][j].set_title(f'GT {label}. Pred {labels[np.argmax(prediction, axis=1)[0]]}')\n        ax[i][j].axis('off')\n        j += 1\n        if j == columns:\n            j = 0\n            i += 1\n\n    plt.show()","91c05430":"%%time\nshow_predictions(resnet_preproc, test_data_path)","ab7f5401":"## Test Images","c9146e31":"## LeNet'98\n\n\u041e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0438 LeNet5:\n\n- \u0421\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u0430\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0430\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0438\u0437 \u0442\u0440\u0451\u0445 \u0441\u043b\u043e\u0451\u0432: \u0441\u043b\u043e\u0438 \u0441\u0432\u0451\u0440\u0442\u043a\u0438 (convolution), \u0441\u043b\u043e\u0438 \u0433\u0440\u0443\u043f\u043f\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f (pooling) \u0438 \u0441\u043b\u043e\u0438 \u043d\u0435\u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0441\u0442\u0438 (non-linearity) \u2013> \u0441 \u043c\u043e\u043c\u0435\u043d\u0442\u0430 \u043f\u0443\u0431\u043b\u0438\u043a\u0430\u0446\u0438\u0438 \u0440\u0430\u0431\u043e\u0442\u044b \u041b\u0435\u043a\u0443\u043d\u0430 \u044d\u0442\u043e, \u043f\u043e\u0436\u0430\u043b\u0443\u0439, \u043e\u0434\u043d\u0430 \u0438\u0437 \u0433\u043b\u0430\u0432\u043d\u044b\u0445 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0435\u0439 \u0433\u043b\u0443\u0431\u043e\u043a\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043a \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c.\n- \u041f\u043e\u0434\u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u044f \u043a\u0430\u0440\u0442.\n- \u041d\u0435\u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0441\u0442\u044c \u0432 \u0432\u0438\u0434\u0435 \u0433\u0438\u043f\u0435\u0440\u0431\u043e\u043b\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0442\u0430\u043d\u0433\u0435\u043d\u0441\u0430 \u0438\u043b\u0438 \u0441\u0438\u0433\u043c\u043e\u0438\u0434.\n- \u0424\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0432 \u0432\u0438\u0434\u0435 \u043c\u043d\u043e\u0433\u043e\u0441\u043b\u043e\u0439\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438.\n\n<img src='https:\/\/drive.google.com\/uc?exoprt=view&id=1pPe1aBh7ySg89cxbWEZ07iabvvXABUxd'>","95f7c81c":"<img src='https:\/\/drive.google.com\/uc?export=view&id=1qqbZ6iWZaD6LMjuIJ85mBGYpBwi0w-HL'>","d8e50c9e":"\u0413\u043b\u0443\u0431\u043e\u043a\u0438\u0435 \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0435 \u0441\u0435\u0442\u0438 \u043f\u0440\u0435\u0432\u0437\u043e\u0448\u043b\u0438 \u0447\u0435\u043b\u043e\u0432\u0435\u0447\u0435\u0441\u043a\u0438\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0432 2015 \u0433\u043e\u0434\u0443. \u0413\u043b\u0443\u0431\u043e\u043a\u0438\u0435 \u0441\u0435\u0442\u0438 \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u044e\u0442 \u043d\u0438\u0437\u043a\u043e-, \u0441\u0440\u0435\u0434\u043d\u0435- \u0438 \u0432\u044b\u0441\u043e\u043a\u043e\u0443\u0440\u043e\u0432\u043d\u0435\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438  \u0441\u043a\u0432\u043e\u0437\u043d\u044b\u043c \u043c\u043d\u043e\u0433\u043e\u0441\u043b\u043e\u0439\u043d\u044b\u043c \u0441\u043f\u043e\u0441\u043e\u0431\u043e\u043c, \u0430 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0441\u043b\u043e\u0435\u0432 \u043e\u0431\u043e\u0433\u0430\u0442\u0438\u0442\u044c \u00ab\u0443\u0440\u043e\u0432\u043d\u0438\u00bb \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432. \u041d\u043e \u0443 \u0433\u043b\u0443\u0431\u043e\u043a\u0438\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439 \u0431\u044b\u043b\u0430 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430: \u0437\u0430\u0442\u0443\u0445\u0430\u044e\u0449\u0438\u0435 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b. \u041e\u0441\u043e\u0431\u0435\u043d\u043d\u043e \u044d\u0442\u043e \u044f\u0432\u043d\u043e \u0447\u0443\u0432\u0441\u0442\u0432\u0443\u0435\u0442\u0441\u044f \u0441 \u0441\u0438\u0433\u043c\u043e\u0438\u0434\u043e\u0439.\n\n$d\\sigma = \\sigma(1 - \\sigma) \\leqslant \\frac{1}{4}$\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=171JbyNkSSqzhPdX4fp439zOouEzJmq_s'>","9d7bd9df":"## ResNet'15\n\n\u0414\u043e \u044d\u0442\u043e\u0433\u043e \u0431\u043e\u0440\u043e\u043b\u0438\u0441\u044c \u0441 \u0437\u0430\u0442\u0443\u0445\u0430\u044e\u0449\u0438\u043c\u0438 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u0430\u043c\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u0437\u0430 \u0441\u0447\u0435\u0442 \u0432\u0432\u043e\u0434\u0430 \u0434\u0440\u0443\u0433\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438.\n\n\u0427\u0442\u043e\u0431\u044b \u043f\u0440\u0435\u043e\u0434\u043e\u043b\u0435\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0437\u0430\u0442\u0443\u0445\u0430\u044e\u0449\u0438\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432, Microsoft \u0432\u0432\u0435\u043b\u0430 \u0433\u043b\u0443\u0431\u043e\u043a\u0443\u044e \u00ab\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u0443\u044e\u00bb \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1RGJQl4-SmysYbAqwcy8Lm5qEPbiebZOO'>\n\n\u0421\u043c\u044b\u0441\u043b:\n\n$y = f(x) + x $<br>\n$dy = df(x) + 1 $<br>\n<h3>$\\frac{dL}{dx} = \\frac{dL}{dy} \\frac{dy}{dx} = \\frac{dL}{dy}(df(x) + 1 )$<\/h3><br>\n\n\u0422\u043e \u0435\u0441\u0442\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b \u0432\u0441\u0451 \u0440\u0430\u0432\u043d\u043e \u0431\u0443\u0434\u0443\u0442 \u043f\u0440\u043e\u0442\u0435\u043a\u0430\u0442\u044c \u0434\u0430\u043b\u044c\u0448\u0435 \u0432 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043d\u043e\u043c \u0432\u0438\u0434\u0435.\n\n\n\u0421\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f \u0431\u044b\u0441\u0442\u0440\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 (shortcut connections, residual connections) \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u044e\u0442 \u043e\u0434\u0438\u043d \u0438\u043b\u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u043b\u043e\u0435\u0432 \u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u044e\u0442 \u0441\u043e\u043f\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u043e\u0432.\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1JcQDIjA-97L2xs3o-JD4SWBld9J0OMW-'>\n\n\u0415\u0449\u0435 \u043e\u0434\u043d\u0430 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c ResNet, \u0447\u0442\u043e \u0432 \u043a\u043e\u043d\u0446\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0435 \u0441\u043b\u043e\u0438, \u043f\u0440\u0438\u0447\u0438\u043d\u0430 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u0438\u043c\u0435\u0435\u0442\u0441\u044f \u0443\u0436\u0435 \u0438 \u0442\u0430\u043a \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0441\u043b\u043e\u0436\u043d\u0430\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0443\u0436\u0435 \u0438 \u0442\u0430\u043a \u043c\u043e\u0433\u043b\u0430 \u0440\u0435\u0448\u0438\u0442\u044c\u0441\u044f \u0437\u0430\u0434\u0430\u0447\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043e\u0431\u044b\u0447\u043d\u0430 \u043f\u0435\u0440\u0435\u043a\u043b\u0430\u0434\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439.","2e1cddcb":"## VGG'14\n\u0412 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0432 \u041e\u043a\u0441\u0444\u043e\u0440\u0434\u0435 VGG-\u0441\u0435\u0442\u044f\u0445 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u043c \u0441\u043b\u043e\u0435 \u0432\u043f\u0435\u0440\u0432\u044b\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043b\u0438 \u0444\u0438\u043b\u044c\u0442\u0440\u044b 3\u04453 \u0438 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u043b\u0438 \u044d\u0442\u0438 \u0441\u043b\u043e\u0438 \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0441\u0432\u0451\u0440\u0442\u043e\u043a.\n\n\u0412\u043c\u0435\u0441\u0442\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c\u044b\u0445 \u0432 AlexNet \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 9\u04459 \u0438 11\u044511 \u0441\u0442\u0430\u043b\u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0442\u044c \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u0435\u0435 \u043c\u0435\u043b\u043a\u0438\u0435 \u0444\u0438\u043b\u044c\u0442\u0440\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u0442\u0430\u0440\u0430\u043b\u0438\u0441\u044c \u0438\u0437\u0431\u0435\u0436\u0430\u0442\u044c \u0430\u0432\u0442\u043e\u0440\u044b LeNet. \u041d\u043e \u0431\u043e\u043b\u044c\u0448\u0438\u043c \u043f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432\u043e\u043c VGG \u0441\u0442\u0430\u043b\u0430 \u043d\u0430\u0445\u043e\u0434\u043a\u0430, \u0447\u0442\u043e \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u0432\u0451\u0440\u0442\u043e\u043a 3\u04453, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0451\u043d\u043d\u044b\u0445 \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c, \u043c\u043e\u0433\u0443\u0442 \u044d\u043c\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u043a\u0440\u0443\u043f\u043d\u044b\u0435 \u0441\u0432\u0435\u0440\u0442\u043a\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, 5\u04455 \u0438\u043b\u0438 7\u04457.\n\n\u041a\u0430\u0441\u043a\u0430\u0434 \u0438\u0437 \u0434\u0432\u0443\u0445 \u0441\u0432\u0435\u0440\u0442\u043e\u043a 3\u04453 \u0440\u0430\u0432\u0435\u043d \u0441\u0432\u0435\u0440\u0442\u043a\u0435 5\u04455, \u043d\u043e \u0441 \u043c\u0435\u043d\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432.\n(5\u04455 = 25 + 1 = 26; 3x3 + 3x3 + 2 = 20)\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1GvrtEDocJ3xp9RKqgQu0-JnyTssqZhzV'>","a278d727":"## Visualize the result\n","32d6c5f3":"## AlexNet'12\n\n\u0412 AlexNet \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0439 LeNet \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u044b \u0432 \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u0435\u0435 \u043a\u0440\u0443\u043f\u043d\u0443\u044e \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u0430 \u0438\u0437\u0443\u0447\u0438\u0442\u044c \u043d\u0430\u043c\u043d\u043e\u0433\u043e \u0431\u043e\u043b\u0435\u0435 \u0441\u043b\u043e\u0436\u043d\u044b\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u044b \u0438 \u0438\u0445 \u0438\u0435\u0440\u0430\u0440\u0445\u0438\u0438. \u041e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0438:\n\n- \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0431\u043b\u043e\u043a\u043e\u0432 ReLU \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043d\u0435\u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0441\u0442\u0435\u0439.\n- \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 max pooling, \u0447\u0442\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0438\u0437\u0431\u0435\u0436\u0430\u0442\u044c \u044d\u0444\u0444\u0435\u043a\u0442\u043e\u0432 \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u044f average pooling.\n\n\u041d\u0430 \u0432\u0445\u043e\u0434 \u0438\u0434\u0443\u0442 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 224\u0445224, \u0435\u0441\u0442\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u043d\u0435 \u0432\u0441\u0435 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0442\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0431\u0443\u0434\u0435\u0442 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u043f\u0440\u043e\u0441\u0442\u043e \u0441\u0436\u0430\u0442\u044c \u0438\u0445 \u0434\u043e \u043d\u0443\u0436\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430.\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1sjEftFGiJ50-m3VevamktVznsx6bY3Yw' width=700>","f1e27422":"\u0420\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0438 \u044d\u0442\u043e\u0439 \u0441\u0435\u0442\u0438 \u043f\u0440\u0438\u0434\u0443\u043c\u0430\u043b\u0438 \u0441\u043f\u043e\u0441\u043e\u0431, \u0447\u0442\u043e\u0431\u044b \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b \u043d\u0435 \u0437\u0430\u0442\u0443\u0445\u0430\u043b\u0438: \u0432\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u043d\u0430 \u043f\u0440\u043e\u0442\u044f\u0436\u0435\u043d\u0438\u0438 \u0432\u0441\u0435\u0439 \u0441\u0435\u0442\u0438, \u0447\u0442\u043e\u0431\u044b \u043a\u043e\u0433\u0434\u0430 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0432\u044b\u0445\u043e\u0434\u0430 \u043d\u0430\u0447\u0438\u043d\u0430\u043b \u0437\u0430\u0442\u0443\u0445\u0430\u0442\u044c, \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0430\u043b\u0441\u044f \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u0441\u043e \u0432\u0442\u043e\u0440\u043e\u0433\u043e \u0432\u044b\u0445\u043e\u0434\u0430.\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1q3oJXpwGStYit5Ii13DIsexVqxwIjyjE'>","70658bdf":"\u041f\u0440\u043e\u0434\u043e\u043b\u0436\u0438\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","c347479d":"\u041c\u043d\u043e\u0433\u0438\u0435 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u0431\u0443\u0447\u0430\u043b\u0438\u0441\u044c \u043d\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 ImageNet, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 14,197,122 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a - \u044d\u0442\u043e \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0440\u0430\u0437\u043c\u0435\u0447\u0430\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0441 \u0432\u044b\u0441\u043e\u043a\u0438\u043c \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0435\u043c, \u043e\u0442\u043d\u043e\u0441\u044f\u0449\u0438\u0445\u0441\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043a 22 \u0442\u044b\u0441\u044f\u0447\u0430\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439. \u041f\u0440\u043e\u0432\u043e\u0434\u0438\u043b\u0441\u044f \u00ab\u041a\u0440\u0443\u043f\u043d\u043e\u043c\u0430\u0441\u0448\u0442\u0430\u0431\u043d\u044b\u0439 \u043a\u043e\u043d\u043a\u0443\u0440\u0441 \u0432\u0438\u0437\u0443\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f ImageNet\u00bb (ILSVRC2013). ILSVRC \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u043f\u043e\u0434\u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e ImageNet \u0438\u0437 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e 1000 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 1000 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439.\n\n<img src='https:\/\/avatars.mds.yandex.net\/get-zen_doc\/127510\/pub_5c33ad37c906e200abbace3b_5c33adfbe5e73b00aad095a1\/scale_1200'>","33705ef2":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b \u043d\u0430 \u0441\u043b\u043e\u044f\u0445","751d3312":"## Load the Images with a generator","0f434934":"## GoogLeNet\n\n\u042d\u0442\u0430 \u0441\u0435\u0442\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 Inception \u0431\u043b\u043e\u043a\u0438. \u042d\u0442\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u044f \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 1\u04451, 3\u04453 \u0438 5\u04455. \u041d\u043e \u0433\u043b\u0430\u0432\u043d\u0430\u044f \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432 1\u04451 \u0434\u043b\u044f \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u044f \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043a\u0430\u043d\u0430\u043b\u043e\u0432 \u043f\u0435\u0440\u0435\u0434 \u043f\u043e\u0434\u0430\u0447\u0435\u0439 \u0432 \u0431\u043e\u043b\u0435\u0435 \u00ab\u0434\u043e\u0440\u043e\u0433\u0438\u0435\u00bb \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0435 \u0431\u043b\u043e\u043a\u0438. \u041e\u0431\u044b\u0447\u043d\u043e \u044d\u0442\u0443 \u0447\u0430\u0441\u0442\u044c \u043d\u0430\u0437\u044b\u0432\u0430\u044e\u0442 bottleneck. \u0412\u043c\u0435\u0441\u0442\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u0432\u0435\u0440\u0442\u043a\u0438 5\u04455 \u043d\u0430 \u043d\u0430\u0448\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0438, \u043c\u043e\u0436\u0435\u043c \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043f\u0440\u043e\u0439\u0442\u0438\u0441\u044c \u0441\u0432\u0435\u0440\u0442\u043a\u043e\u0439 1\u04451 \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0432 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u0430\u043d\u0430\u043b\u043e\u0432, \u0430 \u0437\u0430\u0442\u0435\u043c \u043f\u043e \u043d\u0438\u043c \u043f\u0440\u043e\u0439\u0442\u0438\u0441\u044c \u0441\u0432\u0435\u0440\u0442\u043a\u043e\u0439 5\u04455, \u0432\u0435\u0440\u043d\u0443\u0432 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u0430\u043d\u0430\u043b\u043e\u0432. \u041e\u043f\u0435\u0440\u0430\u0446\u0438\u0439 \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044c\u0448\u0435, \u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0431\u0443\u0434\u0435\u0442 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0439.\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1hgoTi6d-pdRPHgnfVGssQIQXBUdrkWrk'>","fb2aadf4":"## Load the model\n","5dff9c84":"## Train the model\n"}}