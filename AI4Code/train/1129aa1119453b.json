{"cell_type":{"44de2ccf":"code","220d843a":"code","c36ea625":"code","b0998b9d":"code","0020156b":"code","bd450222":"code","0a27d59f":"code","d825b13d":"code","63772baf":"code","b235db9b":"code","18be1e63":"code","4573da53":"code","3dc8063a":"code","6c4ed830":"code","c306c3ee":"code","9f5a344f":"code","9a196bb4":"code","9a4f01e9":"code","601248b4":"markdown","38dbf2ca":"markdown","ad54ed7f":"markdown","5e61036e":"markdown","32efbd94":"markdown","29eef697":"markdown","0052b66c":"markdown","d64a97d3":"markdown","b5dd4f87":"markdown","d16461ce":"markdown","61c4bafc":"markdown","41747d58":"markdown","79fb7d5b":"markdown","21fa6f52":"markdown","d55b26e8":"markdown"},"source":{"44de2ccf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","220d843a":"dataset_train = pd.read_csv('\/kaggle\/input\/Stock_Price_Train.csv')\ndataset_train.head()","c36ea625":"train = dataset_train.loc[:,[\"Open\"]].values\ntrain","b0998b9d":"plt.plot(train)\nplt.xlabel('Time')\nplt.ylabel('Price Open Value')\nplt.title('Stock Price')\nplt.show()","0020156b":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nscaler = MinMaxScaler(feature_range = (0,1))\ntrain_scaled = scaler.fit_transform(train)\ntrain_scaled\n","bd450222":"plt.plot(train_scaled)\nplt.show()","0a27d59f":"X_train = []\ny_train = []\ntime_stemp = 50\nfor i in range(time_stemp, 1258):\n    X_train.append(train_scaled[i-time_stemp:i, 0])\n    y_train.append(train_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)\n","d825b13d":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train","63772baf":"y_train","b235db9b":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n","18be1e63":"model = Sequential()\nmodel.add(LSTM(10,input_shape = (X_train.shape[1],1))) #10LSTM neuron(block)\nmodel.add(Dense(1))\nmodel.compile(optimizer = 'adam',loss = 'mean_squared_error')\nmodel.fit(X_train,y_train,epochs = 100, batch_size = 1)","4573da53":"test_dataset = pd.read_csv('\/kaggle\/input\/Stock_Price_Test.csv')\ntest_dataset.head()","3dc8063a":"real_stock_price = test_dataset.loc[:,['Open']].values\nreal_stock_price","6c4ed830":"dataset_total = pd.concat((dataset_train['Open'],test_dataset['Open']),axis = 0)\ninputs = dataset_total[len(dataset_total) - len(test_dataset) - time_stemp:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)\ninputs","c306c3ee":"X_test = []\ny_test = []\nfor i in range(time_stemp, 70):\n    X_test.append(inputs[i-time_stemp:i,0])\n    y_test.append(inputs[i, 0])\nX_test, y_test = np.array(X_test), np.array(y_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))","9f5a344f":"predicted_stock_price = model.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)","9a196bb4":"import matplotlib.pyplot as plt\nimport math\ntrain_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)\ntrain_predict = scaler.inverse_transform(train_predict)\ntrainY = scaler.inverse_transform([y_train])\ntest_predict = scaler.inverse_transform(test_predict)\ntestY= scaler.inverse_transform([y_test])\ntrain_score = math.sqrt(mean_squared_error(trainY[0],train_predict[:,0]))\nprint('Train Score %.2f RMSE' %(train_score))\ntest_score = math.sqrt(mean_squared_error(testY[0],test_predict[:,0]))\nprint('Test Score %.2f RMSE' %(test_score))","9a4f01e9":"plt.plot(real_stock_price, color =  'red', label = 'real_stock_price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'predicted_stock_price with lstm' )\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show","601248b4":"# Create RNN Model","38dbf2ca":"# Feature Scaling (Normalization)","ad54ed7f":"# Load and Preprocessing Data","5e61036e":"* This preprocessing provide us with opportunities to rescale our train data from 0 to 1. \n* Actually, It is a normalization process. ","32efbd94":"* **Needed Libraries**","29eef697":"* **Getting Test Data**","0052b66c":"* **Prediction Part**","d64a97d3":"* **Initializing LSTM**","b5dd4f87":"# Reshaping","d16461ce":"# Spliting Train to x_train and y_train\n* In this part, A data structure with 50 timesteps and 1 output is  created.\n* It takes first 50 datas as x_train and 51th data become y_train to predict it. Then again It takes 1 - 51 data as x_train and 52th data as y_train and so on with shifting one.","61c4bafc":"* **Visualization**","41747d58":"# Conclusion\n* **RNN with LSTM Layer gives us better result than RNN**\n* **You can look at this notebooks for [RNN without LSTM in Stock Price Dataset]**(https:\/\/www.kaggle.com\/muhammeddalkran\/implementing-rnn-without-lstm-with-keras)","79fb7d5b":"* Visualization of Our Train Data\n","21fa6f52":"# Implementing RNN(Recurrent Neural Network with LSTM) with Keras\n* > For Implementing RNN(Recurrent Neural Network without LSTM) with Kreas, Please Look at [here](https:\/\/www.kaggle.com\/muhammeddalkran\/implementing-rnn-without-lstm-with-keras)","d55b26e8":"# Predictions and Visualization RNN Model"}}