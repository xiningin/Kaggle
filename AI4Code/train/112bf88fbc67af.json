{"cell_type":{"58af61c2":"code","e86a2bf8":"code","479b59d1":"code","f53d4d3e":"code","92cbcddd":"code","a38bf4ab":"code","bc0a7bb7":"code","6228fbee":"code","ff59b0d9":"code","2ca9be22":"code","f1945157":"markdown"},"source":{"58af61c2":"import math\nimport os\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.applications import DenseNet201\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\nimport time\nfrom keras.models import load_model\nfrom keras.preprocessing import image ","e86a2bf8":"model = load_model('..\/input\/dr-detection\/dr_model.h5')\nmodel.summary()","479b59d1":"from keras.models import Model  \ndr_model = Model(inputs=model.layers[0].layers[0].input, \n                 outputs=(model.layers[0].layers[-1].output)) ","f53d4d3e":"def GetCAM(model,cmodel,img_path):\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    x = np.expand_dims(x, axis=0)\n    pred_vec = model.predict(x)\n    pred=np.argmax(pred_vec)\n    print(img_path)\n    if pred==1:\n        print(\"==> DR\")\n    else:\n        print(\"==> NODR\")\n    last_conv_output = dr_model.predict(x)\n    last_conv_output = np.squeeze(last_conv_output)\n    # bilinear upsampling to resize each filtered image to size of original image \n    mat_for_mult = scipy.ndimage.zoom(last_conv_output, (32, 32, 1), order=1) \n    # dim: 224 x 224 x 1048\n    #print(mat_for_mult.shape)\n    # get fc layer weights\n    all_amp_layer_weights = model.layers[-1].get_weights()[0]\n    amp_layer_weights = all_amp_layer_weights[:, pred]\n    # get class activation map for object class that is predicted to be in the image\n    cam = np.dot(mat_for_mult.reshape((224*224, 1024)), amp_layer_weights).reshape(224,224) \n    # dim: 224 x 224\n    return cam\n    \n    ","92cbcddd":"cam=GetCAM(model,dr_model,\"..\/input\/aptos2019-blindness-detection\/train_images\/0083ee8054ee.png\")","a38bf4ab":"plt.imshow(cam)","bc0a7bb7":"im = cv2.resize(cv2.cvtColor(cv2.imread(\"..\/input\/aptos2019-blindness-detection\/train_images\/0097f532ac9f.png\"), cv2.COLOR_BGR2RGB), (224, 224))","6228fbee":"fig, ax = plt.subplots()\nax.imshow(im, alpha=1)\nax.imshow(cam, cmap='jet', alpha=0.1)","ff59b0d9":"train_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')","2ca9be22":"fig = plt.figure(figsize=(32, 32))\nnum_samples=2\n\nfor class_id in sorted(train_df['diagnosis'].unique()):\n    for i, (idx, row) in enumerate(train_df.loc[train_df['diagnosis'] == class_id].sample(num_samples).iterrows()):\n        ax = fig.add_subplot(5, num_samples, class_id *num_samples + i + 1, xticks=[], yticks=[])\n        im = cv2.resize(cv2.cvtColor(cv2.imread(f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"), cv2.COLOR_BGR2RGB), (224, 224))\n        cam=GetCAM(model,dr_model,f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\")\n        #plt.imshow(im)\n        ax.imshow(im, alpha=1)\n        ax.imshow(cam, cmap='jet', alpha=0.3)\n        ax.set_title(f'Label: {class_id}')","f1945157":"Lets load binary classification model (NODR vs DR)"}}