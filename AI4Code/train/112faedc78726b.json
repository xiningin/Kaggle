{"cell_type":{"f43b91be":"code","9af36cdb":"code","f9764c8a":"code","920016fe":"code","2b389928":"code","2c2f89a3":"code","e3d4a9b6":"code","24500260":"code","3afe361a":"code","24fabb55":"markdown","8a527967":"markdown","1cc8dfe9":"markdown"},"source":{"f43b91be":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u3092import\u3057\u307e\u3059\nfrom io import BytesIO\nimport warnings\nimport multiprocessing\nimport IPython\nimport time\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm.notebook import tqdm\nimport librosa \nimport librosa.display\nfrom pydub import AudioSegment\nwarnings.simplefilter('ignore')","9af36cdb":"!pip install gtts\nfrom gtts import gTTS","f9764c8a":"INPUT_DIR = '\/kaggle\/input\/hah-data-science-challenge'","920016fe":"# \u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\ndf_train = pd.read_csv(f'{INPUT_DIR}\/train.csv', index_col=False)\ndf_test = pd.read_csv(f'{INPUT_DIR}\/test.csv', index_col=False)\ndf = pd.concat([df_train, df_test])","2b389928":"recording_map = {\n    'PC\u5185\u81d3': 'PC\u5185\u8535', \n    'PC\u5185\u8535': 'PC\u5185\u8535', \n    'USB1': 'USB1', \n    'USB2': 'USB2', \n    'USB3': 'USB3', \n    'USB4': 'USB4', \n    '\u30b9\u30de\u30db': '\u30b9\u30de\u30db', \n    '\u30b9\u30de\u30db\u306e\u30dc\u30a4\u30b9\u30ec\u30b3\u30fc\u30c0': '\u30b9\u30de\u30db', \n    '\u5185\u8535\u30de\u30a4\u30af': 'PC\u5185\u8535'\n}\n\ndistance_map = {\n    '10cm': '10cm',\n    '10\u339d': '10cm',\n    '1M': '1m',\n    '20cm': '20cm',\n    '20\u339d': '20cm',\n    '2M': '2m',\n    '2m': '2m',\n    '30cm': '30cm',\n    '30cn': '30cm',\n    '30\u339d': '30cm',\n    '3m': '3m',\n    '40cm': '40cm',\n    '40\u339d': '40cm',\n    '50cm': '50cm',\n    '50\u339d': '50cm',\n    '5cm': '5cm',\n    '8cm': '8cm',\n    '\uff11\uff2d': '1m'\n}\n\ndf['\u9332\u97f3\u65b9\u6cd5'] = df['\u9332\u97f3\u65b9\u6cd5'].replace(recording_map)\ndf['\u30de\u30a4\u30af\u8ddd\u96e2'] = df['\u30de\u30a4\u30af\u8ddd\u96e2'].replace(distance_map)\ndf['Target'] = df['Target'].fillna('\u30e9\u30d9\u30eb\u306a\u3057').replace({0.0:'\u6b63\u5e38', 1.0:'\u7570\u5e38'})\ndf['file_stem'] = df['\u30d5\u30a1\u30a4\u30eb'].str.replace('.wav', '')","2c2f89a3":"# \u30b0\u30eb\u30fc\u30d7\u3092\u793a\u3059\u5217\u3092\u8ffd\u52a0\ndf['group'] = '\u306d\u3058' + df['\u306d\u3058'] + '_\u30d7\u30ec\u30fc\u30c8' + df['\u30d7\u30ec\u30fc\u30c8'] + '_' + df['\u9332\u97f3\u65b9\u6cd5'] + '_' + df['\u30de\u30a4\u30af\u8ddd\u96e2']","e3d4a9b6":"df.head()","24500260":"def output_merged_wavfile(args):\n    group, df = args\n    sounds = AudioSegment.empty()\n    \n    # \u30b0\u30eb\u30fc\u30d7\u306e\u8aac\u660e\u6587\u3092text_to_speech\u3067\u4f5c\u6210\u3057\u3001\u982d\u306b\u8ffd\u52a0\n    group_caption = group.replace('_', '\u3002') # \u30b0\u30eb\u30fc\u30d7\u306e\u8aac\u660e\u6587\n    tts = gTTS(text=group_caption, lang='ja', slow=False)\n    mp3_fp = BytesIO()\n    tts.write_to_fp(mp3_fp)\n    mp3_fp.seek(0)\n    caption = AudioSegment.from_mp3(mp3_fp)\n    sounds += caption\n    \n    # \u5404\u30d5\u30a1\u30a4\u30eb\u306e\u30c7\u30fc\u30bf\u3092\u8ffd\u52a0\n    files = df['\u30d5\u30a1\u30a4\u30eb'].to_list()\n    targets = df['Target'].to_list()\n    for file, target in zip(files, targets):\n        if 'train' in file:\n            filepath = f'{INPUT_DIR}\/train\/train\/{file}'\n            file_caption = file.replace('.wav', '') + '\u3002' + target\n        elif 'test' in file:\n            filepath = f'{INPUT_DIR}\/test\/test\/{file}'\n            file_caption = file.replace('.wav', '')\n            \n        # file\u306e\u8aac\u660e\u6587\u3092text_to_speech\u3067\u4f5c\u6210\n        tts = gTTS(text=file_caption, lang='ja', slow=False)\n        mp3_fp = BytesIO()\n        tts.write_to_fp(mp3_fp)\n        mp3_fp.seek(0)\n        caption = AudioSegment.from_mp3(mp3_fp)\n        caption = caption.speedup(playback_speed=1.75)\n\n        # \u6253\u97f3\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n        sound = AudioSegment.from_file(filepath, \"wav\")\n        # \u97f3\u58f0\u30c7\u30fc\u30bf\u3092\u7d50\u5408\n        sounds += caption + sound\n        \n        time.sleep(10) # gtts\u3078\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u304c\u9ad8\u983b\u5ea6\u3060\u3068\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067wait\u304b\u3051\u308b\n        \n    sounds.export(f'{group}.wav', format=\"wav\")\n    return","3afe361a":"processes = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    imap = pool.imap_unordered(output_merged_wavfile, df.groupby('group'))\n    result = list(tqdm(imap, total=df['group'].nunique()))","24fabb55":"# \u540d\u5bc4\u305b\u3068\u30b0\u30eb\u30fc\u30d7\u5206\u3051\n\uff08 \u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\uff1ahttps:\/\/www.kaggle.com\/ryoichi0917\/corrections-to-notation-errors-and-eda-for-meta \uff09\n\n\u8868\u8a18\u63fa\u308c\u3092\u76f4\u3057\u305f\u3046\u3048\u3067\u3001\u6761\u4ef6\u306e\u7d44\u307f\u5408\u308f\u305b\u306e\u30b0\u30eb\u30fc\u30d7\u306b\u5206\u3051\u307e\u3059","8a527967":"# wav\u30d5\u30a1\u30a4\u30eb\u7d50\u5408\uff08caption\u4ed8\u304d\uff09\n\u5404\u6761\u4ef6\u30b0\u30eb\u30fc\u30d7\u3054\u3068\u306e\u6253\u97f3\u30c7\u30fc\u30bf\u3092\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u307e\u3068\u3081\u307e\u3057\u305f\u3002  \ntext_to_speech\u3067\u306e\u30ad\u30e3\u30d7\u30b7\u30e7\u30f3\u4ed8\u304d\u3067\u3059\u3002  \n\u901a\u52e4\u306e\u304a\u4f9b\u3084\u4f5c\u696d\u7528BGM\u306b\u3069\u3046\u305e\u3002","1cc8dfe9":"# \u5404\u30b0\u30eb\u30fc\u30d7\u3054\u3068wav\u30d5\u30a1\u30a4\u30eb\u3092\u7d50\u5408\u3057\u3001wav\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b"}}