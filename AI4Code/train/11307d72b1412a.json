{"cell_type":{"53f7f455":"code","fd37985e":"code","25eca80d":"code","8e474486":"code","c7058c06":"code","84e85342":"code","18daaa4f":"code","0b0be65c":"code","f75a077c":"code","64b755f4":"code","e2d55919":"code","c9a7c4e3":"code","d6f5d274":"code","4dde2569":"code","5b5d935e":"code","87986657":"code","1d864959":"code","ae5155b2":"code","9efedfa0":"code","98c9d610":"code","5b25276c":"code","b66df4c6":"code","f05c532b":"markdown","9982b910":"markdown","8c9ac369":"markdown"},"source":{"53f7f455":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd37985e":"import matplotlib.pyplot as plt\nfrom glob import glob\nfrom sklearn import model_selection\nimport torch\nimport albumentations as albu\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom pytorch_lightning.callbacks import EarlyStopping\nfrom sklearn import metrics\n%matplotlib inline","25eca80d":"early_stop_callback = EarlyStopping(\n   monitor='val_loss',\n   min_delta=0.0001,\n   patience=5,\n   verbose=False,\n   mode='min',\n)","8e474486":"with_mask = glob('\/kaggle\/input\/face-mask-dataset\/data\/with_mask\/*.jpg')\nwithout_mask = glob('\/kaggle\/input\/face-mask-dataset\/data\/without_mask\/*.jpg')","c7058c06":"fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(15, 15))\naxs = np.array(axs).ravel()\nfor i in range(100):\n    axs[i].imshow(plt.imread(with_mask[i]))\n    axs[i].grid('off')\n    axs[i].axis('off')\n# plt.suptitle('with mask images')\nplt.show()\n","84e85342":"fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(15, 15))\naxs = np.array(axs).ravel()\nfor i in range(100):\n    axs[i].imshow(plt.imread(without_mask[i]))\n    axs[i].grid('off')\n    axs[i].axis('off')\n# plt.suptitle('without mask images')\nplt.show()","18daaa4f":"faces = with_mask + without_mask\nlabels = [1]*len(with_mask) + [0]*len(without_mask)\nfaces_train, faces_test, labels_train, labels_test = model_selection.train_test_split(faces, labels, test_size=0.2, shuffle=True, random_state=1)","0b0be65c":"from torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom tqdm import tqdm\nfrom PIL import Image\nimport cv2\n\nclass MyCustomDataset(Dataset):\n    \n    def read_face(self, face_path):\n        face_img = cv2.imread(face_path)\n        if face_img.shape[2] > 3:\n            face_img = face_img[:, :, :3]\n        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n        return face_img\n        \n    def __init__(self, faces, labels, split):\n        self.faces = [self.read_face(face_path) for face_path in tqdm(faces)]\n        self.labels = labels\n        self.split = split\n        \n        self.transforms = transforms.Compose([transforms.ToTensor()])\n        self.aug_train = albu.Compose({\n            albu.Resize(128, 128),\n            albu.VerticalFlip(p=0.5),\n            albu.Rotate(limit=(-10, 10)),\n            albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        })\n        \n        self.aug_test = albu.Compose({\n            albu.Resize(128, 128),            \n            albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        })\n        \n    def __getitem__(self, index):\n        face = self.faces[index]    \n        if self.split == 'train':\n            face = self.aug_train(image=np.array(face))['image']\n        else:\n            face = self.aug_test(image=np.array(face))['image']\n        face = self.transforms(face)\n        label = np.float32(self.labels[index])\n        return face, label\n\n    def __len__(self):\n        return len(self.faces)","f75a077c":"train_dataset = MyCustomDataset(faces_train, labels_train, 'train')\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n\ntest_dataset = MyCustomDataset(faces_test, labels_test, 'test')\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)","64b755f4":"import pytorch_lightning as pl\nfrom torchvision import models\nimport torch.nn as nn\n\nconfig = {\n    'device': 'cuda:0',\n    'learning_rate': 0.0001,\n    'max_epochs': 10\n}\n\nclass LitNet(pl.LightningModule):\n\n    def __init__(self, train_dl, val_dl, test_dl):\n        super(LitNet, self).__init__()        \n        self.model = models.vgg16(pretrained=False)\n        self.model.classifier[6] = nn.Linear(4096, 1)        \n        self.criterion = nn.BCEWithLogitsLoss()\n\n        self.learning_rate = config['learning_rate']   \n        self.train_dl = train_dl\n        self.val_dl = val_dl\n        self.test_dl = test_dl\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.forward(x)\n        loss = self.criterion(y_hat, y.view(y_hat.size()))\n        tensorboard_logs = {'train_loss': loss}\n        return {'loss': loss, 'log': tensorboard_logs}\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.forward(x)\n        loss = self.criterion(y_hat, y.view(y_hat.size()))\n        return {'val_loss': loss}\n\n    def validation_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss}\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n\n    def test_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.forward(x)\n        loss = self.criterion(y_hat, y.view(y_hat.size()))\n        return {'test_loss': loss}\n\n    def test_end(self, outputs):\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n        logs = {'test_loss': avg_loss}\n        return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n\n#     @pl.data_loader\n    def train_dataloader(self):\n        return self.train_dl\n\n#     @pl.data_loader\n    def val_dataloader(self):\n        return self.val_dl\n\n#     @pl.data_loader\n    def test_dataloader(self):\n        return self.test_dl","e2d55919":"model = LitNet(train_dataloader, test_dataloader, test_dataloader)","c9a7c4e3":"trainer = pl.Trainer(max_epochs=config['max_epochs'],\n                        gpus=1, \n                        check_val_every_n_epoch=1,\n                        auto_lr_find=False,\n                        early_stop_callback=early_stop_callback)    \ntrainer.fit(model)\ntrainer.test()","d6f5d274":"model.freeze()\nop_sigmoid = nn.Sigmoid()\n\ny_true, y_pred = [], []\nfor data in test_dataloader:\n    imgs, lbls = data\n    imgs, lbls = imgs.to(config['device']), lbls.to(config['device'])\n    preds = model(imgs)\n    y_pred.append(preds.data.cpu().numpy())\n    y_true.append(lbls.data.cpu().numpy())\n    \ny_true = np.concatenate(y_true)\ny_pred = np.concatenate(y_pred)","4dde2569":"precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred)\nfpr, tpr, _ = metrics.roc_curve(y_true, y_pred)","5b5d935e":"fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\naxs = np.array(axs).ravel()\n\naxs[0].plot(recall, precision)\naxs[0].set_xlabel('Recall')\naxs[0].set_ylabel('Precision')\naxs[0].set_title('Precision Recall Curve')\n\n\naxs[1].plot(fpr, tpr)\naxs[1].set_xlabel('FPR')\naxs[1].set_ylabel('TPR')\naxs[1].set_title('ROC Curve')\n\nfor a in range(2):\n    axs[a].grid(True)\n    axs[a].set_ylim([0, 1])","87986657":"auroc = metrics.roc_auc_score(y_true, y_pred)\naverage_precision = metrics.average_precision_score(y_true, y_pred)\n\nprint ('auroc %f'%auroc)\nprint ('average precision %f'%average_precision)","1d864959":"class UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n            # The normalize code -> t.sub_(m).div_(s)\n        return tensor\n    \n    \nunorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))","ae5155b2":"import torchvision\nto_pil = torchvision.transforms.ToPILImage()\n\nfalse_negatives = []\nfalse_positives = []\n\nfor data in test_dataloader:\n    imgs, lbls = data\n    imgs, lbls = imgs.to(config['device']), lbls.to(config['device'])\n    preds = op_sigmoid(model(imgs))\n    bin_preds = (preds > 0.5).data.cpu().numpy().astype(np.int)    \n    lbls = lbls.data.cpu().numpy()\n    for img, pred, lbl, bin_pred in zip(imgs, preds, lbls, bin_preds):\n        if bin_pred[0] != lbl:\n            if lbl == 1:\n                false_negatives.append((img, pred[0]))\n            else:\n                false_positives.append((img, pred[0]))","9efedfa0":"nfn, nfp = len(false_negatives), len(false_positives)","98c9d610":"def draw_grid(nrows, ncols, images):\n    images = images[:nrows*ncols]\n    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 15))\n    axs = np.array(axs).ravel()\n\n    for i, dt in enumerate(images):    \n        img = unorm(dt[0])\n        img = to_pil(img.data.cpu())\n        img = np.asarray(img)\n        axs[i].imshow(img)\n        axs[i].axis('off')\n        axs[i].set_title('Prediction %f'%dt[1])\n    \n    plt.show()","5b25276c":"# false negatives\ndraw_grid(nfn\/\/3, 3, false_negatives)","b66df4c6":"# false positives\ndraw_grid(nfp\/\/3, 3, false_positives)","f05c532b":"Let's visualize some images from with_mask and without_mask folders.","9982b910":"Reading the face mask images. There are two folders. We will use 'glob' to read the files from these two folders.","8c9ac369":"As baseline we will use vgg16 network to do the binary classification. PyTorch is the easiest framework for me to build and train the network. We will first create a custom dataloader to load the images for training and testing purpose."}}