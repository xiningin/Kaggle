{"cell_type":{"a9b70a10":"code","8b757102":"code","b0b812de":"code","f3cca458":"code","2bfd17b9":"code","e3653474":"code","f5855c38":"code","efb81d39":"code","32f62aac":"code","98fe9193":"code","ecad209d":"code","1a5fe8b2":"code","16c86ad1":"code","d509c627":"code","a4d1de98":"code","5a77366b":"code","b5e5dd76":"code","bb12e1a5":"code","55f31ac6":"code","a3e7e9f2":"code","14bab45d":"code","67bfb8c9":"code","5288a15d":"code","bc5d024a":"code","36487057":"code","f1331afb":"code","816a8dc0":"code","7fe028c8":"code","d7e05570":"code","4090b961":"code","044f2ea9":"code","ed44fd35":"code","8754ac5f":"code","59a551f7":"code","83519cf7":"code","41884208":"code","9b9a6e03":"code","75c43e9e":"code","6054f654":"code","e1a20c75":"code","bbe05f4a":"code","83b3b924":"code","1f6d672e":"code","22cb5810":"code","7a3bef55":"code","32df243b":"code","4d30a901":"code","5b8d7dd6":"code","3114094b":"code","3553389e":"code","2d7664ac":"code","b40ac161":"code","cfb0e2b0":"code","de114149":"code","dd0384aa":"code","d06c1be9":"code","7d292992":"code","ecbd28f5":"code","4603b078":"code","735bad04":"code","9920043a":"code","75ba2c80":"code","43fd198a":"code","dbbdf682":"code","1d804126":"code","31af3e69":"code","761a5082":"code","a96e09f7":"code","200d8727":"code","23576cd6":"code","c849bbdc":"code","d25f56e5":"code","719aee24":"code","7ce0c569":"code","3ca2878f":"code","1bab1c1c":"code","022b100d":"code","8e42bf2f":"code","1761b365":"code","565c3ce2":"markdown","870aef62":"markdown","bd503e7d":"markdown","3950f1dc":"markdown","93421628":"markdown","aeec45e5":"markdown","64eca121":"markdown","cd3ab82c":"markdown","b6e3ae07":"markdown","2a9c9c94":"markdown","01fe0382":"markdown","c9b94b76":"markdown","073329dd":"markdown","aa97f802":"markdown","1d3f2b07":"markdown","864e8d4e":"markdown","bb1f418e":"markdown","3f964c35":"markdown","b6f5dcfa":"markdown","e33ddd65":"markdown","a9308728":"markdown","76121b4e":"markdown","5317f2df":"markdown","423c0aee":"markdown","d0cc6f99":"markdown","82963e45":"markdown","1beecf46":"markdown","cb56de29":"markdown","1582980d":"markdown","18c5b676":"markdown","2f69765e":"markdown","be9c1707":"markdown","1944f5f1":"markdown","cbbd1e3d":"markdown","eb8c0c69":"markdown","56184a7c":"markdown","4ed58354":"markdown","91941745":"markdown","7fbd92b5":"markdown","6434b39d":"markdown","71973af6":"markdown","8d6adb86":"markdown","e5b2eed6":"markdown","8ac633a2":"markdown","1ec984fd":"markdown","27575d50":"markdown","1d5a9676":"markdown","c9b3c809":"markdown","46a643eb":"markdown","1c9c8c59":"markdown"},"source":{"a9b70a10":"#Libraries used in the project\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly_express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8b757102":"#Reading the input dataset \ndata = pd.read_csv('..\/input\/loandata\/Loan payments data.csv')\n\n# pd.options.display.max_columns = None\n# pd.options.display.max_rows = None\n\ndata.head()","b0b812de":"df = data.copy()","f3cca458":"df.info()","2bfd17b9":"df.describe()","e3653474":"#Changed the name of a value in 'education' column from 'Bechalor' to 'Bachelor'\ndf['education']= df['education'].replace('Bechalor','Bachelor')","f5855c38":"#Find the number of missing values in each columns\ndf.isna().sum()","efb81d39":"#Temporarily Filling the empty values in 'past_due_days' as '0'\ndf['past_due_days'] = df['past_due_days'].fillna(0)","32f62aac":"#Filling the empty values in 'paid_off_time' as '-1'\ndf['paid_off_time'] = df['paid_off_time'].fillna(-1)","98fe9193":"#Find the number of missing values in each columns\ndf.isna().sum()","ecad209d":"#Number of unique values in each column\nfor cat in data.columns:\n    print(\"Number of levels in category '{0}': \\b  {1:2.0f} \".format(cat, df[cat].unique().size))","1a5fe8b2":"#Coverting the following columns to 'datetime'\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf['due_date'] = pd.to_datetime(df['due_date'])\ndf['paid_off_time'] = pd.to_datetime(df['paid_off_time']).dt.date","16c86ad1":"#To Convert the 'paid_off_time' column to datetime64 type\ndf['paid_off_time'] = pd.to_datetime(df['paid_off_time'])\ndf.head()","d509c627":"df.info()","a4d1de98":"df_fe = df.copy()","5a77366b":"df_fe.head()","b5e5dd76":"for i in range(len(df_fe[df_fe['loan_status']==\"PAIDOFF\"])):\n    df_fe['past_due_days'][i] = (df_fe['paid_off_time'][i] - df_fe['effective_date'][i] + pd.Timedelta(days=1)).days - df_fe['terms'][i]\ndf_fe.head(10)","bb12e1a5":"#Records where the difference in the paid_off_time and effective_date is greater than the terms\ndf_fe[(df_fe['past_due_days']>0)&(df_fe['loan_status']=='PAIDOFF')]","55f31ac6":"a = df_fe['loan_status'].value_counts()\npd.DataFrame(a)","a3e7e9f2":"plt.pie(df_fe['loan_status'].value_counts(),labels=df_fe['loan_status'].unique(),explode=[0,0.1,0],startangle=144,autopct='%1.f%%')\nplt.title('Loan Status Distribution',fontsize = 20)\nplt.show()","14bab45d":"b= df_fe['Gender'].value_counts()\npd.DataFrame(b)","67bfb8c9":"c = df_fe.groupby(['Gender'])['loan_status'].value_counts()\npd.DataFrame(c)","5288a15d":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['Gender'],hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Gender vs Loan Status',fontsize=20)\nplt.xlabel('Gender', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","bc5d024a":"d = df_fe['education'].value_counts()\npd.DataFrame(d)","36487057":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['education'],hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Education vs Loan Status',fontsize=20)\nplt.xlabel('Education', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","f1331afb":"for i in df_fe['loan_status'].unique():\n    agemean=df_fe[df_fe['loan_status']==i]['age'].mean()\n    agemode=df_fe[df_fe['loan_status']==i]['age'].mode()\n    print(\"average age of people whose loan status is'{0}': \\b {1:2.2f} and mode is {2}\".format(i,agemean, agemode[0]))","816a8dc0":"plt.figure(figsize = [14,5])\nsns.countplot(df_fe['age'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Age vs Loan Status',fontsize=20)\nplt.xlabel('Age', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","7fe028c8":"e = df_fe['Principal'].value_counts()\npd.DataFrame(e)","d7e05570":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['Principal'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Principal vs Loan Status',fontsize=20)\nplt.xlabel('Principal', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","4090b961":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['terms'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Terms vs Loan Status',fontsize=20)\nplt.xlabel('Terms', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","044f2ea9":"g = df_fe.groupby(['effective_date'])['loan_status'].value_counts()\npd.DataFrame(g)","ed44fd35":"plt.figure(figsize = [10,5])\ndates = df_fe['effective_date'].dt.date\nsns.countplot(x=dates, hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Effective Date vs Loan Status',fontsize=20)\nplt.xlabel('Effective Date', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","8754ac5f":"# specifies the parameters of our graphs\nfig = plt.figure(figsize=(18,8), dpi=1600)\nalpha_bar_chart = 0.55\n\n# lets us plot many diffrent shaped graphs together \nax1 = plt.subplot2grid((2,3),(0,0))\nsns.countplot(df_fe['loan_status'],hue=df_fe['education'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Education',fontsize=15)\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=14)\n\nplt.subplot2grid((2,3),(0,1),rowspan=2)\nplt.pie(df_fe['loan_status'].value_counts(),labels=df_fe['loan_status'].unique(),explode=[0,0.1,0],startangle=165,autopct='%1.f%%',)\nplt.grid(b=True, which='major', axis='y')\nplt.title(\"Loan Status Distribution\",fontsize=20)\n\nax3 = plt.subplot2grid((2,3),(0,2))\nsns.countplot(df_fe['loan_status'],hue=df_fe['terms'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Terms',fontsize=15)\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=14)\n\nax4 = plt.subplot2grid((2,3),(1,0))\nsns.countplot(df_fe['loan_status'],hue=df_fe['Principal'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Principal',fontsize=15)\nplt.xlabel('Loan Status',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nax5 = plt.subplot2grid((2,3),(1,2))\nsns.countplot(df_fe['loan_status'],hue=df_fe['Gender'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Gender',fontsize=15)\nplt.xlabel('Loan Status',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nplt.show()","59a551f7":"px.scatter(df_fe, x=\"age\", y=\"past_due_days\", size =\"terms\" ,color=\"loan_status\",\n           hover_data=['Gender','Principal'], log_x=True, size_max=8)","83519cf7":"# Relation between loan_status and past_due_days\n%matplotlib inline\nplt.figure(figsize = [9,5])\nsns.boxplot(x='loan_status', y='past_due_days', data=df_fe)\nplt.xlabel('Loan Status', fontsize=16)\nplt.ylabel('Past Due Days', fontsize=16)\nplt.show()","41884208":"df_fe = df_fe.drop(['Loan_ID','effective_date','due_date','paid_off_time'],axis = 1)\ndf_fe.head()","9b9a6e03":"df_fe.info()","75c43e9e":"p = df_fe.groupby(['loan_status'])['Principal'].value_counts()\npd.DataFrame(p)","6054f654":"df_fe_Pri = df_fe.copy()","e1a20c75":"df_fe_Pri.head()","bbe05f4a":"df_fe_Pri[df_fe_Pri['terms']==7]","83b3b924":"df_fe_Pri[(df_fe_Pri['Principal']!=800) &(df_fe_Pri['Principal']!=1000)]","1f6d672e":"#Dropping rows where 'Principal' is not equal to 800 and 1000 [12 rows]\ndf_fe_Pri = df_fe_Pri[(df_fe_Pri['Principal']==800) | (df_fe_Pri['Principal']==1000)]","22cb5810":"#Dropping rows where 'terms' = 7 days [21 rows]\ndf_fe_Pri = df_fe_Pri[df_fe_Pri['terms']!=7]","7a3bef55":"df_fe_Pri.head()","32df243b":"df_fe_Pri.shape","4d30a901":"df_clean = df_fe_Pri.copy()","5b8d7dd6":"def age_classification(age):\n    if age.item()<21:\n        return 'Young'\n    elif age.item()>=21 and age.item()<31:\n        return 'MidAge'\n    elif age.item()>=31 and age.item()<41:\n        return 'Senior'\n    else:\n        return 'Older'","3114094b":"#Categorizing age column\ndf_clean['age'] = df_clean[['age']].apply(age_classification,axis=1)","3553389e":"df_clean.info()","2d7664ac":"df_clean['terms'] = df_clean['terms'].astype('object')\ndf_clean['Principal'] = df_clean['Principal'].astype('object')","b40ac161":"#Select the variables to be one-hot encoded\none_hot_features = ['education','Gender','Principal','age','terms']\n# Convert categorical variables into dummy\/indicator variables (i.e. one-hot encoding).\none_hot_encoded = pd.get_dummies(df_clean[one_hot_features],drop_first=True)\none_hot_encoded.info(verbose=True, memory_usage=True, null_counts=True)\n# Convert Categorical to Numerical for default column","cfb0e2b0":"one_hot_encoded.head()","de114149":"df_encoded = pd.concat([df_clean,one_hot_encoded],axis=1)\ndf_encoded.head()","dd0384aa":"df_encoded.drop(['terms','education','Gender','age','Principal'],axis=1,inplace = True)\ndf_encoded.head()","d06c1be9":"df_clean['loan_status'].unique()","7d292992":"loan_status_dict = {'PAIDOFF':1,'COLLECTION':2,'COLLECTION_PAIDOFF':3}\ndf_encoded['loan_status'] = df_encoded.loan_status.map(loan_status_dict)\ndf_encoded.head()","ecbd28f5":"df_model = df_encoded.copy()","4603b078":"df_model.info()","735bad04":"df_model.head()","9920043a":"correlation = df_model[df_model.columns].corr()\nplt.figure(figsize=(12, 10))\nplot = sns.heatmap(correlation, vmin = -1, vmax = 1,annot=True, annot_kws={\"size\": 10})\nplot.set_xticklabels(plot.get_xticklabels(), rotation=30)","75ba2c80":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split   #splitting data\n\n#Standardize rows into uniform scale\n\nX = df_model.drop(['loan_status','past_due_days'],axis=1)\ny = df_model['loan_status']\n\n# scaler = MinMaxScaler()#StandardScaler,MinMaxScaler\n# scaler.fit(X_Act)#df_model[cols_to_norm]\n\n# # Scale and center the data\n# fdf_normalized = scaler.fit_transform(X_Act)\n\n# # # Create a pandas DataFrame\n# fdf_normalized_df = pd.DataFrame(data=fdf_normalized, index=X_Act.index, columns=X_Act.columns)\n\n# X = fdf_normalized_df\n\n##Note: In this case, Scaling is not required\n\nX.head()","43fd198a":"#Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=400,test_size=0.30,stratify = y)","dbbdf682":"from collections import Counter\nprint(\"y : \",Counter(y))\nprint(\"y_train : \",Counter(y_train))\nprint(\"y_test : \",Counter(y_test))","1d804126":"# Actual Values(of Majority Class) of y_test\ny_test.value_counts()\ny_test.value_counts().head(1) \/ len(y_test)","31af3e69":"# metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, recall_score","761a5082":"def model_train(model, name):\n    model.fit(X_train, y_train)                                          # Fitting the model\n    y_pred = model.predict(X_test)                                       # Making prediction from the trained model\n    cm = confusion_matrix(y_test, y_pred)                               \n    print(\"Grid Search Confusion Matrix \" +\" Validation Data\")                # Displaying the Confusion Matrix\n    print(cm)\n    print('-----------------------')\n    print('-----------------------')\n    cr = classification_report(y_test, y_pred)\n    print(name +\" Classification Report \" +\" Validation Data\")           # Displaying the Classification Report\n    print(cr)\n    print('------------------------')\n    print(name + \" Bias\")                                                 # Calculating bias\n    bias = y_pred - y_test.mean()\n    print(\"Bias \"+ str(bias.mean()))\n    \n    print(name + \" Variance\")                                             # Calculate Variance\n    var = np.var([y_test, y_pred], axis=0)\n    print(\"Variance \" + str(var.mean()) )\n#     return auc, rec, model\n    return model\n","a96e09f7":"# Building the Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1000,max_iter=500,class_weight='balanced')    # Set Large C value for low regularization to prevent overfitting\n# logreg.fit(X_train, y_train)\n\ndt_model = model_train(logreg, \"Logistic Regression\")\nprint('_________________________')\nprint(\"Coefficients: \",logreg.coef_)                                            # Coefficients for Logistic Regression\nprint(\"Intercepts: \",logreg.intercept_)","200d8727":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'gini',max_depth = 4, min_samples_leaf =2,random_state=101,class_weight='balanced')\n\ndt_model = model_train(dt, \"Decision Tree\")","23576cd6":"# pip install imbalanced-learn","c849bbdc":"#Let us try some sampling technique to remove class imbalance\nfrom imblearn.over_sampling import SMOTE,KMeansSMOTE,SVMSMOTE\n#Over-sampling: SMOTE\n#SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, \n#based on those that already exist. It works randomly picking a point from the minority class and computing \n#the k-nearest neighbors for this point.The synthetic points are added between the chosen point and its neighbors.\nsmote = KMeansSMOTE(sampling_strategy='auto')\n\nX_sm, y_sm = smote.fit_sample(X, y)\nprint(X_sm.shape, y_sm.shape)","d25f56e5":"#Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm,random_state=400,test_size=0.30,stratify = y_sm)#,stratify = y","719aee24":"from collections import Counter\nprint(\"y : \",Counter(y))\nprint(\"y_train : \",Counter(y_train))\nprint(\"y_test : \",Counter(y_test))","7ce0c569":"# Actual Values(of Majority Class) of y_test\ny_test.value_counts()\ny_test.value_counts().head(1) \/ len(y_test)","3ca2878f":"# Building the Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1000,max_iter=500,class_weight='balanced')#solver ='lbfgs',class_weight='balanced'    # Set Large C value for low regularization to prevent overfitting\n# logreg.fit(X_train, y_train)\n\ndt_model = model_train(logreg, \"Logistic Regression\")\nprint('_________________________')\nprint(\"Coefficients: \",logreg.coef_)                                            # Coefficients for Logistic Regression\nprint(\"Intercepts: \",logreg.intercept_)","1bab1c1c":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'gini',max_depth = 4, min_samples_leaf =2,random_state=101)\n\ndt_model = model_train(dt, \"Decision Tree\")","022b100d":"from sklearn.model_selection import GridSearchCV\n\nrandom_grid = {'n_estimators': range(5,20),\n              'max_features' : ['auto', 'sqrt'],\n              'max_depth' : [10,20,30,40],\n              'min_samples_split':[2,5,10],\n              'min_samples_leaf':[1,2,4]}\n\nrf = RandomForestClassifier()\n\nrf_gs = GridSearchCV(rf, random_grid, cv = 3, n_jobs=1, verbose=2)\n\nrf_gs.fit(X_train, y_train)\ny_pred = rf_gs.predict(X_test)\n","8e42bf2f":"print(rf_gs.best_estimator_)\nprint('-----------------------')\nprint(\"Grid Search Validation Data\")\ncm = confusion_matrix(y_test, y_pred)                               \nprint(\"Grid Search Confusion Matrix \" +\" Validation Data\")                # Displaying the Confusion Matrix\nprint(cm)\nprint('-----------------------')\ncr = classification_report(y_test, y_pred)\nprint(\"Grid Search Classification Report \" +\" Validation Data\")           # Displaying the Classification Report\nprint(cr)\nprint('------------------------')\nprint(\"Grid Search Bias\")                                                 # Calculating bias\nbias = y_pred - y_test.mean()\nprint(\"Bias \"+ str(bias.mean()))\n    \nprint(\"Grid Search Variance\")                                             # Calculate Variance\nvar = np.var([y_test, y_pred], axis=0)\nprint(\"Variance \" + str(var.mean()) )","1761b365":"# Import Eli5 package\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Find the importance of columns for prediction\nperm = PermutationImportance(dt, random_state=10).fit(X_test,dt.predict(X_test))\neli5.show_weights(perm, feature_names = X.columns.tolist())","565c3ce2":"# Filling Missing Values \/ Data Imputation","870aef62":"## Checkpoint 1","bd503e7d":"#### Observations:\n*Around <b>40%<\/b> of <b>male<\/b> population have <b>repaid<\/b> their loan <b>lately (or yet to pay)<\/b> <br>\n*Around <b>30%<\/b> of <b>female<\/b> population have <b>repaid<\/b> their loan <b>lately (or yet to pay)<\/b> <br>","3950f1dc":"# **Conclusion**\n## From the Decision tree model, we have acheived an accuracy of 72% after applying SMOTE technique on the imbalanced target class.","93421628":"## Decision Tree","aeec45e5":"# Banking - Loan Payment Data","64eca121":"### Loan Status vs Past Due Days","cd3ab82c":"### Loan Effective Date Analysis","b6e3ae07":"### Loan Status Distribution","2a9c9c94":"### From the above results, we can observe that:\n<br>1.F1 Score using Logistic regression = 0.26\n<br>2.F1 Score using Decision Tree = 0.28\n\nThe results are low due to the <b>imbalance<\/b> in the class categories.\n\nLet's try to apply sampling methods to overcome this issue","01fe0382":"### Age vs Past Due Days","c9b94b76":"## Introduction","073329dd":"#### Observations:\n* <b>Majority<\/b> of the people who took loan have <b>age<\/b> ranging from <b>24 years<\/b> to <b>38 years<\/b><br>","aa97f802":"#### Observations:\n*<b>**20%**<\/b> of the people have <b>**not repaid**<\/b> the loan <b>**(COLLECTION)**<\/b><br>\n*<b>**20%**<\/b> of the people have <b>**repaid**<\/b> the loan but <b>lately<\/b> after due date <b>**(COLLECTION_PAIDOFF)**<\/b><br>\n*<b>**60%**<\/b> of the people have <b>**repaid**<\/b> the loan <b>**on time**<\/b> <b>**(PAIDOFF)**<\/b><br>","1d3f2b07":"### Age Analysis","864e8d4e":"# Feature Analysis","bb1f418e":"<br>The current data set includes details of the 500 people who have opted for loan. Also, the data mentions whether the person has paid back the loan or not and if paid, in how many days they have paid.\nIn this project, we will try to draw few insights on sample Loan data.\n\n<br>Please find the details of dataset below which can help to understand the features in it.\n\n<br>Loan_id : A unique loan (ID) assigned to each loan customers- system generated\n<br>Loan_status : Tell us if a loan is paid off, in collection process - customer is yet to payoff, or paid off after the collection efforts\n<br>Principal : Principal loan amount at the case origination OR Amount of Loan Applied\n<br>terms : Schedule(time period to repay)\n<br>Effective_date : When the loan got originated (started)\n<br>Due_date : Due date by which loan should be paid off\n<br>Paidoff_time : Actual time when loan was paid off , null means yet to be paid\n<br>Past_due_days : How many days a loan has past due date\n<br>Age : Age of customer\n<br>Education : Education level of customer applied for loan\n<br>Gender : Customer Gender (Male\/Female)","3f964c35":"#### Observations:\n*Only <b>few people<\/b> have opted loan for <b>7 days term<\/b> <br>\n*Majority of the <b>late payments<\/b> are from people who have their loan terms as <b>15 days<\/b> and <b>30 days<\/b> <\/b><br>","b6f5dcfa":"### Let's try to check the metrics with couple of models.","e33ddd65":"### SMOTE - OverSampling","a9308728":"# Feature Engineering","76121b4e":"## Label Encoding - 'loan_status'","5317f2df":"## Are people going to pay the money back? Lets See!\n\n<img align=\"Centre\" src=\"https:\/\/images.unsplash.com\/photo-1580722434936-3d175913fbdc?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=500&q=60\" width=\"600px\"> <br \/>\n\nPhoto Credits: Jules Bss on Unsplash","423c0aee":"## CheckPoint 3","d0cc6f99":"## Logistic Regression","82963e45":"## Decision Tree","1beecf46":"#### Observations:\n*On <b>11th and 12th September<\/b>, loan was given to <b>many people<\/b> maybe as part of a drive.<br>\n*Most of people who <b>paid latety(or yet to pay)<\/b> are from these <b>2 days<\/b>.","cb56de29":"## CheckPoint 4","1582980d":"### Age Classification","18c5b676":"## Dropping Principal Values [300, 500, 700, 900] & 'terms' = 7 days","2f69765e":"### Loan Status Analysis","be9c1707":"### Function To Run Different Models","1944f5f1":"#### Observations:\n*We can infer that if people take <b>more than 25 days after due date<\/b>, they might end up in taking <b>even more time.<\/b>","cbbd1e3d":"#### Observations:\n*Most of the <b>Elder people<\/b> (35 - 50 years) have paid back loan <b>on time.<\/b>","eb8c0c69":"## Model Explainability","56184a7c":"## Spelling Correction","4ed58354":"### Principal Analysis","91941745":"#### Replacing values in past_due_days column for PAIDOFF class","7fbd92b5":"#### Observations:\n* <b>Majority<\/b> of the loan takers are from <b>High School<\/b> or <b>College<\/b> background<br>\n* <b>Very few<\/b> people from <b>Masters or above<\/b> background took loan.","6434b39d":"## Logistic Regression","71973af6":"# Model Building","8d6adb86":"## CheckPoint 5","e5b2eed6":"## One hot encoding - 'terms', 'education', 'Principal', 'age' & 'Gender'","8ac633a2":"## CheckPoint 2","1ec984fd":"# **Thank You**","27575d50":"### Term Analysis","1d5a9676":"## Grid Seach","c9b3c809":"### Education Analysis","46a643eb":"### Gender Analysis","1c9c8c59":"#### Observations:\n*<b>Majority<\/b> of the people have opted for <b>Principal<\/b> of $\\$800$ and $\\$1000$ <br>"}}