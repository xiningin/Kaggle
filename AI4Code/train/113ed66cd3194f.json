{"cell_type":{"145f7315":"code","2fbe9cea":"code","b5da41de":"code","f25c0d6b":"code","0aeb46e2":"code","52f822b0":"code","8a7514a1":"code","44effe1e":"code","0aa2330a":"code","de0a98b1":"code","ef7e3c56":"code","2cb61385":"code","2bf3c429":"code","a8ef323c":"code","09a43188":"code","cd6b7638":"code","85f24a22":"code","f5e0cf9f":"code","141db5d6":"code","8d1bea30":"code","059e9d98":"code","41406972":"code","a230fc35":"code","f4b73d7b":"code","0d0886a4":"code","619a7577":"code","bde81583":"code","b296b1b7":"code","eb82a9f1":"code","4448ca1f":"code","1b4aec01":"code","2da1c97a":"code","0a0b66c9":"code","15416276":"code","099760dd":"code","56de21b7":"code","f50cc518":"code","8830e435":"code","ec535555":"code","0c7d8c58":"code","8dbe4c84":"code","def3fe65":"code","6e759fef":"code","3d5aa758":"code","e0763c7b":"code","32205cac":"code","7156f551":"code","db0f1036":"code","05dd3d1a":"code","a990f96b":"code","b8a8999d":"code","31edfcc1":"code","8eeabf70":"code","ff06697a":"code","05b1f4ec":"code","5235497e":"code","7a2c88bf":"code","3d77185d":"code","4874b08f":"code","96fee068":"code","5754ab25":"code","0fe391f6":"code","920d5e32":"code","8f1f9561":"code","dee0068b":"code","9f17c91c":"code","5d6a5831":"code","6a3eaa8a":"code","61d9ca1d":"code","60675d5b":"code","1e847d23":"code","d47ef1fc":"code","c0c2c840":"code","7950d809":"code","7b2c8c80":"code","6f72254b":"code","9f940a2f":"code","0e811bb3":"code","1deabdf4":"code","cb2f70e6":"code","8931ce56":"code","0f8f902d":"code","5a78d00c":"code","9721a823":"code","6d8a58f9":"code","02b5d34e":"code","ee676936":"code","5446aad3":"code","61939b54":"code","c9dc6d20":"code","99525b41":"code","73af0b2b":"code","14e2e970":"code","f2ce6360":"code","38eb0bcd":"code","e4bc8e44":"code","b827f910":"code","6c8b8c14":"code","3868baaa":"code","9625c44e":"code","acecbe0f":"code","954424d1":"code","7d056666":"code","16e22b23":"code","588222cc":"code","8c0ed2d9":"code","3c4efc16":"code","af017ac0":"code","adb4cbf0":"code","b060e87e":"code","60ef9440":"code","311f588c":"code","4f5e68dd":"code","233a33c6":"code","fefe03ab":"code","679cd134":"code","070f458c":"code","03c30557":"code","b56ba7e5":"code","fdc64447":"code","d384b0d3":"code","316c4fdf":"markdown","60e8443d":"markdown","56b8dbd8":"markdown","4b152078":"markdown","c306d52a":"markdown","33396572":"markdown","5b6b586c":"markdown","57b3768c":"markdown","a2ae44ff":"markdown","9c52b8ec":"markdown"},"source":{"145f7315":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2fbe9cea":"movie=pd.read_csv(r'\/kaggle\/input\/cinema-movie\/Movie_regression.csv')\nmovie.head()","b5da41de":"#hidden layer starts ","f25c0d6b":"movie['Movie ID'] = movie.index\nmovie.head()","0aeb46e2":"cols = movie.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nmovie = movie[cols] \nmovie.head()","52f822b0":"movie= movie.sample(frac=1).reset_index(drop=True)\ntrain= movie[:int(0.7*(len(movie)))]\ntrain.head()\n","8a7514a1":"train.shape","44effe1e":"test_df=movie[int(0.7*(len(movie))):]\ntest_df.shape","0aa2330a":"test=test_df.drop('Collection',axis=1)\ntest.head()","de0a98b1":"test=test.reset_index()\n","ef7e3c56":"test=test.drop('index',axis=1)\ntest.head()","2cb61385":"check=test_df[['Movie ID','Collection']]\ncheck.shape","2bf3c429":"#hidden layer stops ","a8ef323c":"train.head()","09a43188":"test.head()","cd6b7638":"train.info(),test.info()","85f24a22":"train.shape,test.shape","f5e0cf9f":"train.describe()","141db5d6":"test.describe()","8d1bea30":"round((train.isnull().sum() * 100 \/ len(train)),2)","059e9d98":"round((test.isnull().sum() * 100 \/ len(test)),2)","41406972":"sns.distplot(train['Time_taken'])\nplt.show()","a230fc35":"sns.distplot(test['Time_taken'])\nplt.show()","f4b73d7b":"train['Time_taken'].describe()","0d0886a4":"train['Time_taken'].fillna(train['Time_taken'].mean(), inplace = True) \ntest['Time_taken'].fillna(train['Time_taken'].mean(), inplace = True) ","619a7577":"train.info(),test.info()","bde81583":"# import pandas_profiling as pp \n# profile = pp.ProfileReport(train) \n# profile.to_file(\"MovieEDA.html\")","b296b1b7":"train.info(),test.info()","eb82a9f1":"train['Num_multiplex']=train['Num_multiplex'].astype('float')\ntrain['Avg_age_actors']=train['Avg_age_actors'].astype('float')\ntrain['Trailer_views']=train['Trailer_views'].astype('float')\ntest['Num_multiplex']=test['Num_multiplex'].astype('float')\ntest['Avg_age_actors']=test['Avg_age_actors'].astype('float')\ntest['Trailer_views']=test['Trailer_views'].astype('float')","4448ca1f":"train.info(),test.info()","1b4aec01":"train.hist(figsize=(32,20),bins=50)\nplt.xticks(rotation=90)\nplt.show()","2da1c97a":"trainfinal=train.copy()\ntestfinal=test.copy()","0a0b66c9":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(train, train_size = 0.7, random_state = 42)","15416276":"df_train.shape, df_test.shape","099760dd":"X_train=df_train.drop(['Collection','Movie ID'],axis=1)\ny_train=df_train['Collection']\nX_test=df_test.drop(['Collection','Movie ID'],axis=1)\ny_test=df_test['Collection']","56de21b7":"X_train.info()","f50cc518":"X_train.columns","8830e435":"from catboost import CatBoostRegressor\nmodel=CatBoostRegressor()\ncategorical_features_indices = np.where(X_train.dtypes != np.float)[0]\nmodel.fit(X_train,y_train,cat_features=([11, 14]))\nscore_cbr=model.score(X_test,y_test)\nprint(\"Score :\", score_cbr)","ec535555":"from sklearn.metrics import mean_squared_error\nrmse_cbr=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE CatBoostRegressor :',rmse_cbr)","0c7d8c58":"from sklearn.metrics import mean_squared_log_error\nRMSLE_cbr=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for CatBoostRegressor:\",RMSLE_cbr)","8dbe4c84":"#Encode categorical data\ndummy = pd.get_dummies(train[[\"Genre\",\"3D_available\"]]).iloc[:,:-1]\ntrain = pd.concat([train,dummy], axis=1)\ntrain = train.drop([\"Genre\",\"3D_available\"], axis=1)\ntrain.shape","def3fe65":"#Encode categorical data\ndummy = pd.get_dummies(test[[\"Genre\",\"3D_available\"]]).iloc[:,:-1]\ntest = pd.concat([test,dummy], axis=1)\ntest = test.drop([\"Genre\",\"3D_available\"], axis=1)\ntest.shape","6e759fef":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(train, train_size = 0.7, random_state = 42)","3d5aa758":"df_train.shape, df_test.shape","e0763c7b":"X_train=df_train.drop(['Collection','Movie ID'],axis=1)\ny_train=df_train['Collection']\nX_test=df_test.drop(['Collection','Movie ID'],axis=1)\ny_test=df_test['Collection']\n","32205cac":"X_train.info()","7156f551":"X_train.columns","db0f1036":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.fit_transform(X_train[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nX_train.head()","05dd3d1a":"X_eval.head()","a990f96b":"X_test[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.transform(X_test[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nX_test.head()","b8a8999d":"X_test.shape,X_train.shape","31edfcc1":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8eeabf70":"X_train = X_train.drop([\"Lead_Actress_rating\"], axis = 1)\nX_test = X_test.drop([\"Lead_Actress_rating\"], axis = 1)","ff06697a":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","05b1f4ec":"X_train = X_train.drop([\"Lead_ Actor_Rating\"], axis = 1)\nX_test = X_test.drop([\"Lead_ Actor_Rating\"], axis = 1)","5235497e":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","7a2c88bf":"X_train = X_train.drop([\"Producer_rating\"], axis = 1)\nX_test = X_test.drop([\"Producer_rating\"], axis = 1)","3d77185d":"import statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","4874b08f":"X_train = X_train.drop([\"Multiplex coverage\"], axis = 1)\nX_test = X_test.drop([\"Multiplex coverage\"], axis = 1)","96fee068":"import statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","5754ab25":"import xgboost as xgb\nmodel=xgb.XGBRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_xgb=model.score(X_test,y_test)\nprint(\"Score XGBRegressor :\", score_xgb)","0fe391f6":"from sklearn.metrics import mean_squared_error\nrmse_xgb=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE XGBRegressor :',rmse_xgb)","920d5e32":"from sklearn.metrics import mean_squared_log_error\nRMSLE_xgb=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for XGBRegressor :\",RMSLE_xgb)","8f1f9561":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nX_trainlr=X_train.copy()\nimport statsmodels.api as sm\nX_train_lm = sm.add_constant(X_trainlr)\nlr = sm.OLS(y_train, X_trainlr).fit()\nlr.summary()","dee0068b":"X_train1 = X_trainlr.drop([\"Avg_age_actors\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","9f17c91c":"X_train1 = X_train1.drop([\"Num_multiplex\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","5d6a5831":"X_train1 = X_train1.drop([\"Time_taken\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","6a3eaa8a":"X_train1 = X_train1.drop([\"Twitter_hastags\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","61d9ca1d":"X_train1 = X_train1.drop([\"3D_available_NO\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","60675d5b":"X_train1 = X_train1.drop([\"Critic_rating\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","1e847d23":"X_train1 = X_train1.drop([\"Movie_length\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","d47ef1fc":"X_testlr=X_test.copy()\ncol1=X_train1.columns\nX_testlr=X_test[col1]\n# Adding constant variable to test dataframe\nX_testlr= sm.add_constant(X_testlr)","c0c2c840":"from sklearn.metrics import mean_squared_error\nrmse_lr=mean_squared_error(lr.predict(X_testlr),y_test)**0.5\nprint('RMSE Linear Regression:',rmse_lr)","7950d809":"from sklearn.metrics import mean_squared_log_error\nRMSLE_lr=np.sqrt(mean_squared_log_error( y_test, abs(lr.predict(X_testlr))))\nprint(\"RMSLE for Linear Regression:\",RMSLE_lr)","7b2c8c80":"from sklearn.ensemble import GradientBoostingRegressor\nmodel= GradientBoostingRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_gbc=model.score(X_test,y_test)\nprint(\"Score GradientBoostingRegressor:\", score_gbc)","6f72254b":"from sklearn.metrics import mean_squared_error\nrmse_gbc=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE GradientBoostingRegressor :',rmse_gbc)","9f940a2f":"from sklearn.metrics import mean_squared_log_error\nRMSLE_gbc=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for GradientBoostingRegressor :\",RMSLE_gbc)","0e811bb3":"from sklearn.ensemble import AdaBoostRegressor\nmodel = AdaBoostRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_abr=model.score(X_test,y_test)\nprint(\"Score AdaBoostRegressor:\", score_abr)","1deabdf4":"from sklearn.metrics import mean_squared_error\nrmse_abr=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE AdaBoostRegressor :',rmse_abr)","cb2f70e6":"from sklearn.metrics import mean_squared_log_error\nRMSLE_abr=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for AdaBoostRegressor :\",RMSLE_abr)","8931ce56":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_rfr=model.score(X_test,y_test)\nprint(\"Score RandomForestRegressor:\", score_rfr)","0f8f902d":"from sklearn.metrics import mean_squared_error\nrmse_rfr=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE RandomForestRegressor :',rmse_rfr)","5a78d00c":"from sklearn.metrics import mean_squared_log_error\nRMSLE_rfr=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for RandomForestRegressor :\",RMSLE_rfr)","9721a823":"from sklearn.ensemble import BaggingRegressor\nfrom sklearn import tree\nmodel = BaggingRegressor(tree.DecisionTreeRegressor(random_state=42))\nmodel.fit(X_train, y_train)\nscore_br=model.score(X_test,y_test)\nprint(\"Score BaggingRegressor:\", score_br)","6d8a58f9":"from sklearn.metrics import mean_squared_error\nrmse_br=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE  BaggingRegressor :',rmse_br)","02b5d34e":"from sklearn.metrics import mean_squared_log_error\nRMSLE_br=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for BaggingRegressor :\",RMSLE_br)","ee676936":"import lightgbm as lgb\ntrain_data=lgb.Dataset(X_train,label=y_train)\nparams = {'learning_rate':0.001}\nmodel= lgb.train(params, train_data)","5446aad3":"from sklearn.metrics import mean_squared_error\nrmse_lgb=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE Light GBM :',rmse_lgb)","61939b54":"from sklearn.metrics import mean_squared_log_error\nRMSLE_lgb=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for Light GBM:\",RMSLE_lgb)","c9dc6d20":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state=42)\nrf.fit(X_train, y_train)","99525b41":"from sklearn.model_selection import GridSearchCV","73af0b2b":"params = {\n    'max_depth': [8,10,15,],\n    'min_samples_leaf': [2,3,5],\n    'max_samples': [50,75,100]\n    \n}","14e2e970":"grid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv=5,\n                           n_jobs=-1, verbose=1)","f2ce6360":"%%time\ngrid_search.fit(X_train, y_train)","38eb0bcd":"grid_search.best_score_","e4bc8e44":"rf_best = grid_search.best_estimator_\nrf_best","b827f910":"from sklearn.metrics import mean_squared_error\nrmse_rfr_ht=mean_squared_error(rf_best.predict(X_test),y_test)**0.5\nprint('RMSE RandomForestRegressor With Hypertuning :',rmse_rfr_ht)","6c8b8c14":"from sklearn.metrics import mean_squared_log_error\nRMSLE_rfr_ht=np.sqrt(mean_squared_log_error( rf_best.predict(X_test),y_test ))\nprint(\"RMSLE for RandomForestRegressor With Hypertuning :\",RMSLE_rfr_ht)","3868baaa":"score_rfr_ht=rf_best.score(X_test,y_test)\nprint(\"Score RandomForestRegressor With Hypertuning :\", score_rfr_ht)","9625c44e":"print('RMSE Light GBM                                 :',rmse_lgb)\nprint('RMSE XGBRegressor                              :',rmse_xgb)\nprint('RMSE GradientBoostingRegressor                 :',rmse_gbc)\nprint('RMSE AdaBoostRegressor                         :',rmse_abr)\nprint('RMSE  BaggingRegressor                         :',rmse_br)\nprint('RMSE CatBoostRegressor                         :',rmse_cbr)\nprint(\"RMSE RandomForestRegressor Without Hypertuning :\",rmse_rfr)\nprint('RMSE RandomForestRegressor With Hypertuning    :',rmse_rfr_ht)\nprint(\"RMSE for Linear Regression                     :\",rmse_lr)","acecbe0f":"print(\"Score RandomForestRegressor Without Hypertuning :\", score_rfr)\nprint(\"Score RandomForestRegressor With Hypertuning    :\",score_rfr_ht)\nprint('Score XGBRegressor                              :',score_xgb)\nprint('Score GradientBoostingRegressor                 :',score_gbc)\nprint('Score AdaBoostRegressor                         :',score_abr)\nprint('Score  BaggingRegressor                         :',score_br)\nprint('Score CatBoostRegressor                         :',score_cbr)","954424d1":"print('RMSLE for Light GBM                                 :',RMSLE_lgb)\nprint('RMSLE for XGBRegressor                              :',RMSLE_xgb)\nprint('RMSLE for GradientBoostingRegressor                 :',RMSLE_gbc)\nprint('RMSLE for AdaBoostRegressor                         :',RMSLE_abr)\nprint('RMSLE for  BaggingRegressor                         :',RMSLE_br)\nprint('RMSLE for CatBoostRegressor                         :',RMSLE_cbr)\nprint(\"RMSLE for RandomForestRegressor Without Hypertuning :\",RMSLE_rfr)\nprint(\"RMSLE for RandomForestRegressor With Hypertuning    :\",RMSLE_rfr_ht)\nprint(\"RMSLE for Linear Regression                         :\",RMSLE_lr)","7d056666":"X_train=trainfinal.drop(['Collection','Movie ID'],axis=1)\ny_train=trainfinal['Collection']\nX_test=testfinal.drop(['Movie ID'],axis=1)","16e22b23":"X_train.info()","588222cc":"X_train.columns","8c0ed2d9":"X_train.info()","3c4efc16":"from catboost import CatBoostRegressor\nmodel=CatBoostRegressor()\ncategorical_features_indices = np.where(X_train.dtypes != np.float)[0]\ncategorical_features_indices\nmodel.fit(X_train,y_train,cat_features=([11, 14]))","af017ac0":"from sklearn.metrics import r2_score\nr2_score_rf_train=round(r2_score(y_train, model.predict(X_train)),2)\nprint(\"R-squared Train:\",r2_score_rf_train)","adb4cbf0":"model.feature_importances_","b060e87e":"imp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": model.feature_importances_})","60ef9440":"imp_df.sort_values(by=\"Imp\", ascending=False)","311f588c":"testfinal.info()","4f5e68dd":"# predict the target on the train dataset\npredict_test = model.predict(X_test)\nprint('Target on test data\\n\\n',predict_test)","233a33c6":"submission = pd.DataFrame({\n        \"Movie ID\": testfinal[\"Movie ID\"],\n        \"Collection\": predict_test \n    })\nsubmission.to_csv('submission.csv', index=False)","fefe03ab":"submission.head()","679cd134":"check.head()","070f458c":"plt.grid\nsns.lineplot(data=check, x=\"Movie ID\", y=\"Collection\")\nsns.lineplot(data=submission, x=\"Movie ID\", y=\"Collection\")\nplt.show()","03c30557":"from sklearn.metrics import mean_squared_log_error\nnp.sqrt(mean_squared_log_error( check['Collection'], submission['Collection']))","b56ba7e5":"print(\"Score in the event :\",np.sqrt(mean_squared_log_error( check['Collection'], submission['Collection'])))","fdc64447":"from sklearn.metrics import mean_squared_error\nmean_squared_error(check['Collection'], submission['Collection'])**0.5","d384b0d3":"print(\"Score in the event : \",mean_squared_error(check['Collection'], submission['Collection'])**0.5)","316c4fdf":"If evaulation is based on **RMSE**","60e8443d":"# Missing Value Treatment","56b8dbd8":"Now, we can focus on creating our algorithm for main data of Hackathon","4b152078":"# EVALUATION ","c306d52a":"# **In the event, we will recieve test, train file**","33396572":"If evaulation is based on **RMSLE**","5b6b586c":"For other algorithms ","57b3768c":"**Data they will share with us**","a2ae44ff":"**CatBoostRegressor is best algorithm for this regression problem for following factors**\n\n- RMSLE for CatBoostRegressor is lowerest compared to others\n- Score for CatBoostRegressor is higherest compared to others\n- RMSE for CatBoostRegressor is lowerest compared to others","9c52b8ec":"**The orginal Data the orginizer will have**"}}