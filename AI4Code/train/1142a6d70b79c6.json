{"cell_type":{"bb505038":"code","6f3682a7":"code","bde066f4":"code","fc39b5a5":"code","50fdafba":"code","96071ae1":"code","8e8508c8":"code","db8d73fa":"code","1a2e3848":"code","f562b18b":"code","0a8c8286":"code","e8732371":"code","43f23ed2":"code","e297dec4":"code","ab01f5ee":"code","fd521c41":"code","22867867":"code","f341513e":"code","4beb6d91":"markdown","c5c6f2d9":"markdown","538fa175":"markdown","07aaf141":"markdown"},"source":{"bb505038":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f3682a7":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","bde066f4":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","fc39b5a5":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 0.001\ntraining_epochs = 163\nbatch_size = 10\n# \uc2a4\ucf00\uc77c\ub7ec \ud65c\uc6a9\nScaler = preprocessing.StandardScaler()","50fdafba":"train_data=pd.read_csv('..\/input\/unemployment-rate\/train_unemployment_rate.csv',header=None, usecols=range(1,4))\ntest_data=pd.read_csv('..\/input\/unemployment-rate\/test_unemployment_rate.csv',header=None, usecols=range(1,3))","96071ae1":"x_train_data=train_data.loc[:,0:2]\ny_train_data=train_data.loc[:,3]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\n\n# \uc2a4\ucf00\uc77c\ub7ec\ub97c \ud1b5\ud574 preprocessing\nx_train_data = Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)","8e8508c8":"train_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)","db8d73fa":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)","1a2e3848":"# \ub808\uc774\uc5b4 \uc0dd\uc131\nlinear1 = torch.nn.Linear(2,1,bias=True)","f562b18b":"torch.nn.init.xavier_uniform_(linear1.weight)","0a8c8286":"model = torch.nn.Sequential(linear1).to(device)","e8732371":"# \uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\nloss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","43f23ed2":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%03d' % (epoch + 1), 'rate =', '{:.1f}'.format(avg_cost))\n\nprint('Learning finished')","e297dec4":"with torch.no_grad():\n\n  x_test_data=test_data.loc[:,:]\n  x_test_data=np.array(x_test_data)\n  x_test_data = Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction = model(x_test_data)","ab01f5ee":"correct_prediction = prediction.cpu().numpy().reshape(-1,1)","fd521c41":"submit=pd.read_csv('..\/input\/unemployment-rate\/submission.csv')","22867867":"for i in range(len(correct_prediction)):\n  submit['Expected'][i]=correct_prediction[i].item()","f341513e":"submit.to_csv('baseline.csv',index=False,header=True)","4beb6d91":"## \ub370\uc774\ud130 \ub85c\ub354","c5c6f2d9":"## \ubaa8\ub378 \ud559\uc2b5","538fa175":"## \ubaa8\ub378 \ud14c\uc2a4\ud2b8\n","07aaf141":"## csv\ud30c\uc77c \uc0dd\uc131"}}