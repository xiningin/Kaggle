{"cell_type":{"78ee6569":"code","f996c3fc":"code","c893c61a":"code","8ab7b281":"code","44209a08":"code","1206226c":"code","6f8fe2fb":"code","8cebd646":"code","4cbd28c6":"code","4e3040e9":"code","daa7fd50":"code","e0ff571d":"code","2cb2d882":"code","1fe328ce":"code","e4fed57c":"code","4546ca91":"code","9fc8fa47":"code","2eafbb40":"code","7a6926a7":"code","1f4c96cc":"code","69c1550d":"code","703ffb8e":"code","5ae887ea":"code","9f44db71":"code","4208daa3":"code","5c8c65c2":"code","99cc0ad0":"code","feeba422":"code","1173b966":"code","fd63b192":"code","b534dd43":"code","f6a6edd4":"code","97e45e08":"code","bc151d8b":"code","b15d3710":"code","6e887017":"code","13db4030":"code","a84536f8":"code","0709d366":"code","c4fb124b":"code","76f9fddf":"code","9c8a6f61":"code","5d04db2c":"code","c976d84e":"code","7359f8fe":"code","de1030e2":"code","2f0d0212":"code","ecd27aae":"code","5e648980":"code","347ca148":"code","4e6e8126":"code","3033fbaf":"code","dfaa1f82":"code","8082a37f":"code","fe384a07":"code","71c5b605":"code","243c318e":"code","a3a75ba7":"code","ff4b63be":"code","8407c52d":"code","2fd6558c":"code","93b8ff5d":"code","b840b4da":"code","c1908579":"markdown","e3286aac":"markdown","ca0300e0":"markdown"},"source":{"78ee6569":"#Loading libraries \nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (16.0, 8.0)\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\npd.options.display.max_rows = 81","f996c3fc":"#loading data\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","c893c61a":"train","8ab7b281":"test","44209a08":"train.dtypes","1206226c":"print ('The train data has {0} rows and {1} columns'.format(train.shape[0],train.shape[1]))\nprint ('----------------------------')\nprint ('The test data has {0} rows and {1} columns'.format(test.shape[0],test.shape[1]))","6f8fe2fb":"train.info()","8cebd646":"#check missing values\ntrain.columns[train.isnull().any()]","4cbd28c6":"#missing value counts in each of these columns\nmiss = train.isnull().sum()\/len(train)\nmiss = miss[miss > 0]\nmiss.sort_values(inplace=True)\nmiss","4e3040e9":"#visualising missing values\nmiss = miss.to_frame()\nmiss.columns = ['count']\nmiss.index.names = ['Name']\nmiss['Name'] = miss.index\n\n#plot the missing value count\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.barplot(x = 'Name', y = 'count', data=miss)\nplt.xticks(rotation = 90)\nplt.show()","daa7fd50":"#SalePrice\nsns.distplot(train['SalePrice'])","e0ff571d":"#skewness\nprint(\"The skewness of SalePrice is {}\".format(train['SalePrice'].skew()))","2cb2d882":"#now transforming the target variable\ntarget = np.log(train['SalePrice'])\nprint ('Skewness is', target.skew())\nsns.distplot(target);","1fe328ce":"#separate variables into new data frames\nnumeric_data = train.select_dtypes(include=[np.number])\ncat_data = train.select_dtypes(exclude=[np.number])\nprint(\"There are {} numeric and {} categorical columns in train data\".format(numeric_data.shape[1],cat_data.shape[1]))","e4fed57c":"del numeric_data['Id']","4546ca91":"#correlation plot\ncorr = numeric_data.corr()\nsns.heatmap(corr);","9fc8fa47":"corr['SalePrice'].sort_values(ascending=False)*100","2eafbb40":"train['OverallQual'].unique()","7a6926a7":"#let's check the mean price per quality and plot it.\npivot = train.pivot_table(index='OverallQual', values='SalePrice', aggfunc=np.median)\npivot","1f4c96cc":"pivot.plot(kind='bar', color='red');","69c1550d":"#GrLivArea variable\nsns.jointplot(x=train['GrLivArea'], y=train['SalePrice']);","703ffb8e":"cat_data.describe()","5ae887ea":"sp_pivot = train.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\nsp_pivot","9f44db71":"sp_pivot.plot(kind='bar',color='red');","4208daa3":"cat = [f for f in train.columns if train.dtypes[f] == 'object']\ndef anova(frame):\n    anv = pd.DataFrame()\n    anv['features'] = cat\n    pvals = []\n    for c in cat:\n           samples = []\n           for cls in frame[c].unique():\n                  s = frame[frame[c] == cls]['SalePrice'].values\n                  samples.append(s)\n           pval = stats.f_oneway(*samples)[1]\n           pvals.append(pval)\n    anv['pval'] = pvals\n    return anv.sort_values('pval')\n\ncat_data['SalePrice'] = train.SalePrice.values\nk = anova(cat_data) \nk['disparity'] = np.log(1.\/k['pval'].values) \nsns.barplot(data=k, x = 'features', y='disparity') \nplt.xticks(rotation=90) \nplt;","5c8c65c2":"#create numeric plots\nnum = [f for f in train.columns if train.dtypes[f] != 'object']\nnum.remove('Id')\nnd = pd.melt(train, value_vars = num)\nn1 = sns.FacetGrid (nd, col='variable', col_wrap=4, sharex=False, sharey = False)\nn1 = n1.map(sns.distplot, 'value')\nn1;","99cc0ad0":"def boxplot(x,y,**kwargs):\n            sns.boxplot(x=x,y=y)\n            x = plt.xticks(rotation=90)\n\ncat = [f for f in train.columns if train.dtypes[f] == 'object']\n\np = pd.melt(train, id_vars='SalePrice', value_vars=cat)\ng = sns.FacetGrid (p, col='variable', col_wrap=2, sharex=False, sharey=False, height=5)\ng = g.map(boxplot, 'value','SalePrice')\ng;","feeba422":"#removing outliers\ntrain.drop(train[train['GrLivArea'] > 4000].index, inplace=True)\ntrain.shape #removed 4 rows","1173b966":"#imputing using mode\ntest.loc[666, 'GarageQual'] = \"TA\" #stats.mode(test['GarageQual']).mode\ntest.loc[666, 'GarageCond'] = \"TA\" #stats.mode(test['GarageCond']).mode\ntest.loc[666, 'GarageFinish'] = \"Unf\" #stats.mode(test['GarageFinish']).mode\ntest.loc[666, 'GarageYrBlt'] = \"1980\" #np.nanmedian(test['GarageYrBlt'])","fd63b192":"#mark as missing\ntest.loc[1116, 'GarageType'] = np.nan","b534dd43":"#importing function\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndef factorize(data, var, fill_na = None):\n    if fill_na is not None:\n        data[var].fillna(fill_na, inplace=True)\n    le.fit(data[var])\n    data[var] = le.transform(data[var])\n    return data","f6a6edd4":"#combine the data set\nalldata = train.append(test)\nalldata.shape","97e45e08":"#impute lotfrontage by median of neighborhood\nlot_frontage_by_neighborhood = train['LotFrontage'].groupby(train['Neighborhood'])\n\nfor key, group in lot_frontage_by_neighborhood:\n                idx = (alldata['Neighborhood'] == key) & (alldata['LotFrontage'].isnull())\n                alldata.loc[idx, 'LotFrontage'] = group.median()","bc151d8b":"#imputing missing values\nalldata[\"MasVnrArea\"].fillna(0, inplace=True)\nalldata[\"BsmtFinSF1\"].fillna(0, inplace=True)\nalldata[\"BsmtFinSF2\"].fillna(0, inplace=True)\nalldata[\"BsmtUnfSF\"].fillna(0, inplace=True)\nalldata[\"TotalBsmtSF\"].fillna(0, inplace=True)\nalldata[\"GarageArea\"].fillna(0, inplace=True)\nalldata[\"BsmtFullBath\"].fillna(0, inplace=True)\nalldata[\"BsmtHalfBath\"].fillna(0, inplace=True)\nalldata[\"GarageCars\"].fillna(0, inplace=True)\nalldata[\"GarageYrBlt\"].fillna(0.0, inplace=True)\nalldata[\"PoolArea\"].fillna(0, inplace=True)","b15d3710":"qual_dict = {np.nan: 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\nname = np.array(['ExterQual','PoolQC' ,'ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu', 'GarageQual','GarageCond'])\n\nfor i in name:\n     alldata[i] = alldata[i].map(qual_dict).astype(int)\n\nalldata[\"BsmtExposure\"] = alldata[\"BsmtExposure\"].map({np.nan: 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}).astype(int)\n\nbsmt_fin_dict = {np.nan: 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\nalldata[\"BsmtFinType1\"] = alldata[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\nalldata[\"BsmtFinType2\"] = alldata[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)\nalldata[\"Functional\"] = alldata[\"Functional\"].map({np.nan: 0, \"Sal\": 1, \"Sev\": 2, \"Maj2\": 3, \"Maj1\": 4, \"Mod\": 5, \"Min2\": 6, \"Min1\": 7, \"Typ\": 8}).astype(int)\n\nalldata[\"GarageFinish\"] = alldata[\"GarageFinish\"].map({np.nan: 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3}).astype(int)\nalldata[\"Fence\"] = alldata[\"Fence\"].map({np.nan: 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4}).astype(int)\n\n#encoding data\nalldata[\"CentralAir\"] = (alldata[\"CentralAir\"] == \"Y\") * 1.0\nvarst = np.array(['MSSubClass','LotConfig','Neighborhood','Condition1','BldgType','HouseStyle','RoofStyle','Foundation','SaleCondition'])\n\nfor x in varst:\n         factorize(alldata, x)\n\n#encode variables and impute missing values\nalldata = factorize(alldata, \"MSZoning\", \"RL\")\nalldata = factorize(alldata, \"Exterior1st\", \"Other\")\nalldata = factorize(alldata, \"Exterior2nd\", \"Other\")\nalldata = factorize(alldata, \"MasVnrType\", \"None\")\nalldata = factorize(alldata, \"SaleType\", \"Oth\")","6e887017":"#creating new variable (1 or 0) based on irregular count levels\n#The level with highest count is kept as 1 and rest as 0\nalldata[\"IsRegularLotShape\"] = (alldata[\"LotShape\"] == \"Reg\") * 1\nalldata[\"IsLandLevel\"] = (alldata[\"LandContour\"] == \"Lvl\") * 1\nalldata[\"IsLandSlopeGentle\"] = (alldata[\"LandSlope\"] == \"Gtl\") * 1\nalldata[\"IsElectricalSBrkr\"] = (alldata[\"Electrical\"] == \"SBrkr\") * 1\nalldata[\"IsGarageDetached\"] = (alldata[\"GarageType\"] == \"Detchd\") * 1\nalldata[\"IsPavedDrive\"] = (alldata[\"PavedDrive\"] == \"Y\") * 1\nalldata[\"HasShed\"] = (alldata[\"MiscFeature\"] == \"Shed\") * 1\nalldata[\"Remodeled\"] = (alldata[\"YearRemodAdd\"] != alldata[\"YearBuilt\"]) * 1\n\n#Did the modeling happen during the sale year?\nalldata[\"RecentRemodel\"] = (alldata[\"YearRemodAdd\"] == alldata[\"YrSold\"]) * 1\n\n# Was this house sold in the year it was built?\nalldata[\"VeryNewHouse\"] = (alldata[\"YearBuilt\"] == alldata[\"YrSold\"]) * 1\nalldata[\"Has2ndFloor\"] = (alldata[\"2ndFlrSF\"] == 0) * 1\nalldata[\"HasMasVnr\"] = (alldata[\"MasVnrArea\"] == 0) * 1\nalldata[\"HasWoodDeck\"] = (alldata[\"WoodDeckSF\"] == 0) * 1\nalldata[\"HasOpenPorch\"] = (alldata[\"OpenPorchSF\"] == 0) * 1\nalldata[\"HasEnclosedPorch\"] = (alldata[\"EnclosedPorch\"] == 0) * 1\nalldata[\"Has3SsnPorch\"] = (alldata[\"3SsnPorch\"] == 0) * 1\nalldata[\"HasScreenPorch\"] = (alldata[\"ScreenPorch\"] == 0) * 1\n\n#setting levels with high count as 1 and the rest as 0\n#you can check for them using the value_counts function\nalldata[\"HighSeason\"] = alldata[\"MoSold\"].replace({1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0})\nalldata[\"NewerDwelling\"] = alldata[\"MSSubClass\"].replace({20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0, 90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0})","13db4030":"alldata.shape","a84536f8":"#create alldata2\nalldata2 = train.append(test)\n\nalldata[\"SaleCondition_PriceDown\"] = alldata2.SaleCondition.replace({'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n\n# house completed before sale or not\nalldata[\"BoughtOffPlan\"] = alldata2.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\nalldata[\"BadHeating\"] = alldata2.HeatingQC.replace({'Ex': 0, 'Gd': 0, 'TA': 0, 'Fa': 1, 'Po': 1})","0709d366":"#calculating total area using all area columns\narea_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea' ]\n\nalldata[\"TotalArea\"] = alldata[area_cols].sum(axis=1)\nalldata[\"TotalArea1st2nd\"] = alldata[\"1stFlrSF\"] + alldata[\"2ndFlrSF\"]\nalldata[\"Age\"] = 2010 - alldata[\"YearBuilt\"]\nalldata[\"TimeSinceSold\"] = 2010 - alldata[\"YrSold\"]\nalldata[\"SeasonSold\"] = alldata[\"MoSold\"].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, 6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\nalldata[\"YearsSinceRemodel\"] = alldata[\"YrSold\"] - alldata[\"YearRemodAdd\"]\n\n# Simplifications of existing features into bad\/average\/good based on counts\nalldata[\"SimplOverallQual\"] = alldata.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\nalldata[\"SimplOverallCond\"] = alldata.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\nalldata[\"SimplPoolQC\"] = alldata.PoolQC.replace({1 : 1, 2 : 1, 3 : 2, 4 : 2})\nalldata[\"SimplGarageCond\"] = alldata.GarageCond.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplGarageQual\"] = alldata.GarageQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplFireplaceQu\"] = alldata.FireplaceQu.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplFireplaceQu\"] = alldata.FireplaceQu.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplFunctional\"] = alldata.Functional.replace({1 : 1, 2 : 1, 3 : 2, 4 : 2, 5 : 3, 6 : 3, 7 : 3, 8 : 4})\nalldata[\"SimplKitchenQual\"] = alldata.KitchenQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplHeatingQC\"] = alldata.HeatingQC.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplBsmtFinType1\"] = alldata.BsmtFinType1.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\nalldata[\"SimplBsmtFinType2\"] = alldata.BsmtFinType2.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\nalldata[\"SimplBsmtCond\"] = alldata.BsmtCond.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplBsmtQual\"] = alldata.BsmtQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplExterCond\"] = alldata.ExterCond.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nalldata[\"SimplExterQual\"] = alldata.ExterQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n\n#grouping neighborhood variable based on this plot\ntrain['SalePrice'].groupby(train['Neighborhood']).median().sort_values().plot(kind='bar');","c4fb124b":"neighborhood_map = {\"MeadowV\" : 0, \"IDOTRR\" : 1, \"BrDale\" : 1, \"OldTown\" : 1, \"Edwards\" : 1, \"BrkSide\" : 1, \"Sawyer\" : 1, \"Blueste\" : 1, \"SWISU\" : 2, \"NAmes\" : 2, \"NPkVill\" : 2, \"Mitchel\" : 2, \"SawyerW\" : 2, \"Gilbert\" : 2, \"NWAmes\" : 2, \"Blmngtn\" : 2, \"CollgCr\" : 2, \"ClearCr\" : 3, \"Crawfor\" : 3, \"Veenker\" : 3, \"Somerst\" : 3, \"Timber\" : 3, \"StoneBr\" : 4, \"NoRidge\" : 4, \"NridgHt\" : 4}\n\nalldata['NeighborhoodBin'] = alldata2['Neighborhood'].map(neighborhood_map)\nalldata.loc[alldata2.Neighborhood == 'NridgHt', \"Neighborhood_Good\"] = 1\nalldata.loc[alldata2.Neighborhood == 'Crawfor', \"Neighborhood_Good\"] = 1\nalldata.loc[alldata2.Neighborhood == 'StoneBr', \"Neighborhood_Good\"] = 1\nalldata.loc[alldata2.Neighborhood == 'Somerst', \"Neighborhood_Good\"] = 1\nalldata.loc[alldata2.Neighborhood == 'NoRidge', \"Neighborhood_Good\"] = 1\nalldata[\"Neighborhood_Good\"].fillna(0, inplace=True)\nalldata[\"SaleCondition_PriceDown\"] = alldata2.SaleCondition.replace({'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n\n# House completed before sale or not\nalldata[\"BoughtOffPlan\"] = alldata2.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\nalldata[\"BadHeating\"] = alldata2.HeatingQC.replace({'Ex': 0, 'Gd': 0, 'TA': 0, 'Fa': 1, 'Po': 1})\nalldata.shape","76f9fddf":"#create new data\ntrain_new = alldata[alldata['SalePrice'].notnull()]\ntest_new = alldata[alldata['SalePrice'].isnull()]\ntrain","9c8a6f61":"test","5d04db2c":"#get numeric features\nnumeric_features = [f for f in train_new.columns if train_new[f].dtype != object]\n\n#transform the numeric features using log(x + 1)\nfrom scipy.stats import skew\nskewed = train_new[numeric_features].apply(lambda x: skew(x.dropna().astype(float)))\nskewed = skewed[skewed > 0.75]\nskewed = skewed.index\ntrain_new[skewed] = np.log1p(train_new[skewed])\ntest_new[skewed] = np.log1p(test_new[skewed])\ndel test_new['SalePrice']","c976d84e":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(train_new[numeric_features])\nscaled = scaler.transform(train_new[numeric_features])\n\nfor i, col in enumerate(numeric_features):\n       train_new[col] = scaled[:,i]\n\nnumeric_features.remove('SalePrice')\nscaled = scaler.fit_transform(test_new[numeric_features])\n\nfor i, col in enumerate(numeric_features):\n      test_new[col] = scaled[:,i]","7359f8fe":"def onehot(onehot_df, df, column_name, fill_na):\n    onehot_df[column_name] = df[column_name]\n    if fill_na is not None:\n        onehot_df[column_name].fillna(fill_na, inplace=True)\n    dummies = pd.get_dummies(onehot_df[column_name], prefix=\"_\"+column_name)\n    onehot_df = onehot_df.join(dummies)\n    onehot_df = onehot_df.drop([column_name], axis=1)\n    return onehot_df\n\ndef munge_onehot(df):\n    onehot_df = pd.DataFrame(index = df.index)\n\n    onehot_df = onehot(onehot_df, df, \"MSSubClass\", None)\n    onehot_df = onehot(onehot_df, df, \"MSZoning\", \"RL\")\n    onehot_df = onehot(onehot_df, df, \"LotConfig\", None)\n    onehot_df = onehot(onehot_df, df, \"Neighborhood\", None)\n    onehot_df = onehot(onehot_df, df, \"Condition1\", None)\n    onehot_df = onehot(onehot_df, df, \"BldgType\", None)\n    onehot_df = onehot(onehot_df, df, \"HouseStyle\", None)\n    onehot_df = onehot(onehot_df, df, \"RoofStyle\", None)\n    onehot_df = onehot(onehot_df, df, \"Exterior1st\", \"VinylSd\")\n    onehot_df = onehot(onehot_df, df, \"Exterior2nd\", \"VinylSd\")\n    onehot_df = onehot(onehot_df, df, \"Foundation\", None)\n    onehot_df = onehot(onehot_df, df, \"SaleType\", \"WD\")\n    onehot_df = onehot(onehot_df, df, \"SaleCondition\", \"Normal\")\n\n    #Fill in missing MasVnrType for rows that do have a MasVnrArea.\n    temp_df = df[[\"MasVnrType\", \"MasVnrArea\"]].copy()\n    idx = (df[\"MasVnrArea\"] != 0) & ((df[\"MasVnrType\"] == \"None\") | (df[\"MasVnrType\"].isnull()))\n    temp_df.loc[idx, \"MasVnrType\"] = \"BrkFace\"\n    onehot_df = onehot(onehot_df, temp_df, \"MasVnrType\", \"None\")\n\n    onehot_df = onehot(onehot_df, df, \"LotShape\", None)\n    onehot_df = onehot(onehot_df, df, \"LandContour\", None)\n    onehot_df = onehot(onehot_df, df, \"LandSlope\", None)\n    onehot_df = onehot(onehot_df, df, \"Electrical\", \"SBrkr\")\n    onehot_df = onehot(onehot_df, df, \"GarageType\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"PavedDrive\", None)\n    onehot_df = onehot(onehot_df, df, \"MiscFeature\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"Street\", None)\n    onehot_df = onehot(onehot_df, df, \"Alley\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"Condition2\", None)\n    onehot_df = onehot(onehot_df, df, \"RoofMatl\", None)\n    onehot_df = onehot(onehot_df, df, \"Heating\", None)\n\n    # we'll have these as numerical variables too\n    onehot_df = onehot(onehot_df, df, \"ExterQual\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"ExterCond\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"BsmtQual\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"BsmtCond\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"HeatingQC\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"KitchenQual\", \"TA\")\n    onehot_df = onehot(onehot_df, df, \"FireplaceQu\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"GarageQual\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"GarageCond\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"PoolQC\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"BsmtExposure\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"BsmtFinType1\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"BsmtFinType2\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"Functional\", \"Typ\")\n    onehot_df = onehot(onehot_df, df, \"GarageFinish\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"Fence\", \"None\")\n    onehot_df = onehot(onehot_df, df, \"MoSold\", None)\n\n    # Divide  the years between 1871 and 2010 into slices of 20 years\n    year_map = pd.concat(pd.Series(\"YearBin\" + str(i+1), index=range(1871+i*20,1891+i*20))  for i in range(0, 7))\n    yearbin_df = pd.DataFrame(index = df.index)\n    yearbin_df[\"GarageYrBltBin\"] = df.GarageYrBlt.map(year_map)\n    yearbin_df[\"GarageYrBltBin\"].fillna(\"NoGarage\", inplace=True)\n    yearbin_df[\"YearBuiltBin\"] = df.YearBuilt.map(year_map)\n    yearbin_df[\"YearRemodAddBin\"] = df.YearRemodAdd.map(year_map)\n\n    onehot_df = onehot(onehot_df, yearbin_df, \"GarageYrBltBin\", None)\n    onehot_df = onehot(onehot_df, yearbin_df, \"YearBuiltBin\", None)\n    onehot_df = onehot(onehot_df, yearbin_df, \"YearRemodAddBin\", None)\n    return onehot_df\n\n#create one-hot features\nonehot_df = munge_onehot(train)\n\nneighborhood_train = pd.DataFrame(index=train_new.shape)\nneighborhood_train['NeighborhoodBin'] = train_new['NeighborhoodBin']\nneighborhood_test = pd.DataFrame(index=test_new.shape)\nneighborhood_test['NeighborhoodBin'] = test_new['NeighborhoodBin']\n\nonehot_df = onehot(onehot_df, neighborhood_train, 'NeighborhoodBin', None)","de1030e2":"train_new = train_new.join(onehot_df) \ntrain_new.shape","2f0d0212":"#adding one hot features to test\nonehot_df_te = munge_onehot(test)\nonehot_df_te = onehot(onehot_df_te, neighborhood_test, \"NeighborhoodBin\", None)\ntest_new = test_new.join(onehot_df_te)\ntest_new.shape\n(1459, 417)","ecd27aae":"#dropping some columns from the train data as they are not found in test\ndrop_cols = [\"_Exterior1st_ImStucc\", \"_Exterior1st_Stone\",\"_Exterior2nd_Other\",\"_HouseStyle_2.5Fin\",\"_RoofMatl_Membran\", \"_RoofMatl_Metal\", \"_RoofMatl_Roll\", \"_Condition2_RRAe\", \"_Condition2_RRAn\", \"_Condition2_RRNn\", \"_Heating_Floor\", \"_Heating_OthW\", \"_Electrical_Mix\", \"_MiscFeature_TenC\", \"_GarageQual_Ex\",  \"_PoolQC_Fa\"]\ntrain_new.drop(drop_cols, axis=1, inplace=True)\ntrain_new.shape\n(1456, 417)","5e648980":"#removing one column missing from train data\ntest_new.drop([\"_MSSubClass_150\"], axis=1, inplace=True)\n\n# Drop these columns\ndrop_cols = [\"_Condition2_PosN\", # only two are not zero\n         \"_MSZoning_C (all)\",\n         \"_MSSubClass_160\"]\n\ntrain_new.drop(drop_cols, axis=1, inplace=True)\ntest_new.drop(drop_cols, axis=1, inplace=True)","347ca148":"#create a label set\nlabel_df = pd.DataFrame(index = train_new.index, columns = ['SalePrice'])\nlabel_df['SalePrice'] = np.log(train['SalePrice'])\nprint(\"Training set size:\", train_new.shape)\nprint(\"Test set size:\", test_new.shape)","4e6e8126":"train_new1 = train_new.drop(['SalePrice'], axis=1)","3033fbaf":"train_new1","dfaa1f82":"test_new","8082a37f":"o1 = ['Alley', 'Condition2', 'Electrical', 'GarageType', 'GarageYrBlt', 'Heating', 'LandContour', 'LandSlope', 'LotShape', 'MiscFeature', 'PavedDrive', 'RoofMatl', 'Street', 'Utilities', '_NeighborhoodBin_-0.04760808471778121']\no2 = ['Alley', 'Condition2', 'Electrical', 'GarageType', 'GarageYrBlt', 'Heating', 'LandContour', 'LandSlope', 'LotShape', 'MiscFeature', 'PavedDrive', 'RoofMatl', 'Street', 'Utilities', '_NeighborhoodBin_-1.0875767879360991']","fe384a07":"train_new1 = train_new1.drop(o1, axis=1)\ntest_new1 = test_new.drop(o2, axis=1)","71c5b605":"# test_new1 = test_new.drop(o2, axis=1)","243c318e":"import xgboost as xgb\nregr = xgb.XGBRegressor(colsample_bytree=0.2,\n                       gamma=0.0,\n                       learning_rate=0.05,\n                       max_depth=6,\n                       min_child_weight=1.5,\n                       n_estimators=7200,\n                       reg_alpha=0.9,\n                       reg_lambda=0.6,\n                       subsample=0.2,\n                       seed=42,\n                       silent=1)\n\nregr.fit(train_new1, label_df)","a3a75ba7":"from sklearn.metrics import mean_squared_error\ndef rmse(y_test,y_pred):\n      return np.sqrt(mean_squared_error(y_test,y_pred))\n\n# run prediction on training set to get an idea of how well it does\ny_pred = regr.predict(train_new1)\ny_test = label_df\nprint(\"XGBoost score on training set: \", rmse(y_test, y_pred))\n\n# make prediction on test set\ny_pred_xgb = regr.predict(test_new1)\n\n#submit this prediction and get the score\npred1 = pd.DataFrame({'Id': test['Id'], 'SalePrice': np.exp(y_pred_xgb)})\npred1.to_csv('xgbnono.csv', header=True, index=False)","ff4b63be":"from sklearn.linear_model import Lasso\n\n#found this best alpha through cross-validation\nbest_alpha = 0.00099\n\nregr = Lasso(alpha=best_alpha, max_iter=50000)\nregr.fit(train_new1, label_df)\n\n# run prediction on the training set to get a rough idea of how well it does\ny_pred = regr.predict(train_new1)\ny_test = label_df\nprint(\"Lasso score on training set: \", rmse(y_test, y_pred))","8407c52d":"#make prediction on the test set\ny_pred_lasso = regr.predict(test_new1)\nlasso_ex = np.exp(y_pred_lasso)\npred1 = pd.DataFrame({'Id': test['Id'], 'SalePrice': lasso_ex})\npred1.to_csv('lasso_model.csv', header=True, index=False)","2fd6558c":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nnp.random.seed(10)\n\n#create Model\n#define base model\ndef base_model():\n    model = Sequential()\n    model.add(Dense(20, input_dim=398, init='normal', activation='relu'))\n    model.add(Dense(10, init='normal', activation='relu'))\n    model.add(Dense(1, init='normal'))\n    model.compile(loss='mean_squared_error', optimizer = 'adam')\n    return model\n\nseed = 7\nnp.random.seed(seed)\n\nscale = StandardScaler()\nX_train = scale.fit_transform(train_new1)\nX_test = scale.fit_transform(test_new1)\n\nkeras_label = label_df.as_matrix()\nclf = KerasRegressor(build_fn=base_model, nb_epoch=1000, batch_size=5,verbose=0)\nclf.fit(X_train,keras_label)\n\n#make predictions and create the submission file \nkpred = clf.predict(X_test) \nkpred = np.exp(kpred)\npred_df = pd.DataFrame(kpred, index=test[\"Id\"], columns=[\"SalePrice\"]) \npred_df.to_csv('keras1.csv', header=True, index_label='Id')","93b8ff5d":"#simple average\ny_pred = (y_pred_xgb + y_pred_lasso) \/ 2\ny_pred = np.exp(y_pred)\npred_df = pd.DataFrame(y_pred, index=test[\"Id\"], columns=[\"SalePrice\"])\npred_df.to_csv('ensemble1.csv', header=True, index_label='Id')","b840b4da":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","c1908579":"## 6. Feature Engineering","e3286aac":"## 7. Model Training and Evaluation","ca0300e0":"## 5. Data Preprocessing"}}