{"cell_type":{"b1ceaf21":"code","df2c1881":"code","d857b5b2":"code","bbe7bcf4":"code","978f8438":"code","ad767520":"code","5783fd48":"code","aebdfa04":"code","0bd4bb68":"code","5761b93e":"code","622ce5b1":"code","0208a1b7":"code","2155225c":"code","7be98f6f":"code","8b44f80f":"code","e53b8ae5":"code","007c7ab6":"code","e5782605":"code","ccdcf5d5":"code","ae20e871":"code","136dbdbb":"code","75c9ba35":"code","3250d2a0":"markdown","611d8ab1":"markdown"},"source":{"b1ceaf21":"import glob\nimport os.path as osp\n\nimport pandas as pdN\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import models, transforms\nimport cv2\nimport albumentations as A","df2c1881":"# Import Data","d857b5b2":"from fastai.vision.all import *","bbe7bcf4":"import pandas as pd\ndf_train = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2021-fgvc8\/train.csv\")\ndf_sub = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv\")","978f8438":"d_set = set()\nfor k in df_train.labels.unique():\n    d_set = d_set | set(k.split(\" \"))\nprint(f\"num of labels: {len(d_set)}  {d_set}\")","ad767520":"# M\u00e3 h\u00f3a c\u00e1c nh\u00e3n, th\u00e0nh d\u1ea1ng interger \u0111\u1ec3 m\u00f4 h\u00ecnh c\u00f3 th\u1ec3 hi\u1ec3u \u0111\u01b0\u1ee3c\ndef to_label(df):\n    \"\"\"\n    h\u00e0m m\u00e3 h\u00f3a cho c\u00e1c nh\u00e3n\n    \"\"\"\n    le = LabelEncoder()\n    df[\"labels_n\"] = le.fit_transform(df.labels.values)\n    return df\n\ndf_train = to_label(df_train)\ndf_labels_idx = df_train.loc[df_train.duplicated([\"labels\", \"labels_n\"])==False]\\\n                [[\"labels_n\", \"labels\"]].set_index(\"labels_n\").sort_index()\ndisplay(df_labels_idx)","5783fd48":"#Gi\u1ea3i n\u00e9n finetuningmodelzoo\n\n! ls \/kaggle\/input\/finetuningmodelzoo","aebdfa04":"def make_datapath_list(phase=\"train\", val_size=0.25):\n    \"\"\"\n    h\u00e0m t\u1ea1o path cho d\u1eef li\u1ec7u\n    \n    C\u00e1c t\u1eeb : 'train','val','test' - c\u1ee5 th\u1ec3 h\u00f3a \u0111\u1ec3 d\u00f9ng cho hu\u1ea5n luy\u1ec7n d\u1eef li\u1ec7u v\u00e0 test d\u1eef li\u1ec7u.\n    \n    val_size : float - t\u1ec9 l\u1ec7 d\u1eef li\u1ec7u x\u00e1c th\u1ef1c \u0111\u1ec3 hu\u1ea5n luy\u1ec7n d\u1eef li\u1ec7u\n    \n    tr\u1ea3 v\u1ec1 : path_list - 1 list ch\u1ee9a c\u00e1c path d\u1eef li\u1ec7u\n    \n    \"\"\"\n    \n    if phase in [\"train\", \"val\"]:\n        phase_path = \"train_images\"    \n    elif phase in [\"test\"]:\n        phase_path = \"test_images\"\n    else:\n        print(f\"{phase} not in path\")\n    rootpath = \"\/kaggle\/input\/plant-pathology-2021-fgvc8\/\"\n#     rootpath = \"\/kaggle\/input\/resized-plant2021\/img_sz_256\/\"\n    target_path = osp.join(TRAIN_IMAGE_PATH , '*.jpg') if  phase in ['train', 'val'] else osp.join(rootpath+phase_path+\"\/*.jpg\")\n\n    path_list = []\n    \n    for path in glob.glob(target_path):\n        path_list.append(path)\n        \n    if phase in [\"train\", \"val\"]:\n        train, val = train_test_split(path_list, test_size=val_size, random_state=0, shuffle=True)\n        if phase == \"train\":\n            path_list = train\n        else:\n            path_list = val\n    \n    return path_list","0bd4bb68":"\"\"\"\n    t\u1ea1o l\u1edbp ti\u1ec1n x\u1eed l\u00fd h\u00ecnh \u1ea3nh\n    c\u00e1c thu\u1ed9c t\u00ednh :\n    resize : ki\u1ec3u s\u1ed1 nguy\u00ean\n    mean : (R, G, B) - gi\u00e1 tr\u1ecb trung b\u00ecnh cho m\u1ed7i k\u00eanh m\u00e0u\n    std : (R, G, B) - \u0111\u1ed9 l\u1ec7ch ti\u00eau chu\u1ea9n cho m\u1ed7i k\u00eanh m\u00e0u\n\"\"\"\n\nclass ImageTransform():\n  \n    def __init__(self, resize, mean, std):\n        self.data_transform = {\n#             'train': A.Compose(albumentation_list),\n            'train': transforms.Compose([\n                transforms.Resize(resize),\n                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomPerspective(),\n                transforms.ToTensor(),\n#                 transforms.RandomRotation(),\n                transforms.Normalize(mean, std)\n            ]),\n            'val': transforms.Compose([\n                transforms.Resize(resize),\n                transforms.CenterCrop(resize),\n                transforms.ToTensor(),\n                transforms.Normalize(mean, std)\n            ]),\n            'test': transforms.Compose([\n                transforms.Resize(resize),\n                transforms.CenterCrop(resize),\n                transforms.ToTensor(),\n                transforms.Normalize(mean, std)\n            ])\n        }\n    \n    def __call__(self, img, phase=\"train\"):       \n        return self.data_transform[phase](img)\n#         return self.data_transform[phase](image=img).get('image')","5761b93e":"\"\"\"\n    L\u1edbp t\u1ea1o t\u1eadp d\u1eef li\u1ec7u\n    c\u00e1c thu\u1ed9c t\u00ednh :\n        df_train: DataFrame - ch\u1ee9a c\u00e1c nh\u00e3n h\u00ecnh \u1ea3nh\n        file_list: list - 1 danh s\u00e1ch ch\u1ee9a c\u00e1c \u0111\u01b0\u1eddng d\u1eabn \u0111\u1ebfn h\u00ecnh \u1ea3nh\n        transform: \u0111\u1ed1i t\u01b0\u1ee3ng - cho l\u1edbp ti\u1ec1n x\u1eed l\u00fd h\u00ecnh \u1ea3nh\n        'train', 'val', 'test' - d\u00f9ng cho hu\u1ea5n luy\u1ec7n v\u00e0 test d\u1eef li\u1ec7u\n\"\"\"\nclass PlantDataset(data.Dataset):\n\n    def __init__(self, df_train, file_list, transform=None, phase='train'):\n        self.df_train = df_train\n        self.df_labels_idx = df_labels_idx\n        self.file_list = file_list\n        self.transform = transform\n        self.phase = phase\n\n#  tr\u1ea3 v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng h\u00ecnh \u1ea3nh\n    def __len__(self):\n        return len(self.file_list)\n\n\n# Nh\u1eadn d\u1eef li\u1ec7u \u1edf \u0111\u1ecbnh d\u1ea1ng Tensor v\u00e0 nh\u00e3n c\u1ee7a ti\u1ec1n x\u1eed l\u00fd h\u00ecnh \u1ea3nh \n    def __getitem__(self, index):\n       \n        # t\u1ea3i h\u00ecnh \u1ea3nh.\n        img_path = self.file_list[index]\n        img = Image.open(img_path)\n#         img = cv2.imread(img_path)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # x\u1eed l\u00fd h\u00ecnh \u1ea3nh tr\u01b0\u1edbc\n        img_transformed = self.transform(img, self.phase)\n        \n        # t\u00ean h\u00ecnh \u1ea3nh\n        image_name = img_path[-20:]\n        \n        # tr\u00edch xu\u1ea5t c\u00e1c nh\u00e3n\n        if self.phase in [\"train\", \"val\"]:\n            label = df_train.loc[df_train[\"image\"]==image_name][\"labels_n\"].values[0]\n        elif self.phase in [\"test\"]:\n            label = -1\n        \n#       tr\u1ea3 v\u1ec1 x\u1eed l\u00fd h\u00ecnh \u1ea3nh tr\u01b0\u1edbc, nh\u00e3n, t\u00ean h\u00ecnh \u1ea3nh\n        return img_transformed, label, image_name","622ce5b1":"size=224\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ntest_list = make_datapath_list(phase=\"test\")\ntest_dataset = PlantDataset(df_train, test_list, transform=ImageTransform(size, mean, std), phase='test')","0208a1b7":"batch_size = 128\n\n# t\u1ea1o dataloader\ntest_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# to Dictionary\ndataloaders_dict = {\"test\": test_dataloader}\n\n# Operation check\n#batch_iterator = iter(dataloaders_dict[\"train\"])\n#inputs, labels = next(batch_iterator)\n#print(inputs.size())  # torch.Size([3, 3, 224, 224]) : [batch_size, Channel, H, W]\n#print(labels)","2155225c":"# Load Model","7be98f6f":"SELECTION_MODEL = 'AlexNet' # AlexNet, VGG16, DenseNet","8b44f80f":"if SELECTION_MODEL == 'AlexNet':\n    net = models.alexnet(pretrained=False)\n    net.classifier[6] = nn.Linear(in_features=4096, out_features=12)","e53b8ae5":"if SELECTION_MODEL == 'VGG16':\n    net = models.vgg16(pretrained=False)\n    net.classifier[6] = nn.Linear(in_features=4096, out_features=12)","007c7ab6":"if SELECTION_MODEL == 'DenseNet':\n    net = models.densenet161(pretrained=False)\n    prev_out_feature = net.classifier.in_features\n    \n    new_last_layer = [\n        nn.Linear(prev_out_feature, 2208),\n        nn.ReLU(inplace = True),\n        nn.Dropout(p=0.5, inplace=False),\n        \n        nn.Linear(2208, 1104),\n        nn.ReLU(inplace = True),\n        nn.Dropout(p=0.5, inplace=False),\n        \n        nn.Linear(1104, 552),\n        nn.ReLU(inplace = True),\n        nn.Dropout(p=0.2, inplace=False),\n        \n        nn.Linear(552, 138),\n        nn.ReLU(inplace = True),\n        nn.Dropout(p=0.2, inplace=False),\n        \n        nn.Linear(138, 12),\n    ]\n    \n    net.classifier = nn.Sequential(*new_last_layer)","e5782605":"load_path = ''\nif SELECTION_MODEL == 'DenseNet':\n    load_path = \"..\/input\/finetuningmodelzoo\/densenet_second10epoch_fine_tuning_v1.h\"\nelif SELECTION_MODEL == 'AlexNet':\n    load_path = '\/kaggle\/input\/finetuningmodelzoo\/alexnet_final200epoch_fine_tuning_v1.h'\nelif SELECTION_MODEL == 'VGG16':\n    load_path = '..\/input\/finetuningmodelzoo\/vgg16_final-50epoch_fine_tuning_v1.h'","ccdcf5d5":"if torch.cuda.is_available():\n    load_weights = torch.load(load_path)\n    net.load_state_dict(load_weights)\nelse:\n    load_weights = torch.load(load_path, map_location={\"cuda:0\": \"cpu\"})\n    net.load_state_dict(load_weights)","ae20e871":"class PlantPredictor():\n    \"\"\"\n    Class for predicting labels from output results\n    \n    Attributes\n    ----------\n    df_labels_idx: DataFrame\n        DataFrame that associates INDEX with a label name\n    \"\"\"\n    \n    def __init__(self, net, df_labels_idx, dataloaders_dict):\n        self.net = net\n        self.df_labels_idx = df_labels_idx\n        self.dataloaders_dict = dataloaders_dict\n        self.df_submit = pd.DataFrame()\n        \n    \n    def __predict_max(self, out):\n        \"\"\"\n        Get the label name with the highest probability.\n        \n        Parameters\n        ----------\n        predicted_label_name: str\n            Name of the label with the highest prediction probability\n        \"\"\"\n        maxid = np.argmax(out.detach().numpy(), axis=1)\n        df_predicted_label_name = self.df_labels_idx.iloc[maxid]\n        \n        return df_predicted_label_name\n    \n    def inference(self):\n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Devices to be used : {device}\")\n        df_pred_list = []\n        for inputs, _, image_name in tqdm(self.dataloaders_dict['test']):\n            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n            self.net.to(device)\n            inputs = inputs.to(device)\n            out = self.net(inputs)\n            device = torch.device(\"cpu\")\n            out = out.to(device)\n            df_pred = self.__predict_max(out).reset_index(drop=True)\n            df_pred[\"image\"] = image_name\n            df_pred_list.append(df_pred)\n            \n        self.df_submit = pd.concat(df_pred_list, axis=0)\n        self.df_submit = self.df_submit[[\"image\", \"labels\"]].reset_index(drop=True)","136dbdbb":"predictor = PlantPredictor(net, df_labels_idx, dataloaders_dict)\npredictor.inference()","75c9ba35":"df_submit = predictor.df_submit.copy()\ndf_submit.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","3250d2a0":"**N\u1ea1p d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o**","611d8ab1":"**D\u00e1n nh\u00e3n cho d\u1eef li\u1ec7u**"}}