{"cell_type":{"99872a3d":"code","5ccf6083":"code","64a00b60":"code","2c11757f":"code","2822204a":"code","ea8b0fb0":"code","0cac91a9":"code","8e8da182":"code","624eec3d":"code","776f07d8":"code","57ddae6a":"code","8bfb0728":"code","2ba8ed45":"code","cfc53274":"code","92341159":"code","0263a130":"code","bde77235":"code","7b4dc01c":"code","48b9771e":"code","7032a198":"code","0d51c502":"code","475954d4":"code","a03a0991":"code","ee9378fa":"code","1e49db88":"markdown","0a32bdbe":"markdown","8b785837":"markdown","50f21e12":"markdown","9b505860":"markdown","4e10a2a7":"markdown","926f6bcc":"markdown","fb492290":"markdown","a5f81273":"markdown","4498f307":"markdown","06ffda7f":"markdown","3efee24f":"markdown","c8f8917a":"markdown","dfe09c2f":"markdown","3c13c01e":"markdown","4fea2f03":"markdown","af7bed1a":"markdown","a330e660":"markdown"},"source":{"99872a3d":"from fastai.vision import open_image","5ccf6083":"img_id = \"0002cc93b\"\nimg_path = f\"..\/input\/severstal-steel-defect-detection\/train_images\/{img_id}.jpg\"","64a00b60":"open_image(img_path)","2c11757f":"#\u00a0One channel from RGB but not necessary here (since all three channels are the same).\nopen_image(img_path, convert_mode = \"L\")","2822204a":"img = open_image(img_path)","ea8b0fb0":"# Displaying the first 5 * 5 patch\nimg.px[:, :5, :5]","0cac91a9":"# The image shape: (channels, width, height)\nimg.px.shape","8e8da182":"# Notice that all channels contain the same information here.\nprint((img.px[0, : , :] == img.px[1, :, :]).all())\nprint((img.px[1, : , :] == img.px[2, :, :]).all())","624eec3d":"import pandas as pd\ntrain_df = pd.read_csv(\"..\/input\/severstal-steel-defect-detection\/train.csv\")","776f07d8":"train_df.head()","57ddae6a":"#\u00a0Will extract img_id and class_id\ntrain_df[\"img_id\"] = train_df[\"ImageId_ClassId\"].str.split(\".\").str[0]\ntrain_df[\"class_id\"] =  train_df[\"ImageId_ClassId\"].str.split(\".\").str[1].str.split('_').str[1]","8bfb0728":"train_df.head()","2ba8ed45":"train_df.loc[lambda df: df[\"img_id\"] == img_id, [\"EncodedPixels\", \"class_id\"]]","cfc53274":"# The mask is the first elemen\nmask_rle = train_df.loc[lambda df: df[\"img_id\"] == img_id, \"EncodedPixels\"].values[0]","92341159":"from fastai.vision import open_mask_rle\nmask_shape = (img.px.shape[1], img.px.shape[2])\nmask = open_mask_rle(mask_rle, shape=mask_shape)\nmask","0263a130":"from fastai.vision import ImageSegment\n# Need to create a mask using the ImageSegment class\nmask = ImageSegment(mask.data.transpose(2, 1))\nmask","bde77235":"img.show(y=mask, figsize=(20, 10), title=f\"{img_id} with mask, label 1\")","7b4dc01c":"!mkdir ..\/masks","48b9771e":"import math\nimport torch\nfrom fastai.vision import open_mask_rle, ImageSegment\n\ndef get_and_save_mask(img_id, df, shape=(1600, 256)):\n    \"\"\" Extract the mask(s) for each image. The mask could be None.\"\"\"\n    # Shape: (width, height)\n    # One mask (or none) per image.\n    masks = []\n    rle_df = df.loc[df[\"img_id\"] == img_id, ['class_id', 'EncodedPixels']]\n    # Not all images have masks\n    for row in rle_df.itertuples():\n        rle = row.EncodedPixels\n        class_id = row.class_id\n        if isinstance(rle, float) and math.isnan(rle):\n            continue\n        one_mask = open_mask_rle(rle, shape=shape)\n        one_mask = int(class_id) * one_mask.data\n        masks.append(one_mask)\n    if len(masks) == 0:\n        return\n    stacked_mask = torch.stack(masks, dim=0).sum(dim=0)\n    mask_img = ImageSegment(stacked_mask.reshape((1, shape[0], shape[1])).transpose(2, 1))\n    mask_img.save(f\"..\/masks\/{img_id}.jpg\")","7032a198":"#\u00a0Run over all the train images\nfor img_id in train_df[\"img_id\"].unique():\n    get_and_save_mask(img_id, train_df)","0d51c502":"from fastai.vision import open_mask\nopen_mask(\"..\/masks\/0025bde0c.jpg\")","475954d4":"#\u00a0Filtering images with at least one mask\nwith_masks_df = (train_df.groupby('img_id')['EncodedPixels'].count() \n                      .reset_index()\n                      .rename(columns={\"EncodedPixels\": \"n_masks\"}))\nwith_masks_df = with_masks_df.loc[lambda df: df[\"n_masks\"] > 0, :]","a03a0991":"# data pipeline\nfrom fastai.vision import SegmentationItemList, get_transforms\n\ntrain_folder = \"..\/input\/severstal-steel-defect-detection\/train_images\/\"\nsl = SegmentationItemList.from_df(with_masks_df, train_folder, suffix=\".jpg\")\nsize = 256\nbatch_size = 16\ndata = (sl.split_none()\n          .label_from_func(lambda x : str(x).replace(train_folder, '..\/masks\/'),\n                           classes=[0, 1, 2, 3, 4])\n          .transform(get_transforms(), size=size, tfm_y=True)\n          .databunch(bs=batch_size))","ee9378fa":"data.show_batch()","1e49db88":"Before doing that, let's plot both the image and the mask in a single plot.","0a32bdbe":"Looks better!","8b785837":"Alright, to get started, let's get an image from the training dataset.\nFor that, we will need only two things:\n\n1. path to the image\n2. [`open_image`](https:\/\/docs.fast.ai\/vision.image.html#open_image) utility function","50f21e12":"Awesome, it worked! Alright, now that we have both images and masks saved \nas files, let's load a bunch of them.\n\nBefore we dive deep, here is the plan to get the data pipeline: \n\n* contruct a DataFrame that contains only images having at least one mask (this will be called\n`with_masks_df`)\n* Load images using the `from_df` method\n* Extract labels using the `label_from_func` method: this takes a function that reads\none image input path and outputs a mask path. Since we have multiple classes (0 for background\nand 1 through 4 for the different defect types), these should be passed as well.\n* Transform the images and masks. Notice that this step is optional but I am \nadding it to get resized images (since I pass the `size` variable)\n* Finally, use the `databunch` method to create a [**DataBunch**](https:\/\/docs.fast.ai\/basic_data.html#DataBunch). Again, this isn't necessary but will comes handy in the next notebook so I want you to get used to the concept.\n\n","9b505860":"Let's load one of these saved masks. ","4e10a2a7":"Next, let's load a mask for the given image. As you will see, the masks are stored as textual representation (run-length encoding shortned as rle) rather than images to save space. This is a slightly more complicated task but \nnothing insurmontable. For that, we will need three things:\n    \n1. mapping between the image and the mask (or masks if many)\n2. the mask's rle\n3. [`open_mask_rle utiliy`](https:\/\/docs.fast.ai\/vision.image.html#open_mask_rle) function","926f6bcc":"That was easy!","fb492290":"Let's find the rle corresponding to the `img_id` (id of the displayed image). ","a5f81273":"#\u00a0Combining both steps in a pipeline","4498f307":"This is a series of notebooks were I explore the [**fastai**](https:\/\/www.fast.ai\/) [**library**](https:\/\/docs.fast.ai\/) (with a focus on computer vision given the nature of the competition). More parts will be available in the upcoming weeks, so stay tuned!\n\nIn this first part, I will show you:\n\n1. How to read an image\n2. How to read a mask from a [**run-length encoding**](https:\/\/en.wikipedia.org\/wiki\/Run-length_encoding)\n3. How to combine both steps to get a bunch of images and masks\n\nLet's start!","06ffda7f":"#\u00a0Loading a mask","3efee24f":"I was planning to run a data pipeline without doing any intermediate steps. However, I was unable to do so so far. If you know how to do it, please let me know in the comments section.\nFor now, I have a step where I extract and save masks (one mask per image). \n\nLet's go through this.","c8f8917a":"That's it for this first notebook. In the next one, we will be building upon these foundations\nand train a [**U-net**](https:\/\/arxiv.org\/abs\/1505.04597) model. \nStay tuned. ;)","dfe09c2f":"#\u00a0Loading an image","3c13c01e":"Hum, that looks like a mask but wrongly shaped. What went wrong?\nWell, this is a quirk of the rle format. I won't delve into too much details but\njust remember that you need to rotate the mask 90 degrees (counter-clockwise).\nTo do so, one can use the transpose operation. ","4fea2f03":"Now that the pipeline is defined, we can visualize some images with the associated masks.","af7bed1a":"Great! So we have one mask (represented using rle) with `class_id` 1 for the given image. Let's\nplot the mask!","a330e660":"To get the mapping and the rle, we need to open the train CSV. Will be using pandas for that."}}