{"cell_type":{"c84dc4c9":"code","4b876dda":"code","baa16893":"code","313f2236":"code","76c91921":"code","965e5638":"code","bd972045":"code","771bed04":"code","7c609dda":"code","6d057f74":"code","1182e792":"code","70315eac":"code","78fecd66":"code","41081704":"code","de740359":"code","a9a5f971":"code","6720847f":"code","468f4392":"code","c80a99d3":"code","d95084cb":"code","7e6fa99f":"code","7093f04a":"code","5a9c2c35":"code","a5c75e96":"code","12f735c7":"code","255ca6c9":"code","97a1ca0e":"code","e84349d3":"code","8d4a2a0c":"code","9869718c":"code","13dbbfef":"markdown","fdd8f446":"markdown","8b8e7b97":"markdown","00244161":"markdown","684e3645":"markdown","80d54ca0":"markdown","ed4c34b8":"markdown","9c0a1577":"markdown","b3522cb7":"markdown","88f5f036":"markdown","16e29fa7":"markdown","d609253c":"markdown"},"source":{"c84dc4c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b876dda":"from sklearn.datasets import load_breast_cancer","baa16893":"cancer=load_breast_cancer()","313f2236":"type(cancer)","76c91921":"cancer.keys()","965e5638":"print(cancer['DESCR'])","bd972045":"df=pd.DataFrame(cancer['data'],columns=cancer['feature_names'])","771bed04":"df.head()","7c609dda":"df.info()","6d057f74":"from sklearn.preprocessing import StandardScaler","1182e792":"scaler=StandardScaler()\nscaler.fit(df)","70315eac":"scaled_df=scaler.transform(df)","78fecd66":"from sklearn.decomposition import PCA ","41081704":"pca=PCA(n_components=2)","de740359":"pca.fit(scaled_df)","a9a5f971":"pca_df=pca.transform(scaled_df)","6720847f":"pca_df.shape","468f4392":"pca_df","c80a99d3":"plt.figure(figsize=(8,6))\nplt.scatter(pca_df[:,0],pca_df[:,1],c=cancer['target'])\nplt.xlabel('First principal component')\nplt.ylabel('Second Principal component')\nplt.legend()","d95084cb":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(pca_df,cancer['target'],test_size=0.2)","7e6fa99f":"from sklearn.neighbors import KNeighborsClassifier","7093f04a":"knn=KNeighborsClassifier(n_neighbors=1)","5a9c2c35":"knn.fit(xtrain,ytrain)","a5c75e96":"pred=knn.predict(xtest)","12f735c7":"from sklearn.metrics import classification_report,confusion_matrix\ncon=confusion_matrix(ytest,pred)\nprint(con)","255ca6c9":"rep=classification_report(ytest,pred)\nprint(rep)","97a1ca0e":"from sklearn.model_selection import cross_val_score","e84349d3":"err=[]\nfor i in range(1,40):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    score=cross_val_score(knn,pca_df,cancer['target'],cv=10)\n    err.append(1-score.mean())","8d4a2a0c":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),err,linestyle='dashed',marker='o',markersize=10,markerfacecolor='red')\nplt.xlabel('K-neighbor')\nplt.ylabel('Error rate')","9869718c":"knn = KNeighborsClassifier(n_neighbors=21)\n\nknn.fit(xtrain,ytrain)\npred = knn.predict(xtest)\n\nprint('WITH K=21')\nprint('\\n')\nprint(confusion_matrix(ytest,pred))\nprint('\\n')\nprint(classification_report(ytest,pred))","13dbbfef":"**Thus the no of false positives with n_neighbors = 21 is reduced from n_neighbors=1.**","fdd8f446":"# **Principal Component Analysis**","8b8e7b97":"# **Dataset** \n**we are going to create dataframe from the cancer data** ","00244161":"**From the above description we can say that there are 569 records and 30 features in the dataset and there are two classes of label ie Malignant and Benign.**","684e3645":"**There are two occurences of false positive.It means that the model did not predict the two cancer affected person.We have to increase the model accuracy**","80d54ca0":"# **Standard Normalisation**\n**The first step of dimensionality reduction is standard normalisation so that all the features in the dataset becomes in the same range.Then the dataset will be of mean 0 and standard deviation is 1**","ed4c34b8":"**Thus we can see that the no of features is reduced from 30 to 2**","9c0a1577":"**We can take n_neighbors = 21 because after that there is no decrease in error.It is the minimum error**","b3522cb7":"# PCA\n**In pca we are converting the more no of features into reduced no of features.**","88f5f036":"# **K-Nearest Neighbor**\nwe are going to use the K nearest neighbor algorithm for the purpose of classification","16e29fa7":"**Thus the diagram clearly explains that the data of two classes are easily separable.**","d609253c":"# Cross validation\n**choosing the correct k neighbor**"}}