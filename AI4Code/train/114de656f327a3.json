{"cell_type":{"e8549a7a":"code","bc97e8d2":"code","9ba33ceb":"code","f2cca8db":"code","ed37b21f":"code","e3ea7c5c":"code","1b75edd3":"code","020f11e9":"code","22fb1130":"code","31053857":"code","cbc4e2e5":"code","d9c738e7":"code","4a580cc9":"code","0453bcaa":"code","c4798efb":"code","2e4f05a2":"code","388b5246":"code","cf3bcdbb":"code","4d90a8d0":"code","f4ff9c4c":"markdown"},"source":{"e8549a7a":"#importing the libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bc97e8d2":"#reading the data\ndata=pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","9ba33ceb":"#understanding the data\ndata.head()","f2cca8db":"#deleting unwanted columns\ndrop_cols=[\"id\",\"Unnamed: 32\"]\ndata.drop(drop_cols,axis=1,inplace=True)","ed37b21f":"data.columns","e3ea7c5c":"#checking the null values \ndata.isna().sum()","1b75edd3":"#and converting M to 1 and B to 0 \ndata['diagnosis']=[1 if x=='M' else 0 for x in data['diagnosis']]","020f11e9":"#checking the distribution of the target variable\ndata.diagnosis.value_counts()","22fb1130":"#separating the dependent and independent features\ny=data.diagnosis\nX=data\nX.drop(\"diagnosis\",axis=1,inplace=True)","31053857":"X.head()","cbc4e2e5":"#spliting the data into train and test\ntrain_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.3,random_state=123)\nprint(train_X.shape)\nprint(test_X.shape)\nprint(train_y.shape)\nprint(test_y.shape)","d9c738e7":"#standardizing the data\nstd=StandardScaler()\nstd.fit(train_X)\ntrain_X=pd.DataFrame(std.transform(train_X),index=train_X.index)\ntest_X=pd.DataFrame(std.transform(test_X),index=test_X.index)","4a580cc9":"train_X.head()","0453bcaa":"#importing the keras and other libraries \nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import regularizers,optimizers\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau","c4798efb":"#building the neural network...\n#Defining the Optimizer\nadam=keras.optimizers.adam(lr=0.001,decay=0.0005)\n\n## Just a way to define neural nets. There are two ways sequential and functional\n## Sequential model lets you add neural net layers one after another by calling function\nmodel=Sequential()\n\n## Adding layers sequentially one by one...\n## Notice our data has 30 input columns which goes into as the \"input_shape\" parameter\nmodel.add(Dense(16,input_shape=(30,)))\n\nmodel.add(Dense(8,init=\"uniform\",activation=\"relu\"))\n\nmodel.add(Dense(4,init=\"uniform\",activation=\"relu\"))\n\n## Notice the use of l2 regularizer\nmodel.add(Dense(1,activation=\"sigmoid\",kernel_regularizer=regularizers.l2()))\n\n## Callbacks\nearlystopper = EarlyStopping(monitor='val_loss', patience=10)\nreduce_lr = ReduceLROnPlateau(patience=5, verbose=1)\n\n#compiling our model and defining the loss function\nmodel.compile(optimizer=adam,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\n#training the neural nets\nhistory=model.fit(train_X,train_y,validation_data=(test_X,test_y),epochs=200,batch_size=50,callbacks=[earlystopper,reduce_lr])","2e4f05a2":"train_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\n\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfrom matplotlib import pyplot as plt #plt is a visualization module in matplotlib.  \n%matplotlib inline \nplt.figure(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.plot(train_loss)\nplt.plot(val_loss)\n\nplt.subplot(1,2,2)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.plot(train_acc)\nplt.plot(val_acc)","388b5246":"# USING SKLEARN MLP CLASSIFIER WITH GRID SEARCH\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\n\nclassifier=MLPClassifier(activation=\"logistic\",random_state=123)\n\nparam= {\"batch_size\" : [16, 32, 64, 128],\n           \"hidden_layer_sizes\" : [(11,), (15,), (19,),(21,)],\n           \"max_iter\" : [50, 100, 150, 200]}\n\ngrid=GridSearchCV(estimator=classifier,param_grid=param,cv=5,n_jobs=1)\ngrid.fit(train_X,train_y)\ngrid.best_estimator_","cf3bcdbb":"train_preds=grid.best_estimator_.predict(train_X)\ntest_preds=grid.best_estimator_.predict(test_X)","4d90a8d0":"from sklearn.metrics import accuracy_score\nprint(\"Train Accuracy  :  \",accuracy_score(train_y,train_preds))\nprint(\"Test Accuracy   :  \",accuracy_score(test_y,test_preds))","f4ff9c4c":"Attribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)\n\nb) texture (standard deviation of gray-scale values)\n\nc) perimeter\n\nd) area\n\ne) smoothness (local variation in radius lengths)\n\nf) compactness (perimeter^2 \/ area - 1.0)\n\ng) concavity (severity of concave portions of the contour)\n\nh) concave points (number of concave portions of the contour)\n\ni) symmetry\n\nj) fractal dimension (\"coastline approximation\" - 1)\n"}}