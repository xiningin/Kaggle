{"cell_type":{"939fc822":"code","c996b508":"code","d2e01675":"code","4bb4cc61":"code","483447a3":"code","0048d2f8":"code","36d413a4":"code","d597d698":"code","b4dbd057":"code","18d7e4f6":"code","48012496":"code","9ac8578a":"code","e745b514":"code","dde0ab37":"code","7735a296":"code","c9170b35":"code","6d92bb6f":"code","3e88306b":"code","7f537abb":"code","38c24fff":"code","c11f65d9":"code","f8081b0e":"code","4e2bd0bf":"code","6901dc4d":"code","5cb3ed04":"markdown","46b9b09a":"markdown","9fdd9353":"markdown","369450ac":"markdown","f67c695f":"markdown","531776d9":"markdown","f27600e0":"markdown","c7e406c8":"markdown","d15214da":"markdown","c789e438":"markdown","898ab120":"markdown"},"source":{"939fc822":"\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nfrom sklearn.metrics import accuracy_score\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","c996b508":"df = pd.read_csv('..\/input\/parkinsonsxyz\/parkinsons2.csv')\ndf.head()","d2e01675":"df.shape","4bb4cc61":"df.info()","483447a3":"df.describe().T","0048d2f8":"df.isnull().sum()","36d413a4":"# Plot histograms for each variable\ndf.hist(figsize=(20,12))\nplt.show()","d597d698":"df['status'].value_counts()","b4dbd057":"percentage_of_disease = 147 \/ (147 + 48) * 100\npercentage_of_not_having_disease = 48 \/ (147 + 48) * 100\nprint('percentage of having disease' , percentage_of_disease)\nprint('percentage of not having disease' , percentage_of_not_having_disease)","18d7e4f6":"sns.catplot(x='status',kind='count',data=df)","48012496":"df.columns","9ac8578a":"col={'MDVP:Fo(Hz)': 1, 'MDVP:Fhi(Hz)':2, 'MDVP:Flo(Hz)':3, 'MDVP:Jitter(%)':4,\n       'MDVP:Jitter(Abs)':5, 'MDVP:RAP':6, 'MDVP:PPQ':7, 'Jitter:DDP':8,\n       'MDVP:Shimmer':9, 'MDVP:Shimmer(dB)':10, 'Shimmer:APQ3':11, 'Shimmer:APQ5':12,\n       'MDVP:APQ':13, 'Shimmer:DDA':14, 'NHR':15, 'HNR':16, 'RPDE':17, 'DFA':18, 'spread1':19,\n       'spread2':20, 'D2':21, 'PPE':22}","e745b514":"plt.figure(figsize=(20,30))\n\nfor variable,i in col.items():\n                     plt.subplot(5,5,i)\n                     plt.boxplot(df[variable])\n                     plt.title(variable)\n\nplt.show()","dde0ab37":"q1 = df.quantile(0.25)\nq2 = df.quantile(0.5)\nq3 = df.quantile(0.75)\nIQR = q3-q1\nprint(IQR)","7735a296":"df_out = df[~((df < (q1 - 1.5* IQR)) | (df > (q3 + 1.5 * IQR))).any(axis =1)]","c9170b35":"plt.figure(figsize=(20,30))\n\nfor variable,i in col.items():\n                     plt.subplot(5,5,i)\n                     plt.boxplot(df_out[variable])\n                     plt.title(variable)\n\nplt.show()","6d92bb6f":"#sns.pairplot(df_out , hue = 'status')","3e88306b":"x=df.drop(['status'],axis=1)\ny=df['status']","7f537abb":"scaler=MinMaxScaler((-1,1))\nx=scaler.fit_transform(x)","38c24fff":"x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=7)","c11f65d9":"x = np.array(df_out.drop(['status'],axis=1))\ny = np.array(df_out['status'])","f8081b0e":"from sklearn.metrics import classification_report, confusion_matrix\nxgb= XGBClassifier()\nxgb.fit(x_train,y_train)\ny_pred=xgb.predict(x_test)\nprint(classification_report(y_test,y_pred))\naccuracy1=xgb.score(x_test,y_test)\nprint (accuracy1*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","4e2bd0bf":"from sklearn.ensemble import RandomForestClassifier \nfrom sklearn.tree import DecisionTreeClassifier\n\ndes_class=DecisionTreeClassifier()\ndes_class.fit(x_train,y_train)\ndes_predict=des_class.predict(x_test)\nprint(classification_report(y_test,des_predict))\naccuracy3=des_class.score(x_test,y_test)\nprint(accuracy3*100,'%')\ncm = confusion_matrix(y_test, des_predict)\nsns.heatmap(cm, annot= True)","6901dc4d":"from sklearn.naive_bayes  import GaussianNB \nfrom sklearn.metrics import classification_report, confusion_matrix\nnvclassifier = GaussianNB()\nnvclassifier .fit(x_train,y_train)\ny_pred=nvclassifier .predict(x_test)\nprint(classification_report(y_test,y_pred))\nprint(accuracy_score(y_pred,y_test)*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","5cb3ed04":"Applying XGBoost Classifier first, I have not done any hyperparameter tuning and optimization for this dataset but you can can try this will surely help in increasing the accuracy upto a certain level.","46b9b09a":"Scaling the values between -1 and 1 before applying the three models.","9fdd9353":"Introduction:-\n\nParkinson\u2019s disease is a progressive disorder of the central nervous system affecting movement and inducing tremors and stiffness. It has 5 stages to it and affects more than 1 million individuals every year in India. This is chronic and has no cure yet. It is a neurodegenerative disorder affecting dopamine-producing neurons in the brain.\n\nProblem Statement:- Prediction of PARKINSON'S Disease.\n\nThe Dataset contains following columns:-\n\n1) name - object\n\n2) MDVP:Fo(Hz) - float64\n\n3) MDVP:Fhi(Hz) - float64\n\n4) MDVP:Flo(Hz) - float64\n\n5) MDVP:Jitter(%) - float64\n\n6) MDVP:Jitter(Abs) - float64\n\n7) MDVP:RAP - float64\n\n8) MDVP:PPQ - float64\n\n9) Jitter:DDP - float64\n\n10) MDVP:Shimmer - float64\n \n11) MDVP:Shimmer(dB) - float64\n\n12) Shimmer:APQ3 - float64\n\n13) Shimmer:APQ5 - float64\n\n14) MDVP:APQ - float64\n\n15) Shimmer:DDA - float64\n\n16) NHR - float64\n\n17) HNR - float64\n\n18) status - int64\n\n19) RPDE - float64\n\n20) DFA - float64\n\n21) spread1 - float64\n\n22) spread2 - float64\n\n23) D2 - float64\n\n24) PPE - float64\n\nData visualization done with using various plots.\n\nMachine learning algorithm used\n\n1) XGBOOST\n\n2) Decision Tree Classifier\n\n3) Naive Bayes","369450ac":"**Thank You please upvote if you like the kernel.**","f67c695f":"**XG BOOST CLASSIFIER IS GIVING US A GOOD ACCURACY OF 95% WITH GOOD PRECISION AND RECALL SCORE.**","531776d9":"**Removing the outliers from the features.**","f27600e0":"Health status:-\n\n1= parkinsons\n\n0=healthy\n\nMore number of peoples are suffering from parkisons disease.","c7e406c8":"Splitting the dependent and independent variables before modelling.","d15214da":"**DECISION TREE CLASSIFIER IS GIVING A ACCURACY OF 85% WHICH IS NOT THAT BAD BUT LESSS IN COMPARISION XG BOOST CLASSIFIER. IN HEALTHCARE SECTOR WE NEED TO MAKE SURE THAT WE ARE HAVING A GOOD ACCURACY AS WE CANNOT COMPROMISE WRONG PREDICTIONS WITH PATIENTS LIFE WHILE PREDICTING DISEASE.**","c789e438":"***XG BOOST CLASSIFIER IS GIVING US A GOOD ACCURACY OF 95% WITH GOOD PRECISION AND RECALL SCORE.We can stick with this model for now.***","898ab120":"Splitting up the datasets into 80% training set and 20% test set."}}