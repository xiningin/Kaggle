{"cell_type":{"e69d1cd0":"code","5ceee8a4":"code","68ff60f2":"code","be1fa26d":"code","d586d1ce":"code","07c7acd9":"code","61906431":"code","98c805c3":"code","3eaf34a7":"code","7a6a0fc8":"code","3bd0d621":"code","9cb032d9":"code","37271caa":"code","dc6cbd7b":"code","c992bd1f":"code","ec4ae42a":"code","b7a98927":"code","88026618":"code","3729ee00":"code","85b4a116":"code","49356be4":"code","66da6121":"code","98f882ca":"code","7f1ad633":"code","bd5bea20":"code","a12ada76":"code","5b0ae142":"code","d54eb30b":"markdown","e3389928":"markdown","d35ba28a":"markdown","ab9194b3":"markdown","1772c26e":"markdown","ff9161f1":"markdown","69061d3e":"markdown","432d0268":"markdown","a75c7282":"markdown","b6e245e7":"markdown","b2cd75ca":"markdown","70eace4a":"markdown","889a7b91":"markdown","99fbc18f":"markdown","07430129":"markdown","84b9228a":"markdown","878fb922":"markdown","877eaa91":"markdown","4b0eb294":"markdown","b2986fda":"markdown","71ac52af":"markdown","720999e9":"markdown","7c315449":"markdown","824722d0":"markdown","6c3a607e":"markdown","858aa325":"markdown"},"source":{"e69d1cd0":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport skimage\nimport skimage.io","5ceee8a4":"IMAGE_PATH = '..\/\/input\/\/chinese-mnist\/\/data\/\/data\/\/'","68ff60f2":"os.listdir(\"..\/\/input\/\/chinese-mnist\")","be1fa26d":"data_df=pd.read_csv('..\/\/input\/\/chinese-mnist\/\/chinese_mnist.csv')","d586d1ce":"data_df.shape","07c7acd9":"data_df.sample(100).head()","61906431":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()\/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data(data_df)","98c805c3":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","3eaf34a7":"def create_file_name(x):\n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","7a6a0fc8":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)","3bd0d621":"data_df.head()","9cb032d9":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","37271caa":"def read_image_sizes(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    return list(image.shape)","dc6cbd7b":"m = np.stack(data_df['file'].apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h'])\ndata_df = pd.concat([data_df,df],axis=1, sort=False)","c992bd1f":"print(f\"Images widths #: {data_df.w.nunique()},  heights #: {data_df.h.nunique()}\")\nprint(f\"Images widths values: {data_df.w.unique()},  heights values: {data_df.h.unique()}\")","ec4ae42a":"data_df.head()","b7a98927":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.nunique()}: {list(data_df.sample_id.unique())}\")\nprint(f\"Characters codes: {data_df.code.nunique()}: {list(data_df.code.unique())}\")\nprint(f\"Characters: {data_df.character.nunique()}: {list(data_df.character.unique())}\")\nprint(f\"Numbers: {data_df.value.nunique()}: {list(data_df.value.unique())}\")","88026618":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set2')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()  ","3729ee00":"plot_count(\"code\", \"character code\", data_df, size=3)","85b4a116":"plot_count(\"value\", \"number value\", data_df, size=3)","49356be4":"print(f\"frequence of each character:\")\ndata_df.character.value_counts()","66da6121":"def show_images(df, isTest=False):\n    f, ax = plt.subplots(10,15, figsize=(15,10))\n    for i,idx in enumerate(df.index):\n        dd = df.iloc[idx]\n        image_name = dd['file']\n        image_path = os.path.join(IMAGE_PATH, image_name)\n        img_data = cv.imread(image_path)\n        ax[i\/\/15, i%15].imshow(img_data)\n        ax[i\/\/15, i%15].axis('off')\n    plt.show()","98f882ca":"df = data_df.loc[data_df.suite_id==1].sort_values(by=[\"sample_id\",\"value\"]).reset_index()\nshow_images(df)","7f1ad633":"df = data_df.loc[data_df.suite_id==37].sort_values(by=[\"sample_id\",\"value\"]).reset_index()\nshow_images(df)","bd5bea20":"df = data_df.loc[data_df.suite_id==75].sort_values(by=[\"sample_id\",\"value\"]).reset_index()\nshow_images(df)","a12ada76":"df = data_df.loc[data_df.code==1].sample(150).reset_index()\nshow_images(df)","5b0ae142":"df = data_df.loc[data_df.code==5].sample(150).reset_index()\nshow_images(df)","d54eb30b":"Let's look now to a selection of writings for number 0.","e3389928":"<h1><center><font size=\"6\">Chinese MNIST Exploratory Data Analysis<\/font><\/center><\/h1>\n\n<center><img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F769452%2Ffae77a81c057fe419de60f5e2b20be25%2Fchinese_mnist_profile_small.png?generation=1596963542354014&alt=media\"><\/img><\/center>\n \n \n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the data analysis<\/a>  \n - <a href='#21'>Load packages<\/a>  \n - <a href='#21'>Load the data<\/a>  \n - <a href='#21'>Preprocessing data<\/a>  \n- <a href='#3'>Data exploration<\/a>   \n - <a href='#31'>Check for missing data<\/a>  \n - <a href='#32'>Explore image data<\/a>  \n - <a href='#33'>Suits, samples, characters distribution<\/a>  \n- <a href='#4'>Conclusions<\/a>      ","d35ba28a":"For volunteer number 75:","ab9194b3":"We have 100 suites, each with 10 samples.","1772c26e":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n# <a id='6'>Conclusions<\/a>  \n\nWe analyzed the dataset, focusing on understanding the data distribution. In the next Notebooks, we will see how we can use this data to train a model to classify new images by character (number value, code or an echivalent label associated).\n\n\n<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>","ff9161f1":"## <a id='31'>Check for missing data<\/a>  \n\nLet's create a function that check for missing data in the dataset.","69061d3e":"We show here the samples drawn by volunteer number 1.","432d0268":"Let's also check that each line in the dataset has a corresponding image in the image list.  \nFirst, we will have to compose the name of the file from the indexes.","a75c7282":"There is a dataset file and a folder with images.  \n\nLet's load the dataset file first.","b6e245e7":"# <a id='21'>Load packages<\/a>\n\nWe load the packages used for the analysis.\n","b2cd75ca":"There is no missing (null) data in the dataset. Still it might be that some of the data labels are misspelled; we will check this when we will analyze each data feature.","70eace4a":"# <a id='1'>Introduction<\/a>  \n\n\nIn this Kernel, we will explore a dataset with adnotated images of Chinese numbers, handwritten by a number of 100 volunteers, each providing a number of 10 samples, each sample with a complete set of 15 Chinese characters for numbers.\n\nThe Chinese characters are the following:\n* \u96f6 - for 0  \n* \u4e00 - for 1\n* \u4e8c - for 2  \n* \u4e09 - for 3  \n* \u56db - for 4  \n* \u4e94 - for 5  \n* \u516d - for 6  \n* \u4e03 - for 7  \n* \u516b - for 8  \n* \u4e5d - for 9  \n* \u5341 - for 10\n* \u767e - for 100\n* \u5343 - for 1000\n* \u4e07 - for 10 thousands\n* \u4ebf - for 100 millions\n\n\nThe objective of the Kernel is to take us through the first steps of a machine learning analysis. We start by preparing the analysis (load the libraries and the data), continue with an Exploratory Data Analysis (EDA) where we highlight various data features, spending some time to try to understand the data.\n\nThe first step is to prepare the data analysis.\n\n<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  ","889a7b91":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n# <a id='3'>Data exploration<\/a>  \n\n\n\nLet's start by checking if there are missing data, unlabeled data or data that is inconsistently labeled. \n","99fbc18f":"We also set the image path.","07430129":"Let's check the distribution of images width and height.","84b9228a":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n\n# <a id='22'>Load the data<\/a>  \n\nLet's see first what data files do we have in the root directory.","878fb922":"## <a id='33'>Suites, Samples, Characters distribution<\/a>  \n\nLet's check the suites of the images. For this, we will group by `suite`.","877eaa91":"Let's also check the image sizes.","4b0eb294":"Let's also glimpse the dataframe with the new columns.","b2986fda":"And here are the samples drawn by volunteer number 37.","71ac52af":"There are 15000 rows and 5 columns. Let's look to the data.","720999e9":"Let's see now a collection of writings for number 4.","7c315449":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n## <a id='32'>Explore image data<\/a>  \n\nLet's also check the image data. First, we check how many images are stored in the image folder.","824722d0":"The data contains the following values:  \n\n* suite_id - each suite corresponds to a set of handwritten samples by one volunteer;  \n* sample_id - each sample wil contain a complete set of 15 characters for Chinese numbers;\n* code - for each Chinese character we are using a code, with values from 1 to 15;\n* value - this is the actual numerical value associated with the Chinese character for number;  \n* character - the Chinese character;  \n\nWe index the files in the dataset by forming a file name from suite_id, sample_id and code. The pattern for a file is as following:\n\n> \"input_{suite_id}_{sample_id}_{code}.jpg\"","6c3a607e":"Let's glimpse the data. First, let's check the number of columns and rows.","858aa325":"# <a id='2'>Prepare the data analysis<\/a>   \n\n\nBefore starting the analysis, we need to make few preparation: load the packages, load and inspect the data.\n\n"}}