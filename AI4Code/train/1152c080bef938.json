{"cell_type":{"60066299":"code","502011cf":"code","22bafd7b":"code","ba9b44c0":"code","a1d4f3ff":"code","828dc6c6":"code","a3d49970":"code","6c815ad7":"code","851e61e8":"code","1eba8510":"code","fc777d94":"code","4ac89f7c":"code","e03afde3":"code","41c56bc2":"code","9cd1a2df":"code","7e50c8c6":"code","1edbd81e":"code","3002199b":"code","67626682":"code","5efcca17":"code","a1231b8d":"code","0993f1ca":"code","4992b22a":"code","02ca201f":"code","58d2cd66":"code","5b5adf6c":"code","eed1c8d1":"code","7709c3a8":"code","e81f58cf":"code","06b79091":"code","064c59ed":"code","36ddc1ee":"code","9245e2e5":"code","49c18c96":"code","972cd347":"code","b62ab58f":"code","2a95fcf3":"code","5ff2bb19":"code","1bfd54dd":"code","9e7dd5cc":"code","828d8bc1":"code","337a20fc":"markdown","7e01db4b":"markdown","5d1083c2":"markdown","af297b31":"markdown","f93bcd99":"markdown","dcac99cd":"markdown","790216ec":"markdown","138e29b2":"markdown","7a9a9109":"markdown","fba4dca0":"markdown","c2e192f1":"markdown","d358431b":"markdown"},"source":{"60066299":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","502011cf":"import pandas as pd\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# For preprocessing the data\nfrom sklearn.preprocessing import Imputer\nfrom sklearn import preprocessing\n\n# To split the dataset into train and test datasets\nfrom sklearn.model_selection import train_test_split\n\n# To calculate the accuracy score of the model\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,confusion_matrix\n\ndf = pd.read_csv(\"..\/input\/Bank_Personal_Loan_Modelling.csv\")","22bafd7b":"df.head()","ba9b44c0":"df.dtypes","a1d4f3ff":"#5 point summary analysis\ndf.describe()","828dc6c6":"df.groupby([\"Personal Loan\"]).count()\n\n# Class distribution among B and M is almost 2:1. The model will better predict B and M","a3d49970":"df.columns[(df == 0).all()]","6c815ad7":"# The first column is id column which is customer ID and nothing to do with the model attriibutes. So drop it.\ndf =  df.drop(columns=['ID'], axis=1)\ndf","851e61e8":"# Number of records(rows) in the dataframe\nlen(df)","1eba8510":"df.isnull().values.any() # If there are any null values in data set","fc777d94":"# Handling missing data\n# Test whether there is any null value in our dataset or not. We can do this using isnull() method.\ndf.isnull().sum()","4ac89f7c":"# Excluding Outcome column which has only \ndf.drop(['Personal Loan'], axis=1).hist(stacked=False, bins=100, figsize=(30,45), layout=(14,4))","e03afde3":"df.corr() # It will show correlation matrix","41c56bc2":"# However we want to see correlation in graphical representation so below is function for that\ndef plot_corr(df, size=11):\n    corr = df.corr()\n    fig, ax = plt.subplots(figsize=(size, size))\n    ax.matshow(corr)\n    plt.xticks(range(len(corr.columns)), corr.columns)\n    plt.yticks(range(len(corr.columns)), corr.columns)","9cd1a2df":"plot_corr(df)","7e50c8c6":"sns.pairplot(df,diag_kind='kde')","1edbd81e":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Personal Loan',axis=1)     # Predictor feature columns (8 X m)\nY = df['Personal Loan']   # Predicted class (1=True, 0=False) (1 X m)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n# 1 is just any random seed number\n\nX_train.head()","3002199b":"# Checking if any column has any 0.\n(df == 0).all()","67626682":"from sklearn.linear_model import LogisticRegression\n\n#Build the logistic regression model\nlogisticRegr = LogisticRegression()\n\nlogisticRegr.fit(X_train, y_train)","5efcca17":"# Use score method to get accuracy of model\nscore = logisticRegr.score(X_test, y_test)\nprint(score)","a1231b8d":"#Predict for train set\npred_train = logisticRegr.predict(X_train)\nmat_train = confusion_matrix(y_train,pred_train)\n\nprint(\"confusion matrix = \\n\",mat_train)","0993f1ca":"#Predict for test set\npred_test = logisticRegr.predict(X_test)\n\nmat_test = confusion_matrix(y_test,pred_test)\nprint(\"confusion matrix = \\n\",mat_test)","4992b22a":"cm = metrics.confusion_matrix(y_test, pred_test, labels=[1, 0])\ncm","02ca201f":"df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","58d2cd66":"print(\"Classification Report for Logistic Regression\")\nprint(metrics.classification_report(y_test, pred_test, labels=[1, 0]))","5b5adf6c":"#AUC ROC curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nlogit_roc_auc = roc_auc_score(y_test, logisticRegr.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logisticRegr.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","eed1c8d1":"auc_score = metrics.roc_auc_score(y_test, logisticRegr.predict_proba(X_test)[:,1])\nround( float( auc_score ), 3 )","7709c3a8":"from sklearn.naive_bayes import GaussianNB # using Gaussian algorithm from Naive Bayes\n\n# create the model\nnaive_model = GaussianNB()\n\nnaive_model.fit(X_train, y_train.ravel())","e81f58cf":"#Predict for train set\nnaive_train_predict = naive_model.predict(X_train)\n\n\nprint(\"Model Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, naive_train_predict)))\nprint()","06b79091":"#Predict for test set\nnaive_test_predict = naive_model.predict(X_test)\n\nprint(\"Model Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, naive_test_predict)))\nprint()","064c59ed":"mat_test = confusion_matrix(y_test,naive_test_predict)\nprint(\"confusion matrix = \\n\",mat_test)","36ddc1ee":"print(\"Confusion Matrix for Naive Bayes\")\ncm = metrics.confusion_matrix(y_test, naive_test_predict, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","9245e2e5":"print(\"Classification Report for Naive Bayes\")\nprint(metrics.classification_report(y_test, naive_test_predict, labels=[1, 0]))","49c18c96":"from sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import zscore\n# convert the features into z scores as we do not know what units \/ scales were used and store them in new dataframe\n# It is always adviced to scale numeric attributes in models that calculate distances.\n\nXScaled  = X.apply(zscore)  # convert all attributes to Z scale \n\nXScaled.describe()","972cd347":"# Split X and y into training and test set in 75:25 ratio\n\nX_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(XScaled, Y, test_size=0.30, random_state=1)","b62ab58f":"NNH = KNeighborsClassifier(n_neighbors= 7 , weights = 'distance' )","2a95fcf3":"# Call Nearest Neighbour algorithm\n\nNNH.fit(X_train_knn, y_train_knn)","5ff2bb19":"# For every test data point, predict it's label based on 5 nearest neighbours in this model. The majority class will \n# be assigned to the test data point\n\npredicted_labels = NNH.predict(X_test_knn)\nNNH.score(X_test_knn, y_test_knn)","1bfd54dd":"mat_test = confusion_matrix(y_test_knn,predicted_labels)\nprint(\"confusion matrix for KNN = \\n\",mat_test)","9e7dd5cc":"cm = metrics.confusion_matrix(y_test_knn, predicted_labels, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","828d8bc1":"print(\"Classification Report for KNN\")\nprint(metrics.classification_report(y_test_knn, predicted_labels, labels=[1, 0]))","337a20fc":"## Build kNN Model","7e01db4b":"## Hypothesis\nPredict the likelihood of a liability customer buying personalloans.\n\nNULL Hypothesis is customer buying personalloans.\n1. **FP or Type I error** : are most dangerous as I predicted that they will buy but they end up not taking the personal loan.\n2. **FN or Type II error** : I predicted that they wont buy personal loan but they end up buying the personal loan.","5d1083c2":"## Evaluate Performance of kNN Model","af297b31":"In above plot yellow colour represents maximum correlation and blue colour represents minimum correlation.\n# We can see age and experience has a correlation.","f93bcd99":"## Logistic Regression","dcac99cd":"## Naive Bayes","790216ec":"## The confusion matrix\n\n## True Positives (TP): we correctly predicted that they may take personal loan 85\n## True Negatives (TN): we correctly predicted that they won't take personal loan  1241\n## False Positives (FP): we incorrectly predicted that they may take personal loan  (a \"Type I error\") 110 Falsely predict positive Type I error\n## False Negatives (FN): we incorrectly predicted that they won't take personal loan (a \"Type II error\") 64 . Falsely predict negative Type II error","138e29b2":"## The confusion matrix\n\n## True Positives (TP): we correctly predicted that they may take personal loan 74\n## True Negatives (TN): we correctly predicted that they won't take personal loan  1348\n## False Positives (FP): we incorrectly predicted that they may take personal loan  (a \"Type I error\") 3 Falsely predict positive Type I error\n## False Negatives (FN): we incorrectly predicted that they won't take personal loan (a \"Type II error\") 75 . Falsely predict negative Type II error\n\n","7a9a9109":"## **KNN Classification**","fba4dca0":"## Identify Correlation in data","c2e192f1":"## The confusion matrix\n## True Positives (TP): we correctly predicted that they may take personal loan 43\n## True Negatives (TN): we correctly predicted that they won't take personal loan  1318\n## False Positives (FP): we incorrectly predicted that they may take personal loan  (a \"Type I error\") 33 Falsely predict positive Type I error\n## False Negatives (FN): we incorrectly predicted that they won't take personal loan (a \"Type II error\") 106 . Falsely predict negative Type II error","d358431b":"## Spliting the data \n# We will use 70% of data for training and 30% for testing."}}