{"cell_type":{"5fe2403b":"code","08bcc293":"code","87e5c94a":"code","95f1cda6":"code","cbae870d":"code","5addd756":"code","e69af8c2":"code","56a84e9a":"code","867fb2c1":"code","729edd09":"code","d01c11ca":"code","2c94ad45":"code","b67538c3":"code","000f9330":"code","6e63818c":"code","1f11c860":"code","4d58c637":"code","2d658df1":"code","245f936a":"code","e5d7b7b5":"code","060f6e7d":"code","379128e4":"code","01ac8164":"code","3d8488dc":"code","d20fb74e":"code","318cf457":"code","9127cafc":"code","6668f086":"code","da2f97be":"code","42373400":"code","7aa62062":"code","a17243fc":"code","26af9415":"code","dc7bda38":"code","86525781":"code","2c9638a8":"code","de8e9c31":"code","ff0022db":"code","9acb0965":"code","aa791398":"markdown","9e5a0479":"markdown","4a57acf7":"markdown","25bdb207":"markdown","a2145b5d":"markdown","e07e490b":"markdown","7da9b4eb":"markdown","582aa518":"markdown","9fa6c611":"markdown","71628a40":"markdown","1887d7f4":"markdown","508511e8":"markdown","fdad5a4f":"markdown","8e331faa":"markdown","03266205":"markdown","2c0b8185":"markdown","a411cdfb":"markdown"},"source":{"5fe2403b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","08bcc293":"# Importing the libraries \nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns","87e5c94a":"\n# Importing the Boston Housing dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()\n","95f1cda6":"# Initializing the dataframe\ndata = pd.DataFrame(boston.data)","cbae870d":"# Adding feature name to the dataframe\ndata.columns = boston.feature_names","5addd756":"# the upper 5 data\ndata.head()","e69af8c2":"# the lower 5 data\ndata.tail()","56a84e9a":"data.shape","867fb2c1":"data.columns","729edd09":"data.dtypes","d01c11ca":"data.info()","2c94ad45":"data.isnull().sum()","b67538c3":"data['CRIM'].unique()","000f9330":"data['ZN'].unique()","6e63818c":"data['INDUS'].unique()","1f11c860":"data['NOX'].unique()","4d58c637":"data['RM'].unique()","2d658df1":"data['AGE'].unique()","245f936a":"data['DIS'].unique()","e5d7b7b5":"data['RAD'].unique()","060f6e7d":"data['PTRATIO'].unique()","379128e4":"data['B'].unique()","01ac8164":"data['LSTAT'].unique()","3d8488dc":"# Assign the target column\ndata['PRICE'] = boston.target ","d20fb74e":"# Shows the statistical summary\ndata.describe()","318cf457":"data.CRIM.quantile(0.999)","9127cafc":"cor=data.corr()\n#Heatmap for visualisation of correlation analysis\nplt.figure(figsize=(10,8))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\n#when we write annot= True , it shows the values .\nplt.show()","6668f086":"x=data[['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']]\ny=data['PRICE']","da2f97be":"# split data into train and test\nfrom sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts = train_test_split(x,y,test_size=0.2)\n# we have to split the data into 80% as train and 20% as test so we have specified test_size as 0.2\nprint(x.shape)\nprint(xtr.shape)\nprint(xts.shape)\nprint(y.shape)\nprint(ytr.shape)\nprint(yts.shape)","42373400":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(xtr, ytr)","7aa62062":"y_pred = regressor.predict(xts)","a17243fc":"#calculating r2score\nfrom sklearn.metrics import r2_score\nr2_score(yts,y_pred)","26af9415":"#To find the error\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(yts,y_pred)","dc7bda38":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(yts,y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","86525781":"# Import Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Create a Random Forest Regressor\nreg = RandomForestRegressor()\n\n# Train the model using the training sets \nreg.fit(xtr, ytr)","2c9638a8":"y_pred = reg.predict(xts)","de8e9c31":"r2_score(yts,y_pred)","ff0022db":"mean_squared_error(yts,y_pred)","9acb0965":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(yts,y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","aa791398":"- In this project we are given with a dataset having 506 rows and 13 attributes (features) with a target column (price). \n- The features describe a house in Boston.\n- We have to prepare a machine learning model that will predict the house price.\n- To train our machine learning model with boston housing data, we will be using scikit-learn\u2019s boston dataset.","9e5a0479":"### details of the features:\n- CRIM per capita crime rate by town \n- ZN proportion of residential land zoned for lots over 25,000 sq.ft. \n- INDUS proportion of non-retail business acres per town \n- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n- NOX nitric oxides concentration (parts per 10 million) \n- RM average number of rooms per dwelling \n- AGE proportion of owner-occupied units built prior to 1940 \n- DIS weighted distances to five Boston employment centres \n- RAD index of accessibility to radial highways \n- TAX full-value property-tax rate per 10,000usd \n- PTRATIO pupil-teacher ratio by town \n- B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n- LSTAT % lower status of the population \n\nEach record in the database describes a Boston suburb or town.","4a57acf7":"# Aanalysis of data","25bdb207":"#  Applying Random Forest Regressor algorithm","a2145b5d":"# Evaluating the model","e07e490b":"# Importing libraries","7da9b4eb":"As the 99 percentile data of the column has the value 81 so we can say that there is no incorrect entry in the dataset","582aa518":"From the above observation it is clear that there is no missing values in the data set .","9fa6c611":"# Visualisation of data","71628a40":"# Importing dataset","1887d7f4":"# Spliting the dataset","508511e8":"#  **Boston House Price Predict**","fdad5a4f":"# Applying simplelinearregression algorithm","8e331faa":"From the above analysis we can onserve that the attributes are having a good correlation value with each other .\nHence there exist some linear relation among the attributes so we can apply linear regression in this case. ","03266205":"so we have applied two algorithem one is multiple linear regression and the other is random forest regressor algorithm .\nIncase of multiple linear regression we got 76% accuracy and in case of random forest the accuracy is 91% . \nthe performance of second model is good so we can use this model to predict the price of the house .","2c0b8185":"From the above analysis we can observe that 75% of CRIM values are below 3.677083 but the max value is 88.976200 , so there nay be some wrong entry exist in the dataset","a411cdfb":"# Evaluating the model"}}