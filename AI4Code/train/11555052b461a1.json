{"cell_type":{"aeafe730":"code","d69e0890":"code","551934bf":"code","5f7de9aa":"code","359502d9":"code","c1ad37c0":"code","7ae4179d":"code","0fcb5843":"code","5e7d21cb":"code","09c94452":"code","0ebf0d17":"code","f1d32c0e":"code","e2d9b416":"code","574fdffe":"code","9fb04a95":"code","340b17e9":"code","b880cb82":"code","bcceb7f2":"markdown","a04758d9":"markdown","21edf17e":"markdown","c219ef5a":"markdown","d9c182cf":"markdown","f7ea0a3f":"markdown","9ae2e029":"markdown","8bd3b986":"markdown"},"source":{"aeafe730":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d69e0890":"train = pd.read_json('..\/input\/persianslang\/data.json', encoding='utf8')\ntrain.head()","551934bf":"train.isnull().sum()","5f7de9aa":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'green',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(train[\"words\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Persian Slang\")\nplt.show()","359502d9":"!pip install arabic_reshaper\n!pip install python-bidi\n!pip install requests","c1ad37c0":" !pip install ar_wordcloud","7ae4179d":"import codecs\nfrom wordcloud import WordCloud\nfrom bidi.algorithm import get_display\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport arabic_reshaper # this was missing in your code\n\nfrom collections import Counter\n\nfrom wordcloud import WordCloud          # pip install wordcloud\nimport matplotlib.pyplot as plt          \n# -- Arabic text dependencies\nfrom arabic_reshaper import reshape      # pip install arabic-reshaper\nfrom bidi.algorithm import get_display   # pip install python-bidi\n\ntext = \" \".join(str(each) for each in train.words)\n\nrtl = lambda w: get_display(reshape(f'{w}'))\n\nCOUNTS = Counter(\"'\u0645\u062a\u0631\u0627\u062f\u0641\u0647\u0627'\u0646\u062e \u062f\u0627\u062f\u0646 \u060c\u0631\u0627\u0647 \u062f\u0627\u062f\u0646\".split())\ncounts = {rtl(k):v for k, v in COUNTS.most_common(10)}\n\nurl= 'https:\/\/www.google.com\/get\/noto\/#naskh-arab'\n\nfont_file = '.\/NotoNaskhArabic-Regular.ttf' # download from: https:\/\/www.google.com\/get\/noto\nwordcloud = WordCloud(font_path=font_file).generate_from_frequencies(counts)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","0fcb5843":"!pip install wordcloud-fa","5e7d21cb":"from wordcloud_fa import WordCloudFa","09c94452":"wordcloud = WordCloudFa()","0ebf0d17":"wordcloud = WordCloudFa(persian_normalize=True)","f1d32c0e":"wordcloud = WordCloudFa(include_numbers=False)","e2d9b416":"wordcloud = WordCloudFa(no_reshape=True)","574fdffe":"wordcloud = WordCloudFa(persian_normalize=True)\nwc = wordcloud.generate(text)\nimage = wc.to_image()\nimage.show()\nimage.save('wordcloud.png')\nplt.show()","9fb04a95":"wordcloud = WordCloudFa()\nfrequencies = wordcloud.process_text(text)\nwc = wordcloud.generate_from_frequencies(frequencies)","340b17e9":"stop_words = set(['\u06a9\u0644\u0645\u0647\u200c\u06cc \u0627\u0648\u0644', '\u06a9\u0644\u0645\u0647\u200c\u06cc \u062f\u0648\u0645'])\nwc = WordCloudFa(stopwords=stop_words)\nplt.show()","b880cb82":"wc = WordCloudFa()\nwc.add_stop_words(['\u06a9\u0644\u0645\u0647\u200c\u06cc \u0627\u0648\u0644', '\u06a9\u0644\u0645\u0647\u200c\u06cc \u062f\u0648\u0645'])\nplt.show()","bcceb7f2":"#Codes by https:\/\/pypi.org\/project\/wordcloud-fa\/","a04758d9":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT2lMWOUKtpxulKPp5Ra9jZYP_1KPG-lUlNrA&usqp=CAU)youtube.com","21edf17e":"#Working with Stopwords","c219ef5a":"#Generating Word Cloud from Frequencies\n\nI don't even know what is Frequency to a WordCloud.","d9c182cf":"Since we have only one column I've no clue about what to perform. I tried yo add label though it doesn't work.","f7ea0a3f":"\"If you want to add additional words to the default stopwords, you can simply call add_stop_words method on your instance of WordCloudFa and pass an iterable type (list, set, ...) into it.\"","9ae2e029":"#Generating Word Cloud from Text","8bd3b986":"Till now I don't know how to make a WordCloud with those characters, which tff font to apply? Cannot open Resource."}}