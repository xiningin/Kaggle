{"cell_type":{"74de9615":"code","699c2767":"code","e1b7bf6c":"code","927ca518":"code","8e6f6396":"code","93f21ad3":"code","1c616868":"code","566f91f3":"code","6d0c6934":"code","93d9910e":"code","ca0a81c4":"code","4fe8bd9a":"code","d0c71c31":"markdown","b05c9388":"markdown","9a7ce740":"markdown","266e4190":"markdown","badfe219":"markdown","f7b3cdd2":"markdown","b4d13f60":"markdown","aef0dca9":"markdown"},"source":{"74de9615":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import mutual_info_classif, VarianceThreshold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVC\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","699c2767":"def get_data(target_name='target'):\n    \"\"\"\n    Gets the training data and extracts the target. \n    \n    Returns:\n        train (pd.DataFrame): training data.\n        target (np.ndarray): target values, binary\n    \"\"\"\n    train = pd.read_csv(\"..\/input\/train.csv\")\n    test = pd.read_csv(\"..\/input\/test.csv\")\n    try:\n        target = train[target_name]\n        train.drop(target_name, axis=1, inplace=True)\n    except KeyError:\n        # no column named target_name, find binary column\n        for key in train.columns:\n            x = train[key].values\n            if np.array_equal(x, x.astype(bool)):\n                target_name = key\n        target = train[target_name]\n        train.drop(target_name, axis=1, inplace=True)\n    print('The column used as target is : {}'.format(target_name))\n    return train, test, target","e1b7bf6c":"train, test, target = get_data()","927ca518":"wheezy_value = 65\n\ntrain_wheezy = train.loc[train['wheezy-copper-turtle-magic']==wheezy_value,:]\ntarget_wheezy = target[train_wheezy.index].values\ntrain_wheezy.drop(['id', 'wheezy-copper-turtle-magic'], inplace=True, axis=1)","8e6f6396":"mi = mutual_info_classif(train_wheezy.values, target_wheezy, discrete_features=False)\n\nfeature_stds = train_wheezy.std().values\n\nplt.plot(mi[feature_stds>1.5], label='high variance features')\nplt.plot(mi[feature_stds<1.5], label='low variance features')\nplt.legend()","93f21ad3":"# select high variance features\ntrain_wheezy_reduced = VarianceThreshold(1.5).fit_transform(train_wheezy)\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)","1c616868":"print('Validation: {0:.3f} +\/- {1:.3f}'.format(np.mean(val_scores), np.std(val_scores)))\nprint('Train: {0:.3f} +\/- {1:.3f}'.format(np.mean(train_scores), np.std(train_scores)))","566f91f3":"# select low variance features\nVT =  VarianceThreshold(1.5)\ntrain_wheezy_reduced = VT.fit_transform(train_wheezy)\ncolumns = train_wheezy.columns.values[VT.variances_<1.5]\ntrain_wheezy_reduced = train_wheezy[columns].values\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)","6d0c6934":"print('Validation: {0:.3f} +\/- {1:.3f}'.format(np.mean(val_scores),np.std(val_scores)))\nprint('Train: {0:.3f} +\/- {1:.3f}'.format(np.mean(train_scores),np.std(train_scores)))","93d9910e":"# select low variance features\nmi = mutual_info_classif(train_wheezy.values, target_wheezy)\ncolumns = train_wheezy.columns.values[mi>0.0475]\ntrain_wheezy_reduced = train_wheezy[columns].values\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\n\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)","ca0a81c4":"print('Validation: {0:.3f} +\/- {1:.3f}'.format(np.mean(val_scores),np.std(val_scores)))\nprint('Train: {0:.3f} +\/- {1:.3f}'.format(np.mean(train_scores),np.std(train_scores)))","4fe8bd9a":"high_variance_features = train_wheezy.columns.values[VT.variances_>1.5][9:12]\nlow_variance_features = train_wheezy.columns.values[VT.variances_<1.5][:3]\n\nfeatures_to_plot = np.append(high_variance_features, low_variance_features)\n\nsns.pairplot(train_wheezy[features_to_plot])","d0c71c31":"# Look at the low variance features - are they useless?\n\nAs pointed out by Chris Deotte, the features for each value of wheezy-copper-turtle-magic have either a 'high' or 'low' variance. Chris suggested that the low variance features were not useful predictors of the target.\n\nAnother [kernel](https:\/\/www.kaggle.com\/mhviraf\/there-is-predictive-power-in-the-useless-columns) also questioned if they were useful. \n\nChris also [demonstrated](https:\/\/www.kaggle.com\/c\/instant-gratification\/discussion\/93379) the curse of dimensionality, and how it can lead to seperability, even for random noise.\n\nI wanted to do a quick check of if the low-variance features were indeed useless. I thought I might as well share the kernel. I just fitted a quick NuSVC using three different feature selection methods.\n\n\n**Summary:** Assuming the features are independent, it does not appear the low-variance features contain any useful predictors of the target. This agrees with all previous work.","b05c9388":"# Conclusions\n\nLooking at the three models we have constructed it does seem to strongly support the hypothesis that the low variance features hold no predictive power. \n\nIt seems, therefore, that a variance based thresholding is an essential first feature selection step.\n\n\nQuestions to answer:\n - Could they hold information in a way I am not sensitive to in this kernel? I.e., could you have features which appear random, but are not lineraly independent and when combined contain predictors of the target?","9a7ce740":"## Fit a basic model using different feature sets","266e4190":"#### Is there any 'talk' between the low and high variance features.\n\nAnother thing to check is if there is any interaction between the low and high variance features. \n\nWe can use a pairplot to begin to look into this. \n\n\nThis quick plot doesn't indicate any strong interactions.","badfe219":"#### Using mutual information\n\nWe will remove features with a low mutual information.","f7b3cdd2":"### Mutual information\n\nSome of the 'low variance features' have a relatively high mutual information. So it is worth investigating further if they contain any predictive power.\n\nI don't understand why the Mutual information does not appear to be a useful measure of feature importance in this case.","b4d13f60":"#### Using low-variance features\n\nNow we will test using the low variance features.","aef0dca9":"#### Using the method suggested by Chris as a baseline:\n- Removing the low variance features"}}