{"cell_type":{"e3715ef6":"code","a3efeb0b":"code","719fc8f7":"code","5d9fe2f1":"code","3839195d":"code","b28279cf":"code","c569ffd9":"code","b84c87de":"markdown","751c4e0a":"markdown","6fe61727":"markdown","e7c14172":"markdown","a0524d0a":"markdown"},"source":{"e3715ef6":"# Load packages\nimport numpy as np \nimport pandas as pd\nimport os\n\n# Big query helpers\nfrom google.cloud import bigquery\nfrom bq_helper import BigQueryHelper\n\n# Import plotting libaries\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.io as pio\n\n# Need this so we can use Plotly in offline mode\n# This will allow the maps we make to show up in this notebook\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()","a3efeb0b":"# Set up query helpers\nbq_assistant = BigQueryHelper(\"bigquery-public-data\", \"epa_historical_air_quality\")\npollutants = ['o3','co','no2','so2','pm25_frm']","719fc8f7":"# This code block based on Air Pollution 101 kernel by Mohammed Jabri\npollutant_year = \"\"\"\n    SELECT\n        pollutant.county_name AS county, AVG(pollutant.aqi) AS AvgAQI_pollutant,\n        pollutant.state_code, pollutant.county_code\n    FROM\n      `bigquery-public-data.epa_historical_air_quality.pollutant_daily_summary` as pollutant\n    WHERE\n      pollutant.poc = 1\n      AND EXTRACT(YEAR FROM pollutant.date_local) = 2016\n    GROUP BY \n      pollutant.state_code, pollutant.county_code, pollutant.county_name\n\"\"\"","5d9fe2f1":"# Initialize the data-frame for 2016\ndf_2016 = pd.DataFrame()\n\n# Now loop through the pollutants list we already have\nfor elem_g in pollutants : \n    \n    # Replaces the word 'pollutant' in the query with the actual pollutant's name\n    query = pollutant_year.replace(\"pollutant\", elem_g)\n    \n    # Runs the query and transforms it to a pandas data-frame \n    # Create a joined up FIPS code that uniquely identifies counties\n    # Set the index \n    temp = bq_assistant.query_to_pandas(query)\n    temp['location_code'] = temp['state_code'] + temp['county_code']\n    temp.set_index('location_code') \n    \n    # Concatenate the tables of the different pollutants together \n    # Fill in the missing values with the mean of the column\n    if elem_g == 'o3': \n        df_2016 = temp \n    \n    # Merge on location code\n    else:\n        temp.drop(['state_code', 'county_code', 'county'], inplace = True, axis = 1)\n        df_2016 = pd.merge(df_2016, temp, how = 'outer', on = ['location_code'],\n                          indicator = elem_g + '_merge')\n\n# Randomly pick 10 counties to take a look at the data\ndf_2016.sample(10,random_state = 42)","3839195d":"# Fill in the numeric missing values \nfor column in df_2016.columns: \n    if df_2016[column].dtype in ['float64', 'int64']: \n        df_2016[column].fillna(df_2016[column].mean(), inplace = True)\n\n# Randomly pick 10 counties to take a look at the data\ndf_2016.sample(10,random_state = 42)","b28279cf":"def make_plot(pollutant, plot_labels, color_scale):\n    '''This code makes the choloropleth map.'''\n\n    # Store the location codes (also called FIPS codes)\n    fips = df_2016['location_code'].tolist()\n    values = df_2016['AvgAQI_' + pollutant].tolist()\n    \n    # Store the end-points \n    endpts = list(np.linspace(min(values), max(values), len(color_scale) - 1))\n\n    # Create the choloropleth map\n    fig = ff.create_choropleth(\n        fips = fips, values = values, scope = ['usa'],\n        binning_endpoints = endpts, colorscale = color_scale,\n        show_state_data = False,\n        show_hover = True, centroid_marker = {'opacity': 0},\n        asp = 2.9, title = 'USA by Average ' + plot_labels[pollutant]['title'],\n        legend_title = 'Avg. ' + plot_labels[pollutant]['title']\n    )\n\n    # Show the chloropleth map\n    iplot(fig, filename = 'choropleth_full_usa')\n    \n    return","c569ffd9":"# Run the code\nif __name__ == '__main__':\n\n    # Store the labels dictionary \n    plot_labels = {'o3': {'title': 'O3'}, 'co': {'title': 'CO'}, \n                   'pm25_frm': {'title': 'PM 2.5'}, 'no2': {'title': 'NO2'}, \n                  'so2': {'title': 'SO2'}} \n\n    # Store the color-scale\n    color_scale = [\"#f7fbff\",\"#ebf3fb\",\"#deebf7\",\"#d2e3f3\",\"#c6dbef\",\"#b3d2e9\",\"#9ecae1\",\n                  \"#85bcdb\",\"#6baed6\",\"#57a0ce\",\"#4292c6\",\"#3082be\",\"#2171b5\",\"#1361a9\",\n                  \"#08519c\",\"#0b4083\",\"#08306b\"]\n    \n    # Make the plot for each pollutant\n    for pollutant in pollutants:\n        make_plot(pollutant, plot_labels, color_scale)","b84c87de":"## Missing values \n\nThe data we have seems fine. There is one catch: there are counties in the data-set where certain pollutants were not measured in 2016. For example, the Avg. AQI index value for Hendricks county is missing in the random sample that we have drawn above. We need to deal with these missing values in some way. The code block below fills in these missing values with the average value for that column.","751c4e0a":"# Mapping Air Quality Over Time in the United States\n\n## Introduction\nThe historical air quality data-set placed on Kaggle by the USDA is a great chance to use BigQuery and and create interesting and cool data visualizations with the plotly library's features. This notebook creates a choloropleth map of the US for the different pollutants in the air quality data-set observed by county.  The SQL queries are heavily based on the Air Pollution 101 Kernel by Mohammed Jabri.","6fe61727":"## Creating the maps! \nThe code below calls the Plotly API to create a choloropleth map for each pollutant at the county level for the USA. The high number of missing values in each plot are surprising. It would be interesting to predict these from the existing data.","e7c14172":"## SQL queries\n\nNow that we have set up the environment, we can write the SQL queries that will get the data we need. To make the choloropleth map, we need 1) the air pollution AQI summaries by county and 2) the FIPS or location codes of each state and county. ","a0524d0a":"## Data preparation \n\nWe are now ready to run the SQL query.  We want to get the data from the daily summary table for each pollutant and each county. We could do the join in SQL using 'JOIN' commands but this will take a long time. Instead of doing this, we can run the queries for each pollutant and then merge the results in pandas. \n\nThe merge in the code block below is an outer join because we want all the possible data that exists for each county. Just because a county does not have measurements for a particular pollutant does not mean that we want to discard all that county's data completely. We still want to retain whatever information exists. "}}