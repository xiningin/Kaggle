{"cell_type":{"d99ba688":"code","7d6016fc":"code","49a6d60c":"code","a4b5d66a":"code","ea541c77":"code","2c243dde":"code","6f329c7b":"code","f4541e83":"code","332965f0":"code","e2439899":"code","02321f95":"code","2f4f8ce7":"code","6f3af1f0":"code","81d81148":"code","60396b25":"code","cdee798c":"code","87e72552":"code","eb87d220":"code","84b11a4c":"code","b9d2ec98":"code","c48dc782":"code","c5a7f0ea":"code","ecc7d867":"code","182f3f4f":"code","12de3bf5":"code","1abd717e":"code","2b8a8495":"code","bbde2204":"code","d9bc6ebd":"code","2a9258fd":"code","6c25f683":"code","fb364d20":"code","9f2aa104":"code","fc1c2268":"code","6881011b":"code","2771c174":"code","bed27ea1":"code","480bf6b8":"code","17cc0252":"code","ab4e2b40":"code","b4395757":"code","65b37226":"code","38c392fe":"code","a00279b6":"code","31db25c8":"code","a9e2c378":"code","e3ad9eeb":"code","145743a2":"code","e69715d8":"code","acae835d":"code","d79efe1d":"code","8f0fb92b":"code","a6455a18":"code","cab0875b":"code","893c0009":"code","cc230959":"code","ae6f4ae4":"code","15b8a8ae":"code","d5f6b183":"code","2157ec6e":"code","6163b0b0":"code","19730fbd":"code","077467fa":"code","0938808e":"code","8af7f133":"code","0459f83f":"code","b99f7c5c":"code","f8c14b31":"code","a0abd89d":"markdown","bfb86d76":"markdown","0c6c7a79":"markdown","990a4f5d":"markdown","e8e52278":"markdown","a9d12284":"markdown","c8925982":"markdown","a3608de5":"markdown","11079e08":"markdown","1ffc6e86":"markdown","0818afb6":"markdown","638a1e9e":"markdown","cd1f126a":"markdown","41eedf74":"markdown","01d3d5f5":"markdown","aaed251e":"markdown","9332e4e7":"markdown","9c57b9c5":"markdown","ecf9b99a":"markdown","99b9791b":"markdown","c4cb6aac":"markdown","276a25b9":"markdown","c1c6702c":"markdown","298149fc":"markdown","a30fd9b2":"markdown","0c1e0662":"markdown","6899ffd0":"markdown","4609ab13":"markdown","246df68e":"markdown","95c34e58":"markdown","b26921e1":"markdown","750297d1":"markdown","5584184d":"markdown","b174faa2":"markdown","579cb399":"markdown","56ae711a":"markdown","8bc8f619":"markdown","2e5f839d":"markdown","ea5a3f74":"markdown","774f3905":"markdown","4500847f":"markdown","5e55acb8":"markdown","080c5020":"markdown","a6e35ed0":"markdown","a7d2f8bc":"markdown","5b40d027":"markdown","957cac6f":"markdown","bc55cb08":"markdown","9d026212":"markdown","02289dac":"markdown","23cbf5b8":"markdown","ec6aeaae":"markdown","bcf96540":"markdown","7bdb82cb":"markdown","296f29b4":"markdown","14f81c9b":"markdown"},"source":{"d99ba688":"!pip install split-folders","7d6016fc":"# Third party\nfrom keras.applications import VGG16, Xception, InceptionResNetV2,DenseNet201, NASNetLarge\nfrom tensorflow.python.keras.applications.efficientnet import EfficientNetB7\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, AveragePooling2D, GaussianNoise \nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport numpy as np\nimport tensorflow as tf\nimport random as python_random\nimport splitfolders\n\n# Local application\nimport miner_a_de_datos_redes_neuronales_utilidad as utils","49a6d60c":"device_type = \"GPU\"\n\nutils.check_physical_devices(device_type)","a4b5d66a":"seed = 27912","ea541c77":"ratio = (0.8, 0.2)\ngroup_prefix = None\ninput_folder = \"..\/input\/recognition-2020\/train\"\noutput_folder = \"..\/new_input\/recognition-2020\"","2c243dde":"splitfolders.ratio(input_folder, output=output_folder, seed=seed, ratio=(0.8, 0.2), group_prefix=group_prefix) ","6f329c7b":"rescale = 1 \/ 255","f4541e83":"width_shift_range= 0.1\nheight_shift_range= 0.1\nbrightness_range= [0.9, 1.1]\nshear_range= 0.1\nzoom_range= 0.1\n\n\ntrain_generator1 = ImageDataGenerator(rescale=rescale)\n\ntrain_generator2 = ImageDataGenerator(rescale=rescale,\n                                     zoom_range=zoom_range,\n                                     shear_range=shear_range,\n                                     width_shift_range=width_shift_range,\n                                     height_shift_range=height_shift_range,\n                                     #brightness_range=brightness_range\n                                     )","332965f0":"validation_generator = ImageDataGenerator(rescale=rescale)","e2439899":"test_generator = ImageDataGenerator(rescale=rescale)","02321f95":"batch_size = 64\ntarget_size = (128, 128)","2f4f8ce7":"directory = \"..\/new_input\/recognition-2020\/train\"\n\ntrain_iterator1 = train_generator1.flow_from_directory(seed=seed,\n                                                     directory=directory,\n                                                     batch_size=batch_size,\n                                                     target_size=target_size)\n\ntrain_iterator2 = train_generator2.flow_from_directory(seed=seed,\n                                                     directory=directory,\n                                                     batch_size=batch_size,\n                                                     target_size=target_size)","6f3af1f0":"directory = \"..\/new_input\/recognition-2020\/val\"\n\nvalidation_iterator = validation_generator.flow_from_directory(seed=seed,\n                                                               directory=directory,\n                                                               batch_size=batch_size,\n                                                               target_size=target_size)\n","81d81148":"directory = \"..\/input\/recognition-2020\/test\"\nshuffle = False\n\ntest_iterator = test_generator.flow_from_directory(seed=seed,\n                                                   shuffle=shuffle,\n                                                   directory=directory,\n                                                   batch_size=batch_size,\n                                                   target_size=target_size)","60396b25":"data_format = \"channels_last\"\ninput_shape = (*target_size, 3)","cdee798c":"flatten_layer = Flatten(data_format=data_format, input_shape=input_shape)","87e72552":"activation = \"relu\"\n\nhidden_layer_1 = Dense(256, activation=activation)\nhidden_layer_2 = Dense(256, activation=activation)\nhidden_layer_3 = Dense(128, activation=activation)\nhidden_layer_4 = Dense(128, activation=activation)\nhidden_layer_5 = Dense(64, activation=activation)\nhidden_layer_6 = Dense(32, activation=activation)\nhidden_layer_7 = Dense(32, activation=activation)","eb87d220":"dropout_layer_1 = Dropout(0.25)\ndropout_layer_2 = Dropout(0.25)\ndropout_layer_3 = Dropout(0.25)\ndropout_layer_4 = Dropout(0.15)\ndropout_layer_5 = Dropout(0.15)\ndropout_layer_6 = Dropout(0.15)","84b11a4c":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)","b9d2ec98":"neural_network_model = utils.group_layers(flatten_layer,\n                                          hidden_layer_1,                                          \n                                          dropout_layer_1,\n                                          hidden_layer_2,\n                                          dropout_layer_2,\n                                          hidden_layer_3,\n                                          dropout_layer_3,\n                                          hidden_layer_4,\n                                          dropout_layer_4,\n                                          hidden_layer_5,\n                                          dropout_layer_5,\n                                          hidden_layer_6,\n                                          dropout_layer_6,\n                                          hidden_layer_7,\n                                          output_layer)","c48dc782":"line_length = 79","c5a7f0ea":"neural_network_model.summary(line_length)","ecc7d867":"lr = 1e-3","182f3f4f":"model = neural_network_model\n\nutils.compile_model(model, lr)","12de3bf5":"activation = \"relu\"\n\nconvolutional_layer_1 = GaussianNoise(0.2,input_shape=input_shape)","1abd717e":"convolutional_layer_2 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_3 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_4 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_5 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_6 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_7 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_8 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_9 = Conv2D(128, 3, activation=activation)\nconvolutional_layer_10 = Conv2D(128, 3, activation=activation)\nconvolutional_layer_11 = Conv2D(256, 3, activation=activation)\nconvolutional_layer_12 = Conv2D(256, 3, activation=activation)\nconvolutional_layer_13 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_14 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_15 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_16 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_17 = Conv2D(64, 3, activation=activation)","2b8a8495":"max_pooling_layer_1 = MaxPooling2D(2)\nmax_pooling_layer_2 = MaxPooling2D(2)\nmax_pooling_layer_3 = MaxPooling2D(2)\nmax_pooling_layer_4 = MaxPooling2D(2)\nmax_pooling_layer_5 = MaxPooling2D(2)","bbde2204":"dropout_layer_1 = Dropout(0.25)\ndropout_layer_2 = Dropout(0.25)\ndropout_layer_3 = Dropout(0.15)\ndropout_layer_4 = Dropout(0.15)\n","d9bc6ebd":"#capa de aplanamiento\nflatten_layer = Flatten(data_format=data_format)","2a9258fd":"hidden_layer_1 = Dense(512, activation=activation)\nhidden_layer_2 = Dense(256, activation=activation)\nhidden_layer_3 = Dense(128, activation=activation)","6c25f683":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)","fb364d20":"convolutional_neural_network_model = utils.group_layers(convolutional_layer_1,\n                                                        convolutional_layer_2,  \n                                                        max_pooling_layer_1,\n                                                        \n                                                        convolutional_layer_4,\n                                                        convolutional_layer_5,\n                                                        max_pooling_layer_2,\n                                                        \n                                                        convolutional_layer_9,\n                                                        convolutional_layer_10, \n                                                        max_pooling_layer_3,\n                                                        \n                                                        convolutional_layer_11,\n                                                        convolutional_layer_12, \n                                                        max_pooling_layer_4,\n                                                        \n                                                        flatten_layer,\n                                                        hidden_layer_1,                                                      \n                                                        dropout_layer_1,\n                                                        hidden_layer_2,\n                                                        dropout_layer_3,\n                                                        output_layer)","9f2aa104":"convolutional_neural_network_model.summary(line_length)","fc1c2268":"model = convolutional_neural_network_model\n\nutils.compile_model(model, lr)","6881011b":"weights = \"imagenet\"\ninclude_top = False\n\n#vgg16_model = VGG16(weights=weights, include_top=include_top, input_shape=input_shape)\n#vgg16_model = Xception(weights=weights, include_top=include_top, input_shape=input_shape)\nvgg16_model = InceptionResNetV2(weights=weights, include_top=include_top, input_shape=input_shape)\n#vgg16_model = DenseNet201(weights=weights, include_top=include_top, input_shape=input_shape)\n#vgg16_model = EfficientNetB7(weights=weights, include_top=include_top, input_shape=input_shape)","2771c174":"model = vgg16_model\n\nutils.freeze_layers(model)","bed27ea1":"last_layer = vgg16_model.output","480bf6b8":"flatten_layer = Flatten(data_format=data_format)(last_layer)","17cc0252":"activation = \"relu\"\n\nhidden_layer_1 = Dense(256, activation=activation)(flatten_layer)\ndrop_out_layer_1 = Dropout(0.25)(hidden_layer_1)\nhidden_layer_2 = Dense(128, activation=activation)(drop_out_layer_1)\ndrop_out_layer_2 = Dropout(0.25)(hidden_layer_2)\nhidden_layer_3 = Dense(64, activation=activation)(drop_out_layer_2)\ndrop_out_layer_3 = Dropout(0.15)(hidden_layer_3)\nhidden_layer_3 = Dense(32, activation=activation)(drop_out_layer_3)\ndrop_out_layer_3 = Dropout(0.15)(hidden_layer_3)","ab4e2b40":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)(drop_out_layer_3)","b4395757":"input_layer = vgg16_model.input","65b37226":"transfer_learning_model = Model(inputs=input_layer, outputs=output_layer)","38c392fe":"transfer_learning_model.summary(line_length)","a00279b6":"model = transfer_learning_model\n\nutils.compile_model(model, lr)","31db25c8":"my_callbacks1 = [\n    EarlyStopping(patience=3, monitor=\"val_loss\", restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.0001),\n]","a9e2c378":"model = neural_network_model\n\nneural_network_history = model.fit_generator(epochs=40,\n                                             generator=train_iterator1,\n                                             callbacks=my_callbacks1,\n                                             validation_data=validation_iterator)","e3ad9eeb":"history = neural_network_history\n\nutils.plot_history(history)","145743a2":"model = convolutional_neural_network_model\n\nconvolutional_neural_network_history = model.fit_generator(epochs=20,\n                                                           generator=train_iterator2,\n                                                           callbacks=my_callbacks1,\n                                                           validation_data=validation_iterator)","e69715d8":"history = convolutional_neural_network_history\n\nutils.plot_history(history)","acae835d":"model = transfer_learning_model\n\ntransfer_learning_history = model.fit_generator(epochs=10,\n                                                generator=train_iterator2,\n                                                callbacks=my_callbacks1,\n                                                validation_data=validation_iterator)","d79efe1d":"history = transfer_learning_history\n\nutils.plot_history(history)","8f0fb92b":"generator = test_iterator","a6455a18":"model = neural_network_model\nneural_network_predictions = utils.predict(model, generator)","cab0875b":"model = convolutional_neural_network_model\nconvolutional_neural_network_predictions = utils.predict(model, generator)","893c0009":"model = transfer_learning_model\ntransfer_learning_predictions = utils.predict(model, generator)","cc230959":"predictions = neural_network_predictions\n\nneural_network_submission = utils.create_submission(predictions)","ae6f4ae4":"predictions = convolutional_neural_network_predictions\n\nconvolutional_neural_network_submission = utils.create_submission(predictions)","15b8a8ae":"predictions = transfer_learning_predictions\n\ntransfer_learning_submission = utils.create_submission(predictions)","d5f6b183":"random_state = seed","2157ec6e":"neural_network_submission.sample(5, random_state=random_state)","6163b0b0":"convolutional_neural_network_submission.sample(5, random_state=random_state)","19730fbd":"transfer_learning_submission.sample(5, random_state=random_state)","077467fa":"path_or_buf = \"neural_network_submission.csv\"\n\nneural_network_submission.to_csv(path_or_buf)","0938808e":"path_or_buf = \"convolutional_neural_network_submission.csv\"\n\nconvolutional_neural_network_submission.to_csv(path_or_buf)","8af7f133":"path_or_buf = \"transfer_learning_submission.csv\"\n\ntransfer_learning_submission.to_csv(path_or_buf)","0459f83f":"filepath = \"neural_network_model.h5\"\n\nneural_network_model.save(filepath)","b99f7c5c":"filepath = \"convolutional_neural_network_model.h5\"\n\nconvolutional_neural_network_model.save(filepath)","f8c14b31":"filepath = \"transfer_learning_model.h5\"\n\ntransfer_learning_model.save(filepath)","a0abd89d":"Primeramente destacar que, aunque consigamos buenos scores en el `val_accuracy`, esto no significa mucho, debemos buscar no sobreajustar en las gr\u00e1ficas y luego probarlo en la competici\u00f3n, ya que nosotros obten\u00edamos muy buenos `val_accuracy` pero en la competici\u00f3n nuestros modelos no consegu\u00edan ni el rendimiento m\u00ednimo esperado en este tipo de redes, todo debido al aumento de datos, que no se plasmaban en los scores.\n\nA partir de esto tuvimos que establecer una nueva red pero b\u00e1sicamente fue la misma, hemos llegado a varias conclusiones:\n\n1. Es muy recomendable usar poolings despu\u00e9s de las capas convolucionales\n2. Los mejores scores los hemos conseguido de con un m\u00e1ximo de 2 convolucionales juntas y una capa pooling despu\u00e9s\n3. El m\u00e1ximo conjunto de 2 convolucionales + pooling es 4, esto se debe al tama\u00f1o de los datos\n4. Capas totalmente conectadas utilizamos 2, con 2 consegu\u00edamos mejores scores que con 1 o 3, junto con sus respectivos dropouts\n\nCon esta configuraci\u00f3n acabamos mejorando los valores obtenidos que sin utilizar el ampliamiento de datos, luego tambi\u00e9n comentar que los valores y los par\u00e1metros escogidos en el principio para el ampliamiento de datos, han sido comparados y comprobados, comprobando que con modificarlos muy poco es donde obtenemos mejores predicciones.","bfb86d76":"**Capa de salida**","0c6c7a79":"**Capas pooling**","990a4f5d":"## 2.2 Generadores","e8e52278":"## 2.3 Iteradores","a9d12284":"Declaramos la semilla","c8925982":"**Fijamos las capas del modelo escogido como no entrenables para evitar modificar pesos**","a3608de5":"**test_generator**","11079e08":"Finalmente descartamos el brillo. Al ser im\u00e1genes en blanco y negro, jugar con el brillo m\u00e1s que ayudarnos nos empeora y tras las pruebas lo acabamos descubriendo y descartando.","1ffc6e86":"**Capa de salida**","0818afb6":"## 3.1. Redes neuronales","638a1e9e":"A pesar de que esta es la peor para este tipo de problemas, hemos querido trabajar diferentes opciones, y b\u00e1sicamente al obtener un buen score tanto aqu\u00ed como en la competici\u00f3n, nos hemos quedado con la cofiguraci\u00f3n siguiente:\n\n1. Flatten inicial\n2. **Dense 256 neuronas**\n3. Dropout 0.25\n4. **Dense 256 neuronas**\n5. Dropout 0.25\n6. **Dense 128 neuronas**\n7. Dropout 0.25\n8. **Dense 128 neuronas**\n9. Dropout 0.15\n10. **Dense 64 neuronas**\n11. Dropout 0.15\n12. **Dense 32 neuronas**\n13. Dropout 0.15\n14. **Dense 32 neuronas**\n15. Output final\n\nDonde observamos que la propagaci\u00f3n funciona mejor, de m\u00e1s neuronas a menos, junto con capas dropout entre medias para bajar el sobreajuste (donde importante no subir los dropout, al menos en nuestros casos, m\u00e1s del 0.5 porque acaba siendo inneficiente). Conforme reducimos estas neuronas tambi\u00e9n reducimos el dropout para aumentar algo m\u00e1s la contribuci\u00f3n de estas \u00faltimas capas en el modelo.","cd1f126a":"**Patr\u00f3n de recomendaci\u00f3n del profesor**\n\n1. `M` secuencias de una capa convolucional + *ReLU* + *pooling* (opcional).\n2. `K` secuencias de una capa completamente conectada + *ReLU*.\n3. Capa completamente conectada.\n\nCon `M > 0` y `K >= 0 & K < 3`.\n\n**Dise\u00f1o**\n\n* Capa GaussianNoise\n* **Capa convolucional** (con 32 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* Capa MaxPooling (con tama\u00f1o de filtro de 2) \n\n* **Capa convolucional** (con 64 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* **Capa convolucional** (con 64 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* Capa MaxPooling (con tama\u00f1o de filtro de 2) \n\n* **Capa convolucional** (con 128 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* **Capa convolucional** (con 128 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* Capa MaxPooling (con tama\u00f1o de filtro de 2) \n\n* **Capa convolucional** (con 256 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* **Capa convolucional** (con 256 filtros y un tama\u00f1o de filtro de 3) + *ReLU* \n* Capa MaxPooling (con tama\u00f1o de filtro de 2) \n\n* Capa Flatten\n* *Capa Dense 512 neuronas*\n* Capa Dropout 0.25\n* *Capa Dense 256 neuronas*\n* Capa Dropout 0.15\n* Output final","41eedf74":"En nuestro caso utilizamos un aumento de datos, para que nuestras redes sepan entrenar en caso de tratar im\u00e1genes con ruido, los par\u00e1metros utilizados:\n* width_shift_range: desplaza la imagen horizontalmente\n* height_shift_range: desplaza la imagen verticalmente\n* brightness_range: aumenta o disminuye el brillo\n* shear_range: inclina la imagen\n* zoom_range: amplia o aleja la foto","01d3d5f5":"# Pr\u00e1ctica 3: Redes neuronales (*Deep Learning*)\n\n####\u00a0Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jim\u00e9nez\n* Jos\u00e9 Antonio G\u00e1mez Mart\u00edn\n\n### Alumnado:\n\n* Alejandro G\u00f3mez Escribano\n* Mykola Mandzyak","aaed251e":"**Ficheros para la competici\u00f3n**","9332e4e7":"**A\u00f1adimos la configuraci\u00f3n propuesta**","9c57b9c5":"**Resto de capas convolucionales**","ecf9b99a":"## 2.1 SplitFolders","99b9791b":"# 1. Preliminares","c4cb6aac":"**Creaci\u00f3n del modelo**","276a25b9":"**test_iterator**","c1c6702c":"**Comprobaci\u00f3n de ficheros**","298149fc":"**Capas Dropout**","a30fd9b2":"Utilizamos 2 train debido a que hemos llegado a la conclusi\u00f3n de que la red neuronal b\u00e1sica trabaja mejor sin ampliamiento de datos, llegando hasta un 87% de acierto en la competici\u00f3n, algo que para este tipo de redes no est\u00e1 nada mal.","0c1e0662":"**Capas Dropouts**","6899ffd0":"# 4. Modelado y evaluaci\u00f3n","4609ab13":"**validation_generator**","246df68e":"Declaramos la `GPU`","95c34e58":"**Especificamos la capa de entrada y salida**","b26921e1":"# 2. Carga de datos","750297d1":"**validation_iterator**","5584184d":"**Primera capa convolucional Gausiana**","b174faa2":"**Librer\u00edas**","579cb399":"Utilizamos 2 callbacks, uno para parar si no mejoran mucho los resultados y otro anteriormente comentado para cambiar la tasa de aprendizaje si tampoco va mejorando","56ae711a":"**Guardamos los ficheros**","8bc8f619":"## 3.2. Redes neuronales convolucionales","2e5f839d":"**train_generator**","ea5a3f74":"**Capa de entrada**","774f3905":"# 3. Modelos basados en redes neuronales","4500847f":"**Capa de salida**","5e55acb8":"**Aplanamos la salida**","080c5020":"## 3.3. Transfer Learning","a6e35ed0":"Para el Transfer Learning, los modelos que hemos estudiado son:\n\n* EfficientNetB7\n* VGG16\n* Xception\n* DenseNet201\n* InceptionResNetV2\n\n\nAdem\u00e1s este orden que hemos puesto es el que han seguido de menor a mayor score en la competici\u00f3n (empezando con el peor `EfficientNetB7` y terminando por `InceptionResNetV2`)\n\nRecalcar que la primera, es de las nuevas de keras y en nuestro caso pr\u00e1cticamente parece que predice de forma aleatoria, tambi\u00e9n intentamos probar `NASNetLarge` por los buenos score que ten\u00eda en el top-5 pero nos ped\u00eda un input-shize m\u00ednimo y por eso no la hemos estudiado.\n\nPara la comparaci\u00f3n hemos utlizado un esquema similar al de las redes neuronales b\u00e1sicas de esta pr\u00e1ctica para evitar sobreajustes. A ra\u00edz de esta configuraci\u00f3n hemos establecido las comparaciones. Nosotros hemos enfocado el trabajo de esta forma pero claro, seguro que cada modelo tendr\u00eda mejorar\u00eda o empeorar\u00eda de maneras distintas dependiendo de la configuraci\u00f3n que demos, a\u00fan as\u00ed como en nuestro trabajo quer\u00edamos enfocar m\u00e1s la competici\u00f3n en el cnn, dejamos esta parte para hacer pruebas y comparaciones de modelos con \"igual estructura\".","a7d2f8bc":"## 4.2 Redes neuronales convolucionales","5b40d027":"Utilizada para generalizar","957cac6f":"**Capas ocultas**","bc55cb08":"## 4.1 Redes neuronales","9d026212":"## 4.3 Transfer Learning","02289dac":"**Capa completamente conectada final**","23cbf5b8":"Sobre el `learning_rate` hemos observado que esta configuraci\u00f3n es la que mejores resultados produce en ejecuciones globales, a\u00fan as\u00ed en los callbacks utilizamos un par\u00e1metro que lo modifica en las ejecuciones dependiendo del `val_lose`, ya que nos ha parecido interesante modificar la tasa de aprendizaje en medio de la ejecuci\u00f3n cuando `val_lose` no mejora.","ec6aeaae":"# 5. Predicci\u00f3n","bcf96540":"**train_iterator**","7bdb82cb":"## Un peque\u00f1o par\u00e9ntesis: Garantizado la reproducibilidad de los experimentos","296f29b4":"**Creaci\u00f3n del modelo**","14f81c9b":"**Callbacks**"}}