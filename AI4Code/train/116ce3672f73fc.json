{"cell_type":{"3dc6d500":"code","aa18c96c":"code","7efb07e8":"code","d9e07472":"code","05e74cf9":"code","ceecaa3a":"code","1c63f0cf":"code","20356359":"code","0a7b629d":"code","3230e4bd":"code","26951f41":"code","1efae63e":"code","4fc216c3":"markdown","7ff0598a":"markdown","9cb84853":"markdown"},"source":{"3dc6d500":"from tensorflow import keras\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet import ResNet50\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","aa18c96c":"labels = pd.read_csv('\/kaggle\/input\/appa-real-face-cropped\/labels.csv')\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)","7efb07e8":"train_gen_flow = train_datagen.flow_from_dataframe(\n        dataframe=labels,\n        directory='\/kaggle\/input\/appa-real-face-cropped\/final_files\/final_files\/',\n        x_col='file_name',\n        y_col='real_age',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='raw',\n        seed=12345\n)","d9e07472":"features, target = next(train_gen_flow)\n\nfig = plt.figure(figsize=(10,10))\nfor i in range(10):\n    fig.add_subplot(4, 4, i+1)\n    plt.imshow(features[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()","05e74cf9":"labels.hist(bins=100,density=True)","ceecaa3a":"# load train\ntrain_datagen = ImageDataGenerator(validation_split=0.25, rescale=1.\/255,shear_range=0.2,\n                                    horizontal_flip=True,)\n#\u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e.\n\ntrain_data = train_datagen.flow_from_dataframe(\n        dataframe=labels,\n        directory='\/kaggle\/input\/appa-real-face-cropped\/final_files\/final_files\/',\n        x_col='file_name',\n        y_col='real_age',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='raw',\n        seed=12345,\n        subset='training')","1c63f0cf":"#load test\ntest_datagen = ImageDataGenerator(validation_split=0.25, rescale=1.\/255)\ntest_data = test_datagen.flow_from_dataframe(\n        dataframe=labels,\n        directory='\/kaggle\/input\/appa-real-face-cropped\/final_files\/final_files\/',\n        x_col='file_name',\n        y_col='real_age',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='raw',\n        seed=12345,\n        subset='validation')","20356359":"#create model\n\noptimizer= Adam() \nbackbone = ResNet50(input_shape=(150,150,3),weights='imagenet', include_top=False)\nmodel = Sequential()\nmodel.add(backbone)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1, activation='relu'))\nmodel.compile(loss=\"mean_squared_error\",optimizer=optimizer, metrics=[\"mean_absolute_error\"])","0a7b629d":"def train_model(model, train_data, test_data,batch_size=None,epochs=10, steps_per_epoch =None, validation_steps=None):\n    my_callbacks = [ tf.keras.callbacks.EarlyStopping(patience=35)] #\u0440\u0430\u043d\u043d\u044f\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430\n    if steps_per_epoch is None:\n        steps_per_epoch = len(train_data)\n    if validation_steps is None:\n        validation_steps = len(test_data)\n    model.fit(train_data,\n          validation_data=test_data,\n          steps_per_epoch=steps_per_epoch,\n          validation_steps=validation_steps,\n          verbose=1, epochs=epochs,  callbacks=my_callbacks)\n    return model","3230e4bd":"trained_model = train_model(model, train_data, test_data,batch_size=None,epochs=300, steps_per_epoch =None, validation_steps=None)","26951f41":"#Epoch 35\/150 adam tandart, +augmentation\n#178\/178 [==============================] - 98s 548ms\/step - loss: 10.7784 - mean_absolute_error: 2.5221 - val_loss: 80.2944 - val_mean_absolute_error: 6.6870","1efae63e":"trained_model.save(\"model.h5\")","4fc216c3":"## Model","7ff0598a":"# Age detection with keras","9cb84853":"## take a look"}}