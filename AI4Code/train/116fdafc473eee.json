{"cell_type":{"5abd17ed":"code","a56a76e8":"code","30187652":"code","e6aca744":"code","b35e1e74":"code","e0b90bf0":"code","977b1793":"code","92a1a5c5":"code","c748b506":"code","41c2a999":"code","c9ae6f84":"code","ffc6249b":"code","d2f5dc79":"code","36682f9e":"code","98d0c71d":"code","a0714ffe":"code","ad53b185":"code","be48de4f":"code","376297d3":"code","60b097ba":"code","08fda219":"code","8c3a71c8":"code","c466abcd":"code","6ffd6a6d":"code","f8a3a74a":"code","2563a86f":"code","dfaa381a":"code","d3e3d0fe":"code","946ba3e4":"code","6314f499":"code","2da9f90f":"code","0ad95cec":"code","038d760b":"code","ac406a52":"code","603be622":"code","a93c357f":"code","7e12857a":"code","d5382bc3":"code","89ebe5b2":"code","5e96e674":"code","eae70a5c":"code","a5d2ffff":"code","354e707f":"code","633dad83":"code","f5765630":"markdown","d3ba1458":"markdown","0720df13":"markdown","09b899e6":"markdown","7e4f6ba1":"markdown","289fd7bb":"markdown","9d7a4ab3":"markdown","22b7cbbf":"markdown","c466b978":"markdown","08c0556f":"markdown","101147fc":"markdown","4b0292d3":"markdown","b937897c":"markdown","5624d72f":"markdown","2d04c22e":"markdown","75eb4afd":"markdown","945223f7":"markdown","b268aad5":"markdown","3dbb6b8e":"markdown","631b48d5":"markdown","e11f8486":"markdown","705a7161":"markdown","aeedf03e":"markdown","26470d86":"markdown"},"source":{"5abd17ed":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image as img\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.activations as Actications\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom keras.utils.vis_utils import model_to_dot\nimport os\nimport matplotlib.pyplot as plot\nimport cv2\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix as CM\nfrom random import randint\nfrom IPython.display import SVG\nimport matplotlib.gridspec as gridspec","a56a76e8":"tf.__version__","30187652":"cv2.__version__","e6aca744":"X = []\ny = []\nIMG_SIZE = 150\nDIR = \"..\/input\/intel-image-classification\/seg_train\/seg_train\"\nfolders = os.listdir(DIR)\nfolders","b35e1e74":"for i, file in enumerate(folders):\n    filename = os.path.join(DIR, file)\n    print(\"Folder {} started\".format(file))\n    try:\n        for img in os.listdir(filename):\n            path = os.path.join(filename, img)\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n\n            X.append(np.array(img))\n            y.append(i)\n    except:\n        print(\"File {} not read\".format(path))\n        \n    print(\"Folder {} done\".format(file))\n    print(\"The folder {} is labeled as {}\".format(file, i))","e0b90bf0":"np.unique(y, return_counts=True)","977b1793":"from tqdm import tqdm\nX=[]\nZ=[]\n\nIMG_SIZE=150\nIMAGE_BUILDINGS_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/buildings'\nIMAGE_FOREST_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/forest'\nIMAGE_GLACIER_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/glacier'\nIMAGE_MOUNTAIN_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/mountain'\nIMAGE_SEA_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/sea'\nIMAGE_STREET_DIR='..\/input\/intel-image-classification\/seg_train\/seg_train\/street'","92a1a5c5":"def assign_label(img,image_type):\n    return image_type","c748b506":"def make_train_data(image_type,DIR):\n    for img in tqdm(os.listdir(DIR)):\n        label=assign_label(img,image_type)\n        path = os.path.join(DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        \n        X.append(np.array(img))\n        Z.append(__builtins__.str(label))","41c2a999":"make_train_data('Buildings',IMAGE_BUILDINGS_DIR)\nprint(len(X))","c9ae6f84":"make_train_data('Forest',IMAGE_FOREST_DIR)\nprint(len(X))","ffc6249b":"make_train_data('Glacier',IMAGE_GLACIER_DIR)\nprint(len(X))","d2f5dc79":"make_train_data('Mountain',IMAGE_MOUNTAIN_DIR)\nprint(len(X))","36682f9e":"make_train_data('Sea',IMAGE_SEA_DIR)\nprint(len(X))","98d0c71d":"make_train_data('Street',IMAGE_STREET_DIR)\nprint(len(X))","a0714ffe":"dirs = os.listdir('..\/input\/intel-image-classification\/seg_train\/seg_train')\nprint(\"The Different Classes in dataset are :\")\ndirs","ad53b185":"\nfrom IPython.display import display\nfrom PIL import Image \nlabels = []\ndic = dict()\nfor i in range(0,6):\n    str = '..\/input\/intel-image-classification\/seg_train\/seg_train\/'+dirs[i]\n    count = 0\n    for j in os.listdir(str):\n        str2 = str+\"\/\"+j\n        im = Image.open(str2)\n        count += 1\n        labels.append(j)\n    dic[dirs[i]] = count","be48de4f":"labels1 = []\ndic1 = dict()\nIMAGE_SIZE = (64,64)\nfor i in range(0,6):\n    str = '..\/input\/intel-image-classification\/seg_test\/seg_test\/'+dirs[i]\n    count = 0\n    for j in os.listdir(str):\n        str2 = str+\"\/\"+j\n        im = Image.open(str2)\n        count += 1\n        labels1.append(j)\n    dic1[dirs[i]] = count","376297d3":"print (\"Number of training examples: {}\".format(len(labels)))\nprint (\"Number of testing examples: {}\".format(len(labels1)))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","60b097ba":"lis1 = []\nlis2 = []\nfor key,val in dic.items():\n    lis1.append(val)\n    lis2.append(key)","08fda219":"lis11 = []\nlis22 = []\nfor key,val in dic1.items():\n    lis11.append(val)\n    lis22.append(key)","8c3a71c8":"data = {'Name':lis2, 'train':lis1,'test':lis11}\ndata","c466abcd":"import pandas as pd\ndf = pd.DataFrame(data)\ndf","6ffd6a6d":"ax = df.plot.bar(x='Name', y=['train','test'], rot=0)\nplt.title('Training sets Input')","f8a3a74a":"plt.pie(lis1,\n        explode=(0, 0, 0, 0, 0, 0) , \n        labels=lis2,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","2563a86f":"import random as rn\nfig,ax=plt.subplots(5,3)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (3):\n        l=rn.randint(0,len(Z))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Intel_Image: '+Z[l])\n        \nplt.tight_layout()","dfaa381a":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\nseg_train = train_datagen.flow_from_directory('..\/input\/intel-image-classification\/seg_train\/seg_train',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","d3e3d0fe":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\nseg_test = test_datagen.flow_from_directory('..\/input\/intel-image-classification\/seg_test\/seg_test',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\nIMAGE_SIZE = (64,64)","946ba3e4":"cnn = tf.keras.models.Sequential()","6314f499":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","2da9f90f":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","0ad95cec":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","038d760b":"cnn.add(tf.keras.layers.Flatten())","ac406a52":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","603be622":"cnn.add(tf.keras.layers.Dense(units=6, activation='softmax'))","a93c357f":"cnn.summary()","7e12857a":"cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","d5382bc3":"trained= cnn.fit(x = seg_train, validation_data = seg_test, epochs = 25)","89ebe5b2":"plt.plot(trained.history['loss'])\nplt.plot(trained.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","5e96e674":"plt.plot(trained.history['accuracy'])\nplt.plot(trained.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","eae70a5c":"import numpy as np\nfrom keras.preprocessing import image\ntest_image1 = image.load_img('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/5.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image1)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\nif result[0][0] == 1:\n  prediction = 'Building'\nelif result[0][1] == 1:\n  prediction = 'Forest'\nelif result[0][2] == 1:\n  prediction = 'Glacier'\nelif result[0][3] == 1:\n  prediction = 'Mountain'\nelif result[0][4] == 1:\n  prediction = 'Sea'\nelif result[0][5] == 1:\n  prediction = 'Street'\nelse:\n    print(\"Error\")","a5d2ffff":"result","354e707f":"print(prediction)","633dad83":"from IPython.display import display\nfrom PIL import Image \ndisplay(plt.imshow(test_image1))\nplt.title(\"Street Image\")","f5765630":"## Importing The Libraries","d3ba1458":"### Training the CNN on the Training set and evaluating it on the Test set","0720df13":"### Preprocessing the Test set","09b899e6":"!pip install keras\n","7e4f6ba1":"### Step 2 - Pooling","289fd7bb":"!pip install opencv-python","9d7a4ab3":"## 2.2 ) Visualizing some Random Images","22b7cbbf":"### Making the functions to get the training and validation set from the Images","c466b978":"## Evaluating the Model Performance","08c0556f":"##  Predicting single image and visualizing it","101147fc":"### Step 1 - Convolution","4b0292d3":"## Part 2 - Building the CNN","b937897c":"### Preprocessing the Training set","5624d72f":"### Step 4 - Full Connection","2d04c22e":"!pip install tensorflow","75eb4afd":"# Convolutional Neural Network","945223f7":"### Adding a second convolutional layer","b268aad5":"# Analising the Data","3dbb6b8e":"### Step 5 - Output Layer","631b48d5":"## Part 3 - Training the CNN","e11f8486":"### Compiling the CNN","705a7161":"### Step 3 - Flattening","aeedf03e":"### Installing the libraries","26470d86":"### Initialising the CNN"}}