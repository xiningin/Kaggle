{"cell_type":{"9cde932e":"code","9dd85eea":"code","79aa23b5":"code","31775599":"code","1c465da1":"code","6a66a03a":"code","62021cfe":"markdown","04be0b96":"markdown","88beabd5":"markdown","30d59dff":"markdown","c80fd550":"markdown","326d4e98":"markdown","e6f853b2":"markdown"},"source":{"9cde932e":"# Install latest transformers library\n!pip install transformers --upgrade\n\n# Language modeling\n!wget -P \/tmp https:\/\/raw.githubusercontent.com\/huggingface\/transformers\/master\/examples\/language-modeling\/run_language_modeling.py\n\n# SQuAD 2.0\n!wget -P \/tmp https:\/\/raw.githubusercontent.com\/huggingface\/transformers\/master\/examples\/question-answering\/run_squad.py\n!wget -P \/tmp https:\/\/rajpurkar.github.io\/SQuAD-explorer\/dataset\/train-v2.0.json\n!wget -P \/tmp https:\/\/rajpurkar.github.io\/SQuAD-explorer\/dataset\/dev-v2.0.json\n\n# Remove wandb\n!pip uninstall -y wandb","9dd85eea":"!python \/tmp\/run_language_modeling.py \\\n    --model_type bert \\\n    --model_name_or_path google\/bert_uncased_L-6_H-512_A-8 \\\n    --do_train \\\n    --mlm \\\n    --line_by_line \\\n    --block_size 512 \\\n    --train_data_file ..\/input\/cord19-qa\/cord19.txt \\\n    --per_gpu_train_batch_size 4 \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 3.0 \\\n    --output_dir bert-small-cord19 \\\n    --save_steps 0 \\\n    --overwrite_output_dir","79aa23b5":"!python \/tmp\/run_squad.py \\\n    --model_type bert \\\n    --model_name_or_path bert-small-cord19 \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --version_2_with_negative \\\n    --train_file \/tmp\/train-v2.0.json \\\n    --predict_file \/tmp\/dev-v2.0.json \\\n    --per_gpu_train_batch_size 8 \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 3.0 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir bert-small-cord19-squad2 \\\n    --save_steps 0 \\\n    --threads 2 \\\n    --overwrite_cache \\\n    --overwrite_output_dir","31775599":"!python \/tmp\/run_squad.py \\\n    --model_type bert \\\n    --model_name_or_path bert-small-cord19-squad2 \\\n    --do_train \\\n    --do_lower_case \\\n    --version_2_with_negative \\\n    --train_file ..\/input\/cord19-qa\/cord19-qa.json \\\n    --per_gpu_train_batch_size 8 \\\n    --learning_rate 5e-5 \\\n    --num_train_epochs 10.0 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir bert-small-cord19qa \\\n    --save_steps 0 \\\n    --threads 2 \\\n    --overwrite_cache \\\n    --overwrite_output_dir","1c465da1":"# Remove large training cache files from output\n!rm -rf cached_*","6a66a03a":"import csv\nimport string\nimport sys\n\nfrom transformers.pipelines import pipeline\n\n# Create NLP pipeline\nnlp = pipeline(\"question-answering\", model=\"bert-small-cord19qa\", tokenizer=\"bert-small-cord19qa\")\n\n# Init questions\/contexts\/answers\nquestions = [\"What containment method?\",\n             \"What weather factor?\",\n             \"What is the incubation period range?\",\n             \"What is model prediction?\",\n             \"What is cancer risk number?\"]\n\ncontexts = [\"With contact tracing, the proportion q of individuals exposed to the virus is quarantined.\",\n            \"Higher temperatures and higher RH (38 C, and >95% RH) have been found to reduce virus viability.\",\n            \"The average incubation period is 5-6 days, ranging from 1-14 days 6 .\",\n            \"Therefore, if person-to-person transmission persists from February, we predict the epidemic peak would occur in June.\",\n            \"cancer was associated with an increased risk for severe events (odds ratio, 5.34; 95% confidence interval [CI], 1.80 to 16.18; P = .0026),\"]\n\nanswers = [\"contact tracing\",\n           \"Higher temperatures and higher RH\",\n           \"5-6 days\",\n           \"epidemic peak would occur in June\",\n           \"odds ratio, 5.34\"]\n\n# Show results\nfor x, result in enumerate(nlp(question=questions, context=contexts)):\n    # Remove leading\/trailing punctuation\n    result[\"answer\"] = result[\"answer\"].strip(string.punctuation)\n    print(result, answers[x])","62021cfe":"# bert-small-cord19-squad2\n\nThe next step takes the fine-tuned language model and trains it on SQuAD 2.0. SQuAD 2.0 is a better fit than 1.1 as it handled abstaining from answering a question, which is important for this dataset.\n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19-squad2](https:\/\/huggingface.co\/NeuML\/bert-small-cord19-squad2)","04be0b96":"# Model Discussion\n\n[BERT-Small](https:\/\/huggingface.co\/google\/bert_uncased_L-6_H-512_A-8) was selected as the root model after testing various models ([BERT-Base](https:\/\/huggingface.co\/bert-base-uncased), [ALBERT-base v2](https:\/\/huggingface.co\/albert-base-v2), [SciBERT](https:\/\/huggingface.co\/allenai\/scibert_scivocab_uncased), [BioBERT](https:\/\/huggingface.co\/monologg\/biobert_v1.1_pubmed), [DistilBERT](https:\/\/huggingface.co\/distilbert-base-uncased), [BERT-Tiny](https:\/\/huggingface.co\/google\/bert_uncased_L-2_H-128_A-2) and [BERT-Mini](https:\/\/huggingface.co\/google\/bert_uncased_L-4_H-256_A-4)).\n\nThe CORD-19 QA extractive model is primarily designed to execute subqueries against large lists of search results, therefore it needs to be performant. BERT-Base, ALBERT-base v2 and SciBERT all roughly had the same execution time. BERT-Tiny and BERT-Mini were much faster than BERT-Small but just couldn't reach a reasonable level of answering accuracy. DistilBERT was slower than BERT-Small.\n\nThe second part of model selection is whether to start with a general English language model or a medical\/scientific model. My assumption going in was that models trained on medical data would be more accurate and perform better. But what I found was that BERT-Small performed better as I built out the CORD-19 QA dataset. My hypothesis behind this is that given my limited medical background, the way I constructed the questions to ask of the data was better suited to a general language model.\n\nOthers may find different results and it's easy to modify\/test. Simply clone this notebook and change a single line in the code below to substitute an alternate model.","88beabd5":"# bert-small-cord19qa\n\nThe last step is taking the fine-tuned SQuAD 2.0 model and further fine-tuning it on [700+ CORD-19 specific QA pairs](https:\/\/www.kaggle.com\/davidmezzetti\/cord19-qa).\n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19qa](https:\/\/huggingface.co\/NeuML\/bert-small-cord19qa)","30d59dff":"# CORD-19 QA Transformer Model\n\nThis notebook builds a CORD-19 extractive QA model based on the BERT-Small model. The model is designed to help extract structured information out of CORD-19 articles. \n\nThe following sections go through detailed steps in building these models, background information on each step and a link to pre-trained models on Hugging Face's website.","c80fd550":"# bert-small-cord19\n\nThe file [cord19.txt](https:\/\/www.kaggle.com\/davidmezzetti\/cord19-qa?select=cord19.txt) is a partial export of sentences from the CORD-19 dataset, representing the best articles, ones with detected study designs. \n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19](https:\/\/huggingface.co\/NeuML\/bert-small-cord19)","326d4e98":"# Testing the model\nTest the model with the following handful of question\/context\/answer groups","e6f853b2":"# Install libraries and download build scripts"}}