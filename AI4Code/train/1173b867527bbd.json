{"cell_type":{"7bf65d23":"code","d64adb33":"code","7c8223ac":"code","47672814":"code","d5ab69e0":"code","bc5cf1f8":"code","e1c82449":"code","c7cd59c1":"code","821dd543":"code","31d5b81c":"code","eebfe8d2":"code","944d1ee0":"code","508837cc":"code","ca897742":"code","7360aaa7":"code","7292c400":"code","5f70d343":"code","988b2fea":"code","acc82d42":"code","a3efb95a":"code","ce8060d8":"code","3290bcc6":"code","23ea0906":"code","d55c301f":"code","1d7470e6":"code","dd23affe":"code","d339bf03":"code","1a8bc401":"code","9372f60d":"code","3e04d7e7":"code","ccdbab64":"code","c7ffe2d3":"markdown","4a12c742":"markdown","a8a414a4":"markdown","c8d66026":"markdown","e89c3eb1":"markdown","25fd63a2":"markdown","a83b9b02":"markdown","f48aa472":"markdown","035bee33":"markdown","af7a4a2c":"markdown","87164086":"markdown","a5395b11":"markdown","a004c3a5":"markdown","700dd9df":"markdown","eef1605e":"markdown","9a0f5be5":"markdown","ca7c3c9c":"markdown"},"source":{"7bf65d23":"# Importing required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Plotting Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# settings\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d64adb33":"#  Fetching all the files in pandas dataframes\nshops = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\nsales = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\nitem = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nitem_catg = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")","7c8223ac":"sales.dtypes","47672814":"print('training data has {} columns and {} rows'.format(sales.shape[1],sales.shape[0]))\nprint('test data has {} columns and {} rows'.format(test.shape[1],test.shape[0]))","d5ab69e0":"#formatting the date column correctly\nimport datetime\nsales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))","bc5cf1f8":"sales.head()","e1c82449":"sales.describe()","c7cd59c1":"test_only = test[~test['item_id'].isin(sales['item_id'].unique())]['item_id'].unique()\nprint('test only items:', len(test_only))","821dd543":"# dropping shops&items not in test data\nshops_in_test = test.shop_id.unique()\nitems_in_test = test.item_id.unique()\nsales = sales[sales.shop_id.isin(shops_in_test)]\nsales = sales[sales.item_id.isin(items_in_test)]\n\nprint('sales:', sales.shape)","31d5b81c":"sales.head()","eebfe8d2":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)","944d1ee0":"sales = sales[sales.item_cnt_day<1000]","508837cc":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\n\n\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)","ca897742":"## Checking the number of items sold per month\nmonth_wise_items_sold = sales.groupby('date_block_num').agg({'item_cnt_day' : sum},inplace = True , reset_index = True)\nplt.figure(figsize=(18,5))\nplt.title('Items sold by the company')\nplt.xlabel('Time')\nplt.ylabel('Items sold')\nplt.plot(month_wise_items_sold);","7360aaa7":"calculating_revenue = sales\ncalculating_revenue['revenue'] = calculating_revenue['item_price'] * calculating_revenue['item_cnt_day']\ncalculating_revenue.head()","7292c400":"## Checking the revenue generated by the company per month\nmonth_wise_revenue = calculating_revenue.groupby('date_block_num').agg({'revenue' : sum})\nplt.figure(figsize=(20,5))\nplt.title('revenue generated per month by the company')\nplt.xlabel('Time')\nplt.ylabel('Revenue generated')\nplt.plot(month_wise_revenue);","5f70d343":"shop_wise_revenue = calculating_revenue.groupby('shop_id').agg({'revenue' : sum})\nplt.figure(figsize=(20,5))\nplt.title('revenue generated by the individual shops')\nplt.xlabel('Shop id')\nplt.ylabel('Revenue generated')\nplt.plot(shop_wise_revenue);","988b2fea":"## Checking number of returned items\nreturned_items = sales[sales['item_cnt_day'] < 0]\nmonth_wise_items_returned = returned_items.groupby('date_block_num').agg({'item_cnt_day' : sum})\nmonth_wise_items_returned['item_cnt_day'] = month_wise_items_returned['item_cnt_day'].abs()\nplt.figure(figsize=(20,5))\nplt.title('Items returned per month')\nplt.xlabel('Time')\nplt.ylabel('Items returned')\nplt.plot(month_wise_items_returned);","acc82d42":"timeseries = month_wise_items_sold ","a3efb95a":"plt.figure(figsize=(16,6))\nplt.plot(timeseries.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(timeseries.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","ce8060d8":"import statsmodels.api as sm\n\nprint('multiplicative model')\n# multiplicative\nmul_model = sm.tsa.seasonal_decompose(timeseries.values,freq=12,model=\"multiplicative\")\n\nfig = mul_model.plot()\n\n# ------------------------------------------------------------------------------------\nprint('Additive model') \n# Additive\nadd_model = sm.tsa.seasonal_decompose(timeseries.values,freq=12,model=\"additive\")\n\nfig = add_model.plot()\n","3290bcc6":"# Stationarity tests\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\n\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(timeseries)","23ea0906":"# To remove trend\nfrom pandas import Series as Series\n\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","d55c301f":"timeseries.columns","1d7470e6":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\n\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\n\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","dd23affe":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","d339bf03":"# adding the dates to the Time-series as index\nts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","1a8bc401":"from fbprophet import Prophet\n\nts.columns=['ds','y']\n#instantiate Prophet with only yearly seasonality as our data is monthly \nmodel = Prophet( yearly_seasonality=True) \nmodel.fit(ts) #fit the model with your dataframe","9372f60d":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","3e04d7e7":"model.plot(forecast)","ccdbab64":"model.plot_components(forecast)","c7ffe2d3":"item_cnt_day column has negative values as well, I will be considering them as the items returned to the stores on that day","4a12c742":"As p value > 0.05 we take the series as seosanal time series\n\n## Decomposing time series data","a8a414a4":"## As we can see there is still some patterns left in the residual of additive model, we would assume the timeseries to be multiplicative that can be shown as yt=St x Tt x Et","c8d66026":"## As we can see there is a sudden peak after the 10th month and 22nd month, that probably signifies the increase in sales during holidays period around christmas in Russia","e89c3eb1":"# Checking for Outliers","25fd63a2":"# **Data Exploration**","a83b9b02":"As p value is now less than 0.05, we can consider that the data is stationary","f48aa472":"In the first Boxplot \n    1. There are 2 outliers\n\nIn the second Boxplot\n    1. There is no outlier\n\n## Removing the outliers","035bee33":"### Shop id 31 has the highest revenue amongst all","af7a4a2c":"# Exploring Time Series","87164086":"## Checking the items which are present in test set but not in training set","a5395b11":"# Predicting the sales of items from different stores for a russian company\n## Tushar Pasricha - April 2020","a004c3a5":"## As we can see in the above graph the revenue generated is higher around 24th month in the series i.e December 2014 has the highest sales of all time","700dd9df":"### The maximum number of items were returned to the company in 24th month of the data provided i.e. December 2014","eef1605e":"## **sales_train data** ","9a0f5be5":"As we can see in the above graph, there is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a increasing \"Trend\".\n\nLet's check that with decomposition into Trend, seasonality and residuals.","ca7c3c9c":"# Time Series Forecasting\n### We  will apply prophet model for baseline"}}