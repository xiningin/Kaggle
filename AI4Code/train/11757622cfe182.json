{"cell_type":{"84281d89":"code","51e19ed5":"code","ce739e37":"code","9e371782":"code","9fb624bb":"code","fcdd66f2":"code","cbddec6d":"code","0f4a27ba":"code","9c0ebc35":"code","a718baa6":"code","934fbf8d":"code","27246dd1":"code","235e51ce":"code","ebc78eae":"code","83996495":"code","32309908":"code","f5fffaa2":"code","e37f9b3c":"code","5e095eaa":"code","99025fa0":"code","7c1c87a2":"code","e93986fe":"code","4070252a":"code","c3e6a59d":"code","15dd33b6":"code","af7157c7":"code","08f680c9":"code","bace89dc":"code","09c7387b":"code","a86c5f4b":"code","9e08bf60":"code","e1922f3c":"code","ba259d71":"code","f7d6147c":"code","475241ea":"code","237d09fe":"code","b2c70809":"code","ecbac712":"code","23827725":"code","e751f0e7":"code","71f8051c":"code","6efd508a":"code","988d19c8":"markdown"},"source":{"84281d89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport statsmodels.api as sm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","51e19ed5":"data=pd.read_csv('..\/input\/credit\/Credit (1).csv')","ce739e37":"data.head()","9e371782":"data.info()","9fb624bb":"data.isnull().sum()","fcdd66f2":"data.nunique()","cbddec6d":"categorical=[\"NoofTime30_59DaysPastDue\", \"NorOfTimes90DaysLate\", \"NoRealEstateLoansOrLines\", \"NoOfTime60_89DaysPastDue\", \"NoOfDependents\"]","0f4a27ba":"data.describe()","9c0ebc35":"data[categorical].columns","a718baa6":"for col in data[categorical].columns:\n#     sns.countplot(data[col])\n    fig = px.histogram(x=data[col], color=data[col])\n    fig.update_layout(title_text=col)\n    fig.show()","934fbf8d":"sns.pairplot(data)","27246dd1":"coll=[]\nfor i in data.columns:\n    if data[i].nunique()>15:\n        coll.append(i)","235e51ce":"coll","ebc78eae":"import scipy.stats as stats\nplt.subplots(figsize=(12,9))\n\nsns.distplot(data['RevolvingUtiOfUnsecuredLines'], fit=stats.norm)\n\n# Get the fitted parameters used by the function\n\n(mu, sigma) = stats.norm.fit(data['RevolvingUtiOfUnsecuredLines'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(data['RevolvingUtiOfUnsecuredLines'], plot=plt)\nplt.show()","83996495":"for i in coll:\n    plt.subplots(figsize=(12,9))\n\n    sns.distplot(data[i], fit=stats.norm)\n\n    # Get the fitted parameters used by the function\n\n    (mu, sigma) = stats.norm.fit(data[i])\n\n    # plot with the distribution\n\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n    plt.ylabel('Frequency')\n\n    #Probablity plot\n\n    fig = plt.figure()\n    stats.probplot(data[i], plot=plt)\n    plt.show()","32309908":"from scipy.stats import norm, skew #for some statistics\n# Check the skew of all numerical features\nskewed_feats = data.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness","f5fffaa2":"skewness.plot()\n","e37f9b3c":"skewness = skewness[abs(skewness) > 0.75]\nnew_data=data.iloc[:,1:]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.05\nfor feat in new_data.columns:\n    new_data[feat] = boxcox1p(new_data[feat], lam)","5e095eaa":"new_data.head()","99025fa0":"for i in coll:\n    plt.subplots(figsize=(12,9))\n\n    sns.distplot(new_data[i], fit=stats.norm)\n\n    # Get the fitted parameters used by the function\n\n    (mu, sigma) = stats.norm.fit(new_data[i])\n\n    # plot with the distribution\n\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n    plt.ylabel('Frequency')\n\n    #Probablity plot\n\n    fig = plt.figure()\n    stats.probplot(new_data[i], plot=plt)\n    plt.show()","7c1c87a2":"data","e93986fe":"Y=data.iloc[:,0:1]\nX1=data.iloc[:,1:]\nX2=new_data","4070252a":"X2","c3e6a59d":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n","15dd33b6":"Y","af7157c7":"clf1 = DecisionTreeClassifier(random_state=10)\nclf2 = KNeighborsClassifier(n_neighbors=5)\n","08f680c9":"from sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X1, Y, test_size=0.2, random_state=10)","bace89dc":"clf1.fit(X_train, y_train)\ny_pred1=clf1.predict(X_test)\nacc1=metrics.accuracy_score(y_test, y_pred1)\nprec1=metrics.precision_score(y_test, y_pred1, average='weighted')\nrecall1=metrics.recall_score(y_test, y_pred1, average='weighted')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred1))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred1, average='weighted'))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred1, average='weighted'))\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred1, target_names=['0', '1']))\n","09c7387b":"clf2.fit(X_train, y_train)\ny_pred2=clf2.predict(X_test)\nacc2=metrics.accuracy_score(y_test, y_pred2)\nprec2=metrics.precision_score(y_test, y_pred2, average='weighted')\nrecall2=metrics.recall_score(y_test, y_pred2, average='weighted')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred2))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred2, average='weighted'))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred2, average='weighted'))\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred2, target_names=['0', '1']))","a86c5f4b":"from mlxtend.evaluate import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\ny_preds1=pd.DataFrame(y_pred1)\ncm = confusion_matrix(y_target=y_test, \n                      y_predicted=y_preds1, \n                      binary=False)\ncm\n\n\nimport matplotlib.pyplot as plt\nfrom mlxtend.evaluate import confusion_matrix\nprint(\"Decision Tree\")\nfig, ax = plot_confusion_matrix(conf_mat=cm)\nplt.show()","9e08bf60":"from mlxtend.evaluate import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\ny_preds2=pd.DataFrame(y_pred2)\n\ncm = confusion_matrix(y_target=y_test, \n                      y_predicted=y_preds2, \n                      binary=False)\ncm\n\n\nimport matplotlib.pyplot as plt\nfrom mlxtend.evaluate import confusion_matrix\nprint(\"KNN Classifier\")\nfig, ax = plot_confusion_matrix(conf_mat=cm)\nplt.show()","e1922f3c":"rp={'Model': ['Decision Tree', 'KNN' ],'Accuracy':[acc1,acc2], 'Precision': [prec1,prec2], 'Recall': [recall1, recall2]}","ba259d71":"report=pd.DataFrame(rp, columns=['Model','Accuracy', 'Precision', 'Recall'])","f7d6147c":"report","475241ea":"X_train, X_test, y_train, y_test = train_test_split(X2, Y, test_size=0.2, random_state=10)","237d09fe":"clf1.fit(X_train, y_train)\ny_pred1=clf1.predict(X_test)\nacc1=metrics.accuracy_score(y_test, y_pred1)\nprec1=metrics.precision_score(y_test, y_pred1, average='weighted')\nrecall1=metrics.recall_score(y_test, y_pred1, average='weighted')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred1))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred1, average='weighted'))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred1, average='weighted'))\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred1, target_names=['0', '1']))\n","b2c70809":"clf2.fit(X_train, y_train)\ny_pred2=clf2.predict(X_test)\nacc2=metrics.accuracy_score(y_test, y_pred2)\nprec2=metrics.precision_score(y_test, y_pred2, average='weighted')\nrecall2=metrics.recall_score(y_test, y_pred2, average='weighted')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred2))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred2, average='weighted'))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred2, average='weighted'))\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred2, target_names=['0', '1']))","ecbac712":"from mlxtend.evaluate import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\ny_preds1=pd.DataFrame(y_pred1)\ncm = confusion_matrix(y_target=y_test, \n                      y_predicted=y_preds1, \n                      binary=False)\ncm\n\n\nimport matplotlib.pyplot as plt\nfrom mlxtend.evaluate import confusion_matrix\nprint(\"Decision Tree\")\nfig, ax = plot_confusion_matrix(conf_mat=cm)\nplt.show()","23827725":"from mlxtend.evaluate import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\ny_preds2=pd.DataFrame(y_pred2)\n\ncm = confusion_matrix(y_target=y_test, \n                      y_predicted=y_preds2, \n                      binary=False)\ncm\n\n\nimport matplotlib.pyplot as plt\nfrom mlxtend.evaluate import confusion_matrix\nprint(\"KNN Classifier\")\nfig, ax = plot_confusion_matrix(conf_mat=cm)\nplt.show()","e751f0e7":"rp={'Model': ['Decision Tree', 'KNN' ],'Accuracy':[acc1,acc2], 'Precision': [prec1,prec2], 'Recall': [recall1, recall2]}","71f8051c":"report=pd.DataFrame(rp, columns=['Model','Accuracy', 'Precision', 'Recall'])","6efd508a":"report","988d19c8":"No Null Values"}}