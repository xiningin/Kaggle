{"cell_type":{"b071b370":"code","9fab8f7e":"code","4c7ca2da":"code","ccfcb3aa":"code","d1fc5c9f":"code","ca1d8c93":"code","33fbbb7a":"code","7d93ea14":"code","327d5a48":"code","4227d7dd":"code","e92349cb":"code","02e12076":"code","c6979e23":"code","4c340cd4":"code","2b8b2a02":"code","d2d6201e":"code","a6af12b0":"code","e5712387":"code","13a13e16":"code","a751bbac":"code","29ccdead":"code","f64b1499":"code","5924a0cd":"code","8442d481":"code","8f3f4a49":"code","64a3fb10":"code","8521ed8d":"code","a4c7580a":"code","773d0533":"code","8605a9fa":"code","7adf57a3":"code","d5f5b34e":"code","a146ce74":"code","a0629e21":"code","5411427c":"code","c87d173c":"code","3df10c42":"code","c7ce5929":"code","52f4e9ac":"code","14cff575":"code","9c4d263a":"code","b1463a06":"code","02feeb86":"code","e33cab7a":"code","990147a4":"code","30a857bb":"code","8e0b4063":"code","d4b8b41a":"code","b735f82d":"code","43860487":"code","c11eb55b":"code","4a429fcb":"code","f57fa661":"code","6e692698":"code","b0bfb135":"code","b4c2851d":"code","dd625b6e":"code","77f2c623":"code","0d9572d0":"code","4a02c935":"code","77668f49":"markdown","d5e78a6e":"markdown","4a91ec68":"markdown","8b7cc967":"markdown","74f05f5e":"markdown","bd00c051":"markdown","84f47c1d":"markdown","811f8ab0":"markdown"},"source":{"b071b370":"\"\"\"\nCreate by karl bina\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9fab8f7e":"pd.set_option('display.max_rows', None)","4c7ca2da":"Test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nTrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","ccfcb3aa":"Train_set = Train.copy()\nTest_set = Test.copy()","d1fc5c9f":"Train_set.head()","ca1d8c93":"Test_set.head()","33fbbb7a":"Train_set.shape","7d93ea14":"Train_set.dtypes.value_counts()","327d5a48":"Train_set.dtypes.value_counts().plot.bar()","4227d7dd":"import seaborn  as sns","e92349cb":"############################ identify empty values #######################################\nplt.figure(figsize=(12, 8))\nsns.heatmap(Train_set.isna(), cbar=False)","02e12076":"Train_set.isna().sum()","c6979e23":"### Percentage of empty data\n(Train_set.isna().sum() \/Train_set.shape[0]).sort_values(ascending=False)","4c340cd4":"Train_set['Survived'].value_counts(normalize=True)","2b8b2a02":"for value in Train_set.select_dtypes('float64'):\n    plt.figure()\n    sns.distplot(Train_set[value])","d2d6201e":"for value in Train_set.select_dtypes('int64'):\n    plt.figure()\n    try:\n        sns.distplot(Train_set[value])\n    except RuntimeError as re:\n        if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n            sns.distplot(Train_set[value], kde_kws={'bw': 0.1})\n        else:\n            raise re","a6af12b0":"plt.figure(figsize=(12, 8))\nsns.countplot(x='Sex', hue='Survived', data=Train_set)","e5712387":"Survived = Train_set[Train_set['Survived'] == 1].drop(['Survived','PassengerId','Name','Sex',\n                                                       'Cabin','Ticket','Embarked'],\n                                                      axis=1)\nDie = Train_set[Train_set['Survived'] == 0].drop(['Survived','PassengerId','Name','Sex',\n                                                       'Cabin','Ticket','Embarked'],\n                                                      axis=1)\ndf = Train_set.drop(['Survived','PassengerId','Name','Sex',\n                                                       'Cabin','Ticket','Embarked'],\n                                                      axis=1)","13a13e16":"for col in df:\n    try:\n        plt.figure()\n        sns.distplot(Survived[col], label='Survived')\n        sns.distplot(Die[col], label='Die')\n        plt.legend()\n    except RuntimeError as re:\n        if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n            plt.figure()\n            sns.distplot(Survived[col], label='Survived', kde_kws={'bw': 0.1})\n            sns.distplot(Die[col], label='Die', kde_kws={'bw': 0.1})\n            plt.legend()\n        else:\n            raise re    ","a751bbac":"Train_set.drop(['Survived','PassengerId','Name','Cabin','Ticket','Embarked'],\n                                                      axis=1).groupby(['Sex','Pclass']).mean()","29ccdead":"sns.pairplot(Train_set)","f64b1499":"Train_set['Sex'].value_counts()","5924a0cd":"df = Train.copy() ","8442d481":"df.head()","8f3f4a49":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder","64a3fb10":"def Encodage(df):\n    code = {'male':1,\n            'female':0}\n    for col in df.select_dtypes('object').columns:\n        df.loc[:,col] = df[col].map(code)\n        \n    return df","8521ed8d":"def Imputation(df):\n    df = df.drop(['PassengerId','Name','Cabin','Ticket','Embarked'], axis=1)\n    df = df.dropna(axis=0)\n    \n    return df","a4c7580a":"def pre_processing(df):\n    df = Imputation(df)\n    df = Encodage(df)\n    \n    X = df.drop(['Survived'], axis=1)\n    y = df[\"Survived\"]\n    \n    return X, y","773d0533":"X_train, y_train = pre_processing(df)","8605a9fa":"print(y_train.shape)\nprint(X_train.shape)","7adf57a3":"def Imputation_test(df):\n    #df = df.dropna(axis=0)\n    id_passenger = df[\"PassengerId\"]\n    df = df.drop(['PassengerId','Name','Cabin','Ticket','Embarked'], axis=1)\n    \n    return df,id_passenger","d5f5b34e":"def pre_processing_test(df):\n    df, PassengerId = Imputation_test(df)\n    df = Encodage(df)\n        \n    return df, PassengerId","a146ce74":"X_test, PassengerId = pre_processing_test(Test_set)","a0629e21":"plt.figure()\nsns.heatmap(X_test, cbar=False)","5411427c":"mean_fare = X_test['Fare'].mean()\nmean_fare","c87d173c":"mean_age = X_test['Age'].mean()\nmean_age","3df10c42":"X_test['Fare'].fillna(value=X_test['Fare'].median(), inplace=True)\nX_test['Age'].fillna(value=X_test['Age'].median(), inplace=True)","c7ce5929":"from sklearn.svm import  SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import StandardScaler","52f4e9ac":"model_list = []","14cff575":"preprocessor = make_pipeline(SelectKBest(f_classif, k='all'))","9c4d263a":"randomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nadaboost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nsvm = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=1))\nknn = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())\nbayes = make_pipeline(preprocessor, StandardScaler(), GaussianNB())","b1463a06":"model_list = {'randomForest':randomForest,\n             'adaboost': adaboost,\n             'svm': svm,\n             'knn': knn,\n             'bayes': bayes\n             }","02feeb86":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve","e33cab7a":"predict_list = {}\n\ndef Evaluation(key, model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    predict_list.update({key: y_pred})\n    \n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=4, scoring='accuracy',\n                                            train_sizes=np.linspace(0.1,1,10))\n    \n    plt.figure()\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\n    plt.ylabel('Score')\n    plt.title(key)\n    plt.legend()\n    ","990147a4":"for key, model in model_list.items():\n    Evaluation(key, model)\n    ","30a857bb":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nimport scipy as sc","8e0b4063":"param_svm = [{'svc__C': sc.stats.expon(scale=100), \n                        'svc__gamma': sc.stats.expon(scale=.1),\n                        'svc__kernel': ['rbf']},\n                       {'svc__C': sc.stats.expon(scale=100), \n                        'svc__kernel': ['linear']}]\n                        ","d4b8b41a":"grid_random = RandomizedSearchCV(estimator=svm, param_distributions = param_svm, \n                        cv =5, scoring ='accuracy', refit = True, n_jobs = -1,\n                       random_state=1, n_iter=100)","b735f82d":"grid_random.fit(X_train, y_train)\nprint(grid_random.best_params_)\ny_pred = grid_random.predict(X_test)","43860487":"grid_random.best_score_","c11eb55b":"Evaluation('svm',grid_random.best_estimator_)","4a429fcb":"submission = pd.DataFrame(PassengerId)\nsubmission['Survived'] = y_pred\nsubmission.to_csv('submission.csv', header= True, index= False) \n","f57fa661":"submission.shape","6e692698":"knn","b0bfb135":"param_knn = [{'n_neighbors': np.arange(1,50),\n              'metric': ['euclidean', 'manhattan']}]","b4c2851d":"grid_random_knn = RandomizedSearchCV(KNeighborsClassifier(), param_knn,\n                                     cv=4, n_jobs = 1,\n                                    n_iter=30)","dd625b6e":"grid_random_knn.fit(X_train, y_train)","77f2c623":"print(grid_random_knn.best_params_)\ny_pred = grid_random_knn.predict(X_test)","0d9572d0":"Evaluation('knn',grid_random_knn.best_estimator_)","4a02c935":"grid_random_knn.best_score_","77668f49":"**PRE-PROCESSING**","d5e78a6e":"# **OPTIMIZATION**","4a91ec68":"We will keep SVM model because the SVM model optimizer give the best score 0.83057","8b7cc967":"LINK TARGET \/ SEX, AGE","74f05f5e":"# CONCLUSION","bd00c051":"**SVM - Optimization**\n* we will the best score, the goal is to get score for models","84f47c1d":"**KNN Optimization**","811f8ab0":"EXPLORATORY DATA ANALYSIS"}}