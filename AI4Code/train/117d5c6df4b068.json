{"cell_type":{"1b71bb91":"code","4727283e":"code","abb5c5a7":"code","7156e4cb":"code","def836bf":"code","0c8f1221":"code","5405bc51":"code","aa5fb98d":"code","440ab39e":"code","a94a9528":"code","07891786":"code","5703019b":"code","82cd2797":"code","07e9a78a":"code","672e122c":"code","5d2da482":"code","5c862cf0":"code","9c8c5ec6":"code","382037d5":"code","e4e4c469":"code","af5236cd":"code","68907511":"code","8f411d33":"code","f10d97c3":"code","626409f0":"code","a8eca6dd":"code","7b93158c":"code","57bcf0a0":"code","60899d1e":"code","916f2347":"code","fd1f9f6c":"code","fc6ddfc7":"code","38ca3b34":"code","da6906da":"markdown","b58f1096":"markdown","ea5dbe41":"markdown","17063c63":"markdown","8326e33e":"markdown"},"source":{"1b71bb91":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np","4727283e":"loans = pd.read_csv(\"..\/input\/kiva_loans.csv\")\nmpi = pd.read_csv(\"..\/input\/kiva_mpi_region_locations.csv\")\ntheme = pd.read_csv(\"..\/input\/loan_theme_ids.csv\")\ntheme_region = pd.read_csv(\"..\/input\/loan_themes_by_region.csv\")","abb5c5a7":"loans.head(5)","7156e4cb":"mpi.head(5)","def836bf":"theme.head(5)","0c8f1221":"theme_region.head(5)","5405bc51":"# Loans\n\nprint(loans.shape)\n\n# number of rows\n\nprint(len(loans))\n\n# NAs\n\nloans.isnull().sum()\n\n# % of NAs\n\n(loans.isnull().sum()\/len(loans))*100\n\n# Variables tags, region, funded time and partner id have the most missing values\n\n# Removing tags and funded time as they are not important\n\nloans2 = loans.drop(columns = ['tags', 'funded_time'])\n\n(loans2.isnull().sum()\/len(loans2))*100\n\n# Now removing rows with missing values\n\nloans3 = loans2.dropna()\n\nloans3.shape","aa5fb98d":"# Data pre-processing for formats and currencies\n\n# Selecting the relavant columns\n\nloans4 = loans3[['id', 'funded_amount', 'loan_amount', 'activity', 'sector', 'country_code', 'country', 'region', \\\n                 'partner_id', 'disbursed_time', \\\n                 'term_in_months','lender_count','borrower_genders', 'repayment_interval']]\nloans4.shape\n\n# Changing data formats\n\nloans5= loans4\n\nloans5.is_copy = False\n\nloans5.disbursed_time = loans5.disbursed_time.str[:4]\n\nloans5.disbursed_time.head(5)\n\nloans5.disbursed_time.astype(int).head(5)","440ab39e":"import seaborn as sb\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\n\nloans5.describe()","a94a9528":"loans5.describe(include = 'all')","07891786":"# Basic graphs using seaborn\n\n# Number of loans by sector\n\nplt.figure(figsize=(17,8))\n\nsb.countplot(x=\"sector\", data=loans5, palette=\"Blues_d\");\nplt.title('Number of loans by sector')\nplt.xlabel('sector')\nplt.ylabel('number of loans')\n\n\nplt.show()","5703019b":"# Loan amount given by activity\n\nplt.figure(figsize=(17,8))\n\nactivity_wise = loans5.groupby(by=['activity'])[loans5.columns[2]].sum().sort_values(ascending = False).head(10)\nsb.barplot(activity_wise.values, activity_wise.index, )\nplt.xlabel('loan amount(in $10M)')\nplt.title('Activity wise loan amount')\n\nplt.show()","82cd2797":"# Pre-processing MPI dataset\n\n# Loans\n\nprint(mpi.shape)\n\n# number of rows\n\nprint(len(mpi))\n\n# NAs\n\nmpi.isnull().sum()\n\n# % of NAs\n\n(mpi.isnull().sum()\/len(mpi))*100\n\n# It is a wrong representation of the data which has few inapproriate rows which have to be removeds\n\n# Now removing rows with missing values\n\nmpi2 = mpi.dropna()\n\nmpi2.shape\n\nmpi2.head(10)","07e9a78a":"# Some more pre-processing\n\n# Data type checking for map\n\nprint(mpi2[\"MPI\"].dtype)\nprint(mpi2[\"lat\"].dtype)\nprint(mpi2[\"lon\"].dtype)","672e122c":"# plotting for mpi dataset\n\nimport folium as folium","5d2da482":"plt.figure(figsize=(17,8))\n\ndef plot_mpi_by_region(col_val):\n    # generate a new map\n    folium_map = folium.Map(zoom_start=12,\n                        tiles=\"CartoDB dark_matter\",\n                        width='50%')\n\n    # for each row in the data, add a cicle marker\n    for index, row in mpi2.iterrows():\n\n        # generate the popup message that is shown on click.\n        popup_text = \"World Region:  {}<br> MPI: {}\"\n        popup_text = popup_text.format(row[\"world_region\"],\n                          row[\"MPI\"])\n\n        # generate the popup message that is shown on click.\n    #     popup_text = \"world_region:  {}<br> country: {}<br> region: {}<br> MPI: {}\"\n    #     popup_text = popup_text.format(row[\"world_region\"],\n    #                       row[\"country\"],\n    #                       row[\"region\"],\n    #                       row[\"MPI\"])\n\n        # radius of circles\n        radius = row[\"MPI\"]*2\n\n        # choose the color of the marker\n        if row[col_val]>0.5:\n            # color=\"#FFCE00\" # orange\n            # color=\"#007849\" # green\n            color=\"#EF0225\" # red\n        elif row[col_val]<0.5 and row[col_val]>0.25:\n            # color=\"#0375B4\" # blue\n            # color=\"#FFCE00\" # yellow            \n            color=\"#FCEf00\" # yellow\n        else:\n            color = \"#1BED04\" # green\n            \n\n        # add marker to the map\n        folium.CircleMarker(location=(row[\"lat\"],\n                                      row[\"lon\"]),\n                            radius=radius,\n                            color=color,\n                            popup = popup_text,\n                            fill=True).add_to(folium_map)\n\n    return folium_map\n\n# In the parameter area, enter the column you wish to base your size of marker upon\ntry:\n    mpi_map = plot_mpi_by_region(\"MPI\")\nexcept TypeError:\n    print('please enter a numeric field to get the marker')\n    \nmpi_map","5c862cf0":"# Pre-processing third database\n\n# Themes\n\nprint(theme.shape)\n\n# number of rows\n\nprint(len(theme))\n\n# NAs\n\ntheme.isnull().sum()\n\n# Dropping rows with blank themes\n\ntheme2 = theme.dropna()\n\ntheme2.shape","9c8c5ec6":"# Pre-processing fourth database\n\n# Themes region\n\nprint(theme_region.shape)\n\n# number of rows\n\nprint(len(theme_region))\n\n# NAs\n\ntheme_region.isnull().sum()\n\n# % of NAs\n\n(theme_region.isnull().sum()\/len(theme_region))*100\n\n# It is a wrong representation of the data which has few inapproriate rows which have to be removeds\n\n# Removing geocode_old, geocode, names, lat, lon and mpi_geo\n\ntheme_region2 = theme_region.drop(columns = ['geocode_old', 'geocode', 'names', 'lat', 'lon', 'mpi_geo'])\n\n(theme_region2.isnull().sum()\/len(theme_region2))*100\n\n# Now removing rows with missing values\n\ntheme_region3 = theme_region2.dropna()\n\ntheme_region3.shape\n\ntheme_region3.head(10)","382037d5":"# EDA on loans theme dataset\n\n# Major lenders\n\n# Basic graphs using seaborn\n\n# Number of loans by sector\n\nimport squarify as squarify\n\nplt.figure(figsize=(17,8))\n\n# field_partner = theme_region3.groupby(by=['Field Partner Name'])[theme_region3.columns[1]].count().\\\n#                 sort_values(ascending = False).head(10)\n# sb.barplot(field_partner.values, field_partner.index, orient = \"h\", color = \"brown\")\n# plt.xlabel('Number of loans given')\n# plt.title('Major lenders')\n\n# plt.show()\n\n\nfield_partner = theme_region3['Field Partner Name'].value_counts().sort_values(ascending = False).head(10)\nsquarify.plot(sizes=field_partner.values,label=field_partner.index, value=field_partner.values)\nplt.title('Number of loans given by major field partners')\n\nplt.show()","e4e4c469":"# sb.distplot(theme_region3['rural_pct'], kde = False, rug = True)\n\nplt.hist(theme_region3['rural_pct'], 50, normed = 1, facecolor = 'green')\nplt.xlabel(\"rural percentage\")\nplt.ylabel(\"percentage of data\")\nplt.title(\"Rural percentage histogram\")\n\nplt.show()\n\n# This shows that most of the loans are offered to people living in regions with high rural population","af5236cd":"#### Predictive Analytics\n\n# Good funding in future largely depends on good repayment of loans. A lender whose who knows how his loan will be repayed\n# is in a better position to secure funding for future\n\n# Here we will try to predict what will be the repayment pattern of a loan\n# We will do this using random forest\n\n# Subsetting the dataset for random forest\n\nloans6 = loans5[['loan_amount', 'disbursed_time','term_in_months', 'lender_count', 'repayment_interval']]\n\nloans6.repayment_interval.astype('category')\n\nloans6.head(5)","68907511":"loans6.describe()","8f411d33":"# Splitting the data into test and training\n\nloans6['is_train'] = np.random.uniform(0, 1, len(loans6)) <= .75\n\ntrain, test = loans6[loans6['is_train']==True], loans6[loans6['is_train']==False]\n\n# number of observations in train and test\nprint('Number of observations in the training data:', len(train))\nprint('Number of observations in the test data:',len(test))","f10d97c3":"# List of predictor variables\n\n# Traget valiable is repayment interval\nfeatures = loans6.columns[:4]\n\n# View features\nfeatures","626409f0":"# One-hot encoding of target variable\n\ny = pd.factorize(train['repayment_interval'])[0]\n\n# View target\ny","a8eca6dd":"# Importing libraries\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Initializing a random forest model\n\nmodel_rf = RandomForestClassifier(n_jobs=2, random_state=0)","7b93158c":"# Training the model on train set\n\nmodel_rf.fit(train[features], y)","57bcf0a0":"# Applying to test dataset\n\nmodel_rf.predict(test[features])","60899d1e":"# top 10 obs\n\nmodel_rf.predict_proba(test[features])[0:10]","916f2347":"# Converting back to original forms of repayment intervals\n\npreds = loans6.repayment_interval[model_rf.predict(test[features])]\n\npreds.head(5)","fd1f9f6c":"# View a list of the features and their importance scores\nlist(zip(train[features], model_rf.feature_importances_))","fc6ddfc7":"# Merging loans5 and theme2\n\ncombined  = loans5.join(theme2, on = 'id', how = 'left', rsuffix = '2')\n\ncombined.head(5)","38ca3b34":"# writing out the combined dataset to an output csv file for further analysis\n\ncombined.to_csv('combined_dataset.csv', sep = ',')","da6906da":"**Pre-processing tables and data quality check**","b58f1096":"**The analysis presented below is for Kiva Crowdfunding**\n\n**Goal**\n\nKiva.org is an online crowdfunding platform to extend financial services \nto poor and financially excluded people around the world. Kiva lenders have \nprovided over $1 billion dollars in loans to over 2 million people. In order \nto set investment priorities, help inform lenders, and understand their target \ncommunities, knowing the level of poverty of each borrower is critical. However, \nthis requires inference based on a limited set of information for each borrower.\n\nIn this problem we are trying to estimate the level of poverty of every borrower \nto help lenders and undertand their target communities\n\n**Datasets**\n\nThere are 4 datasets involved in this analysis\nKiva_loans - loan dataset from Kiva\nKiva_mpi_region_locations - The mpi of the regions along with geo-locations\nLoan_theme_ids - The themes of the loans\nLoan_themes_by_region - Region-wise loan themess","ea5dbe41":"**Exploratory Data Analysis**","17063c63":"**Applying random forest to find the major factors influencing the loan repayment**","8326e33e":"**Reading in the datasets**"}}