{"cell_type":{"8afde737":"code","468697ce":"code","35024c1c":"code","68626ed6":"code","29083b3e":"code","983c1450":"code","09832f01":"code","8dcb6efb":"code","2ea6a421":"code","28d1a3ca":"code","7d8495aa":"code","9e5d5274":"code","d213d531":"code","2bc029fd":"code","cd62e4c6":"code","dd3ef391":"code","f902453a":"code","634de317":"code","335a2f7c":"code","3cd50296":"code","53639ceb":"code","a84039d8":"code","4189b1cb":"code","9f2e9e88":"code","67dd2cbb":"code","6de28cf7":"code","1df49df6":"markdown","74319672":"markdown","026e0727":"markdown","c3fe5cf6":"markdown","87a79bcc":"markdown","752109a1":"markdown","a7c6bed3":"markdown","b8a6679b":"markdown","2b743982":"markdown","4a9e9a05":"markdown"},"source":{"8afde737":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nplt.style.use('fivethirtyeight')\npalette = 'tab10'\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","468697ce":"train = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","35024c1c":"train = train.sample(frac=.1)","68626ed6":"structures = pd.read_csv(\"..\/input\/structures.csv\")\nstructures.head()","29083b3e":"mulliken = pd.read_csv(\"..\/input\/mulliken_charges.csv\")\nmulliken.head()","983c1450":"potential_energy = pd.read_csv(\"..\/input\/potential_energy.csv\")\npotential_energy.head()","09832f01":"magnetic_shielding = pd.read_csv(\"..\/input\/magnetic_shielding_tensors.csv\")\nmagnetic_shielding.head()","8dcb6efb":"test = pd.read_csv(\"..\/input\/test.csv\")\ntest.head()","2ea6a421":"train = pd.merge(train, structures, 'inner', left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'] )\ntrain = pd.merge(train, structures, 'inner', left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\n\ntrain = pd.merge(train, mulliken, 'inner', left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'])\ntrain = pd.merge(train, mulliken, 'inner', left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\ntrain = pd.merge(train, potential_energy, 'inner', 'molecule_name')\ntrain = pd.merge(train, potential_energy, 'inner', 'molecule_name')\ntrain = pd.merge(train, magnetic_shielding, 'inner', left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'])\ntrain = pd.merge(train, magnetic_shielding, 'inner', left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\n\n\ntest = pd.merge(test, structures, 'inner', left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'])\ntest = pd.merge(test, structures, 'inner', left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\n\ntrain = train.drop(['atom_index_x', 'atom_index_y'], 1)\ntest = test.drop(['atom_index_x', 'atom_index_y'], 1)","28d1a3ca":"train.head()","7d8495aa":"test.count()","9e5d5274":"train[train.columns[:-1]] .nunique()","d213d531":" train.isna().sum()","2bc029fd":"fig, ax = plt.subplots(1,2 , figsize=(15,6))\nsize_molecule = pd.pivot_table(train, index=['molecule_name'], aggfunc='size')\nsns.distplot(size_molecule, ax=ax[0])\nax[0].set_title('Train Distribution of molecule duplicates')\n\nsize_molecule = pd.pivot_table(test, index=['molecule_name'], aggfunc='size')\nsns.distplot(size_molecule, ax=ax[1])\nax[1].set_title('Test Distribution of molecule duplicates')\nplt.tight_layout()\nplt.show()","cd62e4c6":"liste_mol_train = train['molecule_name'].unique()\nlen(test[test['molecule_name'].isin(liste_mol_train)])","dd3ef391":"table = pd.pivot_table(train, 'scalar_coupling_constant', ['atom_1', 'atom_2', 'type'] ).reset_index()\n\nsubmission = pd.merge(test, table, 'left', ['atom_1', 'atom_2', 'type'])\ntable","f902453a":"submission.head()","634de317":"submission['scalar_coupling_constant'].dropna().count()","335a2f7c":"fig, ax = plt.subplots(1,2 , figsize=(15,6))\n\nsns.countplot(y='type', data=train, order=train['type'].value_counts().index, ax=ax[0], palette=palette)\nsns.barplot('scalar_coupling_constant', 'type', data=train, order=train['type'].value_counts().index, palette=palette, ax=ax[1])\nplt.tight_layout()\nplt.show()","3cd50296":"fig, ax = plt.subplots(1,2 , figsize=(15,6))\n\nsns.barplot('scalar_coupling_constant', 'atom_x', data=train, ax=ax[0])\nsns.barplot('scalar_coupling_constant', 'atom_y', data=train, ax=ax[1])\nplt.tight_layout()\nplt.show()","53639ceb":"fig, ax = plt.subplots(1,2 , figsize=(15,6))\n\nsns.barplot('scalar_coupling_constant', 'atom_x', data=train, ax=ax[0])\nsns.barplot('scalar_coupling_constant', 'atom_y', data=train, ax=ax[1])\nplt.tight_layout()\nplt.show()","a84039d8":"train.columns","4189b1cb":"fig, ax = plt.subplots(1,3 , figsize=(15,6))\nsns.distplot(train['x_x'], ax=ax[0])\nsns.distplot(train['y_x'], ax=ax[1])\nsns.distplot(train['z_x'], ax=ax[2])\n\nplt.tight_layout()\nplt.show()","9f2e9e88":"fig, ax = plt.subplots(1,3 , figsize=(15,6))\nsns.distplot(train['x_y'], ax=ax[0])\nsns.distplot(train['y_y'], ax=ax[1])\nsns.distplot(train['z_y'], ax=ax[2])\n#ax[0].set_title('Train Distribution of molecule duplicates')\n\nplt.tight_layout()\nplt.show()","67dd2cbb":"g=sns.FacetGrid(train, col=\"atom_y\", height=4, aspect=1)\ng.map(sns.distplot, \"x_y\", hist=False)\nplt.show()\n\ng=sns.FacetGrid(train, col=\"atom_y\", height=4 aspect=1)\ng.map(sns.distplot, \"y_y\", hist=False)\nplt.show()\n\n\ng=sns.FacetGrid(train, col=\"atom_y\", height=4, aspect=1)\ng.map(sns.distplot, \"z_y\", hist=False)\nplt.show()","6de28cf7":"train.head()","1df49df6":"Tr\u00e8s grande amplitude de la sortie, pr\u00e9voir la standardisation","74319672":"Nombre de sample cons\u00e9quent, Faire juste un split Train\/test\n\nPossible distribution Log Normal pour *Y*","026e0727":"Aucune mol\u00e9cule du *train* dans le *test*","c3fe5cf6":"#### Create a baseline model","87a79bcc":"# Load Data ","752109a1":"#### Score de 1.30","a7c6bed3":"g=sns.FacetGrid(train, col=\"type\", height=6, aspect=1)\ng.map(sns.distplot, \"x_y\", hist=False)","b8a6679b":"Le comptage suit une loi normale avec une moyenne ~50.\n\nJe peux cr\u00e9\u00e9r une baseline en predisant la moyenne par mol\u00e9cule.","2b743982":"# EDA ","4a9e9a05":"submission = submission[['id', 'scalar_coupling_constant']]\nsubmission.to_csv('submission.csv', index=False)"}}