{"cell_type":{"6e618148":"code","d47828b8":"code","3946f3de":"code","451a8369":"code","e6b95dfc":"code","a19f1af7":"code","b3fdfb15":"code","e3650ab7":"code","9fa5f62e":"code","751a0747":"code","266367b5":"code","02c16e1a":"code","e4be1562":"code","a706c43c":"code","60fe8d03":"code","8ccad08e":"code","78355c70":"code","3d460468":"code","7a2899c9":"code","09934e30":"code","995aa8e2":"code","55a9329e":"code","75264150":"markdown","568ff11e":"markdown","3a09cf1f":"markdown","07af8b07":"markdown","18d1a8c3":"markdown"},"source":{"6e618148":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# import data set\ndf = pd.read_csv('\/kaggle\/input\/clinical-dataset-of-the-cypguides-trial\/Dataset.csv',delimiter=',')\n\ndf.head(2)","d47828b8":"# take a look at the data formats\ndf.info()","3946f3de":"# what columns do we have\ndf.columns","451a8369":"# target variable description\ndf.LOS.describe()","e6b95dfc":"# los is in hours lets convert it to full days\ndf.LOS = df.LOS.apply(lambda x: round(x\/24,0))","a19f1af7":"# most patients stay around 7 days\ndf.LOS.describe()","b3fdfb15":"# right skewed distribution\n# this means, that although most of the patients are in care for 7-8 days few of them are in care up to 116 days\nimport seaborn as sns\nsns.distplot(df.LOS,kde=True,bins=30)","e3650ab7":"# cast the values to categorical values and \n# substitute them with dummy numerical values in order to make them processable by our models\ndf[\"GENDER\"] = df[\"GENDER\"].astype('category').cat.codes\ndf[\"RACE\/ETHNICITY\"] = df[\"RACE\/ETHNICITY\"].astype('category').cat.codes\ndf['MD'] = df['MD'].astype('category').cat.codes\ndf['Assignment'] = df['Assignment'].astype('category').cat.codes\ndf['EMR'] = df['EMR'].astype('category').cat.codes\ndf['Therapeutic Guidances'] = df['Therapeutic Guidances'].astype('category').cat.codes\n","9fa5f62e":"# look at the new data set\ndf.head(2)","751a0747":"# take a look at the Diagnosis column\n# here we can see that we can combine some diagnosis together \n# also the frequency and severity of the illness is kept in this text field\ndf.Diagnosis.value_counts()","266367b5":"# put similar diagnosis types together\n# diagnosis_type -> states the main diagnosis given\n# frequency      -> states the frequency the illness appears\n# severity       -> states the severity of the illness\n# features       -> special \"features\" of the illness e.g. anxiety or psychotic features\n\nfor idx,row in df.iterrows():\n    if row[\"Diagnosis\"] == \"MDD, Recurrent, Severe Without Psychotic Features\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = None\n    elif row[\"Diagnosis\"] == \"Depressive Disorder NOS\":\n        df.loc[idx,\"diagnosis_type\"] = \"depression\"\n    elif row[\"Diagnosis\"] == \"MDD, Recurrent, Unspecified\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n    elif row[\"Diagnosis\"] == \"MDD, Single Episode,Severe Without Psychotic Features\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = None\n    elif row[\"Diagnosis\"] == \"MDD\" or row[\"Diagnosis\"] == \"Unspecified Depressive Disorder\" or row[\"Diagnosis\"] == \"Major depression, melancholic type\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n    elif row[\"Diagnosis\"]==\"row MDD, Single Episode, Severe With Psychotic Features\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = \"psychotic\"\n    elif row[\"Diagnosis\"] == \"MDD, Recurrent, Severe With Psychotic Features\" \\\n        or row[\"Diagnosis\"] == \"Major depressive disorder, recurrent episode, severe, with psychosis\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = \"psychotic\"\n    elif row[\"Diagnosis\"] == \"MDD, Single Episode, Unspecified\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n    elif row[\"Diagnosis\"] == \"MDD, Recurrent, Moderate\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"moderate\"\n    elif row[\"Diagnosis\"] == \"MDD, Recurrent, Chronic\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"chronic\"\n    elif row[\"Diagnosis\"] == \"MDD, recurrent, severe\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"severe\"\n    elif row[\"Diagnosis\"] == \"Severe episode of recurrent major depressive disorder, without psychotic features\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = None\n    elif row[\"Diagnosis\"] == \"MDD, Single Episode, Moderate\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n        df.loc[idx,\"severity\"] = \"moderate\"\n    elif row[\"Diagnosis\"] == \"\\tDepression, unspecified type \":\n        df.loc[idx,\"diagnosis_type\"] = \"depression\"\n    elif row[\"Diagnosis\"] == \"MDD, Recurrent, Mild\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"mild\"\n    elif row[\"Diagnosis\"] == \"MDD, Single Episode, Mild\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n        df.loc[idx,\"severity\"] = \"mild\"\n    elif row[\"Diagnosis\"] == \"MDD, recurrent episodes\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n    elif row[\"Diagnosis\"] == \"Depression with suicidal ideation\":\n        df.loc[idx,\"diagnosis_type\"] = \"depression\"\n        df.loc[idx,\"severity\"] = \"severe\"\n    elif row[\"Diagnosis\"] == \"Bipolar II Disorder\":\n        df.loc[idx,\"diagnosis_type\"] = \"bipolar_disorder\"\n    elif row[\"Diagnosis\"] == \"Mood Disorder NOS\":\n        df.loc[idx,\"diagnosis_type\"] = \"mood_disorder\"\n    elif row[\"Diagnosis\"] == \"Major depressive disorder, recurrent episode with anxious distress\" or row[\"Diagnosis\"] == \"\\tMDD, recurrent episode with anxious distress\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"features\"] = \"anxiety\"\n    elif row[\"Diagnosis\"] == \"MDD, single episode with psychotic features, mood-conguent\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"single\"\n        df.loc[idx,\"features\"] = \"psychotic\"\n    elif row[\"Diagnosis\"] == \"Adjustment Disorder With Depressed Mood\":\n        df.loc[idx,\"diagnosis_type\"] = \"adjustment_disorder\"\n    elif row[\"Diagnosis\"] == \"Major depressive disorder, recurrent, with postpartum onset\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n    elif row[\"Diagnosis\"] == \"MDD, recurrent, severe with atypical features\":\n        df.loc[idx,\"diagnosis_type\"] = \"major_depressive_disorder\"\n        df.loc[idx,\"frequency\"] = \"recurrent\"\n        df.loc[idx,\"severity\"] = \"severe\"\n        df.loc[idx,\"features\"] = \"atypical\"\n    elif row[\"Diagnosis\"] == \"Schizoaffective Disorder\":\n        df.loc[idx,\"diagnosis_type\"] = \"schizoaffective_disorder\"\n    elif row[\"Diagnosis\"] == \"Dissociative Disorder\":\n        df.loc[idx,\"diagnosis_type\"] = \"dissociative_disorder\"\n\nprint(\"Count of unique diagnosis: \")\nprint(df.diagnosis_type.value_counts(dropna=False))\nprint(\"\")\nprint(\"Count of frequencies: \")\nprint(df.frequency.value_counts(dropna=False))\nprint(\"\")\nprint(\"Count of severity stages: \")\nprint(df.severity.value_counts(dropna=False))\nprint(\"\")\nprint(\"Count of features: \")\nprint(df.features.value_counts(dropna=False))\n","02c16e1a":"# cast the newly created values to categorical values \n# and substitute them with dummy numerical values\ndf['diagnosis_type'] = df['diagnosis_type'].astype('category').cat.codes\ndf['frequency'] = df['frequency'].astype('category').cat.codes\ndf['severity'] = df['severity'].astype('category').cat.codes\ndf['features'] = df['features'].astype('category').cat.codes","e4be1562":"# drop the Diagnosis and ID columns as the have no value for the regression\ndf.drop([\"Diagnosis\",\"ID\"], axis=1, inplace=True)","a706c43c":"# columns in the new data set\ndf.columns","60fe8d03":"# split the data in train and test set\nfrom sklearn.model_selection import train_test_split\n\nX=df.drop(columns=\"LOS\") \ny=df[\"LOS\"] # target feature\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True) # 20% test data\n\n\n","8ccad08e":"# we have 1200 observations in the training set and 300 in the test set\nX_train.shape, y_train.shape","78355c70":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# define parameter space\nmax_iter = np.arange(100, 3000, step=500)\n\nparameter_space = {\n    'hidden_layer_sizes': [(20,),(128,64,32,16,4), (64,32,16,8,4), (32,16,8,4,2), (16,8,4,2,1), (100)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.001, 0.05,1, 2],\n    'learning_rate': ['constant','adaptive'],\n    'max_iter': max_iter\n}\n\n# define model\nmodel = MLPRegressor(random_state=0)\n\n# conduct Randomized Gridsearch with 3-fold Cross Validation\n# Randomized Gridsearch is faster than normal GridSearch \n# tip: use RGS for the dirty work to find a parameter range and fine tune with normal Gridsearch for the best results\nclf = RandomizedSearchCV(model, parameter_space, n_jobs=-1, cv=3, verbose=1)\nclf.fit(X_train, y_train)\n\n# get best hyperparameter combination - best estimator\nprint(clf.best_estimator_)","3d460468":"model = clf.best_estimator_\n\n# predict the values in the test set with the created model\ny_pred = model.predict(X_test)\n\nprint(f\"Mean squared error (MSE): \", round(mean_squared_error(y_test, y_pred),2))\nprint(f\"Coefficient of determination (R^2): \", round(r2_score(y_test, y_pred),2))\n\nsns.scatterplot(y_test, y_pred, alpha=0.5, )\nplt.xlabel('Actual Value')\n# Set y-axis label\nplt.ylabel('Predicted Value')","7a2899c9":"print(df.columns)","09934e30":"\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# define parameter space that is to be searched\nn_estimators = np.arange(100, 2000, step=100)\nmax_features = [\"auto\", \"sqrt\", \"log2\"]\nmax_depth = list(np.arange(10, 100, step=10)) + [None]\nmin_samples_split = np.arange(2, 10, step=2)\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nparameter_space = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\nmodel = RandomForestRegressor(random_state=0)\n\nclf = RandomizedSearchCV(model, parameter_space, n_jobs=-1, cv=3)\nclf.fit(X_train, y_train)\n\n# get best hyperparameter combination - best estimator\nprint(clf.best_estimator_)","995aa8e2":"model = clf.best_estimator_\n\n# predict the values in the test set with the created model\ny_pred = model.predict(X_test)\n\nprint(f\"Mean squared error (MSE): \", round(mean_squared_error(y_test, y_pred),2))\nprint(f\"Coefficient of determination (R^2): \", round(r2_score(y_test, y_pred),2))\n\nsns.scatterplot(y_test, y_pred, alpha=0.5, )\nplt.xlabel('Actual Value')\n# Set y-axis label\nplt.ylabel('Predicted Value')","55a9329e":"# plot feature importance\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","75264150":"# Multi Layer Perceptron Regressor","568ff11e":"# Conclusion\n\n**apparently the age, medication AB small indicators for the LOS however, the number of Administrations (medication given) is the by far the most important predictor**\n- Interestingly enough the diagnosis_type was no real help**\n- only the severity of the illness has a little impact**\n- a further, in depth, feature engineering is needed in order to achieve better results**","3a09cf1f":"# **Diagnosis Feature Engineering**\n\n**A key feature of the data set is the free text Diagnosis column. In order to make sense of this feature I clustered some diagnosis together and created new features indicating the**\n1. diagnosis_type -> which states the main diagnosis given\n2. frequency      -> which states the frequency the illness appears\n3. severity       -> which states the severity of the illness\n4. features       -> special \"features\" of the illness e.g. anxiety or psychotic features","07af8b07":"# Introduction\n\nThe following data set is a first template for a regression of the LOS Feature (Length of Stay). I did not further plot the individual features or their relationsship to each other as this is not the scope of this notebook. Some work regarding an EDA was already provided by @mpwolke.\n\nWith this notebook I wanted to deliver a first template for a regression of the LOS feature. \nTo achieve some good results I used a MLPRegressor and performed a Random Gridsearch for hyperparameter tuning.\n\nMost of the work here went in the feature engineering of the free text Diagnosis feature which in my opinion can be one of the key indicators for the LOS feature.\n\nFeel free to comment on my work so that I and you can learn something from this. \n\nI hope you have fun reading this notebook. \n\nCheers Dominik\n","18d1a8c3":"# Random Forest Regressor"}}