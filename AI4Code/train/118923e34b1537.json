{"cell_type":{"54dac637":"code","ab0dfa3e":"code","e3f2e912":"code","2b133850":"code","67822c60":"code","0f48b901":"code","840472a2":"code","e31900c2":"code","8eed4272":"code","b7a65f61":"code","8984bc26":"code","c465102b":"code","6e4724fc":"code","d0e111e5":"code","973413f8":"code","4113ca4d":"code","041dc14c":"code","9b70948b":"code","5c19f998":"code","dd272346":"code","d49b8a3d":"code","b148b1d9":"code","95a60b0f":"code","50992c0a":"code","6b4107cb":"code","6ece03d9":"code","357adf47":"code","4a44a45f":"code","5da3ed3f":"code","9ef79516":"code","6df0c777":"code","dd336318":"code","4401ac93":"code","49e50998":"code","4deea5ec":"code","55ad9727":"code","9ae9f590":"code","c57bb2d8":"code","0bcd1a96":"code","91ffa0fb":"code","2504b339":"code","f059a26b":"code","34bcc67d":"code","2585f8a1":"markdown","865bcee7":"markdown","9b7058b4":"markdown","938c195e":"markdown","9d7f0046":"markdown","d7ba21a0":"markdown","6e721ba0":"markdown","6f64525a":"markdown","50183cd5":"markdown","15137719":"markdown","61e7bd2f":"markdown"},"source":{"54dac637":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab0dfa3e":"df1 = pd.read_csv('..\/input\/used-car-price-data\/car_data.csv')\ndf2 = pd.read_csv('..\/input\/used-car-price-data\/model_data.csv')","e3f2e912":"df1.head()","2b133850":"len(df1)","67822c60":"df2.head()","0f48b901":"len(df2)","840472a2":"df=df1.merge(df2,left_on='Model', right_on='Model')","e31900c2":"df.head()","8eed4272":"len(df)","b7a65f61":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom datetime import date\nt = date.today()\nt_date=t.strftime(\"%d-%m-%Y\")\ny = t.strftime(\"%Y\")","8984bc26":"df['car_old']=df['Year'].apply(lambda x: int(y)-x)","c465102b":"price=[]\nrep=['Lakh','Lakhs','Rs.',',']\nfor i in df['Current Price']:\n    if type(i) is str:\n        for j in rep:\n            i=i.replace(j,'')\n        price.append(float(i))\n    elif type(i) is float:\n        price.append(i)\n    \ndf['Price']=price      \ndf=df[df['Price']!=0]","6e4724fc":"price=[]\nfor i in df['Price']:\n    #print (i)\n    if i\/\/10 <= 100.0:\n        price.append(round(i*100000,2))\n    else:\n        price.append(round(i,2))\n    \ndf['Price']=price      \n","d0e111e5":"insu =[]\nfor i in df['Insurance']:\n    if (i=='Insurance Expired') | (i=='Expired'):\n        insu.append('Expired')\n    elif str(i) <t_date:\n        insu.append('Expired')\n    elif str(i) >=t_date:\n        insu.append('Current')\n    else:\n        insu.append(i)\ndf['Insurance_status']=insu\ndf=df.drop('Insurance',axis=1)\ndf=df.drop('Current Price',axis=1)","973413f8":"import re\ndf['company']=df['Model'].apply(lambda x: re.findall(r\"[A-Z][^A-Z]*\",x)[0])\n\ndf['company']=df['company'].apply(lambda x: 'Hyundai' if x =='Hyundaii20' else x)\ndf['company']=df['company'].apply(lambda x: 'Hyundai' if x =='Hyundaii10' else x)\ndf['company']=df['company'].apply(lambda x: 'BMW' if x is 'B' else x)\ndf['company']=df['company'].apply(lambda x: 'MGHECTORSHARPDCT' if x is 'M' else x)","4113ca4d":"df.head()","041dc14c":"df['Insurance']=df['Insurance_status'].apply(lambda x: 1 if x=='Current' else 0)","9b70948b":"df.drop(labels=['Year'], axis=1, inplace=True)\ndf.drop('Insurance_status', axis=1,inplace=True)","5c19f998":"df.head()","dd272346":"df['Transmission'].value_counts()","d49b8a3d":"df['Transmission']=df['Transmission'].apply(lambda x: 1 if x=='AUTOMATIC' else 0)","b148b1d9":"df['Fuel Type'].value_counts()","95a60b0f":"#since the CNG & LPG are less consuming fueal type, i hope we can consider the Pertol+CNG & Petrol+LPG as pertol vechile\n#Diesel -- 1\n#Petrol -- 0\n\ndf['Fuel Type']=df['Fuel Type'].apply(lambda x: 1 if x=='Diesel' else 0)","50992c0a":"df.head()","6b4107cb":"df.dropna(axis=0, inplace=True)","6ece03d9":"df.corr()['Selling Price'].sort_values()","357adf47":"fig = px.scatter_3d(df, x='Selling Price', y='Car Condition', z='Price', color='Selling Price')\nfig.show()","4a44a45f":"sns.heatmap(df.corr(), annot=True)","5da3ed3f":"sns.boxplot(df['Selling Price'])","9ef79516":"df.head()","6df0c777":"num=['Selling Price','Kilometers Driven','Car Condition','car_old','Price']","dd336318":"from scipy import stats\nz_score = np.abs(stats.zscore(df[num]))\nfiltered = (z_score <2).all(axis=1)\ndf=df[filtered]","4401ac93":"df.shape","49e50998":"X=df.drop('Selling Price', axis=1)\ny=df['Selling Price']\ncat=X.select_dtypes(include='object').columns\nnum=X.select_dtypes(exclude='object').columns","4deea5ec":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,  random_state=42, shuffle=True)","55ad9727":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\ncol_transfer = ColumnTransformer([('cat_col',OneHotEncoder(sparse=False),cat),('num_col',StandardScaler(),num)], remainder='passthrough')","9ae9f590":"col_transfer.fit(X)\nX_train=col_transfer.transform(X_train)\nX_test = col_transfer.transform(X_test)","c57bb2d8":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n","0bcd1a96":"test_residual = y_test - pred\nsns.scatterplot(x=y_test, y=test_residual)\nplt.axhline(y=0,color='r',ls='--')","91ffa0fb":"sns.distplot(test_residual)","2504b339":"from sklearn.linear_model import ElasticNet,Lasso,Ridge, SGDRegressor, LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nmodel = [ElasticNet(),Lasso(),Ridge(), SGDRegressor(), SVR(), RandomForestRegressor(), AdaBoostRegressor()]\nfor i in model[0:4]:\n    gride = GridSearchCV(estimator=i, cv=10, param_grid={'alpha': [0.00001,0.0001,0.001,0.01,0.1,1,1.10, 10,100]}, scoring='r2')\n    gride.fit(X_train, y_train)\n    pred = gride.predict(X_test)\n    print(\"Regression: {}\\n\".format(i))\n    print(\"Best Score: {}\\n\".format(np.round(gride.best_score_,2)*100))\n    print(\"Best Param: {}\\n\".format(gride.best_params_,2))\n    print(\"R2 score from Predict: {}\".format(np.round(r2_score(y_test, pred),2)))\n    ","f059a26b":"from sklearn.model_selection import cross_val_score\ndef get_valdiation(model):\n    cv=cross_val_score(model,X_train,y_train,cv=10)\n    model.fit(X_train,y_train)\n    pred=model.predict(X_test)\n    print(\"Regression: {} \\n\".format(model))\n    print(\"Score: {:.2f} %\".format(np.mean(cv)*100))\n    print(\"Standard deviation: {:.2f}\".format(np.std(cv)))\n    print(\"R2 score from Predict: {} \\n\\n\".format(np.round(r2_score(y_test, pred),2)))\n    test_residual = y_test - pred\n    sns.scatterplot(x=y_test, y=test_residual)\n    plt.axhline(y=0,color='r',ls='--')\n    plt.title(\"Regressor : {}\".format(model))\n    plt.show()\n    sns.distplot(test_residual)\n    plt.show()","34bcc67d":"model = [ElasticNet(alpha=0.001),Lasso(alpha=10),Ridge(alpha=1), SGDRegressor(), RandomForestRegressor(), AdaBoostRegressor(), LinearRegression()]\nfor i in model:\n    get_valdiation(i)","2585f8a1":"Create price column from Current price column","865bcee7":"Transmission columns consist of junk values other than Automatic or Manual Tansmission. lets us replace the Junk values with \"MANUAL\" assuming the cars are Manual Tansmission. \n1. Automatic -- 1\n2. Manual --0","9b7058b4":"# Read Data","938c195e":"# Data Cleaning","9d7f0046":"#Find how many year old","d7ba21a0":"# Column Transfer","6e721ba0":"# Explore the Target feature","6f64525a":"Merge 2 tables as one dataset by column 'Model'","50183cd5":"Update Insurance column","15137719":"# Conclusion: \nRandomForest Regressor works well for this problem with 85% accuracy","61e7bd2f":"# Train Test Split"}}