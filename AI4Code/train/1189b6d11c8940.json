{"cell_type":{"83941d54":"code","c414890a":"code","9898d25f":"code","56009af4":"code","0071d1d4":"code","a0db48cb":"code","76678149":"code","a603c371":"code","1d5309b9":"code","ad0f1ae9":"code","bd76384a":"code","c1afa9f7":"code","30241ed4":"code","35a47710":"code","ff7517a6":"code","2aee8949":"code","dc13f369":"code","7c9dc306":"code","c8e93c88":"code","c176d95a":"markdown","6f486db3":"markdown","ee76fd99":"markdown","9220bef5":"markdown","08e05e17":"markdown","84116393":"markdown","240d989d":"markdown","6ae25741":"markdown","f8dea3a0":"markdown","490cf2c5":"markdown","ac47cc9b":"markdown","c93cebaf":"markdown","cbaca387":"markdown","0824569b":"markdown","75aaf1c3":"markdown","85100aef":"markdown","73df85c9":"markdown","b3e02f6f":"markdown"},"source":{"83941d54":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\n\nfrom scipy.misc import imread, imresize\nfrom skimage.transform import resize\nfrom tqdm import tqdm\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import Xception\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Activation, Dense, Multiply, Input\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam  \nfrom keras import backend as K\n\nfrom itertools import chain\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c414890a":"path_to_train = '..\/input\/train\/'\ndata = pd.read_csv('..\/input\/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","9898d25f":"class DataGenerator:\n    def __init__(self):\n        self.image_generator = ImageDataGenerator(rescale=1. \/ 255,\n                                     vertical_flip=True,\n                                     horizontal_flip=True,\n                                     rotation_range=180,\n                                     fill_mode='reflect')\n    def create_train(self, dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            random_indexes = np.random.choice(len(dataset_info), batch_size)\n            batch_images1 = np.empty((batch_size, shape[0], shape[1], shape[2]))\n            batch_images2 = np.empty((batch_size, shape[0], shape[1], shape[2]))\n            batch_labels = np.zeros((batch_size, 28))\n            for i, idx in enumerate(random_indexes):\n                image1, image2 = self.load_image(\n                    dataset_info[idx]['path'], shape)\n                batch_images1[i] = image1\n                batch_images2[i] = image2\n                batch_labels[i][dataset_info[idx]['labels']] = 1\n            yield [batch_images1, batch_images2], batch_labels\n            \n    \n    def load_image(self, path, shape):\n        image_red_ch = skimage.io.imread(path+'_red.png')\n        image_yellow_ch = skimage.io.imread(path+'_yellow.png')\n        image_green_ch = skimage.io.imread(path+'_green.png')\n        image_blue_ch = skimage.io.imread(path+'_blue.png')\n\n        image1 = np.stack((\n            image_red_ch, \n            image_yellow_ch, \n            image_blue_ch), -1)\n        image2 = np.stack((\n            image_green_ch, \n            image_green_ch, \n            image_green_ch), -1)\n        image1 = resize(image1, (shape[0], shape[1], 3), mode='reflect')\n        image2 = resize(image2, (shape[0], shape[1], 3), mode='reflect')\n        return image1.astype(np.float), image2.astype(np.float)","56009af4":"# create train datagen\ntrain_datagen = DataGenerator()\n\ngenerator = train_datagen.create_train(\n    train_dataset_info, 5, (299,299,3))","0071d1d4":"images, labels = next(generator)\nimages1, images2 = images\nfig, ax = plt.subplots(2,5,figsize=(25,15))\nfor i in range(5):\n    ax[0, i].imshow(images1[i])\nfor i in range(5):\n    ax[1, i].imshow(images2[i])\nprint('min: {0}, max: {1}'.format(images1.min(), images1.max()))","a0db48cb":"# from https:\/\/www.kaggle.com\/kmader\/rgb-transfer-learning-with-inceptionv3-for-protein\ndata['target_list'] = data['Target'].map(lambda x: [int(a) for a in x.split(' ')])\nall_labels = list(chain.from_iterable(data['target_list'].values))\nc_val = Counter(all_labels)\nn_keys = c_val.keys()\nmax_idx = max(n_keys)\ndata['target_vec'] = data['target_list'].map(lambda ck: [i in ck for i in range(max_idx+1)])\nfrom sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(data, \n                 test_size = 0.2, \n                  # hack to make stratification work                  \n                 stratify = data['Target'].map(lambda x: x[:3] if '27' not in x else '0'))\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')\n\n\n","76678149":"train_dataset_info = []\nfor name, labels in zip(train_df['Id'], train_df['Target'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)\nvalid_dataset_info = []\nfor name, labels in zip(valid_df['Id'], valid_df['Target'].str.split(' ')):\n    valid_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\nvalid_dataset_info = np.array(valid_dataset_info)\nprint(train_dataset_info.shape, valid_dataset_info.shape)","a603c371":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\ntrain_sum_vec = np.sum(np.stack(train_df['target_vec'].values, 0), 0)\nvalid_sum_vec = np.sum(np.stack(valid_df['target_vec'].values, 0), 0)\nax1.bar(n_keys, [train_sum_vec[k] for k in n_keys])\nax1.set_title('Training Distribution')\nax2.bar(n_keys, [valid_sum_vec[k] for k in n_keys])\n_ = ax2.set_title('Validation Distribution')","1d5309b9":"def create_model(input_shape, n_out):\n    inp_image = Input(shape=input_shape)\n    inp_mask = Input(shape=input_shape)\n    pretrain_model_image = InceptionResNetV2(include_top=False, weights='imagenet',pooling='max')\n    pretrain_model_image.name='xception_image'\n    pretrain_model_mask = InceptionResNetV2(include_top=False, weights='imagenet',pooling='max')\n    pretrain_model_mask.name='xception_mask'\n    \n    \n    x = Multiply()([pretrain_model_image(inp_image), pretrain_model_mask(inp_mask)])\n    out = Dense(n_out, activation='sigmoid')(x)\n    model = Model(inputs=[inp_image, inp_mask], outputs=[out])\n\n    return model","ad0f1ae9":"import tensorflow as tf\ndef f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)","bd76384a":"keras.backend.clear_session()\n\nmodel = create_model(input_shape=(299,299,3), n_out=28)\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc', f1])\n\nmodel.summary()","c1afa9f7":"epochs = 9; batch_size = 12\ncheckpointer = ModelCheckpoint(\n    '..\/working\/Xception.model', \n    verbose=2, \n    save_best_only=True)\n\n\n# create train and valid datagens\ntrain_generator = train_datagen.create_train(\n    train_dataset_info, batch_size, (299,299,3))\nvalidation_generator = train_datagen.create_train(\n    valid_dataset_info, batch_size, (299,299,3))\nK.set_value(model.optimizer.lr, 0.0002)\n# train model\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=len(train_df)\/\/batch_size,\n    validation_data=validation_generator,\n    validation_steps=len(valid_df)\/\/batch_size\/\/10,\n    epochs=epochs, \n    verbose=1,\n    callbacks=[checkpointer])","30241ed4":"fig, ax = plt.subplots(1, 2, figsize=(15,5))\nax[0].set_title('loss')\nax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax[1].set_title('acc')\nax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\nax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\nax[0].legend()\n_ = ax[1].legend()","35a47710":"submit = pd.read_csv('..\/input\/sample_submission.csv')","ff7517a6":"%%time\npredicted = []\nfrom tqdm import tqdm_notebook\nfor name in tqdm(submit['Id']):\n    path = os.path.join('..\/input\/test\/', name)\n    image1, image2 = train_datagen.load_image(path, (299,299,3))\n    score_predict = model.predict([image1[np.newaxis], image2[np.newaxis]])[0]\n    label_predict = np.arange(28)[score_predict>=0.5]\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    predicted.append(str_predict_label)","2aee8949":"submit['Predicted'] = predicted\nsubmit.to_csv('submission.csv', index=False)","dc13f369":"name_label_dict = {\n    0:  \"Nucleoplasm\",  \n    1:  \"Nuclear membrane\",   \n    2:  \"Nucleoli\",   \n    3:  \"Nucleoli fibrillar center\",   \n    4:  \"Nuclear speckles\",\n    5:  \"Nuclear bodies\",   \n    6:  \"Endoplasmic reticulum\",   \n    7:  \"Golgi apparatus\",   \n    8:  \"Peroxisomes\",   \n    9:  \"Endosomes\",   \n    10:  \"Lysosomes\",   \n    11:  \"Intermediate filaments\",   \n    12:  \"Actin filaments\",   \n    13:  \"Focal adhesion sites\",   \n    14:  \"Microtubules\",   \n    15:  \"Microtubule ends\",   \n    16:  \"Cytokinetic bridge\",   \n    17:  \"Mitotic spindle\",   \n    18:  \"Microtubule organizing center\",   \n    19:  \"Centrosome\",   \n    20:  \"Lipid droplets\",   \n    21:  \"Plasma membrane\",   \n    22:  \"Cell junctions\",   \n    23:  \"Mitochondria\",   \n    24:  \"Aggresome\",   \n    25:  \"Cytosol\",   \n    26:  \"Cytoplasmic bodies\",   \n    27:  \"Rods & rings\"\n}","7c9dc306":"submit['target_list'] = submit['Predicted'].map(lambda x: [int(a) for a in str(x).split(' ')])\nsubmit['target_vec'] = submit['target_list'].map(lambda ck: [i in ck for i in range(max_idx+1)])\nall_labels = list(chain.from_iterable(submit['target_list'].values))\nc_val = Counter(all_labels)\nn_keys = c_val.keys()\nmax_idx = max(n_keys)\nfor k,v in name_label_dict.items():\n    print(v, 'count:', c_val[k] if k in c_val else 0)","c8e93c88":"train_sum_vec = np.sum(np.stack(submit['target_vec'].values, 0), 0)\n_ = plt.bar(n_keys, [train_sum_vec[k] for k in n_keys])\n","c176d95a":"### Introduction\nLet's try to understand how to use channels in learning. First variant is combine them all together like [here](https:\/\/www.kaggle.com\/byrachonok\/pretrained-inceptionresnetv2-base-classifier) \n\nIn our case we will use two branch of network - first one is about data and second one is about \"The protein of interest\". We will get 2 images from 4 sources:\n1. Yellow, blue and red channel - we create RGB image (yellow channel will be in fact green color now);\n2. Source green channel will be grayscale image but with 3 equal channel (condition for using Imagenet weights)\n\nLet's start from imports and data loading:","6f486db3":"### Visualization\nFirst line is RGB images, second line is relevant grayscale images:","ee76fd99":"### Create model\nOur model will have two Xception branches, each will return 2048 size vector and they will multiply before prediction:","9220bef5":"### Visualize history\nThere are a few epochs only, but in full variant it will be useful:","08e05e17":"### Load dataset info:","84116393":"6### Create datagenerator\n\nOur generator will return next structure: ([RGB_images, grayscale_images], labels). As described above, now we will have two inputs","240d989d":"### Create submit","6ae25741":"### Compile model\nCompile our model, note, we will use binary_crossentropy as loss (we have sigmoid output layer and multilabel task) ans two metrics: accuracy and f1:","f8dea3a0":"### F1 metric for progress monitoring from [this kernel](https:\/\/www.kaggle.com\/guglielmocamporese\/macro-f1-score-keras):","490cf2c5":"### Show data:","ac47cc9b":"### Classes distribution:","c93cebaf":"### Split data\nSplit data into train and val part with a ratio 80\/20, we will use for it \"hack\" from [this kernel](https:\/\/www.kaggle.com\/kmader\/rgb-transfer-learning-with-inceptionv3-for-protein)","cbaca387":"### Create lists for training:","0824569b":"### Let's look on distribution of train and val parts:","75aaf1c3":"### Imports:","85100aef":"### Conclusion\nIt is only example how we can use data, but also it is not finish variant, we can improve several things:\n1. Train more! 4 epochs is not enough;\n2. Change Xception network to another one (InceptionV3, for example);\n3. You can add augmentation for your data;\n4. Play with merge layer (now it is Multiply), you can change it to Add or something else.\n\n#### Happy kaggling!","73df85c9":"### Analysis of submission\nLet's look at our results, Which proteins occur most often in our submission?","b3e02f6f":"### Train model\nWe have a little bit big model (two Xception branches), 1 epoch trains around 1 hour, so we will train only 4 epochs (kaggle has 6 hours limit). Also, we will validate only on 10% of valid data, here it is not necessary in fact, but when you will try it by yourself, you will monitor quality based on val f1 score and val loss."}}