{"cell_type":{"927b49dc":"code","e0cc5c59":"code","c6a0d781":"code","6eae39e2":"code","a02eeefd":"code","b129336f":"code","a1bb6559":"code","9090a47c":"code","d18f9afd":"code","775e3d35":"code","6f73a023":"code","72ca1de6":"code","32177218":"code","ebcfb656":"code","b7db23f0":"code","cd62f591":"code","7bb4c55f":"code","d507d005":"code","47430255":"code","8f9f2d96":"code","27f9b534":"code","673c21b5":"code","7ac40c83":"code","a38f8c13":"code","94f6b4c8":"code","760cf924":"markdown","3851646f":"markdown","2f4a25b5":"markdown","6dd5100c":"markdown","e09d65ba":"markdown","8aa3e873":"markdown","782d55c9":"markdown","ae614ec1":"markdown","bbc2a9e3":"markdown","2b925a0f":"markdown","54b6f90f":"markdown","cb892568":"markdown","dc06c3d4":"markdown","917a5543":"markdown","d01e1ad8":"markdown","5868cf1c":"markdown","f1d5f083":"markdown","7abfaaf4":"markdown","5548499c":"markdown","f4efcd50":"markdown","bafb7e21":"markdown","64f9601c":"markdown","af9b2785":"markdown","40dd9dc6":"markdown","5e21246f":"markdown","044c26dc":"markdown","f2134b8c":"markdown","b7fa27aa":"markdown","03451019":"markdown","867338e3":"markdown","b3bc9b7d":"markdown","9c1c55ab":"markdown","09084625":"markdown","47e2ce4d":"markdown"},"source":{"927b49dc":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score, make_scorer\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (15, 5)\n    \ncalifornia = fetch_california_housing()","e0cc5c59":"# First thing we'll do is exploring our data set. In every scikit Dataset there's a DESCR atribute with the description of the dataset.\n\nprint(california.DESCR)","c6a0d781":"# For EDA, we'll use pandas API, so we'll transform numpy arrays in pandas dataframes\n\nconcat_california_array = np.concatenate((california.data, np.reshape(california.target, (california.target.shape[0],1))), axis = 1)\n\ncalifornia_df = pd.DataFrame(concat_california_array, columns = california.feature_names + ['price'])\n\ncalifornia_df.head(3)","6eae39e2":"plt.figure(figsize=(15,10))\n\n# We divide population by ten to scale bubble sizes.\n\nplt.scatter(california_df['Longitude'],california_df['Latitude'],c=california_df['price'],s=california_df['Population']\/10,cmap='viridis')\nplt.colorbar()\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.title('house price on basis of geo-coordinates')\nplt.show()","a02eeefd":"#corelation matrix\n\nplt.figure(figsize=(11,7))\nsns.heatmap(cbar=False,annot=True,data=california_df.corr()*100,cmap='coolwarm')\nplt.title('% Corelation Matrix')\nplt.show()","b129336f":"california_df.isnull().sum()","a1bb6559":"# Our goal here is to extract the numeric columns so we can boxplot them in order to detect outliers.\n\n# Numeric column extraction\n\nnumeric_columns = california_df.select_dtypes(include = ['float64', 'int']).columns\nlen_numeric_columns = len(numeric_columns)\n\n\n# Boxplotting\n\nfig = plt.figure(figsize = (15,10))\n\n# Set number of columns you want to plot\n\nn_cols = 3\n\nn_plot_rows = len_numeric_columns\/\/n_cols\nn_plot_rows\n\n\nfor i, column in enumerate(numeric_columns):\n    ax = fig.add_subplot(n_plot_rows, n_cols, i+1)\n    sns.boxplot(y = california_df[column], orient = 'h', ax = ax)\n\nfig.tight_layout()","9090a47c":"X = california.data\ny = california.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","d18f9afd":"# Because we have several features with outliers, we should scale them with RobustScaler.\n\nrs = RobustScaler()\nX_train_rs = rs.fit_transform(X_train )\nX_test_rs = rs.transform(X_test)","775e3d35":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Without scaling.\nlg = LinearRegression()\nlg.fit(X_train, y_train)\n\n# With scaling\n\nlg_rs = LinearRegression()\nlg_rs.fit(X_train_rs, y_train)\n\n# Obtaining prediction\ny_est = lg.predict(X_test)\ny_est_rs = lg_rs.predict(X_test_rs)\n\n# Obtaining mean squared error and R2 coefficient for TESTING\nMSE_tst = mean_squared_error(y_test, y_est)\nR2_coeff = lg.score(X_test,y_test)\n\nMSE_tst_rs = mean_squared_error(y_test, y_est_rs)\nR2_coeff_rs = lg_rs.score(X_test_rs,y_test)\n\n\n# Obtaining mean squared error and R2 coefficient FOR TRAINING\nMSE_train = mean_squared_error(y_train, lg.predict(X_train))\nR2_train_coeff = lg.score(X_train,y_train)\n\n\n\n# Printing error and model precission\nprint('TESTING METRICS')\n\nprint('Metrics without scaling:')\nprint('MSE : ' + str(MSE_tst))\nprint('R2 score: ' + str(R2_coeff))\n\nprint('\\nMetrics with RobustScaler:')\nprint('MSE : ' + str(MSE_tst_rs))\nprint('R2 score: ' + str(R2_coeff_rs))\n\nprint('\\nTRAINING METRICS')\n\nprint('Metrics without scaling:')\nprint('MSE : ' + str(MSE_train))\nprint('R2 score: ' + str(R2_train_coeff))\n","6f73a023":"from sklearn.neighbors import KNeighborsRegressor\n\n\nk_max =20\nrang_K = np.arange(1, k_max+1)\ntuned_parameters = [{'n_neighbors': rang_K}]\nnfold = 5\n\n# Grid search for finding optimal hyperparameters. We'll use two scoring methods: R2 and MSE.\n\nneigh_CV = GridSearchCV(KNeighborsRegressor(), \n                        tuned_parameters, \n                        cv=nfold, \n                        scoring = {'MSE': make_scorer(mean_squared_error), 'R2': make_scorer(r2_score)},\n                        return_train_score=True, refit = 'R2', n_jobs=-1).fit(X_train_rs, y_train)\n\n# Obtaining prediction \ny_est = neigh_CV.predict(X_test_rs) \n\n# Obtaining mse and R2 coefficient\nMSE_tst = mean_squared_error(y_test,y_est)\nR2_coeff = neigh_CV.score(X_test_rs,y_test)\n\n# Obtaining best params.\nK_CV = neigh_CV.best_params_['n_neighbors']\n\nprint('MSE : ' + str(MSE_tst))\nprint('R2 score: ' + str(R2_coeff))\nprint('Selected value of k: ' + str(K_CV))","72ca1de6":"fig = plt.figure(figsize = (15,10))\n\nprint(\"Cross validation results:\")\ncv_results = pd.DataFrame(neigh_CV.cv_results_)\naccs = pd.DataFrame(columns=[\"Neighbors\"])\n\n# Mostramos los resultados\nmelted_accs = accs.assign(**{'Neighbors': pd.DataFrame(neigh_CV.cv_results_['params']).unstack().values,\n                             \"Training R2\": cv_results.mean_train_R2,\n                             \"Validation R2\": cv_results.mean_test_R2,\n                             \"Traning MSE\": cv_results.mean_train_MSE,\n                             \"Validation MSE\": cv_results.mean_test_MSE}) \\\n                            .melt('Neighbors', value_vars = ['Traning MSE', 'Validation MSE'], var_name=\"Type\", value_name=\"MSE\")\ng = sns.lineplot(x=\"Neighbors\", y=\"MSE\", hue='Type', data=melted_accs)","32177218":"from sklearn.ensemble import RandomForestRegressor\n\nnfold = 5\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30, 100, 150], \n    'max_features': [2, 4, 6, 8]\n    },\n    {'bootstrap': [False], 'n_estimators': [3, 10, 30, 100], 'max_features': [2, 3, 4]}\n]\n\ngrid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=nfold, \n                           scoring = {'MSE': make_scorer(mean_squared_error), 'R2': make_scorer(r2_score)},\n                           return_train_score=True, refit = 'R2', n_jobs=-1).fit(X_train_rs, y_train)\n\n","ebcfb656":"# Obtaining prediction \ny_est = grid_search.predict(X_test_rs) \ny_est_train = grid_search.predict(X_train_rs) \n\n# Obtaining mse and R2 coefficient for test\nMSE_tst = mean_squared_error(y_test,y_est)\nR2_coeff = grid_search.score(X_test_rs,y_test)\n\n# Obtaining mse and R2 coefficient for train\nMSE_train = mean_squared_error(y_train,y_est_train)\nR2_coeff_train = grid_search.score(X_train_rs,y_train)\n\n# Obtaining best params.\nRF_best_params = grid_search.best_params_\n\nprint('MSE test : ' + str(MSE_tst))\nprint('R2 test score: ' + str(R2_coeff))\n\nprint('MSE train : ' + str(MSE_train))\nprint('R2 train score: ' + str(R2_coeff_train))\n\nprint('Selected value of best params: ' + str(RF_best_params))","b7db23f0":"df_metrics = pd.concat( [pd.DataFrame(grid_search.cv_results_['params']),\n            pd.DataFrame({'train_MSE': grid_search.cv_results_['mean_train_MSE']}),\n            pd.DataFrame({'test_MSE': grid_search.cv_results_['mean_test_MSE']})\n            ], axis = 1\n            )\nm = ((df_metrics.max_features == 3) & (df_metrics.bootstrap == False))\ndf_metrics.loc[:, ['n_estimators', 'test_MSE']]\n#df_metrics = df_metrics.melt('n_estimators', value_vars = ['train_MSE', 'test_MSE'], var_name = 'Type')\n\nfig = plt.figure(figsize = (15,10))\n\ng = sns.lineplot(x=\"n_estimators\", y=\"test_MSE\", data=df_metrics, err_style = None)","cd62f591":"# We use this function made by Sklearn (https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_learning_curve.html)\n\n# Graphics \"Scalabilty of the model\" and \"Performance of the model\" have been removed.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate 3 plots: the test and training learning curve, the training\n    samples vs fit times curve, the fit times vs score curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    axes : array of 3 axes, optional (default=None)\n        Axes to use for plotting the curves.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 5-fold cross-validation,\n          - integer, to specify the number of folds.\n          - :term:`CV splitter`,\n          - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer\/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : int or None, optional (default=None)\n        Number of jobs to run in parallel.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    train_sizes : array-like, shape (n_ticks,), dtype float or int\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the dtype is float, it is regarded as a\n        fraction of the maximum size of the training set (that is determined\n        by the selected validation method), i.e. it has to be within (0, 1].\n        Otherwise it is interpreted as absolute sizes of the training sets.\n        Note that for classification the number of samples usually have to\n        be big enough to contain at least one sample from each class.\n        (default: np.linspace(0.1, 1.0, 5))\n    \"\"\"\n    if axes is None:\n        _, axes = plt.subplots(1, 1, figsize=(15, 10))\n\n    axes.set_title(title)\n    if ylim is not None:\n        axes.set_ylim(*ylim)\n    axes.set_xlabel(\"Training examples\")\n    axes.set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n\n    # Plot learning curve\n    axes.grid()\n    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes.legend(loc=\"best\")\n\n\n\n    return plt","7bb4c55f":"title = \"Learning Curves Random Forest\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n\nestimator = grid_search.best_estimator_\nplot_learning_curve(estimator, title, X_train_rs, y_train,\n                    cv=cv, n_jobs=4)\n\n\nplt.show()","d507d005":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nada_reg = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=200, learning_rate=0.5 ).fit(X_train_rs, y_train)\n\n\n# Obtaining prediction \ny_est = ada_reg.predict(X_test_rs) \n\n# Obtaining mse and R2 coefficient\nMSE_tst = mean_squared_error(y_test,y_est)\nR2_coeff = ada_reg.score(X_test_rs,y_test)\n\nprint('MSE : ' + str(MSE_tst))\nprint('R2 score: ' + str(R2_coeff))","47430255":"#Importing xgboost regresssor\nfrom xgboost import XGBRegressor\n\n# In other to take a peek at the model performance and show feature importance, we'll train a simple model. Later, we'll tune hyperparameters in order\n# to obtain the best model.\n\nxg_regressor = XGBRegressor(max_depth=6, n_estimators=500, learning_rate=0.01, silent=True)\nxg_regressor.fit(X_train_rs, y_train)\n\nprint('Feature importance:')\nfor name, score in zip(california['feature_names'], xg_regressor.feature_importances_):\n  print(name, '{0:.2f} %'.format(score*100))\n\nprint('\\n'*2, 'Scoring:')\nprint('MSE for test {0:.2f}'.format(mean_squared_error(y_test, xg_regressor.predict(X_test_rs))))\nprint('R-squared for test {0:.2f}'.format(xg_regressor.score(X_test_rs, y_test)))\nprint('MSE for train {0:.2f}'.format(mean_squared_error(y_train, xg_regressor.predict(X_train_rs))))\nprint('R-squared for train {0:.2f}'.format(xg_regressor.score(X_train_rs, y_train)))","8f9f2d96":"# A parameter grid for XGBoost\nparams = {\n        'n_estimators':[100,150,200,300,350],\n        'learning_rate': np.linspace(0.1, 1.0, 10),\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': np.arange(3,11,1),\n        }","27f9b534":"from sklearn.model_selection import RandomizedSearchCV\n\n\nxgb_reg = XGBRegressor(silent=True)\n\n\nxgb_random = RandomizedSearchCV(estimator = xgb_reg, param_distributions = params, n_iter = 200, cv = 5, verbose=0,  \n                                scoring = {'MSE': make_scorer(mean_squared_error), 'R2': make_scorer(r2_score)},\n                                return_train_score=True, refit = 'R2', n_jobs=-1).fit(X_train_rs, y_train)\n\n\n","673c21b5":"\n\n# Obtaining prediction \ny_est = xgb_random.predict(X_test_rs) \ny_est_train = xgb_random.predict(X_train_rs) \n\n# Obtaining mse and R2 coefficient for test\nMSE_tst = mean_squared_error(y_test,y_est)\nR2_coeff = xgb_random.score(X_test_rs,y_test)\n\n# Obtaining mse and R2 coefficient for train\nMSE_train = mean_squared_error(y_train,y_est_train)\nR2_coeff_train = xgb_random.score(X_train_rs,y_train)\n\n# Obtaining best params.\nRF_best_params = xgb_random.best_params_\n\nprint('MSE test : ' + str(MSE_tst))\nprint('R2 test score: ' + str(R2_coeff))\n\nprint('MSE train : ' + str(MSE_train))\nprint('R2 train score: ' + str(R2_coeff_train))\n\nprint('Selected value of best params: ' + str(RF_best_params))","7ac40c83":"title = \"Learning Curves XGBoost\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n\nestimator = xgb_random.best_estimator_\nplot_learning_curve(estimator, title, X_train_rs, y_train,\n                    cv=cv, n_jobs=-1)\n\n\nplt.show()","a38f8c13":"print('Feature importance:')\nfor name, score in zip(california['feature_names'], xgb_random.best_estimator_.feature_importances_):\n  print(name, '{0:.2f} %'.format(score*100))","94f6b4c8":"#We select the most important features\n\nX_train_less_features = X_train_rs[:,[0,2,5,7]]\n\ntitle = \"Learning curve XGBoost\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n\nestimator = xgb_random.best_estimator_\nplot_learning_curve(estimator, title, X_train_less_features, y_train,\n                    cv=cv, n_jobs=-1)\n\n\nplt.show()","760cf924":"### GRADIENT BOOSTING","3851646f":"# SPLITTING AND SCALING DATA ","2f4a25b5":"It seems that Random Forest is overfitting training data","6dd5100c":"As we've mentioned before, Random Forest is overfitting training data","e09d65ba":"## GEOSPATIAL PLOT","8aa3e873":"## ENSEMBLES","782d55c9":"# EXPLORATORY DATA ANALYSIS","ae614ec1":"From the former graphic, we see that our model has high validation and high training errors. It suffers from high bias and low variance, underfitting the training data.\n\nIf most our house prices range between 120K and 270K, an error of 35k-45K is very significant.\n\n","bbc2a9e3":"## California Housing DataSet\n","2b925a0f":"We'll use RandomizedSearchCV, which has the advantage that, instead of trying all combination of the hyperparameters grid with each KFOLD CV, it picks ramdom combinations. This way, we can have a notion of the best hyperparameters so we can center ranges in our GridSearch (but we'll not use it because of computational capacity).","54b6f90f":"## KNN","cb892568":"As we can see, for this problem, linear regression is not the way to go: our score is really bad. Most of our house prices range between 120K and 270K (as we see in the boxplot), so and error of 53K is really huge!!!","dc06c3d4":"##### HYPERPARAMETER TUNING","917a5543":"From the Pearson correlation between each pair of columns, we see that:\n\n- Latitude and longitude are negatively correlated. This is logical because of California State shape. Houses seem to be parallel along the coast, so it has a negative \"slope\". This means that we could remove one or the other from our dataset in orden to predict house price, because they are redundant.\n- Median income is highly correlated with our target value, so this means that this feature we'll have the most important role, as we'll see with feature_importance_ decission tree attribute.","d01e1ad8":"So we should scale the data with **RobustScaler**, which uses statistics that are robust to outliers\n","5868cf1c":"There's one thing that it's not said in DESCR, and it's that target value corresponds to the average house value in units of 100,000.","f1d5f083":"### OUTLIER DETECTION","7abfaaf4":"## LINEAR REGRESSION","5548499c":"From the previous boxplots, we see that there are several features with outliers. These features are:\n\n- MedInc: median income in block\n- AveRooms: average number of rooms\n- AveBedrms: average number of bedrooms\n- Population: block population\n- Price: house prices","f4efcd50":"### ADABOOST","bafb7e21":"**Removing features reduces our valdation score very badly**. So we choose the model given by RandomizedSearch CV with a R2 test score of 0.849 and these params:\n\n- 'subsample': 1.0, \n- 'n_estimators': 300\n- 'min_child_weight': 5\n- 'max_depth': 8 \n- 'learning_rate': 0.1 \n- 'gamma': 0 \n- 'colsample_bytree': 0.8","64f9601c":"Houses near to the ocean should have higher prices than inland ones. We'll make a scatter plot to corroborate our hypothesis.","af9b2785":"## NULL AND OUTLIER EXPLORATION","40dd9dc6":"### RANDOM FOREST","5e21246f":"# BUILDING OUR MACHINE LEARNING MODEL","044c26dc":"We haven't nulls in our dataframe.","f2134b8c":"### NULL EXPLORATION","b7fa27aa":"Now we'll train a Nearest Neighbors algorithm with different hyperparameters. In order to do so, we'll make use of GridSearchCV function, which allow us to do a cross-validation search.","03451019":"Our best test performance is achieves with 100 estimators.","867338e3":"So that's true, houses along the coast have higher values, as expected.","b3bc9b7d":"\nWe have in total 5 * 10 * 3 * 6 * 3 * 3 * 7 = 56.700 combinations. That's why we choose RamdomizedSearch over GridSearch in first place. It would take a lot of time to try all these combinations.","9c1c55ab":"There seem to be a little bit of overfitting, but not as much as Random forest. We can remove overfitting by selecting only the most important features or by early stoping. We'll try removing features.","09084625":"#### XGBOOST (THE WINNER)","47e2ce4d":"## CORRELATION MATRIX"}}