{"cell_type":{"64ff3695":"code","2258824c":"code","dcb1f085":"code","7ecb3b55":"code","0d1b3444":"code","d63947b3":"code","22507be5":"code","584069c9":"code","75915111":"code","b2b59b1b":"code","cb49e3ea":"code","535a4c7a":"code","cf45fc68":"code","f12db7b9":"code","f4ca76fa":"code","17351d7e":"code","29419654":"code","6c99c055":"code","c72cf217":"code","7fc039fa":"code","b6aead14":"code","2ffe2bcd":"code","85b73521":"code","a4a398e8":"code","4e44267c":"code","bb1c77fc":"markdown","dcd3c9d2":"markdown","c7a54416":"markdown","ad9d23d4":"markdown","52241b3e":"markdown","55c462f1":"markdown","de219122":"markdown"},"source":{"64ff3695":"%matplotlib inline\nimport os\nimport matplotlib.pyplot as plt\n\ndata={}\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/cash-recognition-system\/Cash'):\n    print(dirname)\n    item = dirname.split('\/')[-1]\n    if len(filenames)>0:\n        data[item]=len(filenames)","2258824c":"my_colors = ['brown','pink', 'red', 'green', 'blue', 'cyan','orange','purple'] \nplt.bar([i for i in data.keys()],[j for j in data.values()],color=my_colors)\nplt.xlabel('Notes')\nplt.ylabel('No of image')\nplt.show()","dcb1f085":"\nimport matplotlib.image as mpimg\nBasePath = '\/kaggle\/input\/cash-recognition-system\/Cash\/Cash\/100\/'\nfileNames= os.listdir('\/kaggle\/input\/cash-recognition-system\/Cash\/Cash\/100\/')\nImg_path=[]\nfor file in fileNames[:10]:\n    IMG_PATH = os.path.join(BasePath,file)\n    Img_path.append(IMG_PATH)\n    \n#print(Img_path)\nplt.figure(figsize=(50,50))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.axis('off')\n    plt.xticks([]),plt.yticks([])\n    image = mpimg.imread(Img_path[i])\n    plt.imshow(image)\nplt.show()\n","7ecb3b55":"%%writefile hdf5datasetwriter.py\nimport h5py\nimport os\n\nclass HDF5DatasetWriter:\n    def __init__(self, dims, outputPath, dataKey=\"images\",\n    bufSize=500):\n        # check to see if the output path exists, and if so, raise\n        # an exception\n        if os.path.exists(outputPath):\n            raise ValueError(\"The supplied \u2018outputPath\u2018 already \"\n            \"exists and cannot be overwritten.Manually delete \"\n            \"the file before continuing.\", outputPath)\n        self.db = h5py.File(outputPath, \"w\")\n        self.data = self.db.create_dataset(dataKey, dims,\n                                           dtype=\"float\",compression='gzip',compression_opts=9)\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],),\n                                             dtype=\"int\",compression='gzip',compression_opts=9)\n        self.bufSize = bufSize\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, rows, labels):\n\n        # add the rows and labels to the buffer\n        self.buffer[\"data\"].extend(rows)\n        self.buffer[\"labels\"].extend(labels)\n        if len(self.buffer[\"data\"]) >= self.bufSize:\n            self.flush()\n\n    def flush(self):\n\n        # write the buffers to disk then reset the buffer\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n\n    def storeClassLabels(self, classLabels):\n\n        # create a dataset to store the actual class label names,\n        # then store the class labels\n        dt = h5py.special_dtype(vlen=str)\n        labelSet = self.db.create_dataset(\"label_names\",\n                                          (len(classLabels),), dtype=dt)\n        labelSet[:] = classLabels\n\n    def close(self):\n\n        # check to see if there are any other entries in the buffer\n        # that need to be flushed to disk\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n\n        # close the dataset\n        self.db.close()","0d1b3444":"import os\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.applications import VGG16\nfrom keras.applications import imagenet_utils\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom sklearn.preprocessing import LabelEncoder\nfrom hdf5datasetwriter import HDF5DatasetWriter\n#from imutils import paths\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","d63947b3":"IMG_PATH = []\nlabels =[]\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/cash-recognition-system\/Cash\/Cash\/'):\n    for filename in filenames:\n        imagepath = os.path.join(dirname,filename)\n        IMG_PATH.append(imagepath)\n        label = imagepath.split('\/')[-2]\n        labels.append(label)\n       # print(imagepath)\n        #print(label)\nprint(len(IMG_PATH))\nprint(len(labels))\n","22507be5":"le = LabelEncoder()\nlabels=le.fit_transform(labels)\nle.classes_\n","584069c9":"classTotals = labels.sum(axis=0)\nclassWeight = classTotals.max()\/classTotals","75915111":"Base_model = VGG16(weights=\"imagenet\", include_top=False,input_shape=(224,224,3))\nBase_model.summary()","b2b59b1b":"writer = HDF5DatasetWriter((len(IMG_PATH),512*7*7),'Nepali_Cash_Features.hdf5',bufSize=100)\nwriter.storeClassLabels(le.classes_)","cb49e3ea":"Batch_size=32\nfor i in tqdm(np.arange(0,len(IMG_PATH),Batch_size)):\n    batchPaths = IMG_PATH[i:i+Batch_size]\n    batchLabels = labels[i:i+Batch_size]\n    batchImages = []\n    \n    for (j,imagePath) in enumerate(batchPaths):\n        image = load_img(imagePath,target_size = (224,224))\n        image = img_to_array(image)\n        image=np.expand_dims(image,axis=0)\n        image = imagenet_utils.preprocess_input(image)\n        batchImages.append(image)\n    \n    batchImages = np.vstack(batchImages)\n    features = Base_model.predict(batchImages,batch_size=Batch_size)\n    features = features.reshape((features.shape[0],512*7*7))\n    writer.add(features,batchLabels)\nwriter.close()\n\n        ","535a4c7a":"import h5py\ndb=h5py.File('\/kaggle\/working\/Nepali_Cash_Features.hdf5')\nlist(db.keys())","cf45fc68":"print(db['images'].shape)\nprint(db['labels'].shape)\nprint(db['label_names'].shape)","f12db7b9":"db = h5py.File('\/kaggle\/working\/Nepali_Cash_Features.hdf5', \"r\")\ni = int(db[\"labels\"].shape[0] * 0.75)","f4ca76fa":"trainX=db[\"images\"][:i]\ntestX=db[\"images\"][i:]\ntrainY=db[\"labels\"][:i]\ntestY = db[\"labels\"][i:]\nprint(trainX[0])","17351d7e":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\ntrainX_res,trainY_res = ros.fit_resample(trainX, trainY)","29419654":"from collections import Counter\nprint(sorted(Counter(trainY_res).items()))","6c99c055":"from keras.models import Sequential\nfrom keras.layers import Flatten,Dense,GlobalAveragePooling2D\n\nmodel=Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape=(7,7,512)))\nmodel.add(Dense(6,activation='softmax'))\nmodel.summary()","c72cf217":"model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=[\"acc\"])\nmodel.fit(trainX_res.reshape(-1,7,7,512), trainY_res,epochs=100,validation_data=(testX.reshape(-1,7,7,512),testY))","7fc039fa":"db.close()","b6aead14":"model.save('NepaliCash.hdf5')","2ffe2bcd":"!pip install imutils\n","85b73521":"from imutils import paths\nbatchImages = []\nimagePaths = list(paths.list_images('..\/input\/neplesenotes\/Neplese notes\/'))\nfor image in imagePaths:\n    img=load_img(image ,target_size=(224, 224,3))\n    img=img_to_array(img)\n    img=np.expand_dims(img,axis=0)\n    img=imagenet_utils.preprocess_input(img)\n    batchImages.append(img)\nbatchImages=np.vstack(batchImages)\n    \nfeatures=Base_model.predict(batchImages)\nfeatures=features.reshape(features.shape[0],7*7*512)","a4a398e8":"prediction=model.predict(features.reshape(-1,7,7,512)).argmax(axis=1)\n","4e44267c":"import cv2\nclassLabels=list(le.classes_)\nfig=plt.figure(figsize=(50, 50))\ncolumns = 2\nrows = 3\nfor (i, imagePath) in enumerate(imagePaths):\n    # load the example image, draw the prediction, and display it\n    # to our screen\n    image = cv2.imread(imagePath)\n    image= cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    cv2.putText(image, \"Label: {}\".format(classLabels[prediction[i]]),\n    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n    fig.add_subplot(rows, columns,i+1)\n    plt.imshow( image)\nplt.show()","bb1c77fc":"# Observing the data","dcd3c9d2":"# **Data Visualization**","c7a54416":"# Importing Libraries","ad9d23d4":"# Data preparation","52241b3e":"# Label Encoding","55c462f1":"# Feature extraction","de219122":"# HDF5 dataset writer"}}