{"cell_type":{"fa7d088d":"code","c29f56c0":"code","485fb8e8":"code","1a9ea960":"code","7d2a2e66":"code","87f6ddea":"code","eb749a28":"code","16363a17":"code","8cc96664":"code","cb8ef2fe":"code","173cd87d":"code","acbbd808":"code","569721d0":"code","23036b30":"code","008b985e":"code","36c0c123":"code","7c5978f0":"code","e417f467":"code","083c3c4a":"code","5117dd27":"code","504b8a17":"code","16d5eda1":"code","7f0a99ad":"code","8c19aca4":"code","05356a97":"code","60013f52":"code","1541275c":"code","caa79286":"code","e45dabcd":"code","f1b67eef":"code","42b80638":"code","f5be89a7":"code","056a46ad":"code","2db9943a":"code","75dbaa32":"code","61b9b114":"code","036045b9":"code","aefa3208":"code","68b616d6":"code","b709e965":"code","501c91cf":"code","e4d0402d":"code","3b6144c8":"code","836d7898":"code","ac3f50c0":"code","b1d5ae33":"code","72a8bc01":"code","bd5d91d5":"code","1f13be80":"code","4e4177ec":"code","32af5e7a":"code","d914ee5d":"code","1a819289":"code","2219af08":"code","c798e69d":"code","eb800d7a":"code","7d88f93d":"code","dc68a36f":"code","dc1125b9":"code","d44cb769":"code","18e124a3":"code","b00bc132":"code","19b1f051":"code","34cfe000":"code","4d865625":"code","7debdcdc":"code","2dd600d2":"code","83286902":"code","363b6e0b":"code","7449a9e4":"code","de5108b7":"code","043cd8c7":"markdown","b8896fa6":"markdown","3bc20ea8":"markdown","afc34b83":"markdown","cf51d95a":"markdown","43d3914e":"markdown","6723cb98":"markdown","9496b8be":"markdown","12f86635":"markdown","cdc0d1fc":"markdown","2e07413c":"markdown","eeed8e2d":"markdown","6f4e2c5f":"markdown","b71ad56b":"markdown","62657e2f":"markdown","1d5a6020":"markdown","6f4c980c":"markdown","fb193efb":"markdown","00d18bb7":"markdown"},"source":{"fa7d088d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c29f56c0":"app = pd.read_csv(\"..\/input\/credit-card-approval-prediction\/application_record.csv\")\ncrecord = pd.read_csv(\"..\/input\/credit-card-approval-prediction\/credit_record.csv\")","485fb8e8":"app.info()","1a9ea960":"crecord.info()","7d2a2e66":"app['ID'].nunique() # the total rows are 438,557. This means it has duplicates","87f6ddea":"crecord['ID'].nunique() \n# this has around 43,000 unique rows as there are repeating entries for different monthly values and status.","eb749a28":"len(set(crecord['ID']).intersection(set(app['ID']))) # checking to see how many records match in two datasets","16363a17":"sns.heatmap(app.isnull()) # checking for null values. Seems like occupation_type has many","8cc96664":"sns.heatmap(crecord.isnull()) # checking for null values. All good here!","cb8ef2fe":"app = app.drop_duplicates('ID', keep='last') \n# we identified that there are some duplicates in this dataset\n# we will be deleting those duplicates and will keep the last entry of the ID if its repeated.","173cd87d":"app.drop('OCCUPATION_TYPE', axis=1, inplace=True) \n#we identified earlier that occupation_type has many missing values\n# we will drop this column","acbbd808":"ot = pd.DataFrame(app.dtypes =='object').reset_index()\nobject_type = ot[ot[0] == True]['index']\nobject_type\n#we are filtering the columns that have non numeric values to see if they are useful","569721d0":"num_type = pd.DataFrame(app.dtypes != 'object').reset_index().rename(columns =  {0:'yes\/no'})\nnum_type = num_type[num_type['yes\/no'] ==True]['index']\n#HAVE CREATED SEPARATE LIST FOR NUMERIC TYPE INCASE IT WILL BE NEEDED IN FURTHER ANALYSIS\n# IT IS NEEDED IN FURTHER ANALYSIS","23036b30":"a = app[object_type]['CODE_GENDER'].value_counts()\nb = app[object_type]['FLAG_OWN_CAR'].value_counts()\nc = app[object_type]['FLAG_OWN_REALTY'].value_counts()\nd = app[object_type]['NAME_INCOME_TYPE'].value_counts()\ne = app[object_type]['NAME_EDUCATION_TYPE'].value_counts()\nf = app[object_type]['NAME_FAMILY_STATUS'].value_counts()\ng = app[object_type]['NAME_HOUSING_TYPE'].value_counts()\n\nprint( a,\"\\n\",b,'\\n', c, '\\n', d, '\\n', e, '\\n', f, '\\n', g)\n\n#this is just to see what each column is. \n#It seems that all of them are important since there is very fine classifcation in each column.\n# their effectiveness cannot be judged at this moment so we convert all of them to numeric values.","008b985e":"app.head(10)","36c0c123":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor x in app:\n    if app[x].dtypes=='object':\n        app[x] = le.fit_transform(app[x])\n# we have transformed all the non numeric data columns into data columns\n# this method applies 0,1.. classification to different value types.","7c5978f0":"app.head(10)","e417f467":"app[num_type].head()\n# We will look at numeric columns and see if there is anything that needs to be changed. ","083c3c4a":"fig, ax= plt.subplots(nrows= 3, ncols = 3, figsize= (14,6))\n\nsns.scatterplot(x='ID', y='CNT_CHILDREN', data=app, ax=ax[0][0], color= 'orange')\nsns.scatterplot(x='ID', y='AMT_INCOME_TOTAL', data=app, ax=ax[0][1], color='orange')\nsns.scatterplot(x='ID', y='CNT_FAM_MEMBERS', data=app, ax=ax[0][2], color= 'orange')\nsns.scatterplot(x='ID', y='DAYS_EMPLOYED', data=app, ax=ax[1][0])\nsns.scatterplot(x='ID', y='FLAG_MOBIL', data=app, ax=ax[1][1])\nsns.scatterplot(x='ID', y='FLAG_WORK_PHONE', data=app, ax=ax[1][2])\nsns.scatterplot(x='ID', y='FLAG_PHONE', data=app, ax=ax[2][0])\nsns.scatterplot(x='ID', y='FLAG_EMAIL', data=app, ax=ax[2][1])\nsns.scatterplot(x='ID', y='DAYS_BIRTH', data=app, ax=ax[2][2])","5117dd27":"# FOR CNT_CHILDREN COLUMN\nq_hi = app['CNT_CHILDREN'].quantile(0.999)\nq_low = app['CNT_CHILDREN'].quantile(0.001)\napp = app[(app['CNT_CHILDREN']>q_low) & (app['CNT_CHILDREN']<q_hi)]","504b8a17":"# FOR AMT_INCOME_TOTAL COLUMN\nq_hi = app['AMT_INCOME_TOTAL'].quantile(0.999)\nq_low = app['AMT_INCOME_TOTAL'].quantile(0.001)\napp= app[(app['AMT_INCOME_TOTAL']>q_low) & (app['AMT_INCOME_TOTAL']<q_hi)]","16d5eda1":"#FOR CNT_FAM_MEMBERS COLUMN\nq_hi = app['CNT_FAM_MEMBERS'].quantile(0.999)\nq_low = app['CNT_FAM_MEMBERS'].quantile(0.001)\napp= app[(app['CNT_FAM_MEMBERS']>q_low) & (app['CNT_FAM_MEMBERS']<q_hi)]","7f0a99ad":"fig, ax= plt.subplots(nrows= 3, ncols = 3, figsize= (14,6))\n\nsns.scatterplot(x='ID', y='CNT_CHILDREN', data=app, ax=ax[0][0], color= 'orange')\nsns.scatterplot(x='ID', y='AMT_INCOME_TOTAL', data=app, ax=ax[0][1], color='orange')\nsns.scatterplot(x='ID', y='CNT_FAM_MEMBERS', data=app, ax=ax[0][2], color= 'orange')\nsns.scatterplot(x='ID', y='DAYS_EMPLOYED', data=app, ax=ax[1][0])\nsns.scatterplot(x='ID', y='FLAG_MOBIL', data=app, ax=ax[1][1])\nsns.scatterplot(x='ID', y='FLAG_WORK_PHONE', data=app, ax=ax[1][2])\nsns.scatterplot(x='ID', y='FLAG_PHONE', data=app, ax=ax[2][0])\nsns.scatterplot(x='ID', y='FLAG_EMAIL', data=app, ax=ax[2][1])\nsns.scatterplot(x='ID', y='DAYS_BIRTH', data=app, ax=ax[2][2])","8c19aca4":"crecord['Months from today'] = crecord['MONTHS_BALANCE']*-1\ncrecord = crecord.sort_values(['ID','Months from today'], ascending=True)\ncrecord.head(10)\n# we calculated months from today column to see how much old is the month\n# we also sort the data according to ID and Months from today columns. ","05356a97":"crecord['STATUS'].value_counts() \n# performed a value count on status to see how many values exist of each type","60013f52":"crecord['STATUS'].replace({'C': 0, 'X' : 0}, inplace=True)\ncrecord['STATUS'] = crecord['STATUS'].astype('int')\ncrecord['STATUS'] = crecord['STATUS'].apply(lambda x:1 if x >= 2 else 0)\n# replace the value C and X with 0 as it is the same type\n# 1,2,3,4,5 are classified as 1 because they are the same type\n# these will be our labels\/prediction results for our model","1541275c":"crecord['STATUS'].value_counts(normalize=True) \n# there is a problem here\n# the data is oversampled for the labels\n# 0 are 99%\n# 1 are only 1% in the whole dataset\n# we will need to address the oversampling issue in order to make sense of our analysis\n# this will be done after when we combine both the datasets\n# so first we will join the datasets","caa79286":"crecordgb = crecord.groupby('ID').agg(max).reset_index()\ncrecordgb.head() \n#we are grouping the data in crecord by ID so that we can join it with app","e45dabcd":"df = app.join(crecordgb.set_index('ID'), on='ID', how='inner')\ndf.drop(['Months from today', 'MONTHS_BALANCE'], axis=1, inplace=True)\ndf.head()\n# no that this is joined, we will solve over sampling issue","f1b67eef":"df.info() # checking for number of rows. \n# there are 9516 rows.","42b80638":"X = df.iloc[:,1:-1] # X value contains all the variables except labels\ny = df.iloc[:,-1] # these are the labels","f5be89a7":"y","056a46ad":"X","2db9943a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n# we create the test train split first","75dbaa32":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_scaled = pd.DataFrame(ss.fit_transform(X_train), columns=X_train.columns)\nX_test_scaled = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)\n# we have now fit and transform the data into a scaler for accurate reading and results.","61b9b114":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_balanced, y_balanced = oversample.fit_resample(X_scaled, y_train)\nX_test_balanced, y_test_balanced = oversample.fit_resample(X_test_scaled, y_test)\n# we have addressed the issue of oversampling here","036045b9":"y_train.value_counts()","aefa3208":"y_balanced.value_counts()","68b616d6":"y_test.value_counts()","b709e965":"y_test_balanced.value_counts()","501c91cf":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import validation_curve\nfrom scipy.stats import randint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\n!pip install pydotplus\nimport pydotplus\nfrom IPython.display import Image\nfrom sklearn.model_selection import learning_curve \nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV","e4d0402d":"%%time\n\nfrom scipy.stats import randint as sp_randint\nfrom random import uniform\n\nparameter_space = {\n    'hidden_layer_sizes': [(sp_randint.rvs(1,5,1),sp_randint.rvs(1,5,1),)],\n#     'activation': ['tanh', 'relu', 'logistic'],\n#     'activation': ['logistic'],\n#     'solver': ['sgd', 'adam', 'lbfgs'],\n    'solver': ['lbfgs'],\n    'max_iter' : [10000],\n#     'alpha': [uniform(0.0001, 0.0002)],\n         'alpha': [1e-5],\n#     'learning_rate': ['constant','adaptive']}\n         'learning_rate': ['adaptive']}\nmlp_cv = MLPClassifier(random_state=0,max_iter=10000)\nmlp_cv = RandomizedSearchCV(mlp_cv, parameter_space, cv=3,n_jobs=-1)\nmlp_cv.fit(X_balanced,y_balanced)\nprint(\"Tuned Parameters: {}\".format(mlp_cv.best_params_))\nprint(\"Best score is {}\".format(mlp_cv.best_score_))","3b6144c8":"%%time\n# mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=0, max_iter=10000)\n# model = mlp.fit(X_balanced, y_balanced)\nprediction = mlp_cv.predict(X_test_balanced)","836d7898":"print(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","ac3f50c0":"def plot_learning_curve(estimator):\n    sizes, training_scores, testing_scores , fit_times, _= learning_curve(estimator, X_balanced, y_balanced, cv=3, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 100), return_times=True) \n    # Mean and Standard Deviation of training scores \n    mean_training = np.mean(training_scores, axis=1) \n    Standard_Deviation_training = np.std(training_scores, axis=1) \n\n    # Mean and Standard Deviation of testing scores \n    mean_testing = np.mean(testing_scores, axis=1) \n    Standard_Deviation_testing = np.std(testing_scores, axis=1) \n    \n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n    \n    _, axes = plt.subplots(1, 2, figsize=(20, 5))\n\n    # dotted blue line is for training scores and green line is for cross-validation score \n    axes[0].plot(sizes, mean_training, '--', color=\"b\",  label=\"Training score\") \n    axes[0].plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n\n    # Drawing plot \n#     plt.title(\"LEARNING CURVE FOR MLP Classifier\") \n    axes[0].set_title(\"LEARNING CURVE FOR MLP Classifier\")\n    axes[0].set_xlabel(\"Training Set Size\"), axes[0].set_ylabel(\"Accuracy Score\"), axes[0].legend(loc=\"best\") \n    \n    axes[1].grid()\n#     axes[1].plot(fit_times_mean, mean_testing, 'o-')\n#     axes[1].set_xlabel(\"fit_times\")\n#     axes[1].set_ylabel(\"Score\")\n\n    axes[1].plot(sizes, fit_times_mean, 'o-')\n    axes[1].set_xlabel(\"Training Set Size\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Performance of the model\")\n    \n    \n    return plt","b1d5ae33":"%%time\nplot_learning_curve(mlp_cv.best_estimator_)","72a8bc01":"def plot_validation_curve(param, param_range,estimator, param_range_label=None):\n#     param_range = np.arange(1, 41, 2)\n    train_scores, test_scores = validation_curve(estimator, X_balanced, y_balanced, param_name=param, cv=3, param_range=param_range,n_jobs=-1, scoring=\"accuracy\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.title(\"Validation Curve with MLPClassifier\")\n    plt.xlabel(param)\n    plt.ylabel(\"Score\")\n    plt.ylim(0.0, 1.1)\n    if(param_range_label!= None):\n        ind = np.arange(len(param_range))\n        \n        plt.plot(ind, train_scores_mean, label=\"Training score\", color=\"r\")\n        plt.plot(ind, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n        plt.xticks(ind,param_range_label)\n        \n    else:\n        plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n        plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n        \n    plt.legend(loc=\"best\")\n#     param_range = np.arange(1, param_range.max(), 2)\n#     plt.xticks(param_range)\n    plt.show()","bd5d91d5":"%%time\nparam_range = np.arange(1e-5, 1e-4, 10e-6)\n# param_range_label = ['1','1.1e-5','1.1e-5','1.1e-5','1.1e-5','1.1e-5','1.1e-5','1.1e-5','1.1e-5']\nparam_name=\"alpha\"\nplot_validation_curve(param_name,param_range,mlp_cv.best_estimator_)","1f13be80":"%%time\nmlp_cv.best_params_['alpha'] = 1e-5\nmlp_iter1=MLPClassifier(random_state=0)\nmlp_iter1.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter1.fit(X_balanced, y_balanced)\nprediction = mlp_iter1.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","4e4177ec":"%%time\nmlp_cv.best_params_['alpha'] = 1e-4\nmlp_iter1=MLPClassifier(random_state=0)\nmlp_iter1.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter1.fit(X_balanced, y_balanced)\nprediction = mlp_iter1.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","32af5e7a":"%%time\nmlp_cv.best_params_['alpha'] = 0.1\nmlp_iter1=MLPClassifier(random_state=0)\nmlp_iter1.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter1.fit(X_balanced, y_balanced)\nprediction = mlp_iter1.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","d914ee5d":"%%time\nmlp_cv.best_params_['alpha'] = 0.9\nmlp_iter1=MLPClassifier(random_state=0)\nmlp_iter1.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter1.fit(X_balanced, y_balanced)\nprediction = mlp_iter1.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","1a819289":"%%time\nmlp_cv.best_params_['alpha'] = 0.001 #default\nmlp_iter1=MLPClassifier(random_state=0)\nmlp_iter1.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter1.fit(X_balanced, y_balanced)\nprediction = mlp_iter1.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","2219af08":"%%time\n# param_range = [(10,),(20,),(30,),(40,),(50,)]\n# param_range = [(100,100),(200,200),(300,300),(400,400),(500,500),(600,600)]\n# param_range_label = ['(100,100)','(200,200)','(300,300)','(400,400)','(500,500)','(600,600)']\n# param_range = [(10,10),(20,20),(30,30),(40,40),(50,50),(60,60),(70,70),(80,80),(90,90),(100,100)]\n# param_range_label = ['(10,10)','(20,20)','(30,30)','(40,40)','(50,50)','(60,60)','(70,70)','(80,80)','(90,90)','(100,100)']\nparam_range = [(10,10),(20,20),(30,30),(40,40),(50,50)]\nparam_range_label = ['(10,10)','(20,20)','(30,30)','(40,40)','(50,50)']\nparam_name=\"hidden_layer_sizes\"\nplot_validation_curve(param_name,param_range,mlp_cv.best_estimator_,param_range_label)","c798e69d":"%%time\nmlp_cv.best_params_['hidden_layer_sizes'] = (10,10)\nmlp_iter2=MLPClassifier(random_state=0)\nmlp_iter2.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter2.fit(X_balanced, y_balanced)\nprediction = mlp_iter2.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","eb800d7a":"%%time\nmlp_cv.best_params_['hidden_layer_sizes'] = (30,30)\nmlp_iter2=MLPClassifier(random_state=0)\nmlp_iter2.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter2.fit(X_balanced, y_balanced)\nprediction = mlp_iter2.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","7d88f93d":"%%time\nmlp_cv.best_params_['hidden_layer_sizes'] = (50,50)\nmlp_iter2=MLPClassifier(random_state=0)\nmlp_iter2.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter2.fit(X_balanced, y_balanced)\nprediction = mlp_iter2.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","dc68a36f":"%%time\nplot_learning_curve(mlp_iter2)","dc1125b9":"param_range = np.arange(10, 200, 20)\nparam_name=\"max_iter\"\nplot_validation_curve(param_name,param_range,mlp_iter2)","d44cb769":"%%time\nmlp_cv.best_params_['max_iter'] = 25\nmlp_iter3=MLPClassifier(random_state=0)\nmlp_iter3.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter3.fit(X_balanced, y_balanced)\nprediction = mlp_iter3.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","18e124a3":"%%time\nmlp_cv.best_params_['max_iter'] = 100\nmlp_iter3=MLPClassifier(random_state=0)\nmlp_iter3.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter3.fit(X_balanced, y_balanced)\nprediction = mlp_iter3.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","b00bc132":"%%time\nmlp_cv.best_params_['max_iter'] = 2000\nmlp_iter3=MLPClassifier(random_state=0)\nmlp_iter3.set_params(**mlp_cv.best_params_)\n","19b1f051":"%%time\nmodel = mlp_iter3.fit(X_balanced, y_balanced)\n","34cfe000":"%%time\nprediction = mlp_iter3.predict(X_test_balanced)","4d865625":"\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","7debdcdc":"%%time\nmlp_cv.best_params_['max_iter'] = 20000\nmlp_iter3=MLPClassifier(random_state=0)\nmlp_iter3.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter3.fit(X_balanced, y_balanced)\nprediction = mlp_iter3.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","2dd600d2":"%%time\nmlp_cv.best_params_['max_iter'] = 200\nmlp_iter3=MLPClassifier(random_state=0)\nmlp_iter3.set_params(**mlp_cv.best_params_)\nmodel = mlp_iter3.fit(X_balanced, y_balanced)\nprediction = mlp_iter3.predict(X_test_balanced)\nprint(confusion_matrix(y_test_balanced, prediction))\nprint(classification_report(y_test_balanced, prediction))","83286902":"%%time\nplot_learning_curve(mlp_iter3)","363b6e0b":"# %%time\n# mlp_gs = MLPClassifier(max_iter=10000)\n# parameter_space = {\n#     'hidden_layer_sizes': [(5,2)],\n#     'activation': ['tanh', 'relu'],\n#     'solver': ['lbfgs','sgd', 'adam'],\n#     'alpha': [0.0001, 0.05],\n#     'learning_rate': ['constant','adaptive']\n# }\n# from sklearn.model_selection import GridSearchCV\n# clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n# clf.fit(X_balanced, y_balanced) # X is train samples and y is the corresponding labels\n# print('Best parameters found:\\n', clf.best_params_)","7449a9e4":"# %%time\n# prediction = clf.predict(X_test_balanced)","de5108b7":"# from sklearn.metrics import classification_report, confusion_matrix\n# print(confusion_matrix(y_test_balanced, prediction))\n# print(classification_report(y_test_balanced, prediction))","043cd8c7":"(50,50) seems fine as increasing neurons doesnt provide significant improvement.","b8896fa6":"doing random search first step source: https:\/\/gist.github.com\/otaviomguerra\/51df7a4cff28f92de7105f12a0724115","3bc20ea8":"\n# Learning curve: iteration 2","afc34b83":"# Importing Libraries","cf51d95a":"# Iter 3","43d3914e":"There are outliers in 3 columns.\n1. CNT_CHILDREN\n2. AMT_INCOME_TOTAL\n3. CNT_FAM_MEMBERS","6723cb98":"* We need to remove these outliers to make sure they do not affect our model results. \n* We will now remove these outliers. ","9496b8be":"# Extracting data using two data sources","12f86635":"Source:https:\/\/www.geeksforgeeks.org\/using-learning-curves-ml\/\n\n# Learning curve: iteration 1","cdc0d1fc":"# Grid search:\nsource: https:\/\/panjeh.medium.com\/scikit-learn-hyperparameter-optimization-for-mlpclassifier-4d670413042b","2e07413c":"df.info() # checking for number of rows. \n# there are 9516 rows.","eeed8e2d":"* Using different methods to understand data\n* data is complex and both dataset need some kind of transformation before analysis\n* datasets are indivudally dealt with and then eventually compiled using joins","6f4e2c5f":"# Credit Card Prediction Analysis!","b71ad56b":"* We notice in the value counts above that label types are now balanced\n* the problem of oversampling is solved now","62657e2f":"Findings: changing alpha doesnt matter.","1d5a6020":"source: https:\/\/www.kaggle.com\/umerkk12\/credit-card-predictive-analysis","6f4c980c":"# Initially i tried with only min max scaling but i got max iter reaching limit error. i will try again with mentioned https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html 0 mean and unit var scalling","fb193efb":"<img src=\"data:image\/jpeg;base64,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\">\n\n# Context\n\nCredit score cards are a common risk control method in the financial industry. It uses personal information and data submitted by credit card applicants to predict the probability of future defaults and credit card borrowings. The bank is able to decide whether to issue a credit card to the applicant. Credit scores can objectively quantify the magnitude of risk.\n\nGenerally speaking, credit score cards are based on historical data. Once encountering large economic fluctuations. Past models may lose their original predictive power. Logistic model is a common method for credit scoring. Because Logistic is suitable for binary classification tasks and can calculate the coefficients of each feature. In order to facilitate understanding and operation, the score card will multiply the logistic regression coefficient by a certain value (such as 100) and round it.\n \nAt present, with the development of machine learning algorithms. More predictive methods such as Boosting, Random Forest, and Support Vector Machines have been introduced into credit card scoring. However, these methods often do not have good transparency. It may be difficult to provide customers and regulators with a reason for rejection or acceptance.\n \n\n\n# Task\nBuild a machine learning model to predict if an applicant is 'good' or 'bad' client, different from other tasks, the definition of 'good' or 'bad' is not given. You should use some techique, such as vintage analysis to construct you label.\n\n# Following main steps were used:\n* Fill missing values with mode\n* Find correlation between features\n* Oversample data set\n* Use scaling (StandardScaler)\n* Do ramdomizedSearchCV to select initialized parameters\n* Plot learning curves over multiple iterations\n* Plot validation curves over multiple iterations\n\n","00d18bb7":"# Algorithms code start below\n"}}