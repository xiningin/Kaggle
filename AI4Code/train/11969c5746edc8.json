{"cell_type":{"ad70f255":"code","7ce585ab":"code","96b703fb":"code","1d98d3b4":"code","79b8f785":"code","e4348fe1":"code","277b2c80":"code","a8a8d3c9":"code","94d056c7":"code","de5d4c03":"code","bb50d122":"code","ab63c30c":"code","66fb2f1a":"code","09ba1866":"code","1044d6af":"code","2993acce":"code","30e89f43":"code","7bb63393":"code","a871f37a":"code","7f94bf96":"code","2be8dd43":"code","d049cd35":"code","37e06733":"code","d1b4c49b":"code","e32fd539":"code","a35c215d":"code","01df39d1":"code","b6eaa1f2":"code","b8abb3ff":"code","b674a395":"code","ad9d7198":"code","d22abd03":"code","1a109637":"code","31bcebdf":"code","69a19db5":"code","cf36b6eb":"code","445c3121":"code","4e6102b9":"code","69fed9e2":"code","8030a732":"code","124ea2a1":"code","245658e9":"code","52fb35ef":"code","ec0b0725":"code","3a7894cb":"code","c559ece4":"code","e602dfc1":"code","4fc36981":"code","6dd403a7":"code","e82056f3":"code","2953dc5f":"code","546f3877":"code","6acf2179":"code","119c1791":"code","c2e4852a":"markdown"},"source":{"ad70f255":"!pip install -U scikit-learn","7ce585ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96b703fb":"plt.rcParams.update({'figure.max_open_warning': 0})\nrg_palette = sns.color_palette(palette=[\"red\",\"green\"])\nsns.set_theme(style=\"darkgrid\", palette=rg_palette)","1d98d3b4":"df = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')\ndf.head()","79b8f785":"df.shape","e4348fe1":"df.info()","277b2c80":"df.isna().sum(axis=0)","a8a8d3c9":"print('Number of categories per each feature:')\nfor col in df.columns:\n    print(f'{col}: {df[col].nunique()}')","94d056c7":"df = df.drop(columns=['veil-type'])","de5d4c03":"df['class'].value_counts()\n# Classes seems balanced","bb50d122":"# similar_distributions:\n#   features that show little difference in distribution\n#   between poisonous and edible\n\nsimilar_distributions = [\n    \"cap-shape\",\n    \"gill-attachment\",\n    \"veil-color\",\n    \"ring-number\"\n]\n\n\n# opposite_distributions:\n#   features that show opposite distribution\n#   between poisonous and edible\n\nopposite_distributions = [\n    \"bruises\",\n    \"odor\",\n    \"gill-size\",\n    \"spore-print-color\"\n]\n\n\n# distinctive_distributions:\n#   features that have one or few categories\n#   that are distinctive in either\n#   poisonous or edible class\n\ndistinctive_distributions = [\n    \"cap-surface\",\n    \"gill-spacing\",\n    \"gill-color\",\n    \"stalk-shape\",\n    \"stalk-root\",\n    \"stalk-surface-above-ring\",\n    \"stalk-surface-below-ring\",\n    \"ring-type\",\n    \"population\",\n    \"habitat\"\n]","ab63c30c":"for col in similar_distributions:\n    sns.displot(\n        df,\n        x=col,\n        hue=\"class\",\n        col=\"class\",\n        binwidth=3,\n        height=3\n    )","66fb2f1a":"for col in distinctive_distributions:\n    sns.displot(\n        df,\n        x=col,\n        hue=\"class\",\n        col=\"class\",\n        binwidth=3,\n        height=3\n    )","09ba1866":"for col in opposite_distributions:\n    sns.displot(\n        df,\n        x=col,\n        hue=\"class\",\n        col=\"class\",\n        binwidth=3,\n        height=3\n    )","1044d6af":"from sklearn.model_selection import train_test_split","2993acce":"df_shuffled = df.sample(frac=1)\nX, y = df_shuffled.drop(columns=['class']), df_shuffled['class'].copy()\nX_train, X_test, y_train, y_test = train_test_split(X.copy(), y.copy(), test_size=0.15, random_state=42)","30e89f43":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, plot_tree\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, \\\n                             GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFECV, RFE, SelectKBest, chi2, mutual_info_classif\n\nfrom xgboost import XGBClassifier","7bb63393":"categories_for_each_column = [X[col].unique() for col in X]\ncategories_for_each_column","a871f37a":"label_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\ny_train = label_encoder.transform(y_train)\ny_test = label_encoder.transform(y_test)","7f94bf96":"encoder = OneHotEncoder(categories=categories_for_each_column, sparse=False)\npipe = make_pipeline(encoder, SVC())","2be8dd43":"pipe.fit(X_train, y_train)\ny_test_pred = pipe.predict(X_test)\nprint(classification_report(y_test, y_test_pred))","d049cd35":"cross_val_score(pipe, X, y, scoring='accuracy', cv=5)","37e06733":"import itertools","d1b4c49b":"category_names_per_column = [[f'{col}-{category_name}' for category_name in categories_for_each_column[i]] for i, col in enumerate(X.columns)]\n# flatten this list\ncategory_names = list(itertools.chain(*category_names_per_column))","e32fd539":"X_oh = pd.DataFrame(encoder.transform(X), columns=category_names)\nX_oh.head()","a35c215d":"fig, ax = plt.subplots(figsize=(13, 13))\nsns.heatmap(X_oh.corr(), vmin=-1, vmax=1, ax=ax)\n# We can clearly see, that some of OneHot columns are correlated","01df39d1":"def find_correlated_columns(df, threshold):\n    corr = df.corr()\n    corr_abs = corr.abs()\n    col_pair_to_correlation = {}\n    for col in df.columns:\n        most_correlated_cols = corr.loc[col][corr_abs[col] >= threshold]\n        most_correlated_cols = most_correlated_cols.index.drop(col)\n        for correlated_col in most_correlated_cols:\n            correlation_value = corr.loc[col, correlated_col]\n            col_pair_to_correlation[tuple(sorted((col, correlated_col)))] = correlation_value\n    return col_pair_to_correlation","b6eaa1f2":"find_correlated_columns(X_oh, 0.7)","b8abb3ff":"num_jobs = -1\nclassifier_list = [LogisticRegression(n_jobs=num_jobs), \n                   SGDClassifier(alpha=0.01, n_jobs=num_jobs), \n                   DecisionTreeClassifier(), \n                   ExtraTreeClassifier(max_depth=5, min_samples_split=10, splitter='random'), \n                   RandomForestClassifier(n_estimators=100, n_jobs=num_jobs), \n#                    SVC(shrinking=True, kernel='rbf'), \n#                    XGBClassifier(booster='gbtree', use_label_encoder=False, n_jobs=num_jobs), \n                   GradientBoostingClassifier(n_estimators=100, loss='deviance'), \n#                    AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=50)\n]","b674a395":"classifiers = []\nrankings = []","ad9d7198":"for i in range(len(classifier_list)):\n    print(f'{i} out of {len(classifier_list)}')\n    classifier = classifier_list[i]\n#     if getattr(classifier, 'coef_', None) is None and getattr(classifier, 'feature_importances_', None) is None:\n#         print(f'Skipping {classifier}')\n    rfe = RFE(classifier, n_features_to_select=1, step=1, verbose=0)\n    rfe.fit(X_oh, y)\n    rankings.append(rfe.ranking_)\n    classifiers.append(classifier)\nprint('Done')","d22abd03":"classifiers","1a109637":"rankings","31bcebdf":"def estimator_name(estimator):\n    str_representation = str(estimator)\n    end_of_name_index = str_representation.index('(')\n    return str_representation[:end_of_name_index]\n\nestimator_name(classifier_list[0])","69a19db5":"d = {'feature': X_oh.columns}\nfor classifier, ranks in zip(classifiers, rankings):\n    d[estimator_name(classifier)] = ranks\nfeature_rankings = pd.DataFrame(d)\nfeature_rankings","cf36b6eb":"summed_rankings = feature_rankings.select_dtypes(int).sum(axis=1)\nsummed_rankings","445c3121":"sorted_rankings = [0] * len(summed_rankings)\nfor i, x in enumerate(sorted(range(len(summed_rankings)), key=lambda y: summed_rankings[y])):\n    sorted_rankings[x] = i + 1  # offset so that lowest rank is 1\nsorted_rankings[:10]","4e6102b9":"feature_rankings['overall_ranking'] = sorted_rankings\nfeature_rankings","69fed9e2":"feature_rankings.sort_values(by='overall_ranking', inplace=True)\nfeature_rankings.head()","8030a732":"feature_rankings = feature_rankings.set_index('feature')\nfeature_rankings.head(10)","124ea2a1":"print(distinctive_distributions)\nprint(opposite_distributions)","245658e9":"df_oh = pd.concat([X_oh.astype('category'), pd.Series(y, name='class')], axis=1)\nfor col in feature_rankings.index[:5]:\n    sns.displot(\n        data=df_oh,\n        x=col,\n        col=\"class\",\n        binwidth=3,\n        height=3\n    )","52fb35ef":"# if spore-print-color-r == 0, then it's 100% class 1\ndf_oh.groupby(['class', 'spore-print-color-r'])['class'].count()","ec0b0725":"fig = go.Figure()\nfig.update_layout(\n    autosize=False,\n    width=1400,\n    height=700,\n    yaxis={\n         'title_text': 'Relative importance'\n    }\n)\n\nfor feature_name in feature_rankings.index:\n    fig.add_trace(go.Box(\n        name=feature_name,\n        y=feature_rankings.loc[feature_name],\n        text=feature_rankings.columns,\n        showlegend=False\n    ))\n\nfig.show()","3a7894cb":"validation_scores = feature_rankings.copy()\nfor classifier in classifiers:\n    classifier_name = estimator_name(classifier)\n    print(f'Cross validating {classifier_name}')\n    sorted_features = feature_rankings[classifier_name].sort_values()\n    score_means = []\n    score_stds = []\n    for i in range(len(sorted_features)):\n        reduced_feature_subset = sorted_features.index[:i+1]\n        scores = cross_val_score(classifier, X_oh[reduced_feature_subset], y, scoring='accuracy', cv=5, n_jobs=-1)\n        score_means.append(scores.mean())\n        score_stds.append(scores.std())\n    classifier_scores = pd.DataFrame({\n        f'{classifier_name}_accuracy_mean': score_means,\n        f'{classifier_name}_accuracy_std': score_stds,\n    }, index=sorted_features.index)\n    validation_scores = validation_scores.join(classifier_scores, how='inner')\n    assert len(validation_scores) == len(X_oh.columns)\nvalidation_scores","c559ece4":"fig = make_subplots(\n    rows=len(classifiers),\n    cols=1,\n    vertical_spacing=0.1,\n    subplot_titles=[estimator_name(classifier) for classifier in classifiers]\n)\nfig.update_layout(\n    autosize=False,\n    width=1400,\n    height=2200,\n)\n\nfor i, classifier in enumerate(classifiers):\n    classifier_name = estimator_name(classifier)\n    fig.update_yaxes(title_text=\"Accuracy\", range=[0, 1.1], row=i+1, col=1)\n    scores_sorted_by_feature_ranking = validation_scores.sort_values(by=classifier_name)\n    accuracy_mean = scores_sorted_by_feature_ranking[f'{classifier_name}_accuracy_mean']\n    accuracy_std = scores_sorted_by_feature_ranking[f'{classifier_name}_accuracy_std']\n    # print STD area + mean line\n    fig.add_trace(go.Scatter(\n        x=scores_sorted_by_feature_ranking.index.tolist() + scores_sorted_by_feature_ranking.index.tolist()[::-1],\n        y=(accuracy_mean+accuracy_std).tolist() + (accuracy_mean-accuracy_std).tolist()[::-1],\n        fill='toself'\n    ), row=i+1, col=1)\n    fig.add_trace(go.Scatter(\n        x=scores_sorted_by_feature_ranking.index,\n        y=accuracy_mean,\n        showlegend=False\n    ), row=i+1, col=1)\n\nfig.show()","e602dfc1":"chi2kbest = SelectKBest(chi2)\nchi2kbest.fit(X_oh, y)\nmutinfo_kbest = SelectKBest(mutual_info_classif)\nmutinfo_kbest.fit(X_oh, y)","4fc36981":"chi2_sorted_column_names, chi2_sorted_scores = zip(*sorted(zip(X_oh.columns, chi2kbest.scores_), key=lambda x: x[1], reverse=True))\nmutinfo_sorted_column_names, mutinfo_sorted_scores = zip(*sorted(zip(X_oh.columns, mutinfo_kbest.scores_), key=lambda x: x[1], reverse=True))\n\nfig = make_subplots(\n    rows=2,\n    cols=1,\n    vertical_spacing=0.07,\n    subplot_titles=['chi2', 'mutual info classif']\n)\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=800,\n)\n\nn=40\n\nfig.add_trace(go.Bar(x=chi2_sorted_scores[:n], \n                     y=chi2_sorted_column_names[:n], \n                     name='chi2',\n                     orientation='h'),\n              row=1, col=1)\nfig.add_trace(go.Bar(x=mutinfo_sorted_scores[:n],\n                     y=mutinfo_sorted_column_names[:n],\n                     name='mutual info classif',\n                     orientation='h'), \n              row=2, col=1)\n\nfig.show()","6dd403a7":"columns_to_consider = set(mutinfo_sorted_column_names[:n]).union(set(chi2_sorted_column_names[:n]))\nfilter_feature_rankings = pd.DataFrame({}, index=columns_to_consider)\nchi2_scores, mutinfo_scores = [], []\nfor col in columns_to_consider:\n    chi2_score = chi2_sorted_scores[chi2_sorted_column_names.index(col)]\n    mutinfo_score = mutinfo_sorted_scores[mutinfo_sorted_column_names.index(col)]\n    chi2_scores.append(chi2_score)\n    mutinfo_scores.append(mutinfo_score)\nfilter_feature_rankings['chi2_score'] = chi2_scores\nfilter_feature_rankings['mutinfo_score'] = mutinfo_scores\nfilter_feature_rankings.head()","e82056f3":"filter_feature_rankings['chi2_rank'] = filter_feature_rankings['chi2_score'].rank(ascending=False)\nfilter_feature_rankings['mutinfo_rank'] = filter_feature_rankings['mutinfo_score'].rank(ascending=False)","2953dc5f":"summed_rankings = filter_feature_rankings[['chi2_rank', 'mutinfo_rank']].sum(axis=1)\nsorted_rankings = [0] * len(summed_rankings)\nfor i, x in enumerate(sorted(range(len(summed_rankings)), key=lambda y: summed_rankings[y])):\n    sorted_rankings[x] = i + 1  # offset so that lowest rank is 1\nfilter_feature_rankings['overall_rank'] = sorted_rankings\nfilter_feature_rankings.sort_values(by='overall_rank').head(20)","546f3877":"filter_validation_scores = filter_feature_rankings.copy()\nfilter_validation_scores = filter_validation_scores.sort_values(by='overall_rank')\nfor classifier in classifiers:\n    classifier_name = estimator_name(classifier)\n    print(f'Cross validating {classifier_name}')\n    score_means = []\n    score_stds = []\n    for i in range(len(filter_feature_rankings)):\n        reduced_feature_subset = filter_validation_scores.index[:i+1]\n        scores = cross_val_score(classifier, X_oh[reduced_feature_subset], y, scoring='accuracy', cv=5, n_jobs=-1)\n        score_means.append(scores.mean())\n        score_stds.append(scores.std())\n    classifier_scores = pd.DataFrame({\n        f'{classifier_name}_accuracy_mean': score_means,\n        f'{classifier_name}_accuracy_std': score_stds,\n    }, index=filter_validation_scores.index)\n    filter_validation_scores = filter_validation_scores.join(classifier_scores, how='inner')\n    assert len(filter_validation_scores) == len(filter_feature_rankings)\nfilter_validation_scores.head(10)","6acf2179":"fig = make_subplots(\n    rows=len(classifiers),\n    cols=1,\n    vertical_spacing=0.1,\n    subplot_titles=[estimator_name(classifier) for classifier in classifiers]\n)\nfig.update_layout(\n    autosize=False,\n    width=1400,\n    height=2200,\n)\n\n\nfor i, classifier in enumerate(classifiers):\n    classifier_name = estimator_name(classifier)\n    fig.update_yaxes(title_text=\"Accuracy\", range=[0, 1.1], row=i+1, col=1)\n    accuracy_mean = filter_validation_scores[f'{classifier_name}_accuracy_mean']\n    accuracy_std = filter_validation_scores[f'{classifier_name}_accuracy_std']\n    # print STD area + mean line\n    fig.add_trace(go.Scatter(\n        x=scores_sorted_by_feature_ranking.index.tolist() + scores_sorted_by_feature_ranking.index.tolist()[::-1],\n        y=(accuracy_mean+accuracy_std).tolist() + (accuracy_mean-accuracy_std).tolist()[::-1],\n        fill='toself'\n    ), row=i+1, col=1)\n    fig.add_trace(go.Scatter(\n        x=scores_sorted_by_feature_ranking.index,\n        y=accuracy_mean,\n        showlegend=False\n    ), row=i+1, col=1)\n\nfig.show()","119c1791":"decision_tree = classifiers[2]\ncols = filter_validation_scores.index[:18]\ndecision_tree.fit(X_oh[cols], y)\nprint(f'Accuracy: {decision_tree.score(X_oh[cols], y)}')\nfig, ax = plt.subplots(figsize=(25, 25))\n_ = plot_tree(classifiers[2], feature_names=cols, class_names=['eatable', 'poisonous'],\n              filled=True, fontsize=13, ax=ax)","c2e4852a":"No missing values. All features are categorical (or maybe ordinal)"}}