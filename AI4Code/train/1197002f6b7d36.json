{"cell_type":{"694c83a5":"code","d9872fc4":"code","7ad22429":"code","48c8a21a":"code","81ec8c53":"code","02792b42":"code","bd2ce12e":"code","c5b4ad59":"code","11501d5b":"code","0f89cff5":"code","162a4210":"code","66d05545":"code","4a464b81":"code","e819c9db":"code","d5271409":"code","6f91b85f":"code","13552df5":"code","a8072246":"code","fcdb9e86":"code","40c677db":"code","134e5f5d":"code","2b0e702d":"code","3476a466":"code","d3a68bdf":"code","b7a3913c":"code","7ac8f974":"code","43e251a7":"code","c759278a":"code","4700ead3":"code","0072ef79":"code","f5d51f88":"code","8c0b4450":"code","3c3fad5a":"code","0fd4598e":"code","0bb6ca8f":"code","6b4ffcda":"code","e0861d97":"code","a6a3b634":"code","d44e6055":"code","17eb818e":"code","8ea7fb8d":"code","bf56ee45":"code","080e6809":"code","0814dd5e":"code","4745ae3a":"code","d0a18f2c":"code","219b9215":"code","927159e3":"code","bd481038":"code","ccdfd18b":"code","ebd8055a":"code","0a710a97":"code","68e29697":"code","d3778146":"code","d7123861":"code","162f44d1":"code","cd46397d":"code","f346068e":"code","7f596cb6":"code","cb01f2e3":"code","b1b7b189":"code","fe62003f":"code","a0128c15":"code","0b75ff14":"code","afd48039":"code","5ace8475":"code","301d8a50":"code","ce936543":"code","aadfd61b":"code","107d1359":"code","2112b67b":"code","4ca00a2a":"code","e5803946":"markdown","1ba91f4d":"markdown","ce37adc1":"markdown","8abf63dc":"markdown","5545ec23":"markdown","006205d1":"markdown","a7c1580c":"markdown","cd56169b":"markdown","7c575dfb":"markdown","6e4699a6":"markdown","9e07b0a9":"markdown","16069147":"markdown","99148c83":"markdown","5de7a860":"markdown","57443b16":"markdown","3e8708a4":"markdown","8be327a0":"markdown","830eb4c0":"markdown","939dc87a":"markdown","59a9fac7":"markdown","4dfc94a2":"markdown","9ff8cb95":"markdown","74a344ef":"markdown","8055244f":"markdown","601bcb8d":"markdown","ba1986a7":"markdown","653ff6cd":"markdown","396bb7da":"markdown","22d1e3d5":"markdown","a5371adc":"markdown","4b6ee0f2":"markdown","f45bb52e":"markdown","93f1326d":"markdown","4313f60b":"markdown","90f997d3":"markdown","d2b9b479":"markdown","72b4a26d":"markdown","681df99f":"markdown","2f95fa2a":"markdown","7ef6ba18":"markdown","9eff5651":"markdown"},"source":{"694c83a5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d9872fc4":"import re\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib\nmatplotlib.rcParams[\"figure.dpi\"] = 100","7ad22429":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nmerged_data = pd.concat([train_data, test_data]).reset_index(drop=True)\nmerged_data.sample(5)","48c8a21a":"def row_col(data):\n    print(\"Total rows present in dataset    - {}\".format(data.shape[0]))\n    print(\"Total columns present in dataset - {}\".format(data.shape[1]))\n\nprint(\"Training Data: \")\nrow_col(train_data)\nprint()\nprint(\"Testing Data: \")\nrow_col(test_data)","81ec8c53":"def get_cat_num(data):\n    \n    categorical = []\n    numerical = []\n\n    for column in data.drop('Survived', axis=1).columns:\n        if data[column].dtype == \"O\":\n            categorical.append(column)\n        else:\n            numerical.append(column)\n    \n    return categorical, numerical\n\ncategorical, numerical = get_cat_num(merged_data)\nprint(\"Target variable is 'Survived'.\")\nprint()\nprint(\"There are {} categorical features.\".format(len(categorical)))\nprint(\"Categorical features: {}\".format(categorical))\nprint()\nprint(\"There are {} numerical features.\".format(len(numerical)))\nprint(\"Numerical features: {}\".format(numerical))","02792b42":"merged_data.info()","bd2ce12e":"merged_data.isnull().sum()","c5b4ad59":"age_to_be_filled = merged_data.dropna().groupby(['Pclass', 'Sex']).apply(lambda df: round(df['Age'].median(), 0))\nage_to_be_filled","11501d5b":"def fill_age(row):\n    row['Age'] = age_to_be_filled[row['Pclass']][row['Sex']]\n    return row\n\nmerged_data[merged_data['Age'].isna()] = merged_data[merged_data['Age'].isna()].apply(lambda r: fill_age(r), axis=1)","0f89cff5":"merged_data[merged_data['Fare'].isnull()]","162a4210":"merged_data.groupby(['Embarked', 'Pclass']).apply(lambda df: df['Fare'].mean())","66d05545":"merged_data.loc[merged_data['Ticket']=='3701', 'Fare'] = 14.43","4a464b81":"merged_data['Embarked'].fillna(merged_data['Embarked'].mode()[0], inplace=True)","e819c9db":"merged_data['Deck'] = merged_data['Cabin'].str[0]\npd.crosstab(merged_data['Deck'], merged_data['Pclass'])","d5271409":"merged_data['Deck'] = merged_data['Deck'].fillna(merged_data['Pclass'].map({1:'ABCDET', 2:'DEF', 3:'EFG'}))","6f91b85f":"merged_data.drop('Cabin', axis=1, inplace=True)","13552df5":"# Ok, we have filled all missing values. Here missing values in Survived is nothing but testing data records.\n\nmerged_data.isnull().sum()","a8072246":"def chi_square_test(df, var1, var2):\n    '''\n    H0 : Two variables are independent.\n    H1 : Two variables are correlated.\n    '''\n    contigency = pd.crosstab(df[var1], df[var2])\n    chi2, p, dof, expected = chi2_contingency(contigency)\n    \n    print('P value          :', p)\n    print()\n    print('Result:')\n    \n    if p <= 0.05:\n        print('We\\'ll reject H0. Means {} and {} are correlated variables.'.format(var1, var2))\n    else:\n        print('We\\'ll not reject H0. Means {} and {} are independent variables.'.format(var1, var2))","fcdb9e86":"merged_data.drop(columns='PassengerId', inplace=True)","40c677db":"fig = px.pie(names=merged_data['Survived'].value_counts().index, values=merged_data['Survived'].value_counts().values, hole=0.5, template='seaborn')\nfig.update_layout(title='Pie chart of Survived')\nfig.show()","134e5f5d":"merged_data.corr()[['Survived']]","2b0e702d":"fig = sns.barplot(merged_data['Pclass'].value_counts().index, merged_data['Pclass'].value_counts().values, palette='coolwarm')\nfig.set_title('Count plot of Pclass', fontsize=14, fontweight='bold')\nfig.bar_label(fig.containers[0])\nplt.show()","3476a466":"merged_data.groupby('Pclass').apply(lambda df: df['Fare'].median()).reset_index(name='Fare')","d3a68bdf":"fig = px.histogram(data_frame=train_data, x='Pclass', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Pclass | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)\nfig.show()","b7a3913c":"chi_square_test(train_data, 'Pclass', 'Survived')","7ac8f974":"def get_text(name):\n    return re.findall(', (.*?)\\.', name)[0]\n\nmerged_data['Name'] = merged_data['Name'].apply(lambda x: get_text(x))\nmerged_data.rename(columns={'Name': 'Title'}, inplace=True)","43e251a7":"plt.figure(figsize=(12,6))\nfig = sns.barplot(merged_data['Title'].value_counts().values, merged_data['Title'].value_counts().index, palette='coolwarm')\nfig.set_title('Count plot of Title', fontsize=14, fontweight='bold')\nfig.bar_label(fig.containers[0])\nplt.show()","c759278a":"merged_data['Title'] = np.where(merged_data['Title'].isin(['Mr', 'Miss', 'Mrs', 'Master', 'Rev', 'Dr']), merged_data['Title'], 'Other')","4700ead3":"# If you look closely merged_data[~merged_data['Survived'].isna()] is training data.\n\nfig = px.histogram(data_frame=merged_data[~merged_data['Survived'].isna()], x='Title', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Title | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)\nfig.show()","0072ef79":"chi_square_test(merged_data[~merged_data['Survived'].isna()], 'Title', 'Survived')","f5d51f88":"merged_data['Title'] = merged_data['Title'].map({'Mrs':0, 'Miss':1, 'Other':2, 'Master':3, 'Dr':4, 'Mr':5, 'Rev':6})","8c0b4450":"fig = px.pie(names=merged_data['Sex'].value_counts().index, values=merged_data['Sex'].value_counts().values, hole=0.5, template='seaborn')\nfig.update_layout(title='Pie chart of Sex')","3c3fad5a":"fig = px.histogram(data_frame=train_data, x='Sex', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Sex | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)","0fd4598e":"chi_square_test(train_data, 'Sex', 'Survived')","0bb6ca8f":"merged_data['Sex'].replace({'male':0, 'female':1}, inplace=True)","6b4ffcda":"plt.figure(figsize=(12,4))\nsns.distplot(train_data[train_data['Survived']==0]['Age'], label='Not Survived', hist=False)\nsns.distplot(train_data[train_data['Survived']==1]['Age'], label='Survived', hist=False)\nplt.xticks(range(0,100,5))\nplt.xlim((0,90))\nplt.legend()\nplt.show()","e0861d97":"merged_data.loc[merged_data['Age']<=15, 'Age'] = 1\nmerged_data.loc[(merged_data['Age']<=30) & (merged_data['Age']>15), 'Age'] = 2\nmerged_data.loc[(merged_data['Age']<=40) & (merged_data['Age']>30), 'Age'] = 3\nmerged_data.loc[(merged_data['Age']<=58) & (merged_data['Age']>40), 'Age'] = 4\nmerged_data.loc[merged_data['Age']>58, 'Age'] = 5","a6a3b634":"fig = px.histogram(data_frame=merged_data[~merged_data['Survived'].isna()], x='Age', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Age | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)","d44e6055":"chi_square_test(merged_data[~merged_data['Survived'].isna()], 'Age', 'Survived')","17eb818e":"plt.figure(figsize=(8,5))\nfig = sns.barplot(merged_data['SibSp'].value_counts().index, merged_data['SibSp'].value_counts().values, palette='coolwarm')\nfig.set_title('Count plot of SibSp', fontsize=14, fontweight='bold')\nfig.bar_label(fig.containers[0])\nplt.show()","8ea7fb8d":"plt.figure(figsize=(8,5))\nfig = sns.barplot(merged_data['Parch'].value_counts().index, merged_data['Parch'].value_counts().values, palette='coolwarm')\nfig.set_title('Count plot of Parch', fontsize=14, fontweight='bold')\nfig.bar_label(fig.containers[0])\nplt.show()","bf56ee45":"merged_data['Familysize'] = merged_data['Parch'] + merged_data['SibSp'] + 1\nmerged_data.drop(columns=['Parch', 'SibSp'], inplace=True)","080e6809":"merged_data['Familysize'].value_counts()","0814dd5e":"merged_data.loc[ merged_data['Familysize'] == 1, 'Familysize'] = 0\nmerged_data.loc[(merged_data['Familysize'] > 1) & (merged_data['Familysize'] <= 4), 'Familysize'] = 1\nmerged_data.loc[(merged_data['Familysize'] > 4) & (merged_data['Familysize'] <= 7), 'Familysize'] = 2\nmerged_data.loc[ merged_data['Familysize'] > 7, 'Familysize'] = 3","4745ae3a":"merged_data['Familysize'].value_counts()","d0a18f2c":"fig = px.histogram(data_frame=merged_data[~merged_data['Survived'].isna()], x='Familysize', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Familysize | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)","219b9215":"chi_square_test(merged_data[~merged_data['Survived'].isna()], 'Familysize', 'Survived')","927159e3":"merged_data.drop('Ticket', axis=1, inplace=True)","bd481038":"sns.stripplot(merged_data['Survived'], merged_data['Fare'])\nplt.show()","ccdfd18b":"sns.stripplot(merged_data['Pclass'], merged_data['Fare'])\nplt.show()","ebd8055a":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\nsns.distplot(merged_data['Fare'], hist=False, ax=ax1)\nax1.set_title('Distribution(Before)')\nsns.boxplot(merged_data['Fare'], ax=ax2)\nax2.set_title('Boxplot(Before)')\nplt.show()","0a710a97":"# As skewed data is not advisable, we will use log transformer.\n\nmerged_data['Fare'] = np.log1p(merged_data['Fare'])","68e29697":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\nsns.distplot(merged_data['Fare'], hist=False, ax=ax1)\nax1.set_title('Distribution(After)')\nsns.boxplot(merged_data['Fare'], ax=ax2)\nax2.set_title('Boxplot(After)')\nplt.show()","d3778146":"merged_data.groupby('Deck').apply(lambda df: (len(df), df['Fare'].mean())).reset_index(name='length, fare(mean)')","d7123861":"fig = px.histogram(data_frame=merged_data[~merged_data['Survived'].isna()], x='Deck', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Deck | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)","162f44d1":"merged_data['Deck'] = merged_data['Deck'].map({'T':0, 'EFG':1, 'DEF':2, 'ABCDET':3, 'A':4, 'G':5, 'C':6, 'F':7, 'B':8, 'E':9, 'D':10})","cd46397d":"merged_data.groupby('Embarked').apply(lambda df: len(df))","f346068e":"fig = px.histogram(data_frame=merged_data[~merged_data['Survived'].isna()], x='Embarked', color='Survived', barnorm='percent', template='seaborn')\nfig.update_layout(title='Embarked | Prob. of Survival', xaxis={'tickmode':'linear'}, bargap=0.2)","7f596cb6":"chi_square_test(train_data, 'Embarked', 'Survived')","cb01f2e3":"train = merged_data[merged_data['Survived'].notna()]\ntest = merged_data[merged_data['Survived'].isna()].reset_index(drop=True)","b1b7b189":"X = pd.get_dummies(train.drop('Survived', axis=1), drop_first=True)\ny = train['Survived']\n\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=21)","fe62003f":"'''\nplt.figure(figsize=(6,3))\nfeature_imp = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\nfeature_imp.plot(kind='bar', title='Feature Importances')\nplt.ylabel('Score')\nplt.show()\n'''","a0128c15":"def get_report(model_name, model, X, y, cv_folds):\n    \n    model.fit(X, y)\n    pred = model.predict(X)\n    \n    cv_score = cross_val_score(model, X, y, cv=cv_folds, scoring='accuracy')\n    \n    print(\"\\n--------------------------- Model Report ---------------------------\")\n    print()\n    print(\"Model    :\", model_name)\n    print(\"Accuracy :\", round(accuracy_score(y, pred), 4))\n    print(\"CV Score : Mean -\", round(cv_score.mean(), 4), \"| Std -\", round(cv_score.std(), 4), \"| Min -\", round(cv_score.min(), 4), \"| Max -\", round(cv_score.max(), 4))\n    print()","0b75ff14":"get_report('Support Vector Classifier', SVC(), X, y, 10)\nget_report('Random Forest Classifier', RandomForestClassifier(), X, y, 10)\nget_report('XGBoost Classifier', XGBClassifier(verbosity = 0), X, y, 10)","afd48039":"parameters = {\n    'kernel': ['rbf'],\n    'C': [1, 5, 10, 100],\n    'gamma': [0.01, 0.1, 0.3, 0.5]\n}\n\nclf_svc = GridSearchCV(SVC(probability=True), parameters, scoring=\"accuracy\", cv=5, n_jobs=-1)\nclf_svc.fit(X_train, y_train)\n\nprint('Best Parameters  :', clf_svc.best_params_)\nprint('Best Score       :', clf_svc.best_score_)\nprint('Validation Score :', clf_svc.score(X_val, y_val))","5ace8475":"parameters = {\n   'bootstrap': [True],\n   'max_depth': [20, 30, 40, 50],\n   'min_samples_split': [8, 10, 12],\n   'min_samples_leaf': [1, 3, 10],\n   'n_estimators': [100, 120, 140]\n}\n\nclf_rfc = GridSearchCV(RandomForestClassifier(), parameters, scoring=\"accuracy\", cv=5)\nclf_rfc.fit(X_train, y_train)\n\nprint('Best Parameters  :', clf_rfc.best_params_)\nprint('Best Score       :', clf_rfc.best_score_)\nprint('Validation Score :', clf_rfc.score(X_val, y_val))","301d8a50":"parameters = {\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [5, 7, 9],\n    'n_estimators' : [20, 40, 60, 80]\n}\n\nclf_xgb = GridSearchCV(XGBClassifier(probability=True, eval_metric='logloss'), parameters, scoring=\"accuracy\", cv=5)\nclf_xgb.fit(X_train, y_train)\n\nprint('Best Parameters  :', clf_xgb.best_params_)\nprint('Best Score       :', clf_xgb.best_score_)\nprint('Validation Score :', clf_xgb.score(X_val, y_val))","ce936543":"def get_prediction(df):\n    \n    prob_1 = clf_svc.best_estimator_.predict_proba(df)[:, 1]\n    prob_2 = clf_rfc.best_estimator_.predict_proba(df)[:, 1]\n    prob_3 = clf_xgb.best_estimator_.predict_proba(df)[:, 1]\n    pred = []\n\n    for p1, p2, p3 in zip(prob_1, prob_2, prob_3):\n        p = sum([p1, p2, p3])\/3\n        if p >=0.4:\n            pred.append(1)\n        else:\n            pred.append(0)\n    \n    return pred","aadfd61b":"prediction = get_prediction(X)\nskplt.metrics.plot_confusion_matrix(y, prediction, figsize=(6,6))\nplt.show()","107d1359":"target_names = ['Survived', 'Not Survived']\nprint(classification_report(y, prediction, target_names=target_names))","2112b67b":"X_test = pd.get_dummies(test.drop('Survived', axis=1), drop_first=True)\nfinal_pred = get_prediction(X_test)","4ca00a2a":"output = pd.DataFrame({'PassengerId': pd.Series(range(892, 1310)), 'Survived': final_pred})\noutput.to_csv('submission.csv', index=False)","e5803946":"# <center>Kaggle - Titanic: Machine Learning from Disaster<\/center>","1ba91f4d":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Import the Libraries <\/b>\n<\/span>","ce37adc1":"Frome previous two features we'll create new feature <b>Family Size<\/b>.","8abf63dc":"As we can see from above, Class 1 can have 6 possible decks (A,B,C,D,E,T). Class 2 can have 3 decks (D, E, F) and Class 3 can have 3 decks (E,F,G). Here we cannot randomly choose decks according to class. So let create 3 new decks for each class.","5545ec23":"<p style=\"font-size: 28px;color:#5d99ad;\">SibSp<\/p>\n\n>Data type: Numerical(Discrete)\n\n>Number of siblings \/ spouses aboard the Titanic\n\n>Sibling = brother, sister, stepbrother, stepsister\n\n>Spouse = husband, wife","006205d1":"* Family Size: 1 -> Alone\n* Family Size: 2-4 -> Small Family\n* Family Size: 2-4 -> Medium Family\n* Family Size: >7 -> Large Family","a7c1580c":"<p style=\"font-size: 28px;color:#5d99ad;\">Fare<\/p>\n\n>Data type: Numerical(Continous)\n\n>Fare seems very much important feature to predict our target variable.\n\n>Right skewed data.","cd56169b":"<b>Observations:<\/b>\n\n* Unfortunetly around 61.6% passengers couldn't survived.\n* As of now only two numerical features Pclass & Fare seems correlated with target variable.\n\nNote: This is the numbers of training data only","7c575dfb":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Loading & Reading the Data <\/b>\n<\/span>","6e4699a6":"### Age\n\nTo fill the missing values of <b>Age<\/b> we'll use <b>Pclass & Sex<\/b>.","9e07b0a9":"<p style=\"font-size: 28px;color:#5d99ad;\">Age<\/p>\n\n>Data type: Numerical(Continous)\n\n>Age in years\n\n>Age follows Normal Distribution","16069147":"<b>Observations:<\/b>\n\n* Survival rate of Female and boys was higher.","99148c83":"Here, NaN values in Survived column means particular instance is from test data. So we keep it as it is. We can see from above there are 4  other features (Age, Fare, Cabin, Embarked) which contains null values. Before we go further we'll handle these null values.","5de7a860":"### Cabin \n\nAgain we gonna use <b>Pclass<\/b> to fill the missing values of <b>Cabin<\/b>.","57443b16":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Feature Analysis <\/b>\n<\/span>","3e8708a4":"<b>Observations<\/b>:\n\n1. Highest fare was in cabin C. While lowest was in cabin F\n1. B & D were the cabin in which more people(~75%) survived.\n1. More people(75.4%) from cabin F counldn't survived.","8be327a0":"<b>Observations:<\/b>\n\n1. Female had high chances(74%) of survival. Which is very much as compared to male passengers.\n1. Around 64.4% passengers were male.","830eb4c0":"<span style=\"font-size:25px;font-family:Dubai;\">Hyper-parameter Tuning<\/span>","939dc87a":">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\n>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\n>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.","59a9fac7":"<b>Observations<\/b>:\n\n1. Most of the passengers boarded the ship from Southampton.\n1. Passengers who were from 'Cherbourg' had a higher chance of surviving(55.35%).","4dfc94a2":"![titanic.jpg](attachment:b66b4a0d-ddec-4da0-9ebc-24b3f022b7f6.jpg)","9ff8cb95":"<p style=\"font-size: 28px;color:#5d99ad;\">PassengerId<\/p>\n\n>Data type: numerical(continuous)\n\n>Possible Values: 1 to 1309\n\n> Every passenger provived with unique number(w.r.t. this dataset). It has nothing to do with survival. We'll drop PassengerId.","74a344ef":"<b>Observations:<\/b>\n\n1. Most of the passengers were 20-30 years old.\n1. Children were more likely to survive.\n1. Higher the age lower the chances of survival.","8055244f":"<p style=\"font-size: 28px;color:#5d99ad;\">Name<\/p>\n\n>This feature may not directly contribute to survival. Here we can do one thing extract only title from all passenger's name.","601bcb8d":"<p style=\"font-size: 28px;color:#5d99ad;\">Pclass<\/p>\n\n>Data type: Categorical(Ordinal)\n\n>Possible Values: 1(Upper Class) or 2(Middle Class) or 3(Lower Class)\n\n>It is a ticket class. This feature may be very useful for prediction.","ba1986a7":"<p style=\"font-size: 28px;color:#5d99ad;\">Parch<\/p>\n\n>Data type: Numerical(Discrete)\n\n>Number of parents \/ children aboard the Titanic\n\n>Parent = mother, father\n\n>Child = daughter, son, stepdaughter, stepson","653ff6cd":"<span style=\"font-size:25px;font-family:Dubai;\">Final Model<\/span>","396bb7da":"<p style=\"font-size: 28px;color:#5d99ad;\">Survived<\/p>\n\n>Data type: Categorical\n\n>Possible Values: 0(No) or 1(Yes)\n\n>This feature is cause of all this mess. I mean this is our target variable. We gonna predict whether person survived.","22d1e3d5":"### Embarked \n\nTo fill the missing values of <b>Embarked<\/b> we'll use mode. ","a5371adc":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Model Building <\/b>\n<\/span>","4b6ee0f2":"<p style=\"font-size: 28px;color:#5d99ad;\">Ticket<\/p>\nI don't think this <b>Ticket<\/b> feature is important to predict whether passenger survived or not. So, we'll drop it.","f45bb52e":"<p style=\"font-size: 28px;color:#5d99ad;\">Deck<\/p>\n\n>Data type: Categorical","93f1326d":"<p style=\"font-size: 28px;color:#5d99ad;\">Sex<\/p>\n\n>Data type: Categorical\n\n>Possible Values: male or female\n\n>Gender of Passenger","4313f60b":"<p style=\"font-size: 28px;color:#5d99ad;\">Embarked<\/p>\n\n>Data type: Categorical\n\n>Possible Values: C, Q, S\n\n>Where the traveler mounted from.\n\n>C = Cherbourg, Q = Queenstown, S = Southampton","90f997d3":"<b>Observations:<\/b>\n\n* We can clearly see that passengers from class-1 had higher chances(63%) of survive.\n* More passengers were travelling in class-3.\n* Fare of class-1 is much higher than rest of the two.","d2b9b479":"You can match both the box plots. Now, there are very less outliers.","72b4a26d":"### Fare ","681df99f":"<b>Observations<\/b>:\n\n1. Passengers who are alone were less likely to survive. \n1. All the passengers who are with large family fail to survive. \n1. Around 58% passengers with small size family survived.","2f95fa2a":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Meta Information of Data <\/b>\n<\/span>","7ef6ba18":"<span style=\"font-size:25px;font-family:Dubai;display:block;background-color:#fdfd96;color:#1b395b;height:35px;text-align:center;padding:2px;\"><b> Impute Missing Values <\/b>\n<\/span>","9eff5651":"<b>Observations<\/b>:\n\n1. Most people who survived in disaster had paid high amount.\n1. Class-1 had higher fare. And we have aleardy seen among these 3 classes passengers from Class-1 were more likely to survive. Simply if you have paid high then probability of survival was high."}}