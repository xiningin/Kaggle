{"cell_type":{"c170daae":"code","d97a4a86":"code","ab63d732":"code","a8e0a826":"code","7e42bfc0":"code","3383ca61":"code","bf5bbef8":"code","caee6021":"code","751cb620":"code","6ded0596":"code","4a11b41b":"code","7b0b8969":"code","1b845d91":"code","5edc59f8":"code","320a0e50":"code","4eb9665b":"code","a3b78bef":"code","2f465af6":"code","78e1c2a0":"code","1d7187a7":"code","227f17b9":"code","e1eb4301":"code","9644c23d":"code","2e1664f2":"code","9dd8369c":"code","f2246ec7":"code","9a2c6ff7":"code","bb505fc2":"code","7e1780f2":"code","6139551f":"code","9f2c4388":"code","cf155877":"code","a9ff8e3e":"code","94082b0c":"code","05404671":"code","96ba4541":"code","87d4ae48":"code","b2b8b52f":"code","3c9d8126":"code","30981b5d":"code","41863fda":"code","0ff33c43":"code","16d94c8c":"code","6c94bdfe":"code","022428b5":"code","5e48adbf":"code","9b78938e":"code","6565c49e":"code","1be33a4b":"code","412ecec6":"code","d4c105dc":"code","fc71e4ad":"code","128f6bf7":"code","2914ca12":"code","0c54e9a9":"code","c0ee7568":"code","88281b87":"code","3af2d85f":"code","fc62e6e5":"code","c76887a1":"code","795cdcfa":"code","ad767db3":"code","365a1dbe":"code","8575e692":"code","64467a80":"code","228b343b":"code","1d636730":"markdown","050b9b74":"markdown","b7b149a6":"markdown","34b3ff05":"markdown","d67f9d8c":"markdown","2f71480c":"markdown","394716c4":"markdown","4da26369":"markdown","1ab314be":"markdown","48d5360b":"markdown","d5de1f74":"markdown","6b1a130d":"markdown","aeb8fa0d":"markdown","e7a0689d":"markdown","80962f78":"markdown","0ce5fdd2":"markdown","847bc1b7":"markdown","da031c7a":"markdown"},"source":{"c170daae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d97a4a86":"pip install --upgrade pip","ab63d732":"import numpy as np\nimport pandas as pd\nimport random\nseed = 44  \nrandom.seed(seed)\nnp.random.seed(seed)","a8e0a826":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7e42bfc0":"train =  pd.read_csv(\"\/kaggle\/input\/wids-datasets\/TrainingWiDS2021.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/wids-datasets\/UnlabeledWiDS2021.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/wids-datasets\/SolutionTemplateWiDS2021.csv\")","3383ca61":"train = train.drop(['Unnamed: 0'], axis =1)\ntrain.head()","bf5bbef8":"test = test.drop(['Unnamed: 0'], axis =1)\ntest.head()","caee6021":"submission.head()","751cb620":"train.shape, test.shape, submission.shape","6ded0596":"train.info()","4a11b41b":"train.dtypes","7b0b8969":"train.columns","1b845d91":"train = train.drop(['hospital_id'], axis = 1)   # \"hospital_id\" has no positive effcet on model performance\ntest = test.drop(['hospital_id'], axis = 1)\n\ntrain = train.drop(['readmission_status'], axis = 1) # \"readmission_status\" being a constant feature\ntest = test.drop(['readmission_status'], axis = 1)","5edc59f8":"train['encounter_id'] = train['encounter_id'].astype(\"object\")\ntrain['icu_id'] = train['icu_id'].astype(\"object\")\n\ntest['encounter_id'] = test['encounter_id'].astype(\"object\")\ntest['icu_id'] = test['icu_id'].astype(\"object\")","320a0e50":"categorical_feats= train.dtypes[train.dtypes == \"object\"].index; categorical_feats","4eb9665b":"numerical_feats= train.dtypes[train.dtypes != \"object\"].index; numerical_feats","a3b78bef":"train['ethnicity_count']= train.groupby([\"ethnicity\"])[\"encounter_id\"].transform(\"count\")\ntrain['gender_count']= train.groupby([\"gender\"])[\"encounter_id\"].transform(\"count\")\ntrain['hospital_admit_source_count']= train.groupby([\"hospital_admit_source\"])[\"encounter_id\"].transform(\"count\")\ntrain['icu_admit_source_count']= train.groupby([\"icu_admit_source\"])[\"encounter_id\"].transform(\"count\")\ntrain['icu_stay_type_count']= train.groupby([\"icu_stay_type\"])[\"encounter_id\"].transform(\"count\")\ntrain['icu_type_count']= train.groupby([\"icu_type\"])[\"encounter_id\"].transform(\"count\")\ntrain['icu_id_count']= train.groupby([\"icu_id\"])[\"encounter_id\"].transform(\"count\")\n\ntest['ethnicity_count']= test.groupby([\"ethnicity\"])[\"encounter_id\"].transform(\"count\")\ntest['gender_count']= test.groupby([\"gender\"])[\"encounter_id\"].transform(\"count\")\ntest['hospital_admit_source_count']= test.groupby([\"hospital_admit_source\"])[\"encounter_id\"].transform(\"count\")\ntest['icu_admit_source_count']= test.groupby([\"icu_admit_source\"])[\"encounter_id\"].transform(\"count\")\ntest['icu_stay_type_count']= test.groupby([\"icu_stay_type\"])[\"encounter_id\"].transform(\"count\")\ntest['icu_type_count']= test.groupby([\"icu_type\"])[\"encounter_id\"].transform(\"count\")\ntest['icu_id_count']= test.groupby([\"icu_id\"])[\"encounter_id\"].transform(\"count\")","2f465af6":"list(numerical_feats)","78e1c2a0":"train.shape, test.shape","1d7187a7":"ntrain = train.shape[0]\nntest = test.shape[0]\n\nall_data = pd.concat((train, test)).reset_index(drop=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","227f17b9":"num_col =  ['age','bmi','elective_surgery','height','pre_icu_los_days','weight', \n            'albumin_apache','apache_2_diagnosis','apache_3j_diagnosis','apache_post_operative','arf_apache',\n            'bilirubin_apache','bun_apache','creatinine_apache','fio2_apache','gcs_eyes_apache','gcs_motor_apache',\n            'gcs_unable_apache','gcs_verbal_apache','glucose_apache','heart_rate_apache','hematocrit_apache',\n            'intubated_apache','map_apache','paco2_apache','paco2_for_ph_apache','pao2_apache','ph_apache',\n            'resprate_apache','sodium_apache','temp_apache','urineoutput_apache','ventilated_apache','wbc_apache',\n            'd1_diasbp_invasive_max','d1_diasbp_invasive_min','d1_diasbp_max','d1_diasbp_min',\n            'd1_diasbp_noninvasive_max','d1_diasbp_noninvasive_min','d1_heartrate_max','d1_heartrate_min',\n            'd1_mbp_invasive_max','d1_mbp_invasive_min','d1_mbp_max','d1_mbp_min','d1_mbp_noninvasive_max',\n            'd1_mbp_noninvasive_min','d1_resprate_max','d1_resprate_min','d1_spo2_max','d1_spo2_min',\n            'd1_sysbp_invasive_max','d1_sysbp_invasive_min','d1_sysbp_max','d1_sysbp_min','d1_sysbp_noninvasive_max',\n            'd1_sysbp_noninvasive_min','d1_temp_max','d1_temp_min','h1_diasbp_invasive_max','h1_diasbp_invasive_min',\n            'h1_diasbp_max','h1_diasbp_min','h1_diasbp_noninvasive_max','h1_diasbp_noninvasive_min','h1_heartrate_max',\n            'h1_heartrate_min','h1_mbp_invasive_max','h1_mbp_invasive_min','h1_mbp_max','h1_mbp_min',\n            'h1_mbp_noninvasive_max','h1_mbp_noninvasive_min','h1_resprate_max','h1_resprate_min','h1_spo2_max',\n            'h1_spo2_min','h1_sysbp_invasive_max','h1_sysbp_invasive_min','h1_sysbp_max','h1_sysbp_min',\n            'h1_sysbp_noninvasive_max','h1_sysbp_noninvasive_min','h1_temp_max','h1_temp_min','d1_albumin_max',\n            'd1_albumin_min','d1_bilirubin_max','d1_bilirubin_min','d1_bun_max','d1_bun_min','d1_calcium_max',\n            'd1_calcium_min','d1_creatinine_max','d1_creatinine_min','d1_glucose_max','d1_glucose_min',\n            'd1_hco3_max','d1_hco3_min','d1_hemaglobin_max','d1_hemaglobin_min','d1_hematocrit_max',\n            'd1_hematocrit_min','d1_inr_max','d1_inr_min','d1_lactate_max','d1_lactate_min','d1_platelets_max',\n            'd1_platelets_min','d1_potassium_max','d1_potassium_min','d1_sodium_max','d1_sodium_min','d1_wbc_max',\n            'd1_wbc_min','h1_albumin_max','h1_albumin_min','h1_bilirubin_max','h1_bilirubin_min','h1_bun_max',\n            'h1_bun_min','h1_calcium_max','h1_calcium_min','h1_creatinine_max','h1_creatinine_min','h1_glucose_max',\n            'h1_glucose_min','h1_hco3_max','h1_hco3_min','h1_hemaglobin_max','h1_hemaglobin_min','h1_hematocrit_max',\n            'h1_hematocrit_min','h1_inr_max','h1_inr_min','h1_lactate_max','h1_lactate_min','h1_platelets_max',\n            'h1_platelets_min','h1_potassium_max','h1_potassium_min','h1_sodium_max','h1_sodium_min','h1_wbc_max',\n            'h1_wbc_min','d1_arterial_pco2_max','d1_arterial_pco2_min','d1_arterial_ph_max','d1_arterial_ph_min',           \n            'd1_arterial_po2_max','d1_arterial_po2_min','d1_pao2fio2ratio_max',\n            'd1_pao2fio2ratio_min','h1_arterial_pco2_max','h1_arterial_pco2_min','h1_arterial_ph_max',\n            'h1_arterial_ph_min','h1_arterial_po2_max','h1_arterial_po2_min','h1_pao2fio2ratio_max',\n            'h1_pao2fio2ratio_min','aids','cirrhosis','hepatic_failure','immunosuppression','leukemia','lymphoma',\n            'solid_tumor_with_metastasis','diabetes_mellitus','ethnicity_count','gender_count',\n            'hospital_admit_source_count','icu_admit_source_count','icu_stay_type_count','icu_type_count']\n\ncat_col = [col for col in test.columns if col not in num_col]\ncat_col","e1eb4301":"cat_col.remove('encounter_id')","9644c23d":"train.describe()","2e1664f2":"test.describe()","9dd8369c":"sns.countplot(train.diabetes_mellitus)","f2246ec7":"print(\"Are There Missing value in train? :\",train.isnull().any().any())\nprint((train.isnull().sum()\/train.shape[0])*100)","9a2c6ff7":"print(\"Are There Missing value in test? :\",test.isnull().any().any())\nprint((test.isnull().sum()\/test.shape[0])*100)","bb505fc2":"f,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(train.corr(),annot=True,linewidth=.5,fmt='.1f',ax=ax)\nplt.show()","7e1780f2":"all_data.head()","6139551f":"def check_categorical_relationship(cat_col,y_col,df):\n    for feat in cat_col:\n        plt.figure(figsize=(20,5))\n        sns.barplot(df[feat],df[y_col])\n        plt.show()\n        print(\"\\n \\n \\n \")","9f2c4388":"check_categorical_relationship(cat_col,'age',all_data)","cf155877":"all_data.gender.unique()","a9ff8e3e":"all_data = all_data.fillna(9999)\nall_data.head()","94082b0c":"print(\"Are There still Missing value in data? :\",all_data.isnull().any().any())\nprint((all_data.isnull().sum()\/all_data.shape[0])*100)","05404671":"all_data.gender.unique()","96ba4541":"mapper = {\"M\":\"M\",\"F\":'F',9999:'O'}","87d4ae48":"all_data.gender = all_data.gender.map(mapper)","b2b8b52f":"all_data.gender.unique()","3c9d8126":"final_data=pd.get_dummies(all_data,columns=cat_col)","30981b5d":"all_data.diabetes_mellitus = all_data.diabetes_mellitus.astype(int)\nfinal_data.diabetes_mellitus = final_data.diabetes_mellitus.astype(int)","41863fda":"final_data.drop(columns=['encounter_id'],inplace=True)","0ff33c43":"#Get the new dataset\ntrain_n = final_data[:ntrain]\ntest_n = final_data[ntrain:]","16d94c8c":"TARGET_COL = 'diabetes_mellitus'","6c94bdfe":"train_n[TARGET_COL].value_counts()\/len(train_n)","022428b5":"print(train_n.shape,test_n.shape)","5e48adbf":"# Separate majority and minority classes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\ndf_majority = train_n[train_n['diabetes_mellitus']==0]\ndf_minority = train_n[train_n['diabetes_mellitus']==1]\n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=83798,    # to match majority class\n                                 random_state= 303) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.diabetes_mellitus.value_counts()","9b78938e":"train_n = df_upsampled","6565c49e":"X= train_n.drop(columns=['diabetes_mellitus'])\ny= train_n.diabetes_mellitus","1be33a4b":"!pip install lightgbm","412ecec6":"import lightgbm as lgb   \nmodel = lgb.LGBMClassifier(random_state=44,n_estimators=1000,silent=False,\n                           scale_pos_weight= 1,colsample_bylevel=0.8,subsample=0.8)  \nmodel.fit(X,y)","d4c105dc":"fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': X.columns})\nfea_imp.sort_values(by='imp',ascending=False,inplace=True)\nfea_imp.head(30)","fc71e4ad":"index_to_use_later = test['encounter_id'].values","128f6bf7":"cols=list(X.columns)\noutput= model.predict_proba(test_n[cols])","2914ca12":"submission_df = pd.DataFrame(columns=['encounter_id','diabetes_mellitus'])    \nsubmission_df['encounter_id'] = index_to_use_later\nsubmission_df['diabetes_mellitus'] = output[:,1]              # 0.85382 on LB","0c54e9a9":"submission_df.to_csv('lgb1_sub.csv',index=False)    \nsubmission_df.head()","c0ee7568":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify = y)","88281b87":"import lightgbm as lgb\nclf1 = lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bylevel=0.8,\n               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n               min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=31,\n               objective=None, random_state=44, reg_alpha=0.0, reg_lambda=0.0,\n               scale_pos_weight=1, silent=False, subsample=0.8,\n               subsample_for_bin=200000, subsample_freq=0)  ","3af2d85f":"from sklearn.model_selection import KFold,StratifiedKFold\nkf = StratifiedKFold(n_splits= 5, shuffle=True)\n\npredicts = []\nfor train_index, test_index in kf.split(X, y):\n    print(\"###\")\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    clf1.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100,verbose=200)\n    predicts.append(clf1.predict_proba(X_test))  ","fc62e6e5":"test_pred = clf1.predict_proba(test_n[cols])","c76887a1":"submit = pd.DataFrame({'encounter_id':index_to_use_later})\nsubmit['diabetes_mellitus'] = test_pred[:,1]\nsubmit.to_csv(\"sub_lgb2_5kfold.csv\", index = False)           # 0.85005 on LB                                                        \nsubmit.head()","795cdcfa":"model= lgb.LGBMClassifier(random_state=44,early_stopping_rounds = 250,\n                      n_estimators=10000,min_data_per_group=5, # reduce overfitting when using categorical_features\n                      boosting_type='gbdt',num_leaves=151,max_depth=- 1,\n                      learning_rate=0.02,subsample_for_bin=200000, \n                      min_split_gain=0.0,min_child_weight=0.001,min_child_samples=20,\n                      subsample=1.0,subsample_freq=0,colsample_bytree=.75,reg_alpha=1.3, \n                      reg_lambda=0.1,n_jobs=- 1,cat_smooth=1.0, \n                      silent=True, importance_type='split')                                   \nmodel.fit(X_train,y_train,eval_set=[(X_test, y_test)],eval_metric = 'auc',verbose=False)","ad767db3":"from sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nprint(f\"accuracy score is {accuracy_score(y_test, model.predict(X_test))}\")              \nprint(metrics.classification_report(y_test, model.predict(X_test), labels=[0, 1]))","365a1dbe":"test_pred = model.predict_proba(test_n[cols])","8575e692":"submit = pd.DataFrame({'encounter_id':index_to_use_later})\nsubmit['diabetes_mellitus'] = test_pred[:,1]\nsubmit.to_csv(\"sub_lgb3.csv\", index = False)         # 0.85948                                                           \nsubmit.head()","64467a80":"#def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, X_test,y_test,\n#                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n#                       do_probabilities = False):\n#    gs = GridSearchCV(\n#        estimator=model,\n#        param_grid=param_grid, \n#        cv=cv, \n#        n_jobs=-1, \n#        scoring=scoring_fit,\n#        verbose=2\n#    )\n#    fitted_model = gs.fit(X_train_data, y_train_data, eval_set=[(X_test, y_test)], eval_metric='l1')\n    \n#    if do_probabilities:\n#      pred = fitted_model.predict_proba(X_test_data)\n#    else:\n#      pred = fitted_model.predict(X_test_data)\n    \n#    return fitted_model, pred","228b343b":"#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n#model = lgb.LGBMClassifier()\n#param_grid = {\n#    'learning_rate' : [0.03,0.04,0.05,0.06],\n#    'n_estimators': [1000],\n#     'colsample_bytree': [0.7],\n#     'max_depth': [20],\n#     'num_leaves': [50, 100, 200],\n#     'reg_alpha': [1.1, 1.2, 1.3],\n#     'reg_lambda': [1.1, 1.2, 1.3],\n#     'min_split_gain': [0.3, 0.4],\n#     'subsample': [0.7, 0.8, 0.9],\n#     'subsample_freq': [20]\n#}\n\n#model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test,X_test,y_test, model, \n#                                 param_grid, cv=5, scoring_fit='accuracy')\n\n#print(model.best_score_)\n#print(model.best_params_)","1d636730":"# Getting rid of unwanted features:","050b9b74":"# Feel free to fork or replicate this Notebook.","b7b149a6":"# Checking for numerical features","34b3ff05":"# Grid Search Approach","d67f9d8c":"# Remember to handle the missing values.","2f71480c":"**The dataset is skewed towards class 0, consider balancing the dataset.**","394716c4":"# Join train and test together","4da26369":"# LGBMClassifier 3:","1ab314be":"# Checking for categorical features","48d5360b":"# LGBMClassifier 1:","d5de1f74":"# Feature Engineering:","6b1a130d":"# Aim and Objectives:\n\n**This Notebook was created purposely to share ideas, learn and to reveal some underlying facts inside the given WIDS datasets.**","aeb8fa0d":"# LGBMClassifier 2 (with 5kfolds):","e7a0689d":"\n\n\n\n# Note: Please, don't forget to upvote this Notebook if you find it very useful. \n\n","80962f78":"# No need of imputation for missing values in the given dataset, you can still achieve a very good score on LB.","0ce5fdd2":"\n# The following steps below were taken to achieve this aforementioned score on the Leaderboard:\n\n- Groupby count of categorical variables using 'encounter_id'.\n- Get rid of unwanted features e.g hospital_id & constant variable \"read-admission\". \n- Fill nan's with \"9999\" and performing some filling missing values techniques on features like \"age\" & gender respectively.\n- Implementating Exploratory Data Analysis (EDA) showing some relationships between feature \"age\" and all categorical features in the given dataset.\n- Creating dummy for all categorical features.\n- Applying Oversampling technique on the minority class \"1\" of the target variable \"diabetes_mellitus\".\n- Three different types of LGBClassifier models were implemented (each with accuracy score of over 85% respectively).","847bc1b7":"# Fill mising value","da031c7a":"\n# This Notebook achieved a score of 0.85948 on LB."}}