{"cell_type":{"3fa1974e":"code","14058bf1":"code","a852e2f4":"code","f9630cc3":"code","764cb71d":"code","03373925":"code","00012554":"code","6af66b7c":"code","65336334":"code","dfe9dddd":"markdown","e0374710":"markdown","9d9ec359":"markdown","036b15d5":"markdown"},"source":{"3fa1974e":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport matplotlib.pyplot as plt\nimport torch\nfrom skimage import exposure\nfrom shutil import copyfile\nfrom IPython.display import Image, clear_output","14058bf1":"# Clone and install YOLOv5\n!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd yolov5\n%pip install -qr requirements.txt\n%cd ..\/\nclear_output()\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","a852e2f4":"# Copy the requirements file over so we don't have to change directory later. Is there an argument for this?\ncopyfile('yolov5\/requirements.txt', '\/kaggle\/working\/requirements.txt');","f9630cc3":"# Load a DICOM file\ndef load_file(filename):\n    img = pydicom.dcmread(filename)\n    pixels = img.pixel_array\n    max_pixel = np.max(pixels)\n\n    if img.PhotometricInterpretation == \"MONOCHROME1\":\n        pixels = max_pixel - pixels\n        \n    pixels = exposure.equalize_adapthist(pixels)\n    pixels = (pixels * 255).astype(np.uint8)\n    return pixels","764cb71d":"# Call YOLO detect.py with the image we exported\ndef detect():\n    # Clean up results from the last run\n    if os.path.exists('\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt'):\n        os.remove('\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt')\n\n    # Call yolo detect\n    !python yolov5\/detect.py --source test.jpg --weights ..\/input\/cxr-anatomy-detection\/anatomy_detection.pt --img 640 --exist-ok --line-thickness 10 --save-txt","03373925":"# Load a DICOM files\nfilename = '..\/input\/siim-covid19-detection\/train\/01494b9b4423\/fb5ef1804d54\/336db847af0e.dcm'\npixels = load_file(filename)\n\n# Export a JPG for YOLO to predict on\ncv2.imwrite('test.jpg',pixels);\n\n# Run detect\ndetect()\n\n# Plot the original image and the predicted anatomy boxes\nplt.figure(figsize=(16,16)) \n\nplt.subplot(1, 2, 1)\nplt.imshow(pixels, cmap='gray')  \n\nplt.subplot(1, 2, 2)\nimg = cv2.imread('\/kaggle\/working\/runs\/detect\/exp\/test.jpg')\nplt.imshow(img, cmap='gray')","00012554":"# Get the class and BB data from the text file YOLO exports\nboxes = pd.read_csv(\"\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt\", delim_whitespace=True, header=None, index_col=False)\nboxes.head()","6af66b7c":"# Load a DICOM files\nfilename = '..\/input\/siim-covid19-detection\/train\/011475cb6db4\/1e4fb80bda7c\/390ce1f029e7.dcm'\npixels = load_file(filename)\n\n# Export a JPG for YOLO to predict on\ncv2.imwrite('test.jpg',pixels);\n\n# Run detect\ndetect()\n\n# Plot the original image and the predicted anatomy boxes\nplt.figure(figsize=(16,16)) \n\nplt.subplot(1, 2, 1)\nplt.imshow(pixels, cmap='gray')  \n\nplt.subplot(1, 2, 2)\nimg = cv2.imread('\/kaggle\/working\/runs\/detect\/exp\/test.jpg')\nplt.imshow(img, cmap='gray')","65336334":"boxes = pd.read_csv(\"\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt\", delim_whitespace=True, header=None, index_col=False)\nboxes.head()","dfe9dddd":"#### - Let's do another one","e0374710":"#### The predicted bounding boxes are stored in a text file. The first column is the class prediction. The last four columns are the normalized BB coords.\n- Refer to the class list at the top.","9d9ec359":"#### The boxes can be converted to pixel coords and used for cropping or ROI equalization .. or possibly for rotating\/aligning images.\n\n- I demonstrate how to use this to 'Smart Crop' images in this notebook:\nhttps:\/\/www.kaggle.com\/davidbroberts\/smart-cropping-cxr-with-yolov5","036b15d5":"<div class='alert alert-info' style='text-align: center'><h1>Detecting Anatomy on Chest X-Rays with Torch\/YOLOv5<\/h1><\/div>\n\n![cxr.jpg](attachment:77272972-ab15-4dea-a99b-a6ce51529414.jpg)\n\n### This notebook demonstrates a simple YOLO O.D. model I made to detect 10 classes of anatomy on chest radiographs.\n### I hand-annotated all classes on 100 images from the SIIM-FISABIO-COVID19 dataset.\n### I trained the model for 500 epochs on google colab Pro GPU. mAP was over .80 for lungs I think. Not bad for a quick model.\n\n#### The classes it can detect are:\n\n- 0 = Left Lung\n- 1 = Right Lung\n- 2 = Left Clavicle\n- 3 = Right Clavicle\n- 4 = Left Humeral Head\n- 5 = Right Humeral Head\n- 6 = Heart\n- 7 = Gastric Bubble\n- 8 = Carina\n- 9 = Trachea\n\nTrain notebook -> https:\/\/www.kaggle.com\/davidbroberts\/chest-anatomy-detection-train\n\nUsing this model to crop images: https:\/\/www.kaggle.com\/davidbroberts\/smart-cropping-cxr-with-yolov5"}}