{"cell_type":{"d9c00c29":"code","b5a9176b":"code","d80743f1":"code","5f43ca23":"code","ecd592fa":"code","fdff4e8d":"code","d77248da":"code","b91313d0":"code","6a44b8f4":"code","97d087fa":"code","f7f68cc4":"code","27a45f5e":"code","00f7bedd":"code","c3277ee5":"code","f9b962e0":"code","464250df":"code","ccb36b06":"code","d41bcc7c":"code","7cc1a5d3":"code","0854bd03":"code","997b1ee1":"code","35ac5478":"code","92982425":"code","220974c2":"code","5da923f9":"markdown"},"source":{"d9c00c29":"#Requirement already satisfied #in 2020 11 01\n#!pip install pip install tensorflow-addons\n\n!pwd\n\n!nvidia-smi","b5a9176b":"#https:\/\/www.kaggle.com\/yasufuminakama\/moa-pytorch-nn-starter\n#part of codes are derived from above note by Y.Nakama\n\nimport tensorflow.keras.layers\n\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\ntrain_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('..\/input\/lish-moa\/train_targets_nonscored.csv')\nval_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nsubmission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","d80743f1":"# ref: https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180165\n# check if labels for 'ctl_vehicle' are all 0.\ntrain = train_features.merge(train_targets_scored, on='sig_id')\nprint(train.shape)","5f43ca23":"\ntarget_cols = []\n\nfor c in train_targets_scored.columns:\n    if c != 'sig_id':\n        target_cols.append(c)\nprint(len(target_cols))\nprint(target_cols)\n\ncols = target_cols + [\"cp_type\"]\n#print(cols)","ecd592fa":"# constrcut train&test except 'cp_type'=='ctl_vehicle' data\nprint(train_features.shape, val_features.shape)\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nval = val_features[val_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nprint(train.shape, val.shape)","fdff4e8d":"def cate2num(df):\n    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 3, 'D2': 4})\n    return df\n\ntrain = cate2num(train)\nval = cate2num(val)\n\n","d77248da":"print(train.shape,val.shape)","b91313d0":"train_input=train[train_features.columns].values[:,2:].astype(np.float32)\nprint(train_input.shape )\nprint(train_input.dtype)\nprint(train_input)","6a44b8f4":"g_num=770\ntrain_input_g = train_input[:,:g_num]\ntrain_input_c = train_input[:,g_num:]\nprint(train_input_g.shape)\nprint(train_input_c.shape)","97d087fa":"train_label=train[target_cols].values.astype(np.float32)\nprint(train_label.shape)","f7f68cc4":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Dropout, Conv2D, BatchNormalization, Activation,Multiply,Dense,Add\nfrom tensorflow.keras.layers import UpSampling2D, add, concatenate, MaxPooling2D, AveragePooling2D,GlobalAveragePooling2D, Concatenate\nfrom tensorflow_addons.optimizers import RectifiedAdam\n\ndef logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred,0.001,0.999)\n    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))\n\n\ninput_g = Input(shape=(train_input_g.shape[-1],))\n\nx = Dense(2048)(input_g)\nx = BatchNormalization()(x)\nx = Activation(tf.nn.swish)(x)\n\nx = Dense(1024)(x)\nx = BatchNormalization()(x)\nout_g = Activation(tf.nn.swish)(x)\n\ninput_c = Input(shape=(train_input_c.shape[-1],))\nx = Dense(2048)(input_c)\nx = BatchNormalization()(x)\nx = Activation(tf.nn.swish)(x)\n\nx = Dense(1024)(x)\nx = BatchNormalization()(x)\nout_c = Activation(tf.nn.swish)(x)\n\nconcat = Concatenate()([out_g,out_c])\n\nx = Dropout(0.2)(concat)\n\nout = Dense(train_label.shape[-1],activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[input_g,input_c], outputs=out)\n\nmodel.summary()","27a45f5e":"tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True)","00f7bedd":"#opt = tf.keras.optimizers.SGD(0.01)\n#opt = tf.keras.optimizers.Adam(0.001)\nopt = RectifiedAdam(0.0001)\n#\n#model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics =[\"accuracy\"])\n#model.compile(optimizer=opt,loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001)\n#              ,metrics =[logloss])\n\nmodel.compile(optimizer=opt,loss=tf.keras.losses.Huber(delta=1.0, name='huber_loss')\n              ,metrics =[logloss])\n\nepochs = 1000\nresult = model.fit(x= [train_input_g,train_input_c], y = train_label, epochs= epochs, batch_size=2048, validation_split=0.8, verbose=0)","c3277ee5":"print(\"last_val_logloss\",result.history[\"val_logloss\"][-1])\nprint(\"best_val_logloss\",min(result.history[\"val_logloss\"]))\nprint(\"best_val_logloss_epoch\",np.argmin(np.array(result.history[\"val_logloss\"])))\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(range(1, epochs+1), result.history[\"loss\"], label=\"training\")\nplt.plot(range(1, epochs+1), result.history[\"val_loss\"], label=\"validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","f9b962e0":"pred = model.predict([train_input_g[0:20],train_input_c[0:20]])\nmodel.evaluate([train_input_g[0:20],train_input_c[0:20]],train_label[0:20])\n","464250df":"pred_idx = np.argmax(pred,axis=1)\nprint(pred_idx)","ccb36b06":"\nfor i in range(20):\n    tmp = train_label[i]\n    print(np.argmax(tmp),pred_idx[i])","d41bcc7c":"val_input=val[val.columns].values[:,2:].astype(np.float32)\nprint(val_input.shape )\nprint(val_input.dtype)\nprint(val_input)","7cc1a5d3":"print(val_input.shape)\nval_input_g = val_input[:,:g_num]\nval_input_c = val_input[:,g_num:]\nprint(val_input_g.shape,val_input_c.shape)","0854bd03":"predictions = model.predict([val_input_g,val_input_c])","997b1ee1":"print(predictions.shape)\nprint(predictions[0:10])","35ac5478":"#pred_sub = np.where(predictions>0.5,0.999,0.001)\n#pred_sub = np.where(predictions<0.001,0.001,predictions)\n#clipping\npred_sub = np.clip(predictions,0.001,0.999)","92982425":"#print(target_cols)\nval[target_cols] = pred_sub\n#val[[\"sig_id\"]+target_cols].to_csv(\".\/pred.csv\",index=False)","220974c2":"sub = submission.drop(columns=target_cols).merge(val[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub.to_csv('.\/submission.csv', index=False)\nsub.head()","5da923f9":"# split the input into g and c gained the score little"}}