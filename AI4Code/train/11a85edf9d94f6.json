{"cell_type":{"801bdd0b":"code","b4d7f7f1":"code","1c9d4db1":"code","b1da8cda":"code","2a1111b4":"code","9cbe2db8":"code","9fd4d1aa":"code","545f3a48":"code","88bc981f":"code","1cf3083a":"code","c189c981":"code","73f80e76":"code","c881b924":"code","03d5d636":"markdown","839a8ba5":"markdown","e9d5b7a3":"markdown","a846f6c3":"markdown","7c93ca2c":"markdown","a51dec82":"markdown","80c213a8":"markdown","3d541f1d":"markdown","fd0c88ab":"markdown","dfb8cce1":"markdown","e4ec6a0c":"markdown","5ebaff71":"markdown","54d28eb6":"markdown","89f1af85":"markdown","911a10f7":"markdown","7dd9ea11":"markdown","8250ac3f":"markdown","b2dff57c":"markdown","288462a8":"markdown"},"source":{"801bdd0b":"import pandas as pd\ntrain = pd.read_csv('..\/input\/mentalcom\/train.csv')\ntest = pd.read_csv('..\/input\/mentalcom\/test_x.csv')\nsubmission = pd.read_csv('..\/input\/mentalcom\/sample_submission.csv')","b4d7f7f1":"print(train.shape)\nprint(test.shape)\nprint(submission.shape)","1c9d4db1":"pip install pycaret","b1da8cda":"from pycaret.classification import *","2a1111b4":"# 'voted' \uceec\ub7fc\uc774 \uc608\uce21 \ub300\uc0c1\uc774\ubbc0\ub85c target \uc778\uc790\uc5d0 \uba85\uc2dc\n# 'voted' column is the target variable\nclf = setup(data = train, target = 'voted')","9cbe2db8":"best_3 = compare_models(sort = 'AUC', n_select = 3)","9fd4d1aa":"blended = blend_models(estimator_list = best_3, fold = 5, method = 'soft')","545f3a48":"pred_holdout = predict_model(blended)","88bc981f":"final_model = finalize_model(blended)","1cf3083a":"predictions = predict_model(final_model, data = test)","c189c981":"predictions","73f80e76":"submission['voted'] = predictions['Score']","c881b924":"submission.to_csv('submission_proba_0.csv', index = False)","03d5d636":"## \ubd84\ub958 \uc791\uc5c5\uc5d0 \ud544\uc6a9\ud55c \ud568\uc218 \ubd88\ub7ec\uc624\uae30 (Import methods for classification task)","839a8ba5":"## \ubaa8\ub378 \ud559\uc2b5 \ubc0f \ube44\uad50 (Train models and compare)\n\n- \ud658\uacbd \uad6c\ucd95\uc744 \ud588\uc73c\ub2c8 PyCaret\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uae30\ubcf8 \ubaa8\ub378\uc5d0 \ub300\ud574 \ud559\uc2b5\ud558\uace0 \ube44\uad50\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n- compared_models \ud568\uc218\ub97c \ud1b5\ud574 15\uac1c\uc758 \uae30\ubcf8 \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uace0 \uc131\ub2a5\uc744 \ube44\uad50\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n- AUC \uae30\uc900\uc73c\ub85c \uc131\ub2a5\uc774 \uac00\uc7a5 \uc88b\uc740 3\uac1c\uc758 \ubaa8\ub378\uc744 \ucd94\ub824\ub0b4\uc5b4 \uc800\uc7a5\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \ubcf8 \ub300\ud68c \ud3c9\uac00\uc9c0\ud45c\uac00 AUC\uc774\uae30 \ub54c\ubb38\uc5d0 AUC \uae30\uc900\uc73c\ub85c \ubaa8\ub378\uc744 \uc120\uc815\ud569\ub2c8\ub2e4.\n-----\n- Now we have constructed the environment, we will now train and compare the default models provided in PyCaret\n- By using 'compare_models' method we can easily train and compare 15 default models provided in the package\n- We will select top 3 models in terms of AUC, that is because the evaluation metric for this competition is AUC","e9d5b7a3":"- \uc544\ub9c8 0.77 \uc815\ub3c4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc77c \uac83\uc774\uba70 \ucd94\uac00 \uc791\uc5c5\uc744 \ud1b5\ud574 \uc131\ub2a5\uc744 \ub354 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc744\uac70\ub77c \uae30\ub300\ud569\ub2c8\ub2e4. \n- You will probabily get around 0.77 AUC and with additional steps I think we can improve this score. ","a846f6c3":"- predict_model \ud568\uc218\ub97c \ud1b5\ud574 \uc7ac\ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub300\ud68c\uc6a9 test set\uc5d0 \ub300\ud574 \uc608\uce21\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n- We will now use the re-trained model on the test set for the competition","7c93ca2c":"## \ub300\ud68c\uc6a9 test set\uc5d0 \ub300\ud55c \uc608\uce21 (Predicting on test set for the competition)","a51dec82":"\uc774\ubc88 \ucf54\ub4dc\uc5d0\uc11c\ub294 AutoML \ud328\ud0a4\uc9c0\uc778 PyCaret\uc744 \ud65c\uc6a9\ud558\uc5ec \uc815\ud615\ub370\uc774\ud130 \ub300\ud68c\uc5d0 \ucc38\uc5ec\ud558\ub294 \uacfc\uc815\uc744 \uc54c\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. Feature engineering, model tuning \uc5c6\uc774 \uc8fc\uc5b4\uc9c4 \ub370\uc774\ud130\ub97c \uadf8\ub300\ub85c \ud65c\uc6a9\ud558\uc5ec default \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\uace0 \uc608\uce21 \ud588\uc73c\ubbc0\ub85c, \ucd94\uac00 \uc791\uc5c5\uc744 \ud1b5\ud574 \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc904 \uc218 \uc788\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4. \n\n\uac1c\uc778\uc801\uc73c\ub85c PyCaret\uc740 \uc544\uc9c1\uae4c\uc9c0 single output\uc778 \ubb38\uc81c\uc5d0\ub294 \uc801\ud569\ud55c\ub370 multi output \ubb38\uc81c\uc5d0\ub294 \ubd80\uc801\ud569\ud55c\uac83 \uac19\uc2b5\ub2c8\ub2e4. \ud639\uc2dc multi output \ubb38\uc81c\uc5d0\ub3c4 \uc798 \uc801\uc6a9\ub41c\ub2e4\uba74 \uc54c\ub824\uc8fc\uc138\uc694!\n\nIn this kernel we will use an AutoML package called PyCaret to enter data science competitions with structured data. I've used the given data without any feature engineering and trained the models without model tuning, so I expect better scores if we engineer additional feature and tune the models. \n\nI think PyCaret is approporiate for single output prediction tasks, but I still haven't figured out easier way to implement it on multi output prediction tasks. Would appreciate it if anyone could share tutorial code on applying PyCaret on multi output prediction task. ","80c213a8":"- \ud655\ub960 \uac12\uc774 'Score' \uceec\ub7fc\uc5d0 \uc800\uc7a5\ub418\uc5b4 \uc788\uc73c\ubbc0\ub85c \ud574\ub2f9 \uac12\uc744 submission \ud30c\uc77c\uc5d0 \uc62e\uaca8 \ub370\uc774\ucf58\uc5d0 \uc81c\ucd9c\ud558\uaca0\uc2b5\ub2c8\ub2e4. \n- The probability values are stored on 'Score' column. So we will write them on our submission format and submit on DACON.","3d541f1d":"## \ubaa8\ub378 \uc608\uce21 (Prediction)\n- \uad6c\ucd95\ub41c \uc559\uc0c1\ube14 \ubaa8\ub378\uc744 \ud1b5\ud574 \uc608\uce21\uc744 \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n- setup \ud658\uacbd\uc5d0 \uc774\ubbf8 hold-out set\uc774 \uc874\uc7ac\ud558\ubbc0\ub85c \ud574\ub2f9 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \uc608\uce21\uc744 \ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5\uc744 \ud655\uc778\ud558\uaca0\uc2b5\ub2c8\ub2e4. \n\n----\n- We will use the ensembled model on predicting unseen data.\n- There is already a hold-out set constucted on our environment so we will test on it to evaluate the performance.","fd0c88ab":"## \ubaa8\ub378 \uc559\uc0c1\ube14 (Model Ensemble)","dfb8cce1":"## \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 (Read Data)","e4ec6a0c":"- AUC\uac00 0.7725\ub85c \uaf64 \uc900\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n- We got a pretty decent model with AUC of 0.7725","5ebaff71":"- CatBoost Classfier, Gradient Boosting Classifer, LGBM\uc774 \uac00\uc7a5 \uc88b\uc740 3\uac1c\uc758 \ubaa8\ub378\uc785\ub2c8\ub2e4. \ud574\ub2f9 \ubaa8\ub378\uc740 best_3 \ubcc0\uc218\uc5d0 \uc800\uc7a5\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \n- CatBoost Classfier, Gradient Boosting Classifer, and LGBM are the best 3 models. Those models are now stored in best_3 variable. ","54d28eb6":"## \uc815\ud615\ub370\uc774\ud130 \ub300\ud68c\ub294 AutoML\uc5d0 \ub54c\ub824\ubc15\uace0(?) \uc2dc\uc791\ud558\uc790!\n\ucd9c\ucc98 : https:\/\/dacon.io\/competitions\/official\/235647\/codeshare\/1701?page=1&dtype=recent&ptype=pub","89f1af85":"## PyCaret \ud328\ud0a4\uc9c0 \uc124\uce58 (Install PyCaret)","911a10f7":"## \ub370\uc774\ud130 \uad6c\uc870 \ud655\uc778 (Checking the shapes of data)","7dd9ea11":"- \ud559\uc2b5\ub41c 3\uac1c\uc758 \ubaa8\ub378\uc744 \uc559\uc0c1\ube14 \uc2dc\ud0a4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4. \ubcf8 \ub300\ud68c\ub294 score \ucd5c\uc801\ud654\ub97c \uc704\ud574 \ud655\ub960 \uac12\uc744 \uc608\uce21\ud574\uc57c \ud558\ubbc0\ub85c soft vote ensemble\uc744 \uc9c4\ud589\ud558\uaca0\uc2b5\ub2c8\ub2e4. \n------\n- We will now ensemble the three models. In order to optimize the score for this competition we have to predict probabilities, we we will soft-vote ensemble the three models using 'blend_models' method. ","8250ac3f":"## \uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc7ac\ud559\uc2b5 (Re-training the model on whole data)","b2dff57c":"- \ud604\uc7ac\uae4c\uc9c0 \uc2e4\ud5d8\uc740 \uc8fc\uc5b4\uc9c4 train \ub370\uc774\ud130\ub97c \ub2e4\uc2dc \ud55c \ubc88 train \/ validation\uc73c\ub85c \ub098\ub220\uc11c \uc2e4\ud5d8\uc744 \ud55c \uac83\uc774\ubbc0\ub85c, \uc804\uccb4 train \ub370\uc774\ud130\uc5d0 \ud559\uc2b5\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \n- \ucd5c\uc801\uc758 \uc131\ub2a5\uc744 \uc704\ud574 \uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ud559\uc2b5\uc744 \uc2dc\ucf1c\uc8fc\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4. \n\n------\n- Until now we have splitted the given train data into another train \/ validation sets to experiment. So the models are not trained on the full training data set.\n- We will train the model on the whole dataset for the most optimal performance. ","288462a8":"## \uc2e4\ud5d8 \ud658\uacbd \uad6c\ucd95 (Setup the environment)\n\n- PyCaret\uc5d0\uc11c\ub294 \ubaa8\ub378 \ud559\uc2b5 \uc804 \uc2e4\ud5d8 \ud658\uacbd\uc744 \uad6c\ucd95 \ud574\uc8fc\uc5b4\uc57c \ud569\ub2c8\ub2e4. setup \ud568\uc218\ub97c \ud1b5\ud574 \ud658\uacbd\uc744 \uad6c\ucd95\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n- setup \ub2e8\uacc4\uc5d0\uc11c\ub294 PyCaret\uc774 \uc790\ub3d9\uc73c\ub85c \uceec\ub7fc \ud615\ud0dc\ub97c \uc778\uc2dd\ud569\ub2c8\ub2e4. \uadf8 \ud6c4 \uc0ac\uc6a9\uc790\uc5d0\uac8c \uc81c\ub300\ub85c \uc778\uc2dd\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\uc744 \ubc1b\uac8c \ub429\ub2c8\ub2e4. \uadf8 \ub54c enter\ub97c \ub20c\ub7ec\uc8fc\uc2dc\uba74 \ub429\ub2c8\ub2e4. \n- \ub610\ud55c \uc8fc\uc5b4\uc9c4 \ub370\uc774\ud130\uc758 \uc5bc\ub9c8\ub97c \uc0ac\uc6a9\ud558\uc5ec train \/ validation\uc744 \uad6c\ucd95\ud560\uc9c0 \ubb3b\uac8c \ub418\ub294\ub370, \uc804\uccb4 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uace0 \uc2f6\ub2e4\uba74 enter \ub20c\ub7ec\uc8fc\uc2dc\uba74 \ub429\ub2c8\ub2e4. \n----\n\n- In PyCaret you have to setup the environment before experimenting with the models. It can be done by using 'setup' method. \n- In setup stage, PyCaret automatically interprets column types of the given data and asks the user if it has intepreted it correctly. You can customize whether you want each columns to be interpreted differently by using the parameters in setup method. In this tutorial we will just go with the automatic interpretation by pressing 'enter'. \n- Also, it asks the ratio of dataset used to contruct train\/validation sets. We will use 100% of the dataset so just press 'enter' again. "}}