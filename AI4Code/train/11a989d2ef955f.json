{"cell_type":{"fdc41249":"code","c6b12441":"code","1637544e":"code","484553f5":"code","5bfaf610":"code","3352293c":"code","ff70c914":"code","18aa7c3a":"code","36627887":"code","e2c02693":"code","3a9ad98f":"code","0ac26b01":"code","3b20ad25":"code","55e74e6c":"code","ba952f2e":"code","d126f277":"code","e62fe483":"code","8f05f063":"code","c50cd635":"code","825c1842":"code","eab59dca":"code","f0159752":"code","24f50846":"code","4d9767df":"code","8a5882c3":"code","3df80a48":"code","7c667616":"code","18c47d50":"code","250d4f84":"code","adf3ae9c":"code","1739e8aa":"code","814bc597":"code","d181d3a3":"code","83492755":"code","74f23524":"code","6ec2b1c2":"code","d818e5c6":"code","71f5ddd7":"code","f65f9609":"code","1e821818":"code","b16dd4ba":"code","6814affe":"code","ccdaa42c":"code","7e2c6fef":"markdown","df046da4":"markdown","e4d8d116":"markdown","92872302":"markdown","21b884d0":"markdown","eab451ec":"markdown","790997a2":"markdown","4f19b960":"markdown","00a28d55":"markdown","bac1f2f3":"markdown","640c6c68":"markdown","03a07755":"markdown","db075081":"markdown","5257b464":"markdown","d9d340e5":"markdown","a23f9a6f":"markdown","72fb61b3":"markdown","3a3f395d":"markdown","284f409a":"markdown","518fe0f6":"markdown","49f10f0c":"markdown","642bf749":"markdown","2f3d5b7e":"markdown","50250865":"markdown","ed06d2b9":"markdown","2f38a517":"markdown","3b9eafa3":"markdown"},"source":{"fdc41249":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport cv2\nfrom glob import glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimage_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/CXR_png\")\nmask_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/masks\")\nreading_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/ClinicalReadings\")\n\n# Any results you write to the current directory are saved as output.","c6b12441":"images = os.listdir(image_path)\nmasks = os.listdir(mask_path)\nreadings = os.listdir(reading_path)\nprint('Total number of x-ray images:',len(images))\nprint('Total number of masks:',len(masks))\nprint('Total number of clinical readings:',len(readings))","1637544e":"tb_positive = [image for image in images if image.split('.png')[0][-1]=='1']\ntb_negative = [image for image in images if image.split('.png')[0][-1]=='0']\nprint('There are %d tuberculosis positive cases.' % len(tb_positive))\nprint('There are %d tuberculosis negative cases.' % len(tb_negative))","484553f5":"from IPython.display import Image\npos_image = np.random.choice(tb_positive,1)\nneg_image = np.random.choice(tb_negative,1)\nprint(\"Image %s is positive on tuberculosis.\" % pos_image[0])\ndisplay(Image(os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/CXR_png\",pos_image[0]),width=256,height=256))\nprint(\"Image %s is negative on tuberculosis.\" % neg_image[0])\ndisplay(Image(os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/CXR_png\",neg_image[0]),width=256,height=256))","5bfaf610":"tb_state = [int(image.split('.png')[0][-1]) for image in images]\nimg_df = pd.DataFrame({'Image_name':images, 'TB_state': tb_state})\nimg_df['Path'] = img_df['Image_name'].map(lambda x: \"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/CXR_png\/\"+x)\nimg_df['Source'] = img_df['Image_name'].map(lambda x: x.split('_')[0])\nimg_df['Text_path'] = img_df['Image_name'].map(lambda x: \"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/ClinicalReadings\/\"+x.split('.png')[0]+'.txt')\nimg_df.head()","3352293c":"ages=[]\ngenders=[]\ndescriptions=[]\nfor txt in img_df.Text_path.tolist():\n    lines = [line for line in open(txt,'r')]\n    if \"Patient's Sex:\" in lines[0]:\n        gender = lines[0][lines[0].index(\"Patient's Sex:\")+len(\"Patient's Sex:\")+1]\n        genders.append(gender)\n        start = lines[1].index(\"Patient's Age:\")\n        length = len(\"Patient's Age:\")\n        age = int(lines[1][start+length+2:start+length+4])\n        ages.append(age)\n        description = ' '.join(lines[2:]).strip()\n        descriptions.append(description)\n    else:\n        if \"male\" or \"MALE\" in lines[0]:\n            gender = 'M'\n            genders.append(gender)\n        else:\n            gender = 'F'\n            genders.append(gender)\n        if \"yrs\" in lines[0]:\n            start = lines[0].index(\"yrs\")\n            age = int(lines[0][start-2:start])\n            ages.append(age)\n        elif \"yr\" in lines[0]:\n            start = lines[0].index(\"yr\")\n            age = int(lines[0][start-2:start])\n            ages.append(age)\n        else:\n            ages.append(np.NaN)\n        description = ' '.join(lines[1:]).strip()\n        descriptions.append(description)\n            \nimg_df['Age'] = ages\nimg_df['Gender'] = genders\nimg_df['Description'] = descriptions\nimg_df.head()","ff70c914":"sns.countplot(x='TB_state', data=img_df)","18aa7c3a":"img_df.groupby(by='Source')['Image_name'].count()","36627887":"sns.countplot(x='Source', data=img_df)","e2c02693":"sns.countplot(x='Gender', hue='TB_state', data=img_df)","3a9ad98f":"print('TB positive rate of male patients:',sum((img_df.Gender=='M') & (img_df.TB_state==1)) \/ sum(img_df.Gender=='M'))","0ac26b01":"print('TB positive rate of female patients:',sum((img_df.Gender=='F') & (img_df.TB_state==1)) \/ sum(img_df.Gender=='F'))","3b20ad25":"img_df[img_df.Age.isnull()]","55e74e6c":"null_age_imgs = img_df[img_df.Age.isnull()].Text_path\nfor txt in null_age_imgs:\n    lines = [line for line in open(txt,'r')]\n    print(lines)","ba952f2e":"img_df.ix[446,'Age']=1\nimg_df.ix[469,'Age']=0\nimg_df.ix[535,'Age']=1\nimg_df.ix[660,'Age']=42\nimg_df[img_df.Age.isnull()]","d126f277":"sns.distplot(img_df[img_df.TB_state==1]['Age'], kde=False)","e62fe483":"from sklearn.model_selection import train_test_split\ntrain_val_ind, test_ind = train_test_split(range(800), test_size=0.15)\ntrain_ind, val_ind = train_test_split(train_val_ind, test_size=0.17647)\n\nprint('The length of train set:', len(train_ind))\nprint('The length of validation set:', len(val_ind))\nprint('The length of test set:', len(test_ind))","8f05f063":"# Create a new directory\nnew_dir = 'new_dir'\nos.mkdir(new_dir)\n\n# Create folders inside the new_dir\n\n# train\n    # Negative\n    # Positive\ntrain_dir = os.path.join(new_dir, 'train_dir')\nos.mkdir(train_dir)\nNegative = os.path.join(train_dir, 'Negative')\nos.mkdir(Negative)\nPositive = os.path.join(train_dir, 'Positive')\nos.mkdir(Positive)\n\n# val\n    # Negative\n    # Positive\nval_dir = os.path.join(new_dir, 'val_dir')\nos.mkdir(val_dir)\nNegative = os.path.join(val_dir, 'Negative')\nos.mkdir(Negative)\nPositive = os.path.join(val_dir, 'Positive')\nos.mkdir(Positive)\n    \n# test\n    # Negative\n    # Positive\ntest_dir = os.path.join(new_dir, 'test_dir')\nos.mkdir(test_dir)\nNegative = os.path.join(test_dir, 'Negative')\nos.mkdir(Negative)\nPositive = os.path.join(test_dir, 'Positive')\nos.mkdir(Positive)","c50cd635":"img_df.head(2)","825c1842":"['Negative','Positive'][img_df[img_df.Image_name=='CHNCXR_0151_0.png']['TB_state'].tolist()[0]]","eab59dca":"train_paths = img_df.ix[train_ind,'Path'].tolist()\nval_paths = img_df.ix[val_ind,'Path'].tolist()\ntest_paths = img_df.ix[test_ind,'Path'].tolist()\n\nfor path in train_paths:\n    label = ['Negative','Positive'][img_df[img_df.Path==path]['TB_state'].tolist()[0]]\n    image_name = img_df[img_df.Path==path]['Image_name'].tolist()[0]\n    source = os.path.join(path)\n    dest = os.path.join(train_dir, label, image_name)\n    \n    image = cv2.imread(source)\n    image = cv2.resize(image, (512, 512))\n    # save the image at the destination\n    cv2.imwrite(dest, image)\n    #shutil.copyfile(src, dst)\n\nfor path in val_paths:\n    label = ['Negative','Positive'][img_df[img_df.Path==path]['TB_state'].tolist()[0]]\n    image_name = img_df[img_df.Path==path]['Image_name'].tolist()[0]\n    source = os.path.join(path)\n    dest = os.path.join(val_dir, label, image_name)\n    \n    image = cv2.imread(source)\n    image = cv2.resize(image, (512, 512))\n    # save the image at the destination\n    cv2.imwrite(dest, image)\n    #shutil.copyfile(src, dst)\n\nfor path in test_paths:\n    label = ['Negative','Positive'][img_df[img_df.Path==path]['TB_state'].tolist()[0]]\n    image_name = img_df[img_df.Path==path]['Image_name'].tolist()[0]\n    source = os.path.join(path)\n    dest = os.path.join(test_dir, label, image_name)\n    \n    image = cv2.imread(source)\n    image = cv2.resize(image, (512, 512))\n    # save the image at the destination\n    cv2.imwrite(dest, image)\n    #shutil.copyfile(src, dst)","f0159752":"# check how many train images we have in each folder\nprint(len(os.listdir('new_dir\/train_dir\/Negative')))\nprint(len(os.listdir('new_dir\/train_dir\/Positive')))","24f50846":"# check how many val images we have in each folder\nprint(len(os.listdir('new_dir\/val_dir\/Negative')))\nprint(len(os.listdir('new_dir\/val_dir\/Positive')))","4d9767df":"# check how many test images we have in each folder\nprint(len(os.listdir('new_dir\/test_dir\/Negative')))\nprint(len(os.listdir('new_dir\/test_dir\/Positive')))","8a5882c3":"aaa = os.listdir('new_dir\/test_dir\/Positive')\ndisplay(Image(os.path.join(\"new_dir\/test_dir\/Positive\",aaa[0]),width=256,height=256))","3df80a48":"# check how many test images we have in each folder\nprint(len(os.listdir('new_dir\/test_dir\/Negative')))\nprint(len(os.listdir('new_dir\/test_dir\/Positive')))","7c667616":"from tensorflow.python.keras.applications import ResNet50, InceptionV3, InceptionResNetV2\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\n#num_classes = 2\n#resnet_weights_path = '..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n#inceptionv3_weights_path = '..\/input\/keras-pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\ninceptionresnetv2_weights_path = '..\/input\/keras-pretrained-models\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_model = Sequential()\n#my_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n#my_model.add(InceptionV3(include_top=False, pooling='avg', weights=inceptionv3_weights_path))\nmy_model.add(InceptionResNetV2(include_top=False, pooling='avg', weights=inceptionresnetv2_weights_path))\nmy_model.add(Dense(2, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_model.layers[0].trainable = False","18c47d50":"my_model.summary()","250d4f84":"my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","adf3ae9c":"#from tensorflow.python.keras.applications.resnet50 import preprocess_input\n#from tensorflow.python.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.python.keras.applications.inception_resnet_v2 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 256","1739e8aa":"train_batch_size = 40\nval_batch_size = 60\n\ndata_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   rotation_range=10,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   zoom_range=0.1)\n'''\ndata_generator_with_aug = ImageDataGenerator(\n                                   rotation_range=10,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   zoom_range=0.1)\n'''\ntrain_generator = data_generator_with_aug.flow_from_directory(\n        'new_dir\/train_dir',\n        target_size=(image_size, image_size),\n        batch_size=train_batch_size,\n        class_mode='categorical')\n\ndata_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n#data_generator_no_aug = ImageDataGenerator()\nvalidation_generator = data_generator_no_aug.flow_from_directory(\n        'new_dir\/val_dir',\n        target_size=(image_size, image_size),\n        batch_size=val_batch_size,\n        class_mode='categorical')","814bc597":"len(train_generator), len(validation_generator)","d181d3a3":"for i in range(len(train_generator)):\n    imgs, labels = next(train_generator)\n    \n# plots images with labels within jupyter notebook\n# source: https:\/\/github.com\/smileservices\/keras_utils\/blob\/master\/utils.py\n\ndef plots(ims, figsize=(20,10), rows=5, interp=False, titles=None): # 12,6\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n        \nplots(imgs, titles=None) # titles=labels will display the image labels","83492755":"import time\nstart = time.time()\n\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfilepath = \"inception_1stlayernottrained_256_40_60_100.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n'''\nearly = EarlyStopping(monitor=\"val_acc\", \n                      mode=\"min\", \n                      patience=5)\n'''\n                                                            \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = my_model.fit_generator(\n          train_generator,\n          steps_per_epoch=len(train_generator),\n          epochs=100,\n          validation_data=validation_generator,\n          validation_steps=len(validation_generator),\n          callbacks=callbacks_list)\n\nprint('Running time: %.4f seconds' % (time.time()-start))","74f23524":"test_generator = data_generator_no_aug.flow_from_directory(\n        'new_dir\/test_dir',\n        target_size=(image_size, image_size),\n        class_mode='categorical',\n        shuffle=False)","6ec2b1c2":"my_model.load_weights(filepath)\n\ntest_loss, test_acc = my_model.evaluate_generator(test_generator)\nprint('Test loss:', test_loss)\nprint('Test accuracy:', test_acc)","d818e5c6":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","71f5ddd7":"from sklearn.metrics import confusion_matrix\ntest_labels = test_generator.classes\npredictions = my_model.predict_generator(test_generator, verbose=1)\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))\nsns.heatmap(cm, annot=True, cbar=False)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix')","f65f9609":"from sklearn.metrics import classification_report\nprint(classification_report(test_labels, predictions.argmax(axis=1)))","1e821818":"np.mean(test_labels == (predictions[:,1]>0.4))","b16dd4ba":"cm = confusion_matrix(test_labels, predictions[:,1]>0.4)\nsns.heatmap(cm, annot=True, cbar=False)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix')","6814affe":"print(classification_report(test_labels, predictions[:,1]>0.4))","ccdaa42c":"import shutil\nshutil.rmtree('new_dir')","7e2c6fef":"Now we consolidate all patients' information into a dataframe.","df046da4":"### Delete the image data directory we created to prevent a Kaggle error.\n### Kaggle allows a max of 500 files to be saved.","e4d8d116":"## Part 1: Exploratory data analysis\n### Extract patients information","92872302":"Next, the missing age information is fixed.","21b884d0":"## Part 2: Tuberculosis status prediction","eab451ec":"Predict test set","790997a2":"There are 800 chest x-ray images and 704 masks.","4f19b960":"We have more male patients, and the TB positive rate is also higher for male patients (51.4%) compared with female (28.4%).","00a28d55":"We notice there are a few null values in Age column. ","bac1f2f3":"Below shows one TB positive image and one TB negative image. ","640c6c68":"Transfer the images into folders.","03a07755":"Split data into train, validation and test sets.","db075081":"Next, I will try ResNet50, InceptionV3 and InceptionResNetV2.","5257b464":"Data augmentation","d9d340e5":"Classification report","a23f9a6f":"## This notebook basically covers two parts based on the chest X-ray datasets:\n* ### Exploratory data analysis\n* ### Use transfer learning based on pretrained model to predict tuberculosis","72fb61b3":"Out of the 800 x-ray images, 394 are tuberculosis positive and 406 are negative.","3a3f395d":"Let's inspect these few records and we find that Age unit is missing.","284f409a":"By default, prediction is classified as positive when the probability of class \"Positive\" is larger than 0.5. But in medical diagnosis false negative cases should be avoided as much as possible. Therefore, the probability threshold is lowered to mitigate false negative. ","518fe0f6":"Compile model","49f10f0c":"Visualize a batch of augmented images","642bf749":"As mentioned earlier, the proportion of TB positive cases is around 50%, out of all the x-ray images.","2f3d5b7e":"Out of the 800 images, 662 are from Shenzhen and 138 are from Montgomery.","50250865":"Fit model","ed06d2b9":"Confustion matrix","2f38a517":"Recreate directories","3b9eafa3":"The age distribution of TB positive patients is shown in the below histogram. Age group from 20 to 40 contributes the highest proportion of TB positive patients."}}