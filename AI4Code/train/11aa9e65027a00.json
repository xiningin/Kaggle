{"cell_type":{"bdf56b10":"code","737dcb8a":"code","8a95643d":"code","05414302":"code","6691d627":"code","49ba7c31":"code","fb502509":"code","62642a6d":"markdown","e7f4d65b":"markdown","716f6843":"markdown"},"source":{"bdf56b10":"#Manipulate data\nimport pandas as pd\nimport numpy as np\n\n# make a prediction with a stacking ensemble\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import StackingRegressor\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import StackingClassifier","737dcb8a":"train1 = pd.read_csv('..\/input\/stemming\/train_praprocess_stem.csv')\ntest1 = pd.read_csv('..\/input\/stemming\/test_praprocess_stem.csv')","8a95643d":"#count_vectorizer = CountVectorizer()\ncount_vectorizer = CountVectorizer(ngram_range = (1,2), min_df = 1)\ntrain_vectors = count_vectorizer.fit_transform(train1['text'])\ntest_vectors = count_vectorizer.transform(test1[\"text\"])\n\n## Keeping only non-zero elements to preserve space \ntrain_vectors.shape","05414302":"tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df = 2, max_df = 0.5)\ntrain_tfidf = tfidf.fit_transform(train1['text'])\ntest_tfidf = tfidf.transform(test1[\"text\"])\n\ntrain_tfidf.shape","6691d627":"# # Create classifiers\n# rf = RandomForestClassifier()\n# et = ExtraTreesClassifier()\n# knn = KNeighborsClassifier()\n# svc = SVC()\n# rg = RidgeClassifier()\n# lg = LogisticRegression()\n# nb = MultinomialNB()\n# ada = AdaBoostClassifier()\n# grad = GradientBoostingClassifier()\n# xgb = XGBClassifier()\n# clf_array = [rf, et, knn, svc, rg, lg, nb, ada, grad, xgb]\n\n# define the base models\nlevel0 = list()\nlevel0.append(('svm', SVC()))\nlevel0.append(('ext', ExtraTreesClassifier()))\nlevel0.append(('ada', AdaBoostClassifier()))\nlevel0.append(('grad', GradientBoostingClassifier()))\nlevel0.append(('xgb', XGBClassifier()))\n# define meta learner model\ngrid = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\nlogreg = LogisticRegression()\nlevel1 = GridSearchCV(logreg,grid,cv=5)\n# define the stacking ensemble\nmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n# fit the model on all available data\nmodel.fit(train_vectors, train1['label'])\n# Cross Validation\nscores = model_selection.cross_val_score(model, train_vectors, train1[\"label\"], cv=5, scoring=\"f1\")\n# make a prediction for one example\nprint('Cross Validation: %.6f' % (scores.mean()))","49ba7c31":"test_read = pd.read_excel('..\/input\/dataset-bdc\/Data Uji BDC.xlsx')\ntemplate = pd.read_csv('..\/input\/dataset-bdc\/template jawaban BDC.csv')\ndf = template['ID']\nsample_submission = pd.DataFrame()\nsample_submission[\"ID\"] = test_read[\"ID\"]\nsample_submission[\"prediksi\"] = model.predict(test_vectors) \nsample_submission = pd.merge(df, sample_submission)\nsample_submission.to_csv(\"stacking_(92.83).csv\", index=False)","fb502509":"sample_submission.head()","62642a6d":"# Bag of Word","e7f4d65b":"# TF-IDF Vectorizer","716f6843":"# Stacking Logistic Regression"}}