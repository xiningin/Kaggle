{"cell_type":{"e718c151":"code","d0cde940":"code","1b4b320f":"code","d9ed12e3":"code","58177b53":"code","50c4955d":"code","cee0db8a":"code","69f778a5":"code","ec9945ed":"code","d4c137d3":"code","4f2b73b9":"code","e6ee4ab7":"code","90665545":"code","938ae73a":"code","1567b057":"code","ecbebed8":"code","004f9a0d":"code","c38c17e3":"code","fa6037c0":"code","ca16f32d":"code","1909d3cb":"code","490c19ab":"code","5d5cbf5c":"code","619e319a":"code","a9ee4307":"code","23005435":"code","feb16afd":"code","17ce1453":"code","a41138c8":"code","e90659d9":"code","cb2fc874":"code","51e6374a":"code","9656be6b":"code","c6ce90a2":"code","de8038cc":"code","770c4b07":"code","e1119704":"code","2d2ce9c6":"code","4ab1cb83":"code","5e682acb":"code","d92b5797":"code","c2f9a79d":"code","46f8f4c4":"code","a85c76d1":"code","e7fc5329":"code","3d737a92":"code","451af8d2":"code","9b30a48d":"markdown","40cd24a0":"markdown","9a68e074":"markdown"},"source":{"e718c151":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0cde940":"tweets_data_training = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\n\ntweets_data_test = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","1b4b320f":"tweets_data_training.head()","d9ed12e3":"tweets_data_training.shape","58177b53":"tweets_data_test.shape","50c4955d":"p= sns.countplot(data=tweets_data_training, x='target')","cee0db8a":"tweet_count_by_target = tweets_data_training['target'].value_counts()\ntweet_count_by_target","69f778a5":"sum_tweets = tweet_count_by_target.sum(axis=0)\nprint('{0:.1f}% of tweets in the dataset are about real disasters while the rest are not'.format((tweet_count_by_target[1]\/sum_tweets)*100))","ec9945ed":"sample_disaster_tweet = tweets_data_training[tweets_data_training['target']==1]['text'].sample(1, random_state=42).values\n\nsample_not_disaster_tweet = tweets_data_training[tweets_data_training['target']==0]['text'].sample(1, random_state=42).values\n\nsample_disaster_tweet","d4c137d3":"sample_not_disaster_tweet","4f2b73b9":"tweets_data_training.info()","e6ee4ab7":"tweets_data_training['location'].value_counts()","90665545":"tweets_data_training['keyword'].value_counts()","938ae73a":"tweets_data_copy = tweets_data_training.copy()\ntweets_data_copy.fillna({'keyword': 'None', 'location': 'None'}, inplace=True)\ntweets_data_copy.isnull().sum()","1567b057":"data_compared_by_location = tweets_data_copy[['target']]\ndata_compared_by_location['location_tagged_or_not'] = (tweets_data_copy['location']!='None')","ecbebed8":"p= sns.countplot(x='location_tagged_or_not', hue='target', data=data_compared_by_location)","004f9a0d":"import nltk\nimport sys\nimport spacy\n\nfrom nltk.corpus import stopwords\nimport string\n\nnlp = spacy.load(\"en_core_web_sm\", disable=['parser','ner'])\n\nstop = set(stopwords.words('english'))\n\n# set of all punctuations\npunc = set(string.punctuation)\n\ndef clean_text(text):\n\n    # Convert the text into lowercase\n    text = text.lower()\n\n    # Split into list\n    wordList = text.split()\n\n    # Remove punctuation\n    wordList = [\"\".join(x for x in word if x not in punc) for word in wordList]    \n\n    # Remove stopwords\n    wordList = [word for word in wordList if word not in stop]\n\n    reformed_sentence = \" \".join(wordList)\n    doc = nlp(reformed_sentence)\n    return \" \".join([token.lemma_ for token in doc])\n\nclean_text(\"I am sleeping\")","c38c17e3":"tweets_data_copy['clean_text'] = tweets_data_copy['text'].astype('str').apply(clean_text)","fa6037c0":"tweets_data_copy['clean_text'][0:5]","ca16f32d":"disaster_tweets = tweets_data_copy[tweets_data_copy['target']==1]['clean_text']\nnot_disaster_tweets = tweets_data_copy[tweets_data_copy['target']==0]['clean_text']","1909d3cb":"disaster_tweets[0:5].values","490c19ab":"not_disaster_tweets[0:5].values","5d5cbf5c":"from wordcloud import WordCloud, ImageColorGenerator\n\ndef word_freq_dict(text):\n    # Convert text into word list\n    wordList = text.split()\n    # Generate word freq dictionary\n    wordFreqDict = {word: wordList.count(word) for word in wordList}\n    return wordFreqDict\n\n# Function to plot Wordcloud\ndef word_cloud_from_frequency(word_freq_dict, title, figure_size=(10,6)):\n    wordcloud.generate_from_frequencies(word_freq_dict)\n    plt.figure(figsize=figure_size)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()","619e319a":"disaster_tweets_corpus = \" \".join(disaster_tweets.values)\nnot_disaster_tweets_corpus = \" \".join(not_disaster_tweets.values)","a9ee4307":"disaster_tweets_word_freq = word_freq_dict(disaster_tweets_corpus)\n\nwordcloud = WordCloud(width=5000,\n    height=3000,\n    max_words=200,\n    colormap='Reds',\n    background_color='white')\n\nword_cloud_from_frequency(disaster_tweets_word_freq, \"Most frequent Words in tweets about disasters\")","23005435":"not_disaster_tweets_word_freq = word_freq_dict(not_disaster_tweets_corpus)\n\nwordcloud = WordCloud(width=5000,\n    height=3000,\n    max_words=200,\n    colormap='Greens',\n    background_color='white')\n\nword_cloud_from_frequency(not_disaster_tweets_word_freq, \"Most frequent Words in tweets not about disasters\")","feb16afd":"plt.figure(figsize=(10, 6))\ntop_20_words_disaster_tweets = dict(sorted(disaster_tweets_word_freq.items(), reverse=True, key=lambda k:k[1] )[:20])\n\np = sns.barplot(y= list(top_20_words_disaster_tweets.keys()), x= list(top_20_words_disaster_tweets.values()), color='red')","17ce1453":"plt.figure(figsize=(10, 6))\ntop_20_words_not_disaster_tweets= dict(sorted(not_disaster_tweets_word_freq.items(), reverse=True, key=lambda k:k[1] )[:20])\n\np = sns.barplot(y= list(top_20_words_not_disaster_tweets.keys()), x= list(top_20_words_not_disaster_tweets.values()), color='green')","a41138c8":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer","e90659d9":"categorical_features = ['keyword', 'location']\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\ntext_to_vector_transformer = CountVectorizer()\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('cat', categorical_transformer, categorical_features),\n        ('text', text_to_vector_transformer, 'clean_text')\n    ])","cb2fc874":"clf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression())])","51e6374a":"X = tweets_data_copy[['keyword','location','clean_text']]\ny = tweets_data_copy['target']","9656be6b":"y_pred = cross_val_predict(clf, X, y, cv=3)","c6ce90a2":"from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score, confusion_matrix, roc_curve","de8038cc":"accuracy_score(y, y_pred)","770c4b07":"f1_score(y, y_pred)","e1119704":"precision_score(y, y_pred)","2d2ce9c6":"recall_score(y, y_pred)","4ab1cb83":"roc_auc_score(y, y_pred)","5e682acb":"conf_matrix = confusion_matrix(y, y_pred)\np= sns.heatmap(annot=True, cmap='YlOrBr', data=conf_matrix)","d92b5797":"fpr_clf, tpr_clf, thresholds_clf = roc_curve(y, y_pred)\nplt.figure(figsize=(10,6))\nplt.plot(fpr_clf, tpr_clf, linewidth=2, color='r')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')","c2f9a79d":"tweets_data_test.head()","46f8f4c4":"X_test = tweets_data_test[['keyword', 'location', 'text']].copy()\nX_test['clean_text'] = X_test['text'].astype('str').apply(clean_text)","a85c76d1":"X_test.drop(columns=['text'], inplace=True)\nX_test.head()","e7fc5329":"clf.fit(X, y)\noutput = clf.predict(X_test)","3d737a92":"output[:5]","451af8d2":"X_test['target'] = output\n#X_test.to_csv('submission.csv')","9b30a48d":"Can the location of a tweet tell us if a disaster actually took place?","40cd24a0":"Removal of stopwords and lemmatization","9a68e074":"## Preprocessing of text data"}}