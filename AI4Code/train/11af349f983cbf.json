{"cell_type":{"6ce900fa":"code","83705f2e":"code","c5c364c4":"code","57d18d55":"code","78462235":"code","56f5de7a":"code","2f03469b":"code","1fc7f5a1":"code","9850825d":"code","ba97d694":"code","64e80160":"code","41032f01":"code","ea8d8725":"code","eb6e6aa7":"code","ea09203c":"code","56ba3577":"code","8e7c75b7":"code","3a7e1230":"code","39473ca9":"code","62177534":"code","9bc43bb7":"code","652c30ee":"code","5f596e0e":"code","86d5838f":"code","03685061":"code","5629b591":"code","07b6374c":"code","0b687cec":"code","0b550d4a":"code","baaa6239":"code","9067febd":"markdown","0855bd64":"markdown","27967fb6":"markdown","36fd6b62":"markdown","b307d082":"markdown","2eab5eb9":"markdown","0249dce4":"markdown","28bb023c":"markdown","9c305c9d":"markdown","7c0e1caa":"markdown"},"source":{"6ce900fa":"RUNALL = False\nSKIP_SVM = False #SVM takes a HUUGE amount of time\nSKIP_TSNE = False\nSKIP_GRIDS = False\n\nimport numpy as np\nimport cv2\nimport time\nimport random\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport glob\nimport os\nimport sys\nfrom sklearn.decomposition import PCA\n#from sklearn.manifold import TSNE\n#MulticoreTSNE is faster because ... it uses multicore\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn.cluster import KMeans\n\nimport numpy\nfrom IPython.display import HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n","83705f2e":"PCA_n_components = 28\nRF_n_estimators = 20\nwidth = 34\nheight = 34\nmean = 0.068000\nvar = 0.048000\n\ndef load_images(width,height,mean,var):\n    start = time.time()\n    fruit_images = []\n    fruit_images_noisy = []\n    labels = []\n    labels_noisy = []\n    imgcount = 0\n    for fruit_dir_path in glob.glob(\"..\/input\/*\/fruits-360\/Training\/*\"):\n        fruit_label = fruit_dir_path.split(\"\/\")[-1]\n        for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n\n            image = cv2.resize(image, (width, height))\n            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n            fruit_images.append(image)\n            labels.append(fruit_label)\n\n            #get more training data to increase accuracy\n            row,col,ch = image.shape\n            sigma = var**0.5\n            gauss = np.array(image.shape)\n            gauss = np.random.normal(mean,sigma,(row,col,ch))\n            gauss = gauss.reshape(row,col,ch)\n            img2 = cv2.flip( image, 1 )\n            img2 = img2 + img2 * gauss\n            img2 = img2.astype('uint8')\n            fruit_images_noisy.append(img2)\n            labels_noisy.append(fruit_label)\n            imgcount += 1\n            #for fast testing noise, outcomment this\n            #if imgcount>100:\n            #    break\n        #for fast testing noise, outcomment this\n        #if imgcount>100:\n            #break\n        \n    fruit_images = np.array(fruit_images)\n    labels = np.array(labels)\n    end = time.time()\n    print(\"Loading %d images took %d s\" % (imgcount,end-start))\n    return (fruit_images,fruit_images_noisy,labels,labels_noisy)","c5c364c4":"RUNALL = True","57d18d55":"(fruit_images,fruit_images_noisy,labels,labels_noisy) = load_images(width,height,mean,var)\nlabel_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\nid_to_label_dict = {v: k for k, v in label_to_id_dict.items()}","78462235":"id_to_label_dict","56f5de7a":"label_ids = np.array([label_to_id_dict[x] for x in labels])\nlabel_ids_combined = [*label_ids,*label_ids]","2f03469b":"def plot_image_grid(images, nb_rows, nb_cols, figsize=(5, 5)):\n    assert len(images) == nb_rows*nb_cols, \"Number of images should be the same as (nb_rows*nb_cols)\"\n    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=figsize)\n    \n    n = 0\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            # axs[i, j].xaxis.set_ticklabels([])\n            # axs[i, j].yaxis.set_ticklabels([])\n            axs[i, j].axis('off')\n            axs[i, j].imshow(images[n])\n            n += 1        ","1fc7f5a1":"if not SKIP_GRIDS:\n    plot_image_grid(fruit_images[0:100], 10, 10)\n    plot_image_grid(fruit_images_noisy[0:100], 10, 10)","9850825d":"if not SKIP_GRIDS:\n    plot_image_grid(fruit_images[2000:2400], 20, 20, figsize=(10,10))\n    plot_image_grid(fruit_images_noisy[2000:2400], 20, 20, figsize=(10,10))","ba97d694":"scaler = StandardScaler()\nscaler_combined = StandardScaler()","64e80160":"start = time.time()\n\nimages_scaled = scaler.fit_transform([i.flatten() for i in fruit_images])\n\nimages_scaled_combined = scaler_combined.fit_transform([i.flatten() for i in [*fruit_images,*fruit_images_noisy]])\n\nend = time.time()\nprint(\"StandardScaler took %d s\" % (end-start))","41032f01":"start = time.time()\n\npca = PCA(n_components=PCA_n_components)\npca_result = pca.fit_transform(images_scaled)\n\npca_combined = PCA(n_components=PCA_n_components)\npca_result_combined = pca_combined.fit_transform(images_scaled_combined)\n\nend = time.time()\nprint(\"PCA took %d s\" % (end-start))","ea8d8725":"if not SKIP_TSNE:\n    start = time.time()\n    tsne = TSNE(n_jobs=4,n_components=2, perplexity=40.0)\n    tsne_result = tsne.fit_transform(pca_result)\n    tsne_result_scaled = StandardScaler().fit_transform(tsne_result)\n    end = time.time()\n    print(\"TSNE took %d s\" % (end-start))","eb6e6aa7":"def visualize_scatter(data_2d, label_ids, id_to_label_dict=None, figsize=(20,20)):\n    if not id_to_label_dict:\n        id_to_label_dict = {v:i for i,v in enumerate(np.unique(label_ids))}\n    \n    plt.figure(figsize=figsize)\n    plt.grid()\n    \n    nb_classes = len(np.unique(label_ids))\n    \n    cmap = plt.cm.get_cmap(\"jet\", nb_classes)\n    \n    for i, label_id in enumerate(np.unique(label_ids)):\n        plt.scatter(data_2d[np.where(label_ids == label_id), 0],\n                    data_2d[np.where(label_ids == label_id), 1],\n                    marker='o',\n                    c= cmap(i),\n                    linewidth='5',\n                    alpha=0.8,\n                    label=id_to_label_dict[label_id])\n    #plt.legend(loc='best')\n    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),\n          fancybox=True, shadow=True, ncol=1, fontsize=figsize[0])","ea09203c":"def visualize_scatter_with_images(data_2d, images, figsize=(45,45), image_zoom=1):\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.grid()\n    artists = []\n    for xy, i in zip(data_2d, images):\n        x0, y0 = xy\n        img = OffsetImage(i, zoom=image_zoom)\n        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n        artists.append(ax.add_artist(ab))\n    ax.update_datalim(data_2d)\n    ax.autoscale()\n    plt.show()","56ba3577":"if not SKIP_TSNE:\n    start = time.time()\n    visualize_scatter(tsne_result_scaled, label_ids, id_to_label_dict, figsize=(25, 25))\n    end = time.time()\n    print(\"visualize_scatter took %d s\" % (end-start))","8e7c75b7":"if not SKIP_TSNE:\n    start = time.time()\n    visualize_scatter_with_images(tsne_result_scaled, fruit_images, image_zoom=0.4, figsize=(25, 25))\n    end = time.time()\n    print(\"visualize_scatter_with_images took %d s\" % (end - start))","3a7e1230":"start = time.time()\n\nX_train, X_test, y_train, y_test = train_test_split(pca_result, label_ids,stratify = label_ids, test_size=0.25, random_state=42)\n\nX_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(pca_result_combined, label_ids_combined,stratify = label_ids_combined, test_size=0.25, random_state=42)\n\nend = time.time()\nprint(\"train_test_split took %d s\" % (end - start))","39473ca9":"start = time.time()\n\nforest = RandomForestClassifier(n_estimators=RF_n_estimators,n_jobs=4,random_state=42)\nforest = forest.fit(X_train, y_train)\n\nforest_combined = RandomForestClassifier(n_estimators=RF_n_estimators,n_jobs=4,random_state=42)\nforest_combined = forest_combined.fit(X_train_combined, y_train_combined)\n\nend = time.time()\nprint(\"RandomForestClassifier took %d s\" % (end - start))","62177534":"start = time.time()\n\ntest_predictions = forest.predict(X_test)\n\ntest_predictions_combined = forest_combined.predict(X_test_combined)\n\nend = time.time()\nprint(\"test_predictions took %d s\" % (end - start))","9bc43bb7":"start = time.time()\n\nprecision = accuracy_score(test_predictions, y_test) * 100\n\nprecision_combined = accuracy_score(test_predictions_combined, y_test_combined) * 100\n\nend = time.time()\nprint(\"RandomForest accuracy_score took %d s\" % (end - start))\nprint(\"Accuracy with RandomForest: {0:.6f}\".format(precision))\nprint(\"Accuracy with RandomForest and noisy images: {0:.6f}\".format(precision_combined))","652c30ee":"if not SKIP_SVM:\n    start = time.time()\n    svm_clf = svm.SVC(gamma='auto')\n    svm_clf = svm_clf.fit(X_train, y_train) \n    svm_clf_combined = svm.SVC(gamma='auto')\n    svm_clf_combined = svm_clf_combined.fit(X_train_combined, y_train_combined) \n    end = time.time()\n    print(\"SVM took %d s\" % (end - start))","5f596e0e":"if not SKIP_SVM:\n    start = time.time()\n    test_predictions = svm_clf.predict(X_test)\n    test_predictions_combined = svm_clf_combined.predict(X_test_combined)\n    end = time.time()\n    print(\"svm_clf.predict took %d s\" % (end - start))","86d5838f":"if not SKIP_SVM:\n    start = time.time()\n    precision = accuracy_score(test_predictions, y_test) * 100\n    precision_combined = accuracy_score(test_predictions_combined, y_test_combined) * 100\n    end = time.time()\n    print(\"SVM accuracy_score took %d s\" % (end - start))\n    print(\"Accuracy with SVM: {0:.6f}\".format(precision))\n    print(\"Accuracy with SVM and noisy images: {0:.6f}\".format(precision_combined))","03685061":"def load_validation_images(label_to_id_dict,width,height):\n    start = time.time()\n    validation_fruit_images = []\n    validation_image_paths = {}\n    validation_labels = [] \n    for fruit_dir_path in glob.glob(\"..\/input\/*\/fruits-360\/Test\/*\"):\n        fruit_label = fruit_dir_path.split(\"\/\")[-1]\n        for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n\n            image = cv2.resize(image, (width, height))\n            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n            validation_fruit_images.append(image)\n            validation_labels.append(fruit_label)\n            validation_image_paths[fruit_label] = image_path\n    validation_fruit_images = np.array(validation_fruit_images)\n    validation_labels = np.array(validation_labels)\n    validation_label_ids = np.array([label_to_id_dict[x] for x in validation_labels])\n    flattened_images = [i.flatten() for i in validation_fruit_images]\n    print(\"validation_flattened_images len: %d\" % len(flattened_images))\n    return (flattened_images,validation_label_ids,validation_image_paths)","5629b591":"(validation_images,validation_label_ids,validation_image_paths) = load_validation_images(label_to_id_dict,width,height)\n\nvalidation_images_scaled = scaler.transform(validation_images)\nvalidation_pca_result = pca.transform(validation_images_scaled)\n\nvalidation_images_scaled_combined = scaler_combined.transform(validation_images)\nvalidation_pca_combined_result = pca_combined.transform(validation_images_scaled_combined)\n\nend = time.time()\nprint(\"Validation preperation took %d s\" % (end - start))\n","07b6374c":"start = time.time()\ntest_predictions = forest.predict(validation_pca_result)\nprecision = accuracy_score(test_predictions, validation_label_ids) * 100\n\ntest_predictions_combined = forest_combined.predict(validation_pca_combined_result)\nprecision_combined = accuracy_score(test_predictions_combined, validation_label_ids) * 100\nprint(\"Validation Accuracy with Random Forest: {0:.6f}\".format(precision))\nprint(\"Validation Accuracy with Random Forest and noisy images: {0:.6f}\".format(precision_combined))\nend = time.time()\nprint(\"Random Forest prediction took %d s\" % (end - start))","0b687cec":"def get_thumbnail(path):\n    i = Image.open(path)\n    i.thumbnail((150, 150), Image.LANCZOS)\n    return i\n\ndef image_base64(im):\n    if isinstance(im, str):\n        im = get_thumbnail(im)\n    with BytesIO() as buffer:\n        im.save(buffer, 'jpeg')\n        return base64.b64encode(buffer.getvalue()).decode()\n\ndef image_formatter(path):\n    return f'<img src=\"data:image\/jpeg;base64,{image_base64(get_thumbnail(path))}\">'\n\ndata = []\nprocessed = []\nunique, counts = numpy.unique(y_train, return_counts=True)\nid_to_label_dict = {v: k for k, v in label_to_id_dict.items()}\nfor t in range(0,len(test_predictions)):\n    id = validation_label_ids[t]\n    if not id in processed:\n        test_predictions_sub =  []\n        test_predictions_sub_combined =  []\n        id_list = []\n        id_list_combined = []\n        for i in range(0,len(test_predictions)):\n            if validation_label_ids[i] == id:\n                test_predictions_sub.append(test_predictions[i])\n                id_list.append(id)\n        for i in range(0,len(test_predictions_combined)):\n            if validation_label_ids[i] == id:\n                test_predictions_sub_combined.append(test_predictions_combined[i])\n                id_list_combined.append(id)\n        accuracy = accuracy_score(test_predictions_sub,id_list)*100\n        accuracy_WNI = accuracy_score(test_predictions_sub_combined,id_list_combined)*100\n        data.append((id_to_label_dict[id],accuracy,accuracy_WNI,counts[id],validation_image_paths[id_to_label_dict[id]]))\n        processed.append(id)\nif not id in processed:\n    accuracy = accuracy_score(test_predictions_sub,id_list)*100\n    accuracy_WNI = accuracy_score(test_predictions_sub_combined,id_list_combined)*100\n    data.append((id_to_label_dict[id],accuracy,accuracy_WNI,counts[id],validation_image_paths[id_to_label_dict[id]]))\ndata.sort(key=lambda x:x[2])\ndata.reverse()\npd.set_option('display.max_colwidth', -1)\ndf=pd.DataFrame(data, columns=[\"Label\",\"Accuracy\",\"Accuracy WNI\",\"Count in y_train\", \"Image\"])\nHTML(df.to_html(escape=False ,formatters=dict(Image=image_formatter)))\n","0b550d4a":"if not SKIP_SVM:\n    start = time.time()\n    test_predictions = svm_clf.predict(validation_pca_result)\n    test_predictions_combined = svm_clf_combined.predict(validation_pca_combined_result)\n    precision = accuracy_score(test_predictions, validation_label_ids) * 100\n    precision_combined = accuracy_score(test_predictions_combined, validation_label_ids) * 100\n    end = time.time()\n    print(\"Validation Accuracy with SVM: {0:.6f}\".format(precision))\n    print(\"Validation Accuracy with SVM and noisy images: {0:.6f}\".format(precision_combined))\n    print(\"SVM prediction took %d s\" % (end - start))","baaa6239":"if not RUNALL:\n    scaler = StandardScaler()\n    validation_images = None\n    validation_images_scaled = None\n\n    #these were the default values\n    width = 45\n    height = 45\n    mean = 0.03\n    var = 0.03\n    PCA_n_components = 50\n    RF_n_estimators = 10\n    min_samples_leaf = 1\n    \n    totalstart = time.time()\n    data = []\n    for step in range(0,50):\n        print(\"########%d#######\" % step)\n        x = random.randint(10,48)\n        # i bet the optimal values can also be found by machine learning, but for now we just use random numbers and decide manually\n        PCA_n_components = random.randint(20,200)\n        RF_n_estimators = random.randint(5,20)\n        width = x\n        height = x\n        mean = random.randint(10,600) \/ 1000.0\n        var = random.randint(10,600) \/ 1000.0\n        min_samples_leaf = random.randint(1,10)\n\n        print(\"Params PCA_n_components: %d RF_n_estimators: %d width: %d height: %d mean: %f var: %f min_samples_leaf: %d\" %\n             (\n                 PCA_n_components,\n                 RF_n_estimators,\n                 width,\n                 height,\n                 mean,\n                 var,\n                 min_samples_leaf\n             )\n             )\n\n        start = time.time()\n        (fruit_images,fruit_images_noisy,labels,labels_noisy) = load_images(width,height,mean,var)\n        images_scaled = scaler.fit_transform([i.flatten() for i in fruit_images])\n        label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n        id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}\n        label_ids = np.array([label_to_id_dict[x] for x in labels])\n\n        print(\"running PCA\")\n        pca = PCA(n_components=PCA_n_components)\n        pca_result = pca.fit_transform(images_scaled)\n\n        print(\"loading Validationdata\")\n        (validation_images,validation_label_ids,validation_image_paths) = load_validation_images(label_to_id_dict,width,height)\n        validation_images_scaled = scaler.transform(validation_images)\n        validation_pca_result = pca.transform(validation_images_scaled)\n\n        X_train, X_test, y_train, y_test = train_test_split(pca_result, label_ids,stratify = label_ids, test_size=0.25, random_state=42)\n        forest = RandomForestClassifier(n_estimators=RF_n_estimators,min_samples_leaf=min_samples_leaf,n_jobs=4,random_state=42)\n        forest = forest.fit(X_train, y_train)\n        test_predictions = forest.predict(X_test)\n        accuracy1 = accuracy_score(test_predictions, y_test) * 100\n        print(\"accuracy against training data: %f\" % accuracy1)\n        test_predictions = forest.predict(validation_pca_result)\n        accuracy2 = accuracy_score(test_predictions, validation_label_ids) * 100\n        print(\"accuracy against validation data: %f\" % accuracy2)\n        elapsed_time = (time.time()-start)\n        print(\"elapsed_time %d s\" % elapsed_time)\n        data.append((\n            PCA_n_components,\n            RF_n_estimators,\n            width,\n            height,\n            mean,\n            var,\n            min_samples_leaf,\n            accuracy2,\n            elapsed_time\n        ))\n        if (time.time()-totalstart) > 40*60:\n            break\n    pd.DataFrame(data, columns=[\n        \"PCA_n_components\",\n        \"RF_n_estimators\",\n        \"width\",\n        \"height\",\n        \"mean\",\n        \"var\",\n        \"min_samples_leaf\",\n        \"Accuracy\",\n        \"Time\"])","9067febd":"## Work in Progress - find optimal training values","0855bd64":"## Train SVM","27967fb6":"## With SVM","36fd6b62":"![](http:\/\/)","b307d082":"### Accuracy by category","2eab5eb9":"## Visualize the data with PCA and t-SNE","0249dce4":"## Train Random Forest Classifier","28bb023c":"# Validate the models on the Validation Data","9c305c9d":"Just like a 2yo kid draws :P\n\nBtw. we can call it art and sell for a lot of...computational power","7c0e1caa":"## With Random Forest"}}