{"cell_type":{"61d4f19f":"code","acbacf1f":"code","416a92c7":"code","f549b1ec":"code","8d4f0a4e":"code","c56c14bb":"code","c4e5bc26":"code","3a03d910":"code","24f3acb2":"code","c7a2783a":"code","f0a371a8":"code","bb15a7ca":"code","7dbb08d5":"code","0b4e2837":"markdown","aa198f2c":"markdown","eed823fb":"markdown","c715384f":"markdown","66372310":"markdown","47740161":"markdown","b7bbfb29":"markdown","ead495fb":"markdown","dfdc0b6f":"markdown","aecd6e5f":"markdown","dbe5c98d":"markdown","3ac90b4d":"markdown","2749ba16":"markdown"},"source":{"61d4f19f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\") \nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","acbacf1f":"data = pd.read_csv(r\"\/kaggle\/input\/deepnlp\/Sheet_1.csv\",encoding= \"latin1\" )\ndata.drop([\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\n           \"Unnamed: 6\",\"Unnamed: 7\",], axis = 1, inplace =True)\ndata = pd.concat([data[\"class\"],data[\"response_text\"]], axis = 1)\n\ndata.dropna(axis=0, inplace =True)\ndata.head(10)","416a92c7":"data[\"class\"] = [1 if each == \"flagged\" else 0 for each in data[\"class\"]]\ndata.head()","f549b1ec":"data.response_text[16]","8d4f0a4e":"first_text = data.response_text[16]\ntext = re.sub(\"[^a-zA-Z]\",\" \",first_text)\ntext = text.lower() \nprint(text)","c56c14bb":"text = nltk.word_tokenize(text)\ntext = [ word for word in text if not word in set(stopwords.words(\"english\"))]\nprint(text)","c4e5bc26":"lemmatizer = WordNetLemmatizer()\ntext = [(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word, \"n\"),pos = \"v\"),pos=\"a\")) for word in text]\nprint(text)","3a03d910":"description_list = []\nfor description in data.response_text:\n       \n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower() \n    \n    description = nltk.word_tokenize(description)\n    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    \n    lemmatizer = WordNetLemmatizer()\n    description = (lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word, \"n\"),pos = \"v\"),pos=\"a\") for word in description)\n    \n    description = \" \".join(description)\n    description_list.append(description)","24f3acb2":"description_list[16]","c7a2783a":"max_features = 100\ncount_vectorizer = CountVectorizer(max_features=max_features)\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\nprint(\"Top {} Most Used Words: {}\".format(max_features,count_vectorizer.get_feature_names()))","f0a371a8":"y = data.iloc[:,0].values\nx = sparce_matrix","bb15a7ca":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)","7dbb08d5":"nb = GaussianNB()\nnb.fit(x_train,y_train)\ny_pred = nb.predict(x_test)\nprint(\"Accuracy: {}\".format(round(nb.score(y_pred.reshape(-1,1),y_test),2)))","0b4e2837":"## Libraries and Utilities","aa198f2c":"## 0 to Not Flagged and 1 to Flagged","eed823fb":"<p style=\"text-align:center;font-size:38px;color:#EC0F0F;\">Therapy Chatbot<\/p> \n\n![image.png](attachment:image.png)\n\n\nThe dataset contains 80 user responses, in the response_text column, to a therapy chatbot. Bot said: 'Describe a time when you have acted as a resource for someone else'.  User responded. If a response is 'not flagged', the user can continue talking to the bot. If it is 'flagged', the user is referred to help. We are going to predict if it is flagged or not according to users responses.","c715384f":"## Lemmatization","66372310":"## Loading Data","47740161":"### Fit the Model","b7bbfb29":"## All Words","ead495fb":"## Naive Bayes","dfdc0b6f":"- We can remove non-letter characters in our text with Regular Expression method.\n- The lower() methods returns the lowercased string from the given string. It converts all uppercase characters to lowercase. If no uppercase characters exist, it returns the original string.","aecd6e5f":"## Bag of Words","dbe5c98d":"## Regular Expression","3ac90b4d":"## Irrelevant Words (Stopwords)","2749ba16":"### Train Test Split"}}