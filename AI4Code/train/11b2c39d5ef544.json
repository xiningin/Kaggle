{"cell_type":{"b5d35dc3":"code","97be03a4":"code","fa76464e":"code","8a378433":"code","943ef2aa":"code","a2d1d581":"code","1d33d749":"code","8799c7ee":"code","bfa62add":"code","b33e74ca":"code","a504d31d":"code","1e361755":"code","4523d7a0":"code","820c35c7":"code","57cb4c55":"code","7d0d2ef4":"markdown","000c1a93":"markdown","12abe6ea":"markdown","291a4838":"markdown","1d7d8a73":"markdown","bfa19746":"markdown","bf94de9c":"markdown","cb99710f":"markdown","5937ba8b":"markdown"},"source":{"b5d35dc3":"!pip install pandas ml_extend","97be03a4":"import numpy as np\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori, association_rules","fa76464e":"data = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\ndata = data.head(30000) #using only half data due to memory issues\ndata.head()","8a378433":"data.shape","943ef2aa":"#Append Quantity column. Since, there's 1 product on every row we can easily use Quantity as 1 which will be added subsequently.\ndata.insert(7, 'quantity',1)\ndata.shape","a2d1d581":"data.head()","1d33d749":"#Total no. of unique orders and products\ndata.describe(include = 'all')","8799c7ee":"data['product_id'].value_counts()","bfa62add":"#If you want to cross check the data you can replace 10 with 80.\nitem_freq = data['product_id'].value_counts()\ndata = data[data.isin(item_freq.index[item_freq >= 10]).values]\ndata['product_id'].value_counts()","b33e74ca":"#Average products purchased per transaction\ndata['order_id'].value_counts().mean()","a504d31d":"#Create a basket of all products, orders and quantity\nbasket = (data.groupby(['order_id','product_id'])['quantity']).sum().unstack().reset_index().fillna(0).set_index('order_id')\nbasket.head()","1e361755":"#Convert 0.0 to 0, convert the units to One hot encoded values\ndef encode_units(x):\n    if x<= 0:\n        return 0\n    if x>=1:\n        return 1\n    \nbasket_sets = basket.applymap(encode_units)\nbasket_sets.head()","4523d7a0":"#Build frequent itemsets\nfrequent_itemsets = apriori(basket_sets, min_support = 0.0001, use_colnames = True)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\nfrequent_itemsets","820c35c7":"#Create Rules\nrules = association_rules(frequent_itemsets, metric = 'support', min_threshold = 0.0001)\nrules","57cb4c55":"#Products having 50% confidence likely to be purchased together\nrules[rules['confidence'] >= 0.50]","7d0d2ef4":"Recommender\/recommendation system is a subclass of information filtering system that seeks to predict the rating\/ preference a user would give to an item.\n\nThey are primarily used in applications where a person\/ entity is involved with a product\/ service. To further improve their experience with this product, we try to personalize it to their needs. For this we have to look up at their past interactions with this product.\n\nIn one line -> **Specialized content for everyone.**\n\nFor further info, [Wiki](https:\/\/en.wikipedia.org\/wiki\/Recommender_system)\n\n**Types of Recommender System**\n\n* 1). [Popularity Based](https:\/\/www.kaggle.com\/sasha18\/popularity-based-movie-recommendation)\n* 2). Classification Based\n* 3). [Content Based](https:\/\/www.kaggle.com\/sasha18\/recommend-books-using-count-tfidf-on-titles)\n* 4). [Collaborative Based](https:\/\/www.kaggle.com\/sasha18\/recommend-top-restaurants-based-on-preference)\n* 5). [Hybrid Based (Content + Collaborative)](https:\/\/www.kaggle.com\/sasha18\/recommend-top-restaurants-based-on-preference)\n* 6). [Association Based Rule Mining](https:\/\/www.kaggle.com\/sasha18\/perform-market-basket-analysis-with-e-comm-data)","000c1a93":"In real world scenarios, you will receive data in this format with every product within an order given in separate rows. We have to find the relation between 2 or more products frequently appearing together. We can't use this data the way it is, we got to further convert this into a format that is accepted by Apriori algorithm.\n\n# Data Preprocessing\n\n**Things to do:**\n* Total no. of unique orders and products\n* Whether to drop products that are purchased within a given threshold\n* Average no. of products purchased in a given order","12abe6ea":"With this we consider only the products that were purchased for a min. of 10 times.","291a4838":"# Summary & Model deployment\n\nWhile performing MBA on huge datasets you have to answer some questions,\n* What location is this data representative of\n* With E-commerce data it highly depends on the demography of the region as it directly relates to products sold\n* Different types of customers, i.e end user or retailer\n* It is not a one solution fits all so ensure the distribution of data is balanced\n\nYou may also face memory issues, such cases you can tweak product threshold values and support values based on domain knowledge in a way, such that important info isn't lost. Stakeholders would mostly be interested in Support, Confidence, sometimes Lift too. Suggest you to acquaint yourselves with leverage and conviction, they are the same info presented in a different perspective. \n\nFor me, presenting this report to stakeholders becomes a challenge, I googled a lot but couldn't  find a solution. I usually follow the below format to explain this report. I'll change this when I have a better one.\n\n![image.png](attachment:image.png)\n\nIf you want to find a better algorithm than Apriori then you should try this one and let us know. -> [SPMF](http:\/\/www.philippe-fournier-viger.com\/spmf\/)\n\n***Happy recommending !! :)***","1d7d8a73":"# Recommend similar products using Apriori\n\nFor a detailed explanation, please refer [KDnuggets](https:\/\/www.kdnuggets.com\/2019\/12\/market-basket-analysis.html)\n\n**Things to do:**\n* Create a basket of all products, orders and quantity\n* Perform One hot encoding so as to convert all quantities into format suitable for apriori algorithm\n* Build list of frequent itemsets\n* Generate rules based on your requirements","bfa19746":"# Market basket analysis using Apriori algorithm\n\nHere we attempt to group common patterns of items together using Association rules using Apriori algorithm.\n\nAssociation rules do not extract an individual's preference, rather find relationships between sets of elements of every distinct transaction.\n\nMetrics useful for MBA:\n\n* A).Support: % of times when Milk & Butter were purchased. \n    * (No.of transactions having Milk & Butter \/ Total No. of transactions) in %\n\n* B).Confidence: Whats the probability % of Butter in basket provided Milk in basket ?\n    * Confidence(Butter -> Milk) = (support(Milk U Butter)\/ support(Butter) remember this is not equal to Confidence(Milk, Butter) Ranges from 0 (No relation) to 1 (High relation) in %\n\n* C).Lift: How much will sale of Butter increase when you sell Milk or vice versa ?\n    * Lift{Milk, Butter} = Lift{Butter,Milk} = support(Milk U Butter)\/ support(Milk) * support(Butter) Ranges from 1 (No relationship) to 1> Negative relationship, 1< Positive relationship\n\n* D).Conviction: What is your conviction to purchase product 2 provided you have purchased product 1?\n    * High value, higher chances of purchasing product 2\n    * Conviction{Trousers -> Belt} = 2.614\n    * Conviction{Shirts -> Belt} = 0.86\n    \n# Import packages and dataset","bf94de9c":"If your dataset has a count of order numbers as huge as 1 million, then you can choose to drop some products that were purchased just once or below some threshold. Here I would take a threshold of 10. This would ensure not to overburden the system while giving you the best results. \n\n*No point in deriving relations out of products that were rarely purchased, right.*","cb99710f":"Order_item_id column is the counter that would count no. of items in an order. For Apriori we need Quantity column,that will calculate the quantity of a product purchased in a given order. We shall append this column towards the end.","5937ba8b":"## Frequent Itemsets"}}