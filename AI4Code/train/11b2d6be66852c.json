{"cell_type":{"519d07f5":"code","97acc355":"code","2bc038b1":"code","a3a1b070":"code","26fd5f31":"code","363d8450":"code","86674d9c":"code","5755531e":"code","7eede71d":"code","38e48bf4":"code","8f6d839b":"code","4f5d1280":"code","cec7ea65":"code","0900ce1a":"code","fad1a087":"code","284cb5bd":"code","8172691f":"code","955adea9":"code","f155d180":"code","08c4aac9":"code","63a26f26":"code","ce2bbde1":"code","d39ecdba":"code","5dd84b46":"code","ac600cb0":"code","1df14b17":"code","53fe4df7":"code","2a100a07":"code","f8b91354":"code","e19a88ab":"code","5aa71674":"code","db9036f2":"code","a3c7e7cc":"code","e8b11b3e":"code","66d9cdf8":"code","875019dd":"code","19c5934e":"code","08c6f02c":"code","30ac4ec6":"code","44cf91a7":"code","cf569716":"code","df933bc2":"code","15c6868c":"code","648b17f9":"code","a86598c7":"code","2ec348dc":"code","e4e148fc":"markdown","a0ea8328":"markdown","dc55faa4":"markdown","5b04297f":"markdown","32add1e1":"markdown","0bc8f21c":"markdown","678236d4":"markdown","9d90adc5":"markdown","5415cf83":"markdown","0ccfa463":"markdown","7c80f177":"markdown","e3d1ae23":"markdown","5b551411":"markdown","5b638785":"markdown","1da9633a":"markdown","a62e5020":"markdown","285685b1":"markdown","238a7b2d":"markdown","a5a8098d":"markdown","ab5f977e":"markdown","aafe6163":"markdown","54e17b84":"markdown","30c54b40":"markdown","1cb5e581":"markdown","2a192232":"markdown","642f0225":"markdown","10a06014":"markdown","e10b7bc9":"markdown","881bc177":"markdown","8a4716f8":"markdown","b432c326":"markdown"},"source":{"519d07f5":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os","97acc355":"from sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier","2bc038b1":"path_in = '..\/input\/cat-in-the-dat-ii\/'\nprint(os.listdir(path_in))","a3a1b070":"train_data = pd.read_csv(path_in+'train.csv', index_col=0)\ntest_data = pd.read_csv(path_in+'test.csv', index_col=0)\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv', index_col=0)","26fd5f31":"def plot_bar(data, name):\n    data_label = data[name].value_counts()\n    dict_train = dict(zip(data_label.keys(), ((data_label.sort_index())).tolist()))\n    names = list(dict_train.keys())\n    values = list(dict_train.values())\n    plt.bar(names, values)\n    plt.grid()\n    plt.show()","363d8450":"def plot_bar_compare(train, test, name, rot=False):\n    \"\"\" Compare the distribution between train and test data \"\"\"\n    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n    \n    train_label = train[name].value_counts().sort_index()\n    dict_train = dict(zip(train_label.keys(), ((100*(train_label)\/len(train.index)).tolist())))\n    train_names = list(dict_train.keys())\n    train_values = list(dict_train.values())\n    \n    test_label = test[name].value_counts().sort_index()\n    dict_test = dict(zip(test_label.keys(), ((100*(test_label)\/len(test.index)).tolist())))\n    test_names = list(dict_test.keys())\n    test_values = list(dict_test.values())\n    \n    axs[0].bar(train_names, train_values, color='yellowgreen')\n    axs[1].bar(test_names, test_values, color = 'sandybrown')\n    axs[0].grid()\n    axs[1].grid()\n    axs[0].set_title('Train data')\n    axs[1].set_title('Test data')\n    axs[0].set_ylabel('%')\n    if(rot==True):\n        axs[0].set_xticklabels(train_names, rotation=45)\n        axs[1].set_xticklabels(test_names, rotation=45)\n    plt.show()","86674d9c":"print('# samples train:', len(train_data))\nprint('# samples test:', len(test_data))","5755531e":"cols_with_missing_train_data = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_test_data = [col for col in test_data.columns if test_data[col].isnull().any()]\nprint('train cols with missing data:', cols_with_missing_train_data)\nprint('test cols with missing data:', cols_with_missing_test_data)","7eede71d":"imp_cat = SimpleImputer(strategy='most_frequent')\ntrain_data[cols_with_missing_train_data] = imp_cat.fit_transform(train_data[cols_with_missing_train_data])\ntest_data[cols_with_missing_test_data] = imp_cat.fit_transform(test_data[cols_with_missing_test_data])","38e48bf4":"train_data.columns","8f6d839b":"train_data.head()","4f5d1280":"plot_bar(train_data, 'target')","cec7ea65":"features_bin = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\nfeatures_cat = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\nfeatures_hex = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nfeatures_ord = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\nfeatures_cyc = ['day', 'month']","0900ce1a":"map_ord_1 = {'Novice':1, 'Contributor':2, 'Expert':3, 'Master':4, 'Grandmaster':5}\nmap_ord_2 = {'Freezing': 1, 'Cold':2, 'Warm':3, 'Hot':4, 'Boiling Hot': 5, 'Lava Hot':6}\nmap_ord_3 = dict(zip(train_data['ord_3'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['ord_3'].value_counts())+1)))\nmap_ord_4 = dict(zip(train_data['ord_4'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['ord_4'].value_counts())+1)))","fad1a087":"temp_ord_5 = pd.DataFrame(train_data['ord_5'].value_counts().sort_index().keys(), columns=['ord_5'])\ntemp_ord_5['First'] = temp_ord_5['ord_5'].astype(str).str[0].str.upper()\ntemp_ord_5['Second'] = temp_ord_5['ord_5'].astype(str).str[1].str.upper()\ntemp_ord_5['First'] = temp_ord_5['First'].replace(map_ord_4)\ntemp_ord_5['Second'] = temp_ord_5['Second'].replace(map_ord_4)\ntemp_ord_5['Add'] = temp_ord_5['First']+temp_ord_5['Second']\ntemp_ord_5['Mul'] = temp_ord_5['First']*temp_ord_5['Second']\nmap_ord_5 = dict(zip(temp_ord_5['ord_5'],\n                     temp_ord_5['Mul']))","284cb5bd":"plot_bar_compare(train_data, test_data, 'nom_0')","8172691f":"train_data['rgb'] = np.where(train_data['nom_0'] == 'Green', 0, 1)\ntest_data['rgb'] = np.where(test_data['nom_0'] == 'Green', 0, 1)","955adea9":"plot_bar_compare(train_data, test_data, 'nom_1', rot=True)","f155d180":"train_data['round'] = np.where(train_data['nom_1'] == 'Circle', 1, 0)\ntest_data['round'] = np.where(test_data['nom_1'] == 'Circle', 1, 0)","08c4aac9":"plot_bar_compare(train_data, test_data, 'nom_2', rot=True)","63a26f26":"train_data['feet'] = np.where(train_data['nom_2'] == 'Snake', 0, 1)\ntest_data['feet'] = np.where(test_data['nom_2'] == 'Snake', 0, 1)","ce2bbde1":"plot_bar_compare(train_data, test_data, 'nom_3', rot=True)","d39ecdba":"train_data['monarchy'] = np.where(train_data['nom_3'] == 'Canada', 1, 0)\ntest_data['monarchy'] = np.where(test_data['nom_3'] == 'Canada', 1, 0)","5dd84b46":"plot_bar_compare(train_data, test_data, 'nom_4', rot=True)","ac600cb0":"train_data['electro'] = np.where(train_data['nom_4'] == 'Theremin', 1, 0)\ntest_data['electro'] = np.where(test_data['nom_4'] == 'Theremin', 1, 0)","1df14b17":"y_train = train_data['target']\ndel train_data['target']","53fe4df7":"X_train = train_data.copy()\nX_test = test_data.copy()","2a100a07":"le = LabelEncoder()\nfor col in features_bin:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","f8b91354":"le = LabelEncoder()\nfor col in features_cat:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","e19a88ab":"le = LabelEncoder()\nfor col in features_hex:\n    le.fit(X_train[col].append(X_test[col]))\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","5aa71674":"X_train['ord_1'] = X_train['ord_1'].replace(map_ord_1)\nX_train['ord_2'] = X_train['ord_2'].replace(map_ord_2)\nX_train['ord_3'] = X_train['ord_3'].replace(map_ord_3)\nX_train['ord_4'] = X_train['ord_4'].replace(map_ord_4)\nX_train['ord_5'] = X_train['ord_5'].replace(map_ord_5)\nX_test['ord_1'] = X_test['ord_1'].replace(map_ord_1)\nX_test['ord_2'] = X_test['ord_2'].replace(map_ord_2)\nX_test['ord_3'] = X_test['ord_3'].replace(map_ord_3)\nX_test['ord_4'] = X_test['ord_4'].replace(map_ord_4)\nX_test['ord_5'] = X_test['ord_5'].replace(map_ord_5)","db9036f2":"for feature in features_cyc:\n    X_train[feature+'_sin'] = np.sin((2*np.pi*X_train[feature])\/max(X_train[feature]))\n    X_train[feature+'_cos'] = np.cos((2*np.pi*X_train[feature])\/max(X_train[feature]))\n    X_test[feature+'_sin'] = np.sin((2*np.pi*X_test[feature])\/max(X_test[feature]))\n    X_test[feature+'_cos'] = np.cos((2*np.pi*X_test[feature])\/max(X_test[feature]))\nX_train = X_train.drop(features_cyc, axis=1)\nX_test = X_test.drop(features_cyc, axis=1)","a3c7e7cc":"mean = X_train[features_hex].mean(axis=0)\nX_train[features_hex] = X_train[features_hex].astype('float32')\nX_train[features_hex] -= X_train[features_hex].mean(axis=0)\nstd = X_train[features_hex].std(axis=0)\nX_train[features_hex] \/= X_train[features_hex].std(axis=0)\nX_test[features_hex] = X_test[features_hex].astype('float32')\nX_test[features_hex] -= mean\nX_test[features_hex] \/= std","e8b11b3e":"mean = X_train[features_ord].mean(axis=0)\nX_train[features_ord] = X_train[features_ord].astype('float32')\nX_train[features_ord] -= X_train[features_ord].mean(axis=0)\nstd = X_train[features_ord].std(axis=0)\nX_train[features_ord] \/= X_train[features_ord].std(axis=0)\nX_test[features_ord] = X_test[features_ord].astype('float32')\nX_test[features_ord] -= mean\nX_test[features_ord] \/= std","66d9cdf8":"mean = X_train[features_cat].mean(axis=0)\nX_train[features_cat] = X_train[features_cat].astype('float32')\nX_train[features_cat] -= X_train[features_cat].mean(axis=0)\nstd = X_train[features_cat].std(axis=0)\nX_train[features_cat] \/= X_train[features_cat].std(axis=0)\nX_test[features_cat] = X_test[features_cat].astype('float32')\nX_test[features_cat] -= mean\nX_test[features_cat] \/= std","875019dd":"X_train.columns","19c5934e":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2020)","08c6f02c":"weight = float(len(y_train[y_train == 0]))\/float(len(y_train[y_train == 1]))\nw1 = np.array([1]*y_train.shape[0])\nw1[y_train==1]=weight","30ac4ec6":"X_train[features_cat].head()","44cf91a7":"model = XGBClassifier(objective ='binary:logistic',\n                      colsample_bytree = 0,\n                      learning_rate = 0.2,\n                      max_depth = 15,\n                      n_estimators = 400,\n                      scale_pos_weight = 2,\n                      random_state = 2020,\n                      subsample = 0.8)","cf569716":"model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, sample_weight=w1)","df933bc2":"preds_val = model.predict_proba(X_val)[:,1]","15c6868c":"score = metrics.roc_auc_score(y_val ,preds_val)\nprint(\"score: %f\" % (score))","648b17f9":"# metrics.plot_confusion_matrix(model,\n#                               X_val, y_val,\n#                               cmap=plt.cm.Blues,\n#                               normalize=None,\n#                               values_format='d')","a86598c7":"y_test = model.predict_proba(X_test)[:,1]","2ec348dc":"num = samp_subm.index\noutput = pd.DataFrame({'id': num,\n                       'target': y_test})\noutput.to_csv('submission.csv', index=False)","e4e148fc":"## Feature nom_2 - animals\nThe snake has no feet.","a0ea8328":"# Show target\nWe have a look on the distribution of the target values.","dc55faa4":"# Handle missing data\nFirst we handle missing data by a simple imputer with the most-frequent strategy.","5b04297f":"## Feature nom_4 - musical instruments\nThe Theremin is a electronical instrument.","32add1e1":"# Welcome to the great Categorical Feature Encoding Challenge #2\nThis notebook is a starter code for all beginners and easy to understand. I used the following notebook to improve knowledge about encoding:\nhttps:\/\/www.kaggle.com\/shahules\/an-overview-of-encoding-techniques\n\nAdditionally there are created new features based on the relationsship between the nominal features. <br>\nIt is used the XGB Classifier with a simple setting and great results.","0bc8f21c":"## Predict test data","678236d4":"## Evalaute the model with the val data","9d90adc5":"## Categorical features\nUse the simple LabelEncoder.","5415cf83":"# Define XGBClassifier and Predict\nDetermine the parameters of the XGB Classifier with a simple grid search.\n## Set model and fit","0ccfa463":"# Read input data","7c80f177":"## Feature nom_3 - countries\nCanda is a monarchy.","e3d1ae23":"# Confusion Matrix\nExample of confusion matrix usage to evaluate the quality of the output of a classifier data set. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.","5b551411":"# Classify the features","5b638785":"# Encode the features","1da9633a":"# Split train and val data","a62e5020":"## Hexadecimal features\nUse the simple LabelEncoder.","285685b1":"## Feature nom_1 the geometric shape\nOnly the circle has no corners.","238a7b2d":"# Plot the nominal features and think about a relationsship\n## Feature nom_0 - the color\nBlue and Red are colors of the RGB color space, Green not.","a5a8098d":"# Plot bar function","ab5f977e":"# Load Libraries","aafe6163":"## Binary features\nUse the simple LabelEncoder.","54e17b84":"# Calc the class wights of the target","30c54b40":"# Show features","1cb5e581":"# Scale data","2a192232":"# Input path","642f0225":"# Write the Export","10a06014":"# Overview\nWe have a look on the number of samples and check missing data. ","e10b7bc9":"## Cyclic features","881bc177":"# Define the scaler mappings for the ordinal features\nFor ord_0 is nothing to do.","8a4716f8":"# Define y_train","b432c326":"## Ordinal features\nUse the mapping for ord_1 to ord_5."}}