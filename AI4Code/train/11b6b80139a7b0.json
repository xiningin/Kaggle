{"cell_type":{"03b2cb73":"code","dcb596eb":"code","3def889a":"code","ca6105c0":"code","5f622fac":"code","1eb21eb4":"code","5830e7b2":"code","312ea4ba":"code","287d24fe":"code","e9efe7d8":"code","8d2c3e86":"code","cd4c0b87":"code","a798b5a8":"code","b3644468":"code","0d063b5a":"code","009da289":"code","06387ac9":"code","f6fcae9b":"code","5996aae6":"code","97d1dafb":"code","9277fd73":"code","b02b4d0c":"code","87b54faa":"code","0fe3bb90":"code","cdd0e296":"code","52f57751":"code","ab37a94d":"code","0e14039f":"code","5cbae987":"code","7f453365":"code","66bdf675":"code","96156a6e":"code","3ecb9b01":"code","bd587387":"code","3202a894":"code","19ea0501":"code","2f497ba3":"code","3ea0fd36":"code","f44b9cff":"code","fb80a4e4":"code","8029c4bc":"code","7feb28b8":"code","d43191a6":"code","6b718d33":"code","f362b099":"code","450ed668":"code","5a10157d":"code","46938de2":"code","5cc04f85":"code","d662c5a7":"code","488bc112":"code","8a784b73":"code","79dad03d":"code","b044eb37":"code","da54a00a":"code","eca1f00b":"code","91afd6fd":"code","8176714b":"code","7a0123ef":"code","a4955c24":"code","5b04f111":"code","410aaefb":"code","8182a957":"markdown"},"source":{"03b2cb73":"#importing libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom datetime import date,datetime,timedelta\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","dcb596eb":"#reading the train data and test data\ndata=pd.read_csv('..\/input\/Train.csv')\ntest=pd.read_csv('..\/input\/Test.csv')","3def889a":"data.head()","ca6105c0":"#checking shape of the data\ndata.shape","5f622fac":"#checking NA's  values \ndata.isna().sum()","1eb21eb4":"#checking statistics for every column\ndata.describe(include='all')\n","5830e7b2":"#checking data types \ndata.dtypes","312ea4ba":"#droping the unwanted columns\ndata.drop('CustomerID',axis=1,inplace=True)\ndata.drop('CustomerName',axis=1,inplace=True)","287d24fe":"#creating a new Dateof birth column from yearofbirth,monthofbirth,dayoofbirth\ndata['Dateofbirth'] = pd.to_datetime(\ndata[['yearofBirth', 'monthofBirth', 'dayofBirth']].astype(str).agg('-'.join, axis=1))\n\n#creating a year column from dateofbirth\ndata['year']=data['Dateofbirth'].dt.year\n\n#adding a new column AGE from present year and year of birth\ndata['age']=2019-data['year']\n","e9efe7d8":"sns.countplot(data.Churn)\nplt.title(\"distribution of Levels in churn \")","8d2c3e86":"sns.countplot(data.Occupation)\nplt.xticks(rotation=45)\nplt.title('No of categories in occupation')","cd4c0b87":"#histogram for account balance\nplt.hist(data.AccountBalance,bins=10)\nplt.xlabel(\"account balance\")\nplt.ylabel(\"frequency\")\nplt.title(\"distribution for account balance\")\n","a798b5a8":"sns.boxplot(x='Churn',y='CreditScore',data=data)\nplt.title(\"churn vs CreditScore\")","b3644468":"sns.countplot(x='Churn',hue='Occupation',data=data)\nplt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0.5)","0d063b5a":"sns.boxplot(x='Churn',y='Salary',data=data)\nplt.title(\"churn vs Salary\")","009da289":"#churn vs age,here we can observe that the churn rate is more between 40-50 age \nsns.boxplot(x=data.Churn,y=data.age)\nplt.title(\"churn vs age\")","06387ac9":"sns.countplot(x='Churn',hue='Gender',data=data)\nplt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0.5)","f6fcae9b":"#droping year column\ndata.drop('year',axis=1,inplace=True)","5996aae6":"#creating lists of categorical and numerical columns\ncat_cols=['Gender','Location','Education','MaritalStatus','Occupation','Ownhouse']\nnum_cols=['yearofBirth','monthofBirth','dayofBirth','yearofEntry','monthofEntry','dayofEntry','CreditScore','AccountBalance','NumberOfProducts','IsCreditCardCustomer','ActiveMember','Salary']\n","97d1dafb":"#separating the independent and dependent column\ny=data.Churn\nX=data\nX.drop('Churn',axis=1,inplace=True)","9277fd73":"#spliting the train data into train_X,train_y,valid_X,valid_y\ntrain_X,valid_X,train_y,valid_y=train_test_split(X,y,train_size=0.7,random_state=1)\n\n#printing the shape of train_X,train_y,validation_X,validation_y\nprint(train_X.shape)\nprint(valid_X.shape)\nprint(train_y.shape)\nprint(valid_y.shape)","b02b4d0c":"#deleting the Dateofbirth column since we added new column called 'AGE'\ntrain_X.drop('Dateofbirth',axis=1,inplace=True)\n\n#CONVERTING THE DATATYPES TO FLOAT AND CATEGORIC\ntrain_X[cat_cols]=train_X[cat_cols].apply(lambda x:x.astype(\"category\"))\ntrain_X[num_cols]=train_X[num_cols].apply(lambda x:x.astype(\"float\"))","87b54faa":"train_num_data=train_X.loc[:,num_cols]\ntrain_cat_data=train_X.loc[:,cat_cols]","0fe3bb90":"from sklearn.preprocessing import StandardScaler\nstand=StandardScaler()\nstand.fit(train_num_data[train_num_data.columns])\ntrain_num_data[train_num_data.columns]=stand.transform(train_num_data[train_num_data.columns])","cdd0e296":"train_X=pd.concat([train_num_data,train_cat_data],axis=1)\n\n#creating dummies \ntrain_X=pd.get_dummies(train_X,columns=cat_cols)","52f57751":"#PREPROCESSING ON VALIDATION DATA\n#droping dateofbirth column since we calculated age column\nvalid_X.drop('Dateofbirth',axis=1,inplace=True)\n\n#CONVERTING THE DATATYPES TO FLOAT AND CATEGORIC\nvalid_X[cat_cols]=valid_X[cat_cols].apply(lambda x:x.astype(\"category\"))\nvalid_X[num_cols]=valid_X[num_cols].apply(lambda x:x.astype(\"float\"))\n\nvalid_num_data=valid_X.loc[:,num_cols]\nvalid_cat_data=valid_X.loc[:,cat_cols]\n\nvalid_num_data[valid_num_data.columns]=stand.transform(valid_num_data[valid_num_data.columns])\n\nvalid_X=pd.concat([valid_num_data,valid_cat_data],axis=1)\n\n#creating dummies \nvalid_X=pd.get_dummies(valid_X,columns=cat_cols)","ab37a94d":"#checking the shape of train_X,validation_X\nprint(valid_X.shape)\nprint(train_X.shape)","0e14039f":"test.head()","5cbae987":"#keeping the CustomerID in custid variable for submission along with test predictions\ncustid=test.CustomerID\n","7f453365":"#preprocessing on test droping unwanted columns\ntest.drop('CustomerID',axis=1,inplace=True)\ntest.drop('CustomerName',axis=1,inplace=True)\n\n#creating a new dateofbirth column from year of birth,month of birth,day of birth\ntest['Dateofbirth'] = pd.to_datetime(\ntest[['yearofBirth', 'monthofBirth', 'dayofBirth']].astype(str).agg('-'.join, axis=1))\n\n#creating year column from dateofbirth for calculating age \ntest['year']=test['Dateofbirth'].dt.year\n\n#creating new \"age\" column subrating from present year and yearofbirth\ntest['age']=2019-test['year']\n\n#and droping year column\ntest.drop('year',axis=1,inplace=True)\n\n#droping dateofbirth column from test\ntest.drop('Dateofbirth',axis=1,inplace=True)","66bdf675":"#CONVERTING THE DATATYPES TO FLOAT AND CATEGORIC\ntest[cat_cols]=test[cat_cols].apply(lambda x:x.astype(\"category\"))\ntest[num_cols]=test[num_cols].apply(lambda x:x.astype(\"float\"))\n\ntest_num_data=test.loc[:,num_cols]\ntest_cat_data=test.loc[:,cat_cols]\n\ntest_num_data[test_num_data.columns]=stand.transform(test_num_data[test_num_data.columns])\n\ntest=pd.concat([test_num_data,test_cat_data],axis=1)\n\n#creating dummies \ntest=pd.get_dummies(test,columns=cat_cols)","96156a6e":"#checking shape for train_X,valdiation_X,test data\nprint(train_X.shape)\nprint(valid_X.shape)\nprint(test.shape)","3ecb9b01":"#MODEL1 LOGISTIC MODEL\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,accuracy_score\n\n#fitting the model on train_X,TRAIN_Y\nlog=LogisticRegression()\nlog.fit(train_X,train_y)\n","bd587387":"#prediction on train_x,validation_x using logistic model and storing it in variables \ntrain_preds1=log.predict(train_X)\nvalid_preds1=log.predict(valid_X)","3202a894":"#checking model performance using accuaracy and recall\nprint(\"accuracy on train data:\",classification_report(train_y,train_preds1))\nprint(\"accuracy on validation data:\",classification_report(valid_y,valid_preds1))\ntrain_score1=accuracy_score(train_y,train_preds1)\nvalid_score1=accuracy_score(valid_y,valid_preds1)","19ea0501":"#creating a function which will plot learning curves for our model\n#which will help us get bias and variance\nfrom sklearn.model_selection import learning_curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10)):\n    \n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)#if y limits are given consider the specified limits\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    #getting means and std for train and test for particular train_sizes\n    #with specified cv.\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    #creating connections between the training score points since we only get points.\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    #similarly for cross validation\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","2f497ba3":"plot_learning_curve(log,'logistic regression learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","3ea0fd36":"#MODEL2 DECISION TREE CLASSIFIER AND FITTING ON TRAIN AND VALIDATION\nfrom sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier()\ndtc.fit(train_X,train_y)\n\n#predicting on train_X,valdiation_x and storing in variables\ntrain_preds2=dtc.predict(train_X)\nvalid_preds2=dtc.predict(valid_X)","f44b9cff":"#checking accuracy and recall on train and validation\nprint(\"accuracy on train data:\",classification_report(train_y,train_preds2))\nprint(\"accuracy on validation data:\",classification_report(valid_y,valid_preds2))\ntrain_score2=accuracy_score(train_y,train_preds2)\nvalid_score2=accuracy_score(valid_y,valid_preds2)","fb80a4e4":"plot_learning_curve(dtc,'Decision tree learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","8029c4bc":"#MODEL3 KNN CLASIFIER\nfrom sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\nknn.fit(train_X,train_y)\n\n#predicting on train and validation\ntrain_preds3=knn.predict(train_X)\nvalid_preds3=knn.predict(valid_X)\n\n#checking accuarcy score on train and validation\nprint(\"accuracy_score on train data:\",accuracy_score(train_y,train_preds3))\nprint(\"accuracy_score on validaion data:\",accuracy_score(valid_y,valid_preds3))\n\ntrain_score3=accuracy_score(train_y,train_preds3)\nvalid_score3=accuracy_score(valid_y,valid_preds3)","7feb28b8":"plot_learning_curve(knn,'KNN learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","d43191a6":"#MODEL 4\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nsvc=SVC()\n\n \nparam_grid = {\n\n'C': [0.001, 0.01, 0.1, 1, 10],\n'gamma': [0.001, 0.01, 0.1, 1], \n'kernel':['linear','rbf']}\n\n \nsvc_cv = GridSearchCV(estimator = svc, param_grid = param_grid, cv = 10,n_jobs=-1)","6b718d33":"svc_cv.fit(train_X,train_y)","f362b099":"svc_cv.best_estimator_.fit(train_X,train_y)","450ed668":"#predicting on train and validation\ntrain_preds4=svc_cv.best_estimator_.predict(train_X)\nvalid_preds4=svc_cv.best_estimator_.predict(valid_X)","5a10157d":"#checking accuarcy score on train and validation\nprint(\"accuracy_score on train data:\",accuracy_score(train_y,train_preds4))\nprint(\"accuracy_score on validaion data:\",accuracy_score(valid_y,valid_preds4))\n\ntrain_score4=accuracy_score(train_y,train_preds4)\nvalid_score4=accuracy_score(valid_y,valid_preds4)","46938de2":"plot_learning_curve(svc_cv.best_estimator_,'SVC learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","5cc04f85":"#MODEL 5\nfrom sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\n\nmax_depth=[4,6,8,10]\nmin_samples_leaf=[0.06,0.08,0.10]\nmax_features=[0.02,0.04,0.06,0.08]\n\nparams={\n    \"max_depth\":max_depth,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"max_features\": max_features,\n}\n\ngrid=GridSearchCV(estimator=rfc,param_grid=params,cv=5,n_jobs=-1)\ngrid.fit(train_X,train_y)","d662c5a7":"grid.best_estimator_","488bc112":"#getting best estimator from grid search and fitting on train_x,train_y\ngrid.best_estimator_.fit(train_X,train_y)\n\n#prediction on train and validation \ntrain_preds5=grid.predict(train_X)\nvalid_preds5=grid.predict(valid_X)\n","8a784b73":"#checking the model performance using accuracy score on train and validation\nprint(\"accuracy_score on train data:\",accuracy_score(train_y,train_preds5))\nprint(\"accuracy_score on validaion data:\",accuracy_score(valid_y,valid_preds5))\n\ntrain_score5=accuracy_score(train_y,train_preds5)\nvalid_score5=accuracy_score(valid_y,valid_preds5)","79dad03d":"plot_learning_curve(grid.best_estimator_,'RandomForest learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","b044eb37":"#MODEL 6\n#importing Randomsearchcv and creating hyperparameters for XGboost \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\nxgb2=XGBClassifier()\nn_estimaters=[50,100,150,200]\nmax_depth=[2,3,5,7]\nlearnin_rate=[0.05,0.1,0.15,0.20]\nmin_child_wgt=[1,2,3,4]\n\n\n\nhyperparameter={\n    \"n_estimaters\":n_estimaters,\n    \"max_depth\":max_depth,\n    \"learnin_rate\":learnin_rate,\n    \"min_child_wgt\":min_child_wgt,\n\n}\n\n# using RandomizedSearchCV for 5 fold cross validation XGboost as estimator\nrandom_cv2=RandomizedSearchCV(estimator=xgb2,param_distributions=hyperparameter,cv=5,n_jobs=-1)\n\n#fitting on trainx,trainy\nrandom_cv2.fit(train_X,train_y)","da54a00a":"random_cv2.best_estimator_.fit(train_X,train_y)\n\n#and predicting on trainx and validationx using best estimator\ntrain_preds6=random_cv2.best_estimator_.predict(train_X)\nvalid_preds6=random_cv2.best_estimator_.predict(valid_X)","eca1f00b":"#checking the model performance using accuracy score on train and validation\nprint(\"accuracy_score on train data:\",accuracy_score(train_y,train_preds6))\nprint(\"accuracy_score on validaion data:\",accuracy_score(valid_y,valid_preds6))\n\ntrain_score6=accuracy_score(train_y,train_preds6)\nvalid_score6=accuracy_score(valid_y,valid_preds6)","91afd6fd":"plot_learning_curve(random_cv2.best_estimator_,'XGboost learning curve',train_X,train_y,ylim=None, cv=5,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10))","8176714b":"results=pd.DataFrame({\n    \"Model\":[\"Logistic_Regression\",\"Decision_tree\",\"KNN\",\"SVC\",\"RandomForest\",\"XgBOOST\"],\n    \"train_score\":[train_score1,train_score2,train_score3,train_score4,train_score5,train_score6],\n    \"validation_score\":[valid_score1,valid_score2,valid_score3,valid_score4,valid_score5,valid_score6]\n})","7a0123ef":"results","a4955c24":"test_predictions=random_cv2.best_estimator_.predict(test)","5b04f111":"test_predictions=pd.DataFrame(test_predictions,custid.values)","410aaefb":"test_predictions","8182a957":"CUSTOMER CHURN PREDICTION\n\nTARGET VARAIBLE: CHURN(yes\/no)\n\nPROBLEM: CLASSIFICATION PROBLEM\n\nDATA DESCRIPTION\n\nCustomerID: ID  of teh customer\n\nCustomerName: Name of the customer\n\nyearofBirth: year of the customer born\n\nmonthofBirth: month of the customer born\n\ndayofBirth: day of the customer born\n\nyearofEntry: year when customer registered in bank\n\nmonthofEntry: month when customer registered in bank\n\ndayofEntry: day when customer registered in bank\n\nGender: sex of the person(male\/female)\n\nLocation: Location of the customer\n\nEducation: Educational background of the customer\n\nMaritalStatus: either the customer married or not\n\nOccupation: Occupation of the customer\n\nOwnhouse: customer having a ownhouse or not(yes\/no)\n\nCreditScore: creditscore of teh customer\n\nAccountBalance: Account balance of the customer\n\nIsCreditCardCustomer: is customer having a credit card are not?(1\/0)\n\nActiveMember: is the customer active member are not(0\/1)\n\nSalary: Salary of teh customer\n\nchurn: is the customer left from bank or not?(yes\/no)"}}