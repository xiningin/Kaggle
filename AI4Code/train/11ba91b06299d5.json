{"cell_type":{"ebdf80a6":"code","9dfae3a1":"code","56a6b764":"code","0108c00d":"code","4507b769":"code","bc1f2943":"code","b6d1c706":"code","83c4dec0":"code","26325e53":"code","5a189cb5":"code","d4ab6352":"code","8fbe6538":"code","74251010":"code","7907c0bd":"code","3dd04d87":"code","956b5951":"code","f4446f94":"code","b1d0da26":"code","da988884":"code","a97508af":"code","2c5edfc8":"code","79446aae":"code","3d34fa73":"code","00e05b8c":"code","c4710d65":"code","a9876113":"code","e561d8cb":"code","631d1dcd":"code","f3feeedd":"code","8fed541b":"code","baf5a623":"code","43a9ef6d":"code","a4aebb7f":"code","2251582b":"code","497c0941":"code","ced7b587":"code","684e74ff":"code","ac0bcb6f":"code","40e1b7ab":"code","17c828b7":"code","0c502261":"code","c1d9d755":"markdown","773a3d94":"markdown","fe97b6f7":"markdown","32b4cac7":"markdown","cbe443c6":"markdown","6063d095":"markdown","479b0e41":"markdown","85ca93dc":"markdown","81ec0d49":"markdown","1702074f":"markdown","a6c36f40":"markdown","9779d845":"markdown","c0dd5ac7":"markdown","7eef3f1a":"markdown"},"source":{"ebdf80a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#Dataframe manipulation library\nimport pandas as pd\n#Math functions, we'll only need the sqrt function so let's import only that\nfrom math import sqrt\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9dfae3a1":"#Storing the movie information into a pandas dataframe\nmovies_df = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\n#Storing the user information into a pandas dataframe\nratings_df = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")","56a6b764":"movies_df.shape","0108c00d":"movies_df.head()","4507b769":"#Using regular expressions to find a year stored between parentheses\n#We specify the parantheses so we don't conflict with movies that have years in their titles\nmovies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n#Removing the parentheses\nmovies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n#Removing the years from the 'title' column\nmovies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n#Applying the strip function to get rid of any ending whitespace characters that may have appeared\nmovies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\nmovies_df.head()","bc1f2943":"#Every genre is separated by a | so we simply have to call the split function on |\nmovies_df['genres'] = movies_df.genres.str.split('|')\nmovies_df.head()","b6d1c706":"#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.\nmoviesWithGenres_df = movies_df.copy()\n\n#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column\nfor index, row in movies_df.iterrows():\n    for genre in row['genres']:\n        moviesWithGenres_df.at[index, genre] = 1\n#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\nmoviesWithGenres_df = moviesWithGenres_df.fillna(0)\nmoviesWithGenres_df.head()","83c4dec0":"userInput = [\n            {'title':'Breakfast Club, The', 'rating':5},\n            {'title':'Toy Story', 'rating':3.5},\n            {'title':'Jumanji', 'rating':2},\n            {'title':\"Pulp Fiction\", 'rating':5},\n            {'title':'Akira', 'rating':4.5}\n         ] \ninputMovies = pd.DataFrame(userInput)\ninputMovies","26325e53":"#Filtering out the movies by title\ninputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n#Then merging it so we can get the movieId. It's implicitly merging it by title.\ninputMovies = pd.merge(inputId, inputMovies)\n#Dropping information we won't use from the input dataframe\ninputMovies = inputMovies.drop('genres', 1).drop('year', 1)\n#Final input dataframe\n#If a movie you added in above isn't here, then it might not be in the original \n#dataframe or it might spelled differently, please check capitalisation.\ninputMovies","5a189cb5":"#Filtering out the movies from the input\nuserMovies = moviesWithGenres_df[moviesWithGenres_df['movieId'].isin(inputMovies['movieId'].tolist())]\nuserMovies","d4ab6352":"#Resetting the index to avoid future issues\nuserMovies = userMovies.reset_index(drop=True)\n#Dropping unnecessary issues due to save memory and to avoid issues\nuserGenreTable = userMovies.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\nuserGenreTable","8fbe6538":"inputMovies['rating']","74251010":"#Dot produt to get weights\nuserProfile = userGenreTable.transpose().dot(inputMovies['rating'])\n#The user profile\nuserProfile","7907c0bd":"#Now let's get the genres of every movie in our original dataframe\ngenreTable = moviesWithGenres_df.set_index(moviesWithGenres_df['movieId'])\n#And drop the unnecessary information\ngenreTable = genreTable.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\ngenreTable.head()","3dd04d87":"genreTable.shape","956b5951":"#Multiply the genres by the weights and then take the weighted average\nrecommendationTable_df = ((genreTable*userProfile).sum(axis=1))\/(userProfile.sum())\nrecommendationTable_df.head()","f4446f94":"#Sort our recommendations in descending order\nrecommendationTable_df = recommendationTable_df.sort_values(ascending=False)\n#Just a peek at the values\nrecommendationTable_df.head()","b1d0da26":"#The final recommendation table\nmovies_df.loc[movies_df['movieId'].isin(recommendationTable_df.head(20).keys())]","da988884":"movies_df.head()","a97508af":"#Dropping the genres column\nmovies_df = movies_df.drop('genres', 1)\nmovies_df.head()","2c5edfc8":"ratings_df.head()","79446aae":"#Drop removes a specified row or column from a dataframe\nratings_df = ratings_df.drop('timestamp', 1)\nratings_df.head()","3d34fa73":"userInput = [\n            {'title':'Breakfast Club, The', 'rating':5},\n            {'title':'Toy Story', 'rating':3.5},\n            {'title':'Jumanji', 'rating':2},\n            {'title':\"Pulp Fiction\", 'rating':5},\n            {'title':'Akira', 'rating':4.5}\n         ] \ninputMovies = pd.DataFrame(userInput)\ninputMovies","00e05b8c":"#Filtering out the movies by title\ninputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n#Then merging it so we can get the movieId. It's implicitly merging it by title.\ninputMovies = pd.merge(inputId, inputMovies)\n#Dropping information we won't use from the input dataframe\ninputMovies = inputMovies.drop('year', 1)\n#Final input dataframe\n#If a movie you added in above isn't here, then it might not be in the original \n#dataframe or it might spelled differently, please check capitalisation.\ninputMovies","c4710d65":"#Filtering out users that have watched movies that the input has watched and storing it\nuserSubset = ratings_df[ratings_df['movieId'].isin(inputMovies['movieId'].tolist())]\nuserSubset.head()","a9876113":"#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\nuserSubsetGroup = userSubset.groupby(['userId'])","e561d8cb":"#lets look at one of the users, e.g. the one with userID=1130\nuserSubsetGroup.get_group(1130)","631d1dcd":"userSubsetGroup.head()","f3feeedd":"#Sorting it so users with movie most in common with the input will have priority\nuserSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)","8fed541b":"# Check the first 3 users\nuserSubsetGroup[0:3]","baf5a623":"# we only use a subset of top 100 users\nuserSubsetGroup = userSubsetGroup[0:100]","43a9ef6d":"#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\npearsonCorrelationDict = {}\n\n#For every user group in our subset\nfor name, group in userSubsetGroup:\n    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n    group = group.sort_values(by='movieId')\n    inputMovies = inputMovies.sort_values(by='movieId')\n    #Get the N for the formula\n    nRatings = len(group)\n    #Get the review scores for the movies that they both have in common\n    temp_df = inputMovies[inputMovies['movieId'].isin(group['movieId'].tolist())]\n    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n    tempRatingList = temp_df['rating'].tolist()\n    #Let's also put the current user group reviews in a list format\n    tempGroupList = group['rating'].tolist()\n    #Now let's calculate the pearson correlation between two users, so called, x and y\n    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)\/float(nRatings)\n    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)\/float(nRatings)\n    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)\/float(nRatings)\n    \n    #If the denominator is different than zero, then divide, else, 0 correlation.\n    if Sxx != 0 and Syy != 0:\n        pearsonCorrelationDict[name] = Sxy\/sqrt(Sxx*Syy)\n    else:\n        pearsonCorrelationDict[name] = 0","a4aebb7f":"pearsonCorrelationDict.items()","2251582b":"pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\npearsonDF.columns = ['similarityIndex']\npearsonDF['userId'] = pearsonDF.index\npearsonDF.index = range(len(pearsonDF))\npearsonDF.head()","497c0941":"topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\ntopUsers.head()","ced7b587":"topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\ntopUsersRating.head()","684e74ff":"#Multiplies the similarity by the user's ratings\ntopUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\ntopUsersRating.head()","ac0bcb6f":"#Applies a sum to the topUsers after grouping it up by userId\ntempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\ntempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\ntempTopUsersRating.head()","40e1b7ab":"#Creates an empty dataframe\nrecommendation_df = pd.DataFrame()\n#Now we take the weighted average\nrecommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']\/tempTopUsersRating['sum_similarityIndex']\nrecommendation_df['movieId'] = tempTopUsersRating.index\nrecommendation_df.head()","17c828b7":"#sort it and see the top 20 recommendations\n\nrecommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\nrecommendation_df.head(10)","0c502261":"movies_df.loc[movies_df['movieId'].isin(recommendation_df.head(10)['movieId'].tolist())]","c1d9d755":"we're going to turn each genre into weights. We can do this by using the input's reviews and multiplying them into the input's genre table and then summing up the resulting table by column. This operation is actually a dot product between a matrix and a vector, so we can simply accomplish by calling Pandas's \"dot\" function.","773a3d94":"### Similar Users","fe97b6f7":"### Building the UserProfile","32b4cac7":"### Advantages and Disadvantages of Collaborative Filtering\n\n##### Advantages\n* Takes other user's ratings into consideration\n* Doesn't need to study or extract information from the recommended item\n* Adapts to the user's interests which might change over time\n\n##### Disadvantages\n* Approximation function can be slow\n* There might be a low of amount of users to approximate\n* Privacy issues when trying to learn the user's preferences","cbe443c6":"## User-based Collaborative Filtering\n\n __Collaborative Filtering__, which is also known as __User-User Filtering__. As hinted by its alternate name, this technique uses other users to recommend items to the input user. It attempts to find users that have similar preferences and opinions as the input and then recommends items that they have liked to the input. There are several methods of finding similar users (Even some making use of Machine Learning), and the one we will be using here is going to be based on the __Pearson Correlation Function__.\n \n The process for creating a User Based recommendation system is as follows:\n- Select a user with the movies the user has watched\n- Based on his rating to movies, find the top X neighbours \n- Get the watched movie record of the user for each neighbour.\n- Calculate a similarity score using some formula\n- Recommend the items with the highest score\n","6063d095":"### Rating of selected users to all movies\nWe're going to do this by taking the weighted average of the ratings of the movies using the Pearson Correlation as the weight. But to do this, we first need to get the movies watched by the users in our __pearsonDF__ from the ratings dataframe and then store their correlation in a new column called _similarityIndex\". This is achieved below by merging of these two tables.[](http:\/\/)","479b0e41":"Next, we are going to compare all users (not really all !!!) to our specified user and find the one that is most similar.  \nwe're going to find out how similar each user is to the input through the __Pearson Correlation Coefficient__. It is used to measure the strength of a linear association between two variables. The formula for finding this coefficient between sets X and Y with N values can be seen in the image below. \n\nWhy Pearson Correlation?\n\nPearson correlation is invariant to scaling, i.e. multiplying all elements by a nonzero constant or adding any constant to all elements. For example, if you have two vectors X and Y,then, pearson(X, Y) == pearson(X, 2 * Y + 3). This is a pretty important property in recommendation systems because for example two users might rate two series of items totally different in terms of absolute rates, but they would be similar users (i.e. with similar ideas) with similar rates in various scales .\n\n![alt text](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/bd1ccc2979b0fd1c1aec96e386f686ae874f9ec0 \"Pearson Correlation\")\n\nThe values given by the formula vary from r = -1 to r = 1, where 1 forms a direct correlation between the two entities (it means a perfect positive correlation) and -1 forms a perfect negative correlation. \n\nIn our case, a 1 means that the two users have similar tastes while a -1 means the opposite.","85ca93dc":"## Content-Based recommendation system\n\nNow, let's take a look at how to implement __Content-Based__ or __Item-Item recommendation systems__. This technique attempts to figure out what a user's favourite aspects of an item is, and then recommends items that present those aspects. In our case, we're going to try to figure out the input's favorite genres from the movies and ratings given.","81ec0d49":"Let's also sort these groups so the users that share the most movies in common with the input have higher priority. This provides a richer recommendation since we won't go through every single user.","1702074f":"### Recommendation table","a6c36f40":"Top x(=50) similar users to the input user","9779d845":"Now all we need to do is simply multiply the movie rating by its weight (The similarity index), then sum up the new ratings and divide it by the sum of the weights.\n\nWe can easily do this by simply multiplying two columns, then grouping up the dataframe by movieId and then dividing two columns:\n\nIt shows the idea of all similar users to candidate movies for the input user:","c0dd5ac7":"### Advantages and Disadvantages of Content-Based Filtering\n\n##### Advantages\n* Learns user's preferences\n* Highly personalized for the user\n\n##### Disadvantages\n* Doesn't take into account what others think of the item, so low quality item recommendations might happen\n* Extracting data is not always intuitive\n* Determining what characteristics of the item the user dislikes or likes is not always obvious","7eef3f1a":"Since keeping genres in a list format isn't optimal for the content-based recommendation system technique, we will use the One Hot Encoding technique to convert the list of genres to a vector where each column corresponds to one possible value of the feature. This encoding is needed for feeding categorical data. In this case, we store every different genre in columns that contain either 1 or 0. 1 shows that a movie has that genre and 0 shows that it doesn't. Let's also store this dataframe in another variable since genres won't be important for our first recommendation system."}}