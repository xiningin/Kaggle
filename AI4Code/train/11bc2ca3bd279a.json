{"cell_type":{"3915d1d6":"code","6ea7d171":"code","6d199d94":"code","09dc6d1a":"code","9a0f68d8":"code","016ddc07":"code","8d29e928":"code","8f65861b":"code","e1aefcf7":"code","22f201a3":"code","1a46c7c0":"code","a6f22d05":"code","bfa65053":"code","1c277c59":"code","9fc7664a":"code","1a38a2c1":"code","0052b244":"code","1384a860":"code","8c802671":"code","c77bf30c":"code","e33fc366":"code","c6204dcf":"code","04215664":"code","d32c8cc1":"code","b1e69bce":"code","93d11f4e":"code","023503d7":"code","779f1880":"code","8e5c9749":"markdown","97fda0a7":"markdown","2e12f7d7":"markdown","51f63d76":"markdown","490a1461":"markdown","839804a4":"markdown","e418428a":"markdown","6db0d8c5":"markdown","81a1ce07":"markdown","ebcaba94":"markdown","f87c923d":"markdown","05a0fe06":"markdown","78f2a0b1":"markdown","b76d2fdf":"markdown","54fa3960":"markdown","ca9bcbec":"markdown","4969e721":"markdown","0aa1b71a":"markdown","ebaba586":"markdown","8d845d21":"markdown","9d9cb330":"markdown","cbc436da":"markdown","5acb23cc":"markdown"},"source":{"3915d1d6":"### installlation required\n#!pip install mlxtend\n\n# libraries\nimport pandas as pd\npd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\n# this code ensures that the output is on a single line.\npd.set_option('display.expand_frame_repr', False)\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6ea7d171":"df=pd.read_csv('\/kaggle\/input\/online-retail-ii-data-set-from-ml-repository\/Year 2010-2011.csv', encoding = 'unicode_escape')\ndf.head()","6d199d94":"def check_df(dataframe):\n    print(\"################ Shape ####################\")\n    print(dataframe.shape)\n    print(\"############### Columns ###################\")\n    print(dataframe.columns)\n    print(\"############### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"############### Head ######################\")\n    print(dataframe.head())\n    print(\"############### Tail ######################\")\n    print(dataframe.tail())\n    print(\"############### Describe ###################\")\n    print(dataframe.describe().T)\n\ncheck_df(df)","09dc6d1a":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe","9a0f68d8":"df = retail_data_prep(df)","016ddc07":"# EXAMPLE:\n\n# Description   NINE DRAWER OFFICE TIDY   SET 2 TEA TOWELS I LOVE LONDON    SPACEBOY BABY GIFT SET\n# Invoice\n# 536370                              0                                 1                       0\n# 536852                              1                                 0                       1\n# 536974                              0                                 0                       0\n# 537065                              1                                 0                       0\n# 537463                              0                                 0                       1","8d29e928":"df_de = df[df['Country'] == \"Germany\"]\ndf_de.head(10)","8f65861b":"df_de.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).head(10)","e1aefcf7":"df_de.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().iloc[0:5, 0:5]","22f201a3":"df_de.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).iloc[0:5, 0:5]","1a46c7c0":"# applymap will itinirate all cells in the dataframe. apply would only itinirate in row or columns\ndf_de.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).applymap(\n    lambda x: 1 if x > 0 else 0).iloc[0:5, 0:5]","a6f22d05":"def create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","bfa65053":"de_inv_pro_df = create_invoice_product_df(df_de)\nde_inv_pro_df.head()","1c277c59":"def create_invoice_product_df(dataframe, id= True):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","9fc7664a":"de_inv_pro_df = create_invoice_product_df(df_de)\nde_inv_pro_df.head()","1a38a2c1":"de_inv_pro_df = create_invoice_product_df(df_de, id=True)","0052b244":"def check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)","1384a860":"check_id(df_de, \"10002\")","8c802671":"# minumum support value 0.01, we don't want to get below 0.01 \n# In real life scenarios, this minimum support value is very low.\nfrequent_itemsets = apriori(de_inv_pro_df, min_support=0.01, use_colnames=True)\nfrequent_itemsets.sort_values(\"support\", ascending=False).head(10)","c77bf30c":"rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\nrules.sort_values(\"support\", ascending=False).head()","e33fc366":"rules.sort_values(\"lift\", ascending=False).head(10)","c6204dcf":"product_id = \"22492\"\ncheck_id(df, product_id)","04215664":"sorted_rules = rules.sort_values(\"lift\", ascending=False)\n\nrecommendation_list = []\n\nfor i, product in enumerate(sorted_rules[\"antecedents\"]):\n    for j in list(product):\n        if j == product_id:\n            recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n\nrecommendation_list[0:3]","d32c8cc1":"check_id(df, \"21915\")","b1e69bce":"def arl_recommender(rules_df, product_id, rec_count=1):\n\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n\n    recommendation_list = []\n\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n\n    return recommendation_list[:rec_count]","93d11f4e":"check_id(df, \"23049\")","023503d7":"arl_recommender(rules, \"22492\", 1)","779f1880":"arl_recommender(rules, \"22492\", 2)","8e5c9749":"Let's check first stockcode's name 10002","97fda0a7":"<a id = \"9\"><\/a><br>\n## 3. Association Rules\nWe will subtract the probabilities of all possible products being together.","2e12f7d7":"<a id = \"7\"><\/a><br>\n### Outlier Observations","51f63d76":"<a id = \"11\"><\/a><br>\n# 4. References\n* https:\/\/github.com\/mvahit\n* https:\/\/www.veribilimiokulu.com\/\n* https:\/\/www.linkedin.com\/in\/vahitkeskin\/\n* https:\/\/www.analyticssteps.com\/blogs\/what-are-recommendation-systems-machine-learning\n* https:\/\/en.wikipedia.org\/wiki\/Association_rule_learning","490a1461":"<a id = \"6\"><\/a><br>\n### Load and Check Data","839804a4":"* The ouput indicates **Invoice 536527** has these above items.\n* We want to see the description (products) in the columns.\n* And we want to see whether there are products at the intersections of the matrix or not. We can do this with unstack function, we could have used pivot funct instead of it","e418428a":"* In this section, we will create a matrix of invoice and products as in the example below. ","6db0d8c5":"<a id = \"1\"><\/a><br>\n## 1. Data Preprocessing\n\n<a id = \"2\"><\/a><br>\n### 1.1 Business Problem\nTo suggest products to customers who have reached the basket stage.","81a1ce07":"* If there is a product in the columns, we expect 1, if not 0.\n* Firstly, we will assign 0 to NaN values.","ebcaba94":"Let's turn all these codes into a single function (named create_invoice_product_df).","f87c923d":"<a id = \"3\"><\/a><br>\n### 1.2 Dataset Story\n* The data set named Online Retail II is a UK-based online sale.\n* Store's sales between 01\/12\/2009 - 09\/12\/2011.\n* The product catalog of this company includes souvenirs. promotion can be considered as products.\n* There is also information that most of its customers are wholesalers..","05a0fe06":"<a id = \"5\"><\/a><br>\n### 1.4 Libraries ","78f2a0b1":"<a id = \"4\"><\/a><br>\n### 1.3 Variables\n* **InvoiceNo**: Invoice number. The unique number of each transaction, namely the invoice. Aborted operation if it starts with C.\n* **StockCode**: Product code. Unique number for each product.\n* **Description**: Product name\n* **Quantity**: Number of products. It expresses how many of the products on the invoices have been sold.\n* **InvoiceDate**: Invoice date and time.\n* **UnitPrice**: Product price (in GBP)\n* **CustomerID**: Unique customer number\n* **Country**: The country where the customer lives.","b76d2fdf":"\n# Introduction\nAssociation rule learning is a rule-based machine learning approach for finding significant connections between variables in large databases. It is designed to identify strong rules that have been identified in databases using various measures of interest.\n\nOur aim is to suggest products to users in the product purchasing process by applying association analysis to the online retail II dataset.\n\n1. Data Preprocessing\n2. Preparing ARL Data Structure (Invoice-Product Matrix))\n3. Association Rules\n4. Making Product Suggestions to Users at the Shopping Cart Stage\n\n\n<font color = 'blue'>\nContent: \n\n    \n\n1. [Data Preprocessing](#1)\n    * 1.1 [Business Problem](#2)\n    * 1.2 [Dataset Story](#3)\n    * 1.3 [Variables](#4)\n    * 1.4 [Libraries](#5)\n    * 1.5 [Load and Check Data](#6)\n    * 1.6 [Outlier Observations](#7)\n1. [Preparing ARL Data Structure (Invoice-Product Matrix)](#8)\n1. [Association Rules](#9)\n1. [Making Product Suggestions to Users at the Shopping Cart Stage](#10)\n1. [References](#11)","54fa3960":"* We will only work on Germany, let's filter. ","ca9bcbec":"<a id = \"10\"><\/a><br>\n## 4. Making Product Suggestions to Users at the Shopping Cart Stage\nExample Product Id: 22492","4969e721":"Seconly, If there is a product in the columns, we will convert it to 1.","0aa1b71a":"Let's define a function for checking StockCode number","ebaba586":"If want to see two product suggection","8d845d21":"#### Some Notes\n* For example, if I had 10,000 products, I wouldn't be interested in all of them. In this case it should be done at category level\n* When the person adds a product to the cart, what I will suggest should already be clear.\n* I know what to suggest with product X, but if the person has already bought this product, it is necessary to make a correction accordingly. There must be an intermediate control mechanism. At the database level, the userid should be checked. If the person has not bought that product after checking, it is necessary to recommend that product. This cannot be done. There is a fine line you should consider","9d9cb330":"* **antecedent support:** probability of the first product\n* **consequent support:** probability of the second product and others\n* **support:** probability of two products (or more) appearing together\n* **confidence:** when product x is bought, the probability of purchasing product y\n* **lift:** when x is taken, the probability of getting y increases by this much (lift)","cbc436da":"It doesn't look good, let's make id = True in create_invoice_product_df for better looking matrix","5acb23cc":"<a id = \"8\"><\/a><br>\n## 2. Preparing ARL Data Structure (Invoice-Product Matrix)"}}