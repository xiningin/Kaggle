{"cell_type":{"cf4b54e1":"code","cff2aff8":"code","db352bfa":"code","6622d27c":"code","09e037f5":"code","0715e283":"code","3e730afe":"code","a4920f42":"code","8b460fc6":"code","594a3397":"code","70f76989":"code","42bed589":"code","ae42625d":"code","58827560":"code","d3ae90c6":"code","3f7a3592":"code","4f96d530":"code","d406d7e2":"code","6e8e975a":"code","4a33e657":"code","6497b20b":"code","d67d7ce3":"code","6323b0c9":"code","eea1fd11":"code","ee742ff4":"code","8269a367":"code","d1ca7bcf":"code","995773fd":"code","76c3e700":"code","c5fb1647":"code","00869461":"code","3f7dddb6":"code","83a0335c":"code","dd93b461":"code","e936e8a0":"code","47b89bc7":"code","a11d8e46":"code","db8a6bd4":"code","22d4972c":"code","dd1cffba":"code","e5394514":"code","5c45199d":"code","cba0f6b3":"code","73fa17db":"code","068931ab":"code","025c7fd3":"code","9aeff4e4":"code","f6be7f6e":"code","002ed15b":"code","8cdbde98":"code","3e42cd3d":"code","f1f29318":"code","834ddb09":"code","2abb7adb":"code","0d943ed2":"code","47477282":"code","ef58da7a":"code","01097d4e":"code","ace81d29":"code","780e49df":"code","6e76d20b":"code","b8a03b43":"code","fde4ad6c":"code","516eeb3e":"code","bc151c43":"code","039b3177":"code","84ec4a68":"code","a230f0ae":"code","31924bf4":"code","e3383f39":"code","6f5fa5ce":"code","c2e0f2bf":"markdown","08a2a9e3":"markdown","508a29dd":"markdown","c8c8d8dc":"markdown","ceeab921":"markdown","fb4ac190":"markdown","b370a744":"markdown","3ae2efed":"markdown","1b59dd03":"markdown","c88b342c":"markdown","af965094":"markdown","0e8236e3":"markdown","cd2a52a7":"markdown","cde0fcc5":"markdown","4bab7bc7":"markdown","42a29f78":"markdown","0f128a8a":"markdown","4b8e7530":"markdown","0c5faca3":"markdown","3ac79f6e":"markdown","c2281203":"markdown","7942d0e7":"markdown","19dfeff3":"markdown","a6bd3674":"markdown","1606770b":"markdown","0fcdb032":"markdown","387c4170":"markdown","8962fad1":"markdown","937fa480":"markdown","0a65502b":"markdown","94112a14":"markdown","d3dc394c":"markdown","723971a4":"markdown","bf4005e3":"markdown","dddced05":"markdown","89032e55":"markdown","48711726":"markdown","89c225c3":"markdown","f8823172":"markdown","92653841":"markdown","ac608e21":"markdown","8f23ff1d":"markdown","4b4dbdd1":"markdown","5d23fc32":"markdown","c718a660":"markdown","2e0e51dd":"markdown","7fe2f9f1":"markdown","bfe162c2":"markdown","d8054a0e":"markdown","3039b417":"markdown","dbedc29b":"markdown","f91d3e21":"markdown","113df173":"markdown","5ca9d528":"markdown","3694e0af":"markdown","2b72cd79":"markdown","fba48cf4":"markdown","b529d5a1":"markdown"},"source":{"cf4b54e1":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\n\n# reading data files\n# using encoding = \"ISO-8859-1\" to avoid pandas encoding error\nrounds = pd.read_csv(\"\/kaggle\/input\/spark-fund-investment-analysis\/datasets\/rounds2.csv\", encoding = \"ISO-8859-1\")\ncompanies = pd.read_csv(\"\/kaggle\/input\/spark-fund-investment-analysis\/datasets\/companies.txt\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n","cff2aff8":"profile = ProfileReport(rounds, title='Rounds Profiling Report', html={'style':{'full_width':True}})\nprofile","db352bfa":"profile = ProfileReport(companies, title='Companies Profiling Report', html={'style':{'full_width':True}})\nprofile","6622d27c":"# look at companies head\ncompanies.head()","09e037f5":"# identify the unique number of permalinks in companies\nlen(companies.permalink.unique())","0715e283":"# converting all permalinks to lowercase\ncompanies['permalink'] = companies['permalink'].str.lower()\ncompanies.head()\n","3e730afe":"# look at unique values again\nlen(companies.permalink.unique())","a4920f42":"# look at unique company names in rounds df\n# note that the column name in rounds file is different (company_permalink)\nlen(rounds.company_permalink.unique())\n","8b460fc6":"# converting column to lowercase\nrounds['company_permalink'] = rounds['company_permalink'].str.lower()\nrounds.head()","594a3397":"# Look at unique values again\nlen(rounds.company_permalink.unique())","70f76989":"# companies present in rounds file but not in (~) companies file\nrounds.loc[~rounds['company_permalink'].isin(companies['permalink']), :]","42bed589":"# looking at the indices with weird characters\nrounds_original = pd.read_csv(\"\/kaggle\/input\/spark-fund-investment-analysis\/datasets\/rounds2.csv\", encoding = \"ISO-8859-1\")\nrounds_original.iloc[[29597, 31863, 45176, 58473], :]","ae42625d":"rounds['company_permalink'] = rounds.company_permalink.str.encode('utf-8').str.decode('ascii', 'ignore')\nrounds.loc[~rounds['company_permalink'].isin(companies['permalink']), :]","58827560":"# Look at unique values again\nlen(rounds.company_permalink.unique())","d3ae90c6":"# companies present in companies df but not in rounds df\ncompanies.loc[~companies['permalink'].isin(rounds['company_permalink']), :]\n","3f7a3592":"# remove encoding from companies df\ncompanies['permalink'] = companies.permalink.str.encode('utf-8').str.decode('ascii', 'ignore')\n","4f96d530":"# companies present in companies df but not in rounds df\ncompanies.loc[~companies['permalink'].isin(rounds['company_permalink']), :]\n","d406d7e2":"# quickly verify that there are 66368 unique companies in both\n# and that only the same 66368 are present in both files\n\n# unqiue values\nprint(len(companies.permalink.unique()))\nprint(len(rounds.company_permalink.unique()))\n\n# present in rounds but not in companies\nprint(len(rounds.loc[~rounds['company_permalink'].isin(companies['permalink']), :]))","6e8e975a":"# missing values in companies df\ncompanies.isnull().sum()","4a33e657":"# missing values in rounds df\nrounds.isnull().sum()","6497b20b":"# merging the two dfs\nmaster = pd.merge(companies, rounds, how=\"inner\", left_on=\"permalink\", right_on=\"company_permalink\")\nmaster.head()","d67d7ce3":"# print column names\nmaster.columns","6323b0c9":"# removing redundant columns\nmaster =  master.drop(['company_permalink'], axis=1) ","eea1fd11":"# look at columns after dropping\nmaster.columns","ee742ff4":"# column-wise missing values \nmaster.isnull().sum()","8269a367":"# summing up the missing values (column-wise) and displaying fraction of NaNs\nround(100*(master.isnull().sum()\/len(master.index)), 2)","d1ca7bcf":"# dropping columns \nmaster = master.drop(['funding_round_code', 'homepage_url', 'founded_at', 'state_code', 'region', 'city'], axis=1)\nmaster.head()","995773fd":"# summing up the missing values (column-wise) and displaying fraction of NaNs\nround(100*(master.isnull().sum()\/len(master.index)), 2)","76c3e700":"# summary stats of raised_amount_usd\nmaster['raised_amount_usd'].describe()","c5fb1647":"# removing NaNs in raised_amount_usd\nmaster = master[~np.isnan(master['raised_amount_usd'])]\nround(100*(master.isnull().sum()\/len(master.index)), 2)","00869461":"country_codes = master['country_code'].astype('category')\n\n# displaying frequencies of each category\ncountry_codes.value_counts()","3f7dddb6":"# viewing fractions of counts of country_codes\n100*(master['country_code'].value_counts()\/len(master.index))","83a0335c":"# removing rows with missing country_codes\nmaster = master[~pd.isnull(master['country_code'])]\n\n# look at missing values\nround(100*(master.isnull().sum()\/len(master.index)), 2)","dd93b461":"# removing rows with missing category_list values\nmaster = master[~pd.isnull(master['category_list'])]\n\n# look at missing values\nround(100*(master.isnull().sum()\/len(master.index)), 2)","e936e8a0":"# look at the master df info for number of rows etc.\nmaster.info()","47b89bc7":"# after missing value treatment, approx 77% observations are retained\n100*(len(master.index) \/ len(rounds.index))","a11d8e46":"# first, let's filter the df so it only contains the four specified funding types\ndf = master[(master.funding_round_type == \"venture\") | \n        (master.funding_round_type == \"angel\") | \n        (master.funding_round_type == \"seed\") | \n        (master.funding_round_type == \"private_equity\") ]","db8a6bd4":"# distribution of raised_amount_usd\nsns.boxplot(y=df['raised_amount_usd'])\nplt.yscale('log')\nplt.show()","22d4972c":"# summary metrics\ndf['raised_amount_usd'].describe()","dd1cffba":"# comparing summary stats across four categories\nsns.boxplot(x='funding_round_type', y='raised_amount_usd', data=df)\nplt.yscale('log')\nplt.show()","e5394514":"# compare the mean and median values across categories\ndf.pivot_table(values='raised_amount_usd', columns='funding_round_type', aggfunc=[np.median, np.mean])","5c45199d":"# compare the median investment amount across the types\ndf.groupby('funding_round_type')['raised_amount_usd'].median().sort_values(ascending=False)","cba0f6b3":"# filter the df for private equity type investments\ndf = df[df.funding_round_type==\"venture\"]\n\n# group by country codes and compare the total funding amounts\ncountry_wise_total = df.groupby('country_code')['raised_amount_usd'].sum().sort_values(ascending=False)\nprint(country_wise_total)","73fa17db":"# top 9 countries\ntop_9_countries = country_wise_total[:9]\ntop_9_countries","068931ab":"# filtering for the top three countries\ndf = df[(df.country_code=='USA') | (df.country_code=='GBR') | (df.country_code=='IND')]\ndf.head()","025c7fd3":"# filtered df has about 38800 observations\ndf.info()","9aeff4e4":"# boxplot to see distributions of funding amount across countries\nplt.figure(figsize=(10, 10))\nsns.boxplot(x='country_code', y='raised_amount_usd', data=df)\nplt.yscale('log')\nplt.show()","f6be7f6e":"# extracting the main category\ndf.loc[:, 'main_category'] = df['category_list'].apply(lambda x: x.split(\"|\")[0])\ndf.head()","002ed15b":"# drop the category_list column\ndf = df.drop('category_list', axis=1)\ndf.head()","8cdbde98":"# read mapping file\nmapping = pd.read_csv(\"\/kaggle\/input\/spark-fund-investment-analysis\/datasets\/mapping.csv\", sep=\",\")\nmapping.head()","3e42cd3d":"# missing values in mapping file\nmapping.isnull().sum()","f1f29318":"# remove the row with missing values\nmapping = mapping[~pd.isnull(mapping['category_list'])]\nmapping.isnull().sum()","834ddb09":"# converting common columns to lowercase\nmapping['category_list'] = mapping['category_list'].str.lower()\ndf['main_category'] = df['main_category'].str.lower()","2abb7adb":"# look at heads\nprint(mapping.head())","0d943ed2":"print(df.head())","47477282":"mapping['category_list']","ef58da7a":"# values in main_category column in df which are not in the category_list column in mapping file\ndf[~df['main_category'].isin(mapping['category_list'])]","01097d4e":"# values in the category_list column which are not in main_category column \nmapping[~mapping['category_list'].isin(df['main_category'])]","ace81d29":"# replacing '0' with 'na'\nmapping['category_list'] = mapping['category_list'].apply(lambda x: x.replace('0', 'na'))\nprint(mapping['category_list'])","780e49df":"# merge the dfs\ndf = pd.merge(df, mapping, how='inner', left_on='main_category', right_on='category_list')\ndf.head()","6e76d20b":"# let's drop the category_list column since it is the same as main_category\ndf = df.drop('category_list', axis=1)\ndf.head()","b8a03b43":"# look at the column types and names\ndf.info()","fde4ad6c":"# store the value and id variables in two separate arrays\n\n# store the value variables in one Series\nvalue_vars = df.columns[9:18]\n\n# take the setdiff() to get the rest of the variables\nid_vars = np.setdiff1d(df.columns, value_vars)\n\nprint(value_vars, \"\\n\")\nprint(id_vars)","516eeb3e":"# convert into long\nlong_df = pd.melt(df, \n        id_vars=list(id_vars), \n        value_vars=list(value_vars))\n\nlong_df.head()","bc151c43":"# remove rows having value=0\nlong_df = long_df[long_df['value']==1]\nlong_df = long_df.drop('value', axis=1)","039b3177":"# look at the new df\nlong_df.head()\nlen(long_df)","84ec4a68":"# renaming the 'variable' column\nlong_df = long_df.rename(columns={'variable': 'sector'})","a230f0ae":"long_df.info()","31924bf4":"# summarising the sector-wise number and sum of venture investments across three countries\n\n# first, let's also filter for investment range between 5 and 15m\ndf = long_df[(long_df['raised_amount_usd'] >= 5000000) & (long_df['raised_amount_usd'] <= 15000000)]\n","e3383f39":"# groupby country, sector and compute the count and sum\ndf.groupby(['country_code', 'sector']).raised_amount_usd.agg(['count', 'sum'])","6f5fa5ce":"# plotting sector-wise count and sum of investments in the three countries\nplt.figure(figsize=(16, 14))\n\nplt.subplot(2, 1, 1)\np = sns.barplot(x='sector', y='raised_amount_usd', hue='country_code', data=df, estimator=np.sum)\np.set_xticklabels(p.get_xticklabels(),rotation=30)\nplt.title('Total Invested Amount (USD)')\n\nplt.subplot(2, 1, 2)\nq = sns.countplot(x='sector', hue='country_code', data=df)\nq.set_xticklabels(q.get_xticklabels(),rotation=30)\nplt.title('Number of Investments')\n\n\nplt.show()","c2e0f2bf":"Now, we'll read the ```mapping.csv``` file and merge the main categories with its corresponding column. ","08a2a9e3":"Thus, this is most likely a data quality issue we have introduced while reading the data file into python. Specifically, this is most likely caused because of encoding.\n\nFirst, let's try to figure out the encoding type of this file. Then we can try specifying the encoding type at the time of reading the file. The ```chardet``` library shows the encoding type of a file.","508a29dd":"The median investment amount for type 'private_equity' is approx. USD 20m, which is beyond Teclov' range of 5-15m. The median of 'venture' type is about USD 5m, which is suitable for them. The average amounts of angel and seed types are lower than their range.\n\nThus, 'venture' type investment will be most suited to them.","c8c8d8dc":"Thus, there are 66368 unique companies in the table and ```permalink``` is the unique primary key. Each row represents a unique company.\n\nLet's now check whether all of these 66368 companies are present in the rounds file, and if some extra ones are present.","ceeab921":"Let's look at the fraction of missing values in the columns.","fb4ac190":"This will be much more easy to understand using a plot.","b370a744":"## Country Analysis\n\nLet's now compare the total investment amounts across countries. Note that we'll filter the data for only the 'venture' type investments and then compare the 'total investment' across countries.","3ae2efed":"Note that there's a large difference between the mean and the median values for all four types. For type venture, for e.g. the median is about 20m while the mean is about 70m. \n\nThus, the choice of the summary statistic will drastically affect the decision (of the investment type). Let's choose median, since there are quite a few extreme values pulling the mean up towards them - but they are not the most 'representative' values.\n","1b59dd03":"Let's now extract the top 9 countries from ```country_wise_total```.","c88b342c":"The dataframe now contains only venture type investments in countries USA, IND and GBR, and we have mapped each company to one of the eight main sectors (named 'sector' in the dataframe). \n\nWe can now compute the sector-wise number and the amount of investment in the three countries.","af965094":"The variables funding_round_code and raised_amount_usd contain some missing values, as shown above. We'll deal with them after we're done with understanding the data - column names, primary keys of tables etc.","0e8236e3":"Note that there's a significant difference between the mean and the median - USD 9.5m and USD 2m. Let's also compare the summary stats across the four categories.","cd2a52a7":"Apparently, pandas cannot decode \"cp1254\" in this case. After searching a lot on stackoverflow and Google, the best conclusion that can be drawn is that this file is encoded using multiple encoding types (may be because the ```company_permalink``` column contains names of companies in various countries, and hence various languages).\n\nAfter trying various other encoding types (in vain), this answer suggested an alternate (and a more intelligent) way: https:\/\/stackoverflow.com\/questions\/45871731\/removing-special-characters-in-a-pandas-dataframe.\n\n","cde0fcc5":"## Sector Analysis\n\nFirst, we need to extract the main sector using the column ```category_list```. The category_list column contains values such as 'Biotechnology|Health Care' - in this, 'Biotechnology' is the 'main category' of the company, which we need to use.\n\nLet's extract the main categories in a new column.","4bab7bc7":"Let's now look at the column ```country_code```. To see the distribution of the values for categorical variables, it is best to convert them into type 'category'.","42a29f78":"# Part 2: Data Cleaning - II\n\nNow that we've treated the encoding problems (caused by special characters), let's complete the data cleaning process by treating missing values. ","0f128a8a":"Thus, the top country in terms of the number of investments (and the total amount invested) is the USA. The sectors 'Others', 'Social, Finance, Analytics and Advertising' and 'Cleantech\/Semiconductors' are the most heavily invested ones.\n\nIn case you don't want to consider 'Others' as a sector, 'News, Search and Messaging' is the next best sector.","4b8e7530":"Now let's try telling pandas (at the time of importing) the encoding type. Here's a list of various encoding types python can handle: https:\/\/docs.python.org\/2\/library\/codecs.html#standard-encodings.","0c5faca3":"One can visually analyse the distribution and the total values of funding amount.","3ac79f6e":"Now, we have to compute a **representative value of the funding amount** for each type of invesstment. We can either choose the mean or the median - let's have a look at the distribution of ```raised_amount_usd``` to get a sense of the distribution of data.\n\n","c2281203":"Let's have a look at the company permalinks which are in the 'rounds' file but not in 'companies'.","7942d0e7":"# Part 3: Analysis\n\n\nIn this section, we'll conduct the three types of analyses - funding type, country analysis, and sector analysis.\n\n\n## Funding Type Analysis\n\nLet's compare the funding amounts across the funding types. Also, we need to impose the constraint that the investment amount should be between 5 and 15 million USD. We will choose the funding type such that the average investment amount falls in this range.","19dfeff3":"There seem to be 90247 unique values of ```company_permalink```, whereas we expected only 66368. May be this is because of uppercase\/lowercase issues.\n\nLet's convert the column to lowercase and look at unique values again.","a6bd3674":"Clearly, the column ```funding_round_code``` is useless (with about 73% missing values). Also, for the business objectives given, the columns ```homepage_url```, ```founded_at```, ```state_code```, ```region``` and ```city``` need not be used.\n\nThus, let's drop these columns.","1606770b":"Let's have a look at the ```category_list``` column of the mapping file. These values will be used to merge with the main df.","0fcdb032":"This looks fine now. Let's now merge the two dataframes.","387c4170":"# Teclov Part 1: Data Cleaning\n\nLet's start with getting the datafiles rounds.csv and companies.txt.\n","8962fad1":"After filtering for 'venture' investments and the three countries USA, Great Britain and India, the filtered df looks like this.","937fa480":"There seem to be 2 extra permalinks in the rounds file which are not present in the companies file. Let's hope that this is a data quality issue, since if this were genuine, we have two companies whose investment round details are available but their metadata (company name, sector etc.) is not available in the companies table.","0a65502b":"We can now drop the ```category_list``` column.","94112a14":"Among the top 9 countries, USA, GBR and IND are the top three English speaking countries. Let's filter the dataframe so it contains only the top 3 countries.","d3dc394c":"Firstly, let's get rid of the missing values since we'll not be able to merge those rows anyway. ","723971a4":"Ideally, the ```permalink``` column in the companies dataframe should be the unique_key of the table, having 66368 unique company names (links, or permalinks). Also, these 66368 companies should be present in the rounds file.\n\nLet's first confirm that these 66368 permalinks (which are the URL paths of companies' websites) are not repeating in the column, i.e. they are unique.","bf4005e3":"## Missing Value Treatment\n\nLet's now move to missing value treatment. \n\nLet's have a look at the number of missing values in both the dataframes.","dddced05":"By far, the most number of investments have happened in American countries. We can also see the fractions.","89032e55":"To be able to merge all the ```main_category``` values with the mapping file's ```category_list``` column, all the values in the  ```main_category``` column should be present in the ```category_list``` column of the mapping file.\n\nLet's see if this is true.","48711726":"Notice that values such as 'analytics', 'business analytics', 'finance', 'nanatechnology' etc. are not present in the mapping file.\n\nLet's have a look at the values which are present in the mapping file but not in the main dataframe df.","89c225c3":"We can now get rid of the rows where the column 'value' is 0 and then remove that column altogether.","f8823172":"Since the columns ```company_permalink``` and ```permalink``` are the same, let's remove one of them.\n","92653841":"Let's now look at the companies present in the companies df but not in rounds df - ideally there should be none.","ac608e21":"This seems to work fine. \n\nLet's now look at the number of unique values in rounds dataframe again.","8f23ff1d":"### Converting the 'wide' dataframe to 'long'\n\nYou'll notice that the columns representing the main category in the mapping file are originally in the 'wide' format - Automotive & Sports, Cleantech \/ Semiconductors etc.\n\nThey contain the value '1' if the company belongs to that category, else 0. This is quite redundant. We can as well have a column named 'sub-category' having these values. \n\nLet's convert the df into the long format from the current wide format. First, we'll store the 'value variables' (those which are to be melted) in an array. The rest will then be the 'index variables'.","4b4dbdd1":"The mean is somewhere around USD 10 million, while the median is only about USD 1m. The min and max values are also miles apart. \n\nIn general, since there is a huge spread in the funding amounts, it will be inappropriate to impute it with a metric such as median or mean. Also, since we have quite a large number of observations, it is wiser to just drop the rows. \n\nLet's thus remove the rows having NaNs in ```raised_amount_usd```.","5d23fc32":"Note that the fraction of missing values in the remaining dataframe has also reduced now - only 0.65% in ```category_list```. Let's thus remove those as well.\n\n**Note**\nOptionally, you could have simply let the missing values in the dataset and continued the analysis. There is nothing wrong with that. But in this case, since we will use that column later for merging with the 'main_categories', removing the missing values will be quite convenient (and again - we have enough data).","c718a660":"Thus, the ```companies``` df also contains special characters. Let's treat those as well.","2e0e51dd":"Note that the column ```raised_amount_usd``` is an important column, since that is the number we want to analyse (compare, means, sum etc.). That needs to be carefully treated. \n\nAlso, the column ```country_code``` will be used for country-wise analysis, and ```category_list``` will be used to merge the dataframe with the main categories.\n\nLet's first see how we can deal with missing values in ```raised_amount_usd```.\n","7fe2f9f1":"If you see carefully, you'll notice something fishy - there are sectors named *alter0tive medicine*, *a0lytics*, *waste ma0gement*, *veteri0ry*, etc. This is not a *random* quality issue, but rather a pattern. In some strings, the 'na' has been replaced by '0'. This is weird - maybe someone was trying to replace the 'NA' values with '0', and ended up doing this. \n\nLet's treat this problem by replacing '0' with 'na' in the ```category_list``` column.","bfe162c2":"Now, we have shortlisted the investment type (venture) and the three countries. Let's now choose the sectors.","d8054a0e":"Let's now look at the number of missing values in the master df.","3039b417":"The company weird characters appear when you import the data file. To confirm whether these characters are actually present in the given data or whether python has introduced them while importing into pandas, let's have a look at the original CSV file in Excel.","dbedc29b":"Also, let's convert all the entries to lowercase (or uppercase) for uniformity.","f91d3e21":"Let's also look at the summary metrics.","113df173":"Now it makes sense - there are 66368 unique companies in both the ```rounds``` and ```companies``` dataframes. \n\nIt is possible that a similar encoding problems are present in the companies file as well. Let's look at the companies which are present in the companies file but not in the rounds file - if these have special characters, then it is most likely because the ```companies``` file is encoded (while rounds is not).","5ca9d528":"All the permalinks have weird non-English characters. Let's see whether these characters are present in the original df as well. ","3694e0af":"Now, we can either delete the rows having ```country_code``` missing (about 6% rows), or we can impute them by ```USA```. Since the number 6 is quite small, and we have a decent amount of data, it may be better to just remove the rows.\n\n**Note that** ```np.isnan``` does not work with arrays of type 'object', it only works with native numpy type (float). Thus, you can use ```pd.isnull()``` instead.","2b72cd79":"Now, since we need to merge the mapping file with the main dataframe (df), let's convert the common column to lowercase in both.","fba48cf4":"Since there are no misisng values in the permalink or company_permalink columns, let's merge the two and then work on the master dataframe.","b529d5a1":"Thus, the encoding issue seems resolved now. Let's write these (clean) dataframes into separate files so we don't have to worry about encoding problems again."}}