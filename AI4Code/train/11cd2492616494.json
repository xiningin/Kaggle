{"cell_type":{"0abb6dc4":"code","80ff807a":"code","f7c2fc2b":"code","ac90b0f1":"code","aea12a40":"code","d2567048":"code","835104e9":"code","369f7da2":"code","5fe4a820":"code","7b3a8fc2":"code","8a72abb7":"code","b40b7bed":"code","52aecaa4":"code","9c6b3955":"code","243c1b3d":"code","6afffddd":"code","8ac9e49e":"code","3ab4f4a6":"code","1221bf28":"code","bde53efe":"code","9033fe04":"code","6b12f108":"code","e4a608a1":"code","82500a98":"code","9adfd119":"code","1322752c":"markdown","e3678996":"markdown","a0d79737":"markdown","1e7fb7c5":"markdown","a1fa98bc":"markdown","bd17990f":"markdown","888de364":"markdown","803928da":"markdown"},"source":{"0abb6dc4":"!pip install -q pyicu\n!pip install -q pycld2\n!pip install -q polyglot\n!pip install -q pyyaml h5py  # Required to save models in HDF5 format","80ff807a":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nimport tqdm\nimport transformers\nimport tensorflow as tf\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom polyglot.detect import Detector\n\nimport matplotlib.pyplot as plt","f7c2fc2b":"print(tf.__version__)\nprint(transformers.__version__)\nprint(tf.keras.__version__)","ac90b0f1":"# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";","aea12a40":"def get_language(text):\n    return Detector(\n        \"\".join(x for x in text if x.isprintable()), quiet=True\n    ).languages[0].name\n\nPATH =  \"..\/input\/jigsaw-multilingual-toxic-comment-classification\"\nFILES = os.listdir(PATH)\nprint(FILES)\n\nTRAIN_PATH = os.path.join(PATH, 'jigsaw-toxic-comment-train.csv')\ndata = pd.read_csv(TRAIN_PATH)\n\ndata[\"lang\"] = data[\"comment_text\"].apply(get_language)\ndata = data[data['lang'] == 'English']","d2567048":"data.head()","835104e9":"data.toxic.value_counts()","369f7da2":"X = data[['comment_text']]\ny = data[['toxic']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ny_test = y_test.toxic.values\ny_train = y_train.toxic.values\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","5fe4a820":"def map_func(input_ids, masks, labels):\n    return {\n        'input_ids': input_ids,\n        'attention_mask': masks\n    }, labels\n\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = transformers.AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\nSEQ_LEN = 128\nX_train_ids = np.zeros((len(X_train), SEQ_LEN))\nX_train_mask = np.zeros((len(X_train), SEQ_LEN))\n\nX_test_ids = np.zeros((len(X_test), SEQ_LEN))\nX_test_mask = np.zeros((len(X_test), SEQ_LEN))\n\nfor i, sequence in enumerate(X_train['comment_text']):\n    tokens = tokenizer.encode_plus(\n        sequence, max_length=SEQ_LEN,\n        truncation=True, padding='max_length',\n        add_special_tokens=True, return_token_type_ids=False,\n        return_attention_mask=True, return_tensors='tf'\n    )\n    X_train_ids[i, :], X_train_mask[i, :] = tokens['input_ids'], tokens['attention_mask']\n    \nfor i, sequence in enumerate(X_test['comment_text']):\n    tokens = tokenizer.encode_plus(\n        sequence, max_length=SEQ_LEN,\n        truncation=True, padding='max_length',\n        add_special_tokens=True, return_token_type_ids=False,\n        return_attention_mask=True, return_tensors='tf'\n    )\n    X_test_ids[i, :], X_test_mask[i, :] = tokens['input_ids'], tokens['attention_mask']\n    \ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train_ids, X_train_mask, y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test_ids, X_test_mask, y_test))\n\ntrain_dataset = train_dataset.map(map_func)\ntest_dataset = test_dataset.map(map_func)\n\ntrain_dataset = train_dataset.shuffle(100000).batch(32, drop_remainder=True)\ntest_dataset = test_dataset.shuffle(100000).batch(32, drop_remainder=True)","7b3a8fc2":"bert = transformers.TFAutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\ninput_ids = tf.keras.layers.Input(shape=(SEQ_LEN, ), name='input_ids', dtype='int32')\nmask = tf.keras.layers.Input(shape=(SEQ_LEN, ), name='attention_mask', dtype='int32')\n\nembeddings = bert.bert(input_ids, attention_mask=mask)[1]\n\nX = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n# X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n# X = tf.keras.layers.BatchNormalization()(X)\n# X = tf.keras.layers.Dense(128, activation='relu')(X)\n# X = tf.keras.layers.Dropout(0.1)(X)\n# X = tf.keras.layers.Dense(32, activation='relu')(X)\ny = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(X)\n\nmodel = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n\nmodel.layers[2].trainable = False\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(lr=1e-5, decay=1e-6), \n    loss='binary_crossentropy', \n    metrics=[tf.keras.metrics.AUC(name='AUC')]\n)\n\nr = model.fit(\n    train_dataset,\n    validation_data=(test_dataset),\n    epochs=10,\n    batch_size=4096\n)","8a72abb7":"model.evaluate(test_dataset)","b40b7bed":"def plot_learning_evolution(r):\n    plt.figure(figsize=(12, 8))\n    \n    plt.subplot(2, 2, 1)\n    plt.plot(r.history['loss'], label='Loss')\n    plt.plot(r.history['val_loss'], label='val_Loss')\n    plt.title('Loss evolution during trainig')\n    plt.legend()\n\n    plt.subplot(2, 2, 2)\n    plt.plot(r.history['AUC'], label='AUC')\n    plt.plot(r.history['val_AUC'], label='val_AUC')\n    plt.title('AUC score evolution during trainig')\n    plt.legend();","52aecaa4":"plot_learning_evolution(r)","9c6b3955":"# y_pred = model.predict(test_dataset)\n# confusion_matrix(y_test, y_pred.round())","243c1b3d":"!pip install pyyaml h5py  # Required to save models in HDF5 format","6afffddd":"tf.keras.models.save_model(model, \"hate_speech_10_epochs.hdf5\")\nmodel.save(\"hate_speech_10_epochs.h5\")","8ac9e49e":"hdf5_model = tf.keras.models.load_model(\"hate_speech_10_epochs.hdf5\")\nhdf5_model.summary()","3ab4f4a6":"h5_model = tf.keras.models.load_model(\"hate_speech_10_epochs.h5\")\nh5_model.summary()","1221bf28":"def prep_sentence(sentence):\n    tokens = tokenizer.encode_plus(\n        sentence, max_length=SEQ_LEN,\n        truncation=True, padding='max_length',\n        add_special_tokens=True, return_token_type_ids=False,\n        return_attention_mask=True, return_tensors='tf'\n    )\n    return {\n        'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n        'attention_mask': tf.cast(tokens['attention_mask'], tf.float64)\n    }","bde53efe":"toxic_speechs = [\n    'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n    'MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MOVIES. HE HAS SO MUCH BUTTSEX THAT HIS ASSHOLE IS NOW BIG ENOUGH TO BE CONSIDERED A COUNTRY.',\n    \"A block ohhhhhhhhhhhhhh noooooooooooo I'm soooo like gonna cry and like shit ... ha ha.  you think i care?  i dont even use wikipedia.  look at the serb reporting me to the geek squad, what are you like 5?  Rumor has it that you are another canadian serb.  Rumor has it that you have pissed of a select few from B93 & WP.   )  BYE BYE.\",\n    \"it is a constructive edit you idiot, every kid of every age should know that santa claus is fucking fictional. ever since i first heard of santa claus i knew that he was fictional, my parents didn't give me any delusions and if they had, i would've laughed in their faces and said it isn't logical because it fucking isn't. every kid should be logical just like i was and every kid should be able to logically fucking infer that there is no fucking santa claus in the real human universe.\",\n    'honestly ==\\nyou need to crawl under a rock and DIE YOU FAT BASTARD\\n\\n=='\n]","9033fe04":"for speech in toxic_speechs:\n    prediction = h5_model.predict(prep_sentence(speech))\n    print(prediction)","6b12f108":"for speech in toxic_speechs:\n    prediction = hdf5_model.predict(prep_sentence(speech))\n    print(prediction)","e4a608a1":"non_toxic_speechs = [\n    \"Gale, you're living proof why wikipedia should NEVER be trusted as fact. I mean, telling someone to blindly believe whatever's said instead of verifying? You need to take a walk in traffic for saying that!\\n\\n99.149.119.168\",\n    'EastEnders Manual of Style \\n\\nHello, just wanted you to be aware of the EE MoS, which helps us work out what is appropriate for Infoboxes etc.  Cheers,  (Talk)',\n    'You need to provide high-quality secondary sources (e.g., not original publications from medical experiments, but perhaps review articles or medical textbooks) that support this significant change in definition.',\n    \"I appreciate your responses, guys. I take the recommendation as an admin as a great compliment. However, since I move around so much and my knowledge of Wikipedia isn't where I would like it to be before I went after something like that, I will get back to you if the vote ever happens. In the mean time, I definitely appreciate the compliment. }\",    \n    \"Stop reinserting harrassing content on WP:ANI \\n\\nStop readding this material.  If you continue with this from other IP ranges or addresses we will be forced to block larger IP ranges from editing.  You aren't allowed to harrass people like this on Wikipedia.\"\n]","82500a98":"for speech in non_toxic_speechs:\n    prediction = h5_model.predict(prep_sentence(speech))\n    print(prediction)","9adfd119":"for speech in non_toxic_speechs:\n    prediction = hdf5_model.predict(prep_sentence(speech))\n    print(prediction)","1322752c":"# Toxic Comments","e3678996":"# Saving and Uploading the model","a0d79737":"## Tokenizing the data","1e7fb7c5":"# Non-Toxic Comments","a1fa98bc":"# Split data to Train and Test","bd17990f":"# Model Building","888de364":"# Identificar comentarios de toxicidad\n\n# 1. Descripci\u00f3n\n- Un \u00e1rea principal de atenci\u00f3n son los modelos de aprendizaje autom\u00e1tico que pueden identificar la toxicidad en las conversaciones en l\u00ednea, donde la toxicidad se define como cualquier cosa grosera, irrespetuosa o que pueda hacer que alguien abandone una discusi\u00f3n. Si se pueden identificar estas contribuciones t\u00f3xicas, podr\u00edamos tener una Internet m\u00e1s segura y colaborativa.\n\n- \"Descargo de responsabilidad\": el conjunto de datos de este concurso contiene texto que puede considerarse profano, vulgar u ofensivo.\n\n# 2. Evaluaci\u00f3n\n- \"\u00e1rea bajo la curva ROC\" entre la probabilidad pronosticada y el objetivo observado.\n\n# 3. Datos\n- `comment_text`: Contiene el texto de un comentario que ha sido clasificado como t\u00f3xico o no t\u00f3xico (0 ... 1 en la columna de t\u00f3xicos). Los comentarios del conjunto de datos est\u00e1n completamente en ingl\u00e9s y provienen de Civil Comments o de ediciones de la p\u00e1gina de discusi\u00f3n de Wikipedia.\n\n- \u00bfQu\u00e9 estoy prediciendo?\n> Est\u00e1 prediciendo la probabilidad de que un comentario sea t\u00f3xico. Un comentario t\u00f3xico recibir\u00eda un 1.0. Un comentario benigno y no t\u00f3xico recibir\u00eda un 0,0. En el conjunto de prueba, todos los comentarios se clasifican como 1.0 o 0.0.","803928da":"# Data Preprocessing"}}