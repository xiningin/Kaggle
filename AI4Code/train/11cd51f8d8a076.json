{"cell_type":{"cf7aee15":"code","21b32e70":"code","8caeb19b":"code","0c656fa1":"code","cc31f27f":"code","e138575d":"code","c34fa835":"code","ab910fb8":"code","858036c6":"code","8ed8c592":"code","aa61b295":"code","84b9a7da":"code","7d032e2a":"code","83d7105b":"code","a8e1a3c7":"code","bffb3595":"code","29c06be8":"code","81f625fd":"code","7bbf1cf8":"code","7c6f649e":"code","b48ce69d":"code","a4c4f4f1":"code","10dd535a":"code","73ec885f":"code","998fdcd6":"code","2f5c612b":"code","4fa0c405":"code","7dba3cb6":"code","82c478fb":"code","a1cc9785":"code","b80550f2":"code","1f39ab5d":"markdown","34e89cc4":"markdown","d60a7a16":"markdown","b39aa82e":"markdown"},"source":{"cf7aee15":"import torch.nn as nn\nimport os\nimport torch\nimport torchvision\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom torch.utils.data.dataloader import DataLoader","21b32e70":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\ndevice","8caeb19b":"import pandas as pd \nimport numpy as np\n\n# Dataset Transformation Class\nclass MNISTDataset:\n    def __init__(self, data_path, transforms = None):\n        self.data = pd.read_csv(data_path)\n        print('Dataset Shape is : ',self.data.shape)\n        self.transform = transforms\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        # Checking if Transform is null or not\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n\nclass ToTensor:\n    def __call__(self, image):\n        return torch.from_numpy(image)\n\n    \n# Apply Transformation on the Train and Test Data\ntransforms = torchvision.transforms.ToTensor()\n\n# Loading the Training and Test Dataset\ntrain_data = MNISTDataset('..\/input\/digit-recognizer\/train.csv', transforms = transforms)","0c656fa1":"# Checking the Size of the Datasets\nprint(len(train_data))\nsample = train_data[0]\nimg, label = sample\nprint(type(img), type(label))\nprint('Image Size : ', img.size())","cc31f27f":"# Generating the seed in order to remove Randomization\n\ntorch.manual_seed(43)","e138575d":"# Creating Validation and Training Split\n\nval_size = 5000\ntrain_size = len(train_data) - val_size\n\ntraindata, valdata = random_split(train_data, [train_size, val_size])\nprint(len(traindata), len(valdata))","c34fa835":"# Creating Batches of Training Data\n\ntrain_loader = DataLoader(traindata, batch_size = 128, shuffle = True, num_workers = 4, pin_memory = True)\nval_loader = DataLoader(valdata, batch_size = 128, shuffle = True, num_workers = 4, pin_memory = True)\n\ntrain_iter = iter(train_loader)\nimgs, labels = train_iter.next()\nprint('Batch Images Size is : ',imgs.size())\nprint('Batch Labels Size is : ',labels.size())","ab910fb8":"# Visualizing batch of Training Images using make_grid\n\nfor images, labels in train_loader:\n    plt.figure(figsize = (16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow = 16).permute((1,2,0)))\n    break","858036c6":"# Committing upto this point into the Jovian\n!pip install jovian --upgrade -q\nimport jovian\nproject_name = 'digit_recognizer_feed_forward'\njovian.commit(project = project_name)","8ed8c592":"# Logging the necessary info\njovian.log_dataset(dataset_url = 'https:\/\/www.kaggle.com\/c\/digit-recognizer\/data', val_size = val_size, random_seed = 43)","aa61b295":"def accuracy_function(preds, labels):\n    _, indices = torch.max(preds, dim = 1)\n    return torch.tensor(torch.sum(indices == labels).item() \/ len(labels))\n\ndef predict(preds):\n    \n    return indices\n\nclass NNBaseClass(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_size, hidden_size1),\n            nn.ReLU(),\n            nn.Linear(hidden_size1, hidden_size2),\n            nn.ReLU(),\n            nn.Linear(hidden_size2, output_size))\n        \n    def forward(self, X):\n        X = X.view(X.size(0), -1)\n        return self.network(X)\n    \n    def prediction(self, batch):\n        img, labels = batch\n        # Moving batches into the Device\n        img = img.to(device)\n        labels = labels.to(device)\n        outputs = self.forward(img)\n        _, indices = torch.max(outputs, dim = 1)\n        return indices\n    \n    \n    def training_batch(self, batch):\n        img, labels = batch\n        # Moving batches into the Device\n        img = img.to(device)\n        labels = labels.to(device)\n        outputs = self.forward(img)\n        loss = F.cross_entropy(outputs, labels)\n        return loss\n    \n    def validating_batch(self, batch):\n        img, labels = batch\n        # Moving batches into the Device\n        img = img.to(device)\n        labels = labels.to(device)\n        outputs = self.forward(img)\n        loss = F.cross_entropy(outputs, labels)\n        acc = accuracy_function(outputs, labels)\n        return {'val_loss': loss, 'val_acc': acc}\n    \n    def validation_log(self, val_dict):\n        # Extracting Loss and Accuracy from the Val_Dict\n        losses = [x['val_loss'] for x in val_dict]\n        accuracies = [x['val_acc'] for x in val_dict]\n        mean_loss  = torch.stack(losses).mean()\n        mean_acc   = torch.stack(accuracies).mean()\n        return {'val_batch_loss': mean_loss.item(), 'val_batch_acc': mean_acc.item()}\n\n    def epoch_log(self,curr_epoch, total_epochs, model_dict):\n        print(f\"Epoch : [{curr_epoch}\/{total_epochs}], Training Loss : {model_dict['train_batch_loss']}, Val Loss : {model_dict['val_batch_loss']}, Val Acc : {model_dict['val_batch_acc']}\")\n        ","84b9a7da":"# Hyperparameters Setting\ninput_size = 784\nhidden_size1 = 40\nhidden_size2 = 30\noutput_size = 10\n\nmodel = NNBaseClass(input_size, hidden_size1, hidden_size2, output_size).to(device)\n\nlr = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr = lr)","7d032e2a":"# Inspecting the parameters of the Model\nfor params in model.parameters():\n    print(params.shape)","83d7105b":"# Doing the initial prediction from the randomly initialize model\nfor images, labels in train_loader:\n    images = images.to(device)\n    labels = labels.to(device)\n    outputs = model.forward(images)\n    loss = F.cross_entropy(outputs, labels)\n    acc = accuracy_function(outputs, labels)\n    break\nprint('Loss of the Batch is : ',loss.item())\nprint('Accuracy of the Batch is : ', acc.item())\nprint('Outputs Tensor is : ', outputs[:2].data)","a8e1a3c7":"# Committing and Logging into Jovian\n\njovian.reset()\njovian.log_hyperparams({\n    'num_epochs': 20,\n    'batch_size': 128,\n    'lr': lr\n})\n\njovian.commit(project = project_name)","bffb3595":"@torch.no_grad()\ndef Evaluate_Func(model, val_loader1):\n    logs = [model.validating_batch(batch) for batch in val_loader1]\n    return model.validation_log(logs)\n\ndef Training_Func(model, num_epochs, train_loader, val_loader, optimizer):\n    history = []\n    for epoch in range(num_epochs):\n        train_history = []\n        for batch in train_loader:\n            loss = model.training_batch(batch)\n            train_history.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        with torch.no_grad():   \n            result = Evaluate_Func(model, val_loader)\n            result['train_batch_loss'] = torch.stack(train_history).mean().item()\n            model.epoch_log(epoch, num_epochs, result)\n            history.append(result)\n    return history","29c06be8":"result = [Evaluate_Func(model, val_loader)]\nresult","81f625fd":"num_epochs = 20\nhistory = Training_Func(model, num_epochs, train_loader, val_loader, optimizer)","7bbf1cf8":"# Validation Accuracy\n\nacc = [x['val_batch_acc'] for x in history]\nplt.plot(acc, '-rx')\nplt.xlabel('Number of Epochs')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Acc w.r.t Epochs')","7c6f649e":"# Train Loss Vs Validation Loss\n\ntrain_loss = [x['train_batch_loss'] for x in history]\nval_loss   = [x['val_batch_loss'] for x in history]\nplt.plot(train_loss, '-bx')\nplt.plot(val_loss, '-rx')\nplt.xlabel('Number of Epochs')\nplt.ylabel('Loss')\nplt.title('Loss w.r.t Epochs')","b48ce69d":"jovian.log_metrics(train_loss=history[-1]['train_batch_loss'], \n                   val_loss=history[-1]['val_batch_loss'], \n                   val_acc=history[-1]['val_batch_acc'])\njovian.commit(project = project_name)","a4c4f4f1":"# Test Dataset Transformation Class\nclass TestMNISTDataset:\n    def __init__(self, data_path, transforms = None):\n        self.data = pd.read_csv(data_path)\n        print('Dataset Shape is : ',self.data.shape)\n        self.transform = transforms\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index,:].values.astype(np.uint8).reshape((28, 28, 1))\n        \n        # Checking if Transform is null or not\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n    \nclass ToTensor:\n    def __call__(self, image):\n        return torch.from_numpy(image)\n\n\ntest_data = TestMNISTDataset('..\/input\/digit-recognizer\/test.csv', transforms = transforms)","10dd535a":"# Checking the Size of the Datasets\n\nprint(len(test_data))\nsample = test_data[0]\nimg, label = sample\nprint(type(img), type(label))\nprint('Image Size : ', img.size())","73ec885f":"test_loader = DataLoader(test_data, batch_size = 128, num_workers = 4, pin_memory = True)\ntest_iter = iter(test_loader)\nimgs, labels = test_iter.next()\nprint(imgs.size(), labels.size())","998fdcd6":"# Testing TEST DATA \nindices = []\nfor batch in test_loader:\n    outputs = model.prediction(batch)\n    indices.append(outputs)","2f5c612b":"Label = [] \nfor i in range(len(indices)):\n    for j in indices[i]:\n        Label.append(j.item())\nlen(Label)","4fa0c405":"# Writing the Submission.csv File\nsample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsample_submission = sample_submission.drop([\"Label\"], axis=1) \nsample_submission.insert(1,'Label',Label)","7dba3cb6":"sample_submission.head(10)","82c478fb":"sample_submission.to_csv('Digit_Recognizer_Submission.csv', index = False)","a1cc9785":"# Model Checkpoint Saving\n\ncheckpoint = {'model_state_dict':model.state_dict(), 'optimizer.state_dict':optimizer.state_dict()}\nFILE = 'MNIST_CHECKPOINT.pth'\ntorch.save(checkpoint, FILE)","b80550f2":"# Commiting the Code to Jovian \n\njovian.commit(project =  project_name, environment = None, outputs = [checkpoint])","1f39ab5d":"# Training Loop","34e89cc4":"# Handling Test Data ","d60a7a16":"# MODEL RELATED FUNCTIONS","b39aa82e":"# Plotting the Results of the Training"}}