{"cell_type":{"003ecd90":"code","69462d7e":"code","4aa51e17":"code","9dd064d7":"code","6d264390":"code","2cd7eef1":"code","86d5bfe0":"code","d60f2734":"code","7ca399b0":"code","449d23b6":"code","8d4c85a8":"code","5f6fc15a":"code","c8899aa4":"code","0c578746":"code","b85a83c7":"code","f02930f6":"code","5b3c931e":"code","24b83c8b":"code","7dfa6fdd":"code","9f8650e5":"code","d6f57344":"code","a7a26b40":"code","682f9bb4":"code","aa74c53a":"code","a3e217c7":"code","050d3a23":"code","c2657274":"code","6e028225":"code","91fb2791":"code","ab4e2aa2":"code","05f9b7c8":"code","eeec4523":"code","82bde50a":"code","72a56566":"code","a468aa6b":"code","9d5947e8":"code","425aa66e":"markdown","c2baf2f3":"markdown","69eb00d5":"markdown","c9dd0cfc":"markdown","a2d2159c":"markdown","348ba342":"markdown","57ffb8dd":"markdown","00f03281":"markdown","b5f10b89":"markdown","0ffbc084":"markdown","eac7c265":"markdown","f241c9aa":"markdown","4bd41b22":"markdown","fde43373":"markdown","b8fbff6c":"markdown","8284c9a4":"markdown","26af13d6":"markdown","c534d74d":"markdown","6d80d09e":"markdown","7b8d3ae2":"markdown","b5aca1b6":"markdown","74bbda59":"markdown","b5c0aacd":"markdown","f22dd66e":"markdown","65098ed2":"markdown","6544414b":"markdown"},"source":{"003ecd90":"# modules to handle data\nimport pandas as pd\n\n\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","69462d7e":"train_df.head()","4aa51e17":"test_df.head()","9dd064d7":"train_df.describe()","6d264390":"test_df.describe()","2cd7eef1":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Relation between PassengerId and Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'PassengerId', bins=20)","86d5bfe0":"#Relation between Pclass e Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Pclass', bins=5)","d60f2734":"#Relation between Age e Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=5)","7ca399b0":"#Relation between SibSp e Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'SibSp', bins=5)","449d23b6":"#Relation between Parch e Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Parch', bins=5)","8d4c85a8":"#Relation between Fare e Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Fare', bins=5)","5f6fc15a":"#Stores the PassengerId Column of Test to be used in the submission\npassengerId = test_df.PassengerId\n\ntrain_df = train_df.drop('PassengerId', axis = 1)\ntest_df = test_df.drop('PassengerId', axis = 1)","c8899aa4":"train_df['Name'].describe()","0c578746":"train_df['Title'] = train_df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\ntrain_df['Title'].value_counts()","b85a83c7":"norm_titles = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n}\n\n\n\ntrain_df.Title = train_df.Title.map(norm_titles)\n\ntrain_df.Title.value_counts()","f02930f6":"#Checking  Age mean Grouping Sex and Title.\ntrain_grouped = train_df.groupby(['Sex','Title','Pclass'])\ntrain_grouped.Age.mean()","5b3c931e":"#Applying the mean values of the Sex\/Title\/Pclass group to the empty values of Age.\ntrain_df.Age = train_grouped.Age.apply(lambda x: x.fillna(x.mean()))","24b83c8b":"#Checking how many null values \u200b\u200bthere are in Age (Expected Value = 0)\ntrain_df.Age.isnull().sum()","7dfa6fdd":"#Let's do the same with the test set\n\ntest_df['Title'] = test_df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\ntest_df.Title = test_df.Title.map(norm_titles)\ntest_grouped = test_df.groupby(['Sex','Title','Pclass'])\ntest_df.Age = test_grouped.Age.apply(lambda x: x.fillna(x.mean()))\ntest_df.Age.isnull().sum()\n\ntest_df.Title.value_counts()","9f8650e5":"\n# find most frequent Embarked value and store in variable\nmost_embarked = train_df.Embarked.value_counts().index[0]\n\n# fill NaN with most_embarked value\ntrain_df.Embarked = train_df.Embarked.fillna(most_embarked)\n# fill NaN with median fare\ntrain_df.Fare = train_df.Fare.fillna(train_df.Fare.median())\n\ntrain_df.Cabin = train_df.Cabin.fillna('U')\ntrain_df.Cabin = train_df.Cabin.map(lambda x: x[0])\ntrain_df['Cabin'] = train_df.Cabin.replace({'T': 'G'})\ntrain_df.Cabin.value_counts()\n","d6f57344":"#Doing the same with Test data\n\n# fill Cabin NaN with U for unknown\ntest_df.Cabin = test_df.Cabin.fillna('U')\n# find most frequent Embarked value and store in variable\nmost_embarked = test_df.Embarked.value_counts().index[0]\n\n# fill NaN with most_embarked value\ntest_df.Embarked = test_df.Embarked.fillna(most_embarked)\n# fill NaN with median fare\ntest_df.Fare = test_df.Fare.fillna(train_df.Fare.median())\n\n#O M\u00e1ximo que d\u00e1 para fazer com a coluna Cabin por hora \u00e9 isolar a primeira letra e agrup\u00e1-la\ntest_df['Cabin'] = test_df.Cabin.apply(lambda name: name[0])\ntest_df.Cabin.value_counts()","a7a26b40":"train_df['FamilySize'] = train_df.Parch + train_df.SibSp + 1\ntrain_df['FamilySize'].describe()","682f9bb4":"#Relation between Family and Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'FamilySize', bins=20)","aa74c53a":"#Now for Test\ntest_df['FamilySize'] = test_df.Parch + test_df.SibSp + 1\ntest_df['FamilySize'].describe()","a3e217c7":"# TRAIN\ntrain_df.Sex = train_df.Sex.map({\"male\": 0, \"female\":1})\n# create dummy variables for categorical features\npclass_dummies = pd.get_dummies(train_df.Pclass, prefix=\"Pclass\")\ntitle_dummies = pd.get_dummies(train_df.Title, prefix=\"Title\")\ncabin_dummies = pd.get_dummies(train_df.Cabin, prefix=\"Cabin\")\nembarked_dummies = pd.get_dummies(train_df.Embarked, prefix=\"Embarked\")\n# concatenate dummy columns with main dataset\ntrain_dummies = pd.concat([train_df, pclass_dummies, title_dummies, cabin_dummies, embarked_dummies], axis=1)\n\n# drop categorical fields\ntrain_dummies.drop(['Pclass', 'Title', 'Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n\ntrain_dummies.head()","050d3a23":"train_dummies.columns","c2657274":"len(train_dummies.columns)","6e028225":"# TEST\ntest_df.Sex = test_df.Sex.map({\"male\": 0, \"female\":1})\n# create dummy variables for categorical features\npclass_dummies = pd.get_dummies(test_df.Pclass, prefix=\"Pclass\")\ntitle_dummies = pd.get_dummies(test_df.Title, prefix=\"Title\")\ncabin_dummies = pd.get_dummies(test_df.Cabin, prefix=\"Cabin\")\nembarked_dummies = pd.get_dummies(test_df.Embarked, prefix=\"Embarked\")\n# concatenate dummy columns with main dataset\ntest_dummies = pd.concat([test_df, pclass_dummies, title_dummies, cabin_dummies, embarked_dummies], axis=1)\n\n# drop categorical fields\ntest_dummies.drop(['Pclass', 'Title', 'Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n\ntest_dummies.head()\n","91fb2791":"test_dummies.columns","ab4e2aa2":"len(test_dummies.columns)","05f9b7c8":"test_dummies.columns","eeec4523":"train_dummies.columns","82bde50a":"import operator\nimport math\nimport random\n\nimport numpy as np\n\nfrom deap import algorithms\nfrom deap import base\nfrom deap import creator\nfrom deap import tools\nfrom deap import gp","72a56566":"def mydeap(mungedtrain, epochs): \n    \n    inputs = mungedtrain.drop('Survived', axis = 1).values.tolist()\n    outputs = mungedtrain['Survived'].values.tolist()\n    \n    # Define new functions\n    def protectedDiv(left, right):\n        try:\n            return left \/ right\n        except ZeroDivisionError:\n            return 1\n    \n    pset = gp.PrimitiveSet(\"MAIN\", 26) # eight input\n    pset.addPrimitive(operator.add, 2)\n    pset.addPrimitive(operator.sub, 2)\n    pset.addPrimitive(operator.mul, 2)\n    pset.addPrimitive(protectedDiv, 2)\n    pset.addPrimitive(operator.neg, 1)\n    pset.addPrimitive(math.cos, 1)\n    pset.addPrimitive(math.sin, 1)\n    pset.addPrimitive(max, 2)\n    pset.addPrimitive(min, 2) # add more?\n    pset.renameArguments(ARG0='x1')\n    pset.renameArguments(ARG1='x2')\n    pset.renameArguments(ARG2='x3')\n    pset.renameArguments(ARG3='x4')\n    pset.renameArguments(ARG4='x5')\n    pset.renameArguments(ARG5='x6')\n    pset.renameArguments(ARG6='x7')\n    pset.renameArguments(ARG7='x8')\n    pset.renameArguments(ARG8='x9')\n    pset.renameArguments(ARG9='x10')\n    pset.renameArguments(ARG10='x11')\n    pset.renameArguments(ARG11='x12')\n    pset.renameArguments(ARG12='x13')\n    pset.renameArguments(ARG13='x14')\n    pset.renameArguments(ARG14='x15')\n    pset.renameArguments(ARG15='x16')\n    pset.renameArguments(ARG16='x17')\n    pset.renameArguments(ARG17='x18')\n    pset.renameArguments(ARG18='x19')\n    pset.renameArguments(ARG19='x20')\n    pset.renameArguments(ARG20='x21')\n    pset.renameArguments(ARG21='x22')\n    pset.renameArguments(ARG22='x23')\n    pset.renameArguments(ARG23='x24')\n    pset.renameArguments(ARG24='x25')\n    pset.renameArguments(ARG25='x26')\n    \n    creator.create(\"FitnessMin\", base.Fitness, weights=(1.0,))\n    creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n    \n    toolbox = base.Toolbox()\n    toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3) #\n    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n    toolbox.register(\"compile\", gp.compile, pset=pset)\n    \n    def evalSymbReg(individual):\n        # Transform the tree expression in a callable function\n        func = toolbox.compile(expr=individual)\n        # Evaluate the accuracy\n        return sum(round(1.-(1.\/(1.+np.exp(-func(*in_))))) == out for in_, out in zip(inputs, outputs))\/len(mungedtrain),\n    \n    toolbox.register(\"evaluate\", evalSymbReg)\n    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n    toolbox.register(\"mate\", gp.cxOnePoint)\n    toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n    toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n    \n    toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n    toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n    \n    random.seed(318)\n    \n    pop = toolbox.population(n=300) #\n    hof = tools.HallOfFame(1)\n    \n    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n    stats_size = tools.Statistics(len)\n    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n    mstats.register(\"avg\", np.mean)\n    mstats.register(\"std\", np.std)\n    mstats.register(\"min\", np.min)\n    mstats.register(\"max\", np.max)\n    \n    pop, log = algorithms.eaSimple(pop, toolbox, 0.5, 0.2, epochs, stats=mstats,\n                                   halloffame=hof, verbose=True) #\n    \n    print(hof[0])\n    func2 =toolbox.compile(expr=hof[0])\n    return func2","a468aa6b":"def Outputs(data):\n    return np.round(1.-(1.\/(1.+np.exp(-data))))","9d5947e8":"\n#Main Function\nif __name__ == \"__main__\":\n    train = train_dummies\n    test = test_dummies.columns\n    \n    #passengerId = test.PassengerId.astype(int)\n    #mungedtrain = MungeData(train)\n    mungedtrain = train_dummies.astype(float) #PreProcessing(train)\n    \n    #Genetic Programing \n    GeneticFunction = mydeap(mungedtrain, epochs = 100)\n    \n    #test\n    #mytrain = mungedtrain.iloc[:,2:10].values.tolist()\n    mytrain = mungedtrain.drop('Survived', axis = 1).values.tolist()\n    \n    trainPredictions = Outputs(np.array([GeneticFunction(*x) for x in mytrain]))\n\n    from sklearn.metrics import accuracy_score\n    print(accuracy_score(mungedtrain.Survived.astype(int),trainPredictions.astype(int)))\n    \n    #mungedtest = MungeData(test)\n    mungedtest = test_dummies.astype(float) #PreProcessing(test)\n    #mytest = mungedtest.iloc[:,1:9].values.tolist()\n    mytest = mungedtest.values.tolist()\n     \n    testPredictions = Outputs(np.array([GeneticFunction(*x) for x in mytest]))\n\n    pdtest = pd.DataFrame({'PassengerId': passengerId,\n                            'Survived': testPredictions.astype(int)})\n    pdtest.to_csv('gptest.csv', index=False)","425aa66e":"Now let's replace all null values in the Age column with average values extracted from the grouping of the Title column. For example, all Age values will be 21.8 when Sex is Female and the Title is \"Miss.\" Note that this is more powerful than just changing Age to an average value of the Age column.","c2baf2f3":"<a id=\"id4\"><\/a> <br> \n# **4. Data Pre-processing** \n\n","69eb00d5":"Let's graphically check if there is a correlation between the assignments and the target class.","c9dd0cfc":"<h3>Extracting Valuable Information<\/h3>\n\n","a2d2159c":"<h3>Name Attribute<\/h3>\n\nIn a first analysis, we may find that the Name column is not an important attribute for the model. If we analyze the variability of the attribute this can be confirmed. ","348ba342":"<h2> Atributes: Cabin, Embarked e Fare<\/h2>","57ffb8dd":"We found that there is a good correlation between FamilySize and Survived","00f03281":"<h2> Creating a New Feature: FamilySize <\/h2>\nAccording to the description of the problem the family relationship is described as follows. SibSp: Defines whether the person had brother, Sibling = brothers, sisters, may brother, half sister Spouse = husband, wife (lover or bride were ignored)\n\nParch: Parent = mother, father Child = daughter, son, stepdaughter, stepchild some children traveled with the nanny, in this case, the parch = 0\n\nThus, a good way to represent the data is to create a feature called family that involves Parch and SibSp","b5f10b89":"\nIt is noticed that there are 517 entries of the type 'Mr', 182 of type 'Miss', 125 of type 'Mrs', 40 of type 'Master' and a few of other types. So that there is not so much variability we will replace some names with others.\n\n* \"Capt\": \"Officer\",\n* \"Col\": \"Officer\",\n* \"Major\": \"Officer\",\n* \"Jonkheer\": \"Royalty\",\n* \"Don\": \"Royalty\",\n* \"Sir\" : \"Royalty\",\n* \"Dr\": \"Officer\",\n* \"Rev\": \"Officer\",\n* \"the Countess\":\"Royalty\",\n* \"Dona\": \"Royalty\",\n* \"Mme\": \"Mrs\",\n* \"Mlle\": \"Miss\",\n* \"Ms\": \"Mrs\",\n* \"Mr\" : \"Mr\",\n* \"Mrs\" : \"Mrs\",\n* \"Miss\" : \"Miss\",\n* \"Master\" : \"Master\",\n* \"Lady\" : \"Royalty\"\n","0ffbc084":"<img src=\"https:\/\/deap.readthedocs.io\/en\/master\/_images\/deap_long.png\" width=30% \/>\n**DEAP** is a novel evolutionary computation framework for rapid prototyping and testing of ideas. It seeks to make algorithms explicit and data structures transparent. It works in perfect harmony with parallelisation mechanism such as multiprocessing and SCOOP.\n\n\nCheck the library's documentation through the following link: https:\/\/deap.readthedocs.io\/","eac7c265":"<h3>Data Dictionary<\/h3><br>\n\n<b>survival<\/b>\tSurvival\t0 = No, 1 = Yes<br>\n<b>pclass<\/b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex<\/b>\tSex\t<br>\n<b>Age<\/b>\tAge in years\t<br>\n<b>sibsp<\/b>\t# of siblings \/ spouses aboard the Titanic\t<br>\n<b>parch<\/b>\t# of parents \/ children aboard the Titanic\t<br>\n<b>ticket<\/b>\tTicket number\t<br>\n<b>fare<\/b>\tPassenger fare\t<br>\n<b>cabin<\/b>\tCabin number\t<br>\n<b>embarked\t<\/b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Variable Notes<\/h3><br>\n<b>pclass: <\/b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: <\/b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:<\/b> The dataset defines family relations in this way...<br>\n- <b>Sibling <\/b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse <\/b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: <\/b>The dataset defines family relations in this way...<br>\n- <b>Parent<\/b> = mother, father<br>\n- <b>Child <\/b>= daughter, son, stepdaughter, stepson<br>\n\nSome children travelled only with a nanny, therefore parch=0 for them.<br>","f241c9aa":"After checking the histograms of **PassengerId**, **Age**, **Pclass**, **SibSp**, **Parch** and **Fare** we can verify a certain correlation between them and the Survived column , except for PassengerId, where the value of Survived is not influenced by the increase or decrease of PassengerId\n\n\nFor this reason, we will delete the PassengerId column, but before we need to store it in a variable to be used later in the submission.","4bd41b22":"\n<h1 style=\"color:red\">Please, votes up if you like this Kernel.<\/h1>","fde43373":"<a id=\"ref\"><\/a> <br> \n# **6. References** \n* https:\/\/deap.readthedocs.io\/en\/0.7-0\/examples\/onemax.html\n* https:\/\/www.kaggle.com\/adrianoavelar\/model-thats-breaks-0-8-score-for-titanic-problem\n* https:\/\/towardsdatascience.com\/introduction-to-genetic-algorithms-including-example-code-e396e98d8bf3","b8fbff6c":"\nThere are 891 Records and all are unique, ie there is no way to group the values of **\"Name\"** into classes of Survivors and Non Survivors. However, there is the possibility of using name titles to create subgroups, such as Mr, Miss or Mrs etc ...\n\nFirst let's separate the texts from the Name column using the \",\" tab of the '.' Tab. Thus, the name \"Cumings, Mrs. John Bradley (Florence Briggs Th ...\" will be transformed into \"Mrs.\" The result is placed in a new column named \"Title\"","8284c9a4":"<a id=\"id2\"><\/a> <br> \n# **2. Get the Data (Collect \/ Obtain):** \nThe first step in any problem is to collect the data. In most Kaggle problems, data is already provided, in which case there is no need for collection. Access the link to know more about the available data: https:\/\/www.kaggle.com\/c\/titanic\/data","26af13d6":"<a id=\"id1\"><\/a> <br> \n# **1. Problem Definition:** \n\nOn April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n<h3> The data have 891 entries on train dataset and 418 on test dataset<\/h3>\n- 10 columns in train_csv and 9 columns in train_test\n","c534d74d":"<h3>Age Attribute: Filling Null Values<\/h3>\n\n\nNow, we can see that the Title column is beginning to say more about who survived. Now, we can use this field to estimate the age of crew members who have empty or null values","6d80d09e":"<a id=\"id3\"><\/a> <br> \n# **3. Load the Dataset** \n\nIn this step, the goal is to verify that the data is being loaded correctly, check the number and name of the columns, and get some information about the problem data.","7b8d3ae2":"Create the main GA function\n","b5aca1b6":"**NOTE ABOUT THIS KERNEL**\nI wrote this kernel because I did not find any that explained how to implement a solution for TITANIC using genetic algorithm. This kernel is still in development and needs several tweaks. Please post in the comments if you have any questions or suggestions for this kernel. Thank you very much in advance.\n\n<h1 style=\"color:red\">Please, votes up if you like this Kernel.<\/h1>\n","74bbda59":"<h1> Resolving Titanic with Evolutionary Algorithm <\/h1>\n<h2>This kernel will provide a analysis through the Titanic Disaster to understand the Survivors patterns and will provide a solution based in Evolutionary Algorithm <\/h2><br>\n\nThe Kernel handles with data (<i>transform, missings, manipulation<\/i>), explore the data (<i>descritive and visual<\/i>) and also create a Deep Learning model using GA with **DEAP library**","b5c0aacd":"<a id=\"id5\"><\/a> <br> \n# **5. Model** \n\n","f22dd66e":"<h2>Genetic Algorithm with DEAP<\/h2>\n\nWe will implement a GA with DEAP so the first step is to import the libraries.\n","65098ed2":"# Table of Contents:\n\n**1. [Problem Definition](#id1)** <br>\n**2. [Get the Data (Collect \/ Obtain)](#id2)** <br>\n**3. [Load the Dataset](#id3)** <br>\n**4. [Data Pre-processing](#id4)** <br>\n**5. [Model with Genetic Algorithm](#id5)** <br>\n**6. [Visualization and Analysis of Results](#id6)** <br>\n**7. [Submittion](#id7)** <br>\n**8. [References](#ref)** <br>\n","6544414b":"<h3>Math doens't like Letters<\/h3>\n\nMathematical models do not get along well with letters. So we need to turn all categorical columns into numeric columns. We could do this with LabelEncoder, but there is a more advanced technique called OneEncoder and it can be applied quite simply with the Pandas get_dummies method.\n"}}