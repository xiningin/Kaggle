{"cell_type":{"6c15abc9":"code","8bd706de":"code","260b71bc":"code","34130a97":"code","2b136432":"code","a37c2b3b":"code","c9ae4837":"code","0f4975b7":"code","a6086fab":"code","89ff9272":"code","57e92254":"code","5dbd8c8b":"code","38359f05":"code","9201deb8":"code","5baae9ac":"code","c036205f":"code","6edc6bcd":"code","7e1d1076":"code","5bf72765":"code","c0d6848e":"code","e3c8aff1":"code","9f86bb51":"code","a7c2898b":"code","ba1a29dd":"code","14628f0a":"markdown","8d68e513":"markdown","e0d92b28":"markdown","470fa993":"markdown","32775ec0":"markdown","8defd90d":"markdown"},"source":{"6c15abc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8bd706de":"#Firstly, read data from csv file.\ndataset = pd.read_csv('..\/input\/international-airline-passengers.csv',skipfooter=5)","260b71bc":"dataset.info()","34130a97":"dataset.head()","2b136432":"dataset.tail(10)","a37c2b3b":"dataset.describe()","c9ae4837":"# We only use Number of Passengers in this project. Therefore, we create a new data named as 'data' and\n# assign to just passenger number to this new smaller data.\ndata = dataset.iloc[:,1].values","0f4975b7":"# Let's take a look our new data.\nplt.plot(data)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Passengers\")\nplt.title(\"International Airline Passengers\")\nplt.show()","a6086fab":"# Let's look at the shape of data.\ndata.shape","89ff9272":"# As you can see; shape of data is (142,). We should reshape it.\ndata =data.reshape(-1,1)\ndata.astype(\"float32\")\ndata.shape","57e92254":"# After reshaping, we should scale all of datas between 0 and 1.\nfrom sklearn.preprocessing import MinMaxScaler #import scling library\nscaler = MinMaxScaler(feature_range=(0,1))\ndata_scaled = scaler.fit_transform(data)","5dbd8c8b":"# Let's check our data!\ndata_scaled\n# As you can see, we scaled our values!","38359f05":"train_data_size = int(len(data_scaled)*0.50)\ntest_data_size = len(data_scaled) - train_data_size\nprint(\"Train data size is {}\".format(train_data_size))\nprint(\"Test data size is {}\".format(test_data_size))","9201deb8":"train = data_scaled[0:train_data_size,:]\ntest = data_scaled[train_data_size:len(data_scaled),:]\n# Let's check number of train and test datas again\nprint(\"Train data size is {}\".format(len(train)))\nprint(\"Test data size is {}\".format(len(test)))","5baae9ac":"x_train = []\ny_train = []\ntime_steps=10\nfor i in range(len(train)-time_steps-1):\n    a = train[i:(i+time_steps),0]\n    x_train.append(a)\n    y_train.append(train[i + time_steps,0])\ntrainX = np.array(x_train)\ntrainY = np.array(y_train)","c036205f":"trainX.shape","6edc6bcd":"x_test = []\ny_test = []\nfor i in range(len(test)-time_steps-1):\n    a = test[i:(i+time_steps),0]\n    x_test.append(a)\n    y_test.append(test[i + time_steps,0])\ntestX = np.array(x_test)\ntestY = np.array(y_test)","7e1d1076":"testX.shape","5bf72765":"# Let's reshape trainX and testX\ntrainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1],1))\ntestX = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n# Print and check shapes\nprint(\"Shape of trainX is {}\".format(trainX.shape))\nprint(\"Shape of testX is {}\".format(testX.shape))","c0d6848e":"# Firstly, define libraries\nfrom keras.layers import Dense, SimpleRNN, Dropout\nfrom keras.metrics import mean_squared_error\nfrom keras.models import Sequential","e3c8aff1":"# Initializing RNN\nmodel = Sequential()\n# Add the first layer and Dropout regularization\nmodel.add(SimpleRNN(units=100,activation='tanh',return_sequences=True, \n                    input_shape=(trainX.shape[1],1)))\nmodel.add(Dropout(0.20))\n# Second layer and Dropout regularization\nmodel.add(SimpleRNN(units = 100, activation='tanh',return_sequences=True))\nmodel.add(Dropout(0.20))\n# Third layer and Dropout regularization\nmodel.add(SimpleRNN(units = 70, activation='tanh', return_sequences= True))\nmodel.add(Dropout(0.20))\n# Fourth layer and Dropout regularization\nmodel.add(SimpleRNN(units = 50))\nmodel.add(Dropout(0.20))\n# Add final or output layer\nmodel.add(Dense(units=1))\n\n# Compile our RNN model\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the training set\nmodel.fit(trainX, trainY, epochs = 200, batch_size=32)\n# Remember; epochs, batch_size etc. are just some of hyper parameters. \n# You can change these parameters whatever you want","9f86bb51":"trainPrediction = model.predict(trainX)\ntestPrediction = model.predict(testX)\n\n# Remember, we scaled datas between 0 and 1 but now we're at the end of the project.\n# So we should inverse transform datas.\n\ntrainPrediction = scaler.inverse_transform(trainPrediction)\ntrainY = scaler.inverse_transform([trainY])\ntestPrediction = scaler.inverse_transform(testPrediction)\ntestY = scaler.inverse_transform([testY])","a7c2898b":"# There is some problem in there but I didn't know what is it.\n# I googled it and helps with DATAI Team found the problem :)\n# Convert tensor to numpy. Otherwise we could not sqrt values.\nimport tensorflow as tf\nsess = tf.Session()\nwith sess.as_default():\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPrediction[:,0]).eval())\n    testScore = math.sqrt(mean_squared_error(testY[0], testPrediction[:,0]).eval())\nprint(\"Train Score is %.2lf RMSE\"%(trainScore))\nprint(\"Test Score is %.2lf RMSE\"%(testScore))","ba1a29dd":"trainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_steps:len(trainPrediction)+time_steps, :] = trainPrediction\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPrediction)+(time_steps*2)+1:len(dataset)-1, :] = testPrediction\n\nplt.plot(scaler.inverse_transform(data_scaled),label = 'True Values', color='blue')\nplt.plot(trainPredictPlot,label='Train Prediction', color='red')\nplt.plot(testPredictPlot,label = 'Test Prediction', color='green')\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Passengers\")\nplt.title(\"International Airline Passengers\")\nplt.legend()\nplt.show()","14628f0a":"**and now time to train-test datas split!**","8d68e513":"**CONCLUSION**\n\nWe tried to workout on RNN with Keras library. Our predictions are not perfect but that seems enough for now :) I learned a lot of things from this project myself and I hope you did it too. Your examinations and comments are so important to me. Please, check it out and feel relax to comment me. ","e0d92b28":"**INTRODUCTION**\n\nIn th's project, we'll try to understand and exercise the RNN (Recurrent Neural Network). I decided to use 'International Airline Passengers' dataset for this workout. You'll see:\n* Data Loading and Reading\n* Data Preprocessing (Scaling, Train-Test Datas Split, Reshaping)\n* RNN with Keras\n* Predictions and Visualizations\n* Conclusion\n\nin this project.","470fa993":"**And the final mission: Predictions and Visualization!**","32775ec0":"**Time to RNN with Keras!!**","8defd90d":"Let's look at our RMSE (Root Mean Squared Error)"}}