{"cell_type":{"47724d30":"code","9e49dc42":"code","b8712d83":"code","a458f681":"code","580fe2a8":"code","c2d457bd":"code","55a10332":"code","b6747ed1":"code","5de1bad3":"code","674cabf3":"code","43989df6":"code","8c56d53b":"code","fbc85729":"code","57f441f8":"code","760066f7":"code","d7913b8c":"code","7b048ce7":"code","ac3f4206":"code","12d237aa":"code","db277ba3":"code","b8dc4692":"code","c23d5db2":"code","e2fef0a7":"code","6c623990":"code","59bf9975":"code","c8606945":"code","a4924b6b":"code","79fcfd29":"code","5c7b4465":"code","c3300977":"code","2ceda26e":"code","a13c1aa2":"code","86fbcbac":"code","845e6b05":"code","d169078f":"code","d5520917":"code","627f7fdd":"code","19cd9e48":"code","b094dcf9":"code","51984572":"code","07543b02":"code","42228059":"code","355750b8":"code","dca7319d":"code","f9a076da":"code","17d9dcdd":"code","631c72f8":"code","d33e78a6":"code","d4e52521":"code","ab7f6aaa":"code","6af00c08":"code","71d1bd6c":"code","49337d44":"code","524398b3":"code","97332b80":"code","c21dfd3d":"markdown","9366ac4c":"markdown","fffe9f6e":"markdown","b570bf44":"markdown","96d9aaba":"markdown","2c7592f3":"markdown","04b1dc1f":"markdown","c5b4642a":"markdown","7140eb1b":"markdown","55a32cd7":"markdown","3b7e4119":"markdown","2250c2dd":"markdown","7c1de786":"markdown","e23179e6":"markdown","fc9607ec":"markdown","24f5c8ec":"markdown","ab2cc117":"markdown","37b4b4b4":"markdown","16885e1d":"markdown","b510e8d0":"markdown","b162fb59":"markdown","0d202000":"markdown","8e457ea1":"markdown","dd1fe531":"markdown","31c24ad7":"markdown","5ad6ae97":"markdown","4ce2e7fa":"markdown","c1d553bd":"markdown","056f9716":"markdown","c1ab49ce":"markdown","3e7add14":"markdown","9308cde2":"markdown","b426d753":"markdown","b89a748d":"markdown","058d137f":"markdown","8f134285":"markdown","9950e6b2":"markdown","f0f0bbfa":"markdown","624bda70":"markdown","d3425243":"markdown","65bf1150":"markdown","a9d017e3":"markdown","8049163b":"markdown","32a2cbde":"markdown","2409b6b6":"markdown","10d464f2":"markdown","ac21a2ac":"markdown","51b64f55":"markdown","b66c7626":"markdown","c5e2d7a7":"markdown","9c6f210c":"markdown","eeec278a":"markdown","b4616e23":"markdown","e693ea6e":"markdown","4e278ab0":"markdown","124e0dfc":"markdown","8a6fe9d2":"markdown","eab3d434":"markdown","53f0ccac":"markdown"},"source":{"47724d30":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ast import literal_eval\n%matplotlib inline\n\nfrom datetime import datetime\nimport datetime\nimport wordcloud as wc\nimport plotly\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        saving=False\n\n","9e49dc42":"df1=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')\ndf2=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')","b8712d83":"df1=df1.rename({'movie_id': 'id'},axis=1)\ndf1.columns = ['id','title2','cast','crew']\ndf2= df2.merge(df1,on='id')","a458f681":"df2.info()","580fe2a8":"df2.drop(columns=['title2'],inplace=True)\ndf2.head(5)","c2d457bd":"df2.isnull()","55a10332":"sns.heatmap(df2.isnull(),yticklabels=False,cbar=False,cmap='viridis')","b6747ed1":"df2.select_dtypes('object').nunique()","5de1bad3":"plt.figure(figsize=(25,6))\n\n\nplt.subplot(2, 3, 1)\nsns.distplot(df2['revenue'])\n\nplt.subplot(2, 3, 2)\nsns.distplot(df2['vote_count'])\n\nplt.subplot(2, 3, 3)\nsns.distplot(df2['budget'])\n\nplt.subplot(2, 3, 4)\nsns.distplot(df2['vote_average'].fillna(0).astype(int))\n\nplt.subplot(2, 3, 5)\nsns.distplot(df2['runtime'].fillna(0).astype(int))\n\nplt.subplot(2, 3, 6)\nsns.distplot(df2['popularity'].fillna(0).astype(int))\n\nplt.suptitle('Checking for Skewness', fontsize = 15)\nplt.show()","674cabf3":"pop= df2.sort_values('revenue', ascending=False)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,4))\n\nplt.barh(pop['title'].head(6),pop['revenue'].head(6), align='center',\n        color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel(\"revenue\")\nplt.title(\"revenue Movies\")\n","43989df6":"pop= df2.sort_values('popularity', ascending=False)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,4))\n\nplt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',\n        color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel(\"Popularity\")\nplt.title(\"Popular Movies\")\n","8c56d53b":"movies = df2\nmovies['spoken_languages'] = movies['spoken_languages'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n\n\ns = movies.apply(lambda x: pd.Series(x['spoken_languages']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'spoken_languages_count'\ncon_df = movies.drop('spoken_languages', axis=1).join(s)\ncon_df = pd.DataFrame(con_df['spoken_languages_count'].value_counts())\ncon_df['spoken_language'] = con_df.index\ncon_df.columns = ['num_spoken_language', 'spoken_language']\n\n","fbc85729":"con_df = con_df.reset_index().drop('index', axis=1)\ncon_df.head(100)","57f441f8":"con_df = con_df[:5]\n\nfig = plt.figure(figsize=(12,7))\nsns.barplot(data = con_df, x='spoken_language', y = 'num_spoken_language')\n\nplt.tight_layout()","760066f7":"movies = df2\nmovies['production_countries'] = movies['production_countries'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n\ns = movies.apply(lambda x: pd.Series(x['production_countries']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'countries'","d7913b8c":"con_df = movies.drop('production_countries', axis=1).join(s)\ncon_df = pd.DataFrame(con_df['countries'].value_counts())\ncon_df['country'] = con_df.index\ncon_df.columns = ['num_movies', 'country']\ncon_df = con_df.reset_index().drop('index', axis=1)\ncon_df.head(20)\n","7b048ce7":"con_df.loc[con_df.country == 'United States of America', 'num_movies'] = 700\ncon_df.head(20)\ncon_df.to_csv('mycsvfile.csv')","ac3f4206":"data = [ dict(\n        type = 'choropleth',\n        locations = con_df['country'],\n        locationmode = 'country names',\n        z = con_df['num_movies'],\n        text = con_df['country'],\n        colorscale = [[0,'rgb(255, 255, 255)'],[1,'rgb(255, 0,255)']],\n        autocolorscale = False,\n        reversescale = False,\n        marker = dict(\n            line = dict (\n                color = 'rgb(0,0,0)',\n                width = 0.5\n            ) ),\n        colorbar = dict(\n            autotick = False,\n            tickprefix = '',\n            title = 'Production Countries'),\n      ) ]\n\nlayout = dict(\n    title = 'Production Countries for the Movies (USA is being 700+ to be apple to watch other countries)',\n    geo = dict(\n        showframe = False,\n        showcoastlines = False,\n        projection = dict(\n            type = 'Mercator'\n        )\n    )\n)\n\nfig = dict( data=data, layout=layout )\npy.iplot( fig, validate=False, filename='d3-world-map' )","12d237aa":"# helper functions to deal with multi-hot features\ndef group_indices(series,index=\"id\"):\n    d={}\n    for i in range(series.size):\n        l=eval(series.iloc[i])\n        for x in l:\n            d.setdefault(x[index],[])\n            d[x[index]].append(i)\n    return d\n\ndef get_groups(series,index=\"name\"):\n    s=set()\n    for i in range(series.size):\n        l=eval(series.iloc[i])\n        for x in l:s.add(x[index])\n    return list(s)\n\ndef multi_count(series,index=\"id\"):\n    return {k:len(v) for (k,v) in group_indices(series,index).items()}\n\ndef expand_multi_feature(df,column,index=\"id\"):\n    groups=group_indices(df[column],index=index)\n    result=pd.DataFrame()\n    for name,indices in groups.items():\n        rows=df.iloc[indices].copy()\n        rows[column]=name\n        result=result.append(rows)\n    return result\n\ndef multi_groupby(df1,column,index=\"id\"):\n    return expand_multi_feature(df,column,index).groupby(column)","db277ba3":"# numbers of movies released in each decade\ndef count_pie(series,filename):\n    counts=series.value_counts()\n    counts=counts\/counts.sum()\n    labels=['' if num<0.01 else str(year) for (year,num) in counts.items()]\n    f, ax = plt.subplots(figsize=(8, 8))\n    explode = [0.02 if counts.iloc[i] < 100 else 0.001 for i in range(counts.size)]\n    plt.pie(counts,labels=labels,autopct=lambda x:'{:1.0f}%'.format(x) if x > 1 else '',explode=explode)\n    if saving:plt.savefig(filename,dpi=150)\n    plt.show()\n\ndef count_decade_pie(df,filename):\n    count_pie(df2.release_date.dropna().apply(lambda x:str(int(x[:4])\/\/10*10)+'s'),filename)\n    \ncount_decade_pie(df2,filename=\"pie_decade.png\")","b8dc4692":"# wordcloud of genres and keywords\ndef multi_wordcloud(series,filename):\n    w=wc.WordCloud(background_color=\"white\",margin=20,width=800,height=600,prefer_horizontal=0.7,max_words=50,scale=2)\n    count=multi_count(series,\"name\")\n    w.generate_from_frequencies(count)\n    if saving:w.to_file(filename)\n    f, ax = plt.subplots(figsize=(16, 8))\n    plt.axis('off')\n    plt.imshow(w)\n    plt.show()\n\nmulti_wordcloud(df2.genres,filename=\"wordcloud_genres.png\")\nmulti_wordcloud(df2.keywords,filename=\"wordcloud_genres2.png\")","c23d5db2":"# distribution of popularity and runtime groupby genres\ndef plotby_box(df,x,y,filename,yscale=\"linear\"):\n    sns.set(style=\"whitegrid\")\n    df=df.replace(0,np.nan).copy()\n    f,ax=plt.subplots(figsize=(20, 10))\n    sns.boxenplot(data=expand_multi_feature(df,x,\"name\"),x=x,y=y)\n    plt.yscale(yscale)\n    plt.yticks(fontsize=20)\n    plt.xticks(rotation=55,fontsize=20)\n    plt.xlabel(x,fontsize=30)\n    plt.ylabel(y,fontsize=30)\n    if saving:plt.savefig(filename,bbox_inches=\"tight\",dpi=150)\n    plt.show()\n    \nplotby_box(df2,\"genres\",\"popularity\",yscale=\"log\",filename=\"genres_popularity.png\")","e2fef0a7":"def plotby_bar(df,x,y,filename):\n    sns.set(style=\"whitegrid\")\n    df=df.replace(0,np.nan).copy()\n    f,ax=plt.subplots(figsize=(20, 10))\n    sns.barplot(data=expand_multi_feature(df,x,\"name\"),x=x,y=y)\n    plt.yticks(fontsize=20)\n    plt.xticks(rotation=55,fontsize=20)\n    plt.xlabel(x,fontsize=30)\n    plt.ylabel(y,fontsize=30)\n    if saving:plt.savefig(filename,bbox_inches=\"tight\",dpi=150)\n    plt.show()\n    \nplotby_bar(df2,\"genres\",\"vote_average\",filename=\"genres_vote.png\")\n","6c623990":"# Filter only votes to movies in movies metadata\nratings = pd.read_csv('..\/input\/the-movies-dataset\/ratings_small.csv')\nratings_df = ratings.merge(df2[['id']], left_on=['movieId'], right_on=['id'], how='inner')\n# add a new feature, time_dt, to ratings_df by converting timestamp to date\nratings_df['time_dt'] = ratings_df['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n# split the time_dt to year features\nratings_df['year'] = ratings_df['time_dt'].dt.year","59bf9975":"dt = ratings_df.groupby(['year'])['rating'].mean().reset_index()\nfig, (ax) = plt.subplots(ncols=1, figsize=(12,5))\nplt.plot(dt['year'],dt['rating']);\nplt.xlabel('Year');\nplt.ylabel('Average ratings');\nplt.title('Average ratings per year')\nplt.show()","c8606945":"plt.figure(figsize=(10,7))\nplt.title('Correlation Matrix')\n# mask = np.triu(np.ones_like(md.corr(), dtype=np.bool))\nsns.heatmap(df2.corr(),annot=True)\nplt.show()","a4924b6b":"df2.head()\ndf2.columns","79fcfd29":"C = df2['vote_average'].mean()\nm = df2['vote_count'].quantile(0.9)\nC, m","5c7b4465":"# Filter out movies that don't have 90 % of vote count\nq_movies = df2.copy().loc[df2['vote_count'] >= m]\nq_movies.shape","c3300977":"def weighted_rating(x, m=m, C=C):\n    v = x['vote_count']\n    R = x['vote_average']\n    return (v\/(v+m) * R) + (m\/(m+v) * C)\n\nq_movies['score'] = q_movies.apply(weighted_rating, axis=1)\nq_movies = q_movies.sort_values('score', ascending=False)\n\nq_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)\n","2ceda26e":"pop = df2.sort_values('popularity', ascending=False)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,4))\n\nplt.barh(pop['title'].head(6), pop['popularity'].head(6), align='center') \nplt.gca().invert_yaxis()\nplt.xlabel('Popularity')\nplt.title('Popular Movies')","a13c1aa2":"df2['overview'].head(5)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ntfidf = TfidfVectorizer(stop_words='english')\n\ndf2['overview'] = df2['overview'].fillna('')\n\ntfidf_matrix = tfidf.fit_transform(df2['overview'])\n\ntfidf_matrix.shape\n\ncosine_sim = linear_kernel(tfidf_matrix)","86fbcbac":"# Trying cosine similarity\n\ndocuments = [\n    'alpine snow winter boots.',\n    'snow winter jacket.',\n    'active swimming briefs',\n    'active running shorts',\n    'alpine winter gloves'\n]\n\ncntvt = CountVectorizer(stop_words='english')\n\ntfidf_matrix = cntvt.fit_transform(documents)\ncntvt.get_feature_names()\ntfidf_matrix.todense()\n\ncos_sim = cosine_similarity(tfidf_matrix)\ncos_sim","845e6b05":"indices = pd.Series(df2.index, index=df2['title']).drop_duplicates()\n\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n    return df2['title'].iloc[movie_indices]\n\nidx = indices[\"The Dark Knight Rises\"]\ndf2['title'].iloc[[i[0] for i in (sorted(list(enumerate(cosine_sim[idx])), key=lambda x: x[1], reverse=True)[1:11])]]","d169078f":"get_recommendations('The Dark Knight Rises')","d5520917":"get_recommendations('The Avengers')","627f7fdd":"# literal_eval is a python function to evaluate correctness of string data. It\n# will also create python objects for you \nfrom ast import literal_eval\n\nfeatures = ['cast', 'crew', 'keywords', 'genres']\n\ndf2['cast'][0]\ndf2['crew'][0]\ndf2['keywords'][0]\ndf2['genres'][0]\n\nfor feature in features:\n    df2[feature] = df2[feature].apply(literal_eval)","19cd9e48":"def get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","b094dcf9":"# return top 3\ndef get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        if len(names) > 3:\n            names = names[:3]\n        return names\n    \n    return []","51984572":"df2['director'] = df2['crew'].apply(get_director)\n\nfeatures = ['cast', 'keywords', 'genres']\nfor feature in features:\n    df2[feature] = df2[feature].apply(get_list)\n    \ndf2[['title', 'cast', 'director', 'keywords', 'genres']].head(5)","07543b02":"#data cleaning and prepa\n\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","42228059":"features = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    df2[feature] = df2[feature].apply(clean_data)","355750b8":"# create \"soup\" for the vectorization used to compute the cosine similarity matrix\n\ndef create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\ndf2['soup'] = df2.apply(create_soup, axis=1)","dca7319d":"count = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(df2['soup'])\n\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)\ndf2 = df2.reset_index()\nindices = pd.Series(df2.index, index=df2['title'])","f9a076da":"get_recommendations('The Dark Knight Rises', cosine_sim2)","17d9dcdd":"get_recommendations('The Godfather', cosine_sim2)","631c72f8":"# User-User, Item-Item Collaborative filtering\nfrom surprise import Reader, Dataset, SVD #, cross_validate #evaluate\nfrom surprise.model_selection import cross_validate, KFold\nreader=Reader(rating_scale=(1,5))","d33e78a6":"#read the user rating file (subset file to improve processing time)\nratings=pd.read_csv('..\/input\/the-movies-dataset\/ratings_small.csv')\nratings.head()","d4e52521":"data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n# data.split(n_folds=5)\n\nsvd= SVD()\n# evaluate(svd, data, measures=['RMSE','MAE'])\n# cross_validate(NormalPredictor(), data, cv=5)\n\n# Run 5-fold cross-validation and print results\ncross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","ab7f6aaa":"#create a training set for svd\ntrainset = data.build_full_trainset()\nsvd.fit(trainset)","6af00c08":"#getting all userId =1 with the rattings\nratings[ratings['userId'] == 1]","71d1bd6c":"str(svd.predict(1, 302).est)","49337d44":"try:  # SciPy >= 0.19\n    from scipy.special import comb, logsumexp\nexcept ImportError:\n    from scipy.misc import comb, logsumexp  # noqa \n!pip install auto-sklearn\n!apt-get remove swig \n!apt-get install swig3.0 build-essential -y\n!ln -s \/usr\/bin\/swig3.0 \/usr\/bin\/swig\n!apt-get install build-essential\n!pip install --upgrade setuptools\n# !pip install sklearn\n\nimport autosklearn.classification\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\nimport os  \nimport autosklearn.regression\nfrom sklearn.model_selection import train_test_split","524398b3":"# from scipy.special import comb\n# import sklearn\n# import sklearn.model_selection\nmovies = df2.dropna(subset=['vote_average', 'budget', 'revenue'], how='all')\nX = movies[['budget', 'revenue']]\ny = movies['vote_average']\n\n \n\nX = X.iloc[:, :].values\ny = y.iloc[:].values\ny = y.astype(int)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nX_train, X_test, y_train, y_test = \\\n    sklearn.model_selection.train_test_split(X, y, random_state=1)\nautoml = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder='\/tmp\/autosklearn_cv_example_tto2',\n    output_folder='\/tmp\/autosklearn_cv_example_oto22',\n    delete_tmp_folder_after_terminate=False,\n    resampling_strategy='cv',\n    resampling_strategy_arguments={'folds': 5},\n)\n\n \n\n# fit() changes the data in place, but refit needs the original data. We\n# therefore copy the data. In practice, one should reload the data\nautoml.fit(X_train.copy(), y_train.copy(), dataset_name='movie_recommendation')\n# During fit(), models are fit on individual cross-validation folds. To use\n# all available data, we call refit() which trains all models in the\n# final ensemble on the whole dataset.\nautoml.refit(X_train.copy(), y_train.copy())\n\n \n\nprint(automl.show_models())","97332b80":"predictions = automl.predict(X_test)\nprint(\"Accuracy as per AutoML: \", sklearn.metrics.accuracy_score(y_test, predictions))","c21dfd3d":"# 3.1 Demographic Filtering","9366ac4c":"The most basic form of a recommendation engine would be where the engine recommends the most popular items to all the users. That would be generalized as everyone would be getting similar recommendations as we didn\u2019t personalize the recommendations.","fffe9f6e":"# 2.2 1.2 Reading the data","b570bf44":"The highest average vote for the genres are war, history and documentary","96d9aaba":"Just a peak at our data.","2c7592f3":"using cosine_similarity with overview for the movie 'The Dark Knight Rises' we got this result","04b1dc1f":"The table shows us most movies are made in USA","c5b4642a":"# 1. ML Project 2","7140eb1b":"# 1.3 Team Members","55a32cd7":"There are 481 movies which are less than 90% of vote count","3b7e4119":"# 2.2 1.3 Training Data Info","2250c2dd":"The objective of this project is to recommend users and movies","7c1de786":"as we can see here there are a lot of nullable values in the homepage and the tagline columns ","e23179e6":"from the spoken language the highest is English with 4485","fc9607ec":"# 2.1.2 2.3 Popularity vs Genres","24f5c8ec":"In this technique, the users are recommended the similar content which they have used\/watched\/liked the most before.","ab2cc117":"# 2.1.4 2.5 Rate vs Movies","37b4b4b4":"* https:\/\/www.kaggle.com\/sjj118\/movie-visualization-recommendation-prediction\n* https:\/\/www.kaggle.com\/rounakbanik\/movie-recommender-systems\n* https:\/\/www.kaggle.com\/ibtesama\/getting-started-with-a-movie-recommendation-system\n* https:\/\/surprise.readthedocs.io\/en\/stable\/getting_started.html\n* https:\/\/medium.com\/@gracy.f\/automl-for-python-on-windows-314ca8ea6955","16885e1d":"# 1.1 Introduction","b510e8d0":"Using cosine_similarity with keywords, genres, director and cast we get movie recommendation for 'The Dark Knight Rises' as above which is better result","b162fb59":"# 2.6 1.8 Popularity vs Movies","0d202000":"# 1.2 Agenda","8e457ea1":"Let's join the two dataset on the 'id' column","dd1fe531":"This means the vote_average mean is 6.09 ,and we will only consider movies that have a minimum vote count of 1838.4","31c24ad7":"1. Data Set Selection\n2. EDA\n3. Demographic filtering\n4. Content-based recommenders\n5. Collaborative filtering \n6. AutoML","5ad6ae97":"as above we can tell that Avatar has the highest revenue","4ce2e7fa":"# 2.9 2.1 Years Vs Movies","c1d553bd":"Root-Mean-Square Error (RMSE) was used for evaluation and is\ndefined as follows:\n\nRMSE <- function(true_ratings, predicted_ratings){\n    sqrt(mean((true_ratings - predicted_ratings)^2))\n}\n\nRMSE was the metric used to judge entries in the Netflix challenge. The lower the RMSE was on Netflix\u2019s quiz set between the submitted rating predictions and the actual ratings, the better the method was.\nso we are using RMSE on our recommendation system","056f9716":"# 2.4 1.6  Checking Distribution ","c1ab49ce":"It is showing us that popularity and vote_count, and revenue and vote_count have the highest which is 0.78","3e7add14":"The chart is telling us the highest language is English","9308cde2":"1. Eden Zere\n2. Essey Abraham Tezare\n3. Mario Arismendi Matos","b426d753":"# 5.1 Collaborative Filtering","b89a748d":"cosine_similarity tells us using some equation how similar they are,so as above we can see that 'alpine snow winter' boots is similar with 'snow winter jacket' because they both have 'snow winter' content in the sentence so that gave us result of 0.577","058d137f":"TfidVectorizer it helps us to put each word in a column and stop the common english word like example 'the' word","8f134285":"# 2.5 1.7 Revenue vs Movies","9950e6b2":"# 4.1 Content Based","f0f0bbfa":"Above tells us that most movies are Drama,Comedy and thriller and from the keywords we have most repeated key is independent","624bda70":"read user rating file","d3425243":"# 2 1. Data Set Selection And EDA","65bf1150":"We used SVD(Singular Value Decompostion)\nthe SVD is used as a collaborative filtering technique. It uses a matrix structure where each row represents a user, and each column represents an item. The elements of this matrix are the ratings that are given to items by users.","a9d017e3":"# 2.1.3 2.4 Vote_Average vs Genres","8049163b":"# 2.1 1.1 Import libraries","32a2cbde":"# 2.7 1.9 Languages vs Movies","2409b6b6":"As above we can see that Minions is the most popular movie ","10d464f2":"we can tell that the movies most rated are in 2015","ac21a2ac":"The pie chart tells us that in 2000s there were alot of movies released","51b64f55":"Joining the keywords, cast, director and genres","b66c7626":"For movie with Id 302, we get a prediction of estimated rate 2.85 out 5 with user Id 1.","c5e2d7a7":"In collaborative filtering, two entities collaborate to deduce recommendations on the basis of certain similarities between them. These filtering techniques are broadly of two types:\n\n1.User Based Collaborative Filtering: In user based collaborative filtering, we find out the similarity score between the two users. On the basis of similarity score, we recommend the items bought\/liked by one user to other user assuming that he might like these items on the basis of similarity. This will be more clear when we go ahead and implement this. Major online streaming service, Netflix have their recommendation engine based on user based collaborative filtering.\n\n2.Item Based Collaborative Filtering: In item based collaborative filtering, the similarity of an item is calculated with the existing item being consumed by the existing users. Then on the basis of amount of similarity, we can say that if user X likes item A and a new item P is most similar to item A then it highly makes sense for us to recommend item P to user X.","9c6f210c":"# 2.2 1.4 Checking for Null Data","eeec278a":"# 2.1.1 2.2 Genres","b4616e23":"# 2.1.3 2.4 Correlation Matrix","e693ea6e":"The first dataset contains the following features:-\n\n* movie_id - A unique identifier for each movie.\n* cast - The name of lead and supporting actors.\n* crew - The name of Director, Editor, Composer, Writer etc.\n\nThe second dataset has the following features:- \n\n* budget - The budget in which the movie was made.\n* genre - The genre of the movie, Action, Comedy ,Thriller etc.\n* homepage - A link to the homepage of the movie.\n* id - This is infact the movie_id as in the first dataset.\n* keywords - The keywords or tags related to the movie.\n* original_language - The language in which the movie was made.\n* original_title - The title of the movie before translation or adaptation.\n* overview - A brief description of the movie.\n* popularity - A numeric quantity specifying the movie popularity.\n* production_companies - The production house of the movie.\n* production_countries - The country in which it was produced.\n* release_date - The date on which it was released.\n* revenue - The worldwide revenue generated by the movie.\n* runtime - The running time of the movie in minutes.\n* status - \"Released\" or \"Rumored\".\n* tagline - Movie's tagline.\n* title - Title of the movie.\n* vote_average -  average ratings the movie recieved.\n* vote_count - the count of votes recieved.\n\n\n","4e278ab0":"From the above we got RMSE of mean of 0.89 which is good","124e0dfc":"# 2.8 2.0 Countries Vs Movies","8a6fe9d2":"# 7.1 References","eab3d434":"# 6.1 AutoMl","53f0ccac":"# 2.3 1.5 Distict values"}}