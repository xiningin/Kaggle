{"cell_type":{"45302fb3":"code","cd45aee8":"code","b6c4d4b9":"code","a353df34":"code","0fbbfb1e":"code","389464a7":"code","16672989":"code","a39fc492":"code","cf3bc345":"code","40024f61":"code","acf45c8e":"code","06cf4896":"code","88a140cf":"code","1a07e0fe":"code","f2818168":"code","dad2fa71":"code","f7f86733":"code","340aa885":"code","a07cad97":"code","4509817f":"code","791f3246":"code","c746f481":"code","2ae14560":"markdown","c09fc5ee":"markdown","9ec7885a":"markdown","1a6c7c9c":"markdown","567f7170":"markdown","c446f7e8":"markdown","02ddc003":"markdown","dbbcb8b3":"markdown","5525ef89":"markdown","5e23e547":"markdown","9532baa9":"markdown","2b6e0a69":"markdown","6c223411":"markdown","41583756":"markdown","1317e562":"markdown","529d1d03":"markdown","96c690e6":"markdown","a2c70b4f":"markdown","b0256a54":"markdown","f9b8c288":"markdown"},"source":{"45302fb3":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nimport csv\nimport gc","cd45aee8":"# defining data directory paths\ntrain_dir = \"..\/input\/train.csv\"\ntest_dir = \"..\/input\/test.csv\"\n\ndf = pd.read_csv(train_dir)\ndf.info()","b6c4d4b9":"labels = df[\"label\"].values.tolist() # extracting labels from the database and converting it into a list\nlabels = np.array(labels)\n\nn_classes = len(set(labels)) # defining number of classes\n\nlabels = keras.utils.to_categorical(labels) # converting the labels to one-hot format","a353df34":"df_train = df.drop([\"label\"], axis = 1) # extracting the image data\ndata = df_train.values.tolist() # converting image data to list\ndata = np.array(data)\ndata = data.astype('float32')\/255.0 # converting data into range 0-1","0fbbfb1e":"dataframes_i = []\nfor i in range(10):\n    tempdf = None\n    tempdf = df[df[\"label\"]==i].drop([\"label\"], axis = 1)\n    temp = tempdf.values.tolist()\n    dataframes_i.append(temp[0:5])\n    \nfig = plt.figure(figsize = (8,20)) #defining figure\ndef plot_images(image, index):\n    fig.add_subplot(10,5, index)\n    plt.axis(\"on\")\n    plt.tick_params(left = False, bottom=False, labelbottom=False, labelleft = False,)\n    plt.imshow(image, cmap = 'Greys')\n    return\n\nindex = 1\nfor i in dataframes_i:\n    for j in i:\n        x = np.array(j)\n        x = x.reshape(28,28)\n        plot_images(x, index)\n        index += 1\nplt.show()","389464a7":"print(\"Training data shape = \" + str(data.shape))\nprint(\"Training labels shape = \" + str(labels.shape))","16672989":"gen_model = Sequential()\ngen_model.add(Dense(784, activation = 'relu', input_shape = (784,)))\ngen_model.add(Dense(512, activation = 'relu'))\ngen_model.add(Dense(264, activation = 'relu'))\ngen_model.add(Dense(10, activation = 'softmax'))\nprint(\"STANDARD NEURAL NETWORK MODEL :-\")\ngen_model.summary()","a39fc492":"gen_model.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])","cf3bc345":"gen_model_hist = gen_model.fit(data, labels, batch_size = 32, epochs = 5, validation_split = 0.1)","40024f61":"plt.plot(gen_model_hist.history[\"acc\"])\nplt.plot(gen_model_hist.history[\"val_acc\"])\nplt.title(\"Training vs Validation Accuracy\")\nplt.legend([\"Training\",\"Validation\"], loc = 'lower right')\nplt.show()","acf45c8e":"del gen_model, gen_model_hist\ngc.collect()","06cf4896":"X_train_cnn = data.reshape(len(data), 28, 28, 1)","88a140cf":"cnn_model = Sequential()\ncnn_model.add(Conv2D(32, kernel_size = [3,3], activation = 'relu', input_shape = (28,28,1)))\ncnn_model.add(Conv2D(64, kernel_size = [3,3], activation = 'relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(MaxPool2D(pool_size = [2,2], strides = 2))\ncnn_model.add(Conv2D(128, kernel_size = [3,3], activation = 'relu'))\ncnn_model.add(MaxPool2D(pool_size = [2,2], strides = 2))\ncnn_model.add(Flatten())\ncnn_model.add(Dense(512, activation = 'relu'))\ncnn_model.add(Dense(10, activation = 'softmax'))\nprint(\"CONVOLUTIONAL NEURAL NETWORK MODEL :-\")\ncnn_model.summary()","1a07e0fe":"cnn_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\ncnn_model_hist = cnn_model.fit(X_train_cnn, labels, batch_size = 32, epochs = 6, validation_split = 0.1)","f2818168":"plt.plot(cnn_model_hist.history[\"acc\"])\nplt.plot(cnn_model_hist.history[\"val_acc\"])\nplt.title(\"Training vs Validation Accuracy (CNN Model)\")\nplt.legend([\"Training\",\"Validation\"], loc = 'lower right')\nplt.show()","dad2fa71":"del cnn_model, cnn_model_hist\ngc.collect()","f7f86733":"data_aug = ImageDataGenerator(featurewise_center = False,\n                             samplewise_center = False,\n                             featurewise_std_normalization = False,\n                             samplewise_std_normalization = False,\n                             zca_whitening = False,\n                             rotation_range = 10,\n                             zoom_range = 0.1,\n                             width_shift_range = 0.1,\n                             height_shift_range = 0.1,\n                             horizontal_flip = False,\n                             vertical_flip = False)","340aa885":"# defining several models\nmodels_ensemble = []\nfor i in range(7):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = [3,3], activation = 'relu', input_shape = (28,28,1)))\n    model.add(Conv2D(64, kernel_size = [3,3], activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n    model.add(Conv2D(128, kernel_size = [3,3], activation = 'relu'))\n    model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu'))\n    model.add(Dense(10, activation = 'softmax'))\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    models_ensemble.append(model)","a07cad97":"# defining training routine\nmodel_histories = []\ni = 1\nfor model in models_ensemble:\n    xtrain, xtest, ytrain, ytest = train_test_split(X_train_cnn, labels, test_size = 0.07)\n    print(\"Model \" +str(i)+ \" : \",end=\"\")\n    model_history = model.fit_generator(data_aug.flow(xtrain, ytrain, batch_size = 64), epochs = 1, verbose = 1, validation_data = (xtest, ytest), steps_per_epoch = xtrain.shape[0])\n    model_histories.append(model_history)\n    i += 1","4509817f":"# import and preprocess test data\ntestdata = pd.read_csv(test_dir)\ntestdata = testdata.values.tolist()\ntestdata = np.array(testdata)\ntestdata_reshaped = testdata.reshape(testdata.shape[0], 28, 28, 1)\ntestdata_reshaped = testdata_reshaped.astype('float')\/255.0\n\ndef make_predictions_final_model(curr_model):\n    prediction_array = curr_model.predict_on_batch(testdata_reshaped)\n    predictions = [np.argmax(i) for i in prediction_array]\n    return predictions","791f3246":"predictions_ensemble = [] \n\n# Make predictions using seperate models\nfor model in models_ensemble:\n    curr_predictions = make_predictions_final_model(model)\n    predictions_ensemble.append(curr_predictions)\n\nprediction_per_image = []\n# Make a list of predictions for a particular image \nfor i in range(len(predictions_ensemble[0])):\n    temppred = [predictions_ensemble[0][i], predictions_ensemble[1][i], predictions_ensemble[2][i], predictions_ensemble[3][i], predictions_ensemble[4][i], predictions_ensemble[5][i], predictions_ensemble[6][i]]\n    prediction_per_image.append(temppred)\n    \n# Find the maximum occuring element in the array (list)\nprediction_per_image = np.array(prediction_per_image)\nmodes = stats.mode(prediction_per_image, axis = 1)\n\n# append the modes to the final prediction list\nfinal_predictions = []      \nfor i in modes[0]:\n    final_predictions.append(i[0])","c746f481":"final_csv = []\ncsv_title = ['ImageId', 'Label']\nfinal_csv.append(csv_title)\nfor i in range(len(final_predictions)):\n    image_id = i + 1\n    label = final_predictions[i]\n    temp = [image_id, label]\n    final_csv.append(temp)\n\nprint(len(final_csv))\n\nwith open('submission_csv_aug.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerows(final_csv)\nfile.close()","2ae14560":"* The dataframe contains image labels defining which class the particular image belongs to, also the columns ranging pixel0 - pixel738 contains a value for that particular pixel.\n* The image is of the size 28x28","c09fc5ee":"We will assess the working of neural nets on the MNIST digits dataset using three approaches :\n1. **Using the standard neural network architecture.**\n2. **Using the convolutional neural network architecture.**\n3. **Adding Data Augmentation and then using the convolutional neural network architecture.**","9ec7885a":"**Defining the CNN model :**","1a6c7c9c":"**ADDING DATA AUGMENTATION AND ENSEMBLING MODELS:**","567f7170":"**Defining Standard Neural Network** : \nNow that we have the training data and labels we will define a simple neural network.","c446f7e8":"Now plotting the training and validation accuracy plots :","02ddc003":"**CONVOLUTIONAL NEURAL NETWORK**","dbbcb8b3":"* Firstly we will make predictions on each model and then save it into lists, this will create 5 different prediction lists.\n* Then we will use these lists to make new list exclusively for each image which will contain predictions from each model.\n* Finally we will find the mode from each list and then append it to a new list which will be the final predictions for our model.","5525ef89":"First we need to load and process the data, as the data provided in not in form of images but rather in form of a dataframe. Lets check what data is provided in the dataframe.","5e23e547":"**Training data :** Extracting from dataframe -> converting to list -> numpy array -> scaling into range 0-1.","9532baa9":"**Defining Labels :** extracting labels from dataframe -> converting to numpy array -> converting to one-hot format.\n","2b6e0a69":"As we are adding the data augmentation and training models several times, this process will take some time.","6c223411":"Plotting an image from each class to get insight on image data.\nPlotting 5 images from each class","41583756":"**Now we will use all our models to make predictions**\n* Make predictions from one model -> add to list -> repeat for all models -> then we will find the mode of predictions -> use it as final prediction.","1317e562":"Creating the output csv file.","529d1d03":"Now we will use the convolutional neural network architecture to train the model, for this we need to modify our data as :\n* reshaping the training data into (n, 28, 28, 1) as there is only one channel and image is of size 28x28.","96c690e6":"Now we will train 7 different classifiers on the cnn architecture and then use them for preditions.\n1. We will build 7 different models.\n2. Train those models on different splits of data.\n3. Use those models for predictions as : we take the mode from the predictions.","a2c70b4f":"Checking shape of training data and labels","b0256a54":"Plotting the model metrics:","f9b8c288":"Compiling and fitting the data in the model."}}