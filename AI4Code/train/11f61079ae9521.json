{"cell_type":{"a21b32ab":"code","09a7b56c":"code","133c5775":"code","9ca3c390":"code","a250e0b9":"code","658ebb3e":"code","6e4bce25":"code","d4490ea1":"code","0037a81e":"code","7438a658":"code","c2fa3d9f":"code","ca7fa869":"code","ebe645e4":"code","8800d8cb":"code","5757e789":"code","991a4d3e":"code","3d8fd851":"code","e9f053bb":"code","5246238a":"code","fa7e6367":"code","f34cdb39":"code","532e458e":"code","815e506c":"code","8cd3795c":"code","1fdbe0e2":"markdown","144e0683":"markdown","df4bb52c":"markdown","6434870c":"markdown","fc08dc93":"markdown","d732992a":"markdown","c07f68d8":"markdown","629cc603":"markdown","ec7cd0fb":"markdown","be1fc64c":"markdown","390d1213":"markdown","4b630030":"markdown","ff16b196":"markdown","d75a9fb3":"markdown"},"source":{"a21b32ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09a7b56c":"from IPython.display import clear_output","133c5775":"# unzip training data\n!unzip \/kaggle\/input\/dogs-vs-cats\/train.zip\nclear_output()\n\n# install imutils\n!pip install imutils\nclear_output()\n\n# install easy_tfrecord\n!pip install easy-tfrecord\nclear_output()","9ca3c390":"import time\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom imutils import paths\nfrom tfrecord import TFRecord # easy-tfrecord\nfrom sklearn.model_selection import train_test_split","a250e0b9":"# set the directory\ndata_dir = \".\/train\"\n\n# get all the image paths\nimage_paths = list(paths.list_images(data_dir))\nprint(image_paths[:5])","658ebb3e":"# extract the labels\nlabels = [path.split(os.path.sep)[-1].split('.')[0]\n          for path in image_paths]\nclasses = sorted(set(labels))\nprint(\"Unique Classes\", classes)\nprint(labels[:5])","6e4bce25":"# encode the labels\nlabel2idx = {label: idx for idx, label in enumerate(classes)}\nidx2label = {idx: label for label, idx in label2idx.items()}\nlabels_enc = [label2idx[label] for label in labels]\nprint(\"Labels: \", labels[:5])\nprint(\"Labels Encoded: \",labels_enc[:5])","d4490ea1":"# split the dataset into train, valid, test\nX_train, X_valid, y_train, y_valid = train_test_split(image_paths, labels_enc, test_size=0.2,\n                                                      random_state=42)\n\nX_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.2,\n                                                    random_state=42)\nlen(X_train), len(X_valid), len(X_test)","0037a81e":"# create a function to load the image\ndef load_images(image_path, label, classes=classes):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = tf.cast(image, tf.uint8)\n    image = image \/ 255\n    \n    # onehot encode label\n    oh_label = tf.one_hot(label, depth=len(classes))\n    return image, oh_label","7438a658":"# Create tf dataset\ntrain_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\nvalid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\ntest_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n# apply load_images func\ntrain_set = train_set.map(load_images, num_parallel_calls=AUTOTUNE)\ntrain_set = train_set.batch(32).prefetch(AUTOTUNE)\n\nvalid_set = valid_set.map(load_images, num_parallel_calls=AUTOTUNE)\nvalid_set = valid_set.batch(32).prefetch(AUTOTUNE)\n\ntest_set = test_set.map(load_images, num_parallel_calls=AUTOTUNE)\ntest_set = test_set.batch(32).prefetch(AUTOTUNE)","c2fa3d9f":"fig = plt.figure(figsize=(10, 8))\n\nfor batch in train_set.take(1):\n    indices = np.random.randint(32, size=8)\n    for i,idx in enumerate(indices):\n        ax = fig.add_subplot(2, 4, i+1)\n        plt.imshow(batch[0][idx])\n        plt.axis(\"off\")\n        plt.title(idx2label[batch[1][idx].numpy().argmax(axis=-1)])\n    plt.tight_layout()\n    plt.show()","ca7fa869":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K","ebe645e4":"class AlexNet:\n    @staticmethod\n    def build(width, height, depth, classes, reg=0.0002):\n        # initialize the model \n        model = Sequential()\n        # Block 1\n        model.add(Conv2D(96, 11, strides=4, input_shape=(height, width, depth),\n                         padding=\"same\", kernel_regularizer=l2(reg), activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # Block 2\n        model.add(Conv2D(256, 5, padding=\"same\", kernel_regularizer=l2(reg),\n                         activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # Block 3\n        model.add(Conv2D(384, 3, padding=\"same\", kernel_regularizer=l2(reg),\n                         activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Conv2D(384, 3, padding=\"same\", kernel_regularizer=l2(reg),\n                         activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Conv2D(256, 3, padding=\"same\", kernel_regularizer=l2(reg),\n                         activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # Block 4\n        model.add(Flatten())\n        model.add(Dense(4096, kernel_regularizer=l2(reg), activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        # Block 5\n        model.add(Dense(4096, kernel_regularizer=l2(reg), activation=\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        # Softmax Classifier\n        model.add(Dense(classes, kernel_regularizer=l2(reg), activation=\"softmax\"))\n        \n        return model","8800d8cb":"# instantiate object of TFRecord class\ntfrec = TFRecord(n_classes=2, image_shape=[224, 224, 3]) # image_shape: all images will be resized to this shape [224, 224]\n\n# compute n_shards for training set (you can directly pass value to n_shards)\ntrain_shards = tfrec.compute_nshards(X_train)\ntrain_tfrecords = tfrec.write_tfrecords(X_train, y_train, save_path=\".\/data\/train\",\n                                        n_shards=train_shards)\n\n# compute n_shards for validation set (optional)\nvalid_shards = tfrec.compute_nshards(X_valid)\ntrain_tfrecords = tfrec.write_tfrecords(X_valid, y_valid, save_path=\".\/data\/valid\", \n                                        n_shards=valid_shards)","5757e789":"# create datasets for training and validation set\ntrain_dataset = tfrec.parse_tfrecord(\".\/data\/train\")\nvalid_dataset = tfrec.parse_tfrecord(\".\/data\/valid\")\n\n# create a function to normalize images: (any kind of preprocessing functions can be added)\ndef normalize(image, label):\n    image = image \/ 255\n    return (image, label)\n\n# normalize images\ntrain_dataset = train_dataset.map(normalize, num_parallel_calls=AUTOTUNE)\nvalid_dataset = valid_dataset.map(normalize, num_parallel_calls=AUTOTUNE)","991a4d3e":"# build model\nmodel = AlexNet.build(width=227, height=227, depth=3, classes=2, reg=0.0002)\n\n# define optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# compile model\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n\n# create early stopping callback\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n\n# let's track time taken for 5 epochs\nstart = time.time()\n# fit the model\nhistory = model.fit(train_dataset, epochs=5, validation_data=valid_dataset,\n                    callbacks=[early_stop])\nend = time.time()","3d8fd851":"time_taken = round((end - start)\/60, 2)\nprint(\"Time taken for 5 epochs: {} mins\".format(time_taken))","e9f053bb":"# plot accuracy and loss\n# def plot_metrics(history):\n#     fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n#     ax[0].plot(history.history[\"loss\"], label=\"Train Loss\")\n#     ax[0].plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n#     ax[0].set_title(\"Training and Validation Loss\")\n#     ax[0].set_xlabel(\"Epoch\")\n#     ax[0].set_ylabel(\"Loss\")\n\n#     ax[1].plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n#     ax[1].plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n#     ax[1].set_title(\"Training and Validation Accuracy\")\n#     ax[1].set_xlabel(\"Epoch\")\n#     ax[1].set_ylabel(\"Accuracy\")\n#     plt.suptitle(\"Trained without TF Records\")\n#     plt.show()\n\n# plot_metrics(history)","5246238a":"# evaluate on a test set\nloss, acc = model.evaluate(test_set, verbose=0)\nprint(\"Loss: {:.4f}\\nAccuracy: {:.2f}%\".format(loss, acc*100))","fa7e6367":"from sklearn.metrics import classification_report\n\npredictions = model.predict(test_set)\npredictions = predictions.argmax(axis=-1)\nprint(classification_report(y_test, predictions))","f34cdb39":"# build model\nmodel_1 = AlexNet.build(width=224, height=224, depth=3, classes=2, reg=0.0002)\n\n# define optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# compile model\nmodel_1.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n\n# create early stopping callback\n# early_stop = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n\nstart = time.time()\n# fit the model\nhistory = model_1.fit(train_set, epochs=5, validation_data=valid_set)\nend = time.time()","532e458e":"time_taken = round((end - start)\/60, 2)\nprint(\"Time taken for 5 epochs: {} mins\".format(time_taken))","815e506c":"# plot_metrics(history)","8cd3795c":"# evaluate on a test set\nloss, acc = model_1.evaluate(test_set, verbose=0)\nprint(\"Loss: {:.4f}\\nAccuracy: {:.2f}%\".format(loss, acc*100))","1fdbe0e2":"**Build and train model**","144e0683":"## Encode labels","df4bb52c":"**Evaluate on a test set**","6434870c":"# Split into train, valid & test","fc08dc93":"## Without TF Records\nWatch time taken per epoch","d732992a":"## Build Model","c07f68d8":"## Get image paths and labels","629cc603":"**Uncomment below line if you want to plot losses and accuracies.**","ec7cd0fb":"## Display some images","be1fc64c":"### Time taken to finish 5 epochs:\n- **With TFRecords**: _2.63 minutes_\n- **Without TFRecords**: _4.05 minutes_","390d1213":"## Create tf.data Datasets","4b630030":"## Training with TF Records (easy_tfrecord)\n**Writing TFRecords**","ff16b196":"**Loading from TFRecords**","d75a9fb3":"**Print classification report**"}}