{"cell_type":{"cfdab7a8":"code","e1a88f3f":"code","9a1c1a38":"code","ce5654bd":"code","a0398d97":"code","c1753e54":"code","c29ff0ba":"code","b54ec964":"code","cbab17ba":"code","4d5629a3":"code","01434b43":"code","f03e462d":"code","76b32068":"code","b308942a":"code","d28f6cd6":"code","bbda6733":"code","a15b6a5e":"code","3d16d203":"code","fad410be":"code","d48df2f9":"code","e3c7c677":"code","33121082":"code","88782604":"code","32affd35":"code","8c80d5f0":"code","fd3c9ba8":"markdown","4ade91be":"markdown","a5d5d5b8":"markdown","dfe16619":"markdown","59c4ea6a":"markdown"},"source":{"cfdab7a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e1a88f3f":"import pandas as pd\n\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_train.head()","9a1c1a38":"# Descripe numerical features\ndf_train.describe().transpose()","ce5654bd":"# Descripe categorical features\ndf_train.describe(include = ['O']).transpose()","a0398d97":"# Check missing values\ndf_train.isnull().sum()","c1753e54":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Plot age\nf, axes = plt.subplots(1, 2, figsize=(20, 4))\ndf_train['Age'].hist(bins=20, ax=axes[0])\n# df_train['AgeLog'] = np.log(df_train['Age'])\ndf_train['Age__Log'] = df_train['Age'].transform(np.log)\ndf_train['Age__Log'].hist(bins=20, ax=axes[1])","c29ff0ba":"f, axes = plt.subplots(1, 2, figsize=(20, 4))\ndf_train['Fare'].hist(ax=axes[0], bins=20)\ndf_train['Fare__Log'] = df_train['Fare'].transform(lambda x: np.log(x + 1))\ndf_train['Fare__Log'].hist(ax=axes[1], bins=20)","b54ec964":"df_train['Cabin__FirstChar'] = df_train['Cabin'].astype(str).str[0]\ndf_train['Cabin__FirstChar'].fillna('n', inplace=True)\ndf_train['Cabin__FirstChar'].value_counts()","cbab17ba":"df_train['Ticket__Number'] = df_train['Ticket'].map(lambda x: ''.join(i for i in x if i.isnumeric()))\nmedian_value = df_train['Ticket__Number'][df_train['Ticket__Number'] != ''].astype(int).median()\ndf_train['Ticket__Number'][df_train['Ticket__Number'] == ''] = str(int(median_value))\ndf_train['Ticket__Number'] = df_train['Ticket__Number'].astype(int)\n\nf, axes = plt.subplots(1, 2, figsize=(20, 4))\ndf_train['Ticket__Number'].hist(bins=20, ax=axes[0])\ndf_train['Ticket__Number__Log'] = df_train['Ticket__Number'].transform(np.log)\n\ndf_train['Ticket__Number__Log'].hist(bins=20, ax=axes[1])","4d5629a3":"df_train['Ticket__Chars'] = df_train['Ticket'].map(lambda x: ''.join(i for i in x if i.isalpha()))\ndf_train['Ticket__Chars'][df_train['Ticket__Chars'] == ''] = 'missing'\nprint(df_train['Ticket__Chars'].unique())","01434b43":"df_train['Name__Length'] = df_train['Name'].str.len()\ndf_train['Name__Length__Log'] = df_train['Name__Length'].transform(np.log)\nf, axes = plt.subplots(1, 2, figsize=(20, 4))\ndf_train['Name__Length'].hist(bins=20, ax=axes[0])\ndf_train['Name__Length__Log'].hist(bins=20, ax=axes[1])","f03e462d":"# Print all column types\nprint('numeric columns', df_train.select_dtypes(exclude=['object']).columns.tolist(), sep='\\n')\nprint('string columns', df_train.select_dtypes(include=['object']).columns.tolist(), sep='\\n')","76b32068":"# Extract columns\nnumerical_features = [\n    'Name__Length', \n    'Name__Length__Log', \n    'Age', \n    'Age__Log', \n    'SibSp', \n    'Parch', \n    'Fare', \n    'Fare__Log', \n    'Ticket__Number', \n    'Ticket__Number__Log',\n]\ncategorical_features = [\n    'Sex', \n    'Embarked', \n    'Cabin__FirstChar', \n    'Ticket__Chars',\n]\ntarget_column = 'Survived'\n\nX_train = df_train.copy()\ny_train = X_train.pop(target_column)\nX_train = X_train[categorical_features + numerical_features]\n\nX_train.head()","b308942a":"from sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Define transformation of numerical features\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])","d28f6cd6":"from sklearn.preprocessing import OneHotEncoder\n\n# Define transformation of categorical features\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","bbda6733":"from sklearn.compose import ColumnTransformer\n\n# Define column transformation\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer,   numerical_features),\n        ('cat', categorical_transformer, categorical_features)])","a15b6a5e":"from sklearn.ensemble import GradientBoostingClassifier\n\npipe_GBR  = Pipeline(\n    steps = [ ('preprocessor', preprocessor),\n              ('GBR', GradientBoostingClassifier(random_state=5,\n                      n_estimators=400, max_depth=5 )) ])","3d16d203":"from xgboost import XGBClassifier\n\n# https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#xgboost.XGBClassifier\npipe_XGB  = Pipeline(\n    steps = [ ('preprocessor', preprocessor),\n              ('XGB', XGBClassifier(max_depth=6, \n                      n_estimators=1000, random_state=5, nthread=-1)) ])","fad410be":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\npipe_ADA = Pipeline(\n    steps= [('preprocessor', preprocessor),\n            ('ADA', AdaBoostClassifier(\n                DecisionTreeClassifier(max_depth=8, \n                                       min_samples_leaf=5,\n                                       min_samples_split=5), \n                random_state=5)) ])","d48df2f9":"from lightgbm import LGBMClassifier\n\n# https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html#lightgbm.LGBMClassifier\npipe_LGBM = Pipeline(\n    steps= [('preprocessor', preprocessor),\n            ('LGBM', LGBMClassifier(n_estimators=1000) ) ])","e3c7c677":"from mlxtend.classifier import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\ngbc = GradientBoostingClassifier(random_state=5, n_estimators=400, max_depth=5)\nxgb = XGBClassifier(max_depth=6, n_estimators=1000, random_state=5, nthread=-1)\nabc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=8, \n                                          min_samples_leaf=5,\n                                          min_samples_split=5), \n                         random_state=5)\nlgbm = LGBMClassifier(n_estimators=1000)\n\nlr = LogisticRegression(solver='lbfgs')\nsclf = StackingClassifier(classifiers=[gbc, xgb, abc, lgbm], \n                          meta_classifier=lr)\n\npipe_STACK_1 = Pipeline(steps=[ ('preprocessor', preprocessor),\n                                ('stack1', sclf) ])","33121082":"from sklearn.model_selection import cross_val_score\n\nlist_pipelines = [pipe_GBR, pipe_XGB, pipe_LGBM, pipe_ADA, pipe_STACK_1]\n\nprint(\"model\", \"\\t\", \"mean acc\", \"\\t\", \"std\", \"\\t\", \"\\t\", \"min acc\")\nprint(\"-+\"*30)\nfor pipe in list_pipelines :\n    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n    print(pipe.steps[1][0], \"\\t\", \n          '{:08.6f}'.format(np.mean(scores)), \"\\t\",  \n          '{:08.6f}'.format(np.std(scores)),  \"\\t\", \n          '{:08.6f}'.format(np.min(scores)))","88782604":"# Fit final model\npipe_STACK_1.fit(X_train, y_train)","32affd35":"# Create prediction\ndf_test['Age__Log'] = df_test['Age'].transform(np.log)\ndf_test['Fare__Log'] = df_test['Fare'].transform(lambda x: np.log(x + 1))\ndf_test['Cabin__FirstChar'] = df_train['Cabin'].astype(str).str[0]\ndf_test['Cabin__FirstChar'].fillna('n', inplace=True)\ndf_test['Ticket__Number'] = df_test['Ticket'].map(lambda x: ''.join(i for i in x if i.isnumeric()))\nmedian_value = df_train['Ticket__Number'].median()\ndf_test['Ticket__Number'][df_test['Ticket__Number'] == ''] = str(int(median_value))\ndf_test['Ticket__Number'] = df_test['Ticket__Number'].astype(int)\ndf_test['Ticket__Number__Log'] = df_test['Ticket__Number'].transform(np.log)\ndf_test['Ticket__Chars'] = df_test['Ticket'].map(lambda x: ''.join(i for i in x if i.isalpha()))\ndf_test['Ticket__Chars'][df_test['Ticket__Chars'] == ''] = 'missing'\ndf_test['Name__Length'] = df_test['Name'].str.len()\ndf_test['Name__Length__Log'] = df_test['Name__Length'].transform(np.log)\n\nX_test = df_test.copy()\nX_test = X_test[categorical_features + numerical_features]\n\nX_test.head()","8c80d5f0":"pred_stack1 = pipe_STACK_1.predict(X_test)\nsub_stack1 = pd.DataFrame()\nsub_stack1['PassengerId'] = df_test['PassengerId']\nsub_stack1['Survived'] = pred_stack1\n\nsub_stack1.to_csv('submission.csv', index=False)\n\nsub_stack1","fd3c9ba8":"## Create final predictions","4ade91be":"# Data exploration","a5d5d5b8":"# Model training","dfe16619":"# Load data","59c4ea6a":"## Create classification pipelines"}}