{"cell_type":{"e100e437":"code","11c01df9":"code","6c571fad":"code","a6af5656":"code","ea9a3aea":"code","75217fdd":"code","f3c053a6":"code","2f83d3aa":"code","7e5aab2f":"code","c61f53ba":"code","c31d6afe":"code","e5021324":"code","707b31f7":"code","922bcb34":"code","a41b2bb5":"code","ae5ef96a":"code","4dd26ce8":"code","ec2a104f":"code","a7137631":"code","4df938ad":"code","8718dd1f":"code","fc93efbf":"code","1517f432":"code","857fba9d":"code","d06b85db":"code","95795ef7":"code","d394f334":"code","fcfa29a6":"code","99c08b80":"code","5582c6cd":"code","2958ef6c":"code","6d13ee16":"code","cda77f0a":"code","ab82d6ed":"code","0f4f9355":"code","1855a5f1":"code","cf539978":"code","6f8e06d4":"code","e967f633":"code","eb442f9c":"code","63d1eb10":"code","a4192107":"code","0038d217":"markdown","20cf75ee":"markdown","2b26f634":"markdown","ba4dbef2":"markdown","72d9190f":"markdown","cfca6a65":"markdown","630dd060":"markdown","1b0a49c6":"markdown","fd74d4ee":"markdown","963e2dcb":"markdown","a05a4b03":"markdown","833139e8":"markdown","b305a311":"markdown","0b1da592":"markdown","9621352c":"markdown","3c6d5906":"markdown","a11c716c":"markdown","639e34e1":"markdown","19613c76":"markdown","4ac80f67":"markdown","5e2d4b26":"markdown","eb7c3a36":"markdown","f948430e":"markdown","479fe7bb":"markdown","b7462af3":"markdown","76498223":"markdown","a8777ace":"markdown","7e30e951":"markdown","fba1982a":"markdown","d1589293":"markdown","05901b0a":"markdown","718cdc24":"markdown","598e2d5c":"markdown","3e514c89":"markdown","f00f88a2":"markdown","e606ca57":"markdown","454c056b":"markdown","17a0ce64":"markdown","0c946134":"markdown","37c66d9b":"markdown","0266f6b2":"markdown","82efda8a":"markdown","0cc96f7f":"markdown","c21e70f1":"markdown","33a5b03f":"markdown","4b28048b":"markdown","8a5028ea":"markdown","754ebb98":"markdown","4921fed3":"markdown","0f385339":"markdown","211876dd":"markdown","53d0a6f6":"markdown","ac8552fa":"markdown","2386cf71":"markdown","274d2bd9":"markdown","df3171a3":"markdown","9e2cb17f":"markdown","d086e06f":"markdown","f0011d2e":"markdown","a9899db6":"markdown"},"source":{"e100e437":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn","11c01df9":"treino = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\",\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\",\n        index_col=['Id'])","6c571fad":"treino.head()","a6af5656":"treino.info()","ea9a3aea":"treino.describe()","75217fdd":"treino_copia = treino.copy()","f3c053a6":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntreino_copia['income'] = le.fit_transform(treino_copia['income'])","2f83d3aa":"sns.pairplot(treino, diag_kws={'bw':\"1.0\"}, hue = 'income', palette='viridis')","7e5aab2f":"plt.figure(figsize=(10,8))\nsns.heatmap(treino_copia.corr(), vmin=-1, vmax=1, annot=True, cmap='viridis')\nplt.show()","c61f53ba":"plt.figure(figsize=(10,8))\nsns.boxenplot(x='income', y='education.num', data=treino, palette='viridis')\nplt.title('Education.num boxenplot')","c31d6afe":"plt.figure(figsize=(10,8))\ntreino['education.num'].hist(color = 'mediumseagreen')\nplt.xlabel('education.num')\nplt.ylabel('quantity')\nplt.title('Education.num histogram')","e5021324":"plt.figure(figsize=(10,8))\nsns.boxenplot(x='income', y='age', data=treino, palette='viridis')\nplt.title('Age boxenplot')","707b31f7":"plt.figure(figsize=(10,8))\ntreino['age'].hist(color = 'mediumseagreen')\nplt.xlabel('age')\nplt.ylabel('quantity')\nplt.title('Age histogram')","922bcb34":"plt.figure(figsize=(10,8))\nsns.boxenplot(x='income', y='hours.per.week', data=treino, palette='viridis')\nplt.title('Hours.per.week boxenplot')","a41b2bb5":"plt.figure(figsize=(10,8))\ntreino['hours.per.week'].hist(color = 'mediumseagreen')\nplt.xlabel('hours.per.week')\nplt.ylabel('quantity')\nplt.title('Hours.per.week histogram')","ae5ef96a":"plt.figure(figsize=(10,8))\ntreino['capital.gain'].hist(color = 'mediumseagreen')\nplt.xlabel('capital.gain')\nplt.ylabel('quantity')\nplt.title('Capital.gain histogram')","4dd26ce8":"plt.figure(figsize=(10,8))\ntreino['capital.loss'].hist(color = 'mediumseagreen')\nplt.xlabel('capital.loss')\nplt.ylabel('quantity')\nplt.title('Capital.loss histogram')","ec2a104f":"sns.catplot(y='workclass', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Workclass catplot')","a7137631":"sns.catplot(y='education', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Education catplot')","4df938ad":"sns.catplot(y='marital.status', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Marital.status catplot')","8718dd1f":"sns.catplot(y='occupation', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Occupation catplot')","fc93efbf":"sns.catplot(y='relationship', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Relationship catplot')","1517f432":"sns.catplot(y='race', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Race catplot')","857fba9d":"plt.figure(figsize=(10, 8))\ncolors = ['darkslateblue', 'teal', 'darkcyan', 'mediumseagreen', 'yellowgreen', ]\ntreino['race'].value_counts().plot(kind = 'pie', colors=colors)","d06b85db":"income_menor = treino.loc[treino['income'] == '<=50K']\nincome_maior = treino.loc[treino['income'] == '>50K']\n\npd.concat([income_menor['race'].value_counts(), income_maior['race'].value_counts()], axis=1, keys=[\"<=50K\", \">50K\"]).plot(kind='bar', color=colors, figsize=(10,8))\nplt.xlabel('race')\nplt.ylabel('quantity')\nplt.title('Race and income comparation')","95795ef7":"sns.catplot(y='sex', x='income', kind='bar', data=treino_copia, palette='viridis', height=8)\nplt.title('Sex catplot')","d394f334":"plt.figure(figsize=(10, 8))\ntreino['sex'].value_counts().plot(kind = 'pie', colors=colors)","fcfa29a6":"pd.concat([income_menor['sex'].value_counts(), income_maior['sex'].value_counts()], axis=1, keys=[\"<=50K\", \">50K\"]).plot(kind='bar', color=colors, figsize=(10,8))\nplt.xlabel('sex')\nplt.ylabel('quantity')\nplt.title('Sex and income comparation')","99c08b80":"plt.figure(figsize=(10,8))\nsns.catplot(y='native.country', x='income', kind='bar', data=treino_copia, palette='viridis', height=8);\nplt.title('Native.country catplot')","5582c6cd":"treino[\"native.country\"].value_counts()","2958ef6c":"treino.drop_duplicates(keep='first', inplace=True)","6d13ee16":"treino = treino.drop(['fnlwgt', 'native.country', 'education'], axis=1)","cda77f0a":"Y_treino = treino.pop('income')\nX_treino = treino","ab82d6ed":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\npipeline_categ = Pipeline(steps = [\n    ('imputador', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(sparse=False))\n])","0f4f9355":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\n\npipeline_num = Pipeline(steps = [\n    ('imputer', KNNImputer(n_neighbors=5, weights=\"uniform\")),\n    ('scaler', StandardScaler())\n])","1855a5f1":"from sklearn.preprocessing import RobustScaler\n\npipeline_robust = Pipeline(steps = [\n    ('imputer', KNNImputer(n_neighbors=5, weights=\"uniform\")),\n    ('scaler', RobustScaler())\n])","cf539978":"from sklearn.compose import ColumnTransformer\n\ncolunasNumericas = list(X_treino.select_dtypes(include = [np.number]).columns.values)\ncolunasCategoricas = list(X_treino.select_dtypes(exclude = [np.number]).columns.values)\n\ncolunasNumericas.remove('capital.gain')\ncolunasNumericas.remove('capital.loss')\n\npreprocessador = ColumnTransformer(transformers = [\n    ('numerico', pipeline_num, colunasNumericas),\n    ('categorico', pipeline_categ, colunasCategoricas),\n    ('robust', pipeline_robust, ['capital.gain', 'capital.loss'])\n])","6f8e06d4":"X_treino = preprocessador.fit_transform(X_treino)","e967f633":"from sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmelhorK = 10\nmelhorAcuracia = 0.0\n\nprint('- Busca grosseira')\nfor k in [10, 20, 30]:\n    acuracia = cross_val_score(KNeighborsClassifier(n_neighbors=k), X_treino, Y_treino, cv=5, scoring='accuracy').mean()\n    print('k =', k,': Acur\u00e1cia',100 * acuracia)\n    if acuracia > melhorAcuracia:\n        melhorAcuracia = acuracia\n        melhorK = k\nprint('========')\n\nprint('- Busca fina')\nfor k in range((melhorK - 5), (melhorK + 5)):\n    acuracia = cross_val_score(KNeighborsClassifier(n_neighbors=k), X_treino, Y_treino, cv=5, scoring='accuracy').mean()\n    print('k =', k,': Acur\u00e1cia',100 * acuracia)\n    if acuracia > melhorAcuracia:\n        melhorAcuracia = acuracia\n        melhorK = k\nprint('========')\n\nprint('Melhor k:', melhorK)\nprint('Melhor acur\u00e1cia:', 100 * melhorAcuracia)","eb442f9c":"knn = KNeighborsClassifier(n_neighbors=26)\nknn.fit(X_treino, Y_treino)","63d1eb10":"teste = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\", sep=r'\\s*,\\s*', engine='python', na_values=\"?\")\nX_teste = teste.drop(['fnlwgt', 'native.country', 'education'], axis=1)\nX_teste = preprocessador.transform(X_teste)\npredicoes = knn.predict(X_teste)\n\npredicoes","a4192107":"submissao = pd.DataFrame()\nsubmissao[0] = teste.index\nsubmissao[1] = predicoes\nsubmissao.columns = ['Id', 'income']\n\nsubmissao.to_csv('submission.csv', index = False)","0038d217":"#### 2.2.3. Marital.status","20cf75ee":"Uso os mesmos artif\u00edcios usados anteriormente para este atributo.","2b26f634":"## 3. Pr\u00e9-processamento dos dados","ba4dbef2":"Importo o arquivo que ser\u00e1 classificado e removo as colunas que foram julgadas desnecess\u00e1rias:","72d9190f":"Os r\u00f3tulos do atributo **sex** n\u00e3o s\u00e3o igualmente distribu\u00eddos. Pelo gr\u00e1fico de pizza pode-se notar que existem mais homens do que mulheres na amostra. Dessa forma, recorro ao \u00faltimo gr\u00e1fico plotado para estabelecer uma rela\u00e7\u00e3o entre os dois r\u00f3tulos e a vari\u00e1vel de classe **income**. Observa-se que, para os homens, a propor\u00e7\u00e3o entre os que ganham mais do que 50K e os que ganham menos \u00e9 maior do que para as mulheres. Isso, sem d\u00favidas, evid\u00eancia uma diferen\u00e7a salarial para os dois g\u00eaneros.","cfca6a65":"#### 2.1.1. Education.num","630dd060":"Observa-se que a distribui\u00e7\u00e3o dessas duas vari\u00e1veis se d\u00e1, majoritariamente, ao redor do zero. Portanto, pode-se inferir que esse dado n\u00e3o foi coletado para a maioria da amostra. Sendo assim, essas duas vari\u00e1veis s\u00e3o poss\u00edveis candidatas, juntamente com a **fnlwgt**, para serem exclu\u00eddas do treino do modelo de classifica\u00e7\u00e3o.","1b0a49c6":"Finalmente, essa \u00faltima an\u00e1lise mostra que a maioria das pessoas tem uma jornada de trabalho de 35 \u00e0 40 horas semanais. Al\u00e9m disso, em geral, as pessoas que ganham mais que 50K tem uma jornada de trabalho de 40 \u00e0 50 horas semanais. ","fd74d4ee":"## 2. Visualiza\u00e7\u00e3o dos dados","963e2dcb":"Em seguida, removo as colunas que julgo, baseado nas discuss\u00f5es das se\u00e7\u00f5es anteriores, que n\u00e3o s\u00e3o \u00fateis para fazer o classsificador.","a05a4b03":"### 3.3. Pr\u00e9-processamento dos dados num\u00e9ricos","833139e8":"Para esse plot, fa\u00e7o algumas considera\u00e7\u00f5es. Inicialmente, vamos analisar a distribui\u00e7\u00e3o dos r\u00f3tulos desse atributo. Para isso, uso o gr\u00e1fico de pizza.","b305a311":"Finalmente, uso o `KNeighborsClassifier` e o `cross_val_score` para construir o classificador e calcular sua acur\u00e1cia. Para achar o melhor **k** uso dois la\u00e7os: um que percorre algumas dezenas e um que, achado a dezena com melhor acur\u00e1cia, procura na vizinhan\u00e7a unitariamente. \n\n","0b1da592":"#### 2.2.4. Occupation","9621352c":"Como era de se esperar, as pessoas que ganham mais do que 50K tem maior n\u00edvel de escolaridade do que as que ganham menos. Nessa vari\u00e1vel, os n\u00fameros de 1 \u00e0 16 s\u00e3o mapeamentos dos n\u00edveis de escolaridade.","3c6d5906":"Agora, basta criar o classificador kNN com esse k e submeter para avalia\u00e7\u00e3o no Kaggle:","a11c716c":"### 1.2. Importa\u00e7\u00e3o dos dados ","639e34e1":"## 4. Classificador ","19613c76":"Logo de cara, pode-se fazer alguns apontamentos:\n* A correla\u00e7\u00e3o linear entre a vari\u00e1vel e ela mesma \u00e9 perfeita e positiva, sendo assim, a diagonal principal apresenta \u03c1 = 1 e a colora\u00e7\u00e3o do limite superior da escala;\n* As vari\u00e1veis que mais influenciam no atributo **income** s\u00e3o as mais pr\u00f3ximas, em m\u00f3dulo, do zero. Em ordem decrescente, s\u00e3o elas: **education.num**, **age**, **hours.per.week**, **capital.gain** e **capital.loss**;\n* A vari\u00e1vel **fnlwgt** \u00e9 a que menos influencia no atributo **income**. Na realidade, ela \u00e9 pouco correlacionada com todas as outras vari\u00e1veis. Sendo assim, ela \u00e9 uma das poss\u00edveis vari\u00e1veis que ser\u00e1 descartada para fazer o modelo de classifica\u00e7\u00e3o.\n","4ac80f67":"Visto que o objetivo do projeto \u00e9 predizer a vari\u00e1vel de classe **income**, uso a classe LabelEncoder para transformar os dados \"<=50K\" e \">50K\" em vari\u00e1veis num\u00e9ricas. Isso facilitar\u00e1 encontrar a rela\u00e7\u00e3o entre essa vari\u00e1vel e as demais vari\u00e1veis num\u00e9ricas.","5e2d4b26":"J\u00e1 de cara, observa-se alta dispers\u00e3o dos dados dos atributos **capital.gain** e **capital.loss**. Ambos apresentam valores de desvio padr\u00e3o (**std**) consideravelmente mais altos do que suas m\u00e9dias (**mean**). ","eb7c3a36":"Inicialmente, ploto um **pairplot** que mostra a distribui\u00e7\u00e3o dos atributos com vari\u00e1veis num\u00e9ricas (diagonal principal), assim como as rela\u00e7\u00f5es entre pares de atributos.\n","f948430e":"### 1.1. Importa\u00e7\u00e3o das bibliotecas","479fe7bb":"#### 2.1.4. Capital.gain e capital.loss","b7462af3":"# PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n## Aplica\u00e7\u00e3o do classificador k-NN para a base *adult*\nGabriel Henrique de Morais, N\u00b0USP 11260940","76498223":"Um agradecimento especial ao @Bernardo_Coutinho e ao Grupo Turing pela disponibiliza\u00e7\u00e3o dos **Turing Talks**, que me ajudaram muito na realiza\u00e7\u00e3o desse trabalho.","a8777ace":"## 1. Prepara\u00e7\u00e3o dos dados","7e30e951":"Aqui \u00e9 poss\u00edvel observar que esses dados s\u00e3o extremamente desbalanceados, com os Estados Unidos tendo ocorr\u00eancia de mais de 90% em rela\u00e7\u00e3o aos demais pa\u00edses. Sendo assim, esse atributo \u00e9 um dos candidatos a serem desconsiderados para a constru\u00e7\u00e3o do classificador.","fba1982a":"### 2.1. Dados num\u00e9ricos","d1589293":"Nesta etapa, importo o arquivo da base de dados *Adults* (dispon\u00edvel no [reposit\u00f3rio UCI](https:\/\/archive.ics.uci.edu\/ml\/datasets.php)) que ser\u00e1 usado como base de treino. Para tanto, utilizo o m\u00e9todo `read_csv` da biblioteca **pandas**. Al\u00e9m disso, marco a coluna 'Id' como a coluna de \u00edndices. Os dados com \"?\" ser\u00e3o especificados como dados faltantes.\n\n","05901b0a":"Essas duas vari\u00e1veis s\u00e3o as que apresentam desvio padr\u00e3o elevado, como apontado no final da se\u00e7\u00e3o **1.2. Importa\u00e7\u00e3o dos dados**. Ploto os seus histogramas para an\u00e1lise:","718cdc24":"### 3.2. Pr\u00e9-processamento dos dados categ\u00f3ricos","598e2d5c":"Nesta se\u00e7\u00e3o, busco fazer uma an\u00e1lise mais profunda dos dados. Para isso, fa\u00e7o uso de artif\u00edcios visuais para melhorar o entendimento dos dados. Come\u00e7o fazendo uma c\u00f3pia dos dados. Essa c\u00f3pia ser\u00e1 usada apenas nessa se\u00e7\u00e3o para auxiliar o processo de visualiza\u00e7\u00e3o.\n\n\n","3e514c89":"Agora, fa\u00e7o uma r\u00e1pida apresenta\u00e7\u00e3o dos tr\u00eas atributos que mais influenciam o **income** e uma breve considera\u00e7\u00e3o sobre eles. Para tal, uso **boxenplots** e **histogramas**. O primeiro apresenta uma an\u00e1lise visual da posi\u00e7\u00e3o, dispers\u00e3o, simetria, caudas e valores discrepantes (outliers) do conjunto de dados, j\u00e1 o segundo evidencia estimativas de n\u00facleos de densidade da distribui\u00e7\u00e3o de cada vari\u00e1vel.","f00f88a2":"Ou seja, a maioria das pessoas do banco de dados s\u00e3o brancas. Al\u00e9m disso, elas est\u00e3o entre as que mais ganham. Podemos fazer outra ressalva: a m\u00e9dia da diferen\u00e7a salarial entre os brancos \u00e9 pequena. Ela \u00e9 evidenciada pelo tra\u00e7o horizontal preto no **catplot** que \u00e9 curto. Por outro lado, apesar dos povos asi\u00e1ticos das ilhas do Pac\u00edfico ganharem mais do que os brancos, a diferen\u00e7a salarial entre pessoas desse mesmo grupo \u00e9 maior.\nAgora, fa\u00e7o um gr\u00e1fico que explicita essas diferen\u00e7as. ","e606ca57":"#### 2.2.1. Workclass","454c056b":"Fa\u00e7o tamb\u00e9m o tratamento de dois atributos com alta dispers\u00e3o, conforme observado nas se\u00e7\u00f5es anteriores: **capital.gain** e **capital.loss**. Para isso, uso o `RobustScaler`.","17a0ce64":"## 5. Submiss\u00e3o","0c946134":"#### 2.2.5. Relationship","37c66d9b":"#### 2.2.6. Race","0266f6b2":"J\u00e1 de cara, pode-se notar algumas coisas interessantes. O desvio (representado pelo tra\u00e7o horizontal preto) \u00e9 muito grande para a maioria dos pa\u00edses. Portanto, para analisar melhor esses dados, uso o m\u00e9todo `value_counts`.","82efda8a":"### 3.4. Aplica\u00e7\u00e3o dos pr\u00e9-processamentos ","0cc96f7f":"Portanto, o melhor **k** \u00e9 26 e a acur\u00e1cia fica em 84.9397%. A **acur\u00e1cia** \u00e9 obtida com 1 - (taxa de erro) e pode ser entendida como a proximidade entre o valor obtido e o valor real. ","c21e70f1":"#### 2.1.2. Age\n","33a5b03f":"Nesta se\u00e7\u00e3o, sigo as dicas disponibilizadas no \"Turing Talks\" sobre [limpeza de dados](https:\/\/medium.com\/turing-talks\/como-fazer-uma-limpeza-de-dados-completa-em-python-7abc9dfc19b8). Meus agradecimentos ao @Bernardo_Coutinho pela sugest\u00e3o! :)\n\nCome\u00e7o ent\u00e3o pela exlus\u00e3o dos dados repetidos. Para isso, uso o m\u00e9todo `drop_duplicates`.","4b28048b":"Agora, separo a vari\u00e1vel de classe **income** do resto do banco de dados.","8a5028ea":"Em seguida, busco fazer uma an\u00e1lise mais detalhada da correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas com uso de um **heatmap**. A constru\u00e7\u00e3o de um **heatmap** \u00e9 baseada no coeficiente de correla\u00e7\u00e3o de Pearson (\u03c1), que mede a correla\u00e7\u00e3o entre duas vari\u00e1veis. Esse coeficiente assume valores de -1 a 1.\n*   \u03c1 = 1: correla\u00e7\u00e3o perfeita positiva entre as duas vari\u00e1veis;\n*   \u03c1 = 0: duas vari\u00e1veis n\u00e3o dependem linearmente uma da outra\n*   \u03c1 = -1: correla\u00e7\u00e3o negativa perfeita entre as duas vari\u00e1veis.\n\nCabe mencionar que o coeficiente de correla\u00e7\u00e3o de Pearson avalia apenas rela\u00e7\u00f5es lineares de depend\u00eancia. Para analisar outros graus de depend\u00eancia pode-se usar outros coeficiente, como o coeficiente de correla\u00e7\u00e3o de postos de Spearman, que avalia rela\u00e7\u00f5es mon\u00f3tonas, sejam elas lineares ou n\u00e3o.","754ebb98":"#### 2.2.7. Sex","4921fed3":"Agora, utilizo os m\u00e9todos `head` e `info` para ter uma vis\u00e3o geral dos dados e das vari\u00e1veis do banco de dados.","0f385339":"#### 2.1.3. Hours.per.week","211876dd":"#### 2.2.2. Education","53d0a6f6":"### 2.2. Dados categ\u00f3ricos","ac8552fa":"A amostra da popula\u00e7\u00e3o considerada pelo banco de dados se distribui de maneira assim\u00e9trica \u00e0 esquerda, de forma que as idades mais comuns estejam entre 20 e 45 anos. Al\u00e9m disso, a maioria das pessoas que ganham mais do que 50K tem entre 35 e 50 anos e a maioria que ganha menos do que 50K tem entre 25 e 45 anos.","2386cf71":"### 3.1. Limpeza dos dados ","274d2bd9":"Come\u00e7o completando os dados faltantes dos atributos categ\u00f3ricos com a classe `SimpleImputer`. Atrav\u00e9s da estrat\u00e9gia `most_frequent`, ser\u00e1 poss\u00edvel completar os dados faltantes com a moda amostral do atributo.\nConcomitantemente, transformo os dados categ\u00f3ricos em num\u00e9ricos, j\u00e1 que o k-NN calcular\u00e1 a dist\u00e2ncia euclidiana e, portanto, os dados devem ser n\u00fameros. Para essa transforma\u00e7\u00e3o, uso o `One Hot Encoder`. Finalmente, construo a **Pipeline**, que re\u00fane as instru\u00e7\u00f5es que ser\u00e3o realizadas.","df3171a3":"Com isso, observa-se algumas caracter\u00edsticas:\n\n\n*   Existem 15 colunas no dataframe: 1 de vari\u00e1vel de classe (**income**) e 14 de atributos;\n*   6 colunas cont\u00e9m dados num\u00e9ricos;\n*   As colunas **workclass** e **occupation** s\u00e3o as que t\u00eam mais dados faltantes, com 1836 e 1843, respectivamente.\n\nNeste momento, busco usar ferramentas da estat\u00edstica descritiva para caracterizar as partes da amostra que usam vari\u00e1veis num\u00e9ricas. Para isso, uso o m\u00e9todo `describe`.\n\n\n\n","9e2cb17f":"\nInicialmente, importo as bibliotecas que ser\u00e3o utilizadas ao longo deste projeto.","d086e06f":"Para essa etapa, analizo as vari\u00e1veis que n\u00e3o s\u00e3o num\u00e9ricas, s\u00e3o elas: **workclass**, **education**, **marital.status**, **occupation**, **relationship**, **race**, **sex** e **native.country**. Para analisar essas vari\u00e1veis, uso **catplots**, para estabelecer uma rela\u00e7\u00e3o entre o atributo e a vari\u00e1vel de classe **income**.","f0011d2e":"#### 2.2.8. Native.country","a9899db6":"Come\u00e7o completando os dados faltantes dos atributos num\u00e9ricos com o `KNNImputer`. Em seguida, fa\u00e7o a normaliza\u00e7\u00e3o dos dados, para que as dist\u00e2ncias euclidiana n\u00e3o sofram influ\u00eancia da cardinalidade dos atributos. Para isso, uso o `StandardScaler`."}}