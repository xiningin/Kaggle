{"cell_type":{"20919b4b":"code","456a3cc8":"code","f7a76b4f":"code","d08aa6fe":"code","3cd68b46":"code","a53f574f":"code","034da0dc":"code","69405e9f":"code","153019d4":"code","5b8a0ed2":"code","59f49e9c":"code","5c8f6a2f":"code","22fd368b":"markdown","05b420bb":"markdown"},"source":{"20919b4b":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom tqdm import tqdm\nfrom sklearn.svm import SVC\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input\nfrom keras.layers.recurrent import LSTM, GRU\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import concatenate\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import make_union\n\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import Callback, EarlyStopping\nfrom nltk import word_tokenize","456a3cc8":"# read data to dataframe\ndf_train = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv')\ndf_test = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv')\n\nprint('train shape {} rows, {} cols'.format(*df_train.shape))\nprint('test shape {} rows, {} cols'.format(*df_test.shape))","f7a76b4f":"X_train = df_train[\"comment_text\"].fillna(\"fillna\").values\ny_train = df_train[[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n]].values\nX_test = df_test[\"comment_text\"].fillna(\"fillna\").values\n\nmax_features = 30000\nmaxlen = 100\nembed_size = 300\n\ntokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train) + list(X_test))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)\nx_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n\nEMBEDDING_FILE = '..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec'\n\n\ndef get_coefs(word, *arr):\n  return word, np.asarray(arr, dtype='float32')\n\n\nembeddings_index = dict(\n    get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n\nword_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_size))\nfor word, i in word_index.items():\n  if i >= max_features:\n    continue\n  embedding_vector = embeddings_index.get(word)\n  if embedding_vector is not None:\n    embedding_matrix[i] = embedding_vector","d08aa6fe":"from sklearn.metrics import roc_auc_score\n\nclass RocAucEvaluation(Callback):\n\n  def __init__(self, validation_data=(), interval=1):\n    super(Callback, self).__init__()\n\n    self.interval = interval\n    self.X_val, self.y_val = validation_data\n\n  def on_epoch_end(self, epoch, logs={}):\n    if epoch % self.interval == 0:\n      y_pred = self.model.predict(self.X_val, verbose=0)\n      score = roc_auc_score(self.y_val, y_pred)\n      print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch + 1, score))","3cd68b46":"def get_model():\n  inp = Input(shape=(maxlen,))\n  x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n  x = SpatialDropout1D(0.2)(x)\n  x = Bidirectional(GRU(80, return_sequences=True))(x)\n  avg_pool = GlobalAveragePooling1D()(x)\n  max_pool = GlobalMaxPooling1D()(x)\n  conc = concatenate([avg_pool, max_pool])\n  outp = Dense(6, activation=\"sigmoid\")(conc)\n\n  model = Model(inputs=inp, outputs=outp)\n  model.compile(\n      loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n  return model","a53f574f":"model = get_model()","034da0dc":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","69405e9f":"model.summary()","153019d4":"batch_size = 32\nepochs = 500\n\nX_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)","5b8a0ed2":"roc_auc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n\nhist = model.fit(X_tra, y_tra, \n                 batch_size=batch_size, \n                 epochs=epochs, \n                 validation_data=(X_val, y_val),\n                 callbacks=[roc_auc, EarlyStopping(patience=10)], verbose=2)","59f49e9c":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","5c8f6a2f":"y_pred = model.predict(x_test, batch_size=1024)\nsubmission = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv')\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv('submission.csv', index=False)","22fd368b":"9,184,806 parameters shoul be trained.","05b420bb":"# Toxic comment classification via pooled GRU and FastText"}}