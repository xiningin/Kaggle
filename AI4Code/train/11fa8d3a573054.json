{"cell_type":{"0a609be7":"code","dc935583":"code","bcc50e1d":"code","dfe2f59f":"code","f56dfceb":"code","0967bff1":"code","b04ebadf":"code","56b1e67d":"code","dbafcc42":"code","5bc3ec78":"code","814ff706":"code","8d1fd292":"code","e6d6eda4":"code","591cfb92":"code","d5396e4b":"code","b14027c3":"code","1f191d13":"code","f4133a5f":"code","506597bb":"code","4d9d33c6":"code","05a82b75":"code","4d76d158":"code","8938d0c5":"code","15619605":"code","285acf9d":"code","6bc9d23d":"code","8a48e519":"code","3f855a65":"code","d63cf9fa":"code","682208e1":"code","06a013fc":"code","a3241e6c":"code","67e74dc3":"code","c6d0b35f":"code","45df3e06":"code","c5271ac0":"code","2e9335d8":"code","32ae5896":"code","f378dc04":"code","ebb3a18f":"code","55327fde":"code","c193aa23":"markdown","3fcd4183":"markdown","85474e33":"markdown","9070d67e":"markdown","d9acfb99":"markdown","6525ed97":"markdown","8704dde4":"markdown","6a38090f":"markdown","ee258894":"markdown","5dc5e7e2":"markdown","050ef3dd":"markdown","718692a0":"markdown","4527254e":"markdown","871f0c92":"markdown","e7e0a520":"markdown","90b98f44":"markdown","2a7b3287":"markdown","754aaee0":"markdown","b35071bd":"markdown","6e069178":"markdown","9d56a533":"markdown","c296aa70":"markdown","831d861b":"markdown","89ac2b19":"markdown","b2f10a34":"markdown","f3d8fc4b":"markdown","4ca53096":"markdown","482f2138":"markdown","687752f0":"markdown","b7b9f4e1":"markdown","f37598e0":"markdown","8103f432":"markdown","bab66a19":"markdown","fcfbf02a":"markdown","0d20df81":"markdown","16949290":"markdown","e94c7108":"markdown","cb362d9b":"markdown","25767ece":"markdown","a0873e4a":"markdown","91cd6d40":"markdown","9c911062":"markdown","fb683a31":"markdown","0988917c":"markdown","55cd29d7":"markdown","c0de3181":"markdown","76e41b34":"markdown","28682a1b":"markdown","2d041ff2":"markdown","6036b13e":"markdown"},"source":{"0a609be7":"import os\nimport random\nimport gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\nimport tensorflow as tf\nfrom keras.utils.vis_utils import plot_model\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","dc935583":"tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nlen(tf.config.list_physical_devices('GPU'))","bcc50e1d":"seed = 666\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)                      \nrandom.seed(666)","dfe2f59f":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(f\"Training observations {train.shape[0]}, Test observations {test.shape[0]} \\n\")\n\ntrain.head()","f56dfceb":"fig, ax = plt.subplots(figsize = (8, 4))\n\nsns.countplot(data = train, x = \"label\", ax = ax, color = \"#101820\")\n\nax.set_title(\"Countplot for Train Labels\")\n\nsns.despine()\nplt.show()","0967bff1":"train_X = train.drop(\"label\", axis = 1)\ntrain_y = train[\"label\"]\n\ndel train\n_ = gc.collect()","b04ebadf":"train_X = train_X \/ 255\nX_test = test \/ 255\n\ndel test\n_ = gc.collect()","56b1e67d":"print(f\"Training data shape: {train_X.shape} \\nTest data shape: {X_test.shape}\")\n\ntrain_X = train_X.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)\n\nprint(f\"Training data shape after rescaling: {train_X.shape} \\nTest data shape after rescaling: {X_test.shape}\")","dbafcc42":"train_y = to_categorical(train_y, num_classes = 10)","5bc3ec78":"fig = plt.figure(1, figsize = (8, 8))\nfig.suptitle(\"Training Set Images (Sample)\")\n\nfor i in range(100):\n    \n    plt.subplot(10, 10, i + 1)\n    plt.imshow(train_X[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","814ff706":"fig = plt.figure(1, figsize = (8, 8))\nfig.suptitle(\"Test Set Images (Sample)\")\n\nfor i in range(100):\n    \n    plt.subplot(10, 10, i + 1)\n    plt.imshow(X_test[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","8d1fd292":"X_train, X_val, y_train, y_val = train_test_split(train_X, \n                                                  train_y, \n                                                  test_size = 0.1, \n                                                  random_state = 666, \n                                                  stratify = train_y)\n\nprint(f\"Training set shape: {X_train.shape} \\nValidation set shape: {X_val.shape}\")","e6d6eda4":"def simple_model():\n    \n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),\n            \n            Flatten(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n    \n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","591cfb92":"model = simple_model()\nmodel.summary()","d5396e4b":"print(\"Simple Model Architecture\\n\")\nplot_model(model, to_file = \"simple_model.png\", show_shapes = True, show_layer_names = True)","b14027c3":"history = model.fit(\n    X_train, y_train, \n    validation_data = (X_val, y_val),\n    epochs = 10, batch_size = 64\n)","1f191d13":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(10), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(10), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(10), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(10), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","f4133a5f":"datagen = ImageDataGenerator(\n    rotation_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    zoom_range = 0.15,\n    horizontal_flip = False, \n    vertical_flip = False\n)","506597bb":"sample_image = 12345\n\nplt.imshow(X_train[sample_image], cmap = plt.cm.binary)\nplt.title(\"Original Image\")\nplt.axis(\"off\"); plt.show()\n\naug = datagen.flow(X_train[sample_image].reshape(-1, 28, 28, 1), batch_size = 1)\n\nfig, axes = plt.subplots(3, 10, figsize = (15, 6))\naxes = axes.ravel()\n\nfor i in range(30):  \n    \n    aug_img = next(aug)[0]\n    axes[i].imshow(aug_img, cmap = plt.cm.binary)\n    axes[i].axis(\"off\")\n    \nplt.show()","4d9d33c6":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = simple_model()\n\nmodel.summary()","05a82b75":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 10, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] \/\/ 64\n)","4d76d158":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(10), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(10), y = history.history[\"val_loss\"], ax = axes[0], label = \"Valiidation Loss\")\n\nsns.lineplot(x = range(10), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(10), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","8938d0c5":"def simple_extra_layers():\n\n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),\n\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),   \n            Dropout(0.3),\n\n            Flatten(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n\n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","15619605":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = simple_extra_layers()\n\nmodel.summary()","285acf9d":"print(\"Adding a few extra layers to Simple Model\\n\")\n\nplot_model(model, to_file = \"few_extra_layers_model.png\", show_shapes = True, show_layer_names = True)","6bc9d23d":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 10, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] \/\/ 64\n)","8a48e519":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","3f855a65":"def final_model():\n\n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            BatchNormalization(),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            MaxPool2D(pool_size = (2, 2)),\n\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            MaxPool2D(pool_size = (2, 2)),   \n            Dropout(0.3),\n            \n            Flatten(),\n            Dense(units = 128, activation = \"relu\"),\n            BatchNormalization(),\n            Dense(units = 64, activation = \"relu\"),\n            BatchNormalization(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n\n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","d63cf9fa":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = final_model()\nmodel.summary()","682208e1":"print(\"Final Model Archtitecture\\n\")\n\nplot_model(model, to_file = \"final_model.png\", show_shapes = True, show_layer_names = True)","06a013fc":"reduce_lr = ReduceLROnPlateau(\n    monitor = \"val_accuracy\", \n    patience = 3,\n    verbose = 1, \n    factor = 0.5, \n    min_lr = 0.0000001\n)\n\nearly_stopping = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 10,\n    verbose = 1,\n    mode = \"max\",\n)\n\ncheckpoint = ModelCheckpoint(\n    monitor = \"val_accuracy\",\n    filepath = \"mnist_cnn.{epoch:02d}-{val_accuracy:.6f}.hdf5\",\n    verbose = 1,\n    save_best_only = True, \n    save_weights_only = True\n)","a3241e6c":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 100, batch_size = 64, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] \/\/ 64,\n    callbacks=[reduce_lr, early_stopping, checkpoint]\n)","67e74dc3":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = final_model()\nmodel.load_weights(\".\/mnist_cnn.24-0.996429.hdf5\")","c6d0b35f":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","45df3e06":"val_preds = np.argmax(model.predict(X_val), axis = 1)\ntrain_preds = np.argmax(model.predict(X_train), axis = 1)","c5271ac0":"fig, axes = plt.subplots(1, 2, figsize = (18, 6))\n\ncm_train = confusion_matrix(np.argmax(y_train, axis = 1), train_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm_train)\ndisp.plot(cmap = plt.cm.Blues, ax = axes[0])\n\ncm_val = confusion_matrix(np.argmax(y_val, axis = 1), val_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm_val)\ndisp.plot(cmap = plt.cm.Blues, ax = axes[1])\n\naxes[0].set_title(\"Training Set\"); axes[1].set_title(\"Validation Set\")\n\nplt.show()","2e9335d8":"errors = (val_preds - np.argmax(y_val, axis = 1) != 0)\n\npred_error = val_preds[errors]\nobserved_error = np.argmax(y_val, axis = 1)[errors]\nimage_error = X_val[errors]\nlen(pred_error)","32ae5896":"fig = plt.figure(1, figsize=(10, 10))\nfig.suptitle(\"Errors in Validation\")\n\nrows = int(len(pred_error) ** 0.5) - 1\ncols = int(len(pred_error) \/ rows) + 1\n\nfor i in range(len(pred_error)):\n    \n    plt.subplot(rows, cols, i + 1)\n    plt.imshow(image_error[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    plt.title(f\"True Value: {observed_error[i]} \\nPrediction: {pred_error[i]}\")\n    \nplt.tight_layout()\nplt.show()","f378dc04":"errors = (train_preds - np.argmax(y_train, axis = 1) != 0)\n\ntrain_pred_error = train_preds[errors]\ntrain_observed_error = np.argmax(y_train, axis = 1)[errors]\ntrain_image_error = X_train[errors]\nlen(train_pred_error)","ebb3a18f":"fig = plt.figure(1, figsize = (15, 10))\nfig.suptitle(\"Errors in Training\")\n\nrows = int(len(train_pred_error) ** 0.5) - 1\ncols = int(len(train_pred_error) \/ rows) + 1\n\nfor i in range(len(train_pred_error)):\n    \n    plt.subplot(rows, cols, i + 1)\n    plt.imshow(train_image_error[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    plt.title(f\"True Value: {train_observed_error[i]} \\nPrediction: {train_pred_error[i]}\")\n    \nplt.tight_layout()\nplt.show()","55327fde":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\n\npreds = np.argmax(model.predict(X_test), axis = 1)\nsubmission[\"Label\"] = preds\nsubmission.to_csv(\"cnn.csv\",index = False)\nsubmission","c193aa23":"<a id=\"section-four-two\"><\/a>\n\n## 4.2 Feed Model with Augmented Data","3fcd4183":"<a id=\"section-read\"><\/a>\n\n# Readings, Resources","85474e33":"[take me to the top](#section-top)","9070d67e":"Nice, there is no problem. But now, let's look at the predictions.","d9acfb99":"Converting label to one hot vectors.","6525ed97":"I just add 2 convolutional layer with 64 filters, max pooling again and 0.3 dropout. We still have a simple model.","8704dde4":"[take me to the top](#section-top)","6a38090f":"[take me to the top](#section-top)","ee258894":"In machine learning - deep learning, I think, the most important think is to know what you do. If you have knowledge about how they work, you can code it without much effort. Try lots of things, fail, add or change something, fail, try different idea, fail. Finally, you can success.\n\nIt is like a computer game.","5dc5e7e2":"[take me to the top](#section-top)","050ef3dd":"Setting seed for reproducibility\n\nhttps:\/\/www.kaggle.com\/lbronchal\/keras-gpu-cpu-reproducibility-test","718692a0":"You can see 100 images from training set from below.","4527254e":"Hard to detect for human eyes.","871f0c92":"High bias problem remains. If we increase epoch number, this problem could be solved. Or adding more layers, for example Batch Normalization can be helpful for converging faster.","e7e0a520":"<a id=\"section-conc\"><\/a>\n\n# Conclusion","90b98f44":"At the top, we can see a random original image from training set.\n\nAt the bottom, we have its 30 copies with some rotation, shifting, etc.","2a7b3287":"[take me to the top](#section-top)","754aaee0":"[take me to the top](#section-top)","b35071bd":"You can see 100 images from test set from below. A couple of them is really hard to detectable, isn't it?","6e069178":"We have quitely balanced dataset, nice.","9d56a533":"[take me to the top](#section-top)","c296aa70":"Converting images to gray scale. It helps to converge CNN quickly.","831d861b":"<a id=\"section-six\"><\/a>\n\n# 6. Final Model","89ac2b19":"[take me to the top](#section-top)","b2f10a34":"[take me to the top](#section-top)","f3d8fc4b":"Okay, our model didn't learn well, high bias. We use 10 epochs, we can increase that. Or, We can create bigger network and then we will look at what did happened.","4ca53096":"<a id=\"section-top\"><\/a>\n# Table of Contents\n* [Introduction](#section-intro)\n* [1. Basic Processing, Data Preparation](#section-one)\n* [2. Visualizing Images](#section-two)\n* [3. Simple Model](#section-three)\n* [4. Simple Model with Data Augmentation](#section-four)\n    * [4.1 Data Augmentation](#section-four-one)\n    * [4.2 Feed Model with Augmented Data](#section-four-two)\n\n\n* [5. Adding few Layers](#section-five)\n* [6. Final Model](#section-six)\n* [7. Interpreting Results and Error Analysis](#section-seven)\n    * [7.1 Confusion Matrix](#section-seven-one)\n    * [7.2 Error Analysis](#section-seven-two)\n\n\n\n* [Conclusion](#section-conc)\n* [Readings, Resources](#section-read)","482f2138":"<a id=\"section-two\"><\/a>\n\n# 2. Visualizing Images","687752f0":"<a id=\"section-one\"><\/a>\n\n# 1. Basic Processing, Data Preparation","b7b9f4e1":"I just add BatchNormalization after convolutional layers and also, two fully connected layers (128 - 64 units) with batch normalization added before the output layer.","f37598e0":"<a id=\"section-intro\"><\/a>\n# Introduction\nIn this notebook, I will build a CNN network layer by layer. Visualize observations and results. Try something and see results. It is deep learning, enjoy it.","8103f432":"<a id=\"section-four-one\"><\/a>\n\n## 4.1 Data Augmentation","bab66a19":"<a id=\"section-five\"><\/a>\n\n# 5. Adding few Layers","fcfbf02a":"First, I will create a simple CNN model to see what we need. After looking first results, I will add some layers or doing something.\n\nFor first model, I will just use two convolutional layer with 32 filter, 3 kernel size with relu activation. Then, max pooling with (2, 2) pool size.","0d20df81":"<a id=\"section-seven-one\"><\/a>\n\n## 7.1 Confusion Matrix","16949290":"<a id=\"section-seven\"><\/a>\n\n# 7. Interpreting Results and Error Analysis","e94c7108":"Okay, we have overfitting situation. We have high balance. To solve it, we can get more data. Data augmentation is one of the most important techniques for this situation, since we are working on image data.","cb362d9b":"[take me to the top](#section-top)","25767ece":"Let's look at confusion matrix. Two things are noticeable. There is a confusion between 4-9 and 1-7.\n\nWe can see this problem both sets. \n\nOne more thing. I want to know how the model fails at 4-9. Let's look at images that the model predict wrong.","a0873e4a":"<a id=\"section-three\"><\/a>\n\n# 3. Simple Model","91cd6d40":"Now, I will use same model with augmented dataset. Let's examine it and then see what we will do.","9c911062":"<a id=\"section-four\"><\/a>\n\n# 4. Simple Model with Data Augmentation","fb683a31":"https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6?rvi=1\n\nhttps:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist\n\nhttps:\/\/www.kaggle.com\/lbronchal\/keras-gpu-cpu-reproducibility-test\n\n\nAndrew NG's Deep Learning course is as good as his Machine Learning course. If you need theory, you should look at it.\n\nhttps:\/\/keras.io\/examples\/vision\/\n\nFinally, I want to say that, Keras has one of the best documentations that I read. You should take a look at. It will motivate you.","0988917c":"If we use more epochs, some callbacks will help us to prevent overfitting problem.\n\nReduceLROnPPlateau, reduces learning rate during training. It monitors a metric or loss, if results are not going well, it reduces learning rate.\n\nEarlyStopping, stops training if validation score doesn't improve. Important for prevent overfitting.\n\nCheckpoint, saves model when validation score improves.","55cd29d7":"Creating validation set with 10% of training data. It is enough.\n\nI also set stratify parameter for equally distributed labels.","c0de3181":"[take me to the top](#section-top)","76e41b34":"We have 784 pixel data, it means 28*28 pixel images.","28682a1b":"[take me to the top](#section-top)","2d041ff2":"<a id=\"section-seven-two\"><\/a>\n\n## 7.2 Error Analysis","6036b13e":"We can create new images with using ImageDataGenerator class from Keras.\n\nIt takes an image, rotates, shifts, zooms etc.\n\nBut we have to be careful. We are working with number images and some augmentations could hurt our model. For example, if we use flipping, we get meaningles images, and for some numbers i.e. 6 and 9, it will cause a problem."}}