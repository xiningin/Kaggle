{"cell_type":{"dd79e6d6":"code","26453e7a":"code","1cac3dee":"code","313e9db9":"code","15827082":"code","3f776e08":"code","af6c7ce7":"code","e45695d9":"code","69d09c96":"code","a9f25971":"code","f13b3006":"code","3f671012":"code","79f86da0":"code","d30030b0":"code","96b1ed95":"code","b3a64276":"code","d35b66cd":"code","b094834d":"code","46cd2d51":"code","bf4e75eb":"code","44cc795e":"code","9a5e43cb":"code","8fa93c4b":"code","84683637":"code","f247d225":"code","a91c7fa1":"code","740fea08":"markdown","9739f19d":"markdown","049545a3":"markdown","3b87550f":"markdown","b859e1bd":"markdown","8941c4f8":"markdown","12673f5b":"markdown","d2998792":"markdown","46a84001":"markdown","7e42ae65":"markdown"},"source":{"dd79e6d6":"import warnings\nwarnings.filterwarnings(\"ignore\")","26453e7a":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","1cac3dee":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","313e9db9":"train_df.head()","15827082":"test_df.head()","3f776e08":"train_df = train_df.drop(columns = ['Name','Ticket','Cabin'])\ntest_df  = test_df.drop(columns = ['Name','Ticket','Cabin'])","af6c7ce7":"print(\"Training data NaN frequency: \\n\",train_df.isnull().sum(),end=\"\\n\\n\")\nprint(\"Testing data NaN frequency: \\n\", test_df.isnull().sum())","e45695d9":"whole_data=[train_df,test_df]\nfor data in whole_data:\n    mean = data[\"Age\"].mean()\n    std = data[\"Age\"].std()\n    data_isnull=data['Age'].isnull().sum()\n    random_arengment = np.random.randint(mean - std, mean + std, size = data_isnull)\n\n    \n    slice_=data['Age'].copy()\n    slice_[np.isnan(slice_)]=random_arengment\n    data[\"Age\"]=slice_\n    data[\"Age\"]=data[\"Age\"].astype(int)","69d09c96":"grouped = train_df.groupby(by='Embarked').count()['PassengerId']\nmost_frequent_count = max(grouped)\n\nmost_frequent_val = grouped.index[grouped==most_frequent_count][0]\n\nwhole_data=[train_df,test_df]\n\nfor data in whole_data:\n    data['Embarked']=data['Embarked'].fillna(most_frequent_val)","a9f25971":"missing_fare_class = test_df[test_df['Fare'].isna()]['Pclass'].values[0]\nfares_subset = test_df[test_df['Pclass']==missing_fare_class]\n\nfsm = np.round(fares_subset['Fare'].mean(),4) #fsm -> fares_subset_mean\n\nna_index = test_df.index[test_df['Fare'].isna()][0]\n\ntest_df.loc[na_index,'Fare']=fsm","f13b3006":"print(\"Training data NaN frequency: \\n\",train_df.isnull().sum(),end=\"\\n\\n\")\nprint(\"Testing data NaN frequency: \\n\", test_df.isnull().sum())","3f671012":"encoder = LabelEncoder()\n\ntrain_df['Embarked'] = encoder.fit_transform(train_df['Embarked'])\ntrain_df['Sex'] = encoder.fit_transform(train_df['Sex'])\n\ntest_df['Embarked'] = encoder.fit_transform(test_df['Embarked'])\ntest_df['Sex'] = encoder.fit_transform(test_df['Sex'])","79f86da0":"test_df","d30030b0":"#Training data\nxtr , ytr = (np.array(train_df.drop(columns=['PassengerId','Survived'])),np.array(train_df['Survived']))\n\n#Testing data\nxte = np.array((test_df.drop(columns=['PassengerId']))) \ntest_indexs = np.array(test_df['PassengerId'])","96b1ed95":"scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n\nxtr = scaler.fit_transform(xtr)\nxte = scaler.fit_transform(xte)","b3a64276":"model1 = LogisticRegression()\nmodel1.fit(xtr,ytr)\n\nprint(\"Training accuracy: \" ,model1.score(xtr,ytr)*100,\"%\")","d35b66cd":"model2 = DecisionTreeClassifier()\nmodel2.fit(xtr,ytr)\n\nprint(\"Training accuracy: \" ,model2.score(xtr,ytr)*100,\"%\")","b094834d":"model3 = RandomForestClassifier(criterion=\"entropy\")\nmodel3.fit(xtr,ytr)\n\nprint(\"Training accuracy: \" ,model3.score(xtr,ytr)*100,\"%\")","46cd2d51":"model4 = SVC(C=10)\nmodel4.fit(xtr, ytr)\nprint(\"Training accuracy: \" ,model4.score(xtr,ytr)*100,\"%\")","bf4e75eb":"model5 = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',learning_rate=0.4)\nmodel5.fit(xtr,ytr)\n\nprint(\"Training accuracy: \" ,model5.score(xtr,ytr)*100,\"%\")","44cc795e":"model = KNeighborsClassifier(n_neighbors=2)\nmodel.fit(xtr,ytr)\n\nprint(\"Training accuracy: \" ,model.score(xtr,ytr)*100,\"%\")","9a5e43cb":"optim = Adam(\n    learning_rate=0.001,\n)\n\nmodel6 = Sequential()\n\nmodel6.add(Dense(11, input_shape=(xtr.shape[1],), activation='relu',kernel_initializer='normal'))\nmodel6.add(Dense(7, activation='relu',kernel_initializer='normal'))\n\n\nmodel6.add(Dense(1, activation='sigmoid'))\nmodel6.summary() \n\nmodel6.compile(optimizer=optim, loss='binary_crossentropy',metrics='accuracy')\n\n\nes = EarlyStopping(monitor='val_accuracy', mode='max',patience=10,restore_best_weights=True)\n\nhistory = model6.fit(xtr,ytr,callbacks=[es],epochs=100,batch_size=1,validation_split = 0.1,shuffle=True)","8fa93c4b":"predictions=(model6.predict(xte) > 0.5).astype('int32').reshape(len(xte),)","84683637":"predictions","f247d225":"submission_df = pd.DataFrame()\nsubmission_df['PassengerId']=test_indexs\nsubmission_df['Survived']=predictions","a91c7fa1":"submission_df.to_csv(\"submission.csv\",index=False)","740fea08":"<p style = \"font-size: 120%\"> Let's check once again <\/p>","9739f19d":"<h2> Preparing models <\/h2>","049545a3":"Since we know that tickets are divided by socio-economic status, we can inpute missing ticket values by mean of their corresponding class","3b87550f":"<h2> Saving results for submission <\/h2>","b859e1bd":"<p style=\"font-size: 120%\"> Dealing with missing Embarked <\/p>","8941c4f8":"<p style=\"font-size: 120%\"> Dealing with missing Fare data <\/p>","12673f5b":"<h2> Processing Data <\/h2>","d2998792":"<h2> Reading Data <\/h2>","46a84001":"<p style=\"font-size: 120%\" > Dealing with missing age values<\/p>","7e42ae65":"<p style=\"font-size: 120%\">You might save and submit prediction results of each model one by one to check which one is better. For demonstration purposes I have done only for one of them.<\/p>"}}