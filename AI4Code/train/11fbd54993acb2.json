{"cell_type":{"733d5792":"code","474fbe48":"code","0f7a2b04":"code","8446486a":"code","c52a31cd":"code","5689dbf5":"code","3c720091":"code","ec68245b":"code","0bdaa666":"code","bd197a2b":"code","ab8de041":"code","7136dbae":"code","7e3c0b32":"code","d995506c":"code","9bfcd514":"code","24def257":"code","c4b69ec0":"code","f63620cf":"markdown","85e1a7ab":"markdown","a37ad19c":"markdown","50947a12":"markdown","eaa2ab90":"markdown","b392985e":"markdown","268f8b18":"markdown","12e843b0":"markdown","b858609a":"markdown","c39bddee":"markdown","218d99cc":"markdown","e3d1d7cf":"markdown","9da97acd":"markdown","29d78179":"markdown","06cf0c8c":"markdown","72a985e4":"markdown"},"source":{"733d5792":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex6 import *\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.layers.experimental.preprocessing as preprocessing\n\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '..\/input\/car-or-truck\/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '..\/input\/car-or-truck\/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","474fbe48":"# all of the \"factor\" parameters indicate a percent-change\naugment = keras.Sequential([\n    preprocessing.RandomContrast(factor=0.5),\n    #preprocessing.RandomFlip(mode='horizontal'), # meaning, left-to-right\n    #preprocessing.RandomFlip(mode='vertical'), # meaning, top-to-bottom\n    #preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n    #preprocessing.RandomRotation(factor=0.20),\n    #preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n])\n\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint('RandomContrast(factor=0.5)')\nplt.show()","0f7a2b04":"augment = keras.Sequential([\n    preprocessing.RandomFlip(mode='horizontal'), # meaning, left-to-right\n])\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint(\"RandomFlip(mode='horizontal')\")\nplt.show()","8446486a":"augment = keras.Sequential([\n    preprocessing.RandomFlip(mode='vertical'), # meaning, left-to-right\n])\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint(\"RandomFlip(mode='vertical')\")\nplt.show()","c52a31cd":"augment = keras.Sequential([\n    preprocessing.RandomWidth(factor=0.15), # meaning, left-to-right\n])\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint(\"RandomWidth(factor=0.15)\")\nplt.show()","5689dbf5":"augment = keras.Sequential([\n    preprocessing.RandomRotation(factor=0.20), # meaning, left-to-right\n])\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint(\"RandomRotation(factor=0.20)\")\nplt.show()","3c720091":"augment = keras.Sequential([\n    preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1), # meaning, left-to-right\n])\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    #plt.axis('off')\n\nprint(\"RandomTranslation(height_factor=0.1, width_factor=0.1)\")\nplt.show()","ec68245b":"# View the solution (Run this code cell to receive credit!)\nq_1.check()","0bdaa666":"# Lines below will give you a hint \n#q_1.solution()","bd197a2b":"# View the solution (Run this code cell to receive credit!)\nq_2.check()","ab8de041":"# Lines below will give you a hint \n#q_2.solution()","7136dbae":"import tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\n\nmodel = keras.Sequential([\n    layers.InputLayer(input_shape=[128, 128, 3]),\n    \n    # Data Augmentation\n    preprocessing.RandomContrast(factor=0.10),\n    preprocessing.RandomFlip(mode='horizontal'),\n    preprocessing.RandomRotation(factor=0.10),\n    \n    # Block One\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(8, activation='relu'),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n# Check your answer\nq_3.check()","7e3c0b32":"model.summary()","d995506c":"tf.keras.utils.plot_model(model, show_shapes=True)","9bfcd514":"# Lines below will give you a hint or solution code\n#q_3.hint()\n#q_3.solution()","24def257":"optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n)\n\n# Plot learning curves\nimport pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","c4b69ec0":"# View the solution (Run this code cell to receive credit!)\nq_4.solution()","f63620cf":"# 4) Train Model #\n\nExamine the training curves. What there any sign of overfitting? How does the performance of this model compare to other models you've trained in this course?","85e1a7ab":"The [EuroSAT](https:\/\/www.kaggle.com\/ryanholbrook\/eurosat) dataset consists of satellite images of the Earth classified by geographic feature. Below are a number of images from this dataset.\n\n<figure>\n<img src=\"https:\/\/i.imgur.com\/LxARYZe.png\" width=600, alt=\"Sixteen satellite images labeled: SeaLake, PermanentCrop, Industrial, Pasture, Residential, and Forest.\">\n<\/figure>","a37ad19c":"In this exercise, we'll look at a few datasets and think about what kind of augmentation might be appropriate. Your reasoning might be different that what we discuss in the solution. That's okay. The point of these problems is just to think about how a transformation might interact with a classification problem -- for better or worse.","50947a12":"# 1) EuroSAT #\n\nWhat kinds of transformations might be appropriate for this dataset?","eaa2ab90":"Now you'll use data augmentation with a custom convnet similar to the one you built in Exercise 5. Since data augmentation effectively increases the size of the dataset, we can increase the capacity of the model in turn without as much risk of overfitting.","b392985e":"# Conclusion #\n\nData augmentation is a powerful and commonly-used tool to improve model training, not only for convolutional networks, but for many other kinds of neural network models as well. Whatever your problem, the principle remains the same: you can make up for an inadequacy in your data by adding in \"fake\" data to cover it over. Experimenting with augmentations is a great way to find out just how far your data can go!","268f8b18":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/196537) to chat with other Learners.*","12e843b0":"Do the transformations you chose seem reasonable for the *Car or Truck* dataset?","b858609a":"# (Optional) Explore Augmentation #\n\nUncomment a transformation and run the cell to see what it does. You can experiment with the parameter values too, if you like. (The `factor` parameters should be greater than 0 and, generally, less than 1.) Run the cell again if you'd like to get a new random image.","c39bddee":"**This notebook is an exercise in the [Computer Vision](https:\/\/www.kaggle.com\/learn\/computer-vision) course.  You can reference the tutorial at [this link](https:\/\/www.kaggle.com\/ryanholbrook\/data-augmentation).**\n\n---\n","218d99cc":"# Introduction #\n\nIn these exercises, you'll explore what effect various random transformations have on an image, consider what kind of augmentation might be appropriate on a given dataset, and then use data augmentation with the *Car or Truck* dataset to train a custom network.\n\nRun the cell below to set everything up!","e3d1d7cf":"Now we'll train the model. Run the next cell to compile it with a loss and accuracy metric and fit it to the training set.","9da97acd":"The [TensorFlow Flowers](https:\/\/www.kaggle.com\/ryanholbrook\/tensorflow-flowers) dataset consists of photographs of flowers of several species. Below is a sample.\n\n<figure>\n<img src=\"https:\/\/i.imgur.com\/Mt7PR2x.png\" width=600, alt=\"Sixteen images of flowers labeled: roses, tulips, dandelion, and sunflowers\">\n<\/figure>","29d78179":"# 2) TensorFlow Flowers #\n\nWhat kinds of transformations might be appropriate for the TensorFlow Flowers dataset?","06cf0c8c":"# The End #\n\nThat's all for **Computer Vision** on Kaggle Learn! Are you ready to apply your knowledge? Check out our two bonus lessons! They'll walk you through preparing a submission for a competition while you learn how to train neural nets with TPUs, Kaggle's most advanced accelerator. At the end, you'll have a complete notebook ready to extend with ideas of your own.\n- [Create Your First Submission](https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission) - Prepare a submission for our *Petals to the Metal* Getting Started competition. You'll train a neural net to recognize over 100 species of flowers.\n- [Cassava Leaf Disease](https:\/\/www.kaggle.com\/jessemostipak\/getting-started-tpus-cassava-leaf-disease) - Rather compete for money and medals? Train a neural net to diagnose common diseases in the cassava plant, a staple security crop in Africa.\n\nHave fun learning!","72a985e4":"# 3) Add Preprocessing Layers #\n\nAdd these preprocessing layers to the given model.\n\n```\npreprocessing.RandomContrast(factor=0.10),\npreprocessing.RandomFlip(mode='horizontal'),\npreprocessing.RandomRotation(factor=0.10),\n```\n"}}