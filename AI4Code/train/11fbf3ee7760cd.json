{"cell_type":{"bcd1ac98":"code","7a0f9388":"code","ec026266":"code","6881fb82":"code","d942102e":"code","f869735c":"code","4d0d0341":"code","5057a402":"code","ae94d518":"code","151999b8":"code","2be90cc7":"code","a3cd229a":"code","e4530db8":"code","cb8cfe26":"code","55a3c279":"code","cf99c63a":"code","f2cc4ea2":"code","99d95567":"code","e3063eeb":"code","f0af9259":"code","46748b96":"code","92e28546":"code","10156948":"code","b2870afd":"code","4a3bc31c":"code","07b19fb4":"code","e273c5b6":"code","c55d47d3":"code","373aeaa9":"code","c442f1b3":"code","c484bc98":"code","90b70ec6":"code","419f20ad":"code","5d23ae72":"code","db112a1f":"code","534ebe14":"code","52216354":"code","1fdb725b":"code","ccc86f1e":"code","d0e58410":"code","0f2bf510":"code","80259e56":"markdown","4f7fc46a":"markdown","98644ace":"markdown","b66ff934":"markdown"},"source":{"bcd1ac98":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7a0f9388":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ec026266":"df=pd.read_csv('\/kaggle\/input\/legal-citation-text-classification\/legal_text_classification.csv')","6881fb82":"df.head()","d942102e":"df.info()","f869735c":"df.isnull().sum()","4d0d0341":"df['case_outcome'].unique()","5057a402":"df.groupby('case_outcome')['case_id'].count().plot.bar()","ae94d518":"df=df.dropna(how='any')","151999b8":"df","2be90cc7":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english'))\ndf2= df[['case_text']]\ndf2['case_text'] = df2['case_text'].str.lower()\ndf2['case_text'] = df2['case_text'].apply(word_tokenize)\ndf2['case_text'] = df2['case_text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf2['case_text'] = df2['case_text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf2['case_text'] = df2['case_text'].apply(lambda x : [word for word in x if len(word) > 1])","a3cd229a":"df2['case_outcome']=df['case_outcome']","e4530db8":"df2","cb8cfe26":"df['case_outcome'].unique()","55a3c279":"df2_cited=df2[df2['case_outcome']=='cited']\ndf2_applied=df2[df2['case_outcome']=='applied']\ndf2_followed=df2[df2['case_outcome']=='followed']\ndf2_referred=df2[df2['case_outcome']=='referred to']\ndf2_related=df2[df2['case_outcome']=='related']\ndf2_considered=df2[df2['case_outcome']=='considered']\ndf2_discussed=df2[df2['case_outcome']=='discussed']\ndf2_distinguished=df2[df2['case_outcome']=='distinguished']\ndf2_affirmed=df2[df2['case_outcome']=='affirmed']\ndf2_approved=df2[df2['case_outcome']=='approved']","cf99c63a":"df3_cited=df2_cited['case_text'].explode()\ndf3_applied=df2_applied['case_text'].explode()\ndf3_followed=df2_followed['case_text'].explode()\ndf3_referred=df2_referred['case_text'].explode()\ndf3_related=df2_related['case_text'].explode()\ndf3_considered=df2_considered['case_text'].explode()\ndf3_discussed=df2_discussed['case_text'].explode()\ndf3_distinguished=df2_distinguished['case_text'].explode()\ndf3_affirmed=df2_affirmed['case_text'].explode()\ndf3_approved=df2_approved['case_text'].explode()","f2cc4ea2":"df3_cited=pd.DataFrame(df3_cited)\ndf3_applied=pd.DataFrame(df3_applied)\ndf3_followed=pd.DataFrame(df3_followed)\ndf3_referred=pd.DataFrame(df3_referred)\ndf3_related=pd.DataFrame(df3_related)\ndf3_considered=pd.DataFrame(df3_considered)\ndf3_discussed=pd.DataFrame(df3_discussed)\ndf3_distinguished=pd.DataFrame(df3_distinguished)\ndf3_affirmed=pd.DataFrame(df3_affirmed)\ndf3_approved=pd.DataFrame(df3_approved)","99d95567":"import squarify","e3063eeb":"df2_total=df2['case_text'].explode()\ndf2_total=pd.DataFrame(df2_total)","f0af9259":"df2_total=pd.DataFrame(df2_total.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf2_total=df2_total.rename(columns={'case_text': 'num'})\n\nx = df2_total['num']\nlabel = df2_total.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","46748b96":"df3_cited=pd.DataFrame(df3_cited.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_cited=df3_cited.rename(columns={'case_text': 'num'})\n\nx = df3_cited['num']\nlabel = df3_cited.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","92e28546":"df3_applied=pd.DataFrame(df3_applied.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_applied=df3_applied.rename(columns={'case_text': 'num'})\n\nx = df3_applied['num']\nlabel = df3_applied.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","10156948":"df3_followed=pd.DataFrame(df3_followed.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_followed=df3_followed.rename(columns={'case_text': 'num'})\n\nx = df3_followed['num']\nlabel = df3_followed.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","b2870afd":"df3_referred=pd.DataFrame(df3_referred.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_referred=df3_referred.rename(columns={'case_text': 'num'})\n\nx = df3_referred['num']\nlabel = df3_referred.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","4a3bc31c":"df3_related=pd.DataFrame(df3_related.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_related=df3_related.rename(columns={'case_text': 'num'})\n\nx = df3_related['num']\nlabel = df3_related.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","07b19fb4":"df3_considered=pd.DataFrame(df3_considered.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_considered=df3_considered.rename(columns={'case_text': 'num'})\n\nx = df3_considered['num']\nlabel = df3_considered.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","e273c5b6":"df3_discussed=pd.DataFrame(df3_discussed.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_discussed=df3_discussed.rename(columns={'case_text': 'num'})\n\nx = df3_discussed['num']\nlabel = df3_discussed.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","c55d47d3":"df3_distinguished=pd.DataFrame(df3_distinguished.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_distinguished=df3_distinguished.rename(columns={'case_text': 'num'})\n\nx = df3_distinguished['num']\nlabel = df3_distinguished.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","373aeaa9":"df3_affirmed=pd.DataFrame(df3_affirmed.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_affirmed=df3_affirmed.rename(columns={'case_text': 'num'})\n\nx = df3_affirmed['num']\nlabel = df3_affirmed.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","c442f1b3":"df3_approved=pd.DataFrame(df3_approved.groupby('case_text')['case_text'].count().sort_values(ascending=False).head(30))\ndf3_approved=df3_approved.rename(columns={'case_text': 'num'})\n\nx = df3_approved['num']\nlabel = df3_approved.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","c484bc98":"df['case_outcome'].unique()","90b70ec6":"df['case_outcome']=df['case_outcome'].replace({'cited':1, 'applied':2,'followed':3,'referred to':4,'related':5,'considered':6,'discussed':7,\n              'distinguished':8,'affirmed':9,'approved':10})","419f20ad":"from sklearn.model_selection import train_test_split\n\nsentences = df['case_text'].values\ny = df['case_outcome'].values\n\nsentences_train, sentences_test, y_train, y_test = train_test_split(\n    sentences, y, test_size=0.25, random_state=1000)","5d23ae72":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nvectorizer.fit(sentences_train)\n\nX_train = vectorizer.transform(sentences_train)\nX_test  = vectorizer.transform(sentences_test)\nX_train","db112a1f":"from keras.models import Sequential\nfrom keras import layers","534ebe14":"import tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout","52216354":"input_dim = X_train.shape[1]\n\nmodel = Sequential()\nmodel.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\nmodel.add(layers.Dense(1, activation='softmax'))","1fdb725b":"model.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n               metrics=['accuracy'])\nmodel.summary()","ccc86f1e":"from keras.backend import clear_session\nclear_session()","d0e58410":"history = model.fit(X_train, y_train,\n                    epochs=100,\n                    verbose=False,\n                    validation_data=(X_test, y_test),\n                    batch_size=10)","0f2bf510":"train_score = model.evaluate(X_train, y_train)\ntest_score = model.evaluate(X_test, y_test)\nprint('Train loss:', train_score[0])\nprint('Train accuracy:', train_score[1])\nprint('Test loss:', test_score[0])\nprint('Test accuracy:', test_score[1])","80259e56":"# 2) What words are used in each case outcomes","4f7fc46a":"# 1) Data Preprocessing","98644ace":"# 3) Multi-categiries prediction trial","b66ff934":"# I tired muti-categories prediction model of text.\n\n![ANN.a2284c5d07a3.png](attachment:9d4b5b27-2fb8-4210-818b-badbb4acf8ae.png)\n\n# I reffered to 'Python for NLP: Multi-label Text Classification with Keras'.\nhttps:\/\/realpython.com\/python-keras-text-classification\/"}}