{"cell_type":{"98d6499c":"code","739f6d72":"code","c80a9bb5":"code","3fccb10b":"code","d1fd6cf6":"code","d772c71e":"code","ca5770b8":"code","d802effa":"code","36612e03":"code","a07dfe0d":"code","9fa22c70":"code","d966be3d":"code","78ed8a47":"code","570b36e0":"code","a499e109":"code","37e3ff0c":"code","ce4c594e":"code","e0514744":"code","e9c72481":"code","570e6b00":"code","1fef0416":"code","de3ca249":"code","d5b95892":"code","02399bdb":"code","bee0abe0":"code","7e93b47a":"code","948114b2":"code","6bee64d3":"markdown","8907ea22":"markdown","71d8d3d4":"markdown","1e51e5eb":"markdown","b6dbe8a0":"markdown","dff73bac":"markdown","d00bda3d":"markdown","e9faf0d8":"markdown","77ae59e1":"markdown","313c8e09":"markdown","bbc273b9":"markdown","f8b40474":"markdown"},"source":{"98d6499c":"import cv2\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport gc\n\ndim = 160  # px to scale\n\npath = '..\/input\/plant-seedlings-classification\/train\/*\/*.png' \nfiles = glob(path)\n\ntrainImg = []\ntrainLabel = []\n\nj = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    print(str(j) + \"\/\" + str(num), end=\"\\r\")\n    trainImg.append(cv2.resize(cv2.imread(img), (dim, dim)))  # Get image (with resizing)\n    trainLabel.append(img.split('\/')[-2])  # Get image label (folder name)\n    j += 1\n\ntrainImg = np.asarray(trainImg)  # Train images set\ntrainLabel = pd.DataFrame(trainLabel)  # Train labels set","739f6d72":"# Show some of the train images\nfig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    img.title.set_text(trainLabel[0][index])\n    plt.imshow(trainImg[index])\nplt.tight_layout()\nplt.show()","c80a9bb5":"def preProcessImage(Img_arr, getEx=True):\n    clearImg = []\n    for img in Img_arr:\n        # Use gaussian blur\n        blurImg = cv2.GaussianBlur(img, (5, 5), 0)   \n\n        # Convert to HSV image\n        hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n\n        # Create mask (parameters - green color range)\n        lower_green = (25, 40, 50)\n        upper_green = (75, 255, 255)\n\n        mask = cv2.inRange(hsvImg, lower_green, upper_green)  \n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n        # Create bool mask\n        bMask = mask > 0  \n\n        # Apply the mask\n        clear = np.zeros_like(img, np.uint8)  # Create empty image\n        clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n\n        clearImg.append(clear)  # Append image without backgroung\n\n        # Show examples\n        if getEx:\n            fig = plt.figure(figsize=(10, 10))\n            imagels = [img,blurImg,hsvImg,mask,bMask,clear]\n            titlels = ['Original Image','Blur Image','HSV Image','Mask','Boolean Mask', 'Clear Image']\n            for i in range(6):\n                plot = fig.add_subplot(2, 3, i + 1)\n                plt.xticks([]),plt.yticks([])\n                plot.title.set_text(titlels[i])\n                plt.imshow(imagels[i])\n            plt.tight_layout()\n            plt.show()\n            getEx = False\n\n    return(np.asarray(clearImg))","3fccb10b":"clearTrainImg = preProcessImage(trainImg)","d1fd6cf6":"fig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    img.title.set_text(trainLabel[0][index])\n    plt.imshow(clearTrainImg[index])\nplt.tight_layout()\nplt.show()","d772c71e":"# Normalizing the train Images\nx_train = clearTrainImg \/ 255.0","ca5770b8":"from sklearn.preprocessing import OneHotEncoder\n\n# Encode labels and create classes\nenc = OneHotEncoder(categories='auto')\ny_train = enc.fit_transform(trainLabel).toarray()","d802effa":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\nfor train_index, test_index in sss.split(x_train, y_train):\n    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n    x_train, x_valid = x_train[train_index], x_train[test_index]\n    y_train, y_valid = y_train[train_index], y_train[test_index]","36612e03":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=20,\n                            zoom_range=0.15,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.15,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            brightness_range=[0.4,1],\n                            rescale=1.0\/255.0)\ndatagen.fit(x_train)","a07dfe0d":"from keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import BatchNormalization, GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import Xception\n\n\nnum_classes = 12\nlearning_rate = 0.001\nbatch_size = 32\n\nbase_model = Xception(input_shape=(dim, dim, 3), include_top=False,weights='imagenet')\n\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(100, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dropout(0.5),\n    \n    Dense(50, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dense(num_classes,activation='softmax')\n])\n\n\nmodel.compile(optimizer = optimizers.Nadam(learning_rate=learning_rate),\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n\n# callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n#               ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n#               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n\nresult = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), verbose = 1,\n                   batch_size=batch_size, epochs=25, validation_data=(x_valid, y_valid))\n\n(loss, accuracy) = model.evaluate(x_valid, y_valid)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","9fa22c70":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","d966be3d":"base_model.trainable = True\nmodel.get_layer('xception').trainable","78ed8a47":"model.compile(optimizer=optimizers.Nadam(learning_rate=0.0006), loss='categorical_crossentropy', metrics=['accuracy'])","570b36e0":"result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=50, \n                   initial_epoch=25, validation_data=(x_valid, y_valid),verbose=1)","a499e109":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","37e3ff0c":"gc.collect()","ce4c594e":"model.compile(optimizer=optimizers.Nadam(learning_rate=0.00006), loss='categorical_crossentropy', metrics=['accuracy'])","e0514744":"result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=75, \n                   initial_epoch=50, validation_data=(x_valid, y_valid),verbose=1)","e9c72481":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","570e6b00":"gc.collect()","1fef0416":"path = '..\/input\/plant-seedlings-classification\/test\/*.png'\nfiles = glob(path)\n\ntestImg = []\ntestId = []\nj = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    print(\"Obtain images: \" + str(j) + \"\/\" + str(num), end='\\r')\n    testId.append(img.split('\/')[-1])  # Images id's\n    testImg.append(cv2.resize(cv2.imread(img), (dim, dim)))\n    j += 1\n\ntestImg = np.asarray(testImg)  # Train images set","de3ca249":"# Show some of the test images\nfig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    plt.imshow(testImg[index])\nplt.tight_layout()\nplt.show()","d5b95892":"clearTestImg = preProcessImage(testImg,getEx=True)","02399bdb":"# Normalisation of the test images\nclearTestImg = clearTestImg \/ 255","bee0abe0":"pred = model.predict(clearTestImg)","7e93b47a":"predNum = np.argmax(pred, axis=1)\npredStr = []\nfor i in range(len(predNum)):\n    predStr.append(enc.categories_[0][predNum[i]])\n    \nres = {'file': testId, 'species': predStr}\nres = pd.DataFrame(res)\nres.to_csv(\"submission.csv\", index=False)","948114b2":"model.save(\"saved_model\")","6bee64d3":"## Fine-tuning our model","8907ea22":"## Testing our trained Model","71d8d3d4":"### Plotting some of the Pre-Processed train Image","1e51e5eb":"### Data Pre-processing (Creating a mask for the Green colour)","b6dbe8a0":"## Testing our Model ","dff73bac":"### Plotting some images from the Training Set ","d00bda3d":"## Pre-processing the test images","e9faf0d8":"## Image Augmentation","77ae59e1":"## Creating a custom-Xception Model","313c8e09":"## Creating the submission file","bbc273b9":"## Reading images from the directories","f8b40474":"## OneHotEncoding and Train-Validation Split"}}