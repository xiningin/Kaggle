{"cell_type":{"cf554ca9":"code","a5b43405":"code","c6eac2e0":"code","ed7796dc":"code","8035c8fd":"code","fd412013":"code","9429177c":"code","7e88fdbc":"code","8aeeae58":"code","0747462d":"code","544b35ad":"code","dbc897ce":"code","09a86881":"code","404d8b28":"code","5f67a519":"code","55101ef1":"code","ad4698d7":"code","c4c7652f":"code","b248ff48":"code","883eeced":"code","9dcee659":"code","ed42f0fe":"code","7db2c0da":"code","81180dce":"markdown","8214606f":"markdown"},"source":{"cf554ca9":"import os \nimport numpy as np \nimport pandas as pd \nimport imageio \nimport matplotlib.pyplot as plt \n%matplotlib inline","a5b43405":"import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate","c6eac2e0":"path =''\nimage_path = os.path.join(path,'..\/input\/lyft-udacity-challenge\/dataA\/dataA\/CameraRGB\/')\nmask_path = os.path.join(path,'..\/input\/lyft-udacity-challenge\/dataA\/dataA\/CameraSeg\/')\n\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list[:3]","ed7796dc":"#Path + List\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]\nimage_list[:3]","8035c8fd":"#Sort the list \nimage_list = sorted(image_list)\nmask_list = sorted(mask_list)\n\nprint(\"number of images is : {} \".format(len(image_list)))\nimage_list[:3]","fd412013":"n = 2 # you can chose any index \nimg  = imageio.imread(image_list[n])\nprint(img.shape)\nmask = imageio.imread(mask_list[n])\nprint(mask.shape)\n\nmask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n\n# now let's plot \nfig ,arr  = plt.subplots(1,2,figsize=(15,10))\narr[0].imshow(img)\narr[0].set_title('Original Image')\narr[1].imshow(mask, cmap='Paired')\narr[1].set_title('Mask')","9429177c":"image_list_dataset = tf.data.Dataset.list_files(image_list ,shuffle=False)\nmask_list_dataset = tf.data.Dataset.list_files(mask_list , shuffle=False)\n\nimages_filenames = tf.constant(image_list)\nmasks_filenames = tf.constant(mask_list)\n\n","7e88fdbc":"images_filenames[:3]","8aeeae58":"dataset = tf.data.Dataset.from_tensor_slices((images_filenames\n                                              ,masks_filenames))\nfor image,mask in dataset.take(1) : \n    print(image)\n    print(mask)","0747462d":"def process_path(image_path,mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img,channels=3)\n    #this do the same as dividing by 255 to set the values between 0 and 1 (normalization)\n    img = tf.image.convert_image_dtype(img,tf.float32) \n    \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask,channels=3)\n    mask = tf.math.reduce_max(mask,axis=-1,keepdims=True)\n    return img , mask\n\ndef preprocess(image,mask) : \n    input_image = tf.image.resize(image,(96,128),method='nearest')\n    input_mask = tf.image.resize(mask,(96,128),method='nearest')\n    \n    return input_image , input_mask\n","544b35ad":"image_ds = dataset.map(process_path) # apply the preprocces_path function to our dataset\nprint(image_ds)\nprocessed_image_ds = image_ds.map(preprocess) # apply the preprocess function to our dataset","dbc897ce":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \n    conv = Conv2D(n_filters, \n                  kernel_size = 3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n    conv = Conv2D(n_filters, \n                  kernel_size = 3, \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(conv) \n    \n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n        \n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n        \n        \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","09a86881":"def upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \n    up = Conv2DTranspose(\n                 n_filters,  \n                 kernel_size = 3,\n                 strides=(2,2),\n                 padding='same')(expansive_input)\n    \n    merge = concatenate([up, contractive_input], axis=3)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,   \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,  \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n    \n    \n    return conv","404d8b28":"def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n    \n    inputs = Input(input_size)\n    \n    #contracting path\n    cblock1 = conv_block(inputs, n_filters)\n    cblock2 = conv_block(cblock1[0], 2*n_filters)\n    cblock3 = conv_block(cblock2[0], 4*n_filters)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.3) \n    cblock5 = conv_block(cblock4[0],16*n_filters, dropout_prob=0.3, max_pooling=None)     \n    \n    #expanding path\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n    \n    conv10 = Conv2D(n_classes, kernel_size=1, padding='same')(conv9)  \n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model","5f67a519":"img_height = 96\nimg_width = 128\nnum_channels = 3\n\nunet = unet_model((img_height, img_width, num_channels))","55101ef1":"unet.summary()","ad4698d7":"unet.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","c4c7652f":"EPOCHS = 10\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 500\nBATCH_SIZE = 16\nprocessed_image_ds.batch(BATCH_SIZE)\ntrain_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(processed_image_ds.element_spec)\nmodel_history = unet.fit(train_dataset, epochs=EPOCHS)","b248ff48":"plt.plot(model_history.history[\"accuracy\"])","883eeced":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","9dcee659":"def create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","ed42f0fe":"def show_predictions(dataset=None, num=1):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = unet.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])","7db2c0da":"show_predictions(train_dataset, 6)","81180dce":"# Image Semantic Segmentation with U-Net\n\n**loss: 0.1134 - accuracy: 0.9622**","8214606f":"![image.png](attachment:c7656420-6705-4949-98ad-e30a8e49cb06.png)\n\nU-Net Model Design\nTo design our model, we will carry out the following steps\n\nDefine a function for an encoding block. The function will return the next layer output and the skip connection output for the corresponding block in the model\nDefine a function for a decoding block. This function will merge the skip-connection input with the previous layer, process it, and return an output\nDevelop a model using both the encoding and decoding blocks output"}}