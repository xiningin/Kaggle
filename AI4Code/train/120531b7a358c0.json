{"cell_type":{"23d3ff59":"code","ec41efdf":"code","17108923":"code","914226c5":"code","3cccb2c5":"code","39895b96":"code","82d583e7":"code","bbff93fb":"code","cc329c1a":"code","7e8b496a":"code","c02a4d6e":"code","9665df6f":"code","6938f84f":"code","57407d3c":"code","75650dbd":"code","67b1fa32":"code","a786ca47":"code","5537e49b":"code","a7a9d91f":"code","d967ba24":"code","19d38685":"code","d96a7c2a":"code","e0a782a1":"code","030a95d5":"code","31c2a0dc":"code","579a1b1d":"code","33f0eeb0":"code","76eeb6da":"code","905faa31":"code","348eff36":"code","f63356fa":"code","3e119ac6":"code","a94f136b":"code","82e7860a":"code","6d53637a":"code","7893a5bc":"code","aa938acd":"code","fc5e9dea":"code","68e506b6":"code","5472e2fa":"code","ee507ae8":"code","ab6cfbea":"code","f1c4c8a6":"code","ba257e42":"code","f82c8185":"code","e4c60468":"code","f0c0ccdb":"code","82697fac":"code","065b5c5a":"code","c112b70c":"code","c59efeb8":"code","0545c1c7":"code","987658d3":"code","5a1fabc9":"code","b4377fbe":"code","0f4cf8ae":"code","32fc6f73":"code","63f8e64b":"code","c2fc28c8":"code","5048bdb4":"code","c63bfef8":"code","499721cd":"code","c7f8a12b":"code","fb82c436":"code","666d746a":"code","0d44423d":"code","006129c0":"code","57b6f71f":"code","8fd1eaec":"code","8b960742":"code","fabed04c":"code","b4a618de":"code","ccdf8419":"code","eadd6716":"code","77e714f4":"code","64093e65":"code","a3077167":"code","b17defe1":"code","59a0dc3d":"code","ff415ac9":"code","762556fa":"code","5657d8eb":"code","3560b2e6":"code","74a6c5b9":"code","133e3b1a":"code","152dc5d0":"code","13ec4f2f":"code","e15f92d8":"code","79b6220f":"code","8746b435":"code","e88d4530":"code","ddafa21a":"code","f83946a2":"code","3f7f828d":"code","feb6eaea":"code","49fd16a6":"code","4d670e6c":"code","127b0d06":"code","f4c5232c":"code","f28f3e0d":"code","2b8d528d":"code","acfd948e":"code","90596647":"code","c046723e":"markdown","6f493e78":"markdown","f69aae8f":"markdown","2c50bbe8":"markdown","0bf33d5c":"markdown","a77696c8":"markdown","7b042593":"markdown","778ab885":"markdown","5abf471f":"markdown","c80bfb73":"markdown","cf8099a9":"markdown","8d611b9a":"markdown","84a7e855":"markdown","75f34840":"markdown","8dbdfb62":"markdown","f9408695":"markdown","d9ead24f":"markdown","35b6e3ee":"markdown","b22bc6ab":"markdown","5a756453":"markdown","1c63548a":"markdown","ab91d4ff":"markdown","4ea6f404":"markdown","82dd9054":"markdown","9fb0cc72":"markdown","ec5a6c6e":"markdown","a89216f5":"markdown","0ce26ab1":"markdown","a28924e7":"markdown"},"source":{"23d3ff59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec41efdf":"!pip install openpyxl","17108923":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf =pd.read_excel('..\/input\/covid19\/dataset.xlsx')\npd.set_option('display.max_row', 111)\npd.set_option('display.max_column', 111)","914226c5":"df.head()","3cccb2c5":"df.shape\n","39895b96":"df.dtypes.value_counts()","82d583e7":"plt.figure(figsize=(20,10))\nsns.heatmap(df.isna())","bbff93fb":"(df.isna().sum()\/df.shape[0]).sort_values(ascending=True)","cc329c1a":"df = df[df.columns[df.isna().sum()\/df.shape[0] <0.9]]\ndf.head()","7e8b496a":"plt.figure(figsize=(20,10))\nsns.heatmap(df.isna())","c02a4d6e":"df['SARS-Cov-2 exam result'].value_counts(normalize=True)","9665df6f":"for col in df.select_dtypes('float'):\n    plt.figure()\n    sns.distplot(df[col])","6938f84f":"sns.distplot(df['Patient age quantile'])","57407d3c":"df['Patient age quantile'].value_counts()","75650dbd":"df['SARS-Cov-2 exam result'].unique()","67b1fa32":"for col in df.select_dtypes('object'):\n    print(col,df[col].unique())","a786ca47":"for col in df.select_dtypes('object'):\n    print(df[col].value_counts())","5537e49b":"positive_df = df[df['SARS-Cov-2 exam result'] =='positive']\nnegative_df = df[df['SARS-Cov-2 exam result'] =='negative']","a7a9d91f":"missing_rate = df.isna().sum()\/df.shape[0]\nblood_columns = df.columns[(missing_rate<0.9)&(missing_rate> 0.88)]\nviral_columns = df.columns[(missing_rate<0.88)&(missing_rate> 0.75)]","d967ba24":"for col in blood_columns:\n    plt.figure()\n    sns.distplot(positive_df[col],label='positive')\n    sns.distplot(negative_df[col],label='negative')\n    plt.legend()","19d38685":"sns.countplot(x='Patient age quantile', hue='SARS-Cov-2 exam result',data=df)","d96a7c2a":"pd.crosstab(df['SARS-Cov-2 exam result'],df['Influenza A'])","e0a782a1":"for col in viral_columns:\n    plt.figure()\n    sns.heatmap(pd.crosstab(df['SARS-Cov-2 exam result'],df[col]),annot=True,fmt='d')","030a95d5":"sns.pairplot(df[blood_columns])","31c2a0dc":"sns.heatmap(df[blood_columns].corr())","579a1b1d":"sns.clustermap(df[blood_columns].corr())","33f0eeb0":"for col in blood_columns:\n    plt.figure()\n    sns.lmplot(x='Patient age quantile',y=col,hue='SARS-Cov-2 exam result',data=df)","76eeb6da":"df.corr()['Patient age quantile'].sort_values()","905faa31":"pd.crosstab(df['Influenza A'], df['Influenza A, rapid test'])","348eff36":"pd.crosstab(df['Influenza B'], df['Influenza B, rapid test'])","f63356fa":"np.sum(df[viral_columns[:-2]] =='detected',axis=1).plot()","3e119ac6":"df['infected'] = np.sum(df[viral_columns[:-2]] =='detected',axis=1)>1","a94f136b":"df.head()","82e7860a":"infected_df=df[df['infected'] ==True]\nnot_infected_df = df[df['infected']==False]","6d53637a":"for col in blood_columns:\n    plt.figure()\n    sns.distplot(infected_df[col],label='infected')\n    sns.distplot(not_infected_df[col], label='not infected')\n    plt.legend()","7893a5bc":"\ndef hospitalization(df):\n    if df['Patient addmited to regular ward (1=yes, 0=no)'] == 1:\n        return 'surveillance'\n    elif df['Patient addmited to semi-intensive unit (1=yes, 0=no)'] == 1:\n        return 'semi intensive care'\n    elif df['Patient addmited to intensive care unit (1=yes, 0=no)'] == 1:\n        return 'intensive care'\n    else:\n        return 'unknown'","aa938acd":"df['status'] = df.apply(hospitalization,axis=1)","fc5e9dea":"df.head()","68e506b6":"for col in blood_columns:\n    plt.figure()\n    for cat in df['status'].unique():\n        sns.distplot(df[df['status']==cat][col],label=cat)\n    plt.legend()","5472e2fa":"df[blood_columns].count()","ee507ae8":"df[viral_columns].count()","ab6cfbea":"df.dropna().count()","f1c4c8a6":"df1 = df[viral_columns[:-2]]\ndf1['covid'] = df['SARS-Cov-2 exam result']\ndf1.dropna()['covid'].value_counts(normalize=True)","ba257e42":"df1 = df[blood_columns[:-2]]\ndf1['covid'] = df['SARS-Cov-2 exam result']\ndf1.dropna()['covid'].value_counts(normalize=True)","f82c8185":"from scipy.stats import ttest_ind ","e4c60468":"positive_df.shape","f0c0ccdb":"negative_df.shape","82697fac":"balanced_neg = negative_df.sample(positive_df.shape[0])","065b5c5a":"def t_test(col) : \n    alpha = 0.02\n    stat,p = ttest_ind(balanced_neg[col].dropna(),positive_df[col].dropna())\n    if p < alpha:\n        return 'H rejected'\n    else:\n        return 0","c112b70c":"for col  in blood_columns:\n    print(col, t_test(col))","c59efeb8":"df =pd.read_excel('..\/input\/covid19\/dataset.xlsx')","0545c1c7":"df.head()","987658d3":"missing_rate= df.isna().sum()\/df.shape[0]","5a1fabc9":"blood_columns = list(df.columns[(missing_rate < 0.9) & (missing_rate >0.88)])\nviral_columns = list(df.columns[(missing_rate < 0.80) & (missing_rate > 0.75)])","b4377fbe":"key_columns = ['Patient age quantile', 'SARS-Cov-2 exam result']","0f4cf8ae":"df = df[key_columns + blood_columns + viral_columns]\ndf.head()","32fc6f73":"from sklearn.model_selection import train_test_split","63f8e64b":"trainset, testset = train_test_split(df, test_size=0.2, random_state=0)","c2fc28c8":"trainset['SARS-Cov-2 exam result'].value_counts()","5048bdb4":"testset['SARS-Cov-2 exam result'].value_counts()","c63bfef8":"def encoding(df):\n    code = {'positive':1,'negative':0,'detected':1,'not_detected':0}\n    for  col in df.select_dtypes('object'):\n        df[col]=df[col].map(code)\n        \n    return df","499721cd":"def feature_engineering(df):\n    df[' infected'] = df[viral_columns].sum(axis=1) >= 1\n    df = df.drop(viral_columns, axis=1)\n    return df","c7f8a12b":"def imputation(df):\n    #df['is na'] =(df['Parainfluenza 3'].isna()) | (df['Leukocytes'].isna())\n    #df=df.fillna(-999)\n    df=df.dropna(axis=0)\n    \n    return df","fb82c436":"def preprocessing(df):\n    df = encoding(df)\n    feature_engineering(df)\n\n    df=imputation(df)\n    \n    X= df.drop('SARS-Cov-2 exam result',axis=1)\n    y = df['SARS-Cov-2 exam result']\n    \n    print(y.value_counts())\n    \n    return X,y","666d746a":"X_train, y_train= preprocessing(trainset)","0d44423d":"X_test, y_test = preprocessing(testset)","006129c0":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA","57b6f71f":"model= DecisionTreeClassifier(random_state=0)","8fd1eaec":"from sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve","8b960742":"def evaluation(model):\n    model.fit(X_train,y_train)\n    ypred=model.predict(X_test)\n    \n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred ))\n    \n    N, train_score, val_score=learning_curve(model,X_train,y_train,cv=4,scoring='f1',train_sizes=np.linspace(0.1,1,10))\n    \n    plt.figure(figsize=(12,8))\n    plt.plot(N,train_score.mean(axis=1),label='train score')\n    plt.plot(N,val_score.mean(axis=1), label = 'validation score')\n    plt.legend()","fabed04c":"evaluation(model)","b4a618de":"pd.DataFrame(model.feature_importances_,index=X_train.columns).plot.bar(figsize=(12,8))","ccdf8419":"model = RandomForestClassifier(random_state=0) ","eadd6716":"evaluation(model)","77e714f4":"pd.DataFrame(model.feature_importances_,index=X_train.columns).plot.bar(figsize=(12,8))","64093e65":"model_2 = make_pipeline( SelectKBest(f_classif, k=4),\n                      RandomForestClassifier(random_state=0))","a3077167":"evaluation(model_2)","b17defe1":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler","59a0dc3d":"preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))","ff415ac9":"RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nAdaBoost=make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor,StandardScaler(),SVC(random_state=0))\nKNN = make_pipeline(preprocessor, StandardScaler(),KNeighborsClassifier())","762556fa":"dict_of_models = {'RandomForest': RandomForest,\n                  'AdaBoost' : AdaBoost,\n                  'SVM': SVM,\n                  'KNN': KNN\n                 }","5657d8eb":"\nfor name, model in dict_of_models.items():\n    print(name)\n    evaluation(model)","3560b2e6":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","74a6c5b9":"SVM","133e3b1a":"hyper_params = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n                'svc__C':[1, 10, 100, 1000, 3000], \n               'pipeline__polynomialfeatures__degree':[2, 3],\n               'pipeline__selectkbest__k': range(45, 60)}","152dc5d0":"#grid= GridSearchCV(SVM, hyper_params, scoring='recall', cv=4)\n#grid.fit(X_train,y_train)\n#print(grid.best_params_)\n\n#y_pred=grid.predict(X_test)\n\n#print(classification_report(y_test,y_pred))","13ec4f2f":"#evaluation(grid.best_estimator_)","e15f92d8":"grid2 = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=4,n_iter=40)\ngrid2.fit(X_train,y_train)\nprint(grid2.best_params_)\n\ny_pred=grid2.predict(X_test)\n\nprint(classification_report(y_test,y_pred))","79b6220f":"evaluation(grid2)","8746b435":"from sklearn.metrics import precision_recall_curve","e88d4530":"precision, recall, threshold = precision_recall_curve(y_test, grid2.best_estimator_.decision_function(X_test))","ddafa21a":"plt.plot(threshold, precision[:-1], label='precision')\nplt.plot(threshold, recall[:-1], label='recall')\nplt.legend()","f83946a2":"def final_model(model, X, threshold=0):\n    return model.decision_function(X) > threshold","3f7f828d":"y_pred = final_model(grid2.best_estimator_, X_test, threshold=-1)","feb6eaea":"f1_score(y_test, y_pred)","49fd16a6":"from sklearn.metrics import recall_score","4d670e6c":"recall_score(y_test, y_pred)","127b0d06":"df_submission1 = pd.Series({'F1 score (%)': f1_score(y_test, y_pred)*100, 'recall score (%)': recall_score(y_test, y_pred)*100})\ndf_submission1.to_csv('F1 and recall scores.csv')\nsub1 = pd.read_csv('F1 and recall scores.csv')\nsub1.columns=['','']\nsub1.index = ['','']","f4c5232c":"sub1","f28f3e0d":"df_submission2 = pd.DataFrame({'Negative test':[confusion_matrix(y_test,y_pred)[0,0],confusion_matrix(y_test,y_pred)[0,1]]\n                  ,'Positive test':[confusion_matrix(y_test,y_pred)[1,0],confusion_matrix(y_test,y_pred)[1,1]]}) \n\ndf_submission2.index=['Negative test','Positive test']\ndf_submission2.to_csv('Predictions(positive-negative).csv')\nsub2 = pd.read_csv('Predictions(positive-negative).csv')","2b8d528d":"sub2","acfd948e":"sub2.columns=['','Negative test','Positive test']\nsub2.index=['','']","90596647":"sub2","c046723e":"# Create a train set and a test set","6f493e78":"# Basic Analysis\n","f69aae8f":"## missing values analysis ","2c50bbe8":"we can see that the viral variables are less important.","0bf33d5c":"We can see that we only identified 17% of positive cases with this simple model.\n\nThe model is clearly overffiting, even when we drop the viral variables","a77696c8":"## Testing null  hypothesis ","7b042593":"### Target\/age","778ab885":"### viral\/viral","5abf471f":"### blood\/blood","c80bfb73":"#  Exploratory Data Analysis\n  \n  \n## Basic Analysis\n\n  * Target variable : SARS-Cov-2 exam result\n  * Rows and columns : 5644 and 111\n  * types of variables : 70 qualitative variables and 41 quantitative variables\n  * Missing values :\n      * A lot of NaN ( half of the variables > 90% of NaN)\n      * two groups of data 76% test and 89% blood level\n      \n  \n  \n  * Target visualization : 10% positive\n  * Meaning of the variables :\n      * standardized continuous variables, skewed variables, blood test\n      * age quantile column : hard to interpret this variable as there are no informations\n      * qualitative variables : binary(0,1), viral, Rhinovirus is very high\n  * Relationship between variables and target :  \n      * target\/blood : monocytes, platelets and leukocytes rates seem to be connected to covid-19 -> we need to test this hypothesis\n      * target\/age : Young people are less contaminated? but as we do not know the age in the age quantile column, we cannot be sure. But this variable can be interesting to compare with blood test results\n     * target\/viral : double diseases are rare. Rhinovirus\/Enterovirus positive  and covid-19 n\u00e9gative? another hypothesis to test. but it is possible to have two diseases, so there is no connection with covid-19.\n     \n     ### summary\n      * Many missing values, we can only keep 20% of the dataset\n      * two groups of interesting data : viral and blood\n      * Almost no variables to distinguish positive and negative cases. We can not know if someone is infected by covid-19 based on Blood test alone. We need to identify the variables that can help us, such as monocytes...\n     \n    ## Detailed Analysis\n    \n    \n * Relationship between variables :\n \n     * blood\/blood : some variables are highly correlated\n     * blood\/age : low correlation between age and blood level\n     * viral\/viral : influenza rapid test lead to bad results, we may have to drop related variables\n     * disease\/blood : blood level between infected and covid-19 are different\n     * hospitalization\/infected : \n     * hospitalization\/blood : interesting if we want to predict in which hospital service a patient should go\n     \n  * Missing values (NaN) analysis :\n  \n      * viral : 1350 (92\/8%)\n      * blood : 600 (87\/13%) \n      * both : 90%\n      \n  * Testing null hypothesis (H): \n      * Patient infected by covid-19 have different Leukocytes, Monocytes and  Platelets rate \n          * H = Mean rates are equal for positive and negative patients : rejected\n      ","cf8099a9":" # PRE-PROCESSING ","8d611b9a":"### Relationship between variables and target","84a7e855":"# Encoding","75f34840":"# Evaluation","8dbdfb62":"### disease\/blood","f9408695":"### Target \/blood","d9ead24f":"This is a work in progress, I will try to improve my predictions by working on the data cleaning, feature enginnering and the modeling, try a deep learning model and XGboost model.\n\nIf you  liked this notebook let me know with a +1 or a comment or both :)\n\nThanks again","35b6e3ee":"# Submission","b22bc6ab":"### Conclusions\n\nIn this work, we analysed a dataset in order to predict if a patient is infected by covid-19 or not. \nWe have seen that it is possible to predict test result as the f1 and recall score are 61% and 66%.","5a756453":"The DecisionTreeClassifier model is overffiting. let us try a RandomForestClassifier","1c63548a":"# Modeling","ab91d4ff":"### Drop the useless columns with 90% of NaN","4ea6f404":"### Target \/viral","82dd9054":"### variables visualization","9fb0cc72":"# Detailed analysis\n\n## Variables\/variables","ec5a6c6e":"### hospitalization\/infected","a89216f5":"# Modeling","0ce26ab1":"### Target column ","a28924e7":"Hi everyone, this is my first project on kaggle. I am sure there are a lot of things that I can improve, so please feel free to give me comments so I can improve my work :)\n\nThanks :)\n"}}