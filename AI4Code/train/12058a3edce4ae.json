{"cell_type":{"0a27e93a":"code","40f07129":"code","23ca0ddc":"code","a3a90fcc":"code","bf38ea77":"code","0fdcf212":"code","6abd9052":"code","4071a452":"code","219146a5":"code","ff9e90ca":"code","25f96991":"code","8f7c0e51":"markdown","db69b152":"markdown","135d4e38":"markdown"},"source":{"0a27e93a":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv(\"..\/input\/incident-impact-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/incident-impact-prediction\/test.csv\")","40f07129":"Y = train.impact\ntrain.drop(['impact'], axis=1, inplace=True)\nX = train\ndel train","23ca0ddc":"X.drop(['Unnamed: 0', 'created_at', 'updated_at'], axis=1, inplace=True)\nprint(test.columns)\ntest.drop(['S.No', 'created_at', 'updated_at'], axis=1, inplace=True)\nprint(Y.shape, X.shape)\nprint(Y.describe())\nprint(X.describe())\ncategorical = [col for col in X.columns if X[col].dtype==object]\nnumerical = [col for col in X.columns if X[col].dtype!=object]\nprint(categorical, len(categorical))\nprint(numerical, len(numerical))","a3a90fcc":"for col in categorical:\n    temp = {}\n    count = 0\n    for val in X[col].values:\n        try:\n            temp[val]\n        except:\n            temp[val] = count\n            count += 1\n    for val in test[col].values:\n        try:\n            temp[val]\n        except:\n            temp[val] = count\n            count += 1\n    X[col] = [temp[x] for x in X[col].values]\n    test[col] = [temp[x] for x in test[col].values]\nprint(X[categorical])","bf38ea77":"#Eliminate the NAN\nfor col in X.columns:\n    X.loc[X[col] == '?', col] = 0\n\n#Check the unique values\nimport seaborn as sns\nnu = X.nunique().reset_index()\nnu.columns = ['features', 'uniques']\nax = sns.barplot(x='features', y='uniques', data=nu)\nax.tick_params(axis='x', rotation=90)\nprint(nu)","0fdcf212":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.heatmap(X.corr(), annot=True, linewidth=0.02)\nfig=plt.gcf()\nfig.set_size_inches(20,20)\nplt.show()","6abd9052":"corr = X.corr()\ndrop_cols = []\nfor col in X.columns:\n    if sum(corr[col].map(lambda x: abs(x) > 0.1)) <= 4:\n        drop_cols.append(col)\nX.drop(drop_cols, axis=1, inplace=True)\nprint(drop_cols)\ndisplay(X)","4071a452":"from sklearn import tree, feature_extraction\nfrom sklearn.model_selection import cross_val_score\nclf = tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_depth=100,\n    random_state=11\n)\n\nprint(cross_val_score(clf, X, Y, cv=5))","219146a5":"clf.fit(X, Y)\np = clf.predict(X)\npredict = clf.predict(test.drop(drop_cols, axis=1))","ff9e90ca":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncfm = confusion_matrix(Y, p)\nsns.heatmap(cfm, annot=True)\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nplt.show()","25f96991":"#Save Prediciton\nss = pd.DataFrame(zip([x for x in range(1, len(predict)+1)], predict), columns=['ID', 'prediction1'])\nprint(ss.shape)\nss.to_csv('submission.csv', index=False)","8f7c0e51":"#Read the Input Data","db69b152":"#Checking the predictions","135d4e38":"#Data Processing"}}