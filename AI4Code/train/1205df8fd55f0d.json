{"cell_type":{"25692555":"code","a708eaf8":"code","6fc75753":"code","f5c85bd7":"code","019251bc":"code","07c4147b":"code","3470e307":"code","6ae19858":"code","d77b262a":"code","ed7cc990":"code","d58cce3d":"code","ba7f1522":"code","fe724650":"code","4ebfb6d9":"code","55768d49":"code","b088e972":"code","e393b842":"code","119ef3ed":"code","724ae2e1":"code","e3e23e19":"code","bd2ea113":"code","19225bd7":"code","cdc56ea4":"code","6c5cfbc4":"code","efecab2c":"code","8bc6c0c6":"code","90aa87d1":"code","2713a372":"code","e3ae2108":"code","23601e7f":"code","01f4bff2":"code","00e06a36":"code","00b122a2":"code","800a0931":"code","9b93718f":"code","7ba15472":"code","a81df5ee":"code","d9e58c37":"code","368814e3":"code","87e2723f":"code","1ab21d44":"code","2406ca00":"code","bd183d74":"code","74203a19":"code","a146ac0e":"code","f60a3655":"code","72083889":"code","f95e3dc0":"code","9c063285":"code","fc26386c":"code","6f9b5fb4":"code","e134a09d":"code","15d6f454":"code","f91dcd0f":"code","7441e30f":"code","e570e9aa":"code","050f4d7f":"markdown","5ae6f1d4":"markdown","222e1ac3":"markdown","4e0f4c56":"markdown","a46980b0":"markdown","fcff63d4":"markdown","ad345e56":"markdown","ea8930ac":"markdown","3b85c57e":"markdown","7ffefe5d":"markdown","2ba69186":"markdown","7b98e72d":"markdown","00ebb2d0":"markdown","bcfedefa":"markdown","b1d29806":"markdown","6c7cbcd9":"markdown","3202bdf8":"markdown"},"source":{"25692555":"'''\nLearn Covid Platform COVID-19 Impact\n'''\n\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\n\nimport os\nimport re\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\n\nplt.style.use('seaborn-whitegrid') #Seaborn style\n","a708eaf8":"# List all files available\ndistricts = []\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        data = os.path.join(dirname, filename)\n        # print(os.path.join(dirname, filename))","6fc75753":"# Districts Info \n#filtrar datos en base a district_info.csv\n%time\ndistricts_path = \"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\"\ndistricts_info_df = pd.read_csv(districts_path)\nprint(districts_info_df.info())\nprint(districts_info_df.head())\nprint(districts_info_df.isna().sum())\nprint(\"==Delete all district that has state as NaN\")\ndistricts_info_df = districts_info_df[districts_info_df.state.notna()].reset_index(drop=True)\nprint(districts_info_df.isna().sum())\nprint(districts_info_df.head())\ndistricts_info_df = pd.read_csv(districts_path)\nprint(districts_info_df.info())\nprint(districts_info_df.head())\nprint(districts_info_df.isna().sum())\nprint(\"==Delete all district that has state as NaN\")\ndistricts_info_df = districts_info_df[districts_info_df.state.notna()].reset_index(drop=True)\nprint(districts_info_df.isna().sum())\nprint(districts_info_df.head())","f5c85bd7":"%time\nproducts_path = \"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\"\nproducts_info_df = pd.read_csv(products_path)\n# Rename column \"LP ID\"\n# prod_cols = products_info_df.columns.tolist()\n# prod_cols[0] = \"lp_id\"\n# products_info_df.columns=prod_cols\n# products_info_df.head()\n\ntemp_sectors = products_info_df['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_info_df = products_info_df.join(temp_sectors)\nproducts_info_df.drop(\"Sector(s)\", axis=1, inplace=True)\n\ndel temp_sectors\n\nproducts_info_df['primary_function_main'] = products_info_df['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_info_df['primary_function_sub'] = products_info_df['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_info_df['primary_function_sub'] = products_info_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts_info_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\nprint(products_info_df.head())","019251bc":"districts_info_df.sort_values(by=\"district_id\", ascending=True)","07c4147b":"%time\n\nENGAGEMENT_PATH = \"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\"\n\ntemp = []\n\nfor district in districts_info_df.district_id.unique():\n    df = pd.read_csv(f'{ENGAGEMENT_PATH}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    if df.time.nunique() == 366:\n        temp.append(df)\n\nall_engagement_df = pd.concat(temp)\nall_engagement_df = all_engagement_df.reset_index(drop=True)\n\n# Only consider districts with full 2020 engagement data\ndistricts_info_df = districts_info_df[districts_info_df.district_id.isin(all_engagement_df.district_id.unique())].reset_index(drop=True)\nproducts_info_df = products_info_df[products_info_df['LP ID'].isin(all_engagement_df.lp_id.unique())].reset_index(drop=True)","3470e307":"#Printing the total number of rowns in engagement\nall_engagement_df = all_engagement_df[all_engagement_df.lp_id.isin(products_info_df['LP ID'].unique())]\nprint(len(all_engagement_df))","6ae19858":"# Fix date column\nall_engagement_df.time = all_engagement_df.time.astype('datetime64[ns]')","d77b262a":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_info_df['state_abbrev'] = districts_info_df['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_info_df['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']","ed7cc990":"fig = go.Figure()\nlayout = dict(\n    title_text = \"Available School Districts in each State\",\n    geo_scope='usa',\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations=districts_info_by_state.state_abbrev,\n        zmax=1,\n        z = districts_info_by_state.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='white',\n        geo='geo',\n        colorscale=px.colors.sequential.RdBu_r, \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","d58cce3d":"#Checking the dtype of each column\nall_engagement_df.info()","ba7f1522":"all_engagement_df.head()","fe724650":"# All engagement number of rows\nall_engagement_df.shape","4ebfb6d9":"# Merging the districts with engagement data\nengagement_district_df = all_engagement_df.merge(districts_info_df, on=\"district_id\", how=\"right\")\nengagement_district_df.head()","55768d49":"# Merging the districts with engagement data2\nengagement_district_df = all_engagement_df.merge(districts_info_df, on=\"district_id\", how=\"right\")\nengagement_district_df.head()","b088e972":"# View number of registers\nengagement_district_df.shape","e393b842":"engagement_district_df.dropna(subset=[\"lp_id\"],inplace=True)\nengagement_district_df.shape","119ef3ed":"# View NA in engagment_district_df \nengagement_district_df.isna().sum()","724ae2e1":"products_info_df.isna().sum()","e3e23e19":"pd.DataFrame(engagement_district_df.state.value_counts())","bd2ea113":"# Merge engagement_district_df with productos_info_df\n# Rename column \"LP ID\"\nprod_cols = products_info_df.columns.tolist()\nprod_cols[0] = \"lp_id\"\nproducts_info_df.columns=prod_cols\nengagement_district_product_df = engagement_district_df.merge(products_info_df, on=\"lp_id\", how=\"left\")\nengagement_district_product_df.shape","19225bd7":"engagement_district_product_df[engagement_district_product_df[\"URL\"].isna()]","cdc56ea4":"# NaN in engagement_district_product_df\npd.DataFrame(engagement_district_product_df.isna().sum())","6c5cfbc4":"# Delete rows with NA in engagement_index\nengagement_district_product_df.dropna(subset=[\"engagement_index\"],inplace=True)\nengagement_district_product_df.shape","efecab2c":"engagement_district_product_df.head()","8bc6c0c6":"pd.DataFrame(engagement_district_product_df['Product Name'].value_counts())","90aa87d1":"# Separating data in pct_black\/hispanic in different columns\nengagement_district_product_df['pct_black'] = engagement_district_product_df['pct_black\/hispanic'].map(lambda x: float(x.split(\",\")[0][1:]))\npd.unique(engagement_district_product_df['pct_black'])\nengagement_district_product_df['pct_hispanic'] = engagement_district_product_df['pct_black\/hispanic'].map(lambda x: float(x.split(\",\")[1][:-1]))\npd.unique(engagement_district_product_df['pct_hispanic'])","2713a372":"# Separate data in pct_free\/reduced in diferent columns\nengagement_district_product_df['pct_free'] = engagement_district_product_df['pct_free\/reduced'].map(lambda x: float(str(x).split(\",\")[0][1:]), na_action='ignore')\npd.unique(engagement_district_product_df['pct_free'])\nengagement_district_product_df['pct_reduced'] = engagement_district_product_df['pct_free\/reduced'].map(lambda x: float(str(x).split(\",\")[1][:-1]), na_action='ignore')\npd.unique(engagement_district_product_df['pct_reduced'])","e3ae2108":"# Final Dataframe\nengagement_district_product_df.head()","23601e7f":"# Parameters\nlist_state = list(pd.unique(engagement_district_product_df['state']))\nlist_products = list(pd.unique(engagement_district_product_df['Product Name']))\nlist_companies = list(pd.unique(engagement_district_product_df['Provider\/Company Name']))\nlist_locale = list(pd.unique(engagement_district_product_df['locale']))\nlist_date = list(pd.unique(engagement_district_product_df['time']))","01f4bff2":"def plot_engagement_state_product(state,product_name):\n  global engagement_district_product_df\n  df = engagement_district_product_df.loc[engagement_district_product_df['Product Name'] == product_name]\n  df2 = df.loc[df['state'] == state]\n  data = df2.groupby('time')['engagement_index'].mean()\n  # print(df2.groupby('time')['engagement_index'].mean())\n  plt.figure(figsize=(18,5))\n  plt.plot(data)\n  plt.show()","00e06a36":"# Mean Engament_index by date (with state and product_name as parameters)\ninteract(plot_engagement_state_product, state=list_state, product_name = list_products);","00b122a2":"def plot_engagement_state_company(state,company):\n  global engagement_district_product_df\n  df = engagement_district_product_df.loc[engagement_district_product_df['Provider\/Company Name'] == company]\n  df2 = df.loc[df['state'] == state]\n  data = df2.groupby('time')['engagement_index'].mean()\n  # print(df2.groupby('time')['engagement_index'].mean())\n  plt.figure(figsize=(18,5))\n  plt.plot(data)\n  plt.show()","800a0931":"# Mean Engament_index by date (with state and company as parameters)\ninteract(plot_engagement_state_company, state=list_state, company = list_companies);","9b93718f":"def plot_engagement_state_locale(state,locale):\n  global engagement_district_product_df\n  df = engagement_district_product_df.loc[engagement_district_product_df['locale'] == locale]\n  df2 = df.loc[df['state'] == state]\n  data = df2.groupby('time')['engagement_index'].mean()\n  # print(df2.groupby('time')['engagement_index'].mean())\n  plt.figure(figsize=(18,5))\n  plt.plot(data)\n  plt.show()","7ba15472":"# Mean Engament_index by date (with state and locale\/type of state as parameters)\ninteract(plot_engagement_state_locale, state=list_state, locale = list_locale);","a81df5ee":"def map_by_product_time(product,time):\n    global engagement_district_product_df\n    df = engagement_district_product_df.loc[engagement_district_product_df['Product Name'] == product]\n    df2 = df.loc[df['time'] == time]\n    data = df2.groupby('state_abbrev')['engagement_index'].mean().to_frame().reset_index(drop=False)\n    \n    data.columns = ['state_abbrev', 'mean_engagement']\n    \n    fig = go.Figure()\n    layout = dict(\n        title_text = \"Average Engagement Index by State\",\n        geo_scope='usa',\n    )\n\n    fig.add_trace(\n        go.Choropleth(\n            locations=data.state_abbrev,\n            zmax=1,\n            z = data.mean_engagement,\n            locationmode = 'USA-states', # set of locations match entries in `locations`\n            marker_line_color='white',\n            geo='geo',\n            colorscale=px.colors.sequential.RdBu_r, \n        )\n    )\n\n    fig.update_layout(layout)   \n    fig.show()","d9e58c37":"# Mean Engament_index by state in a map (with product and time as parameters)\ninteract(map_by_product_time, product=list_products, time = list_date);","368814e3":"# Which is the most popular company\nplt.figure(figsize=(10,70))\nengagement_district_product_df['Provider\/Company Name'].value_counts().sort_values(ascending=True).plot.barh()\nplt.title(\"Most Popular Provider Company\")\nplt.ylabel(\"Name\")\nplt.xlabel(\"Frequency\");","87e2723f":"# Which is the most used product\nplt.figure(figsize=(10,10))\nengagement_district_product_df['Product Name'].value_counts().sort_values(ascending=True)[0:15].plot.barh()\nplt.xlabel(\"Frequency\")\nplt.title(\"Most Used Products\");\n","1ab21d44":"# Which is the most used product\nplt.figure(figsize=(18,5))\nengagement_district_product_df['Product Name'].value_counts()[7:20].sort_values(ascending=True).plot.barh()\nplt.ylabel(\"Frequency\")\nplt.xlabel(\"Products\")\nplt.title(\"Most Used Products w\/o Google Suite\");","2406ca00":"# Which is the most popular product\nplt.figure(figsize=(10,80))\nengagement_district_product_df['Product Name'].value_counts().sort_values(ascending=True).plot.barh();\nplt.title(\"Most Popular Product\");","bd183d74":"# Most popular products \nmost_popular_products = engagement_district_product_df['Product Name'].value_counts()[0:20]\nmost_popular_products = most_popular_products.index.tolist()\nmost_popular_products","74203a19":"# Import extra libraries\nimport datetime\nimport glob\nfrom ipywidgets import interact, interactive, fixed, interact_manual\n\n# Create a list with path to daily report of covid-19 data for every day of 2020\nCOVID_PATH = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports_us\"\nnumdays = 366\nbase = datetime.date(2020, 1, 1)\ndate_list = [base + datetime.timedelta(days=x) for x in range(numdays)]\ncovid_path_list = []\ntemp = []\nfor date in date_list:\n  day = str(date.day)\n  if len(day)==1:\n    day = \"0\"+day\n\n  month = str(date.month)\n  if len(month)==1:\n    month = \"0\"+month\n\n  path = COVID_PATH + \"\/\"+month +\"-\" +day +\"-\" +str(date.year)+\".csv\"\n  covid_path_list.append(path)\n\n# Read and append only files from 4th of April (first case) to the end of year 2020.\nfor filename in covid_path_list[102:]:\n  df_1 = pd.read_csv(filename, index_col=None, header=0)\n  temp.append(df_1)\n\n# Create database from extracted data\nall_covid_cases_df = pd.concat(temp)\nall_covid_cases_df = all_covid_cases_df.reset_index(drop=True)","a146ac0e":"engagement_district_product_df_1 = engagement_district_product_df[4065:]\nprint(all_covid_cases_df.head())\nprint(engagement_district_product_df_1.head())\nprint(engagement_district_product_df.head())","f60a3655":"print(all_covid_cases_df.columns)\n# Sepparate colum \"Last_Update\", which has hour and date of report, into a column that only has date, and another that only has hour\nall_covid_cases_df[['time', 'LU_hour']] = all_covid_cases_df['Last_Update'].str.split(' ',4,expand=True)","72083889":"# Function. Graphs reported cases of Covid-19 according to date, and Engagement of a Given product by State during 2020. \n# Two plots are made\ndef get_covid_graph(Province_State, product_name):\n  global all_covid_cases_df\n  df_c = all_covid_cases_df.loc[all_covid_cases_df['Province_State'] == Province_State]\n  data_c = df_c.groupby('time')['Confirmed'].mean()\n  plt.figure(figsize=(30,5))\n  plt.plot(data_c)\n  plt.show()\n\n  global engagement_district_product_df_1\n  df = engagement_district_product_df_1.loc[engagement_district_product_df_1['Product Name'] == product_name]\n  df2 = df.loc[df['state'] == Province_State]\n  data = df2.groupby('time')['engagement_index'].mean()\n  \n  plt.figure(figsize=(30,5))\n  plt.plot(data)\n  plt.show()","f95e3dc0":"# Example of Function. Using Utah as a State and Google Drive as the product to analize engagement.\nget_covid_graph('Utah', 'Google Drive')","9c063285":"# Use of Python's interact function to create a small UI to control Province State and Product Name interactively \ninteract(get_covid_graph, Province_State=['Connecticut', 'Utah', 'Massachusetts', 'Illinois', 'California', 'Ohio', 'Missouri', 'Indiana', 'Washington', 'Virginia', 'North Carolina', 'New Jersey', 'New Hampshire', 'Michigan', 'District Of Columbia', 'Arizona', 'New York', 'Tennessee', 'Florida'], product_name=['Google Drive','YouTube','Google Classroom']);","fc26386c":"# Forecast based in product_name and state\ndef forecasting(product_name,state):\n  global engagement_district_product_df\n  df = engagement_district_product_df.loc[engagement_district_product_df['Product Name'] == product_name]\n  df2 = df.loc[df['state'] == state]\n  print(df2.shape)\n  data = df2.groupby('time')['engagement_index'].mean().values\n  print( df.loc[df['state'] == state])\n  # fit model\n  model = SARIMAX(data, order=(1, 0, 0), seasonal_order=(1, 0, 0, 12))\n  model_fit = model.fit(disp=False)\n  # make prediction\n  yhat = model_fit.predict()\n  print(len(yhat))\n  return yhat","6f9b5fb4":"predictions = forecasting(\"Google Docs\",\"Utah\")\nplt.figure(figsize=(18,5))\nplt.plot(predictions)\nplt.show()","e134a09d":"#Weekend Eradication\ndef weekendEr(predictions):\n  a=2\n  global engagement_district_product_df\n  arr=[]\n  x=0\n  \n  while(x<366):\n    x+=1\n    if(x==a or x==a+1):\n      if(x==a):\n        arr.append(x)\n      else:\n        arr.append(x)\n        a=a+6\n\n  print(len(arr))\n  print(predictions.shape)\n  \n  predictions2=pd.DataFrame(predictions)\n  predictions2.drop(labels=arr, axis=0,  columns=None, level=None, inplace=True, errors='raise')\n  pred=predictions2.to_numpy()\n  print(predictions2.shape)\n  return predictions2","15d6f454":"#promedy for 5 days\ndef med(predictions):\n  a=0\n  sum=0\n  arr=[]\n  for x in range(365):\n    if(a==4):\n      arr.append(sum\/5)\n      sum=0\n      a=0\n    sum=sum+predictions[x]\n    a+=1\n  predictions2=pd.DataFrame(arr)\n  return predictions2","f91dcd0f":"#average data every 5 days\npredictionsEradication = med(predictions)\nprint(predictionsEradication.head)\nplt.figure(figsize=(18,5))\nplt.plot(predictionsEradication)\nplt.show()","7441e30f":"#promedy for 5 days\ndef comparison(engagement_comparison):\n  nmp=engagement_comparison.to_numpy()\n  #First part of the year 152 days \n  a=0\n  #we take out 92 days that are the summer vacation\n  #the second part of the year will be conforme by 108 days because\n  #we take out the last 2 weeks of december for vacations\n  b=244\n  sum=0\n  sum2=0\n  arr=[]\n  for x in range(152):\n    sum=sum+nmp[x]\n\n  for y in range(108):\n    sum2=sum2+nmp[y+244]\n\n  arr.append(sum\/152)\n  arr.append(sum2\/108)\n  comp=pd.DataFrame(arr)\n  return comp\n","e570e9aa":"#comparison of engagement in the first half of the year and in the last half of the year, taking out the vacations \ncomp=comparison(engagement_district_product_df['engagement_index'])\nprint(comp.shape)\nprint(comp.head)\n# print(engagement_district_product_df['engagement_index'].shape)","050f4d7f":"# Mean Engament index by date by State (Dropdown) and Locale (Dropdown)\nUse the dropdowns to interact","5ae6f1d4":"# Mean Engament index by date by State (Dropdown) and Locale (Dropdown)\nUse the dropdowns to interact","222e1ac3":"We can infer that in the first 2020 semester the engagement_index average was greather than the second 2020 semester","4e0f4c56":"# Most Popular\nIn this section we present an analysis of most popular products","a46980b0":"# Engagement Data\nWe are only considering districts with full 2020 engagement data to avoid some errors and bias on incomplete data.","fcff63d4":"# Mean Engament index by State (dropdown) and product (dropdown)\nUse the dropdowns to interact","ad345e56":"# Lost values on the final table that include Engagement | District | Product\nThese lost values are cleaned","ea8930ac":"# Interactive Graphics\nIn this section we will present a series of graphics in which you as a reader can interact and select new parameters, this section uses dropdowns to select the state and different parameters for the the Exploratory Data Analysis (May need to be runned inside Kaggle to be seen)","3b85c57e":"# Districts Info\nWe dropped all the values with Nan from districts","7ffefe5d":"# Exploring the Final Table","2ba69186":"# Mean Engament index by State (dropdown) and Companies (dropdown)\nUse the dropdowns to interact","7b98e72d":"# Relation of Engagement and Deaths in USA\nIn this section we will present an analysis about the posibbly relation into engagement and number of deaths caused by Covid-19","00ebb2d0":"# Forecasting of engagement_index\n","bcfedefa":"# Number of values for each product","b1d29806":"# Number of available data by each State","6c7cbcd9":"# Products Info","3202bdf8":"# Number of Available School Districts per State"}}