{"cell_type":{"2dfae899":"code","c7047007":"code","7bb44f34":"code","6d59df54":"code","96dca597":"code","10289f82":"code","be55c42b":"code","5cce3145":"code","b193e3e0":"code","d8202d98":"code","46075eb1":"code","35ae96db":"markdown","3164abe9":"markdown","aa5634a6":"markdown","3f992d7f":"markdown","a7712974":"markdown","28ce1cf8":"markdown","16b7c71d":"markdown","3e0aea8e":"markdown","ced17db7":"markdown"},"source":{"2dfae899":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c7047007":"import pandas as pd\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain_data.columns","7bb44f34":"y = train_data.Survived\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Ticket', 'Cabin', 'Embarked']\nX = train_data[features]\nX_test = test_data[features]\ntrain_data.describe()","6d59df54":"X.head()","96dca597":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 42)\ncategorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n                        X[cname].dtype == \"object\"]\nnumerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]","10289f82":"my_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_valid = X_valid[my_cols].copy()\nX = X[my_cols].copy()\nX_test = X_test[my_cols].copy()","be55c42b":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nnumerical_transformer = SimpleImputer(strategy = 'constant')\ncategorial_transformer = Pipeline(steps = [\n    ('imputer', SimpleImputer(strategy = 'most_frequent')), \n    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n])\npreprocessor = ColumnTransformer(transformers = \n                               [('num', numerical_transformer, numerical_cols),\n                               ('cat', categorial_transformer, categorical_cols)\n                               ])","5cce3145":"from sklearn.ensemble import GradientBoostingClassifier\nmy_model = GradientBoostingClassifier()","b193e3e0":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nmy_pipeline = Pipeline(steps =\n                      [('processor', preprocessor), \n                      ('model', my_model)])\nmy_pipeline.fit(X_train, y_train)\npreds_test = my_pipeline.predict(X_valid)\nmy_pipeline.score(X_valid, y_valid)","d8202d98":"my_pipeline.fit(X, y)\npreds =my_pipeline.predict(X_test)","46075eb1":"output = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                       'Survived': preds})\noutput.to_csv('submission.csv', index=False)","35ae96db":"# **Simple and easy to understand and wrote in very few lines**","3164abe9":"Here are some of the models that I have used\n\nRidgeclassifier, LogisticRegression, SGDClassifier from linear_models; GradientBoostingClassifier, RandomForestClassifier, from ensemble; SVC from svm","aa5634a6":"Even though I am getting less accuracy_score using GradientBoosyingClassifier I am using it in my model because it is perofrming well on test data","3f992d7f":"# If you feel it is simple and useful please UPVOTE  ","a7712974":"**Not given any data description to minimize the length of notebook**\n\nAnd also it is easy to understand given features as there are very few of them","28ce1cf8":"Various Classification models are avaliable in sklearn you checkout those models and comapre those models scores","16b7c71d":"**PUBLIC SCORE 0.78947**","3e0aea8e":"It is my first notebook in Kaggle so if you have any suggestions please post them\n\nInstead of import everything at once I have imported everything as required","ced17db7":"If you have any doubts about Pipelines you can refer to Intermidate machine learning in courses section (Kaggle)"}}