{"cell_type":{"6718e27d":"code","74bea322":"code","ae8afcf6":"code","c539911b":"code","3497b1cf":"code","d483ece4":"code","a0673c4d":"code","6b5cfd96":"code","55bcb80f":"code","0bdef153":"code","81ed433c":"code","1501b9c4":"code","ad61d66b":"code","7f6f21b3":"code","27500680":"code","d0591240":"code","76e58a80":"code","a16994e0":"code","c5b4f2d4":"code","6a76f731":"code","085fd08e":"code","1ef7f0a9":"code","f6717bad":"code","a8d2b9b8":"code","d3195935":"code","73aa5d6e":"code","5abff4c6":"code","b8d6e8fe":"code","e79d52d3":"code","bc9a848c":"code","9baa17f6":"code","31ebb006":"code","614cfe02":"code","d02f0c33":"code","9ff6bb79":"markdown","91132fc2":"markdown","9f7a740f":"markdown","0a38d8e6":"markdown","0da3674d":"markdown","2f21d32e":"markdown","5d6757ea":"markdown","e3b3dd76":"markdown","cded49ff":"markdown","89203c41":"markdown","9fd55f16":"markdown","105fdd3e":"markdown","1649959e":"markdown","65ad71d1":"markdown","6c59aa34":"markdown","9c97ef0e":"markdown","ec493a45":"markdown","bcba1fdb":"markdown","16238085":"markdown","a415063f":"markdown"},"source":{"6718e27d":"# load libraries\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt # ploting the data\nimport seaborn as sns # ploting the data\nimport math # calculation\n\nfrom textblob import TextBlob #test analysis\nimport nltk\nfrom wordcloud import WordCloud # to generatewordcloud analysis","74bea322":"# Load the dataset\ndf = pd.read_csv('\/kaggle\/input\/Observations2.csv', engine = \"python\")","ae8afcf6":"df.info()","c539911b":"# Drop the unnecessary variables or the variables not entered by the user in the application\ndf.drop(['ID', 'HSWorEnv', 'Location', 'FatalCategory', 'HEObservationCategory'], axis=1, inplace=True)","3497b1cf":"# Polarity: \ndef extract_sentiment_polarity(text):\n    try:\n        return TextBlob(text).sentiment.polarity\n    except:\n        return None\n\ndef extract_sentiment_subjectivity(text):\n    try:\n        return TextBlob(text).sentiment.subjectivity\n    except:\n        return None\n    \ndf[\"Summary_polarity\"] = df[\"Summary\"].apply(extract_sentiment_polarity)\ndf[\"Summary_subjectivity\"] = df[\"Summary\"].apply(extract_sentiment_subjectivity)\n\ndf[\"Description_polarity\"] = df[\"Description\"].apply(extract_sentiment_polarity)\ndf[\"Description_subjectivity\"] = df[\"Description\"].apply(extract_sentiment_subjectivity)\n\ndf[\"ActionTaken_polarity\"] = df[\"ActionTaken\"].apply(extract_sentiment_polarity)\ndf[\"ActionTaken_subjectivity\"] = df[\"ActionTaken\"].apply(extract_sentiment_subjectivity)","d483ece4":"# Set up visualization colors\n\n# Set up color blind friendly color palette\n# The palette with grey:\ncbPalette = [\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n# The palette with black:\ncbbPalette = [\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n\n# sns.palplot(sns.color_palette(cbPalette))\n# sns.palplot(sns.color_palette(cbbPalette))\n\nsns.set_palette(cbPalette)\n#sns.set_palette(cbbPalette)","a0673c4d":"title = 'Practice Type Count'\nsns.countplot(y = df['PracticeType'])\nplt.title(title)\nplt.ioff()","6b5cfd96":"title = ' Count IncidentType'\nf, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(y = df['IncidentType'])\nplt.title(title)\nplt.ioff()","55bcb80f":"title = 'Section Count'\nsns.countplot(y = df['Section'])\nplt.title(title)\nplt.ioff()","0bdef153":"title = 'HEReportingType Count'\nsns.countplot(y = df['HEReportingType'])\nplt.title(title)\nplt.ioff()","81ed433c":"title = 'Median Summary Polarity per Practice Type'\nresult = df.groupby([\"PracticeType\"])['Summary_polarity'].aggregate(np.median).reset_index().sort_values('Summary_polarity')\nsns.barplot(x='PracticeType', y=\"Summary_polarity\", data=df)\nplt.title(title)\nplt.ioff()","1501b9c4":"title = 'Median Summary Subjectivity per Practice Type'\nresult = df.groupby(['PracticeType'])['Summary_subjectivity'].aggregate(np.median).reset_index().sort_values('Summary_subjectivity')\nsns.barplot(x='PracticeType', y='Summary_subjectivity', data=df)\nplt.title(title)\nplt.ioff()","ad61d66b":"title = 'Descrition Polarity per Practice Type'\nresult = df.groupby(['PracticeType'])['Description_polarity'].aggregate(np.median).reset_index().sort_values('Description_polarity')\nsns.barplot(x='PracticeType', y='Description_polarity', data=df)\nplt.title(title)\nplt.ioff()","7f6f21b3":"title = 'Descrition Subjectivity per Practice Type'\nresult = df.groupby(['PracticeType'])['Description_subjectivity'].aggregate(np.median).reset_index().sort_values('Description_subjectivity')\nsns.barplot(x='PracticeType', y='Description_subjectivity', data=df)\nplt.title(title)\nplt.ioff()","27500680":"# see https:\/\/www.kaggle.com\/nidaguler\/eda-and-data-visualization-ny-airbnb\ntitle = 'Median Sentiment Polarity according to Section'\nresult = df.groupby(['Section'])['Summary_polarity'].aggregate(np.median).reset_index().sort_values('Summary_polarity')\nsns.barplot(x='Section', y='Summary_polarity', data=df, order=result['Section'])\nplt.title(title)\nplt.ioff()","d0591240":"f, ax = plt.subplots(figsize=(12, 12))\ntitle = 'Sentiment Polarity according to Incident type'\nresult = df.groupby(['IncidentType'])['Summary_polarity'].aggregate(np.median).reset_index().sort_values('Summary_polarity')\nsns.barplot(y='IncidentType', x='Summary_polarity', data=df, order=result['IncidentType'])\nplt.title(title)\nplt.ioff()","76e58a80":"pd.crosstab(index=df['PracticeType'], columns=df['IncidentType'])","a16994e0":"contingency_table = pd.crosstab(index=df['PracticeType'], \n                          columns=df['Section'])\ncontingency_table","c5b4f2d4":"contingency_table.plot(kind=\"bar\", \n                 figsize=(8,8),\n                 stacked=True)","6a76f731":"contingency_table = pd.crosstab(index=df['PracticeType'], \n                          columns=df['HEReportingType'])\ncontingency_table","085fd08e":"contingency_table.plot(kind=\"bar\", \n                 figsize=(8,8),\n                 stacked=True)","1ef7f0a9":"# Separate the data into Hazard and Good Practice dataset\ndf_Hazard = df.loc[(df['PracticeType'] == 'Hazard')]\ndf_Good = df.loc[(df['PracticeType'] == 'Good Practice')]","f6717bad":"# See https:\/\/stackoverflow.com\/questions\/33279940\/how-to-combine-multiple-rows-of-strings-into-one-using-pandas\ntext_hazard = df_Hazard.Summary.str.cat(sep=', ') # Contenate the text of all rows of the Summary column\nprint (\"There are {} words in the combination of all Summary.\".format(len(text_hazard)))","a8d2b9b8":"# https:\/\/www.datacamp.com\/community\/tutorials\/wordcloud-python\n# Create stopword list:\nstopwords = (['for', 'in', 'the', 'and', 'on', 'site', 'to', 'or', 'with', 'from', 'A14', 'when', 'there', 'is'])\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text_hazard)\n\n# Display the generated image:\n# the matplotlib way:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","d3195935":"text_good = df_Good.Summary.str.cat(sep=', ') # Contenate the text of all rows of the Summary column\nprint (\"There are {} words in the combination of all Summary.\".format(len(text_good)))","73aa5d6e":"wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text_good)\n\n# Display the generated image:\n# the matplotlib way:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","5abff4c6":"df.drop(['ObservationDateTime', 'Summary', 'Description', 'ActionTaken', 'HEReportingType'], axis=1, inplace=True)","b8d6e8fe":"# Encoding categorical data\n# See https:\/\/pbpython.com\/categorical-encoding.html\n#data = pd.get_dummies(data, columns=['IncidentType', 'Section', 'HEReportingType'], drop_first=True)\ndf = pd.get_dummies(df, columns=['IncidentType', 'Section'], drop_first=True)","e79d52d3":"# Keep only the row with known PracticeType\ndf =  df.loc[(df['PracticeType'] == 'Hazard') | (df['PracticeType'] == 'Good Practice')]","bc9a848c":"# Split the dataset\ny = df['PracticeType'].values","9baa17f6":"# https:\/\/machinelearningmastery.com\/handle-missing-data-python\/\nfrom sklearn.impute import SimpleImputer\nvalues = df.drop('PracticeType', axis=1).values\nimputer = SimpleImputer()\ntransformed_values = imputer.fit_transform(values)\n# count the number of NaN values in each column\nprint(np.isnan(transformed_values).sum())","31ebb006":"X = transformed_values","614cfe02":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","d02f0c33":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\n\naccuracy_score(y_test, y_predict)","9ff6bb79":"The user of the [A14 road](https:\/\/highwaysengland.co.uk\/A14-Cambridge-to-Huntingdon-Improvement-Scheme-home) can report incident using an application. The goal of this challenge proposed by the organizers of the [Project:Hack5 hackathon](https:\/\/projectdataanalytics.uk\/eventer\/projecthack-5) and [Highways England](https:\/\/highwaysengland.co.uk\/) is to perform sentiment analysis to obtain new insigts from the users comments and improve the user experiences on the application.","91132fc2":"## Modeling the Practice Type","9f7a740f":"# Variables Description\n\n* ID: identification number of the user reporting an incident on the A14 road\n* PracticeType: User entered report nature: Hazard or Good Practice Observation\n* IncidentType: Type of event reported\n* HSWorEn: Nature of the incident: Health and Safety or Environement\n* Section: Section of A14 road where the incident occured\n* Location: Precised location on the section\n* ObservationDateTime: Data and time of the user from completion\n* Summary: Short sumary of the report entered by the user\n* Description: Full description of the event by the user\n* ActionTaken: Action taken by Highways England\n* FatalCategory: Category of the incident\n* HEObservationCategory: Category of the Health and Safety Observation\n* HEReportingType: Health and Safety reporting","0a38d8e6":"## Visualization","0da3674d":"### Fit the model: Random Forest\u00b6","2f21d32e":"The goal is to generate autocompletion form for the application users. If we can pre filled some entries the users are more likely to complete the whole form.","5d6757ea":"### Categories count","e3b3dd76":"# Sentiment Analysis from A14 road users comments","cded49ff":"# Conclusion\n\nUsing a Random Forest model, we can predict the nature of the user observation with an 84% accuracy. We could then use this model to prefill this variable on the form filled by the A14 users. This approach will reduce the amount of data to enter for the users and likely increase the form completion rate.","89203c41":"### Sentiment per section","9fd55f16":"## References\n### Visualization\n* https:\/\/www.analyticsvidhya.com\/blog\/2019\/09\/comprehensive-data-visualization-guide-seaborn-python\/\n* https:\/\/elitedatascience.com\/python-seaborn-tutorial\n\n### Categorical Variables\n* https:\/\/dzone.com\/articles\/correlation-between-categorical-and-continuous-var-1\n* https:\/\/adataanalyst.com\/data-analysis-resources\/visualise-categorical-variables-in-python\/\n\n### Natural Language Processing\n* https:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html\n* https:\/\/planspace.org\/20150607-textblob_sentiment\/\n\n### Machine Learning\n* https:\/\/towardsdatascience.com\/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n* https:\/\/stackoverflow.com\/questions\/3172509\/numpy-convert-categorical-string-arrays-to-an-integer-array\n\n### Wordcloud analysis\n* https:\/\/www.datacamp.com\/community\/tutorials\/wordcloud-python\n* https:\/\/www.kaggle.com\/zynicide\/wine-reviews\/kernels\n\n### Modeling\n* https:\/\/ehackz.com\/2018\/03\/23\/python-scikit-learn-random-forest-classifier-tutorial\/\n* https:\/\/scikit-learn.org\/stable\/modules\/ensemble.html\n\n### Missing values\n* https:\/\/machinelearningmastery.com\/handle-missing-data-python\/","105fdd3e":"### Split the dataset","1649959e":"### Data Encoding","65ad71d1":"### PracticeType according to sentiment","6c59aa34":"## Initialization","9c97ef0e":"## Add scores column","ec493a45":"### Deal with missing values","bcba1fdb":"## Introduction","16238085":"### Association between categorical variables","a415063f":"### Wordcloud analysis"}}