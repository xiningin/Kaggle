{"cell_type":{"f7f769c6":"code","5d566834":"code","88f5e432":"code","37c26441":"code","afd9f79f":"code","5c4485b9":"code","04af662f":"code","f71d478e":"code","9fa43c53":"code","3d241801":"code","8b06e344":"code","0ebf7570":"code","3cdbd70c":"code","592ed4da":"code","f00e63a8":"code","a90081b8":"code","f03ab6f7":"code","0cc1048e":"code","723dc364":"code","e28d7de6":"code","3d2ded4d":"code","a40d0458":"code","4509aafb":"code","72908d85":"code","e4af855d":"code","951cf852":"code","dce0d25d":"code","be0e6115":"code","6c9eeb63":"markdown","efe42159":"markdown","fd14ef70":"markdown","8751fc44":"markdown","c8bdc3b2":"markdown","51dc7e6c":"markdown","abf6ee57":"markdown","8c0ea4d6":"markdown","91b1f44a":"markdown","2308d8aa":"markdown","54209697":"markdown","16cdd83c":"markdown","fadb2b3f":"markdown","63e76902":"markdown","f2d667cc":"markdown","3f8bc7d5":"markdown","bdda476b":"markdown","eb507e05":"markdown","6d6ab0e7":"markdown","497a2ee7":"markdown"},"source":{"f7f769c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d566834":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","88f5e432":"train_data.head()","37c26441":"train_data.shape","afd9f79f":"train_data.info()","5c4485b9":"train_data.describe()","04af662f":"train_data.isnull().sum()","f71d478e":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","9fa43c53":"survived = train_data[train_data['Survived']==1]['Sex'].value_counts()\ndead = train_data[train_data['Survived']==0]['Sex'].value_counts()\ndf = pd.DataFrame([survived, dead])\ndf.index = ['Survived', 'Dead']\ndf.plot(kind='bar', stacked='True')","3d241801":"survived = train_data[train_data['Survived']==1]['Pclass'].value_counts()\ndead = train_data[train_data['Survived']==0]['Pclass'].value_counts()\ndf = pd.DataFrame([survived, dead])\ndf.index = ['Survived', 'Dead']\ndf.plot(kind='bar', stacked='True')","8b06e344":"survived = train_data[train_data['Survived']==1]['SibSp'].value_counts()\ndead = train_data[train_data['Survived']==0]['SibSp'].value_counts()\ndf = pd.DataFrame([survived, dead])\ndf.index = ['Survived', 'Dead']\ndf.plot(kind='bar', stacked='True')","0ebf7570":"survived = train_data[train_data['Survived']==1]['Parch'].value_counts()\ndead = train_data[train_data['Survived']==0]['Parch'].value_counts()\ndf = pd.DataFrame([survived, dead])\ndf.index = ['Survived', 'Dead']\ndf.plot(kind='bar', stacked='True')","3cdbd70c":"numerical_cols = train_data[['Age', 'SibSp', 'Parch', 'Fare']]\nsns.heatmap(numerical_cols.corr())","592ed4da":"train_data['cabin_letter'] = train_data['Cabin'].apply(lambda x: str(x)[0])\nprint(train_data['cabin_letter'].value_counts())\npd.pivot_table(train_data, index='Survived', columns = 'cabin_letter', values = 'Name', aggfunc = 'count')","f00e63a8":"train_data['title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\nprint(train_data['title'].value_counts())","a90081b8":"#fill null age values with the mean\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())","f03ab6f7":"#Normalize the fare to get a Gaussian distribution (and deal with variance)\ntrain_data['norm_fare'] = np.log(train_data['Fare']+1)\ntest_data['norm_fare'] = np.log(test_data['Fare']+1)\n\ntrain_data['norm_fare'] = train_data['norm_fare'].fillna(train_data['norm_fare'].median())\ntest_data['norm_fare'] = test_data['norm_fare'].fillna(test_data['norm_fare'].median())","0cc1048e":"#drop null rows for embarked (since there aren't that many of them)\ntrain_data.dropna(subset = ['Embarked'], inplace = True)\ntest_data.dropna(subset = ['Embarked'], inplace = True)","723dc364":"test_data['letter'] = test_data['Cabin'].apply(lambda x: str(x)[0])\ntest_data['title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","e28d7de6":"#delete Name feature from data set\ntrain_data.pop(\"Name\")\ntest_data.pop(\"Name\")","3d2ded4d":"#get dummie variables from categories for train and test sets\ntrain_data['train_test'] = 1\ntest_data['train_test'] = 0\nall_data = pd.concat([train_data,test_data])\n\ndummies = pd.get_dummies(all_data[['Age', 'Sex', 'Pclass', 'Parch', 'SibSp', 'Embarked', 'norm_fare', 'cabin_letter', 'title', 'train_test']])\n\n#split back into train and test sets using train_test values\nX_train = dummies[dummies['train_test']==1].drop(['train_test'], axis = 1)\nX_test = dummies[dummies['train_test']==0].drop(['train_test'], axis = 1)\n\ny_train = all_data[all_data['train_test']==1]['Survived']","a40d0458":"#Double check that the splitting worked properly\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\n\n#is_nan = X_test.isnull()\n#row_nan = is_nan.any(axis = 1)\n#dff = X_test[row_nan]\n\n#print(dff)\n#print(X_test['norm_fare'].())","4509aafb":"#make all necessary imports\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","72908d85":"lr = LinearRegression()\ndt = DecisionTreeClassifier(random_state = 42)\nknn = KNeighborsClassifier()","e4af855d":"cv = cross_val_score(lr, X_train, y_train, cv=6)\nprint(cv.mean())","951cf852":"cv = cross_val_score(dt, X_train, y_train, cv=6)\nprint(cv.mean())","dce0d25d":"cv = cross_val_score(knn,X_train,y_train,cv=6)\nprint(cv.mean())","be0e6115":"#predict on model with best score\n\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test).astype(int)\n\n#prepare submission\nfinal = {'PassengerId': test_data['PassengerId'], 'Survived': predictions}\nsubmission = pd.DataFrame(data = final)\n\nsubmission.to_csv('submission.csv', index = False)","6c9eeb63":"Women were more likely to survive than men.","efe42159":"**Import matplotlib and seaborn**","fd14ef70":"# **4. Evaluate Models**","8751fc44":"1st class was more likely to survive. \n3rd class was more likely to die.","c8bdc3b2":"People with no parents or children present were more likely to die.","51dc7e6c":"Correlations between numerical features in the dataset. ","abf6ee57":"**Decision Tree:**","8c0ea4d6":"# **2. Exploratory Data Analysis**","91b1f44a":"# **5. Select Best Model**","2308d8aa":"On our training data, the **KNN** classifier has the best score so we will chose that as our final model.","54209697":"# **1. Load the Data**","16cdd83c":"# **3. Build Models**","fadb2b3f":"# **Feature Engineering**\n\n1. Look at cabin location (based on letter)\n2. Look at people's titles\n","63e76902":"**Linear Regression:**","f2d667cc":"There is clearly data missing in several rows for Age and Cabin.","3f8bc7d5":"**Data Preprocessing**\n\n- Get rid of null data where possible\n- Get rid of irrelevant features\n- Use get dummies on categorical variables\n- Fill null data for age (too much to drop)\n- Do same transforms to test data as to train data","bdda476b":"**K Neighbors:**","eb507e05":"People with no siblings or spouses present were more likely to die.","6d6ab0e7":"Try Linear Regression, K Nearest Neighbors and Decision Tree","497a2ee7":"Look at the relationships between survival and some of the features in the dataset."}}