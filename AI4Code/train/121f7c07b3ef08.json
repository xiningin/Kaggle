{"cell_type":{"e25bb110":"code","896352bc":"code","f9db17b0":"code","6546dd18":"code","70dca5e0":"code","18619f8d":"code","80c598f6":"code","707833d4":"code","d0611a0f":"code","a9adcba2":"code","3eafaaad":"code","4c3ebd68":"code","b4e82849":"code","16c98466":"code","99597425":"markdown","e52d9263":"markdown","a9f2df4f":"markdown","b1e99005":"markdown","22ae0520":"markdown","ce03fa60":"markdown","a1ddc572":"markdown","e4ac93ff":"markdown"},"source":{"e25bb110":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport os\nimport glob\nimport shutil\n\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport tensorflow as tf\n\n# Import packages for data handling\nimport h5py\nfrom PIL import Image\nfrom skimage.io import imread\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# Import deep learning package (tensorflow)\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import mobilenet_v2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Concatenate\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical\n\ncolor = sns.color_palette()\n%matplotlib inline\n\n# Set seed nunmber to all packages\nseed_number = 24\nnp.random.seed(seed_number)\ntf.random.set_seed(seed_number)\n","896352bc":"# Configuring directories\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nroot = \"..\/input\/lcc-fasd\"\ninput_dir = os.path.join(root,\"LCC_FASD\")\ntrain_dir = os.path.join(input_dir, 'LCC_FASD_training')\nval_dir = os.path.join(input_dir, 'LCC_FASD_development')\ntest_dir = os.path.join(input_dir, 'LCC_FASD_evaluation')\n\ndataset_dir = [dir for dir in sorted(os.listdir(input_dir)) if os.path.isdir(os.path.join(input_dir, dir))]\nlabel_name = [subdir for subdir in sorted(os.listdir(train_dir)) if os.path.isdir(os.path.join(train_dir, subdir))]\n\n# Printing the directory informations\nprint(f\"Main directories\\t: {os.listdir(root)}\")\nprint(f\"Dataset sub-directories\\t: {dataset_dir}\")\nprint(f\"Train set directory\\t: {label_name}\")","f9db17b0":"dir_dict = {'train': train_dir, 'val': val_dir, 'test': test_dir}\ncase_count, img_disp, set_length  = {}, {}, {}\n\nfor key, val in dir_dict.items():\n    case_count[key] = {}\n    img_disp[key] = {}\n    set_count = 0\n    \n    for label in label_name:\n        label_list = list(sorted(glob.glob(os.path.join(val, label, \"*.png\"))))\n        if len(label_list) == 0:\n          continue\n\n        case_count[key][label] = len(label_list)\n        set_count += len(label_list)\n        \n        select_img_id = np.random.randint(len(label_list)-1)\n        # print(select_img_id)\n        img_disp[key][label] = label_list[select_img_id]\n        \n    set_length[key] = set_count\n\ncase_count_df = pd.DataFrame(case_count)\nimg_disp_df = pd.DataFrame(img_disp)\nprint(f\"Dataset summary:\\n\\n{case_count_df}\")","6546dd18":"# Visualizing some of the data set\nnum_classes = len(label_name)\nnum_dataset = 0\nfor key, val in set_length.items():\n  num_dataset += 1 if val > 0 else 0\n\nf, ax = plt.subplots(num_classes, num_dataset, figsize=(num_dataset*10, 18))\n\nfor k in range(num_classes*num_dataset):\n    j, i = k\/\/num_dataset, k%num_dataset  # Image indexing\n    \n    img = imread(img_disp_df.iloc[j, i])\n    ax[j, i].imshow(img, cmap='gray')\n    ax[j, i].set_title(f\"{img_disp_df.columns[i].upper()}: {img_disp_df.index[j].capitalize()}\", fontsize=32)\n    ax[j, i].axis('off')\n    ax[j, i].set_aspect('auto')\nplt.show()","70dca5e0":"# Instantiate data generator for training procedure\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range = 20,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.15,\n                                   zoom_range = 0.15,\n                                   horizontal_flip = True,\n                                   fill_mode=\"nearest\")\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255) if set_length[\"test\"] > 0 else None","18619f8d":"# Define dataset properties\ntrain_batch_size = 32\nval_batch_size = 32\nimg_width = 224\nimg_height = 224\n\n# Generate dataset for train, val and test\ntrain_gen = train_datagen.flow_from_directory(train_dir,\n                                              batch_size = train_batch_size,\n                                              class_mode = 'binary',\n                                              target_size = (img_width, img_height),\n                                              seed = seed_number)\n\nval_gen = val_datagen.flow_from_directory(val_dir,\n                                          batch_size = val_batch_size,\n                                          class_mode = 'binary',\n                                          target_size = (img_width, img_height),\n                                          seed = seed_number)\n\nif test_datagen is not None:\n  test_gen = test_datagen.flow_from_directory(test_dir,\n                                              batch_size = 1,\n                                              class_mode = 'binary',\n                                              target_size = (img_width, img_height),\n                                              seed = seed_number,\n                                              shuffle=False)\nelse:\n  test_gen = None","80c598f6":"# Displaying the dataset generator information\nprint(f'Train set batch shape\\t: {next(train_gen)[0].shape}')\nprint(f'Val set batch shape\\t: {next(val_gen)[0].shape}')\nprint(f'Test set batch shape\\t: {next(test_gen)[0].shape}') if test_gen is not None else None","707833d4":"# Don't forget to turn on the Internet to download the respective pre-trained weights!\npretrain_net = mobilenet_v2.MobileNetV2(input_shape = (img_width, img_height, 3),\n                                        include_top = False,\n                                        weights = 'imagenet')\n\n# load_param_path = '..\/input\/mobilenet_v2\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'  # Offline alternative\n# pretrain_net.load_weights(load_param_path)  # Manually load the weights from the input directory\n\n# ------ Freezing layer(s) up to a specific layer ------\nfreeze_before = None  #\"block_16_expand\"  # use None to train, use \"all\" to freeze all the layers\n\nif freeze_before:\n    for layer in pretrain_net.layers:\n        if layer.name == freeze_before:\n            break\n        else:\n            layer.trainable = False\n","d0611a0f":"# Adding extra layer for our problem\nx = pretrain_net.output\nx = Conv2D(32, (3, 3), activation='relu')(x)\nx = Dropout(rate=0.2, name='extra_dropout1')(x)\nx = GlobalAveragePooling2D()(x)\n# x = Dense(units=128, activation='relu', name='extra_fc1')(x)\n# x = Dropout(rate=0.2, name='extra_dropout1')(x)\nx = Dense(1, activation='sigmoid', name='classifier')(x)\n\nmodel = Model(inputs=pretrain_net.input, outputs=x, name='mobilenetv2_spoof')\nprint(model.summary())\n\n# Notice: Unhide the OUTPUT!","a9adcba2":"train_id = \"lcc-train04b-weight_all\"  # ID of the training procedure\nnum_epochs = 15  # Set the number of epochs to train\nlearning_rate = 5e-5  # Set the learning rate to use\n\nprint(f\"Training config of '{train_id}'...\")\nprint(f\"Number of epoch\\t: {num_epochs}\")\nprint(f\"Initial LR\\t: {learning_rate}\")\n\nmodel.compile(optimizer = Adam(lr=learning_rate),\n              loss = 'binary_crossentropy',\n              metrics = ['acc'])\n\n# Define model callback\nsave_dir = os.path.join(\".\/\", train_id)\nif not os.path.isdir(save_dir):\n  os.makedirs(save_dir)\n\ncont_filepath = \"mobilenetv2-epoch_{epoch:02d}.hdf5\"\ncont_checkpoint = ModelCheckpoint(os.path.join(save_dir, cont_filepath))\n\nbest_filepath = \"mobilenetv2-best.hdf5\"\nbest_checkpoint = ModelCheckpoint(os.path.join(save_dir, best_filepath),\n                                  save_best_only=True,\n                                  save_weights_only=True)\n\n# Instantiate tensorboard\nlog_dir = os.path.join(save_dir, \"logs\")\nuse_tensorboard = TensorBoard(log_dir=log_dir,\n                              histogram_freq=1,\n                              update_freq=\"batch\")\n\n# Instantiate learning rate scheduler with Plateau method\nplateau_scheduler = ReduceLROnPlateau(factor=0.2, patience=3, verbose=1, \n                                      min_delta= 0.005, min_lr=5e-7)\n\n# Displaying tensorboard\n#%tensorboard --logdir log_dir\n\n# Define class weight\ntrain_length = len(train_gen.classes)\nweight0 = train_length \/ case_count_df['train'][label_name[0]] * (1 \/ len(label_name))\nweight1 = train_length \/ case_count_df['train'][label_name[1]] * (1 \/ len(label_name))\nclass_weight = {0: weight0, 1: weight1}\n\nprint(f\"Class weight\\t: {class_weight}\")\n","3eafaaad":"# Resume training (UNCOMMENT to use!)\n# checkpoint_path = \"mobilenetv2-epoch_01\"\n# model.load(os.path.join(savedir, checkpoint_path))\n\n# Perform training\nhistory = model.fit(train_gen,\n                    epochs = num_epochs,\n                    steps_per_epoch = set_length['train'] \/\/ train_batch_size,\n                    validation_data = val_gen,\n                    validation_steps = 1,\n                    callbacks = [best_checkpoint,\n                                 cont_checkpoint,\n                                 plateau_scheduler],\n                    class_weight=class_weight)\n\nhistory_df = pd.DataFrame.from_dict(history.history)\nhistory_df.to_csv(os.path.join(save_dir, \"history.csv\"), index=False)\n\n# Notice: Unhide the OUTPUT!","4c3ebd68":"# Plotting the train results\ntrain_accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(train_accuracy))\nplt.figure(figsize=(12,4))\n\n# Plotting the accuracy\nplt.subplot(1,2,1)\nplt.plot(epochs, train_accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'val'], loc='lower right')\n\n# Plotting the loss\nplt.subplot(1,2,2)\nplt.plot(epochs, train_loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['train', 'val'], loc='upper right')\n\nplt.show()","b4e82849":"# Test set accuracy and loss\ntest_scores = model.evaluate(test_gen, steps=set_length['test'])\nprint(\"Test results Accuracy: {0:.2f}% and Loss: {0:.2f}\".format(test_scores[1]*100, test_scores[0]))\n\n# Calculate prediction\nthreshold = 0.5  # Define the sigmoid threshold for True or False\ny_pred_value = np.squeeze(model.predict(test_gen, steps=set_length['test'], verbose=1))\n\ny_pred = np.zeros(y_pred_value.shape).astype(np.int32)  # Sigmoid\ny_pred[y_pred_value > threshold] = 1\n\n# y_pred = np.argmax(y_pred_value, axis=-1).astype(np.int32)  # Softmax\n\ny_true = test_gen.classes\n\n# Sanity check on the y_pred and y_true value\nprint(f\"Label\\t\\t: {y_true[:10]}\")\nprint(f\"Prediction\\t: {y_pred[:10]}\")","16c98466":"# Confusion matrix result\nconfusion_matrix_result = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(confusion_matrix_result,\n                      figsize=(12,8),\n                      hide_ticks=True,\n                      cmap=plt.cm.jet)\nplt.title(\"Face Spoofing Detection\")\nplt.xticks(range(2), ['Real', 'Spoof'], fontsize=16)\nplt.yticks(range(2), ['Real', 'Spoof'], fontsize=16)\nplt.show()\n\n# Precision and Recall metrics\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprecision = tp \/ (tp+fp)\nrecall = tp \/ (tp+fn)\nf1_score = 2 * precision * recall \/ (precision+recall)\n\nprint(\"Report Summary:\")\nprint(\"Precision\\t: {:.2f}%\".format(precision*100))\nprint(\"Recall\\t\\t: {:.2f}%\".format(recall*100))\nprint(\"F1 Score\\t: {:.2f}%\".format(f1_score*100))\n\nprint(\"\\nNotes: \")\nprint(\"True labels\\t: Spoof\")\nprint(\"False labels\\t: Real\")\n","99597425":"# Dataset Problem\nInstantiate dataset object for training procedure (e.g., train, val, and test)","e52d9263":"# Face Anti-Spoofing Detection\nTransfer learning of a MobileNetV2 is used as the classifier, in order to provide fast inference time with respectable precision","a9f2df4f":"Start training!","b1e99005":"# Perform Training\nDefine the training procedure","22ae0520":"# Generate Model\nUsing a pre-trained MobileNet-v2 model, provided by tensorflow","ce03fa60":"# Observing the Dataset\nGrasping some of the dataset information","a1ddc572":"Configuring directories","e4ac93ff":"# Results evaluation\nUse this section to evaluate the model performance on the Test set."}}