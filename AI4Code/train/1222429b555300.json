{"cell_type":{"0cd18310":"code","558a8133":"code","ddc40be5":"code","c10fab52":"code","2a4a2f1b":"code","fa4e1a70":"code","49827e54":"code","eab6c788":"code","c3814a19":"code","03f355ab":"code","6503f0e2":"code","cba189d5":"code","aca9b82b":"code","e8a295ea":"code","e4a89aac":"code","bbfa132b":"code","5f7bfe63":"code","770bed5e":"code","6d2570ec":"code","344b09e4":"code","e386f039":"code","dfe4c048":"code","dc545cff":"code","9727191f":"code","f12a11ed":"code","918824e6":"code","c08a9fca":"code","d415486b":"code","989a0613":"code","84283f91":"code","f2765857":"code","f7b691da":"code","44aa94b5":"code","4babad96":"code","a9187084":"code","42a39cd7":"code","ddb5ef15":"code","bb7093ff":"code","61a2bcfd":"code","a7620e3b":"code","4712ac61":"code","76a396e6":"code","0de6407b":"code","6c40cad2":"code","2e15d584":"markdown","679e3316":"markdown","8708cdc0":"markdown","48661f02":"markdown","bcb82551":"markdown","dde794ac":"markdown","5c457306":"markdown","77678878":"markdown","3c44c73c":"markdown","470b1c6a":"markdown","096dbb1e":"markdown","a593ff41":"markdown","98cf61f1":"markdown","0d209f60":"markdown","bb1e1f62":"markdown","a2fd4c13":"markdown","e5c660c6":"markdown","fd65b3c9":"markdown","36ddbdc7":"markdown","8f54bb55":"markdown","33f12c2f":"markdown","3716d742":"markdown","f4938bcf":"markdown","397eaa33":"markdown","0ca8d574":"markdown","c4950ce1":"markdown","f2cc5653":"markdown","6f71d714":"markdown","d3545789":"markdown","f0ea2317":"markdown","5919883c":"markdown","fff641b7":"markdown","66ebbcab":"markdown","4ed1a112":"markdown"},"source":{"0cd18310":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom surprise import Dataset \nfrom surprise import Reader\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\nfrom surprise.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score,classification_report","558a8133":"df = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/ratings_small.csv\")\ndf.head()","ddc40be5":"df.isna().sum()","c10fab52":"dup_bool = df.duplicated(['userId','movieId','rating'])\nprint(\"Number of duplicate records:\",sum(dup_bool))","2a4a2f1b":"print(\"Total no of ratings :\",df.shape[0])\nprint(\"No. of unique users:\", df[\"userId\"].nunique())\nprint(\"No. of unique movies:\", df[\"movieId\"].nunique())","fa4e1a70":"fig, ax = plt.subplots(figsize=(12,8))\nax.set_title('Ratings distribution', fontsize=15)\nsns.countplot(df['rating'])\nax.set_xlabel(\"ratings in interval\")\nax.set_ylabel(\"Total number of ratings\")","49827e54":"ratings_per_user = df.groupby(by='userId')['rating'].count()#.sort_values(ascending=False)\nratings_per_user.describe()","eab6c788":"ratings_per_movie = df.groupby(by='movieId')['rating'].count()\nratings_per_movie.describe()","c3814a19":"reader = Reader()\nratings = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)","03f355ab":"train_ratings, test_ratings = train_test_split(ratings, test_size=.20, random_state = 42)\nprint(\"Size of trainset: \", train_ratings.n_ratings)\nprint(\"Size of testset: \", len(test_ratings))","6503f0e2":"from surprise import BaselineOnly","cba189d5":"baseline_model = BaselineOnly(verbose = False)\nbaseline_model.fit(train_ratings)","aca9b82b":"train_predictions = baseline_model.test(train_ratings.build_testset())\ntest_predictions = baseline_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions,verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions,verbose = False))","e8a295ea":"movies = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv\")\nmovies.head()","e4a89aac":"def get_top_n_recommendations(userId,predictions, n=5):\n    predict_ratings = {}\n    # loop for getting predictions for the user\n    for uid, iid, true_r, est, _ in predictions:\n        if (uid==userId):\n            predict_ratings[iid] = est\n    predict_ratings = sorted(predict_ratings.items(), key=lambda kv: kv[1],reverse=True)[:n]\n    top_movies = [i[0] for i in predict_ratings]\n    top_movies = [str(i) for i in top_movies]\n    print(\"=\"*10,\"Recommended movies for user {} :\".format(userId),\"=\"*10)\n    print(movies[movies[\"id\"].isin(top_movies)][\"original_title\"].to_string(index=False))\nget_top_n_recommendations(450,test_predictions)","bbfa132b":"from surprise import KNNBasic\nknn_model = KNNBasic(random_state = 42,verbose = False)\nknn_model.fit(train_ratings)","5f7bfe63":"train_predictions = knn_model.test(train_ratings.build_testset())\ntest_predictions = knn_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","770bed5e":"param_grid = {'k': list(range(10,45,5)),\n             'min_k' : list(range(5,11))}\ngs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], return_train_measures = True, cv = 5)\ngs.fit(ratings)\ngs.best_params['rmse']","6d2570ec":"tuned_knn_model = KNNBasic(k = 15, min_k= 5,random_state = 42, verbose = False)\ntuned_knn_model.fit(train_ratings)\ntrain_predictions = tuned_knn_model.test(train_ratings.build_testset())\ntest_predictions = tuned_knn_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","344b09e4":"knn_model_item_based = KNNBasic(user_based = False, random_state = 42)\nknn_model_item_based.fit(train_ratings)","e386f039":"train_predictions = knn_model_item_based.test(train_ratings.build_testset())\ntest_predictions = knn_model_item_based.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","dfe4c048":"from surprise import SVD","dc545cff":"svd_model = SVD(random_state = 42)\nsvd_model.fit(train_ratings)","9727191f":"train_predictions = svd_model.test(train_ratings.build_testset())\ntest_predictions = svd_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","f12a11ed":"param_distributions  = {'n_factors': list(range(50,160,10)),'reg_all': np.arange(0.02,0.2,0.02),'n_epochs' : list(range(1,51))}\nrs = RandomizedSearchCV(SVD, param_distributions, measures=['rmse'], return_train_measures = True, cv = 5, n_iter = 20)\nrs.fit(ratings)\nrs.best_params['rmse']","918824e6":"tuned_svd_model = SVD(n_factors=130, reg_all =0.1, n_epochs = 50, random_state = 42,verbose = False)\ntuned_svd_model.fit(train_ratings)\ntrain_predictions = tuned_svd_model.test(train_ratings.build_testset())\ntest_predictions = tuned_svd_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","c08a9fca":"from surprise import NMF","d415486b":"nmf_model = NMF(random_state = 42)\nnmf_model.fit(train_ratings)","989a0613":"train_predictions = nmf_model.test(train_ratings.build_testset())\ntest_predictions = nmf_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","84283f91":"param_distributions  = {'n_factors': list(range(10,20,2)),'reg_pu': np.arange(0.02,0.2,0.02),'reg_qi': np.arange(0.02,0.2,0.02), 'n_epochs' : list(range(1,51))}\nrs = RandomizedSearchCV(NMF, param_distributions, measures=['rmse'], return_train_measures = True, cv = 5, n_iter = 20)\nrs.fit(ratings)\nrs.best_params['rmse']","f2765857":"#tuned_nmf_model = NMF(n_factors=18, reg_pu = 0.06, reg_qi = 0.16, n_epochs = 38, random_state = 42)\ntuned_nmf_model = NMF(n_factors=18, reg_pu = 0.13999999999999999, reg_qi = 0.12000000000000001, n_epochs = 34, random_state = 42)\ntuned_nmf_model.fit(train_ratings)\ntrain_predictions = tuned_nmf_model.test(train_ratings.build_testset())\ntest_predictions = tuned_nmf_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions, verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions, verbose = False))","f7b691da":"userIds = []\nmovieIds = []\nratings = []\nfor (uid, iid, rating) in train_ratings.all_ratings():\n    userIds.append(train_ratings.to_raw_uid(uid))\n    movieIds.append(train_ratings.to_raw_iid(iid))\n    ratings.append(rating)\ndict = {'userId': userIds, 'movieId': movieIds, 'rating': ratings}\ntraining_df = pd.DataFrame(dict)","44aa94b5":"user_averages = training_df.groupby(\"userId\")[\"rating\"].mean()\nuser_averages","4babad96":"train_actual_labels = []\ntrain_predicted_labels = []\nfor uid, iid, r_ui, est, _ in train_predictions:\n    if((r_ui - user_averages[uid])>0):\n        train_actual_labels.append(\"Yes\")\n    else:\n        train_actual_labels.append(\"No\")\n    if((est - user_averages[uid])>0):\n        train_predicted_labels.append(\"Yes\")\n    else:\n        train_predicted_labels.append(\"No\")","a9187084":"print(\"Training data distribution of liked movies derived from actual ratings\")\nprint(pd.Series(train_actual_labels).value_counts())\nprint(\"\\nTraining data distribution of liked movies derived from predicted ratings\")\nprint(pd.Series(train_predicted_labels).value_counts())","42a39cd7":"test_actual_labels = []\ntest_predicted_labels = []\nfor uid, iid, r_ui, est, _ in test_predictions:\n    if((r_ui - user_averages[uid])>0):\n        test_actual_labels.append(\"Yes\")\n    else:\n        test_actual_labels.append(\"No\")\n    if((est - user_averages[uid])>0):\n        test_predicted_labels.append(\"Yes\")\n    else:\n        test_predicted_labels.append(\"No\")","ddb5ef15":"print(\"Test data distribution of liked movies derived from predicted ratings\")\nprint(pd.Series(test_actual_labels).value_counts())\nprint(\"\\nTest data distribution of liked movies derived from predicted ratings\")\nprint(pd.Series(test_predicted_labels).value_counts())","bb7093ff":"print(\"Confusion matrix on test data\")\nconfusion_matrix(test_actual_labels,test_predicted_labels)","61a2bcfd":"print(\"Training data precision : \", precision_score(train_actual_labels,train_predicted_labels,pos_label=\"Yes\"))\nprint(\"Test data precision : \", precision_score(test_actual_labels,test_predicted_labels,pos_label=\"Yes\"))","a7620e3b":"print(\"Training data recall : \", recall_score(train_actual_labels,train_predicted_labels,pos_label=\"Yes\"))\nprint(\"Test data recall : \", recall_score(test_actual_labels,test_predicted_labels,pos_label=\"Yes\"))","4712ac61":"print(\"=\"*20, \"Classification Report\", \"=\"*20)\nprint(classification_report(test_actual_labels,test_predicted_labels))","76a396e6":"print(tuned_nmf_model.predict(672, 1721)) # unknown user id but known movie id\nprint(tuned_nmf_model.predict(43, 2277))  # known user id but unknown movie id\nprint(tuned_nmf_model.predict(671, 2277)) # unknown user id and unknown movie id","0de6407b":"biased_nmf_model = NMF(biased = True,random_state = 42)\nbiased_nmf_model.fit(train_ratings)\ntrain_predictions = biased_nmf_model.test(train_ratings.build_testset())\ntest_predictions = biased_nmf_model.test(test_ratings)\nprint(\"RMSE on training data : \", accuracy.rmse(train_predictions,verbose = False))\nprint(\"RMSE on test data: \", accuracy.rmse(test_predictions,verbose = False))","6c40cad2":"print(biased_nmf_model.predict(672, 1721)) # unknown user id but known movie id\nprint(biased_nmf_model.predict(43, 2277))  # known user id but unknown movie id\nprint(biased_nmf_model.predict(671, 2277)) # unknown user id and unknown movie id","2e15d584":"### 4. Basic data exploration\n\n#### 4.1 Total number of users, movies and ratings","679e3316":"#### 6.1.c Recommending Top 'n' movies","8708cdc0":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python\/","48661f02":"#### 6.3.1.b Evaluating the results","bcb82551":"#### 6.2.1.b Evaluating the results","dde794ac":"#### 6.2.1.c Hyper-parameter tuning to find optimal value of k and min_k","5c457306":"So here, Biased NMF can be used to get more sensible results. Biased version of NMF considers\n* User bias(user's own rating average) when a new item is added to the platform\n* Item bias(item's own rating average) when a new user joins the platform\n\n#### 8.1 Biased NMF","77678878":"## 6. ML models for recommendation from Surprise library\n\n### 6.1 Baseline method\n\n#### 6.1.a Fitting Baseline model","3c44c73c":"### 6.2.2 Item-item similarity based\n\n#### 6.2.2.a Fitting model","470b1c6a":"#### 6.1.b Evaluating the results","096dbb1e":"* Minimum number of ratings to a movie = **1** \n* Maximum number of ratings to a movie = **341**\n* average ratings per movie = **11** ","a593ff41":"* Minimum number of ratings given by a user = **20**\n* Maximum number of ratings given by a user = **2391**\n* average ratings per user = **149**","98cf61f1":"#### 3.2 Checking for duplicate records","0d209f60":"#### 6.3.2.b Evaluating the results","bb1e1f62":"### 3. Data preprocessing\n\n#### 3.1 Checking for missing values column wise","a2fd4c13":"#### Splitting into train and test set","e5c660c6":"#### 4.3 Ratings per user","fd65b3c9":"## 6.3 Matrix Factorization based methods\n\n### 6.3.1 SVD\n\n#### 6.3.1.a Fitting model","36ddbdc7":"### 8. Handling Cold Start problem\n\nCold start problem is a special case in recommendation whenever\n* A new user joins the platform\/service\n* A new item is added to the platform\/service\n* Both(a new user joins and a new item is added)\n\nIn such scenarios, the Surprise library algorithms by default return the overall global average.","8f54bb55":"### 5. Loading as Surprise dataframe and train-test split","33f12c2f":"#### 4.2 Distribution of ratings","3716d742":"### 2. Loading data","f4938bcf":"#### 6.3.2.a Fitting model","397eaa33":"### 7. Additional performance measures for Recommendation\n\n#### 7.1 Precision and Recall\n\nApart from error based measures(like RMSE), we can also evaluate classification based performance measures(like accuracy, precision, recall) by imposing the recommendation problem as a binary classification problem.\n\nA simple assumption can be stated as follows in order to convert this to a binary classification problem.\n* If the rating provided by a user to a particular movie is above its own average rating then probably s(he) likes that particular movie\n* Otherwise, he does not like that particular movie","0ca8d574":"### 6.2 Using KNNBasic\n\n### 6.2.1 User-user similarity based\n\n#### 6.2.1.a Fitting model ","c4950ce1":"#### 4.4 Ratings per movie","f2cc5653":"### Notebook - Table of Content\n\n1. [**Importing necessary libraries**](#1.-Importing-necessary-libraries)   \n2. [**Loading data**](#2.-Loading-data) \n3. [**Data preprocessing**](#3.-Data-preprocessing)  \n    3.1 [**Checking for missing values column wise**](#3.1-Checking-for-missing-values-column-wise)           \n    3.2 [**Checking for duplicates records**](#3.2-Checking-for-duplicate-records)     \n4. [**Basic data exploration**](#4.-Basic-data-exploration)  \n    4.1 [**Total number of users, movies and ratings**](#4.1-Total-number-of-users,-movies-and-ratings)  \n    4.2 [**Distribution of ratings**](#4.2-Distribution-of-ratings)  \n    4.3 [**Ratings per user**](#4.3-Ratings-per-user)      \n    4.4 [**Ratings per movie**](#4.4-Ratings-per-movie)  \n5. [**Loading as Surprise dataframe and train-test split**](#5.-Loading-as-Surprise-dataframe-and-train-test-split)  \n6. [**ML models for recommendation from Surprise library**](#6.-ML-models-for-recommendation-from-Surprise-library)  \n    6.1 [**Baseline method**](#6.1-Baseline-method)  \n    6.2 [**Using KNNBasic**](#6.2-Using-KNNBasic)  \n    6.2.1 [**User-user-similarity-based**](#6.2.1-User-user-similarity-based)  \n    6.2.2 [**Item-item similarity based**](#6.2.2-Item-item-similarity-based)  \n    6.3 [**Matrix Factorization based methods**](#6.3-Matrix-Factorization-based-methods)  \n    6.3.1 [**SVD**](#6.3.1-SVD)       \n    6.3.2 [**NMF**](#6.3.2-NMF)    \n7. [**Additional performance measures for Recommendation**](#7.-Additional-performance-measures-for-Recommendation)      \n    7.1 [**Precision and Recall**](#7.1-Precision-and-Recall)    \n8. [**Handling Cold Start problem**](#8.-Handling-Cold-Start-problem)     \n    8.1 [**Biased NMF**](#8.1-Biased-NMF)    ","6f71d714":"#### 7.1 Imposing as a binary classification problem","d3545789":"### 1. Importing necessary libraries","f0ea2317":"#### 6.3.1.c Hyper-parameter tuning to find optimal value of n_factors, reg_all and n_epochs","5919883c":"#### 7.2 Evaluating Precision and Recall","fff641b7":"#### 6.3.2.c Hyper-parameter tuning to find optimal value of n_factors, reg_pu, reg_qi and n_epochs","66ebbcab":"#### 6.2.2.b Evaluating the results","4ed1a112":"### 6.3.2 NMF"}}