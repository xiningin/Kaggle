{"cell_type":{"44552c6a":"code","d7619b73":"code","a63f3f44":"code","77c92eab":"code","2cb011ff":"code","1d5bc103":"code","3041d1c5":"code","7896bb15":"code","e82e061a":"code","6db4f465":"code","43db63bd":"code","27d0c4b6":"code","16896b81":"code","7ed23774":"code","284bf432":"code","3708cc59":"code","67504091":"code","cbe78bde":"code","a6e705b0":"code","cbcb35db":"code","a670a8c4":"code","eded60a1":"code","b4e6d431":"code","ba7b2ec4":"code","8163032e":"code","15da7b45":"code","bac1e4b6":"code","cb9f0fdd":"code","2a1fca7d":"code","86758661":"code","fe158b8e":"code","2c8171d0":"code","05105591":"markdown"},"source":{"44552c6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7619b73":"#load image\ndata='\/kaggle\/input\/animal-image-datasetdog-cat-and-panda\/animals\/'","a63f3f44":"import os\nfrom os import listdir","77c92eab":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","2cb011ff":"x=[]\ny=[]\n\nk=\"\/kaggle\/input\/animal-image-datasetdog-cat-and-panda\/animals\/animals\/\"\nfor file1 in listdir(k):\n    file2=k+\"\/\"+file1\n    for file3 in listdir(file2):\n        file4=file2+\"\/\"+file3\n        image = load_img(file4,target_size=(108,108,3))\n        img_array = img_to_array(image)\n        x.append(img_array)\n        y.append(file1)","1d5bc103":"len(x),len(y)","3041d1c5":"import numpy as np","7896bb15":"x=np.array(x)\ny=np.array(y)","e82e061a":"x.shape,y.shape","6db4f465":"from sklearn.preprocessing import LabelEncoder\nk = LabelEncoder()\ny= k.fit_transform(y)","43db63bd":"from keras.utils import to_categorical\ny=to_categorical(y)","27d0c4b6":"x=x\/255","16896b81":"y.shape","7ed23774":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1\/3, random_state = 0)","284bf432":"from keras.applications.vgg16 import VGG16","3708cc59":"model=VGG16(input_shape=(108,108,3),include_top=False)","67504091":"from keras import Model\nfrom keras.optimizers import SGD\nfrom keras.layers import Flatten, Dense","cbe78bde":"def Animal_Image():\n    model=VGG16(input_shape=(108,108,3),include_top=False)\n    for layer in model.layers:\n        layer.trainable = False\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n    class2 = Dense(62, activation=\"relu\", kernel_initializer=\"he_uniform\")(class1)\n    output = Dense(3, activation=\"softmax\")(class1)\n    model1 = Model(inputs=model.inputs, outputs=output)\n    opt = SGD(lr=0.01, momentum=0.9)\n    model1.compile(optimizer=opt,loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model1","a6e705b0":"obj=Animal_Image()","cbcb35db":"objective=obj.fit(x_train,y_train,batch_size=32, validation_data=(x_test,y_test),epochs=12,verbose=1)","a670a8c4":"_, acc =obj.evaluate(x_test,y_test, verbose=0)","eded60a1":"acc","b4e6d431":"pip install lime","ba7b2ec4":"ids = []\n\nfor i in range(0, len(x_test)):\n    if obj.predict(x_test[i].reshape(1,108,108,3)).argmax(axis=1)[0] != y_test[i].argmax(axis=-1):\n        ids.append(i)\n\nprint(len(ids))","8163032e":"import lime\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nimport matplotlib.pyplot as plt\n\nexplainer = lime_image.LimeImageExplainer()","15da7b45":"plt.rcParams[\"figure.figsize\"] = (8,6)","bac1e4b6":"idx = ids[0]\n\nexplanation = explainer.explain_instance(x_test[idx].astype('double'), obj.predict, hide_color=0)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0],\n                                            positive_only=False, negative_only=False, num_features=-1, hide_rest=False)\ntemp2, mask2 = explanation.get_image_and_mask(explanation.top_labels[0],\n                                            positive_only=False, negative_only=True, num_features=-1, hide_rest=True)\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3)\nax1.imshow(x_test[idx])\nax2.imshow(mark_boundaries(temp, mask))\nax3.imshow(mark_boundaries(temp2, mask2))","cb9f0fdd":"fig, (ax1, ax2) = plt.subplots(1, 2)\nplt.subplots_adjust(wspace=0.4)\n\n# original heatmap\n\ndict_heatmap = dict(explanation.local_exp[explanation.top_labels[0]])\nheatmap = np.vectorize(dict_heatmap.get)(explanation.segments)\nim1 = ax1.imshow(heatmap, cmap = 'RdYlGn', vmin  = -heatmap.max(), vmax = heatmap.max())\nplt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n\n# inverted heatmap\n\ndict_heatmap = dict(explanation.local_exp[explanation.top_labels[0]])\nheatmap = np.vectorize(dict_heatmap.get)(explanation.segments)\nheatmap = heatmap*-1\nim2 = ax2.imshow(heatmap, cmap = 'RdYlGn', vmin  = -heatmap.max(), vmax = heatmap.max())\nplt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)","2a1fca7d":"idx = ids[500]\n\nexplanation = explainer.explain_instance(x_test[idx].astype('double'), obj.predict, hide_color=0)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=-1, hide_rest=True)\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nax2.imshow(x_test[idx])","86758661":"idx = ids[300]\n\nexplanation = explainer.explain_instance(x_test[idx].astype('double'), obj.predict, hide_color=0)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=-1, hide_rest=True)\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nax2.imshow(x_test[idx])","fe158b8e":"idx = ids[200]\n\nexplanation = explainer.explain_instance(x_test[idx].astype('double'), obj.predict, hide_color=0)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=-1, hide_rest=False)\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nax2.imshow(x_test[idx])","2c8171d0":"idx = ids[800]\n\nexplanation = explainer.explain_instance(x_test[idx].astype('double'), obj.predict, hide_color=0)\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=-1, hide_rest=True)\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nax2.imshow(x_test[idx])","05105591":"Applying VGG16 convolutional neural network"}}