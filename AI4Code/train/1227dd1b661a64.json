{"cell_type":{"daa34542":"code","dbe5f54c":"code","05c69a59":"code","ce9e76a2":"code","0fb0a822":"code","1aa12db5":"code","bf951370":"code","30af9cb6":"code","9da1f23f":"code","21bb85c3":"code","83a2f6ee":"code","9e3f8c70":"code","ab189aa0":"code","f86a440f":"code","75f689d9":"code","a52ae76b":"code","4267c9ca":"code","34f17d08":"code","a13a90d6":"code","c47fd759":"code","3ffd06b6":"code","25bdc9ae":"code","711b6d01":"code","c53ad4a8":"code","04862995":"code","911a027a":"code","e142dd54":"code","56a43e36":"code","97210659":"code","86136fbb":"code","58a294ed":"code","9404120e":"code","d3998632":"code","5ed4488d":"code","95139d1a":"code","dbb80697":"markdown","6e557807":"markdown","b51ea66c":"markdown","7e413088":"markdown","d5461f23":"markdown","6304bccd":"markdown","3d9efc2e":"markdown","f1406f73":"markdown","339ec062":"markdown","35a8940b":"markdown","66f7f3cf":"markdown","129f6ccf":"markdown","9e1a2a73":"markdown"},"source":{"daa34542":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\n%matplotlib inline","dbe5f54c":"# input shape of image\nhight = 151\nwidth = 332\nimg_shape = (hight, width)\ninput_img_shape = img_shape + (3,)","05c69a59":"def show_n_imgs_per_label(n_num_of_img, label, X, y):\n  fig = plt.figure(figsize=(20,20))\n  label_index = np.array(np.where(y == label)).squeeze()\n  for index in range(n_num_of_img):\n      i = label_index[index]\n      ax = fig.add_subplot(1, n_num_of_img, index+1, xticks=[], yticks=[])\n      ax.imshow(X[i].reshape(input_img_shape))\n      ax.set_title(str(y[i]))","ce9e76a2":"from skimage.color import gray2rgb\ndef get_train_and_labels(dataset):\n    y = dataset[\"Type\"]\n    X = dataset.drop(['Type'],axis=1)\n    X = X.values.reshape((-1,)+ img_shape + (1,))\n    X = X\/255.0\n    X_rgb = np.empty(shape=((len(X),)+input_img_shape))\n    for idx, img in enumerate(X):\n      X_rgb[idx] = gray2rgb(img[:,:,0])\n    return X_rgb,y","0fb0a822":"dataset_path = \"..\/input\/eye-disorder-dataset\/eye_dataset.csv\"\ndataset = pd.read_csv(dataset_path)\n","1aa12db5":"X,y = get_train_and_labels(dataset)","bf951370":"print(\"Shape of X : \",X.shape)\nprint(\"Shape of y : \",y.shape)\nprint(\"Shape of Image : \", X[0].shape)","30af9cb6":"show_n_imgs_per_label(5,\"cat\", X, y)\nshow_n_imgs_per_label(5,\"crossed\", X, y)\nshow_n_imgs_per_label(5,\"bulk\", X, y)","9da1f23f":"np.unique(y, return_counts=True)","21bb85c3":"label_classes = np.unique(y, return_counts=True)[0]","83a2f6ee":"sns.countplot(x=y)","9e3f8c70":"from sklearn.model_selection import train_test_split\ndef get_train_test_data(X, y, test_size=0.1, random_state =42):\n  x_train,x_test,y_train,y_test = train_test_split(X, \n                                                   y,\n                                                   test_size=test_size,\n                                                   random_state=random_state,\n                                                   stratify=y)\n\n\n  return x_train, x_test, y_train, y_test","ab189aa0":"from keras.preprocessing.image import ImageDataGenerator\n# build generator first without augmentation fro testing and train\ntrain_datagen = ImageDataGenerator(validation_split=0.1)\n                                   #horizontal_flip=True,\n                                   #$vertical_flip=True)\ntest_datagen = ImageDataGenerator()\n","f86a440f":"y_true = pd.get_dummies(y).values","75f689d9":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import  GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","a52ae76b":"# Build model on top of MobileNetV2 model\n\nvgg16_model = VGG16(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=input_img_shape,\n    include_top=False)  # Do not include the ImageNet classifier at the top.\n","4267c9ca":"vgg16_model.summary()","34f17d08":"# Freeze the base_model\nvgg16_model.trainable = False\nvgg16_model.layers[-2].trainable = True","a13a90d6":"# Create new model on top.\ninputs = keras.Input(shape=input_img_shape, name=\"img_input\")","c47fd759":"# Create new model on top.\nlayer = vgg16_model(inputs)\nlayer = keras.layers.GlobalAveragePooling2D()(layer)\nlayer = Dense(128)(layer)\nlayer = Dropout(0.5)(layer)\nlayer = BatchNormalization()(layer)\nlayer = Activation('relu')(layer)\noutputs = Dense(3, activation='softmax')(layer)","3ffd06b6":"model = keras.Model(inputs, outputs)","25bdc9ae":"model.summary()\n","711b6d01":"# config the metrics for the model\nmetrics = ['accuracy',\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]","c53ad4a8":"def get_callbacks():\n\n  early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                            mode='auto', restore_best_weights=True)\n\n  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                                verbose=1, mode='auto')\n  # define checkpoints\n\n  checkpoint_path = working_dir + \"\/training\/checkpoints\/cp.ckpt\"\n  checkpoint_dir = os.path.dirname(checkpoint_path)\n\n  # Create a callback that saves the model's weights\n  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                  save_weights_only=True,\n                                                  verbose=1)\n  return [reduce_lr, early_stop, cp_callback]","04862995":"# Train Model on new data\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), \n                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n                        metrics=metrics)\n\n","911a027a":"x_train, x_test, y_train, y_test = get_train_test_data(X, y_true, test_size = 0.1)","e142dd54":"x_train.shape","56a43e36":"history = model.fit(train_datagen.flow(x_train, y_train, batch_size=32,\n         subset='training'),\n         validation_data=train_datagen.flow(X, y_true,\n         batch_size=10, subset='validation'), epochs=100)","97210659":"import matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (12, 10)\ndef plot_metrics(history):\n  metrics = ['loss', 'prc', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch, history.history[metric], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()","86136fbb":"def evaluate_model(model, history):\n  plot_metrics(history)\n  ","58a294ed":"evaluate_model(model, history)","9404120e":"predictions = model.predict(x_test)","d3998632":"from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix","5ed4488d":"from sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(true_labels, predictions, classes):\n  lb = LabelBinarizer()\n  lb.fit(classes)\n  predictions_class = lb.inverse_transform(predictions)\n  y_true_labels = lb.inverse_transform(true_labels)\n  cm = confusion_matrix(y_true_labels, predictions_class, labels=lb.classes_)\n  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.classes_)\n  disp.plot()\n  cls_report = classification_report(y_true_labels, predictions_class, output_dict=True)\n  display(pd.DataFrame(cls_report))","95139d1a":"plot_confusion_matrix(y_test, predictions, label_classes)","dbb80697":"## Transfer Learning - Defining the base model VGG16","6e557807":"# Explore Data","b51ea66c":"# Building Model\n\n","7e413088":"# Prepare Data for the model\n1. split the data into training and test\n2. create an [`ImageDataGenerator`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator#flow) for image augmentation (that is not necessary here)\n3. However, ImageGeneration is also usfull for getting batches images and shuffeling the data as well as deviding the dataset into train and validation.","d5461f23":"## Evaluating Model","6304bccd":"## Training Model","3d9efc2e":"## Get Files","f1406f73":"## Building on top of VGG","339ec062":"# Abstract\n* The purpose of the notebook is to build an image classifier for eye-disorder. \n* The dataset contain 100 images and based on it we will try to build a classifier.\n* Because of the small amount of images we will make use of model transfer (VGG16) and image augmentation","35a8940b":"# Get Files and Load dataset\n","66f7f3cf":"## Load Dataset and Utils\nBelow several functions utils to load the data.\n1. `show_n_img_per_label` - for exploring the images in the dataset\n2. `get_train_and_label` - load label and img and convert images from gray scale to rgb. Thsi is needed for streaming all the images to VGG16 model that I will use for transfer learning. in order to convert the images I will use[gray2rgb](https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.color.html#skimage.color.gray2rgb). This utility just duplicates the gray image 3 times into the 3 rgb channels","129f6ccf":"\n\n> The performance look relatively good... We can see some spikes in the validation, let us chack the test\n\n","9e1a2a73":"## Defining metrics, callbacks and complie model"}}