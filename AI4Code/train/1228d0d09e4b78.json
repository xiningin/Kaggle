{"cell_type":{"d530b493":"code","31f2095c":"code","e0104c27":"code","90af867a":"code","a810b637":"code","52b2c87b":"code","042abacb":"code","1a78ec29":"code","68e4d954":"code","24840d96":"code","44c6e63f":"code","bef25cf1":"code","8958b192":"code","302c6a22":"code","24a3fc29":"code","19065ba1":"code","a9099bda":"code","3f394d0d":"code","e0dc7386":"code","496d0ea0":"code","aa859286":"code","3efa2c15":"code","bb5a5dd4":"code","1bc348af":"code","f0e856d7":"code","246e81f7":"code","668923a1":"markdown","989c1640":"markdown","c0afd9bc":"markdown","903612e8":"markdown","1862c223":"markdown","056d60c4":"markdown","f2a80533":"markdown","3d5cc0b6":"markdown","b43feb78":"markdown","31c6a5b2":"markdown","7ac4238c":"markdown","11f787a6":"markdown","dbb1f6cd":"markdown","b9b20e47":"markdown","e5128fd4":"markdown"},"source":{"d530b493":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","31f2095c":"dataPath = '..\/input\/m5-forecasting-accuracy\/'\ntimesteps = 14\nstartDay = 350\n","e0104c27":"dt = pd.read_csv(dataPath + \"\/sales_train_validation.csv\")\ndt.head(3)\n","90af867a":"print(dt.info())","a810b637":"def reduction_mem(df):\n    float_cols = [c for c in df if df[c].dtype == 'float64']\n    int_cols = [c for c in df if df[c].dtype in ['int64', 'int32']]\n    df[float_cols] = df[ float_cols].astype(np.float16)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n    ","52b2c87b":"#Reduce memory usage and compare with the previous one to be sure\ndt = reduction_mem(dt)","042abacb":"print(dt.info())","1a78ec29":"#Take the transpose so that we have one day for each row, and 30490 items' sales as columns\ndt = dt.T\ndt.head(8)","68e4d954":"#Remove id, item_id, dept_id, cat_id, store_id, state_id columns\ndt = dt[6 + startDay:]\ndt.head(5)","24840d96":"cal_data = pd.read_csv(dataPath + 'calendar.csv')","44c6e63f":"#Create dataframe with zeros for 1969 days in the calendar\ndaysBeforeEvent = pd.DataFrame(np.zeros((1969,1)))\n","bef25cf1":"# \"1\" is assigned to the days before the event_name_1. Since \"event_name_2\" is rare, it was not added.\nfor x,y in cal_data.iterrows():\n    if((pd.isnull(cal_data[\"event_name_1\"][x])) == False):\n           daysBeforeEvent[0][x-1] = 1 \n            #if first day was an event this row will cause an exception because \"x-1\".\n            #Since it is not i did not consider for now.\n\n   ","8958b192":"#\"calendar\" won't be used anymore. \ndel cal_data\n","302c6a22":"#\"daysBeforeEventTest\" will be used as input for predicting (We will forecast the days 1913-1941)\ndaysBeforeEventTest = daysBeforeEvent[1913:1941]\n#\"daysBeforeEvent\" will be used for training as a feature.\ndaysBeforeEvent = daysBeforeEvent[startDay:1913]\n\n","24a3fc29":"#Before concatanation with our main data \"dt\", indexes are made same and column name is changed to \"oneDayBeforeEvent\"\ndaysBeforeEvent.columns = [\"oneDayBeforeEvent\"]\ndaysBeforeEvent.index = dt.index\n\n","19065ba1":"dt = pd.concat([dt, daysBeforeEvent], axis = 1)\n\ndt.columns","a9099bda":"#Feature Scaling\n#Scale the features using min-max scaler in range 0-1\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ndt_scaled = sc.fit_transform(dt)","3f394d0d":"X_train = []\ny_train = []\nfor i in range(timesteps, 1913 - startDay):\n    X_train.append(dt_scaled[i-timesteps:i])\n    y_train.append(dt_scaled[i][0:30490]) \n    #\u0130mportant!! if extra features are added (like oneDayBeforeEvent) \n    #use only sales values for predictions (we only predict sales) \n    #this is why 0:30490 columns are choosen","e0dc7386":"del dt_scaled\n","496d0ea0":"#Convert to np array to be able to feed the  BiLSTM model\nX_train = np.array(X_train, dtype = 'float16')\ny_train = np.array(y_train, dtype = 'float32')\nprint(X_train.shape)\nprint(y_train.shape)","aa859286":"#for the GPU\nimport tensorflow as tf\nmodel = tf.keras.models.Sequential([\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True), input_shape= (np.array(X_train).shape[1], np.array(X_train).shape[2])),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n        tf.keras.layers.Dense(30490),\n    ])\nmodel.summary()\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","3efa2c15":"lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',factor=0.5, patience=3,\n                                                    verbose=1,\n                                                    min_lr=0.000001,\n                                                   )","bb5a5dd4":"#model training for GPU\nmodel.fit(X_train, y_train, epochs = 50, batch_size = 10,callbacks=[lr_scheduler])","1bc348af":"inputs= dt[-timesteps:]\ninputs = sc.transform(inputs)","f0e856d7":"X_test = []\nX_test.append(inputs[0:timesteps])\nX_test = np.array(X_test)\npredictions = []\n\nfor j in range(timesteps,timesteps + 28):\n#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n    predicted_stock_price = model.predict(X_test[0,j - timesteps:j].reshape(1, timesteps, 30491))\n    testInput = np.column_stack((np.array(predicted_stock_price), daysBeforeEventTest[0][1913 + j - timesteps]))\n    X_test = np.append(X_test, testInput).reshape(1,j + 1,30491)\n    predicted_stock_price = sc.inverse_transform(testInput)[:,0:30490]\n    predictions.append(predicted_stock_price)","246e81f7":"import time\n\nsubmission = pd.DataFrame(data=np.array(predictions).reshape(28,30490))\n\nsubmission = submission.T\n    \nsubmission = pd.concat((submission, submission), ignore_index=True)\n\nsample_submission = pd.read_csv(dataPath + \"\/sample_submission.csv\")\n    \nidColumn = sample_submission[[\"id\"]]\n    \nsubmission[[\"id\"]] = idColumn  \n\ncols = list(submission.columns)\ncols = cols[-1:] + cols[:-1]\nsubmission = submission[cols]\n\ncolsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n\nsubmission.columns = colsdeneme\n\ncurrentDateTime = time.strftime(\"%d%m%Y_%H%M%S\")\n\nsubmission.to_csv(\"submission.csv\", index=False)","668923a1":"# Bidirectional LSTM Model with tf.Keras","989c1640":"# Submission File Creation\n* Here, the submission file creation is done.","c0afd9bc":"* Below timesteps is set to 14 to use past 14 days' sales.\n* Since there are lots of zero values in first days, \"startDay\" parameter can be used ignore unwanted days from the beginning.","903612e8":"* Since, the \"daysBeforeEvent\" feature is used for predicting after the model trained as input, we seperate the 28 days as \"daysBeforeEventTest\"\n* For training the first 1914 days (if \"startDay\" is zero otherwise \"1913-startDay\") will be used.","1862c223":"# *please upvote*","056d60c4":"![resim.png](attachment:resim.png)","f2a80533":"* Here a dataframe is created to store the knowledge if an event exist in the next day\n* Firstly, fill with zeros the dataframe","3d5cc0b6":"* The shape of the data is not exactly what we want.\n* We want to have each day as row and 30490 items' sales as columns (features)\n* Therefore take the transpose of \"dt\"","b43feb78":"* Remove the first six  colums id, item_id, dept_id, cat_id, store_id, state_id columns, to end up only days as rows","31c6a5b2":"* Concatenate \"daysBeforeEvent\" feature with our main dataframe \"dt\"","7ac4238c":"* Take last days, 14 for this notebook (\"timestep\" parameter) in order to predict firts unknown day's sales.\n* Before using values for prediction, again use min-max transformation","11f787a6":"* Here is the important part. \"X_train\" and \"y_train\" data is created. For each X_train item, 14 past days' sales and 14 daysBeforeEvent feature are included. So one element of X_train's shape is (14, 30491). For y_train we are predicting one day sales of 30490 items therefore one element of y_train's shape is (1, 30490)","dbb1f6cd":"Creation of X_train and y_train\n![resim.png](attachment:resim.png)","b9b20e47":"* Here is again an important part. \n* We are using last 14 days in order to predict day 1915 sales.\n* In order to predict 1916th day, 13 days from our input data and 1 day from our prediction are used. After that we slide the window one by one.\n    * 12 days from input data + 2 days from our prediction to predict 1917th day\n    * 11 days from input data + 3 days from our prediction to predict 1918th day\n    * .....\n    * 14 days our prediction to predict last 1941th day sales.","e5128fd4":"* Now, \"1\" is assigned the day before an event exist. Other days will remain as \"0\"."}}