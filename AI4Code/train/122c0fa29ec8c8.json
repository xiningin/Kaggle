{"cell_type":{"2b48f801":"code","d3a07297":"code","a1b6a3d2":"code","3b2f6228":"code","ef442324":"code","d106ad30":"code","cf35e556":"code","b199fadb":"code","8d1497cb":"code","985a84a3":"code","4b6d5915":"code","f859aa3b":"code","68917d2a":"code","e191dcff":"code","f2e3a89f":"code","3b69e1aa":"code","2be51964":"code","1575446a":"code","8258e77a":"code","ce27ec6d":"code","6f917a7d":"markdown","564ffc44":"markdown"},"source":{"2b48f801":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3a07297":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport datetime\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n%matplotlib inline","a1b6a3d2":"dataset=pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","3b2f6228":"dataset","ef442324":"sex = dataset['sex'].unique()\nd1 = dataset[dataset['sex']==sex[0]][['age','DEATH_EVENT']].rename(columns={'DEATH_EVENT':'Died'}).groupby('age').sum().reset_index()\nd2 = dataset[dataset['sex']==sex[1]][['age','DEATH_EVENT']].rename(columns={'DEATH_EVENT':'Dont died'}).groupby('age').sum().reset_index()\nd1.merge(d2,on='age').set_index('age').style.background_gradient('Blues')","d106ad30":"plt.figure(figsize=(16,9))\nsns.displot(data=dataset[dataset['DEATH_EVENT']==1],y='age',element=\"step\",multiple=\"stack\",kde=True)\nplt.show()","cf35e556":"sns.displot(data=dataset,x='age',hue='DEATH_EVENT',element=\"step\",multiple=\"stack\",kde=True)","b199fadb":"sns.violinplot(x='DEATH_EVENT', y='age', data=dataset)","8d1497cb":"plt.figure(figsize=(12,9))\ng=sns.displot(data=dataset[dataset['DEATH_EVENT']==1], x=\"age\", col='sex',hue='smoking', multiple=\"stack\",element=\"step\",kde=True)","985a84a3":"sns.violinplot(x='DEATH_EVENT', y='age', data=dataset)","4b6d5915":"corr_data = dataset.corr()\n\nmask = np.zeros_like(corr_data)\n\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize=(20,12))\n\nsns.heatmap(corr_data.abs(),cmap='YlOrBr', annot=True, fmt='.2f',square=True,mask=mask, vmax=.3,linewidths=.5)\nplt.show()","f859aa3b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nx_treino,x_teste,y_treino,y_teste=train_test_split(dataset.drop('DEATH_EVENT',axis=1),dataset['DEATH_EVENT'],test_size=0.2,random_state=106)","68917d2a":"print('The training dataset has {} patients, the test has {} patients.'.format(x_treino.shape[0], x_teste.shape[0]))","e191dcff":"modelo_log=LogisticRegression(max_iter=1500,solver='liblinear')\nmodelo_log.fit(x_treino,y_treino)\npredicao_log=modelo_log.predict(x_teste)","f2e3a89f":"print(classification_report(y_teste,predicao_log))\nprint(\"\\n\")","3b69e1aa":"acc_logReg = round(modelo_log.score(x_treino,y_treino) * 100, 2)\nprint(\"Accuracy of the Logistic Regression model: {}\".format(acc_logReg))","2be51964":"scaler=StandardScaler()\nx_treino=scaler.fit_transform(x_treino)\nx_teste=scaler.transform(x_teste)","1575446a":"from sklearn.ensemble import RandomForestClassifier\nmodelo_randon = RandomForestClassifier(n_estimators=100)\nmodelo_randon.fit(x_treino,y_treino)\npredicao_randon=modelo_randon.predict(x_teste)\n","8258e77a":"print(classification_report(y_teste,predicao_randon))\nprint(\"\\n\")","ce27ec6d":"from sklearn.model_selection import cross_val_score\nSEED = 50\nnp.random.seed(SEED)\ncv = StratifiedKFold(n_splits = 5, shuffle = True)\nresults_tree = cross_val_score(modelo_randon, x_treino, y_treino, cv=cv, scoring = 'accuracy')\nresults_log = cross_val_score(modelo_log, x_treino, y_treino, cv=cv, scoring = 'accuracy')\ndef intervalo(results):\n    mean = results.mean()\n    dv = results.std()\n    print('Average accuracy: {:.2f}%'.format(mean*100))\n    print('Accuracy range: [{:.2f}% ~ {:.2f}%]'\n           .format((mean - 2*dv)*100, (mean + 2*dv)*100))\n    \nprint(\"RandomForestClassifier\")\nintervalo(results_tree)\nprint(\"\\n\")\nprint(\"LogisticRegression\")\nintervalo(results_log)","6f917a7d":"How we can see, you can't say that smooking (by the dataset) has a lot of correlacion with heart failure.","564ffc44":"Here, we can see that most people who died had the ages between 60 and 70 years old"}}