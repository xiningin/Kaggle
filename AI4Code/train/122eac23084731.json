{"cell_type":{"74371f74":"code","420d7b95":"code","9dfc9295":"code","d6b6ff45":"code","ab462d0c":"code","5c335cf7":"code","0f43ce93":"code","9ec50618":"code","4d6fc6bb":"code","a4b39790":"code","5087d3a6":"code","ac7bacb3":"code","a02cbf8a":"code","a049fd95":"code","2bbdd77d":"code","92792909":"code","51725f3f":"code","195afbe3":"code","192c9e74":"code","179ce5af":"code","4ad27f94":"code","6d6bccfe":"code","8accc98f":"code","5f99951c":"code","d0b6713b":"code","aebaeb35":"code","864b3814":"code","e5d2aa90":"code","22393be3":"code","dbd13aef":"code","094ef87c":"code","c31553e6":"code","f8b58f10":"code","74ada7ef":"code","57dc26ce":"code","f6f07be7":"code","a3b55793":"code","bd66af5a":"code","65dc5396":"code","c886d2aa":"code","7bf1d8f0":"code","ccd0e62e":"code","14659032":"code","ac440031":"code","08ef779b":"code","a141b667":"code","d40e2e42":"code","fd164db8":"code","f4869d99":"code","945c7040":"code","f0778af4":"markdown","2648ffe7":"markdown","3eb33b85":"markdown","f96c22de":"markdown","c1c2f6f1":"markdown","b0620c43":"markdown","c9cf46be":"markdown","62c72713":"markdown","a4874214":"markdown","418353ae":"markdown","23359c38":"markdown","5767cbf5":"markdown"},"source":{"74371f74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","420d7b95":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","9dfc9295":"#Loading Titanic Data file","d6b6ff45":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","ab462d0c":"train.head()","5c335cf7":"data = train.append(test, ignore_index = True, sort = True)","0f43ce93":"data.shape","9ec50618":"data.info()","4d6fc6bb":"data.isnull().sum()","a4b39790":"data[\"Age\"]= data[\"Age\"].fillna(data[\"Age\"].mean())\ndata[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].mean())\ndata[\"Embarked\"] = data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\nPassengerId = data.loc[891:,'PassengerId']","5087d3a6":"data[\"Cabin\"] = data[\"Cabin\"].fillna(\"U\")\ndata[\"Cabin\"] = data[\"Cabin\"].apply(lambda x: x[0])\ndata[\"Cabin\"] = data[\"Cabin\"].apply(lambda x: 1 if x[0] == \"U\" else 0)","ac7bacb3":"data[\"Ticket\"] =data[\"Ticket\"].apply(lambda x: x[0])","a02cbf8a":"data[\"Family\"] = data[\"Parch\"].apply(lambda x: 1 if x>0 else 0)\ndata[\"Family with siblings\/spouse\"] = data[\"SibSp\"].apply(lambda x: 1 if x >0 else 0 )\nticketMap = data['Ticket'].value_counts().to_dict()\ndata['TicketCount'] = data['Ticket'].map(ticketMap)","a049fd95":"data_num = [\"Age\", \"Fare\"]\ndrop = [\"Name\",\"Parch\",\"SibSp\",\"Ticket\",\"TicketCount\"]","2bbdd77d":"data = data.drop(drop, axis = 1)","92792909":"data_cat = [\"Embarked\", \"PassengerId\",\n            'Cabin',\"Pclass\",\"Sex\",\"Family\",\"Family with siblings\/spouse\",\"Survived\"]\ndata.head()","51725f3f":"num_data = data[data_num]\ncat_data = data[data_cat]","195afbe3":"num_data.skew()","192c9e74":"fare = num_data[\"Fare\"]\nfare = np.log(fare)","179ce5af":"num_data.skew()","4ad27f94":"num_data.hist(figsize = (4,4) )","6d6bccfe":"import seaborn as sns\nsns.pairplot(data, hue = \"Survived\", diag_kind = \"auto\", kind = \"scatter\", palette = \"Accent\")","8accc98f":"sns.distplot(data['Age'])","5f99951c":"sns.distplot(num_data[\"Fare\"])","d0b6713b":"sns.barplot(\"Pclass\",\"Survived\", data = data, palette = \"Greens\")","aebaeb35":"sns.barplot(\"Embarked\",\"Survived\", data = data, palette  = \"Purples\")","864b3814":"sns.barplot(\"Family\", \"Embarked\",hue =\"Survived\", data = data, palette = \"pastel\")","e5d2aa90":"sns.barplot(\"Age\", \"Sex\", hue = \"Survived\", data = data, palette = \"PuBu\")","22393be3":"sns.catplot(y =\"Embarked\", hue = \"Survived\", kind = \"count\", palette = \"pastel\", data = data)","dbd13aef":"sns.catplot(y=\"Embarked\", hue=\"Pclass\", kind=\"count\",palette=\"pastel\", edgecolor=\".6\",data=data);","094ef87c":"sns.catplot(x=\"Age\", y=\"Embarked\",hue=\"Survived\", data= data, orient=\"h\", height=2, aspect=3,\n            palette=\"Set3\",\n            kind=\"violin\")","c31553e6":"sns.catplot(y=\"Pclass\", hue=\"Survived\", kind=\"count\",palette=\"Greens\", edgecolor=\".6\",data=data)","f8b58f10":"cat_data.columns","74ada7ef":"cat_data.head()","57dc26ce":"data_embarked = pd.get_dummies(cat_data[\"Embarked\"], drop_first = True, prefix = \"Embarked\")\ndata_pclass = pd.get_dummies(cat_data[\"Pclass\"], drop_first = True, prefix = \"pclass\")\ndata_sex = pd.get_dummies(cat_data[\"Sex\"], drop_first = True, prefix = \"sex\")","f6f07be7":"cat_data = pd.concat([cat_data, data_embarked, data_pclass, data_sex], axis =1)","a3b55793":"drop_columns = [\"Embarked\",\"Pclass\",\"Sex\"]\ncat_data = cat_data.drop(drop_columns, axis = 1)","bd66af5a":"new_data = pd.concat([num_data,cat_data], axis = 1)\nnew_data.head()","65dc5396":"\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\ntree_one = model.fit(x_features_one, y_target)","c886d2aa":"y = new_data[\"Survived\"]\nx = new_data.drop(\"Survived\", axis = 1)","7bf1d8f0":"#x = x.apply(lambda x: (x - np.mean(x)) \/ (np.max(x) - np.min(x))) \nx.isnull().any()","ccd0e62e":"x.isnull().any()\ny.head()","14659032":"x_train = x.iloc[0:891, :-1]\ny_train = x.iloc[0:891, -1]\nx_test = x.iloc[891: , :-1]","ac440031":"lr = LogisticRegression()\nlr.fit(x_train, y_train.values.ravel())","08ef779b":"rfc = RandomForestClassifier()\nrfc.fit(x_train,y_train)","a141b667":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\ntree_one = model.fit(x_train, y_train)","d40e2e42":"predictions = tree_one.predict(x_test)","fd164db8":"#predictions = rfc.predict(x_test)","f4869d99":"submission.to_csv(\"Submission.csv\", index=False)","945c7040":"# Submission\nsubmission = pd.DataFrame({\n        \"PassengerId\": PassengerId,\n        \"Survived\": predictions.astype(int)\n    })","f0778af4":"Building Logistic Regression Model","2648ffe7":"Building Random Forest Model","3eb33b85":"Machine learning is basically categorized into three parts:\na)\tSupervised Learning (When we deal with labeled data)\nb)\tUnsupervised Learning (When we deal with unlabeled data)\nc)\tReinforcement Learning (When system take decisions based on past experiences)\nNow, to train or to interact with machine we need some kind of tool. So, the commonly used tools are:\n1.\tPython\n2.\tR \n3.\tSAS\n4.\tJava\n5.\tMATLAB","f96c22de":"Exploratory Data Analysis","c1c2f6f1":"Machine learning is a subset of Artificial intelligence that provides system to learn and improves of its own without being explicitly programmed.\nIt basically consists of different algorithms through which we train the machine and once the training is done machine predicts the results for us.\n","b0620c43":"Importing packages ","c9cf46be":"Data Preparation","62c72713":" Introduction to Machine learning with Python","a4874214":"In this kernel, we\u2019ll discuss about Python. Python is an open source high level object oriented programming language. Few most important features of python is listed below:\na)\tPython is quick to read and easy to learn.\nb) It is dynamically typed\nc)\tIt is interpreted so no need to compile the program","418353ae":"Prediction and submission","23359c38":"Let's start our programming. I'm dividing this program into small parts, so that  it would be easy to understand. So the parts of our program are listed below:\n\n1. Import packages\n2. Load data\n3. Data preparation\n4. Exploratory Data Analysis\n5. Spliting dataset into train and test data.\n6. Building Logistic Regression Model\n7. Building Random Forest Model \n8.Prediction and submission","5767cbf5":"Splitting Dataset for model building."}}