{"cell_type":{"2607a3c3":"code","5bbc6dc2":"code","14ec60de":"code","8f12388b":"code","71ccd849":"code","c84f24ae":"code","d546e9d0":"code","fb3ba089":"code","ce7e7705":"code","cff50caa":"code","262d4e38":"code","284186d1":"code","724a902d":"code","b3bb56de":"code","638616f9":"code","1f8428d8":"code","4fc09d0e":"markdown","2cf99c6f":"markdown","fdf2e106":"markdown","16865f41":"markdown","6ac10573":"markdown","9630cc40":"markdown","f85eb5dd":"markdown","5574c90f":"markdown","50bb6e80":"markdown","7d2e7e07":"markdown","3ebdde09":"markdown","d51b6986":"markdown","848e41c0":"markdown","6db099e5":"markdown","91235b58":"markdown"},"source":{"2607a3c3":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')","5bbc6dc2":"df = pd.read_csv('..\/input\/iris\/Iris.csv')\ndf.head()","14ec60de":"df.info()","8f12388b":"df.describe()","71ccd849":"df['Species'].value_counts()","c84f24ae":"df.isnull().sum()","d546e9d0":"X = df.iloc[:, 1:5].values\ny = df.iloc[:, 5].values","fb3ba089":"lbe = LabelEncoder()\ny = lbe.fit_transform(y)","ce7e7705":"def model():\n    rn = Sequential()\n    # initial layer\n    rn.add(Dense(units = 4, activation = 'relu', input_dim = 4))\n    # hidden layer\n    rn.add(Dense(units = 4, activation = 'relu'))\n    # Output layer (softmax used for 3 or more outputs)\n    rn.add(Dense(units = 3, activation = 'softmax'))\n    # Compile\n    rn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n    return rn","cff50caa":"classifier = KerasClassifier(build_fn = model, epochs = 250, batch_size = 10)","262d4e38":"results = cross_val_score(estimator = classifier, X = X, y = y, cv = 5, scoring = 'accuracy')\nmean = results.mean()\nsd = results.std()","284186d1":"# Probability of each test\nprint(f'Results: {results}\\nMean: {mean}\\nStandard Deviation: {sd}')","724a902d":"def updateModel(neurons):\n    classifier = Sequential()\n    # Camada de entrada\n    classifier.add(Dense(units = neurons, activation = 'relu', \n                        kernel_initializer = 'random_uniform', input_dim = 4))\n    classifier.add(Dropout(0.3))\n    # Camada oculta\n    classifier.add(Dense(units = neurons, activation = 'relu', \n                        kernel_initializer = 'random_uniform'))\n    classifier.add(Dropout(0.3))\n    # Camada de saida (softmax utilizada para 3 ou mais sa\u00eddas)\n    classifierclassifier.add(Dense(units = 3, activation = 'softmax'))\n    # Otimizador\n    classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n                      metrics = ['accuracy'])\n    return classifier","b3bb56de":"classifier = KerasClassifier(build_fn = updateModel)\nparameters = {'epochs': [1000, 2000],\n              'neurons': [8, 16, 24]}\nparameters","638616f9":"# The Grid makes all possible combinations in our variable 'parameters', the higher the 'cv' the more combinations are tested.\ngrid_search = GridSearchCV(estimator= classifier,\n                          param_grid= parameters,\n                          scoring = 'accuracy',\n                          cv = 3)\ngrid_search = grid_search.fit(X, y)","1f8428d8":"best_parameters = grid_search.best_params_\nprint(f'Best Parameters: {best_parameters}')","4fc09d0e":"## Detection of iris-versicolor, iris-virginica and iris-setosa using Artificial Neural Networks\n![iris.png](attachment:iris.png)\n\n#### Dataset information:\n\n- The Iris dataset was used in R.A. Fisher's classic 1936 paper, [The Use of Multiple Measurements in Taxonomic Problems](https:\/\/rcs.chemometrics.ru\/Tutorials\/classification\/Fisher.pdf), and can also be found on the [UCI Machine Learning Repository](http:\/\/archive.ics.uci.edu\/ml\/).\n\n- It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n\nThe dataset can be found on the `` Kaggle`` platform at the link below:\n\n- https:\/\/www.kaggle.com\/uciml\/iris","2cf99c6f":"###### Separating the Predictors and the Class","fdf2e106":"#### Finding Missing Data (NaN)\nOur dataset does not have missing values as it says on the UCI website, but just in case:","16865f41":"The ``describe()`` function generates a lot of information about numeric variables that can also be useful:The ``describe()`` function generates a lot of information about numeric variables that can also be useful:","6ac10573":"It can be seen that all variables are of type ``float64`` (\"decimal\" numbers) except for the target variable which is of type ``object``.\n\nwe will need to perform the transformation from \"object\" type to numeric type.","9630cc40":"We can see that all our data is balanced.","f85eb5dd":"## 1. Imports from libraries","5574c90f":"## 3. Construction of the model (Artificial neural networks)\n\nThe purpose of the Neural Networks algorithm is to imitate the nervous system of humans in the learning process, it is inspired by biological neural networks.\n\n![rairis.png](attachment:rairis.png)","50bb6e80":"## 2. Starting...","7d2e7e07":"###### Artificial neural network parameters:\nLink: https:\/\/keras.io\/\n\nParameters of the `` RNA``:\n\n     Sequential - Creation of a new neural network\n     Dense - All connected neurons\n     units - Number of neurons that are part of the hidden layer\n     activation - Activation function that will be inserted\n     input_dim - how many elements are there in the input layer\n     Dropout - is used to decrease the chance of overfitting (20% of input neurons are zeroed)\n    \n``Compile`` parameters:\n\n     optimizer - descent of the gradient and descent of the stochastic gradient\n     loss - Loss function (binary_crossentropy as there is only one exit)\n     metrics - Evaluation metrics (obs - more than one can be placed)","3ebdde09":"## 4. Tuning of parameters\n\nThe test below usually takes a long time, I performed several tests separate from each other and got the following result:\n\n    best accuracy = 96%\n\nBest parameters:\n\n    activation = relu\n    batch_size = 10\n    Dropout = 0.3\n    epochs = 1000\n    kernel_initializer = random_uniform\n    loss =  sparse_categorical_crossentropy\n    neurons = 8\n    optimizer = adam","d51b6986":"We have 5 columns present in no dataset provided, four of them being characteristic variables (input data) and one of them a target variable (which we want our model to be able to predict).\n\nThe characteristic variables are:\n\n    sepal length\n    sepal width\n    petal length\n    petal width\n  \nThe target variable is:\n\n    Species - a *softmax* type that indicates an iris class:\n        iris-versicolor\n        Iris-virginica\n        Iris-setosa ","848e41c0":"###### Network Creation Parameters\n\n     build_fn - Neural network build function\n     epochs - the number of times the weights will be adjusted\n     batch_size - error calculation every 10 records\n\n###### Cross Validation Parameters\n\n     estimator - Neural network creation function\n     X - Predictive attributes\n     y - Output class\n     cv - Number of test times (10 database divisions)\n     scoring - return of results","6db099e5":"As expected, we have no missing values :D","91235b58":"###### Categorical to Numeric Output Data Transformation"}}