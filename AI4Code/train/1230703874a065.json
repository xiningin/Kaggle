{"cell_type":{"bce372ad":"code","624ff4d8":"code","4c8e2f87":"code","072ac00c":"code","680cfabf":"code","7fa12a50":"code","07b390e2":"code","7bb7a470":"code","5a869ef0":"code","3597aa8b":"code","a331c6c2":"code","cb6e7968":"code","835ffda0":"code","eb98f3f9":"code","b2282502":"code","7c49eeb4":"code","676efc0e":"code","c6bb0c57":"code","c83eb9d3":"code","8ea34058":"markdown","1cf2dede":"markdown","fdf84359":"markdown","0414bc09":"markdown","a0e62eb2":"markdown","e1d2a5ec":"markdown","1f47391a":"markdown","6c5a9967":"markdown","ed477e85":"markdown","2b71e45c":"markdown","5d4ebf1d":"markdown","059a3df6":"markdown","0b103e9f":"markdown"},"source":{"bce372ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/exzeodata\/sample\/train\"))\n\n# Any results you write to the current directory are saved as output.","624ff4d8":"import sys\nimport os\nfrom os.path import isfile, join\nfrom os import listdir\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dropout, Flatten, Dense, Activation\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras import callbacks\nimport pandas as pd\nimport numpy as np\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.resnet50 import preprocess_input\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom keras.optimizers import Adam, SGD","4c8e2f87":"# dataset=\"..\/input\/exzeodata\/sample\"\ntrain_data_dir=\"..\/input\/exzeodata\/sample\/train\"\ntest=\"..\/input\/exzeodata\/sample\/test\"","072ac00c":"img_width, img_height = 150, 150\nnb_train_samples = 350\nnb_validation_samples = 150\nnb_filters1 = 32\nnb_filters2 = 64\nconv1_size = 3\nconv2_size = 2\npool_size = 2\nclasses_num = 2\nbatch_size = 32\nlr = 0.0001\nepochs = 5","680cfabf":"def img_to_tensor(image_path, target_size):\n    img = load_img(image_path, target_size=target_size)\n    tensor = img_to_array(img)\n    tensor = np.expand_dims(tensor, axis=0)\n    print(\"Image \"\"\" + str(image_path) +\n          \" \"\" converted to tensor with shape \" + str(tensor.shape))\n    return tensor","7fa12a50":"def getCustommodel():\n    model1 = Sequential()\n    model1.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(img_width, img_height, 3), activation='relu'))\n    model1.add(Conv2D(32, (3, 3), activation='relu'))\n    model1.add(MaxPooling2D(pool_size=(2, 2)))\n    model1.add(Dropout(0.2))\n\n    model1.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n    model1.add(Conv2D(64, (3, 3), activation='relu'))\n    model1.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model1.add(Flatten())\n    model1.add(Dense(512, activation='relu'))\n    model1.add(Dropout(0.2))\n    model1.add(Dense(2, activation='softmax'))\n\n    model1.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True), \n                  metrics=['accuracy'])\n    model1.summary()\n    \n    return model1","07b390e2":"m=getCustommodel()\nm.summary()","7bb7a470":"def getpretrainedmodel():\n    base_model = MobileNet(weights='imagenet', include_top=False)\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(1024, activation='relu')(x)  # dense layer 2\n    x = Dense(512, activation='relu')(x)  # dense layer 3\n    preds = Dense(2, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=preds)\n    for layer in model.layers[:20]:\n        layer.trainable = False\n    for layer in model.layers[20:]:\n        layer.trainable = True\n    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    return model\n\np=getpretrainedmodel()\np.summary()","5a869ef0":"def datagenerators(mode=\"pretrained\"):\n    \n    if mode==\"custom\":\n        train_datagen = ImageDataGenerator(\n            rescale=1. \/ 255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            validation_split=0.3\n            )\n    else:\n        train_datagen = ImageDataGenerator(\n            rescale=1. \/ 255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            validation_split=0.3,\n        preprocessing_function=preprocess_input)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset=\"training\")\n\n    validation_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset=\"validation\")\n\n    return train_generator, validation_generator","3597aa8b":"def getTestImages(folder):\n    a = []\n    b = []\n    for f in listdir(folder):\n        temp = (join(folder, f))\n        print(temp)\n        b.append(f)\n        a.append(img_to_tensor(temp, target_size=(img_width, img_height)))\n    return (a, b)","a331c6c2":"(a,b)=getTestImages(test)\nprint(a)\nprint(b)","cb6e7968":"def ensemble_predictor(trained_ensemble, test_folder, method=\"vote\"):\n\n    test_tensors, test_images = getTestImages(test_folder)\n    # test_images = np.array(test_images)\n    # print(test_images.shape)\n\n    p1 = []\n    p3 = []\n    output = {}\n    if method == \"average\":\n        for i in range(len(test_tensors)):\n            t1 = trained_ensemble[0].predict(test_tensors[i])\n            t2 = trained_ensemble[1].predict(test_tensors[i])\n            tt = t2\n            output[test_images[i]] = np.argmax(tt, axis=1)\n\n    # for i in range(len(p1)):\n        # if(np.argmax(p1[i], axis=1) > np.argmax(p2[i], axis=1)):\n            # output[test_images[i]] = 1\n\n    return output","835ffda0":"model1 = getCustommodel()\nmodel3 = getpretrainedmodel()\n\nensemble = []\nensemble.append(model1)\nensemble.append(model3)\n\ntrained_ensemble = []\nfor i in ensemble:\n    a, b = datagenerators()\n    i.fit_generator(\n        a,\n        samples_per_epoch=nb_train_samples,\n        epochs=7,\n        validation_data=b,\n        validation_steps=nb_validation_samples)\n\n    trained_ensemble.append(i)\n","eb98f3f9":"output = ensemble_predictor(ensemble, test, method=\"average\")\nprint(output)","b2282502":"predictions={}\nfor i,j in output.items():\n    predictions[i]=j[0]","7c49eeb4":"print(predictions)","676efc0e":"df=pd.DataFrame()\ndf['filename']=predictions.keys()\ndf['label']= predictions.values()","c6bb0c57":"print(df.head(3))","c83eb9d3":"df.T.to_csv(\"output.csv\")","8ea34058":"## The Hyperparams that we have here -","1cf2dede":"## **Our Architecture of Custom CNN:**","fdf84359":"## By Anubhav Kesari","0414bc09":"## **Defining the DataGenerators for the Models**","a0e62eb2":"# **EXZEO Hiring Challenge Solutions**","e1d2a5ec":"##  **PreTrained MobileNet Architecture as Transfer Learning**","1f47391a":"## **Creating our custom CNN Model for Classification**","6c5a9967":"## **Training the Ensemble and Predicting the test images**","ed477e85":"## **Steps Involved** \n","2b71e45c":"## **Using Average Based Ensembling of the two models we Defined above**","5d4ebf1d":"## G**etting all images in form of tensors **","059a3df6":"## Creating the CNN Model - Model1","0b103e9f":"### 1. Getting the required imports in the environment"}}