{"cell_type":{"d32c8952":"code","72401b3b":"code","dcf894a8":"code","085f8193":"code","ef5e4955":"code","d7796c37":"code","e75f22ad":"code","2f8eb2bb":"code","38a686f7":"code","6a206070":"code","26a2d2fa":"code","76ff8c9a":"code","8941fe66":"code","dc781b79":"code","32568846":"code","a62bd32a":"code","e48ddfe4":"code","3f6cdc17":"code","ec9ee380":"code","897efbc7":"code","481f48f3":"code","07c18f1d":"code","246ab877":"code","3176910f":"code","db6e2ca2":"code","b427a8ef":"code","f4165ee7":"code","cacb7885":"code","8e8dae0b":"code","0244eb01":"code","84403092":"code","85654faf":"code","3b58c89e":"code","684187ff":"code","8d13a8dd":"code","940b40d1":"code","30a489d5":"code","0ec7c8c4":"code","7923caf8":"code","4a4aec24":"code","528177a0":"code","2ad6cce7":"code","bfa99a3c":"code","0ce0786b":"code","03ded47e":"code","b73a9e45":"code","35e237fc":"code","da5699e5":"code","08dabac1":"code","52009d89":"code","9464f7be":"code","9fc40e57":"code","85931d52":"code","68a32037":"code","426caabd":"code","3163dc10":"code","de18133b":"code","d9d6e63d":"code","b173796d":"code","dd569360":"code","f9c54597":"code","73ab8c8e":"code","73fb296d":"markdown","e44253da":"markdown","f8bf52cd":"markdown","1bf83128":"markdown","016f2ce2":"markdown","62018cf6":"markdown","0358cc4a":"markdown","3a673769":"markdown","a512e2ac":"markdown","12aaf9bb":"markdown","28cacce1":"markdown","33ee1df3":"markdown","c3f99317":"markdown","b45d281a":"markdown","346e8667":"markdown","4214a553":"markdown"},"source":{"d32c8952":"import pandas as pd\nimport numpy as np","72401b3b":"df = pd.read_csv('titanic.csv')","dcf894a8":"df.head()","085f8193":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ef5e4955":"#\u00a0Dataset: https:\/\/www.kaggle.com\/heptapod\/titanic\ndf = pd.read_csv('titanic.csv')","d7796c37":"df.head()","e75f22ad":"sns.boxplot(df['Age'])","2f8eb2bb":"def outlier_thresholds(dataframe, column_name, q1=0.25, q3=0.75):\n    \"\"\"\n    It returns the upper and lower values for outlier detections\n    \"\"\"\n    q1 = dataframe[column_name].quantile(0.25)\n    q3 = dataframe[column_name].quantile(0.75)\n    iqr = q3 - q1\n    low_limit = q1 - 1.5 * iqr\n    up_limit = q3 + 1.5 * iqr\n    return low_limit, up_limit\n","38a686f7":"outlier_thresholds(df,'Age')","6a206070":"def check_outlier(dataframe, column_name):\n    \"\"\"\n    Is there any outliers in the variable?\n    \"\"\"\n    low, up = outlier_thresholds(dataframe, column_name)\n    if dataframe[(dataframe[column_name] < low) | (dataframe[column_name] > up)].any(axis=None):\n        return True\n    else:\n        return False\n","26a2d2fa":"print(\"Yes there are outliers\" if check_outlier(df,'Age') else \"No there aren't outliers\")","76ff8c9a":"def grab_outliers(dataframe, col_name, index=False):\n    \"\"\"\n    It returns the outliers. If the index param is True, it returns the outliers' indices.\n    \"\"\"\n    low, up = outlier_thresholds(dataframe, col_name)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index","8941fe66":"grab_outliers(df,'Age')","dc781b79":"def remove_outlier(dataframe, col_name):\n    \"\"\"\n    It removes the outliers from the dataset.\n    \"\"\"\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers","32568846":"df.shape","a62bd32a":"wo_df = remove_outlier(df,'Age')","e48ddfe4":"wo_df.shape","3f6cdc17":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","ec9ee380":"replace_with_thresholds(df,'Age')","897efbc7":"check_outlier(df,'Age')","481f48f3":"from sklearn.neighbors import LocalOutlierFactor\n\ndf = sns.load_dataset('diamonds')\ndf = df.select_dtypes(['float64','int64'])\ndf = df.dropna()\n\nclf = LocalOutlierFactor(n_neighbors=20) # neighbors observation counts 20\nclf.fit_predict(df) # apply LOF by using the df\ndf_scores = clf.negative_outlier_factor_ # negatif outlier factor values. While This score going to up, the \"lof\" being more normal\n# inlier values more near the 1, outlier values more far the 1\ndf_scores[0:5]\n\nnp.sort(df_scores)[0:5] # the worst (outlier) 5 observation\n\nscores = pd.DataFrame(np.sort(df_scores))\n# elbow method; the point where the slope cuts steepness is captured.\nscores.plot(stacked=True,xlim=[0,20], style='.-')\nplt.show()\n\nth = np.sort(df_scores)[3] # for the threshold value for this example, we can look at the plot\n\ndf[df_scores < th] # Observations with a lof score lower than the threshold\n\ndf.describe().T\n","07c18f1d":"import numpy as np\nimport pandas as pd","246ab877":"df = pd.read_csv('titanic.csv')","3176910f":"df.head()","db6e2ca2":"# is there any missing value\ndf.isnull().values.any()\n\n# missing values count per variables\ndf.isnull().sum()\ndf.isnull().sum().sort_values(ascending=False)\n\n# non-missing values count per variables\ndf.notnull().sum()\n\n# the total count of missing values in the dataframe\ndf.isnull().sum().sum()\n\n# the observations which has at least 1 missing value\ndf[df.isnull().any(axis=1)]\n\n# the observations which hasn't any missing value\ndf[df.notnull().all(axis=1)]\n\n# inspecting for ratio based\n(df.isnull().sum() \/ df.shape[0] * 100).sort_values(ascending=False)","b427a8ef":"df.dropna()","f4165ee7":"df.fillna(0).head()","cacb7885":"df['Age'].fillna(df['Age'].mean())","8e8dae0b":"df = pd.read_csv('titanic.csv').drop('PassengerId',axis=1)","0244eb01":"df.isna().sum()","84403092":"dff = pd.get_dummies(df,drop_first=True)\ndff.head()","85654faf":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndff = pd.DataFrame(scaler.fit_transform(dff), columns=dff.columns)\ndff.head()","3b58c89e":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndff = pd.DataFrame(imputer.fit_transform(dff), columns=dff.columns)\ndff.head()\n\ndff = pd.DataFrame(scaler.inverse_transform(dff), columns=dff.columns)\n\ndf[\"age_imputed_knn\"] = dff[[\"Age\"]]\n\ndf.loc[df[\"Age\"].isnull()]","684187ff":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","8d13a8dd":"df = sns.load_dataset('tips')","940b40d1":"df.head()","30a489d5":"pd.get_dummies(df)","0ec7c8c4":"var = df[['day']]","7923caf8":"pd.get_dummies(var)","4a4aec24":"pd.get_dummies(var,drop_first=True)","528177a0":"def rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n","2ad6cce7":"def rare_encoder(dataframe, cat_cols, rare_perc):\n    temp_df = dataframe.copy()\n    rare_columns = [col for col in cat_cols if (temp_df[col].value_counts() \/ len(temp_df) < 0.01).sum() > 1]\n\n    for col in rare_columns:\n        tmp = temp_df[col].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[col] = np.where(temp_df[col].isin(rare_labels), 'Rare', temp_df[col])\n\n    return temp_df\n","bfa99a3c":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler","0ce0786b":"df = pd.read_csv('titanic.csv')","03ded47e":"df.head()","b73a9e45":"from sklearn.preprocessing import StandardScaler","35e237fc":"scaler = StandardScaler()","da5699e5":"scaler.fit_transform(df[['Fare']])","08dabac1":"from sklearn.preprocessing import RobustScaler","52009d89":"scaler = RobustScaler()","9464f7be":"scaler.fit_transform(df[['Fare']])","9fc40e57":"from sklearn.preprocessing import MinMaxScaler","85931d52":"scaler = MinMaxScaler(feature_range=(0,1))","68a32037":"scaler.fit_transform(df[['Fare']])","426caabd":"import pandas as pd\nimport numpy as np","3163dc10":"df = pd.read_csv('titanic.csv')","de18133b":"df.head()","d9d6e63d":"df = df[['PassengerId','Survived','Pclass','Name','Age']]","b173796d":"df.head()","dd569360":"def create_title(x):\n    title = ''\n    if 'Mr.' in x:\n        title = 'Male'\n    elif 'Mrs.' in x or 'Miss.' in x:\n        title = 'Female'\n    else:\n        title = 'Unknown'\n    return title","f9c54597":"df.loc[:,'Title'] = df['Name'].apply(create_title)","73ab8c8e":"df.head()","73fb296d":"## Standard Scaler","e44253da":"# Introduction\n\n[@mebaysan](https:\/\/github.com\/mebaysan)\n\nI've prepared this notebook for [this](https:\/\/medium.com\/@mebaysan\/what-is-feature-engineering-11729cc57d89) Medium.com paper. The code's meaning will be presented in the paper. I will be just sharing the codes in this notebook.","f8bf52cd":"# Missing Values","1bf83128":"## Predictive Methods (KNN)","016f2ce2":"## One-Hot Encoding","62018cf6":"## Dummy Variables","0358cc4a":"## Removing","3a673769":"## Rare Encoding","a512e2ac":"# Encoding","12aaf9bb":"## Imputation","28cacce1":"# Outliers","33ee1df3":"# Feature Extraction","c3f99317":"## Min-Max Scaler","b45d281a":"## Robust Scaler","346e8667":"## Multi-Variable Outliers Analyze: Local Outlier\u00a0Factor","4214a553":"# Feature Scaling"}}