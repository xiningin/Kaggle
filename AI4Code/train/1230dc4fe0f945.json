{"cell_type":{"34b9d81b":"code","381d3ad0":"code","dfe21a7b":"code","87807b3b":"code","4edc0e94":"code","bf8166ba":"code","83af7493":"code","74ddd03b":"code","8a3605da":"code","c436a299":"code","db4cbac3":"code","596ea91f":"code","a793b4b4":"code","ddd9d935":"code","49d2ed67":"code","9d5aa21c":"code","e71af4a1":"code","16da3ef8":"code","1129b038":"markdown","649f1eb8":"markdown","aad86335":"markdown","74f89343":"markdown","6a372bab":"markdown","6853d5b2":"markdown","12f39b2c":"markdown","2aafd7ba":"markdown","cb56d6e7":"markdown","2a7b8a79":"markdown","e82e3a0e":"markdown","15c8ac77":"markdown","4493115c":"markdown","4c0c17dd":"markdown","1b74aacd":"markdown","e0fdca02":"markdown","18793408":"markdown","a0d81aae":"markdown","8d66f506":"markdown"},"source":{"34b9d81b":"import numpy as np \nimport pandas as pd \n\nimport sklearn.feature_extraction.text as text\n\nimport spacy\nfrom wordcloud import WordCloud,STOPWORDS\nnlp=spacy.load(\"en_core_web_lg\")\n\nimport textblob\n\n\nimport PIL\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","381d3ad0":"\ndata=pd.read_csv(\"..\/input\/indian-financial-news-articles-20032020\/IndianFinancialNews.csv\")\n\ndata","dfe21a7b":"data=data[['Date','Title']].drop_duplicates()\ndata","87807b3b":"\ndata['Date']=pd.to_datetime(data['Date'], infer_datetime_format=True)\ndata['Year']=data['Date'].dt.year\ndata","4edc0e94":"### Get imp words by year\n\ndef get_imp(bow,mf,ngram):\n    tfidf=text.CountVectorizer(bow,ngram_range=(ngram,ngram),max_features=mf,stop_words='english')\n    matrix=tfidf.fit_transform(bow)\n    return pd.Series(np.array(matrix.sum(axis=0))[0],index=tfidf.get_feature_names()).sort_values(ascending=False).head(100)\n\n","bf8166ba":"bow=data['Title'].tolist()","83af7493":"\n\ntotal_data=get_imp(bow,mf=5000,ngram=1)\n\n### Yearly trends\nimp_terms_unigram={}\nfor y in data['Year'].unique():\n    bow=data[data['Year']==y]['Title'].tolist()\n    imp_terms_unigram[y]=get_imp(bow,mf=5000,ngram=1)\n    \ncommon_unigram={}\nfor y in np.arange(2003,2020,1):\n    if y==2003:       \n        common_unigram[y]=set(imp_terms_unigram[y].index).intersection(set(imp_terms_unigram[y+1].index))\n    else:\n        common_unigram[y]=common_unigram[y-1].intersection(set(imp_terms_unigram[y+1].index))    \n\n","74ddd03b":"\ntotal_data_bigram=get_imp(bow=bow,mf=5000,ngram=2)\n\nimp_terms_bigram={}\nfor y in data['Year'].unique():\n    bow=data[data['Year']==y]['Title'].tolist()\n    imp_terms_bigram[y]=get_imp(bow,mf=5000,ngram=2)\n    \n### Common bigrams across all the years\ncommon_bigram={}\nfor y in np.arange(2003,2020,1):\n    if y==2003:\n         common_bigram[y]=set(imp_terms_bigram[y].index).intersection(set(imp_terms_bigram[y+1].index))\n    else:\n        common_bigram[y]=common_bigram[y-1].intersection(set(imp_terms_bigram[y+1].index))\n### Common bigrams across all the years\ncommon_bigram={}\nfor y in np.arange(2003,2020,1):\n    if y==2003:\n         common_bigram[y]=set(imp_terms_bigram[y].index).intersection(set(imp_terms_bigram[y+1].index))\n    else:\n        common_bigram[y]=common_bigram[y-1].intersection(set(imp_terms_bigram[y+1].index))\n\n    ","8a3605da":"\ntotal_data_trigram=get_imp(bow=bow,mf=5000,ngram=3)\n\nimp_terms_trigram={}\nfor y in data['Year'].unique():\n    bow=data[data['Year']==y]['Title'].tolist()\n    imp_terms_trigram[y]=get_imp(bow,mf=5000,ngram=3)\n\n    \n### Common trigrams, 1 year window\ncommon_trigram_1yr={}\nfor y in np.arange(2003,2020,1):\n    common_trigram_1yr[str(y)+\"-\"+str(y+1)]=set(imp_terms_trigram[y].index).intersection(set(imp_terms_trigram[y+1].index))\n### Commin trigrams, 2 year window\ncommon_trigram_2yr={}\nfor y in np.arange(2003,2018,3):\n    if y==2003:\n        common_trigram_2yr[str(y)+\"-\"+str(y+1)+\"-\"+str(y+2)]=set(imp_terms_trigram[y].index).intersection(set(imp_terms_trigram[y+1].index)).intersection(set(imp_terms_trigram[y+2].index))\n    else:\n        common_trigram_2yr[str(y)+\"-\"+str(y+1)+\"-\"+str(y+2)]=set(imp_terms_trigram[y].index).intersection(set(imp_terms_trigram[y+1].index)).intersection(set(imp_terms_trigram[y+2].index))\n","c436a299":"plt.subplot(1,3,1)\ntotal_data.head(20).plot(kind=\"bar\",figsize=(25,10),colormap='Set2')\nplt.title(\"Unigrams\",fontsize=30)\nplt.yticks([])\nplt.xticks(size=20)\nplt.subplot(1,3,2)\ntotal_data_bigram.head(20).plot(kind=\"bar\",figsize=(25,10),colormap='Set2')\nplt.title(\"Bigrams\",fontsize=30)\nplt.yticks([])\nplt.xticks(size=20)\nplt.subplot(1,3,3)\ntotal_data_trigram.head(20).plot(kind=\"bar\",figsize=(25,10),colormap='Set2')\nplt.title(\"Trigrams\",fontsize=30)\nplt.yticks([])\nplt.xticks(size=20)\n\n    \n","db4cbac3":"for i in range(1,19,1):\n    plt.subplot(9,2,i)\n    imp_terms_bigram[2002+i].head(5).plot(kind=\"barh\",figsize=(20,35),colormap='Set2')\n    plt.title(2002+i,fontsize=20)\n    plt.xticks([])\n    plt.yticks(size=20,rotation=5)","596ea91f":"for i in range(1,19,1):\n    plt.subplot(9,2,i)\n    imp_terms_trigram[2002+i].head(5).plot(kind=\"barh\",figsize=(20,30),colormap=\"Set2\")\n    plt.title(2002+i,fontsize=20)\n    plt.xticks([])\n    plt.yticks(size=15,rotation=5)","a793b4b4":"index_yes=data['Title'].str.match(r'(?=.*\\byes\\b)(?=.*\\bbank\\b).*$',case=False)\ndata_yes=data.loc[index_yes].copy()\ndata_yes['polarity']=data_yes['Title'].map(lambda x: textblob.TextBlob(x).sentiment.polarity)","ddd9d935":"pos=data_yes.query(\"polarity>0\")['Title']\nneg=data_yes.query(\"polarity<0\")['Title']\nprint(\"The number of positve headlines were {} times the negative headlines\".format(round(len(pos)\/len(neg),2)))","49d2ed67":"plt.figure(figsize=(8,8))\nplt.bar([\"Positive\",\"Negative\"],[len(pos),len(neg)])\nplt.title(\"Frequency of Positive and Negative News about Yes Bank\",fontsize=20)","9d5aa21c":"bow=data_yes['Title'].str.replace(r'yes|bank',\"\",case=False).tolist()\nyes_uni=get_imp(bow,mf=5000,ngram=1)\nyes_bi=get_imp(bow,mf=5000,ngram=2)\nyes_tri=get_imp(bow,mf=5000,ngram=3)","e71af4a1":"plt.subplot(1,3,1)\nyes_uni.head(10).plot(kind=\"barh\",figsize=(24,6),colormap=\"Set2\")\nplt.title(\"Unigrams\",fontsize=30)\nplt.yticks(size=20)\nplt.xticks([])\nplt.subplot(1,3,2)\nyes_bi.head(10).plot(kind=\"barh\",figsize=(24,6),colormap=\"Set1\")\nplt.title(\"Bigrams\",fontsize=30)\nplt.yticks(size=20)\nplt.xticks([])\nplt.subplot(1,3,3)\nyes_tri.head(10).plot(kind=\"barh\",figsize=(24,6),colormap=\"Set3\")\nplt.title(\"Trigrams\",fontsize=30)\nplt.yticks(size=20)\nplt.xticks([])","16da3ef8":"#url=\"https:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/8\/85\/Yes_Bank_logo.svg\/1200px-Yes_Bank_logo.svg.png\"\n\nyes_text=\" \".join(bow)\n\ncon_mask=np.array(PIL.Image.open('..\/input\/word-cloud\/YesBank.png'))\n\nwc = WordCloud(max_words=500, mask=con_mask,width=5000,height=2500,background_color=\"Black\",stopwords=STOPWORDS).generate(yes_text)\nplt.figure( figsize=(30,15))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.yticks([])\nplt.xticks([])\nplt.savefig('.\/yes.png', dpi=50)\nplt.show()","1129b038":"# Yes Bank Headlines","649f1eb8":"COVID has entered the top of the news even in Financial newspapers\n\nYes Bank which almost went bankrupt and was rescued by the RBI took top slot. Yes Bank promotor Rana Kapoor and the bank crisis are also in the top 5 for 2020\n\nEven in 2019, two bank failures of PMC Bank and Yes Bank are the top bigrams","aad86335":"# Plot the n-grams","74f89343":"<h2> Top 5 Bigrams across years<\/h2>","6a372bab":"![Source: Mint](https:\/\/images.livemint.com\/rf\/Image-621x414\/LiveMint\/Period2\/2018\/01\/20\/Photos\/Processed\/newspapers5-kBWB--621x414@LiveMint.jpg)\nI leverage the great data set to practice some text mining and visualization skills. \n\nLet me see if I may uncover some interesting insights.\n\nIs there anything you want me to discuss or explore. Please let me know in the comments sections\n\nThanks for your encouragement!!","6853d5b2":"<h2> Top 5 Trigrams across years<\/h2>","12f39b2c":"# Read the Data ","2aafd7ba":"# Bigrams","cb56d6e7":"# Let's add Year (for annual trends)","2a7b8a79":"# Unigrams","e82e3a0e":"# Trigrams","15c8ac77":"# Bigrams and Trigrams across years\nTo get a sense of trend across years, I also plotted bigrams and trigrams across the years","4493115c":"# Import Libraries","4c0c17dd":"# Interesting isn't it!! In spite of the scam and potential bankruptcy, we have alomost as much positive news as negative news on Yes Bank","1b74aacd":"# Visualization Indian Financial News Headlines ","e0fdca02":"# Remove Unwanted Rows & Duplicates (if any)","18793408":"# What Next?\n\nClean up\n\nIntroduce stop words and remove  Indian currency (Rs) and other details\n\nAdd some more themes\n\nWill work on it some more and update\n\nThanks for your comments and feedback","a0d81aae":"Note: 582 duplicates were removed\n\nWe have over 17 years of data-- from Feb 2003 to May 2020","8d66f506":"Ohh Kay!!!\nYes Bnk crisis and COVID19 are the top of the trigrams in 2020 as well"}}