{"cell_type":{"47f16227":"code","72528b31":"code","76c1cf8b":"code","5b72c531":"code","f0dc6eef":"code","13205711":"code","e584175b":"code","2173e0bf":"code","4a52ae8d":"code","e0a9759a":"code","756af9ac":"code","8a1a98ce":"code","d45f0920":"code","c30de9d2":"code","185b49d6":"code","993f7481":"markdown","03bad89e":"markdown","e576c758":"markdown","1f617738":"markdown","eb15420a":"markdown","38c7a6cc":"markdown","49de91ba":"markdown","f2ed4a33":"markdown","1feab924":"markdown","c4dc742b":"markdown","efdecdaf":"markdown"},"source":{"47f16227":"import pandas as pd\nimport sklearn\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n","72528b31":"train = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\",\n        names=[\n        \"Id\",\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n         engine='python',skiprows = 1,na_values=\"?\").drop([\"Id\"], axis = 1)\n\ntest = pd.read_csv(\"..\/input\/adult-pmr3508\/test_data.csv\",\n        names=[\n        \"Id\",\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\"],\n         engine='python',skiprows = 1,na_values=\"?\").drop([\"Id\"], axis = 1)\ntrain","76c1cf8b":"train.drop_duplicates(keep = 'first', inplace = True)\ntrain = train.drop(['fnlwgt', 'Country', 'Education'], axis=1)\ntest = test.drop(['fnlwgt', 'Country', 'Education'], axis=1)\n","5b72c531":"train","f0dc6eef":"numtreino = train[[ \"Age\", \"Education-Num\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\" ,\"Target\" ]]\n\ncategtreino = train.drop([\"Age\", \"Education-Num\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\" ,\"Target\"] , axis = 1)\n\nnumtest = test[[\"Age\", \"Education-Num\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\" ]]\n\ncategtest = test.drop([\"Age\", \"Education-Num\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\"], axis = 1)","13205711":"numtreino.head()","e584175b":"categtreino.head()","2173e0bf":"categtreino = pd.get_dummies(categtreino)\ncategtest = pd.get_dummies(categtest)\n\ncategtreino.head()","4a52ae8d":"train = pd.concat([categtreino, numtreino], axis = 1)\ntest = pd.concat([categtest, numtest], axis =1)\ntrain.head()","e0a9759a":"categtreino","756af9ac":"y_train = train[[\"Target\"]]\nx_train = train.drop([\"Target\"], axis = 1)\nx_test = test\n","8a1a98ce":"#vamos buscar o k que tem o melhor score\nbestscore=[0,0]\n#for k in range(15):\n #   knn = KNeighborsClassifier(n_neighbors = (2*k+1))\n  #  score = cross_val_score(knn, x_train, y_train, cv = 5, scoring=\"accuracy\")\n   # print(\"Utilizando k =\", (k*2+1), score.mean())\n    #if score.mean() > bestscore[1]:\n     #   bestscore[0] = k*2+1\n      #  bestscore[1] = score.mean()\nknn = KNeighborsClassifier(n_neighbors = (21))\nscore = cross_val_score(knn, x_train, y_train, cv = 5, scoring=\"accuracy\")\nprint(\"O K que melhor se ajustou foi k = 21; com uma pontua\u00e7\u00e3o de\",score.mean() )\n    ","d45f0920":"knn = KNeighborsClassifier(n_neighbors= 21)\nknn.fit(x_train, y_train)","c30de9d2":"predicao = knn.predict(x_test)\npredicao","185b49d6":"submission = pd.DataFrame()\nsubmission[\"ID\"] = test.index\nsubmission[\"Income\"] = predicao\nsubmission.to_csv('submission.csv',index = False)\nsubmission","993f7481":"**Classification with the Adult dataset**\n\n**PMR3508 - Aprendizado de M\u00e1quina**\n\n**Hash Code: PMR3508-2021-100**","03bad89e":"Agora a base categorica ser\u00e1 dividida, de modo que cada categoria receba uma coluna para ser marcada com 0 ou 1. ","e576c758":"Agora iremos unir as bases novamente.","1f617738":"Agora que j\u00e1 temos qual K deve ser utilizado iremos realizar nossas predi\u00e7\u00f5es.\n\nPrimeiramente o classificador vai ser ajustado utilziando a base de treino, com k = 20","eb15420a":"Com a predi\u00e7\u00e3o pronta vamos criar um arquivo csv para submeter as predi\u00e7\u00f5es.","38c7a6cc":"**2. Tratamento de Dados**\n\nUtilziando a biblioteca pandas, importaremos as bases de dados de treino e teste.\n\nEm seguida uma parte da base \u00e9 impressa para se ter uma visualiza\u00e7\u00e3o da mesma.","49de91ba":"**1. Aqui estaremos importando as bibliotecas que ser\u00e3o utilizadas.**\n\n* Pandas: Importa\u00e7\u00e3o e manipula\u00e7\u00e3o do dataframe\n* sklearn: Ferramentas de Machine learn\n* Numpy: An\u00e1lises e manipula\u00e7\u00f5es alg\u00e9bricas","f2ed4a33":"Como podemos analisar existem v\u00e1riaveis num\u00e9ricas, como idade e vari\u00e1veis categoricas como o estado matrimonial. \n\nPortanto ser\u00e1 necess\u00e1rio separar as bases entre num\u00e9ricas e categ\u00f3ricas\n\nAs novas bases est\u00e3o impressas para melhor visualiza\u00e7\u00e3o","1feab924":"**3. Treino do classificador**\n\nAgora o classificar ser\u00e1 treinado utilizando K variando de 1 a 31 (utilizando apenas valores \u00edmpares) para encontrar o K que resulta em um melhor score. \n\n**Nota se que esse teste demanda muita capacidade de processamento, portanto o c\u00f3digo que testa todos os valores poss\u00edveis receber\u00e1 um # na frente, e o c\u00f3digo ir\u00e1 rodar apenas uma vez com o melhor k encontrado em testes anteriores**","c4dc742b":"Para finalizar o tratamento de dados, a base ser\u00e1 separada entre features(x) e target(y)","efdecdaf":"Agora utilizando a base de testes, o classificar vai criar uma array com as predi\u00e7\u00f5es."}}