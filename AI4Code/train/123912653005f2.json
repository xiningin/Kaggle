{"cell_type":{"ea859180":"code","de26fb15":"code","d5b158ca":"code","9c3ed5d6":"code","80d8af67":"code","ef913802":"code","ed05649d":"code","a9d2fc0e":"code","df33b37d":"code","8877bb23":"code","bab1d4aa":"code","dd399c1e":"code","93588030":"code","826d3b6e":"code","bad9a3bc":"code","3d2ca118":"code","db55e1df":"code","ed87c9e4":"code","9506be0c":"code","18c7787d":"code","3dda2b15":"code","76c1e406":"code","c1bb9441":"code","fba23902":"code","b4963789":"code","e823ab6c":"code","ee1c0808":"code","7c72be0a":"code","63b4cfb0":"code","d828af0a":"code","f727f705":"code","238ae3b5":"code","cb6479fc":"code","5e8faa65":"code","9d5c9a63":"code","d666dc18":"code","3672cd24":"code","59d657c8":"code","ef91bfdd":"code","9b3c0099":"code","ba69381d":"code","b0a47dd8":"code","043d7c4b":"code","3cb3e0d6":"code","308b8b5e":"code","949d267c":"code","61fbc521":"code","f976bdf5":"code","1f5d5338":"code","a1b494f7":"code","ee0df9ae":"code","23b8dec2":"code","f8d95dbc":"code","d28a4218":"code","96158c02":"code","60ffdecd":"code","96358795":"code","94ea471c":"code","48d2c3c1":"code","2a7671b5":"code","dc20a3bf":"code","a9744fe5":"code","abba1541":"code","5eba054a":"code","1183b2d6":"code","e4707c81":"code","63d4c923":"code","34a0a83f":"code","ff228b37":"code","7d9655a4":"code","8648e7e9":"code","6f575405":"code","55a325c6":"code","290d0633":"code","507c2f7a":"code","b77e37d1":"code","4d0e700e":"code","e0aaeb54":"code","10a1e782":"code","a02e19f7":"code","4c3b5f39":"code","55fc89b5":"code","228209d9":"code","d97faf29":"code","20e0f6ba":"code","d7cbf101":"code","5d173cd5":"code","f0795cf1":"code","4f744f9c":"code","c21db4c9":"code","9c3aef0e":"code","ebc46e5b":"code","1f917e31":"code","e0161526":"code","62bb176d":"code","4a8004c7":"code","a942c59a":"markdown","7aa1bd57":"markdown","3bb858ad":"markdown","408eeef0":"markdown","98fc4b90":"markdown","1c606153":"markdown","cffff911":"markdown","b6e39d92":"markdown","4fdc9550":"markdown","8990c22a":"markdown","0686378b":"markdown","188704e6":"markdown","e01adc73":"markdown","70bc3028":"markdown","e1d10040":"markdown","104928a9":"markdown","78284f4b":"markdown","2a6da308":"markdown","24baf17d":"markdown","1e511480":"markdown","7d47b87d":"markdown","d3155472":"markdown","a00ea244":"markdown","fe1a2711":"markdown","c3fcb654":"markdown","ec34c4a9":"markdown","40425af0":"markdown","5b16f2f4":"markdown","6b137665":"markdown","b4097acf":"markdown","b879dd69":"markdown","14924a38":"markdown","160cc432":"markdown","42120886":"markdown","2c16f87b":"markdown"},"source":{"ea859180":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns #prettier data visualization\nimport torch\nsns.set_theme()\nsns.set_style(\"whitegrid\")","de26fb15":"torch.manual_seed(42)\nnp.random.seed(42)","d5b158ca":"#Funci\u00f3n que muestra una peque\u00f1a imagen\ndef mostrar_ropa_por_categoria(array_x,array_y,categoria:int) -> None:\n    plt.imshow(X=array_x[(array_y == categoria)[:,0]][0][0])\n    \n#Funci\u00f3n que muestra una Grafica de L\u00ednea de el error del Modelo\ndef mostrar_aprendizaje(error_list_train,error_list_test) -> None:\n    ax = sns.lineplot(data=dict(enumerate(error_list_train)))\n    ax.set(xlabel='# Epoch',ylabel='Negative Log Likelihood Loss',title='Error de Entrenamiento')\n    plt.show()\n    ax = sns.lineplot(data=dict(enumerate(error_list_test)))\n    ax.set(xlabel='# Epoch',ylabel='Negative Log Likelihood Loss',title='Error de Prueba')\n    plt.show()","9c3ed5d6":"test_path = '..\/input\/fashionmnist\/fashion-mnist_test.csv'\ntrain_path = '..\/input\/fashionmnist\/fashion-mnist_train.csv'\nmapper = {0:\"T-shirt\/top\",1:\"Trouser\" ,2:\"Pullover\",3:\"Dress\",4:\"Coat\",5:\"Sandal\",6:\"Shirt\",\n          7:\"Sneaker\",8:\"Bag\",9:\"Ankle boot\"}","80d8af67":"# Primero que nada Cargamos los datos de Entrenamiento y de pruebas. Verificando sus dimensiones para \n# Asegurarnos que todo est\u00e9 bien. \ntraining_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n#Cargamos los datos de Entrenamiento\ntraining_data_y = training_data[['label']].to_numpy()\ntraining_data_x = training_data.iloc[:,1:].to_numpy()\n\n#Cargamos los datos de Prueba\ntest_data_y = test_data[['label']].to_numpy()\ntest_data_x = test_data.iloc[:,1:].to_numpy()\n\nprint(f'Training: X({training_data_x.shape[0]},{training_data_x.shape[1]}) Y({training_data_y.shape[0]},{training_data_y.shape[1]})')\nprint(f'Test: X({test_data_x.shape[0]},{test_data_x.shape[1]}) Y({test_data_y.shape[0]},{test_data_y.shape[1]})')\n\n# Y a\u00f1adimos unos Asserts para asegurarnos que todo tiene sentido. \n# Afirmaciones de la cantidad de filas\nassert training_data_x.shape[0] == training_data_y.shape[0] \nassert test_data_x.shape[0] == test_data_y.shape[0] \n\n# Afirmaciones de la cantidad de columnas\nassert training_data_x.shape[1] == test_data_x.shape[1] \nassert training_data_y.shape[1] == test_data_y.shape[1] ","ef913802":"### Reformamos las Imagenes para a su forma Matricial \ntraining_data_x = training_data_x.reshape((-1,1,28,28))\ntest_data_x = test_data_x.reshape((-1,1,28,28))\n\nprint(f'Training: X({training_data_x.shape[0]},{training_data_x.shape[1]},{training_data_x.shape[2]},{training_data_x.shape[3]}) Y({training_data_y.shape[0]},{training_data_y.shape[1]})')\nprint(f'Test: X({test_data_x.shape[0]},{test_data_x.shape[1]},{test_data_x.shape[2]},{test_data_x.shape[3]}) Y({test_data_y.shape[0]},{test_data_y.shape[1]})')\n","ed05649d":"#Mostramos Im\u00e1genes Aleatorias\ntraining_sample = np.random.randint(low=0,high=training_data_x.shape[0])\ntest_sample = np.random.randint(low=0,high=test_data_x.shape[0])\n#Tomamos una imagen del Training Data\nplt.imshow(X=training_data_x[training_sample,0])\nprint(f'Es un {mapper[training_data_y[training_sample,0]]}')\nplt.show()\n#Tomamos una imagen del Test Data\nplt.imshow(X=test_data_x[test_sample,0])\nprint(f'Es un {mapper[test_data_y[test_sample,0]]}')\n\nplt.show()","a9d2fc0e":"# Tomamos 1 Ejemplo de cada Tipo de Ropa\nfig = plt.figure(figsize=(8,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i+1,title=f'{mapper[i]} ({i})')\n    mostrar_ropa_por_categoria(training_data_x,training_data_y,i)\nplt.show()","df33b37d":"training_data_x = (torch.from_numpy(training_data_x).type(torch.float)).cuda()\ntraining_data_y = (torch.from_numpy(training_data_y)[:,0]).cuda()\ntest_data_x = (torch.from_numpy(test_data_x).type(torch.float)).cuda()\ntest_data_y = (torch.from_numpy(test_data_y)[:,0]).cuda()","8877bb23":"print(training_data_x.dtype)\nprint(training_data_y.dtype)\nprint(test_data_x.dtype)\nprint(test_data_y.dtype)","bab1d4aa":"train_dataset = torch.utils.data.TensorDataset(training_data_x,training_data_y)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,batch_size=128)","dd399c1e":"# Modelo 0 de Prueba\n\n# Se genera el modelo con dos capas convolucionales, en cada capa se realiza un MaxPool que reduce el tama\u00f1o a la mitad\nmodel = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Flatten(),\n          torch.nn.Linear(1568,32),\n          torch.nn.ReLU(),\n          torch.nn.Linear(32,16),\n          torch.nn.ReLU(),\n          torch.nn.Linear(16,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel.to('cuda')","93588030":"epochs = 60\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model.parameters(),lr=0.001)\nmodel_0_error_accums_train = []\nmodel_0_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_0_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model.eval()\n            Y_predict_test = model(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_0_error_accums_test.append(loss.item())\n            model.train()","826d3b6e":"mostrar_aprendizaje(model_0_error_accums_train,model_0_error_accums_test)","bad9a3bc":"with torch.no_grad():\n    Y_predict_train = model(training_data_x)\n    Y_predict_test = model(test_data_x)    ","3d2ca118":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","db55e1df":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","ed87c9e4":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","9506be0c":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","18c7787d":"# Modelo 1 de Prueba\n\nmodel1 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Flatten(),\n          torch.nn.Linear(1568,32),\n          torch.nn.ReLU(),\n          torch.nn.Linear(32,16),\n          torch.nn.ReLU(),\n          torch.nn.Linear(16,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel1.to('cuda')","3dda2b15":"epochs = 80\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model1.parameters(),lr=0.001)\nmodel_1_error_accums_train = []\nmodel_1_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model1(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_1_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model1.eval()\n            Y_predict_test = model1(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_1_error_accums_test.append(loss.item())\n            model1.train()","76c1e406":"mostrar_aprendizaje(model_1_error_accums_train,model_1_error_accums_test)","c1bb9441":"with torch.no_grad():\n    Y_predict_train = model1(training_data_x)\n    Y_predict_test = model1(test_data_x)","fba23902":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","b4963789":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","e823ab6c":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","ee1c0808":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","7c72be0a":"# Modelo 2 de Prueba\n\nmodel2 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          torch.nn.Flatten(),\n          torch.nn.Linear(1568,32),\n          torch.nn.PReLU(32),\n          torch.nn.Linear(32,16),\n          torch.nn.PReLU(16),\n          torch.nn.Linear(16,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel2.to('cuda')","63b4cfb0":"epochs = 60\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model2.parameters(),lr=0.001)\nmodel_2_error_accums_train = []\nmodel_2_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model2(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_2_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model2.eval()\n            Y_predict_test = model2(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_2_error_accums_test.append(loss.item())\n            model2.train()","d828af0a":"mostrar_aprendizaje(model_2_error_accums_train,model_2_error_accums_test)","f727f705":"with torch.no_grad():\n    Y_predict_train = model2(training_data_x)\n    Y_predict_test = model2(test_data_x)","238ae3b5":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","cb6479fc":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","5e8faa65":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","9d5c9a63":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","d666dc18":"# Modelo 3 de Prueba\n\nmodel3 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n    \n          torch.nn.Flatten(),\n          torch.nn.Linear(3136,256),\n          torch.nn.ReLU(),\n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel3.to('cuda')","3672cd24":"epochs = 60\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model3.parameters(),lr=0.001,momentum=0.9)\nmodel_3_error_accums_train = []\nmodel_3_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model3(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_3_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model3.eval()\n            Y_predict_test = model3(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_3_error_accums_test.append(loss.item())\n            model3.train()","59d657c8":"mostrar_aprendizaje(model_3_error_accums_train,model_3_error_accums_test)","ef91bfdd":"with torch.no_grad():\n    Y_predict_train = model3(training_data_x)\n    Y_predict_test = model3(test_data_x)","9b3c0099":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","ba69381d":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","b0a47dd8":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","043d7c4b":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","3cb3e0d6":"# Modelo 4 de Prueba\n\nmodel4 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.Flatten(),\n    \n          torch.nn.Dropout(p=0.5),\n          torch.nn.Linear(3136,256),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.3),\n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.1),\n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.05),\n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel4.to('cuda')","308b8b5e":"epochs = 80\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model4.parameters(),lr=0.001,momentum=0.9)\nmodel_4_error_accums_train = []\nmodel_4_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model4(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_4_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model4.eval()\n            Y_predict_test = model4(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_4_error_accums_test.append(loss.item())\n            model4.train()","949d267c":"mostrar_aprendizaje(model_4_error_accums_train,model_4_error_accums_test)","61fbc521":"model4.eval()","f976bdf5":"with torch.no_grad():\n    Y_predict_train =  model4(training_data_x)\n    Y_predict_test = model4(test_data_x)","1f5d5338":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","a1b494f7":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","ee0df9ae":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","23b8dec2":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","f8d95dbc":"# Modelo 5 de Prueba\n\nmodel5 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.Flatten(),\n    \n          torch.nn.Dropout(p=0.7),\n          torch.nn.Linear(3136,256),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.5),\n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.1),\n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.05),\n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel5.to('cuda')","d28a4218":"epochs = 80\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model5.parameters(),lr=0.001,momentum=0.9)\nmodel_5_error_accums_train = []\nmodel_5_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model5(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_5_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model5.eval()\n            Y_predict_test = model5(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_5_error_accums_test.append(loss.item())\n            model5.train()","96158c02":"mostrar_aprendizaje(model_5_error_accums_train,model_5_error_accums_test)","60ffdecd":"model5.eval()","96358795":"with torch.no_grad():\n    Y_predict_train =  model5(training_data_x)\n    Y_predict_test = model5(test_data_x)","94ea471c":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","48d2c3c1":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","2a7671b5":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","dc20a3bf":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","a9744fe5":"# Modelo 6 de Prueba\n\nmodel6 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.Flatten(),\n    \n          torch.nn.Linear(3136,256),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.5),\n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.3),\n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.05),\n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel6.to('cuda')","abba1541":"epochs = 80\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model6.parameters(),lr=0.001,momentum=0.9)\nmodel_6_error_accums_train = []\nmodel_6_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model6(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_6_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model6.eval()\n            Y_predict_test = model6(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_6_error_accums_test.append(loss.item())\n            model6.train()","5eba054a":"mostrar_aprendizaje(model_6_error_accums_train,model_6_error_accums_test)","1183b2d6":"model6.eval()","e4707c81":"with torch.no_grad():\n    Y_predict_train =  model6(training_data_x)\n    Y_predict_test = model6(test_data_x)","63d4c923":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","34a0a83f":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","ff228b37":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","7d9655a4":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","8648e7e9":"# Modelo 7 de Prueba\n\nmodel7 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.Flatten(),\n\n          torch.nn.Linear(3136,256),\n          torch.nn.ReLU(),\n    \n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n    \n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n    \n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel7.to('cuda')","6f575405":"epochs = 80\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model7.parameters(),lr=0.001,momentum=0.9,weight_decay= 0.01)\nmodel_7_error_accums_train = []\nmodel_7_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model7(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_7_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model7.eval()\n            Y_predict_test = model7(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_7_error_accums_test.append(loss.item())\n            model7.train()","55a325c6":"mostrar_aprendizaje(model_7_error_accums_train,model_7_error_accums_test)","290d0633":"with torch.no_grad():\n    Y_predict_train =  model7(training_data_x)\n    Y_predict_test = model7(test_data_x)","507c2f7a":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","b77e37d1":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","4d0e700e":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","e0aaeb54":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","10a1e782":"# Modelo 8 de Prueba\n\nmodel8 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,16,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(16,32,3,padding=\"same\"),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.Flatten(),\n            \n          torch.nn.Dropout(p=0.7),\n          torch.nn.Linear(3136,4096),\n          torch.nn.ReLU(),\n          torch.nn.BatchNorm1d(4096),\n          \n          torch.nn.Dropout(p=0.5),\n          torch.nn.Linear(4096,2048),\n          torch.nn.ReLU(),\n          torch.nn.BatchNorm1d(2048),\n    \n          torch.nn.Dropout(p=0.1),\n          torch.nn.Linear(2048,512),\n          torch.nn.ReLU(),\n          torch.nn.BatchNorm1d(512),\n    \n          torch.nn.Dropout(p=0.05),\n          torch.nn.Linear(512,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\nmodel8.to('cuda')","a02e19f7":"epochs = 20\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model8.parameters(),lr=0.001,momentum=0.9)\nmodel_8_error_accums_train = []\nmodel_8_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model8(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_8_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model8.eval()\n            Y_predict_test = model8(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_8_error_accums_test.append(loss.item())\n            model8.train()","4c3b5f39":"mostrar_aprendizaje(model_8_error_accums_train,model_8_error_accums_test)","55fc89b5":"model8.eval()","228209d9":"with torch.no_grad():\n    Y_predict_train =  model8(training_data_x)\n    Y_predict_test = model8(test_data_x)","d97faf29":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","20e0f6ba":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","d7cbf101":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","5d173cd5":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","f0795cf1":"# Modelo 9 de Prueba (Basado en el Modelo 4 y el Modelo 7)\n\nmodel9 = torch.nn.Sequential(\n          torch.nn.Conv2d(1,32,3,padding=\"same\"),\n          torch.nn.ReLU(),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n          \n          torch.nn.Conv2d(32,64,3,padding=\"same\"),\n          torch.nn.ReLU(),\n          torch.nn.MaxPool2d((3,3),stride=2,padding=1),\n    \n          torch.nn.Conv2d(64,128,3,padding=\"same\"),\n          torch.nn.ReLU(),\n          torch.nn.Flatten(),\n    \n          torch.nn.Dropout(p=0.7),\n          torch.nn.Linear(6272,256),\n          torch.nn.ReLU(),\n\n          torch.nn.Dropout(p=0.5),\n          torch.nn.Linear(256,64),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.3),\n          torch.nn.Linear(64,32),\n          torch.nn.ReLU(),\n    \n          torch.nn.Dropout(p=0.1),\n          torch.nn.Linear(32,10),\n          torch.nn.LogSoftmax(dim=1),\n        )\n\nmodel9.to('cuda')","4f744f9c":"epochs = 100\ncriterion = torch.nn.NLLLoss()\noptimizer = torch.optim.SGD(model9.parameters(),lr=0.001,momentum=0.9,weight_decay=0.001)\nmodel_9_error_accums_train = []\nmodel_9_error_accums_test = []\nfor i in range(epochs):\n    accum_loss = 0\n    for inputs,labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model9(inputs)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item()\n    else:\n        print(f\"La perdida de Entrenamiento para el Epoch {i + 1} es: {accum_loss\/len(train_loader)}\" )\n        model_9_error_accums_train.append(accum_loss\/len(train_loader))\n        with torch.no_grad():\n            model9.eval()\n            Y_predict_test = model9(test_data_x)    \n            loss = criterion(Y_predict_test,test_data_y)\n            print(f\"La perdida de Pruebas para el Epoch {i + 1} es: {loss.item()}\" )\n            model_9_error_accums_test.append(loss.item())\n            model9.train()","c21db4c9":"mostrar_aprendizaje(model_9_error_accums_train,model_9_error_accums_test)","9c3aef0e":"model9.eval()","ebc46e5b":"with torch.no_grad():\n    Y_predict_train =  model9(training_data_x)\n    Y_predict_test = model9(test_data_x)","1f917e31":"Y_predict_train = torch.exp(Y_predict_train)\nY_predict_test = torch.exp(Y_predict_test)","e0161526":"training_accuracy = torch.sum(training_data_y == torch.max(Y_predict_train,axis=1).indices) \/\\\nlen(Y_predict_train)\ntest_accuracy = torch.sum(test_data_y == torch.max(Y_predict_test,axis=1).indices) \/\\\nlen(Y_predict_test)\nprint(f'Training Accuracy: {training_accuracy * 100}%\\nTest Accuracy: {test_accuracy * 100}%')","62bb176d":"# Tomamos 10 Predicci\u00f3nes Erroneas\nwrong_examples_x = test_data_x[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_examples_y = test_data_y[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = Y_predict_test[~(test_data_y == torch.max(Y_predict_test,axis=1).indices)][:10]\nwrong_predictions = torch.max(wrong_predictions,axis=1).indices","4a8004c7":"fig = plt.figure(figsize = (16,8))\nfor i in range(0,10):\n    fig.add_subplot(2,5,i + 1,title=f'Label Correcto: {mapper[wrong_examples_y.cpu().numpy()[i]]}\\nLabel Predicho: {mapper[wrong_predictions.cpu().numpy()[i]]}')\n    plt.imshow(X=wrong_examples_x.cpu().numpy()[i][0])\nplt.show()","a942c59a":"## Modelo 1","7aa1bd57":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","3bb858ad":"## Modelo 0\n","408eeef0":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","98fc4b90":"### Conversi\u00f3n de los Arrays de Numpy a Tensores de Pytorch","1c606153":"### Crear los DataLoaders","cffff911":"## Modelo 6","b6e39d92":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","4fdc9550":"### Carga de las Im\u00e1genes usando Numpy","8990c22a":"### Arquitectura del Modelo","0686378b":"### Rutas de las Im\u00e1genes","188704e6":"<body>\n    <img src= \"https:\/\/emovies.oui-iohe.org\/wp-content\/uploads\/2021\/02\/logo-unimetcon-rif-300x142.jpg\"\/>\n    <center><h1>Proyecto 1<\/h1><\/center>\n    <center><h1>Categorizaci\u00f3n de Ropa: MNIST Dataset<\/h1><\/center>\n    <h2>Elaborado Por:<\/h2>\n    <ul>\n        <li><h3>Andr\u00e9s Betancourt, Carnet: 20191110760<\/h3><\/li>\n        <li><h3>Manuel G\u00f3mez, Carnet: 20191110110<\/h3><\/li>\n    <\/ul>\n<\/body>","e01adc73":"### Modelo 7","70bc3028":"### Pruebas del Modelo","e1d10040":"### Muestreo Categ\u00f3rico De Im\u00e1genes","104928a9":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","78284f4b":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","2a6da308":"## Modelo 3","24baf17d":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","1e511480":"## Carga de Datos y Muestras de las Im\u00e1genes","7d47b87d":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","d3155472":"### Muestreo Aleatorio de Im\u00e1genes","a00ea244":"### Pruebas del Modelo","fe1a2711":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","c3fcb654":"## Modelo 9","ec34c4a9":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo","40425af0":"### Entrenamiento del Modelo","5b16f2f4":"## Modelo 8","6b137665":"## Modelo 2","b4097acf":"### Funciones Auxiliares para la Muestra de Datos","b879dd69":"## Modelo 4","14924a38":"### Configurar Valores Semilla para asegurar resultados reproducibles","160cc432":"## Importaciones B\u00e1sicas","42120886":"## Modelo 5","2c16f87b":"### Ejemplos de Prueba donde el Modelo Lleg\u00f3 al Resultado Erroneo"}}