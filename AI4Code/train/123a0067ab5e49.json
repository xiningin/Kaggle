{"cell_type":{"28646140":"code","53e627ff":"code","7ece2aee":"code","fabb6ccb":"code","1fe8798e":"code","a0766ee1":"code","cbc9ade7":"code","7902334f":"code","e8937ad9":"code","dabe459b":"code","caab6a0b":"code","1e8818a7":"markdown","66b0d34a":"markdown","02051df7":"markdown","a2f87487":"markdown"},"source":{"28646140":"from transformers import *","53e627ff":"import numpy as np","7ece2aee":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = TFBertForMaskedLM.from_pretrained('bert-base-uncased') \n\n# DEFINE SENTENCE\nstr = '[CLS] Data science is [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","fabb6ccb":"str = '[CLS] BERT is the [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","1fe8798e":"str = '[CLS] Apple really [MASK] good those [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","a0766ee1":"str = '[CLS] Kaggle is definitely not [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","cbc9ade7":"str = '[CLS] Google will dominate the [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","7902334f":"str = '[CLS] Microsoft will languish in the [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","e8937ad9":"str = '[CLS] The king of NLP will always [MASK] [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","dabe459b":"str = '[CLS] Kaggle is [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","caab6a0b":"str = '[CLS] @philippsinger is a [MASK] grandmaster on Kaggle . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\nprint( tokenizer.decode(predicted_words) )","1e8818a7":"KAGGLE IS A GOOSE, NOT A CHICKEN!!","66b0d34a":"# Credits\n\n* @cdeotte for providing the base with his wonderful discussion post.","02051df7":"# First of all, let me make things clear.","a2f87487":"If BERT gets this one I'll give it a nice Coke."}}