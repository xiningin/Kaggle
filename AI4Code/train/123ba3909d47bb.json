{"cell_type":{"60e06bbf":"code","7ce99aba":"code","88e15b48":"code","148859eb":"code","fd99943b":"code","500c725a":"code","552f3d34":"code","3e8c5fc0":"code","d3482389":"code","862f7c3e":"code","0dadd07c":"code","45f45fa6":"code","674edd95":"code","be50abc4":"code","f066f620":"code","84399687":"code","3ddf728e":"markdown"},"source":{"60e06bbf":"import shap","7ce99aba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport xgboost as xgb\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88e15b48":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ndf_train.head()\n\n# PassengerId:\u4e57\u5ba2\u5225\u30e6\u30cb\u30fc\u30afID\n# Survived\uff1a\u751f\u5b58\u30d5\u30e9\u30b0\uff08\uff10\uff1d\u6b7b\u4ea1\u3001\uff11\uff1d\u751f\u5b58\uff09\n# Pclass\uff1a\u30c1\u30b1\u30c3\u30c8\u30af\u30e9\u30b9\uff08\uff11\uff1d\u30bb\u30ec\u30d6\u3001\uff12\uff1d\u4e00\u822c\u968e\u7d1a\u3001\uff13\uff1d\u52b4\u50cd\u968e\u7d1a\uff09\n# Name\uff1a\u4e57\u5ba2\u306e\u540d\u524d\n# Sex\uff1a\u6027\u5225\n# Age\uff1a\u5e74\u9f62\n# SibSp\uff1a\u708a\u3044\u305f\u5fcd\u82e6\u306b\u540c\u60c5\u3057\u3066\u3044\u308b\u5144\u5f1f\u30fb\u914d\u5076\u8005\u306e\u6570\n# Parch\uff1a\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u306b\u540c\u60c5\u3057\u3066\u3044\u308b\u89aa\u30fb\u5b50\u4f9b\u306e\u6570\n# Ticket\uff1a\u30c1\u30b1\u30c3\u30c8\u756a\u53f7\n# Fare\uff1a\u6599\u91d1\n# Cabin\uff1a\u5ba2\u5ba4\u756a\u53f7\n# Embarked\uff1a\u51fa\u6e2f\u5730\uff08\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u306b\u4e57\u3063\u305f\u6e2f\uff09","148859eb":"# \u57fa\u672c\u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ndf_train.describe()","fd99943b":"def isnullData(df):\n    nullVal = df.isnull().sum()\n    percent = 100 * df.isnull().sum()\/len(df)\n    nullTable = pd.concat([nullVal,percent],axis=1)\n    nullTable_ren_columns = nullTable.rename(columns={0:\"\u6b20\u640d\u6570\",1:\"%\"})\n    \n    return nullTable_ren_columns\n\nisnullData(df_train)\n","500c725a":"isnullData(df_test)","552f3d34":"# \u2461\u6b20\u640d\u30c7\u30fc\u30bf\u306e\u4e8b\u524d\u51e6\u7406\n# \u2461-(1) \u6b20\u640d\u30c7\u30fc\u30bf\u3092\u4ee3\u7406\u30c7\u30fc\u30bf\u306b\u5165\u308c\u66ff\u3048\u308b\n# \u300cCabin\u300d\u306f\u4e88\u6e2c\u30e2\u30c7\u30eb\u3067\u4f7f\u308f\u306a\u3044\u306e\u3067\u3001\u300cAge\u300d\u3068\u300cEmbarked\u300d\u306e2\u3064\u306e\u6b20\u640d\u30c7\u30fc\u30bf\u3092\u88dc\u5b8c\u3059\u308b\n\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u306eAge\u306e\u6b20\u640d\u7b87\u6240\u306b\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u306eAge\u306e\u4e2d\u592e\u5024\u3092\u4ee3\u5165\u3059\u308b\n# pandas.DataFrame.fillna() \u6b20\u640d\u5024\u3092\u5f15\u6570\u306e\u5024\u306b\u7f6e\u304d\u63db\u3048\u308b\ndf_train[\"Age\"] = df_train[\"Age\"].fillna(df_train[\"Age\"].median())\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u306eEmbarked\u306e\u6b20\u640d\u7b87\u6240\u306b\u3001S\u3092\u4ee3\u5165\u3059\u308b\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna(\"S\")\n\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u3066\u6b20\u640d\u304c\u306a\u304f\u306a\u3063\u305f\u4e8b\u3092\u78ba\u8a8d(Cabin\u306f\u9664\u304f)\nisnullData(df_train)","3e8c5fc0":"# \u2461-(2) \u6587\u5b57\u5217\u30ab\u30c6\u30b4\u30ea\u5217\u30c7\u30fc\u30bf\u3092\u6570\u5b57\u3078\u5909\u63db\n# \u4e88\u60f3\u3067\u4f7f\u3046\u9805\u76ee\u3067\u6587\u5b57\u5217\u3092\u5024\u3068\u3057\u3066\u6301\u3063\u3066\u3044\u308b\u30ab\u30e9\u30e0\u306f\u300cSex\u300d\u3068\u300cEmbarked\u300d\n# Sex\u306f\u300cmale\u300d\u300cfemale\u300d\u306e\uff12\u3064\u306e\u6587\u5b57\u5217\u5024\n# Embarked\u306f\u306f\u300cS\u300d\u300cC\u300d\u300cQ\u300d\u306e3\u3064\u306e\u6587\u5b57\u5217\u5024\u3000\u3053\u308c\u3089\u3092\u6570\u5b57\u306b\u5909\u63db\u3059\u308b\u3002\n\n# Sex\u306b\u3066male\u30920 female\u30921\u3000\u306b\u5909\u63db\ndf_train[\"Sex\"][df_train[\"Sex\"] == \"male\"] = 0\ndf_train[\"Sex\"][df_train[\"Sex\"] == \"female\"] = 1\n\n# Embarked\u306b\u3066S\u30920 C\u30921\u3000Q\u30922 \u306b\u5909\u63db\ndf_train[\"Embarked\"][df_train[\"Embarked\"] == \"S\" ] = 0\ndf_train[\"Embarked\"][df_train[\"Embarked\"] == \"C\" ] = 1\ndf_train[\"Embarked\"][df_train[\"Embarked\"] == \"Q\"] = 2\n\n# \u6700\u521d\u306e10\u884c\u3092\u898b\u3066\u5909\u63db\u3055\u308c\u305f\u304b\u3092\u78ba\u8a8d\ndf_train.head(10)","d3482389":"#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u304a\u3044\u3066\u3082\u540c\u69d8\u306b\u3001\u6b20\u640d\u30c7\u30fc\u30bf\u306e\u4e8b\u524d\u51e6\u7406\u3092\u884c\u3046\ndf_test[\"Age\"] = df_test[\"Age\"].fillna(df_test[\"Age\"].median())\ndf_test[\"Sex\"][df_test[\"Sex\"] == \"male\"] = 0\ndf_test[\"Sex\"][df_test[\"Sex\"] == \"female\"] = 1\ndf_test[\"Embarked\"][df_test[\"Embarked\"] == \"S\"] = 0\ndf_test[\"Embarked\"][df_test[\"Embarked\"] == \"C\"] = 1\ndf_test[\"Embarked\"][df_test[\"Embarked\"] == \"Q\"] = 2\n#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u306fFare\u304c\u4e00\u3064\u6b20\u640d\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u4e2d\u592e\u5024\u3092\u8a2d\u5b9a\u3059\u308b\ndf_test.Fare[152] = df_test.Fare.median()\n\n# \u6700\u521d\u306e10\u884c\u3092\u898b\u3066\u5909\u63db\u3055\u308c\u305f\u304b\u3092\u78ba\u8a8d\ndf_test.head(10)","862f7c3e":"# \u8aac\u660e\u5909\u6570\u3068\u3057\u3066\u306f\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"\u3092\u4f7f\u7528\u3059\u308b\nfeatures_col = [\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]\nfeatures = df_train[features_col].values\n# \u76ee\u7684\u5909\u6570\u3068\u3057\u3066\"Survived\"\u3092\u53d6\u5f97\ntarget = df_train[\"Survived\"].values","0dadd07c":"df_train[features_col]","45f45fa6":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u306e\u7bc4\u56f2\u3092\u6307\u5b9a\nparameters = {\n    \"n_estimators\":[i for i in range(10,100,10)],\n    \"learning_rate\":[10,1,0.1,0.01],\n    \"max_depth\":[i for i in range(1,5,1)],\n    \"random_state\":[3],\n}\n#\u4ea4\u5dee\u691c\u8a3c+\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u306b\u3088\u308a\u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u691c\u7d22\nclf = GridSearchCV(XGBClassifier(), parameters, cv=5)\nclf.fit(features, target)","674edd95":"print(\"\u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf: {}\".format(clf.best_params_))\nprint(\"\u6700\u826f\u4ea4\u5dee\u691c\u8a3c\u30b9\u30b3\u30a2: {:.2f}\".format(clf.best_score_))\n# \u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf: {'criterion': 'friedman_mse', 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_split': 2, 'random_state': 3}\n# \u6700\u826f\u4ea4\u5dee\u691c\u8a3c\u30b9\u30b3\u30a2: 0.83","be50abc4":"from xgboost import XGBClassifier\n# \u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u6539\u3081\u3066XGBClassifier\u306e\u4f5c\u6210\n# model = XGBClassifier(max_depth=3, learning_rate=1, n_estimators=40, random_state=3)\nmodel = XGBClassifier(max_depth=3, learning_rate=0.01, n_estimators=50, random_state=3)\n# \u4e88\u6e2c\u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u3055\u305b\u308b\nmodel.fit(features, target)\n# \u9069\u5408\u5177\u5408\u3092\u78ba\u8a8d 0.8316498316498316\nprint(\"\u8a13\u7df4\u30c7\u30fc\u30bf\u30b9\u30b3\u30a2:\",model.score(features,target))","f066f620":"# \u300ctest\u300d\u306e\u8aac\u660e\u5909\u6570\u306e\u5024\u3092\u53d6\u5f97\ntest_features = df_test[features_col].values\n# \u300cdf_test\u300d\u306e\u8aac\u660e\u5909\u6570\u3092\u4f7f\u3063\u3066\u300cmy_tree_one\u300d\u306e\u30e2\u30c7\u30eb\u3067\u4e88\u6e2c\nmy_prediction = model.predict(test_features)\n# \u4e88\u6e2c\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u3092\u78ba\u8a8d\nprint(\"my_prediction\u306e\u5927\u304d\u3055\uff1a\",my_prediction.shape)\n#\u4e88\u6e2c\u30c7\u30fc\u30bf\u306e\u4e2d\u8eab\u3092\u78ba\u8a8d\nprint(my_prediction)\n# \u2463\u4e88\u6e2c\u5024\u3092\u53d6\u5f97\u3057\u3066\u63d0\u51fa\u7528CSV\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\n# \u5143\u306e\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304b\u3089PassengerId\u3092\u53d6\u5f97\nPassengerId = np.array(df_test[\"PassengerId\"]).astype(int)\n# my_prediction(\u4e88\u6e2c\u30c7\u30fc\u30bf\uff09\u3068PassengerId\u3092\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3078\u843d\u3068\u3057\u8fbc\u3080\nmy_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n# submission.csv\u3068\u3057\u3066\u66f8\u304d\u51fa\u3057\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30e9\u30d9\u30eb\u3068\u3057\u3066PassengerId\u3092\u6307\u5b9a\nmy_solution.to_csv(\"result.csv\", index_label = [\"PassengerId\"])","84399687":"shap.initjs()\nexplainer = shap.TreeExplainer(model=model, feature_perturbation='feature_perturbation', model_output='margin')\n\nshap_values = explainer.shap_values(X=features)\nshap.summary_plot(shap_values, features)","3ddf728e":"# \u524d\u51e6\u7406"}}