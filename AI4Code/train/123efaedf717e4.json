{"cell_type":{"8b9bce0c":"code","b29f149b":"code","1fd48767":"code","47472e89":"code","8072c260":"code","e08c2d86":"code","0e1f0a72":"code","81ea1e02":"code","22d5b238":"code","957d0ae4":"code","90521c88":"code","5cfd8c93":"code","5f977de3":"code","ffe22535":"markdown","bc801fa2":"markdown","9ecff051":"markdown","8348b9e0":"markdown","6ccaef74":"markdown","628d15d7":"markdown","8a59e71a":"markdown","6d8e72f2":"markdown","2e884f5c":"markdown","94966674":"markdown","a4838f23":"markdown"},"source":{"8b9bce0c":"import numpy as np\nimport pandas as pd\nimport optuna\nimport os\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n#import the data\ntrain_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","b29f149b":"#set the train data\ny = train_data.SalePrice\nx = train_data.drop(columns=[\"SalePrice\",\"Id\"], axis=1)","1fd48767":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'most_frequent')\nimputer.fit(x)\nx_temp = imputer.transform(x)\nx = pd.DataFrame(x_temp, columns = x.columns).astype(x.dtypes.to_dict())\nx.info()","47472e89":"x_num = list(x.select_dtypes(exclude=object).columns)\nscaler = preprocessing.MinMaxScaler().fit(x[x_num])\nx[x_num] = scaler.transform(x[x_num])","8072c260":"x = pd.get_dummies(x)\nx = x.reindex(columns = x.columns, fill_value=0)\nx","e08c2d86":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.02, random_state=1)\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","0e1f0a72":"def create_model(para_layers, para_dense, para_dropout):\n    model = keras.Sequential()\n    \n    for i in range(para_layers):\n        model.add(layers.Dense(para_dense, activation='relu'))\n        model.add(layers.Dropout(para_dropout))\n    model.add(layers.Dense(1))\n    \n    return model","81ea1e02":"# try yourself removing comment tag\ndef objective(trial):\n    tf.random.set_seed(17)\n\n    #trials\n    epochs = trial.suggest_int('epochs',90,150)\n    batch_size = trial.suggest_int('batch_size',32,72)\n    n_layer = trial.suggest_int('n_layer', 3, 7)\n    dense = trial.suggest_int('dense', 256, 1024)\n    dropout = trial.suggest_uniform('dropout',0.3,0.8)\n    \n    #get the model\n    model = create_model(n_layer, dense, dropout)\n    \n    model.compile(\n        optimizer=\"adam\",\n        loss='mean_squared_logarithmic_error',\n        metrics=['mean_squared_logarithmic_error'],\n    )\n\n    #train\n    history = model.fit(\n        x_train, y_train,\n        batch_size = batch_size,\n        epochs = epochs,\n        validation_data=(x_val, y_val),\n        verbose=0\n    )\n\n    return np.sqrt(mean_squared_log_error(model.predict(x_val), y_val))\n\n# trial on parameter optimization\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=1000)\n\nprint(\"study.best_trial: {}\".format(study.best_trial))","22d5b238":"tf.random.set_seed(17)\n\n# directly get the best result from optuna result\nepochs = study.best_params['epochs']\nbatch_size = study.best_params['batch_size']\nn_layer = study.best_params['n_layer']\ndense = study.best_params['dense']\ndropout = study.best_params['dropout']\n\nmodel = create_model(n_layer, dense, dropout)\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss='mean_squared_logarithmic_error',\n    metrics=['mean_squared_logarithmic_error'],\n)\n\nhistory = model.fit(\n    x_train, y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(x_val, y_val),\n    verbose=0\n)\n\nmsle = np.sqrt(mean_squared_log_error(model.predict(x_val), y_val))\nprint(msle)","957d0ae4":"x_test = test_data.drop(columns=[\"Id\"], axis=1)\n\nimputer = SimpleImputer(strategy = 'most_frequent')\nimputer.fit(x_test)\nx_temp = imputer.transform(x_test)\nx_test = pd.DataFrame(x_temp, columns = x_test.columns).astype(x_test.dtypes.to_dict())\nx_test.info()","90521c88":"x_test[x_num] = scaler.transform(x_test[x_num])","5cfd8c93":"x_test = pd.get_dummies(x_test)\nx_test = x_test.reindex(columns = x.columns, fill_value=0)\nx_test","5f977de3":"preds = model.predict(x_test)\npreds_2 = [i[0] for i in preds]\nout = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': preds_2}) \nout.to_csv('submission.csv',index=False)","ffe22535":"## TEST DATA","bc801fa2":"deal with categories","9ecff051":"rescale with previous scaler","8348b9e0":"## IMPORT","6ccaef74":"Convert category to number","628d15d7":"rescaling","8a59e71a":"## MAKE THE MODEL and FIND THE PARAMETERS\nParameterize the model and find optimized parameters using bayesian optimization","6d8e72f2":"## Reference\nHouse Prices - Regression Techniques Submission  \nhttps:\/\/www.kaggle.com\/omkaarp\/house-prices-regression-techniques-submission\n\nHouse prices. Keras NN with data augmentation.  \nhttps:\/\/www.kaggle.com\/paveltrusov\/house-prices-keras-nn-with-data-augmentation","2e884f5c":"## SCALING THE DATA\nFill missing value with most_frequent strategy","94966674":"## MAKE SUBMISSION DATA","a4838f23":"Split data to training and validation"}}