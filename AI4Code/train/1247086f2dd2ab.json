{"cell_type":{"7d93032a":"code","eb98515a":"code","798002e5":"code","e812834a":"code","c0b176eb":"code","8bfb03f7":"code","2f9208dc":"code","37f11527":"code","857c146c":"code","21cc7e7a":"code","8502fd62":"code","a8656429":"code","1782a00b":"code","4ffc6e82":"code","47f5cfcd":"code","31768e17":"code","7722fdc0":"code","8989cf27":"code","84aafd36":"code","04b2b043":"code","bad25511":"code","45800006":"markdown","e00c8b6a":"markdown","79d466e9":"markdown","bf8a40c1":"markdown","a26a1121":"markdown","bea2c12b":"markdown","e9b5a04c":"markdown","f3b156fe":"markdown","2063c05d":"markdown","3c22b2d6":"markdown","d09c09eb":"markdown","c0e3d8a5":"markdown","804d5138":"markdown"},"source":{"7d93032a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (12,8)})\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# print(os.listdir(\"..\/input\"))","eb98515a":"# Load data as Pandas dataframe\ntrain = pd.read_csv('..\/input\/train.csv', )\ntest = pd.read_csv('..\/input\/test.csv')\ndf = pd.concat([train, test], axis=0, sort=True)","798002e5":"df.head()","e812834a":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n\n        \ndisplay_all(df.describe(include='all').T)","c0b176eb":"df['Survived'].value_counts()","8bfb03f7":"# create new Title column\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","2f9208dc":"df.head()","37f11527":"df['Title'].value_counts()","857c146c":"# replace rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndf.replace({'Title': mapping}, inplace=True)","21cc7e7a":"# confirm that we are left with just six values\ndf['Title'].value_counts()","8502fd62":"# impute missing Age values using median of Title groups\ntitle_ages = dict(df.groupby('Title')['Age'].median())\n\n# create a column of the average ages\ndf['age_med'] = df['Title'].apply(lambda x: title_ages[x])\n\n# replace all missing ages with the value in this column\ndf['Age'].fillna(df['age_med'], inplace=True, )\ndel df['age_med']","a8656429":"sns.barplot(x='Title', y='Age', data=df, estimator=np.median, ci=None, palette='Blues_d')\nplt.xticks(rotation=45)\nplt.show()","1782a00b":"sns.countplot(x='Title', data=df, palette='hls', hue='Survived')\nplt.xticks(rotation=45)\nplt.show()","4ffc6e82":"sns.swarmplot(x='Sex', y='Fare', hue='Survived', data=df)\nplt.show()","47f5cfcd":"# impute missing Fare values using median of Pclass groups\nclass_fares = dict(df.groupby('Pclass')['Fare'].median())\n\n# create a column of the average fares\ndf['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x])\n\n# replace all missing fares with the value in this column\ndf['Fare'].fillna(df['fare_med'], inplace=True, )\ndel df['fare_med']","31768e17":"sns.catplot(x='Embarked', y='Survived', data=df,\n            kind='bar', palette='muted', ci=None)\nplt.show()","7722fdc0":"df['Embarked'].fillna(method='backfill', inplace=True)","8989cf27":"# create Family_Size column (Parch +)\ndf['Family_Size'] = df['Parch'] + df['SibSp']","84aafd36":"display_all(df.describe(include='all').T)","04b2b043":"train = df[pd.notnull(df['Survived'])]\ntest = df[pd.isnull(df['Survived'])]","bad25511":"train.to_csv('train_clean.csv', index=False)\ntest.to_csv('test_clean.csv', index=False)","45800006":"<a id=\"fare\"><\/a>\n## 2.2. Impute missing fare values\nFor the single missing fare value, I also use the median fare value for the passenger's class.   \n\n> Perhaps you could come up with a cooler way of visualising the relationship between the price a passenger paid for their ticket and their chances of survival?","e00c8b6a":"# 4. Save cleaned version\nFinally, let's save our cleaned data set so we can use it in other notebooks.","79d466e9":"### Extract title from name\nWe can use a regular expression to extract the title from the `Name` column. We will do this by finding the adjacent letters that are immediately followed by a full stop.\n","bf8a40c1":"<a id=\"feature-engineering\"><\/a>\n# 3. Add family size column\nWe can use the two variables of **Parch** and **SibSp** to create a new variable called **Family_Size**. This is simply done by adding `Parch` and `SibSp` together.","a26a1121":"### Use median of title group\nNow, for each missing age value, we will impute the age using the median age for all people with the same title.","bea2c12b":"# Table of Contents:\n\n- **1. [Load Packages and Data](#loading)**\n- **2. [Imputation](#impute-missing)**\n  - **2.1. [Age](#age)**\n  - **2.1. [Fare](#fare)**\n  - **2.1. [Embarked](#embarked)**\n- **3. [Feature engineering](#feature-engineering)**","e9b5a04c":"<a id=\"impute-missing\"><\/a>\n# 2. Imputation \nWe can see above that there are a few columns with missing values. The `Cabin` column is missing over 1000 values, so we won't use that for predictions, but the `Age`, `Embarked` and `Fare` columns are all complete enough that we can fill in the missing values through imputation.   \n<a id=\"age\"><\/a>\n## 2.1. Impute missing age values\nA simple option for the missing age values is to use the median age value. Let's go a little further and use each passenger's *Title* to estimate their age. E.g. if a passenger has the title of *Dr*, I will give them the median age value for all other passengers with the same title.","f3b156fe":"# Titanic challenge part 1\nIn this notebook, we will be covering all of the steps required to wrangle the Titanic data set into a format that is suitable for machine learning.   \nWe will do each of the following:\n  - impute missing values\n  - create new features (feature engineering)\n  \n[**Part 2**](https:\/\/www.kaggle.com\/jamesleslie\/titanic-random-forest-grid-search) of this challenge involves fitting and tuning a **random forest** to make predictions.","2063c05d":"We can visualize the median ages for each title group. Below, we see that each title has a distinctly different median age. \n> **Note**: There is no risk in doing this after imputation, as the median of an age group has not been affected by our actions.","3c22b2d6":"<a id=\"loading\"><\/a>\n# 1. Load packages and data\nFirst step, as always, is to import the necessary Python packages and load the input data as a Pandas dataframe.\n\nI chose to combine the train and test set into one. Since we will have to impute some missing age and fare values, I prefer to do this across the entire dataset, rather than separately across train and test sets. ","d09c09eb":"<a id=\"embarked\"><\/a>\n## 2.3. Impute missing \"embarked\" value\nThere are also just two missing values in the `Embarked` column. Here we will just use the Pandas 'backfill' method.\n","c0e3d8a5":"### Use only the most common titles\nLet's take a look at the unique titles across all passengers:","804d5138":"As we can see above, there are quite a few different titles. However, many of these titles are just French versions of the more common English titles, e.g. Mme = Madame = Mrs.   \n\nWe will use the six most common titles, replacing all other titles with the most appropriate of these six."}}