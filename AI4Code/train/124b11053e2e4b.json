{"cell_type":{"ab0fd30b":"code","212d85db":"code","259902c0":"code","47472b1b":"code","6a25b10d":"code","1e48a426":"code","82ff7d30":"code","d2416fc1":"code","2c2180c2":"code","9692e16d":"code","f6290f6c":"code","84eba2b8":"code","8f9ce414":"code","6a60f19b":"code","e0e2ebe3":"code","f3aa42d5":"code","e0596d39":"code","a0923b85":"code","754f2235":"code","0fe4f72c":"code","4672368b":"code","901e0a18":"code","697a274d":"code","b25c4078":"code","b8682461":"code","4bbbb4ad":"code","9c581ae0":"code","8a911574":"code","d44f11da":"code","d991e73e":"code","eb8c74fb":"code","fe46ccba":"code","5c793892":"code","78ba4e89":"code","a79d368a":"code","ebf4c272":"code","e1b36b77":"code","167a7545":"code","588eaba1":"code","5d77da37":"code","c4cbc8d0":"code","7d1f3b58":"code","56e0e290":"code","917437c4":"code","1cd77bba":"code","448caf39":"code","3ef86d36":"code","2bca9d19":"code","337965fb":"code","58dfbca7":"markdown","b2ac5d88":"markdown","8fb01373":"markdown","eb823abc":"markdown","8c014878":"markdown","f13c8f02":"markdown","6a5901bd":"markdown","fafa2e69":"markdown","c4ee5d9b":"markdown","4d65f121":"markdown","d17fa886":"markdown","d3b194f4":"markdown","4d837ee3":"markdown","5f04dcf9":"markdown","d9ab2ad6":"markdown","6173f24d":"markdown","c59fa5aa":"markdown","98d2cddc":"markdown","60ccdd33":"markdown","5e10afc4":"markdown","274c27fa":"markdown","95cb775f":"markdown","f19e160c":"markdown","ecc5ce86":"markdown","b81f7ce7":"markdown","56ebeb70":"markdown"},"source":{"ab0fd30b":"import pandas as pd\nimport numpy as np\nimport missingno as msno","212d85db":"# Matplotlib for additional customization\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Seaborn for plotting and styling\nimport seaborn as sns","259902c0":"# Para reducir memoria de los datasets:\ndef reduce_memory(ds_tmp):\n    int_columns = ds_tmp.select_dtypes(include=[np.int16,np.int32,np.int64]).columns.tolist()\n    for col in int_columns:\n        ds_tmp[col] = pd.to_numeric(arg=ds_tmp[col], downcast='integer')\n\n    float_columns = ds_tmp.select_dtypes(include=[np.float64]).columns.tolist()\n    for col in float_columns:\n        ds_tmp[col] = pd.to_numeric(arg=ds_tmp[col], downcast='float')","47472b1b":"import os\nprint(os.listdir(\"..\/input\/sistema-recomendador-bbva-kfc\/\"))","6a25b10d":"data_base_trx = pd.read_csv(\"..\/input\/sistema-recomendador-bbva-kfc\/01dataBaseTrainTrxRec.csv\")\ndata_base_perfil = pd.read_csv(\"..\/input\/sistema-recomendador-bbva-kfc\/02dataBasePerfilRec.csv\")\nprint(\"data_base_trx:\",data_base_trx.shape)\nprint(\"data_base_perfil:\",data_base_perfil.shape)","1e48a426":"data_base_trx.head()","82ff7d30":"data_base_perfil.head()","d2416fc1":"data_base_trx.info()","2c2180c2":"data_base_perfil.info()","9692e16d":"# Agruparemos todos los consumos del a\u00f1o de los clientes por establecimiento\ncliEstab = data_base_trx.groupby(['codCliente','codEstab'], as_index=False ).agg({'ratingMonto':'sum'})\ndf_ratingMonto = cliEstab.copy()\ndf_ratingMonto.head(25)","f6290f6c":"df_ratingMonto.info()","84eba2b8":"reduce_memory(df_ratingMonto)\ndf_ratingMonto.info()","8f9ce414":"n_clie_ori = df_ratingMonto.codCliente.nunique()\nn_estab_ori = df_ratingMonto.codEstab.nunique()\n\nprint('Num de Clientes: '+ str(n_clie_ori))\nprint('Num de Establecimientos: '+str(n_estab_ori))","6a60f19b":"list_codEstab = df_ratingMonto.codEstab.value_counts().index.values\nlist_codEstab.sort()\nlist_codEstab = ['estab' + str(i) for i in list_codEstab ] # agregando el prefijo \"estab\" a cada codEstab\nlist_codEstab[0:10]","e0e2ebe3":"min_nClie_x_estab = 50 # valor elegido ad-hoc","f3aa42d5":"# Contamos el nro de clientes por Establecimiento\ncontadorRM_Est = df_ratingMonto.groupby(\"codEstab\")['codCliente'].count()\n# Identificamos los establecimientos que cumplen el nro m\u00ednimo de clientes\nEstab_selected = contadorRM_Est[contadorRM_Est >= min_nClie_x_estab].index.tolist()\nEstab_selected.sort()\nEstab_selected[:5]","e0596d39":"# Seleccionamos los registros con los establecimientos identificados: fx: \".isin()\"\ndf_ratingMonto = df_ratingMonto.loc[df_ratingMonto['codEstab'].isin(Estab_selected)]\ndf_ratingMonto.shape","a0923b85":"min_nEstab_x_clie = 20 # valor elegido ad-hoc","754f2235":"# Contamos el nro de establecimientos por Cliente\ncontadorRM_Clie = df_ratingMonto.groupby(\"codCliente\")['ratingMonto'].count()\n# Identificamos los clientes que cumplen el nro m\u00ednimo de establecimientos\nClie_selected = contadorRM_Clie[contadorRM_Clie >= min_nEstab_x_clie].index.tolist()\nClie_selected.sort()\nClie_selected[:5]","0fe4f72c":"# Seleccionamos los registros con los clientes identificados: fx: \".isin()\"\ndf_ratingMonto = df_ratingMonto.loc[df_ratingMonto['codCliente'].isin(Clie_selected)]\ndf_ratingMonto.shape","4672368b":"# **Tama\u00f1o de la base final:**\ndf_ratingMonto.shape","901e0a18":"print(\"Las dimensiones de Clientes y Establecimientos de la base final a trabajar el Sistemas de Recomendaci\u00f3n son:\")\nn_clie = df_ratingMonto.codCliente.nunique()\nn_estab = df_ratingMonto.codEstab.nunique()\n\nprint('Num de Clientes: '+ str(n_clie))\nprint('Num de Establecimientos: '+str(n_estab))","697a274d":"df_ratingMonto.head()","b25c4078":"list_codEstab = df_ratingMonto.codEstab.value_counts().index.values\nlist_codEstab.sort()\nprint(list_codEstab[0:10])\nlist_codEstab = ['estab' + str(i) for i in list_codEstab ] # agregando el prefijo \"estab\" a cada codEstab\nprint(list_codEstab[0:10])","b8682461":"from sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(df_ratingMonto, test_size=0.20, random_state = 99 ) # 20% Test\n\ntrain_data.reset_index(drop = True,inplace=True)\ntest_data.reset_index(drop = True,inplace=True)","4bbbb4ad":"#Creando la matrices cliente-establecimiento para el training y calcular las predicciones para el test\ntrain_data_matrix = np.zeros((n_clie_ori + 1, n_estab), dtype='float32')\ntrain_data_matrix.shape","9c581ae0":"# Seleccionamos \ntrain_data_matrix = pd.DataFrame(train_data_matrix, columns = list_codEstab).iloc[df_ratingMonto.codCliente.unique(),:]\ntrain_data_matrix.shape","8a911574":"from time import time\ntime_star = time()\n\nfor line in train_data.itertuples():\n    train_data_matrix.loc[line[1], \"estab\"+str(line[2])] = line[3]  \n    \ntime_end = time()\nprint (\"Time: \", np.round((time_end-time_star)\/60,1), \" minutes\")","d44f11da":"train_data_matrix.head(10)","d991e73e":"train_data_matrix.tail(10)","eb8c74fb":"train_data_matrix.info()","fe46ccba":"#Create two user-item matrices, testing\ntest_data_matrix = np.zeros((n_clie_ori + 1, n_estab), dtype='float32') \ntest_data_matrix.shape","5c793892":"test_data_matrix = pd.DataFrame(test_data_matrix, columns = list_codEstab).iloc[df_ratingMonto.codCliente.unique(),:]\ntest_data_matrix.shape","78ba4e89":"from time import time\ntime_star = time()\n\nfor line in test_data.itertuples():\n    test_data_matrix.loc[line[1], \"estab\"+str(line[2])] = line[3]  \n    \ntime_end = time()\nprint (\"Time: \", np.round((time_end-time_star)\/60,1), \" minutes\")","a79d368a":"test_data_matrix.head(10)","ebf4c272":"test_data_matrix.tail(10)","e1b36b77":"test_data_matrix.info()","167a7545":"# Funcion para extraer los establecimientos top por cliente","588eaba1":"def fx_estab_tops_xCliente(base_ratings, cod_cliente, n_tops = None):\n    \"Funcion para extraer los establecimientos top(de mayor a menor rating) de un cliente determinado.\"\n    if cod_cliente not in base_ratings.index.values:\n            print(\"Cliente No Encontrado\")\n            return(None)\n    else:\n        row_cliente = base_ratings.loc[cod_cliente,:]\n        row_cliente.fillna(0, inplace = True)\n        estab_of_cli = row_cliente.index[row_cliente.nonzero()].values\n        lista_estab_final = row_cliente[estab_of_cli].sort_values(ascending = False)\n        lista_estab_final = pd.DataFrame({'Estab': lista_estab_final.index.values, \n                                          'montoRating': lista_estab_final.values})\n        return(lista_estab_final.head(n_tops))","5d77da37":"fx_estab_tops_xCliente(base_ratings = test_data_matrix, cod_cliente = 99, n_tops = None)","c4cbc8d0":"from sklearn.metrics.pairwise import cosine_similarity\n\nfrom time import time\ntime_star = time()\n\nprint(\"Iniciando clie_similaridad \")\nclie_similaridad = cosine_similarity(X = train_data_matrix) # metric='cosine', 'euclidean'\nprint(\"Finaliz\u00f3 clie_similaridad \")\n\ntime_end = time()\nprint (\"Time: \", np.round((time_end-time_star)\/60,4), \" minutes\")\nprint(\"Dimensiones:\",clie_similaridad.shape)","7d1f3b58":"pd.DataFrame(clie_similaridad).head()","56e0e290":"from time import time\ntime_star = time()\n\nprint(\"Iniciando estab_similaridad \")\nestab_similaridad = cosine_similarity(X = train_data_matrix.T)\nprint(\"Finaliz\u00f3 estab_similaridad\")\n\ntime_end = time()\nprint (\"Time: \", np.round((time_end-time_star)\/60,4), \" minutes\")\nprint(\"Dimensiones:\",estab_similaridad.shape)","917437c4":"pd.DataFrame(estab_similaridad).head()","1cd77bba":"def predict(ratings, similaridad, type='clie'):\n    if type == 'clie':\n        mean_clie_rating = np.nanmean(ratings,axis=1)\n        #np.newaxis: crea una nueva dimensi\u00f3n al array (o matrix)\n        ratings = np.nan_to_num(ratings) # reemplazar nulos con ceros\n        ratings_diff = (ratings - mean_clie_rating[:, np.newaxis]) \n        pred = mean_clie_rating[:, np.newaxis] + similaridad.dot(ratings_diff)\/np.array([np.abs(similaridad).sum(axis=1)]).T\n    elif type == 'estab':\n        pred = ratings.dot(similaridad)\/np.array([np.abs(similaridad).sum(axis=1)])     \n    return pred","448caf39":"print(\"clie_based_prediccion...\")\nclie_prediccion = predict(train_data_matrix.values, clie_similaridad, type='clie')\nclie_prediccion = pd.DataFrame(clie_prediccion)\nclie_prediccion.index, clie_prediccion.columns = train_data_matrix.index, train_data_matrix.columns\nprint(\"fin clie_based_prediccion...\")","3ef86d36":"print(\"estab_based_prediccion...\")\nestab_prediccion = predict(train_data_matrix.values, estab_similaridad, type='estab')\nestab_prediccion = pd.DataFrame(estab_prediccion)\nestab_prediccion.index, estab_prediccion.columns = train_data_matrix.index, train_data_matrix.columns\nprint(\"fin estab_based_prediccion...\")","2bca9d19":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\ndef rmse(prediccion, ratings_true):\n    indexes_nonzeros = ratings_true.nonzero() # obtener los indices de los ratings reales (<> 0)\n    prediccion = prediccion[indexes_nonzeros].flatten() # flatten(): convierte la matriz en una sola dimension\n    ratings_true = ratings_true[indexes_nonzeros].flatten() # flatten(): convierte la matriz en una sola dimension\n    return sqrt(mean_squared_error(prediccion, ratings_true))","337965fb":"# Comparando ambas predicciones\nprint('clie-based CF RMSE: ' + str(rmse(clie_prediccion.values, test_data_matrix.values)))\nprint('estab-based CF RMSE: ' + str(rmse(estab_prediccion.values, test_data_matrix.values)))","58dfbca7":"### Predicciones","b2ac5d88":"# Sistema de Recomendaci\u00f3n","8fb01373":"clie-based CF RMSE: 0.025793318651065544\n\nestab-based CF RMSE: 0.0260687491041326","eb823abc":"1. Seleccionando establecimientos con almenos **\"min_nClie_x_estab\"** clientes en el a\u00f1o ...","8c014878":"### Data Testing","f13c8f02":"# 0. Importar Librerias","6a5901bd":"### Cosine Similarity:\nLa similitud de coseno es una medida de similitud entre dos vectores distintos de cero de un espacio de producto interno que mide el coseno del \u00e1ngulo entre ellos. Mientras m\u00e1s cercano sea a 1, son m\u00e1s similares.\n![](https:\/\/hsto.org\/files\/f73\/289\/979\/f732899792f246358649e89765cd88da.png)\nMayor informaci\u00f3n: \n* http:\/\/mlwiki.org\/index.php\/Cosine_Similarity\n* https:\/\/en.wikipedia.org\/wiki\/Cosine_similarity","fafa2e69":"# 2. Preparaci\u00f3n de los DFs iniciales","c4ee5d9b":"Creando el pre-listado de los establecimientos...","4d65f121":"## Evaluacion","d17fa886":"![](https:\/\/raw.githubusercontent.com\/KevenRFC\/wp-content\/master\/RecomenderSystem_01.PNG)","d3b194f4":"## Reducci\u00f3n de la base Cliente-Establecimientos","4d837ee3":"Dividiremos nuestro dataset en training y testing para poder evaluar internamente luego nuestro modelo y comparar los diferentes m\u00e9todos a utilizar","5f04dcf9":"* **Nuevas versiones ser\u00e1n actualizadas en este mismo kernel!**","d9ab2ad6":"## Matrices de Distancias","6173f24d":"Similaridad entre establecimientos...","c59fa5aa":"**Por temas de capacidad de memoria y procesamientos, seleccionaremos un subconjunto de establecimientos y clientes**","98d2cddc":"### Split Data: Training & Testing Dataset","60ccdd33":"### Calculando las predicciones:","5e10afc4":"Esto es solo una primera versi\u00f3n del Sistema de Recomendaci\u00f3n para el caso del BBVA Data Challenge.\nLa metodolog\u00eda a usar es Collaborative Filtering basado tanto en Cliente (user) y Establecimiento (item).\n\nLink: https:\/\/www.kaggle.com\/c\/bbvadatachallenge-recomendador\n\nPara este trabajo se tom\u00f3 como gu\u00eda la siguiente documentaci\u00f3n:\nhttp:\/\/www.mmds.org\/mmds\/v2.1\/ch09-recsys1.pdf","274c27fa":"Funcion **predict** que tiene como par\u00e1metro usar la matriz de similaridad basada en Clientes o Establecimientos:","95cb775f":"2. Seleccionando clientes con almenos **\"min_nEstab_x_clie\"** establecimientos en el a\u00f1o (en base al nuevo **df_ratingMonto**)...","f19e160c":"# 1. Carga de Datos","ecc5ce86":"Similaridad entre clientes ...","b81f7ce7":"### Data Training","56ebeb70":"**Creando el listado final de establecimientos:**"}}