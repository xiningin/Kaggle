{"cell_type":{"fec33467":"code","ed023af9":"code","6f939f66":"code","8d4eab39":"code","16c06b36":"code","2592e055":"code","886c3ce5":"code","71320906":"code","10be9edf":"code","6a348f9e":"code","a2c6a4b9":"code","89c4cf01":"code","aca7d56d":"code","4b38aa6f":"code","7dd6afa6":"code","b5fa8250":"markdown","8a880c66":"markdown","3b18df60":"markdown","e0c4d663":"markdown","bff1510f":"markdown"},"source":{"fec33467":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import *\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport cv2\nimport re\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ed023af9":"dataset_dir = '..\/input\/ranzcr-clip-catheter-line-classification\/'\ntrain_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n\ntrain_img = os.path.join(dataset_dir,'train')\ntrain_annotations_df = pd.read_csv(os.path.join(dataset_dir, 'train_annotations.csv'))","6f939f66":"train_df.head(5)","8d4eab39":"seed = 456\nbatch_size = 16\nnp.random.seed(seed)\ntf.random.set_seed(seed)","16c06b36":"img_size = 256\ntrain_tfr = os.path.join(dataset_dir, \"train_tfrecords\")\n\nautotune = tf.data.experimental.AUTOTUNE\n\nfeature_map = {\n        'ETT - Abnormal' : tf.io.FixedLenFeature([], tf.int64),\n        'ETT - Borderline' : tf.io.FixedLenFeature([], tf.int64),\n        'ETT - Normal' : tf.io.FixedLenFeature([], tf.int64),\n        \"NGT - Abnormal\" : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Borderline' : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Incompletely Imaged' : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Normal' : tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Abnormal' : tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Borderline': tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Normal': tf.io.FixedLenFeature([], tf.int64),\n        'StudyInstanceUID' : tf.io.FixedLenFeature([], tf.string),\n        'Swan Ganz Catheter Present' : tf.io.FixedLenFeature([], tf.int64),\n        'image' : tf.io.FixedLenFeature([], tf.string)\n    }","2592e055":"def read_tfrecords(example):\n    example = tf.io.parse_single_example(example, feature_map)\n    #decoding images\n    image = tf.image.decode_jpeg(example['image'])\n    #converting grayscale to rgb\n    image = tf.image.grayscale_to_rgb(image)\n    #resizing images\n    image = tf.image.resize(image, (img_size, img_size))\n    \n    if augmenter:\n        image = augment(image)\n    \n    image = image\/255\n    \n    features = tf.stack([\n        example['ETT - Abnormal'],\n        example['ETT - Borderline'],\n        example['ETT - Normal'],\n        example[\"NGT - Abnormal\"],\n        example['NGT - Borderline'],\n        example['NGT - Incompletely Imaged'],\n        example['NGT - Normal'],\n        example['CVC - Abnormal'],\n        example['CVC - Borderline'],\n        example['CVC - Normal'],\n        example['Swan Ganz Catheter Present']\n        ])\n    \n    \n    return image, features","886c3ce5":"import tensorflow_addons as tfa\n\ndef load_dataset(filenames, aug):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_tfrecords, num_parallel_calls = autotune)\n    \n    return tfrecords\n\ndef augment(image):\n    \n    decider = tf.random.uniform(shape = (1,1), minval = 0, maxval = 1)\n    \n    if decider > 0.5:\n        dx_dy = tf.random.uniform(shape = (1,2), minval = -20, maxval = 20)\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        image = tf.image.random_brightness(image, 0.5)\n        image = tf.image.random_contrast(image, 0.2, 0.5)\n\n        image = tfa.image.translate(image, dx_dy)\n\n    \n    return image\n\ndef class_func(images, label):\n    return label\n    \n    \ndef get_dataset(filenames, aug):\n    \n    global augmenter\n    \n    augmenter = aug\n\n    \n    ds = load_dataset(filenames,augmenter)\n    ds = ds.batch(batch_size)\n    #ds = ds.shuffle(512)\n    #ds = ds.cache()\n    ds = ds.repeat()\n    ds = ds.prefetch(autotune)\n    \n    return ds","71320906":"validation_split = 0.25\nTFR_fnames = tf.io.gfile.glob(train_tfr + '\/*.tfrec')\nTFR_fnames_train = TFR_fnames[int(len(TFR_fnames) * validation_split):]\nTFR_fnames_valid = TFR_fnames[:int(len(TFR_fnames) * validation_split)]","10be9edf":"train_dataset = get_dataset(TFR_fnames_train, True)\nvalid_dataset = get_dataset(TFR_fnames_valid, False)","6a348f9e":"def create_model(base_model):\n    inputs = tf.keras.Input(shape = (img_size, img_size, 3,))\n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n    outputs = tf.keras.layers.Dense(11, activation = 'sigmoid')(x)\n    \n    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n    \n    model.summary()\n    \n    optimizer = tf.keras.optimizers.Adam(9e-6)\n    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = [tf.keras.metrics.AUC(multi_label=True)])\n    \n    return model\n\nXception = Xception(include_top = False,\n                     weights = '..\/input\/keras-pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                    input_shape = (img_size, img_size, 3))\n\nXception.trainable  = True\n\nxception = create_model(Xception)","a2c6a4b9":"train_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_train))\nvalid_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_valid))\nprint(\"There are: \" + str(train_samples) + \" train samples and \" + str(valid_samples) + \" validation samples\")","89c4cf01":"epochs = 15\n\ncallbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_auc',\n                                              mode = 'max',\n                                             patience = 1  ,\n                                             restore_best_weights = True)]\n\nhistory = xception.fit(train_dataset, epochs = epochs,\n             validation_data = valid_dataset, \n              steps_per_epoch = 250,\n             validation_steps = 250, \n              callbacks = callbacks,\n             verbose = 1)","aca7d56d":"plt.rcParams.update({'font.size': 16})\nhist = pd.DataFrame(history.history)\nfig, (ax1, ax2) = plt.subplots(figsize=(12,12),nrows=2, ncols=1)\nhist['loss'].plot(ax=ax1,c='k',label='training loss')\nhist['val_loss'].plot(ax=ax1,c='r',linestyle='--', label='validation loss')\nax1.legend()\nhist['auc'].plot(ax=ax2,c='k',label='training AUC')\nhist['val_auc'].plot(ax=ax2,c='r',linestyle='--',label='validation AUC')\nax2.legend()\nplt.show()","4b38aa6f":"from sklearn.metrics import classification_report\n\n\ntest_dir = \"..\/input\/ranzcr-clip-catheter-line-classification\/test_tfrecords\"\nTFR_fnames_test = tf.io.gfile.glob(test_dir + '\/*.tfrec')\n\ntest_feature_map = {\n    \"StudyInstanceUID\" : tf.io.FixedLenFeature([], tf.string),\n    \"image\" : tf.io.FixedLenFeature([], tf.string)\n    }\n\ndef read_tfr(example):\n    \n    example = tf.io.parse_single_example(example, test_feature_map)\n    \n    image = tf.io.decode_jpeg(example['image'])\n    \n    image = tf.image.resize(image, (img_size,img_size))\n    \n    image = tf.image.grayscale_to_rgb(image)\n    \n    image = image \/ 255\n    \n    return image\n\n\n\ndef load_ds(filenames):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_tfr, num_parallel_calls = autotune)\n    \n    return tfrecords\n    \n    \ndef get_ds(filenames):\n    \n    ds = load_ds(filenames)\n    ds = ds.batch(4)\n    ds = ds.prefetch(autotune)\n    \n    return ds\n\ndef read_ids(example):\n    \n    example = tf.io.parse_single_example(example, test_feature_map)\n    ids = example['StudyInstanceUID']\n    \n    \n    return ids\n\ndef load_ds_ids(filenames):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_ids, num_parallel_calls = autotune)\n    \n    return tfrecords\n    \n    \ndef get_ds_ids(filenames):\n    \n    ds = load_ds_ids(filenames)\n    ds = ds.batch(test_samples)\n    ds = ds.prefetch(autotune)\n    \n    return ds\n\ntest_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_test))\ntest_ds = get_ds(TFR_fnames_test)\ntest_ids = get_ds_ids(TFR_fnames_test)\n\ny_preds = xception.predict(test_ds, batch_size=4)\n\nresults = pd.DataFrame(y_preds)","7dd6afa6":"ids = next(iter(test_ids)).numpy()\n\nfor i in range(ids.shape[0]):\n    ex = str(ids[i])\n    ex = ex[2:-1]\n    ids[i] = ex\nids = pd.Series(ids)\n\ncolumns = ['StudyInstanceUID', 'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n           \"NGT - Abnormal\", 'NGT - Borderline','NGT - Incompletely Imaged',\n           'NGT - Normal', 'CVC - Abnormal','CVC - Borderline',\n           'CVC - Normal','Swan Ganz Catheter Present']\n\nresults_df = pd.concat([ids, results], axis = 1)\nresults_df.columns = columns\nresults_df.to_csv('submission.csv', index = False)","b5fa8250":"# Xception\n\n**It is an Depthwise separable covolutions based pretrained model which was first proposed in 2017, more can be read from [here](https:\/\/arxiv.org\/pdf\/1610.02357.pdf)**\n","8a880c66":"# Plotting the Metrics","3b18df60":"# Submissions","e0c4d663":"# References\n1. https:\/\/www.kaggle.com\/tpothjuan\/efficientnetb7-resnet50-ensemble-tfrecords\n2. https:\/\/keras.io\/examples\/keras_recipes\/tfrecord\/\n3. https:\/\/arxiv.org\/abs\/1610.02357","bff1510f":"# Checking Data to be Trained"}}