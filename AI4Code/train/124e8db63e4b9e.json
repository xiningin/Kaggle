{"cell_type":{"df616c08":"code","690ed6fe":"code","36b7d92d":"code","1f23b058":"code","07445166":"code","7e351532":"code","c1f326ba":"code","c738cb8d":"code","e850ad57":"code","fc26aa9e":"code","a61942e5":"code","acc0d407":"code","a6103006":"code","b143380f":"code","df66ffd2":"code","be2ceee5":"code","84386c6e":"code","95406cba":"code","e1fa7273":"code","a5c81124":"code","df8bc633":"code","8c1af558":"code","e67ab23a":"code","b5e09906":"code","e2159711":"code","ad462c12":"markdown","13a9460a":"markdown","e97457e7":"markdown","ec8dcb19":"markdown","3440fcd6":"markdown","ff76db72":"markdown"},"source":{"df616c08":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport string\nfrom string import punctuation\nimport collections\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","690ed6fe":"data = pd.read_csv('\/kaggle\/input\/amazon-music-reviews\/Musical_instruments_reviews.csv')\ndata.head()","36b7d92d":"data.shape","1f23b058":"data = data.drop(['reviewerID', 'asin','reviewerName', 'unixReviewTime', 'helpful'], axis = 1)\ndata.head()","07445166":"data.isna().sum()","7e351532":"data['reviewText'].fillna('Null', inplace = True)\ndata.isna().any()","c1f326ba":"data['overall'].unique()","c738cb8d":"def rating(overall):\n    if (int(overall <= 3)):\n        return 0\n    else:\n        return 1\n        \ndata['rating'] = data['overall'].apply(rating)\ndata = data.drop(['overall'], axis = 1)\ndata.head()","e850ad57":"data.rating.unique()","fc26aa9e":"sns.countplot(data.rating)","a61942e5":"data['reviewText'] = data['reviewText'] + data['summary']\ndata = data.drop(['summary'], axis = 1)\ndata.head()","acc0d407":"x = pd.DataFrame(data['reviewText'])\ny = pd.DataFrame(data.rating)\ndata.reviewText = data.reviewText.astype('str')","a6103006":"nlp = spacy.load(\"en_core_web_sm\")\ntokenizer = RegexpTokenizer(r'\\w+')\nlemmatizer = WordNetLemmatizer()\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)\n\n            \ndef furnished(text):\n    final_text = []\n    for i in text.split():\n        if i.lower() not in stop:\n            word = lemmatizer.lemmatize(i)\n            final_text.append(word.lower())\n    return \" \".join(final_text)\n\n\n            \ndata.reviewText = data.reviewText.apply(furnished)","b143380f":"data.reviewText.describe()","df66ffd2":"for i in data.reviewText:\n    global text\n    text = i.split()\n    \ncounter=Counter(text)\nmost=counter.most_common()\n\nx, y= [], []\nfor word,count in most[:20]:\n    if (word not in stop):\n        x.append(word)\n        y.append(count)\nplt.figure(figsize = (10,10))     \nsns.barplot(x=y,y=x)","be2ceee5":"data.head()","84386c6e":"x_train,x_test,y_train,y_test = train_test_split(data.reviewText,data.rating,test_size = 0.2 , random_state = 0)","95406cba":"#bow\ncv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\nbow_x_train = cv.fit_transform(x_train)\nbow_x_test = cv.transform(x_test)\n\nprint('bow_x_train:',bow_x_train.shape)\nprint('bow_x_test:',bow_x_test.shape)","e1fa7273":"#tf-idf \ntv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n\ntfidf_x_train =tv.fit_transform(x_train)\ntfidf_x_test =tv.transform(x_test)\n\nprint('tfidf_x_train:',tfidf_x_train.shape)\nprint('tfidf_x_test:',tfidf_x_test.shape)\n","a5c81124":"#Naive Bayes\nnb = MultinomialNB()\n\n#fit\nbow = nb.fit(bow_x_train, y_train)\ntfidf = nb.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = nb.predict(bow_x_test)\ntfidf_predict = nb.predict(tfidf_x_test)\n\n#accuracy\nnb_bow = accuracy_score(y_test, bow_predict)\nnb_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('nb bow accuracy:', nb_bow)\nprint('tfidf accuracy:', nb_tfidf)","df8bc633":"#random forest\nrf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n\n#fit\nbow = rf.fit(bow_x_train, y_train)\ntfidf = rf.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = rf.predict(bow_x_test)\ntfidf_predict = rf.predict(tfidf_x_test)\n\n#accuracy\nrf_bow = accuracy_score(y_test, bow_predict)\nrf_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('rf bow accuracy:', rf_bow)\nprint('rf tfidf accuracy:', rf_tfidf)","8c1af558":"#Linear SVC\nls =  LinearSVC()\n\n#fit\nbow = ls.fit(bow_x_train, y_train)\ntfidf = ls.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = ls.predict(bow_x_test)\ntfidf_predict = ls.predict(tfidf_x_test)\n\n#accuracy\nls_bow = accuracy_score(y_test, bow_predict)\nls_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('ls bow accuracy:', ls_bow)\nprint('ls tfidf accuracy:', ls_tfidf)","e67ab23a":"#lr\nlr = LogisticRegression(random_state=0)\n\n#fit\nbow = lr.fit(bow_x_train, y_train)\ntfidf = lr.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = lr.predict(bow_x_test)\ntfidf_predict = lr.predict(tfidf_x_test)\n\n#accuracy\nlr_bow = accuracy_score(y_test, bow_predict)\nlr_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('lr bow accuracy:', lr_bow)\nprint('lr tfidf accuracy:', lr_tfidf)","b5e09906":"data = {'accuracy': [nb_bow * 100, nb_tfidf * 100, rf_bow * 100, rf_tfidf * 100, lr_bow * 100, lr_tfidf * 100, ls_tfidf * 100, ls_bow * 100],\n                   'model': ['naive bayes bow', 'naive bayes tfidf', 'random forest bow', 'random forest tfidf', \n                                'logit bow', 'logit tfidf', 'SVM bow', 'SVM tfidf']}\ndf = pd.DataFrame(data, columns = ['accuracy', 'model'])\ndf.head(8)","e2159711":"plt.figure(figsize = (17,7))\nsns.barplot(y = df.accuracy, x = df.model)","ad462c12":"Most of the reviews are good","13a9460a":"### Common words viz","e97457e7":"### Model Fitting, Prediction and accuracy","ec8dcb19":"### Good and Bad reviews viz","3440fcd6":"* removing stop words\n* removing punctuations\n* tokenization\n* lemmatization\n* bow\n* tf-idf ","ff76db72":"around the same accuracy of 89%"}}