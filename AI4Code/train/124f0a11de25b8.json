{"cell_type":{"23dbaaf1":"code","dce2fcbc":"code","96ecdc37":"code","e03111d6":"code","887ca572":"markdown","00c65e49":"markdown","5a07f843":"markdown","65728286":"markdown","c5e9bf5f":"markdown","50920981":"markdown","0c35cd6e":"markdown","15757cc6":"markdown","a1d6e9ae":"markdown","5c5532a3":"markdown","09e662fd":"markdown","4a0d43b2":"markdown"},"source":{"23dbaaf1":"import cv2\nimport matplotlib.pyplot as plt","dce2fcbc":"cam = cv2.VideoCapture(0)","96ecdc37":"detector=cv2.CascadeClassifier('..\/input\/haarcascade\/haarcascade_frontalface_default.xml')","e03111d6":"Id=input('enter your ID')\nsampleNum=0\nwhile(True):\n    ret, img = cam.read()\n    #converting RGB image to grayscale\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    #now we call our classifier(detector)\n    faces = detector.detectMultiScale(gray, 1.3, 5)\n    \n    for (x,y,w,h) in faces:\n        #plotting rectangle around the face\n        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n        \n        #saving the captured face in the dataset folder\n        cv2.imwrite(\"dataset\/User.\"+Id +'.'+ str(sampleNum) + \".jpg\", gray[y:y+h,x:x+w])\n        sampleNum=sampleNum+1\n        \n        plt.imshow('frame',img)\n        \n        #cv2.imshow does not work on kaggle, you can use this line while operating on other IDEs like google colab.\n        cv2.imshow('frame',img)\n        \n    # break if the sample number is morethan 20\n    if sampleNum>20:\n        break\ncam.release()\ncv2.destroyAllWindows()","887ca572":"**cv2.CascadeClassifier()** function is used to point to the location of the xml file.","00c65e49":"Reference taken from [HERE](https:\/\/www.youtube.com\/watch?v=gksXyp3J-Ho&list=PLyOoBDpzMQO6Qj3GrEKEuacsSCCPxabis&index=6&t=443s)\n\n\n[REFERENCE 2](https:\/\/medium.com\/@mrdatainsight\/how-to-use-opencv-imshow-in-a-jupyter-notebook-quick-tip-ce83fa32b5ad#:~:text=For%20those%20of%20you%20who,your%20code%20interactively%20using%20notebooks.)","5a07f843":"**cv2.VideoCapture()** function is used to capture video from webcam. Webcam access is not allowed in kaggle notebooks so you can try this on other python idles( maybe google colab or other IDEs)","65728286":"Here haarcascade_frontalface_default.xml is used for face detection and then capturing the images in grayscale.","c5e9bf5f":"**NOTE:** It doesn't matter what ID you take, but you must remember which ID is for which face.","50920981":"The code cell below won't operate on kaggle, I've implemented the whole code on local IDE, and I've posted it here for sharing purposes. ","0c35cd6e":"## This is how with just a few lines of code you can store face data superfast and then train your own facial recognition model.","15757cc6":"This is implemented using Haar Cascade Classifer. Haar Cascade classifier is an effective object detection approach which was proposed by Paul Viola and Michael Jones in their paper, \u201cRapid Object Detection using a Boosted Cascade of Simple Features\u201d in 2001. In Haar Cascade Classifiers there are huge individual .xml files with a lot of feature sets and each xml corresponds to a very specific type of use case.\n\nCascade classifier is an approach where a cascade function is trained from a lot of images both positive and negative.","a1d6e9ae":"## Model creation after collecting data as per this notebook : https:\/\/www.kaggle.com\/nandinibagga\/face-recognition-model-opencv-lbph","5c5532a3":"* Here first you are asked to enter the ID. This is to make sure that every face has a specific ID associated to it so that you can create supervised learning model on labelled data.\n\n* Then there is a while loop, which runs and saves 20 pictures of a face taken from your webcam in grayscale.(I have set it here to be 20, you can change it as per your choice)\n\n* ret, img = cam.read() - Reading (cam.read()) from a VideoCapture returns a tuple (return value, image). With the first item you check wether the reading was successful, and if it was then you proceed to use the returned image img. (cam.read() doesn't work on kaggle)\n\n* Then we convert RGB image to gray scale which makes it easier for detection.\n\n* Then we call our classifier(detector) and we call the **detectMultiScale()** function which is used to detect faces of different sizes in the image. Here we have set three parameters:\n                1. image : Matrix of the type CV_8U containing an image where objects are detected.\n                2. scaleFactor : Parameter specifying how much the image size is reduced at each image scale. This scale factor is used to create scale pyramid as shown in the picture. Suppose, the scale factor is 1.03, it means we're using a small step for resizing, i.e. reduce size by 3 %, we increase the chance of a matching size with the model for detection is found, while it's expensive.\n                3. minNeighbors : Parameter specifying how many neighbors each candidate rectangle should have to retain it. This parameter will affect the quality of the detected faces: higher value results in less detections but with higher quality. We're using 5 in the code.\ncheck here for reference: [REFERENCE1](https:\/\/www.bogotobogo.com\/python\/OpenCV_Python\/python_opencv3_Image_Object_Detection_Face_Detection_Haar_Cascade_Classifiers.php)\n* detector.detectMultiScale(gray, 1.3, 5) - This line will capture all the faces that it sees in the image and create a rectangle around the faces and then stores the x-coordinate, y-coordinate, width(w) and height(h) of the detected feature of the face. \n\n\n* ![image.png](attachment:f4eebf52-74dc-4dc1-a64c-d154c40206e5.png) This is how the coordinates of the image are stored on detection.\n\n* The above data is used to create a rectangle aroung the face.\n\n* Finally, using cv2.imwrite() we store the images in dataset folder. Inside this folder the mages will be stored as User.\"Id\".\"samplenum\".jpg. We are saving the cropped image by slicing the gray[] array and keeping the only rows and columns in which the face is deetcted.\n\n* Lastly, I am taking 20 photos per ID, but you can change it as per your preference.\n\n* Then we close the camera and destroy all the windows.","09e662fd":"# Simplest way to take data for training Facial Recognition model.","4a0d43b2":"Before implementing the code **make sure you have, opencv-contrib-python library installed**. \n*pip install opencv-contrib-python*\n"}}