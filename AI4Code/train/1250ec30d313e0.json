{"cell_type":{"557e080c":"code","98b3b3d8":"code","85ecd3b6":"code","6bfc135f":"code","96202677":"code","3792bcc6":"code","6c717ea4":"code","04f08f1e":"code","76108065":"code","d0d66d3b":"code","df13e51b":"code","48a814a3":"code","fcea2967":"code","b4cc6a7a":"code","8ac534f9":"code","434cfcc5":"code","427ef16a":"code","35def655":"code","1335cba9":"code","905e4662":"code","d5e4e352":"code","755a6f64":"code","3dd951f9":"code","7dca25df":"code","eb97dcb9":"code","3f549a54":"code","10e6d303":"code","9978219f":"code","c3e8ad15":"code","44b664c7":"code","09bde272":"code","c1ac8b41":"code","7936223a":"code","7cb60514":"code","d3f67594":"code","c31f577e":"code","ba4ebf3a":"code","519b6e74":"code","20911cbf":"code","7fd52d86":"code","3e07025b":"code","caed5a7e":"code","a5f5fa3e":"code","d0717eb8":"code","bdcf348e":"code","325780d2":"code","7b0755d7":"code","29d6d23c":"code","5954be0e":"code","c5968677":"code","216aa3f5":"code","3373a048":"code","41f80d96":"markdown","a0c2a76f":"markdown","694dfdb8":"markdown","f75a29cf":"markdown","e1857c69":"markdown","944109de":"markdown","d72f0ed2":"markdown","7bb812f0":"markdown","42ade037":"markdown"},"source":{"557e080c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98b3b3d8":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(train_data.shape)\nprint(test_data.shape)","85ecd3b6":"full_data = pd.concat([train_data, test_data], axis = 0, sort = False)\nprint(full_data.shape)\nfull_data.head()","6bfc135f":"def missing_data(df):\n    missing_values = df.isnull().sum().sort_values(ascending = False)\n    missing_values_df = pd.DataFrame(missing_values[missing_values>0])\n    \n    missing_percent = missing_values\/len(df) * 100\n    missing_percent_df = pd.DataFrame(missing_percent[missing_percent>0])\n\n    missing_df =  pd.concat([missing_values_df,missing_percent_df],axis = 1)\n    missing_df.columns = ['missing_counts','missing_percent']\n    \n    return missing_df","96202677":"def df_info(df):\n    data_type = pd.DataFrame(df.dtypes,columns = ['data_type'])\n    data_type['count_unique_values'] = [df[col].nunique() for col in df.columns]\n    data_type['unique_values_examples10'] = [df[col].unique()[0:10] for col in df.columns]\n    return data_type","3792bcc6":"#visual representation of missing values\nsns.heatmap(full_data.isnull(), cbar = False)","6c717ea4":"missing_data(full_data)","04f08f1e":"df_info(full_data)","76108065":"full_data.describe()","d0d66d3b":"# Drop the column Cabin as more 77% of the data is absent \nfull_data.drop(['Cabin','Name','Ticket'], axis=1, inplace = True)","df13e51b":"#handle missing values \nfull_data.Age = full_data.Age.fillna(int(full_data.Age.mean()))\nfull_data['Embarked'] = full_data['Embarked'].fillna(full_data['Embarked'].mode()[0])\nfull_data['Fare'] = full_data['Fare'].fillna(full_data['Fare'].mean())","48a814a3":"missing_data(full_data)","fcea2967":"#function to find categorical and numeric columns\ndef catnum_cols(df):\n    cat_cols = df[df['data_type']=='object'].index\n    num_cols = df[df['data_type']!='object'].index\n    return num_cols, cat_cols","b4cc6a7a":"dfinfo = df_info(full_data)\nnumcols,catcols = catnum_cols(dfinfo)","8ac534f9":"numcols,catcols","434cfcc5":"numcols = numcols.drop(['PassengerId', 'Survived'])\nnumcols\ncatcols","427ef16a":"cat_to_num = pd.get_dummies(full_data[catcols], drop_first = True)\ncat_to_num.head()","35def655":"full_data = pd.concat([full_data,cat_to_num], axis =1)\nfull_data.drop(catcols, axis=1, inplace = True)\nfull_data.head()","1335cba9":"train = full_data[:891].copy()\ntest = full_data[891:].copy()\ntest.drop('Survived', axis=1, inplace = True)\nprint(train.shape)\nprint(test.shape)","905e4662":"sns.heatmap(train.corr(), annot= True)","d5e4e352":"y_train = train['Survived']\nX_train = train.drop(['Survived','PassengerId'], axis = 1)","755a6f64":"X_train.head()","3dd951f9":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[numcols] = scaler.fit_transform(X_train[numcols])\nX_train.head()","7dca25df":"X_train.corr()","eb97dcb9":"import statsmodels.api as sm\ncols = X_train.columns\ncols","3f549a54":"cols = cols.drop(['Embarked_Q','Fare','Parch'])\ncols","10e6d303":"X_train_sm = sm.add_constant(X_train[cols])\nlogm = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\nres = logm.fit()\nres.summary()","9978219f":"from statsmodels.stats.outliers_influence import variance_inflation_factor","c3e8ad15":"vif = pd.DataFrame()\nvif['Features'] = X_train[cols].columns\nvif['VIF'] = [variance_inflation_factor(X_train[cols].values, i) for i in range(X_train[cols].shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","44b664c7":"y_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","09bde272":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred.shape","c1ac8b41":"y_train_pred_final = pd.DataFrame({'Survived' : y_train.values, 'SurvivedProb' : y_train_pred})\ny_train_pred_final['PassID'] = y_train.index\ny_train_pred_final.head()","7936223a":"y_train_pred_final['SurvivedPred'] = y_train_pred_final.SurvivedProb.map(lambda x : 1 if x>0.5 else 0)\ny_train_pred_final.head()","7cb60514":"from sklearn import metrics","d3f67594":"confusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.SurvivedPred)\nprint(confusion)","c31f577e":"print(metrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.SurvivedPred))","ba4ebf3a":"TP = confusion[1,1] #True Positives\nTN = confusion[0,0] #True Negatives\nFP = confusion[0,1] #False Positives\nFN = confusion[1,0] #False Negatives","519b6e74":"#sensitivity \nprint(TP \/ float(TP+FN))\n\n#specificity\nprint(TN\/ float(TN+FP))\n\n#false positives\nprint(FP\/ float(TN+FP))","20911cbf":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","7fd52d86":"draw_roc(y_train_pred_final.Survived, y_train_pred_final.SurvivedProb)","3e07025b":"numbers = [float(x)\/10 for x in range(10)]\nfor i in numbers :\n    y_train_pred_final[i] = y_train_pred_final.SurvivedProb.map(lambda x : 1 if x>i else 0)\ny_train_pred_final.head()","caed5a7e":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","a5f5fa3e":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","d0717eb8":"y_train_pred_final['final_SurvivedPred'] = y_train_pred_final.SurvivedProb.map( lambda x: 1 if x > 0.6 else 0)\n\ny_train_pred_final.head()","bdcf348e":"X_test = test.drop('PassengerId', axis = 1)\nX_test.head()","325780d2":"X_test[numcols] = scaler.transform(X_test[numcols])\nX_test.head()","7b0755d7":"X_test_sm = sm.add_constant(X_test[cols])\nX_test_sm.head()","29d6d23c":"y_test_pred = res.predict(X_test_sm)\ny_test_pred.head()","5954be0e":"y_test_pred_df = pd.DataFrame()\ny_test_pred_df['PassengerId'] = test['PassengerId']\ny_test_pred_df['Survived_pred'] = y_test_pred","c5968677":"y_test_pred_df['Survived'] = y_test_pred_df.Survived_pred.map(lambda x : 1 if x>0.6 else 0)\ny_test_pred_df.head()","216aa3f5":"y_test_pred_final = y_test_pred_df.drop('Survived_pred', axis = 1)\ny_test_pred_final.head()","3373a048":"y_test_pred_final.to_csv('submission.csv', index = False)","41f80d96":"Based on the business requirement you can choose the cut-off value corresponding to the best accuracy\/sensitivity\/specificity.\nHere we are more concerned about the best accuracy and so I have choosen 0.6","a0c2a76f":"Concatenating the train and test dataset to perform operations on the whole dataset. Also it will help us capture all the unique values of feature while performing one-hot encoding.","694dfdb8":"Creating a function which will provide you with the data type, count of unique values and some sample unique values of each column","f75a29cf":"Creating a function which gives you the count and percentage of missing values in each column","e1857c69":"### ROC Curve","944109de":"## Train Data","d72f0ed2":"## Build the Model","7bb812f0":"## Data Preparation ","42ade037":"## Test Data"}}