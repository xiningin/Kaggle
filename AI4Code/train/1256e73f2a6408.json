{"cell_type":{"04d1e5a7":"code","20f0127e":"code","d7a53aa1":"code","01698129":"code","4c57408e":"code","ea7182dd":"code","56bb7136":"code","d249e601":"code","c564ca19":"code","45473246":"code","b54ade1e":"code","cbb9ca39":"code","141ebe52":"code","f5d38541":"code","59635335":"code","e44c3753":"code","1e8b21eb":"code","960a15ed":"code","beb35cdb":"code","e5c86f68":"code","dd532fc2":"code","7045ff67":"code","8c0d2c64":"code","c2af6221":"code","5c4f51e5":"code","09b21dc4":"code","5f59f60a":"code","1390912b":"code","c450ea5c":"code","f79213e0":"code","c9ed381e":"code","878b58b5":"code","1ca563c6":"markdown","febafbed":"markdown","d0e97b28":"markdown","dd2ae85b":"markdown","26f65657":"markdown","48b8c65f":"markdown","1a7f3a15":"markdown","0f283b17":"markdown","47fd8b23":"markdown","85bbb19b":"markdown"},"source":{"04d1e5a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt #visualization\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20f0127e":"df = pd.read_csv('..\/input\/epitope-prediction\/input_sars.csv', encoding='ISO-8859-2')\ndf.head()","d7a53aa1":"df1 = pd.read_csv('..\/input\/ai4all-project\/results\/deconvolution\/CIBERSORTx_Results_Krasnow_facs_droplet.csv', encoding='ISO-8859-2')\ndf1.head()","01698129":"sns.countplot(x=\"B cell\",data=df1,palette=\"flag\",edgecolor=\"black\")\nplt.title('B cell', weight='bold')\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\n# changing the font size\nsns.set(font_scale=1)","4c57408e":"# checking dataset\n\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","ea7182dd":"# Distribution of different type of amount\nfig , ax = plt.subplots(1,3,figsize = (12,5))\n\nstart_position = df.start_position.values\nend_position = df.end_position.values\ntarget = df.target.values\n\nsns.distplot(start_position , ax = ax[0] , color = 'blue').set_title('B Cell Start Position' , fontsize = 14)\nsns.distplot(end_position , ax = ax[1] , color = 'cyan').set_title('B Cell End Position' , fontsize = 14)\nsns.distplot(target , ax = ax[2] , color = 'purple').set_title('B Cell Target' , fontsize = 14)\n\n\nplt.show()","56bb7136":"import matplotlib.gridspec as gridspec\nfrom scipy.stats import skew\nfrom sklearn.preprocessing import RobustScaler,MinMaxScaler\nfrom scipy import stats\nimport matplotlib.style as style\nstyle.use('seaborn-colorblind')","d249e601":"def plotting_3_chart(df, feature): \n    ## Creating a customized chart. and giving in figsize and everything. \n    fig = plt.figure(constrained_layout=True, figsize=(10,6))\n    ## crea,ting a grid of 3 cols and 3 rows. \n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n    #gs = fig3.add_gridspec(3, 3)\n\n    ## Customizing the histogram grid. \n    ax1 = fig.add_subplot(grid[0, :2])\n    ## Set the title. \n    ax1.set_title('Histogram')\n    ## plot the histogram. \n    sns.distplot(df.loc[:,feature], norm_hist=True, ax = ax1)\n\n    # customizing the QQ_plot. \n    ax2 = fig.add_subplot(grid[1, :2])\n    ## Set the title. \n    ax2.set_title('QQ_plot')\n    ## Plotting the QQ_Plot. \n    stats.probplot(df.loc[:,feature], plot = ax2)\n\n    ## Customizing the Box Plot. \n    ax3 = fig.add_subplot(grid[:, 2])\n    ## Set title. \n    ax3.set_title('Box Plot')\n    ## Plotting the box plot. \n    sns.boxplot(df.loc[:,feature], orient='v', ax = ax3 );\n \n\nprint('Skewness: '+ str(df['target'].skew())) \nprint(\"Kurtosis: \" + str(df['target'].kurt()))\nplotting_3_chart(df, 'target')","c564ca19":"train_heat=df[df[\"target\"].notnull()]\ntrain_heat=train_heat.drop([\"target\"],axis=1)\nstyle.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (10,8))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train_heat.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(train_heat.corr(), \n            cmap=sns.diverging_palette(255, 133, l=60, n=7), \n            mask = mask, \n            annot=True, \n            center = 0, \n           );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 30);","45473246":"fig = px.bar(df, \n             x='kolaskar_tongaonkar', y='isoelectric_point', color_discrete_sequence=['#2B3A67'],\n             title='Kolaskar and Tongaonkar antigenicity scale', text='end_position')\nfig.show()","b54ade1e":"fig = px.bar(df, \n             x='kolaskar_tongaonkar', y='hydrophobicity', color_discrete_sequence=['crimson'],\n             title='Kolaskar and Tongaonkar antigenicity scale', text='end_position')\nfig.show()","cbb9ca39":"ax = df.groupby('kolaskar_tongaonkar')['end_position'].mean().plot(kind='barh', figsize=(12,8),\n                                                           title='Mean estimated Kolaskar Tongaonkar')\nplt.xlabel('Mean estimated Kolaskar Tongaonkar scale')\nplt.ylabel('2018')\nplt.show()","141ebe52":"fig = px.bar(df, \n             x='chou_fasman', y='stability', color_discrete_sequence=['orange'],\n             title='Chou & Fasman Beta Turn Prediction', text='end_position')\nfig.show()","f5d38541":"from category_encoders import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\ncols_selected = ['chou_fasman']\nohe = OneHotEncoder(cols=cols_selected, use_cat_names=True)\ndf_t = ohe.fit_transform(df[cols_selected+['end_position']])\n\n#scaler = MaxAbsScaler()\nX = df_t.iloc[:,:-1]\ny = df_t.iloc[:, -1].fillna(df_t.iloc[:, -1].mean()) \/ df_t.iloc[:, -1].max()\n\nmdl = Ridge(alpha=0.1)\nmdl.fit(X,y)\n\npd.Series(mdl.coef_, index=X.columns).sort_values().head(10).plot.barh()","59635335":"fig = px.bar(df, \n             x='hydrophobicity', y='parker', color_discrete_sequence=['darkgreen'],\n             title='Parker Hydrophilicity Prediction', text='end_position')\nfig.show()","e44c3753":"ax = df.groupby('parker')['end_position'].min().sort_values(ascending=True).plot(kind='barh', figsize=(12,8), color='r',\n                                                                                  title='Min.estimated Parker Prediction')\nplt.xlabel('Min.estimated Parker Prediction')\nplt.ylabel('End Position')\nplt.show()","1e8b21eb":"fig = px.bar(df, \n             x='aromaticity', y='emini', color_discrete_sequence=['purple'],\n             title='Emini surface accessibility scale', text='end_position')\nfig.show()","960a15ed":"def plot_emini(col, df, title):\n    fig, ax = plt.subplots(figsize=(18,6))\n    df.groupby(['emini'])[col].sum().plot(rot=45, kind='bar', ax=ax, legend=True, cmap='bone')\n    ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n    ax.set(Title=title, xlabel='Emini')\n    return ax","beb35cdb":"plot_emini('isoelectric_point', df, 'B Cell Emini Scale');","e5c86f68":"ax = df.groupby('parker')['stability', 'hydrophobicity'].sum().plot(kind='bar', rot=45, figsize=(12,6), logy=True,\n                                                                 title='Parker Scale')\nplt.xlabel('Parker Scale')\nplt.ylabel('Stability & Hydrophilicity')\n\nplt.show()","dd532fc2":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split","7045ff67":"#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","8c0d2c64":"from sklearn.model_selection import train_test_split\n# Hot-Encode Categorical features\ndf = pd.get_dummies(df) \n\n# Splitting dataset back into X and test data\nX = df[:len(df)]\ntest = df[len(df):]\n\nX.shape","c2af6221":"# Save target value for later\ny = df.target.values\n\n# In order to make imputing easier, we combine train and test data\ndf.drop(['target'], axis=1, inplace=True)\ndf = pd.concat((df, test)).reset_index(drop=True)","5c4f51e5":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=0)","09b21dc4":"from sklearn.model_selection import KFold\n# Indicate number of folds for cross validation\nkfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Parameters for models\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]","5f59f60a":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LassoCV\n# Lasso Model\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas = alphas2, random_state = 42, cv=kfolds))\n\n# Printing Lasso Score with Cross-Validation\nlasso_score = cross_val_score(lasso, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlasso_rmse = np.sqrt(-lasso_score.mean())\nprint(\"LASSO RMSE: \", lasso_rmse)\nprint(\"LASSO STD: \", lasso_score.std())","1390912b":"# Training Model for later\nlasso.fit(X_train, y_train)","c450ea5c":"from PIL import Image\nim = Image.open(\"..\/input\/ai4all-project\/figures\/classifier\/lassoRandomForest_5gene_roc.png\")\n#tlabel = np.asarray(Image.open(\"..\/input\/train_label\/170908_061523257_Camera_5_instanceIds.png\")) \/\/ 1000\n#tlabel[tlabel != 0] = 255\n# plt.imshow(Image.blend(im, Image.fromarray(tlabel).convert('RGB'), alpha=0.4))\nplt.imshow(im)\ndisplay(plt.show())","f79213e0":"#plt.style.use('dark_background')\ndef plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set2')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()","c9ed381e":"plot_count(\"start_position\", \"start_position\", df,4)","878b58b5":"plt.style.use('dark_background')\nplot_count(\"end_position\", \"end_position\", df,4)","1ca563c6":"#Other Scales in the Tutorial, though they aren't in this file.\n\nKarplus and Schulz flexibility scale\nReference: Karplus PA, Schulz GE. Prediction of Chain Flexibility in Proteins - A tool for the Selection of Peptide Antigens. Naturwissenschafren 1985; 72:212-3.\nDescription: In this method, flexibility scale based on mobility of protein segments on the basis of the known temperature B factors of the a-carbons of 31 proteins of known structure was constructed. The calculation based on a flexibility scale is similar to classical calculation, except that the center is the first amino acid of the six amino acids window length, and there are three scales for describing flexibility instead of a single one.\n\nBepipred-1.0 Linear Epitope Prediction\nReference: Jens Erik Pontoppidan Larsen, Ole Lund and Morten Nielsen. Improved method for predicting linear B-cell epitopes. Immunome Res. 2006; 2: 2..\nDescription: BepiPred predicts the location of linear B-cell epitopes using a combination of a hidden Markov model and a propensity scale method. The residues with scores above the threshold (default value is 0.35) are predicted to be part of an epitope and colored in yellow on the graph (where Y-axes depicts residue scores and X-axes residue positions in the sequence) and marked with \"E\" in the output table. The\u00cavalues\u00caof the scores are not affected by the selected threshold. The table below shows the relationship between selected thresholds and the sensitivity\/specificity of the prediction method, calculated on basis of the epitope\/non-epitope predictions. The table is based on a large benchmark calculation containing close to 85 B cell epitopes.\n\nBepiPred-2.0: Sequential B-Cell Epitope Predictor\nReference: Jespersen MC, Peters B, Nielsen M, Marcatili P. BepiPred-2.0: improving sequence-based B-cell epitope prediction using conformational epitopes. Nucleic Acids Res 2017.\nThe BepiPred-2.0 server predicts B-cell epitopes from a protein sequence, using a Random Forest algorithm trained on epitopes and non-epitope amino acids determined from crystal structures. A sequential prediction smoothing is performed afterwards. The residues with scores above the threshold (default value is 0.5) are predicted to be part of an epitope and colored in yellow on the graph (where Y-axes depicts residue scores and X-axes residue positions in the sequence) and marked with \"E\" in the output table. The\u00cavalues\u00caof the scores are not affected by the selected threshold. The table below shows the relationship between selected thresholds and the sensitivity\/specificity of the prediction method. http:\/\/tools.iedb.org\/bcell\/help\/","febafbed":"##Kolaskar and Tongaonkar antigenicity scale\n\nReference: Kolaskar AS, Tongaonkar PC. A semi-empirical method for prediction of antigenic determinants on protein antigens. FEBS Lett. 1990 Dec 10;276(1-2):172-4. Description: A semi-empirical method which makes use of physicochemical properties of amino acid residues and their frequencies of occurrence in experimentally known segmental epitopes was developed to predict antigenic determinants on proteins. Application of this method to a large number of proteins has shown by the authors that the method can predict antigenic determinants with about 75% accuracy which is better than most of the known methods http:\/\/tools.iedb.org\/bcell\/help\/","d0e97b28":"#Chou and Fasman beta turn prediction\n\nReference: Chou PY, Fasman GD. Prediction of the secondary structure of proteins from their amino acid sequence. Adv Enzymol Relat Areas Mol Biol. 1978;47:45-148.\nDescription: The rationale for predicting turns to predict antibody epitopes is based on the paper by Pellequer et al, Immunology Letters, 36 (1993) 83-99. Instead of implementing the turn scale of that paper which has some non-standard properties, we decided to use the Chou and Fasman scale which is commonly used to predict beta turns as described in the reference link above.\nhttp:\/\/tools.iedb.org\/bcell\/help\/","dd2ae85b":"#Lasso","26f65657":"#Antibody Epitope Prediction - Tutorial\n\nI. Methods for predicting continuous antibody epitope from protein sequences\n\nGeneral basis: Parameters such as hydrophilicity, flexibility, accessibility, turns, exposed surface, polarity and antigenic propensity of polypeptides chains have been correlated with the location of continuous epitopes. This has led to a search for empirical rules that would allow the position of continuous epitopes to be predicted from certain features of the protein sequence. All prediction calculations are based on propensity scales for each of the 20 amino acids. Each scale consists of 20 values assigned to each of the amino acid residues on the basis of their relative propensity to possess the property described by the scale.\nGeneral method: When computing the score for a given residue i, the amino acids in an interval of the chosen length, centered around residue i, are considered. In other words, for a window size n, the i - (n-1)\/2 neighboring residues on each side of residue i were used to compute the score for residue i. Unless specified, the score for residue i is the average of the scale values for these amino acids (see table 1 for specific method implementation details). In general, a window size of 5 to 7 is appropriate for finding regions that may potentially be antigenic.\n\nInterpretation of output graphs and tables: On the graphs, the Y-axes depicts for each residue the correspondent score (averaged in the specified window), be it a BepiPred score or a residue score on the Karplus and Schulz flexibility scale; while the X-axes depicts the residue positions in the sequence. The tables provide values of calculated scores for each residue. The larger score for the residues might be interpreted as that the residue might have a higher probability to be part of epitope (those residues are colored in yellow on the graphs). However, the presented methods do not predict the epitopes per se, either linear or discontinuous, -- they might only guide the researchers to further explore the protein regions on being genuine epitopes.http:\/\/tools.iedb.org\/bcell\/help\/","48b8c65f":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRe9oro6cBfFoQvBOOyQ_BkLV00V1CgerDTIQ&usqp=CAU)slideplayer.com","1a7f3a15":"Das War's Kaggle Notebook Runner: Mar\u00edlia Prata   @mpwolke","0f283b17":"#B-Cell\n\n![](https:\/\/askabiologist.asu.edu\/sites\/default\/files\/resources\/activities\/body_depot\/viral_attack\/duck3.gif)You might think B-cells got their name because they are made inside your bones. It is true that most blood cells are made inside the bone marrow, but that is not where the \u201cB\u201d in B-cells came from. Their name comes from the name of the place they were discovered, the Bursa of Fabricius. The Bursa is an organ only found in birds.(Probably Kagglers have that organ too, since we're all are birds) https:\/\/askabiologist.asu.edu\/b-cell","47fd8b23":"#Emini surface accessibility scale\n\nReference: Emini EA, Hughes JV, Perlow DS, Boger J. Induction of hepatitis A virus-neutralizing antibody by a virus-specific synthetic peptide. J Virol. 1985 Sep;55(3):836-9.\nDescription: The calculation was based on surface accessibility scale on a product instead of an addition within the window. The accessibility profile was obtained using the formulae Sn = (n+4+i ) (0.37)-6 where Sn is the surface probability, dn is the fractional surface probability value, and i vary from 1 to 6. A hexapeptide sequence with Sn greater than 1.0 indicates an increased probability for being found on the surface.http:\/\/tools.iedb.org\/bcell\/help\/","85bbb19b":"#Parker Hydrophilicity Prediction\n\nReference: Parker JM, Guo D, Hodges RS. New hydrophilicity scale derived from high-performance liquid chromatography peptide retention data: correlation of predicted surface residues with antigenicity and X-ray-derived accessible sites. Biochemistry. 1986 Sep 23; 25(19):5425-32.\nDescription: In this method, hydrophilic scale based on peptide retention times during high-performance liquid chromatography (HPLC) on a reversed-phase column was constructed. A window of seven residues was used for analyzing epitope region. The corresponding value of the scale was introduced for each of the seven residues and the arithmetical mean of the seven residue value was assigned to the fourth, (i+3), residue in the segment.http:\/\/tools.iedb.org\/bcell\/help\/"}}