{"cell_type":{"ed9c8c8b":"code","7a7b0545":"code","3b55de3d":"code","18d0ccc9":"code","f5c9fcc5":"code","a75498f8":"code","ef2c87bf":"code","4d3ec439":"code","3c89762b":"code","0ab51700":"code","2306815b":"code","723d8985":"code","21e7999b":"code","32b0f776":"code","3503d663":"code","4d49ced8":"code","e1b2407d":"code","68563df5":"code","e842680f":"code","5c247b6f":"code","d9256ea8":"code","2435abeb":"code","8cd61cb1":"code","d6e17b66":"code","2fe20a52":"code","e7fc1fe8":"code","78505f63":"code","a201b39c":"code","24a6e315":"code","f622cbc1":"markdown","d58b2628":"markdown","41ba079a":"markdown","e8ae42c1":"markdown","1b1c517b":"markdown","7eb42bdf":"markdown","2cbcc85f":"markdown","78c92923":"markdown","ba5cbecf":"markdown","b67563e4":"markdown","199773c5":"markdown","70524241":"markdown","7cc24f5f":"markdown","92cae391":"markdown","8f990fce":"markdown","dcb8ec87":"markdown","36409deb":"markdown","fa591c74":"markdown","82f29f4c":"markdown","8d6f37f9":"markdown","22ce86dd":"markdown","0b6f9a6c":"markdown","e2a05378":"markdown","0d2ddce9":"markdown","aa063942":"markdown","3470cd12":"markdown","f1c9155d":"markdown"},"source":{"ed9c8c8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a7b0545":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","3b55de3d":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","18d0ccc9":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","f5c9fcc5":"train.info()","a75498f8":"test.info()","ef2c87bf":"fig, axs = plt.subplots(1,2, figsize=(15,5))\nsns.heatmap(train.corr(), ax=axs[0], annot=True).set(title='Train')\nsns.heatmap(test.corr(), ax=axs[1], annot=True).set(title='Test')","4d3ec439":"train[['Age', 'Fare']].describe()","3c89762b":"test[['Age', 'Fare']].describe()","0ab51700":"df_age_null = train[train[\"Age\"].isnull()]\ndf_age_null.groupby(['Pclass'])['PassengerId'].count()","2306815b":"df_age_null = test[test[\"Age\"].isnull()]\ndf_age_null.groupby(['Pclass'])['PassengerId'].count()","723d8985":"train.groupby(['Pclass'])['Age'].describe()","21e7999b":"test.groupby(['Pclass'])['Age'].describe()","32b0f776":"train[train['Age'] < 1]['Age'].describe()","3503d663":"test[test['Age'] < 1]['Age'].describe()","4d49ced8":"fig, axs = plt.subplots(4,2, figsize=(15,15))\nsns.histplot(data=train, ax=axs[0,0], x=\"Age\", kde=True, hue='Survived')\nsns.histplot(data=train, ax=axs[0,1], x=\"Age\", kde=True, hue='Sex')\nsns.scatterplot(data=train, ax=axs[1,0], x=\"Pclass\", y=\"Fare\", hue='Survived')\nsns.scatterplot(data=train, ax=axs[1,1], x=\"Age\", y=\"Fare\", hue='Survived')\nsns.boxplot(data=train, ax=axs[2,0], x=\"Sex\", y=\"Age\", hue='Survived')\nsns.boxplot(data=train, ax=axs[2,1], x=\"Pclass\", y=\"Fare\", hue='Survived')\nsns.histplot(data=train, ax=axs[3,0], x=\"Fare\", kde=True, bins=10)","e1b2407d":"fig, axs = plt.subplots(4,2, figsize=(15,15))\nsns.histplot(data=test, ax=axs[0,0], x=\"Age\", kde=True)\nsns.histplot(data=test, ax=axs[0,1], x=\"Age\", kde=True, hue='Sex')\nsns.scatterplot(data=test, ax=axs[1,0], x=\"Pclass\", y=\"Fare\")\nsns.scatterplot(data=test, ax=axs[1,1], x=\"Age\", y=\"Fare\")\nsns.boxplot(data=test, ax=axs[2,0], x=\"Sex\", y=\"Age\")\nsns.boxplot(data=test, ax=axs[2,1], x=\"Pclass\", y=\"Fare\")\nsns.histplot(data=test, ax=axs[3,0], x=\"Fare\", kde=True, bins=10)","68563df5":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='median', verbose=0, copy=True)\n\ntrain['Age'] = imputer.fit_transform(train['Age'].values.reshape(-1,1))[:,0]  \ntrain['Age'].astype(int)\n\ntest['Age'] = imputer.fit_transform(test['Age'].values.reshape(-1,1))[:,0]  \ntest['Age'].astype(int)","e842680f":"def update_age_less_one(x):\n    if x < 1:\n        return 1\n    return x\n\ntrain['Age'] = train['Age'].apply(lambda x: update_age_less_one(x))\ntest['Age'] = test['Age'].apply(lambda x: update_age_less_one(x))","5c247b6f":"imputer = SimpleImputer(missing_values=np.nan, strategy='median', verbose=0, copy=True)\n\ntrain['Fare'] = imputer.fit_transform(train['Fare'].values.reshape(-1,1))[:,0]\ntest['Fare'] = imputer.fit_transform(test['Fare'].values.reshape(-1,1))[:,0]","d9256ea8":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=5, init='random')\n\nkmeans.fit(train[['Pclass','Fare']])\ntrain['Fare_class'] = kmeans.labels_\n\nkmeans.fit(test[['Pclass','Fare']])\ntest['Fare_class'] = kmeans.labels_\n\nfig, axs = plt.subplots(1,2, figsize=(15,5))\nsns.scatterplot(data=train, ax=axs[0], x='Pclass', y='Fare', c=train['Fare_class']).set(title='Train')\nsns.scatterplot(data=test, ax=axs[1], x='Pclass', y='Fare', c=test['Fare_class']).set(title='Test')","2435abeb":"train = pd.get_dummies(train, columns=['Sex','Embarked', 'Pclass','Fare_class'])\ntest = pd.get_dummies(test, columns=['Sex','Embarked', 'Pclass','Fare_class'])","8cd61cb1":"train.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Fare'], inplace=True)\npassenger_ids = test['PassengerId']\ntest.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Fare'], inplace=True)","d6e17b66":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n  \ntrain[[\"ScaledAge\"]] = scaler.fit_transform(train[[\"Age\"]])\ntrain.drop(columns=['Age'], inplace=True)\n\ntest[[\"ScaledAge\"]] = scaler.fit_transform(test[[\"Age\"]])\ntest.drop(columns=['Age'], inplace=True)","2fe20a52":"from sklearn.model_selection import train_test_split\n\nX = train.iloc[:, 1:]\ny = train['Survived']\n\nx_train, x_test, y_train, y_test = train_test_split(X, y)","e7fc1fe8":"def create_model(first_input, dropout):\n    \n    model = tf.keras.models.Sequential()    \n    model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(first_input, )))\n    model.add(tf.keras.layers.Dense(units=256, activation='relu', input_shape=(128, )))\n    model.add(tf.keras.layers.Dropout(dropout))\n    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    model.summary()\n    \n    return model","78505f63":"from datetime import datetime\nfrom keras.callbacks import ModelCheckpoint\n\ndef training_model(input_shape, dropout, epochs, batch_size, data, save):\n    \n    result = pd.DataFrame(columns=['epochs', 'test_loss', 'test_accuracy'])    \n \n    for n_epochs in range(epochs['min_epochs'], epochs['max_epochs']+1, epochs['step']):        \n        model = create_model(input_shape, dropout)\n        model.fit(data['x_train'], data['y_train'], epochs=n_epochs, batch_size=batch_size)       \n        test_loss, test_accuracy = model.evaluate(data['x_test'], data['y_test'])       \n        result = result.append({'epochs': n_epochs, 'test_loss': test_loss, 'test_accuracy':test_accuracy}, ignore_index=True)\n    \n    #Save results in csv files\n    filename = 'training_{0}.csv'.format(str(datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\")))\n    result.to_csv(filename, index=True)\n        \n    if save:\n        #Save the model architecture and weights\n        model.save(\"model.h5\")              ","a201b39c":"epochs = { 'min_epochs': 10, 'max_epochs': 10, 'step': 5 }\ndata = { 'x_train': x_train, 'y_train': y_train, 'x_test': x_test, 'y_test': y_test }\ninput_shape = train.shape[1]-1\ndropout = 0.2\nbatch_size = 10\ntraining_model(input_shape, dropout, epochs, batch_size, data, True)","24a6e315":"from keras.models import load_model\n\nmodel = load_model('model.h5')\ny_predict = pd.DataFrame(model.predict_classes(test))\nsubmission = pd.concat([passenger_ids,y_predict],axis=1)\nsubmission.columns = [\"PassengerId\",\"Survived\"]\nsubmission.to_csv(\"Submission.csv\",index=False)\nsubmission.head()","f622cbc1":"## M\u00e9dia de idade entre os passageiros de diferente classes (Dados de Treino)","d58b2628":"## Quantidade de crian\u00e7as menores de 1 ano (Dados de Treino)","41ba079a":"## Execu\u00e7\u00e3o do modelo para avalia\u00e7\u00e3o","e8ae42c1":"## Na coluna \"Age\", as linhas com valor nulo ser\u00e3o atualizadas com a mediana da idade dos passageiros.","1b1c517b":"## Criando a rede neural com duas camadas densas","7eb42bdf":"# Mapa de correla\u00e7\u00e3o entre as features","2cbcc85f":"# Analisando a feature \"Age\"","78c92923":"## Linhas com o valor nulo (Dados de Teste)","ba5cbecf":"## Carregando os dados de testes que ser\u00e3o utilizados na submiss\u00e3o e avalia\u00e7\u00e3o do modelo","b67563e4":"## Visualiza\u00e7\u00e3o gr\u00e1fica dos dados de treino","199773c5":"## Linhas com o valor nulo (Dados de Treino)","70524241":"## Aplicando o algoritmo K-means para agrupar Fare\/Pclass","7cc24f5f":"## Analisando as features quantitativas","92cae391":"## Treinamento do modelo","8f990fce":"## Criando a fun\u00e7\u00e3o que vai treinar o modelo","dcb8ec87":"## Informa\u00e7\u00f5es b\u00e1sicas dos dados de treinamento","36409deb":"## Visualiza\u00e7\u00e3o gr\u00e1fica dos dados de teste","fa591c74":"## Crian\u00e7as menores de 1 ano, ser\u00e3o atualizadas com o valor 1","82f29f4c":"## Quantidade de crian\u00e7as menores de 1 ano (Dados de Teste)","8d6f37f9":"## Deletando as features irrelevantes","22ce86dd":"## Informa\u00e7\u00f5es b\u00e1sicas dos dados de teste","0b6f9a6c":"## Carregando os dados de treino do modelo","e2a05378":"## Aplicando o scaling na coluna \"Age\" para ficar entre os valores [0,1]","0d2ddce9":"## Divis\u00e3o dos dados de Treino (Para avalia\u00e7\u00e3o pr\u00e9via do modelo)","aa063942":"## M\u00e9dia de idade entre os passageiros de diferente classes (Dados de Teste)","3470cd12":"# Ajustando algumas features","f1c9155d":"## Transformando as features categ\u00f3ricas (one hot encoder)"}}