{"cell_type":{"4730f88c":"code","f2569f2c":"code","20b66e64":"code","1265af6c":"code","dc51a506":"code","9605ae6a":"code","d3912b16":"code","79f2a088":"code","40680c3d":"code","e89ee38b":"code","af3e4c72":"code","1a431710":"code","827a1fea":"code","5dc0a208":"code","42d501f6":"code","e6c2718a":"code","517ed01f":"code","86eb18b8":"code","08a6020f":"code","6c89b1d6":"code","8593fb16":"code","8d39bda7":"code","41b51696":"code","08eb6a66":"code","4c7e866a":"code","87735fb2":"code","b89c5e45":"code","44dcc630":"code","b244c5aa":"code","efb48fa9":"code","4ee514c0":"code","47915412":"code","28e9a204":"code","fd48a639":"markdown","bdede7f7":"markdown","dfb52a75":"markdown","0ac22bd0":"markdown","aad05637":"markdown"},"source":{"4730f88c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2569f2c":"import os\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","20b66e64":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nimport kerastuner\nimport keras.backend as k\n#from keras_tqdm import TQDMCallback\nfrom tqdm import tqdm\nfrom PIL import Image","1265af6c":"k.image_data_format()","dc51a506":"DATA_DIR = '..\/input\/cell-images-for-detecting-malaria\/cell_images'","9605ae6a":"UNINFECTED_DATA_DIR = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected'\nlabel = []\ndataset = []\ncount = 0\nSIZE = 160\nfor i,image_name in enumerate(os.listdir(UNINFECTED_DATA_DIR)):\n    try:\n        if (image_name.split('.')[1] == 'png'):\n            image = cv2.imread(UNINFECTED_DATA_DIR+'\/'+ image_name)\n            image = Image.fromarray(image, 'RGB')\n            image = image.resize((SIZE, SIZE))\n            dataset.append(np.array(image))\n            label.append(0)\n            count +=1\n    except Expection:\n        print('cound not read image number {} with name {}'.format(i,image_name))\ntotal_uninfected = count\nprint('total number of Uninfected images is {}'.format(count))","d3912b16":"PARASITIZED_DATA_DIR = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized'\ncount = 0\nSIZE = 160\nfor i,image_name in enumerate(os.listdir(PARASITIZED_DATA_DIR)):\n    try:\n        if (image_name.split('.')[1] == 'png'):\n            image = cv2.imread(PARASITIZED_DATA_DIR+'\/'+ image_name)\n            image = Image.fromarray(image, 'RGB')\n            image = image.resize((SIZE, SIZE))\n            dataset.append(np.array(image))\n            label.append(1)\n            count +=1\n    except Expection:\n        print('cound not read image number {} with name {}'.format(i,image_name))\ntotal_parasitized = count\nprint('total number of Parasitized images is {}'.format(count))","79f2a088":"print('Total number of images {}'.format(len(dataset)))","40680c3d":"plt.figure(figsize=(15,10))\nprint('UNINFECTED IMAGES')\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    img = mpimg.imread(UNINFECTED_DATA_DIR+'\/'+os.listdir(UNINFECTED_DATA_DIR)[i])\n    plt.imshow(img, cmap=plt.cm.binary)\nplt.show()\n\n","e89ee38b":"plt.figure(figsize=(15,10))\nprint('PARASITIZED IMAGES')\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    img = mpimg.imread(PARASITIZED_DATA_DIR+'\/'+os.listdir(PARASITIZED_DATA_DIR)[i])\n    plt.imshow(img, cmap=plt.cm.binary)\nplt.show()\n\n","af3e4c72":"from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(dataset, to_categorical(np.array(label)), test_size = 0.20, random_state = 0 ,shuffle =True)","1a431710":"X_train = np.array(X_train)\nX_test = np.array(X_test)","827a1fea":"classifier = None\nclassifier = Sequential()\nclassifier.add(Conv2D(32, (3, 3), input_shape = (SIZE, SIZE, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Conv2D(32, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Flatten())\nclassifier.add(Dense(activation = 'relu', units=512))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Dense(activation = 'relu', units=256))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Dense(activation = 'sigmoid', units=2))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nprint(classifier.summary())\n","5dc0a208":"from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\nearlystop = EarlyStopping(monitor = 'val_loss',\n                          min_delta = 0,\n                          patience = 5,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nscheduler = LearningRateScheduler(scheduler, verbose=0)","42d501f6":"history = classifier.fit(X_train, y_train, batch_size=32,epochs=50, verbose=1, validation_split=0.15, callbacks=[earlystop])","e6c2718a":"print(\"Loss of the model is - \" , classifier.evaluate(X_test,y_test)[0] , \"%\")\nprint(\"Accuracy of the model is - \" , classifier.evaluate(X_test,y_test)[1]*100 , \"%\")","517ed01f":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","86eb18b8":"show_final_history(history)","08a6020f":"predictions = model.(X_test)\npredictions[:5]","6c89b1d6":"predictions = np.argmax(predictions,1)","8593fb16":"y_test_inv = np.argmax(y_test,1)","8d39bda7":"from sklearn.metrics import classification_report, confusion_matrix","41b51696":"labels = ['Uninfected', 'Parasitized']\nprint(classification_report(y_test_inv, predictions, target_names = labels))","08eb6a66":"cm = confusion_matrix(y_test_inv,predictions)\ncm","4c7e866a":"cm = pd.DataFrame(cm , index = labels , columns = labels)","87735fb2":"plt.figure(figsize = (10,10))\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = labels , yticklabels = labels)","b89c5e45":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input","44dcc630":"vgg = VGG16(input_shape = [160, 160, 3], weights = 'imagenet', include_top = False);","b244c5aa":"for layer in vgg.layers:\n    layer.trainable = False","efb48fa9":"base_model = vgg.output\nbase_model = GlobalAveragePooling2D()(base_model)\nprediction = Dense(2, activation = 'softmax')(base_model)\nmodel = Model(inputs= vgg.input, outputs = prediction)\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","4ee514c0":"model.summary()","47915412":"history = model.fit(X_train, y_train, batch_size=32,epochs=50, verbose=1, validation_split=0.15, callbacks=[earlystop])","28e9a204":"print(\"Test_Accuracy(after transfer learning): {:.2f}%\".format(model.evaluate(X_test, y_test, verbose = 1)[1]*100))","fd48a639":"**Accuracy that model attain is ~ 95% for training and testing**","bdede7f7":"# Data Preprocessing","dfb52a75":"# Second Method (Transfer learning)","0ac22bd0":"## Data Visualization","aad05637":"# Model Building"}}