{"cell_type":{"1b10e6fc":"code","83afbeec":"code","04503621":"code","99e967c5":"code","0e8acb2d":"code","0c5da348":"code","2adcdc4d":"code","af2b9de9":"code","774536e5":"code","3c952f3a":"code","9b822942":"code","28f9c8e2":"code","2135effd":"code","1597a273":"code","58d42590":"code","517e3bc3":"code","12781217":"code","cdafe092":"code","f85a3f7e":"code","fb6c3153":"code","402b1fb1":"code","fba8d5b7":"code","079989c4":"code","edc23588":"markdown","a85c5eb2":"markdown"},"source":{"1b10e6fc":"import pandas as pd\nimport numpy as np\nimport collections\nfrom datetime import datetime\nfrom datetime import timedelta\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\nfrom sklearn import linear_model\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import zero_one_loss\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","83afbeec":"train=pd.read_csv(\"\/kaggle\/input\/data-science-bowl-2019\/train.csv\",sep=',',decimal='.')\ntest=pd.read_csv(\"\/kaggle\/input\/data-science-bowl-2019\/test.csv\",sep=',',decimal='.')\ntrain_labels=pd.read_csv(\"\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv\",sep=',',decimal='.')\nspecs=pd.read_csv(\"\/kaggle\/input\/data-science-bowl-2019\/specs.csv\",sep=',',decimal='.')\nsample_submission=pd.read_csv(\"\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv\",sep=',',decimal='.')","04503621":"print('Evaluaciones: ', train_labels['title'].unique())\nprint('Total de Evaluaciones: ', len(train_labels['title'].unique()))","99e967c5":"assessment=train_labels['title'].value_counts()\nfig = plt.figure()\nax = assessment.plot(kind='barh',grid=False, color='blue')\nplt.show()","0e8acb2d":"train=train.drop(['timestamp','event_data'],axis=1)\ntest=test.drop(['timestamp','event_data'],axis=1)","0c5da348":"train=train[train.installation_id.isin(train_labels.installation_id.unique())]\ntest_assess = test[test.type == 'Assessment'].copy()\ntest_labels = sample_submission.copy()\ntest_labels['title'] = test_labels['installation_id'].progress_apply(lambda install_id: test_assess[test_assess.installation_id == install_id].iloc[-1].title)\n","2adcdc4d":"train=train.drop(['event_id','event_code'],axis=1)\ntest=test.drop(['event_id','event_code'],axis=1)\n\ntrain_2=(pd.get_dummies(train.drop(columns=['game_session', 'event_count', 'game_time']),\n            columns=['title', 'type', 'world']).groupby(['installation_id']).sum())\n\ntest_2=(pd.get_dummies(test.drop(columns=['game_session', 'event_count', 'game_time']),\n            columns=['title', 'type', 'world']).groupby(['installation_id']).sum())\n\ntrain_3=(train[['installation_id', 'event_count', 'game_time']].groupby(['installation_id'])\n        .agg([np.sum, np.mean, np.std, np.min, np.max]))\n            \ntest_3=(test[['installation_id', 'event_count', 'game_time']].groupby(['installation_id'])\n        .agg([np.sum, np.mean, np.std, np.min, np.max]))","af2b9de9":"def parameters(group1, col):\n    return group1[['installation_id', col, 'event_count', 'game_time']\n                 ].groupby(['installation_id', col]).agg([np.mean, np.sum, np.std]).reset_index().pivot(\n        columns=col,index='installation_id')\n\n\nworld_time_stats_train = parameters(train, 'world')\ntype_time_stats_train = parameters(train, 'type')\nworld_time_stats_test = parameters(test, 'world')\ntype_time_stats_test = parameters(test, 'type')","774536e5":"new_train=train_2.join(train_3).join(world_time_stats_train).join(type_time_stats_train).fillna(0)\nnew_test=test_2.join(test_3).join(world_time_stats_test).join(type_time_stats_test).fillna(0)","3c952f3a":"titles = train_labels.title.unique()\ntitle2mode = {}\n\nfor title in titles:\n    mode = train_labels[train_labels.title == title].accuracy_group.value_counts().index[0]\n    title2mode[title] = mode\n\ntrain_labels['title_mode'] = train_labels.title.apply(lambda title: title2mode[title])\ntest_labels['title_mode'] = test_labels.title.apply(lambda title: title2mode[title])","9b822942":"final_train = pd.get_dummies((train_labels.set_index('installation_id')\n        .drop(columns=['num_correct', 'num_incorrect', 'accuracy', 'game_session'])\n        .join(new_train)),columns=['title'])\n\n\n\nfinal_train = final_train.reset_index().groupby('installation_id').apply(lambda x: x.iloc[-1])\nfinal_train = final_train.drop(columns='installation_id')\n\nprint('Dimensi\u00f3n train_labels:', final_train.shape)\n\nfinal_test = pd.get_dummies(test_labels.set_index('installation_id').join(new_test), columns=['title'])\n\nprint('Dimensi\u00f3n test_labels:',final_test.shape)\n","28f9c8e2":"X = final_train.drop(columns='accuracy_group').values\ny = final_train['accuracy_group'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\nprint('Dimensiones x_train: ',X_train.shape)\nprint('Dimensiones x_test: ',X_test.shape)\nprint('Dimensiones y_train: ',y_train.shape)\nprint('Dimensiones y_test: ',y_test.shape)","2135effd":"X2=final_train.drop(columns='accuracy_group').index\ny2=final_train['accuracy_group'].index\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=1)","1597a273":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","58d42590":"model = linear_model.LogisticRegression()\nmodel.fit(X_train,y_train)\npredictions = model.predict(X_test)\nprint('Predicci\u00f3n con accuracy_score: ', accuracy_score(y_test, predictions))","517e3bc3":"from sklearn.metrics import cohen_kappa_score\nscore_kappa=cohen_kappa_score(y_test, predictions, weights='quadratic')\nprint(score_kappa)","12781217":"print('------Regresi\u00f3n Logistica-----\\n')\nprint('Matriz de confusi\u00f3n: \\n', confusion_matrix(y_test, predictions))\n\n\nprint('Report: \\n', classification_report(y_test, predictions))","cdafe092":"print('Predicci\u00f3n con zero-one-loss: ',zero_one_loss(y_test, predictions))\n","f85a3f7e":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)","fb6c3153":"predictions = model.predict(X_test)\n\nprint('Predicci\u00f3n con accuracy_score: ',accuracy_score(y_test, predictions))\n\n","402b1fb1":"print('------Random Forest Classifier-----\\n')\nprint('Matriz de confusi\u00f3n: \\n', confusion_matrix(y_test, predictions))\n\n\nprint('Report: \\n', classification_report(y_test, predictions))","fba8d5b7":"sub=pd.DataFrame()\nsub['installation_id']=X_test2\nsub['accuracy_group']=predictions\n\n\nscore_kappa=cohen_kappa_score(y_test, predictions, weights='quadratic')\nprint(score_kappa)","079989c4":"sub.to_csv('submission.csv', index=False)","edc23588":"# Logistic Regression","a85c5eb2":"# Random Forest Classifier"}}