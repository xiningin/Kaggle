{"cell_type":{"755a4241":"code","af06f24e":"code","631de5fa":"code","6b5cff9a":"code","6f0c80e1":"code","fb239462":"code","bac73365":"code","9dbb4a05":"code","1be37c1b":"code","c35778ef":"code","a92e5f2a":"code","c2c8cdad":"code","afaf0118":"code","2a67541a":"code","10ea26d4":"code","8f13aee8":"code","6d4dc67a":"code","fe9d2f5e":"code","2cd8ab81":"code","f39f7984":"code","7e1bea8c":"code","e4ee39f4":"code","6cdead7e":"code","397b65cc":"code","cb12eedf":"code","aa8be400":"code","b388f0db":"code","99f2eb12":"code","275d3a87":"code","860c3040":"code","e6f77c37":"code","b1eacd3e":"code","ebde14bf":"code","601b6052":"code","abe6fa37":"code","0628fe02":"code","14874820":"code","133637a3":"code","48176260":"code","96424cbd":"code","6acb108f":"code","48c34b0f":"code","603b4f38":"markdown","a8046c91":"markdown","4e0bc980":"markdown","cebc1407":"markdown","0d66badc":"markdown","bf9a5c13":"markdown","082d5b1f":"markdown","31f51eb0":"markdown","d0d32ef8":"markdown","91c43877":"markdown","24d4906d":"markdown","7f974d77":"markdown","b2fa875b":"markdown","20ef9b57":"markdown","aa55abe4":"markdown","0b99c1b2":"markdown","caffe263":"markdown","b6a576a3":"markdown","961c2412":"markdown","fa92bd99":"markdown"},"source":{"755a4241":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport xgboost as xgb\nnp.random.seed(2019)\nfrom scipy.stats import skew\nfrom scipy import stats\nimport statsmodels\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint(\"done\")\nimport pandas as pd\nimport numpy as np\nimport math\nimport datetime\nimport matplotlib.pyplot as plt\nimport matplotlib","af06f24e":"def read_and_concat_dataset(training_path, test_path):\n    train = pd.read_csv(training_path)\n    train['train'] = 1\n    test = pd.read_csv(test_path)\n    test['train'] = 0\n    data = train.append(test, ignore_index=True)\n    return train, test, data\n\ntrain, test, data = read_and_concat_dataset('..\/input\/titanic\/train.csv', '..\/input\/titanic\/test.csv')\ndata = data.set_index('PassengerId')","631de5fa":"data.head(3)","6b5cff9a":" g = sns.heatmap(data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, cmap = \"coolwarm\")","6f0c80e1":"def counting_values(data, variable1, variable2):\n    return data[[variable1, variable2]][data[variable2].isnull()==False].groupby([variable1], as_index=False).mean().sort_values(by=variable2, ascending=False)","fb239462":"counting_values(data, 'Sex','Survived')","bac73365":"grid = sns.FacetGrid(data, col='Survived', row='Pclass', size=2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)","9dbb4a05":"grid = sns.FacetGrid(data, row='Embarked', col='Survived', size=2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)","1be37c1b":"data.isnull().sum()","c35778ef":"data.groupby('Pclass').Fare.mean()","a92e5f2a":"data.Fare = data.Fare.fillna(0)","c2c8cdad":"print(data.Embarked.value_counts())\ndata.Embarked = data.Embarked.fillna('S')","afaf0118":"data.Cabin = data.Cabin.fillna('Unknown_Cabin')\ndata['Cabin'] = data['Cabin'].str[0]","2a67541a":"data.groupby('Pclass').Cabin.value_counts()","10ea26d4":"data['Cabin'] = np.where((data.Pclass==1) & (data.Cabin=='U'),'C',\n                                            np.where((data.Pclass==2) & (data.Cabin=='U'),'D',\n                                                                        np.where((data.Pclass==3) & (data.Cabin=='U'),'G',\n                                                                                                    np.where(data.Cabin=='T','C',data.Cabin))))","8f13aee8":"#let's replace a few titles -> \"other\" and fix a few titles\ndata['Title'] = np.where((data.Title=='Capt') | (data.Title=='Countess') | (data.Title=='Don') | (data.Title=='Dona')\n                        | (data.Title=='Jonkheer') | (data.Title=='Lady') | (data.Title=='Sir') | (data.Title=='Major') | (data.Title=='Rev') | (data.Title=='Col'),'Other',data.Title)\n\ndata['Title'] = data['Title'].replace('Ms','Miss')\ndata['Title'] = data['Title'].replace('Mlle','Miss')\ndata['Title'] = data['Title'].replace('Mme','Mrs')","6d4dc67a":"data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\nfacet = sns.FacetGrid(data = data, hue = \"Title\", legend_out=True, size = 4.5)\nfacet = facet.map(sns.kdeplot, \"Age\")\nfacet.add_legend();","fe9d2f5e":"sns.boxplot(data = data, x = \"Title\", y = \"Age\")","2cd8ab81":"facet = sns.FacetGrid(data, hue=\"Survived\",aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, data['Age'].max()))\nfacet.add_legend()","f39f7984":"data.groupby('Title').Age.mean()","7e1bea8c":"data['Age'] = np.where((data.Age.isnull()) & (data.Title=='Master'),5, np.where((data.Age.isnull()) & (data.Title=='Miss'),22, np.where((data.Age.isnull()) & (data.Title=='Mr'),32, np.where((data.Age.isnull()) & (data.Title=='Mrs'),37, np.where((data.Age.isnull()) & (data.Title=='Other'),45, np.where((data.Age.isnull()) & (data.Title=='Dr'),44,data.Age))))))                   ","e4ee39f4":"data['FamilySize'] = data.SibSp + data.Parch + 1\ndata['Mother'] = np.where((data.Title=='Mrs') & (data.Parch >0),1,0)\ndata['Free'] = np.where(data['Fare']==0, 1,0)\ndata = data.drop(['SibSp','Parch','Sex'],axis=1)","6cdead7e":"import string\nTypeOfTicket = []\nfor i in range(len(data.Ticket)):\n    ticket = data.Ticket.iloc[i]\n    for c in string.punctuation:\n                ticket = ticket.replace(c,\"\")\n                splited_ticket = ticket.split(\" \")   \n    if len(splited_ticket) == 1:\n                TypeOfTicket.append('NO')\n    else: \n                TypeOfTicket.append(splited_ticket[0])\n            \ndata['TypeOfTicket'] = TypeOfTicket\n\ndata.TypeOfTicket.value_counts()\ndata['TypeOfTicket'] = np.where((data.TypeOfTicket!='NO') & (data.TypeOfTicket!='PC') & (data.TypeOfTicket!='CA') & \n                                (data.TypeOfTicket!='A5') & (data.TypeOfTicket!='SOTONOQ'),'other',data.TypeOfTicket)\ndata = data.drop('Ticket',axis=1)","397b65cc":"counting_values(data, 'Title','Survived')","cb12eedf":"counting_values(data, 'TypeOfTicket','Survived')","aa8be400":"counting_values(data, 'Cabin','Survived')","b388f0db":"bins = [0,12,24,45,60,data.Age.max()]\nlabels = ['Child', 'Young Adult', 'Adult','Older Adult','Senior']\ndata[\"Age\"] = pd.cut(data[\"Age\"], bins, labels = labels)","99f2eb12":"data = pd.get_dummies(data)","275d3a87":"from sklearn.model_selection import train_test_split\ntrainX, testX, trainY, testY = train_test_split(data[data.Survived.isnull()==False].drop('Survived',axis=1),data.Survived[data.Survived.isnull()==False],test_size=0.30, random_state=2019)","860c3040":"Results = pd.DataFrame({'Model': [],'Accuracy Score': [], 'Recall':[], 'F1score':[]})","e6f77c37":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score","b1eacd3e":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(max_depth=4)\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nres = pd.DataFrame({\"Model\":['DecisionTreeClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)],\n                   \"Recall\": [recall_score(testY, y_pred)],\n                   \"F1score\": [f1_score(testY, y_pred)]})\nResults = Results.append(res)","ebde14bf":"pd.crosstab(testY, y_pred, rownames=['Real data'], colnames=['Predicted'])","601b6052":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=2500, max_depth=4)\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['RandomForestClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)],\n                   \"Recall\": [recall_score(testY, y_pred)],\n                   \"F1score\": [f1_score(testY, y_pred)]})\nResults = Results.append(res)","abe6fa37":"pd.crosstab(testY, y_pred, rownames=['Real data'], colnames=['Predicted'])","0628fe02":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['KNeighborsClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)],\n                   \"Recall\": [recall_score(testY, y_pred)],\n                   \"F1score\": [f1_score(testY, y_pred)]})\nResults = Results.append(res)","14874820":"pd.crosstab(testY, y_pred, rownames=['Real data'], colnames=['Predicted'])","133637a3":"from sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['SVC'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)],\n                   \"Recall\": [recall_score(testY, y_pred)],\n                   \"F1score\": [f1_score(testY, y_pred)]})\nResults = Results.append(res)","48176260":"pd.crosstab(testY, y_pred, rownames=['Real data'], colnames=['Predicted'])","96424cbd":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['LogisticRegression'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)],\n                   \"Recall\": [recall_score(testY, y_pred)],\n                   \"F1score\": [f1_score(testY, y_pred)]})\nResults = Results.append(res)","6acb108f":"pd.crosstab(testY, y_pred, rownames=['Real data'], colnames=['Predicted'])","48c34b0f":"Results","603b4f38":"Cabin vs Survived","a8046c91":"** Lets import the needfull Libraries for the work**","4e0bc980":"Lets find the correlation matrix:","cebc1407":"**Random Forest Classifier**","0d66badc":"**KNeighbors Classifier**","bf9a5c13":"This is the work for machine learning from disaster using the titanic dataset. \nI will do feature engineering and then use different methods for prediction. ","082d5b1f":"Title vs Survived","31f51eb0":"Embarked vs Survived","d0d32ef8":"Pclass vs Survived","91c43877":"##** Moving to feature engineering**","24d4906d":"##**Missing values**","7f974d77":"##**Results**","b2fa875b":"**Decision Tree Classifier**","20ef9b57":"TypeOfTicket vs Survived","aa55abe4":"**Logistic Regression**","0b99c1b2":"**Lets import the data**","caffe263":"I create dummy variables for all variables with categories using the function get_dummies from pandas.","b6a576a3":"I'm gonna to put result of each model in Data Frame 'Results'","961c2412":"##** Now lets make the models**\n* Decision Tree Classifier\n* Random Forest Classifier\n* KNeighbors Classifier\n* SVM\n* Logistic Regression\n","fa92bd99":"**SVM**"}}