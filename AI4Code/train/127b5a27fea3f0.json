{"cell_type":{"4219f3dc":"code","569696dc":"code","5da515ff":"code","e0e04e88":"code","ae8292a2":"code","67f0e488":"code","0c2095ea":"code","b27038f6":"code","85035f56":"code","5c5d9891":"code","0176d977":"code","99c4e6f5":"code","940ff6fb":"code","7d0a9492":"code","ef7fdbbf":"code","a1df58d0":"code","8a420368":"code","b04262fa":"code","58aeeff6":"code","44f6e69f":"code","f1ca9e60":"code","c2a59ef3":"code","6097357f":"code","f7cfc1bd":"code","366961f2":"code","e54837ca":"markdown"},"source":{"4219f3dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","569696dc":"import matplotlib.pyplot as plt\nfrom numpy.core.umath_tests import inner1d\n%matplotlib inline\nimport seaborn as sea\nimport warnings\nwarnings.filterwarnings('ignore')","5da515ff":"train=pd.read_csv('..\/input\/data.csv')","e0e04e88":"train.head()","ae8292a2":"train['diagnosis'].value_counts()","67f0e488":"train.isnull().sum()*100\/train.shape[0]","0c2095ea":"from sklearn.preprocessing import LabelEncoder\nlabel=LabelEncoder()\ntrain['diagnosis']=label.fit_transform(train['diagnosis'])","b27038f6":"train.head()","85035f56":"train.drop('Unnamed: 32',axis=1,inplace=True)","5c5d9891":"target=train['diagnosis']","0176d977":"train.drop('diagnosis',axis=1,inplace=True)","99c4e6f5":"target.value_counts().plot.bar()","940ff6fb":"train.drop('id',axis=1,inplace=True)","7d0a9492":"from sklearn.model_selection import train_test_split","ef7fdbbf":"x_train,x_test,y_train,y_test=train_test_split(train,target,test_size=0.25,random_state=0)","a1df58d0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier","8a420368":"classi=[LogisticRegression(),RandomForestClassifier(),DecisionTreeClassifier(),GaussianNB(),KNeighborsClassifier(),MLPClassifier(),XGBClassifier()]","b04262fa":"from sklearn.model_selection import cross_val_score","58aeeff6":"i=0\nfor x in classi:\n    cv=cross_val_score(x,train,target,cv=10)\n    print(i,cv.mean())\n    i=i+1","44f6e69f":"classi[6]","f1ca9e60":"classifier=XGBClassifier()\nclassifier.fit(x_train,y_train)","c2a59ef3":"y_pred=classifier.predict(x_test)","6097357f":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)","f7cfc1bd":"cm","366961f2":"(89+51)\/x_test.shape[0]","e54837ca":"Unnamed having 100% nan value,\nso we drop it"}}