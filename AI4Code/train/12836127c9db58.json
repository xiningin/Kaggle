{"cell_type":{"0a7699a4":"code","853c9395":"code","5c12b924":"code","55b76328":"code","5f9fd19a":"code","4313e452":"code","90f259d8":"code","41bd4424":"code","bce96799":"code","b4dd6c7e":"code","36899631":"code","3ff3c080":"code","7b67256a":"code","b826fb93":"code","01da26a8":"markdown","03302048":"markdown","e6767397":"markdown","8d0a8fa5":"markdown","cd8f45db":"markdown","bc96867f":"markdown","d78385af":"markdown","7ec086de":"markdown","e73492b8":"markdown","13b9d8d3":"markdown","b46a1492":"markdown"},"source":{"0a7699a4":"import os\nimport json\nimport gc\nimport pickle\n\nimport fasttext\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import spearmanr\nfrom tqdm import tqdm_notebook as tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import (\n    Input, Embedding,\n    GRU, Dense, Bidirectional, GlobalMaxPooling1D, \n    SpatialDropout1D, Dropout, BatchNormalization, \n    concatenate\n)","853c9395":"train = pd.read_csv(\"\/kaggle\/input\/google-quest-challenge\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/google-quest-challenge\/test.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/google-quest-challenge\/sample_submission.csv\")\n\nprint(train.shape)\nprint(test.shape)\ntrain.head()","5c12b924":"tokenizer = Tokenizer()\ntext_cols = [train.question_title, train.question_body, train.answer, \n             test.question_title, test.question_body, test.answer]\n\nfor text in tqdm(text_cols):\n    tokenizer.fit_on_texts(text.values)","55b76328":"def compute_sequences(cols, tokenizer, maxlens):\n    sequences = []\n    \n    for texts, maxlen in zip(cols, maxlens):\n        seq = tokenizer.texts_to_sequences(texts.values)\n        seq = pad_sequences(seq, maxlen=maxlen)\n        sequences.append(seq)\n    \n    return sequences","5f9fd19a":"train_data = compute_sequences(\n    [train.question_title, train.question_body, train.answer], \n    tokenizer,\n    [30, 300, 300]\n)\n\ntest_data = compute_sequences(\n    [test.question_title, test.question_body, test.answer], \n    tokenizer,\n    [30, 300, 300]\n)","4313e452":"def build_embedding_matrix(tokenizer, path):\n    num_words = len(tokenizer.word_index) + 1\n    \n    embedding_matrix = np.zeros((num_words, 300))\n    ft_model = fasttext.load_model(path)\n\n    for word, i in tokenizer.word_index.items():\n        embedding_matrix[i] = ft_model.get_word_vector(word)\n    \n    return embedding_matrix","90f259d8":"%%time\npath = '\/kaggle\/input\/fasttext-crawl-300d-2m-with-subword\/crawl-300d-2m-subword\/crawl-300d-2M-subword.bin'\nembedding_matrix = build_embedding_matrix(tokenizer, path)","41bd4424":"def spearman_table(true_labels, y_pred):    \n    table = []\n    \n    for i, col in enumerate(true_labels.columns):\n        corr = spearmanr(true_labels[col], y_pred[:, i]).correlation\n        table.append({'column': col, 'correlation': corr})\n    \n    return pd.DataFrame(table)","bce96799":"def gru_block(x_in, gru1, gru2, embedding, block_name, hidden_dim=200):\n    x = embedding(x_in)\n    x = SpatialDropout1D(0.2, name=f'{block_name}_sp_drop')(x)\n    x = gru1(x)\n    x = gru2(x)\n    x = GlobalMaxPooling1D(name=f'{block_name}_pool')(x)\n    x = Dense(hidden_dim, activation='relu', name=f'{block_name}_fc')(x)\n    x = BatchNormalization(name=f'{block_name}_bn')(x)\n    x = Dropout(0.5, name=f'{block_name}_drop')(x)\n\n    return x\n\n\ndef build_model(embedding_matrix, output_shape, gru_dim=200, hidden_dim=400):\n    embedding = Embedding(\n        *embedding_matrix.shape, \n        weights=[embedding_matrix], \n        trainable=False, \n        mask_zero=True,\n        name='text_embedding'\n    )\n    gru1 = Bidirectional(GRU(gru_dim, return_sequences=True), name='BiGRU1')\n    gru2 = Bidirectional(GRU(gru_dim, return_sequences=True), name='BiGRU2')\n    \n    # question title\n    qt_in = Input(shape=(None,), name='qtitle_input')\n    # question body\n    qb_in = Input(shape=(None,), name='qbody_input')\n    # answer\n    a_in = Input(shape=(None,), name='answer_input')\n    \n    qt = gru_block(qt_in, gru1, gru2, embedding, block_name='qtitle')\n    qb = gru_block(qb_in, gru1, gru2, embedding, block_name='qbody')\n    a = gru_block(a_in, gru1, gru2, embedding, block_name='answer')\n    \n    hidden = concatenate([qt, qb, a])\n    hidden = Dense(hidden_dim, activation='relu')(hidden)\n    hidden = BatchNormalization()(hidden)\n    hidden = Dropout(0.5)(hidden)\n    hidden = Dense(hidden_dim, activation='relu')(hidden)\n    hidden = BatchNormalization()(hidden)\n    hidden = Dropout(0.5)(hidden)\n    out = Dense(output_shape, activation='sigmoid', name='output')(hidden)\n    \n    model = Model(inputs=[qt_in, qb_in, a_in], outputs=out)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001, amsgrad=True), metrics=['mae'])\n\n    return model","b4dd6c7e":"train_labels = train.loc[:, 'question_asker_intent_understanding':]","36899631":"model = build_model(embedding_matrix, output_shape=train_labels.shape[1])\nmodel.summary()","3ff3c080":"checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n\ntrain_history = model.fit(\n    train_data, \n    train_labels.values,\n    epochs=50,\n    validation_split=0.2,\n    callbacks=[checkpoint],\n    batch_size=256\n)","7b67256a":"train_pred = model.predict(train_data, batch_size=512)\n\nsp_df = spearman_table(train_labels, train_pred)\nprint(\"Mean Spearman Correlation:\", sp_df.correlation.mean())\nsp_df","b826fb93":"with open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","01da26a8":"## Training start here","03302048":"## Generate sequence and padding","e6767397":"## Functions for building embedding and model","8d0a8fa5":"## Creating embedding matrix","cd8f45db":"## Evaluate Model","bc96867f":"# Modelling","d78385af":"# About this kernel\n\nSection to be added.\n\nInference Kernel: https:\/\/www.kaggle.com\/xhlulu\/quest-bigru-inference-kernel","7ec086de":"## Create and fit tokenizer","e73492b8":"## Metrics","13b9d8d3":"# Load and preprocess","b46a1492":"## Save model"}}