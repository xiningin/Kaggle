{"cell_type":{"0f9c8a68":"code","d1e03822":"code","fc7f9f45":"code","84534cf2":"code","d3ed8456":"code","3879e18a":"code","4fda1e05":"code","34987a51":"code","91a25f57":"code","27f1fa0a":"code","6cbbe8cf":"code","191236df":"code","f3eb32e1":"code","192682f9":"code","ed938e2a":"code","59c683ec":"code","decb60c5":"code","09957b58":"code","3744c483":"code","ea64c0ba":"code","68d80009":"code","4539ac2a":"code","96692235":"code","8625e769":"markdown","bddd00b5":"markdown","e4fce751":"markdown","2522d83e":"markdown","d4a9d467":"markdown","6e04ce5e":"markdown","46d1d5be":"markdown","535793db":"markdown","4ac2e3f9":"markdown","c40f0bc6":"markdown"},"source":{"0f9c8a68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1e03822":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Normalization\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt","fc7f9f45":"train_data = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-3\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-3\/eval.csv\")","84534cf2":"train_data.describe()","d3ed8456":"test_data.describe()","3879e18a":"features = train_data.loc[:, '0':'1274']\nlabels = train_data['Eat']\n\nt_test_data = test_data.loc[:, '0':'1274'] #Copy of the testing data without pubchem ID","4fda1e05":"X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size=0.33, random_state = 42)\nkfold = KFold(n_splits=10)\ncvscores = []","34987a51":"norm_layer = Normalization()\nnorm_layer.adapt(X_train)","91a25f57":"def mod_1():\n    model_1 = keras.Sequential([\n        norm_layer,\n        keras.layers.Dense(128, activation='relu'),\n        keras.layers.Dense(64, activation='relu'),\n        keras.layers.Dense(1)\n    ])\n\n    model_1.compile(loss='mse',\n                 optimizer=keras.optimizers.Adam(0.001))\n    return model_1","27f1fa0a":"for train, test in kfold.split(features, labels):\n    model = mod_1()\n    model.fit(features.iloc[train], labels.iloc[train], epochs=10)\n    scores = model.evaluate(features.iloc[test], labels.iloc[test])\n    cvscores.append(scores)\n","6cbbe8cf":"plt.bar([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], cvscores)\nplt.xlabel(\"Fold\")\nplt.ylabel(\"MSE\")\nplt.title(\"Model 1 Validation Distribution\")","191236df":"model_1 = mod_1()\nresults1 = model_1.predict(t_test_data).flatten()\noutput1 = pd.DataFrame({'id': test_data.id, 'Eat':results1})\noutput1.describe()","f3eb32e1":"sgd = SGD(learning_rate=0.001, momentum=0.9)","192682f9":"def mod_2():\n    model_2 = keras.Sequential([\n        norm_layer,\n        keras.layers.Dense(128, activation='tanh'),\n        keras.layers.Dense(64, activation='tanh'),\n        keras.layers.Dense(1)\n    ])\n\n    model_2.compile(loss='mse',\n                 optimizer=sgd)\n    return model_2","ed938e2a":"cvscores2 = []\nfor train, test in kfold.split(features, labels):\n    model = mod_2()\n    model.fit(features.iloc[train], labels.iloc[train], epochs=10)\n    scores = model.evaluate(features.iloc[test], labels.iloc[test])\n    cvscores2.append(scores)","59c683ec":"plt.bar([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], cvscores2)\nplt.xlabel(\"Fold\")\nplt.ylabel(\"MSE\")\nplt.title(\"Model 2 Validation Distribution\")","decb60c5":"model_2 = mod_2()\nresults2 = model_2.predict(t_test_data).flatten()\noutput2 = pd.DataFrame({'id': test_data.id, 'Eat':results2})\noutput2.describe()","09957b58":"def mod_3():\n    model_3 = keras.Sequential([\n        norm_layer,\n        keras.layers.Dense(128, activation='softmax'),\n        keras.layers.Dense(64, activation='softmax'),\n        keras.layers.Dense(1)\n    ])\n\n    model_3.compile(loss='mse',\n                 optimizer=sgd)\n    return model_3","3744c483":"cvscores3 = []\nfor train, test in kfold.split(features, labels):\n    model = mod_3()\n    model.fit(features.iloc[train], labels.iloc[train], epochs=10)\n    scores = model.evaluate(features.iloc[test], labels.iloc[test])\n    cvscores3.append(scores)","ea64c0ba":"plt.bar([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], cvscores3)\nplt.xlabel(\"Fold\")\nplt.ylabel(\"MSE\")\nplt.title(\"Model 3 Validation Distribution\")","68d80009":"model_3 = mod_3()\nresults3 = model_3.evaluate(X_test, y_test)\noutput3 = pd.DataFrame({'id': test_data.id, 'Eat':results3})\noutput3.describe()","4539ac2a":"results = model_2.predict(t_test_data).flatten()\noutput = pd.DataFrame({'id': test_data.id, 'Eat':results})\noutput.to_csv('submission.csv', index=False)","96692235":"print(output.to_string())","8625e769":"# Parsing in the testing and training data","bddd00b5":"# Model 1 using Adam optimizer\n- with 'relu' as the activation function for both layers","e4fce751":"# Creation of the normalization layer","2522d83e":"# Setting features as columns '0' to '1274' to omit ID and pubchem ID","d4a9d467":"# Model 2 using SGD as the optimizer","6e04ce5e":"# Model 3 using softmax as the activation function","46d1d5be":"# Creating the testing and training data split and defining 10-folds for CV","535793db":"# Submitting model 2 - best MSE\n- Also the model that gave me the best score upon multiple submissions, used 1000 epochs for submission*","4ac2e3f9":"# Import Statements","c40f0bc6":"# Getting an understanding of the training and testing data"}}