{"cell_type":{"988b1c8e":"code","1536edb6":"code","4aec0165":"code","4186d2ea":"code","bf2c122d":"code","b94e077c":"code","9bed90d4":"code","993a832f":"code","0674ed87":"code","4936ca95":"code","5da2f5fb":"code","49d37dff":"code","99cc02c3":"code","a857a2f0":"code","2f4a8579":"code","020656ea":"code","9a1a9652":"code","d454bd64":"code","4596784d":"code","60642160":"code","bea161dc":"code","18530d6f":"code","896218d0":"code","ee55e7f4":"code","914783e6":"code","dd0f568b":"code","fad44ed6":"code","5ffd431b":"code","e04eaeed":"code","99257468":"code","c6638c52":"code","b8ce1811":"markdown","dfb31c5a":"markdown","de12ae32":"markdown","18e1ad44":"markdown","e2c7ae30":"markdown","f927de35":"markdown","4f36be15":"markdown","09a05b08":"markdown"},"source":{"988b1c8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1536edb6":"df=pd.read_csv('..\/input\/regression-with-neural-networking\/concrete_data.csv')","4aec0165":"df.head()","4186d2ea":"df.shape","bf2c122d":"df.isnull().sum()","b94e077c":"x=df.iloc[:,:-1]","9bed90d4":"x.head()","993a832f":"y=df.iloc[:,-1]","0674ed87":"y.head()","4936ca95":"import keras","5da2f5fb":"from keras.models import Sequential\nfrom keras.layers import Dense","49d37dff":"n=len(x.columns)","99cc02c3":"n","a857a2f0":"def regression_model():\n    model=Sequential()\n    model.add(Dense(10,activation='relu',input_shape=(n,)))\n    model.add(Dense(1))\n    \n    model.compile(optimizer='adam',loss='mean_squared_error')\n    return model","2f4a8579":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n","020656ea":"reg=regression_model()","9a1a9652":"reg.fit(xtrain,ytrain,epochs=50,verbose=1)","d454bd64":"loss_ans=reg.evaluate(xtest,ytest)\nloss_ans","4596784d":"from sklearn.metrics import mean_squared_error\n\nypred=reg.predict(xtest)\n\nres=np.sqrt(mean_squared_error(ypred,ytest))\n\nres","60642160":"reg.get_weights()","bea161dc":"total_mean_squared_errors = 50\nepochs = 50\nmean_squared_errors = []\nfor i in range(0, total_mean_squared_errors):\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=i)\n    reg.fit(X_train, y_train, epochs=epochs, verbose=0)\n    MSE = reg.evaluate(xtest, ytest, verbose=0)\n    print(\"MSE \"+str(i+1)+\": \"+str(MSE))\n    y_pred = reg.predict(xtest)\n    mean_square_error = mean_squared_error(ytest, y_pred)\n    mean_squared_errors.append(mean_square_error)\n\nmean_squared_errors = np.array(mean_squared_errors)\nmean = np.mean(mean_squared_errors)\nstandard_deviation = np.std(mean_squared_errors)\n\nprint('\\n')\nprint(\"Below is the mean and standard deviation of \" +str(total_mean_squared_errors) + \" mean squared errors without normalized data. Total number of epochs for each training is: \" +str(epochs) + \"\\n\")\nprint(\"Mean: \"+str(mean))\nprint(\"Standard Deviation: \"+str(standard_deviation))","18530d6f":"x = (x - x.mean()) \/ x.std()\nx.head()","896218d0":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n","ee55e7f4":"reg.fit(xtrain,ytrain,epochs=50,verbose=1)","914783e6":"ypred=reg.predict(xtest)\n\nres=np.sqrt(mean_squared_error(ypred,ytest))\n\nres","dd0f568b":"reg.fit(xtrain,ytrain,epochs=100,verbose=1)","fad44ed6":"ypred=reg.predict(xtest)\n\nres=np.sqrt(mean_squared_error(ypred,ytest))\n\nres","5ffd431b":"def regression_model():\n    model=Sequential()\n    model.add(Dense(10,activation='relu',input_shape=(n,)))\n    model.add(Dense(16,activation='relu'))\n    model.add(Dense(24,activation='relu'))\n    model.add(Dense(1))\n    \n    model.compile(optimizer='adam',loss='mean_squared_error')\n    return model","e04eaeed":"reg=regression_model()","99257468":"reg.fit(xtrain,ytrain,epochs=100,verbose=1)","c6638c52":"ypred=reg.predict(xtest)\n\nres=np.sqrt(mean_squared_error(ypred,ytest))\n\nres","b8ce1811":"**Now we can say that the model with more number of hidden layers give better performance in this problem case**","dfb31c5a":"# C. Increase the no of epochs ","de12ae32":"# B. Normalise the data","18e1ad44":"# Regression model using Keras","e2c7ae30":"# Mean squared error","f927de35":"****The loss is less when we increase the epochs****","4f36be15":"# Train test split","09a05b08":"# D. Increase the number of hidden layers"}}