{"cell_type":{"50c43435":"code","6dfe1113":"code","404a045f":"code","75f70e6d":"code","5091e5f8":"code","b6305999":"code","10b6c0c0":"code","504bed9b":"code","3678e61f":"code","9cf67e1e":"code","33b6941a":"code","aa0912d8":"code","8f436e17":"code","2940223a":"code","9facbb11":"code","475d8622":"code","831de32e":"code","2d55216c":"code","e300a438":"code","1c2c7496":"code","393d61da":"code","3da175c4":"code","2eef3d2c":"code","a7ff02ce":"code","1ab3314e":"code","400311e0":"code","9b8d4a9a":"code","f7c8bb0b":"code","91885cf5":"code","fb1975cd":"code","33c89a23":"code","64760432":"code","0ebcc4c9":"code","ab9a6290":"code","cfcd81c8":"code","97c401db":"code","94603d7f":"code","734dce40":"code","2788ce63":"code","39f91fad":"code","bbd06311":"code","4b170310":"code","e48f7097":"code","08375820":"code","4b979249":"code","837e0752":"markdown","ffa7cae6":"markdown","3eb09a5c":"markdown","37bdff2c":"markdown","ddbc6265":"markdown","e1e3bca6":"markdown","0531161d":"markdown","db5bfce7":"markdown","9e4c5576":"markdown","54fd7ead":"markdown","9ac7af4b":"markdown","b637d357":"markdown","31247618":"markdown","d691b15c":"markdown","70732771":"markdown","37730ed4":"markdown","222072a0":"markdown","f9375089":"markdown","66453e8b":"markdown","58f1259b":"markdown","19071b58":"markdown","6c7e964d":"markdown","b8d84557":"markdown","181bcb51":"markdown","9f71071b":"markdown","5c9567fe":"markdown","1b51d36d":"markdown","84dcde6e":"markdown","95db0b67":"markdown","38181986":"markdown","8d2ec743":"markdown","9e3436ed":"markdown","a50bb1e9":"markdown","8aff8398":"markdown","7c890ddb":"markdown"},"source":{"50c43435":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport logging\n\nimport os\n","6dfe1113":"from tqdm.auto import tqdm\ntqdm.pandas()","404a045f":"!ls \/kaggle\/input\/","75f70e6d":"!ls \/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/pdf_json | head -n 10","5091e5f8":"#!head \/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/pdf_json\/00623bf2715e25d3acacb3f210d6888ed840e3cb.json -n 200","b6305999":"!ls \/kaggle\/input\/covid-nlp-preprocess\/output","10b6c0c0":"!ls \/kaggle\/input\/covid-nlp-preprocess\/output\/paragraphs","504bed9b":"class COVDoc:\n    def __init__(self):\n        self.filepath_proc = None\n        self.filepath_orig = None\n        #self.basepath_orig = None\n        #self.text_proc = None\n        self.text_orig = None\n        self.abstract = None\n        self.tokenized_proc = None\n        self.doc_type = None\n    \n    #this function allows me to lazy-load the original text to save memory\n    def load_orig(self):\n        with open(self.filepath_orig) as f:\n            d = json.load(f)\n            body = \"\"\n            for idx, paragraph in enumerate(d[\"body_text\"]):\n                body += f\"{paragraph['text']}\\n\"\n            self.text_orig = body\n\n    def load_abstract(self):\n        with open(self.filepath_orig) as f:\n            d = json.load(f)\n            if \"abstract\" in d:\n                abstract_list = d[\"abstract\"]\n                if len(abstract_list) > 0:\n                    self.abstract = d[\"abstract\"][0][\"text\"]\n","3678e61f":"import glob, os, json\n\ndef load_docs(base_path, base_path_orig, doc_type):\n    loaded_docs = []\n    file_paths_proc = glob.glob(base_path)\n    file_names_proc = [os.path.basename(path) for path in file_paths_proc]\n    file_names_orig = [os.path.splitext(filename)[0]+\".json\" for filename in file_names_proc]\n    #file_paths_orig = [os.path.join(base_path_orig, filename) for filename in file_names_orig]\n    for idx, filepath_proc in enumerate(file_paths_proc):\n        doc = COVDoc()\n        doc.doc_type = doc_type\n        #doc.basepath_orig = base_path_orig\n        doc.filepath_proc = filepath_proc\n        filename = file_names_orig[idx]\n        if filename.startswith(\"PMC\"):\n            filepath = os.path.join(base_path_orig, \"pmc_json\", filename)\n        else:\n            filepath = os.path.join(base_path_orig, \"pdf_json\", filename)\n        doc.filepath_orig = filepath\n        with open(filepath_proc) as f:\n            d = f.read()\n            doc.tokenized_proc = d.strip().split(\" \")\n            if len(doc.tokenized_proc) < 2:\n                print(\"skipping doc due to no content:\"+filepath_proc)\n                continue\n            if \"PMC2114261\" in filename:\n                print(doc.filepath_proc)\n                print(doc.filepath_orig)\n            doc.tokenized_proc = [token for token in doc.tokenized_proc if (token != \"et\" and token != \"al\" and token != \"fig\") ]\n        loaded_docs.append(doc)\n    return loaded_docs","9cf67e1e":"!ls \/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\n","33b6941a":"!ls \/kaggle\/input\/covid-nlp-preprocess\/output\/whole","aa0912d8":"med_docs = load_docs(\"\/kaggle\/input\/covid-nlp-preprocess\/output\/whole\/biorxiv_medrxiv\/*.txt\", \"\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\", \"medx\")\nlen(med_docs)","8f436e17":"comuse_docs = load_docs(\"\/kaggle\/input\/covid-nlp-preprocess\/output\/whole\/comm_use_subset\/*.txt\", \"\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\", \"comm_user\")\nlen(comuse_docs)","2940223a":"noncom_docs = load_docs(\"\/kaggle\/input\/covid-nlp-preprocess\/output\/whole\/noncomm_use_subset\/*.txt\", \"\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\", \"noncomm\")\nlen(noncom_docs)","9facbb11":"custom_docs = load_docs(\"\/kaggle\/input\/covid-nlp-preprocess\/output\/whole\/custom_license\/*.txt\", \"\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\", \"custom\")\nlen(custom_docs)","475d8622":"#!cat \/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/pmc_json\/PMC5632742.xml.json\n#!cat \/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\/pdf_json\/94f6c2e70e777539702580b3afc0c2d45a4d57b0.json","831de32e":"#!ls kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/pdf_orig","2d55216c":"#https:\/\/www.machinelearningplus.com\/nlp\/gensim-tutorial\/\nfrom gensim.models import LdaModel, LdaMulticore\nfrom gensim import corpora\n\nall_docs = med_docs\nall_docs.extend(comuse_docs)\nall_docs.extend(noncom_docs)\nall_docs.extend(custom_docs)\n\ndoc_tokens = [doc.tokenized_proc for doc in all_docs]\n\n#id to word mapping for gensim\nid2word = corpora.Dictionary(doc_tokens)","e300a438":"corpus = [id2word.doc2bow(text) for text in doc_tokens] ","1c2c7496":"del doc_tokens","393d61da":"#https:\/\/stackoverflow.com\/questions\/7016056\/python-logging-not-outputting-anything\n#for handler in logging.root.handlers[:]:\n#    logging.root.removeHandler(handler)\n#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n","3da175c4":"#test_lda = LdaMulticore(corpus,num_topics=2, id2word=id2word, iterations=500, passes=2) \n#sentence = 'i like red wine with steak'\n#sentence2 = [word for word in sentence.lower().split()] \n#test_lda[id2word.doc2bow(sentence2)]","2eef3d2c":"from gensim.models import CoherenceModel\ndef compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3): \n    \"\"\"\n    Compute c_v coherence for various number of topics\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respect \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in tqdm(range(start, limit, step)):\n        model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word, iterations=600, passes=2) \n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n#        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n    return model_list, coherence_values","a7ff02ce":"topic_count_start = 3\ntopic_count_step = 1\ntopic_count_limit = 10\n# Can take a long time to run.\nmodel_list, coherence_values = \\\n  compute_coherence_values(dictionary=id2word, corpus=corpus, texts=None, limit=topic_count_limit, start=topic_count_start, step=topic_count_step)\n#  compute_coherence_values(dictionary=id2word, corpus=corpus, texts=doc_tokens, limit=topic_count_limit, start=topic_count_start, step=topic_count_step)\n","1ab3314e":"coherence_values","400311e0":"import matplotlib.pyplot as plt \n%matplotlib inline\n# Show graph\nx = range(topic_count_start, topic_count_limit, topic_count_step)\nplt.plot(x, coherence_values) \nplt.xlabel(\"Num Topics\") \nplt.ylabel(\"Coherence score\") \nplt.legend((\"coherence_values\"), loc='best') \nplt.show()","9b8d4a9a":"topic_idx = np.argmax(coherence_values)\nprint(coherence_values[topic_idx]) \ntest_lda = model_list[topic_idx]\n","f7c8bb0b":"test_lda.num_topics","91885cf5":"topic_idx","fb1975cd":"n_topics = test_lda.num_topics\ncol_names = []\nfor x in range(n_topics):\n    topic_name = f\"Topic{x+1}\"\n    col_names.append((topic_name, \"Word\"))\n    col_names.append((topic_name, \"Weight\"))\n     ","33c89a23":"tw_df = pd.DataFrame()","64760432":"data = []\nfor x in range(n_topics):\n    top_words = test_lda.show_topic(x, 20)\n    words = []\n    weights = []\n    for word_weight in top_words:\n        words.append(word_weight[0])\n        weights.append(word_weight[1])\n    data.append(words)\n    data.append(weights)\n    tw_df[f\"Word{x+1}\"] = words\n    tw_df[f\"Weight{x+1}\"] = weights   ","0ebcc4c9":"tw_df.columns = pd.MultiIndex.from_tuples(col_names)","ab9a6290":"tw_df","cfcd81c8":"import heapq \n\ntop_docs = {} \n#first create placeholder lists for top 3 docs in each topic \nfor t in range(0, n_topics):\n    doc_list = [(-1,-1),(-1,-1),(-1,-1)] \n    heapq.heapify(doc_list)\n    top_docs[t] = doc_list\n#count variable in following is practically doc_id since the index is from 0 with increments of 1\ncount = 0\nfor doc in tqdm(corpus):\n    topics = test_lda[doc] \n    for topic_prob in topics:\n        topic_n = topic_prob[0]\n        topic_p = topic_prob[1]\n        top_list = top_docs[topic_n]\n        #count is document id, heapq sorts by first item in tuple\n        heapq.heappushpop(top_list, (topic_p, count))\n        #above pushes new item, pops lowest item. so pop itself if lowest..\n    count += 1","97c401db":"#print(top_docs)","94603d7f":"top_sorted = {}\nfor topic_id in top_docs:\n    heap = top_docs[topic_id]\n    sorted_topics = [heapq.heappop(heap) for _ in range(len(heap))] \n    print(str(topic_id)+\": \"+str(sorted_topics)) \n    top_sorted[topic_id] = sorted_topics\n","734dce40":"topic_names = [f\"Topic{x+1}\" for x in range(n_topics)]\nword_names = [f\"Word{x+1}\" for x in range(3)]\n\ntop_doc_weights = []\ntop_doc_paths = []\n\npd.options.display.max_colwidth = 100\n\nfor topic_id in top_sorted:\n    top_docs = top_sorted[topic_id]\n    doc_ids = [doc_tuple[1] for doc_tuple in top_sorted[topic_id]] \n    doc_weights = [doc_tuple[0] for doc_tuple in top_sorted[topic_id]]\n    topic_docs = [all_docs[doc_id] for doc_id in doc_ids]\n    for x in range(3):\n        doc = topic_docs[x]\n        doc_path = f\"{doc.doc_type}\/{os.path.basename(doc.filepath_orig)}\"\n        weight = doc_weights[x]\n        top_doc_weights.append(weight)\n        top_doc_paths.append(doc_path)\ntop_doc_weights.reverse()\ntop_doc_paths.reverse()\n","2788ce63":"df = pd.DataFrame()\ndf[\"weight\"] = top_doc_weights\ndf[\"path\"] = top_doc_paths\ndf.index = pd.MultiIndex.from_product([topic_names,\n                                     ['Doc1', 'Doc2', 'Doc3']],\n                                    names=['',''])\ndf","39f91fad":"for topic_id in top_sorted:\n    print()\n    print()\n    print(f\"----------- TOPIC {topic_id}: -----------\")\n    top_docs = top_sorted[topic_id]\n    doc_ids = [doc_tuple[1] for doc_tuple in top_sorted[topic_id]] \n    doc_weights = [doc_tuple[0] for doc_tuple in top_sorted[topic_id]]\n    topic_docs = [all_docs[doc_id] for doc_id in doc_ids]\n    for x in range(3):\n        print(f\"----------- TOPIC {topic_id} \/ doc {x+1}: -----------\")\n        doc = topic_docs[x]\n        doc.load_abstract()\n        doc.load_orig()\n        if doc.abstract != None:\n            print(doc.abstract)\n        else:\n            print(doc.text_orig[:400])\n","bbd06311":"!pip install --upgrade transformers","4b170310":"from transformers import pipeline","e48f7097":"summarizer = pipeline('summarization')\n#summarizer(TEXT_TO_SUMMARIZE)","08375820":"for topic_id in top_sorted:\n    print()\n    print()\n    print(f\"----------- TOPIC {topic_id}: -----------\")\n    top_docs = top_sorted[topic_id]\n    doc_ids = [doc_tuple[1] for doc_tuple in top_sorted[topic_id]] \n    doc_weights = [doc_tuple[0] for doc_tuple in top_sorted[topic_id]]\n    topic_docs = [all_docs[doc_id] for doc_id in doc_ids]\n    for x in range(3):\n        print(f\"----------- TOPIC {topic_id} \/ doc {x+1}: -----------\")\n        doc = topic_docs[x]\n        doc.load_orig()\n        weight = doc_weights[x]\n        print(f\"topic %:{weight}, document:{doc.filepath_orig}\")\n        #and this is the magic line doing the summary\n        print(summarizer(doc.text_orig, min_length=200, max_length=400))","4b979249":"for topic_id in top_sorted:\n    print()\n    print()\n    print(f\"----------- TOPIC {topic_id}: -----------\")\n    top_docs = top_sorted[topic_id]\n    doc_ids = [doc_tuple[1] for doc_tuple in top_sorted[topic_id]] \n    doc_weights = [doc_tuple[0] for doc_tuple in top_sorted[topic_id]]\n    topic_docs = [all_docs[doc_id] for doc_id in doc_ids]\n    combined_text = \"\"\n    for x in range(3):\n        print(f\"----------- TOPIC {topic_id} \/ doc {x+1}: -----------\")\n        doc = topic_docs[x]\n        doc.load_orig()\n        weight = doc_weights[x]\n        print(f\"topic %:{weight}, document:{doc.filepath_orig}\")\n        combined_text += \" \"+doc.text_orig\n        #and this is the magic line doing the summary\n    print(summarizer(combined_text, min_length=500, max_length=1000))","837e0752":"How many topics did we end up with choosing?","ffa7cae6":"Which model was it in the list of tried models?","3eb09a5c":"Thanks for the great libs HuggingFacers! Straight out of the HuggingFace examples:","37bdff2c":"Find the model with highest coherence:","ddbc6265":"Here we look at the top-3 documents in each topic, run the transformer-summarizer on them, and compare to the beginning of the doc itself (usually an abstract..). Lets see the beginning of the original doc itself first:","e1e3bca6":"Print and visualize the coherence results for the different model configurations:","0531161d":"# Summarizing Topic Models with Transformers\n\nThis kernel uses preprocessed data from [my earlier kernel](https:\/\/www.kaggle.com\/donkeys\/my-little-preprocessing). First, explore a bit of topic model parameters space, use the parameters to build matching topic models using [Gensim LDA](https:\/\/radimrehurek.com\/gensim\/auto_examples\/tutorials\/run_lda.html), finds the most representative documents for each topic, and summarizes those documents using [HuggingFace Transformers](https:\/\/github.com\/huggingface\/transformers). The idea was to look at possibility of summarizing topic models based on large sets of text, and whether reasonable topic models can be found, ...\n\n### Version History\n- v11 update preprocessing with April 17th set, fixed filepath indices, fix other minor issues \n- v10 updated preprocessing\n- v8 updated preprocessing\n- v4-5 update to new preprocessing, pmc docs\n- v3 clean up tokens from a few excess words id'd in v2, summarize top 3 \/ topic as one set for topic\n- v2 first public version. find topic count using coherence values, describe top 20 words\/tokens per topic, and top 3 documents per topic, summarize the top 3 \/ topic using transformers\n","db5bfce7":"## The Four Datasets","9e4c5576":"TQDM for progress bars in notebooks:","54fd7ead":"# Summarize with Transformers","9ac7af4b":"And as another viewpoint, try to summarize all top 3 documents in one for each topic:","b637d357":"# Read in the Data","31247618":"Well, I thought this was interesting.\n\nSometimes it looks like there are some issues with how the transformer summarizes longer texts. Most of the time it seems to pick a specific \"topic\" (no pun intended..:) and just write a piece on that. Great looking for automated generation though.\n\nAnd that's all folks. Not sure how useful it is for actual COVID research but it was an interesting start (for me) on the COVID docs..","d691b15c":"## Gensim (Hyper)Parameter Search","70732771":"# Gensim Processing and LDA Topic Modelling","37730ed4":"Collect all four datasets into one, and convert the documents into Gensim consumable format:","222072a0":"Visualize the topics in terms of their top words (words giving highest importance in the specific topic):","f9375089":"LDA Topic Models represent assignments of words in documents to different topics. Find the documents that are assigned most into each topic. Assume that those documents best represent that topic:","66453e8b":"If you like to play with a small, single instance model, try uncommenting below and play with the parameters.","58f1259b":"Gensim has a notion of [Topic Coherence](https:\/\/rare-technologies.com\/what-is-topic-coherence\/). The higher the coherence value, the better the topics should be. So I tried some different values to pick the best one (according to the coherence measure):","19071b58":"I am using a preprocessed dataset generated by my [other notebook](https:\/\/www.kaggle.com\/donkeys\/preprocess-input-docs-from-apr-17-upload-dataset), and uploaded as a [dataset](). This avoids some [memory issues](https:\/\/www.kaggle.com\/general\/142462#803723) that seem occut on Kaggle when using notebook outputs directly as inputs. This dataset has directories for \"paragraphs\" and \"whole\" documents. The first one hosts all docs split into paragraphs according to the original inputs. The second one has combined each document into one whole text file per document.","6c7e964d":"## Final Topic Models","b8d84557":"### Final Thoughts","181bcb51":"The following summarizes the 3 top documents per topic. These are the same ones I printed the beginning for earlier above. So perhaps compare the above short snippets (potential abstracts) to what summary the transformer provides:","9f71071b":"Again, as in preprocessing, I use a simple data structure to hold the different forms of the text in each doc:","5c9567fe":"This experiments with topic models of different sizes to see what kind of coherence it gives. The model with highest coherence is then used later. This loop here for now just runs a few different values, although I tried more earlier:","1b51d36d":"The details of the topics change a bit over runs due to random init state and similar factors. So cannot comment on exact detail as it might change on notebook run. But on a general level the topics seem to describe patient studies, patients in general, viruses, trials. Depending on how many we take. It seems that up to about 5 topics the set can be seen as providing quite coherent topics that are quite identifiable with some \"concept\".","84dcde6e":"Uncomment the cell below to enable Gensim logging to console. This shows at what point the topics start to converge, and how much they converge. So I found with 2 passes and about 250+ iterations they seemed to converge quite well (around 90%). So I went with that.. Just disabled this for public kernel because it produces a lot of spammy text.","95db0b67":"Function to load different datasets into memory, matching the preprocessed texts to their original files:","38181986":"# Find Top Documents\/Articles for Topics","8d2ec743":"Load all four datasets in preprocessed form, and capture reference to original, non-processed file:","9e3436ed":"### Most Coherent Topics","a50bb1e9":"Install the transformer libs:","8aff8398":"We are short on memory again, so clear everything when can:","7c890ddb":"The above shows two .txt files, and four directories under both paragraphs and whole dirs. The directories match those in the Kaggle input dataset for documents. Just the contents have been preprocessed to remove stopwords, lemmatize, clean up a bit. The .txt files contain a set of unrecognized words and their closest identified matching identified words. So one could update the preprocessor if there is a frequent typo, or similar, in the dataset documents.\n\nAnyway, for this kernel the important bits are in the four directories \/ folders. The preprocessed documents."}}