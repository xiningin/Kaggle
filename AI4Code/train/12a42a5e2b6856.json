{"cell_type":{"ce4e5298":"code","abf85cc4":"code","b27f4f7d":"code","bdfcba78":"code","6bb35dc8":"code","03fefe49":"code","c49036cc":"code","a9a1c017":"code","f9155e2e":"code","89129803":"code","bbaf7a84":"code","181c8392":"code","396d7e17":"code","d152013d":"code","ffee74a7":"code","31c4b9b2":"code","5d87d385":"code","28f9ead8":"code","e3a04112":"code","997ab513":"code","4c7d1bbc":"code","d0a09327":"code","41fd2084":"code","07d1cf68":"markdown","5a5f2a11":"markdown","6c5c4641":"markdown","ddf05e67":"markdown","5101e55d":"markdown","a668424c":"markdown","921f6b22":"markdown","04ea5dea":"markdown","48b65feb":"markdown","6f81b6aa":"markdown","a5698dfa":"markdown","9a85a3d0":"markdown","f0c23ef8":"markdown"},"source":{"ce4e5298":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abf85cc4":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 14, 8\nRANDOM_SEED = 42\nLABELS = [\"Normal\", \"Fraud\"]","b27f4f7d":"data = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","bdfcba78":"data.head()","6bb35dc8":"data.info()","03fefe49":"data.isnull().values.any()","c49036cc":"count_classes = pd.value_counts(data['Class'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot=0)\n\nplt.title(\"Transaction Class Distribution\")\n\nplt.xticks(range(2), LABELS)\n\nplt.xlabel(\"Class\")\n\nplt.ylabel(\"Frequency\")","a9a1c017":"## Get the Fraud and the normal dataset \n\nfraud = data[data['Class']==1]\n\nnormal = data[data['Class']==0]","f9155e2e":"print(fraud.shape,normal.shape)","89129803":"## We need to analyze more amount of information from the transaction data\n#How different are the amount of money used in different transaction classes?\nfraud.Amount.describe()","bbaf7a84":"normal.Amount.describe()","181c8392":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Amount per transaction by class')\nbins = 50\nax1.hist(fraud.Amount, bins = bins)\nax1.set_title('Fraud')\nax2.hist(normal.Amount, bins = bins)\nax2.set_title('Normal')\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\nplt.show();","396d7e17":"# We Will check Do fraudulent transactions occur more often during certain time frame ? Let us find out with a visual representation.\n\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Time of transaction vs Amount by class')\nax1.scatter(fraud.Time, fraud.Amount)\nax1.set_title('Fraud')\nax2.scatter(normal.Time, normal.Amount)\nax2.set_title('Normal')\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","d152013d":"## Take some sample of the data\n\ndata1= data.sample(frac = 0.1,random_state=1)\n\ndata1.shape","ffee74a7":"data1.shape","31c4b9b2":"#Determine the number of fraud and valid transactions in the dataset\n\nFraud = data1[data1['Class']==1]\n\nValid = data1[data1['Class']==0]\n\noutlier_fraction = len(Fraud)\/float(len(Valid))","5d87d385":"\nprint(outlier_fraction)\n\nprint(\"Fraud Cases : {}\".format(len(Fraud)))\n\nprint(\"Valid Cases : {}\".format(len(Valid)))","28f9ead8":"## Correlation\nimport seaborn as sns\n#get correlations of each features in dataset\ncorrmat = data1.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","e3a04112":"data1.head()","997ab513":"columns = data1.columns.tolist()\n# Filter the columns to remove data we do not want \ncolumns = [c for c in columns if c not in [\"Class\"]]\n# Store the variable we are predicting \ntarget = \"Class\"\n# Define a random state \nstate = np.random.RandomState(42)\nX = data1[columns]\nY = data1[target]\nX_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n# Print the shapes of X & Y\nprint(X.shape)\nprint(Y.shape)","4c7d1bbc":"\nclassifiers = {\n    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X), \n                                       contamination=outlier_fraction,random_state=state, verbose=0),\n    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n                                              leaf_size=30, metric='minkowski',\n                                              p=2, metric_params=None, contamination=outlier_fraction),\n    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n                                         max_iter=-1)\n   \n}","d0a09327":"type(classifiers)\n","41fd2084":"n_outliers = len(Fraud)\nfor i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"Local Outlier Factor\":\n        y_pred = clf.fit_predict(X)\n        scores_prediction = clf.negative_outlier_factor_\n    elif clf_name == \"Support Vector Machine\":\n        clf.fit(X)\n        y_pred = clf.predict(X)\n    else:    \n        clf.fit(X)\n        scores_prediction = clf.decision_function(X)\n        y_pred = clf.predict(X)\n    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != Y).sum()\n    # Run Classification Metrics\n    print(\"{}: {}\".format(clf_name,n_errors))\n    print(\"Accuracy Score :\")\n    print(accuracy_score(Y,y_pred))\n    print(\"Classification Report :\")\n    print(classification_report(Y,y_pred))","07d1cf68":"## Visualizations","5a5f2a11":"### Visualizing both the datasets (Fraud and normal)","6c5c4641":"## Define the outlier detection methods","ddf05e67":"## Correlations","5101e55d":"## Importing all the required librarires","a668424c":"### Using small fraction of dataset to easily run ","921f6b22":"### Seperating fraud and normal dataset","04ea5dea":"## Create independent and Dependent Features","48b65feb":"### Checking any null values","6f81b6aa":"### Loading the dataset","a5698dfa":"### Analyzing the dataset ","9a85a3d0":"## Feature Engineering","f0c23ef8":"## Evaluating the model using Isolation Forest, Local Outlier Factor(LOF), and SVM algorithm"}}