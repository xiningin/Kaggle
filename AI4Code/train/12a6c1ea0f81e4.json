{"cell_type":{"4dd17240":"code","a8dfb53d":"code","2f615e88":"code","5d5b5859":"code","a166464e":"code","f6acf8b8":"code","20bcdaa0":"code","46e1b28f":"code","833247de":"code","ca5e5633":"code","76e90a6d":"code","395cdb9b":"code","05f7e8f8":"markdown","160043f3":"markdown","4bf87e24":"markdown","c00b27c1":"markdown","dc557a77":"markdown","1899d3bf":"markdown","ffe7a821":"markdown","b5740c32":"markdown","ac88f63f":"markdown","91268f4f":"markdown","0c9531c3":"markdown","62562b9e":"markdown"},"source":{"4dd17240":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a8dfb53d":"# \u00c9 feito a leitura do dataset para treinamento do modelo\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain_data","2f615e88":"# Leitura do dataset de teste\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_data","5d5b5859":"#Do dataset de treinamento eu quero a previs\u00e3o de quem sobreviveu ou n\u00e3o\ny = train_data.Survived\n\nX = train_data.drop(columns=['Survived'])","a166464e":"# #Aqui separamos os dados de testes e avalia\u00e7\u00e3o\nfrom sklearn.model_selection import train_test_split\n\n\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, random_state = 0)","f6acf8b8":"# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\n\nX_full = X[my_cols].copy()\nX_test = test_data[my_cols].copy()\n\nprint(my_cols)","20bcdaa0":"train_X.head()","46e1b28f":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor)])\nX_train = clf.fit_transform(X_train)\nX_valid = clf.transform(X_valid)","833247de":"# XGBoost \nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier(n_estimators=1000, learning_rate=0.40, random_state=0)","ca5e5633":"# Treinando o modelo\nmodel.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)\n","76e90a6d":"from sklearn.metrics import mean_absolute_error\n\npredictions = model.predict(X_valid)\n\nprint(mean_absolute_error(y_valid, predictions))\n","395cdb9b":"X_full = clf.fit_transform(X_full)\nX_test = clf.transform(X_test)\n\nmodel.fit(X_full,y)\n\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","05f7e8f8":"Para a avalia\u00e7\u00e3o do modelo foi utilizado o m\u00e9todo Mean Absolute Error ou MAE.\nEsse m\u00e9todo mede a acuracia do modelo atrav\u00e9s da m\u00e9dia dos erros de cada previs\u00e3o, ou seja, ir\u00e1 o valor do erro para cada predi\u00e7\u00e3o atrav\u00e9s do seguinte c\u00e1lculo:\n> erro = valor real - valor da predicao\n\nE o MAE ser\u00e1 a m\u00e9dia desses valores.\n","160043f3":"### 6 - Predict","4bf87e24":"### 3 - Selecionar o Modelo","c00b27c1":"### 5 - Melhorando o modelo","dc557a77":"Nesse algoritmo eu dividi o dataset X (que \u00e9 o dataset de treinamento para a competi\u00e7\u00e3o) em dados para treino e avalia\u00e7\u00e3o, por\u00e9m para a competi\u00e7\u00e3o todo o dataset X deve ser utilizado para treinamento.","1899d3bf":"#### 4 - Avaliando o Modelo","ffe7a821":"O algoritmo para a competi\u00e7\u00e3o foi criada com base no processo\n1. Pegar os dados\n2. Preparar os dados\n3. Selecionar o modelo\n4. Avaliar Modelo\n5. Melhorar parametros\n6. Predi\u00e7\u00f5es","b5740c32":"### 2 - Preparando os dados","ac88f63f":"Fiz alguns testes usando o n_estimators e max_deth com outros valores, mas a configura\u00e7\u00e3o padrao do algoritmo teve melhor resultado. Uma melhoria que pode ser interessante \u00e9 o uso de pipeline.","91268f4f":"O passo a seguir \u00e9 obrigat\u00f3rio e gerado j\u00e1 pela pr\u00f3pria plataforma.\nBasicamente, est\u00e1 sendo feito os importes necess\u00e1rios para o desenvolvimento do algoritmo.","0c9531c3":"Esse modelo tem 15% de erro, ou seja, 85% de acur\u00e1cia para a Random Forest\nPara o XGBoost o MAE j\u00e1 \u00e9 menor","62562b9e":"### 1 - Pegar os dados"}}