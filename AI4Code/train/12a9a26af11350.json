{"cell_type":{"810cf0c3":"code","9034ec5e":"code","a84b63c9":"code","f07bae61":"code","8edb1575":"code","86a708b6":"code","ef284588":"code","bae4c9af":"code","2fbdc2e3":"code","226081e7":"code","fd8f3cfb":"code","3e477d4a":"code","db9ae8bc":"code","68199a52":"code","b5bb4d5c":"code","bcd8f62b":"code","e2645b2b":"code","c1ec9c34":"code","64e2849d":"code","87f4a66b":"code","daeff1db":"code","7b4a623b":"code","7787731b":"code","899937ea":"code","0b1213b7":"code","6ce4ac77":"code","c11f146a":"code","130eb465":"code","764c6903":"code","0543be08":"code","a4b85d5a":"code","fbf0cd0b":"markdown","c23d7c1f":"markdown","e20a7a6d":"markdown","578e24dc":"markdown","7bcad204":"markdown","cf357b87":"markdown","0d3c1c30":"markdown","9854559a":"markdown"},"source":{"810cf0c3":"# Import dependencies\nimport json # reading in source file\nimport re # regular expressions\nimport time\nimport pandas as pd\n# TODO Investigate \"SettingWithCopyWarning\" and refactor df assignments using .loc\npd.options.mode.chained_assignment = None","9034ec5e":"# Load data into dataframe\ndataDir = \"\/kaggle\/input\/imdb-review-dataset\/\" \nfiles_to_load = [\"part-01.json\", \"part-02.json\", \"part-03.json\", \"part-04.json\", \"part-05.json\", \"part-06.json\"]\nreviews_json = list()\n\nstartTime = time.time()\nfor current_file in files_to_load:\n    print(f\"Starting load of {current_file}...\")\n    with open(f\"{dataDir}\/{current_file}\", mode='r') as file:\n        new_reviews = json.load(file)\n        for review in new_reviews:\n            reviews_json.append(review)\n    print(f\"Finished load of {current_file} at {time.time() - startTime:.2f} total seconds elapsed\")\nprint(f\"Loading complete after {time.time() - startTime:.2f} seconds, {len(reviews_json):,} items in reviews_json\")\n\nreviews_total_count = len(reviews_json)\nprint(f\"Total reviews in the working data: {reviews_total_count:,}\")\n\n# Convert list of dicts to pandas dataframe\nreviews_df_raw = pd.DataFrame(reviews_json)","a84b63c9":"## LIMITED RESOURCES MODE: COMMENT OUT ABOVE BLOCK AND UNCOMMENT BELOW BEFORE RUNNING NOTEBOOK\n#part_one_filepath = 'DataFolder\/part-01.json' # Replace with your filepath\n#with open(part_one_filepath, mode='r') as file:\n#    reviews_json = json.load(file)\n#\n## Remove the [...] piece below to test with the full ~1mil records in part-01.json\n#reviews_df_raw = pd.DataFrame(reviews_json[0:100000]) # Use 100,000 records, about 10% of first chunk","f07bae61":"# Peek at the data before we get started\nreviews_df_raw.head(10)","8edb1575":"# Remove uninteresting columns for efficiency\nreviews_df_raw.drop([\"review_id\", \"reviewer\", \"helpful\"], axis=1, inplace=True)","86a708b6":"# Check for na's\nreviews_df_raw.isna().sum()","ef284588":"# Remove na's from rating, the only col with na's\nraw_records_count = len(reviews_df_raw[\"movie\"])\n\nreviews_df_trim = reviews_df_raw[reviews_df_raw[\"rating\"].notna()]\ntrim_records_count = len(reviews_df_trim[\"movie\"])\n\npct_with_rating = trim_records_count \/ raw_records_count * 100\n\nprint(f\"After removing records with \\'na\\' rating {trim_records_count:,} remain out of original {raw_records_count:,} ({pct_with_rating:.2f}%)\") ","bae4c9af":"# Confirm removing na's was successful\nif reviews_df_trim.isna().sum().sum() == 0:\n    print(\"No remaining na's in working data.\")\nelse:\n    raise SystemExit(f\"\\'na\\' values still present: \\n{reviews_df_trim.isna().sum()}\")","2fbdc2e3":"# Check types of remaining columns so we know what to fix\n# \"object\" in python is ok for text (movie, review_summary, and review_detail)\n# Others we can correct as part of our initial cleaning\nreviews_df_trim.dtypes","226081e7":"# Cast ratings as int (safe now that NaNs have been removed)\nreviews_df_trim[\"rating\"] = reviews_df_trim[\"rating\"].astype(int)\n\nprint(\"ratings summary stats\")\nprint(\"Avg: \", reviews_df_trim[\"rating\"].mean())\nprint(\"Max: \", reviews_df_trim[\"rating\"].max())\nprint(\"Min: \", reviews_df_trim[\"rating\"].min())\nprint(\"Med: \", reviews_df_trim[\"rating\"].median())","fd8f3cfb":"# Cast spoiler_tag as boolean\nreviews_df_trim[\"spoiler_tag\"] = reviews_df_trim[\"spoiler_tag\"] == 1\nspoiler_value_counts = reviews_df_trim[\"spoiler_tag\"].value_counts()\ncurrent_records_count = len(reviews_df_trim[\"spoiler_tag\"])\nspoiler_count = spoiler_value_counts[1]\nspoiler_pct = spoiler_count \/ current_records_count * 100\nprint(f\"Out of {current_records_count:,} reviews {spoiler_count:,} are spoilers ({spoiler_pct:.2f}%)\\n\")\nprint(spoiler_value_counts)","3e477d4a":"# Cast review_date as datetime\nreviews_df_trim[\"review_date\"] = pd.to_datetime(reviews_df_trim[\"review_date\"])\n\nprint(\"review_date Summary Stats\")\nprint(\"Avg: \", reviews_df_trim[\"review_date\"].mean())\nprint(\"Max: \", reviews_df_trim[\"review_date\"].max())\nprint(\"Min: \", reviews_df_trim[\"review_date\"].min())","db9ae8bc":"# Check types once more to confirm recent changes\nprint(reviews_df_trim.dtypes)\n\n# Peek at data to check our progress\nreviews_df_trim.head()","68199a52":"# Separate Year using regular expressions\nyearPattern = r'(?:\\()(\\d{4})(?!\\-)?(?:\\d{4})?(?:\\sTV\\sMovie)?(?:\\sVideo)?(?:\\s?\\)$)(?!\\sSeason\\s\\d+\\,?\\sEpisode\\s\\d+$)' ","b5bb4d5c":"# Use regex to pull years from movie column\nyearExtract = reviews_df_trim[\"movie\"].str.extract(yearPattern)\nyearExtract.isna().sum()","bcd8f62b":"# Check records where not even one year was pulled through regex, these should all be shows\n# Need specify [0] here because regex returns a list (in this case a list of length 1) \n# Use list() on returned series to see full text of the column\nlist(reviews_df_trim[reviews_df_trim[\"movie\"].str.extract(yearPattern)[0].isna()][\"movie\"])[0:15]","e2645b2b":"# We've used regex to pull the year from every record that matches our formatting\n# We can now create a dataframe excluding all TV show reviews, by only taking records that match our regex  \nmovie_reviews_df = reviews_df_trim[reviews_df_trim[\"movie\"].str.extract(yearPattern)[0].notna()]\n\nbefore_regex_count = len(reviews_df_trim[\"movie\"])\nafter_regex_count = len(movie_reviews_df[\"movie\"])\npct_not_movie = after_regex_count \/ before_regex_count * 100\n\nprint(f\"After removing TV Series, {after_regex_count:,} reviews remain out of {before_regex_count:,} ({pct_not_movie:.2f}%).\")","c1ec9c34":"# Create year column to hold parsed year info\nmovie_reviews_df[\"year\"] = movie_reviews_df[\"movie\"].str.extract(yearPattern)[0]","64e2849d":"# Pull name from movies column\nnamePattern = r'^(.+)(?:\\s\\()'","87f4a66b":"# This pattern is simpler, so we'll just quickly check the regex is matching correctly\nnameExtract = movie_reviews_df[\"movie\"].str.extract(namePattern)\nnameExtract[0:10]","daeff1db":"# Create column to hold parsed Title info\nmovie_reviews_df[\"title\"] = movie_reviews_df[\"movie\"].str.extract(namePattern)\nmovie_reviews_df.head()","7b4a623b":"bad_titles_count = len(movie_reviews_df[movie_reviews_df[\"title\"].isna()])\nbefore_titles_cleaning_count = len(movie_reviews_df[\"title\"])\nif (bad_titles_count > 0):\n    print(f\"Bad titles detected: {bad_titles_count:,}\")\n    print(f\"Before dropping title na's: {before_titles_cleaning_count:,}\")\n    print(\"Dropping records with irregularly formatted names: \")\n    print(movie_reviews_df[movie_reviews_df[\"title\"].isna()][\"movie\"].value_counts()) # List to display all\n    movie_reviews_df.drop(movie_reviews_df[movie_reviews_df[\"title\"].isna()].index, inplace = True)\nelse:\n    print(\"No na values detected in title column.\")\n\nafter_titles_cleaning_count = len(movie_reviews_df[\"title\"])\nprint(f\"After cleaning steps: {after_titles_cleaning_count:,} reviews remaining out of initial {reviews_total_count:,}\")\nclean_reviews_df = movie_reviews_df","7787731b":"# Does the spread of ratings pass a sanity check?\nclean_reviews_df['rating'].plot(kind='hist')\nclean_reviews_df['rating'].describe()[1:]","899937ea":"# Which release years have the most review activity?\nclean_reviews_df.groupby(['year']).count()['movie'].sort_values(ascending=False).head()","0b1213b7":"# Overall stats of years with reviews in working data\nclean_reviews_df['year'] = clean_reviews_df['year'].astype(str).astype(int)\nclean_reviews_df['year'].describe()[1:] # \"count\", the first index, is excluded to keep the format nice","6ce4ac77":"# Verify oldest movie... chances are whoever is commenting on ancient film would mention how old it is\noldest_movie_review = clean_reviews_df.loc[clean_reviews_df[\"year\"] == clean_reviews_df['year'].describe()[\"min\"]]\nprint(list(oldest_movie_review[\"movie\"])[0])# List() is an easy way to display a long string inside a series\nlist(oldest_movie_review[\"review_detail\"])[0] # Use the [0] index in case there are multiple for the oldest movie","c11f146a":"# Verify newest movie... nothing releasing in 2022 should have a review, but maybe it's tied to something still shooting\nnewest_movie_review = clean_reviews_df.loc[clean_reviews_df[\"year\"] == clean_reviews_df['year'].describe()[\"max\"]]\nprint(list(newest_movie_review[\"movie\"])[0])\nlist(newest_movie_review[\"review_detail\"])[0]","130eb465":"# Create a 4.9gb .csv file in working folder, to be used for later EDA\nclean_reviews_df.to_csv(\"imdbReviewsClean.csv\", sep=\"\\t\", index = False)","764c6903":"# Which movies have the most reviews?\nmovie_review_value_counts = clean_reviews_df[\"title\"].value_counts()\nunique_movie_count = len(movie_review_value_counts)\nprint(f\"{unique_movie_count:,} unique movies\\n\")\nmost_reviewed_movie = movie_review_value_counts.head(1).index[0]\nmost_reviewed_movie_count = movie_review_value_counts.head(1)[0]\nprint(f\"Most reviewed movie in working data: {most_reviewed_movie} with {most_reviewed_movie_count:,} reviews.\\n\")\nprint(movie_review_value_counts.head(15))","0543be08":"# How concentrated is review activity?\nprint(\"Summary Stats: Count of Reviews per Unique Movie\")\nprint(movie_review_value_counts.describe()[1:]) # \"count\" below refers to total unique movies ","a4b85d5a":"# What % of movies recieves more than the avg. amount of reviews?\navg_reviews = movie_review_value_counts.describe()['mean']\nabove_avg_reviews = len(movie_review_value_counts[movie_review_value_counts > avg_reviews])\nprint(f\"Average review count per unique movie: {avg_reviews:.2f}\")\nprint(f\"Movies with above avg. review count: {above_avg_reviews:,} \/ {unique_movie_count:,} = {above_avg_reviews \/ unique_movie_count * 100:.2f}%\")","fbf0cd0b":"# Introduction\n## ETL of Enam Biswas's IMDb Largest Review Dataset\n## Goals:\n   * Automate the creation of a ready-to-analyze dataframe of relevant data from all six json sourcefiles\n   * Clean and explore the data to get a few summaries and identify points of interest for later analyses\n   * Keep kernel novice-friendly by explaining busy lines, printing results in plain english\n\nThis script creates a filtered dataframe excluding any reviews on TV series, and writes that to the working dir as imdbReviewsClean.csv (4.9gb).","c23d7c1f":"# TODO (Inspiration for EDA)\n\n## Questions for Clean Data\n\n  * Is there a correlation between average review rating and date of review?\n      * Do certain weekdays\/months\/holidays correlate to changes in average ratings?\n  * A minority of movies get most of the review activity, could we use a model to a predict if a movie to be in this minority?\n      * This might be more interesting after linking other movie data to use as predictors\n  * What are IMDB reviewers' \"highest ranked\" movies by average rating?\n  * Can we detect overlap between fandoms through reviewers who rate multiple titles?\n  * Who are the most prolific reviewers on IMDB? What % of all reviews are posted by these reviewers?\n  * What distinguishes a helpful review from one that gets voted unhelpful?\n      * Are there \"controversial\" reviews that have high amounts of votes both ways?\n      * What distinguishes reviews that generate engagement from those that receive few votes either way? \n\n## Wrangling Tasks\n\n  * Change pipeline to not drop ReviewerID and Helpful at start, to allow analysis on those columns\n      * Break Helpful column into helpful_votes and unhelpful_votes\n  * Connect this data with movie data from other sources, to link genre\/director\/actors\/release date info\n      * This data does not provide the IMBD ID (format \"tt1234567\") can we effectively match by Title\/Year?\n  * Create separate dataframe for analyzing reviews of ongoing\/finished shows\n      * How does avg. rating change over a season for a given show?\n      * Can we see public opinion turn against Game of Thrones as its last season aired?\n  * Create separate dataframe for analyzing reviews of of \"TV Movie\" or \"Video\" entries","e20a7a6d":"# Write Cleaned DataFrame to CSV","578e24dc":"# Feature Extraction with Regular Expressions\n\nMost common pattern: \"Title (2000)\" or \"Title (2000- )\" or \"Title (2000-2001)\"\n\nAlso common pattern is \"Title (2000) Season #, Episode #\"\n\nThere are weird ones like 'The West: The People (1500-1806) (1996) Season 1, Episode 1'\n\nAnother: 'Red Riding: The Year of Our Lord 1980 (2009 TV Movie)'\n\nAnother: 'The Adventures of Moby Dick (1996 Video)'\n\n\nThis is also a good opportunity to remove TV shows from our working data. We want to cut out TV shows, but TV Movies and Video should be kept.\nAny dashes in the year parsing indicate it's a show, and should not be carried forward in the analysis.\n\nIf you don't know anything about regular expressions, it's a way we can set abstract text patterns to pull specific data from many text objects at once. If you want to learn more about regular expressions or test different versions of this pattern, you can check out https:\/\/regexr.com\/ , which is what I used to test the patterns in this notebook.\n\nBelow, (?:\\d{4}) isn't strictly necessary but if we want to pull info about finished shows later (pattern \"(2000-2001)\") then we can change the hyphen group to non-capturing, and set the second year piece to capture.","7bcad204":"# Read Source Data","cf357b87":"# Trim Columns, Set Data Types","0d3c1c30":"# Sample EDA Questions","9854559a":"# Verify Cleaned Data"}}