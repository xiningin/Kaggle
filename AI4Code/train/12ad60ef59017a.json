{"cell_type":{"ae2fd7dc":"code","4506fc8c":"code","413b2223":"code","cb84ad48":"code","39365096":"code","3a717746":"code","ffb3751a":"code","c65297da":"code","163f0871":"code","8a3b6417":"code","6cb65120":"code","22297595":"code","40dd6f58":"code","84057f81":"code","682d7a1f":"code","209d9a95":"code","4ae9ceb6":"code","ca014597":"code","6a46f14a":"code","b3341fce":"code","cf716369":"code","0900698f":"code","e72277e6":"code","8ae4e2c5":"code","3eb17df6":"code","38b878c3":"code","3939fade":"code","a16c832d":"code","2781ef8b":"code","0fdb8f43":"markdown","f41f4d5f":"markdown","3dc6a0ba":"markdown","9250159c":"markdown","5a8340ab":"markdown","0492aefe":"markdown","30142d14":"markdown","7a343820":"markdown","5e7307bd":"markdown","3aa004b0":"markdown","05172c3e":"markdown","9f2d97a4":"markdown","8ae0acfc":"markdown","1cfcfc93":"markdown","79ad9338":"markdown","a0076936":"markdown","6d77823b":"markdown","64e5b57d":"markdown"},"source":{"ae2fd7dc":"!pip3 install ktrain","4506fc8c":"import warnings\nwarnings.filterwarnings(\"ignore\")","413b2223":"import numpy as np\nimport pandas as pd\nimport missingno as msno\nimport seaborn as sns\nimport plotly.graph_objects as go\n#import plotly.express as px\nimport matplotlib.pyplot as plt\nimport spacy\n\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom wordcloud import WordCloud, STOPWORDS \nimport ktrain\nfrom ktrain import text\n\nfrom collections import Counter","cb84ad48":"df = pd.read_csv('..\/input\/sentiment-analysis-for-financial-news\/all-data.csv', encoding='cp437', header=None)\ndf.head()","39365096":"df.columns = [\"Sentiment\", \"News\"]\ndf.head()","3a717746":"df.isnull().sum().any()","ffb3751a":"df.duplicated().sum()","c65297da":"df.drop_duplicates(inplace=True)","163f0871":"nlp = spacy.load('en')\n\ndef normalise(msg):\n    \n    doc = nlp(msg)\n    res = []\n    \n    for token in doc:\n        if token.is_stop or token.is_punct or token.is_space or not(token.is_oov): #Removing Stop words and words out of vocabulary\n            pass\n        else:\n            res.append(token.lemma_.lower())\n            \n    return res","8a3b6417":"df['News'] = df['News'].apply(normalise)\ndf.head()","6cb65120":"fig = go.Figure([go.Bar(x=df.Sentiment.value_counts().index, y=df.Sentiment.value_counts().tolist())])\nfig.update_layout(\n    title=\"Values in each Sentiment\",\n    xaxis_title=\"Sentiment\",\n    yaxis_title=\"Values\")\nfig.show()","22297595":"words_collection = Counter([item for sublist in df['News'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","40dd6f58":"word_string = \" \".join(words_collection)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=1500, \n                      width=1000,\n                      height=650\n                         ).generate(word_string)","84057f81":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","682d7a1f":"pos_df = df[df['Sentiment'] == 'positive']\nneg_df = df[df['Sentiment'] == 'negative']\nneu_df = df[df['Sentiment'] == 'neutral']","209d9a95":"words_collection = Counter([item for sublist in pos_df['News'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","4ae9ceb6":"word_string = \" \".join(words_collection)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=1500, \n                      width=500,\n                      height=650\n                         ).generate(word_string)","ca014597":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","6a46f14a":"words_collection = Counter([item for sublist in neg_df['News'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","b3341fce":"word_string = \" \".join(words_collection)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=1500, \n                      width=500,\n                      height=650\n                         ).generate(word_string)","cf716369":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","0900698f":"words_collection = Counter([item for sublist in neg_df['News'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","e72277e6":"word_string = \" \".join(words_collection)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=1500, \n                      width=500,\n                      height=650\n                         ).generate(word_string)","8ae4e2c5":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","3eb17df6":"le = LabelEncoder()\ndf['Sentiment'] = le.fit_transform(df['Sentiment'])\n\ndf['News'] = df['News'].apply(lambda m: \" \".join(m))\n\ndf.head()","38b878c3":"(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(df, \n                                                                    'News',\n                                                                    label_columns=['Sentiment'],\n                                                                   maxlen=500,\n                                                                    preprocess_mode='bert')","3939fade":"model = text.text_classifier(name='bert',\n                             train_data=(x_train, y_train),\n                             preproc=preproc)","a16c832d":"learner = ktrain.get_learner(model=model,\n                             train_data=(x_train, y_train),\n                             val_data=(x_test, y_test),\n                             batch_size=6)","2781ef8b":"learner.fit_onecycle(lr=2e-5,\n                     epochs=1)","0fdb8f43":"## Negative Sentiment Wordcloud","f41f4d5f":"Good that no null values are there <br>\n\nWhat about duplicates?","3dc6a0ba":"## Financial News Analysis using BERT\n\n<center><h1>Beware of little expenses, a small leak will sink a great ship<\/h1><\/center>","9250159c":"Just need to rename the columns now","5a8340ab":"**Let us split it up based on sentiment**","0492aefe":"# Packages Used","30142d14":"Data is ready :)","7a343820":"# Final Notes\n\nThings I might look to rectify is maybe give a better visualisation of the sentiments perhaps but I don't really know what exactly.","5e7307bd":"## Neutral Sentiment Wordcloud","3aa004b0":"## Any Null Values?","05172c3e":"Mostly normal stuff like \"communication\", \"network\", \"worker\" are said in neutral news.<br>\n\nLet's convert the sentiment values to numbers before and the lists to string as well before sending it to BERT","9f2d97a4":"**The numbers:**\n\nNeutral - 2879<br>\nPositve - 1363<br>\nNegative - 604<br>\n\nWe can map them to numbers before training.","8ae0acfc":"Out they go.","1cfcfc93":"## Positive Sentiment Wordcloud","79ad9338":"# Visuals in each Sentiment\n\n## Overall Representation ","a0076936":"# Training BERT\n\nOur data is ready, so let us know send it to BERT.","6d77823b":"# Text Cleaning","64e5b57d":"![michael-longmire-lhltMGdohc8-unsplash.jpg](attachment:michael-longmire-lhltMGdohc8-unsplash.jpg)\n\n<span>Photo by <a href=\"https:\/\/unsplash.com\/@f7photo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Michael Longmire<\/a> on <a href=\"https:\/\/unsplash.com\/s\/photos\/finance?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash<\/a><\/span>"}}