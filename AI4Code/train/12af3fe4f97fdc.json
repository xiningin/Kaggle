{"cell_type":{"097f1839":"code","b61927ea":"code","8cf1cee1":"code","cdcfbe6f":"code","704aaba1":"code","9b2ae77a":"code","b31fe9b7":"code","f15ad36e":"code","40146b77":"code","8a673b0a":"code","74825d99":"code","91673ae2":"code","fe555538":"code","833df30d":"code","1895e70e":"code","ab9fa3ea":"code","549bbbcc":"code","5c00bd9d":"code","972130db":"code","6b318a4f":"code","4b638f0a":"code","2555e18f":"code","3c6b0ad5":"code","b29fd635":"code","2492552f":"code","756fd754":"code","f39ae4b9":"code","2787b52c":"code","7900653a":"code","5965605c":"code","37dbe072":"code","a86118a5":"code","ebbc5e6f":"code","abeb7465":"code","9d7c1c49":"code","11b1863c":"code","7dce9a54":"code","59f06be8":"code","84df0088":"code","eb088ac0":"code","c93d2c1e":"code","ed9d11e2":"code","d108b634":"code","f0b899a8":"code","eec4f1a3":"code","d8d0a208":"code","d3cfe38e":"markdown","9c5dfca8":"markdown","332fcf60":"markdown","de98e823":"markdown","e15695a0":"markdown","bb0c3634":"markdown","1b80ba65":"markdown","1d02a421":"markdown","52daf2e7":"markdown","3df9c2ef":"markdown","00c2f35e":"markdown","6a04b801":"markdown"},"source":{"097f1839":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.head(5)","b61927ea":"df = df.drop(columns = [\"Time\"])","8cf1cee1":"from sklearn.preprocessing import StandardScaler\ndf[\"Amount\"] = StandardScaler().fit_transform(df[\"Amount\"].values.reshape(-1,1))","cdcfbe6f":"df.head(5)","704aaba1":"df.isnull().sum()","9b2ae77a":"X = df.drop(columns = [\"Class\"])\ny = df[\"Class\"]\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nx = y.value_counts().sort_index(ascending=False)\nprint(x)\nplt.bar([\"1\", \"0\"], list(x.values), color =[\"b\", \"r\"],width = 0.4)","b31fe9b7":"import time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier as knn_normal\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values.reshape(-1,1), test_size = 0.1)","f15ad36e":"frauds = df[df[\"Class\"] == 1]\nprint(X_train.dtype)\nX_train = X_train.astype(\"float32\")\nX_test = X_test.astype(\"float32\")\nfrauds = frauds.astype(\"float32\")\nprint(X_train.dtype)","40146b77":"t0 = time.time()\nknn = knn_normal(n_neighbors = 5)\nknn.fit(X_train, y_train)\nprint(confusion_matrix(y_test, knn.predict(X_test)))\ntime.time() - t0","8a673b0a":"import sys\n!cp ..\/input\/rapids\/rapids.21.06 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","74825d99":"import cuml\nt0 = time.time()\nfrom cuml.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ncf = confusion_matrix(y_test, knn.predict(X_test))\nprint(cf)\ntime.time() - t0","91673ae2":"from cuml.ensemble import RandomForestClassifier\nfrom cuml.linear_model import LogisticRegression\nfrom cuml.neighbors import KNeighborsClassifier\nfrom cuml.svm import SVC\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","fe555538":"f1_scores_fraud = {\"rf\" : \"\", \"lr\" : \"\", \"knn\": \"\",\"svc\": \"\"}\nf1_scores_non_fraud = {\"rf\" : \"\", \"lr\" : \"\", \"knn\": \"\",\"svc\": \"\"}\nfraud_only_acc = {\"rf\" : \"\", \"lr\" : \"\", \"knn\": \"\", \"svc\": \"\"}\nfrom sklearn.metrics import accuracy_score\ndef train_data(X_train,X_test,y_train,y_test):\n    lr = LogisticRegression()\n    rf = RandomForestClassifier(max_features=1.0,\n                   n_bins=8,\n                   n_estimators=40)\n    knn = KNeighborsClassifier(n_neighbors=10)\n    svc = SVC(kernel='poly', degree=2, gamma='auto', C=1)\n    \n    algorithms = {\"lr\" : lr, \"knn\" : knn, \"rf\": rf, \"svc\": svc}\n    \n    for key, a in algorithms.items():\n        print(key, \"trained\")\n        a.fit(X_train, y_train)\n    \n    for key, a in algorithms.items():\n        f1_scores_non_fraud[key] = float(classification_report(y_test, a.predict(X_test)).split()[7])\n        f1_scores_fraud[key] = float(classification_report(y_test, a.predict(X_test)).split()[12])\n        fraud_only_acc[key] = accuracy_score(frauds[\"Class\"], a.predict(frauds.drop(columns = [\"Class\"])))","833df30d":"f1_fraud = {}\nf1_non_fraud = {}\nfraud_acc = {}","1895e70e":"import time\ndef train(X_train, X_test, y_train, y_test):\n    t0 = time.time()\n    train_data(X_train, X_test, y_train, y_test)\n    print(\"Runtime(s) : \", time.time() - t0)\ntrain(X_train, X_test, y_train, y_test)","ab9fa3ea":"def plot_f1_scores(tag):\n    labels = f1_scores.keys()\n    for x in f1_scores.values():\n        non_fraud.append(x[0])\n        fraud.append(x[1])\n    x = np.arange(len(labels))  # the label locations\n    width = 0.35  # the width of the bars\n    fig, ax = plt.subplots()\n    rects1 = ax.bar(x - width\/2, f1_scores_non_fraud.values(), width, label='Non Fraud')\n    rects2 = ax.bar(x + width\/2, f1_scores_fraud.values(), width, label='Fraud')\n    # Add some text for labels, title and custom x-axis tick labels, etc.\n    ax.set_ylabel('Scores')\n    ax.set_title('F1 Scores')\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels)\n    ax.legend()\n    ax.bar_label(rects1, padding=3)\n    ax.bar_label(rects2, padding=3)\n    fig.tight_layout()\n    plt.show()\n    for key, val in f1_scores_fraud.items():\n        f1_fraud[key+ tag] = val\n    for key, val in f1_scores_non_fraud.items():\n        f1_non_fraud[key + tag] = val\nplot_f1_scores(\"_n\")","549bbbcc":"def plot_fraud_only(tag):\n    plt.bar(fraud_only_acc.keys(), fraud_only_acc.values(), color =[\"b\", \"r\", \"c\", \"m\", \"y\"],width = 0.4)\n    print(fraud_only_acc)\n    for key,value in fraud_only_acc.items():\n        fraud_acc[key + tag] = value\nplot_fraud_only(\"_n\")","5c00bd9d":"from imblearn.over_sampling import SMOTE\nsm = SMOTE()\nX_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\nzeros = len(y_train_sm[y_train_sm == 0])\nones = len(y_train_sm[y_train_sm == 1])\nplt.bar([\"0\", \"1\"], [zeros, ones] , color =[\"b\", \"r\"],width = 0.4)","972130db":"train(X_train_sm, X_test, y_train_sm, y_test)","6b318a4f":"plot_f1_scores(\"_smote\")","4b638f0a":"plot_fraud_only(\"_smote\")","2555e18f":"from imblearn.under_sampling import NearMiss\nnm = NearMiss(version = 1)\nX_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\nzeros = len(y_train_nm[y_train_nm == 0])\nones = len(y_train_nm[y_train_nm == 1])\nplt.bar([\"0\", \"1\"], [zeros, ones] , color =[\"b\", \"r\"],width = 0.4)","3c6b0ad5":"train_data(X_train_nm, X_test, y_train_nm, y_test)","b29fd635":"plot_f1_scores(\"_nearmiss\")","2492552f":"plot_fraud_only(\"_nearmiss\")","756fd754":"from imblearn.over_sampling import ADASYN\nada = ADASYN()\nX_train_ada, y_train_ada = ada.fit_resample(X_train, y_train)\nzeros = len(y_train_ada[y_train_ada == 0])\nones = len(y_train_ada[y_train_ada == 1])\nplt.bar([\"0\", \"1\"], [zeros, ones] , color =[\"b\", \"r\"],width = 0.4)","f39ae4b9":"train(X_train_ada, X_test, y_train_ada, y_test)","2787b52c":"plot_f1_scores(\"_adasyn\")","7900653a":"plot_fraud_only(\"_adasyn\")","5965605c":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(sampling_strategy='minority')\nX_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\nzeros = len(y_train_ros[y_train_ros == 0])\nones = len(y_train_ros[y_train_ros == 1])\nplt.bar([\"0\", \"1\"], [zeros, ones] , color =[\"b\", \"r\"],width = 0.4)","37dbe072":"train(X_train_ros, X_test, y_train_ros, y_test)","a86118a5":"plot_f1_scores(\"_ROS\")","ebbc5e6f":"plot_fraud_only(\"_ROS\")","abeb7465":"from imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(sampling_strategy='majority')\nX_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\nzeros = len(y_train_rus[y_train_rus == 0])\nones = len(y_train_rus[y_train_rus == 1])\nplt.bar([\"0\", \"1\"], [zeros, ones] , color =[\"b\", \"r\"],width = 0.4)","9d7c1c49":"train(X_train_rus, X_test, y_train_rus, y_test)","11b1863c":"plot_f1_scores(\"_RUS\")","7dce9a54":"plot_fraud_only(\"_RUS\")","59f06be8":"X_train_2 = pd.DataFrame(X_train.copy())\nX_train_2.insert(0, \"Potability\", y_train, True)\nzero  = X_train_2[X_train_2['Potability']==0]   \none = X_train_2[X_train_2['Potability']==1]  \nprint(len(zero), len(one))\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(one, replace = True, n_samples = len(zero)) \nX_train_2 = pd.concat([zero, df_minority_upsampled])\nfrom sklearn.utils import shuffle\nX_train_2 = shuffle(X_train_2) ","84df0088":"X_train_res = X_train_2.drop(columns = [\"Potability\"])\ny_train_res = X_train_2[\"Potability\"]\nplt.bar([\"0\", \"1\"], list(y_train_res.value_counts()), color =[\"b\", \"r\"],width = 0.4)","eb088ac0":"train(X_train_res, X_test, y_train_res, y_test)","c93d2c1e":"plot_f1_scores(\"_resample\")","ed9d11e2":"plot_fraud_only(\"_resample\")","d108b634":"f1_fraud = sorted(f1_fraud.items(), key = lambda x : x[1], reverse = True)\nf1_fraud = dict(f1_fraud)\nf1_fraud","f0b899a8":"fig = plt.figure(figsize=(30, 12), dpi=250)\nax = fig.add_axes([0,0,1,1])\nax.bar(f1_fraud.keys(),f1_fraud.values(), width = 0.5)\nfor label in ax.get_xticklabels():\n    label.set_ha(\"right\")\n    label.set_rotation(45)\n#plt.ylim(0.9, 1)\nplt.show()","eec4f1a3":"fraud_acc = sorted(fraud_acc.items(), key = lambda x : x[1], reverse = True)\nfraud_acc = dict(fraud_acc)\nfraud_acc","d8d0a208":"fig = plt.figure(figsize=(30, 12), dpi=250)\nax = fig.add_axes([0,0,1,1])\nax.bar(fraud_acc.keys(),fraud_acc.values(), width = 0.5)\nfor label in ax.get_xticklabels():\n    label.set_ha(\"right\")\n    label.set_rotation(45)\nplt.ylim(0.9, 1)\nplt.show()","d3cfe38e":"## 5. Random Under Sampling","9c5dfca8":"## 1.SMOTE","332fcf60":"SMOTE is an oversampling technique where the synthetic samples are generated for the minority class.","de98e823":"#### As you can see, CPU version takes 1 minutes but GPU version takes 6 seconds. We will train our data with GPU versions","e15695a0":"View data distribution in train dataset","bb0c3634":"## 7.Plot Results","1b80ba65":"## 6. Sklearn.utils.resample","1d02a421":"### Best Algorithm is KNearestNeighbor with Random Over Sampling Algorithm. It Gives nearly %98 accuracy only Fraud Cases. And 0,72 F1-Score for fraud cases on train dataset.","52daf2e7":"Okay we will not look f1-scores of non-fraud datas it's nearly 1 for every class. We will look f1-scores of fraud train-datas and accuries on only fraud datas.","3df9c2ef":"## 4. Random Over Sampling","00c2f35e":"## 2. NearMiss","6a04b801":"## 3. ADASYN"}}