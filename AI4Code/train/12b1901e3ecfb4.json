{"cell_type":{"1a468fe0":"code","314fdefb":"code","e1f78222":"code","1ee1ac20":"code","f2b2fc13":"code","72b9aa92":"code","a16e6d48":"code","5139488f":"code","eb4b8c27":"code","47224576":"code","6182da91":"code","d413103d":"code","a80c0d6a":"code","b148e400":"code","9b53c422":"code","057be56b":"code","0deb3f42":"code","e1e39313":"code","93791d4f":"markdown","8e59b00a":"markdown","07183bb4":"markdown","d1edaa7d":"markdown","07d97b93":"markdown","70d8d34c":"markdown","8936afc6":"markdown","cb14bd3e":"markdown","aab50ebd":"markdown","12f653b4":"markdown","b850b5d5":"markdown","ee7875ee":"markdown","46babf58":"markdown","e94e6b35":"markdown"},"source":{"1a468fe0":"import pandas as pd\nimport os\nos.listdir('\/kaggle\/input\/coleridgeinitiative-show-us-the-data')","314fdefb":"import pandas as pd\ndf_train=pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv')\ndf_train.head()","e1f78222":"print('Total rows in the train data set are :'+str(len(df_train)))","1ee1ac20":"for col in df_train.columns:\n    print(f\"{col}: {len(df_train[col].unique())}\")\n","f2b2fc13":"df_train['dataset_title'].value_counts()","72b9aa92":"df_test=pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv')\ndf_test","a16e6d48":"df_input = pd.DataFrame(columns=['id','section_title','text','data_label'])\nids=df_train['Id'].values\nimport warnings\nwarnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n#len(ids)\nfor id in ids:\n    df=pd.read_json ('..\/input\/coleridgeinitiative-show-us-the-data\/train\/{}.json'.format(id))\n    for data_label in df_train[df_train['Id']==id]['dataset_label'].values:\n        new_df=df[df['text'].str.contains(data_label)].copy(deep=True)\n        new_df.loc[:,['data_label']] = data_label\n        new_df.loc[:,['id']] = id\n        new_df.reset_index(inplace=True,drop=True)\n        df_input=pd.concat([df_input, new_df], ignore_index=True)\n        df_input.reset_index(inplace=True,drop=True)\n\n    ","5139488f":"df_input.head()","eb4b8c27":"df_input.isnull().sum()\n","47224576":"from wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport pickle\nimport pyLDAvis.sklearn\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6182da91":"words =list( df_input['data_label'].values)\nwords=[word.split() for word in words]","d413103d":"allwords = []\nfor wordlist in words:\n    allwords += wordlist\n#print(allwords)","a80c0d6a":"mostcommon = FreqDist(allwords).most_common(100)\nwordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\nfig = plt.figure(figsize=(30,10), facecolor='white')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 100 Most Common Words in Data Label', fontsize=50)\nplt.tight_layout(pad=0)\nplt.show()","b148e400":"mostcommon_small = FreqDist(allwords).most_common(25)\nx, y = zip(*mostcommon_small)\nplt.figure(figsize=(50,30))\nplt.margins(0.02)\nplt.bar(x, y)\nplt.xlabel('Words', fontsize=50)\nplt.ylabel('Frequency of Words', fontsize=50)\nplt.yticks(fontsize=40)\nplt.xticks(rotation=60, fontsize=40)\nplt.title('Freq of 25 Most Common Words in Data-Label', fontsize=60)\nplt.show()","9b53c422":"words =list( df_input['section_title'].values)\nstopwords=['ourselves', 'hers','the', 'between', 'yourself', 'but', 'again','of', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\nsplit_words=[]\nfor word in words:\n    lo_w=[]\n    list_of_words=str(word).split()\n    for w in list_of_words:\n        if w not in stopwords:\n            lo_w.append(w)\n    split_words.append(lo_w)\nallwords = []\nfor wordlist in split_words:\n    allwords += wordlist\nmostcommon = FreqDist(allwords).most_common(100)\nwordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\nfig = plt.figure(figsize=(30,10), facecolor='white')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 100 Most Common Words in Section Title', fontsize=50)\nplt.tight_layout(pad=0)\nplt.show()\n#print(allwords)\nmostcommon_small = FreqDist(allwords).most_common(25)\nx, y = zip(*mostcommon_small)\nplt.figure(figsize=(50,30))\nplt.margins(0.02)\nplt.bar(x, y)\nplt.xlabel('Words', fontsize=50)\nplt.ylabel('Frequency of Words', fontsize=50)\nplt.yticks(fontsize=40)\nplt.xticks(rotation=60, fontsize=40)\nplt.title('Freq of 25 Most Common Words in Section-Title', fontsize=60)\nplt.show()","057be56b":"df_test_input = pd.DataFrame(columns=['id','section_title','text'])\nids=df_test['Id'].values\nimport warnings\nwarnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n#len(ids)\nfor id in ids:\n    df=pd.read_json ('..\/input\/coleridgeinitiative-show-us-the-data\/test\/{}.json'.format(id))\n    df.loc[:,['id']] = id\n    df.reset_index(inplace=True,drop=True)\n    df_test_input=pd.concat([df_test_input, df], ignore_index=True)\n    df_test_input.reset_index(inplace=True,drop=True) ","0deb3f42":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\nsubmission_df = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv', index_col=0)\nsubmission_df","e1e39313":"df_test_input['length'] = df_test_input.text.str.len()\ndf_test_input =df_test_input[df_test_input.length > 0]\nsubmission_df = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv', index_col=0)\ndatasets_titles = [str(x).lower() for x in df_input['data_label'].unique()]\nimport re\nlabels = []\nfor index in submission_df.index:\n    publication_text = df_test_input[df_test_input['id'] == index].text.str.cat(sep='\\n').lower()\n    label = []\n    for dataset_title in datasets_titles:\n        if dataset_title in publication_text:\n            label.append(clean_text(dataset_title))\n    labels.append('|'.join(label))\n\nsubmission_df['PredictionString'] = labels\n\nsubmission_df.to_csv('submission.csv')\n\nsubmission_df","93791d4f":"### **Term Frequency Analysis of data-label**","8e59b00a":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background-color:#142B33; border:0' role=\"tab\" aria-controls=\"home\"><center>Overview of the Notebook<\/center><\/h2>\n\n* [Data Details](#1)\n* [Loading publication data from json files for given data-label and publication-id](#2)\n* [EDA on the loaded publication data](#3)\n* [Static data-label matching and submission](#4)\n","07183bb4":"<a id=\"2\"><\/a>\n<h2 style='background-color:#142B33; border:0; color:white'><center>Loading publication data from json files for given data-label and publication-id <center><h2>","d1edaa7d":"**There are no null values in the dataset.**","07d97b93":"**Some of the work in this notebook are created using the following notebook, if you like mine, then vist and like the following one as well**\nhttps:\/\/www.kaggle.com\/josephassaker\/coleridge-initiative-eda-na-ve-submission","70d8d34c":"<a id=\"1\"><\/a>\n<h2 style='background-color:#142B33; border:0; color:white'><center>Data Details <center><h2>","8936afc6":"### **Term Frequency Analysis of Section-Title**","cb14bd3e":"# **Coleridge Initiative - Show US the Data**\n\n![image.png](attachment:image.png)\n\n**Aim of the competition is to predict excerpts from the longer texts for each publication that appear to denote a data-set name or title**","aab50ebd":"<a id=\"4\"><\/a>\n<h2 style='background-color:#142B33; border:0; color:white'><center>Static data-label matching and submission <center><h2>","12f653b4":"### **Let\u2019s see if there are any null values present in our dataset:**","b850b5d5":"<a id=\"3\"><\/a>\n<h2 style='background-color:#142B33; border:0; color:white'><center>EDA on the loaded publication data <center><h2>","ee7875ee":"1. **Here we consider publication-id's from train-data frame and use it to read the json data from train folder.**\n\n2. **Each json file contains multiple sections, an example of one such id is shown below:**\n ![image.png](attachment:image.png)\n \n3. **We see that each json file\/ each publication-id has multiple sections with corresponding text-data, we are going to use this further.**\n \n4. **Above structure is leveraged to retrieve the section-name and its associated text by verifying if the text present in each of those section contains the data-label or not.**\n \n5. **Once we execute the above step, we filter for section-name whose section-text contains the data-label.**","46babf58":"**Similarly Let us Load the Test Data**","e94e6b35":"Data provided to us in this competition comprises of following 4 items:\n\n1. train.csv - This file comprises of publication-id and the associated data title and labels along with the cleansed label.\n2. train folder - This folder provides json file for each of the id's present in the above csv file, with each of the json file describing section-details of the publication and the associated text with it.\n3. sample_submission.csv - This file comprises of id, for which we must predict the data-set title.\n4. test folder - This folder provides json file for each of the id's present in test.csv file and the json file describes the section details of the publication and the associated text."}}