{"cell_type":{"23b24adb":"code","1209db90":"code","e9515093":"code","507f62eb":"code","02c7b0e4":"code","18ed52a7":"code","9e8082a1":"code","9cb6403c":"code","0598a350":"code","f6748b79":"code","a7ab46f2":"code","4d601222":"code","d55c5335":"code","8ebf4b86":"code","47489910":"code","2f81c5f8":"code","80022b4d":"code","23bfb970":"code","75920fb4":"code","790a0318":"code","c05de96d":"code","a11ea12b":"code","dfec5e7a":"markdown","1692fb01":"markdown","56d26974":"markdown","bfdc0727":"markdown","f9019f25":"markdown","90f82452":"markdown","3c7e33b0":"markdown","9c00df73":"markdown","3bd873e0":"markdown","00cc8c27":"markdown","174bf668":"markdown","cbb0a294":"markdown","0d8a7ad9":"markdown","7a7a3c17":"markdown","a4ff250f":"markdown"},"source":{"23b24adb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom IPython.display import display\nimport tqdm","1209db90":"train_dataset = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\nprint(\"Training dataset:\\n\")\ndisplay(train_dataset)","e9515093":"# checking if there are any duplicates:\ndup_rows = train_dataset[train_dataset.duplicated(['keyword','location','text','target'])]\ndisplay(dup_rows)\n\n# eliminating the duplicates:\ntrain_dataset.drop_duplicates(['keyword','location','text','target'], keep='first', inplace=True)\ndisplay(train_dataset)\nprint(\"Duplicates removed\")","507f62eb":"# eliminating junk values from 'keyword' in train set:\nempty_str=[]\nfor i in tqdm.tqdm(train_dataset['keyword']):\n    if i is np.NaN:\n        i=''\n    empty_str.append(i)\ntrain_dataset['keyword'] = empty_str\n\n# eliminating junk values from 'location' in train set:\nempty_str=[]\nfor i in tqdm.tqdm(train_dataset['location']):\n    if i is np.NaN:\n        i=''\n    empty_str.append(i)\ntrain_dataset['location'] = empty_str\n\ndisplay(train_dataset)","02c7b0e4":"new_train_dataset = train_dataset\ndetails=[]\n\nfor i in tqdm.tqdm(train_dataset['text']):\n    details.append(str(train_dataset.text[train_dataset.text == i].values[0])+\" \"+\n                       str(train_dataset.keyword[train_dataset.text == i].values[0])+\" \"+\n                           str(train_dataset.location[train_dataset.text == i].values[0]))\n\n# creating the new column 'details':\nnew_train_dataset['details'] = details\ndisplay(new_train_dataset)","18ed52a7":"# import statements:\nimport re   # to search for html tags, punctuations & special characters\n\n# importing gensim.models to implement Word2Vec:\nimport gensim\nfrom gensim import models\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\n\nfinal_clean_details = []\nlist_of_lists_details = []\n\n# Remove HTML tags - getting all the HTML tags and replacing them with blank spaces:\ndef cleanhtml(sentence):\n    clean_text = re.sub('<.*?>', ' ', sentence)\n    return clean_text\n\n# Remove punctuations & special characters - getting all the punctuations and replacing them with blank spaces:\ndef cleanpunc(sentence):\n    clean_text = re.sub(r'[@#$%\\^&\\*+=\\d]', r' ', sentence) # removing special characters\n    clean_text = re.sub(r'[,.;\\'\"\\-\\!?:\\\\\/|\\[\\]{}()]', r' ', clean_text) # removing punctuations\n    return clean_text\n\nfinal_clean_details = []\n\nfor sentence in tqdm.tqdm(new_train_dataset['details'].values):\n    sentence = cleanhtml(sentence)\n    sentence = cleanpunc(sentence)\n    clean_sentence = []\n    \n    # for each word in the sentence, if it is alphabetic, we append it to the new list\n    for word in sentence.split():\n        if word.isalpha() and len(word)>2:\n            clean_sentence.append(word.lower())\n    \n    cleansent = \" \".join(clean_sentence)\n    # for each review in the 'Text' column, we create a list of words that appear in that sentence and store it in another list. \n    # basically, a list of lists - because that's how the model takes the input while training:\n    final_clean_details.append(cleansent)\n    list_of_lists_details.append(clean_sentence)\n\n# creating another column with clean text:\nnew_train_dataset['clean_details'] = final_clean_details\nprint(\"Sentence cleaning completed\")\ndisplay(new_train_dataset)","9e8082a1":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# Bag of Words (BoW)\/ uni-gram:\nbow_model = CountVectorizer(min_df=3)\nbow_model = bow_model.fit(new_train_dataset['clean_details'])\nbow_vectors = bow_model.transform(new_train_dataset['clean_details'])\nprint(\"Shape of the BoW vectors: \", bow_vectors.shape)\n\n# bi-gram:\ngram_model = CountVectorizer(min_df=3, ngram_range=(1,2))\ngram_vectors = gram_model.fit_transform(new_train_dataset['clean_details'])\nprint(\"Shape of the bi-gram vectors: \", gram_vectors.shape)\n\n# TF-IDF (Term frequency - Inverse Document Frequency):\ntfidf_model = TfidfVectorizer(min_df=3, ngram_range=(1,3))\ntfidf_model = tfidf_model.fit(new_train_dataset['clean_details'])\ntfidf_vectors = tfidf_model.transform(new_train_dataset['clean_details'])\nprint(\"Shape of the TF-IDF vectors: \", tfidf_vectors.shape)","9cb6403c":"# importing gensim.models to implement Word2Vec:\nimport gensim\nfrom gensim import models\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\n\n# in the filename, 300 stands for 300 dimensions:\n# loading the model, this is a very high resource consuming task: \ng_trained_model = KeyedVectors.load_word2vec_format('..\/input\/googles-trained-word2vec-model-in-python\/GoogleNews-vectors-negative300.bin', binary=True)\nprint(\"Model loaded successfully: \", type(g_trained_model))","0598a350":"w2v_vec_sentence= []\n\nfor sentence in tqdm.tqdm(list_of_lists_details):\n    vec_sent = np.zeros(300)\n    for word in sentence:\n        if word in g_trained_model:\n            vec_word = g_trained_model[word]\n            vec_sent+=vec_word\n\n    vec_sent\/=len(sentence)\n    w2v_vec_sentence.append(vec_sent)\n\nprint(\"Avg. Word2Vec calculations completed!\")","f6748b79":"# creating a dictionary to store the IDF values and access them directly afterwards:\ntfidf_dict = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n\ntfidf_vec_sentence = []\ntfidf_features = tfidf_model.get_feature_names()\n\nfor sentence in tqdm.tqdm(list_of_lists_details):\n    vec_sent = np.zeros(300)\n    length_sent = len(sentence)\n    sum_tfidf_w2v_val = 0\n    sum_tfidf_val = 0\n    for word in sentence:\n        if word in g_trained_model and word in tfidf_dict.keys():\n            tfidf_val = (sentence.count(word)\/ length_sent) * tfidf_dict[word]  # calc.  TF * IDF\n            w2v_val = g_trained_model[word]  # calc.  Word2Vec\n            tfidf_w2v_val = tfidf_val * w2v_val  # calc. TF-IDF * Word2Vec\n            sum_tfidf_w2v_val += tfidf_w2v_val # summation of TF-IDF * Word2Vec\n            sum_tfidf_val += tfidf_val  # summation of TF * IDF\n         \n    if sum_tfidf_val == 0:\n            tfidf_vec_sentence.append(vec_sent)\n    try:\n        tfidf_vec_sentence.append(sum_tfidf_w2v_val\/ sum_tfidf_val) # (summation of TF-IDF * Word2Vec)\/ (summation of TF * IDF)\n    except:\n        pass\n    \nprint(\"TF-IDF weighted Word2Vec calculations completed!\")","a7ab46f2":"# Merging 'id' & 'target' for Avg. Word2Vec for train dataset:\nw2v_vec_array = np.asarray(w2v_vec_sentence)\nprint(type(w2v_vec_array))\nprint(w2v_vec_array.shape)\n\n#w2v_vec_array = np.hstack((w2v_vec_array, new_train_dataset['id'].values.reshape(7561,1)))\n#w2v_vec_array = np.hstack((w2v_vec_array, new_train_dataset['target'].values.reshape(7561,1)))\n#print(w2v_vec_array.shape)","4d601222":"target = new_train_dataset['target']\ntarget = target.values.reshape(7561,1)\nprint(type(target))\nprint(target.shape)","d55c5335":"# K-NN for Average Word2Vec:\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Splitting into training set & test set:\nx_train, x_test, y_train, y_test = train_test_split(w2v_vec_array, target, test_size=0.2, random_state=0)\nprint(\"Training set:\")\nprint(x_train.shape)\nprint(\"Testing set: \")\nprint(x_test.shape)\n\n# creating cross validation set out of train set:\n# x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n# print(\"Training set:\")\n# print(x_train.shape)\n# print(\"Validation set:\")\n# print(x_cv.shape)\n\n# NOTE - Try to split the x_train & y_train into x_cv, x_cv_test, y_cv & y_cv_test respectively since we are \n#        trying to find the best hyper-parameter 'aplha'\n\nfor i in range(1,20,2):\n    knn_classifier = KNeighborsClassifier(n_neighbors=i)\n    knn_classifier.fit(x_train, y_train.ravel())\n    pred_cv = knn_classifier.predict(x_test)\n    acc = accuracy_score(y_test, pred_cv)\n    print(\"Cross validation accuracy of Avg. weighted Word2Vec vectors using \", i,\"NN is: \", acc)","8ebf4b86":"# using 11-NN\nknn_classifier = KNeighborsClassifier(n_neighbors=11)\nknn_classifier = knn_classifier.fit(x_train, y_train)\nknn_preds = knn_classifier.predict(x_test)\n\n# Checking with confusion matrix:\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, knn_preds)\nimport seaborn as sns\nprint(\"Confusion matrix:\")\nsns.heatmap(data=cm, annot=True)","47489910":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(\"True positives: \", TP)\nprint(\"True negatives: \", TN)\nprint(\"False positives: \", FP)\nprint(\"False negatives: \", FN)\n\nacc = (TP+TN)\/(TP+TN+FP+FN)\nprecision = TP\/ (TP+FP)\nrecall = TP\/ (TP+FN)\nf1_score = 2*precision*recall\/ (precision + recall)\n\nprint(\"\\n=========Final performance evaluation=========\")\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F-1 Score: \", f1_score)\nprint(\"==============================================\")","2f81c5f8":"from sklearn.linear_model import LogisticRegression\n\nlr_classifier = LogisticRegression(dual=False, random_state=0, solver='liblinear')\nlr_classifier = lr_classifier.fit(x_train, y_train.ravel())\nlr_preds = lr_classifier.predict(x_test)\n\n# Checking with confusion matrix:\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, lr_preds)\nimport seaborn as sns\nprint(\"Confusion matrix:\")\nsns.heatmap(data=cm, annot=True)","80022b4d":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(\"True positives: \", TP)\nprint(\"True negatives: \", TN)\nprint(\"False positives: \", FP)\nprint(\"False negatives: \", FN)\n\nacc = (TP+TN)\/(TP+TN+FP+FN)\nprecision = TP\/ (TP+FP)\nrecall = TP\/ (TP+FN)\nf1_score = 2*precision*recall\/ (precision + recall)\n\nprint(\"\\n=========Final performance evaluation=========\")\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F-1 Score: \", f1_score)\nprint(\"==============================================\")","23bfb970":"from sklearn.svm import SVC\n\nlinSVM = SVC(kernel='rbf', random_state=0)\nlinSVM = linSVM.fit(x_train, y_train.ravel())\nlinSVM_preds = lr_classifier.predict(x_test)\n\n# Checking with confusion matrix:\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, linSVM_preds)\nimport seaborn as sns\nprint(\"Confusion matrix:\")\nsns.heatmap(data=cm, annot=True)","75920fb4":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(\"True positives: \", TP)\nprint(\"True negatives: \", TN)\nprint(\"False positives: \", FP)\nprint(\"False negatives: \", FN)\n\nacc = (TP+TN)\/(TP+TN+FP+FN)\nprecision = TP\/ (TP+FP)\nrecall = TP\/ (TP+FN)\nf1_score = 2*precision*recall\/ (precision + recall)\n\nprint(\"\\n=========Final performance evaluation=========\")\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F-1 Score: \", f1_score)\nprint(\"==============================================\")","790a0318":"from sklearn.naive_bayes import BernoulliNB\n\n# Splitting into training set & test set:\nx_train, x_test, y_train, y_test = train_test_split(bow_vectors, target, test_size=0.2, random_state=0)\nprint(\"Training set:\")\nprint(x_train.shape)\nprint(\"Testing set: \")\nprint(x_test.shape)\n\n# NOTE - Try to split the x_train & y_train into x_cv, x_cv_test, y_cv & y_cv_test respectively since we are \n#        trying to find the best hyper-parameter 'aplha'.\n\nfor i in range(1,10):\n    nb_class = BernoulliNB(alpha=i)\n    nb_class = nb_class.fit(x_train, y_train.ravel())\n    nb_preds = nb_class.predict(x_test)\n    acc = accuracy_score(y_test, nb_preds)\n    print(\"Cross validation accuracy of Avg. weighted Word2Vec vectors using Bernoulli NB, with aplha=\", i,\" is: \", acc)","c05de96d":"nb_class = BernoulliNB(alpha=2)\nnb_class = nb_class.fit(x_train, y_train)\nnb_preds = nb_class.predict(x_test)\n\n# Checking with confusion matrix:\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, nb_preds)\nimport seaborn as sns\nprint(\"Confusion matrix:\")\nsns.heatmap(data=cm, annot=True)","a11ea12b":"TP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\n\nprint(\"True positives: \", TP)\nprint(\"True negatives: \", TN)\nprint(\"False positives: \", FP)\nprint(\"False negatives: \", FN)\n\nacc = (TP+TN)\/(TP+TN+FP+FN)\nprecision = TP\/ (TP+FP)\nrecall = TP\/ (TP+FN)\nf1_score = 2*precision*recall\/ (precision + recall)\n\nprint(\"\\n=========Final performance evaluation=========\")\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F-1 Score: \", f1_score)\nprint(\"==============================================\")","dfec5e7a":"### 6. TF-IDF weighted Word2Vec:","1692fb01":"## Applying Logistic Regression:","56d26974":"## Applying Linear SVM:","bfdc0727":"### 5. Average weighted Word2Vec:","f9019f25":"### Eliminating the noisy data:","90f82452":"### Checking & eliminating the duplicates:","3c7e33b0":"## Applying Bernoulli Naive Bayes:","9c00df73":"## Importing the libraries & the dataset:","3bd873e0":"## Applying K-NN:","00cc8c27":"## Text pre-processing:","174bf668":"### 4. Word2Vec - Using Google's Word2Vec model for Vectorization:","cbb0a294":"## Conclusion - Bernoulli Naive Bayes with alpha**=2 seems to be the best choice for this problem.","0d8a7ad9":"## Featurization\/ Text data vectorization:\n\n1. Bag of Words(BoW)\/ uni-gram\n2. bi-gram\n3. TF-IDF (Term frequency - Inverse Document Frequency)\n4. Word2Vec (Creating the custom Word2Vec model)\n5. Avg. weighted Word2Vec\n6. TF-IDF weighted Word2Vec","7a7a3c17":"### 1. Bag of Words(BoW)\/ uni-gram:\n### 2. bi-gram\n### 3. TF-IDF (Term frequency - Inverse Document Frequency)","a4ff250f":"### Eliminating the junk\/ empty values:"}}