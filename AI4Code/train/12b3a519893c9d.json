{"cell_type":{"ac540a4d":"code","f61457c9":"code","bacc1860":"code","d9ab3091":"code","dff0c68f":"code","436e800a":"code","03cafde9":"code","32545bd3":"code","872e7aa7":"code","8d365d9a":"code","8770d5db":"code","401a6829":"code","d85d7815":"code","82975a3c":"markdown","766d8f01":"markdown","7547c093":"markdown","d22e4c64":"markdown","da64fef3":"markdown","55cf84b0":"markdown","33f46a2c":"markdown","8fd61903":"markdown","909df87c":"markdown","2f677527":"markdown","ce663f8c":"markdown","8e3f4e8e":"markdown","089d7f8a":"markdown","fcef9deb":"markdown","25000f82":"markdown","44f73489":"markdown","db18c70b":"markdown"},"source":{"ac540a4d":"import numpy as np \nimport matplotlib.pyplot as plt\nimport nibabel as nib\nimport cv2 as cv","f61457c9":"# Load the data\nfn = \"\/kaggle\/input\/hardi-reconstruction-challenge-2013\/DWIS_hardi-scheme_SNR-30.nii\"\nmri = nib.load(fn).get_fdata()\nprint(mri.shape)\n\n# Visualize data: slices of (x, y)\nfig, ax = plt.subplots(4, 4)\nfig.suptitle(\"Slices of HARDI data\")\nfor i in range(1, 5):\n    for j in range(1, 5):\n        ax[i-1,j-1].imshow(mri[:, :, i+j, 1])\n        \n# Choosing our image\nimage = mri[:, :, 25, 1]\nimage = cv.resize(image, (64, 64))\nimage = image \/ np.max(image)\nplt.figure()\nplt.imshow(image)\nplt.title(\"The image we will sparsify\")\n","bacc1860":"# Iteratively compute all wavelets by tiling wavelet resolutions      \ndef haar_tiling(waveres, imsize):\n    \n    sq_imsize = imsize ** 2\n    wavelets = np.ones((sq_imsize, 1))\n    \n    # For every resolution\n    for i in range(len(waveres)):\n\n        n_tiles = 4 ** i\n        tile_w = int(np.sqrt(n_tiles))\n        tile_size = np.round(imsize \/ (2 ** i))\n        \n        # Tile the wavelets\n        for j in range(n_tiles):\n            m = np.zeros(n_tiles)\n            m[j] = 1\n            m = m.reshape((tile_w, tile_w))\n            \n            # Generate the wavelet, vectorize and normalize it.\n            for h in waveres[i]:\n           \n                w = np.kron(m, h)\n                w = w.reshape((sq_imsize, 1))\n                w = w \/ np.max(w)\n                \n                wavelets = np.hstack((wavelets, w))\n         \n    return wavelets\n\n# Iteratively get all the wavelet resolutions\ndef haar_res(imsize, d):\n\n    waveres = []\n    while d > 1:\n        half = int(imsize \/ 2)\n\n        # Case 1: split horizontally\n        h1 = np.ones((imsize, imsize))\n        h1[half:, :] = -1\n\n        # Case 2: split vertically\n        h2 = np.ones((imsize, imsize))\n        h2[:, half:] = -1\n\n        # Case 3: split diagonally\n        h3 = np.ones((imsize, imsize))\n        h3[half:, :half] = -1\n        h3[:half, half:] = -1\n        \n        waveres.append([h1, h2, h3])\n        imsize = half\n        d = d-1\n           \n    return waveres\n\n# Generate a dictionary of haar wavelets\n# Input: imsize. The side length of a square image. Must be a power of 2.\n# Input: d. Controls the resolution of the wavelets.\n# Output: haardict. Dictionary of vectorized wavelets, dimensions are [imsize^2 x 4^d]\ndef haarDictionary(imsize, d):\n    waveres = haar_res(imsize, d)\n    haardict = haar_tiling(waveres, imsize)\n    return haardict\n","d9ab3091":"D = haarDictionary(64, 6)\nprint(D.shape)\n\nfig, ax = plt.subplots(4, 4)\nfig.suptitle(\"First 16 entries of our Haar Dictionary\")\nfor i in range(4):\n    for j in range(4):\n        h = D[:, j + 4*i].reshape((64, 64))\n        ax[i,j].imshow(h)","dff0c68f":"# Perform OMP on vectorized image\n# Returns error and support: for experimenting on \ndef OMPtest(image, D, k):\n\n    S = []\n    \n    r = image\n    r_err = [1]\n    \n    imnorm = np.linalg.norm(image)\n    \n    for i in range(k):\n        \n        # Find maximally correlated column of D\n        p = np.abs(D.T @ r)\n        j = np.argmax(p)\n        \n        # Update support, basis set\n        S.append(j)\n        Ds = D[:, S]\n        \n        # update estimate\n        x_hat = np.linalg.pinv(Ds) @ image\n        \n        # Compute residual\n        r = image - Ds @ x_hat\n        r_err.append(np.linalg.norm(r) \/ imnorm)\n\n    return S, x_hat, r_err\n            ","436e800a":"# This version of OMP only returns the representation\n# This code is for 3D Convolutional Dictionary Learning, presented later\ndef OMP(image, D, k):\n\n    S = []\n    r = image\n    \n    for i in range(k):\n        \n        # Find maximally correlated column of D\n        p = np.abs(D.T @ r)\n        j = np.argmax(p)\n        \n        # Update support, basis set\n        S.append(j)\n        Ds = D[:, S]\n        \n        # update estimate\n        x_hat = np.linalg.pinv(Ds) @ image\n        \n        # Compute residual\n        r = image - Ds @ x_hat\n\n    sol = np.zeros(D.shape[1])\n    sol[S] = x_hat\n    return sol\n            ","03cafde9":"im = image.reshape(64 * 64)\n\nK = [10, 50, 100, 200, 400]\nerr = [[] for i in range(5)]\nrec = [[] for i in range(5)]\n\nfor i in range(len(K)):\n    Supp, x_hat, err[i] = OMPtest(im, D, K[i])\n    rec[i] = D[:, Supp] @ x_hat\n\nfig, ax = plt.subplots(2, 3, figsize=(10, 10))\nfig.suptitle(\"OMP Reconstructions for varying K\")\n\nax[0, 0].imshow(image)\nax[0, 0].title.set_text(\"Original image\")\n\nax[0, 1].imshow(rec[0].reshape(64, 64))\nax[0, 1].title.set_text(\"Reconstruction, K = \" + str(K[0]))\n\nax[0, 2].imshow(rec[1].reshape(64, 64))\nax[0, 2].title.set_text(\"Reconstruction, K = \" + str(K[1]))\n\nax[1, 0].imshow(rec[2].reshape(64, 64))\nax[1, 0].title.set_text(\"Reconstruction, K = \" + str(K[2]))\n\nax[1, 1].imshow(rec[3].reshape(64, 64))\nax[1, 1].title.set_text(\"Reconstruction, K = \" + str(K[3]))\n\nax[1, 2].imshow(rec[4].reshape(64, 64))\nax[1, 2].title.set_text(\"Reconstruction, K = \" + str(K[4]))\n\n\nplt.figure()\nplt.plot(err[-1])\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Normalized Reconstruction Error\")\nplt.title(\"OMP Error over Iterations\")\n","32545bd3":"def ISTA(image, D, k, lambd, L):\n    \n    x_hat = np.zeros(D.shape[1])\n    err = []\n    imnorm = np.linalg.norm(image)\n    for i in range(k):\n        \n        # Compute error\n        err.append(np.linalg.norm(image - D @ x_hat) \/ imnorm)\n        \n        # Compute gradient update\n        x_hat += (-1\/L) * ( D.T @ (D @ x_hat - image) )\n        \n        # Apply soft thresholding\n        x_hat[x_hat > lambd] -= lambd\n        x_hat[x_hat < -1*lambd] += lambd\n        ind = np.where((x_hat <= lambd) & (x_hat >= -1*lambd))[0]\n        x_hat[ind] = 0\n        \n    return x_hat, err\n        \n        ","872e7aa7":"im = image.reshape(64 * 64)\nlambd = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n\nerr = [[] for i in range(5)]\nrec = [[] for i in range(5)]\nK = [[] for i in range(5)]\n\nfor i in range(len(lambd)):\n    x_hat, err[i] = ISTA(im, D, 200, lambd[i], 10000)\n    rec[i] = D @ x_hat\n    K[i] = len(x_hat) - len(np.where(x_hat == 0)[0])\n\nfig, ax = plt.subplots(2, 3, figsize=(10, 10))\nfig.suptitle(\"ISTA Reconstructions for varying lambda\")\n\nax[0, 0].imshow(image)\nax[0, 0].title.set_text(\"Original image\")\n\nax[0, 1].imshow(rec[0].reshape(64, 64))\nax[0, 1].title.set_text(\"Lambda = \" + str(lambd[0]) + \" K = \" + str(K[0]))\n\nax[0, 2].imshow(rec[1].reshape(64, 64))\nax[0, 2].title.set_text(\"Lambda = \" + str(lambd[1]) + \" K = \" + str(K[1]))\n\nax[1, 0].imshow(rec[2].reshape(64, 64))\nax[1, 0].title.set_text(\"Lambda = \" + str(lambd[2]) + \" K = \" + str(K[2]))\n\nax[1, 1].imshow(rec[3].reshape(64, 64))\nax[1, 1].title.set_text(\"Lambda = \" + str(lambd[3]) + \" K = \" + str(K[3]))\n\nax[1, 2].imshow(rec[4].reshape(64, 64))\nax[1, 2].title.set_text(\"Lambda = \" + str(lambd[4]) + \" K = \" + str(K[4]))\n\n\nplt.figure()\nfor i in range(5):\n    plt.plot(err[i])\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Normalized Reconstruction Error\")\nplt.title(\"ISTA Error over Iterations\")\nplt.legend([\"Lambda = \" + str(i) for i in lambd])\n\nplt.figure()\nplt.plot(K)\nplt.xlabel(\"-log(Lambda)\")\nplt.xticks([0, 1, 2, 3, 4], [\"5\",\"6\",\"7\",\"8\",\"9\"])\nplt.ylabel(\"Dimensionality\")\nplt.title(\"Representation Dimensionality for varying lambda\")","8d365d9a":"# Function to initialize the dictionary by sampling M random kxkxk patches from the data\n\ndef sample3DPatches(data, M, k):\n    (X, Y, Z, G) = data.shape\n    \n    patches = np.zeros((M, k*k*k))\n    \n    for i in range(M):\n        \n        x = np.random.randint(X - k + 1)\n        y = np.random.randint(Y - k + 1)\n        z = np.random.randint(Z - k + 1)\n        g = np.random.randint(G)\n        \n        patch = data[x:x+k, y:y+k, z:z+k, g]\n        patch = np.reshape(patch, k*k*k)\n        patch = patch \/ np.max(patch)\n        \n        patches[i] = patch  \n\n    return patches\n    ","8770d5db":"# Class to iterate through indices of a 3D convolution\n\nclass ConvIterator3D:\n        \n    def __init__(self, x_dim, y_dim, z_dim, ksize, stride=1):\n        self.ksize = ksize\n        self.stride = stride\n        self.x_max = x_dim - ksize + 1\n        self.y_max = y_dim - ksize + 1\n        self.z_max = z_dim - ksize + 1\n     \n    def __iter__(self):\n        self.x = 0\n        self.y = 0\n        self.z = 0\n        return self\n\n    def __next__(self):\n        \n        if self.z >= self.z_max:\n            raise StopIteration\n        \n        x, y, z = self.x, self.y, self.z\n        \n        self.x += self.stride\n        if self.x >= self.x_max:\n            self.y += self.stride\n            self.x = 0\n            \n        if self.y >= self.y_max:\n            self.z += self.stride\n            self.y = 0\n            \n        return (x, y, z)\n\n             \n        ","401a6829":"\"\"\"\nFunction to perform convolutional dictionary learning\nInput: X = data (nxnxn cube)\n       D = dictionary initialized from random patches (n_atoms * patch_size)\n       ksize = kernel size\n       max_iters = maximum number of iterations\nOutput:\n       gamma = sparse representation\n       \n\"\"\"\ndef convDictLearn(X, D, ksize, stride, max_iters, D_lr, OMP_K):\n    \n    # Set up parameters\n    conv_iter = ConvIterator3D(X.shape[0], X.shape[1], X.shape[2], ksize, stride)\n    n_atoms = D.shape[0]\n    n_patches = int(((X.shape[0] - ksize + 1) ** 3) \/ stride)\n    patch_size = ksize ** 3\n    imnorm = np.linalg.norm(X)\n\n    \n    # Initialize gamma, error\n    gamma = np.zeros((n_patches, n_atoms))\n    error = []\n    \n    for i in range(max_iters):\n        \n        # Solve sparse coding problem for each patch, incrementally compute reconstruction\n        X_hat = np.zeros(X.shape)\n        count = np.zeros(X_hat.shape)\n        \n        for j, idx in enumerate(iter(conv_iter)):\n            \n            patch = X[idx[0]:idx[0]+ksize,\n                      idx[1]:idx[1]+ksize,\n                      idx[2]:idx[2]+ksize]\n            \n            patch = np.reshape(patch, patch_size)\n            \n            gamma[j] = OMP(patch, D.T, OMP_K)\n            \n            rec = D.T @ gamma[j]            \n            X_hat[idx[0]:idx[0]+ksize,\n                  idx[1]:idx[1]+ksize,\n                  idx[2]:idx[2]+ksize] += np.reshape(rec, (ksize, ksize, ksize))\n            \n            count[idx[0]:idx[0]+ksize,\n                  idx[1]:idx[1]+ksize,\n                  idx[2]:idx[2]+ksize] += 1\n        \n        X_hat = X_hat \/ count\n        \n        # Compute residual\n        R = X - X_hat\n        error.append(np.linalg.norm(R) \/ imnorm)\n        \n        # Compute dictionary update\n        gradD = np.zeros(D.shape)\n        for j, idx in enumerate(iter(conv_iter)):\n            patch = R[idx[0]:idx[0]+ksize,\n                      idx[1]:idx[1]+ksize,\n                      idx[2]:idx[2]+ksize]\n            patch = np.reshape(patch, patch_size)\n            gradD -= D_lr * np.outer(patch, gamma[j]).T   \n        \n        D -= gradD\n        for j in range(D.shape[0]):\n            D[j] \/= np.max(D[j])\n        \n    return X_hat, D, gamma, error\n\n    ","d85d7815":"ksize = 10\nstride = 4\nmax_iters = 25\nD_lr = 0.01\nOMP_K = 4\n\nD = sample3DPatches(mri[:, :, :, 1:10], 1000, ksize)\n\nX = mri[:, :, :, 1]\nX \/= np.max(X)\n\nX_hat, D, gamma, error = convDictLearn(X, D, ksize, stride, max_iters, D_lr, OMP_K)\n\nfig, ax = plt.subplots(2, 3, figsize=(10, 10))\nfig.suptitle(\"3D CDL Reconstructions\")\n\nax[0, 0].imshow(X[25, :, :])\nax[0, 0].title.set_text(\"Original image: YZ slice\")\n\nax[0, 1].imshow(X[:, 25, :])\nax[0, 1].title.set_text(\"Original image: XZ slice\")\n\nax[0, 2].imshow(X[:, :, 25])\nax[0, 2].title.set_text(\"Original image: XY slice\")\n\nax[1, 0].imshow(X_hat[25, :, :])\nax[1, 0].title.set_text(\"Reconstructed image: YZ slice\")\n\nax[1, 1].imshow(X_hat[:, 25, :])\nax[1, 1].title.set_text(\"Reconstructed image: XZ slice\")\n\nax[1, 2].imshow(X_hat[:, :, 25])\nax[1, 2].title.set_text(\"Reconstructed image: XY slice\")\n\nplt.figure()\nplt.plot(error)\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Normalized Reconstruction Error\")\nplt.title(\"Error over iterations of 3D CDL\")\n\nnon_zeros = (((X.shape[0] - ksize) ** 3) \/ stride) * OMP_K\nsparsity = 1 -  (non_zeros \/ (X.shape[0] * X.shape[1] * X.shape[2]))\nprint(\"The sparsity of the reconstruction is \" + str(sparsity * 100) + \"%\")\n","82975a3c":"# Load and Visualize HARDI data\n\nHARDI data is comprised of two parts: spatial location and angular information. The first three dimensions of a HARDI tensor comprise the three spatial dimensions to form a voxel. The last dimension of a HARDI tensor comprises a list of intensities along various angular  directions. \n\nBelow, we visualize several slices of HARDI data along the XY plane. This data is of a silicone phantom, and was taken from the [2013 HARDI reconstruction challenge](http:\/\/hardi.epfl.ch\/static\/events\/2013_ISBI\/training_data.html#trainingdata). \n\nI also pick an image to reconstruct using a dictionary of Haar wavelets and sparse coding algorithms. I resized this image to 64x64 and normalized it to simplify later calculations.","766d8f01":"### Helper Functions","7547c093":"# Convolutional Dictionary Learning\n\nDictionary learning algorithms learn both the sparse representation and the dictionary itself, which can provide more accurate representations than if the dictionary was immutable. These algorithms work by iteratively holding the dictionary constant and updating the sparse representation, then holding the representation constant and updating the dictionary until convergence. \n\nConvolutional dictionary learning (CDL) is a novel method of dictionary learning particularly tuned for representing images. CDL works by splitting up the image into small patches, iteratively updating sparse representations for each patch and a dictionary of features until convergence, and stitching reconstructed patches back together to form an image. For more details on CDL, refer to this [paper](https:\/\/openaccess.thecvf.com\/content_CVPR_2019\/papers\/Zisselman_A_Local_Block_Coordinate_Descent_Algorithm_for_the_CSC_Model_CVPR_2019_paper.pdf).\n\nHere, CDL has been adapted to learn a 3D slice of HARDI data along 1 gradient. The algorithm is roughly described below:\n\n0. Let the 3D signal we want to represent be X, which has V voxels. \n1. Initialize a patch dictionary D by sampling M random kxkxk 3D patches from HARDI data, where k << cuberoot(V). \n    1. Each sample is vectorized, normalized, and stored in the dictionary.\n2. Until convergence or a maximum number of iterations:\n    1. For each kxkxk patch in X taken by 3D convolution:\n        1. gamma_j = The jth sparse representation of the jth 3D patch of X, computed using OMP.\n           Note that the convolution can be strided, since we don't need every signal patch to reconstruct all voxels.\n        2. Add gamma_j to the reconstructed signal X_hat. \n    2. Normalize X_hat so that each voxel is represented by the average of all reconstructed patches it lives in. \n    3. Compute the residual: R = X - X_hat\n    4. Compute the dictionary update\n        1. The update is done by gradient descent. The gradient is equal to the sum of gradients at each patch,\n           which is Rj * gamma_j.T, where Rj is the jth patch of the residual.\n\nThe sparsity of the representation, gamma, is determined by the number of patches considered and the sparsity per patch. The number of patches is determined by the kernel size of the convolution and the stride: a larger kernel and stride mean that fewer patches are needed to convolve over the data. The sparsity per patch is controlled by OMP. ","d22e4c64":"# Iterative Soft Thresholding Algorithm\n\nThe Iterative Soft Thresholding Algorithm (ISTA) is an iterative method to solve the LASSO problem. Essentially, since we can't use gradient descent directly due to the non-differentiability of the L1 norm, we use proximal gradient descent. This means at each iteration, we perform a gradient descent update and apply a proximal operator: soft thresholding. \n\n0. INITIALIZE: x_hat = zeros, step size = 1\/L, lambda is set appropriately\n1. FOR K iterations:\n    1. Compute gradient update. x_hat = x_hat - (1\/L) grad(f(x))\n    2. Apply Soft Thresholding Function to x_hat:\n        1. S(x_hat) = x_hat - lambda if x_hat > lambda\n        2. S(x_hat) = x_hat + lambda if x_hat < -lambda\n        3. S(x_hat) = 0 if -lambda <= x_hat <= lambda\n        \nThe result of this algorithm will be a sparse representation of the image solving the LASSO problem. Other flavours of this algorithm, such as FISTA, use tricks like line searches and interpolation to speed up convergence.","da64fef3":"# Conclusions\n\nIn this notebook, we generated sparse representations of 2D slices of HARDI image data with 2D Haar wavelets and sparse coding algorithms like OMP and ISTA. We could reduce the dimensionality of the data by around 75% while maintaining a decent representation of the original image. We also generated sparse representations of 3D slices of HARDI data using 3D convolutional dictionary learning. Again, we could compress the 3D slices by 60% without too much loss of information. \n\n### OMP vs ISTA\n\nAt first glance, OMP appears to provide the sparsest representation with the smallest error. However, as you probably realized after running this notebook, OMP takes far longer than ISTA to complete. This is because at each iteration, we must compute a pseudoinverse, which is computationally intensive task. When extrapolated to full scale HARDI image with much larger dictionaries, it is clear that reconstruction of HARDI data using OMP alone isn't feasible.\n\nISTA tackles a relaxed problem, LASSO, instead of the much harder P0 problem. Thus, the sparsity may be a little less and the overall error a little worse, but we achieve a marked improvement in speed. Since the whole point of sparsifying HARDI data is to achieve computational speedup, using an ISTA algorithm makes much more sense. However, ISTA must have a finely tuned choice of lambda to work well: too large and the representation will have high error, but too small and the representation won't be sparse.\n\n\n### 3D CDL\n\nThe 3D CDL algorithm we used in this notebook provides some promising results, as it could sparsify whole 3D sections without massive error. Interestingly, representations generated by 3D CDL appear \"smoothed\" as if a gaussian blur was convolved over the image - this may be an artifact of the averaging at each voxel over patches. \n\nThe 3D CDL algorithm might be extendable to 4D, sparsifying along the gradient directions as well. However, increasing the number of dimensions to convolve over sharply increases computational cost and could increase the lower bound of sparsity achievable, since we'd need an extra dimensions worth of parameters to keep track of. \n\nImprovements in this algorithm could also include a larger dictionary trained on a larger dataset, and alternative choices for sparse coding. I used OMP since I could directly control the sparsity and didn't need to use extra hyperparameters, but faster algorithms usch as ISTA or LARS are probably needed to scale up this approach. Finally, this algorithm can be parallelized quite easily: each sparse coding can be learned on a different thread, so this algorithm can take advantage of hardware speedups. \n\n\n### Ending notes\nSparse coding algorithms can greatly reduce the dimensionality of HARDI images, reducing the amount of computation required for each scan. Thus, sparse coding algorithms can hopefully help efforts to bring HARDI imaging technology to widespread use by reducing the currently infeasibly long scan times. \n","55cf84b0":"### Visualize OMP Reconstructions for various sparsity","33f46a2c":"### OMP Code","8fd61903":"### Generate and Visualize the Dictionary","909df87c":"# Orthogonal Matching Pursuit\n\nOrthogonal matching pursuit (OMP) is an iterative method of solving the P0 optimization problem: min ||Ax - b||^2 st ||x||_0 = k\n\nP0 is normally NP hard, so instead of searching combinatorially for the best support with cardinality k, we use a greedy iterative approach.\n\n0. INIT: residual = image, Support = {}\n1. FOR K iterations:\n    1. Find the atom (j) in the dictionary that is maximally correlated with the residual\n    2. Add the atom to the support (S = S U {j})\n    3. Select all the atoms from the dictionary currently in the support. Call that Ds.\n    4. Estimate the solution: x_hat = pinv(Ds) * image\n    5. Compute residual: r = image - Ds * x_hat\n    \nThe result of OMP is thus the K atoms of the dictionary with the best reconstruction of the image. ","2f677527":"# Imports","ce663f8c":"# 2D Haar Wavelets: Our Dictionary of Choice\n\nHaar wavelets are a family of rescaled \"square shaped\" functions that are commonly used to approximate signals .Similar to a fourier basis, any signal can be approximated as a linear combination of a basis comprised by these wavelets. Haar wavelets are generated essentially by recursively subdividing an interval and fitting a Haar wavelet in that fraction of an interval. \n\n#### 1D Haar Wavelet\n![image.png](attachment:image.png)\n\n2D Haar wavelets are tensor products of the 1D wavelets, naturally extending the \"square shape function\" into two dimensions. A square patch of space can be recursively subdivided into quadrants, and a vertical, horizontal, and diagonal wavelet can be fit into this quadrant. 2D Haar wavelets are commonly used to sparsify images, as images can be reconstructed using a linear combination of these wavelets. \n\n\nHere, we iteratively build a dictionary of Haar wavelets with which we will generate our sparse representations. First, we generate wavelets for every resolution, i.e. a wavelet for every subdivided quartet. Then, we fit these wavelets into their appropriate quadrants, vectorize the 2D space, and normalize to generate an entry of our 2D Haar basis. Thus, we generate a dictionary of size (imsize^2 x 4^(d-1)) where d controls how many subdivisions to do. ","8e3f4e8e":"# Sparse Reconstructions of HARDI images\n\nHigh angular resolution diffusion imaging (HARDI) is the state of the art diffusion MRI technique. Unfortunately, it is not widely adopted due to the ridiculously high dimensionality of its data, requiring infeasibly long compute times to process. However, sparse coding could help solve this issue by providing low dimensional representations of HARDI data, which would significantly cut the time required to compute these images. \n\nThis notebook demonstrates how to create sparse representations of HARDI images. First, 2D images were sparsified using using 2D Haar wavelets and the OMP and ISTA sparse coding algorithms. Next, 3D boxes were sparsified using 3D convolutional dictionary learning. Finally, I compare the speed and sparsity of these algorithms, and remark on their usefulness for HARDI data. ","089d7f8a":"### Results","fcef9deb":"### ISTA Code","25000f82":"### 3D convolutional dictionary learning code","44f73489":"### Code to generate the Dictionary","db18c70b":"### Visualize ISTA Recovery for varying lambda"}}