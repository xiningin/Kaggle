{"cell_type":{"e6cc2db1":"code","35c264f7":"code","704de0ef":"code","b85cfac1":"code","a5f17f94":"code","db8b59d5":"code","5cdb38be":"code","a765dc36":"code","0a530049":"code","a40feb4b":"code","5bfaf5b3":"code","e57c88e3":"code","8e60ef0f":"code","379aaaf4":"code","b6dd7402":"code","acb45cc8":"code","92f226f6":"code","fb879230":"code","d9687d3c":"code","6f8cc13d":"code","e25ed9f9":"code","13380762":"code","b89830d5":"code","14b1d48b":"code","5cb5c409":"code","f34cb041":"code","dfe7cf54":"code","285a7e45":"code","f87486e4":"code","ba697160":"code","fba6916e":"code","c6b1d5e0":"code","4b590f1c":"code","2ddb3dab":"markdown","910dedce":"markdown"},"source":{"e6cc2db1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35c264f7":"dataset = pd.read_json('\/kaggle\/input\/recipe-ingredients-dataset\/train.json')","704de0ef":"dataset.head()","b85cfac1":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (15,10))\nsns.countplot(dataset['cuisine'])\nplt.xticks(rotation = 90,fontsize = 12)","a5f17f94":"words = [' '.join(word) for word in dataset['ingredients']]\ndataset['ingredients2'] = words","db8b59d5":"dataset.head()","5cdb38be":"dataset.shape","a765dc36":"#Removing numbers ,puntuations and other special characters\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0,39774):\n    review = re.sub('[^a-zA-Z]',' ',dataset['ingredients2'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)\n#Same code below can also be used","0a530049":"dataset['ingredients modified'] = corpus","a40feb4b":"#This is regex which removes the digits\ns='1 1cool co1l coo1'\ns=re.sub(r\"(\\d)\", \"\", s)\nprint(s)","5bfaf5b3":"#This removes all types of brackets\ns='hi 1(bye)'\ns=re.sub(r'\\([^)]*\\)', '', s)\nprint(s)","e57c88e3":"#This removes the brand names\ns='hi 1 Marvel\u2122 hi'\ns=re.sub(u'\\w*\\u2122', '', s)\nprint(s)","8e60ef0f":"\n#This removes the stopwords\nimport re\nfrom nltk.corpus import stopwords\ns=\"I love this phone, its super fast and there's so much new and cool things with jelly bean....but of recently I've seen some bugs.\"\npattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\ns = pattern.sub('', s)\nprint(s)","379aaaf4":"#This removes the stopwords and tokenize the sentences\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n\nexample_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n\nstop_words = set(stopwords.words('english'))\n\nword_tokens = word_tokenize(example_sent)\n\nfiltered_sentence = [w for w in word_tokens if not w in stop_words]\n\nfiltered_sentence = []\n\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\n\nprint(word_tokens)\nprint(filtered_sentence)","b6dd7402":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(dataset['ingredients modified'])\n\nprint(X)","acb45cc8":"Cuisine_unique = dataset['cuisine'].unique()","92f226f6":"y = dataset.cuisine","fb879230":"cusine_dict = {Cuisine_unique[i]:i for i in range(0,len(Cuisine_unique))}\ninv_cusine_dict = {i:Cuisine_unique[i] for i in range(0,len(Cuisine_unique))}","d9687d3c":"cusine_dict","6f8cc13d":"inv_cusine_dict","e25ed9f9":"y = y.map(cusine_dict)","13380762":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)","b89830d5":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfor K in range(10):\n    K_value = K+1\n    neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n    neigh.fit(X_train, y_train) \n    y_pred = neigh.predict(X_test)\n    print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"% for K-Value:\",K_value)","14b1d48b":"neigh = KNeighborsClassifier(n_neighbors = 10, weights='uniform', algorithm='auto')\nneigh.fit(X_train, y_train) \ny_pred = neigh.predict(X_test)\nprint(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"%\")","5cb5c409":"from sklearn import svm\nlin_clf = svm.LinearSVC(C=1)\nlin_clf.fit(X_train, y_train)\ny_pred_svc=lin_clf.predict(X_test)\nprint(accuracy_score(y_test,y_pred)*100)","f34cb041":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(accuracy_score(y_test,y_pred)*100)","dfe7cf54":"from sklearn.linear_model import LogisticRegression\nlogisticRegr = LogisticRegression(max_iter=  1000)\nlogisticRegr.fit(X_train, y_train)\ny_pred = logisticRegr.predict(X_test)\nprint(accuracy_score(y_test,y_pred)*100)","285a7e45":"res = pd.DataFrame(y_pred_svc,columns =['Predicted'])","f87486e4":"df3=pd.DataFrame({'id':y_test.index, 'cuisine':y_test.values})\ny_test1=df3['cuisine'].tolist()\ny_test1","ba697160":"result=pd.DataFrame({'Actual Cuisine':y_test1, 'Predicted Cuisine':y_pred})\nprint(result)","fba6916e":"result['Actual Cuisine'] =result['Actual Cuisine'].map(inv_cusine_dict) ","c6b1d5e0":"result['Predicted Cuisine'] = result['Predicted Cuisine'].map(inv_cusine_dict)","4b590f1c":"result","2ddb3dab":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nparameter_candidates = [\n  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf','sigmoid']},\n]\nclf = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates, n_jobs=-1)\nclf.fit(X_train, y_train)   \nprint('Best score for data1:', clf.best_score_) \nprint('Best parameters:',clf.best_params_) ","910dedce":"import re\nl=[]\nfor s in df['ing']:\n    \n    #Remove punctuations\n    s=re.sub(r'[^\\w\\s]','',s)\n    \n    #Remove Digits\n    s=re.sub(r\"(\\d)\", \"\", s)\n    \n    #Remove content inside paranthesis\n    s=re.sub(r'\\([^)]*\\)', '', s)\n    \n    #Remove Brand Name\n    s=re.sub(u'\\w*\\u2122', '', s)\n    \n    #Convert to lowercase\n    s=s.lower()\n    \n    #Remove Stop Words\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(s)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n    filtered_sentence = []\n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n    s=' '.join(filtered_sentence)\n    \n    #Remove low-content adjectives\n    \n    \n    #Porter Stemmer Algorithm\n    words = word_tokenize(s)\n    word_ps=[]\n    for w in words:\n       word_ps.append(ps.stem(w))\n    s=' '.join(word_ps)\n    \n    l.append(s)\ndf['ing_mod']=l\n\nprint(df.head(10))"}}