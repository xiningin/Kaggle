{"cell_type":{"9c4c8712":"code","87dbb45c":"code","39259331":"code","41b6955f":"code","c79d79be":"code","fbe631c7":"code","b35cd056":"code","7506abb2":"code","c751258d":"code","81b7cd27":"code","46348b38":"code","8dbead35":"code","24861059":"code","22754e58":"code","ae528c9e":"code","28e18591":"code","f277aee5":"code","f824d7ed":"code","9579149d":"code","03401006":"code","ae601946":"markdown","ab1e87e9":"markdown","61a9caa6":"markdown","63e1e84f":"markdown","86059f79":"markdown","a22df19d":"markdown","a59d6fd6":"markdown","26587473":"markdown","0becd458":"markdown","ae0d94c1":"markdown","913dbdb0":"markdown","7e98bb74":"markdown","8c6d15c4":"markdown","2af39d9a":"markdown","9eec77bd":"markdown","ecb40124":"markdown","b70a5a51":"markdown"},"source":{"9c4c8712":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob\nimport os\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ndsb_data_dir = os.path.join('..', 'input')\nstage_label = 'stage1'","87dbb45c":"train_labels = pd.read_csv(os.path.join(dsb_data_dir,'{}_train_labels.csv'.format(stage_label)))\ntrain_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\ntrain_labels.sample(3)","39259331":"all_images = glob(os.path.join(dsb_data_dir, 'stage1_*', '*', '*', '*'))\nimg_df = pd.DataFrame({'path': all_images})\nimg_id = lambda in_path: in_path.split('\/')[-3]\nimg_type = lambda in_path: in_path.split('\/')[-2]\nimg_group = lambda in_path: in_path.split('\/')[-4].split('_')[1]\nimg_stage = lambda in_path: in_path.split('\/')[-4].split('_')[0]\nimg_df['ImageId'] = img_df['path'].map(img_id)\nimg_df['ImageType'] = img_df['path'].map(img_type)\nimg_df['TrainingSplit'] = img_df['path'].map(img_group)\nimg_df['Stage'] = img_df['path'].map(img_stage)\nimg_df.sample(2)","41b6955f":"%%time\ntrain_df = img_df.query('TrainingSplit==\"train\"')\ntrain_rows = []\ngroup_cols = ['Stage', 'ImageId']\nfor n_group, n_rows in train_df.groupby(group_cols):\n    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n    c_row['masks'] = n_rows.query('ImageType == \"masks\"')['path'].values.tolist()\n    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n    train_rows += [c_row]\ntrain_img_df = pd.DataFrame(train_rows)    \nIMG_CHANNELS = 3\ndef read_and_stack(in_img_list):\n    return np.sum(np.stack([imread(c_img) for c_img in in_img_list], 0), 0)\/255.0\ntrain_img_df['images'] = train_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])\ntrain_img_df['masks'] = train_img_df['masks'].map(read_and_stack).map(lambda x: x.astype(int))\ntrain_img_df.sample(1)","c79d79be":"n_img = 6\nfig, m_axs = plt.subplots(2, n_img, figsize = (12, 4))\nfor (_, c_row), (c_im, c_lab) in zip(train_img_df.sample(n_img).iterrows(), \n                                     m_axs.T):\n    c_im.imshow(c_row['images'])\n    c_im.axis('off')\n    c_im.set_title('Microscope')\n    \n    c_lab.imshow(c_row['masks'])\n    c_lab.axis('off')\n    c_lab.set_title('Labeled')","fbe631c7":"train_img_df['Red'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]))\ntrain_img_df['Green'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,1]))\ntrain_img_df['Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,2]))\ntrain_img_df['Gray'] = train_img_df['images'].map(lambda x: np.mean(x))\ntrain_img_df['Red-Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]-x[:,:,2]))\nsns.pairplot(train_img_df[['Gray', 'Red', 'Green', 'Blue', 'Red-Blue']])","b35cd056":"train_img_df['images'].map(lambda x: x.shape).value_counts()","7506abb2":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, UpSampling2D, Lambda\nsimple_cnn = Sequential()\nsimple_cnn.add(BatchNormalization(input_shape = (None, None, IMG_CHANNELS), \n                                  name = 'NormalizeInput'))\nsimple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\nsimple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n# use dilations to get a slightly larger field of view\nsimple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\nsimple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\nsimple_cnn.add(Conv2D(32, kernel_size = (3,3), dilation_rate = 3, padding = 'same'))\n\n# the final processing\nsimple_cnn.add(Conv2D(16, kernel_size = (1,1), padding = 'same'))\nsimple_cnn.add(Conv2D(1, kernel_size = (1,1), padding = 'same', activation = 'sigmoid'))\nsimple_cnn.summary()","c751258d":"from keras import backend as K\nsmooth = 1.\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\nsimple_cnn.compile(optimizer = 'adam', \n                   loss = dice_coef_loss, \n                   metrics = [dice_coef, 'acc', 'mse'])","81b7cd27":"def simple_gen():\n    while True:\n        for _, c_row in train_img_df.iterrows():\n            yield np.expand_dims(c_row['images'],0), np.expand_dims(np.expand_dims(c_row['masks'],-1),0)\n\nsimple_cnn.fit_generator(simple_gen(), \n                         steps_per_epoch=train_img_df.shape[0],\n                        epochs = 3)","46348b38":"%%time\ntest_df = img_df.query('TrainingSplit==\"test\"')\ntest_rows = []\ngroup_cols = ['Stage', 'ImageId']\nfor n_group, n_rows in test_df.groupby(group_cols):\n    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n    test_rows += [c_row]\ntest_img_df = pd.DataFrame(test_rows)    \n\ntest_img_df['images'] = test_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])\nprint(test_img_df.shape[0], 'images to process')\ntest_img_df.sample(1)","8dbead35":"%%time\ntest_img_df['masks'] = test_img_df['images'].map(lambda x: simple_cnn.predict(np.expand_dims(x, 0))[0, :, :, 0])","24861059":"n_img = 3\nfrom skimage.morphology import closing, opening, disk\ndef clean_img(x):\n    return opening(closing(x, disk(1)), disk(3))\nfig, m_axs = plt.subplots(3, n_img, figsize = (12, 6))\nfor (_, d_row), (c_im, c_lab, c_clean) in zip(test_img_df.sample(n_img).iterrows(), \n                                     m_axs):\n    c_im.imshow(d_row['images'])\n    c_im.axis('off')\n    c_im.set_title('Microscope')\n    \n    c_lab.imshow(d_row['masks'])\n    c_lab.axis('off')\n    c_lab.set_title('Predicted')\n    \n    c_clean.imshow(clean_img(d_row['masks']))\n    c_clean.axis('off')\n    c_clean.set_title('Clean')","22754e58":"from skimage.morphology import label # label regions\ndef rle_encoding(x):\n    '''\n    x: numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns run length as list\n    '''\n    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cut_off = 0.5):\n    lab_img = label(x>cut_off)\n    if lab_img.max()<1:\n        lab_img[0,0] = 1 # ensure at least one prediction per image\n    for i in range(1, lab_img.max()+1):\n        yield rle_encoding(lab_img==i)","ae528c9e":"_, train_rle_row = next(train_img_df.tail(5).iterrows()) \ntrain_row_rles = list(prob_to_rles(train_rle_row['masks']))","28e18591":"tl_rles = train_labels.query('ImageId==\"{ImageId}\"'.format(**train_rle_row))['EncodedPixels']","f277aee5":"match, mismatch = 0, 0\nfor img_rle, train_rle in zip(sorted(train_row_rles, key = lambda x: x[0]), \n                             sorted(tl_rles, key = lambda x: x[0])):\n    for i_x, i_y in zip(img_rle, train_rle):\n        if i_x == i_y:\n            match += 1\n        else:\n            mismatch += 1\nprint('Matches: %d, Mismatches: %d, Accuracy: %2.1f%%' % (match, mismatch, 100.0*match\/(match+mismatch)))","f824d7ed":"test_img_df['rles'] = test_img_df['masks'].map(clean_img).map(lambda x: list(prob_to_rles(x)))","9579149d":"out_pred_list = []\nfor _, c_row in test_img_df.iterrows():\n    for c_rle in c_row['rles']:\n        out_pred_list+=[dict(ImageId=c_row['ImageId'], \n                             EncodedPixels = ' '.join(np.array(c_rle).astype(str)))]\nout_pred_df = pd.DataFrame(out_pred_list)\nprint(out_pred_df.shape[0], 'regions found for', test_img_df.shape[0], 'images')\nout_pred_df.sample(3)","03401006":"out_pred_df[['ImageId', 'EncodedPixels']].to_csv('predictions.csv', index = False)","ae601946":"# Create Training Data\nHere we make training data and load all the images into the dataframe. We take a simplification here of grouping all the regions together (rather than keeping them distinct).","ab1e87e9":"# Load in all Images\nHere we load in the images and process the paths so we have the appropriate information for each image","61a9caa6":"# Loss\nSince we are being evaulated with intersection over union we can use the inverse of the DICE score as the loss function to optimize","63e1e84f":"## Calculate the RLEs for a Train Image","86059f79":"# Look at the intensity distribution\nHere we look briefly at the distribution of intensity and see a few groups forming, they should probably be handled separately. ","a22df19d":"# Show a few images\nHere we show a few images of the cells where we see there is a mixture of brightfield and fluorescence which will probably make using a single segmentation algorithm difficult","a59d6fd6":"## Check\nSince we made some simplifications, we don't expect everything to be perfect, but pretty close","26587473":"## Take the RLEs from the CSV","0becd458":"# Check Dimensions \nHere we show the dimensions of the data to see the variety in the input images","ae0d94c1":"## Making a simple CNN\nHere we make a very simple CNN just to get a quick idea of how well it works. For this we use a batch normalization to normalize the inputs. We cheat a bit with the padding to keep problems simple.","913dbdb0":"# Apply Model to Test\nHere we apply the model to the test data","7e98bb74":"# Calculate RLE for all the masks\nHere we generate the RLE for all the masks and output the the results to a table. We use a few morphological operations to clean up the images before submission since they can be very messy (remove single pixels, connect nearby regions, etc)","8c6d15c4":"## Show a few predictions","2af39d9a":"# Overview\nThe kernel goes through\n1. the preprocessing steps to load the data\n1. a quick visualization of the color-space\n1. training a simple CNN\n1. applying the model to the test data\n1. creating the RLE test data","9eec77bd":"# Simple Training\nHere we run a simple training, with each image being it's own batch (not a very good idea), but it keeps the code simple","ecb40124":"# Read in the labels\nLoad the RLE-encoded output for the training set","b70a5a51":"# Check RLE\nCheck that our approach for RLE encoding (stolen from [here](https:\/\/www.kaggle.com\/rakhlin\/fast-run-length-encoding-python)) works"}}