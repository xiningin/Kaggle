{"cell_type":{"f7018306":"code","f26afe50":"code","7d9ab978":"code","36ace37e":"code","2f077337":"code","45cf69b0":"code","14e2c8e1":"code","d4c8641c":"code","fd454389":"code","3ba22ef0":"code","97fa6fd1":"code","734e23ff":"code","9337437a":"code","6658547e":"code","97bd5546":"code","7e33d3ad":"code","11eb4ef4":"code","55e08872":"code","5b40906d":"code","1bcdc18a":"code","716c0b82":"code","1d6b6955":"code","5c1049fb":"code","0a4ec763":"code","5e324ce6":"code","aa1b89d4":"code","4f6900c5":"code","8f466b6c":"code","c7efebc0":"code","e39214f6":"code","58716e70":"code","1a21e54e":"code","d54d30a8":"code","572ac0f6":"code","7e688c89":"code","0893f000":"code","78536371":"code","31ae0c05":"code","29d37429":"code","10f97724":"code","b7b20c28":"code","421ed04e":"code","08834020":"code","6df41605":"code","96370f9f":"code","28bcb320":"code","b4a4ae4d":"code","26875305":"code","96ebf1a1":"code","6a486635":"code","bf98958c":"code","7d4db094":"code","47f4d812":"code","c5dbdebf":"code","521aba35":"code","e335c93a":"code","101bcf76":"code","984821de":"code","377c0eaa":"code","14748495":"code","d97a838b":"code","c1aa5eb9":"markdown","18df4ba1":"markdown"},"source":{"f7018306":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f26afe50":"# import dataset\ndata = pd.read_csv(\"\/kaggle\/input\/farmers-markets-in-the-united-states\/wiki_county_info.csv\")","7d9ab978":"data.head()","36ace37e":"print(data.shape)","2f077337":"usa = pd.read_csv(\"\/kaggle\/input\/farmers-markets-in-the-united-states\/farmers_markets_from_usda.csv\")","45cf69b0":"usa.head()","14e2c8e1":"usa.shape","d4c8641c":"data.describe()","fd454389":"# Check the total null values\ndata.isnull().sum()","3ba22ef0":"# county unique name\nprint(data[\"State\"].nunique())\nprint(data[\"State\"].duplicated().value_counts())","97fa6fd1":"# drop the number column\ndata.drop(\"number\", axis=1, inplace=True)","734e23ff":"# fill county and state\ndata[\"county\"].fillna(\"unknown\", inplace=True)\ndata[\"State\"].fillna(\"unknown\", inplace=True)\nprint(usa.shape)","9337437a":"# farmers_markets_from_usda\nusa.info()","6658547e":"data.head(7)","97bd5546":"# import essential package\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7e33d3ad":"data.shape","11eb4ef4":"# Group by State and per capita income\ndf = data.groupby(\"State\")[\"per capita income\"].sum().groupby(\"State\").max().sort_values(ascending=False)","55e08872":"# Drop two row that contain null value\ndata.drop([2205, 2522],axis=0, inplace=True)","5b40906d":"# Replace and convert as int\n\ndata[\"population\"] = data[\"population\"].str.replace(\",\",\"\")\ndata[\"population\"] = data[\"population\"].astype(int)\ndata[\"number of households\"] = data[\"number of households\"].str.replace(\",\",\"\")\ndata[\"number of households\"] = data[\"number of households\"].astype(int)\ndata[\"per capita income\"] = data[\"per capita income\"].str.replace(\"$\",\"\")\ndata[\"per capita income\"] = data[\"per capita income\"].str.replace(\",\",\"\")\ndata[\"per capita income\"] = data[\"per capita income\"].astype(int)\ndata[\"median household income\"] = data[\"median household income\"].str.replace(\"$\",\"\")\ndata[\"median household income\"] = data[\"median household income\"].str.replace(\",\",\"\")\ndata[\"median household income\"] = data[\"median household income\"].astype(int)\ndata[\"median family income\"] = data[\"median family income\"].str.replace(\"$\",\"\")\ndata[\"median family income\"] = data[\"median family income\"].str.replace(\",\",\"\")\ndata[\"median family income\"] = data[\"median family income\"].astype(int)","1bcdc18a":"# full information of dataset\ndata.info()","716c0b82":"# State, county Vs per capita\n# The term \"per capita\" is a Latin phrase that translates to \"per person\".\n\ndef state(state_name):\n    data_state = data[data[\"State\"]==state_name][[\"county\", \"per capita income\", \"population\"]].sort_values(\"per capita income\", ascending=False)\n    return data_state","1d6b6955":"cap = state(\"Virginia\")\ndf = pd.DataFrame(cap)","5c1049fb":"# visualization for virginia\n\nsns.set(style=\"darkgrid\", palette='Set1')\nplt.subplots(figsize=(30,8))\nplt.xticks(rotation=90)\nsns.barplot(x=df[\"county\"], y=df[\"per capita income\"], data=df);","0a4ec763":"print(\"Per capita max: at {} {} min: at {} {}\".format(df[\"county\"][df[\"per capita income\"].idxmax()], df[\"per capita income\"].max(), df[\"county\"][df[\"per capita income\"].idxmin()], df[\"per capita income\"].min()))","5e324ce6":"cap = state(\"New York\")\ndf = pd.DataFrame(cap)","aa1b89d4":"# visualization for New York\n\nsns.set(style=\"darkgrid\", palette='Set1')\nplt.subplots(figsize=(30,8))\nplt.xticks(rotation=90)\nsns.barplot(x=df[\"county\"], y=df[\"per capita income\"], data=df);","4f6900c5":"print(\"Per capita max: at {} {} min: at {} {}\".format(df[\"county\"][df[\"per capita income\"].idxmax()], df[\"per capita income\"].max(), df[\"county\"][df[\"per capita income\"].idxmin()], df[\"per capita income\"].min()))","8f466b6c":"# Now try to find out from every state which county has per capita income max\nmax_capita_county = data.groupby([\"State\", \"county\"])[\"per capita income\"].sum().sort_values(ascending=False).reset_index()","c7efebc0":"max_capita_county","e39214f6":"# create a new dataframe\ndf2 = pd.DataFrame(max_capita_county)\ndf2.head(20)","58716e70":"# Visualize first 20 per capita max value\n\nplt.subplots(figsize=(16,5));\nsns.barplot(x=df2[:20][\"county\"], y=df2[:20][\"per capita income\"], data=df2);\nplt.xticks(rotation=90);","1a21e54e":"# print the county name and value\nmax_county = df2[\"county\"][df2[\"per capita income\"].idxmax()]\nprint(\"per capita income at {}\".format(max_county))\nprint(\"per capita income max {}\".format(df2[\"per capita income\"].max()))","d54d30a8":"# Visualize last 20 per capita min value\n\nplt.subplots(figsize=(16,5));\nsns.barplot(x=df2[3210:][\"county\"], y=df2[3210:][\"per capita income\"], data=df2);\nplt.xticks(rotation=90);","572ac0f6":"# print the county name and min value of all\nmax_county = df2[\"State\"][df2[\"per capita income\"].idxmin()]\nprint(\"per capita income at {}\".format(max_county))\nprint(\"per capita income max {}\".format(df2[\"per capita income\"].min()))","7e688c89":"data.head()","0893f000":"# population increase and number of households increase\ndata.plot(kind=\"scatter\", x=\"population\", y=\"number of households\", figsize=(10, 5), alpha=0.5)","78536371":"usa.head()","31ae0c05":"# Drop some columns\ndrop_list = ['FMID', 'street', 'zip', 'city', 'Season1Date', 'Season1Time', 'Season2Date',\n'Season2Time', 'Season3Date', 'Season3Time', 'Season4Date', 'Season4Time', 'updateTime', 'Location']\nusa.drop(drop_list, axis=1, inplace=True)\nusa.columns","29d37429":"usa.head()","10f97724":"# Farmer market dataset information\nusa.info()","b7b20c28":"# Farmers market data total null value\nprint(usa.isna().sum())\n# Check unique value[not necessary]\nprint(usa[\"Organic\"].unique())","421ed04e":"# Replace the column Organic (-) value by (N)\nusa[\"Organic\"].replace(\"-\", \"N\", inplace=True)\nusa[\"Bakedgoods\"].unique()","08834020":"usa.head()","6df41605":"# Product list\nfood_df = ['Organic', 'Bakedgoods', 'Cheese', 'Crafts', 'Flowers', 'Eggs',\n       'Seafood', 'Herbs', 'Vegetables', 'Honey', 'Jams', 'Maple', 'Meat',\n       'Nursery', 'Nuts', 'Plants', 'Poultry', 'Prepared', 'Soap', 'Trees',\n       'Wine', 'Coffee', 'Beans', 'Fruits', 'Grains', 'Juices', 'Mushrooms',\n       'PetFood', 'Tofu', 'WildHarvested']\n\n# Social platform and other media.\n# for null value we assign 0, else 1\nmedia = ['Website', 'Facebook', 'Twitter', 'Youtube', 'OtherMedia']\nfor social in media:\n    usa[social] = (usa[social].notnull().astype('int'))\n\n\n# replace all the nan value by N\nfor i in food_df:\n    usa[i].replace(np.nan, \"N\", inplace=True)\n\n\n# import label encoder\nfrom sklearn.preprocessing import LabelEncoder\n# label_encoder object knows how to understand word labels.\nlabel_encoder = LabelEncoder()\nfor col in set(food_df):\n    usa[col] = label_encoder.fit_transform(usa[col])\n    \n# payment method replace value by 1 and 0. If Y assign 1 else 0\npayment_modes = ['Credit', 'WIC', 'WICcash', 'SFMNP', 'SNAP']\nfor payment_mode in payment_modes:\n    try:\n        usa[payment_mode] = usa[payment_mode].replace(to_replace=['Y', 'N'], value=[1,0])\n    except:\n        continue\n# create new column\nusa['payment type'] = usa.loc[:, 'WIC':'SNAP'].sum(1)","96370f9f":"usa.head()","28bcb320":"usa.columns","b4a4ae4d":"# create a dataframe for product\ndf_list = ['State' ,'County', 'Organic', 'Bakedgoods', 'Cheese', 'Crafts', 'Flowers', 'Eggs',\n       'Seafood', 'Herbs', 'Vegetables', 'Honey', 'Jams', 'Maple', 'Meat',\n       'Nursery', 'Nuts', 'Plants', 'Poultry', 'Prepared', 'Soap', 'Trees',\n       'Wine', 'Coffee', 'Beans', 'Fruits', 'Grains', 'Juices', 'Mushrooms',\n       'PetFood', 'Tofu', 'WildHarvested']\n\nmarket = pd.DataFrame(usa, columns=df_list)\npd.set_option('display.max_columns', 50)","26875305":"market.head()","96ebf1a1":"# add all values from organic to wildharvested for different state and stored in new column called product\nmarket[\"product\"] = market.loc[:,'Organic':'WildHarvested'].sum(1)","6a486635":"market.head(10)","bf98958c":"# create separate dataframe for product and try to visualize\nmarket_county = market.groupby([\"State\", \"County\"])[\"product\"].max().sort_values(ascending=False).reset_index()\ndf3 = pd.DataFrame(market_county)\ndf3.head()","7d4db094":"# visualize by state vs product\nplt.subplots(figsize=(20,5))\nsns.barplot(\n        data=df3,\n        x=\"State\",\n        y=\"product\",\n        palette=['blue', 'red', 'yellow', 'grey'],\n        saturation=0.6,\n    )\n\nplt.xticks(rotation=90)","47f4d812":"# social network user for every state\nsocial_media = usa.groupby([\"State\", \"County\"])['Website', 'Facebook', 'Twitter', 'Youtube', 'OtherMedia'].max().reset_index()\nsocial_media = pd.DataFrame(social_media)\nsocial_media.head()","c5dbdebf":"# Website User from different State\nwebsite_user = social_media.groupby([\"State\"])[\"Website\"].sum().sort_values(ascending=False).reset_index()\nwebsite_user = pd.DataFrame(website_user)\n# Facebook User from different State\nfacebook_user = social_media.groupby([\"State\"])[\"Facebook\"].sum().sort_values(ascending=False).reset_index()\nfacebook_user = pd.DataFrame(facebook_user)\n# Twitter User from different State\ntwitter_user = social_media.groupby([\"State\"])[\"Twitter\"].sum().sort_values(ascending=False).reset_index()\ntwitter_user = pd.DataFrame(twitter_user)\n# Youtube User from different State\nyoutube_user = social_media.groupby([\"State\"])[\"Youtube\"].sum().sort_values(ascending=False).reset_index()\nyoutube_user = pd.DataFrame(youtube_user)\n# OTher Media User from different State\nother_user = social_media.groupby([\"State\"])[\"OtherMedia\"].sum().sort_values(ascending=False).reset_index()\nother_user = pd.DataFrame(other_user)","521aba35":"user_web=website_user[\"State\"][website_user[\"Website\"].idxmin()]\nprint(\"website user max from {} and from different county {}\".format(user_web, website_user[\"Website\"][0]))\n\nuser_fb=facebook_user[\"State\"][facebook_user[\"Facebook\"].idxmin()]\nprint(\"Facebook user max from {} and from different county {}\".format(user_fb, facebook_user[\"Facebook\"][0]))\n\nuser_tweet=twitter_user[\"State\"][twitter_user[\"Twitter\"].idxmin()]\nprint(\"Twitter user max from {} and from different county {}\".format(user_tweet, twitter_user[\"Twitter\"][0]))\n\nuser_youtube=youtube_user[\"State\"][youtube_user[\"Youtube\"].idxmin()]\nprint(\"Youtube user max from {} and from different county {}\".format(user_youtube, youtube_user[\"Youtube\"][0]))\n\nuser_other=other_user[\"State\"][other_user[\"OtherMedia\"].idxmin()]\nprint(\"OtherMedia user max from {} and from different county {}\".format(user_other, other_user[\"OtherMedia\"][0]))","e335c93a":"usa.head()","101bcf76":"# Total market in different State\ntotal_market = usa.groupby([\"State\"])[\"MarketName\"].value_counts().groupby([\"State\"]).sum().sort_values(ascending=False).reset_index()\ntotal_market = pd.DataFrame(total_market)","984821de":"total_market","377c0eaa":"data[\"per capita income\"].max()","14748495":"population = data.groupby(data[\"State\"])[\"population\"].sum().sort_values(ascending=False).reset_index()\npopulation = pd.DataFrame(population)","d97a838b":"population","c1aa5eb9":"# Please upvote me, It will encourage me more ","18df4ba1":"# we see that large poppulation has large market size\n# large market size has high per capita max\n# So, the data doesn't reflect that criticism"}}