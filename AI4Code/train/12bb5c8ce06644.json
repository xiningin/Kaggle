{"cell_type":{"0040a116":"code","42464937":"code","bd9314b7":"code","4dfcd6ed":"code","ae0ecfcb":"code","ca4c26b4":"code","deb84cfb":"code","a8de9c85":"code","257af8f6":"code","11aa7395":"code","9fc12540":"code","af55e1e3":"code","b875df71":"code","3edf73f7":"code","d9b1694e":"code","77117a43":"code","57b83fd3":"code","740e49fe":"code","ad5804c4":"code","2f8d0c1f":"code","162336bb":"code","b3beb27b":"code","b15564df":"code","89d38274":"code","11aed3bf":"markdown","8d8745cc":"markdown","b2bd641e":"markdown","8907c12e":"markdown","1e9a34ae":"markdown","9737be03":"markdown","6fb0daec":"markdown"},"source":{"0040a116":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport cv2\nimport random\nfrom random import randint\nimport time\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42464937":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","bd9314b7":"from fastai.vision.all import *\nfrom fastai.imports import *\nfrom fastai.vision.data import *\nfrom fastai import *\nimport numpy as np\nimport fastai\nimport matplotlib.pyplot as plt","4dfcd6ed":"path = Path(\"\/kaggle\/input\/penquin\")\npath.ls()","ae0ecfcb":"np.random.seed(42)\ndata = ImageDataLoaders.from_folder(path, train=\".\", valid_pct=0.2, item_tfms=RandomResizedCrop(512, min_scale=0.75),\n                                    bs=32,batch_tfms=[*aug_transforms(size=256, max_warp=0), Normalize.from_stats(*imagenet_stats)],num_workers=0)","ca4c26b4":"data.show_batch(nrows=3, figsize=(7,8))","deb84cfb":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","a8de9c85":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","257af8f6":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/penquin\/f.jpg', loader_transform)","11aa7395":"loader_transform = transforms.CenterCrop(140)\nimshow('..\/input\/penquin\/l.jpg', loader_transform)","9fc12540":"    def __init__(self, size):\n        self.size = size\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            assert len(size) == 2, \"Please provide only two dimensions (h, w) for size.\"\n            self.size = size\n\n    def __call__(self, img):\n        return F.five_crop(img, self.size)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(size={0})'.format(self.size)\n\n\n#loader_transform = transforms.FiveCrop(140)\n\nloader_transform = transforms.TenCrop(140, vertical_flip=False)\n\nimshow('..\/input\/penquin\/g.jpg', loader_transform)","af55e1e3":"loader_transform = transforms.Grayscale(num_output_channels=1)\n\nimshow('..\/input\/penquin\/m.jpg', loader_transform)","b875df71":"loader_transform = transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\n\nimshow('..\/input\/penquin\/n.jpg', loader_transform)","3edf73f7":"loader_transform = transforms.Pad(140, fill=0, padding_mode='constant')\n\nimshow('..\/input\/penquin\/u.jpg', loader_transform)","d9b1694e":"loader_transform = transforms.RandomAffine(45, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n\nimshow('..\/input\/penquin\/r.jpg', loader_transform)","77117a43":"loader_transform = transforms.RandomAffine(90, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n\nimshow('..\/input\/penquin\/q.jpg', loader_transform)","57b83fd3":"loader_transform = transforms.RandomApply([transforms.Resize((140, 140))], p=0.5)\n\nimshow('..\/input\/penquin\/c.jpg', loader_transform)","740e49fe":"loader_transform = transforms.RandomApply([transforms.Resize((140, 140)),transforms.Pad(140, fill=0), transforms.RandomHorizontalFlip()],p=0.5)\nimshow('..\/input\/penquin\/c.jpg', loader_transform)","ad5804c4":"loader_transform = transforms.RandomCrop(32, padding=4, padding_mode='reflect')\n\nimshow('..\/input\/penquin\/k.jpg', loader_transform)","2f8d0c1f":"loader_transform = transforms.RandomHorizontalFlip(p=0.5)\n\nimshow('..\/input\/penquin\/a.jpg', loader_transform)","162336bb":"loader_transform = transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0)\n\nimshow('..\/input\/penquin\/i.jpg', loader_transform)","b3beb27b":"loader_transform = transforms.RandomVerticalFlip(p=0.5)\n\nimshow('..\/input\/penquin\/j.jpg', loader_transform)","b15564df":"loader_transform = transforms.RandomErasing( p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n\nimshow('..\/input\/penquin\/j.jpg', loader_transform)","89d38274":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Mar\u00edlia Prata, @mpwolke Was here' )","11aed3bf":"#With a Little (Big) help from my friend Balraj Ashwath @balraj98","8d8745cc":"![](https:\/\/i.ytimg.com\/vi\/eykcCNCwlYU\/maxresdefault.jpg)youtube.com","b2bd641e":"#How can I know, before start creating the Notebook, that there is Batches or Not in the Dataloader?","8907c12e":"#TORCHVISION.TRANSFORMS  https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html","1e9a34ae":"#Changing 45 degrees to 90 degrees","9737be03":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcR5_Lc68Q7VQp1CSahauxaerDZOtEc-aqcOMQ&usqp=CAU)journaldev.com","6fb0daec":"#Now I'm suffering with size!"}}