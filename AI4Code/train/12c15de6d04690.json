{"cell_type":{"470d5306":"code","9b2dab9a":"code","7f86b4d2":"code","5f628c1b":"code","5fc308ba":"code","8989e80b":"code","5daafd7c":"code","e654e046":"code","f30ca481":"code","94334c11":"code","6d5db840":"code","989fa7ba":"code","7c33124d":"code","aea242a6":"code","6ef49d87":"code","7712da13":"code","a38788c1":"code","d7a598f1":"code","f4dc2ec5":"code","f91fb4da":"code","2da7095d":"code","7dbc6d81":"code","19e04a45":"code","8d58c880":"code","e2ba9492":"code","c0a2b7ba":"code","77a6edb4":"code","b3c147ec":"code","d7a92088":"code","29a12210":"code","9c4b5dea":"code","dcdc1d17":"code","85b45e6d":"code","71dbf4ae":"code","59d7a885":"code","eee429c7":"code","c76f3579":"code","5784c945":"code","3e32449a":"code","41ba1e87":"code","4814bb2e":"code","23408e92":"code","aef2cced":"code","dcbf0765":"code","f1cfb240":"code","91478ce1":"code","57bdc163":"code","21837672":"code","bcc91c6a":"code","6cb1d977":"code","81bc8788":"code","fa632a83":"code","43a06c2b":"code","0a6621ad":"code","a0e66de7":"code","6db4c567":"code","2414c42d":"code","cccfc06c":"code","218c8e4a":"code","d8fab5c7":"markdown"},"source":{"470d5306":"%matplotlib inline\nRANDOM_STATE = 0\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.options.display.float_format = '{:.0f}'.format\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\nfrom pandas import Series\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport eli5 \nfrom eli5.sklearn import PermutationImportance\n\nimport itertools","9b2dab9a":"def summary(df):\n    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    return summary","7f86b4d2":"def plot_cf_matrix_and_roc(model, \n                           X_train, \n                           y_train,\n                           X_test, \n                           y_test,\n                           y_pred, \n                           classes=[0,1],\n                           normalize=False,\n                           cmap=plt.cm.Blues):\n    metrics_list = []\n    \n    # the main plot\n    plt.figure(figsize=(15,5))\n\n    # the confusion matrix\n    plt.subplot(1,2,1)\n    cm = confusion_matrix(y_test, y_pred)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    \n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        plt.title(\"Normalized confusion matrix\")\n    else:\n        plt.title('Confusion matrix')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    # the result metrix\n    summary_df = pd.DataFrame([[str(np.unique( y_pred )),\n                               str(round(metrics.precision_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.accuracy_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.recall_score(y_test, y_pred.round(), average='binary'),3)),\n                               str(round(metrics.roc_auc_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.cohen_kappa_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.f1_score(y_test, y_pred.round(), average='binary'),3))]], \n                              columns=['Class', 'Precision', 'Accuracy', 'Recall', 'ROC-AUC', 'Kappa', 'F1-score'])\n    # print the metrics\n    print(\"\\n\");\n    print(summary_df);\n    print(\"\\n\");\n    \n    plt.show()","5f628c1b":"def cross_val(X, y, param, cat_features='', class_weights = '', n_splits=3):\n    results = []\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n    \n    for tr_ind, val_ind in skf.split(X, y):\n        X_train_i = X.iloc[tr_ind]\n        y_train_i = y.iloc[tr_ind]\n        \n        X_valid_i = X.iloc[val_ind]\n        y_valid_i = y.iloc[val_ind]\n        \n        if class_weights == '' :\n            clf = CatBoostClassifier(iterations=param['iterations'],\n                            loss_function = param['loss_function'],\n                            depth=param['depth'],\n                            l2_leaf_reg = param['l2_leaf_reg'],\n                            eval_metric = param['eval_metric'],\n                            leaf_estimation_iterations = 10,\n                            use_best_model=True,\n                            logging_level='Silent',\n                            od_type=\"Iter\",\n                            early_stopping_rounds=param['early_stopping_rounds']\n            )\n        else:\n            clf = CatBoostClassifier(iterations=param['iterations'],\n                            loss_function = param['loss_function'],\n                            depth=param['depth'],\n                            l2_leaf_reg = param['l2_leaf_reg'],\n                            class_weights = class_weights,\n                            eval_metric = param['eval_metric'],\n                            leaf_estimation_iterations = 10,\n                            use_best_model=True,\n                            logging_level='Silent',\n                            od_type=\"Iter\",\n                            early_stopping_rounds=param['early_stopping_rounds']\n            )\n        \n        \n        if cat_features == '' :\n            clf.fit(X_train_i, \n                    y_train_i,\n                    eval_set=(X_valid_i, y_valid_i)\n            )\n        else:\n            clf.fit(X_train_i, \n                    y_train_i,\n                    cat_features=cat_features,\n                    eval_set=(X_valid_i, y_valid_i)\n            )\n        \n        # predict\n        y_pred = clf.predict(X_valid_i)\n        \n        # select the right metric\n        if(param['eval_metric'] == 'Recall'):\n            metric = metrics.recall_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'Accuracy'):\n            metric = metrics.accuracy_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'F1'):\n            metric = metrics.f1_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'AUC'):\n            metric = metrics.roc_auc_score(y_valid_i, y_pred)\n        elif(param['eval_metric'] == 'Kappa'):\n            metric = metrics.cohen_kappa_score(y_valid_i, y_pred)\n        else:\n            metric = metrics.accuracy_score(y_valid_i, y_pred)\n        \n        #append the metric\n        results.append(metric)\n        \n        print('Classes: '+str(np.unique( y_pred )))\n        print('Precision: '+str(round(metrics.precision_score(y_valid_i, y_pred.round()),3)))\n        print('Accuracy: '+str(round(metrics.accuracy_score(y_valid_i, y_pred.round()),3)))\n        print('Recall: '+str(round(metrics.recall_score(y_valid_i, y_pred.round(), average='binary'),3)))\n        print('Roc_Auc: '+str(round(metrics.roc_auc_score(y_valid_i, y_pred.round()),3)))\n        print('F1 score: '+str(round(metrics.f1_score(y_valid_i, y_pred.round(), average='binary'),3)))\n        print('Mean and standard deviation for '+param['eval_metric']+' oof prediction: ',np.mean(results),np.std(results))\n        print(\"\\n\")\n    return sum(results)\/n_splits","5fc308ba":"def catboost_GridSearchCV(X, y, params, cat_features='', class_weights='', n_splits=5):\n    ps = {'score':0,'param': []}\n    for prms in tqdm(list(ParameterGrid(params)), ascii=True, desc='Params Tuning:'):\n        score = cross_val(X, y, prms, cat_features, class_weights, n_splits)\n        if score > ps['score']:\n            ps['score'] = score\n            ps['param'] = prms\n    print('Score: '+str(ps['score']))\n    print('Params: '+str(ps['param']))\n    return ps['param']","8989e80b":"# Load in the train and test datasets from the CSV files\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# to cleanup and modify the data\ndata_cleaner = [train_df, test_df]","5daafd7c":"train_df.head()","e654e046":"train_df.describe()","f30ca481":"train_df.info()","94334c11":"train_df.shape","6d5db840":"train_df.isnull().sum()","989fa7ba":"train_df.info()","7c33124d":"train_df['Initial']=0\nfor i in train_df:\n    train_df['Initial']=train_df.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations","aea242a6":"test_df['Initial']=0\nfor i in test_df:\n    test_df['Initial']=test_df.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations","6ef49d87":"pd.crosstab(train_df.Initial,train_df.Sex).T.style.background_gradient(cmap='summer_r')","7712da13":"pd.crosstab(test_df.Initial,test_df.Sex).T.style.background_gradient(cmap='summer_r')","a38788c1":"newtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"}","d7a598f1":"#train_df[train_df['Initial'].isnull()]","f4dc2ec5":"#test_df[test_df['Initial'].isnull()]","f91fb4da":"#train_df['Initial']=train_df.Initial.map(newtitles)\n#test_df['Initial']=test_df.Initial.map(newtitles)","2da7095d":"# Miss\ntrain_df['Initial']=train_df['Initial'].replace(['Mlle', 'Mme','Ms'], 'Miss')\ntest_df['Initial']=test_df['Initial'].replace(['Mlle', 'Mme','Ms'], 'Miss')\n\n# Noble passengers\ntrain_df['Initial']=train_df['Initial'].replace(['Sir','Don','Dona','Jonkheer','Lady','Countess'], 'Noble')\ntest_df['Initial']=test_df['Initial'].replace(['Sir','Don','Dona','Jonkheer','Lady','Countess'], 'Noble')\n\n# passengers with a higher social standing\ntrain_df['Initial']=train_df['Initial'].replace(['Dr', 'Rev','Col','Major','Capt'], 'Others')\ntest_df['Initial']=test_df['Initial'].replace(['Dr', 'Rev','Col','Major','Capt'], 'Others')","7dbc6d81":"pd.crosstab(train_df.Initial,train_df.Sex).T.style.background_gradient(cmap='summer_r')","19e04a45":"pd.crosstab(test_df.Initial,test_df.Sex).T.style.background_gradient(cmap='summer_r')","8d58c880":"train_df.head()","e2ba9492":"#Embarked\ntrain_df['Embarked'].fillna('S', inplace = True)\n\n#Fare\ntrain_df['Fare'].fillna(train_df['Fare'].median(), inplace = True)","c0a2b7ba":"#Embarked\ntest_df['Embarked'].fillna('S', inplace = True)\n\n#Fare\ntest_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)","77a6edb4":"def newage (cols):\n    Initial=cols[0]\n    Sex=cols[1]\n    Age=cols[2]\n    if pd.isnull(Age):\n        if Initial=='Master' and Sex==\"male\":\n            return 4.57\n        elif Initial=='Miss' and Sex=='female':\n            return 21.8\n        elif Initial=='Mr' and Sex=='male': \n            return 32.37\n        elif Initial=='Mrs' and Sex=='female':\n            return 35.72\n        elif Initial=='Officer' and Sex=='female':\n            return 49\n        elif Initial=='Officer' and Sex=='male':\n            return 46.56\n        elif Initial=='Royalty' and Sex=='female':\n            return 40.50\n        else:\n            return 42.33\n    else:\n        return Age","b3c147ec":"#train_df.Age=train_df[['Initial','Sex','Age']].apply(newage, axis=1)\n#test_df.Age=test_df[['Initial','Sex','Age']].apply(newage, axis=1)","d7a92088":"train_df.groupby('Initial')['Age'].mean()","29a12210":"#Age\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Mr'),'Age']=32\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Mrs'),'Age']=36\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Master'),'Age']=5\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Miss'),'Age']=22\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Noble'),'Age']=42\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='YoungMiss'),'Age']=12\ntrain_df.loc[(train_df.Age.isnull())&(train_df.Initial=='Other'),'Age']=47","9c4b5dea":"train_df[train_df['Age'].isnull()]","dcdc1d17":"train_df['Age'].fillna(47, inplace = True)","85b45e6d":"test_df.groupby('Initial')['Age'].mean()","71dbf4ae":"#Age\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Mr'),'Age']=32\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Mrs'),'Age']=39\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Master'),'Age']=7\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Miss'),'Age']=22\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Noble'),'Age']=39\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='YoungMiss'),'Age']=12\ntest_df.loc[(test_df.Age.isnull())&(test_df.Initial=='Other'),'Age']=45","59d7a885":"test_df[test_df['Age'].isnull()]","eee429c7":"for dataset in [train_df, test_df]:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset[\"SmallFamily\"]= np.where((dataset[\"FamilySize\"] > 1) & (dataset[\"FamilySize\"] < 4), 1, 0)\n    dataset[\"MediumFamily\"]= np.where((dataset[\"FamilySize\"] >= 4) & (dataset[\"FamilySize\"] < 7), 1, 0)\n    dataset[\"LargeFamily\"]= np.where(dataset[\"FamilySize\"] >= 7, 1, 0)\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n    dataset[\"IsMother\"]= np.where((dataset[\"Sex\"]==\"female\") & (dataset[\"Parch\"] > 0) & (dataset[\"Initial\"] != \"Miss\"), 1, 0)\n    #dataset['IsChild'] = np.where(dataset[\"Age\"] < 16, 1, 0)\n    #dataset[\"Is_Married\"]= np.where(dataset[\"Initial\"] == 'Mrs', 1, 0)\n    #dataset['Embarked'] = dataset['Embarked'].map(embarkedMap)\n    #dataset['Sex'] = dataset['Sex'].map(genderMap)\n    #dataset['Ticket_Frequency'] = dataset.groupby('Ticket')['Ticket'].transform('count')\n    #dataset['Ticket2']=dataset.Ticket.apply(lambda x : len(x))\n    #dataset['Cabin2']=dataset.Cabin.apply(lambda x : len(x))\n    #dataset['Name2']=dataset.Name.apply(lambda x: x.split(',')[0].strip())","c76f3579":"# Store our passenger ID for the submission\nPassengerId = test_df['PassengerId']\ntrain_df = train_df.drop(columns=['PassengerId',  'Ticket', 'Name', 'Cabin', 'SibSp','Parch', 'FamilySize'])\ntest_df = test_df.drop(columns=['PassengerId',  'Ticket', 'Name', 'Cabin', 'SibSp','Parch','FamilySize'])","5784c945":"train_df.isnull().sum()","3e32449a":"train_df.head()","41ba1e87":"sns.countplot(train_df['Survived'])","4814bb2e":"train_df.columns","23408e92":"#train_df = train_df.drop(columns=['SibSp','Parch','Ticket','Cabin'])\n#test_df = test_df.drop(columns=['SibSp','Parch','Ticket','Cabin'])","aef2cced":"sns.heatmap(train_df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","dcbf0765":"train_df2 = train_df.copy().drop(columns=['Survived'])\ntrain_df2.corrwith(train_df.Survived).plot.bar(figsize=(20,15), \n                                              title=\"Correlation with the response Variable\", \n                                              fontsize=15, rot=90, grid=True)","f1cfb240":"train_df.columns","91478ce1":"summary(train_df)","57bdc163":"from sklearn.preprocessing import MinMaxScaler\ncol_names = train_df.columns.drop(['Sex', 'Embarked', \"Initial\", \"Survived\"])\nfeatures = train_df[col_names]\nscaler = MinMaxScaler(feature_range = (-1,1)).fit(features.values)\nfeatures = scaler.transform(features.values)\ntrain_df[col_names] = features\n\ncol_names = test_df.columns.drop(['Sex', 'Embarked', \"Initial\"])\nfeatures = test_df[col_names]\nscaler = MinMaxScaler(feature_range = (-1,1)).fit(features.values)\nfeatures = scaler.transform(features.values)\ntest_df[col_names] = features","21837672":"from sklearn.model_selection import train_test_split\nX_train = train_df.drop('Survived', 1)\ny_train = train_df['Survived']","bcc91c6a":"from sklearn.utils import class_weight\ncw = list(class_weight.compute_class_weight('balanced',\n                                             np.unique(train_df['Survived']),\n                                             train_df['Survived']))","6cb1d977":"cw","81bc8788":"cat_features = ['Sex', 'Embarked', \"Initial\"]\n\nparams = {'depth':[1, 2, 3],\n          'iterations':[3000],\n          'early_stopping_rounds': [3000],\n          'learning_rate':[0.01],\n          'loss_function': ['Logloss'],\n          'l2_leaf_reg':np.logspace(-20,-19, 3),\n          'eval_metric':['Recall']\n}\n\nparam = catboost_GridSearchCV(X_train, y_train, params, cat_features, cw)","fa632a83":"# cross validate the best model\ncross_val(X_train, y_train, param, cat_features, cw, 5)","43a06c2b":"# build the final model with the best parameters\nclf = CatBoostClassifier(iterations=param['iterations'],\n                        loss_function = param['loss_function'],\n                        depth=param['depth'],\n                        l2_leaf_reg = param['l2_leaf_reg'],\n                        eval_metric = param['eval_metric'],\n                        leaf_estimation_iterations = 10,\n                        class_weights = cw,\n                        use_best_model=True\n)\n\nX_train, X_test, y_train, y_test = train_test_split(X_train,\n                                                        y_train, \n                                                        shuffle=True,\n                                                        random_state=RANDOM_STATE,\n                                                        test_size=0.2,\n                                                        stratify=y_train\n    )\n\nclf.fit(X_train, \n        y_train,\n        cat_features=cat_features,\n        logging_level='Silent',\n        eval_set=(X_test, y_test)\n)","0a6621ad":"pred_y = clf.predict(X_test)","a0e66de7":"plot_cf_matrix_and_roc(clf, X_train, y_train, X_test, y_test, pred_y , classes=['No Survived','Survived'])","6db4c567":"submission_predictions = clf.predict(test_df)","2414c42d":"submission_predictions.shape","cccfc06c":"PassengerId.shape","218c8e4a":"submission = pd.DataFrame({\n        \"PassengerId\": PassengerId,\n        \"Survived\": submission_predictions\n    })\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(submission.shape)","d8fab5c7":"## Prepare X_train, y_train, X_test and y_test"}}