{"cell_type":{"edd4c7e1":"code","f43ca597":"code","1dbd6860":"code","e5de3789":"code","0b545893":"code","4f0f0184":"code","39b3155b":"code","df97de9a":"code","06a75dd4":"code","47b8f4d0":"code","f3affd01":"code","c0329d2f":"code","c413c54d":"code","95ac1b55":"code","03700b69":"code","2571c092":"code","9bccd1df":"code","20f9d02b":"code","cdf0a03b":"code","288d4f52":"code","d52efc71":"code","147b2afa":"code","5065ccde":"markdown","ba9783d2":"markdown","ded81fd9":"markdown","2b3c9224":"markdown","bacac1b4":"markdown","70f75974":"markdown","70377be6":"markdown","1406c9c5":"markdown","b295873b":"markdown","42b78fb0":"markdown","710529a2":"markdown","30ea6c00":"markdown","672356c3":"markdown","87d6b81e":"markdown","4c17f4ae":"markdown","9f80d931":"markdown","d537dddb":"markdown"},"source":{"edd4c7e1":"!pip install xgboost -q\n!pip install catboost -q\n!pip install lightgbm -q\n!pip install hyperopt -q","f43ca597":"from hyperopt import fmin, hp, tpe, STATUS_OK, STATUS_FAIL, Trials\n\nfrom copy import deepcopy\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import clear_output\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom sklearn.svm import SVR\n\n\nimport lightgbm\nimport catboost\nimport xgboost","1dbd6860":"print(xgboost.__version__)","e5de3789":"X_train = pd.read_csv('..\/input\/30-days-of-ml\/train.csv', index_col='id')\nX_test = pd.read_csv('..\/input\/30-days-of-ml\/test.csv', index_col='id')","0b545893":"print(f\"Train Shape: {X_train.shape}\\nTest Shape: {X_test.shape}\")","4f0f0184":"X_train.dropna(axis=0, subset=['target'], inplace=True)\ny_train = X_train.target\nX_train.drop(['target'], axis=1, inplace=True)","39b3155b":"X_train.info()","df97de9a":"cat_cols = [col for col in X_train.columns if X_train[col].dtype==\"O\"]\nnum_cols = [col for col in X_train.columns if(X_train[col].dtype==\"int64\" or X_train[col].dtype==\"float64\")]","06a75dd4":"X_train[num_cols].plot(kind = \"box\")\nplt.xticks(rotation = 45)","47b8f4d0":"outlier_cols = ['cont0','cont6','cont8']\nfor col in outlier_cols:\n    std = 1.5 * X_train[col].std()\n    mean = X_train[col].mean()\n    floor, ceil = mean - std, mean + std\n    X_train[col] = X_train[col].clip(floor, ceil)","f3affd01":"X_train[num_cols].plot(kind = \"box\")\nplt.xticks(rotation = 45)","c0329d2f":"enc = OrdinalEncoder()\nenc.fit(X_train[cat_cols])\nprint(X_train.shape)\nX_cat_transformed = pd.DataFrame(enc.transform(X_train[cat_cols]))\nX_cat_transformed.index = X_train.index\nX_cat_transformed.columns = X_train[cat_cols].columns\nX_train_final = X_train.drop(columns = cat_cols, axis=1).merge(X_cat_transformed, left_index = True, right_index = True)\nX_train_final.shape","c413c54d":"X_cat_transformed = pd.DataFrame(enc.transform(X_test[cat_cols]))\nX_cat_transformed.index = X_test.index\nX_cat_transformed.columns = X_test[cat_cols].columns\nX_test_final = X_test.drop(columns = cat_cols, axis=1).merge(X_cat_transformed, left_index = True, right_index = True)\nX_test_final.shape","95ac1b55":"scaler = StandardScaler()","03700b69":"X_train_scaled = scaler.fit_transform(X_train_final.loc[:,num_cols])\nX_test_final_scaled = scaler.transform(X_test_final.loc[:,num_cols])","2571c092":"X_train_final.loc[:,num_cols] = X_train_scaled\nX_test_final.loc[:,num_cols] = X_test_final_scaled","9bccd1df":"best_params = {\n    'xgb': {\n        'colsample_bytree': 0.3398838070392557,\n        'learning_rate': 0.09585559562730613,\n        'max_depth': 9,\n        'reg_alpha': 49.17007471724148,\n        'reg_lambda': 70.78224065652488,\n        'subsample': 0.9654423298684486,\n        'n_estimators': 200\n    },\n    'lgb': {\n        'colsample_bytree': 0.12196519218211449,\n        'learning_rate': 0.09971998930607824,\n        'max_depth': 6,\n        'reg_alpha': 2.1249428657367573,\n        'reg_lambda': 26.674990507780684,\n        'subsample': 0.7034838024278993,\n        'n_estimators': 10000,\n    },\n    'ctb': {\n        'max_depth': 5,\n        'iterations': 2500,\n        'learning_rate': 0.01,\n        'eval_metric': 'RMSE'\n    }\n}","20f9d02b":"results   = np.zeros(len(X_train_final))\nscore     = 0.0\nnumFolds  = 6\nscore_arr = []\npreds_arr = []\npreds     = pd.DataFrame()\nfolds     = KFold(n_splits = numFolds, shuffle = True)\n\nmodel_xgb = xgboost.XGBRegressor(**best_params['xgb'], predictor=\"gpu_predictor\", tree_method = 'gpu_hist', random_state = 197)\nmodel_lgb = lightgbm.LGBMRegressor(**best_params['lgb'], device_type=\"gpu\", random_state = 197)\n\nmodels = {\n    'xgb': {\n        'model'    : model_xgb,\n        'score'    : deepcopy(score),\n        'results'  : deepcopy(results),\n        'score_arr': deepcopy(score_arr),\n        'preds_arr': deepcopy(preds_arr),\n        'preds'    : deepcopy(preds)\n    },\n    'lgb': {\n        'model'    : model_lgb,\n        'score'    : deepcopy(score),\n        'results'  : deepcopy(results),\n        'score_arr': deepcopy(score_arr),\n        'preds_arr': deepcopy(preds_arr),\n        'preds'    : deepcopy(preds)\n    }\n}\nfor model in models.keys(): \n    for i,(train_index, test_index) in enumerate(folds.split(X_train_final)):\n        X_train_fold, X_test_fold = X_train_final.iloc[train_index,:], X_train_final.iloc[test_index,:]\n        y_train_fold, y_test_fold = y_train.iloc[train_index].values.ravel(), y_train.iloc[test_index].values.ravel()\n        models[model]['model'].fit(X_train_fold, y_train_fold)\n        models[model]['results'][test_index] = models[model]['model'].predict(X_test_fold)\n        rmse_compute = mean_squared_error(y_test_fold, models[model]['results'][test_index])\n        models[model]['score'] += rmse_compute\n        print(f'Model {model}\\tScore CV iteration {i}: {rmse_compute}')\n        models[model]['score_arr'].append(rmse_compute)\n        models[model]['preds_arr'].append(models[model]['model'].predict(X_test_final))\n    models[model]['score'] \/= numFolds\n    names = []\n    for i,test_preds in enumerate(models[model]['preds_arr']):\n        names.append(f'pred_{i}')\n        models[model]['preds'][names[-1]] = test_preds\n    pred_aggr = models[model]['preds'].aggregate(np.mean, axis = 1)\n    models[model]['preds']['id'] = X_test_final.index\n    models[model]['preds']['target'] = pred_aggr\n    models[model]['preds'].drop(names, axis = 1, inplace = True)\n    print()","cdf0a03b":"model_ctb = catboost.CatBoostRegressor(\n                **best_params['ctb'],\n                task_type=\"GPU\", devices='0:1', verbose = 0\n            )\nmodel_ctb.fit(X_train_final, y_train, early_stopping_rounds = 100)\npred_ctb = model_ctb.predict(X_test_final)","288d4f52":"pred = {\n    'xgb': models['xgb']['preds'].drop('id',axis=1).to_numpy().reshape(-1,),\n    'lgb': models['lgb']['preds'].drop('id',axis=1).to_numpy().reshape(-1,), \n    'ctb': pred_ctb.reshape(-1,)\n}\npred_df = pd.DataFrame(pred)","d52efc71":"submit_map = [\n    x for x in zip(\n        ['final_submission','submission_lgb+xgb','submission_lgb','submission_xgb','submission_ctb'],\n        [pred_df.aggregate(np.mean, axis = 1),pred_df.loc[:,['xgb','lgb']].aggregate(np.mean, axis = 1),pred_df.lgb,pred_df.xgb,pred_df.ctb]\n    )\n]\nsubmissions = {}\nId = X_test.index\nfor (f_name,target) in submit_map:\n    submission = pd.DataFrame({\n        'id':Id,\n        'target':target\n    })\n    submissions[f_name] = submission","147b2afa":"for key,value in submissions.items():\n    print(f'{key}\\n{value.shape}\\t{list(value.columns)}')\n    value.to_csv(f'{key}', index = False)","5065ccde":"## Predictions on each model","ba9783d2":"# Modelling Strategy","ded81fd9":"```python\nclass HPOpt(object):\n\n    def __init__(self, x_train, x_test, y_train, y_test):\n        self.x_train = x_train\n        self.x_test  = x_test\n        self.y_train = y_train\n        self.y_test  = y_test\n        self.best_params = {}\n        self.loss = {}\n\n    def process(self, fn_name, space, trials, algo, max_evals):\n        fn = getattr(self, fn_name)\n        try:\n            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n        except Exception as e:\n            return {'status': STATUS_FAIL,\n                    'exception': str(e)}\n        return result, trials\n\n    def xgb_reg(self, para):\n        reg = xgboost.XGBRegressor(**para['reg_params'], predictor=\"gpu_predictor\", tree_method = 'gpu_hist')\n        return self.train_reg(reg, para, 'xgb')\n\n    def lgb_reg(self, para):\n        reg = lightgbm.LGBMRegressor(**para['reg_params'], device_type=\"gpu\")\n        return self.train_reg(reg, para, 'lgb')\n\n    def train_reg(self, reg, para, model):\n        reg.fit(self.x_train, self.y_train,\n                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n                **para['fit_params'])\n        pred = reg.predict(self.x_test)\n        loss = para['loss_func'](self.y_test, pred)\n        if model not in self.loss:\n            self.loss[model] = loss\n            self.best_params[model] = para['reg_params']\n        elif self.loss[model] > loss:\n            self.loss[model] = loss\n            self.best_params[model] = para['reg_params']\n        return {'loss': loss, 'status': STATUS_OK}\n```","2b3c9224":"## Creating submissions","bacac1b4":"## Saving submissions","70f75974":"### Remove rows with missing target, separate target from predictors","70377be6":"## Encode categorical columns","1406c9c5":"### Scaler","b295873b":"### Hyperopt for finding the best hyperparameters for the model","42b78fb0":"```python \nobj = HPOpt(X_train, X_valid, y_train, y_valid)\n\nxgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\nlgb_opt = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n```","710529a2":"```python\n# XGB parameters\nxgb_reg_params = {\n    'learning_rate'   : hp.uniform('learning_rate',    0.01, 0.1),\n    'max_depth'       : hp.choice('max_depth',         np.arange(2, 12, 1, dtype=int)),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0, 1),\n    'subsample'       : hp.uniform('subsample',        0.5, 1),\n    'n_estimators'    : 200,\n    'reg_lambda'      : hp.uniform('reg_lambda',       0, 100),\n    'reg_alpha'       : hp.uniform('reg_alpha',        0, 100),\n}\nxgb_fit_params = {\n    'eval_metric'          : 'rmse',\n    'early_stopping_rounds': 300,\n    'verbose'              : False\n}\nxgb_para = dict()\nxgb_para['reg_params'] = xgb_reg_params\nxgb_para['fit_params'] = xgb_fit_params\nxgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\n\n# LightGBM parameters\nlgb_reg_params = {\n    'learning_rate'   : hp.uniform('learning_rate',    0.01, 0.1),\n    'max_depth'       : hp.choice('max_depth',         np.arange(2, 12, 1, dtype=int)),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0, 1),\n    'subsample'       : hp.uniform('subsample',        0.5, 1),\n    'n_estimators'    : 200,\n    'reg_lambda'      : hp.uniform('reg_lambda',       0, 100),\n    'reg_alpha'       : hp.uniform('reg_alpha',        0, 100),\n}\nlgb_fit_params = {\n    'eval_metric'          : 'l2',\n    'early_stopping_rounds': 300,\n    'verbose'              : False\n}\nlgb_para = dict()\nlgb_para['reg_params'] = lgb_reg_params\nlgb_para['fit_params'] = lgb_fit_params\nlgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n```","30ea6c00":"# Preprocess","672356c3":"```python\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_final, y_train, train_size = 0.95)\n```","87d6b81e":"## Cap outliers","4c17f4ae":"```javascript\nbest_params\n{\n    'xgb': {\n        'colsample_bytree': 0.3398838070392557,\n        'learning_rate': 0.09585559562730613,\n        'max_depth': 9,\n        'reg_alpha': 49.17007471724148,\n        'reg_lambda': 70.78224065652488,\n        'subsample': 0.9654423298684486,\n        'n_estimators': 200\n    },\n    'lgb': {\n        'colsample_bytree': 0.12196519218211449,\n        'learning_rate': 0.09971998930607824,\n        'max_depth': 6,\n        'reg_alpha': 2.1249428657367573,\n        'reg_lambda': 26.674990507780684,\n        'subsample': 0.7034838024278993\n        'n_estimators': 10000,\n    },\n    'ctb': {\n        'max_depth': 5,\n        'iterations': 2500,\n        'learning_rate': 0.01,\n        'eval_metric': 'RMSE'\n    }\n}\n```","9f80d931":"```python\n{\n    'xgb': {\n        'model': XGBRegressor(\n            base_score=0.5, booster='gbtree', colsample_bylevel=1,\n            colsample_bynode=1, colsample_bytree=0.2182898814682573, gamma=0,\n            gpu_id=0, importance_type='gain', interaction_constraints='',\n            learning_rate=0.09323922084779779, max_delta_step=0, max_depth=9,\n            min_child_weight=1, missing=nan, monotone_constraints='()',\n            n_estimators=200, n_jobs=2, num_parallel_tree=1,\n            predictor='gpu_predictor', random_state=0,\n            reg_alpha=11.374118398625518, reg_lambda=50.708666588422645,\n            scale_pos_weight=1, subsample=0.742190358295902,\n            tree_method='gpu_hist', validate_parameters=1, verbosity=None),\n        'score': 0.521641624024092,\n        'results': array(\n            [8.37726212, 8.2092495 , 8.16110611, ..., 8.20567703, 8.01847553, 8.35764503]),\n        'score_arr': [\n            0.5207345737017616,\n            0.5236626689473538,\n            0.5212746580710197,\n            0.5214333808089531,\n            0.5215819643873493,\n            0.5211624982281141\n        ]\n    },\n    'lgb': {\n        'model': LGBMRegressor(\n            colsample_bytree=0.21972699016990532, device_type='gpu',\n            learning_rate=0.09556740318797943, max_depth=7, n_estimators=200,\n            reg_alpha=17.419359116208657, reg_lambda=46.10054704182324,\n            subsample=0.6656261736409221),\n        'score': 0.5214663914709199,\n        'results': array([8.28485245, 8.24871135, 8.17802269, ..., 8.18250891, 8.00794612, 8.28965002]),\n        'score_arr': [\n            0.5208610592792908,\n            0.5155923152385317,\n            0.5202420220221392,\n            0.5242637510920929,\n            0.52547260387267,\n            0.5223665973207943\n        ]\n    }\n}\n```","d537dddb":"# Read the data"}}