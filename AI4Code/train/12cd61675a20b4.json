{"cell_type":{"43ab5c58":"code","ef39f361":"code","e26f8d1e":"code","1edbf6a6":"code","268b31c1":"code","baae4182":"code","0db14d2c":"code","5aa0db89":"code","5606d80f":"code","50b46b1f":"code","f5101472":"code","9a3ff6d6":"code","3bcbe83b":"code","056f3c40":"code","ea1d1f63":"code","a4cdc1a4":"code","66abab33":"code","81311b71":"code","9b66d666":"code","2853011c":"code","9b5c8f4d":"code","c0f3c967":"code","4e6c06ba":"code","a93ecd78":"code","cf1f0174":"code","dabd9bdd":"code","550db9d5":"code","4226c081":"code","9db2dd55":"markdown","4775bf1b":"markdown","8c1b0029":"markdown","996ab1d4":"markdown","bcdf21c8":"markdown","412d23ef":"markdown","8dc71647":"markdown","ab2a101d":"markdown"},"source":{"43ab5c58":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re\nimport pydicom\nimport warnings\n\nfrom PIL import Image\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\n\nfrom matplotlib import pyplot as plt\n\n\nwarnings.filterwarnings(\"ignore\")\n\n\nDIR_INPUT = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection'\nDIR_TRAIN = f'{DIR_INPUT}\/train'\nDIR_TEST = f'{DIR_INPUT}\/test'","ef39f361":"train_df = pd.read_csv(f'{DIR_INPUT}\/train.csv')\ntrain_df.fillna(0, inplace=True)\ntrain_df.loc[train_df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\n# FasterRCNN handles class_id==0 as the background.\ntrain_df[\"class_id\"] = train_df[\"class_id\"] + 1\ntrain_df.loc[train_df[\"class_id\"] == 15, [\"class_id\"]] = 0\n\ntrain_df.shape","e26f8d1e":"train_df.sort_values(by='image_id').head(20)","1edbf6a6":"# train_df[\"class_id\"].value_counts()\ntrain_df[\"class_id\"].nunique()","268b31c1":"sample_id = \"000434271f63a053c4128a0ba6352c7f\"\n\ndicom = pydicom.dcmread(f\"{DIR_TRAIN}\/{sample_id}.dicom\")\ndicom","baae4182":"image = dicom.pixel_array * dicom.RescaleSlope + dicom.RescaleIntercept\n\nplt.imshow(image, cmap='gray')","0db14d2c":"dicom","5aa0db89":"image_ids = train_df['image_id'].unique()\nvalid_ids = image_ids[-3000:]\ntrain_ids = image_ids[:-3000]","5606d80f":"valid_df = train_df[train_df['image_id'].isin(valid_ids)]\ntrain_df = train_df[train_df['image_id'].isin(train_ids)]","50b46b1f":"valid_df.shape, train_df.shape","f5101472":"class VinBigDataset(Dataset):\n    \n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n        \n        self.image_ids = dataframe[\"image_id\"].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n        \n    def __getitem__(self, index):\n        \n        image_id = self.image_ids[index]\n        records = self.df[(self.df['image_id'] == image_id)]\n        records = records.reset_index(drop=True)\n\n        dicom = pydicom.dcmread(f\"{self.image_dir}\/{image_id}.dicom\")\n        \n        image = dicom.pixel_array\n        \n        if \"PhotometricInterpretation\" in dicom:\n            if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                image = np.amax(image) - image\n        \n        intercept = dicom.RescaleIntercept if \"RescaleIntercept\" in dicom else 0.0\n        slope = dicom.RescaleSlope if \"RescaleSlope\" in dicom else 1.0\n        \n        if slope != 1:\n            image = slope * image.astype(np.float64)\n            image = image.astype(np.int16)\n            \n        image += np.int16(intercept)        \n        \n        image = np.stack([image, image, image])\n        image = image.astype('float32')\n        image = image - image.min()\n        image = image \/ image.max()\n        image = image * 255.0\n        image = image.transpose(1,2,0)\n       \n        if records.loc[0, \"class_id\"] == 0:\n            records = records.loc[[0], :]\n        \n        boxes = records[['x_min', 'y_min', 'x_max', 'y_max']].values\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n        labels = torch.tensor(records[\"class_id\"].values, dtype=torch.int64)\n\n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n\n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n\n        if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.tensor(sample['bboxes'])\n\n        if target[\"boxes\"].shape[0] == 0:\n            # Albumentation cuts the target (class 14, 1x1px in the corner)\n            target[\"boxes\"] = torch.from_numpy(np.array([[0.0, 0.0, 1.0, 1.0]]))\n            target[\"area\"] = torch.tensor([1.0], dtype=torch.float32)\n            target[\"labels\"] = torch.tensor([0], dtype=torch.int64)\n            \n        return image, target\n    \n    def __len__(self):\n        return self.image_ids.shape[0]","9a3ff6d6":"# Albumentations\ndef get_train_transform():\n    return A.Compose([\n        A.Flip(0.5),\n        A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=45, p=0.25),\n        A.LongestMaxSize(max_size=800, p=1.0),\n\n        # FasterRCNN will normalize.\n        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transform():\n    return A.Compose([\n        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","3bcbe83b":"# load a model; pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)","056f3c40":"num_classes = 15\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","ea1d1f63":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_dataset = VinBigDataset(train_df, DIR_TRAIN, get_train_transform())\nvalid_dataset = VinBigDataset(valid_df, DIR_TRAIN, get_valid_transform())\n\n\n# split the dataset in train and test set\nindices = torch.randperm(len(train_dataset)).tolist()\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)","a4cdc1a4":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","66abab33":"images, targets = next(iter(train_data_loader))","81311b71":"images = list(image.to(device) for image in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]","9b66d666":"boxes = targets[2]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[2].permute(1,2,0).cpu().numpy()","2853011c":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","9b5c8f4d":"class Averager:\n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total \/ self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0","c0f3c967":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n\nnum_epochs = 12","4e6c06ba":"loss_hist = Averager()\nitr = 1\n\nfor epoch in range(num_epochs):\n    loss_hist.reset()\n    \n    for images, targets in train_data_loader:\n        \n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n\n        loss_hist.send(loss_value)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if itr % 100 == 0:\n            print(f\"Iteration #{itr} loss: {loss_hist.value}\")\n\n        itr += 1\n        \n        # !!!REMOVE THIS!!!\n        break\n    \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")   \n    # print(\"Saving epoch's state...\")\n    # torch.save(model.state_dict(), f\"model_state_epoch_{epoch}.pth\")","a93ecd78":"images, targets = next(iter(valid_data_loader))","cf1f0174":"images = list(img.to(device) for img in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]","dabd9bdd":"boxes = targets[1]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[1].permute(1,2,0).cpu().numpy()","550db9d5":"model.eval()\ncpu_device = torch.device(\"cpu\")\n\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]","4226c081":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","9db2dd55":"# Pytorch starter - FasterRCNN Train","4775bf1b":"# Sample","8c1b0029":"\n# DICOM Sample","996ab1d4":"You can find the [inference notebook here](https:\/\/kaggle.com\/pestipeti\/vinbigdata-fasterrcnn-pytorch-inference)\n\n- FasterRCNN from torchvision\n- Uses Resnet50 backbone\n- Albumentation enabled (flip + shift-scale-rotate)\n- Original Dicom Images (resized by faster-rcnn)\n- No validation yet\n\nI trained the latest version (LB: 0.91) on my local machine; the settings were the same as in this notebook (v12).","bcdf21c8":"# Train","412d23ef":"# Model","8dc71647":"# Data preparation","ab2a101d":"```\n********************************************************************************************\n         __           _                                _       _                 _    \n        \/ _|         | |                              | |     | |               | |   \n       | |_ ___  _ __| | ___ __ ___  _   _ _ __   ___ | |_ ___| |__   ___   ___ | | __\n       |  _\/ _ \\| '__| |\/ \/ '_ ` _ \\| | | | '_ \\ \/ _ \\| __\/ _ \\ '_ \\ \/ _ \\ \/ _ \\| |\/ \/\n       | || (_) | |  |   <| | | | | | |_| | | | | (_) | ||  __\/ |_) | (_) | (_) |   < \n       |_| \\___\/|_|  |_|\\_\\_| |_| |_|\\__, |_| |_|\\___\/ \\__\\___|_.__\/ \\___\/ \\___\/|_|\\_\\\n                                      __\/ |                                           \n                                     |___\/                                    \n********************************************************************************************\n                    If you'd like to publish a forked version of this notebook,\n                             please do not remove this notice.\n--------------------------------------------------------------------------------------------\n                                      Original Notebook\n--------------------------------------------------------------------------------------------\nTitle...............: VinBigData FasterRCNN PyTorch - Train\nLink................: https:\/\/kaggle.com\/pestipeti\/vinbigdata-fasterrcnn-pytorch-train\nAuthor..............: Peter (https:\/\/kaggle.com\/pestipeti)\nVersion.............: 12\n\n\n--------------------------------------------------------------------------------------------\n                                          Fork #1                   \n--------------------------------------------------------------------------------------------\nTitle...............: [Your notebook's title]\n\n```"}}