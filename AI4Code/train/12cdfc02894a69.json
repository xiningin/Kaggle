{"cell_type":{"e26fae13":"code","57c8bf22":"code","944f7a80":"code","65c867f3":"code","f6228e94":"code","eb903023":"code","13050214":"code","07bdb098":"code","8ac05aaf":"code","f20f90a5":"code","ef9e0988":"code","60d54929":"code","afad50db":"code","c1946b8e":"code","74c2fed9":"code","cc6f55d7":"code","d6fde248":"code","74c4bb5c":"code","66539c5c":"code","17764584":"code","a3225c40":"code","6c84d157":"code","87e047f9":"code","647747a9":"code","038bf8ed":"code","15b5c981":"code","2a27d0a0":"code","53f8e3dd":"code","bec7c85d":"code","bff503ba":"code","a9fc8ae7":"code","c4ba4eab":"code","e46a92fa":"code","0652e0ad":"code","8de786d2":"code","bd843441":"code","d714d9c4":"code","2b41affe":"code","38946e93":"code","8d6988b2":"code","d1909fdd":"code","2d38518a":"code","cf3a36fa":"code","519c9813":"code","9d16a309":"code","bb7243b1":"markdown","5a29de2a":"markdown","20cc2882":"markdown","f502f32f":"markdown","fb5e0bc1":"markdown","ead169b8":"markdown","b555ed29":"markdown","814d685a":"markdown","b976b07c":"markdown","7337075c":"markdown","cf1f4893":"markdown","0aa9a9b2":"markdown","92ad6212":"markdown","bf694d0a":"markdown","0e685149":"markdown","2a6c523b":"markdown","c5a263a7":"markdown","e8c5b614":"markdown","45ae6c6c":"markdown"},"source":{"e26fae13":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nimport datetime\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb","57c8bf22":"train_data=pd.read_csv('..\/input\/energy-industry\/ml_case_training_data.csv')\ntrain_out=pd.read_csv('..\/input\/energy-industry\/ml_case_training_output.csv')\ntrain_hist=pd.read_csv('..\/input\/energy-industry\/ml_case_training_hist_data.csv')","944f7a80":"train_data.head(4)","65c867f3":"train_data.describe()","f6228e94":"train_data.shape","eb903023":"train_data.dtypes","13050214":"nan_count=((train_data.isna().sum()\/train_data.shape[0])*100).sort_values(ascending=False)\nnan_count=nan_count[nan_count>0]\nplt.figure(figsize=(15,10))\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\nplt.xticks(rotation=90)\nsns.barplot(nan_count.index, nan_count.values)","07bdb098":"train_data.drop(nan_count.index[:7],axis=1,inplace=True)","8ac05aaf":"train_data['channel_sales']=train_data['channel_sales'].fillna('new category')","f20f90a5":"train_data[nan_count.index[8:]].nunique()","ef9e0988":"train_data[nan_count.index[8:]].isna().sum()","60d54929":"train_data[['date_modif_prod','date_renewal','date_end']]=train_data[['date_modif_prod','date_renewal',\n                                                            'date_end']].fillna(method='bfill')","afad50db":"for col in [x for x in nan_count.index[8:] if x not in ['date_modif_prod','date_renewal','date_end','origin_up',\n                                                        'forecast_price_energy_p1','forecast_price_energy_p2']]:\n    train_data[col] = np.round(pd.to_numeric(train_data[col], errors='coerce')).astype('Int64')","c1946b8e":"origin_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\ntrain_data[['origin_up']]=origin_imp.fit_transform(train_data[['origin_up']])","74c2fed9":"imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\ntrain_data[[x for x in nan_count.index[8:] if x not in ['date_modif_prod',\n                                                        'date_renewal','origin_up','date_end']]]=imp_freq.fit_transform(\n    train_data[[x for x in nan_count.index[8:] if x not in ['date_modif_prod',\n                                                        'date_renewal','origin_up','date_end']]])","cc6f55d7":"train=pd.merge(train_data, train_out, on=['id'])","d6fde248":"sales = train[[\"channel_sales\",\n               \"churn\", \"id\"]].groupby([\n    \"channel_sales\",\"churn\"])[\"id\"].count().unstack(level=1).sort_values(by=[1],ascending=False)[:5]\nsales_percentage = (sales.div(sales.sum(axis=1), axis=0)*100)\nsales.plot(kind=\"bar\",\n figsize=(18,10),\n stacked=True,\nrot=0,\n title= \"Top 5 sales channel with highest Churn Rate\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"Channel_sales\")\nplt.show()","74c4bb5c":"cons_12m = train[[\"has_gas\",\n               \"churn\", \"id\"]].groupby([\n    \"has_gas\",\"churn\"])[\"id\"].count().unstack(level=1).sort_values(by=[1],ascending=False)\ncons_12m_percentage = (cons_12m.div(cons_12m.sum(axis=1), axis=0)*100)\ncons_12m.plot(kind=\"bar\",\n figsize=(10,10),\n stacked=True,\nrot=0,\n title= \"Churn Rate - Has Gas Connection VS No Gas Connection\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"has_gas\")\nplt.show()","66539c5c":"cons_12m = train[[\"nb_prod_act\",\n               \"churn\", \"id\"]].groupby([\n    \"nb_prod_act\",\"churn\"])[\"id\"].count().unstack(level=1).sort_values(by=[1],ascending=False)[:5]\ncons_12m_percentage = (cons_12m.div(cons_12m.sum(axis=1), axis=0)*100)\ncons_12m.plot(kind=\"bar\",\n figsize=(18,10),\n stacked=True,\nrot=0,\n title= \"Churn Rate - No.of active connections\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"active connections\")\nplt.show()","17764584":"cons_12m = train[[\"num_years_antig\",\n               \"churn\", \"id\"]].groupby([\n    \"num_years_antig\",\"churn\"])[\"id\"].count().unstack(level=1).sort_values(by=[1],ascending=False)[:10]\ncons_12m_percentage = (cons_12m.div(cons_12m.sum(axis=1), axis=0)*100)\ncons_12m.plot(kind=\"bar\",\n figsize=(18,10),\n stacked=True,\nrot=0,\n title= \"Churn Rate - Antiquity of consumer\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"Antiquity\")\nplt.show()","a3225c40":"cons_12m = train[[\"origin_up\",\n               \"churn\", \"id\"]].groupby([\n    \"origin_up\",\"churn\"])[\"id\"].count().unstack(level=1).sort_values(by=[1],ascending=False)\ncons_12m_percentage = (cons_12m.div(cons_12m.sum(axis=1), axis=0)*100)\ncons_12m.plot(kind=\"bar\",\n figsize=(18,10),\n stacked=True,\nrot=0,\n title= \"Churn Rate - code of the electricity campaign the customer first subscribed to\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"origin_up\")\nplt.show()","6c84d157":"train_data.hist(bins=50, figsize=(20,15))\nplt.tight_layout(pad=0.4)\nplt.show()","87e047f9":"train_hist.hist(bins=50, figsize=(20,15))\nplt.tight_layout(pad=0.4)\nplt.show()","647747a9":"for col in ['date_activ','date_end','date_modif_prod','date_renewal']:\n    train[col]=pd.to_datetime(train_data[col])","038bf8ed":"train.dtypes","15b5c981":"train['contract_tenure']=train['date_end']-train['date_activ']\ntrain['contract_tenure']=train['contract_tenure'].apply(lambda x:x.days)","2a27d0a0":"train['contract_tenure_year']=train['contract_tenure'].apply(lambda x:int(np.round(x\/365)))","53f8e3dd":"tenure = train[[\"contract_tenure_year\", \"churn\", \"id\"]].groupby([\"contract_tenure_year\",\n                                                                 \"churn\"])[\"id\"].count().unstack(level=1)\ntenure_percentage = (tenure.div(tenure.sum(axis=1), axis=0)*100)\ntenure.plot(kind=\"bar\",\n figsize=(18,10),\n stacked=True,\nrot=0,\n title= \"Tenure VS Churn Rate\")\n# Rename legend\nplt.legend([\"Retention\", \"Churn\"], loc=\"upper right\")\n# Labels\nplt.ylabel(\"No. of Consumers\")\nplt.xlabel(\"No. of years\")\nplt.show()","bec7c85d":"train['bill_dev']=(train['cons_12m']\/12)-train['cons_last_month']","bff503ba":"def handleInf(x):\n    if x==float('-inf') or x==float('inf'):\n        return 0","a9fc8ae7":"train['cons_pattern']=train['forecast_cons_12m']\/train['cons_12m']\ntrain.cons_pattern=train.cons_pattern.apply(handleInf)","c4ba4eab":"train_hist.shape","e46a92fa":"train_hist.head(3)","0652e0ad":"(train_hist.isna().sum()\/train_hist.shape[0])*100","8de786d2":"imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain_hist[['price_p1_var','price_p2_var','price_p3_var','price_p1_fix','price_p2_fix','price_p3_fix']]=imp_freq.fit_transform(\n    train_hist[['price_p1_var','price_p2_var','price_p3_var','price_p1_fix','price_p2_fix','price_p3_fix']])","bd843441":"train_hist['price_p1']=train_hist['price_p1_var']+train_hist['price_p1_fix']\ntrain_hist['price_p2']=train_hist['price_p2_var']+train_hist['price_p2_fix']\ntrain_hist['price_p3']=train_hist['price_p3_var']+train_hist['price_p3_fix']\ntrain_hist['pp12']=train_hist['price_p2']-train_hist['price_p1']\ntrain_hist['pp23']=train_hist['price_p3']-train_hist['price_p2']\ntrain_hist['pp13']=train_hist['price_p3']-train_hist['price_p1']","d714d9c4":"train_hist.drop(['price_date','price_p1_var','price_p2_var','price_p3_var',\n                'price_p1_fix','price_p2_fix','price_p3_fix'],inplace=True,axis=1)","2b41affe":"train=pd.merge(train_hist, train, on=['id'])","38946e93":"train.fillna(0,inplace=True)\ny = train[\"churn\"]\nX = train.drop(labels = [\"id\",'date_activ','date_end','date_modif_prod','date_renewal',\"churn\"],axis = 1)","8d6988b2":"X['has_gas']=X['has_gas'].apply(lambda x:0 if x=='f' else 1)","d1909fdd":"ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6,24])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","2d38518a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=18)","cf3a36fa":"model = xgb.XGBClassifier(learning_rate=0.1,max_depth=6,n_estimators=500,n_jobs=-1,use_label_encoder=False)\nresult = model.fit(X_train,y_train)","519c9813":"def evaluate(model_, X_test_, y_test_):\n \n prediction_test_ = model_.predict(X_test_)\n \n results = pd.DataFrame({\"Accuracy\" : [metrics.accuracy_score(y_test_, prediction_test_)],\n \"Precision\" : [metrics.precision_score(y_test_, prediction_test_)],\n \"Recall\" : [metrics.recall_score(y_test_, prediction_test_)]})\n \n\n return results\n","9d16a309":"evaluate(model, X_test, y_test)","bb7243b1":"Filling mising dates with dates from next row","5a29de2a":"Hmm...Campaign_disc_ele column doesn't have any entry in it. Another 6 columns have more than 50% of the data empty. Lets drop those features as columns with majority null values is only going to hurt our model.","20cc2882":"We are going to evaluate our model on our test data (which we did not use for training) using the evalution metrics of:\n","f502f32f":"In the features, Features channel_sales and origin_up are the two categorical variables. Let's encode them.","fb5e0bc1":"# Modeling & Evaluation","ead169b8":"# Feature Engineering","b555ed29":"Let's calculate the deviation of last month bill from the average of last 12 months.","814d685a":"Next we will split the data into training and validation data. The percentages of each test can be changed but a 75%-25% is a good ratio. We also use a random state generator in order to split it randomly.","b976b07c":"Label encode has_gas feature","7337075c":"Only less than a percent of the data is missing in train_hist dataset. Fill them with mean values","cf1f4893":"We can clearly see that churn is very low for companies which joined recently or that have made the contract a long time ago. With the higher number ofchurners within the 3-7 years of tenure.","0aa9a9b2":"Calculate the ratio of last 12month consumption to next 12 month forecasted consumption","92ad6212":"The goal of this program challenge is to predict the probability of customers churn on one of BCG clients called PowerCo. PowerCo is a company that focus on supplying gas and electricity for SME( Small Medium Enterprises) and residential customers. They want to derive an effective decision to the declining customers lately by collaboration with BCG. One hypothesis that likely to happen of the customers churn during period of January to March 2016 is the price sensitiviy and the issue of power-liberalization market in Europe. We, as consultant want to understand the data better and derive actionable insights through the hypothesis whether we should consider marketing strategy that PowerCo is trying to do by offering 20% discount to the customers churn. Is it an effective way to do or any other solutions that we can deliver to the client?. Because this is a classification problem, we will be using one or more classification algorithms such as Logistic Regression, Decision tree, or Random Forest by always checking a few importants parts such as overfitting or underfitting model.\n\nFor these reasons, We will analyze three datasets that we will believe can support the insights by following data :\n\nHistorical customer data: Customer data such as usage, sign up date, forecasted usage etc\nHistorical pricing data: variable and fixed pricing data etc\nChurn indicator: whether each customer has churned or not\nWe start the exploratory data analysis by loading the dataset using pandas, checking missing values, doing feature engineering,checking outliers and comparing between univariate and bivariate features,improving the model using ML Algorithms(Logistics regression, Decision Tree, Random Forest or Gradient Boosting) as classificication model. However, before diving into building model, we will be building exploratory data analysis for the first project.\n\nFile descriptions\n\nml_case_training_data.csv - the training set (contains 16096 records)\nml_case_training_hist_data.csv - the testing set (contains 193002 records)\nml_case_training_output.csv - a sample of output whether the clients churned or not\nData fields\n\nid contact id\nactivity_new category of the company's activity\ncampaign_disc_ele code of the electricity campaign the customer last subscribed to\nchannel_sales code of the sales channel\ncons_12m electricity consumption of the past 12 months\ncons_gas_12m gas consumption of the past 12 months\ncons_last_month electricity consumption of the last month\ndate_activ date of activation of the contract\ndate_end registered date of the end of the contract\ndate_first_activ date of first contract of the client\ndate_modif_prod date of last modification of the product\ndate_renewal date of the next contract renewal\nforecast_base_bill_ele forecasted electricity bill baseline for next month\nforecast_base_bill_year forecasted electricity bill baseline for calendar year\nforecast_bill_12m forecasted electricity bill baseline for 12 months\nforecast_cons forecasted electricity consumption for next month\nforecast_cons_12m forecasted electricity consumption for next 12 months\nforecast_cons_year forecasted electricity consumption for next calendar year\nforecast_discount_energy forecasted value of current discount\nforecast_meter_rent_12m forecasted bill of meter rental for the next 12 months\nforecast_price_energy_p1 forecasted energy price for 1st period\nforecast_price_energy_p2 forecasted energy price for 2nd period\nforecast_price_pow_p1 forecasted power price for 1st period\nhas_gas indicated if client is also a gas client\nimp_cons current paid consumption\nmargin_gross_pow_ele gross margin on power subscription\nmargin_net_pow_ele net margin on power subscription\nnb_prod_act number of active products and services\nnet_margin total net margin\nnum_years_antig antiquity of the client (in number of years)\norigin_up code of the electricity campaign the customer first subscribed to\npow_max subscribed power\nprice_date reference date\nprice_p1_var price of energy for the 1st period\nprice_p2_var price of energy for the 2nd period\nprice_p3_var price of energy for the 3rd period\nprice_p1_fix price of power for the 1st period\nprice_p2_fix price of power for the 2nd period\nprice_p3_fix price of power for the 3rd period\nchurned has the client churned over the next 3 months\n","bf694d0a":"Let's build some new features from the exisitng features that might help the model. LEt's start with the current contract's tenure.","0e685149":"Like our intuition, the no. of unique values in the price and power features reduced when converted to integer. L:ets replace the missing values with most frequent values.","2a6c523b":"We can go further and apply K fold cross validation and hyperparameter tuning to improve the model score. However, I am stopping it here for now. If you have liked the kernel, **Do upvote!**","c5a263a7":"# EDA & Data Cleaning","e8c5b614":"Price, Power etc are units that can be converted as integers and not float since decimal places in prices doesn't make a huge change in value. Like wise is the case for power units. We exclude 'forecast_price_energy_p1','forecast_price_energy_p2' from converting since the values in every entry is around zero.","45ae6c6c":"Now it's time to split the data into Independent and Dependent variables. Lets drop dates and id from the train dataset as we are going to the modelling part where we need only features."}}