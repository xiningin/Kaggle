{"cell_type":{"2de6178a":"code","01e9435e":"code","bcb3f948":"code","6bc0e6e8":"code","0fc6a171":"code","6aaf8220":"code","3f67f693":"code","fce96ec4":"code","d3427214":"code","7b28d029":"code","1714b321":"code","271a4267":"code","6eb76e19":"code","d2a8eb80":"code","60fbcfce":"code","f0aaf33f":"code","d937ca93":"code","c2581775":"code","e9d1f760":"code","38d4e100":"code","ce5128ed":"code","265b44f3":"code","819b5b55":"code","643a79fc":"code","0a168473":"markdown","fd923f02":"markdown","0d171e69":"markdown","59549606":"markdown","1696f17b":"markdown","8bbc5a75":"markdown","04a7fe68":"markdown"},"source":{"2de6178a":"#Importing dependencies\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","01e9435e":"#reading the data\ndata=pd.read_csv('amazon_alexa.tsv', sep='\\t')\ndata.info()","bcb3f948":"#Checking for missing data\ndata.isnull().any().any()","6bc0e6e8":"#Determine overall sentiment using histogram to plot feedback\noverall_sentiment = data['feedback']\nplt.hist(overall_sentiment, bins = 2)\nplt.xlabel('Negative             Positive ')\nplt.ylabel('Number of Reviews')\nplt.show() ","0fc6a171":"data.feedback.value_counts()","6aaf8220":"data.groupby('variation').mean()[['rating']].plot.barh(figsize=(12, 7),colormap = 'ocean')\nplt.title(\"Variation wise Mean Ratings\");","3f67f693":"Sentiment_count=data.groupby('rating').count()\nplt.bar(Sentiment_count.index.values, Sentiment_count['verified_reviews'])\nplt.xlabel('Review Sentiments')\nplt.ylabel('Number of Review')\nplt.show()","fce96ec4":"data.rating.value_counts()","d3427214":"# adding a length column for analyzing the length of the reviews\n\ndata['length'] = data['verified_reviews'].apply(len)\n\ndata.groupby('length').describe().sample(5)","7b28d029":"color = plt.cm.rainbow(np.linspace(0, 1, 15))\ndata['variation'].value_counts().plot.bar(color = color, figsize = (15, 9))\nplt.title('Distribution of Variations in Alexa', fontsize = 20)\nplt.xlabel('variations')\nplt.ylabel('count')\nplt.show()","1714b321":"#finding which words occur the most\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize import RegexpTokenizer\ntoken = RegexpTokenizer(r'[a-zA-Z0-9]+')\ncv = CountVectorizer(stop_words='english',tokenizer = token.tokenize)","271a4267":"words = cv.fit_transform(data.verified_reviews)\nsum_words = words.sum(axis=0)","6eb76e19":"words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])","d2a8eb80":"color = plt.cm.jet(np.linspace(0, 1, 20))\nfrequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\nplt.title(\"Top 20 Most Frequently Occuring Words\")\nplt.show()","60fbcfce":"#todo:wordcloud\n!pip install wordcloud\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(background_color='white',width=800, height=500).generate_from_frequencies(dict(words_freq))\nplt.figure(figsize=(10,8))\nplt.imshow(wordcloud)\nplt.title(\"WordCloud - Vocabulary from Reviews\", fontsize=22);","f0aaf33f":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","d937ca93":"corpus = []\nfor i in range(0, 3150):\n    review = re.sub('[^a-zA-Z]', ' ', data['verified_reviews'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","c2581775":"from sklearn.feature_extraction.text import TfidfVectorizer\ntf=TfidfVectorizer()\ntext_tf= tf.fit_transform(data['verified_reviews'])","e9d1f760":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    text_tf, data['rating'], test_size=0.3, random_state=123)","38d4e100":"#model building, model used: Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Generation Using Multinomial Naive Bayes\nclf = MultinomialNB().fit(X_train, y_train)\npredicted= clf.predict(X_test)\nprint(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted)*100)","ce5128ed":"text_counts= cv.fit_transform(data['verified_reviews'])","265b44f3":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    text_counts, data['rating'], test_size=0.3, random_state=1)","819b5b55":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\n# Model Generation Using Multinomial Naive Bayes\nclf = MultinomialNB().fit(X_train, y_train)\npredicted= clf.predict(X_test)\nprint(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted)*100)","643a79fc":"predicted","0a168473":"#### All of the Alexa Product variation's mean ratings are above 4 ( in a rating scale 1-5) with the Oak & Walnut finish rated slightly higher. ","fd923f02":"#### The words echo and love have been used the most; Followed by adjectives such as : Great,music,works,sound,easy.","0d171e69":"##### 1: Positive Sentiment, 0: Negative Sentiment\n##### The product users have an overwhelmingly positive sentiment associated to the Alexa.","59549606":"#### The variations plot above represents the number of different variants of the Amazon Alexa that have been reviewed. ","1696f17b":"# Amazon Alexa Reviews Sentiment Analysis using NLP\n<b>About the Data<\/b>\n\nThis dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train Machine for sentiment analysis.\n\n<b>What has been done with the data ?<\/b><\/br>\n\nThis data has been used to analyse Amazon's Alexa product line-up, and perform sentiment analysis to understand why users like a certain product.\n<\/br>\n\n<b>Source:<\/b>\nExtracted from Amazon's website\n","8bbc5a75":"#### Our multinomial classifier model yields a 75% accuracy","04a7fe68":"<p> A word cloud is a novelty visual representation of text data, typically used to depict keyword metadata on websites, or to visualize free form text. The importance of each WORD is shown with font size or color.<\/p>"}}