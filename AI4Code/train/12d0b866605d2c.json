{"cell_type":{"b8cb06d9":"code","9b16eb28":"code","e758fe61":"code","a1513f64":"code","28215ba8":"code","0a10cdda":"code","4286efef":"code","74477d9d":"code","864a8234":"code","a1d99227":"code","a84349d0":"code","240ff588":"code","759ef850":"code","ccda3304":"code","1a651184":"code","32f3fac1":"code","268c1476":"code","be6a52d4":"code","48931d68":"code","b94da3ce":"code","22d3b27a":"code","259754bb":"code","0de34b7d":"code","06d95a88":"code","e2db6af0":"code","dc64190d":"code","e2225758":"code","6c5fe2e1":"code","4b3261a0":"code","c54ab6f1":"code","116c2742":"code","ae536695":"code","1cd7c934":"code","2eafb086":"code","cc54c82a":"markdown","5018dd92":"markdown","2d2d4e18":"markdown","1fe7ca0c":"markdown","ac64e71a":"markdown","d753415a":"markdown","aa19ff9e":"markdown","179bcd3e":"markdown","21ddde76":"markdown","0c324914":"markdown","1f4c4880":"markdown"},"source":{"b8cb06d9":"import imagehash\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nfrom PIL import Image\nimport plotly.express as px\nimport string\nimport re\nimport cv2\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#import geffnet\n#from transformers import *\nimport os\n\n#+++++++++++\nimport sys\nsys.path = [\n    '..\/input\/geffnet-20200820'  \n] + sys.path\n","9b16eb28":"# Images Directory\n\ntrain_img_path = \"..\/input\/shopee-product-matching\/train_images\/\"\ntest_img_path = \"..\/input\/shopee-product-matching\/test_images\/\"\n","e758fe61":"train_data =pd.read_csv(\"..\/input\/shopee-product-matching\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/shopee-product-matching\/test.csv\")\nsample = pd.read_csv('..\/input\/shopee-product-matching\/sample_submission.csv')\ntest_img = \"..\/input\/shopee-product-matching\/test_images\"","a1513f64":"train_data.head()","28215ba8":"train_data[\"path\"] = [os.path.join(train_img_path,s) for s in train_data[\"image\"]]\ntest_data[\"path\"] = [os.path.join(test_img_path,s) for s in test_data[\"image\"]]\n","0a10cdda":"train_data.to_csv(\"train_data.csv\",index=False)\ntest_data.to_csv(\"test_data.csv\",index=False)","4286efef":"train_data.head(3)","74477d9d":"nRow, nCol = train_data.shape\nprint('train_data:', {nRow},'rows ', {nCol},'columns')","864a8234":"# find image_phash duplicates And visualize\ndup_data = train_data[\"image_phash\"].value_counts()\ndup_data = pd.DataFrame(dup_data).reset_index(drop=False).rename(columns={\"image_phash\":\"Occurences\",\"index\":\"image_phash\"})\ndup_data[\"image_phash\"] = dup_data[\"image_phash\"].astype(\"str\")\nfig = px.bar(dup_data[:20],x=\"image_phash\",y=\"Occurences\",color= \"Occurences\",\\\n             title=\"duplicates image_phash \")\nfig.update_layout(title ={\"x\":0.475,\"y\":0.9,\"xanchor\":\"center\",\"yanchor\":\"top\"})\nfig.show()","a1d99227":"dup_data.head()","a84349d0":"#fad28daa2ad05595\n\nimages_filter = ['posting_id', 'image_phash', 'image', 'title', 'path']\n\nimages_filter2 = train_data[images_filter]\n\n#df[ (df.column0 == thing1) and (df.column1 == thing2) ]\n\n#filtered_data2 = filtered_data2.image_phash == \"fad28daa2ad05595\"\n\nimages_filter3 = images_filter2[images_filter2['image_phash'] == 'fad28daa2ad05595'] \n  \n#print(df_new) \n\n# Filter data to image_phash = fad28daa2ad05595\n# Title: sugarbaby\n\nimages_filter3.head()\n","240ff588":"sugarbaby_item_len = len(images_filter3)\nprint(sugarbaby_item_len)","759ef850":"plt.figure(figsize=(20,20))\n\nfor num,a in enumerate(images_filter3[\"path\"]):\n    plt.subplot(6,5,num+1)\n    img = cv2.imread(a)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.axis(\"off\")\n    plt.title(images_filter3[\"posting_id\"].iloc[num])\n    plt.imshow(img)\n    ","ccda3304":"#04a00bccb7f1560e755f5f1def73db59.jpg\n#1dbf735adb93d54e6340af02f9b5472e.jpg\n#003c7129aef72ad3ae8af64eac5bfd29.jpg\n#0f459b1e8aa89ee9e79b2ec95440e9c3.jpg\n\n# Create the Hash Object of the first image\nPictureHash1 = imagehash.average_hash(Image.open(train_img_path + '04a00bccb7f1560e755f5f1def73db59.jpg'))\nprint('Picture Hashing: ' + str(PictureHash1))\n\n# Create the Hash Object of the second image\nPictureHash2 = imagehash.average_hash(Image.open(train_img_path + '1dbf735adb93d54e6340af02f9b5472e.jpg'))\nprint('Picture Hashing: ' + str(PictureHash2))\n\nif PictureHash1 == PictureHash2:\n    print(\"Identical pictuers\")\nelse:\n    print(\"diffrent pictuers\")\n\n","1a651184":"from PIL import *\nfrom skimage import *\nimport imagehash","32f3fac1":"plt.figure(figsize=(20,20))\n\nfor num,a in enumerate(test_data[\"path\"]):\n    \n    plt.subplot(1,3,num+1)\n    img = cv2.imread(a)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    plt.imshow(img)\n    plt.axis(\"off\")","268c1476":"test_data.head()","be6a52d4":"# find image_phash duplicates And visualize\ndup_data = test_data[\"image_phash\"].value_counts()\ndup_data = pd.DataFrame(dup_data).reset_index(drop=False).rename(columns={\"image_phash\":\"Occurences\",\"index\":\"image_phash\"})\ndup_data[\"image_phash\"] = dup_data[\"image_phash\"].astype(\"str\")\nfig = px.bar(dup_data[:25],x=\"image_phash\",y=\"Occurences\",color= \"Occurences\",\\\n             title=\"duplicates image_phash \")\nfig.update_layout(title ={\"x\":0.475,\"y\":0.9,\"xanchor\":\"center\",\"yanchor\":\"top\"})\nfig.show()","48931d68":"from collections import defaultdict","b94da3ce":"every_phash = defaultdict(list)","22d3b27a":"practicedf = train_data.iloc[:20,:]","259754bb":"for num, row in enumerate(practicedf[['posting_id', 'image_phash']].values):\n    every_phash[row[1]].append(row[0])","0de34b7d":"phash_list = []\n\nfor num, row in enumerate(practicedf[['posting_id','image_phash']].values):\n    pred = \"\"\n    for a in every_phash[row[1]]:\n        pred = pred + a + \" \"\n\n    \n    pred=pred[:-1] # delete last space\n    \n    phash_list.append(pred)","06d95a88":"phash_list[:20]","e2db6af0":"practicedf[\"matches\"] = phash_list\npracticedf","dc64190d":"test_data","e2225758":"every_phash = defaultdict(list)","6c5fe2e1":"for num, row in enumerate(test_data[['posting_id', 'image_phash']].values):\n    every_phash[row[1]].append(row[0])","4b3261a0":"every_phash\n","c54ab6f1":"phash_list = []\n\nfor num, row in enumerate(test_data[['posting_id','image_phash']].values):\n    pred = \"\"\n    for a in every_phash[row[1]]:\n        pred = pred + a + \" \"\n\n    \n    pred=pred[:-1] # delete last space\n    \n    phash_list.append(pred)","116c2742":"test_data[\"matches\"] = phash_list\ntest_data","ae536695":"for num, row in enumerate(test_data[['posting_id', 'image_phash']].values):\n    every_phash[row[1]].append(row[0])","1cd7c934":"submission = test_data[[\"posting_id\",\"matches\"]]\nsubmission","2eafb086":"submission.to_csv(\"submission.csv\",index=False)","cc54c82a":"# I will start workting with test images\n* i will check image_phash description  \n* i will check the Average Hashing of the images","5018dd92":"**Load the 3 Test Images**","2d2d4e18":"> image_phash fad28daa2ad05595 Occurences 26 let us check if all having the same pictuer","1fe7ca0c":"# Shopee - Price Match Guarantee\nDetermine if two products are the same by their images\n\n* predicts which items are the same products.\n* product matching\n\n**Benifits:** \nThe applications go far beyond Shopee or other retailers.\nYour contributions to product matching could support:\n* More accurate product categorization\n* Uncover marketplace spam\n* Aid shoppers to hunt for the very best deals.\n\n","ac64e71a":"# Train Images","d753415a":"# Add Img full path as column: path","aa19ff9e":"# Observation on image_phash fad28daa2ad05595 \n* 26 items have the same image and almost the same title.\n* I will consider image_phash and the title with the image\n","179bcd3e":"# **Disply top Occurences (duplicates) 20 records.**","21ddde76":"# Loading and exploring data (EDA)","0c324914":"* **(Please consider upvoting if you find it useful to you)**\n* **Switch off the internet from settings before submit**\n* **Thanks**","1f4c4880":"# Submission CSV\n"}}