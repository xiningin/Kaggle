{"cell_type":{"c75727dd":"code","6b1b6c19":"code","e37684a9":"code","6137549b":"code","ec56307c":"code","cf9092e8":"code","bc9746c4":"code","0baa937b":"code","b8b2c2e7":"code","1ceadc0f":"code","1c442139":"code","dc1854e1":"code","58865405":"code","5eb603c1":"code","2216d69b":"code","6db0785f":"code","8105493e":"code","e2225e61":"code","cec0c967":"code","4248d6b8":"code","8d587303":"code","ab9ad44b":"code","27927cd5":"code","5033c61b":"code","be356e90":"code","9f5d3e36":"code","bda9b8bc":"code","4b8aafbc":"code","e8fa77f8":"code","d662a611":"code","c6c19201":"code","3475c447":"code","4d457d26":"code","64c52b58":"code","02ae0f40":"markdown","ddb81d20":"markdown","b73d7ec2":"markdown","a1488e60":"markdown","0d73b7a9":"markdown","465514a3":"markdown","7f9f3401":"markdown","1fe6148a":"markdown","3506716b":"markdown"},"source":{"c75727dd":"# Read the Dataset\nimport pandas as pd\nx = pd.read_json('..\/input\/covid-patient-datasets\/covid.json')\n\ndataset1 = pd.read_json('..\/input\/covid-patient-datasets\/covid.json')","6b1b6c19":"# Convert the Dataset from JSON to CSV\nx.to_csv()","e37684a9":"x['concept'] = 1","6137549b":"#generation false data\nimport numpy as np\na = np.zeros((487,23))\n\nimport random\nfor i in range(487):\n  for j in range (23):\n      s = random.randint(0,1)\n      a[i,j] = s\n    \n    \n    \nfor i in range(487):\n    a[i,1] = random.randint(2,90)\n# convert from numpy to pandas\ncolumns = ['#','age','Sleep_problems','Headache', 'Diarrhea', 'Abdominal_pain',\n                 'body_pain', 'Body_discoloration', 'Cough',    'Fever', 'Ague', \n                  'Sore_throat', 'Fatigue', 'runny_nose', 'Chest_pain', 'Decreased_appetite',\n                  'Vomit'  , 'Nausea',    'Sneezing', 'Shortness_of_breath', 'Loss_of_smell', \n                  'Loss_of_taste',  'urticaria']\n\ndata = pd.DataFrame(a, columns = columns)\n\ndata['concept'] = 0","ec56307c":"data","cf9092e8":"# Combining Datasets\ndataset = pd.concat([x, data])","bc9746c4":"dataset","0baa937b":"# Show the dataset\ndataset.head()","b8b2c2e7":"#Get some information about our Dataset\ndataset.info()\ndataset.describe().transpose()","1ceadc0f":"# Check if there are any Null values\ndataset.isnull().sum()","1c442139":"dataset.isna().sum()","dc1854e1":"# Replace nan with 0 and null with yes\nimport numpy as np\ndataset.age.replace('-', 0, inplace=True)\ndataset.Headache.replace('', 'yes', inplace=True)","58865405":"# Convert dataset['age'] from object to int\ndataset['age'] = dataset['age'].astype(object).astype(int)","5eb603c1":"# Replace datates[age=0] with dataset[age=age.mean]\ndataset.age.replace(0, dataset['age'].mean(), inplace=True)","2216d69b":"dataset.info()","6db0785f":"# Make sure there is nothing except (Yes, yes, No, no) in the dataset\nfor i in range(len(dataset)):\n  for j in range(2,23): #Except the first and second columns \n    if (dataset.iloc[i,j] != 'Yes') and (dataset.iloc[i,j]!='yes') and (dataset.iloc[i,j]!='No') and (dataset.iloc[i,j]!='no'):\n      dataset.iloc[i,j] = 'yes'","8105493e":"# Replace (1, 0) instead of (yes, no)\n\n# Sleep_problems column\ndataset.Sleep_problems.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Headache column\ndataset.Headache.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Diarrhea column\ndataset.Diarrhea.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Abdominal column\ndataset.Abdominal_pain.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# body_pain column\ndataset.body_pain.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Body_discoloration column\ndataset.Body_discoloration.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Cough column\ndataset.Cough.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Fever column\ndataset.Fever.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Aguen column\ndataset.Ague.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n# Sore_throat column\ndataset.Sore_throat.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Fatigue column\ndataset.Fatigue.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# runny_nose column\ndataset.runny_nose.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Chest_pain column\ndataset.Chest_pain.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Decreased_appetite column\ndataset.Decreased_appetite.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Vomit column\ndataset.Vomit.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Nausea column\ndataset.Nausea.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Sneezing column\ndataset.Sneezing.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Shortness_of_breath column\ndataset.Shortness_of_breath.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Loss_of_smell column\ndataset.Loss_of_smell.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Loss_of_taste column\ndataset.Loss_of_taste.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)\n\n\n# Urticaria column\ndataset.urticaria.replace(('yes' , 'Yes', 'no' , 'No'), (1, 1, 0, 0), inplace=True)","e2225e61":"# Remove duplicate rows\ndataset.drop_duplicates(inplace=True)\ndataset.duplicated()","cec0c967":"# Create 'concept' column in dataset and set its value\n#dataset['concept'] = 1\n\n#for i in range(len(dataset)):\n  #if all(dataset.iloc[i,j]==0 for j in range(2,23)):\n\n    #print(i)\n    #dataset.iloc[i,23] = 0","4248d6b8":"# Normalaize the dataset\n\nx = dataset.drop(['#', 'concept'], axis=1)\nx_norm = (x - x.mean()) \/ (x.std())\n\nx_norm","8d587303":"# Sort the dataset\ndataset.sort_values(by='age', ascending=True)","ab9ad44b":"# Calculate the correlation coefficients\nxx = dataset.drop(['#'], axis=1)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(24, 12))\nsns.heatmap(xx.corr(method='pearson'), annot=True)","27927cd5":"corr = np.zeros(22)\nfor i in range (22):\n  corr[i] = xx.iloc[:,i].corr(xx['concept'])\n\nprint(np.sort(corr))","5033c61b":"# Find-s algorithm\ndef train(c,t):\n    for i, val in enumerate(t):\n        if val == 'yes' or \"Yes\":\n            specific_hypothesis = c[i].copy()\n            break\n             \n    for i, val in enumerate(c):\n        if t[i] == 'yes' or \"Yes\":\n            for x in range(len(specific_hypothesis)):\n                if val[x] != specific_hypothesis[x]:\n                    specific_hypothesis[x] = '?'\n                else:\n                    pass\n                 \n    return specific_hypothesis","be356e90":"# Set inputs\na = dataset1.drop(['#'], axis=1)\na = np.array(a)\n\n\n# Set target\nfor i in range(len(dataset)):\n\n  if dataset.iloc[i,23] == 1:\n    dataset['concept_d'] = 'yes'\n\nb = dataset['concept_d'] #target\nb = np.array(b)\n\n\nprint(\"The final hypothesis is:\",train(a,b))","9f5d3e36":"#Defining Model (Candidate Elimination algorithm concepts)\n\ndef learn(concepts, target):\n\n    specific_h = concepts[0].copy()\n\n    print(\"Initialization of specific_h and general_h\")\n\n    print(\"specific_h: \",specific_h)\n\n    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n\n    print(\"general_h: \",general_h)\n\n    print(\"concepts: \",concepts)\n\n    for i, h in enumerate(concepts):\n\n        if target[i] == \"yes\":\n\n            for x in range(len(specific_h)):\n\n                #print(\"h[x]\",h[x])\n\n                if h[x] != specific_h[x]:\n\n                    specific_h[x] = '?'\n\n                    general_h[x][x] = '?'\n\n        if target[i] == \"no\":\n\n            for x in range(len(specific_h)):\n\n                if h[x] != specific_h[x]:\n\n                    general_h[x][x] = specific_h[x]\n\n                else:\n\n                    general_h[x][x] = '?'\n\n    print(\"\\nSteps of Candidate Elimination Algorithm: \",i+1)\n\n    print(\"Specific_h: \",i+1)\n\n    print(specific_h,\"\\n\")\n\n    print(\"general_h :\", i+1)\n\n    print(general_h)\n\n    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n\n    print(\"\\nIndices\",indices)\n\n    for i in indices:\n\n        general_h.remove(['?', '?', '?', '?', '?', '?'])\n\n    return specific_h, general_h\n\ns_final,g_final = learn(a, b)\n\nprint(\"\\nFinal Specific_h:\", s_final, sep=\"\\n\")\n\nprint(\"Final General_h:\", g_final, sep=\"\\n\")","bda9b8bc":"# Naive Bayes Algorithm\nX = x_norm.values\nY = dataset.iloc[:, -1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, Y_train)\n\ny_pred  =  classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm = confusion_matrix(Y_test, y_pred)\nac = accuracy_score(Y_test,y_pred)\n\nprint(ac)","4b8aafbc":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train, Y_train)\n\ny_pred1 = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(Y_test, y_pred1))\nprint(classification_report(Y_test, y_pred1))","e8fa77f8":"# MLPC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import make_classification\n\nclf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, Y_train)\n\ny_pred2 = clf.predict(X_test)\nclf.score(X_test, Y_test)","d662a611":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,Y_train)\n\n#Predict the response for test dataset\ny_pred3 = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred3))","c6c19201":"# ID3 (Iterative Dichotomiser 3) Algorithm implementation from scratch\n\nimport math\nfrom collections import deque\n\nclass Node:\n    \"\"\"Contains the information of the node and another nodes of the Decision Tree.\"\"\"\n\n    def __init__(self):\n        self.value = None\n        self.next = None\n        self.childs = None\n\n\nclass DecisionTreeClassifier:\n    \"\"\"Decision Tree Classifier using ID3 algorithm.\"\"\"\n\n    def __init__(self, X, feature_names, labels):\n        self.X = X\n        self.feature_names = feature_names\n        self.labels = labels\n        self.labelCategories = list(set(labels))\n        self.labelCategoriesCount = [list(labels).count(x) for x in self.labelCategories]\n        self.node = None\n        self.entropy = self._get_entropy([x for x in range(len(self.labels))])  # calculates the initial entropy\n\n    def _get_entropy(self, x_ids):\n        \"\"\" Calculates the entropy.\n        Parameters\n        __________\n        :param x_ids: list, List containing the instances ID's\n        __________\n        :return: entropy: float, Entropy.\n        \"\"\"\n        # sorted labels by instance id\n        labels = [self.labels[i] for i in x_ids]\n        # count number of instances of each category\n        label_count = [labels.count(x) for x in self.labelCategories]\n        # calculate the entropy for each category and sum them\n        entropy = sum([-count \/ len(x_ids) * math.log(count \/ len(x_ids), 2) if count else 0 for count in label_count])\n        return entropy\n\n    def _get_information_gain(self, x_ids, feature_id):\n        \"\"\"Calculates the information gain for a given feature based on its entropy and the total entropy of the system.\n        Parameters\n        __________\n        :param x_ids: list, List containing the instances ID's\n        :param feature_id: int, feature ID\n        __________\n        :return: info_gain: float, the information gain for a given feature.\n        \"\"\"\n        # calculate total entropy\n        info_gain = self._get_entropy(x_ids)\n        # store in a list all the values of the chosen feature\n        x_features = [self.X[x][feature_id] for x in x_ids]\n        # get unique values\n        feature_vals = list(set(x_features))\n        # get frequency of each value\n        feature_vals_count = [x_features.count(x) for x in feature_vals]\n        # get the feature values ids\n        feature_vals_id = [\n            [x_ids[i]\n            for i, x in enumerate(x_features)\n            if x == y]\n            for y in feature_vals\n        ]\n\n        # compute the information gain with the chosen feature\n        info_gain = info_gain - sum([val_counts \/ len(x_ids) * self._get_entropy(val_ids)\n                                     for val_counts, val_ids in zip(feature_vals_count, feature_vals_id)])\n\n        return info_gain\n\n    def _get_feature_max_information_gain(self, x_ids, feature_ids):\n        \"\"\"Finds the attribute\/feature that maximizes the information gain.\n        Parameters\n        __________\n        :param x_ids: list, List containing the samples ID's\n        :param feature_ids: list, List containing the feature ID's\n        __________\n        :returns: string and int, feature and feature id of the feature that maximizes the information gain\n        \"\"\"\n        # get the entropy for each feature\n        features_entropy = [self._get_information_gain(x_ids, feature_id) for feature_id in feature_ids]\n        # find the feature that maximises the information gain\n        max_id = feature_ids[features_entropy.index(max(features_entropy))]\n\n        return self.feature_names[max_id], max_id\n\n    def id3(self):\n        \"\"\"Initializes ID3 algorithm to build a Decision Tree Classifier.\n        :return: None\n        \"\"\"\n        x_ids = [x for x in range(len(self.X))]\n        feature_ids = [x for x in range(len(self.feature_names))]\n        self.node = self._id3_recv(x_ids, feature_ids, self.node)\n        print('')\n\n    def _id3_recv(self, x_ids, feature_ids, node):\n        \"\"\"ID3 algorithm. It is called recursively until some criteria is met.\n        Parameters\n        __________\n        :param x_ids: list, list containing the samples ID's\n        :param feature_ids: list, List containing the feature ID's\n        :param node: object, An instance of the class Nodes\n        __________\n        :returns: An instance of the class Node containing all the information of the nodes in the Decision Tree\n        \"\"\"\n        if not node:\n            node = Node()  # initialize nodes\n        # sorted labels by instance id\n        labels_in_features = [self.labels[x] for x in x_ids]\n        # if all the example have the same class (pure node), return node\n        if len(set(labels_in_features)) == 1:\n            node.value = self.labels[x_ids[0]]\n            return node\n        # if there are not more feature to compute, return node with the most probable class\n        if len(feature_ids) == 0:\n            node.value = max(set(labels_in_features), key=labels_in_features.count)  # compute mode\n            return node\n        # else...\n        # choose the feature that maximizes the information gain\n        best_feature_name, best_feature_id = self._get_feature_max_information_gain(x_ids, feature_ids)\n        node.value = best_feature_name\n        node.childs = []\n        # value of the chosen feature for each instance\n        feature_values = list(set([self.X[x][best_feature_id] for x in x_ids]))\n        # loop through all the values\n        for value in feature_values:\n            child = Node()\n            child.value = value  # add a branch from the node to each feature value in our feature\n            node.childs.append(child)  # append new child node to current node\n            child_x_ids = [x for x in x_ids if self.X[x][best_feature_id] == value]\n            if not child_x_ids:\n                child.next = max(set(labels_in_features), key=labels_in_features.count)\n                print('')\n            else:\n                if feature_ids and best_feature_id in feature_ids:\n                    to_remove = feature_ids.index(best_feature_id)\n                    feature_ids.pop(to_remove)\n                # recursively call the algorithm\n                child.next = self._id3_recv(child_x_ids, feature_ids, child.next)\n        return node\n\n    def printTree(self):\n        if not self.node:\n            return\n        nodes = deque()\n        nodes.append(self.node)\n        while len(nodes) > 0:\n            node = nodes.popleft()\n            print(node.value)\n            if node.childs:\n                for child in node.childs:\n                    print('({})'.format(child.value))\n                    nodes.append(child.next)\n            elif node.next:\n                print(node.next)","3475c447":"X_train1 = dataset.drop(['concept'], axis=1)\n\nY_train1 = dataset['concept']\nY_train1 = Y_train1.to_numpy()\n\n","4d457d26":"tree_clf = DecisionTreeClassifier(X=X_train1, feature_names=Y_train1, labels=Y_train1)\nprint(\"System entropy {:.4f}\".format(tree_clf.entropy))","64c52b58":"dataset.describe().transpose()","02ae0f40":"> **ID3 (Iterative Dichotomiser 3) Algorithm**","ddb81d20":"# **Author: PariSima Arman**\n\nFinal edit on 1\/15\/2022\n\n\nAll rights reserved","b73d7ec2":"> **MultiLayer Perceptron Classifier (MLPC)**","a1488e60":"**Candidate Elimination algorithm**","0d73b7a9":"**Therefore, age, urticaria, vomit, body discoloration and sneezing have the least correlation with concept**","465514a3":"> **Decision Tree**","7f9f3401":"> **Find-S Algorithm******","1fe6148a":"> **KNN**","3506716b":"**Naive Bayes Algorithm**"}}