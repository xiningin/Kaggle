{"cell_type":{"709eefa0":"code","e6e6f7ce":"code","59d67e4a":"code","14534a31":"code","8a104500":"code","231e1a30":"code","a89c6cf4":"code","d52ef692":"code","3279e79c":"code","5046ddb1":"code","afb1e10a":"code","5439c189":"code","251e8e29":"code","81d62138":"code","ee3fbb6d":"code","d9b94cd4":"code","79f61610":"code","7eb5894f":"code","f3f2b036":"code","a1dc8610":"code","edfe8867":"code","d2ed1a37":"markdown","5213c287":"markdown","f44c487d":"markdown","feae8d3f":"markdown","835bc24e":"markdown","94af4317":"markdown","28cd27c1":"markdown"},"source":{"709eefa0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e6e6f7ce":"bmw = pd.read_csv(r'\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv')","59d67e4a":"bmw.head()","14534a31":"bmw.tail()","8a104500":"bmw.describe()","231e1a30":"bmw.query('engineSize == 0').head()","a89c6cf4":"bmw.isnull().sum()","d52ef692":"object_cols = [col for col in bmw.columns if bmw[col].dtype == \"object\"]","3279e79c":"object_cols","5046ddb1":"bmw[object_cols].nunique()","afb1e10a":"y=bmw.price\nX_=bmw.drop('price',axis=1)","5439c189":"X=pd.get_dummies(X_)","251e8e29":"from sklearn.model_selection import train_test_split","81d62138":"X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)","ee3fbb6d":"from xgboost import XGBRegressor\nfrom sklearn.metrics import accuracy_score","d9b94cd4":"my_model = XGBRegressor(n_estimators=500, learning_rate=0.1, n_jobs=-1)","79f61610":"my_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)], \n             verbose=False)","7eb5894f":"y_pred = my_model.predict(X_test)","f3f2b036":"my_model.score(X_test,y_test)","a1dc8610":"prices = pd.DataFrame(data={'Actual':y_test,'Predicted':y_pred}).round(0).astype(int)","edfe8867":"prices","d2ed1a37":"We'll use get_dummies from pandas to get rid of categorical variables.\nBut first let's split features and values for prediction ('price').","5213c287":"So, I've got accuracy score **94.8%** using **XGBRegressor**","f44c487d":"Everything is clear )))","feae8d3f":"Do we have any NaN datas?","835bc24e":"It's my first steps in Kaggle. I hope, I've made something useful.","94af4317":"Let's find out how many unique values for object columns do we have:","28cd27c1":"I'm just curious: which car has engineSize = 0?"}}