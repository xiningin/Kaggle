{"cell_type":{"54910ea1":"code","9e30dbd2":"code","14ae451c":"code","693abd68":"code","221e41bb":"code","58fe11f3":"code","bc8ceefe":"code","bea185ce":"code","11e3d5e3":"code","466fad76":"code","f20c603b":"code","723095aa":"code","680f6b50":"code","abfeaca2":"code","e7db3eea":"code","755acb26":"code","1df20ad1":"code","faf27ef0":"code","7b9821e1":"code","0f6e8f53":"code","dbd06a04":"code","eed4938a":"code","47c2021a":"code","59127dda":"code","7011d531":"code","d64f2d0d":"code","35f93a28":"code","e5d152e6":"code","49a8a8a1":"code","e5a184f4":"code","7620cd08":"code","fcb49c9d":"code","cc9996fb":"code","33045b89":"code","a7246a70":"code","06ffb17e":"code","0c3b578b":"code","74bd55e3":"code","fbe43505":"code","f512b61e":"code","03e66925":"code","336b0676":"code","5e5a6892":"code","558369d2":"code","ee131153":"code","04ea3b43":"code","ab57b0e9":"code","873a2533":"code","df82847f":"code","2fade825":"code","9466409a":"code","34c0c04c":"code","62c4a851":"code","a080d122":"code","e93c7949":"code","69d90568":"code","e1ebd3b5":"code","fe79de06":"markdown","51b652e2":"markdown","8a5e106e":"markdown","31c80bc1":"markdown","89a15fe3":"markdown","9d41f314":"markdown","2bc4bedf":"markdown","43841879":"markdown","67bcfa5b":"markdown","9a5dd9db":"markdown","f43e328d":"markdown","94be7e9b":"markdown","35458bdc":"markdown","ffabb2fe":"markdown","d9521730":"markdown","12bb5d3c":"markdown","1cefedc2":"markdown"},"source":{"54910ea1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e30dbd2":"# Importing Important Libraries\n\nimport numpy as np # for mathematical computation\nimport pandas as pd # for dealing with the data\nimport matplotlib.pyplot as plt # for visualization\nimport seaborn as sns # for visualization\n%matplotlib inline","14ae451c":"train = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")","693abd68":"train.head()","221e41bb":"train.shape","58fe11f3":"test.head()","bc8ceefe":"test.shape","bea185ce":"train.info()","11e3d5e3":"test.info()","466fad76":"# Let's see a statistical summary of the numerical columns in the train and test dataset.\n\ntrain.describe()","f20c603b":"test.describe()","723095aa":"plt.figure(figsize = (12,8))\nprint(train['Is_Lead'].value_counts())\ncolors = ['#66b3ff','#ffcc99']\nplt.pie(train['Is_Lead'].value_counts(), labels = ['0','1'], autopct='%.1f%%',colors= colors)\nplt.legend()\nplt.show()","680f6b50":"plt.figure(figsize = (12,8))\nsns.countplot(x='Gender', hue='Is_Lead', data=train).set_title('Gender Wise Customer Response in the Recommended Credit Cards')","abfeaca2":"plt.figure(figsize = (12,8))\nsns.countplot('Occupation', hue = 'Is_Lead', data = train).set_title('Occupation Wise Customer Response in the Recommended Credit Cards')","e7db3eea":"plt.figure(figsize = (12,8))\nsns.countplot('Channel_Code', hue = 'Is_Lead', data = train).set_title('Channel Code Wise Customer Response in the Recommended Credit Cards')","755acb26":"plt.figure(figsize = (10,6))\nsns.countplot('Channel_Code', hue = 'Is_Lead', data = train).set_title('Channel Code Wise Customer Response in the Recommended Credit Cards')","1df20ad1":"plt.figure(figsize = (10,6))\nsns.countplot(data=train.fillna('Missing'), x='Credit_Product', hue='Is_Lead', palette='summer')","faf27ef0":"# Region_Code : Code of the Region for the customers\n\nplt.figure(figsize=(15,8))\nax = sns.countplot(train.Region_Code, hue=train.Is_Lead)\nax.set_title('Distribution of Region Code')\nplt.xticks(rotation=45)\nplt.show()","7b9821e1":"rc_encoding = train.groupby('Region_Code')['Is_Lead'].mean().reset_index()\n\nplt.figure(figsize=(15,6))\nax = sns.barplot(x='Region_Code', y='Is_Lead', data=rc_encoding.sort_values(by=['Is_Lead'], ascending=False));\nax.set_title('Lead Probability Distribution of Region Code')\nplt.xticks(rotation=45)\nplt.show()","0f6e8f53":"# Avg_Account_Balance : Average Account Balance for the Customer in last 12 Months\n\nplt.figure(figsize=(12,6))\nax = sns.distplot(train.Avg_Account_Balance\/10000)\nax.set_title('Distribution of Average Account Balance (10k scale)')\nplt.show()","dbd06a04":"plt.figure(figsize=(10,6))\nax = sns.boxplot(train.Avg_Account_Balance, orient = 'v')\nax.set_title('Distribution of Average Account Balance ')\nplt.show()","eed4938a":"# Age: Age of the Customer (in Years)\n\nplt.figure(figsize=(12, 6))\nax = sns.distplot(train.Age)\nax.set_title('Distribution of Age')\nplt.show()","47c2021a":"plt.figure(figsize=(12, 6))\nsns.boxplot(train.Age).set_title(\"Distribution of Age\")","59127dda":"train.head()","7011d531":"# Replacing null values with 'Not Sure' for both train and test sets. Its al together creating new class\n\ntrain['Credit_Product'] = train['Credit_Product'].fillna(\"Not Sure\")\ntest['Credit_Product'] = test['Credit_Product'].fillna(\"Not Sure\")\ntrain[train['Credit_Product'] == 'Not Sure'].head()","d64f2d0d":"# Storing target value in 'Target' attribute for further usage\n\nTarget = pd.DataFrame(train['Is_Lead'])","35f93a28":"# Dropping unwanted columns \n\ntrain = train.drop(['Is_Lead', 'ID'], axis = 1)\ntest = test.drop(['ID'], axis = 1)\n\nprint(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","e5d152e6":"# Concat both sets to data file\n\ndata = pd.concat([train, test])\ndata.shape","49a8a8a1":"# Trying to reduce skewnees by applying some operators \n\ndata['Avg_Account_Balance'] = np.log(data['Avg_Account_Balance'])\n\ndata.head()","e5a184f4":"# Getting numeric and categorical columns\n\ndata_num_cols = data._get_numeric_data().columns \ndata_cat_cols = data.columns.difference(data_num_cols)\nprint(\"Numeric columns: \", data_num_cols)\nprint()\nprint(\"Categorical columns: \", data_cat_cols)","7620cd08":"#Separating both numeric and categorical data from set\n\ndata_num_data = data.loc[:, data_num_cols]\ndata_cat_data = data.loc[:, data_cat_cols]\n\nprint(\"Shape of num data:\", data_num_data.shape)\nprint(\"Shape of cat data:\", data_cat_data.shape)","fcb49c9d":"# Using StandardScaler to scale the data\n\nfrom sklearn import preprocessing\ns_scaler = preprocessing.StandardScaler()\ndata_num_data_s = s_scaler.fit_transform(data_num_data)\n\ndata_num_data_s = pd.DataFrame(data_num_data_s, columns = data_num_cols)\n\nfig, (ax1) = plt.subplots(ncols=1, figsize=(8, 5))\nax1.set_title('After StandardScaler')\n\nsns.kdeplot(data_num_data_s['Age'], ax=ax1)\nsns.kdeplot(data_num_data_s['Vintage'], ax=ax1)\nsns.kdeplot(data_num_data_s['Avg_Account_Balance'], ax=ax1);","cc9996fb":"from sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\ndata_cat_data = data_cat_data.apply(LabelEncoder().fit_transform)","33045b89":"# Strorig cleaned data into 'data_new'\n\ndata_num_data_s.reset_index(drop=True, inplace=True)\ndata_cat_data.reset_index(drop=True, inplace=True)\n#df = pd.concat([df1, df2], axis=1)\ndata_new = pd.concat([data_num_data_s, data_cat_data], axis = 1)","a7246a70":"Target","06ffb17e":"# Splitting back the data into train and test\n\ntrain_new = data_new.iloc[:245725,]\ntest_new = data_new.iloc[245726:,]\n\nprint(\"Shape of train data:\", train_new.shape)\nprint(\"Shape of test data:\", test_new.shape)","0c3b578b":"train_new.isnull().sum()","74bd55e3":"train_new.dtypes","fbe43505":"# Split the dataset into training and testing set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_new,Target,test_size=0.2,random_state=42)","f512b61e":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","03e66925":"# Now Ensemble Techniques (Bagging and Boosting)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","336b0676":"# Fitting random forest classifier\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)","5e5a6892":"# Evaluate Model Performance\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, plot_roc_curve, auc","558369d2":"rf_pred = rf.predict(X_test)\n\nrf_auc = roc_auc_score(y_test, rf_pred)\nrf_auc","ee131153":"# Fitting XGB Classifier\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)","04ea3b43":"xgb_pred = rf.predict(X_test)\n\nxgb_auc = roc_auc_score(y_test, rf_pred)\nxgb_auc","ab57b0e9":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='minority')\nX_sm, y_sm = smote.fit_resample(train_new,Target)","873a2533":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)","df82847f":"# Fitting random forest classifier on balanced dataset\n\nrfb = RandomForestClassifier()\nrfb.fit(X_train, y_train)","2fade825":"rfb_pred = rfb.predict(X_test)\n\nrfb_auc = roc_auc_score(y_test, rfb_pred)\nrfb_auc","9466409a":"# Fitting LightGBM on balance data\n\nfrom lightgbm import LGBMClassifier\n\nlgb = LGBMClassifier()\nlgb.fit(X_train, y_train)","34c0c04c":"lgb_predict = lgb.predict(X_test)","62c4a851":"lgb_auc_score = roc_auc_score(y_test, lgb_predict)\nlgb_auc_score","a080d122":"# Fitting XGB Classifier on balanced dataset\n\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)","e93c7949":"xgb_predict = model.predict(X_test)","69d90568":"xgb_auc_score = roc_auc_score(y_test, xgb_predict)\nxgb_auc_score","e1ebd3b5":"# Plotting roc curve\n\nfrom sklearn import metrics\n\nfalse_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, xgb_predict)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nplt.plot(false_positive_rate, true_positive_rate,label='AUC Level = %0.2f' % (roc_auc))\nplt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","fe79de06":"***Handle Categorical Variable using Label Encoder***","51b652e2":"***It is very strange to observe that the missing values do actually have more leads. Thus we should fill the missing values.***","8a5e106e":"## *Exploratory Data Analysis*","31c80bc1":"***The dataset is quite imbalanced as 76% peoples are not not interested for Credit card and 24% are interested***","89a15fe3":"***Let's see gender wise customer's response on recommended credit cards.***","9d41f314":"***The above summary shows that the average age of the customers who are eligible to take credit cards is 43 and the minimum age is 23 and the maximum age is 85.***\n\n***Vintage is how long the eligible customers have been on the bank records.The average is 3 year 8 months and the minimum is 7 months, the maximum year is 11 years(135 months)***","2bc4bedf":"***Channel X3 and X2 people are highly interested in recomeended credit cards when comapared to others, while people belongs to channel X1 are hihly non-interested in recommended credit cards.***","43841879":"## *Data Preprocessing*","67bcfa5b":"*We have outliers in the Average Account Balance feature*","9a5dd9db":"*The above information shows that there are nine features to predict the customer's interests in the recommended credit cards.*\n\n*In train dataset there are 245725 observations and 9 features and 1 target column.*","f43e328d":"## *Model Building*","94be7e9b":"***The count plot shows that male customers are highly interests in recommended credit cards when compare to female customers.***\n\n***The percentage of customers not interested in the recommended policies is high in both genders.***","35458bdc":"* Each region has differnt trend\n \n* Dummy Encoding of Region Code will increase complexity of Model and also preformance will be lowered\n \n* Will use Lead Probabilty Score of each region instead of categories.\n\n\n*probability_score = no_of_leads_in_region \/ no_of_customers_in_region*","ffabb2fe":"***Self employed people are highly interested in recomeended credit cards when comapared to others***","d9521730":"## *Model Performance Improvement*","12bb5d3c":"***Since Area Under the Curve is 90% which indicates that model performance is excellent and need no improvement at all.***","1cefedc2":"*The test dataset contains 105312 obsevations and 9 features.*"}}