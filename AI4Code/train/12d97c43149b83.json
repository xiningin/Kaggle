{"cell_type":{"decde3b3":"code","8a7d66e0":"code","28f0e692":"code","a9e5523e":"code","21e5d599":"code","7697dded":"code","06b09b53":"code","af8357a3":"code","5b4345eb":"code","ac455c96":"code","6379c5d2":"code","0da9cbce":"code","73892fbf":"code","79924da1":"markdown","03d54297":"markdown","1e9b2793":"markdown","efc2c55b":"markdown","3eb9f2ce":"markdown","a92df58a":"markdown","ef3acc4f":"markdown","cdb157d7":"markdown","3d276c00":"markdown","2e7ce727":"markdown","1c3ef138":"markdown"},"source":{"decde3b3":"# import pandas\nimport pandas as pd\n\n# read csv \ntrain_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\n\n# view first 5 rows of data\ntrain_data.head()","8a7d66e0":"# use .columns to view the column names in the data\ntrain_data.columns","28f0e692":"# Edit date: 03\/24\/2021 \n\n# defining prediction target\ny = train_data.SalePrice\n\n# choosing features\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n\n# defining features\nX = train_data[features]","a9e5523e":"# import the train_test_split function\nfrom sklearn.model_selection import train_test_split\n\n# define our two separate X and y\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0) # specify a number for random_state to \n                                                                        # ensure same results each run","21e5d599":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","7697dded":"# set list of potential tree depth \ncandidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n\n# use list comprehension to create a dictionary of each leaf node corresponding to its MAE\nscores = {leaf_node: get_mae(leaf_node, train_X, val_X, train_y, val_y) for leaf_node in candidate_max_leaf_nodes}\n\n# define best tree: min leaf_node and its MAE\nbest_tree= {min(scores, key=scores.get) : min(scores.values())}\n\n# define best_tree_size\nbest_tree_size = min(scores, key=scores.get)\n\n# view best_tree\nbest_tree","06b09b53":"# we've already imported DecisionTreeRegressor so we just need to import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# define model \ntrain_model = DecisionTreeRegressor(random_state=0)\n\n# fit model\ntrain_model.fit(train_X, train_y)","af8357a3":"# make validation predictions and calculate mean absolute error w\/out specifying max_leaf_nodes\nval_predictions = train_model.predict(val_X)\nval_mae = mean_absolute_error(val_y, val_predictions)\nprint(\"Validation Mean absolute error without specifing max_leaf nodes: {:,.0f}\".format(val_mae))","5b4345eb":"# redefine model with best_tree_size\ntrain_model = DecisionTreeRegressor(max_leaf_nodes=50, random_state=0)\n\n# fit model\ntrain_model.fit(train_X,train_y)\n\n# calculating MAE using max_leaf_node \nval_predictions = train_model.predict(val_X)\nval_mae = mean_absolute_error(val_y, val_predictions)\nprint(\"Validation Mean absolute error for best value of max_leaf_node: {:,.0f}\".format(val_mae))","ac455c96":"# define RandomForestRegressor model\nrf_model = RandomForestRegressor(random_state=0)\n\n# fit model\nrf_model.fit(train_X, train_y)\n\n# make predictions using RandomForestRegressor\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(val_y, rf_val_predictions)\nprint(\"Validation Mean absolute error for RandomForest Model: {:,.0f}\".format(rf_val_mae))","6379c5d2":"# build RF model and train it on all X and y \nrf_model_full_data = RandomForestRegressor(random_state=0)\nrf_model_full_data.fit(X,y)","0da9cbce":"# load data from test.csv\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\n\n# create test_X which includes the columns from the predictions and applies it to the test_data\ntest_X= test_data[features]\n\n# make predictions for the competition\ntest_pred = rf_model_full_data.predict(test_X)","73892fbf":"output = pd.DataFrame({'Id': test_data.Id,\n                      'SalePrice': test_pred})\noutput.to_csv('submission.csv', index=False)","79924da1":"# Task 3: Split the data\n\nBefore we start building our model and making predictions, we'll have to split the data into two sets: training data & validation data\n\n**Why?** When we fit the model, the patterns are derived from the training data, meaning that if we make predictions using the training data then our model will appear very accurate. If it were given new data, then model would produce very inaccurate predictions.\n\nTherefore, we'll use `train_test_split` function from `sklearn.model_selection` to split our data into two different datasets. ","03d54297":"# Task 2: Inspect data\n\nAlthough we do see a whole column filled with `NaN`, we're going to disregard it in this case since if you refer to the `data_description.txt` you'll see that the `NaN` indicate that the houses did not have whatever the column name states. It does not mean that data wasn't recorded for it.\n\nWe can continue to inspecting our data to see what our prediction target is and what features we want to select for our model.","1e9b2793":"# Task 1: Load the data\n\n\nWe'll use the python library `pandas` to load and view our data","efc2c55b":"Now, let's find our best tree size","3eb9f2ce":"Last step is to submit the data!","a92df58a":"## Task 2.1 Defining the prediction target and features\nIn the Intro to Machine Learning course, I'll start off with the given features listed in the tutorial. As I advance within the course, I'll figure out ways to improve my model and add more features.\n\nFor now, I'll use the following features: `['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']`\n\nAnd since we're dealing with housing prices, our prediction target will be `SalePrice`","ef3acc4f":"## Task 4.1 Make predictions\nNow that the hard part is over with, all we'll have to do is plug in our variables into our model and see what predictions we get. \n\nWe'll use `DecisionTreeRegressor` and `RandomForestRegressor` as our models.","cdb157d7":"# Task 5: Create model for competition","3d276c00":"# Introduction\nIn this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this course.\n\nThe focus of this notebook are:\n\n1. Build a Random Forest model with all of your data (X and y).\n2. Read in the \"test\" data, which doesn't include values for the target. Predict home values in the test data with your Random Forest model.\n3. Submit those predictions to the competition and see your score.\n4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.\n\n# Tasks\nBefore building our model and submiting those predictions to the competition, we'll do a step-by-step process from loading the data to preparing it for our model.\n\nThese steps consist of:\n\n1. Loading the Data\n2. Inspecting the Data (i.e identifying the prediction target and features) \n3. Split the Data\n4. Build Model\n5. Create Model for Competition","2e7ce727":"# Task 4: Build model with training data\n### Subtasks:\n1. Find best_tree_size from max_leaf_node\n2. Make validation predictions \n    * when not specifying `max_leaf_node` \n    * specifying `max_leaf_node`\n    * using RandomForestRegressor\n    \nWe'll first build our model using our training data and build 3 different models to see which produces the lowest MAE (mean absolute error).\n\nIn summary, `max_leaf_node` is a list of values on how deep we want our tree. This helps in controlling underfitting vs. overfitting. We'll pick the `best_tree_size`, which is the leaf node with minimum MAE.\n\nWe'll create a function called `get_mae` that'll perform that process.","1c3ef138":"It seems that the `RandomForestRegressor` model predicts a smaller MAE at 23,093. With that information, I'll use the `RandomForestRegressor` to create a model for the competition.\n\nFor better accuracy, I'll create a new model and train it on all the training data before making predictions from the data in `test.csv`"}}