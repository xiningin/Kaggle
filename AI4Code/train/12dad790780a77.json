{"cell_type":{"348cec34":"code","c369eb91":"code","f211bfa4":"code","78c5eacd":"code","7e0d6318":"code","4e18a583":"code","5343e337":"code","63a5859e":"code","ed0f7400":"code","a54abca7":"code","f6c0ba86":"code","0ac06e5f":"code","34aa02a9":"code","6b863bcf":"code","26f7d531":"markdown","a4cf7285":"markdown","1389a602":"markdown","4862cf27":"markdown","32a86178":"markdown"},"source":{"348cec34":"# install latest version of sklearn(permutation importance needs ver.0.22 or later)\n#  git+https:\/\/github.com\/scikit-learn\/scikit-learn.git\n!pip install -U scikit-learn==\"0.22\"","c369eb91":"import matplotlib\nfrom matplotlib import font_manager\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rc\n\nfrom matplotlib import animation as ani\nfrom IPython.display import Image\n\nplt.rcParams[\"patch.force_edgecolor\"] = True\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\nsns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'","f211bfa4":"import sklearn\nsklearn.__version__","78c5eacd":"from sklearn.inspection import permutation_importance","7e0d6318":"import lightgbm as lgb\nfrom sklearn import datasets\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy.random as rd","4e18a583":"data = load_boston(return_X_y=False)\nX = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\ny = data[\"target\"]\nX.head()","5343e337":"from sklearn.metrics import mean_squared_error, make_scorer\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred)) \nmse_scorer = make_scorer(rmse)","63a5859e":"rd.seed(123)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\neval_result = {}\ncallbacks = [lgb.record_evaluation(eval_result)]\n\nparams_fit = {'X': X_train,\n              'y': y_train,\n              'eval_set': (X_test, y_test),\n              'early_stopping_rounds': 5,\n              'verbose': False,\n              'eval_metric': 'l2',\n             }\nmodel = lgb.LGBMRegressor(objective=\"regression\", n_estimators=100, importance_type=\"gain\", random_state=123)\ngbm = model.fit(**params_fit, callbacks=callbacks)\n# gbm.evals_result_\n\nimportance_df = pd.DataFrame({\"gain\":model.feature_importances_}, index=X.columns).sort_values(\"gain\", ascending=False)\nprint(\"[Feature importance]\")\ndisplay(importance_df)\n\nprint(\"[Permutation importance]\")\nresult = permutation_importance(model, X_train, y_train, scoring=mse_scorer, n_repeats=10, n_jobs=-1, random_state=71)\nresult_df = pd.DataFrame({\"importances_mean\":result[\"importances_mean\"], \"importances_std\":result[\"importances_std\"]}, index=X.columns)\ndisplay(result_df.sort_values(\"importances_mean\", ascending=False))\n\nresult_df.sort_values(\"importances_mean\", ascending=False).importances_mean.plot.barh()","ed0f7400":"rd.seed(123)\nX, X_test, y, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\nFOLD_NUM = 5\nfold_seed = 71\nfolds = KFold(n_splits=FOLD_NUM, shuffle=True, random_state=fold_seed)\nfold_iter = folds.split(X, y=y)\n\noof_preds = np.zeros(X.shape[0])\ny_preds = np.zeros((FOLD_NUM, X_test.shape[0]))\nmodels = []\nimportance_list = []\nperm_imp_list = []\nfold_label = np.zeros(X.shape[0])\nfor n_fold, (trn_idx, val_idx) in enumerate(fold_iter):\n    print(f\"========= fold:{n_fold} =========\")\n\n    X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_valid = y[trn_idx], y[val_idx]\n\n    params_fit = {'X': X_train,\n                  'y': y_train,\n                  'eval_set': (X_valid, y_valid),\n                  'early_stopping_rounds': 5,\n                  'verbose': False,\n                  'eval_metric': 'l2',\n                 }\n    model = lgb.LGBMRegressor(objective=\"regression\", n_estimators=100, importance_type=\"gain\", random_state=123)\n    gbm = model.fit(**params_fit, callbacks=callbacks)\n    models += [model]\n    \n    fold_label[val_idx] = n_fold\n    oof_preds[val_idx] = model.predict(X_valid, model.best_iteration_)\n    \n    rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[val_idx]))\n    print(f\"rmse score = {rmse: 0.5f}\")\n    \n    # Feature importance\n    importance_df = pd.DataFrame({\"gain\":model.feature_importances_}, index=X.columns).sort_values(\"gain\", ascending=False)\n    importance_list += [importance_df]\n    print(\"[Importance]\")\n    display(importance_df)\n    \n    # run permutation importance\n    result = permutation_importance(model, X_train, y_train, scoring=mse_scorer, n_repeats=10, n_jobs=-1, random_state=71)\n    perm_imp_df = pd.DataFrame({\"importances_mean\":result[\"importances_mean\"], \"importances_std\":result[\"importances_std\"]}, index=X.columns)\n    perm_imp_list += [perm_imp_df]\n    print(\"[Permutation feature Importance]\")\n    display(perm_imp_df.sort_values(\"importances_mean\", ascending=True))\n    perm_imp_df.sort_values(\"importances_mean\", ascending=False).importances_mean.plot.barh()\n    plt.show()\n    #break","a54abca7":"perm_importances_mean = pd.concat(perm_imp_list, axis=1)[\"importances_mean\"]\nperm_importances_mean.columns = [f\"fold_{i}\" for i in range(FOLD_NUM)]\nperm_importances_mean[\"ave\"] = perm_importances_mean.mean(axis=1)\nperm_importances_mean = perm_importances_mean.sort_values(\"ave\", ascending=False)","f6c0ba86":"perm_importances_std = pd.concat(perm_imp_list, axis=1)[\"importances_std\"]\nperm_importances_std.columns = [f\"fold_{i}\" for i in range(FOLD_NUM)]","0ac06e5f":"plt.figure(figsize=(25, 6))\nax = plt.subplot(111)\nperm_importances_mean.plot.bar(ax=ax, yerr=perm_importances_std)\nplt.title(\"Permutation Feature Importance\")","34aa02a9":"rmse = np.sqrt(mean_squared_error(y, oof_preds))\nprint(f\"rmse score = {rmse: 0.5f}\")","6b863bcf":"pred_result_df = pd.DataFrame({\"ground_truth\":y, \"oof_preds\":oof_preds, \"label\": [f\"fold_{int(l)}\" for l in  fold_label],})\n\nplt.figure(figsize=(8,7))\nax = plt.subplot(111)\nsns.scatterplot(x=\"ground_truth\", y=\"oof_preds\", hue=\"label\", data=pred_result_df, hue_order=[f\"fold_{int(l)}\" for l in range(5)], ax=ax)","26f7d531":"# Scoring function","a4cf7285":"* ## Permutation Importance\nPermutation importance is implemented on Scikit-learn 0.22 or later. In this kernel, introducing a usage of Permutation feature importance with LightGBM 5-fold CV.  \nURL: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance","1389a602":"# Hold-out prediction","4862cf27":"# 5-fold CV","32a86178":"# Loading data"}}