{"cell_type":{"0050d370":"code","b2e61552":"code","ec9ecc8a":"code","a90e0cf0":"code","c63e5f66":"code","5fd53e94":"code","ebc7f2ad":"code","ab69ae56":"code","07001ce3":"code","7d4d940f":"code","45a07d59":"code","9ec3ceb5":"code","8ed4fd34":"code","1a61fcb1":"code","ecd9742b":"code","b18acd76":"code","d0993daf":"code","12371164":"code","42bf613c":"code","117ba6d6":"code","28157740":"code","fb4a2a82":"code","81d02e7d":"code","a2eafa84":"code","8f914090":"markdown","34618cba":"markdown","9c88d8bd":"markdown","9c6a7eaf":"markdown","77cacc4b":"markdown"},"source":{"0050d370":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2e61552":"df5 = pd.read_csv(\"\/kaggle\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/nonbreaking_prefixes\/nonbreaking_prefix.pt\", low_memory=False)\nprint(df5.shape)\ndf5.head().style.set_properties(**{'background-color':'darksalmon',\n                                     'color': 'purple'})","ec9ecc8a":"df1= pd.read_csv('..\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/perluniprops\/Hiragana.txt', sep='\\t', error_bad_lines=False)\ndf1.head()","a90e0cf0":"df2= pd.read_csv('..\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/perluniprops\/Katakana.txt', sep='\\t', error_bad_lines=False)\ndf2.head()","c63e5f66":"df3= pd.read_csv('..\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/perluniprops\/Hangul_Syllables.txt', sep='\\t', error_bad_lines=False)\ndf3.head()","5fd53e94":"df4= pd.read_csv('..\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/perluniprops\/IsAlpha-unichars-au.txt', sep='\\t', error_bad_lines=False)\ndf4.head()","ebc7f2ad":"df = pd.read_csv(\"\/kaggle\/input\/sacremoses\/sacremoses-master\/sacremoses\/data\/nonbreaking_prefixes\/nonbreaking_prefix.de\", low_memory=False)\nprint(df.shape)\ndf.head().style.set_properties(**{'background-color':'darksalmon',\n                                     'color': 'purple'})","ab69ae56":"df.isnull().sum()","07001ce3":"df[\"#Anything in this file\"].value_counts()","7d4d940f":"#It has space before followed\n\ndf[\" followed by a period (and an upper-case word)\"].value_counts()","45a07d59":"df[\" followed by a period (and an upper-case word)\"].value_counts().plot.bar(color=['blue', 'red'], title='Followed by Period & Upper Case Word',);","9ec3ceb5":"df[\"#Anything in this file\"].value_counts()[:10].plot.barh(color='blue', title='Anything in this file',);","8ed4fd34":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.RdBu(np.linspace(0,1,20))\ndf[\"#Anything in this file\"].value_counts().sort_values(ascending=False).head(10).plot.pie(y=\" followed by a period (and an upper-case word)\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"Anything in this file\")\nplt.axis(\"off\")\nplt.show()","1a61fcb1":"!pip install -U nltk","ecd9742b":"!pip install mosestokenizer","b18acd76":"import nltk\nnltk.download('perluniprops')\n\nfrom mosestokenizer import MosesTokenizer, MosesDetokenizer","d0993daf":"# here we will call .close() explicitly at the end:\ntokenize = MosesTokenizer('en')\ntokenize('no german words end in single lower-case letters')\n['no', 'german', 'words', 'end', 'in', 'single', 'lower', '-', 'case', 'letters']\ntokenize.close()","12371164":"#MosesTokenizer callable objects take a string and return a list of tokens (strings).\n\n# here we take advantage of the context manager interface:\nwith MosesTokenizer('en') as tokenize:\n     tokenize('no german words end in single lower-case letters')\n\n['no', 'german', 'words', 'end', 'in', 'single', 'lower', '-', 'case', 'letters']","42bf613c":"#MosesDetokenizer takes a list of tokens and returns a string:\n\nwith MosesDetokenizer('en') as detokenize:\n     detokenize(['no', 'german', 'words', 'end', 'in', 'single', 'lower', '-', 'case', 'letters'])\n\n'no german words end in single lower-case letters'","117ba6d6":" from mosestokenizer import MosesSentenceSplitter","28157740":"with MosesSentenceSplitter('en') as splitsents:\n     splitsents([\n         'Has any german word, ended in single lower-case letters?',\n         'so we throw those in too.'\n     ])\n\n['Has any german word', 'ended in single lower-case letters? so we throw those in too.']","fb4a2a82":"from mosestokenizer import MosesPunctuationNormalizer","81d02e7d":"with MosesPunctuationNormalizer('en') as normalize:\n     normalize('\u00abno german words end in single lower-case letters\u00bb \u2014 so we throw those in too.')\n\n'\"no german words end in single lower-case letters\" - so we throw those in too.'","a2eafa84":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata @mpwolke was Here.' )","8f914090":"#Mosestokenizer by Luis MS Gomes\n\n#https:\/\/pypi.org\/project\/mosestokenizer\/","34618cba":"![](https:\/\/opengraph.githubassets.com\/89a5d407361233a6f4d9792067391bd51919fcc97acc71a64b2aca0de76aaacc\/alvations\/sacremoses)github.com","9c88d8bd":"![](https:\/\/opengraph.githubassets.com\/cbffb3b0e40aa6da8a8219d3bec2b92ae406d958ef34be2e39206156b87648b3\/bkj\/mosestokenizer)github.com","9c6a7eaf":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSckHo6MixNJMyHW2sCteldK8X4jiukGPU8HUQZzZJuXWhnnDtRXWKwmxcvh8upWeJ5Zw&usqp=CAU)programmersought.com","77cacc4b":"#MosesDetokenizer takes a list of tokens and returns a string:"}}