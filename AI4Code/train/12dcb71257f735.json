{"cell_type":{"c9e02269":"code","265e2f96":"code","8b31c4f2":"code","eeeaa0a9":"code","079ce271":"code","061a37ce":"code","13c38ceb":"code","81fb56f1":"code","bbe4e0bf":"code","faaac215":"code","d2a44dff":"code","94ee8fd2":"code","8384b6dc":"code","457db890":"code","728c7459":"code","b9800869":"code","cf2d43da":"code","c4b9902a":"code","8b0422c2":"code","6d429763":"code","be2b21de":"code","82c7f4fd":"code","2efc5bb5":"code","959e6fb3":"code","2cab252c":"code","919eef28":"markdown"},"source":{"c9e02269":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Dense\nimport tensorflow_addons as tfa\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss","265e2f96":"np.random.seed(666)","8b31c4f2":"train_features = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntrain_targets = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntest_features = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')","eeeaa0a9":"def preprocess(df):\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n    del df['sig_id']\n    return df","079ce271":"train = preprocess(train_features)\ntest = preprocess(test_features)","061a37ce":"del train_targets['sig_id']","13c38ceb":"train_targets['cp_type'] = train['cp_type']","81fb56f1":"train = train[train['cp_type'] != 'ctl_vehicle']\ntrain_targets = train_targets[train_targets['cp_type'] != 'ctl_vehicle']\n\ntrain = train.drop(['cp_type'], axis=1)\ntrain_targets = train_targets.drop(['cp_type'], axis=1)","bbe4e0bf":"train = train.reset_index().drop(['index'], axis=1)\ntrain_targets = train_targets.reset_index().drop(['index'], axis=1)","faaac215":"train_categories = train[['cp_dose', 'cp_time']]\ntest_categories = test[['cp_dose', 'cp_time']]","d2a44dff":"test_cp_type = test['cp_type']\ntest = test.drop(['cp_type'], axis=1)","94ee8fd2":"train","8384b6dc":"def create_autoencoder():\n    input_vector = Input(shape=(874,))\n    encoded = Dense(2000, activation='elu')(input_vector)\n    encoded = Dense(1000, activation='elu')(encoded)\n    decoded = Dense(2000, activation='elu')(encoded)\n    decoded = Dense(874, activation='elu')(decoded)\n    \n    autoencoder = tf.keras.Model(\n        input_vector, \n        decoded\n    )\n    \n    autoencoder.compile(\n        optimizer='adadelta', \n        loss='mse'\n    )\n    \n    return autoencoder","457db890":"autoencoder = create_autoencoder()","728c7459":"autoencoder.summary()","b9800869":"mu, sigma = 0, 0.05\n\nnoise = np.random.normal(\n    mu, \n    sigma, \n    [21948, 874]\n) \nnoised_train = train + noise","cf2d43da":"autoencoder.fit(\n    noised_train, \n    train, \n    epochs=1000,\n    batch_size=128,\n    shuffle=True,\n    validation_split=0.2\n)","c4b9902a":"encoder = tf.keras.Model(\n    autoencoder.input, \n    autoencoder.layers[2].output\n)","8b0422c2":"train_features = pd.DataFrame(encoder.predict(train))\ntest_features = pd.DataFrame(encoder.predict(test))","6d429763":"train_features","be2b21de":"def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(1000),\n        tf.keras.layers.BatchNormalization(),\n\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(350)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(\n            tf.keras.layers.Dense(\n                206, \n                activation=\"sigmoid\"\n            )\n        )\n    ])\n    model.compile(\n        optimizer=tfa.optimizers.AdamW(\n            lr=1e-3, \n            weight_decay=1e-5, \n            clipvalue=700\n        ), \n        loss='binary_crossentropy'\n    )\n    return model","82c7f4fd":"submission.loc[:, train_targets.columns] = 0\nres = train_targets.copy()\nfor n, (tr, te) in enumerate(KFold(n_splits=7, random_state=666, shuffle=True).split(train_targets)):\n    print(f'Fold {n}')\n    \n    model = create_model()\n    \n    model.fit(\n        train_features.values[tr],\n        train_targets.values[tr],\n        epochs=50, \n        batch_size=128\n    )\n    \n    submission.loc[:, train_targets.columns] += model.predict(test_features)\n    res.loc[te, train_targets.columns] = model.predict(train_features.values[te])\n    \nsubmission.loc[:, train_targets.columns] \/= (n+1)\n\nmetrics = []\nfor _target in train_targets.columns:\n    metrics.append(log_loss(train_targets.loc[:, _target], res.loc[:, _target]))","2efc5bb5":"print(f'OOF Metric: {np.mean(metrics)}')","959e6fb3":"submission['cp_type'] = test_cp_type\nfor col in submission.columns:\n    if col in ['sig_id', 'cp_type', 'cp_dose', 'cp_time']:\n        continue\n    submission.loc[submission['cp_type'] == 'ctl_vehicle', col] = 0\n\nsubmission = submission.drop(['cp_type'], axis=1)","2cab252c":"submission.to_csv('submission.csv', index=False)","919eef28":"## Current best version - 29."}}