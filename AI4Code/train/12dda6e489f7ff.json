{"cell_type":{"ec78f0f3":"code","c3f44e3f":"code","9a7ed0dc":"code","e12eea1b":"code","593869c6":"code","a549dd2d":"code","fa3a49da":"code","8ce7c69b":"code","0d8e1aac":"code","e2c8e698":"code","ef89acc8":"code","9538655a":"code","bf8784ef":"code","fc5b6212":"code","cc661b52":"code","abb61fc3":"code","b9de5509":"code","ede48b67":"code","e248d743":"code","02e07a33":"code","e41c6c7e":"code","efa710c0":"markdown","f9cfae0d":"markdown","2ba6c34c":"markdown","654ae7e1":"markdown","73bab4eb":"markdown","613d008c":"markdown","e781c03d":"markdown","653d356e":"markdown","f49517e2":"markdown","e0946530":"markdown","4f698429":"markdown","90e38ec4":"markdown","ebc7a1a5":"markdown","77f217c0":"markdown","0c3b35db":"markdown","67bab139":"markdown","3e2b74f4":"markdown","c5accf70":"markdown","e67c34fd":"markdown"},"source":{"ec78f0f3":"import numpy as np, pandas as pd\nimport matplotlib.pyplot as plt, seaborn as sns\nsns.set()\n\nfrom sklearn.cluster import KMeans","c3f44e3f":"data = pd.read_csv(\"..\/input\/iris-data\/iris_dataset.csv\")\ndata.head()","9a7ed0dc":"data1 = data[[\"sepal_length\", \"sepal_width\"]]\nplt.scatter(data1[\"sepal_length\"], data1[\"sepal_width\"])\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","e12eea1b":"kmeans = KMeans(2)  # instantiating KMeans(<number of clusters we want>)\nkmeans.fit(data1)  # fitting our data on the model","593869c6":"data2 = data.copy()  # making a copy of original data for visualization ahead\ndata2['cluster_pred'] = kmeans.fit_predict(data1)  # adding a new column in data to contain each observation's \"cluster\" ","a549dd2d":"plt.scatter(data2['sepal_length'], data2['sepal_width'], c = data2['cluster_pred'], cmap = 'rainbow')\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","fa3a49da":"from sklearn import preprocessing","8ce7c69b":"data1_scaled = preprocessing.scale(data1)  # standardization\ndata1_scaled[:5]  # printing first five observations of scaled data","0d8e1aac":"kmeans_scaled = KMeans(2)\nkmeans.fit(data1_scaled)","e2c8e698":"data2['cluster_pred']=kmeans_scaled.fit_predict(data1_scaled)","ef89acc8":"plt.scatter(data2['sepal_length'], data2['sepal_width'], c= data2['cluster_pred'], cmap = 'rainbow')\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","9538655a":"kmeans_scaled = KMeans(3)\nkmeans.fit(data1_scaled)\n\ndata2['cluster_pred']=kmeans_scaled.fit_predict(data1_scaled)\n\nplt.scatter(data2['sepal_length'], data2['sepal_width'], c= data2['cluster_pred'], cmap = 'rainbow')\nplt.title(\"Clusters = 3\")\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","bf8784ef":"kmeans_scaled = KMeans(4)\nkmeans.fit(data1_scaled)\n\ndata2['cluster_pred']=kmeans_scaled.fit_predict(data1_scaled)\n\nplt.scatter(data2['sepal_length'], data2['sepal_width'], c= data2['cluster_pred'], cmap = 'rainbow')\nplt.title(\"Clusters = 4\")\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","fc5b6212":"wcss = []  # empty list to contain wcss value for number of clusters 1, 2, 3, ..., 9\ncl_number = 10\nfor i in range(1, cl_number):\n    kmeans = KMeans(i)\n    kmeans.fit(data1_scaled)\n    wcss_i = kmeans.inertia_\n    wcss.append(wcss_i)\nwcss","cc661b52":"plt.plot(range(1, 10), wcss)\nplt.title(\"The Elbow Method\")\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()","abb61fc3":"kmeans_scaled = KMeans(3)\nkmeans.fit(data1_scaled)\n\ndata2['cluster_pred']=kmeans_scaled.fit_predict(data1_scaled)\n\nplt.scatter(data2['sepal_length'], data2['sepal_width'], c= data2['cluster_pred'], cmap = 'rainbow')\nplt.title(\"Clusters = 3\")\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()","b9de5509":"plt.scatter(data[\"sepal_length\"], data[\"sepal_width\"])\nplt.title(\"Sepal Shape\")\nplt.xlabel(\"Sepal Length\")\nplt.ylabel(\"Sepal Width\")\n\nplt.show()\n\n\nplt.scatter(data[\"petal_length\"], data[\"petal_width\"])\nplt.title(\"Petal Shape\")\nplt.xlabel(\"Petal Length\")\nplt.ylabel(\"Petal Width\")\n\nplt.show()","ede48b67":"from sklearn import preprocessing\n\ndata_scaled = preprocessing.scale(data)\ndata_scaled[:5]","e248d743":"wcss = []  # empty list to contain wcss value for number of clusters 1, 2, 3, ..., 9\ncl_number = 10\nfor i in range(1, cl_number):\n    kmeans = KMeans(i)\n    kmeans.fit(data_scaled)\n    wcss_i = kmeans.inertia_\n    wcss.append(wcss_i)\nwcss","02e07a33":"plt.plot(range(1, 10), wcss)\nplt.title(\"The Elbow Method\")\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()","e41c6c7e":"kmeans_scaled = KMeans(3)\nkmeans.fit(data_scaled)\n\ndata['cluster_pred']=kmeans_scaled.fit_predict(data_scaled)\n\nplt.scatter(data['sepal_length'], data['sepal_width'], c= data['cluster_pred'], cmap = 'rainbow')\nplt.xlabel(\"Length of the Sepal\")\nplt.ylabel(\"Width of the Sepal\")\nplt.show()\n\nplt.scatter(data['petal_length'], data['petal_width'], c= data['cluster_pred'], cmap = 'rainbow')\nplt.xlabel(\"Length of the Petal\")\nplt.ylabel(\"Width of the Petal\")\nplt.show()","efa710c0":"## 5. Standardizing Data:\nFor standardizing, we will import 'preprocessing' method from sklearn.","f9cfae0d":"## 6. Clustering Scaled Data","2ba6c34c":"Our data consists of flowers' shape parameters. We are going to group flowers on the basis of their shape features. Sepals and petals define the shape of the flower, so we have lengths and widths of both, sepals and petals.","654ae7e1":"We can cluster observations in any number of groups we want. But, what is the optimal number of clusters. We take advantage of The Elbow Method for this purpose.","73bab4eb":"**Choosing Number of Clusters**","613d008c":"Here, we can see that 3 or 4 are the best solutions we have for the number of clusters, as wcss is not decreasing so much after them. I will choose 3 for now. But, choosing 4 is also reasonable depending upon the problem we have in hand.\n\n**Clustering into Three**","e781c03d":"## 3. Plotting Data\nSince 2D scatterplot can only work for two features, we will choose sepal length and width as those two features and for now be grouping our data on those two features as well.","653d356e":"By looking at this grouped scatter plot, we can see that the observations are mainly grouped on the basis of their sepal length and not on width. This is becaues length of the sepal has a higher range than that of the sepal width and therefore length carries more wieght than width. To overcome this, we must standardize our features.","f49517e2":"**Standardizing Data**","e0946530":"Above clustering is produced on the basis of all features including petal and sepal shape features.","4f698429":"## 2. Loading Data","90e38ec4":"The above grouping weighs both of the features (i.e. length and width of the sepals) equally. We can define weight of a feature by altering its range.\n\nLet's repeat the process for 3 and 4 clusters.","ebc7a1a5":"From above graph, we can interpret that the lengths of sepals are in range of 4.0 to 8.0 and widths are in range(2.0 to 4.5).","77f217c0":"Number of clusters = 2 to 3 seem fine for this problem. We will be choosing k=3.\n\n'k' represents number of clusters here. This method of clustering analysis is known as **KMeans Clustering**.\n\n**Clustering Data**","0c3b35db":"## 8. Considering All of the Features in Clustering\n\nWe have clustered our observations on the basis of sepal shape only. We can choose how many and which features we want to consider for clustering. Let's take petal shape under consideration too and repeat the process of clustering and see how the clusters are different from the ones we got considering sepal shape only.\n\nWe can not show all of the features in same 2D scatter plot as it can only show two variables. Let's plot for the features of sepals and petals seperately.","67bab139":"## 1. Importing Libraries:","3e2b74f4":"## 4. Clustering Data:\nWe will now be grouping all given flowers(observations) on the basis of these two features (i.e. sepal length and sepal width).\n\nInitially, we will be grouping observations in two clusters.","c5accf70":"## 7. Choosing the Number of Clusters\n\nHow many clusters are enough to represent all the observations of the data set in a way that each cluster is significantly different from others without the number of clusters getting too many.\n\nA quick solution to the problem is the elbow method. It consists of a line graph with number of clusters on the x-axis and sum of squared distance of each point with the centroid (a.k.a. wcss) on the y-axis. The line forms a sort of elbow at some number of clusters after which there is no significant decrease in wcss with the increase in number of clusters.\n\n- wcss = 0 - when each observation is a seperate cluster (meaning: no. of clusters = no. of observations)\n- wcss = 1 - when every observation is in same cluster (meaning: no. of clusters = 0)\n\nWe want our wcss as close to 0 as possible, but at the same time we don't want too many clusters. Elbow is the point to stop.\n\nLet's find the value of wcss for numbers of clusters 1 through 9.","e67c34fd":"## Cluster Analysis\nCluster analysis is a statistical method for processing data. It works by organizing items(observations) into groups, or clusters, on the basis of how closely associated they are.\n\nThe goal is to maximize similarities between observations within a cluster and maximize dissimilarities between clusters.\n\nWe can grouping the observations differently by selecting different features on whose basis we are clustering."}}