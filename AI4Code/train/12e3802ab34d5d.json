{"cell_type":{"c6e72cf8":"code","7fcbef20":"code","4e618cc4":"code","6485e8f0":"code","8c579437":"code","d9336172":"code","9b49e7c5":"code","37698f98":"code","ccbf66df":"code","4e637de0":"code","173cda4f":"code","e9238d36":"code","94635250":"code","d7eaf66c":"code","f23a81e4":"code","ee0c69f8":"code","0bc9d5b6":"code","e76aeb60":"code","4473c4d0":"code","3c41c9d7":"code","0394a768":"code","4ea9e5af":"code","b87db272":"code","2270606c":"code","77a45c79":"code","254f2565":"markdown","f85d1262":"markdown","90f52d9d":"markdown","e7ca9cb0":"markdown","5c01a81d":"markdown","1e252b89":"markdown","868a5277":"markdown"},"source":{"c6e72cf8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fcbef20":"train_df = pd.read_csv(\"\/kaggle\/input\/feedback-prize-2021\/train.csv\")","4e618cc4":"train_df.head()","6485e8f0":"# Load the text files with corresponding ids\n\ntest_names, train_texts = [], []\nfor f in tqdm(list(os.listdir('..\/input\/feedback-prize-2021\/train'))[:]):\n    test_names.append(f.replace('.txt', ''))\n    train_texts.append(open('..\/input\/feedback-prize-2021\/train\/' + f, 'r').read())\ntrain_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n# train_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntrain_text_df.head()","8c579437":"for i in train_df.iterrows():\n    temp_text = i[1]['discourse_text'].split()\n    temp_pred = i[1]['predictionstring'].split()\n    if len(temp_text) != len(temp_pred):\n        print(f\"\"\"len of discourse text : {len(temp_text)}, not macthing with len of prediction string: {len(temp_pred)}\n              \"\"\")\n        print(f\"discourse text: {temp_text}, prediction strin: {temp_pred}\")\n        break","d9336172":"### This is due to not splitting the text properly\nprint(train_text_df[train_text_df['id'] == \"C3811E7F1750\"].values[0][1].split()[302:])","9b49e7c5":"train_df.columns","37698f98":"group_df = train_df.groupby('id')['predictionstring', \"discourse_text\"].agg({\"predictionstring\":' '.join,\n                                                                       \"discourse_text\": \" \".join}).reset_index()","ccbf66df":"group_df.columns","4e637de0":"# Get length of predictions string, discourse len, pred last values based on grouped data\n\ngroup_df['pred_len'] = group_df['predictionstring'].apply(lambda x:len(x.split()))\ngroup_df['discourse_len'] = group_df['discourse_text'].apply(lambda x:len(x.split()))\ngroup_df['pred_last'] = group_df['predictionstring'].apply(lambda x: int(x.split()[-1])+1)","173cda4f":"group_df[group_df['pred_len'] != group_df['discourse_len']].shape[0]\/train_text_df.shape[0]","e9238d36":"# group_df.sort_values('id', inplace=True)\ntrain_text_df = train_text_df.sort_values('id').reset_index(drop=True)","94635250":"train_text_df.tail(10)","d7eaf66c":"group_df.tail(10)","f23a81e4":"id_train = train_text_df['id'].values\ngroup_df['id_train'] = id_train","ee0c69f8":"group_df['text_len'] = train_text_df['text'].apply(lambda x:len(x.split()))","0bc9d5b6":"## We see text length will never match with prediction string length as some words have not annotated: compition guidelines already mentioned this\n\ngroup_df[group_df['text_len'] != group_df['predictionstring']].shape[0]\/train_text_df.shape[0]","e76aeb60":"group_df[group_df['text_len'] < group_df['pred_last']].shape[0]\/train_text_df.shape[0]","4473c4d0":"(group_df['id_train'] == group_df['id']).sum()\/train_text_df.shape[0]","3c41c9d7":"all_entities = []\nfor i in tqdm(train_text_df.iterrows()):\n    total = i[1]['text'].split().__len__()\n#     entities = []\n    entities = [\"O\" for i in range(total)]\n    for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n        discourse = j[1]['discourse_type']\n        list_ix = j[1]['predictionstring'].split()\n        for li in list_ix[1:]:\n#             print(li, entities)\n            entities[int(li)] = f\"I-{discourse}\"\n        entities[int(list_ix[0])] = f\"B-{discourse}\"\n    all_entities.append(entities)","0394a768":"final_df = pd.DataFrame.from_records(all_entities)","4ea9e5af":"final_df['id'] = train_text_df['id']","b87db272":"train_text_df['entities'] = all_entities","2270606c":"train_text_df.head()","77a45c79":"train_text_df.to_csv(\"feedback_prize_ner_tagged_data.csv\", index=False)","254f2565":"### We will group by based on id and do some sanity checks of train.csv file with loaded text files","f85d1262":"## Descripencies in train data","90f52d9d":"### Case1: There are minor cases where len of prediction labels does not match with discourse len, so we have to add extra 'O' tags at the end.","e7ca9cb0":"### Notebook explaining the approach of how to tag NER labels to text data by mapping text files with train.csv\n\nTo see how to model this refer to my other modelling notebook: \n\nhttps:\/\/www.kaggle.com\/raghavendrakotala\/fine-tunned-on-roberta-base-as-ner-problem-0-533","5c01a81d":"## Load the data","1e252b89":"### Case2: Strangely we see prediction string last index greater than text length iteself, this is due to presence of overlapping labels so we will just ignore the duplicates \n","868a5277":"### as we see below length of discourse text not macthching with len of predictionstring. Further more we observe this due to "}}