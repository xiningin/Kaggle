{"cell_type":{"c0e57428":"code","81e3108e":"code","36097693":"code","c88685fc":"code","ec387992":"code","bf94b294":"code","c6e0a636":"code","a76334ce":"code","4c262346":"code","5c354c95":"code","5c952c99":"code","a261ee5e":"code","70dd3dc2":"code","d68801ca":"code","20428267":"code","8bac3b50":"code","d3deb0e5":"code","7e3d8a24":"code","d25ac010":"code","4bf6da16":"code","7ae09180":"code","1d62b553":"code","6923562d":"code","9375a3f9":"code","9031645e":"code","910cbfb8":"code","2fbf60c8":"code","053305aa":"code","8a96e367":"code","6d911615":"code","d34bcaf3":"code","a6e3902d":"code","e0b54e71":"code","6b1df39a":"code","7d015b62":"code","379074b4":"code","b2321284":"code","10ce2b4f":"code","9a26604e":"code","1ff22d7d":"code","28e0e940":"code","14c449bc":"code","92e82178":"code","4c08047b":"code","d139c3f2":"markdown","a35300e9":"markdown","ae1b6504":"markdown","25ad20d9":"markdown"},"source":{"c0e57428":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","81e3108e":"df = pd.read_csv(\"..\/input\/heart.csv\")\ndf.head()","36097693":"df.info()","c88685fc":"df.isnull().sum()","ec387992":"df.describe()","bf94b294":"import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","c6e0a636":"plt.figure(figsize=(18,10))\nsns.heatmap(df.corr(), annot=True, cmap='cool')\nplt.show()","a76334ce":"sns.countplot(df.target, palette=['green', 'red'])\nplt.title(\"[0] == Not Disease, [1] == Disease\");","4c262346":"plt.figure(figsize=(18, 10))\nsns.countplot(x='age', hue='target', data=df, palette=['#1CA53B', 'red'])\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","5c354c95":"fig, axes = plt.subplots(3, 2, figsize=(12,12))\nfs = ['cp', 'fbs', 'restecg','exang', 'slope', 'ca']\nfor i, axi in enumerate(axes.flat):\n    sns.countplot(x=fs[i], hue='target', data=df, palette='bwr', ax=axi) \n    axi.set(ylabel='Frequency')\n    axi.legend([\"Haven't Disease\", \"Have Disease\"])","5c952c99":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='trestbps',y='thalach',data=df,hue='target')\nplt.show()","a261ee5e":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='chol',y='thalach',data=df,hue='target')\nplt.show()","70dd3dc2":"plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","d68801ca":"from sklearn.preprocessing import StandardScaler\n\n# Import tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc","20428267":"# Define our feature and labels\nX = df.drop(['target'], axis=1).values\ny = df['target'].values","8bac3b50":"scale = StandardScaler()\nX = scale.fit_transform(X)","d3deb0e5":"class Model:\n    def __init__(self, model, X, y):\n        self.model = model\n        self.X = X\n        self.y = y\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.5, random_state=42)\n        \n        self.model.fit(self.X_train, self.y_train)\n        self.y_pred = self.model.predict(self.X_test)\n        \n    def model_str(self):\n        return str(self.model.__class__.__name__)\n    \n    def crossValScore(self, cv=5):\n        print(self.model_str() + \"\\n\" + \"=\"*60)\n        scores = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n        for score in scores:  \n            cv_acc = cross_val_score(self.model, \n                                     self.X_train, \n                                     self.y_train, \n                                     cv=cv, \n                                     scoring=score).mean()\n            \n            print(\"Model \" + score + \" : \" + \"%.3f\" % cv_acc)\n        \n    def accuracy(self):\n        accuarcy = accuracy_score(self.y_test, self.y_pred)\n        print(self.model_str() + \" Model \" + \"Accuracy is: \")\n        return accuarcy\n        \n    def confusionMatrix(self):        \n        plt.figure(figsize=(6, 6))\n        mat = confusion_matrix(self.y_test, self.y_pred)\n        sns.heatmap(mat.T, square=True, \n                    annot=True, \n                    cbar=False, \n                    xticklabels=[\"Haven't Disease\", \"Have Disease\"], \n                    yticklabels=[\"Haven't Disease\", \"Have Disease\"])\n        \n        plt.title(self.model_str() + \" Confusion Matrix\")\n        plt.xlabel('Predicted Values')\n        plt.ylabel('True Values');\n        plt.show();\n        \n    def classificationReport(self):\n        print(self.model_str() + \" Classification Report\" + \"\\n\" + \"=\"*60)\n        print(classification_report(self.y_test, \n                                    self.y_pred, \n                                    target_names=['Non Disease', 'Disease']))\n    \n    def rocCurve(self):\n        y_prob = self.model.predict_proba(self.X_test)[:,1]\n        fpr, tpr, thr = roc_curve(self.y_test, y_prob)\n        lw = 2\n        plt.figure(figsize=(10, 8))\n        plt.plot(fpr, tpr, \n                 color='darkorange', \n                 lw=lw, \n                 label=\"Curve Area = %0.3f\" % auc(fpr, tpr))\n        plt.plot([0, 1], [0, 1], color='green', \n                 lw=lw, linestyle='--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(self.model_str() + ' Receiver Operating Characteristic Plot')\n        plt.legend(loc=\"lower right\")\n        plt.show()","7e3d8a24":"from sklearn.ensemble import RandomForestClassifier\n\nclf1 = Model(model=RandomForestClassifier(n_estimators=1000), X=X, y=y)","d25ac010":"clf1.crossValScore(cv=10)","4bf6da16":"clf1.accuracy()","7ae09180":"clf1.confusionMatrix()","1d62b553":"import xgboost as xgb\nclf2 = Model(model=xgb.XGBClassifier(), X=X, y=y)\n","6923562d":"clf2.crossValScore(cv=10)","9375a3f9":"clf2.accuracy()","9031645e":"clf2.confusionMatrix()","910cbfb8":"clf1.classificationReport()","2fbf60c8":"clf2.classificationReport()","053305aa":"clf1.rocCurve()","8a96e367":"clf2.rocCurve()","6d911615":"import warnings\nwarnings.simplefilter(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import QuantileTransformer\n\nlr = LogisticRegression(C=10, n_jobs=-1)\npipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), lr)\n\npip = Model(model=pipeline, X=X, y=y)","d34bcaf3":"pip.crossValScore()","a6e3902d":"pip.accuracy()","e0b54e71":"pip.confusionMatrix()","6b1df39a":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = Model(model=KNeighborsClassifier(n_neighbors=100), X=X, y=y)","7d015b62":"knn.crossValScore()","379074b4":"knn.accuracy()","b2321284":"knn.confusionMatrix()","10ce2b4f":"models = [clf1, clf2,Ann,pip, knn]\nnames = []\naccs = []\nfor model in models:\n    accs.append(model.accuracy())\n    names.append(model.model_str())","9a26604e":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,1.2,0.1))\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=names, y=accs)\nplt.savefig('models_accuracy.png')\nplt.show()","1ff22d7d":"from sklearn.neural_network import MLPClassifier\nAnn = Model(model=MLPClassifier(hidden_layer_sizes=(300,150)), X=X, y=y)\n","28e0e940":"Ann.crossValScore()","14c449bc":"Ann.accuracy()","92e82178":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\npl_mlp=Pipeline(steps=[('scaler',StandardScaler()),('mil_ann',MLPClassifier(hidden_layer_sizes=(1275,637)))])\nscores=cross_val_score(pl_mlp,X_train,y_train,cv=10,scoring='accuracy')\nprint('ANN:',scores.mean())","4c08047b":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score,train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\npl_xgb=Pipeline(steps=[('svm',xgb.XGBClassifier(objective='multi:softmax',num_class=2))])\nscores=cross_val_score(pl_xgb,X_train,y_train,cv=10,scoring='accuracy')\nprint('xgb:',scores.mean())","d139c3f2":"Firstly we have to check the shape of the data**** then have to check is there any null values in the dataset","a35300e9":">*if you want more stats about the data issue the below ","ae1b6504":"by issueing below function we check the correlation of the data points","25ad20d9":" we checked there is no null values in the dataset********"}}