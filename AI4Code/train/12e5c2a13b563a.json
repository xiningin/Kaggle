{"cell_type":{"73965182":"code","1bbc64d9":"code","8848e403":"code","f44d1e0d":"code","ebb6f608":"code","63d3dacd":"code","a1581323":"code","5a10a1d9":"code","619270a7":"code","6e117147":"code","9bc0abf8":"code","e8ce9852":"code","8f56aa97":"code","9f22a9ca":"code","04e46467":"code","05130f8d":"code","9a372d50":"code","cf11deb2":"code","e418d462":"code","ef4b525d":"code","f8653fd2":"code","52424c05":"code","925e48ff":"code","cf460f6b":"code","e4aa9b47":"code","96771198":"code","ff0716b0":"code","08675390":"markdown","8a4ef6dc":"markdown","57d5589b":"markdown","f59b4220":"markdown","0a40c757":"markdown","e58a0c49":"markdown","7b32320b":"markdown","2dbdae33":"markdown","a37833f4":"markdown","d0e2f9da":"markdown","b6471579":"markdown","36fc5673":"markdown","640f58ee":"markdown","316fd3c8":"markdown","29e03b81":"markdown","6ad6d5b1":"markdown","ea7908ac":"markdown","76ab7895":"markdown","5a428847":"markdown","9b873fbb":"markdown"},"source":{"73965182":"%matplotlib inline\nimport numpy as np \nimport time\nimport pandas as pd \nimport torch\nimport torchvision\nfrom torchvision.transforms import ToTensor,Normalize,Compose\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","1bbc64d9":"transform =Compose([ToTensor(),Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrainset=torchvision.datasets.CIFAR10(root='.\/data',train=True,download=True,\n                                      transform=transform)\n\ntestset=torchvision.datasets.CIFAR10(root='.\/data',train=False, download=True,\n                                     transform=transform)","8848e403":"trainset","f44d1e0d":"testset","ebb6f608":"classes=trainset.classes\nclasses","63d3dacd":"torch.manual_seed(42)\nval_size=5000 #10% of training data\ntrain_size=len(trainset)-val_size\ntrainset,valset=torch.utils.data.random_split(trainset,[train_size,val_size])\nprint(len(trainset), len(valset))","a1581323":"batch_size=128\ntrain_data=torch.utils.data.DataLoader(trainset,batch_size,shuffle=True,pin_memory=True)\nval_data=torch.utils.data.DataLoader(valset,batch_size,shuffle=False,pin_memory=True)\ntest_data=torch.utils.data.DataLoader(testset,batch_size,shuffle=False,pin_memory=True)","5a10a1d9":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","619270a7":"sample=iter(train_data)\nimages,labels=sample.next()\nprint('images.shape:', images.shape)\n\nplt.figure(figsize=(20,24))\nplt.axis('off')\nimshow(torchvision.utils.make_grid(images,nrow=16))","6e117147":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def test_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'test_loss': loss.detach(), 'test_acc': acc}\n        \n    def test_epoch_end(self, outputs):\n        batch_losses = [x['test_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['test_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","9bc0abf8":"def evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef test(model, test_loader):\n    model.eval()\n    outputs = [model.test_step(batch) for batch in test_loader]\n    return model.test_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func):\n    history = [] #store model accuracy and loss for each epoch\n    training_start_time=time.time()\n    optimizer = opt_func\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n    return history","e8ce9852":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndevice = get_default_device()\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","8f56aa97":"train_data = DeviceDataLoader(train_data, device)\nval_data = DeviceDataLoader(val_data, device)\ntest_data = DeviceDataLoader(test_data, device)","9f22a9ca":"class BaseCNNModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network=nn.Sequential(\n            nn.Conv2d(3,32,3,padding=1),\n            nn.ReLU(), \n            nn.Conv2d(32,64,3,padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Conv2d(64,128,3,padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Flatten(),\n            nn.Linear(128*8*8,256),\n            nn.ReLU(),\n            nn.Linear(256,84),\n            nn.ReLU(),\n            nn.Linear(84,10))\n    def forward(self,x):\n        return self.network(x)","04e46467":"#moving model to GPU\nmodel_BCM= to_device(BaseCNNModel(),device)\nmodel_BCM","05130f8d":"evaluate(model_BCM,val_data)","9a372d50":"num_epochs=10\nlr=0.001\nmomentum=0.9\nopt_func=torch.optim.SGD(model_BCM.parameters(),lr,momentum)","cf11deb2":"history_BCM=fit(num_epochs,lr,model_BCM,train_data,val_data,opt_func)","e418d462":"def plot_loss_accuracy(history):\n    losses = [x['val_loss'] for x in history]\n    accuracies = [x['val_acc'] for x in history]\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n    axes[0].plot(losses,'-x')\n    axes[0].set_xlabel('epoch')\n    axes[0].set_ylabel('loss')\n    axes[0].set_title('Loss vs. No. of epochs')\n\n    axes[1].plot(accuracies,'-x')\n    axes[1].set_xlabel('epoch')\n    axes[1].set_ylabel('accuracy')\n    axes[1].set_title('Accuracy vs. No. of epochs')\n    plt.show()\n","ef4b525d":"plot_loss_accuracy(history_BCM)","f8653fd2":"class CNNModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network=nn.Sequential(\n            nn.Conv2d(3,32,3,padding=1),\n            nn.BatchNorm2d(32),#2D Batch Normalization since our inputs are 4D.\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.25),\n            \n            nn.Conv2d(32,64,3,padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            \n            nn.Conv2d(64,128,3,padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.25),\n            \n            nn.Conv2d(128,128,3,padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            \n            nn.Conv2d(128,128,3,padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.25),\n            \n            nn.Flatten(),\n            nn.Linear(128*4*4,512),\n            nn.ReLU(),\n            nn.Linear(512,256),\n            nn.ReLU(),\n            nn.Linear(256,10))\n    def forward(self,x):\n        return self.network(x)","52424c05":"model_CNN=to_device(CNNModel(),device)\nmodel_CNN","925e48ff":"num_epochs=50\nlr=0.0001\nopt_func=torch.optim.Adam(model_CNN.parameters(),lr)","cf460f6b":"history_CNN=fit(num_epochs,lr,model_CNN,train_data,val_data,opt_func)","e4aa9b47":"plot_loss_accuracy(history_CNN)","96771198":"test(model_CNN,test_data)","ff0716b0":"PATH = '.\/cifar_CNN.pth'\ntorch.save(model_CNN.state_dict(), PATH)","08675390":"## **Let's save this model**","8a4ef6dc":"#### The CIFAR-10 dataset is provided by Pytorch in it's `torchvision` module,we apply normalization and convert images to tensors while loading.","57d5589b":"#### Before training let's just evaluate this model and see how it performs.","f59b4220":"# **References**\n####   The helper functions for Base class,training and handling for GPU were borrowed from Shadab Hussain's [post](https:\/\/www.kaggle.com\/shadabhussain\/cifar-10-cnn-using-pytorch)","0a40c757":"#### Our base model took 101.79 seconds (almost 2 minutes) to train and achieved a validation score of 51%, let's plot how the loss and accuracy changes with each epoch.","e58a0c49":"# **Loading and Visualizing Data**\n#### Let's begin by importing some Pytorch functionalities to load and look at our data.","7b32320b":"#### Next we write our training loop and some evaluators to validate and test our models. We also need to store losses and accuracies of each epoch and return it after our training.","2dbdae33":"#### The CIFAR10 dataset is divided into 50,000 training samples and 10,000 test samples,to get better model evaluations and training let's divide the training data to get a validation data which we will work on , while the test data remains unseen to us and the model. Since we want as much training samples as we can lets take 90% of training data and remaining 10% as validation data,using `random split` in Pytorch , we set seed because we want the randomness to be reproducible.","a37833f4":"#### As expected it's accuracy is 10% which is equal to the proabability of randomly selecting a class. Now let's go ahead and initialize our model parameters and an optimizer so we can begin training.","d0e2f9da":"# **Building the CNN** (Contribution)\n#### Now that we have our helper functions let's now build a basic CNN model and see how it performs.Even though it's a basic model we will implement  max pooling.\n### **Max Pooling layer** : \n#### It's goal is to shrink the input image so that we can reduce the computational load and parameters thus reducing the chance of overfitting, it works similar to convolution layer with strides ,filter and padding but instead of having weights it just aggregates the inputs using a max function (the reason it's called *max* pooling layer, there is also a mean pooling layer).\n#### We will use a `Sequential` container because it's easy to write and chaining makes writing the forward function simple.","b6471579":"#### To make use of GPU (if available) we use some helper functions to move our model and data batches from CPU to GPU.","36fc5673":"#### Our new model has a much better performance ~ 82% and took just 10 mins to train,proving that `Batch Normalization` and `Dropout` has had a significant impact.\n#### Let's see how loss and accuracy change with epochs","640f58ee":"#### Now let's try to increase the performance by changing the model architecture,let's add some layers and use `Batch Normalization` and `Dropout` layers. \n### **Batch Normalization**:\n#### During training there is a chance that we run into vanishing\/exploding gradients,batch normalization helps to avoid this , the operation can be done before or after the activation function of each hidden layer. This operation involves  zero centering and normalizing the input of each layer which means it let's the model learn the optimal scale and mean of each input.This leads us to faster convergence even though time taken for each epoch is increased, however you would require less training steps and a better result.\n### **Dropout**:\n#### Dropout is a fairly simple but powerful method to increase model performance,at every training step every neuron has a probabilty of being *dropped out*, i.e disabled in this step completely, however it could be active during the next step, what this drop out does is it makes the model less sensitive leading to better generalization. But wait this is just like a regularizer!.Yes and since we are already implementing `Batch Normalization` ( which also behaves like a regularizer) lets set the dropout probability to some small value like 25%.\n\n#### Now let's start building our classifier!!!.","316fd3c8":"#### `momentum` is  a hyperparameter that controls momentum optimization i.e it makes the gradient care about past gradients and updates accordingly ,however to control overshooting we introduce a sor of friction to the descent which is our momentum.Momentum=0.9 works very well in practice so we set that value.","29e03b81":"#### There is also not that much of a drop in accuracy (~ 2%) when exposed to unseen test data,which means our model is quite generalized.","6ad6d5b1":"#### Now we shall use torch's `DataLoader` function to load batches of our data, we set `pin_memory=True` because it speeds up shifting data from CPU to GPU when we use GPU for training.","ea7908ac":"#### Now that we are done with  loading our data ,let's visualize a batch of images.","76ab7895":"#### Now let's warp our loaders so that we can shift data to GPU when available.","5a428847":"#### Now let's initalize our model parameters,epochs and optimizer to begin training. Here let's use the `Adam` optimizer instead of Gradient Descent.\n### **Adam optimizer**:\n#### Adam stands for *adaptive moment estimation* which combines the idea of momentum optimization and [`RMSprop`](https:\/\/towardsdatascience.com\/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a) which is another opitimizer,basically, it keeps track of exponentially decaying average of past gradients and exponentially decaying average of past squared gradients. This leads us to faster convergence to minima and since it's adaptive , we dont need to worry too much about learning rate hyperparameter.","9b873fbb":"## **Helper functions  for building and training**\n#### The following 3 cells have been borrowed from [here](https:\/\/www.kaggle.com\/shadabhussain\/cifar-10-cnn-using-pytorch). The Base class has some core functionalities for training that can be extended when implementing the neural network class as you will see soon.These functions are interoperable and can be used for any image classification task. We wont need to write training steps for every model that we build but simply just extend this class and functions for every model we build."}}