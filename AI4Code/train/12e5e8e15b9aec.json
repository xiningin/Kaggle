{"cell_type":{"ea90b01a":"code","e033f010":"code","fbb7463b":"code","e9f10b44":"code","259c50b1":"code","e8257771":"code","4d600c49":"code","980d6467":"code","846593cf":"code","e7c1ef7b":"code","a6bc5e01":"code","79e9a646":"code","8caac365":"code","ef6204fa":"code","456107b1":"code","c1293a27":"code","350299ec":"code","b59e63b1":"code","c98f378a":"markdown","6fc79f20":"markdown","412915f6":"markdown","9b6101a3":"markdown","f7c84155":"markdown"},"source":{"ea90b01a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\npd.options.display.float_format = '{:.2f}'.format\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        dtname= filename.replace(\".csv\", \"\" )\n        if dtname == \"train\":\n            train= pd.read_csv(os.path.join(dirname, filename)) \n        elif dtname == \"test\":    \n            test= pd.read_csv(os.path.join(dirname, filename)) ","e033f010":"train.head(10), test.head(10)","fbb7463b":"train.describe().T","e9f10b44":"train.info()","259c50b1":"train.R.unique()","e8257771":"train.u_out.unique()","4d600c49":"test.head()","980d6467":"def feature_engineering(df):\n    df[\"u_in_sum\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"sum\")\n    df[\"u_in_cumsum\"] = df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n    df[\"u_in_std\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"std\")\n    df[\"u_in_min\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"min\")\n    df[\"u_in_max\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\n    df[\"u_in_cumsum_reverse\"] = df[\"u_in_sum\"] - df[\"u_in_cumsum\"]\n    \n    df[\"u_in_first\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"first\")\n    df[\"u_in_last\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"last\")\n    \n    df[\"u_in_lag1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(1)\n    df[\"u_in_lead1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(-1)\n    df[\"u_in_lag1_diff\"] = df[\"u_in\"] - df[\"u_in_lag1\"]\n    df[\"u_in_lead1_diff\"] = df[\"u_in\"] - df[\"u_in_lead1\"]\n    \n    df[\"u_out_sum\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"sum\")\n    \n    df[\"time_passed\"] = df.groupby(\"breath_id\")[\"time_step\"].diff()\n    \n    return df\n    \ntrain_1 = feature_engineering(train)\ntest_1 = feature_engineering(test)","846593cf":"train_1.head()","e7c1ef7b":"in_df = train_1[train_1[\"u_out\"] == 0].reset_index(drop=True)\nin_df.shape","a6bc5e01":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","79e9a646":"train.dtypes.T","8caac365":"train_1 = train_1.fillna(train_1.min())\ntest_1 = test_1.fillna(test_1.min())","ef6204fa":"train_1.head()","456107b1":"#drop original dependent var and id \nX = train_1.drop(['id','breath_id' , 'u_in','u_out','pressure','u_in_sum', 'u_in_std','u_in_min','u_in_max','u_in_cumsum_reverse','u_in_first',\n'u_in_last','u_in_lag1','u_in_lead1','u_in_lag1_diff','u_in_lead1_diff','u_out_sum'],axis=1)\n#dt.drop(['SalePrice'], axis=1)\n#id\tbreath_id\tR\tC\ttime_step\tu_in\tu_out\tpressure\tu_in_sum\tu_in_cumsum\tu_in_std\tu_in_min\tu_in_max\tu_in_cumsum_reverse\tu_in_first\tu_in_last\tu_in_lag1\tu_in_lead1\tu_in_lag1_diff\tu_in_lead1_diff\tu_out_sum\ttime_passed\n\ny=train_1.pressure\n# Split train test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)","c1293a27":"#1. linear regression \nfrom sklearn import linear_model\nlr = linear_model.LinearRegression()\nmodel = lr.fit(X_train, y_train)\n#r square \nprint(\"R-Square : \" ,model.score(X_test,y_test))\n#rmse \npreds = model.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nprint ('RMSE: ', mean_squared_error(y_test, preds))","350299ec":"submit= pd.DataFrame()\nsubmit['id'] = test_1.id\n#select features \ntest_features = test_1.drop(['id','breath_id' , 'u_in','u_out','u_in_sum', 'u_in_std','u_in_min','u_in_max','u_in_cumsum_reverse','u_in_first',\n'u_in_last','u_in_lag1','u_in_lead1','u_in_lag1_diff','u_in_lead1_diff','u_out_sum'], axis=1)\npreds = model.predict(test_features)\n#unlog\/exp the prediction  \nfinal_preds = np.exp(preds)\nprint('Original preds :\\n', preds[:5])\nprint('Final preds :\\n', final_preds[:5])\nsubmit['pressure'] = final_preds\n#final submission \nfilename= \"venti_lr\"+datetime.today().strftime('%d-%m-%Y:%H:%M:%S').replace(\"-\",\"_\").replace(\":\",\"_\")+\".csv\"\nsubmit.to_csv(filename, index=False)\nprint(filename ,\" generated\")","b59e63b1":"from datetime import datetime\nfilename= \"venti_v1\"+datetime.today().strftime('%Y-%m-%d-%H:%M:%S').replace(\"-\",\"_\").replace(\":\",\"_\")+\".csv\"\nfilename","c98f378a":"from lofo import Dataset, LOFOImportance, plot_importance\nfrom sklearn.model_selection import GroupKFold\n\ncv = list(GroupKFold(n_splits=5).split(in_df, in_df[\"pressure\"], groups=in_df[\"breath_id\"]))\n\nfeatures = [\"time_step\", \"u_in\", \"R\", \"C\",\n            \"u_in_sum\", \"u_in_cumsum\", \"u_in_std\", \"u_in_min\", \"u_in_max\", \"u_in_cumsum_reverse\",\n            \"u_in_lead1\", \"u_in_lag1\", \"u_in_lag1_diff\", \"u_in_lead1_diff\",\n            \"u_out_sum\", \"time_passed\", \"u_in_first\", \"u_in_last\"]\n\nds = Dataset(in_df, target=\"pressure\", features=features,\n    feature_groups=None,\n    auto_group_threshold=0.9\n)\n \nlofo_imp = LOFOImportance(ds, cv=cv, scoring=\"neg_mean_absolute_error\")\n\nimportance_df = lofo_imp.get_importance()\nimportance_df","6fc79f20":"plot_importance(importance_df, figsize=(8, 10))","412915f6":"lofo_imp = LOFOImportance(ds, cv=cv, scoring=\"neg_mean_absolute_error\")\n\nimportance_df = lofo_imp.get_importance()\nimportance_df","9b6101a3":"#v1 : Results are horrible though <br>\nwith zero - 23388693885184200000000000000000.000 :) <br>\nwith mean()... R-Square :  0.36168178094061076, RMSE:  41.934312966351335 <br>\nwith std() ... R-Square :  0.38445055999331257 RMSE:  40.43851811333169\nadd Code","f7c84155":"!pip install lofo-importance"}}