{"cell_type":{"4d7779b3":"code","47536560":"code","f758f11a":"code","547834ac":"code","9746fa21":"code","9f8ce361":"code","8b3e402d":"code","d9da79a9":"code","0317d783":"code","d63d5db1":"code","ea1628cc":"code","735f6b1d":"code","3291ebe0":"code","4142f681":"code","6f64fc59":"markdown","d6912bee":"markdown","39c300f3":"markdown","b0757808":"markdown","9aa10796":"markdown","4de0d5b1":"markdown","76505d0f":"markdown","96092114":"markdown"},"source":{"4d7779b3":"import torch \nimport pandas as pd\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast","47536560":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","f758f11a":"df_data=pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')","547834ac":"df_data.sample(2)","9746fa21":"!git clone https:\/\/huggingface.co\/facebook\/mbart-large-50-many-to-many-mmt","9f8ce361":"!rm .\/mbart-large-50-many-to-many-mmt\/pytorch_model.bin","8b3e402d":"!wget https:\/\/huggingface.co\/facebook\/mbart-large-50-many-to-many-mmt\/resolve\/main\/pytorch_model.bin -P .\/mbart-large-50-many-to-many-mmt\/","d9da79a9":"!rm .\/mbart-large-50-many-to-many-mmt\/sentencepiece.bpe.model","0317d783":"!wget  https:\/\/huggingface.co\/facebook\/mbart-large-50-many-to-many-mmt\/resolve\/main\/sentencepiece.bpe.model -P .\/mbart-large-50-many-to-many-mmt\/","d63d5db1":"!ls -lh .\/mbart-large-50-many-to-many-mmt","ea1628cc":"ml2en_tokenizer = MBart50TokenizerFast.from_pretrained(\".\/mbart-large-50-many-to-many-mmt\")\n\nml2en_model = MBartForConditionalGeneration.from_pretrained(\".\/mbart-large-50-many-to-many-mmt\").to(device)","735f6b1d":"\ndef trans_module(text, source_language, target_language, piece_len=256, max_batch =8):\n    '''\n    piece_len: max length of input\n    max_batch: num sample of translation per time\n    '''\n    \n    ml2en_tokenizer.src_lang = source_language\n    \n    input_id = ml2en_tokenizer.encode(text)\n    \n    # special inputid for different language\n    start_id=[input_id[0]]\n    end_id=[input_id[-1]]\n    input_id = input_id[1:-1]\n    \n    #save translated result\n    res_text=''\n    \n    input_id_list= []\n    attention_mask_list=[]\n    \n    # create batch samples\n    for i in range(0,len(input_id),piece_len):\n        tmp_id = start_id+input_id[i:i+piece_len]+end_id\n        if len(input_id)<piece_len:\n            #only one sample\n            input_id_list.append(tmp_id)\n            attention_mask_list.append([1]*len(tmp_id))\n            break\n        else:\n            input_id_list.append(tmp_id+((piece_len+2)-len(tmp_id))*[1])#padding\n            attention_mask_list.append([1]*len(tmp_id)+((piece_len+2)-len(tmp_id))*[0])\n    \n    # translation\n    for i in range(0, len(input_id_list),max_batch):\n        input_id_list_batch = input_id_list[i:i+max_batch]\n        attention_mask_list_batch= attention_mask_list[i:i+max_batch]\n        input_dict = {'input_ids':torch.LongTensor(input_id_list_batch).to(device),\"attention_mask\":torch.LongTensor(attention_mask_list_batch).to(device)}\n        generated_tokens = ml2en_model.generate(\n            **input_dict,\n            forced_bos_token_id=ml2en_tokenizer.lang_code_to_id[target_language]\n        )\n        res_tmp =ml2en_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n        \n        # concate\n        res_text+=' '.join(res_tmp)\n    return res_text","3291ebe0":"for text in df_data['text'][:2].values:\n    print('*'*20)\n    print(text)","4142f681":"for text in df_data['text'][:2].values:\n    chinese_translated_res=trans_module(text,\"en_XX\",'zh_CN')\n    print('chinese_translated_res:',chinese_translated_res)\n    english_translated_res=trans_module(chinese_translated_res,\"zh_CN\",\"en_XX\")\n    print('english_translated_res:',english_translated_res)","6f64fc59":"More info:  \n\nPretrained Model:  \nhttps:\/\/huggingface.co\/facebook\/mbart-large-50-many-to-many-mmt\/tree\/main  \nData Augmentation:   \n[Unsupervised Data Augmentation for Consistency Training](https:\/\/arxiv.org\/pdf\/1904.12848.pdf)\n","d6912bee":"It provides an off-line translated API using the facebook\/mbart-large-50-many-to-many-mmt, and have done some preprocessing for a longer text (max_len>500 or any length). Besides, for running faster, it creates batch processing using a batch contain more samples.","39c300f3":"Feel free to use it, any questions can be commented!  \n","b0757808":"## Translation","9aa10796":"## Example","4de0d5b1":"This notebook is created for those people who want to do back translation for data enhancement or some other nlp tasks.  \n\nAlso, everyone can try it!\n\n\n","76505d0f":"## Download model","96092114":"## Tranlation function"}}