{"cell_type":{"a3a8c084":"code","753693f2":"code","e9189b25":"code","a8010d30":"code","b816f8ea":"code","8d4754ea":"code","0862f228":"code","ef3609c5":"code","e4517418":"code","2714bede":"code","d2c39135":"code","5662f13f":"code","72544f4e":"code","709f6ba5":"code","82329d8a":"code","91da1c9a":"code","2ff9c4b1":"code","c346fa33":"code","f1e53b59":"code","394886ec":"code","82c79b59":"code","fcb9a058":"code","4d3e64c1":"code","9882ae19":"code","7be48225":"code","3f18a665":"code","47985486":"code","51c50550":"code","c11f1e43":"code","0f462c1c":"code","c159a8f2":"code","b0ca856f":"code","35c1ef52":"code","93d930c9":"code","da1519dd":"code","abeb38f2":"code","ee853e74":"code","48fc67b4":"code","72f108b6":"code","b783854c":"code","73744889":"code","00ad18b4":"code","35da188b":"code","66252f1b":"code","e988ffda":"code","cf929a7b":"code","0fc94933":"code","98aae10d":"code","e3bb5813":"code","b497948d":"code","eb39b628":"code","8471602c":"code","8ee56263":"code","3dd5b49d":"code","3440ce03":"code","7337e8a0":"code","0a34d0a4":"code","3f8f0aa1":"code","50a59696":"code","8e2ee7f9":"code","fea9d02a":"code","4c510104":"code","0ceb42b6":"code","9fff1ada":"code","73601655":"code","172ae893":"code","0d9424a4":"code","fa886466":"code","0cdc8d4e":"code","ddafe564":"code","f021f5ca":"code","ac43b5a4":"code","3d4f7f0d":"code","5571ec92":"code","b652bbbf":"code","7cb86926":"code","6c6033de":"code","23e979e5":"code","77682f26":"code","f534a8c6":"code","f1dab37e":"code","f821b690":"code","913c8ae4":"code","16c77f98":"code","a07ca074":"markdown","f64a46c7":"markdown","33a3ed02":"markdown","b7a2b2dd":"markdown"},"source":{"a3a8c084":"import re\nfrom pathlib import Path\nimport numpy as np \nimport pandas as pd\nimport pickle\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\n\nfrom skimage import io\n\nfrom tqdm.notebook import tqdm\ntqdm().pandas();\n\nprint('import complete')","753693f2":"input_path = Path.cwd()\/'..\/input\/breast-histopathology-images'\nprint(input_path)","e9189b25":"# Create List of Paths\npath_contents = [path for path in Path.iterdir(input_path)]\n# Print out the first 5 paths\npath_contents[0:10]","a8010d30":"def get_files_folders(path,print_summary = True):\n    folders = []\n    files = []\n    for item in Path.iterdir(path):\n        if item.is_dir():\n            folders.append(item)\n        else:\n            files.append(item)\n    if print_summary:\n        print(f'There are {len(folders)} folders and {len(files)} files in folder {path.name}') \n    \n    return {'folders': folders, 'files': files, 'path': path} ","b816f8ea":"sorted_paths = get_files_folders(input_path)","8d4754ea":"patient_1 = sorted_paths['folders'][0]\n\nfor p in Path.iterdir(patient_1):\n    print(p,'\\n')\n# In order to obtain the number of files and folders\nget_files_folders(patient_1);","0862f228":"def verify_path_contents(input_path,n_folders,n_files,print_summary = True):\n    '''\n    loops through all the directories in a path and checks the number of folders and files in each directory\n    returns a dictionary containing a list of the matched paths and a list of the unmatched paths\n    '''\n    \n    matched_paths = []\n    unmatched_paths = []\n    \n    for path in Path.iterdir(input_path):\n        if path.is_dir():\n            folders = [sub_path for sub_path in Path.iterdir(path) if sub_path.is_dir()]\n            files = [sub_path for sub_path in Path.iterdir(path) if sub_path.is_file()]\n\n            if len(folders) != n_folders or len(files) != n_files:\n                unmatched_paths.append(path)\n            else:\n                matched_paths.append(path)\n        \n    if print_summary:\n        print(f'We have a total of {len(matched_paths)} matched paths, and a total of {len(unmatched_paths)} unmatched paths in {input_path.name}')\n        \n    return {'matched_paths':matched_paths,'unmatched_paths':unmatched_paths}","ef3609c5":"path_contents = verify_path_contents(input_path = input_path, n_folders = 2, n_files = 0)","e4517418":"patient_1_paths = get_files_folders(patient_1)","2714bede":"p = {}\nfor folder in patient_1_paths['folders']:\n    p[folder.name] = get_files_folders(folder)","d2c39135":"\ndisplay(p['0']['files'][0:5])\ndisplay(p['1']['files'][0:5])","5662f13f":"def extract_all_image_paths(input_path = Path.cwd()\/'..\/input\/breast-histopathology-images'):\n    image_paths = [image_path for image_path in Path.glob(input_path,pattern = '*\/*\/*.png')]\n    return image_paths","72544f4e":"image_paths = extract_all_image_paths()","709f6ba5":"image_paths[0:5]","82329d8a":"print(f'We have a total of {len(image_paths)} images.')","91da1c9a":"# let's check that we correctly extracted our paths\ndisplay(image_paths[0:3])\ndisplay(image_paths[10000:10003])","2ff9c4b1":"# Extracts a dict of lists containing the informaion of each path\ndef extract_metadata(image_paths) -> dict:\n    path_data = {'path':[],'patient_id':[],'x_coord':[] ,'y_coord':[],'target':[]}\n    pattern = '\\\/(\\d+)_.+_x(\\d+)_y(\\d+)_.+(\\d)'\n    for image_path in tqdm(image_paths,total = 277524):\n        meta_data = re.search(pattern, str(image_path))\n        \n        path_data['path'].append(image_path)\n        path_data['patient_id'].append(meta_data.group(1))\n        path_data['x_coord'].append(meta_data.group(2))\n        path_data['y_coord'].append(meta_data.group(3))\n        path_data['target'].append(meta_data.group(4))\n    return path_data","c346fa33":"# retrieve dict of path metadata\npath_data = extract_metadata(image_paths)","f1e53b59":"# extract and display the first 3 rows of each value\nfor value in path_data.values():\n    display(value[0:3]) ","394886ec":"# convert dictionary to pandas dataframe --> convert path_data dict to dataframe\ndf = pd.DataFrame.from_dict(path_data)","82c79b59":"# prints the first five rows of the dataframe\ndf.head()","fcb9a058":"# to get a better understanding of our dataframe we use the .info() method\ndf.info()","4d3e64c1":"df.iloc[:,2:5]","9882ae19":"# loop through the desired columns and change the types\nfor col in df.iloc[:,2:5]:\n    df[col] = df[col].astype('int')","7be48225":"df.info()","3f18a665":"# Function below gets the the number of patches for each patient, \n# and gets the ratio of cancerous patches to non-cancerous patches for each patient\n\ndef get_image_count_and_cancer_ratios(path_df):\n    # Return the count of images per patient\n    s1 = path_df.groupby('patient_id')['target'].count()\n    # Return the ratio of cancerous to non-cancerous images per-patient\n    s2 = path_df.groupby('patient_id')['target'].mean()\n\n    # Merge the series into one dataframe that uses the same index\n    df_summary = pd.concat([s1,s2],axis = 1)\n    df_summary.columns = ['n_patches\/patient','cancer_ratio']\n    return df_summary","47985486":"df_summary = get_image_count_and_cancer_ratios(path_df = df)\ndisplay(df_summary)","51c50550":"# Lets get a statistical summary of our dataframe\ndisplay (df_summary.describe())","c11f1e43":"# set bin values for number of images\nbin_values = np.linspace(0,2400,25)\n# below we will group our data into bins in order to e\ndef get_binned_cancer_ratio_df(path_df,bin_values):\n    df_summary = get_image_count_and_cancer_ratios(path_df)\n    # use cut to determine which values fit into which bin\n    bins = pd.cut(df_summary['n_patches\/patient'], bin_values)\n    # group your dataframe by the bins\n    binned_df = df_summary.groupby(bins).median() \n    binned_df['non-cancer_ratio_median'] = binned_df['cancer_ratio'].apply(lambda x: 1-x)\n    binned_df['n_patients_per_bin'] = df_summary['n_patches\/patient'].groupby(bins).count()\n    # rename cancer ratio to cancer ratio median since we are taking the median now\n    binned_df.rename(columns={'cancer_ratio':'cancer_ratio_median'},inplace=True)\n    return binned_df","0f462c1c":"binned_df = get_binned_cancer_ratio_df(df,bin_values)\nbinned_df # fix the average number n_imgs\/patient","c159a8f2":"def plot_patch_info(binned_df,bin_values):\n    \n    # get the the ranges for the x-axis since this is supposed to emulate a histogram\n    ranges = []\n    for i in range(len(bin_values)):\n        try: r = '('+str(int(bin_values[i]))+'-'+str(int(bin_values[i+1]))+')'\n        except: pass\n        ranges.append(r)\n    \n    # Number of Patients per Bin -> Bar Plot\n    trace_0 = go.Bar(name='Number of Patients Per Bin',x=ranges, y=binned_df['n_patients_per_bin'],marker_color='#ff6efa');\n    # Ratio of Cancerous Images -> Bar Plot\n    trace_1 = go.Bar(name='Cancerous Images', x=ranges, y=binned_df['cancer_ratio_median'],marker_color='#8634eb');\n    # Ratio of Non-Cancerous Images -> Bar Plot\n    trace_2 = go.Bar(name='Non-Cancerous Images', x=ranges, y=binned_df['non-cancer_ratio_median'],marker_color='#ff87c9')\n    # Number of Patches per Patient vs Cancer Ratio of Image -> Scatter Plot\n    trace_3 = go.Scatter(name='# Patches vs Cancer Ratio ',x = df_summary['n_patches\/patient'],y = df_summary['cancer_ratio'],mode='markers',marker=dict(size=16,color=df_summary['cancer_ratio'], colorscale=[[0.0, \"#ff87c9\"],[1.0, \"#8634eb\"]]))\n    \n    fig = make_subplots(rows=3, cols=1, \n                        shared_xaxes=True, \n                        vertical_spacing=0.05,\n                        subplot_titles=(\"Frequency of Number of Patches\",\n                                        \"Ratio of Cancerous to Non Cancerous Images as a Function of Number of Images per Patient\",\n                                        \"Number of Patches per Patient vs Cancer Ratio of Image\")\n                       )\n\n    # Change the bar mode\n    fig.update_layout(\n        barmode='stack',\n        bargap=0\n    )\n\n    fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n    fig.update_yaxes(title_text=\"Percentage\", row=2, col=1)\n    fig.update_yaxes(title_text=\"Percentage\", row=3, col=1)\n\n    fig.update_xaxes(title_text=\"Number of Patches\", row=3, col=1)\n    \n    fig.update_layout(height=1800,legend={'traceorder':'normal'})\n    fig.update_xaxes(rangemode=\"tozero\")\n\n    fig.append_trace(trace_0,1,1)\n    fig.append_trace(trace_1,2,1)\n    fig.append_trace(trace_2,2,1)\n    fig.append_trace(trace_3,3,1)\n\n\n    fig.show()","b0ca856f":"path_df = df\n#access rows and columns","35c1ef52":"def get_patient_df(p_id,df=df):\n    return df.loc[df['patient_id']== p_id,:] ","93d930c9":"from matplotlib.colors import LinearSegmentedColormap\n#binary image \ndef scatter_patient_xy(nrows=3,ncols=3):\n    n_imgs = nrows*ncols\n    # get random patient ids to plot\n    p_ids = np.random.choice(df['patient_id'].unique(), size=n_imgs, replace=False)\n    \n    fig, axs = plt.subplots(nrows=nrows,ncols=ncols,figsize=(30,30))\n    \n    colors = ['#ff70db','#9334eb']\n    \n    cmap = LinearSegmentedColormap.from_list(name='',colors = colors, N=2)\n    \n    for i,row in enumerate(axs):\n        for j,ax in enumerate(row):\n            p_id = p_ids[i*nrows+j]\n            p_df = get_patient_df(p_id)\n            \n            x_coords = p_df['x_coord'].values\n            y_coords = p_df['y_coord'].values\n            \n            min_coord = min(x_coords.max(),y_coords.max())\n            s = int(4000\/min_coord*15)\n            \n            targets = p_df['target'].values\n            ax.scatter(x_coords,y_coords,c=targets,cmap=cmap,s=s,marker='s')\n            ax.set_title('Patient: '+p_id)","da1519dd":"def get_tissue_image_array(patient_id,pred = False):\n    path_df = get_patient_df(patient_id)\n    max_coord = np.max((*path_df['x_coord'],*path_df['y_coord']))\n    image_dimension = max_coord + 50\n    grid = 255*np.ones(shape = (image_dimension,image_dimension,3)).astype('uint8')\n    mask = 155*np.ones(shape = (image_dimension,image_dimension,3)).astype('uint8')\n    for x,y,target,path in path_df[['x_coord','y_coord','target','path']].values:\n        img_array = io.imread(path)\n        try:\n            grid[y:y+50,x:x+50] = img_array \n            # if the image is cancerous add\n            if target != 0:\n                mask[y:y+50,x:x+50] = [0,0,255]\n        except: pass\n    if pred == False:\n        img = grid\n    else:\n        alpha = 0.8\n        img  = (mask * (1.0 - alpha) + grid * alpha).astype('uint8') # converting rgb\n        \n    return img\n            ","abeb38f2":"def plot_tissue_images(nrows=3,ncols=3,pred = False,df=df):\n    n_imgs = nrows*ncols\n    p_ids = np.random.choice(df['patient_id'].unique(), size=n_imgs, replace=False)\n    \n    fig,axs = plt.subplots(nrows=nrows,ncols=ncols,figsize=(30,30))\n    for i,row in enumerate(axs):\n        for j,ax in enumerate(row):\n            p_id = p_ids[i*nrows+j]\n            img = get_tissue_image_array(p_id,pred = pred)\n            ax.set_title(f'Breast Tissue Slice for patient {p_id}')\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.imshow(img)\n#plot_tissue_images(pred = True)","ee853e74":"# function that accepts number of patients and returns a dataframe containing all the images for each patient. \n# prioritizes patients with higher number of patches.\ndef get_patients(df,n_patients=10):\n    p_ids = df.groupby('patient_id')['patient_id'].count().sort_values(ascending=False).index[0:n_patients]\n    df =  df.loc[df['patient_id'].isin(p_ids)].reset_index(drop=True)\n    return df","48fc67b4":"sample_df= get_patients(df=df)\nsample_df.info()","72f108b6":"sample_df.head()","b783854c":"def get_img_arrays(df,):\n    # read each image array from corresponding path as grayscale and flatten the image array\n    df['img_array'] = df.progress_apply(lambda x : io.imread(x['path'],as_gray=True).flatten(),axis=1) # make sure to specify axis = 1\n    # get the shape of each image array and store it in the dataframe\n    df['array_shape'] = df.progress_apply(lambda x : x['img_array'].shape[0],axis=1) # make sure to specify axis = 1\n    return df","73744889":"sample_df = get_img_arrays(df = sample_df)","00ad18b4":"sample_df.head()\nprint(sample_df)\n#pltshow(sample_df)","35da188b":"# get the count of the unique values in the column array_shape\nsample_df['array_shape'].value_counts() ","66252f1b":"weird_imgs = sample_df[sample_df['array_shape'] != 2500] ","e988ffda":"# get the shape of the dataframe before dropping the artifacts\n#normalize data, variables will have the same std, thus the same weight which will help PCA to calculate relevant d\u00fczlemler\nsample_df.shape ","cf929a7b":"# drop images using indices of the filter\nsample_df.drop(weird_imgs.index,inplace=True) ","0fc94933":"# get the shape of the dataframe before dropping the artifacts\nsample_df.shape ","98aae10d":"#PCA applying on the images extract image arrays into numpy ones\nsample_df.head()","e3bb5813":"# get the number of rows in the pandas dataframe in order to determine the number of rows in our numpy array\nnrows=sample_df.shape[0]\n# set the number of columns to 2500, which is the length of our array\nncols=2500\n# initialize the array using the information above\nimg_arrays= np.zeros((nrows,ncols))\nprint(img_arrays.shape)","b497948d":"# add all the image arrays to the numpy array that we just initialized\nfor i,array in enumerate(sample_df['img_array']):\n    img_arrays[i,:] = array\ndisplay(img_arrays[0:5,:])","eb39b628":"from sklearn.decomposition import PCA\n# n_components = 0.8, account for 80% of the variation\nimages_pca = PCA()\n# fit the function to our image arrays\nimages_pca.fit(img_arrays);\nprint(sample_df)","8471602c":"# explained get the cumalitive sum of the explained variance ratio for each principle component\nevr = np.cumsum(images_pca.explained_variance_ratio_)\n# plot the explained variance ratio\nfig = go.Figure(data=go.Scatter(y = evr,line=dict(color='#190b15')))\nfig.update_layout(title='Variance Ratio After PCA',\n                   xaxis_title='Number of Principle Components',\n                   yaxis_title='Variance explained by a principal component')\nfig.show()","8ee56263":"# let's now apply PCA but only retrieve the first 150 components or the components that account for 80 percent of the variance\nimages_pca = PCA(0.8) \n# OR\nimages_pca = PCA(150)\n# fit the function to our image arrays\nimages_pca.fit(img_arrays);","3dd5b49d":"# get the shape of the first image array\nsample_df['img_array'][0].shape","3440ce03":"# Apply PCA transformation to each row in the img_array column\n# hint: the transform function accepts a list, so if you wanted to feed it one value you would have to place that value in a list\nsample_df['pca_array'] = sample_df['img_array'].progress_apply(lambda x: images_pca.transform([x]).flatten()) ","7337e8a0":"sample_df['pca_array'][0].shape","0a34d0a4":"sample_df.head()","3f8f0aa1":"components = images_pca.transform(img_arrays)\nprojected = images_pca.inverse_transform(components)\n\n# Plot the results\nfig, ax = plt.subplots(2, 5, figsize=(20, 7))\nfor i in range(5):\n    ax[0, i].imshow(img_arrays[i].reshape(50, 50), cmap='binary_r')\n    ax[1, i].imshow(projected[i].reshape(50, 50), cmap='binary_r')\n    \nax[0, 0].set_ylabel('Before PCA')\nax[1, 0].set_ylabel('150-dim\\nReconstruction');","50a59696":"# get the count of each of the target values\nsample_df['target'].value_counts() ","8e2ee7f9":"# get the dataframe containing the negative target variables\nnegative = sample_df[sample_df['target'] == 0]\n# get the dataframe containing the positive target variables\npositive = sample_df[sample_df['target'] == 1]\n# get the shapes of each dataframe\ndisplay(negative.shape)\ndisplay(positive.shape)","fea9d02a":"from sklearn.utils import resample\n# downsample the negative targets\nneg_downsampled = resample(negative,n_samples=positive.shape[0], random_state=42)\n# combine minority and downsampled majority\ndownsampled = pd.concat([positive, neg_downsampled])\n# check new class counts\ndownsampled['target'].value_counts()","4c510104":"# show the first 5 values of the dataframe\ndownsampled.head()","0ceb42b6":"# let's extract our variables of interest and store them in a new dataframe\ndfd = downsampled.loc[:,['img_array','pca_array','target']]","9fff1ada":"dfd.head()","73601655":"# get the number of rows in the pandas dataframe in order to determine the number of rows in our numpy array\nnrows=dfd.shape[0]\n# set the number of columns to 150, which is the length of our array\nncols=150\n# initialize the array using the information above\npca_arrays= np.zeros((nrows,ncols))\nprint(pca_arrays.shape)","172ae893":"# loop over the array and replace the data\nfor i,array in enumerate(dfd['pca_array']):\n    pca_arrays[i,:] = array","0d9424a4":"from sklearn.model_selection import train_test_split\n# split our data into training and testing data, and input data and target data\nX_train, X_test, y_train, y_test =  train_test_split(pca_arrays, dfd['target'], train_size=0.7, shuffle = True)","fa886466":"# compare the shape of the train and test inputs\nprint(f'X_train Shape: {X_train.shape}')\nprint(f'X_test Shape: {X_test.shape}')\nprint(f'y_train Shape: {y_train.shape}')\nprint(f'y_test Shape: {y_test.shape}')","0cdc8d4e":"#A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class\n\nfrom sklearn.svm import SVC #support vector classification\nfrom sklearn.metrics import plot_confusion_matrix, confusion_matrix\nfrom sklearn import metrics\n\nsvc_rbf = SVC(kernel = 'rbf',gamma = 'auto' )\nsvc_linear = SVC(kernel='linear',gamma = 'auto')\nclf=SVC()\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nplot_confusion_matrix(clf,X_test,y_test)\nmatrix = confusion_matrix(y_test,y_pred)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Support Vector Classification(SVM)\")\n\nprint(matrix.diagonal()\/matrix.sum(axis=1))\nprint(\"Accuracy: \", metrics.accuracy_score(y_test,y_pred)*100,\"%\")","ddafe564":"# fitting our models\nsvc_rbf.fit(X = X_train,y = y_train);\nsvc_linear.fit(X = X_train,y = y_train);","f021f5ca":"print(svc_linear.score(X_train,y_train))\nprint(svc_rbf.score(X_train,y_train))","ac43b5a4":"print(svc_linear.score(X_test,y_test))\nprint(svc_rbf.score(X_test,y_test))","3d4f7f0d":"from sklearn.tree import DecisionTreeClassifier  \nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, confusion_matrix\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\n\n\nplot_confusion_matrix(clf,X_test,y_test)\nmatrix = confusion_matrix(y_test,y_pred)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nmap_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\nprint(list(map_characters.values()))    \nprint(matrix.diagonal()\/matrix.sum(axis=1))\nprint(\"Accuracy: \", metrics.accuracy_score(y_test,y_pred)*100,\"%\")","5571ec92":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=10, random_state=10)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\n\nmatrix = confusion_matrix(y_test,y_pred)\n\nplot_confusion_matrix(clf,X_test,y_test)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Random Forest Classifier\")\nprint(matrix.diagonal()\/matrix.sum(axis=1))\nprint(\"Accuracy: \", metrics.accuracy_score(y_test,y_pred)*100,\"%\")","b652bbbf":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=3)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nmatrix = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(clf,X_test,y_test)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"K Neighbors Classifier\")\nprint(matrix.diagonal()\/matrix.sum(axis=1))\nprint(\"Accuracy: \", metrics.accuracy_score(y_test,y_pred)*100,\"%\")","7cb86926":"from sklearn.linear_model import SGDClassifier\n\nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5000)\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nmatrix = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(clf,X_test,y_test)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"SGDC Classifier\")\nprint(matrix.diagonal()\/matrix.sum(axis=1))\nprint(\"Accuracy: \", metrics.accuracy_score(y_test,y_pred)*100,\"%\")","6c6033de":"from sklearn.metrics import confusion_matrix\n\ntn, fp, fn, tp = confusion_matrix(y_true=y_test,y_pred=svc_linear.predict(X_test)).ravel()\n\nprint(f'training set: true negatives: {tn}')\nprint(f'training set: true positives: {tp}')\nprint(f'training set: false negatives: {fn}')\nprint(f'training set: false positives: {fp}')","23e979e5":"from sklearn.metrics import confusion_matrix\n\ntn, fp, fn, tp = confusion_matrix(y_true=y_test,y_pred=svc_rbf.predict(X_test)).ravel()\n\nprint(f'training set: true negatives: {tn}')\nprint(f'training set: true positives: {tp}')\nprint(f'training set: false negatives: {fn}')\nprint(f'training set: false positives: {fp}')\n","77682f26":"from sklearn.linear_model import LinearRegression as LR\nfrom sklearn.tree import DecisionTreeRegressor as DTR\nfrom sklearn.ensemble import RandomForestRegressor as RFR\nfrom sklearn.ensemble import GradientBoostingRegressor as GBR\nfrom sklearn.ensemble import AdaBoostRegressor as ABR\nfrom sklearn.neighbors import KNeighborsRegressor as KNR\nfrom sklearn.svm import SVR \nfrom sklearn.linear_model import Ridge as RR\nimport seaborn as sns","f534a8c6":"models={'Linear Regression':LR(),'Decision Tree Regression':DTR(),'Random Forest Regression':RFR(),'Gradient Boosting Regression':GBR(),'Ada Boosting Regression':ABR(),'K-Neighbors Regression':KNR(),'Support Vector Regression':SVR(),'Ridge Regression':RR()}\npred =[]\nprint(models.keys())","f1dab37e":"from sklearn.metrics import r2_score\nfor name,algo in models.items():\n    model=algo\n    model.fit(X_test,y_test)\n    predictions = model.predict(X_test)\n    acc=r2_score(y_test, predictions)\n    pred.append(acc)\n    print(name,acc)","f821b690":"final = DTR()\nfinal.fit(X_train,y_train)\nfinal_pred = final.predict(X_test)","913c8ae4":"sns.barplot(y=list(models.keys()),x=pred,linewidth=1.5,orient ='h',edgecolor=\"0.1\")","16c77f98":"sns.distplot(y_test,hist = False,label ='Actual')\nsns.distplot(final_pred,hist = False, label ='Predicted')","a07ca074":"#### Initialize Image Array","f64a46c7":"### Fitting the model ","33a3ed02":"Let's double check that our function is extracting everything correctly","b7a2b2dd":"### Model Evaluation"}}