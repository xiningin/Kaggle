{"cell_type":{"cc19045d":"code","6ceb11da":"code","932d6af1":"code","61772e7f":"code","84d64bd8":"code","4b01264c":"code","0b815f6c":"code","3f99d851":"code","40cf6cdc":"code","28c3f244":"code","49325735":"code","ac4212fd":"code","54971734":"code","f8b47eee":"code","808caa6b":"code","deb6d19e":"code","fa153d2a":"code","0ae582f5":"code","f0c430da":"code","b9355b22":"code","af2c24e8":"code","f0b2bc42":"code","25316427":"code","a3f2b884":"code","70dd0014":"code","5f6fca1a":"code","3445d221":"code","9a166656":"code","73175015":"code","ff7f33dd":"code","cff24a2a":"code","eedff3ad":"code","a1d52c51":"code","d0627ca3":"code","a9066a8a":"code","d33f9f9c":"code","ce7d05eb":"code","7e820c9b":"code","762684a9":"code","e89d3c96":"code","b5cbdbb7":"code","e0f7cb24":"code","a1fdb1be":"code","11605bff":"code","f02cb9db":"code","7b2c8d63":"code","5a53b8af":"code","fa5c46d4":"code","503306f2":"code","7798a8d9":"code","881c168a":"code","0e104ff0":"code","f0f3c824":"code","c2842808":"code","a87bc551":"code","39dd9773":"code","8cbba131":"code","b366007b":"code","51334bc0":"code","1ea73c8a":"code","8434b5dc":"code","a478ae25":"code","780e2e37":"markdown","3f301e31":"markdown","9448b003":"markdown","5f79d1ef":"markdown","e37a1dc2":"markdown","c415504d":"markdown","862b9a75":"markdown","bc0ffd63":"markdown","79b6d415":"markdown","9223aaac":"markdown","17f4f9f0":"markdown","f8a88944":"markdown","3b1f97b6":"markdown","5aa397c2":"markdown","5ca0b5b1":"markdown","ba7548e2":"markdown","a5edb534":"markdown","440d9724":"markdown","3e91bb5c":"markdown","04110a13":"markdown","44535106":"markdown","1262911e":"markdown","8a228dc1":"markdown","0e290fd9":"markdown","d45bbd75":"markdown","8fc80f1a":"markdown","49ef1491":"markdown","bf6e1f7d":"markdown","c3a04588":"markdown","de4c5a8d":"markdown","fddf9dfe":"markdown","f0d815c9":"markdown","77c4f32e":"markdown","8e3fb96a":"markdown","1daa41cb":"markdown","050f243c":"markdown","22958e41":"markdown","3092f028":"markdown","a045c64a":"markdown","de63e912":"markdown","89f418c7":"markdown","7c7e3db5":"markdown","204dd2fc":"markdown","6133e61e":"markdown","e20df439":"markdown","2f62f8f1":"markdown","bc852578":"markdown","302e4bff":"markdown","2fd44ea4":"markdown","0e497ae0":"markdown","a3041754":"markdown","a518deb7":"markdown","a5f7c127":"markdown","f6c3ee4b":"markdown"},"source":{"cc19045d":"import os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n%matplotlib inline\n\n# disable the warning about settingwithcopy warning:\npd.set_option('chained_assignment',None)","6ceb11da":"working_directory_path = \"\/kaggle\/input\/ieee-fraud-detection\/\"\nos.chdir(working_directory_path)","932d6af1":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","61772e7f":"train_identity = pd.read_csv(\"train_identity.csv\")\ntrain_transaction = pd.read_csv(\"train_transaction.csv\")\n\ntest_identity = pd.read_csv(\"test_identity.csv\")\ntest_transaction = pd.read_csv(\"test_transaction.csv\")\n\ntrain_identity = reduce_mem_usage(train_identity)\ntrain_transaction = reduce_mem_usage(train_transaction)\ntest_identity = reduce_mem_usage(test_identity)\ntest_transaction = reduce_mem_usage(test_transaction)","84d64bd8":"# Since the number of columns are too large, we can expand it using pd.set_option()\npd.set_option('display.max_columns', None)  ","4b01264c":"train_transaction['TransactionID'].value_counts().sort_values(ascending = False)","0b815f6c":"train_full = pd.merge(train_identity, train_transaction, on = 'TransactionID')","3f99d851":"print('Number of row in transaction:', len(train_transaction))\nprint('Number of row in identity:', len(train_identity))\n\n# remove train_transaction from memory\n# del train_transaction","40cf6cdc":"train_full.info(verbose=True, null_counts=True)","28c3f244":"train_full_cat = train_full.filter(regex='id|card|ProductCD|addr|email|M|DeviceType|DeviceInfo')","49325735":"plt.figure(figsize=(18,9))\nsns.heatmap(train_full_cat.isnull(), cbar= False)","ac4212fd":"train_full_cat[['id_01','id_12','card1','card2']].info(null_counts=True)","54971734":"train_full_num = train_full.filter(regex='isFraud|TransactionDT|TransactionAmt|dist|C|D')\nplt.figure(figsize=(18,9))\nsns.heatmap(train_full_num.isnull(), cbar= False)","f8b47eee":"train_full_Vesta = train_full.filter(regex='V')\nplt.figure(figsize=(18,9))\nsns.heatmap(train_full_Vesta.isnull(), cbar= False)","808caa6b":"msno.dendrogram(train_full_Vesta)","deb6d19e":"plt.hist(train_transaction['TransactionDT'], label='train')\nplt.hist(test_transaction['TransactionDT'], label='test')\nplt.legend()\nplt.title('Distribution of TransactionDT')","fa153d2a":"plt.figure(figsize=(12,6))\ng = sns.countplot(x = 'isFraud', data = train_full)\ng.set_title(\"Fraud Distribution\", fontsize = 17)\ng.set_xlabel(\"Is Fraud?\", fontsize = 15)\ng.set_ylabel(\"Count\", fontsize = 15)\nplt.legend(title='Fraud', labels=['No', 'Yes'])\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/len(train_full) * 100),\n            ha=\"center\", fontsize=15) ","0ae582f5":"train_full_cat.head()","f0c430da":"plt.figure(figsize=(12,6))\n\ntotal = len(train_full_cat)\n\nplt.subplot(121)\ng = sns.countplot(x = 'ProductCD', data = train_full_cat)\ng.set_title('ProductCD Distribution', fontsize = 15)\ng.set_xlabel(\"Product Code\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(122)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=train_full)\ng1.set_title('ProductCD by Fraud', fontsize = 15)\ng1.set_xlabel(\"Product Code\", fontsize=15)\ng1.set_ylabel(\"Count\", fontsize=15)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])","b9355b22":"train_full[train_full['isFraud'] == 1]['ProductCD'].value_counts(normalize = True)","af2c24e8":"# grouped table\ntrain_full.groupby('ProductCD')['isFraud'].value_counts(normalize = True)","f0b2bc42":"# visualization of table\nplt.figure(figsize=(12,12))\na = train_full.groupby('ProductCD')['isFraud'].value_counts(normalize = True).unstack().plot.bar(stacked = True)\na.set_title('Rate of Fraud by Product Category', fontsize = 15)\nplt.xticks(rotation='horizontal')","25316427":"plt.figure(figsize=(12,10))\nsns.boxplot(x = 'ProductCD', y = 'TransactionAmt', hue = 'isFraud', data = train_full)","a3f2b884":"plt.figure(figsize=(12,10))\nsns.boxplot(x = 'ProductCD', y = 'TransactionDT', hue = 'isFraud', data = train_full)","70dd0014":"train_full_cat.describe().loc[:,'card1':'card5']","5f6fca1a":"train_full_cat.loc[:,'card1':'card5'].nunique()","3445d221":"plt.figure(figsize=(12,6))\n\ntotal = len(train_full_cat)\n\nplt.subplot(121)\ng = sns.countplot(x = 'card4', data = train_full_cat)\ng.set_title('Card Network Distribution', fontsize = 15)\ng.set_xlabel(\"Card Issuers\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(122)\ng1 = sns.countplot(x='card4', hue='isFraud', data=train_full)\ng1.set_title('Card Network by Fraud', fontsize = 15)\ng1.set_xlabel(\"Card Issuers\", fontsize=15)\ng1.set_ylabel(\"Count\", fontsize=15)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])","9a166656":"train_full[train_full['isFraud'] == 1]['card4'].value_counts(normalize = True)","73175015":"# grouped table\ntrain_full.groupby('card4')['isFraud'].value_counts(normalize = True)","ff7f33dd":"# visualization of table\nplt.figure(figsize=(12,12))\nb = train_full.groupby('card4')['isFraud'].value_counts(normalize = True).unstack().plot.bar(stacked = True)\nb.set_title('Rate of Fraud by Card Network', fontsize = 15)\nplt.xticks(rotation='horizontal')","cff24a2a":"plt.figure(figsize=(12,6))\n\ntotal = len(train_full_cat)\n\nplt.subplot(121)\ng = sns.countplot(x = 'card6', data = train_full)\ng.set_title('Card Type Distribution', fontsize = 15)\ng.set_xlabel(\"Card Type\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(122)\ng1 = sns.countplot(x='card6', hue='isFraud', data=train_full)\ng1.set_title('Card Type by Fraud', fontsize = 15)\ng1.set_xlabel(\"Card Type\", fontsize=15)\ng1.set_ylabel(\"Count\", fontsize=15)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])","eedff3ad":"# grouped table\ntrain_full.groupby('card6')['isFraud'].value_counts(normalize = True)","a1d52c51":"# visualization of table\nplt.figure(figsize=(12,12))\nb = train_full.groupby('card6')['isFraud'].value_counts(normalize = True).unstack().plot.bar(stacked = True)\nb.set_title('Rate of Fraud by Card Type', fontsize = 15)\nplt.xticks(rotation='horizontal')","d0627ca3":"plt.figure(figsize=(12,6))\n\ng = sns.countplot(x = 'P_emaildomain', data = train_full)\ng.set_title('Purchaser Email Domain Distribution', fontsize = 15)\ng.set_xlabel(\"Email Domain\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nplt.xticks(rotation='vertical')\n","a9066a8a":"train_full[\"P_parent_emaildomain\"] = train_full[\"P_emaildomain\"].str.split('.', expand = True)[[0]]","d33f9f9c":"plt.figure(figsize=(12,6))\n\ng = sns.countplot(x = 'P_parent_emaildomain', data = train_full)\ng.set_title('Purchaser Email Domain Distribution', fontsize = 15)\ng.set_xlabel(\"Email Domain\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nplt.xticks(rotation= \"vertical\")","ce7d05eb":"P_emaildomain_fraud_rate = train_full.groupby('P_parent_emaildomain')['isFraud'].value_counts(normalize = True).unstack().fillna(0)[1]\n\nplt.figure(figsize=(12,6))\n\ng = sns.countplot(x = 'P_parent_emaildomain', data = train_full, order = P_emaildomain_fraud_rate.index)\ng.set_title('Purchaser Email Domain Distribution', fontsize = 15)\ng.set_xlabel(\"Email Domain\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nplt.xticks(rotation= \"vertical\")\n\nr = g.twinx()\nr = sns.pointplot(x = P_emaildomain_fraud_rate.index, y = P_emaildomain_fraud_rate, color = 'blue')\nr.set_ylabel(\"Fraud Rate\", fontsize = 16, color = \"blue\")\n","7e820c9b":"protonmail_fraud = len(train_full[(train_full['P_parent_emaildomain'] == \"protonmail\") & (train_full['isFraud'] == 1)])\nprotonmail_non_fraud = len(train_full[(train_full['P_parent_emaildomain'] == \"protonmail\") & (train_full['isFraud'] == 0)])\n\nprotonmail_fraud_rate = protonmail_fraud\/ (protonmail_fraud + protonmail_non_fraud)\nprint(\"Number of protonmail fraud transactions:\", protonmail_fraud)\nprint(\"Number of protonmail non-fraud transactions:\", protonmail_non_fraud)\nprint(\"Protonmail fraud rate:\", protonmail_fraud_rate)","762684a9":"train_full[\"R_parent_emaildomain\"] = train_full[\"R_emaildomain\"].str.split('.', expand = True)[[0]]\ntrain_full[\"R_parent_emaildomain\"].fillna(\"NA\", inplace=True)\n\nR_emaildomain_fraud_rate = train_full.groupby('R_parent_emaildomain')['isFraud'].value_counts(normalize = True).unstack().fillna(0)[1]\n\nplt.figure(figsize=(12,6))\n\ng = sns.countplot(x = 'R_parent_emaildomain', data = train_full, order = R_emaildomain_fraud_rate.index)\ng.set_title('Recipient Email Domain Distribution', fontsize = 15)\ng.set_xlabel(\"Email Domain\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\nplt.xticks(rotation= \"vertical\")\n\nr = g.twinx()\nr = sns.pointplot(x = R_emaildomain_fraud_rate.index, y = R_emaildomain_fraud_rate, color = \"blue\")\nr.set_ylabel(\"Fraud Rate\", fontsize = 16, color = \"blue\")","e89d3c96":"def visualize_cat_cariable(variable, df=train_full):\n    train_full[variable].fillna(\"NA\", inplace=True)\n    variable_fraud_rate = df.groupby(variable)['isFraud'].value_counts(normalize = True).unstack().fillna(0)[1]\n    \n    plt.figure(figsize=(12,6))\n\n    g = sns.countplot(x = variable, data = df, order = variable_fraud_rate.index)\n    g.set_title('{} Count'.format(variable), fontsize = 15)\n    g.set_xlabel(\"{}\".format(variable), fontsize=15)\n    g.set_ylabel(\"Count\", fontsize=15)\n    plt.xticks(rotation= \"vertical\")\n\n    r = g.twinx()\n    r = sns.pointplot(x = variable_fraud_rate.index, y = variable_fraud_rate, color = \"blue\")\n    r.set_ylabel(\"Fraud Rate\", fontsize = 16, color = \"blue\")\n","b5cbdbb7":"train_full_cat.loc[:,'M1':'M9'].apply(pd.value_counts)","e0f7cb24":"visualize_cat_cariable('M4')","a1fdb1be":"visualize_cat_cariable('DeviceType')","11605bff":"train_full['DeviceInfo'].value_counts()","f02cb9db":"devicelist = train_full.groupby('DeviceInfo').filter(lambda x: len(x) >500)['DeviceInfo'].unique()","7b2c8d63":"visualize_cat_cariable('DeviceInfo', df = train_full[train_full['DeviceInfo'].isin(devicelist)])","5a53b8af":"# id_list = train_full.loc[:1, 'id_12':'id_38'].columns\n\n# for i in id_list:\n#     print (visualize_cat_variable(i))","fa5c46d4":"visualize_cat_cariable('id_23')","503306f2":"visualize_cat_cariable('id_30')","7798a8d9":"train_full['major_os'] = train_full[\"id_30\"].str.split(' ', expand = True)[[0]]\n\nvisualize_cat_cariable('major_os')","881c168a":"visualize_cat_cariable('id_31')","0e104ff0":"train_full['browser'] = train_full[\"id_31\"].str.split(' ', expand = True)[[0]]\n\nvisualize_cat_cariable('browser')","f0f3c824":"browser_list = train_full.groupby('browser').filter(lambda x: len(x) > 144)['browser'].unique()\nvisualize_cat_cariable('browser',  df = train_full[train_full['browser'].isin(browser_list)])","c2842808":"def visualize_num_variable(variable, df=train_full):\n    plt.figure(figsize=(12,18))\n    plt.suptitle('Distribution of: {}'.format(variable), fontsize=22)\n\n    plt.subplot(321)\n    sns.distplot(df[variable], kde= False)\n    plt.title('{} Distribution'.format(variable), fontsize = 15)\n\n    plt.subplot(322)\n    sns.distplot(np.log10(df[variable]), kde= False)\n    plt.title('Log-transformed Distribution', fontsize = 15)\n\n\n    plt.subplot(323)\n    sns.distplot(df[df['isFraud'] == 0][variable], color = 'skyblue', kde= False, label = 'Not Fraud')\n    sns.distplot(df[df['isFraud'] == 1][variable], color = 'red', kde= False , label = 'Fraud')\n    plt.title('Fraud vs Non-Fraud Distribution', fontsize = 15)\n    plt.legend()\n\n    plt.subplot(324)\n    sns.distplot(np.log10(df[df['isFraud'] == 0][variable]), color = 'skyblue', kde= False, label = 'Not Fraud')\n    sns.distplot(np.log10(df[df['isFraud'] == 1][variable]), color = 'red', kde= False , label = 'Fraud')\n    plt.title('Log-transformed Distribution', fontsize = 15)\n    plt.legend()\n    \n    plt.subplot(313)\n    sns.boxplot(x = 'isFraud', y = variable, data = df)\n    plt.title('Transaction Amount by Fraud', fontsize = 15,  weight='bold')","a87bc551":"visualize_num_variable('TransactionAmt')","39dd9773":"visualize_num_variable('TransactionDT')","8cbba131":"def visualize_num_variable(variable, df=train_full.copy()):\n    # check for homogeneity:\n    if len(df[variable].unique()) <= 1:\n        print('{} is a homogeneous set'.format(variable))\n        return\n    \n    # check for NAs and Zeros\n    if df[variable].isnull().values.any():\n        df = train_full.dropna(subset=[variable])\n\n    if df[variable].min() < 0:\n        plt.figure(figsize=(12,12))\n        plt.suptitle('Distribution of: {}'.format(variable), fontsize=22)\n    \n        plt.subplot(221)\n        sns.distplot(df[variable], kde= False)\n        plt.title('{} Distribution'.format(variable), fontsize = 15)\n        \n        plt.subplot(222)\n        sns.distplot(df[df['isFraud'] == 0][variable], color = 'skyblue', kde= False, label = 'Not Fraud')\n        sns.distplot(df[df['isFraud'] == 1][variable], color = 'red', kde= False , label = 'Fraud')\n        plt.title('Fraud vs Non-Fraud Distribution', fontsize = 15)\n        plt.legend()\n        \n        plt.subplot(212)\n        sns.boxplot(x = 'isFraud', y = variable, data = df)\n        plt.title('{} by Fraud'.format(variable), fontsize = 15,  weight='bold')\n        \n    else:\n        smallest_value = df[df[variable] != 0][variable].min()\n        if df[variable].min() == 0:\n            df[variable].replace(0, smallest_value\/10, inplace=True)       \n\n        plt.figure(figsize=(12,18))\n        plt.text(x=0.5, y=0.5,\n                 s=\"Zeros have been replaced with {} to avoid log infinity\".format(smallest_value\/10),\n                 fontsize=12,horizontalalignment='center')\n\n        plt.suptitle('Distribution of: {}'.format(variable), fontsize=22)\n\n        plt.subplot(321)\n        sns.distplot(df[variable], kde= False)\n        plt.title('{} Distribution'.format(variable), fontsize = 15)\n\n        plt.subplot(322)\n        sns.distplot(np.log10(df[variable]), kde= False)\n        plt.title('Log-transformed Distribution', fontsize = 15)\n\n\n        plt.subplot(323)\n        sns.distplot(df[df['isFraud'] == 0][variable], color = 'skyblue', kde= False, label = 'Not Fraud')\n        sns.distplot(df[df['isFraud'] == 1][variable], color = 'red', kde= False , label = 'Fraud')\n        plt.title('Fraud vs Non-Fraud Distribution', fontsize = 15)\n        plt.legend()\n\n        plt.subplot(324)\n        sns.distplot(np.log10(df[df['isFraud'] == 0][variable]), color = 'skyblue', kde= False, label = 'Not Fraud')\n        sns.distplot(np.log10(df[df['isFraud'] == 1][variable]), color = 'red', kde= False , label = 'Fraud')\n        plt.title('Log-transformed Distribution', fontsize = 15)\n        plt.legend()\n\n        plt.subplot(313)\n        sns.boxplot(x = 'isFraud', y = variable, data = df)\n        plt.title('{} by Fraud'.format(variable), fontsize = 15,  weight='bold')","b366007b":"visualize_num_variable('dist2')","51334bc0":"# id_list = train_full.loc[:1, 'C1':'C14'].columns\n\n# for i in id_list:\n#     print (visualize_num_variable(i))","1ea73c8a":"visualize_num_variable('C3')","8434b5dc":"# id_list = train_full.loc[:1, 'D1':'D15'].columns\n\n# for i in id_list:\n#     print (visualize_num_variable(i))","a478ae25":"visualize_num_variable('D2')\nvisualize_num_variable('D8')\nvisualize_num_variable('D9')","780e2e37":"The transaction ID for transaction table is also unique for each observation. Therefore, we have 1 to 1 join from identity table to transaction table:","3f301e31":"**Observation**: \n    \n    1. Basic information about transaction such as ID, DT, amount and type of product is complete \n    \n    2. Dist1 and dist2 is very sparse.\n    \n    3. C columns are complete\n    \n    4. Most D columns are sparse except D1\n    \nLastly, we want to check for data completeness of **Vesta's engineered features**:","9448b003":"We have a few browers that have absurdly high fraud rate. This is likely to due the scarcity of those browsers. We can fix this by apply a minimum-instance-filter. Let's say 0.1 percent of data rows is our cut-off, then each category must have at least 144 instances to be included in our plot:","5f79d1ef":"**Observation**: Ahh, she looks like a work of art. The repeated missing patterns in the V columns suggest that many V columns are related and perhaps trying to describe certain characteristics of a transaction. For example, columns V322-V399 have identical missing locations.\n\nLet's verify our intuition with correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another:","e37a1dc2":"Card 1 contains 8499 unique values, suggesting card 1 may have been ID of the card. Card 2,3 and 5 have less unique values, so perhaps they could be expiration date, or combinations that generate card identity? Since we don't know how these information was scrammbled, we might pickup patterns generated by encryption algorithm instead of data. No further analysis should be done unless more infomation is given.\n\nSame goes for the addr1 and addr2.","c415504d":"We can aggregate the operating system into a few major OSs. ","862b9a75":"**Obervation**: The first notable id plot is the IP status. It is interesting to see the anonymous IP_Proxy would have a higher fraud rate. If someone were to commit a fraudulent transaction, it makes sense that the person would want to protect his\/her identity.\n\n### Operating Systems","bc0ffd63":"## Joining the transaction data:\n\n### Transaction Table:\n\nTransaction table contain TransactionID, which we can use to join with the identity table.","79b6d415":"## Objective:\n\n**Predict fraud based on transaction information**\n","9223aaac":"**Observation**:The fraud percentage is quite high: 7.85% for the complete observations (identity + transaction). We can see there is a class imbalance problem, where occurence of one class is significantly higher than another. This will lead to much a higher false negative - tendency of picking \"not fraud\". We can mitigate this issue by using two common methods:\n\n1. Cost function based approaches\n\n2. Sampling based approaches","17f4f9f0":"Some people suggest that if `TransactionDT` is measured in seconds, then the combined time period between test and train dataset could total to approximately 1 year, and the gap can account for ~ 1 month. \n\nLynn@Vesta commented in one of the discussion post:\n\n*\"We define reported chargeback on card, user account, associated email address and transactions directly linked to these attributes as fraud transaction (isFraud=1); If none of above is found after 120 days, then we define as legit (isFraud=0)\"*\n","f8a88944":"Protonmail returns an exemely high fraud rate. Almost 80% of transactions from purchaser using protonmail.com were label fraud. Let's double check this result:","3b1f97b6":"**Observartion**: Not much variation in fraud rate between M0, M1, and M2 in M4\n\nWe have gone through all categorical variables in the Transaction Table, now we check out the remaining categorical variables in the Identity Table.\n\n## Examine DeviceType","5aa397c2":"**Observation**: Dist2 does not seem to varies between fraud and not-fraud\n\n## Examine C features\n\nSame way of handling a large number of variables, I only choose the notable plots that reflect a large degree of variation. Trying to keep this kernel concised is one of my goals. In this case, I only consider C3 to have some significant patterns:","5ca0b5b1":"## Examine M1-M9\n\nThe transaction data that has comple identity returns mostly NaN except for M4. Let's check it out:","ba7548e2":"## Examine DeviceInfo","a5edb534":"**Observation**: There is a large number of non-fraud transactions generated at a certain period . This discrepancy also causing the difference in our boxplot.\n\n**Possible Improvement**: I should try undersampling the period of non-fraud so that we have less imbalance issue for that particular period.","440d9724":"**Observation**: Fraud rate is higher for mobile device compared to desktop","3e91bb5c":"**Observation**: We can see that our data has a lot of missing values. White color presents missing values.\n\n1. Most M columns missing almost if not all data\n\n2. Id_07, 08 and id_21-27 missing most data\n\n3. Id_01, id_12, card1, card2 contains mostly non-null. Perhaps, these columns contain unique ID information, and therefore, cannot be null. Let's double check the number of missing in these columns: ","04110a13":"**Observation**: Opera and android browser have relatively high fraud rate","44535106":"## Conclusion for EDA:\n\n1. Target variable has class imbalance problem where instance of fraud is much lower than non-fraud\n\n2. Multiple columns contain too many missing values\n\n3. Several columns are homogeneous, therefore, prodvide no useful information in predicting the target variable (this may not be the case for transaction table since we are using a joined table)\n\n4. There is period of time where instances of non-fraud far exceed the usual proportion of non-fraud to fraud \n\n5. Basic understand of variables can help us do simple feature engineering\n\nWe will deal with each problem with the purpose of improving the prediction accuracy. But first, let's try a default XGBoost model provided by Vesta. We can use this model as a baseline to compare the improvement (or reduction) of each engineered feature, change, and alteration that  we made along the way.\n\n## Brainstorm\nBefore treating this problem like a black box of ensemble learning, it's worthwhile to take our hands off the keyboards and think about the problem of fraud detection in a more \"open-box\" way. There are a lot of intersting questions worth investigating before diving into the madness of hyperparameters tuning. Insights that could lead to trivial and sometimes important questions. Questions that take us on a journey of curiosity and fulfilment. \n\nFor the data scientists whose minds love to wander. This section is dedicated for silly and serious questions alike.\n\n**Scenario** :A Vesta executive storms in the office and excitedly tells everyone that an exciting project has fallen in their laps. It's the fraud detection problem. And he ask his people for some ideas of where to start, which features should be useful in prediciting fraud. He knows it is strange to ask the scientists before attempting any EDA or modeling. After all, they haven't seen a lick of relevant data. But he saids it would be great practive to dip the toe into the water before diving in without any direction. So let's start with the few things that were provided to us: transaction amount, time, card infor, identity, etc... Which information would give us a good start at cracking this problem?\n\nLet's define clearly what is a fraud transaction first. \"Fraud detection is a set of activities undertaken to prevent money or property from being obtained through false pretenses\" [Source](https:\/\/searchsecurity.techtarget.com\/definition\/fraud-detection). Most common type of frauds are forging checks or using stolen credit cards. If a person got of hold of your card info, what should he\/she do with it? After browsing on Reddit, I found some crude scenarios:\n\n1. If you drop your card, it's likely the person who found it by chance and commit a fraud would spend it on consumable and essential products like grocery and gas. The perp will likely go somewhere nearby and spend a larger amount than usual before the card get locked. So perhaps we should look at user's purchase history so that any activities or purchases that deviate from normal buying habit would stand out. But we don't have identifiable data, so we can't go on this route.\n\n2. If your information get hacked by careless purchases on some shady websites\/gas stations, it's likely that your information will be sold to someone else who use your information for making fraud transaction. This person will make an online purchase and ship it to a distributor, who sells the good for cash and share the profit with the frauder. In this situation, the good is shipped to some far-away place from the user's home address. So the further the distance, the more a transaction looks like a fraud? No, of course not. People sends gifts all the times. But perhaps gifting 3 expensive laptops is slightly more suspicious than gifting a box of chocolate.\n    \n    **Feature Engineering:** Combine transaction amount, type of good, and distance together.\n    \n3. Fraud commited by someone close to you (family member: spouse, siblings, etc). It's rare, but it could happen.\n\n4. Prefered tools for committing fraud. We have learned previously in the EDA that Protonmail has exceptionally high fraud rate >95%. A quick google reveal that Proton is a email service that provide free, anonymous, end-to-end encryption email accounts. Quote from Proton website: \"ProtonMail is incorporated in Switzerland and all our servers are located in Switzerland. This means all user data is protected by strict Swiss privacy laws\". Meaning fraud perpetrator not only protected by the full extend of the privacy law, but also doing it at no cost. Similarly, we have other tools that also have abnormally high fraud rate such as:\n\n    * Browser: Comodo IceDragon, Mozilla\/Firefox?? (not firefox, but perhaps is Comodo IceDragon but recognized as another version of Firefox?)\n    \n    * Operating system: \"other\" category has fraud rate of 60%.\n    \n    * Phone (or browser?): Lanix Ilium\n    \n    **Feature Engineering:** New features that emphasize the importance of these tools\n    \n5. Time of operation. Just like any other jobs, frauders operate at routinely hours that perhaps different from the real users. It is strange, at least to me, to make purchase decision to buy an iphone at 3 in the morning. Again, without historical data, this approach is dead in the egg.\n\n\n# Baseline Model\n\nModeling section is being explore in another private notebook since only 1 GPU instance is allow in Kaggle Kernel...","1262911e":"**Observation**: The fraud rate across multiple well-known OSs seem fairly similar. \"Other\" operating systems have a much higher fraud rate.\n\nHowever, it's strange that we see more IOS devices compared to Android, given that Android is the most popular mobile system. If I were to work for Vista, I would ask how the system collects more IOS instances. Could it be that Vista have given us an filtered dataset? Specific market segment? Systematic error or deficiency in collecting Android info?\n\n### Browsers","8a228dc1":"**Observation**: All products have same min and max timedelta range. \n\n**Conclusion**:The plot suggests little to no difference in timedelta accross all groups.\n\n## Examine Card 1,2,3,5\n\nThe card 1,2,3, and 5 was represented as numerical values, temping us to plot the histogram. However, we need to remember that card columns were classified as categorical variables. Meaning it's likely that these numerical variables were coded for categorical variables.","0e290fd9":"Fewer email domains result in cleaner x tickers. Let's add the fraud rate like in the previous graphs, but this time we add the rate line on top of this graph:","d45bbd75":"**Conclusion**: Visa accounts for 61% of all fraud occurences. However, when normalized by total number of each type, Visa have fraud rate of only 8%, lower than Mastercard and same as Discovercard. Only American Express have significantly lower fraud rate compare to others.","8fc80f1a":"### 2. Recipient Email\n\nSimilarly, we can perform the similar analysis on Recepient email domains","49ef1491":"# Explore Numerical Features\n\nI anticipate that most variables we will encounter would not follow a normal distribution. Therefore, for each variable, we will explore:\n\n1. Distribution\n\n2. Log of distribution\n\n3. Distribution by target variable\n\n4. Log of distribution by target variable\n\n5. Boxplot comparison between fraud and non-fraud\n\n## Examine Transaction Amount","bf6e1f7d":"## 3. Replacement or drop the missings\nThe idea of imputation is both *\"seductive and dangerous\"* in the words of R.J.A Little. \n\nI truly believe that there is no best way to deal with missing, especially when having to deal with partial information. Knowing which columns could be imputed or dropped may alter the result of the final predictions by a non-trivial amount. The fact that certain value is missing could have been due to specific variation in the feature (missing not at random). This is one of the process that could have been much more useful if we were given the meaning of each columns. But when life gives you lemon, you turns it into sweet, sweet meachine learning input juice. \n\n### Understand that Train and Test data were splitted by time\n\nThis is a graceful finding from https:\/\/www.kaggle.com\/robikscube\/ieee-fraud-detection-first-look-and-eda.\n\n* The `TransactionDT` feature is defined as time delta from a chosen datetime. This gives us information about the relative time and the countinuity of each transaction. Ploting both test and train `TransactionDT` on the graph suggests that train and test dataset were splited by time, with a gap in between.","c3a04588":"## Examine Transaction DT","de4c5a8d":"## 4. Response\/ Target Variable","fddf9dfe":"**Observations**: C is the most frequent product category. Product C also have the highest count of fraud. We can obtain the proportion of fraud for each product category:","f0d815c9":"I enjoy this format of visualizing, so I should creat a function that help me explore the categorical format with regard to fraud rate:","77c4f32e":"Since we have way too many devices, it makes more sense to select a few devices that has non-trivial count. Let's select categories that have more than 500 counts:","8e3fb96a":"This suggests that there are transactions that don't have identity. A quick research on the [discussion thread](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/101203#latest-605862) reveals that Vesta was unable to collect all identity information due to technical difficulty. Therefore, we will need to face two options:\n\n1. Using identity + transaction to make predictions. This option results in fewer observations but more complete (more features).\n\n2. Using only transaction\n\n3. Using transaction but add identity when avaiable\n\nFor now, we only explore the identity + transaction joined table to do EDA and build model. ","1daa41cb":"# Data Quality Inspection\n\nThere are couple common issues that we need to watch out for:\n\n1. Attributes Formatting (data types)\n\n2. Missing Data\n\n3. Replacement or Drop\n\n4. Response Variable\n\nFirst, let's transform our data into the types that we expected:\n\n## 1. Attributes formatting (data types)","050f243c":"**Observation**: I see alot of domains came from the same distributors such as hotmail.com, hotmail.fr, yahoo.com, yahoo.fr, yahoo.de, etc. We can group these domains together under the parent distributors.\n\n**Action:** Create P_parent_emaildomain field that remove the part after '.' ","22958e41":"# Explore Categorical Features\n**Categorical Features:**\n\n**1. Transactional Table:**\n    \n    ProductCD\n\n    card1 - card6\n\n    addr1, addr2\n\n    Pemaildomain Remaildomain\n\n    M1 - M9\n    \n    \n**2. Identity Table**\n\n    DeviceType\n\n    DeviceInfo\n    \n    id12 - id38\n\nLet's take a quick look at these categorical features:","3092f028":"**Observation**: Not much difference in fraud rate between credit card and debit card\n\n## Examine Email Domain\n\n### 1. Purchaser Email","a045c64a":"## Examine Card 4 and 6\n\n### Card 4: Card Network","de63e912":"**Observation**: Higher values of C3 associated with no-fraud.\n\nC5 and C9 are homogeneous columns.\n\n## Examine D features","89f418c7":"### Card 6: Card Type\n\nSimilarly, we can use the same method of data analysis on this variable:","7c7e3db5":"**Interpretation**: The dendrogram uses a hierarchical clustering algorithm to bin variables against one another by their nullity correlation. Each cluster of leaves explain how one variable might always be empty when another is empty, or filled when another variable is filled. This dendogram suggests that the position of missing\/fill values are correlated. Perhaps similar columns were derived from the same feature or combinations of features.","204dd2fc":"**Observation:** The number of card type are fairly simiar, and so does the fraud cases. ","6133e61e":"## Examine Product Code","e20df439":"**Observation:** Visa card accounts for the highest instances of fraud, but this also because visa is the most popular card type. Again, we can only conclude after comparing the fraud propotion for each card type:","2f62f8f1":"Yes, they are indeed complete, except for card 2. If I were to guess, card1 could be first name and card2 could be last name.\n\nNow let's check out missing data for **numerical variables**:","bc852578":"**Observation**: \n    1. TransactionAmt has right-skewed distribution: most transactions are small (less than $200)\n    2. There is little difference between distribution and average amount for fraud and non-fraud","302e4bff":"Same as previous plot, we need to reduce the number of categories using aggregation:","2fd44ea4":"## Examine Distance 2\n\nDist1 contains no values. For dist2, we also running into two problems:\n\n1. Missing values:\n\n    Solution: keeping only the non-null rows in dist2.\n\n2. Zero values:\n\n    Zero values cause log transform to return infinity values\n\n    Solution: add small amount to 0s to avoid infinity\n    \n3. Negative values\n    \n    The logarithm is only defined for positive numbers. I could perhaps take the log(x+n), where n is the offset values that make the min negative value > 0. However, for such data 0 has a meaning (equality!) that should be respected. Unless I know the meaning of the data, I cannot make arbitrary transformation.\n    \n    Solution: no solution, omit the log-transformation graphs\n\nLet's update our graphing function with this implementation\n","0e497ae0":"**Observation**: We can see the fraud rate is higher for certain devices\n\n## Examine id12 - id38\n\nWe may generate all the graphs for id12 to id38. Depend on your preference, some graphs may be more informative than the other. The graphs below are selected based on:\n\n1. If the graph contains non-masked information (or categories have self-expalainatory meaning)\n    * For example: 'Found' and 'NotFound' are two categories that by themselves, don't provide us with any helpful information in understanding their relationships with target variable. Perhaps our learner can pickup on the differences, but it's outside of our domain to understand these variables semantically. \n\n2. If the graph contains not too many categories so that the xtickers can be plotted legibly\n\nYou can plots them all out and select for yourself. Here are some of my picks:\n\n### IP Proxy","a3041754":"Most of the column names have been masked for privacy protection. Without accurate description of the fields meaning, it would be difficult to determine the type of data. Fortunately, Vesta have provided us with high-level summary of data.\n\nLet's recall the avaiable groups of information that were provided for us:\n\n1. Identity Table:\n\n    * id_01 - id_38: contains network connection information\n    \n    * DeviceType and DeviceInfo\n    \n2. Transactional Table:\n\n    * card1 - card6: card information\n    \n    * addr: address\n    \n    * dist: distance\n\n    * P_ and (R__) emaildomain: purchaser and recipient email domain\n    \n    * C1-C14: counting\n    \n    * D1-D15: timedelta, such as days between previous transaction, etc.\n    \n    * M1-M9: match, such as names on card and address, etc.\n    \n    * V1-V339: Vesta engineered features\n    \n    * ProductCD: product code, the product for each transaction\n    \n    * TransactionDT: timedelta from a given reference datetime\n    \n    * TransactionAMT: transaction payment amount in USD    \n    \n## Missing Data\n    \nLet's take a look at the missing data for the **categorical variables** first:","a518deb7":"**Observation**: Product C are items with low dollar value.","a5f7c127":"**Conclusion**: Product C takes up 67.5% of fraud cases for transactions that have identity. And also have highest rate of fraud: 12%, more than double any other class of product.\n\n**Question**: Why product C? Is there any additional information that help us better understand product C high fraud rate?\n\nWe have 2 numerical variables that we can compare between groups of products:\n\nTransactionDT: timedelta from a given reference datetime\n\nTransactionAmt: transaction payment amount in USD","f6c3ee4b":"However, it comes to my attention that the number of rows are different for each table, despite having unique TransactionID:"}}