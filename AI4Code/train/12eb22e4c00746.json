{"cell_type":{"dfa7293e":"code","3b0c217e":"code","07d38f90":"code","ba8d0386":"code","fad90c36":"code","474f651f":"code","990a7ca2":"code","cdb2e474":"code","2af29d28":"code","b2084f6e":"code","e77d9d6d":"code","32b204e0":"code","7d035a3f":"code","f28ecc5a":"code","dcf9bc3b":"code","8926d2ee":"code","e3c38b48":"code","fbe21cd9":"code","d0324cdf":"code","38b3831a":"code","e4bdb5fc":"code","95e24d28":"code","0450e351":"code","88f562af":"code","24b23d3e":"code","3f8619b0":"code","0b995dfa":"code","62c879fd":"markdown","2af3bd8d":"markdown","ac47b754":"markdown","c89650f1":"markdown","8975018d":"markdown","e2525c81":"markdown","a07b0d52":"markdown","1699bda3":"markdown","00f0519b":"markdown"},"source":{"dfa7293e":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing","3b0c217e":"pd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)","07d38f90":"test_path = '..\/input\/house-prices-advanced-regression-techniques\/test.csv'\ntrain_path = '..\/input\/house-prices-advanced-regression-techniques\/train.csv'\ntest_data = pd.read_csv(test_path)\ntrain_data = pd.read_csv(train_path)\n#Copy of original dataframe\ntest_data_orig = test_data.copy()\ntrain_data_orig = train_data.copy()\nprint('Data imported')","ba8d0386":"#Total rows and columns\ntrain_data_shape = train_data.shape\ntest_data_shape = test_data.shape\n\nprint('Rows train: ', train_data_shape[0],', Columns train: ', train_data_shape[1])\nprint('Rows test: ', test_data_shape[0],', Columns test: ', test_data_shape[1])","fad90c36":"columns_train = ['MSZoning','LotFrontage','LotArea','Utilities','Neighborhood','Condition1','Condition2',\n'OverallQual','OverallCond','YearBuilt','ExterQual','ExterCond','BsmtQual','BsmtCond','Heating','Electrical',\n'GarageQual','GarageCond','SalePrice'\n]\n\ncolumns_test = ['MSZoning','LotFrontage','LotArea','Utilities','Neighborhood','Condition1','Condition2',\n'OverallQual','OverallCond','YearBuilt','ExterQual','ExterCond','BsmtQual','BsmtCond','Heating','Electrical',\n'GarageQual','GarageCond'\n]\n\n\n\ntrain_data = train_data[columns_train]\ntest_data = test_data[columns_test]","474f651f":"#Total of nulls per column\ntrain_total_nulls = train_data.isnull().sum().sort_values(ascending=False)\ntest_total_nulls = test_data.isnull().sum().sort_values(ascending=False)\n\nprint('\\nTotal nulls per column Train Data:\\n', train_total_nulls)\nprint('\\nTotal nulls per column Test Data:\\n', test_total_nulls)","990a7ca2":"#Train set\n\n#Reemplazar nulos\ntrain_data['LotFrontage'].fillna((train_data['LotFrontage'].mean()), inplace=True)\ntrain_data['GarageQual'].fillna(\"NoGarage\", inplace=True)\ntrain_data['GarageCond'].fillna(\"NoGarage\", inplace=True)\n\n#Eliminar filas restantes con nulos\ntrain_data.dropna(inplace=True)\n\ntrain_data.reset_index()","cdb2e474":"#Test set\n\n#Reemplazar nulos\ntest_data['LotFrontage'].fillna((test_data['LotFrontage'].mean()), inplace=True)\ntest_data['GarageQual'].fillna(\"NoGarage\", inplace=True)\ntest_data['GarageCond'].fillna(\"NoGarage\", inplace=True)\ntest_data['BsmtQual'].fillna(test_data.iloc[0]['BsmtQual'], inplace=True)\ntest_data['BsmtCond'].fillna(test_data.iloc[0]['BsmtCond'], inplace=True)\ntest_data['Utilities'].fillna(test_data.iloc[0]['Utilities'], inplace=True)\ntest_data['MSZoning'].fillna(test_data.iloc[0]['MSZoning'], inplace=True)\n\ntest_data.reset_index()","2af29d28":"#Total of nulls per column\ntrain_total_nulls = train_data.isnull().sum().sort_values(ascending=False)\ntest_total_nulls = test_data.isnull().sum().sort_values(ascending=False)\n\nprint('\\nTotal nulls per column Train Data:\\n', train_total_nulls)\nprint('\\nTotal nulls per column Test Data:\\n', test_total_nulls)","b2084f6e":"#Total rows and columns after remove nulls\ntrain_data_shape = train_data.shape\ntest_data_shape = test_data.shape\n\nprint('Rows train: ', train_data_shape[0],', Columns train: ', train_data_shape[1])\nprint('Rows test: ', test_data_shape[0],', Columns test: ', test_data_shape[1])","e77d9d6d":"# Combining train and test datasets to fit encoder\n\ntarget = train_data['SalePrice']\nall_data = pd.concat((train_data, test_data)).reset_index(drop = True)\nall_data.shape","32b204e0":"#Get object type columns\nobjecttype_columns = all_data.select_dtypes(include=[object]).columns   #Object type columns\ndata_objecttype = all_data[objecttype_columns]   #Copy data object type\nprint(objecttype_columns)\n\n\n#Encode categorical data\nall_data[objecttype_columns] = all_data[objecttype_columns].astype('category')","7d035a3f":"#Encoder - Ordinal Encoder\nencoder = OrdinalEncoder()\nencoder.fit(all_data[objecttype_columns])\nall_data[objecttype_columns] = encoder.transform(all_data[objecttype_columns])\n","f28ecc5a":"all_data[objecttype_columns]","dcf9bc3b":"#MinMax Scaler LotArea\nminmax_scaler = MinMaxScaler()\nall_data['LotFrontage'] = minmax_scaler.fit_transform(all_data[['LotFrontage']])\n\nminmax_scaler = MinMaxScaler()\nall_data['LotArea'] = minmax_scaler.fit_transform(all_data[['LotArea']])\n\nminmax_scaler = MinMaxScaler()\nall_data['YearBuilt'] = minmax_scaler.fit_transform(all_data[['YearBuilt']])\n\nall_data.describe()","8926d2ee":"all_data[\"OverallQC\"] = all_data[\"OverallQual\"] * all_data[\"OverallCond\"]\nall_data[\"ExterQC\"] = all_data[\"ExterQual\"] * all_data[\"ExterCond\"]\nall_data[\"BsmtQC\"] = all_data[\"BsmtQual\"] * all_data[\"BsmtCond\"]\nall_data[\"BsmtQC\"] = all_data[\"BsmtQual\"] * all_data[\"BsmtCond\"]","e3c38b48":"# Dividir de nuevo Train and Test\n#y_train = all_data[\"SalePrice\"].copy()\n\nx_train = all_data.iloc[:len(target), :]\n#x_train = all_data.drop(\"SalePrice\", axis=1)\n\nx_test_data = all_data.iloc[len(target):, :]\nx_test_data = x_test_data.drop(\"SalePrice\", axis=1)\n\nprint(x_train.shape, x_test_data.shape)","fbe21cd9":"#Delete outliers Select data between percentile 5 and 95\n\n#Function to calculate percentile 5 y 95\ndef calc_percentil(data, column_name):\n    columndata = data[column_name].values #get column data\n    percentil_5 = np.percentile(columndata, 5) #get perc 5\n    percentil_95 = np.percentile(columndata, 95) #get perc 95\n    return percentil_5, percentil_95\n\n#Function to delete data out of percentile 5 and 95\ndef drop_outlier(data, column_name, percentil5, percentil95):\n    data = data[\n    (data[column_name] > limit1) & \n    (data[column_name] < limit2)\n    ]\n    return data\n\n#calc_percentil(dataframe, column_name)\n#drop_outlier(dataframe, column_name, perc5, perc95)\n\nlimit1, limit2 = calc_percentil(x_train, \"LotArea\")\nx_train = drop_outlier(x_train, \"LotArea\", limit1, limit2)\nlimit1, limit2 = calc_percentil(x_train, \"LotFrontage\")\nx_train = drop_outlier(x_train, \"LotFrontage\", limit1, limit2)\n\nx_train.describe()","d0324cdf":"#Se grafican para ver el resultado\n\nfig = make_subplots(\n    rows=1, \n    cols=2,\n    subplot_titles=(\n\"LotArea\",\n\"LotFrontage\")\n)\n\nfig.update_layout(\n    showlegend=False\n)\n\nfig.add_trace(go.Box(y=x_train['LotArea'], boxpoints=\"all\"), 1,1)\nfig.add_trace(go.Box(y=x_train['LotFrontage'], boxpoints=\"all\"), 1,2)\n\nfig.show()","38b3831a":"y_train_all = x_train['SalePrice']\nx_train_all = x_train.drop('SalePrice', axis=1)","e4bdb5fc":"# Train and Test \nx_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=42)\n#y_train = pd.DataFrame(x_train_all, columns = [\"SalePrice\"])\n#training_set = pd.DataFrame(x_train, columns = feature_cols).merge(y_train, left_index = True, right_index = True)\n#training_set.head()","95e24d28":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\nseed = 7\nnp.random.seed(seed)\ninput_shape = 21\n\ncolumns = x_train.columns\n\n# Model\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Dense(210),\n        layers.Dense(840),\n        layers.Dense(420),\n        layers.Dense(210),\n        layers.Dense(840),\n        layers.Dense(420),\n        layers.Dense(210),\n        layers.Dense(840),\n        layers.Dense(420),\n        layers.Dense(210),\n        layers.Dense(840),\n        layers.Dense(420),\n        layers.Dense(840),\n        layers.Dense(420),\n        layers.Dense(1),\n    ]\n)\n\n\nfeature_cols = x_train[columns]\nlabels = y_train.values\n\nmodel.summary()","0450e351":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.001,\n    decay_steps=10000,\n    decay_rate=0.01)\n\nopt=keras.optimizers.Adamax(learning_rate=lr_schedule)","88f562af":"# Compile model\nmodel.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae', 'mse'])","24b23d3e":"hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, verbose=1)","3f8619b0":"predictions = model.predict(x_test_data)\npredictions[0][0]\n\ndfpred = pd.DataFrame()\n\nfor i, k in enumerate(predictions):\n    dfpred = dfpred.append({'SalePrice' : k[0]},ignore_index=True)","0b995dfa":"dfsubmission = pd.concat([test_data_orig['Id'], dfpred], axis=1, join=\"inner\")\n\ndfsubmission.to_csv('submission.csv', index=False)\n\nprint(dfsubmission)","62c879fd":"# Delete Outliers","2af3bd8d":"# Model","ac47b754":"# Imports","c89650f1":"# Import Data","8975018d":"# Interactions","e2525c81":"# Encode Categorical","a07b0d52":"# Submission","1699bda3":"# House Price Prediction - NN\n\nC\u00e9sar Jim\u00e9nez Mena","00f0519b":"# Scaler"}}