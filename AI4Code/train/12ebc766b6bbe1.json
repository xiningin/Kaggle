{"cell_type":{"e23d5b05":"code","a709468f":"code","96b24be1":"code","2f94a4fa":"code","19810cac":"code","d41c64b6":"code","aede0036":"code","3cb6687c":"code","63b6ae4a":"code","4602ede4":"code","d99c98b6":"code","3a325889":"code","79756a52":"code","34be92bc":"code","208ae8b7":"markdown","e9e1e2ea":"markdown","e58bb23f":"markdown","b7aa0e4c":"markdown","c0ffd298":"markdown","2b54b2e8":"markdown","e8c2946a":"markdown"},"source":{"e23d5b05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n     #   print(os.path.join(dirname, filename))\n    print(dirname)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a709468f":"import matplotlib.pyplot as plt\nimport keras, shutil\nfrom keras.layers import Input, MaxPooling2D, AveragePooling2D, Conv2D, Dense, Flatten, concatenate, BatchNormalization, Add, ZeroPadding2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator","96b24be1":"path = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/'\n\n# print number of samples in each class\nprint(\"Parasitized samples: \", len(os.listdir(os.path.join(path, 'Parasitized'))))\nprint(\"Uninfected samples: \", len(os.listdir(os.path.join(path, 'Uninfected'))))","2f94a4fa":"temp_path = '\/kaggle\/temp\/'\nos.mkdir(temp_path)\n\n# create 'train' and 'val' directory\n# also create sub directories within each directory named as 'parasitized' and 'uninfected' \nos.mkdir(os.path.join(temp_path, 'train'))\nos.mkdir(os.path.join(temp_path, 'train\/parasitized'))\nos.mkdir(os.path.join(temp_path, 'train\/uninfected'))\n\nos.mkdir(os.path.join(temp_path, 'val'))\nos.mkdir(os.path.join(temp_path, 'val\/parasitized'))\nos.mkdir(os.path.join(temp_path, 'val\/uninfected'))","19810cac":"# copy images to 'train' and 'val' directories in '\/kaggle\/temp'\n\n# copy all images to 'train' directory\nfor filename in os.listdir(os.path.join(path, 'Parasitized')):\n    src = path + 'Parasitized\/' + filename\n    dst = temp_path + 'train\/parasitized'\n    shutil.copy(src, dst)\n    \nfor filename in os.listdir(os.path.join(path, 'Uninfected')):\n    src = path + 'Uninfected\/' + filename\n    dst = temp_path + 'train\/uninfected'\n    shutil.copy(src, dst)\n    \n# move 20% of the images to 'val' directory\nfor filename in os.listdir(os.path.join(temp_path, 'train\/parasitized'))[0:2712]:\n    src = temp_path + 'train\/parasitized\/' + filename\n    dst = temp_path + 'val\/parasitized'\n    shutil.move(src, dst)\n    \nfor filename in os.listdir(os.path.join(temp_path, 'train\/uninfected'))[0:2712]:\n    src = temp_path + 'train\/uninfected\/' + filename\n    dst = temp_path + 'val\/uninfected'\n    shutil.move(src, dst)","d41c64b6":"# print number of samples in 'train' and 'val' directory\ntrain_num_samples = 0\nfor _, _, filenames in os.walk(os.path.join(temp_path, 'train')):\n    train_num_samples += len(filenames)\n    \nval_num_samples = 0\nfor _, _, filenames in os.walk(os.path.join(temp_path, 'val')):\n    val_num_samples += len(filenames)\n    \nprint(\"train_num_samples: \",train_num_samples)\nprint(\"val_num_samples: \",val_num_samples)","aede0036":"# create Image Data Generator\ndatagen = ImageDataGenerator(rescale = 1.0 \/ 255)\n\ntrain_batch_size = 32\ntrain_dir = temp_path + 'train\/'\n\n# create train image generator\ntrain_gen = datagen.flow_from_directory(train_dir,\n                                       target_size = (224,224),\n                                       batch_size = train_batch_size,\n                                       class_mode = 'binary')\n\n# create val image generator\nval_batch_size = 32\nval_dir = temp_path + 'val'\n\nval_gen = datagen.flow_from_directory(val_dir,\n                                     target_size = (224, 224),\n                                     batch_size = val_batch_size,\n                                     class_mode = 'binary')","3cb6687c":"# print label encodings\nprint(train_gen.class_indices)","63b6ae4a":"x, y = train_gen.next()\n\nplt.figure(figsize=(20,20))\n\nfor i, (img, label) in enumerate(zip(x, y)):\n    \n    plt.subplot(8, 4, i+1)\n    \n    if label == 0:\n        plt.title('Infected')\n    else:\n        plt.title('Uninfected')\n        \n    plt.imshow(img)","4602ede4":"def inception_module(X, filters, name=None):\n    \"\"\"\n    Creates inception module\n    \n    Arguments:\n    \n    X -- input tensor of shape (m , n_H, n_W, n_C)\n    filters -- python list, containing number of filters for layers as follows:\n                            - conv_1x1         (as f1)\n                            - conv_3x3_reduce  (as f2)\n                            - conv_3x3         (as f3)\n                            - conv_5x5_reduce  (as f4)\n                            - conv_5x5         (as f5)\n                            - max_pool_reduce  (as f6)\n    name -- name of the inception module\n    Returns:\n    X -- output of the inception module, tensor of shape (m, n_H, n_W, n_C)\n    \"\"\"\n    \n    # Retrieve number of filters\n    f1, f2, f3, f4, f5, f6 = filters\n    \n    conv_1x1 = Conv2D(filters = f1, kernel_size = (1,1), strides = (1,1), padding='same', activation='relu', name=name + '\/1x1', kernel_regularizer = l2(0.0002))(X)\n    \n    conv_3x3_reduce = Conv2D(filters = f2, kernel_size = (1,1), strides = (1,1), padding='same', activation='relu', name=name + '\/3x3_reduce', kernel_regularizer = l2(0.0002))(X)\n    conv_3x3 =        Conv2D(filters = f3, kernel_size = (3,3), strides = (1,1), padding='same',activation='relu', name=name + '\/3x3', kernel_regularizer = l2(0.0002))(conv_3x3_reduce)\n    \n    conv_5x5_reduce = Conv2D(filters = f4, kernel_size = (1,1), strides = (1,1), padding='same', activation='relu', name=name + '\/5x5_reduce', kernel_regularizer = l2(0.0002))(X)\n    conv_5x5 =        Conv2D(filters = f5, kernel_size = (5,5), strides = (1,1), padding='same', name=name + '5x5', kernel_regularizer = l2(0.0002))(conv_5x5_reduce)\n    \n    max_pool_reduce = MaxPooling2D(pool_size = (3,3), strides = (1,1), padding='same', name=name + '\/pool')(X)\n    max_pool = Conv2D(filters = f6, kernel_size = (1,1), strides = (1,1), padding='same', activation='relu', name=name + '\/pool_proj', kernel_regularizer = l2(0.0002))(max_pool_reduce)\n    \n    X = concatenate([conv_1x1, conv_3x3, conv_5x5, max_pool], axis=-1, name=name )\n    \n    return X","d99c98b6":"X_input = Input(shape=(224, 224, 3), name='input')\n\ninput_pad = ZeroPadding2D(padding=(3,3), name='zero_padding')(X_input)\nX = Conv2D(filters = 64, kernel_size = (7,7), strides = (2,2), padding='valid', activation='relu', name='conv_1\/7x7', kernel_regularizer = l2(0.0002))(input_pad)\n\nX = Conv2D(filters = 128, kernel_size = (5,5), strides = (2,2), padding='valid', activation='relu', name='conv_2\/5x5', kernel_regularizer = l2(0.0002))(X)\nX = MaxPooling2D(pool_size = (2,2), strides = (2,2), name='max_pool_1')(X)\n\nX = inception_module(X, filters = [64, 96,128, 16, 32, 32], name='inception_3a')\nX = inception_module(X, filters = [128, 128,192, 32,96, 64], name='inception_3b')\n\nX = AveragePooling2D(pool_size = (7,7), strides = (1,1), name='avg_pool_7x7')(X)\n\nX_flatten = Flatten()(X)\nX = Dense(units =1024, activation='relu',name='fc_1')(X_flatten)\nfc_1_dropout = Dropout(rate=0.3)(X)\n\nX = Dense(1, activation='sigmoid', name='output_layer')(fc_1_dropout)\n\n\nmodel = keras.Model(inputs = X_input, outputs = X, name='GoogleNet')\nmodel.summary()","3a325889":"# learning rate decay\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate = 0.00003,\n                                                        decay_steps = 1000, \n                                                        decay_rate = 0.3)\n\n# compile the model\nmodel.compile(loss='binary_crossentropy',\n             optimizer = Adam(learning_rate = 0.00003),\n             metrics = ['accuracy'])\n\n# calculate train steps and val steps\ntrain_steps = np.ceil(train_num_samples \/ train_batch_size)\nval_steps = np.ceil(val_num_samples \/ val_batch_size)\n\n# train the model\nhistory = model.fit_generator(train_gen,\n                             steps_per_epoch = train_steps,\n                             epochs = 10,\n                             validation_data = val_gen,\n                             validation_steps = val_steps)","79756a52":"# save the model\nmodel.save(\"\/kaggle\/working\/malaria_detection.h5\")\n\n \n# plot training and validation accuracy\nplt.plot(history.history['accuracy'], label='train-accuracy')\nplt.plot(history.history['val_accuracy'], label='val-accuracy')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(loc='upper left')\nplt.show()\n\n# plot training and validation loss\nplt.plot(history.history['loss'], label='train-loss')\nplt.plot(history.history['val_loss'], label='val-loss')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(loc='upper left')\nplt.show()","34be92bc":"model = keras.models.load_model(\"\/kaggle\/working\/malaria_detection.h5\")","208ae8b7":"### Compile, Train and Evaluate the model","e9e1e2ea":"There are total 27560 samples in our data. I will use 20% of the data for the validation set. which means that, 2712 images from each class will be moved to validation directory.","e58bb23f":"## Create InceptionNet (GoogleNet)","b7aa0e4c":"First we will copy all images from '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images' to '\/kaggle\/temp\/train\/' and then we will move 20% images to 'val' directory.","c0ffd298":"### Visualize images generated by the ImageGenerator","2b54b2e8":"## Import necessary libraries","e8c2946a":"## Load Data"}}