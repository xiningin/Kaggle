{"cell_type":{"1bd2cf73":"code","b6d655dc":"code","3359f629":"code","1d8cdec6":"code","b3e0ece8":"code","2fecaa5c":"code","d097ac6c":"code","f66642da":"code","5a976a56":"code","6ee5c91f":"code","d4d3169e":"code","ee0af71f":"code","cf82dd88":"code","4aaacad9":"code","e7d4230d":"code","3da7ae66":"code","94eb0ce6":"code","68e3b35c":"code","c7189f34":"code","d1948422":"code","0ea92414":"code","aa42a3b4":"code","54ab7487":"code","9be4e3c8":"code","34fc020e":"code","7aa2e858":"code","ba98fbc7":"code","ec4810dd":"code","8907c520":"code","f4124f99":"code","3ba58a86":"code","a361d6d4":"markdown","3e15ea29":"markdown","7a21f080":"markdown","4efd7e32":"markdown","f2d23690":"markdown","f0c307da":"markdown","c0ac853e":"markdown","f8a88a47":"markdown","a8e202bb":"markdown","aaae27bd":"markdown"},"source":{"1bd2cf73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b6d655dc":"import pandas as pd\nimport numpy as np\n\n# We can set the category here to predict in the second model\ntarget_category = 'computers_accessories'\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 125)\n\ndef profile_col(data, col):\n    print(\"\\n{} has {:,} unique values (out of {:,} total)\".format(\n        col, data[col].nunique(), data.shape[0]))\n    print(\"Value counts:\\n{}\".format(data[col].value_counts()[:20]))\n","3359f629":"# load data sets\npath = '\/kaggle\/input\/applied-ml-microcourse-ecommerce-recommendation\/'\n\norder_items = pd.read_csv('{}olist_order_items_dataset.csv'.format(path))\norders = pd.read_csv('{}olist_orders_dataset.csv'.format(path))\ncustomers = pd.read_csv('{}olist_customers_dataset.csv'.format(path))\norder_payments = pd.read_csv('{}olist_order_payments_dataset.csv'.format(path))\nsellers = pd.read_csv('{}olist_sellers_dataset.csv'.format(path))\nreviews = pd.read_csv('{}olist_order_reviews_dataset.csv'.format(path))\nproducts = pd.read_csv('{}olist_products_dataset.csv'.format(path))\ntranslation = pd.read_csv('{}product_category_name_translation.csv'.format(path))","1d8cdec6":"print(\"{:,} unique orders\".format(order_items['order_id'].nunique()))\nprint(\"{:,} rows (order items)\".format(order_items['order_id'].count()))\norder_items.head()","b3e0ece8":"print(\"{:,} unique orders\".format(orders['order_id'].nunique()))\norders.head()","2fecaa5c":"print(\"{:,} unique order_id values\".format(orders['order_id'].nunique()))\nprint(\"{:,} unique customer_id values\".format(orders['customer_id'].nunique()))","d097ac6c":"print(\"{:,} unique customers\".format(customers['customer_id'].nunique()))\nprint(\"{:,} unique unique_customer_ids\".format(customers['customer_unique_id'].nunique()))\ncustomers.head()","f66642da":"print(\"{:,} order payment lines\".format(order_payments['order_id'].count()))\norder_payments.head()","5a976a56":"# how many sellers are there?\nprint('{:,} unique sellers'.format(sellers['seller_id'].nunique()))\nsellers.head()","6ee5c91f":"# How many products are there?\nprint('{:,} unique products'.format(products['product_id'].nunique()))\nprint('{:,} unique product categories'.format(products['product_category_name'].nunique()))\nproducts.head()","d4d3169e":"translation.head()","ee0af71f":"reviews.head()","cf82dd88":"print(\"{:,} unique order_id values\".format(reviews['order_id'].nunique()))\nprint(\"{:,} unique review_id values\".format(reviews['review_id'].nunique()))\nprint(\"{:,} rows\".format(reviews['review_id'].count()))\nprint(\"{:,} unique review comments\".format(reviews['review_comment_message'].nunique()))","4aaacad9":"# Merge english category onto products\nproducts = products.merge(translation, on='product_category_name')","e7d4230d":"# create label for whether the order has multiple items\nmulti_items = order_items.groupby('order_id')['order_item_id'].max().to_frame().reset_index()\nmulti_items['label_multi_items'] = np.where(multi_items['order_item_id'] > 1, 1, 0)\n\nmulti_items.head()","3da7ae66":"multi_items.groupby('label_multi_items')['order_id'].count()","94eb0ce6":"# Create feature set at the level of the first order item added\ndata = order_items[order_items['order_item_id'] == 1]","68e3b35c":"# include product category information\ndata = data.merge(products[['product_id', 'product_category_name_english', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty',\n                            'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']],\n                  on='product_id')\n\n# include product category information\ndata = data.merge(multi_items[['order_id', 'label_multi_items']], \n                  on='order_id')\n\n# include order payments information\ndata = data.merge(order_payments[['order_id', 'payment_sequential', \n                                  'payment_type','payment_installments', \n                                  'payment_value']])\n\n# merge customer with order \ncustomer_order = customers[['customer_id', 'customer_zip_code_prefix', 'customer_city','customer_state']].merge(\n    orders[['order_id', 'customer_id']])\n\n# include customer state and seller state (locations) \ndata = data.merge(customer_order, \n                  on='order_id')\ndata = data.merge(sellers[['seller_id', 'seller_zip_code_prefix' ,'seller_city', 'seller_state']], \n                  on='seller_id')","c7189f34":"# Reviews?\ndata_reviews = data.merge(reviews[['order_id', 'review_score']], on='order_id')","d1948422":"print(\"Data without reviews has shape {}\".format(data.shape))\nprint(\"Data with reviews has shape {}\".format(data_reviews.shape))","0ea92414":"data_reviews[['order_id', 'shipping_limit_date']].head().sort_values('order_id')","aa42a3b4":"reviews[reviews['order_id'].isin(data_reviews['order_id'].head())][['order_id', 'review_answer_timestamp']].head().sort_values('order_id')","54ab7487":"data.drop(columns=['order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'payment_sequential'], inplace=True)\ndata.head()","9be4e3c8":"data['label_multi_items'].mean()","34fc020e":"categorical_columns = ['product_category_name_english', 'payment_type', 'payment_installments', 'payment_type']\nfor column in categorical_columns:\n    display(data.groupby(column)['label_multi_items'].mean().to_frame().sort_values('label_multi_items', ascending=False).head(10))","7aa2e858":"data.groupby(column)['label_multi_items'].mean().to_frame().sort_values('label_multi_items', ascending=False)","ba98fbc7":"numeric_columns = data.dtypes[data.dtypes=='float64'].index.values\nfor column in numeric_columns:\n    display(data.groupby('label_multi_items')[column].mean().to_frame())","ec4810dd":"import matplotlib.pyplot as plt\n\ndef plot_churn_hist(column):\n    plt.figure()\n    plt.hist(data[data['label_multi_items'] == 0][column], bins=20)\n    plt.hist(data[data['label_multi_items'] == 1][column], bins=20)\n    plt.title(column)\n\nfor column in ['payment_value', 'product_photos_qty', 'price', 'product_weight_g', 'product_description_lenght', 'freight_value']:\n    plot_churn_hist(column)","8907c520":"features = ['customer_id', 'label_multi_items', 'payment_value', 'product_photos_qty', 'price', 'product_weight_g', 'product_description_lenght', 'freight_value',\n           'product_category_name_english', 'payment_type', 'payment_installments']\n\ndata[features].head()","f4124f99":"data_transformed = pd.get_dummies(data[features].drop(columns='customer_id'), drop_first=True)","3ba58a86":"print('Original data has shape {}'.format(data.shape))\nprint('Transformed data has shape {}'.format(data_transformed.shape))\ndata_transformed.head()","a361d6d4":"Now for the numeric columns","3e15ea29":"## Define the entity level for our feature set and build","7a21f080":"## Transformations for modelling","4efd7e32":"## Define our label to predict which orders have multiple items","f2d23690":"## Feature exploration and analysis","f0c307da":"Including reviews has introduced some duplicates.  We could fix this, but there is a bigger question - would we have this data in model run time?","c0ac853e":"We will only worry about creating one-hot encoded variables for now","f8a88a47":"The data for whether an order has multiple items or not does not yet exist at the order level, so we will have to create this from order_items.","a8e202bb":"Let's start with the categorical variables first.","aaae27bd":"As you might expect, reviews are made after the order has been placed.  We will not include this data.\n\nLastly, we will drop any id and date fields that are not features."}}