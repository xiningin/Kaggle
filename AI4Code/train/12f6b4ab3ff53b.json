{"cell_type":{"0312032a":"code","4ae83377":"code","e40d0f83":"code","d36f2464":"code","b7a303ac":"code","f6268246":"code","fac8dac8":"code","9f91dc3a":"code","496bd101":"code","637e727d":"code","988d0adb":"code","f76939f7":"code","fc3f6626":"code","876f5c61":"code","fbbbeea0":"code","fe953883":"markdown"},"source":{"0312032a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4ae83377":"data = pd.read_csv('..\/input\/movie-metadatacsv\/movie_metadata.csv')\ndata.head()","e40d0f83":"#Useful columns\ndata = data[['movie_title', 'title_year', 'genres', 'language', 'country','color', 'director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name', ]]\ndata.isna().sum()","d36f2464":"data_no_duplicates = data.drop_duplicates()\nprint((data.shape[0] - data_no_duplicates.shape[0]),' Perfect duplicates deleted.')\ndata = data_no_duplicates\ndata_no_duplicates = data.drop_duplicates(subset=['movie_title', 'title_year'])\nprint((data.shape[0] - data_no_duplicates.shape[0]),' duplicates by names')\ndata = data_no_duplicates","b7a303ac":"data['movie_title'] = data['movie_title'].str.strip()","f6268246":"\ndata['title_year'].fillna( value=round(data.title_year.mean()) , inplace=True )\ndata['language'].fillna( value='English' , inplace=True )\ndata['country'].fillna( value='USA' , inplace=True )\ndata['color'].fillna( value='Color' , inplace=True )\nfor col in ['director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name']:\n    data[col].fillna( value='' , inplace=True )\n\ndata.head()","fac8dac8":"data_words = data[['movie_title', 'genres', 'language','country', 'color', 'director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name']]\n\ndef replace_space(val):\n    val = val.str.replace(' ','_')\n    val = val.str.replace('.','')\n    return val\n\ndata_words = data_words.apply(replace_space, axis=1)\ndata_words.head()","9f91dc3a":"data['words'] = (data_words['movie_title'] +\n               ' ' + data_words['genres'].str.replace('|', ' ') +\n               ' ' + data_words['language'] +\n               ' ' + data_words['country'] +\n               ' ' + data_words['color'] +\n               ' ' + data_words['director_name'] +\n               ' ' + data_words['actor_1_name'] +\n               ' ' + data_words['actor_2_name'] +\n               ' ' + data_words['actor_3_name']\n              )\ndata.head()","496bd101":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(data['words'])\ntfidf_matrix.shape","637e727d":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(stop_words='english')\ncv_matrix = cv.fit_transform(data['words'])\ncv_matrix.shape","988d0adb":"from sklearn.metrics.pairwise import linear_kernel\n\ncosine_sim_tfidf = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim_cv = linear_kernel(cv_matrix, cv_matrix)","f76939f7":"indices = pd.Series(data.index, index=data['movie_title'])","fc3f6626":"def get_recommendations(title, cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n    return data['movie_title'].iloc[movie_indices]","876f5c61":"get_recommendations('The Avengers', cosine_sim_tfidf)","fbbbeea0":"get_recommendations('The Avengers', cosine_sim_cv)","fe953883":"## Building the model"}}