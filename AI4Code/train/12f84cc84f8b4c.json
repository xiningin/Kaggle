{"cell_type":{"91c8a026":"code","f8ea7490":"code","ec14b745":"code","2648e958":"code","937a59ee":"code","d357d495":"code","2ded7697":"code","49b8a787":"code","fce109db":"code","8ff5b879":"code","bb38f6b6":"code","edaa46cc":"code","adf29d95":"code","18e50bad":"code","62975a11":"code","e426d5da":"code","a63d8555":"code","2779c07e":"code","7979f8b3":"code","3414e01b":"code","fba0d8f3":"code","f8268589":"code","0f1e09cc":"code","91a175f8":"code","9e45a739":"code","f1ae3484":"code","fc076b6d":"code","a102f58a":"code","7b4241db":"code","7bf7a079":"code","5dca7520":"code","936ac715":"code","abbea1a6":"code","235119ae":"code","b41f638b":"code","027fae5f":"code","0ffc5735":"code","0ab42699":"code","042a8c66":"code","bc0c7097":"code","a0606823":"code","526db39b":"code","1ca0326f":"code","a32542c2":"code","b6f91b63":"code","2a05362d":"code","0684d99d":"markdown","4e6363d7":"markdown","8f1aa5a8":"markdown","50a91d33":"markdown"},"source":{"91c8a026":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f8ea7490":"#Importing the required libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport datetime\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn import metrics","ec14b745":"#Reading the CSV file\nhouse = pd.read_csv(\"\/kaggle\/input\/house-price-prediction\/train.csv\")","2648e958":"house.head()","937a59ee":"#Getting an over view of the data\nhouse.info()","d357d495":"house.describe()","2ded7697":"#Checking % of Null values\nround(100*(house.isnull().sum()\/len(house.index)),2)","49b8a787":"# As per the domain knowledge, mapping the columns.\ndef funct_mapper(x):\n    return x.map({'Typ': 7, \"Min1\": 6, \"Min2\": 5, \"Mod\": 4, \"Maj1\": 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0})\n\ndef fence_mapper(x):\n    return x.map({'GdPrv': 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"None\": 0})\n\ndef rating_mapper(x):\n    return x.map({'Ex': 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"None\": 0})\n\ndef rating_mapper1(x):\n    return x.map({'Gd': 4, \"Av\": 3, \"Mn\": 2, \"No\": 1, \"None\": 0})\n\ndef rating_mapper2(x):\n    return x.map({'GLQ': 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, 'Unf': 1, 'None': 0})\n\ndef hs_mapper(x):\n    return x.map({'Fin': 3, \"RFn\": 2, \"Unf\": 1, \"None\": 0})\n\ndef ls_mapper(x):\n    return x.map({'Reg': 3, \"IR1\": 2, \"IR2\": 1, \"IR3\": 0})\n\ndef landsloper_mapper(x):\n    return x.map({'Gtl': 2, \"Mod\": 1, \"Sev\": 0})\n\n# Applying the function to the columns\nhouse[['LotShape']] = house[['LotShape']].apply(ls_mapper)\nhouse[['LandSlope']] = house[['LandSlope']].apply(landsloper_mapper)\nhouse[['Functional']] = house[['Functional']].apply(funct_mapper)\nhouse[['Fence']] = house[['Fence']].apply(fence_mapper)\nhouse[['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']] = house[['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']].apply(rating_mapper)\nhouse[['BsmtExposure']] = house[['BsmtExposure']].apply(rating_mapper1)\nhouse[['BsmtFinType1', 'BsmtFinType2']] = house[['BsmtFinType1', 'BsmtFinType2']].apply(rating_mapper2)\nhouse[['GarageFinish']] = house[['GarageFinish']].apply(hs_mapper)","fce109db":"#We see that there are a lot of null values here. But as per the domain knowledge these are not actually null values.\n#Hence will replace NaN's instead of dropping them.\n\nhouse['Alley'].fillna('No Alley', inplace=True)\nhouse['BsmtQual'].fillna('No Basement', inplace=True)\nhouse['BsmtCond'].fillna('No Basement', inplace=True)\nhouse['BsmtExposure'].fillna('No Basement', inplace=True)\nhouse['BsmtFinType1'].fillna('No Basement', inplace=True)\nhouse['BsmtFinType2'].fillna('No Basement', inplace=True)\nhouse['FireplaceQu'].fillna('No Fireplace', inplace=True)\nhouse['GarageType'].fillna('No Garage', inplace=True)\nhouse['GarageFinish'].fillna('No Garage', inplace=True)\nhouse['GarageQual'].fillna('No Garage', inplace=True)\nhouse['GarageCond'].fillna('No Garage', inplace=True)\nhouse['PoolQC'].fillna('No Pool', inplace=True)\nhouse['Fence'].fillna('No Fence', inplace=True)\nhouse['MiscFeature'].fillna('None', inplace=True)\nhouse['GarageYrBlt'].fillna(2019, inplace=True)","8ff5b879":"#Converting the following to number of years\nhouse['YearBuilt'] = 2019 - house['YearBuilt']\nhouse['YearRemodAdd'] = 2019 - house['YearRemodAdd']\nhouse['GarageYrBlt'] = 2019 - house['GarageYrBlt']\nhouse['YrSold'] = 2019 - house['YrSold']","bb38f6b6":"#Checking for null values again\nround(100*(house.isnull().sum()\/len(house.index)),2)","edaa46cc":"# Filling mean value in LotFrontage where ever there are NaN values.\n\nhouse['LotFrontage'].fillna((house['LotFrontage'].mean()), inplace = True)\n\n# Removing rows where ever MasVnrType,MasVnrArea,Electrical is NaN\nhouse = house[pd.notnull(house['MasVnrType'])]\nhouse = house[pd.notnull(house['MasVnrArea'])]\nhouse =house[pd.notnull(house['Electrical'])]","adf29d95":"#Now the null values are cleaned.\nround(100*(house.isnull().sum()\/len(house.index)),2)","18e50bad":"# Seperating the Numeric columns from the data\nhouse_numeric = house.select_dtypes(include=['float64', 'int64'])\nhouse_numeric.columns","62975a11":"#Checking for corelation\ncor = house_numeric.corr()\ncor","e426d5da":"# Seperating the Categorical columns from the data\nhouse_categorical = house.select_dtypes(include=['object'])\nhouse_categorical.columns","a63d8555":"# Convert into dummies\nhouse_dummies = pd.get_dummies(house_categorical, drop_first=True)\nhouse_dummies.head()","2779c07e":"#Dropping the columns for which we have dummy values.\nhouse = house.drop(list(house_categorical.columns), axis=1)\nhouse.columns","7979f8b3":"house= pd.concat([house, house_dummies], axis=1)","3414e01b":"house.columns","fba0d8f3":"house.head()","f8268589":"house1= house.drop([\"Id\", \"SalePrice\"], axis=1)","0f1e09cc":"house1","91a175f8":"from sklearn.preprocessing import scale\ncols = house1.columns\nhouse1 = pd.DataFrame(scale(house1))\nhouse1.columns = cols","9e45a739":"house1.head()","f1ae3484":"# Assigning X and y where X are the independent variables and y is the dependent variable.\nX = house1\ny = house[\"SalePrice\"].values","fc076b6d":"sns.distplot(house[\"SalePrice\"])","a102f58a":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)","7b4241db":"# Instantiate\nlm = LinearRegression()\n\n# Fit a line\nlm.fit(X_train, y_train)","7bf7a079":"from sklearn.feature_selection import RFE\n\nlm = LinearRegression()\nrfe1 = RFE(lm, 50)\n\n# Fit with 15 features\nrfe1.fit(X_train, y_train)\n\n# Print the boolean results\nprint(rfe1.support_)           \nprint(rfe1.ranking_)","5dca7520":"# list of alphas to tune\nlist_alpha = [0.0001,0.001,0.01,0.1, 0.5, 1.0, 5.0, 20, \n 40, 70, 100, 150, 200, 250, 300, 350, 400, 450, 500, \n 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 2000]\nparams = {'alpha': list_alpha}\n\nridge = Ridge()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train, y_train)","936ac715":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results = cv_results[cv_results['param_alpha']<= 1000]\ncv_results.head()","abbea1a6":"cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n\n# plotting\nplt.figure(figsize=(10,5))\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","235119ae":"model_cv.best_params_","b41f638b":"alpha = 350\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_","027fae5f":"ridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\n\npred = ridge.predict(X_test)\nmse = np.mean((pred - y_test)**2)\nmse","0ffc5735":"ridge.score(X_test,y_test)","0ab42699":"from sklearn import metrics\ny_train_pred = ridge.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","042a8c66":"lasso = Lasso()\n\n# cross validation\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","bc0c7097":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results.head()","a0606823":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.figure(figsize=(10,5))\n\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('Alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","526db39b":"model_cv.best_params_","1ca0326f":"alpha = 400\n\nlasso = Lasso(alpha=alpha)\n        \nlasso.fit(X_train, y_train)","a32542c2":"lasso.coef_","b6f91b63":"lasso.score(X_test,y_test)","2a05362d":"from sklearn import metrics\ny_train_pred = lasso.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","0684d99d":"# Lasso Regression","4e6363d7":"# Ridge Regression","8f1aa5a8":"# Data Preparation","50a91d33":"# Data Cleaning and Mapping "}}