{"cell_type":{"3865f4e7":"code","5412364f":"code","e7f4d42c":"code","0a0fb477":"code","3ff32cd5":"code","b50f6fbb":"code","45f52e27":"code","1cb46966":"code","ac8b7ce8":"code","98b4ea40":"code","7a2e5bb3":"code","87b37e7d":"code","9fdb43b2":"code","54b9a1be":"code","c2aa09e5":"code","4da95be8":"code","f717bbec":"code","369bbc17":"code","891049a9":"code","d62980d5":"code","60c0cc94":"code","0c86d64d":"code","18132f4c":"code","400bfc9b":"code","ce9eab81":"markdown","4c14194e":"markdown","3e070674":"markdown","7907d708":"markdown","ca99441b":"markdown","a8016e17":"markdown","b842834a":"markdown","cdfa1365":"markdown","52c8f682":"markdown","990e9221":"markdown","4bc783bf":"markdown","43051fc2":"markdown","7efd12df":"markdown","1ae53aed":"markdown","91179283":"markdown","24aa70ec":"markdown","c60dda2c":"markdown","78b22f74":"markdown","4b67510c":"markdown","60d4beb4":"markdown","c6f69f2c":"markdown","fed85467":"markdown","2c2f2e73":"markdown"},"source":{"3865f4e7":"# Helper libraries\nimport tensorflow\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2\nimport os\n%matplotlib inline\nprint(tensorflow.__version__)","5412364f":"train_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntrain_df['id_code'] = train_df['id_code'].apply(lambda x:x+'.png')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype(str)\ntest_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\ntest_df['id_code'] = test_df['id_code'].apply(lambda x:x+'.png')\n\nnum_classes = train_df['diagnosis'].nunique()\ndiag_text = ['Normal', 'Mild', 'Moderate', 'Severe', 'Proliferative']","e7f4d42c":"def display_raw_images(df, columns = 4, rows = 3):\n    fig=plt.figure(figsize = (5 * columns, 4 * rows))\n    for i in range(columns * rows):\n        image_name = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_name}')[...,[2, 1, 0]]\n        fig.add_subplot(rows, columns, i + 1)\n        plt.title(diag_text[int(image_id)])\n        plt.imshow(img)\n    plt.tight_layout()\n\ndisplay_raw_images(train_df)","0a0fb477":"unique, counts = np.unique(train_df['diagnosis'], return_counts=True)\nplt.bar(unique, counts)\nplt.title('Class Frequency')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.show()","3ff32cd5":"from sklearn.utils import class_weight\n\nsklearn_class_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(train_df['diagnosis']), \n                train_df['diagnosis'])\n\nprint(sklearn_class_weights)","b50f6fbb":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import DenseNet121, ResNet50, InceptionV3, Xception\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam \n\ndef create_resnet50_model(input_shape, n_out):\n    base_model = ResNet50(weights = None,\n                          include_top = False,\n                          input_shape = input_shape)\n    \n    base_model.load_weights('..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(Dropout(0.5))    \n    model.add(Dense(n_out, activation = 'sigmoid'))\n    return model\n\ndef create_inception_v3_model(input_shape, n_out):\n    base_model = InceptionV3(weights = None,\n                             include_top = False,\n                             input_shape = input_shape)\n    base_model.load_weights('..\/input\/keras-pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(Dropout(0.5))    \n    model.add(Dense(n_out, activation = 'sigmoid'))\n    return model\n\ndef create_xception_model(input_shape, n_out):\n    base_model = Xception(weights = None,\n                             include_top = False,\n                             input_shape = input_shape)\n    base_model.load_weights('..\/input\/keras-pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(Dropout(0.5))    \n    model.add(Dense(n_out, activation = 'sigmoid'))\n    return model\n\ndef create_densenet121_model(input_shape, n_out):\n    base_model = DenseNet121(weights = None,\n                             include_top = False,\n                             input_shape = input_shape)\n    base_model.load_weights('..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5')\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(Dropout(0.5))    \n    model.add(Dense(n_out, activation = 'sigmoid'))\n    return model","45f52e27":"#IMAGE_HEIGHT = 224\n#IMAGE_WIDTH = 224\n#model = create_resnet50_model(input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3), n_out = num_classes)\n#model = create_densenet121_model(input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3), n_out = num_classes)\n\nIMAGE_HEIGHT = 299\nIMAGE_WIDTH = 299\n#model = create_inception_v3_model(input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3), n_out = num_classes)\nmodel = create_xception_model(input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3), n_out = num_classes)\n\nmodel.summary()","1cb46966":"PRETRAINED_MODEL = '..\/input\/pretrained_blindness_detector\/blindness_detector.h5'\n\nif (os.path.exists(PRETRAINED_MODEL)):\n  print('Restoring model from ' + PRETRAINED_MODEL)\n  model.load_weights(PRETRAINED_MODEL)\nelse:\n  print('No pretrained model found. Using fresh model.')\n\ncurrent_epoch = 0","ac8b7ce8":"from tqdm import tqdm_notebook as tqdm\n\ndef crop_image_from_gray(img, tol = 7):\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1 = img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2 = img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3 = img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis = -1)\n        return img\n\ndef preprocess_image(image_path, sigmaX = 10):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX), -4, 128)        \n    return image\n\nprint(\"Preprocessing training images...\")\nx_train = np.empty((train_df.shape[0], IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype = np.uint8)\nfor i, image_id in enumerate(tqdm(train_df['id_code'])):\n    x_train[i, :, :, :] = preprocess_image(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_id}')","98b4ea40":"def display_preprocessed_images(df, columns = 4, rows = 3):\n    fig=plt.figure(figsize = (5 * columns, 4 * rows))\n    for i in range(columns * rows):\n        image_name = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = x_train[i]\n        fig.add_subplot(rows, columns, i + 1)\n        plt.title(diag_text[int(image_id)])\n        plt.imshow(img)\n    plt.tight_layout()\n\ndisplay_preprocessed_images(train_df)","7a2e5bb3":"y_train = pd.get_dummies(train_df['diagnosis']).values\ny_train_multi = np.empty(y_train.shape, dtype = y_train.dtype)\ny_train_multi[:, 4] = y_train[:, 4]\n\nfor i in range(3, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i + 1])","87b37e7d":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train_multi, \n    test_size = 0.20, \n    random_state = 2006\n)","9fdb43b2":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DATA_ROOT = '..\/input\/aptos2019-blindness-detection\/train_images'\nTEST_DATA_ROOT  = '..\/input\/aptos2019-blindness-detection\/test_images'\n\nBATCH_SIZE = 16\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 360, \n    horizontal_flip = True, \n#    vertical_flip = True,\n    zoom_range = [0.99, 1.01], \n    width_shift_range = 0.01,\n    height_shift_range = 0.01)\n\ntrain_generator = train_datagen.flow(\n    x_train, \n    y_train,\n    batch_size = BATCH_SIZE, \n    shuffle = True)","54b9a1be":"WARMUP_EPOCHS = 2\nWARMUP_LEARNING_RATE = 1e-3\n\nfor layer in model.layers:\n    layer.trainable = False\n\nfor i in range(-5, 0):\n    model.layers[i].trainable = True\n\nmodel.compile(optimizer = Adam(lr = WARMUP_LEARNING_RATE),\n              loss = 'binary_crossentropy',  \n              metrics = ['accuracy'])\n\nwarmup_history = model.fit_generator(generator = train_generator,\n#                              class_weight = sklearn_class_weights,\n                              steps_per_epoch = train_generator.n \/\/ train_generator.batch_size,\n                              validation_data = (x_val, y_val),\n                              epochs = WARMUP_EPOCHS,\n                              use_multiprocessing = True,\n                              workers = 4,                                     \n                              verbose = 1).history","c2aa09e5":"FINETUNING_EPOCHS = 20\nFINETUNING_LEARNING_RATE = 1e-4\n\nfor layer in model.layers:\n    layer.trainable = True\n\nmodel.compile(optimizer = Adam(lr = FINETUNING_LEARNING_RATE), \n              loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\ncheckpoint = ModelCheckpoint(\n    'blindness_detector_best.h5', \n    monitor = 'val_acc', \n    mode = 'max', \n    save_best_only = True, \n    save_weights_only = True,\n    verbose = 1)\n\nrlrop = ReduceLROnPlateau(\n    monitor = 'val_loss', \n    mode = 'min', \n    patience = 3, \n    factor = 0.5, \n    min_lr = 1e-6, \n    verbose = 1)\n\nstopping = EarlyStopping(\n    monitor = 'val_acc', \n    mode = 'max', \n    patience = 8, \n    restore_best_weights = True, \n    verbose = 1)\n\nfinetune_history = model.fit_generator(generator = train_generator,\n#                              class_weight = sklearn_class_weights,\n                              steps_per_epoch = train_generator.n \/\/ train_generator.batch_size,\n                              validation_data = (x_val, y_val),\n                              epochs = FINETUNING_EPOCHS,\n                              callbacks = [checkpoint, rlrop, stopping],         \n                              use_multiprocessing = True,\n                              workers = 4,\n                              verbose = 1).history","4da95be8":"training_accuracy = warmup_history['acc'] + finetune_history['acc']\nvalidation_accuracy = warmup_history['val_acc'] + finetune_history['val_acc']\ntraining_loss = warmup_history['loss'] + finetune_history['loss']\nvalidation_loss = warmup_history['val_loss'] + finetune_history['val_loss']\n\nplt.figure(figsize = (8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(training_accuracy, label = 'Training Accuracy')\nplt.plot(validation_accuracy, label = 'Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()), 1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(training_loss, label = 'Training Loss')\nplt.plot(validation_loss, label = 'Validation Loss')\nplt.legend(loc = 'upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0, 1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","f717bbec":"validation_predictions_raw = model.predict(x_val)\nvalidation_predictions = validation_predictions_raw > 0.5\nvalidation_predictions = validation_predictions.astype(int).sum(axis=1) - 1\nvalidation_truth = y_val.sum(axis=1) - 1","369bbc17":"from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n\ndef plot_confusion_matrix(cm, target_names, title = 'Confusion matrix', cmap = plt.cm.Blues):\n    plt.grid(False)\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(target_names))\n    plt.xticks(tick_marks, target_names, rotation = 90)\n    plt.yticks(tick_marks, target_names)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\nnp.set_printoptions(precision = 2)\ncm = confusion_matrix(validation_truth, validation_predictions)\ncm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\nplot_confusion_matrix(cm = cm, target_names = diag_text)\nplt.show()\n\nprint('Confusion Matrix')\nprint(cm)\n\nprint('Classification Report')\nprint(classification_report(validation_truth, validation_predictions, target_names = diag_text))\n\nprint(\"Validation Cohen Kappa score: %.3f\" % cohen_kappa_score(validation_predictions, validation_truth, weights = 'quadratic'))","891049a9":"def plot_image(prediction_array, predicted_label, true_label, img):\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img, cmap = plt.cm.binary)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(diag_text[predicted_label], 100 * np.max(prediction_array), diag_text[true_label]), color = color)\n\ndef plot_prediction(prediction_array, predicted_label, true_label):\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(5), prediction_array, color = \"#777777\")\n    plt.ylim([0, 1]) \n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')\n  \n# Plot some validation images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nplt.figure(figsize=(24, 6))\nnum_cols = 4\nnum_rows = 4\nfor i in range(num_rows * num_cols):\n    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n    plot_image(validation_predictions_raw[i], validation_predictions[i], validation_truth[i], x_val[i])\n    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n    plot_prediction(validation_predictions_raw[i], validation_predictions[i], validation_truth[i])\nplt.show() ","d62980d5":"x_train = None\nx_val = None\nprint(\"Preprocessing test images...\")\n!mkdir 'test_images_preprocessed\/'\nfor i, image_id in enumerate(tqdm(test_df['id_code'])):\n    image = preprocess_image(f'..\/input\/aptos2019-blindness-detection\/test_images\/{image_id}')    \n    cv2.imwrite(f'.\/test_images_preprocessed\/{image_id}', image)\n    ","60c0cc94":"test_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_df,\n    directory = \".\/test_images_preprocessed\/\",\n    x_col = \"id_code\",\n    target_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size = 1,\n    shuffle = False,\n    class_mode = None)\n\ny_test = model.predict_generator(test_generator) > 0.5\ny_test = y_test.astype(int).sum(axis = 1) - 1","0c86d64d":"unique, counts = np.unique(y_test, return_counts = True)\nplt.bar(unique, counts)\n\nunique, counts = np.unique(validation_truth, return_counts = True)\nplt.bar(unique, counts)\n\nplt.title('Class Frequency Training and Predictions')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.show()","18132f4c":"submission_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\nsubmission_df['diagnosis'] = y_test\nsubmission_df.to_csv('submission.csv', index = False)","400bfc9b":"!rm -rf \/kaggle\/working\/test_images_preprocessed\/","ce9eab81":"#### Crop and improve lighting condition using Ben Graham's preprocessing method\nSee: https:\/\/www.kaggle.com\/ratthachat\/aptos-updated-preprocessing-ben-s-cropping","4c14194e":"### Plot some metrics","3e070674":"### Change target to a multi-label problem so a class encompasses all the classes before it.\nsee: https:\/\/arxiv.org\/abs\/0704.1028","7907d708":"### Calculate class weights to help with training on the unbalanced data set.[](http:\/\/) ","ca99441b":"## Make some predictions ","a8016e17":"## Train the clasifier head","b842834a":"### Graph out the class frequency","cdfa1365":"## Read in the training and test data","52c8f682":"## Load a model","990e9221":"## Look at some predictions from the validation set","4bc783bf":"### Get validation predictions from the final model","43051fc2":"## Fine-tune the whole model","7efd12df":"## Plot learning curves","1ae53aed":"### Preprocess the test images","91179283":"## Evaluate the model","24aa70ec":"### Split into training and validation","c60dda2c":"<h2><center>Detect diabetic retinopathy to stop blindness before it's too late<\/center><\/h2>\n<center><img src=\"https:\/\/raw.githubusercontent.com\/dimitreOliveira\/MachineLearning\/master\/Kaggle\/APTOS%202019%20Blindness%20Detection\/aux_img.png\"><\/center>\n##### Image source: http:\/\/cceyemd.com\/diabetes-and-eye-exams\/","78b22f74":"## Preprocess the data","4b67510c":"### Check out the class distribution in the predicitons compared to the traing data","60d4beb4":"### Look at some raw images","c6f69f2c":"### Look at some preprocessed images","fed85467":"## Setup training data generator with augmentation","2c2f2e73":"## Generate a submission"}}