{"cell_type":{"4d1dc3f6":"code","5020f3fd":"code","91713744":"code","40ea0def":"code","decf1ad7":"code","8a07542a":"code","86ee1e8c":"code","66b251f4":"code","b9fdce1c":"code","fc2cb045":"code","7906b4dd":"code","b214762e":"code","dafa270d":"code","59b004da":"code","cb634b9f":"code","42b5c372":"code","5b39983f":"code","08239b11":"code","902af4f1":"code","da6d13c0":"code","fc9f5fd1":"code","bdc28417":"code","d42058d2":"code","f37f0e15":"code","4e11ac71":"code","eee53fc9":"code","3f6430f0":"code","8a275f38":"code","335cf5b9":"code","45c3925d":"code","9572b2e5":"code","4805cea3":"code","aac15581":"code","1d595501":"code","5ce1f8d1":"code","f9f66afb":"code","bc3cd4ec":"code","f90d97f4":"code","e15b2aca":"code","753de3f9":"code","8ea0049c":"code","c3488014":"code","da3f0ae6":"markdown","de5ce00f":"markdown","5504189f":"markdown","be6b133f":"markdown","40fad6f8":"markdown","bd08eef0":"markdown","47eaf147":"markdown","79c5f6b7":"markdown","50e3143c":"markdown","44a69363":"markdown","411bddb2":"markdown","b11c8826":"markdown","0b7a0407":"markdown","3a7d12d3":"markdown"},"source":{"4d1dc3f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5020f3fd":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow import keras\ntfds.disable_progress_bar()\n\nfrom keras.preprocessing import image","91713744":"train_labels = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\ntest_labels = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv')\ntrain_labels.columns","40ea0def":"from keras.preprocessing.image import ImageDataGenerator","decf1ad7":"train_dir = \"..\/input\/dog-breed-identification\/train\"\ntest_dir = \"..\/input\/dog-breed-identification\/test\"","8a07542a":"def append_ext(fn):\n    return fn + '.jpg'\n\ntrain_labels['id'] = train_labels['id'].apply(append_ext)\ntest_labels['id'] = test_labels['id'].apply(append_ext)","86ee1e8c":"import os\n\nsrc_path = \"..\/input\/dog-breed-identification\/train\"\nsub_class = os.listdir(src_path)\n\nfig = plt.figure(figsize = (10, 5))\nfor e in range(len(sub_class[:8])):\n    plt.subplot(2, 4, e+1)\n    img = plt.imread(os.path.join(src_path, sub_class[e]))\n    plt.imshow(img, cmap = plt.get_cmap('gray'))","66b251f4":"batch_size = 32\nimg_size = 224","b9fdce1c":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  horizontal_flip = True,\n                                  validation_split = 0.1\n                                  )","fc2cb045":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_labels,\n    directory = train_dir,\n    x_col = \"id\",\n    y_col = \"breed\",\n    subset = \"training\",\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = True,\n    class_mode = \"categorical\",\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","7906b4dd":"x, y = next(train_generator)","b214762e":"print(type(x))\nprint(x.shape)\nprint(y.shape)","dafa270d":"from mpl_toolkits.axes_grid1 import ImageGrid\n\ndef show_grid(image_list, nrows, ncols, figsize = (10,10), showaxis='off'):\n    if type(image_list) is not list:\n        if(image_list.shape[-1] == 1):\n            image_list = [image_list[i,:,:,0] for i in range(image_list.shape[0])]\n            \n        elif(image_list.shape[-1]==3):\n            image_list = [image_list[i,:,:,:] for i in range(image_list.shape[0])]\n            \n    fig = plt.figure(None, figsize,frameon=False)\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(nrows, ncols),  # creates 2x2 grid of axes\n                     axes_pad=0.3,  # pad between axes in inch.\n                     share_all=True,\n                     )\n    \n    for i in range(nrows*ncols):\n        ax = grid[i]\n        ax.imshow(image_list[i],cmap='Greys_r')  # The AxesGrid object work as a list of axes.\n        ax.axis('off')","59b004da":"show_grid(x, 4, 8, figsize=(25, 25))","cb634b9f":"val_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_labels,\n    directory = train_dir,\n    x_col = \"id\",\n    y_col = \"breed\",\n    subset = \"validation\",\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = True,\n    class_mode = \"categorical\",\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","42b5c372":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_labels,\n    directory = test_dir,\n    x_col = \"id\",\n    y_col = None,\n    batch_size = batch_size,\n    seed = 42,\n    shuffle = False,\n    class_mode = None,\n    target_size = (img_size, img_size),\n    color_mode = \"rgb\"\n)","5b39983f":"model = keras.Sequential([\n    keras.layers.AveragePooling2D(6, 3, input_shape=(224, 224, 3)),\n#     keras.layers.Conv2D(64, 3, activation='relu'),\n#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),\n#     keras.layers.MaxPool2D(2, 2),\n#     keras.layers.Dropout(0.5),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(120, activation='softmax')\n])\n\nmodel.compile(optimizer=keras.optimizers.SGD(learning_rate = 0.01),\n              loss=keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n\nmodel.summary()","08239b11":"early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=5)","902af4f1":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VAL = val_generator.n\/\/val_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size\n\nmodel.fit(train_generator,\n          steps_per_epoch=STEP_SIZE_TRAIN,\n          validation_data=val_generator,\n          validation_steps=STEP_SIZE_VAL,\n          epochs=20,\n          callbacks = [early])","da6d13c0":"import time\n\nstart = time.time()\nscore = model.evaluate(val_generator, batch_size = 32)\nend = time.time()\n\nprint(\"Accuracy: {:.2f}%\".format(score[1] * 100)) \nprint(\"Loss: \",score[0])\nprint(\"Time per test instance: \", (end-start)\/1022)      #no. of val images","fc9f5fd1":"Y_pred = model.predict(val_generator)\ny_pred = np.argmax(Y_pred, axis=1)","bdc28417":"from sklearn.metrics import f1_score\n\nprint(\"Micro F1: \", f1_score(val_generator.classes,y_pred,average='micro'))\nprint(\"Macro F1: \", f1_score(val_generator.classes,y_pred,average='macro'))\nprint(\"Weighted F1: \", f1_score(val_generator.classes,y_pred,average='weighted'))","d42058d2":"pred = model.predict(test_generator)","f37f0e15":"df_submission = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/sample_submission.csv')\ndf_submission.head()","4e11ac71":"import re\n\nfile_list = test_generator.filenames\nid_list = []\nfor name in file_list:\n    m = re.sub('test\/', '', name)\n    m = re.sub('.jpg', '', m)\n    id_list.append(m)","eee53fc9":"df_submission['id'] = id_list\ndf_submission.iloc[:,1:] = pred\ndf_submission.head()","3f6430f0":"final_sub = df_submission.set_index('id')\nfinal_sub.to_csv('Submission.csv')","8a275f38":"pip install -U keras-tuner","335cf5b9":"from kerastuner.tuners import RandomSearch\n\ndef build_model(hp):\n    model = keras.Sequential()\n\n    model.add(keras.layers.AveragePooling2D(6, 3, input_shape=(224, 224, 3)))\n\n#     model.add(keras.layers.MaxPool2D(2, 2))\n   \n    model.add(keras.layers.Flatten())\n\n    #hp.Choice allows the model to try out the different hyperparams to pick out the best performing one\n    model.add(keras.layers.Dense(hp.Choice(\"Dense layer\", [64, 128, 256, 512, 1024]), activation='relu'))\n    model.add(keras.layers.Dropout(hp.Choice(\"Dropout\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6])))\n    model.add(keras.layers.Dense(120, activation='softmax'))\n\n    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    \n    model.compile(optimizer=keras.optimizers.SGD(learning_rate = hp_lr),\n              loss = keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n    \n    return model","45c3925d":"tuner = RandomSearch(\n    build_model,\n    objective = 'val_accuracy',\n    max_trials = 32,\n    directory = '.\/multi_conv'\n)","9572b2e5":"early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=3)","4805cea3":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VAL = val_generator.n\/\/val_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size\n\ntuner.search(train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            validation_data=val_generator,\n            validation_steps=STEP_SIZE_VAL,\n            epochs=20,\n            callbacks=[early])","aac15581":"best_model = tuner.get_best_models()[0]","1d595501":"best_model.evaluate(X_test, y_test)","5ce1f8d1":"best_model.summary()","f9f66afb":"tuner.results_summary()","bc3cd4ec":"best_model.save('.\/best_model')","f90d97f4":"loaded_model = keras.models.load_model('.\/best_model')","e15b2aca":"loaded_model.evaluate(X_test, y_test)","753de3f9":"#RGB image\nrgb_images = np.array([example['image'].numpy() for example in ds_train.take(1)])\nrgb_image = rgb_images[0]\n\nimage = train_images[0].reshape(300, 300)\n\nplt.imshow(rgb_image)\nrgb_image.shape\n\n#Greyscale image\n# image = train_images[0].reshape(300, 300)\n\n# plt.imshow(train_images[0], cmap='Greys_r')","8ea0049c":"import imageio\n\nim = imageio.imread('')\n\nprint(type(im))\n\nim_np = np.asarray(im)\n\nprint(im_np.shape)","c3488014":"# import glob\n\n# # First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername, imagename, objectname and labels\n# detail = sorted(glob.glob(\"..\/input\/dog-breed-identification\/train\/*\"))\n# Folder_Name = [str(i.split(\"in\/\")[0]) + \"in\" for i in detail]\n# Image_Name = [str(i.split(\"\/\")[4]) for i in detail]\n# Train_Labels = np.array((pd.read_csv('..\/input\/dog-breed-identification\/labels.csv'))[\"breed\"])\n\n# # Defining dataframe and saving all the extracted information in that dataframe\n# train_detail = pd.DataFrame() \n# train_detail[\"Folder Name\"] = Folder_Name\n# train_detail[\"Image Name\"] = Image_Name\n# train_detail[\"Train Labels\"] = Train_Labels\n\n\n# # Analying the train data detail\n# print(\"\\nNumber of images in training set = \"+str(len(detail)))\n# print(train_detail.columns)\n# train_detail.head()","da3f0ae6":"## Convert PNG\/JPG Imgaes to Numpy Format","de5ce00f":"### For Submission","5504189f":"## Plot Image from Numpy Array","be6b133f":"### Validation Data","40fad6f8":"## Hyperparameter Tuning","bd08eef0":"## Data Preparation","47eaf147":"## Examples","79c5f6b7":"## Training the CNN","50e3143c":"## Installation","44a69363":"## Save & Load Models","411bddb2":"## Dataset","b11c8826":"### Test Data","0b7a0407":"## Import Necessary Libraries","3a7d12d3":"### Plot Augmented Images"}}