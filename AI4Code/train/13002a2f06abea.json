{"cell_type":{"2b79aae2":"code","42308e8b":"code","99289513":"code","05cf0f59":"code","fe851ff4":"code","f34bdb36":"code","148c3bb5":"code","aaa7f22c":"code","205e1358":"code","a9d3911a":"code","a7744655":"code","ee9886e1":"code","68aae30f":"code","cf67f5e2":"code","e77f1993":"code","ac979d5c":"code","a8cce63b":"code","8ef2ece4":"code","f810be8c":"code","e105bb53":"code","7d9b77d6":"code","35e28653":"code","5f8ecea7":"code","98f1ea61":"code","fa5f80c1":"code","68d399e6":"code","6c28b268":"code","a7324f36":"code","4858524d":"code","3f9bdfe0":"code","06a581f0":"code","6f8733d6":"code","f320df17":"code","c0262d73":"code","7187b546":"code","8f6b9dc0":"code","79a10efb":"code","41907d6a":"code","ed37dc2f":"code","84e262e3":"code","2069c3c2":"code","c2248cfc":"code","19387458":"code","84f17ca5":"code","c4b0af9d":"code","78d728b6":"code","75d7cd27":"code","7a3df182":"code","cd146212":"code","a9dc789f":"code","77c8df03":"code","cb145eb7":"markdown","d50f37ad":"markdown","9c7cbb00":"markdown","03c5646c":"markdown","e4f1d1c3":"markdown","a3559b2d":"markdown","6cae6140":"markdown","f02b3061":"markdown","f4676303":"markdown","052e7eef":"markdown","e19ef7a6":"markdown","18bad941":"markdown","8082d0e2":"markdown","a16b91a2":"markdown","c5ace6dd":"markdown","dc21ee6f":"markdown","5873c680":"markdown","83126da0":"markdown","789422bb":"markdown","7483ad27":"markdown","772e2c1d":"markdown"},"source":{"2b79aae2":"# standard libs\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport json\n\n# plotting libs\nimport seaborn as sns\n\n# geospatial libs\nfrom mpl_toolkits.basemap import Basemap\nfrom shapely.geometry import Polygon\nimport geopandas as gpd\nimport folium\nimport plotly.graph_objects as go\nimport plotly_express as px\n\n# set in line plotly \nfrom plotly.offline import init_notebook_mode;\ninit_notebook_mode(connected=True)","42308e8b":"# import corporate response data\ncc_df = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Corporations\/Corporations Responses\/Climate Change\/2020_Full_Climate_Change_Dataset.csv',dtype={\"Response Answer\":\"string\",\"comments\": \"string\"})\nws_df = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Corporations\/Corporations Responses\/Water Security\/2020_Full_Water_Security_Dataset.csv',dtype={\"comments\": \"string\"})\ncc_df = pd.concat([cc_df, ws_df],ignore_index=True)\ncc_df.rename(columns = {'question_unique_reference':'Question Name','response_value':'Response Answer'}, inplace = True)\n\n# import city responses\ncity_df = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Responses\/2020_Full_Cities_Dataset.csv',dtype={\"Response Answer\":\"string\",\"comments\": \"string\"})\ncity_df = city_df.fillna('Do not know')","99289513":"qs_city = city_df['Question Name'].unique()\nqs = qs_city","05cf0f59":"def get_q(df = city_df, keyword = \"\"):\n    qs = df['Question Name'].unique()\n    matching = [(i,s) for i,s in enumerate(qs) if keyword in s]\n    return matching\n\ndef get_ans(df, qnum):\n    qs = df['Question Name'].unique()\n    return df[df[\"Question Name\"] == qs[qnum]][\"Response Answer\"]\n\ndef combine_ans(df, phrase):\n    sep = []\n    if type(phrase) == list:\n        # set of answers that contain all phrases\n        for p in phrase:\n            tmp = [i[0] for i in get_q(df,p)]\n            sep.append(tmp)\n        q_num = set.intersection(*map(set,sep))\n            \n    else:\n        q_num = [i[0] for i in get_q(df,phrase)]\n        \n    ans_list = []\n    for q in q_num:\n        ans_list.append(' '.join([i for i in list(get_ans(df, q).unique()) if type(i) == str]))\n\n    all_ans = ' '.join([str(elem) for elem in ans_list]) \n    all_ans = all_ans.replace(\"Other, please specify:\",\" \")\n    return all_ans\n\ndef generate_wraptxt(txt, linewidth=40): \n    tit = wrap(txt, width=linewidth)\n    return '\\n'.join(tit)","fe851ff4":"q1='Does your city incorporate sustainability goals and targets (e.g. GHG reductions) into the master planning for the city?'\nq2 = 'Does your city collaborate in partnership with businesses in your city on sustainability projects?'","f34bdb36":"pref_color = [ '#9FF781','#CEF6D8',  '#F7819F', '#F5A9BC','#E6E6E6']\ndds = [city_df.groupby('Question Name').get_group(q1)[\"Response Answer\"].value_counts(),\\\n      city_df.groupby('Question Name').get_group(q2)[\"Response Answer\"].value_counts()]\nq = [q1, q2]\n\nfor i,dd in enumerate(dds):\n    xx = list(dd.keys())\n\n    # matplotlib general settings\n    fig, ax = plt.subplots(figsize=(20,1))\n    plt.title(q[i], fontsize=18, loc='left')\n    ax.get_xaxis().set_visible(False)\n    ax.tick_params(axis='y', labelsize=16, labelcolor='grey')  \n    ax.set_facecolor('white')\n    ax.axis('off')\n    # Draw each bar and text separately with appropriate offset\n    bar_start = 0\n    cnts = [dd[_]\/np.sum(list(dd.values)) for _ in xx]\n\n    for i in range(len(dd)):\n        ax.barh(y=['All Respondents'], width=cnts[i], height=0.1, left=bar_start, color=pref_color[i])\n        plt.text(bar_start + cnts[i]\/2 - 0.01, -0.01, \"{:.0%}\".format(cnts[i]), fontsize=16)\n        bar_start += cnts[i]\n\n#     Draw legend and set color of its text\n    leg = ax.legend(xx, loc=(0,-0.5), ncol=5, fontsize=14, frameon=True, facecolor='white');\n    for txt in leg.get_texts():\n        plt.setp(txt, color='grey')","148c3bb5":"from textwrap import wrap\nbarcolors = [\"#fad46b\",\"#97c6e8\"]\nbarstyle = {\"edgecolor\":\"black\", \"linewidth\":0.5}\n\n# build a city questions df\nd =  {'city': city_df['Organization'].unique()}\ndf_cityQ = pd.DataFrame(data = d)\nmapping_country = dict(city_df[['Organization', 'Country']].values)\ndf_cityQ['Country'] = df_cityQ['city'].map(mapping_country)\n\nq = {'q1': q1, 'q2':q2}\nfor k,val in q.items():\n    options = city_df.groupby('Question Name').get_group(val)[\"Response Answer\"].value_counts().keys()\n    options_map = {}\n    for i in np.arange(len(options)):\n        options_map[options[i]] = i\n\n    df_cityQ[k] = pd.DataFrame(city_df.groupby('Question Name').get_group(val)[\"Response Answer\"]).reset_index(drop = True)\n#     df_cityQ[k] = df_cityQ[k].map(options_map) # convert to numeric values","aaa7f22c":"import matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2, venn3, venn3_circles\n\nplt.figure(figsize=(6,6))\nvd3=venn3([set(df_cityQ[df_cityQ['q1'] == 'Yes']['city']), set(df_cityQ[df_cityQ['q2'] == 'Yes']['city']),\\\n      set(df_cityQ['city'])],\n set_labels= ('Cities incorporating \\n sustainability goal',\\\n                    'Cities collaborating with businesses \\n on sustainability projects','All cities'),\n set_colors=('#c4e6ff', '#F4ACB7','#9D8189'), \n alpha = 0.8)\n\nc=venn3_circles([set(df_cityQ[df_cityQ['q1'] == 'Yes']['city']), set(df_cityQ[df_cityQ['q2'] == 'Yes']['city']),\\\n      set(df_cityQ['city'])], linestyle='-.', linewidth=2, color='grey')\nfor text in vd3.set_labels:\n    text.set_fontsize(16);\n# for text in vd3.subset_labels:\n#     text.set_fontsize(16)\nplt.title('Comparison of city responses: Sustainability development',fontname='Times New Roman',fontweight='bold',fontsize=20,\n pad=30,backgroundcolor='#cbe7e3',color='black',style='italic');\n\nplt.annotate('Planning-first', xy=(-0.3,-0.3), xytext=(0.05,0.1),\nha='center', textcoords= 'axes fraction', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\narrowprops=dict(arrowstyle='<-', connectionstyle='arc3,rad=0.5',color='gray'))\n\nplt.annotate('Collaborating-first', xy=(0.4,0.2), xytext=(1.2,0.3),\nha='center', textcoords= 'axes fraction', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\narrowprops=dict(arrowstyle='<-', connectionstyle='arc3,rad=0.5',color='gray'))\n\nplt.annotate('Planning and Collaborating interrelated', xy=(0.1,-0.2), xytext=(1.1,0.1),\nha='center', textcoords= 'axes fraction', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\narrowprops=dict(arrowstyle='<-', connectionstyle='arc3,rad=0.5',color='gray'))\n\nplt.show()","205e1358":"from matplotlib import cm\nheatmap_args = dict(annot=True, fmt=\"d\", square=False, cmap=cm.get_cmap(\"Greens\",12), \n               center = 90, vmin=0, vmax=500, lw=4, \n               cbar=False)\ndef hide_axes(this_ax):\n    this_ax.set_frame_on(False)\n    this_ax.set_xticks([])\n    this_ax.set_yticks([])\n    return this_ax\n\ndef draw_border_around_axes(this_ax, color=\"black\"):\n    for axis in ['top','bottom','left','right']:\n        this_ax.spines[axis].set_visible(True)\n        this_ax.spines[axis].set_color(color)\n        \ndef draw_code_ml_heatmap_general(df,tmp_ax,**kwargs):\n    hm = sns.heatmap(df, ax = tmp_ax, \n                **kwargs)\n    tmp_ax.set_xlabel('Q1')\n    tmp_ax.set_ylabel('Q2')\n    tmp_ax.set_yticklabels(tmp_ax.get_yticklabels(), rotation=0);\n    return hm \n    \ndef draw_code_ml_heatmap(tmp_ax):\n    hm = draw_code_ml_heatmap_general(allage_codepivot2, tmp_ax, **heatmap_args)\n    return hm\n\ndef calc_df_hist(df):\n    return df\/df.sum().sum()\n\ndef draw_mini_heatmap(df, this_ax, titletxt, linewidth=25, **kwargs):\n    hm = draw_code_ml_heatmap_general(df, this_ax, **kwargs)\n    this_ax.set_title(generate_wraptxt(titletxt, linewidth));\n    this_ax.set_frame_on(True)\n    this_ax.set_xticks([])\n    this_ax.set_yticks([])\n    this_ax.set_xlabel('')\n    this_ax.set_ylabel('')\n    draw_border_around_axes(this_ax)\n    return hm ","a9d3911a":"heatmap_args_nolim = dict(annot=True, fmt=\"d\", square=False, cmap=cm.get_cmap(\"Greens\",12), \n               lw=4, cbar=False)\nheatmap_args_ref = heatmap_args_nolim.copy()\nheatmap_args_ref['square']=True\nheatmap_args_ref['annot']=True\nheatmap_args_ref['fmt']='.0f'\nheatmap_args_ref['cmap']=cm.get_cmap('Greens')\nheatmap_args_ref['center']=13\nheatmap_args_ref['vmax']=25\nheatmap_args_ref['vmin']=0\nheatmap_args_ref['annot_kws']={\"size\":7}\n\nheatmap_args_nolim_sq = heatmap_args_nolim.copy()\nheatmap_args_nolim_sq['square']=True\nheatmap_args_nolim_sq['annot']=False\nheatmap_args_nolim_sq['fmt']='.1%'\nheatmap_args_nolim_sq['cmap']=cm.get_cmap('seismic_r',11)\nheatmap_args_nolim_sq['center']=0\nheatmap_args_nolim_sq['vmax']=0.055\nheatmap_args_nolim_sq['vmin']=-0.055\n","a7744655":"df_cityQ = df_cityQ.replace(\"\", \"Do not know\")\nallage_codepivot2 = pd.crosstab(df_cityQ['q1'], df_cityQ['q2'])\nprefer_order = [0,3,2,1,4]\nallage_codepivot2 = allage_codepivot2[allage_codepivot2.columns[prefer_order]]\n# allage_codepivot2 = allage_codepivot2.reindex(['Do not know','Not intending to incorporate','Intending to incorporate in the next 2 years','In progress','Yes'])\nallage_codepivot2 = allage_codepivot2.reindex(allage_codepivot2.index[prefer_order])\n\nf, ax = plt.subplots(nrows=2, ncols=2, figsize=(9,9), \n                     gridspec_kw={'height_ratios':[2,5], 'width_ratios':[2,5], 'wspace':0.1, 'hspace':0.1})\n\nthis_ax = ax[0,0]\nhide_axes(this_ax)\n\nhm_ax = ax[1,1]\ndraw_code_ml_heatmap(hm_ax);\nhm_ax.yaxis.tick_right()\nhm_ax.yaxis.set_label_position(\"right\")\ndraw_border_around_axes(hm_ax)\n\nthis_ax = ax[0,1]\nallage_codepivot2.sum(axis=0).plot.bar(ax=this_ax, color=barcolors[1],**barstyle)\nthis_ax.set_xlabel(hm_ax.get_xlabel())\nthis_ax.xaxis.set_ticklabels([])\n# this_ax.xaxis.tick_top()\nthis_ax.xaxis.set_label_position(\"top\")\nthis_ax.set_ylabel('# answers')\n\nthis_ax = ax[1,0]\nallage_codepivot2.sum(axis=1)[::-1].plot.barh(ax=this_ax, color=barcolors[0],**barstyle)\nthis_ax.set_ylabel(hm_ax.get_ylabel())\nthis_ax.yaxis.set_label_position(\"left\")\n# this_ax.xaxis.tick_top()\n# this_ax.xaxis.set_label_position(\"top\")\n# this_ax.set_xlim(this_ax.get_xlim()[::-1]);\nthis_ax.set_xlabel('# answers');\nprint(\"Q1: \"+ q1)\nprint(\"Q2: \" + q2)","ee9886e1":"refhist = calc_df_hist(allage_codepivot2)\nthis_ax = plt.axes()\nrh = refhist\nheatmap_args_ref2 = heatmap_args_ref.copy()\nheatmap_args_ref2['annot_kws'] = {\"size\":10}\ndraw_mini_heatmap(\n        round((rh)*100), \n        this_ax, \"Across all surveyed cities (%)\", **heatmap_args_ref2);","68aae30f":"# horizontal comparison\nf, ax = plt.subplots(ncols=3, nrows=1, figsize = (12,4),\n                     gridspec_kw = {\"wspace\":0.75})\n\nthis_ax = ax[0]\ndraw_mini_heatmap(\n        round((refhist)*100), \n        this_ax, \"across all cities (%)\", **heatmap_args_ref2)\n\nfor i, country_name in enumerate(['United States of America', \"Mexico\"]):\n    dat = pd.crosstab(df_cityQ.query('Country == @country_name')['q1'], \\\n                     df_cityQ.query('Country == @country_name')['q2'])\n    dat = dat.reindex(index=df_cityQ['q1'].unique()[[4,3,2,1,0]], \\\n                      columns=df_cityQ['q2'].unique()[[4,3,2,1,0]], fill_value=0)\n    st = calc_df_hist(dat)\n    this_ax = ax[i+1]\n    draw_mini_heatmap(\n            round((st)*100), \n            this_ax, country_name, **heatmap_args_ref2)","cf67f5e2":"import matplotlib.patheffects as path_effects\ndef black_border_around_text(annotation_handle):\n    annotation_handle.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'),\n                       path_effects.Normal()])\n    return annotation_handle\n\ndef draw_zero_heatmap_legend(this_ax, cbar_ax, df):\n    cbar_kws = dict(orientation=\"horizontal\", ticks=np.arange(-0.06,0.06,0.01))    \n    cbar_pos = cbar_ax.get_position()\n    cbar_ax.set_position([cbar_pos.x0, cbar_pos.y0+cbar_pos.height\/2, cbar_pos.width, cbar_pos.height\/6])\n\n    zero_kws = heatmap_args_nolim_sq.copy()\n    zero_kws['cbar_ax'] = cbar_ax\n    zero_kws['cbar_kws'] = cbar_kws\n    zero_kws['cbar'] = True\n    \n    hm = draw_mini_heatmap(\n            df, \n            this_ax, \"\", **zero_kws)\n    arrow_y = this_ax.annotate('', xy=(-0.3,5),  xycoords='data',\n                xytext=(-0.3,0.5), \n                arrowprops=dict(arrowstyle=\"->\",color='black'),\n                horizontalalignment='right', verticalalignment='top',annotation_clip=False\n                )\n    this_ax.set_ylabel('more collaborations',labelpad=15)\n\n    arrow_x = this_ax.annotate('', xy=(5,-0.3),  xycoords='data',\n                xytext=(0.5,-0.3), \n                arrowprops=dict(arrowstyle=\"->\",color='black'),\n                horizontalalignment='right', verticalalignment='top',annotation_clip=False\n                )\n    this_ax.set_xlabel('more planning',labelpad=15)\n    this_ax.xaxis.set_label_position('top')\n    \n#     cbar_ax.set_xticks(np.arange(-0.6,0.6,0.1))\n    labels = cbar_ax.get_xticks()*100\n    cbar_ax.set_xticklabels([\"{0:.0f}%\".format(x) for x in labels])\n    cbar_ax.set_title('histogram difference (perc.points)')\n    return hm ","e77f1993":"f, ax = plt.subplots(ncols=6, nrows=1, figsize = (18,4),\n                     gridspec_kw = {\"width_ratios\":[1,0.1,1,0.25,1,2],\"wspace\":0.25})\n\ncountry_name = \"United States of America\"\n\nthis_ax = ax[0]\ndat = pd.crosstab(df_cityQ.query('Country == @country_name')['q1'], \\\n                     df_cityQ.query('Country == @country_name')['q2'])\n# dat = dat.reindex(index=df_cityQ['q1'].unique(), \\\n#                   columns=df_cityQ['q2'].unique(), fill_value=0)\ndat = dat.reindex(index=df_cityQ['q1'].unique()[[4,3,2,1,0]], \\\n                      columns=df_cityQ['q2'].unique()[[4,3,2,1,0]], fill_value=0)\nst = calc_df_hist(dat)\ndraw_mini_heatmap(\n        round((st)*100), \n        this_ax, country_name, **heatmap_args_ref2)\n\nthis_ax = ax[1]\nan1 = this_ax.annotate(\"-\", xy=(0.5,0.5), fontsize=40, color=\"black\", weight='bold',\n                       verticalalignment='center', horizontalalignment='center', annotation_clip=False)\nblack_border_around_text(an1);\nhide_axes(this_ax)\n\nthis_ax = ax[2]\ndraw_mini_heatmap(\n        round((rh)*100), \n        this_ax, \"all cities surveyed (%)\", **heatmap_args_ref2)\n\nthis_ax = ax[3]\nan1 = this_ax.annotate(\"=\", xy=(0.25,0.5), fontsize=40, color=\"black\", weight='bold',\n               verticalalignment='center', horizontalalignment='center', annotation_clip=False)\nblack_border_around_text(an1);\nhide_axes(this_ax)\n\ndraw_zero_heatmap_legend(ax[4], ax[5], (st-rh));","ac979d5c":"f, ax = plt.subplots(ncols=6, nrows=1, figsize = (18,4),\n                     gridspec_kw = {\"width_ratios\":[1,0.1,1,0.25,1,2],\"wspace\":0.25})\n\ncountry_name = \"United Kingdom of Great Britain and Northern Ireland\"\n\nthis_ax = ax[0]\ndat = pd.crosstab(df_cityQ.query('Country == @country_name')['q1'], \\\n                     df_cityQ.query('Country == @country_name')['q2'])\ndat = dat.reindex(index=df_cityQ['q1'].unique()[[4,3,2,1,0]], \\\n                      columns=df_cityQ['q2'].unique()[[4,3,2,1,0]], fill_value=0)\nst = calc_df_hist(dat)\ndraw_mini_heatmap(\n        round((st)*100), \n        this_ax, country_name, **heatmap_args_ref2)\n\nthis_ax = ax[1]\nan1 = this_ax.annotate(\"-\", xy=(0.5,0.5), fontsize=40, color=\"black\", weight='bold',\n                       verticalalignment='center', horizontalalignment='center', annotation_clip=False)\nblack_border_around_text(an1);\nhide_axes(this_ax)\n\nthis_ax = ax[2]\ndraw_mini_heatmap(\n        round((rh)*100), \n        this_ax, \"all cities surveyed (%)\", **heatmap_args_ref2)\n\nthis_ax = ax[3]\nan1 = this_ax.annotate(\"=\", xy=(0.25,0.5), fontsize=40, color=\"black\", weight='bold',\n               verticalalignment='center', horizontalalignment='center', annotation_clip=False)\nblack_border_around_text(an1);\nhide_axes(this_ax)\n\ndraw_zero_heatmap_legend(ax[4], ax[5], (st-rh));","a8cce63b":"d = {'Organization': city_df['Organization'].unique()}\ndf_green = pd.DataFrame(data=d)\ncity_country_dict = {}\ncity_region_dict = {}\nfor c in d['Organization']:\n    city_country_dict[c] = city_df[city_df['Organization'] == c]['Country'].unique()[0]\n    city_region_dict[c] = city_df[city_df['Organization'] == c]['CDP Region'].unique()[0]\ndf_green['Country'] = df_green['Organization'].map(city_country_dict)\ndf_green['CDP Region'] = df_green['Organization'].map(city_region_dict)","8ef2ece4":"def get_ans_unique_cnts(df,qnum):\n    return len(get_ans(df, qnum).value_counts())\n\ndef separate_qs(df, axis):\n    idx = [i[0] for i in axis]\n    multichoice = []\n    texts = []\n    for i in idx:\n        c = get_ans_unique_cnts(df, i)\n        if(c < 10):\n            multichoice.append(i)\n        else:\n            texts.append(i)\n    return multichoice, texts\n\ndef get_ans_per_firm(df, qnum):\n    qs = df['Question Name'].unique()\n    return df[df[\"Question Name\"] == qs[qnum]].groupby(['Organization'])[\"Response Answer\"].apply(','.join).reset_index()","f810be8c":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# Sentiment analysis for short answer questions\ndef sentiment_score(df, axis, qnum_list):\n    sid = SentimentIntensityAnalyzer()\n    df[axis+'_score'] = 0\n    \n    for q_text in qnum_list:\n        ans_df = get_ans_per_firm(city_df, q_text)\n        df = pd.merge(df, ans_df[['Organization','Response Answer']],on='Organization', how='left')\n\n        for i,ans in enumerate(df['Response Answer']):\n            if type(ans) != str:\n                df.loc[i,axis+'_score'] += 0        \n            else:\n                ss = sid.polarity_scores(ans)\n                df.loc[i,axis+'_score'] += ss['compound'] + ss['pos']\n        del df['Response Answer']\n    return df","e105bb53":"def choice_score(df, axis, qnum_list):\n#     df[axis+'_grade'] = 0\n    options_map = {'Yes':2, 'No':0, 'Question not applicable': 0.5, 'Do not know':-0.5, \\\n              'In progress': 1.5, 'Intending to':1, \"Not intending to\": -1}\n    \n    for q_text in qnum_list:\n        ans_df = get_ans_per_firm(city_df, q_text)\n        ans_df[ans_df['Response Answer'].str.contains(\"Intending to\")] = \"Intending to\"\n        ans_df[ans_df['Response Answer'].str.contains(\"Not intending to\")] = \"Not intending to\"\n        df = pd.merge(df, ans_df[['Organization','Response Answer']],on='Organization', how='left')\n\n        df[axis+'_score'] += ans_df[\"Response Answer\"].map(options_map).fillna(0.1)\n        del df['Response Answer']\n    return df  ","7d9b77d6":"# air quality axis\nair = list(set(get_q(city_df,\"air \")) | set(get_q(city_df,\"gas\")) | set(get_q(city_df,\"Air\")))\nair_choice, air_texts = separate_qs(city_df, air)\ndf_green = sentiment_score(df_green, \"air\", air_texts)\ndf_green = choice_score(df_green, \"air\", air_choice)","35e28653":"# governance axis\ngov = list(set(get_q(city_df,\"policy\")) | set(get_q(city_df,\"plan\")) | set(get_q(city_df,\"social\")) | set(get_q(city_df,\"eco\")) | set(get_q(city_df,\"employ\")))\ngov_choice, gov_texts = separate_qs(city_df, gov)\ndf_green = sentiment_score(df_green, \"gov\", gov_texts)\ndf_green = choice_score(df_green, \"gov\", gov_choice)","5f8ecea7":"# co2 axis\nco2 = list(set(get_q(city_df,\"CO2\")) | set(get_q(city_df,\"carbon\")) | set(get_q(city_df,\"GHG\")) | set(get_q(city_df,\"emission\")))\nco2_choice, co2_texts = separate_qs(city_df, co2)\ndf_green = sentiment_score(df_green, \"co2\", co2_texts)\ndf_green = choice_score(df_green, \"co2\", co2_choice)","98f1ea61":"# energy axis\nenergy = list(set(get_q(city_df,\"energy\")))\nenergy_choice, energy_texts = separate_qs(city_df, energy)\ndf_green = sentiment_score(df_green, \"energy\", energy_texts)\ndf_green = choice_score(df_green, \"energy\", energy_choice)","fa5f80c1":"# building axis\nbuilding = list(set(get_q(city_df,\"building\")))\nbuilding_choice, building_texts = separate_qs(city_df, building)\ndf_green = sentiment_score(df_green, \"building\", building_texts)\ndf_green = choice_score(df_green, \"building\", building_choice)","68d399e6":"# extract quantitiative emission information\ntCO2e = city_df.groupby('Question Name').get_group(qs_city[32]) # total CO2 emission\ndf = df_green.copy()\nemit_list = []\nfor i in tCO2e['Row Number'].unique():\n    CO2_div = tCO2e.groupby('Row Number').get_group(i).reset_index(drop = True)\n    df = pd.merge(df,CO2_div[['Organization','Response Answer']],on='Organization', how='left')\n    df.rename(columns = {'Response Answer':CO2_div['Row Name'][0] + '_emission'}, inplace = True)\n    emit_list.append(CO2_div['Row Name'][0] + '_emission')\n    \nfor i in range(len(emit_list)):\n#     df.loc[df[emit_list[i]] == 'Question not applicable',emit_list[i]] = np.nan\n    df[emit_list[i]] = pd.to_numeric(df[emit_list[i]], errors='coerce')\n    \n# df.fillna('Do not know', inplace = True)\ndf['totalCO2e'] = df[emit_list].sum(axis=1)\ndf['country_emit'] = df.groupby('Country')['totalCO2e'].transform('sum')\ndf['country_emit'] = df['country_emit'].replace(0, np.nan)\n\n# emission map for all countries\nimport plotly.express as px\n\nmy_color_scale=cm.get_cmap(\"Greens\",12)\nfig = px.choropleth(df, locations=\"Country\", locationmode='country names',color=\"country_emit\", \\\n                    color_continuous_scale='Greys', hover_name=\"Country\", range_color=[0,25],\\\n                    title = '2020 Emissions of CO2 per capita (metric tonnes) from buildings for Countries Surveyed by CDP <br><i>(only showing the ones that have valid submissions)<i>')\n\nfig.update_layout(geo=dict(\n    countrycolor= \"#444444\",\n    showcountries=True))\nfig.show()","6c28b268":"# transport axis\ntransport = list(set(get_q(city_df,\"transport\")) | set(get_q(city_df,\"car\")))\ntransport_choice, transport_texts = separate_qs(city_df, transport)\ndf_green = sentiment_score(df_green, \"transport\", transport_texts)\ndf_green = choice_score(df_green, \"transport\", transport_choice)","a7324f36":"# waste axis\nwaste = list(set(get_q(city_df,\"waste\")))\nwaste_choice, waste_texts = separate_qs(city_df, waste)\ndf_green = sentiment_score(df_green, \"waste\", waste_texts)\ndf_green = choice_score(df_green, \"waste\", waste_choice)","4858524d":"# water axis\nwater = list(set(get_q(city_df,\"water\")))\nwater_choice, water_texts = separate_qs(city_df, water)\ndf_green = sentiment_score(df_green, \"water\", water_texts)\ndf_green = choice_score(df_green, \"water\", water_choice)","3f9bdfe0":"# normalize scores along axis\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfor col in df_green.columns[3:]:\n    scaler=MinMaxScaler()\n    df_green[col] = scaler.fit_transform(df_green[[col]])","06a581f0":"# sum up all score\ncol_list = df_green.columns[3:]\ndf_green['sum'] = df_green[col_list].sum(axis=1)\nscaler=MinMaxScaler()\ndf_green['sum'] = scaler.fit_transform(df_green[['sum']])","6f8733d6":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\naxes = ['Air Quality','Environmental Governance','CO2','Energy','Buildings','Transport','Waste & Land use','Water']\nfig = make_subplots(rows=1, cols=1, specs=[[{'type': 'polar'}]*1]*1)\ncity_list = list(df_green.nlargest(10, ['sum'])['Organization'])\nprint(\"Double click the legend to see individual contour!\")\n\nfor c in city_list:\n    city_grade = list(df_green[df_green[\"Organization\"] == c].iloc[0,3:11])\n\n    fig.add_trace(go.Scatterpolar(\n          name = c,\n          r = city_grade + [city_grade[0]],\n          theta = axes + [axes[0]],\n        ), 1, 1)\nfig.update_traces(fill='toself')\nfig.update_layout(\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n      range=[0, 1]\n    )),\n  font_size=12,\n  legend_font_size=12,\n  template = 'presentation',\n  title = '<b>Top 10 Cities with Highest MGCI Score<\/b> <br><i>Double click the legend to see individual contour!<\/i>')\nfig.show()\n\nfig = make_subplots(rows=1, cols=1, specs=[[{'type': 'polar'}]*1]*1)\ncity_list2 = list(df_green.nsmallest(10, ['sum'])['Organization'])\nfor c in city_list2:\n    city_grade = list(df_green[df_green[\"Organization\"] == c].iloc[0,3:11])\n\n    fig.add_trace(go.Scatterpolar(\n          name = c,\n          r = city_grade + [city_grade[0]],\n          theta = axes + [axes[0]],\n        ), 1, 1)\n\nfig.update_traces(fill='toself')\nfig.update_layout(\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n      range=[0, 1]\n    )),\n  font_size=12,\n  legend_font_size=12,\n  template = 'presentation',\n  title = '<b>Top 10 Cities with Lowest MGCI Score<\/b> <br><i>Double click the legend to see individual contour!<\/i>')\n\nfig.show()","f320df17":"# emission map for all countries\nimport plotly.express as px\n\ncols = [\"Organization\",\"air_score\",\"gov_score\",\"co2_score\",\"energy_score\",\"building_score\",\\\n       \"transport_score\",\"waste_score\",\"water_score\",\"sum\"]\ndf_grade = df_green[cols].melt(id_vars=[\"Organization\"], \n        var_name=\"Score\", \n        value_name=\"Value\")\ndf_grade = pd.merge(df_grade, df_green[[\"Organization\", \"Country\"]], on = 'Organization', how='left')\n\nfig = px.choropleth(df_grade,locations=\"Country\", locationmode='country names', color=\"Value\",color_continuous_scale='Greens',\n  animation_frame=\"Score\", animation_group=\"Country\", title = '2020 Modified Green City Index KPI Metric Score Distribution <br><i>- based on features extracted from CDP survey<i>')\n\nfig.update_layout(geo=dict(\n    countrycolor= \"#444444\",\n    showcountries=True))\nfig.show()","c0262d73":"corp_info = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Corporations\/Corporations Disclosing\/Climate Change\/2020_Corporates_Disclosing_to_CDP_Climate_Change.csv')\nd = {'Organization': cc_df['organization'].unique()}\nfirm_green = pd.DataFrame(data=d)\nqs = cc_df['Question Name'].unique()\n\nmapping_country = dict(corp_info[['organization', 'country']].values)\nmapping_industry = dict(corp_info[['organization', 'primary_industry']].values)\nmapping_engage = dict(cc_df[cc_df[\"Question Name\"] == qs[5]][[\"organization\",\"Response Answer\"]].values)\nmapping_climate = dict(cc_df[cc_df[\"Question Name\"] == qs[42]][[\"organization\",\"Response Answer\"]].values)\nmapping_water = dict(cc_df[cc_df[\"Question Name\"] == qs[96]][[\"organization\",\"Response Answer\"]].values)\n\nfirm_green['Country'] = firm_green['Organization'].map(mapping_country)\nfirm_green['Industry'] = firm_green['Organization'].map(mapping_industry)\nfirm_green['engage'] = firm_green['Organization'].map(mapping_engage)\nfirm_green['engage_climate'] = firm_green['Organization'].map(mapping_climate)\nfirm_green['engage_water'] = firm_green['Organization'].map(mapping_water)","7187b546":"# extract quantitiative emission information\ntCO2e = cc_df.groupby('Question Name').get_group(qs[21]) # total scope 1 CO2 emission in metric tons\ntCO2e = tCO2e[(tCO2e[\"row_name\"] == 'Reporting year') & (tCO2e[\"column_number\"] == 1)]\ntCO2e.rename(columns = {'organization': 'Organization'}, inplace = True)\n# df = firm_green.copy()\nfirm_green = pd.merge(firm_green,tCO2e[['Organization','Response Answer']],on='Organization', how='left')\nfirm_green[\"Response Answer\"] = pd.to_numeric(firm_green[\"Response Answer\"], errors='coerce')\nfirm_green.rename(columns = {'Response Answer': 'totCO2'}, inplace = True)\nqs[21]","8f6b9dc0":"def recalc(df, col):\n    d = df[col].value_counts()\n    dd = {}\n    for k,v in d.items():\n        choices = [x.strip() for x in k.split(';')]\n        for choice in choices:\n            if choice in dd:\n                dd[choice] += v\n            else:\n                dd[choice] = v\n    return dd","79a10efb":"from collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS\n\n# city vs. corporate risks\ncity_risk_q = [i[0] for i in get_q(city_df,\"risk\")]\ncity_risk_list = []\nfor q in city_risk_q:\n    city_risk_list.append(' '.join([i for i in list(get_ans(city_df, q).unique()) if type(i) == str and \\\n                                    'http' not in i and 'de' not in i and 'please' not in i]))\n\ncity_risks = ' '.join([str(elem) for elem in city_risk_list]) \n\n# city_risks = combine_ans(city_df, \"risk\")\ncorp_risks = combine_ans(cc_df, \"risk\")\nstopwords = set(STOPWORDS) \n\nfig = plt.figure()\nfig.set_size_inches(20, 10)\ncolors_set = ['royalblue', 'indianred']\nskills_list = [city_risks,corp_risks]\ntitles_list = ['City risks', 'Corporate risks']\n\nfor i in range(2):\n    ax = fig.add_subplot(1,2,i+1)\n    word_could_dict=skills_list[i]\n    # Create wordcloud object\n    wordcloud = WordCloud(width = 1200, height = 1200, background_color=\"white\", stopwords = stopwords, \n                          color_func=lambda *args, **kwargs: colors_set[i], relative_scaling = 0.5).generate(word_could_dict)\n    \n    ax.imshow(wordcloud, interpolation = 'bilinear')\n    ax.axis('off')\n\n    # Set title\n    ax.set_title(titles_list[i], size=48, pad=50)\n    \nplt.tight_layout(pad=0)\nplt.show()","41907d6a":"pref_color = ['#F7819F', '#F5A9BC', '#E6E6E6', '#CEF6D8', '#9FF781']\ndds = [recalc(firm_green, \"engage_climate\"),recalc(firm_green, \"engage_water\")]\nq = [42, 96]\nfor ii,dd in enumerate(dds):\n    xx = sorted(list(dd.keys()))\n\n    # matplotlib general settings\n    fig, ax = plt.subplots(figsize=(35,1),frameon=False)\n    plt.title(\"Q\"+str(q[ii]) + \": \" + qs[q[ii]], fontsize=28, loc='left')\n    ax.get_xaxis().set_visible(False)\n    ax.tick_params(axis='y', labelsize=20, labelcolor='grey')  \n    ax.set_facecolor('white')\n    ax.axis('off')\n\n    # Draw each bar and text separately with appropriate offset\n    bar_start = 0\n    cnts = [dd[_]\/np.sum(list(dd.values())) for _ in xx]\n\n    for i in range(len(dd)):\n        ax.barh(y=['All Respondents'], width=cnts[i], height=0.1, left=bar_start, color=pref_color[i])\n        plt.text(bar_start + cnts[i]\/2 - 0.01, -0.01, \"{:.0%}\".format(cnts[i]), fontsize=20)\n        bar_start += cnts[i]\n\n#     Draw legend and set color of its text\n    leg = ax.legend(xx, loc=(0,-0.5), ncol=5, fontsize=18, frameon=True, facecolor='white');\n    for txt in leg.get_texts():\n        plt.setp(txt, color='grey')","ed37dc2f":"from plotly.offline import init_notebook_mode, iplot\nimport matplotlib.colors as colors\n\n# recalculate to account for multiple answers\ndd1 = recalc(firm_green, \"engage\")\nxx = list(dd1.keys())\nxx = [_ + \"<br>(\" +str(round(100*dd1[_]\/np.sum(list(dd1.values())),1))+ \"%)\" for _ in xx]\nyy = [\"\"]*len(dd1)\ncc = list(colors._colors_full_map.values())\n\ntrace1 = go.Scatter(x = xx, y = [\"\"]*len(dd1), mode='markers', name=\"\", marker=dict(color=cc[:len(xx)], opacity=0.4, size = 0.2*np.array(list(dd1.values()))))\nlayout = go.Layout(barmode='stack', height=380, margin=dict(l=20), title=\"Approaches of corporate engagement on climate-related issues\",\n                   legend = dict(orientation=\"h\", x=0.1, y=1.15), plot_bgcolor='#fff', paper_bgcolor='#fff', \n                   showlegend=False)\n\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)\n\n# city engagement\ndd = get_ans(city_df, 79).value_counts()[1:10]\nxx = list(dd.keys())\nxx = [_ + \"<br>(\" +str(round(100*dd[_]\/dd.values.sum()))+ \"%)\" for _ in xx]\nyy = [\"\"]*len(dd)\ncc = list(colors._colors_full_map.values())\n\ntrace1 = go.Scatter(x = xx, y = [\"\"]*len(dd), mode='markers', name=\"\", marker=dict(color=cc[:len(xx)], opacity=0.4, size = 0.2*np.array(list(dd.values))))\nlayout = go.Layout(barmode='stack', height=320, margin=dict(l=20), title=\"Approaches of city engagement with businesses\",\n                   legend = dict(orientation=\"h\", x=0.1, y=1.15), plot_bgcolor='#fff', paper_bgcolor='#fff', \n                   showlegend=False)\n\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","84e262e3":"vals = dd.values[:6]\/100","2069c3c2":"# flow chart\ncol_yes = \"#fad46b\"\ncol_no = \"#97c6e8\"\npfs = [\"  Cities\", \"  Businesses\"]\n\nroles = list(dd.keys()[1:7])\nds = [\"Collaboration\"]\n\nvals = list(dd.values[:6]\/100)\n# vals = [2.71, 2.3 , 1.72, 1.58, 1.39, 1.31]\nvals2 = [1, 2.3, 1, 1.2, 0.9, 0.9]\nsums = np.array(vals) + np.array(vals2)\nvals += vals2\n\n\nfig = go.Figure(data=[go.Sankey(\n    node = dict(\n      pad = 50,\n      thickness = 10,\n      line = dict(color = \"gray\", width = 2),\n      label =  pfs +  roles + ds,\n      color = [col_yes, col_no] + [\"#6ccc86\"]*6\n    ),\n    link = dict(\n      source = [0, 1]*len(roles) + [2,3,4,5,6,7]*len(ds),\n      target = [2]*len(pfs) + [3]*len(pfs) + [4]*len(pfs) + [5]*len(pfs) + [6]*len(pfs) + [7]*len(pfs) + [8, 8, 8, 8, 8, 8],\n      value = vals + list(sums)\n  ))])\n\n\nfig.update_layout(title_text='Major city-business collaboration pathways extracted from CDP survey',font=dict(size = 12),)\nfig.show()","c2248cfc":"# CO2 emission by industry\nco2_by_industry = firm_green.groupby('Industry')['totCO2'].sum()\nco2_by_industry = dict(sorted(co2_by_industry.items(), key=lambda co2_by_industry: co2_by_industry[1])) # sorted\n\nx_pos = [i for i, _ in enumerate(co2_by_industry)]\n\nfig, ax = plt.subplots(figsize = (10,6))\nplt.barh(x_pos, co2_by_industry.values(), color='green')\nplt.ylabel(\"Industry\")\nplt.xlabel(\"CO2 Emissions (metric ton)\")\nplt.title(\"CO2 emission by industry\",backgroundcolor='#cbe7e3',fontsize = 17)\nax.set_yticks(x_pos)\nax.set_yticklabels(co2_by_industry.keys(), rotation=0)\n# plt.yticks(x_pos, x)\nax.grid(False)\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nplt.show()","19387458":"q = set(get_q(city_df,\"not have\")) & set(get_q(city_df,\"why\")) #| set(get_q(city_df,\"not\"))\nq = dict(q)\nq","84f17ca5":"for k,val in q.items():\n    options = city_df.groupby('Question Name').get_group(val)[\"Response Answer\"].value_counts().keys()\n    options_map = {}\n    for i in np.arange(len(options)):\n        options_map[options[i]] = i\n\n    df_cityQ['q'+str(k)] = pd.DataFrame(city_df.groupby('Question Name').get_group(val)[\"Response Answer\"]).reset_index(drop = True)\n#     df_cityQ[k] = df_cityQ[k].map(options_map) # convert to numeric values\n\ndf_cityQ['CDP Region'] = df_cityQ['city'].map(city_region_dict)","c4b0af9d":"# Compare region distribution\n# city_with_planning = list(df_cityQ[df_cityQ.iloc[:, 4:10].eq(\"Question not applicable\").all(axis=1)][\"city\"])\ncity_wo_planning = list(df_cityQ[(df_cityQ.iloc[:, 4:10].eq(\"Question not applicable\")).sum(axis=1) <5][\"city\"])\ncity_wo_planning = set(city_wo_planning) | set(list(df_cityQ[(df_cityQ.iloc[:, 4:10].eq(\"Do not know\")).sum(axis=1) >= 2][\"city\"])) \ncity_with_planning = [c for c in list(df_cityQ[\"city\"]) if c not in city_wo_planning] \n\ndict_plan_city = df_cityQ[df_cityQ['city'].isin(city_with_planning)]['CDP Region'].value_counts()\ndict_all_city = df_cityQ['CDP Region'].value_counts()\nplan_cities = pd.DataFrame(dict_plan_city,index=dict_plan_city.keys())\nall_cities = pd.DataFrame(dict_all_city)\nCOLORS_SET_B_G_R = [sns.color_palette('muted')[0], sns.color_palette('muted')[2], sns.color_palette('muted')[3]]\n\nsns.set(style=\"whitegrid\")\n# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 6))\nsns.barplot(x=\"CDP Region\", y=all_cities.index, data=all_cities,\n            label=\"Total\", color=\"lightgrey\")\nsns.barplot(x=\"CDP Region\", y=plan_cities.index, data=plan_cities, \n            label=\"Citis with sustainability plans\", color=COLORS_SET_B_G_R[2], edgecolor='black')\n\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True, prop={'size': 10})\nax.set(xlim=(0, 180), ylabel=\"\", xlabel=\"\")\n\n# Remove reduntant borders and labels\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.xaxis.set_label_text(\"# of cities\")\nax.yaxis.set_label_text(\"CDP Region\")\nsns.despine(left=False, bottom=False)\n\n# Set title and labels size\n_ = ax.set_title('Number of Cities with Sustainable Planning across CDP surveys', fontsize=20, pad=25)\nax.tick_params(axis='y', which='major', labelsize=12)\n_ = plt.setp(fig.patches, linewidth=0.5)","78d728b6":"def gen_xaxis(title):\n    \"\"\"\n    Creates the X Axis layout and title\n    \"\"\"\n    xaxis = dict(\n            title=title,\n            titlefont=dict(\n                color='#AAAAAA'\n            ),\n            showgrid=False,\n            color='#AAAAAA',\n            )\n    return xaxis\n\n\ndef gen_yaxis(title):\n    \"\"\"\n    Creates the Y Axis layout and title\n    \"\"\"\n    yaxis=dict(\n            title=title,\n            titlefont=dict(\n                color='#AAAAAA'\n            ),\n            showgrid=False,\n            color='#AAAAAA',\n            )\n    return yaxis\ndef gen_layout(charttitle, xtitle, ytitle, lmarg, h, annotations=None):  \n    \"\"\"\n    Creates whole layout, with both axis, annotations, size and margin\n    \"\"\"\n    return go.Layout(title=charttitle, \n                     height=h, \n                     width=800,\n                     showlegend=False,\n                     xaxis=gen_xaxis(xtitle), \n                     yaxis=gen_yaxis(ytitle),\n                     annotations = annotations,\n                     margin=dict(l=lmarg),\n                    )\ndef gen_annotations(annot):\n    \"\"\"\n    Generates annotations to insert in the chart\n    \"\"\"\n    if annot is None:\n        return []\n    \n    annotations = []\n    # Adding labels\n    for d in annot:\n        annotations.append(dict(xref='paper', x=d['x'], y=d['y'],\n                           xanchor='left', yanchor='bottom',\n                           text= d['text'],\n                           font=dict(size=13,\n                           color=d['color']),\n                           showarrow=False))\n    return annotations","75d7cd27":"df_cityQ[\"sustainable\"] = \"nan\"\ndf_cityQ.loc[df_cityQ[\"city\"].isin(city_wo_planning),\"sustainable\"] = False\ndf_cityQ.loc[df_cityQ[\"city\"].isin(city_with_planning),\"sustainable\"] = True\ndf_green2 = pd.merge(df_green, df_cityQ[['city','sustainable']],left_on='Organization', right_on='city', how='left') \n\nx0 = df_green2[df_green2[\"sustainable\"] == False][\"sum\"]\nx1 = df_green2[df_green2[\"sustainable\"] == True][\"sum\"]\n\n# df2 = pd.merge(df,df_cityQ[['city','sustainable']],left_on='Organization', right_on='city', how='left') \n# x0 = df2[df2[\"sustainable\"] == False][\"totalCO2e\"]\n# x1 = df2[df2[\"sustainable\"] == True][\"totalCO2e\"]\n\nuneco_cities = go.Histogram(\n    x=x0,\n    opacity=0.5,\n    marker={'color': 'lightgray'},\n)\neco_cities = go.Histogram(\n    x=x1,\n    opacity=0.5,\n    marker={'color': 'mediumaquamarine'},\n)\n\nannot_dict = [{'x': 0.2, 'y': 67, 'text': 'The less \"sustainable\" cities tend to get lower scores','color': 'gray'},\n              {'x': 0.6, 'y': 25, 'text': '\"Sustainable\" city group tends to have<br>higher scores','color': 'mediumaquamarine'}]\n\nlayout = gen_layout('<b>Distribution of MGCI Scores of City Groups<\/b><br><i>Based on sustainable planning activities and risk awareness and\/or preparations<\/i>', \n                    'Modified Green City Index (MGCI) Score',\n                    'Quantity of Respondents',\n                    annotations=gen_annotations(annot_dict),\n                    lmarg=120, h=500\n                    )\nlayout['barmode'] = 'overlay'\n\ndata = [uneco_cities, eco_cities]\nlayout = go.Layout(layout)\nfig = go.Figure(data=data, layout=layout)\n\niplot(fig)","7a3df182":"# Comparisons between cities with and without sustainable planning\nfig, ax = plt.subplots(figsize=(5, 5))\nCOLORS_SET_B_G_R = [sns.color_palette('muted')[0], sns.color_palette('muted')[2], sns.color_palette('muted')[3]]\n\ng = sns.barplot(x=\"sustainable\", y=\"sum\",\n                data=df_green2, palette=COLORS_SET_B_G_R[1:3],\n                dodge=True, ci=90, capsize=0.1, errwidth =1, edgecolor='black')\n\n# Remove redundant labels and borders\nsns.despine(left=False, bottom=False)\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n# Set title\n_ = ax.set_title('Average MGCI Scores for City Groups', fontsize=20, pad=25)\n# Set x ticks\nax.tick_params(axis='x', which='major', labelsize=12)\n_ = ax.xaxis.set_ticklabels([\"Sustainable\", \"non-Sustainable\"])\n_ = plt.setp(g.patches, linewidth=0.5) ","cd146212":"# let us fit a decision tree\nfrom sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(max_leaf_nodes=7, min_samples_leaf=5)\ndt.fit(df_green2[df_green2.columns[3:11]], df_green2[\"sustainable\"])\n\n# let us plot a decision tree\nimport graphviz \nfrom sklearn import tree\ndot_data = tree.export_graphviz(dt, out_file=None, \n                                feature_names=df_green2.columns[3:11],  \n                                filled=True, rounded=True,  \n                                special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","a9dc789f":"\nfig = go.Figure(data = [go.Bar(\n            x=dt.feature_importances_[np.argsort(dt.feature_importances_)],\n            y=list(df_green2.columns[3:11][np.argsort(dt.feature_importances_)]),\n            orientation='h', marker=dict(color=COLORS_SET_B_G_R, opacity=0.1))], \n               layout = go.Layout(title=\"MGCI Axis Importances to Sustainable Preparedness\", plot_bgcolor='#fff', paper_bgcolor='#fff',  margin=dict(l=100),\n                               width=900, height=500, legend=dict(orientation=\"h\", x=0.1, y=1.1)))\nfig.show()","77c8df03":"import bs4 as bs\nimport urllib.request\nimport re\nimport nltk\nimport heapq\n\nexcuses = combine_ans(city_df[city_df['Country'] == \"United States of America\"], [\"why\",\"not have\"])\narticle_text = excuses\n\n# Removing Square Brackets and Extra Spaces\narticle_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\narticle_text = re.sub(r'\\s+', ' ', article_text)\n\n# Removing special characters and digits\nformatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\nformatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\nsentence_list = nltk.sent_tokenize(article_text)\nstopwords = nltk.corpus.stopwords.words('english')\n\nword_frequencies = {}\nfor word in nltk.word_tokenize(formatted_article_text):\n    if word not in stopwords:\n        if word not in word_frequencies.keys():\n            word_frequencies[word] = 1\n        else:\n            word_frequencies[word] += 1\n    maximum_frequncy = max(word_frequencies.values())\n    \nfor word in word_frequencies.keys():\n    word_frequencies[word] = (word_frequencies[word]\/maximum_frequncy)\n    sentence_scores = {}\n    \nfor sent in sentence_list:\n    for word in nltk.word_tokenize(sent.lower()):\n        if word in word_frequencies.keys():\n            if len(sent.split(' ')) < 30:\n                if sent not in sentence_scores.keys():\n                    sentence_scores[sent] = word_frequencies[word]\n                else:\n                    sentence_scores[sent] += word_frequencies[word]\n                    \nsummary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n\nsummary_sentences[0] = '- ' + summary_sentences[0] \nsummary = '\\n- '.join(summary_sentences)\n\nprint('\\033[1m' + \"Summary for reasons not planning for sustainability:\" + '\\033[0m')\nprint(summary)","cb145eb7":"<div id=\"#6\"><\/div>\n<font color='#088a5a' size=5>6. References<\/font><br>     \n\n1. Summers, J. Kevin, et al. \"Conceptualizing holistic community resilience to climate events: Foundation for a climate resilience screening index.\" GeoHealth 1.4 (2017): 151-164.\n2. Dietz, Simon, et al. \"An assessment of climate action by high-carbon global corporations.\" Nature Climate Change 8.12 (2018): 1072-1075.\n3. Elijido-Ten, Evangeline O. \"Does recognition of climate change related risks and opportunities determine sustainability performance?.\" Journal of cleaner production 141 (2017): 956-966.\n\nCredits to [Teresa Kubacka](https:\/\/www.kaggle.com\/tkubacka\/a-story-told-through-a-heatmap) and [Shivam Bansal](https:\/\/www.kaggle.com\/shivamb\/spending-for-ms-in-data-science-worth-it) for awesome visualization ideas!","d50f37ad":"<div id=\"#1\"><\/div>\n<font color='#088a5a' size=5>1. Lessons from Working with Survey Data<\/font><br>            \n\nIn this section, we start with looking at 2 dimensions of city development strategy by analyzing 2 specific questions from the city survey.\n","9c7cbb00":"Interpreting the heatmap:\nOverall, this heatmap above illustrates the distribution of specific clusters of survey takers when it comes to their development priorities. The degree gets higher rightwards and downwards.\n\nMore specificlly,\n - the upper left to lower right diagonal suggests both incorporating sustainability goals and targets into city master planning and collaborating in partnership with businesses at equal weight\n - below the diagonal suggests more focus on collaborations\n - above the diagonal are cities that focus more on planning","03c5646c":"<font color='#088a5a' size=5>Contents<\/font><br>\n\n<a href=\"#1\">1. Lessons from Working with Survey Data<\/a>   \n<a href=\"#2\">2. Modified Green City Index (MGCI): Constructing 8 Axes from CDP Survey<\/a>  \n<a href=\"#3\">3. Analysis on Corporate + City: CDP Answer Mining<\/a>   \n<a href=\"#4\">4. Does setting up plans\/targets promote sustainability performance?<\/a>   \n<a href=\"#5\">5. Concluding Remarks: Actionable Insights<\/a>   \n<a href=\"#6\">6. References<\/a>  ","e4f1d1c3":"<div id=\"#3\"><\/div>\n<font color='#088a5a' size=5>3. Analysis on Corporate + City: CDP Answer Mining<\/font><br>            \n\nIn this section, we dive into the corporate survey data set and check whether there is any kind of synergy\/collaborations with the city governments.\n","a3559b2d":"<div id=\"#4\"><\/div>\n<font color='#088a5a' size=5>4. Does setting up plans\/targets promote sustainability performance?<\/font><br>            \n\nIn this part, we aim to provide empirical evidence on the determinants of sustainability performance.","6cae6140":"Here, we simply normalize the heatmap to percentages.","f02b3061":"We could compare horizontally the heatmaps for cities from different countries relative to the average across all cities surveyed.","f4676303":"Here, we make a instinctive difference between a country (e.g. the US) and global average, and immediately see that the US have on average much <span style=\"background:#3333ff; font-weight:bold; color:white\">more cities with both high priorities in planning and collaborating than average<\/span>, and there are <span style=\"background:#ff3333; font-weight:bold; color:white\">relatively few cities prioritizing heavily on collaborations<\/span> in the country. White cells imply no big difference between the selected group and average case.","052e7eef":"### Main Reasons for Not Having ...\n- plans\n- targets\n- assessments","e19ef7a6":"Similarly, if we take a look at the UK, we will see that on average it has much <span style=\"background:#3333ff; font-weight:bold; color:white\">more cities with higher priorities in collaborating than average<\/span>, and there are <span style=\"background:#ff3333; font-weight:bold; color:white\">relatively few cities prioritizing equally on  planning and collaborations<\/span> in the country.","18bad941":"### Summarize the reasons","8082d0e2":"<div id=\"#5\"><\/div>\n<font color='#088a5a' size=5>5. Concluding Remarks: Actionable Insights<\/font><br>            \n\n\nClimate change and water stress is a present risk to business and cities alike.These environmental changes can give rise to many uncertainties and it is management\u2019s responsibility to consider these uncertainties and how best to respond to them. Companies are increasingly expected to provide information and make relevant disclosures. \n <br>\n \nOur analysis draws upon the Green City Index framework and NLP analytics to construct a meaningful KPI for city development and to understand whether sustainability performance is driven by planning and preparedness. In extending the use of the generic approaches in this analysis, important policy implications could be derived. \n <br>\n\nOverall, the results from this exploratory imply two important insights:\n\n**- Going Beyond Climate Change Risk Management**\n <br>\n \nWhilst a growing number of firms start to take a more proactive stance on climate change, many firms are still adopting a \"wait-and-see\" approach. Our quantitative analyses show that greater awareness and preparedness is what sets superior performers apart. Qualitative content analysis confirm that superior performers provide more detailed description of climate change strategies that go beyond managing climate change risks. The results also support the importance of \"command-and-control\" legislations particularly for poor sustainability performers who are likely to react when environmental\/social issues are perceived as a real threat through mandatory sanctions.\n <br> \n\n**- Seeking collaborative opportunities is exceedingly helpful**\n <br> \n\n In the context of this study,  it is essential to prompt more companies to proactively seek innovative opportunities together with local government to address the challenges brought about by climate change. Voluntary proactive collaborations between business entities and governments could significantly boost sustainability performance.\n \n  <br> \nThe findings from this study, however, are subject to a numberof limitations. Data constraints may limit the validity of some variables. It is also important to acknowledge the inherent limitations of empirical analysis to capture the complexity of numerous dimensions included. Despite these constraints, the insights gathered from here can be useful as a springboard for future in-depth studies. ","a16b91a2":"<div align='center'><font size=\"5\" color='#088a5a'>Unlocking Insights from CDP Surve Data: Measuring Sustainability\n<\/font><\/div>\n<div align='center'><font size=\"4\" color=\"#088a5a\">A detailed comparative analysis on the future of eco-KPIs<\/font><\/div>\n<hr>\n\n<p>The measurement of what we call a city\u2019s \u2018sustainability\u2019 has also changed greatly over time. We might say that sustainability used to be about measuring the level of pollution and the amount of parkland. In the 1990s, many cities began to take a new approach to balancing their environmental, social and economic impact, using metrics not only to measure factors such as energy, water use and pollution but also to address concerns such as crime, employment and health. With the exploding amount of urban data, the metrics have become more complex, and their uses have expanded, particularly as the government addresses a wider range of environmental and social needs. When we measure cities now, we are seeking to understand them in order to manage them better and to provide evidence of performance. Increasingly, we measure cities to understand their sustainability and to make decisions that will allow those who live in them to be happier and healthier in the future. \n <\/p>\n\n<img src='https:\/\/i2.wp.com\/wearerestless.org\/wp-content\/uploads\/2016\/11\/HiRes.jpg?zoom=2&resize=1155%2C770&ssl=1' width=500>\n<div align=\"center\"><font size=\"2\">Source: wearerestless.org<\/font><\/div>  \n\n \nA carefully selected and relatively small number of easily understandable Key Performance Indicators (KPI) is useful for city managers to get a snapshot of the city's performance in different areas. The question of interest in this analysis is: **does setting up plans\/targets promote sustainability performance?**\n\n\n\n\n","c5ace6dd":"<div id=\"#2\"><\/div>\n<font color='#088a5a' size=5>2. Modified Green City Index (MGCI): Constructing 8 Axes from CDP Survey<\/font><br>            \n\nIn this part, we will discuss some of the ways in which cities are being measured and how these metrics could evolve. More importantly, it provides practical examples of what leading cities are doing, the lessons to be learned and how these can be applied to other cities.\n\nTo expolre the intersection between environmental issues and social issues, we referenced the well-known green city index and created a modified version where the proxies used to capture the multi-level indicators are sourced from the 2020 CDP survey data. \n\n![image.png](attachment:image.png)\n\n","dc21ee6f":"While proactive environmental initiatives may create an unique edge, such strategy requires substantial resources, management capabilities and long-term commitment. To achieve this, some cities may choose to cooperate with firms, by pooling resources to create synergies and innovative strategies to boost sustainability. The Venn Diagram above shows the number of cities that take different development strategies.","5873c680":"### Grading multiple choice problems and text answer problems differently\n\nSome survey questions are multiple-choice format, where responders simply take one or more choices; while other questions are generally short answer quetions which require providing further information including, but not limited to, the nature of the risks\/opportunities, what actions have been done\/about to be done, among many others. We deal with these two sets of questions differently, as we compute:\n\n- sentiment scores for short answer questions (i.e., narrative disclosures) using NLP processing\n- numeric scores for multiple choice questions with weights for different options","83126da0":"### Clustering based on effects: Decision Trees","789422bb":"Let's take a brief look at why planning\/assessments were not implemented.","7483ad27":"The responses to the above CDP questions provide a good secondary data source to split the responders into groups with or without early planning. ","772e2c1d":"### City + Business Collaboration: what approaches are adopted?"}}