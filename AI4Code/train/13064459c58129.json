{"cell_type":{"11b414e2":"code","e53ab231":"code","53ad235d":"code","c0d836c3":"code","582679ec":"code","6c73b6ac":"code","7784b486":"code","fe604a6d":"code","4d5a5929":"code","a540c1a3":"code","1abeffa2":"code","e8f4a712":"code","fef4a554":"code","db001243":"code","e0cc7458":"code","3e4d6e23":"code","ca9359c0":"code","02515382":"code","6987e35b":"code","22b76717":"code","85ab9b26":"code","957df5ac":"code","7944ce10":"code","36ff8957":"code","5b35a86d":"code","df09301f":"code","59486b41":"code","fe0e389e":"code","dce4f3e6":"code","926ad6e6":"code","5a5ee18e":"markdown","89d5dca3":"markdown","81316bf0":"markdown"},"source":{"11b414e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('svg')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e53ab231":"raw_df = pd.read_csv('\/kaggle\/input\/stumbleupon\/train.tsv', sep='\\t')\n\ndf = raw_df.copy()\ndel df['framebased']\ndel df['urlid']\ndel df['alchemy_category_score']\ndf['is_news'] = df['is_news'].str.replace('?', '0').astype(int)\n","53ad235d":"df.sample(5).T","c0d836c3":"df.label.mean()","582679ec":"df.alchemy_category.value_counts()","6c73b6ac":"label_mean_by_category = df.groupby('alchemy_category').label.mean().sort_values()\nlabel_mean_by_category","7784b486":"plt.figure(figsize=(12, 8))\nlabel_mean_by_category.plot.barh()","fe604a6d":"df.corr()","4d5a5929":"plt.figure(figsize=(12, 8))\nsns.heatmap(df.corr().abs())","a540c1a3":"plt.figure(figsize=(12, 8))\nsns.heatmap(df.corr().abs()[['label']].sort_values('label'))","1abeffa2":"sns.violinplot(x='label', y=\"linkwordscore\", data=df)","e8f4a712":"features_df = df.drop('label', axis=1)\nnum_features = features_df.select_dtypes(np.number)\nnum_features.columns","fef4a554":"num_features.describe()","db001243":"cat_features = df.select_dtypes(include=[np.object])\ncat_features =  cat_features[['alchemy_category', 'news_front_page']]\ncat_features.sample(5)","e0cc7458":"pd.get_dummies(cat_features)","3e4d6e23":"# More robust way to do feature pre-processing.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\nfeatures_df = df.drop('label', axis=1)\nFEATURE_COLUMNS = features_df.columns\nNUM_FEATURES = features_df.select_dtypes(include=[np.number]).columns\nCAT_FEATURES = ['alchemy_category', 'news_front_page']\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n    ('scaler', StandardScaler()),\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('one_hot', OneHotEncoder(handle_unknown='ignore')),\n])\n\npreprocessor = ColumnTransformer(\n  transformers=[\n      ('num', numeric_transformer, NUM_FEATURES),\n      ('cat', categorical_transformer, CAT_FEATURES)\n  ])","ca9359c0":"features_df = preprocessor.fit_transform(df.drop('label', axis=1))\nfeatures_df.shape","02515382":"#features_df = pd.concat([num_features, pd.get_dummies(cat_features)], axis=1)","6987e35b":"#Normalization \n#features_df = (features_df - features_df.mean())\/ features_df.std()\n#features_df.columns\n#features_df.sample(5)","22b76717":"target = df['label']\ntarget.shape","85ab9b26":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(features_df, target, test_size=0.25)","957df5ac":"from sklearn.dummy import DummyClassifier \n\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nbaseline = DummyClassifier(strategy='most_frequent')\n#model = LogisticRegression()\nmodel = RandomForestClassifier()\n","7944ce10":"baseline.fit(x_train, y_train)\nmodel.fit(x_train, y_train)","36ff8957":"from sklearn.metrics import classification_report \n\nbaseline_predictions = baseline.predict(x_test)\nmodel_predictions = model.predict(x_test)\n","5b35a86d":"print(classification_report(y_test, baseline_predictions))","df09301f":"print(classification_report(y_test, model_predictions))","59486b41":"test_df = pd.read_csv('\/kaggle\/input\/stumbleupon\/test.tsv', sep='\\t')\ntest_df['is_news'] = test_df['is_news'].str.replace('?', '0').astype(int) ","fe0e389e":"sub_model = RandomForestClassifier()\nsub_model.fit(features_df, target)\n\ntest_features = preprocessor.transform(test_df[df.drop('label', axis=1).columns])\npredictions = sub_model.predict(test_features)","dce4f3e6":"sub_df = pd.DataFrame({'urlid' : test_df.urlid, 'label': predictions})\nsub_df.head()","926ad6e6":"sub_df.to_csv('submission.csv', index=False)","5a5ee18e":"## Submition","89d5dca3":"# Data Analysis","81316bf0":"# Modeling"}}