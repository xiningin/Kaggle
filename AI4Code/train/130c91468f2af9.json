{"cell_type":{"031e0cc2":"code","60612752":"code","cca74447":"code","753a2a8b":"code","65ecd77a":"code","46e9ea1f":"code","28c212ca":"code","2b29ef83":"code","f9dee86d":"code","aa972030":"code","39fb045e":"code","ee0e2a4f":"code","826caf73":"code","f14d1fbb":"code","e0e9ecf3":"code","5b4c5a49":"code","e0e77e10":"code","d543ed68":"code","9d1ad415":"code","9b5ef4c6":"code","79eabca4":"markdown","6a82a03d":"markdown"},"source":{"031e0cc2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60612752":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","cca74447":"df = pd.read_csv('..\/input\/diabetescsv\/diabetes.csv')\ndf.head()","753a2a8b":"df.isnull().sum()","65ecd77a":"# Separating Independent and dependent Data\nX = df.drop(['Outcome'],axis = 1).values\ny = df['Outcome'].values\nX[:5]","46e9ea1f":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1234)\nprint(X.shape[0], X_train.shape[0])","28c212ca":"# Preparing the data in Tensor Data Type\nX_train = torch.FloatTensor(X_train)\nX_test  = torch.FloatTensor(X_test)\ny_train = torch.LongTensor(y_train)\ny_test  = torch.LongTensor(y_test)\nprint(X_train.shape)","2b29ef83":"# Neural Net class specifying the architecture of the network\n\nclass ANN_Class(nn.Module):\n    def __init__(self, ilayer0_size, hlayer1_size, hlayer2_size, olayer3_size):\n        super().__init__()\n        \n        self.layer1 = nn.Linear(ilayer0_size, hlayer1_size)\n        self.layer2 = nn.Linear(hlayer1_size, hlayer2_size)\n        self.layer3 = nn.Linear(hlayer2_size, olayer3_size)\n        \n    def forward(self, X):\n        X = F.relu(self.layer1(X))\n        X = F.relu(self.layer2(X))\n        X = self.layer3(X)\n        return X","f9dee86d":"# Instantiating the ANN class object\ntorch.manual_seed(30)\nmodel = ANN_Class(X_train.shape[1], 20, 20, 2)","aa972030":"model.eval()","39fb045e":"lrate = 0.01\nnum_epochs  = 500\n# Initializing the Optimizer and Loss function\nloss   =  nn.CrossEntropyLoss()\noptim  =  torch.optim.Adam(model.parameters(), lr = lrate)","ee0e2a4f":"\nlosses = []\n# Training Loop \nfor epoch in range(num_epochs):\n    \n    # Running the Forward Pass\n    y_preds = model.forward(X_train)\n    \n    # Loss Function\n    loss_func = loss(y_preds, y_train)\n    \n    # Calculating the Gradients of the Parameters w.r.t Loss\n    loss_func.backward()\n    \n    # Updating the weights\n    optim.step()\n    \n    # Nullifying the Gradients of the Parameters\n    optim.zero_grad()\n    \n    # Recording the Losses on each Epoch for plotting purpose\n    losses.append(loss_func)\n    \n    # Printing the Details after every 10 Epochs\n    if epoch % 10 == 0:\n        print(f'Epoch : {epoch+1} and Loss : {loss_func.item()}')","826caf73":"# Plotting the Graph of the Losses\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfigsize = plt.figure(figsize=(12,6))\nplt.plot(range(num_epochs), losses, 'b')\nplt.xlabel('Num of Epochs')\nplt.ylabel('Recorded Losses')","f14d1fbb":"# Prediction of Test Data \npredictions = []\n\nwith torch.no_grad():\n    for i,data in enumerate(X_test):\n        pred = model.forward(data)\n        predictions.append(pred.argmax().item())\n        print(f'Prediction for {i} sample is : \\t{pred.argmax().item()}')","e0e9ecf3":"# Finding the Accuracy of the Test Dataset\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nacc = accuracy_score(predictions, y_test)\nprint(f'Accuracy Score of Test Dataset is {acc}')","5b4c5a49":"conf = confusion_matrix(predictions, y_test)\nfig = plt.figure(figsize=(12,6))\n\nimport seaborn as sns\nsns.heatmap(conf, annot = True)\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')","e0e77e10":"# Saving and Loading the PyTorch Model\n\n# Saving the model into \"PIMA_MODEL.pt\" file\ntorch.save(model, 'PIMA_MODEL.pt')\n\n# Loading the model into \"pt_model\" variable\npt_model = torch.load('PIMA_MODEL.pt')","d543ed68":"# Checking the Architecture of the ANN\npt_model.eval()","9d1ad415":"X_test[:5]","9b5ef4c6":"# Predicting the first 10 Test Data Samples\ntest_data = X_test[:10]\npreds = []\n\nwith torch.no_grad():\n    for i in range(10):\n        test_preds = pt_model.forward(test_data[i])\n        preds.append(test_preds.argmax().item())\n    \n# First 10 Test Predictions\n# 0 1 0 1 0 1 0 0 1 0\n\nprint(f'First 10 test_data predictions are : {preds}')\n    ","79eabca4":"# PyTorch Code Starts here..","6a82a03d":"# Pre-Processing Code Starts here.."}}