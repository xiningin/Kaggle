{"cell_type":{"fa5a4031":"code","de92c1f9":"code","df751b50":"code","e6cca390":"code","a4f6b67c":"code","9d992bb2":"code","0aa1d23c":"code","7e909830":"code","521dda86":"code","0194f790":"code","f270ebac":"code","5122ef9d":"code","f6f5c780":"code","2b9f4dcf":"code","9ef0655c":"code","d7a880e5":"code","ff12822e":"code","ee6490e0":"code","b37bd91a":"code","e7553bf3":"code","f68e6045":"code","9ee58843":"code","661f509d":"code","ec9246a3":"code","02536dd0":"code","de96ad04":"code","29f766a5":"code","3645cf8b":"code","45b56313":"code","afe3f969":"markdown","02497835":"markdown","35fc7aa5":"markdown","81fb4e10":"markdown","884cb4c4":"markdown","a098d319":"markdown","51322ed9":"markdown","23d10aa7":"markdown","d5f9ac5a":"markdown","2e2fa230":"markdown","61006dde":"markdown","da140807":"markdown","196ba222":"markdown","19598314":"markdown","412727e8":"markdown","fe70eff2":"markdown","ab8eb512":"markdown","b10bd8d3":"markdown","11907c9f":"markdown","04bb0609":"markdown","4be65b83":"markdown","7d4d5bc9":"markdown","d731fb97":"markdown","f2316c67":"markdown","9193a9e8":"markdown","d1b7750e":"markdown","48de0e0f":"markdown","878fd05c":"markdown","6f835013":"markdown"},"source":{"fa5a4031":"import pandas as pd\nimport tensorflow as tf\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\n# seaborn is of use for visualizing.\nimport seaborn as sns\n\n# load train, test, and submission sample dataset.\ntrain_csv = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest_csv = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nsubmission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')","de92c1f9":"train_csv","df751b50":"train_csv.isnull().sum()","e6cca390":"train_csv.drop_duplicates()","a4f6b67c":"for i in train_csv.drop(['Id','Pawpularity'],axis=1):\n    sns.countplot(train_csv[i])\n    plt.show()","9d992bb2":"sns.distplot(train_csv['Pawpularity'])","0aa1d23c":"test_csv","7e909830":"test_csv.isnull().sum()","521dda86":"submission","0194f790":"# Set the path for loading image dataset.\nos.chdir('..\/input\/petfinder-pawpularity-score\/train')\n\n# We can find the size of each image data from this procedure\nsize_data = pd.DataFrame()\nfor file in os.listdir():\n    imgg = cv2.imread(file)\n    w,h,c = imgg.shape\n    size_data=size_data.append([[w,h,c,imgg.size\/3]])\nsize_data","f270ebac":"size_data[size_data[3] == size_data[3].min()]","5122ef9d":"size_data[3].value_counts()","f6f5c780":"size_data[size_data[3] == 691200]","2b9f4dcf":"train_img = []\nfor i in os.listdir():\n    file = cv2.imread(i)\n    file=cv2.resize(file,(64,64), interpolation=cv2.INTER_AREA)\n    train_img.append(file\/255)\ntrain_img[:5]","9ef0655c":"train_img_name = []\nfor i in os.listdir():\n    train_img_name.append(i)\ntrain_img_name[:5]","d7a880e5":"for name in train_img_name:\n    if name[-4:] != '.jpg':\n        print(name)","ff12822e":"train_csv_data = pd.DataFrame()\nfor img, name in zip(train_img, train_img_name):\n    name=name[:-4]\n    location = train_csv[train_csv['Id'] == name].index[0]\n    train_csv_data= train_csv_data.append([train_csv.loc[location]])\ntrain_csv_data","ee6490e0":"train_csv_data=train_csv_data.reset_index().drop(['index'],axis=1)\ntrain_csv_data","b37bd91a":"image_1 = cv2.imread('.\/'+train_csv_data['Id'][0]+'.jpg')\nplt.imshow(image_1)","e7553bf3":"plt.imshow(train_img[0])","f68e6045":"image_2 = cv2.imread('.\/'+train_csv_data['Id'][1]+'.jpg')\nplt.imshow(image_2)","9ee58843":"plt.imshow(train_img[1])","661f509d":"os.chdir('..\/test')\n\nfor i in os.listdir():\n    file = cv2.imread(i)\n    print(file.shape)","ec9246a3":"test_img = []\nfor i in os.listdir():\n    file = cv2.imread(i)\n    file=cv2.resize(file,(64,64), interpolation=cv2.INTER_AREA)\n    test_img.append(file\/255)\ntest_img[:5]","02536dd0":"test_img_name = []\nfor i in os.listdir():\n    test_img_name.append(i)\ntest_img_name[:5]","de96ad04":"test_csv_data = pd.DataFrame()\nfor img, name in zip(test_img, test_img_name):\n    name=name[:-4]\n    location = test_csv[test_csv['Id'] == name].index[0]\n    test_csv_data= test_csv_data.append([test_csv.loc[location]])\ntest_csv_data=test_csv_data.reset_index().drop(['index'],axis=1)\ntest_csv_data","29f766a5":"test_1 = cv2.imread('.\/'+test_csv_data['Id'][0]+'.jpg')\nplt.imshow(test_1)","3645cf8b":"plt.imshow(test_img[0])","45b56313":"train_csv_x = train_csv_data.drop(['Id','Pawpularity'],axis=1)\ntrain_y = train_csv_data['Pawpularity']\n\ntest_csv_x = test_csv_data.drop(['Id'],axis=1)","afe3f969":"# Import some libraries for handling dataset.","02497835":"## What is the minimum size?","35fc7aa5":"It's resized and rescaled data.","81fb4e10":"# It has done! \n\nYou are ready to use this dataset as train and test for getting score.\n\nI think you may want to know why test image doesn't seem like animal.\n\nAnd, you will wonder whether this dataset can be a useful resource for analyzing or not.\n\nThe clue will be on next notebook.\n\nAnyway, fingers crossed!","884cb4c4":"## For corresponding the image with each id.\n\nEach image data has to correspond to its own id.","a098d319":"It's original data.","51322ed9":"## Prepare the train input, target and test input.","23d10aa7":"Furthermore, there is no duplicated data.","d5f9ac5a":"It has not null-values, either.","2e2fa230":"# Handling image dataset.","61006dde":"## Load test image dataset and rescaling","da140807":"The target variable of train dataset is distributed as below.\n\nIn this part, you have to determine whether you truncate some outliers or not.\n\nHowever, I recommend that you don't truncate because I think those are a part of dataset, too.\n\nWe don't know what the truncated data affects in using deep learning.\n\nIt's just on my experience so, you can select and it's all up to you!","196ba222":"Below procedure is identical with train dataset.","19598314":"## Glancing the test dataset.","412727e8":"It's resized and rescaled data.","fe70eff2":"## Glancing the train csv dataset.\n\nAll columns contain binary values except for 'Id' and 'Pawpularity'","ab8eb512":"## Load train image dataset and rescaling.\n\nThis part is crucial for analysis and is devided into 3 parts.\n\n1. Loading the image dataset.\n\n2. Changing the shape of each image into 64 * 64.\n\n- Why 64 * 64 ?? the reason is that you will stuck in memory allocation.\n\n- That is, there are so many image dataset which make your memory be exploded.\n\n- So, reszing the image into 64 * 64, you can take your memory with sufficient.\n\n3. Rescaling the pixels by deviding with 255.\n\nIn this procedure, the parameter, cv2.INTER_AREA, is useful for interpolation.\n\nThere are several interpolation methods, but I recommend this.","b10bd8d3":"## Count the binary values.\n\nAll data is unbalanced, but you don't have to worry about that.\n\nI will expalin the reason why it is okay in next notebook (coming soon).","11907c9f":"# Read me\n\nHello, This is for begginers who want to know how you can handle this dataset which consists of some csv file and image datasaet.\n\nThis notebook is just for handling data such as loading the dataset, stacking dataset, and etc...\n\nIt will be helpful for preparing analysis to someone who wants to submit.\n\nFurthermore, I will upload the deep learning model through this data handling procedure for getting score.\n\nIf you have any questions, please leave the comments.\n\n\nYou can learn about using deep learning through my previous notebook (it is for titanic analysis).\n\n## [Data handling & Deep learning]\n - https:\/\/www.kaggle.com\/pythonash\/how-to-handle-raw-dataset-and-analyze-with-dl\n \n## [Preparing a completed dataset with proper imputation method]\n - https:\/\/www.kaggle.com\/pythonash\/making-completed-dataset\n \n## [Deep learning model with SeLU activation function]\n- https:\/\/www.kaggle.com\/pythonash\/selu-activation-function-in-dl\n\n**Let's start!**","04bb0609":"## Checking the pixel structure of that.\n\n- It is derived from 960 * 720.","4be65b83":"## Checking the file name.\n\nBefore we match the image data with its own id, we have to check the file name whether file name has identical rule or not.\n\nIf a file name has not '.jpg', it will be shown.","7d4d5bc9":"## Finally, Let's identify the submission form.","d731fb97":"## What is the number of most things?","f2316c67":"## Matching the image dataset order with csv file order.","9193a9e8":"It's original data.","d1b7750e":"What is the shape of test dataset??\n\nIt's (128, 128, 3), but we have to resize the test image into 64 * 64 because of memory allocation problem.\n\nFor analyzing the test dataset, we will match the sizes of both train image and test image, identically.","48de0e0f":"Wow, there is no null-value.\n\nSo, we don't have to mind about imputation.","878fd05c":"## Checking the resized and rescaled image with original image data.","6f835013":"Reindexing the train csv data."}}