{"cell_type":{"939e441a":"code","5f9400be":"code","1b492e8d":"code","ca252c18":"code","a5c95fba":"code","70ccb83d":"code","d107b077":"code","3450efb7":"code","0c04d77a":"code","7efc00d7":"code","4f6cfa0b":"code","f9cf42d8":"code","f1737f58":"code","db25d7e2":"code","3a1b1a60":"code","9e6d4ec2":"code","37e6ae06":"code","59e8c0fa":"code","e27387a8":"code","3f53ab7a":"code","945400b5":"code","3cd007d5":"code","23b65913":"code","7099153c":"code","8d173b14":"code","b4a53780":"code","b472f181":"code","799cd308":"code","6e69f707":"code","5844437d":"code","68d43990":"code","35006e15":"code","53ccbbc4":"code","63f16e58":"code","0a617e00":"code","7000a875":"markdown","8aefbf74":"markdown","33db58f0":"markdown","88a42dec":"markdown","574d77ff":"markdown","fe32b9b1":"markdown","044e628c":"markdown","74ec2a08":"markdown","fdbd2a73":"markdown","798ef414":"markdown","d6d62562":"markdown","f9d60b31":"markdown","6dde1736":"markdown","d9c93754":"markdown","f8fe63e6":"markdown","08260b46":"markdown","a7e260f4":"markdown","0315e2bd":"markdown"},"source":{"939e441a":"# Importing libraries\nimport numpy as np\nimport pandas as pd\n\n# Importing the visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Importing the model building libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\n\n# Importing the warning library\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5f9400be":"# Reading the file\nsurprise_housing_df = pd.read_csv(\"..\/input\/house-price-prediction\/train.csv\")\nsurprise_housing_df.head()","1b492e8d":"# Checking the basic information\nsurprise_housing_df.info()","ca252c18":"# Function to return columns with null values\ndef columns_with_missing_values():\n    total = surprise_housing_df.isnull().sum().sort_values(ascending=False)\n    percent = round(surprise_housing_df.isnull().sum()*100\/len(surprise_housing_df), 2).sort_values(ascending=False)\n    \n    all_features = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    all_features = all_features[all_features.Total != 0]\n    \n    if len(all_features) == 0:\n        return 'No Column with Missing Values.'\n    return all_features\n   \n# Printing columns with null values\ncolumns_with_missing_values()","a5c95fba":"# List of columns with NA has a definition in the sheet\ncolumns_with_meaningfull_null = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageCond\", \"GarageType\", \n          \"GarageFinish\", \"GarageQual\", \"BsmtFinType2\", \"BsmtExposure\", \"BsmtQual\", \"BsmtFinType1\",\n          \"BsmtCond\", \"MasVnrType\"]\n\nfor column in columns_with_meaningfull_null:\n    before = surprise_housing_df[column].isnull().sum()\n    surprise_housing_df[column].fillna(\"None\", inplace=True)\n    print(before, \"missing values of\", column ,\"imputed.\")\n\n# Printing columns with null values\ncolumns_with_missing_values()","70ccb83d":"# List of columns where Median values can be imputed\ncolumns_with_not_meaningfull_null = [\"GarageYrBlt\", \"MasVnrArea\"]\n\nfor column in columns_with_not_meaningfull_null:\n    before = surprise_housing_df[column].isnull().sum()\n    surprise_housing_df[column].fillna(surprise_housing_df[column].median(), inplace=True)\n    print(before, \"missing values of\", column ,\"imputed.\")\n\n# Printing columns with null values\ncolumns_with_missing_values()","d107b077":"# Dropping column with a lot of missing values\nsurprise_housing_df.drop(columns=[\"LotFrontage\"], inplace=True)\n\n# Printing columns with null values\ncolumns_with_missing_values()","3450efb7":"# Removing one row with no straight forward imputation technique\nsurprise_housing_df.dropna(inplace=True)\n\n# Printing columns with null values\ncolumns_with_missing_values()","0c04d77a":"# Making all continuous columns (integer and float) in one dataset \nsurprise_housing_num_df = surprise_housing_df.select_dtypes(include=['float64', 'int64'])\nprint(\"Shape :\", surprise_housing_num_df.shape)\n\nsurprise_housing_num_df.head()","7efc00d7":"# Dropping the 'Id' column\nsurprise_housing_num_df.drop(columns=[\"Id\"], inplace=True)","4f6cfa0b":"# Target column name\nsale_price_column = \"SalePrice\"","f9cf42d8":"# Numerical column data analysis\nplt.figure(figsize=(30, 50))\n\ncount = 1\n\nfor column in surprise_housing_num_df.columns:\n    if column != sale_price_column:\n        plt.subplot(10, 4, count)\n        sns.scatterplot(surprise_housing_df[column], surprise_housing_df[sale_price_column], alpha = 0.3).set(ylabel=None, xlabel=None)\n        plt.title(column + \" vs \" + sale_price_column, weight='bold')\n        count += 1\n    \nplt.show()","f1737f58":"# Correlation graph\nfig = plt.figure(figsize=(25,23),dpi=150)\n\nplt.rc('xtick', labelsize=16)\nplt.rc('ytick', labelsize=16)\n\nsns.heatmap(surprise_housing_num_df.corr(), annot = True, cmap=\"Blues\",fmt='.1f')\nplt.show()","db25d7e2":"# Making all categoric variables (object) in one dataset \nsurprise_housing_obj_df = surprise_housing_df.select_dtypes(exclude=['float64', 'int64'])\nprint(\"Shape\", surprise_housing_obj_df.shape)\n\nsurprise_housing_obj_df.head()","3a1b1a60":"# Categorical column data analysis\nplt.figure(figsize=(30, 50))\n\ncount = 1\n\nfor column in surprise_housing_obj_df.columns:\n    if column != sale_price_column:\n        plt.subplot(11, 4, count)\n        sns.boxplot(x=surprise_housing_df[column], y=surprise_housing_df[sale_price_column]).set(ylabel=None, xlabel=None)\n        plt.title(column, weight='bold')\n        count += 1\n    \nplt.show()","9e6d4ec2":"# Target variable data analysis\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nsns.distplot(surprise_housing_df[sale_price_column]).ticklabel_format(useOffset=False, style='plain')\nplt.title(\"Original\", weight='bold')\n\nplt.subplot(1, 2, 2)\nsns.distplot(np.log(surprise_housing_df[sale_price_column]))\nplt.title(\"Logrithmic\", weight='bold')\n\nplt.show()","37e6ae06":"# Target column (transformed) name\nconverted_sale_price_column = \"ConvertedSalePrice\"\n\nsurprise_housing_num_df[converted_sale_price_column] = np.log(surprise_housing_num_df[sale_price_column])\nsurprise_housing_num_df[[sale_price_column, converted_sale_price_column]].head()","59e8c0fa":"# Creating dummy variables for categorical variables\nsurprise_housing_dummies = pd.get_dummies(surprise_housing_obj_df, drop_first=True)\nprint(\"Shape\", surprise_housing_dummies.shape)\n\nsurprise_housing_dummies.head()","e27387a8":"# Making the final clean dataset to build the model \nsurprise_housing_df=pd.concat([surprise_housing_num_df, surprise_housing_dummies],axis=1)\nsurprise_housing_df.head()","3f53ab7a":"# Scaling the numerical column\nscaler = StandardScaler()\n\ncols = list(surprise_housing_df.columns.values)\ncols.remove(sale_price_column)\ncols.remove(converted_sale_price_column)\n\nsurprise_housing_df[cols] = scaler.fit_transform(surprise_housing_df[cols])\nsurprise_housing_df.head()","945400b5":"X = surprise_housing_df.drop([sale_price_column, converted_sale_price_column], axis=1).values\ny = surprise_housing_df[converted_sale_price_column].values\n\n# split into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size = 0.3, random_state=42)\n\n# list of alphas to tune\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}","3cd007d5":"# Applying Lasso\nlasso = Lasso()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = lasso, param_grid = params, scoring= 'neg_mean_absolute_error', \n                        cv = folds, return_train_score=True, verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","23b65913":"# CV results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results[['params', 'mean_train_score', 'mean_test_score']].head()","7099153c":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","8d173b14":"# Best alpha value\nmodel_cv.best_params_","b4a53780":"# Lasso Model for best param\nlasso = Lasso(alpha=model_cv.best_params_['alpha'])\nlasso.fit(X_train, y_train)\n\ny_pred_lasso_train=lasso.predict(X_train)\nprint('Train R2 Square : ', round(r2_score(y_train, y_pred_lasso_train),2))\n\ny_pred_lasso_test=lasso.predict(X_test)\nprint('Test R2 Square : ', round(r2_score(y_test, y_pred_lasso_test),2))","b472f181":"# Lasso model parameters\nmodel_parameters = list(lasso.coef_)\nmodel_parameters.insert(0, lasso.intercept_)\nmodel_parameters = [round(x, 3) for x in model_parameters]\ncols = surprise_housing_df.columns\ncols = cols.insert(0, \"constant\")\nvar_coeff = [x for x in list(zip(cols, model_parameters)) if abs(x[-1] != 0)]\nlasso_params = pd.DataFrame({'Feature':list(list(zip(*var_coeff))[0]),'Coeff':list(list(zip(*var_coeff))[1])})\nlasso_params.reindex(lasso_params.Coeff.abs().sort_values(ascending = False).index)","799cd308":"sns.distplot((y_train-y_pred_lasso_train))\nplt.show()","6e69f707":"# Applying Ridge\nridge = Ridge()\n\n# Cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, param_grid = params, scoring= 'neg_mean_absolute_error', \n                        cv = folds, return_train_score=True, verbose = 1)    \n\nmodel_cv.fit(X_train, y_train) ","5844437d":"# CV results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results[['params', 'mean_train_score', 'mean_test_score']].head()","68d43990":"# plotting mean test and train scores with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","35006e15":"# Best alpha value\nmodel_cv.best_params_","53ccbbc4":"# Ridge Model for best param\nridge = Ridge(alpha=model_cv.best_params_['alpha'])\nridge.fit(X_train, y_train)\n\ny_pred_ridge_train=ridge.predict(X_train)\nprint('Train R2 Square : ', round(r2_score(y_train, y_pred_ridge_train),2))\n\ny_pred_ridge_test=ridge.predict(X_test)\nprint('Test R2 Square : ', round(r2_score(y_test, y_pred_ridge_test),2))","63f16e58":"# Ridge model parameters\nmodel_parameters = list(ridge.coef_)\nmodel_parameters.insert(0, ridge.intercept_)\nmodel_parameters = [round(x, 3) for x in model_parameters]\ncols = surprise_housing_df.columns\ncols = cols.insert(0, \"constant\")\nvar_coeff = [x for x in list(zip(cols, model_parameters)) if abs(x[-1] != 0)]\nridge_params = pd.DataFrame({'Feature':list(list(zip(*var_coeff))[0]),'Coeff':list(list(zip(*var_coeff))[1])})\nridge_params.reindex(ridge_params.Coeff.abs().sort_values(ascending = False).index)","0a617e00":"sns.distplot((y_train-y_pred_ridge_train))\nplt.show()","7000a875":"## Data Sourcing","8aefbf74":"## Data Definition\n\nA US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. \n\nThe company wants to know the following things about the prospective properties:\n* Which variables are significant in predicting the price of a house, and\n* How well those variables describe the price of a house.\n\nAlso, determine the optimal value of lambda for ridge and lasso regression.","33db58f0":"#### Finding Missing Values","88a42dec":"#### Removing Meaningful Columns - NA means None","574d77ff":"#### Removing Non Meaningful Columns","fe32b9b1":"#### Plotting Categorical Columns","044e628c":"#### Removing One Row - Electrical","74ec2a08":"#### Dropping 'LotFrontage' Column","fdbd2a73":"## Data Preparation","798ef414":"#### Ridge Regression","d6d62562":"#### Lasso Regression","f9d60b31":"## Model Building","6dde1736":"## Data Analysis","d9c93754":"## Data Cleaning","f8fe63e6":"#### Understanding the Data","08260b46":"#### Plotting Numerical Columns","a7e260f4":"#### Scaling Columns","0315e2bd":"#### Plotting Correlation"}}