{"cell_type":{"99945043":"code","94cf3ba1":"code","96948935":"code","334ddd6e":"code","43253457":"code","aeca7b4b":"code","155dec87":"code","c8d16228":"code","efefe0a2":"code","3b6dc27f":"code","9ae41104":"code","45f3e067":"code","c4488868":"code","bac2065b":"code","0de6d23b":"code","30138219":"code","493e55cd":"code","62b3a687":"code","ca7e6071":"code","db609725":"code","75e1526b":"code","60255742":"code","7a5eb6f5":"code","54632345":"code","8a08174d":"code","22078412":"markdown","05acbbbe":"markdown","bffa1524":"markdown","1ff844c1":"markdown","4cbc7bff":"markdown","47274efa":"markdown"},"source":{"99945043":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94cf3ba1":"dataset=pd.read_csv(\"..\/input\/churn-predictions-personal\/Churn_Predictions.csv\")","96948935":"dataset.head(5)","334ddd6e":"import seaborn as sns\nsns.pairplot(dataset)","43253457":"sns.catplot(x=\"IsActiveMember\", y=\"Balance\", col=\"Exited\",\n                data=dataset, kind=\"box\",height=4, aspect=.7,hue=\"NumOfProducts\")","aeca7b4b":"X = dataset.drop([\"RowNumber\",\"CustomerId\",\"Surname\",\"Exited\"], axis=1)","155dec87":"X.head(5)","c8d16228":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nX[\"Gender\"]= le.fit_transform(X[\"Gender\"])","efefe0a2":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])], remainder=\"passthrough\")\nX=np.array(ct.fit_transform(X))","3b6dc27f":"y= dataset[(\"Exited\")]\ny.head(5)","9ae41104":"y=y.values.reshape(-1,1)","45f3e067":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_scaled = sc.fit_transform(X)","c4488868":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=0)","bac2065b":"import tensorflow.keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n","0de6d23b":"# Initiate the sequential model\nmodel = Sequential()\n# add input layers\nmodel.add(Dense(units=25,activation=\"relu\"))\nmodel.add(Dense(units=25,activation=\"relu\"))\nmodel.add(Dense(units=1,activation=\"sigmoid\"))","30138219":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=['accuracy'])","493e55cd":"epochs_hist= model.fit(X_train,y_train,epochs=100,batch_size=25)","62b3a687":"epochs_hist.history.keys()","ca7e6071":"import matplotlib.pyplot as plt\nplt.plot(epochs_hist.history[\"loss\"])\nplt.title('Model Loss Progression During Training')\nplt.ylabel('Training Loss')\nplt.xlabel('Epoch Number')\nplt.legend(['Training Loss'])","db609725":"plt.plot(epochs_hist.history[\"accuracy\"])\nplt.title('Model Accuracy plot')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch Number')\nplt.legend(['Training Accuracy'])","75e1526b":"y_pred=model.predict(X_test)","60255742":"y_pred","7a5eb6f5":"# Converting y_pred to binary\ny_pred = (y_pred > 0.5)","54632345":"from sklearn.metrics import confusion_matrix,accuracy_score\n\ncm=confusion_matrix(y_pred,y_test)\nprint(cm)\n","8a08174d":"accuracy_score(y_pred,y_test)","22078412":"One Hot encoding the Geography column ","05acbbbe":"**Build the ANN Model**","bffa1524":"**Feature Scaling**","1ff844c1":"**Drop unnecessary columns**","4cbc7bff":"**Splitting the dataset into train and test**","47274efa":"Encoding the Gender column"}}