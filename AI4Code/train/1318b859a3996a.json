{"cell_type":{"284e37d5":"code","ef6a006d":"code","094c5164":"code","e14306b6":"code","50e3a560":"code","f4a65109":"code","3b5fa156":"code","133d80e0":"code","2e9f61af":"code","dd709cf8":"code","457093ef":"code","609b09e4":"markdown","7bd6ceb5":"markdown","62b94871":"markdown","afd3ee70":"markdown","353c7966":"markdown","07b4ca6b":"markdown"},"source":{"284e37d5":"import os\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.experimental import enable_halving_search_cv\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import make_scorer\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.multioutput import MultiOutputClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import HalvingGridSearchCV\n\nfrom sklearn.ensemble import BaggingClassifier\n\n\nimport xgboost as xgb","ef6a006d":"file_location = r'..\/input\/palmer-archipelago-antarctica-penguin-data\/penguins_size.csv'\n\npredictor_columns = ['island', 'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\ntarget_column = ['species']","094c5164":"# Open and clean\ndata = pd.read_csv(file_location)\ndata = data.dropna()\ndata = data[data.sex != '.']","e14306b6":"raw_X = np.array(data[predictor_columns])\nraw_Y = np.array(data[target_column])","50e3a560":"# One-hot encode target variable\nbinarizer = MultiLabelBinarizer(classes=['Adelie', 'Chinstrap', 'Gentoo'])\nencoded_Y = binarizer.fit_transform(raw_Y)","f4a65109":"# One-hot encode the categorical columns\nencoder = OneHotEncoder(handle_unknown='ignore')\nencoder.fit(raw_X[:, [0, 5]])","3b5fa156":"# Combine the data\nnew_X_categroical_columns = encoder.transform(raw_X[:, [0, 5]]).toarray()\nold_X_value_columns = raw_X[:, 1:5].astype(np.dtype(float))\nencoded_X = np.concatenate((new_X_categroical_columns, old_X_value_columns), axis=1)","133d80e0":"base_model = xgb.XGBClassifier(use_label_encoder=False,\n                               eval_metric = 'logloss',\n                               eta=0.3,\n                               max_depth=3,\n                               subsample=0.65,\n                               grow_policy='lossguide',\n                               max_leaves=1,\n                               booster='dart',normalize_type='forest',rate_drop=0.001)\nparameters = base_model.get_params()\nparams = {'classify__estimator__' + parameter:value for (parameter, value) in parameters.items()}","2e9f61af":"# Set up our pipeline of just one model\nclassifier = MultiOutputClassifier(xgb.XGBClassifier(), n_jobs=1)\nmodel = Pipeline([('classify', classifier)])\n_ = model.set_params(**params)\n\n# Our model!\nmodel = model","dd709cf8":"f1_micro = make_scorer(f1_score, average='micro')\n\ncv_results = cross_validate(model, encoded_X, encoded_Y, scoring=f1_micro, cv=10, n_jobs=4)\nprint(f'Mean Error: {np.mean(cv_results[\"test_score\"])}')","457093ef":"np.random.seed(seed=8)\n\nX_train, X_test, Y_train, Y_test = train_test_split(encoded_X, encoded_Y)\n\nmodel.fit(X_train, Y_train)\n\npredictions = model.predict(X_test)\nerror = f1_score(Y_test, predictions, average='micro')\nprint(f'Train-Test split error: {error}')","609b09e4":"# Setup\n\nImport some libraries","7bd6ceb5":"# Model Design\nThis is my final model. I explained the details in the overview section.","62b94871":"# Validation\n10-fold CV!","afd3ee70":"# Aaron Spaulding Palmer Penguin Model\n\nThe goal is to predict species of penguin.\n\n# Overview\n## Import data\n* Open data\n* Clean\n    * Remove 'na'\n    * Remove '.'\n* Binarize the target variable to a one-hot encoding\n* One-hot encode the categorical variables in the train data\n    * 'sex'\n    * 'island'\n* One-hot encode the target variable 'species'\n\n## Build the model\nMy final model is an ensemble of three gradient boosting machines (GBMs) where each GBM is assigned one species label. The final species label is then assigned by picking the model that predicts the highest probability.\n\nTo simplify this I use the 'MultiOutputClassifier' from sklearn.\n\n## Validate the model\n### Method\nThis model is validated using a 10-fold cross-validation (CV).\n### Metric\nSince we are doing multi-species classification we need a suitable metric. I use micro-weighted F1. This is the same metric used in the Cornell bird detection competition.\n### Why not a train-test split?\nThe 10-fold CV was chosen since a train-test split may make a model with weak predicitve performance appear otherwise. To highlight this I use my model and show how it appears to have 100% accuracy. This occurs since the chosen test set may not be a good representation of the entire set.\n","353c7966":"# Why not use a train-test split?\nThis is a simple demo to show how a train-test split can be deceiving.\n\nI use the same model and train\/test on a train-test split. If this was our only validation method we might be led to believe that this model is perfect. However this would be incorrect.","07b4ca6b":"## Import data"}}