{"cell_type":{"20c60c5a":"code","70c30999":"code","9107475e":"code","ac1fe8f1":"code","ec3a147e":"code","b94f3415":"code","5953c3b6":"code","b59a2550":"code","57774a82":"code","36ed06c7":"code","5d5a1b7a":"code","ea7626ea":"code","3ce24e55":"code","43ea5661":"code","b279764f":"code","6a8d52f6":"code","95ae114a":"markdown","c7ff9e09":"markdown","4b993bb8":"markdown","3a8b11f5":"markdown","de2aced7":"markdown","8bf3b558":"markdown","6c497e23":"markdown","7de59426":"markdown","e6b83047":"markdown","5b435599":"markdown","c139965b":"markdown"},"source":{"20c60c5a":"## Pretrained weight from version 1 of notebook . trained for 3 epochs\n!ls ..\/input\/3dpretrained\/fold0_epoch_26_0.1700.pth.tar","70c30999":"!pip install monai\n!pip install nilearn","9107475e":"'''\nWritten by SeuTao\n'''\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n","ac1fe8f1":"class Config :\n    '''\nConfigs for training & testing\nWritten by Whalechen\nModified By Nirjhar for Kaggle Kernel\n'''\n\n    data_root ='.\/toy_data'\n    img_list = '.\/toy_data\/test_ci.txt',\n    n_seg_classes=2\n    learning_rate=0.001\n    phase='train'\n    save_intervals=10\n    input_D=56\n    input_H=448\n    input_W=448\n    resume_path=''#'.\/TReNDs\/exp1\/models_resnet_10_B_fold_1\/epoch_13_batch_134_loss_0.1707041710615158.pth.tar'\n    pretrain_path= None\n    new_layer_names=['conv_seg']\n    no_cuda = False\n    gpu_id = [1,2]\n    model='resnet'\n    model_depth=18# help='Depth of resnet (10 | 18 | 34 | 50 | 101)')\n#    resnet_shortcut='B' #help='Shortcut type of resnet (A | B)')\n    manual_seed=1\n    ci_test =True\n    model_name = 'exp1'\n    fold_index = 0\n    no_cuda = False\n    pretrain_path = ''# '..\/input\/3dpretrained\/fold0_epoch_26_0.1700.pth.tar'## This is pretrained model provided by Seutao\n\n    batch_size = 32\n    num_workers = 0\n    model_depth = 34\n    resnet_shortcut = 'B'\n\n    n_epochs = 2\n    fold_index = 0\n\n    model_name = r'prue_3dconv'\n    save_folder = r'.'\n\n#if not os.path.exists(Config.save_folder):\n#        os.makedirs(Config.save_folder)\n        \n## Load Config        \nConfig = Config()","ec3a147e":"##Datasets\nimport os\nimport h5py\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold,StratifiedKFold, GroupKFold, KFold\nimport nilearn as nl\nimport torch\nimport random\nfrom tqdm import tqdm\n\nimport monai\nfrom monai.transforms import \\\n    LoadNifti, LoadNiftid, AddChanneld, ScaleIntensityRanged, \\\n    Rand3DElasticd, RandAffined, \\\n    Spacingd, Orientationd\n\nroot = r'..\/input\/trends-assessment-prediction'\n\ntrain_df = pd.read_csv('{}\/train_scores.csv'.format(root)).sort_values(by='Id')\nloadings = pd.read_csv('{}\/loading.csv'.format(root))\nsample = pd.read_csv('{}\/sample_submission.csv'.format(root))\nreveal = pd.read_csv('{}\/reveal_ID_site2.csv'.format(root))\nICN = pd.read_csv('{}\/ICN_numbers.csv'.format(root))\n\n\"\"\"\n    Load and display a subject's spatial map\n\"\"\"\n\ndef load_subject(filename, mask_niimg):\n    \"\"\"\n    Load a subject saved in .mat format with the version 7.3 flag. Return the subject niimg, using a mask niimg as a template for nifti headers.\n    Args:\n        filename    <str>            the .mat filename for the subject data\n        mask_niimg  niimg object     the mask niimg object used for nifti headers\n    \"\"\"\n    subject_data = None\n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n        # print(subject_data.shape)\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0, 1, 2, 3], [3, 2, 1, 0])\n    # print(subject_data.shape)\n    return subject_data\n    # subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    # return subject_niimg\n\ndef read_data_sample():\n    # Input data files are available in the \"..\/input\/\" directory.\n    # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n    mask_filename = r'{}\/fMRI_mask.nii'.format(root)\n    subject_filename = '{}\/fMRI_train\/10004.mat'.format(root)\n\n    mask_niimg = nl.image.load_img(mask_filename)\n    print(\"mask shape is %s\" % (str(mask_niimg.shape)))\n\n    subject_niimg = load_subject(subject_filename, mask_niimg)\n    print(\"Image shape is %s\" % (str(subject_niimg.shape)))\n    num_components = subject_niimg.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n\nclass TReNDsDataset(Dataset):\n\n    def __init__(self, mode='train', fold_index = 0):\n        # print(\"Processing {} datas\".format(len(self.img_list)))\n        self.mode = mode\n        self.fold_index = fold_index\n\n        if self.mode=='train' or self.mode=='valid' or self.mode=='valid_tta':\n            features = ('age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2')\n            data = pd.merge(loadings, train_df, on='Id').dropna()\n            id_train = list(data.Id)\n            fea_train = np.asarray(data.drop(list(features), axis=1).drop('Id', axis=1))\n            lbl_train = np.asarray(data[list(features)])\n\n            self.all_samples = []\n            for i in range(len(id_train)):\n                id = id_train[i]\n                fea = fea_train[i]\n                lbl = lbl_train[i]\n                filename = os.path.join('{}\/fMRI_train\/{}.mat'.format(root, id))\n                self.all_samples.append([filename, fea, lbl, str(id)])\n\n            fold = 0\n            kf = KFold(n_splits=5, shuffle=True, random_state=1337)\n            for train_index, valid_index in kf.split(self.all_samples):\n                if fold_index == fold:\n                    self.train_index = train_index\n                    self.valid_index = valid_index\n                fold+=1\n\n            if self.mode=='train':\n                self.train_index = [tmp for tmp in self.train_index if os.path.exists(self.all_samples[tmp][0])]\n                self.len = len(self.train_index)\n                print('fold index:',fold_index)\n                print('train num:', self.len)\n\n            elif self.mode=='valid' or self.mode=='valid_tta':\n                self.valid_index = [tmp for tmp in self.valid_index if os.path.exists(self.all_samples[tmp][0])]\n                self.len = len(self.valid_index)\n                print('fold index:',fold_index)\n                print('valid num:', self.len)\n\n        elif  self.mode=='test':\n            labels_df = pd.read_csv(\"{}\/train_scores.csv\".format(root))\n            labels_df[\"is_train\"] = True\n\n            features = ('age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2')\n            data = pd.merge(loadings, labels_df, on=\"Id\", how=\"left\")\n\n            id_test = list(data[data[\"is_train\"] != True].Id)\n            fea_test = np.asarray(data.drop(list(features), axis=1).drop('Id', axis=1)[data[\"is_train\"] != True].drop(\"is_train\", axis=1))\n            lbl_test = np.asarray(data[list(features)][data[\"is_train\"] != True])\n\n            self.all_samples = []\n            for i in range(len(id_test)):\n                id = id_test[i]\n                fea = fea_test[i]\n                lbl = lbl_test[i]\n\n                filename = os.path.join('{}\/fMRI_test\/{}.mat'.format(root, id))\n                if os.path.exists(filename):\n                    self.all_samples.append([id, filename, fea, lbl])\n\n            self.len = len(self.all_samples)\n            print(len(id_test))\n            print('test num:', self.len)\n\n    def __getitem__(self, idx):\n        \n        def get_data(filename):\n            with h5py.File(filename, 'r') as f:\n                subject_data = f['SM_feature'][()]\n                # print(subject_data.shape)\n                # It's necessary to reorient the axes, since h5py flips axis order\n            subject_data = np.moveaxis(subject_data, [0, 1, 2, 3], [3, 2, 1, 0])\n            return subject_data        \n\n        if self.mode == \"train\" :\n            filename, fea, lbl, id =  self.all_samples[self.train_index[idx]]\n            train_img = get_data(filename)\n            train_img = train_img.transpose((3,2,1,0))\n            # (53, 52, 63, 53)\n            train_lbl = lbl\n\n            data_dict = {'image':train_img}\n            rand_affine = RandAffined(keys=['image'],\n                                      mode=('bilinear', 'nearest'),\n                                      prob=0.5,\n                                      spatial_size=(52, 63, 53),\n                                      translate_range=(5, 5, 5),\n                                      rotate_range=(np.pi * 4, np.pi * 4, np.pi * 4),\n                                      scale_range=(0.15, 0.15, 0.15),\n                                      padding_mode='border')\n            affined_data_dict = rand_affine(data_dict)\n            train_img = affined_data_dict['image']\n\n            return torch.FloatTensor(train_img), \\\n                   torch.FloatTensor(train_lbl),\\\n                   torch.FloatTensor(fea) \n\n\n        elif self.mode == \"valid\":\n            filename, fea, lbl, id =  self.all_samples[self.valid_index[idx]]\n            train_img = get_data(filename)\n            train_img = train_img.transpose((3, 2, 1, 0))\n            # (53, 52, 63, 53)\n            train_lbl = lbl\n\n            return torch.FloatTensor(train_img),\\\n                   torch.FloatTensor(train_lbl),\\\n                   torch.FloatTensor(fea) \n\n        elif self.mode == 'test':\n            id, filename, fea, lbl =  self.all_samples[idx]\n            test_img = get_data(filename)\n            test_img = test_img.transpose((3, 2, 1, 0))\n\n            return str(id), \\\n                   torch.FloatTensor(test_img),\\\n                   torch.FloatTensor(fea) \n\n    def __len__(self):\n        return self.len\n\ndef run_check_datasets():\n    dataset = TReNDsDataset(mode='test')\n    for m in range(len(dataset)):\n        tmp = dataset[m]\n        print(m)\n\ndef convert_mat2nii2npy():\n\n    def get_data(filename):\n        with h5py.File(filename, 'r') as f:\n            subject_data = f['SM_feature'][()]\n            # print(subject_data.shape)\n        # It's necessary to reorient the axes, since h5py flips axis order\n        subject_data = np.moveaxis(subject_data, [0, 1, 2, 3], [3, 2, 1, 0])\n        return subject_data\n\n    # train_root = '{}\/fMRI_train\/'.format(root)\n    # train_npy_root = '{}\/fMRI_train_npy\/'.format(root)\n    train_root = '{}\/fMRI_test\/'.format(root)\n    train_npy_root = '{}\/fMRI_test_npy\/'.format(root)\n    os.makedirs(train_npy_root, exist_ok=True)\n\n    mats = os.listdir(train_root)\n    mats = [mat for mat in mats if '.mat' in mat]\n    random.shuffle(mats)\n\n    for mat in tqdm(mats):\n        mat_path = os.path.join(train_root, mat)\n        if os.path.exists(mat_path):\n            print(mat_path)\n\n        npy_path = os.path.join(train_npy_root, mat.replace('.mat','.npy'))\n        if os.path.exists(npy_path):\n            print(npy_path, 'exist')\n        else:\n            data = get_data(mat_path)\n            print(npy_path,data.shape)\n            np.save(npy_path,data.astype(np.float16))","b94f3415":"#run_check_datasets() ## Uncomment this to check dataset. it will take some time .\n","5953c3b6":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom functools import partial\n\n__all__ = [\n    'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n    'resnet152', 'resnet200'\n]\n\ndef conv3x3x3(in_planes, out_planes, stride=1, dilation=1):\n    # 3x3x3 convolution with padding\n    return nn.Conv3d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        dilation=dilation,\n        stride=stride,\n        padding=dilation,\n        bias=False)\n\ndef downsample_basic_block(x, planes, stride, no_cuda=False):\n    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n    zero_pads = torch.Tensor(out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)).zero_()\n    if not no_cuda:\n        if isinstance(out.data, torch.cuda.FloatTensor):\n            zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n    return out\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.conv2 = nn.Conv3d(\n            planes, planes, kernel_size=3, stride=stride, dilation=dilation, padding=dilation, bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm3d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\nclass ResNet3D(nn.Module):\n\n    def __init__(self,\n                 block,\n                 layers,\n                 shortcut_type='B',\n                 num_class = 5,\n                 no_cuda=False,\n                 tab_feat=26):\n\n        self.inplanes = 64\n        self.no_cuda = no_cuda\n        super(ResNet3D, self).__init__()\n\n        # 3D conv net\n        self.conv1 = nn.Conv3d(53, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        # self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n        self.layer2 = self._make_layer(\n            block, 64*2, layers[1], shortcut_type, stride=2)\n        self.layer3 = self._make_layer(\n            block, 128*2, layers[2], shortcut_type, stride=1, dilation=2)\n        self.layer4 = self._make_layer(\n            block, 256*2, layers[3], shortcut_type, stride=1, dilation=4)\n\n        self.fea_dim = 256*2 * block.expansion\n        self.tab_feat = tab_feat\n        self.tab_out = 512\n       \n        self.tab_fc = nn.Sequential(nn.Linear(self.tab_feat, 1024),\n                                 nn.BatchNorm1d(1024),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.8),\n                                 nn.Linear(1024, 512),\n                                 nn.BatchNorm1d(512),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.5))\n        \n        self.fc = nn.Sequential(nn.Linear(self.fea_dim+512, num_class, bias=True))\n\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n            elif isinstance(m, nn.BatchNorm3d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1, dilation=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n\n            if shortcut_type == 'A':\n                downsample = partial(\n                    downsample_basic_block,\n                    planes=planes * block.expansion,\n                    stride=stride,\n                    no_cuda=self.no_cuda)\n            else:\n                downsample = nn.Sequential(\n                    nn.Conv3d(\n                        self.inplanes,\n                        planes * block.expansion,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x,tab_data):\n        x = self.conv1( x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x1 = self.tab_fc(tab_data)\n\n        x = F.adaptive_avg_pool3d(x, (1, 1, 1))\n        emb_3d = x.view((-1, self.fea_dim))\n        x = torch.cat((x1,emb_3d),dim=1)\n        out = self.fc(x)\n        return out\n\n\ndef resnet10(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [1, 1, 1, 1],**kwargs)\n    return model\n\ndef resnet3d_10(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [1, 1, 1, 1], **kwargs)\n    return model\n\ndef resnet18(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [2, 2, 2, 2], **kwargs)\n    return model\n\ndef resnet34(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model\n\ndef resnet50(**kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model = ResNet3D(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\ndef resnet101(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet3D(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\ndef resnet152(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet3D(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model\n\ndef resnet200(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet3D(Bottleneck, [3, 24, 36, 3], **kwargs)\n    return model\n","b59a2550":"## Works only for Resnet10 for now.\nimport torch\nfrom torch import nn\n\n\ndef generate_model(opt):\n    assert opt.model in [\n        'resnet'\n    ]\n\n    print('model depth: ',opt.model_depth)\n\n    if opt.model == 'resnet':\n        assert opt.model_depth in [10, 18, 34, 50, 101, 152, 200]\n        \n        if opt.model_depth == 10:\n            model = resnet10(\n                # sample_input_W=opt.input_W,\n                # sample_input_H=opt.input_H,\n                # sample_input_D=opt.input_D,\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n                # num_seg_classes=opt.n_seg_classes,\n            )\n        elif opt.model_depth == 18:\n            model = resnet18(\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n            )\n        elif opt.model_depth == 34:\n            model = resnet34(\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n            )\n        elif opt.model_depth == 50:\n            model = resnet.resnet50(\n                sample_input_W=opt.input_W,\n                sample_input_H=opt.input_H,\n                sample_input_D=opt.input_D,\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n                num_seg_classes=opt.n_seg_classes)\n        elif opt.model_depth == 101:\n            model = resnet.resnet101(\n                sample_input_W=opt.input_W,\n                sample_input_H=opt.input_H,\n                sample_input_D=opt.input_D,\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n                num_seg_classes=opt.n_seg_classes)\n        elif opt.model_depth == 152:\n            model = resnet.resnet152(\n                sample_input_W=opt.input_W,\n                sample_input_H=opt.input_H,\n                sample_input_D=opt.input_D,\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n                num_seg_classes=opt.n_seg_classes)\n        elif opt.model_depth == 200:\n            model = resnet.resnet200(\n                sample_input_W=opt.input_W,\n                sample_input_H=opt.input_H,\n                sample_input_D=opt.input_D,\n                shortcut_type=opt.resnet_shortcut,\n                no_cuda=opt.no_cuda,\n                num_seg_classes=opt.n_seg_classes)\n    \n    if not opt.no_cuda:\n            model = model.cuda()\n            model = nn.DataParallel(model)\n            net_dict = model.state_dict()\n    else:\n        net_dict = model.state_dict()\n    \n    # load pretrain\n    if opt.pretrain_path:\n        print ('loading pretrained model {}'.format(opt.pretrain_path))\n        pretrain = torch.load(opt.pretrain_path)\n        pretrain_dict = {k: v for k, v in pretrain['state_dict'].items() if k in net_dict.keys() and 'conv1' not in k}\n        print(pretrain_dict.keys())\n\n        net_dict.update(pretrain_dict)\n        model.load_state_dict(net_dict)\n\n        new_parameters = []\n        for pname, p in model.named_parameters():\n            for layer_name in opt.new_layer_names:\n                if pname.find(layer_name) >= 0:\n                    new_parameters.append(p)\n                    break\n\n        new_parameters_id = list(map(id, new_parameters))\n        base_parameters = list(filter(lambda p: id(p) not in new_parameters_id, model.parameters()))\n        parameters = {'base_parameters': base_parameters,\n                      'new_parameters': new_parameters}\n\n        return model, parameters\n\n    return model, model.parameters()\n","57774a82":"\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0) \/ np.sum(y_true, axis=0))\n\ndef weighted_nae(inp, targ):\n    W = torch.FloatTensor([0.3, 0.175, 0.175, 0.175, 0.175])\n    return torch.mean(torch.matmul(torch.abs(inp - targ), W.cuda() \/ torch.mean(targ, axis=0)))\n\ndef valid(data_loader, model, sets):\n    # settings\n    print(\"validation\")\n    model.eval()\n\n    y_pred = []\n    y_true = []\n    loss_ave = []\n\n    with torch.no_grad():\n        for batch_data in tqdm(data_loader):\n                # getting data batch\n                volumes, label,features = batch_data\n                if not sets.no_cuda:\n                    volumes = volumes.cuda()\n                    label = label.cuda()\n                    features = features.cuda()\n\n                logits = model(volumes,features)\n\n                # calculating loss\n                loss_value = weighted_nae(logits, label)\n                y_pred.append(logits.data.cpu().numpy())\n                y_true.append(label.data.cpu().numpy())\n                loss_ave.append(loss_value.data.cpu().numpy())\n\n    print('valid loss', np.mean(loss_ave))\n    y_pred = np.concatenate(y_pred,axis=0)\n    y_true = np.concatenate(y_true,axis=0)\n\n    domain = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n    w = [0.3, 0.175, 0.175, 0.175, 0.175]\n\n    m_all = 0\n    for i in range(5):\n        m = metric(y_true[:,i], y_pred[:,i])\n        print(domain[i],'metric:', m)\n        m_all += m*w[i]\n\n    print('all_metric:', m_all)\n    model.train()\n    return np.mean(loss_ave)\n\ndef test(data_loader, model, sets, save_path):\n    # settings\n    print(\"validation\")\n    model.eval()\n\n    y_pred = []\n    ids_all = []\n    with torch.no_grad():\n        for batch_data in tqdm(data_loader):\n                # getting data batch\n                ids, volumes,features = batch_data\n                if not sets.no_cuda:\n                    volumes = volumes.cuda() \n                    features = features.cuda()\n\n                logits = model(volumes,features)\n                y_pred.append(logits.data.cpu().numpy())\n                ids_all += ids\n\n    y_pred = np.concatenate(y_pred, axis=0)\n    np.savez_compressed(save_path,\n                        y_pred = y_pred,\n                        ids = ids_all)\n    print(y_pred.shape)\n\ndef train(train_loader,valid_loader, model, optimizer, ajust_lr, total_epochs, save_interval, save_folder, sets):\n    f = open(os.path.join(save_folder,'log.txt'),'w')\n\n    # settings\n    batches_per_epoch = len(train_loader)\n    print(\"Current setting is:\")\n    print(sets)\n    print(\"\\n\\n\")\n\n    model.train()\n    train_time_sp = time.time()\n\n    valid_loss = 99999\n    min_loss = 99999\n\n    for epoch in range(total_epochs):\n        rate = ajust_lr(optimizer, epoch)\n\n        # log.info('lr = {}'.format(scheduler.get_lr()))\n        for batch_id, batch_data in enumerate(train_loader):\n            # getting data batch\n            batch_id_sp = epoch * batches_per_epoch\n            volumes, label,features = batch_data\n\n            if not sets.no_cuda: \n                volumes = volumes.cuda()\n                label = label.cuda()\n                features =features.cuda()\n\n            optimizer.zero_grad()\n            logits = model(volumes,features)\n\n            # calculating loss\n            loss = weighted_nae(logits, label)\n            loss.backward()                \n            optimizer.step()\n\n            avg_batch_time = (time.time() - train_time_sp) \/ (1 + batch_id_sp)\n\n            log_ = '{} Batch: {}-{} ({}), ' \\\n                   'lr = {:.5f}, ' \\\n                   'train loss = {:.3f}, ' \\\n                   'valid loss = {:.3f}, ' \\\n                   'avg_batch_time = {:.3f} '.format(sets.model_name, epoch, batch_id, batch_id_sp, rate, loss.item(), valid_loss, avg_batch_time)\n\n            print(log_)\n            f.write(log_ + '\\n')\n            f.flush()\n\n        if 1:\n            valid_loss = valid(valid_loader,model,sets)\n\n            if valid_loss < min_loss:\n                min_loss = valid_loss\n                model_save_path = '{}\/epoch_{}_batch_{}_loss_{}.pth.tar'.format(save_folder, epoch, batch_id, valid_loss)\n\n                model_save_dir = os.path.dirname(model_save_path)\n                if not os.path.exists(model_save_dir):\n                    os.makedirs(model_save_dir)\n\n                log_ = 'Save checkpoints: epoch = {}, batch_id = {}'.format(epoch, batch_id)\n                print(log_)\n                f.write(log_ + '\\n')\n\n                torch.save({'ecpoch': epoch,\n                                    'batch_id': batch_id,\n                                    'state_dict': model.state_dict(),\n                                    'optimizer': optimizer.state_dict()},\n                                    model_save_path)\n\n    print('Finished training')\n    f.close()\n\n","36ed06c7":"# getting model\ntorch.manual_seed(Config.manual_seed)\nmodel, parameters = generate_model(Config)\nprint(model)\n\n# optimizer\ndef get_optimizer(net):\n    \n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=1e-4, betas=(0.9, 0.999), eps=1e-08)\n    \n    def ajust_lr(optimizer, epoch):\n            if epoch < 24 :\n                    lr = 1e-4\n            elif epoch < 36:\n                    lr = 0.5e-4\n            else:\n                    lr = 1e-5\n\n            for p in optimizer.param_groups:\n                    p['lr'] = lr\n            return lr\n\n    rate = ajust_lr(optimizer, 0)\n    return  optimizer, ajust_lr\n\noptimizer, ajust_lr = get_optimizer(model)\n    # train from resume\nif Config.resume_path:\n    if os.path.isfile(Config.resume_path):\n        print(\"=> loading checkpoint '{}'\".format(Config.resume_path))\n        checkpoint = torch.load(Config.resume_path)\n        model.load_state_dict(checkpoint['state_dict'])\n\n    # getting data\nConfig.phase = 'train'\nif Config.no_cuda:\n    Config.pin_memory = False\nelse:\n    Config.pin_memory = True\n\ntrain_dataset = TReNDsDataset(mode='train', fold_index=Config.fold_index)\ntrain_loader = DataLoader(train_dataset, batch_size=Config.batch_size,\n                             shuffle=True, num_workers=Config.num_workers,\n                             pin_memory=Config.pin_memory,drop_last=True)\n\nvalid_dataset = TReNDsDataset(mode='valid', fold_index=Config.fold_index)\nvalid_loader = DataLoader(valid_dataset, batch_size=Config.batch_size,\n                             shuffle=False, num_workers=Config.num_workers,\n                             pin_memory=Config.pin_memory, drop_last=False)\n","5d5a1b7a":"# # training\ntrain(train_loader, valid_loader,model, optimizer,ajust_lr,\n          total_epochs=Config.n_epochs,\n          save_interval=Config.save_intervals,\n          save_folder=Config.save_folder, sets=Config)\n","ea7626ea":"test_dataset = TReNDsDataset(mode='test', fold_index=Config.fold_index)\ntest_loader  = DataLoader(test_dataset, batch_size=Config.batch_size,\n                             shuffle=False, num_workers=Config.num_workers,\n                             pin_memory=False, drop_last=False)\ntest(test_loader, model, Config, '.\/pred.npz') ## Uncomment this to generate pred.npz in kaggle","3ce24e55":"## Loading the prediction done in local gpu","43ea5661":"from sklearn.svm import SVR\nfrom sklearn.model_selection import KFold\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)\/np.sum(y_true, axis=0))\n\nfnc_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/fnc.csv\")\nfnc_df\nloading_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/loading.csv\")\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\nlabels_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/train_scores.csv\")\nlabels_df[\"is_train\"] = True\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n","b279764f":"test_numpy  = np.load('.\/pred.npz')\nage_sub = pd.read_csv(\"..\/input\/rapids-svm-on-trends-neuroimaging\/submission.csv\") ## The age is not doing well so thinking of predicting other 4 values \nsub2= age_sub[\"Predicted\"].values.reshape(age_sub.shape[0]\/\/5, 5)\nsub2[:, 1:] = test_numpy[\"y_pred\"][:,1:]\ntest_df[[ \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]] = sub2\nsub_df = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.head(10)\n\n","6a8d52f6":"sub_df.to_csv(\"submission.csv\", index=False)","95ae114a":"### Start Training","c7ff9e09":"### network","4b993bb8":"### Start Testing","3a8b11f5":"### This is a notebook version of the code shared by SeuTao\n\n#### His gihub repo \n\n##### https:\/\/github.com\/SeuTao\/RSNA2019_Intracranial-Hemorrhage-Detection\n\nI made small modifications to adapt it to Kaggle Kernel for the people who does not have local GPU . ","de2aced7":"## Check Datasets","8bf3b558":"### Create model and dataloader","6c497e23":"### Install","7de59426":"### Config","e6b83047":"### Datasets ","5b435599":"### model","c139965b":"## Common Lib"}}