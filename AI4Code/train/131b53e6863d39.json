{"cell_type":{"76a8e21d":"code","a690a682":"code","1a75055d":"code","6ad9b053":"code","15614da8":"code","c8d01248":"code","9c3a5b00":"code","778e6018":"code","7bfae5d6":"code","4fcb0bdf":"code","68a61401":"code","1dd4289c":"code","7b585794":"code","1045fa52":"code","8bf489ff":"code","3ffc4b4a":"code","631625f8":"code","3b4ba932":"code","5cd9dbe8":"code","3185a323":"code","5d4e1327":"code","5f559865":"markdown","21d99c51":"markdown","d10c5d32":"markdown","ce18ff59":"markdown","6cc08819":"markdown","8a915aa1":"markdown"},"source":{"76a8e21d":"# Importing the libraries \n\nimport pandas as pd\nimport numpy as np \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, GlobalMaxPooling2D, Dropout\nfrom keras.applications import VGG16\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras import layers\n\nfrom sklearn.model_selection import train_test_split\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a690a682":"!rm -rf \".\/train\"\n!unzip \"\/kaggle\/input\/dogs-vs-cats\/train.zip\"","1a75055d":"# Preparing the data\nfilenames = os.listdir(\".\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","6ad9b053":"# Looking at the data in dataframe\ndf.head()","15614da8":"# Changin the category to strings \ndf[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","c8d01248":"# Shape of data\ndf.shape","9c3a5b00":"# Distribution of count classes\nsns.set(style=\"white\")\nsns.countplot(df[\"category\"])","778e6018":"sample = np.random.choice(filenames)\nimage = load_img(\".\/train\/\" + sample)\n# Each image is of different shapes and has 3 channel for RGB\nplt.imshow(image)\nplt.show()","7bfae5d6":"# Splitting the data\ntrain_df, test_df = train_test_split(df, test_size=.2, stratify=df[\"category\"])\ntrain_df = train_df.reset_index()\ntest_df = test_df.reset_index()","4fcb0bdf":"aug_data = ImageDataGenerator(\n    rotation_range = 15, \n    shear_range = .2, \n    zoom_range = .2, \n    horizontal_flip = True, \n    vertical_flip = True, \n    width_shift_range = 0.15, \n    height_shift_range = .15, \n    fill_mode = \"nearest\"\n)","68a61401":"input_shape = (224, 224)\nbatch_size = 32\n\ntrain_generator = aug_data.flow_from_dataframe(\n    dataframe=train_df, \n    directory=\".\/train\/\", \n    x_col = \"filename\",\n    y_col=\"category\", \n    class_mode = \"categorical\", \n    target_size = input_shape, \n    batch_size = batch_size\n    )","1dd4289c":"test_generator = aug_data.flow_from_dataframe(\n    dataframe=test_df, \n    directory=\".\/train\/\", \n    x_col = \"filename\",\n    y_col=\"category\", \n    class_mode = \"categorical\", \n    target_size = input_shape, \n    batch_size = batch_size\n    )","7b585794":"# Load the VGG16 model\n# include_top = False means we don't want to take last 3 fully connected layers of VGG16 and we want weights trained on ImageNet data.\npre_trained_model = VGG16(include_top=False, weights=\"imagenet\")","1045fa52":"pre_trained_model.summary()","8bf489ff":"# We will fix the initial layers and only train the last stacked set of convolution layer\nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n    \nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True","3ffc4b4a":"# Take the output of last pooling layer\nlast_pooling_layer = pre_trained_model.get_layer(\"block5_pool\")\nlast_output = last_pooling_layer.output","631625f8":"# Flatten the output layer which has 512 units\nx = GlobalMaxPooling2D()(last_output)\n\n# After this add a fully connected layer with 512 units \nx = Dense(units=512, activation=\"relu\")(x)\n\n# Add a dropout \nx = Dropout(rate=.25)(x)\n\n# Add a final layer for classification \nx = layers.Dense(units=2, activation=\"softmax\")(x)\n\n# Combine the model with our layers\nmodel = Model(inputs=pre_trained_model.input, outputs=x)","3b4ba932":"model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])","5cd9dbe8":"batch_size = 32\nepochs = 10\ntrain_size = train_df.shape[0]","3185a323":"hist = model.fit_generator(generator = train_generator, epochs = epochs, validation_data = test_generator, verbose=1, \n                           steps_per_epoch = np.ceil(train_size\/batch_size))","5d4e1327":"sns.set(style=\"whitegrid\")\nplt.figure(figsize=(20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='best')\n\nplt.subplot(1, 2, 2)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='best')\nplt.show()","5f559865":"![image.png](attachment:image.png)","21d99c51":"Another way of looking into it:\n![image.png](attachment:image.png)","d10c5d32":"### VGG16\nVGG16 is a type of neural network which worked really well on ImageNet dataset which has 14 million images with 1000 class labels in 2014. It acheived 92.7% top-5 test accuarcy on ImageNet. Before that, we had Alexnet, \n\n\nIt is built using 16 layers out of which 13 are convolution layers and 3 are fully connected layers. There are stacked convlutions followed by MaxPooling. Architecture looks something like this:","ce18ff59":"VGG16 uses colored images with shape (224, 224) dimensions. We will use trained VGG16 modle weights with some tuning to use th efeatures which it learnt from ImageNet dataset. This is also called Transfer Learning.","6cc08819":"Since VGG16 is a kind of CNN, we can't have variable size of input data. Images in our dataset have different shapes, so we need to fix their size. Also, we need to fix it to (224, 224) according to VGG16 architecture. \n\nTo remove this problem, we will use ImageDataGenerator from keras, which will augment our data to make our model robust and also will fix the dimensions to the desired ones.","8a915aa1":"As we can see, there are convolution layers followed by poling layers, we have removed FC layers. \n\nIn this model also, we will fix the weights of initial layers and will train the last block of 3 convolution layer and 1 pooling layer."}}