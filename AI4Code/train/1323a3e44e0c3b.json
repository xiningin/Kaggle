{"cell_type":{"1271f820":"code","03a9fca1":"code","98e124c4":"code","08558210":"code","60facc76":"code","280daf43":"code","688adf07":"code","dc44062f":"code","9a541d88":"code","6422dafd":"code","bf3db407":"code","d6781c4d":"code","3706da5f":"code","f69b783f":"code","5c8fac9c":"code","6f18a862":"code","cc5b6774":"code","bb6819f2":"code","ba993aa4":"code","1715f688":"code","e78c16b8":"code","0a69eac6":"code","d055b584":"code","89501d3b":"code","5d559c39":"code","72d8a8d7":"code","6c2a3eb0":"code","6b677570":"code","53c41acf":"code","ec385dfb":"code","163b7597":"markdown","efc86feb":"markdown","e16e4dc2":"markdown","18defa35":"markdown","2e0cac4e":"markdown","87ab0ae0":"markdown","5529b14a":"markdown","3b42c827":"markdown","790f8943":"markdown","fed396b8":"markdown"},"source":{"1271f820":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","03a9fca1":"from tensorflow import keras\n# from tensorflow.keras.utils import to_categorical\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n# from tensorflow.keras.losses import categorical_crossentropy\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt","98e124c4":"train_data_path = '..\/input\/emnist-balanced-train.csv'\ntest_data_path = '..\/input\/emnist-balanced-test.csv'","08558210":"train_data = pd.read_csv(train_data_path, header=None)","60facc76":"train_data.head(10)","280daf43":"# The classes of this balanced dataset are as follows. Index into it based on class label\nclass_mapping = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt'\n# source data: https:\/\/arxiv.org\/pdf\/1702.05373.pdf","688adf07":"class_mapping[34]","dc44062f":"train_data.shape","9a541d88":"num_classes = len(train_data[0].unique())\nrow_num = 8\n\nplt.imshow(train_data.values[row_num, 1:].reshape([28, 28]), cmap='Greys_r')\nplt.show()\n\nimg_flip = np.transpose(train_data.values[row_num,1:].reshape(28, 28), axes=[1,0]) # img_size * img_size arrays\nplt.imshow(img_flip, cmap='Greys_r')\n\nplt.show()","6422dafd":"def show_img(data, row_num):\n    img_flip = np.transpose(data.values[row_num,1:].reshape(28, 28), axes=[1,0]) # img_size * img_size arrays\n    plt.title('Class: ' + str(data.values[row_num,0]) + ', Label: ' + str(class_mapping[data.values[row_num,0]]))\n    plt.imshow(img_flip, cmap='Greys_r')","bf3db407":"show_img(train_data, 149)","d6781c4d":"# 10 digits, 26 letters, and 11 capital letters that are different looking from their lowercase counterparts\nnum_classes = 47 \nimg_size = 28\n\ndef img_label_load(data_path, num_classes=None):\n    data = pd.read_csv(data_path, header=None)\n    data_rows = len(data)\n    if not num_classes:\n        num_classes = len(data[0].unique())\n    \n    # this assumes square imgs. Should be 28x28\n    img_size = int(np.sqrt(len(data.iloc[0][1:])))\n    \n    # Images need to be transposed. This line also does the reshaping needed.\n    imgs = np.transpose(data.values[:,1:].reshape(data_rows, img_size, img_size, 1), axes=[0,2,1,3]) # img_size * img_size arrays\n    \n    labels = keras.utils.to_categorical(data.values[:,0], num_classes) # one-hot encoding vectors\n    \n    return imgs\/255., labels\n\n","3706da5f":"model = keras.models.Sequential()\n\n# model.add(keras.layers.Reshape((img_size,img_size,1), input_shape=(784,)))\nmodel.add(keras.layers.Conv2D(filters=12, kernel_size=(5,5), strides=2, activation='relu', \n                              input_shape=(img_size,img_size,1)))\n# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(.5))\n\nmodel.add(keras.layers.Conv2D(filters=18, kernel_size=(3,3) , strides=2, activation='relu'))\n# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(.5))\n\nmodel.add(keras.layers.Conv2D(filters=24, kernel_size=(2,2), activation='relu'))\n# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\n# model.add(keras.layers.Conv2D(filters=30, kernel_size=(3,3), activation='relu'))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(units=150, activation='relu'))\nmodel.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\nmodel.summary()","f69b783f":"for layer in model.layers:\n    print(layer.get_output_at(0).get_shape().as_list())\n","5c8fac9c":"X, y = img_label_load(train_data_path)\nprint(X.shape)","6f18a862":"data_generator = keras.preprocessing.image.ImageDataGenerator(validation_split=.2)\n## consider using this for more variety\ndata_generator_with_aug = keras.preprocessing.image.ImageDataGenerator(validation_split=.2,\n                                            width_shift_range=.2, height_shift_range=.2,\n                                            rotation_range=60, zoom_range=.2, shear_range=.3)\n\n# if already ran this above, no need to do it again\n# X, y = img_label_load(train_data_path)\n# print(\"X.shape: \", X.shape)\n\ntraining_data_generator = data_generator.flow(X, y, subset='training')\nvalidation_data_generator = data_generator.flow(X, y, subset='validation')\nhistory = model.fit_generator(training_data_generator, \n                              steps_per_epoch=500, epochs=5, # can change epochs to 10\n                              validation_data=validation_data_generator)\n","cc5b6774":"test_X, test_y = img_label_load(test_data_path)\ntest_data_generator = data_generator.flow(X, y)\n\nmodel.evaluate_generator(test_data_generator)","bb6819f2":"test_data = pd.read_csv(test_data_path, header=None)\nshow_img(test_data, 123)","ba993aa4":"X_test, y_test = img_label_load(test_data_path) # loads images and orients for model","1715f688":"def run_prediction(idx):\n    result = np.argmax(model.predict(X_test[idx:idx+1]))\n    print('Prediction: ', result, ', Char: ', class_mapping[result])\n    print('Label: ', test_data.values[idx,0])\n    show_img(test_data, idx)","e78c16b8":"import random\n\nfor _ in range(1,10):\n    idx = random.randint(0, 47-1)\n    run_prediction(idx)","0a69eac6":"show_img(test_data, 123)\nnp.argmax(y_test[123])","d055b584":"# First, convert Keras Model to TensorFlow Estimator\nmodel_input_name = model.input_names[0]\nestimator_model = keras.estimator.model_to_estimator(keras_model=model, model_dir=\".\/estimator_model\")\nprint(model_input_name)","89501d3b":"# Next, export the TensorFlow Estimator to SavedModel\n\nfrom functools import partial\nimport tensorflow as tf\n\ndef serving_input_receiver_fn():\n    input_ph = tf.placeholder(tf.string, shape=[None], name='image_binary')\n    images = tf.map_fn(partial(tf.image.decode_image, channels=1), input_ph, dtype=tf.uint8)\n    images = tf.cast(images, tf.float32) \/ 255.\n    images.set_shape([None, 28, 28, 1])\n\n    # the first key is the name of first layer of the (keras) model. \n    # The second key is the name of the key that will be passed in the prediction request\n    return tf.estimator.export.ServingInputReceiver({model_input_name: images}, {'bytes': input_ph})","5d559c39":"export_path = estimator_model.export_savedmodel('.\/export', serving_input_receiver_fn=serving_input_receiver_fn)\nexport_path","72d8a8d7":"with open('model.json', 'w') as f:\n    f.write(model.to_json())\nmodel.save_weights('.\/model.h5')\n\nmodel.save('.\/full_model.h5')\n!ls -lh","6c2a3eb0":"import matplotlib.pyplot as plt\n\nprint(history.history.keys())\n\n# accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower right')\nplt.show()\n\n# loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","6b677570":"from PIL import Image\n\ndef export_png(row_num, data=test_data):\n    array = np.transpose(data.values[row_num,1:].reshape(28, 28), axes=[1,0])\n    img = Image.fromarray(array.astype(np.uint8))\n    filename = 'class_' + str(data.values[row_num,0]) + '_label_' + str(class_mapping[data.values[row_num,0]]) + '.png'\n    img.save(filename)","53c41acf":"export_png(149)","ec385dfb":"import base64\nimport json\n\nimg_filename = 'class_19_label_J.png'\njson_filename = 'class_19_label_J.json'\n\nwith open(img_filename, 'rb') as img_file :\n    img_str = base64.b64encode(img_file.read())\n    print(str(img_str))\n\n    json_img = {\"image_bytes\":{\"b64\": str(img_str) }}\n    print(type(json_img['image_bytes']['b64']))\n\nwith open(json_filename, 'w') as outfile:\n    json.dump(json_img, outfile)\n","163b7597":"## Plot loss and accuracy","efc86feb":"### Load dataset ","e16e4dc2":"### Train","18defa35":"## Data is flipped","2e0cac4e":"## Create some output files for sending to Cloud ML Engine's online prediction","87ab0ae0":"### load library","5529b14a":"## Export model to TF SavedModel for CMLE Prediction\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/estimator\/model_to_estimator ","3b42c827":"## Look at some predictions\n","790f8943":"## Keras exports","fed396b8":"### model, compile"}}