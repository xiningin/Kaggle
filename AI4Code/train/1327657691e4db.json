{"cell_type":{"db5d666f":"code","a795f35c":"code","37821f23":"code","35e1de50":"code","a9436036":"code","f96e72a1":"code","6ab77320":"code","6f12a8b5":"code","51032415":"code","ab8594e9":"code","e1f9d3bf":"code","94a4a2f3":"code","90f114c7":"code","174d3d3d":"code","f5fcbb32":"code","bbcac7cd":"code","4708549d":"code","9d254d09":"code","96ca656c":"code","0c6e9380":"code","c5a3f9cf":"code","5426c4d8":"code","15f20bfe":"code","afba585c":"markdown","c1f6f227":"markdown","7c2d9fc0":"markdown","f6cfd53f":"markdown","899e320d":"markdown","6625f5a5":"markdown","8277073d":"markdown","203f0422":"markdown","0a1feb30":"markdown","8692f569":"markdown","e5ec88ca":"markdown","1562ba79":"markdown","66485758":"markdown","4e02edba":"markdown","88b72a6a":"markdown","ef23a900":"markdown","8316352e":"markdown","5dda41eb":"markdown"},"source":{"db5d666f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a795f35c":"data=pd.read_csv(\"..\/input\/daily-temperature-of-major-cities\/city_temperature.csv\")\ndata.head()","37821f23":"#Taking out only Delhi data\ndelhi=data[data[\"City\"]==\"Delhi\"]\ndelhi.reset_index(inplace=True)\ndelhi.drop('index',axis=1,inplace=True)\ndelhi.describe()           ","35e1de50":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,6))\nplt.plot(delhi[\"AvgTemperature\"])\nplt.ylabel(\"Temperature\",fontsize=20)","a9436036":"from sklearn.impute import SimpleImputer\nimputer=SimpleImputer()\ndelhi[\"AvgTemperature\"].replace(-99,np.nan,inplace=True)#Replacing wrong entries with nan \ndelhi[\"AvgTemperature\"]=pd.DataFrame(imputer.fit_transform(delhi.loc[:,\"AvgTemperature\":]))","f96e72a1":"print(min(delhi[\"AvgTemperature\"]))\nyears=delhi[\"Year\"].unique()\nyears","6ab77320":"#Defining training and testing data\ntraining_set=delhi[delhi[\"Year\"]<=2015]\ntest_set=delhi[delhi[\"Year\"]>2015]","6f12a8b5":"#Mean of the temperatures\ndelhi.iloc[:,-1].mean()","51032415":"plt.figure(figsize=(15,7))\nplt.plot(delhi.iloc[:,-1])\nplt.xlabel(\"Time Series\",fontsize=20)\nplt.ylabel(\"Temperature\",fontsize=20)\n#making a list of values to be plotted on y axis\ny_values=[x for x in range(50,101,10)]\ny_values.extend([delhi.iloc[:,-1].min(),delhi.iloc[:,-1].max(),delhi.iloc[:,-1].mean()])\nplt.yticks(y_values)\nplt.axhline(y=delhi.iloc[:,-1].mean(), color='r', linestyle='--',label=\"Mean\")\nplt.legend(loc=1)\nplt.axhline(y=delhi.iloc[:,-1].max(), color='g', linestyle=':')\nplt.axhline(y=delhi.iloc[:,-1].min(), color='g', linestyle=':')","ab8594e9":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(delhi[\"AvgTemperature\"],lags=365)\n#plt.show()","e1f9d3bf":"from statsmodels.graphics.tsaplots import plot_pacf\nplot_pacf(delhi[\"AvgTemperature\"],lags=50)","94a4a2f3":"from statsmodels.tsa.ar_model import AutoReg\nmodel_AR=AutoReg(training_set[\"AvgTemperature\"],lags=365)\nmodel_fit_AR=model_AR.fit()\npredictions_AR = model_fit_AR.predict(training_set.shape[0],training_set.shape[0]+test_set.shape[0]-1)","90f114c7":"\nimport seaborn as sns\nplt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_AR,label=\"Predicted Data\")\nplt.legend()","174d3d3d":"from sklearn.metrics import mean_squared_error\nmse=mean_squared_error(predictions_AR,test_set[\"AvgTemperature\"])\nmse","f5fcbb32":"from statsmodels.tsa.ar_model import AutoReg\nmodel_AR2=AutoReg(training_set[\"AvgTemperature\"],lags=[365])\nmodel_fit_AR2=model_AR2.fit()\npredictions_AR2= model_fit_AR2.predict(training_set.shape[0],training_set.shape[0]+test_set.shape[0]-1)","bbcac7cd":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_AR2,label=\"Predicted Data\")\nplt.legend()","4708549d":"mse=mean_squared_error(predictions_AR2,test_set[\"AvgTemperature\"])\nmse","9d254d09":"from statsmodels.tsa.arima_model import ARMA\nmodel_MA=ARMA(training_set[\"AvgTemperature\"],order=(0,10))\nmodel_fit_MA=model_MA.fit()\npredictions_MA=model_fit_MA.predict(test_set.index[0],test_set.index[-1])","96ca656c":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_MA,label=\"Predictions\")\nplt.legend()","0c6e9380":"mse=mean_squared_error(predictions_MA,test_set[\"AvgTemperature\"])\nmse","c5a3f9cf":"model_ARMA=ARMA(training_set[\"AvgTemperature\"],order=(5,10))\nmodel_fit_ARMA=model_ARMA.fit()\npredictions_ARMA=model_fit_ARMA.predict(test_set.index[0],test_set.index[-1])","5426c4d8":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_ARMA,label=\"Predictions\")\nplt.legend()","15f20bfe":"mse=mean_squared_error(predictions_ARMA,test_set[\"AvgTemperature\"])\nmse","afba585c":"### Let's see how our data looks after dealing with all the wrong values. ","c1f6f227":"### There is an early cutoff after the first lag in the graph","7c2d9fc0":"### Plotting the temperatures","f6cfd53f":"## *LOLLLLL This went down too well, worked like a charm but unfortunately other models won't work like this*\n<img src=\"https:\/\/media1.tenor.com\/images\/610c4fe56dad195b0ffe5e76d2a02761\/tenor.gif?itemid=4461765\">","899e320d":"Let's start with the AutoReg model\n**Lags taken into consideration in model = 1,2,3,.....365**","6625f5a5":"**NOTE**: This dataset contains various cities and nations ,I will be using only the temperatures of Delhi.  ","8277073d":"Let's see how many years of data we have in our data.","203f0422":"OHHHH BOY O BOY we have some wrong values too , as the data have some -99 degree temps. WOOOOSSSSHHH I dont think that is possible as a student of science. We have to deal with this data , so I will make these values imputed.","0a1feb30":"**This graph looks accurate than the previous one but let's check if it actually works better or not**","8692f569":"# **Autoregressive Moving Average (ARMA)**","e5ec88ca":"### **IMPORTING DATA**","1562ba79":"### Clearly the graph looks geometrical and there is no abrupt cutoff in the values","66485758":"# ***NOTE*:**\n\nIt is pretty lame to try to predict something that is going to happen over the next 5 years , but when we have data at our disposal why should'nt we ?\nThat's what data science is for.\nThe model used are just for showcase purposes i.e. how they perform when used on an *almost stationary* data.","4e02edba":"# I would be trying to create another notebook for ARIMA and ARIMAX models with a different data set, this is enough for now with the current dataset. Have a nice day.\n<img src=\"https:\/\/media1.tenor.com\/images\/b93d03f39d1b379cf648e5568a4537e7\/tenor.gif?itemid=11696907\">","88b72a6a":"Now with only lag=365 taking into consideration ","ef23a900":"Let's calculate the mean squared error of the predicted data","8316352e":"## Now that we had a quick look over the data, let's try some TIMEEEE SERRIEESSSS MODEEELLLSS\n<img src=\"https:\/\/media.tenor.com\/images\/8636ae856342f311049ec5573e263889\/tenor.gif\">","5dda41eb":"# **MOVING AVERAGE**"}}