{"cell_type":{"1110b703":"code","960581b2":"code","e9218836":"code","a8f63854":"code","c745de83":"code","67361832":"code","a4caf9a6":"code","f3456340":"code","06cf1200":"code","160ff59d":"code","7097078d":"code","9c4061cd":"code","d8503a1e":"code","97a53a67":"code","78dc9ae0":"code","c8d898b2":"code","b9b7844c":"code","cb22f7c3":"code","e2811290":"code","37fa9eb9":"code","482d20ca":"code","304ac7ba":"code","fa1010c5":"code","1b92a6a8":"code","d15ffc97":"code","55ab6fbb":"code","1d0f8a66":"code","5d2b2ea7":"code","35a97030":"code","9945e729":"code","40ae9cc1":"code","9cdf7759":"code","64ebbbdf":"code","f4803961":"code","a4b47514":"code","d79918f2":"code","ebfeaeb7":"code","16ca911f":"markdown","def3dae2":"markdown","8ff544c4":"markdown","e836bfd5":"markdown","6de35e27":"markdown","0cfafcb5":"markdown","0de641da":"markdown","70cb0536":"markdown","46e15fbc":"markdown","3d7b6632":"markdown","2dcbef21":"markdown","6d5bcbe8":"markdown","3c553177":"markdown","0358820a":"markdown","07197810":"markdown","2bc5a411":"markdown","7eb24443":"markdown","95325cd7":"markdown","a2acf9bc":"markdown","e1092a4b":"markdown"},"source":{"1110b703":"import pandas as pd\nimport numpy as np\nimport missingno\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier,plot_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split,KFold, GroupKFold, StratifiedKFold\nimport warnings\nfrom sklearn.metrics import log_loss\nimport plotly.express as px\nfrom lightgbm import LGBMClassifier\n\nwarnings.filterwarnings(\"ignore\")","960581b2":"train = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/test.csv\")","e9218836":"train.head()","a8f63854":"train = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)","c745de83":"train.info()","67361832":"train.isnull().sum()","a4caf9a6":"test.isnull().sum()","f3456340":"fig = px.histogram(train, x=train['target'], color=train['target'],)\nfig.update_layout(\n    title_text='Target distribution', # title of plot\n    xaxis_title_text='Value', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    \n)\nfig.show()","06cf1200":"rename_labels = {val:idx for idx, val in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(rename_labels)","160ff59d":"fig, ax = plt.subplots(figsize=(15 , 12))\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nsns.heatmap(corr,square=True, center=0, \n            linewidth=0.2, cmap='coolwarm',\n           mask=mask, ax=ax) \n\nax.set_title('Feature Correlation Matrix ', loc='left')\nplt.show()","7097078d":"train.describe()","9c4061cd":"fig, ax = plt.subplots(figsize=(12, 8))\n\n# x = [f'feature_{i}' for i in range(50)]\ny = sorted([len(train[f'feature_{i}'].unique()) for i in range(50)])\n\nax.bar(range(50), y, zorder=10)\nax.set_xticks(range(50))\nax.set_yticks(range(0, 80, 5))\nax.margins(0.02)\n\nax.set_title('TRAIN : # of Features Unique Values', loc='left', fontweight='bold')\nax.grid(axis='y', linestyle='--', zorder=5)\nplt.show()","d8503a1e":"fig, ax = plt.subplots(figsize=(12, 8))\n\n# x = [f'feature_{i}' for i in range(50)]\ny = sorted([len(test[f'feature_{i}'].unique()) for i in range(50)])\n\nax.bar(range(50), y, zorder=10)\nax.set_xticks(range(50))\nax.set_yticks(range(0, 80, 5))\nax.margins(0.02)\n\nax.set_title('TEST : # of Features Unique Values', loc='left', fontweight='bold')\nax.grid(axis='y', linestyle='--', zorder=5)\nplt.show()","97a53a67":"train_p = train\nlic = []\nfor col in train_p.columns[1:-1]:\n    lic.append(col)\n    \ndef plot(col):\n    plt.figure(figsize = (8,5))\n    g = sns.countplot(x = col, hue = 'target', data = train_p)\n    plt.legend(loc='upper right')\n    plt.title(\"Distribution of \"+ col,fontsize=15)\n    plt.show();\n\nfor col in lic:\n    plot(col)","78dc9ae0":"plt.figure(figsize=(18,25))\nsns.boxplot(data=train, orient=\"h\");","c8d898b2":"plt.figure(figsize=(18,25))\nsns.boxplot(data=test.iloc[:,1:], orient=\"h\");","b9b7844c":"le = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])","cb22f7c3":"train.columns","e2811290":"cols = list(train.columns)\ncols.remove(\"target\")","37fa9eb9":"model = XGBClassifier(tree_method = 'gpu_hist' ,\n                      use_label_encoder=False)\nmodel.fit(train.drop(columns='target'),train.target)","482d20ca":"fig, ax = plt.subplots(figsize=(10,10))\nplot_importance(model,\n                height=0.5,\n               max_num_features=None,\n               title='Feature importance',\n                xlabel='F score', \n                ylabel='Features',\n               ax=ax)","304ac7ba":"test_preds = None\ntrain_rmse = 0\nval_rmse = 0\nn_splits = 10\n\nkf = KFold(n_splits = n_splits , shuffle = True , random_state = 0)\nfor fold, (tr_index , val_index) in enumerate(kf.split(train[cols].values , train['target'].values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = train[cols].values[tr_index] , train[cols].values[val_index]\n    y_train,y_val = train['target'].values[tr_index] , train['target'].values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model = CatBoostClassifier(depth=4,\n                               task_type=\"GPU\",\n            max_ctr_complexity=15,\n            iterations=17000,\n            od_wait=1000, od_type='Iter',\n            learning_rate=0.01,\n            min_data_in_leaf=1,\n            use_best_model=True,\n            loss_function='MultiClass')\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = 500)\n    \n    train_preds = model.predict(x_train)\n    train_rmse += mean_squared_error(y_train ,train_preds , squared = False)\n    print(\"Training RMSE : \" , mean_squared_error(y_train ,train_preds , squared = False))\n    \n    val_preds = model.predict(x_val)\n    val_rmse += mean_squared_error(y_val , val_preds , squared = False)\n    print(\"Validation RMSE : \" , mean_squared_error(y_val , val_preds , squared = False))\n    \n    if test_preds is None:\n        test_preds = model.predict_proba(test[cols].values)\n    else:\n        test_preds += model.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\nprint(\"Average Training RMSE : \" , train_rmse \/ n_splits)\nprint(\"Average Validation RMSE : \" , val_rmse \/ n_splits)\n\ntest_preds \/= n_splits","fa1010c5":"test_preds = np.clip(test_preds, 0.08, 0.95)\nsubmission1 = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")\nsubmission1['Class_1']=test_preds[:,0]\nsubmission1['Class_2']=test_preds[:,1]\nsubmission1['Class_3']=test_preds[:,2]\nsubmission1['Class_4']=test_preds[:,3]\nsubmission1.head()","1b92a6a8":"submission1.to_csv(\"CB.csv\",index=False)","d15ffc97":"pip install -U lightautoml","55ab6fbb":"from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task","1d0f8a66":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 3 * 3600 # Time in seconds for automl run\nTARGET_NAME = 'target'","5d2b2ea7":"train_data = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\ntrain_data[TARGET_NAME] = train_data[TARGET_NAME].str.slice(start=6).astype(int) - 1","35a97030":"def create_gr_feats(data):\n    pass\n    \n\nall_df = pd.concat([train_data, test_data]).reset_index(drop = True)\ncreate_gr_feats(all_df)\ntrain_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\nprint(train_data.shape, test_data.shape)","9945e729":"%%time\n\ntask = Task('multiclass',)","40ae9cc1":"%%time\n\nroles = {\n    'target': TARGET_NAME,\n    'drop': ['id'],\n}","9cdf7759":"%%time \n\nautoml = TabularUtilizedAutoML(task = task, \n                               timeout = TIMEOUT,\n                               cpu_limit = N_THREADS,\n                               reader_params = {'n_jobs': N_THREADS},\n                               verbose=0,\n                               configs_list=[\n                                   '..\/input\/lightautoml-configs\/conf_0_sel_type_0.yml',\n                                   '..\/input\/lightautoml-configs\/conf_1_sel_type_1.yml'\n                               ])\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:5], oof_pred.shape))","64ebbbdf":"%%time\n\n# Fast feature importances calculation\nfast_fi = automl.get_feature_scores('fast', silent = False)\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)","f4803961":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(log_loss(train_data[TARGET_NAME].values, oof_pred.data)))","a4b47514":"submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')\nsubmission.iloc[:, 1:] = test_pred.data\nsubmission.to_csv('lightautoml.csv', index = False)","d79918f2":"def generate(main, support, coeff):\n    \n    g = main.copy()    \n    for i in main.columns[1:]:\n        \n        res = []\n        lm, Is = [], []        \n        lm = main[i].tolist()\n        ls = support[i].tolist()  \n        \n        for j in range(len(main)):\n            res.append((lm[j] * coeff) + (ls[j] * (1.- coeff)))            \n        g[i] = res\n        \n    return g\n\nsub = generate(submission, submission1, 0.60)\ndisplay(sub)","ebfeaeb7":"sub.to_csv(\"Hybrid.csv\",index=False)","16ca911f":"# Importing Packages","def3dae2":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")\nsubmission['Class_1']=test_preds[:,0]\nsubmission['Class_2']=test_preds[:,1]\nsubmission['Class_3']=test_preds[:,2]\nsubmission['Class_4']=test_preds[:,3]\nsubmission.head()","8ff544c4":"submission.to_csv(\"XGB.csv\",index=False)","e836bfd5":"test_preds = None\ntrain_rmse = 0\nval_rmse = 0\nn_splits = 10\n\nkf = KFold(n_splits = n_splits , shuffle = True , random_state = 0)\nfor fold, (tr_index , val_index) in enumerate(kf.split(train[cols].values , train['target'].values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = train[cols].values[tr_index] , train[cols].values[val_index]\n    y_train,y_val = train['target'].values[tr_index] , train['target'].values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =XGBClassifier(**xgb_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = 500)\n    \n    train_preds = model.predict(x_train)\n    train_rmse += mean_squared_error(y_train ,train_preds , squared = False)\n    print(\"Training RMSE : \" , mean_squared_error(y_train ,train_preds , squared = False))\n    \n    val_preds = model.predict(x_val)\n    val_rmse += mean_squared_error(y_val , val_preds , squared = False)\n    print(\"Validation RMSE : \" , mean_squared_error(y_val , val_preds , squared = False))\n    \n    if test_preds is None:\n        test_preds = model.predict_proba(test[cols].values)\n    else:\n        test_preds += model.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\nprint(\"Average Training RMSE : \" , train_rmse \/ n_splits)\nprint(\"Average Validation RMSE : \" , val_rmse \/ n_splits)\n\ntest_preds \/= n_splits","6de35e27":"# Feature Importance using XGBoost default Parameters","0cfafcb5":"# XGBoost","0de641da":"xgb_params = {\n     \"seed\":42,\n    \"n_estimators\":10000,\n    \"verbosity\":1,\n    \"eval_metric\":\"mlogloss\",\n    \"alpha\":7.105038963844129,\n    \"colsample_bytree\":0.25505629740052566,\n    \"gamma\":0.4999381950212869,\n    \"reg_lambda\":1.7256912198205319,\n    \"learning_rate\":0.011823142071967673,\n    \"max_bin\":338,\n    \"max_depth\":8,\n    \"min_child_weight\":2.286836198630466,\n    \"subsample\":0.618417952155855,\n    'tree_method':'gpu_hist',\n    'gpu_id':0\n}\nxgb_params['interaction_constraints'] = '[[38, 14], [34, 14, 31], [15, 19]]'","70cb0536":"# CatBoost","46e15fbc":"1. Column names doesn't make much sense as all of columns are named by integer with prefix as feature.so from domain stand-point, cannot interpret much information from column names.\n1. No missing values in the dataset\n1. All the columns are of type integer","3d7b6632":"# Missing Values","2dcbef21":"# Correlation Matrix","6d5bcbe8":"# Importing Data","3c553177":"# Number of features Unique Values","0358820a":"1. The mean of the all the features are closer to zero.\n1. There is low variance across all the features.\n1. The median is mostly 0 except two columns","07197810":"### In the target variable, Class2 has more data points compared to the remaining labels.","2bc5a411":"# **EDA**","7eb24443":"# Outliers","95325cd7":"# LightAutoML","a2acf9bc":"## Predict for test data and check OOF score","e1092a4b":"# Target Distribution"}}