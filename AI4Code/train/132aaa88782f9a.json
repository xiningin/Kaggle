{"cell_type":{"f4195d13":"code","82d1e201":"code","e5345f90":"code","803497d6":"code","6c460dd6":"code","03cf21d2":"code","84ad5c12":"code","84b0ec77":"code","c66e87dd":"code","fbceac68":"code","92d79040":"code","63b65d47":"code","4c0311f7":"code","fba7b806":"code","86ea339a":"code","fb4db034":"code","707ede00":"code","fc4329b9":"code","4c34d14f":"markdown","de2957c8":"markdown","7199ecb9":"markdown","8d71f494":"markdown","4e405e19":"markdown","0b4ce253":"markdown","dfd0f6bc":"markdown","feca92f1":"markdown","71609a58":"markdown","b5460545":"markdown","c025b1a3":"markdown","0c5a464f":"markdown","3617077f":"markdown","b3e1d725":"markdown","e8fa6501":"markdown","fcc58a99":"markdown","b6a7ae70":"markdown","5ea90069":"markdown","eb088520":"markdown","f87101ae":"markdown"},"source":{"f4195d13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # Importing NumPy library\nimport pandas as pd # Importing Pandas library\nimport matplotlib.pyplot as plt # Importing Matplotlib library's \"pyplot\" module\nimport seaborn as sns # Imorting Seaborn library\n\n# Input data files are available in the \"..\/input\/\" directory.\n\n# This lines for Kaggle:\nimport os\nprint(os.listdir(\"..\/input\"))","82d1e201":"data = pd.read_csv(\"..\/input\/bookfeatures.csv\") # Read CSV file and load into \"data\" variable\ndata.info() # Show detailed information for dataset columns(attributes)","e5345f90":"data.corr() # This method shows the correlation matrix of the columns (attributes)","803497d6":"fig, axes = plt.subplots(figsize=(18, 18)) # This method creates a figure and a set of subplots. Then, returns figure and axis infos.\nsns.heatmap(data=data.corr(), annot=True, linewidths=.5, fmt=\".1f\", ax=axes) # Figure out heatmap\n# Parameters:\n# data : 2D data for the heatmap.\n# annot : If True, write the data value in each cell.\n# linewidths : Width of the lines that will divide each cell.\n# fmt : String formatting code to use when adding annotations.\n# ax : Axes in which to draw the plot, otherwise use the currently-active Axes.\nplt.show() # Shows only plot and remove other info","6c460dd6":"data.head(10) # Returns first 10 entries","03cf21d2":"data.columns # Returns column names as a list","84ad5c12":"# Line Plot\n# Plot all Average Rating values of the Dataset\ndata.avgRating.plot(kind='line', color='r', label='Average Rating', linewidth=1, alpha=0.7, grid=True, linestyle = '-', figsize=(18,9))\nplt.legend(loc='upper right')     # Location of the legend\nplt.xlabel('X Axis')              # Label of the X axis\nplt.ylabel('Y Axis')              # Label of the Y axis\nplt.title('Ratings')            # Title of the overall plot\nplt.show()","84b0ec77":"# Scatter Plot\n# x = rating1, y = rating_count\ndata.plot(kind='scatter', x='rating1', y='rating_count', alpha=0.8, color='green', figsize=(18,9))\nplt.xlabel('Rating 1 Star')              # Label of the X axis\nplt.ylabel('Rating Count')               # Label of the y axis\nplt.title('Rating 1 Star to All Rating Scatter Plot') # Title of the all plot\nplt.show()","c66e87dd":"# Histogram\n# Frequency of all average ratings\n# bins : Number of bars in figure\ndata.avgRating.plot(kind='hist', bins=50, figsize = (18,9))\nplt.show()","fbceac68":"dict = {'germany' : 'berlin', 'usa' : 'washington'} # Create a dictionary\nprint(dict.keys()) # Print its keys\nprint(dict.values()) # Print its values","92d79040":"dict[\"germany\"] = \"munich\" # Updating existing entry\nprint(dict)\ndict[\"france\"] = \"paris\" # Adding new entry\nprint(dict)\ndel dict[\"usa\"] # Removing existing entry\nprint(dict)","63b65d47":"print(\"france\" in dict) # Check dictionary key existence\ndict.clear() # Remove all elements of dictionary\nprint(dict)\ndel dict # Remove dictionary itself","4c0311f7":"data.columns","fba7b806":"series = data['avgRating'] # Data which place in \"avgRating\" column return as a Series data type \nprint(type(series)) # Prints type of \"series\" variable\ndata_frame = data[['avgRating']] # Data which place in \"avgRating\" column return as a DataFrame data type\nprint(type(data_frame)) # Prints type of \"data_frame\" variable","86ea339a":"x = data['avgRating'] > 4.0 # Filtering DataFrame and return filtered data\ndata[x].head(10) # Print first 10 filtered data","fb4db034":"# Get data which provides condition \"avgRating > 4.2\" AND \"rating_count > 20000\"\ndata[np.logical_and(data['avgRating'] > 4.2, data['rating_count'] > 20000)]","707ede00":"# Get data which provides condition \"avgRating > 4.2\" AND \"rating_count > 20000\"\ndata[(data['avgRating'] > 4.2) & (data['rating_count'] > 20000)]","fc4329b9":"# Print elements of the list:\nlis = [1, 2, 3, 4, 5, 6]\nfor i in lis:\n    print(\"i is: \", i)\nprint('')\n\n# Enumerating list elements and print they:\nfor index, value in enumerate(lis):\n    print(index, \" : \", value)\nprint('')\n\n# Print dictionary elements:\ndict = {'spain' : 'madrid', 'usa' : 'vegas'}\nfor key, value in dict.items():\n    print(key, \" : \", value)\nprint('')\n\n# Iterating on DataFrame:\nfor index, value in data[['avgRating']][0:1].iterrows():\n    print(index, \" : \", value)","4c34d14f":"## Pandas\n\nWe've already mentioned what this library does. The most useful feature of this library is that it can easily handle files with CSV extension, which is an extension of most dataset. The CSV extension specifies that data is separated by a comma. The Pandas library has 3 types of data structures:\n\n* **Series** : Used for one-dimensional data. Usually has the same functions as arrays.\n* **DataFrame** : Used for two-dimensional data. It is an appropriate data structure for processing Excel tables and CSV data.\n* **Panel** : Used for three-dimensional data. Deprecated in \"0.20.0\" version and will be deleted in later versions.\n\nFirst, let's list again the columns our dataset has:","de2957c8":"As you can see, it found only the correlation of numerical data and presented his Heatmap. For string-type data, doing this is unreasonable and distressing. Let's learn more about dataset by reviewing the first 10 entries:","7199ecb9":"First you can see that there are 2916 entries in this dataset in the line that starts with \"RangeIndex\". These inputs are numbered up from 0 to 2915. You can see that the dataset has 16 columns. Now, let us explain what these columns mean:\n\n* **Unnamed: 0** : Pandas assigned him this name automatically because this column is an unnamed column. This column of type \"_int64_\" and indicates the sequence number of each entry. There is no other purpose.\n* **author** : The column is the author of the book. Column type is \"_object_\".\n* **avgRating** : Indicates the average score of the book. On the GoodReads site, users can rate the books they read with a score between 0 and 5. This column also shows the average scores of books in preparing the dataset. The column is \"_float64_\" because the average score can be a decimal value.\n* **bookid** : Specifies the unique ID of the book assigned to it on the GoodReads site and its type is \"_int64_\".\n* **genre1** : As you know, books and movies have certain genres. This column also specifies the primary genre of this book has and its type is \"_object_\".\n* **genre2** : This column indicates the secondary type that the book has. Its type is \"_object_\".\n* **isbn** : ISBN (International Standard Book Number) is a book numbering system introduced by ISO. This number, which is given to books and unique to every book in the world, is also called the ISBN code. This column indicates this code and its type is \"_float64_\".\n* **lang** : The column is the language of the book. Its type is \"_object_\".\n* **name** : The column is the name of the book. Its type is \"_object_\".\n* **rating1** : Specifies the number of people who gave 1 star, in other words 1 point. Its type is \"_float64_\".\n* **rating2** : Specifies the number of people who gave 2 star, in other words 2 point. Its type is \"_float64_\".\n* **rating3** : Specifies the number of people who gave 3 star, in other words 3 point. Its type is \"_float64_\".\n* **rating4** : Specifies the number of people who gave 4 star, in other words 4 point. Its type is \"_float64_\".\n* **rating5** : Specifies the number of people who gave 5 star, in other words 5 point. Its type is \"_float64_\".\n* **rating_count** : Indicates the total number of people who voted for the book. Its type is \"_float64_\".\n* **url** : Specifies the URL address of the book in the site. Its type is \"_object_\".\n\nAs you can see, columns with a string value is in \"_object_\" type, integer values \u200b\u200bwith a certain number of lengths in \"_int64_\" type, integers with a variable number of lengths, and columns with a decimal value are defined as \"_float64_\". You can also see \"not-null\" in the output and the numbers to the left of it. \"not_null\" is an expression to indicate that this column should not be empty, while the number to the left of it is an expression that indicates that this column is full. At the end of the output, we see statements in the dataset showing how many data types are available and how much memory is used.\n\nNow let's examine the correlation of all columns. Correlation is a number that indicates how the two datasets are related to each other. As this number approaches 1.0, the relationship is strengthened in the right direction. As it approaches -1.0, it is strengthened in the opposite direction. If this value is close to zero, the bond between the two data is weak. Let us now show the matrix that shows the correlation of the columns with each other in a very simple method:","8d71f494":"Let us now see how we can export data in a column to the Series and DataFrame data structures:","4e405e19":"## Iterating on Lists, Dictionaries and Pandas Data Structures\n\nIn this section, we'll show how to iterate on lists, dictionaries, and Pandas' DataFrame data structures using the \"_for_\" loop. Let's show them all on one code:","0b4ce253":"<a id=\"3\"><\/a> <br>\n# 3. Dataset Exploration\n\nIn this section, the description of the structure of the dataset will be made first, then various visualization and information acquisition will be done with Python. The first thing we will do is import the dataset into Python and get the various information about the dataset's attributes with the \"_info()_\" function:","dfd0f6bc":"_Best Regards..._\n\n_**Mustafa Yemural**_","feca92f1":"We could do the same with the \"&\" operator as follows:","71609a58":"<a id=\"4\"><\/a> <br>\n# 4. Line Plots, Scatter Plots and Histograms\n\nIn this section, we will perform three basic graphical drawing operations to examine the relationship between the various columns of dataset. Let us first look at what these graphs are and what their properties are:\n\n* **Line Plot** : It is the best chart to use when the X axis specifies time. In this project, indexes can be taken as time and drawing can be performed.\n* **Scatter Plot** : If there is a correlation between the two variables, it is the best graph to be used.\n* **Histogram** : It is the best graph to be used when we want to see the distribution of numerical data.\n\n\"Pandas.DataFrame.plot\" method will be used for drawing these graphs. Common parameters and descriptions of this method are as follows:\n\n* **kind** : Specifies the type of graph to draw. The values \u200b\u200bthat can be given and their meanings are as follows:\n<table>\n<tr><td><strong>Value<\/strong><\/td> <td><strong>Meaning<\/strong><\/td><\/tr>\n    <tr><td>line<\/td> <td>Line Plot (Default)<\/td><\/tr>\n    <tr><td>bar<\/td> <td>Vertical Bar Plot<\/td><\/tr>\n    <tr><td>barh<\/td> <td>Horizontal Bar Plot<\/td><\/tr>\n    <tr><td>hist<\/td> <td>Histogram<\/td><\/tr>\n    <tr><td>box<\/td> <td>Boxplot<\/td><\/tr>\n    <tr><td>kde<\/td> <td>Kernel Density Estimation Plot<\/td><\/tr>\n    <tr><td>area<\/td> <td>Area Plot<\/td><\/tr>\n    <tr><td>pie<\/td> <td>Pie Plot<\/td><\/tr>\n    <tr><td>scatter<\/td> <td>Scatter Plot<\/td><\/tr>\n    <tr><td>hexbin<\/td> <td>Hexbin Plot<\/td><\/tr>\n<\/table>\n* **color** : Specifies the color of the dot, line, or 2D shapes to be drawn in the plot to be drawn. Various colors can be written in English or in their first letters.\n* **label** : Specifies the label of the variable to be drawn.\n* **linewidth** : Specifies the thickness of the lines to be drawn as a decimal number.\n* **alpha** : Specifies the opacity of the dot, line, or 2D shapes to be drawn in the plot to be drawn. \"1.0\" is the most opaque, while \"0.0\" indicates the most transparent value.\n* **grid** : Indicates whether a grid should be placed behind the drawing.\n* **linestyle** : Specifies the style of lines or dots to draw. The values \u200b\u200bthat can be given and their meanings are as follows:\n<table>\n<tr><td><strong>Value<\/strong><\/td> <td><strong>Meaning<\/strong><\/td><\/tr>\n    <tr><td>'-' or 'solid'<\/td> <td>Solid Line<\/td><\/tr>\n    <tr><td>'--' or 'dashed'<\/td> <td>Dashed Line<\/td><\/tr>\n    <tr><td>'-.' or 'dashdot'<\/td> <td>Dash-dotted Line<\/td><\/tr>\n    <tr><td>':' or 'dotted'<\/td> <td>Dotted Line<\/td><\/tr>\n    <tr><td>'None' or ' ' or ''<\/td> <td>Nothing<\/td><\/tr>\n<\/table>\n\nNow let's draw Line Plot, Scatter Plot and Histogram graphs one by one.","b5460545":"<a id=\"1\"><\/a> <br>\n# 1. Introduction\n\nIn this study, we will analyze the dataset which contains various information of the books on the website of the world's largest book archive and book proposal site [GoodReads](https:\/\/www.goodreads.com). This dataset also includes information on the names, writers and spelling languages of books, as well as the rating and total score based on the votes given by various users. The study will be impelated with the Python programming language and is intended to illustrate the various features and libraries of this language.","c025b1a3":"We can make inferences from this table. For example, we can see how much the \"rating\" columns are related to each other. In addition, the \"isbn\" column with the \"rating\" column, we see how irrelevant. Here, the columns with very strong relationship in inverse proportions do not appear. Now let's examine this matrix as a Heatmap. Heatmap is a two-dimensional data visualization technique where values \u200b\u200bare indicated by colors. With the following code, we can extract the Heatmap of this table using Matplotlib and Seaborn:","0c5a464f":"<a id=\"5\"><\/a> <br>\n# 5. EXTRA: Python Notes\n\nThis section will provide you with a variety of information about the Python programming language and Pandas.","3617077f":"<a id=\"2\"><\/a> <br>\n# 2. Using Libraries\n\nThis section will give information about Python libraries to be used in the study and these libraries will be imported into the project. Here are the libraries and explanations we will use:\n\n* **NumPy** : This library is actually a dependency for other libraries. The main purpose of this library is to provide a variety of mathematical operations on matrices and vectors in Python. Our project will be used this library to provide support to other libraries.\n* **Pandas** : This library performs import and processing of dataset in Python. In our project, it will be used to include the CSV extension dataset in the project and to perform various operations on it.\n* **Matplotlib** : This library, which is usually used to visualize data. It will perform the same task in our project.\n* **Seaborn** : This library which has similar features to Matplotlib is another library used for data visualization in Python. In our project, it will be used for the implementation of various features not included in the Matplotlib library.\n\nNow let's import these libraries into our project and get them ready for use:","b3e1d725":"Let's find out the column names clearly in case they use the column names when programming:","e8fa6501":"## Dictionary\n\nA key-value is an associated data type. It is faster than lists. For example, in the definition \"_dictionary = {'turkey': 'istanbul'}_\" the \"_turkey_\" is key and the \"_istanbul_\" is its value. Now create a dictionary and look at its keys and values:","fcc58a99":"Now let's filter the DataFrames that we get from dataset according to certain conditions and observe the result. For example, let's print entries with an \"avgRating\" column of 4.0 and above, indicating the average score:","b6a7ae70":"As you can see from the column \"_Unnamed: 0_\", some data has been eliminated from the output. Now, using the \"logical_and\" method of the NumPy library, let's filter the two conditions into logical AND:","5ea90069":"The keys must be immutable. Therefore, keys can be string, boolean, float, integer, or tuple. However, since lists are no objects that cannot be changed, the keys cannot be list types. Also, the keys in a dictionary must be unique. Now, add new entries in the dictionary, update and delete the existing entry:","eb088520":"# Contents\n\n1. [Introduction](#1)\n1. [Using Libraries](#2)\n1. [Dataset Exploration](#3)\n1. [Line Plots, Scatter Plots and Histograms](#4)\n1. [EXTRA: Python Notes](#5)","f87101ae":"The last two actions we will do about dictionaries will be to check if an item is in the dictionary and completely delete the dictionary:"}}