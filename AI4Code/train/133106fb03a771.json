{"cell_type":{"b9cc2a0b":"code","286ff918":"code","f46c304a":"code","2f47dfd5":"code","39a5d91e":"code","4dfbb85c":"code","298920ef":"code","a4cd6010":"code","26bfb527":"code","080405b5":"code","fb49412a":"code","80c3e3c7":"code","27358a05":"code","c39a3edc":"code","b6d593dd":"code","5f68d265":"code","ca7e0510":"code","e47e0a8d":"code","717d951a":"code","ddb0c4cb":"code","7102ca5e":"code","c0dc7d1a":"code","4a8eecb2":"code","04918427":"code","179e8723":"code","5624fbf3":"code","91e898a9":"code","7fdc240d":"code","9897a730":"code","ff7fd7d4":"markdown","67d0d6e9":"markdown","09f18ce9":"markdown"},"source":{"b9cc2a0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","286ff918":"import os \nimport pandas as pd\nimport numpy as np\nfrom glob import glob \nimport torch\nfrom PIL import Image\nfrom skimage import io, transform\nfrom skimage.util import random_noise\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils, models\nimport time\nfrom datetime import datetime\nimport gc \n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.tensorboard import SummaryWriter","f46c304a":"def getDevice(): \n    if torch.cuda.is_available():\n        device = torch.device(\"cuda:0\")\n        print(\"Training on GPU... Ready for HyperJump...\")\n        torch.cuda.empty_cache()\n    else:\n        device = torch.device(\"cpu\")\n        print(\"Training on CPU... May the force be with you...\")\n    return device \ndevice = getDevice()","2f47dfd5":"random_state = 8","39a5d91e":"basepath = '\/kaggle\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/'\ndef setupDataFrame(basepath): \n    classesCount = {}\n    dataset_list = []\n\n    for imagePath in glob(os.path.join(basepath, '*', '*.png')):\n        #className = os.path.split(imagePath)[0].split('\/')[2]\n        className = os.path.splitext(os.path.basename(imagePath))[0].split('-')[0]\n        classesCount[className] = classesCount.get(className, 0) + 1\n\n        dataset_list.append({'imagePath': imagePath, 'label': className})\n\n    df = pd.DataFrame(dataset_list)\n    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n    return df, list(classesCount.keys())\ndf, all_labels = setupDataFrame(basepath)\ndf","4dfbb85c":"df.head()","298920ef":"df.value_counts('label')","a4cd6010":"all_labels","26bfb527":"label_to_key_mapper = {}\nkey_to_label_mapper = {}\nfor i, label in enumerate(all_labels): \n    label_to_key_mapper[label] = i\n    key_to_label_mapper[i] = label\ndef label_to_key_transform(label):\n    key = label_to_key_mapper[label]\n    return torch.tensor(key)","080405b5":"X = df.iloc[:,:len(df.columns) - 1]\ny = df.iloc[:,len(df.columns) - 1]\n\nprint(f'X.shape {X.shape} - type(X) {type(X)}')\nprint(f'y.shape {y.shape} - type(y) {type(y)}')","fb49412a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)\n\nX_train = X_train.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\n\nX_test = X_test.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\n\nprint(f'X_train.shape {X_train.shape} - type(X_train) {type(X_train)}')\nprint(f'y_train.shape {y_train.shape} - type(y_train) {type(y_train)}')\nprint(f'X_test.shape {X_test.shape} - type(X_test) {type(X_test)}')\nprint(f'y_test.shape {y_test.shape} - type(y_test) {type(y_test)}')","80c3e3c7":"# Taken from https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html\nclass CustomDataset(Dataset):\n    def __init__(self, X, y, transform, add_salt_and_pepper=False):\n        self.X = X \n        self.y = y\n        self.transform = transform\n        self.add_salt_and_pepper = add_salt_and_pepper\n\n    def __len__(self):\n        return len(self.y)\n        \n    def __getitem__(self, index):\n        if torch.is_tensor(index):\n            index = index.tolist()\n        imagePath = self.X['imagePath'][index]\n        #image = Image.open(imagePath).convert('RGBA')\n        image = Image.open(imagePath).convert('RGB')\n        #image = io.imread(imagePath)\n        if self.transform: \n            image = self.transform(image)\n        if self.add_salt_and_pepper: \n            image = random_noise(image, mode='s&p', amount=0.03, seed=8)\n            image = torch.from_numpy(image)\n        return (image, label_to_key_transform(self.y[index]))\n","27358a05":"\n\nnormal_transform = transforms.Compose([\n    #transforms.ToPILImage(), \n    transforms.ToTensor(), \n    #transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n","c39a3edc":"class CustomModule(nn.Module): \n    def __init__(self, modelName, in_features, out_features, pretrained=True):\n        super().__init__()\n        self.model = self.chooseModel(modelName, in_features, out_features, pretrained)\n\n    def chooseModel(self, modelName, in_features, out_features, pretrained): \n        if modelName == 'resnet': \n            model = models.resnet18(pretrained=pretrained)\n            if in_features > 3: \n                model.conv1 = nn.Conv2d(in_features, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            num_ftrs = model.fc.in_features \n            model.fc = nn.Linear(in_features=num_ftrs, out_features=out_features) \n        else: \n            print('No model given!')\n        return model\n\n    def forward(self, x):\n        outputs = self.model(x) \n        return outputs \n\n","b6d593dd":"def sample_image(X_data, y_data, X_pred, loss, i): \n    fig, ax = plt.subplots(1, 2)\n\n    sample_img = transforms.functional.to_pil_image(X_data[i])\n    output_img = transforms.functional.to_pil_image(X_pred[i])\n\n    ax[0].imshow(sample_img)\n    ax[0].axis('off')\n    ax[1].imshow(output_img, cmap='gray')\n    ax[1].axis('off')\n\n    plt.tight_layout()\n        \n    fig.suptitle(f'{key_to_label_mapper[y_data[i].item()]} - Loss: {loss}')\n    plt.show()\n","5f68d265":"custom_dataset = CustomDataset(X_train, y_train, normal_transform)\ncustom_dataloader = DataLoader(custom_dataset, batch_size=32)\n\ncustom_iter = iter(custom_dataloader)\ncus_sample_, cus_label = next(custom_iter)\ncus_sample = cus_sample_.to(device)\n\nprint(cus_sample.shape)","ca7e0510":"sample_image(cus_sample, cus_label, cus_sample, 0, 15)","e47e0a8d":"def loadModel(modelPath, modelMegaUrl): \n    if not os.path.exists(modelPath):\n        print(f'{modelPath} NOT found... Downloading file from MEGA')\n        from mega import Mega\n        mega = Mega() \n        mega.download_url(modelMegaUrl, '.\/')\ndef saveModel(filename, model, isPart=False): \n    torch.save(model.state_dict(), filename)\n    #if USE_GOOGLE: \n    if False:\n        if isPart: \n            !gupload --to \"\"$PART_MODEL_FOLDER_ID\"\" $filename\n        else: \n            !gupload --to \"\"$MODEL_FOLDER_ID\"\" $filename","717d951a":"def basicMetrics(y_test, y_pred, withLabels=False):\n    result = {}\n    plain_cm = metrics.confusion_matrix(y_test, y_pred)\n    if withLabels: \n        cm = pd.DataFrame(plain_cm, columns=[f'Predicted {label}' for label in all_labels ], index=[f'True {label}' for label in all_labels ]) \n    else: \n        cm = pd.DataFrame(plain_cm)\n\n    result['accuracy'] = metrics.accuracy_score(y_test, y_pred)\n    result['precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n    result['recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n    result['f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n    result['plain_confusion_matrix'] = plain_cm\n    result['confusion_matrix'] = cm\n    return result\n\ndef printMetrics(result): \n    print(\"    - Accuracy: {:.2f}%\".format(result['accuracy'] * 100))\n    print(\"    - Precision: {:.2f}%\".format(result['precision'] * 100))\n    print(\"    - Recall: {:.2f}%\".format(result['recall'] * 100))\n    print(\"    - F1: {:.2f}%\".format(result['f1'] * 100))\n    print(f\"{result['plain_confusion_matrix']}\")","ddb0c4cb":"def test_model(name, model, criterion, dataloader, sampleEvery=200, matrixWithLabels=False): \n\n    print(f'Evaluating {name}')\n    with torch.no_grad(): \n        model.eval()\n        test_losses = []\n        test_accuracies = []\n        eval_start_time = time.time()\n        y_preds = np.arange(0)\n        y_trues = np.arange(0)\n\n        for i, (data_, labels_) in enumerate(dataloader): \n            data, labels = data_.to(device), labels_.to(device)\n            outputs = model(data)\n            loss = criterion(outputs, labels)\n            loss = loss.cpu().detach().item()\n            test_losses.append(loss)\n\n            _, y_pred = torch.max(outputs, dim=1)\n            y_pred = y_pred.cpu().detach()\n            y_true = labels_.detach()\n            accuracy = torch.sum(y_pred == y_true).item()\n            test_accuracies.append(accuracy)\n\n            y_preds = np.append(y_preds, y_pred.numpy())\n            y_trues = np.append(y_trues, y_true.numpy())\n            \n        results = basicMetrics(y_trues, y_preds, withLabels=matrixWithLabels)\n        printMetrics(results)\n\n    overall_loss = np.array(test_losses).mean()\n    overall_accuracy = np.array(test_accuracies).mean()\n    print(f'Test loss resulted in: {overall_loss} with accuracy at: {overall_accuracy} - Testing time took: {time.time() - eval_start_time:3.5} seconds')\n    return overall_loss, results\n","7102ca5e":"def train_model(name, model, train_dataloader, test_dataloader, epochs, optimizer, criterion, evalEvery): \n    losses = []\n    accuracies = []\n    epoch = 0 \n    times_buffed = 0\n    while epoch < epochs: \n        model.train()\n        loss_per_epoch = []\n        loss_per_eval = []\n        accuracy_per_epoch = []\n        accuracy_per_eval = []\n        amount_of_data = 0 \n        best_accuracy_so_far = 0\n        start_time = time.time()\n        eval_start_time = time.time()\n        for i, (data_, labels_) in enumerate(train_dataloader): \n            ## labels is only used for sampling, not for training the model\n            data, labels = data_.to(device), labels_.to(device)\n            if len(data_) <= 1: \n                continue\n\n            optimizer.zero_grad()\n\n            outputs = model(data)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, y_pred = torch.max(outputs, dim=1)\n            y_pred = y_pred.cpu().detach()\n            y_true = labels_.detach()\n            accuracy = torch.sum(y_pred == y_true).item()\n\n            loss_per_epoch.append(loss.cpu().detach().item())\n            loss_per_eval.append(loss.cpu().detach().item())\n            accuracy_per_epoch.append(accuracy)\n            accuracy_per_eval.append(accuracy)\n            amount_of_data += len(data_)\n\n            if i % evalEvery == 0: \n                curr_loss = np.array(loss_per_eval).mean()\n                curr_accuracy = np.array(accuracy_per_eval).mean()\n                time_taken = time.time() - eval_start_time\n                print(f'Epoch {epoch:3}\/{epochs:3} - Batch {i:5} - Loss: {curr_loss} - Accuracy: {curr_accuracy} - Took {time_taken:3.5} seconds at {datetime.now()}')\n                results = basicMetrics(y_true, y_pred)\n                eval_start_time = time.time()\n                accuracy_per_eval = []\n\n        end_time = time.time()\n        loss_per_epoch = np.array(loss_per_epoch).mean()\n        losses.append(loss_per_epoch)\n\n        accuracy_per_epoch = np.array(accuracy_per_epoch).mean()\n        accuracies.append(accuracy_per_epoch)\n\n        print(f'Epoch {epoch:3}\/{epochs:3} - Loss: {loss_per_epoch} - Accuracy: {accuracy_per_epoch} - Took {(end_time - start_time):3.5} seconds at {datetime.now()}')\n\n        test_loss, results = test_model(name, model, criterion, test_dataloader)\n        if results['accuracy'] > best_accuracy_so_far: \n            best_accuracy_so_far = results['accuracy']\n            acc = str(best_accuracy_so_far * 100).replace('.', '_')\n            filename = f'Part-{name}-Accuracy-{acc}.pt'\n            saveModel(filename, model, isPart=True)\n            print('Improvement-Detected, saving-model')\n        print(\"*\" * 100)\n        epoch += 1\n        if times_buffed < 5 and epoch >= epochs and results['accuracy'] < 0.85: \n            epochs += 1\n            times_buffed += 1\n            print(f'Bumping Model Epochs by 1.')\n\n    return model, results\n","c0dc7d1a":"batch_size = 32\n\ntrain_dataset = CustomDataset(X_train, y_train, normal_transform)\ntest_dataset = CustomDataset(X_test, y_test, normal_transform)\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","4a8eecb2":"model = CustomModule('resnet', 3, len(all_labels), pretrained=True)\nmodel.to(device)","04918427":"optimizer = optim.Adam(model.parameters(), lr=1e-5)\ncriterion = nn.CrossEntropyLoss()","179e8723":"epochs = 2\nevalEvery = 100 ","5624fbf3":"name = 'Testing'\nmodel, results = train_model(name, model, train_dataloader, test_dataloader, epochs, optimizer, criterion, evalEvery)","91e898a9":"loss, results = test_model(name, model, criterion, test_dataloader, sampleEvery=10, matrixWithLabels=True)\n","7fdc240d":"printMetrics(results)","9897a730":"results['confusion_matrix']","ff7fd7d4":"## Model","67d0d6e9":"## Testing Custom DataSet","09f18ce9":"## Dataset Setup"}}