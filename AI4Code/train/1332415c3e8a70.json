{"cell_type":{"0f95f83f":"code","a37a8438":"code","bb498e50":"code","3c347b3e":"code","42e78831":"code","80ffe18a":"code","597c533e":"code","1ea797db":"code","436bb83a":"code","be723147":"code","db283105":"code","dfccf738":"code","ddf26c5d":"code","c6ccc329":"code","a4fd0b78":"code","4f9be5ea":"code","60435d81":"code","51777c8f":"code","e095ccb8":"code","acdcbbdf":"code","53f58547":"markdown","23068e10":"markdown","afa5ddbc":"markdown","48288742":"markdown"},"source":{"0f95f83f":"import numpy as np \nimport pandas as pd \nfrom textblob import TextBlob\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","a37a8438":"file = '\/kaggle\/input\/bitcoin-tweets-20160101-to-20190329\/tweets.csv'\ndf = pd.read_csv(file, sep=';',nrows=1300)\nprint(df.head())","bb498e50":"data = df.drop(['replies','likes','retweets','timestamp','url','id','user','fullname'],axis = 1)\ndata.reset_index(drop=True, inplace=True)\ndata.head()","3c347b3e":"tweets = data['text']\nprint(tweets[2])","42e78831":"pip install whatthelang","80ffe18a":"from whatthelang import WhatTheLang\n\nwtl = WhatTheLang()\nL=[]\nfor row in data['text']:\n    if len(row)!=0:\n        L.append(wtl.predict_lang(row))\n    else:\n        L.append(None)\n        \ndata['lang'] = L\ndata.head()","597c533e":"data = data[data[\"lang\"] == 'en']\ndata.head()","1ea797db":"import nltk\nimport re\nfrom nltk.corpus import stopwords\n\ndef text_cleaning(text):\n    forbidden_words = set(stopwords.words('english'))\n    text = ' '.join(text.split('.'))\n    text = re.sub('\\\/',' ',text)\n    text = text.strip('\\'\"')\n    text = re.sub(r'@([^\\s]+)',r'\\1',text)\n    text = re.sub(r'\\\\',' ',text)\n    text = text.lower()\n    text = re.sub('[\\s]+', ' ', text)\n    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n    text = re.sub('((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))',' ',text)\n    text = re.sub(r'((http)\\S+)','',text)\n    text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()\n    text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n    text = [word for word in text.split() if word not in forbidden_words]\n    return ' '.join(text)\n\ndata['text'] = data['text'].apply(lambda text: text_cleaning(text))\ndata.sample(3)","436bb83a":"from textblob import TextBlob\n\ndef sentiment(txt):\n    return TextBlob(txt).sentiment.polarity\n\ndata['sentiment'] = data['text'].apply(lambda txt: sentiment(txt))      # new column of sentiment\n\ndata.sample(10)","be723147":"data.to_csv('my_clean_tweets.csv', sep = ';',index = False)\n\ntweets=pd.read_csv('my_clean_tweets.csv', sep=';')\ntweets.sample(10)","db283105":"from numpy.random import RandomState\n\nrng = RandomState()\ntrain_data = tweets.sample(frac=0.8, random_state=rng)\ntest_data = tweets.loc[~tweets.index.isin(train_data.index)]\nprint('La taille des donn\u00e9es d entrinement:',len(train_data))\nprint('La taille des donn\u00e9es de test:',len(test_data))","dfccf738":"import keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense,LSTM,Dropout,Activation,Embedding,Bidirectional","ddf26c5d":"max_features = 20000  # Only consider the top 20k words\nmaxlen = 200","c6ccc329":"train_data['flag'] = 'TRAIN'\ntest_data['flag'] = 'TEST'\n\n\ntotal_docs = pd.concat([train_data,test_data],axis = 0,ignore_index = True)\nphrases = total_docs['text'].tolist()\n\ntotal_docs.sample(10)","a4fd0b78":"from keras.preprocessing.text import one_hot\nvocab_size = 50000\nencoded_phrases = [one_hot(d, vocab_size) for d in phrases]\ntotal_docs['Phrase'] = encoded_phrases\ntrain_data = total_docs[total_docs['flag'] == 'TRAIN']\ntest_data = total_docs[total_docs['flag'] == 'TEST']\nx_train = train_data['Phrase']\ny_train = train_data['sentiment']\nx_val = test_data['Phrase']\ny_val = test_data['sentiment']","4f9be5ea":"print(total_docs['Phrase'][23])","60435d81":"x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\nx_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)","51777c8f":"model = Sequential()\ninputs = keras.Input(shape=(None,), dtype=\"int32\")\n\n# Embed each integer in a 128-dimensional vector\nmodel.add(inputs)\nmodel.add(Embedding(50000, 32))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(LSTM(32))\n\n# Add a classifier\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.summary()","e095ccb8":"model.compile(optimizer='rmsprop', \n              loss='binary_crossentropy', \n              metrics=[\"accuracy\"])\n\nmodel.fit(x_train, y_train, \n          batch_size=128, \n          epochs=20, \n          validation_data=(x_val, y_val),\n          validation_steps=20)","acdcbbdf":"from keras.preprocessing.text import one_hot\n\ntest_loss, test_acc = model.evaluate(x=x_val, y=y_val)\n\nprint('Test Loss: {}'.format(test_loss))\nprint('Test Accuracy: {}'.format(test_acc))\n\nsample_text = ('Bitcoin just lost half its value overnight. Sorry all you savvy investors ')\nvocab_size = 50000\n\nmodel.predict(one_hot(sample_text, vocab_size))","53f58547":"On divise ensuite le data set data en test et train \n- train est de taille 80%\n- test est de taille 20%","23068e10":"On a converti la phrase en chiffres","afa5ddbc":"In conclusion, we created a bi-directional LSTM model and have trained it to detect sentiment. We reached 80% training and 82% validation accuracy.","48288742":"#  Maintenant c'est la partie keras !!!"}}