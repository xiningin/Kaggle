{"cell_type":{"4fcc50e2":"code","24771682":"code","c1274c09":"code","f71cae57":"code","4067ad77":"code","35921cbe":"code","9b0d6ab6":"code","4b67deb7":"code","f976d315":"code","02a39719":"code","4e1d8932":"code","79e14262":"code","15eda377":"code","2a2c5e64":"code","a537c701":"code","6331a9c7":"code","e1bfe775":"code","94f77b24":"code","2cd1342b":"code","741cebe7":"code","31d0a84e":"code","07761969":"code","842246cc":"code","bf675dbf":"code","b4bc14ba":"code","72dba7fb":"code","a1fc254e":"code","93aaa11d":"code","bf93450f":"code","9b13cd47":"code","93c7e788":"code","cfd28d38":"code","217423ec":"code","46a3e046":"code","db3b9f6d":"code","f1585e6c":"markdown","072fe731":"markdown","dcc2c0cf":"markdown","9865615f":"markdown","792ea852":"markdown","7a323fd2":"markdown","275754c8":"markdown","46c04bcd":"markdown","15f9ef66":"markdown","4d422df5":"markdown","3c7e8988":"markdown","97efac31":"markdown","23aeff88":"markdown","c52b03d2":"markdown","5c1a51b6":"markdown","dbffcf80":"markdown","c67ceb1f":"markdown","37a06bd9":"markdown","d8a63796":"markdown","76965403":"markdown","4755ac5e":"markdown"},"source":{"4fcc50e2":"#common\nimport numpy as np\nimport pandas as pd \nimport IPython\nfrom IPython.display import display\n\n#visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px","24771682":"reddit = pd.read_csv('\/kaggle\/input\/dataisbeautiful\/r_dataisbeautiful_posts.csv', low_memory=False)","c1274c09":"reddit.info()","f71cae57":"reddit.head(3).T","4067ad77":"reddit.loc[reddit['awarders'] == \"[]\", 'awarders'] = 0\nreddit.loc[reddit['awarders'] == \"['stompstumpstamp']\", 'awarders'] = 1\nreddit.loc[reddit['awarders'].isna(), 'awarders'] = 0","35921cbe":"nan_replacements = {\"author_flair_text\": 'none', \"removed_by\": 'avalible', \"total_awards_received\": 0, \"title\": 'unknown'}\nreddit = reddit.fillna(nan_replacements)","9b0d6ab6":"reddit.isna().sum()","4b67deb7":"reddit['created_loc_time'] = pd.to_datetime(reddit['created_utc'], unit='s')","f976d315":"reddit['year'] = [d.year for d in reddit['created_loc_time']]\nreddit['month'] = [d.month for d in reddit['created_loc_time']]\nreddit['day'] = [d.day for d in reddit['created_loc_time']]\nreddit['dayofweek'] = [d.isoweekday() for d in reddit['created_loc_time']]\nreddit['hour'] = [d.hour for d in reddit['created_loc_time']]","02a39719":"reddit.removed_by.value_counts()","4e1d8932":"reddit.loc[reddit['removed_by'] == 'avalible', 'is_avalible'] = 1\nreddit.loc[reddit['removed_by'] != 'avalible', 'is_avalible'] = 0","79e14262":"reddit.head(3).T","15eda377":"top_authors = reddit.query('author != \"[deleted]\"')['author'].value_counts().reset_index()\ntop_authors.head(5)","2a2c5e64":"(reddit.query('author != \"[deleted]\"').\n groupby('author')['score'].sum().\n reset_index().sort_values(by='score', ascending=False).head()\n)","a537c701":"%%time\nreddit[['title', 'score', 'author', 'year']].sort_values(by='score', ascending=False).head()","6331a9c7":"reddit[['title', 'num_comments', 'author', 'year']].sort_values(by='num_comments', ascending=False).head()","e1bfe775":"adult_content = len(reddit.query('over_18 == True')) \/ len(reddit.query('over_18 == False'))\nprint('Total amount of adult-only content = {:.1%}'.format(adult_content))","94f77b24":"fig, axes = plt.subplots(3,3, figsize=(15,12), sharey=True)\nfig.suptitle('Number of posts by months', fontsize=20, y=0.92)\n\ntemp = reddit.query('is_avalible == 1')\ny = 2012\n\nfor i in range(3):\n    for k in range(3):\n        fig = sns.countplot(data=temp[temp['year'] == y], x='month', ax=axes[i,k], color='royalblue')\n        axes[i,k].set(xlabel=y)\n        axes[i,k].set(ylabel='')\n        y += 1\n        \nplt.show()","2cd1342b":"# Create a list of most posted authors\ntemp = top_authors.head(10)\ntemp_1 = temp['index']\n\n# Create a table with the valid data\ntemp_2 = reddit.query('author in @temp_1')[['author', 'year', 'id']]\n\ntemp_pivot = (\n    temp_2.pivot_table(index=['year', 'author'], values='id', aggfunc='count')\n    .reset_index().sort_values(by='year', ascending=False)\n)\n\ntemp_pivot.rename(columns={\"id\": \"posts\"}, inplace=True)\n\n# Plot a figure with the posts distribution, grouped by years\nfig = go.Figure()\n\nfig = px.line(temp_pivot, x=\"year\", y=\"posts\", color=\"author\")\n    \nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.5, y=1.05,\n                              #xanchor='left', \n                              yanchor='bottom',\n                              text='Top 10 of most writing authors by years',\n                              font=dict(size=20,\n                                        color='black'),\n                              showarrow=False))\n# Set the fig' layout\nfig.update_layout(annotations=annotations, plot_bgcolor='white')\nfig.update_xaxes(gridwidth=0.9, gridcolor='silver', linecolor='black', zerolinewidth=1, zerolinecolor='dimgray')\nfig.update_yaxes(gridwidth=0.9, gridcolor='silver', linecolor='black', zerolinewidth=1, zerolinecolor='dimgray')\n\nfig.show()","741cebe7":"hour_distr = reddit.hour.value_counts().sort_values()\n\n#colors = px.colors.cyclical.Twilight\n\nfig = px.pie(values=hour_distr.values, names=hour_distr.index, color_discrete_sequence=px.colors.cyclical.Edge)\n             \nfig.update_traces(\n                  textposition=\"inside\", \n                  textinfo=\"value+percent+label\", insidetextorientation='radial', \n                  hole=.2, \n                 )\n\nfig.update_layout(title_text=\"Proportion of posts by hour\")\n\nfig.show()","31d0a84e":"x = np.array(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'])\ny = np.arange(0, 26)\n\n#colors = color_discrete_sequence=px.colors.cyclical.Edge\n\n#fig = go.Figure(data=[go.Pie(labels=x,\n                             #values=y,\n                             #template='plotly_dark'\n                           # )])\n\nfig = px.pie(values=y, names=x, \n             color_discrete_sequence=(px.colors.cyclical.Twilight), \n             #template='plotly_white'\n            )\n\nfig.update_traces(textposition=\"inside\", \n                  textinfo=\"value+label\", insidetextorientation='radial', \n                  hole=.2, \n                  marker=dict(\n                              #colors=colors, \n                              line=dict(color='dimgray', width=1))\n                )\n\nfig.show()","07761969":"daily_posts = reddit.groupby('day')['id'].count().reset_index()\n\nplt.figure(figsize=(10,6))\n\nsns.set(style='whitegrid')\nax = sns.barplot(data=daily_posts, x='day', y='id', color='royalblue')\nplt.title('Total number of daily posts', fontstyle='italic', size=15)\nax.set(xlabel='Day of month', ylabel='Posts')\nplt.show()","842246cc":"# Remove 2012-2014 and 2020 from our chart\nreddit_1 = reddit.query('2020 > year >= 2015')\ndaily_posts_1 = reddit_1.groupby(['month', 'day'])['id'].count().reset_index()\n\nplt.figure(figsize=(15,10))\nax = sns.boxplot(data=daily_posts_1, x='month', y='id', \n                 showfliers=False, color='royalblue', linewidth=2\n                )\n\nsns.despine(offset=10, trim=True)\nax.set(xlabel='Month', ylabel='Posts')\nplt.title('Distribution of monthly post from 2015 till 2019', size=15)\nplt.show()","bf675dbf":"from wordcloud import WordCloud, STOPWORDS","b4bc14ba":"words = reddit[\"title\"].values\nlen(words)","72dba7fb":"type(words[80324])","a1fc254e":"ls_1 = []\n\nfor i in words:\n    ls_1.append(str(i))","93aaa11d":"ls = []\n\nfor i in range(len(reddit)):\n    ls.append(reddit.author[i])","bf93450f":"plt.figure(figsize=(16,13))\nwc = WordCloud(background_color=\"white\", stopwords = STOPWORDS, max_words=1000, max_font_size= 200,  width=1600, height=800)\nwc.generate(\" \".join(ls))\nplt.title(\"Most discussed terms\", fontsize=20)\nplt.imshow(wc.recolor(colormap='viridis' , random_state=17), alpha=0.98, interpolation=\"bilinear\")\nplt.axis('off')","9b13cd47":"most_pop = reddit.sort_values('score', ascending =False)[['title', 'score']].head(12)\n\nmost_pop['score1'] = most_pop['score']\/1000","93c7e788":"most_pop","cfd28d38":"import matplotlib.style as style","217423ec":"style.available","46a3e046":"style.use('fivethirtyeight')","db3b9f6d":"plt.figure(figsize = (17,15))\n\nsns.barplot(data = most_pop, y = 'title', x = 'score1', color = 'c')\nplt.xticks(fontsize=20, rotation=0)\nplt.yticks(fontsize=21, rotation=0)\nplt.xlabel('Votes in Thousands', fontsize = 21)\nplt.ylabel('')\nplt.title('Most popular posts', fontsize = 30)","f1585e6c":"Dynamic of writing posts by most productive authors.","072fe731":"### 3. Ratings and correlations","dcc2c0cf":"Top-rated posts by all time.","9865615f":"Authors with the maximum number of posts.","792ea852":"Pick out year, month, day, weekday and hour from the creating date.","7a323fd2":"How many posts wrote the authors monthly after Reddit became popular.","275754c8":"#### Hi there! \nThis is one of my first shared notebook on kaggle.  \nI try to do my best!","46c04bcd":"Top-rated authors by all time.","15f9ef66":"### 4. Visualisation","4d422df5":"Percentage of 'adult-only' posts.","3c7e8988":"How many posts were published by each hour.","97efac31":"Is the post availible?","23aeff88":"### 1. Import libraries and data.","c52b03d2":"Refine the 'awarders' column","5c1a51b6":"Replace Nan-values","dbffcf80":"Posts with most numbers of comments.","c67ceb1f":"### 2. Preprocessing","37a06bd9":"Turn UTC to a local time","d8a63796":"Three most productive months are January, February and March (months with the highest median)","76965403":"Worldcloud","4755ac5e":"Total amount of post, sorted by years and months."}}