{"cell_type":{"1f163315":"code","22a00b71":"code","856e3a29":"code","95dcd24f":"code","3459f321":"code","7994cb9a":"code","5096d3ac":"code","45a2e521":"code","985c56d2":"code","4ce9313b":"code","5d4f143b":"code","d5889971":"code","6f117901":"code","a6e9a133":"code","fb5a2c6f":"code","054c3a9d":"code","b07fc1fd":"code","189b9707":"code","1664cb7f":"code","526bc0c6":"code","4c5cda86":"code","4d58189d":"code","ea027048":"code","fcb46b24":"code","3e3f17a0":"code","7efcb571":"code","6bbc551a":"code","2c8edcf8":"code","771ef914":"code","b5143f0c":"code","358ff4a2":"code","504711a2":"code","987cfcfa":"code","a83f2899":"code","a327ca20":"code","5ed419f7":"code","b33fe711":"code","f47ce369":"code","ecb4713c":"code","ecd6dcd5":"code","74ff2fe3":"code","ad8c740c":"code","f87df848":"code","c66c552e":"code","58908a73":"code","a71e5169":"code","e71d2936":"code","c9e13704":"code","76af0257":"code","210255d6":"code","199d60b0":"code","96e20635":"code","638fc04c":"code","637c8342":"code","40be568b":"code","d7bacc46":"code","95725664":"markdown","86e729c5":"markdown","2d13c764":"markdown","19ec88ca":"markdown","29ea23d5":"markdown","2bb0f313":"markdown","12338b7a":"markdown","1e3b1a93":"markdown","f2864106":"markdown","797a44b4":"markdown"},"source":{"1f163315":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22a00b71":"!pip install pandas_profiling","856e3a29":"from pandas_profiling import ProfileReport","95dcd24f":"items = pd.read_csv(os.path.join(dirname, 'items.csv'))\nshops = pd.read_csv(os.path.join(dirname, 'shops.csv'))\ncats = pd.read_csv(os.path.join(dirname, 'item_categories.csv'))\ntrain = pd.read_csv(os.path.join(dirname, 'sales_train.csv'))\n# set index to ID to avoid droping it later\ntest  = pd.read_csv(os.path.join(dirname, 'test.csv')).set_index('ID')\n","3459f321":"# \u30c7\u30fc\u30bf\u306e\u95b2\u89a7\ntrain.head()","7994cb9a":"train.tail()","5096d3ac":"# \u578b\u306e\u78ba\u8a8d\ntrain.info()","45a2e521":"# date: object\u578b->datetime\u578b\u306b\u5909\u63db\u3057\u3066\u51e6\u7406\n# object\u3060\u3068pandas-profiling\u306e\u51e6\u7406\u3082\u91cd\u3044\ntrain[\"date\"] = pd.to_datetime(train[\"date\"])","985c56d2":"# data\u91cf\u306e\u78ba\u8a8d\n# pandas profiling\u306f\u91cd\u3044\u306e\u3067\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308a\u305d\u3046\ntrain.shape","4ce9313b":"# NULL\u30c1\u30a7\u30c3\u30af\ntrain.isnull().sum()","5d4f143b":"# shop\u6570\nlen(train[\"shop_id\"].unique())","d5889971":"# shop\u6bce\u306e\u30ec\u30b3\u30fc\u30c9\u6570\ntrain.groupby(\"shop_id\").count().iloc[:,0].sort_values()","6f117901":"# item\u6570\nlen(train[\"item_id\"].unique())","a6e9a133":"# \u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ntrain.describe()","fb5a2c6f":"## item_price \u304c\u30de\u30a4\u30ca\u30b9\u306e\u30c7\u30fc\u30bf\u304c\u3042\u308b\ntrain[train[\"item_price\"] == -1]","054c3a9d":"# shop_id\u306e\u6bd4\u8f03\ntest_shops = test.shop_id.unique()\ntrain_shops = train.shop_id.unique()\nintersection = set(train_shops)&set(test_shops)\nprint(len(test_shops))\nprint(len(train_shops))\nprint(len(intersection))\nprint(intersection)\n","b07fc1fd":"train_items = train.item_id.unique()\ntest_items = test.item_id.unique()\nintersection = set(train_items)&set(test_items)\nprint(len(test_items))\nprint(len(train_items))\nprint(len(intersection))","189b9707":"# test\u30c7\u30fc\u30bf\u306b\u306a\u3044shop_id\u306e\u30c7\u30fc\u30bf\u306fdrop\u3059\u308b\ntrain = train[train.shop_id.isin(test_shops)]\n# test\u30c7\u30fc\u30bf\u306b\u306a\u3044item_id\u306e\u30c7\u30fc\u30bf\u306fdrop\u3059\u308b\ntrain = train[train.item_id.isin(test_items)]\n\n## \u305f\u3060\u3057\u3001\u30c7\u30fc\u30bf\u3092\u6b8b\u3057\u305f\u307b\u3046\u304c\u7cbe\u5ea6\u304c\u4e0a\u304c\u308b\u53ef\u80fd\u6027\u3082\u3042\u308b\u3057\u3001\u76ee\u7684\u306b\u3088\u3063\u3066\u306f\u6b8b\u3057\u305f\u307b\u3046\u304c\u3088\u3044\u53ef\u80fd\u6027\u3082\u3042\u308b\n## \u3053\u3053\u3067\u306f\u6271\u3044\u3084\u3059\u3055\u3092\u91cd\u8996\u3057\u3066\u30c7\u30fc\u30bf\u3092drop\u3059\u308b\u3002","1664cb7f":"# 2935849 -> 1224439 \u306a\u306e\u3067\u5927\u304d\u304f\u6e1b\u5c11\ntrain.shape","526bc0c6":"profile = ProfileReport(train.sample(frac=0.01), title=\"Pandas Profiling Report\")","4c5cda86":"profile","4d58189d":"items.head()","ea027048":"shops.head()","fcb46b24":"shops","3e3f17a0":"cats.head()","7efcb571":"pd.set_option('display.max_rows', 100)","6bbc551a":"cats","2c8edcf8":"def merge_data(train):\n    # merge all csv files\n    train = pd.merge(train,shops,how=\"left\",on=\"shop_id\")\n    train = pd.merge(train,items,how=\"left\",on=\"item_id\")\n    train = pd.merge(train,cats,how=\"left\",on=\"item_category_id\")\n    return train\n    ","771ef914":"train_merged = merge_data(train)\ntest_merged = merge_data(test)","b5143f0c":"train_merged.head()","358ff4a2":"def fix_duplicates(train):\n    # Several shops are duplicates of each other (according to its name).\n    # Fix train and test set.\n    # \u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56\n    train.loc[train.shop_id == 0, 'shop_id'] = 57\n    # \u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\"\n    train.loc[train.shop_id == 1, 'shop_id'] = 58\n    # \u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\u00b2\n    train.loc[train.shop_id == 10, 'shop_id'] = 11\n    return train\n","504711a2":"train_merged = fix_duplicates(train_merged)\ntest_merged = fix_duplicates(test_merged)","987cfcfa":"# \u30c7\u30fc\u30bf\u91cf\u304c\u591a\u3044\u306e\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\ntrain_merged_sample = train_merged.sample(frac=0.1)\ntrain_merged_sample.shape","a83f2899":"profile_merged = ProfileReport(train_merged_sample, title=\"Pandas Profiling Report\")","a327ca20":"profile_merged","5ed419f7":"# \u6642\u7cfb\u5217\u306e\u7279\u5fb4\u91cf\u4f5c\u6210\ndef make_date_features(train):\n    if train[\"date\"].dtype == \"object\":\n        train[\"date\"] = pd.to_datetime(train[\"date\"])\n        train[\"year\"] = train.date.dt.year\n        train[\"month\"] = train.date.dt.month\n        #train[\"day\"] = train.date.dt.day    \n        #train[\"dayofweek\"] = train.date.dt.dayofweek\n        return train\n    elif train[\"date\"].dtype == \"datetime\":\n        print(\"Skipped: date column is already datetime.\")\n        return train\n    else:\n        print(\"Please check dtype of date column: {0}\".format(train[\"date\"].dtype))\n   \n","b33fe711":"train_merged[\"sales_day\"] = train_merged[\"item_price\"] * train_merged[\"item_cnt_day\"]\ntrain_merged.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).sum()[\"sales_day\"].hist(bins=1000, log=True)","f47ce369":"train_merged.groupby(\"date_block_num\").sum()[\"sales_day\"]","ecb4713c":"train_merged.groupby(\"date_block_num\").sum()[\"sales_day\"].plot()","ecd6dcd5":"train_merged.groupby(\"date_block_num\").sum()[\"item_cnt_day\"]","74ff2fe3":"train_merged.groupby(\"date_block_num\").sum()[\"item_cnt_day\"].plot()","ad8c740c":"train_merged.groupby(\"date_block_num\").mean()[\"item_price\"].plot()","f87df848":"train_merged.head()","c66c552e":"def make_monthly_sales(sales):\n    return sales.groupby([\"date_block_num\", \"shop_id\", \"item_id\"])[\n        [\"date\", \"item_price\", \"item_cnt_day\"]\n    ].agg(\n        {\"date\": [\"min\", \"max\"], \"item_price\": \"mean\", \"item_cnt_day\": \"sum\"}\n    )","58908a73":"train.head()","a71e5169":"train_month = make_monthly_sales(train)","e71d2936":"train_month.head()","c9e13704":"def get_converted_multi_columns(df, *, to_snake_case=True):\n    if to_snake_case:\n        return [col[0] + \"_\" + col[1] for col in df.columns.values]\n    else:\n        return [col[0] + col[1].capitalize() for col in df.columns.values]\n","76af0257":"# \u96c6\u7d04\u306b\u3088\u3063\u3066\u884c\u30fb\u5217\u304c\u305d\u308c\u305e\u308c\u30cd\u30b9\u30c8\u3057\u305f\u306e\u3067\u3001\u30d5\u30e9\u30c3\u30c8\u306a\u884c\u5217\u306b\u623b\u3059\nflat_cols = get_converted_multi_columns(train_month)\ntrain_month.columns = flat_cols\ntrain_month = train_month.reset_index()\n","210255d6":"train_month.head()","199d60b0":"print(train.shape)\nprint(train_month.shape)","96e20635":"train_merged = merge_data(train)","638fc04c":"train_merged = fix_duplicates(train_merged)","637c8342":"train_merged","40be568b":"profile_month = ProfileReport(train_merged, title=\"Pandas Profiling Report\")","d7bacc46":"profile_month","95725664":"- \u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b: \u30a2\u30af\u30bb\u30b5\u30ea\u30fc\n- \u0418\u0433\u0440\u043e\u0432\u044b\u0435 \u043a\u043e\u043d\u0441\u043e\u043b\u0438: \u30b2\u30fc\u30e0\u6a5f\n- \u0418\u0433\u0440\u044b: \u30b2\u30fc\u30e0\n- \u041a\u0430\u0440\u0442\u044b \u043e\u043f\u043b\u0430\u0442\u044b: \u652f\u6255\u3044\u30ab\u30fc\u30c9\n- \u041a\u0438\u043d\u043e: \u6620\u753b\n- \u041a\u043d\u0438\u0433\u0438: \u66f8\u7c4d\n- \u041c\u0443\u0437\u044b\u043a\u0430: \u97f3\u697d\n- \u041f\u043e\u0434\u0430\u0440\u043a\u0438: \u30d7\u30ec\u30bc\u30f3\u30c8\n- \u041f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b: \u30d7\u30ed\u30b0\u30e9\u30e0\n- \u0421\u043b\u0443\u0436\u0435\u0431\u043d\u044b\u0435: \u30b5\u30fc\u30d3\u30b9\n- \u042d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u043f\u0438\u0442\u0430\u043d\u0438\u044f: \u30d0\u30c3\u30c6\u30ea\u30fc","86e729c5":"## Pandas Profiling for Merged Data","2d13c764":"## Pandas Profiling","19ec88ca":"## \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\uff08\u307e\u305a\u306f\u57fa\u672c\u3068\u306a\u308btrain.csv\u304b\u3089\uff09","29ea23d5":"## \u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0","2bb0f313":"## \u30c7\u30fc\u30bf\u78ba\u8a8d\uff08\u5168\u90e8\u30de\u30fc\u30b8\uff09","12338b7a":"## Train\/Test\u306e\u5dee\u3092\u307f\u308b","1e3b1a93":"## \u30e9\u30a4\u30d6\u30e9\u30ea\u3084\u30c7\u30fc\u30bf\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","f2864106":"## \u6708\u6bce,shop\u6bce,item\u6bce\u96c6\u8a08","797a44b4":"### File descriptions\n\n- sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n- sample_submission.csv - a sample submission file in the correct format.\n- items.csv - supplemental information about the items\/products.\n- item_categories.csv  - supplemental information about the items categories.\n- shops.csv- supplemental information about the shops.\n\n### Data fields\n\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd\/mm\/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category\n"}}