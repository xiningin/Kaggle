{"cell_type":{"0aedb115":"code","2d6e8c03":"code","0ee3a487":"code","472a51fc":"code","03ed092f":"code","8fb185ce":"code","b1fd2865":"code","7e4c72b3":"code","5006ed4e":"code","6ba171c6":"code","81984932":"code","869ac84c":"code","ed8f987a":"code","f813c782":"code","d0ac6211":"code","ae4a8788":"code","e40117c7":"code","c56d9b16":"code","79fbb9e7":"code","d212f290":"code","9b770257":"code","1e956f8d":"code","65ef7846":"code","150a7ac7":"code","089e1389":"code","fc41a1f0":"code","2819403d":"code","0e9e6d01":"code","01facc71":"code","c93eca86":"code","a0cf32b8":"code","819d53a2":"code","abdebfe8":"code","74fc94e5":"code","123c6917":"markdown","d1b6fa26":"markdown","f6757a55":"markdown","14505580":"markdown","7ad979b1":"markdown","06c55beb":"markdown","135072c2":"markdown"},"source":{"0aedb115":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\ngc.enable()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport cv2\nimport PIL\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport tensorflow as tf\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout, Activation, BatchNormalization, concatenate\nfrom tensorflow.keras.models import Model\n\nimgSize = 128\n\npath = '\/kaggle\/input\/petfinder-pawpularity-score\/'\nos.listdir(path)","2d6e8c03":"train_data = pd.read_csv(path+'train.csv')\nprint(train_data.shape)\ntrain_data.sample(1)","0ee3a487":"len(os.listdir(path+'train'))","472a51fc":"id_ = train_data.loc[1234, 'Id']\n# Create file\nfile = id_+'.jpg'\n# Is the file in folder?\nfile in os.listdir(path+'train')\n\nimg = cv2.imread(path+'train\/'+file)\nimg = cv2.resize(img, (imgSize,imgSize), interpolation = cv2.INTER_AREA)\nprint('Image shape:', img.shape)\n\nfig, axs = plt.subplots(1, 1, figsize=(7, 7))\naxs.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\naxs.set_xticklabels([])\naxs.set_yticklabels([])\nplt.show()","03ed092f":"X_num = train_data.drop(['Id','Pawpularity'], axis=1)\ny = train_data['Pawpularity']\nprint(X_num.shape)\ny.shape","8fb185ce":"X_num.iloc[1234]","b1fd2865":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","7e4c72b3":"# Model\n\ndef create_mlp(dim, regress=False):\n    model = keras.Sequential()\n    model.add(Dense(64, input_dim=dim, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation=\"linear\"))\n    return model\n\nmlp = create_mlp(X_train.shape[1], regress=False)\nmlp.compile('Adam', 'mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\nmlp.summary()","5006ed4e":"# Fit\n\nhistory = mlp.fit(X_train, y_train, \n                    validation_split = 0.2,\n                    batch_size = 4,\n                    epochs = 20)","6ba171c6":"# Learning curves\n\nacc = history.history['root_mean_squared_error']\nval_acc = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training rmse')\nplt.plot(epochs, val_acc, 'r', label='Validation rmse')\nplt.title('Training and validation root_mean_squared_error')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","81984932":"# Predict on test\n\ny_test = np.array(y_test)\n\nPreds = mlp.predict(X_test)\nPreds = Preds.flatten()\nprint(Preds.shape)\nprint(y_test.shape)\n\n\n# RMSE on test\nnp.sqrt(np.mean((Preds-y_test)**2))","869ac84c":"%%time\n\n# Resize & Normalize the images\n\nX_img = []\nfor i, row in train_data.iterrows():\n    rawImg = cv2.imread(path+'train\/'+row['Id']+'.jpg')\n    image = cv2.resize(rawImg, (imgSize,imgSize), interpolation = cv2.INTER_AREA)\n    normImg = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    X_img.append(normImg)\n    if i % 1000 ==0:\n        print(i)\n\nX_img = np.array(X_img)\nX_img.shape","ed8f987a":"# Image from normalized array\n\n#img = PIL.Image.fromarray(X_img[1234])\n\nimg = cv2.resize(X_img[1234], (imgSize,imgSize), interpolation = cv2.INTER_AREA)\nprint('Image shape:', img.shape)\n\nfig, axs = plt.subplots(1, 1, figsize=(7, 7))\naxs.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\naxs.set_xticklabels([])\naxs.set_yticklabels([])\nplt.show()","f813c782":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(X_img, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","d0ac6211":"def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n\t# initialize the input shape and channel dimension, assuming\n\t# TensorFlow\/channels-last ordering\n\tinputShape = (imgSize, imgSize, 3)\n\tchanDim = -1\n\t# define the model input\n\tinputs = Input(shape=inputShape)\n\t# loop over the number of filters\n\tfor (i, f) in enumerate(filters):\n\t\t# if this is the first CONV layer then set the input\n\t\t# appropriately\n\t\tif i == 0:\n\t\t\tx = inputs\n\t\t# CONV => RELU => BN => POOL\n\t\tx = Conv2D(f, (3, 3), padding=\"same\")(x)\n\t\tx = Activation(\"relu\")(x)\n\t\tx = BatchNormalization(axis=chanDim)(x)\n\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n\n\t# flatten the volume, then FC => RELU => BN => DROPOUT\n\tx = Flatten()(x)\n\tx = Dense(16)(x)\n\tx = Activation(\"relu\")(x)\n\tx = BatchNormalization(axis=chanDim)(x)\n\tx = Dropout(0.5)(x)\n\t# apply another FC layer, this one to match the number of nodes\n\t# coming out of the MLP\n\tx = Dense(4)(x)\n\tx = Activation(\"relu\")(x)\n\tx = Dense(1, activation=\"linear\")(x)\n    \n    # construct the CNN\n\tmodel = Model(inputs, x)\n\t# return the CNN\n\treturn model","ae4a8788":"cnn = create_cnn(imgSize, imgSize, 3, regress=False)\ncnn.compile('Adam', 'mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\nprint(cnn.summary())","e40117c7":"# Fit\n\nhistory = cnn.fit(X_train, y_train, \n                    validation_split = 0.2,\n                    batch_size = 4,\n                    epochs = 20)","c56d9b16":"# Learning curves\n\nacc = history.history['root_mean_squared_error']\nval_acc = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training rmse')\nplt.plot(epochs, val_acc, 'r', label='Validation rmse')\nplt.title('Training and validation root_mean_squared_error')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","79fbb9e7":"# Predict on test\n\ny_test = np.array(y_test)\n\nPreds = cnn.predict(X_test)\nPreds = Preds.flatten()\nprint(Preds.shape)\nprint(y_test.shape)\n\n# RMSE on test\nnp.sqrt(np.mean((Preds-y_test)**2))","d212f290":"del X_train\ndel X_test\ndel cnn\n\ngc.collect()","9b770257":"# Split into Train & Test\n\n# Tabular\nX_trainNum, X_testNum, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\nprint ('X_trainNum: ', X_trainNum.shape)\nprint ('X_testNum: ', X_testNum.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)\n\n# Images\nX_trainImg, X_testImg, y_NOTneeded, y_testNOTneeded = train_test_split(X_img, y, test_size=0.2, random_state=42)\nprint ('X_trainImg: ', X_trainImg.shape)\nprint ('X_testImg: ', X_testImg.shape)\n","1e956f8d":"def create_cnnPart(width, height, depth, filters=(16, 32, 64), regress=False):\n\t# initialize the input shape and channel dimension, assuming\n\t# TensorFlow\/channels-last ordering\n\tinputShape = (imgSize, imgSize, 3)\n\tchanDim = -1\n\t# define the model input\n\tinputs = Input(shape=inputShape)\n\t# loop over the number of filters\n\tfor (i, f) in enumerate(filters):\n\t\t# if this is the first CONV layer then set the input\n\t\t# appropriately\n\t\tif i == 0:\n\t\t\tx = inputs\n\t\t# CONV => RELU => BN => POOL\n\t\tx = Conv2D(f, (3, 3), padding=\"same\")(x)\n\t\tx = Activation(\"relu\")(x)\n\t\tx = BatchNormalization(axis=chanDim)(x)\n\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n\n\t# flatten the volume, then FC => RELU => BN => DROPOUT\n\tx = Flatten()(x)\n\tx = Dense(16)(x)\n\tx = Activation(\"relu\")(x)\n\tx = BatchNormalization(axis=chanDim)(x)\n\tx = Dropout(0.5)(x)\n\t# apply another FC layer, this one to match the number of nodes\n\t# coming out of the MLP\n\tx = Dense(64)(x)\n\tx = Activation(\"relu\")(x)\n\n    \n    # construct the CNN\n\tmodel = Model(inputs, x)\n\t# return the CNN\n\treturn model\n\ndef create_mlpPart(dim, regress=False):\n    model = keras.Sequential()\n    model.add(Dense(64, input_dim=dim, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    \n    return model","65ef7846":"# Model\n\ncnnBranch = create_cnnPart(imgSize, imgSize, 3, regress=False)\nmlpBranch = create_mlpPart(X_trainNum.shape[1], regress=False)\n\n# the MLP and CNN\ncombinedInput = concatenate([mlpBranch.output, cnnBranch.output])\n# our final FC layer head will have two dense layers, the final one\n# being our regression head\nx = Dense(10, activation=\"relu\")(combinedInput)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"linear\")(x)\n# our final model will accept categorical\/numerical data on the MLP\n\nmodel = Model(inputs=[mlpBranch.input, cnnBranch.input], outputs=x)\n\nmodel.compile('Adam', 'mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\nprint(model.summary())","150a7ac7":"# Fit\n\nhistory = model.fit([X_trainNum, X_trainImg], y_train, \n                    validation_split = 0.2,\n                    batch_size = 4,\n                    epochs = 20)","089e1389":"# Learning curves\n\nacc = history.history['root_mean_squared_error']\nval_acc = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training rmse')\nplt.plot(epochs, val_acc, 'r', label='Validation rmse')\nplt.title('Training and validation root_mean_squared_error')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","fc41a1f0":"# Predict on test\n\ny_test = np.array(y_test)\n\nPreds = model.predict([X_testNum, X_testImg])\nPreds = Preds.flatten()\nprint(Preds.shape)\nprint(y_test.shape)\n\n# RMSE on test\nnp.sqrt(np.mean((Preds-y_test)**2))","2819403d":"# Model\n\ncnnBranch = create_cnnPart(imgSize, imgSize, 3, regress=False)\nmlpBranch = create_mlpPart(X_trainNum.shape[1], regress=False)\n\n# the MLP and CNN\ncombinedInput = concatenate([mlpBranch.output, cnnBranch.output])\n# our final FC layer head will have two dense layers, the final one\n# being our regression head\nx = Dense(10, activation=\"relu\")(combinedInput)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"linear\")(x)\n# our final model will accept categorical\/numerical data on the MLP\n\nmodel = Model(inputs=[mlpBranch.input, cnnBranch.input], outputs=x)\n\nmodel.compile('Adam', 'mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\nhistory = model.fit([X_num, X_img], y, \n                    batch_size = 4,\n                    epochs = 20)\n\nprint('model fit')","0e9e6d01":"del X_num\ndel X_img\ndel X_trainNum\ndel X_trainImg\n\ngc.collect()","01facc71":"test_data = pd.read_csv(path+'test.csv')\nprint(test_data.shape)\ntest_data.sample(1)","c93eca86":"samp_subm = pd.read_csv(path+'sample_submission.csv')\nsamp_subm.sample(1)","a0cf32b8":"X_numKag = test_data.drop(['Id'], axis=1)\nprint(X_numKag.shape)","819d53a2":"# Resize & Normalize the images\n\nX_imgKag = []\nfor i, row in test_data.iterrows():\n    rawImg = cv2.imread(path+'test\/'+row['Id']+'.jpg')\n    image = cv2.resize(rawImg, (imgSize,imgSize), interpolation = cv2.INTER_AREA)\n    normImg = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    X_imgKag.append(normImg)\n\nX_imgKag = np.array(X_imgKag)\nX_imgKag.shape","abdebfe8":"# Predict on Kaggle test\n\nPreds = model.predict([X_numKag, X_imgKag])\nPreds = Preds.flatten()\n\nmySubmit = pd.DataFrame(test_data.Id)\nmySubmit['Pawpularity'] = Preds\nmySubmit.head()","74fc94e5":"mySubmit.to_csv('submission.csv', index=False)","123c6917":"# Only tabular metadata","d1b6fa26":"# Data","f6757a55":"# Images AND tabular metadata: two inputs into Keras","14505580":"# Goal: Predict Pawpularity based on BOTH image and tabular data\n\n### Results RSME on test 20%: \n* Only images  = 21.2 \n* Only tabular = 21.1 \n* Images & tabular = 21.05\n\n### Retrain on all data ... predict on Kaggle test ... submit\n\nMany thanks to:\n\n* https:\/\/www.kaggle.com\/drcapa\/petfinder-my-starter\n* https:\/\/www.pyimagesearch.com\/2019\/02\/04\/keras-multiple-inputs-and-mixed-data\/\n* https:\/\/stackoverflow.com\/questions\/55080465\/two-parallel-but-different-datasets-in-keras-as-multiple-inputs","7ad979b1":"# Prep the Kaggle test","06c55beb":"# Only images","135072c2":"# Retrain on ALL data, predict on Kaggle test and submit"}}