{"cell_type":{"571a6f20":"code","e683fdea":"code","01e9397c":"code","dbbc6ba0":"code","282839d2":"code","0a38459c":"code","66d0327d":"code","bbad57c6":"code","12e990ea":"code","b4047b1d":"code","522ff8fa":"code","76d696a5":"code","320cc0be":"code","d18775ef":"code","e1b8cf5e":"code","c4759738":"code","11aafdc6":"code","51151a85":"code","4f8c687e":"code","ca813906":"code","2797a973":"code","de1aca0b":"code","c3fc0661":"code","2ff26ae2":"code","27ccfbfc":"code","dacb50c5":"markdown"},"source":{"571a6f20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e683fdea":"# 1. Data Pre-processing\n\n!pip install mlxtend\n!pip install openpyxl\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\n\n# It ensures that the output is on one line.\npd.set_option('display.expand_frame_repr', False)\nfrom mlxtend.frequent_patterns import apriori, association_rules","01e9397c":"df_ = pd.read_excel(\"..\/input\/uci-online-retail-ii-data-set\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")\ndf = df_.copy()\n\ndf.info()","dbbc6ba0":"df.head()","282839d2":"# We use this function to determine the threshold values of the data.\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","0a38459c":"# This function also replaces the determined outlier threshold values with outliers.\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","66d0327d":"# In this function, we extract the values containing 'C' from the data. \"C\" means returned items.\n# To calculate Total Price, the variables Quantity and Price must be greater than zero.\n# We close the function by calling the Outlier and Threshold functions.\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe","bbad57c6":"df = retail_data_prep(df)","12e990ea":"# 2. Preparing the ARL Data Structure (Invoice-Product Matrix)\n\n# The view we want the data to come from.\n\n# Description   NINE DRAWER OFFICE TIDY   SET 2 TEA TOWELS I LOVE LONDON    SPACEBOY BABY GIFT SET\n# Invoice\n# 536370                              0                                 1                       0\n# 536852                              1                                 0                       1\n# 536974                              0                                 0                       0\n# 537065                              1                                 0                       0\n# 537463                              0                                 0                       1","b4047b1d":"# First we will try to put the invoices on the lines because they will be our basket.\ndf_gr = df[df['Country'] == 'Germany']\n\ndf_gr.head()","522ff8fa":"# According to Invoice and Description, we got groupby and counted Quantities.\n# We said how many of this product are on this invoice.\ndf_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).head(20)","76d696a5":"# We use unstack to avoid multiplexing and we use iloc to show the first 5 observations.\n# If a product is on an invoice, we did it this way to show how many information came from that product.\n# If a product is not in the cart(invoice), NA will come.\ndf_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().iloc[0:5, 0:5]","320cc0be":"# We need one hot encoded version. We want to write 0 where it says NA.\ndf_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).iloc[0:5, 0:5]","d18775ef":"# Now we're going to do something a little different than the last one we did.\n# Here, we will write 1 if the products in the invoices are greater than 0 in quantity.\n# We will write 0 if it is less than 0 or 0. We were operating on rows or columns with apply.\n# Here we will go through all the cells by applying the applymap and perform the operation.\ndf_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).applymap(lambda x: 1 if x > 0 else 0).iloc[0:5, 0:5]\n","e1b8cf5e":"# We create a function called create_invoice_product_df. If we want to search according\n# to the id variable and get results, it will do the same as above according to the stockcode.\n# If we entered the id as False, it will perform the above operation according to Desribtion.\ndef create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","c4759738":"gr_inv_pro_df = create_invoice_product_df(df_gr)\ngr_inv_pro_df.head(20)\n","11aafdc6":"gr_inv_pro_df = create_invoice_product_df(df_gr, id=True)\ngr_inv_pro_df.head()","51151a85":"def check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)","4f8c687e":"check_id(df_gr,21987)\ncheck_id(df_gr,23235)\ncheck_id(df_gr,22747)","ca813906":"# 3. Possibilities of All Possible Product Combinations\n\n# Support(X, Y) = Freq(X, Y) \/ N\n# There are 3 very simple formulas. The 1st is the Support value. It expresses the probability of\n# X and Y occurring together. It is the frequency of X and Y appearing together divided by N.\n\n# Confidence(X, Y) = Freq(X, Y) \/ Freq(X)\n# It expresses the probability of purchasing product Y when product X is purchased.\n# The frequency at which X and Y appear together divided by the frequency at which X appears.\n\n# Lift = Support(X, Y) \/ (Support(x) * Support (Y))\n# When X is purchased, the probability of buying Y increases by a multiple of lift.\n# The probability of X and Y appearing together is the product of the probabilities\n# of X and Y appearing separately.\n# It states an expression such as how many times the probability of buying another product\n# increases when we buy a product.","2797a973":"# If there is a possibility of appearing together in this function, whatever value we enter\n# in min_support will not take into account the values below those values.\nfrequent_itemsets = apriori(gr_inv_pro_df, min_support=0.01, use_colnames=True)\n\nfrequent_itemsets.sort_values(\"support\", ascending=False).head()","de1aca0b":"# By inserting the support values we found with Apriori into the association_rules function,\n# we find some other statistical data such as cofidance and lift.\nrules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n\nrules.sort_values(\"support\", ascending=False).head()","c3fc0661":"# According to this table, the probability of POST product and product numbered 22326\n# appearing together is 0.225383. The probability of being bought together is 0.275401.\n# The increase in the probability of buying these two products together is 1.123735.","2ff26ae2":"rules.sort_values(\"lift\", ascending=False).head(5)","27ccfbfc":"check_id(df_gr, 21989)\ncheck_id(df_gr, 21086)","dacb50c5":" ASSOCIATION RULE LEARNING \n\nThe association rules method is to present these correlations in the best way through\nrules, if there are significant correlations between the items that occur simultaneously\nand frequently, and if there are significant correlations. In other words, it is a\nrule-based machine learning technique used to find patterns in data.\n\nThere is a very big problem in social media channels, on the basis of e-commerce resources\non the internet. There are hundreds of thousands of content on such sites and they are\nstored in their databases. We cannot upload these hundreds of thousands of content to the user.\nWe should use content filtering methods. When we watch or like a video, we enter a certain flow.\nIt takes the best extract of that flow and personalizes us. Basically, our purpose in these systems\nis to filter the contents.\n    Source;\n       https:\/\/www.veribilimiokulu.com\/category\/makine-ogrenmesi\/\n       \n       - Apriori Algorithm -\n\nIt is a basket analysis method and is used to reveal product associations.\n\nSupport(X, Y) = Freq(X, Y) \/ N\n\nThere are 3 very simple formulas. The 1st is the Support value. It expresses the probability of\nX and Y occurring together. It is the frequency of X and Y appearing together divided by N.\n\nConfidence(X, Y) = Freq(X, Y) \/ Freq(X)\n\nIt expresses the probability of purchasing product Y when product X is purchased.\nThe frequency at which X and Y appear together divided by the frequency at which X appears.\n\nLift = Support(X, Y) \/ (Support(x) * Support (Y))\n\nWhen X is purchased, the probability of buying Y increases by a multiple of lift.\nThe probability of X and Y appearing together is the product of the probabilities\nof X and Y appearing separately.\nIt states an expression such as how many times the probability of buying another product\nincreases when we buy a product.\n\nOur aim is to suggest products to users in the product purchasing process by\napplying association analysis to the online retail II dataset."}}