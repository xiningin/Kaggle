{"cell_type":{"370f20b4":"code","f7a183fa":"code","c2f14ac3":"code","6f9c2e42":"code","d29de8f4":"code","6c06c52a":"code","ab7fe99b":"code","c3876054":"code","4518952f":"code","fdf3eccb":"code","106334cf":"code","cf5a61dd":"code","486cf0c9":"code","cccdd22d":"code","65aea319":"code","47d8e23c":"code","9a1a0337":"code","b2630ff9":"code","d0411f82":"code","63cebd42":"code","ac0369f7":"code","5b594249":"code","065645a3":"code","297e06c1":"code","2dc3a3aa":"code","8758c175":"code","1ac3defc":"code","cc24ff6e":"code","da6e2c8b":"code","9d498e0b":"code","1a0e30df":"code","31b9df56":"code","251c6307":"code","34a5abaf":"code","20211bcc":"code","6e77a10d":"code","90a5e641":"code","5f73e45a":"code","caa13d22":"code","4e8216a8":"code","75f2ddf5":"markdown","6f2cf1b0":"markdown","6640eb69":"markdown"},"source":{"370f20b4":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\nfrom keras import optimizers\nfrom keras.layers.normalization import BatchNormalization as BN\n\nfrom keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\nfrom keras.models import Model\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\nfrom keras.backend import tf as ktf\n\nfrom keras.regularizers import l2\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image, ImageDraw, ImageFilter\nprint(os.listdir(\"..\/input\"))","f7a183fa":"train = pd.read_csv('..\/input\/understanding_cloud_organization\/train.csv')","c2f14ac3":"train['ImageId'] = train['Image_Label'].str[:11]\ntrain['ClassId'] = train['Image_Label'].str[12:]\ntrain = train[['ImageId','ClassId','EncodedPixels']]\ntrain","6f9c2e42":"train = train.fillna(0)","d29de8f4":"train","6c06c52a":"mask_count_df = train[\"ImageId\"]\ntrain_img = mask_count_df.drop_duplicates().reset_index()\ntrain_img = train_img.drop(\"index\", axis=1)\ntrain_img","ab7fe99b":"img_name = train[\"ImageId\"][0]\nimg_name","c3876054":"abs_path = \"..\/input\/understanding_cloud_organization\/train_images\/\"","4518952f":"seed_image = cv2.imread(abs_path+img_name)\nseed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\nplt.figure(figsize=(15,15))\nplt.imshow(seed_image, \"gray\")","fdf3eccb":"seed_image.shape","106334cf":"df_exact = train[train[\"ImageId\"] == img_name]\ndf_exact","cf5a61dd":"filelist = os.listdir(\"..\/input\/understanding_cloud_organization\/train_images\/\")\n\nn0 = 0\nn1 = 0\nn2 = 0\nn3 = 0\nn4 = 0\n\nfor i in filelist:\n    x = train[train[\"ImageId\"] == i]\n    if len(x[x[\"EncodedPixels\"] == 0]) == 0:\n        n0 += 1\n        \n    elif len(x[x[\"EncodedPixels\"] == 0]) == 1:\n        n1 += 1\n        \n    elif len(x[x[\"EncodedPixels\"] == 0]) == 2:\n        n2 += 1\n        \n    elif len(x[x[\"EncodedPixels\"] == 0]) == 3:\n        n3 += 1\n        \n    elif len(x[x[\"EncodedPixels\"] == 0]) == 4:\n        n4 += 1\n        \nprint(n0,n1,n2,n3,n4)","486cf0c9":"class_id = [\"Fish\",\"Flower\",\"Gravel\",\"Sugar\"]\n\nclass_num = []\n\nfor i in range(4):\n\n    x = train[train[\"ClassId\"] == class_id[i]]\n    class_num.append(len(x[x[\"EncodedPixels\"] != 0]))\n    \nclass_num = np.array(class_num)\nprint(class_num)","cccdd22d":"plt.bar(class_id, class_num)","65aea319":"df_exact2 = df_exact[df_exact[\"ClassId\"] == \"Fish\"]\ndf_exact2","47d8e23c":"class_id = [\"Fish\",\"Flower\",\"Gravel\",\"Sugar\"]\n\nsegment_4 = []\nfor i in range(4):\n    x = train[train[\"ImageId\"] == img_name]\n    x2 = x[x[\"ClassId\"] == class_id[i]]\n    x3 = x2[\"EncodedPixels\"].values[0]\n    \n    if x3 ==0:\n        x4 = \"ok\"\n        \n    else:\n        x4 = x3.split()\n        \n    segment_4.append(x4)\n\nsegment_4 = np.array(segment_4)","9a1a0337":"#\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u751f\u6210\nseg_img = np.zeros([seed_image.shape[0], seed_image.shape[1],4], dtype=np.uint8)\n\nfor j in range(4):\n    \n    seg_np = np.zeros([seed_image.shape[0]*seed_image.shape[1]], dtype=np.uint8)\n    \n    if segment_4[j]==\"ok\":\n        pass\n    \n    else:\n        for i in range(len(segment_4[j])\/\/2):\n            start = int(segment_4[j][2*i])\n            length = int(segment_4[j][2*i+1])\n            seg_np[start:start+length]=1\n\n    seg_img[:,:,j] = seg_np.reshape([seed_image.shape[1],seed_image.shape[0]]).T\n    #seg_img[:,:,j] = seg_np.reshape([seed_image.shape[0],seed_image.shape[1]])","b2630ff9":"plt.figure(figsize=(15,15))\nplt.imshow(seed_image, \"gray\",vmin=0,vmax=255)","d0411f82":"plt.figure(figsize=(15,15))\nplt.imshow(seg_img[:,:,1],\"gray\",vmin=0,vmax=1)","63cebd42":"def vertical_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[::-1, :, :]\n        fmap = fmap[::-1, :, :]\n    return image, fmap\n\n\ndef horizontal_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[:, ::-1, :]\n        fmap = fmap[:, ::-1, :]\n    return image, fmap\n\ndef image_translation(img,fmap):\n    params = np.random.randint(-50, 51)\n    if not isinstance(params, list):\n        params = [params, params]\n    rows, cols, ch = img.shape\n\n    M = np.float32([[1, 0, params[0]], [0, 1, params[1]]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1), fmap\n\ndef image_shear(img,fmap):\n    params = np.random.randint(-20, 21)*0.01\n    rows, cols, ch = img.shape\n    factor = params*(-1.0)\n    M = np.float32([[1, factor, 0], [0, 1, 0]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1), fmap\n\ndef image_rotation(img,fmap):\n    params = np.random.randint(-5, 6)\n    rows, cols, ch = img.shape\n    M = cv2.getRotationMatrix2D((cols\/2, rows\/2), params, 1)\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1),fmap\n\ndef image_contrast(img,fmap):\n    params = np.random.randint(5, 15)*0.1\n    alpha = params\n    new_img = cv2.multiply(img, np.array([alpha]))                    # mul_img = img*alpha\n    #new_img = cv2.add(mul_img, beta)                                  # new_img = img*alpha + beta\n  \n    return np.expand_dims(new_img, axis=-1), fmap\n\ndef image_blur(img,fmap):\n    params = params = np.random.randint(1, 21)\n    blur = []\n    if params == 1:\n        blur = cv2.blur(img, (3, 3))\n    if params == 2:\n        blur = cv2.blur(img, (4, 4))\n    if params == 3:\n        blur = cv2.blur(img, (5, 5))\n    if params == 4:\n        blur = cv2.GaussianBlur(img, (3, 3), 0)\n    if params == 5:\n        blur = cv2.GaussianBlur(img, (5, 5), 0)\n    if params == 6:\n        blur = cv2.GaussianBlur(img, (7, 7), 0)\n    if params == 7:\n        blur = cv2.medianBlur(img, 3)\n    if params == 8:\n        blur = cv2.medianBlur(img, 5)\n    if params == 9:\n        blur = cv2.blur(img, (6, 6))\n    if params == 10:\n        blur = cv2.bilateralFilter(img, 9, 75, 75)\n    if params > 10:\n        blur = img\n        \n    return blur.reshape([blur.shape[0],blur.shape[1],1]), fmap\n","ac0369f7":"seed_image2 = np.expand_dims(seed_image, axis=-1)","5b594249":"dst, fmap = vertical_flip(seed_image2, seg_img)\n\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\",vmin=0,vmax=1)","065645a3":"dst, fmap = horizontal_flip(seed_image2, seg_img)\n\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","297e06c1":"dst, fmap = image_translation(seed_image2, seg_img)\n\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","2dc3a3aa":"dst, fmap = image_shear(seed_image2, seg_img)\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","8758c175":"dst, fmap = image_rotation(seed_image2, seg_img)\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","1ac3defc":"dst, fmap = image_contrast(seed_image2, seg_img)\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","cc24ff6e":"dst, fmap = image_blur(seed_image2, seg_img)\nplt.figure(figsize=(15,15))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","da6e2c8b":"train_idx, val_idx = train_test_split(\n    train_img.index, random_state=2019, test_size=0.15\n)","9d498e0b":"img_width, img_height = 525, 350 \nnum_train = len(train_idx)\nnum_val = len(val_idx)\nbatch_size = 4\nprint(num_train, num_val)\nabs_path = \"..\/input\/understanding_cloud_organization\/train_images\/\"","1a0e30df":"def get_segment_data(train, img_name, class_id = [\"Fish\",\"Flower\",\"Gravel\",\"Sugar\"]):\n    segment_4 = []\n    for i in range(4):\n        x = train[train[\"ImageId\"] == img_name]\n        x2 = x[x[\"ClassId\"] == class_id[i]]\n        x3 = x2[\"EncodedPixels\"].values[0]\n\n        if x3 ==0:\n            x4 = \"ok\"\n\n        else:\n            x4 = x3.split()\n\n        segment_4.append(x4)\n\n    segment_4 = np.array(segment_4)\n    \n    #\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u751f\u6210\n    seg_img = np.zeros([seed_image.shape[0], seed_image.shape[1],4], dtype=np.uint8)\n\n    for j in range(4):\n\n        seg_np = np.zeros([seed_image.shape[0]*seed_image.shape[1]], dtype=np.uint8)\n\n        if segment_4[j]==\"ok\":\n            pass\n\n        else:\n            for i in range(len(segment_4[j])\/\/2):\n                start = int(segment_4[j][2*i])\n                length = int(segment_4[j][2*i+1])\n                seg_np[start:start+length]=1\n\n        seg_img[:,:,j] = seg_np.reshape([seed_image.shape[1],seed_image.shape[0]]).T\n                \n    return seg_img","31b9df56":"def get_random_data(train_pd, img_index_1, abs_path, img_width, img_height, data_aug):\n    image_name = train_img[\"ImageId\"][img_index_1]\n    image_file = abs_path + image_name\n    fmap = get_segment_data(train_pd, image_name)\n    \n    seed_image = cv2.imread(image_file)\n    seed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\n    seed_image = cv2.resize(seed_image, dsize=(img_width, img_height))\n    seed_image = np.expand_dims(seed_image, axis=-1)\n    fmap = cv2.resize(fmap, dsize=(img_width, img_height))\n    \n    if data_aug:\n        \n        r = np.random.rand()\n        \n        if r >= 0.5:\n    \n            seed_image, fmap = vertical_flip(seed_image, fmap)\n            seed_image, fmap = horizontal_flip(seed_image, fmap)\n            seed_image, fmap = image_shear(seed_image, fmap)\n            seed_image, fmap = image_rotation(seed_image, fmap)\n            seed_image, fmap = image_contrast(seed_image, fmap)\n            seed_image, fmap = image_blur(seed_image, fmap)\n    \n    seed_image = seed_image \/ 255\n    \n    return seed_image, fmap","251c6307":"def data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    '''data generator for fit_generator'''\n    n = len(img_index)\n    i = 0\n    while True:\n        image_data = []\n        fmap_data = []\n        for b in range(batch_size):\n            if i==0:\n                img_index = img_index.take(np.random.permutation(len(img_index)))\n            image, fmap = get_random_data(train_pd, img_index[i], abs_path, img_width, img_height, data_aug)\n            image_data.append(image)\n            fmap_data.append(fmap)\n            i = (i+1) % n\n        image_data = np.array(image_data)\n        fmap_data = np.array(fmap_data)\n        yield image_data, fmap_data\n\ndef data_generator_wrapper(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    n = len(img_index)\n    if n==0 or batch_size<=0: return None\n    return data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug)","34a5abaf":"def resnet_en(data, filters, kernel_size, dilation_rate,option=False):\n    if option:\n        x=BN()(data)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=(1,1),strides=(2,2),padding=\"same\")(x)\n\n        x=BN()(x)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n        \n    else:\n        x=BN()(data)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n\n        x=BN()(x)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n\n    return x\n\ndef shortcut_en(x, residual):\n    '''shortcut connection \u3092\u4f5c\u6210\u3059\u308b\u3002\n    '''\n    x_shape = K.int_shape(x)\n    residual_shape = K.int_shape(residual)\n\n    if x_shape == residual_shape:\n        # x \u3068 residual \u306e\u5f62\u72b6\u304c\u540c\u3058\u5834\u5408\u3001\u306a\u306b\u3082\u3057\u306a\u3044\u3002\n        shortcut = x\n    else:\n        # x \u3068 residual \u306e\u5f62\u72b6\u304c\u7570\u306a\u308b\u5834\u5408\u3001\u7dda\u5f62\u5909\u63db\u3092\u884c\u3044\u3001\u5f62\u72b6\u3092\u4e00\u81f4\u3055\u305b\u308b\u3002\n        stride_w = int(round(x_shape[1] \/ residual_shape[1]))\n        stride_h = int(round(x_shape[2] \/ residual_shape[2]))\n\n        shortcut = Conv2D(filters=residual_shape[3],\n                          kernel_size=(1, 1),\n                          strides=(stride_w, stride_h),\n                          kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n    return Add()([shortcut, residual])","20211bcc":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","6e77a10d":"inputs = Input(shape=(img_height, img_width, 1))\n\nx = Conv2D(filters=16,kernel_size=(7,7), strides=1,padding='same')(inputs)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nfx = resnet_en(x, 16, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 16, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 32, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 32, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 64, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(inputs, fx)\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(2,2),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(2,2),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(1,1),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(1,1),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx1 = MaxPooling2D((1,1),padding=\"same\")(x)\nx1=Conv2DTranspose(filters=512\/\/4,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x1)\nx1 = BN()(x1)\nx1 = Activation(\"relu\")(x1)\n\nx2 = MaxPooling2D((2,2),padding=\"same\")(x)\nx2=Conv2DTranspose(filters=512\/\/4,kernel_size=(1,1),strides=(2,2),padding=\"same\")(x2)\nx2 = BN()(x2)\nx2 = Activation(\"relu\")(x2)\n\nx3 = MaxPooling2D((4,6),padding=\"same\")(x)\nx3=Conv2DTranspose(filters=512\/\/4,kernel_size=(1,1),strides=(4,6),padding=\"same\")(x3)\nx3 = BN()(x3)\nx3 = Activation(\"relu\")(x3)\n\nx4 = MaxPooling2D((11,11),padding=\"same\")(x)\nx4=Conv2DTranspose(filters=512\/\/4,kernel_size=(1,1),strides=(11,11),padding=\"same\")(x4)\nx4 = BN()(x4)\nx4 = Activation(\"relu\")(x4)\n\nx = Concatenate()([x,x1,x2,x3,x4])\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = Lambda(lambda x: ktf.image.resize_images(x, [img_height, img_width],\n                                          align_corners=True), output_shape=(350,525,128))(x)\n\nx=Conv2D(filters=4,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x)\noutputs = Activation('softmax')(x)\n\n# instantiate decoder model\nmodel = Model(inputs, outputs)\nmodel.summary()\n\nmodel.compile(optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n             loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","90a5e641":"model.fit_generator(data_generator_wrapper(train,train_idx, batch_size, abs_path, img_width, img_height, True),\n        steps_per_epoch=max(1, num_train\/\/batch_size),\n        validation_data=data_generator_wrapper(train,train_idx, batch_size, abs_path, img_width, img_height, False),\n        validation_steps=max(1, num_val\/\/batch_size),\n        epochs=5,\n        initial_epoch=0)","5f73e45a":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","caa13d22":"test_path = \"..\/input\/understanding_cloud_organization\/test_images\/\"\n\ntest_list = os.listdir(test_path)\n\nclass_id = [\"Fish\",\"Flower\",\"Gravel\",\"Sugar\"]\n\ndata = []\n\nfor fn in test_list:\n    abs_name = test_path + fn\n    seed_image = cv2.imread(abs_name)\n    seed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\n    seed_image = cv2.resize(seed_image, dsize=(img_width, img_height))\n    seed_image = np.expand_dims(seed_image, axis=-1)\n    seed_image = np.expand_dims(seed_image, axis=0)\n    seed_image = seed_image\/255\n    pred = model.predict(seed_image)\n    \n    for i in range(4):\n        \n        pred_fi = pred[0,:,:,i].T.flatten()\n        pred_fi = np.where(pred_fi > 0.1, 1, 0)\n        pred_fi_id = np.where(pred_fi == 1)\n        pred_fi_id = make_testdata(pred_fi_id[0])\n        x = np.array([fn + \"_\" + class_id[i],pred_fi_id])\n        data.append(x)\n    \ndata = np.array(data)","4e8216a8":"columns = ['Image_Label', 'EncodedPixels']\nd = pd.DataFrame(data=data, columns=columns, dtype='str')\nd.to_csv(\"submission.csv\",index=False)\ndf = pd.read_csv(\"submission.csv\")\nprint(df)","75f2ddf5":"# \u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u304c\u5b58\u5728\u3057\u306a\u3044\u753b\u50cf\u304c\u3042\u308b\u304b\u78ba\u8a8d","6f2cf1b0":"# \u30af\u30e9\u30b9\u3054\u3068\u306eN\u6570\u78ba\u8a8d","6640eb69":"# indicate image"}}