{"cell_type":{"e0468e4a":"code","202f7e7f":"code","afce25ec":"code","6c229ba1":"code","0d34c0cd":"code","294f3b99":"code","794b8254":"code","70e146c6":"code","5be0adcf":"code","ce8ecefd":"code","b6f15ca7":"code","77fefd30":"code","1656ac21":"code","9656e93e":"code","ab6d4bfe":"code","70b9728a":"code","fb3e9b4e":"code","1692d7b8":"code","62cb8dc8":"code","ba32b413":"code","25afc437":"code","0ef73227":"code","47fbb3cd":"code","50a11bf8":"code","c41cb262":"code","a6d96cea":"code","57ab5173":"code","1e0dda49":"code","3fa4a511":"code","ae5d8c8e":"code","45431014":"code","21da61b5":"code","1e1dbbda":"code","b08dffb5":"code","b3eff19d":"code","b006fcac":"code","ce06bafa":"code","82eb2fb6":"code","4946cd25":"code","1ab2aeda":"code","41b2a7ba":"code","7cbad3b8":"code","aaa871d3":"code","4b36624e":"code","f819bfad":"code","f8a5d2ce":"code","dbab8ec9":"code","7815a111":"code","89c4dd00":"code","75ab00fe":"code","9a8ef0f4":"code","4bd8dd60":"code","bc9790fd":"code","dc841bf4":"code","21932dbb":"code","320d6bde":"code","a27e6b62":"code","ef7c11d8":"code","3b376143":"code","ff139b80":"code","3d0112a1":"code","c0d4a6a4":"code","8f19b978":"code","9040c9f9":"code","e8df7253":"code","bf96d04e":"code","72f1aac5":"code","6f81fe37":"code","49e5858d":"markdown","5aa8c92d":"markdown","3e8740e9":"markdown","168ea0eb":"markdown","6212e130":"markdown","aa32632a":"markdown","87f4064d":"markdown","bae0f14e":"markdown","da85bb6d":"markdown","44909948":"markdown","b1655bbd":"markdown","1b19807a":"markdown","7a342615":"markdown","f0f78b09":"markdown","851d6bad":"markdown","c15adaa6":"markdown","f22469d0":"markdown","f6a4ceba":"markdown","fe5cc3fc":"markdown","6eee04f0":"markdown","84e92bd4":"markdown","df249ae6":"markdown","a2920024":"markdown","7ccb7191":"markdown","18b294d8":"markdown","9f3f5bd7":"markdown","2a40a21a":"markdown","c1eefb6e":"markdown","94bd03c3":"markdown","25c5f29f":"markdown","3a1ad042":"markdown","bd7e2cbd":"markdown","9f847a7a":"markdown","d70814fb":"markdown","d5ce86ca":"markdown"},"source":{"e0468e4a":"#'''Importing Data Manipulation Modules'''\nimport numpy as np                 # Linear Algebra\nimport pandas as pd                # Data Processing, CSV file I\/O (e.g. pd.read_csv)\n\n#'''Seaborn and Matplotlib Visualization'''\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\n#'''Plotly Visualizations'''\nimport plotly as plotly                # Interactive Graphing Library for Python\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.offline as py\ninit_notebook_mode(connected=True)\nimport os\n%pylab inline\nimport warnings\nwarnings.filterwarnings('ignore')","202f7e7f":"df = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ndf.head()","afce25ec":"df.shape","6c229ba1":"df.describe()","0d34c0cd":"df.drop('id', axis = 1, inplace = True)","294f3b99":"df.info()","794b8254":"df.isnull().sum()","70e146c6":"response_0 = df[df['Response'] == 0]","5be0adcf":"response_1 = df[df['Response'] == 1]","ce8ecefd":"labels = sorted(df.Response.unique())\nvalues = df.Response.value_counts().sort_index()\ncolors = ['DarkGrey', 'HotPink']\n\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values, pull=[0, 0.06])])\nfig.update_traces(hoverinfo='label+percent', textinfo='value',textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.update_layout(title_text=\"Distribution of Response\")\nfig.show()","b6f15ca7":"labels = sorted(df.Gender.unique())\nvalues = df.Gender.value_counts().sort_index()\ncolors = ['Aqua', 'Peru']\n\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values)])\nfig.update_traces(hoverinfo='label+percent', textinfo='value',textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.update_layout(title_text=\"Distribution of Gender\")\nfig.show()","77fefd30":"trace1 = go.Histogram(\n    x=response_0.Gender,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Gender,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Gender - Response',\n                   xaxis=dict(title='Gender'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","1656ac21":"print('Min age: ', df['Age'].max())\nprint('Max age: ', df['Age'].min())","9656e93e":"fig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nsns.countplot(x = 'Age', data = df)\nax.set_xlabel('Age', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Age Count Distribution', fontsize=15)\nsns.despine()","ab6d4bfe":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\nsns.boxplot(x = 'Age', data = df, orient = 'v', ax = ax1)\nax1.set_xlabel('People Age', fontsize=15)\nax1.set_ylabel('Age', fontsize=15)\nax1.set_title('Age Distribution', fontsize=15)\nax1.tick_params(labelsize=15)\n\nsns.distplot(df['Age'], ax = ax2)\nsns.despine(ax = ax2)\nax2.set_xlabel('Age', fontsize=15)\nax2.set_ylabel('Occurence', fontsize=15)\nax2.set_title('Age x Ocucurence', fontsize=15)\nax2.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","70b9728a":"print('1\u00ba Quartile: ', df['Age'].quantile(q = 0.25))\nprint('2\u00ba Quartile: ', df['Age'].quantile(q = 0.50))\nprint('3\u00ba Quartile: ', df['Age'].quantile(q = 0.75))\nprint('4\u00ba Quartile: ', df['Age'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Ages above: ', df['Age'].quantile(q = 0.75) + \n                      1.5*(df['Age'].quantile(q = 0.75) - df['Age'].quantile(q = 0.25)), 'are outliers')","fb3e9b4e":"print('Numerber of outliers: ', df[df['Age'] >= 85.0]['Age'].count())\nprint('Number of clients: ', len(df))\n#Outliers in %\nprint('Outliers are:', round(df[df['Age'] >= 85.0]['Age'].count()*100\/len(df),10), '%')","1692d7b8":"print('MEAN:', round(df['Age'].mean(), 1))\n\nprint('STD :', round(df['Age'].std(), 1))\n\n#coefficient variation: (STD\/MEAN)*100\n#    cv < 15%, low dispersion\n#    cv > 30%, high dispersion\n\nprint('CV  :',round(df['Age'].std()*100\/df['Age'].mean(), 1), ', High dispersion')\n\n#High dispersion means we have people with all ages and all of them are likely subscrib the service.","62cb8dc8":"trace1 = go.Histogram(\n    x=response_0.Age,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Age,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Age - Response',\n                   xaxis=dict(title='Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","ba32b413":"trace1 = go.Histogram(\n    x=response_0.Driving_License,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Driving_License,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Driving License - Response',\n                   xaxis=dict(title='Driving License'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","25afc437":"trace1 = go.Histogram(\n    x=response_0.Region_Code,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Region_Code,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Region - Response',\n                   xaxis=dict(title='Region Code'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","0ef73227":"trace1 = go.Histogram(\n    x=response_0.Previously_Insured,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Previously_Insured,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Previously Insured - Response',\n                   xaxis=dict(title='Previously Insured'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","47fbb3cd":"nodamage = df[df['Vehicle_Damage'] == 'No']","50a11bf8":"yesdamage = df[df['Vehicle_Damage'] == 'Yes']","c41cb262":"trace1 = go.Histogram(\n    x=response_0.Vehicle_Age,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Vehicle_Age,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Age - Response',\n                   xaxis=dict(title='Vehicle Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","a6d96cea":"trace1 = go.Histogram(\n    x=nodamage.Vehicle_Age,\n    opacity=0.85,\n    name = \"No Damage\",\n    marker=dict(color='LightCyan',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=yesdamage.Vehicle_Age,\n    opacity=0.85,\n    name = \"Damaged\",\n    marker=dict(color='OrangeRed',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Damage - Vehicle Age',\n                   xaxis=dict(title='Vehicle Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","57ab5173":"trace1 = go.Histogram(\n    x=nodamage.Gender,\n    opacity=0.85,\n    name = \"No Damage\",\n    marker=dict(color='LightCyan',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=yesdamage.Gender,\n    opacity=0.85,\n    name = \"Damaged\",\n    marker=dict(color='DeepPink',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Damage - Gender',\n                   xaxis=dict(title='Gender'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","1e0dda49":"sns.catplot(x = 'Vehicle_Age', y = 'Annual_Premium', hue = 'Vehicle_Damage',data = df)","3fa4a511":"#function to group gender into 0,1\ndef gender(dataframe):\n    dataframe.loc[dataframe['Gender'] == 'Male', 'Gender'] = 0\n    dataframe.loc[dataframe['Gender'] == 'Female', 'Gender'] = 1\n    \n    return dataframe\n\ngender(df);\n\ndf['Gender'].value_counts()","ae5d8c8e":"#function to devide Age into 4 groups.\ndef age(dataframe):\n    dataframe.loc[dataframe['Age'] <= 33, 'Age'] = 1\n    dataframe.loc[(dataframe['Age'] > 33) & (dataframe['Age'] <= 52), 'Age'] = 2\n    dataframe.loc[(dataframe['Age'] > 52) & (dataframe['Age'] <= 66), 'Age'] = 3\n    dataframe.loc[(dataframe['Age'] > 66) & (dataframe['Age'] <= 85), 'Age'] = 4\n           \n    return dataframe\n\nage(df)\n\ndf['Age'].value_counts()","45431014":"rcParams['figure.figsize'] = 11.7,8.27\nsns.distplot(df['Annual_Premium'])","21da61b5":"print('1\u00ba Quartile: ', df['Annual_Premium'].quantile(q = 0.25))\nprint('2\u00ba Quartile: ', df['Annual_Premium'].quantile(q = 0.50))\nprint('3\u00ba Quartile: ', df['Annual_Premium'].quantile(q = 0.75))\nprint('4\u00ba Quartile: ', df['Annual_Premium'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Annual Premium above: ', df['Annual_Premium'].quantile(q = 0.75) + \n                      1.5*(df['Annual_Premium'].quantile(q = 0.75) - df['Annual_Premium'].quantile(q = 0.25)), 'are outliers')","1e1dbbda":"print('Numerber of outliers: ', df[df['Annual_Premium'] >= 61892.5]['Annual_Premium'].count())\nprint('Number of clients: ', len(df))\n#Outliers in %\nprint('Outliers are:', round(df[df['Annual_Premium'] >= 61892.5]['Annual_Premium'].count()*100\/len(df),2), '%')","b08dffb5":"#function to devide Annual Premium into 4 groups.\ndef Premium(dataframe):\n    dataframe.loc[dataframe['Annual_Premium'] <= 24405.0, 'Annual_Premium'] = 1\n    dataframe.loc[(dataframe['Annual_Premium'] > 24405.0) & (dataframe['Annual_Premium'] <= 39400.0), 'Annual_Premium'] = 2\n    dataframe.loc[(dataframe['Annual_Premium'] > 39400.0) & (dataframe['Annual_Premium'] <= 55000), 'Annual_Premium'] = 3\n    dataframe.loc[(dataframe['Annual_Premium'] > 55000) & (dataframe['Annual_Premium'] <= 540165.0), 'Annual_Premium'] = 4\n           \n    return dataframe\n\nPremium(df)\n\ndf['Annual_Premium'].value_counts()","b3eff19d":"print('1\u00ba Quartile: ', df['Vintage'].quantile(q = 0.25))\nprint('2\u00ba Quartile: ', df['Vintage'].quantile(q = 0.50))\nprint('3\u00ba Quartile: ', df['Vintage'].quantile(q = 0.75))\nprint('4\u00ba Quartile: ', df['Vintage'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Vintage above: ', df['Vintage'].quantile(q = 0.75) + \n                      1.5*(df['Vintage'].quantile(q = 0.75) - df['Vintage'].quantile(q = 0.25)), 'are outliers')\n","b006fcac":"#function to devide Annual Premium into 4 groups.\ndef Vintage(dataframe):\n    dataframe.loc[dataframe['Vintage'] <= 82.0, 'Vintage'] = 1\n    dataframe.loc[(dataframe['Vintage'] > 82.0) & (dataframe['Vintage'] <= 154.0), 'Vintage'] = 2\n    dataframe.loc[(dataframe['Vintage'] > 154.0) & (dataframe['Vintage'] <= 227.0), 'Vintage'] = 3\n    dataframe.loc[(dataframe['Vintage'] > 227.0) & (dataframe['Vintage'] <= 450), 'Vintage'] = 4\n           \n    return dataframe\n\nVintage(df)\n\ndf['Vintage'].value_counts()","ce06bafa":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\n\ndf['Vehicle_Age']  = labelencoder_X.fit_transform(df['Vehicle_Age']) \ndf['Vehicle_Damage']  = labelencoder_X.fit_transform(df['Vehicle_Damage']) ","82eb2fb6":"df['Gender'] = pd.to_numeric(df['Gender'])","4946cd25":"df.dtypes","1ab2aeda":"df.head()","41b2a7ba":"len(df)","7cbad3b8":"df_no_response = df[df['Response'] == 0]","aaa871d3":"df_response = df[df['Response'] == 1]","4b36624e":"from sklearn.utils import resample\n\ndf_no_response_downsampled = resample(df_no_response,\n                                      replace = False,\n                                      n_samples=2500,\n                                      random_state = 42)\nlen(df_no_response_downsampled)","f819bfad":"df_response_downsampled = resample(df_response,\n                                   replace = False,\n                                   n_samples=2500,\n                                   random_state = 42)\nlen(df_response_downsampled)","f8a5d2ce":"df_downsample = pd.concat([df_no_response_downsampled,df_response_downsampled])","dbab8ec9":"len(df_downsample)","7815a111":"x = df_downsample.drop('Response', axis = 1)","89c4dd00":"y = df_downsample['Response']","75ab00fe":"f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, cmap='Purples')","9a8ef0f4":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\naccuracies = {}","4bd8dd60":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)","bc9790fd":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","dc841bf4":"from sklearn.feature_selection import RFECV\n\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nclf_rf_1 = RandomForestClassifier(random_state = 42) \nrfecv = RFECV(estimator=clf_rf_1, step=1, cv=k_fold,scoring='accuracy')   #10-fold cross-validation\nrfecv = rfecv.fit(x_train, y_train)\n\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', x.columns[rfecv.support_])","21932dbb":"x_1 = df_downsample[['Region_Code','Previously_Insured','Vehicle_Damage','Policy_Sales_Channel']]","320d6bde":"x_train, x_test, y_train, y_test = train_test_split(x_1,y, test_size=0.25, random_state=42)","a27e6b62":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","ef7c11d8":"clf_rf_2 = RandomForestClassifier(random_state=43)      \nclr_rf_2 = clf_rf_2.fit(x_train,y_train)","3b376143":"ac = accuracy_score(y_test,clf_rf_2.predict(x_test))\naccuracies['Random_Forest'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,clf_rf_2.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('RFC Reports\\n',classification_report(y_test, clf_rf_2.predict(x_test)))","ff139b80":"import matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","3d0112a1":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression() \nlogmodel.fit(x_train,y_train)\n\nac = accuracy_score(y_test,logmodel.predict(x_test))\naccuracies['Logistic regression'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,logmodel.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('Logistic regression Reports\\n',classification_report(y_test, logmodel.predict(x_test)))","c0d4a6a4":"from sklearn import model_selection\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Neighbors\nneighbors = np.arange(0,25)\n\n#Create empty list that will hold cv scores\ncv_scores = []\n\n#Perform 10-fold cross validation on training set for odd values of k:\nfor k in neighbors:\n    k_value = k+1\n    knn = KNeighborsClassifier(n_neighbors = k_value, weights='uniform', p=2, metric='euclidean')\n    kfold = model_selection.KFold(n_splits=10, random_state=123)\n    scores = model_selection.cross_val_score(knn, x_train, y_train, cv=k_fold, scoring='accuracy')\n    cv_scores.append(scores.mean()*100)\n    print(\"k=%d %0.2f (+\/- %0.2f)\" % (k_value, scores.mean()*100, scores.std()*100))\n\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint (\"The optimal number of neighbors is %d with %0.1f%%\" % (optimal_k, cv_scores[optimal_k]))\n\nplt.plot(neighbors, cv_scores)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Train Accuracy')\nplt.show()","8f19b978":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=24)\nknn.fit(x_train, y_train)\n\nac = accuracy_score(y_test,knn.predict(x_test))\naccuracies['KNN'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,knn.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('KNN Reports\\n',classification_report(y_test, knn.predict(x_test)))","9040c9f9":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(x_train, y_train)\n\nac = accuracy_score(y_test,dtree.predict(x_test))\naccuracies['decisiontree'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,dtree.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('DecisionTree Reports\\n',classification_report(y_test, dtree.predict(x_test)))","e8df7253":"from sklearn.svm import SVC\nsvc = SVC()\n\nsvc1= SVC(random_state = 42,kernel = 'rbf')\nsvc1.fit(x_train, y_train)\n\nac = accuracy_score(y_test,svc1.predict(x_test))\naccuracies['SVM'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,svc1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('SVM report\\n',classification_report(y_test, svc1.predict(x_test)))","bf96d04e":"from sklearn.naive_bayes import GaussianNB\ngaussiannb= GaussianNB()\ngaussiannb.fit(x_train, y_train)\n\nac = accuracy_score(y_test,gaussiannb.predict(x_test))\naccuracies['GaussianNB'] = ac\n\n\nprint('Accuracy is: ',ac,'\\n')\ncm = confusion_matrix(y_test,gaussiannb.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('GaussianNB report\\n',classification_report(y_test, gaussiannb.predict(x_test)))","72f1aac5":"colors = [\"purple\", \"green\", \"orange\", \"magenta\",\"#CFC60E\",\"#0FBBAE\"]\n\nplt.rcParams['figure.figsize'] = (18,8)\n\nx=list(accuracies.keys())\ny=list(accuracies.values())\n\nbars = plt.bar(x, height=y, width=.4, color = colors)\n\nxlocs, xlabs = plt.xticks()\n\nxlocs=[i for i in x]\nxlabs=[i for i in x]\n\nplt.xlabel('Algorithms', size = 20)\nplt.ylabel('Accuracy %', size = 20)\nplt.xticks(xlocs, xlabs, size = 15)\n\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + .1, yval + .005, yval, size = 15)\n\nplt.show()","6f81fe37":"fig, ax_arr = plt.subplots(nrows = 2, ncols = 3, figsize = (20,15))\nfrom sklearn import metrics\n\n#RandomForest\nprobs = clf_rf_2.predict_proba(x_test)\npreds = probs[:,1]\nfprrfc, tprrfc, thresholdrfc = metrics.roc_curve(y_test, preds)\nroc_aucrfc = metrics.auc(fprrfc, tprrfc)\n\nax_arr[0,0].plot(fprrfc, tprrfc, 'b', label = 'AUC = %0.2f' % roc_aucrfc)\nax_arr[0,0].plot([0, 1], [0, 1],'r--')\nax_arr[0,0].set_title('ROC Random Forest ',fontsize=20)\nax_arr[0,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,0].legend(loc = 'lower right', prop={'size': 16})\n\n#LOGMODEL\nprobs = logmodel.predict_proba(x_test)\npreds = probs[:,1]\nfprlog, tprlog, thresholdlog = metrics.roc_curve(y_test, preds)\nroc_auclog = metrics.auc(fprlog, tprlog)\n\nax_arr[0,1].plot(fprlog, tprlog, 'b', label = 'AUC = %0.2f' % roc_auclog)\nax_arr[0,1].plot([0, 1], [0, 1],'r--')\nax_arr[0,1].set_title('ROC Logistic ',fontsize=20)\nax_arr[0,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,1].legend(loc = 'lower right', prop={'size': 16})\n\n#KNN\nprobs = knn.predict_proba(x_test)\npreds = probs[:,1]\nfprknn, tprknn, thresholdknn = metrics.roc_curve(y_test, preds)\nroc_aucknn = metrics.auc(fprknn, tprknn)\n\nax_arr[0,2].plot(fprknn, tprknn, 'b', label = 'AUC = %0.2f' % roc_aucknn)\nax_arr[0,2].plot([0, 1], [0, 1],'r--')\nax_arr[0,2].set_title('ROC KNN ',fontsize=20)\nax_arr[0,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,2].legend(loc = 'lower right', prop={'size': 16})\n\n#DECISION TREE\nprobs = dtree.predict_proba(x_test)\npreds = probs[:,1]\nfprdtree, tprdtree, thresholddtree = metrics.roc_curve(y_test, preds)\nroc_aucdtree = metrics.auc(fprdtree, tprdtree)\n\nax_arr[1,0].plot(fprdtree, tprdtree, 'b', label = 'AUC = %0.2f' % roc_aucdtree)\nax_arr[1,0].plot([0, 1], [0, 1],'r--')\nax_arr[1,0].set_title('ROC Decision Tree ',fontsize=20)\nax_arr[1,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,0].legend(loc = 'lower right', prop={'size': 16})\n\n\n#Gaussiannb\n\nprobs = gaussiannb.predict_proba(x_test)\npreds = probs[:,1]\nfprgau, tprgau, thresholdgau = metrics.roc_curve(y_test, preds)\nroc_aucgau = metrics.auc(fprgau, tprgau)\n\nax_arr[1,1].plot(fprgau, tprgau, 'b', label = 'AUC = %0.2f' % roc_aucgau)\nax_arr[1,1].plot([0, 1], [0, 1],'r--')\nax_arr[1,1].set_title('ROC Gaussian ',fontsize=20)\nax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})\n\n#All plots\nax_arr[1,2].plot(fprrfc, tprrfc, 'b', label = 'rfc', color='black')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'Logistic', color='blue')\nax_arr[1,2].plot(fprknn, tprknn, 'b', label = 'Knn', color='brown')\nax_arr[1,2].plot(fprdtree, tprdtree, 'b', label = 'Decision Tree', color='green')\nax_arr[1,2].plot(fprgau, tprgau, 'b', label = 'Gaussiannb', color='grey')\nax_arr[1,2].set_title('Receiver Operating Comparison ',fontsize=20)\nax_arr[1,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,2].legend(loc = 'lower right', prop={'size': 16})","49e5858d":"## Gender Segmentation","5aa8c92d":"## Response Analysis","3e8740e9":"# GaussianNB","168ea0eb":"Vehicle Age between 1-2 are most likely to have car accidents, and accroding to the graph beyond, we can conclude that  they tend to be more willing to subscribe our services","6212e130":"> From the graph beyond, we could easily see the age between 35 and 55, they are more likely to response","aa32632a":"More positive response comming from the region 28 and region 8, the other regions are most likely ignore it","87f4064d":"## Shrink our dataset","bae0f14e":"## Region Code Analysis","da85bb6d":"# Group Segmentation & Categorical Treatment","44909948":"## Let's merge these 2 downsampled datasets into a single Dataframe","b1655bbd":"People who have not been insured yet are more likely the potentials clients","1b19807a":"## Age Analysis","7a342615":"# EDA","f0f78b09":"## Driving License Analysis","851d6bad":"## Label Encoder","c15adaa6":"# KNN","f22469d0":"## We are off to go, Features & Target Analysis","f6a4ceba":"## Random Forest","fe5cc3fc":"# LogisticRegression","6eee04f0":"## Vintage Analysis","84e92bd4":"Males are more likely to have car accidents than females.","df249ae6":"# Thanks for watching! please upvote Cheers!","a2920024":"# SVM","7ccb7191":"# Decision Tree","18b294d8":"# Modeling","9f3f5bd7":"## Gender Analysis ","2a40a21a":"> Males are more likely to response","c1eefb6e":"## Vehicle Age","94bd03c3":"## Age Segmentation","25c5f29f":"Vehicle Age between 0 - 2 has a higher and stable Annual Premium, people tend to be more taking care of their cars, wherears when Age > 2, customers are more focosed on lower price services where can enoughly cover the basic requirments.","3a1ad042":"## Previously Insured Analysis","bd7e2cbd":"## Premium Analysis","9f847a7a":"## To conclude: Males at the age between 35~55 who live in region 28 & 8, have not purchased inssurance for their 1-2 year(s) old car yet that had accidents before would be MORE interested in purchasing inssurance.","d70814fb":"People who have driving license are more likely to response","d5ce86ca":"# Our Final Model would be \u3010Random Forest\u3011 with Accuracy 79%, AUC: 0.83"}}