{"cell_type":{"ee6cf59d":"code","0c4deeb0":"code","5251712f":"code","373db56d":"code","cd0b2bef":"code","46900e79":"code","42580dc6":"code","c18e9994":"code","9844e3fa":"code","4cae5721":"code","af91a82f":"code","8edeed00":"code","2d5daf35":"markdown","ccceb0e1":"markdown","9a7ffb6c":"markdown","70e83da7":"markdown","936ac377":"markdown"},"source":{"ee6cf59d":"from scipy import ndimage\nimport operator\nimport cv2\nimport numpy as np \nimport os \nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt ","0c4deeb0":"image_paths=os.listdir('..\/input\/siim-isic-melanoma-classification\/jpeg\/train')\nimage_paths= [\"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/\" + str(x) for x in image_paths]","5251712f":"def cv2_clipped_zoom(img, zoom_factor):\n    \"\"\"\n    Center zoom in\/out of the given image and returning an enlarged\/shrinked view of \n    the image without changing dimensions\n    Args:\n        img : Image array\n        zoom_factor : amount of zoom as a ratio (0 to Inf)\n    \"\"\"\n    height, width = img.shape[:2] # It's also the final desired shape\n    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n\n    ### Crop only the part that will remain in the result (more efficient)\n    # Centered bbox of the final desired size in resized (larger\/smaller) image coordinates\n    y1, x1 = max(0, new_height - height) \/\/ 2, max(0, new_width - width) \/\/ 2\n    y2, x2 = y1 + height, x1 + width\n    bbox = np.array([y1,x1,y2,x2])\n    # Map back to original image coordinates\n    bbox = (bbox \/ zoom_factor).astype(np.int)\n    y1, x1, y2, x2 = bbox\n    cropped_img = img[y1:y2, x1:x2]\n\n    # Handle padding when downscaling\n    resize_height, resize_width = min(new_height, height), min(new_width, width)\n    pad_height1, pad_width1 = (height - resize_height) \/\/ 2, (width - resize_width) \/\/2\n    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n\n    result = cv2.resize(cropped_img, (resize_width, resize_height))\n    result = np.pad(result, pad_spec, mode='constant')\n    assert result.shape[0] == height and result.shape[1] == width\n    return result","373db56d":"def crop_and_zoom(img):\n    bounding=(1024,1024)\n    start = tuple(map(lambda a, da: a\/\/2-da\/\/2, img.shape, bounding))\n    end = tuple(map(operator.add, start, bounding))\n    slices = tuple(map(slice, start, end))\n    return cv2_clipped_zoom(img[slices],2)","cd0b2bef":"example_image='..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0368894.jpg'\nz=plt.imread(example_image)\nplt.imshow(z)","46900e79":"plt.imshow(crop_and_zoom(z))\nplt.imsave(\"example1.png\",z)","42580dc6":"example_2=\"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0094775.jpg\"\nz2=plt.imread(example_2)\nplt.imshow(z2)","c18e9994":"plt.imshow(crop_and_zoom(z2))\nplt.imsave(\"example2.png\",z2)","9844e3fa":"example_3=\"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0166988.jpg\"\nz3=plt.imread(example_3)\nplt.imshow(z3)","4cae5721":"plt.imshow(crop_and_zoom(z3))\nplt.imsave(\"example3.png\",z3)","af91a82f":"def generate_images(imagelist):\n    for x in imagelist:\n        img_name=x.split(sep='\/')[-1]\n        img= plt.imread(x)\n        img=crop_and_zoom(img)\n        plt.imsave(img_name,img)","8edeed00":"generate_images(image_paths[:10])","2d5daf35":"# Generate Images\n\nYou can run the follwing function if you want to generate new images with the given croping and zoom ","ccceb0e1":"Removing unnecessary skin and focus on the melanoma cells ","9a7ffb6c":"You can pass the and process images directly with  help of ImageDataGenerator of tensorflow utilizing Argument  preprocessing_function\n\n\ntf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=crop_and_zoom)","70e83da7":"# Visualization ","936ac377":"## Remove unnecessary parts from the images Focus on what we have to diagnose\n\n"}}