{"cell_type":{"55bf3869":"code","3a02d9ea":"code","537954d9":"code","5b4078f6":"code","a56548d5":"code","436626e6":"code","16de3790":"code","ebd6ba3b":"code","73c74e44":"code","3d7628fe":"code","26b52641":"code","0f42af55":"code","2686e707":"code","5aae3f20":"code","fa871803":"code","7fc68b15":"code","3d112cac":"code","aaf9899b":"code","2909fd2a":"code","e9d0e0ef":"code","5803a2ea":"code","efc25491":"code","ffe2de2f":"code","dd7fcee3":"code","219e827f":"code","164fd23c":"code","401bc48a":"code","05fbcc4e":"code","92693599":"code","80890107":"code","16789c34":"code","77302ec6":"code","f68e0216":"code","fe866521":"code","cded4f6b":"code","e2893197":"code","8bc98e8f":"code","5aaa57eb":"code","49f3147c":"code","2dd45df4":"code","873dba75":"code","25c91f00":"code","07a54207":"code","3cc08e0d":"code","449d69fb":"code","f67f9d6f":"code","0bb71bb4":"code","477ed015":"code","436f48cc":"markdown","fd5d3f4e":"markdown","ec13ac58":"markdown","87d955c8":"markdown","1c7b69e0":"markdown","93a5fcd7":"markdown","b65c9eb0":"markdown","83125aba":"markdown","32aeed81":"markdown","ef391147":"markdown","1c95cbd2":"markdown","36509a63":"markdown","6e8eac28":"markdown","c2efedef":"markdown","bcddd350":"markdown","624bffcf":"markdown","ab2000e0":"markdown","7324654f":"markdown","78ce42c2":"markdown","f665bc2d":"markdown","274d43dd":"markdown","9f68587a":"markdown","e2dd8501":"markdown","ca7bdf62":"markdown","6a22289f":"markdown","e1de6f0f":"markdown","a43244e3":"markdown","8ae4eebb":"markdown","51d88908":"markdown","86a81c85":"markdown","7840fad9":"markdown"},"source":{"55bf3869":"# Loading libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm as cm\nimport string\nimport seaborn as sns\nimport os","3a02d9ea":"# Reading train.csv and taking a look!\nprint(os.listdir(\"..\/input\"))\ntrain_ori = pd.read_csv(\"..\/input\/train.csv\")\ntrain_ori.head(5)","537954d9":"# Read test.csv\ntest_ori = pd.read_csv(\"..\/input\/test.csv\")\ntest_ori.head(5)","5b4078f6":"train_ori.info()","a56548d5":"#We will check NA values in training set\nprint(train_ori.isnull().sum())","436626e6":"test_ori.info()","16de3790":"#We will check NA values in test set\nprint(test_ori.isnull().sum())","ebd6ba3b":"train_ori.Survived.value_counts(normalize=True)","73c74e44":"#The number of passengers for each Pclass are:  \nsns.countplot(x=\"Pclass\", data=train_ori)","3d7628fe":"# The percentage of passengers survived for each Pclass:\nsns.catplot(y=\"Survived\", col=\"Pclass\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","26b52641":"train_ori[\"Title\"]=(train_ori[\"Name\"].str.split(', ').str[1]).str.split('. ').str[0]\ntrain_ori.head(5)","0f42af55":"# The initial different values for Title column are:\nprint(np.unique(np.array(train_ori[\"Title\"])))","2686e707":"# Factorize Title column as [\"Mr\",\"Mrs\",\"Miss\"]\n# We will factorize those values for getting only 3 values: Man, married Woman or unmarried Woman\ntrain_ori.loc[(train_ori[\"Title\"] == \"Capt\") | (train_ori[\"Title\"] == \"Col\") | (train_ori[\"Title\"] == \"Don\") | \n              (train_ori[\"Title\"] == \"Jonkheer\") \n    | (train_ori[\"Title\"] == \"Major\") | (train_ori[\"Title\"] == \"Master\") | (train_ori[\"Title\"] == \"Mr\") |\n              (train_ori[\"Title\"] == \"Rev\") | (train_ori[\"Title\"] == \"Sir\")\n    | (train_ori[\"Title\"] == \"th\"),\"Title\"]= \"Mr\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Lady\") | (train_ori[\"Title\"] == \"Mme\"),\"Title\"] = \"Mrs\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Mlle\") | (train_ori[\"Title\"] == \"Ms\") ,\"Title\"] = \"Miss\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Dr\") & (train_ori[\"Sex\"] == \"female\") ,\"Title\"] = \"Mrs\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Dr\") & (train_ori[\"Sex\"] == \"male\") ,\"Title\"] = \"Mr\"\n\nunique_elements, counts_elements = np.unique(np.array(train_ori[\"Title\"]), return_counts=True)\nprint(unique_elements, counts_elements)","5aae3f20":"#The number of passengers for each Title are:  \nsns.countplot(x=\"Title\", data=train_ori)","fa871803":"# The percentage of passengers survived for each Title:\nsns.catplot(y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","7fc68b15":"#The number of passengers for each Sex are:  \nsns.countplot(x=\"Sex\", data=train_ori)","3d112cac":"# The percentage of passengers survived for each Sex:\nsns.catplot(y=\"Survived\", col=\"Sex\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","aaf9899b":"# We calculate the median age per Title column and we will complete with these ages\nmrage=train_ori[train_ori[\"Title\"] == \"Mr\"][\"Age\"].mean()\nmrsage=train_ori[train_ori[\"Title\"] == \"Mrs\"][\"Age\"].mean()\nmissage=train_ori[train_ori[\"Title\"] == \"Miss\"][\"Age\"].mean()\nprint(\"mean age for Mr: \",mrage)\nprint(\"mean age for Mrs: \",mrsage)\nprint(\"mean age for Miss: \",missage)\n\ntrain_ori.loc[train_ori[\"Title\"] == \"Mr\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Mr\",\"Age\"].fillna(mrage)\ntrain_ori.loc[train_ori[\"Title\"] == \"Mrs\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Mrs\",\"Age\"].fillna(mrsage)\ntrain_ori.loc[train_ori[\"Title\"] == \"Miss\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Miss\",\"Age\"].fillna(missage)","2909fd2a":"train_ori.loc[(train_ori[\"Age\"] >= -0.001) & (train_ori[\"Age\"] < 15),\"Age\"] = 0\ntrain_ori.loc[(train_ori[\"Age\"] >= 15) & (train_ori[\"Age\"] < 18),\"Age\"] = 1\ntrain_ori.loc[(train_ori[\"Age\"] >= 18) ,\"Age\"] = 2","e9d0e0ef":"#The number of passengers for each Age are:  \nsns.countplot(x=\"Age\", data=train_ori)","5803a2ea":"# The percentage of passengers survived for each Age:\nsns.catplot(y=\"Survived\", col=\"Age\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","efc25491":"train_ori[\"FamilySize\"]= train_ori[\"SibSp\"] + train_ori[\"Parch\"] + 1","ffe2de2f":"#The number of passengers for each FamilySize are:  \nsns.countplot(x=\"FamilySize\", data=train_ori)","dd7fcee3":"# The percentage of passengers survived for each FamilySize:\nsns.catplot(y=\"Survived\", col=\"FamilySize\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","219e827f":"print(\"#of differents Fares:\",len(train_ori[\"Fare\"].unique()))\nprint(\"Max Fare:\",train_ori[\"Fare\"].max())\nprint(\"Min Fare:\",train_ori[\"Fare\"].min())\nprint(\"Mean Fare:\",train_ori[\"Fare\"].mean())\nsns.distplot(train_ori['Fare'],kde=False)","164fd23c":"plt.scatter(train_ori['Fare'], train_ori['FamilySize'],c=train_ori['Survived'])","401bc48a":"train_ori['CabinAssigned'] = np.where(train_ori.Cabin.isnull(), 0, 1)\ntrain_ori.head(2)","05fbcc4e":"sns.countplot(x=\"CabinAssigned\", data=train_ori)","92693599":"# The percentage of passengers survived for each CabinAssigned:\nsns.catplot(y=\"Survived\", col=\"CabinAssigned\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"CabinAssigned\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","80890107":"# For Embarked column NA we will apply logic for avoid the NA value.\ntrain_ori[train_ori[\"Embarked\"].isnull()]","16789c34":"train_ori.loc[(train_ori[\"Age\"] == 2.0) & (train_ori[\"Sex\"] == 'female') & (train_ori[\"FamilySize\"] == 1) & (train_ori[\"Pclass\"] == 1)& (train_ori[\"CabinAssigned\"] == 1) & (train_ori[\"Fare\"] >= 75) & (train_ori[\"Fare\"] <= 85)]","77302ec6":"train_ori = train_ori[pd.notnull(train_ori['Embarked'])]","f68e0216":"sns.countplot(x=\"Embarked\", data=train_ori)","fe866521":"# The percentage of passengers survived for each Embarked:\nsns.catplot(y=\"Survived\", col=\"Embarked\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Embarked\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","cded4f6b":"train = train_ori.drop(['Name','PassengerId','Ticket','SibSp','Cabin','Parch'],axis=1)\ntrain.head(10)","e2893197":"#\u00a0Factorize columns \nprint(train.head(10))\ntrain[\"Embarked\"], uniques = pd.factorize(train[\"Embarked\"])\ntrain[\"Sex\"], uniques = pd.factorize(train[\"Sex\"])\ntrain[\"Title\"], uniques = pd.factorize(train[\"Title\"])","8bc98e8f":"# Get intervals for factoring Fares column\npd.qcut(train[\"Fare\"], 4).value_counts().sort_index()","5aaa57eb":"train.loc[(train[\"Fare\"] >= -0.001) & (train[\"Fare\"] < 7.896),\"Fare\"] = 0\ntrain.loc[(train[\"Fare\"] >= 7.896) & (train[\"Fare\"] < 14.454),\"Fare\"] = 1\ntrain.loc[(train[\"Fare\"] >= 14.454) & (train[\"Fare\"] < 31.0),\"Fare\"] = 2\ntrain.loc[(train[\"Fare\"] >= 31.0) ,\"Fare\"] = 3\n\ntrain['Fare'] = train['Fare'].astype(int)","49f3147c":"train.head(10)","2dd45df4":"corr = train.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\n# cmap=cmap,\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","873dba75":"train.corr()[\"Survived\"]","25c91f00":"train.head(4)","07a54207":"# extract most important features and target for cross validation\nfeatures = train.drop(('Survived'), axis=1)\ntarget = train['Survived'].values","3cc08e0d":"from sklearn import model_selection, ensemble, svm\nimport xgboost as xgb\n\n# initialise classifiers\nrf_clf = ensemble.RandomForestClassifier(n_estimators=100, random_state=0)\net_clf = ensemble.ExtraTreesClassifier(n_estimators=100, random_state=0)\ngb_clf = ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0)\nada_clf = ensemble.AdaBoostClassifier(n_estimators=100, random_state=0)\nsvm_clf = svm.LinearSVC(C=0.1,random_state=0)\nxgb_clf = xgb.XGBClassifier(n_estimators=100)\n\ne_clf = ensemble.VotingClassifier(estimators=[('xgb', xgb_clf), ('rf',rf_clf),\n                                              ('et',et_clf), ('gbc',gb_clf), ('ada',ada_clf), ('svm',svm_clf)])\n\n# score using cross validation\nclf_list = [xgb_clf, rf_clf, et_clf, gb_clf, ada_clf, svm_clf, e_clf]\nname_list = ['XGBoost', 'Random Forest', 'Extra Trees', 'Gradient Boosted', 'AdaBoost', 'Support Vector Machine', 'Ensemble']\n\nfor clf, name in zip(clf_list,name_list) :\n    scores = model_selection.cross_val_score(clf, features, target, cv=10)\n    print(\"Accuracy: %0.2f +\/- %0.2f (%s 95%% CI)\" % (scores.mean(), scores.std()*2, name))","449d69fb":"# fit ensemble classifier\nsvm_clf = svm_clf.fit(features,target)","f67f9d6f":"# Process test dataset\n# Create Title column\ntest_ori.head(5)\ntest_ori[\"Title\"]=(test_ori[\"Name\"].str.split(', ').str[1]).str.split('. ').str[0]\n\ntest_ori.loc[(test_ori[\"Title\"] == \"Capt\") | (test_ori[\"Title\"] == \"Col\") | (test_ori[\"Title\"] == \"Don\") | \n              (test_ori[\"Title\"] == \"Jonkheer\") \n    | (test_ori[\"Title\"] == \"Major\") | (test_ori[\"Title\"] == \"Master\") | (test_ori[\"Title\"] == \"Mr\") |\n              (test_ori[\"Title\"] == \"Rev\") | (test_ori[\"Title\"] == \"Sir\")\n    | (test_ori[\"Title\"] == \"th\"),\"Title\"]= \"Mr\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Lady\") | (test_ori[\"Title\"] == \"Mme\"),\"Title\"] = \"Mrs\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Mlle\") | (test_ori[\"Title\"] == \"Ms\") ,\"Title\"] = \"Miss\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Dr\") & (test_ori[\"Sex\"] == \"female\") ,\"Title\"] = \"Mrs\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Dr\") & (test_ori[\"Sex\"] == \"male\") ,\"Title\"] = \"Mr\"\n\ntest_ori[\"FamilySize\"]= test_ori[\"SibSp\"] + test_ori[\"Parch\"]\ntest_ori['CabinAssigned'] = np.where(test_ori.Cabin.isnull(), 0, 1)\ntest_ori = test_ori[pd.notnull(test_ori['Embarked'])]\n\n\ntest = test_ori.drop(['Name','PassengerId','Ticket','Cabin','SibSp','Parch'],axis=1)\n\nprint(test.isnull().sum())\n\n# We calculate the mean age per Title column and we will complete with these ages\nmrage=test[test[\"Title\"] == \"Mr\"][\"Age\"].mean()\nmrsage=test[test[\"Title\"] == \"Mrs\"][\"Age\"].mean()\nmissage=test[test[\"Title\"] == \"Miss\"][\"Age\"].mean()\nprint(\"median age for Mr: \",mrage)\nprint(\"median age for Mrs: \",mrsage)\nprint(\"median age for Miss: \",missage)\n\ntest.loc[test[\"Title\"] == \"Mr\",\"Age\"] = test.loc[test[\"Title\"] == \"Mr\",\"Age\"].fillna(mrage)\ntest.loc[test[\"Title\"] == \"Mrs\",\"Age\"] = test.loc[test[\"Title\"] == \"Mrs\",\"Age\"].fillna(mrsage)\ntest.loc[test[\"Title\"] == \"Miss\",\"Age\"] = test.loc[test[\"Title\"] == \"Miss\",\"Age\"].fillna(missage)\n\ntest[\"Fare\"] = test[\"Fare\"].fillna(0)\n\nprint(test.isnull().sum())\n\ntest[\"Embarked\"], uniques = pd.factorize(test[\"Embarked\"])\ntest[\"Sex\"], uniques = pd.factorize(test[\"Sex\"])\ntest[\"Title\"], uniques = pd.factorize(test[\"Title\"])","0bb71bb4":"test.loc[(test[\"Fare\"] >= -0.001) & (test[\"Fare\"] < 7.896),\"Fare\"] = 0\ntest.loc[(test[\"Fare\"] >= 7.896) & (test[\"Fare\"] < 14.454),\"Fare\"] = 1\ntest.loc[(test[\"Fare\"] >= 14.454) & (test[\"Fare\"] < 31.0),\"Fare\"] = 2\ntest.loc[(test[\"Fare\"] >= 31.0) ,\"Fare\"] = 3\n\ntest['Fare'] = test['Fare'].astype(int)\n\ntest.loc[(test[\"Age\"] >= -0.001) & (test[\"Age\"] < 15),\"Age\"] = 0\ntest.loc[(test[\"Age\"] >= 15) & (test[\"Age\"] < 18),\"Age\"] = 1\ntest.loc[(test[\"Age\"] >= 18) ,\"Age\"] = 2\n\ntest['Age'] = test['Age'].astype(int)","477ed015":"# make prediction\nprediction = svm_clf.predict(test)\nprint(\"From the\",prediction.size, \"passengers, we have found\", prediction.sum(),\"survivals\")\npsgid = np.array(range(892,1310)).astype(int)\noutput = pd.DataFrame(prediction, index=psgid, columns = ['Survived'])\noutput.to_csv('submission.csv', index_label = 'PassengerId')","436f48cc":"The first observation about Fare is that  most of the values are less that 100. ","fd5d3f4e":"As we can see in the last output we conclude that we have found: 185 Miss, 578 Mr and 128 Mrs","ec13ac58":"We will filter the training dataset with the other values for those two observations.","87d955c8":"**0. Objective**  \nHello folks!! This is my first \"public\" kernel in kaggle. I am really happy to be part of this community and I hope that we all can learn new things and techniques \"doing and commenting\"\n","1c7b69e0":" Fisrtly, I am willing to check the percentage of  survival in the training dataset!!","93a5fcd7":"but we cannot find any interesting pattern. Then, we will elimininate these two observations.","b65c9eb0":"**3.2.2. Name**  \nFrom this column we are going to extract the Title (Engineering feature). The Name column will be dropped from the analysis but before that, we are going to extract the Title information from each passenger and we are going to create a new colum named \"Title\" with this information. The Title is the string between the \", \" and the \".\" characters in the column Name.","83125aba":"The idea is to factorize this column to have only 3 values: [\"Mr\",\"Mrs\",\"Miss\"]. For doing that we have applied the following code:","32aeed81":"**3.3. Clean columns**  \nThe next step is to remove some columns that we want to discard because they are not useful for the analysis: \"Name\", \"PasengerId\" ,\"Ticket\", \"Cabin\", \"SibSp\" and \"Parch\"","ef391147":"**3.1 Train and test data set info**  ","1c95cbd2":"**3.2.4. Age**  \nAge: We will factorize in child, teenagers or adults\nAs we know from 3.1 here we have 177 NaN values. We will use the mean of each Title value for adding this value in the missing observations.","36509a63":"**3.6. The final training dataset after cleaning data is shown below**","6e8eac28":"Besides that, FamilySize seems not depend on the Fare paid for that passenger, then price may be per person.","c2efedef":"**3.2.6. Fare**  \nwe will investigate if this colums impatcs on the Survived result. Firstable we will check their values for training passengers:","bcddd350":"**3. Exploratory Data Analysis and Data Cleaning**  ","624bffcf":"**3.2.7. Cabin**  \nIn this column we have many NaN values (687) in training set. We can asume that they are two categories, one with cabin assgined and other with cabin not assigned. With this information we have created a new column call \"CabinAssigned\"","ab2000e0":"**2. Reading Data**  \nFrom input folder we read training and test datasert","7324654f":"**3.2.3. Sex**  \nSex: male or female","78ce42c2":"For our analysis we are going to use the following variables\/columns from training dataset:  \nPclass,\tName, Sex, Age, SibSp, Parch, Fare, Cabin, Embarked","f665bc2d":"Only the 38% of passengers survived...","274d43dd":"**3.2.8. Embarked**  \nEmbarked: Indicating the port where that passenger embarked. In this column there are two NaN values in Training set. For Embarked NA values we will print both observations with NA vlaue in Embarked column, to identify the strategy to fill those values","9f68587a":"**3.5. For Fare and Ages columns we will get intervals before factoring**","e2dd8501":"**3.2. Variables**  \n**3.2.1. Pclass**   \nWe will check how Pclass is correlated with the Survived\n","ca7bdf62":"**1. Introduction**  \nIn this challenge, we will study the probabilities of survive or die for all Titanic passengers depending in different factors like: Name. Gender, Class, Rate,...\n2. Reading Data\n3. Exploratory Data Analysis and Data Cleaning (Engineernig features)  \n4. Create & Compare ML Models  \n","6a22289f":"**3.2.5. SibSp & Parch**  \nNow we are going to combine SibSp and Parch in only one colum: FamilySize = SibSp + Parch + 1 indicanding the family size of each passenger","e1de6f0f":"**3.4. Factorize columns Embarked, Sex and Title**  ","a43244e3":"**Seeing the matrix correlation we can see that Sex and Title has the biggest correlation with Survived variable**","8ae4eebb":"**4. Create & Compare ML Models**  \nNow we are going to create our models. For doing that we are going to create our subsets: Training and Validation dataset. ","51d88908":"**We choose SVM for as our predictor:**","86a81c85":"**5. Clean Test Set**","7840fad9":"Once we have created the Title column we can check what we have got in this new column:"}}