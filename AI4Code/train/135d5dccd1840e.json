{"cell_type":{"bbbeb046":"code","673279a7":"code","d83e63c6":"code","8b6a1ab5":"code","493ba6e4":"code","5cb3c3cb":"code","28cc45a4":"code","a32e98ca":"code","2f3c7d6f":"code","885cfa9d":"markdown","3a538138":"markdown","35285afb":"markdown","2dfec795":"markdown","f314121a":"markdown"},"source":{"bbbeb046":"import random\nrandom.seed(123)\n\n\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nimport sklearn.metrics as skm\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(10,8)})\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","673279a7":"# Loading the data\ndf = pd.read_csv('\/kaggle\/input\/programming-assignment-linear-regression\/ex1data2.csv')\ndf.head()","d83e63c6":"X = df.drop(['house_price'], axis=1).values\nY = df['house_price'].values\n        \nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(X[:, 0], X[:, 1], Y, color='#ef5423')\nplt.show()","8b6a1ab5":"sns.histplot(df['house_price'], bins=15, kde=True)\nplt.show()","493ba6e4":"# Masking to show only one side of the matrix\ncorr = np.corrcoef(df.corr())                        \nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\n# Axtual Correlation matrix as a heatmap\nsns.heatmap(df.corr(), annot=True, mask=mask)\nplt.show()","5cb3c3cb":"fig = plt.figure()\ngs = fig.add_gridspec(1, 2, hspace=0.2, wspace=0.4)\n(ax1, ax2) = gs.subplots(sharex='col', sharey='row')\nfig.suptitle('Scatterplots for House Prices')\nfig.subplots_adjust(top=0.85)\n\nax1.scatter(data=df, x='house_size', y='house_price')\nax2.scatter(data=df, x='number_of_bedrooms', y='house_price')\n\nplt.show()","28cc45a4":"from sklearn.preprocessing import PolynomialFeatures\nimport operator as op\n\nclass reg_models():\n    def __init__(self, df, target):\n        self.df = df\n        self.target = target\n        \n    def preprocessing(self):\n        self.X = self.df.drop([self.target], axis=1).values\n        self.Y = self.df[self.target].values\n        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.X, self.Y, \n                                           test_size = 0.25, random_state=72) \n        return self\n        \n    def fit_predict(self, model_type, deg=2):\n        # Multiple Linear Regression\n        if model_type == 'lin':\n            model = LinearRegression(normalize=True)\n            \n        if model_type == 'poly':\n            pol_feat = PolynomialFeatures(deg)\n            X_train_transf = pol_feat.fit_transform(self.X_train)\n            X_test_transf = pol_feat.fit_transform(self.X_test)\n            model = LinearRegression()\n            \n        if model_type == 'rdg':\n            model = Ridge(alpha=0.0001, normalize=True)\n        \n        if model_type == 'las':\n            model = Lasso(alpha=20, normalize=True)\n            \n        if model_type == 'eln':\n            model = ElasticNet(alpha=0.0001, normalize=True)\n\n        if model_type == 'svr-lin':\n            model = SVR(kernel='linear', C=100, gamma='auto')\n        \n        model.fit(self.X_train,self.Y_train)\n        self.Y_pred = model.predict(self.X_test)\n        return self\n    \n    def cross_validation(self,cv):\n        scoring = ['r2','explained_variance']\n        model = LinearRegression()\n        kf = KFold(n_splits=cv, random_state=None)\n        metrics = []\n        for i in scoring:\n            res = cross_val_score(model, self.X, self.Y, cv = kf, scoring=i)\n            metrics.append(res)\n        \n        scores = {}   \n        for m in range(0, len(scoring)):\n            scores[scoring[m]] = round(metrics[m].mean(), 2)\n            \n        return scores\n    \n    def performance(self):\n        rmse = round(skm.mean_squared_error(self.Y_test, self.Y_pred, squared=False), 2)\n        r2_score = round(skm.r2_score(self.Y_test, self.Y_pred), 4)\n        ev = round(skm.explained_variance_score(self.Y_test, self.Y_pred), 4)\n        mae = round(skm.mean_absolute_error(self.Y_test, self.Y_pred), 2)\n    \n        return [mae, rmse, r2_score, ev]","a32e98ca":"models = {}\nreg = reg_models(df, 'house_price').preprocessing()\nmodels[\"Mult. Reg\"] = reg.fit_predict('lin').performance()\nmodels[\"Poly Reg\"] = reg.fit_predict('poly', 2).performance()\nmodels[\"Ridge Reg\"] = reg.fit_predict('rdg').performance()\nmodels[\"Lasso Reg\"] = reg.fit_predict('las').performance()\nmodels[\"ElaNet Reg\"] = reg.fit_predict('eln').performance()\nmodels[\"SVR Lin\"] = reg.fit_predict('svr-lin').performance()\n\n#table with the model_performances\nmodels_df = pd.DataFrame.from_dict(models, orient='index',\n                  columns=['MAE', 'RSME', 'R_sq', 'Expl. Var.'])\nmodels_df","2f3c7d6f":"reg.cross_validation(cv=4)","885cfa9d":"## 3. Correlation within the data","3a538138":"# Exploratory Data Analysis","35285afb":"## 2. Distribution of the target variable","2dfec795":"## 1. 3D Visualization","f314121a":"# Model Building & Evaluation"}}