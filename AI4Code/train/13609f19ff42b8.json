{"cell_type":{"af8f184e":"code","f7c3e313":"code","733bd106":"code","404920b7":"code","6da140f1":"code","c75e6093":"code","1c2ee264":"code","39a6e64e":"code","d5e2b2c0":"code","8600f71a":"code","99ba0666":"code","6c034ac7":"code","26ceada7":"code","0e402ea9":"code","947e4abd":"code","3943ecb9":"code","d547b4f9":"code","13ea4654":"code","3da3c49b":"code","c172ba90":"code","d81510e6":"code","f8caf2fd":"code","6fe57fc0":"code","14b39387":"code","dd0dd247":"code","5c6d89d6":"code","425ab2c1":"code","424afe55":"code","b9b74c03":"code","f70793b5":"code","3d9d7b9a":"code","bbbe8f6e":"code","217a5c24":"code","ce67061f":"code","fcf3fbf3":"code","264b5734":"code","3a8ecd6f":"code","540ff260":"code","45348dc4":"code","411bff50":"code","35fed3df":"markdown","7455b799":"markdown","f7a22ca8":"markdown","8c88d584":"markdown","76410020":"markdown","5da9dd12":"markdown","145004b9":"markdown","a825c15d":"markdown","37e770b7":"markdown","9d51f5a6":"markdown","ccbb052f":"markdown","e420af0a":"markdown","627bfc68":"markdown","e6487bfd":"markdown","22938088":"markdown","eaca65dd":"markdown"},"source":{"af8f184e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7c3e313":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","733bd106":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","404920b7":"train.head()","6da140f1":"test.head()","c75e6093":"train.describe()","1c2ee264":"test.describe()","39a6e64e":"train.Age = train.Age.fillna(train.Age.mean())\ntrain.info()","d5e2b2c0":"del train[\"Name\"]\ndel train[\"Ticket\"]\ndel train[\"Cabin\"]","8600f71a":"train.head()","99ba0666":"train_dummy = pd.get_dummies(train,columns=[\"Sex\"])","6c034ac7":"train_dummy.head()","26ceada7":"del train_dummy[\"Sex_male\"]","0e402ea9":"sns.heatmap(train_dummy.corr())","947e4abd":"sex_graph = sns.barplot(x = \"Sex_female\", y = \"Survived\", data = train_dummy)\nsex_graph.set(xticklabels=[\"Male\", \"Female\"])\nplt.xlabel(\"Sex\")","3943ecb9":"sex_graph = sns.barplot(x = \"Pclass\", y = \"Survived\", data = train_dummy)","d547b4f9":"sns.barplot(x = \"Embarked\", y = \"Survived\", data = train_dummy)","13ea4654":"df = train_dummy[[\"Age\",\"Survived\"]]\ndf[\"Age_group\"] = 0\ndf = df.dropna()\ndf.describe()","3da3c49b":"df.loc[df[\"Age\"] <= 10 , \"Age_group\"] = 10\ndf.loc[(df[\"Age\"] > 10) & (df[\"Age\"] <= 20), \"Age_group\"] = 20\ndf.loc[(df[\"Age\"] > 20) & (df[\"Age\"] <= 30), \"Age_group\"] = 30\ndf.loc[(df[\"Age\"] > 30) & (df[\"Age\"] <= 40), \"Age_group\"] = 40\ndf.loc[(df[\"Age\"] > 40) & (df[\"Age\"] <= 50), \"Age_group\"] = 50\ndf.loc[(df[\"Age\"] > 50) & (df[\"Age\"] <= 60), \"Age_group\"] = 60\ndf.loc[(df[\"Age\"] > 60) & (df[\"Age\"] <= 70), \"Age_group\"] = 70\ndf.loc[(df[\"Age\"] > 70), \"Age_group\"] = 80\n","c172ba90":"sns.barplot(x = \"Age_group\", y = \"Survived\", data = df)","d81510e6":"train_dummy = pd.get_dummies(train,columns=[\"Embarked\",\"Sex\"])\ndel train_dummy[\"Sex_male\"]\ndel train_dummy[\"Embarked_S\"]","f8caf2fd":"y_train = train_dummy[\"Survived\"]","6fe57fc0":"del train_dummy[\"Survived\"]\nX_train = train_dummy","14b39387":"X_test = test","dd0dd247":"from sklearn.linear_model import LogisticRegression","5c6d89d6":"clf = LogisticRegression(max_iter=1000)","425ab2c1":"clf.fit( X_train, y_train)","424afe55":"X_test = pd.get_dummies(X_test,columns=[\"Embarked\",\"Sex\"])\ndel X_test[\"Sex_male\"]\ndel X_test[\"Embarked_S\"]","b9b74c03":"X_test.Age = X_test.Age.fillna(X_test.Age.mean())\nX_test.Fare = X_test.Fare.fillna(X_test.Fare.mean())","f70793b5":"del X_test[\"Name\"]\ndel X_test[\"Ticket\"]\ndel X_test[\"Cabin\"]","3d9d7b9a":"Y_pred_test = clf.predict(X_test)","bbbe8f6e":"Y_pred_test.shape","217a5c24":"submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","ce67061f":"X_test.shape","fcf3fbf3":"Accuracy = np.mean(submission[\"Survived\"] == Y_pred_test)\nprint(Accuracy)","264b5734":"print(f'With this model we can predict with the {round(Accuracy*100,2)}% who survived in the titanic')","3a8ecd6f":"survived = pd.DataFrame(data = X_test[\"PassengerId\"]).rename(columns={0:'PassengerId'})","540ff260":"survived[\"Survived\"] = Y_pred_test","45348dc4":"survived.head()","411bff50":"survived.to_csv('\/kaggle\/working\/Titanic.csv',index=False)","35fed3df":"We are going to delete one colum of each dummy variables because are not useful","7455b799":"We saw that the female are the group with the highest chance of surviving","f7a22ca8":"# Create the dummys variables","8c88d584":"# Delete columns that are useless ","76410020":"# Divide the labels and the columns","5da9dd12":"# Calculate the Accuracy of the model","145004b9":"# Preprocesing test data\n* Dummy\n* Nulls\n* Del columns","a825c15d":"# Look for the correlation between the columns and the price","37e770b7":"# For the variables that have numerical x label we are going to group\n* Age\n* Fare","9d51f5a6":"# Remove Nulls values\n* Age ()","ccbb052f":"In this graph we saw that the people that were in first class had most posibility of surviving","e420af0a":"# Plotting relationship in survived and columns","627bfc68":"Columns that are not useful in the analisis\n* Name\n* Ticket\n* Cabin\n##### \"This 3 columns we are not going to use because there are unique for each row\"","e6487bfd":"# Look the data","22938088":"The group that has more posibility to survived are the childs ","eaca65dd":"# Create the predicted model"}}