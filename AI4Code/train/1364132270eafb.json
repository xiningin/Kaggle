{"cell_type":{"0a229944":"code","23edce25":"code","f75ecd1a":"code","9d9e4b64":"code","ac84d71c":"code","7ed55ac3":"code","b12abf53":"markdown","49be3378":"markdown","ffc3b4ca":"markdown","26ec7711":"markdown","2c1767bb":"markdown"},"source":{"0a229944":"import pymc3 as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\n#define  basis functions\ndef make_basis(x):\n    # the components are 1,x, cos(2 \\pi x), sin(2 \\pi x)...\n    periodic = np.hstack([np.cos(2*np.pi*x),np.sin(2*np.pi*x),np.cos(4*np.pi*x),np.sin(4*np.pi*x),np.cos(6*np.pi*x),np.sin(6*np.pi*x),np.cos(8*np.pi*x),np.sin(8*np.pi*x),np.cos(10*np.pi*x),np.sin(10*np.pi*x),np.cos(12*np.pi*x),np.sin(12*np.pi*x)])\n    return np.hstack([np.ones((x.shape[0],1)),x, periodic ]) \n\n#  periodic basis starts at column:\ncol_per = 2\n\n#baseline model\ndef run_model(x,y,plot=False):    \n    H = make_basis(x.reshape(-1,1))\n    #normalize the data\n    yn = (y-np.mean(y))\/np.std(y)\n    \n    #select non periodic components of the basis\n    H_np = H[:,0:col_per]\n\n    with pm.Model() as model:\n        #prior\n        w = pm.Normal('weights', mu=0, sd=50, shape=(H.shape[1],))\n        sigma = pm.HalfCauchy('sigma', 5)\n\n        #linear model\n        mu = pm.Deterministic('mu', pm.math.matrix_dot(H,w).T)\n\n        #likelihood\n        y_obs = pm.Normal('y', mu=mu, sd=sigma, observed=yn)\n\n        #we can do  an approximated inference\n    with model:\n        inference = pm.ADVI()\n        approx = pm.fit(60000, method=inference)\n        \n    posterior = approx.sample(draws=500)\n    \n    all_prediction = np.dot(H,posterior['weights'].T).T\n    non_periodic_prediction = np.dot(H_np,posterior['weights'][:,0:col_per].T).T\n    if plot==True:\n        plt.figure()\n        plt.plot(x,np.mean(all_prediction,axis=0),'r', label='Overall Mean')\n        plt.plot(x,np.mean(non_periodic_prediction,axis=0),'b', label='Mean of the non-periodic comp.')\n        plt.legend()\n        plt.scatter(x,yn)\n    Gradients = []\n    for i in range(non_periodic_prediction.shape[0]):\n        Gradients.append(np.min(np.gradient(non_periodic_prediction[i,:], x)))\n        \n    posterior_probability_deriviative_is_positive = len(np.where(np.array(Gradients)>0)[0])\/len(Gradients)\n    print(\"probability that the function is increasing=\", posterior_probability_deriviative_is_positive)\n    if posterior_probability_deriviative_is_positive>0.95:\n        return 1\n    else:\n        return 0\n\n    \n#this is the inpu\nx = np.linspace(0,1,100)    ","23edce25":"\ny =  x + np.cos(4*np.pi*x) + np.random.randn(len(x))*0.2\nplt.plot(x,y)","f75ecd1a":"run_model(x,y,plot=True)","9d9e4b64":"#toy example\ny =  x\/2-2*np.exp(-(x-0.5)**2) + 2 + np.random.randn(len(x))*0.05\nplt.plot(x,y)","ac84d71c":"run_model(x,y, plot=True)","7ed55ac3":"x = np.linspace(0,1,100)\ntest_df = pd.read_csv(\"Dataset\/test.csv\")\n\n\nDecision = pd.DataFrame(columns=['Id','Category'])\nfor r in range(train_df.shape[0]):\n    id_row = test_df.iloc[r,0]\n    y = test_df.iloc[r,1:].values\n    decision = run_model(x,y)\n    Decision = Decision.append({'Id': int(id_row), 'Category': int(decision)}, ignore_index=True) \n    print(Decision)\n    Decision.to_csv(\"Decision_baseline.csv\",  index=False)","b12abf53":"It works well in this case :)\n\nIn the following example, the  time-series is not increasing and it does not have any seasonality component.","49be3378":"We test the model in a toy example. If we remove the seasonality component, then the following time-series is increasing.","ffc3b4ca":"## Baseline Model","26ec7711":"It doesn't work well, the correct answer should be not-increasing. The problem is that the cos\/sin base can also fit any non-linear function in [0,1] :(.\n\n## We run it on the test set","2c1767bb":"## Ideas to improve baseline\n\n1. Adding another non-linear basis function components (e.g., $tanh(w0+w1x)$) and seeing if you can better split the seasonal and non-seasonal component.\n2. In the second example, the sin\/cos basis function fits the nonlinear function, but it is clear that the obtained mean function is non-periodic. By definition a function is periodic in the interval [0,1] if you see at least one full cycle (e.g. $cos(\\pi x)$ is not peridic in [0,1] but $cos(2 \\pi x)$ is). So you could try to verify if the function is periodic or not. In case it is periodic you can use \"non_periodic_prediction\" for checking if the function is increasing or not. Instead, if the function is not periodic that you could use  \"all_prediction\" for checking if the function is increasing or not. How can you test if a function is periodic or not given your basis functions in H ?\n3. The baseline model computes the derivative of the non-seasonal component and checks if the derivative is non-negative for all $x\\in[0,1]$ as a way to assess if sales are increasing. Could an analytical derivative work better in the above case?\n4. You could try to use GPs\n5. Is the decision criterion \"posterior_probability_deriviative_is_positive>0.95\" the best way to make decisions? Maybe you would do better if you take into account the way weighted accuracy is defined for this competition."}}