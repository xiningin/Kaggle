{"cell_type":{"0d678849":"code","bd7ecd5f":"code","043102f6":"code","5258cae2":"code","71aff9d5":"code","d27ff687":"code","88a5b8a1":"code","349d7f6d":"code","2b029907":"code","29602ca9":"code","5010f7ed":"code","6ddddce8":"code","182b5fee":"code","bcbcb543":"code","d5a0b89d":"code","7da08222":"code","c471871b":"code","af527c9d":"code","30f4786b":"code","58833417":"code","0f7ec11f":"code","23bcc3c0":"markdown","1ea8c36c":"markdown","42e15e91":"markdown","0a80d75d":"markdown","c40045bf":"markdown","62db4561":"markdown"},"source":{"0d678849":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd7ecd5f":"df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf.head()","043102f6":"df.info()","5258cae2":"import tensorflow as tf\nfrom tensorflow.keras import layers","71aff9d5":"def identity_block(X,F1,F2,F3,f):\n    X_shortcut = X\n    \n    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=\"valid\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    X = layers.Activation('relu')(X)\n    \n    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=\"same\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    X = layers.Activation('relu')(X) \n    \n    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=\"valid\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    \n    X = layers.Add()([X,X_shortcut])\n    X = layers.Activation('relu')(X)\n    return X","d27ff687":"def conv_block(X,F1,F2,F3,f,s):\n    X_shortcut = X\n    \n    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=\"valid\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    X = layers.Activation('relu')(X)\n    \n    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=\"same\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    X = layers.Activation('relu')(X) \n    \n    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=\"valid\")(X)\n    X = layers.BatchNormalization(axis=-1)(X)\n    \n    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=\"valid\")(X_shortcut)\n    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) \n    \n    X = layers.Add()([X,X_shortcut])\n    X = layers.Activation('relu')(X)\n    return X","88a5b8a1":"from tensorflow.keras import Model","349d7f6d":"def ResNet50(input_shape=(28,28,1),classes = 10):\n    \n    x_input = layers.Input(input_shape)\n    \n    x = layers.ZeroPadding2D((3,3))(x_input)\n    \n    x = layers.Conv2D(filters=4,kernel_size=(3,3),strides=(1,1),padding='valid')(x)\n    x = layers.BatchNormalization(axis=-1)(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n    \n    x = conv_block(x,4,4,8,f=3,s=1)\n    x = identity_block(x,4,4,8,f=3)\n    x = identity_block(x,4,4,8,f=3)\n    \n    x = conv_block(x,8,8,16,f=3,s=1)\n    x = identity_block(x,8,8,16,f=3)\n    x = identity_block(x,8,8,16,f=3)\n    x = identity_block(x,8,8,16,f=3)\n\n    x = conv_block(x,16,16,32,f=3,s=1)\n    x = identity_block(x,16,16,32,f=3)\n    x = identity_block(x,16,16,32,f=3)\n    x = identity_block(x,16,16,32,f=3)\n    x = identity_block(x,16,16,32,f=3)\n    x = identity_block(x,16,16,32,f=3)\n    \n    x = conv_block(x,32,32,64,f=3,s=2)\n    x = identity_block(x,32,32,64,f=3)\n    x = identity_block(x,32,32,64,f=3)\n    \n    x = layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(classes,activation='softmax')(x)\n    \n    model = Model(inputs = x_input,outputs=x)\n    \n    return model\n    ","2b029907":"model = ResNet50((28,28,1),10)\nprint(model.summary())","29602ca9":"y = df['label']\nx = df.drop(columns=['label'])","5010f7ed":"import matplotlib.pyplot as plt\nx_arr = np.zeros((42000,28,28,1))\nfor i in range(x.shape[0]):\n    arr = np.array(x.iloc[i,:])\n    arr = arr.reshape((28,28,1))\n    x_arr[i] = arr","6ddddce8":"count = 1\nplt.figure(figsize=(30,30))\nfor i in range(10):\n    plt.subplot(4,3,count)\n    count = count + 1\n    plt.imshow(x_arr[i])","182b5fee":"print(x_arr.shape)","bcbcb543":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\nx_train,x_test,y_train,y_test = train_test_split(x_arr,y,test_size = 0.1,random_state = 1)\nencoder = LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.fit_transform(y_test)\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\ny = encoder.fit_transform(y)\ny = np_utils.to_categorical(y)\nprint(x_train.shape,y_train.shape,x_test.shape,y_test.shape,sep=\" \")","d5a0b89d":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","7da08222":"history = model.fit(x_train,y_train,batch_size=20,epochs=10,validation_data = (x_test,y_test))","c471871b":"df_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ndf_test.head()","af527c9d":"x_arr_test = np.zeros((df_test.shape[0],28,28,1))\nfor i in range(df_test.shape[0]):\n    arr = np.array(df_test.iloc[i,:])\n    x_arr_test[i] = arr.reshape((28,28,1))","30f4786b":"ytest_pred = model.predict(x_arr_test)\nytest_pred = np.argmax(ytest_pred,axis=1)","58833417":"imageid = np.arange(1,x_arr_test.shape[0]+1)\nimageid = imageid.reshape((imageid.shape[0],1))\nytest_pred = ytest_pred.reshape((ytest_pred.shape[0],1))\nsubmission = np.concatenate((imageid,ytest_pred),axis=1)\nprint(submission)","0f7ec11f":"pd.DataFrame(submission,columns=['ImageId','Label']).to_csv('submission.csv',index=False)","23bcc3c0":"Following architecture is for the ResNet 50:\n![image.png](attachment:d705d445-28ef-4a92-b5da-fd1d3d6792e1.png)","1ea8c36c":"1.) Identity Block<br>\n![image.png](attachment:75f46f74-f19f-45cc-9e5b-42b61983d340.png)\n\nHere the activation from the zeroth layer is added to the output of 3rd layer, before applying the activation.\nThe function created takes input from previous layer 'X';<br>\nF1, F2, F3 are the number of filters for the 1st, 2nd and 3rd convolutional layer.<br>\nf is the filter size of the middle layer (i.e 2nd layer)<br>\n\nThe output size of the identity block is same as the input size. Because in first and third layers<br>\nfilter size and strides used are (1,1) and 'valid' padding is applied. Therefore, as per formula<br> \noutput_size = ((input_size - 1)\/1 - 1) = input_size.<br> \nAnd 'same' padding is applied in the 2nd layer. Therefore the size remains same.<br>","42e15e91":"Here, the 784 pixels are converted to 2D image using np.reshape() function\ntherefore 42000 X 724 becomes 42000 X 28 X 28 X1","0a80d75d":"2.) Convolutional Block<br>\n![image.png](attachment:931dad2d-d323-47d7-a009-4c59490593bc.png)<br>\nHere the activation from the zeroth layer is first passed through convolutional and batch normalization layer, then added to the output of 3rd layer (before applying the activation).\nThe function created takes input from previous layer 'X';<br>\nF1, F2, F3 are the number of filters for the 1st, 2nd and 3rd convolutional layer.<br>\nf is the filter size of the middle layer (i.e 2nd layer)<br>\ns is the strides for the convolutional layer used in the shortcut route<br>\nThe output size of the identity block depends on the stride s of the outer convolutional layer. Because in the outer convolutional layer, filter size and strides used are (1,1) and (s,s) respectively and 'valid' padding is applied. Therefore, as per formula<br> \noutput_size = ((input_size - 1)\/s - 1)<br> \n\nStrides 's' is applied for 1st layer in order to match the output of the outer layer.","c40045bf":"Here, I have used ResNet for Digit Recognizing. There are two essential blocks of the model\n<ol>1.) Identity Block<\/ol>\n<ol>2.) Convolutional Block<\/ol>","62db4561":"First 10 Images have been plotted for verifying the results"}}