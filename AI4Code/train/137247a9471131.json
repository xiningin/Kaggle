{"cell_type":{"bccb1209":"code","8175397f":"code","2d38b614":"code","1c4a6818":"code","628dfd8e":"code","f4c187ed":"code","d7ea5a05":"code","e5b6529f":"code","63c466d4":"code","b8e8899d":"code","e76705d3":"code","18af833a":"code","261466e8":"code","d68364bc":"code","7228fa86":"code","0d4a5be4":"code","910eaed3":"code","0fa9a7a9":"code","a570af68":"code","61529870":"code","baac897a":"code","1900e9bc":"code","ddce0de8":"code","20733d1d":"code","f5c32322":"code","238e65b6":"code","5666afb5":"code","de621d41":"code","16ff4c37":"code","4ba6e1c9":"code","be469d2a":"code","e718e4e3":"code","5cf6cc0b":"code","e8208f65":"code","5e5ea991":"code","077ad635":"code","687024a1":"code","4fb0a494":"code","f645535d":"code","5c8555fe":"code","b243c015":"code","f5cbf98c":"markdown","ec773778":"markdown","ff78b087":"markdown","eae3cf89":"markdown","ca3c5ccf":"markdown","778a390f":"markdown","a4b891ab":"markdown","a425d7c4":"markdown","f9c79a71":"markdown","0dd04128":"markdown","87c35c1a":"markdown","47e57243":"markdown","cbad6a01":"markdown","ee90db76":"markdown","467268d3":"markdown","5bf46525":"markdown","a2a1ee95":"markdown","7515e10d":"markdown","ec901c7c":"markdown","d8a577b1":"markdown"},"source":{"bccb1209":"from scipy.sparse import hstack\nimport time\nimport os\nimport lightgbm as lgb\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, StratifiedKFold, KFold, train_test_split, ShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\n#import ujson as json\nfrom tqdm import tqdm_notebook\nimport collections\nfrom catboost import CatBoostClassifier, Pool, cv","8175397f":"PATH_TO_DATA = '..\/input\/mlcourse-dota2-win-prediction\/'\ntrain_df = pd.read_csv(PATH_TO_DATA + 'train_features.csv')\ntrain_df.head()","2d38b614":"MATCH_FEATURES = [\n    ('game_time', lambda m: m['game_time']),\n    ('game_mode', lambda m: m['game_mode']),\n    ('lobby_type', lambda m: m['lobby_type']),\n    ('objectives_len', lambda m: len(m['objectives'])),\n    ('chat_len', lambda m: len(m['chat'])),\n]\n\nPLAYER_FIELDS = [\n    'hero_id',\n    'gold',\n    'x',\n    'y'\n]\n\n\ndef extract_features_csv(match):\n    row = [\n        ('match_id_hash', match['match_id_hash']),\n    ]\n    \n    for field, f in MATCH_FEATURES:\n        row.append((field, f(match)))\n        \n    for slot, player in enumerate(match['players']):\n        if slot < 5:\n            player_name = 'r%d' % (slot + 1)\n        else:\n            player_name = 'd%d' % (slot - 4)\n\n        for field in PLAYER_FIELDS:\n            column_name = '%s_%s' % (player_name, field)\n            row.append((column_name, player[field]))\n        \n        for field in ['damage']:\n            column_name = '%s_%s' % (player_name, field)\n            row.append((column_name, sum(list(player[field].values()))))\n\n            \n    return collections.OrderedDict(row)\n    \ndef extract_targets_csv(match, targets):\n    return collections.OrderedDict([('match_id_hash', match['match_id_hash'])] + [\n        (field, targets[field])\n        for field in ['game_time', 'radiant_win', 'duration', 'time_remaining', 'next_roshan_team']\n    ])\n\ntry:\n    import ujson as json\nexcept ModuleNotFoundError:\n    import json\n    print ('Please install ujson to read JSON oblects faster')\n    \ntry:\n    from tqdm import tqdm_notebook\nexcept ModuleNotFoundError:\n    tqdm_notebook = lambda x: x\n    print ('Please install tqdm to track progress with Python loops')\n\ndef read_matches(matches_file):\n    \n    MATCHES_COUNT = {\n        'test_matches.jsonl': 10000,\n        'train_matches.jsonl': 39675,\n    }\n    _, filename = os.path.split(matches_file)\n    total_matches = MATCHES_COUNT.get(filename)\n    \n    with open(matches_file) as fin:\n        for line in tqdm_notebook(fin, total=total_matches):\n            yield json.loads(line)\n            \ntrain_features_from_json = []\ntargets_from_json = []\n\nfor match in read_matches(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')):\n    match_id_hash = match['match_id_hash']\n    features = extract_features_csv(match)\n    target = extract_targets_csv(match, match['targets'])\n    \n    train_features_from_json.append(features)\n    targets_from_json.append(target)\n    \ntest_features_from_json = []\n\nfor match in read_matches(os.path.join(PATH_TO_DATA, 'test_matches.jsonl')):\n    match_id_hash = match['match_id_hash']\n    features = extract_features_csv(match)\n    test_features_from_json.append(features)","1c4a6818":"train = pd.DataFrame.from_records(train_features_from_json).set_index('match_id_hash')\ntest = pd.DataFrame.from_records(test_features_from_json).set_index('match_id_hash')\ntargets = pd.DataFrame.from_records(targets_from_json).set_index('match_id_hash')\ny = targets['radiant_win']\n\ntrain.head()","628dfd8e":"test.head()","f4c187ed":"[c for c in train.columns if 'r1_' in c]","d7ea5a05":"rf = RandomForestClassifier(n_estimators=100, \n                            n_jobs=4, \n                            min_samples_leaf=3,\n                            random_state=17)\n\nn_fold = 5\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=17)\ncv_scores_rf_initial = cross_val_score(rf, train, y, cv=cv, \n                                scoring='roc_auc', n_jobs=-1)","e5b6529f":"cv_scores_rf_initial","63c466d4":"cv_scores_rf_initial.mean(), cv_scores_rf_initial.std()","b8e8899d":"\ndef add_new_features(df_features, matches_file):\n    \n    # Process raw data and add new features\n    for match in read_matches(matches_file):\n        match_id_hash = match['match_id_hash']\n\n        radiant_baracks_kills = 0\n        dire_baracks_kills = 0\n\n        for objective in match['objectives']:\n\n            if objective['type'] == 'CHAT_MESSAGE_BARRACKS_KILL':\n                if objective['key'] in ['1','2','4','8','16','32']:\n                    radiant_baracks_kills += 1\n                if objective['key'] in ['64','128','256','512','1024','2048']:\n                    dire_baracks_kills += 1\n\n        df_features.loc[match_id_hash, 'radiant_baracks_kills'] = radiant_baracks_kills\n        df_features.loc[match_id_hash, 'dire_baracks_kills'] = dire_baracks_kills\n        df_features.loc[match_id_hash, 'diff_baracks_kills'] = radiant_baracks_kills - dire_baracks_kills\n","e76705d3":"new_train = pd.DataFrame(index = train.index)\nnew_test = pd.DataFrame(index = test.index)","18af833a":"add_new_features(new_train, \n                 os.path.join(PATH_TO_DATA, \n                              'train_matches.jsonl'))\nadd_new_features(new_test, \n                 os.path.join(PATH_TO_DATA, \n                              'test_matches.jsonl'))","261466e8":"new_train['radiant_baracks_kills'].describe()","d68364bc":"train1 = pd.concat([train, new_train], axis = 1)","7228fa86":"cv_scores_rf1 = cross_val_score(rf, train1, y, cv=cv, \n                                scoring='roc_auc', n_jobs=-1)","0d4a5be4":"cv_scores_rf1.mean(), cv_scores_rf1.std()","910eaed3":"cv_scores_rf1 > cv_scores_rf_initial","0fa9a7a9":"def modify_df_with_feature(dataframe, feature_name):\n    epsilon = 0.00000000000001             # Let's avoid zero devision situation\n    dataframe = dataframe.copy()\n    r_feature_columns = [col for col in dataframe if col.endswith(feature_name)][:5]\n    d_feature_columns = [col for col in dataframe if col.endswith(feature_name)][5:]\n    dataframe['r_' + feature_name + '_total'] = dataframe[r_feature_columns].sum(axis = 1)\n    dataframe['d_' + feature_name + '_total'] = dataframe[d_feature_columns].sum(axis = 1)\n    dataframe[feature_name + '_prop'] = dataframe['r_' + feature_name + '_total'] \/ (dataframe['d_' + feature_name + '_total'] + epsilon)   # <- approved\n\n    return dataframe","a570af68":"train2 = modify_df_with_feature(train1, 'gold')","61529870":"train2.head()","baac897a":"cv_scores_rf2 = cross_val_score(rf, train2, y, cv=cv, \n                                scoring='roc_auc', n_jobs=-1)","1900e9bc":"cv_scores_rf2.mean(), cv_scores_rf2.std()","ddce0de8":"cv_scores_rf2 > cv_scores_rf1","20733d1d":"def add_hero_names(df):\n    hero_columns = [c for c in df.columns if '_hero_' in c]\n    names_df = df[hero_columns]\n    names_df = names_df.astype(str)\n    for team in 'r', 'd':\n        players = [f'{team}{i}' for i in range(1, 6)]\n        hero_columns = [f'{player}_hero_id' for player in players]\n        d = pd.get_dummies(names_df[hero_columns[0]])\n        for c in hero_columns[1:]:\n            d += pd.get_dummies(names_df[c])\n        names_df = pd.concat([names_df, d.add_prefix(f'{team}_hero_')], axis=1)\n        names_df.drop(columns=hero_columns, inplace=True)\n    df = pd.concat([df, names_df], axis = 1)\n    return df","f5c32322":"train3 = add_hero_names(train2)","238e65b6":"cv_scores_rf3 = cross_val_score(rf, train3, y, cv=cv, \n                                scoring='roc_auc', n_jobs=-1)\ncv_scores_rf3.mean(), cv_scores_rf3.std()","5666afb5":"cv_scores_rf3 > cv_scores_rf2","de621d41":"train.head()","16ff4c37":"train_up = train.reset_index()\ntrain_up['match_id_hash'] = train_up['match_id_hash'] + '_up'\ntrain_up.set_index('match_id_hash', inplace=True)","4ba6e1c9":"features = ['hero_id',\n            'gold', \n            'damage',\n           ]","be469d2a":"for t1 in ['r', 'd']:\n    for player in range(1,6):\n        for feature in features:\n            if t1 == 'r':\n                t2 = 'd'\n            else:\n                t2 = 'r'\n            col1 = t1 + str(player) + '_' + feature\n            col2 = t2 + str(player) + '_' + feature\n            train_up[col1] = train[col2].values\n            \n        x_col1 = t1 + str(player) + '_x'\n        x_col2 = t2 + str(player) + '_x'\n        train_up[x_col1] = 186 - (train[x_col2].values - 68)\n        y_col1 = t1 + str(player) + '_y'\n        y_col2 = t2 + str(player) + '_y'\n        train_up[y_col1] = 186 - (train[y_col2].values - 68)","e718e4e3":"train_up.head()","5cf6cc0b":"emb_train = pd.concat([train, train_up])\nemb_train.shape","e8208f65":"targets_up = targets.reset_index()\ntargets_up['match_id_hash'] = targets_up['match_id_hash'] + '_up'\ntargets_up.set_index('match_id_hash', inplace=True)\ntargets_up['radiant_win'] = targets_up['radiant_win'].map({False: True, True: False})\n\ntargets = pd.concat([targets, targets_up])\n\ntargets.shape","5e5ea991":"new_train_up = new_train.reset_index()\nnew_train_up['match_id_hash'] = new_train_up['match_id_hash'] + '_up'\nnew_train_up.set_index('match_id_hash', inplace=True)","077ad635":"for feat in ['_baracks_kills']:\n    for t1 in ['radiant', 'dire']:\n        if t1 == 'radiant':\n            t2 = 'dire'\n        else:\n            t2 = 'radiant'\n        col1 = t1 + feat\n        col2 = t2 + feat\n        new_train_up[col1] = new_train[col2].values\n\n    new_train_up['diff' + feat] = -new_train['diff' + feat].values","687024a1":"emb_new_train = pd.concat([new_train, new_train_up])\nemb_new_train.shape","4fb0a494":"train_emb = pd.concat([emb_train, emb_new_train], axis = 1)\n","f645535d":"train_emb_gold = modify_df_with_feature(train_emb, 'gold')\ntrain_emb_gold_heroes = add_hero_names(train_emb_gold)\ntrain_emb_gold_heroes.shape\ny = targets['radiant_win']","5c8555fe":"cv_scores_rf_final = cross_val_score(rf, train_emb_gold_heroes, y, cv=cv, \n                                scoring='roc_auc', n_jobs=-1)\ncv_scores_rf_final.mean(), cv_scores_rf_final.std()","b243c015":"cv_scores_rf_final > cv_scores_rf3","f5cbf98c":"Define some constants, and then read basic datasets provided by organizers to look, what we have here?","ec773778":"Now we concat barracks columns to the initial dataset and see what happens:","ff78b087":"Code looks ugly, and i'll fix it. But we have a nice inverted copy of our initial dataset","eae3cf89":"Hi, guys!\n\nIn this kernel i'll try to explain my workflow in Dota competition, which resulted in 0.85920 individual score.\n\nI'm a total noob in coding, so some parts of this kernel may look really ugly for my more experienced friends, but somebody definitely can find some valuable ideas here.\n\nIn some rules related reason i had to remove almost all features to have some good non high score example.\n\nLet's import some libraries!","ca3c5ccf":"**Step 4.\nThe zest of the Kaggle competition process.\n**\nLets go and steal some cool ideas!\n\nThis kernel looks good enough to be borrowed for some time: https:\/\/www.kaggle.com\/utapyngo\/dota-2-how-to-make-use-of-hero-ids\n\nHere we make binary feature which tells us, is the hero in the team.","778a390f":"Let's set the first baseline. Random forest classifier can be a good example:","a4b891ab":"Here the results are not exactly positive. But trust me, with the correct classifier this feature set works really good.\n\nAnd you can find lots of other ideas in the public kernels. ","a425d7c4":"You can find some good FE effort from my teammate @Payonear here: https:\/\/www.kaggle.com\/karthur10\/eda-with-gini-coefficient-fe-on-extended-dataset\n\nIn this Kernel i'll describe my approach which made 0.85920 LB score possible.\n\nI had to simplify a model really hard, just to explain concepts, you can definitely do better on each step, and i'll add my comments, what exactly.\n    \n**Step 1.\nDownloading data from json.**","f9c79a71":"**Wow!**\n\n\nMore than 4% up in CV score with a single feature. You have almost 20 only in basic organisers dataset. Just imagine, how many cool things you can do here!\nYou have to consider different options:\n* sometimes std() gives us more info, than mean()\n* may be proportion is not the best option and you have to stick to difference\n* some features can be succesfully combined together in different ways (multiplying, for example)","0dd04128":"**But now, guys, we have a winner!**\n\nThe most valuable step in my model, proposed by @PuffOfSmoke.\n\n**Step 5.\nEmbedding.**\n\nAs you probably know, the more data, the better. We can't use external data, but we can at least augment our dataset.\n\nThe main idea here is: \"what if we flip the whole game? let radiants be dires and and vice versa!\"\n\nWe can create a copy of our train dataset, flip all teams, and then create a copy of target and change the game result.\n\nHope it works, lets try!","87c35c1a":"Step 3.\nIt's time to do some basic FE.","47e57243":"![](http:\/\/minbat.jp\/wp-content\/uploads\/sites\/7\/2019\/07\/DOTA2-1-1024x576.jpg)","cbad6a01":"Lets apply the same transformations to the embedded dataset!","ee90db76":"At this step we definitely can do more interesting things:\n* add more features from json\n* discover some substructure in some features, for example damage consists of damage to heroes, creeps, buildings ect\nand much-much more.\n\nBut lets move further!\n\n**Step 2.\nExtracting objectives**\n\nObjectives field in json has lots interesting stuff inside, lets focus on barracks for now:\n![](https:\/\/liquipedia.net\/commons\/images\/8\/8d\/Barracks.jpg)","467268d3":"**What's next?**\n\nLots of things:\n* Try more sophysticated classifiers like Catboost and LightGBM!\n* Stack\/Blend them!\n* Find a correct feature selection scheme\n* Try to calculate Heroes properties like avg kills in all matches etc\n\nUpvote this post please, if you found it helpful!","5bf46525":"Upsampling really works!\n\nIn practice this last step boosted me from 0.857 to 0.859 in LB Score ","a2a1ee95":"Looks, like a good plan. But we forgot to flip the barracks","7515e10d":"**So, now we have a nice and clean dataset.**\nWe have such column for each hero:\n* Hero_id - id number of hero in the game. We have 115 unique values, and we can make some magic with them later\n* Gold - one of the most valuable features in the game\n* X and Y - coordinates on the map. We will cover them later\n* Damage - a feature not available in the dataset provided by organizers","ec901c7c":"And now we have a cool embedded dataset, lets embed a target!","d8a577b1":"**Nice!\nWe improved mean CV-score, std, and performed better in all folds.**\n\nIf you dive into objectives, you will find much more interesting things:\n* towers\n* aegis\n* chat len\n\n\nFor example, lots of messages in the chat can be interpeted as tactics discussion in a good team. Or may be not :)"}}