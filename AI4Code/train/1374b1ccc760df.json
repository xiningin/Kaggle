{"cell_type":{"24a34e53":"code","083185c0":"code","88c9b96f":"code","fb494668":"code","67555a64":"code","e17688c7":"code","a77411f7":"code","990f98ed":"code","59a546f5":"code","ca3c92cc":"code","a740e277":"code","955afb15":"markdown","4857da86":"markdown","7b6f1cf5":"markdown"},"source":{"24a34e53":"from __future__ import print_function\n\nimport chess\nimport chess.svg\n\nimport numpy as np\nimport time, random\n\nimport torch as T\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm import tqdm\n","083185c0":"datafiles = ['..\/input\/train.csv']\n\nmax_epoch = 3 #100 -- notebook just stops after a while?\nlog_interval = 300\nearly_stopping_patience = 10\nbest_score = None\nbest_accuracy = None\n\n# parameters\n#  1    Side to move\n# 12    Position of each piece (both sides)\n# 12    to squares of each pieces (both sides)\nbit_layers = 1 + \\\n            12 + \\\n            12\nlearning_rate = 0.01\n\n# model structure\nconvolution_layers = 4\nfully_connected = 1\nin_out_channel_multiplier = 3\n\n# check for gpu\ndevice = T.device('cpu')\nif T.cuda.is_available():\n    device = T.device('cuda')\ndevice","88c9b96f":"\ndef create_input(board):\n    posbits = chess.SquareSet(board.turn).tolist()\n    \n    for piece in [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]:\n        posbits += board.pieces(piece, chess.WHITE).tolist()\n\n    for piece in [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]:\n        posbits += board.pieces(piece, chess.BLACK).tolist()\n        \n    # all attack squares\n    to_sqs = [chess.SquareSet() for x in range(7)]\n    for i, p in board.piece_map().items():\n        for t in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT, chess.KING, chess.PAWN]:\n            if p.piece_type==t and p.color==board.turn:\n                to_sqs[p.piece_type] = to_sqs[p.piece_type].union(board.attacks(i))\n            \n    posbits += to_sqs[1].tolist()+to_sqs[2].tolist()+to_sqs[3].tolist()+to_sqs[4].tolist()+to_sqs[5].tolist()+to_sqs[6].tolist()\n    \n    # all opponent attack squares\n    board.turn = not board.turn\n    to_sqs = [chess.SquareSet() for x in range(7)]\n    for i, p in board.piece_map().items():\n        for t in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT, chess.KING, chess.PAWN]:\n            if p.color==board.turn:\n                to_sqs[p.piece_type] = to_sqs[p.piece_type].union(board.attacks(i))\n            \n    posbits += to_sqs[1].tolist()+to_sqs[2].tolist()+to_sqs[3].tolist()+to_sqs[4].tolist()+to_sqs[5].tolist()+to_sqs[6].tolist()\n    board.turn = not board.turn\n    \n    #en passant square\n    #posbits += (chess.SquareSet(chess.BB_SQUARES[board.ep_square]) if board.ep_square else chess.SquareSet()).tolist()\n    \n    x = T.tensor(posbits, dtype = T.float32)\n    x = x.reshape([bit_layers,8,8])\n    return x\n","fb494668":"\nclass FenDataset(Dataset):\n    def __init__(self, filenames, has_header=True):\n        self.all_data = []\n        self.all_fen = []\n        for idx, filename in enumerate(filenames):\n            with open(filename, 'r') as f:\n                lines = f.readlines()[1:] if has_header else f.readlines()\n                for line in tqdm(lines, desc='Loading '+filename+' ('+str(idx+1)+'\/'+str(len(filenames))+')'):\n                    fen, move = line[:-1].split(',')\n                    self.all_fen.append((fen, move))\n                    \n                    board = chess.Board(fen)\n                    x = create_input(board)\n                    move = chess.Move.from_uci(move)\n                    pos = move.from_square*64+move.to_square\n                    self.all_data.append((x, pos, line[:-1]))\n                \n    def __len__(self):\n        return len(self.all_data)\n\n    def __getitem__(self, idx):\n        return self.all_data[idx]\n\n    def getFen(self, idx):\n        return self.all_fen[idx]\n        ","67555a64":"dataset = FenDataset(datafiles)\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = T.utils.data.random_split(dataset, [train_size, test_size])\n\nprint('Samples:',len(dataset), 'Total,', len(train_dataset),'Train,', len(test_dataset),'Test.')\n\ntrain_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n\npatience = 0","e17688c7":"a,b, line = dataset[np.random.choice(100)]\nfen, best_move = line.split(',')\nfen, best_move","a77411f7":"# Board position before the mate\nboard = chess.Board(fen)\nboard","990f98ed":"# Move that mates\nmove = chess.Move.from_uci(best_move)\nboard.san(move)","59a546f5":"board.push(move)\nboard","ca3c92cc":"\nclass Model(nn.Module):\n    def __init__(self, in_channels):\n        super(Model, self).__init__()\n    \n        kernel_size = 3\n        padding = kernel_size\/\/2\n        \n        out_channels = in_channels * in_out_channel_multiplier\n        self.conv_out_nodes = out_channels * 8 * 8\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n        self.bn1 = nn.BatchNorm2d(out_channels) # **** WOW ****\n        \n        if convolution_layers>=2:\n            self.conv2 = nn.Conv2d(out_channels, out_channels*2, kernel_size, padding=padding)\n            self.bn2 = nn.BatchNorm2d(out_channels*2) # **** WOW ****\n            self.conv_out_nodes *= 2\n\n        if convolution_layers>=3:\n            self.conv3 = nn.Conv2d(out_channels*2, out_channels*4, kernel_size, padding=padding)\n            self.bn3 = nn.BatchNorm2d(out_channels*4)\n            self.conv_out_nodes *= 2\n        \n        if convolution_layers>=4:\n            self.conv4 = nn.Conv2d(out_channels*4, out_channels*8, kernel_size, padding=padding)\n            self.bn4 = nn.BatchNorm2d(out_channels*8)\n            self.conv_out_nodes *= 2\n        \n        self.fc1 = nn.Linear(self.conv_out_nodes, 1024)\n        self.drop1 = nn.Dropout(p=0.5)\n        \n        if fully_connected>=2:\n            self.fc2 = nn.Linear(1024, 1024)\n            self.drop2 = nn.Dropout(p=0.5)\n        \n        self.fcf = nn.Linear(1024, 64*64)\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.bn1(x)\n        \n        if convolution_layers >= 2:\n            x = F.relu(self.conv2(x))\n            x = self.bn2(x)\n            \n        if convolution_layers >= 3:\n            x = F.relu(self.conv3(x))\n            x = self.bn3(x)\n        \n        if convolution_layers >= 4:\n            x = F.relu(self.conv4(x))\n            x = self.bn4(x)\n        \n        x = x.view(-1, self.conv_out_nodes)\n        x = F.relu(self.fc1(x))\n        x = self.drop1(x)\n        \n        if fully_connected >= 2:\n            x = F.relu(self.fc2(x))\n            x = self.drop2(x)\n            \n        x = self.fcf(x)\n        #x = F.relu(self.fcf(x))\n        \n        #x = F.log_softmax(x, dim=1)\n        # x = F.softmax(x, dim=1) -- bad\n        \n        return x\n        ","a740e277":"\n# NN\nmodel = Model(bit_layers)\nmodel.to(device)\n\noptimizer = T.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n#optimizer = T.optim.Adam(model.parameters(), lr=learning_rate) # not learning\n\nfor epoch in range(max_epoch):\n    # TRAIN\n    model.train()\n    pbar = tqdm(total=len(train_loader))\n    pbar.set_description('Training ('+str(epoch)+')')\n    for batch_idx, (data, target, fen) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n\n        if batch_idx % log_interval == 0:\n            pbar.set_postfix(loss=loss.item())\n        pbar.update(1)\n    pbar.close()\n\n    # TEST\n    model.eval()\n\n    test_loss = 0\n    correct = 0\n\n    games_sample = []\n    with T.no_grad():\n        for data, target, fen in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            rndidx = np.random.choice(len(fen))\n            games_sample.append((fen[rndidx], output[rndidx]))\n    test_loss \/= len(test_loader.dataset)\n\n    accuracy = 100. * correct \/ len(test_loader.dataset)\n    print('\\tTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)'.format(\n        test_loss, correct, len(test_loader.dataset), accuracy))\n\n    score = -test_loss\n    # early stopping\n    if not best_score or score>best_score or correct>best_accuracy:\n        best_score = score\n        best_accuracy = correct\n        patience = 0\n    else:\n        patience += 1\n        if patience > early_stopping_patience:\n            print('Stopping early!!!')\n            break\n\n    print()\n","955afb15":"Each row in the datafile has a FEN string and a best move string.","4857da86":"**Create Input for the Network:**\n\nThe csv file provide FEN (positions) for the chess game which has a single move that can deliver mate.\nThere are 13 input planes (channels) for each game.\nEach channel is made of 8x8 float values. Each value has either 1 or 0. Indicating presence or absence of a chess piece.\n\nThe first plane just indicates the side to move.\n\nThe next 12 planes indicate position of each piece type for both the sides.\n\nE.g. Initial white king position will be:\n>     00000000\n>     00000000\n>     00000000\n>     00000000\n>     00000000\n>     00000000\n>     00000000\n>     00001000\n    \nThe next 12 planes indicate where each piece type can move to.","7b6f1cf5":"Each line in the dataset has a FEN (chess position) string and a best move string (in uci format).<BR>\nE.g."}}