{"cell_type":{"1639598f":"code","982613c8":"code","bd5597ee":"code","86769d52":"code","986009e9":"code","ebbf3eed":"markdown","6c1a2277":"markdown","b8ba9610":"markdown","3e329821":"markdown"},"source":{"1639598f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","982613c8":"import cv2\nimport numpy as np\nimport pandas as pd\nimport mahotas\nimport h5py\nfrom sklearn.preprocessing import MinMaxScaler\ntraindf=pd.read_csv(\"..\/input\/train_labels.csv\",dtype=str)\ntestdf=pd.read_csv(\"..\/input\/sample_submission.csv\",dtype=str)\ncombineddf = pd.concat([traindf,testdf])","bd5597ee":"def fd_hu_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\ndef fd_haralick(image):    # convert the image to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # compute the haralick texture feature vector\n    haralick = mahotas.features.haralick(gray).mean(axis=0)\n    return haralick\n \ndef fd_histogram(image, mask=None):\n    # convert the image to HSV color-space\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    bins = 256\n    # compute the color histogram\n    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n    # normalize the histogram\n    cv2.normalize(hist, hist)\n    hist= hist.flatten()\n    return hist","86769d52":"global_features = []\nfor i in range(len(traindf)):\n    image = cv2.imread(\"..\/input\/train\/\"+traindf.id[i]+\".tif\")\n    global_feature = np.hstack([fd_histogram(image), fd_haralick(image), fd_hu_moments(image)])\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    global_features.append(global_feature)\nfor i in range(len(testdf)):\n    image = cv2.imread(\"..\/input\/test\/\"+testdf.id[i]+\".tif\")\n    global_feature = np.hstack([fd_histogram(image), fd_haralick(image), fd_hu_moments(image)])\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    global_features.append(global_feature)\n#Normalize The feature vectors...\nrescaled_features = scaler.fit_transform(global_features)\ntarget = list(traindf.label)","986009e9":"h5f_data = h5py.File('data.h5', 'w')\nh5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n\nh5f_label = h5py.File('labels.h5', 'w')\nh5f_label.create_dataset('dataset_1', data=np.array(target))\n\nh5f_data.close()\nh5f_label.close()","ebbf3eed":"# 10-fold cross validation\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","6c1a2277":"test_size = 0.1\n# split the training and testing data\n(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n                                                                                          np.array(global_labels),\n                                                                                          test_size=test_size,\n                                                                                          random_state=seed)","b8ba9610":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.svm import SVC","3e329821":"models = []\nmodels.append(('SVM', SVC(random_state=9)))\n# variables to hold the results and names\nresults = []\nnames = []\nscoring = \"accuracy\"\n\n# import the feature vector and trained labels\nh5f_data = h5py.File('data.h5', 'r')\nh5f_label = h5py.File('labels.h5', 'r')\n\nglobal_features_string = h5f_data['dataset_1']\nglobal_labels_string = h5f_label['dataset_1']\n\nglobal_features = np.array(global_features_string)\nglobal_labels = np.array(global_labels_string)\n\nh5f_data.close()\nh5f_label.close()\n"}}