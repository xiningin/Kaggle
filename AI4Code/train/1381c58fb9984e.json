{"cell_type":{"64ac3bbd":"code","5e696b48":"code","649a6393":"code","b15cd9c5":"code","4f5af8b5":"code","676d340f":"code","04d6f6f5":"code","f67ad359":"code","f46ac451":"code","7ef4ae8e":"code","396fd961":"code","285eb8cd":"code","0375848d":"code","e722ba79":"code","f5679f74":"code","dcd21373":"code","5305155b":"code","4c178e05":"code","d6525c4b":"code","98c488d8":"code","8911da6f":"code","d4235776":"code","8b14c929":"markdown","4865250e":"markdown","13e58159":"markdown","c502378a":"markdown","7b21d588":"markdown","f58b422c":"markdown","7b6d404e":"markdown","dbe7283d":"markdown","61fe12bf":"markdown","ef101e17":"markdown","8a4edc20":"markdown","e0b84ef1":"markdown"},"source":{"64ac3bbd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os #interacting with input and output directories\nimport tensorflow as tf #framework for creating the neural network\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport PIL #Python Imaging Library for image manipulations\nfrom PIL import Image\nimport matplotlib.pyplot as plt # matplot for plotting graphs and displaying sample images","5e696b48":"IMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\npath = '..\/input\/modified-gganbu-data\/Ggnabu Data - Copy\/Training\/Training'","649a6393":"training_ds = tf.keras.preprocessing.image_dataset_from_directory(directory = path, \n                                                                 batch_size = BATCH_SIZE, \n                                                                 image_size = IMAGE_SIZE, \n                                                                 seed = 10, \n                                                                 validation_split = 0.05, \n                                                                 subset = 'training', \n                                                                 label_mode = 'categorical')","b15cd9c5":"validation_ds = tf.keras.preprocessing.image_dataset_from_directory(directory = path, \n                                                                 batch_size = BATCH_SIZE, \n                                                                 image_size = IMAGE_SIZE, \n                                                                 seed = 10, \n                                                                 validation_split = 0.05, \n                                                                 subset = 'validation', \n                                                                 label_mode = 'categorical')","4f5af8b5":"class_names = training_ds.class_names\nprint(class_names)","676d340f":"image_batch, label_batch = next(iter(training_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i]\n    plt.title(class_names[np.argmax(label)])\n    plt.axis(\"off\")","04d6f6f5":"for image_batch, labels_batch in training_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","f67ad359":"AUTOTUNE = tf.data.AUTOTUNE\ntraining_ds = training_ds.prefetch(buffer_size = AUTOTUNE)\nvalidation_ds = validation_ds.prefetch(buffer_size = AUTOTUNE)","f46ac451":"IMAGE_SHAPE = IMAGE_SIZE + (3, )\ninputs = tf.keras.Input(shape = IMAGE_SHAPE)\nx = tfl.Rescaling(1.\/255)(inputs)\nx = tfl.Conv2D(filters = 4, kernel_size =(3, 3), padding = 'same', strides = (1, 1))(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.MaxPool2D(pool_size = (2, 2), strides = 2)(x)\nx = tfl.Conv2D(filters = 8, kernel_size =(3, 3), padding = 'same', strides = (1, 1))(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.MaxPool2D(pool_size = (2, 2), strides = 2)(x)\nx = tfl.Conv2D(filters = 16, kernel_size =(3, 3), padding = 'same', strides = (1, 1))(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.MaxPool2D(pool_size = (2, 2), strides = 2)(x)\nx = tfl.Conv2D(filters = 32, kernel_size =(3, 3), padding = 'same', strides = (1, 1))(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.MaxPool2D(pool_size = (2, 2), strides = 2)(x)\nx = tfl.Conv2D(filters = 64, kernel_size =(3, 3), padding = 'same', strides = (1, 1))(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.MaxPool2D(pool_size = (2, 2), strides = 2)(x)\nx = tfl.Flatten()(x)\nx = tfl.Dense(2500)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(1500)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(1000)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(800)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(600)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(400)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(200)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(100)(x)\nx = tfl.BatchNormalization()(x)\nx = tfl.ReLU()(x)\nx = tfl.Dense(12, activation = 'softmax')(x)","7ef4ae8e":"model = tf.keras.Model(inputs = inputs, outputs = x)","396fd961":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","285eb8cd":"history = model.fit(training_ds, validation_data = validation_ds, epochs = 100, batch_size = 32)","0375848d":"model.summary()","e722ba79":"model.save('gganbuModel.h5')","f5679f74":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","dcd21373":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","5305155b":"class_array = np.array([])\nimage_array = np.array([])\n\nfor dirname, _, filenames in os.walk(\"..\/input\/logical-rhythm-2k21-gganbu\/Test\/Test\"):\n    for filename in filenames:\n        fullFileName = os.path.join(dirname, filename)\n        img_path = fullFileName\n        img = tf.keras.preprocessing.image.load_img(img_path, target_size = IMAGE_SIZE)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = np.expand_dims(img, axis = 0)\n        img_test = img\/255.0\n        pred = model.predict(img)\n        pred = np.argmax(pred)\n        class_array = np.append(class_array, pred)\n        image_array = np.append(image_array, fullFileName[46:])\n\nupdated_im_arr = [x[:-4] for x in image_array]\nupdated_im_arr = [int(i) for i in updated_im_arr]\nprint(class_array, updated_im_arr)\n","4c178e05":"output_1 = pd.DataFrame({'image_number': updated_im_arr,\n                       'country_denomination': class_array})\noutput_1.head()","d6525c4b":"sorted_output = pd.DataFrame(output_1.sort_values(['image_number'], ascending=True).to_numpy(),\n                   index=output_1.index, columns=output_1.columns)\nsorted_output.head()","98c488d8":"num_to_note_dict = {0: 'india_10', 1: 'india_100', 2: 'india_20', \n                   3: 'india_200', 4: 'india_2000', 5: 'india_50', \n                   6: 'india_500', 7: 'thai_100', 8: 'thai_1000',\n                    9: 'thai_20', 10: 'thai_50', 11:'thai_500'}\n\nsorted_output.country_denomination = [num_to_note_dict[item] for item in sorted_output.country_denomination]\nsorted_output.head()","8911da6f":"convert_dict = {'image_number' : int}\nsorted_output = sorted_output.astype(convert_dict)\nprint(sorted_output.dtypes)","d4235776":"sorted_output.to_csv('submission.csv', index=False)","8b14c929":"# Imports","4865250e":"Printing out the currency class names","13e58159":"# CNN architecture \n\nWe have used the following layers - \n* Input - to specify input layer dimensions (image dimensions)\n* Conv2D - convolution layers\n* Rescaling - to rescale input layer pixel values\n* BatchNormalization - has a regularization effect\n* ReLU - activation function\n* MaxPool2D - shrink image dimensions and learn features\n* Flatten - to create a single array for a single example\n* Dense - standard deep neural network layer","c502378a":"# Creating an Efficent Data Input Pipeline to Speed up Training \n\nThe prefetch methods loads images into memory while simultaneously training, thus reducing training time","7b21d588":"Using the adam optimizer as it works better than RMSProp in most cases","f58b422c":"Saving the predictions as a .csv file","7b6d404e":"Creating a simple plot to visualize the kind of images present in dataset along with their labels","dbe7283d":"# Generating Predictions","61fe12bf":"# Preparing the Training and Validation Datasets\n\nWe have used TF's image_dataset_from_directory method to load data. We have created a 5% validation data split. \n\nAlternate ways to create tf.data type dataset include the ImageDataGenerator object, however we found that without data to augment, it has no use.","ef101e17":"# Fixing the Data Format and Path","8a4edc20":"# Introduction to Gganbu Problem Statement\n\n**Our approach** - In order to classify different currency notes of India and Thailand, we need a classification model based on CNNs. We have used Google's Tensorflow as the DL framework as it supports the high level Keras API. Facebook's Pytorch may also be used to accomplish the task. \n\n**Data organization** - Upon having a look at the dataset we found a corrupt file, thus we could not use the dataset available on kaggle and had to re-upload the dataset with the change. In order to simplify the classification process, we also changed the structure of the dataset, merging all similar currency notes into a single folder. Ex. India_10_Mix and India_10_Old, India_10_New were all merged together. This resulted in 12 currency folders with their corresponding images. The test folder on Kaggle was not tampered with.\nAlso we found that the dataset consisted of augmented images, thus we decided not to use data augmentation.\n\nSome of the major problems we encountered while preparing the machine learning model were - \n* Identifying the corrupt image file and removing it\n* Deciding the neural network architecture and layers involved\n* Reducing overfitting on training data\n* Deciding on how to feed data into the model\n* Deciding on the type of optimizer we wanted to use\n* Reducing the training time \n\nThe solutions we found to all these problems are listed along with the cells they correspond to.\n","e0b84ef1":"Plotting the training and validation accuracy and loss graphs"}}