{"cell_type":{"5bad5a52":"code","7f6d9ad6":"code","798113c1":"code","fc671f8d":"code","89b2d62c":"code","ae319e51":"code","40c8afe7":"code","956b019e":"code","3926e833":"code","bf3571a8":"code","37a7e6ee":"code","02f70c18":"code","908bc0ed":"code","15f7b216":"code","21861797":"code","cef46a3c":"code","f0780dcf":"markdown","9e8eece4":"markdown","21bb1f36":"markdown"},"source":{"5bad5a52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7f6d9ad6":"insurance = pd.read_csv('https:\/\/raw.githubusercontent.com\/skathirmani\/datasets\/main\/insurance.csv')\ninsurance['high_bmi_smokers'] = insurance.apply(\n    lambda row: 1 if row['bmi']>30 and row['smoker'] == 'yes' else 0,\n    axis=1)\ninsurance['bmi_smoker'] = insurance['bmi'] * insurance['smoker'].replace({'yes': 1, 'no': 0})\ninsurance.head()","798113c1":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler","fc671f8d":"dummies = pd.get_dummies(insurance, drop_first=True)","89b2d62c":"target_col_name = 'expenses'\ninput_cols_names = dummies.columns.drop([target_col_name, 'bmi_smoker',\n                                         'bmi', 'age','smoker_yes',\n                                        'region_northwest', 'region_southeast',\n                                        'sex_male', 'region_southwest'])\ntrain_x, test_x, train_y, test_y = train_test_split(dummies[input_cols_names],\n                                                   dummies[target_col_name],\n                                                   test_size=0.2,\n                                                   random_state=1)","ae319e51":"scaler = StandardScaler().fit(train_x)\ntrain_x_scaled = scaler.transform(train_x)\ntest_x_scaled = scaler.transform(test_x)\ndf_train_x_scaled = pd.DataFrame(train_x_scaled,\n                                 index=train_x.index,\n                                 columns=train_x.columns)\n\ndf_test_x_scaled = pd.DataFrame(test_x_scaled,\n                                index=test_x.index,\n                               columns=test_x.columns)","40c8afe7":"import statsmodels.api as sm\ntrain_x_with_constant = sm.add_constant(df_train_x_scaled)\ntest_x_with_constant = sm.add_constant(df_test_x_scaled)\n\nmodel = sm.OLS(train_y, train_x_with_constant).fit()\nmodel.summary()","956b019e":"insurance.head()","3926e833":"import seaborn as sns\n\nsns.pairplot(data=insurance, hue='smoker');","bf3571a8":"# 1. Identify if there are missing values; If \n#energy.isna().sum()","37a7e6ee":"url = 'https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00374\/energydata_complete.csv'\nenergy = pd.read_csv(url)\nenergy.head()","02f70c18":"# convert non-numeric to numeric\nenergy['date'] = pd.to_datetime(energy['date'], format='%Y-%m-%d %H:%M:%S')\nenergy['day'] = energy['date'].dt.day\nenergy['month'] = energy['date'].dt.strftime('%b')\nenergy['hour'] = energy['date'].dt.hour\ndummies = pd.get_dummies(energy.drop('date', axis=1), drop_first=True)\n\n# train & test split\ntarget_col_name = 'Appliances'\ninput_cols_names = dummies.columns.drop([target_col_name])\ntrain_x, test_x, train_y, test_y = train_test_split(dummies[input_cols_names],\n                                                   dummies[target_col_name],\n                                                   test_size=0.2,\n                                                   random_state=1)\nscaler = StandardScaler().fit(train_x)\ntrain_x_scaled = scaler.transform(train_x)\ntest_x_scaled = scaler.transform(test_x)\ndf_train_x_scaled = pd.DataFrame(train_x_scaled,\n                                 index=train_x.index,\n                                 columns=train_x.columns)\n\ndf_test_x_scaled = pd.DataFrame(test_x_scaled,\n                                index=test_x.index,\n                               columns=test_x.columns)\ntrain_x_with_constant = sm.add_constant(df_train_x_scaled)\ntest_x_with_constant = sm.add_constant(df_test_x_scaled)\n\nmodel = sm.OLS(train_y, train_x_with_constant).fit()\nmodel.summary()","908bc0ed":"import statsmodels\nstatsmodels.__version__","15f7b216":"from statsmodels.stats.outliers_influence import variance_inflation_factor","21861797":"#train_x.head()","cef46a3c":"results = []\nvif_data = train_x.drop(['bmi_smoker', 'bmi', 'age',\n                        'smoker_yes'], axis=1)\nfor i, column in enumerate(vif_data.columns):\n    vif = variance_inflation_factor(vif_data.values, i)\n    results.append((column, vif))\ndf_vif = pd.DataFrame(results, columns=['variable', 'vif'])\ndf_vif.sort_values('vif', ascending=False)","f0780dcf":"### Questions\n1. Identify if there are missing values; If so fill them\n2. Convert non-numeric to numeric\n3. Divide your data in train & test\n4. Standardize\n5. Fit a multiple linear regression model using all input predictors\n6. Identify Training -R2 \n7. Identify & remove insignificant input predictors","9e8eece4":"## In-class Exercises","21bb1f36":"### Interaction Effect"}}