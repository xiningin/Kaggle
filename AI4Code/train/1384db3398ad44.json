{"cell_type":{"d5d4ef54":"code","83a1dcc2":"code","ea4d90ef":"code","d7cc69ea":"code","95345aeb":"code","67492def":"code","9b4f6775":"code","c605dfc8":"code","e6e841fc":"code","c8939eae":"code","fda2cf96":"code","769765d2":"code","88305f45":"code","6a26001c":"code","6940f3c8":"code","a48e284f":"markdown","2bd84105":"markdown","65f234d1":"markdown","d5144615":"markdown","d5500c7e":"markdown","c733a1b6":"markdown","daf17378":"markdown","a0ce9a4e":"markdown","a04a6758":"markdown","a18dabad":"markdown","4b51e4d7":"markdown","4214a5a1":"markdown","96d3b115":"markdown","76fc3a62":"markdown","91b6f007":"markdown","044c136a":"markdown","1c1223b1":"markdown","9176ed12":"markdown","ca37c8e0":"markdown","e2351de1":"markdown","f7007756":"markdown","e2954e25":"markdown","b40bab59":"markdown"},"source":{"d5d4ef54":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pylab as plt\n\nimport os\nimport PIL\n\npd.options.mode.chained_assignment = None","83a1dcc2":"print('TensorFlow version: {}'.format(tf.__version__))\ndevice_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n    print('GPU device not found - On for CPU time!')\nelse:\n    print('Found GPU at {}'.format(device_name))","ea4d90ef":"#path = '..\/input\/petfinder-pawpularity-score\/train\/'\n#training_img = os.listdir(path) # list all training images names\n#print('There are {} images in the training directory'.format(len(training_img)))\n\n#img_sz = {'width': list(),\n#          'height': list()} # store image attributes for further analysis\n#width, height = 1000, 1000\n\n#for im in training_img:\n#    img = PIL.Image.open(path+im)\n#    w, h = img.size\n#    if w < width:\n#        width = w\n#    if h < height:\n#        height = h\n\n#IMG_WIDTH = width\n#IMG_HEIGHT = height\n#IMG_CHANNELS = 3\n\n#print('Min training image width: {} px'.format(IMG_WIDTH))\n#print('Min training image height: {} px'.format(IMG_HEIGHT))","d7cc69ea":"def read_and_decode(filename, reshape_dims):\n    # Read an image file to a tensor as a sequence of bytes\n    image = tf.io.read_file(filename)\n    # Convert the tensor to a 3D uint8 tensor\n    image = tf.image.decode_jpeg(image, channels=IMG_CHANNELS)\n    # Convert 3D uint8 tensor with values in [0, 1]\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to the desired size\n    return tf.image.resize(image, reshape_dims)\n\ndef show_image(filename):\n    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    plt.imshow(image.numpy());\n    plt.axis('off');\n    \ndef decode_csv(csv_row):\n    record_defaults = ['Id', 'Pawpularity']\n    filename, pawpularity = tf.io.decode_csv(csv_row, record_defaults)\n    pawpularity = tf.convert_to_tensor(np.float(pawpularity), dtype=tf.float32)\n    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    return image, pawpularity","95345aeb":"from sklearn.model_selection import StratifiedShuffleSplit\n\ndata_path = '..\/input\/petfinder-pawpularity-score\/'\ndata = pd.read_csv(data_path+'train.csv')\n\n# Use stratified sampling\nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\nfor train_index, test_index in sssplit.split(data, data['Pawpularity']):\n    training_set = data.iloc[train_index]\n    eval_set = data.iloc[test_index]\n    \n# Visually check distribution of pawpularity score in training and test sets\ntraining_set['Pawpularity'].hist(label='Training set')\neval_set['Pawpularity'].hist(label='Eval set')\nplt.title('Pawpularity score distribution in training and test set')\nplt.xlabel('Pawpularity score')\nplt.ylabel('Count')\nplt.legend(loc='upper right')\nplt.show()\n\n# Export training and test sets as .csv files\ntraining_set['Id'] = training_set['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/train\/'+x+'.jpg')\ntraining_set[['Id', 'Pawpularity']].to_csv('\/kaggle\/working\/training_set.csv', header=False, index=False)\neval_set['Id'] = eval_set['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/train\/'+x+'.jpg')\neval_set[['Id', 'Pawpularity']].to_csv('\/kaggle\/working\/eval_set.csv', header=False, index=False)","67492def":"IMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3\n\npath = '..\/input\/petfinder-pawpularity-score\/train\/'\ntraining_img = os.listdir(path)\nrand_idx = np.random.randint(0, len(training_img)-1)\nrand_img = training_img[rand_idx]\n\nshow_image(path+rand_img)","9b4f6775":"BATCH_SIZE = 256\n\ntrain_dataset = tf.data.TextLineDataset(\n    '\/kaggle\/working\/training_set.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\neval_dataset = tf.data.TextLineDataset(\n    '\/kaggle\/working\/eval_set.csv'\n).map(decode_csv).batch(BATCH_SIZE)","c605dfc8":"# Build model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1, activation=None)\n])","e6e841fc":"model.summary()","c8939eae":"tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)","fda2cf96":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=[tf.keras.metrics.RootMeanSquaredError()])","769765d2":"%%time\n\nhistory = model.fit(train_dataset, validation_data=eval_dataset, epochs=10, batch_size=BATCH_SIZE)","88305f45":"def training_plot(metrics, history):\n    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n    for idx, metric in enumerate(metrics):\n        ax[idx].plot(history.history[metric], ls='dashed')\n        ax[idx].set_xlabel('Epochs')\n        ax[idx].set_ylabel(metric)\n        ax[idx].plot(history.history['val_'+metric]);\n        ax[idx].legend(['train_'+metric, 'val_'+metric])","6a26001c":"training_plot(['loss', 'root_mean_squared_error'], history)","6940f3c8":"sample_submission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\nsample_submission['Id'] = sample_submission['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/test\/'+x+'.jpg')\nsample_submission.to_csv('\/kaggle\/working\/sample_submission.csv', index=False, header=False)\nsample_submission = tf.data.TextLineDataset(\n    '.\/sample_submission.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\n# Make predictions with our model\nsample_prediction = model.predict(sample_submission)\n\n# Format predictions to output for submission\nsubmission_output = pd.concat(\n    [pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv').drop('Pawpularity', axis=1),\n    pd.DataFrame(sample_prediction)],\n    axis=1\n)\nsubmission_output.columns = [['Id', 'Pawpularity']]\n\n# Output submission file to csv\nsubmission_output.to_csv('submission.csv', index=False)","a48e284f":"Well our model has 258,513 trainable parameters. We can expect a quite long training !","2bd84105":"### Compile the CNN","65f234d1":"### Build the CNN","d5144615":"This first attempt wasn't very good. The final RMSE oscillates around 20, which, as stated before, is expressed in the same unit as the target variable, i.e. Pawpularity. That's quite a large error, we'll see later if we can improve it.\n\nA note on these plots: the first two epochs went pretty well, with a validation error lower than the training error. But from the 3rd epoch onwards, we can observe a phenomenon called overfitting: the validation error is larger than the training error. This characterises a situation where the model has learned so well the training data that it has forgotten what its real task was: generalising!","d5500c7e":"Input data are manipulated as tensors, the basic data structures of TensorFlow. Images generally have 3 dimensions: height, width, and number of colour channels. An image dataset is most of the time represented as a rank-4 tensor (or 4D tensor) of shape `(samples, height, width, channels)`. For example, a batch of 32 colour images of size 150 x 150 pixels can be stored in the rank-4 tensor `(32, 150, 150, 3)`.\n\nOur data consists of coloured pets images of different sizes. A convolutional neural network will accept only tensors of fixed size though. Conventionally, we resize the images to the size of the smallest image. We'll do a quick analysis of the images attributes we've got here then.","c733a1b6":"Deep learning models are still machine learning models. Thus we have to build rigourously and precisely training, evaluation and test sets in order to get things done. One simple thing that can be addressed is the conservation of data distribution between the sets. This can ben accomplished by selecting an appropriate way of sampling the data we've got. Instead of doing a random sampling, we're doing a stradified sampling, ensuring the variable to predict (`Pawpularity`) is equally distributed in all the sets.","daf17378":"### Import training and evaluation datasets","a0ce9a4e":"## ETL - Load data and prepare it for feeding a convolutional neural network","a04a6758":"#TODO rewrite model description\n\nOur first convolutional neural network will stack:\n* a first convolution layer `tf.keras.layers.Conv2D` with 64 filters of size 3 * 3 and a `ReLU` activation function\n* a first max pooling layer `tf.keras.layers.MaxPooling2D` with filters of size 2 * 2\n* a second convolution layer `tf.keras.layers.Conv2D` with 32 filters of size 3 * 3 and a `ReLU` activation function\n* a second max pooling layer `tf.keras.layers.MaxPooling2D` with filters of size 2 * 2\n* a third convolution layer `tf.keras.layers.Conv2D` with filters of size 3 * 3 and a `ReLU` activation function\n* an input layer for the regressor `tf.keras.layers.Flatten` \n* a dense layer `tf.keras.Dense` with 32 units (number of filters of the last convolution layer) and a `ReLU` activation function\n* an output dense layer `tf.keras.Dense` with 1 unit (since we're doing regression we're outputing a single value) and no activation function","a18dabad":"### Convolutional Neural Networks (CNN)","4b51e4d7":"## Convolutional Neural Network using Keras","4214a5a1":"Compilation makes the newtork ready for training. We'll specify 3 necessary things, that will guide the training and the behaviour of the model itself, as well as be the conceptual anchor points to which we can stick when thinking about optimising models and improving performance: \n* A **loss function** indicates how the model is behaving while dealing with training data. It's a direct measure of the distance between what the model is producing, and what it should be. Beware of aiming at getting a perfect behaviour of the model on the training data! You'd fall into the overfitting trap: you're model would perfectly learn the training data by heart, but would be unable to generalise predictions to new and previously unseen data\n* An **optimiser** consists of the actual math behind which the model updates its parameters according to the loss function results, to try to get the best training performance. Generally speaking, optimisation is based on gradient methods, that compile derivatives of the loss with regards to the parameters of the models, and different variants exist. We'll select the Adam optimiser, a well-known and well-suited optimiser for computer vision problems.\n* A **performance metric** gives us, the computer scientists, a real figure of how things are going once the model has finished its work. Selecting a performance metric mostly depends on the problem at hand. Here we're performing regression, we'll then look at the actual distance between the predictions made by the model and the truth (roughly). For the sake of interpretability, we'll select Root Mean Squared Error (RMSE) as the performance metric, which is expressed in the same units as the variable we want to predict","96d3b115":"Convolutional neural networks are pretty useful when it comes to image-related tasks (image recognition, image classification, image regression, video analysis, etc.). They're named *convolutional* because at least one of their building layers use convolution instead of general matrix multiplication.\n\nA CNN is fed with data in the form of a tensor of shape `(samples, height, width, channels)`. Data generally goes through 2 different kinds of layers within a CNN:\n\n* `Conv2D`: convolution layers learn local patterns by sliding small 2D windows over the image inputs, instead of learning general patterns from the whole input, as would dense layers do\n* `MaxPooling2D`: max pooling is the operation of extracting windows from the input feature maps and outputting the max value of each channel. It is quite similar to convolution, and allows to extract information from parts of the input instead of using it as a whole\n\n","76fc3a62":"# Convolutional Neural Networks for Image Regression","91b6f007":"### Train the CNN and display results","044c136a":"## Compute predictions and build submission process","1c1223b1":"## Enable GPU","9176ed12":"### Build the training dataset","ca37c8e0":"When training models, the initial dataset is not used as a whole. Instead, models use **mini-batches** of a fixed quantity of samples (defined by `BATCH_SIZE`) for computing loss and optimising weights. Chaining this elementary training steps again and again makes the model eventually see the whole training data, which ends what is called an **epoch**. Here our model will start iterating over training data in mini-batches of 128 samples, 5 times over.","e2351de1":"Now we've got the size of our smallest image. Let's display some images at random and define some data handlers.","f7007756":"This third notebook aims at getting a step further by using tools more dedicated to computer vision problems: namely convolutional neural networks.\n\n**Objectives**\n\n1. Import image data\n2. Prepare data for feeding a convolutional neural network\n3. Build, train and evaluate a convolutional neural network\n4. Submit results for ranking\n\n**Note**: Part of the code and developments of ideas in this notebook has been strongly inspired from Chollet's *Deep Learning with Python* and Lakshmanan, G\u00f6rner and Gillard *Practical Machine Learning for Computer Vision: End-to-End Machine Learning for Images*. These are two must read if you're into machine learning, deep learning, and the beauty and simplicity of engineering science.","e2954e25":"The network is built, let's look at some of its characteristics and plot it. Having a visual understanding might help sometimes","b40bab59":"### Handling image data for convolutional neural networks"}}