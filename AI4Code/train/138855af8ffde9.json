{"cell_type":{"dee8428c":"code","049c535b":"code","8b8afdd5":"code","46bd82b4":"code","3f992aa7":"code","9aadb986":"code","b4290e60":"code","7c5fe3c8":"code","18c631e5":"code","5e176cd4":"code","bb9a3c1d":"code","b2b7e197":"code","0e03e36a":"code","0a36862d":"code","0e56ff7a":"code","a704571a":"code","bc4966ac":"code","493169fa":"code","274c92ca":"code","06d57f19":"code","c3006498":"code","789b41d9":"code","641a99c5":"code","740ffeb6":"code","fc7f62ee":"code","4e4e0129":"code","91d57af5":"code","e63a9d26":"code","8be0ed3d":"code","78e19e5b":"code","e8b5cecc":"code","91314ab8":"code","27d789f9":"code","83faab39":"code","acc42f5d":"markdown","23f57b63":"markdown","cfbad098":"markdown","8380bb98":"markdown","b46ce7e8":"markdown","c4a61fe4":"markdown"},"source":{"dee8428c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom PIL import Image\n\n# Test\nimport glob\nfrom matplotlib.pyplot import imshow\n\nimport os\nimport io\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","049c535b":"## Global Parameters\ntfrecord_name = \"uav_images\"\ntrain_img_path = \"\/kaggle\/input\/uavid-v1\/uavid_train\/seq1\/Images\/\"\ntrain_label_path= \"\/kaggle\/input\/uavid-v1\/uavid_train\/seq1\/Labels\/\"","8b8afdd5":"\"\"\"train_images = glob.glob(train_img_path + '*.png')\ntrain_labels = glob.glob(train_label_path + '*.png')\n# print(images)\nfor image in train_images[:1]:\n    img = Image.open(image)\n    imshow(np.asarray(img))\"\"\"","46bd82b4":"\"\"\"img = Image.open(train_images[5])\nimshow(np.asarray(img))\"\"\"","3f992aa7":"\"\"\"img_labelled = Image.open(train_labels[5])\nimshow(np.asarray(img_labelled))\"\"\"","9aadb986":"def resize_all_train_images_path(train_img_path):\n    \"\"\"\n    Direkt olarak path'den al\u0131p boyutlar\u0131n\u0131 de\u011fi\u015ftiriyoruz.\n    \"\"\"\n    train_images = glob.glob(train_img_path + '*.png')\n    for index in range(len(train_images)):\n        train_images[index] = tf.keras.preprocessing.image.array_to_img(tf.image.resize(np.asarray(Image.open(train_images[index])), [256,256]))\n    return train_images","b4290e60":"def resize_all_train_images_list(train_images):\n    \"\"\"\n    Direkt olarak listeden al\u0131p boyutlar\u0131n\u0131 de\u011fi\u015ftiriyoruz.\n        Bu fonksiyon tfrecord data okunduktan sonra \u00e7a\u011f\u0131rabilinir.\n    \"\"\"\n    \n    for index in range(len(train_images)):\n        train_images[index] = tf.keras.preprocessing.image.array_to_img(tf.image.resize(np.asarray(train_images[index], [256,256])))\n    # test edilecek -> return train_images","7c5fe3c8":"train_images = resize_all_train_images_path(train_img_path=train_img_path)\nlabel_images = resize_all_train_images_path(train_img_path=train_label_path)","18c631e5":"# Test 200 file is 256x256\ntotal = 0\nfor index in range(len(train_images)):\n    if train_images[index].height == 256 and train_images[0].width == 256:\n        total += 1\n\nif total==200:\n    print(\"T\u00fcm foto\u011fraflar resized edildi..\")","5e176cd4":"np.asarray(train_images[1]).shape","bb9a3c1d":"train_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.transpose(np.asarray(train_images[0])))\nlabel_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.transpose(np.asarray(label_images[0])))","b2b7e197":"label_images[0]","0e03e36a":"train_images[0]","0a36862d":"train_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.random_brightness(np.asarray(train_images[0]), max_delta=0.2))\nlabel_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.random_brightness(np.asarray(label_images[0]), max_delta=0.2)) # Label a gerek var m\u0131?","0e56ff7a":"train_images[0]","a704571a":"label_images[0]","bc4966ac":"train_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.resize_with_crop_or_pad(np.asarray(train_images[0]), target_height=))\nlabel_images[0] = tf.keras.preprocessing.image.array_to_img(tf.image.resize_with_crop_or_pad(np.asarray(label_images[0]), target_height=))","493169fa":"def flat_all_train_labels_path(train_label_path):\n    \"\"\"\n    Direkt olarak path'den al\u0131p flatten uyguluyoruz..\n    \"\"\"    \n    \n    train_labels = resize_all_train_images_path(train_label_path)\n    \n    for index in range(len(train_labels)):\n        train_labels[index] = tf.keras.preprocessing.image.array_to_img(tf.image.resize(np.asarray(train_labels[index]), [ 1, 196608]))\n    return train_labels","274c92ca":"def flat_all_train_labels_list(train_label_path):\n    \"\"\"\n    Direkt olarak list'den al\u0131p flatten uyguluyoruz..\n    \"\"\"    \n    \n    train_labels = resize_all_train_images_list(train_label_path)\n    \n    for index in range(len(train_labels)):\n        train_labels[index] = tf.keras.preprocessing.image.array_to_img(tf.image.resize(np.asarray(train_labels[index]), [ 1, 196608]))\n    return train_labels","06d57f19":"train_labels = flat_all_train_labels_path(train_label_path)","c3006498":"print(train_labels[5])","789b41d9":"#buf = io.BytesIO()\n#train_images[5].save(buf, format='JPEG')\n","641a99c5":"#byte_im = buf.getvalue()","740ffeb6":"#print(byte_im)","fc7f62ee":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef write_record(train_images, train_labels, tfrecord_name):\n    features = []\n    # Read image raw data, which will be embedded in the record file later.\n    for index in range(len(train_images)):\n        buf_img = io.BytesIO()\n        buf_label = io.BytesIO()\n        \n        train_images[index].save(buf_img, format='PNG')\n        \n\n        \n        # temp = np.array(train_images[index])\n        \n        image_string = buf_img.getvalue()\n\n\n        train_labels[index].save(buf_label, format='PNG')\n        \n        # test\n        \n        # temp = np.array(train_labels[index])\n        \n        label = buf_label.getvalue()\n\n        # For each sample there are two features: image raw data, and label. Wrap them in a single dict.\n        feature = {\n            'label': _bytes_feature(label),\n            'image_raw': _bytes_feature(image_string),\n        }\n        \n        features.append(feature)\n    \n    # Create a `example` from the feature dict.\n    tf_examples = []\n    for i in range(len(train_images)):\n        tf_example = tf.train.Example(features=tf.train.Features(feature=features[i]))\n        tf_examples.append(tf_example)\n    # tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n  \n    # Write the serialized example to a record file.\n    with tf.io.TFRecordWriter(tfrecord_name + \".tfrecord\") as writer:\n        for index in range(len(train_images)):\n            writer.write(tf_examples[index].SerializeToString())\n","4e4e0129":"write_record(train_images, label_images, tfrecord_name)","91d57af5":"def read_record(tfrecord_name):\n    # Use dataset API to import date directly from TFRecord file.\n    raw_image_dataset = tf.data.TFRecordDataset(tfrecord_name + \".tfrecord\")\n\n    # Create a dictionary describing the features. The key of the dict should be the same with the key in writing function.\n    image_feature_description = {\n        'label': tf.io.FixedLenFeature([], tf.string),\n        'image_raw': tf.io.FixedLenFeature([], tf.string),\n    }\n    \n    # Define the parse function to extract a single example as a dict.\n    def _parse_image_function(example_proto):\n        # Parse the input tf.Example proto using the dictionary above.\n        features = tf.io.parse_single_example(example_proto, image_feature_description)\n        image = tf.io.decode_image(features['image_raw'], dtype=tf.uint8)\n        print(\"TYPE: {}\\tShape: {}\".format(type(image), image.shape))\n        #image.set_shape([3 * 256 * 256])\n        image = tf.reshape(image, [256, 256, 3])\n        \n        label = tf.io.decode_image(features['label'], dtype=tf.uint8)\n        print(\"TYPE: {}\\tShape: {}\".format(type(label), label.shape))\n        #label.set_shape([ 1, 196608])\n        label = tf.reshape(label,[ 1, 196608, 1]) # Buras\u0131 de\u011fi\u015ftirilecek.\n\n        return image,label\n   \n    dataset = raw_image_dataset.map(_parse_image_function)\n    dataset = dataset.cache()\n    dataset = dataset.batch(8)\n        \n    return dataset","e63a9d26":"%xmode Plain","8be0ed3d":"dataset = read_record(tfrecord_name)","78e19e5b":"type(dataset)","e8b5cecc":"dataset","91314ab8":"for x,y in dataset.take(1):\n    print(type(x), type(y))\n    x = x.numpy()\n    y = y.numpy()\n    print(type(x), type(y))\n    print(len(x))\n    print(x[0].shape)\n    print(y[0].shape)\n    img_neww = tf.keras.preprocessing.image.array_to_img(x[3])\n    label_neww = tf.keras.preprocessing.image.array_to_img(y[0])    ","27d789f9":"img_neww","83faab39":"label_neww","acc42f5d":"*write_tfrecords(train_images, label_images, name_of_tfrecords)*","23f57b63":"# Resizing","cfbad098":"* [Data Resizing](#Resizing)\n* [Label Flatten](#Label_Flattening)\n* [Data Augmentation](#Augmentation)","8380bb98":"## Augmentation\n[Reference](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/image#:~:text=TensorFlow%20provides%20functions%20to%20adjust,training%20set%20and%20reduce%20overfitting.)","b46ce7e8":"# Label_Flattening","c4a61fe4":"# T\u00fcm datalar\u0131 tfRecord yap\u0131yoruz"}}