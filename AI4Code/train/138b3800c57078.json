{"cell_type":{"cd71da8d":"code","2c8aed37":"code","958f5fff":"code","173cf1b0":"code","5c86c904":"code","be0d2758":"code","427d73d6":"code","45bf4eb3":"code","e851ea9a":"code","a706e0f4":"code","f151f921":"code","79edfe4a":"code","a367fb13":"code","e84b221d":"code","9009b75b":"code","bd301472":"code","14fcb89e":"code","8e08cbef":"code","8bf2f181":"code","e653fc4b":"code","9d66f37e":"code","2075f9a3":"code","5a28d262":"code","7495802b":"code","c69f09db":"code","296b4112":"code","c89a9b94":"code","819bfcc5":"code","de37cca5":"code","f8b421f3":"code","187fbff2":"code","329180eb":"code","d29ef4c1":"code","636b54b4":"code","a89528d7":"code","d8d99d06":"code","b6a18780":"code","0bb392a5":"code","60ce5435":"code","081720fe":"code","043e04d6":"code","6ceca7aa":"code","5e2e2b12":"code","58a18c5c":"code","68597997":"code","9fdb4a6f":"code","89072943":"code","77b2bf13":"code","9166ef37":"code","94fc5ab0":"code","26d319f0":"code","4020e151":"code","e51f8cd6":"code","becd7be5":"code","ce80613c":"code","3e08e3ba":"code","f28f6241":"code","151c6e72":"code","48847b1f":"code","581ff3ce":"code","44067610":"code","764ff1a8":"markdown","70bac294":"markdown","0891dd4f":"markdown","05f3eec4":"markdown","5eb5a557":"markdown","dfd974a1":"markdown","fb0d6293":"markdown","577ed169":"markdown","a9690acd":"markdown","c0eda9e7":"markdown","3ae6a79c":"markdown","31d86420":"markdown","124a15c3":"markdown","367c428b":"markdown","a9330649":"markdown","4b7b0a62":"markdown","7c5d01e8":"markdown","e7dd0c23":"markdown","c3de1193":"markdown","483d126c":"markdown","06083630":"markdown","0a378a12":"markdown","1e642f15":"markdown","9341d89f":"markdown","4b98feca":"markdown","2fb38e3e":"markdown","9b704f48":"markdown","2f4cb160":"markdown","01ae3db8":"markdown","c25045e7":"markdown","72fb89a9":"markdown"},"source":{"cd71da8d":"# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","2c8aed37":"from fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\n\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *","958f5fff":"PATH = \"..\/input\/diabetic-retinopathy-detection\/\"\nTMP_PATH = \"\/tmp\/tmp\"\nMODEL_PATH = \"\/tmp\/model\/\"\nsz=224  # default\n\narch=resnet34\n# sz = 64  # Because medical images.\n# Not sure anymore about sz=64\nbs = 4  # Because we have a very limited sample\n","173cf1b0":"print('Make sure cuda is installed:', torch.cuda.is_available())\nprint('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","5c86c904":"base_image_dir = os.path.join('..', 'input', 'diabetic-retinopathy-detection')\nretina_df = pd.read_csv(os.path.join(base_image_dir, 'trainLabels.csv'))\nretina_df['PatientId'] = retina_df['image'].map(lambda x: x.split('_')[0])\nretina_df['path'] = retina_df['image'].map(lambda x: os.path.join(base_image_dir,\n                                                         '{}.jpeg'.format(x)))\nretina_df['exists'] = retina_df['path'].map(os.path.exists)\nprint(retina_df['exists'].sum(), 'images found of', retina_df.shape[0], 'total')\nretina_df['eye'] = retina_df['image'].map(lambda x: 1 if x.split('_')[-1]=='left' else 0)\n# from keras.utils.np_utils import to_categorical\n# retina_df['level_cat'] = retina_df['level'].map(lambda x: to_categorical(x, 1+retina_df['level'].max()))\n\nretina_df.dropna(inplace = True)\nretina_df = retina_df[retina_df['exists']]\nretina_df.sample(3)","be0d2758":"retina_df[['level', 'eye']].hist(figsize = (10, 5))","427d73d6":"retina_df = retina_df[['PatientId', 'level', 'eye', 'path']].drop_duplicates()  # Should not drop any rows in this case\n# V1:\n# retina_df[['level', 'PatientId']].groupby(['level']).agg(['count'])\n\n# V2:\nretina_df.pivot_table(index='level', aggfunc=len).sort_values('PatientId', ascending=False)","45bf4eb3":"# retina_df = retina_df.drop(retina_df[[(x in [1, 3, 4]) for x in retina_df.level]].index)","e851ea9a":"def balance_data(class_size):\n    train_df = retina_df.groupby(['level']).apply(lambda x: x.sample(class_size, replace = True)).reset_index(drop = True)\n    print('New Data Size:', train_df.shape[0], 'Old Size:', retina_df.shape[0])\n    train_df[['level', 'eye']].hist(figsize = (10, 5))\n    return train_df\n\ntrain_df = balance_data(148)","a706e0f4":"fnames = train_df['path'].values\nlabels = train_df['level'].values","f151f921":"test_label = train_df.level.unique()[-1]\n\n# To shuffle rows:\n# train_df = train_df.sample(frac=1).reset_index(drop=True)\n\npatient_example = train_df.loc[train_df['level'] == test_label].iloc[0]\npatient_example_index = train_df.index[train_df['PatientId'] == patient_example['PatientId']][-1]\nprint(patient_example)\nassert labels[patient_example_index] == test_label, f\"Check that patient with id {patient_example_index}'s label is equal to {test_label}\"\n\nimg = plt.imread(f'{fnames[patient_example_index]}')\nplt.imshow(img);","79edfe4a":"img.shape","a367fb13":"data = ImageClassifierData.from_names_and_array(\n    path='.\/', \n    fnames=fnames, \n    y=labels, \n    classes=sorted(retina_df.level.unique()), \n    test_name=None, \n    tfms=tfms_from_model(arch, sz)\n)","e84b221d":"img_name = data.trn_ds.fnames[0]; img_name","9009b75b":"img = PIL.Image.open(img_name); img","bd301472":"img.size","14fcb89e":"size_d = {k: PIL.Image.open(k).size for k in data.trn_ds.fnames}\nrow_sz, col_sz = list(zip(*size_d.values()))\nrow_sz = np.array(row_sz); col_sz = np.array(col_sz)","8e08cbef":"plt.hist(row_sz)","8bf2f181":"plt.hist(col_sz[col_sz < 2000])","e653fc4b":"def get_data(sz, bs=4): # sz: image size, bs: batch size\n#     tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    tfms = tfms_from_model(arch, sz)\n    data = ImageClassifierData.from_names_and_array(\n        path='.\/', \n        fnames=fnames, \n        y=labels, \n        classes=sorted(retina_df.level.unique()), \n        test_name=None,\n        tfms=tfms,\n        bs=bs\n    )\n    \n    if len(data.trn_ds) % bs == 1:\n        data = ImageClassifierData.from_names_and_array(path='.\/', classes=sorted(retina_df.level.unique()), test_name=None, tfms=tfms, bs=bs,\n            fnames=fnames[:-1], \n            y=labels[:-1]\n        )\n    assert len(data.trn_ds) % bs != 1, 'This condition makes sure that we never have a batch size of 1, which could cause issues with lr_find for instance.'\n    return data","9d66f37e":"data = get_data(sz=sz, bs=4)","2075f9a3":"from sklearn.metrics import cohen_kappa_score\nfrom fastai.metrics import accuracy, recall, precision, fbeta\n\nquadratic_kappa = lambda y_hat, y: cohen_kappa_score(y_hat, y, weights='quadratic')\ndef f2(log_preds, targs): \n    return fbeta(log_preds, targs, 2)","5a28d262":"print(f'Sample classes: {retina_df.level.unique()}')\n\nlearn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)","7495802b":"learn.fit(1e-2, 3, metrics=[accuracy, recall, precision, f2])\n# learn.fit(1e-2, 3, metrics=[quadratic_kappa])","c69f09db":"def get_80percent_accuracy_with_sample_bias():\n    fnames2 = retina_df['path'].as_matrix()[:-1]\n    labels2 = retina_df['level'].as_matrix()[:-1]\n\n    data = ImageClassifierData.from_names_and_array(\n        path='.\/',\n        fnames=fnames2,\n        y=labels2,\n        classes=sorted(retina_df.level.unique()),\n        test_name=None,\n        tfms=tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    )\n\n    print(retina_df.pivot_table(index='level', aggfunc=len).sort_values('PatientId', ascending=False))\n\n    return ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)\n\nlearn = get_80percent_accuracy_with_sample_bias()","296b4112":"learn.fit(0.01, 2, metrics=[accuracy, recall, precision, f2])","c89a9b94":"# This is the label for a val data\ndata.val_y","819bfcc5":"# from here we know that 'cats' is label 0 and 'dogs' is label 1.\ndata.classes","de37cca5":"# this gives prediction for validation set. Predictions are in log scale\nlog_preds = learn.predict()\nlog_preds.shape","f8b421f3":"log_preds[:10]","187fbff2":"preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\nprobs = np.exp(log_preds[:,1])        # pr(dog)","329180eb":"def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\ndef rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)","d29ef4c1":"def plots(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)\/\/rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])","636b54b4":"def load_img_id(ds, idx): return np.array(PIL.Image.open(ds.fnames[idx]))\n\ndef plot_val_with_title(idxs, title):\n    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n    title_probs = [probs[x] for x in idxs]\n    print(title)\n    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))","a89528d7":"# 1. A few correct labels at random\nplot_val_with_title(rand_by_correct(True), \"Correctly classified\")","d8d99d06":"# 2. A few incorrect labels at random\nplot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")","b6a18780":"def most_by_mask(mask, mult):\n    idxs = np.where(mask)[0]\n    return idxs[np.argsort(mult * probs[idxs])[:4]]\n\ndef most_by_correct(y, is_correct): \n    mult = -1 if (y==1)==is_correct else 1\n    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)","0bb392a5":"plot_val_with_title(most_by_correct(0, True), \"Most correct 0\")","60ce5435":"plot_val_with_title(most_by_correct(2, True), \"Most correct 2\")","081720fe":"plot_val_with_title(most_by_correct(0, False), \"Most incorrect 0\")","043e04d6":"plot_val_with_title(most_by_correct(2, False), \"Most incorrect 2\")","6ceca7aa":"most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\nplot_val_with_title(most_uncertain, \"Most uncertain predictions\")","5e2e2b12":"data = get_data(sz=224, bs=4)","58a18c5c":"learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)","68597997":"lrf=learn.lr_find(start_lr=1e-7, end_lr=1e-1)","9fdb4a6f":"learn.sched.plot()","89072943":"lr = 3e-3","77b2bf13":"learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)","9166ef37":"learn.fit(lr, 3, cycle_len=1, cycle_mult=2)","94fc5ab0":"lrs = np.array([lr\/9,lr\/3,lr])","26d319f0":"learn.unfreeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","4020e151":"learn.sched.plot_lr()","e51f8cd6":"learn.save('224')","becd7be5":"learn.load('224')","ce80613c":"log_preds,y = learn.TTA()\nprobs = np.mean(np.exp(log_preds),0)","3e08e3ba":"accuracy_np(probs, y)","f28f6241":"preds = np.argmax(probs, axis=1)\nprobs = probs[:,1]","151c6e72":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y, preds)\ncm","48847b1f":"plot_confusion_matrix(cm, data.classes)","581ff3ce":"plot_val_with_title(most_by_correct(0, False), \"Most incorrect 0\")","44067610":"plot_val_with_title(most_by_correct(1, False), \"Most incorrect 1\")","764ff1a8":"## Analyzing results","70bac294":"### Looking at pictures again","0891dd4f":"The *learning rate* determines how quickly or how slowly you want to update the *weights* (or *parameters*). Learning rate is one of the most difficult parameters to set, because it significantly affects model performance.\n\nThe method `learn.lr_find()` helps you find an optimal learning rate. It uses the technique developed in the 2015 paper [Cyclical Learning Rates for Training Neural Networks](http:\/\/arxiv.org\/abs\/1506.01186), where we simply keep increasing the learning rate from a very small value, until the loss stops decreasing. We can plot the learning rate across batches to see what this looks like.\n\nWe first create a new learner, since we want to know how to set the learning rate for a new (untrained) model.","05f3eec4":"We can see the plot of loss versus learning rate to see where our loss stops decreasing:","5eb5a557":"# Optional: only keep images of type 0 and 2 (2 being the second most present class in this sample)","dfd974a1":"The loss is still clearly improving at lr=1e-2 (0.01), so that's what we use. Note that the optimal learning rate can change as we train the model, so you may want to re-run this function from time to time.","fb0d6293":"## Choosing a learning rate","577ed169":"## Improving our model","a9690acd":"# Examine the distribution of eye and severity","c0eda9e7":"As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n1. A few correct labels at random\n2. A few incorrect labels at random\n3. The most correct labels of each class (i.e. those with highest probability that are correct)\n4. The most incorrect labels of each class (i.e. those with highest probability that are incorrect)\n5. The most uncertain labels (i.e. those with probability closest to 0.5).","3ae6a79c":"We can't really balance the size of our dataset by down-sampling because almost all images are very large, because of this we are going to resize our images instead.","31d86420":"```python\nlearn = ConvLearner.pretrained(resnet34, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)\n```\n*Parameters*  are learned by fitting a model to the data. *Hyperparameters* are another kind of parameter, that cannot be directly learned from the regular training process. These parameters express \u201chigher-level\u201d properties of the model such as its complexity or how fast it should learn. Two examples of hyperparameters are the *learning rate* and the *number of epochs*.\n\nDuring iterative training of a neural network, a *batch* or *mini-batch* is a subset of training samples used in one iteration of Stochastic Gradient Descent (SGD). An *epoch* is a single pass through the entire training set which consists of multiple iterations of SGD.\n\nWe can now *fit* the model; that is, use *gradient descent* to find the best parameters for the fully connected layer we added. We need to pass two hyperameters: the *learning rate* (generally 1e-2 or 1e-3 is a good starting point, we'll look more at this next) and the *number of epochs* (you can pass in a higher number and just stop training when you see it's no longer improving, then re-run it with the number of epochs you found works well.)","124a15c3":"What is that `cycle_len` parameter? What we've done here is used a technique called *stochastic gradient descent with restarts (SGDR)*, a variant of *learning rate annealing*, which gradually decreases the learning rate as training progresses. This is helpful because as we get closer to the optimal weights, we want to take smaller steps.","367c428b":"1. precompute=True\n1. Use `lr_find()` to find highest learning rate where loss is still clearly improving\n1. Train last layer from precomputed activations for 1-2 epochs\n1. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n1. Unfreeze all layers\n1. Set earlier layers to 3x-10x lower learning rate than next higher layer\n1. Use `lr_find()` again\n1. Train full network with cycle_mult=2 until over-fitting","a9330649":"A common way to analyze the result of a classification model is to use a [confusion matrix](http:\/\/www.dataschool.io\/simple-guide-to-confusion-matrix-terminology\/). Scikit-learn has a convenient function we can use for this purpose:","4b7b0a62":"# Check number of images in each classes","7c5d01e8":"Since we've got a pretty good model at this point, we might want to save it so we can load it again later without training it from scratch.","e7dd0c23":"There is something else we can do with data augmentation: use it at *inference* time (also known as *test* time). Not surprisingly, this is known as *test time augmentation*, or just *TTA*.\n\nTTA simply makes predictions not just on the images in your validation set, but also makes predictions on a number of randomly augmented versions of them too (by default, it uses the original image along with 4 randomly augmented versions). It then takes the average prediction from these images, and uses that. To use TTA on the validation set, we can use the learner's `TTA()` method.","c3de1193":"## Exploring our dataset images size","483d126c":"`ConvLearner.pretrained` builds *learner* that contains a pre-trained model. The last layer of the model needs to be replaced with the layer of the right dimensions. The pretained model was trained for 1000 classes therfore the final layer predicts a vector of 1000 probabilities. The model for cats and dogs needs to output a two dimensional vector. The diagram below shows in an example how this was done in one of the earliest successful CNNs. The layer \"FC8\" here would get replaced with a new layer with 2 outputs.\n\n<img src=\"https:\/\/image.slidesharecdn.com\/practicaldeeplearning-160329181459\/95\/practical-deep-learning-16-638.jpg\" width=\"500\">\n[original image](https:\/\/image.slidesharecdn.com\/practicaldeeplearning-160329181459\/95\/practical-deep-learning-16-638.jpg)","06083630":"By default when we create a learner, it sets all but the last layer to *frozen*. That means that it's still only updating the weights in the last layer when we call `fit`.","0a378a12":"## Classifying diabetic retinopathy","1e642f15":"# Making sure fnames and labels are in order","9341d89f":"We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories).","4b98feca":"## First look at DR pictures","2fb38e3e":"Our validation loss isn't improving much, so there's probably no point further training the last layer on its own.","9b704f48":"## Review: easy steps to train a world-class image classifier","2f4cb160":"### Confusion matrix ","01ae3db8":"# Balance the distribution based on the smallest set","c25045e7":"## Analyzing results: looking at pictures","72fb89a9":"I generally see about a 10-20% reduction in error on this dataset when using TTA at this point, which is an amazing result for such a quick and easy technique!"}}