{"cell_type":{"f8d31f01":"code","c650eea9":"code","28d504d9":"code","55b84d3c":"code","0ddda402":"code","4ad9232d":"code","28e63fbe":"code","6a9eb611":"code","7fc8f48d":"code","66cd0a01":"code","145fc27f":"code","632cd53b":"code","c2719dca":"code","aaa90643":"code","c66c56b3":"code","6b02f70a":"code","cb961816":"code","a89822d8":"code","3373849c":"code","a940b128":"code","55886f61":"code","e47e13d9":"code","49ff94fc":"code","77cd0dd2":"code","d686046c":"code","bd270fb7":"code","c2f3ed11":"code","584c4284":"markdown","acad4620":"markdown","9619aa88":"markdown","fd5109e3":"markdown","b322aedb":"markdown","9b379591":"markdown","56150106":"markdown","30c9bf0e":"markdown","ebc537b1":"markdown","a88dd72d":"markdown","b182ca5f":"markdown","b43b0c22":"markdown","2f864c6b":"markdown","95fae6c1":"markdown","92e5080b":"markdown","2deac7eb":"markdown","349d677e":"markdown","c669d39c":"markdown","5fd755c7":"markdown"},"source":{"f8d31f01":"from IPython.display import Image\nfrom IPython.core.display import HTML\nImage(url= \"https:\/\/pbs.twimg.com\/media\/EUJNQQDXsAwz0tK?format=jpg\")","c650eea9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.integrate import solve_ivp\nfrom scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error","28d504d9":"# Susceptible equation\ndef dS_dt(S, I, R_t, t_inf):\n    return -(R_t \/ t_inf) * I * S\n\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, t_inf, t_inc):\n    return (R_t \/ t_inf) * I * S - (E \/ t_inc)\n\n\n# Infected equation\ndef dI_dt(I, E, t_inc, t_inf):\n    return (E \/ t_inc) - (I \/ t_inf)\n\n\n# Hospialized equation\ndef dH_dt(I, C, H, t_inf, t_hosp, t_crit, m_a, f_a):\n    return ((1 - m_a) * (I \/ t_inf)) + ((1 - f_a) * C \/ t_crit) - (H \/ t_hosp)\n\n\n# Critical equation\ndef dC_dt(H, C, t_hosp, t_crit, c_a):\n    return (c_a * H \/ t_hosp) - (C \/ t_crit)\n\n\n# Recovered equation\ndef dR_dt(I, H, t_inf, t_hosp, m_a, c_a):\n    return (m_a * I \/ t_inf) + (1 - c_a) * (H \/ t_hosp)\n\n\n# Deaths equation\ndef dD_dt(C, t_crit, f_a):\n    return f_a * C \/ t_crit\n\n\ndef SEIR_HCD_model(t, y, R_t, t_inc=2.9, t_inf=5.2, t_hosp=4, t_crit=14, m_a=0.8, c_a=0.1, f_a=0.3):\n    \"\"\"\n\n    :param t: Time step for solve_ivp\n    :param y: Previous solution or initial values\n    :param R_t: Reproduction number\n    :param t_inc: Average incubation period. Default 5.2 days\n    :param t_inf: Average infectious period. Default 2.9 days\n    :param t_hosp: Average time a patient is in hospital before either recovering or becoming critical. Default 4 days\n    :param t_crit: Average time a patient is in a critical state (either recover or die). Default 14 days\n    :param m_a: Fraction of infections that are asymptomatic or mild. Default 0.8\n    :param c_a: Fraction of severe cases that turn critical. Default 0.1\n    :param f_a: Fraction of critical cases that are fatal. Default 0.3\n    :return:\n    \"\"\"\n    if callable(R_t):\n        reprod = R_t(t)\n    else:\n        reprod = R_t\n        \n    S, E, I, R, H, C, D = y\n    \n    S_out = dS_dt(S, I, reprod, t_inf)\n    E_out = dE_dt(S, E, I, reprod, t_inf, t_inc)\n    I_out = dI_dt(I, E, t_inc, t_inf)\n    R_out = dR_dt(I, H, t_inf, t_hosp, m_a, c_a)\n    H_out = dH_dt(I, C, H, t_inf, t_hosp, t_crit, m_a, f_a)\n    C_out = dC_dt(H, C, t_hosp, t_crit, c_a)\n    D_out = dD_dt(C, t_crit, f_a)\n    return [S_out, E_out, I_out, R_out, H_out, C_out, D_out]","55b84d3c":"def plot_model(solution, title='SEIR+HCD model'):\n    sus, exp, inf, rec, hosp, crit, death = solution.y\n    \n    cases = inf + rec + hosp + crit + death\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n    fig.suptitle(title)\n    \n    ax1.plot(sus, 'tab:blue', label='Susceptible');\n    ax1.plot(exp, 'tab:orange', label='Exposed');\n    ax1.plot(inf, 'tab:red', label='Infected');\n    ax1.plot(rec, 'tab:green', label='Recovered');\n    ax1.plot(hosp, 'tab:purple', label='Hospitalised');\n    ax1.plot(crit, 'tab:brown', label='Critical');\n    ax1.plot(death, 'tab:cyan', label='Deceased');\n    \n    ax1.set_xlabel(\"Days\", fontsize=10);\n    ax1.set_ylabel(\"Fraction of population\", fontsize=10);\n    ax1.legend(loc='best');\n    \n    ax2.plot(cases, 'tab:red', label='Cases');    \n    ax2.set_xlabel(\"Days\", fontsize=10);\n    ax2.set_ylabel(\"Fraction of population (Cases)\", fontsize=10, color='tab:red');\n    \n    ax3 = ax2.twinx()\n    ax3.plot(death, 'tab:cyan', label='Deceased');    \n    ax3.set_xlabel(\"Days\", fontsize=10);\n    ax3.set_ylabel(\"Fraction of population (Fatalities)\", fontsize=10, color='tab:cyan');\n","0ddda402":"N = 100000  # Population size\nn_infected = 1\nmax_days = 100\n\n# State at time = 0 for SEIR_HCD model\n# The numbers correspond to the number of people in each of the SEIRHCD compartments\ninitial_state = [(N - n_infected)\/ N, 0, n_infected \/ N, 0, 0, 0, 0]\n\nR_0 = 3.6\nt_inc = 5.6\nt_inf = 2.9\nt_hosp = 4\nt_crit = 14\nm_a = 0.8\nc_a = 0.1\nf_a = 0.3\n\nargs = (R_0, t_inc, t_inf, t_hosp, t_crit, m_a, c_a, f_a)\n\nsol = solve_ivp(SEIR_HCD_model, [0, max_days], initial_state, args=args, t_eval=np.arange(max_days))\n\nplot_model(sol, 'SEIR-HCD Model (without intervention)')","4ad9232d":"R_0 = 3.6 # reproduction number without intervention\nR_t = 0.7  # reproduction number after intervention\nintervention_day = 45\n\ndef time_varying_reproduction(t):\n    if t > intervention_day:\n        return R_t\n    else:\n        return R_0\n    \nargs = (time_varying_reproduction, t_inc, t_inf, t_hosp, t_crit, m_a, c_a, f_a)\n\nsol2 = solve_ivp(SEIR_HCD_model, [0, max_days], initial_state, args=args, t_eval=np.arange(max_days))\n\nplot_model(sol2, f'SEIR-HCD Model (with intervention on day {intervention_day})')","28e63fbe":"sus, exp, inf, rec, hosp, crit, deaths = sol.y\nsus2, exp2, inf2, rec2, hosp2, crit2, deaths2 = sol2.y\n\nf = plt.figure(figsize=(8,5)) \n# plt.plot(exp, 'tab:orange', label='Exposed', linestyle=':');\nplt.plot(inf, 'r', label='Infected', linestyle=':');\nplt.plot(deaths, 'b', label='Deceased', linestyle=':');\nplt.plot(hosp, 'tab:purple', label='Hospitalised', linestyle=':');\n# plt.plot(exp2, 'tab:orange', label='Exposed with intervention');\nplt.plot(inf2, 'r', label='Infected with intervention');\nplt.plot(deaths2, 'b', label='Deceased with intervention');\nplt.plot(hosp2, 'tab:purple', label='Hospitalised with intervention');\n\nplt.title(f'Comparison of the effect of the intervention on day {intervention_day}')\nplt.xlabel(\"Days\", fontsize=10);\nplt.ylabel(\"Fraction of population\", fontsize=10);\nplt.legend(loc='best');","6a9eb611":"Image(url= \"https:\/\/raw.githubusercontent.com\/wiki\/SwissTPH\/openmalaria\/img\/graphs\/decay-functions.png\")","7fc8f48d":"DATE_BORDER = '2020-04-08'\n\ndata_path = Path('\/kaggle\/input\/covid19-global-forecasting-week-3\/')\n\ntrain = pd.read_csv(data_path \/ 'train.csv', parse_dates=['Date'])\ntest = pd.read_csv(data_path \/'test.csv', parse_dates=['Date'])\nsubmission = pd.read_csv(data_path \/'submission.csv', index_col=['ForecastId'])\n\n# Load the population data into lookup dicts\npop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))\n\n# Fix the Georgia State\/Country confusion - probably a better was of doing this :)\ntrain['Province_State'] = train['Province_State'].replace('Georgia', 'Georgia (State)')\ntest['Province_State'] = test['Province_State'].replace('Georgia', 'Georgia (State)')\nprovince_lookup['Georgia (State)'] = province_lookup['Georgia']\n\ntrain['Area'] = train['Province_State'].fillna(train['Country_Region'])\ntest['Area'] = test['Province_State'].fillna(test['Country_Region'])\n\n# https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-1\/discussion\/139172\ntrain['ConfirmedCases'] = train.groupby('Area')['ConfirmedCases'].cummax()\ntrain['Fatalities'] = train.groupby('Area')['Fatalities'].cummax()\n\n# Remove the leaking data\ntrain_full = train.copy()\nvalid = train[train['Date'] >= test['Date'].min()]\ntrain = train[train['Date'] < test['Date'].min()]\n\n# Split the test into public & private\ntest_public = test[test['Date'] <= DATE_BORDER]\ntest_private = test[test['Date'] > DATE_BORDER]\n\n# Use a multi-index for easier slicing\ntrain_full.set_index(['Area', 'Date'], inplace=True)\ntrain.set_index(['Area', 'Date'], inplace=True)\nvalid.set_index(['Area', 'Date'], inplace=True)\ntest_public.set_index(['Area', 'Date'], inplace=True)\ntest_private.set_index(['Area', 'Date'], inplace=True)\n\nsubmission['ConfirmedCases'] = 0\nsubmission['Fatalities'] = 0\n\ntrain_full.shape, train.shape, valid.shape, test_public.shape, test_private.shape, submission.shape","66cd0a01":"OPTIM_DAYS = 21  # Number of days to use for the optimisation evaluation","145fc27f":"# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, t_hosp, t_crit, m, c, f = params\n    N = population\n    n_infected = data['ConfirmedCases'].iloc[0]\n    max_days = len(data) + forecast_days\n    initial_state = [(N - n_infected)\/ N, 0, n_infected \/ N, 0, 0, 0, 0]\n    args = (R_0, 5.6, 2.9, t_hosp, t_crit, m, c, f)\n               \n    sol = solve_ivp(SEIR_HCD_model, [0, max_days], initial_state, args=args, t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec, hosp, crit, deaths = sol.y\n    \n    y_pred_cases = np.clip(inf + rec + hosp + crit + deaths, 0, np.inf) * population\n    y_true_cases = data['ConfirmedCases'].values\n    y_pred_fat = np.clip(deaths, 0, np.inf) * population\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(OPTIM_DAYS, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    \n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","632cd53b":"# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, t_hosp, t_crit, m, c, f, k, L = params  \n    N = population\n    n_infected = data['ConfirmedCases'].iloc[0]\n    max_days = len(data) + forecast_days\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    initial_state = [(N - n_infected)\/ N, 0, n_infected \/ N, 0, 0, 0, 0]\n    args = (time_varying_reproduction, 5.6, 2.9, t_hosp, t_crit, m, c, f)\n            \n    sol = solve_ivp(SEIR_HCD_model, [0, max_days], initial_state, args=args, t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec, hosp, crit, deaths = sol.y\n    \n    y_pred_cases = np.clip(inf + rec + hosp + crit + deaths, 0, np.inf) * population\n    y_true_cases = data['ConfirmedCases'].values\n    y_pred_fat = np.clip(deaths, 0, np.inf) * population\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(OPTIM_DAYS, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","c2719dca":"def use_last_value(train_data, valid_data, test_data):\n    lv = train_data[['ConfirmedCases', 'Fatalities']].iloc[-1].values\n    \n    forecast_ids = test_data['ForecastId']\n    submission.loc[forecast_ids, ['ConfirmedCases', 'Fatalities']] = lv\n    \n    if valid_data is not None:\n        y_pred_valid = np.ones((len(valid_data), 2)) * lv.reshape(1, 2)\n        y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n\n        msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid[:, 0])\n        msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid[:, 1])\n        msle_final = np.mean([msle_cases, msle_fat])\n\n        return msle_final","aaa90643":"def plot_model_results(y_pred, train_data, valid_data=None):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n    \n    ax1.set_title('Confirmed Cases')\n    ax2.set_title('Fatalities')\n    \n    train_data['ConfirmedCases'].plot(label='Confirmed Cases (train)', color='g', ax=ax1)\n    y_pred.loc[train_data.index, 'ConfirmedCases'].plot(label='Modeled Cases', color='r', ax=ax1)\n    ax3 = y_pred['R'].plot(label='Reproduction number', color='c', linestyle='-', secondary_y=True, ax=ax1)\n    ax3.set_ylabel(\"Reproduction number\", fontsize=10, color='c');\n        \n    train_data['Fatalities'].plot(label='Fatalities (train)', color='g', ax=ax2)\n    y_pred.loc[train_data.index, 'Fatalities'].plot(label='Modeled Fatalities', color='r', ax=ax2)\n    \n    if valid_data is not None:\n        valid_data['ConfirmedCases'].plot(label='Confirmed Cases (valid)', color='g', linestyle=':', ax=ax1)\n        valid_data['Fatalities'].plot(label='Fatalities (valid)', color='g', linestyle=':', ax=ax2)\n        y_pred.loc[valid_data.index, 'ConfirmedCases'].plot(label='Modeled Cases (forecast)', color='r', linestyle=':', ax=ax1)\n        y_pred.loc[valid_data.index, 'Fatalities'].plot(label='Modeled Fatalities (forecast)', color='r', linestyle=':', ax=ax2)\n    else:\n        y_pred.loc[:, 'ConfirmedCases'].plot(label='Modeled Cases (forecast)', color='r', linestyle=':', ax=ax1)\n        y_pred.loc[:, 'Fatalities'].plot(label='Modeled Fatalities (forecast)', color='r', linestyle=':', ax=ax2)\n        \n    ax1.legend(loc='best')\n    ","c66c56b3":"def fit_model_public(area_name, \n                     initial_guess=[3.6, 4, 14, 0.8, 0.1, 0.3, 2, 50],\n                     bounds=((1, 20), # R bounds\n                             (0.5, 10), (2, 20), # transition time param bounds\n                             (0.5, 1), (0, 1), (0, 1), (1, 5), (1, 100)), # fraction time param bounds\n                     make_plot=True):\n        \n    train_data = train.loc[area_name].query('ConfirmedCases > 0')\n    valid_data = valid.loc[area_name]\n    test_data = test_public.loc[area_name]  \n    \n    try:\n        population = province_lookup[area_name]\n    except KeyError:\n        population = country_lookup[area_name]\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n        \n    if cases_per_million < 1:\n        return use_last_value(train_data, valid_data, test_data)\n                \n    res_const = minimize(eval_model_const, initial_guess[:-2], bounds=bounds[:-2],\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    dates_all = train_data.index.append(test_data.index)\n    dates_val = train_data.index.append(valid_data.index)\n    \n    \n    # If using a constant R number is better, use that model\n    if res_const.fun < res_decay.fun:\n        msle, sol = eval_model_const(res_const.x, train_data, population, True, len(test_data))\n        res = res_const\n        R_t = pd.Series([res_const.x[0]] * len(dates_val), dates_val)\n    else:\n        msle, sol = eval_model_decay(res_decay.x, train_data, population, True, len(test_data))\n        res = res_decay\n        \n        # Calculate the R_t values\n        t = np.arange(len(dates_val))\n        R_0, t_hosp, t_crit, m, c, f, k, L = res.x  \n        R_t = pd.Series(R_0 \/ (1 + (t\/L)**k), dates_val)\n        \n    sus, exp, inf, rec, hosp, crit, deaths = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': np.clip(inf + rec + hosp + crit + deaths, 0, np.inf) * population,\n        'Fatalities': np.clip(deaths, 0, np.inf) * population,\n        'R': R_t,\n    }, index=dates_all)\n    \n    y_pred_valid = y_pred.iloc[len(train_data): len(train_data)+len(valid_data)]\n    y_pred_test = y_pred.iloc[len(train_data):]\n    y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n        \n    valid_msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid['ConfirmedCases'])\n    valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = np.mean([valid_msle_cases, valid_msle_fat])\n    \n    if make_plot:\n        print(f'Validation MSLE: {valid_msle:0.5f}')\n        print(f'R: {res.x[0]:0.3f}, t_hosp: {res.x[1]:0.3f}, t_crit: {res.x[2]:0.3f}, '\n              f'm: {res.x[3]:0.3f}, c: {res.x[4]:0.3f}, f: {res.x[5]:0.3f}')\n        plot_model_results(y_pred, train_data, valid_data)\n        \n    # Put the forecast in the submission\n    forecast_ids = test_data['ForecastId']\n    submission.loc[forecast_ids, ['ConfirmedCases', 'Fatalities']] = y_pred_test[['ConfirmedCases', 'Fatalities']].values\n    \n    return valid_msle\n            ","6b02f70a":"# Fit a model on the full dataset (i.e. no validation)\ndef fit_model_private(area_name, \n                      initial_guess=[3.6, 4, 14, 0.8, 0.1, 0.3, 2, 50],\n                      bounds=((1, 20), # R bounds\n                              (0.5, 10), (2, 20), # transition time param bounds\n                              (0.5, 1), (0, 1), (0, 1), (1, 5), (1, 100)), # fraction time param bounds\n                      make_plot=True):\n        \n    train_data = train_full.loc[area_name].query('ConfirmedCases > 0')\n    test_data = test_private.loc[area_name]\n    \n    try:\n        population = province_lookup[area_name]\n    except KeyError:\n        population = country_lookup[area_name]\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n        \n    if cases_per_million < 1:\n        return use_last_value(train_data, None, test_data)\n                \n    res_const = minimize(eval_model_const, initial_guess[:-2], bounds=bounds[:-2],\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    dates_all = train_data.index.append(test_data.index)\n    \n    \n    # If using a constant R number is better, use that model\n    if res_const.fun < res_decay.fun:\n        msle, sol = eval_model_const(res_const.x, train_data, population, True, len(test_data))\n        res = res_const\n        R_t = pd.Series([res_const.x[0]] * len(dates_all), dates_all)\n    else:\n        msle, sol = eval_model_decay(res_decay.x, train_data, population, True, len(test_data))\n        res = res_decay\n        \n        # Calculate the R_t values\n        t = np.arange(len(dates_all))\n        R_0, t_hosp, t_crit, m, c, f, k, L = res.x  \n        R_t = pd.Series(R_0 \/ (1 + (t\/L)**k), dates_all)\n        \n    sus, exp, inf, rec, hosp, crit, deaths = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': np.clip(inf + rec + hosp + crit + deaths, 0, np.inf) * population,\n        'Fatalities': np.clip(deaths, 0, np.inf) * population,\n        'R': R_t,\n    }, index=dates_all)\n    \n    y_pred_test = y_pred.iloc[len(train_data):]\n    \n    if make_plot:\n        print(f'R: {res.x[0]:0.3f}, t_hosp: {res.x[1]:0.3f}, t_crit: {res.x[2]:0.3f}, '\n              f'm: {res.x[3]:0.3f}, c: {res.x[4]:0.3f}, f: {res.x[5]:0.3f}')\n        plot_model_results(y_pred, train_data)\n        \n    # Put the forecast in the submission\n    forecast_ids = test_data['ForecastId']\n    submission.loc[forecast_ids, ['ConfirmedCases', 'Fatalities']] = y_pred_test[['ConfirmedCases', 'Fatalities']].values\n            ","cb961816":"fit_model_public('Italy')\nfit_model_private('Italy')","a89822d8":"fit_model_public('Iran')\nfit_model_private('Iran')","3373849c":"fit_model_public('Korea, South')\nfit_model_private('Korea, South')","a940b128":"fit_model_public('Japan')\nfit_model_private('Japan')","55886f61":"fit_model_public('Hubei')\nfit_model_private('Hubei')","e47e13d9":"fit_model_public('United Kingdom')\nfit_model_private('United Kingdom')","49ff94fc":"# Public Leaderboard\nvalidation_scores = []\n\nfor c in tqdm(test_public.index.levels[0].values):\n    try:\n        score = fit_model_public(c, make_plot=False)\n        validation_scores.append({'Country': c, 'MSLE': score})\n        print(f'{score:0.5f} {c}')\n    except IndexError as e:\n        print(c, 'has no cases in train')\n    except ValueError as e:\n        print(c, e)\n\nvalidation_scores = pd.DataFrame(validation_scores)\nprint(f'Mean validation score: {np.sqrt(validation_scores[\"MSLE\"].mean()):0.5f}')","77cd0dd2":"# Find which areas are not being predicted well\nvalidation_scores.sort_values(by=['MSLE'], ascending=False).head(20)","d686046c":"# Private Leaderboard\nfor c in tqdm(test_private.index.levels[0].values):\n    try:\n        score = fit_model_private(c, make_plot=False)\n    except IndexError as e:\n        print(c, 'has no cases in train')","bd270fb7":"submission.round().to_csv('submission.csv')","c2f3ed11":"submission.join(test.set_index('ForecastId')).query(f'Date > \"{DATE_BORDER}\"').round().to_csv('forecast.csv')","584c4284":"I'm not sure why the red line is so wiggly for Japan \u00af\\\\_(\u30c4)_\/\u00af","acad4620":"# Calculate for all countries","9619aa88":"The function below evaluates a model with a constant `R` number as well as `t_hosp`, `t_crit`, `m`, `c`, `f`","fd5109e3":"# SEIR-HCD Model\nThis is a working example of a [SIER](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology#The_SEIR_model) model with added compartments for HCD. The letters stand for:\n* Susceptible\n* Exposed\n* Infected\n* Recovered\n* Hospitalized\n* Critical\n* Death\n\nI have adapted the equations from these great web apps:\n* http:\/\/gabgoh.github.io\/COVID\/index.html\n* https:\/\/neherlab.org\/covid19\n\n**NOTE:** If you are looking for the SIER model, check commit 20 or earlier.","b322aedb":"# Model with intervention\nLets assume that there is some intervention that causes the reproduction number (`R_0`) to fall to a lower value (`R_t`) at a certain time (e.g. physical distancing). Note that the actual drop will occur some time after the intervention measures are implemented.\n\nThis could be modified to take any function of `R_t(t)` values to model the reproduction number as a time varying variable","9b379591":"Let's compare the infection rate between the two cases","56150106":"Above you can see the model optimized on the last `OPTIM_DAYS` days of data from Italy which has been weighted to put more importance on recent data\n\nThe numbers show that `R_0` was around 3.5 and a decayed value is a better fit to the data. This is good news for Italy as it shows its measures are working.\n\nLet's try Iran, South Korea and Japan. I chose these countries since they are probably the most challenging to model","30c9bf0e":"The plot for Hubei looks really good. In fact the data for most of the Chinese provinces fit well to compartment models","ebc537b1":"# Thoughts on compartment models\nI think compartment models are very powerful toy models and add lots of value for scenario testing, e.g. when a healthcare system might be overwhelmed, the impact of various interventions etc.. They can also be easily bootstrapped using population demographics to generate uncertainty estimates on those scenarios. \n\nThe hospitalization compartment in this model is tricky to work with as I had to set the lower bounds for these transition times quite low (`t_hosp`, `t_crit`). I think the reason for this is that many countries are telling people to stay away from the hospitals unless they are experiencing severe symptoms, meaning that once a patient is in a hospital, there are likely to already be very sick. This means when I optimize the transition times to go from hospitalized > severe, the times are often very small.\n\nHowever, I think that for this particular forecasting exercise and metric, there are more accurate methods that can be used. One could also use a compartment model like this to generate features for another model.\n","a88dd72d":"South Korea is unusual due to the incredible efforts to stop the spread","b182ca5f":"# Todo\/ideas\n* Some of the search boundaries boundaries are dependent on each other (e.g. `t_hosp` should always be less than `t_crit`). Using `NonlinearConstraint` may solve this\n* Time dependence of other parameters, e.g. `f` as hospitals get overwhelmed\n* Mix in other sources of data (e.g. number of hospital beds, age demographics)\n* Global optmisation of virus specific parameters\n* Use as features into a different model","b43b0c22":"You can see that after the intervention on day 45, the peak infections is lower than if there was no intervention and there are less than half as many deaths. You can see how powerful self-isolation is from this chart","2f864c6b":"# Fitting the model to data\nThere are certain variables that we can play with to fit the model to real data:\n* Average incubation period, `t_inc`\n* Average infection period, `t_inf`\n* Average hospitalization period, `t_hosp`\n* Average critital period, `t_crit`\n* The fraction of mild\/asymptomatic cases, `m_a`\n* The fraction of severe cases that turn critical, `c_a`\n* The fraction of critical cases that result in a fatality, `f_a`\n* Reproduction number, `R_0` or `R_t`\n\nThe some of these are likely to be constants specific to the virus and some are likely to be time dependent variables dependent on factors such as:\n* When a government intervened\n* Peoples behaviours (do people actively self-isolate, not visit religious shrines etc.)\n* Population demographic of a country (is a significant proportion of the population old?). This is the `a` subscript\n* Heathcare system capacity (hostpital beds per capita)\n* Number of testing kits available\n\nWe have already used two different reproduction numbers above. Let's see if we can derive a time-dependent `R_t` from the data. We will also try and optimize a handful of the parameters above to match the data.\n\nWe will also compare this to just using a single reproduction number. This might actaully be more suitable in countries where the outbreak has just started or they are struggling to limit the spread.\n\nThere are lots of ways to decay a parameter in epidemiology. I'm going to use a Hill decay, which has 2 parameters, `k` and `L` (the half decay constant):","95fae6c1":"## Parameters used in the model\n`R_t` = reproduction number at time t. Typical 3.6* at t=0\n\n**Transition times**\n* `T_inc` = average incubation period. Typical 5.6* days\n* `T_inf` = average infectious period. Typical 2.9 days\n* `T_hosp` = average time a patient is in hospital before either recovering or becoming critical. Typical 4 days\n* `T_crit` = average time a patient is in a critical state (either recover or die). Typical 14 days\n\n**Fractions**\nThese constants are likely to be age specific (hence the subscript a):\n* `m_a` = fraction of infections that are asymptomatic or mild. Assumed 80% (i.e. 20% severe)\n* `c_a` = fraction of severe cases that turn critical. Assumed 10%\n* `f_a` = fraction of critical cases that are fatal. Assumed 30%\n\n*Averages taken from https:\/\/www.kaggle.com\/covid-19-contributions","92e5080b":"# Model without intervention\nLet's see what the model looks like without any intervention, i.e. `R_0` is a contant value","2deac7eb":"Things are not looking good for the UK. Let's hope the lockdown starts bringing the R number down soon","349d677e":"An unusual feature of the Iranian data is how high the R value needs to be for the model to fit. Iran was criticised for not closing religious shrines and locking down earlier, so the virus was extremely contagious. The data also appears of have multiple inflection points","c669d39c":"The function below is essentially the same as above, by R is decayed using a Hill decay function. This model requires 2 additional parameters to be optimized, `k` & `L`","5fd755c7":"The function below fits a SEIR-HCD model for each area, either using a constant R or a decayed R, whichever is better. If the total cases\/1M pop is below 1, then the last value is used."}}