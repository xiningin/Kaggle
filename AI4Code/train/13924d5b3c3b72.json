{"cell_type":{"60284d04":"code","84ca9b34":"code","ca5dd5c6":"code","aea74c84":"code","e8ed921c":"code","e5abda4d":"code","509fe0d1":"code","8f841946":"code","1fc63f74":"code","d4a4b0d0":"code","d3a9da7e":"code","6be8e94c":"code","196b4b98":"markdown","d5ca2c40":"markdown","ee2795e6":"markdown","6013236e":"markdown","6b43a649":"markdown","f7441883":"markdown","9b21ccb9":"markdown","ea9ceec6":"markdown","6f6ccc9e":"markdown","981878f5":"markdown","87b968d0":"markdown"},"source":{"60284d04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84ca9b34":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","ca5dd5c6":"chopped_data = pd.read_csv(\"\/kaggle\/input\/chopped-10-years-of-episode-data\/chopped.csv\")","aea74c84":"chopped_data.head()","e8ed921c":"round_type = \"entree\"\nround_list = chopped_data[round_type].to_list()\nprint(round_list[:5])","e5abda4d":"text = []\n\nfor selection in round_list:                     # For each basket selection in appetizers\n    ingredients_comma =  selection.split(\",\")         # Convert each basket selection into a list of strings\n    ingredients = []\n    for ingredient in ingredients_comma:\n        for element in ingredient.strip().split(\" \"):\n            ingredients.append(element)\n    for i in range(1, len(ingredients)):              # For as long as the list of strings is\n        n_gram = ingredients[:i + 1]                  # create a fragment of the sentence\n        text.append(n_gram)                           # and append it to text\n\nprint(text[:15])","509fe0d1":"tokenizer = Tokenizer(num_words = 2000, oov_token = \"<OOV>\")    # Generate a tokenizer\ntokenizer.fit_on_texts(text)                                    # and fit it on our text\nsequences = tokenizer.texts_to_sequences(text)                  # Turn all of our text into texts\nword_index = tokenizer.word_index                               \nword_count = len(word_index) - 1","8f841946":"max_len = max([len(sequence) for sequence in sequences])\nsequences = np.array(pad_sequences(sequences, maxlen = max_len, padding = \"pre\"))\nprint(sequences)","1fc63f74":"xs = sequences[:,:-1]\nlabels = sequences[:,-1]\n\nys = tf.keras.utils.to_categorical(labels)","d4a4b0d0":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(word_count, 64, input_length = max_len - 1),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n    tf.keras.layers.Dense(word_count +2, activation = \"softmax\"),\n])\n\nmodel.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])","d3a9da7e":"model.fit(xs, ys, epochs=300, verbose = 2)","6be8e94c":"seed_ingredients = \"chicken\"\nnum_words = 6\n\nfor _ in range(num_words):\n    token_list = tokenizer.texts_to_sequences([seed_ingredients])[0]\n    token_list = pad_sequences([token_list], maxlen = max_len - 1, padding = \"pre\")\n    predicted = model.predict_classes(token_list, verbose = 2)\n    output_word = \"\"\n    for word, i in tokenizer.word_index.items():\n        if i == predicted:\n            output_word = word\n            break\n    seed_ingredients += f\" {output_word}\"\n\nprint(seed_ingredients)","196b4b98":"### Training our model","d5ca2c40":"### Making Predictions with our model","ee2795e6":"### Import necessary modules","6013236e":"### Creating a modified sequence of data\nOne which decomposes a sentence so that a sentence like [\"My name is Jordan\"]  turns into [\"My name\", \"My name is\", \"My name is Jordan\"]","6b43a649":"### Creating list of every appetizer ingredient","f7441883":"### Creating our inputs and labels for our training data","9b21ccb9":"### Read CSV of Chopped Episode data","ea9ceec6":"### Padding each element so that they are all the same length","6f6ccc9e":"# Chopped NLP\nData courtesy of Jeffrey Braun (https:\/\/www.kaggle.com\/jeffreybraun\/chopped-10-years-of-episode-data)","981878f5":"### Creating and compiling a model","87b968d0":"### Tokenizing our words"}}