{"cell_type":{"7e7a91ad":"code","cf01b4ee":"code","9ff96e09":"code","2bed61e3":"code","e5e514c5":"code","6eef03f1":"code","2360c787":"code","075d5279":"code","68a34edd":"code","64087597":"code","3f1003f8":"code","8b4c8bfc":"code","2cd677f2":"code","d02ba804":"code","d6673c58":"code","e03f0851":"code","22884a1d":"code","b2ae9325":"code","75078b51":"code","fbbb4359":"code","8204ee4b":"code","b571f910":"code","01294938":"markdown","5eca7c0a":"markdown","c2461250":"markdown","68727f0a":"markdown","0d744108":"markdown","db9fbb52":"markdown"},"source":{"7e7a91ad":"!pip install -q efficientnet\n\nimport efficientnet.tfkeras as efn","cf01b4ee":"import re\nimport math\nimport numpy as np\nimport seaborn as sns","9ff96e09":"from kaggle_datasets import KaggleDatasets\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers","2bed61e3":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\n    \nexcept ValueError:\n    tpu = None\n    \n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n    \nprint('REPLICAS : -> ', strategy.num_replicas_in_sync)","e5e514c5":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('cats-dogs-tfrecords-192x192')","6eef03f1":"TRAINING_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '\/train.*tfrecords')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '\/val.*tfrecords')\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [192,192]\nprint(TRAINING_FILENAMES)\nprint(VALIDATION_FILENAMES)\nprint(BATCH_SIZE)\nprint(IMAGE_SIZE)","2360c787":"EPOCHS = 10\nSTEPS_PER_EPOCH = 15000 \/\/ BATCH_SIZE","075d5279":"def decode_image(image_data):\n    print('About to decode image data...')\n    #image = tf.image.decode_jpeg(image_data, channels = 3)\n    #image = tf.io.parse_tensor(image_data, out_type = tf.uint8)\n    image = tf.io.decode_raw(image_data, tf.uint8)\n    print('Decoded JPEG...')\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    print('Done decoding image')\n    return image","68a34edd":"def read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image_raw\" : tf.io.FixedLenFeature([], tf.string),\n        \"label\" : tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    print('About to parse labeled tfrecord...')\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image_raw'])\n    print('Read Image Data...')\n    label = tf.cast(example['label'], tf.int32)\n    return image, label","64087597":"def load_dataset(filenames, labeled = True, ordered = False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n    \n    print('About to Load TFRECORD Dataset...')\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = tf.data.experimental.AUTOTUNE)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n    print('Read labeled TFRecords...')\n    return dataset","3f1003f8":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled = True)\n    print('loaded training dataset')\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    print('Successfully loaded training dataset')\n    return dataset\n    ","8b4c8bfc":"def get_validation_dataset():\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled = True)\n    print('loaded training dataset')\n    dataset = dataset.repeat(1)\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    print('Successfully loaded validation dataset')\n    return dataset\n    ","2cd677f2":"histories = []","d02ba804":"with strategy.scope():\n    enet = efn.EfficientNetB1(\n        input_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n        weights = 'imagenet',\n        include_top = False\n    )\n    \n    enet.trainable = False\n    model = tf.keras.Sequential([\n        enet, \n        tf.keras.layers.GlobalMaxPooling2D(name = 'layer1'),\n        tf.keras.layers.Dropout(0.4),\n       # tf.keras.layers.Dense(1, activation = 'softmax')\n        tf.keras.layers.Dense(1, activation = 'sigmoid')\n    ])","d6673c58":"\"\"\"# METRICS\n\nmodel.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n             loss = 'sparse_categorical_crossentropy',\n              metrics= ['categorical_accuracy']\n             )\"\"\"","e03f0851":"\"\"\"# METRICS\n\nmodel.compile(optimizer = 'tf.keras.optimizers.Adam(lr = 0.0001)',\n             loss = 'categorical_crossentropy',\n              metrics= ['accuracy']\n             )\"\"\"","22884a1d":"# METRICS\n\nmodel.compile(optimizer = 'rmsprop',\n             loss = 'binary_crossentropy',\n              metrics= ['accuracy']\n             )","b2ae9325":"training_history_effnet = model.fit(get_training_dataset(), \n         steps_per_epoch = STEPS_PER_EPOCH, \n         validation_data = get_validation_dataset(),\n          epochs = EPOCHS\n         )\n\nhistories.append(training_history_effnet)","75078b51":"import seaborn as sns; import matplotlib.pyplot as plt; sns.set()","fbbb4359":"histories[0].history","8204ee4b":"sns.lineplot(x = list(range(1,11)), y = histories[0].history['loss'], label = 'Training Loss', color = 'red');\nsns.lineplot(x = list(range(1,11)), y = histories[0].history['val_loss'], label = 'Validation Loss', color = 'black').set_title('Loss Plot vs Epoch');\nplt.show()","b571f910":"sns.lineplot(x = list(range(1,11)), y = histories[0].history['accuracy'], label = 'Training Accuracy', color = 'black');\nsns.lineplot(x = list(range(1,11)), y = histories[0].history['val_accuracy'], label = 'Validation Accuracy', color = 'red').set_title('Accuracy Plot vs Epoch');\nplt.show()","01294938":"Variables declaration","5eca7c0a":"Function Definition","c2461250":"# TPU Model Training w\/ Custom [TFRecord Dataset](https:\/\/www.kaggle.com\/superficiallybot\/catsdogstfrecords192x192)","68727f0a":"Model Creation","0d744108":"### This was a baseline model. Main aim was to create tfrecords, get it to gcs bucket & load, parse the tfrecords to train TPU Models which has been successful. Improvisations on the Model training can be performed at the dataset link -> https:\/\/www.kaggle.com\/antoreepjana\/cats-dogs-tfrecords-192x192\n\n# Special Thanks to @ifigotin for helping me.","db9fbb52":"Writing the read functions again from scratch for TPU Training"}}