{"cell_type":{"36a6ea62":"code","e0313707":"code","24284a3d":"code","d28fedb4":"code","4262b9fe":"code","cdc33b9a":"code","0d788cfe":"code","e5526271":"code","57727392":"code","0b8c4b59":"code","ec60a4f0":"code","06ed3f9c":"code","9da9d7d7":"code","87f36739":"code","5c6f02ce":"code","589ec4dc":"code","3c3d4202":"code","0be466ec":"code","b0b7b7c7":"code","5a26802a":"code","0ef22eab":"code","b0ab808c":"code","2e318222":"code","4e9ba863":"code","abe824f2":"code","a1ab516b":"code","e3bf4955":"code","40d1953e":"code","3d266373":"code","00cd4ab9":"code","e68c44b1":"code","cfdcddb2":"code","eb5ab0f4":"code","6ebeec23":"code","404cb4e5":"code","c69c3208":"code","b05d5a02":"code","6c706c81":"code","38f6f990":"code","a4a01eae":"code","b4160790":"code","3a914eef":"code","bd9fc2ae":"code","3db0b822":"code","c0bc283b":"code","0895f531":"code","70453c09":"code","5c37a0bf":"code","57c477de":"code","d7e59764":"code","4abd468f":"code","f80dda7f":"code","21b304f7":"code","cd46d8a8":"code","88f66e68":"code","1cf62462":"code","4e936946":"code","a2d28fe4":"code","e90e0ba5":"code","201a9336":"code","6b954308":"code","533c8b8f":"code","8423b937":"code","a3cda941":"code","5b8df52a":"code","17169bb1":"code","2119602e":"code","0bddfeb1":"code","ab21fcbe":"code","f54af172":"code","452819b1":"markdown","0271105e":"markdown","11fcbcbc":"markdown","4b9082ad":"markdown","7e88bfe8":"markdown"},"source":{"36a6ea62":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LinearRegression\nfrom keras.preprocessing.sequence import pad_sequences\n\n\nfrom collections import Counter\nimport nltk\nimport seaborn as sns\nimport string\nfrom nltk.corpus import stopwords\n# import re\n# from autocorrect import spell\nimport regex as re\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import eval\nfrom keras.optimizers import Adam\nfrom keras.layers import LSTM\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Dropout\nfrom keras.layers.convolutional import Conv1D,MaxPooling1D\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e0313707":"data=pd.read_csv('..\/input\/1429_1.csv')\ndata.head()","24284a3d":"# yelp['label'] = ['1' if star > 3 else '0' for star in yelp['stars']];","d28fedb4":"review=pd.DataFrame(data.groupby('reviews.rating').size().sort_values(ascending=False).rename('No of Users').reset_index())\nreview.head()","4262b9fe":"permanent = data[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\nmpermanent=permanent.dropna()\nmpermanent.head()","cdc33b9a":"check =  mpermanent[mpermanent[\"reviews.text\"].isnull()]\ncheck.head()","0d788cfe":"actualrating = mpermanent[(mpermanent['reviews.rating'] == 1) | (mpermanent['reviews.rating'] == 5)]\nactualrating.shape\n","e5526271":"y = actualrating['reviews.rating']\nx = actualrating['reviews.text'].reset_index()\n# X =x[xindex(False)]","57727392":"len(y)\n# len(X)","0b8c4b59":"X = x['reviews.text']\nprint(X)","ec60a4f0":"print(len(X))","06ed3f9c":"import string\nfrom nltk.corpus import stopwords\n# stop=set(stopwords.words('english'))\ndef text_process(text):\n    '''\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Return the cleaned text as a list of words\n    '''\n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    \n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","9da9d7d7":"tokens = X[0].split()\nprint(tokens)","87f36739":"sample_text = \"Hey there! This is a sample review, which happens to contain punctuations.\"\nprint(text_process(sample_text))","5c6f02ce":"from sklearn.feature_extraction.text import CountVectorizer\n# next we need to vectorize our input variable (X)\n#we use the count vectoriser function and the analyser we use is the above lines of code\n# this should return a vector array\nbow_transformer = CountVectorizer(analyzer=text_process).fit(X)","589ec4dc":"len(bow_transformer.vocabulary_)","3c3d4202":"review_24 = X[24]","0be466ec":"bow_25 = bow_transformer.transform([review_24])\nbow_25","b0b7b7c7":"print(bow_25)","5a26802a":"X = bow_transformer.transform(X)","0ef22eab":"#Lets start training the model\nfrom sklearn.model_selection import train_test_split\n#using 30% of the data for testing, this will be revised once we do not get the desired accuracy\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","b0ab808c":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)","2e318222":"preds = nb.predict(X_test)","4e9ba863":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, preds))\nprint('\\n')\nprint(classification_report(y_test, preds))\nnb.score(X_train, y_train)","abe824f2":"from sklearn.svm import SVC\nclf = SVC()\nclf.fit(X_train, y_train) \npredsvm=clf.predict(X_test)","a1ab516b":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, preds))\nprint('\\n')\nprint(classification_report(y_test, predsvm))\npredsvm=clf.predict(X_test)\nclf.score(X_train,y_train)","e3bf4955":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X, y) ","40d1953e":"predsknn=neigh.predict(X_test)","3d266373":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, predsknn))\nprint('\\n')\nprint(classification_report(y_test, predsknn))\nneigh.score(X_train,y_train)","00cd4ab9":"from sklearn.ensemble import GradientBoostingClassifier\nmodel= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\nmodel.fit(X_train, y_train)\npredicted= model.predict(X_test)","e68c44b1":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, predicted))\nprint('\\n')\nprint(classification_report(y_test, predicted))\nmodel.score(X_train,y_train)","cfdcddb2":"positive_review = actualrating['reviews.text'][2]\npositive_review","eb5ab0f4":"positive_review_transformed = bow_transformer.transform([positive_review])\nnb.predict(positive_review_transformed)[0]","6ebeec23":"positive_review = actualrating['reviews.text'][11]\npositive_review","404cb4e5":"positive_review_transformed = bow_transformer.transform([positive_review])\nmodel.predict(positive_review_transformed)[0]","c69c3208":"negative_review = mpermanent['reviews.text'][34650]\nprint(negative_review)","b05d5a02":"negative_review_transformed = bow_transformer.transform([negative_review])\nnb.predict(negative_review_transformed)[0]","6c706c81":"negative_review_transformed = bow_transformer.transform([negative_review])\nneigh.predict(negative_review_transformed)[0]","38f6f990":"negative_review = mpermanent['reviews.text'][34656]\nprint(negative_review)","a4a01eae":"negative_review_transformed = bow_transformer.transform([negative_review])\nnb.predict(negative_review_transformed)[0]","b4160790":"negative_review_transformed = bow_transformer.transform([negative_review])\nneigh.predict(negative_review_transformed)[0]","3a914eef":"#we need to have a label for \n# lets have a label which group the stars into two groups, 1 for good, 0 for bad \n# so anything more than 3 , 3 being neutral is good, rest bad\n# data['label'] = ['1' if reviews.rating > 3 else '0' for reviews.rating in data['reviews.rating']];\nmpermanent['label'] = ['1' if star >= 3 else '0' for star in mpermanent['reviews.rating']];","bd9fc2ae":"mpermanent","3db0b822":"mpermanent.tail()","c0bc283b":"reviews = mpermanent['reviews.text']\nlabels = mpermanent['label']","0895f531":"print(len(reviews))","70453c09":"print(len(labels))","5c37a0bf":"reviews[3]","57c477de":"stop = set(stopwords.words('english'))","d7e59764":"def clean_document(doco):\n    punctuation = string.punctuation\n    punc_replace = ''.join([' ' for s in punctuation])\n    doco_link_clean = re.sub(r'http\\S+', '', doco)\n    doco_clean_and = re.sub(r'&\\S+', '', doco_link_clean)\n    doco_clean_at = re.sub(r'@\\S+', '', doco_clean_and)\n    doco_clean = doco_clean_at.replace('-', ' ')\n    doco_alphas = re.sub(r'\\W +', ' ', doco_clean)\n    trans_table = str.maketrans(punctuation, punc_replace)\n    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')])\n    doco_clean = doco_clean.split(' ')\n    p = re.compile(r'\\s*\\b(?=[a-z\\d]*([a-z\\d])\\1{3}|\\d+\\b)[a-z\\d]+', re.IGNORECASE)\n    doco_clean = ([p.sub(\"\", x).strip() for x in doco_clean])\n    doco_clean = [word.lower() for word in doco_clean if len(word) > 2]\n    doco_clean = ([i for i in doco_clean if i not in stop])\n#     doco_clean = [spell(word) for word in doco_clean]\n#     p = re.compile(r'\\s*\\b(?=[a-z\\d]*([a-z\\d])\\1{3}|\\d+\\b)[a-z\\d]+', re.IGNORECASE)\n    doco_clean = ([p.sub(\"\", x).strip() for x in doco_clean])\n#     doco_clean = ([spell(k) for k in doco_clean])\n    return doco_clean","4abd468f":"# Generate a cleaned reviews array from original review texts\nreview_cleans = [clean_document(doc) for doc in reviews];\nsentences = [' '.join(r) for r in review_cleans ]","f80dda7f":"print(sentences[7])","21b304f7":"print(reviews[7])","cd46d8a8":"reviews.shape\n# sentences.shape","88f66e68":"#Keras\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(sentences)","1cf62462":"text_sequences = np.array(tokenizer.texts_to_sequences(sentences))\nsequence_dict = tokenizer.word_index\nword_dict = dict((num, val) for (val, num) in sequence_dict.items())","4e936946":"print(text_sequences)","a2d28fe4":"print(sequence_dict)","e90e0ba5":"print(word_dict)","201a9336":"reviews_encoded = [];\nfor i,review in enumerate(review_cleans):\n    reviews_encoded.append([sequence_dict[x] for x in review]);","6b954308":"lengths = [len(x) for x in reviews_encoded]\nplt.hist(lengths, bins=range(25))","533c8b8f":"print(reviews_encoded[135])","8423b937":"max_cap =8;\nX = pad_sequences(reviews_encoded, maxlen=max_cap, truncating='post')","a3cda941":"Y = np.array([[0,1] if '0' in label else [1,0] for label in labels])","5b8df52a":"np.random.seed(1024);\nrandom_posits = np.arange(len(X))\nnp.random.shuffle(random_posits);","17169bb1":"X = X[random_posits];\nY = Y[random_posits];","2119602e":"train_cap = int(0.85 * len(X));\ndev_cap = int(0.93 * len(X));","0bddfeb1":"X_train, Y_train = X[:train_cap], Y[:train_cap]\nX_dev, Y_dev = X[train_cap:dev_cap], Y[train_cap:dev_cap]\nX_test1, Y_test1 = X[dev_cap:], Y[dev_cap:]","ab21fcbe":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import eval\nfrom keras.optimizers import Adam\nfrom keras.layers import LSTM\nfrom keras.layers.embeddings import Embedding\n\n\nmodel1 = Sequential();\nmodel1.add(Embedding(len(word_dict)+1, max_cap, input_length=max_cap));\n#adding a LSTM layer of dim 1--\nmodel1.add(LSTM(150, return_sequences=True));\nmodel1.add(LSTM(150, return_sequences=False));\n#adding a dense layer with activation function of relu\nmodel1.add(Dense(100, activation='relu', init='uniform'));#best 50,relu\n#adding the final output activation with activation function of softmax\nmodel1.add(Dense(2, activation='sigmoid', init='uniform'));\nprint(model1.summary());\noptimizer = Adam(lr=0.0001, decay=0.0001);\n\nmodel1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n# fit model and run it for 5 epochs\nmodel1.fit(X_train, Y_train, batch_size=16, epochs=5, validation_data=(X_dev, Y_dev))","f54af172":"score = model1.evaluate(X_test1, Y_test1)\nprint(\"Test accuracy: %0.4f%%\" % (score[1]*100))","452819b1":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\n\nf, ax = plt.subplots(figsize=(15, 10))\nsns.set_color_codes(\"pastel\")\nsns.barplot(y=\"reviews.rating\", x=\"No of Users\", data=review.iloc[:20, :10],label=\"Score\", color=\"pink\")\n\nax.legend(ncol=2, loc=\"upper left\", frameon=True)\nax.set(xlabel=\"No of People\",ylabel=\"Rating\")\nsns.despine(left=True, bottom=True)\nplt.show()","0271105e":"**support vector machine**","11fcbcbc":"**KNeighborsClassifier**","4b9082ad":"**Naive Bayes Classifier**","7e88bfe8":"**GradientBoostingClassifier**"}}