{"cell_type":{"ceba1184":"code","2bead79b":"code","54574d61":"code","b5399c01":"code","baef7ee3":"code","993e62ff":"code","97e6b7f8":"code","8c30faf8":"code","aa6318de":"code","c942000d":"code","97fa1c55":"code","019b58fe":"code","d043345b":"code","5b820f0e":"markdown","e5f342d7":"markdown","7a45da31":"markdown","457375a3":"markdown","e3cd13a0":"markdown","1d50f23f":"markdown","3eca2459":"markdown","4b17a21e":"markdown","5f0b07eb":"markdown","11269a0a":"markdown","fc6eccd5":"markdown","63d1ad20":"markdown","a0e9be31":"markdown","30ee4e69":"markdown","8b09270d":"markdown","ffbd5ce0":"markdown","c2498d5b":"markdown"},"source":{"ceba1184":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import VotingClassifier","2bead79b":"# Load dataset\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")\ndf.head()","54574d61":"care_cols =  ['Patient addmited to regular ward (1=yes, 0=no)',\\\n                'Patient addmited to semi-intensive unit (1=yes, 0=no)',\\\n                 'Patient addmited to intensive care unit (1=yes, 0=no)']\ndefault_hemogram = list(df.columns[6:20])\nspecialist_features = ['Lymphocytes', 'Neutrophils', 'Sodium', 'Potassium', 'Creatinine','Proteina C reativa mg\/dL']\n\nshort_labels = ['No care', 'Regular', 'Semi-Intensive', 'Intensive']\n\ncors = 'SARS-Cov-2 exam result'\n","b5399c01":"# Specialist feature visualization\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")\ndata = df[care_cols + specialist_features].dropna().to_numpy(copy=True)\n\ny_ = data[:,0:3]\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]\n\n# Lymphocytes vs. Neutrophils\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,0], X[idx,1], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Lymphocytes')\nplt.ylabel('Neutrophils')\nplt.show()\n\n# Lymphocytes vs. Neutrophils\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,2], X[idx,3], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Sodium')\nplt.ylabel('Potassium')\nplt.show()\n\n# Creatinine and PCR\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,4], X[idx,5], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Creatinine')\nplt.ylabel('Proteina C reativa mg\/dL')\nplt.show()","baef7ee3":"# Specialist feature visualization only for SARS-Cov-2 positives\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")\ndf_ = df[ df['SARS-Cov-2 exam result'] == 'positive']\ndata = df_[care_cols + specialist_features].dropna().to_numpy(copy=True)\n\ny_ = data[:,0:3]\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]\n\n# Lymphocytes vs. Neutrophils\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,0], X[idx,1], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Lymphocytes')\nplt.ylabel('Neutrophils')\nplt.show()\n\n# Lymphocytes vs. Neutrophils\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,2], X[idx,3], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Sodium')\nplt.ylabel('Potassium')\nplt.show()\n\n# Creatinine and PCR\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,4], X[idx,5], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Creatinine')\nplt.ylabel('Proteina C reativa mg\/dL')\nplt.show()\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]","993e62ff":"plt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,0], X[idx,5], alpha=0.6, label=short_labels[i])\nplt.legend()\nplt.xlabel('Lymphocites')\nplt.ylabel('Proteina C reativa mg\/dL')\nplt.show()\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]","97e6b7f8":"plt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(X[idx,0], X[idx,5], alpha=0.6, label=short_labels[i])\n    \nplt.plot([-2, 1, 1, -2, -2], [-0.4, -0.4, 3.5, 3.5, -0.4], 'r')\nplt.plot([1, 1], [-0.4, 1.5], 'r', label='Risk Boundaries')\n\nplt.legend()\nplt.xlabel('Lymphocites')\nplt.ylabel('Proteina C reativa mg\/dL')\nplt.show()\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]","8c30faf8":"# Base classification experiment\n\nskf = StratifiedKFold(n_splits=2)\n\nc = np.array([ [0, 0],[0,0]])\ny_gt = []\ny_pr = []\nfor train_index, test_index in skf.split(X, y):\n    X_train = X[train_index,:]\n    y_train = y[train_index]\n    X_test = X[test_index,:]\n    y_test = y[test_index]\n    \n    \n    #classifier = RandomForestClassifier(n_estimators=100, max_features=3, class_weight='balanced', criterion='entropy')\n    #classifier = LinearSVC(C=10, class_weight='balanced')\n    #classifier = SVC(C=10, class_weight='balanced', gamma='auto')\n    classifier = LogisticRegression(penalty='l2', C=10, class_weight='balanced')#{'negative': .1, 'positive': 1}, l1_ratio=0.5)\n    #classifier = GaussianNB()\n    classifier.fit(X_train, y_train)\n    y_ = classifier.predict(X_test)\n    y_gt += list(y_test)\n    y_pr += list(y_)\n\nc = confusion_matrix(y_gt, y_pr, labels=range(4))\nprint(classification_report(y_gt, y_pr, labels=range(4)))\nprint(c)","aa6318de":"# Two-label classification experiment\n\nskf = StratifiedKFold(n_splits=2)\n\nc = np.array([ [0, 0],[0,0]])\ny_gt = []\ny_pr = []\ny0 = y\ny0[y0>=1]=1\nfor train_index, test_index in skf.split(X, y0):\n    X_train = X[train_index,:]\n    y_train = y0[train_index]\n    X_test = X[test_index,:]\n    y_test = y0[test_index]\n    \n    \n    #classifier = RandomForestClassifier(n_estimators=100, max_features=3, class_weight='balanced', criterion='entropy')\n    #classifier = LinearSVC(C=10, class_weight='balanced')\n    #classifier = SVC(C=10, class_weight='balanced', gamma='auto')\n    classifier = LogisticRegression(penalty='l2', C=10, class_weight='balanced')#{'negative': .1, 'positive': 1}, l1_ratio=0.5)\n    #classifier = GaussianNB()\n    classifier.fit(X_train, y_train)\n    y_ = classifier.predict(X_test)\n    y_gt += list(y_test)\n    y_pr += list(y_)\n\n\nc = confusion_matrix(y_gt, y_pr, labels=range(2))\nprint(classification_report(y_gt, y_pr, labels=range(2)))\nprint(c)","c942000d":"# Hemogram data feature visualization\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")\ndata = df[care_cols + specialist_features].dropna().to_numpy(copy=True)\n\ny_ = data[:,0:3]\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]\n\nscaler = StandardScaler()\nscaler.fit(X)\nX_ = scaler.transform(X)\n\n# PCA visualization\npca = PCA(n_components=2)\nXpca = pca.fit_transform(X_)\n\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(Xpca[idx,0], Xpca[idx,1], alpha=0.6, label=short_labels[i])\n\nplt.title('PCA')\nplt.legend()\nplt.show()\n\n# t-SNE visualization\ntsne = TSNE(n_components=2)\nXtsne = tsne.fit_transform(X_)\n\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(Xtsne[idx,0], Xtsne[idx,1], alpha=0.6, label=short_labels[i])\n\nplt.title('t-SNE')\nplt.legend()\nplt.show()","97fa1c55":"# Hemogram data feature visualization for SARS-Cov-2-positives\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")\ndf_ = df[ df['SARS-Cov-2 exam result'] == 'positive']\ndata = df_[care_cols + specialist_features].dropna().to_numpy(copy=True)\n\ny_ = data[:,0:3]\ny = y_[:,0]\ny [y_[:,1]==1]=2\ny [y_[:,2]==1]=3\nX = data[:,3:]\n\n\nscaler = StandardScaler()\nscaler.fit(X)\nX_ = scaler.transform(X)\n\n# PCA visualization\npca = PCA(n_components=2)\nXpca = pca.fit_transform(X_)\n\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(Xpca[idx,0], Xpca[idx,1], alpha=0.6, label=short_labels[i])\n\nplt.title('PCA')\nplt.legend()\nplt.show()\n\n# t-SNE visualization\ntsne = TSNE(n_components=2, perplexity=3)\nXtsne = tsne.fit_transform(X_)\n\nplt.figure()\nfor i in range(len(short_labels)):\n    idx = np.where(y == i)[0]\n    plt.scatter(Xtsne[idx,0], Xtsne[idx,1], alpha=0.6, label=short_labels[i])\n\nplt.title('t-SNE')\nplt.legend()\nplt.show()","019b58fe":"skf = StratifiedKFold(n_splits=2)\n\nc = np.array([ [0, 0],[0,0]])\ny_gt = []\ny_pr = []\nfor train_index, test_index in skf.split(X, y):\n    X_train = X[train_index,:]\n    y_train = y[train_index]\n    X_test = X[test_index,:]\n    y_test = y[test_index]\n    \n    \n    #classifier = RandomForestClassifier(n_estimators=100, max_features=3, class_weight='balanced', criterion='entropy')\n    #classifier = LinearSVC(C=10, class_weight='balanced')\n    #classifier = SVC(C=10, class_weight='balanced', gamma='auto')\n    classifier = LogisticRegression(penalty='l2', C=10, class_weight='balanced')#{'negative': .1, 'positive': 1}, l1_ratio=0.5)\n    #classifier = GaussianNB()\n    classifier.fit(X_train, y_train)\n    y_ = classifier.predict(X_test)\n    y_gt += list(y_test)\n    y_pr += list(y_)\n\nc = confusion_matrix(y_gt, y_pr, labels=range(4))\nprint(classification_report(y_gt, y_pr, labels=range(4)))\nprint(c)","d043345b":"# Simplified classification experiment\n\nskf = StratifiedKFold(n_splits=2)\n\nc = np.array([ [0, 0],[0,0]])\ny_gt = []\ny_pr = []\ny0 = y\ny0[y0>=1]=1\nfor train_index, test_index in skf.split(X, y0):\n    X_train = X[train_index,:]\n    y_train = y0[train_index]\n    X_test = X[test_index,:]\n    y_test = y0[test_index]\n    \n    \n    #classifier = RandomForestClassifier(n_estimators=100, max_features=3, class_weight='balanced', criterion='entropy')\n    #classifier = LinearSVC(C=10, class_weight='balanced')\n    #classifier = SVC(C=10, class_weight='balanced', gamma='auto')\n    classifier = LogisticRegression(penalty='l2', C=10, class_weight='balanced')#{'negative': .1, 'positive': 1}, l1_ratio=0.5)\n    #classifier = GaussianNB()\n    classifier.fit(X_train, y_train)\n    y_ = classifier.predict(X_test)\n    y_gt += list(y_test)\n    y_pr += list(y_)\n\n\nc = confusion_matrix(y_gt, y_pr, labels=range(2))\nprint(classification_report(y_gt, y_pr, labels=range(2)))\nprint(c)","5b820f0e":"# Result summary\n\nThe table below summarizes the results in this notebook. We have the following methods:\n1. Threshold-based analysis of PCR and Lymphocites\n1. Logistic regression on PCR and Lymphocites\n1. Logistic regression on complete hemogram\n\nand the following error measures:\n1. Chance of not predicting the need of care to a patient that will need care (probability of false negatives - PFN)\n1. Chance of predicting the need of care to a patient that will not need care (probability of false positives - PFP)\n\n| Method | PFN | PFP |\n| --- | --- | --- |\n| 1 | 13\\% | 15\\% |\n| 2 | 24\\% | 6\\% |\n| 3 | 24\\% | 6\\% |\n\nWe also note that:\n\n1. The specific type of care required by the patient seems to relate to the PCR measure, but does not behave linearly towards it. It is likely that it is linked to other conditions of the patient's medical history.\n1. The accuracy of method 1 (threshold-based analysis of PCR and Lymphocites) is similar to that of others, which rely on more data; hence PCR and Lymphocites seem to be principal elements for estimating the severity of COVID-19.\n1. Moreover, method 1 is entirely transparent, and it is based on medical theory and clear data analysis.\n\n","e5f342d7":"# Visualization 2: data-driven hemogram analysis\n\nIn this visualization, we used machine learning tools to detecting symptom intensity from the full hemogram. This is a data-driven analysis, and, in this case, we use linear algebra tools rather than specialist knowledge.\n\nFirst, we provide two data scatter plots. The first uses PCA and the other uses t-SNE. PCA aims to find a low-dimension projection that allows reconstructing the original dataset with minimum distortion. t-SNE is a manifold learning tool that can be seen a sort of non-linear PCA that allows distortions. The distortion included by t-SNE is such that points that short distances in the original spaces are preserved, but large distances are distorted.","7a45da31":"# Dataset description and usage\n\nThe dataset we have in hands has two types of categorization for data points, which are: according to the presence\/abscense of the Sars-COV-2 pathogen, and according to the intensity of care dedicated to the patient (regular ward, semi-intensive care, and intensive care). The dataset was gathered at a hospital.\n\nThe data related to each patient is intensely irregular. Many patients have data related to a standard hemogram, which is a standard procedure for individuals treated under Brazil's public healthcare system. There are also data related to the presence of other pathogens, which is a standard procedure for individuals treated under private health insurance. Finally, there are some other data related to common, yet non-standard, features that can be analyzed in a blood test.\n\nThis means that the presence or abscence of data (that is, the data incompleteness) relates to socio-economic aspects of the patient. These aspects are not reported in the dataset, hence they cannot be considered here. To ensure that patients are treated equally, we are going to work with the following procedure:\n\n1. We choose feature subsets based on our knowledge of infection diseases\n1. We exclude all individuals that have incomplete data regarding these features (that is, we do *not* perform data imputation)\n\n","457375a3":"# Diagnosis of COVID-19 and its clinical spectrum\n# Task 2 - Predicting Disease Severity\n\nKaggle challenge. URL: https:\/\/www.kaggle.com\/einsteindata4u\/covid19\n\n## Summary of findings:\n\n* Dataset is highly irregular due to different treatment protocols applied to patients;\n* Disease severity seems to relate with Prote\u00edna C-Reativa (PCR) and Lymphocite measures, which are part of standard hemograms;\n* Subjects with low PCR and high Lymphocite measures have a smaller chance of requiring intensive care;\n* Dataset is too small to consider these findings generalizable and to reliably estimate the probability of requiring intensive care; \n* Medical history and other (concurrent or previous) diseases seem to play a key role in the symptom severity in infections.","e3cd13a0":"Although the blue (no care) points seem to gather in somewhat pure clusters, the others (related to different types of care) appear to be more mixed. It is possible that we can draw a classification experiment from this data.\n\n## Classification experiment\n\nOur classification experiment used a 2-fold cross validation protocol. The results for all folds were appended and used for further analysis.","1d50f23f":"It seems obvious that the risk rectangle should be open at the top and left.\n\n## Risk analysis\nWe can count the occurrences of each type of care within each region to estimate the risk related to them:\n\n### Inside the rectangle\n1. Risk of requiring intensive care: 20\\%\n1. Risk of requiring semi-intensive care: 20\\%\n1. Risk of requiring regular care: 47\\%\n1. Total risk for requiring care: 87\\%\n\n### Outside the rectange\n1. Risk of requiring intensive care: 0\\%\n1. Risk of requiring semi-intensive care: 0\\%\n1. Risk of requiring regular care: 15\\%\n1. Total risk for requiring special care: 15\\%","3eca2459":"## Analysis of Theoretically-Relevant Data Visualizations\n\nIt seems that we have got some interesting results here. When we visualize data without considering the pathogen test, then we see a fuzzy point cloud without any groupings. However, when we only consider patients that tested positive for the pathogen, then we see:\n\n1. Low lymphocite levels suggest a higher probability of more intensive care\n1. High PCR levels suggest a higher probability of more intensive care\n1. High Creatinine indicates a higher chance of requiring care, but this behavior is associated with high PCR\n\nThe conclusion regarding lymphocites can be due to the disease evolution timeline, as discussed before. The following tests will assume that all tests were performed at a consistent time (if they were not, then the results with lymphocites should be discarded) - maybe that time was when the first symptoms started appearing and the patient showed up at the hospital door?\n\n## Probability of requiring intensive or semi-intensive care\n\nNow, we will estimate the probability of requiring intensive and\/or semi-intensive care based on the PCR and the Lymphocite measures. Data is distributed as follows:","4b17a21e":"# Visualization 1: theoretically relevant features\n\nThe theoretically relevant features we have are the following:\n\n## Lymphocites and Neutrophils\n* Lymphocites: they tend to grow as a body response to virus infections\n* Neutrophils: they tend to grow as a response to bacterial infection\nIt is important to highly emphasize that the growth of these cells is not linear and depends on the infection time: first, they decrease, then they rise. The timeline is not available in the dataset.\n\n## Sodium and Potassium\nThey are related to active cell membrane transportations, which could be altered in the presence of specific types of infections.\n\n## Creatinine and PCR\n* Creatinine: tends to grow with age and can be used as an indicator liver malfunction, which is a pre-existing condition that could lead to more severe cases of COVID-19.\n* PCR: alterations in PCR happen in many cases of infections and other body disturbances.\n\n\n","5f0b07eb":"As we can see, there seems to be a \"normal\" behavior, which is when PCR is low. A high PCR is (numerically) related to a higher chance of requiring intensive care, unless the Lymphocite measure is high.\n\nNow, there is an important thing to consider here. If we choose to estimate a parametric distribution for this probability, then we should base our distribution function on actual epidemiology theory - it seems to be a stretch to assume that a Gaussian distribution (or a Gaussian Mixture Model) is enough, considering that there are so few data points here.\n\nThe best we can do is separate our data points in regions, and analyze these regions. In special, I want to call the attention to the following thresholds:\n1. $Lymphocites = 1.0$, above which only one subject required hospital care,\n1. $PCR = -0.4$, above which (granted that $Lymphocites < 1.0$) only one subject did not special care.\n\nHence, we can draw a rectangle that bounds the high-risk region for patients:","11269a0a":"The accuracy of this predictor is only 2\\% (one patient) higher than the predictor using two, specialist-selected features. If we simplify the experiment to use two labels (accept\/rejet patient), then we get:","fc6eccd5":"## Data-driven Classification experiment","63d1ad20":"The predictor only accept one patient erroneously, and erroneously suggested sending 7 patients home.\n\nThis strategy for prediction used data selected by specialists. Next, we evaluate a purely data-driven strategy for the same problem.","a0e9be31":"This result is similar to that obtained when using the three specialist-chosen features.","30ee4e69":"Although we cannot see any groupings in these plots, we can restrict our analysis to patients that tested positive for the pathogen, which gives us:\n\n","8b09270d":"These visualizations show overlapping point clouds for regular, semi-intensive, and intensive-care subjects.\n\nI will repeat these visualizations using only patients that tested positive for Sars-Cov-2:","ffbd5ce0":"These results are interesting. The predictor has a tendency of under-estimating the severity of the clinical outcomes. However, it never \"sent home\" anyone that required intensive care, which is a positive aspect. On the other hand, it did suggest sending home five subjects that required hospital care.\n\nAlso, it did suggest hospital care for four subjects that did not require it.\n\nWe hypothesize that the categories are confusing the predictor, because the data related to different care intensities in the previous plots was all scrambled. To evaluate this possibility, we reduced the data labels so that the predictor only had to decide between accepting patients or sending them home. The outcomes are as follows:","c2498d5b":"# Considerations\nIt is **very** important to consider that these assessments are being made:\n1. in a small dataset\n1. which was gathered without scientific rigour\n1. and gathered in a very specific hospital, in a specific geographic region of Brazil\n\nIf we had more data, we would be able to improve our analyses using better, parametric models. Then, threshold estimations and other model fittings could be performed with a higher precision, which is important for public health assessments.\n\nAlso, we stress that **these results regard patients that tested positive for SARS-Cov-2**. Although we believe that everyone in the planet will eventually test positive for such, these results **do not apply for patients that have not been tested**.\n\nWe note that we are using the type of care provided to the patient as a measurement of the intensity of symptoms. The dataset does not provide additional data like the specific symptoms shown by the patient (temperature evolution, blood pressure, etc.) nor disease outcomes (recovery vs. death rates, or time to recovery).\n\nFurthermore, the provided dataset completely ignores each patient's medical history, which is an extraordinary source of information for this type of diagnosis.\n\nHenceforth, the only thing we can responsibly conclude from this analysis is that **SARS-Cov-2-positive patients that have high PCR and low lymphocite measures have a greater tendency to require semi-intensive or intensive care**.\n\nAlthough we suggest some decision thresholds for these measures, they have been normalized for data anonymization."}}