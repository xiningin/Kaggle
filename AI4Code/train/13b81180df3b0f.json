{"cell_type":{"6ddaf8b1":"code","8f320067":"code","1a7914be":"code","993003ce":"code","06752a8e":"code","c3187eed":"code","a6cc8f69":"code","c48aca07":"code","56eccee9":"code","63a431cd":"code","238fb83c":"code","f165a448":"code","4309a0f1":"code","ff1e1704":"code","a820c725":"code","135b34b1":"code","47fe8a08":"code","069a6393":"code","d4b2d822":"code","265890f2":"code","eae0f852":"code","cb7529eb":"code","5fd8401d":"code","d7aafbe3":"code","7b3a809e":"code","f9b4eb0d":"code","17035ed1":"code","98eccfc9":"code","105f6261":"code","fc6945c8":"code","8ceec2e2":"code","ac487c73":"code","5304e1d7":"code","9032e61e":"code","31147d17":"markdown","83efc4d4":"markdown","f7359374":"markdown","84fba496":"markdown","6de9e83d":"markdown","ba4fdf4a":"markdown","f2f7892a":"markdown","bae0b1a8":"markdown"},"source":{"6ddaf8b1":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","8f320067":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","1a7914be":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","993003ce":"train.shape","06752a8e":"test.shape","c3187eed":"train.head()","a6cc8f69":"test.head()","c48aca07":"# Droing target column for the training set\nX_train = train.drop(labels = ['label'], axis = 1)\n\n# The target column\ny_train = train['label']","56eccee9":"y_train.value_counts()","63a431cd":"sns.countplot(y_train);","238fb83c":"X_train.isnull().sum().sum()\n# great no null values","f165a448":"y_train.isnull().sum().sum()","4309a0f1":"# scaling the data \nX_train = X_train \/ 255.00\ntest = test \/ 255.0","ff1e1704":"# Reshaping the data to 3 dimensions (height, width, canal)\nX_train = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","a820c725":"from keras.utils.np_utils import to_categorical\n\n# Encoding Labels\ny_train = to_categorical(y_train, num_classes = 10)","135b34b1":"y_train[0]","47fe8a08":"from sklearn.model_selection import train_test_split","069a6393":"# Spliting the training data to train and test \nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.1)","d4b2d822":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","265890f2":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","eae0f852":"model.summary()","cb7529eb":"from tensorflow.keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau","5fd8401d":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","d7aafbe3":"# Setting learning rate\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nepochs = 20\nbatch_size = 86","7b3a809e":"history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs,\n                   validation_data = (X_test, y_test), verbose = 2)","f9b4eb0d":"evaluation = model.evaluate(X_test,y_test)\nprint(\"validation_loss is {} , validation_acc is {}\".format(evaluation[0],evaluation[1]))","17035ed1":"df_loss_acc = pd.DataFrame(history.history)\ndf_loss=df_loss_acc[['loss','val_loss']]\ndf_acc=df_loss_acc[['accuracy','val_accuracy']]","98eccfc9":"df_loss.plot()","105f6261":"df_acc.plot()","fc6945c8":"y_predicted = model.predict(X_test)\ny_predicted[0]","8ceec2e2":"plt.matshow(X_test[0])","ac487c73":"np.argmax(y_predicted[0])","5304e1d7":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","9032e61e":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submissiom.csv\",index=False)","31147d17":"# Convolutional Model","83efc4d4":"visualizations of loss and accuracy ","f7359374":"- Each image of the numbers consist of 255 pixels so we deivde each one by 255 for Nueral Networks Later","84fba496":"-  converted the label column from 3 as a number to [0,0,0,1,0,0,0,0,0,0]","6de9e83d":"Preparing for confusion Matrix","ba4fdf4a":"- We reshaped the data to 3 dimensions (28px x 28px) instead of padnas DataFrame 1d vector 784 values\n- this will make the computations much faster\n ","f2f7892a":"As you can see it's working well","bae0b1a8":"- How CNN work\n- Each feature is like a mini-image\u2014a small two-dimensional array of values. Features match common aspects of the images. In the case of X images, features consisting of diagonal lines and a crossing capture all the important characteristics of most X\u2019s. These features will probably match up to the arms and center of any image of an X ,After doing this for every feature pixel in every convolutional layer and every weight in every fully connected layer, the new weights give an answer that works slightly better for that image. This is then repeated with each subsequent image in the set of labeled images.\n\n-This is great video by Codebasics he explained it well\n\nhttps:\/\/www.youtube.com\/watch?v=zfiSAzpy9NM&t=4s&ab_channel=codebasics"}}