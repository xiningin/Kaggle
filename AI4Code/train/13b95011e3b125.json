{"cell_type":{"18483b56":"code","e95fe8f4":"code","85b0e045":"code","96ee7fb2":"code","4d4d6448":"code","45264733":"code","e5f2e326":"code","7459cc56":"code","d89476fe":"code","7acd2462":"code","6b295ad3":"code","3d2ec52a":"code","5b3ff180":"code","57f20c00":"code","143ae14f":"code","6c8761c6":"code","3fbbed2b":"markdown","052edeb3":"markdown","4ee2ed78":"markdown","37bdbd04":"markdown","76f46003":"markdown","c69b6013":"markdown","7da79de6":"markdown","67cff106":"markdown","5eb34647":"markdown","d10be9e1":"markdown","9b713bcd":"markdown","afbe5f2f":"markdown","3f7c83d5":"markdown","fa6f757f":"markdown","93b7f7ef":"markdown","a3f455c0":"markdown","403b8999":"markdown","2f591942":"markdown"},"source":{"18483b56":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt","e95fe8f4":"# get pandas dataframes\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nsell_prices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nsales_train = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\n\n# check shapes\nprint(\"calendar: {0}\\nsell_prices: {1}\\nsales_train: {2}\".format(calendar.shape, sell_prices.shape, sales_train.shape))","85b0e045":"def reduce_mem_usage(df, var):\n    \n    # get memory usage before conversion (in Mb)\n    mem_before = df.memory_usage().sum() \/ 1024 ** 2\n    \n    # get integer and float columns\n    int_columns = df.select_dtypes(include=[\"int\"]).columns\n    float_columns = df.select_dtypes(include=[\"float\"]).columns\n\n    # reduce integer columns\n    for col in int_columns:\n        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n\n    # reduce float columns\n    for col in float_columns:\n        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n\n    # get memory usage after conversion (in Mb)\n    mem_after = df.memory_usage().sum() \/ 1024 ** 2\n    # difference before --> after\n    mem_diff = 100 * (mem_before - mem_after) \/ mem_before\n    \n    print(\"{} decreased from {:.2f} Mb to {:.2f} Mb --> ({:.1f}% reduction)\".format(var, mem_before, mem_after, mem_diff))\n    \n    return df\n\ncalendar = reduce_mem_usage(calendar, 'Calendar')\nsell_prices = reduce_mem_usage(sell_prices, 'Sell prices')\nsales_train = reduce_mem_usage(sales_train, 'Sales train')","96ee7fb2":"calendar.head(5)","4d4d6448":"sell_prices.head(5)","45264733":"sales_train.head(5)","e5f2e326":"# columns of sales data\nd_cols = [c for c in sales_train.columns if 'd_' in c]\n    \n# item-wise sum of all sales\nsum_sales = sales_train[d_cols].sum(axis=1)\nmin_sales_ID = sum_sales.idxmin()\nmax_sales_ID = sum_sales.idxmax()\n\n# plotting function\ndef plot_item_sales(ID):\n    item = sales_train.loc[sales_train['id']==sales_train.iloc[ID]['id']] # select item (row)\n    item = item[d_cols] # get only the columns representing the sales time series\n    item = pd.DataFrame([calendar['date'][:1913], item.iloc[0,:].reset_index(drop=True)], index=['date', 'sales']).T\n    item = item.set_index('date')\n    item.plot(figsize=(14,4), title=sales_train.iloc[ID]['id'], legend=None) # plot time series\n\n# plotting\nplot_item_sales(min_sales_ID)\nplot_item_sales(max_sales_ID)\nplt.show()","7459cc56":"# get indices for items sold in each state\nCA = sales_train[sales_train['state_id']=='CA'].index\nTX = sales_train[sales_train['state_id']=='TX'].index\nWI = sales_train[sales_train['state_id']=='WI'].index\n\n# get corresponding sales data\nsales_CA = sales_train.iloc[CA][d_cols]\nsales_TX = sales_train.iloc[TX][d_cols]\nsales_WI = sales_train.iloc[WI][d_cols]\n\n# compare total sales between states\ntotal_CA = sales_CA.sum().sum()\ntotal_TX = sales_TX.sum().sum()\ntotal_WI = sales_WI.sum().sum()\n\nplt.figure(figsize=(8,4))\nsns.set_style('white', {'axes.spines.top': False, 'axes.spines.right': False})\nsns.barplot([total_CA, total_TX, total_WI], ['CA', 'TX', 'WI'], palette=['gold', 'red', 'green']).set_title('Total sales')\nplt.show()","d89476fe":"sales_CA = pd.DataFrame([calendar['date'][:1913], sales_CA.sum().reset_index(drop=True)], index=['date', 'sales']).T\nsales_CA_date = sales_CA.set_index('date')\nsales_CA_date.plot(figsize=(15,3), title='California', color='gold', legend=None)\n\nsales_TX = pd.DataFrame([calendar['date'][:1913], sales_TX.sum().reset_index(drop=True)], index=['date', 'sales']).T\nsales_TX_date = sales_TX.set_index('date')\nsales_TX_date.plot(figsize=(15,3), title='Texas', color='red', legend=None)\n\nsales_WI = pd.DataFrame([calendar['date'][:1913], sales_WI.sum().reset_index(drop=True)], index=['date', 'sales']).T\nsales_WI_date = sales_WI.set_index('date')\nsales_WI_date.plot(figsize=(15,3), title='Wisconsin', color='green', legend=None)\nplt.show()","7acd2462":"# select a dip\nsales_CA_frac = sales_CA[300:400]\n\n# get row representing the minimum (dip)\nsales_CA_frac[sales_CA_frac['sales']==sales_CA_frac['sales'].min()]\n\n# check in plot\nsales_CA_frac.plot(figsize=(15,3), title='California', color='gold', legend=None)\nplt.plot([330, 330], [0, 20000], color='k', alpha=0.5, label='2011-12-25')\nplt.legend()\nplt.show()","6b295ad3":"# get all Christmas dates\nchristmas_dates = [i for i in sales_CA['date'] if '12-25' in i]\n# get their indices\ninds = [sales_CA[sales_CA['date']==i].index[0] for i in christmas_dates]\n\n# check dips over entire time series of sales\nsales_CA_date.plot(figsize=(15,3), title='California', color='gold', label='sales')\nfor i, ind in enumerate(inds):\n    plt.plot([ind, ind], [0, 25000], color='k', alpha=0.3, label = christmas_dates[i])\nplt.legend(loc=3)\nplt.show()","3d2ec52a":"# looking at categories\nprint('Unique categories: {}'.format(set(sales_train['cat_id'])))","5b3ff180":"# get HOBBIES items per state\nhobbies_CA = sales_train.iloc[CA][sales_train.iloc[CA]['cat_id']=='HOBBIES'][d_cols].sum().sum()\nhobbies_TX = sales_train.iloc[TX][sales_train.iloc[TX]['cat_id']=='HOBBIES'][d_cols].sum().sum()\nhobbies_WI = sales_train.iloc[WI][sales_train.iloc[WI]['cat_id']=='HOBBIES'][d_cols].sum().sum()\n\n# get FOODS items per state\nfoods_CA = sales_train.iloc[CA][sales_train.iloc[CA]['cat_id']=='FOODS'][d_cols].sum().sum()\nfoods_TX = sales_train.iloc[TX][sales_train.iloc[TX]['cat_id']=='FOODS'][d_cols].sum().sum()\nfoods_WI = sales_train.iloc[WI][sales_train.iloc[WI]['cat_id']=='FOODS'][d_cols].sum().sum()\n\n# get HOUSEHOLD items per state\nhousehold_CA = sales_train.iloc[CA][sales_train.iloc[CA]['cat_id']=='HOUSEHOLD'][d_cols].sum().sum()\nhousehold_TX = sales_train.iloc[TX][sales_train.iloc[TX]['cat_id']=='HOUSEHOLD'][d_cols].sum().sum()\nhousehold_WI = sales_train.iloc[WI][sales_train.iloc[WI]['cat_id']=='HOUSEHOLD'][d_cols].sum().sum()\n\nfig, axs = plt.subplots(1, 3, sharey=True, figsize=(20,5))\naxs[0] = sns.barplot(['CA', 'TX', 'WI'], [hobbies_CA, hobbies_TX, hobbies_WI], palette=['gold', 'red', 'green'], orient='v', ax=axs[0]).set_title('HOBBIES sales')\naxs[1] = sns.barplot(['CA', 'TX', 'WI'], [foods_CA, foods_TX, foods_WI], palette=['gold', 'red', 'green'], orient='v', ax=axs[1]).set_title('FOODS sales')\naxs[2] = sns.barplot(['CA', 'TX', 'WI'], [household_CA, household_TX, household_WI], palette=['gold', 'red', 'green'], orient='v', ax=axs[2]).set_title('HOUSEHOLD sales')\nplt.show()","57f20c00":"# get unique store IDs\nstores = sorted(list(set(sales_train['store_id'])))\nstores","143ae14f":"# plot time series of total sales of each store\ndef sales_per_store():\n    \n    fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(16,20), sharey=True)\n    \n    for i, store in enumerate(stores):\n        \n        # compute total sales per store\n        indices = sales_train[sales_train['store_id']==store].index\n        sales_of_store = sales_train.iloc[indices][d_cols].sum()\n        sales_of_store = pd.DataFrame([calendar['date'][:1913], sales_of_store.reset_index(drop=True)], index=['date', 'sales']).T\n        sales_of_store = sales_of_store.set_index('date')\n        \n        # for subplots\n        r = int(i\/2) if i%2 == 0 else int(i\/2-0.5)\n        c = 0 if i%2 == 0 else 1\n        \n        # set color\n        if 'CA' in store:\n            color = 'gold'\n        elif 'TX' in store:\n            color = 'red'\n        elif 'WI' in store:\n            color = 'green'\n    \n        # plot\n        sales_of_store.plot(ax=axes[r,c], color=color, title=store, legend=None, rot=20)\n        \n    plt.subplots_adjust(hspace=0.7)\n\nsales_per_store()","6c8761c6":"# bar plot of total sales per store\nall_sales, color = [], []\n\nfor i, store in enumerate(stores):\n    # compute total sales per store\n    indices = sales_train[sales_train['store_id']==store].index\n    sales_of_store = sales_train.iloc[indices][d_cols].sum().sum()\n    all_sales.append(sales_of_store)\n    \n    # set color\n    if 'CA' in store:\n        color.append('gold')\n    elif 'TX' in store:\n        color.append('red')\n    elif 'WI' in store:\n        color.append('green')\n    \nfig, axs = plt.subplots(1, 2, sharey=True, figsize=(18,6))\naxs[0].bar(stores, all_sales, color=color)\naxs[0].set_title('Individual store sales')\naxs[1].bar(['CA', 'TX', 'WI'], [np.mean(all_sales[:4]), np.mean(all_sales[4:7]), np.mean(all_sales[7:])], color=['gold', 'red', 'green'])\naxs[1].set_title('Average store sales per state')\nplt.show()","3fbbed2b":"This dip occurs on Christmas day 2011. Let's double check if this is true for the other years as well.","052edeb3":"This notebook will grow over time as I continue with my analysis. So far, I've only been looking at total sales between states and stores.","4ee2ed78":"**Takeaways:**\n\n- FOODS clearly sells the most items, followed by HOUSEHOLD and lastly HOBBIES","37bdbd04":"## Total sales per state","76f46003":"#### Sales train","c69b6013":"#### Calendar","7da79de6":"Interestingly, there are these periodic dips in sales that occur at the same time across all three states. \n\nLet's take a closer look:","67cff106":"## Total sales per store","5eb34647":"## Reduce memory usage","d10be9e1":"**Takeaways:**\n\n- Apart from the dips at Christmas day, stores show additional dips that seem to be non-period and not across all stores\n- This could perhaps be state holidays\n- CA_3 shows a big increase around April 2015\n- Texas store show a spike up around March\/April 2015\n- WI_1 and WI_2 show sudden increases in sales around May\/June 2012","9b713bcd":"## Total sales per category","afbe5f2f":"## Load data and get shapes","3f7c83d5":"**Takeaways:**\n\n- California has the most total sales, followed by Texas and Wisconsin\n- Texas and Wisconsin have roughly 2\/3 of California's total sales","fa6f757f":"## Least sold and most sold items","93b7f7ef":"**Takeaways:**\n\n- Spikes in sales on certain dates\n- Periods of zero in between --> possibly items out of stock","a3f455c0":"**Takeaways:**\n\n- It appears as though these dips are caused by the closure of stores every year on Christmas day\n- There are also dips a few weeks before Christmas day\n- Sales seem to be highest in the summer, then go down over Christmas, and then start going up again in the new year","403b8999":"## Take a peek","2f591942":"#### Sell prices"}}