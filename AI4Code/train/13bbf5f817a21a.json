{"cell_type":{"3e06326b":"code","465f296e":"code","7b10c944":"code","e8884760":"code","866858fa":"code","2e7b4cc9":"code","7b56cb1b":"code","cacf681a":"markdown","0da29874":"markdown","17d06f17":"markdown"},"source":{"3e06326b":"mod_path = '..\/input\/hubmap-train-model\/'\nimport yaml\nimport pprint\nwith open(mod_path+'params.yaml') as file:\n    P = yaml.load(file, Loader=yaml.FullLoader)\n    pprint.pprint(P)\n    \nTHRESHOLD = 0.4 # preds > THRESHOLD\nWINDOW = 1024\nMIN_OVERLAP = 300\nNEW_SIZE = P['DIM'] #512\n\nSUBMISSION_MODE = 'FULL' \n# 'PUBLIC_TFREC' = use created tfrecords for public test set with MIN_OVERLAP = 300 tiling 1024-512, ignore other (private test) data\n# 'FULL' do not use tfrecords, just full submission \n\nCHECKSUM = False # compute mask sum for each image","465f296e":"# ! pip install ..\/input\/kerasapplications\/keras-team-keras-applications-3b180cb -f .\/ --no-index -q\n# ! pip install segmentation_models -q\n# ! pip install \"..\/input\/segmentation-models\"\n\nimport sys, os\nfrom shutil import copyfile, copytree\nsys.path.append('..\/input\/segmentation-models\/segmentation_models')\n# ! pip install ..\/input\/segmentation-models\n\n! pip install ..\/input\/kerasapplications\/keras-team-keras-applications-3b180cb -f .\/ --no-index -q\n# ! pip install ..\/input\/efficientnet\/efficientnet-1.1.0\/ -f .\/ --no-index -q\n! pip install ..\/input\/imageclassifiers -f .\/ --no-index -q\n! pip install ..\/input\/efficientnet100 -f .\/ --no-index -q\n! pip install ..\/input\/segmentation-models -f .\/ --no-index -q\n\n# copy our file into the working directory (make sure it has .py suffix)\n# copyfile(src = \"..\/input\/segmentation-models\/segmentation_models\/losses.py\", dst = \"..\/working\/losses.py\")\n# copytree(src = \"..\/input\/segmentation-models\/segmentation_models\", dst = \"..\/working\/segmentation_models\")","7b10c944":"import numpy as np\nimport pandas as pd\nimport glob\nimport gc\n\nimport rasterio\nfrom rasterio.windows import Window\n\nimport pathlib\nfrom tqdm.notebook import tqdm\nimport cv2\n\nimport tensorflow as tf\nimport efficientnet as efn\nimport efficientnet.tfkeras\n\nfrom tensorflow.keras.utils import get_custom_objects\n\nos.environ['SM_FRAMEWORK'] = 'tf.keras'\n\nimport segmentation_models as sm","e8884760":"def rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_grid(shape, window=256, min_overlap=32):\n    \"\"\"\n        Return Array of size (N,4), where N - number of tiles,\n        2nd axis represente slices: x1,x2,y1,y2 \n    \"\"\"\n    x, y = shape\n    nx = x \/\/ (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    ny = y \/\/ (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n    \n    for i in range(nx):\n        for j in range(ny):\n            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx*ny,4)\n\ndef dice_coe(output, target, axis = None, smooth=1e-10):\n    output = tf.dtypes.cast( tf.math.greater(output, 0.5), tf. float32 )\n    target = tf.dtypes.cast( tf.math.greater(target, 0.5), tf. float32 )\n    inse = tf.reduce_sum(output * target, axis=axis)\n    l = tf.reduce_sum(output, axis=axis)\n    r = tf.reduce_sum(target, axis=axis)\n\n    dice = (2. * inse + smooth) \/ (l + r + smooth)\n    dice = tf.reduce_mean(dice, name='dice_coe')\n    return dice\n\n# https:\/\/www.kaggle.com\/bigironsphere\/loss-function-library-keras-pytorch#BCE-Dice-Loss\ndef dice_loss(y_true, y_pred, axis = None, smooth=1e-10):\n#     y_pred = tf.dtypes.cast( tf.math.greater(y_pred, 0.5), tf. float32 ) # THIS IS NOT DIFFERENTIABLE!!!\n#     y_true = tf.dtypes.cast( tf.math.greater(y_true, 0.5), tf. float32 )\n    inse = tf.reduce_sum(y_pred * y_true, axis=axis)\n    l = tf.reduce_sum(y_pred, axis=axis)\n    r = tf.reduce_sum(y_true, axis=axis)\n\n    dice = (2. * inse + smooth) \/ (l + r + smooth)\n    dice = tf.reduce_mean(dice)\n    \n    return 1 - dice\n\n# lovasz loss\ndef symmetric_lovasz(y_pred, y_true):\n    return 0.5*(lovasz_hinge(y_pred, y_true) + lovasz_hinge(-y_pred, 1.0 - y_true))\n\n\n# https:\/\/www.kaggle.com\/kool777\/training-hubmap-eda-tf-keras-tpu\n# tversky loss\ndef tversky(y_true, y_pred, alpha=0.7, beta=0.3, smooth=1):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    return (true_pos + smooth) \/ (true_pos + alpha * false_neg + beta * false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true, y_pred)\n\ndef focal_tversky_loss(y_true, y_pred, gamma=0.75): # experiment with different values of gamma\n    tv = tversky(y_true, y_pred)\n    return K.pow((1 - tv), gamma)\n\ndef FocalLoss(targets, inputs, alpha=0.8, gamma=2):    \n    \n    inputs = K.flatten(inputs)\n    targets = K.flatten(targets)\n    \n    BCE = K.binary_crossentropy(targets, inputs)\n    BCE_EXP = K.exp(-BCE)\n    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n    \n    return focal_loss\n\n# Try Dice + topK loss\n\n# Try Dice + Focal loss\ndef dice_focal(ytrue, ypred):\n    return FocalLoss(ytrue, ypred) + dice_loss(ytrue, ypred)\n\nget_custom_objects().update({\"dice\": dice_loss})\n# get_custom_objects().update({\"lovasz\": symmetric_lovasz})\nget_custom_objects().update({\"tversky\": tversky_loss})\nget_custom_objects().update({\"focal_tversky\": focal_tversky_loss})\nget_custom_objects().update({\"binary_focal_loss_plus_dice_loss\": sm.losses.binary_focal_dice_loss})","866858fa":"identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n# fold_models = []\n# for fold_model_path in glob.glob(mod_path+'*.h5'):\n#     fold_models.append(tf.keras.models.load_model(fold_model_path,compile = False))\n# print(len(fold_models))\n\n# model_file = mod_path + \"ek-model-focal-dice-512.h5\"\n# model_file = mod_path + \"ek-model-dice_loss-512.h5\"\n# model_file = mod_path+\"ek-model-focal-tversky-bs4-512.h5\"\n# model_file = mod_path + \"ek-model-focal-dice-bs16-512.h5\"\n\nmodel_file = \"..\/input\/focaltversky-bs16-efficientneth5\/ek-model-focal-tversky-512.h5\"\nmodel_efficientnet = tf.keras.models.load_model(model_file, custom_objects={'dice_coe':dice_coe, 'focal_tversky_loss':focal_tversky_loss})\n\nmodel_file = \"..\/input\/focaltversky-bs16-vgg16h5\/ah-vgg16-focal-tversky-bs16-512.h5\"\nmodel_vgg = tf.keras.models.load_model(model_file, custom_objects={'dice_coe':dice_coe, 'focal_tversky_loss':focal_tversky_loss})\n\nmodels = [model_efficientnet, model_vgg]\n# models = [model_vgg]","2e7b4cc9":"p = pathlib.Path('..\/input\/hubmap-kidney-segmentation')\nsubm = {}\n\nfor i, filename in tqdm(enumerate(p.glob('test\/*.tiff')), \n                        total = len(list(p.glob('test\/*.tiff')))):\n    print(f'{i+1} Predicting {filename.stem}')\n    \n    dataset = rasterio.open(filename.as_posix(), transform = identity)\n    preds = np.zeros(dataset.shape, dtype=np.uint8)    \n\n    slices = make_grid(dataset.shape, window=WINDOW, min_overlap=MIN_OVERLAP)\n\n    for (x1,x2,y1,y2) in slices:\n        image = dataset.read([1,2,3],\n                    window=Window.from_slices((x1,x2),(y1,y2)))\n        image = np.moveaxis(image, 0, -1)\n        image = cv2.resize(image, (NEW_SIZE, NEW_SIZE),interpolation = cv2.INTER_AREA)\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        image = np.expand_dims(image, 0)\n        \n        pred = None\n        \n        # MEAN\n#         for model in models:\n#             raw_pred = model.predict(image)\n#             if pred is None:\n#                 pred =  np.squeeze(raw_pred)\n#             else:\n#                 pred += np.squeeze(raw_pred)\n        \n#         # Mean of predictions\n#         pred = pred\/len(models)\n        \n#         pred = cv2.resize(pred, (WINDOW, WINDOW))\n#         preds[x1:x2,y1:y2] += (pred > THRESHOLD).astype(np.uint8)\n\n        # AT LEAST ONE\n        for model in models:\n            raw_pred = model.predict(image)\n            pred =  np.squeeze(raw_pred)\n            pred = cv2.resize(pred, (WINDOW, WINDOW))\n            preds[x1:x2,y1:y2] += (pred > THRESHOLD).astype(np.uint8)\n        \n    preds = (preds > 0.5).astype(np.uint8)\n    print(preds.shape)\n    \n    subm[i] = {'id':filename.stem, 'predicted': rle_encode_less_memory(preds)}\n    \n    if CHECKSUM:\n        print('Checksum: '+ str(np.sum(preds)))\n    \n    del preds\n    gc.collect();","7b56cb1b":"submission = pd.DataFrame.from_dict(subm, orient='index')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","cacf681a":"# Inference and submission notebook for competition\n## Reference: https:\/\/www.kaggle.com\/wrrosa\/hubmap-tf-with-tpu-efficientunet-512x512-subm","0da29874":"# Load model","17d06f17":"# Make the submission"}}