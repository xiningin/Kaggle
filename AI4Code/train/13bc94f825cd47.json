{"cell_type":{"568f6cd3":"code","98bbd561":"code","c2b4663d":"code","b25610b3":"code","53f47bd4":"code","457cd6ad":"code","21369b13":"code","9e283423":"code","2bc34032":"code","632a3555":"code","44d49bb0":"code","cec40aee":"code","060f09cb":"code","dc64f829":"code","fee4b5d4":"code","e4e99708":"code","f5dfbc93":"code","d33adcd0":"code","4ee698e9":"code","1250f4fc":"code","9c762843":"code","c23d0b6f":"code","dc2df6b3":"code","a3f47453":"code","2079e885":"code","bb8bd07c":"code","3337c469":"code","b916a322":"code","8d4f23b2":"markdown","1980f8b9":"markdown","4d84e7fc":"markdown","ad65daec":"markdown","a5887fe2":"markdown","0289b97a":"markdown","2c35be75":"markdown","b2ed65ea":"markdown","a2679471":"markdown","8456f88c":"markdown","b7e9e424":"markdown","89e0e56d":"markdown","73dffda3":"markdown","21f6f04e":"markdown","80bda272":"markdown","5ee1be56":"markdown","b1d085af":"markdown"},"source":{"568f6cd3":"# Core\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom itertools import combinations\nimport statistics\nimport time\nfrom datetime import datetime\nimport matplotlib.dates as mdates\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression\n\n# Models\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\n# Tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks","98bbd561":"# Save to df\ntrain_data=pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv', index_col='row_id')\ntest_data=pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv', index_col='row_id')\n\n# Shape and preview\nprint('Training data df shape:',train_data.shape)\nprint('Test data df shape:',test_data.shape)\ntrain_data.head()","c2b4663d":"# concise summary of dataset\ntrain_data.info()","b25610b3":"#LOOK AT THE COLUMNS OF TRAIN DATASET AND TEST DATASET.\nprint(train_data.columns)\nprint(test_data.columns)","53f47bd4":"train_data.isnull().sum()","457cd6ad":"print('Training data:')\nprint('Min date', train_data['date'].min())\nprint('Max date', train_data['date'].max())\nprint('')\nprint('Test data:')\nprint('Min date', test_data['date'].min())\nprint('Max date', test_data['date'].max())","21369b13":"sns.displot(data=train_data,x='num_sold')","9e283423":"sns.countplot(x=\"country\",data=train_data)","2bc34032":"sns.countplot(x=\"store\",data=train_data)","632a3555":"sns.countplot(x=\"product\",data=train_data)","44d49bb0":"'''KaggleMart'''\n# Find number of products sold in each day, according to country\ntrain_groupby_finland_KM=train_data[(train_data.country=='Finland') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_norway_KM=train_data[(train_data.country=='Norway') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_sweden_KM=train_data[(train_data.country=='Sweden') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\n\n'''KaggleRama'''\n# Find number of products sold in each day, according to country\ntrain_groupby_finland_KR=train_data[(train_data.country=='Finland') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_norway_KR=train_data[(train_data.country=='Norway') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_sweden_KR=train_data[(train_data.country=='Sweden') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))","cec40aee":"# Figure with 2 subplots\nfig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\n# Overall title\nfig.suptitle('Total sales according to country')\n\n# Subplot 1\nsns.lineplot(ax=axes[0], data=train_groupby_finland_KM, x='date',y='num_sold', label='Finland')\nsns.lineplot(ax=axes[0], data=train_groupby_norway_KM, x='date',y='num_sold', label='Norway')\nsns.lineplot(ax=axes[0], data=train_groupby_sweden_KM, x='date',y='num_sold', label='Sweden')\naxes[0].set_title('\\n Kaggle Mart')\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())\nplt.legend()\n\n# Subplot 2\nsns.lineplot(ax=axes[1], data=train_groupby_finland_KR, x='date',y='num_sold', label='Finland')\nsns.lineplot(ax=axes[1], data=train_groupby_norway_KR, x='date',y='num_sold', label='Norway')\nsns.lineplot(ax=axes[1], data=train_groupby_sweden_KR, x='date',y='num_sold', label='Sweden')\naxes[1].set_title('\\n Kaggle Rama')\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())\nplt.legend()","060f09cb":"'''KaggleMart'''\n# Find number of products sold in each day, according to product\ntrain_groupby_mug_KM=train_data[(train_data['product']=='Kaggle Mug') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_hat_KM=train_data[(train_data['product']=='Kaggle Hat') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_sticker_KM=train_data[(train_data['product']=='Kaggle Sticker') & (train_data['store']=='KaggleMart')].groupby('date').agg(num_sold=('num_sold','sum'))\n\n'''KaggleRama'''\n# Find number of products sold in each day, according to country\ntrain_groupby_mug_KR=train_data[(train_data['product']=='Kaggle Mug') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_hat_KR=train_data[(train_data['product']=='Kaggle Hat') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))\ntrain_groupby_sticker_KR=train_data[(train_data['product']=='Kaggle Sticker') & (train_data['store']=='KaggleRama')].groupby('date').agg(num_sold=('num_sold','sum'))","dc64f829":"# Figure with 2 subplots\nfig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\n# Overall title\nfig.suptitle('Total sales according to product type', fontsize=15)\n\n# Subplot 1\nsns.lineplot(ax=axes[0], data=train_groupby_mug_KM, x='date',y='num_sold', label='Mug')\nsns.lineplot(ax=axes[0], data=train_groupby_hat_KM, x='date',y='num_sold', label='Hat')\nsns.lineplot(ax=axes[0], data=train_groupby_sticker_KM, x='date',y='num_sold', label='Sticker')\naxes[0].set_title('\\n Kaggle Mart')\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())\nplt.legend()\n\n# Subplot 2\nsns.lineplot(ax=axes[1], data=train_groupby_mug_KR, x='date',y='num_sold', label='Mug')\nsns.lineplot(ax=axes[1], data=train_groupby_hat_KR, x='date',y='num_sold', label='Hat')\nsns.lineplot(ax=axes[1], data=train_groupby_sticker_KR, x='date',y='num_sold', label='Sticker')\naxes[1].set_title('\\n Kaggle Rama')\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())\nplt.legend()","fee4b5d4":"# Labels\ny=train_data.num_sold\n\n# Features\nX=train_data.drop('num_sold', axis=1)\n\n# Convert date to 'actual' datetime\nX.date=pd.to_datetime(X.date)\ntest_data.date=pd.to_datetime(test_data.date)","e4e99708":"holiday_path = '..\/input\/holiday-and-special-day\/Holidays_Finland_Norway_Sweden_2015-2019_edit.csv'\n\ndef GetHoliday(holiday_path, df):\n    \"\"\"\n    Get a boolean feature of whether the current row is a holiday sale\n    \"\"\"\n    \n    holiday = pd.read_csv(holiday_path)\n    fin_holiday = holiday.loc[holiday.Country == 'Finland']\n    swe_holiday = holiday.loc[holiday.Country == 'Sweden']\n    nor_holiday = holiday.loc[holiday.Country == 'Norway']\n    df['fin holiday'] = df.date.isin(fin_holiday.Date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.Date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.Date).astype(int)\n    \n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    return df\n\n#X = GetHoliday(holiday_path, X)\n#test_data = GetHoliday(holiday_path, test_data)","f5dfbc93":"hol_path = '..\/input\/public-and-unofficial-holidays-nor-fin-swe-201519\/holidays.csv'\n\ndef unofficial_hol(hol_path, df):\n    countries = {'Finland': 1, 'Norway': 2, 'Sweden': 3}\n    stores = {'KaggleMart': 1, 'KaggleRama': 2}\n    products = {'Kaggle Mug': 1,'Kaggle Hat': 2, 'Kaggle Sticker': 3}\n    \n    # load holiday info.\n    holiday = pd.read_csv(hol_path)\n    \n    fin_holiday = holiday.loc[holiday.country == 'Finland']\n    swe_holiday = holiday.loc[holiday.country == 'Sweden']\n    nor_holiday = holiday.loc[holiday.country == 'Norway']\n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    return df\n\nX = unofficial_hol(hol_path, X)\ntest_data = unofficial_hol(hol_path, test_data)","d33adcd0":"def date_feat_eng(df):\n    #df['day_dummy'] = np.arange(len(df.index))      # 0, 1, 2...\n    df['day_of_week']=df['date'].dt.dayofweek       # 0 to 6\n    df['day_of_month']=df['date'].dt.day            # 1 to 31\n    df['weekend']=(df['day_of_week']\/\/5 == 1)       # 0 or 1\n    df['weekend']=df['weekend'].astype('int')       # int64\n    df['week']=df['date'].dt.isocalendar().week     # 1 to 53\n    df['week'][df['week']>52]=52                    # 1 to 52\n    df['week']=df['week'].astype('int')             # int64\n    df['month']=df['date'].dt.month                 # 1 to 12\n    df['quarter']=df['date'].dt.quarter             # 1 to 4\n    df['year']=df['date'].dt.year                   # 2015 to 2019\n    df.drop('date',axis=1, inplace=True)            # drop date\n    return df\n\nX= date_feat_eng(X)\ntest_data=date_feat_eng(test_data)\n","4ee698e9":"# Load data\nGDP_data = pd.read_csv(\"..\/input\/gdp-20152019-finland-norway-and-sweden\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv\",index_col=\"year\")\n\n# Rename the columns in GDP df \nGDP_data.columns = ['Finland', 'Norway', 'Sweden']\n\n# Plot data\nplt.figure(figsize=(8,5))\n\n# Heatmap with annotations\nsns.heatmap(GDP_data, annot=True, fmt='g', cmap='Blues')\n\n# Aesthetics\nplt.title('Heatmap of GDP in nordic countries')","1250f4fc":"# Create a dictionary\nGDP_dictionary = GDP_data.unstack().to_dict()\n\n# Create new GDP column\n#X['GDP'] = X.set_index(['country', 'year']).index.map(GDP_dictionary.get)\n#test_data['GDP'] = test_data.set_index(['country', 'year']).index.map(GDP_dictionary.get)","9c762843":"# Load data\nGDP_PC=pd.read_csv('..\/input\/gdp-per-capita-finland-norway-sweden-201519\/GDP_per_capita_2015_to_2019_Finland_Norway_Sweden.csv',index_col=\"year\")\n\n# Similar to above (GDP)\nGDP_PC_dictionary = GDP_PC.unstack().to_dict()\n\n# Create new GDP_PC column\nX['GDP_PC'] = X.set_index(['country', 'year']).index.map(GDP_PC_dictionary.get)\ntest_data['GDP_PC'] = test_data.set_index(['country', 'year']).index.map(GDP_PC_dictionary.get)\n\nX.head()","c23d0b6f":"X=pd.get_dummies(X, columns=['store', 'country', 'product'])\ntest_data=pd.get_dummies(test_data, columns=['store', 'country', 'product'])","dc2df6b3":"'''\n# Break off a validation set (in time-series-split style)\nX_train=X.iloc[:3*len(X)\/\/4,:]\nX_valid=X.iloc[3*len(X)\/\/4:,:]\ny_train=y.iloc[:3*len(X)\/\/4]\ny_valid=y.iloc[3*len(X)\/\/4:]\n\n# Base model\nmodel=LGBMRegressor(random_state=0, n_estimators=200, max_depth=6)\n\n# Train model\nmodel.fit(X_train,y_train)\n\n# Predict\npreds = model.predict(X_valid)\n\n# Calcaculate smape\ndef smape(A, F):\n    return 100\/len(A) * np.sum(2 * np.abs(F - A) \/ (np.abs(A) + np.abs(F)))\n\n# Evaluate smape\nsmape(preds,y_valid)\n'''","a3f47453":"# Store results from experiments\nsmape_results=pd.DataFrame.from_dict({'Method':['base','include holidays','date feat. eng. (FE)', 'holidays + date FE', \n                                                'prev. row + GDP (model A)', 'model A + weekend', 'model A + day dummy',\n                                                'model A + unofficial holidays', 'prev. row + GDP per capita', 'GDP per capita instead of GDP'],\n                                      'SMAPE': [16.52,16.46,9.06, 8.94, 9.02, 9.02, 21.97, 9.00, 8.97, 7.82]})\nsmape_results","2079e885":"# Parameter grid\ngrid = {'n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250],\n        'max_depth': [2, 4, 6, 8, 10, 12],\n        'learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15]}\n\n# XGBoost model\nmodel=LGBMRegressor(random_state=0)\n\n# Grid Search with n-fold cross validation\ngrid_model = GridSearchCV(model,grid,cv=5)\n\n# Train classifier with optimal parameters\ngrid_model.fit(X,y)","bb8bd07c":"print(\"The best parameters across ALL searched params:\\n\",grid_model.best_params_)\nprint(\"\\n The best score across ALL searched params:\\n\",grid_model.best_score_) # r^2 score","3337c469":"# Make predictions\npreds_test = np.ceil(grid_model.predict(test_data)) # ceil suggested by Carl\n\n# Save predictions to file\noutput = pd.DataFrame({'row_id': test_data.index,\n                       'num_sold': preds_test})\n\n# Check format\noutput.head()","b916a322":"output.to_csv('submission.csv', index=False)","8d4f23b2":"**Finding the public holidays of Finland, Norway,Sweden**","1980f8b9":"**Loading the data**","4d84e7fc":"**Gross Domestic Product(GDP)**","ad65daec":"# Exploratory Data Analysis","a5887fe2":"# Feature Engineering","0289b97a":"**Sales by Product Type**","2c35be75":"# TPS January","b2ed65ea":"**Encode categorical value**","a2679471":"**Missing Values**","8456f88c":"**Results from Grid  search**","b7e9e424":"**GDP Per capita**","89e0e56d":"**Sales by country**","73dffda3":"**plotting the data**","21f6f04e":"**Timeframe of test and train data**","80bda272":"# Prediction","5ee1be56":"**All Holidays including public and unofficial**","b1d085af":"# Modelling"}}