{"cell_type":{"05ed08fa":"code","b371d5e2":"code","7e74cb7a":"code","9020027c":"code","4670ad0b":"code","5620c5e8":"code","feb5891c":"code","718698cb":"code","fb83b5ec":"code","05f1d5fc":"code","228e5d96":"code","c8183b71":"code","203993a1":"code","5913e0ea":"code","7b8fc6b3":"code","6f7068f2":"code","82f0bfe8":"code","3e9ad937":"code","29a4e26e":"code","e7dd57f1":"code","e0b29aa9":"code","da3d02dd":"code","e54863a3":"code","e35f1ffb":"code","ad4f4a4d":"code","a74ef748":"code","d4f98282":"code","51782b43":"code","aebcad1c":"code","d9586ebe":"code","3bacb7a3":"code","ed22610b":"code","51b69526":"code","06875bd4":"code","2a95a2b1":"code","f0e8939a":"code","6ff69c85":"code","0ebe4208":"code","e7af63cd":"code","d8fa8d7c":"code","74ebdd89":"code","be31e09c":"code","8d93219a":"code","1c98e308":"code","749a688b":"code","7cac6d3c":"code","8f30dbb0":"code","af244daf":"code","4497d563":"code","3d32125a":"code","130c0410":"code","a14a0e3c":"code","2fe9f0ff":"code","5f3ee39d":"code","1379583c":"code","71b3c229":"code","74f60a9e":"code","17c8aeb1":"code","2915d4b0":"code","878fb899":"code","e9ecb520":"code","2073dc1e":"code","64824723":"code","da992f51":"code","fb226f38":"code","abc5f745":"code","87c81ba8":"code","d61994a8":"code","659e1f37":"code","6a43c775":"code","8203807e":"code","24efa25c":"code","ea234d5e":"markdown","a89cb58f":"markdown","b14c0904":"markdown","7a42e1be":"markdown","9b5a35d4":"markdown","c511b4c6":"markdown","74148916":"markdown","a24e669f":"markdown","e0bc25f3":"markdown","de1ebead":"markdown","c8f1c985":"markdown","bad8662a":"markdown","1d77d530":"markdown","fce3a1d6":"markdown","5872ea57":"markdown","f5dcc70c":"markdown","99ee489e":"markdown","4819b43b":"markdown"},"source":{"05ed08fa":"# IMPORT MODULES\n\nimport numpy as np\nfrom numpy import ma\nimport pandas as pd\nimport math\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n%matplotlib inline\nfrom matplotlib import ticker, cm\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n\nfrom scipy.stats import multivariate_normal\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.svm import OneClassSVM\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras import regularizers\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b371d5e2":"# LOAD DATA\n\ndfRaw = pd.read_csv('..\/input\/creditcard.csv')\nprint(dfRaw.shape)\nprint(dfRaw.columns)","7e74cb7a":"data = dfRaw.copy()\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 3),\"%\")\nprint(\"_\"*100)\nprint(data.head())","9020027c":"# PLOT AMOUNT - Norm vs Fraud\n\nnormal_data[\"Amount\"].loc[normal_data[\"Amount\"] < 500].hist(bins=100);\nplt.figure()\nfraud_data[\"Amount\"].loc[fraud_data[\"Amount\"] < 500].hist(bins=100);\nplt.figure()\nprint(\"Mean\", normal_data[\"Amount\"].mean(), fraud_data[\"Amount\"].mean())\nprint(\"Median\", normal_data[\"Amount\"].median(), fraud_data[\"Amount\"].median())","4670ad0b":"# PLOT TIME - Norm vs Fraud\n\nnormal_data[\"Time\"].hist(bins=100);\nplt.figure()\nfraud_data[\"Time\"].hist(bins=100);\nplt.figure()","5620c5e8":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")","feb5891c":"# Check values are centered around 0 after normalization\n\nprint(\"data['Time'].mean()  \", data['Time'].mean())\nprint(\"data['Amount'].mean()  \", data['Amount'].mean())","718698cb":"# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\n#X_valid = np.concatenate([shuffled_data[-2*num_test:-num_test], fraud_pca_data[:246]])\n#y_valid = np.concatenate([np.zeros(num_test), np.ones(246)])\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data only in Test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\n#print(\"X_valid \", X_valid.shape)\n#print(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)","fb83b5ec":"# Calculate the  prob on train vs test vs fraud data only (no normals at all)\n\np = multivariate_normal(mean=np.mean(X_train,axis=0), cov=np.cov(X_train.T))\n\nx = p.pdf(X_train)\nprint(\"max prob of x on X_train\", max(x))\nprint(\"mean prob of x on X_train\", np.mean(x))\nprint('-' * 60)\nMyTrain = np.mean(x)\n\nx = p.pdf(X_test)\nprint(\"max prob of x on X_test\", max(x))\nprint(\"mean prob of x on X_test\", np.mean(x))\nprint('-' * 60)\nMyTest = np.mean(x)\n\nx = p.pdf(fraud_pca_data)\nprint(\"max prob of x on fraud_pca_data\", max(x))\nprint(\"mean prob of x on fraud_pca_data\", np.mean(x))\nprint('-' * 60)\n\nprint('Difference between mean prob of Train vs Test ', MyTrain - MyTest)\n","05f1d5fc":"# Precision = percentage of Fraud caught\n# Recall = percentage of those caught that are actually Fraud\n# F1 score = Harmonic mean of P & R\n# Need to optimize on the hyperparamter of EPSILON","228e5d96":"# Find best epsilon re F1 score\n\nx = p.pdf(X_test)\n\nEpsF1 = []\n\nepsilons = [1e-10, 1e-20, 1e-30, 1e-40, 1e-50, 1e-60, 1e-70, 1e-80, 1e-90, 1e-100, 1e-110, 1e-120,\n           1e-130, 1e-140, 1e-150, 1e-160, 1e-170, 1e-180, 1e-190, 1e-200, 1e-210, 1e-220, 1e-230, 1e-240]\n\nfor e in range(len(epsilons)):\n    eps = epsilons[e]\n    pred = (x <= eps)\n    f = f1_score(y_test, pred, average='binary')\n    #print(\"F1 score on test\", round(f,4), \" with epsilon \", eps)\n    EpsF1.append([eps, round(f,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['epsilon', 'F1'])\nEpsF1df.head()","c8183b71":"# Best Epsilon ... Max F1 on test\n\nEpsF1df.loc[EpsF1df['F1'].idxmax()]\n","203993a1":"EpsF1df.plot.line(\"epsilon\",\"F1\")\nplt.xscale('log')\nplt.xlim(1e-10, 1e-240)\nplt.title(\"F1 vs decreasing log Epsilon\")\nplt.show()","5913e0ea":"# CONFUSION MATRIX and F1 SCORE on Test w best epsilon\n\neps = EpsF1df.loc[EpsF1df['F1'].idxmax()]['epsilon']\n\nprint(\"epsilon \", eps)\nprint(\"_\"*50)\npred = (x<=eps)\nCM = confusion_matrix(y_test,pred)\ntn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n\nprint(CM)\nprint(\"_\"*50)\nprint(\"TP \", tp)\nprint(\"FP \", fp)\nprint(\"TN \", tn)\nprint(\"FN \", fn)","7b8fc6b3":"def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","6f7068f2":"plot_confusion_matrix(CM, \n                      normalize    = False,\n                      target_names = ['Normal', 'Fraud'],\n                      title        = \"Confusion Matrix\")","82f0bfe8":"# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test,pred, average='binary')\nprint(\"precision \", round((precision), 3))\nprint(\"recall \", round((recall), 3))\nprint(\"F1 score on Test\", round((fbeta_score), 3))","3e9ad937":"#  PCA \n\ndata = dfRaw.copy()\nprint(\"Before PCA\")\nprint(data.shape)\nprint(\"AFTER PCA\")\n\npca = PCA(n_components = 0.999999) # This way of setting the components = knowledge of the VARIANCE loss during PCA\n\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] \nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\ndataPostPCA = pca.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((dataPostPCA, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = [0,1,'Class'])\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(data.shape)\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")\n\n#print(data.head)","29a4e26e":"#postPCA = pd.DataFrame(normal_data.sample(10000))\npostPCA = pd.DataFrame(data)\n\npostPCA.plot.scatter(0,1)\nplt.xlim(-100000, 100000)\nplt.ylim(0, 30000)\nplt.title(\"Normal post PCA\")\nplt.show()\n\npostPCA = pd.DataFrame(fraud_data)\n\npostPCA.plot.scatter(0,1, c='r')\nplt.xlim(-100000, 100000)\nplt.ylim(0, 30000)\nplt.title(\"Fraud post PCA\")\nplt.show()","e7dd57f1":"\nnormal_data = normal_data.drop('Class', axis=1)\nfraud_data = fraud_data.drop('Class', axis=1)","e0b29aa9":"# View the FRAUD on a 2 dims (Post PCA) Guassian distribution of the normal data\n# Reducing from 30 dims to 2 - helps with the visualization but surely doesn't help with separating the Fraud from the Normal\n\nx, y = np.mgrid[-100000:100000:100, -1000:3000:100] \npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x; pos[:, :, 1] = y\nrv = multivariate_normal(mean=np.mean(normal_data,axis=0), cov=np.cov(normal_data.T)) # mean and covariance matrix for 2 dims dataset\n\nfig, ax = plt.subplots()\ncs = ax.contourf(x, y, rv.pdf(pos))\ncbar = fig.colorbar(cs)\nplt.title(\"Fraud projected on normal distribution\")\nplt.scatter(fraud_data[0],fraud_data[1], edgecolor=\"r\") # Location on chart of the anomaly points\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(18.5, 10.5)\n#plt.show()","da3d02dd":"# View some NORMAL on a 2 dims (Post PCA) Guassian distribution of the normal data\n# Reducing from 30 dims to 2 - helps with the visualization but surely doesn't help with separating the Fraud from the Normal\n\nSampleNormal = normal_data.sample(500)\n\nx, y = np.mgrid[-100000:100000:100, -1000:3000:100] \npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x; pos[:, :, 1] = y\nrv = multivariate_normal(mean=np.mean(normal_data,axis=0), cov=np.cov(normal_data.T)) # mean and covariance matrix for 2 dims dataset\n\nfig, ax = plt.subplots()\ncs = ax.contourf(x, y, rv.pdf(pos))\ncbar = fig.colorbar(cs)\nplt.title(\"Normal sample of 500 projected on normal distribution\")\nplt.scatter(SampleNormal[0],SampleNormal[1], edgecolor=\"b\") # Location on chart of the anomaly points\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(18.5, 10.5)\n#plt.show()","e54863a3":"data = dfRaw.copy()\n\nprint(\"Before PCA\")\nprint(data.shape)\nprint(\"AFTER PCA\")\n\npca = PCA(n_components = 0.999999) \n\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] \nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\ndataPostPCA = pca.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((dataPostPCA, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = [0,1,'Class'])\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(data.shape)\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")","e35f1ffb":"# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data.drop('Class',1)\nfraud_pca_data = fraud_data.drop('Class',1)\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\n#X_valid = np.concatenate([shuffled_data[-2*num_test:-num_test], fraud_pca_data[:246]])\n#y_valid = np.concatenate([np.zeros(num_test), np.ones(246)])\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data only in Test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\n#print(\"X_valid \", X_valid.shape)\n#print(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)","ad4f4a4d":"# Calculate the  prob on train vs test vs fraud data only (no normals at all)\n\np = multivariate_normal(mean=np.mean(X_train,axis=0), cov=np.cov(X_train.T))\n\nx = p.pdf(X_train)\nprint(\"max prob of x on X_train\", max(x))\nprint(\"mean prob of x on X_train\", np.mean(x))\nprint('-' * 60)\nMyTrain = np.mean(x)\n\nx = p.pdf(X_test)\nprint(\"max prob of x on X_test\", max(x))\nprint(\"mean prob of x on X_test\", np.mean(x))\nprint('-' * 60)\nMyTest = np.mean(x)\n\nx = p.pdf(fraud_pca_data)\nprint(\"max prob of x on fraud_pca_data\", max(x))\nprint(\"mean prob of x on fraud_pca_data\", np.mean(x))\nprint('-' * 60)\n\nprint('Difference between mean prob of Train vs Test ', MyTrain - MyTest)","a74ef748":"# Find best epsilon re F1 score\n\nx = p.pdf(X_test)\n\nEpsF1 = []\n\nepsilons = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n\nfor e in range(len(epsilons)):\n    eps = epsilons[e]\n    pred = (x <= eps)\n    f = f1_score(y_test, pred, average='binary')\n    #print(\"F1 score on test\", round(f,4), \" with epsilon \", eps)\n    EpsF1.append([eps, round(f,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['epsilon', 'F1'])\nEpsF1df.head()","d4f98282":"# Best Epsilon ... Max F1 on test\n\nEpsF1df.loc[EpsF1df['F1'].idxmax()]","51782b43":"EpsF1df.plot.line(\"epsilon\",\"F1\")\nplt.xscale('log')\nplt.xlim(1e-1, 1e-10)\nplt.title(\"F1 vs decreasing log Epsilon\")\nplt.show()","aebcad1c":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")","d9586ebe":"# Check values are centered around 0 after normalization\n\nprint(\"data['Time'].mean()  \", data['Time'].mean())\nprint(\"data['Amount'].mean()  \", data['Amount'].mean())","3bacb7a3":"# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data only in Test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\n#print(\"X_valid \", X_valid.shape)\n#print(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)","ed22610b":"input_dim = X_train.shape[1]\nencoding_dim = 14","51b69526":"# Keras Auto Encoder model\n\ninput_layer = Input(shape=(input_dim, ))\n\nencoder = Dense(encoding_dim, activation=\"tanh\", \n                activity_regularizer=regularizers.l1(10e-5))(input_layer)\nencoder = Dense(int(encoding_dim \/ 2), activation=\"relu\")(encoder)\n\ndecoder = Dense(int(encoding_dim \/ 2), activation='tanh')(encoder)\ndecoder = Dense(input_dim, activation='relu')(decoder)\n\nautoencoder = Model(inputs=input_layer, outputs=decoder)\n\nautoencoder.summary()","06875bd4":"nb_epoch = 10\nbatch_size = 32\n\nautoencoder.compile(optimizer='adam', \n                    loss='mean_squared_error', \n                    metrics=['accuracy'])\n\ncheckpointer = ModelCheckpoint(filepath=\"model.h5\",\n                               verbose=0,\n                               save_best_only=True)\ntensorboard = TensorBoard(log_dir='.\/logs',\n                          histogram_freq=0,\n                          write_graph=True,\n                          write_images=True)\n\nhistory = autoencoder.fit(X_train, X_train,\n                    epochs=nb_epoch,\n                    batch_size=batch_size,\n                    shuffle=True,\n                    validation_data=(X_test, X_test),\n                    verbose=1,\n                    callbacks=[checkpointer, tensorboard]).history","2a95a2b1":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\nepochs = range(1, (len(history_dict['acc']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","f0e8939a":"# Load the best model saved above during training\n\nautoencoder = load_model('model.h5')","6ff69c85":"# Reconstruction error on Train\n\n# As Train has no Fraud\ny_train = np.zeros(X_train.shape[0])\n\npredictions = autoencoder.predict(X_train)\npredictions.shape\n\nmse = np.mean(np.power(X_train - predictions, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                        'true_class': y_train})\nprint(error_df.shape[0], ' rows')\nprint('mean error of recon on TRAIN', round(error_df.reconstruction_error.mean(),2))\nprint('std error of recon on TRAIN', round(error_df.reconstruction_error.std(),2))","0ebe4208":"# Reconstruction error on Test\n\npredictions = autoencoder.predict(X_test)\npredictions.shape\n\nmse = np.mean(np.power(X_test - predictions, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                        'true_class': y_test})\nprint(error_df.shape[0], ' rows')\nprint('mean error of recon on TEST', round(error_df.reconstruction_error.mean(),2))\nprint('std error of recon on TEST', round(error_df.reconstruction_error.std(),2))","e7af63cd":"# Reconstruction error on Fraud\n\n# As Fraud is all Fraud\ny_Fraud = np.ones(fraud_pca_data.shape[0])\ny_Fraud.shape\n\npredictions = autoencoder.predict(fraud_pca_data)\npredictions.shape\n\nmse = np.mean(np.power(fraud_pca_data - predictions, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                        'true_class': y_Fraud})\nprint(error_df.shape[0], ' rows')\nprint('mean error of recon on FRAUD', round(error_df.reconstruction_error.mean(),2))\nprint('std error of recon on FRAUD', round(error_df.reconstruction_error.std(),2))","d8fa8d7c":"# Predictions on Normal vs Fraud on Test ... using the reconstruction error as the parameter to tweak for best F1\n\n# Reconstruction error on Test\n\npredictions = autoencoder.predict(X_test)\npredictions.shape\n\nmse = np.mean(np.power(X_test - predictions, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                        'true_class': y_test})\nprint(error_df.shape[0], ' rows')\nprint('mean error of recon on TEST', round(error_df.reconstruction_error.mean(),2))\nprint('std error of recon on TEST', round(error_df.reconstruction_error.std(),2))\n\nReconError = 4.0\n\npred = [1 if e > ReconError else 0 for e in error_df.reconstruction_error.values]\nlen(pred)\n#pred = (x <= eps)\nf = f1_score(y_test, pred, average='binary')\nprint(\"F1 score on test\", round(f,4), \" with reconstruction error  \", ReconError)","74ebdd89":"minRE = 1\nmaxRE = 50\n    \nEpsF1 = []\n\nfor TryRE in range(minRE,maxRE):\n    pred = [1 if e > TryRE else 0 for e in error_df.reconstruction_error.values]\n    f = f1_score(y_test, pred, average='binary')\n    #print(\"F1 score on test\", round(f,4), \" with epsilon \", eps)\n    EpsF1.append([TryRE, round(f,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['ReconError', 'F1'])\nEpsF1df.head()","be31e09c":"# Best Recon Error ... Max F1 on test\n\nEpsF1df.loc[EpsF1df['F1'].idxmax()]","8d93219a":"EpsF1df.plot.line(\"ReconError\",\"F1\")\nplt.xlim(1, 50)\nplt.title(\"F1 vs ReconError\")\nplt.show()","1c98e308":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")","749a688b":"# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 20000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data only in Test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\n#print(\"X_valid \", X_valid.shape)\n#print(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)","7cac6d3c":"X_inliers = shuffled_data[-num_test:]\nX_outliers = fraud_pca_data[:]\nX = np.r_[X_inliers, X_outliers]\n\nn_outliers = len(X_outliers)\nground_truth = np.ones(len(X), dtype=int)\nground_truth[-n_outliers:] = -1\n\nPercFraud = n_outliers \/ X_test.shape[0]\nPercFraud\n\nprint('X_inliers ', X_inliers.shape)\nprint('X_outliers ', X_outliers.shape)\nprint('X ', X.shape)\nprint('n_outliers ', n_outliers)\nprint('percent fraud in test: ', PercFraud)","8f30dbb0":"%%time\n\n# fit the model for outlier detection (default)\nclf = LocalOutlierFactor(n_neighbors=20, contamination = PercFraud)\n# use fit_predict to compute the predicted labels of the training samples\n# (when LOF is used for outlier detection, the estimator has no predict,\n# decision_function and score_samples methods).\ny_pred = clf.fit_predict(X)\nn_errors = (y_pred != ground_truth).sum()\nX_scores = clf.negative_outlier_factor_\nn_errors","af244daf":"print('accuracy ' , round(1 - (n_errors \/ X.shape[0]),4))","4497d563":"# Note that the ground truth and the y_pred for LOF is different than the original ... inliers = normal = 1 and outliers = fraud = -1\n# We have to modify the y_pred for the F1 score calculation to be similar to the above \n\ny_predLOF = y_pred.copy()\ny_predDF = pd.DataFrame(y_predLOF)\nprint(y_predDF[y_predDF[0] == -1].count())\n\ny_predDF[y_predDF[0] == 1] = 0\ny_predDF[y_predDF[0] == -1] = 1\nprint(y_predDF[y_predDF[0] == 1].count())\n\ny_predLOF = y_predDF.values\ny_predLOF = np.ravel(y_predLOF)\n","3d32125a":"# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score on Test\", round((fbeta_score), 4))","130c0410":"# Optimize num of neighbors hyper paramter for best F1\n\nminRE = 500\nmaxRE = 1100\n    \nEpsF1 = []\n\nfor TryRE in range(minRE,maxRE,100):\n    clf = LocalOutlierFactor(n_neighbors=TryRE, contamination = PercFraud)\n    y_pred = clf.fit_predict(X)\n    n_errors = (y_pred != ground_truth).sum()\n    X_scores = clf.negative_outlier_factor_\n    \n    y_predLOF = y_pred.copy()\n    y_predDF = pd.DataFrame(y_predLOF)\n    \n    y_predDF[y_predDF[0] == 1] = 0\n    y_predDF[y_predDF[0] == -1] = 1\n    \n    y_predLOF = y_predDF.values\n    y_predLOF = np.ravel(y_predLOF)\n    \n    precision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\n    \n    print(\"F1 score on test\", round(fbeta_score,4), \" with num neighbors \", TryRE)\n    EpsF1.append([TryRE, round(fbeta_score,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['NumNeighb', 'F1'])\nEpsF1df.head()","a14a0e3c":"EpsF1df.plot.line(\"NumNeighb\",\"F1\")\nplt.xlim(500, 1000)\nplt.title(\"F1 vs NumNeighb\")\nplt.show()","2fe9f0ff":"data = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492\/284807, 4),\"%\")\n\n# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data only in Test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\n#print(\"X_valid \", X_valid.shape)\n#print(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)\n\nX_inliers = shuffled_data[-num_test:]\nX_outliers = fraud_pca_data[:]\nX = np.r_[X_inliers, X_outliers]\n\nn_outliers = len(X_outliers)\nground_truth = np.ones(len(X), dtype=int)\nground_truth[-n_outliers:] = -1\n\nPercFraud = n_outliers \/ X_test.shape[0]\nPercFraud\n\nprint('X_inliers ', X_inliers.shape)\nprint('X_outliers ', X_outliers.shape)\nprint('X ', X.shape)\nprint('n_outliers ', n_outliers)\nprint('percent fraud in test: ', PercFraud)","5f3ee39d":"clf = LocalOutlierFactor(n_neighbors=900, contamination = PercFraud)\n\ny_pred = clf.fit_predict(X)\nn_errors = (y_pred != ground_truth).sum()\nX_scores = clf.negative_outlier_factor_\n#print('accuracy ' , round(1 - (n_errors \/ X.shape[0]),4))\nn_errors","1379583c":"y_predLOF = y_pred.copy()\ny_predDF = pd.DataFrame(y_predLOF)\n\ny_predDF[y_predDF[0] == 1] = 0\ny_predDF[y_predDF[0] == -1] = 1\n\ny_predLOF = y_predDF.values\ny_predLOF = np.ravel(y_predLOF)\n\n# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score on Test\", round((fbeta_score), 4))","71b3c229":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\n# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\n\nX_inliers = shuffled_data[-num_test:]\nX_outliers = fraud_pca_data[:]\nX = np.r_[X_inliers, X_outliers]\n\nn_outliers = len(X_outliers)\nground_truth = np.ones(len(X), dtype=int)\nground_truth[-n_outliers:] = -1\n\nPercFraud = n_outliers \/ X_test.shape[0]\nPercFraud\n\nprint('X_inliers ', X_inliers.shape)\nprint('X_outliers ', X_outliers.shape)\nprint('X ', X.shape)\nprint('n_outliers ', n_outliers)\nprint('percent fraud in test: ', PercFraud)\n","74f60a9e":"cov = EllipticEnvelope(support_fraction = 0.994, contamination = PercFraud)\n\ny_pred = cov.fit_predict(X)\nn_errors = (y_pred != ground_truth).sum()\nn_errors","17c8aeb1":"y_predLOF = y_pred.copy()\ny_predDF = pd.DataFrame(y_predLOF)\n\ny_predDF[y_predDF[0] == 1] = 0\ny_predDF[y_predDF[0] == -1] = 1\n\ny_predLOF = y_predDF.values\ny_predLOF = np.ravel(y_predLOF)\n\n# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score on Test\", round((fbeta_score), 4))","2915d4b0":"CM = confusion_matrix(y_test, y_predLOF)\ntn, fp, fn, tp = confusion_matrix(y_test, y_predLOF).ravel()\n\nprint(CM)\nprint(\"_\"*50)\nprint(\"TP \", tp)\nprint(\"FP \", fp)\nprint(\"TN \", tn)\nprint(\"FN \", fn)","878fb899":"plot_confusion_matrix(CM, \n                      normalize    = False,\n                      target_names = ['Normal', 'Fraud'],\n                      title        = \"Confusion Matrix\")","e9ecb520":"# Optimize support_fraction hyper paramter for best F1\n\nminRE = 0.95\nmaxRE = 0.99\n    \nEpsF1 = []\n\nfor TryRE in np.arange(minRE, maxRE, 0.01):\n    cov = EllipticEnvelope(support_fraction = TryRE, contamination = PercFraud)\n    y_pred = cov.fit_predict(X)\n    n_errors = (y_pred != ground_truth).sum()\n    \n    y_predLOF = y_pred.copy()\n    y_predDF = pd.DataFrame(y_predLOF)\n    \n    y_predDF[y_predDF[0] == 1] = 0\n    y_predDF[y_predDF[0] == -1] = 1\n    \n    y_predLOF = y_predDF.values\n    y_predLOF = np.ravel(y_predLOF)\n    \n    precision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\n    \n    print(\"F1 score on test\", round(fbeta_score,4), \" with support_fraction \", TryRE)\n    EpsF1.append([TryRE, round(fbeta_score,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['SupFrac', 'F1'])\nEpsF1df.head()","2073dc1e":"EpsF1df.plot.line(\"SupFrac\",\"F1\")\nplt.xlim(minRE, maxRE)\nplt.title(\"F1 vs SupFrac\")\nplt.show()","64824723":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\n# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\n\nX_inliers = shuffled_data[-num_test:]\nX_outliers = fraud_pca_data[:]\nX = np.r_[X_inliers, X_outliers]\n\nn_outliers = len(X_outliers)\nground_truth = np.ones(len(X), dtype=int)\nground_truth[-n_outliers:] = -1\n\nPercFraud = n_outliers \/ X_test.shape[0]\nPercFraud\n\nprint('X_inliers ', X_inliers.shape)\nprint('X_outliers ', X_outliers.shape)\nprint('X ', X.shape)\nprint('n_outliers ', n_outliers)\nprint('percent fraud in test: ', PercFraud)\n","da992f51":"%%time\n\nisofo = IsolationForest(n_estimators = 1050, max_features = 1.0, max_samples=1.0, \n                        behaviour=\"new\", bootstrap=False, random_state=22,\n                        contamination = PercFraud)\n\ny_pred = isofo.fit_predict(X)\nn_errors = (y_pred != ground_truth).sum()\nprint(n_errors)","fb226f38":"y_predLOF = y_pred.copy()\ny_predDF = pd.DataFrame(y_predLOF)\n\ny_predDF[y_predDF[0] == 1] = 0\ny_predDF[y_predDF[0] == -1] = 1\n\ny_predLOF = y_predDF.values\ny_predLOF = np.ravel(y_predLOF)\n\n# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score on Test\", round((fbeta_score), 4))","abc5f745":"# Optimize Num Estimators hyper paramter for best F1\n\nminRE = 900\nmaxRE = 1150\n    \nEpsF1 = []\n\nfor TryRE in np.arange(minRE, maxRE, 50):\n    isofo = IsolationForest(n_estimators = TryRE, max_features = 1.0, max_samples=1.0, \n                        behaviour=\"new\", bootstrap=False, random_state=22,\n                        contamination = PercFraud)\n\n    y_pred = isofo.fit_predict(X)\n    n_errors = (y_pred != ground_truth).sum()\n    \n    y_predLOF = y_pred.copy()\n    y_predDF = pd.DataFrame(y_predLOF)\n    \n    y_predDF[y_predDF[0] == 1] = 0\n    y_predDF[y_predDF[0] == -1] = 1\n    \n    y_predLOF = y_predDF.values\n    y_predLOF = np.ravel(y_predLOF)\n    \n    precision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\n    \n    print(\"F1 score on test\", round(fbeta_score,4), \" with num_estimators \", TryRE)\n    EpsF1.append([TryRE, round(fbeta_score,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['NumEstim', 'F1'])\nEpsF1df.head()","87c81ba8":"EpsF1df.plot.line(\"NumEstim\",\"F1\")\nplt.xlim(minRE, maxRE)\nplt.title(\"F1 vs NumEstim\")\nplt.show()","d61994a8":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\n# CREATE the TRAIN and TEST sets\n# Fraud data is ONLY in TEST - not in TRAIN\n\nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1, random_state=1960)[:-num_test].values\nX_train = shuffled_data\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(492)])\n\n\nX_inliers = shuffled_data[-num_test:]\nX_outliers = fraud_pca_data[:]\nX = np.r_[X_inliers, X_outliers]\n\nn_outliers = len(X_outliers)\nground_truth = np.ones(len(X), dtype=int)\nground_truth[-n_outliers:] = -1\n\nPercFraud = n_outliers \/ X_test.shape[0]\nPercFraud\n\nprint('X_inliers ', X_inliers.shape)\nprint('X_outliers ', X_outliers.shape)\nprint('X ', X.shape)\nprint('n_outliers ', n_outliers)\nprint('percent fraud in test: ', PercFraud)\n","659e1f37":"%%time\n\nOneSVM = OneClassSVM(nu = PercFraud)\n\ny_pred = OneSVM.fit_predict(X)\nn_errors = (y_pred != ground_truth).sum()\nprint(n_errors)","6a43c775":"y_predLOF = y_pred.copy()\ny_predDF = pd.DataFrame(y_predLOF)\n\ny_predDF[y_predDF[0] == 1] = 0\ny_predDF[y_predDF[0] == -1] = 1\n\ny_predLOF = y_predDF.values\ny_predLOF = np.ravel(y_predLOF)\n\n# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score on Test\", round((fbeta_score), 4))","8203807e":"# Optimize nu hyper paramter for best F1\n\nminRE = 0.017\nmaxRE = 0.022\n    \nEpsF1 = []\n\nfor TryRE in np.arange(minRE, maxRE, 0.001):\n    OneSVM = OneClassSVM(nu = TryRE)\n    y_pred = OneSVM.fit_predict(X)\n    n_errors = (y_pred != ground_truth).sum()\n    \n    y_predLOF = y_pred.copy()\n    y_predDF = pd.DataFrame(y_predLOF)\n    \n    y_predDF[y_predDF[0] == 1] = 0\n    y_predDF[y_predDF[0] == -1] = 1\n    \n    y_predLOF = y_predDF.values\n    y_predLOF = np.ravel(y_predLOF)\n    \n    precision,recall,fbeta_score, support  = precision_recall_fscore_support(y_test, y_predLOF, average='binary')\n    \n    print(\"F1 score on test\", round(fbeta_score,4), \" with nu \", TryRE)\n    EpsF1.append([TryRE, round(fbeta_score,4)])\n    \nEpsF1df = pd.DataFrame(EpsF1, columns = ['nu', 'F1'])\nEpsF1df.head()","24efa25c":"EpsF1df.plot.line(\"nu\",\"F1\")\nplt.xlim(minRE, maxRE)\nplt.title(\"F1 vs nu\")\nplt.show()","ea234d5e":"# Optimize Epsilon","a89cb58f":"# Optimize the reconstruction error for best F1","b14c0904":"The following on the 75,492 test LOF w 20 neighbors takes 12 mins so for running multiple times to find the best num of neighbors - we'll reduce the test size","7a42e1be":"colors = np.where(data[\"Class\"]==1,'r','y')\n\ndata.plot.scatter(\"Time\",\"Amount\", c=colors)\ndata.plot.scatter(\"V1\",\"V2\", c=colors)\ndata.plot.scatter(\"V1\",\"Amount\", c=colors)\n","9b5a35d4":"# Multi-variate Gaussian prob distribution","c511b4c6":"# Auto Encoders\n\n* The idea is to use the Reconstruction Error as the limit to separate between Normal (low reconstruction error) and Fraud anomalies (high reconstruction errors)\n* Reconstruction error is the MSE between the input X_train and the output of the autoencoder which has the same dimensions as X_train.\n* Not to be confused with the error between a prediction and the true label","74148916":"# Local Outlier Factor (LOF)","a24e669f":"# Isolation Forest\nRequires same manipulation as LOF ... inliers = 1 and outliers = -1 while the original is normal = 0 and fraud = 1","e0bc25f3":"# Fraud goes into Test only. Train contains only normal transactions.\n\n* Trying with Fraud in both valid and test = F1 score on test = 0.55\n* **Fraud only in test** = F1 score on test = 0.71\n* If there are no fraud in valid - there's no need for valid\n","de1ebead":" ...# Features' Prob DISTRIBUTION ... Visualization\n\nplt.figure()\nmatplotlib.style.use('ggplot')\npca_columns = list(data)[:-1]\nnormal_data[pca_columns].hist(stacked=False, bins=100, figsize=(12,30), layout=(16,2))","c8f1c985":"# Comparison of anomaly detection algorithms on the credit card fraud dataset:\n\n* Multivariate Gaussian probability, Auto Encoders, Local Outlier Factor LOF, Robust Covariance (Elliptic Envelope), Isolation Forest and One Class SVM\n\n* I believe that a system for anomaly detection should NOT be a supervised ML algorithm as it will (maybe) learn only anomalies it has seen during training. The true magic lies in being able to identify an anomaly never seen before...\n* As the data is very skewed - there are **only 0.17%** fraudulent transactions in the 280k samples -  accuracy is not a good metric: any \"model\" predicting ALL are normal transactions will have a 99.83% accuracy. \n* We need to use Recall, Precision and their prodigy (harmonic mean) - the F1 score. I've tried to optimize each model's hyperparameters for the best F1.\n* The models below do not take into account the time sequences, (while still having the time as a separate feature).The time series nature of the anomaly detection should be dealt with RNN or LSMT or etc. - maybe another notebook.\n* The training set does NOT include any Fraud, so when the model is exposed to one in Test, it will stand out from the normal transactions. I've tried dividing the Fraud half into a Validation subset and half in Test - F1 score being lower.\n* PCA was used only for visualization. With or Without Scaling before PCA - F1 score very low.\n\n* With the above in mind I've compared between the following on F1 score on **Test**:\n\n\n### **Multivariate Gaussian prob distribution F1= 0.71** optimizing Epsilon \n\n### **Auto-encoders F1= 0.53** optimizing Reconstruction Error\n\n### **LOF Local Outlier Factor F1= 0.57** optimizing number of neighbors\n\n### **Robust Covariance (Elliptic Envelope) *F1= 0.80*** optimizing support fraction\n\n### **Isolation Forest F1= 0.47** optimizing num estimators\n\n### **One Class SVM F1= 0.27** optimizing nu\n\n\n### Check out nb comparing 5 supervised learning algorithms on this dataset using oversampling, SMOTE and ADASYN \nhttps:\/\/www.kaggle.com\/drscarlat\/fraud-detection-under-oversampling-smote-adasyn \n### ...it achieves F1 = 0.87\n\n* Many thanks to the following:\n* https:\/\/scikit-learn.org\/stable\/auto_examples\/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py\n* https:\/\/www.kaggle.com\/tildekarthik\/a-multivariate-gaussian-anomaly-detection\n* https:\/\/www.kaggle.com\/clemensmzr\/simple-multivariate-gaussian-anomaly-detection\n","bad8662a":"Best F1 score after PCA = 0.022 ... similar F1 when scaling was used before PCA","1d77d530":"# One Class SVM\nRequires same manipulation as LOF ... inliers = 1 and outliers = -1 while the original is normal = 0 and fraud = 1","fce3a1d6":"# PCA = 2 ... Only for visualization ... with or without prior scaling = low F1\n","5872ea57":"#  SCALER \/ Normalization\n\ndata = dfRaw.copy()\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] # all cols without Class\nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\nprint(\"Before PCA\")\nprint(data.shape)\nprint(\"AFTER PCA\")","f5dcc70c":"Knowing that 900 is the best num of neighbors for LOF we test the original 75,492 so the results can be compared to other models\nThis may take 20 mins\n\n","99ee489e":"# For viz AFTER Scaling and PCA\npostPCA = pd.DataFrame(data)\n\npostPCA.plot.scatter(0,1)\nplt.xlim(-10, 80)\nplt.ylim(-10, 10)\nplt.title(\"Normal post PCA\")\nplt.show()\n\npostPCA = pd.DataFrame(fraud_data)\n\npostPCA.plot.scatter(0,1, c='r')\nplt.xlim(-10, 80)\nplt.ylim(-10, 10)\nplt.title(\"Normal post PCA\")\nplt.show()","4819b43b":"# Robust Covariance (Elliptic Envelope)\n\nRequires same manipulation as LOF ... inliers = 1 and outliers = -1 while the original is normal = 0 and fraud = 1"}}