{"cell_type":{"a4c475f4":"code","1e571983":"code","182063de":"code","14104804":"code","3e719d75":"code","d45c623d":"code","84d3147c":"code","27ba78ee":"code","6dfca5fd":"code","25fca6cf":"code","156d81d6":"code","5a7542a3":"code","8356b3a8":"code","7988b30a":"code","47667f46":"code","33f57032":"markdown","39a5cb46":"markdown","86706850":"markdown","4bc6173d":"markdown","80b3a0b1":"markdown","cca748b4":"markdown","720e4fa0":"markdown","1fba74f8":"markdown","93eeb68a":"markdown","36251782":"markdown","4995ea73":"markdown","d1a26cb2":"markdown","a852a0f0":"markdown"},"source":{"a4c475f4":"import re\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport lightgbm as lgb\nimport xgboost as xg\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold","1e571983":"#Prepping X_train\n#Note - 512 x 512 - 7.2 GB\n\nImg_size = 512  \nX0 = []\nbase_pth = '..\/input\/train_images\/'\n\nfor filename in os.listdir('..\/input\/train_images\/'):\n    ds = cv2.imread(str(base_pth+filename),0)\n    b0 = cv2.resize(ds,(Img_size,Img_size))\n    X0.append(b0)","182063de":"#Prepping Y_train\n\ndf_train = pd.read_csv('..\/input\/train.csv')\ny = []\n\nfor filename in os.listdir('..\/input\/train_images\/'):\n    idz = str(filename)[:-4]\n    for idx,each in enumerate(df_train['id_code']):\n        if idz == each:\n            y.append(int(df_train.iloc[idx,1]))","14104804":"X = np.array([i[0] for i in X0]).reshape((-1,512))\ny = np.array(y)","3e719d75":"def conf_matrix(y_pred,y_actual):\n        \n    cm = confusion_matrix(y_actual, y_pred)\n    acc = (y_actual == y_pred).sum()\/len(y_actual)\n\n    return cm,acc","d45c623d":"def print_metrics(cm,acc):\n    print(\"Confusion Matrix - \")\n    print(cm)\n    print(\"Accuracy\")\n    print(acc)","84d3147c":"def train_test_func(algo_init_model):\n    \n    #Add k_Fold step here\n    k = 5\n    kf = KFold(n_splits=k)\n    \n    avg_cm = np.zeros((5,5))\n    avg_acc = 0\n    \n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        #Training\n        y_pred = algo_init_model.fit(X_train, y_train)\n\n        #Prediction\n        y_pred_val = y_pred.predict(X_test)\n\n        #Metrics\n        cm, acc = conf_matrix(y_pred_val,y_test)\n        avg_acc += acc\n        avg_cm += cm\n\n    print_metrics(avg_cm\/k,avg_acc\/k)","27ba78ee":"#Trying on Naive Bayes\ngnb = MultinomialNB()\ntrain_test_func(gnb)","6dfca5fd":"#Trying on Decision Tree\nclf = tree.DecisionTreeClassifier()\ntrain_test_func(clf)","25fca6cf":"#Trying on Logistic Regression\nclf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\ntrain_test_func(clf)","156d81d6":"#Trying on Random Forest\nclf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\ntrain_test_func(clf)","5a7542a3":"#Trying on AdaBoost\nclf = AdaBoostClassifier(n_estimators=50,learning_rate=1,random_state=0)\ntrain_test_func(clf)","8356b3a8":"#Trying on KNN\nneigh = KNeighborsClassifier(n_neighbors=5)\ntrain_test_func(neigh)","7988b30a":"#Trying on LightGBM\n\nparams = {}\nparams['learning_rate'] = 0.003\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'multiclass'\nparams['metric'] = 'multi_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 30\nparams['min_data'] = 50\nparams['max_depth'] = 20\nparams['num_class'] = 5\n\nk = 5\nkf = KFold(n_splits=k)\n    \navg_cm = np.zeros((5,5))\navg_acc = 0\n    \nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n        \n    #Training\n    d_train = lgb.Dataset(X_train, label=y_train)\n    y_pred = lgb.train(params, d_train, 100)\n\n    #Prediction\n    y_pred_val0 = y_pred.predict(X_test)\n    print(y_pred_val0[0])\n    \n    y_pred_val = []\n\n    for x in y_pred_val0:\n        print(np.argmax(x))\n        y_pred_val.append(np.argmax(x))\n    \n    #Metrics\n    cm, acc = conf_matrix(y_pred_val,y_test)\n    avg_acc += acc\n    avg_cm += cm\nprint_metrics(avg_cm\/k,avg_acc\/k)","47667f46":"#Trying on XGBoost\nxgbt = xg.XGBClassifier()\ntrain_test_func(xgbt)","33f57032":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>Decision Tree<\/div>","39a5cb46":"### <div style=' color: white; background-color: #2D93D5; border-left: 10px solid #014F99; padding: 20px;'> Data Description <\/div>\n- **Total entries in training set - 3662**\n    - *0 - No DR - 1805 (49.29%)*\n    - *1 - Mild - 999 (27.28%)*\n    - *2 - Moderate - 370 (10.10%)*\n    - *3 - Severe - 295 (8.05%)*\n    - *4 - Proliferative DR - 193 (5.27%)*","86706850":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>Logistic Regression<\/div>","4bc6173d":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>AdaBoost<\/div>","80b3a0b1":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>KNN<\/div>","cca748b4":"# <div style=' background-color: #ddffff; border-left: 10px solid #2196F3; padding: 20px;'> Playing with the data! <\/div>","720e4fa0":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>XGBoost<\/div>","1fba74f8":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>Multi-Nomial Naive Bayes<\/div>","93eeb68a":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>Random Forest<\/div>","36251782":"Note - All files are of format .png which are being resized to (512 x 512) dimensions and being read as grayscale images.","4995ea73":"### <div style=' color: white; background-color: #2D93D5; border-left: 10px solid #014F99; padding: 20px;'>Survey<\/div>","d1a26cb2":"#### <div style=' color: black; background-color: #C7D86F; border-left: 10px solid #F7C407; padding: 20px;'>LightGBM<\/div>","a852a0f0":"### <div style=' color: white; background-color: #2D93D5; border-left: 10px solid #014F99; padding: 20px;'> Simplified Problem Statement <\/div>\n- The problem is -\n    - From a labelled dataset of 3662 retina images. Teach \/ Train a Machine Learning model to correctly identify the severity of diabetic retinopathy on a scale of 0 to 4.\n"}}