{"cell_type":{"f6174840":"code","ac7a2e01":"code","e16ed840":"code","049fbe4b":"code","27e44c1a":"code","007fb4a9":"markdown","64dedb20":"markdown","4416ee99":"markdown","d2399e35":"markdown","9bad8e36":"markdown","f85acf49":"markdown","77aa6d2b":"markdown","054df596":"markdown","fc529f1f":"markdown","24e7ae81":"markdown","24d6fae1":"markdown","137cd31a":"markdown"},"source":{"f6174840":"import numpy as np\nimport imageio\nimport torch\ntorch.set_printoptions(edgeitems=2, threshold=50)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","ac7a2e01":"dir_path = \"\/kaggle\/input\"\nvol_arr = imageio.volread(dir_path, 'DICOM')\nvol_arr.shape","e16ed840":"vol = torch.from_numpy(vol_arr).float()\nvol = torch.unsqueeze(vol, 0)\n\nvol.shape","049fbe4b":"vol","27e44c1a":"plt.imshow(vol_arr[38]);","007fb4a9":"https:\/\/github.com\/deep-learning-with-pytorch\/dlwpt-code\n","64dedb20":"CTs have only a single intensity channel, similar to a grayscale image. This means\nthat often, the channel dimension is left out in native data formats; so, similar to the\nlast section, the raw data typically has three dimensions. By stacking individual 2D\nslices into a 3D tensor, we can build volumetric data representing the 3D anatomy of a\nsubject. Unlike what we saw in figure 4.1, the extra dimension in figure 4.2 represents\nan offset in physical space, rather than a particular band of the visible spectrum.","4416ee99":"Part 2 of this book will be devoted to tackling a medical imaging problem in the real\nworld, so we won\u2019t go into the details of medical-imaging data formats. For now, it suf-\nfices to say that there\u2019s no fundamental difference between a tensor storing volumet-\nric data versus image data. We just have an extra dimension, depth, after the channel\ndimension, leading to a 5D tensor of shape N \u00d7 C \u00d7 D \u00d7 H \u00d7 W.","d2399e35":"We\u2019ve learned how to load and represent 2D images, like the ones we take with a camera.\nIn some contexts, such as medical imaging applications involving, say, CT (computed\ntomography) scans, we typically deal with sequences of images stacked along the head-\nto-foot axis, each corresponding to a slice across the human body. In CT scans, the inten-\nsity represents the density of the different parts of the body\u2014lungs, fat, water, muscle,\nand bone, in order of increasing density\u2014mapped from dark to bright when the CT\nscan is displayed on a clinical workstation. The density at each point is computed from\nthe amount of X-rays reaching a detector after crossing through the body, with some\ncomplex math to deconvolve the raw sensor data into the full volume.","9bad8e36":"All data from book **Deep Learning with PyTorch** https:\/\/pytorch.org\/deep-learning-with-pytorch","f85acf49":"* https:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch2-dog-detection\n\n* https:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch2-gan-horse-zebra\n\n* https:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch3-tensors\n\n* https:\/\/www.kaggle.com\/dmisky\/dlwpt-p1ch4-working-with-images","77aa6d2b":"As was true in section 4.1.3, the layout is different from what PyTorch expects, due to\nhaving no channel information. So we\u2019ll have to make room for the channel dimen-\nsion using unsqueeze :","054df596":"Let\u2019s load a sample CT scan using the volread function in the imageio module, which\ntakes a directory as an argument and assembles all Digital Imaging and Communi-\ncations in Medicine (DICOM) files (From the Cancer Imaging Archive\u2019s CPTAC-LSCC collection: http:\/\/mng.bz\/K21K) in a series in a NumPy 3D array (code\/p1ch4\/\n2_volumetric_ct.ipynb).","fc529f1f":"## Loading a specialized format","24e7ae81":"![image.png](attachment:image.png)","24d6fae1":"3D images: Volumetric data","137cd31a":"At this point we could assemble a 5D dataset by stacking multiple volumes along the\nbatch direction, just as we did in the previous section. We\u2019ll see a lot more CT data in\npart 2."}}