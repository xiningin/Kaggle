{"cell_type":{"e2387fa0":"code","3921433a":"code","e876291c":"code","c7cd27df":"code","78e2dddf":"code","4e4c02a6":"code","7dd4cad2":"code","56019401":"code","84b0f5cf":"code","ad507ea2":"code","e8fd01dc":"code","ca071084":"code","f59cc3c3":"code","6eb6eb27":"code","2693da70":"code","6e7fc1e2":"code","a0aa6c54":"code","1a8080fa":"code","e18ade2d":"code","533c9b4b":"code","419a1797":"code","23797ec9":"code","fecf50fb":"code","f6acdd57":"code","cc2fa565":"code","9da877c4":"code","005497a8":"code","7a68092b":"code","ad1737f4":"code","b8de0046":"markdown","5a648c5f":"markdown","959ee952":"markdown","815eb18b":"markdown","74b6023c":"markdown","701ee4f8":"markdown","18e71a5f":"markdown","70189b5e":"markdown","a63a7e47":"markdown","e9071d9b":"markdown","22e593cc":"markdown","03efc8b6":"markdown","1741eb78":"markdown","07ae4d87":"markdown","1d6be43c":"markdown","57c4f326":"markdown"},"source":{"e2387fa0":"import os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\n\nfrom sklearn import model_selection\n\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision.transforms import transforms\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F","3921433a":"os.listdir('..\/input\/version-8-indian-dance-forms\/IndianDanceForms2')","e876291c":"base_path = '..\/input\/version-8-indian-dance-forms\/IndianDanceForms2'\ntrain_dir = os.path.join(base_path, 'train')\ntest_dir = os.path.join(base_path, 'test')\ntrain_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n# valid_df = pd.read_csv('..\/input\/validation-data\/valid.csv')\nvalid_df = pd.read_csv(os.path.join(base_path, 'valid.csv'))\nvalid_dir = os.path.join(base_path, 'test')\ntest_df['target'] = ['manipuri']*len(test_df)\nif not os.path.isdir('output'):\n    os.mkdir('output')\nouput_dir = 'output'\n\nidx_class_labels = {\n    0: 'bharatanatyam',\n    1: 'kathak', \n    2: 'kathakali',\n    3: 'kuchipudi',\n    4: 'manipuri',\n    5: 'mohiniyattam',\n    6: 'odissi',\n    7: 'sattriya'\n}\nclass_idx_labels = {\n    'bharatanatyam': 0,\n    'kathak': 1,\n    'kathak ': 1,\n    'kathakali': 2,\n    'kuchipudi': 3,\n    'manipuri': 4,\n    'mohiniyattam': 5,\n    'odissi': 6,\n    'sattriya': 7\n}\n\nnum_classes = len(idx_class_labels.items())\nval_size = 0.1\n## Model Config\ntorch.manual_seed(10)","c7cd27df":"def show_sample(img, target):\n    plt.imshow(img.permute(1, 2, 0))\n    print(\"Label\" ,decode_target(int(target), text_labels=True))\n    \ndef show_difference(img1, target1, img2, target2):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n    ax1.set_title(\"Before Transformation\")\n    ax1.imshow(img1.permute(1, 2 ,0))\n    ax2.set_title(\"After Transformation\")\n    ax2.imshow(img2.permute(1, 2 ,0))\n    \ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break\n        \ndef encode_label(label):\n    idx = class_idx_labels[label] \n    return idx\n\ndef decode_target(target, text_labels=True):\n    result = []\n    if text_labels:\n        return idx_class_labels[target]\n    else:\n        return target\n## Example\n# print(encode_label('manipuri'), decode_target(2))\n# print( decode_target(2, text_labels=True))","78e2dddf":"class IndianDanceForms(Dataset):\n    def __init__(self, train_df, train_dir, transform=None):\n        self.train_dir = train_dir\n        self.train_df = train_df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.train_df)\n    \n    def __getitem__(self, idx):\n        row = self.train_df.loc[idx]\n        img_id, label = row['Image'], row['target']\n        img = Image.open(os.path.join(self.train_dir, img_id))\n        if self.transform:\n            img = self.transform(img)\n        return img, encode_label(label)","4e4c02a6":"# train_df[\"kfold\"] = -1\n# train_df = train_df.sample(frac=1).reset_index(drop=True)\n# y = train_df.target.values\n# kf = model_selection.StratifiedKFold(n_splits=10)\n# for folds_, (t_, v_) in enumerate(kf.split(X=train_df, y=y)):\n#     train_df.loc[v_, \"kfold\"] = folds_\n# train_df.head()","7dd4cad2":"padding = (10, 15, 20, 30)\ntrain_transform = transforms.Compose([\n                                transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(degrees=(-10,+10)),\n                                transforms.RandomAffine(0, translate=None, scale=(0.9, 1.1), shear=1, resample=False, fillcolor=0),\n                                transforms.Pad(padding, fill=0, padding_mode='reflect'),\n                                transforms.Resize(size=(224, 224)),\n#                                 transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                ])\nvalid_transform = transforms.Compose([\n                                transforms.Resize(size=(224, 224)),\n#                                 transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                ])\ntrain_ds = IndianDanceForms(train_df, train_dir, train_transform)\nvalid_ds = IndianDanceForms(valid_df, valid_dir, valid_transform)\nprint(len(train_ds), len(valid_ds))","56019401":"batch_size = 64\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size, shuffle=False, num_workers=2, pin_memory=True)\nshow_batch(train_dl)","84b0f5cf":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim = 1)\n    return torch.tensor(torch.sum(preds==labels).item() \/ len(preds))\n\nclass MulticlassClassifierBase(nn.Module):\n    \n    def training_step(self, batch):\n        img, label = batch\n        out = self(img)\n        loss = criterion(out, label)\n        accu = accuracy(out, label)\n        return accu ,loss\n    def validation_step(self, batch):\n        img, label = batch\n        out = self(img)\n        loss = criterion(out, label)\n        accu = accuracy(out, label)\n        return {\"val_loss\": loss.detach(), \"val_acc\": accu}\n    \n    def validation_epoch_ends(self, outputs):\n        batch_loss = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_loss).mean()\n        batch_acc = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        return {\"val_loss\":epoch_loss.item(), \"val_acc\":epoch_acc.item()}\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}],train_accu: {:.4f}, learning_rate: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['train_accu'], result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","ad507ea2":"# network = models.wide_resnet101_2(pretrained=True)\n# network","e8fd01dc":"class DanceFormModel(MulticlassClassifierBase):\n    def __init__(self):\n        super().__init__()\n        self.network = models.wide_resnet50_2(pretrained=True)\n        n_inputs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n                              nn.Linear(n_inputs, 256),\n                              nn.ReLU(),\n                              nn.Dropout(0.5),\n                              nn.Linear(256, 8),\n                              nn.LogSoftmax(dim=1)\n                                )\n    def forward(self, xb):\n        return self.network(xb)\n    \n    def freeze(self):\n        for param in self.network.parameters():\n            param.require_grad=False\n        for param in self.network.fc.parameters():\n            param.require_grad=True\n    def unfreeze(self):\n        for param in self.network.parameters():\n            param.require_grad=True\n    \n","ca071084":"# class DanceFormModel(MulticlassClassifierBase):\n#     def __init__(self):\n#         super().__init__()\n#         self.network = models.resnet50(pretrained=True)\n#         n_inputs = self.network.fc.in_features\n#         self.network.fc = nn.Sequential(\n#                               nn.Linear(n_inputs, 256),\n#                               nn.ReLU(),\n#                               nn.Dropout(0.5),\n#                               nn.Linear(256, 8),\n#                               nn.LogSoftmax(dim=1)\n#                                 )\n#     def forward(self, xb):\n#         return self.network(xb)\n    \n#     def freeze(self):\n#         for param in self.network.parameters():\n#             param.require_grad=False\n#         for param in self.network.fc.parameters():\n#             param.require_grad=True\n#     def unfreeze(self):\n#         for param in self.network.parameters():\n#             param.require_grad=True\n    ","f59cc3c3":"model = DanceFormModel()","6eb6eb27":"# def try_batch(dl):\n#     for images, labels in dl:  \n#         print(images.shape)\n#         out = model(images)\n#         print(out.shape)\n#         print(out[0])\n#         break\n# try_batch(train_dl)    ","2693da70":"@torch.no_grad()\ndef evaluate(model, valid_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in valid_loader]\n    return model.validation_epoch_ends(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit(epochs, max_lr,  model, train_loader, valid_loader, weight_decay=0, grad_clip=None,opt_func=torch.optim.SGD, max_epochs_stop=3):\n    history = []\n    \n    valid_loss_min = np.Inf\n    valid_acc_max = 0\n    model_file_name = 'indian_dance_form.pth'\n    model_file_name2 = 'indian_dance_form_max_acc.pth'\n    epochs_no_improve =  0\n    optimizer = opt_func(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.00001)\n                         \n    for epoch in range(epochs):\n        model.train()\n        train_loss = []\n        train_accu = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            \n            accu, loss = model.training_step(batch)\n            train_loss.append(loss)\n            train_accu.append(accu)\n            loss.backward()\n            ## Gradient Clipping\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            \n            \n            \n        result = evaluate(model, valid_loader)\n#         scheduler.step(result['val_loss'])\n        ########### Early Stopping ##############                                         \n        valid_loss = result['val_loss']\n        valid_acc = result['val_acc']\n        if valid_acc > valid_acc_max:\n            torch.save(model.state_dict(), model_file_name2)\n            valid_acc_max = valid_acc\n        if valid_loss<valid_loss_min:\n            torch.save(model.state_dict(), model_file_name)\n            valid_loss_min = valid_loss                                  \n            epochs_no_improve = 0          \n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve > max_epochs_stop:\n                result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n                result[\"train_accu\"] = torch.stack(train_accu).mean().item()\n                result[\"lrs\"] = lrs\n                model.epoch_end(epoch, result)\n                history.append(result)\n                print(\"Early Stopping............................\")\n                return history                                \n                                                 \n        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n        result[\"train_accu\"] = torch.stack(train_accu).mean().item()\n        result[\"lrs\"] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    print(\"VAL LOSS MIN {}\".format(valid_loss_min))\n    print(\"VAL ACC MAX {}\".format(valid_acc_max))\n    return history","6e7fc1e2":"def get_device():\n    print(torch.cuda.is_available())\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n            \n    def __len__(self):\n        return len(self.dl)","a0aa6c54":"device = get_device()\n## Loading data to devide\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)\n## Loading model to device\nmodel = to_device(DanceFormModel(), device)\n## lets try passing a batch to model again\n# try_batch(train_dl)","1a8080fa":"torch.cuda.empty_cache()","e18ade2d":"## Hyper Parameters\nmax_epochs_stop = 10\nmax_lr = 1e-4\ngrad_clip = 0.1\nweight_decay = 1e-3\nbatch_size = 64\ncriterion = nn.CrossEntropyLoss()\nepochs = 25\nopt_func = torch.optim.Adam\n## Evaluating with non-trained model\nevaluate(model, valid_dl)","533c9b4b":"## Freezing except last layer\nmodel.freeze()\n## Training\nhistory = fit(epochs, max_lr, model, train_dl, valid_dl, weight_decay, grad_clip, opt_func, max_epochs_stop)","419a1797":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \nplot_losses(history)","23797ec9":"def plot_accuracy(history):\n        \n    train_accu = [x.get('train_accu') for x in history]\n    val_accu = [x['val_acc'] for x in history]\n    plt.plot(train_accu, '-bx')\n    plt.plot(val_accu, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Accuracy vs. No. of epochs');\nplot_accuracy(history)","fecf50fb":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n    \nplot_lrs(history)","f6acdd57":"# for img, label in tqdm(valid_dl):\n#     output = model(img)\n#     _, pred = torch.max(output.cpu().detach(), dim=1)\n#     if pred != label:\n#         wrong_images.append(img)","cc2fa565":"batch_size =1\ntransform = transforms.Compose([\n                                transforms.Resize(size=(224, 224)),\n#                                 transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                ])\ntest_dataset = IndianDanceForms(test_df, test_dir, transform = transform)\ntest_dl = DeviceDataLoader(DataLoader(test_dataset, batch_size, num_workers=0, pin_memory=False), device)\n@torch.no_grad()\ndef predict_dl(dl, model):\n    torch.cuda.empty_cache()\n    batch_pred = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        _, pred = torch.max(probs.cpu().detach(), dim=1)\n        batch_pred.append(pred.cpu().detach())        \n    return [decode_target(int(x), text_labels=True) for x in batch_pred]\ndef submitting(test_dl, model, sub_fname):\n    test_preds = predict_dl(test_dl, model)\n    submission_df = test_df\n    submission_df['target'] = test_preds\n    submission_df.head()\n    submission_df.to_csv(sub_fname, index=False)\n    return submission_df","9da877c4":"model.load_state_dict(torch.load('.\/indian_dance_form.pth'))\nsubmission_df = submitting(test_dl, model, 'submission.csv')\nmodel.load_state_dict(torch.load('.\/indian_dance_form_max_acc.pth'))\nsubmission_df = submitting(test_dl, model, 'submission_with_acc.csv')","005497a8":"### Predict Single Images\ndef predict_single(image):\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    preds = model(xb)\n    _, prediction = torch.max(preds.cpu().detach(), dim=1)\n    return decode_target(int(prediction), text_labels=True)\n#     print(\"Prediction: \", int(prediction), decode_target(int(prediction), text_labels=True))\n#     show_sample(image, prediction)\n# predict_single(valid_ds[8][0])","7a68092b":"wrong_id = []\nfor i in range(len(valid_ds)):\n    preds = predict_single(valid_ds[i][0])\n    img, target = valid_ds[i]\n    target = decode_target(target)\n    if preds != target:\n        wrong_id.append(i)\nlen(wrong_id)\n# wrong_id","ad1737f4":"img_ll = []\nlabel_ll = []\npredicted_ll = []\nfor ind1 in valid_df.index:\n    for ind2 in submission_df.index:\n        if valid_df['Image'][ind1] == submission_df['Image'][ind2]:\n            if valid_df['target'][ind1] != submission_df['target'][ind2]:\n                img_ll.append(valid_df['Image'][ind1])\n                label_ll.append(valid_df['target'][ind1])\n                predicted_ll.append(submission_df['target'][ind1])\n                \ndict = {\"Image\":img_ll, \"target\":label_ll, \"predicted\":predicted_ll}\nretrain_df = pd.DataFrame(dict)\nprint(retrain_df.head())\nretrain_df.to_csv('compare.csv')","b8de0046":"### Model","5a648c5f":"### Config Files","959ee952":"Check how evaluation works","815eb18b":"## Training and Evaluating","74b6023c":"## For K-fold cross validation","701ee4f8":"## Initializing Device also Loading Data and Model to device","18e71a5f":"### Checking how each batch goes through model","70189b5e":"### Utility Functions","a63a7e47":"# Training","e9071d9b":"### Libraries","22e593cc":"## Checking the wrong one","03efc8b6":"### Applying Transformations","1741eb78":"## Creating Dataset and Dataloaders\n### Now we will Create custom dataset by extending pytorch Dataset class. We also add provision for adding transformers.","07ae4d87":"## Wrong Predictions","1d6be43c":"## Visualize","57c4f326":"### Consideration of transformations"}}