{"cell_type":{"ccb7367e":"code","e09fe17a":"code","eab1ca12":"code","207988d7":"code","910be04b":"code","5e5c134b":"code","5f62618e":"code","3b229bed":"code","0f7de961":"code","c38da39a":"code","12029be0":"code","a9f8544d":"code","b8fef24f":"code","f76a4c46":"code","0a92131d":"code","10cc37df":"code","c85f99fa":"code","de23e7b7":"code","e1908208":"code","b1da33bc":"code","b2c711fe":"code","c5ab7b76":"code","a0bfa1f5":"markdown","3f2e8881":"markdown","302fdcbc":"markdown","11a7e032":"markdown","61a2a75e":"markdown","9337e802":"markdown","d82eadda":"markdown","cc88f5c5":"markdown","06a293eb":"markdown","ce63555e":"markdown","28057228":"markdown","44955b77":"markdown","18e54f68":"markdown","b022af7d":"markdown","cf369cb3":"markdown","e779fa52":"markdown","2de0bc50":"markdown","a582eeab":"markdown","57048b23":"markdown","6c1ba8b8":"markdown","2ed795fc":"markdown","8b9dcb76":"markdown","86fce013":"markdown","bc6d6c22":"markdown","dc7cf663":"markdown","5840ae0f":"markdown","fccd3c8b":"markdown","5b72af04":"markdown","6622f0d2":"markdown"},"source":{"ccb7367e":"import pandas as pd\nimport numpy as np\nimport gc, warnings\nwarnings.filterwarnings('ignore')","e09fe17a":"sale_train = pd.read_csv('..\/input\/sales_train.csv')","eab1ca12":"print(\"----------Top-5- Record----------\")\nprint(sale_train.head(5))\nprint(\"-----------Information-----------\")\nprint(sale_train.info())\nprint(\"-----------Data Types-----------\")\nprint(sale_train.dtypes)\nprint(\"----------Missing value-----------\")\nprint(sale_train.isnull().sum())\nprint(\"----------Null value-----------\")\nprint(sale_train.isna().sum())\nprint(\"----------Shape of Data----------\")\nprint(sale_train.shape)","207988d7":"print('Number of duplicates:', len(sale_train[sale_train.duplicated()]))","910be04b":"def downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\nsale_train = downcast_dtypes(sale_train)\nprint(sale_train.info())","5e5c134b":"sales_by_item_id = sale_train.pivot_table(index=['item_id'],values=['item_cnt_day'], \n                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\nsales_by_item_id.columns = sales_by_item_id.columns.droplevel().map(str)\nsales_by_item_id = sales_by_item_id.reset_index(drop=True).rename_axis(None, axis=1)\nsales_by_item_id.columns.values[0] = 'item_id'","5f62618e":"sales_by_item_id.sum()[1:].plot(legend=True, label=\"Monthly sum\")","3b229bed":"sales_by_item_id.mean()[1:].plot(legend=True, label=\"Monthly mean\")","0f7de961":"outdated_items = sales_by_item_id[sales_by_item_id.loc[:,'27':].sum(axis=1)==0]\nprint('Outdated items:', len(outdated_items))","c38da39a":"test = pd.read_csv('..\/input\/test.csv')\nprint('Outdated items in test set:', len(test[test['item_id'].isin(outdated_items['item_id'])]))","12029be0":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sale_train['item_cnt_day'])\nprint('Sale volume outliers:',sale_train['item_id'][sale_train['item_cnt_day']>500].unique())\n\nplt.figure(figsize=(10,4))\nplt.xlim(sale_train['item_price'].min(), sale_train['item_price'].max())\nsns.boxplot(x=sale_train['item_price'])\nprint('Item price outliers:',sale_train['item_id'][sale_train['item_price']>50000].unique())","a9f8544d":"sales_by_shop_id = sale_train.pivot_table(index=['shop_id'],values=['item_cnt_day'], \n                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\nsales_by_shop_id.columns = sales_by_shop_id.columns.droplevel().map(str)\nsales_by_shop_id = sales_by_shop_id.reset_index(drop=True).rename_axis(None, axis=1)\nsales_by_shop_id.columns.values[0] = 'shop_id'\n\nfor i in range(6,34):\n    print('Not exists in month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,'0':str(i)].sum(axis=1)==0].unique())\n\nfor i in range(6,28):\n    print('Shop is outdated for month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,str(i):].sum(axis=1)==0].unique())\n","b8fef24f":"print('Recently opened shop items:', len(test[test['shop_id']==36]))","f76a4c46":"shops = pd.read_csv('..\/input\/shops.csv')\nshops.head()","0a92131d":"shops['shop_name'] = shops['shop_name'].apply(lambda x: x.lower()).str.replace('[^\\w\\s]', '').str.replace('\\d+','').str.strip()\nshops['shop_city'] = shops['shop_name'].str.partition(' ')[0]\nshops['shop_type'] = shops['shop_name'].apply(lambda x: '\u043c\u0442\u0440\u0446' if '\u043c\u0442\u0440\u0446' in x else '\u0442\u0440\u0446' if '\u0442\u0440\u0446' in x else '\u0442\u0440\u043a' if '\u0442\u0440\u043a' in x else '\u0442\u0446' if '\u0442\u0446' in x else '\u0442\u043a' if '\u0442\u043a' in x else 'NO_DATA')\nshops.head()","10cc37df":"items = pd.read_csv('..\/input\/items.csv')\nitems.head()","c85f99fa":"# Ugly code to show the idea\nfrom collections import Counter\nfrom operator import itemgetter\nitems['name_1'], items['name_2'] = items['item_name'].str.split('[', 1).str\nitems['name_1'], items['name_3'] = items['item_name'].str.split('(', 1).str\n\nitems['name_2'] = items['name_2'].str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ').str.lower()\nitems['name_3'] = items['name_3'].str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ').str.lower()\nitems = items.fillna('0')\n\nresult_1 = Counter(' '.join(items['name_2'].values.tolist()).split(' ')).items()\nresult_1 = sorted(result_1, key=itemgetter(1))\nresult_1 = pd.DataFrame(result_1, columns=['feature', 'count'])\nresult_1 = result_1[(result_1['feature'].str.len() > 1) & (result_1['count'] > 200)]\n\nresult_2 = Counter(' '.join(items['name_3'].values.tolist()).split(\" \")).items()\nresult_2 = sorted(result_2, key=itemgetter(1))\nresult_2 = pd.DataFrame(result_2, columns=['feature', 'count'])\nresult_2 = result_2[(result_2['feature'].str.len() > 1) & (result_2['count'] > 200)]\n\nresult = pd.concat([result_1, result_2])\nresult = result.drop_duplicates(subset=['feature'])\n\nprint('Most common aditional features:', result)","de23e7b7":"print('Unique item names:', len(items['item_name'].unique()))","e1908208":"import re\ndef name_correction(x):\n    x = x.lower()\n    x = x.partition('[')[0]\n    x = x.partition('(')[0]\n    x = re.sub('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ', x)\n    x = x.replace('  ', ' ')\n    x = x.strip()\n    return x\n\nitems['item_name'] = items['item_name'].apply(lambda x: name_correction(x))\nitems.head()","b1da33bc":"print('Unique item names after correction:', len(items['item_name'].unique()))","b2c711fe":"categories = pd.read_csv('..\/input\/item_categories.csv')\ncategories.head()","c5ab7b76":"test = pd.read_csv('..\/input\/test.csv')\ngood_sales = test.merge(sale_train, on=['item_id','shop_id'], how='left').dropna()\ngood_pairs = test[test['ID'].isin(good_sales['ID'])]\nno_data_items = test[~(test['item_id'].isin(sale_train['item_id']))]\n\nprint('1. Number of good pairs:', len(good_pairs))\nprint('2. No Data Items:', len(no_data_items))\nprint('3. Only Item_id Info:', len(test)-len(no_data_items)-len(good_pairs))\n  ","a0bfa1f5":"## 1.7 Category info\n* * *\nThe structure here is\n### Section name - subsection\nwe can split it and have two features from one","3f2e8881":"# Overview\nWhat is this kernel about?\n* No predictions to make \n* No features to create\n\nWe will load competition data and look closer on it. We will try to understand what we have in our hands and how we can work with it.\n* * *","302fdcbc":"## 1.2 shop_id\n* * *\n### Lets now group train data by shop_id.\nWe can see new shops - probably there will be a sales spike (opening event for example).\nApparently closed shops (ill call it \"outdated shops\")  - no sales for last 6 months.","11a7e032":"## 1.3 Price\n* * *\n### Possible Price features:\n1. Price category (1$\/10$\/20$\/ etc.) - obviously (or not obviously),  items with smaller price have greater volumes\n2. Discount and Discount duration\n3. Price lag (shows discount)\n4. Price correction (rubl\/usd pair)\n5. Shop Revenue","61a2a75e":"### Possible Category features\n1. Section\n2. Main Category name\n3. Main SubCategory name \n4. Secondary SubCategory name\n","9337e802":"### Possible Shop features:\n1. Shop City\n2. Shop Type","d82eadda":"#### Is it feature? Yes. We need to apply different prediction approach for each type of items in the test set.\n####  For example - \"No Data Items\" - it is more likely classification task.","cc88f5c5":"### Let's see how many products are outdated (no sales for the last 6 months)\n12391 of 21807 is a huge number. Probably we can set 0 for all that items and do not make any model prediction.","06a293eb":"## 1.5 Shop info\n* * *\nThe structure of the shop information is evident.\n### Shop City | Shop type | Shop name","ce63555e":"With a close look we can find out that some shops have duplicated id\/name - probably it changed location (within commercial center), or it has a different type (isle sale point), but I decided to merge it.\n* 11 => 10\n* 1  => 58\n* 0  => 57\n* 40 => 39\n\nI converted train shop_id to shop_id that is in the test set","28057228":"### Outliers by price and sales volume\nWe will get rid of them later\n\n#### please see lovely kernel made by Denis Larionov (I stole few graphs from there)\n* https:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost","44955b77":"### Item name correction\nFor our basic \"name feature\" it is enough to find identical items (not similar but identical),","18e54f68":"### How many outdated items in test set?\n6888 - not much but we have such items","b022af7d":"We can view basic DafaFrame information. \n\nAs you can see, we do not have broken and nan data that is good.","cf369cb3":"## 1.8 Test Set\n* * *\nThe key to my success was the analysis of Test test data.\n\nWe have three groups of items:\n1. Item\/shop pairs that are in train\n2. Items without any data\n3. Items that are in train","e779fa52":"### But I did manual feature extraction here to have four features.\nSection \/ Main Category name \/ Main SubCategory name \/ Secondary SubCategory name\n#### \u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b \/ PS2\t\/ PS \/ 2","2de0bc50":"### Simple graph\nWhat this graph is telling us. Basically nothing.)) I only see that train data has many old products (degradation line) and many 1c products are seasonal and probably release date depended.\n\n#### I'm not very good with graphs and presentations - there are better data representation examples:\n* https:\/\/www.kaggle.com\/dimitreoliveira\/model-stacking-feature-engineering-and-eda\n* https:\/\/www.kaggle.com\/jagangupta\/time-series-basics-exploring-traditional-ts","a582eeab":"I can advise downcasting your DataFrame. It will save you some memory, and believe me you will need all memory possible.\n\nIn our case from 134.4+ MB, we went to 61.6+ MB\n\nNot a great deal right now but such approach works with bigger DF also.\n\n#### please see this two links for more tips (I stole that downcast basic snippet from anqitu)))\n* https:\/\/www.kaggle.com\/anqitu\/feature-engineer-and-model-ensemble-top-10\n* https:\/\/www.kaggle.com\/yuliagm\/how-to-work-with-big-datasets-on-16g-ram-dask","57048b23":"We have duplicated rows, but I don't think that it is a mistake.\n\nIt could be different sales methods or client type, etc.\n\nYou can remove it, but I really don't believe that 6 rows of 3m can make the difference.","6c1ba8b8":"We can enconde \"features\" that many items have.\n\nThe structure is always the same\n### Item name [category feature] (additional feature)\nwe can split it, and \"one hot encode it.\"","2ed795fc":"## 1.1 Item_id\n* * *\n### Lets group data by item_id and date_block_num and look closer on it.\n","8b9dcb76":"### Possible item_id features:\n1. Lags\n2. Release date\n3. Last month sale\n4. Days on sale\n5. Neighbors (items with id 1000 and 1001 could be somehow similar - genre, type, release date)","86fce013":"## 1.6 Item info\n* * *\nLet's see what we can get from this file.","bc6d6c22":" ## Load train data\n * * *","dc7cf663":"### Possible Item features:\n1. Item name\n2. Encoded aditional feature ","5840ae0f":"### Possible shop_id features\n1. Lags (shop_id\/shp_cnt_mth)\n2. Opening month (possible  opening sales)\n3. Closed Month (possible stock elimination)","fccd3c8b":"## 1.4 Dates\n* * *\n### Possible Date features:\n1. Weekends and holidays sales (to correct monthly sales)\n2. Number of days in the month (to correct monthly sales)\n3. Month number (for seasonal items)","5b72af04":"In our test set we have 5100 sales in really new shop and no \"outdated shops\" but anyway it is good feature for future.","6622f0d2":"### Next part will be about data aggregation and feature preparation.\n## To be continued..."}}