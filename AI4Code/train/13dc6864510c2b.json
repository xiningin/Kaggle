{"cell_type":{"83d60e34":"code","46d24945":"code","6c04081b":"code","3a3ae8bb":"code","63a00ec8":"code","2d16eff5":"code","73bbc72b":"code","7090ca9a":"code","bd1b5839":"code","782a18e5":"code","807a6a84":"code","21d91999":"code","278de460":"code","f821a055":"code","04c69906":"code","b4dad1e8":"code","fe1f1966":"code","8e1ac5ad":"code","0fb10781":"code","d83fdd80":"code","e064c39f":"code","633ea020":"code","7216cd62":"code","706380c1":"code","5de0c0cc":"code","7fd18726":"code","b9627194":"code","b0ce9711":"code","c37177ab":"code","8f9d7601":"code","c0645f71":"code","7fe8e759":"code","25eb64ed":"code","e54e7bc1":"markdown","ca9bda4b":"markdown","8b7e16ad":"markdown","5b1c5519":"markdown","20ec5d49":"markdown","8b1c4dd5":"markdown","629ffa3a":"markdown","35d5dd83":"markdown","4543fd35":"markdown","7375d7af":"markdown","51862004":"markdown","cae90389":"markdown","e8f77877":"markdown","df4e8570":"markdown","c0a8b88f":"markdown","7c8d2ed7":"markdown","340e9380":"markdown","4e526d89":"markdown"},"source":{"83d60e34":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization\nimport matplotlib.image as mpimg\nimport tensorflow as tf # Deep Learning Framework\nimport pathlib","46d24945":"for dirpath, dirnames, filenames in os.walk('..\/input\/intel-image-classification'):\n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","6c04081b":"data_dir = pathlib.Path('..\/input\/intel-image-classification\/seg_train\/seg_train')\nclass_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\nclass_names","3a3ae8bb":"import random\ndef view_random_img(target_dir, class_names=class_names):\n    target_class = random.choice(class_names)\n    randomImg = random.choice(os.listdir(target_dir + '\/' + target_class))\n    target_path = target_dir + '\/' + target_class + '\/' + randomImg\n    \n    img = mpimg.imread(target_path)\n    plt.imshow(img)\n    plt.title(target_class)\n    plt.axis(False);","63a00ec8":"view_random_img(target_dir='..\/input\/intel-image-classification\/seg_train\/seg_train')","2d16eff5":"test_dir = '..\/input\/intel-image-classification\/seg_test\/seg_test\/'\ntrain_dir = '..\/input\/intel-image-classification\/seg_train\/seg_train\/'","73bbc72b":"# Load data from directory and turn them into batches\nIMG_SIZE = (150, 150)\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n                                                                        image_size=IMG_SIZE,\n                                                                        label_mode=\"categorical\",\n                                                                         batch_size=64)\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n                                                                        image_size=IMG_SIZE,\n                                                                        label_mode=\"categorical\",\n                                                                         batch_size=64)","7090ca9a":"# Class Names\nclass_names = train_data.class_names\nclass_names","bd1b5839":"# Create the model\nmodel_0 = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n    tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=IMG_SIZE+(3,)),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\n# Compile the model\nmodel_0.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\n# Fit the model\nhistory_0 = model_0.fit(train_data,\n                        epochs=5,\n                        steps_per_epoch=len(train_data),\n                        validation_data=test_data,\n                        validation_steps=len(test_data))","782a18e5":"# Let's check model summary\nmodel_0.summary()","807a6a84":"# Ploting loss curve\n\ndef plot_loss_curves(history):\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();\n    \n\nplot_loss_curves(history_0)","21d91999":"# Let's evaluate the model\nmodel_0.evaluate(test_data)","278de460":"# Setting up EarlyStopping Callback\nearlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          patience=3)\n# Setting up model's check point\ncheckpoint_path = 'model_checkpoint\/cp_fine_tune.ckpt'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                      monitor='val_loss',\n                                                      save_best_only=True)\n                                                    \n# Setting up ReduceLROnPlateau Callback\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                                                 patience=2, verbose=1, min_lr=1e-6)","f821a055":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(policy=\"mixed_float16\")\nmixed_precision.global_policy()","04c69906":"# Create the base model\nbase_model = tf.keras.applications.efficientnet.EfficientNetB2(include_top=False)\nbase_model.trainable=False\n# Create the funtional model\ninputs = tf.keras.Input(shape=(IMG_SIZE+(3,)))\nx = base_model(inputs, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(len(class_names))(x)\noutputs = tf.keras.layers.Activation('softmax', dtype=tf.float32)(x)\nmodel_2 = tf.keras.Model(inputs, outputs)\n\n# Compile the model\nmodel_2.compile(loss='categorical_crossentropy',\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[\"accuracy\"])\nmodel_2.summary()","b4dad1e8":"# Fit the model\nhistory_ENB2 = model_2.fit(train_data,\n                             epochs=5,\n                             steps_per_epoch=len(train_data),\n                             validation_data=test_data,\n                             validation_steps=len(test_data),\n                             callbacks=[model_checkpoint])","fe1f1966":"def plot_loss_curves(history):\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","8e1ac5ad":"plot_loss_curves(history_ENB2)","0fb10781":"result_feature_extraction = model_2.evaluate(test_data)","d83fdd80":" model_2.save('FeatureExtraction.h5')","e064c39f":"!ls","633ea020":"loaded_model = tf.keras.models.load_model('FeatureExtraction.h5')","7216cd62":"# Making Layer of our base_model trainable for fine-tuning\nloaded_model.layers[1].trainable = True","706380c1":"print(len(loaded_model.layers[1].trainable_variables))","5de0c0cc":"# Compile the loaded model for fine tuning\nloaded_model.compile(loss='categorical_crossentropy',\n                     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                     metrics=[\"accuracy\"])","7fd18726":"# Fit the fine tuned model\nhistory_fine_tune_ENB2 = loaded_model.fit(train_data,\n                                         epochs=20,\n                                         steps_per_epoch=len(train_data),\n                                         validation_data=test_data,\n                                         validation_steps=len(test_data),\n                                         callbacks=[model_checkpoint, earlystopping_callback,\n                                                   reduce_lr])","b9627194":"# Evalute our model\nloaded_model.evaluate(test_data)","b0ce9711":"def load_and_prep_image(filename, img_shape=150, scale=True):\n  # Read in the image\n  img = tf.io.read_file(filename)\n  # Decode it into a tensor\n  img = tf.io.decode_image(img)\n  # Resize the image\n  img = tf.image.resize(img, [img_shape, img_shape])\n  if scale:\n    # Rescale the image (get all values between 0 and 1)\n    return img\/255.\n  else:\n    return img","c37177ab":"import os\npred_img = os.listdir(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\")\nimport random\ncustom_images = []\nfor i in range(10):\n  custom_images.append(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\"+random.choice(pred_img))\n\ncustom_images","8f9d7601":"# Make predictions on custom images\nplt.figure(figsize=(15,13),tight_layout=True)\nfor i, img in enumerate(custom_images):\n    img = load_and_prep_image(img, scale=False) # load in target image and turn it into tensor\n    pred_prob = loaded_model.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [None, 150, 150, 3]\n    pred_class = class_names[pred_prob.argmax()] # find the predicted class label\n    \n  \n    # Plot the image with appropriate annotations\n    plt.subplot(2, 5, i+1)\n    plt.imshow(img\/255.) # imshow() requires float inputs to be normalized\n    plt.title(f\"pred: {pred_class} | prob: {pred_prob.max():.2f}\")\n    plt.axis(False)","c0645f71":"def pred_plot(file, model, class_names=class_names, image_size=(150, 150)):\n    img = tf.io.read_file(file)\n    img = tf.io.decode_image(img, channels=3)\n    img = tf.image.resize(img, size=image_size)\n    \n    pred_probs = model.predict(tf.expand_dims(img, axis=0))\n    pred_class = class_names[pred_probs.argmax()]\n    \n    plt.imshow(img\/225.)\n    plt.title(f'Pred: {pred_class}')\n    plt.axis(False);","7fe8e759":"url ='..\/input\/mountain1\/mountaain.jpg'\npred_plot(url, model=model_2, class_names=class_names)","25eb64ed":"# Save fine tune model\nloaded_model.save('fine-tune-ENB2.h5')","e54e7bc1":"## Visualizing the data","ca9bda4b":"### Compile and Fit the model for fine tuning","8b7e16ad":"### Mixed Precision\n\nMixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory.","5b1c5519":"## Evaluating our model","20ec5d49":"### Load the model for Fine tuning","8b1c4dd5":"## Basic CNN model","629ffa3a":"## Ploting loss curve","35d5dd83":"## Required Libraries","4543fd35":"## Let's now try to train the model on augmented data and see if there is any difference in performance.","7375d7af":"### Looks like our intial model is performing ok. But it can perform better.","51862004":"## Explore the data","cae90389":"### Create the Feature Extraction model","e8f77877":"### Let's view some predicted results.","df4e8570":"### Setting Callbacks","c0a8b88f":"### Evaluate and save the Feature Extraction model","7c8d2ed7":"# Intel Image Classification using CNN\n\nIn this notebook I have build a basic CNN model. Then I have used Transfer Learning using EfficientNetB2.","340e9380":"## Prepare the data","4e526d89":"### Plot the loss curve"}}