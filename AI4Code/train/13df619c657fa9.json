{"cell_type":{"f669ab91":"code","4553d45c":"code","273cae01":"code","81688944":"code","166f7a74":"code","6ab9a1b6":"code","53158236":"code","2ad5e44e":"code","4c864622":"code","b617ba99":"code","09c6720c":"code","4ec55fe7":"code","3090470a":"code","67e5436d":"code","3867f706":"code","5949fcd4":"code","04f61722":"code","7fae2944":"code","21244494":"markdown","9e9f2c82":"markdown","62b0e130":"markdown","50bf6ae5":"markdown","e79749ed":"markdown","fce0a428":"markdown","2f39e818":"markdown","91d7a133":"markdown","48ed2d87":"markdown","647d6ab3":"markdown","b26da5bd":"markdown","79f8ec9a":"markdown","83c629e5":"markdown","00238292":"markdown","1940d19f":"markdown","2fcf9a20":"markdown","8844e038":"markdown","59a5375e":"markdown","3c903fd1":"markdown"},"source":{"f669ab91":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4553d45c":"#path varies depending if I am running on my own machine or Kaggle\n\nmy_path = \"\/Users\/Ethan\/Desktop\/Desktop - Ethan\u2019s MacBook Air\/Personal Projects\/Baseball\/fan-engagement\/data\"\n\nkaggle_path = \"..\/input\/mlb-player-digital-engagement-forecasting\"","273cae01":"def read_data(path, file):\n    \n    df = pd.read_csv(f\"{path}\/{file}.csv\")\n    \n    num_rows = len(df)\n    num_cols = len(df.columns)\n    mem_usage = df.memory_usage(deep = True).sum()\n    \n    print(f\"{file}.csv: {num_rows} rows; {num_cols} columns; {mem_usage} bytes of memory.\")\n    return df","81688944":"#change my_path to kaggle_path when running on Kaggle\n\ntrain = read_data(kaggle_path, \"train\")\nteams = read_data(kaggle_path, \"teams\")\nseasons = read_data(kaggle_path, \"seasons\")\nplayers = read_data(kaggle_path, \"players\")\nawards = read_data(kaggle_path, \"awards\")\nexample_test = read_data(kaggle_path, \"example_test\")\nexample_submission = read_data(kaggle_path, \"example_sample_submission\")","166f7a74":"train.head()","6ab9a1b6":"train.info()","53158236":"def json_to_df(df, column):\n    \n    num_rows = len(df)\n    \n    data_list = []\n    for row in range(num_rows):\n        \n        json_data = df.iloc[row][column]\n        if str(json_data) != \"nan\": #we don't want to append NA values in the dataframes\n            data = pd.read_json(json_data)\n            data_list.append(data)\n        \n    all_data = pd.concat(data_list, axis = 0)\n    \n    num_rows = len(all_data)\n    num_cols = len(all_data.columns)\n    mem_usage = all_data.memory_usage(deep = True).sum()\n    \n    print(f\"{column}: {num_rows} rows; {num_cols} cols; {mem_usage} bytes.\")\n    return all_data","2ad5e44e":"#a list of the 11 columns, not including the date.  We have this info in each json cell anyway.\n\nnested_columns = train.columns[1:]","4c864622":"#we yield 11 dataframes from train.csv\n\nengage, games, rosters, player_boxes, team_boxes, transactions, standings, awards, events, player_twitter, team_twitter = [json_to_df(train, var) for var in nested_columns]","b617ba99":"engage.head()","09c6720c":"from datetime import datetime, timedelta","4ec55fe7":"engage[\"engagementMetricsDate\"] = pd.to_datetime(engage[\"engagementMetricsDate\"])\n\n#As the competiton notes, the engagement data corresponds to information from the day prior.  Therefore, when\n#joining this data to any other data, we need to join on the previous day.  \n\nengage[\"engagementMetricsDate\"] = engage[\"engagementMetricsDate\"] - timedelta(days = 1)\n\nengage = engage.rename(columns = {\"engagementMetricsDate\": \"date\"})","3090470a":"games[\"gameDate\"] = pd.to_datetime(games[\"gameDate\"])\nrosters[\"gameDate\"] = pd.to_datetime(rosters[\"gameDate\"])\nplayer_boxes[\"gameDate\"] = pd.to_datetime(player_boxes[\"gameDate\"])\nteam_boxes[\"gameDate\"] = pd.to_datetime(team_boxes[\"gameDate\"])\ntransactions[\"date\"] = pd.to_datetime(transactions[\"date\"])\nstandings[\"gameDate\"] = pd.to_datetime(standings[\"gameDate\"])\nawards[\"awardDate\"] = pd.to_datetime(awards[\"awardDate\"])\nevents[\"gameDate\"] = pd.to_datetime(events[\"gameDate\"])\nplayer_twitter[\"date\"] = pd.to_datetime(player_twitter[\"date\"])\nteam_twitter[\"date\"] = pd.to_datetime(team_twitter[\"date\"])\n\ngames = games.rename(columns = {\"gameDate\": \"date\"})\nrosters = rosters.rename(columns = {\"gameDate\": \"date\"})\nplayer_boxes = player_boxes.rename(columns = {\"gameDate\": \"date\"})\nteam_boxes = team_boxes.rename(columns = {\"gameDate\": \"date\"})\nstandings = standings.rename(columns = {\"gameDate\": \"date\"})\nawards = awards.rename(columns = {\"awardDate\": \"date\"})\nevents = events.rename(columns = {\"gameDate\": \"date\"})","67e5436d":"engage.head()","3867f706":"player_twitter.head()","5949fcd4":"#It is important to left join since we don't want to lose any information regarding target variables.\n\nengage_twitter = pd.merge(engage, player_twitter, on = [\"date\", \"playerId\"], how = \"left\")","04f61722":"engage_twitter.head()","7fae2944":"#engage.to_csv(\"..\/fan-engagement\/data\/engage.csv\", index = False)\n#games.to_csv(\"..\/fan-engagement\/data\/games.csv\", index = False)\n#rosters.to_csv(\"..\/fan-engagement\/data\/rosters.csv\", index = False)\n#player_boxes.to_csv(\"..\/fan-engagement\/data\/player_boxes.csv\", index = False)\n#team_boxes.to_csv(\"..\/fan-engagement\/data\/team_boxes.csv\", index = False)\n#transactions.to_csv(\"..\/fan-engagement\/data\/transactions.csv\", index = False)\n#standings.to_csv(\"..\/fan-engagement\/data\/standings.csv\", index = False)\n#awards.to_csv(\"..\/fan-engagement\/data\/awards.csv\", index = False)\n#events.to_csv(\"..\/fan-engagement\/data\/events.csv\", index = False)\n#player_twitter.to_csv(\"..\/fan-engagement\/data\/player_twitter.csv\", index = False)\n#team_twitter.to_csv(\"..\/fan-engagement\/data\/team_twitter.csv\", index = False)","21244494":"Each row in this dataset corresponds to every date spanning from January 1st, 2018 through April 30th, 2021, and missing values often correspond to off-season dates.  The MLB pre-season (Spring Training) usually starts in late February and the post-season usually ends in late October.  The regular season usually spans from the beginning of April through the end of September.  Transactions (trades) and awards are not daily occurances, and Twitter followers are recorded at the 1st of every month according to the competition.","9e9f2c82":"## Cleaning","62b0e130":"## Merging: Example","50bf6ae5":"# MLB Fan Engagement - Getting Started","e79749ed":"We can now save all of the converted data for my next notebook, which will involve merging much of the data, cleaning, and feature selecting.  Thanks for reading!","fce0a428":"In this notebook, I will import all of the original data from Kaggle's MLB fan engagement competition (https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/data) and clean it into a format that allows me to easily analyze, select features, and create models.\n\nThis notebook should serve as a guide for getting started on this competition by organizing these large amounts of data.  This notebook will also be well-documented so that I can explain the information that all of the data conveys.","2f39e818":"Notice how our keys of interest are date and player id.  All data in the player_twitter df corresponds to engagement data for the next day, so these dataframes are ready to be merged.","91d7a133":"Each of these dataframes contain keys of date and player id, including the engagement target variable dataframe.  We can later use these keys to join all dataframes together when analyzing and creating the models.","48ed2d87":"NA's represent dates that aren't the first of the month or players who don't have Twitter info.","647d6ab3":"The new engagement dataframe now has dates that corresponds to targets for the next day.","b26da5bd":"Events make up a massive amount of information because it includes many variables for each individual pitch.","79f8ec9a":"## Importing the Data","83c629e5":"An example of a dataframe created from a json column:","00238292":"## Unnesting the Training Data ","1940d19f":"train.csv is the main dataset of interest and takes up a large amount of memory because each cell corresponds to a multitude of information at a given date.  All of this information is stored in json format.  The rest of the dataframes are helpful for identifying teams and players from their IDs, recording when each season begins, etc.","2fcf9a20":"Now, some cleaning is required.  We need to convert each date into a pandas datetime object and then make sure all keys are named identically so we can join the data as we please.","8844e038":"Now, for train.csv, we need to convert the json from each cell into dataframes.  Each of the 11 columns will correspond to a dataframe, as nextDayPlayerEngagement represents the target variables.  The following function will convert the json into a dataframe given a column from train.csv.","59a5375e":"## Conclusion","3c903fd1":"First, I will import the data and explain what we are working with."}}