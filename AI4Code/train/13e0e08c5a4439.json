{"cell_type":{"7dc8b126":"code","9f3f12e5":"code","2e0299c0":"code","01cfe852":"code","9275105c":"code","732121d5":"code","ba1a2620":"code","760aea87":"code","8cce55de":"code","08a23bc2":"code","c7c6342a":"code","60f955c9":"code","b17d4217":"code","13704587":"code","c0133fbf":"code","299ee55a":"code","2dd03b00":"code","c9eb4a4b":"code","4ec537de":"code","ef6c1821":"code","4ae0a855":"code","34f28432":"code","739130a3":"code","9e127f8f":"code","9faa3f9b":"code","504195cb":"code","9fd436ed":"code","f0126e85":"markdown","a7457300":"markdown","6572df3c":"markdown","d8dca409":"markdown","e33a71d7":"markdown","0e0f7474":"markdown","57c6c0a3":"markdown","8fdb9569":"markdown","98628120":"markdown","2732c173":"markdown","369b6528":"markdown","1b9a1201":"markdown","59d63a8d":"markdown","01c43105":"markdown","73caa151":"markdown","be6b1556":"markdown","e1ea489f":"markdown","0f18ffe0":"markdown","92d06033":"markdown","927e6ff4":"markdown","c9348fa8":"markdown","edce2d99":"markdown","b39cc9da":"markdown"},"source":{"7dc8b126":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f3f12e5":"data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nvalidation = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv') ","2e0299c0":"print('data shape: ', data.shape)\nprint('validation shape', validation.shape)","01cfe852":"data.head()","9275105c":"validation.head()","732121d5":"from sklearn.utils import resample","ba1a2620":"data_sample = resample(data, n_samples = 5000)","760aea87":"data_sample.shape","8cce55de":"import matplotlib.pyplot as plt","08a23bc2":"X = data_sample.drop(['label'], axis = 1)\ny = data_sample.label","c7c6342a":"plt.hist(y)\nplt.show()","60f955c9":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)","b17d4217":"from sklearn import neighbors\nknn = neighbors.KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test)","13704587":"from sklearn import svm\nsvc = svm.SVC()\nsvc.fit(X_train, y_train)\nsvc.score(X_test, y_test)","c0133fbf":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef prep_data(raw):\n    raw = raw.to_numpy()\n    y = raw[:, 0]\n    out_y = keras.utils.to_categorical(y, num_classes)\n    \n    x = raw[:,1:]\n    num_images = raw.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x \/ 255\n    return out_x, out_y\n\nX, y = prep_data(data)","299ee55a":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)","2dd03b00":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D","c9eb4a4b":"#define\nmodel = Sequential()\n\nmodel.add(Conv2D(12, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\n\nmodel.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(40, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(60, kernel_size=(3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n#compile\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n#fit\nmodel.fit(X_train, y_train,\n          validation_data = (X_test, y_test),\n          batch_size = 32,\n          epochs = 10)\n#note: you have multiple ways of doing the validation. The validation_data (and thus the train\/test split) is not necessary\n#as you can use the validation_split argument that will automatically select a part of the input data for the validation","4ec537de":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy : %.2f%%\" % (scores[1]*100))","ef6c1821":"model.save(\"digitRecognizerModel.h5\")\nprint(\"The model has been saved!\")","4ae0a855":"preds = model.predict_classes(X_test)","34f28432":"#our y_test was categorical, so let's get it back to normal\ny_test_transfo = y_test.argmax(1)","739130a3":"wrong_preds = []\nfor i in range(0, len(preds), 1):\n    if preds[i].any() != y_test_transfo[i].any():\n        wrong_preds.append(i)","9e127f8f":"plt.figure(figsize=(15,25))\ni=1\nfor j in wrong_preds:\n    plt.subplot(10,5,i)\n    plt.axis('off')\n    plt.imshow(X_test[j][:,:,0])\n    pred_classe = preds[j].argmax(axis=-1)\n    plt.title('Prediction : %d \/ Label : %d' % (preds[j], y_test_transfo[j]))\n    i+=1","9faa3f9b":"validation = validation.to_numpy()\n\nnum_images = validation.shape[0]\nx_val = validation.reshape(num_images, img_rows, img_cols, 1)\nx_val = x_val \/ 255\n\ny_val = model.predict_classes(x_val)","504195cb":"sub = pd.DataFrame()\nsub['ImageId'] = list(range(1, validation.shape[0] + 1))\nsub['Label'] = y_val","9fd436ed":"sub.to_csv('sub_file.csv', index=False)","f0126e85":"Let's save our model so we don't have to train it everytime we need it.","a7457300":"### K-nn","6572df3c":"## How can we improve the accuracy?\n\nTo see if we can improve the accuracy, first, let's take look at the digits that were not predicted correctly by our neural model.","d8dca409":"### Train\/Test split","e33a71d7":"A quick look at the distribution shows that the classes are distributed in an acceptable way.","0e0f7474":"## Bonus : Submission\n\nLast but not least, how to submit your results to enter the competition.\n\nAfter a quick pre-processing, we can use our model make predictions from our validation data.\n\nWe then store those predictions in a dataframe with an ID for each picture, for submissions requirements.\n\nLast step, we convert our dataframe to a csv file that we can find in the Kaggle output section.","57c6c0a3":"# Conclusion\n\nWe can clearly see that in the digit recognizer case, the Convolutional Neural Network surpasses the classifiers. Without really tuning any of them, the difference in accuracy is in a few percents, which is huge in our case.\n\nWe managed to reach an accuracy above 98%, which only leaves a few samples that are hard to read, even for a human being. \n\n### Thanks for reading this notebook!","8fdb9569":"### Is that accuracy good?\n\nThe results are already quite impressive: considering that we have 10 different classes that are almost equally distributed, the lowest accuracy score would be 10%.\n\nWe could try to improve our classifiers accuracy by tuning their parameters with the [GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html) optimizer, but it won't improve the results that much in our case.","98628120":"### Data sampling\n\nFor execution time purposes, we will only select a sample of our data. ","2732c173":"The 3 main steps to build a CNN model :\n\n- **definition:** we set the model structure: the type and the number of kernels, as well as their parameters\n- **compilation:** we choose which parameters will be used as a basis for the model optimization\n- **fitting:** we finally train the model, and choose the training parameters","369b6528":"### X\/Y definition ","1b9a1201":"## Data processing for the classifiers\n\nAs the input data is different for the classifiers and the CNN, we will have to do this data processing part for each of our approaches.","59d63a8d":"## Data pre-processing","01c43105":"## Building our classifiers\n\nFor the classifiers, let's try two of the most common ones, the K-nn and the SMV.","73caa151":"Every digit picture is composed of 784 pixels : 28 rows of 28 pixels, to form a 28x28 matrix. The values go from 0 to 255, representing the darkness of every pixel.\n\nIn our dataset, the pixels have been transformed from a matrix of 28 by 28 to a row of 748 elements, for storage purposes.","be6b1556":"### SVM","e1ea489f":"Obviously, the data shape has a label column, the first one, while the validation one hasn't, because we have to predict it.","0f18ffe0":"We can clearly see that our model has a tendancy to predict 0 wrongly. \n\nBut in the meantime, those digits are badly written: even a human could be wrong at guessing the numbers below.","92d06033":"# CNN","927e6ff4":"### X\/Y definition\n\nWe are going to use a short function called prep_data that will do the data preprocessing for us. This one was taken from the Kaggle Deep Learning course.","c9348fa8":"### Train\/Test split","edce2d99":"### Building the model","b39cc9da":"# Digit Recognizer: Basic Classifiers VS CNN\n\nOur objective here is to try two different approachs to build a digit recognizer tool.\n\nThe first approach will use classifier models, in our case the K-nn and the SVM classifiers. For the second approach, we will use a Convolutional Neural Network (CNN).  \n\nIn the end, we'll be able to compare our two approachs and see which one provides us the best digit predictions. \n\n> *Spoiler alert: the CNN will overwhelm the classifiers :)*\n\n**Enjoy reading!**"}}