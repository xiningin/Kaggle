{"cell_type":{"10774556":"code","41df15c5":"code","61825c90":"code","35f8fa34":"code","2f28ed03":"code","574fdf24":"code","ebcedbbd":"code","0b123b2d":"code","0ddea2c5":"code","5b77d2c3":"code","b6b8c005":"code","3d99f5b8":"code","6474a1ee":"code","b5954b05":"code","1373b3f7":"code","bf817bf2":"code","d64d7485":"code","b7dd37bc":"code","f5720406":"code","d4bfcbf4":"code","cd387f6c":"code","f73a74bc":"code","0e6ddee3":"code","d546b304":"markdown","ec3b8525":"markdown","a64cffd1":"markdown","fdfbf827":"markdown","e6ac3ce7":"markdown","817c8a3a":"markdown","eec7fd63":"markdown","3cabe1c2":"markdown","f0158447":"markdown"},"source":{"10774556":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","41df15c5":"data = pd.read_csv(\"..\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")","61825c90":"data.isnull().sum()","35f8fa34":"data = data.dropna()\ndata.isnull().any()","2f28ed03":"fig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(abs(data.corr()), annot=True, square=True, cbar=False, ax=ax, linewidths=0.25);","574fdf24":"data = data.drop(columns= ['Direct_Bilirubin', 'Alamine_Aminotransferase', 'Total_Protiens'])","ebcedbbd":"data['Dataset'] = data['Dataset'].replace(1,0)\ndata['Dataset'] = data['Dataset'].replace(2,1)","0b123b2d":"print('How many people to have disease:', '\\n', data.groupby('Gender')[['Dataset']].sum(), '\\n')\nprint('How many people participated in the study:', '\\n', data.groupby('Gender')[['Dataset']].count())","0ddea2c5":"print('Percentage of people with the disease depending on gender:')\ndata.groupby('Gender')[['Dataset']].sum()\/ data.groupby('Gender')[['Dataset']].count()","5b77d2c3":"age=pd.cut(data['Age'], [0,18,91])\nprint('Distribution of the disease by gender and age')\ndata.pivot_table('Dataset', ['Gender', age])","b6b8c005":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","3d99f5b8":"X = data[['Age', 'Gender', 'Total_Bilirubin','Alkaline_Phosphotase','Aspartate_Aminotransferase','Albumin','Albumin_and_Globulin_Ratio']]\ny = pd.Series(data['Dataset'])","6474a1ee":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nX['Gender'] = labelencoder.fit_transform(X['Gender'])","b5954b05":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(x_train)\nX_test = scaler.transform(x_test)","1373b3f7":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean","bf817bf2":"ABC = AdaBoostClassifier()","d64d7485":"def get_models():\n        models = dict()\n        models['10'] = AdaBoostClassifier(n_estimators=10)\n        models['30'] = AdaBoostClassifier(n_estimators=30)\n        models['50'] = AdaBoostClassifier(n_estimators=50)\n        models['75'] = AdaBoostClassifier(n_estimators=75)\n        models['100'] = AdaBoostClassifier(n_estimators=100)\n        models['125'] = AdaBoostClassifier(n_estimators=125)\n        models['150'] = AdaBoostClassifier(n_estimators=150)\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n\nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('n_estimators')\nplt.show()    ","b7dd37bc":"def get_models():\n        models = dict()\n        for i in range(1,15):\n            models[str(i)] = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=i))\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n \nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('max_depth')\nplt.show()","f5720406":"def get_models():\n        models = dict()\n        for i in range(1, 21, 1):\n            per = i\/10\n            key = '%.3f' % per\n            models[key] = AdaBoostClassifier(learning_rate=per)\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n \nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.xticks(rotation=45)\nplt.title('Learning rate')\nplt.show()","d4bfcbf4":"ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n                         n_estimators=125,\n                        learning_rate = 0.6,\n                        random_state=42)\n\nABC.fit(X_train, y_train)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(ABC, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n('Accuracy: %.3f' % (mean(n_scores)))","cd387f6c":"labels = ABC.predict(X_test)\nmatrix = confusion_matrix(y_test, labels)\nsns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\nplt.xlabel('true label')\nplt.ylabel('predicted label');","f73a74bc":"logit_roc_auc = roc_auc_score(y_test, labels)\nfpr, tpr, thresholds = roc_curve(y_test, ABC.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='(area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","0e6ddee3":"print(classification_report(y_test, labels))","d546b304":"### Data analysis ###","ec3b8525":"### Train model ###","a64cffd1":"Women have a higher percentage of the disease, so we will conduct a separate study, depending on the gender of the person.","fdfbf827":"In this nootbook I use AdaBoostClassifier and the base estimator is DecisionTreeClassifier.\nLet`s look at some of the hyperparameters that we can consider tuning for the AdaBoost ensemble and their effect on model productivity:\n1. Number of Trees - 'n_estimators'\n2. Max depth of the trees\n3. Learning Rate\n\nFor it we to do:\n- create dictionary of models with differents hyperparameters\n- evaluate the model using repeated k-fold cross-validation\n- look at the mean of the accuracy of the each model across all repeats and folds.","e6ac3ce7":"Thanks to https:\/\/machinelearningmastery.com\/\n\n### HAPPY Coding ###","817c8a3a":"We can see that with these hyperparameters model predict from people with disease 1:3.\nSo it is can miss many people with desease and for improvement model need more data.","eec7fd63":"Among men with the disease at risk young people under 18 years of age.","3cabe1c2":"Now we choose the appropriate hyperparameters and train the model.","f0158447":"As we can see there are correlation: 'Total_Bilirubin'-'Direct_Bilirubin', 'Alamine_Aminotransferase'-'Aspartate_Aminotransferase', 'Total_Protiens'-'Albumin'.\nI drop from data: 'Direct_Bilirubin', 'Alamine_Aminotransferase', 'Total_Protiens'.\n\nAnd data look like:\n\nCategorical:\n- Gender\n\nContinuous data:\n- Age\n- Total_Bilirubin\n- Alkaline_Phosphotase\n- Aspartate_Aminotransferase\n- Albumin\n- Albumin_and_Globulin_Ratio"}}