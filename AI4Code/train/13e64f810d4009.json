{"cell_type":{"4a029312":"code","f7d992c6":"code","88b9a9a8":"code","8169a38d":"code","50dad0e1":"code","c3e0d378":"code","72ee3f2f":"code","6aed1853":"code","53e6bb18":"code","4653f43a":"code","1a7f42af":"code","53a38a6c":"code","a417f967":"code","1c3f0b08":"code","2fbdc74b":"code","27c98ce6":"code","d7c8a151":"code","a1154d0d":"code","9f3ac945":"code","3849569a":"code","b3c87413":"code","017144dd":"code","9df25b0a":"code","60d75f50":"code","e48a68ae":"code","410d335d":"code","633e6450":"code","61489ac0":"code","62b314ea":"code","c89b593e":"code","41c76d4a":"markdown","73ddf80f":"markdown","cc5b08f6":"markdown","4526bc2a":"markdown","ea05d93f":"markdown","2f434d48":"markdown","f300cd58":"markdown"},"source":{"4a029312":"import tensorflow as tf\nimport keras\nprint(keras.__version__)","f7d992c6":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport random\nfrom PIL import Image \nfrom skimage.io import imread","88b9a9a8":"leafType = os.listdir(\"..\/input\/augmented\/data\/train\") # list of all the leaf types in the dataset\nmain_dir = \"..\/input\/augmented\/data\" ## main directory\ntrain_dir = \"..\/input\/augmented\/data\/train\" ## train directory\ntest_dir = \"..\/input\/augmented\/data\/valid\" ## test directory\nprint('base_dir:', (os.listdir(main_dir )))\nprint('total nubmer of classes:', len(os.listdir(train_dir )))","8169a38d":"import matplotlib.image as mpimg\npath = test_dir+'\/Diseased'\nimages = os.listdir(path)","50dad0e1":"images[0:10]","c3e0d378":"img = mpimg.imread(path+'\/'+images[74])\n\nplt.imshow(img)","72ee3f2f":"# number of samples for each class i.e images in each directory\nprint('total nubmer of images of each class in train set')\nfor i in leafType:\n    temp_dir = os.path.join(train_dir, i)\n    print(i[0:50],\":  \", len( os.listdir(temp_dir)))\n    \n    \nprint('\\ntotal nubmer of images of each class in test set')    \nfor i in leafType:\n    \n    temp_dir = os.path.join(test_dir, i)\n    print(i[0:50],\":  \", len( os.listdir(temp_dir)))","6aed1853":"import numpy as np\nimport matplotlib.pyplot as plt","53e6bb18":"\n\nw = 10\nh = 10\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\n\nfor i in range(columns*rows):\n    img = np.random.randint(10, size=(h,w))\n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"ax:\"+str(i))  # set title\n    plt.imshow(img, alpha=0.25)\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show() ","4653f43a":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport random\nfrom PIL import Image \nfrom skimage.io import imread","1a7f42af":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# --------------------\n# Flow training images in batches of 32 using train_datagen generator\n# --------------------\ntrain_it = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=32,\n                                                    class_mode='binary',\n                                                    target_size=(224,224))     \n# --------------------\n# Flow validation images in batches of 32 using test_datagen generator\n# --------------------\ntest_it =  test_datagen.flow_from_directory(test_dir,\n                                                         batch_size=32,\n                                                         class_mode  = 'binary',\n                                                         target_size = (224,224))","53a38a6c":"np.unique(train_it.classes)","a417f967":"import tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model \n","1c3f0b08":"# # Flatten the output layer to 1 dimension\n# x = layers.Flatten()(base_model.output)\n\n# inputs = tf.keras.Input(shape=(3,))\n# # Add a fully connected layer with 512 hidden units and ReLU activation\n# x = layers.Dense(512, activation='relu')(x)\n\n# # Add a dropout rate of 0.5\n# x = layers.Dropout(0.5)(x)\n\n# # Add a final sigmoid layer for classification\n# x = layers.Dense(1, activation='relu')(x)\n\n# model = tf.keras.models.Model(base_model.input, x)\n\n# model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['accuracy'])\n\n# model.summary()\n\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nmodel = Sequential()\ninputShape = (224,224,3)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (3,224,224)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nmodel.summary()","2fbdc74b":"history = model.fit(train_it, validation_data = test_it, validation_steps = 50,\n  steps_per_epoch = 100, epochs = 50, verbose=1, batch_size= 64)","27c98ce6":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d7c8a151":"import seaborn as sns\nY_pred = model.predict_generator(test_it)\nsns.kdeplot(Y_pred[:,0])","a1154d0d":"acc = model.evaluate_generator(test_it)\n","9f3ac945":"acc","3849569a":"from keras.preprocessing import image\npath1 = \"..\/input\/augmented\/data\/valid\/Diseased\/\"\npath2 = \"..\/input\/augmented\/data\/valid\/Healthy\/\"\n\nlist1 = os.listdir(path1)\nlist2 = os.listdir(path2)\ny_predicted = []\ny_actual = []\n\n#diseased class first\nfor i in range(len(list1)):\n    y_actual.append(0)\n    path_val_image = path1 +'\/'+list1[i] # path of image\n    img = image.load_img(path_val_image, target_size=(224, 224,3))\n    x = image.img_to_array(img).reshape(-1,224,224,3)\n    x = x\/255\n    classes = model.predict(x)\n#     print(classes)\n    if classes<0.5:\n        y_predicted.append(0)\n    else:\n        y_predicted.append(1)\n        \n        \n# print('&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&')\n\nfor i in range(len(list2)):\n    y_actual.append(1)\n    path_val_image = path2 +'\/'+list2[i] # path of image\n    img = image.load_img(path_val_image, target_size=(224, 224,3))\n    x = image.img_to_array(img).reshape(-1,224,224,3)\n    x = x\/255\n    classes = model.predict(x)\n#     print(classes)\n    if classes<0.5:\n        y_predicted.append(0)\n    else:\n        y_predicted.append(1)\n    \n","b3c87413":"from sklearn.metrics import classification_report, confusion_matrix\ntarget_names = ['Diseased', 'Healthy']\n\nprint('Confusion Matrix')\nprint(confusion_matrix(y_actual, y_predicted))\nprint('Classification Report')\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","017144dd":"from keras.preprocessing import image\n\npp_ = \"..\/input\/binaryplantdisease\/PlantDIseaseDataset\/valid\/Diseased\/\"\nimgs_list = os.listdir(pp_)\n\n\npath_val_image = pp_+'\/'+imgs_list[40] # copied path of image\nprint(path_val_image)\nimg = image.load_img(path_val_image)\nprint(img.size)\nplt.imshow(img)\nplt.show()\n\n\nimg = image.load_img(path_val_image, target_size=(224, 224,3))\nx = image.img_to_array(img).reshape(-1,224,224,3)\nx = x\/255\n# x = np.vstack([x])\n# img = np.expand_dims(x, axis=0)\n\nclasses = model.predict(x)\nprint(classes)\nif classes<0.5:\n    print(\" diseased\")\nelse:\n    print(\"healthy\")","9df25b0a":"path_val_image = \"..\/input\/augmented\/data\/train\/Diseased\/001187a0-57ab-4329-baff-e7246a9edeb0___RS_Early.B 8178_flipTB.JPG\" # copied path of image\nimg = mpimg.imread(path_val_image)\nplt.imshow(img)\nplt.show()","60d75f50":"img = image.load_img(path_val_image, target_size=(224, 224))\nx = image.img_to_array(img)\nx = x\/255\nx = np.vstack([x])\nimg = np.expand_dims(x, axis=0)\n\nclasses = model.predict(img)\nprint(classes)\nif classes<0.5:\n    print(\" diseased\")\nelse:\n    print(\"healthy\")","e48a68ae":"path_val_image = \"..\/input\/real-life-image\/real_life_plant.jpg\" # copied path of image\nimg = mpimg.imread(path_val_image)\nplt.imshow(img)\nplt.show()","410d335d":"\n\nimg = image.load_img(path_val_image, target_size=(224, 224))\nx = image.img_to_array(img)\nx = x\/255\nx = np.vstack([x])\nimg = np.expand_dims(x, axis=0)\n\nclasses = model.predict(img)\nprint(classes)\nif classes<0.5:\n    print(\" diseased\")\nelse:\n    print(\"healthy\")","633e6450":"# serialize to JSON\njson_file = model.to_json()\nwith open('\/kaggle\/working\/layers.txt', \"w\") as file:\n    file.write(json_file)\n# serialize weights to HDF5\nmodel.save_weights('model_weights.h5')\n\n","61489ac0":"# loading the model\nfrom keras.models import model_from_json\nfile = open('\/kaggle\/working\/layers.txt', 'r')\nmodel_json = file.read()\nfile.close()\nloaded_model = model_from_json(model_json)\n# load weights\nloaded_model.load_weights('model_weights.h5')","62b314ea":"import pathlib \nimport tensorflow as tf\n\nconverter =  tf.lite.TFLiteConverter.from_keras_model(loaded_model)\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\ntflite_model = converter.convert()","c89b593e":"tflite_model_file = pathlib.Path('ssaPlantDiseaseDetector.tflite')\ntflite_model_file.write_bytes(tflite_model)","41c76d4a":"# Testing on real life plant leaf picture\n","73ddf80f":"## PlantDiseaseDetection","cc5b08f6":"## predicting classes","4526bc2a":"#  **converting into tflite file**\n\n","ea05d93f":"## Exploring data","2f434d48":"## Image data preprocessing\n","f300cd58":"## Building a model "}}