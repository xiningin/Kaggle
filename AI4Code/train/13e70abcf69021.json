{"cell_type":{"0e431aab":"code","a31e2736":"code","21828fa2":"code","daf0fcb2":"code","68e61d9a":"code","9e571a89":"code","fd47d209":"code","c76da131":"code","32cabe40":"markdown","e6b38f48":"markdown","983645ac":"markdown","7fe7aee3":"markdown","fc4aa180":"markdown"},"source":{"0e431aab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a31e2736":"# Get the support classes that were used to create this dataset\n!git clone https:\/\/github.com\/z-a-f\/zaf_funcs.git","21828fa2":"import pickle\nfrom zaf_funcs.transforms import *\n\n# Load the pickles\nwith open('\/kaggle\/input\/tinyimagenet-normalized\/val_data.pickle', 'rb') as val_file:\n    print(\"Loading the validation pickle...\")\n    val_data = pickle.load(val_file)\nwith open('\/kaggle\/input\/tinyimagenet-normalized\/train_data.pickle', 'rb') as train_file:\n    print(\"Loading the training pickle...\")\n    train_data = pickle.load(train_file)\n","daf0fcb2":"train_data.eval()","68e61d9a":"print(type(train_data), type(val_data))\nprint(\"Number of samples in the training set:\", len(train_data))\nprint(\"Number of samples in the validation set:\", len(val_data))\nprint(\"Training sample 0:\", train_data[0])","9e571a89":"import matplotlib.pyplot as plt\nimport torch\n\ntrain_data.eval()\n\n# Show the first sample\nsample = train_data[42]\nimg, label = sample\nimg = img.permute((0, 2, 3, 1))  # NCHW -> NHWC\nimg = img.squeeze()\n\n# Denormalize the image\nmean = torch.tensor([0.485, 0.456, 0.406])  # From the dataset description\nstd = torch.tensor([0.229, 0.224, 0.225])  # From the dataset description\nimg = img * std\nimg = img + mean\n\nprint(img.min(), img.max())\nplt.imshow(img)\nplt.title(\"Label: {}\".format(label.item()))","fd47d209":"train_data.train()\n\ntrain_loader = train_data.batch_loader(16)\n\nfor imgs, lbls in train_loader:\n    print(\"Batch img dims:\", imgs.shape)\n    print(\"Batch lbl dims:\", lbls.shape)\n    break","c76da131":"for t in train_data.transform.ts:\n    print(type(t))\nfor t in train_data.final_transform.ts:\n    print(type(t))","32cabe40":"The `.train` mode allows you to add data transformations.\nTo add the transformations you need to change the `train_data.transform.ts` list.","e6b38f48":"### Loading the set\n\nThe dataset is using the `pickle`.\n\n**Note: The dataset is loaded into the RAM, and WILL use a lot of it to load :)**","983645ac":"## Loading batches of data\n\nYou can use the `.batch_loader(batch_nums)` to load the datasets. That also allows you to use the `.train` mode on the datasets","7fe7aee3":"## Prerequisites\n\nThis dataset requires the class definitions located at https:\/\/github.com\/z-a-f\/zaf_funcs.git","fc4aa180":"### Accessing individual samples\n\nThe dataset supports indexing, which returns the sample as a tuple `(img, lbl)`.\nHowever, the dataset has to be in the `.eval()` mode.\nIf in training mode, you need to access batches of data (due to transformation stuff).\nThe images are in the `NCHW` layout, and saved as PyTorch tensors.\n"}}