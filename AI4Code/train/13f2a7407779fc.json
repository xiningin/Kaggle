{"cell_type":{"ead1b898":"code","0481d106":"code","d9231620":"code","70d147d3":"code","db362409":"code","123e1cef":"code","640040f0":"code","7730f77a":"code","e848842c":"code","bcfdc01d":"code","29af9aa4":"code","7a6a9297":"markdown","fc42923e":"markdown","2778fa5f":"markdown","8a3f4bc8":"markdown","57018ac6":"markdown","14e1142a":"markdown","e7155776":"markdown","96e9cb71":"markdown","9be4d6c2":"markdown","a178d1d5":"markdown"},"source":{"ead1b898":"import torch\nimport os, sys, ast\nimport pandas as pd\nimport numpy as np\nimport glob\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","0481d106":"DATA = '\/kaggle\/input\/global-wheat-detection\/'\ndf=pd.read_csv(DATA+\"train.csv\")\ndf.bbox = df.bbox.apply(ast.literal_eval)\nfor i in range(len(df)):\n    df.bbox.iloc[i][2]=df.bbox.iloc[i][0]+df.bbox.iloc[i][2] # xmax\n    df.bbox.iloc[i][3]=df.bbox.iloc[i][1]+df.bbox.iloc[i][3] # ymax\ndf.sample(5)","d9231620":"%mkdir train\n%mkdir validate\n\nfiles = glob.glob(DATA+\"train\/*\")\ntrain, validate, rest = np.split(files, [int(len(files)*0.2), int(len(files)*0.25)])\nfor i in range(len(train)):\n    shutil.copy2(train[i], '.\/train')\nfor i in range(len(validate)):\n    shutil.copy2(validate[i], '.\/validate')\nlen(train), len(validate), len(rest)","70d147d3":"%%capture\n!mkdir -p \/tmp\/pip\/cache\/\n!cp \/kaggle\/input\/detecto-install\/detecto-1.1.3.xyz \/tmp\/pip\/cache\/detecto-1.1.3.tar.gz\n!cp \/kaggle\/input\/detecto-install\/detecto-1.1.3-py3-none-any.whl \/tmp\/pip\/cache\/\n!pip install --no-index --find-links \/tmp\/pip\/cache\/ detecto\n!mkdir -p \/root\/.cache\/torch\/checkpoints\/\n!cp \/kaggle\/input\/faster-rcnn\/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth \/root\/.cache\/torch\/checkpoints\/","db362409":"from detecto import utils, visualize, core\n\nplt.rcParams['figure.figsize'] = (12.0, 12.0)\n\nfiles = glob.glob(\".\/train\/*\")\nfor i in range(len(files)):\n    fid = files[i].replace('.\/train\/', '').split('.')[0]\n    bx = df[df.image_id == fid]\n    if len(bx) > 0:\n        boxes=torch.FloatTensor(bx.bbox.tolist())\n        image = utils.read_image('.\/train\/'+fid+'.jpg')\n        visualize.show_labeled_image(image, boxes)\n        break","123e1cef":"%%capture\n# install Pascal VOC writer from dataset\n!cp \/kaggle\/input\/detecto-install\/pascal_voc_writer-0.1.4-py3.6.egg \/tmp\/pip\/cache\/\n!cp \/kaggle\/input\/detecto-install\/pascal_voc_writer-0.1.4-py2.py3-none-any.whl \/tmp\/pip\/cache\/\n!pip install --no-index --find-links \/tmp\/pip\/cache\/ pascal_voc_writer","640040f0":"from pascal_voc_writer import Writer\n\nLABEL = \"Wheat\"\ndef create_voc(folder):\n    files = glob.glob(folder+\"\/*\")\n    for i in range(len(files)):\n        fid = files[i].replace(folder+'\/','').split('.')[0]\n        ldf=df[df.image_id == fid].reset_index()\n        if len(ldf)> 0:\n            width, height = ldf.width.iloc[0], ldf.height.iloc[0]\n            writer = Writer(fid+'.jpg', width, height)\n            for j in range(len(ldf)):\n                writer.addObject(LABEL, \n                                 int(ldf.bbox.iloc[j][0]), \n                                 int(ldf.bbox.iloc[j][1]), \n                                 int(ldf.bbox.iloc[j][2]),\n                                 int(ldf.bbox.iloc[j][3]))\n            writer.save(folder+'\/'+fid+'.xml')\n        \ncreate_voc(\".\/validate\")\ncreate_voc(\".\/train\")","7730f77a":"dataset = core.Dataset('.\/train\/')\nloader = core.DataLoader(dataset, batch_size=16, shuffle=True)\nval_dataset = core.Dataset('.\/validate\/')\nmodel = core.Model([LABEL])\nlosses = model.fit(loader, val_dataset, epochs=2, learning_rate=0.001, lr_step_size=5, verbose=True)\nprint(losses)","e848842c":"#cleanup\n!rm -fr train\n!rm -fr validate","bcfdc01d":"tfiles = glob.glob(DATA+\"test\/*\")\npredf=pd.DataFrame(columns=['image_id', 'PredictionString'])\nfor i in range(len(tfiles)):\n    image = utils.read_image(tfiles[i])\n    fid = tfiles[i].replace(DATA+'test\/','').split('.')[0]\n    predictions = model.predict(image)\n    labels, boxes, scores = predictions\n    b=boxes.numpy().astype(int)\n    s=scores.numpy()\n    pstr=''\n    for i in range(len(b)):\n        p=[b[i][0], b[i][1], b[i][2]-b[i][0], b[i][3]-b[i][1]]\n        pstr=pstr+str(s[i])+' '+str(p[0])+' '+str(p[1])+' '+str(p[2])+' '+str(p[3])+' '\n    predf=predf.append({'image_id': fid, 'PredictionString': pstr}, ignore_index=True)","29af9aa4":"predf.to_csv('submission.csv', index=False)","7a6a9297":"## Install Detecto\nDetecto is installed from a dataset, since internet is turned off. We also need the faster-rcnn pre-trained model, again fetched from a dataset.","fc42923e":"## Train model\nTraining is super simple, just a few lines:","2778fa5f":"## Visualize\nLet's start by visualizing a random image.","8a3f4bc8":"Create Pascal VOC .xml files, one for each image:","57018ac6":"## Predict\nThen we can do predictions:","14e1142a":"## Create Pascal VOC data\nDetecto expects annotation data in Pascal VOC format. And thus we need to install the pascal-voc-writer.","e7155776":"## Copy a subset of training data\nDetecto wants training and validation data in separate folders. So below we will take a subset (to speed things up) of the training data and copy into local folders.","96e9cb71":"## Object detection with Detecto\n[Detecto](https:\/\/github.com\/alankbi\/detecto) is a Python library built on top of PyTorch that simplifies the process of building object detection models. Only a few lines of code is needed to train a model. Let's give it a spin on the Global Wheat Detection dataset.","9be4d6c2":"## Import annotation data\nStart by reading annotation data from the .csv file.","a178d1d5":"## Submit\nAnd finally submit the data:"}}