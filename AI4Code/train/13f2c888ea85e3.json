{"cell_type":{"e2627b47":"code","07cfd6be":"code","278b9eb1":"code","e138e40e":"code","e7625e27":"code","4525368b":"code","9bb54eef":"code","84f0799d":"code","3034f48d":"code","c91641d2":"code","213f4f22":"code","552a8ecc":"code","fd44f379":"code","60f5fd61":"code","5dc671ee":"code","0fc74604":"code","22f082b9":"code","8069d4c2":"code","103d68df":"code","78aa7d1f":"code","aec8f0d5":"code","b6e0738d":"code","6e25f0e7":"code","b5b24f74":"code","0cc35f09":"code","379c544f":"code","c514a234":"code","57325aac":"code","b68163dc":"code","feb1c931":"code","ad58b2d9":"code","bc8b9813":"code","d35388b8":"code","d13cf05b":"code","abfb29bc":"code","2e9fce3c":"code","32db310c":"code","ea522055":"markdown","90bac28c":"markdown","4f5939f6":"markdown","067aadbd":"markdown","45843a27":"markdown","3a95a78a":"markdown","0a439337":"markdown","8c1cb4b7":"markdown","7b30977b":"markdown","e092e4d8":"markdown","19f47e9e":"markdown","d4e63ebd":"markdown"},"source":{"e2627b47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07cfd6be":"#importing libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#importing sklearn libraries\nimport sklearn\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.express as px","278b9eb1":"mall_df= pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\nmall_df.head()","e138e40e":"#check the shape of dataset\n\nmall_df.shape","e7625e27":"#check the info of dataset\n\nmall_df.info()","4525368b":"#describe the dataframe\n\nmall_df.describe()","9bb54eef":"#check all the columns\n\nmall_df.columns","84f0799d":"#checking null values\n\nmall_df.isnull().sum()","3034f48d":"#percentage null values\n\n100*mall_df.isnull().sum()\/len(mall_df)","c91641d2":"# checking duplicate values\n\nmall_df.duplicated(subset = 'CustomerID').sum()","213f4f22":"# Box Plot\nplt.figure(figsize=(15, 5))\nfeatures = ['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)']\nfor i in enumerate(features):\n    ax = plt.subplot(1, 3, i[0]+1)\n    sns.boxplot(mall_df[i[1]])\n    plt.xticks(rotation=20)","552a8ecc":"# distribution Plot\nplt.figure(figsize=(15, 5))\nfeatures = ['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)']\nfor i in enumerate(features):\n    ax = plt.subplot(1, 3, i[0]+1)\n    sns.distplot(mall_df[i[1]])\n    plt.xticks(rotation=20)","fd44f379":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,3,1)\nsns.boxplot(x=mall_df.Gender, y=mall_df.Age)\nplt.title('Age')\n\nplt.subplot(1,3,2)\nsns.boxplot(x=mall_df.Gender, y=mall_df['Annual Income (k$)'])\nplt.title('Annual Income (k$)')\n\nplt.subplot(1,3,3)\nsns.boxplot(x=mall_df.Gender, y=mall_df['Spending Score (1-100)'])\nplt.title('Spending Score (1-100)')\n\nplt.show()","60f5fd61":"#scatter plot\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nsns.scatterplot(x=mall_df.Age,y=mall_df['Spending Score (1-100)'],hue=mall_df.Gender)\n\nplt.subplot(1,3,3)\nsns.scatterplot(x=mall_df.Age,y=mall_df['Annual Income (k$)'],hue=mall_df.Gender)\n\nplt.subplot(1,3,2)\nsns.scatterplot(x=mall_df['Annual Income (k$)'],y=mall_df['Spending Score (1-100)'],hue=mall_df.Gender)","5dc671ee":"# creating a new df with only numerical column\nmall_df1= mall_df.drop(['CustomerID', 'Gender'], axis=1)\nmall_df1.head()","0fc74604":"#converting Gender Variable\n#Male - 1\n#Female -0\n'''''variablelist =  ['Gender']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Male': 1, \"Female\": 0})\n\n# Applying the function to the columns\nmall_df1[variablelist] = mall_df1[variablelist].apply(binary_map)\nmall_df1.head()'''","22f082b9":"# initiate an object\nscaler= StandardScaler()\n\n# fit-transform data\nmall_df1_scaled= scaler.fit_transform(mall_df1)\nmall_df1_scaled.shape","8069d4c2":"mall_df1_scaled= pd.DataFrame(mall_df1_scaled)\nmall_df1_scaled.columns = ['Age','Annual Income (k$)','Spending Score (1-100)']\nmall_df1_scaled.head()","103d68df":"# function hopkin statistics\n\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan\nfrom sklearn.neighbors import NearestNeighbors\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n        \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","78aa7d1f":"# Evaluate Hopkins Statistics\nprint('Hopkins statistics is: ', round(hopkins(mall_df1_scaled),2))","aec8f0d5":"# k-means with some arbitrary k\nkmeans = KMeans(n_clusters=4, max_iter=100, random_state=0)\nkmeans.fit(mall_df1_scaled)","b6e0738d":"kmeans.labels_","6e25f0e7":"# elbow-curve\/SSD\nssd = []\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=100, random_state=0)\n    kmeans.fit(mall_df1_scaled)\n    \n    ssd.append(kmeans.inertia_)\n    \n# plot the SSDs for each n_clusters\n# ssd\nplt.plot(ssd)\nplt.show()","b5b24f74":"# silhouette analysis\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=100, random_state=0)\n    kmeans.fit(mall_df1_scaled)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(mall_df1_scaled, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","0cc35f09":"# final model with k=4\nkmeans = KMeans(n_clusters=4, max_iter=100, random_state=0)\nkmeans.fit(mall_df1_scaled)","379c544f":"kmeans.labels_","c514a234":"# assign the label\nmall_df['cluster_id'] = kmeans.labels_\nmall_df.head()","57325aac":"mall_df['cluster_id'].value_counts()","b68163dc":"# plot\nplt.title('Age')\nsns.boxplot(x='cluster_id', y='Age', data=mall_df)\nplt.show()","feb1c931":"# plot\nplt.title('Annual Income (k$)')\nsns.boxplot(x='cluster_id', y='Annual Income (k$)', data=mall_df)\nplt.show()","ad58b2d9":"# plot\nplt.title('Spending Score (1-100)')\nsns.boxplot(x='cluster_id', y='Spending Score (1-100)', data=mall_df)\nplt.show()","bc8b9813":"sns.countplot(data= mall_df , hue='Gender', x='cluster_id').tick_params(axis='x', rotation = 45)","d35388b8":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Spending Score (1-100)\", y=\"Age\", color=\"cluster_id\")\nfig.show()","d13cf05b":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Spending Score (1-100)\", y=\"Annual Income (k$)\", color=\"cluster_id\")\nfig.show()","abfb29bc":"#scatter plot gdpp-child_mort\n\nfig = px.scatter(mall_df, x=\"Annual Income (k$)\", y=\"Age\", color=\"cluster_id\")\nfig.show()","2e9fce3c":"mall_grouped= mall_df.groupby('cluster_id')","32db310c":"mall_grouped['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)'].mean().sort_values(by=['Age', 'Annual Income (k$)',\n       'Spending Score (1-100)'], ascending=[True, True, True])","ea522055":"## Step 3: Exploratory Data Analysis (EDA)","90bac28c":"Using Elbow curve, we will consider k=3.","4f5939f6":"### Scaling Data","067aadbd":"## Step 5: Hopkins Statistics","45843a27":"## Step 4: Preparing Data","3a95a78a":"## Conclusion:","0a439337":"## Step 6: K-Means Clustering","8c1cb4b7":"#### Elbow Curve:","7b30977b":"## Step 2: Data Cleaning","e092e4d8":"* Cluster 0 belongs to High Income and low spending score people who are mid aged.\n* Cluster 1 belong to Low Income and High Spending score people who are mostly young aged.\n* Cluster 2 belong to Average Income and Average Spending score people who are mostly old aged.\n* Cluster 3 belong to High Income and High Average Spending score people who are at their 30s.","19f47e9e":"#### Silhouette Analysis","d4e63ebd":"## Step 1: Reading and understanding data:"}}