{"cell_type":{"7a9f6cd0":"code","404f2fe4":"code","c16040b4":"code","6ee13b31":"code","58f550e0":"code","102dda05":"code","e9fe8ca9":"code","9b1c03e5":"code","2921f228":"code","cc809653":"code","9d71239d":"code","77397f0b":"code","3c863a18":"code","d0e574c3":"code","d917269c":"markdown","a8be413e":"markdown","656d669c":"markdown","aee0ed3f":"markdown","f7c9cf53":"markdown","2b023fe7":"markdown","0dfa0322":"markdown","6fc785bb":"markdown","88810e00":"markdown","99e513f2":"markdown","b9b205ab":"markdown","3fae1162":"markdown","86f1a18e":"markdown"},"source":{"7a9f6cd0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import date, datetime\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","404f2fe4":"train_path = '..\/input\/tabular-playground-series-jan-2022\/train.csv'\ntest_path = '..\/input\/tabular-playground-series-jan-2022\/test.csv'","c16040b4":"df = pd.read_csv(train_path,index_col='row_id')\ntest_df = pd.read_csv(test_path,index_col='row_id')","6ee13b31":"df.head()","58f550e0":"country_finland = df['country']=='Finland'\nstore_mart = df['store']=='KaggleMart'\nproduct_mug = df['product']=='Kaggle Mug'\ncondition = country_finland & store_mart & product_mug\n\ndf_date = df.copy()\ndf_date['date'] = pd.to_datetime(df_date['date'])\n\nplt.figure(figsize=(30,8))\nsns.lineplot(x='date',y='num_sold',data=df_date[condition])\nplt.show()","102dda05":"def convertToTime(x):\n    return datetime.strptime(x,'%Y-%m-%d').timestamp()\n\ndef getDay(x):\n    return int(str(x).split('-')[2])\n\ndef getMonth(x):\n    return int(str(x).split('-')[1])\n\ndef getYear(x):\n    return int(str(x).split('-')[0])\n\ndef getWeekday(x):\n    return int(datetime.strptime(x,'%Y-%m-%d').weekday())\n\ndf['year'] = df['date'].apply(getYear)\ndf['month'] = df['date'].apply(getMonth)\ndf['day'] = df['date'].apply(getDay)\ndf['weekday'] = df['date'].apply(getWeekday)\ndf['weekend'] = (df['weekday']>4).astype(int)\n# df['date'] = df['date'].apply(convertToTime)\ndf.drop('date',inplace=True,axis=1)\n# df.drop('year',inplace=True,axis=1)\n\ntest_df['year'] = test_df['date'].apply(getYear)\ntest_df['month'] = test_df['date'].apply(getMonth)\ntest_df['day'] = test_df['date'].apply(getDay)\ntest_df['weekday'] = test_df['date'].apply(getWeekday)\ntest_df['weekend'] = (test_df['weekday']>4).astype(int)\n# test_df['date'] = test_df['date'].apply(convertToTime)\ntest_df.drop('date',inplace=True,axis=1)\n# test_df.drop('year',inplace=True,axis=1)\n\ndf.head()","e9fe8ca9":"from sklearn.model_selection import train_test_split\n\nX = df.drop(\"num_sold\",axis=1)\ny = df['num_sold']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2)","9b1c03e5":"cat_col = [c for c in X_train.columns if X_train[c].dtype in ['object']]\nnum_col = [c for c in X_train.columns if X_train[c].dtype in ['float64','int64']]\n\nprint(\"*\"*20)\nprint(\"Columns:\")\nprint(\"Category:\",cat_col)\nprint(\"Numeric:\",num_col)\nprint(\"*\"*20)\n\nprint(\"Unique values\")\nfor col in cat_col:\n    print(col,X_train[col].unique())","2921f228":"print(\"*\"*20)\nprint(\"Missing value:\")\nprint(X_train.isnull().sum())\nprint(\"*\"*20)","cc809653":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n\nstandarizer = StandardScaler()\nscaler = MinMaxScaler()\n\nstandard_col = ['year', 'month', 'day', 'weekday', 'weekend']\n\nif (len(standard_col)):\n    X_train[standard_col] = standarizer.fit_transform(X_train[standard_col])\n    X_valid[standard_col] = standarizer.transform(X_valid[standard_col])\n\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\n\nX_train.head()","9d71239d":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor()\nmodel.fit(X_train,y_train)","77397f0b":"from sklearn.metrics import mean_absolute_error\n\nvalid_predicts = model.predict(X_valid)\nprint(mean_absolute_error(valid_predicts,y_valid))","3c863a18":"from sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\ndef create_pipeline(n_est):\n    num_trans = Pipeline(steps=[\n        (\"imputer\",SimpleImputer(strategy=\"median\")),\n        (\"standard\",StandardScaler())\n    ])\n    cat_trans = Pipeline(steps=[\n        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n        (\"onehot\",OneHotEncoder(handle_unknown='ignore'))\n    ])\n    preprocessor = ColumnTransformer(transformers=[\n        ('numeric',num_trans,standard_col),\n        ('catergory',cat_trans,cat_col)\n    ])\n    pipe = Pipeline(steps=[\n        ('preprocess',preprocessor),\n        ('model',XGBRegressor(n_estimators=n_est))\n    ])\n    return pipe\n\ndef test_score(n_est):\n    pipe = create_pipeline(n_est)\n    scores = cross_val_score(pipe, X, y, cv=5, scoring='neg_mean_absolute_error')    \n    return -scores.mean()\n\nn_est = list(range(10,201,10))\nscores = []\n\nfor est in n_est:\n    print(\"Testing:\",est,end=' - ')\n    scores.append(test_score(est))\n    print(scores[-1])\n    \nplt.plot(n_est,scores)\nplt.show()","d0e574c3":"final_model = create_pipeline(n_est[np.argmin(scores)])\nfinal_model.fit(X,y)\ntest_predict = final_model.predict(test_df)\n\nresult = pd.DataFrame({\n    \"row_id\": test_df.index,\n    'num_sold': test_predict\n})\nprint(result.head())\nresult.to_csv('submission.csv',index=False)","d917269c":"# Load data","a8be413e":"# Import libraries","656d669c":"# Column types","aee0ed3f":"# Standarize and encoding","f7c9cf53":"# Evaluate with MAE","2b023fe7":"# Create submission","0dfa0322":"# Split dataset into train and validation","6fc785bb":"# Create machine learning model","88810e00":"# Feature engineering\n- From the diagram above, we can see that the number of sold product increase sharply around the beginning of each year\n- Furthermore, it is easy to understand that the number of customer at the weekend also higher than in weekday\n- Because of those reason, I convert the `date` column into `year`, `month`, `day`, `weekday` and `weekend` ","99e513f2":"# Take a glance","b9b205ab":"# Fine-tune with grid search and cross-validation","3fae1162":"# Missing values","86f1a18e":"# Data path"}}