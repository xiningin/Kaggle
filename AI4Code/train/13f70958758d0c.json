{"cell_type":{"3568e049":"code","419a42b1":"code","0a5c8dc2":"code","d50e3490":"code","70f188a9":"code","c354ea4b":"code","9da6a3a6":"code","88cf385e":"code","efeb8271":"markdown","8a0544be":"markdown","1df8f37e":"markdown","c13a09e9":"markdown","d945bed0":"markdown","24dc424b":"markdown","524c9e6c":"markdown"},"source":{"3568e049":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nfrom torch import nn, optim\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import make_grid\nfrom collections import OrderedDict\nimport csv\nimport matplotlib.pyplot as plt","419a42b1":"#Loading data\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","0a5c8dc2":"train_data = torch.tensor(df_train.drop(['label'], axis=1).values.astype('float32')) \/ 255\nlabels = torch.tensor(df_train['label'].values.astype(np.float32)).long()\ntest_data = torch.tensor(df_test.values.astype('float32')) \/ 255\n\n#Getting dataloaders ready for training\ntrain_tensor_dataset = torch.utils.data.TensorDataset(train_data, labels)\n\n#Splitting the dataset into train and validate datasets\ntrain_size = int(0.8 * len(train_tensor_dataset))\nvalidate_size = len(train_tensor_dataset) - train_size\ntrain_dataset, validate_dataset = torch.utils.data.random_split(train_tensor_dataset, [train_size, validate_size])\n\ndataloaders = OrderedDict([\n    ('train', torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)),\n    ('validate', torch.utils.data.DataLoader(validate_dataset, batch_size=64, shuffle=True))\n])","d50e3490":"random_sel = np.random.randint(len(df_train), size=64)\ngrid = make_grid(torch.Tensor((df_train.iloc[random_sel, 1:].values\/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (64, 8)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off');","70f188a9":"def create_model(input_size, hidden_layer=[4096, 2048], output_size=10, drop_p=0.5):\n    model = nn.Sequential(OrderedDict([('layer1', nn.Linear(input_size, hidden_layer[0])),\n                                            ('ReLU1', nn.ReLU()),\n                                            ('layer2', nn.Linear(hidden_layer[0], hidden_layer[1])),\n                                            ('ReLU2', nn.ReLU()),\n                                            ('layer3', nn.Linear(hidden_layer[1], output_size)),\n                                            ('dropout', nn.Dropout(p=drop_p)),\n                                            ('output', nn.LogSoftmax(dim=-1))]))\n    return model\nmodel = create_model(train_data.shape[1], [200,100])","c354ea4b":"def validate_model(model, dataloader, device, criterion):\n    correct = 0\n    total = 0\n    test_loss = 0\n    model.to(device)\n    model.float()\n    for data in dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model.forward(inputs)\n        test_loss += criterion(outputs, labels).item() \/ len(dataloader)\n        ps = torch.exp(outputs)\n        _, predicted = torch.max(ps.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        accuracy = 100 * correct \/ total\n    return test_loss, accuracy","9da6a3a6":"def train_network(model, dataloader, learning_rate=0.001, device='cuda', epochs=3):\n    print_every = 100\n    steps = 0\n    model.to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    for e in range(epochs):\n        model.train()\n        running_loss = 0\n        total = 0\n        correct = 0\n        for ii, (inputs, labels) in enumerate(dataloader):\n            steps += 1\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            output = model.forward(inputs)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            # accuracy\n            _, predicted = torch.max(output.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            if steps % print_every == 0:\n                model.eval()\n                with torch.no_grad():\n                    test_loss, accuracy = validate_model(model, dataloaders['validate'], device, criterion)\n\n                print(\"Epoch: {}\/{}.. \".format(e+1, epochs),\n                      \"Training Loss: {:.3f}.. \".format(running_loss\/print_every),\n                      \"Training Accuracy: %d %%\" % (100 * correct \/ total),\n                      \"Test Loss: {:.3f}.. \".format(test_loss),\n                      \"Test Accuracy: %d %%\" % (accuracy))\n\n                running_loss = 0\n        print('Finished Epoch!')\n    print('Finished Training!')\ntrain_network(model, dataloaders['train'], 0.001, 'cpu')","88cf385e":"results = []\nfor inputs in test_data:\n    with torch.no_grad():\n        output = model.forward(torch.tensor(inputs))\n        ps = torch.exp(output)\n        results = np.append(results, ps.topk(1)[1].numpy()[0])\nresults = results.astype(int)\nindex = [x+1 for x in df_test.index.tolist()]\ndf = pd.DataFrame({'ImageId': index, 'Label':results})\ndf.to_csv(\"submission.csv\", index = False)","efeb8271":"### Training the model\nDefine a function to train the model with the training data.\nThe function takes the model, dataloader, learning rate, device(cpu, cuda) and epochs(number of iterations) as parameters.\nThe function prints the loss and accuracy of the model with the training data and uses the validate_model function to print the loss and accuracy of the validation data with each iteration.","8a0544be":"### Getting the data ready for training\nSplit the training data into input data and labels. Then normalize the input data by dividing by 255 and it is ready to be converted to a tensor.\nThen split the training data into training and validation data and create the dataloaders.\nAnd of course load and normalize the test data and convert it to a tensor as well.","1df8f37e":"## An image representation of a batch of the data\nPlotting 8x8 grid of images using matplotlib","c13a09e9":"### Model validation\nDefine a function to validate the model with the validation chunk of the training data which was split earlier.\nThe function takes the model, dataloader, device(cpu, cuda) and the criterion as parameters.\nThe function returns the loss and the accuracy of the model with the validation data.","d945bed0":"### Saving results as a CSV\nRun the model with the test data and get the top result and add it to the csv next to the imageId.","24dc424b":"### Creating the model\nDefine a function that creates the model with input size, hidden layers, output size and dropout probability as parameters.\nThe model has 2 hidden layers with ReLU as an activation function for the hidden layers and LogSoftmax for the output.","524c9e6c":"### Loading the data\nLoad the data by reading from the csv file."}}