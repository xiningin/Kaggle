{"cell_type":{"04742eb5":"code","d3d4e6b6":"code","5f6eb13d":"code","c94598cc":"code","805fdb30":"code","996d58f7":"code","60d1f56a":"code","67a057a6":"code","77cb5a14":"code","ae57bf30":"code","13f9088d":"code","609c56c2":"code","5f129890":"code","5fd2b830":"code","40e0b676":"code","f12e495f":"code","e297ed57":"code","dd03e16d":"code","6c7861c6":"code","fa8e7065":"code","bdcd81fe":"code","37626a74":"code","5e7815ad":"code","7c09bdf1":"code","6f634ed4":"code","484232ca":"code","fe1d5565":"code","99cd306b":"code","83a259e4":"code","e9846373":"code","ca651ca0":"code","9eb63e86":"code","08e11ed8":"code","b75c3eae":"code","b0eff0af":"code","b571ec8b":"code","ae7848fb":"code","7115d7a1":"code","766f6032":"code","664aec6f":"code","f9009df4":"code","dae8e993":"code","59af9e12":"code","ff45213e":"code","be789872":"code","e1896997":"code","e5dc3d1b":"code","eac3daa1":"code","eee74d35":"code","83867758":"code","be741cd0":"code","da2ea603":"code","1eafb50a":"code","352dde77":"code","cafb1331":"code","ee898853":"code","d35e6c26":"code","8e4ef599":"code","82e0aca9":"code","98865343":"code","aac7b40a":"code","0af4952b":"code","8a338652":"markdown","06aa2bca":"markdown","2d3cb17a":"markdown","0c2bcf66":"markdown","c44e30f0":"markdown","0632d907":"markdown","ba399f92":"markdown","ff6e747b":"markdown","3e744740":"markdown","073effe8":"markdown","015eb025":"markdown","94c5d2e2":"markdown","7aa94507":"markdown","65695ec6":"markdown","4a8206e7":"markdown","cbf5149f":"markdown","c0c8c220":"markdown","f61ed524":"markdown","7db76702":"markdown","c29474f6":"markdown","3a87dd7c":"markdown","c10bae80":"markdown"},"source":{"04742eb5":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d3d4e6b6":"data = pd.read_csv(\"..\/input\/imdb-most-popular-films-and-series\/imdb.csv\")","5f6eb13d":"data.head()","c94598cc":"data.shape","805fdb30":"''' Here Rate is dependent variable and other 13 columns are independent varibles.'''","996d58f7":"data.describe() ## only date is numeric type","60d1f56a":"data.info()","67a057a6":"data['Date'].value_counts()","77cb5a14":"data['Name'].value_counts()","ae57bf30":"data['Genre'].value_counts()","13f9088d":"data['Type'].value_counts()","609c56c2":"data['Votes'].value_counts()","5f129890":"data['Votes'] = data['Votes'].apply(lambda x : x.replace(',',''))","5fd2b830":"data['Certificate'].value_counts()","40e0b676":"len(data['Certificate'].value_counts())","f12e495f":"## Replacing Not Rated with Unrated.\ndata['Certificate'] = data['Certificate'].replace({'Not Rated': 'Unrated'})","e297ed57":"## In Episode columns there is so many null values represented as -\n## So we can drop this column.\ndata['Episodes'].value_counts()","dd03e16d":"## Episod have mostly nan values so we need to delete that columns.\ndata.drop(['Episodes'],inplace = True , axis = 1)","6c7861c6":"data['Rate'] = data['Rate'].replace({'None': np.nan})\ndata['Rate'] = data['Rate'].replace({'No Rate': np.nan})\ndata['Votes'] = data['Votes'].replace({'None': np.nan})\ndata['Genre'] = data['Genre'].replace({'None': np.nan})\ndata['Duration'] = data['Duration'].replace({'None': np.nan})\ndata['Certificate'] = data['Certificate'].replace({'None': np.nan})\ndata['Votes'] = data['Votes'].replace({'No Votes': np.nan})\ndata['Votes'] = data['Votes'].replace({'NoVotes': np.nan})","fa8e7065":"data.head()","bdcd81fe":"data.isnull().sum()","37626a74":"data.isnull().sum().sum()\/ len(data)*100","5e7815ad":"data = data.dropna()","7c09bdf1":"data.isnull().sum()","6f634ed4":"data.shape","484232ca":"\ndata = data.drop_duplicates()\ndata.shape","fe1d5565":"## First import preprocessing from sklearn liabrary \nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","99cd306b":"data.head()","83a259e4":"categorical_cols = ['Type','Certificate']","e9846373":"data = pd.get_dummies(data, columns = categorical_cols)","ca651ca0":"data['Nudity'].value_counts() # In Nudity column there is null values.","9eb63e86":"data['Nudity']=data['Nudity'].replace({'No Rate':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'None':0})\ndata['Nudity'].value_counts() ","08e11ed8":"data['Violence'].value_counts() \ndata['Violence']=data['Violence'].replace({'No Rate':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'None':0})","b75c3eae":"data['Profanity'].value_counts() \ndata['Profanity']=data['Profanity'].replace({'No Rate':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'None':0})","b0eff0af":"data['Alcohol'].value_counts() \ndata['Alcohol']=data['Alcohol'].replace({'No Rate':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'None':0})","b571ec8b":"data['Frightening'].value_counts() \ndata['Frightening']=data['Frightening'].replace({'No Rate':0, 'Mild':1, 'Moderate':2, 'Severe':3, 'None':0})","ae7848fb":"data['Genre'].value_counts()\n## In this Genre feature there is 359 Unique classes.so here we can't use one hot encoding so we use here label encoding.","7115d7a1":"data['Genre']=le.fit_transform(data['Genre'])","766f6032":"data.head()","664aec6f":"data.info()","f9009df4":"## Lets change remaning features the obect type to numeric type.\ndata['Duration']= data['Duration'].astype('int')","dae8e993":"data['Votes']= data['Votes'].astype('int')","59af9e12":"## Rating is float type for ex 4.5,2,3.6 etc.\ndata['Rate']= data['Rate'].astype('float')","ff45213e":"data.dtypes","be789872":"data['Name'].value_counts()","e1896997":"## The Name feature is repeated values and we are not consider episodes 1,2,3 and its effect on model\n## so i drop this feature.\ndata = data.drop('Name',axis = 1)","e5dc3d1b":"data.head()","eac3daa1":"x = data.drop(['Rate'],axis = 1)\ny = data['Rate']","eee74d35":"x.isnull().sum()","83867758":"## To check Multicoliearity we are use VIF Method.\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","be741cd0":"vif1 = pd.DataFrame()\nvif1['feature'] = x.columns","da2ea603":"x.columns","1eafb50a":"## Calculating VIF for each feature\nvif1['VIF']= [variance_inflation_factor(x.values,i)\n                            for i in range(len(x.columns))]\nprint(vif1)","352dde77":"sns.jointplot(data['Date'],data['Rate'])","cafb1331":"sns.jointplot(data['Nudity'],data['Rate'])","ee898853":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","d35e6c26":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.33, random_state = 0)","8e4ef599":"## Scaling Standard dization mean = 0 and std = 1.\n## converted normal dist.\nfrom sklearn.preprocessing import StandardScaler\nstd_x = StandardScaler()\nx_train = std_x.fit_transform(x_train)\nx_test = std_x.transform(x_test)","82e0aca9":"regressor = LinearRegression()\nregressor.fit(x_train, y_train)","98865343":"y_pred = regressor.predict(x_test)","aac7b40a":"from sklearn.metrics import r2_score\nscore = r2_score(y_pred,y_test)\nprint('R2 Score is',score)","0af4952b":"print('MAE',metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE',metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","8a338652":"## About_Dataset\nhttps:\/\/www.kaggle.com\/mazenramadan\/imdb-most-popular-films-and-series\n\nDataset Consist of 14 Columns","06aa2bca":"### Missing Values handling methods.\n* Delete feature \/ column:-\n     If columns have more than 60% as null values then entire column can be dropped. \n* Numeric Type Feature:-\n- If feature\/column does not contain outliers then replace missing values by mean.\n- If feature\/column contain outliers then replace missing values by median. ( Median is not affected by outliers)\n* Categorical Type Feature:-\n- Replace missing values by Mode.( we can't compute Mean & Median of categorical features )","2d3cb17a":"### One hot Encoding\n* A one hot encoding is a representation of categorical variables as binary vectors.\n* One-Hot Encoding is the process of creating dummy variables.\n* That\u2019s primarily the reason we need to convert categorical columns to numerical columns so that a machine learning         algorithm understands it. This process is called categorical encoding.","0c2bcf66":"## 1. Multicolinearity","c44e30f0":"## Assumptions.\n### Linear Regression","0632d907":"## Problem_Statement\n* To Predict Movie Rating using different features.","ba399f92":"#### Observation :-\nSo here we can see there are only 3 columns contain missing values. \n* Votes :       This feature is numeric feature.\n* Duration :    This feature is numeric feature.\n* Rate :        This feature is numeric feature.\n* certificate : This feature is categorical feature.","ff6e747b":"### Conversion Categorical to Numeric.","3e744740":"#### Observation\n* If VIF is above 10 then its a **Multicolinearity Present.**\n* So Here is **not Multicolinearity present.**\n* There is no Multicolinearity here.","073effe8":"# Linear_Regression_Analysis","015eb025":"#### Observation :-\n     * Our data is Linear","94c5d2e2":"## Linearity","7aa94507":"## Modelling","65695ec6":"### Duplicate_Dataset","4a8206e7":"# Data_Preprocessing.\nLet's find out categories first.","cbf5149f":"### Missing_Values_Handling.","c0c8c220":"### Lable Encoding \n What is label encoding?    \n Label Encoding is a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering.","f61ed524":" Above data set tell us:-    \n 1] We have **14 Features** and **6178 observations.**    \n 2] 1 is integer data type and 13 object types but there is mistake some of the features supposed to be integers but implied as object.      \n 3] It says there is **no null values** present but from the data set we can say that there is same.    \n 4] sometimes in the data **null values not present but None value or nan value may be present .**","7db76702":"Nudity Feature have levels and None here means there is no Nudity present in movie.So we are replacing it using this method. Same process for Violence , profanity, Alcohol, Frightening. This are the Ordinal Variables.","c29474f6":"#### Observation\n* So there was duplicate data.","3a87dd7c":"R2 is Negative because the chosen model does not follow the trend of the data ","c10bae80":"Suppose we Directly use label Encoding then they directly choose Numbers zero, one, Two by randomly."}}