{"cell_type":{"79dcbd63":"code","dc8d7e26":"code","02c0d8d0":"code","9f8d7550":"code","8ae6338b":"code","545f1dcd":"code","e43bee5c":"code","d6cf328e":"code","aefebe72":"code","a5af0be0":"code","0437f665":"code","e392a7b2":"code","d5c5017c":"code","7db58d81":"code","6ae96e80":"code","e61b8b33":"code","5aae75ad":"code","8b6a4880":"code","aa25d11f":"code","61ae98ae":"code","da05f286":"code","7fe6232a":"code","3031ce44":"code","359a0894":"code","f06071ff":"code","a45caf8d":"markdown","c4d2b1b9":"markdown","2da80cb9":"markdown","06b1dedc":"markdown","ef318463":"markdown","0a88b36e":"markdown","beee9f92":"markdown","c209287f":"markdown","245f3b2f":"markdown","8f353b15":"markdown","9750cd61":"markdown","2aaeb18b":"markdown","8788c9d7":"markdown","6c5f0180":"markdown","1c8b37be":"markdown","2485aa6a":"markdown","590aeee8":"markdown","f5ade8f5":"markdown"},"source":{"79dcbd63":"!pip install -q efficientnet #\u56e0\u4e3a\u6211\u4eec\u60f3\u7528 EfficientNet\u6a21\u578b\uff0c\u6240\u4ee5\u6211\u4eec\u5148\u8fdb\u884c\u5b89\u88c5efficientnet\uff0c\n# \u611f\u53f9\u53f7\u8868\u793a\u8c03\u7528\u63a7\u5236\u53f0\uff0c\u8fd9\u53e5\u4ee3\u7801\u7b49\u4ef7\u4e8e\u4e8e\u5728\u63a7\u5236\u53f0\u8f93\u5165\u4e86pip install -q efficientnet","dc8d7e26":"# \u5bfc\u5165\u9700\u8981\u7684\u5305\nimport math, re, os # math\uff1a\u5305\u62ec\u4e00\u4e9b\u901a\u7528\u7684\u6570\u5b66\u516c\u5f0f\uff1bre\uff1a\u5b57\u7b26\u4e32\u6b63\u5219\u5339\u914d\uff1bos\uff1a\u64cd\u4f5c\u7cfb\u7edf\u63a5\u53e3\nimport tensorflow as tf # tensorflow\u5305\nimport numpy as np # numpy\u64cd\u4f5c\u6570\u7ec4\nfrom matplotlib import pyplot as plt   # matplotlib\u8fdb\u884c\u753b\u56fe\nfrom kaggle_datasets import KaggleDatasets # Kaggle\u6570\u636e\u96c6\nimport efficientnet.tfkeras as efn    # \u5bfc\u5165efficientnet\u6a21\u578b\n# \u4ecepython\u7684sklearn\u673a\u5668\u5b66\u4e60\u4e2d\u5bfc\u5165f1\u503c\u3001\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u6df7\u6dc6\u77e9\u9635\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix  \n\nprint(\"Tensorflow version \" + tf.__version__) #\u68c0\u67e5tensorflow\u7684\u7248\u672c","02c0d8d0":"# Detect hardware, return appropriate distribution strategy\n# try:\n      # TPU\u68c0\u6d4b\u3002 \u5982\u679c\u8bbe\u7f6e\u4e86TPU_NAME\u73af\u5883\u53d8\u91cf\uff0c\u5219\u4e0d\u9700\u8981\u4efb\u4f55\u53c2\u6570\u3002 \u5728Kaggle\u4e0a\uff0c\u60c5\u51b5\u603b\u662f\u5982\u6b64\u3002\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync) #\u8f93\u51fa\u526f\u672c\u6570","9f8d7550":"AUTO = tf.data.experimental.AUTOTUNE # \u53ef\u4ee5\u8ba9\u7a0b\u5e8f\u81ea\u52a8\u7684\u9009\u62e9\u6700\u4f18\u7684\u7ebf\u7a0b\u5e76\u884c\u4e2a\u6570\n\n# Create strategy from tpu\n# \u4eceTPU\u521b\u5efa\u90e8\u7f72\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver() #\u5982\u679c\u5148\u524d\u8bbe\u7f6e\u597d\u4e86\uff34\uff30\uff35\uff3f\uff2e\uff21\uff2d\uff25\u73af\u5883\u53d8\u91cf\uff0c\u4e0d\u9700\u8981\u518d\u7ed9\u53c2\u6570\uff0e\ntf.config.experimental_connect_to_cluster(tpu) # \u914d\u7f6e\u5b9e\u9a8c\u8fde\u63a5\u5230\u7fa4\u96c6\ntf.tpu.experimental.initialize_tpu_system(tpu) # \u521d\u59cb\u5316tpu\u7cfb\u7edf\nstrategy = tf.distribute.experimental.TPUStrategy(tpu) # \u8bbe\u7f6eTPU\u90e8\u7f72\n\n\n# \u5b98\u65b9\u7ed9\u51fa\u7684\u7ade\u8d5b\u6570\u636e\u8bbf\u95ee\u6ce8\u91ca\n# Competition data access\n# TPUs read data directly from Google Cloud Storage (GCS). \n# This Kaggle utility will copy the dataset to a GCS bucket co-located with the TPU. \n# If you have multiple datasets attached to the notebook, \n# you can pass the name of a specific dataset to the get_gcs_path function. \n# The name of the dataset is the name of the directory it is mounted in. \n# Use !ls \/kaggle\/input\/ to list attached datasets.\n# \u6bd4\u8d5b\u6570\u636e\u8bbf\u95ee\n# TPU\u76f4\u63a5\u4eceGoogle Cloud Storage\uff08GCS\uff09\u8bfb\u53d6\u6570\u636e\u3002\n# \u8be5Kaggle\u5b9e\u7528\u7a0b\u5e8f\u4f1a\u5c06\u6570\u636e\u96c6\u590d\u5236\u5230\u4e0eTPU\u5e76\u7f6e\u7684GCS\u5b58\u50a8\u6876\u4e2d\u3002\n# \u5982\u679c\u7b14\u8bb0\u672c\u6709\u591a\u4e2a\u6570\u636e\u96c6\uff0c\n# \u60a8\u53ef\u4ee5\u5c06\u7279\u5b9a\u6570\u636e\u96c6\u7684\u540d\u79f0\u4f20\u9012\u7ed9get_gcs_path\u51fd\u6570\u3002\n# \u6570\u636e\u96c6\u7684\u540d\u79f0\u662f\u5176\u5b89\u88c5\u76ee\u5f55\u7684\u540d\u79f0\u3002\n# \u4f7f\u7528\uff01ls \/ kaggle \/ input \/\u5217\u51fa\u9644\u52a0\u7684\u6570\u636e\u96c6\u3002\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path() #\u8bbe\u7f6eKaggle\u6570\u636e\u7684\u8bbf\u95ee\u8def\u5f84\n\n# Configuration\n\nIMAGE_SIZE = [512, 512] # \u914d\u7f6e\u50cf\u7d20\u70b9\u77e9\u9635\u5927\u5c0f\nEPOCHS = 20 # # \u914d\u7f6e\u6a21\u578b\u8bad\u7ec3\u7684\u8f6e\u6b21\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync # \u8bbe\u7f6e\u6bcf\u4e2a\u5c0f\u6279\u91cf\u7684\u5927\u5c0f","8ae6338b":"# \u914d\u7f6e\u4e0d\u540c\u5927\u5c0f\u56fe\u7247\u7684\u8def\u5f84\nGCS_PATH_SELECT = { # available image sizes\n    192: GCS_DS_PATH + '\/tfrecords-jpeg-192x192',\n    224: GCS_DS_PATH + '\/tfrecords-jpeg-224x224',\n    331: GCS_DS_PATH + '\/tfrecords-jpeg-331x331',\n    512: GCS_DS_PATH + '\/tfrecords-jpeg-512x512'\n}\nGCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/train\/*.tfrec') # \u8bad\u7ec3\u96c6\u8def\u5f84\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/val\/*.tfrec') # \u9a8c\u8bc1\u96c6\u8def\u5f84\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/test\/*.tfrec') # \u6d4b\u8bd5\u96c6\u8def\u5f84 predictions on this dataset should be submitted for the competition","545f1dcd":"# 104\u79cd\u82b1\u7684\u540d\u79f0\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']","e43bee5c":"# \u5c55\u793a\u8bad\u7ec3\u548c\u9a8c\u8bc1\u66f2\u7ebf\uff0c\u4e5f\u5c31\u662f\u635f\u5931\u548c\u51c6\u786e\u7387\u968f\u8f6e\u6b21\u7684\u53d8\u5316\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call # \u5728\u7b2c\u4e00\u6b21\u8c03\u7528\u8be5\u51fd\u6570\u65f6\u8bbe\u7f6e\u5b50\u56fe\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot) #\u8bbe\u7f6e\u5b50\u56fe\n    ax.set_facecolor('#F8F8F8') #\u8bbe\u7f6e\u80cc\u666f\u989c\u8272\n    ax.plot(training) #\u753b\u8bad\u7ec3\u96c6\u7684\u66f2\u7ebf\n    ax.plot(validation) #\u753b\u6d4b\u8bd5\u96c6\u7684\u66f2\u7ebf\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title) #\u8bbe\u7f6ey\u8f74\u6807\u9898\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch') #\u8bbe\u7f6ex\u8f74\u6807\u9898\n    ax.legend(['train', 'valid.']) #\u8bbe\u7f6e\u56fe\u4f8b\n    \n# \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))  # \u8bbe\u7f6e\u753b\u5e03\u5927\u5c0f\n    ax = plt.gca() #\u8fd4\u56de\u5f53\u524daxes(matplotlib.axes.Axes) \u83b7\u53d6\u5f53\u524d\u5b50\u56fe\n    ax.matshow(cmat, cmap='Reds') #\u7ed8\u5236\u77e9\u9635\n    ax.set_xticks(range(len(CLASSES)))  #\u6839\u636e\u82b1\u6735\u7c7b\u522b\u6570\uff08\u5176\u5b9e\u5c31\u662f104\uff09\u8bbe\u7f6ex\u8f74\u8303\u56f4\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7}) #\u8bbe\u7f6ex\u8f74\u4e0b\u6807\u5b57\u4f53\u7684\u5927\u5c0f\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\") #\u66f4\u6362x\u8f74\u4e0b\u6807\u89d2\u5ea6\n    ax.set_yticks(range(len(CLASSES)))  #\u6839\u636e\u82b1\u6735\u7c7b\u522b\u6570\uff08\u5176\u5b9e\u5c31\u662f104\uff09\u8bbe\u7f6ey\u8f74\u8303\u56f4\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7}) #\u8bbe\u7f6ey\u8f74\u4e0b\u6807\u5b57\u4f53\u7684\u5927\u5c0f\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\") #\u66f4\u6362y\u8f74\u4e0b\u6807\u89d2\u5ea6\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score) #\u66f4\u6539\u683c\u5f0f\u4e3a\u67093\u4f4d\u5c0f\u6570\u7684\u6d6e\u70b9\u6570\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision) #\u66f4\u6539\u683c\u5f0f\u4e3a\u67093\u4f4d\u5c0f\u6570\u7684\u6d6e\u70b9\u6570\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall) #\u66f4\u6539\u683c\u5f0f\u4e3a\u67093\u4f4d\u5c0f\u6570\u7684\u6d6e\u70b9\u6570\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'}) #\u6dfb\u52a0\u6587\u672c\u6ce8\u91ca\n    plt.show()","d6cf328e":"# \u8bbe\u7f6enumpy\u6570\u7ec4\u57fa\u672c\u5c5e\u6027\uff0c\u8bbe\u7f6e\u663e\u793a15\u4e2a\u6570\u5b57\uff0c\u7528\u4e8e\u63d2\u5165\u6362\u884c\u7b26\u7684\u6bcf\u884c\u5b57\u7b26\u6570\uff08\u9ed8\u8ba4\u4e3a75\uff09\u3002\n# threshold : int, optional\uff0cTotal number of array elements which trigger summarization rather than full repr (default 1000).\n# \u5f53\u6570\u7ec4\u6570\u76ee\u8fc7\u5927\u65f6\uff0c\u8bbe\u7f6e\u663e\u793a\u51e0\u4e2a\u6570\u5b57\uff0c\u5176\u4f59\u7528\u7701\u7565\u53f7\n# linewidth : int, optional\uff0cThe number of characters per line for the purpose of inserting line breaks (default 75).\n# \u7528\u4e8e\u63d2\u5165\u6362\u884c\u7b26\u7684\u6bcf\u884c\u5b57\u7b26\u6570\uff08\u9ed8\u8ba4\u4e3a75\uff09\u3002\nnp.set_printoptions(threshold=15, linewidth=80)\n\n# \u5c06\u5c0f\u6279\u91cf\u56fe\u7247\u548c\u6807\u7b7e\u5904\u7406\u4e3anumpy\u5411\u91cf\u683c\u5f0f\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data \n    numpy_images = images.numpy() #\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3anumpy\u5411\u91cf\u683c\u5f0f\n    numpy_labels = labels.numpy() #\u5c06label\u6807\u7b7e\u8f6c\u6362\u4e3anumpy\u5411\u91cf\u683c\u5f0f\n    if numpy_labels.dtype == object: # \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4e3a\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\uff0c\u5b83\u4eec\u662f\u56fe\u50cfID\u5b57\u7b26\u4e32\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # \u5982\u679c\u6ca1\u6709\u6807\u7b7e\uff0c\u53ea\u6709\u56fe\u50cfID\uff0c\u5219\u5bf9\u6807\u7b7e\u8fd4\u56deNone\uff08\u6d4b\u8bd5\u6570\u636e\u5c31\u662f\u8fd9\u79cd\u60c5\u51b5\uff09\n    return numpy_images, numpy_labels\n\n# \u628a\u5b9e\u9645\u7c7b\u578b\u548c\u6a21\u578b\u9884\u6d4b\u51fa\u6765\u7684\u6a21\u578b\u4e00\u8d77\u663e\u793a\u5728\u56fe\u7247\u4e0a\u65b9\uff0c\u8fd9\u662f\u7528\u7ed9\u9a8c\u8bc1\u96c6\u7684\uff0c\u5f53\u5bf9\u9a8c\u8bc1\u96c6\u9884\u6d4b\u5b8c\u6807\u7b7e\u540e\u548c\u9a8c\u8bc1\u96c6\u7684\u5b9e\u9645\u6807\u7b7e\u8fdb\u884c\u6bd4\u8f83\n# label,\u56fe\u7247\u4e2d\u82b1\u6735\u7684\u5b9e\u9645\u7c7b\u522b\n# correct_label\uff0c\u5f53\u524d\u6211\u4eec\u9884\u6d4b\u7684\u7c7b\u522b\ndef title_from_label_and_target(label, correct_label):\n    # \u5982\u679c\u6ca1\u6709\u9884\u6d4b\u7684\u7c7b\u522b\uff0c\u5219\u8fd4\u56de\u5b9e\u9645\u7c7b\u522b\uff0c\u6bd4\u5982\u8bad\u7ec3\u96c6\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label) #\u5224\u65ad\u4e00\u4e0b\u5b9e\u9645\u7c7b\u522b\u548c\u6211\u4eec\u9884\u6d4b\u7684\u7c7b\u522b\u662f\u5426\u4e00\u81f4\n    # \u5982\u679c\u4e00\u81f4\uff0c\u5219\u8fd4\u56deOK\uff0c\u4e0d\u4e00\u81f4\u5219\u8fd4\u56deNO\u52a0\u5b9e\u9645\u7c7b\u522b\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\n# \u7ed8\u5236\u4e00\u6735\u82b1\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off') # \u4e0d\u663e\u793a\u5750\u6807\u5c3a\u5bf8\n    plt.imshow(image) #\u51fd\u6570\u8d1f\u8d23\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\uff0c\u5e76\u663e\u793a\u5176\u683c\u5f0f\uff1b\u800cplt.show()\u5219\u662f\u5c06plt.imshow()\u5904\u7406\u540e\u7684\u51fd\u6570\u663e\u793a\u51fa\u6765\u3002\n    if len(title) > 0:\n        #\u7ed8\u5236\u56fe\u7247\u7684\u6807\u9898\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize\/1.2), color='red' if red else 'black', \n                  fontdict={'verticalalignment':'center'}, pad=int(titlesize\/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \n# \u5c55\u793a\u5c0f\u6279\u91cf\u56fe\u7247\uff0c\u6211\u4eec\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\u7ecf\u5e38\u5c55\u793a20\u5f20\u7167\u7247\ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)   # \u53ea\u5c55\u793a\u56fe\u7247 \u6d4b\u8bd5\u96c6\u9700\u8981\u8fd9\u4e2a\n    display_batch_of_images(images, predictions) #\u5c55\u793a\u56fe\u7247\u52a0\u9884\u6d4b\u7684\u7c7b\u522b \u6d4b\u8bd5\u96c6\u9700\u8981\u8fd9\u4e2a\n    display_batch_of_images((images, labels)) #\u5c55\u793a\u56fe\u7247\u52a0\u5b9e\u9645\u6807\u7b7e \u8bad\u7ec3\u96c6\u9700\u8981\u8fd9\u4e2a\n    display_batch_of_images((images, labels), predictions) #\u5c55\u793a\u56fe\u7247+\u5b9e\u9645\u7c7b\u522b+\u9884\u6d4b\u7c7b\u522b \u9a8c\u8bc1\u96c6\u9700\u8981\u8fd9\u4e2a\uff0c\u56e0\u4e3a\u9a8c\u8bc1\u96c6\u65e2\u6709\u5b9e\u9645\u6807\u7b7e\uff0c\u4e5f\u4f1a\u8fdb\u884c\u9884\u6d4b\n    \"\"\"\n    # \u8bfb\u53d6\u56fe\u7247\u548c\u5b9e\u9645\u6807\u7b7e\u6570\u636e\uff0c\u800c\u4e14\u8fd9\u4e9b\u6570\u636e\u88ab\u8f6c\u6362\u6210numpy\u5411\u91cf\u7684\u683c\u5f0f\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    # \u5982\u679c\u6ca1\u6709\u5b9e\u9645\u6807\u7b7e\uff08\u5373if labels is None\u4e3atrue\uff09\uff0c\u6bd4\u5982\u6d4b\u8bd5\u96c6\uff0c\u90a3\u4e48\u6211\u4eec\u9700\u8981\u5c06labels\u53d8\u91cf\u8bbe\u4e3a\u6bcf\u4e2a\u5143\u7d20\u90fd\u4e3anone\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # \u81ea\u52a8\u5e73\u65b9\uff1a\u8fd9\u5c06\u5220\u9664\u4e0d\u9002\u5408\u6b63\u65b9\u5f62\u6216\u77e9\u5f62\u7684\u6570\u636e\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)\/\/rows  #\" \/\/ \" \u8868\u793a\u6574\u6570\u9664\u6cd5,\u8fd4\u56de\u4e0d\u5927\u4e8e\u7ed3\u679c\u7684\u4e00\u4e2a\u6700\u5927\u7684\u6574\u6570\uff0c\u5411\u4e0b\u53d6\u6574\n        \n    # \u5927\u5c0f\u548c\u95f4\u8ddd\n    FIGSIZE = 13.0  #\u753b\u56fe\u5927\u5c0f\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        # \u5982\u679c\u884c\u5927\u4e8e\u5217\n        plt.figure(figsize=(FIGSIZE,FIGSIZE\/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE\/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING\/max(rows,cols)*40+3 # \u7ecf\u8fc7\u6d4b\u8bd5\u53ef\u4ee5\u57281x1\u523010x10\u56fe\u50cf\u4e0a\u5de5\u4f5c\u7684\u9b54\u672f\u516c\u5f0f\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","aefebe72":"# \u51c6\u5907\u56fe\u50cf\u6570\u636e\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3) # \u5c06\u56fe\u7247\u89e3\u7801\n    # \u4e4b\u524d\u8bad\u7ec3\u56fe\u50cf\u4fdd\u5b58\u5728\u4e00\u4e2a uint8 \u7c7b\u578b\u7684\u6570\u7ec4\u4e2d\uff0c\u53d6\u503c\u533a\u95f4\u4e3a [0, 255]\u3002\u6211\u4eec\u9700\u8981\u5c06\u5176\u53d8\u6362\u4e3a\u4e00\u4e2a float32 \u6570\u7ec4\uff0c\u5176\u5f62\u53d6\u503c\u8303\u56f4\u4e3a 0~1\u3002\n    # \u5c06\u56fe\u7247\u8f6c\u6362\u4e3a[0\uff0c1]\u8303\u56f4\u5185\u7684\u6d6e\u70b9\u6570\n    image = tf.cast(image, tf.float32) \/ 255.0  \n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # TPU\u6240\u9700\u7684\u7cbe\u786e\u7684\u5927\u5c0f\n    return image\n\n# \u8bfb\u53d6\u5e26\u6709\u6807\u7b7e\u7684TFRecord \u683c\u5f0f\u6587\u4ef6\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\n# \u8bfb\u53d6\u6ca1\u6709\u6807\u7b7e\u7684TFRecord \u683c\u5f0f\u6587\u4ef6\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\n# \u8fd9\u4e09\u4e2a\u53c2\u6570\u5206\u522b\u4e3a\uff1a\u6587\u4ef6\u8def\u5f84\u3001\u662f\u5426\u6709\u6807\u7b7e\u3001\u662f\u5426\u6309\u987a\u5e8f\uff08\u5c31\u662f\u8981\u4e0d\u8981\u628a\u6570\u636e\u987a\u5e8f\u6253\u4e71\uff09\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # \u4eceTFRecords\u8bfb\u53d6\u3002 \u4e3a\u4e86\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u8bf7\u4e00\u6b21\u4ece\u591a\u4e2a\u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\uff0c\u800c\u4e0d\u8003\u8651\u6570\u636e\u987a\u5e8f\u3002 \u987a\u5e8f\u65e0\u5173\u7d27\u8981\uff0c\u56e0\u4e3a\u65e0\u8bba\u5982\u4f55\u6211\u4eec\u90fd\u4f1a\u5bf9\u6570\u636e\u8fdb\u884c\u6df7\u6d17\u3002\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # \u7981\u7528\u987a\u5e8f\uff0c\u63d0\u9ad8\u901f\u5ea6\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)  # \u81ea\u52a8\u4ea4\u9519\u8bfb\u53d6\u591a\u4e2a\u6587\u4ef6\n    dataset = dataset.with_options(ignore_order) # \u5728\u6d41\u5165\u6570\u636e\u540e\u7acb\u5373\u4f7f\u7528\u6570\u636e\uff0c\u800c\u4e0d\u662f\u6309\u539f\u59cb\u987a\u5e8f\u4f7f\u7528\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # \u5982\u679c\u6807\u8bb0\u4e3aTrue\u5219\u8fd4\u56de\uff08\u56fe\u50cf\uff0clabel\uff09\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u5982\u679c\u6807\u8bb0\u4e3aFalse\uff0c\u5219\u8fd4\u56de\uff08\u56fe\u50cf\uff0cid\uff09\u5bf9\u7684\u6570\u636e\u96c6\n    return dataset\n\n# \u6309\u6c34\u5e73 (\u4ece\u5de6\u5411\u53f3) \u968f\u673a\u7ffb\u8f6c\u56fe\u50cf.\u8fd4\u56de\u56fe\u7247\u7684\u53c2\u6570image\u548clabel\ndef data_augment(image, label, seed=2020):\n    # TensorFlow\u51fd\u6570\uff1atf.image.random_flip_left_right\n    # \u6309\u6c34\u5e73 (\u4ece\u5de6\u5411\u53f3) \u968f\u673a\u7ffb\u8f6c\u56fe\u50cf.\n    # \u4ee51\u6bd42\u7684\u6982\u7387,\u8f93\u51faimage\u6cbf\u7740\u7b2c\u4e8c\u7ef4\u7ffb\u8f6c\u7684\u5185\u5bb9,\u5373,width.\u5426\u5219\u6309\u539f\u6837\u8f93\u51fa\u56fe\u50cf.\n    # \u53c2\u6570\uff1a\n    # image\uff1a\u5f62\u72b6\u4e3a[height, width, channels]\u7684\u4e09\u7ef4\u5f20\u91cf.\n    # seed\uff1a\u4e00\u4e2aPython\u6574\u6570,\u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u968f\u673a\u79cd\u5b50.\u67e5\u770btf.set_random_seed\u884c\u4e3a.\n    # \u8fd4\u56de\uff1a\u4e00\u4e2a\u4e0eimage\u5177\u6709\u76f8\u540c\u7c7b\u578b\u548c\u5f62\u72b6\u7684\u4e09\u7ef4\u5f20\u91cf.\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    \n#     image = tf.image.random_flip_up_down(image, seed=seed)\n#     image = tf.image.random_brightness(image, 0.1, seed=seed)\n#     image = tf.image.random_jpeg_quality(image, 85, 100, seed=seed)\n#     image = tf.image.resize(image, [530, 530])\n#     image = tf.image.random_crop(image, [512, 512], seed=seed)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\n# \u83b7\u53d6\u8bad\u7ec3\u96c6\ndef get_training_dataset():\n    # \u52a0\u8f7d\u8bad\u7ec3\u96c6\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u8bad\u7ec3\u96c6\u8def\u5f84\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u8868\u793a\u6709\u6807\u7b7e\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    # \u5c06\u6570\u636e\u8f6c\u6362\u5e76\u884c\u5316\n    # \u4e3anum_parallel_calls \u53c2\u6570\u9009\u62e9\u6700\u4f73\u503c\u53d6\u51b3\u4e8e\u60a8\u7684\u786c\u4ef6\u3001\u8bad\u7ec3\u6570\u636e\u7684\u7279\u5f81\uff08\u4f8b\u5982\u5176\u5927\u5c0f\u548c\u5f62\u72b6\uff09\u3001Map \u529f\u80fd\u7684\u6210\u672c\u4ee5\u53ca\u5728 CPU \u4e0a\u540c\u65f6\u8fdb\u884c\u7684\u5176\u4ed6\u5904\u7406\uff1b\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    # \u91cd\u590d\u6b64\u6570\u636e\u96c6count\u6b21\u6570\n    # \u51fd\u6570\u5f62\u5f0f\uff1arepeat(count=None)\n    # \u53c2\u6570count:(\u53ef\u9009\uff09\u8868\u793a\u6570\u636e\u96c6\u5e94\u91cd\u590d\u7684\u6b21\u6570\u3002\u9ed8\u8ba4\u884c\u4e3a\uff08\u5982\u679ccount\u662fNone\u6216-1\uff09\u662f\u65e0\u9650\u671f\u91cd\u590d\u7684\u6570\u636e\u96c6\u3002\n    dataset = dataset.repeat() # \u6570\u636e\u96c6\u5fc5\u987b\u91cd\u590d\u51e0\u4e2a\u8f6e\u6b21\n    dataset = dataset.shuffle(2048) #\u5c06\u6570\u636e\u6253\u4e71\uff0c\u62ec\u53f7\u4e2d\u6570\u503c\u8d8a\u5927\uff0c\u6df7\u4e71\u7a0b\u5ea6\u8d8a\u5927\n    dataset = dataset.batch(BATCH_SIZE) # \u6309\u7167\u987a\u5e8f\u5c06\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u6570\u76ee\u884c\u6570\u636e\u5408\u6210\u4e00\u4e2a\u5c0f\u6279\u91cf\uff0c\u6700\u540e\u4e00\u4e2a\u5c0f\u6279\u91cf\u53ef\u80fd\u5c0f\u4e8e20\n    # pipeline\uff08\u7ba1\u9053\uff09\u8bfb\u53d6\u6570\u636e\uff0c\u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u4e0b\u4e00\u6279\uff08\u81ea\u52a8\u8c03\u6574\u9884\u53d6\u7f13\u51b2\u533a\u5927\u5c0f\uff09\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n\n# \u83b7\u53d6\u9a8c\u8bc1\u96c6\ndef get_validation_dataset(ordered=False):\n    # \u52a0\u8f7d\u8bad\u7ec3\u96c6\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u9a8c\u8bc1\u96c6\u8def\u5f84\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u8868\u793a\u6709\u6807\u7b7e\uff0c\u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3a\u4e0d\u6309\u7167\u987a\u5e8f\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE) ## \u6309\u7167\u987a\u5e8f\u5c06\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u6570\u76ee\u884c\u6570\u636e\u5408\u6210\u4e00\u4e2a\u5c0f\u6279\u91cf\uff0c\u6700\u540e\u4e00\u4e2a\u5c0f\u6279\u91cf\u53ef\u80fd\u5c0f\u4e8e20\n    dataset = dataset.cache() # \u4f7f\u7528.cache()\u65b9\u6cd5\uff1a\u5f53\u8ba1\u7b97\u7f13\u5b58\u7a7a\u95f4\u8db3\u591f\u65f6\uff0c\u5c06preprocess\u7684\u6570\u636e\u5b58\u50a8\u5728\u7f13\u5b58\u7a7a\u95f4\u4e2d\u5c06\u5927\u5e45\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u3002\n    # pipeline\uff08\u7ba1\u9053\uff09\u8bfb\u53d6\u6570\u636e\uff0c\u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u4e0b\u4e00\u6279\uff08\u81ea\u52a8\u8c03\u6574\u9884\u53d6\u7f13\u51b2\u533a\u5927\u5c0f\uff09\n    dataset = dataset.prefetch(AUTO)  \n    return dataset\n\n# \u5c06\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u5408\u5e76\ndef get_train_valid_datasets():\n    dataset = load_dataset(TRAINING_FILENAMES + VALIDATION_FILENAMES, labeled=True)\n       # \u5c06\u6570\u636e\u8f6c\u6362\u5e76\u884c\u5316\n    # \u52a0\u8f7d\u8bad\u7ec3\u96c6\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u8bad\u7ec3\u96c6\u8def\u5f84\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u8868\u793a\u6709\u6807\u7b7e\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    # \u91cd\u590d\u6b64\u6570\u636e\u96c6count\u6b21\u6570\n    # \u51fd\u6570\u5f62\u5f0f\uff1arepeat(count=None)\n    # \u53c2\u6570count:(\u53ef\u9009\uff09\u8868\u793a\u6570\u636e\u96c6\u5e94\u91cd\u590d\u7684\u6b21\u6570\u3002\u9ed8\u8ba4\u884c\u4e3a\uff08\u5982\u679ccount\u662fNone\u6216-1\uff09\u662f\u65e0\u9650\u671f\u91cd\u590d\u7684\u6570\u636e\u96c6\u3002\n    dataset = dataset.repeat() # \u6570\u636e\u96c6\u5fc5\u987b\u91cd\u590d\u51e0\u4e2a\u8f6e\u6b21\n    dataset = dataset.shuffle(2048) # \u5c06\u6570\u636e\u6253\u4e71\uff0c\u62ec\u53f7\u4e2d\u6570\u503c\u8d8a\u5927\uff0c\u6df7\u4e71\u7a0b\u5ea6\u8d8a\u5927\n    dataset = dataset.batch(BATCH_SIZE)\n    # pipeline\uff08\u7ba1\u9053\uff09\u8bfb\u53d6\u6570\u636e\uff0c\u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u4e0b\u4e00\u6279\uff08\u81ea\u52a8\u8c03\u6574\u9884\u53d6\u7f13\u51b2\u533a\u5927\u5c0f\uff09\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# \u83b7\u53d6\u6d4b\u8bd5\u96c6\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    # pipeline\uff08\u7ba1\u9053\uff09\u8bfb\u53d6\u6570\u636e\uff0c\u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u4e0b\u4e00\u6279\uff08\u81ea\u52a8\u8c03\u6574\u9884\u53d6\u7f13\u51b2\u533a\u5927\u5c0f\uff09\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# \u8ba1\u7b97\u6570\u636e\u96c6\u6837\u672c\u6570\u76ee\ndef count_data_items(filenames):\n    # \u6570\u636e\u96c6\u7684\u6570\u91cf\u4ee5.tfrec\u6587\u4ef6\u7684\u540d\u79f0\u7f16\u5199\uff0c\u5373flowers00-230.tfrec = 230\u4e2a\u6570\u636e\u9879\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","a5af0be0":"# LearningRate Function \u81ea\u5df1\u7f16\u5199\u7684\u5b66\u4e60\u7387\u51fd\u6570\n# \u8fd4\u56de\u5b66\u4e60\u7387\u00b7\ndef lrfn(epoch):\n    LR_START = 0.00001 # \u521d\u59cb\u5b66\u4e60\u7387\n    LR_MAX = 0.00005 * strategy.num_replicas_in_sync # \u6700\u5927\u5b66\u4e60\u7387\n    LR_MIN = 0.00001 # \u6700\u5c0f\u5b66\u4e60\u7387\n    LR_RAMPUP_EPOCHS = 5\n    LR_SUSTAIN_EPOCHS = 0\n    LR_EXP_DECAY = .8\n    \n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr","0437f665":"# \u6570\u636e\u5c55\u793a\nprint(\"Training data shapes:\")\n# \u8f93\u51fa\u8bad\u7ec3\u96c6\u524d3\u4e2a\u5c0f\u6279\u91cf\u7684\u56fe\u50cf\u6570\u636e\u5f62\u72b6\u3001\u6807\u7b7e\u5f62\u72b6\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n# \u8bad\u7ec3\u6570\u636e\u6807\u7b7e\u793a\u4f8b\nprint(\"Training data label examples:\", label.numpy())\n\nprint(\"Validation data shapes:\")\n# \u8f93\u51fa\u9a8c\u8bc1\u96c6\u524d3\u4e2a\u5c0f\u6279\u91cf\u7684\u56fe\u50cf\u6570\u636e\u5f62\u72b6\u3001\u6807\u7b7e\u5f62\u72b6\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n# \u9a8c\u8bc1\u6570\u636e\u6807\u7b7e\u793a\u4f8b\nprint(\"Validation data label examples:\", label.numpy())\n\nprint(\"Test data shapes:\")\n# \u8f93\u51fa\u6d4b\u8bd5\u96c6\u524d3\u4e2a\u5c0f\u6279\u91cf\u7684\u56fe\u50cf\u6570\u636e\u5f62\u72b6\u3001\u6807\u7b7e\u5f62\u72b6\nfor image, idnum in get_test_dataset().take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\n# \u6d4b\u8bd5\u96c6\u7684id\u793a\u4f8b\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","e392a7b2":"# \u67e5\u770b\u8bad\u7ec3\u96c6\ntraining_dataset = get_training_dataset() #\u901a\u8fc7\u4e00\u4e2a\u51fd\u6570\u6765\u83b7\u53d6\u8bad\u7ec3\u96c6\ntraining_dataset = training_dataset.unbatch().batch(20) # \u5c06\u8bad\u7ec3\u96c6\u5206\u6210\u5927\u5c0f\u4e3a20\u7684\u5c0f\u6279\u91cf\ntrain_batch = iter(training_dataset) # \u9996\u5148\u83b7\u5f97Iterator\u5bf9\u8c61","d5c5017c":"# \u518d\u6b21\u8fd0\u884c\u8be5\u5355\u5143\u683c\u4ee5\u83b7\u53d6\u4e0b\u4e00\u7ec4\u56fe\u50cf\ndisplay_batch_of_images(next(train_batch))","7db58d81":"# \u67e5\u770b\u6d4b\u8bd5\u96c6\ntest_dataset = get_test_dataset() #\u901a\u8fc7\u4e00\u4e2a\u51fd\u6570\u6765\u83b7\u53d6\u6d4b\u8bd5\u96c6\ntest_dataset = test_dataset.unbatch().batch(20) # \u5c06\u8bad\u7ec3\u96c6\u5206\u6210\u5927\u5c0f\u4e3a20\u7684\u5c0f\u6279\u91cf\ntest_batch = iter(test_dataset) # \u9996\u5148\u83b7\u5f97Iterator\u5bf9\u8c61","6ae96e80":"# \u518d\u6b21\u8fd0\u884c\u8be5\u5355\u5143\u683c\u4ee5\u83b7\u53d6\u4e0b\u4e00\u7ec4\u56fe\u50cf\ndisplay_batch_of_images(next(test_batch))","e61b8b33":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES) # \u8bad\u7ec3\u96c6\u6837\u672c\u6570\u76ee\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES) # \u9a8c\u8bc1\u96c6\u6837\u672c\u6570\u76ee\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES) # \u6d4b\u8bd5\u96c6\u6837\u672c\u6570\u76ee\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE # \u6bcf\u8f6e\u6b21\u4e2d\u7684\u6b65\u6570=\u8bad\u7ec3\u96c6\u6837\u672c\u6570\u9664\u4ee5\u6bcf\u4e2a\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u6570\u76ee\n# \u8f93\u51fa\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u7684\u6570\u76ee\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","5aae75ad":"# \u521b\u5efa\u6a21\u578b\u5e76\u52a0\u8f7d\u5230TPU\nwith strategy.scope():\n    # \u521b\u5efaEfficientNetB7\u6a21\u578b\n    enet = efn.EfficientNetB7( # \u9009\u62e9EfficientNet\u4e2d\u7684EfficientNetB7\u6a21\u578b\n        input_shape=(512, 512, 3), # \u89c4\u5b9a\u8f93\u5165\u6570\u636e\u7684\u5f62\u72b6\n        weights='imagenet', # \u7528ImageNet\u7684\u53c2\u6570\u521d\u59cb\u5316\u6a21\u578b\u7684\u53c2\u6570\u3002\u5982\u679c\u4e0d\u60f3\u4f7f\u7528ImageNet\u4e0a\u9884\u8bad\u7ec3\u5230\u7684\u6743\u91cd\u521d\u59cb\u8bdd\u6a21\u578b\uff0c\u53ef\u4ee5\u5c06\u5404\u8bed\u53e5\u7684\u4e2d'imagenet'\u66ff\u6362\u4e3a'None'\u3002\n        include_top=False # include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\uff0cFalse\u4e3a\u4e0d\u4fdd\u7559\n    )\n    \n    # \u521b\u5efa\u6a21\u578b\n    model = tf.keras.Sequential([ #Sequential\u7c7b\uff08\u4ec5\u7528\u4e8e\u5c42\u7684\u7ebf\u6027\u5806\u53e0\uff0c\u8fd9\u662f\u76ee\u524d\u6700\u5e38\u89c1\u7684\u7f51\u7edc\u67b6\u6784\uff09\n        enet, # EfficientNetB7\u6a21\u578b\n        tf.keras.layers.GlobalAveragePooling2D(), #\u5168\u5c40\u5e73\u5747\u6c60\n        # len(CLASSES)\uff1a\u8868\u793a\u8fd9\u4e2a\u5c42\u5c06\u8fd4\u56de\u4e00\u4e2a\u5927\u5c0f\u4e3a\u7c7b\u522b\u4e2a\u6570\uff08104\uff09\u7684\u5f20\u91cf\n        # activation='softmax'\uff1a\u8868\u793a\u8fd9\u4e2a\u5c42\u5c06\u8fd4\u56de\u56fe\u7247\u5728104\u4e2a\u7c7b\u522b\u4e0a\u7684\u6982\u7387\uff0c\u5176\u4e2d\u6700\u5927\u7684\u6982\u7387\u8868\u793a\u8fd9\u4e2a\u56fe\u7247\u7684\u9884\u6d4b\u7c7b\u522b\n        # softmax\u6fc0\u6d3b\u51fd\u6570\u7684\u672c\u8d28\u5c31\u662f\u5c06\u4e00\u4e2aK\u7ef4\u7684\u4efb\u610f\u5b9e\u6570\u5411\u91cf\u538b\u7f29\uff08\u6620\u5c04\uff09\u6210\u53e6\u4e00\u4e2aK\u7ef4\u7684\u5b9e\u6570\u5411\u91cf\uff0c\u5176\u4e2d\u5411\u91cf\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u53d6\u503c\u90fd\u4ecb\u4e8e\uff080\uff0c1\uff09\u4e4b\u95f4\u5e76\u4e14\u548c\u4e3a1\u3002\n        # \u5728\u591a\u5206\u7c7b\u5355\u6807\u7b7e\u95ee\u9898\u4e2d\uff0c\u53ef\u4ee5\u7528softmax\u4f5c\u4e3a\u6700\u540e\u7684\u6fc0\u6d3b\u5c42\uff0c\u53d6\u6982\u7387\u6700\u9ad8\u7684\u4f5c\u4e3a\u7ed3\u679c\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    \n    # \u7f16\u8bd1\u6a21\u578b\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(), #\u4f18\u5316\u5668\uff1aAdam \u662f\u4e00\u79cd\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u8fc7\u7a0b\u7684\u4e00\u9636\u4f18\u5316\u7b97\u6cd5\uff0c\u5b83\u80fd\u57fa\u4e8e\u8bad\u7ec3\u6570\u636e\u8fed\u4ee3\u5730\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\n        # \u635f\u5931\u51fd\u6570\uff1a\n        # \u5bf9\u4e8e\u591a\u5206\u7c7b\u95ee\u9898\uff0c\u53ef\u4ee5\u7528\u5206\u7c7b\u4ea4\u53c9\u71b5\uff08categorical crossentropy\uff09\u6216\u7a00\u758f\u5206\u7c7b\u4ea4\u53c9\u71b5\uff08sparse_categorical_crossentropy\uff09\u635f\u5931\u51fd\u6570\n        # \u8fd9\u4e2asparse_categorical_crossentropy\u635f\u5931\u51fd\u6570\u5728\u6570\u5b66\u4e0a\u4e0e categorical_crossentropy \u5b8c\u5168\u76f8\u540c\uff0c\n        # \u5982\u679c\u76ee\u6807\u662f one-hot \u7f16\u7801\u7684\uff0c\u90a3\u4e48\u4f7f\u7528 categorical_crossentropy \u4f5c\u4e3a\u635f\u5931\uff1b\n        # \u5982\u679c\u76ee\u6807\u662f\u6574\u6570\uff0c\u90a3\u4e48\u4f7f\u7528 sparse_categorical_crossentropy \u4f5c\u4e3a\u635f\u5931\u3002\n        loss = 'sparse_categorical_crossentropy', \n        metrics=['sparse_categorical_accuracy'] # \u76d1\u63a7\u6307\u6807\uff1a\u5206\u7c7b\u51c6\u786e\u7387\n    )\n    \n     #\u6a21\u578b\u7684\u6458\u8981\n    model.summary()","8b6a4880":"model.save('the_save_model.h5') #\u4fdd\u5b58\u5168\u6a21\u578b","aa25d11f":"# scheduler = tf.keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)\n# \u4f5c\u4e3a\u56de\u8c03\u51fd\u6570\u7684\u4e00\u5458,LearningRateScheduler \u53ef\u4ee5\u6309\u7167epoch\u7684\u6b21\u6570\u81ea\u52a8\u8c03\u6574\u5b66\u4e60\u7387,\n# \u53c2\u6570\uff1a\n# schedule\uff1a\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u5c06\u4e00\u4e2aepoch\u7d22\u5f15\u4f5c\u4e3a\u8f93\u5165\uff08\u6574\u6570\uff0c\u4ece0\u5f00\u59cb\u7d22\u5f15\uff09\u5e76\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5b66\u4e60\u901f\u7387\u4f5c\u4e3a\u8f93\u51fa\uff08\u6d6e\u70b9\u6570\uff09\u3002\n# \u6211\u4eec\u8fd9\u91cc\u7528lrfn\uff08epoch\uff09\u51fd\u6570\n# verbose\uff1aint\uff1b\u5f53\u5176\u4e3a0\u65f6\uff0c\u4fdd\u6301\u5b89\u9759\uff1b\u5f53\u5176\u4e3a1\u65f6\uff0c\u8868\u793a\u66f4\u65b0\u6d88\u606f\u3002\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1) \n\n# \u8bad\u7ec3\u6a21\u578b\nhistory = model.fit(\n    get_train_valid_datasets(),  # \u83b7\u53d6\u8bad\u7ec3\u96c6\n    steps_per_epoch=STEPS_PER_EPOCH, # \u8bbe\u7f6e\u6bcf\u8f6e\u7684\u6b65\u6570\n    epochs=EPOCHS,  # \u8bbe\u7f6e\u8f6e\u6b21\n    callbacks=[lr_schedule], # \u8bbe\u7f6e\u56de\u8c03\u51fd\u6570\n    validation_data=get_validation_dataset() # \u8bbe\u7f6e\u9a8c\u8bc1\u96c6\n)","61ae98ae":"# \u753b\u51fa\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u968f\u8f6e\u6b21\u53d8\u5316\u7684\u635f\u5931\u548c\u51c6\u786e\u7387\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211) #\u635f\u5931\u66f2\u7ebf\ndisplay_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 212) #\u51c6\u786e\u7387\u66f2\u7ebf\n# display_training_curves(history.history['loss'], history.history['loss'], 'loss', 211)\n# display_training_curves(history.history['sparse_categorical_accuracy'], history.history['sparse_categorical_accuracy'], 'accuracy', 212)","da05f286":"# \u56e0\u4e3a\u6211\u4eec\u8981\u5206\u5272\u6570\u636e\u96c6\u5e76\u5206\u522b\u5bf9\u56fe\u50cf\u548c\u6807\u7b7e\u8fdb\u884c\u8fed\u4ee3\uff0c\u6240\u4ee5\u987a\u5e8f\u5f88\u91cd\u8981\u3002\ncmdataset = get_validation_dataset(ordered=True)  # \u9a8c\u8bc1\u96c6\nimages_ds = cmdataset.map(lambda image, label: image)  # \u56fe\u50cf\u96c6\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch() # \u6807\u7b7e\u96c6 \ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch\ncm_probabilities = model.predict(images_ds) # \u56fe\u7247\u5728104\u4e2a\u7c7b\u522b\u4e0a\u7684\u6982\u7387\ncm_predictions = np.argmax(cm_probabilities, axis=-1) # \u5176\u4e2d\u6700\u5927\u7684\u6982\u7387\u8868\u793a\u8fd9\u4e2a\u56fe\u7247\u7684\u9884\u6d4b\u7c7b\u522b\nprint(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels) # \u8f93\u51fa\u6b63\u786e\uff08\u5b9e\u9645\uff09\u6807\u7b7e\u7684\u5f62\u72b6\u3001\u8f93\u51fa\u6b63\u786e\u6807\u7b7e \nprint(\"Predicted labels: \", cm_predictions.shape, cm_predictions) # \u8f93\u51fa\u9884\u6d4b\u6807\u7b7e\u7684\u5f62\u72b6\u3001\u8f93\u51fa\u9884\u6d4b\u6807\u7b7e","7fe6232a":"# \u8ba1\u7b97\u6df7\u6dc6\u77e9\u9635\n# \u53c2\u6570\u4e3a\u5b9e\u9645\u6807\u7b7e\u548c\u9884\u6d4b\u7684\u6807\u7b7e\ncmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n# \u8ba1\u7b97f1\u5206\u6570\nscore = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n# \u8ba1\u7b97\u7cbe\u786e\u7387\nprecision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n# \u8ba1\u7b97\u53ec\u56de\u7387\nrecall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n# \u5f52\u4e00\u5316\ncmat = (cmat.T \/ cmat.sum(axis=1)).T # normalized\n# \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\ndisplay_confusion_matrix(cmat, score, precision, recall)\n# \u8f93\u51faf1\u5206\u6570\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\nprint('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))","3031ce44":"# \u56e0\u4e3a\u6211\u4eec\u8981\u5206\u5272\u6570\u636e\u96c6\u5e76\u5206\u522b\u5bf9\u56fe\u50cf\u548cID\u8fdb\u884c\u8fed\u4ee3\uff0c\u6240\u4ee5\u987a\u5e8f\u5f88\u91cd\u8981\u3002\ntest_ds = get_test_dataset(ordered=True) # \u6d4b\u8bd5\u96c6\n\n# \u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9884\u6d4b\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image) #\u6d4b\u8bd5\u96c6\u7684\u56fe\u7247\nprobabilities = model.predict(test_images_ds) # \u56fe\u7247\u5728104\u4e2a\u7c7b\u522b\u4e0a\u7684\u6982\u7387\npredictions = np.argmax(probabilities, axis=-1) # \u5176\u4e2d\u6700\u5927\u7684\u6982\u7387\u8868\u793a\u8fd9\u4e2a\u56fe\u7247\u7684\u9884\u6d4b\u7c7b\u522b\nprint(predictions) # \u8f93\u51fa\u9884\u6d4b\u7c7b\u522b\n\n# \u751f\u6210\u63d0\u4ea4\u6587\u4ef6\nprint('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch() #\u6d4b\u8bd5\u96c6\u7684id\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # \u51c6\u6362id\u7684\u6570\u636e\u7c7b\u578b # all in one batch\n\n# \u7b2c\u4e00\u79cd\u5b58\u50a8\u6587\u4ef6\u65b9\u5f0f\uff0c\u4e0d\u9700\u8981pandas\n# np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n# \u7b2c\u4e8c\u79cd\u5b58\u50a8\u6587\u4ef6\u7684\u65b9\u5f0f\uff0c\u9700\u8981pandas\nimport pandas as pd\ntest = pd.DataFrame({\"id\":test_ids,\"label\":predictions}) #\u5c06id\u5217\u548clabel\u5217\u521b\u5efa\u6210\u4e00\u4e2aDataFrame\nprint(test.head) # \u8f93\u51fatest\u7684\u524d\u51e0\u884c\ntest.to_csv(\"submission.csv\",index = False) # \u751f\u6210\u6ca1\u6709\u7d22\u5f15\u7684submission.csv\uff0c\u4ee5\u4fbf\u63d0\u4ea4","359a0894":"dataset = get_validation_dataset()  # \u83b7\u53d6\u9a8c\u8bc1\u96c6\ndataset = dataset.unbatch().batch(20)  #\u5c06\u9a8c\u8bc1\u96c6\u5206\u6210\u5927\u5c0f\u4e3a20\u7684\u5c0f\u6279\u91cf\nbatch = iter(dataset) # \u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aIterator\u5bf9\u8c61","f06071ff":"# \u518d\u6b21\u8fd0\u884c\u8be5\u5355\u5143\u683c\u4ee5\u83b7\u53d6\u4e0b\u4e00\u7ec4\u56fe\u50cf\nimages, labels = next(batch) # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u7684\u4e0b\u4e00\u4e2a\u6279\u91cf\nprobabilities = model.predict(images) # \u56fe\u7247\u5728104\u4e2a\u7c7b\u522b\u4e0a\u7684\u6982\u7387\npredictions = np.argmax(probabilities, axis=-1) # \u5176\u4e2d\u6700\u5927\u7684\u6982\u7387\u8868\u793a\u8fd9\u4e2a\u56fe\u7247\u7684\u9884\u6d4b\u7c7b\u522b\ndisplay_batch_of_images((images, labels), predictions) # \u5c55\u793a\u4e00\u4e2a\u6279\u91cf\u7684\u56fe\u7247\uff0c\u56fe\u7247\u6807\u9898\u4e3a\u9884\u6d4b\u6807\u7b7e+\u9884\u6d4b\u6807\u7b7e\u662f\u5426\u6b63\u786e\uff08OK\u6216NO\uff09\n# \u4e3e\u4e2a\u4f8b\u5b50\uff1a\u6807\u9898\u4e3awild rose\uff08NO->watercress\uff09\uff0c\u8fd9\u4e2a\u56fe\u7247\u5b9e\u9645\u662f\u8c46\u74e3\u82b1\uff0c\u4f46\u662f\u9884\u6d4b\u4e3a\u91ce\u73ab\u7470\uff0c\u6240\u4ee5\u5b83\u662f\u9519\u7684\u3002\u6240\u4ee5\u5b83\u7684\u6807\u7b7e\u4e3a \u91ce\u73ab\u7470\uff08NO->\u8c46\u74e3\u82b1\uff09","a45caf8d":"# 4. \u914d\u7f6eTPU\u3001\u8bbf\u95ee\u8def\u5f84\u7b49","c4d2b1b9":"# 7.1. \u521b\u5efa\u6a21\u578b\u5e76\u52a0\u8f7d\u5230TPU","2da80cb9":"# 8. \u9884\u6d4b","06b1dedc":"## 5.2. \u6570\u636e\u96c6\u51fd\u6570","ef318463":"# 9. \u89c6\u89c9\u4e0a\u8fdb\u884c\u4e00\u4e0b\u9a8c\u8bc1\uff0c\u770b\u4e0b\u9884\u6d4b\u6548\u679c\n\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u9009\u62e9\u9a8c\u8bc1\u96c6\u8fdb\u884c\u89c6\u89c9\u4e0a\u7684\u9a8c\u8bc1\uff1f\n\n\u6211\u4eec\u9009\u53d6\u9a8c\u8bc1\u96c6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u56e0\u4e3a\u6a21\u578b\u662f\u6839\u636e\u8bad\u7ec3\u96c6\u8bad\u7ec3\u7684\uff0c\u800c\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u90fd\u548c\u8bad\u7ec3\u96c6\u6beb\u4e0d\u76f8\u5173\uff0c\u4f46\u662f\u9a8c\u8bc1\u96c6\u6709\u5b9e\u9645\u6807\u7b7e\uff0c\u65b9\u4fbf\u6211\u4eec\u8fdb\u884c\u9a8c\u8bc1","0a88b36e":"## 7.4. \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635","beee9f92":"## 7.2. \u8bad\u7ec3\u6a21\u578b","c209287f":"# \u7248\u672c\u66f4\u65b0\u60c5\u51b5\n\u4ee5\u4e0b\u51c6\u786e\u7387\u5168\u90fd\u662f\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u548c\u6bd4\u8d5b\u63d0\u4ea4\u4ee5\u540e\u7684\u51c6\u786e\u7387\u6709\u4e00\u5b9a\u533a\u522b\uff0c\u56e0\u4e3a\u7b97\u6cd5\u4e0d\u4e00\u6837\n* V1\uff1a\u5b98\u65b9\u7ed9\u51fa\u7684\u4ee3\u7801\uff0c\u7528\u4e86VGG\u6a21\u578b\uff0c\u51c6\u786e\u738740%\n* V2-V8\uff1a\u4e0d\u65ad\u589e\u5220\u5c42\uff0c\u5e76\u8c03\u8d85\u53c2\u6570\uff0c\u66f4\u6362\u635f\u5931\u51fd\u6570\u4e0e\u4f18\u5316\u5668 \u51c6\u786e\u7387\u589e\u957f\u523060%\u5c31\u9047\u5230\u74f6\u9888\u4e86\n* V9\uff1a\u5c1d\u8bd5\u901a\u8fc7\u4ec5\u57285\u5206\u949f\u5185\u8bad\u7ec3softmax\u5c42\u6765\u9884\u70ed\uff0c\u7136\u540e\u518d\u91ca\u653e\u6240\u6709\u91cd\u91cf\u3002\u51c6\u786e\u7387\u4e0b\u964d\u523050%\n* V10\uff1a\u66f4\u591a\u6570\u636e\u6269\u5145 \u51c6\u786e\u738755%\n* V11\uff1a\u4f7f\u7528LR Scheduler \u51c6\u786e\u738762%\n* V12\uff1a\u540c\u65f6\u4f7f\u7528\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u3002 \u51c6\u786e\u738768%\n* V13\uff1b\u4f7f\u7528\u8c37\u6b4c\u5f00\u6e90\u65b0\u6a21\u578b EfficientNetB7 \u51c6\u786e\u738791%\uff0c\u5bb3\u6015\n* V14\uff1a\u8bad\u7ec3\u66f4\u957f\u7684\u65f6\u95f4\uff0825\u4e2a\u8f6e\u6b21\uff09\u3002\u51c6\u786e\u738782%\uff0c\u4e0b\u964d\u4e86\uff0c\u662f\u56e0\u4e3a\u8fc7\u62df\u5408\u5427\n* V15\uff1a\u56de\u523020\u4e2a\u8f6e\u6b21\uff1b Global Max Pooling instead of Average\u3002\uff08\u5168\u5c40\u6700\u5927\u6c60\u800c\u4e0d\u662f\u5e73\u5747\u3002\uff09 \u51c6\u786e\u738767%\uff0c\u4e0d\u9002\u5408\n* V16\uff1a\u56de\u6eda\u5230global average pooling \uff08\u5168\u5c40\u5e73\u5747\u6c60\uff09 \u51c6\u786e\u738781%\n* V18\uff1a\u56de\u6eda\u5230V13\uff0c\u5e76\u8c03\u8282\u90e8\u5206\u53c2\u6570 \u51c6\u786e\u738799.9%\uff0c\u6050\u6016\u5982\u65af\uff0c\u6211\u597d\u65e0\u654c","245f3b2f":"# 2. \u5bfc\u5165\u9700\u8981\u7684\u5305","8f353b15":"# 5. \u5404\u79cd\u51fd\u6570","9750cd61":"# 3. \u68c0\u6d4bTPU\u548cGPU\n\u6211\u8fd9\u91cc\u6ce8\u91ca\u6389\u7684\u539f\u56e0\u662f\u6211\u4eec\u5df2\u7ecf\u77e5\u9053TPU\u548cGPU\u5b58\u5728\uff0c\u800c\u4e14\u6211\u4eec\u6253\u7b97\u5b8c\u5168\u7528TPU\u800c\u4e0d\u7528GPU","2aaeb18b":"\u4fdd\u5b58\u5168\u6a21\u578b\n\n\u53ef\u4ee5\u5bf9\u6574\u4e2a\u6a21\u578b\u8fdb\u884c\u4fdd\u5b58\uff0c\u5176\u4fdd\u5b58\u7684\u5185\u5bb9\u5305\u62ec\uff1a\n\n1. \u8be5\u6a21\u578b\u7684\u67b6\u6784\n1. \u6a21\u578b\u7684\u6743\u91cd\uff08\u5728\u8bad\u7ec3\u671f\u95f4\u5b66\u5230\u7684\uff09\n1. \u6a21\u578b\u7684\u8bad\u7ec3\u914d\u7f6e\uff08\u4f60\u4f20\u9012\u7ed9\u7f16\u8bd1\u7684\uff09\uff0c\u5982\u679c\u6709\u7684\u8bdd\n1. \u4f18\u5316\u5668\u53ca\u5176\u72b6\u6001\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\uff08\u8fd9\u4f7f\u60a8\u53ef\u4ee5\u4ece\u4e2d\u65ad\u7684\u5730\u65b9\u91cd\u65b0\u542f\u52a8\u8bad\u7ec3","8788c9d7":"## 7.3. \u7ed8\u5236\u635f\u5931\u548c\u51c6\u786e\u7387\u66f2\u7ebf","6c5f0180":"# 6. \u6570\u636e\u96c6\u53ef\u89c6\u5316","1c8b37be":"# 1. \u5b89\u88c5efficientnet","2485aa6a":"## 5.1. \u53ef\u89c6\u5316\u51fd\u6570","590aeee8":"## 5.3. \u6a21\u578b\u51fd\u6570","f5ade8f5":"# 7. \u8bad\u7ec3\u6a21\u578b"}}