{"cell_type":{"4568d934":"code","88108ba0":"code","82c1bc3c":"code","cd996ff6":"code","440caba4":"code","1af89e37":"code","62206c36":"code","7f8b6979":"code","08614e17":"markdown","1a3d60c7":"markdown","5de5c068":"markdown","7623c204":"markdown","f8284a74":"markdown","cd8cb5df":"markdown","11926350":"markdown","ae120a39":"markdown","f76059ee":"markdown","c8bcd46f":"markdown"},"source":{"4568d934":"# generate and plot an idealized gaussian\nfrom numpy import arange\nfrom matplotlib import pyplot\nfrom scipy.stats import norm\n# x-axis for the plot\nx_axis = arange(-3, 3, 0.001)\n# y-axis as the gaussian\ny_axis = norm.pdf(x_axis, 0, 1)\n# plot data\npyplot.plot(x_axis, y_axis)\npyplot.show()","88108ba0":"# generate a sample of random gaussians\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# histogram of generated data\npyplot.hist(data)\npyplot.show()","82c1bc3c":"#generate a sample of random gaussians\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# histogram of generated data\npyplot.hist(data, bins=100)\npyplot.show()","cd996ff6":"# calculate the mean of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import mean\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate mean\nresult = mean(data)\nprint('Mean: %.3f' % result)","440caba4":"# calculate the median of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import median\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate median\nresult = median(data)\nprint('Median: %.3f' % result)","1af89e37":"# generate and plot gaussians with different variance\nfrom numpy import arange\nfrom matplotlib import pyplot\nfrom scipy.stats import norm\n# x-axis for the plot\nx_axis = arange(-3, 3, 0.001)\n# plot low variance\npyplot.plot(x_axis, norm.pdf(x_axis, 0, 0.5))\n# plot high variance\npyplot.plot(x_axis, norm.pdf(x_axis, 0, 1))\npyplot.show()","62206c36":"# calculate the variance of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import var\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate variance\nresult = var(data)\nprint('Variance: %.3f' % result)","7f8b6979":"# calculate the standard deviation of a sample\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import std\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = 5 * randn(10000) + 50\n# calculate standard deviation\nresult = std(data)\nprint('Standard Deviation: %.3f' % result)","08614e17":"# 6. Describing a Gaussian:\n\nIn applied machine learning, you will often need to report the results of an algorithm. That is,\nreport the estimated skill of the model on out-of-sample data. This is often done by reporting\nthe mean performance from a k-fold cross-validation, or some other repeated sampling procedure.\nWhen reporting model skill, you are in e\u000bect summarizing the distribution of skill scores, and\nvery likely the skill scores will be drawn from a Gaussian distribution.\nIt is common to only report the mean performance of the model. This would hide two\nother important details of the distribution of the skill of the model. As a minimum I would\nrecommend reporting the two parameters of the Gaussian distribution of model scores and the\nsize of the sample. Ideally, it would also be a good idea to con\frm that indeed the model skill\nscores are Gaussian or look Gaussian enough to defend reporting the parameters of the Gaussian\ndistribution. This is important because the distribution of skill scores can be reconstructed by\nreaders and potentially compared to the skill of models on the same problem in the future.","1a3d60c7":"It is helpful when data is Gaussian or when we assume a Gaussian distribution for calculating\nstatistics. This is because the Gaussian distribution is very well understood. So much so that\nlarge parts of the field of statistics are dedicated to methods for this distribution. Thankfully,\nmuch of the data we work with in machine learning often fits a Gaussian distribution. Examples\ninclude the input data we may use to fit a model and the multiple evaluations of a model on\ndifferent samples of training data. Not all data is Gaussian, and it is sometimes important to\nmake this discovery either by reviewing histogram plots of the data or using statistical tests to\ncheck. Some examples of observations that do not fit a Gaussian distribution and instead may\nfit an exponential (hockey-stick shape) include:\n\n    * People's incomes.\n    * Population of cities.\n    * Sales of books.\n    \nA uniform distribution is another common distribution, often seen when each item or value\nhas an equal value for being selected. The shape of a graph of the uniform distribution is a \nat\nline.","5de5c068":"# 1. Gaussian Distribution: \n\nA distribution of data refers to the shape it has when you graph it, such as with a histogram.\nThe most commonly seen and therefore well-known distribution of continuous values is the bell\ncurve. It is known as the normal distribution, because it the distribution that a lot of data falls\ninto. It is also known as the Gaussian distribution, more formally, named for Carl Friedrich\nGauss. As such, you will see references to data being normally distributed or Gaussian, which\nare interchangeable, both referring to the same thing: that the data looks like the Gaussian\ndistribution. Some examples of observations that have a Gaussian distribution include:\n\n    * People's heights.\n    * IQ scores.\n    * Body temperature.","7623c204":"A sample of data is a snapshot from a broader population of all possible observations that\ncould be taken of a domain or generated by a process. Interestingly, many observations fit a\ncommon pattern or distribution called the normal distribution, or more formally, the Gaussian\ndistribution. A lot is known about the Gaussian distribution, and as such, there are whole\nsub fields of statistics and statistical methods that can be used with Gaussian data. In this\ntutorial, you will discover the Gaussian distribution, how to identify fit, and how to calculate\nkey summary statistics of data drawn from this distribution. After completing this tutorial, you\nwill know:\n   * That the Gaussian distribution describes many observations, including many observations\nseen during applied machine learning.\n   * That the central tendency of a distribution is the most likely observation and can be\nestimated from a sample of data as the mean or median.\n   * That the variance is the average deviation from the mean in a distribution and can be\nestimated from a sample of data as the variance and standard deviation.","f8284a74":"# Tutorial Overview\nThis tutorial is divided into 6 parts; they are:\n\n    1. Gaussian Distribution\n    2. Sample vs Population\n    3. Test Dataset\n    4. Central Tendencies\n    5. Variance\n    6. Describing a Gaussian","cd8cb5df":"# 3. Test Dataset:\n\nBefore we explore some important summary statistics for data with a Gaussian distribution, let's\nfirst generate a sample of data that we can work with. We can use the randn() NumPy function\nto generate a sample of random numbers drawn from a Gaussian distribution. There are two\nkey parameters that define any Gaussian distribution; they are the mean and the standard\ndeviation. We will go more into these parameters later as they are also key statistics to estimate\nwhen we have data drawn from an unknown Gaussian distribution.\n\nThe randn() function will generate a specified number of random numbers (e.g. 10,000)\ndrawn from a Gaussian distribution with a mean of zero and a standard deviation of 1. We can\nthen scale these numbers to a Gaussian of our choosing by rescaling the numbers. This can be\nmade consistent by adding the desired mean (e.g. 50) and multiplying the value by the standard\ndeviation (5).","11926350":"# 2. Sample vs Population:\n\nWe can think of data being generated by some unknown process. The data that we collect is\ncalled a data sample, whereas all possible data that could be collected is called the population.\n\n    * Data Sample: A subset of observations from a group.\n    * Data Population: All possible observations from a group.\n    \nThis is an important distinction because di\u000berent statistical methods are used on samples vs\npopulations, and in applied machine learning, we are often working with samples of data. If you\nread or use the word population when talking about data in machine learning, it very likely\nmeans sample when it comes to statistical methods.\nTwo examples of data samples that you will encounter in machine learning include:\n\n    * The train and test datasets.\n    * The performance scores for a model.\n    \nWhen using statistical methods, we often want to make claims about the population using\nonly observations in the sample. Two clear examples of this include:\n\n    * The training sample must be representative of the population of observations so that we\n       can fit a useful model.\n    * The test sample must be representative of the population of observations so that we can\n       develop an unbiased evaluation of the model skill.\n\nBecause we are working with samples and making claims about a population, it means that\nthere is always some uncertainty, and it is important to understand and report this uncertainty.","ae120a39":"# 5. Variance:\n\nThe variance of a distribution refers to how much on average that observations vary or di\u000ber\nfrom the mean value. It is useful to think of the variance as a measure of the spread of a\ndistribution. A low variance will have values grouped around the mean (e.g. a narrow bell\nshape), whereas a high variance will have values spread out from the mean (e.g. a wide bell\nshape.) We can demonstrate this with an example, by plotting idealized Gaussians with low\nand high variance. The complete example is listed below.","f76059ee":"# 4. Central Tendency:\n\nThe central tendency of a distribution refers to the middle or typical value in the distribution.\nThe most common or most likely value. In the Gaussian distribution, the central tendency is\ncalled the mean, or more formally, the arithmetic mean, and is one of the two main parameters\nthat defines any Gaussian distribution. The mean of a sample is calculated as the sum of the\nobservations divided by the total number of observations in the sample.\n\nWhere xi is the ith observation from the dataset and n is the total number of observations.\n\nThe notation for the population mean is the Greek lower case letter mu (\u0016). The notation\nfor the sample mean is the variable with a bar above, such as x-bar (\u0016x). We can calculate the\nmean of a sample by using the mean() NumPy function on an array.","c8bcd46f":"Running the example generates a plot of an idealized Gaussian distribution. The x-axis are\nthe observations and the y-axis is the likelihood of each observation. In this case, observations\naround 0.0 are the most common and observations around -3.0 and 3.0 are rare or unlikely."}}