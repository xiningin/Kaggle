{"cell_type":{"61abcf00":"code","995e1780":"code","37851862":"code","2bb2bd51":"code","99b031bd":"code","0ba1dcf4":"code","9bb09e74":"code","1b0ebcc3":"code","0a16889e":"code","73d9d568":"code","646c8b8d":"code","74cc3991":"code","55d8fda8":"code","f49e21d6":"code","599a31b8":"code","4519a9cc":"code","2342f0a8":"markdown","d9fad951":"markdown","3360ffa2":"markdown","e0b88ec0":"markdown","9e9ac383":"markdown","844e5481":"markdown","53485938":"markdown","cbe2e523":"markdown"},"source":{"61abcf00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python https:\/\/www.kaggle.com\/uysimty\/get-start-image-classification\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","995e1780":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","37851862":"train.head(10)","2bb2bd51":"train.isnull().any().describe()","99b031bd":"y=train['label']\ny_asli=y\nX=train.drop('label', axis=1)","0ba1dcf4":"X=X.values.reshape(-1,28,28,1)","9bb09e74":"from keras.utils.np_utils import to_categorical\n\ny=to_categorical(y, num_classes=10)","1b0ebcc3":"from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)","0a16889e":"import matplotlib.pyplot as plt\nplt.imshow(X_train[3][:,:,0])","73d9d568":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\naugmentation_generate = ImageDataGenerator(\n    rescale=1.\/255,        \n    horizontal_flip= False,\n    rotation_range=90,\n    vertical_flip = False,\n    validation_split = 0.0\n)","646c8b8d":"data_train_generator = augmentation_generate.flow(\n    X_train,y_train,\n    batch_size=32   # 5 data untuk proses propagasi maju\n\n)","74cc3991":"data_validation_gen = augmentation_generate.flow(\n    X_test,y_test,\n    batch_size=32     \n)","55d8fda8":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nmodel_cnn3 = Sequential()\nshape=(28,28,1)\nmodel_cnn3.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=shape))\nmodel_cnn3.add(MaxPooling2D((2, 2)))\nmodel_cnn3.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel_cnn3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_cnn3.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel_cnn3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_cnn3.add(Flatten())                         # flatten array\nmodel_cnn3.add(Dense(256, activation='relu'))     # Fungsi aktivasi relu berjumlah 256 buah\nmodel_cnn3.add(Dense(10, activation='softmax'))    # Fungsi aktivasi softmax untuk 3 buah output (paper, rock, scissor)","f49e21d6":"import tensorflow as tf\nloss_fn = tf.keras.losses.Poisson(reduction=\"auto\", name=\"poisson\")   # Loss function berbentuk fungsi Poisson digunakan untuk menghitung nilai error\nmodel_cnn3.compile(loss=loss_fn, optimizer=tf.optimizers.Adam(), metrics=['accuracy']) # optimizer digunakan untuk update nilai hidden layer untuk updating nilai ke nilai yang lebih baik","599a31b8":"model_cnn3.fit(\n      data_train_generator, # Data train generator\n      epochs=40,           # Jumlah epoch maksimal\n      steps_per_epoch=65,  # Jumlah data yang diperlukan untuk menyelesaikan satu kali epoch\n      validation_steps=5,  # Jumlah data validasi yang dilewatkan\n      validation_data=data_validation_gen, verbose=1)","4519a9cc":"scores = model_cnn3.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (model_cnn3.metrics_names[1], scores[1]*100))\nprint(\"%s: %.2f%%\" % (model_cnn3.metrics_names[0], scores[0]*100))","2342f0a8":"# Hot Label Encoding for Y_label","d9fad951":"## Image processing before train the model","3360ffa2":"# Begin training the model","e0b88ec0":"label : shows the label determined by all 784 pixels data\n\npixel : determined the level of black concentration of pixel","9e9ac383":"# Reshaping the data","844e5481":"# Load the Data","53485938":"# Evaluate model","cbe2e523":"# Label the data"}}