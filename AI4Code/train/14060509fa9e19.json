{"cell_type":{"0c730f57":"code","5bc2ace1":"code","d3ed591d":"code","1ff44170":"code","124be8d0":"code","1fceb046":"code","c5b5737b":"code","e8dac6c9":"code","017c8c3d":"code","ffabbf30":"code","48db4f40":"code","12d75b23":"code","4d7846a4":"code","bd049f7a":"code","8292c513":"code","cdeaee58":"code","ea8bd2ed":"code","4fdd26ac":"code","472ad692":"code","b058c5b9":"code","86372460":"code","aa70f12e":"code","dc2a9218":"code","be59c309":"code","e60b4f1d":"code","c2daf7a5":"code","ba935f07":"code","6783d8f1":"code","aee46826":"code","8bb376b7":"code","92f6cec8":"code","46143bcb":"code","abeb88fc":"code","15483ed6":"code","9ba0338f":"code","e22ddd2e":"code","d0f344f8":"code","7e13a01e":"code","2c68510c":"code","72f60a6e":"code","893dcc69":"code","7dfd6093":"code","cee64e4e":"code","f98edddb":"code","48a9869b":"code","850f0bba":"code","68639a91":"code","f27f679c":"code","f0b29663":"code","c369b69b":"code","e86eaf5a":"code","1c07b33b":"code","f41b6b1d":"code","5b6fe4ae":"code","6dc4e2f5":"code","4faa634e":"code","9637f5d9":"code","d48be404":"markdown","c544fa00":"markdown","66ad54eb":"markdown","78b25e73":"markdown","f27a5e4d":"markdown","c1fe2ef2":"markdown","7eb250fa":"markdown","8609a46d":"markdown","a30b9239":"markdown","9a816984":"markdown","7723f3c6":"markdown","2ae7f9a5":"markdown","099acca8":"markdown","39b1fdeb":"markdown","5df65d0e":"markdown","62d5385e":"markdown","e7dfe588":"markdown","c8a87758":"markdown","b4adb8d9":"markdown","389e67ee":"markdown","ccc128c1":"markdown","48489447":"markdown","d1db0eb9":"markdown","c33a21db":"markdown","4844c189":"markdown","7edb7789":"markdown","d534898b":"markdown","c0f9d5d3":"markdown","5c86799d":"markdown","ba72f0a5":"markdown","f5ef7b7c":"markdown","6a481bfe":"markdown","6ae80a54":"markdown","cf10b2a2":"markdown","cee2a43d":"markdown","db039f53":"markdown","9f64318d":"markdown","dfda9633":"markdown","e0a6ab1a":"markdown","b3b5167d":"markdown","9ca82ae8":"markdown","d067cf78":"markdown","397bf182":"markdown","64a74b93":"markdown","bf701ec1":"markdown","60e5f8d2":"markdown","72b5c116":"markdown","2cd8463d":"markdown","09604b0d":"markdown","95110c71":"markdown","19c49ca7":"markdown","b74b966f":"markdown","3cd689ea":"markdown","29ff107c":"markdown","0e49487e":"markdown","8ff7c06f":"markdown","10ea5eac":"markdown","b4585e61":"markdown","c627f02e":"markdown","ecedddf8":"markdown","27484c88":"markdown","e93e74d4":"markdown","7256a018":"markdown","18ad2678":"markdown"},"source":{"0c730f57":"# Ignore warnings :\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Handle table-like data and matrices :\nimport numpy as np\nimport pandas as pd\nimport math \n\n\n\n# Modelling Algorithms :\n\n# Classification\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n\n# Regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n\n\n# Modelling Helpers :\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n\n\n#preprocessing :\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler, Imputer, LabelEncoder\n\n\n\n#evaluation metrics :\n\n# Regression\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n\n# Classification\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  \n\n\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport missingno as msno\n\n\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplt.rcParams.update(params)","5bc2ace1":"# Center all plots\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\");","d3ed591d":"df = pd.read_csv('..\/input\/diamonds.csv')\ndiamonds = df.copy()","1ff44170":"# How the data looks\ndf.head()","124be8d0":"# We'll Explore All the features in the Later Part, Now let's look for Null Values if any..","1fceb046":"df.drop(['Unnamed: 0'] , axis=1 , inplace=True)\ndf.head()","c5b5737b":"df.shape","e8dac6c9":"# So, We have 53,940 rows and 10 columns","017c8c3d":"df.info()","ffabbf30":"# It seems there are no Null Values.\n# Let's Confirm\ndf.isnull().sum()","48db4f40":"msno.matrix(df) # just to visualize. no missing values.","12d75b23":"df.describe()","4d7846a4":"df.loc[(df['x']==0) | (df['y']==0) | (df['z']==0)]","bd049f7a":"len(df[(df['x']==0) | (df['y']==0) | (df['z']==0)])","8292c513":"df = df[(df[['x','y','z']] != 0).all(axis=1)]","cdeaee58":"# Just to Confirm\ndf.loc[(df['x']==0) | (df['y']==0) | (df['z']==0)]","ea8bd2ed":"# Nice and Clean. :)","4fdd26ac":"sns.factorplot(data=df , kind='box' , size=7, aspect=2.5)","472ad692":"# Correlation Map\ncorr = df.corr()\nsns.heatmap(data=corr, square=True , annot=True, cbar=True)","b058c5b9":"# Visualize via kde plots","86372460":"sns.kdeplot(df['carat'], shade=True , color='r')","aa70f12e":"sns.jointplot(x='carat' , y='price' , data=df , size=5)","dc2a9218":"sns.factorplot(x='cut', data=df , kind='count',aspect=2.5 )","be59c309":"sns.factorplot(x='cut', y='price', data=df, kind='box' ,aspect=2.5 )","e60b4f1d":"# Understanding Box Plot :\n\n# The bottom line indicates the min value of Age.\n# The upper line indicates the max value.\n# The middle line of the box is the median or the 50% percentile.\n# The side lines of the box are the 25 and 75 percentiles respectively.","c2daf7a5":"sns.factorplot(x='color', data=df , kind='count',aspect=2.5 )","ba935f07":"sns.factorplot(x='color', y='price' , data=df , kind='violin', aspect=2.5)","6783d8f1":"labels = df.clarity.unique().tolist()\nsizes = df.clarity.value_counts().tolist()\ncolors = ['#006400', '#E40E00', '#A00994', '#613205', '#FFED0D', '#16F5A7','#ff9999','#66b3ff']\nexplode = (0.1, 0.0, 0.1, 0, 0.1, 0, 0.1,0)\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=0)\nplt.axis('equal')\nplt.title(\"Percentage of Clarity Categories\")\nplt.plot()\nfig=plt.gcf()\nfig.set_size_inches(6,6)\nplt.show()","aee46826":"sns.boxplot(x='clarity', y='price', data=df )","8bb376b7":"plt.hist('depth' , data=df , bins=25)","92f6cec8":"sns.jointplot(x='depth', y='price' , data=df , kind='regplot', size=5)","46143bcb":"sns.kdeplot(df['table'] ,shade=True , color='orange')","abeb88fc":"sns.jointplot(x='table', y='price', data=df , size=5)","15483ed6":"sns.kdeplot(df['x'] ,shade=True , color='r' )\nsns.kdeplot(df['y'] , shade=True , color='g' )\nsns.kdeplot(df['z'] , shade= True , color='b')\nplt.xlim(2,10)","9ba0338f":"df['volume'] = df['x']*df['y']*df['z']\ndf.head()","e22ddd2e":"plt.figure(figsize=(5,5))\nplt.hist( x=df['volume'] , bins=30 ,color='g')\nplt.xlabel('Volume in mm^3')\nplt.ylabel('Frequency')\nplt.title('Distribution of Diamond\\'s Volume')\nplt.xlim(0,1000)\nplt.ylim(0,50000)","d0f344f8":"sns.jointplot(x='volume', y='price' , data=df, size=5)","7e13a01e":"df.drop(['x','y','z'], axis=1, inplace= True)\n#df.head()","2c68510c":"label_cut = LabelEncoder()\nlabel_color = LabelEncoder()\nlabel_clarity = LabelEncoder()\n\n\ndf['cut'] = label_cut.fit_transform(df['cut'])\ndf['color'] = label_color.fit_transform(df['color'])\ndf['clarity'] = label_clarity.fit_transform(df['clarity'])","72f60a6e":"#df.head()","893dcc69":"# Split the data into train and test.","7dfd6093":"X = df.drop(['price'], axis=1)\ny = df['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=66)","cee64e4e":"# Applying Feature Scaling ( StandardScaler )\n# You can also Apply MinMaxScaler.","f98edddb":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","48a9869b":"# Collect all R2 Scores.\nR2_Scores = []\nmodels = ['Linear Regression' , 'Lasso Regression' , 'AdaBoost Regression' , 'Ridge Regression' , 'GradientBoosting Regression',\n          'RandomForest Regression' ,\n         'KNeighbours Regression']","850f0bba":"clf_lr = LinearRegression()\nclf_lr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_lr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_lr.predict(X_test)\nprint('')\nprint('####### Linear Regression #######')\nprint('Score : %.4f' % clf_lr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","68639a91":"clf_la = Lasso(normalize=True)\nclf_la.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_la, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_la.predict(X_test)\nprint('')\nprint('###### Lasso Regression ######')\nprint('Score : %.4f' % clf_la.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","f27f679c":"clf_ar = AdaBoostRegressor(n_estimators=1000)\nclf_ar.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_ar, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_ar.predict(X_test)\nprint('')\nprint('###### AdaBoost Regression ######')\nprint('Score : %.4f' % clf_ar.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","f0b29663":"clf_rr = Ridge(normalize=True)\nclf_rr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_rr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_rr.predict(X_test)\nprint('')\nprint('###### Ridge Regression ######')\nprint('Score : %.4f' % clf_rr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","c369b69b":"clf_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls',verbose = 1)\nclf_gbr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_gbr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_gbr.predict(X_test)\nprint('')\nprint('###### Gradient Boosting Regression #######')\nprint('Score : %.4f' % clf_gbr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","e86eaf5a":"clf_rf = RandomForestRegressor()\nclf_rf.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_rf, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_rf.predict(X_test)\nprint('')\nprint('###### Random Forest ######')\nprint('Score : %.4f' % clf_rf.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","1c07b33b":"no_of_test=[100]\nparams_dict={'n_estimators':no_of_test,'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2']}\nclf_rf=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params_dict,scoring='r2')\nclf_rf.fit(X_train,y_train)\nprint('Score : %.4f' % clf_rf.score(X_test, y_test))\npred=clf_rf.predict(X_test)\nr2 = r2_score(y_test, pred)\nprint('R2     : %0.2f ' % r2)\nR2_Scores.append(r2)","f41b6b1d":"clf_knn = KNeighborsRegressor()\nclf_knn.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_knn, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_knn.predict(X_test)\nprint('')\nprint('###### KNeighbours Regression ######')\nprint('Score : %.4f' % clf_knn.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","5b6fe4ae":"n_neighbors=[]\nfor i in range (0,50,5):\n    if(i!=0):\n        n_neighbors.append(i)\nparams_dict={'n_neighbors':n_neighbors,'n_jobs':[-1]}\nclf_knn=GridSearchCV(estimator=KNeighborsRegressor(),param_grid=params_dict,scoring='r2')\nclf_knn.fit(X_train,y_train)\nprint('Score : %.4f' % clf_knn.score(X_test, y_test))\npred=clf_knn.predict(X_test)\nr2 = r2_score(y_test, pred)\nprint('R2     : %0.2f ' % r2)\nR2_Scores.append(r2)","6dc4e2f5":"compare = pd.DataFrame({'Algorithms' : models , 'R2-Scores' : R2_Scores})\ncompare.sort_values(by='R2-Scores' ,ascending=False)","4faa634e":"sns.barplot(x='R2-Scores' , y='Algorithms' , data=compare)","9637f5d9":"sns.factorplot(x='Algorithms', y='R2-Scores' , data=compare, size=6 , aspect=4)","d48be404":"### Let's Have a look at them.","c544fa00":"## 3.2) Cut\n\n* **Although the Carat Weight of a Diamond has the Strongest Effect on Prices, the Cut can still Drastically Increase or Decrease its value.**\n* **With a Higher Cut Quality, the Diamond\u2019s Cost per Carat Increases.**\n* **This is because there is a Higher Wastage of the Rough Stone as more Material needs to be Removed in order to achieve better Proportions and Symmetry.**\n\n[Click Here to Lean More about How Cut Affects the Price.](https:\/\/www.lumeradiamonds.com\/diamond-education\/diamond-cut)","66ad54eb":"![](https:\/\/i.imgur.com\/Ij090Kn.jpg)","78b25e73":"### It seems that VS1 and VS2 affect the Diamond's Price equally having quite high Price margin.","f27a5e4d":"## 1.1) Importing Libraries","c1fe2ef2":"## 3.7) Dimensions","7eb250fa":"### Random Forest Regressor gives us the highest R2-Score [ 98% ] .","8609a46d":"<a id=\"there_you_go_7\"><\/a>\n# 7) Modelling Algos","a30b9239":"## 3.6) Table\n* **Table is the Width of the Diamond's Table expressed as a Percentage of its Average Diameter.**\n* **If the Table (Upper Flat Facet) is too Large then light will not play off of any of the Crown's angles or facets and will not create the Sparkly Rainbow Colors.**\n* **If it is too Small then the light will get Trapped and that Attention grabbing shaft of light will never come out but will \u201cleak\u201d from other places in the Diamond.**\n\n[Click Here to Learn More about How Table Affects the Price of Diamonds.](https:\/\/beyond4cs.com\/grading\/depth-and-table-values\/)","9a816984":"![](https:\/\/i.imgur.com\/fLbAstc.jpg)","7723f3c6":"## 7.5) GradientBoosting Regression","2ae7f9a5":"## What are Diamonds?\n* **Diamonds are the Precious stone consisting of a clear and colourless Crystalline form of pure carbon.**\n* **They are the hardest Gemstones known to man and can be scratched only by other Diamonds.**","099acca8":"## CONCLUSIONS :\n**1. Depth is inversely related to Price.**\n> * This is because if a Diamond's Depth percentage is too large or small the Diamond will become '__Dark__' in appearance because it will no longer return an Attractive amount of light.\n\n**2. The Price of the Diamond is highly correlated to Carat, and its Dimensions.**\n\n**3. The Weight (Carat) of a diamond has the most significant impact on its Price. **\n> * Since, the larger a stone is, the Rarer it is, one 2 carat diamond will be more '__Expensive__' than the total cost of two 1 Carat Diamonds of the same Quality.\n\n**4. The Length(x) , Width(y) and Height(z) seems to be higly related to Price and even each other.**\n\n**5. Self Relation ie. of a feature to itself is 1 as expected.**\n\n**6. Some other Inferences can also be drawn.**","39b1fdeb":"## 3.3) Color\n* **The Color of a Diamond refers to the Tone and Saturation of Color, or the Depth of Color in a Diamond.**\n* **The Color of a Diamond can Range from Colorless to a Yellow or a Faint Brownish Colored hue.**\n* **Colorless Diamonds are Rarer and more Valuable because they appear Whiter and Brighter.**\n\n[Click Here to Learn More about How Color Affects the Price](https:\/\/enchanteddiamonds.com\/education\/understanding-diamond-color)","5df65d0e":"### We can see there are 20 rows with Dimensions 'Zero'.\n* **We'll Drop them as it seems better choice instead of filling them with any of Mean or Median**","62d5385e":"## 4.1) Create New Feature 'Volume'","e7dfe588":"## Why are Diamonds so Valuable?\n* **Whether it is a Rare book, a fine bottle of Scotch, or a Diamond, something that is Rare and Unique is often expensive.**\n* **But what makes it truly Valuable is that this Rarity coincides with the desire of many to possess it. ;)**\n* **Diamonds are Rare because of the Incredibly powerful forces needed to create them.**\n\n\n* **And therefore Diamonds are considered to be Very Costly.**","c8a87758":"## 1.4) Drop the 'Unnamed: 0' column as we already have Index.","b4adb8d9":"### Great, So there are no NaN values.","389e67ee":"**We'll Create a New Feature based on the Dimensions in the Next Section called 'Volume' and Visualize how it affects the Price.**","ccc128c1":"<a id=\"there_you_go_8\"><\/a>\n# 8) Visualizing R2-Score of Algorithms","48489447":"### It seems that there is Linear Relationship between Price and Volume (x \\* y \\* z).","d1db0eb9":"## 1.7) Scaling of all Features","c33a21db":"### Premium Cut on Diamonds as we can see are the most Expensive, followed by Excellent \/ Very Good Cut.","4844c189":"### It seems that Carat varies with Price Exponentially.","7edb7789":"## 1.2) Extract Dataset\n* Specify the location to the Dataset and Import them.","d534898b":"## 7.7) KNeighbours Regression","c0f9d5d3":"## 7.3) AdaBosst Regression","5c86799d":"# Topics\n1. [**Exploring Dataset**](#there_you_go_1)\n2. [**Correlation b\/w Features**](#there_you_go_2)\n3. [**Visualizations**](#there_you_go_3)\n4. [**Feature Engineering**](#there_you_go_4)\n5. [**Feature Encoding**](#there_you_go_5)\n6. [**Feature Scaling**](#there_you_go_6)\n7. [**Modelling Algorithms**](#there_you_go_7)\n8. [**Comparing R2 Scores**](#there_you_go_8)","ba72f0a5":"## 4.2) Drop X, Y, Z","f5ef7b7c":"## 1.6) Dropping Rows with Dimensions 'Zero'.","6a481bfe":"* **Divide the Dataset into Train and Test, So that we can fit the Train for Modelling Algos and Predict on Test.**\n* **Then Apply Feature Scaling although it's not neccessary in this case. But it surely helps.**","6ae80a54":"<a id=\"there_you_go_3\"><\/a>\n# 3. Visualization Of All Features","cf10b2a2":"## 1.3) Features\n* **Carat : ** Carat weight of the Diamond.\n* **Cut : ** Describe cut quality of the diamond.\n> * Quality in increasing order Fair, Good, Very Good, Premium, Ideal .\n* **Color : ** Color of the Diamond.\n> * With D being the best and J the worst.\n* **Clarity : ** Diamond Clarity refers to the absence of the Inclusions and Blemishes.\n> * (In order from Best to Worst, FL = flawless, I3= level 3 inclusions) FL, IF, VVS1, VVS2, VS1, VS2, SI1, SI2, I1, I2, I3\n* **Depth : ** The Height of a Diamond, measured from the Culet to the table, divided by its average Girdle Diameter.\n* **Table : ** The Width of the Diamond's Table expressed as a Percentage of its Average Diameter.\n* **Price : ** the Price of the Diamond.\n* **X : ** Length of the Diamond in mm.\n* **Y : ** Width of the Diamond in mm.\n* **Z : ** Height of the Diamond in mm.\n\n*Qualitative Features (Categorical) : Cut, Color, Clarity. *\n\n*Quantitative Features (Numerical) : Carat, Depth , Table , Price , X , Y, Z.*\n\n\n### Price is the Target Variable.","cee2a43d":"### Carat vs Price","db039f53":"## 7.6) RandomForest Regression","9f64318d":"<a id=\"there_you_go_1\"><\/a>\n# 1) Explore Dataset & Examine what Features affect the Price of Diamonds.","dfda9633":"<a id=\"there_you_go_4\"><\/a>\n# 4) Feature Engineering","e0a6ab1a":"## 7.1) Linear Regression","b3b5167d":"### Tuning Parameters","9ca82ae8":"![](https:\/\/i.imgur.com\/blhMqmD.jpg)","d067cf78":"## 3.5) Depth\n* **The Depth of a Diamond is its Height (in millimeters) measured from the Culet to the Table.**\n* **If a Diamond's Depth Percentage is too large or small the Diamond will become Dark in appearance because it will no longer return an Attractive amount of light.**\n\n[Click Here to Learn More about How Depth Affects the Price of Diamonds.](https:\/\/beyond4cs.com\/grading\/depth-and-table-values\/)","397bf182":"### Wait\n* **Do you see the Min. Values of X, Y and Z. It can't be possible..!!**\n* **It doesn't make any sense to have either of Length or Width or Height to be zero..**","64a74b93":"# DIAMONDS IN-DEPTH ANALYSIS\n* You can also view the notebook on the link below.\n* *Github Link* - **https:\/\/github.com\/Chinmayrane16\/Diamonds-In-Depth-Analysis**\n* **Do Upvote if you like it :)**","bf701ec1":"<a id=\"there_you_go_6\"><\/a>\n# 6) Feature Scaling","60e5f8d2":"* **Label the Categorical Features with digits to Distinguish.**\n* **As we can't feed String data for Modelling.**","72b5c116":"![](https:\/\/i.imgur.com\/hA3oat5.png)","2cd8463d":"## 3.1) Carat\n\n* **Carat refers to the Weight of the Stone, not the Size.**\n* **The Weight of a Diamond has the most significant Impact on its Price.**\n* **Since the larger a Stone is, the Rarer it is, one 2 Carat Diamond will be more Expensive than the Total cost of two 1 Carat Diamonds of the Same Quality.**\n* **The carat of a Diamond is often very Important to People when shopping But it is a Mistake to Sacrifice too much quality for sheer size.**\n\n\n[Click Here to Learn More about How Carat Affects the Price of Diamonds.](https:\/\/www.diamondlighthouse.com\/blog\/2014\/10\/23\/how-carat-weight-affects-diamond-price\/)","09604b0d":"## Cut vs Price","95110c71":"### We can Infer from the plot that the Price can vary heavily for the same Depth.\n* **And the Pearson's Correlation shows that there's a slightly inverse relation between the two.**","19c49ca7":"# Thank You :)","b74b966f":"**The Values are Distributed over a Small Scale.**","3cd689ea":"## 1.5) Examine NaN Values","29ff107c":"<a id=\"there_you_go_2\"><\/a>\n# 2) Correlation Between Features","0e49487e":"### Color vs Price","8ff7c06f":"### Tuning Parameters","10ea5eac":"## How Diamonds are formed?\n* **Diamonds are formed deep within the Earth about 100 miles or so below the surface in the upper mantle.**\n* **Obviously in that part of the Earth it\u2019s very hot.** \n* **There\u2019s a lot of pressure, the weight of the overlying rock bearing down, so that combination of high temperature and high pressure is what\u2019s necessary to grow diamond crystals in the Earth.**","b4585e61":"## 7.4) Ridge Regression","c627f02e":"* **As the Dimensions increases, Obviously the Prices Rises as more and more Natural Resources are Utilised.**","ecedddf8":"## 3.4) Clarity\n* **Diamond Clarity refers to the absence of the Inclusions and Blemishes.**\n* **An Inclusion is an Imperfection located within a Diamond. Inclusions can be Cracks or even Small Minerals or Crystals that have formed inside the Diamond.**\n* **Blemishing is a result of utting and polishing process than the environmental conditions in which the diamond was formed. It includes scratches, extra facets etc.**\n\n[Click Here to Learn More about How Clarity Affects the Price of Diamonds.](https:\/\/www.diamondmansion.com\/blog\/understanding-how-diamond-clarity-affects-value\/)","27484c88":"![](https:\/\/i.imgur.com\/Bbf0GWk.jpg)","e93e74d4":"![](https:\/\/i.imgur.com\/6PannTm.jpg)","7256a018":"## 7.2) Lasso Regression","18ad2678":"<a id=\"there_you_go_5\"><\/a>\n# 5) Feature Encoding"}}