{"cell_type":{"a6e33b7c":"code","f715d4ae":"code","f2732a04":"code","d6022b8f":"code","55c4fc04":"code","7e770a60":"code","b9f907f0":"code","43037cbc":"code","55b192dd":"code","68a95ae0":"code","a725373a":"code","8f4bcda7":"code","dd4a4bd8":"code","d2494c73":"code","0d389847":"code","5db6c503":"code","0798ab65":"code","5ec67158":"code","9555b8ba":"markdown","2207b87c":"markdown","1daa84a5":"markdown","08576145":"markdown","0b5d9a29":"markdown","7ff5e74b":"markdown","b1d2e6bd":"markdown","d387373b":"markdown","19d150a5":"markdown","5001bcb1":"markdown","e711f636":"markdown","02129114":"markdown","69c5b50b":"markdown","62b4762b":"markdown","ae5a703a":"markdown"},"source":{"a6e33b7c":"!pip install -I vaex","f715d4ae":"# Load Libraries\nimport vaex\nvaex.multithreading.thread_count_default = 8\nimport vaex.ml\n\nimport numpy as np\nimport pylab as plt\nimport time\nfrom pathlib import Path\nimport pprint\nimport pandas\nfrom IPython.core.interactiveshell import InteractiveShell  # for printing all outputs of a cell \nInteractiveShell.ast_node_interactivity = \"all\" # to revert to original setting set InteractiveShell.ast_node_interactivity = \"last_expr\"\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f2732a04":"SMALL_SIZE = 12\nMEDIUM_SIZE = 14\nBIGGER_SIZE = 16\n\nplt.rc('font', size=SMALL_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title","d6022b8f":"# Load data using Vaex\nstart = time.time()\ndata_dir = Path('..\/input\/tabular-playground-series-nov-2021\/')\nvaex_train = vaex.read_csv(data_dir \/ \"train.csv\")\nvaex_test = vaex.read_csv(data_dir \/ \"test.csv\")\nend = time.time()\nprint(end - start)","55c4fc04":"# See the description\nvaex_train.info()","7e770a60":"# let's shuffle\nvaex_train = vaex_train.shuffle(random_state=31)","b9f907f0":"# Train and validation split, no shuffling occurs\ndf_train, df_validation = vaex_train.ml.train_test_split(test_size=0.2, verbose=False)","43037cbc":"# Inspect the target variable\ntrain_spam_value_counts = df_train.target.value_counts()\nvalidation_spam_value_counts = df_validation.target.value_counts()\n\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(121)\ntrain_spam_value_counts.plot.bar()\ntrain_spam_ratio = train_spam_value_counts[1]\/train_spam_value_counts[0]\nplt.title(f'Train set: spam ratio: {train_spam_ratio:.2f}')\nplt.ylabel('Number of Emails')\n\nplt.subplot(122)\nvalidation_spam_value_counts.plot.bar()\nvalidation_spam_ratio = validation_spam_value_counts[1]\/validation_spam_value_counts[0]\nplt.title(f'Validation set: spam ratio: {validation_spam_ratio:.2f}')\nplt.ylabel('Number of Emails')\n\nplt.tight_layout()\nplt.show()","55b192dd":"import xgboost\nimport vaex.ml.sklearn\n\nfeatures = vaex_train.column_names[1:-1] # because we want to exclude id and target columns from the training dataset\n\n# Instantiate the xgboost model normally, using the scikit-learn API\nxgb_model = xgboost.sklearn.XGBClassifier(\n#                                           max_depth=11,\n                                          learning_rate=0.1,\n#                                           n_estimators=500,\n#                                           subsample=0.75,\n#                                           colsample_bylevel=1,\n#                                           colsample_bytree=1,\n#                                           scale_pos_weight=1.5,\n                                          reg_lambda=1.5,\n                                          reg_alpha=5,\n#                                           n_jobs=8,\n                                          random_state=42,\n                                          use_label_encoder=False,\n                                          verbosity=0)\n\n# Make it work with vaex (for the automagic pipeline and lazy predictions)\nvaex_xgb_model = vaex.ml.sklearn.Predictor(features=features,\n                                           target='target',\n                                           model=xgb_model,\n                                           prediction_name='prediction_xgb')\n# Train the model\nvaex_xgb_model.fit(df_train)\n\n# Get the prediction of the model on the training data\ndf_train = vaex_xgb_model.transform(df_train)\n\n# Preview the resulting train dataframe that contans the predictions\ndf_train","68a95ae0":"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\ndef binary_metrics(y_true, y_pred):\n    acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n    f1 = f1_score(y_true=y_true, y_pred=y_pred)\n    roc = roc_auc_score(y_true=y_true, y_score=y_pred)\n    print(f'Accuracy: {acc:.3f}')\n    print(f'f1 score: {f1:.3f}')\n    print(f'roc-auc: {roc:.3f}')","a725373a":"print('Metrics for the training set:')\nbinary_metrics(y_true=df_train.target.values, y_pred=df_train.prediction_xgb.values)","8f4bcda7":"# Train the model\nvaex_xgb_model.fit(df_validation)\n\n# Get the prediction of the model on the validation data\ndf_validation = vaex_xgb_model.transform(df_validation)\n\n# Preview the resulting train dataframe that contans the predictions\ndf_validation","dd4a4bd8":"print('Metrics for the validation set:')\nbinary_metrics(y_true=df_validation.target.values, y_pred=df_validation.prediction_xgb.values)","d2494c73":"plt.figure(figsize=(6, 9))\n\nind = np.argsort(xgb_model.feature_importances_)[::-1]\nfeatures_sorted = np.array(features)[ind]\nimportances_sorted = xgb_model.feature_importances_[ind]\n\nplt.barh(y=range(len(features)), width=importances_sorted, height=0.2)\nplt.title('Gain')\nplt.yticks(ticks=range(len(features)), labels=features_sorted)\nplt.gca().invert_yaxis()\nplt.show()","0d389847":"from sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression","5db6c503":"# The Support Vector Classifier\nvaex_svc = vaex.ml.sklearn.Predictor(features=features,\n                                     target='target',\n                                     model=SVC(max_iter=1000, random_state=42),\n                                     prediction_name='prediction_svc')\n\n# Logistic Regression\nvaex_logistic = vaex.ml.sklearn.Predictor(features=features,\n                                          target='target',\n                                          model=LogisticRegression(max_iter=1000, random_state=42, solver='liblinear'),\n                                          prediction_name='prediction_lr')\n\n# Train the new models and apply the transformation to the train dataframe\nfor model in [vaex_svc, vaex_logistic]:\n    model.fit(df_train)\n    df_train = model.transform(df_train)\n\n# Preview of the train DataFrame\ndf_train.head(5)","0798ab65":"# Weighed mean of the classes\nprediction_final = (df_train.prediction_xgb.astype('int') * 0.3 +\n                    df_train.prediction_svc.astype('int') * 0.5 +\n                    df_train.prediction_xgb.astype('int') * 0.2)\n# Get the predicted class\nprediction_final = (prediction_final >= 0.5)\n\n# Add the expression to the train DataFrame\ndf_train['prediction_final'] = prediction_final\n\n# Preview\ndf_train[df_train.get_column_names(regex='^predict')]","5ec67158":"pred_columns = df_validation.get_column_names(regex='^prediction_')\nfor i in pred_columns:\n    print(i)\n    binary_metrics(y_true=df_validation.target.values, y_pred=df_validation[i].values)\n    print(' ')","9555b8ba":"# Adjusting matplotlib parmeters\n\nLet's modify some of the matplotlib default settings, just to make the plots a bit more legible.","2207b87c":"# Performance on training set\n\nlet\u2019s see what the performance is of the model on the training set. First let\u2019s create a convenience function that will help us get multiple metrics at once.","1daa84a5":"# Sanity Checks\n\nlet\u2019s verify that our train and test sets are \u201csimilar\u201d enough.\n\nLet us check the fraction of the target variable.","08576145":"# Ensemble\n\nthe predictions from the SVC and the LogisticRegression classifiers are added as virtual columns in the training dataset. This is quite powerful, since now we can easily use them to create an ensemble! For example, let\u2019s do a weighted mean.","0b5d9a29":"# Performance on validation set\n\nLet's check the model performance on the validation set.","7ff5e74b":"# References\n\n1. Thank you to Vaex Documentation for showing [how to use Vaex](https:\/\/vaex.io\/docs\/example_ml_titanic.html#).\n2. This [Stack Overflow link](https:\/\/stackoverflow.com\/questions\/65682019\/attributeerror-str-object-has-no-attribute-decode-in-fitting-logistic-regre) was used to resolve an error.","b1d2e6bd":"# Modeling (part 1): gradient boosted trees","d387373b":"Now let\u2019s check the performance of the model on the training set.","19d150a5":"# Feature importance\n\nLet\u2019s now look at the feature importance of the xgboost model.","5001bcb1":"# Modeling (part 2): Linear models & Ensembles","e711f636":"let\u2019s check the performance of all the individual models as well as on the ensembler, on the validation set","02129114":"# Problem Statement\n\nIn this competition, we predict whether or not an email is spam.\n\nWe are going to cover the following steps:\n1. Install Vaex\n2. Adjust Matplotlib Parameters\n3. Load Data\n4. Shuffling\n5. Split into Train and Validation\n6. Sanity Checks\n7. Modeling (Part 1): Gradient Boosting Trees\n8. Performance on Training Set\n9. Performance on Validation Set\n10. Feature Importance\n11. Modeling (Part 2): Linear Models and Ensembles\n12. Ensemble\n13. References\n\nLet's get started.\n\n# Install Vaex","69c5b50b":"# Split into train and Validation\n\nOnce the data is shuffled, let\u2019s split it into train and validation sets. The validation set will comprise 20% of the training data.","62b4762b":"# Load Data","ae5a703a":"# Shuffling\n\nIf required, we can shuffle the dataset."}}