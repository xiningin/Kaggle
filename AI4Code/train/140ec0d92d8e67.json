{"cell_type":{"59056883":"code","8e8b37a5":"code","10d17a69":"code","ecd0f8fc":"code","9b2133f4":"code","c8baaad6":"code","3108399c":"code","e44d2e75":"code","142cc3e1":"code","e09aff91":"code","b4729f64":"code","ec9bd458":"code","8153729b":"code","8edbe17a":"code","d8560ba8":"code","4ca8d57e":"code","f9a2fc70":"code","a70ed65f":"code","d89eb313":"code","7ede0955":"code","d6eff594":"code","b56cfdd5":"code","385cb8ee":"code","e88f3f31":"code","dd82d326":"code","361aba22":"code","cd02e9e1":"code","53eadf24":"code","1065cda3":"code","438f2d52":"code","eb0d9f17":"markdown","ae7f9536":"markdown","7157174b":"markdown","c2810b13":"markdown","e22ff9e6":"markdown","72c8e58d":"markdown","e1df203d":"markdown","1471043e":"markdown","1f3ab417":"markdown"},"source":{"59056883":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport plotly.express as px # plotting\nfrom sklearn.decomposition import PCA # Principal Component Analysis","8e8b37a5":"train = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntargets = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","10d17a69":"targets[targets.columns[1:]].sum().sort_values()[:20]","ecd0f8fc":"known_experiments = ['diuretic',\n'autotaxin_inhibitor',                           \n'protein_phosphatase_inhibitor',                 \n'antiarrhythmic',                                \n'retinoid_receptor_antagonist',                  \n'nicotinic_receptor_agonist',                    \n'atm_kinase_inhibitor',                          \n'calcineurin_inhibitor',                         \n'lxr_agonist',                                   \n'elastase_inhibitor',                            \n'steroid',                                       \n'leukotriene_inhibitor',                         \n'coagulation_factor_inhibitor',                  \n'ubiquitin_specific_protease_inhibitor',         \n'tropomyosin_receptor_kinase_inhibitor',         \n'laxative']","9b2133f4":"len(known_experiments)","c8baaad6":"\"\"\"\nCode by @namanj27 from CatBoost MoA [EDA | Starter] \n\nhttps:\/\/www.kaggle.com\/namanj27\/catboost-moa-eda-starter\n\"\"\"\n\ntrain_n = pd.merge(train, targets, on='sig_id')\n\nX_train = []\nX_train_columns = train_n.columns\n\nfor v in train_n.values:\n    info = v[:876]\n    binary = v[876:]\n    index = [k for k, i in enumerate(binary) if i==1]\n    \n    for i in index:\n        for k in range(len(binary)):\n            if k==i:\n                X_train.append(list(info) + [X_train_columns[876+k]])\n\nX_train = pd.DataFrame(X_train, columns=train.columns.tolist() + ['pred'])","3108399c":"X_train","e44d2e75":"X_train['Known_Experiment'] = 'No'","142cc3e1":"# If its in known experiment then add the target to 'experiment'\nfor i, row in X_train.iterrows():\n    if row['pred'] in known_experiments:\n        X_train.loc[i, 'Known_Experiment'] = row['pred']","e09aff91":"only_known_experiments = X_train[X_train['pred'].isin(known_experiments)]\nonly_known_experiments","b4729f64":"# Each of the targets have 6 unique ids that are the product of the cp_time, cp_dose and cp_type\nonly_known_experiments.groupby('pred').nunique()[['sig_id', 'cp_type', 'cp_time', 'cp_dose']]","ec9bd458":"X_train","8153729b":"pca = PCA(n_components=50)\nresults = pca.fit_transform(X_train[X_train.columns[4:-2]])","8edbe17a":"fig = px.scatter_3d(x=results[:, 0],\n                    y=results[:, 1],\n                    z=results[:, 2],\n                    opacity=0.4,\n                    title=\"PCA Plot of Known Experiment Targets and All\",\n                    color=X_train['Known_Experiment'])\nfig.show()","d8560ba8":"only_exp_idx = X_train.index[X_train['Known_Experiment'] != \"No\"]","4ca8d57e":"fig = px.scatter_3d(x=results[only_exp_idx, 0],\n                    y=results[only_exp_idx, 1],\n                    z=results[only_exp_idx, 2],\n                    opacity=0.8,\n                    title=\"PCA Plot of Known Experiment Targets Only\",\n                    color=X_train.loc[only_exp_idx, 'Known_Experiment'])\nfig.show()","f9a2fc70":"sig_id_testing = only_known_experiments[['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'pred']].reset_index()\ndel sig_id_testing['index']\nsig_id_testing","a70ed65f":"sig_id_testing['sig_id'] = sig_id_testing['sig_id'].apply(lambda x: x[3:]) # Removing id_","d89eb313":"letter_cols = [\"Letter \"+str(i+1) for i in range(9)]\nletter_cols","7ede0955":"individual_letters = sig_id_testing.sig_id.str.split(\"\",expand=True)\ndel individual_letters[0], individual_letters[10] # Remove spaces\nindividual_letters.columns = letter_cols\nindividual_letters","d6eff594":"# Combination of 2 letters (forward pass)\nfor i in range(8):\n    individual_letters['Letter '+str(i+1)+'+'+'Letter '+str(i+2)] = individual_letters['Letter '+str(i+1)] + individual_letters['Letter '+str(i+2)] ","b56cfdd5":"# Combination of 3 letters (forward pass)\nfor i in range(7):\n    individual_letters['Letter '+str(i+1)+'+'+'Letter '+str(i+2)+'+'+'Letter '+str(i+3)] = individual_letters['Letter '+str(i+1)] + individual_letters['Letter '+str(i+2)] + individual_letters['Letter '+str(i+3)] ","385cb8ee":"# Combination of 4 letters (forward pass)\nfor i in range(6):\n    individual_letters['Letter '+str(i+1)+'+'+'Letter '+str(i+2)+'+'+'Letter '+str(i+3)+'+'+'Letter '+str(i+4)] = individual_letters['Letter '+str(i+1)] + individual_letters['Letter '+str(i+2)] + individual_letters['Letter '+str(i+3)] + individual_letters['Letter '+str(i+4)] ","e88f3f31":"individual_letters","dd82d326":"sig_id_testing = pd.concat([sig_id_testing, individual_letters], axis=1).reset_index()","361aba22":"del sig_id_testing['index']\nsig_id_testing","cd02e9e1":"categorical_ = sig_id_testing.copy()\n\nfor column in categorical_.columns[1:]:\n    categorical_[column] = categorical_[column].astype('category').cat.codes","53eadf24":"categorical_","1065cda3":"corr = categorical_[categorical_.columns[2:]].corr()\ncorr[['cp_time', 'cp_dose', 'pred']].style.background_gradient(cmap='coolwarm').set_precision(2)","438f2d52":"# There are 4\/5\/6 unique letters for each prediction so this doesnt really help isolate anything\n# Using the sig_id to cluster 6 at a time may not help either\n\nsig_id_testing[['Letter 4', 'pred']].groupby('pred').agg(['nunique'])","eb0d9f17":"Clustering 6 sig_id's at a time using K-means or other algorithms may not be so useful","ae7f9536":"# Extracting Targets with Unique Experiments","7157174b":"# Preprocessing","c2810b13":"Letter 4 and prediction show the most promising correlation","e22ff9e6":"I was unable to find a link between targets\/sig_id to get experiment_id - maybe you will have better luck","72c8e58d":"# Examining sig_id","e1df203d":"Based on discussions [here](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/190772) we know that each experiment has 6 sig_ids (2 cp_dose * 3 cp_time).\n\nIf we check the target columns we can look for targets that only activate for a given experiment, therefore they would only activate 6 times and must have equal number of cp_dose and cp_time across all targets","1471043e":"# File Imports","1f3ab417":"# Visualizations"}}