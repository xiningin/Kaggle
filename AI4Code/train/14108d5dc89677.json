{"cell_type":{"702064f5":"code","88bb8d24":"code","1edb41e9":"code","1dddec7d":"code","fd048906":"code","9e5db8a4":"code","6b10ce63":"code","d7dc0971":"code","92a2b1a8":"code","57c59279":"code","e8640339":"code","5e59d16a":"code","e61ddf42":"code","9497d51c":"code","7103d42c":"code","78c8e9ec":"code","b7db3100":"code","59324dec":"code","ea9e83d6":"code","0ea2dda1":"code","719a266c":"code","d0d3fd38":"code","89d6aed8":"code","ff9313aa":"code","4938abc2":"code","2ba9a44b":"code","1d0fb3ee":"code","aeb49dbc":"code","c3d621d9":"code","4c5c02af":"code","edbb335b":"code","5485443c":"code","3ede92bb":"code","a38d5109":"code","945d6ac9":"code","3d955e9d":"code","1ecc3ecd":"code","e7960c41":"code","a70d6fc2":"code","d179a4ed":"code","816d54f9":"markdown","d6b9c078":"markdown","5873b022":"markdown","ec64f7c1":"markdown","d420d62a":"markdown","119188a9":"markdown","93864976":"markdown","e92a588c":"markdown","7ad9ba7f":"markdown","ac1d9c56":"markdown","ce07dd11":"markdown","73f99326":"markdown","e7bc604f":"markdown","fb42fd58":"markdown","cfddad79":"markdown","9ec66f14":"markdown","628df3ce":"markdown","04e5ddd2":"markdown","9e2c12d9":"markdown","e4ce0ed3":"markdown","6a1e855c":"markdown","0dce9f21":"markdown","fdd0ecce":"markdown","ff862029":"markdown","da3471a3":"markdown","ca7f942e":"markdown"},"source":{"702064f5":"# importing libraries\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\n\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV","88bb8d24":"face_cascade = cv2.CascadeClassifier('..\/input\/famous-personalities-image-dataset\/haarcascade_frontalface_default.xml')","1edb41e9":"# returns an array if the image contains more than one faces\ndef get_cropped_image_if_2_eyes(image_path):\n    img = cv2.imread(image_path)\n    roi=[] \n    if img is not None:\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n        \n        for (x,y,w,h) in faces:\n            roi_gray = gray[y:y+h, x:x+w]\n            roi_color = img[y:y+h, x:x+w]\n            roi.append(roi_color)\n    return roi","1dddec7d":"# reading an image\nx='..\/input\/famous-personalities-image-dataset\/Dataset\/Dataset\/Melinda_Gates\/2Q__ (10).jpg'\noriginal_image=cv2.imread(x)\nplt.imshow(original_image)","fd048906":"#cropping the face from the image\n\ncropped_image=get_cropped_image_if_2_eyes(x)\nfor i in range(len(cropped_image)):\n    plt.imshow(cropped_image[i])\n    \n","9e5db8a4":"path_to_data = \"..\/input\/famous-personalities-image-dataset\/Dataset\/Dataset\"\npath_to_cr_data = \"..\/input\/famous-personalities-image-dataset\/cropped\/cropped\"","6b10ce63":"# dataset folder contains folders of different personalities which are containing raw images\nimport os\nimg_dirs = []\nfor entry in os.scandir(path_to_cr_data):\n    if entry.is_dir():\n        img_dirs.append(entry.path)\n        \nimg_dirs","d7dc0971":"# Uncomment the code if you want to generate cropped images\n\n# # creating a cropped folder to store cropped face images\n# import shutil\n# #  if folder \"cropped\" exists remove it\n# if os.path.exists(path_to_cr_data):\n#      shutil.rmtree(path_to_cr_data)\n# # create folder\n# os.mkdir(path_to_cr_data)","92a2b1a8":"# Uncomment the code if you want to generate cropped images\n\n\n# cropped_image_dirs = []\n# celebrity_file_names_dict = {}\n# for img_dir in img_dirs:\n#     count = 1\n#     celebrity_name = img_dir.split('\/')[-1]\n#     print(celebrity_name)\n#     celebrity_file_names_dict[celebrity_name] = []\n    \n#     for entry in os.scandir(img_dir):\n# #         print(entry)\n#         roi_color = get_cropped_image_if_2_eyes(entry.path)\n#         if len(roi_color)!=0:\n#             for i in range(len(roi_color)):\n#                 cropped_folder = path_to_cr_data + celebrity_name\n#                 if not os.path.exists(cropped_folder):\n#                     os.makedirs(cropped_folder)\n#                     cropped_image_dirs.append(cropped_folder)\n#                     print(\"Generating cropped images in folder: \",cropped_folder)\n#                 cropped_file_name = celebrity_name + str(count) + \".png\"\n                \n#                 cropped_file_path = cropped_folder + \"\/\" + cropped_file_name\n#                 cv2.imwrite(cropped_file_path, roi_color[i])\n#                 celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n#                 count +=1","57c59279":"img_dirs","e8640339":"# Generating wavelet images for fitting into SVM and Logistic Regression models.\n\nimport numpy as np\nimport pywt\nimport cv2\n\ndef w2d(img,mode='haar',level=1):\n    imArray=img\n    #Data-type conversion\n    #convert to grayscale\n    imArray=cv2.cvtColor(imArray,cv2.COLOR_RGB2GRAY)\n    #convert to float\n    imArray=np.float32(imArray)\n    imArray\/=255\n    #computeCoefficients\n    coeffs=pywt.wavedec2(imArray,mode,level=level)\n    \n    #process Coefficients\n    coeffs_H=list(coeffs)\n    coeffs_H[0]*=0\n    \n    #reconstruction\n    imArray_H=pywt.waverec2(coeffs_H,mode)\n    imArray_H*=255\n    imArray_H=np.uint8(imArray_H)\n    \n    return imArray_H\n","5e59d16a":"celebrity_file_names_dict2={}\nfor img_dir in img_dirs:\n#     print(img_dir)\n    celebrity_name = img_dir.split('\/')[-1]\n#     print(celebrity_name)\n    file_list = []\n    for entry in os.scandir(img_dir):\n        file_list.append(entry.path)\n    celebrity_file_names_dict2[celebrity_name] = file_list\n# celebrity_file_names_dict2","e61ddf42":"class_dict2 = {}\ncount = 0\nfor celebrity_name in celebrity_file_names_dict2.keys():\n    class_dict2[celebrity_name] = count\n    count = count + 1\nclass_dict2","9497d51c":"# inverse dictionary\ninv_dict2 = dict(zip(class_dict2.values(), class_dict2.keys())) \ninv_dict2","7103d42c":"X, y = [], []\nfor celebrity_name, training_files in celebrity_file_names_dict2.items():\n    for training_image in training_files:\n        img = cv2.imread(training_image)\n        if img is not None:\n            scalled_raw_img = cv2.resize(img, (32, 32))\n            img_har = w2d(img,'db1',5)\n            scalled_img_har = cv2.resize(img_har, (32, 32))\n            combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n            X.append(combined_img)\n            y.append(class_dict2[celebrity_name])","78c8e9ec":"# we have total 2716 images to fit into model\nlen(X)","b7db3100":"# reshaping to 32*32*2 size\nX = np.array(X).reshape(len(X),4096).astype(float)\nX.shape","59324dec":"# fitting into SVM classfier with rbf kernel\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\npipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","ea9e83d6":"print(classification_report(y_test, pipe.predict(X_test)))","0ea2dda1":"model_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto',probability=True),\n        'params' : {\n            'svc__C': [1,10,100],\n            'svc__kernel': ['rbf','linear']\n        }  \n    },\n    \n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'logisticregression__C': [1,5,10]\n        }\n    }\n}","719a266c":"scores = []\nbest_estimators = {}\nimport pandas as pd\nfor algo, mp in model_params.items():\n    pipe = make_pipeline(StandardScaler(), mp['model'])\n    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n    clf.fit(X_train, y_train)\n    scores.append({\n        'model': algo,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    best_estimators[algo] = clf.best_estimator_\n    \ndf = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf","d0d3fd38":"best_estimators['svm'].score(X_test,y_test)","89d6aed8":"best_estimators['logistic_regression'].score(X_test,y_test)","ff9313aa":"best_clf = best_estimators['svm']","4938abc2":"best_clf","2ba9a44b":"print(classification_report(y_test, best_clf.predict(X_test)))","1d0fb3ee":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, best_clf.predict(X_test))\ncm","aeb49dbc":"import seaborn as sn\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","c3d621d9":"X, y = [], []\nfor celebrity_name, training_files in celebrity_file_names_dict2.items():\n    for training_image in training_files:\n        img = cv2.imread(training_image)\n#         if img is not None:\n        scalled_raw_img = cv2.resize(img, (32, 32))\n#         img_har = w2d(img,'db1',5)\n#         scalled_img_har = cv2.resize(img_har, (32, 32))\n#         combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n        X.append(scalled_raw_img)\n        y.append(class_dict2[celebrity_name])","4c5c02af":"len(X)","edbb335b":"X[0]","5485443c":"len(X[0])","3ede92bb":"X = np.array(X).reshape(len(X),32,32,3).astype(float)\nX.shape","a38d5109":"y = np.array(y).reshape(-1).astype(float)\ny.shape","945d6ac9":"X=X\/255.0\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=0)","3d955e9d":"cnn = models.Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\ncnn.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\ncnn.fit(X_train, y_train, epochs=40)","1ecc3ecd":"y_pred = cnn.predict(X_test)\ny_pred_classes = [np.argmax(element) for element in y_pred]\n\nprint(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))","e7960c41":"# cnn.save(\"my_model.h5\") #using h5 extension\n# print(\"model saved!!!\")","a70d6fc2":"# import json\n# with open(\"class_dictionary.json\",\"w\") as f:\n#     f.write(json.dumps(class_dict2))","d179a4ed":"# from keras.models import load_model\n\n# model = load_model('my_model.h5')\n# model.summary()","816d54f9":"## Run the next two cell only if you want to generate cropped images but for now I have already generated them and stored in the \"cropped\" folder.","d6b9c078":"### Plotting the confusion matrix","5873b022":"## 6.Conclusion","ec64f7c1":"### Note-The cell below will take around 1.5 hour to run.","d420d62a":"### Fitting data on CNN model","119188a9":"## 2.Load and Manipulate Data","93864976":"## 4. Model fitting and selection\n","e92a588c":"# FAMOUS PERSONALITIES IMAGE CLASSIFIER","7ad9ba7f":"### Using GridSearchCV to generate the best model","ac1d9c56":"### Classifying using Convolutional Neural Networks(CNN)","ce07dd11":"## Introduction\n\n### In this project we are going to build an image classifier for 10 of world's famous personalities which are listed below.\n#### 1.Anushka Sharma (Actress-India)\n#### 2.Barack Obama (Former USA President)\n#### 3.Bill Gates (Philanthropist)\n#### 4.Dalai Lama (Spiritual Leader)\n#### 5.Indira Nooyi (CEO-Pepsico)\n#### 6.Melinda Gates (Philanthropist)\n#### 7.Narendra Modi (Prime Minister of India)\n#### 8.Sundar Pichai (CEO-Google)\n#### 9.Vikas Khanna (Celebrity Chef)\n#### 10.Virat Kohli (Cricketer)\n### We will use various machine learning and deep learning techniques like SVM,Logistic Regression,Convolutional Neural Networks(CNN) to build our model.\n\n### The dataset is manually downloaded from different sites like Google Images,Getty Images,Shutterstock etc.","73f99326":"### Dictionary to store classes of different personalities.","e7bc604f":"### We got a 91% test case accuracy for SVM model and 94% for CNN model. Hence it again proved that when it comes to image classification CNN works best.\n### Now we will deploy the model and create a UI interface to classfiy the images.","fb42fd58":"## 3. Data Preparation for the Model fitting","cfddad79":"### We can see that test data accuracy using CNN is coming to be 94% which is highest among all our models.Hence finalizing this as the final model for our image classification.","9ec66f14":"### Best Model till now is SVM with 91% test data accuracy.","628df3ce":"## 5. Saving the Model","04e5ddd2":"### Generating and renaming cropped images","9e2c12d9":"<img align=\"left\" width=\"500\" height=\"400\" src=\"https:\/\/drive.google.com\/uc?export=view&id=1DS32nPNsNJT2S7TM2BrwGF7sxCZK2gfC\">","e4ce0ed3":"### Overview of Notebook\n#### 1.Exploratory Image Analysis\u00b6\n#### 2.Load and Manipulate Data\n#### 3. Data Preparation for the Model fitting\n#### 4. Model fitting and selection\n#### 5. Saving the Model    \n#### 6. Conclusion.\n\n### Github Link for this Project \n### https:\/\/github.com\/tanish265\/Famous-Personalities-Image-Classifier","6a1e855c":"### Using Opencv haarcascade to recognize face in an image.","0dce9f21":"### Creating a vertical stack of raw image and wavelet function generated image and storing in input variable X.","fdd0ecce":"## 1. Exploratory Image Analysis","ff862029":"### Storing cropped images names in a dictionary.","da3471a3":"### Function for getting cropped faces from an image.","ca7f942e":"### Changing shape of the input variable array to fit for CNN which requires 4 dimensional array"}}