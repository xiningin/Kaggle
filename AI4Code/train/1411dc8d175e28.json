{"cell_type":{"9219ecf9":"code","25d2e81f":"code","69ffcc70":"code","23684188":"code","b25ef0d6":"code","1a433087":"code","e31dbf88":"code","dc9aaa88":"code","f8e13beb":"code","0b6db5e8":"code","e2806bfd":"code","8d5530b1":"code","e1263ce7":"code","b7834c00":"code","4796ccbf":"code","6039f677":"code","ea70ab7e":"markdown","50e85d28":"markdown","4e63b1ed":"markdown","9171a27c":"markdown","47e220e6":"markdown","79b06225":"markdown","b275a1f0":"markdown","e0fa3dec":"markdown","d36fa155":"markdown","5bd8df4a":"markdown","090be69f":"markdown","3dac2da2":"markdown","3eb17f8a":"markdown","30ca3981":"markdown","2687bfed":"markdown","435a40ad":"markdown","4be023bb":"markdown"},"source":{"9219ecf9":"import os\nimport warnings \nwarnings.filterwarnings('ignore') #ignoring unwanted warnings\n\n#Reading file\nimport h5py\nfile = h5py.File('..\/input\/classification-of-handwritten-letters\/LetterColorImages_123.h5')\n\n#Finding columns\ncolumns = list(file.keys())\nprint(columns)","25d2e81f":"import numpy as np\nimport pandas as pd\n\n#Data-preprocessing\nbackground = np.array(file[columns[0]])\nlabels = np.array(file[columns[2]])\nimg = np.array(file[columns[1]])\n\nimg_rows,img_cols = 32,32\nnum_images = len(file[columns[1]])\nimages = img.reshape(num_images,img_rows,img_cols,3)\nimages = images\/255","69ffcc70":"#Visualising the letter\nimport pylab as pl\npl.figure(figsize=(3,3))\nvar = 400\npl.title('Label:%s'%labels[var]+' Background:%s'%background[var])\npl.imshow(images[var])\npl.show()","23684188":"from tensorflow import keras\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nnum_labels = 33 #33 alphabets in russian language\n\ny = OneHotEncoder(categories='auto').fit_transform(labels.reshape(-1,1)).toarray().astype('int64')  #reshape(-1,1) changes horizontal vector to vertical vector\nx = images\nX_train,X_val,y_train,y_val = train_test_split(x,y,test_size=0.2,stratify=y,random_state=42)","b25ef0d6":"#Building model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,Dense,Flatten,Dropout,MaxPooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n\nhand_model = Sequential()\n\n#Input layers\nhand_model.add(Conv2D(32, kernel_size = (3, 3),\n                     activation = 'relu',\n                     input_shape = (32,32,3)))\nhand_model.add(Conv2D(64, (3, 3), activation = 'relu'))\nhand_model.add(Conv2D(128, (4, 4), activation = 'relu'))\nhand_model.add(MaxPooling2D(pool_size = (2, 2)))\nhand_model.add(Dropout(0.25))\nhand_model.add(Flatten())\nhand_model.add(Dense(128, activation = 'relu'))\nhand_model.add(Dropout(0.25))\n\n#Output layer\nhand_model.add(Dense(num_labels,activation='softmax'))","1a433087":"#Compiling model:\nhand_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n#call-backs:\nbest_weights = ModelCheckpoint(filepath='best_weights.hdf5',verbose=2,save_best_only=True)\nreducing_LR = ReduceLROnPlateau(monitor='val_loss',patience=10,verbose=2,factor=0.75)\nstopping = EarlyStopping(monitor='val_loss',patience=20,verbose=2)","e31dbf88":"#fit the model\nmodel_history = hand_model.fit(X_train,y_train,batch_size=64,epochs=100,\n                               verbose=1,validation_data=(X_val,y_val),\n                               callbacks=[best_weights,reducing_LR,stopping])","dc9aaa88":"import matplotlib.pyplot as plt\n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'])\nplt.show()","f8e13beb":"plt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'])\nplt.show()","0b6db5e8":"hand_model.load_weights('best_weights.hdf5')\nhand_model.evaluate(X_val,y_val)","e2806bfd":"# Read and display images\nimport matplotlib.pyplot as plt\nimport glob\nimport imageio\nimport cv2\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\ndef import_data(path,csv_file):\n    data = pd.read_csv(path + csv_file)\n    data['source'] = csv_file[:-4] + '\/'\n    return data\n\n#Creating a Dataframe:\npath = '..\/input\/classification-of-handwritten-letters\/'\ncsv_files = ['letters.csv','letters2.csv','letters3.csv']\ndata1 = import_data(path,csv_files[0])\ndata2 = import_data(path,csv_files[1])\ndata3 = import_data(path,csv_files[2])\ndata = pd.concat([data1,data2,data3],ignore_index=True)\n\n\ndel(data1,data2,data3)","8d5530b1":"data.tail()","e1263ce7":"#All letters in russian:\nall_letters = ''\nfor i in data.letter.unique():\n    all_letters += i\nprint(all_letters)","b7834c00":"#Preprocess image:\ndef to_img(filename):\n    img = load_img(filename,target_size=(32,32))\n    img = img_to_array(img)\n    img = img.reshape(1,32,32,3)\n    img = img.astype('float32')\n    img = img\/255.0\n    return img\n\ndef actual_value(filename,df,column_name):\n    file = os.path.basename(os.path.normpath(filename))\n    index_row = df[df['file']==file].index[0]\n    return df.loc[index_row,column_name]","4796ccbf":"test_img = to_img(path+'letters3\/09_236.png')\npredicted_letter = hand_model.predict_classes(test_img)\nplt.imshow(test_img[0])\nprint('predicted:',all_letters[predicted_letter[0]])\nprint('actual:',actual_value(path+'letters3\/09_236.png',data,'letter'))","6039f677":"my_path = '..\/input\/myhandwritten-letters\/'\ntest_img = to_img(my_path+'IMG-8461.jpg')\npredicted_letter = hand_model.predict_classes(test_img)\nplt.imshow(test_img[0])\nprint('predicted:',all_letters[predicted_letter[0]])\nprint('actual:k')","ea70ab7e":"# Recognizing Handwritten Russian Letters with CNN\n","50e85d28":"***If you like my notebook please do upvote :)***\n","4e63b1ed":"**Creating methods for converting image and finding actual label**","9171a27c":"**Evaluating Model Performance**","47e220e6":"**Contents:**\n* Reading the dataset\n* Data-preprocessing\n* Visualization\n* One-hot Encoding and Train-Val Split\n* Building CNN model\n* Evaluating Model performance\n* DataFrame creation\n* Testing model with random images","79b06225":"# **One-hot Encoding target variable and Train-Validation split**","b275a1f0":"*Storing Russian letters in a string*","e0fa3dec":"**Resulting DataFrame**","d36fa155":"# ***Testing model with my own handwritting***","5bd8df4a":"# **Visualization**","090be69f":"# **Building our own CNN model**\n> **Dropouts:** It is used to speed up model and prevent overfitting of data \n> \n> **MaxPooling2D:** It downsamples the input representation by taking the maximum value over the window(pool_size)","3dac2da2":"# **Testing our model with random image from dataset**","3eb17f8a":"# **Reading the dataset**","30ca3981":"# **Data preprocessing**","2687bfed":"# **Best weights performance on Validation data**","435a40ad":"***Please be free to edit this notebook and try out your own ideas***","4be023bb":"**Creating a Dataframe for valuation**"}}