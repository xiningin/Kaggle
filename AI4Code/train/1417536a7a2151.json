{"cell_type":{"dc6d04c4":"code","e2ccbaaa":"code","d75088b6":"code","dc9446e5":"code","042a2590":"code","16be5854":"code","2f4fc076":"code","14221759":"code","0aedb765":"code","35e4bae1":"code","b3135496":"code","89bcbcb1":"code","7e3ff084":"code","503619e9":"code","85309866":"code","fda89b4f":"code","179e0fd9":"code","7fc910f4":"code","5886d9f7":"code","8c41caed":"code","57523a05":"code","f28aaa38":"code","89f9bd1c":"code","fc91fdc5":"code","51a5563e":"code","54ad244e":"code","64f2936b":"code","df28ae97":"code","212cc414":"code","564f4269":"code","2a7f3e9f":"code","928a6636":"code","abaa8fb9":"markdown"},"source":{"dc6d04c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e2ccbaaa":"submission = pd.read_csv('\/kaggle\/input\/widsdatathon2021\/SolutionTemplateWiDS2021.csv')","d75088b6":"training_data = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\ntraining_data.head()","dc9446e5":"training_data = training_data[training_data['age']>=16]","042a2590":"test_data = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")","16be5854":"submission['encounter_id'] = test_data['encounter_id']","2f4fc076":"list(training_data.columns)","14221759":"len(training_data['readmission_status'].unique())","0aedb765":"training_data = training_data.drop(['Unnamed: 0','encounter_id'],axis = 1)\ntest_data = test_data.drop(['Unnamed: 0','encounter_id'],axis = 1)","35e4bae1":"import seaborn as sns\nimport matplotlib.pyplot as plt","b3135496":"from scipy.stats import norm","89bcbcb1":"training_data = training_data.fillna(training_data.mean())\ntest_data = test_data.fillna(test_data.mean())","7e3ff084":"object_columns = []\ndrop_columns = []\ndouble_val_columns = []\nfor col in training_data.columns:\n    if training_data[col].dtype in ['object']:\n        object_columns.append(col)\n        continue\n    if len(training_data[col].unique()) == 1:\n        drop_columns.append(col)\n        continue\n    if len(training_data[col].unique()) == 2:\n        double_val_columns.append(col)\n        continue\n    plt.figure()\n    sns.distplot(training_data[col],fit = norm, kde = False)\n    plt.figure()\n    sns.distplot(test_data[col],fit = norm,kde = False)","503619e9":"print(object_columns)\nprint(drop_columns)\nprint(double_val_columns)","85309866":"object_columns = object_columns + ['apache_2_diagnosis','apache_3j_diagnosis']\ndrop_columns = drop_columns + ['hospital_id','icu_id']","fda89b4f":"training_data[object_columns] = training_data[object_columns].fillna(\"\")\ntest_data[object_columns] = test_data[object_columns].fillna(\"\")","179e0fd9":"def prepare_data(train_data,test_data):\n    for col in object_columns+double_val_columns:\n        if col == 'diabetes_mellitus':\n            continue\n        vals = list(train_data[col].unique())\n        for val in vals:\n            train_data[col+'_'+str(val)] = train_data[col].apply(lambda x: (x==val)*1.0)\n            test_data[col+'_'+str(val)] = test_data[col].apply(lambda x: (x==val)*1.0)\n        train_data = train_data.drop(col,axis = 1)\n        test_data = test_data.drop(col,axis = 1)\n    train_data = train_data.drop(drop_columns,axis = 1)\n    test_data = test_data.drop(drop_columns,axis = 1)\n    return train_data,test_data","7fc910f4":"training_data,test_data = prepare_data(training_data,test_data)","5886d9f7":"print(training_data.shape)\nprint(test_data.shape)","8c41caed":"cols = list(training_data.columns)\nmax_cols = []\nmin_cols = []\nfor col in cols:\n    if '_max' in col:\n        max_cols.append(col)\n    if '_min' in col:\n        min_cols.append(col)","57523a05":"def divide_spec(x,y):\n    if y!=0: return x\/y\n    return 0","f28aaa38":"max_cols[0][:-4]","89f9bd1c":"for i in range(len(max_cols)):\n    training_data[max_cols[i][:-4]+'_ratio'] = training_data.apply(lambda x: divide_spec(x[min_cols[i]],x[max_cols[i]]),axis = 1)\n    test_data[max_cols[i][:-4]+'_ratio'] = test_data.apply(lambda x: divide_spec(x[min_cols[i]],x[max_cols[i]]),axis = 1)\n    training_data[max_cols[i][:-4]+'_diff'] = training_data.apply(lambda x: x[min_cols[i]]-x[max_cols[i]],axis = 1)\n    test_data[max_cols[i][:-4]+'_diff'] = test_data.apply(lambda x: x[min_cols[i]]-x[max_cols[i]],axis = 1)\n    ","fc91fdc5":"'diabetes_mellitus' in training_data.columns","51a5563e":"from sklearn.model_selection import train_test_split as tts\nY = training_data['diabetes_mellitus']\nX = training_data.drop('diabetes_mellitus',axis = 1)\nX_datatrain,X_datatest,Y_datatrain,Y_datatest = tts(X,Y,test_size = 0.2,random_state = 42)","54ad244e":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report as clr\nxgreg = XGBClassifier(learning_rate = 0.025,\n                      n_estimators = 4000,\n                      sampling_method = 'gradient_based',\n                      max_depth = 4,\n                      scale_pos_weight = 2,\n                      alpha = 10,\n                      reg_lambda = 5,\n                      subsample = 0.75,\n                      colsample_bytree = 0.5,\n                      colsample_bynode = 0.8,\n                      colsample_bylevel = 0.8,\n                      tree_method = 'gpu_hist')\neval_set = [(X_datatrain, Y_datatrain), (X_datatest, Y_datatest)]\nxgreg.fit(X_datatrain,Y_datatrain,eval_metric = ['auc'],eval_set = eval_set,\n          early_stopping_rounds = 100)\npred_train = xgreg.predict(X_datatrain)\npred_test = xgreg.predict(X_datatest)\nprint(clr(Y_datatrain,pred_train))\nprint(clr(Y_datatest,pred_test))","64f2936b":"from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\nmodel_basic = CatBoostClassifier(verbose=False,\n                                 learning_rate=0.1, \n                                 depth = 5,\n                                 task_type=\"GPU\",\n                                 iterations=1500)\nmodel_basic.fit(X_datatrain,Y_datatrain, plot=True,silent=True)\nprint(model_basic.get_best_score())\npred_train = model_basic.predict(X_datatrain)\npred_test = model_basic.predict(X_datatest)\nprint(clr(Y_datatrain,pred_train))\nprint(clr(Y_datatest,pred_test))","df28ae97":"df = pd.DataFrame(model_basic.predict_proba(X_datatest))","212cc414":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(Y_datatrain,df[0].tolist())\n#calculate the g-mean for each threshold\ngmeans = np.sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\nprint(fpr,tpr,thresholds)\nprint(ix)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n# plot the roc curve for the model\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, marker='.', label='Logistic')\nplt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n# show the plot\nplt.show()","564f4269":"df['prediction'] = df[0].apply(lambda x: (x<0.70)*1.0)\nprint(clr(Y_datatest,df['prediction'].tolist()))","2a7f3e9f":"#df = pd.DataFrame(xgreg.predict_proba(test_data[actual_cols]))\n#df['prediction'] = df[0].apply(lambda x:(x<=0.7)*1)\n#submission['diabetes_mellitus'] = df['prediction'].tolist()\n#submission.to_csv('original_submission_70.csv',index = False)","928a6636":"df = pd.DataFrame(model_basic.predict_proba(test_data))\ndf['prediction'] = df[0].apply(lambda x:(x<=0.7)*1)\nsubmission['diabetes_mellitus'] = df['prediction'].tolist()\nsubmission.to_csv('catboost_submission_70.csv',index = False)","abaa8fb9":"https:\/\/machinelearningmastery.com\/threshold-moving-for-imbalanced-classification\/<br\/>\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.roc_curve.html<br\/>\nhttps:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html<br\/>\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2020\/discussion\/133189<br\/>\nhttps:\/\/www.kaggle.com\/danofer\/wids21-adversarial-validation<br\/>"}}