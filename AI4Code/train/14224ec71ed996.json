{"cell_type":{"37a4d7f1":"code","935692e5":"code","b6f64d9d":"code","447a85ae":"code","7a4493a8":"code","4e2a3426":"code","355aed96":"code","715d0476":"code","22a135ce":"code","c9a8d2ce":"code","d092f10d":"code","46603f56":"code","ff2968d2":"code","1f4faacf":"code","849cade2":"code","c0b34dad":"code","cb95ad53":"markdown","7d4c9fa0":"markdown","7f869ffd":"markdown","b297feed":"markdown","092fe321":"markdown"},"source":{"37a4d7f1":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\nfrom sklearn.model_selection import train_test_split","935692e5":"# The data needs to be split into a training set and a test set\n# To use 80\/20, set the training size to .8\ntraining_set_size_portion = .8\n\n# Keep track of the accuracy score\naccuracy_score = 0\n# The DNN has hidden units, set the spec for them here, you can change these to see if accuracy increases\n# But simpler networks are easy to train and converge, so try making units in each layer smaller, there will be\n# very little trade-off in accuracy\nhidden_units_spec = [10,20,10]\nn_classes_spec = 2\nsteps_spec = 2000\nepochs_spec = 15\n\nfile_name = \"..\/input\/wdbc.csv\"\n# Define the temp directory for keeping the model and checkpoints\ntmp_dir_spec = \"tmp\/model\"\n\n# Taking only 2 features as of now, can see if any feature cross works after analysing data\nfeatures = ['radius','texture']\n\n# Here's the label that we want to predict -- it's also a column in the CSV\nlabels = ['diagnosis_numeric']\n\ndata = pd.read_csv(file_name, low_memory=False, delimiter=',')","b6f64d9d":"data.describe()","447a85ae":"randomized_data = data.reindex(np.random.permutation(data.index))\ntraining_data, test_data = train_test_split(randomized_data, test_size=0.2, random_state=42)","7a4493a8":"training_data.describe()","4e2a3426":"test_data.describe()","355aed96":"training_features = training_data[features].copy()\ntraining_labels = training_data[labels].copy()\n\ntest_features = test_data[features].copy()\ntest_labels = test_data[labels].copy()","715d0476":"feature_columns = [tf.feature_column.numeric_column(key) for key in features]","22a135ce":"classifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns, \n    hidden_units=hidden_units_spec, \n    n_classes=n_classes_spec, \n    model_dir=tmp_dir_spec)","c9a8d2ce":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key, value in dict(features).items()}                                           \n    \n    # Construct a dataset, and configure batching\/repeating.\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified.\n    if shuffle:\n      ds = ds.shuffle(buffer_size=10000)\n    \n    # Return the next batch of data.\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","d092f10d":"# Train the model using the classifer.\nclassifier.train(input_fn=lambda: my_input_fn(training_features, training_labels, batch_size=10), steps=steps_spec)","46603f56":"accuracy_score = classifier.evaluate(input_fn=lambda: my_input_fn(test_features, test_labels, num_epochs=1, shuffle=False))[\"accuracy\"]\nprint(\"Accuracy = {}\".format(accuracy_score))","ff2968d2":"prediction_set = pd.DataFrame({'radius':[14, 13], 'texture':[25, 26]})","1f4faacf":"predict_input_fn = tf.estimator.inputs.pandas_input_fn(x=prediction_set, num_epochs=1, shuffle=False)","849cade2":"predictions = list(classifier.predict(input_fn=predict_input_fn))","c0b34dad":"predicted_classes = [p[\"classes\"] for p in predictions] \nresults=np.concatenate(predicted_classes) \nprint(results)","cb95ad53":"## Implementing a neural net for tabular data of breast cancer features with binary classification - Weekend Project","7d4c9fa0":"## Step 2: Exploring feature data\n\n### Looking at distribution of feature space and see if any have anomalies and outliers (for example max value being too big compared to 75th percentile value)\nTODO: Add correlation matrix, scatterplot of features we are picking, try with other features too","7f869ffd":"### Make sure that distribution of test and train data are identical, this should be case since we have shuffled it, but never the less, lets be wary!","b297feed":"### Let us shuffle the data before kicking off test-train split of data, we will just use sklearn *train_test_split* for it","092fe321":"## Step 1: Initial logisitics and loading the csv\n\nThe data is from [UCI dataset](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29), but with a modification that the target value __diagnosis__ is a numeric (__diagnosis_numeric__) instead of categorical text in the original data"}}