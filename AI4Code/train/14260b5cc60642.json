{"cell_type":{"526665e4":"code","cea933c1":"code","f2b6e53f":"code","4b578503":"code","1c96c45e":"code","d7a810c2":"code","4a332b4a":"code","7e2f89ad":"code","cdf57477":"code","083356f5":"code","1b5d4e25":"code","02ba8d18":"code","2b1b3ffc":"code","c6874e98":"code","177a1deb":"code","adb868e2":"code","17eeb77f":"code","6af22386":"code","4c4f3cb5":"code","10981f0a":"code","1cc36dff":"code","88b94e20":"code","a956833a":"code","c9162fbc":"code","4301a8d0":"code","01cd8b6e":"code","6737c4d5":"code","364d4368":"code","45bfa310":"code","c05edec3":"code","16ae29d6":"code","c31eb80b":"code","9fc284e0":"code","ca81c52f":"code","33278f58":"code","2043aa30":"code","ea78c64a":"code","fa98cd4d":"code","f1068342":"code","75237d72":"code","3ddd3914":"code","ff7edc89":"code","96e2758d":"code","a81de782":"code","e7360885":"code","5b671cab":"code","30c7fad7":"code","35bbe443":"code","f6401092":"code","2ce859db":"code","c627cbdb":"code","8e21dafb":"code","04ad765a":"code","e95c32bd":"code","9a61a822":"code","c0c2662a":"code","485815cd":"code","dc6b5ed5":"code","c72bea01":"code","e3d5dc9e":"code","7f30a671":"code","3de889f5":"code","0c61d754":"code","d31c550e":"code","f986fe85":"code","e2610460":"code","1d8e6de5":"code","2eb3cc52":"code","890e144a":"code","cdda70b4":"code","f6fa584f":"code","c1038017":"code","a5d9482c":"code","644e9682":"code","eb9df273":"code","339f6d8b":"code","b06e58de":"code","1074bcc5":"code","471fe5c5":"code","4c7842ee":"code","8bae7e93":"code","299dad07":"code","819f9786":"code","dd9c361d":"code","3dfc0f78":"code","f8bdc061":"code","9734cbfa":"code","979b9f35":"code","f5f3184d":"code","5bfdfe13":"code","55183d45":"code","ebeeae17":"code","cb610786":"code","63ca83b3":"code","171557c7":"code","4e5117f1":"code","ad1413fb":"code","a532c648":"code","aa92d1dc":"code","3c565545":"code","eae3cbaf":"code","ed247414":"code","5329f01f":"code","f0394d78":"code","bb9dbea6":"code","49139e42":"code","97d8ac5f":"code","dcc59346":"code","417e4cf7":"code","4ec83042":"code","72a8ebfc":"code","e79e741f":"code","f7aa7df7":"code","ccc15b4b":"code","9858a5c5":"code","71cb0853":"code","d7fa6b9b":"code","5e65ed04":"code","3e538dd1":"code","b36c4ef9":"code","c65ab5bf":"code","f9d9f131":"code","61e7f407":"code","5a517c32":"code","4bba2607":"code","212d3e32":"code","90fd31dc":"code","5eedbe80":"code","e55e36f5":"code","d0c5d93d":"code","2e5e16b3":"code","9364d17a":"code","21f62af0":"code","76318633":"code","f0055bba":"code","dbfc9c45":"code","b136760f":"code","cdbe448e":"code","33a6224c":"code","66a9f57d":"code","dc3783ef":"code","90dc7c49":"code","92080519":"code","8e40c536":"code","0d41cfaf":"code","26a353a3":"code","7be7083d":"code","998006d0":"code","93792dbd":"code","0d65a012":"code","d20b8cd0":"code","1072aa03":"code","a46a9458":"code","4458b9a0":"code","06bc5e95":"code","44594bf0":"code","815caaaf":"code","be5d0406":"code","03161492":"code","abace066":"code","e11495de":"code","e363d710":"code","e15bde6a":"code","5f3eabcf":"code","16624cbe":"code","e51c01d5":"code","25fd918c":"code","d597470a":"code","3acc0110":"code","27e6dffa":"code","a415baff":"code","7c050374":"code","de814c37":"code","e4b2965a":"code","8811bd37":"code","9f89d333":"code","8397a719":"code","ac50aeb9":"code","cf3e24ba":"code","311339dc":"code","ca42f249":"code","33757f13":"code","e3b8cb40":"markdown","7ae8e3a5":"markdown","4012f2ae":"markdown","c60cc6b8":"markdown","4c3f055e":"markdown","4abf141d":"markdown","ac82ec8a":"markdown","7fb3e589":"markdown","68ff1d94":"markdown","c00fd105":"markdown","42b484b0":"markdown","eb0d87ae":"markdown","67b0e222":"markdown","37e3bf3a":"markdown","8a53bbbc":"markdown","b27444fb":"markdown","c95e139f":"markdown","12655d5d":"markdown","d80ec45f":"markdown","b1aca490":"markdown","af903af9":"markdown","838f21c6":"markdown","f8c68706":"markdown","1a050fb3":"markdown","3a925005":"markdown","600c6c38":"markdown","e4e42e76":"markdown","1e5ab9d1":"markdown","eb118a8f":"markdown","1785aad0":"markdown","d34cbdb1":"markdown","aa79634f":"markdown","3266b774":"markdown","0b0a2706":"markdown","ea082a6d":"markdown","52146523":"markdown","ff525db8":"markdown","7d888fe4":"markdown","5dbb8bdc":"markdown","f2b8bdcb":"markdown","281d69c1":"markdown","73ee913f":"markdown"},"source":{"526665e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cea933c1":"train = pd.read_csv('\/kaggle\/input\/healthcare-provider-fraud-detection-analysis\/Train-1542865627584.csv');","f2b6e53f":"train.head()","4b578503":"train.shape","1c96c45e":"outpatient= pd.read_csv(\"\/kaggle\/input\/healthcare-provider-fraud-detection-analysis\/Train_Outpatientdata-1542865627584.csv\")\noutpatient.head()","d7a810c2":"outpatient.shape","4a332b4a":"inpatient= pd.read_csv(\"\/kaggle\/input\/healthcare-provider-fraud-detection-analysis\/Train_Inpatientdata-1542865627584.csv\")\ninpatient.head()","7e2f89ad":"inpatient.shape","cdf57477":"beneficiary= pd.read_csv(\"\/kaggle\/input\/healthcare-provider-fraud-detection-analysis\/Train_Beneficiarydata-1542865627584.csv\")\nbeneficiary.head()","083356f5":"df_procedures1 =  pd.DataFrame(columns = ['Procedures'])\ndf_procedures1['Procedures'] = pd.concat([inpatient[\"ClmProcedureCode_1\"], inpatient[\"ClmProcedureCode_2\"], inpatient[\"ClmProcedureCode_3\"], inpatient[\"ClmProcedureCode_4\"], inpatient[\"ClmProcedureCode_5\"], inpatient[\"ClmProcedureCode_6\"]], axis=0, sort=True).dropna()\ndf_procedures1['Procedures'].head(10)","1b5d4e25":"df_procedures1.shape","02ba8d18":"grouped_procedure_df = df_procedures1['Procedures'].value_counts()\ngrouped_procedure_df","2b1b3ffc":"df_diagnosis = pd.DataFrame(columns = ['Diagnosis'])\ndf_diagnosis['Diagnosis'] = pd.concat([inpatient[\"ClmDiagnosisCode_1\"], inpatient[\"ClmDiagnosisCode_2\"], inpatient[\"ClmDiagnosisCode_3\"], inpatient[\"ClmDiagnosisCode_4\"], inpatient[\"ClmDiagnosisCode_5\"], inpatient[\"ClmDiagnosisCode_6\"], inpatient[\"ClmDiagnosisCode_7\"], inpatient[\"ClmDiagnosisCode_8\"], inpatient[\"ClmDiagnosisCode_9\"], inpatient[\"ClmDiagnosisCode_10\"]], axis=0, sort=True).dropna()\ndf_diagnosis['Diagnosis'].head(10)","c6874e98":"df_diagnosis.shape","177a1deb":"grouped_diagnosis_df = df_diagnosis['Diagnosis'].value_counts()\ngrouped_diagnosis_df","adb868e2":"grouped_procedure_df1 = grouped_procedure_df.to_frame()\ngrouped_procedure_df1","17eeb77f":"grouped_procedure_df1.columns = ['count']\ngrouped_procedure_df1","6af22386":"grouped_procedure_df1['Procedure'] = grouped_procedure_df1.index\ngrouped_procedure_df1","4c4f3cb5":"grouped_procedure_df1['Percentage'] = (grouped_procedure_df1['count']\/sum(grouped_procedure_df1['count']))*100\ngrouped_procedure_df1['Percentage']","10981f0a":"grouped_diagnosis_df = grouped_diagnosis_df.to_frame()\ngrouped_diagnosis_df.columns = ['count']\ngrouped_diagnosis_df['Diagnosis'] = grouped_diagnosis_df.index\ngrouped_diagnosis_df['Percentage'] = (grouped_diagnosis_df['count']\/sum(grouped_diagnosis_df['count']))*100\ngrouped_diagnosis_df['Percentage']","1cc36dff":"# taking only top 20 \n\nplot_procedure_df1 = grouped_procedure_df1.head(20)\nplot_diagnosis_df1 = grouped_diagnosis_df.head(20)","88b94e20":"# Plotting the most commonly used diagnosis and procedures \nfrom matplotlib import pyplot as plt\nplot_procedure_df1['Procedure'] = plot_procedure_df1['Procedure'].astype(str)\nplot_procedure_df1.sort_values(by=['Percentage'])\nplot_procedure_df1.plot(x ='Procedure', y='Percentage', kind='bar', color ='green',\n                  title='Procedure Distribution- Inpatient', figsize=(15,10));","a956833a":"plot_diagnosis_df1['Diagnosis'] =  plot_diagnosis_df1['Diagnosis'].astype(str)\nplot_diagnosis_df1.sort_values(by=['Percentage'])\nplot_diagnosis_df1.plot(x ='Diagnosis', y='Percentage', kind='bar', color ='green',\n                  title='Diagnosis Distribution- Inpatient', figsize=(15,10));","c9162fbc":"df_procedures2 =  pd.DataFrame(columns = ['Procedures'])\ndf_procedures2['Procedures'] = pd.concat([outpatient[\"ClmProcedureCode_1\"], outpatient[\"ClmProcedureCode_2\"], outpatient[\"ClmProcedureCode_3\"], outpatient[\"ClmProcedureCode_4\"], outpatient[\"ClmProcedureCode_5\"], outpatient[\"ClmProcedureCode_6\"]], axis=0, sort=True).dropna()\ndf_procedures2['Procedures'].head(10)","4301a8d0":"grouped_procedure_df2 = df_procedures2['Procedures'].value_counts()","01cd8b6e":"df_diagnosis2 = pd.DataFrame(columns = ['Diagnosis'])\ndf_diagnosis2['Diagnosis'] = pd.concat([outpatient[\"ClmDiagnosisCode_1\"], outpatient[\"ClmDiagnosisCode_2\"], outpatient[\"ClmDiagnosisCode_3\"], outpatient[\"ClmDiagnosisCode_4\"], outpatient[\"ClmDiagnosisCode_5\"], outpatient[\"ClmDiagnosisCode_6\"], outpatient[\"ClmDiagnosisCode_7\"],  outpatient[\"ClmDiagnosisCode_8\"], outpatient[\"ClmDiagnosisCode_9\"], outpatient[\"ClmDiagnosisCode_10\"]], axis=0, sort=True).dropna()\ndf_diagnosis2['Diagnosis'].head(10)\ngrouped_diagnosis_df2 = df_diagnosis2['Diagnosis'].value_counts()","6737c4d5":"grouped_procedure_df_op = grouped_procedure_df2.to_frame()\ngrouped_procedure_df_op.columns = ['count']\ngrouped_procedure_df_op['Procedure'] = grouped_procedure_df_op.index\ngrouped_procedure_df_op['Percentage'] = (grouped_procedure_df_op['count']\/sum(grouped_procedure_df_op['count']))*100\ngrouped_procedure_df_op['Percentage']","364d4368":"grouped_diagnosis_df_op = grouped_diagnosis_df2.to_frame()\ngrouped_diagnosis_df_op.columns = ['count']\ngrouped_diagnosis_df_op['Diagnosis'] = grouped_diagnosis_df_op.index\ngrouped_diagnosis_df_op['Percentage'] = (grouped_diagnosis_df_op['count']\/sum(grouped_diagnosis_df_op['count']))*100\ngrouped_diagnosis_df_op['Percentage']","45bfa310":"# taking only top 20 \n\nplot_procedure_df2 = grouped_procedure_df_op.head(20)\nplot_diagnosis_df2 = grouped_diagnosis_df_op.head(20)","c05edec3":"# Plotting the most commonly used diagnosis and procedures \nfrom matplotlib import pyplot as plt\n\n\nplot_procedure_df2['Procedure'] = plot_procedure_df2['Procedure'].astype(str)\nplot_procedure_df2.sort_values(by=['Percentage'])\nplot_procedure_df2.plot(x ='Procedure', y='Percentage', kind='bar', color ='yellow',\n                   title='Procedure Distribution- Outpatient', figsize=(15,7));","16ae29d6":"plot_diagnosis_df2['Diagnosis'] = plot_diagnosis_df2['Diagnosis'].astype(str)\nplot_diagnosis_df2.sort_values(by=['Percentage'])\nplot_diagnosis_df2.plot(x ='Diagnosis', y='Percentage', kind='bar', color ='yellow',\n                   title='Diagnosis Distribution- Outpatient', figsize=(15,7))","c31eb80b":"T_fraud = train['PotentialFraud'].value_counts()\ngrouped_train_df = T_fraud.to_frame()\n\ngrouped_train_df.columns = ['count']\ngrouped_train_df['Fraud'] = grouped_train_df.index\ngrouped_train_df['Percentage'] = (grouped_train_df['count']\/sum(grouped_train_df['count']))*100\ngrouped_train_df['Percentage'].plot( kind='bar',color = \"blue\", title = 'Distribution')","9fc284e0":"Train_f =  pd.DataFrame(columns = ['PotentialFraud', 'Provider'])\nTrain_f = train.loc[(train['PotentialFraud'] == 'Yes')]\nTrain_f","ca81c52f":"fraud_provider_ip_df = pd.merge(inpatient, Train_f, how='inner', on='Provider')\nfraud_provider_ip_df","33278f58":"len(fraud_provider_ip_df)","2043aa30":"(len(fraud_provider_ip_df)\/len(inpatient)) * 100","ea78c64a":"fraud_provider_op_df = pd.merge(outpatient, Train_f, how='inner', on='Provider')\nfraud_provider_op_df","fa98cd4d":"len(fraud_provider_op_df)","f1068342":"(len(fraud_provider_op_df)\/len(outpatient))*100","75237d72":"df_procedures2 =  pd.DataFrame(columns = ['Procedures'])\ndf_procedures2['Procedures'] = pd.concat([fraud_provider_ip_df[\"ClmProcedureCode_1\"], fraud_provider_ip_df[\"ClmProcedureCode_2\"], fraud_provider_ip_df[\"ClmProcedureCode_3\"], fraud_provider_ip_df[\"ClmProcedureCode_4\"], fraud_provider_ip_df[\"ClmProcedureCode_5\"], fraud_provider_ip_df[\"ClmProcedureCode_6\"]], axis=0, sort=True).dropna()\ndf_procedures2['Procedures'].head(10)","3ddd3914":"grouped_F_procedure_df = df_procedures2['Procedures'].value_counts()\ngrouped_F_procedure_df","ff7edc89":"grouped_F_procedure_df2 = grouped_F_procedure_df.to_frame()\ngrouped_F_procedure_df2.columns = ['count']\ngrouped_F_procedure_df2['Procedure'] = grouped_F_procedure_df2.index\ngrouped_F_procedure_df2['Percentage'] = (grouped_F_procedure_df2['count']\/sum(grouped_F_procedure_df2['count']))*100\ngrouped_F_procedure_df2['Percentage']","96e2758d":"df_diagnosis2 = pd.DataFrame(columns = ['Diagnosis'])\ndf_diagnosis2['Diagnosis'] = pd.concat([fraud_provider_ip_df[\"ClmDiagnosisCode_1\"], fraud_provider_ip_df[\"ClmDiagnosisCode_2\"], fraud_provider_ip_df[\"ClmDiagnosisCode_3\"], fraud_provider_ip_df[\"ClmDiagnosisCode_4\"], fraud_provider_ip_df[\"ClmDiagnosisCode_5\"], fraud_provider_ip_df[\"ClmDiagnosisCode_6\"], fraud_provider_ip_df[\"ClmDiagnosisCode_7\"],  fraud_provider_ip_df[\"ClmDiagnosisCode_8\"], fraud_provider_ip_df[\"ClmDiagnosisCode_9\"], fraud_provider_ip_df[\"ClmDiagnosisCode_10\"]], axis=0, sort=True).dropna()\ndf_diagnosis2['Diagnosis'].head(10)","a81de782":"grouped_F_diagnosis_df = df_diagnosis2['Diagnosis'].value_counts()\ngrouped_F_diagnosis_df","e7360885":"grouped_F_diagnosis_df2 = grouped_F_diagnosis_df.to_frame()\ngrouped_F_diagnosis_df2.columns = ['count']\ngrouped_F_diagnosis_df2['Diagnosis'] = grouped_F_diagnosis_df2.index\ngrouped_F_diagnosis_df2['Percentage'] = (grouped_F_diagnosis_df2['count']\/sum(grouped_F_diagnosis_df2['count']))*100\ngrouped_F_diagnosis_df2['Percentage']","5b671cab":"plot_F_procedure_df1 = grouped_F_procedure_df2.head(20)\n\nplot_F_diagnosis_df1 = grouped_F_diagnosis_df2.head(20)","30c7fad7":"plot_F_procedure_df1.plot(x ='Procedure', y='Percentage', kind = 'bar', color ='g', figsize=(15,7))","35bbe443":"plot_F_diagnosis_df1.plot(x ='Diagnosis', y='Percentage', kind = 'bar', color ='y', figsize=(15,7))","f6401092":"df_procedures_op2 =  pd.DataFrame(columns = ['Procedures'])\ndf_procedures_op2['Procedures'] = pd.concat([fraud_provider_op_df[\"ClmProcedureCode_1\"], fraud_provider_op_df[\"ClmProcedureCode_2\"], fraud_provider_op_df[\"ClmProcedureCode_3\"], fraud_provider_op_df[\"ClmProcedureCode_4\"], fraud_provider_op_df[\"ClmProcedureCode_5\"], fraud_provider_op_df[\"ClmProcedureCode_6\"]], axis=0, sort=True).dropna()\ndf_procedures_op2['Procedures'].head(10)","2ce859db":"grouped_F_procedure_op_df = df_procedures_op2['Procedures'].value_counts()\ngrouped_F_procedure_op_df.head()","c627cbdb":"grouped_F_procedure_opdf2 = grouped_F_procedure_op_df.to_frame()\ngrouped_F_procedure_opdf2.columns = ['count']\ngrouped_F_procedure_opdf2['Procedure'] = grouped_F_procedure_opdf2.index\ngrouped_F_procedure_opdf2['Percentage'] = (grouped_F_procedure_opdf2['count']\/sum(grouped_F_procedure_opdf2['count']))*100\ngrouped_F_procedure_opdf2['Percentage'].head()","8e21dafb":"df_diagnosis_op2 = pd.DataFrame(columns = ['Diagnosis'])\ndf_diagnosis_op2['Diagnosis'] = pd.concat([fraud_provider_op_df[\"ClmDiagnosisCode_1\"], fraud_provider_op_df[\"ClmDiagnosisCode_2\"], fraud_provider_op_df[\"ClmDiagnosisCode_3\"], fraud_provider_op_df[\"ClmDiagnosisCode_4\"], fraud_provider_op_df[\"ClmDiagnosisCode_5\"], fraud_provider_op_df[\"ClmDiagnosisCode_6\"], fraud_provider_op_df[\"ClmDiagnosisCode_7\"],  fraud_provider_op_df[\"ClmDiagnosisCode_8\"], fraud_provider_op_df[\"ClmDiagnosisCode_9\"], fraud_provider_op_df[\"ClmDiagnosisCode_10\"]], axis=0, sort=True).dropna()\ndf_diagnosis_op2['Diagnosis'].head()","04ad765a":"grouped_F_diagnosis_op_df = df_diagnosis2['Diagnosis'].value_counts()\ngrouped_F_diagnosis_op_df.head()","e95c32bd":"grouped_F_diagnosis_opdf2 = grouped_F_diagnosis_op_df.to_frame()\ngrouped_F_diagnosis_opdf2.columns = ['count']\ngrouped_F_diagnosis_opdf2['Diagnosis'] = grouped_F_diagnosis_opdf2.index\ngrouped_F_diagnosis_opdf2['Percentage'] = (grouped_F_diagnosis_opdf2['count']\/sum(grouped_F_diagnosis_opdf2['count']))*100\ngrouped_F_diagnosis_opdf2['Percentage'].head()","9a61a822":"plot_F_procedure_opdf1 = grouped_F_procedure_opdf2.head(20)\n\nplot_F_diagnosis_opdf1 = grouped_F_diagnosis_opdf2.head(20)","c0c2662a":"plot_F_procedure_opdf1.plot(x ='Procedure', y='Percentage', kind = 'bar', color ='g', figsize=(15,7))","485815cd":"plot_F_diagnosis_opdf1.plot(x ='Diagnosis', y='Percentage', kind = 'bar', color ='y', figsize=(15,7))","dc6b5ed5":"beneficiary.head()","c72bea01":"fraud_beneficiary_ip_op_df = pd.merge(beneficiary, fraud_provider_ip_df, how='inner', on='BeneID')\nfraud_beneficiary_ip_op_df.head()","e3d5dc9e":"Train_F_Beneficiary_grouped = fraud_beneficiary_ip_op_df['State'].value_counts()\nTrain_F_Beneficiary_grouped.head()","7f30a671":"Train_F_Beneficiary_grouped1 = Train_F_Beneficiary_grouped.to_frame()\nTrain_F_Beneficiary_grouped1['Count'] =  Train_F_Beneficiary_grouped1['State']\nTrain_F_Beneficiary_grouped1['STATE'] = Train_F_Beneficiary_grouped1.index\nTrain_F_Beneficiary_grouped1 = Train_F_Beneficiary_grouped1.drop(['State'], axis = 1)\nTrain_F_Beneficiary_grouped1 = Train_F_Beneficiary_grouped1.head(20)\nTrain_F_Beneficiary_grouped1","3de889f5":"Train_F_Beneficiary_grouped1.plot(x ='STATE', y='Count', kind = 'bar', figsize= (15,7));","0c61d754":"fraud_beneficiary_ip_op_df['DOB'] =  pd.to_datetime(fraud_beneficiary_ip_op_df['DOB'], format='%Y-%m-%d')  \nnow = pd.to_datetime('2009-12-01' , format = '%Y-%m-%d') # Assuming this is 2009 data as the last recorded death is for 2009\nfraud_beneficiary_ip_op_df['DOB'] = fraud_beneficiary_ip_op_df['DOB'].where(fraud_beneficiary_ip_op_df['DOB'] < now) \nfraud_beneficiary_ip_op_df['age'] = (now - fraud_beneficiary_ip_op_df['DOB']).astype('<m8[Y]')  \nax = fraud_beneficiary_ip_op_df['age'].plot.hist(bins=20, alpha=0.5, figsize=(8, 6), edgecolor='b')","d31c550e":"beneficiary['DOB'] =  pd.to_datetime(beneficiary['DOB'], format='%Y-%m-%d')  \nnow = pd.to_datetime('2009-12-01' , format = '%Y-%m-%d') # Assuming this is 2009 data as the last recorded death is for 2009\nbeneficiary['DOB'] = beneficiary['DOB'].where(beneficiary['DOB'] < now)\nbeneficiary['age'] = (now - beneficiary['DOB']).astype('<m8[Y]')\nax = beneficiary['age'].plot.hist(bins=20, alpha=0.5, figsize=(8, 6), edgecolor='b')","f986fe85":"ax = inpatient['InscClaimAmtReimbursed'].plot.hist(bins=20, alpha=0.5, figsize=(8, 6), facecolor='g', edgecolor='g')\n# Insurance Claim amount reimbursed.","e2610460":"import seaborn as sns\ninpatient_1 = pd.merge(inpatient, train, how='inner', on='Provider')\ng = sns.FacetGrid(inpatient_1, col='PotentialFraud', height=8)\ng.map(plt.hist, 'InscClaimAmtReimbursed', bins=20, color = 'g')","1d8e6de5":"inpatient_1 = inpatient_1.loc[(inpatient_1['PotentialFraud'] == 'Yes')]\nTotal = inpatient_1['InscClaimAmtReimbursed'].sum()\nprint(Total)","2eb3cc52":"ax = outpatient['InscClaimAmtReimbursed'].plot.hist(bins=100,range=[0,5000], alpha=0.5, figsize=(8, 6), facecolor='c', edgecolor='k')","890e144a":"outpatient_1 = pd.merge(outpatient, train, how='inner', on='Provider')\ng = sns.FacetGrid(outpatient_1, col='PotentialFraud', height=8)\ng.map(plt.hist, 'InscClaimAmtReimbursed', bins=20, range=[0, 5000], color ='c')","cdda70b4":"beneficiary.isna().sum()","f6fa584f":"beneficiary['DOB'] = pd.to_datetime(beneficiary['DOB'] , format = '%Y-%m-%d')\nbeneficiary['DOD'] = pd.to_datetime(beneficiary['DOD'],format = '%Y-%m-%d',errors='ignore')\nbeneficiary['Age'] = round(((beneficiary['DOD'] - beneficiary['DOB']).dt.days)\/365)\n\n## As we see that last DOD value is 2009-12-01 ,which means Beneficiary Details data is of year 2009.\n## so we will calculate age of other benficiaries for year 2009.","c1038017":"beneficiary.Age.fillna(round(((pd.to_datetime('2009-12-01' , format = '%Y-%m-%d') - beneficiary['DOB']).dt.days)\/365),\n                                 inplace=True)","a5d9482c":"beneficiary.head()","644e9682":"## Creating the master DF\ninpatient['EncounterType'] = 0\noutpatient['EncounterType'] = 1\nframes = [inpatient, outpatient]\nTrainInAndOut = pd.concat(frames)\nTrainInAndOutBenf = pd.merge(TrainInAndOut, beneficiary, how='inner', on='BeneID')\nMaster_df = pd.merge(TrainInAndOutBenf, train, how='inner', on='Provider')","eb9df273":"Master_df.head()","339f6d8b":"Master_df['PotentialFraud'].value_counts()","b06e58de":"Master_df.shape","1074bcc5":"Master_df.isnull().sum()","471fe5c5":"## removing the column DOD and DOB also creating a new column IsDead as we already have the age we do not need date of death and date of birth \n\nMaster_df.loc[Master_df['DOD'].isnull(), 'IsDead'] = '0'\nMaster_df.loc[(Master_df['DOD'].notnull()), 'IsDead'] = '1'\nMaster_df = Master_df.drop(['DOD'], axis = 1)\nMaster_df = Master_df.drop(['DOB'], axis = 1)","4c7842ee":"Master_df = Master_df.drop(['age'], axis = 1) ","8bae7e93":"Master_df['AdmissionDt'] = pd.to_datetime(Master_df['AdmissionDt'] , format = '%Y-%m-%d')\nMaster_df['DischargeDt'] = pd.to_datetime(Master_df['DischargeDt'],format = '%Y-%m-%d')\nMaster_df['DaysAdmitted'] = ((Master_df['DischargeDt'] - Master_df['AdmissionDt']).dt.days)+1\nMaster_df.loc[Master_df['EncounterType'] == 1, 'DaysAdmitted'] = '0'\nMaster_df[['EncounterType','DaysAdmitted','DischargeDt','AdmissionDt']].head()\nMaster_df = Master_df.drop(['DischargeDt'], axis = 1)\nMaster_df = Master_df.drop(['AdmissionDt'], axis = 1)","299dad07":"Master_df.loc[Master_df['DeductibleAmtPaid'].isnull(), 'DeductibleAmtPaid'] = '0'","819f9786":"cols= ['ClmAdmitDiagnosisCode', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_10',\n       'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4',\n       'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7',\n       'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmProcedureCode_1',\n       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',\n       'ClmProcedureCode_5', 'ClmProcedureCode_6']","dd9c361d":"Master_df[cols]= Master_df[cols].replace({np.nan:0})\nMaster_df","3dfc0f78":"for i in cols:\n    Master_df[i][Master_df[i]!=0]= 1","f8bdc061":"Master_df[cols]= Master_df[cols].astype(float)","9734cbfa":"Master_df['TotalDiagnosis']= Master_df['ClmDiagnosisCode_1']+Master_df['ClmDiagnosisCode_10']+Master_df['ClmDiagnosisCode_2']+ Master_df['ClmDiagnosisCode_3']+ Master_df['ClmDiagnosisCode_4']+Master_df['ClmDiagnosisCode_5']+ Master_df['ClmDiagnosisCode_6']+ Master_df['ClmDiagnosisCode_7']+Master_df['ClmDiagnosisCode_8']+ Master_df['ClmDiagnosisCode_9']","979b9f35":"Master_df['TotalProcedure']= Master_df['ClmProcedureCode_1']+Master_df['ClmProcedureCode_2']+Master_df['ClmProcedureCode_3']+ Master_df['ClmProcedureCode_4']+ Master_df['ClmProcedureCode_5']+Master_df['ClmProcedureCode_6']","f5f3184d":"Master_df.columns","5bfdfe13":"remove=['Provider','BeneID', 'ClaimID', 'ClaimStartDt','ClaimEndDt','AttendingPhysician',\n       'OperatingPhysician', 'OtherPhysician', 'ClmDiagnosisCode_1',\n       'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4',\n       'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7',\n       'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10',\n       'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3',\n       'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6',\n       'ClmAdmitDiagnosisCode','DeductibleAmtPaid','NoOfMonths_PartACov',\n        'NoOfMonths_PartBCov','DiagnosisGroupCode',\n        'State', 'County']","55183d45":"Master_df.drop(columns=remove, axis=1, inplace=True)","ebeeae17":"Master_df.head()","cb610786":"Master_df.shape","63ca83b3":"Master_df['RenalDiseaseIndicator'].value_counts()","171557c7":"Master_df['RenalDiseaseIndicator']= Master_df['RenalDiseaseIndicator'].replace({'Y':1,'0':0})","4e5117f1":"Master_df['RenalDiseaseIndicator']=Master_df['RenalDiseaseIndicator'].astype(int)","ad1413fb":"Master_df.describe(include='O')","a532c648":"Master_df['IsDead']=Master_df['IsDead'].astype(float)\nMaster_df['DaysAdmitted']=Master_df['DaysAdmitted'].astype(float)","aa92d1dc":"Master_df['PotentialFraud']=Master_df['PotentialFraud'].replace({'Yes':1, 'No':0})","3c565545":" Master_df['PotentialFraud']=Master_df['PotentialFraud'].astype(int)","eae3cbaf":"Master_df['PotentialFraud']","ed247414":"x= Master_df.drop('PotentialFraud', axis=1)\ny= Master_df.loc[:,'PotentialFraud']","5329f01f":"x.columns","f0394d78":"num_col= ['InscClaimAmtReimbursed',\n       'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n       'DaysAdmitted', 'TotalDiagnosis', 'TotalProcedure']","bb9dbea6":"numerical_columns= x.loc[:,num_col]\nnumerical_columns.describe()","49139e42":"numerical_columns.head()","97d8ac5f":"cat_col= ['EncounterType', 'Gender', 'Race',\n       'RenalDiseaseIndicator', 'ChronicCond_Alzheimer',\n       'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n       'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n       'ChronicCond_Depression', 'ChronicCond_Diabetes',\n       'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n       'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke','IsDead']","dcc59346":"x_cat= x.loc[:,cat_col]\nx_cat","417e4cf7":"from sklearn.preprocessing import StandardScaler","4ec83042":"scale= StandardScaler()\nx_num= scale.fit_transform(x[num_col])","72a8ebfc":"x_num= pd.DataFrame(x_num, columns=['InscClaimAmtReimbursed','IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt','OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age','DaysAdmitted', 'TotalDiagnosis', 'TotalProcedure'])","e79e741f":"x= pd.concat([x_num, x_cat], axis=1)\nx","f7aa7df7":"x.columns","ccc15b4b":"y","9858a5c5":"from sklearn.model_selection import train_test_split","71cb0853":"x_train,x_test, y_train, y_test= train_test_split(x,y, test_size=0.1, random_state=42)","d7fa6b9b":"from imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(random_state=0)\nx_train1,y_train1 = rus.fit_resample(x_train, y_train)","5e65ed04":"'''from imblearn import over_sampling\n\nada = over_sampling.ADASYN(random_state=0)\nx_train2, y_train2 = ada.fit_resample(x_train, y_train)'''","3e538dd1":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, auc, roc_curve","b36c4ef9":"from xgboost import plot_importance\nfrom xgboost import XGBClassifier\nxgb= XGBClassifier()\nxgb.fit(x_train,y_train)\nplot_importance(xgb)","c65ab5bf":"xgb= XGBClassifier()\nxgb.fit(x_train1,y_train1)\nplot_importance(xgb)","f9d9f131":"'''xgb.fit(x_train2,y_train2)\nplot_importance(xgb)'''","61e7f407":"acc_score=[]","5a517c32":"from sklearn.model_selection import GridSearchCV","4bba2607":"from sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nestimator=  DecisionTreeClassifier()\nparam_grid= {'criterion':['gini', 'entropy'],\n             'max_depth':[3,4,5],\n             'min_samples_split':[2,3,5]\n             }\ngrid_search = GridSearchCV(estimator = estimator, param_grid = param_grid)\ngrid_search.fit(x_train1, y_train1)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","212d3e32":"'''param_grid= {'criterion':['gini', 'entropy'],\n             'max_depth':[3,4,5],\n             'min_samples_split':[2,3,5]\n             }\ngrid_search = GridSearchCV(estimator = estimator, param_grid = param_grid)\ngrid_search.fit(x_train2, y_train2)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)'''","90fd31dc":"grid_search.fit(x_train, y_train)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","5eedbe80":"from sklearn.ensemble import RandomForestClassifier\nestimator1= RandomForestClassifier()\n'''estimator1.fit(x_train, y_train)\nmodel_score= estimator1.predict(x_train)\naccuracy= estimator1.predict(x_test)\nprint(accuracy_score(y_train, model_score))\nprint(accuracy_score(y_test, accuracy))'''","e55e36f5":"'''estimator1.fit(x_train1, y_train1)\nmodel_score= estimator1.predict(x_train1)\naccuracy= estimator1.predict(x_test)\nprint(accuracy_score(y_train1, model_score))\nprint(accuracy_score(y_test, accuracy))'''","d0c5d93d":"'''estimator1.fit(x_train2, y_train2)\nmodel_score= estimator1.predict(x_train2)\naccuracy= estimator1.predict(x_test)\nprint(accuracy_score(y_train2, model_score))\nprint(accuracy_score(y_test, accuracy))'''","2e5e16b3":"from sklearn.naive_bayes import GaussianNB\nbayes= GaussianNB()\nbayes.fit(x_train, y_train)\ntrain_pred= bayes.predict(x_train)\ntest_pred= bayes.predict(x_test)\nprint(accuracy_score(y_train,train_pred))\nprint(accuracy_score(y_test,test_pred))","9364d17a":"bayes.fit(x_train, y_train)\ntrain_pred= bayes.predict(x_train1)\ntest_pred= bayes.predict(x_test)\nprint(accuracy_score(y_train1,train_pred))\nprint(accuracy_score(y_test,test_pred))","21f62af0":"'''bayes.fit(x_train, y_train)\ntrain_pred= bayes.predict(x_train2)\ntest_pred= bayes.predict(x_test)\nprint(accuracy_score(y_train2,train_pred))\nprint(accuracy_score(y_test,test_pred))'''","76318633":"from sklearn.linear_model import LogisticRegression\nlr= LogisticRegression()\nlr.fit(x_train, y_train)\ntrain_pred= lr.predict(x_train)\ntest_pred= lr.predict(x_test)\nprint(accuracy_score(y_train,train_pred))\nprint(accuracy_score(y_test,test_pred))","f0055bba":"lr.fit(x_train1, y_train1)\ntrain_pred= lr.predict(x_train1)\ntest_pred= lr.predict(x_test)\nprint(accuracy_score(y_train1,train_pred))\nprint(accuracy_score(y_test,test_pred))","dbfc9c45":"'''lr.fit(x_train2, y_train2)\ntrain_pred= lr.predict(x_train2)\ntest_pred= lr.predict(x_test)\nprint(accuracy_score(y_train2,train_pred))\nprint(accuracy_score(y_test,test_pred))'''","b136760f":"import time\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import fbeta_score\nestimator=  DecisionTreeClassifier(criterion= 'gini', max_depth=5, min_samples_split= 2)\nestimator.fit(x_train, y_train)\nmodel_score= estimator.predict(x_train)\naccuracy= estimator.predict(x_test)\nstart = time.time()\nestimator.score(x_train, y_train)\nacc_random_forest = round(accuracy_score(y_test,accuracy)*100, 2)\nf1_random_forest = round(f1_score(y_test,accuracy,average = \"binary\")*100, 2)\nf_beta_random_forest = round(fbeta_score(y_test,accuracy,average = \"binary\",beta=0.5)*100, 2)\n\nend = time.time()\n\nacc_score.append({'Model':'Decision Tree', 'Score': accuracy_score(y_train, model_score), 'Accuracy': accuracy_score(y_test, accuracy), 'Time_Taken':end - start})","cdbe448e":"fn= ['InscClaimAmtReimbursed', 'IPAnnualReimbursementAmt',\n    'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt',\n    'OPAnnualDeductibleAmt', 'Age', 'DaysAdmitted',\n    'TotalDiagnosis', 'TotalProcedure', 'EncounterType', 'Gender', 'Race',\n    'RenalDiseaseIndicator', 'ChronicCond_Alzheimer',\n    'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n    'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n    'ChronicCond_Depression', 'ChronicCond_Diabetes',\n    'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n    'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke', 'IsDead']","33a6224c":"cl=['No','Yes']","66a9f57d":"fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (15,10), dpi=300)\ntree.plot_tree(estimator, feature_names= fn, class_names=cl);","dc3783ef":"m1= Master_df['DaysAdmitted'].mean()\ns1= Master_df['DaysAdmitted'].std()\nprint((0.007*s1)+m1)\nprint((9.57*s1)+m1)\nprint((9.135*s1)+m1)","90dc7c49":"m2= Master_df['OPAnnualDeductibleAmt'].mean()\ns2= Master_df['OPAnnualDeductibleAmt'].std()\nprint((10.514*s2)+m2)","92080519":"m3= Master_df['Age'].mean()\ns3= Master_df['Age'].std()\nprint((-0.481*s3)+m3)","8e40c536":"m4= Master_df['InscClaimAmtReimbursed'].mean()\ns4= Master_df['InscClaimAmtReimbursed'].std()\nprint((10.075*s4)+m4)","0d41cfaf":"confusion_matrix(y_test,accuracy)","26a353a3":"tn, fp, fn, tp = confusion_matrix(y_test,accuracy).ravel()\n(tn, fp, fn, tp)  ","7be7083d":"train_fpr, train_tpr, thresholds = roc_curve(y_train, estimator.predict_proba(x_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, estimator.predict_proba(x_test)[:,1])\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC CURVE\")\nplt.show()","998006d0":"from sklearn.ensemble import RandomForestClassifier\nestimator1= RandomForestClassifier()\nestimator1.fit(x_train, y_train)\nmodel_score= estimator1.predict(x_train)\naccuracy= estimator1.predict(x_test)\nstart = time.time()\nestimator1.score(x_train, y_train)\nacc_random_forest = round(accuracy_score(y_test,accuracy)*100, 2)\nf1_random_forest = round(f1_score(y_test,accuracy,average = \"binary\")*100, 2)\nf_beta_random_forest = round(fbeta_score(y_test,accuracy,average = \"binary\",beta=0.5)*100, 2)\nend = time.time()\nacc_score.append({'Model':'Random Forest', 'Score': accuracy_score(y_train, model_score), 'Accuracy': accuracy_score(y_test, accuracy),'Time_Taken':end - start})","93792dbd":"confusion_matrix(y_test,accuracy)","0d65a012":"tn, fp, fn, tp = confusion_matrix(y_test,accuracy).ravel()\n(tn, fp, fn, tp)","d20b8cd0":"train_fpr, train_tpr, thresholds = roc_curve(y_train, estimator1.predict_proba(x_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, estimator1.predict_proba(x_test)[:,1])\n\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC CURVE\")\nplt.show()","1072aa03":"y_test_rf= y_test.reset_index()\ny_test.head()","a46a9458":"x_test_rf=  x_test.reset_index()\nx_test.head()","4458b9a0":"y_test_rf.shape","06bc5e95":"accuracy= accuracy.reshape(55822,1)","44594bf0":"accuracy.shape","815caaaf":"accuracy= pd.DataFrame(accuracy, columns= ['Predict'])\naccuracy","be5d0406":"predictor= pd.concat([y_test_rf,accuracy], axis=1)\npredictor","03161492":"Index_label = predictor[(predictor['PotentialFraud'] ==1) & (predictor['Predict']==1)]\nindicies= Index_label['index']","abace066":"wrong_predictions= Master_df.iloc[indicies,:]\nwrong_predictions","e11495de":"print('Fraud Insurance Claims detected - ',wrong_predictions['InscClaimAmtReimbursed'].sum())\nprint('Fraud Insurance Claims for Inpatients detected - ',wrong_predictions['IPAnnualReimbursementAmt'].sum())\nprint('Fraud Insurance Claims for Outpatients detected - ',wrong_predictions['OPAnnualReimbursementAmt'].sum())","e363d710":"fraud_index= y_test_rf[y_test_rf['PotentialFraud']==1]\nindicies1= fraud_index['index']","e15bde6a":"frauds= Master_df.iloc[indicies1,:]\nfrauds","5f3eabcf":"print('Fraud Insurance Claims without model - ',frauds['InscClaimAmtReimbursed'].sum())\nprint('Fraud Insurance Claims for Inpatients without model - ',frauds['IPAnnualReimbursementAmt'].sum())\nprint('Fraud Insurance Claims for Outpatients without model - ',frauds['OPAnnualReimbursementAmt'].sum())","16624cbe":"print('Insurance Claim Amount Saved - $', 30673230- 23525520)\nprint('Inpatient Insurance Claim Amount Saved - $',122946970- 78254980)\nprint('Outpatient insurance Claim Amount Saved - $',48642580- 27754480)","e51c01d5":"from sklearn.naive_bayes import GaussianNB\nbayes= GaussianNB()\nbayes.fit(x_train, y_train)\ntrain_pred= bayes.predict(x_train)\ntest_pred= bayes.predict(x_test)\nstart = time.time()\nbayes.score(x_train, y_train)\nacc_random_forest = round(accuracy_score(y_test,test_pred)*100, 2)\nf1_random_forest = round(f1_score(y_test,test_pred,average = \"binary\")*100, 2)\nf_beta_random_forest = round(fbeta_score(y_test,test_pred,average = \"binary\",beta=0.5)*100, 2)\n\nend = time.time()\n\nacc_score.append({'Model':'Naive Bayes', 'Score': accuracy_score(y_train, train_pred), 'Accuracy': accuracy_score(y_test, test_pred),'Time_Taken':end- start})","25fd918c":"confusion_matrix(y_test,test_pred)","d597470a":"tn, fp, fn, tp = confusion_matrix(y_test,test_pred).ravel()\n(tn, fp, fn, tp)","3acc0110":"train_fpr, train_tpr, thresholds = roc_curve(y_train, bayes.predict_proba(x_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, bayes.predict_proba(x_test)[:,1])\n\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC CURVE\")\nplt.show()","27e6dffa":"from sklearn.linear_model import LogisticRegression\nlr= LogisticRegression()\nlr.fit(x_train, y_train)\ntrain_pred= lr.predict(x_train)\ntest_pred= lr.predict(x_test)\nstart = time.time()\nlr.score(x_train, y_train)\nacc_random_forest = round(accuracy_score(y_test,test_pred)*100, 2)\nf1_random_forest = round(f1_score(y_test,test_pred,average = \"binary\")*100, 2)\nf_beta_random_forest = round(fbeta_score(y_test,test_pred,average = \"binary\",beta=0.5)*100, 2)\n\nend = time.time()\nacc_score.append({'Model': \"Logistic Regression\", 'Score': accuracy_score(y_train,train_pred), 'Accuracy': accuracy_score(y_test,test_pred), 'Time_Taken':end - start})","a415baff":"confusion_matrix(y_test,test_pred)","7c050374":"tn, fp, fn, tp = confusion_matrix(y_test,test_pred).ravel()\n(tn, fp, fn, tp)","de814c37":"train_fpr, train_tpr, thresholds = roc_curve(y_train, lr.predict_proba(x_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, lr.predict_proba(x_test)[:,1])\n\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC CURVE\")\nplt.show()","e4b2965a":"xgb= XGBClassifier()\nxgb.fit(x_train, y_train)\nmodel_score= xgb.predict(x_train)\naccuracy= xgb.predict(x_test)\nstart = time.time()\nxgb.score(x_train, y_train)\nacc_random_forest = round(accuracy_score(y_test,accuracy)*100, 2)\nf1_random_forest = round(f1_score(y_test,accuracy,average = \"binary\")*100, 2)\nf_beta_random_forest = round(fbeta_score(y_test,accuracy,average = \"binary\",beta=0.5)*100, 2)\n\nend = time.time()\nacc_score.append({'Model':'XG boost', 'Score': accuracy_score(y_train, model_score), 'Accuracy': accuracy_score(y_test, accuracy), 'Time_Taken':end - start})","8811bd37":"confusion_matrix(y_test,accuracy)","9f89d333":"tn, fp, fn, tp = confusion_matrix(y_test,accuracy).ravel()\n(tn, fp, fn, tp)","8397a719":"train_fpr, train_tpr, thresholds = roc_curve(y_train, xgb.predict_proba(x_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, xgb.predict_proba(x_test)[:,1])\n\nplt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\nplt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC CURVE\")\nplt.show()","ac50aeb9":"accuracy= pd.DataFrame(acc_score, columns=['Model','Score','Accuracy','Time_Taken'])\naccuracy.sort_values(by='Accuracy', ascending= False, inplace= True)\naccuracy","cf3e24ba":"plt.figure(figsize=(15,8))\nsns.barplot(x= accuracy.Model, y=accuracy.Accuracy);","311339dc":"import pickle","ca42f249":"pickle.dump(estimator1, open('model.pkl','wb'))\n\nmodel = pickle.load(open('model.pkl','rb'))","33757f13":"print(model.predict([[6.542662,2.610838,2.234826,-0.571436,-0.578530,-0.519851,2.832646,2.446318,-0.190910,0,1,1,0,1,1,1,2,2,1,1,1,2,1,1,0.0]]))","e3b8cb40":"### Outpatient","7ae8e3a5":"This seems logical as most of the patients are of an age >65","4012f2ae":"### Average Age for the data set and as a comparison for the probable fradulent activites applied on what age range","c60cc6b8":"Here too we see a similar pattern","4c3f055e":"Calculating the number of days the patient was admitted to the dospital and removing admission and discharge date, For outpatients as they do not get admitted will put number of days admitted = 0","4abf141d":"Looking for the most common procedure codes which are applied for the fradulent and non fradulent services to see any specific pattern","ac82ec8a":"### Checking for missing values in the data set","7fb3e589":"### Logistic Regression","68ff1d94":"### Inpatient data as a whole not just the fradulent activities","c00fd105":"### After Evaluation of Various parameters","42b484b0":"This means from our inpatient dataset for training we can have fradulent activities on more than half of them - 58% are potential fradulent encounters","eb0d87ae":"### Naive Bayes","67b0e222":"### Destandardizing Values","37e3bf3a":"### Inpatient","8a53bbbc":"### Logistic Regression","b27444fb":"### 2. What are the most common procedures and diagnosis codes performed by the potential fradulent providers","c95e139f":"### Naive Bayes","12655d5d":"We see that for inpatient the most common procedure used is 4019, 9904, 2724 among others\n\nWe see that for inpatient the most common Diagnosis used is 4019, 2724,25000 among others","d80ec45f":"### Inpatient","b1aca490":"### Random Forest","af903af9":"### Outpatient","838f21c6":"### Inpatient","f8c68706":"241288510 - around 240 Million dollars worth of claim might have some fradulent activity. Even if we assume that it has just 10% fradulent activity the amount will be quite huge","1a050fb3":"We see that it is a significantly large amount which might be fradulent.","3a925005":"We see a minor difference between the most used diagnosis and procedure codes between inpatient and outpatients\n\nWe see that for inpatient the most common procedure used is 9904, 3722, 4516 among others\n\nWe see that for inpatient the most common Diagnosis used is 4019, 25000, 2724 among others","600c6c38":"### Decision Tree","e4e42e76":"### Inpatient","1e5ab9d1":"### Random Forest","eb118a8f":"This means from our outpatient dataset for training we can have fradulent activities on around 38% of encounters","1785aad0":"So we see there are 189394 outpatient cases that the potential fradulent providers have interacted with at one point or the other during their services at the hospital. This is around 37% of the cases which we have in our inpatient data.","d34cbdb1":"Removing coulmns which are not necessary","aa79634f":"Only the date of death is empty - makes sense for the people who are alive","3266b774":"## Exploratory Data Analysis","0b0a2706":"### 4.Which states\/localities have the highest number of potential frauds","ea082a6d":"### Adding Age Column","52146523":"### Train- Test Split","ff525db8":"### XG Boost","7d888fe4":"### Decision Tree","5dbb8bdc":"### Which were the most used procedure codes and diagnosis codes used by the potential fradulent providers","f2b8bdcb":"So we see there are 23402 admitted(inpatients) cases that the potential fradulent providers have interacted with at one point or the other during their services at the hospital. This is around 58% of the cases which we have in our inpatient data.","281d69c1":"### Outpatient","73ee913f":"### What is the average cost of potential fraud claims and also what is the cost as % of whole. Checking the outliers for such claims"}}