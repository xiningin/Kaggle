{"cell_type":{"ae18c090":"code","61a812bf":"code","d734264d":"code","683abc92":"code","dfd07e9a":"code","75afb624":"code","c6d7a00c":"code","d533466a":"code","279a464d":"code","5382425c":"code","15159490":"code","8eb8fae8":"code","8e408dd0":"code","4897ec09":"code","97b698c3":"code","321de89e":"code","980d9d21":"code","a17cf66e":"code","84b3a601":"code","fe260a80":"code","5d770dbb":"code","a2fb43ef":"code","1adb1d29":"code","195bf946":"code","45cd35b0":"markdown"},"source":{"ae18c090":"import pandas as pd\nimport numpy as np\n\nfrom catboost import CatBoostClassifier\nimport category_encoders as ce\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score","61a812bf":"path = \"..\/input\/tabular-playground-series-apr-2021\/\"\ntrain = pd.read_csv(path+'train.csv', index_col=0)\ntest = pd.read_csv(path+'test.csv', index_col=0)\nsubmission = pd.read_csv(path+'sample_submission.csv')","d734264d":"# Calcule SameFirstName\n\ntrain['FirstName'] = train['Name'].apply(lambda x:x.split(', ')[0])\ntrain['n'] = 1\ngb = train.groupby('FirstName')\ndf_names = gb['n'].sum()\ntrain['SameFirstName'] = train['FirstName'].apply(lambda x:df_names[x])\n\ntest['FirstName'] = test['Name'].apply(lambda x:x.split(', ')[0])\ntest['n'] = 1\ngb = test.groupby('FirstName')\ndf_names = gb['n'].sum()\ntest['SameFirstName'] = test['FirstName'].apply(lambda x:df_names[x])\n\n# To preprocess\n\ndata = pd.concat([train, test], axis=0)\n\n# Before fill missing\ndata['AnyMissing'] = np.where(data.isnull().any(axis=1) == True, 1, 0)\n\n# Family\ndata['FamilySize'] = data['SibSp'] + data['Parch'] + 1\ndata['IsAlone'] = np.where(data['FamilySize'] <= 1, 1, 0)\n\n# Cabin\ndata['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ndata['Cabin'] = data['Cabin'].fillna('X').map(lambda x: x[0].strip())\ncabin_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5,\n             'F': 6, 'G': 7, 'T': 1, 'X': 8}\ndata['Cabin'] = data['Cabin'].str[0].fillna('X').replace(cabin_map)\n\n# Embarked\n#map_Embarked = train.Embarked.mode().item()\ndata['Embarked'] = data['Embarked'].fillna(\"No\")\nconditions = [\n    (data['Embarked']==\"S\"),\n    (data['Embarked']==\"Q\"),\n    (data['Embarked']==\"C\"),\n    (data['Embarked']==\"No\")\n]\nchoices = [0, 1, 2, -1]\ndata[\"Embarked\"] = np.select(conditions, choices)\ndata['Embarked'] = data['Embarked'].astype(int)\n\n# Name\ndata['SecondName'] = data.Name.str.split(', ', 1, expand=True)[1] # to try\ndata['IsFirstNameDublicated'] = np.where(data.FirstName.duplicated(), 1, 0)\n\n# Fare\ndata['Fare'] = data['Fare'].fillna(train['Fare'].median())\n# train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n# [(0.679, 10.04] < (10.04, 24.46] < (24.46, 33.5] < (33.5, 744.66]]\n# From original Titanic:\nconditions = [\n    (data['Fare'] <= 7.91),\n    ((data['Fare'] > 7.91) & (data['Fare'] <= 14.454)),\n    ((data['Fare'] > 14.454) & (data['Fare'] <= 31)),\n    (data['Fare'] > 31)\n]\n\nchoices = [0, 1, 2, 3]\ndata[\"Fare\"] = np.select(conditions, choices)\ndata['Fare'] = data['Fare'].astype(int)\n\n# Fix Ticket\n# data['TicketNum'] = data.Ticket.str.extract(r'(\\d+)').\\\n#                     astype('float64', copy=False) # to_try\ndata['Ticket'] = data.Ticket.str.replace('\\.','', regex=True).\\\n                    str.replace('(\\d+)', '', regex=True).\\\n                    str.replace(' ', '', regex=True).\\\n                    replace(r'^\\s*$', 'X', regex=True).\\\n                    fillna('X')\n\n#data['Ticket'] = data['Ticket'].astype('category').cat.codes # to_try\n\n# Age \nconditions = [\n    ((data.Sex==\"female\")&(data.Pclass==1)&(data.Age.isnull())),\n    ((data.Sex==\"male\")&(data.Pclass==1)&(data.Age.isnull())),\n    ((data.Sex==\"female\")&(data.Pclass==2)&(data.Age.isnull())),\n    ((data.Sex==\"male\")&(data.Pclass==2)&(data.Age.isnull())),\n    ((data.Sex==\"female\")&(data.Pclass==3)&(data.Age.isnull())),\n    ((data.Sex==\"male\")&(data.Pclass==3)&(data.Age.isnull()))\n]\nchoices = data[['Age', 'Pclass', 'Sex']].\\\n            dropna().\\\n            groupby(['Pclass', 'Sex']).\\\n            mean()['Age']\n\ndata[\"Age\"] = np.select(conditions, choices)\n\nconditions = [\n    (data['Age'].le(16)),\n    (data['Age'].gt(16) & data['Age'].le(32)),\n    (data['Age'].gt(32) & data['Age'].le(48)),\n    (data['Age'].gt(48) & data['Age'].le(64)),\n    (data['Age'].gt(64))\n]\nchoices = [0, 1, 2, 3, 4]\n\ndata[\"Age\"] = np.select(conditions, choices)\n\n# Sex\ndata['Sex'] = np.where(data['Sex']=='male', 1, 0)\n\n# Drop columns\ndata = data.drop(['Name', 'n'], axis = 1)\n\n# Transform object to category\n#for col in data.columns[data.dtypes=='object'].tolist():\n#    data.loc[:,col] = data.loc[:,col].astype('category')","683abc92":"# Splitting into train and test\ntrain = data.iloc[:train.shape[0]]\ntest = data.iloc[train.shape[0]:].drop(columns=['Survived'])","dfd07e9a":"train.head(3)","75afb624":"lab_cols = ['Pclass','Age', 'Ticket', 'Fare', 'Cabin', 'Embarked']\ntarget = 'Survived'\n\nX_m = train[train.Sex==1].drop(target, axis=1)\nX_m = X_m[['Pclass', 'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket']]\ny_m = train[train.Sex==1][target]\n\nX_f = train[train.Sex==0].drop(target, axis=1)\nX_f = X_f[['Pclass', 'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket','SameFirstName']]\ny_f = train[train.Sex==0][target]\n\ntest_m = test[test.Sex==1][['Pclass',  'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket']]\ntest_f = test[test.Sex==0][['Pclass',  'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket','SameFirstName']]","c6d7a00c":"def kfold_prediction(X, y, X_test, K, od_wait = 500):\n\n    yp = pd.DataFrame()\n    trs = []\n    acc_trs = []\n    \n    kf = StratifiedKFold(n_splits=K, shuffle=True, random_state=314)\n    \n    for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n        print(f\"\\n FOLD {i} ...\")\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        params = {'loss_function':'Logloss',\n                  'eval_metric': 'AUC', # 'Accuracy'\n                  'od_wait':od_wait,\n                  'od_type':'Iter', \n                  'n_estimators': 10000,\n                  'cat_features': lab_cols,\n                  'verbose': od_wait,\n                  'random_seed': 314\n         }\n        \n        clf = CatBoostClassifier(**params)\n        \n        model_fit = clf.fit(X_train,y_train,\n                            eval_set=[(X_train, y_train), (X_val, y_val)],\n                            use_best_model=True,\n                            plot=False)\n        \n        yp_val = model_fit.predict_proba(X_val)[:, 1]\n        acc = accuracy_score(y_val, np.where(yp_val>0.5, 1, 0))\n        print(f\"- Accuracy before : {acc} ...\")\n        \n        # Moving threshold\n        thresholds = np.arange(0.0, 1.0, 0.01)\n        accuracy_scores = []\n        for thresh in thresholds:\n            accuracy_scores.append(\n                accuracy_score(y_val, [1 if m>thresh else 0 for m in yp_val]))\n\n        accuracies = np.array(accuracy_scores)\n        max_accuracy = accuracies.max() \n        max_accuracy_threshold =  thresholds[accuracies.argmax()] \n        trs = trs + [max_accuracy_threshold]\n        \n        print(\"- Max accuracy threshold: \"+str(max_accuracy_threshold))\n        \n        acc = accuracy_score(y_val, \n                             np.where(yp_val>max_accuracy_threshold, 1, 0)) \n        acc_trs = acc_trs + [acc]\n        print(f\"- Accuracy after: {acc} !\")\n        \n        yp_test = model_fit.predict_proba(X_test)[:, 1]\n        yp_fold = pd.DataFrame({\n            'fold'+str(i): np.where(yp_test>max_accuracy_threshold, 1, 0)})\n        \n        yp = pd.concat([yp, yp_fold], axis=1)\n    \n    return yp, trs, acc_trs","d533466a":"yp_m, trs_m, acc_m = kfold_prediction(X_m, y_m, test_m, 5)","279a464d":"yp_f, trs_f, acc_f = kfold_prediction(X_f, y_f, test_f, 5)","5382425c":"print('Model to Sex==\"male\"')\nprint(\"Final mean and std accuracy: \", np.mean(acc_m), round(np.std(acc_m), 5))\nprint(\"Final mean and std accuracy with Threshold: \", np.mean(trs_m), round(np.std(trs_m), 5))\n\nprint('\\nModel to Sex==\"female\"')\nprint(\"Final mean and std accuracy: \", np.mean(acc_f), round(np.std(acc_f), 5))\nprint(\"Final mean and std accuracy with Threshold: \", np.mean(trs_f), round(np.std(trs_f), 5))","15159490":"def vote(r, columns):\n    \"\"\"https:\/\/www.kaggle.com\/belov38\/catboost-lb\/\"\"\"\n    ones = 0\n    zeros = 0\n    for i in columns:\n        if r[i]==0:\n            zeros+=1\n        else:\n            ones+=1\n    if ones>zeros:\n        return 1\n    else:\n        return 0","8eb8fae8":"submission_sex = pd.concat([\n    pd.DataFrame({\n        'PassengerId' : test_m.index,\n        'Survived':yp_m.apply(lambda x:vote(x, yp_m.columns.tolist()),axis=1)\n    })\n    ,\n    pd.DataFrame({\n        'PassengerId' : test_f.index,\n        'Survived':yp_f.apply(lambda x:vote(x, yp_f.columns.tolist()),axis=1)\n    })    \n]).sort_values('PassengerId').reset_index(drop=True)\n\nsubmission_sex.to_csv('submission_sex.csv', index = False)","8e408dd0":"test['Survived'] = [x for x in submission_sex.Survived]\n\ndata = pd.concat([train, test], axis=0)","4897ec09":"lab_cols = ['Pclass','Age', 'Ticket', 'Fare', 'Cabin', 'Embarked']\ntarget = 'Survived'\n\nX = data.drop(target, axis=1)\nX = X[['Pclass', 'Sex', 'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket','SameFirstName']]\ny = data[target]\n\ntest = test[['Pclass', 'Sex',  'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket','SameFirstName']]","97b698c3":"yp, trs, acc = kfold_prediction(X, y, test, 5, 300)","321de89e":"print('Model with train + pseudo train')\nprint(\"Final mean and std accuracy: \", np.mean(acc), round(np.std(acc), 5))\nprint(\"Final mean and std accuracy with Threshold: \", np.mean(trs), round(np.std(trs), 5))","980d9d21":"submission_pseudo = pd.DataFrame({\n    'PassengerId': test.index,\n    'Survived':yp.apply(lambda x:vote(x, yp.columns.tolist()),axis=1)\n})\n\nsubmission_pseudo.to_csv('submission_pseudo_test.csv', index = False) # best 0.80398 LB","a17cf66e":"lab_cols = ['Pclass','Age', 'Ticket', 'Fare', 'Cabin', 'Embarked']\ntarget = 'Survived'\n\nX_m_pseudo = data[X.Sex==1]\nX_m_pseudo = X_m_pseudo[['Pclass', 'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket']]\ny_m_pseudo = data[data.Sex==1][target]\n\nX_f_pseudo = data[X.Sex==0].drop(target, axis=1)\nX_f_pseudo = X_f_pseudo[['Pclass', 'Age','Embarked','Parch','SibSp','Fare','Cabin','Ticket','SameFirstName']]\ny_f_pseudo = data[data.Sex==0][target]","84b3a601":"yp_m_pseudo, trs_m_pseudo, acc_m_pseudo = kfold_prediction(X_m_pseudo, y_m_pseudo, test_m, 5, 300)","fe260a80":"yp_f_pseudo, trs_f_pseudo, acc_f_pseudo = kfold_prediction(X_f_pseudo, y_f_pseudo, test_f, 5, 300)","5d770dbb":"print('Model to Sex==\"male\" + pseudo train')\nprint(\"Final mean and std accuracy: \", np.mean(acc_m_pseudo), round(np.std(acc_m_pseudo), 5))\nprint(\"Final mean and std accuracy with Threshold: \", np.mean(trs_m_pseudo), round(np.std(trs_m_pseudo), 5))\n\nprint('\\nModel to Sex==\"female\" + pseudo train')\nprint(\"Final mean and std accuracy: \", np.mean(acc_f_pseudo), round(np.std(acc_f_pseudo), 5))\nprint(\"Final mean and std accuracy with Threshold: \", np.mean(trs_f_pseudo), round(np.std(trs_f_pseudo), 5))","a2fb43ef":"submission_sex_pseudo = pd.concat([\n    pd.DataFrame({\n        'PassengerId' : test_m.index,\n        'Survived':yp_m_pseudo.apply(lambda x:vote(x, yp_m_pseudo.columns.tolist()),axis=1)\n    })\n    ,\n    pd.DataFrame({\n        'PassengerId' : test_f.index,\n        'Survived':yp_f_pseudo.apply(lambda x:vote(x, yp_f_pseudo.columns.tolist()),axis=1)\n    })    \n]).sort_values('PassengerId').reset_index(drop=True)\n\nsubmission_sex_pseudo.to_csv('submission_sex_pseudo.csv', index = False)","1adb1d29":"final_predictions = pd.concat([\n    submission_sex.drop(\"PassengerId\", axis = 1).rename(columns={\"Survived\": \"Survived0\"}), \n    submission_pseudo.drop(\"PassengerId\", axis = 1).rename(columns={\"Survived\": \"Survived1\"}), \n    submission_sex_pseudo.drop(\"PassengerId\", axis = 1).rename(columns={\"Survived\": \"Survived2\"})\n    ], axis = 1)","195bf946":"pd.DataFrame({\n        'PassengerId' : test.index,\n        'Survived':final_predictions.apply(lambda x:vote(x, final_predictions.columns.tolist()),axis=1)\n    }).to_csv('submission_final.csv', index = False)","45cd35b0":"# Problem definition\n\nThe dataset is used for this competition is synthetic but based on a real dataset (in this case, the actual Titanic data!) and generated using a CTGAN.\n\nData description: \n\n| Variable        | Definition           | Key  |\n|---------------|:-------------|------:|\n|survival |\tSurvival | 0 = No, 1 = Yes |\n|pclass |\tTicket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n|sex |\tSex\t ||\n|Age |\tAge in years\t ||\n|sibsp |\t# of siblings \/ spouses aboard the Titanic\t ||\n|parch |\t# of parents \/ children aboard the Titanic\t ||\n|ticket |\tTicket number\t ||\n|fare |\tPassenger fare\t ||\n|cabin |\tCabin number\t| |\n|embarked |\tPort of Embarkation\t| C = Cherbourg, Q = Queenstown, S = Southampton |\n\n<br>\n\nWhere `survival` will be our target variable! \ud83c\udfaf\n\n<br>\n\nCheck out: \n\n  \u279c [Tuning of a Lightgbm with Bayesian Optimization using the `tidymodels` framework in R](https:\/\/www.kaggle.com\/gomes555\/tps-apr2021-r-eda-lightgbm-bayesopt)\n\n  \u279c [AutoML (lgbm + catboost) with mljar](https:\/\/www.kaggle.com\/gomes555\/tps-apr2021-autoboost-mljar)\n  \n  \u279c [Feature Selection with RFE + Boruta](https:\/\/www.kaggle.com\/gomes555\/tps-apr2021-feature-selection-rfe-boruta)\n  \n  \u279c [Simple CatBoost + Preprocess](https:\/\/www.kaggle.com\/gomes555\/tps-apr2021-simple-catboost)\n  \n<br>\n\n<p align=\"right\"><span style=\"color:firebrick\">Dont forget the upvote if you liked the notebook! \u270c\ufe0f <\/p>"}}