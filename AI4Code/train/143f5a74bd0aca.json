{"cell_type":{"05c2b3d4":"code","b3fc0d30":"code","8543d9ca":"code","f166ec8c":"code","c3954cb9":"code","7951392b":"code","573d590a":"code","ab9b72ef":"code","7731cb08":"code","1630383e":"code","84db5da7":"code","d532ed2f":"code","75c08a2a":"code","758662ed":"code","5b89b431":"code","67c81f1e":"code","c00ff8ce":"code","adf99ced":"code","d91a2514":"code","e4ea4eee":"code","6dc24125":"code","8645ff6e":"code","48c8ae34":"code","7e15d5d6":"code","87249863":"code","63a36a71":"code","83ce39db":"code","9881bcc4":"markdown","c56b873a":"markdown","93166475":"markdown","47da6a72":"markdown","e4c1259d":"markdown","85e08204":"markdown","a0991f63":"markdown","5c52d067":"markdown"},"source":{"05c2b3d4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n# import matplotlib.image as Image\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras","b3fc0d30":"direcory_train = '..\/input\/petfinder-pawpularity-score\/train\/'\ndirectory_test = '..\/input\/petfinder-pawpularity-score\/test\/'\n\ncsv_train = '..\/input\/petfinder-pawpularity-score\/train.csv'\ncsv_test = '..\/input\/petfinder-pawpularity-score\/test.csv'","8543d9ca":"data = pd.read_csv(csv_train)\ndata.head()","f166ec8c":"data.info()","c3954cb9":"data.describe()","7951392b":"fig = plt.figure(figsize=(20,5))\narr, bins, patches = plt.hist(data.Pawpularity, bins = 199)\nplt.xticks(range(1,101), rotation=90)\nplt.show()","573d590a":"pawpularity_0 = data[data.Pawpularity <= 5]\npawpularity_30 = data[(data.Pawpularity >= 25) & (data.Pawpularity <= 35)]\npawpularity_100 = data[data.Pawpularity >= 95]","ab9b72ef":"def show_images(paws):\n    fig = plt.figure(figsize=(10,10), constrained_layout=True)\n    grids = fig.add_gridspec(3,3)\n    \n    for i in range(3):\n        for j in range(3):\n            img = Image.open(direcory_train + paws.Id.iloc[i*3 + j] + '.jpg')\n            ax = fig.add_subplot(grids[i,j])\n            ax.imshow(img)\n    \n    plt.show()","7731cb08":"print('Pawpularity <= 5')\nshow_images(pawpularity_0)","1630383e":"print('Pawpularity >= 25 and <=35')\nshow_images(pawpularity_30)","84db5da7":"print('Pawpularity >= 95')\nshow_images(pawpularity_100)","d532ed2f":"data_np = []\ntarget = data.Pawpularity\n\nimg_shape = (250,250,3)","75c08a2a":"def make_nparray(data, directory):\n    im_array = np.zeros((data.shape[0], img_shape[0], img_shape[1], 3), dtype=np.uint8)\n    \n    for i in range(data.shape[0]):\n        img = Image.open(directory + data.Id.iloc[i] + '.jpg')\n        img = img.resize((img_shape[0], img_shape[1]))\n        im_array[i] = np.array(img, dtype=np.uint8)\n    \n    return im_array","758662ed":"# Run this on kaggle notebook\ndata_np = make_nparray(data, direcory_train)","5b89b431":"# No need to run this on local machine. simply save and load from local machine!\n\ndef load_data():\n    global data_np\n    \n    import pickle\n\n    # data_file = open('data_file.pkl', 'wb')\n    # pickle.dump(data_np, data_file)\n    # data_file.close()\n\n    data_file = open('data_file.pkl', 'rb')\n    data_np = pickle.load(data_file)\n    data_file.close()\n\n# load_data()","67c81f1e":"start_lr = 0.000625\nmin_lr = 0.00001\nmax_lr = 0.001\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        lr = (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n        return lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nrang = np.arange(15)\ny = [lrfn(x) for x in rang]\nplt.plot(rang, y)\nprint('Learning rate per epoch:')","c00ff8ce":"def make_model_with_metadata(lr, epoch, meta):\n    \n    mobileNet = keras.applications.MobileNetV2(input_shape=img_shape,\n                                               include_top=False,\n                                               weights=None\n                                              )\n    meta_in = keras.layers.Input((12,))\n    X = keras.layers.GlobalAveragePooling2D()(mobileNet.output)\n    X = keras.layers.BatchNormalization()(X)\n    X = keras.layers.Flatten()(X)\n    X = keras.layers.Concatenate()([X, meta_in])\n    X = keras.layers.Dense(100)(X)\n    X = keras.layers.BatchNormalization()(X)\n    X = keras.layers.Dense(1)(X)\n    \n    opt = keras.optimizers.Adam(lr)\n    model = keras.models.Model(inputs = [mobileNet.input, meta_in], outputs = X)\n    \n    model.compile(optimizer=opt, loss='mean_squared_error', metrics= ['mean_squared_error'])\n    \n    return model","adf99ced":"meta_data = data.loc[:, 'Subject Focus':'Blur']\nmeta_data_np = np.array(meta_data)","d91a2514":"meta_model = make_model_with_metadata(0.0001, 1, meta_data_np)\nmeta_model.summary()","e4ea4eee":"es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)","6dc24125":"meta_model.fit(x=[data_np, meta_data_np],\n               y=target, batch_size=12,\n               epochs=20,\n               validation_split=0.15,\n               workers=6,\n               callbacks=[lr_callback, es_callback])\n\ndel meta_data_np\ndel data_np","8645ff6e":"test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","48c8ae34":"test_np = make_nparray(test, directory_test)","7e15d5d6":"test_meta = test.loc[:, 'Subject Focus':]\ntest_meta = np.array(test_meta)","87249863":"predictions = meta_model.predict([test_np, test_meta])\nsubmission = pd.DataFrame(predictions, columns=['Pawpularity'])\nsubmission['Id'] = test.Id\nsubmission.head()","63a36a71":"submission.to_csv('submission.csv', index=False)","83ce39db":"# from tensorflow.python.client import device_lib\n# print(device_lib.list_local_devices())","9881bcc4":"## Convert images to nparray","c56b873a":"## Predict","93166475":"## Load Test","47da6a72":"### View some images with low and high pawpularity","e4c1259d":"## Train","85e08204":"## Output","a0991f63":"## EDA","5c52d067":"## Import"}}