{"cell_type":{"bdbd87de":"code","e0946a44":"code","79378603":"code","4c98e6a4":"code","cb257ef6":"code","21f37107":"code","13940f30":"code","875631b7":"code","7b26425b":"code","dd664e25":"code","839e67d8":"code","2fae945e":"code","2df280bf":"code","0172bc5e":"code","4b4250cd":"code","b72fc5ce":"code","57a79f2d":"code","d8daa8e6":"code","8783a81f":"code","54fbd924":"code","6e88b789":"code","3fc88737":"code","7369807d":"code","3f3eb3fe":"code","95f78b27":"code","cd385456":"code","cf12a5bc":"markdown","ceba81e2":"markdown","306cf2fd":"markdown","82865c7e":"markdown","4bf53a33":"markdown","b135d7c3":"markdown","9f4f1d76":"markdown","a5a502ac":"markdown","e919f3b9":"markdown","ebcca871":"markdown","32b750ba":"markdown","a9a0def1":"markdown","2a23dc1e":"markdown","2c3f42f2":"markdown","014ca634":"markdown","bcdb091f":"markdown","38e44f3f":"markdown","8a0874fa":"markdown","3ccee69b":"markdown","69534987":"markdown","8b7e9f9e":"markdown","acd6e1fb":"markdown","b944d51d":"markdown","c0eda6e9":"markdown"},"source":{"bdbd87de":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","e0946a44":"data = pd.read_csv('..\/input\/autism-screening-on-adults\/autism_screening.csv')\nprint(data.info())\nprint(data.info)","79378603":"data.replace('?', np.nan, inplace=True)\ndata = data.drop(columns = ['used_app_before'])\ndata = data.drop(columns = ['age_desc'])\ndata = data.rename(columns={'Class\/ASD' : 'classASD'})\ndata = data.rename(columns={'austim' : 'autism'})\ndata = data.rename(columns={'contry_of_res' : 'country_of_res'})\ndata.info()","4c98e6a4":"print(data['result'].describe())\nsns.displot(data['result'], bins=50, kde = False)","cb257ef6":"print(data['age'].describe())\nsns.displot(data['age'], bins=50, kde = False)","21f37107":"data.loc[data.age == 383, 'age'] = 38\ndata['age'].fillna(data['age'].mode()[0], inplace=True)","13940f30":"data.age = data.age.astype(int)\ndata.result = data.result.astype(int)\ndata = data.fillna(data.mode().iloc[0])\ndata.info()\ndata.head()","875631b7":"data = data.drop(columns = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', ])","7b26425b":"plt.figure(figsize = (15, 15))\nsns.countplot(x = 'classASD', hue = 'gender', data = data)\nplt.show()","dd664e25":"plt.figure(figsize = (15, 15))\nsns.countplot(x = 'classASD', hue = 'ethnicity', data = data)\nplt.show()","839e67d8":"plt.figure(figsize = (30, 20))\nsns.countplot(x = 'classASD', hue = 'country_of_res', data = data)","2fae945e":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['ethnicity'] = le.fit_transform(data['ethnicity'])\ndata['jundice'] = le.fit_transform(data['jundice'])\ndata['autism'] = le.fit_transform(data['autism'])\ndata['country_of_res'] = le.fit_transform(data['country_of_res'])\ndata['relation'] = le.fit_transform(data['relation'])\ndata['classASD'] = le.fit_transform(data['classASD'])\ndata['gender'] = le.fit_transform(data['gender'])\ndata['age'] = le.fit_transform(data['age'])\n","2df280bf":"data.head()","0172bc5e":"corrMatrix = data.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","4b4250cd":"data = data.drop(columns = ['gender', 'country_of_res', 'relation'])","b72fc5ce":"data.classASD.hist()","57a79f2d":"X = data.drop(columns = 'classASD')\nY = data['classASD']","d8daa8e6":"from sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()  \nscaler.fit(X)  \nX = scaler.transform(X)  ","8783a81f":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(3, 2), random_state=1, max_iter=10000)\nclf.fit(X, Y)\nMLPClassifier(alpha=1e-3, hidden_layer_sizes=(3, 2), random_state=1, solver='adam', max_iter=10000)","54fbd924":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(clf, X, Y, cv=5)","6e88b789":"print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))","3fc88737":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(3, input_dim = 5, activation='relu'))\nmodel.add(Dense(3, activation = 'relu'))","7369807d":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, Y, epochs = 200, batch_size = 10, verbose = 0)\n_, accuracy = model.evaluate(X, Y)\nprint('Accuracy: %.4f' % (accuracy * 100))","3f3eb3fe":"from sklearn.utils import check_random_state\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","95f78b27":"lx = data.drop(columns = ['classASD'])\nly = data['classASD']\nlx_train, lx_test, ly_train, ly_test = train_test_split(lx, ly, test_size=0.2)","cd385456":"lx_train = scaler.fit_transform(lx_train)\nlx_test = scaler.fit_transform(lx_test)\nlogReg = LogisticRegression(C = 50. \/ 10000, penalty='l1', solver='liblinear', tol=0.1)\nlogReg.fit(lx_train, ly_train)\nsparsity = np.mean(logReg.coef_ == 0) * 100\nscore = logReg.score(lx_test, ly_test)\n\nprint(\"Test score with L1 penalty: %.4f\" % score)","cf12a5bc":"This looks like a more propable accuracy. Now lets look how a simple Logistic Regression will solve that problem","ceba81e2":"First model - MLPClassifier from sklearn library.","306cf2fd":"It looks like women are more often classified on ASD, but not but a whole lot. Lets look at ethicities next.","82865c7e":"Lets take a look at classASD histogram. If the proportion was not balanced enough, models could learn to always just guess one anwser, and we want something more complicated than that.","4bf53a33":"Now lets try with keras Sequential model\njust to be fair, same amount of layers, tuples, and same solver","b135d7c3":"As we can see, most cases are in USA and UK. But are those two observations real coreallations or pure coincidence?\nWe will take a look at that now.\nFirst, i will convert all strings to integers (unique integer for each of possible strings) using LabelEncoder.","9f4f1d76":"I will start with scaling features.","a5a502ac":"I've noticed that instead of NaN there are question marks when data is missing, we will deal with that.\nAlso, i will drop a few columns that i consider not important from the get go and rename others, for simplicity sake","e919f3b9":"It looks like White-European adults are visibly more often classified on ASD\nNow lets take a look at nationality.","ebcca871":"result and classASD have a really strong correlation. Othe columns aren't nearly as correlated as \"result\".\ni shall drop all columns with weaker correlation than 0.1","32b750ba":"alpha = 0.001, 2 layers with 3 tuples may seem a little too little, but it will be more than enough.\nI will cross-validate that model 5 times.","a9a0def1":"I will try guessing if someone is classified on Autism Spectrum Disorder, which is our \"classASD\" collumn.\nLets see some data about gender, ethnicity and nationality","2a23dc1e":"And now, we can create correlation matrix for all our data","2c3f42f2":"Now, changing data types and fill all other blanks with first values of their columns.\nThere arent that many missing values, so it wont hurt our models that much.","014ca634":"Its hard to believe that someone would be 383 years old and still alive, so i will consider it as a typo and change it to 38.\nAlso two records are missing and i would like change result and age data type to integer, so i will fill all blanks with first value.","bcdb091f":"lets take a look how our data looks now","38e44f3f":"As i mentioned earlier, \"result\" is a sum of scores from A1 to A10, so we dont really need all columns for all scores.","8a0874fa":"Looks good enough for me, now i will separate data for features (X) and anwser (Y)","3ccee69b":"spliting test and train datasets in 8:2 ratio","69534987":"First, loading our data and looking into it","8b7e9f9e":"Thats a really good score, a little too good. Its because of such a big correlation of \"result\" and \"classASD\". Either our model is that good, or its overfitting.","acd6e1fb":"Now lets take a look at results of test","b944d51d":"Looks like its almost the same anwser as for keras model","c0eda6e9":"As we can see, all values of result are between 0 and 10. They are a sum of scores from A1 to A10\n\nWe know that this operate on data from adults. Lets take a look at their age ratio"}}