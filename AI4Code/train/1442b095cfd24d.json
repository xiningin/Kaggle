{"cell_type":{"d9e2af9d":"code","1117ee60":"code","9925e396":"code","f8c16210":"code","505a6d95":"code","6e28ba21":"code","9163c347":"code","c40269ee":"code","ee58be1a":"code","08ebb28b":"code","73d3820e":"code","06ef8ee2":"code","abb7043b":"code","1f12d9d9":"code","3399bdf1":"code","dd52de49":"code","9e0b440f":"code","da65d0d1":"code","606e7556":"code","f936596c":"code","6d2b1d6c":"code","6eb0c771":"code","fdaa9ef6":"markdown","aca965ac":"markdown","1f578c73":"markdown","e7dc7581":"markdown","e36d3237":"markdown","fc4fe1d9":"markdown","5432a7ee":"markdown","be188148":"markdown","61dc02b5":"markdown","8c660264":"markdown","c553a9a8":"markdown","8e60dd99":"markdown","9df2670e":"markdown","1e31f6ad":"markdown","9fa56a59":"markdown","b70f2e90":"markdown","677974fa":"markdown"},"source":{"d9e2af9d":"# importing Tensorflow 2.x\nimport tensorflow as tf\nprint(\"We are using the Tensorflow Version {}\".format(tf.__version__))","1117ee60":"#importing required packages \nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport datetime","9925e396":"#importing the Fashion MNIST dataset from keras\nfrom tensorflow.keras.datasets import fashion_mnist as dataset","f8c16210":"(X_train, y_train), (X_test, y_test) = dataset.load_data()","505a6d95":"print(\"The shape of the X_train is {}\".format( X_train.shape))\nprint(\"The shape of the y_train is {}\".format(y_train.shape))\nprint(\"The shape of the X_test is {}\".format(X_test.shape))\nprint(\"The shape of the y_test is {}\".format(y_test.shape))","6e28ba21":"#Let's have a look at the first image from our X_train and the \n# corresponding label from y_train\nprint(\"The First Image has the label {}\".format(y_train[0]))\nplt.imshow(X_train[0])\nplt.colorbar()\nplt.title('Visualization of the Dataset')\nplt.show()","9163c347":"#Normalizing the train and test image data\nX_train = X_train\/255.0\nX_test = X_test\/ 255.0","c40269ee":"#Let's again have a look at the first image from our X_train and\n#see if we have successfully normalized the datasets\nplt.imshow(X_train[0])\nplt.colorbar()\nplt.title('Visualization of the Dataset')\nplt.show()","ee58be1a":"#Splitting the training fdataset into train and validation datasets\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=0)","08ebb28b":"print(\"The shape of the X_train is {}\".format(X_train.shape))\nprint(\"The shape of the y_train is {}\".format(y_train.shape))\nprint(\"The shape of the X_valid is {}\".format(X_valid.shape))\nprint(\"The shape of the y_valid is {}\".format(y_valid.shape))","73d3820e":"#Before proceeding, we need to reshape our images in the dataset\nX_train = X_train.reshape(X_train.shape[0], *(28,28,1))\nX_valid = X_valid.reshape(X_valid.shape[0], *(28,28,1))\nX_test = X_test.reshape(X_test.shape[0], *(28,28,1))","06ef8ee2":"#Let's now have a look at the shapes\nprint(\"The shape of the X_train is {}\".format(X_train.shape))\nprint(\"The shape of the X_valid is {}\".format(X_valid.shape))\nprint(\"The shape of the X_test is {}\".format(X_test.shape))","abb7043b":"#Let's define our CNN model\n\nCNN_model = Sequential([\n                        #First Convolution Layer\n                        Conv2D(filters=32,kernel_size=(3,3),\n                               activation=tf.keras.layers.LeakyReLU(alpha=0.01),\n                               kernel_initializer='he_normal',\n                               input_shape=(28,28,1)),\n                        \n                        MaxPool2D(pool_size=(2,2)),\n                        Dropout(0.5),\n\n                        #Second Convolution Layer\n                        Conv2D(filters=64,kernel_size=(3,3),\n                               kernel_initializer='he_normal',\n                               activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n                        \n                        MaxPool2D(pool_size=(2,2)),\n                        Dropout(0.4),\n\n                        #Third Convolution Layer\n                        Conv2D(filters=128,kernel_size=(3,3),\n                               kernel_initializer='he_normal',\n                               activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n                        \n                        MaxPool2D(pool_size=(2,2)),\n                     \n\n                        #Flattening the output from last conv layer\n                        Flatten(),\n\n                        #Using Feed Forward NN as final layers for Classification\n                        #Feed Forward Layer 1\n                        Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.001)),\n\n                        #Feed Forward Layer 2\n                        Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.001)),\n\n                        #Feed Forward Layer 3\n                        Dense(32, activation='relu'),\n\n                        #Output Layer\n                        Dense(10, 'softmax')\n])","1f12d9d9":"#Let's compile our CNN model\nloss_function = 'sparse_categorical_crossentropy'\nLEARNING_RATE = 0.001\nCNN_model.compile(\n    loss = loss_function,\n    optimizer = Adam(lr=LEARNING_RATE),\n    metrics = [\"accuracy\"]\n)","3399bdf1":"#Load the TensorBoard Notebook extension\n%load_ext tensorboard","dd52de49":"# Create the \"logdir\" for visualizing the Data\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n#Get the TensorBoard instance\n#We will use this instance during the training process\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)","9e0b440f":"#Starting the TensorBoard before training to monitor the progress\n%tensorboard --logdir logs","da65d0d1":"history = CNN_model.fit(x=X_train, \n            y=y_train, \n            epochs=100, \n            validation_data=(X_valid, y_valid))\n\n\"\"\"\nUse this will working with TensorBoard\n\nhistory = CNN_model.fit(x=X_train, \n            y=y_train, \n            epochs=100, \n            validation_data=(X_valid, y_valid), \n            callbacks=[tensorboard_callback])\n\"\"\"","606e7556":"# Plot the training Loss and Validation Loss\nplt.plot(history.history['loss'],label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc=\"best\")\nplt.show()","f936596c":"score = CNN_model.evaluate(x=X_test, y=y_test, verbose=0)","6d2b1d6c":"print(\"The loss on the test set is {}\".format(score[0]))\nprint(\"The accuracy on the test set is {}\".format(score[1]))","6eb0c771":"#Saving the model\nCNN_model.save('\/content\/sample_data\/Model')\n\n#Saving the weights\nCNN_model.save_weights('\/content\/sample_data\/ModelWeights')","fdaa9ef6":"## Training the Model","aca965ac":"Previously, we had the shape **(x,28,28)** for X_train, X_valid and X_test. Notice that, after reshaping, these have the shapes **(x,28,28,1)**. The one at the end denotes that we have grayscale images and the number of channels we have is one. This reshaping of image data is important because our model will take the input with 4 integer shape. The 3 integer input shape will result in error. ","1f578c73":"## Importing the dataset and required packages","e7dc7581":"# Image Classification on Fashion MNIST with TensorFlow and TensorBoard\n\n","e36d3237":"From the colorbar in the above visualization, it is clear that we have grayscale images in the dataset and hence their values range from 0 to 255. However, we would like to scale these pixel values in our dataset so that the values range from 0 to 1. This will help us to converge our CNN training faster","fc4fe1d9":"## Saving the model","5432a7ee":"## Data Preprocessing","be188148":"## Evaluation on the Test Set","61dc02b5":"## Set up the Tensorboard","8c660264":"Number of Images in the Train Dataset - 60,000\n\nNumber of Images in the Test Dataset - 10,000\n\nSize of each Image - (28,28)\n\nType of Image - Grayscale Image\n\nNumber of Labels - 10\n\n\n~~~\nLabel\tDescription\n0\t    T-shirt\/top\n1\t    Trouser\n2\t    Pullover\n3\t    Dress\n4\t    Coat\n5\t    Sandal\n6\t    Shirt\n7\t    Sneaker\n8\t    Bag\n9\t    Ankle boot\n~~~","c553a9a8":"The original MNIST dataset contains a lot of handwritten digits. People from AI\/ML\/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset they would try on. ***\u201cIf it doesn\u2019t work on MNIST, it won\u2019t work at all\u201d***, they said. ***\u201cWell, if it does work on MNIST, it may still fail on others.\u201d*** Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset to benchmark machine learning algorithms, as it shares the same image size and the structure of training and testing splits.","8e60dd99":"## References","9df2670e":"## The CNN Model","1e31f6ad":"* https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\n\n* https:\/\/github.com\/markjay4k","9fa56a59":"## About the Dataset","b70f2e90":"Note that the TensorBoard Feature may encounter problems on Kaggle.\n\nIt's more advisable to download this notebook and use it on Google Colab or your local machine","677974fa":"Run the cells in this section if you want to use TensorBoard"}}