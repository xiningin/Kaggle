{"cell_type":{"2f78d37a":"code","99935605":"code","307c6fd3":"code","ae503c9f":"code","935964f5":"code","89f1ab27":"code","80731af1":"code","190b2790":"code","d561214d":"code","10c8229b":"code","1dc10762":"code","e2a8f42d":"code","440bcf6e":"code","b408dd70":"code","55edb6eb":"code","2c138170":"code","61cfed2d":"code","b0016560":"code","d722b81e":"code","243ee23c":"code","f806d116":"code","96d9d161":"code","74a3811a":"code","4112e550":"code","1fb0d21a":"code","3c09c2d7":"code","7e63ee81":"code","05a84349":"code","934d9d17":"code","8597ced9":"code","6ff41390":"code","92367dc5":"code","3e9758db":"code","ed354cd8":"code","2d72658f":"code","cbf03e2f":"code","679b429a":"code","968102d5":"code","9396e0b6":"code","c7fa5995":"code","d8b501da":"code","2e0d02d8":"code","f802c737":"code","528dea2d":"code","cd033296":"code","2df9b628":"code","ef98e4fd":"code","33ae62bc":"code","6b10fb46":"code","d6fc7ae0":"code","46a383a8":"code","1fd3f10a":"code","4fcdde95":"code","0b09ebb6":"markdown","083abf00":"markdown","18b2b49b":"markdown","6101975a":"markdown","b05f3904":"markdown","0848549b":"markdown","923d2ce3":"markdown","7a33a97b":"markdown","733e151c":"markdown","8e848296":"markdown","06a87383":"markdown","d5d96f63":"markdown","2c0682d8":"markdown","265c0c97":"markdown","6d24f839":"markdown","f5d698a0":"markdown","e55976be":"markdown","7b95cece":"markdown","02e4015d":"markdown","8054cdae":"markdown","1fc7c4ef":"markdown","d6762962":"markdown"},"source":{"2f78d37a":"# preprocessing\nimport numpy as np\nimport pandas as pd \n\n# graph\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\n# model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\n\n# evaluation\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom bayes_opt import BayesianOptimization\n\n# utils\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","99935605":"seed = 223","307c6fd3":"train_act = pd.read_csv('\/kaggle\/input\/train_activity.csv')\ntrain_pay = pd.read_csv('\/kaggle\/input\/train_payment.csv')\ntrain_pledge = pd.read_csv('\/kaggle\/input\/train_pledge.csv')\ntrain_trade = pd.read_csv('\/kaggle\/input\/train_trade.csv')\ntrain_combat = pd.read_csv('\/kaggle\/input\/train_combat.csv')\nprint('train activity shape: ',train_act.shape)\nprint('train payment shape: ',train_pay.shape)\nprint('train pledge shape: ',train_pledge.shape)\nprint('train trade shape: ',train_trade.shape)\nprint('train combat shape: ',train_combat.shape)","ae503c9f":"test1_act = pd.read_csv('\/kaggle\/input\/test1_activity.csv')\ntest1_pay = pd.read_csv('\/kaggle\/input\/test1_payment.csv')\ntest1_pledge = pd.read_csv('\/kaggle\/input\/test1_pledge.csv')\ntest1_trade = pd.read_csv('\/kaggle\/input\/test1_trade.csv')\ntest1_combat = pd.read_csv('\/kaggle\/input\/test1_combat.csv')\nprint('test1 activity shape: ',test1_act.shape)\nprint('test1 payment shape: ',test1_pay.shape)\nprint('test1 pledge shape: ',test1_pledge.shape)\nprint('test1 trade shape: ',test1_trade.shape)\nprint('test1 combat shape: ',test1_combat.shape)","935964f5":"test2_act = pd.read_csv('\/kaggle\/input\/test2_activity.csv')\ntest2_pay = pd.read_csv('\/kaggle\/input\/test2_payment.csv')\ntest2_pledge = pd.read_csv('\/kaggle\/input\/test2_pledge.csv')\ntest2_trade = pd.read_csv('\/kaggle\/input\/test2_trade.csv')\ntest2_combat = pd.read_csv('\/kaggle\/input\/test2_combat.csv')\nprint('test2 activity shape: ',test2_act.shape)\nprint('test2 payment shape: ',test2_pay.shape)\nprint('test2 pledge shape: ',test2_pledge.shape)\nprint('test2 trade shape: ',test2_trade.shape)\nprint('test2 combat shape: ',test2_combat.shape)","89f1ab27":"train_label = pd.read_csv('\/kaggle\/input\/train_label.csv')\nprint('train_label shape: ',train_label.shape)","80731af1":"def add_feature_ma3_diff(feature, data, x_df, name):\n    # groupby acc_id, day and sum\n    f_df = data.groupby(['acc_id','day'])[feature].sum().reset_index()\n    \n    # make moving average 3 and calculate difference ma3 and feature values\n    f_df['ma3'] = f_df.groupby('acc_id')[feature].rolling(3, min_periods=1).mean().values\n    f_df['{}_diff'.format(feature)] = f_df['ma3'] - f_df[feature]\n    \n    # extract last day values\n    max_idx = f_df.groupby('acc_id').day.idxmax()\n    f_df = f_df.iloc[max_idx, :][['acc_id','{}_diff'.format(feature)]]\n    \n    # left join on acc_id\n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left')\n    print('add {} ma3 diff - {} shape: {}'.format(feature, name, x_df.shape))\n    \n    return x_df","190b2790":"def add_feature_cnt(feature, data, x_df, feature_name, name):\n    '''\n    add_feature_cnt : \uc774\uac70\ub294 \ubb34\uc2a8 \ud568\uc218\n    '''\n    f_df = data[['acc_id',feature]].drop_duplicates().groupby('acc_id').count().reset_index()\n    f_df = f_df.rename(columns={feature:'{}_cnt'.format(feature_name)})\n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left')\n    print('add {} count - {} shape: {}'.format(feature_name, name, x_df.shape))\n    return x_df","d561214d":"def add_day_total_cnt(data, x_df, feature_name, name):\n    f_df = data.groupby(['acc_id','server','char_id']).day.count().reset_index().groupby('acc_id').day.sum().reset_index()\n    f_df = f_df.rename(columns={'day':'{}_total_cnt'.format(feature_name)})\n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left')\n    print('add {} total count - {} shape: {}'.format(feature_name, name, x_df.shape))\n    return x_df","10c8229b":"def add_char_id_total_cnt(data, x_df, feature_name, name):\n    f_df = data[['acc_id','server','char_id']].drop_duplicates().groupby('acc_id').char_id.count().reset_index()\n    f_df = f_df.rename(columns={'char_id':'{}_total_cnt'.format(feature_name)})\n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left')\n    print('add {} total count - {} shape: {}'.format(feature_name, name, x_df.shape))\n    return x_df","1dc10762":"def add_trade_categorical_cnt(feature, user_type, x_df, name):\n    f_df = train_trade[[user_type,feature]].pivot_table(index=[user_type,feature], aggfunc='size').reset_index()\n    f_df = f_df.set_index([user_type,feature]).unstack()\n    # change names\n    f_df.columns = ['{}_{}'.format(user_type.split('_')[0], c[1]) for c in f_df.columns]\n    f_df = f_df.reset_index().rename(columns={user_type:'acc_id'})\n    \n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left').fillna(0)\n    print(\"add {}'s {} - {} shape: {}\".format(user_type, feature, name, x_df.shape))\n    \n    return x_df","e2a8f42d":"def add_trade_day_cnt_diff(user_type, x_df, name):\n    type_name = user_type.split('_')[0]\n    f_df = train_trade[[user_type,'day']].pivot_table(index=[user_type,'day'], aggfunc='size').reset_index()\n    trd_total = f_df.groupby(user_type)[0].sum().reset_index().rename(columns={0:'{}_trd_cnt'.format(type_name)})\n    trd_7 = f_df[f_df.day>21].groupby(user_type)[0].sum().reset_index().rename(columns={0:'{}_trd7_cnt'.format(type_name)})\n\n    # calc trd count and trd diff\n    f_df = pd.merge(trd_total, trd_7, on=user_type, how='left').fillna(0)\n    f_df['{}_trd_diff'.format(type_name)] = f_df['{}_trd_cnt'.format(type_name)] - f_df['{}_trd7_cnt'.format(type_name)]\n    f_df = f_df.rename(columns={user_type:'acc_id'})\n    f_df = f_df[['acc_id','{}_trd_cnt'.format(type_name),'{}_trd_diff'.format(type_name)]]\n    \n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left').fillna(0)\n    print(\"add {}'s day - {} shape: {}\".format(user_type, name, x_df.shape))\n        \n    return x_df","440bcf6e":"def add_trade_feature_sum_diff(feature, user_type, x_df, name):\n    type_name = user_type.split('_')[0]\n    f_df = train_trade.groupby([user_type,'day'])[feature].sum().reset_index()\n    f_total = f_df.groupby(user_type)[feature].sum().reset_index().rename(columns={feature:'{}_{}_sum'.format(type_name, feature)})\n    f_7 = f_df[f_df.day>21].groupby(user_type)[feature].sum().reset_index().rename(columns={feature:'{}_{}_sum7'.format(type_name, feature)})\n\n    # calc f count and f diff\n    f_df = pd.merge(f_total, f_7, on=user_type, how='left').fillna(0)\n    f_df['{}_{}_diff'.format(type_name, feature)] = f_df['{}_{}_sum'.format(type_name, feature)] - f_df['{}_{}_sum7'.format(type_name, feature)]\n    f_df = f_df.rename(columns={user_type:'acc_id'})\n    f_df = f_df[['acc_id','{}_{}_sum'.format(type_name, feature),'{}_{}_diff'.format(type_name, feature)]]\n    \n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left').fillna(0)\n    print(\"add {}'s {} sum and diff 7 - {} shape: {}\".format(user_type, feature, name, x_df.shape))\n        \n    return x_df","b408dd70":"def add_feature_daily_calc(feature, data, x_df, calc, name):\n    f_df = data.groupby(['acc_id','day'])[feature].sum().reset_index()\n    if calc == 'mean':\n        f_df = f_df.groupby('acc_id')[feature].mean().reset_index()\n        f_df = f_df.rename(columns={feature:'{}_mean'.format(feature)})\n    elif calc == 'median':\n        f_df = f_df.groupby('acc_id')[feature].median().reset_index()\n        f_df = f_df.rename(columns={feature:'{}_median'.format(feature)})\n    elif calc == 'std':\n        f_df = f_df.groupby('acc_id')[feature].std().reset_index()\n        f_df = f_df.rename(columns={feature:'{}_std'.format(feature)})\n    elif calc == 'max':\n        f_df = f_df.groupby('acc_id')[feature].max().reset_index()\n        f_df = f_df.rename(columns={feature:'{}_max'.format(feature)})\n    elif calc == 'min':\n        f_df = f_df.groupby('acc_id')[feature].min().reset_index()\n        f_df = f_df.rename(columns={feature:'{}_min'.format(feature)})\n        \n    x_df = pd.merge(x_df, f_df, on='acc_id', how='left')\n    print(\"add {} {} - {} shape: {}\".format(feature, name, calc, x_df.shape))\n    \n    return x_df","55edb6eb":"train = train_act[['acc_id']].drop_duplicates().copy()\ntest1 = test1_act[['acc_id']].drop_duplicates().copy()\ntest2 = test2_act[['acc_id']].drop_duplicates().copy()\nprint('train shape: ',train.shape)\nprint('test1 shape: ',test1.shape)\nprint('test2 shape: ',test2.shape)","2c138170":"# train\ntrain = add_feature_cnt('day', train_act, train, 'act_day', 'train')\ntrain = add_feature_cnt('day', train_combat, train, 'combat_day', 'train')\n# test1\ntest1 = add_feature_cnt('day', test1_act, test1, 'act_day', 'test1')\ntest1 = add_feature_cnt('day', test1_combat, test1, 'combat_day', 'test1')\n# test2\ntest2 = add_feature_cnt('day', test2_act, test2, 'act_day', 'test2')\ntest2 = add_feature_cnt('day', test2_combat, test2, 'combat_day', 'test2')","61cfed2d":"# train\ntrain = add_day_total_cnt(train_act, train, 'act_day', 'train')\ntrain = add_day_total_cnt(train_combat, train, 'combat_day', 'train')\n# test1\ntest1 = add_day_total_cnt(test1_act, test1, 'act_day', 'test1')\ntest1 = add_day_total_cnt(test1_combat, test1, 'combat_day', 'test1')\n# test2\ntest2 = add_day_total_cnt(test2_act, test2, 'act_day', 'test2')\ntest2 = add_day_total_cnt(test2_combat, test2, 'combat_day', 'test2')","b0016560":"# train\ntrain = add_char_id_total_cnt(train_act, train, 'act_char_id', 'train')\ntrain = add_char_id_total_cnt(train_combat, train, 'combat_char_id', 'train')\n# test1\ntest1 = add_char_id_total_cnt(test1_act, test1, 'act_char_id', 'test1')\ntest1 = add_char_id_total_cnt(test1_combat, test1, 'combat_char_id', 'test1')\n# test2\ntest2 = add_char_id_total_cnt(test2_act, test2, 'act_char_id', 'test2')\ntest2 = add_char_id_total_cnt(test2_combat, test2, 'combat_char_id', 'test2')","d722b81e":"act_features = ['playtime','npc_kill','solo_exp','party_exp','quest_exp','rich_monster','death','exp_recovery','game_money_change','fishing','private_shop','enchant_count']\ncombat_features = ['level','pledge_cnt','random_defender_cnt','temp_cnt','same_pledge_cnt','etc_cnt','num_opponent']\nfor f in act_features:\n    train = add_feature_ma3_diff(f, train_act, train, 'train')\n    test1 = add_feature_ma3_diff(f, test1_act, test1, 'test1')\n    test2 = add_feature_ma3_diff(f, test2_act, test2, 'test2')\nprint()\nfor f in combat_features:\n    train = add_feature_ma3_diff(f, train_combat, train, 'train')\n    test1 = add_feature_ma3_diff(f, test1_combat, test1, 'test1')\n    test2 = add_feature_ma3_diff(f, test2_combat, test2, 'test2')","243ee23c":"for f in act_features:\n    train = add_feature_daily_calc(f, train_act, train, 'mean', 'train')\n    test1 = add_feature_daily_calc(f, test1_act, test1, 'mean', 'test1')\n    test2 = add_feature_daily_calc(f, test2_act, test2, 'mean', 'test2')\nprint()\nfor f in combat_features:\n    train = add_feature_daily_calc(f, train_combat, train, 'mean', 'train')\n    test1 = add_feature_daily_calc(f, test1_combat, test1, 'mean', 'test1')\n    test2 = add_feature_daily_calc(f, test2_combat, test2, 'mean', 'test2')","f806d116":"train = add_trade_categorical_cnt('item_type','source_acc_id', train, 'train')\ntest1 = add_trade_categorical_cnt('item_type','source_acc_id', test1, 'test1')\ntest2 = add_trade_categorical_cnt('item_type','source_acc_id', test2, 'test2')\n\ntrain = add_trade_categorical_cnt('item_type','target_acc_id', train, 'train')\ntest1 = add_trade_categorical_cnt('item_type','target_acc_id', test1, 'test1')\ntest2 = add_trade_categorical_cnt('item_type','target_acc_id', test2, 'test2')","96d9d161":"train = add_trade_day_cnt_diff('source_acc_id', train, 'train')\ntest1 = add_trade_day_cnt_diff('source_acc_id', test1, 'test1')\ntest2 = add_trade_day_cnt_diff('source_acc_id', test2, 'test2')\n\ntrain = add_trade_day_cnt_diff('target_acc_id', train, 'train')\ntest1 = add_trade_day_cnt_diff('target_acc_id', test1, 'test1')\ntest2 = add_trade_day_cnt_diff('target_acc_id', test2, 'test2')","74a3811a":"for f in ['item_amount','type']:\n    train = add_trade_feature_sum_diff(f, 'source_acc_id', train, 'train')\n    test1 = add_trade_feature_sum_diff(f, 'source_acc_id', test1, 'test1')\n    test2 = add_trade_feature_sum_diff(f, 'source_acc_id', test2, 'test2')\n\n    train = add_trade_feature_sum_diff(f, 'target_acc_id', train, 'train')\n    test1 = add_trade_feature_sum_diff(f, 'target_acc_id', test1, 'test1')\n    test2 = add_trade_feature_sum_diff(f, 'target_acc_id', test2, 'test2')","4112e550":"pledge_cnt_sum_df = train_combat.groupby('acc_id').agg({'pledge_cnt':'sum','num_opponent':'sum'})\npledge_cnt_sum_df.columns = ['total_pledge_cnt','total_num_opponent']\ntrain = pd.merge(train, pledge_cnt_sum_df, on='acc_id', how='left')\nprint('train \ud06c\uae30 \uccb4\ud06c: ',train.shape)\n\npledge_cnt_sum_df = test1_combat.groupby('acc_id').agg({'pledge_cnt':'sum','num_opponent':'sum'})\npledge_cnt_sum_df.columns = ['total_pledge_cnt','total_num_opponent']\ntest1 = pd.merge(test1, pledge_cnt_sum_df, on='acc_id', how='left')\nprint('test1 \ud06c\uae30 \uccb4\ud06c: ',test1.shape)\n\npledge_cnt_sum_df = test2_combat.groupby('acc_id').agg({'pledge_cnt':'sum','num_opponent':'sum'})\npledge_cnt_sum_df.columns = ['total_pledge_cnt','total_num_opponent']\ntest2 = pd.merge(test2, pledge_cnt_sum_df, on='acc_id', how='left')\nprint('test2 \ud06c\uae30 \uccb4\ud06c: ',test2.shape)","1fb0d21a":"total_pledge_id_df = train_pledge[['acc_id','char_id','server','pledge_id']].drop_duplicates().groupby('acc_id').pledge_id.count().reset_index()\ntotal_pledge_id_df.columns = ['acc_id','total_pledge_id']\ntrain = pd.merge(train, total_pledge_id_df, on='acc_id', how='left')\ntrain = train.fillna(0)\nprint('train \ud06c\uae30 \uccb4\ud06c: ',train.shape)\n\ntotal_pledge_id_df = test1_pledge[['acc_id','char_id','server','pledge_id']].drop_duplicates().groupby('acc_id').pledge_id.count().reset_index()\ntotal_pledge_id_df.columns = ['acc_id','total_pledge_id']\ntest1 = pd.merge(test1, total_pledge_id_df, on='acc_id', how='left')\ntest1 = test1.fillna(0)\nprint('test1 \ud06c\uae30 \uccb4\ud06c: ',test1.shape)\n\ntotal_pledge_id_df = test2_pledge[['acc_id','char_id','server','pledge_id']].drop_duplicates().groupby('acc_id').pledge_id.count().reset_index()\ntotal_pledge_id_df.columns = ['acc_id','total_pledge_id']\ntest2 = pd.merge(test2, total_pledge_id_df, on='acc_id', how='left')\ntest2 = test2.fillna(0)\nprint('test2 \ud06c\uae30 \uccb4\ud06c: ',test2.shape)","3c09c2d7":"amount_by_acc_id = train_pay.groupby('acc_id').agg({'amount_spent':['max','median']})\namount_by_acc_id.columns = ['max_amount','median_amount']\ntrain = pd.merge(train, amount_by_acc_id, on='acc_id', how='left')\ntrain = train.fillna(0)\nprint('train \ud06c\uae30 \uccb4\ud06c: ',train.shape)","7e63ee81":"amount_by_acc_id = test1_pay.groupby('acc_id').agg({'amount_spent':['max','median']})\namount_by_acc_id.columns = ['max_amount','median_amount']\ntest1 = pd.merge(test1, amount_by_acc_id, on='acc_id', how='left')\ntest1 = test1.fillna(0)\nprint('test1 \ud06c\uae30 \uccb4\ud06c: ',test1.shape)","05a84349":"amount_by_acc_id = test2_pay.groupby('acc_id').agg({'amount_spent':['max','median']})\namount_by_acc_id.columns = ['max_amount','median_amount']\ntest2 = pd.merge(test2, amount_by_acc_id, on='acc_id', how='left')\ntest2 = test2.fillna(0)\nprint('test2 \ud06c\uae30 \uccb4\ud06c: ',test2.shape)","934d9d17":"amount_features = ['etc_cnt_diff',\n                 'random_defender_cnt_mean',\n                 'npc_kill_mean',\n                 'solo_exp_mean',\n                 'playtime_mean',\n                 'game_money_change_mean',\n                 'source_enchant_scroll',\n                 'num_opponent_diff',\n                 'level_diff',\n                 'playtime_diff',\n                 'fishing_diff',\n                 'npc_kill_diff',\n                 'quest_exp_diff',\n                 'game_money_change_diff',\n                 'temp_cnt_mean',\n                 'source_item_amount_diff',\n                 'etc_cnt_mean',\n                 'source_item_amount_sum',\n                 'solo_exp_diff',\n                 'death_diff',\n                 'party_exp_diff',\n                 'max_amount']","8597ced9":"survival_features = ['playtime_mean',\n                     'playtime_diff',\n                     'npc_kill_mean',\n                     'npc_kill_diff',\n                     'game_money_change_mean',\n                     'quest_exp_mean',\n                     'solo_exp_mean',\n                     'solo_exp_diff',\n                     'level_mean',\n                     'quest_exp_diff',\n                     'game_money_change_diff',\n                     'fishing_mean',\n                     'temp_cnt_mean',\n                     'death_mean',\n                     'etc_cnt_mean',\n                     'target_item_amount_diff',\n                     'target_item_amount_sum',\n                     'num_opponent_mean',\n                     'source_item_amount_sum',\n                     'fishing_diff',\n                     'median_amount',\n                     'party_exp_mean']","6ff41390":"def survival64(y_pred, dataset):\n    y_true = dataset.get_label()\n    y_pred = np.array([64 if x > 64 else x for x in y_pred])\n    y_pred = np.array([0 if x < 0 else x for x in y_pred])\n    y_pred = np.round(y_pred)\n    error = metrics.mean_absolute_error(y_true, y_pred)\n    return 'error', error, False","92367dc5":"def amount_postprocessing(pred):\n    return pd.Series(pred).apply(lambda x: 0 if x < 0 else x)\n\ndef survival_postprocessing(pred):\n    pred = pd.Series(pred).apply(lambda x: 64 if x > 64 else x)\n    return pred.apply(lambda x: 1 if x < 0 else x).round()","3e9758db":"kf = KFold(n_splits=5, random_state=seed)","ed354cd8":"x_data = train.set_index('acc_id')\ny_amount_train = train_label.amount_spent\ny_survival_train = train_label.survival_time\ny_survival_train_week = y_survival_train \/\/ 7\n\nx_test1 = test1.set_index('acc_id')\nx_test2 = test2.set_index('acc_id')","2d72658f":"def LGB_amount_evaluate(**params):\n    params['n_estimators'] = int(round(params['n_estimators'],0))\n    params['eta'] = int(round(params['eta'],0))\n    params['num_leaves'] = int(round(params['num_leaves'],0))\n    params['colsample_bytree'] = int(round(params['colsample_bytree'],0))\n        \n    test_pred = pd.DataFrame()\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(kf.split(x_data, y_amount_train)):\n        X_train, X_valid = x_data.iloc[train_idx], x_data.iloc[valid_idx]\n        y_train, y_valid = y_amount_train[train_idx], y_amount_train[valid_idx]\n        \n        model = lgb.LGBMRegressor(**params,\n                                  random_state=seed,\n                                  verbose=0,\n                                  metric='mae')\n        model.fit(X_train, y_train)\n\n        y_pred_valid = model.predict(X_valid)\n        y_pred_valid = amount_postprocessing(y_pred_valid)\n    \n        test_pred['{}_fold'.format(n_fold)] = y_pred_valid\n        \n    # \uc74c\uc218\ub97c \ubd99\uc778 \uc774\uc720\ub294 Target\uc774 \ub192\uc740\uac12\uc774\uc5b4\uc57c\ud558\uae30 \ub54c\ubb38\uc774\ub2e4.\n    return -metrics.mean_absolute_error(y_valid, test_pred.mean(axis=1))","cbf03e2f":"def LGB_survival_evaluate(**params):\n    params['n_estimators'] = int(round(params['n_estimators'],0))\n    params['eta'] = int(round(params['eta'],4))\n    params['num_leaves'] = int(round(params['num_leaves'],0))\n    params['colsample_bytree'] = int(round(params['colsample_bytree'],0))\n        \n    test_pred = pd.DataFrame()\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(kf.split(x_data, y_survival_train)):\n        X_train, X_valid = x_data.iloc[train_idx], x_data.iloc[valid_idx]\n        y_train, y_valid = y_survival_train[train_idx], y_survival_train[valid_idx]\n        \n        model = lgb.LGBMRegressor(**params,\n                                  random_state=seed,\n                                  verbose=0,\n                                  metric='mae')\n        model.fit(X_train, y_train)\n\n        y_pred_valid = model.predict(X_valid)\n        y_pred_valid = survival_postprocessing(y_pred_valid)\n    \n        test_pred['{}_fold'.format(n_fold)] = y_pred_valid\n        \n    # \uc74c\uc218\ub97c \ubd99\uc778 \uc774\uc720\ub294 Target\uc774 \ub192\uc740\uac12\uc774\uc5b4\uc57c\ud558\uae30 \ub54c\ubb38\uc774\ub2e4.\n    return -metrics.mean_absolute_error(y_valid, test_pred.mean(axis=1))","679b429a":"lgb_param_grid = {\n    'n_estimators':(500,2000),\n    'eta':(0.01, 0.5),\n    'num_leaves':(30,50),\n    'bagging_fraction':(0.5,1),\n    'feature_fraction':(0.5,1),\n    'colsample_bytree':(0.5,1)\n}\n\nlgb_week_param_grid = {\n    'n_estimators':(500,2000),\n    'eta':(0.01, 0.5),\n    'num_leaves':(30,50),\n    'bagging_fraction':(0.5,1),\n    'feature_fraction':(0.5,1),\n    'colsample_bytree':(0.5,1)\n}","968102d5":"lgb_b_o_amount = BayesianOptimization(LGB_amount_evaluate, lgb_param_grid, random_state=seed)\nlgb_b_o_amount.maximize(init_points=5, n_iter=20)","9396e0b6":"lgb_b_o_survival = BayesianOptimization(LGB_survival_evaluate, lgb_param_grid, random_state=seed)\nlgb_b_o_survival.maximize(init_points=5, n_iter=20)","c7fa5995":"lgb_amount_bp = dict()\nfor k, v in lgb_b_o_amount.max['params'].items():\n    lgb_amount_bp[k] = v\n\nlgb_survival_bp = dict()\nfor k, v in lgb_b_o_survival.max['params'].items():\n    lgb_survival_bp[k] = v\n\n# num_leaves\nlgb_amount_bp['num_leaves'] = int(np.round(lgb_amount_bp['num_leaves']))\nlgb_survival_bp['num_leaves'] = int(np.round(lgb_survival_bp['num_leaves']))\n# n_estimators\nlgb_amount_bp['n_estimators'] = int(np.round(lgb_amount_bp['n_estimators']))\nlgb_survival_bp['n_estimators'] = int(np.round(lgb_survival_bp['n_estimators']))","d8b501da":"lgb_amount_bp = {'bagging_fraction': 0.8927746477285299,\n                 'colsample_bytree': 0.9606149102852795,\n                 'eta': 0.4164215305825649,\n                 'feature_fraction': 0.840013600879963,\n                 'n_estimators': 500,\n                 'num_leaves': 30}","2e0d02d8":"lgb_survival_bp = {'bagging_fraction': 0.5,\n                     'colsample_bytree': 0.5,\n                     'eta': 0.01,\n                     'feature_fraction': 0.5,\n                     'n_estimators': 653,\n                     'num_leaves': 50}","f802c737":"# Amount LGB Model\nlgb_amount_model = lgb.LGBMRegressor(**lgb_amount_bp,\n                                     random_state=seed,\n                                     verbose=0,\n                                     metric='mae')\nlgb_amount_model.fit(x_data[amount_features], y_amount_train)\n# light GBM amount spent\nlgb_amount_pred_test1 = lgb_amount_model.predict(x_test1[amount_features])\nlgb_amount_pred_test2 = lgb_amount_model.predict(x_test2[amount_features])\n\n\n# Survival LGB Model\nlgb_survival_model = lgb.LGBMRegressor(**lgb_survival_bp,\n                                       random_state=seed,\n                                       verbose=0,\n                                       metric='mae')\nlgb_survival_model.fit(x_data[survival_features], y_survival_train)\n# light GBM survival time\nlgb_survival_pred_test1 = lgb_survival_model.predict(x_test1[survival_features])\nlgb_survival_pred_test2 = lgb_survival_model.predict(x_test2[survival_features])\n\n# Post Processing\nlgb_amount_pred_test1 = amount_postprocessing(lgb_amount_pred_test1)\nlgb_amount_pred_test2 = amount_postprocessing(lgb_amount_pred_test2)\nlgb_survival_pred_test1 = survival_postprocessing(lgb_survival_pred_test1)\nlgb_survival_pred_test2 = survival_postprocessing(lgb_survival_pred_test2)\n\n# concat\ntest1_lgb = pd.DataFrame({'acc_id':test1.acc_id,\n                         'survival_time':lgb_survival_pred_test1,\n                         'amount_spent':lgb_amount_pred_test1})\ntest2_lgb = pd.DataFrame({'acc_id':test2.acc_id,\n                         'survival_time':lgb_survival_pred_test2,\n                         'amount_spent':lgb_amount_pred_test2})\n# print\nprint('Light GBM Test1 Prediction shape: ',test1_lgb.shape)\nprint('Light GBM Test2 Prediction shape: ',test2_lgb.shape)","528dea2d":"test1_lgb.to_csv('test1_predict.csv', index=False)\ntest2_lgb.to_csv('test2_predict.csv', index=False)","cd033296":"f_score_amount = pd.DataFrame({'feature':x_data[amount_features].columns,\n                               'score':lgb_amount_model.feature_importances_})","2df9b628":"f_score_survival = pd.DataFrame({'feature':x_data[survival_features].columns,\n                               'score':lgb_survival_model.feature_importances_})","ef98e4fd":"f, ax = plt.subplots(1,2,figsize=(15,5))\nsns.barplot(x='score', y='feature', data=f_score_amount.sort_values(by='score',ascending=False), ax=ax[0])\nsns.barplot(x='score', y='feature', data=f_score_survival.sort_values(by='score',ascending=False), ax=ax[1])\nax[0].set_title('Amount Spent', size=15)\nax[1].set_title('Survival Time', size=15)\nplt.show()","33ae62bc":"def score_function(predict, actual):\n    \n    # predict = pd.read_csv(predict_label, engine='python') # \uc608\uce21 \ub2f5\uc548 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30\n    # actual = pd.read_csv(actual_label,engine='python') # \uc2e4\uc81c \ub2f5\uc548 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30\n\n    predict.acc_id = predict.acc_id.astype('int')\n    predict = predict.sort_values(by =['acc_id'], axis = 0) # \uc608\uce21 \ub2f5\uc548\uc744 acc_id \uae30\uc900\uc73c\ub85c \uc815\ub82c \n    predict = predict.reset_index(drop = True)\n    actual.acc_id = actual.acc_id.astype('int')\n    actual = actual.sort_values(by =['acc_id'], axis = 0) # \uc2e4\uc81c \ub2f5\uc548\uc744 acc_id \uae30\uc900\uc73c\ub85c \uc815\ub82c\n    actual =actual.reset_index(drop=True)\n    \n    if predict.acc_id.equals(actual.acc_id) == False:\n        print('acc_id of predicted and actual label does not match')\n        sys.exit() # \uc608\uce21 \ub2f5\uc548\uc758 acc_id\uc640 \uc2e4\uc81c \ub2f5\uc548\uc758 acc_id\uac00 \ub2e4\ub978 \uacbd\uc6b0 \uc5d0\ub7ec\ucc98\ub9ac \n    else:\n            \n        S, alpha, L, sigma = 30, 0.01, 0.1, 15  \n        cost, gamma, add_rev = 0,0,0 \n        profit_result = []\n        survival_time_pred = list(predict.survival_time)\n        amount_spent_pred = list(predict.amount_spent)\n        survival_time_actual = list(actual.survival_time)\n        amount_spent_actual = list(actual.amount_spent)    \n        for i in range(len(survival_time_pred)):\n            if survival_time_pred[i] == 64 :                 \n                cost = 0\n                optimal_cost = 0\n            else:\n                cost = alpha * S * amount_spent_pred[i]                    #\ube44\uc6a9 \uacc4\uc0b0\n                optimal_cost = alpha * S * amount_spent_actual[i]          #\uc801\uc815\ube44\uc6a9 \uacc4\uc0b0 \n            \n            if optimal_cost == 0:\n                gamma = 0\n            elif cost \/ optimal_cost < L:\n                gamma = 0\n            elif cost \/ optimal_cost >= 1:\n                gamma = 1\n            else:\n                gamma = (cost)\/((1-L)*optimal_cost) - L\/(1-L)              #\ubc18\uc751\ub960 \uacc4\uc0b0\n            \n            if survival_time_pred[i] == 64 or survival_time_actual[i] == 64:\n                T_k = 0\n            else:\n                T_k = S * np.exp(-((survival_time_pred[i] - survival_time_actual[i])**2)\/(2*(sigma)**2))    #\ucd94\uac00 \uc0dd\uc874\uae30\uac04 \uacc4\uc0b0\n                \n            add_rev = T_k * amount_spent_actual[i]                         #\uc794\uc874\uac00\uce58 \uacc4\uc0b0\n    \n           \n            profit = gamma * add_rev - cost                                #\uc720\uc800\ubcc4 \uae30\ub300\uc774\uc775 \uacc4\uc0b0\n            profit_result.append(profit)\n            \n        score = sum(profit_result) \n    return score","6b10fb46":"y_amount_train_pred = lgb_amount_model.predict(x_data[amount_features])\ny_survival_train_pred = lgb_survival_model.predict(x_data[survival_features])\n\ny_amount_train_pred = amount_postprocessing(y_amount_train_pred)\ny_survival_train_pred = survival_postprocessing(y_survival_train_pred)","d6fc7ae0":"train_pred_df = pd.DataFrame({'acc_id':train.acc_id,\n                              'survival_time':y_survival_train_pred,\n                              'amount_spent':y_amount_train_pred})","46a383a8":"train_score = score_function(train_pred_df, train_label)\ntrue_score = score_function(train_label,train_label)","1fd3f10a":"print('Train score: ',train_score)\nprint('true score: ',true_score)","4fcdde95":"pd.merge(train_pred_df, train_label, on='acc_id', how='left').head(20)","0b09ebb6":"## Day","083abf00":"### Best Parameters","18b2b49b":"# Baseline Part 3\n\n## \uc0ac\uc6a9 \ubaa8\ub378\n1. Linear Regression\n2. Random Forest\n3. Light GBM\n\n## Preprocessing\n**\uc2dc\uac04\uc5d0 \ub530\ub978 \ubcc0\ud654 \ucd94\uac00\uc801\uc6a9**\n\n\n- lag1~7 \ub370\uc774\ud130 \uc0ac\uc6a9\n    - Activity and Combat \uc0ac\uc6a9\ud574\ubd24\ub294\ub370 \ubcc4\ub85c \uc601\ud5a5 X \n- \uc720\uc800\ubcc4 \ub9c8\uc9c0\ub9c9 \uc0ac\uc6a9\uc77c\uae30\uc900 MA3 - \ub9c8\uc9c0\ub9c9\ub0a0\uc9dc \ub370\uc774\ud130 \uc0ac\uc6a9\n    - Activity and Combat \ubcc0\uc218 \uc801\uc6a9\n\n\n\n`Trade` \n1. \uc720\uc800\ubcc4 \ucd1d \ud310\ub9e4\uc218 \/ \ucd1d \uad6c\ub9e4\uc218\n2. \uc720\uc800\ubcc4 \ucd1d \ud310\ub9e4\uc218 - \ub9c8\uc9c0\ub9c9 7\uc77c \ub3d9\uc548 \ud310\ub9e4\uc218 \/ \ucd1d \uad6c\ub9e4\uc218 - \ub9c8\uc9c0\ub9c9 7\uc77c \ub3d9\uc548 \uad6c\ub9e4\uc218\n3. \uc720\uc800\ubcc4 \uc544\uc774\ud15c \uc720\ud615\ubcc4 \ucd1d \ud310\ub9e4 \uc218\n4. \uc720\uc800\ubcc4 \uc544\uc774\ud15c \uc720\ud615\ubcc4 \ucd1d \uad6c\ub9e4 \uc218\n5. \uc720\uc800\ubcc4 \uac70\ub798\uc720\ud615\uc758 \ud569 == \uac70\ub798\ucc3d \uac70\ub798 \ucd1d \ud69f\uc218\n \n`Pledge`\n1. \uc720\uc800\ubcc4 \ud608\ub9f9 \uc544\uc774\ub514 \ucd1d \uc218\n\n\n## Modeling\n- Kfold \uc801\uc6a9\n- Light GBM \uc801\uc6a9\n\n## Hyperparameter Tuning\n- Bayesian Optimization Tuning\n    - \uc9c4\ud589 \uc911 \n\n## \uacb0\uacfc\n**Baseline 1**\n\nModel | Score\n---|---\nTrue Label | 30704.35\nLinear Regression | 3492.45\nRandom Forest | 3993.83\nLight GBM | 3674.59\n\n**Baseline 2**\n\nModel | Score\n---|---\nTrue Label | 30704.35\nLinear Regression | 2543.74\nRandom Forest | 4312.06\nLight GBM | 4140.03","6101975a":"## Score","b05f3904":"# Modeling","0848549b":"## Model 1: Light GBM","923d2ce3":"1. Light GBM","7a33a97b":"# Feature Engineering Function","733e151c":"# Evaluation\nFeature Importance","8e848296":"## max_amount & median_amount\n28\uc77c\ub3d9\uc548 payment \uae30\ub85d\uc774 \uc788\ub294 \uc720\uc800\ub9cc \ucd5c\ub300\uac12\uacfc \uc911\uac04\uac12\uc73c\ub85c \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4","06a87383":"# Total Day","d5d96f63":"# Load Data","2c0682d8":"## total pledge_id \n1. \uc720\uc800\ubcc4 \uac00\uc785\ud55c \ud608\ub9f9 \uc218\ub97c \ud655\uc778\ud558\uae30\uc704\ud574 \uc720\uc800ID, \uce90\ub9ad\ud130ID, \uc11c\ubc84, \ud608\ub9f9ID\ub97c \ucd94\ucd9c \ud6c4 \uc911\ubcf5\uac12\uc744 \uc81c\uac70\ud55c\ub2e4.\n2. \uc720\uc800\ubcc4 \ud608\ub9f9 \uc218\ub97c \uc13c\ub2e4.","265c0c97":"## total pledge_cnt & total num_opponent\n- \uc720\uc800\ubcc4 \uadf8\ub8f9\ud654\ub97c \ud1b5\ud574 \ud608\ub9f9\uac04 \uc804\ud22c \ucd1d \ud69f\uc218 & \uc804\ud22c \uce90\ub9ad\ud130 \ucd1d \uc218\ub97c \uad6c\ud55c\ub2e4.","6d24f839":"**Custom Metric**\n- survival time\uc758 \uacbd\uc6b0 64\uc774\uc0c1\uc778 \uac12\uc740 64\ub85c \ubcc0\ud658\ud574\uc8fc\uc5b4\uc57c \ud55c\ub2e4. \n- Boosting model\ub4e4\uc740 \ud559\uc2b5\uacfc\uc815\uc5d0 \ud3c9\uac00\uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec error\ub97c \ud559\uc2b5\ud558\uae30 \ub54c\ubb38\uc5d0 \ubb38\uc81c \ud574\uacb0\uc5d0 \uc801\ud569\ud55c \ud3c9\uac00\uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud574\uc57c\ud55c\ub2e4.","f5d698a0":"## Target","e55976be":"## 5 Folds","7b95cece":"## Total Char_id","02e4015d":"**\ud6c4\ucc98\ub9ac (Post Processing)**","8054cdae":"# Configuration\n\uae30\ubcf8 \uc124\uc815\uac12\uc744 \uc9c0\uc815\ud558\ub294 \uacf3","1fc7c4ef":"# Feature Selection","d6762962":"# Initialize dataset"}}