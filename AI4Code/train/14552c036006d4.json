{"cell_type":{"4940fd61":"code","c06fb0c9":"code","0085336a":"code","2c25a21b":"code","5743fd34":"code","fdbf66af":"code","7c4c7ffa":"code","64a5d1fb":"markdown","fe3e1c04":"markdown","dfad4f9e":"markdown","3d7d9d09":"markdown","9e5c4af3":"markdown","42bd6583":"markdown","c557ea57":"markdown","83d4a72e":"markdown"},"source":{"4940fd61":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# for Box-Cox Transformation\nfrom scipy import stats\n\n# for min_max scaling\nfrom mlxtend.preprocessing import minmax_scaling\n\n# plotting modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# read in all our data\nkickstarters_2017 = pd.read_csv(\"..\/input\/kickstarter-projects\/ks-projects-201801.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","c06fb0c9":"# generate 1000 data points randomly drawn from an exponential distribution\noriginal_data = np.random.exponential(size = 1000)\n\n# mix-max scale the data between 0 and 1\nscaled_data = minmax_scaling(original_data, columns = [0])\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(original_data, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","0085336a":"# normalize the exponential data with boxcox\nnormalized_data = stats.boxcox(original_data)\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(original_data, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(normalized_data[0], ax=ax[1])\nax[1].set_title(\"Normalized data\")","2c25a21b":"# select the usd_goal_real column\nusd_goal = kickstarters_2017.usd_goal_real\n\n# scale the goals from 0 to 1\nscaled_data = minmax_scaling(usd_goal, columns = [0])\n\n# plot the original & scaled data together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","5743fd34":"# Your turn! \n# We just scaled the \"usd_goal_real\" column. What about the \"goal\" column?\n# select the usd_goal_real column\ngoal = kickstarters_2017.goal\n\n# scale the goals from 0 to 1\nscaled_data = minmax_scaling(goal, columns = [0])\n\n# plot the original & scaled data together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(kickstarters_2017.goal, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","fdbf66af":"# get the index of all positive pledges (Box-Cox only takes postive values)\nindex_of_positive_pledges = kickstarters_2017.usd_pledged_real > 0\n\n# get only positive pledges (using their indexes)\npositive_pledges = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]\n\n# normalize the pledges (w\/ Box-Cox)\nnormalized_pledges = stats.boxcox(positive_pledges)[0]\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(positive_pledges, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(normalized_pledges, ax=ax[1])\nax[1].set_title(\"Normalized data\")","7c4c7ffa":"# Your turn! \n# We looked as the usd_pledged_real column. What about the \"pledged\" column? Does it have the same info?\n","64a5d1fb":"# Step 2: scaling\n## minmax_scaling(array, columns, min_val=0, max_val=1)\nParameters\n    array : pandas DataFrame or NumPy ndarray, shape = [n_rows, n_columns].\n    columns : array-like, shape = [n_columns] Array-like with column names, e.g., ['col1', 'col2', ...] or column indices [0, 2, 4, ...]\n    min_val : int or float, optional (default=0) minimum value after rescaling.\n    max_val : int or float, optional (default=1) maximum value after rescaling.\n\nReturns\n    df_new : pandas DataFrame object.\n    Copy of the array or DataFrame with rescaled columns.\n___\n\nTo practice scaling and normalization, we're going to be using a dataset of Kickstarter campaigns. (Kickstarter is a website where people can ask people to invest in various projects and concept products.) Let's start by scaling the goals of each campaign, which is how much money they were asking for.","fe3e1c04":"It's not perfect (it looks like a lot pledges got very few pledges) but it is much closer to normal!","dfad4f9e":"Notice that the *shape* of the data doesn't change, but that instead of ranging from 0 to 8ish, it now ranges from 0 to 1.\n\n___\n## Normalization\n\nThe point of normalization is to change your observations so that they can be described as a normal distribution.\n\nIn general, you'll only want to normalize your data if you're going to be using a machine learning or statistics technique that assumes your data is normally distributed. Some examples of these include t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes. (Pro tip: any method with \"Gaussian\" in the name probably assumes normality.)\n\nThe method were  using to normalize here is called the [Box-Cox Transformation](https:\/\/en.wikipedia.org\/wiki\/Power_transform#Box%E2%80%93Cox_transformation).","3d7d9d09":"And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https:\/\/www.kaggle.com\/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also lets you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nTry finding a new dataset and pretend you're preparing to preform a [regression analysis](https:\/\/www.kaggle.com\/rtatman\/the-5-day-regression-challenge). ([These datasets are a good start!](https:\/\/www.kaggle.com\/rtatman\/datasets-for-regression-analysis)) Pick three or four variables and decide if you need to normalize or scale any of them and, if you think you should, practice applying the correct technique.","9e5c4af3":"# Scaling vs. Normalization: What's the difference?\n\n## **Scaling**\n\nThis means that you're transforming your data so that it fits within a specific scale, like 0-100 or 0-1.  \n\nYou want to scale data when you're using methods based on measures of how far apart data points, like [support vector machines, or SVM](https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine) or [k-nearest neighbors, or KNN](https:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm). With these algorithms, a change of \"1\" in any numeric feature is given the same importance. By scaling your variables, you can help compare different variables on equal footing.\n","42bd6583":"# Step 1: Get our environment set up","c557ea57":"Notice that the *shape* of our data has changed. Before normalizing it was almost L-shaped. But after normalizing it looks more like the outline of a bell (hence \"bell curve\"). \n\n___\n## Example\n\nFor the following example, decide whether scaling or normalization makes more sense. \n\n* You want to build a linear regression model to predict someone's grades given how much time they spend on various activities during a normal school week.  You notice that your measurements for how much time students spend studying aren't normally distributed: some students spend almost no time studying and others study for four or more hours every day. Should you scale or normalize this variable?\n* You're still working on your grades study, but you want to include information on how students perform on several fitness tests as well. You have information on how many jumping jacks and push-ups each student can complete in a minute. However, you notice that students perform far more jumping jacks than push-ups: the average for the former is 40, and for the latter only 10. Should you scale or normalize these variables?","83d4a72e":"# Step 2: normalization\n## scipy.stats.boxcox(x, lmbda=None, alpha=None)\nBox-Cox power transformation\nhttps:\/\/www.isixsigma.com\/tools-templates\/normality\/making-data-normal-using-box-cox-power-transformation\/\n\nA procedure to identify an appropriate exponent (Lambda = l) to use to transform data into a \u201cnormal shape.\u201d The Lambda value indicates the power to which all data should be raised. In order to do this, the Box-Cox power transformation searches from Lambda = -5 to Lamba = +5 until the best value is found. \n\nThe Box-Cox power transformation is not a guarantee for normality. This is because it actually does not really check for normality; the method checks for the smallest standard deviation. The assumption is that among all transformations with Lambda values between -5 and +5, transformed data has the highest likelihood \u2013 but not a guarantee \u2013 to be normally distributed when standard deviation is the smallest. Therefore, it is absolutely necessary to always check the transformed data for normality using a probability plot.\n\nAdditionally, the Box-Cox Power transformation only works if all the data is positive and greater than 0. This, however, can usually be achieved easily by adding a constant (c) to all data such that it all becomes positive before it is transformed. \n___\n\nOk, now let's try practicing normalization. We're going to normalize the amount of money pledged to each campaign."}}