{"cell_type":{"9bac4fbf":"code","46d69616":"code","9d3196f6":"code","b328be9e":"code","0f8a15ed":"code","ed66ce27":"code","39815e6d":"code","919d8cbf":"code","d8dbb1c1":"code","e25345c1":"code","788eb2bd":"code","b3bf93fc":"code","f736b046":"code","fa587c51":"code","afcc4883":"code","843f2dc2":"code","df4885ff":"code","a5f7a8a0":"code","17866689":"code","b4444c32":"code","45d984b9":"code","3a1b631e":"code","a4203b9b":"code","4c4fe6ce":"code","300c939f":"markdown","434a547e":"markdown","e0bc7dda":"markdown","4b9bbfa1":"markdown","cb976e34":"markdown","8b98ce42":"markdown","95f0054b":"markdown"},"source":{"9bac4fbf":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","46d69616":"%%time\ntrain = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/train.csv')\ntest = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/test.csv')\ntrain.head()\n","9d3196f6":"train.shape, test.shape","b328be9e":"# combining test and train to do feature engineering.\ntest['importance']=-1\ntrain['label'] = 'train'\ntest['label'] = 'test'\ncombined = pd.concat([train,test],axis=0)\ncombined.shape","0f8a15ed":"for col in combined.columns:\n    print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum())\n\n#     a lot of features have multiple empty values and single constant value.","ed66ce27":"def combine_issues(df):\n#     combining all the issues columns to form one issue column\n    issue_columns = [\n        'issue.0', 'issue.1', 'issue.2', 'issue.3', 'issue.4', 'issue.5', 'issue.6', 'issue.7', 'issue.8', \n        'issue.9', 'issue.10', 'issue.11', 'issue.12', 'issue.13', 'issue.14', 'issue.15', 'issue.16', \n        'issue.17', 'issue.18', 'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23']\n    issue_df = combined[issue_columns]\n    issue_df.fillna('',inplace=True)\n    issue_df['issues'] = issue_df[issue_columns].apply(lambda x: '. '.join([val for val in x if val != '']), axis=1)\n    df.drop(issue_columns, axis=1, inplace=True)\n    issue_df.drop(issue_columns, axis=1, inplace=True)\n    df = pd.concat([df, issue_df], axis=1)\n    return df\n\n\ndef lowercase_texts(df):\n    print('converting all text columns in lowercase.',)\n    for col in combined.columns:\n        if combined[col].dtype=='object':\n            combined[col] = combined[col].str.lower()\n    return df\n\n\ndef universalize_countries(df):\n#     converting all the countries to single symbolic numerical value.(eg - Albania, albania, abl, ab -> 1)\n    country_dict_A = df[['respondentOrderEng','country.name']].set_index('country.name').T.to_dict('list')\n    country_dict_C = df[['respondentOrderEng','respondent.0']].set_index('respondent.0').T.to_dict('list')    \n    country_dict = {}\n    for d in (country_dict_A, country_dict_C):#, country_dict_C): #, country_dict_D, country_dict_E, country_dict_F): \n        country_dict.update(d)\n        \n    country_dict = {k: v for k, v in country_dict.items() if pd.notna(k)}\n    df['respondent.0'] = df['respondent.0'].apply(lambda x: country_dict[x][0])\n    df['respondent.1'] = df['respondent.1'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.2'] = df['respondent.2'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.3'] = df['respondent.3'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.4'] = df['respondent.4'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    del df['respondentOrderEng']\n    return df\n\ndef remove_constant_values(df):\n#     this function removes redundant constant features.\n    print('Removing constant columns -> ',)\n    for col in df.columns:\n        if df[col].nunique()==1:\n            print(col,end=', ' )\n            del df[col]\n    return df\n\ndef remove_unwanted_features(df):\n#     these features dont add any valueable signal to the data.\n    remove_cols =['parties.0', 'country.alpha2', 'parties.1', 'country.name', 'docname', 'appno', 'ecli', 'kpdate', 'originatingbody_name']\n    for col in remove_cols:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df\n\n  \ndef featurize_columns(df):\n#     making new columns.\n    df['itemid'] = df['itemid'].apply(lambda x: x[4:7])\n    df['sharepointid'] = df['sharepointid'].apply(lambda x: str(x)[:3])\n    df['total_respondents'] = 5- df[['respondent.0','respondent.1','respondent.2','respondent.3','respondent.4']].isna().sum(axis=1)\n\n    return df\n\ndef featurize_date_columns(df):\n    #     making new columns based on dates.\n    df['daysbetween_intro_decision'] = (pd.to_datetime(df['decisiondate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_intro_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_decision_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['decisiondate'])).dt.days\n    df.drop(['decisiondate','introductiondate','judgementdate'], axis=1, inplace=True)\n    return df\n\ndef encoding(df):\n    df['doctypebranch'] = le.fit_transform(df['doctypebranch'])\n    df['separateopinion'] = le.fit_transform(df['separateopinion'])\n    df['typedescription'] = le.fit_transform(df['typedescription'])\n    return df\n\ndef fill_missing(df):\n    for col in df.columns:\n        if col not in ['label', 'issues']:\n            df[col].fillna(0,inplace=True)\n            df[col] = df[col].astype('int')\n    return df","39815e6d":"combined.head()","919d8cbf":"# pd.set_option('display.max_colwidth', -1)\n# combined[['issues']]","d8dbb1c1":"combined = combine_issues(combined)\nprint('combined shape after combining issues ->', combined.shape)\ncombined = lowercase_texts(combined)\ncombined = universalize_countries(combined)\ncombined = featurize_columns(combined)\ncombined = featurize_date_columns(combined)\ncombined = encoding(combined)\ncombined = remove_constant_values(combined)\nprint('\\ncombined shape after removing constant features->', combined.shape)\ncombined = remove_unwanted_features(combined)\ncombined = fill_missing(combined)","e25345c1":"combined.head()","788eb2bd":"combined.to_csv('combined_inbetween.csv',index=False)\n","b3bf93fc":"# for col in combined.columns:\n#     print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum(), 'type-> ',combined[col].dtype)","f736b046":"# before making the model, delete label column, delete issues column.\n# separate test and train, delete output of test.\n# explore blackstone - https:\/\/spacy.io\/universe\/project\/blackstone for making new features from issues.\n# test filling missing values using different stratergies.","fa587c51":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score","afcc4883":"target_col = 'importance'","843f2dc2":"combined_train = combined.query('label == \"train\"').drop(['issues', 'label'] , axis=1)","df4885ff":"# split test and train\nX_train, X_test, Y_train, Y_test = \\\n    train_test_split(combined_train.drop([target_col], axis=1), \n                     combined_train[target_col], \n                     test_size=0.2, \n                     stratify=combined_train[target_col])\nprint(len(X_train),' samples in training data\\n',\n      len(X_test),' samples in test data\\n', )","a5f7a8a0":"clf_dict = {\"LGBM Classifier\": \n            {'classifier': LGBMClassifier(),\n                 'params': [\n                            {\n                             'learning_rate': [0.01, 0.1, 1.0],\n                             'n_estimators' :[10, 50, 500, 1000],\n                             'max_depth':[5, 3,7],\n                             'max_features' : [3, 5, 7, 11]\n                            }\n                           ]\n            },\n           }","17866689":"res_df  = pd.DataFrame()\nnum_clf = len(clf_dict.keys())\nres_df = pd.DataFrame(\n    data=np.zeros(shape=(num_clf, 3)),\n    columns = ['classifier',\n                   'train_score', \n                   'test_score',\n            ]\n)","b4444c32":"%%time\ncount = 0\nfor key, clf in clf_dict.items():\n    print(key, clf)\n\n    grid = GridSearchCV(clf[\"classifier\"],\n                        clf[\"params\"],\n                        refit=True,\n                        cv=10,\n                        scoring = 'accuracy',\n                        n_jobs = -1,\n                        verbose=0\n                        \n                       )\n    estimator = grid.fit(\n                        X_train,\n                        Y_train)\n    train_score = estimator.score(X_train,\n                                      Y_train)\n    test_score = estimator.score(X_test,\n                                 Y_test)\n    count+=1\n    \n    res_df.loc[count,'classifier'] = key\n    res_df.loc[count,'train_score'] = train_score\n    res_df.loc[count,'test_score'] = test_score\n    print(f\"{key} best params: {grid.best_params_}\")\nres_df.iloc[1:, :]","45d984b9":"xgbm = LGBMClassifier(max_depth=6, learning_rate=0.1, n_estimators=500,\n                         min_child_weight=100, subsample=1.0, \n                         colsample_bytree=0.8, colsample_bylevel=0.8,\n                         random_state=42, n_jobs=-1)\n\n\nprint(\"Cross Validating...\")\noof_preds = cross_val_predict(xgbm, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)","3a1b631e":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\npreds = grid.predict(tst)\npreds","a4203b9b":"sub = pd.DataFrame(columns=[\"appno\",\"importance\"])\nsub[\"appno\"] = test.appno\nsub[\"importance\"] = preds\n","4c4fe6ce":"sub.to_csv(\"submission2.csv\", index=False)","300c939f":"<h3 style=\"background-color:powderblue;text-align:center;\">Submission<\/h3>  ","434a547e":"<h3 style=\"background-color:powderblue;text-align:center;\">Modeling<\/h3> ","e0bc7dda":"- Problem description: https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-machine-learning-challenge-predict-grievance-importance\/","4b9bbfa1":"[![upvote](https:\/\/emoji.gg\/assets\/emoji\/upvote.png)](https:\/\/emoji.gg\/emoji\/upvote)\n<h1 style=\"background-color:yellow;text-align:center;\">If you find this notebook helpful please upvote!!!<\/h1>","cb976e34":"<h3 style=\"background-color:powderblue;text-align:center;\">Load data<\/h3>","8b98ce42":"<h3 style=\"background-color:powderblue;text-align:center;\">Grid Search<\/h3>  ","95f0054b":"<h3 style=\"background-color:powderblue;text-align:center;\">Feature Engineering<\/h3>"}}