{"cell_type":{"c0b3577e":"code","52391eb1":"code","4cae7842":"code","cb876fb8":"code","0bfe6718":"code","f62bd391":"code","95c260be":"code","583f69c5":"code","b46165e4":"code","7b64b0f0":"code","c15c42f4":"code","5d3a2a49":"code","581a9483":"code","46f4cd87":"code","bb36fe11":"code","121fcf1b":"code","15cd2e5b":"code","94094088":"code","1c07a189":"code","793afedf":"code","d49578f7":"code","03326fdd":"code","6a487999":"code","9ae60d5a":"code","e2f5fd26":"code","c0b04ac4":"markdown","f3a6ad70":"markdown","a4fc99aa":"markdown","be16efde":"markdown","2668a431":"markdown","841e6778":"markdown","597cf415":"markdown","18c76027":"markdown","724c9a26":"markdown","73575207":"markdown","9530da61":"markdown","24d9e905":"markdown","c7f0c783":"markdown","940fdad7":"markdown","549f0f72":"markdown","3063e9e7":"markdown","69b3c488":"markdown","ba0b76aa":"markdown","4f0138ce":"markdown","3eea3e21":"markdown","e6232501":"markdown","10a522a9":"markdown","e7d89775":"markdown","19bef200":"markdown","35293861":"markdown","811403ea":"markdown","ed3a2c54":"markdown"},"source":{"c0b3577e":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nrndd = 12345\n\ndf = pd.read_csv('\/kaggle\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\ndf.info()","52391eb1":"df.head()","4cae7842":"df.tail()","cb876fb8":"df.drop('RowNumber', axis = 1, inplace = True)\ndf.head()","0bfe6718":"df.Gender.unique()","f62bd391":"df.Gender = df.Gender.map({'Female': 0, 'Male':1})\ndf.head()","95c260be":"encoder = OrdinalEncoder()\ndata = encoder.fit_transform(df)\ndf_trans = pd.DataFrame(data, columns = df.columns)\ndf_trans.head()","583f69c5":"df_trans.info()","b46165e4":"df_trans = df_trans.astype({\n    'CustomerId'    : 'int32',\n    'Surname'       : 'int32',\n    'Geography'     : 'int32',\n    'Gender'        : 'int32',\n    'Age'           : 'int32',\n    'Tenure'        : 'int32',\n    'NumOfProducts' : 'int32',\n    'HasCrCard'     : 'int32',\n    'IsActiveMember': 'int32',\n    'Exited'        : 'int32'})\ndf_trans.info()","7b64b0f0":"target = df_trans['Exited']\ntrain = df_trans.drop('Exited', axis = 1)","c15c42f4":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.25, random_state=rndd)","5d3a2a49":"#create a model for prediction\nrand_Forest = RandomForestClassifier(random_state = rndd)\n\n# define model parameters and values for tuning\nparameters = {\n    'n_estimators':np.arange(1,300, 50),\n    'max_depth' : np.arange(2, 30, 2),\n    'min_samples_split': np.arange(2, 30, 2),\n    'min_samples_leaf': np.arange(2, 30, 2)    \n}\n#create a searchCV to cycle through the possible values\nrand_Forest_grid = RandomizedSearchCV(\n    estimator = rand_Forest,\n    param_distributions  = parameters,\n    scoring='f1',\n    n_jobs=2,\n    cv = 5,\n    n_iter = 150,\n    verbose=True, refit=True, return_train_score = True, random_state = rndd)\n    \n#fit the model    \nrand_Forest_grid.fit(X_train, y_train)\n#check scores result\nf1_train = rand_Forest_grid.best_score_\nprint('Best Estimator: ', rand_Forest_grid.best_estimator_)\nprint('Best Params: ', rand_Forest_grid.best_params_)\nprint('f1 =', f1_train)\npredicted_train = rand_Forest_grid.predict(X_train)\naccuracy_train = accuracy_score(y_train, predicted_train)\nprint('accuracy =', accuracy_train)\nroc_auc_score_train =  roc_auc_score(y_train, predicted_train)\nprint('roc_auc_score',  roc_auc_score_train)","581a9483":"#predict values on previously trained model\ny_predicted = rand_Forest_grid.predict(X_test)\n\nf1_test = f1_score(y_test, y_predicted)\naccuracy_test = accuracy_score(y_test, y_predicted)\nroc_auc_score_test =  roc_auc_score(y_test, y_predicted)\nprint('TEST       f1      =', f1_test)\nprint('TEST accuracy      =', accuracy_test)\nprint('TEST roc_auc_score =', roc_auc_score_test)","46f4cd87":"#Create empty dataframe with columns\nresults = pd.DataFrame(columns=['expirement', 'f1_train', 'f1_test', 'accuracy_train', 'accuracy_test', 'roc_auc_train', 'roc_auc_test'])\n#add values to columns accordingly\nresults = results.append([{'expirement':'simple model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","bb36fe11":"X_train.describe()","121fcf1b":"#create scaler\nscaler = StandardScaler()\n#fit and transform data\nX_train_scaled = scaler.fit_transform(X_train)\n#transform data based on previous fit process\nX_test_scaled = scaler.transform(X_test)\n\n#put transformed data for pretty print\nd = pd.DataFrame(columns=X_train.columns, data=X_train_scaled).describe()\nprint('order of values', abs(d.loc['mean','EstimatedSalary']\/ d.loc['mean','CreditScore']))","15cd2e5b":"#create model with parameters vased on previous training result\nrand_Forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=18, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=2, min_samples_split=20,\n                       min_weight_fraction_leaf=0.0, n_estimators=101,\n                       n_jobs=None, oob_score=False, random_state=12345,\n                       verbose=0, warm_start=False)\n\n#define function for reducing code duplication\ndef checkModel(X_train, y_train, X_test, y_test, model = rand_Forest):\n    \n    model.fit(X_train, y_train)\n    y_train_predicted = rand_Forest.predict(X_train)\n    f1_train = f1_score(y_train, y_train_predicted)\n    accuracy_train = accuracy_score(y_train, y_train_predicted)\n    roc_auc_score_train =  roc_auc_score(y_train, y_train_predicted)\n    \n    print('roc_auc_score',  roc_auc_score_train)\n    print('f1 =', f1_train)\n    print('accuracy =', accuracy_train)\n    \n    y_test_predicted = rand_Forest.predict(X_test)\n    f1_test = f1_score(y_test, y_test_predicted)\n    accuracy_test = accuracy_score(y_test, y_test_predicted)\n    roc_auc_score_test =  roc_auc_score(y_test, y_test_predicted)\n    \n    print('TEST       f1 =', f1_test)\n    print('TEST accuracy =', accuracy_test)\n    print('TEST roc_auc_score =', roc_auc_score_test)\n    \n    return f1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test\n\n#call function\nf1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_scaled, y_train, X_test_scaled, y_test)","94094088":"results = results.append([{'expirement':'scaled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","1c07a189":"y_train.value_counts()","793afedf":"def upsample_1(features, target, repeat):\n    #array only with 0 values from features\n    features_zeros = features[target == 0]\n    #array only with 1 values from features\n    features_ones = features[target == 1]\n    \n    #array only with 0 values from target\n    target_zeros = target[target == 0]\n    #array only with 1 values from target\n    target_ones = target[target == 1]\n    \n    #create new data frame with features 0 values and features 1 value repeated Repeat(incoming parameters in functions) times\n    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n    \n    #create new data frame with target 0 values and target 1 value repeated Repeat(incoming parameters in functions) times\n    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n    \n    #just shuffle values in dataframe\n    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=rndd)\n    \n    return features_upsampled, target_upsampled","d49578f7":"X_train_u, y_train_u = upsample_1(X_train, y_train, 4)\nX_test_u, y_test_u = upsample_1(X_test, y_test, 4)\ny_train_u.value_counts()","03326fdd":"f1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_u, y_train_u, X_test_u, y_test_u)","6a487999":"results = results.append([{'expirement':'upsmpled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","9ae60d5a":"scaler = StandardScaler()\nX_train_u_scaled = scaler.fit_transform(X_train_u)\nX_test_u_scaled = scaler.transform(X_test_u)\n\nf1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_u_scaled, y_train_u, X_test_u_scaled, y_test_u)","e2f5fd26":"results = results.append([{'expirement':'upsmpled scaled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","c0b04ac4":"Check their upsmpling result","f3a6ad70":"We observe that 0 is a value 4 times greater than 1. Let's try to equalize their number by applying the technique upsampling\/downsampling. To do this, randomly mix the existing data with the target feature 1. For this porprouse define a function upsample_1","a4fc99aa":"For now we got not bad results. Lets check our data deeper.","be16efde":"rndd=12345","2668a431":"For a make prediction via scikit-learn, we should prepare our dataset, the should consist only numeric values. We starting from 'Gender' column.","841e6778":"The 'RowNumber' columns looks like index duplicate. Let's dropp it.","597cf415":"Now let's create datasets for training. First cut the 'Exited' it is our target value.","18c76027":"As you can see dataset consist only from numeric values.\n<br> Now checking value types.","724c9a26":"For having ability to reproduce experimental values , we define constant for future using in random state generators","73575207":"We can optimize value types.","9530da61":"For future comparing results we will save all result in dataset result.","24d9e905":"For columns 'Surname' and 'Geography' we will used OrdinalEncoder, for coding every string value to the int value. In general cloumns like 'Surname' should not be presented in real dataset, and they cannot affect the final result, but looking a little ahead in our case have a positive impact on the metrics.","c7f0c783":"Now the scale order of values is same, lets check result on our model. For now we will used hyper parmeters from previous grid trainig.\n<br> Best Params:  {'n_estimators': 101, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 18}","940fdad7":"![](http:\/\/)now we have training a model RandomForestClassifier, let's start training data and predict target data.","549f0f72":"The consist only from two values, for this purpose we change values to int","3063e9e7":"It is necessary to predict whether the client will leave the Bank in the near future or not. You are presented with historical data on customer behavior and termination of contracts with the Bank.","69b3c488":"As we can see there are improvements, but they showed themselves only in the training sample. Now lets check our target value","ba0b76aa":"As we can see the data set is full without any NaN values.\nNow let's briefly see the data from the top and from the end.","4f0138ce":"As we can see the result is also positive. Particularly for the main metric for classification F1\n<br> Now lets apply scaller also, and check result.","3eea3e21":"put result to our dataset","e6232501":"Put result scores to dataframe","10a522a9":"now checking our model on test parts of data","e7d89775":"## **1. DataSet preparation**","19bef200":"Now you can see taht 0 and 1 meet about the same time, lets check result on our model.","35293861":"As you can see EstimatedSalary mean = 5008.469733 and CreditScore mean=260.16760  - the order of values is 5008\/260 = 16+ times different. It is not good for model. Let's bring to one order via StandartScaler","811403ea":"**In this paper, we have considered two techniques for dealing with data imbalances in data classification. This is a dimensionality reduction of values and upsampling by target value.**","ed3a2c54":"### **2. Split data for trainig**"}}