{"cell_type":{"a1d9600c":"code","00a878b0":"code","c438d6bd":"code","6b8f8653":"code","2bc79b9f":"code","04341f9b":"code","6b5e603d":"code","e1a35dbc":"code","a651e314":"code","5aaef5ce":"code","bbcbfa8c":"code","53b1f3fc":"code","df12fffa":"code","ec9650f1":"code","818a6008":"code","4c1f30e2":"code","d4528409":"code","c1655c33":"code","2d428674":"code","a2c7d3ec":"code","11e0a84e":"code","23893771":"code","c77f09df":"code","2976ce7d":"code","423db830":"code","a8c6d07b":"code","5adbf13a":"code","989299eb":"code","d62dac8d":"code","8462d25f":"code","c4e3a067":"code","edbdda37":"code","f3588aaa":"code","02ac2328":"code","98fcbaf2":"code","846364f4":"code","9df239ae":"code","3e6e9dec":"code","1937f754":"code","92aaf945":"code","e669076f":"code","70440fde":"code","63b4006f":"code","0d7e6c8c":"code","7ac2a8b9":"code","a2a541fa":"code","9387cb63":"code","fe7d719f":"code","b77bbae8":"code","88908f60":"code","016fe434":"code","ed9f8f24":"markdown","cdfc8775":"markdown","61e656ed":"markdown","e4b9ee8d":"markdown","9de5d0e9":"markdown","5bd1dc1c":"markdown","4a73a37f":"markdown","f47f7d14":"markdown","320812fe":"markdown","3f22f881":"markdown","fea03b65":"markdown","a783229e":"markdown","f0536cb2":"markdown","ca50f1ab":"markdown","02e478b2":"markdown","7956327d":"markdown","282c7cd7":"markdown","5194f9d0":"markdown","c0a059cd":"markdown","002ad323":"markdown","35ee44e7":"markdown","9c73514e":"markdown","21a75d90":"markdown","f1c7a84e":"markdown","45245c02":"markdown","44fe2deb":"markdown","a07d2940":"markdown","13a58b88":"markdown","14d33aae":"markdown","3eb26559":"markdown","cb3d7e31":"markdown","33897a54":"markdown","951626f1":"markdown","ddeca248":"markdown","c211774a":"markdown","9e3c88c7":"markdown","288ecad5":"markdown","1a25ad91":"markdown","845e7b29":"markdown","cb672ad8":"markdown","ff3b66bc":"markdown","5a83acbb":"markdown","9946a48d":"markdown","afe37da1":"markdown","6a98f13f":"markdown","2a092d2f":"markdown","a23c5f1e":"markdown"},"source":{"a1d9600c":"#packages\n%matplotlib inline \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nsns.set(style=\"ticks\", color_codes=True)\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection  import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\nfrom sklearn.pipeline import make_pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","00a878b0":"CRdf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","c438d6bd":"#dataset size\nCRdf.shape","6b8f8653":"#display 5 first rows\nCRdf.head(5)","2bc79b9f":"#display 5 last rows\nCRdf.tail()","04341f9b":"#variables types\nCRdf.dtypes","6b5e603d":"def NA_val(data):\n    \n    missing = data.isna().sum()\n    missing = missing[missing>0]\n    missing_perc = missing\/CRdf.shape[0]*100\n    na = pd.DataFrame([missing, missing_perc], index = ['missing_num', 'missing_perc']).T\n    NA_val = na.sort_values(by = 'missing_perc', ascending = False)\n    NA_val = round(NA_val,2)\n\n    return NA_val","e1a35dbc":"NA_val=NA_val(CRdf)\nNA_val","a651e314":"print(CRdf.shape)\nprint(CRdf.describe())","5aaef5ce":"print(\"Column Names\", CRdf.columns) #Here I am using both the print function","bbcbfa8c":"CRdf.hist(figsize=(20,20))\nplt.show()\n","53b1f3fc":"# designate target variable name\ntargetVar = 'Class'\n#print(targetVar)\ntargetSeries = CRdf[targetVar] #notice one column is considered a series in pandas\n#print(targetSeries)\n#remove target from current location and insert in column number 0\ndel CRdf[targetVar]\nCRdf.insert(0, targetVar, targetSeries)\n#reprint dataframe and see target is in position 0\nCRdf.head()","df12fffa":"#Basic bar chart since the target is binominal\ngroupby = CRdf.groupby(targetVar)\ntargetEDA=groupby[targetVar].aggregate(len)\nprint(targetEDA)\n\nlabels = [\"Normal\", \"Fraud\"]\nplt.figure()\ntargetEDA.plot(kind='bar', grid=True, color='orange')\nplt.axhline(0, color='k')\nplt.title(\"Transaction Class Distribution\")\nplt.xticks(range(2), labels)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\");","ec9650f1":"#Calculate fraud rate\nnb_customers = len(CRdf.index)\nprint('There are a total of %s customers in the dataset among which %s anomaly (or fraud).' \n      %(nb_customers, CRdf[CRdf['Class'] == 1].shape[0]))\nCR_NB = CRdf['Class'].value_counts()[1]\nFraudRate = float(CR_NB) \/ nb_customers\nprint('The Attrition rate is {:.2f}%'.format(FraudRate*100))","818a6008":"normal_transactions = CRdf[CRdf['Class'] == 0]\nfraud_transactions = CRdf[CRdf['Class'] == 1]\nnormal_transactions.head(5)","4c1f30e2":"normal_transactions.Amount.describe()","d4528409":"fraud_transactions.Amount.describe()","c1655c33":"plt.figure(figsize = (11,3))\nplt.subplot(1,2,1)\nplt.scatter(normal_transactions.Time, normal_transactions.Amount)\nplt.title('Normal transactions')\nplt.xlabel('Time in seconds'); \nplt.ylabel('Amount')\nplt.subplot(1,2,2)\nplt.scatter(fraud_transactions.Time, fraud_transactions.Amount)\nplt.title('Fraud transactions')\nplt.xlabel('Time in seconds'); \nplt.ylabel('Amount')\n\nplt.show()","2d428674":"CRdf.drop([\"Time\"], axis=1, inplace=True)","a2c7d3ec":"#correlation matrix\ncorr = CRdf.corr()\n\n#plot using seaborn library\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(17, 11))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(round(corr,2), annot=True, mask=mask, cmap=cmap, vmax=.3,\n                linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax);\nplt.show()","11e0a84e":"target = 'Class'\npredictors = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n       'Amount']","23893771":"# split dataset into testing and training\n# column location 1 to end of dataframe are the features.\n# column location 0 is the target\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    CRdf.iloc[:,1:].values, CRdf.iloc[:,0].values, test_size=0.30, random_state=0)","c77f09df":"print(features_test.shape)\nprint(features_train.shape)\nprint(target_test.shape)\nprint(target_train.shape)","2976ce7d":"#decision tree. Call up my model and name it clf\n#clf is a notation used by many people for classifier\nfrom sklearn import tree \ndt_clf = tree.DecisionTreeClassifier()\n#Call up the model to see the parameters you can tune (and their default setting)\nprint(dt_clf)","423db830":"#train model\ndt_model = dt_clf.fit(features_train, target_train)","a8c6d07b":"#Predict clf DT model again test data\ntarget_pred_dt = dt_model.predict(features_test)","5adbf13a":"print(\"Decision Tree Accuracy Score\", accuracy_score(target_test, target_pred_dt))\nprint(classification_report(target_test, target_pred_dt, target_names = [\"Class = no\", \"Class = yes\"]))\nprint(confusion_matrix(target_test, target_pred_dt))\n\n#extracting true_positives, false_positives, true_negatives, false_negatives\ntn, fp, fn, tp = confusion_matrix(target_test, target_pred_dt).ravel()\nprint(\"True Negatives: \",tn)\nprint(\"False Positives: \",fp)\nprint(\"False Negatives: \",fn)\nprint(\"True Positives: \",tp)","989299eb":"imp = pd.DataFrame({'Feature': predictors, 'Feature importance': dt_model.feature_importances_})\nimp = imp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=imp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()  ","d62dac8d":"\n# Run grid search, get the prediction array and print the accuracy and best combination\ndef fit_and_pred_grid_classifier(clf, param_grid, X_train, X_test, y_train, y_test, scoring = \"recall\", folds = 10):\n\n    \n    gs = GridSearchCV(estimator = clf, param_grid = param_grid, cv = folds, scoring = scoring, n_jobs = -1, verbose = 0)\n    gs = gs.fit(X_train, y_train)\n\n    best_score = gs.best_score_\n    best_parameters = gs.best_params_\n\n    # Get the prediction array\n    grid_search_pred = gs.predict(X_test)\n    \n    \n    # summarize results\n    print(\"Best \" +  scoring + \" score: %f using %s\" % (best_score, best_parameters))\n    means = gs.cv_results_['mean_test_score']\n    stds = gs.cv_results_['std_test_score']\n    params = gs.cv_results_['params']\n    \n    for mean, stdev,param in zip(means, stds, params):\n        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n\n    return grid_search_pred, grid_search_pred\n","8462d25f":"param_grid = {\"max_depth\": [3,7,11],\n              \"max_features\": [3,9,15],\n             \"criterion\": [\"gini\", \"entropy\"]\n             }\nimport time\nstart = time.time()\n\n# Run grid search, print the results and get the prediction array and model\ngs_pred_dt, dt_grid = fit_and_pred_grid_classifier(dt_clf, param_grid, features_train,\n                                                   features_test, target_train, target_test)\n\nend = time.time()\nprint(\"Time to run\", round(end-start), \"seconds\")","c4e3a067":"#validate set\ncm_dt = confusion_matrix(target_test, gs_pred_dt)#correlation matrix\n\nprint(classification_report(target_test, gs_pred_dt,target_names = [\"Class = no\", \"Class = yes\"])) \nprint(\"Recall: \" + str(round(recall_score(target_test, gs_pred_dt), 4) * 100) + \"%\") \n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cm_dt.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cm_dt.flatten()\/np.sum(cm_dt)]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in\n          zip(group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm_dt, annot=labels, fmt='', cmap='Oranges')","edbdda37":"from sklearn.ensemble import RandomForestClassifier\n#Build\nrf_clf = RandomForestClassifier(max_features='auto', random_state=123)\nprint(rf_clf)\n","f3588aaa":"#Train set\nrf_model = rf_clf.fit(features_train, target_train)\n\n#Validation set - prediction\ntarget_pred_rf = rf_clf.predict(features_test)\n","02ac2328":"print(\"Random Forest classifier Accuracy Score\", accuracy_score(target_test, target_pred_rf))\nprint(classification_report(target_test, target_pred_rf, target_names = [\"Class = no\", \"Class = yes\"]))\nprint(confusion_matrix(target_test, target_pred_rf))\n\n#extracting true_positives, false_positives, true_negatives, false_negatives\ntn, fp, fn, tp = confusion_matrix(target_test, target_pred_rf).ravel()\nprint(\"True Negatives: \",tn)\nprint(\"False Positives: \",fp)\nprint(\"False Negatives: \",fn)\nprint(\"True Positives: \",tp)","98fcbaf2":"imp = pd.DataFrame({'Feature': predictors, 'Feature importance': rf_clf.feature_importances_})\nimp = imp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=imp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()   ","846364f4":"from sklearn.ensemble import ExtraTreesClassifier\nclf_xdt = ExtraTreesClassifier(n_estimators= 100, n_jobs=-1, random_state=123)\nprint(clf_xdt)","9df239ae":"#train data\nmodel_xdt = clf_xdt.fit(features_train, target_train)\n\n#validation set\ntarget_predicted=clf_xdt.predict(features_test)","3e6e9dec":"print(\"Extra Trees Accuracy\", accuracy_score(target_test,target_predicted))\ntarget_names = [\"Class = no\", \"Class = yes\"]\nprint(classification_report(target_test, target_predicted,target_names=target_names))\nprint(confusion_matrix(target_test, target_predicted))","1937f754":"imp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf_xdt.feature_importances_})\nimp = imp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=imp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()   ","92aaf945":"# use a full grid over all parametersimport time\nimport time\nparam_grid = {\"max_features\": [7,11,15]}\nstart = time.time()\n\n# run grid search\nimport time\nstart = time.time()\n\n# run grid search\nxdt_gs_pred, xdt_grid = fit_and_pred_grid_classifier(clf_xdt, param_grid, features_train, \n                                                     features_test, target_train, target_test, scoring='recall')\nend = time.time()\nprint(\"Time to run\", round(end-start), \"seconds\")\n","e669076f":"#with the validation set\ncm_xdt = confusion_matrix(target_test, xdt_gs_pred)#confusion matrix\n\nprint(classification_report(target_test, xdt_gs_pred,target_names = [\"Class = no\", \"Class = yes\"])) \nprint(\"Recall: \" + str(round(recall_score(target_test, xdt_gs_pred),4) * 100) + \"%\") \n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cm_xdt.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cm_xdt.flatten()\/np.sum(cm_xdt)]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in\n          zip(group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm_xdt, annot=labels, fmt='', cmap='Oranges')","70440fde":"#Normalize features\nscaler = StandardScaler()  \n#Train\nscaler.fit(features_train)  \n#Validate\nfeatures_train_norm = scaler.transform(features_train)  \n# apply same transformation to test data\nfeatures_test_norm = scaler.transform(features_test) \n","63b4006f":"from sklearn.linear_model import SGDClassifier\nsgd_linear_svm_clf = SGDClassifier(random_state=0)\nprint(sgd_linear_svm_clf )\n\n#Train data\nmodel_sgd = sgd_linear_svm_clf.fit(features_train_norm, target_train)\n\n#test data\ntarget_pred_sgd = sgd_linear_svm_clf.predict(features_test_norm)\nprint(\"Accuracy\", accuracy_score(target_test, target_pred_sgd))\ntarget_names = [\"Class = no\", \"Class = yes\"]\nprint(classification_report(target_test, target_pred_sgd, target_names=target_names))\nprint(confusion_matrix(target_test, target_pred_sgd))","0d7e6c8c":"import time\nstart = time.time()\nparam_grid = {'alpha': [0.0001,0.01,0.1]\n             }\n# Run grid search, print the results and get the prediction array and model\ngsd_gs_pred, gsd_grid = fit_and_pred_grid_classifier(sgd_linear_svm_clf, param_grid, features_train_norm, \n                                                     features_test_norm, target_train, target_test)\nend = time.time()\nprint(\"Time to run\", round(end-start), \"seconds\")","7ac2a8b9":"#validate set\ncm_gsd = confusion_matrix(target_test, gsd_gs_pred)#confusion matrix\n\nprint(classification_report(target_test, gsd_gs_pred,target_names = [\"Class = no\", \"Class = yes\"])) \nprint(\"Recall: \" + str(round(recall_score(target_test, gsd_gs_pred),4) * 100) + \"%\") \n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cm_gsd.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cm_gsd.flatten()\/np.sum(cm_gsd)]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in\n          zip(group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm_gsd, annot=labels, fmt='', cmap='Oranges')","a2a541fa":"# building logistic regression classifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.ticker\n\nlogit = LogisticRegression()\n\n#Call up the model to see the parameters you can tune (and their default setting)\nprint(logit)","9387cb63":"#train model\nlogit_model = logit.fit(features_train_norm, target_train)\n\n#validate set\nlogit_predicted=logit.predict(features_test_norm)","fe7d719f":"print(\"Logistic classifier Accuracy Score\", accuracy_score(target_test, logit_predicted))\nprint(classification_report(target_test, logit_predicted))\nprint(confusion_matrix(target_test, logit_predicted))\n\n#extracting true_positives, false_positives, true_negatives, false_negatives\ntn, fp, fn, tp = confusion_matrix(target_test, logit_predicted).ravel()\nprint(\"True Negatives: \",tn)\nprint(\"False Positives: \",fp)\nprint(\"False Negatives: \",fn)\nprint(\"True Positives: \",tp)","b77bbae8":"param_grid = {'penalty' : ['l1', 'l2'],\n    'C' : np.logspace(-1, 1, 10),\n    'solver' : ['liblinear']}\n\n# Run grid search, print the results and get the prediction array and model\nlogit_target_pred, logit_grid = fit_and_pred_grid_classifier(logit, param_grid, features_train_norm, \n                                                     features_test_norm, target_train, target_test)\nend = time.time()\nprint(\"Time to run\", round(end-start), \"seconds\")\n","88908f60":"#validate set\ncm_logit = confusion_matrix(target_test, logit_target_pred)#confusion matrix\n\nprint(classification_report(target_test, logit_target_pred,target_names=['Class = no','Class = yes'])) \nprint(\"Recall: \" + str(round(recall_score(target_test, logit_target_pred),4) * 100) + \"%\") \n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cm_logit.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cm_logit.flatten()\/np.sum(cm_logit)]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in\n          zip(group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm_logit, annot=labels, fmt='', cmap='Oranges')","016fe434":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.naive_bayes import GaussianNB\n\n# Instantiate the classfiers and make a list\nclassifiers = [make_pipeline(StandardScaler(), LogisticRegression()),\n               tree.DecisionTreeClassifier(),\n               RandomForestClassifier(max_features='auto', n_estimators=100), \n               ExtraTreesClassifier(n_estimators= 100),\n               ]\n\n# Define a result table as a DataFrame\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    model = cls.fit(features_train, target_train)\n    target_predicted = model.predict_proba(features_test)[::,1]\n    \n    fpr, tpr, _ = roc_curve(target_test,  target_predicted)\n    auc = roc_auc_score(target_test, target_predicted)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\n\n# Set name of the classifiers as index labels\nresult_table.set_index('classifiers', inplace=True)\n\n\nfig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"False Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()","ed9f8f24":"The fraud (Class 1) frequency is too low to see; to remind the number of fraudulent transactions is 492 frauds.","cdfc8775":"### 3. 5. Logit Regression Model\n\n","61e656ed":"### 3. 3. Extremely Randomized Trees (Extra Trees)\n\nExtra Trees is like Random Forest, in that it builds multiple trees and splits nodes using random subsets of features, but with two key differences: it does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits. ","e4b9ee8d":"We reach the best recall score (56.85%)  for alpha value equals to 0.0001.","9de5d0e9":"The Decision Tree classifier's accuracy score is 99.92%, which is a excellent score.\n\nPrecision: How often is the classifier correct with its positive predictions? Precision = True Positives\/(True Positives + False Positives). \n\nRecall: How well does the classifier predict positive cases? Recall = True Positives\/(True Positives + False Negatives). Yes, recall is the same as the sensitivity rate. \n\nF1-score is a function of Precision and Recall. It is needed when you want to seek a balance between Precision and Recall.\n\nOur classifier correctly identifies 77% of fraudulent transactions (Recall). Also, The DT classifier is 79% correct when it predicts \"fraud\" (Precision).\n\n* We can further deepen our analysis by trying to improve the recall score (sensitivity). As we know, this metric is very important in detecting anomalies.","5bd1dc1c":"### 3. 2. Random Forest Model\n\n\nRandom Forest is a variant of Bagging where only a randomly chosen subset of features are considered to split at each node. Each node is split on the \"best\" of the given subset of features. The random forest model has  less variance than the decision tree.","4a73a37f":"Now, let's call the tuning for DT classifier. \n\nThe first parameter to tune is max_depth. This indicates how deep the tree can be. The deeper the tree, the more splits it has and it captures more information about the data. We fit a decision tree with depths ranging from 1 to 32. Other hyper parameters we can also tune are \"max_features\" and the \"criterion\" type.","f47f7d14":"### 3. 1. Decision Tree Classification","320812fe":"#### **In order to tune the different methods I am going to create a tuning function based on GridSearch:**","3f22f881":"### 3. 6.  ROC Curves","fea03b65":"Let's first normalize features:","a783229e":"Let's check the variables types","f0536cb2":"In general we obtained very good scores for all models. The logistic regression model leads with a auc score equals to 96.9%.  ","ca50f1ab":"Credit Card Fraud Detection with Machine Learning is a process of data investigation and the development of a model that will provide the best results in revealing and preventing fraudulent transactions. This is achieved through bringing together all meaningful features of card users\u2019 transactions, such as Date, User Zone, Product Category, Amount, Provider, Client\u2019s Behavioral Patterns, etc.\n\nThe Credit Card Fraud Detection Problem includes modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. This model is then used to identify whether a new transaction is fraudulent or not. Our aim here is to detect 100% of the fraudulent transactions while minimizing the incorrect fraud classifications.\n\nThe purpose of this data analysis is therefore to identify potential fraudulent credit card transactions.\n\nI order to detect these anomalies and propose a prediction model, I would use machine learning-based techniques such as: Desicion Tree Classification, Random Forest classification method, Logistic Regregression etc.\n","02e478b2":"How different are the amount of money used in different transaction classes?","7956327d":"#### Confusion matrix:","282c7cd7":"### Tuning...","5194f9d0":"### 3. 4. Stochastic Gradient Descent Classifier","c0a059cd":"#### *Confusion matrix:*","002ad323":"## Credit Card Fraud Analysis - Predictive Models","35ee44e7":"### Import Standard Packages:","9c73514e":"Machine Learning-based Fraud Detection:\n\n* Detecting fraud automatically\n* Real-time streaming\n* Less time needed for verification methods\n* Identifying hidden correlations in data","21a75d90":"Features importance:","f1c7a84e":"Good accuracy 99.90%. Our classifier correctly identifies 55% of fraud transactions (Recall). The Stochastic Gradient Descent  classifier is 87% correct when it predicts \"Fraud\" (Precision).","45245c02":"### Correlation:\n\nBy plotting a correlation matrix, we have a very nice overview of how the features are related to one another.","44fe2deb":"We reach the best recall score, about 77% by using inputs {'criterion': 'entropy', 'max_depth': 3, 'max_features': 15}.","a07d2940":"This classifier correctly identifies 75% of \"Fraud\" (recall). This classifier is also 97% correct when it predicts an fraudulent case (precision). ","13a58b88":"*Features importance:*","14d33aae":"**Tuning:** The most important parameter is the number of random features to sample at each split point (max_features).","3eb26559":"## 3. Machine Learning Models\n\n\nMachine learning algorithms have hyperparameters that allow you to tailor the behavior of the algorithm to your specific dataset.\nHyperparameters are different from parameters, which are the internal coefficients or weights for a model found by the learning algorithm. Unlike parameters, hyperparameters are specified by the practitioner when configuring the model.\nTypically, it is challenging to know what values to use for the hyperparameters of a given algorithm on a given dataset, therefore it is common to use random or grid search strategies for different hyperparameter values.","cb3d7e31":"The logistic regression classier correctly predicted 85284entries as \"Normal transactions (No Fraudulents)\" and 91 entries as \"Fraudulents\". It also incorrectly predicted 56 entries as \"No Fraudulents\" and 0.01% (12 entries) as \"Fraudulents\". The recall score change to 61.9%.","33897a54":"The above correlation matrix shows that none of the V1 to V28 PCA components have any correlation to each other, however the target variable \"Class\" has some form positive and negative correlations with the V components, but it has no correlation with Time and Amount. There is no risk of collinarity between our variables.","951626f1":"### Data\nfrom https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have **492** frauds out of **284,807** transactions. The dataset is highly unbalanced, the positive class (frauds) account for **0.172%** of all transactions.\n\nThe dataset consists of numerical values from the **28** \"Principal Component Analysis (PCA)\" transformed features, namely V1 to V28. Furthermore, there is no metadata about the original features provided, so pre-analysis or feature study could not be done.\nThe 'Time' and 'Amount' features are not transformed data.","ddeca248":"#### Create a training and test set with a split 70\/30:","c211774a":"Well done! We increase the recall score from 75% to 79.45%.","9e3c88c7":"By using default paramenters the Random Forest classifier is 94% corret when identifying \"fraud transaction\" (precision) and the model also has a good recall score (75%). As the DT model, the RF model did with a very good accuracy.","288ecad5":"## 1. Load the dataset:","1a25ad91":"The logit model also did it with a good 99.92% accuracy. It correctly identifies 62% of fraud transactions (Recall), and this method is 88% correct when it predicts a fraud transaction (Precision).\n\nThe logit model correctly predicted 85284 entries as \"Normal transactions (No Fraudulents)\" and 91 entries as \"Fraudulent\".\n\n","845e7b29":"#### Drop the variable Time:","cb672ad8":"Good! there is no missing value in the dataset.","ff3b66bc":"#### Confusion matrix*:*","5a83acbb":"The observation of the graphs above shows that the time of transactions does not really matters. ","9946a48d":"## 4.  Conclusion\n\nWe have first explorated the dataset, by understanding features and the relationship between each to other. In the second part We modeled the data set to achieve about 99.9% accuracy for fraud detection according to the different supervized ML methods implemented. Such models will intially capture all the frauds, but will rigorously classify non-frauds as fradulent as well.\n\nSince all algorithms performed with high accuracy, it was interesting to look at other metrics, especially the recall score. By tuning our models we managed to increase the recall score. This comes out with good results, however at the cost of computational expense.\n\nSo, overall, the Extremely Randomized Trees model (Extra Trees) were much more successful in determining fraudulent transactions. With a high accuracy (99.95%), a good recall score equal to 79.45% and a goog precision (97%), this model seems to be the best candidate to detect fraudulent transactions. It is followed by the Random Forest model. The gradient descent classifier has the fewest recall score.","afe37da1":"The results presented above show us that:\n\nWe now correctly predicted  **117** entries as \"Fraudulent\" and increase the recall score to 80% from 77%. This a little bit better than previously, with default parameters.","6a98f13f":"Let's check for missing values","2a092d2f":"# 2. Exploratory Data Analysis\n","a23c5f1e":"The classifier correctly predicted 85290 (99.82%) entries as \"Normal transactions (No Fraudulents)\" and 112 entries as \"Fraudulents\" (0.13%). This method incorrectly predicted 35 entries as \"No Fraudulents\" and 6 as \"Fraudulents\". We slightly improve the recall score from 75 to 76%."}}