{"cell_type":{"9b24da52":"code","4d04b9d3":"code","1f1c1319":"code","96f16df6":"code","a4aeac9b":"code","9d2793bb":"code","65ea26a6":"code","e0912aa4":"code","76c9bbb4":"code","15c9601c":"code","d997186b":"code","8a13e7b3":"code","cb0d1ce4":"code","5a58d966":"code","2fdc1d56":"code","76c2984a":"code","c243ddb2":"code","c401ccbb":"code","83d2be1c":"markdown","72ccffae":"markdown","9f28ac03":"markdown","2633df11":"markdown","ed1c935d":"markdown","b9bcc07c":"markdown","d4d7145a":"markdown","35e27bed":"markdown","6ae7d4b5":"markdown","273611eb":"markdown","5bc2b046":"markdown","c414dd8c":"markdown","b1dc4d77":"markdown","706a7326":"markdown","92075dfc":"markdown","0148eaea":"markdown","c0926fcc":"markdown","d00fb247":"markdown"},"source":{"9b24da52":"import numpy as np, pandas as pd\nimport matplotlib.pyplot as plt, seaborn as sns\nimport statsmodels.api as sm\n\nsns.set()","4d04b9d3":"raw_data = pd.read_csv(\"..\/input\/portuguese-bank-data\/Bank_data.csv\")\nraw_data.head(3)","1f1c1319":"data = raw_data.copy()\n\ndata = data.drop([\"Unnamed: 0\"], axis = 1)\n\ndata[\"y\"] = data[\"y\"].map({\"yes\":1, \"no\":0})\ndata.head()","96f16df6":"data.info()  # result shows there are no null values","a4aeac9b":"y1, (x1, x2, x3, x4, x5, x6) = plt.subplots(1, 6, sharey=True, figsize =(15,3))  # sharey - sharing what is on y-axis\n\nx1.scatter(data['interest_rate'],data['y'])\nx1.set_title('Interest Rate and y')\nx2.scatter(data['credit'],data['y'])\nx2.set_title('Credit and y')\nx3.scatter(data['duration'],data['y'])\nx3.set_title('Duration and y')\nx4.scatter(data['march'],data['y'])\nx4.set_title('March and y')\nx5.scatter(data['may'],data['y'])\nx5.set_title('May and y')\nx6.scatter(data['previous'],data['y'])\nx6.set_title('Previous and y')\n\nplt.show()","9d2793bb":"features = [\"interest_rate\", \"march\", \"may\", \"credit\", \"previous\", \"duration\"]\nx1 = data[features]\ny = data[\"y\"]","65ea26a6":"x = sm.add_constant(x1)\nreg_logit = sm.Logit(y, x)\nresults_logit = reg_logit.fit()\nresults_logit.summary()","e0912aa4":"features.remove(\"may\")\nfeatures","76c9bbb4":"x1 = data[features]\ny = data[\"y\"]\n\nx = sm.add_constant(x1)\nreg_logit = sm.Logit(y, x)\nresults_logit = reg_logit.fit()\nresults_logit.summary()","15c9601c":"def confusion_matrix(data, actual_values, model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s     \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n        \n        # an array of 'y' predicted through the model\n        pred_values = model.predict(data)\n        \n        # creating two bins of ranges 0 to 0.5 and 0.5 to 1\n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        \n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])\/cm.sum()\n        \n        # Return the confusion matrix and accuracy\n        return cm, accuracy","d997186b":"confusion_matrix(x, y, results_logit)","8a13e7b3":"test_data = pd.read_csv(\"..\/input\/portuguese-bank-data\/bank_data_testing.csv\")\ntest_data = test_data.drop([\"Unnamed: 0\"], axis = 1)\ntest_data[\"y\"] = test_data[\"y\"].map({\"yes\":1, \"no\":0})  # mapping 'y'\ntest_data.head()","cb0d1ce4":"Y = test_data[\"y\"]\nX1 = test_data[features]","5a58d966":"X = sm.add_constant(X1)","2fdc1d56":"def confusion_matrix(data,actual_values,model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s\n            \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n        \n        #Predict the values using the Logit model\n        pred_values = model.predict(data)\n        # Specify the bins \n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])\/cm.sum()\n        # Return the confusion matrix and the accuracy\n        return cm, accuracy","76c2984a":"cm = confusion_matrix(X, Y, results_logit)\ncm","c243ddb2":"cm_df = pd.DataFrame(cm[0])\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\ncm_df","c401ccbb":"print('Missclassification rate: ' + str((13+18)\/222))","83d2be1c":"**applying regression again,** on updated list of features","72ccffae":"# 1. Importing Libraries","9f28ac03":"**Misclassification Rate:** It is opposite of accuracy. Accuracy + Misclassification Rate = 1","2633df11":"**Lets make a DataFrame to make it more understandable!**","ed1c935d":"By looking at test results, we can say that our model has performed equally good on test data as it did on training data. We can see that it is not an under or over fitted model.","b9bcc07c":"# 4. Declaring Dependent and Independent Variables","d4d7145a":"# 2. Loading Data","35e27bed":"# 6. Confusion Matrix","6ae7d4b5":"**Declaring dependent and independent variables**","273611eb":"# 7. Testing Model\nNormally, we split same data in train-test data sets and used them to train and then test the model. But for this particualar problem, we have a different data set to test our model.\n\n**Let's start with loading test data!**","5bc2b046":"P Value for 'may' is very high. We may want to drop that feature from our model and train the model again.","c414dd8c":"# Logistic Regression:\nWe have seen a [basic form of logistic regression](http:\/\/https:\/\/www.kaggle.com\/salmankhi\/simple-logistic-regression-model) that was a univariate logistic regression. Let's do a problem with multiple independent variables in mind.\n\n**Problem statement** is same. We need to predict whether a certain client will subscribe to the bank's new term deposit or not. But, now we have some other potential features in our hand alongwith the durations of clients' association with the bank.\n\nLet's start with importing libraries and data!","b1dc4d77":"# 5. Applying Logistic Regression","706a7326":"There are no null values. We may continue to train our logistic regression model.\n\nBut, before that, let's visualize the data!","92075dfc":"# 3. Data Visualization","0148eaea":"Our model is now trained and ready to predict target for given features. But, before trying our model before unseen data, let's see how accurately it is trained on the data that has been given to it to be trained.\n\nFor this pupose we have **Confusion Matrix** that provides us with the frequencies of rights and wrongs. It is used to assess the accuracy of the model.","c0926fcc":"**Interpretation of Confusion Matrix:**\n\nConfusion matrix contains 4 values. The leading diagnal contains the frequencies for which model predicted correct results and the counterdiagonal contains number of times it predicted wrong.\n\nFor this particular case:\n\n|   |   |   |   |\n|---|---|---|---|\n||Predicted 0|Predicted 1|\n|Actual 0|218|41|\n|Actual 1|30|229|\n\nAccuracy can be found out by dividing number of correct predictions with number of incorrect ones.\n\nIt is understandable that our model have higher accuracy(i.e. ~86.29%) on this data as it is trained on this same data. Next up we will find out how well is the accuracy of the model is on unseen data.","d00fb247":"Features are ready to be tested, we will be predicting values in same function in which we will be creating **Confusion Matrix** of how accurate model performed on new data."}}