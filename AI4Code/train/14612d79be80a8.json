{"cell_type":{"708389e9":"code","d82db21e":"code","446077c8":"code","78e50b17":"code","3a79e98c":"code","35efd938":"code","2b1043c1":"code","2618cbc3":"code","00934e1a":"code","6437e05d":"code","41671b50":"code","e51a30d8":"code","d971045d":"code","58cab518":"code","221d2b5a":"code","aeca8567":"code","5a4739fc":"code","3326a8a9":"code","82882f00":"code","17ae788c":"code","00961e25":"code","af08cd5b":"code","c320ab8f":"code","ffee0a9e":"code","5dcb1b07":"code","4a3092d3":"code","69c772c5":"code","f0854bb5":"code","c0065b73":"code","3b9356bd":"code","cd789293":"code","4f31c81d":"code","edc07ef6":"code","50607d4c":"code","18054467":"code","5c5b2719":"code","2f7b56cb":"code","ff795344":"code","c7f8af05":"code","6be8855f":"code","5e1b6f86":"code","366bc3df":"code","fb3a694e":"code","29642b2e":"code","c264910a":"code","11930ea4":"markdown","07d92084":"markdown","f6cc0f92":"markdown","a2d2e76e":"markdown","40834b5e":"markdown","b605fc75":"markdown","7433f27b":"markdown","4ea57b26":"markdown","f0584322":"markdown"},"source":{"708389e9":"# IMPORTS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import average_precision_score, roc_auc_score, f1_score, precision_score, \\\nrecall_score, cohen_kappa_score, classification_report,confusion_matrix\nimport numpy as np\nimport pandas as pd\nimport csv as csv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style='darkgrid')\n\n# FILES IN THE INPUT DIRECTORY\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d82db21e":"#Begin by reading the data\nShotData = pd.read_csv('\/kaggle\/input\/shotdata\/ShotData.csv')","446077c8":"#What does the data set look like?\nprint(ShotData.columns)\nShotData.head()","78e50b17":"#How many rows and columns are there?\nShotData.shape","3a79e98c":"#Meta data\nprint(ShotData.info())\nShotData.describe()","35efd938":"#'outcome'\n#Starting with our target variable, we are only interested in whether a goal is scored or not.\n#We can hence map all goal outcomes to 'Goal' and all no-goal outcomes to 'NoGoal'\nShotData['outcome'] = ShotData['outcome'].replace(['Goal','owngoal'], 'Goal')\nShotData['outcome'] = ShotData['outcome'].replace(['Missed','Blocked','Saved','GoalFrame'], 'NoGoal')","2b1043c1":"#'match_minute' and 'match_second'\n#It makes sense to combine these into one column for time elapsed, which can then be binned and plotted as a barplot\n#Bins of match quarters:\nShotData['Time'] = ShotData['match_minute'] + (ShotData['match_second']\/60)\nShotData['Time'] = pd.qcut(ShotData['Time'], 4, labels=['FirstQuarter','SecondQuarter','ThirdQuarter','FourthQuarter'])\nplt.figure(figsize=(22, 9))\nsns.countplot(x='Time', hue='outcome', data=ShotData)\nplt.xlabel('Time Interval (mins)', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.legend(['Goal', 'NoGoal'], loc='upper right', prop={'size': 15})\nplt.title('Count of Goals in {} Feature'.format('Time'), size=15, y=1.05)\nplt.show()\n\n#Looking instead at percentage of shots that end in a goal for each interval:\nInterval = ShotData.groupby('Time')['outcome'].value_counts(normalize=True).mul(100).rename('Percent').reset_index()\nplt.figure(figsize=(22, 9))\nsns.barplot(x='Time', y='Percent', hue='outcome', data=Interval)\nplt.xlabel('Time Interval (mins)', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Percentage of Goals in {} Feature'.format('Time'), size=15, y=1.05)\nplt.show()","2618cbc3":"#'position_x' and position_y\n#These are the (x,y) positions of shots. To understand the distribution we can plot a scatter graph\nplt.figure(figsize=(22, 9))\nsns.scatterplot(x=ShotData['position_y'], y=ShotData['position_x'], hue=ShotData['outcome'])\nplt.xlabel('Y', size=15, labelpad=20)\nplt.ylabel('X', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Goals scored by location', size=15, y=1.05)\nplt.show()","00934e1a":"#'play_type'\n#This will best be visualised with a bar chart to show the relative success of different types of play\n#There is one data entry named 'direct corner' while the other entries of this type are 'Direct Corner', so we should change this\nShotData['play_type'] = ShotData['play_type'].replace('Direct corner', 'Direct Corner')\nplt.figure(figsize=(22, 9))\nsns.countplot(x='play_type', hue='outcome', data=ShotData)\nplt.xlabel('Play Type', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.legend(['Goal', 'NoGoal'], loc='upper right', prop={'size': 15})\nplt.title('Count of Goals in {} Feature'.format('play_type'), size=15, y=1.05)\nplt.show()\n\n#The axis is skewed since the vast majority of shots come from open play.\n#Looking instead at percentage of shots that end in a goal for each play type:\nPlayType = ShotData.groupby('play_type')['outcome'].value_counts(normalize=True).mul(100).rename('Percent').reset_index()\nplt.figure(figsize=(22, 9))\nsns.barplot(x='play_type', y='Percent', hue='outcome', data=PlayType)\nplt.xlabel('Play Type', size=15, labelpad=20)\nplt.ylabel('Shot Outcome Percentage', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Percentage of Goals in {} Feature'.format('play_type'), size=15, y=1.05)\nplt.show()","6437e05d":"#'BodyPart'\n#We approach this in the same way as play_type\nplt.figure(figsize=(22, 9))\nsns.countplot(x='BodyPart', hue='outcome', data=ShotData)\nplt.xlabel('BodyPart', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.legend(['Goal', 'NoGoal'], loc='upper right', prop={'size': 15})\nplt.title('Count of Goals in {} Feature'.format('BodyPart'), size=15, y=1.05)\nplt.show()\n\n#Looking instead at percentage of shots that end in a goal for each body part:\nBodyPart = ShotData.groupby('BodyPart')['outcome'].value_counts(normalize=True).mul(100).rename('Percent').reset_index()\nplt.figure(figsize=(22, 9))\nsns.barplot(x='BodyPart', y='Percent', hue='outcome', data=BodyPart)\nplt.xlabel('Body Part', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Percentage of Goals in {} Feature'.format('BodyPart'), size=15, y=1.05)\nplt.show()","41671b50":"#'Number_Intervening_Opponents' and 'Number_Intervening_Teammates'\n#If there are bodies in the way of a shot, they will interfere regardless of what team they are on\n#It therefore makes sense to combine these two columns into one\nShotData['Intervening'] = ShotData['Number_Intervening_Opponents'] + ShotData['Number_Intervening_Teammates']\nplt.figure(figsize=(22, 9))\nsns.countplot(x='Intervening', hue='outcome', data=ShotData)\nplt.xlabel('Number of Players Intervening', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.legend(['Goal', 'NoGoal'], loc='upper right', prop={'size': 15})\nplt.title('Count of Goals in {} Feature'.format('Intervening'), size=15, y=1.05)\nplt.show()\n\n#Looking instead at percentage of shots that end in a goal for each number of intervening players:\nIntervening = ShotData.groupby('Intervening')['outcome'].value_counts(normalize=True).mul(100).rename('Percent').reset_index()\nplt.figure(figsize=(22, 9))\nsns.barplot(x='Intervening', y='Percent', hue='outcome', data=Intervening)\nplt.xlabel('Number of Players Intervening', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Percentage of Goals in {} Feature'.format('Intervening'), size=15, y=1.05)\nplt.show()","e51a30d8":"#'Interference_on_Shooter'\n#There are several rows with missing data. \n#A closer look shows us that all these shots had few intervening players and all resulted in goals.\n#It would therefore be sensible to fill these null values with a 'Low' interference level:\nShotData['Interference_on_Shooter'] = ShotData['Interference_on_Shooter'].fillna('Low')\n#Finally, this variable will also be best visualized with a bar plot\nplt.figure(figsize=(22, 9))\nsns.countplot(x='Interference_on_Shooter', hue='outcome', data=ShotData)\nplt.xlabel('Interference Level', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.legend(['Goal', 'NoGoal'], loc='upper right', prop={'size': 15})\nplt.title('Count of Goals in {} Feature'.format('Interference_on_Shooter'), size=15, y=1.05)\nplt.show()\n\n#Looking instead at percentage of shots that end in a goal for each level of interference:\nInterference = ShotData.groupby('Interference_on_Shooter')['outcome'].value_counts(normalize=True).mul(100).rename('Percent').reset_index()\nplt.figure(figsize=(22, 9))\nsns.barplot(x='Interference_on_Shooter', y='Percent', hue='outcome', data=Interference)\nplt.xlabel('Interference Level', size=15, labelpad=20)\nplt.ylabel('Shot Outcome', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Percentage of Goals in {} Feature'.format('Interference_on_Shooter'), size=15, y=1.05)\nplt.show()","d971045d":"#Correlations\nShotData_corr = ShotData.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\nShotData_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\nShotData_corr.drop(ShotData_corr.iloc[7::2].index, inplace=True)\nShotData_corr_nd = ShotData_corr.drop(ShotData_corr[ShotData_corr['Correlation Coefficient'] == 1.0].index)\nplt.figure(figsize=(20,20))\nsns.heatmap(ShotData.drop(['match_minute','match_second'], axis=1).corr(), annot=True, square=True, cmap='coolwarm', annot_kws={'size': 18})\nplt.tick_params(axis='x', labelsize=14)\nplt.tick_params(axis='y', labelsize=14)\nplt.title('Shot Data Correlations', size=20, y=1.05)\nplt.show()","58cab518":"#Reminder of the data set\nShotData.head()","221d2b5a":"#'match_minute' and 'match_second'\n#These features are obsolete with the time bins we introduced, so can be dropped:\nShotData.drop(['match_minute','match_second'], axis=1, inplace=True)","aeca8567":"#'position_x' and 'position_y'\n#From the scatter plot, it is clear that most goals are scored close to the origin.\n#A naive model might hence associate low x values with a higher chance of scoring.\n#This is not always the case, for example shots near the corner.\n#Instead, we should base our predictions on shot distance and shot angle\n#To find these we perform a coordinate transformation from cartesian (x,y) to polar (R, theta)\n#We use goals of width 7.32m and posts with coordinates (0,-3.66),(0,3.66), then use trigonometry to find shot angle\nShotData['Shot_Distance'] = np.sqrt(ShotData['position_x']**2 + ShotData['position_y']**2)\nShotData['Shot_Angle'] = np.degrees(np.arcsin((7.32*ShotData['position_x'])\/\n                                              (np.sqrt(ShotData['position_x']**2 + (ShotData['position_y']-3.66)**2)*np.sqrt(ShotData['position_x']**2 + (ShotData['position_y']+3.66)**2))))\nShotData.drop(['position_x','position_y'], axis=1, inplace=True)","5a4739fc":"#'play_type' and 'BodyPart'\n#These two features are non-ordinal categorical variables, and we should therefore One-Hot Encode them:\nShotData = pd.get_dummies(ShotData, columns=['play_type','BodyPart'])","3326a8a9":"#'Number_Intervening_Opponents' and 'Number_Intervening_Teammates'\n#These features are obsolete having been combined in 'Intervening', so can be dropped\nShotData.drop(['Number_Intervening_Opponents','Number_Intervening_Teammates'], axis=1, inplace=True)","82882f00":"#'Interference_on_Shooter'\n#This feature is a categorical ordinal feature (Low->Medium->High) and so we can label encode it\n#Rather than using a label encoder it is simpler in this case to use replace()\nShotData['Interference_on_Shooter'] = ShotData['Interference_on_Shooter'].replace('Low', 1)\nShotData['Interference_on_Shooter'] = ShotData['Interference_on_Shooter'].replace('Medium', 2)\nShotData['Interference_on_Shooter'] = ShotData['Interference_on_Shooter'].replace('High', 3)","17ae788c":"#'Time'\n#This is a categorical feature and not immediately obvious if it is ordinal or not.\n#For example, you might expect more goals to be scored later in games when defenders are tiring.\n#Based on the barplots, which showed no clear trends, I would argue that it is not ordinal, and should therefore be OH Encoded.\nShotData = pd.get_dummies(ShotData, columns=['Time'])","00961e25":"#Outcome\n#This is a binary Goal\/NoGoal target variable, so we can replace with 1s and 0s:\nShotData['outcome'] = ShotData['outcome'].replace('Goal', 1)\nShotData['outcome'] = ShotData['outcome'].replace('NoGoal', 0)\nShotData.head()","af08cd5b":"#First splitting the data into training data and validation data that will allow us to tune the model\ny = ShotData['outcome']\nX = ShotData.drop(['outcome'], axis=1)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, \n                                                               test_size=0.3, random_state=0)","c320ab8f":"#The model we will use is a Gradient Boosting Classifier, which is an ensemble of decision trees.\n#Models are added iteratively, using the loss function to train new models as they are added\n#We will define a function to find the best hyperparameters for the model using Bayesian optimization:\n\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\ndef hyperopt_train_test(params): \n    model = GradientBoostingClassifier(\n                        learning_rate=params['learning_rate'],\n                        min_samples_leaf=params['min_samples_leaf'],\n                        max_depth = params['max_depth'],\n                        max_features = params['max_features'],\n                        random_state=0)\n\n    model.fit(X_train, y_train)\n    return {\n        'learning_rate': params['learning_rate'],\n        'min_samples_leaf': params['min_samples_leaf'],\n        'max_depth': params['max_depth'],\n        'max_features': params['max_features'],     \n        'train_ROCAUC': roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n        'valid_ROCAUC': roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n        'train_PRAUC': average_precision_score(y_train, model.predict_proba(X_train)[:, 1]),\n        'valid_PRAUC': average_precision_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n        'recall': recall_score(y_valid, model.predict(X_valid)),\n        'precision': precision_score(y_valid, model.predict(X_valid)),\n        'f1_score': f1_score(y_valid, model.predict(X_valid)),\n        'train_accuracy': model.score(X_train, y_train),\n        'validation_accuracy': model.score(X_valid, y_valid),\n    }\n\ndef f(params):\n    res = hyperopt_train_test(params)\n    res['loss'] = - res['valid_ROCAUC']\n    res['status'] = STATUS_OK \n    return res \n\nspace4gbc = {\n        'learning_rate': hp.uniform('learning_rate', 0.05, 0.3),\n        'min_samples_leaf': hp.choice('min_samples_leaf', range(15, 200)),\n        'max_depth': hp.choice('max_depth', range(2, 20)),\n        'max_features': hp.choice('max_features', range(5, 15))\n}\n","ffee0a9e":"trials = Trials() #Showing trials as they are run\nbest = fmin(f, space4gbc, algo=tpe.suggest, max_evals=50, trials=trials) #minimises our function across parameter space\nprint(best)","5dcb1b07":"#Our data set is highly imbalanced, with far more no-goals than goals.\n#If we predicted no-goal in every case we would get an accuracy of:\nprint(1-y.sum()\/len(y))","4a3092d3":"#Therefore the best metric to evaluate our model is Precision-Recall Area Under Curve (PR-AUC)\n#This metric is better to evaluate imbalanced data sets where we are interested in the positive class (goals)\n#Top 5 trials ranked by PR-AUC\npd.DataFrame(trials.results).sort_values(by='valid_PRAUC', ascending=False).head(5)","69c772c5":"#We choose our hyperparameters from above\nmodel = GradientBoostingClassifier(learning_rate=0.266464,\n                                   min_samples_leaf=45,\n                                   max_depth=3,\n                                   max_features=15,\n                                   random_state=0)\nmodel.fit(X_train,y_train)\n\nprint('The model has an accuracy of {}%.'.format(round(model.score(X_valid, y_valid)*100),2))\nprint('A baseline guess of no-goal for every shot has an accuracy of {}%.'.format(round((1-y.sum()\/len(y))*100),2))\nprint('*'*30)\nprint('The model has a PR-AUC score of {}%.'.format(round(average_precision_score(y_valid, model.predict_proba(X_valid)[:, 1])*100),2))\nprint('The baseline PR-AUC score is {}%.'.format(round((y.sum()\/len(y))*100),2))","f0854bb5":"#Using a confusion matrix tells us which shots are being correctly classified\nmatrix = confusion_matrix(y,model.predict(X))\nprint('Confusion Matrix:')\nprint(matrix)","c0065b73":"print('In total there were {} shots, with {} goals and {} no-goals'.format(matrix.sum(axis=0).sum(), matrix.sum(axis=1)[1], matrix.sum(axis=1)[0]))\nprint('Our model correctly predicted {} goals and {} misses'.format(matrix[1][1], matrix[0][0]))\nprint('There were {} goals incorrectly classed as misses, and {} misses incorrectly classed as goals'. format(matrix[1][0], matrix[0][1]))","3b9356bd":"#We can sanity-check the model by calculating goal probability for our shots\nShotData['PGoal'] = model.predict_proba(X)[:,1]\nShotData.sort_values('PGoal', ascending=False)","cd789293":"#Finally, we can have a look at feature importance, which will tell us which features were more or less important in helping the model to classify shots:\nimport eli5\neli5.explain_weights(model, feature_names=list(X_train.columns))","4f31c81d":"#Read the data\nevents = pd.read_csv('\/kaggle\/input\/raweventsdata\/data\/Sample_Game_2\/Sample_Game_2_RawEventsData.csv', index_col='Start Frame')\nevents.head()","edc07ef6":"#Reading tracking data and cleaning column values.\n#The frame feature is common to both tracking and events data, so will be used as an index.\nhome_tracking = pd.read_csv('..\/input\/raweventsdata\/data\/Sample_Game_2\/Sample_Game_2_RawTrackingData_Home_Team.csv', skiprows=2)\nfor i in range(2,16):\n    home_tracking.columns.values[(2*i)-1] = '{}_x(home)'.format(home_tracking.columns.values[(2*i)-1])\n    home_tracking.columns.values[(2*i)] = '{}_y(home)'.format(home_tracking.columns.values[(2*i)-1].split('_')[0])\nhome_tracking.columns.values[-1] = 'Ball_y'\nhome_tracking.columns.values[-2] = 'Ball_x'\nhome_tracking = home_tracking.set_index('Frame')\n\naway_tracking = pd.read_csv('..\/input\/raweventsdata\/data\/Sample_Game_2\/Sample_Game_2_RawTrackingData_Away_Team.csv', skiprows=2)\nfor i in range(2,14):\n    away_tracking.columns.values[(2*i)-1] = '{}_x(away)'.format(away_tracking.columns.values[(2*i)-1])\n    away_tracking.columns.values[2*i] = '{}_y(away)'.format(away_tracking.columns.values[(2*i)-1].split('_')[0])\naway_tracking.columns.values[-1] = 'Ball_y'\naway_tracking.columns.values[-2] = 'Ball_x'\naway_tracking = away_tracking.set_index('Frame')","50607d4c":"#Merging home and away tracking\n#Drop duplicate columns:\nhome_tracking.drop(columns=['Ball_x','Ball_y'], inplace = True)\naway_tracking.drop(columns=['Period', 'Time [s]'], inplace = True)\n#Merge\nfull_tracking = home_tracking.merge(away_tracking, left_index=True, right_index=True)","18054467":"#Merging tracking and events data\n#Drop duplicate columns:\nfull_tracking.drop('Period', axis=1, inplace=True)\n#We are interested only in where a shot is taken from and not where it ends up.\n#Hence we are only interested in the starting time, frame and position of each event.\n#Start time is already contained in the time feature of the tracking data\n#Start positions are already contained in the ball feature of the tracking data\nevents.drop(columns=['Start Time [s]', 'End Frame', 'End Time [s]', 'Start X', 'Start Y', 'End X', 'End Y'], inplace=True)\nsample_game = events.merge(full_tracking, left_index=True, right_index=True)\n","5c5b2719":"#Filtering down to just the shots\nsample_game_shots = sample_game[sample_game['Type'] == 'SHOT']\nprint(sample_game_shots.columns)\nsample_game_shots.head()","2f7b56cb":"#It will help to convert x and y positions to the same coordinate frame as the ShotData.\n#This coordinate system begins in the top-left, and values range from 0->1\n#A pitch has dimensions 106m x 68m, so we will multiply our values by these numbers.\n#We must also shift our y values by 0.5\nfor i in range(4,31):\n    sample_game_shots.iloc[:,(2*i)-1] = sample_game_shots.iloc[:,(2*i)-1]*106\n    sample_game_shots.iloc[:,2*i] = (sample_game_shots.iloc[:,2*i]-0.5)*68\n","ff795344":"#Reset the index so shot count starts from zero\nsample_game_shots.reset_index(inplace=True, drop=True)","c7f8af05":"#Plotting positions\nhome_x = sample_game_shots.iloc[:,7:34:2]\nhome_y = sample_game_shots.iloc[:,8:35:2]\naway_x = sample_game_shots.iloc[:,35:58:2]\naway_y = sample_game_shots.iloc[:,36:59:2]\nball_x = sample_game_shots['Ball_x']\nball_y = sample_game_shots['Ball_y']\n\nShotNumber = 19\n\nplt.figure(figsize=(22, 9))\nsns.scatterplot(x=np.array([ball_x.iloc[ShotNumber]]), y=np.array([ball_y.iloc[ShotNumber]]), color='black', alpha=1.0, s=200, label='Ball')\nsns.scatterplot(x=home_x.iloc[ShotNumber].values, y=home_y.iloc[ShotNumber].values, color='red', alpha=0.7, s=100, label='Home')\nsns.scatterplot(x=away_x.iloc[ShotNumber].values, y=away_y.iloc[ShotNumber].values, color='blue', alpha=0.7, s=100, label='Away')\nplt.xlim([0,106])\nplt.ylim([-34,34])\nplt.xlabel('X', size=15, labelpad=20)\nplt.ylabel('Y', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\nplt.show()","6be8855f":"#Using these shot plots, the job now is to manually obtain values for interference, intervening, play type and body part.\n#Time and shot distance\/angle can be found from the sample_game_shots dataframe, although we must be careful to check direction of play for x positions:\n#x positions:\n\nsample_game_shots['x_distance'] = sample_game_shots['Ball_x']\nsample_game_shots.loc[((sample_game_shots['Team'] == 'Away') & (sample_game_shots['Period'] == 1)),'x_distance'] = 106 - sample_game_shots.loc[((sample_game_shots['Team'] == 'Away') & (sample_game_shots['Period'] == 1)),'x_distance']\nsample_game_shots.loc[((sample_game_shots['Team'] == 'Home') & (sample_game_shots['Period'] == 2)),'x_distance'] = 106 - sample_game_shots.loc[((sample_game_shots['Team'] == 'Home') & (sample_game_shots['Period'] == 2)),'x_distance']","5e1b6f86":"#We will create dataframes for the test data with the same structure as the training data so that the model recognises it.\n#It will help to split the test data into home and away shots so we can decide who had better chances\nhome_full = sample_game_shots[sample_game_shots['Team'] == 'Home']\n\nhome_X_test = pd.DataFrame(columns=X.columns, index= list(home_full.index))\nhome_y_test = pd.DataFrame(home_full['Subtype'])\n\n#Shot Distance and Shot Angle can be found reusing the code from earlier\nhome_X_test['Shot_Distance'] = np.sqrt(home_full['x_distance']**2 + home_full['Ball_y']**2)\nhome_X_test['Shot_Angle'] = np.degrees(np.arcsin((7.32*home_full['x_distance'])\/(np.sqrt(home_full['x_distance']**2 + (home_full['Ball_y']-3.66)**2)*np.sqrt(home_full['x_distance']**2 + (home_full['Ball_y']+3.66)**2))))\n\n#Interference, Intervening and play type will all be inferred from shot plots.\n#As we have no implicit definitions for interference or intervening, these numbers will be approximate\n#For larger data sets, this could (should) be automated\nhome_X_test['Interference_on_Shooter'] = [2,2,2,3,1,1,2,2,1,1,2,3,1]\nhome_X_test['Intervening'] = [3,1,2,2,4,2,3,1,1,2,2,3,4]\nhome_X_test['play_type_Direct Corner'] = [0,0,0,0,0,0,0,0,0,0,0,0,0]\nhome_X_test['play_type_Direct freekick'] = [0,0,0,0,0,0,0,0,0,0,0,0,0]\nhome_X_test['play_type_Open Play'] = [1,1,1,1,1,1,1,1,1,1,1,1,1]\nhome_X_test['play_type_Penalty'] = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n\n#For body part, we only have information on whether it was a header or not\n#In this case, I will use the assumption that every other shot was right-footed (left\/right outcomes were highly balanced)\nhome_X_test['BodyPart_Head'] = home_full['Subtype'].str.startswith('HEAD').astype(int)\nhome_X_test['BodyPart_Left'] = 0\nhome_X_test['BodyPart_Other'] = 0 \nhome_X_test['BodyPart_Right'] = home_X_test['BodyPart_Head'].replace({0:1,1:0}) \n\n#For time, we can divide into period 1 and 2 then define approximate quarters at 1350s (22.5min) and 4050s (67.5min)\nhome_X_test['Time_FirstQuarter'] = ((home_full['Period'] == 1) & (home_full['Time [s]'] < 1350)).astype(int)\nhome_X_test['Time_SecondQuarter'] = ((home_full['Period'] == 1) & (home_full['Time [s]'] >= 1350)).astype(int)\nhome_X_test['Time_ThirdQuarter'] = ((home_full['Period'] == 2) & (home_full['Time [s]'] < 4050)).astype(int)\nhome_X_test['Time_FourthQuarter'] = ((home_full['Period'] == 2) & (home_full['Time [s]'] >= 4050)).astype(int)\n","366bc3df":"#Doing the same for the away team:\naway_full = sample_game_shots[sample_game_shots['Team'] == 'Away']\n\naway_X_test = pd.DataFrame(columns=X.columns, index= list(away_full.index))\naway_y_test = pd.DataFrame(away_full['Subtype'])\n\n#Shot Distance and Shot Angle can be found reusing the code from earlier\naway_X_test['Shot_Distance'] = np.sqrt(away_full['x_distance']**2 + away_full['Ball_y']**2)\naway_X_test['Shot_Angle'] = np.degrees(np.arcsin((7.32*away_full['x_distance'])\/(np.sqrt(away_full['x_distance']**2 + (away_full['Ball_y']-3.66)**2)*np.sqrt(away_full['x_distance']**2 + (away_full['Ball_y']+3.66)**2))))\n\n#Interference, Intervening and play type will all be inferred from shot plots.\n#As we have no implicit definitions for interference or intervening, these numbers will be approximate\n#For larger data sets, this could (should) be automated\naway_X_test['Interference_on_Shooter'] = [1,2,3,1,1,1,1,1,1,1,3]\naway_X_test['Intervening'] = [4,1,1,7,3,8,3,4,1,13,2]\naway_X_test['play_type_Direct Corner'] = [0,0,0,0,0,0,0,0,0,0,0]\naway_X_test['play_type_Direct freekick'] = [0,0,0,0,0,0,0,0,0,1,0]\naway_X_test['play_type_Open Play'] = [1,1,1,1,1,1,1,1,0,0,1]\naway_X_test['play_type_Penalty'] = [0,0,0,0,0,0,0,0,1,0,0]\n\n#For body part, we only have information on whether it was a header or not\n#In this case, I will use the assumption that every other shot was right-footed (left\/right outcomes were highly balanced)\naway_X_test['BodyPart_Head'] = away_full['Subtype'].str.startswith('HEAD').astype(int)\naway_X_test['BodyPart_Left'] = 0\naway_X_test['BodyPart_Other'] = 0 \naway_X_test['BodyPart_Right'] = away_X_test['BodyPart_Head'].replace({0:1,1:0}) \n\n#For time, we can divide into period 1 and 2 then define approximate quarters at 1350s (22.5min) and 4050s (67.5min)\naway_X_test['Time_FirstQuarter'] = ((away_full['Period'] == 1) & (away_full['Time [s]'] < 1350)).astype(int)\naway_X_test['Time_SecondQuarter'] = ((away_full['Period'] == 1) & (away_full['Time [s]'] >= 1350)).astype(int)\naway_X_test['Time_ThirdQuarter'] = ((away_full['Period'] == 2) & (away_full['Time [s]'] < 4050)).astype(int)\naway_X_test['Time_FourthQuarter'] = ((away_full['Period'] == 2) & (away_full['Time [s]'] >= 4050)).astype(int)\n","fb3a694e":"#Now we have our cleaned shot data, we can run the model to see the probabilities of each shot ending up as a goal\nhome_y_test['PGoal'] = model.predict_proba(home_X_test)[:,1]\nprint('Home scored 3 goals. The chance quality model suggests they should have scored {}'.format(home_y_test['PGoal'].sum()))\nhome_y_test","29642b2e":"away_y_test['PGoal'] = model.predict_proba(away_X_test)[:,1]\nprint('Away scored 2 goals. The chance quality model suggests they should have scored {}'.format(away_y_test['PGoal'].sum()))\naway_y_test","c264910a":"#Joining the shot data together to help with the report:\nreport = pd.concat([home_y_test,away_y_test]).sort_index()\nreport['Team'] = sample_game_shots['Team']\nreport['Player'] = sample_game_shots['From']\nreport['Time [min]'] = round(sample_game_shots['Time [s]'] \/ 60,2)\nreport['Period'] = sample_game_shots['Period']","11930ea4":"**Applying the model**","07d92084":"**Model Fitting**","f6cc0f92":"# Step 2 - Sample Game\n\nThe aim of this step is to apply my chance quality model to a sample game, using tracking data for the home and away teams in order to construct a report on which team had the better chances and should have won. I will first explore the data, then attempt to manipulate it into the same format as my shot data training set, such that the model can then be applied to this game.","a2d2e76e":"**Exploratory Data Analysis and Cleaning**","40834b5e":"**Conclusions**\n\nThe match finished 3-2. The home team had more shots, but the away team should have scored more goals. This can largely be attributed to a few high quality chances, including a penalty.","b605fc75":"A shot from 1.8 metres out and a shot angle of 35.8 degrees, with low interference and no intervening players, scored a goal probability of **0.95**.\n\nA shot from 34.96 metres out and a shot angle of 8.9 degrees, with medium interference and 3 intervening players, scored a goal probability of **0.01** (Just!)","7433f27b":"**Data Processing**\n\nAll of our features should be in a format that is useful to our algorithm","4ea57b26":"**Data Exploration**","f0584322":"# STEP 1 - MODEL\n\nThe aim of this step is to create a chance quality model using the 'ShotData' dataset, calculating the probability of a shot resulting in a goal. My approach is to first investigate the data with some exploratory data analysis, process the data so it will be in its most useful form, then fit and tune a model using machine learning that will predict the probability of a goal being scored."}}