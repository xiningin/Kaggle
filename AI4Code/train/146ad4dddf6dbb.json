{"cell_type":{"f1ccbdff":"code","26a9c3e0":"code","64698b99":"code","9689ed16":"code","d1697036":"code","a015ca8a":"code","f9730408":"code","c392c9dc":"code","6dc55c3b":"code","40350d18":"code","e2436826":"code","0d3b0b53":"markdown","fab580f3":"markdown","52a52310":"markdown"},"source":{"f1ccbdff":"import pandas as pd\nimport numpy as np\n\npd.options.display.max_columns = 250\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import plot_confusion_matrix\n\nimport matplotlib.pyplot as plt\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26a9c3e0":"%mkdir --parents \/root\/.kaggle\/\n%cp \/kaggle\/input\/kaggle.json","64698b99":"train_df = pd.read_csv('\/kaggle\/input\/homesite-quote-conversion\/train.csv.zip')\ntest_df = pd.read_csv('\/kaggle\/input\/homesite-quote-conversion\/test.csv.zip')\nsample_submission_df = pd.read_csv('\/kaggle\/input\/homesite-quote-conversion\/sample_submission.csv.zip')","9689ed16":"def drop_cols(df):\n    df.drop(['Original_Quote_Date'],axis=1,inplace=True)\n    return df\n\ntrain_df = drop_cols(train_df)\ntest_df = drop_cols(test_df)","d1697036":"cols_to_delete = train_df.isna().sum()[train_df.isna().sum() > 0].index\n\ndef drop_cols_from_list(df,cols_to_delete):\n    df.drop(cols_to_delete,axis=1,inplace=True)\n    return df\n\ntrain_df = drop_cols_from_list(train_df,cols_to_delete)\ntest_df = drop_cols_from_list(test_df,cols_to_delete)","a015ca8a":"#dropping high unique categorical columns\ncols_to_drop = []\n\nfor i in set(train_df.columns) - set(train_df._get_numeric_data().columns):\n    if (train_df.loc[:,i].nunique() >= 3):\n        cols_to_drop.append(i)\n        \ntrain_df = drop_cols_from_list(train_df,cols_to_drop)\ntest_df = drop_cols_from_list(test_df,cols_to_drop)","f9730408":"cls_to_encode = set(train_df.columns) - set(train_df._get_numeric_data().columns)\n\n#one hot encoding:\ndef ohe(df,cls_to_encode):\n    df = pd.get_dummies(df,columns=cls_to_encode,drop_first=True)\n    return df\n\ntrain_df = ohe(train_df,cls_to_encode)\ntest_df = ohe(test_df,cls_to_encode)","c392c9dc":"test_df[list(set(test_df.columns) - set(train_df.columns))] = 0","6dc55c3b":"X = train_df.drop('QuoteConversion_Flag',axis=1)\ny = train_df.QuoteConversion_Flag\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42)\n\n\nrfc = RandomForestClassifier(n_jobs=-1)\nrfc.fit(X_train,y_train)","40350d18":"print(\"train accuracy score = \", accuracy_score(y_train,rfc.predict(X_train)))\nprint(\"test accuracy score = \", accuracy_score(y_test,rfc.predict(X_test)))\n\nplot_roc_curve(rfc, X_test, y_test)\nplt.show()\n\nplot_confusion_matrix(rfc, X_test, y_test,values_format='d')\nplt.show()\n","e2436826":"output_submission = pd.DataFrame(zip(X_test.QuoteNumber,rfc.predict(X_test)), columns = ['QuoteNumber','QuoteConversion_Flag'])\noutput_submission.to_csv('\/kaggle\/working\/output_submission.csv',index=False)","0d3b0b53":"## Removing outliers & na values","fab580f3":"## RF MODEL","52a52310":"## Dropping Columns"}}