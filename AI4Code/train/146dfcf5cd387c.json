{"cell_type":{"d5d2ebd2":"code","3191a433":"code","f8ff196f":"code","6bb14a47":"code","969e148b":"code","74e3523a":"code","9402bd04":"code","8759a11c":"code","9ca873a8":"code","487314bc":"code","31217b0a":"code","316e33f4":"code","dac76170":"code","dc902603":"code","c51bec06":"code","cbd2d457":"code","13a1d3ae":"code","fe5148c7":"code","2879f89a":"code","416fe63c":"code","d35ab6a2":"code","2a56d575":"code","8d009a08":"code","a199689a":"code","381558dc":"code","b8c86d96":"code","f6721324":"code","9705757b":"code","df854492":"code","03bd2d20":"code","00529fd6":"code","86d7f775":"code","ea699158":"code","add6dc80":"code","b00d33ba":"code","11df846b":"code","50e74b71":"code","ef7d7473":"code","75411fa1":"code","e70746bd":"code","ab061ac4":"code","d8c7576f":"code","48599ea1":"code","f17cbb03":"code","018d975f":"code","635da750":"code","133eddcf":"code","0306ecf9":"code","07389717":"code","4d9335af":"code","1bc29369":"code","e4dc2fab":"code","18be92b3":"code","a258f7ab":"code","6454ecba":"code","51d64382":"code","0bbaf746":"code","7f2ab070":"code","858e8f8c":"code","0a52bea5":"code","5757495a":"code","eb77aeb8":"code","02844ea9":"code","7e8ddb2b":"code","795935d1":"code","c6c8a2e2":"code","53f9ba77":"code","6e7fb861":"code","7ee22289":"code","518d47ea":"code","6285621a":"code","2de389f5":"code","f50b8c0b":"code","73c95aae":"code","197f479e":"code","397bf0a4":"code","b848e96d":"code","a98a4c5c":"code","c52727e0":"code","36c516c8":"code","f46ad2f8":"code","0fc05b45":"code","c4af7350":"markdown","009a4db4":"markdown","d1338534":"markdown","f791737f":"markdown","6711e14a":"markdown","998c44ae":"markdown","3d2ba4a3":"markdown","f882701e":"markdown","af833781":"markdown","c79eba84":"markdown","a8aca891":"markdown","9aa8e28e":"markdown","cfee6d74":"markdown","c64a04ac":"markdown","0b12aba3":"markdown","e8ca4dc6":"markdown","aab34f82":"markdown"},"source":{"d5d2ebd2":"!pip install --upgrade seaborn\n!pip install ensemble_boxes","3191a433":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","f8ff196f":"pd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.set_option('max_colwidth',1600)","6bb14a47":"dim = 512 #512, 256, 'original'\nfold = 4","969e148b":"train_df = pd.read_csv(f'..\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df.head()","74e3523a":"train_df['image_path'] = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train\/'+train_df.image_id+('.png' if dim!='original' else '.jpg')\ntrain_df.head()","9402bd04":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","8759a11c":"# train_df[(train_df.image_id=='9a5094b2563a1ef3ff50dc5c7ff71345')]","9ca873a8":"# IoU = Calculate_IoU( (692.0,1375.0,1657.0,1799.0), (689.0,1313.0,1666.0,1763.0))\n# print(\"IoU\u662f\uff1a{}\".format(IoU))","487314bc":"# train_df[(train_df.image_id=='051132a778e61a86eb147c7c6f564dfe')]","31217b0a":"train_df.shape","316e33f4":"class_name_ids = ['Aortic enlargement','Atelectasis','Calcification','Cardiomegaly','Consolidation','ILD','Infiltration','Lung Opacity','Nodule\/Mass','Other lesion','Pleural effusion','Pleural thickening','Pneumothorax','Pulmonary fibrosis']\nvalues = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\nclass_dictionary = dict(zip(class_name_ids, values))\nprint (class_dictionary)","dac76170":"train_df['class_id'].value_counts(normalize = False, dropna = False)","dc902603":"# class_name_ids = ['Aortic Enlargement','Atelectasis','Calcification','Cardiomegaly','Consolidation','ILD','Infiltration','Lung Opacity','Nodule\/Mass','Other Lesion','Pleural Effusion','Pleural Thickening','Pneumothorax','Pulmonary Fibrosis']\n# values = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n# class_dictionary = dict(zip(class_name_ids, values))\n# print (class_dictionary)","c51bec06":"# # import numpy as np\n# import pandas as pd\n\n# from tqdm import tqdm\n# from ensemble_boxes import *\n\n# consist_iou_threshold=0.3\n# # ===============================\n# # Default WBF config (you can change these)\n# iou_thr = 0.5\n# skip_box_thr = 0.0001\n# sigma = 0.1\n# # ===============================\n\n# # Loading the train DF\n# # df = pd.read_csv(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\")\n# df = train_df\n# df.fillna(0, inplace=True)\n# # df.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\n# results = []\n# image_ids = df[\"image_id\"].unique()\n\n\n# count=3#\n\n\n# for image_id in tqdm(image_ids, total=len(image_ids)):\n#     count-=1\n#     print('count',count)\n#     if count==0:#\n#         break#\n    \n#     print('image_id',image_id)\n        \n#     # All annotations for the current image.\n#     data = df[df[\"image_id\"] == image_id]\n#     data = data.reset_index(drop=True)\n#     annotations = {}\n#     weights = []\n    \n    \n#     width=data.iloc[0].width\n#     height=data.iloc[0].height\n#     image_path=data.iloc[0].image_path\n#     class_name=data.iloc[0].class_name\n\n#     # WBF expects the coordinates in 0-1 range.\n#     max_value = data.iloc[:, 4:8].values.max()\n#     data.loc[:, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]] = data.iloc[:, 4:8]\n\n#     # Loop through all of the annotations\n#     for idx, row in data.iterrows():\n\n#         class_name_id = row[\"class_name\"]\n\n#         if class_name_id not in annotations:\n#             annotations[class_name_id] = {\n#                 \"boxes_list\": [],\n#                 \"rad_id_list\": [],\n#                 \"labels_list\": [],\n#             }\n\n#             # We consider all of the radiologists as equal.\n#             weights.append(1.0)\n\n#         annotations[class_name_id][\"boxes_list\"].append([row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n#         annotations[class_name_id][\"rad_id_list\"].append(row[\"rad_id\"])\n#         annotations[class_name_id][\"labels_list\"].append(class_name_id)\n#         print('class_name_id',class_name_id)\n\n#     boxes_list = []\n#     rad_list = []\n#     labels_list = []\n    \n#     print('annotations',annotations)\n\n#     for annotator in annotations.keys():\n#         boxes_list.append(annotations[annotator][\"boxes_list\"])\n#         rad_list.append(annotations[annotator][\"rad_id_list\"])\n#         labels_list.append(annotations[annotator][\"labels_list\"])\n        \n#     print()\n#     print('boxes_list',boxes_list)\n#     print()\n#     print('rad_list',rad_list)\n#     print()\n#     print('labels_list',labels_list)","cbd2d457":"# import pandas as pd\n# df = pd.DataFrame({'BoolCol': [1, 2, 3, 3, 4],'attr': [22, 33, 22, 44, 66]},  \n#        index=[10,20,30,40,50])  \n# print(df)  \n# a = df[(df.BoolCol==3)&(df.attr==22)].index.tolist()  \n# print(a)  ","13a1d3ae":"def Calculate_IoU(predicted_bound, ground_truth_bound):\n    pxmin, pymin, pxmax, pymax = predicted_bound\n    print(\"\u9884\u6d4b\u6846P\u7684\u5750\u6807\u662f\uff1a({}, {}, {}, {})\".format(pxmin, pymin, pxmax, pymax))\n    gxmin, gymin, gxmax, gymax = ground_truth_bound\n    print(\"\u539f\u6807\u8bb0\u6846G\u7684\u5750\u6807\u662f\uff1a({}, {}, {}, {})\".format(gxmin, gymin, gxmax, gymax))\n    \n#  \"\"\"\n#  computing the IoU of two boxes.\n#  Args:\n#   box: (xmin, ymin, xmax, ymax),\u901a\u8fc7\u5de6\u4e0b\u548c\u53f3\u4e0a\u4e24\u4e2a\u9876\u70b9\u5750\u6807\u6765\u786e\u5b9a\u77e9\u5f62\u4f4d\u7f6e\n#  Return:\n#   IoU: IoU of box1 and box2.\n#  \"\"\"\n    \n\n    parea = (pxmax - pxmin) * (pymax - pymin) # \u8ba1\u7b97P\u7684\u9762\u79ef\n    garea = (gxmax - gxmin) * (gymax - gymin) # \u8ba1\u7b97G\u7684\u9762\u79ef\n    print(\"\u9884\u6d4b\u6846P\u7684\u9762\u79ef\u662f\uff1a{}\uff1b\u539f\u6807\u8bb0\u6846G\u7684\u9762\u79ef\u662f\uff1a{}\".format(parea, garea))\n    print('mark1')\n\n    # \u6c42\u76f8\u4ea4\u77e9\u5f62\u7684\u5de6\u4e0b\u548c\u53f3\u4e0a\u9876\u70b9\u5750\u6807(xmin, ymin, xmax, ymax)\n    xmin = max(pxmin, gxmin) # \u5f97\u5230\u5de6\u4e0b\u9876\u70b9\u7684\u6a2a\u5750\u6807\n    ymin = max(pymin, gymin) # \u5f97\u5230\u5de6\u4e0b\u9876\u70b9\u7684\u7eb5\u5750\u6807\n    xmax = min(pxmax, gxmax) # \u5f97\u5230\u53f3\u4e0a\u9876\u70b9\u7684\u6a2a\u5750\u6807\n    ymax = min(pymax, gymax) # \u5f97\u5230\u53f3\u4e0a\u9876\u70b9\u7684\u7eb5\u5750\u6807\n    print('mark2')\n    # \u8ba1\u7b97\u76f8\u4ea4\u77e9\u5f62\u7684\u9762\u79ef\n    w = xmax - xmin\n    h = ymax - ymin\n    if w <=0 or h <= 0:\n        return 0,(0,0,0,0)\n    print('mark3')\n    area = w * h # G\u2229P\u7684\u9762\u79ef\n    # area = max(0, xmax - xmin) * max(0, ymax - ymin) # \u53ef\u4ee5\u7528\u4e00\u884c\u4ee3\u7801\u7b97\u51fa\u6765\u76f8\u4ea4\u77e9\u5f62\u7684\u9762\u79ef\n    print(\"G\u2229P\u7684\u5750\u6807\u662f\uff1a\",xmin,ymin,xmax,ymax)\n    print(\"G\u2229P\u7684\u9762\u79ef\u662f\uff1a{}\".format(area))\n\n    # \u5e76\u96c6\u7684\u9762\u79ef = \u4e24\u4e2a\u77e9\u5f62\u9762\u79ef - \u4ea4\u96c6\u9762\u79ef\n    IoU = area \/ (parea + garea - area)\n\n    return IoU,(xmin,ymin,xmax,ymax)\n \nif __name__ == '__main__':\n    IoU = Calculate_IoU( (-1, -1, 1, 1), (0, 0, 2, 2))\n    print(\"IoU\u662f\uff1a{}\".format(IoU))","fe5148c7":"# import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nfrom ensemble_boxes import *\n\nconsist_iou_threshold=0.5\n# ===============================\n# Default WBF config (you can change these)\niou_thr = 0.5\nskip_box_thr = 0.0001\nsigma = 0.1\n# ===============================\n\n# Loading the train DF\n# df = pd.read_csv(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\")\ndf = train_df\ndf.fillna(0, inplace=True)\n# df.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\nresults = []\nimage_ids = df[\"image_id\"].unique()\n\n\n# count=3000#\n\n\nfor image_id in tqdm(image_ids, total=len(image_ids)):\n#     count-=1\n#     print('count',count)\n#     if count==0:#\n#         break#\n    \n    print('image_id',image_id)\n        \n    # All annotations for the current image.\n    data = df[df[\"image_id\"] == image_id]\n    data = data.reset_index(drop=True)\n    annotations = {}\n    weights = []\n    \n    \n    width=data.iloc[0].width\n    height=data.iloc[0].height\n    image_path=data.iloc[0].image_path\n    class_name=data.iloc[0].class_name\n\n    # WBF expects the coordinates in 0-1 range.\n    max_value = data.iloc[:, 4:8].values.max()\n    data.loc[:, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]] = data.iloc[:, 4:8]\n\n    # Loop through all of the annotations\n    for idx, row in data.iterrows():\n#         print('index',row.index.tolist()[0]) \n        class_name_id = row[\"class_name\"]\n#         print('index',row.index)\n        if class_name_id not in annotations:\n            annotations[class_name_id] = {\n                \"boxes_list\": [],\n                \"rad_id_list\": [],\n                \"labels_list\": [],\n            }\n\n            # We consider all of the radiologists as equal.\n            weights.append(1.0)\n\n        annotations[class_name_id][\"boxes_list\"].append([row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n        annotations[class_name_id][\"rad_id_list\"].append(row[\"rad_id\"])\n        annotations[class_name_id][\"labels_list\"].append(class_name_id)\n        print('class_name_id',class_name_id)\n\n    boxes_list = []\n    rad_list = []\n    labels_list = []\n    \n    print('annotations',annotations)\n\n    for annotator in annotations.keys():\n        boxes_list.append(annotations[annotator][\"boxes_list\"])\n        rad_list.append(annotations[annotator][\"rad_id_list\"])\n        labels_list.append(annotations[annotator][\"labels_list\"])\n        \n    print()\n    print('boxes_list',boxes_list)\n    print()\n    print('rad_list',rad_list)\n    print()\n    print('labels_list',labels_list)\n    print()\n    print()\n    \n#     for i in range(len(boxes_list)):\n        \n\n#         for j in range(0,len(boxes_list[i])-1):\n#             iou_value_list=[]\n# #             G_P_box_list=[]\n# #             box_pass_sign=False\n#             for k in range(1+j,len(boxes_list[i])):\n#                 gt_ground=(boxes_list[i][j][0], boxes_list[i][j][1], boxes_list[i][j][2], boxes_list[i][j][3])\n#                 pr_ground=(boxes_list[i][k][0], boxes_list[i][k][1], boxes_list[i][k][2], boxes_list[i][k][3])\n#                 print('gt_ground',gt_ground)\n#                 print('pr_ground',pr_ground)\n#                 iou_value,G_P_box=Calculate_IoU(gt_ground,pr_ground)\n#                 iou_value_list.append(iou_value)\n#                 # \u5982\u679c\u4e24\u4e2a\u6846iou\u5927\u4e8e\u9608\u503cconsist_iou_threshold\n#                 if iou_value>consist_iou_threshold:\n#                     results.append({\n#                     \"image_id\": image_id,\n#                     \"class_id\": int(class_dictionary[labels_list[i][0]]),\n#                     \"rad_id\": \"wbf\",\n#                     \"x_min\": G_P_box[0],\n#                     \"y_min\": G_P_box[1],\n#                     \"x_max\": G_P_box[2],\n#                     \"y_max\": G_P_box[3],\n#                     \"width\": width,\n#                     \"height\": height,\n#                     \"image_path\": image_path,\n#                     \"class_name\":  labels_list[i][0]\n#                 })\n\n    #                     G_P_box_list.append(G_P_box)\n    #             for p in range(len(iou_value_list)):\n    #                 pass\n    #                 np.mean(iou_value_list)\n    #             if box_pass_sign:\n\n    for i in range(len(boxes_list)):\n        \n        if (labels_list[i][0]=='Aortic enlargement')|(labels_list[i][0]=='Cardiomegaly')|(labels_list[i][0]=='Pleural effusion')|(labels_list[i][0]=='Pleural thickening')|(labels_list[i][0]=='Pulmonary fibrosis'):\n            for j in range(0,len(boxes_list[i])-1):\n                iou_value_list=[]\n    #             G_P_box_list=[]\n    #             box_pass_sign=False\n                for k in range(1+j,len(boxes_list[i])):\n                    gt_ground=(boxes_list[i][j][0], boxes_list[i][j][1], boxes_list[i][j][2], boxes_list[i][j][3])\n                    pr_ground=(boxes_list[i][k][0], boxes_list[i][k][1], boxes_list[i][k][2], boxes_list[i][k][3])\n                    print('gt_ground',gt_ground)\n                    print('pr_ground',pr_ground)\n                    iou_value,G_P_box=Calculate_IoU(gt_ground,pr_ground)\n                    iou_value_list.append(iou_value)\n                    # \u5982\u679c\u4e24\u4e2a\u6846iou\u5927\u4e8e\u9608\u503cconsist_iou_threshold\n                    if iou_value>consist_iou_threshold:\n                        results.append({\n                        \"image_id\": image_id,\n                        \"class_id\": int(class_dictionary[labels_list[i][0]]),\n                        \"rad_id\": \"wbf\",\n                        \"x_min\": G_P_box[0],\n                        \"y_min\": G_P_box[1],\n                        \"x_max\": G_P_box[2],\n                        \"y_max\": G_P_box[3],\n                        \"width\": width,\n                        \"height\": height,\n                        \"image_path\": image_path,\n                        \"class_name\":  labels_list[i][0]\n                    })\n\n    #                     G_P_box_list.append(G_P_box)\n    #             for p in range(len(iou_value_list)):\n    #                 pass\n    #                 np.mean(iou_value_list)\n    #             if box_pass_sign:\n        else:\n            for j in range(0,len(boxes_list[i])-1):\n                results.append({\n                    \"image_id\": image_id,\n                    \"class_id\": int(class_dictionary[labels_list[i][0]]),\n                    \"rad_id\": \"wbf\",\n                    \"x_min\": boxes_list[i][j][0],\n                    \"y_min\": boxes_list[i][j][1],\n                    \"x_max\": boxes_list[i][j][2],\n                    \"y_max\": boxes_list[i][j][3],\n                    \"width\": width,\n                    \"height\": height,\n                    \"image_path\": image_path,\n                    \"class_name\":  labels_list[i][0]\n                })\n\n                \n#             'Aortic enlargement''Cardiomegaly''Pleural effusion''Pleural thickening''Pulmonary fibrosis'\n        \n                \n                \n\nresults = pd.DataFrame(results)","2879f89a":"results = pd.DataFrame(results)\nresults['class_id'].value_counts(normalize = False, dropna = False)\ntrain_df=results\ntrain_df","416fe63c":"train_df['class_id'].value_counts(normalize = False, dropna = False)","d35ab6a2":"# import numpy as np\n# a = [2,4,6,8,10]\n# average_a = np.mean(a)\n# average_a","2a56d575":"# !pip install ensemble_boxes","8d009a08":"gkf  = GroupKFold(n_splits = 5)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.image_id.tolist())):\n    train_df.loc[val_idx, 'fold'] = fold\ntrain_df.head()","a199689a":"train_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","381558dc":"# os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/train', exist_ok = True)\n# os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/val', exist_ok = True)\n# os.makedirs('\/kaggle\/working\/vinbigdata\/images\/train', exist_ok = True)\n# os.makedirs('\/kaggle\/working\/vinbigdata\/images\/val', exist_ok = True)\n# label_dir = '\/kaggle\/input\/vinbigdata-yolo-labels-dataset\/labels'","b8c86d96":"import os.path as osp\nfrom path import Path\nfrom collections import Counter\nimport cv2\nfrom ensemble_boxes import *","f6721324":"imagepaths = train_df['image_path'].unique()\ntrain_annotations=train_df","9705757b":"# img_array  = cv2.imread('\/kaggle\/input\/vinbigdata-512-image-dataset\/vinbigdata\/train\/d3637a1935a905b3c326af31389cb846.png')","df854492":"def Create_nms_box_txt(desktop_path,name):\n    iou_thr = 0.5\n    skip_box_thr = 0.0001\n    viz_images = []\n#     image_basename = Path(path).stem\n    image_basename = name\n#     print(f\"(\\'{image_basename}\\', \\'{path}\\')\")\n    img_annotations = train_annotations[train_annotations.image_id==image_basename]\n\n    boxes_viz = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    labels_viz = img_annotations['class_id'].to_numpy().tolist()\n\n    print(\"Bboxes before nms:\\n\", boxes_viz)\n    print(\"Labels before nms:\\n\", labels_viz)\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    weights = []\n\n    boxes_single = []\n    labels_single = []\n\n    cls_ids = img_annotations['class_id'].unique().tolist()\n    count_dict = Counter(img_annotations['class_id'].tolist())\n    print(count_dict)\n\n    for cid in cls_ids:       \n        ## Performing Fusing operation only for multiple bboxes with the same label\n        if count_dict[cid]==1:\n            labels_single.append(cid)\n            boxes_single.append(img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().squeeze().tolist())\n\n        else:\n            cls_list =img_annotations[img_annotations.class_id==cid]['class_id'].tolist()\n            labels_list.append(cls_list)\n            bbox = img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n\n            ## Normalizing Bbox by Image Width and Height\n            bbox = bbox\/(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n\n\n            bbox = np.clip(bbox, 0, 1)\n            boxes_list.append(bbox.tolist())\n\n            scores_list.append(np.ones(len(cls_list)).tolist())\n\n            weights.append(1)\n\n            \n    # Perform NMS\n    if len(boxes_list)==0:\n        boxes=boxes_single\n        box_labels=labels_single\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n        \n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])\n        \n    else:\n        boxes, scores, box_labels = nms(boxes_list, scores_list, labels_list, weights=weights,\n                                    iou_thr=iou_thr)\n\n\n        #img_array.shape[1]\u662f\u5bbd\u5ea6\n        boxes = boxes*(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n        boxes = boxes.round(1).tolist()\n        box_labels = box_labels.astype(int).tolist()\n\n        boxes.extend(boxes_single)\n        box_labels.extend(labels_single)\n\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n\n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])","03bd2d20":"# iou_thr = 0.5\n# skip_box_thr = 0.0001\n# viz_images = []\n# for i, path in tqdm(enumerate(imagepaths[5:6])):\n#     image_basename = Path(path).stem\n#     print(f\"(\\'{image_basename}\\', \\'{path}\\')\")\n#     img_annotations = train_annotations[train_annotations.image_id==image_basename]\n\n#     boxes_viz = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n#     labels_viz = img_annotations['class_id'].to_numpy().tolist()\n\n#     print(\"Bboxes before nms:\\n\", boxes_viz)\n#     print(\"Labels before nms:\\n\", labels_viz)\n\n#     boxes_list = []\n#     scores_list = []\n#     labels_list = []\n#     weights = []\n\n#     boxes_single = []\n#     labels_single = []\n\n#     cls_ids = img_annotations['class_id'].unique().tolist()\n#     count_dict = Counter(img_annotations['class_id'].tolist())\n#     print(count_dict)\n\n#     for cid in cls_ids:       \n#         ## Performing Fusing operation only for multiple bboxes with the same label\n#         if count_dict[cid]==1:\n#             labels_single.append(cid)\n#             boxes_single.append(img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().squeeze().tolist())\n\n#         else:\n#             cls_list =img_annotations[img_annotations.class_id==cid]['class_id'].tolist()\n#             labels_list.append(cls_list)\n#             bbox = img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n\n#             ## Normalizing Bbox by Image Width and Height\n#             bbox = bbox\/(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n\n\n#             bbox = np.clip(bbox, 0, 1)\n#             boxes_list.append(bbox.tolist())\n\n#             scores_list.append(np.ones(len(cls_list)).tolist())\n\n#             weights.append(1)\n\n\n#     # Perform NMS\n#     boxes, scores, box_labels = nms(boxes_list, scores_list, labels_list, weights=weights,\n#                                     iou_thr=iou_thr)\n    \n#     print(\"Bboxes without multipy:\\n\", boxes)\n\n#     #img_array.shape[1]\u662f\u5bbd\u5ea6\n#     boxes = boxes*(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n#     boxes = boxes.round(1).tolist()\n#     box_labels = box_labels.astype(int).tolist()\n\n#     boxes.extend(boxes_single)\n#     box_labels.extend(labels_single)\n\n#     print(\"Bboxes after nms:\\n\", boxes)\n#     print(\"Labels after nms:\\n\", box_labels)\n\n#     count_dict = Counter(box_labels)\n#     print(count_dict)\n\n#     text_create('.\/',image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])","00529fd6":"def Create_softnms_box_txt(desktop_path,name):\n    iou_thr = 0.5\n    skip_box_thr = 0.0001\n    viz_images = []\n    sigma = 0.1\n#     image_basename = Path(path).stem\n    image_basename = name\n#     print(f\"(\\'{image_basename}\\', \\'{path}\\')\")\n    img_annotations = train_annotations[train_annotations.image_id==image_basename]\n\n    boxes_viz = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    labels_viz = img_annotations['class_id'].to_numpy().tolist()\n\n    print(\"Bboxes before nms:\\n\", boxes_viz)\n    print(\"Labels before nms:\\n\", labels_viz)\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    weights = []\n\n    boxes_single = []\n    labels_single = []\n\n    cls_ids = img_annotations['class_id'].unique().tolist()\n    count_dict = Counter(img_annotations['class_id'].tolist())\n    print(count_dict)\n\n    for cid in cls_ids:       \n        ## Performing Fusing operation only for multiple bboxes with the same label\n        if count_dict[cid]==1:\n            labels_single.append(cid)\n            boxes_single.append(img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().squeeze().tolist())\n\n        else:\n            cls_list =img_annotations[img_annotations.class_id==cid]['class_id'].tolist()\n            labels_list.append(cls_list)\n            bbox = img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n\n            ## Normalizing Bbox by Image Width and Height\n            bbox = bbox\/(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n\n\n            bbox = np.clip(bbox, 0, 1)\n            boxes_list.append(bbox.tolist())\n\n            scores_list.append(np.ones(len(cls_list)).tolist())\n\n            weights.append(1)\n\n            \n    # Perform NMS\n    if len(boxes_list)==0:\n        boxes=boxes_single\n        box_labels=labels_single\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n        \n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])\n        \n    else:\n        boxes, scores, box_labels = soft_nms(boxes_list, scores_list, labels_list, weights=weights,\n                                    iou_thr=iou_thr)\n\n\n        #img_array.shape[1]\u662f\u5bbd\u5ea6\n        boxes = boxes*(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n        boxes = boxes.round(1).tolist()\n        box_labels = box_labels.astype(int).tolist()\n\n        boxes.extend(boxes_single)\n        box_labels.extend(labels_single)\n\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n\n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])","86d7f775":"def Create_non_maximum_weighted_box_txt(desktop_path,name):\n    iou_thr = 0.5\n    skip_box_thr = 0.0001\n    viz_images = []\n#     image_basename = Path(path).stem\n    image_basename = name\n#     print(f\"(\\'{image_basename}\\', \\'{path}\\')\")\n    img_annotations = train_annotations[train_annotations.image_id==image_basename]\n\n    boxes_viz = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    labels_viz = img_annotations['class_id'].to_numpy().tolist()\n\n    print(\"Bboxes before nms:\\n\", boxes_viz)\n    print(\"Labels before nms:\\n\", labels_viz)\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    weights = []\n\n    boxes_single = []\n    labels_single = []\n\n    cls_ids = img_annotations['class_id'].unique().tolist()\n    count_dict = Counter(img_annotations['class_id'].tolist())\n    print(count_dict)\n\n    for cid in cls_ids:       \n        ## Performing Fusing operation only for multiple bboxes with the same label\n        if count_dict[cid]==1:\n            labels_single.append(cid)\n            boxes_single.append(img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().squeeze().tolist())\n\n        else:\n            cls_list =img_annotations[img_annotations.class_id==cid]['class_id'].tolist()\n            labels_list.append(cls_list)\n            bbox = img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n\n            ## Normalizing Bbox by Image Width and Height\n            bbox = bbox\/(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n\n\n            bbox = np.clip(bbox, 0, 1)\n            boxes_list.append(bbox.tolist())\n\n            scores_list.append(np.ones(len(cls_list)).tolist())\n\n            weights.append(1)\n\n            \n    # Perform NMS\n    if len(boxes_list)==0:\n        boxes=boxes_single\n        box_labels=labels_single\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n        \n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])\n        \n    else:\n        boxes, scores, box_labels = non_maximum_weighted(boxes_list, scores_list, labels_list, weights=weights,\n                                    iou_thr=iou_thr)\n\n\n        #img_array.shape[1]\u662f\u5bbd\u5ea6\n        boxes = boxes*(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n        boxes = boxes.round(1).tolist()\n        box_labels = box_labels.astype(int).tolist()\n\n        boxes.extend(boxes_single)\n        box_labels.extend(labels_single)\n\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n\n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])","ea699158":"def Create_weighted_boxes_fusion_box_txt(desktop_path,name):\n    iou_thr = 0.5\n    skip_box_thr = 0.0001\n    viz_images = []\n#     image_basename = Path(path).stem\n    image_basename = name\n#     print(f\"(\\'{image_basename}\\', \\'{path}\\')\")\n    img_annotations = train_annotations[train_annotations.image_id==image_basename]\n\n    boxes_viz = img_annotations[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().tolist()\n    labels_viz = img_annotations['class_id'].to_numpy().tolist()\n\n    print(\"Bboxes before nms:\\n\", boxes_viz)\n    print(\"Labels before nms:\\n\", labels_viz)\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    weights = []\n\n    boxes_single = []\n    labels_single = []\n\n    cls_ids = img_annotations['class_id'].unique().tolist()\n    count_dict = Counter(img_annotations['class_id'].tolist())\n    print(count_dict)\n\n    for cid in cls_ids:       \n        ## Performing Fusing operation only for multiple bboxes with the same label\n        if count_dict[cid]==1:\n            labels_single.append(cid)\n            boxes_single.append(img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy().squeeze().tolist())\n\n        else:\n            cls_list =img_annotations[img_annotations.class_id==cid]['class_id'].tolist()\n            labels_list.append(cls_list)\n            bbox = img_annotations[img_annotations.class_id==cid][['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n\n            ## Normalizing Bbox by Image Width and Height\n            bbox = bbox\/(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n\n\n            bbox = np.clip(bbox, 0, 1)\n            boxes_list.append(bbox.tolist())\n\n            scores_list.append(np.ones(len(cls_list)).tolist())\n\n            weights.append(1)\n\n            \n    # Perform NMS\n    if len(boxes_list)==0:\n        boxes=boxes_single\n        box_labels=labels_single\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n        \n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])\n        \n    else:\n        boxes, scores, box_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=weights,\n                                    iou_thr=iou_thr)\n\n\n        #img_array.shape[1]\u662f\u5bbd\u5ea6\n        boxes = boxes*(img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"], img_annotations.iloc[0][\"width\"], img_annotations.iloc[0][\"height\"])\n        boxes = boxes.round(1).tolist()\n        box_labels = box_labels.astype(int).tolist()\n\n        boxes.extend(boxes_single)\n        box_labels.extend(labels_single)\n\n        print(\"Bboxes after nms:\\n\", boxes)\n        print(\"Labels after nms:\\n\", box_labels)\n\n        count_dict = Counter(box_labels)\n        print(count_dict)\n\n        text_create(desktop_path,image_basename,boxes,box_labels,img_annotations.iloc[0][\"width\"],img_annotations.iloc[0][\"height\"])","add6dc80":"def text_create(desktop_path,name, boxes,box_labels,w,h):\n    \n    full_path = os.path.join(desktop_path, name+'.txt')  # \u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a.doc\u7684word\u6587\u6863\n    print('full_path',full_path)\n    file = open(full_path, 'w')\n    \n    dw = 1. \/ (w)\n    dh = 1. \/ (h)\n    \n    for i in range(len(boxes)):\n\n        \n        x = (boxes[i][0] + boxes[i][2]) \/ 2.0\n        y = (boxes[i][1] + boxes[i][3]) \/ 2.0\n        w = boxes[i][2] - boxes[i][0]\n        h = boxes[i][3] - boxes[i][1]\n\n        \n        x = x * dw\n        w = w * dw\n        y = y * dh\n        h = h * dh\n        \n        \n        file.write(str(box_labels[i])+ ' '+ str(x)+ ' '+ str(y)+ ' '+ str(w)+ ' '+ str(h)+ ' '+ '\\n') \n        print(str(box_labels[i])+ ' '+ str(x)+ ' '+ str(y)+ ' '+ str(w)+ ' '+ str(h)+ ' ')\n    file.close()","b00d33ba":"os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/labels\/val', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/val', exist_ok = True)\nlabel_dir = '\/kaggle\/input\/vinbigdata-yolo-labels-dataset\/labels'\nfor file in tqdm(train_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/train')\n    filename = file.split('\/')[-1].split('.')[0]\n    \n    # nms stuff\n    print(filename)\n    Create_softnms_box_txt('\/kaggle\/working\/vinbigdata\/labels\/train',filename)\n    \n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/train')\n    \nfor file in tqdm(val_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/val')\n    filename = file.split('\/')[-1].split('.')[0]\n    \n    # nms stuff\n    Create_softnms_box_txt('\/kaggle\/working\/vinbigdata\/labels\/val',filename)\n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/val')","11df846b":"# import os\n# path = os.getcwd()#\u83b7\u53d6\u5f53\u524d\u8def\u5f84\n# print(path)\n\n# # all_files = [f for f in os.listdir('\/kaggle\/working\/vinbigdata\/labels\/val' )]#\u8f93\u51fa\u6839path\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u540d\u5230\u4e00\u4e2a\u5217\u8868\u4e2d\n# all_files = [f for f in os.listdir(path )]#\u8f93\u51fa\u6839path\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u540d\u5230\u4e00\u4e2a\u5217\u8868\u4e2d\n# #\u5bf9\u5404\u4e2a\u6587\u4ef6\u8fdb\u884c\u5904\u7406\n# print(all_files)","50e74b71":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","ef7d7473":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","75411fa1":"# https:\/\/www.kaggle.com\/ultralytics\/yolov5\n# !git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')\n# %pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","e70746bd":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data\/images\/\nImage(filename='runs\/detect\/exp\/zidane.jpg', width=600)","ab061ac4":"# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 50 --data \/kaggle\/working\/vinbigdata.yaml --weights yolov5s.pt --cache","d8c7576f":"a=1","48599ea1":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels_correlogram.jpg'));","f17cbb03":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels.jpg'));","018d975f":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch0.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch1.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch2.jpg'))","635da750":"fig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'runs\/train\/exp\/test_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'runs\/train\/exp\/test_batch{row}_pred.jpg', fontsize = 12)","133eddcf":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/results.png'));","0306ecf9":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/confusion_matrix.png'));","07389717":"# 0     3625\n# 3     2860\n# 13    1299\n# 11     763 0.5\n# 8      728\n# 10     699\n# 7      448\n# 9      357 0.67\n# 6      291\n# 5      290\n# 2      193\n# 4      121\n# 12      97\n# 1       46","4d9335af":"!python detect.py --weights 'runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata\/images\/val\\\n--exist-ok","1bc29369":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*')\nfor _ in range(3):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","e4dc2fab":"a=1","18be92b3":"# shutil.rmtree('\/kaggle\/working\/vinbigdata')\n# shutil.rmtree('runs\/detect')\n# for file in (glob('runs\/train\/exp\/**\/*.png', recursive = True)+glob('runs\/train\/exp\/**\/*.jpg', recursive = True)):\n#     os.remove(file)","a258f7ab":"dim = 512 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test'\n# weights_dir = '\/kaggle\/input\/vinbigdata-cxr-ad-yolov5-14-class-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\nweights_dir = f'runs\/train\/exp\/weights\/best.pt'","6454ecba":"test_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test.csv')\ntest_df.head()","51d64382":"os.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","0bbaf746":"!python detect.py --weights $weights_dir\\\n--img 640\\\n--conf 0.15\\\n--iou 0.4\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok","7f2ab070":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n#     print('bboxes',bboxes)\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","858e8f8c":"image_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))","0a52bea5":"pred_df_pure = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df_pure = pd.merge(test_df, pred_df_pure, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df_pure = sub_df_pure[['image_id', 'PredictionString']]\nsub_df_pure.to_csv('\/kaggle\/working\/sub_df_pure.csv',index = False)\nsub_df_pure.tail()","5757495a":"display(sub_df_pure)","eb77aeb8":"a=1","02844ea9":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*png')\nfor _ in range(6):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","7e8ddb2b":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndim = 512 #512, 256, 'original'\nfold = 4\n\ntrain_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df.head()\n\ntrain_df['x_min'] = train_df.apply(lambda row: (row.x_min)\/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)\/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)\/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)\/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)\/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)\/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()","795935d1":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","c6c8a2e2":"list_mid_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.x_mid\n    y_val = train_df_0.y_mid\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_mid_gaussian_kde.append(evalutor)","53f9ba77":"list_w_h_gaussian_kde=[]\nfor i in range(14):\n    \n\n    train_df_0 = train_df[train_df.class_id==i]\n    x_val = train_df_0.w\n    y_val = train_df_0.h\n    print(len(x_val))\n\n    # Calculate the point density\n    xy = np.vstack([x_val,y_val])\n    z = gaussian_kde(xy)(xy)\n\n    fig, ax = plt.subplots(figsize = (10, 10))\n    # ax.axis('off')\n    ax.axis([0,1,1,0])\n    ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n    # ax.set_xlabel('x_mid')\n    # ax.set_ylabel('y_mid')\n    plt.show()\n\n    evalutor=gaussian_kde(xy)\n    # evalutor.evaluate([[0.6],[0.4]])\n    list_w_h_gaussian_kde.append(evalutor)","6e7fb861":"# https:\/\/www.pythonheidong.com\/blog\/article\/436765\/a0facf9464d9337dc1eb\/\nlist_area_gaussian_kde=[]\nfor i in range(14):\n    train_df_0 = train_df[train_df.class_id==i]\n    data = train_df_0.w\n\n    density = gaussian_kde(data)\n    xs = np.linspace(0,1,200)\n    plt.plot(xs,density(xs))\n    plt.show()\n    list_area_gaussian_kde.append(density)","7ee22289":"def Hotmask_mid_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_mid_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[0]],[normalized_xmid_ymid_w_h[1]]])\n    \n    return value\n\ndef Hotmask_w_h_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_w_h_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate([[normalized_xmid_ymid_w_h[2]],[normalized_xmid_ymid_w_h[3]]])\n    \n    return value\n\ndef Hotmask_area_value(class_id,normalized_xmid_ymid_w_h):\n    evaluator = list_area_gaussian_kde[int(class_id)]\n    value = evaluator.evaluate(normalized_xmid_ymid_w_h[2]*normalized_xmid_ymid_w_h[3])\n    \n    return value","518d47ea":"image_ids = []\nPredictionStrings = []\nsum_delte_on=0\n\n# threshold=0.001\nthreshold_mid=0.001\nthreshold_w_h=0.001\nthreshold_area=0.001\n\nfor file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n    delte_on=0\n    \n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n#     print('data',data.type)\n    \n    list_classid_probility = data[:, :2]\n    list_normalized_box = data[:, 2:]\n    delte_sign=[]\n#     filtered_list_classid_probility=[]\n#     filtered_list_normalized_box=[]\n    \n#     print('data[:, :2]',data[:, :2]) \n    \n    for i in range(len(list_classid_probility)):\n        if (Hotmask_mid_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_mid and Hotmask_w_h_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_w_h and Hotmask_area_value(list_classid_probility[i][0] , list_normalized_box[i])>threshold_area) or list_classid_probility[i][0]==14:\n            delte_sign.append(True)\n        else:\n            delte_sign.append(False)\n            delte_on+=1\n            \n#             filtered_list_classid_probility.append(list_classid_probility[i][0])\n#             filtered_list_normalized_box.append(list_classid_probility[i].tolist())\n            \n#     prin**t('filtered_list_normalized_box',filtered_list_normalized_box) \n    \n    print('delte_sign',delte_sign) \n    bboxes = list(np.round(np.concatenate((data[:, :2][delte_sign], np.round(yolo2voc(h, w, data[:, 2:][delte_sign]))), axis =1).reshape(-1), 1).astype(str))\n#     bboxes = np.array(list(np.round(np.concatenate((filtered_list_classid_probility, np.round(yolo2voc(h, w, filtered_list_normalized_box))), axis =1).reshape(-1), 1).astype(str)),dtype=np.float32)\n#     print('data[:, 2:]',data[:, 2:])\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))\n    \n    if delte_on!=0:\n        sum_delte_on+=1","6285621a":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\n\nsub_df.loc[sub_df['PredictionString'] =='','PredictionString']=\"14 1 0 0 1 1\"\nsub_df.to_csv('\/kaggle\/working\/submission_softnms.csv',index = False)\nsub_df.tail()","2de389f5":"display(sub_df)","f50b8c0b":"import pandas as pd\nimport numpy as np\nfrom glob import glob\nimport shutil","73c95aae":"import os \nos.getcwd()","197f479e":"pred_14cls =sub_df\npred_2cls = pd.read_csv('\/kaggle\/input\/vinbigdata-2class-prediction\/2-cls test pred.csv')","397bf0a4":"count_low=0\ncount_mid=0\ncount_high=0\ndef filter_2cls_raw(row, low_thr=0.08, high_thr=0.95):\n    global count_low\n    global count_mid\n    global count_high\n    prob = row['target']\n    if prob<low_thr:\n        ## Less chance of having any disease\n        row['PredictionString'] = '14 1 0 0 1 1'\n        count_low+=1\n    elif low_thr<=prob<high_thr:\n        ## More change of having any diesease\n        row['PredictionString']+=f' 14 {prob} 0 0 1 1'\n        count_mid+=1\n    elif high_thr<=prob:\n        ## Good chance of having any disease so believe in object detection model\n        row['PredictionString'] = row['PredictionString']\n        count_high+=1\n    else:\n        raise ValueError('Prediction must be from [0-1]')\n    return row","b848e96d":"pred_raw = pd.merge(pred_14cls, pred_2cls, on = 'image_id', how = 'left')\npred_raw.head()","a98a4c5c":"sub_raw = pred_raw.apply(filter_2cls_raw, axis=1)\nprint(count_low\/3000,count_mid\/3000,count_high\/3000)","c52727e0":"sub_raw[['image_id', 'PredictionString']].to_csv('submission_raw.csv',index = False)","36c516c8":"print_df=sub_raw[['image_id', 'PredictionString']]","f46ad2f8":"display(print_df)","0fc05b45":"# for i in range(sub_raw.shape[0]):\n# #     sub_raw.iloc[i]['image_id', 'PredictionString']\n#     print(print_df.loc[i])","c4af7350":"# Copying Files","009a4db4":"# Split","d1338534":"# [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png)","f791737f":"# (Loss, Map) Vs Epoch","6711e14a":"# Version\n* `v13`: Fold4\n* `v12`: Fold3\n* `v10`: Fold2\n* `v09`: Fold1\n* `v03`: Fold0","998c44ae":"# Inference","3d2ba4a3":"# Confusion Matrix","f882701e":"# Only 14 Class","af833781":"# Train","c79eba84":"## Pretrained Checkpoints:\n\n| Model | AP<sup>val<\/sup> | AP<sup>test<\/sup> | AP<sub>50<\/sub> | Speed<sub>GPU<\/sub> | FPS<sub>GPU<\/sub> || params | FLOPS |\n|---------- |------ |------ |------ | -------- | ------| ------ |------  |  :------: |\n| [YOLOv5s](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 37.0     | 37.0     | 56.2     | **2.4ms** | **416** || 7.5M   | 13.2B\n| [YOLOv5m](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 44.3     | 44.3     | 63.2     | 3.4ms     | 294     || 21.8M  | 39.4B\n| [YOLOv5l](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | 47.7     | 47.7     | 66.5     | 4.4ms     | 227     || 47.8M  | 88.1B\n| [YOLOv5x](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0)    | **49.2** | **49.2** | **67.7** | 6.9ms     | 145     || 89.0M  | 166.4B\n| | | | | | || |\n| [YOLOv5x](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0) + TTA|**50.8**| **50.8** | **68.9** | 25.5ms    | 39      || 89.0M  | 354.3B\n| | | | | | || |\n| [YOLOv3-SPP](https:\/\/github.com\/ultralytics\/yolov5\/releases\/tag\/v3.0) | 45.6     | 45.5     | 65.2     | 4.5ms     | 222     || 63.0M  | 118.0B","a8aca891":"# Inference Plot","9aa8e28e":"# Batch Image","cfee6d74":"# Selecting Models\nIn this notebok I'm using `v5s`. To select your prefered model just replace `--cfg models\/yolov5s.yaml --weights yolov5s.pt` with the following command:\n* `v5s` : `--cfg models\/yolov5s.yaml --weights yolov5s.pt`\n* `v5m` : `--cfg models\/yolov5m.yaml --weights yolov5m.pt`\n* `v5l` : `--cfg models\/yolov5l.yaml --weights yolov5l.pt`\n* `v5x` : `--cfg models\/yolov5x.yaml --weights yolov5x.pt`","c64a04ac":"# YOLOv5 Stuff","0b12aba3":"# Get Class Name","e8ca4dc6":"# GT Vs Pred","aab34f82":"# Class Distribution"}}