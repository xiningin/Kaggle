{"cell_type":{"839588f5":"code","2a2d7708":"code","54b282d9":"code","65e66468":"code","20bbe5ed":"code","12d860b4":"code","d72eebfb":"code","94f6fdf4":"code","6b8c78aa":"code","31c99ac7":"code","a5aa2966":"code","3e4c7b05":"code","25b5ef15":"code","cf3137ee":"code","eb68d5af":"code","f9b322f8":"code","be75c0ae":"code","61189a7a":"code","186f1758":"code","0fe28dea":"code","7a9e523d":"code","216a18d7":"code","3716d87f":"code","1b08c028":"code","6198adbb":"code","32a51c21":"code","b2f5f7ec":"code","65d705c5":"code","231bcf32":"code","72600d97":"code","499d3240":"code","1ad5301e":"code","303f84f4":"code","72bab0df":"code","3b0729f5":"code","e1c742fe":"code","d23b3d54":"code","a31c242e":"code","b0680a8b":"code","0171e3b3":"code","43004b70":"code","db516e38":"code","71d769c9":"code","f19b80c9":"code","814afb4d":"code","e574d515":"code","4298308b":"code","89069e07":"code","533d9add":"code","61704020":"code","189d9cbf":"code","8a403869":"code","a971dfdc":"code","e70db172":"code","1937ee27":"code","040eda4b":"code","30a0f127":"code","c2b5479a":"code","c3824bd1":"code","97752092":"code","0ee54af3":"code","1156112f":"code","3aebd881":"markdown","28f879fe":"markdown","ecde2967":"markdown","a6a7ad8b":"markdown","3ccff0b3":"markdown","e050ba66":"markdown","bcdf3f54":"markdown","f46f92f0":"markdown","61c09b7b":"markdown","90172e45":"markdown","b072f5dc":"markdown","7ae8ba5b":"markdown","13e95940":"markdown","6af8e08f":"markdown","a07781bc":"markdown","be93192d":"markdown","d38e9102":"markdown","2369fd84":"markdown","74a8f084":"markdown","1fb225fa":"markdown","674669b7":"markdown","3b2cd495":"markdown","e4250d81":"markdown","05a51a51":"markdown","17131781":"markdown","f63be842":"markdown","fdd6b1e1":"markdown","c522dc8e":"markdown","732655e7":"markdown","aa370371":"markdown"},"source":{"839588f5":"# Check the tensorflow version\n\nimport tensorflow as tf\ntf.__version__","2a2d7708":"import pandas as pd\nimport numpy as np\nimport os\n\nimport cv2\n\nimport albumentations as albu\nfrom albumentations import Compose, ShiftScaleRotate, Resize\nfrom albumentations.pytorch import ToTensor\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom sklearn.metrics import classification_report\n\nimport shutil\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","54b282d9":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3\n","65e66468":"os.listdir('..\/input\/plant-pathology-2020-fgvc7')","20bbe5ed":"# Source: Scikit Learn website\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/\n# model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n# selection-plot-confusion-matrix-py\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\n","12d860b4":"path = '..\/input\/plant-pathology-2020-fgvc7\/train.csv'\ndf_train = pd.read_csv(path)\n\npath = '..\/input\/plant-pathology-2020-fgvc7\/test.csv'\ndf_test = pd.read_csv(path)\n\npath = '..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv'\ndf_sample = pd.read_csv(path)\n\n\nprint(df_train.shape)\nprint(df_test.shape)\nprint(df_sample.shape)","d72eebfb":"# Identify the target class of each row in the train set\n\ndef get_class(row):\n    \n    if row['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    \n    elif row['rust'] == 1:\n        return 'rust'\n    \n    elif row['scab'] == 1:\n        return 'scab'\n    \n    else:\n        return 'healthy'\n    \ndf_train['target'] = df_train.apply(get_class, axis=1)\n\ndf_train.head()","94f6fdf4":"# Filter out each class\ndf_healthy = df_train[df_train['target'] == 'healthy']\ndf_multiple_diseases = df_train[df_train['target'] == 'multiple_diseases']\ndf_rust = df_train[df_train['target'] == 'rust']\ndf_scab = df_train[df_train['target'] == 'scab']\n","6b8c78aa":"# Example\ndf_scab.head()","31c99ac7":"path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'\n\nimage_list = list(df_healthy['image_id'])\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(25,10))\n\n# Our subplot will contain 2 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\nplt.subplot(2,4,1)\n\n# plt.imread reads an image from a path and converts it into an array\n\n# starting from 1 makes the code easier to write\nfor i in range(1,9):\n    \n    plt.subplot(2,4,i)\n    \n    # get an image\n    image = image_list[i]\n    \n    # display the image\n    plt.imshow(plt.imread(path + image + '.jpg'))\n    \n    plt.xlabel('healthy', fontsize=20)","a5aa2966":"path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'\n\nimage_list = list(df_multiple_diseases['image_id'])\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(25,10))\n\n# Our subplot will contain 2 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\nplt.subplot(2,4,1)\n\n# plt.imread reads an image from a path and converts it into an array\n\n# starting from 1 makes the code easier to write\nfor i in range(1,9):\n    \n    plt.subplot(2,4,i)\n    \n    # get an image\n    image = image_list[i]\n    \n    # display the image\n    plt.imshow(plt.imread(path + image + '.jpg'))\n    \n    plt.xlabel('multiple_diseases', fontsize=20)","3e4c7b05":"path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'\n\nimage_list = list(df_rust['image_id'])\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(25,10))\n\n# Our subplot will contain 2 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\nplt.subplot(2,4,1)\n\n# plt.imread reads an image from a path and converts it into an array\n\n# starting from 1 makes the code easier to write\nfor i in range(1,9):\n    \n    plt.subplot(2,4,i)\n    \n    # get an image\n    image = image_list[i]\n    \n    # display the image\n    plt.imshow(plt.imread(path + image + '.jpg'))\n    \n    plt.xlabel('rust', fontsize=20)","25b5ef15":"path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'\n\nimage_list = list(df_scab['image_id'])\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(25,10))\n\n# Our subplot will contain 2 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\nplt.subplot(2,4,1)\n\n# plt.imread reads an image from a path and converts it into an array\n\n# starting from 1 makes the code easier to write\nfor i in range(1,9):\n    \n    plt.subplot(2,4,i)\n    \n    # get an image\n    image = image_list[i]\n    \n    # display the image\n    plt.imshow(plt.imread(path + image + '.jpg'))\n    \n    plt.xlabel('scab', fontsize=20)","cf3137ee":"df_train['target'].value_counts()","eb68d5af":"# select the column that we will use for stratification\ny = df_train['target']\n\n# shuffle\ndf_train = shuffle(df_train)\n\ndf_train, df_val = train_test_split(df_train, test_size=0.2, random_state=101, stratify=y)\n\n\nprint(df_train.shape)\nprint(df_val.shape)","f9b322f8":"df_train['target'].value_counts()","be75c0ae":"df_val['target'].value_counts()","61189a7a":"df_1 = df_train[df_train['target'] != 'multiple_diseases']\n\ndf_2 = df_train[df_train['target'] == 'multiple_diseases']\n\ndf_train_up = pd.concat([df_1, df_2,  df_2,  df_2,  df_2,  df_2], axis=0).reset_index(drop=True)\n\ndf_train = shuffle(df_train_up)\n\nprint(df_train.shape)\n\ndf_train.head()","186f1758":"# This is the new class distribution of the train set\n\ndf_train['target'].value_counts()","0fe28dea":"df_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)","7a9e523d":"!ls","216a18d7":"# Albumentations\n\nimport albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix\n\n","3716d87f":"# Define the transforms\n\n# Modified from --> Pneumothorax - 1st place solution\n# Source: https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/discussion\/107824#latest-620521\n\n\naug_types = albu.Compose([\n            albu.HorizontalFlip(),\n             albu.OneOf([\n                albu.HorizontalFlip(),\n                albu.VerticalFlip(),\n                ], p=0.8),\n            albu.OneOf([\n                albu.RandomContrast(),\n                albu.RandomGamma(),\n                albu.RandomBrightness(),\n                ], p=0.3),\n            albu.OneOf([\n                albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n                albu.GridDistortion(),\n                albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n                ], p=0.3),\n            albu.ShiftScaleRotate()\n            ])\n\n","1b08c028":"# Get an image to test the transformations\n\n# get a list of train png images\npath = '..\/input\/plant-pathology-2020-fgvc7\/images\/'\nimage_list = os.listdir(path)\n\nfname = image_list[1]\nimage_path = path + fname\n\nprint(fname)\n\nimage = plt.imread(image_path)\nplt.imshow(image)\n\nplt.show()","6198adbb":"# Test the transformation setup.\n# The image will be different each time this cell is run.\n\naug_image = augment_image(aug_types, image)\n\nplt.imshow(aug_image)\n\nplt.show()","32a51c21":"#df_train.head()","b2f5f7ec":"def train_generator(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n\n\n       \n              \n            # Augment the image and mask\n            # ===========================\n\n                aug_image = augment_image(aug_types, image)\n              \n                # insert the image into X_train\n                X_train[i] = aug_image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train\/255\n\n            yield X_train, y_train","65d705c5":"# Test the generator\n\n# initialize\ntrain_gen = train_generator(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","231bcf32":"y_train","72600d97":"# Print the first image in X_train\n# Remember that train images have been augmented.\n\nimage = X_train[0,:,:,:]\nplt.imshow(image)","499d3240":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                       \n                \n            # Normalize the images\n            X_val = X_val\/255\n\n            yield X_val, y_val","1ad5301e":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","303f84f4":"y_val","72bab0df":"# print the image from X_val\nimage = X_val[0,:,:,:]\nplt.imshow(image)","3b0729f5":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test\/255\n\n            yield X_test","e1c742fe":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","d23b3d54":"# print the image from X_test\n\nimage = X_test[0,:,:,:]\nplt.imshow(image)","a31c242e":"from tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n","b0680a8b":"from tensorflow.keras.applications.mobilenet import MobileNet\n\nmodel = MobileNet(weights='imagenet')\n\n# Exclude the last 2 layers of the above model.\nx = model.layers[-2].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\npredictions = Dense(4, activation='softmax')(x)\n\n# inputs=model.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.summary()","0171e3b3":"TRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = TRAIN_BATCH_SIZE\nval_batch_size = VAL_BATCH_SIZE\n\n# determine num train steps\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\n\n# determine num val steps\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","43004b70":"# Initialize the generators\ntrain_gen = train_generator(batch_size=TRAIN_BATCH_SIZE)\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nmodel.compile(\n    Adam(lr=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\n\nfilepath = \"model.h5\"\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=3, \n                                   verbose=1, mode='max')\n\n\n\nlog_fname = 'training_log.csv'\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=50, \n                              validation_data=val_gen, validation_steps=val_steps,\n                             verbose=1,\n                             callbacks=callbacks_list)","db516e38":"# Display the training log\n\ntrain_log = pd.read_csv('training_log.csv')\n\ntrain_log.head()","71d769c9":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","f19b80c9":"model.load_weights('model.h5')\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(val_gen, \n                        steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","814afb4d":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.show()","e574d515":"model.load_weights('model.h5')\n\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict_generator(val_gen, steps=len(df_val), verbose=1)\n","4298308b":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\n","89069e07":"# get y_true as index values\n\ncols = ['healthy', 'multiple_diseases', 'rust', 'scab']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\n","533d9add":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ncm = confusion_matrix(y_true, y_pred)","61704020":"cm_plot_labels = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","189d9cbf":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(y_true, y_pred, target_names=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\nprint(report)","8a403869":"model.load_weights('model.h5')\n\n# initialize the generator\ntest_gen = test_generator(batch_size=1)\n\npreds = model.predict_generator(test_gen, steps=len(df_test), verbose=1)","a971dfdc":"#preds","e70db172":"# Put the preds into a dataframe\n\ndf_preds = pd.DataFrame(preds, columns=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\ndf_preds['image_id'] = df_test['image_id'].copy()\n\ndf_preds.head()","1937ee27":"df_test.head()","040eda4b":"#df_sample.head()","30a0f127":"# Create a submission csv file\n\ndf_results = pd.DataFrame({'image_id': df_preds.image_id,\n                            'healthy': df_preds.healthy,\n                               'multiple_diseases': df_preds.multiple_diseases,\n                               'rust': df_preds.rust,\n                               'scab': df_preds.scab\n                           }).set_index('image_id')\n\n\n# create a submission csv file\ndf_results.to_csv('submission.csv', \n                  columns=['healthy', 'multiple_diseases', 'rust', 'scab']) ","c2b5479a":"df_results.head()","c3824bd1":"!ls","97752092":"# --ignore-installed is added to fix an error.\n\n# https:\/\/stackoverflow.com\/questions\/49932759\/pip-10-and-apt-how-to-avoid-cannot-uninstall\n# -x-errors-for-distutils-packages\n\n!pip install tensorflowjs --ignore-installed","0ee54af3":"# Use the command line conversion tool to convert the model\n\n!tensorflowjs_converter --input_format keras model.h5 tfjs\/model","1156112f":"# check that the folder containing the tfjs model files has been created\n!ls","3aebd881":"## Model Architecture","28f879fe":"## Approach\n\n- Resize all images to 224x224x3\n- Use a 80\/20 train test split\n- Fine tune a Mobilenet model that was pre-trained on imagenet.\n- Use the Adam optimizer, categorical crossentropy loss and a learning rate of 0.001 with reduce-on-plateau.\n- We won't use the pre-processing method that was applied to the imagenet images that were used to pre-train Mobilenet. Instead we will simply normalize all images by dividing by 255.\n- Perform image augmentation using the Albumentations library. Data augmentation will help to reduce overfitting, improve model performance and help the model generalize better.\n- Upsample the data in the multiple_diseases class as recommended in this paper:<br>\nA systematic study of the class imbalance problem in convolutional neural networks<br>https:\/\/arxiv.org\/abs\/1710.05381","ecde2967":"## Convert the Model to Tensorflow.js\n\nThis needs to be done so that the model can be used in the web app.","a6a7ad8b":"## Make a prediction on the val set","3ccff0b3":"## Create the train and val sets","e050ba66":"## Create a submission csv file","bcdf3f54":"## Conclusion\n\nOverall it appears that deep learning can handle this classification task quite easily. The only area that the model struggles with is classifying the multiple_diseases class. If the researchers were to add more raw image data to this class then that should fix this weakness. \n\n\nOne of the research objectives of this competition is to determine if a model is able to perform well when the images vary in depth perception\u2014angle, light and shade. This is quite easy to test by accessing the web app on a mobile phone. \n\nWith a phone the leaves can be photograhed at different angles, depths and under different lighting conditions. The app will instantly classify each photograph so it will be easy to judge this model's capability under different conditions. \n\n- Navigate to http:\/\/apple.test.woza.work\/\n- Click the Submit button and then select \"Camera\". (This works on Android.)\n- Take a photo of a leaf. The photo you take will be sent directly to the app for classification.\n\n\n\n\nAs a bonus here are a few things that you can do to improve the leaderboard score:\n- Use a larger pre-trained model.\n- Use test time augmentation (TTA).\n- Try pseudo labeling.\n- Ensemble the predictions from different folds and\/or different models - stack the predictions or take a simple average.\n\n\nThank you for reading.","f46f92f0":"<img src=\"http:\/\/apple.test.woza.work\/assets\/kaggleimage.jpg\" width=\"500\"><\/img>\n","61c09b7b":"## Confusion Matrix","90172e45":"## Make a test set prediction","b072f5dc":"### Apple Leaf Health Analyzer\nby Marsh [ @vbookshelf ]<br>\n12 March 2020","7ae8ba5b":"### Create dataframes","13e95940":"### [ 2 ] Val Generator","6af8e08f":"### [ 3 ] Test Generator","a07781bc":"## Display some images from each class","be93192d":"## Classification Report","d38e9102":"## Introduction\n\nIn this kernel we will build a Tensorflow_2.0 Keras model to classify the health status of apple tree leaves. \n\nThere are 4 output classes:\n- healthy\n- multiple_diseases\n- rust\n- scab\n\n\nThe dataset consists of 1821 training images. This is quite small by deep learning standards. However, by using data augmentation combined with a pre-trained Mobilenet model the validation accuracy score will be greater than 90%. Augmentation will also help the model to generalize better.\n\nI chose Mobilenet because my aim was to deploy the trained model online in a Tensorflow.js web interface. The web app makes it possible for this model to be taken outside and field tested under varying image conditions - lighting, shade, angles, depth, orienation etc. \n\nMobilenet was designed for use on the web. It's small which means that it downoads fairly quickly and it runs fast. \n\nThis is the link to the live web app. I suggest using the Chrome browser. The code is available on Github. \n\n> Web App<br>\n> http:\/\/apple.test.woza.work\/\n>\n> Github<br>\n> https:\/\/github.com\/vbookshelf\/Apple-Tree-Leaf-Health-Analyzer\n\n\n","2369fd84":"## Save the dataframes as compressed csv files\nThese csv files will allow us to use Pandas chunking to feed images into the generators.","74a8f084":"## Upsample the multiple_diseases class","1fb225fa":"## Citations\n\n- Albumentations: fast and flexible image augmentations<br>\nhttps:\/\/arxiv.org\/abs\/1809.06839\n\n- Plant Pathology 2020 - FGVC7 Dataset<br>\nPaper pending\n\n- Image by congerdesign on Pixabay","674669b7":"### [ 1 ] Train Generator","3b2cd495":"**Recall** = Given a class, will the classifier be able to detect it?<br>\n**Precision** = Given a class prediction from a classifier, how likely is it to be correct?<br>\n**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.\n\nThis is a helpful tutorial by Minsuk Heo on Accuracy, Precision and F1 Score:<br>\nhttps:\/\/www.youtube.com\/watch?v=HBi-P5j0Kec","e4250d81":"## Data Summary\n\n- 1821 jpg train images\n- 1821 jpg test images\n- 4 classes: healthy (516 images), multiple_diseases (91 images), rust (622 images), scab (592 images)\n- There are substantially fewer images in the multiple_diseases class.\n\n\n\n","05a51a51":"## Evaluate the model on the val set","17131781":"## Train the Model","f63be842":"## Plot the training curves","fdd6b1e1":"## Build the Data Generators","c522dc8e":"## Set up and test the Augmentations","732655e7":"## Prepare the Data","aa370371":"## Helper Functions"}}