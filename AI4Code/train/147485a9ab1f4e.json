{"cell_type":{"388ee85c":"code","8af56947":"code","5b379b03":"code","3b404d46":"code","48b39d0a":"code","61395908":"code","5e103d34":"code","f1cdb0b6":"code","fc1cf86c":"code","83e39695":"code","68f17910":"code","f8c4b966":"code","824f06f4":"code","cf22901b":"code","97447b68":"code","d4a703c6":"code","a9dacdf7":"code","1ae5abe5":"code","e6976bb8":"code","57d217de":"code","fff9cddd":"code","8210cf9c":"code","5151daee":"code","6b711f93":"code","3b85c28c":"code","5d15c530":"code","75c03cbb":"code","61647d3b":"code","74eef808":"code","9285280c":"code","637d61bb":"code","82045eb4":"markdown","f28b5467":"markdown","62308bfa":"markdown","83e6dbb6":"markdown","5e257cec":"markdown","d51edcd2":"markdown","20cabecd":"markdown","ee893abd":"markdown","507887f1":"markdown","87d268b1":"markdown","6a0ae05e":"markdown","a5c8e77f":"markdown","69a29d38":"markdown","bacfed2c":"markdown","d5b10ae7":"markdown","2af3278f":"markdown","6f3b2201":"markdown","dad95665":"markdown","f360e640":"markdown","6405c7c9":"markdown","62997e0c":"markdown","a3049215":"markdown","7037ec3a":"markdown","34234e1e":"markdown","41ac8db1":"markdown","9c088a35":"markdown","0b97fd97":"markdown","ec30d6b4":"markdown","12a1d749":"markdown","48b7463b":"markdown","0fee53fa":"markdown","eadbf417":"markdown","5d130911":"markdown","b9e1e4fc":"markdown","5c1d831e":"markdown","4a9ec036":"markdown","e1a8a125":"markdown","ce59adab":"markdown","3db21852":"markdown","30825546":"markdown","ae8b4465":"markdown","4930be05":"markdown","3e1ff8a8":"markdown","29a4d7af":"markdown","52730656":"markdown","68dfa4ac":"markdown","124f159b":"markdown","7367e026":"markdown","2cc9394b":"markdown","e1d162df":"markdown","16e068a6":"markdown","44df5ec0":"markdown"},"source":{"388ee85c":"# data processing and visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# algorithm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVC\n# training\u8bad\u7ec3\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV","8af56947":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ngender_submission = pd.read_csv(\"..\/input\/gender_submission.csv\")","5b379b03":"train.describe(include=\"all\")","3b404d46":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train)\nprint(\"\u5973\u6027\u751f\u5b58\u7387:\", train[\"Survived\"][train[\"Sex\"] == \"female\"].value_counts(normalize=True)[1])\nprint(\"\u7537\u6027\u751f\u5b58\u7387:\", train[\"Survived\"][train[\"Sex\"] == \"male\"].value_counts(normalize=True)[1])","48b39d0a":"train[\"Family_size\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"Family_size\"] = test[\"SibSp\"] + test[\"Parch\"]","61395908":"train[\"Fname\"] = train.Name.apply(lambda x: x.split(\",\")[0])\ntest[\"Fname\"] = test.Name.apply(lambda x: x.split(\",\")[0])","5e103d34":"train[train.Fname == \"Vander Planke\"]","f1cdb0b6":"test[test.Fname == \"Vander Planke\"]","fc1cf86c":"train[train.Fname == \"Allison\"]","83e39695":"train[(train.Fname == \"Hoyt\") & (train.Family_size > 0)]","68f17910":"train[(train.Fname == \"Moubarek\") & (train.Family_size > 0)]","f8c4b966":"dead_train = train[train[\"Survived\"] == 0]\nfname_ticket = dead_train[(dead_train[\"Sex\"] == \"female\") & (dead_train[\"Family_size\"] >= 1)][[\"Fname\", \"Ticket\"]]\ntrain[\"dead_family\"] = np.where(train[\"Fname\"].isin(fname_ticket[\"Fname\"]) & train[\"Ticket\"].isin(fname_ticket[\"Ticket\"]) & ((train[\"Age\"] >=1) | train.Age.isnull()), 1, 0)\ntest[\"dead_family\"] = np.where(test[\"Fname\"].isin(fname_ticket[\"Fname\"]) & test[\"Ticket\"].isin(fname_ticket[\"Ticket\"]) & ((test[\"Age\"] >=1) | test.Age.isnull()), 1, 0)","824f06f4":"live_train = train[train[\"Survived\"] == 1]\nlive_fname_ticket = live_train[(live_train[\"Sex\"] == \"male\") & (live_train[\"Family_size\"] >= 1) & ((live_train[\"Age\"] >= 18) | (live_train[\"Age\"].isnull()))][[\"Fname\", \"Ticket\"]]\ntrain[\"live_family\"] = np.where(train[\"Fname\"].isin(live_fname_ticket[\"Fname\"]) & train[\"Ticket\"].isin(live_fname_ticket[\"Ticket\"]), 1, 0)\ntest[\"live_family\"] = np.where(test[\"Fname\"].isin(live_fname_ticket[\"Fname\"]) & test[\"Ticket\"].isin(live_fname_ticket[\"Ticket\"]), 1, 0)","cf22901b":"dead_man_fname_ticket = train[(train[\"Family_size\"] >= 1) & (train[\"Sex\"] == \"male\") & (train[\"Survived\"] == 0) & (train[\"dead_family\"] == 0)][[\"Fname\", \"Ticket\"]]\ntrain[\"deadfamily_man\"] = np.where(train[\"Fname\"].isin(dead_man_fname_ticket[\"Fname\"]) & train[\"Ticket\"].isin(dead_man_fname_ticket[\"Ticket\"]) & (train.Sex == \"male\"), 1, 0)\ntrain[\"deadfamily_woman\"] = np.where(train[\"Fname\"].isin(dead_man_fname_ticket[\"Fname\"]) & train[\"Ticket\"].isin(dead_man_fname_ticket[\"Ticket\"]) & (train.Sex == \"female\"), 1, 0)\ntest[\"deadfamily_man\"] = np.where(test[\"Fname\"].isin(dead_man_fname_ticket[\"Fname\"]) & test[\"Ticket\"].isin(dead_man_fname_ticket[\"Ticket\"]) & (test.Sex == \"male\"), 1, 0)\ntest[\"deadfamily_woman\"] = np.where(test[\"Fname\"].isin(dead_man_fname_ticket[\"Fname\"]) & test[\"Ticket\"].isin(dead_man_fname_ticket[\"Ticket\"]) & (test.Sex == \"female\"), 1, 0)\ntrain.loc[(train[\"dead_family\"] == 0) & (train[\"live_family\"] == 0) & (train[\"deadfamily_man\"] == 0) & (train[\"deadfamily_woman\"] == 0) & (train[\"Family_size\"] >= 1) & (train[\"Sex\"] == \"male\"), \"deadfamily_man\"] = 1\ntrain.loc[(train[\"dead_family\"] == 0) & (train[\"live_family\"] == 0) & (train[\"deadfamily_man\"] == 0) & (train[\"deadfamily_woman\"] == 0) & (train[\"Family_size\"] >= 1) & (train[\"Sex\"] == \"female\"), \"deadfamily_woman\"] = 1\ntest.loc[(test[\"dead_family\"] == 0) & (test[\"live_family\"] == 0) & (test[\"deadfamily_man\"] == 0) & (test[\"deadfamily_woman\"] == 0) & (test[\"Family_size\"] >= 1) & (test[\"Sex\"] == \"male\"), \"deadfamily_man\"] = 1\ntest.loc[(test[\"dead_family\"] == 0) & (test[\"live_family\"] == 0) & (test[\"deadfamily_man\"] == 0) & (test[\"deadfamily_woman\"] == 0) & (test[\"Family_size\"] >= 1) & (test[\"Sex\"] == \"female\"), \"deadfamily_woman\"] = 1","97447b68":"grp_tk = train.drop([\"Survived\"], axis=1).append(test).groupby([\"Ticket\"])\ntickets = []\nfor grp, grp_train in grp_tk:\n    ticket_flag = True\n    if len(grp_train) != 1:\n        for i in range(len(grp_train) - 1):\n            if grp_train.iloc[i][\"Fname\"] != grp_train.iloc[i+1][\"Fname\"]:\n                ticket_flag = False\n    if ticket_flag == False:\n        tickets.append(grp)\ntrain.loc[(train.Ticket.isin(tickets)) & (train.Family_size == 0) & (train.Sex == \"male\"), \"deadfamily_man\"] = 1\ntrain.loc[(train.Ticket.isin(tickets)) & (train.Family_size == 0) & (train.Sex == \"female\"), \"deadfamily_woman\"] = 1\ntest.loc[(test.Ticket.isin(tickets)) & (test.Family_size == 0) & (test.Sex == \"male\"), \"deadfamily_man\"] = 1\ntest.loc[(test.Ticket.isin(tickets)) & (test.Family_size == 0) & (test.Sex == \"female\"), \"deadfamily_woman\"] = 1","d4a703c6":"test = test.fillna({\"Fare\": test[test[\"Pclass\"] == 3][\"Fare\"].mean()})","a9dacdf7":"train = train.drop([\"PassengerId\", \"Ticket\", \"Cabin\", \"Embarked\", \"Fname\"], axis=1)\ntest = test.drop([\"PassengerId\", \"Ticket\", \"Cabin\", \"Embarked\", \"Fname\"], axis=1)","1ae5abe5":"train_dummies_sex = pd.get_dummies(train[\"Sex\"])\ntest_dummies_sex = pd.get_dummies(test[\"Sex\"])\ntrain = pd.concat([train, train_dummies_sex], axis=1)\ntest = pd.concat([test, test_dummies_sex], axis=1)\ntrain = train.drop([\"Sex\"], axis=1)\ntest = test.drop([\"Sex\"], axis=1)","e6976bb8":"train_name = train.Name.str.extract(\"([a-zA-Z]+)\\.\")\ntest_name = test.Name.str.extract(\"([a-zA-Z]+)\\.\")\ntrain_name[\"Title\"] = train.Name.str.extract(\"([a-zA-Z]+)\\.\")\ntest_name[\"Title\"] = test.Name.str.extract(\"([a-zA-Z]+)\\.\")\n \ntrain_name = train_name.drop([0], axis=1)\ntest_name = test_name.drop([0], axis=1)\n \ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Mlle\", \"Ms\"], \"Miss\")\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Mme\"], \"Mrs\")\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Countess\", \"Sir\", \"Lady\", \"Don\"], \"Royal\")\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Dr\", \"Rev\", \"Col\", \"Major\", \"Jonkheer\", \"Capt\"], \"Rare\")\n \ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Ms\"], \"Miss\")\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Dona\"], \"Mrs\")\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Dr\", \"Rev\", \"Col\"], \"Rare\")\n \ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Mr\"], 1)\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Miss\"], 2)\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Mrs\"], 3)\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Master\"], 4)\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Royal\"], 5)\ntrain_name[\"Title\"] = train_name[\"Title\"].replace([\"Rare\"], 6)\n \ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Mr\"], 1)\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Miss\"], 2)\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Mrs\"], 3)\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Master\"], 4)\ntest_name[\"Title\"] = test_name[\"Title\"].replace([\"Rare\"], 6)\n \ntrain[\"Title\"] = train_name[\"Title\"]\ntest[\"Title\"] = test_name[\"Title\"]\n \ntrain = train.drop([\"Name\"], axis=1)\ntest = test.drop([\"Name\"], axis=1)","57d217de":"age_train = pd.concat([train.drop([\"Survived\"], axis=1), test], axis=0)\nage_train = age_train[age_train[\"Age\"].notnull()]\n \nage_label = age_train[\"Age\"]\nage_train = age_train.drop([\"Age\"], axis=1)\n \nRFR = RandomForestRegressor(max_depth=16, n_estimators=16)\nRFR.fit(age_train, age_label)\n \ntrain.loc[train.Age.isnull(), [\"Age\"]] = RFR.predict(train[train.Age.isnull()].drop([\"Age\", \"Survived\"], axis=1))\ntest.loc[test.Age.isnull(), [\"Age\"]] = RFR.predict(test[test.Age.isnull()].drop([\"Age\"], axis=1))","fff9cddd":"train = train.drop([\"SibSp\", \"Parch\"], axis=1)\ntest = test.drop([\"SibSp\", \"Parch\"], axis=1)","8210cf9c":"train.loc[train[\"Age\"] <= 15, \"AgeBin\"] = 0\ntrain.loc[(train[\"Age\"] > 15) & (train[\"Age\"] <= 30), \"AgeBin\"] = 1\ntrain.loc[(train[\"Age\"] > 30) & (train[\"Age\"] <= 49), \"AgeBin\"] = 2\ntrain.loc[(train[\"Age\"] > 49) & (train[\"Age\"] < 80), \"AgeBin\"] = 3\ntrain.loc[train[\"Age\"] >= 80, \"AgeBin\"] = 4\ntest.loc[test[\"Age\"] <= 15, \"AgeBin\"] = 0\ntest.loc[(test[\"Age\"] > 15) & (test[\"Age\"] <= 30), \"AgeBin\"] = 1\ntest.loc[(test[\"Age\"] > 30) & (test[\"Age\"] <= 49), \"AgeBin\"] = 2\ntest.loc[(test[\"Age\"] > 49) & (test[\"Age\"] < 80), \"AgeBin\"] = 3\ntest.loc[test[\"Age\"] >= 80, \"AgeBin\"] = 4","5151daee":"pd.qcut(train.drop([\"Survived\"], axis=1).append(test)[\"Fare\"], 5).head(10)","6b711f93":"train.loc[train[\"Fare\"] <= 7.854, \"FareBin\"] = 0\ntrain.loc[(train[\"Fare\"] > 7.854) & (train[\"Fare\"] <= 10.5), \"FareBin\"] = 1\ntrain.loc[(train[\"Fare\"] > 10.5) & (train[\"Fare\"] <= 21.558), \"FareBin\"] = 2\ntrain.loc[(train[\"Fare\"] > 21.558) & (train[\"Fare\"] <= 41.579), \"FareBin\"] = 3\ntrain.loc[train[\"Fare\"] > 41.579, \"FareBin\"] = 4\ntest.loc[test[\"Fare\"] <= 7.854, \"FareBin\"] = 0\ntest.loc[(test[\"Fare\"] > 7.854) & (test[\"Fare\"] <= 10.5), \"FareBin\"] = 1\ntest.loc[(test[\"Fare\"] > 10.5) & (test[\"Fare\"] <= 21.558), \"FareBin\"] = 2\ntest.loc[(test[\"Fare\"] > 21.558) & (test[\"Fare\"] <= 41.579), \"FareBin\"] = 3\ntest.loc[test[\"Fare\"] > 41.579, \"FareBin\"] = 4","3b85c28c":"train = train.drop([\"Age\", \"Fare\"], axis=1)\ntest = test.drop([\"Age\", \"Fare\"], axis=1)","5d15c530":"train.head(10)","75c03cbb":"y = train[\"Survived\"]\ntrain_x, val_x, train_y, val_y = train_test_split(train.drop([\"Survived\"], axis=1), y, test_size=0.22, random_state=0)\nclf = SVC(C=1, probability=True)\nclf.fit(train_x, train_y)\nclf.score(val_x, val_y)","61647d3b":"svc_grid = GridSearchCV(SVC(), {\"C\": [i for i in range(1, 101)]}, cv=4)\nsvc_grid.fit(train.drop([\"Survived\"], axis=1), y)\nsvc_grid.best_params_","74eef808":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n \n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n \n    plt.legend(loc=\"best\")\n    return plt","9285280c":"cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\nplot_learning_curve(SVC(C=10), \"C=10\", train.drop([\"Survived\"], axis=1), y, cv=cv)","637d61bb":"clf = SVC(C=10, probability=True)\nclf.fit(train_x, train_y)\ngender_submission[\"Survived\"] = clf.predict(test)\ngender_submission.to_csv(\"1.csv\", index=False)","82045eb4":"**Pclass**: Representing social status, **the higher the social status, the easier to survive**.","f28b5467":"***Load Data***","62308bfa":"These conclusions are all observed by myself. Interested friends can observe it by yourselves.","83e6dbb6":"**1. Same Fname, same Ticket, and Family_size>0 can determine a family, except for one family, the family's ticket number is consecutive, but the impact is not significant.** This special family's Fname is Vander Planke.","5e257cec":"**Add Fname feature, the last name**","d51edcd2":"**Age bin. Through visual observation, I found that children under the age of 15 who were not labeled as dead families survived, and the mortality rate of men aged 50 to 80 was extremely high**. So :","20cabecd":"**SibSp**: number of siblings and spouses on board.","ee893abd":"**Fare bin**","507887f1":"**Parch**: Number of parents and children on board.","87d268b1":"***Module Imports***","6a0ae05e":"**Fill missing Fare**","a5c8e77f":"**Age-missing value prediction, due to the use of algorithmic predictions, each prediction result is biased, which will lead to deviations in the final survival prediction results.**","69a29d38":"This part of the code is a bit messy, because it is divided twice, the first time did not do all.","bacfed2c":"**Name**: Most people will delete the Name directly when trying for the first time. But after getting deeper and deeper, you will find that **there is a huge amount of information hidden in the Name, including the title and surname**. I have also seen the use of the length of the name as a feature, I also tried it and found that it did not help much.","d5b10ae7":"**Add Family_size feature**","2af3278f":"**Embarked**: S port has the most people boarding the ship, and the survival rate is also the highest, but after trying it, the impact is not big.","6f3b2201":"**Summary of each feature**","dad95665":"**Ticket**: The ticket will also be removed when the first attempt is made. However, **Ticket and Name together constitute an important family feature**, and this is the place where this kernel is heavily handled.","f360e640":"**2. Families with female deaths, except for infants under one year of age, all family members die**. (The score has a big boost for the first time, after adding the feature)","6405c7c9":"**Add same Ticket, male die, female survive, child survive feature**","62997e0c":"This is the official example code, you can use it directly.","a3049215":"**5. The passengers of the same Ticket, perhaps friends, most of them also meet the above three family characteristics. However, after the family members is removed from training set, there are fewer passengers in the same ticket, and most of them are in line with male die, female survive, child survive.**","7037ec3a":"***data analysis and feature engineering***","34234e1e":"For Cabin, Embarked, etc. are already optional in my model and will not be discussed in this kernel. **The focus of this kernel will be discussed in Name, SibSp, Parch, and Ticket to build family and group characteristics**.","41ac8db1":"**PassengerId**: Of course **useless**","9c088a35":"**Sex feature processing**","0b97fd97":"**Age**: **The child's survival rate is quite high. Age has a lot of missing values and needs to be filled**.","ec30d6b4":"**Name processing, extracting the title in the Name, has a certain help for the age prediction, and does not seem to help the survival prediction.**","12a1d749":"If you are Chinese, you can check out my [blog](https:\/\/blog.csdn.net\/qq_33758867\/article\/details\/86715089) .","48b7463b":"At this point, all family and group features have been added. Next, there are some common treatments.","0fee53fa":"**Age bin and Fare bin**.(refer to [Titanic [0.82] - [0.83]](https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83)). I have not done this before, and I can't improve the score after 0.8. Although I don't understand the principle, I did improve the score after do this.","eadbf417":"**Sex survival rate**","5d130911":"**Delete features**","b9e1e4fc":"Then, after a series of explosion observations, well, there is no visualization here, that is, one piece of data is directly observed by the naked eye.","5c1d831e":"**Conclusion**","4a9ec036":"**Sex**\uff1aWomen's priority principle, ** women's survival rate is quite high**.","e1a8a125":"**Delete features**","ce59adab":"***Training with SVM***","3db21852":"**Delete features**","30825546":"**Add male die, female survive, child survive feature**","ae8b4465":"**Add female death family feature**","4930be05":"OK, the feature engineering is done, let's take a look at our data.","3e1ff8a8":"**Fare**: The fare corresponds to the ticket number. The same ticket number has the same fare, but the same fare, the ticket number is not necessarily the same.","29a4d7af":"**3. If a male older than 18 years old survives in the family, or a male of the age nan survives, the family will all survive**. (After joining this feature, the score reached 0.8)","52730656":"**Take a look at the learning curve**","68dfa4ac":"It can be seen that **the female survival rate is quite high and the male survival rate is quite low**. Basically, **one out of every five women survives, and one out of every five men dies**. It's important to note here, assuming that the Titanic's female is all alive and the male is dead, then we need to pay attention to **what the horrible thing happened to the dead woman and what lucky thing the living male has encountered**. Throughout the features, the only thing that can be thought of is that **all kinds of relatives and friends dragged down the dead woman or saved the living male**, so we turned our attention to **the family and peers**.","124f159b":"**Add male surviving family feature**","7367e026":"**First, make a simple observation of the data.**","2cc9394b":"**Submit. The parameters selected by GridSearchCV are not necessarily optimal parameters, and you need to manually adjust the parameters.The score will fluctuate between 0.79 and 0.81. My current highest score is 0.81339.**","e1d162df":"**GridSearchCV. After many trials, I only need to adjust C.**","16e068a6":"**4. The rest of the family, except for a few, male die, female survive, child survive.**","44df5ec0":"**Cabin**: Most kernels use the presence or absence of Cabin feature, but it has little effect."}}