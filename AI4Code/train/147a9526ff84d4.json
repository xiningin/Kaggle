{"cell_type":{"c3abb821":"code","bb85f6f4":"code","8a0331cc":"code","36aa2d38":"code","cf20c9c0":"code","986f1c50":"code","c5a277d4":"code","a8fecdc3":"code","8737bc0b":"code","48437654":"code","ecf2181e":"code","0e12ce92":"code","1aff4aee":"code","df6432b2":"code","c1849a3c":"code","a04b9612":"code","eacd7317":"code","831728b2":"code","26a1d5df":"code","a70aa4fc":"code","cfa63368":"code","ce902ab5":"code","9b54904d":"code","1a9d463d":"code","610711f9":"code","c29ef2cf":"code","af6ac433":"code","c840503b":"code","a32a8e95":"code","7001eb3c":"code","88a78835":"code","0a1b0701":"code","b8b962b0":"code","085d4ff6":"code","eb77245b":"code","79ad71b1":"code","db1bad15":"code","46142261":"code","a7c86f41":"code","1e787bc9":"code","d2dd3390":"code","f81d440d":"code","165a4b46":"code","d0d3ce7c":"code","024ea412":"code","526ad6fa":"code","c1d33c7e":"code","40a7e252":"code","25860510":"code","4e3c1f16":"code","bd7a1858":"code","14461087":"code","b5b0974a":"code","3b260624":"code","5f32fd56":"code","e5ebf1dd":"code","e23fa7d4":"code","08243756":"code","b0d207d2":"code","34694ebc":"code","4626815f":"code","e50b2559":"code","4278192a":"code","9f68cbe8":"code","49d76fa2":"code","26d3ca7b":"code","13308bf9":"code","62d7b150":"code","d1368059":"code","1fbc936d":"code","46fa026f":"code","c6ff236e":"code","e3c535ba":"code","533a6339":"code","9d3c85ca":"code","2cb966e6":"code","6624add0":"code","60b76e4f":"code","b43cb09a":"code","ffd0c1f8":"code","7df092d8":"code","bbbcf877":"code","3a44c6ce":"code","f5601b3e":"code","c9fb154f":"code","a965e7e8":"code","a4022ff3":"code","c63b1289":"code","e1cd4309":"code","9949ed3d":"code","bff809f3":"code","7171587d":"code","047bd30c":"code","5895144f":"code","50108d46":"code","bd60ed23":"code","955744df":"code","9a54e2d2":"code","fc90dcc1":"code","e1b0f272":"code","607d2347":"code","0b8af66e":"code","6970ed27":"code","a2d173fd":"code","56a0c78a":"code","fd52ecf4":"code","81ee435e":"code","2e91e051":"code","55bacd6a":"code","af92ab54":"code","0da5d872":"code","92744de3":"code","e602941c":"code","c5bf9431":"code","37ba3673":"code","5e167d30":"markdown","cfc83676":"markdown","970a9328":"markdown","bee66c6a":"markdown","529ba993":"markdown","c521aaa2":"markdown","414d2ae2":"markdown","7a875f52":"markdown","26c7227c":"markdown"},"source":{"c3abb821":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb85f6f4":"1502\/2224","8a0331cc":"# Import libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","36aa2d38":"# Read the test and train datasets\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","cf20c9c0":"train.head()","986f1c50":"\ntrain.describe(include = 'all')","c5a277d4":"train.shape","a8fecdc3":"test.head()","8737bc0b":"test.describe(include = 'all')","48437654":"test.shape","ecf2181e":"# Missing value percentage in train data\n\n100*train.isnull().sum()\/train.shape[0]","0e12ce92":"# Removing Cabin variable\n\ntrain.drop(['Cabin'], axis = 1, inplace = True)\ntrain.head()","1aff4aee":"# Removing Cabin variable from test \n\ntest.drop(['Cabin'], axis = 1, inplace = True)","df6432b2":"# Removing rows where Embarked variable is missing\n\ntrain = train[~train['Embarked'].isnull()].copy()","c1849a3c":"# Age variable\n\ntrain['Age'].describe()","a04b9612":"# Imputing age with median (28)\n\ntrain['Age'].fillna(28, inplace = True)","eacd7317":"# Looking at test data again\n\ntest.describe(include = 'all')","831728b2":"# Imputing missing row in Fare with median\n\ntest['Fare'].fillna(14.4542, inplace = True)","26a1d5df":"# Imputing missing rows in Age with median\n\ntest['Age'].fillna(27, inplace = True)","a70aa4fc":"test.describe(include = 'all')","cfa63368":"# Ticket class\n\nsns.countplot(train['Pclass'])\nplt.show()","ce902ab5":"# Sex\n\nsns.countplot(train['Sex'])\nplt.show()","9b54904d":"# Siblings\/spouses\n\nsns.countplot(train['SibSp'])\nplt.show()","1a9d463d":"# Parents\/Children\n\nsns.countplot(train['Parch'])\nplt.show()","610711f9":"# Cabin\n\nsns.countplot(train['Embarked'])\nplt.show()","c29ef2cf":"# Boxplot of age\n\nsns.boxplot(train['Age'])\nplt.show()","af6ac433":"# Boxplot of fare\n\nsns.boxplot(train['Fare'])\nplt.show()","c840503b":"# Removing outlier\n\ntrain = train[train['Fare'] < 400]","a32a8e95":"# Boxplot of fare\n\nsns.boxplot(train['Fare'])\nplt.show()","7001eb3c":"# Removing Name and PassengerId variable from train and test\n\ntrain.drop(['PassengerId', 'Name'], axis = 1, inplace = True)\ntest_id = test['PassengerId']\ntest.drop(['PassengerId', 'Name'], axis = 1, inplace = True)","88a78835":"# Encoding Pclass\n\ntrain['Pclass'] = train['Pclass'].map({1: 'First', 2: 'Second', 3: 'Third'})\ntest['Pclass'] = test['Pclass'].map({1: 'First', 2: 'Second', 3: 'Third'})","0a1b0701":"# Creating dummy variables for train data\n\ndummy_var = pd.get_dummies(train[['Pclass', 'Sex', 'Embarked']], drop_first = True)\n\ntrain = pd.concat([train, dummy_var], axis = 1)","b8b962b0":"# Creating dummy variables for test data\n\ndummy_var = pd.get_dummies(test[['Pclass', 'Sex', 'Embarked']], drop_first = True)\n\ntest = pd.concat([test, dummy_var], axis = 1)","085d4ff6":"y_train = train['Survived']\nX_train = train.drop(['Survived'], axis = 1)","eb77245b":"X_train.drop(['Pclass', 'Sex', 'Embarked', 'Ticket'], axis = 1, inplace = True)\ntest.drop(['Pclass', 'Sex', 'Embarked', 'Ticket'], axis = 1, inplace = True)","79ad71b1":"from sklearn.preprocessing import StandardScaler","db1bad15":"# Scaling train\n\nscaler = StandardScaler()\n\nX_train[['Age', 'SibSp', 'Parch', 'Fare']] = scaler.fit_transform(X_train[['Age', 'SibSp', 'Parch', 'Fare']])","46142261":"test[['Age', 'SibSp', 'Parch', 'Fare']] = scaler.transform(test[['Age', 'SibSp', 'Parch', 'Fare']])","a7c86f41":"# Correlation matrix\n\nsns.heatmap(X_train.corr(), annot = True)\nplt.show()","1e787bc9":"import statsmodels.api as sm","d2dd3390":"logm0 = sm.GLM(y_train, (sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm0.fit().summary()","f81d440d":"# Removing columns with high p-value and training the model again\n\ncol = X_train.columns\ncol\n\n","165a4b46":"col = col.drop('Fare', 1)\ncol","d0d3ce7c":"logm1 = sm.GLM(y_train, (sm.add_constant(X_train[col])), family = sm.families.Binomial())\nlogm1.fit().summary()","024ea412":"col = col.drop('Embarked_Q', 1)\ncol","526ad6fa":"logm2 = sm.GLM(y_train, (sm.add_constant(X_train[col])), family = sm.families.Binomial())\nlogm2.fit().summary()","c1d33c7e":"col = col.drop('Parch', 1)\ncol","40a7e252":"logm3 = sm.GLM(y_train, (sm.add_constant(X_train[col])), family = sm.families.Binomial())\nlogm3.fit().summary()","25860510":"res = logm3.fit()","4e3c1f16":"y_train_pred = res.predict((sm.add_constant(X_train[col]))).values.reshape(-1)","bd7a1858":"y_train_pred[:10]","14461087":"y_train_pred_final = pd.DataFrame({'Churn': y_train.values, 'Churn_prob': y_train_pred})","b5b0974a":"y_train_pred_final['Predicted'] = y_train_pred_final['Churn_prob'].map(lambda x: 1 if x > 0.5 else 0)","3b260624":"from sklearn import metrics","5f32fd56":"print(metrics.accuracy_score(y_train_pred_final['Churn'], y_train_pred_final['Predicted']))","e5ebf1dd":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","e23fa7d4":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_prob, drop_intermediate = False )","08243756":"draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_prob)","b0d207d2":"numbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Churn_prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","34694ebc":"from sklearn.metrics import confusion_matrix","4626815f":"cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","e50b2559":"cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","4278192a":"y_train_pred_final['Predicted_rev'] = y_train_pred_final['Churn_prob'].map(lambda x: 1 if x > 0.6 else 0)","9f68cbe8":"metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.Predicted_rev)","49d76fa2":"y_test_pred = res.predict((sm.add_constant(test[col]))).values.reshape(-1)","26d3ca7b":"y_test_pred","13308bf9":"test['Predicted'] = pd.DataFrame({'Churn_p': y_test_pred})['Churn_p'].map(lambda x: 1 if x > 0.6 else 0)","62d7b150":"test['PassengerId'] = test_id","d1368059":"test.head()","1fbc936d":"# Importing data again\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","46fa026f":"# Assigning labels to each dataframe\n\ntrain['label'] = 'train'\ntest['label'] = 'test'","c6ff236e":"train.head()","e3c535ba":"test.head()","533a6339":"# Separating y_train and X_train\n\ny_train = train['Survived']\nX_train = train.drop(['Survived'], axis = 1)\nX_train.head()","9d3c85ca":"all_data = pd.concat([X_train, test])\nall_data.head()","2cb966e6":"# Imputing missing values in Cabin variable with 'Unknown'\n# because missing cabin might indicate that it is a low class cabin\n# We will find it out in Bivariate Analysis and see if we need to drop the Cabin variable\n\nall_data['Cabin'].fillna('Unknown', inplace = True)","6624add0":"# Imputing Age, Fare with median value\n\nall_data['Age'].fillna(28, inplace = True)\nall_data['Fare'].fillna(14.454200, inplace = True)","60b76e4f":"# Imputing Embarked with mode\n\nall_data['Embarked'].fillna(all_data['Embarked'].value_counts().index[0], inplace = True)","b43cb09a":"# Checking missing values again\n\n100*all_data.isnull().sum()\/all_data.shape[0]","ffd0c1f8":"# Capping Fare at 300\n\nall_data['Fare'] = all_data['Fare'].apply(lambda x : 300 if x > 299 else x)","7df092d8":"# Remove unnecessary variables of PassengerId and Name\n\nall_data.drop(['PassengerId', 'Name', 'Ticket', 'Embarked'], axis = 1, inplace = True)\nall_data.head()","bbbcf877":"# Encoding Sex\n\nall_data['Sex'] = all_data['Sex'].map({'male': 1, 'female': 0})\nall_data.head()","3a44c6ce":"all_data.drop('Cabin', axis = 1, inplace = True)\nall_data.head()","f5601b3e":"X_train = all_data[all_data['label'] == 'train']\nX_test = all_data[all_data['label'] == 'test']\n\nX_train.drop('label', axis = 1, inplace = True)\nX_test.drop('label', axis = 1, inplace = True)","c9fb154f":"from sklearn.tree import DecisionTreeClassifier","a965e7e8":"dt = DecisionTreeClassifier(random_state = 42)","a4022ff3":"from sklearn.model_selection import GridSearchCV","c63b1289":"params = {\n    'max_depth': [2, 3, 4, 5],\n    'min_samples_leaf': [5, 8, 10, 12, 15, 20, 25, 30, 40, 50, 75, 100],\n    'criterion': [\"gini\", \"entropy\"]\n}","e1cd4309":"grid_search = GridSearchCV(estimator = dt, param_grid = params, cv = 5, n_jobs = -1, verbose = 1, scoring = 'accuracy')","9949ed3d":"grid_search.fit(X_train, y_train)","bff809f3":"score_df = pd.DataFrame(grid_search.cv_results_)\nscore_df.head()","7171587d":"score_df.nlargest(5, 'mean_test_score')","047bd30c":"grid_search.best_estimator_","5895144f":"dt_best = grid_search.best_estimator_","50108d46":"from sklearn.metrics import accuracy_score","bd60ed23":"def evaluate_model(dt_classifier):\n    print(\"Train Accuracy :\", accuracy_score(y_train, dt_classifier.predict(X_train)))\n    print(\"Train Confusion Matrix:\")\n    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))\n    print(\"-\"*50)\n    print(\"Test Accuracy :\", accuracy_score(y_test, dt_classifier.predict(X_test)))\n    print(\"Test Confusion Matrix:\")\n    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))","955744df":"accuracy_score(y_train, dt_best.predict(X_train))","9a54e2d2":"y_test_pred = dt_best.predict(X_test)","fc90dcc1":"test['Survived'] = pd.DataFrame({'Churn_label' : y_test_pred})['Churn_label']\ntest.head()","e1b0f272":"output = test[['PassengerId', 'Survived']]","607d2347":"dt.fit(X_train, y_train)","0b8af66e":"from IPython.display import Image","6970ed27":"from six import StringIO","a2d173fd":"from sklearn.tree import export_graphviz","56a0c78a":"!pip install pydotplus","fd52ecf4":"import pydotplus, graphviz","81ee435e":"dot_data = StringIO()","2e91e051":"export_graphviz(dt, out_file = dot_data, filled = True, rounded = True, feature_names = X_train.columns, class_names = ['No', 'Yes'])","55bacd6a":"graph = pydotplus.graph_from_dot_data(dot_data.getvalue())","af92ab54":"Image(graph.create_png())","0da5d872":"y_train_pred = dt.predict(X_train)\ny_test_pred = dt.predict(X_test)","92744de3":"print(accuracy_score(y_train, y_train_pred))","e602941c":"y_test_pred","c5bf9431":"test['Survived'] = pd.DataFrame({'Churn_label' : y_test_pred})['Churn_label']\ntest.head()","37ba3673":"output = test[['PassengerId', 'Survived']]","5e167d30":"We have missing values in both the train and test datasets. So, whatever operation we apply to our train data, we have to apply it to the test data too.","cfc83676":"67.5% passengers died in the Titanic disaster.","970a9328":"# Decision Tree Model","bee66c6a":"Cabin has 77.1% values missing. So, it's better to remove this column.","529ba993":"The mean is 29.64 years while the median is 28 years. Let's impute the missing rows with the median.","c521aaa2":"We can see that 38.4% people have survived in the train dataset, which is slightly more than the overall survival rate. <br>\nThe median age is 28 years. <br>\nThe median fare is 14.45 Dollars while the mean fare is 32.2 Dollars, which indicates the distribution of fare is skewed towards the right. ","414d2ae2":"## Univariate Analysis","7a875f52":"Embarked variable has 0.22% rows as missing. We can remove these rows.","26c7227c":"Age variable has 19.9% rows as missing. We can impute these rows. But, let's look at the variable description first."}}