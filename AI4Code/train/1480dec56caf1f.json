{"cell_type":{"edbae010":"code","284b7a19":"code","b038155b":"code","4e225e6c":"code","6eb74edd":"code","58449653":"code","b136dccf":"code","c947009e":"code","1932c46f":"code","18fdd718":"code","1b639075":"code","3e17818e":"code","8428c07e":"code","045a8b89":"code","dd2d1489":"code","cf9190a8":"code","05dfddbd":"code","599a4f80":"code","29ad2aea":"code","009bd480":"code","d38fe799":"code","fcdfe3ae":"code","e32e4470":"code","916e9183":"code","b6280686":"code","6324fc9e":"code","fe4f1e89":"code","27762586":"code","32f75469":"code","32fa132c":"code","368a9393":"code","6467ed06":"code","b40d6be3":"code","4a0ffe47":"code","f1e82e70":"code","59c79f98":"code","58a70c89":"code","c9220ff4":"code","710db52b":"code","a562e1fd":"code","de8876ec":"code","3b4afda2":"code","06202281":"code","ea1dc2d0":"code","0e5bf99a":"code","8aa8378e":"code","e51a48bf":"code","58d34e5e":"code","adddb02e":"code","e242b38d":"code","c859e5df":"code","4f28d4ba":"code","a1bbc817":"code","0246e80a":"code","db78cc91":"code","9494fa82":"code","0d7fabd1":"code","cba307e2":"code","1ea83b41":"markdown","d16378d7":"markdown","07952fef":"markdown","c8929b9b":"markdown","7890985f":"markdown","1bd2568e":"markdown","e4b70cbe":"markdown","b098e663":"markdown","ef475ca9":"markdown","cfdf036f":"markdown","c2c20caf":"markdown","d4a498d8":"markdown","2fb6c633":"markdown","49c4b8ab":"markdown","9f493fcd":"markdown","e527c75c":"markdown","e691f411":"markdown","9a46d389":"markdown","f844dd30":"markdown","0d35892c":"markdown","52379682":"markdown","c7f93278":"markdown","de4a1967":"markdown","db344f75":"markdown","d37f81b1":"markdown","39eeb861":"markdown","e6e31588":"markdown","7e645267":"markdown","3c17075c":"markdown","311c5d0e":"markdown","6b91cf6a":"markdown","351036ec":"markdown","6f1631ff":"markdown","6f725ca7":"markdown","2ed4a22d":"markdown","6b2f603c":"markdown","a38345ca":"markdown","bde198f9":"markdown","8c099b7d":"markdown","7fb923b3":"markdown","505fcf15":"markdown","b11b87bc":"markdown","bd4cd33c":"markdown","093e41e5":"markdown","7f3c5815":"markdown","49c76368":"markdown","6a25bb65":"markdown","d711b60c":"markdown","ed46dad7":"markdown","d5247081":"markdown","3b8624fe":"markdown","064cfc9b":"markdown","7853917f":"markdown","f8bb7fcd":"markdown","619fc9a2":"markdown","d6e9040f":"markdown","440a173a":"markdown","a168f527":"markdown","f08d427c":"markdown","431977be":"markdown","fd8884f8":"markdown","3394378f":"markdown"},"source":{"edbae010":"import numpy as np\nimport pandas as pd\nfrom matplotlib import rcParams\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit, cross_validate\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nfrom tqdm import tqdm","284b7a19":"data_all = pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\")","b038155b":"data_all.head()","4e225e6c":"data_all.shape","6eb74edd":"data_all.replace('?',np.nan, inplace=True)","58449653":"pd.value_counts(data_all['income'])\/data_all['income'].count()*100","b136dccf":"data_all.describe(include=\"all\").T","c947009e":"data_all[(data_all['hours.per.week'] <= 4) & (data_all['income'] == '>50K')].sort_values(by='education.num')","1932c46f":"# fill values\nprint(data_all['workclass'].mode())\nprint(data_all['occupation'].mode())\nprint(data_all['native.country'].mode())\ndata_all['workclass'].fillna(data_all['workclass'].mode()[0], inplace=True)\ndata_all['occupation'].fillna(data_all['occupation'].mode()[0], inplace=True)\ndata_all['native.country'].fillna(data_all['native.country'].mode()[0], inplace=True)","18fdd718":"data_all.info()","1b639075":"sns.set(rc={'figure.figsize':(10,4)})\nsns.set_style(\"white\")\ng = sns.countplot(x=\"workclass\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()\ng = g.set_xticklabels(g.get_xticklabels(), rotation=60, horizontalalignment='right')","3e17818e":"data_all[data_all['income'] == '>50K']['workclass'].value_counts()\/data_all['workclass'].value_counts()","8428c07e":"data_all.replace({'workclass':{'Federal-gov':'fed_gov', \n                               'State-gov':'gov', 'Local-gov':'gov',\n                               'Without-pay':'unemployed','Never-worked':'unemployed', \n                               'Self-emp-inc':'self-emp'}}\n                 ,inplace=True)","045a8b89":"sns.set(rc={'figure.figsize':(10,4)})\nsns.set_style(\"white\")\ng = sns.countplot(x=\"occupation\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()\ng = g.set_xticklabels(g.get_xticklabels(), rotation=60, horizontalalignment='right')","dd2d1489":"data_all[data_all['income'] == '>50K']['occupation'].value_counts()\/data_all['occupation'].value_counts()","cf9190a8":"data_all.replace({'occupation':{'Exec-managerial':'premium_pay', \n                                'Prof-specialty':'good_pay','Protective-serv':'good_pay', 'Tech-support':'good_pay',\n                                'Craft-repair':'normal_pay', 'Sales':'normal_pay','Transport-moving':'normal_pay',\n                                'Adm-clerical':'low_pay','Armed-Forces':'low_pay','Farming-fishing':'low_pay','Machine-op-inspct':'low_pay',\n                                'Other-service':'poor_pay', 'Handlers-cleaners':'poor_pay', 'Priv-house-serv':'poor_pay'}},inplace=True)","05dfddbd":"sns.set(rc={'figure.figsize':(10,4)})\nsns.set_style(\"white\")\ng = sns.countplot(x=\"education.num\", hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()\ng = g.set_xticklabels(g.get_xticklabels(), rotation=60, horizontalalignment='right')","599a4f80":"sns.set(rc={'figure.figsize':(10,4)})\nsns.set_style(\"white\")\ng = sns.countplot(x=\"marital.status\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()\ng = g.set_xticklabels(g.get_xticklabels(), rotation=30, horizontalalignment='right')","29ad2aea":"data_all.replace({'marital.status':{'Never-married':'single','Divorced':'single','Separated':'single',\n                                   'Widowed':'single','Married-spouse-absent':'single','Married-AF-spouse':'single',\n                                   'Married-civ-spouse':'married'}},inplace=True)","009bd480":"sns.set(rc={'figure.figsize':(4,4)})\nsns.set_style(\"white\")\nsns.countplot(x=\"sex\",hue=\"income\", data=data_all, palette=\"Set3\")\nsns.despine()","d38fe799":"sns.catplot(x=\"sex\", y=\"age\", kind=\"violin\", inner=\"box\", data=data_all[data_all['income'] == '>50K'], orient=\"v\")","fcdfe3ae":"sns.catplot(x=\"education\", y=\"age\", kind=\"violin\", inner=\"box\"\n            , data=data_all[data_all['income'] == '>50K'], orient=\"v\", aspect=2.5, height=5)","e32e4470":"sns.set(rc={'figure.figsize':(6,4)})\nsns.set_style(\"white\")\nsns.countplot(x=\"race\", hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","916e9183":"data_all[data_all['income'] == '>50K']['race'].value_counts()\/data_all['race'].value_counts()","b6280686":"g = sns.catplot(x=\"education\", y=\"age\", hue=\"race\", kind=\"violin\", inner=\"quartile\", split=True\n            , data=data_all[(data_all['income'] == '>50K') & (data_all['race'].isin(['White','Black']))], orient=\"v\", aspect=2.5, height=5)\ng = g.set_xticklabels(rotation=60, horizontalalignment='right')","6324fc9e":"g = sns.catplot(x=\"occupation\", y=\"age\", hue=\"race\", kind=\"violin\", inner=\"quartile\", split=True\n            , data=data_all[(data_all['race'].isin(['White','Black']))], orient=\"v\", aspect=2, height=4)\ng = g.set_xticklabels(rotation=60, horizontalalignment='right')","fe4f1e89":"data_all.replace({'race':{'Black':'not-white', 'Asian-Pac-Islander':'not-white', 'Amer-Indian-Eskimo':'not-white'\n                          ,'Other':'not-white'}}\n                , inplace=True)","27762586":"sns.set(rc={'figure.figsize':(10,4)})\nsns.set_style(\"white\")\nsns.countplot(x=\"relationship\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","32f75469":"data_all.replace({'relationship':{'Husband':'family','Wife':'family','Not-in-family':'not_family','Own-child':'family',\n                                  'Unmarried':'not_family','Other-relative':'not_family'}},inplace=True)","32fa132c":"data_all['age_bins'] = pd.cut(data_all['age'], bins=4)\nsns.set(rc={'figure.figsize':(6,4)})\nsns.set_style(\"white\")\nsns.countplot(x=\"age_bins\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","368a9393":"data_all['hpw_bins'] = pd.cut(data_all['hours.per.week'], 4)\nsns.set(rc={'figure.figsize':(6,4)})\nsns.set_style(\"white\")\nsns.countplot(x=\"hpw_bins\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","6467ed06":"data_all['cap_gain_bins'] = pd.cut(data_all['capital.gain'], [0,3000,7000,100000])\nsns.set(rc={'figure.figsize':(5,3)})\nsns.set_style(\"white\")\nsns.countplot(x=\"cap_gain_bins\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","b40d6be3":"data_all['cap_loss_bins'] = pd.cut(data_all['capital.loss'], [0,1000,5000])\nsns.set(rc={'figure.figsize':(3,3)})\nsns.set_style(\"white\")\nsns.countplot(x=\"cap_loss_bins\",hue=\"income\", data=data_all, palette=\"Set2\")\nsns.despine()","4a0ffe47":"data_all.replace({'native.country':{'China': 'asia', 'Hong': 'asia', 'India': 'asia', 'Iran': 'asia', 'Cambodia': 'asia', 'Japan': 'asia', 'Laos': 'asia', 'Philippines': 'asia', 'Vietnam': 'asia', 'Taiwan': 'asia', 'Thailand': 'asia'}},inplace=True)\ndata_all.replace({'native.country':{'England': 'europe', 'France': 'europe', 'Germany': 'europe', 'Greece': 'europe', 'Holand-Netherlands': 'europe', 'Hungary': 'europe', 'Ireland': 'europe', 'Italy': 'europe', 'Poland': 'europe', 'Portugal': 'europe', 'Scotland': 'europe', 'Yugoslavia': 'europe'}},inplace=True)\ndata_all.replace({'native.country':{'Canada':'NAmerica','United-States':'NAmerica','Puerto-Rico':'NAmerica'}},inplace=True)\ndata_all.replace({'native.country':{'Columbia': 'SA', 'Cuba': 'SA', 'Dominican-Republic': 'SA', 'Ecuador': 'SA', 'El-Salvador': 'SA', 'Guatemala': 'SA', 'Haiti': 'SA', 'Honduras': 'SA', 'Mexico': 'SA', 'Nicaragua': 'SA', 'Outlying-US(Guam-USVI-etc)': 'SA', 'Peru': 'SA', 'Jamaica': 'SA', 'Trinadad&Tobago': 'SA'}},inplace=True)\ndata_all.replace({'native.country':{'South':'SA'}},inplace=True)","f1e82e70":"# Except North America\nsns.set_style(\"white\")\nsns.countplot(x=\"native.country\",hue=\"income\", data=data_all[data_all['native.country'] != 'NAmerica'], palette=\"Set2\")\nsns.despine()","59c79f98":"data_all.drop(columns=['age_bins','hpw_bins','cap_gain_bins','cap_loss_bins'],inplace=True)","58a70c89":"data_all.at[data_all[data_all['income'] == '<=50K'].index, 'income'] = 1\ndata_all.at[data_all[data_all['income'] == '>50K'].index, 'income'] = 0","c9220ff4":"pd.value_counts(data_all['income'])\/data_all['income'].count()*100","710db52b":"# we will not use 'education' column as we have 'education.num'\ndata_all.drop(columns=['education'], inplace=True)","a562e1fd":"X,y = data_all.loc[:,data_all.columns != 'income'], data_all.loc[:,data_all.columns == 'income']\nX_train, X_test, y_train, y_test = train_test_split(data_all.loc[:,data_all.columns != 'income']\n                                                    , data_all.loc[:,data_all.columns == 'income']\n                                                    , test_size=0.1, random_state=42, stratify=data_all['income'], shuffle=True)","de8876ec":"X_train.shape, X_test.shape","3b4afda2":"#### Keep numerical\nscalar_train = StandardScaler()\nnum_col_names = X_train.select_dtypes(include=['int64']).columns\nnum_col_df = X_train[num_col_names].copy()\nscaled_num_col_df = scalar_train.fit_transform(num_col_df)\nfor i,j in enumerate(num_col_names):\n    X_train[j] = scaled_num_col_df[:,i]\n\n#---------------------------------\nnum_col_df_test = X_test[num_col_names].copy()\nscaled_num_col_df = scalar_train.transform(num_col_df_test)\nfor i,j in enumerate(num_col_names):\n    X_test[j] = scaled_num_col_df[:,i]","06202281":"X_train.head()","ea1dc2d0":"category_cols = list(set(X_train.columns.tolist()) - set(num_col_names))\nfor col in category_cols:\n    X_train[col] = X_train[col].astype('category')\n    X_test[col] = X_test[col].astype('category')","0e5bf99a":"X_train = pd.get_dummies(columns=category_cols, data=X_train, prefix=category_cols, prefix_sep=\"_\",drop_first=True)\n\nX_test = pd.get_dummies(columns=category_cols, data=X_test, prefix=category_cols, prefix_sep=\"_\",drop_first=True)","8aa8378e":"print(X_train.columns, X_train.shape)","e51a48bf":"X_train = np.asarray(X_train).astype('float32')\ny_train = np.asarray(y_train).astype('float32')","58d34e5e":"# performance on logistic regression\nlog_clf = LogisticRegression(solver='liblinear', random_state=42, max_iter=500)\n\nlog_clf.fit(X_train, y_train.ravel())\n\ntest_pred = log_clf.predict(X_test)","adddb02e":"y_test = np.asarray(y_test).astype('float32').ravel()","e242b38d":"prec_t = precision_score(y_test, test_pred)\nrec_t = recall_score(y_test, test_pred)\nprint(\"Test SK_Precision: %.3f\" % prec_t)\nprint(\"Test SK_Recall: %.3f\" % rec_t)\nprint(\"Test F1 Score: %.3f\" % ((2*prec_t*rec_t)\/(prec_t + rec_t)))\nprint(\"Test Accuracy: %.3f\" % accuracy_score(y_test, test_pred))","c859e5df":"skf = StratifiedKFold(n_splits=4)\nskf.get_n_splits(X_train, y_train)\n\nnn = []; rf = []; et = []; gb = []; svc = []; y_1 = []\n\nfor train_index, test_index in tqdm(skf.split(X_train, y_train)):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train_1, X_test_1 = X_train[train_index], X_train[test_index]\n    y_train_1, y_test_1 = y_train[train_index], y_train[test_index]\n    \n    # Neural network\n    clf = MLPClassifier(hidden_layer_sizes=(32,16,8), random_state=42)\n    clf.fit(X_train_1, y_train_1.ravel())\n    train_pred = clf.predict_proba(X_test_1)\n    nn.extend(list(train_pred[:,1].ravel()))\n    \n    # RandomForest\n    clf = RandomForestClassifier(max_depth=20, random_state=42, n_estimators=100, min_samples_split=0.01)\n    clf.fit(X_train_1, y_train_1.ravel())\n    train_pred = clf.predict_proba(X_test_1)\n    rf.extend(list(train_pred[:,1].ravel()))\n    \n    # ExtraTrees\n    clf = ExtraTreesClassifier(max_depth=20, random_state=42, min_samples_split=0.01)\n    clf.fit(X_train_1, y_train_1.ravel())\n    train_pred = clf.predict_proba(X_test_1)\n    et.extend(list(train_pred[:,1].ravel()))\n    \n    # GBM\n    clf = GradientBoostingClassifier(min_samples_split=0.01, random_state=42, n_estimators=100)\n    clf.fit(X_train_1, y_train_1.ravel())\n    train_pred = clf.predict_proba(X_test_1)\n    gb.extend(list(train_pred[:,1].ravel()))\n    \n    # SVM\n    clf = SVC(random_state=42, C=2, kernel='linear', probability=True)\n    clf.fit(X_train_1, y_train_1.ravel())\n    train_pred = clf.predict_proba(X_test_1)\n    svc.extend(list(train_pred[:,1].ravel()))  \n    \n    y_1.extend(list(y_test_1.ravel()))\n    \n\nprint(len(nn), len(rf), len(et), len(gb), len(svc), len(y_1))","4f28d4ba":"X_2 = pd.DataFrame.from_dict({'NN':nn, 'RF':rf, 'ET':et, 'GB':gb, 'SVC':svc, 'Y':y_1})\nprint(X_2.shape)\nX_2.head()","a1bbc817":"cv_splits = StratifiedShuffleSplit(n_splits=5, test_size=0.3, train_size=0.7, random_state=42)\n\nalg = LogisticRegression(solver='liblinear', random_state=42, max_iter=500)\n\ncross_val = cross_validate(alg, \n                           X_2.loc[:, ~X_2.columns.isin(['Y'])], \n                           X_2['Y'],\n                           cv  = cv_splits,\n                           scoring = ['precision', 'recall', 'f1'],\n                           return_train_score=True, return_estimator=False\n                          )","0246e80a":"print(cross_val['train_precision'].mean())\nprint(cross_val['train_recall'].mean())\nprint(cross_val['train_f1'].mean())\nprint(\"--\")\nprint(cross_val['test_precision'].mean())\nprint(cross_val['test_recall'].mean())\nprint(cross_val['test_f1'].mean())","db78cc91":"nnt = []; rft = []; ett = []; gbt = []; svct = []; y_1t = []\n\n# Neural network\nclf = MLPClassifier(hidden_layer_sizes=(32,16,8), random_state=42)\nclf.fit(X_train, y_train.ravel())\ntrain_pred = clf.predict_proba(X_test)\nnnt.extend(list(train_pred[:,1].ravel()))\n\n# RandomForest\nclf = RandomForestClassifier(max_depth=20, random_state=42, n_estimators=100, min_samples_split=0.01)\nclf.fit(X_train, y_train.ravel())\ntrain_pred = clf.predict_proba(X_test)\nrft.extend(list(train_pred[:,1].ravel()))\n\n# ExtraTrees\nclf = ExtraTreesClassifier(max_depth=20, random_state=42, min_samples_split=0.01)\nclf.fit(X_train, y_train.ravel())\ntrain_pred = clf.predict_proba(X_test)\nett.extend(list(train_pred[:,1].ravel()))\n\n# GBM\nclf = GradientBoostingClassifier(random_state=42, n_estimators=100, min_samples_split=0.01)\nclf.fit(X_train, y_train.ravel())\ntrain_pred = clf.predict_proba(X_test)\ngbt.extend(list(train_pred[:,1].ravel()))\n\n# SVM\nclf = SVC(random_state=42, C=1, kernel='linear', probability=True)\nclf.fit(X_train, y_train.ravel())\ntrain_pred = clf.predict_proba(X_test)\nsvct.extend(list(train_pred[:,1].ravel()))\n\n\ny_1t.extend(list(y_test))\n\n\nprint(len(nnt), len(rft), len(ett), len(gbt), len(svct), len(y_1t))","9494fa82":"X_test_new = pd.DataFrame.from_dict({'NN':nnt, 'RF':rft, 'ET':ett, 'GB':gbt, 'SVC':svct, 'Y':y_1t})\nprint(X_test_new.shape)\nX_test_new.head()","0d7fabd1":"alg.fit(X_2.loc[:, ~X_2.columns.isin(['Y'])], X_2['Y'])\ntest_pred = alg.predict(X_test_new.loc[:, ~X_test_new.columns.isin(['Y'])])","cba307e2":"prec_t = precision_score(X_test_new['Y'].values.ravel().tolist(), test_pred.ravel().tolist())\nrec_t = recall_score(X_test_new['Y'].values.ravel().tolist(), test_pred.ravel().tolist())\nprint(\"Test SK_Precision: %.3f\" % prec_t)\nprint(\"Test SK_Recall: %.3f\" % rec_t)\nprint(\"Test F1 Score: %.3f\" % ((2*prec_t*rec_t)\/(prec_t + rec_t)))\nprint(\"Test Accuracy: %.3f\" % accuracy_score(X_test_new['Y'].values.ravel().tolist(), test_pred.ravel().tolist()))","1ea83b41":"We can see that less educated people earn > 50K\/year at an older age as compared to others","d16378d7":"People at higher-up positions (Exec-managerial) have more probablity of earning more than >50K per year  \nAs expected, blue-collared workforce (handlers etc..) have much less probabilty of earning >50K, some still seem to be earning > 50K but those are most probably older people","07952fef":"looks like some discrimination with black folks.. lets draw a graph comparing education, age, [White, black] races and income (only > 50K)","c8929b9b":"let's see some numbers, graph isn't quite clear","7890985f":"# Data Preprocessing\n\nIn next few steps, we will convert categorical variables to numerical, scale numerical variables, convert target variable to binary and drop 'education' variable, we will keep all other variables","1bd2568e":"# Data Exploration (EDA)","e4b70cbe":"Education vs Income","b098e663":"# Predictions  \n\n* Use the same steps for test set too\n* Train the first-stage models on whole training set and then predict on test set\n* Use meta-model to create final predictions","ef475ca9":"Let's see some actual numbers","cfdf036f":"We will next do a train test split - 0.3 part for testing and rest for training  \nWe will `stratify` our data on 'income' so that class distribution is same in both training and test","c2c20caf":"Let's try logistic regression","d4a498d8":"Things kind of look alright to me.. more or less ok (with few exceptions, but that could actually be an issue iwth data too)  \n\nLet's see if low proportion of people earning >50K is because black people are more employed in low paying occupation ?","2fb6c633":"let's **drop eduction** field as the same information is already presented by another numerical variable **education.num**","49c4b8ab":"Update native.country values.. using continent names rather than country names to club together classes","9f493fcd":"Scaling numerical variables  \n**Tip:** Make sure to use same scale for both training and testing (meaning don't fit separately on train and test sets)","e527c75c":"This seems like the case, more of them (as compared to white) are employed in low and poor pay occupations.. so this explains it\n\nAlso, we will group together some classes","e691f411":"Well at-least people earning > 50 K are highly educated (so probably not outliers), also looks like their occupations in 'execs' or 'profs'","9a46d389":"Hmm... looks like we have '?' character in data for missing values, we will need to replace that","f844dd30":"Do females earn more at higer age as compared to males?","0d35892c":"**Change**  \n\nThere's about **1.4% improvement in f1 score **and **2.3% in accuracy**, we might be able to improve further by tuning classifiers","52379682":"capital gains field is co-related with income, more gains means more income","c7f93278":"Checking number of classes and class distribution, we should check if our classes are balanced or skewed, it would help us choose correct performance metric for evaluating model","de4a1967":"We will again group some classes based on above numbers","db344f75":"We can see the pay gap between genders, proportion of females earning > 50K is less as compared to males","d37f81b1":"Looks like Workclass, Occupation and native.country has NaN values  \nWe will use mode (most occuring) as imputing method to fill these NaNs  \n\n**Age** seem alright, minimum is 17 and maximum is 90 (who's still working at 90?)  \n**hours.per.week** - minimum is only 1 ? We will check this.. could be an outlier if salary is >50K","39eeb861":"replacing '?' with NaN for now, it would be easier to fill NaN later with other resonable estimates","e6e31588":"Let's just see what all and how manu columns are present in our final dataset which we will use for training","7e645267":"**Let's see if this score can be improved**","3c17075c":"<u>Let's get Started!<\/u>\n\nImporting required modules","311c5d0e":"# Stacked Generalization\/Stacking  \n\n* We will split the training data in 4 parts - train_a, train_b, train_c, train_d  \n* Fit a first-stage model on train_a+train_b+train_c combined and then predict on train_d. Repeat this step 3 more times to create predictions for aall 4 train sets.  \n* Repeat the previous step for other models as well. I have randomly selected NN, RF, ET, GBM and SVM\n* train a meta model (logistic regression) on the predictions of previous models","6b91cf6a":"Let's see some numbers - what percentage of people in each class earns more than 50K a year","351036ec":"as expected, proportion of younger people earning more than 50K\/year is less as compared to adult and senior people","6f1631ff":"Again, we will group some classes into one","6f725ca7":"# Adult Census Income\n**Predict whether income exceeds $50K\/yr based on census data**  \n\n\n---\n\n\nMy objective of creating this kernel is to learn (and teach) to apply **Stacking** and see the improvement in performance\n\n\n**Contents:**\n1. [Data Exploration and Visualization](#Data-Exploration-(EDA))\n2. [Data Preprocessing](#Data-Preprocessing)\n3. [Modeling](#Modeling-Part)\n4. [Stacking](#Stacked-Generalization\/Stacking)\n5. [Predictions](#Predictions)\n","2ed4a22d":"simple math.. the more you work more you would earn","6b2f603c":"relation case looks similar (related) to 'marital.status' field.. people happily married are husband and wife (and this graph suggests the same, people who are married have more probability of earning > 50K).. we may remove one of the feature from our model","a38345ca":"relationship vs income","bde198f9":"No correlation with any country.. although proportion of people from south america region earning less than 50K is more as compared to people from other region","8c099b7d":"we will now create separate binary features for each workclass type, occupation type, race type, country name and marital status","7fb923b3":"Looks like all variables scaled perfectly  \n\nConverting rest of the variables to `category` type foe easier preprocessing in next steps","505fcf15":"Reading data file","b11b87bc":"Not quite sure what to conclude.. seems like people happily married (or let's just say married) have higher chances of earning > 50K as compared to other (unhappy ?) people.. doesn't look quite intutive to me though  \n'Never-married' people are probably younger folks and that's why they earn less","bd4cd33c":"Final check if we still have any NaN's in our data","093e41e5":"Occupation vs Income","7f3c5815":"We will also club together some of the classes based on above information","49c76368":"So proportion of people earning > 50K is more for highly educated people... only if I knew before ;)","6a25bb65":"# Modeling Part\n\n","d711b60c":"Gender vs Income","ed46dad7":"**Observation 1:** Most of the employess are employed in Private sector and looks like people who are self employed (inc - i believe registered firms) are more likely to earn >50K a year  \nIn general, count of people earning <=50K is more than count of people earning more","d5247081":"let's fill all missing values with `mode`","3b8624fe":"We can see that there are **two classes** the **classes are skewed.**\n\nWill choose <b>F1-Score<\/b> (Precision and Recall) as the performance metric for our model","064cfc9b":"just check if everything got converted to 0 and 1 and class distribution is still same.. verification step","7853917f":"Checking how many (Rows, Columns) are present in data","f8bb7fcd":"Now we will do some basic **EDA**, we will visualize independent variable against dependent and try to determine some relationships. We will look out for any outliers or anything out of ordinary. We will also do some **feature engineering** steps (clubbing similar classes, thereby reducing features dimension)  \n\nThis section is a bit more detailed so please skip to [Data Preprocessing](#Data-Preprocessing) section directly if you want to","619fc9a2":"Doesn't quite look like the case, both male and female have approximately same median age when they start to earn > 50K","d6e9040f":"let's first convert income variable to binary 0 and 1 (as needed by model)","440a173a":"Much awaited Age vs Income comparision","a168f527":"Doesn't look like same case with capital loss though, income doesn't seem to be related with capital.loss directly","f08d427c":"Is there any pay gap between people from different races ?","431977be":"Take a peek at the data, see what columns are present and the data types, also check if headers are picked correctly","fd8884f8":"Let's look at data characteristics in bit more detail, and look for potential outliers in the data","3394378f":"**Summarized findings**\n1. Majority of people work in **Private**-Sector\n2. People who are <b>self-employed <\/b>(self-employed-inc), or with <b>higher-education degree<\/b> (Prof-school, doctorate, masters) generally earn more than 50K a year,\n3. People who are married have higher chances of earning more than >50K (may be this is related to age)\n4. Approx 1\/3rd of male earns more than 50K. For females this number is much lower\n5. As age increases, proportion of people earning more than 50K increases\n6. As number of work hours per week increases, proportion of people earning > 50K also increases, although people at higher-up positions tend to earn > 50K even when working for very few number of hours\n7. More capital gain translates to more than 50K income\n8. Proportion of black people earning > 50K is less than white people but when taking education into account, they seem to be paid fairely (with few exceptions). When compared with occupation we found that more of them are employed in low, poor pay occupations and hence proportion is less"}}