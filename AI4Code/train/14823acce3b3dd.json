{"cell_type":{"580bf9d7":"code","39fe5cf2":"code","86b72e84":"code","8bbb79f9":"code","566b3040":"code","fddb9234":"code","ecc8b0d3":"code","9453c681":"code","a700e6fe":"code","3fad640e":"code","c5e9aefe":"code","216843b8":"code","53e36353":"code","e83e3e14":"markdown"},"source":{"580bf9d7":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import LabelEncoder\n#from keras.utils.np_utils import to_categorical\n\nfrom keras.applications import VGG16\nfrom keras import models \nfrom keras import layers\n\nfrom keras.preprocessing.image import ImageDataGenerator","39fe5cf2":"images_dir = '..\/input\/images\/Images'\n\nbreed_list= os.listdir(images_dir)\nbreed_list = breed_list[:50]","86b72e84":"#Loading training data\ndef load_img_nd_labels(breed_list):\n    img_lst = []\n    lables= []\n    for index,category in enumerate(breed_list):\n        for image_name in os.listdir(images_dir+\"\/\"+category):\n            img = cv2.imread(images_dir+\"\/\"+category+\"\/\"+image_name, 1) \n            img = cv2.resize(img,(150,150))\n            \n            img_lst.append(np.array(img))\n            \n            lables.append(str(category))\n    return img_lst, lables","8bbb79f9":"images, lables = load_img_nd_labels(breed_list)","566b3040":"print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(lables))","fddb9234":"images = np.array(images)\n","ecc8b0d3":"label_encoder = LabelEncoder()\nlables = label_encoder.fit_transform(lables)","9453c681":"print('images shpae: ', images.shape)\nprint(\"lable shape\", lables.shape)","a700e6fe":"x_train,x_test,y_train,y_test = train_test_split(images,lables,test_size=0.3,random_state=69)","3fad640e":"print(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"\\nx_test shape = \",x_test.shape)\nprint(\"y_test shape = \",y_test.shape)","c5e9aefe":"#Model\n\nconv_base = VGG16(weights='imagenet',                \n                  include_top=False,              \n                  input_shape=(150, 150, 3))\n\nmodel = models.Sequential() 5\nmodel.add(conv_base) \nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dense(10,activation='softmax')) \n\n\nmodel.summary()","216843b8":"#Data Augmentation\ndatagen = ImageDataGenerator(rescale = 1.\/255,       \n        rotation_range=10,  \n        zoom_range = 0.2, \n        width_shift_range=0.2,  \n        height_shift_range=0.2, \n        horizontal_flip=True,  \n        vertical_flip=False) \n\ntrain_aug = datagen.flow(x_train, y_train, batch_size = 25)\ntest_aug = datagen.flow(x_test, y_test, batch_size = 25)","53e36353":"model.compile(loss=\"sparse_categorical_crossentropy\",\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n    train_aug,\n    validation_data  = test_aug,\n    epochs = 50,\n    validation_steps = 1000,\n    steps_per_epoch  = 1000\n)","e83e3e14":"1. This model needs fine tuning\n2. it seems label encodiing not useful so have to use to_categorical"}}