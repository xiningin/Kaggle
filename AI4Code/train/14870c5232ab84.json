{"cell_type":{"b6e7b510":"code","ca56af3f":"code","22282dc3":"code","4b9f664e":"code","a38d3061":"code","05dcad8e":"code","d3698a53":"code","78cfb9ef":"code","377c1ca9":"code","deec7b69":"code","716f8994":"code","306aea58":"code","19ea133c":"code","a7bdfff6":"code","6e8e1f74":"code","e5237cd9":"code","ce5015e9":"code","38becdb5":"code","471a109a":"code","e3db718b":"code","5c5f5b85":"code","1267fde0":"code","0a7bbcd8":"code","6e20bc5d":"code","f7063684":"code","89e8c947":"code","9e11c71c":"code","6563a73e":"code","13ac5d75":"code","d3b5f120":"code","8d1d6232":"code","197907da":"code","d548c47f":"code","50c7299c":"code","537cfcd4":"code","35780a3e":"code","b4af604c":"code","4b902576":"code","9c469a33":"code","efbc0486":"code","d935ab54":"code","465b00fd":"code","f4c82fa2":"code","fa4de2ed":"code","805c0e13":"code","6620035a":"code","95d7add0":"code","8b91eead":"code","06c20bd5":"code","b34d4a90":"code","49717a05":"code","4a90a522":"code","d0e8e247":"code","9e8b45eb":"code","a2e4dd4e":"code","88ec7b1b":"code","fe759e60":"code","21350584":"code","66149b48":"code","2435d75b":"code","0b19efa8":"code","00a91129":"code","9f2128d1":"code","0db0f9df":"code","23ae5e23":"code","10a20432":"code","c2460289":"code","eabf4614":"code","0bdebbfc":"code","7bd7b713":"code","eb3b4762":"code","5d0e6b84":"code","ebd0bb0f":"code","5f856acb":"code","bc425a23":"code","267c1187":"code","0601c4ab":"code","0096dc49":"markdown","45e2011e":"markdown","7d985013":"markdown","05082e40":"markdown","e5552685":"markdown","f08864f9":"markdown","7fba522d":"markdown","a33c6997":"markdown","9e545a12":"markdown","b4f25b7f":"markdown","34709740":"markdown","7046ade7":"markdown","f93d78ff":"markdown","55cd41cd":"markdown","b7d6df5e":"markdown","c11dd121":"markdown","4259110c":"markdown","851d176c":"markdown","a0ebd06e":"markdown","0e6c3ea4":"markdown","93a78cec":"markdown","06a6a755":"markdown","9c6c74a3":"markdown","6313f5f3":"markdown","8dea0ffb":"markdown","0c16571f":"markdown","dad1e378":"markdown","95951bf8":"markdown","7664c1a0":"markdown","c6d8a830":"markdown"},"source":{"b6e7b510":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ca56af3f":"# This is to supress the warning messages (if any) generated in our code\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import of fundamental libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statistics as sts\n%matplotlib inline","22282dc3":"train = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv',index_col=0)\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv',index_col=0)\nprint(f'Train dataset: {train.shape[0]} rows and {train.shape[1]} columns')\nprint(f'Test dataset:  {test.shape[0]} rows and {test.shape[1]} columns')","4b9f664e":"train.info()","a38d3061":"# A huge mix of categorical (nominal and ordinal) with numerical (discrete and continuos) features.\n# We will split them and apply some EDA seperately\nfrom sklearn.compose import make_column_selector as selector\n\n#####################\n# All numerical features\n####################\nnum_cols = selector(dtype_exclude=['object','category'])\nnum_cols = num_cols(train)\nnum_cols.remove('MSSubClass')\nnum_cols.remove('SalePrice')\n\n####################################\n# Numerical features: Discrete (disc)\n####################################\ndisc = ['OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath',\n        'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'MoSold', 'YrSold']\n\n################################\n# Numerical features: Continuous\n###############################\ncont = []\nfor i in num_cols:\n    if i not in disc:\n        cont.append(i)\n\n######################\n# All categorical features\n#####################\ncat_cols = selector(dtype_include=['object','category'])\ncat_cols = cat_cols(train)\ncat_cols = cat_cols + ['MSSubClass']\n\n#################\n# Ordinal \n#################\nordi = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n       'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond','PoolQC', 'Fence']\n\n# Nominal\nnomi = []\nfor i in cat_cols:\n    if i not in ordi:\n        nomi.append(i)","05dcad8e":"sns.set_style('darkgrid')\nfig = plt.figure(figsize=(24,20))\nfor index, col in enumerate(cont):\n    plt.subplot(6,4,index+1)\n    sns.distplot(train.loc[:,col].dropna(),kde=False)\nfig.tight_layout(pad=1.0)\nsns.set_context('paper',font_scale=1.5)","d3698a53":"sns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index,col in enumerate(disc):\n    plt.subplot(5,3,index+1)\n    sns.countplot(x=col, data=train)\nfig.tight_layout(pad=1.0)","78cfb9ef":"sns.set_context('paper',font_scale=1)\nfig = plt.figure(figsize=(24,30))\nfor index,col in enumerate(nomi):\n    plt.subplot(9,5,index+1)\n    sns.countplot(x=col, data=train[nomi])\n    plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","377c1ca9":"sns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index,col in enumerate(ordi):\n    plt.subplot(5,3,index+1)\n    sns.countplot(x=col, data=train[ordi])\n    plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","deec7b69":"# Numerical continuious columns vs the SalePrice\nsns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index in range(len(cont)):\n    plt.subplot(5,5,index+1)\n    sns.scatterplot(x=train[cont].iloc[:,index],\n                    y=train['SalePrice'],\n                    data=train)\nfig.tight_layout(pad=1.0)","716f8994":"disc_S = disc + ['SalePrice']","306aea58":"sns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index,col in enumerate(disc):\n    plt.subplot(5,3,index+1)\n    sns.boxplot(x=col,y='SalePrice',data=train[disc_S])\n    #plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","19ea133c":"nomi_S = nomi + ['SalePrice']","a7bdfff6":"sns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index,col in enumerate(nomi):\n    plt.subplot(6,5,index+1)\n    sns.boxplot(x=col,y='SalePrice',data=train[nomi_S])\n    plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","6e8e1f74":"ordi_S = ordi + ['SalePrice']","e5237cd9":"sns.set_context('paper',font_scale=1.5)\nfig = plt.figure(figsize=(24,20))\nfor index,col in enumerate(ordi):\n    plt.subplot(6,5,index+1)\n    sns.boxplot(x=col,y='SalePrice',data=train[ordi_S])\n    plt.xticks(rotation=90)\nfig.tight_layout(pad=1.0)","ce5015e9":"# Checking for multicollinearity within numerical columns\n# (keep in mind correlation and causation are different things)\n\nplt.figure(figsize=(14,12))\nnum_correlation = train[num_cols].corr()\nsns.set_style('darkgrid')\nsns.heatmap(num_correlation, \n            #mask = num_correlation < 0.8,\n            linewidth=0.5,\n            cmap='Blues');","38becdb5":"t1 = num_correlation.abs().unstack().drop_duplicates().sort_values(ascending=False)\nt1[(t1< 1) & (t1 > 0.8)]","471a109a":"# Investigating correlation between numerical features and the target (SalePrice)\nnum_cols_S = num_cols + ['SalePrice']\ncorrelation = train[num_cols_S].corr()\nc1 = correlation[['SalePrice']].sort_values(['SalePrice'],ascending=False)\nc1[0:10]","e3db718b":"train = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv',index_col=0)\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv',index_col=0)\n\n# Concatenating train and test datasets.\n# They can be split again later on using the id columns as reference\nfull_data = pd.concat([train,test],axis=0)","5c5f5b85":"print(f'Train dataset: {train.shape[0]} rows and {train.shape[1]} columns')\nprint(f'Test dataset:  {test.shape[0]} rows and {test.shape[1]} columns')\nprint(f'full_data dataset:  {full_data.shape[0]} rows and {full_data.shape[1]} columns')","1267fde0":"plt.figure(figsize=(24,6))\nsns.heatmap(full_data.isnull(),\n            yticklabels=False,\n            cbar=False,\n            cmap='viridis');","0a7bbcd8":"def missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)","6e20bc5d":"missing_value(full_data)","f7063684":"## Features with more than 90% of values missing:\n## PoolQC, MiscFeature, Alley\n### Droping PoolQC, MiscFeature and Alley\nfull_data.drop(['PoolQC','MiscFeature','Alley'],axis=1,inplace=True)","89e8c947":"full_data.shape","9e11c71c":"ordi.remove('PoolQC')","6563a73e":"nomi.remove('MiscFeature')\nnomi.remove('Alley')","13ac5d75":"full_data.drop(['GarageCars','GarageYrBlt','TotRmsAbvGrd','1stFlrSF'],axis=1,inplace=True)","d3b5f120":"disc.remove('TotRmsAbvGrd')\ndisc.remove('GarageCars')","8d1d6232":"cont.remove('1stFlrSF')\ncont.remove('GarageYrBlt')","197907da":"full_data.shape","d548c47f":"missing_value(full_data[cont])","50c7299c":"# LotFrontage - missing values imputed using median of Neighborhood\nfull_data['LotFrontage'] = full_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n# MasVnrArea - missing values imputed using mode\nfull_data['MasVnrArea'] = full_data['MasVnrArea'].fillna(sts.mode(full_data['MasVnrArea']))\n# GarageArea - missing values imputed using mean value\nfull_data['GarageArea'] = full_data['GarageArea'].fillna(full_data['GarageArea'].mean())\n# BsmtFinSF1 - missing values imputed using mode value\nfull_data['BsmtFinSF1'] = full_data['BsmtFinSF1'].fillna(sts.mode(full_data['BsmtFinSF1']))\n# BsmtFinSF2 - missing values imputed using mode value\nfull_data['BsmtFinSF2'] = full_data['BsmtFinSF2'].fillna(sts.mode(full_data['BsmtFinSF2']))\n# BsmtUnfSF - missing values imputed using median value\nfull_data['BsmtUnfSF'] = full_data['BsmtUnfSF'].fillna(full_data['BsmtUnfSF'].median())\n# TotalBsmtSF - missing values imputed using mean value\nfull_data['TotalBsmtSF'] = full_data['TotalBsmtSF'].fillna(full_data['TotalBsmtSF'].mean())","537cfcd4":"missing_value(full_data[disc])","35780a3e":"# BsmtFullBath - missing values imputed using mode value\nfull_data['BsmtFullBath'] = full_data['BsmtFullBath'].fillna(sts.mode(full_data['BsmtFullBath']))\n# BsmtFullBath - missing values imputed using mode value\nfull_data['BsmtHalfBath'] = full_data['BsmtHalfBath'].fillna(sts.mode(full_data['BsmtHalfBath']))\n","b4af604c":"missing_value(full_data[nomi])","4b902576":"lst = list(missing_value(full_data[nomi]).index)\nfull_data[lst] = full_data[lst].transform(lambda x : x.fillna(x.mode()[0]))","9c469a33":"missing_value(full_data[ordi])","efbc0486":"lst2 = list(missing_value(full_data[ordi]).index)\nfull_data[lst2] = full_data[lst2].fillna(\"NA\")","d935ab54":"singlers_ordi = []\nfor i in ordi:\n    counts = train[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(train) * 100 > 90:\n        singlers_ordi.append(i)\n\nsinglers_ordi = list(singlers_ordi)","465b00fd":"singlers_ordi","f4c82fa2":"pd.DataFrame({'count': train['GarageCond'].dropna().value_counts(), \n                  '%': train['GarageCond'].dropna().value_counts()\/len(train)*100})","fa4de2ed":"train['GarageCond'].isnull().sum()","805c0e13":"# Dropping GarageCond as 90% of its non NA values are in a single class\nfull_data.drop('GarageCond', axis=1, inplace=True)","6620035a":"full_data.shape","95d7add0":"ordi.remove('GarageCond')","8b91eead":"singlers_nomi = []\nfor i in nomi:\n    counts = train[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(train) * 100 > 95:\n        singlers_nomi.append(i)\n\nsinglers_nomi = list(singlers_nomi)","06c20bd5":"singlers_nomi","b34d4a90":"pd.DataFrame({'count': train['Street'].value_counts(), \n                  '%': train['Street'].value_counts()\/len(train)*100})","49717a05":"pd.DataFrame({'count': train['Utilities'].value_counts(), \n                  '%': train['Utilities'].value_counts()\/len(train)*100})","4a90a522":"pd.DataFrame({'count': train['LandSlope'].value_counts(), \n                  '%': train['LandSlope'].value_counts()\/len(train)*100})","d0e8e247":"pd.DataFrame({'count': train['Condition2'].value_counts(), \n                  '%': train['Condition2'].value_counts()\/len(train)*100})","9e8b45eb":"pd.DataFrame({'count': train['RoofMatl'].value_counts(), \n                  '%': train['RoofMatl'].value_counts()\/len(train)*100})","a2e4dd4e":"pd.DataFrame({'count': train['Heating'].value_counts(), \n                  '%': train['Heating'].value_counts()\/len(train)*100})","88ec7b1b":"full_data.drop(singlers_nomi,axis=1,inplace=True)","fe759e60":"full_data.shape","21350584":"nomi.remove('Street')\nnomi.remove('Utilities')\nnomi.remove('Condition2')\nnomi.remove('RoofMatl')\nnomi.remove('Heating')","66149b48":"ordinal_map = {'Ex': 5,'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA':0}\nordmap = ['GarageQual', 'FireplaceQu', 'KitchenQual', 'HeatingQC', 'BsmtCond', \n          'BsmtQual', 'ExterCond', 'ExterQual']\n\nfor i in ordmap:\n    full_data[i] = full_data[i].map(ordinal_map)","2435d75b":"Bsmt_map = {'GLQ': 6,'ALQ': 5,'BLQ': 4,'Rec': 3,'LwQ': 2,'Unf': 1, 'NA': 0}\nbsmtmap = ['BsmtFinType2', 'BsmtFinType1']\n\nfor i in bsmtmap:\n    full_data[i] = full_data[i].map(Bsmt_map)","0b19efa8":"expose_map = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\nfull_data['BsmtExposure'] = full_data['BsmtExposure'].map(expose_map)","00a91129":"fence_map = {'GdPrv': 4,'MnPrv': 3,'GdWo': 2, 'MnWw': 1,'NA': 0}\nfull_data['Fence'] = full_data['Fence'].map(fence_map) ","9f2128d1":"sns.set_context('paper',font_scale=1.2)\nsns.set_style('darkgrid')\nsns.histplot(x='SalePrice',data=full_data,bins=30,kde=True)\nplt.show()","0db0f9df":"full_data['SalePrice'].describe()","23ae5e23":"full_data[full_data['SalePrice'] > 500000]","10a20432":"full_data = full_data.drop(full_data[full_data['SalePrice']>500000].index)","c2460289":"full_data[\"SalePrice\"] = np.log(full_data['SalePrice'])","eabf4614":"sns.set_context('paper',font_scale=1.2)\nsns.set_style('darkgrid')\nsns.histplot(x='SalePrice',data=full_data,bins=30,kde=True)\nplt.show()","0bdebbfc":"full_data = pd.get_dummies(full_data)\nprint(f'full_data dataset: {full_data.shape[0]} rows and {full_data.shape[1]} columns')","7bd7b713":"# spliting train and test datasets \nX = full_data.iloc[:1451,]\ny = X['SalePrice']\ntest = full_data.iloc[1451:,]\n\nX.drop('SalePrice',axis=1,inplace=True)\ntest.drop('SalePrice',axis=1,inplace=True)","eb3b4762":"from sklearn.preprocessing import RobustScaler\n\ncols = X.select_dtypes(np.number).columns\ntransformer = RobustScaler().fit(X[cols])\nX[cols] = transformer.transform(X[cols])\ntest[cols] = transformer.transform(test[cols])","5d0e6b84":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=21)","ebd0bb0f":"import time","5f856acb":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Instance of the model\nxgb = XGBRegressor()\n\n#list of parameters to optimize\nparam_lst = {\n    'learning_rate' : [0.01, 0.1, 0.15, 0.3, 0.5],\n    'n_estimators' : [100, 500, 1000, 2000, 3000],\n    'max_depth' : [3, 6, 9],\n    'min_child_weight' : [1, 5, 10, 20],\n    'reg_alpha' : [0.001, 0.01, 0.1],\n    'reg_lambda' : [0.001, 0.01, 0.1]\n}\n\n# Randomizedd search instance\nxgb_reg = RandomizedSearchCV(estimator = xgb, \n                             param_distributions = param_lst,\n                             n_iter = 100,\n                             scoring = 'neg_root_mean_squared_error',\n                             cv = 5)\n\n# Looking for the best parametes and timing the search\nstart = time.time()\nxgb_search = xgb_reg.fit(X_train, y_train)\nstop = time.time()\nprint(f'Tuning XGBoost hyperparameters:{stop-start:.2f} seconds')\n\nbest_param = xgb_search.best_params_\nxgb = XGBRegressor(**best_param)","bc425a23":"#####################################\n## function to calculate the mean score of cross_val\n#####################################\ndef mean_cross_val(model, X, y):\n    score = cross_val_score(model, X, y, cv=5)\n    mean = score.mean()\n    return mean\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\n\nxgb.fit(X_train, y_train)   \npreds = xgb.predict(X_val) \npreds_test_xgb = xgb.predict(test)\n\nmae_xgb = mean_absolute_error(y_val, preds)\nrmse_xgb = np.sqrt(mean_squared_error(y_val, preds))\nscore_xgb = xgb.score(X_val, y_val)\ncv_xgb = mean_cross_val(xgb, X, y)\n\nprint(f'Mean Absolute Error: {mae_xgb:.4f}')\nprint(f'Root of Mean Squared Error: {rmse_xgb:.4f}')\nprint(f'Score (R^2): {score_xgb:.4f}')\nprint(f'Mean of cross_val score: {cv_xgb:.4f}')","267c1187":"subm = np.exp(preds_test_xgb)\nsubmission = pd.DataFrame({'Id': test.index,\n                           'SalePrice': subm})\n\nsubmission.to_csv(\"submission_xgb.csv\", index=False)","0601c4ab":"subm = np.exp(preds_test_xgb)\noutput = pd.DataFrame({'Id': test.index,\n                       'SalePrice': subm})\noutput.to_csv('submission2.csv',index=False)\nprint('Ready!!')","0096dc49":"### Missing values - nominal features","45e2011e":"### Missing values - continuous features","7d985013":"### Numeric features: discrete features","05082e40":"### Categorical features: nominal variables","e5552685":"### Missing values - discrete features","f08864f9":"### Multicollinearity in Nominal variables","7fba522d":"From the results of correlation matrix between numerical features and their correlation with the target features the following ones were removed:","a33c6997":"## Scaling the data","9e545a12":"### Target feature - SalePrice","b4f25b7f":"Removing outliers from the target feature","34709740":"### Multicolinearity - numerical features","7046ade7":"# Preprocessing","f93d78ff":"### XGBoost","55cd41cd":"### Submission","b7d6df5e":"### Mapping ordinal features","c11dd121":"### Categorical features: ordinal variables","4259110c":"### Categorical features: ordinal variables","851d176c":"# Machine learning","a0ebd06e":"### Categorical features: nominal variables","0e6c3ea4":"### Numeric features: continuous variables","93a78cec":"## Univariate EDA","06a6a755":"### Correlation with target feature","9c6c74a3":"### Numeric features: continuous variables","6313f5f3":"## Correlation matrix","8dea0ffb":"# Exploratory Data Analysis","0c16571f":"### Numeric features: discrete variables","dad1e378":"Normalizing the distribution ","95951bf8":"### Missing Values - ordinal variables","7664c1a0":"## Bi-variate EDA: features vs target","c6d8a830":"### Categorical features with single classes"}}