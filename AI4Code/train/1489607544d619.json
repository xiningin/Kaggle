{"cell_type":{"9f92e6ec":"code","75fadd67":"code","8488780e":"code","33892314":"code","1baeac68":"code","3f4833d4":"code","25ede485":"code","f9070911":"code","dd41dc03":"code","a31349be":"code","ba2900de":"code","8c68b4b7":"code","451bff2c":"markdown","0dd59942":"markdown","759fbf8b":"markdown","c8e2f9f5":"markdown","a19da99e":"markdown","51c4c2d5":"markdown","a4195553":"markdown","0c6da645":"markdown","6e4b8b09":"markdown","16f26fbe":"markdown","06c24ca6":"markdown"},"source":{"9f92e6ec":"# We have used a Deep Learning Technique known as Convolutional Neural Network","75fadd67":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8488780e":"train = ImageDataGenerator(rescale=1\/255)\ntest = ImageDataGenerator(rescale=1\/255)","33892314":"train_dataset = train.flow_from_directory(\"..\/input\/for-image-classification-of-cheetah-vs-hyena\/train\/\", target_size=(200, 200), class_mode = 'binary')\ntest_dataset = test.flow_from_directory(\"..\/input\/for-image-classification-of-cheetah-vs-hyena\/validation\/\", target_size=(200, 200), class_mode = 'binary')","1baeac68":"model = keras.Sequential()","3f4833d4":"model = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(200,200,3)))\nmodel.add(keras.layers.MaxPool2D(2,2))\n\nmodel.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(keras.layers.MaxPool2D(2,2))\n\nmodel.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(keras.layers.MaxPool2D(2,2))\n\nmodel.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(keras.layers.MaxPool2D(2,2))\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(512,activation='relu'))\n\nmodel.add(keras.layers.Dense(1,activation='sigmoid'))","25ede485":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","f9070911":"\"\"\"We can train our model by calling the fit_generator() function which takes our training images as input for training and our validation images for testing.\"\"\"\nmodel.fit_generator(train_dataset, steps_per_epoch = 30, epochs = 10, validation_data = test_dataset)","dd41dc03":"# It's a good practice to save your models so you don't need to train them every time and a saved model can also be helpful during deployment.\ntf.keras.models.save_model(model, 'best_model.hdf5')","a31349be":"\"\"\"All fancy preprocessing, numbers, layers, and accuracy aside, the most effective way to test a model is to use it. Here, I found a few images that are neither from the training nor the test dataset. Let's see how or model performed:\"\"\"\ndef predict(filename):\n    img1 = image.load_img(filename, target_size=(200, 200))\n    \n    plt.imshow(img1)\n    Y = image.img_to_array(img1)\n    X = np.expand_dims(Y, axis=0)\n    val = model.predict(X)\n    print(val)\n    if val == 1:\n        plt.xlabel(\"A Hyna\")\n    elif val == 0:\n        plt.xlabel(\"A Cheetah\")","ba2900de":"# Here we just created a function that will predict the image class based on our model upon giving the image path.\npredict('..\/input\/for-image-classification-of-cheetah-vs-hyena\/train\/cheetah\/cheetah_000_resized.jpg')","8c68b4b7":"predict('..\/input\/for-image-classification-of-cheetah-vs-hyena\/train\/hyena\/hyena_000_resized.jpg')","451bff2c":"# Testing","0dd59942":"**Steps per epoch:** Denote the number of batches to be selected for one Epoch.\n\n**Epoch:** Consists of one full cycle through the training data. (Multiple steps).","759fbf8b":"Then we use the objects to call the flow_from_directory method by specifying our path to the train and test directories.\n\nThe target size we used is 200 x 200, even though our dataset images were already resized, I used this to reduce the image sizes for even faster computation.\n\nClass_mode is Binary since we have only 2 classes: Cheetah and Jaguar (0 or 1).","c8e2f9f5":"# Training","a19da99e":"**Step by Step Explanation**\n\nThe **input_shape** is 200*200 which is our image size and 3 represents colour channel RGB (since we have coloured images).\n\n**Conv2D():** Neural networks apply a filter to an input image to create a feature map that summarizes the presence of detected features or patterns in the input. In our case, there are 32, 64, 128 and 128 filters or kernels in respective layers.\n\nIf you noticed, we increase the number of filters per layer this is because as we move forward in the layers, the patterns get more complex; hence there are larger combinations of patterns to capture. So, we increase the filter size in subsequent layers to capture as many combinations as possible.\n\n**MaxPool2D():** Max pooling is a pooling operation that selects the largest element from the region of the feature map covered by the filter. In simple terms in Max pooling, we choose the maximum value within a matrix to reduce image size without losing the image information.\n\n**Flatten():** Converts the multi-dimensional image data array to a single dimensional array.\n\n**Dense():** Fully connected neural network layer where each input node is connected to each output node. We have used this layer twice one in the hidden layer with 512 neurons and then for the output layer with a single neuron and sigmoid function to make final predictions.","51c4c2d5":"ImageDataGenerator helps us load and label image datasets. We create two objects for ImageDataGenerator and also rescale the image such that their pixel values are **normalized** between 0 and 1(by dividing by 255).\n\nWe do this so that each input has a similar distribution and the model runs much faster since convergence takes a lot less time now.\n\n**Why 255?**\n\nRGB (Red, Green, Blue) are 8 bit each.\nThe range for each individual colour is 0\u2013255 (as 2\u2078 = 256 possibilities). So by dividing by 255, the 0\u2013255 range can be described with a 0.0\u20131.0 range where 0.0 means 0 (0x00) and 1.0 means 255 (0xFF).","a4195553":"# Preparing the Data\n##### We will use TensorFlow to build CNN model. First, we import all the necessary libraries:","0c6da645":"# Preprocessing","6e4b8b09":"# Saving the model","16f26fbe":"# Model Building\nIn case, you are not interested in the highly technical parts of this project I recommend you skip this section.\n![](https:\/\/miro.medium.com\/max\/696\/1*PVXecfFQKDGvy8XrQ6fWcA.jpeg)","06c24ca6":"# About the Project\n##### We have used a dataset of Cheetah and Hyena images and trained a Deep Learning model that would differentiate and classify images. Since our model is trained on images, it would try to distinguish tha animals only based on their physical attribute, which are: Their Coat, Physical Size, etc."}}