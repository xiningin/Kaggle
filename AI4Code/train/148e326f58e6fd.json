{"cell_type":{"44819ef7":"code","755646af":"code","979b24b4":"code","a51d16f9":"code","f7118abb":"code","8373159c":"code","2b6c2253":"code","10e8d1df":"code","0ccb3ac8":"code","5b6247d3":"code","cd6081dc":"code","69d37b87":"code","aad3136a":"code","1457184a":"code","4cb1de70":"code","7d93eb46":"code","015c9ff2":"code","e6250d10":"code","f9213efd":"code","4293b9f2":"code","6f3fca41":"code","8950a201":"code","67fe7d13":"markdown","c799e2b5":"markdown","effd7dfb":"markdown","997ab5c4":"markdown","7ec6b499":"markdown","943103df":"markdown","987d9a4e":"markdown","f7bac3a5":"markdown"},"source":{"44819ef7":"import numpy as np\nimport pandas as pd\nimport numba as nb\n\nfrom sklearn.utils import shuffle\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output","755646af":"df_train = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ndf_test = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","979b24b4":"X_train, y_train = df_train[df_train['label'] < 10].values[:,1:], df_train[df_train['label'] < 10].values[:,0]\nX_test, y_test = df_test[df_test['label'] < 10].values[:,1:], df_test[df_test['label'] < 10].values[:,0]","a51d16f9":"# Normalize\nX_train, X_test = X_train \/ 255., X_test \/ 255\n\n# Format (#, 1, 28, 28)\nX_train, X_test = X_train.reshape(X_train.shape[0], 1, 28, 28), X_test.reshape(X_test.shape[0], 1, 28, 28)","f7118abb":"NUM_OUTPUT = 10\nLEARNING_RATE = 0.0001\nIMG_WIDTH = 28\nIMG_DEPTH = 1\nFILTER_SIZE=5\nNUM_FILT1 = 8\nNUM_FILT2 = 8\nBATCH_SIZE = 8\nNUM_EPOCHS = 3000\nMU = 0.95\nNUM_IMAGES = int(len(X_train) \/ BATCH_SIZE)","8373159c":"@nb.jit(nopython=True)\ndef maxpool(X, f, s):\n    (l, w, w) = X.shape\n    pool = np.zeros((l, (w-f)\/\/s+1,(w-f)\/\/s+1))\n    for jj in range(0,l):\n        for i in range(0, w, s):\n            for j in range(0, w, s):\n                pool[jj,i\/\/2,j\/\/2] = np.max(X[jj,i:i+f,j:j+f])\n    return pool","2b6c2253":"@nb.jit(nopython=True)\ndef relu(x):\n    return x * (x > 0)\n\n@nb.jit(nopython=True)\ndef drelu(x):\n    return 1. * (x > 0)","10e8d1df":"def softmax_cost(out,y):\n    eout = np.exp(out, dtype=np.float)\n    probs = eout\/sum(eout)\n\n    p = sum(y*probs)\n    cost = -np.log(p)\n    return cost, probs","0ccb3ac8":"@nb.jit(nopython=True)\ndef forward(image, theta, sizes):\n    filt1, filt2, bias1, bias2, theta3, bias3 = theta\n    l, w, f, l1, l2, w1, w2 = sizes\n\n    conv1 = np.zeros((l1,w1,w1))\n    conv2 = np.zeros((l2,w2,w2))\n\n    for jj in range(0,l1):\n        for x in range(0,w1):\n            for y in range(0,w1):\n                conv1[jj,x,y] = np.sum(image[:,x:x+f,y:y+f]*filt1[jj])+bias1[jj]\n    conv1 = relu(conv1)\n\n    for jj in range(0,l2):\n        for x in range(0,w2):\n            for y in range(0,w2):\n                conv2[jj,x,y] = np.sum(conv1[:,x:x+f,y:y+f]*filt2[jj])+bias2[jj]\n    conv2 = relu(conv2)\n\n    ## Pooled layer with 2*2 size and stride 2,2\n    pooled_layer = maxpool(conv2, 2, 2)\t\n\n    fc1 = pooled_layer.reshape(((w2\/\/2)*(w2\/\/2)*l2,1))\n\n    out = theta3.dot(fc1) + bias3\n\n    return conv1, conv2, pooled_layer, fc1, out","5b6247d3":"# get the highest (index) value of the arrays\ndef get_nanargmax(conv2, sizes):\n\n    def nanargmax(a):\n        idx = np.argmax(a, axis=None)\n        multi_idx = np.unravel_index(idx, a.shape)\n        if np.isnan(a[multi_idx]):\n            nan_count = np.sum(np.isnan(a))\n            idx = np.argpartition(a, -nan_count-1, axis=None)[-nan_count-1]\n            multi_idx = np.unravel_index(idx, a.shape)\n        return multi_idx\n\n    l, w, f, l1, l2, w1, w2 = sizes\n    nanarg = np.zeros((l2, w2, w2, 2))\n\n    for jj in range(0, l2):\n        for i in range(0, w2, 2):\n            for j in range(0, w2, 2):\n                (a,b) = nanargmax(conv2[jj,i:i+2,j:j+2])\n                nanarg[jj, i, j, 0] = a\n                nanarg[jj, i, j, 1] = b\n\n    return nanarg","cd6081dc":"@nb.jit(nopython=True)\ndef init_grads(sizes):\n    l, w, f, l1, l2, w1, w2 = sizes\n    \n    dconv2 = np.zeros((l2, w2, w2))\n    dconv1 = np.zeros((l1, w1, w1))\n\n    dfilt2 = np.zeros((l2, l1,f,f))\n    dbias2 = np.zeros((l2, ))\n\n    dfilt1 = np.zeros((l1,l,f,f))\n    dbias1 = np.zeros((l1,))\n    \n    return dconv1, dconv2, dfilt1, dfilt2, dbias1, dbias2","69d37b87":"@nb.jit(nopython=True)\ndef backward(image, label, theta, delta, probs, nanarg, sizes):\n    l, w, f, l1, l2, w1, w2 = sizes\n    conv1, conv2, pooled_layer, fc1, out = delta\n    dconv1, dconv2, dfilt1, dfilt2, dbias1, dbias2 = init_grads(sizes)\n\n    dout = probs - label\n    dtheta3 = dout.dot(fc1.T)\n    dbias3 = dout\n\n    dfc1 = theta3.T.dot(dout)\n    dpool = dfc1.T.reshape((l2, w2\/\/2, w2\/\/2))\n\n    for jj in range(0, l2):\n        for i in range(0, w2, 2):\n            for j in range(0, w2, 2):\n                a = int(nanarg[jj , i, j, 0])\n                b = int(nanarg[jj , i, j, 1])\n                dconv2[jj,i+a,j+b] = dpool[jj,i\/\/2,j\/\/2]\n\n    dconv2 = dconv2 * drelu(conv2)\n\n    for jj in range(0,l2):\n        for x in range(0,w2):\n            for y in range(0,w2):\n                dfilt2[jj]+=dconv2[jj,x,y]*conv1[:,x:x+f,y:y+f]\n                dconv1[:,x:x+f,y:y+f]+=dconv2[jj,x,y]*filt2[jj]\n        dbias2[jj] = np.sum(dconv2[jj])\n\n    dconv1 = dconv1 * drelu(conv1)\n\n    for jj in range(0,l1):\n        for x in range(0,w1):\n            for y in range(0,w1):\n                dfilt1[jj]+=dconv1[jj,x,y]*image[:,x:x+f,y:y+f]\n\n        dbias1[jj] = np.sum(dconv1[jj])\n\n    return dfilt1, dfilt2, dbias1, dbias2, dtheta3, dbias3","aad3136a":"def init_grads_velocity(filt1, filt2, bias1, bias2, theta3, bias3):\n    dfilt1 = np.zeros((len(filt1), filt1[0].shape[0], filt1[0].shape[1], filt1[0].shape[2]))\n    dbias1 = np.zeros((len(filt1),))\n    v1 = np.zeros((len(filt1), filt1[0].shape[0], filt1[0].shape[1], filt1[0].shape[2]))\n    bv1 = np.zeros((len(filt1),))\n\n    dfilt2 = np.zeros((len(filt2), filt2[0].shape[0], filt2[0].shape[1], filt2[0].shape[2]))\n    dbias2 = np.zeros((len(filt2),))\n    v2 = np.zeros((len(filt2), filt2[0].shape[0], filt2[0].shape[1], filt2[0].shape[2]))\n    bv2 = np.zeros((len(filt2),))\n\n    dtheta3 = np.zeros(theta3.shape)\n    dbias3 = np.zeros(bias3.shape)\n    v3 = np.zeros(theta3.shape)\n    bv3 = np.zeros(bias3.shape)\n\n    return dfilt1, dfilt2, dtheta3, dbias1, dbias2, dbias3, v1, v2, v3, bv1, bv2, bv3","1457184a":"def batches(X, y, size):\n    batches = []\n    \n    for idx in np.array_split(np.arange(len(X)), len(X) \/ size):\n        X_batch = X[idx]\n        y_batch = y[idx]\n        batches.append((X_batch, y_batch))\n    \n    return batches","4cb1de70":"np.random.seed(3424242)\n\nscale = 1.0\nstddev = scale * np.sqrt(1.\/FILTER_SIZE*FILTER_SIZE*IMG_DEPTH)\n\nfilt1 =np.random.normal(loc = 0, scale=stddev, size=((NUM_FILT1,IMG_DEPTH,FILTER_SIZE,FILTER_SIZE)))\nbias1 = np.zeros((NUM_FILT1,))\nfilt2 =np.random.normal(loc = 0, scale=stddev, size=((NUM_FILT2,NUM_FILT1,FILTER_SIZE,FILTER_SIZE)))\nbias2 = np.zeros((NUM_FILT2,))\n\nw1 = IMG_WIDTH-FILTER_SIZE+1\nw2 = w1-FILTER_SIZE+1\n\ntheta3 = np.random.rand(NUM_OUTPUT, (w2\/\/2)*(w2\/\/2)*NUM_FILT2) * 0.01\nbias3 = np.zeros((NUM_OUTPUT,1))\n\ntheta = filt1, filt2, bias1, bias2, theta3, bias3","7d93eb46":"(l,w,w) = X_train[0].shape\n(l1,f,f) = filt2[0].shape\nl2 = len(filt2)\nw1 = w-f+1\nw2 = w1-f+1\n\nsizes = l, w, f, l1, l2, w1, w2","015c9ff2":"accuracies = []\ncosts = []","e6250d10":"for epoch in range(NUM_EPOCHS):\n\n    filt1, filt2, bias1, bias2, theta3, bias3 = theta\n    dfilt1, dfilt2, dtheta3, dbias1, dbias2, dbias3, v1, v2, v3, bv1, bv2, bv3 = init_grads_velocity(filt1, filt2, bias1, bias2, theta3, bias3)\n    \n    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n    minibatches = batches(X_train, y_train, BATCH_SIZE)\n    \n    idx = np.random.randint(0, len(minibatches))\n    X_batch, y_batch = minibatches[idx]\n\n    acc = 0\n    cost_epoch = 0\n\n    for i in range(0, BATCH_SIZE):\n\n        label = np.zeros((theta3.shape[0],1))\n        label[int(y_batch[i]),0] = 1\n\n        delta = forward(X_batch[i], theta, sizes)\n\n        cost, probs = softmax_cost(delta[-1], label)\n        if np.argmax(probs) == np.argmax(label):\n            acc += 1\n        cost_epoch += cost\n            \n        nanarg = get_nanargmax(delta[1], sizes)\n        dfilt1, dfilt2, dbias1, dbias2, dtheta3, dbias3 = backward(X_batch[i], label, theta, delta, probs, nanarg, sizes)\n\n        dfilt2 += dfilt2\n        dbias2 += dbias2\n\n        dfilt1 += dfilt1\n        dbias1 += dbias1\n\n        dtheta3 += dtheta3\n        dbias3 += dbias3\n        \n    accuracies.append(acc)\n    costs.append(cost_epoch\/BATCH_SIZE)\n\n    v1 = MU * v1 - LEARNING_RATE * dfilt1 \/ BATCH_SIZE\n    filt1 += v1\n    bv1 = MU * bv1 - LEARNING_RATE * dbias1 \/ BATCH_SIZE\n    bias1 += bv1\n\n    v2 = MU * v2 - LEARNING_RATE * dfilt2 \/ BATCH_SIZE\n    filt2 += v2\n    bv2 = MU * bv2 - LEARNING_RATE * dbias2 \/ BATCH_SIZE\n    bias2 += bv2\n\n    v3 = MU * v3 - LEARNING_RATE * dtheta3 \/ BATCH_SIZE\n    theta3 += v3\n    bv3 = MU * bv3 - LEARNING_RATE * dbias3 \/ BATCH_SIZE\n    bias3 += bv3\n\n    theta = filt1, filt2, bias1, bias2, theta3, bias3\n\n    if(epoch % 150 == 0):\n        print(\"Epoch:{0:3d}, Accuracy:{1:0.3f}, Cost:{2:3.3f}\".format(epoch, acc\/BATCH_SIZE, costs[-1][0]))","f9213efd":"costs = np.array(costs)\naccuracies = np.array(accuracies)","4293b9f2":"plt.figure(figsize=(10,10))\nplt.plot(costs, \"-b\", label=\"Cost\")\nplt.plot(accuracies, \"-r\", label=\"Accuracy\")\nplt.legend(loc=\"upper right\")\nplt.show()","6f3fca41":"def accuracy(X_test, y_test):\n    acc = 0\n    for i in range(len(X_test)):\n        delta = forward(X_test[i], theta, sizes)\n        cost, probs = softmax_cost(delta[-1], label)\n        \n        if np.argmax(probs) == y_test[i]:\n            acc += 1\n    print(\"Test accuracy:{0:2.2f}%\".format(acc\/len(X_test) * 100))","8950a201":"accuracy(X_test, y_test)","67fe7d13":"# Activation Functions","c799e2b5":"# Momentum Training","effd7dfb":"# Parameters","997ab5c4":"# Prepare Data","7ec6b499":"# Forward Propagation","943103df":"# Sign Language MNIST CNN from Scratch Numba CPU","987d9a4e":"# Backward Propagation","f7bac3a5":"# Analyze training data"}}