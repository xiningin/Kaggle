{"cell_type":{"beea584b":"code","4bff2dc8":"code","632c1918":"code","f85478ad":"code","702da738":"code","6f5f8e9f":"code","370d1c5d":"code","50f44a1e":"code","57e84426":"code","057f765e":"code","42eb9273":"code","ae6974f8":"code","8d844704":"code","d2389ccc":"code","838c4511":"code","fd541339":"code","f69d1226":"code","a4439d44":"code","15cfa2ad":"code","81affdde":"code","7467b7fe":"code","186fd1e9":"code","e117dca5":"code","f7033469":"code","5d8d8386":"code","19a0d2d4":"code","c48bd40c":"code","ac019348":"code","d056ec60":"code","cee84201":"code","dc24e0cf":"code","a6a606cb":"code","0f4e8c99":"code","1b6d638c":"markdown","4be6fd8e":"markdown","4e582491":"markdown","8ace0610":"markdown","56aa047c":"markdown","0fbd338e":"markdown","9ca3c20c":"markdown","b8c92e0b":"markdown","b3a969c6":"markdown","692838dd":"markdown","4d3677be":"markdown","ee5880a3":"markdown","18e8ab35":"markdown","68bd54fb":"markdown","e9bee072":"markdown"},"source":{"beea584b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4bff2dc8":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport cv2\n\nimport glob","632c1918":"base_path = \"..\/input\/balls-image-classification\/balls\"\n\ntrain_dir = \"..\/input\/balls-image-classification\/balls\/train\"\ntest_dir = \"..\/input\/balls-image-classification\/balls\/test\"\nval_dir = \"..\/input\/balls-image-classification\/balls\/valid\"","f85478ad":"df = pd.read_csv(\"..\/input\/balls-image-classification\/balls\/balls.csv\")","702da738":"print(f\"Total number of imgaes -- > {len(df)}\")","6f5f8e9f":"data_count = df['data set'].value_counts()","370d1c5d":"print(f\"Number of training images --> {data_count[0]}\")\nprint(f\"Number of testing images --> {data_count[1]}\")\nprint(f\"Number of validation images --> {data_count[2]}\")","50f44a1e":"plt.figure(figsize=(15, 10))\nplt.pie(x=np.array([data_count[0], data_count[1], data_count[2]]), autopct=\"%.1f%%\", explode=[0.2,0, 0], labels=[\"train\", \"test\", \"validation\"], pctdistance=0.5)\nplt.title(\"Share of train, test and validation images\", fontsize=14);","57e84426":"ball_classes = os.listdir(train_dir)","057f765e":"len(ball_classes)","42eb9273":"train_images = glob.glob(f\"{train_dir}\/*\/*.jpg\")\ntest_images = glob.glob(f\"{test_dir}\/*\/*.jpg\")\nval_images = glob.glob(f\"{val_dir}\/*\/*.jpg\")","ae6974f8":"class_dict = {}\nfor clas in ball_classes:\n    num_items = len(os.listdir(os.path.join(train_dir, clas)))\n    class_dict[clas] = num_items","8d844704":"class_dict","d2389ccc":"plt.figure(figsize=(15,8))\nplt.bar(list(class_dict.keys()), list(class_dict.values()), width=0.4,align=\"center\" )\nplt.xticks(rotation=90)\n\nplt.xlabel(\"Type of balls\")\nplt.ylabel(\"Number of balls\")\nplt.show()","838c4511":"fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i,ax in enumerate(axes.flat):\n    images = os.listdir(os.path.join(train_dir, ball_classes[i]))\n    img = cv2.imread(os.path.join(train_dir, ball_classes[i], images[i]))\n    img = cv2.resize(img, (512,512))\n    ax.imshow(img)\n    ax.set_title(ball_classes[i])\nfig.tight_layout()    \nplt.show()","fd541339":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\nval_datagen = ImageDataGenerator(rescale = 1.\/255.,)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255.,)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, batch_size=20, class_mode='categorical', target_size = (220, 220))\nvalidation_generator = val_datagen.flow_from_directory(val_dir, batch_size=20, class_mode = 'categorical', target_size=(220, 220))\ntest_generator = test_datagen.flow_from_directory(test_dir,shuffle=False, batch_size=20, class_mode = 'categorical', target_size=(220, 220))","f69d1226":"input_shape = (220, 220, 3)","a4439d44":"# define the model\nbase_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=input_shape, include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n    \nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(512, activation = 'relu'))\n# model.add(Dropout(0.2))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\n# model.add(Dropout(0.2))\nmodel.add(Dense(24, activation='softmax'))\nmodel.summary()","15cfa2ad":"model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n\n# callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)\n\nhistory = model.fit(train_generator, validation_data=validation_generator, steps_per_epoch = 100, epochs=30)","81affdde":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","7467b7fe":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","186fd1e9":"pred = model.predict(test_generator)","e117dca5":"pred","f7033469":"y_pred = np.argmax(pred, axis=1)","5d8d8386":"y_pred_class = dict((v,k) for k,v in test_generator.class_indices.items())\n    ","19a0d2d4":"y_pred_class","c48bd40c":"y_pred","ac019348":"y_pred = list(map(lambda x: y_pred_class[x], y_pred))","d056ec60":"y_pred","cee84201":"y_true = test_generator.classes","dc24e0cf":"y_true = list(map(lambda x: y_pred_class[x], y_true))","a6a606cb":"print(classification_report(y_true, y_pred))","0f4e8c99":"results = model.evaluate(test_generator)","1b6d638c":"# Import necessary libraries","4be6fd8e":"<p style=\"font-size: 2rem\"> Number of training images available for each class: <\/p>","4e582491":"<p style=\"font-size: 1.5rem\"> Please comment, if you have any suggestions.<\/p>\n<p style=\"font-size: 1.5rem\"> Please UPVOTE, if you found this notebook helpful <\/p>\n<p style=\"font-size: 2rem\"> Thank you<\/p>","8ace0610":"# Model Training","56aa047c":"# Model creation","0fbd338e":"# Metrics","9ca3c20c":"# Accuracy = 95%","b8c92e0b":"<p style=\"font-size: 1.5rem\">Total number of images<\/p>","b3a969c6":"<p style=\"font-size: 2rem\"> There are 24 classes of balls present in the dataset<\/p>","692838dd":"# EDA and data visualization","4d3677be":"<p style=\"font-size: 1.5rem\">Number of train, test and validation images<\/p>","ee5880a3":"# Create image generators","18e8ab35":"<p style=\"font-size: 1.5rem\"> <em>Paint balls<\/em> have the least number of images whereas <em>cannon balls<\/em> the highest <\/p>","68bd54fb":"<p style=\"font-size: 2rem\">Training images comprise 92.3% of the total images<\/p>","e9bee072":"## Define the paths for train, test and validation datasets"}}