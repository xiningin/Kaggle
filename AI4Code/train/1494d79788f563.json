{"cell_type":{"c27a9cd1":"code","f56de6a2":"code","40c001f9":"code","de99a844":"code","78e22b68":"code","91cfbf6c":"code","a5c4b614":"code","a2c37418":"code","104c0b13":"code","6336a01d":"code","ca8d5de8":"code","5d72b243":"code","13fe4690":"code","7aa277bc":"code","7a34f4c1":"code","1c99ce8a":"code","518df7a8":"code","b67e1784":"code","38e317d2":"code","a4821e90":"code","d6f4e559":"code","0dd6157e":"code","ed13145f":"code","b5899426":"code","f1d537ca":"code","ed406089":"markdown"},"source":{"c27a9cd1":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\n\nimport os\nimport path","f56de6a2":"import math\n\ndef sigmoid(x):\n  return 1 \/ (1 + math.exp(-x))","40c001f9":"oof_values = pd.read_csv('..\/input\/swim-classify\/oof_df.csv') \n#oof_values","de99a844":"oof_values['preds'] = oof_values['preds'].apply(sigmoid)\noof_values['preds'] = oof_values['preds'] * 100","78e22b68":"cv_score = metrics.mean_squared_error(oof_values['Pawpularity'], oof_values['preds'], squared = False)\ncv_score","91cfbf6c":"err = []\nfor row in zip(oof_values['Pawpularity'], oof_values['preds']):\n    err.append(metrics.mean_squared_error([row[0]], [row[1]], squared = False))\n    \noof_values['error'] = err\n\ndisplay(oof_values.head())","a5c4b614":"def make_ranges(value):\n    if value <= 10:\n        return 1\n    elif value > 10 and value <= 20:\n        return 2\n    elif value > 20 and value <= 30:\n        return 3\n    elif value > 30 and value <= 40:\n        return 4\n    elif value > 40 and value <= 50:\n        return 5\n    elif value > 50 and value <= 60:\n        return 6\n    elif value > 60 and value <= 70:\n        return 7\n    elif value > 70 and value <= 80:\n        return 8\n    elif value > 80 and value <= 90:\n        return 9\n    elif value > 90:\n        return 10\n\noof_values['range'] = oof_values['Pawpularity'].apply(make_ranges)","a2c37418":"sns.catplot(x = 'range', y = 'error', data = oof_values)","104c0b13":"for i in range(1, 11):\n    print(oof_values['error'][oof_values.range == i].median())\n#seems to predict well the ranges of 20 - 50 Pawpularity","6336a01d":"MAIN_PATH = '..\/input\/stanford-dogs-dataset\/images\/Images'\nmain_categories = list(os.listdir(MAIN_PATH))","ca8d5de8":"#len(os.listdir(os.path.join(MAIN_PATH,main_categories[0])))\ntotal_images = 0\nfor dir in os.listdir(MAIN_PATH):\n    total_images += len(os.listdir(os.path.join(MAIN_PATH,dir)))\nprint(total_images)","5d72b243":"import sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nimport random\nimport cv2\npd.set_option('display.max_columns', None)\n\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","13fe4690":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers = 4\n    size = 224\n    batch_size = 10\n    model_name = 'swin_base_patch4_window7_224'\n    seed = 42\n    target_size = 1\n    target_col = 'Pawpularity'","7aa277bc":"def get_test_transforms(DIM = CFG.size):\n    return albumentations.Compose(\n        [\n          albumentations.Resize(DIM,DIM),\n          albumentations.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n          ),\n          ToTensorV2(p=1.0)\n        ]\n    )","7a34f4c1":"class CuteDataset(Dataset):\n    def __init__(self, images_filepaths, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        label = torch.tensor(self.targets[idx]).float()\n        return image, label","1c99ce8a":"class PetNet(nn.Module):\n    def __init__(self, model_name = CFG.model_name, out_features = 1, input_channels = 3, pretrained = False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained = pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n                  nn.Linear(128, 64),\n                  nn.SiLU(),\n                  nn.Linear(64, 1)\n        )\n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, image):\n        image_embeds = self.model(image)\n        x = self.dropout(image_embeds)\n        z = self.fc(x)\n        return z","518df7a8":"#full set of images\n\n# MAIN_PATH = '..\/input\/stanford-dogs-dataset\/images\/Images'\n# test_images = []\n# for dir in os.listdir(MAIN_PATH):\n#     test_images += os.listdir(os.path.join(MAIN_PATH,dir))","b67e1784":"all_dirs = os.listdir(MAIN_PATH)\nfirst_dir = all_dirs[0]\ntest_images = []\n\ntest_images += os.listdir(os.path.join(MAIN_PATH,first_dir))","38e317d2":"all_test_images = []\nfor dir in os.listdir(MAIN_PATH):\n    for image in os.listdir(os.path.join(MAIN_PATH,dir)):\n        added_path = os.path.join(MAIN_PATH, dir, image)\n        all_test_images.append(str(added_path))\n#all_test_images","a4821e90":"# def add_paths(input):\n#     return os.path.join(MAIN_PATH, first_dir, input)","d6f4e559":"test_df = pd.DataFrame()\ntest_df['image_path'] = all_test_images\n#test_df['image_path'] = test_df['image_path'].apply(lambda x : add_paths(x))\ndisplay(test_df.head(5))","0dd6157e":"models_dir = '..\/input\/swim-classify'\npredicted_labels = None\nfor model_name in glob.glob(models_dir + '\/*.pth'):\n    model = PetNet()\n    state = torch.load(model_name, \n                       map_location=torch.device('cpu'))['model']\n    model.load_state_dict(state)\n    model = model.to(device)\n    model.eval()\n    \n    test_dataset = CuteDataset(\n        images_filepaths = test_df['image_path'].values,\n        targets = [0] * len(test_df['image_path'].values),\n        transform = get_test_transforms()\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size = CFG.batch_size,\n        shuffle=False, num_workers = CFG.num_workers,\n        pin_memory=True\n    )\n    \n    temp_preds = None\n    \n    with torch.no_grad():\n        for (images, target) in tqdm(test_loader, desc = f'Predicting.'):\n            images = images.to(device)\n            predictions = torch.sigmoid(model(images)).to('cpu').numpy()*100\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    if predicted_labels is None:\n        predicted_labels = temp_preds\n    else:\n        predicted_labels += temp_preds\n        \npredicted_labels \/= (len(glob.glob(models_dir + '\/*.pth')))","ed13145f":"test_df['ext_predictions'] = predicted_labels\ntest_df.head()","b5899426":"plt.hist(test_df['ext_predictions'])","f1d537ca":"test_df.to_csv('external_stanforddata.csv', index = False)","ed406089":"# Inference on external data"}}