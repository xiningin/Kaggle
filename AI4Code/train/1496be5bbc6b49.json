{"cell_type":{"86debb6c":"code","1d97cbd1":"code","3e6864d5":"code","20636961":"code","6b7b0e66":"code","8ec0cc87":"code","f707c0fd":"code","44ac5a70":"code","d12f6ca9":"code","4b298f5e":"code","d3c32605":"code","db8a359e":"code","8c57c914":"code","f52ba239":"markdown","1ec9b065":"markdown","ef31efd9":"markdown","bfd7e068":"markdown","2afe0e68":"markdown","02b120f5":"markdown","254fe227":"markdown","6905c164":"markdown","8e729b7a":"markdown","214afe35":"markdown","067cc774":"markdown","2022a5ae":"markdown","4a01ccdd":"markdown","5649d3ac":"markdown","d2fd5697":"markdown"},"source":{"86debb6c":"import math\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.neural_network import MLPRegressor\nfrom mxnet import autograd, gluon, np, npx\nfrom mxnet import init\nfrom mxnet.gluon import nn\nimport mxnet as mx\n\n!pip install -qq d2l==0.16.3\nfrom d2l import mxnet as d2l\n\nfrom IPython.display import clear_output\n\nnpx.set_np()","1d97cbd1":"path = '..\/input\/avocado-prices\/avocado.csv'\ndf = pd.read_csv(path)\n\ndf.set_index('Date', inplace=True)\ndf.sort_values(by='Date', inplace=True)\n\ndf.head()","3e6864d5":"average_prices = np.array(df['AveragePrice'].values)\n\nX = np.arange(len(average_prices)).astype(np.float32)\ny = average_prices.astype(np.float32)\n\ny \/= y.max()","20636961":"plt.figure(figsize=(11,8))\nplt.plot(X[:50], y[:50], 'b-')","6b7b0e66":"n_train = 50\nn_test = 50\n\nx_train = X[:n_train]\n\n# Training outputs\ny_train = y[:n_train]\n\n# Testing examples\nx_test = np.arange(0, 50, 1)\ny_truth = y[x_test]","8ec0cc87":"def plot_kernel_reg(y_hat):\n    d2l.plot(x_test, [y_truth, y_hat], 'x', 'y', legend=['Truth', 'Pred'],\n             xlim=[0, 50], ylim=[0, 1], figsize=(8,8))\n    d2l.plt.plot(x_train, y_train, 'o', alpha=0.5);","f707c0fd":"class NWKernelRegression(nn.Block):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.w = self.params.get('w', shape=(1,))\n\n    def forward(self, queries, keys, values):\n        # Shape of the output `queries` and `attention_weights`:\n        # (no. of queries, no. of key-value pairs)\n        queries = queries.repeat(keys.shape[1]).reshape((-1, keys.shape[1]))\n        self.attention_weights = npx.softmax(\n            -((queries - keys) * self.w.data())**2 \/ 2)\n        # Shape of `values`: (no. of queries, no. of key-value pairs)\n        return npx.batch_dot(np.expand_dims(self.attention_weights, 1),\n                             np.expand_dims(values, -1)).reshape(-1)","44ac5a70":"net = NWKernelRegression()\nnet.initialize(init=init.Normal(sigma=0.5), force_reinit=True)\n\nkeys = np.tile(x_train, (n_test, 1))\nvalues = np.tile(y_train, (n_test, 1))\ny_hat = net(x_test, keys, values)\nplot_kernel_reg(y_hat)","d12f6ca9":"n_train = len(x_train)\n\nkeys = np.tile(x_train, (n_test, 1))\nvalues = np.tile(y_train, (n_test, 1))","4b298f5e":"loss = gluon.loss.L2Loss()\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})","d3c32605":"losses = []\nfor epoch in range(30):\n    with autograd.record():\n        l = loss(net(x_train, keys, values), y_train)\n    l.backward()\n    losses.append(l.sum())\n    trainer.step(1)\n    clear_output(wait=True)\n    print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')","db8a359e":"_ = plt.figure(figsize=(8,8))\n_ = plt.title(\"Train Losses\")\n_ = plt.plot(losses)\nplt.show()","8c57c914":"keys = np.tile(x_train, (n_test, 1))\nvalues = np.tile(y_train, (n_test, 1))\ny_hat = net(x_test, keys, values)\nplot_kernel_reg(y_hat)","f52ba239":"## Intial Prediction","1ec9b065":"<h1 id=\"analysis\" style=\"color:#d48100; background:#dadde4; border:0.5px dotted #9bbc5c;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","ef31efd9":"## Load Data","bfd7e068":"## Features Engineering","2afe0e68":"## Training","02b120f5":"<h1 id=\"train\" style=\"color:#d48100; background:#dadde4; border:0.5px dotted #9bbc5c;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#train\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","254fe227":"Goal of the notebook is to use nonparametric Nadaraya-Watson Kernel Regression in order to predict the prices of the avocados.\n\n![nwk.png](attachment:0727ac29-b7c9-4c84-86bd-8ff1e178e34f.png)","6905c164":"<h1 id=\"dataset\" style=\"color:#d48100; background:#dadde4; border:0.5px dotted #9bbc5c;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","8e729b7a":"<h1 id=\"goal\" style=\"color:#d48100; background:#dadde4; border:0.5px dotted #9bbc5c;\"> \n    <center>Goal\n        <a class=\"anchor-link\" href=\"#goal\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","214afe35":"## Split Training\/Testing","067cc774":"## Predictions","2022a5ae":"## Loss","4a01ccdd":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/30292\/38613\/ab6171de10588e40148aed91ff39e2e9\/dataset-cover.jpg\" \/>\n<\/div>","5649d3ac":"## Model","d2fd5697":"## Creation of the tiles"}}