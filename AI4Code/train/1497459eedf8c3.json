{"cell_type":{"ae1ec2f6":"code","6fea7165":"code","f7a4b5b9":"code","8c61eedc":"code","f45224ad":"code","4c99fee9":"code","edea821d":"code","6b2f42c5":"code","eb6ee72b":"code","86c24d5b":"code","ca86e660":"code","aaf11fce":"code","2ae9108c":"code","bb566723":"code","1a1ed306":"code","072440ae":"markdown","747acc89":"markdown","e4390144":"markdown","755ef04e":"markdown","1493fe32":"markdown","a537079e":"markdown","6dc31f1a":"markdown","5b894997":"markdown"},"source":{"ae1ec2f6":"#-------------------------------------------------------------------------------\n# Program Name:        Deep Convolutional Neural Network (DCNN) for building mapping\n# Purpose:     Test DCNN on mapping building footprint\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# Input data files are available in the read-only \"..\/input\/\" directory\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# Version:     0.1 \n#              Functionalities:\n#              1. Loading data;\n#              2. Preparing training and testing sets;\n#              3. Setting up experiment, including model configuration and training session;\n#              4. Predicting.\n\n# Author:      Jiong (Jon) Wang\n#\n# Created:     24\/08\/2020\n# Copyright:   (c) JonWang 2020\n# Licence:     <your licence>\n#-------------------------------------------------------------------------------\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, model_from_json, load_model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    UpSampling2D,\n    MaxPooling2D,\n    Input,\n    Conv2DTranspose,\n    UpSampling2D,\n    Flatten,\n    BatchNormalization,\n    Activation,\n    Add,\n    Concatenate\n)\nfrom tensorflow.keras.layers import RepeatVector, Reshape\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.applications import MobileNetV2, ResNet50V2, ResNet50\nfrom imgaug import augmenters as iaa\nfrom scipy import interpolate\nfrom osgeo import gdal_array\nfrom pathlib import Path\nfrom functools import partial\nfrom sklearn.metrics import jaccard_score\nimport pandas as pd\nimport joblib, json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport os\nimport tensorflow as tf\n!pip install imagecorruptions","6fea7165":"#for dirname, _, filenames in os.walk('\/kaggle\/input\/building'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n        \nprint('\\nUsing tensorflow version %s' % (tf.__version__))","f7a4b5b9":"# load rasters: base image along with its label\n# Stack base image and label into a list of array\ndef load_rasters(path, subUL, band_ind):  # Subset from original raster with extent and upperleft coord\n    \"\"\"Load training data pairs (two high resolution images and two low resolution images)\"\"\"\n    file_list = path  # List image name\n    assert len(file_list) == 2\n\n    # Ensure the order of the list: base image first !!\n    for file in file_list:  # Organize file list\n        img_name = str(file)\n        if 'image' in img_name:\n            base = file\n        elif 'label' in img_name:\n            label = file\n    file_list = [base, label]\n    \n    stack = []  # Stack base and label together into a 3D array\n    for file in file_list:\n        if 'image' in str(file):\n            data = gdal_array.LoadFile(str(file), xoff=subUL[0], yoff=subUL[1]) #.astype(np.int),ysize=extent[1],xsize=extent[0]\n            print(data.shape)\n            data = data[tuple(band_ind),:,:]  # Worldview image with 3rd dimension at first\n            data = np.transpose(data,(1,2,0))  # Transpose 3rd to last \n            stack.append(data)\n        else:\n            data = gdal_array.LoadFile(str(file), xoff=subUL[0], yoff=subUL[1]) #.astype(np.int),xsize=extent[0],ysize=extent[1]\n            if len(data.shape)==3:\n                data = data[0,:,:]\n            if np.max(data)>200:\n                data = data\/255\n            data = data[:,:,np.newaxis]\n            print(data.shape)\n            stack.append(data)\n#        image = Image.fromarray(data)\n#        data = nan_remover(data)\n#        setattr(image, 'filename', file)\n    # Ensure the size of base and label is are consistent\n    assert stack[0].shape[0] == stack[-1].shape[0]\n    assert stack[0].shape[1] == stack[-1].shape[1]\n    return stack[:-1], stack[-1]\n\n\n# Clean the NaN values\ndef nan_remover(array):\n    x = np.arange(0, array.shape[1])\n    y = np.arange(0, array.shape[0])\n    # Masking invalid values\n    array = np.ma.masked_invalid(array)\n    xx, yy = np.meshgrid(x, y)\n    # Getting only the valid values\n    x1 = xx[~array.mask]\n    y1 = yy[~array.mask]\n    newarr = array[~array.mask]\n    array_interp = interpolate.griddata((x1, y1), newarr.ravel(),\n                              (xx, yy), method='nearest')\n    # Clean the edge\n    bad_indexes = np.isnan(array_interp)\n    good_indexes = np.logical_not(bad_indexes)\n    good_data = array_interp[good_indexes]\n    interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)\n    array_interp[bad_indexes] = interpolated\n    return array_interp","8c61eedc":"# Sample patches from an image band\/layer\n# Stride controls the overlap of patches\ndef gen_patches(image, size, stride):\n    \"\"\"Segment input images into patches\"\"\"\n    if not isinstance(size, tuple):  # Ensure format is tuple\n        size = (size, size)\n    if stride is None:\n        stride = size\n    elif not isinstance(stride, tuple):\n        stride = (stride, stride)\n    # Columns in priority\n    for i in range(0, image.shape[0] - size[0] + 1, stride[0]):  # One patch every stride\n        for j in range(0, image.shape[1] - size[1] + 1, stride[1]):\n            yield image[i:i + size[0], j:j + size[1], :]  # If Pillow Image is used: image.crop([i, j, i + size[0], j + size[1]])\n\n\n# Advanced version of patch sampling\n# Sample patches at target areas with criteria, such as label size\ndef gen_patches_ctrl():  # With controlled position\n    \n    return None\n\n\n# Generate patches for all layers\/bands in stack\ndef stack_to_patches(stack, size, stride, patches):\n#    assert len(stack) == 4\n    for i in range(len(stack)):  # Loop over the layers\/bands in the stack\n        # If Pillow Image: img_to_array(img)\n        patches[i] += [img for img in gen_patches(stack[i], size, stride)]\n\n\n# Arrange training and validation sets from the patches\ndef load_train_set(data_dir, subUL, band_ind, size, stride):\n    # Load image data from training folder\n    patches = [[] for _ in range(2)]  # Empty list to store patches for each layer\/band in stack\n    \n    \"\"\"\n    # Original read-in from folders\n    image_list = [name for name in Path(data_dir\/'train\/image').glob('*.tif')]  # Loop over all images\n    label_list = [name for name in Path(data_dir\/'train\/label').glob('*.tif')]  # Loop over all labels\n    all_list = {'image':image_list,'label':label_list}\n    df = pd.DataFrame(all_list, columns=['image','label'])\n    \n    for ind, row in df.iterrows():  # Loop over names of all image, label pairs\n        print('loading image pairs from {} and {}'.format(row['image'], row['label']))\n        train_path = [row['image'], row['label']]\n        stack = load_rasters(train_path, subUL, band_ind)\n        stack = [*stack[0], stack[1]]\n        # subset samples into patches\n        stack_to_patches(stack, size, stride, patches)\n    \"\"\"\n    \n    # Original read-in from folders\n    with open(data_dir\/'train\/train_data.db', 'rb') as fo:  \n        stacks = joblib.load(fo)\n        \n    print('loading image pairs from prepared stacks')\n    for stack in stacks:  # Loop over names of all image, label pairs\n        if np.max(stack[1])>250:\n            stack = [*stack[0], stack[1]\/255]\n        else:\n            stack = [*stack[0], stack[1]]\n            # subset samples into patches\n        stack_to_patches(stack, size, stride, patches)\n    del stacks\n            \n    # Split patches into training and validation sets        \n    patch_train = [[] for _ in range(2)]\n    patch_val = [[] for _ in range(2)]\n    for i in range(2):\n        patch_train[i] = np.stack(patches[i][:int(len(patches[i])*0.7)])\n        patch_val[i] = np.stack(patches[i][int(len(patches[i])*0.7):])\n    # Return 4-dimensional array (number, height, width, channel)\n    return patch_train[:-1], patch_train[-1], patch_val[:-1], patch_val[-1]\n\n\n# Arrange test set by using another set of raster input\ndef load_test_set(stack, block_size):\n    assert len(stack) == 2    \n    stack = [*stack[0], stack[1]]  # Update stack by split tuple into list\n    patches = [[] for _ in range(len(stack))]  # Stack length already changed\n    stack_to_patches(stack, size=block_size, stride=None, patches=patches)\n\n    for i in range(len(stack)):\n        patches[i] = np.stack(patches[i])\n    return patches[:-1], patches[-1]","f45224ad":"# Jaccard index realized as intersection over union (iou)\ndef mean_iou(y_true, y_pred):\n    # Consider prediction greater than 0.5\n    y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold\n    inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)\n    union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter\n    return K.mean((inter + K.epsilon()) \/ (union + K.epsilon()))\n\n\n# Covariance\ndef cov(y_true, y_pred):\n    return K.mean((y_true - K.mean(y_true)) * K.transpose((y_pred - K.mean(y_pred))))\n\n\n# Correlation\ndef r2(y_true, y_pred):\n    # mean calls tensor property instead of ndarray\n    tf_true = y_true\n    if not isinstance(y_true, tf.Tensor):\n        tf_true = tf.convert_to_tensor(y_true)\n    res = K.sum(K.square(y_true - y_pred))\n    tot = K.sum(K.square(y_true - K.mean(tf_true)))\n    return 1 - res \/ (tot + K.epsilon())\n\n\n# Signal-to-noise ratio\ndef psnr(y_true, y_pred, data_range=50):\n    #Peak signal-to-noise ratio averaged over samples and channels\n    mse = K.mean(K.square(y_true - y_pred), axis=(-3, -2))\n    return K.mean(20 * K.log(data_range \/ K.sqrt(mse)) \/ np.log(10))\n\n\n# structural similarity measurement system\ndef ssim(y_true, y_pred, data_range=50):\n    \"\"\"structural similarity measurement system.\"\"\"\n    K1 = 0.01\n    K2 = 0.03\n\n    mu_x = K.mean(y_pred)\n    mu_y = K.mean(y_true)\n\n    sig_x = K.std(y_pred)\n    sig_y = K.std(y_true)\n    sig_xy = cov(y_true, y_pred)\n\n    L = data_range\n    C1 = (K1 * L) ** 2\n    C2 = (K2 * L) ** 2\n\n    return ((2 * mu_x * mu_y + C1) * (2 * sig_xy * C2) \/\n            (mu_x ** 2 + mu_y ** 2 + C1) * (sig_x ** 2 + sig_y ** 2 + C2))\n\n'''\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) \/ (union + smooth), axis=0)\n'''\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","4c99fee9":"# Visualize model architecture\nimport tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2, ResNet50V2, ResNet101\nmodel = ResNet50V2(input_shape=(64,64,3), weights=\"imagenet\", include_top=False)  #, alpha=1.3)\ntf.keras.utils.plot_model(model, show_shapes=True)\n#model.summary()","edea821d":"# UNet with residual blocks V2\ndef ResUNet(img, n_class=2, activation='relu', batch_norm=True, final_activation='softmax'):\n    \"\"\"\n    Build UNet model with ResBlock.\n    Args:\n        filter_root (int): Number of filters to start with in first convolution.\n        depth (int): How deep to go in UNet i.e. how many down and up sampling you want to do in the model. \n                    Filter root and image size should be multiple of 2^depth.\n        n_class (int, optional): How many classes in the output layer. Defaults to 2.\n        input_size (tuple, optional): Input image size. Defaults to (256, 256, 1).\n        activation (str, optional): activation to use in each convolution. Defaults to 'relu'.\n        batch_norm (bool, optional): To use Batch normaliztion or not. Defaults to True.\n        final_activation (str, optional): activation for output layer. Defaults to 'softmax'.\n    Returns:\n        obj: keras model object\n    \"\"\"\n    filter_root, depth = 32, 5\n    inputs = Input(shape=img.shape[-3:])\n    input_len = 3\n    x = inputs\n    # Dictionary for long connections\n    long_connection_store = {}\n\n    if input_len == 3:\n        Conv = Conv2D\n        MaxPooling = MaxPooling2D\n        UpSampling = UpSampling2D\n    elif input_len == 4:\n        Conv = Conv3D\n        MaxPooling = MaxPooling3D\n        UpSampling = UpSampling3D\n\n    # Down sampling\n    for i in range(depth):\n        out_channel = 2**i * filter_root\n\n        # Residual\/Skip connection\n        res = Conv(out_channel, kernel_size=1, padding='same', use_bias=False, name=\"Identity{}_1\".format(i))(x)\n\n        # First Conv Block with Conv, BN and activation\n        conv1 = Conv(out_channel, kernel_size=3, padding='same', name=\"Conv{}_1\".format(i))(x)\n        if batch_norm:\n            conv1 = BatchNormalization(name=\"BN{}_1\".format(i))(conv1)\n        act1 = Activation(activation, name=\"Act{}_1\".format(i))(conv1)\n\n        # Second Conv block with Conv and BN only\n        conv2 = Conv(out_channel, kernel_size=3, padding='same', name=\"Conv{}_2\".format(i))(act1)\n        if batch_norm:\n            conv2 = BatchNormalization(name=\"BN{}_2\".format(i))(conv2)\n\n        resconnection = Add(name=\"Add{}_1\".format(i))([res, conv2])\n\n        act2 = Activation(activation, name=\"Act{}_2\".format(i))(resconnection)\n\n        # Max pooling\n        if i < depth - 1:\n            long_connection_store[str(i)] = act2\n            x = MaxPooling(padding='same', name=\"MaxPooling{}_1\".format(i))(act2)\n        else:\n            x = act2\n\n    # Upsampling\n    for i in range(depth - 2, -1, -1):\n        out_channel = 2**(i) * filter_root\n\n        # long connection from down sampling path.\n        long_connection = long_connection_store[str(i)]\n\n        up1 = UpSampling(name=\"UpSampling{}_1\".format(i))(x)\n        up_conv1 = Conv(out_channel, 2, activation='relu', padding='same', name=\"upConv{}_1\".format(i))(up1)\n\n        #  Concatenate.\n        up_conc = Concatenate(axis=-1, name=\"upConcatenate{}_1\".format(i))([up_conv1, long_connection])\n\n        #  Convolutions\n        up_conv2 = Conv(out_channel, 3, padding='same', name=\"upConv{}_1\".format(i))(up_conc)\n        if batch_norm:\n            up_conv2 = BatchNormalization(name=\"upBN{}_1\".format(i))(up_conv2)\n        up_act1 = Activation(activation, name=\"upAct{}_1\".format(i))(up_conv2)\n\n        up_conv2 = Conv(out_channel, 3, padding='same', name=\"upConv{}_2\".format(i))(up_act1)\n        if batch_norm:\n            up_conv2 = BatchNormalization(name=\"upBN{}_2\".format(i))(up_conv2)\n\n        # Residual\/Skip connection\n        res = Conv(out_channel, kernel_size=1, padding='same', use_bias=False, name=\"upIdentity{}_1\".format(i))(up_conc)\n\n        resconnection = Add(name=\"upAdd{}_1\".format(i))([res, up_conv2])\n\n        x = Activation(activation, name=\"upAct{}_2\".format(i))(resconnection)\n\n    # Final convolution\n    output = Conv(n_class, 1, padding='same', activation=final_activation, name='output')(x)\n    model = Model(inputs, outputs=output, name='ResUNet')\n    return model","6b2f42c5":"# UNet with residual blocks V2\ndef bn_act(x, act=True):\n    x = BatchNormalization()(x)\n    if act == True:\n        x = Activation(\"relu\")(x)\n    return x\n\ndef conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = bn_act(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv\n\ndef stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    \n    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = Add()([conv, shortcut])\n    return output\n\ndef residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n    \n    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = Add()([shortcut, res])\n    return output\n\ndef upsample_concat_block(x, xskip):\n    u = UpSampling2D((2, 2))(x)\n    c = Concatenate()([u, xskip])\n    return c\n\ndef ResUNetV2(img):\n    f = [16, 32, 64, 128, 256]\n    inputs = Input(shape=img.shape[-3:])\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e5, f[4], strides=1)\n    b1 = conv_block(b0, f[4], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e4)\n    d1 = residual_block(u1, f[4])\n    \n    u2 = upsample_concat_block(d1, e3)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e2)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e1)\n    d4 = residual_block(u4, f[1])\n    \n    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n    model = Model(inputs, outputs)\n    return model","eb6ee72b":"#Resnet50 encoder for UNet\ndef res_u(img):\n    inputs = Input(shape=img.shape[-3:], name=\"input_image\")\n    \n    encoder = ResNet50(input_tensor=inputs, weights=\"imagenet\", include_top=False, pooling=None)\n    \n    #encoder.trainable=False\n    for l in encoder.layers:\n        l.trainable = True\n        \n    skip_connection_names = [\"input_image\", \"conv1_relu\", \"conv2_block3_out\", \n                             \"conv3_block4_out\", \"conv4_block6_out\"]\n    encoder_output = encoder.get_layer(\"conv5_block3_out\").output  # \"post_relu\"\n        \n    #### ResNet50V2\n    \"\"\"\n    skip_connection_names = [\"input_image\", \"conv1_conv\", \"conv2_block1_preact_relu\", \n                             \"conv3_block1_preact_relu\", \"conv4_block1_preact_relu\"]\n    encoder_output = encoder.get_layer(\"conv5_block1_preact_relu\").output  # \"post_relu\"\n    \"\"\"\n    \n    f = [3, 64, 256, 512, 1024]\n    x = encoder_output\n    for i in range(1, len(skip_connection_names)+1, 1):\n        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n        x = UpSampling2D((2, 2))(x)\n        x = Concatenate()([x, x_skip])\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs, x)\n    return model","86c24d5b":"# MobileNetV2 Encoder for U-net\ndef m_u_net(img):\n    inputs = Input(shape=img.shape[-3:], name=\"input_image\")\n    \n    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=1.3)  # weights=\"imagenet\",\n    #encoder.trainable=False\n    skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\n    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n    \n    f = [16, 32, 48, 64]\n    x = encoder_output\n    for i in range(1, len(skip_connection_names)+1, 1):\n        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n        x = UpSampling2D((2, 2))(x)\n        x = Concatenate()([x, x_skip])\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs, x)\n    return model\n\n# U-net \ndef u_net(img):\n    inputs = Input(shape=img.shape[-3:])\n    conv1_1 = Conv2D(16, (3, 3), padding='same')(inputs)\n    bn1_1 = BatchNormalization(axis=3)(conv1_1)\n    relu1_1 = Activation('relu')(bn1_1)\n    conv1_2 = Conv2D(16, (3, 3), padding='same')(relu1_1)\n    bn1_2 = BatchNormalization(axis=3)(conv1_2)\n    relu1_2 = Activation('relu')(bn1_2)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(relu1_2)\n    \n    conv2_1 = Conv2D(32, (3, 3), padding='same')(pool1)\n    bn2_1 = BatchNormalization(axis=3)(conv2_1)\n    relu2_1 = Activation('relu')(bn2_1)\n    conv2_2 = Conv2D(32, (3, 3), padding='same')(relu2_1)\n    bn2_2 = BatchNormalization(axis=3)(conv2_2)\n    relu2_2 = Activation('relu')(bn2_2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(relu2_2)\n    \n    conv3_1 = Conv2D(64, (3, 3), padding='same')(pool2)\n    bn3_1 = BatchNormalization(axis=3)(conv3_1)\n    relu3_1 = Activation('relu')(bn3_1)\n    conv3_2 = Conv2D(64, (3, 3), padding='same')(relu3_1)\n    bn3_2 = BatchNormalization(axis=3)(conv3_2)\n    relu3_2 = Activation('relu')(bn3_2)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(relu3_2)\n    \n    conv4_1 = Conv2D(128, (3, 3), padding='same')(pool3)\n    bn4_1 = BatchNormalization(axis=3)(conv4_1)\n    relu4_1 = Activation('relu')(bn4_1)\n    conv4_2 = Conv2D(128, (3, 3), padding='same')(relu4_1)\n    bn4_2 = BatchNormalization(axis=3)(conv4_2)\n    relu4_2 = Activation('relu')(bn4_2)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(relu4_2)\n    \n    conv5_1 = Conv2D(256, (3, 3), padding='same')(pool4)\n    bn5_1 = BatchNormalization(axis=3)(conv5_1)\n    relu5_1 = Activation('relu')(bn5_1)\n    conv5_2 = Conv2D(256, (3, 3), padding='same')(relu5_1)\n    bn5_2 = BatchNormalization(axis=3)(conv5_2)\n    relu5_2 = Activation('relu')(bn5_2)\n    \n    up6 = Concatenate()([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(relu5_2), relu4_2])\n    conv6_1 = Conv2D(128, (3, 3), padding='same')(up6)\n    bn6_1 = BatchNormalization(axis=3)(conv6_1)\n    relu6_1 = Activation('relu')(bn6_1)\n    conv6_2 = Conv2D(128, (3, 3), padding='same')(relu6_1)\n    bn6_2 = BatchNormalization(axis=3)(conv6_2)\n    relu6_2 = Activation('relu')(bn6_2)\n    \n    up7 = Concatenate()([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(relu6_2), relu3_2])\n    conv7_1 = Conv2D(64, (3, 3), padding='same')(up7)\n    bn7_1 = BatchNormalization(axis=3)(conv7_1)\n    relu7_1 = Activation('relu')(bn7_1)\n    conv7_2 = Conv2D(64, (3, 3), padding='same')(relu7_1)\n    bn7_2 = BatchNormalization(axis=3)(conv7_2)\n    relu7_2 = Activation('relu')(bn7_2)\n    \n    up8 = Concatenate()([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(relu7_2), relu2_2])\n    conv8_1 = Conv2D(32, (3, 3), padding='same')(up8)\n    bn8_1 = BatchNormalization(axis=3)(conv8_1)\n    relu8_1 = Activation('relu')(bn8_1)\n    conv8_2 = Conv2D(32, (3, 3), padding='same')(relu8_1)\n    bn8_2 = BatchNormalization(axis=3)(conv8_2)\n    relu8_2 = Activation('relu')(bn8_2)\n    \n    up9 = Concatenate()([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(relu8_2), relu1_2])\n    conv9_1 = Conv2D(16, (3, 3), padding='same')(up9)\n    bn9_1 = BatchNormalization(axis=3)(conv9_1)\n    relu9_1 = Activation('relu')(bn9_1)\n    conv9_2 = Conv2D(16, (3, 3), padding='same')(relu9_1)\n    bn9_2 = BatchNormalization(axis=3)(conv9_2)\n    relu9_2 = Activation('relu')(bn9_2)\n    \n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(relu9_2)\n    \n    model = Model(inputs=[inputs], outputs=[conv10])\n    print(model.summary())\n    \n    return model\n\n\ndef get_model(name):\n    \"\"\"Get model function from the name space in strings\"\"\"\n    return globals()[name]\n","ca86e660":"\n# Define an experiment for training and test session\nclass Experiment(object):\n    def __init__(self, load_set, build_model, optimizer, save_dir='.'):\n        self.load_set = load_set\n        self.build_model = build_model\n        self.optimizer = optimizer\n        self.save_dir = Path(save_dir)\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n\n        self.config_file = self.save_dir \/ 'config.yaml'\n        self.model_file = self.save_dir \/ 'model.hdf5'\n        self.visual_file = self.save_dir \/ 'model.eps'\n\n        self.train_dir = self.save_dir \/ 'train'\n        self.train_dir.mkdir(exist_ok=True)\n        self.history_file = self.train_dir \/ 'history.csv'\n        self.weights_dir = self.train_dir \/ 'weights'\n        self.weights_dir.mkdir(exist_ok=True)\n\n        self.test_dir = self.save_dir \/ 'test'\n        self.test_dir.mkdir(exist_ok=True)\n\n    def weights_file(self, epoch=None):\n        if epoch is None:\n            return self.weights_dir \/ 'ep{epoch:04d}.hdf5'\n        else:\n            return self.weights_dir \/ 'ep{:04d}.hdf5'.format(epoch)\n\n    @property\n    def latest_epoch(self):\n        try:\n            return pd.read_csv(str(self.history_file))['epoch'].iloc[-1]\n        except (FileNotFoundError, pd.io.common.EmptyDataError):\n            pass\n        return -1\n\n    @staticmethod\n    def _ensure_dimension(array, dim):\n        while len(array.shape) < dim:\n            array = array[np.newaxis, ...]\n        return array\n\n    @staticmethod\n    def _ensure_channel(array, c):\n        return array[..., c:c + 4]\n\n    @staticmethod\n    def validate(array):\n        array = Experiment._ensure_dimension(array, 4)\n        array = Experiment._ensure_channel(array, 0)\n        return array\n    \n    # Image augmentation\n    @staticmethod\n    def augment(dataset):\n        sometimes = lambda aug: iaa.Sometimes(0.7, aug)\n        seq = iaa.Sequential([\n            sometimes(iaa.imgcorruptlike.Fog(severity=1)),\n            sometimes(iaa.imgcorruptlike.Spatter(severity =1)),\n#            sometimes(iaa.Crop(px=(0, 1))), # crop images from each side by 0 to 16px (randomly chosen)\n#            sometimes(iaa.Fliplr(1)), # horizontally flip 50% of the image\n#            sometimes(iaa.GaussianBlur(sigma=(0, 0.05))), # blur images with a sigma of 0 to .1\n#            sometimes(iaa.Affine(\n#                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n#                #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n#                rotate=(-45, 45), # rotate by -45 to +45 degrees\n#                shear=(-3, 3), # shear by -10 to +10 degrees\n#                #order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n#            )),\n#            sometimes(iaa.PiecewiseAffine(scale=(0, 0.03))),\n#            sometimes(iaa.PerspectiveTransform(scale=(0, 0.1)))\n        ])\n        dataset = seq.augment_images(dataset)\n        return dataset\n\n    def compile(self, model):\n        \"\"\"Compile model with default settings.\"\"\"\n        model.compile(optimizer=self.optimizer, loss=dice_coef_loss, metrics=[mean_iou])  # 'binary_crossentropy'\n        return model\n\n    def train(self, data_dir, epochs, band_ind, resume=True):\n        # Load and process data\n        x_train, y_train, x_val, y_val = self.load_set()\n        assert len(x_train) == len(x_val)\n        \n#        # Augmentation\n#        for i in range(1):\n#            x_train[i] = self.augment(x_train[i])\n#            x_val[i] = self.augment(x_val[i])\n        \n        # Validate dimension\n        for i in range(1):\n            x_train[i], x_val[i] = [self.validate(x*1.0) for x in [x_train[i], x_val[i]]]\n        y_train, y_val = [self.validate(y*1.0) for y in [y_train, y_val]]\n\n        # Compile model\n        model = self.compile(self.build_model(*x_train))\n        model.summary()\n        #self.config_file.write_text(model.to_yaml())\n        #plot_model(model, to_file=str(self.visual_file), show_shapes=False)\n\n        # Inherit weights\n        if resume:\n            latest_epoch = self.latest_epoch\n            if latest_epoch > -1:\n                weights_file = self.weights_file(epoch=latest_epoch)\n                model.load_weights(str(weights_file))\n            initial_epoch = latest_epoch + 1\n        else:\n            initial_epoch = 0\n\n        # Set up callbacks\n        callbacks = []\n        callbacks += [ModelCheckpoint(str(self.model_file))]\n#        callbacks += [ModelCheckpoint(str(self.weights_file()), save_weights_only=True)]\n        callbacks += [CSVLogger(str(self.history_file), append=resume)]\n        callbacks += [ReduceLROnPlateau(factor=0.5, cooldown=0, patience=30, min_lr=0.5e-5)]\n\n        # Train\n        model.fit(x_train, y_train, batch_size=16, epochs=epochs, callbacks=callbacks, \n                  shuffle=True, validation_data=(x_val, y_val), initial_epoch=initial_epoch)\n\n        # Plot metrics history\n        prefix = str(self.history_file).rsplit('.', maxsplit=1)[0]\n        df = pd.read_csv(str(self.history_file))\n        epoch = df['epoch']\n        for metric in ['Loss', 'mean_iou']:\n            train = df[metric.lower()]\n            val = df['val_' + metric.lower()]\n            plt.figure()\n            plt.plot(epoch, train, label='train')\n            plt.plot(epoch, val, label='val')\n            plt.legend(loc='best')\n            plt.xlabel('Epoch')\n            plt.ylabel(metric)\n            plt.savefig('.'.join([prefix, metric.lower(), 'png']))\n            plt.close()\n\n    def test_on_image(self, test_dir, output_dir, subUL, band_ind, \n                      block_size, metrics=[jaccard_score]):\n        # Load images\n        print('Loading test image from {}'.format(test_dir))\n        input_images, valid_image = load_rasters(test_dir, subUL, band_ind)\n        assert input_images[0].shape[-1] == len(band_ind)\n        name = input_images[-1].filename.name if hasattr(input_images[-1], 'filename') else ''\n        print('Predict on image {}'.format(name))\n        \n        # Pad input image as multiple of block size\n        input_row, input_col = input_images[0].shape[0], input_images[0].shape[1]\n        input_images[0] = np.lib.pad(input_images[0], ((0, block_size[0]-input_row%block_size[0]), \n                                           (0, block_size[1]-input_col%block_size[1]),(0,0)), 'edge')\n\n        # Generate output image and measure run time\n        # The shape of the x_inputs (numbers, height, width, channels)\n        x_inputs = [self.validate(img_to_array(im)) for im in input_images]\n#        assert x_inputs[0].shape[1] % block_size[0] == 0\n#        assert x_inputs[0].shape[2] % block_size[1] == 0\n        x_train, _ = load_test_set((input_images, valid_image), block_size=block_size)\n\n        model = self.compile(self.build_model(*x_train))\n        if self.model_file.exists():\n            model.load_weights(str(self.model_file))\n\n        t_start = time.perf_counter()\n        y_preds = model.predict(x_train, batch_size=1)  # 4-dimensional array with batch size\n        # map predicted patches back to original image extent\n        y_pred = np.empty((input_images[0].shape[0], input_images[0].shape[1], 1), dtype=np.float32)\n        row_step = block_size[0]\n        col_step = block_size[1]\n        rows = x_inputs[0].shape[1] \/\/ block_size[0]\n        cols = x_inputs[0].shape[2] \/\/ block_size[1]\n        count = 0\n        for i in range(rows):\n            for j in range(cols):\n                y_pred[i * row_step:(i + 1) * row_step, j * col_step:(j + 1) * col_step] = y_preds[count]\n                count += 1\n        assert count == rows * cols\n        y_pred = y_pred[:valid_image.shape[0],:valid_image.shape[1]]  # Cut back to unpadded size\n        \n        # Plot prediction and reference\n        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(24,10))\n        ax1.imshow(y_pred[:,:,0],'gray')\n        ax1.set_title('Prediction')\n        ax2.imshow(input_images[0])\n        ax2.set_title('Reference')\n\n        t_end = time.perf_counter()\n\n        # Record metrics\n        row = pd.Series()\n        row['name'] = name\n        row['time'] = t_end - t_start\n        y_true = self.validate(img_to_array(valid_image))\n        y_pred = self.validate(y_pred)\n        for metric in metrics:\n#            row[metric.__name__] = K.eval(metric(y_true, y_pred))\n            row[metric.__name__] = metric(y_true[0].squeeze(), \n               (y_pred[0].squeeze()>.5).astype(int), average='macro')\n\n        prototype = str(valid_image.filename) if hasattr(valid_image, 'filename') else None\n        gdal_array.SaveArray(y_pred[0].squeeze().astype(np.int16),\n                             str(output_dir \/ name),\n                             prototype=prototype)\n        return row\n    \n    def test(self, data_dir, subUL, band_ind, block_size=(500, 500), metrics=[jaccard_score]):\n        test_set='test'\n        print('Testing...')\n        output_dir = self.test_dir\/test_set\n        output_dir.mkdir(exist_ok=True)\n\n        # Evaluate metrics on each image\n        # Different from training that load all images at once before training\n        # test_on_image is put in the loop called for each image\n        image_list = [name for name in Path(data_dir\/test_set\/'image').glob('*.tif')]  # Loop over all images\n        label_list = [name for name in Path(data_dir\/test_set\/'label').glob('*.tif')]  # Loop over all labels\n        all_list = {'image':image_list,'label':label_list}\n        df = pd.DataFrame(all_list, columns=['image','label'])\n        \n        rows = []\n        for ind, row in df.iterrows():  # Loop over names of all image, label pairs\n            print('loading image pairs from {} and {}'.format(row['image'], row['label']))\n            test_path = [row['image'], row['label']]\n            rows += [self.test_on_image(test_path, output_dir, subUL, band_ind, \n                                        block_size=block_size, metrics=metrics)]\n        df = pd.DataFrame(rows)\n        # Compute average metrics\n        row = pd.Series()\n        row['name'] = 'average'\n        for col in df:\n            if col != 'name':\n                row[col] = df[col].mean()\n        df = df.append(row, ignore_index=True)\n        df.to_csv(str(self.test_dir \/ '{}\/metrics.csv'.format(test_set)))\n\n","aaf11fce":"#------------------------\n# Set working directory and parameters\n#------------------------\n\n# Working directory\n#repo_dir = Path('__file__').parents[0]\ndata_dir = Path('..\/input\/building\/sample_data2\/')\nsave_dir = Path('..\/output\/kaggle\/working')\n\n# Affiliated parameters from JSON file\n#with open('parameter2.json', 'r') as read_file:\n#    param = json.load(read_file)\n","2ae9108c":"#------------------------\n# Experiment configure and compile\n#------------------------\n\n# Input training patch dimensions\nsize=64  # param['size']\nstride=64  # param['stride']  # Sampling stride\n#extent = param['extent']\nepochs=5 #param['epochs']\n# Index of selected band\nbands=[3,2,1]  # param['band_ind']\nband_ind=[i-1 for i in bands]\n# Subset study area\nsubUL=[0,0]  # param['subUL']\nblock_size=tuple([256,256])  # tuple(param['block_size'])\n\n\nbuild_model = get_model('res_u') #(param['model']['name'])\n\noptimizer = getattr(optimizers, 'Adam')  # getattr(optimizers, param['optimizer']['name'])\noptimizer = optimizer(lr=1e-4, decay=1e-5)  # optimizer(**param['optimizer']['params'])\n\n#if 'optimizer' in param:\n#    optimizer = getattr(optimizers, 'Adam')  # getattr(optimizers, param['optimizer']['name'])\n#    optimizer = optimizer(lr=1e-4, decay=1e-5)  # optimizer(**param['optimizer']['params'])\n#else:\n#    optimizer = 'Adam'\n       \n# Simple version of data loading functionality\nload_set = partial(load_train_set, data_dir, \n                   subUL, band_ind, size, stride)\n\n# Setup experiment\nexpt = Experiment(load_set=load_set,\n                  build_model=build_model, optimizer=optimizer,\n                  save_dir='results')  # save_dir=param['save_dir']\n               ","bb566723":"#------------------------\n# Train\n#------------------------    \nprint('training process...')\nexpt.train(data_dir=data_dir, band_ind=band_ind, \n           epochs=epochs, resume=False)\n","1a1ed306":"#------------------------\n# Test\n#------------------------    \n# Evaluation\nprint('evaluation process...')\nexpt.test(data_dir=data_dir, subUL=subUL, \n          band_ind=band_ind, block_size=block_size)  # lr_block_size=lr_block_size\n#    for test_set in param['test_sets']:\n#        expt.test(test_set=test_set, lr_block_size=lr_block_size)\n","072440ae":"### Functionality 05: Train and predict","747acc89":"### Functionality 06: Running","e4390144":"### Functionality 04: Model options","755ef04e":"### Functionality 03: Customize loss function metrics","1493fe32":"### Functionality 01: Load and organize images","a537079e":"# The morphology of human settlements based upon building configurations","6dc31f1a":"### Functionality 00: View files and versions","5b894997":"### Functionality 02: Prepare data for train, val, test"}}