{"cell_type":{"142ac2c5":"code","62f8ca69":"code","5acb3a50":"code","cc28f5b4":"code","11149302":"code","c3232581":"code","6ba54e20":"code","7963a5c5":"code","01853176":"code","4044a668":"code","9017b89e":"code","e9b95e11":"code","7f840a0f":"code","99c65d3b":"code","6ae5bc35":"code","54c4245f":"code","76935154":"code","82352eea":"code","9e217623":"code","cc30d897":"code","17e07b5a":"code","2186017b":"code","f56ee3c5":"markdown","d2cbe3e5":"markdown","b2510f5d":"markdown","40537a9d":"markdown","dc1eee6d":"markdown","1e9c8dc7":"markdown","9c8775e9":"markdown","a8d32b3b":"markdown","f924d567":"markdown","f294f0a7":"markdown","6f644e29":"markdown","fbf90e12":"markdown","539c2ab2":"markdown","a0e40232":"markdown","d8a219b8":"markdown","e5e86685":"markdown","44b6b104":"markdown","0e91259d":"markdown","7634b725":"markdown","98d2676c":"markdown","690de5c5":"markdown","89bb8ba2":"markdown","0069ee9b":"markdown"},"source":{"142ac2c5":"from IPython.utils import io\n\nwith io.capture_output() as captured:\n    %load_ext tensorboard\n    %tensorboard --logdir runs --bind_all\n\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorwriter = SummaryWriter()","62f8ca69":"import numpy\nimport pandas\nimport seaborn\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\n\nimport torch","5acb3a50":"RANDOM_STATE = 1234\n\ntorch.manual_seed(RANDOM_STATE)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(RANDOM_STATE)","cc28f5b4":"BATCH_SIZE = 2048\nEPOCHS = 300\nLEARNING_RATE = 1e-3","11149302":"if torch.cuda.is_available() and torch.version.cuda:\n    device = torch.device(\"cuda\")\nelif torch.cuda.is_available() and torch.version.hip:\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")","c3232581":"df = pandas.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","6ba54e20":"df","7963a5c5":"df = df.assign(\n    Amount=RobustScaler().fit_transform(df[\"Amount\"].values.reshape(-1, 1)),\n    Time=RobustScaler().fit_transform(df[\"Time\"].values.reshape(-1, 1))\n)","01853176":"df = df.sample(frac=1, random_state=RANDOM_STATE)","4044a668":"X = df.loc[:, df.columns != \"Class\"].values.astype(numpy.float32)\ny = df.loc[:, df.columns == \"Class\"].values.reshape(-1).astype(numpy.int64)\n\nX_train, X_evaluate, y_train, y_evaluate = train_test_split(\n    X, y, test_size=0.10, random_state=RANDOM_STATE\n)","9017b89e":"train_dataset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_train).to(device),\n    torch.from_numpy(y_train).to(device)\n)\n\nevaluate_dataset = torch.utils.data.TensorDataset(\n    torch.from_numpy(X_evaluate).to(device),\n    torch.from_numpy(y_evaluate).to(device)\n)","e9b95e11":"train_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n)\n\nevaluate_loader = torch.utils.data.DataLoader(\n    evaluate_dataset, batch_size=BATCH_SIZE, shuffle=True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    evaluate_dataset, batch_size=1, shuffle=False\n)","7f840a0f":"_, (p1, p2) = numpy.unique(y, return_counts=True)\n\nax = seaborn.countplot(\n    data = df,\n    x=\"Class\"\n)","99c65d3b":"total_files = EPOCHS * len(train_loader) + EPOCHS * len(evaluate_loader)","6ae5bc35":"class ANN(torch.nn.Module):\n    def __init__(self):\n        super(ANN, self).__init__()\n\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Linear(30, 256),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.Dropout(0.3),\n        )\n\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Linear(256, 256),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.Dropout(0.3),\n        )\n\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Linear(256, 256),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.Dropout(0.3),\n        )\n\n        self.layer4 = torch.nn.Sequential(\n            torch.nn.Linear(256, 2),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        return self.layer4(x)","54c4245f":"model = ANN().to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = torch.nn.CrossEntropyLoss()","76935154":"from tqdm.notebook import tqdm\n\nprogress = tqdm(total=total_files)\n\nWEIGHTS = torch.tensor([1.0, 5.0], device=device)\n\nfor epoch in range(EPOCHS):\n    train_accuracy, evaluation_accuracy = 0, 0\n    train_loss, evaluation_loss = 0, 0\n\n    with torch.enable_grad():\n        model.train()\n        for X, y in train_loader:\n            output = model(X)\n            loss = criterion(output, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Log performance\n            train_accuracy += accuracy_score(output.cpu().argmax(dim=1), y.cpu().data)\n            train_loss += loss.data\n\n            progress.update(1)\n\n    with torch.no_grad():\n        model.eval()\n        for X, y in evaluate_loader:\n            output = model(X)\n\n            # Log performance\n            evaluation_accuracy += accuracy_score(output.cpu().argmax(dim=1), y.cpu().data)\n            evaluation_loss += criterion(output, y).data\n\n            progress.update(1)\n\n    # Log performance\n    tensorwriter.add_scalars(\n        \"Accuracy\",\n        {\n            \"Train\": train_accuracy \/ len(train_loader),\n            \"Evaluate\": evaluation_accuracy \/ len(evaluate_loader),\n        },\n        epoch,\n    )\n    tensorwriter.add_scalars(\n        \"Loss\",\n        {\n            \"Train\": train_loss \/ len(train_loader),\n            \"Evaluate\": evaluation_loss \/ len(evaluate_loader),\n        },\n        epoch,\n    )\n\nprogress.close()","82352eea":"y_preds = []\n\nwith torch.no_grad():\n    model.eval()\n    for X, y in tqdm(test_loader):\n        y_preds.append(model(X).argmax(dim=1).item())","9e217623":"print(classification_report(y_evaluate, y_preds))","cc30d897":"cm = confusion_matrix(y_evaluate, y_preds)\n\nlabels = numpy.unique(y_preds)\n\ndf = pandas.DataFrame(cm, index=labels, columns=labels)\n\n_, ax = plt.subplots(figsize=(4, 4), dpi=50)\nax = seaborn.heatmap(\n    df,\n    cmap=\"rocket\",\n    square=True,\n    annot=True,\n    fmt=\".5g\",\n    annot_kws={\"size\": \"xx-large\"},\n    linewidths=1\n)","17e07b5a":"torch.save(\n    model.cpu().state_dict(),\n    f\"CNN_{LEARNING_RATE}_{BATCH_SIZE}.pickle\"\n)","2186017b":"tensorwriter.close()","f56ee3c5":"Specify training optimizer and criterion.","d2cbe3e5":"### Save model","b2510f5d":"# Credit card fraud detection","40537a9d":"# TODO:\n\nFix imbalance. Currently very bad at predicting.","dc1eee6d":"## Preprocessing\n\nScale *amount* and *time* using `sklearn.preprocessing.RobustScale`.","1e9c8dc7":"Packaging the seperated train-test data into tensor datasets.","9c8775e9":"An integer is set as a random state used in Numpy, Scikit-learn, PyTorch, etc. Furthermore, manual_seed set to make independent sessions as reproducible as possible using this random state. PyTorch does not guarantee reproducibility between PyTorch commits, different platforms, individual commits or between GPU and CPU executions despite using identical seeds.","a8d32b3b":"## Loading data\n\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where there is 492 frauds out of 284807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.","f924d567":"Training the model.","f294f0a7":"## Data\n\nFirsly, a summary of the data by classes.","6f644e29":"At last, closing streams and open files.","fbf90e12":"## Validation\n\nBenchmark the model using different metrics and methods.\n\n### Generate prediction\n\nFirst step include generating *y_preds* for furher use.","539c2ab2":"Launching a tensorboard for tracking of model performance, etc.","a0e40232":"## Model","d8a219b8":"Calculating amount of lines to include\/process in the model training.","e5e86685":"Checking GPU availability to utilize Compute Unified Device Architecture (CUDA) or Heterogeneous Interface for Portability (HIP) if available for GPGPU acceleration of training else the process fall back on CPU. The current model in this notebook is complex and may take days to run on a consumer CPU. Use of GPU acceleration is highly encouraged.","44b6b104":"### Classification summary","0e91259d":"### Confusion Matrix","7634b725":"The dataset is split into a train and test dataset using `sklearn.model_selection.train_test_split`.","98d2676c":"Defining some constants used to split the data and train the model. These are related to the data loading process in PyTorch, the optimizer, the loss function and the learning rate scheduler.","690de5c5":"The last step is to randomly sample \/ randomise order of the feature \/ target row-wise.","89bb8ba2":"Packaging data into torch dataloders with specific batch sizes.","0069ee9b":"Importing necessary packages including PyTorch and scikit-learn."}}