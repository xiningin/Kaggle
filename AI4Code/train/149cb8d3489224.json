{"cell_type":{"f12bf59b":"code","09d3f343":"code","d174f3ea":"code","9e9b7d6d":"code","706c293a":"code","797fe830":"code","7d1400f4":"code","bc1b53bd":"code","4f74890a":"code","2055d63b":"code","a435defa":"code","39797df5":"code","79692f53":"code","1f1561f1":"code","a8dbefb2":"code","35ed3418":"code","1b0cecee":"code","304a9b55":"code","cfc40221":"code","b9fac957":"code","1d455773":"code","6ada352f":"code","f22b371c":"code","0a19f0b9":"code","5dc53380":"code","6c4fde92":"code","e0be95f1":"code","02b0a9b9":"code","aacb01fd":"code","e824b1a5":"code","56460ab9":"code","d1b3c71b":"code","82454ccb":"code","c0f4d03b":"code","fd95f41a":"code","39b728dc":"code","6cff4bb0":"code","d0cd7c72":"code","7c0638a7":"code","1396c1c5":"code","d3c24186":"code","0db7f85c":"code","d1063422":"code","2999419c":"markdown","77db7299":"markdown","2d76f691":"markdown","58c78bb8":"markdown","428c0a59":"markdown","d46b7f70":"markdown","8f351753":"markdown","5fab2979":"markdown","a45eb82a":"markdown","dd393db5":"markdown","d1121fe4":"markdown","07fc1310":"markdown","681d8952":"markdown","7f73606b":"markdown","9e29083b":"markdown","06cf6966":"markdown"},"source":{"f12bf59b":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.simplefilter(\"ignore\")","09d3f343":"tweets_df = pd.read_csv(\"\/kaggle\/input\/all-covid19-vaccines-tweets\/vaccination_all_tweets.csv\")","d174f3ea":"print(f\"data shape: {tweets_df.shape}\")","9e9b7d6d":"tweets_df.info()","706c293a":"tweets_df.describe()","797fe830":"tweets_df.head()","7d1400f4":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","bc1b53bd":"missing_data(tweets_df)","4f74890a":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","2055d63b":"unique_values(tweets_df)","a435defa":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))","39797df5":"most_frequent_values(tweets_df)","79692f53":"def plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","1f1561f1":"plot_count(\"user_name\", \"User name\", tweets_df,4)","a8dbefb2":"plot_count(\"user_location\", \"User location\", tweets_df,4)","35ed3418":"plot_count(\"source\", \"Source\", tweets_df,4)","1b0cecee":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","304a9b55":"\nfrom wordcloud import WordCloud, STOPWORDS\ndef show_wordcloud(data, title=\"\"):\n    text = \" \".join(t for t in data.dropna())\n    stopwords = set(STOPWORDS)\n    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\"])\n    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,background_color=\"black\").generate(text)\n    fig = plt.figure(1, figsize=(16,16))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(top=2.3)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","cfc40221":"show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets')","b9fac957":"india_df = tweets_df.loc[tweets_df.user_location==\"India\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')","1d455773":"us_df = tweets_df.loc[tweets_df.user_location==\"United States\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from US')","6ada352f":"uk_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\nshow_wordcloud(uk_df['text'], title = 'Prevalent words in tweets from UK')","f22b371c":"ca_df = tweets_df.loc[tweets_df.user_location==\"Canada\"]\nshow_wordcloud(ca_df['text'], title = 'Prevalent words in tweets from Canada')","0a19f0b9":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","5dc53380":"tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\ntweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ntweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)","6c4fde92":"tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","e0be95f1":"tweets_df['hashtags_individual'].head()","02b0a9b9":"tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])","aacb01fd":"tweets_df['year'] = tweets_df['datedt'].dt.year\ntweets_df['month'] = tweets_df['datedt'].dt.month\ntweets_df['day'] = tweets_df['datedt'].dt.day\ntweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\ntweets_df['hour'] = tweets_df['datedt'].dt.hour\ntweets_df['minute'] = tweets_df['datedt'].dt.minute\ntweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\ntweets_df['date_only'] = tweets_df['datedt'].dt.date","e824b1a5":"tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\ntweets_agg_df.columns = [\"date_only\", \"count\"]","56460ab9":"def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n    plt.xticks(rotation=90)\n    if hue:\n        plt.title(f'{y} grouped by {hue} | {title}')\n    else:\n        plt.title(f'{y} | {title}')\n    if(is_log):\n        ax.set(yscale=\"log\")\n    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n    plt.show() ","d1b3c71b":"plot_time_variation(tweets_agg_df, title=\"Number of tweets \/ day of year\",size=3)","82454ccb":"plot_count(\"dayofweek\", \"tweets \/ day of week\", tweets_df, size=3, ordered=False)","c0f4d03b":"plot_count(\"dayofyear\", \"tweets \/ day of year\", tweets_df, size=3, ordered=False)","fd95f41a":"plot_count(\"date_only\", \"tweets \/ date\", tweets_df,size=4, ordered=False)","39b728dc":"plot_count(\"hour\", \"tweets \/ hour\", tweets_df,size=4, ordered=False)","6cff4bb0":"plot_count(\"minute\", \"tweets \/ minute\", tweets_df,size=5, ordered=False)","d0cd7c72":"# borrowed from https:\/\/www.kaggle.com\/pashupatigupta\/sentiments-transformer-vader-embedding-bert\nsia = SentimentIntensityAnalyzer()\ndef find_sentiment(post):\n    if sia.polarity_scores(post)[\"compound\"] > 0:\n        return \"Positive\"\n    elif sia.polarity_scores(post)[\"compound\"] < 0:\n        return \"Negative\"\n    else:\n        return \"Neutral\" ","7c0638a7":"def plot_sentiment(df, feature, title):\n    counts = df[feature].value_counts()\n    percent = counts\/sum(counts)\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n\n    counts.plot(kind='bar', ax=ax1, color='green')\n    percent.plot(kind='bar', ax=ax2, color='blue')\n    ax1.set_ylabel(f'Counts : {title} sentiments', size=12)\n    ax2.set_ylabel(f'Percentage : {title} sentiments', size=12)\n    plt.suptitle(f\"Sentiment analysis: {title}\")\n    plt.tight_layout()\n    plt.show()","1396c1c5":"tweets_df['sentiment'] = tweets_df['text'].apply(lambda x: find_sentiment(x))\nplot_sentiment(tweets_df, 'sentiment', 'Text')","d3c24186":"show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Positive', 'text'], title = 'Prevalent words in tweets (Positive sentiment)')","0db7f85c":"show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Negative', 'text'], title = 'Prevalent words in tweets (Negative sentiment)')","d1063422":"show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Neutral', 'text'], title = 'Prevalent words in tweets (Neutral sentiment)')","2999419c":"### Text wordcloauds","77db7299":"### Tweet source","2d76f691":"### Unique values","58c78bb8":"### Extract date and time features","428c0a59":"### Missing data","d46b7f70":"# Data preparation\n\n## Load packages","8f351753":"## Load data","5fab2979":"<center><h1>Explore Vaccines Tweets<\/h1><\/center>\n\n\n<center><img src=\"https:\/\/images.unsplash.com\/photo-1605377347958-e8bd4c00ba1d?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=700&q=80\" width=400><img><\/center>\n\n# Introduction\n\n\nThe Dataset we are using here is collected using Twitter API, **tweepy** and Python package.\n\nThe following vaccines are included:  \n* Pfizer\/BioNTech;   \n* Sinopharm;  \n* Sinovac;  \n* Moderna;  \n* Oxford\/AstraZeneca;   \n* Covaxin;   \n* Sputnik V.  \n\n","a45eb82a":"### Hashtags analysis","dd393db5":"## Visualize the data distribution","d1121fe4":"### Most frequent values","07fc1310":"# Data exploration\n\n\n## Glimpse the data","681d8952":"### User location","7f73606b":"### User name","9e29083b":"## Sentiment analysis","06cf6966":"### Time variation"}}