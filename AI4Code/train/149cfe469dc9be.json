{"cell_type":{"7270985b":"code","b9ff1efd":"code","e39eef48":"code","84ae44c5":"code","de28c21f":"code","c6ac8a8b":"code","067bf1e7":"code","58b975d9":"code","0cd837c9":"code","29f1f7b2":"code","a1b0c62e":"code","c6afda62":"code","8fba63be":"code","2b54c929":"code","6bf48a22":"code","af85ac89":"code","5bf089e2":"code","bdd7f0ae":"code","03f18e0a":"code","a898d014":"code","2f23b2e3":"code","2699b529":"markdown","46a559b3":"markdown","2b4c4227":"markdown","79ccbe73":"markdown","7dfe6f7c":"markdown"},"source":{"7270985b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Modelling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, normalize\nfrom sklearn.ensemble import RandomForestRegressor # Model\nfrom sklearn.metrics import mean_squared_error # Evaluation\n\n# Statistics\nfrom scipy import stats\nfrom scipy.stats import norm, skew \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9ff1efd":"train_pd = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_pd = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","e39eef48":"train_pd.info()","84ae44c5":"fig, ax = plt.subplots()\nax.scatter(x = train_pd['GrLivArea'], y = train_pd['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","de28c21f":"fig, ax = plt.subplots()\nax.scatter(x = train_pd['MSSubClass'], y = train_pd['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","c6ac8a8b":"# Target variable - SalePrice\nsns.displot(train_pd['SalePrice']);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_pd['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_pd['SalePrice'], plot=plt)\nplt.show()","067bf1e7":"# Normalize target variable\ntrain_pd[\"SalePrice\"] = np.log1p(train_pd[\"SalePrice\"])\n\n# View the normalized distribution\nsns.displot(train_pd['SalePrice'])\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_pd['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_pd['SalePrice'], plot=plt)\nplt.show()","58b975d9":"# Save Id\ntrain_x_id = train_pd['Id']\ntest_x_id = test_pd['Id']\n# Drop Id\ntrain_pd.drop(\"Id\", axis = 1, inplace = True)\ntest_pd.drop(\"Id\", axis = 1, inplace = True)\n# Separate target from predictors\ntrain_y_full = train_pd.SalePrice\ntrain_x_full = train_pd.drop(['SalePrice'], axis=1)\n# Divide data into training and validation subsets\ntrain_x, valid_x, train_y, valid_y = train_test_split(train_x_full, train_y_full, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","0cd837c9":"train_x.head()","29f1f7b2":"valid_x.head()","a1b0c62e":"train_y","c6afda62":"valid_y","8fba63be":"list(train_x.columns.values)","2b54c929":"cols_with_missing = [col for col in train_x.columns if train_x[col].isnull().any()] \ntrain_x[cols_with_missing]","6bf48a22":"# Get list of categorical variables\nc = (train_x.dtypes == 'object')\ncategorical_cols = list(c[c].index)\n\nprint(\"Categorical variables:\")\nprint(categorical_cols)","af85ac89":"# Select numerical columns\nnumerical_cols = [cname for cname in train_x.columns if train_x[cname].dtype in ['int64', 'float64']]\n\nprint(\"Numerical variables:\")\nprint(numerical_cols)","5bf089e2":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","bdd7f0ae":"# Define model\nrf_model = RandomForestRegressor(n_estimators=500, random_state=0)","03f18e0a":"# Validation function\ndef rmsle(valid_y, preds):\n    return np.sqrt(mean_squared_error(valid_y, preds))","a898d014":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rf_model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(train_x, train_y)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(valid_x)\n\n# Evaluate the model\nscore = rmsle(valid_y, preds)\nprint('RMSLE:', score)","2f23b2e3":"sub = pd.DataFrame()\nsub['Id'] = test_x_id\nsub['SalePrice'] = my_pipeline.predict(test_pd)\nsub.to_csv('submission.csv',index=False)","2699b529":"# Load dataset","46a559b3":"# Submission","2b4c4227":"# Import libraries","79ccbe73":"# Explore Dataset","7dfe6f7c":"# Feature Engineering"}}