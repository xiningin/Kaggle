{"cell_type":{"d988f980":"code","2b3aa878":"code","f5aa9ef0":"code","6b2a2ed1":"code","129a5321":"code","d2ed640c":"code","3b0ce32d":"code","780c5caa":"code","b4255801":"code","2fe4aaa0":"code","ab2b6b45":"code","9dba62f3":"code","60937cc0":"code","d2bda6d3":"code","88301d8e":"code","5149f881":"code","3f89ea2c":"code","a6877e11":"code","d4971384":"code","c3b17d51":"code","0c471322":"code","3014b72e":"code","b21089a1":"code","cdb1df22":"code","ad4300bc":"code","19c4b956":"code","9d5dd47f":"markdown","dd0b851b":"markdown","4e094961":"markdown","b3fe5595":"markdown"},"source":{"d988f980":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2b3aa878":"import numpy as np\n\nimport os\nimport sys\nimport cv2\nfrom keras.utils import to_categorical\nimport matplotlib\nfrom keras import backend as k\nk.clear_session()","f5aa9ef0":"import random\nrandom.seed(10)\nallLabels =  os.listdir(\"..\/input\/plant-seedlings-classification\/train\/\")  # list of subdirectories and files\ntrainDir='\/kaggle\/working\/..\/input\/plant-seedlings-classification\/train\/'\n\nfrom keras.preprocessing.image import  img_to_array, load_img\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\n\ndata = []\nlabels = []\n\n# loop over the input images\ndirs = os.listdir(trainDir) \nfor dir in dirs:\n    absDirPath = os.path.join(os.path.sep,trainDir, dir)\n    images = os.listdir(absDirPath)\n    for imageFileName in images:\n        \n        # load the image, pre-process it, and store it in the data list\n        imageFullPath = os.path.join(trainDir, dir, imageFileName)\n        #print(imageFullPath)\n        img = load_img(imageFullPath)\n        arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n        arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n        #print(arr.shape)\n        data.append(arr)\n        #label = classes_to_int(dir)\n        label=str(imageFullPath.split('\/')[-2])\n        #print(label)\n        labels.append(label)\n\n  ","6b2a2ed1":"len(images)\nprint('Number of images :-',len(data))\nprint('Numbe of Labels',len(labels))","129a5321":"data[0]","d2ed640c":"%matplotlib inline\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\n#to view the images\n\nfor i in range(1,10):\n    #print(i)\n    new_image = tf.keras.preprocessing.image.array_to_img(data[i])\n    #Show image\n    #fig, axs = plt.subplots(1, j, figsize=(20, 20))\n    plt.imshow(new_image)\n    plt.show()\n    \n\n","3b0ce32d":"from sklearn.preprocessing import LabelEncoder\n\n# scale the raw pixel intensities to the range [0, 1]\nTrainX = np.array(data, dtype=\"float\") \/ 255.0\nY_labels = np.array(labels)\n# convert the labels from integers to vectors\n#Y =  to_categorical(Y, num_classes=12)\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(Y_labels)\ntrain_labels_encoded = labelEncoder.transform(Y_labels)\ntrainY = tf.keras.utils.to_categorical(train_labels_encoded, num_classes=12)\n        ","780c5caa":"print(TrainX.shape)\nprint(trainY.shape)","b4255801":"from sklearn.model_selection import train_test_split\nprint(\"Train Validation Split into 80:20...\")\nsys.stdout.flush()\n# partition the data into training and validation splits \n(x_train, valX, y_train, valY) = train_test_split(TrainX,trainY,test_size=0.20, random_state=10)\n","2fe4aaa0":"from keras.preprocessing.image import ImageDataGenerator\n\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n   horizontal_flip=True, fill_mode=\"nearest\")","ab2b6b45":"from keras import backend as k\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dense\nfrom keras.optimizers import Adam\n# initialize the model\n\nsys.stdout.flush()\nk.clear_session()\n\ninputShape = (WIDTH, HEIGHT, DEPTH)\nEPOCHS = 40\nINIT_LR = 1e-3\nBS = 32\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape)) \nmodel.add(Activation(\"relu\"))\n#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (5, 5), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\n# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\n#  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=500))\nmodel.add(Activation(\"relu\"))\n\n# softmax classifier\nmodel.add(Dense(units=12))\nmodel.add(Activation(\"softmax\"))\n   \nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nmodel.summary()\n","9dba62f3":"# train the network\n\nsys.stdout.flush()\n\nH = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS), \n                        validation_data=(valX, valY), \n                        steps_per_epoch=len(x_train) \/\/ BS, \n                        epochs=EPOCHS, verbose=1)\n","60937cc0":"\nfrom matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\n\npyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\npyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\npyplot.title(\"Training \/Validation and Accuracy on  crop classification\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Accuracy\")\npyplot.legend(loc=\"lower left\")\n","d2bda6d3":"\nfrom matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\npyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\npyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n\npyplot.title(\"Training \/Validation Loss on  crop classification\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Loss\")\npyplot.legend(loc=\"lower left\")\n","88301d8e":"#allLabels =  os.listdir(\"..\/input\/test\/\")  # list of subdirectories and files\ntestDir='\/kaggle\/working\/..\/input\/plant-seedlings-classification\/test\/'\n\nfrom keras.preprocessing.image import  img_to_array, load_img\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\nTestdata = []\nfilenames = []\n    # loop over the input images\nimages = os.listdir(testDir)\nfor imageFileName in images:\n # load the image, pre-process it, and store it in the data list\n    imageFullPath = os.path.join(testDir, imageFileName)\n    #print(imageFullPath)\n    img = load_img(imageFullPath)\n    arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n    arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n    Testdata.append(arr)\n    filenames.append(imageFileName)\n   \n\n","5149f881":"# scale the raw pixel intensities to the range [0, 1]\ntestX = np.array(Testdata, dtype=\"float\") \/ 255.0\n","3f89ea2c":"testX.shape","a6877e11":"len(filenames)","d4971384":"print(filenames[0])","c3b17d51":"predicted_probs = model.predict(testX, batch_size=10, verbose=1)\n\n#predicted_probs = model.predict_generator(test_generator(test_files), steps=len(test_files))\n#[f.split('\/')[3] for f in test_files]\npredicted_classes = np.argmax(predicted_probs, axis=1)\nout_df = pd.DataFrame({'file':filenames , \n                       'species': labelEncoder.inverse_transform(predicted_classes)})\nout_df.to_csv('submission_conv.csv', index=False)","0c471322":"#tf.keras.applications\nfrom tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\n\n#RESNET_WEIGHTS_PATH = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n#RESNET_WEIGHTS_PATH = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmodel2 = Sequential()\n#model2 = Sequential()\nmodel2.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n\n#model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n\n\n#model2.add(ResNet50(include_top=False, pooling='max', weights= 'imagenet'))\n#model2.layers[0].trainable = True\n\n# Say not to train first layer (ResNet) model as it is already trained\nmodel2.layers[0].trainable = False\n\n","3014b72e":"from tensorflow.keras.layers import Dropout\n#get Output layer of Pre0trained model\nx = model2.output\n\n#Flatten the output to feed to Dense layer\nx = tf.keras.layers.Flatten()(x)\n\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\n\n#Add one Dense layer\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\n\n#Add output layer\nprediction = tf.keras.layers.Dense(12,activation='softmax')(x)\n\n#Using Keras Model class\nfinal_model = tf.keras.models.Model(inputs=model2.input, #Pre-trained model input as input layer\n                                    outputs=prediction) #Output layer added\n\n#optimizer = optimizers.SGD(lr=0.0001, momentum=0.9)\nfinal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n","b21089a1":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nearly = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n","cdb1df22":"H = final_model.fit_generator(aug.flow(x_train, y_train, batch_size=BS), \n                                validation_data=(valX, valY), \n                                steps_per_epoch=len(x_train) \/\/ BS, \n                                epochs=EPOCHS, verbose=1,\n                                callbacks = [early])","ad4300bc":"predicted_probs2 = final_model.predict(testX, batch_size=10, verbose=1)\n\n#predicted_probs = model.predict_generator(test_generator(test_files), steps=len(test_files))\n#[f.split('\/')[3] for f in test_files]\npredicted_classes2 = np.argmax(predicted_probs2, axis=1)\nout_df = pd.DataFrame({'file':filenames , \n                       'species': labelEncoder.inverse_transform(predicted_classes2)})\nout_df.to_csv('submissionTL.csv', index=False)","19c4b956":"from matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\n\npyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\npyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\npyplot.title(\"Training \/Validation and Accuracy on  crop classification with Transfer Learning\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Accuracy\")\npyplot.legend(loc=\"lower left\")","9d5dd47f":"train_batches = aug.flow(x_train, y_train, batch_size=44)\nval_batches = aug.flow(valX, valX, batch_size=4)\n#test_batches = gen.flow(x_test, predictions, batch_size=16)\nN= steps_per_epoch=len(x_train) \/\/ BS\nmi = MixIterator([train_batches, val_batches],N)\n#model.fit_generator(mi, mi.N, nb_epoch=8, validation_data=(x_val, y_val))\n\nH = model.fit_generator(mi,\n                  validation_data=(valX, valY), \n                  steps_per_epoch=len(x_train) \/\/ BS, \n                  epochs=EPOCHS, \n                  verbose=1)\n\n","dd0b851b":"Trying Transfer Learning with Resnet","4e094961":"# Create a MixIterator object\n# This class is a simple method to create batches from several other batch generators\nclass MixIterator(object):\n    def __init__(self, iters,N):\n        self.iters = iters\n        self.N=N\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n        return (n0, n1)","b3fe5595":"model2 = tf.keras.applications.resnet50.ResNet50(include_top=False, #Do not include FC layer at the end\n                                          input_shape= inputShape,\n                                          weights='imagenet')\n\n#Set pre-trained model layers to not trainable\nfor layer in model.layers:\n    layer.trainable = False"}}