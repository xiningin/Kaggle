{"cell_type":{"c89618f0":"code","4bfd5aa8":"code","9c30be41":"code","d06d44a2":"code","c95fc4e8":"code","2cf72445":"code","6e11238d":"code","8eb47428":"code","9adf0e27":"code","feb0e985":"code","e48d2d4b":"code","5f931a0c":"code","34f463bd":"code","a16f755a":"markdown","0ff527a5":"markdown","a5816fee":"markdown","e7985bf9":"markdown","86f5a702":"markdown"},"source":{"c89618f0":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training XGBoost model\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error","4bfd5aa8":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)","9c30be41":"y = train['target']\nfeatures = train.drop(['target'], axis=1)\n\nfeatures.head()","d06d44a2":"# choose ordinal encode\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","c95fc4e8":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","2cf72445":"# paramaters\nn_estimators_test = [400, 800, 1200, 1600, 2000]\nlearning_rate_test = [0.01, 0.02, 0.03, 0.04, 0.05]\nearly_stopping_rounds_test = [1, 2, 3, 4, 5]","6e11238d":"def score_model(n=1000, l=0.01, e=5):\n    model = XGBRegressor(n_estimators=n, learning_rate=l, n_jobs=4, tree_method='gpu_hist')\n    # the data is large so n_jobs may work\n    model.fit(X_train, y_train,\n              early_stopping_rounds=e,\n              eval_set=[(X_valid, y_valid)],\n              verbose=False)\n    preds_valid = model.predict(X_valid)\n    return mean_squared_error(y_valid, preds_valid, squared=False)","8eb47428":"df_predict = pd.DataFrame(columns=['n_estimators', 'learning_rate', 'early_stopping_rounds', 'score'])","9adf0e27":"for n in n_estimators_test:\n    for l in learning_rate_test:\n        for e in early_stopping_rounds_test:\n            pred = score_model(n=n, l=l, e=e)\n            df_predict = df_predict.append(\n                {\"n_estimators\": n, \"learning_rate\": l, \"early_stopping_rounds\": e, \"score\": pred}, ignore_index=True)","feb0e985":"df_predict = df_predict.sort_values('score')","e48d2d4b":"df_predict.head()","5f931a0c":"# less n_estimators & less score\u3000is suitable, so I choose second one\nmodel = XGBRegressor(n_estimators=800, learning_rate=0.05, n_jobs=4, tree_method='gpu_hist')\nmodel.fit(X_train, y_train,\n            early_stopping_rounds=5,\n            eval_set=[(X_valid, y_valid)],\n            verbose=False)","34f463bd":"predictions = model.predict(X_test)\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","a16f755a":"## this is \n- I try to tune parameter of my XGboost model\n\n### disclaimer\u00b6\n- I'm a machine learning newbie\n- So if you find odd part in this notebook, please leave the comments.","0ff527a5":"## Load the data","a5816fee":"## Parameter tuning","e7985bf9":"## preprocessing","86f5a702":"- Then I try to find the suitable combination of some parameters\n- I test all combinations of below parameters and decide one that is the minimum RMSE"}}