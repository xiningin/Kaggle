{"cell_type":{"0edf5215":"code","b7c27539":"code","ab78fdae":"code","e1ea87e4":"code","9d701b01":"code","bd848293":"code","9d0a2b1a":"code","abd553ad":"code","9f441446":"code","9d25bd99":"code","bf0807d0":"code","786e4061":"code","8fea4434":"code","aca29de3":"code","ff7afe3e":"code","1141e0cc":"code","2639669a":"code","3f738002":"code","51761756":"code","b680d98f":"code","cf090975":"code","6b836c1e":"code","f8037a36":"code","d3ac8e66":"code","52e0e2d5":"code","52427edf":"code","4a9ed2fe":"code","4d7e3465":"code","aa70cf42":"code","215ea4ec":"code","4785caf1":"code","02c4ba09":"code","d05fe3ec":"code","6c5a2fed":"code","ddeee916":"code","8fd23ff3":"markdown","a81d676c":"markdown","b1bd8066":"markdown","e5fafa80":"markdown","2414da9b":"markdown","c36b73b1":"markdown","276b6d45":"markdown","708192e4":"markdown","9f66b7b4":"markdown","52d4e62a":"markdown","0a3c6837":"markdown","c49402e8":"markdown","b2d581cb":"markdown","2c0679a5":"markdown","a85215e2":"markdown"},"source":{"0edf5215":"SEED = 2311\n\nimport time\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.ensemble import ExtraTreesClassifier #estimator for feature importances\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import VarianceThreshold\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","b7c27539":"data_dir = '..\/input\/tabular-playground-series-nov-2021\/'","ab78fdae":"def compress(df):\n    numeric = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    \n    start_mem = df.memory_usage().sum() \/ (2 ** 20) #memory in MB\n    \n    for col in df.columns: \n        col_type = df[col].dtypes\n        \n        if col_type in numeric:\n            c_min, c_max = df[col].min(), df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    \n    end_mem = df.memory_usage().sum() \/ (2 ** 20)\n    percent_reduction = 100 * (start_mem - end_mem) \/ start_mem\n    \n    print(f'Memory usage decreased from {start_mem:5.2f} Mb to {end_mem:5.2f} Mb ({percent_reduction:.2f}% reduction)')\n    \n    return df","e1ea87e4":"%%time\ntrain = compress(pd.read_csv(data_dir + 'train.csv'))","9d701b01":"%%time\ntest = compress(pd.read_csv(data_dir + 'test.csv'))","bd848293":"train.head()","9d0a2b1a":"train.shape, test.shape","abd553ad":"gc.collect()","9f441446":"train['fold'] = -1","9d25bd99":"#chose to create 6 folds since we have 600k samples, nice and round 100k per fold\nN_SPLITS = 6\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X=train, y=train.target)):\n    train.loc[val_idx, 'fold'] = fold","bf0807d0":"train.head()","786e4061":"train.fold.value_counts()","8fea4434":"%%time\ntrain.to_csv('tps-nov21-6folds.csv', index=False)","aca29de3":"features = [f for f in train.columns if f not in ('id', 'target', 'fold')]","ff7afe3e":"gc.collect()","1141e0cc":"robust = ('robust', RobustScaler())\nquantile = ('quantile', QuantileTransformer())\nstandard = ('standard', StandardScaler())\nminmax = ('minmax', MinMaxScaler())\nnorm = ('norm', Normalizer())\n\nclf = ('lr', LogisticRegression(solver='liblinear', random_state=SEED))\n\nmodel_dict = {\n    1: Pipeline([robust, clf]),\n    2: Pipeline([quantile, clf]),\n    3: Pipeline([standard, clf]),\n    4: Pipeline([minmax, clf]),\n    5: Pipeline([norm, clf])\n}","2639669a":"def custom_cross_val_predict(train, test, features, model):\n    oof_preds = {}\n    test_preds = []\n    scores = []\n    \n    cv_start = time.time()\n    \n    for fold in range(N_SPLITS):\n        xtrain = train[train.fold != fold].reset_index(drop=True)\n\n        xval = train[train.fold == fold].reset_index(drop=True)    \n        val_idx = xval.id.values.tolist()\n        \n        fold_start = time.time()\n        \n        model.fit(xtrain[features], xtrain.target)        \n        val_preds = model.predict_proba(xval[features])[:,1] #out-of-fold predictions      \n        oof_preds.update(dict(zip(val_idx, val_preds)))\n        auc = roc_auc_score(xval.target, val_preds)\n        scores.append(auc)\n        \n        fold_end = time.time()\n        \n        print(f'Fold #{fold}: AUC = {auc:.5f}\\t[Time: {fold_end - fold_start:.2f} secs]')\n        \n        test_preds.append(model.predict_proba(test[features])[:,1])\n        \n    cv_end = time.time()\n    print(f'Average AUC = {np.mean(scores):.5f} with std. dev. = {np.std(scores):.5f}')\n    print(f'[Total time: {cv_end - cv_start:.2f} secs]')\n    \n    oof_preds = pd.DataFrame.from_dict(oof_preds, orient='index').reset_index()\n    test_preds = np.mean(np.column_stack(test_preds), axis=1)\n    \n    return oof_preds, test_preds\n","3f738002":"for model_id, model in model_dict.items():\n    print('----- MODEL-' + str(model_id) + ' -----')\n    \n    oof_preds, test_preds = custom_cross_val_predict(train, test, features, model)\n    \n    oof_preds.columns = ['id', 'oof' + str(model_id)] #extracting model number from model_dict key\n    oof_preds.to_csv('oof' + str(model_id) + '.csv', index=False)\n    \n    output = pd.DataFrame({'id': test.id, 'target': test_preds})\n    output.to_csv('submission' + str(model_id) + '.csv', index=False)","51761756":"!head submission1.csv","b680d98f":"#can be merged based on 'id' into meta-dataset for stacking model\n!head oof3.csv","cf090975":"model = model_dict[3] #StandardScaler() -> LogisticRegression()","6b836c1e":"gc.collect()","f8037a36":"vt_default_selector = VarianceThreshold().fit(train[features]) #default threshold = 0\nfeature_mask = vt_default_selector.get_support() #array of booleans \n\nfeature_mask[:10]","d3ac8e66":"#extracting list of selected features using the feature mask obtained from SelectFromModel\ndef get_selected_features(feature_mask, input_features):\n    return [b for a, b in zip(feature_mask, input_features) if a]","52e0e2d5":"vt_default_features = get_selected_features(feature_mask, features)\n\nvt_default_features[:5], vt_default_features[-5:], len(vt_default_features)","52427edf":"vt_custom_selector = VarianceThreshold(threshold=0.1).fit(train[features])\nfeature_mask = vt_custom_selector.get_support()\nvt_custom_features = get_selected_features(feature_mask, features)\nlen(vt_custom_features)","4a9ed2fe":"print(f'Dropped features: {sorted(list(set(features) - set(vt_custom_features)))}')","4d7e3465":"%%time\ntree_estimator = ExtraTreesClassifier(\n    n_estimators=150, \n    random_state=SEED\n)\n\ntree_estimator.fit(train[features], train.target)","aa70cf42":"tree_mean_selector = SelectFromModel(tree_estimator, prefit=True, threshold='mean')\nfeature_mask = tree_mean_selector.get_support()\ntree_mean_features = get_selected_features(feature_mask, features)\nlen(tree_mean_features)","215ea4ec":"tree_median_selector = SelectFromModel(tree_estimator, prefit=True, threshold='median')\nfeature_mask = tree_median_selector.get_support()\ntree_median_features = get_selected_features(feature_mask, features)\nlen(tree_median_features)","4785caf1":"%%time\nlinear_estimator = LinearSVC(C=0.5, penalty=\"l1\", dual=False, random_state=SEED)\nlinear_estimator.fit(train[features], train.target)","02c4ba09":"linear_mean_selector = SelectFromModel(linear_estimator, prefit=True, threshold='mean')\nfeature_mask = linear_mean_selector.get_support()\nlinear_mean_features = get_selected_features(feature_mask, features)\nlen(linear_mean_features)","d05fe3ec":"linear_median_selector = SelectFromModel(linear_estimator, prefit=True, threshold='median')\nfeature_mask = linear_median_selector.get_support()\nlinear_median_features = get_selected_features(feature_mask, features)\nlen(linear_median_features)","6c5a2fed":"feature_dict = {\n    6: vt_custom_features, #feature scaling models were numbered up to 5. \n    7: tree_mean_features,\n    8: tree_median_features,\n    9: linear_mean_features,\n    10: linear_median_features\n}","ddeee916":"for fid, features in feature_dict.items():\n    print('----- MODEL-' + str(fid) + ' -----')\n    \n    oof_preds, test_preds = custom_cross_val_predict(train, test, features, model)\n    \n    oof_preds.columns = ['id', 'oof' + str(fid)]\n    oof_preds.to_csv('oof' + str(fid) + '.csv', index=False)\n    \n    output = pd.DataFrame({'id': test.id, 'target': test_preds})\n    output.to_csv('submission' + str(fid) + '.csv', index=False)","8fd23ff3":"# Creating Folds  \nWill be using the same folds for cross validating all models here and in future notebooks.","a81d676c":"# Highlights  \n\n* Different preprocessing methods and their effect on performance and training time.\n* Feature selection methods with anonymous features.\n* Effect of reduced feature sets on model performance.\n* Framework for model evaluation - creating k-folds, pipelines, generating out-of-fold predictions for each model (if needed for stacking).  \n\nReferences:\n1. scikit-learn documentation\n2. [Kaggle's 30 days of ML](https:\/\/www.youtube.com\/playlist?list=PL98nY_tJQXZnP-k3qCDd1hljVSciDV9_N) youtube playlist by [Abhishek Thakur](https:\/\/www.kaggle.com\/abhishek). A must-watch for every beginner. The 'custom_cross_val_predict' function borrows heavily from the content discussed in the playlist.","b1bd8066":"**This was an experiment with feature preprocessing and selection.**  \n* I browsed the scikit-learn documentation and chose preprocessing methods which I thought would modify the data in noticeably different ways. You can do the same and choose from several other methods.  \n* My approach was the same for feature selection methods. The chosen methods gave different feature sets depending on their internal mechanism of feature importance. I evaluated the feature selection methods only after pruning the preprocessing experiment. You can choose otherwise.  \n* And finally, all the methods were evaluated with a single classifier (logistic regression). The wide variety of classifiers certainly does not need coverage, hence the lack of focus there. You can choose any other classifier to replicate the experiment.","e5fafa80":"Well, our performance has suffered. So what did we achieve?  \n\n* Our 'base model' i.e., Model-3 had an average AUC of 0.74852 and it used the complete dataset.\n* With half the data and in half the time, we have an average AUC of 0.73674 (Model-8)\n* With almost one-fourth the data and in almost one-fourth the time, we have an average AUC of 0.72691 (Model-7)\n\nWe gained time and memory for a slight hit to our performance.  \n(Or a very large hit, depending on your attachment to the public LB :D )","2414da9b":"# Imports","c36b73b1":"**Using [SelectFromModel](https:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html#feature-selection-using-selectfrommodel)**  \n\nThe estimator calculates feature importances and the transformer selects those above a certain threshold.","276b6d45":"**Using [VarianceThreshold](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.VarianceThreshold.html#sklearn-feature-selection-variancethreshold)**  \n\nLow variance features can be discarded since they will not have a significant effect on the target variable.","708192e4":"1. Applying QuantileTransformer (Model-2) and Normalizer (Model-5) resulted in a drop in performance.  \n2. Applying RobustScaler (Model-1), StandardScaler (Model-3) and MinMaxScaler (Model-4) gave nearly equal AUC but the training time is significantly less with StandardScaler. Our Logistic Regression classifier is able to fit faster when the data is centered (mean = 0) with unit variance.  \n\nBased on these results, **we will stick with StandardScaler for our model pipeline** when we experiment with different feature selection methods.  \n\nAnother point to remember is that this variation in performance may not hold for other datasets and classifiers. In case we see significant improvement in scores for a particular feature set after feature selection, we can come back to this step and experiment with preprocessing again.","9f66b7b4":"L1-based (linear model) feature selection","52d4e62a":"There are no zero-variance features in our original dataset. Hence, no features were discarded. Let us add a threshold to remove low-variance features.","0a3c6837":"# Preprocessing + Linear model pipelines","c49402e8":"Tree-based feature selection","b2d581cb":"**Function for reducing memory usage:** *compress*","2c0679a5":"**Time to submit!**  \n(The submission associated with the notebook will be for Model-3)\n\nThe folds dataset, out-of-fold predictions, and test predictions for all the models will be saved with the notebook.","a85215e2":"# [Feature Selection](https:\/\/en.wikipedia.org\/wiki\/Feature_selection)  \n\nMotivation - simplifying the models and reducing training times, by reducing the amount of data to be processed while maintaining relevant information  \nSince the features are anonymous, we cannot apply informed modifications. Thus, we will experiment with some feature selection methods based on the samples themselves.  \nFor different methods, we will end up with (hopefully) different subsets of features. We will evaluate them using the model we selected earlier and compare the performance with the results we have for the complete dataset.\n\nAnother branch of methods to reduce dimensions (a.k.a features) is [feature projection](https:\/\/en.wikipedia.org\/wiki\/Feature_extraction) (a.k.a feature extraction). They involve deriving new features from the original ones to transform the data into fewer dimensions. We will not be exploring these methods here."}}