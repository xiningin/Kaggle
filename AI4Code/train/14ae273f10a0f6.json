{"cell_type":{"b33281d6":"code","1bcd92ef":"code","2e6e73e5":"code","05535ad9":"code","52c9c034":"code","d08da423":"code","1b53a6e0":"code","d66fb9f8":"code","ac26cfc1":"code","85cd08e0":"code","e8c40224":"code","ad634678":"code","b0c532c0":"code","430b216f":"code","fc4d897a":"code","cf404953":"code","b6cf0231":"code","c58cbaac":"code","5a2286b9":"code","c6eed388":"code","8efce673":"code","1a989a7b":"code","12e8c49b":"code","7af9ea6d":"code","7ab7a39d":"code","8b948dff":"code","00060e78":"code","2f285871":"code","6742d6de":"code","5934a934":"code","93a5b60a":"code","a560b7f1":"code","70731ea1":"code","5a2d0211":"code","a67c3c70":"code","1ce3b37e":"markdown","290a89c9":"markdown","4c1e7e06":"markdown","c6f290d5":"markdown","094ef580":"markdown","81fb6400":"markdown","abf63c32":"markdown","962290b5":"markdown","61cd2c1b":"markdown","b2eb7898":"markdown","ff4858f4":"markdown","13143a92":"markdown","e96d8684":"markdown","6cc91a5e":"markdown","a9f2a117":"markdown","24bf1767":"markdown","ec3de472":"markdown","1bf36d6b":"markdown","4956557f":"markdown","6500b435":"markdown","f2fb2479":"markdown","2c479835":"markdown","2ae13f71":"markdown"},"source":{"b33281d6":"from os import environ\n\nTPU_ENABLED=False\nif environ.get('TPU_NAME') is not None:\n    TPU_ENABLED=True\n    \nprint(TPU_ENABLED)\n    ","1bcd92ef":"# TPU reqs\nif TPU_ENABLED:\n    !pip install -U tensorflow==2.7.0 -q\n    !pip install -U tensorflow-gcs-config -q\n    !pip install cloud-tpu-client -q\n\n    import tensorflow as tf \n    from cloud_tpu_client import Client\n    print(\"Update TPU server tensorflow version\u2026\")\n    Client().configure_tpu_version(tf.__version__)","2e6e73e5":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU\/GPU\/multi-GPU\/cluster-GPU detection code\nimport tensorflow as tf \n\nstrategy = tf.distribute.get_strategy()\n\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\n\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n    !nvidia-smi\n\nprint(\"Strategy: \", strategy)\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\nprint(\"Data mode tf: \", TPU_ENABLED)\nprint('Tensorflow   :', tf.__version__)","05535ad9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\nimport shutil\nfrom pathlib import Path\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","52c9c034":"!pip freeze > requirements.txt ","d08da423":"# \u0412 setup \u0432\u044b\u043d\u043e\u0441\u0438\u043c \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438: \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0435 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c.\n\nEPOCHS               = 10  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 4 * strategy.num_replicas_in_sync\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 15%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = \"..\/input\/\"\n!echo DATA_PATH=$DATA_PATH\nPATH = \"..\/working\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f\n!echo PATH=$PATH\n\n# Enable to make bucket replicas \nGENERATE_GCS_DATA=False","1b53a6e0":"# \u0423\u0441\u0442\u0430\u043d\u0430\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\nos.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","d66fb9f8":"!ls \/kaggle\/input\/\ntrain_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\nprint(train_df.head())\nprint(sample_submission.head())","ac26cfc1":"train_df.info()\nsample_submission.info()","85cd08e0":"train_df.Category.value_counts()\n# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0435 - \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e","e8c40224":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n\nprint(os.listdir(PATH))","ad634678":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=16)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(4,4, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","b0c532c0":"image = PIL.Image.open(PATH+'\/train\/0\/100380.jpg')\nprint(image.filename)\nimgplot = plt.imshow(image)\nplt.show()\n\nimage.size","430b216f":"def image_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    return tf.train.Feature(\n        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n    )\n\ndef bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n\ndef int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef create_example(image, path, example):\n    feature = {\n        \"image\": image_feature(image),\n        \"category\": int64_feature(example[\"Category\"]),\n        \"id\": bytes_feature(example[\"Id\"]),\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef parse_tfrecord_fn(example):\n    feature_description = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"category\": tf.io.FixedLenFeature([], tf.int64),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    return example","fc4d897a":"tfrecords_dir = \"tfrecords\"\n\nnum_samples = 4096\n\nprint(\"Let's make TFRecords!\\n\")\n\ndef make_tfrec(df, num_samples, images_source_path, tfrecords_dir):\n    Path(tfrecords_dir).mkdir(parents=True, exist_ok=True)\n    \n    num_tfrecords = len(df) \/\/ num_samples\n    if len(df) % num_samples:\n        num_tfrecords += 1  # add one record if there are any remaining samples\n    \n    for tfrec_num in range(num_tfrecords):\n        samples = df[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n#         print(samples)\n\n        with tf.io.TFRecordWriter(\n            tfrecords_dir + \"\/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n        ) as writer:\n            for index, row in samples.iterrows():\n                image_path = os.path.join(images_source_path, str(row['Category']), str(row['Id']))\n                with open(image_path, \"rb\") as local_file: # <= change here\n                    image = local_file.read()\n                image = tf.image.decode_jpeg(image, channels=3)\n                example = create_example(image, image_path, row)\n                writer.write(example.SerializeToString())\n                \ndef count_data_items(filenames):\n    import re\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nif GENERATE_GCS_DATA:\n    # MAKE TRAIN TFRec\n    make_tfrec(train_df, num_samples, os.path.join(PATH, 'train'), \"tfrecords\/train\")\n    test_dir = os.path.join(PATH, 'test_upload')\n\n    # MAKE TEST TFRec\n    # emulate train\/structure\n    with zipfile.ZipFile(os.path.join(DATA_PATH, 'test.zip')) as z:\n        z.extractall(os.path.join(test_dir)) \n    # Emulate Category = 0\n    shutil.move((os.path.join(test_dir, \"test_upload\")), (os.path.join(test_dir, \"0\")))\n\n    test_images_dir = os.path.join(test_dir, \"0\")\n    make_tfrec(sample_submission, num_samples, test_dir, \"tfrecords\/test\")","cf404953":"import glob\n\n!tree $tfrecords_dir\n# print(glob.glob(os.path.join(tfrecords_dir, 'train', \"*\")))\nprint(\"TRAIN records: \", count_data_items(glob.glob(os.path.join(tfrecords_dir, 'train', \"*\"))))\nprint(\"TEST records: \", count_data_items(glob.glob(os.path.join(tfrecords_dir, 'test', \"*\"))))","b6cf0231":"# Cloud Storage\nfrom google.cloud import storage\nfrom google.cloud.storage import Bucket\n\nclient = storage.Client(project='kaggle-335514')\nprint(list(client.list_buckets()))\nbucket_name = 'sf-dl-car-classification'\n\nif Bucket(client, bucket_name).exists() == False:\n    bucket = client.create_bucket(bucket_name)\n\ndef upload_files(bucket_name, source_folder, subfolder=\"\"):\n    import os.path\n    source_folder = os.path.join(source_folder, subfolder)\n    bucket = client.get_bucket(bucket_name)\n    for filename in os.listdir(source_folder):\n        if os.path.isdir(os.path.join(source_folder, filename)):\n            print(\"DIR: \", filename)\n            upload_files(bucket_name, source_folder, filename)\n        else:\n            blob = bucket.blob(os.path.join(subfolder, filename))\n            print(blob)\n            blob.upload_from_filename(os.path.join(source_folder, filename))\n    \n    return bucket.path\n\nif GENERATE_GCS_DATA:\n    upload_files(bucket_name, tfrecords_dir)\n\nprint(\"Files in bucket:\")\nfor blob in client.list_blobs(bucket_name):\n    print(blob.name)","c58cbaac":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\n\nfilenames = tf.io.gfile.glob(f\"gs:\/\/{bucket_name}\/train\/file*.tfrec\")\nprint(filenames[0])\n\nraw_dataset = tf.data.TFRecordDataset(filenames[0])\nparsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n\nplt.figure(figsize=(12,8))\n\nfor index, features in enumerate(parsed_dataset.take(16)):\n    image = features[\"image\"].numpy()\n    plt.subplot(4,4, index+1)\n    plt.imshow(image)\n    plt.title('Class: '+f\"{features['category']}\")\n    plt.axis('off')\nplt.show()","5a2286b9":"!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor -q","c6eed388":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\ntransforms = albumentations.Compose([\n    albumentations.Rotate(always_apply=False, p=0.5, limit=(-30, 30), interpolation=0, border_mode=4, value=(0, 0, 0), mask_value=None),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=1),\n    albumentations.GaussianBlur(p=0.5, blur_limit=(3, 21)),\n    albumentations.HueSaturationValue(hue_shift_limit=0.3, sat_shift_limit=0.3, val_shift_limit=0.3, p=0.3),\n    albumentations.RGBShift(p=0.25, r_shift_limit=0.2, g_shift_limit=0.2, b_shift_limit=0.2),\n])","8efce673":"# TFRecordSet\ndef augment_sample(image, other):\n    image = tf.numpy_function(func=numpy_augment, inp=[image], Tout=tf.float32)\n\n    return image, other\n\ndef numpy_augment(image):\n    \n#     image = tf.cast(x=image, dtype=tf.float32).numpy()\n    image = transforms(image=image)['image']\n    image = tf.cast(image\/255.0, tf.float32)\n    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n    \n    return image\n\ndef prepare_sample(features, labeled=True):\n    image = features[\"image\"]\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, size=(IMG_SIZE, IMG_SIZE))\n    if labeled:\n        return image, tf.one_hot(features[\"category\"], CLASS_NUM) #features[\"category\"]\n    else:\n        return image, features[\"id\"]\n\ndef get_dataset(filenames, batch_size, shuffle=True, labeled=True, augment=False):\n    dataset = (tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n               .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n               .map(lambda x: prepare_sample(x, labeled=labeled), num_parallel_calls=AUTOTUNE)\n                )\n    \n    if augment:\n        dataset = (dataset.map(augment_sample, num_parallel_calls=AUTOTUNE))\n\n    if shuffle:\n        dataset = dataset.shuffle(batch_size * 10, reshuffle_each_iteration=False)\n        \n    dataset = (dataset.batch(batch_size)\n               .prefetch(AUTOTUNE))\n    \n    return dataset\n\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_filenames = tf.io.gfile.glob(f\"gs:\/\/{bucket_name}\/train\/file*.tfrec\")\nprint(\"Train TF: \\n\",train_filenames)\nall_dataset = get_dataset(train_filenames, BATCH_SIZE, augment=True)\n\n# Divide Train\/Validation\n\ndef is_val(x, y):\n    return x % 100 < int(VAL_SPLIT * 100)\n\ndef is_train(x, y):\n    return not is_val(x, y)\n\nrecover = lambda x,y: y\n\ntrain_dataset = all_dataset.enumerate() \\\n                    .filter(is_train) \\\n                    .map(recover) \\\n                    .repeat()\n\nval_dataset = all_dataset.enumerate() \\\n                    .filter(is_val) \\\n                    .map(recover) \\\n                    .repeat()\n\ntest_filenames = tf.io.gfile.glob(f\"gs:\/\/{bucket_name}\/test\/file*.tfrec\")\nprint(\"Test TF: \\n\",test_filenames)\ntest_dataset = get_dataset(test_filenames, BATCH_SIZE, shuffle=False, labeled=False)","1a989a7b":"TRAIN_COUNT = count_data_items(train_filenames)\n\nlst = [1] * TRAIN_COUNT\nVAL_COUNT = 0\nfor idx, val in enumerate(lst):\n    if is_val(idx, 0):\n        VAL_COUNT += 1\n\nTRAIN_COUNT -= VAL_COUNT\nTEST_COUNT = count_data_items(test_filenames)\n\nprint(\"TRAIN_COUNT: \", TRAIN_COUNT)\nprint(\"VAL_COUNT: \", VAL_COUNT)\nprint(\"TEST_COUNT: \", TEST_COUNT)\n\n# COUNT. This takes time...\n# count = 0\n# for element in train_dataset.as_numpy_iterator():\n#     count += 1\n#     print(count)\n# #       print(element)\n# print(\"Count :\", count)","12e8c49b":"# Plot sample\ndef view_image(ds):\n\n    plt.figure(figsize=(12,8))\n    \n    for index, record in enumerate(ds.take(16)):\n        image = record[0].numpy()\n        label = record[1].numpy()\n        plt.subplot(4,4, index+1)\n        plt.imshow(image)\n#         plt.title('Class: '+f\"{label}\")\n        plt.axis('off')\n#         print(image.shape, label.shape)\n    plt.show()\n    \nprint(\"TRAIN\")\nview_image(train_dataset.unbatch())\n\n# print(\"VAL\")\n# view_image(val_dataset.unbatch())\n\n# print(\"TEST\")\n# view_image(test_dataset.unbatch())","7af9ea6d":"with strategy.scope():\n    base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    # let's add a fully-connected layer\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.25)(x)\n    # and a logistic layer -- let's say we have 10 classes\n    predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n    # this is the model we will train\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","7ab7a39d":"# model.summary()\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c Batch Normalization","8b948dff":"checkpoint = ModelCheckpoint('best_model.hdf5', monitor = ['val_accuracy'], verbose = 1, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f 1. \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0438\u0437 https:\/\/keras.io\/callbacks\/\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f 2. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate\n# https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n# http:\/\/teleported.in\/posts\/cyclic-learning-rate\/ (eng)","00060e78":"%%time\n\nSTEPS_PER_EPOCH = TRAIN_COUNT \/\/ BATCH_SIZE\n\n# tf.keras.backend.clear_session()\nhistory = model.fit(\n    x=train_dataset,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    validation_data = val_dataset, \n    validation_steps = STEPS_PER_EPOCH,\n    epochs=EPOCHS,\n    callbacks = callbacks_list,\n#     verbose=1,\n)\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c transfer learning \u0441 fine-tuning","2f285871":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\nmodel.save('..\/working\/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","6742d6de":"%%time\nscores = model.evaluate(val_dataset,\n                        steps=121,\n#                         verbose=1\n                       )\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","5934a934":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","93a5b60a":"predictions = model.predict(test_dataset.map(lambda image, idnum: image), 121, verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","a560b7f1":"test_images_dir = os.path.join(test_dir, \"0\")\n\nprint(\"Test Images: \", len(os.listdir(test_images_dir)))\nprint(\"Predictions: \", len(predictions))","70731ea1":"test_ids_ds = test_dataset.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(6675))).numpy().astype('U')\nprint(test_ids[:10])","5a2d0211":"submission = pd.DataFrame({'Id':test_ids, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c Test Time Augmentation (TTA)\n# https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","a67c3c70":"submission.head()","1ce3b37e":"## Check sample","290a89c9":"### \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 BETTER AUG","4c1e7e06":"# \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438","c6f290d5":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","094ef580":"## TPU Setup","81fb6400":"\u0412 \u0418\u0442\u043e\u0433\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 93%. \n\u0423\u0447\u0438\u0442\u044b\u0432\u0430\u044f \u0447\u0442\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 10 - \u044d\u0442\u043e \u041e\u0447\u0435\u043d\u044c \u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442!     \n\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f:","abf63c32":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint \u0447\u0442\u043e\u0431 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c.","962290b5":"## \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","61cd2c1b":"## Transfer to GCS","b2eb7898":"\u041e\u0431\u0443\u0447\u0430\u0435\u043c:","ff4858f4":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438 \u0438\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u0438\u043c\u0430\u0442\u044c \u043a\u0430\u043a \u0438\u0445 \u043b\u0443\u0447\u0448\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0438 \u0441\u0436\u0438\u043c\u0430\u0442\u044c.","13143a92":"## \u0418\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e, \u043a \u043a\u0430\u043a\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0442\u043d\u0435\u0441\u0435\u0442 \u0432\u043e\u0442 \u044d\u0442\u0438 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0438?","e96d8684":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","6cc91a5e":"**\u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 Tensorflow v2**","a9f2a117":" ## TFRECORD","24bf1767":"* \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u0435 transfer learning \u0441 fine-tuning\n* \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u0442\u0435 LR, optimizer, loss\n* \u041f\u043e\u0434\u0431\u0435\u0440\u0438\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u0431\u0430\u0442\u0447 \u0438 \u0442.\u0434.)\n* \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439 (\u0430 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e Xception) \u0438\u043b\u0438 \u0438\u0445 \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u0438. \u041f\u0440\u0438\u043c\u0435\u0440\u044b SOTA \u043d\u0430 ImageNet  \n* \n* \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 Batch Normalization \u0438 \u043f\u043e\u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0439\u0442\u0435 \u0441 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043e\u0439 \u201c\u0433\u043e\u043b\u043e\u0432\u044b\u201d\n* \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback Keras https:\/\/keras.io\/callbacks\/ \n* \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 TTA (Test Time Augmentation)\n* \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e*: \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate (https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http:\/\/teleported.in\/posts\/cyclic-learning-rate\/ (eng))\n* \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e*: \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, Albumentations )\n\n### \u0423\u0434\u0430\u0447\u0438 \u0432 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438!","ec3de472":"### \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c Xception:","1bf36d6b":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","4956557f":"> \u042d\u0442\u043e \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c Keras. \u0412\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u043e\u0442 \u043a\u0435\u0440\u043d\u0435\u0440 \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u0445 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0439 \u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432.\n# \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f \u044d\u0442\u043e\u0433\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f: \u0432\u0437\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 ImageNet \u0441\u0435\u0442\u044c Xception \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443. \n\u041f\u043e \u0445\u043e\u0434\u0443 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0434\u0430\u0432\u0430\u0442\u044c \u0432\u0430\u043c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043c\u043e\u0433\u0443\u0442 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438. \n\n\n\u0423\u0434\u0430\u0447\u0438 \u0438 \u041f\u043e\u0435\u0445\u0430\u043b\u0438!","6500b435":"### \u0423\u0436\u0435 \u0434\u043e\u0433\u0430\u0434\u044b\u0432\u0430\u0435\u0442\u0435\u0441\u044c, \u0447\u0442\u043e \u043e\u0437\u043d\u0430\u0447\u0430\u044e\u0442 \u043a\u043b\u0430\u0441\u0441\u044b?","f2fb2479":"# \u0427\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c, \u0447\u0442\u043e\u0431\u044b \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442:","2c479835":"\n# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","2ae13f71":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445"}}