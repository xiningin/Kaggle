{"cell_type":{"1aa7bf60":"code","47db2ea4":"code","df6d3a34":"code","719d1aef":"code","ed6d5e2e":"code","61a82bdd":"code","358d8341":"code","c4dd9ecd":"code","15e74465":"code","c85f0db9":"code","7e2ec685":"code","6ea1029e":"code","199d56a5":"code","72531f96":"markdown"},"source":{"1aa7bf60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47db2ea4":"X = tf.range(10)\ndataset = tf.data.Dataset.from_tensor_slices(X)\ndataset","df6d3a34":"for item in dataset:\n    print(item)","719d1aef":"dataset = dataset.repeat(3).batch(7)\nfor item in dataset:\n    print(item)","ed6d5e2e":"dataset = dataset.map(lambda x: x * 2)","61a82bdd":"dataset = dataset.apply(tf.data.experimental.unbatch())","358d8341":"dataset = dataset.filter(lambda x: x < 10)","c4dd9ecd":"for item in dataset.take(3):\n    print(item)","15e74465":"dataset = tf.data.Dataset.range(10).repeat(3)\ndataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\nfor item in dataset:\n    print(item)","c85f0db9":"with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n    f.write(b\"This is the first record\")\n    f.write(b\"And this is the second record\")","7e2ec685":"filepaths = [\"my_data.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filepaths)\nfor item in dataset:\n    print(item)","6ea1029e":"options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\nwith tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n    f.write(b\"This is the first record\")\n    f.write(b\"And this is the second record\")","199d56a5":"dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n                                  compression_type=\"GZIP\")","72531f96":"THIS NOTEBOOK FOLLOWS CHAPTER 13 OF Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition\n"}}