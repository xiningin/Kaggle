{"cell_type":{"1e42ae70":"code","c1f541d1":"code","33d6583b":"code","d838ae8f":"code","78ce4c3e":"code","311ef921":"code","29d5f2d1":"code","b3c8e268":"code","ed8f0539":"code","3172108f":"code","4ae31258":"code","a7be6f9c":"code","b6aa7568":"code","3d9ac459":"code","326f5890":"code","e0e7cc84":"code","d0c8f992":"code","4d07a393":"markdown","ed5c6766":"markdown","b827ecf2":"markdown","42ec62a9":"markdown"},"source":{"1e42ae70":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport torch\nimport importlib\nimport cv2 \nimport pandas as pd\n\nfrom PIL import Image\nfrom IPython.display import display","c1f541d1":"# download required packages - first time when I created database (https:\/\/www.kaggle.com\/remekkinas\/yolox-cots-models) with required moduls for YOLOX\n# don't use this section of code until Kaggle doesn't change something in the environment (!!)\n\n\n#%mkdir \/kaggle\/working\/yolox-dep\n#!pip download pip -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download loguru -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download ninja -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download onnx==\"1.8.1\" -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download onnxruntime==\"1.8.0\" -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download onnxoptimizer>=\"0.2.5\" -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download thop -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download tabulate -d \"\/kaggle\/working\/yolox-dep\"\n#!pip download onnx-simplifier==0.3.5 -d \"\/kaggle\/working\/yolox-dep\"","33d6583b":"# Copy YOLOX and required modules from local repository (Kaggle dataset -> https:\/\/www.kaggle.com\/remekkinas\/yolox-cots-models)\n%cp -r \/kaggle\/input\/yolox-cots-models \/kaggle\/working\/\n%cp -r \/kaggle\/input\/reff-model\/best_ckpt.pth \/kaggle\/working\/yolox-cots-models\/YOLOX\n%cd \/kaggle\/working\/yolox-cots-models\/yolox-dep","d838ae8f":"# Install YOLOX required modules\n\n!pip install pip-21.3.1-py3-none-any.whl -f .\/ --no-index\n!pip install loguru-0.5.3-py3-none-any.whl -f .\/ --no-index\n!pip install ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl -f .\/ --no-index\n!pip install onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl -f .\/ --no-index\n!pip install onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -f .\/ --no-index\n!pip install onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl -f .\/ --no-index\n!pip install thop-0.0.31.post2005241907-py3-none-any.whl -f .\/ --no-index\n!pip install tabulate-0.8.9-py3-none-any.whl -f .\/ --no-index\n#!pip install onnx-simplifier-0.3.6.tar.gz -f .\/ --no-index","78ce4c3e":"# Install YOLOX\n%cd \/kaggle\/working\/yolox-cots-models\/YOLOX\n!pip install -r requirements.txt\n!pip install -v -e . ","311ef921":"# Install CocoAPI tool\n%cd \/kaggle\/working\/yolox-cots-models\/yolox-dep\/cocoapi\/PythonAPI\n\n!make\n!make install\n!python setup.py install","29d5f2d1":"import pycocotools","b3c8e268":"%cd \/kaggle\/working\/yolox-cots-models\/YOLOX\n\nCHECKPOINT_FILE = 'best_ckpt.pth'","ed8f0539":"# config_file_template = '''\n\n# #!\/usr\/bin\/env python3\n# # -*- coding:utf-8 -*-\n# # Copyright (c) Megvii, Inc. and its affiliates.\n\n# import os\n\n# from yolox.exp import Exp as MyExp\n\n\n# class Exp(MyExp):\n#     def __init__(self):\n#         super(Exp, self).__init__()\n#         self.depth = 1\n#         self.width = 1\n#         self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n#         self.num_classes = 1\n\n# '''\n\nconfig_file_template = '''\n\n#!\/usr\/bin\/env python3\n# -*- coding:utf-8 -*-\n# Copyright (c) Megvii, Inc. and its affiliates.\n\nimport os\n\nfrom yolox.exp import Exp as MyExp\n\n\nclass Exp(MyExp):\n    def __init__(self):\n        super(Exp, self).__init__()\n        self.depth = 1\n        self.width = 1\n        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n        \n        # Define yourself dataset path\n        self.data_dir = \"dataset\/images\"\n        self.train_ann = \"train.json\"\n        self.val_ann = \"valid.json\"\n\n        self.num_classes = 1\n\n        self.max_epoch = 20\n        self.data_num_workers = 2\n        self.eval_interval = 1\n        \n        self.mosaic_prob = 1.0\n        self.mixup_prob = 1.0\n        self.hsv_prob = 1.0\n        self.flip_prob = 0.5\n        self.no_aug_epochs = 2\n        \n        self.input_size = (800, 1280)\n        self.mosaic_scale = (0.5, 1.5)\n        self.random_size = (10, 20)\n        self.test_size = (800, 1280)\n\n'''\n\nwith open('cots_config5.py', 'w') as f:\n    f.write(config_file_template)","3172108f":"from yolox.utils import postprocess\nfrom yolox.data.data_augment import ValTransform\n\nCOCO_CLASSES = (\n  \"starfish\",\n)\n\n# get YOLOX experiment\ncurrent_exp = importlib.import_module('cots_config5')\nexp = current_exp.Exp()\nprint(exp)\n# set inference parameters\ntest_size = (800, 1280)\nnum_classes = 1\nconfthre = 0.1\nnmsthre = 0.45\n\n\n# get YOLOX model\nmodel = exp.get_model()\nmodel.cuda()\nmodel.eval()\n\n# get custom trained checkpoint\nckpt_file = \"best_ckpt.pth\"\nckpt = torch.load(ckpt_file, map_location=\"cpu\")\nmodel.load_state_dict(ckpt[\"model\"])","4ae31258":"def yolox_inference(img, model, test_size): \n    bboxes = []\n    bbclasses = []\n    scores = []\n    \n    preproc = ValTransform(legacy = False)\n\n    tensor_img, _ = preproc(img, None, test_size)\n    tensor_img = torch.from_numpy(tensor_img).unsqueeze(0)\n    tensor_img = tensor_img.float()\n    tensor_img = tensor_img.cuda()\n\n    with torch.no_grad():\n        outputs = model(tensor_img)\n        outputs = postprocess(\n                    outputs, num_classes, confthre,\n                    nmsthre, class_agnostic=True\n                )\n\n    if outputs[0] is None:\n        return [], [], []\n    \n    outputs = outputs[0].cpu()\n    bboxes = outputs[:, 0:4]\n\n    bboxes \/= min(test_size[0] \/ img.shape[0], test_size[1] \/ img.shape[1])\n    bbclasses = outputs[:, 6]\n    scores = outputs[:, 4] * outputs[:, 5]\n    \n    return bboxes, bbclasses, scores","a7be6f9c":"def draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, classes_dict):\n    for i in range(len(bboxes)):\n            box = bboxes[i]\n            cls_id = int(bbclasses[i])\n            score = scores[i]\n            if score < confthre:\n                continue\n            x0 = int(box[0])\n            y0 = int(box[1])\n            x1 = int(box[2])\n            y1 = int(box[3])\n\n            cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), 2)\n            cv2.putText(img, '{}:{:.1f}%'.format(classes_dict[cls_id], score * 100), (x0, y0 - 3), cv2.FONT_HERSHEY_PLAIN, 0.8, (0,255,0), thickness = 1)\n    return img","b6aa7568":"TEST_IMAGE_PATH = \"\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/9674.jpg\"\nimg = cv2.imread(TEST_IMAGE_PATH)\ndef RecoverHE(sceneRadiance):\n    for i in range(3):\n        sceneRadiance[:, :, i] =  cv2.equalizeHist(sceneRadiance[:, :, i])\n    return sceneRadiance\nimg=RecoverHE(img)\n# Get predictions\nbboxes, bbclasses, scores = yolox_inference(img, model, test_size)\n\n# Draw predictions\nout_image = draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, COCO_CLASSES)\n\n# Since we load image using OpenCV we have to convert it \nout_image = cv2.cvtColor(out_image, cv2.COLOR_BGR2RGB)\ndisplay(Image.fromarray(out_image))","3d9ac459":"%cd \/kaggle\/working\/","326f5890":"import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()  ","e0e7cc84":"submission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image_np, sample_prediction_df) in iter_test:\n    image_np=RecoverHE(image_np[:,:,::-1])\n    bboxes, bbclasses, scores = yolox_inference(image_np, model, test_size)\n    \n    predictions = []\n    for i in range(len(bboxes)):\n        box = bboxes[i]\n        cls_id = int(bbclasses[i])\n        score = scores[i]\n        if score < confthre:\n            continue\n        x_min = int(box[0])\n        y_min = int(box[1])\n        x_max = int(box[2])\n        y_max = int(box[3])\n        \n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n        \n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    \n    prediction_str = ' '.join(predictions)\n    sample_prediction_df['annotations'] = prediction_str\n    env.predict(sample_prediction_df)\n\n    print('Prediction:', prediction_str)","d0c8f992":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","4d07a393":"## SUBMIT PREDICTION TO COMPETITION","ed5c6766":"### TEST MODEL - MAKE INFERENCE ON SAMPLE DATA\n","b827ecf2":"<div class=\"alert alert-success\" role=\"alert\">\n    Find this notebook helpful? :) Please give me a vote ;) Thank you\n <\/div>","42ec62a9":"### INSTALL YOLOX \n<div class=\"alert alert-warning\" role=\"alert\"><strong>It unfortunately requires a lot of Kaggle enviroment hacking :) due to competition limitation - no internet access during submission.<\/strong><\/div>"}}