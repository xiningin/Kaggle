{"cell_type":{"0fc9fbe2":"code","d23f8a4f":"code","590a9a40":"code","d1d19089":"code","2c55e917":"code","8a2de957":"code","cc687945":"code","ac1e0f2c":"code","e7794166":"code","6c864a00":"code","77d68498":"code","e90094f5":"code","141e4d14":"code","d44cbb2e":"code","808312bf":"code","f60e2e14":"code","2cd9e8a5":"code","1c7a6ecc":"code","cc3d6bca":"code","038b18e5":"code","4c5f06e7":"code","3a2cd9d4":"code","f320e5ce":"code","ab456258":"code","4c86f467":"code","7cb534c3":"code","1e7aea9b":"code","783a9874":"code","f5e90358":"code","28eba74e":"code","55727632":"code","9887857a":"code","9315a5be":"code","cec3813c":"code","38a39771":"code","b79ea952":"code","c5f06a75":"code","47f88f73":"code","cb31c6f4":"code","cd6829ce":"code","ab545cea":"code","3c9f7b5f":"code","5b790daa":"code","60b033b7":"code","f4f49e9e":"code","9a252d46":"markdown","a4f7ff7a":"markdown","995f9ee5":"markdown","48cc29d4":"markdown","e0431518":"markdown","520d60e9":"markdown","e5cf589d":"markdown","36e26f82":"markdown","09d058ea":"markdown","dca1ca00":"markdown","41a9a507":"markdown","9c00ad78":"markdown","6544dc05":"markdown","62e00707":"markdown","778e0314":"markdown","764f4589":"markdown","842ed707":"markdown","e28c0c0e":"markdown","beffd9b9":"markdown","043730c0":"markdown"},"source":{"0fc9fbe2":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set3')\n\nimport cv2\nimport gc\n\nimport itertools\nimport collections\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords\n\nimport re\nfrom wordcloud import WordCloud\n\nimport os\nprint(os.listdir('\/kaggle\/input\/shopee-product-matching\/'))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter('ignore')","d23f8a4f":"base_dir = '\/kaggle\/input\/shopee-product-matching\/'","590a9a40":"train = pd.read_csv(base_dir + 'train.csv')\nprint(train.shape)\ntrain.head()","d1d19089":"test = pd.read_csv(base_dir + 'test.csv')\nprint(test.shape)\ntest.head()","2c55e917":"sub = pd.read_csv(base_dir + 'sample_submission.csv')\nprint(sub.shape)\nsub.head()","8a2de957":"print(f'Number of train images: {len(os.listdir(base_dir + \"train_images\/\"))}')\nprint(f'Number of test images: {len(os.listdir(base_dir + \"test_images\/\"))}')","cc687945":"train.info()","ac1e0f2c":"train['image_path'] = base_dir + 'train_images\/' + train['image']\ntest['image_path'] = base_dir + 'test_images\/' + test['image']\ndisplay(train.head(), test.head())","e7794166":"tmp = train.groupby('label_group')['posting_id'].agg('unique').to_dict()\ntrain['target'] = train['label_group'].map(tmp)\ntrain.head(2)","6c864a00":"def get_f1metric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row.target, row[col]))\n        return 2 * n \/ (len(row.target) + len(row[col]))\n    return f1score","77d68498":"#To calculate F1 score - local\ntmp = train.groupby('image_phash')['posting_id'].agg('unique').to_dict()\ntrain['oof'] = train['image_phash'].map(tmp)\ntrain.head(2)","e90094f5":"train['f1_base'] = train.apply(get_f1metric('oof'), axis = 1)\nprint(f\"Train F1 Score: {train['f1_base'].mean()}\")","141e4d14":"def display_images(paths, rows, cols, title = None):\n    fig, ax = plt.subplots(rows, cols, figsize = (16, 12))\n    ax = ax.flatten()\n    for i, path in enumerate(image_paths):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        ax[i].set_title(img.shape)\n        ax[i].imshow(img)\n        ax[i].grid(False)\n    if title:\n        plt.suptitle(title, fontsize = 15, y = 1.0)","d44cbb2e":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3, 'Display Random Train Images')","808312bf":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3)","f60e2e14":"image_paths = test['image_path'].values\ndisplay_images(image_paths, 1, 3)","2cd9e8a5":"train['label_group'].value_counts()","1c7a6ecc":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 3627744656].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","cc3d6bca":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 994676122].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","038b18e5":"image_paths = train['image_path'][train['label_group'] == 1615893885].values\ndisplay_images(image_paths, 1, 2, 'Train Images with least frequent label group')","4c5f06e7":"plt.title('Distribution of trainset title length')\nsns.histplot(train['title'].apply(lambda x: len(x)), kde = True);","3a2cd9d4":"print(f'Number of unqiue titles in trainset: {train[\"title\"].nunique()}')","f320e5ce":"train['title_len'] = train['title'].apply(lambda x: len(x))\ntest['title_len'] = test['title'].apply(lambda x: len(x))\n\nprint(f'Max. train title length: {train[\"title_len\"].max()}')\nprint(f'Min. train title length: {train[\"title_len\"].min()}')","ab456258":"def plot_wordcloud(data, senti = None, text = None):\n    stop = stopwords.words('english')\n    all_words = [word for each in data['title'] for word in each.split() if word not in stop]\n    word_freq = Counter(all_words)\n\n    wordcloud = WordCloud(width = 900,\n                          height = 500,\n                          max_words = 200,\n                          max_font_size = 100,\n                          relative_scaling = 0.5,\n                          background_color = \"rgba(255, 255, 255, 0)\", \n                          mode = \"RGBA\",\n                          normalize_plurals = True).generate_from_frequencies(word_freq)\n    plt.figure(figsize = (16, 12))\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.title(text)\n    plt.axis(\"off\")\n    plt.show()","4c86f467":"plot_wordcloud(train, text = 'Train Title WordCloud')","7cb534c3":"train['title'].value_counts()","1e7aea9b":"t = 'Koko syubbanul muslimin koko azzahir koko baju'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","783a9874":"t = 'Emina Glossy Stain'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","f5e90358":"t = 'Viva Air Mawar'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","28eba74e":"#For submission test set will be replaced with bigger dataset\nif len(test) == 3:\n    df = train\n    img_dir = '..\/input\/shopee-product-matching\/train_images\/'\n    print(df.shape)\nelse:\n    df = test\n    img_dir = '..\/input\/shopee-product-matching\/test_images\/'\n    print(df.shape)","55727632":"import tensorflow as tf\n\nfrom tensorflow.keras.applications import EfficientNetB0\n\nprint(f'Tensorflow version: {tf.__version__}')","9887857a":"class ImageDataGen(tf.keras.utils.Sequence):\n    def __init__(self, img_path, data, batch_size, \n                 dim, shuffle = False):\n        self.dim  = dim\n        self.data = data\n        self.shuffle  = shuffle\n        self.img_path = img_path\n        self.batch_size = batch_size\n        self.list_idx = self.data.index.values\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(float(len(self.data)) \/ float(self.batch_size)))\n    \n    def __getitem__(self, index):\n        batch_idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        \n        idx = [self.list_idx[k] for k in batch_idx]\n        \n        Data   = np.zeros((len(batch_idx), self.dim, self.dim, 3), dtype = 'float32')\n        \n        for i, k in enumerate(idx):\n            # load the image file using cv2\n            image = cv2.imread(self.img_path + self.data['image'][k])\n            image = cv2.resize(image, (self.dim, self.dim))\n            \n            # assign \n            Data[i, ] =  image\n            \n        return Data\n    \n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.list_idx))\n        if self.shuffle:\n            np.random.shuffle(self.indices)","9315a5be":"def plot_images(dataset, row, col):\n    plt.rcParams['figure.figsize'] = 20, 10\n    for i in range(row):\n        f, ax = plt.subplots(1, col)\n        for p in range(col):\n            idx = np.random.randint(0, len(dataset))\n            img = dataset[idx]\n            ax[p].grid(False)\n            ax[p].axis('off')\n            ax[p].imshow(img[0].astype('uint8'))\n    plt.show()\n    \ntraingen = ImageDataGen(img_dir, df, batch_size = 32, dim = 256)\nplot_images(traingen, 3, 3)\n\ndel traingen\ngc.collect()","cec3813c":"weights = '..\/input\/tfkeras-efficientnet-weights\/efficientnetb0_notop.h5'\n\nmodel = EfficientNetB0(weights = weights, include_top = False, pooling = 'avg', input_shape = None)","38a39771":"def chunker(data, size):\n    return (data[start: start + size] for start in range(0, len(data), size))","b79ea952":"%%time\nchunk_size = 4096\nembeddings = []\n\nfor k, chunk in enumerate(chunker(df, chunk_size)):\n    print(f'Chunk: {k + 1}')\n    datagen = ImageDataGen(img_dir, chunk, batch_size = 128, dim = 256)\n    img_embed = model.predict(datagen, verbose = 1)\n    embeddings.append(img_embed)\n    \nimage_embeddings = np.concatenate(embeddings)\nprint(f'Train Image Embeddings shape: {image_embeddings.shape}')\n\ngc.collect()","c5f06a75":"from sklearn.neighbors import NearestNeighbors","47f88f73":"n = 50\nnn = NearestNeighbors(n_neighbors = n)\nnn.fit(image_embeddings)\n#distances, indices = nn.kneighbors(image_embeddings)","cb31c6f4":"%%time\n#chunk_size = 4096\npreds = []\n\nfor k, chunk in enumerate(chunker(image_embeddings, chunk_size)):\n    print(f'Chunk: {k + 1}')\n    distances, indices = nn.kneighbors(chunk)\n    for i in range(len(chunk)):\n        dists = np.where(distances[i,] < 6.0)[0]\n        idx = indices[i, dists]\n        post_ids = df['posting_id'].iloc[idx].values\n        preds.append(post_ids)\n\nprint(len(preds))\ngc.collect()","cd6829ce":"df['matches'] = preds\ndf['num_similar_img'] = df['matches'].apply(lambda x: len(x))\ndf.head()","ab545cea":"from textwrap import wrap\n\ndef plot_similar():\n    while(True):\n        pid = np.random.choice(df['posting_id'].values, 1)\n        pred_ids = df['matches'][df['posting_id'] == pid[0]].values[0]\n        #print(pred_ids)\n        if len(pred_ids) > 1:\n            break\n\n    if len(pred_ids) > 7:\n        col = 6\n    else:\n        col = len(pred_ids)\n    fig, ax = plt.subplots(1, col, figsize = (10, 4))\n\n    for i, ids in enumerate(pred_ids[:col]):\n        path = df['image_path'][df['posting_id'] == ids].values[0]\n        title = df['title'][df['posting_id'] == ids].values[0]\n        img = cv2.imread(path)\n        ax[i].imshow(img)\n        ax[i].set_title(\"\\n\".join(wrap(title, 30)), fontsize = 10)\n        ax[i].grid(False)\n        ax[i].axis('off')","3c9f7b5f":"plot_similar()\nplot_similar()","5b790daa":"#To calculate F1 score - local\ntmp = df.groupby('label_group')['posting_id'].agg('unique').to_dict()\ndf['target'] = df['label_group'].map(tmp)\ndf['f1_img'] = df.apply(get_f1metric('matches'), axis = 1)\nprint(f\"CV Score: {df['f1_img'].mean()}\")","60b033b7":"df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\nsubs = pd.read_csv('submission.csv')\nsubs.head()","f4f49e9e":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","9a252d46":"__Define model to extract embeddings__","a4f7ff7a":"__Display Images with same title__","995f9ee5":"__Display similar images__","48cc29d4":"# Evaluation Metric\n\n__Submissions will be evaluated based on their mean F1 score.__","e0431518":"__Check Images have loaded correctly__","520d60e9":"__Title Text WordCloud__","e5cf589d":"- Since GPU Notebook should < 2 hours, we chunk the inout data to speed up ","36e26f82":"Thanks to Chris @cdeotte for his great works and sharing the knowledge!!","09d058ea":"# Competition Goal\n\n__In this competition, you\u2019ll apply your machine learning skills to build a model that predicts which items are the same products.__","dca1ca00":"# Submission","41a9a507":"# Code Requirements\n\nSubmissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n\n- CPU Notebook <= 9\n- GPU Notebook <= 2\n- Internet access disabled\n- Freely & publicly available external data is allowed, including pre-trained models\n- Submission file must be named \"submission.csv\"","9c00ad78":"__Display Images by Label_Group__","6544dc05":"__Shopee is the leading e-commerce platform in Southeast Asia and Taiwan.__","62e00707":"# Find similar images using image embeddings","778e0314":"- Let's add a column in the train\/test set with the train\/test images path","764f4589":"__Display Test Images__","842ed707":"__Finding Similar Images using Nearest Neighbor__\n\n- Extract image embeddings using a pre-trained tensorflow model\n- Find nearest neighbor of an image based on Euclidean Distance using sklearn ","e28c0c0e":"- So there are images with same title in the dataset","beffd9b9":"__Display random train Images__","043730c0":"__Use KNN to find similar images__"}}