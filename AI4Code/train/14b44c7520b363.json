{"cell_type":{"5a2d9a53":"code","56c5c532":"code","f517c020":"code","a420d8e6":"code","e3957a79":"code","fcf969d4":"code","4a5e582b":"code","7097b788":"code","32beb269":"code","2bbcd2a2":"code","dbd55f3b":"code","1ee18616":"code","bb97f7e7":"code","09725b54":"code","91b6c9a4":"code","148a764a":"code","1d8cfb7f":"code","e37c502e":"code","3207e53e":"code","269656f2":"code","5e8f212c":"code","51000a28":"code","2039c78d":"code","d710a664":"code","7b141cdf":"code","af059b5b":"code","72cc6ee1":"code","bbff13d4":"code","b111497f":"code","31c1182b":"code","ca06fa26":"code","e173c2fd":"code","600c25e1":"code","9e463588":"code","a60be480":"code","ab8b9a5b":"code","c3a3f810":"code","064abd20":"code","fe1cb16d":"code","2ac05471":"code","2c0b989e":"code","ec6ee4b2":"code","b158751f":"code","de25d9ca":"code","dd9afb76":"code","d3084807":"code","65c2272b":"code","25e82f18":"markdown","e7eb233c":"markdown","b048272a":"markdown","551ab3e0":"markdown"},"source":{"5a2d9a53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.options.display.max_columns = 999\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","56c5c532":"trainData=pd.read_csv(\"\/kaggle\/input\/elo-merchant-category-recommendation\/train.csv\")\nnewTrans=pd.read_csv(\"\/kaggle\/input\/elo-merchant-category-recommendation\/new_merchant_transactions.csv\")\npastTrans=pd.read_csv(\"\/kaggle\/input\/elo-merchant-category-recommendation\/historical_transactions.csv\")\nmerchants=pd.read_csv(\"\/kaggle\/input\/elo-merchant-category-recommendation\/merchants.csv\")\nnewTrans=newTrans.drop(columns=['merchant_category_id','purchase_date'])\npastTrans=pastTrans.drop(columns=['merchant_category_id','purchase_date'])\nmerchants=merchants[['merchant_id','merchant_category_id','subsector_id','numerical_1','numerical_2','avg_sales_lag12','avg_purchases_lag12','active_months_lag12']]","f517c020":"newTrans.head()","a420d8e6":"pastTrans.head()","e3957a79":"agg_func = {\n    'installments': ['mean'],\n    'month_lag': ['mean','count'],\n    'purchase_amount': ['mean']}\n    \nnewTransSummary = newTrans.groupby(['card_id']).agg(agg_func)\nnewTransSummary.columns = ['_'.join(col).strip() for col in newTransSummary.columns.values]\nnewTransSummary.reset_index(inplace=True)\npastTransSummary = pastTrans.groupby(['card_id']).agg(agg_func)\npastTransSummary.columns = ['_'.join(col).strip() for col in pastTransSummary.columns.values]\npastTransSummary.reset_index(inplace=True)","fcf969d4":"newTrans=newTrans.sort_values(by=['month_lag'], ascending=False)\npastTrans=pastTrans.sort_values(by=['month_lag'], ascending=False)\npastTrans=pastTrans.drop_duplicates('card_id',keep='first')\nnewTrans=newTrans.drop_duplicates('card_id',keep='first')\nnewTrans.reset_index(inplace=True)\npastTrans.reset_index(inplace=True)","4a5e582b":"### Aggregated with the latest and past summary with merchants info\naggregatedNew=newTrans.merge(newTransSummary,on='card_id',how='left')\naggregatedPast=pastTrans.merge(pastTransSummary,on='card_id',how='left')\naggregatedNew=aggregatedNew.merge(merchants,on='merchant_id',how='left')\naggregatedPast=aggregatedPast.merge(merchants,on='merchant_id',how='left')\naggregatedNew=aggregatedNew.drop(columns=['index','merchant_id'])\naggregatedPast=aggregatedPast.drop(columns=['index','merchant_id'])\n","7097b788":"del pastTrans\ndel newTrans\ndel merchants","32beb269":"aggregatedPast.head()","2bbcd2a2":"aggregatedPast.columns = [col+'_'+'past' for col in aggregatedPast.columns]\naggregatedAll=aggregatedNew.merge(aggregatedPast,left_on='card_id',right_on='card_id_past',how='outer')\ncardId=aggregatedAll['card_id'].tolist()\n#aggregatedAll=aggregatedAll.drop(columns=['card_id_past'])","dbd55f3b":"del aggregatedPast\ndel aggregatedNew","1ee18616":"aggregatedAll.head()","bb97f7e7":"aggregatedAll.isna().sum() \nids=aggregatedAll['card_id_past'].tolist()\naggregatedAll=aggregatedAll.drop(columns=['card_id','card_id_past'])\naggregatedAll['authorized_flag']=aggregatedAll['authorized_flag'].fillna('Unknown')\naggregatedAll['city_id']=aggregatedAll['city_id'].fillna('Unknown')\naggregatedAll['category_1']=aggregatedAll['category_1'].fillna('Unknown')\naggregatedAll['installments']=aggregatedAll['installments'].fillna(0)\naggregatedAll['category_3']=aggregatedAll['category_3'].fillna('Unknown')\naggregatedAll['month_lag']=aggregatedAll['month_lag'].fillna('Unknown')\naggregatedAll['purchase_amount']=aggregatedAll['purchase_amount'].fillna(0.0)\naggregatedAll['category_2']=aggregatedAll['category_2'].fillna('Unknown')\naggregatedAll['state_id']=aggregatedAll['state_id'].fillna('Unknown')\naggregatedAll['subsector_id_x']=aggregatedAll['subsector_id_x'].fillna('Unknown')\naggregatedAll['installments_mean']=aggregatedAll['installments_mean'].fillna(0)\naggregatedAll['month_lag_mean']=aggregatedAll['month_lag_mean'].fillna(0)\naggregatedAll['month_lag_count']=aggregatedAll['month_lag_count'].fillna(0)\naggregatedAll['purchase_amount_mean']=aggregatedAll['purchase_amount_mean'].fillna(0)\naggregatedAll['merchant_category_id']=aggregatedAll['merchant_category_id'].fillna('Unknown')\naggregatedAll['subsector_id_y']=aggregatedAll['subsector_id_y'].fillna('Unknown')\naggregatedAll['numerical_1']=aggregatedAll['numerical_1'].fillna(aggregatedAll['numerical_1'].mean())\naggregatedAll['numerical_2']=aggregatedAll['numerical_2'].fillna(aggregatedAll['numerical_2'].mean())\naggregatedAll['avg_sales_lag12']=aggregatedAll['avg_sales_lag12'].fillna(0.0)\naggregatedAll['avg_purchases_lag12']=aggregatedAll['avg_purchases_lag12'].fillna(0.0)\naggregatedAll['active_months_lag12']=aggregatedAll['active_months_lag12'].fillna(0.0)\n\n\n\n","09725b54":"aggregatedAll['category_3_past']=aggregatedAll['category_3_past'].fillna('Unknown')\naggregatedAll['category_2_past']=aggregatedAll['category_2_past'].fillna('Unknown')\naggregatedAll['merchant_category_id_past']=aggregatedAll['merchant_category_id_past'].fillna('Unknown')\naggregatedAll['subsector_id_y_past']=aggregatedAll['subsector_id_y_past'].fillna('Unknown')\naggregatedAll['numerical_1_past']=aggregatedAll['numerical_1_past'].fillna(aggregatedAll['numerical_1_past'].mean())\naggregatedAll['numerical_2_past']=aggregatedAll['numerical_2_past'].fillna(aggregatedAll['numerical_2_past'].mean())\naggregatedAll['avg_sales_lag12_past']=aggregatedAll['avg_sales_lag12_past'].fillna(0.0)\naggregatedAll['avg_purchases_lag12_past']=aggregatedAll['avg_purchases_lag12_past'].fillna(0.0)\naggregatedAll['active_months_lag12_past']=aggregatedAll['active_months_lag12_past'].fillna(0.0)\n","91b6c9a4":"aggregatedAll.isna().sum() ","148a764a":"aggregatedAll.head()","1d8cfb7f":"set(aggregatedAll['category_1_past'].tolist())","e37c502e":"categoricalColumns=['authorized_flag','category_1','installments','category_3','month_lag','category_2','authorized_flag_past','category_1_past','installments_past','category_3_past','month_lag_past','category_2_past']\ntoEmbedding=['city_id','state_id','subsector_id_x','merchant_category_id','subsector_id_y',\n             'city_id_past','state_id_past','subsector_id_x_past','merchant_category_id_past','subsector_id_y_past']\nnumericalColumns=['purchase_amount','installments_mean','month_lag_mean','month_lag_count','purchase_amount_mean','numerical_1','numerical_2','avg_sales_lag12','avg_purchases_lag12','active_months_lag12',\n                  'purchase_amount_past','installments_mean_past','month_lag_mean_past','month_lag_count_past','purchase_amount_mean_past','numerical_1_past','numerical_2_past','avg_sales_lag12_past','avg_purchases_lag12_past','active_months_lag12_past']","3207e53e":"len(categoricalColumns)+len(toEmbedding)+len(numericalColumns)","269656f2":"len(aggregatedAll.columns)","5e8f212c":"aggregatedAll=aggregatedAll[categoricalColumns+toEmbedding+numericalColumns]","51000a28":"## Latent Dim=5\n## On 'city_id','state_id','subsector_id_x','merchant_category_id','subsector_id_y'\nallCity=list(set(aggregatedAll['city_id'].tolist()+aggregatedAll['city_id_past'].tolist()))\nallState=list(set(aggregatedAll['state_id'].tolist()+aggregatedAll['state_id_past'].tolist()))\nallSubsectorx=list(set(aggregatedAll['subsector_id_x'].tolist()+aggregatedAll['subsector_id_x_past'].tolist()))\nallMerchantCat=list(set(aggregatedAll['merchant_category_id'].tolist()+aggregatedAll['merchant_category_id_past'].tolist()))\nallSubsectory=list(set(aggregatedAll['subsector_id_y'].tolist()+aggregatedAll['subsector_id_y_past'].tolist()))\n\n","2039c78d":"## Label Encode\ncityEncoding={}\ncityEncoding2={}\nfor i in range(len(allCity)):\n    cityEncoding[i]=allCity[i]\n    cityEncoding2[allCity[i]]=i\n\nstateEncoding={}\nstateEncoding2={}\n\nfor i in range(len(allState)):\n    stateEncoding[i]=allState[i]\n    stateEncoding2[allState[i]]=i\n\nsubsectorxEncoding={}\nsubsectorxEncoding2={}\n\nfor i in range(len(allSubsectorx)):\n    subsectorxEncoding[i]=allSubsectorx[i]\n    subsectorxEncoding2[allSubsectorx[i]]=i\n    \n\nmerchantCatEncoding={}\nmerchantCatEncoding2={}\n\nfor i in range(len(allMerchantCat)):\n    merchantCatEncoding[i]=allMerchantCat[i]\n    merchantCatEncoding2[allMerchantCat[i]]=i\n    \n\nsubsectoryEncoding={}\nsubsectoryEncoding2={}\n\nfor i in range(len(allSubsectory)):\n    subsectoryEncoding[i]=allSubsectory[i]\n    subsectoryEncoding2[allSubsectory[i]]=i\n\n","d710a664":"aggregatedAll['ID']=ids\naggregatedAll=aggregatedAll.sample(frac=1)\naggregatedAll.reset_index(drop=True)","7b141cdf":"aggregatedAll=pd.get_dummies(data=aggregatedAll, columns=categoricalColumns)","af059b5b":"aggregatedAll.head()","72cc6ee1":"idLst=aggregatedAll['ID'].tolist()\naggregatedAll=aggregatedAll.drop(columns=['ID'],inplace=False)\naggregatedAll=aggregatedAll.reset_index(drop=True)\ntrainData2=trainData[['card_id','target']]\naggregatedAll['ID']=idLst\naggregatedAll=aggregatedAll.merge(trainData2,left_on='ID',right_on='card_id',how='right')\naggregatedAll.head()","bbff13d4":"result=aggregatedAll['target'].tolist()\naggregatedAll=aggregatedAll.drop(columns=['ID','card_id'])\naggregatedAll.head()","b111497f":"aggregatedAll=aggregatedAll.drop(columns=['target'])","31c1182b":"aggregatedAll['city_id']=aggregatedAll['city_id'].apply(lambda x:cityEncoding2[x])\naggregatedAll['city_id_past']=aggregatedAll['city_id_past'].apply(lambda x:cityEncoding2[x])\n\naggregatedAll['state_id']=aggregatedAll['state_id'].apply(lambda x:stateEncoding2[x])\naggregatedAll['state_id_past']=aggregatedAll['state_id_past'].apply(lambda x:stateEncoding2[x])\n\naggregatedAll['subsector_id_x']=aggregatedAll['subsector_id_x'].apply(lambda x:subsectorxEncoding2[x])\naggregatedAll['subsector_id_x_past']=aggregatedAll['subsector_id_x_past'].apply(lambda x:subsectorxEncoding2[x])\n\naggregatedAll['merchant_category_id']=aggregatedAll['merchant_category_id'].apply(lambda x:merchantCatEncoding2[x])\naggregatedAll['merchant_category_id_past']=aggregatedAll['merchant_category_id_past'].apply(lambda x:merchantCatEncoding2[x])\n\naggregatedAll['subsector_id_y']=aggregatedAll['subsector_id_y'].apply(lambda x:subsectoryEncoding2[x])\naggregatedAll['subsector_id_y_past']=aggregatedAll['subsector_id_y_past'].apply(lambda x:subsectoryEncoding2[x])\n","ca06fa26":"bigX=np.array(aggregatedAll)","e173c2fd":"result=np.array([[x] for x in result])","600c25e1":"print(bigX.shape)\nprint(result.shape)","9e463588":"aggregatedAll.head()","a60be480":"print(len(cityEncoding))\nprint(len(stateEncoding))\nprint(len(subsectorxEncoding))\nprint(len(merchantCatEncoding2))\nprint(len(subsectoryEncoding))\n","ab8b9a5b":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","c3a3f810":"x=tf.placeholder(tf.float32,shape=(None, 103))\ny=tf.placeholder(tf.float32,shape=(None,1))\n\ncityLab=tf.slice(x, [0,0],[-1, 1])\ncityLabPast=tf.slice(x, [0,5],[-1, 1])\ncityLab=tf.dtypes.cast(cityLab, tf.int32)\ncityLabPast=tf.dtypes.cast(cityLabPast, tf.int32)\ncityEmbedding=tf.Variable(tf.random_normal([309,5], stddev=0.1))\nembeddedCity=tf.nn.embedding_lookup(cityEmbedding,cityLab)\nembeddedCityPast=tf.nn.embedding_lookup(cityEmbedding,cityLabPast)\n\n\nstateLab=tf.slice(x, [0,2],[-1, 1])\nstateLabPast=tf.slice(x, [0,6],[-1, 1])\nstateLab=tf.dtypes.cast(stateLab, tf.int32)\nstateLabPast=tf.dtypes.cast(stateLabPast, tf.int32)\nstateEmbedding=tf.Variable(tf.random_normal([26,5], stddev=0.1))\nembeddedState=tf.nn.embedding_lookup(stateEmbedding,cityLab)\nembeddedStatePast=tf.nn.embedding_lookup(stateEmbedding,stateLabPast)\n\nsubsectorxLab=tf.slice(x, [0,3],[-1, 1])\nsubsectorxLabPast=tf.slice(x, [0,7],[-1, 1])\nsubsectorxLab=tf.dtypes.cast(subsectorxLab, tf.int32)\nsubsectorxLabPast=tf.dtypes.cast(subsectorxLabPast, tf.int32)\nsubsectorxLabEmbedding=tf.Variable(tf.random_normal([42,5], stddev=0.1))\nembeddedSubsectorX=tf.nn.embedding_lookup(subsectorxLabEmbedding,subsectorxLab)\nembeddedSubsectorXPast=tf.nn.embedding_lookup(subsectorxLabEmbedding,subsectorxLabPast)\n\nmerchantCatLab=tf.slice(x, [0,4],[-1, 1])\nmerchantCatLabPast=tf.slice(x, [0,8],[-1, 1])\nmerchantCatLab=tf.dtypes.cast(merchantCatLab, tf.int32)\nmerchantCatLabPast=tf.dtypes.cast(merchantCatLabPast, tf.int32)\nmerchantCatLabEmbedding=tf.Variable(tf.random_normal([294,5], stddev=0.1))\nembeddedmerchantCat=tf.nn.embedding_lookup(merchantCatLabEmbedding,merchantCatLab)\nembeddedmerchantCatPast=tf.nn.embedding_lookup(merchantCatLabEmbedding,merchantCatLabPast)\n\nsubsectoryLab=tf.slice(x, [0,5],[-1, 1])\nsubsectoryLabPast=tf.slice(x, [0,9],[-1, 1])\nsubsectoryLab=tf.dtypes.cast(subsectoryLab, tf.int32)\nsubsectoryLabPast=tf.dtypes.cast(subsectoryLabPast, tf.int32)\nsubsectoryLabEmbedding=tf.Variable(tf.random_normal([41,5], stddev=0.1))\nembeddedSubsectorY=tf.nn.embedding_lookup(subsectoryLabEmbedding,subsectoryLab)\nembeddedSubsectorYPast=tf.nn.embedding_lookup(subsectoryLabEmbedding,subsectoryLabPast)\n\nadditionEncoding=embeddedCity+embeddedCityPast+embeddedState+embeddedStatePast+embeddedSubsectorX+embeddedSubsectorXPast+embeddedmerchantCat+embeddedmerchantCatPast+embeddedSubsectorY+embeddedSubsectorYPast\n\ninterCity=tf.multiply(embeddedCity,embeddedCityPast)\ninterState=tf.multiply(embeddedState,embeddedStatePast)\ninterSubsectorx=tf.multiply(embeddedSubsectorX,embeddedSubsectorXPast)\ninterMerchant=tf.multiply(embeddedmerchantCat,embeddedmerchantCatPast)\ninterSubsectory=tf.multiply(embeddedSubsectorY,embeddedSubsectorYPast)\n\nFMPart=tf.concat(\n    [additionEncoding,interCity,interState,interSubsectorx,interMerchant,interSubsectory],2)\nFMPart=tf.squeeze(FMPart, [1])","064abd20":"FFfeatures=cityLab=tf.slice(x, [0,10],[-1, 93])\nhidden1=tf.layers.dense(FFfeatures, 32,activation=tf.nn.sigmoid)\ndeepPart=tf.layers.dense(hidden1,16,activation=tf.nn.sigmoid)\n\nDeepFMHidden=tf.concat([FMPart,deepPart],1)\nDeepFMHidden2=tf.layers.dense(DeepFMHidden,16,activation=tf.nn.tanh)\nDeepFMHidden3=tf.layers.dense(DeepFMHidden2,8,activation=tf.nn.tanh)\nDeepFMFinal=tf.layers.dense(DeepFMHidden3,1)","fe1cb16d":"FMPart.shape","2ac05471":"deepPart.shape","2c0b989e":"DeepFMHidden.shape","ec6ee4b2":"DeepFMFinal.shape","b158751f":"loss=mse = tf.losses.mean_squared_error(y, DeepFMFinal) \ntraining=tf.train.AdamOptimizer(0.003).minimize(loss)","de25d9ca":"## Training","dd9afb76":"sess=tf.Session()\ninit=tf.global_variables_initializer()\nsess.run(init)\n\nbatchSize=128\nepochs=50\ncnter=0\nttLoss=0.0\nfor idx in range(epochs):\n    cnter=0\n    for i in range(int(bigX.shape[0]\/batchSize)-1):\n        tempX=bigX[i*batchSize:(i+1)*batchSize]\n        tempY=result[i*batchSize:(i+1)*batchSize]\n        _,temploss=sess.run([training,loss],feed_dict={x:tempX,y:tempY})\n        ttLoss+=temploss\n        if i%10000==0:\n            print('Current Loss: '+ str(ttLoss\/10000.0))\n            ttLoss=0.0","d3084807":"allPred=[]\nfor i in range(int(bigX.shape[0]\/batchSize)-1):\n    tempX=bigX[i*batchSize:(i+1)*batchSize]\n    tempY=result[i*batchSize:(i+1)*batchSize]\n    _,_,pred=sess.run([training,loss,DeepFMFinal],feed_dict={x:tempX,y:tempY})\n    allPred+=list(pred.reshape([128]))\n","65c2272b":"[x[0] for x in result]","25e82f18":"### Change number of Epoches to 200 - 2000 for better performance","e7eb233c":"## Free memoery again","b048272a":"### Create Embeddings","551ab3e0":"### Release memory"}}