{"cell_type":{"9f58179d":"code","fa8415a8":"code","e95809df":"code","3a0df347":"code","c0bf6ce4":"markdown","d81479c3":"markdown","4ab0c418":"markdown","7476bba8":"markdown"},"source":{"9f58179d":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score","fa8415a8":"num_classes = 28\n\ndf = pd.read_csv('..\/input\/train.csv')\n\ny_true = np.zeros((len(df), num_classes))\n\nfor i, row in df.iterrows():\n    for lblIndex in row['Target'].split():\n        y_true[i][int(lblIndex)] = 1\n        \nprint(y_true.shape)","e95809df":"print(f1_score(y_true, y_true, average='macro'))","3a0df347":"for batch_size in [64, 32, 16]:\n    print(\"Batch size:\", batch_size, \"F1 macro:\", f1_score(y_true[:batch_size], y_true[:batch_size], average='macro'))","c0bf6ce4":"### Read all true labels from training set to demonstate the idea on them","d81479c3":"### We can calculate f1 score for all true labels with themselves. This should give f1 equal to 1 since all classes are present in training set.","4ab0c418":"### As far as we know f1 score is highly dependent from true positive rate. If a class is not present then it will have true positive rate and f1 score both equal to 0, even though all predictions are correct. That could have a stong effect******** on small batches when not all classes are present.","7476bba8":"### After that we will calculate f1 score for true labels with themselves for small batches to see the effect"}}