{"cell_type":{"856750b0":"code","72c3357a":"code","8bc8c7c3":"code","310ca2bf":"code","1162bc4d":"code","e35967d0":"code","19cc1ee8":"code","76faa384":"code","0fd56c16":"code","5d42238f":"code","cc32f604":"code","16b3439f":"code","5eb8caff":"code","c92aaa3d":"code","6d1a6520":"code","71035b05":"code","eaac1e29":"code","af72aaba":"code","7ba562c7":"code","edc2c200":"code","f70d91f6":"code","394cf167":"code","e6f631e4":"code","49e5c9d7":"code","5fe9e544":"code","2d4adad9":"code","2b489654":"code","c52a1679":"code","cdd6b279":"code","c623c53c":"code","d0228efd":"code","7e46796f":"code","558a95b5":"code","391b37d9":"code","30c6e702":"code","760ba715":"code","f46e0bd0":"code","2c4351d2":"code","2130d861":"code","db405aa1":"code","ea23c918":"code","79effd6d":"code","7b9c0e18":"code","19f3b97d":"code","09d4bb96":"code","33723c37":"code","ff467075":"code","3105e795":"code","973594c3":"code","3ba26665":"code","15fccbb6":"code","68996817":"code","72a64131":"code","81b94c7d":"code","c2099a14":"code","01c7f232":"code","8cac2c82":"code","5cb5bd44":"code","f6f36cd3":"code","c7d6e3be":"code","71ef76cc":"code","eadb49c1":"code","f55149e3":"code","ffe02116":"code","7aa40c1e":"code","8f164d1d":"code","44097efb":"code","92c26ac4":"code","dd985b14":"code","d38c4041":"code","c77e8b9b":"code","baa9232c":"code","6509f6e3":"code","bae50439":"code","88537d3b":"code","536a4d64":"code","e11b3c5b":"code","7e4c0b9c":"code","a9e552c6":"code","51cbec12":"code","2e8c16e4":"code","f8f665e4":"markdown","96f3ffb6":"markdown","42f3656c":"markdown","12b59320":"markdown","4a5a5854":"markdown","efcc4ab0":"markdown","bdb91d3b":"markdown","808a1c53":"markdown","7baf534f":"markdown","b5a9692d":"markdown","a5a402d9":"markdown","776210dd":"markdown","6756ab37":"markdown","502cb67b":"markdown","cb20f98c":"markdown","02b2016b":"markdown","c2e64ea1":"markdown","e21fa70f":"markdown","dbb83942":"markdown","ecf30d20":"markdown","4d88cdf4":"markdown","68c912d3":"markdown","d6e14a57":"markdown","3223096a":"markdown","feb90025":"markdown","75070ff6":"markdown","4d7d3686":"markdown","7f8bca83":"markdown","6b119170":"markdown","3abe50aa":"markdown","0514cb75":"markdown","edc91473":"markdown","ec96feaf":"markdown"},"source":{"856750b0":"# Importing Pandas and NumPy\nimport pandas as pd\nimport numpy as np","72c3357a":"# Importing all datasets\nchurn_data = pd.read_csv(\"..\/input\/logit-churn-tele\/churn_data.csv\")\ncustomer_data = pd.read_csv(\"..\/input\/logit-churn-tele\/customer_data.csv\")\ninternet_data = pd.read_csv(\"..\/input\/logit-churn-tele\/internet_data.csv\")","8bc8c7c3":"#Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')","310ca2bf":"#Final dataframe with all predictor variables\ntelecom = pd.merge(df_1, internet_data, how='inner', on='customerID')","1162bc4d":"# Let's see the head of our master dataset\ntelecom.head()","e35967d0":"telecom.describe()","19cc1ee8":"# Let's see the type of each column\ntelecom.info()","76faa384":"# Converting Yes to 1 and No to 0\ntelecom['PhoneService'] = telecom['PhoneService'].map({'Yes': 1, 'No': 0})\ntelecom['PaperlessBilling'] = telecom['PaperlessBilling'].map({'Yes': 1, 'No': 0})\ntelecom['Churn'] = telecom['Churn'].map({'Yes': 1, 'No': 0})\ntelecom['Partner'] = telecom['Partner'].map({'Yes': 1, 'No': 0})\ntelecom['Dependents'] = telecom['Dependents'].map({'Yes': 1, 'No': 0})","0fd56c16":"# Creating a dummy variable for the variable 'Contract' and dropping the first one.\ncont = pd.get_dummies(telecom['Contract'],prefix='Contract',drop_first=True)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,cont],axis=1)\n\n# Creating a dummy variable for the variable 'PaymentMethod' and dropping the first one.\npm = pd.get_dummies(telecom['PaymentMethod'],prefix='PaymentMethod',drop_first=True)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,pm],axis=1)\n\n# Creating a dummy variable for the variable 'gender' and dropping the first one.\ngen = pd.get_dummies(telecom['gender'],prefix='gender',drop_first=True)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,gen],axis=1)\n\n# Creating a dummy variable for the variable 'MultipleLines' and dropping the first one.\nml = pd.get_dummies(telecom['MultipleLines'],prefix='MultipleLines')\n#  dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ml1],axis=1)\n\n# Creating a dummy variable for the variable 'InternetService' and dropping the first one.\niser = pd.get_dummies(telecom['InternetService'],prefix='InternetService',drop_first=True)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,iser],axis=1)\n\n# Creating a dummy variable for the variable 'OnlineSecurity'.\nos = pd.get_dummies(telecom['OnlineSecurity'],prefix='OnlineSecurity')\nos1= os.drop(['OnlineSecurity_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,os1],axis=1)\n\n# Creating a dummy variable for the variable 'OnlineBackup'.\nob =pd.get_dummies(telecom['OnlineBackup'],prefix='OnlineBackup')\nob1 =ob.drop(['OnlineBackup_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ob1],axis=1)\n\n# Creating a dummy variable for the variable 'DeviceProtection'. \ndp =pd.get_dummies(telecom['DeviceProtection'],prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,dp1],axis=1)\n\n# Creating a dummy variable for the variable 'TechSupport'. \nts =pd.get_dummies(telecom['TechSupport'],prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ts1],axis=1)\n\n# Creating a dummy variable for the variable 'StreamingTV'.\nst =pd.get_dummies(telecom['StreamingTV'],prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,st1],axis=1)\n\n# Creating a dummy variable for the variable 'StreamingMovies'. \nsm =pd.get_dummies(telecom['StreamingMovies'],prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'],1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,sm1],axis=1)","5d42238f":"#telecom['MultipleLines'].value_counts()","cc32f604":"# We have created dummies for the below variables, so we can drop them\ntelecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)","16b3439f":"#The varaible was imported as a string we need to convert it to float\ntelecom['TotalCharges'] =telecom['TotalCharges'].convert_objects(convert_numeric=True)\n#telecom['tenure'] = telecom['tenure'].astype(int).astype(float)","5eb8caff":"telecom.info()","c92aaa3d":"# Checking for outliers in the continuous variables\nnum_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]","6d1a6520":"# Checking outliers at 25%,50%,75%,90%,95% and 99%\nnum_telecom.describe(percentiles=[.25,.5,.75,.90,.95,.99])","71035b05":"# Adding up the missing values (column-wise)\ntelecom.isnull().sum()","eaac1e29":"# Checking the percentage of missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","af72aaba":"# Removing NaN TotalCharges rows\ntelecom = telecom[~np.isnan(telecom['TotalCharges'])]","7ba562c7":"# Checking percentage of missing values after removing the missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","edc2c200":"# Normalising continuous features\ndf = telecom[['tenure','MonthlyCharges','TotalCharges']]","f70d91f6":"normalized_df=(df-df.mean())\/df.std()","394cf167":"telecom = telecom.drop(['tenure','MonthlyCharges','TotalCharges'], 1)","e6f631e4":"telecom = pd.concat([telecom,normalized_df],axis=1)","49e5c9d7":"telecom","5fe9e544":"churn = (sum(telecom['Churn'])\/len(telecom['Churn'].index))*100","2d4adad9":"churn","2b489654":"from sklearn.model_selection import train_test_split","c52a1679":"# Putting feature variable to X\nX = telecom.drop(['Churn','customerID'],axis=1)\n\n# Putting response variable to y\ny = telecom['Churn']","cdd6b279":"y.head()","c623c53c":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)","d0228efd":"import statsmodels.api as sm","7e46796f":"# Logistic regression model\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()","558a95b5":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","391b37d9":"# Let's see the correlation matrix \nplt.figure(figsize = (20,10))        # Size of the figure\nsns.heatmap(telecom.corr(),annot = True)","30c6e702":"X_test2 = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)\nX_train2 = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)","760ba715":"plt.figure(figsize = (20,10))\nsns.heatmap(X_train2.corr(),annot = True)","f46e0bd0":"logm2 = sm.GLM(y_train,(sm.add_constant(X_train2)), family = sm.families.Binomial())\nlogm2.fit().summary()","2c4351d2":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 13)             # running RFE with 13 variables as output\nrfe = rfe.fit(X,y)\nprint(rfe.support_)           # Printing the boolean results\nprint(rfe.ranking_)           # Printing the ranking","2130d861":"# Variables selected by RFE \ncol = ['PhoneService', 'PaperlessBilling', 'Contract_One year', 'Contract_Two year',\n       'PaymentMethod_Electronic check','MultipleLines_No','InternetService_Fiber optic', 'InternetService_No',\n       'OnlineSecurity_Yes','TechSupport_Yes','StreamingMovies_No','tenure','TotalCharges']","db405aa1":"# Let's run the model using the selected variables\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogsk = LogisticRegression()\nlogsk.fit(X_train[col], y_train)","ea23c918":"#Comparing the model with StatsModels\nlogm4 = sm.GLM(y_train,(sm.add_constant(X_train[col])), family = sm.families.Binomial())\nlogm4.fit().summary()","79effd6d":"# UDF for calculating vif value\ndef vif_cal(input_data, dependent_col):\n    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.OLS(y,x).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)","7b9c0e18":"telecom.columns\n['PhoneService', 'PaperlessBilling', 'Contract_One year', 'Contract_Two year',\n       'PaymentMethod_Electronic check','MultipleLines_No','InternetService_Fiber optic', 'InternetService_No',\n       'OnlineSecurity_Yes','TechSupport_Yes','StreamingMovies_No','tenure','TotalCharges']","19f3b97d":"# Calculating Vif value\nvif_cal(input_data=telecom.drop(['customerID','SeniorCitizen', 'Partner', 'Dependents',\n                                 'PaymentMethod_Credit card (automatic)','PaymentMethod_Mailed check',\n                                 'gender_Male','MultipleLines_Yes','OnlineSecurity_No','OnlineBackup_No',\n                                 'OnlineBackup_Yes', 'DeviceProtection_No', 'DeviceProtection_Yes',\n                                 'TechSupport_No','StreamingTV_No','StreamingTV_Yes','StreamingMovies_Yes',\n                                 'MonthlyCharges'], axis=1), dependent_col='Churn')","09d4bb96":"col = ['PaperlessBilling', 'Contract_One year', 'Contract_Two year',\n       'PaymentMethod_Electronic check','MultipleLines_No','InternetService_Fiber optic', 'InternetService_No',\n       'OnlineSecurity_Yes','TechSupport_Yes','StreamingMovies_No','tenure','TotalCharges']","33723c37":"logm5 = sm.GLM(y_train,(sm.add_constant(X_train[col])), family = sm.families.Binomial())\nlogm5.fit().summary()","ff467075":"# Calculating Vif value\nvif_cal(input_data=telecom.drop(['customerID','PhoneService','SeniorCitizen', 'Partner', 'Dependents',\n                                 'PaymentMethod_Credit card (automatic)','PaymentMethod_Mailed check',\n                                 'gender_Male','MultipleLines_Yes','OnlineSecurity_No','OnlineBackup_No',\n                                 'OnlineBackup_Yes', 'DeviceProtection_No', 'DeviceProtection_Yes',\n                                 'TechSupport_No','StreamingTV_No','StreamingTV_Yes','StreamingMovies_Yes',\n                                 'MonthlyCharges'], axis=1), dependent_col='Churn')","3105e795":"# Let's run the model using the selected variables\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogsk = LogisticRegression()\nlogsk.fit(X_train[col], y_train)","973594c3":"# Predicted probabilities\ny_pred = logsk.predict_proba(X_test[col])","3ba26665":"# Converting y_pred to a dataframe which is an array\ny_pred_df = pd.DataFrame(y_pred)","15fccbb6":"# Converting to column dataframe\ny_pred_1 = y_pred_df.iloc[:,[1]]","68996817":"# Let's see the head\ny_pred_1.head()","72a64131":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)","81b94c7d":"# Putting CustID to index\ny_test_df['CustID'] = y_test_df.index","c2099a14":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)","01c7f232":"# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df,y_pred_1],axis=1)","8cac2c82":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 1 : 'Churn_Prob'})","5cb5bd44":"# Rearranging the columns\ny_pred_final = y_pred_final.reindex_axis(['CustID','Churn','Churn_Prob'], axis=1)","f6f36cd3":"# Let's see the head of y_pred_final\ny_pred_final.head()","c7d6e3be":"# Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\ny_pred_final['predicted'] = y_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.5 else 0)","71ef76cc":"# Let's see the head\ny_pred_final.head()","eadb49c1":"from sklearn import metrics","f55149e3":"help(metrics.confusion_matrix)","ffe02116":"# Confusion matrix \nconfusion = metrics.confusion_matrix( y_pred_final.Churn, y_pred_final.predicted )\nconfusion","7aa40c1e":"# Predicted     not_churn    churn\n# Actual\n# not_churn        1326      166\n# churn            249       333  ","8f164d1d":"#Let's check the overall accuracy.\nmetrics.accuracy_score( y_pred_final.Churn, y_pred_final.predicted)","44097efb":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","92c26ac4":"# Let's see the sensitivity of our logistic regression model\nTP \/ float(TP+FN)","dd985b14":"# Let us calculate specificity\nTN \/ float(TN+FP)","d38c4041":"# Calculate false postive rate - predicting churn when customer does not have churned\nprint(FP\/ float(TN+FP))","c77e8b9b":"# positive predictive value \nprint (TP \/ float(TP+FP))","baa9232c":"# Negative predictive value\nprint (TN \/ float(TN+ FN))","6509f6e3":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(6, 4))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return fpr, tpr, thresholds","bae50439":"draw_roc(y_pred_final.Churn, y_pred_final.predicted)","88537d3b":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_pred_final[i]= y_pred_final.Churn_Prob.map( lambda x: 1 if x > i else 0)\ny_pred_final.head()","536a4d64":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix( y_pred_final.Churn, y_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","e11b3c5b":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])","7e4c0b9c":"y_pred_final['final_predicted'] = y_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.3 else 0)","a9e552c6":"y_pred_final.head()","51cbec12":"#Let's check the overall accuracy.\nmetrics.accuracy_score( y_pred_final.Churn, y_pred_final.final_predicted)","2e8c16e4":"metrics.confusion_matrix( y_pred_final.Churn, y_pred_final.final_predicted )","f8f665e4":"### Checking the Correlation Matrix","96f3ffb6":"### Model Evaluation","42f3656c":"### Finding Optimal Cutoff Point","12b59320":"### Correlation Matrix","4a5a5854":"### Re-Running the Model","efcc4ab0":"### From the curve above, 0.3 is the optimum point to take it as a cutoff probability.","bdb91d3b":"Now we can see we have all variables as integer.","808a1c53":"### ROC Curve","7baf534f":"After dropping highly correlated variables now let's check the correlation matrix again.","b5a9692d":"Now we don't have any missing values","a5a402d9":"### Dropping Variable with high VIF","776210dd":"### Dropping the repeated variables","6756ab37":"### Feature Selection Using RFE","502cb67b":"### Making Predictions","cb20f98c":"### Let's understand the structure of our dataframe","02b2016b":"### Checking for Outliers","c2e64ea1":"We have almost 27% churn rate","e21fa70f":"Optimal cutoff probability is that prob where we get balanced sensitivity and specificity","dbb83942":"### Checking the Churn Rate","ecf30d20":"### Dummy Variable Creation","4d88cdf4":"An ROC curve demonstrates several things:\n\n- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.","68c912d3":"## Model Building\nLet's start by splitting our data into a training set and a test set.","d6e14a57":"It means that 11\/7043 = 0.001561834 i.e 0.1%, best is to remove these observations from the analysis","3223096a":"### Feature Standardisation","feb90025":"### Checking for Missing Values and Inputing Them","75070ff6":"### Data Preparation","4d7d3686":"### Splitting Data into Training and Test Sets","7f8bca83":"### Dropping highly correlated variables.","6b119170":"## Telecom Churn Analysis\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.","3abe50aa":"Now let's run our model again after dropping highly correlated variables","0514cb75":"### Importing and Merging Data","edc91473":"### Running Your First Training Model","ec96feaf":"From the distribution shown above, you can see that there no outliner in your data. The numbers are gradually increasing."}}