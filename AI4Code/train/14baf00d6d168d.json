{"cell_type":{"f8d8b2f8":"code","dc7bd844":"code","4479a1cc":"code","256c77d7":"code","bf8ab830":"code","b87b1edf":"code","202b40d8":"code","f631e216":"code","65abfc1d":"code","18432343":"code","0d7e79b2":"code","d544f986":"code","82e38779":"code","378a6c8e":"code","9970981b":"code","f1331fcb":"code","0510c0ab":"code","b1150a22":"code","66c4084a":"code","320f4d72":"code","a0edea2f":"code","1ab914a5":"code","d0625b44":"code","0e6bce79":"code","b90d5536":"code","7b1c34e2":"code","84560814":"code","d1273d9c":"code","da126266":"code","93339f7b":"code","7aa4ea62":"markdown","d3a129af":"markdown","b196c5cb":"markdown","5348e191":"markdown","67892282":"markdown","4dc68744":"markdown","38563790":"markdown","723c86c9":"markdown"},"source":{"f8d8b2f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dc7bd844":"data=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')\nfull=pd.concat([data,test])\nprint(full.shape)\nfull.head()","4479a1cc":"test.head()","256c77d7":"data.isnull().sum()\n","bf8ab830":"test.isnull().sum()","b87b1edf":"# A string coorelation can be observed \nfig = plt.figure(figsize=(11,6))\nax = sns.countplot(data['Sex'],hue=data['Survived'])\nax.set_title('By Sex Survived',fontsize = 20)\n","202b40d8":"fig = plt.figure(figsize=(11,6))\nax = sns.countplot(data['Fare'],hue=data['Survived'])\nax.set_title('By Fare Survived',fontsize = 20)","f631e216":"fare_ranges = np.array([x*20 for x in range(30)])\ndata['Fare'] =fare_ranges.searchsorted(data.Fare)\ndata.head()","65abfc1d":"fig = plt.figure(figsize=(11,6))\nax = sns.countplot(data['Fare'],hue=data['Survived'])\nax.set_title('By Fare Survived',fontsize = 20)","18432343":"full['Has_Age'] = full['Age'].isnull().map(lambda x : 0 if x == True else 1)\nfull['Title'] = full.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nfull.head()\n","0d7e79b2":"full['Title'] = full['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n                                               'Dr', 'Dona', 'Jonkheer', \n                                                'Major','Rev','Sir'],'Unknown') \nfull['Title'] = full['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\nfull['Title'] = full['Title'].replace(['Lady'],'Mrs')\ng = sns.factorplot(y='Age',x='Title',kind='box',hue='Pclass', data=full, \n               size=6,aspect=1.5)\nplt.subplots_adjust(top=0.93)\ng.fig.suptitle('Age vs Pclass cross Title', fontsize = 20)\n","d544f986":"full.drop(columns=['Cabin','PassengerId','Ticket'],inplace=True)\nfull['FamilySize']=full['Parch']+full['SibSp']+1\nfull.head()\n","82e38779":"data=full[full['Survived'].isnull()==False]\nprint(data[['FamilySize', 'Survived']].groupby(data['FamilySize'], as_index=False).mean())\n","378a6c8e":"fx, axes = plt.subplots(1, 2, figsize=(15,5))\naxes[0].set_title('Family Size counts')\naxes[1].set_title('Survival Rate vs Family Size')\nfig1_family = sns.countplot(x=data.FamilySize, ax=axes[0], palette='cool')\nfig2_family = sns.barplot(x=data.FamilySize, y=data.Survived, ax=axes[1], palette='cool')\n","9970981b":"full['isAlone'] = full['FamilySize'].map(lambda x: 1 if x<2 or x>7   else 0)\n","f1331fcb":"data=full[full['Survived'].isnull()==False]\nfx, axes = plt.subplots(1, 2, figsize=(15, 6))\nfig1_alone = sns.countplot(data=data, x='isAlone', ax=axes[0])\nfig2_alone = sns.barplot(data=data, x='isAlone', y='Survived', ax=axes[1])\n","0510c0ab":"## no need for sibsp and parch now\nfull.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)\n\n","b1150a22":"missing_mask = (full['Has_Age'] == 0)\npd.crosstab(full[missing_mask]['Pclass'],full[missing_mask]['Title'])","66c4084a":"#lets see the median of each combo (pclass\/title)\n# we use median to escape the outliers influence\nfull.pivot_table(values='Age', index=['Pclass'], columns=['Title'],aggfunc=np.median)\n","320f4d72":"full['Title'] = full['Title'].map({\"Mr\":0, \"Unknown\" : 1, \"Master\" : 2, \"Miss\" : 3, \"Mrs\" : 4 })\nPclass_title_pred = full.pivot_table(values='Age', index=['Pclass'], columns=['Title'],aggfunc=np.median).values\n# by default lets copy the old age col in the pcall_title col\nfull['P_Ti_Age'] = full['Age']\n","a0edea2f":"# filling Missing age with Pclass & Title\nfor i in range(0,5):\n    # 0,1,2,3,4\n    for j in range(1,4):\n        # 1,2,3\n            full.loc[(full.Age.isnull()) & (full.Pclass == j) & (full.Title == i),'P_Ti_Age'] = Pclass_title_pred[j-1, i]\nfull['P_Ti_Age'] = full['P_Ti_Age'].astype('int')","1ab914a5":"full.head()\n","d0625b44":"age_ranges = np.array([16,100])\nfull['Age'] =age_ranges.searchsorted(full.Age)\n\nfull['P_Ti_Age'] = age_ranges.searchsorted(full.P_Ti_Age)\nfull.head()\n","0e6bce79":"## transforming the embarked and sex feature to numeric \nfull=full[False==full['Embarked'].isnull()]\nfull['Embarked']=full['Embarked'].apply(lambda x : 0 if x=='S' else 1 if x=='C' else 2)\nfull['Sex']=full['Sex'].apply(lambda x : 0 if x=='male' else 1 )\n","b90d5536":"data_without_old_age=full.drop(columns=['Name','Age'])\ndata_without_old_age.head()","7b1c34e2":"# split the data again to train and test \nto_predict=data_without_old_age[data_without_old_age['Survived'].isnull()]\ndata=data_without_old_age[False==data_without_old_age['Survived'].isnull()]\n","84560814":"## At This stage, I have finished the feature engineering part, Shoosed xgboost to go with and I have only to define my validation \n##strategy to go with ","d1273d9c":"import warnings\nfrom sklearn.model_selection import StratifiedKFold ## slightly better than normal cross val\nwarnings.filterwarnings('ignore')\n\nestim=np.array([x for x in (5,25,50,100)])\nscores=[]\nfor n in range(4):\n    xg_gbm = xgb.XGBClassifier(max_depth=7, n_estimators=estim[n], learning_rate=0.5,colsample_bytree=0.6)\n    (x_tr,y_tr)=(data.drop('Survived',axis=1).values, data['Survived'].values)\n    skf=StratifiedKFold(n_splits=10,shuffle=True,random_state=123)\n    cv_scores=[]\n    for tr_ind,val_ind in skf.split(x_tr, y_tr):\n        X_tr, X_val=data.iloc[tr_ind],data.iloc[val_ind]\n        xg_gbm.fit(data.iloc[tr_ind].drop('Survived',axis=1).values,data.iloc[tr_ind].Survived.values)\n        cv_scores.append(accuracy_score(xg_gbm.predict(data.iloc[val_ind].drop('Survived',axis=1).values),data.iloc[val_ind].Survived.values))\n\n    scores.append((np.asarray(cv_scores)).mean())\n    #print((np.asarray(cv_scores)).mean())\nplt.plot(estim,scores)\n","da126266":"## after arround 40 estimator, the model started to overfit,\n## also keep in mind that there is a relation between nb_estimator and learning rate","93339f7b":"test['Survived']=xg_gbm.predict(to_predict.drop('Survived',axis=1).values)\nresult_df=test[['PassengerId','Survived']]\nresult_df['Survived']=result_df['Survived'].astype('int')\nresult_df.to_csv('Random_f_output_family_sz_.csv',header=True,index=False)\nresult_df.tail()\n","7aa4ea62":"The goal of the previous work is to add a feature that indicat if the passenger is a child ","d3a129af":">  ### Transforming Fare to categorical for better visualisation\n","b196c5cb":"> ### Now let's use the Title+Pclass  feature to imputate the Age ","5348e191":"**What about the age feature ?**\n*  We saw earlier that it contain a lot of nan's\n*  We cannot drop all the rows as they contain almost 40% our data\n* we're going to guess the age from another feature here \n","67892282":"What model to use ?\n* in this kind of problem we create a base model with random forest\/xgboost and see\n* in our case we'll go with Xgboost","4dc68744":"## EDA (Exploratory data analysis)","38563790":"## Add is-alone feature","723c86c9":"**Is family size important ?**\n* Let's add first of all the family size feature "}}