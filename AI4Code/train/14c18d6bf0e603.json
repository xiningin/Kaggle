{"cell_type":{"39f56fac":"code","5a987d17":"code","1d9985c2":"code","b7206543":"code","19becfa0":"code","6d1e187f":"code","c22bd16c":"code","183e370e":"code","8051214c":"code","010506b0":"code","447c102d":"code","c5d3f3ae":"code","da10ec79":"code","baa06191":"code","cb9fc38c":"code","794ccbef":"code","07f040c3":"code","b6b9cf4f":"code","4a1897d4":"code","ffe5b99e":"code","94b9e82f":"code","6d6391fd":"code","dd97e35a":"code","7c32242e":"code","3d0fe992":"code","35531b0d":"markdown","59c7a60a":"markdown","1f6a2e07":"markdown","b47b3d12":"markdown","47cd37dc":"markdown","c613c1ff":"markdown","57392684":"markdown","8ce44da0":"markdown","5ef739f0":"markdown","5968b42b":"markdown","50e4256b":"markdown","3b2aa631":"markdown","dbe60743":"markdown","ee6875fa":"markdown","b94286f1":"markdown","6256cd43":"markdown","8d68cc74":"markdown","1cb5e1c7":"markdown","9e291a63":"markdown","aa08cdbb":"markdown"},"source":{"39f56fac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nimport albumentations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nprint(tf.__version__)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames[:5]:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5a987d17":"CLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}\nSEED = 77\nrandom.seed(SEED)\nIMG_CHANNELS = 3\nIMG_WIDTH = 512\n\n# These are used for histogram equalization\nclipLimit=2.0 \ntileGridSize=(8, 8)  \n\nchannels = {\"R\":0, \"G\": 1, \"B\":2}","1d9985c2":"sample_submission = pd.read_csv(\"\/kaggle\/input\/aptos2019-blindness-detection\/sample_submission.csv\")\nprint(sample_submission.head())\ntest_file = pd.read_csv(\"\/kaggle\/input\/aptos2019-blindness-detection\/test.csv\")\ntrain_file = pd.read_csv(\"\/kaggle\/input\/aptos2019-blindness-detection\/train.csv\")\nprint(test_file.head())\nprint(train_file.head())","b7206543":"# Now check the distribution of train images\nprint(len(train_file))\ntrain_file['diagnosis'].hist(figsize = (8,4))","19becfa0":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(4*columns, 3*rows))\n    \n    random_indices = random.sample(range(0, len(train_file)), columns*rows)\n    count = 0\n    for i in random_indices:\n        image_path = df.loc[i,'id_code']\n        image_rating = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, count+1)\n        count += 1\n        plt.title(image_rating)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_file, 4, 8)","6d1e187f":"sample_img_path = random.choice(train_file[\"id_code\"])\nsample_img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{sample_img_path}.png')\nsample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\nprint(sample_img.shape)\nplt.imshow(sample_img)","c22bd16c":"def draw_img(imgs, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = (f'..\/input\/aptos2019-blindness-detection\/train_images\/{row[\"id_code\"]}.png')\n        img = cv2.imread(imgPath)\n        row = idnx \/\/ 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axis[row, col].imshow(img)\n    plt.suptitle(class_label)\n    plt.show()","183e370e":"CLASS_ID = 0\ndraw_img(train_file[train_file.diagnosis == CLASS_ID].head(12), CLASSS[CLASS_ID])","8051214c":"CLASS_ID = 4\ndraw_img(train_file[train_file.diagnosis == CLASS_ID].head(12), CLASSS[CLASS_ID])","010506b0":"# HE --> Histogram Equalization: True to apply CLAHE to the color channel image\n\nprint(channels)\nprint(clipLimit)\nprint(tileGridSize)\n\ndef display_single_channel_samples(df, columns=4, rows=3, channel = \"G\", HE = False):\n    fig=plt.figure(figsize=(4*columns, 3*rows))\n    random.seed(SEED) # This lines make sure that all the following function calls will\n                    # show the same set of randomly selected images\n    random_indices = random.sample(range(0, len(train_file)), columns*rows)\n    \n    count = 0\n    for i in random_indices:\n        # Load images and convert to RGB\n        image_path = df.loc[i,'id_code']\n        image_rating = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # Apply some pre-processing\n        img = img[:,:,channels[channel]]\n        if HE: #If the histogram equalization is applied\n            clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n            img = clahe.apply(img) #This is for creating the image with a higher contrast\n        else:\n            pass\n        \n        # Actually drawing stuff \n        fig.add_subplot(rows, columns, count+1)\n#         fig.add_subplot()\n        count += 1\n        plt.title(image_rating)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n","447c102d":"display_single_channel_samples(train_file, 4, 3)","c5d3f3ae":"display_single_channel_samples(train_file,4,3, \"G\", HE = True)","da10ec79":"display_single_channel_samples(train_file,4,3, \"R\", HE = True)","baa06191":"display_single_channel_samples(train_file,4,2, \"B\", HE = False)","cb9fc38c":"display_single_channel_samples(train_file,4,2, \"B\", HE = True)","794ccbef":"def resize_bens(df, columns=4, rows=3, sigmaX = 20, img_width = IMG_WIDTH): # Assume image is square \n    fig=plt.figure(figsize=(4*columns, 3*rows))\n    \n    random.seed(SEED)\n    random_indices = random.sample(range(0, len(train_file)), columns*rows)\n    count = 0\n    for i in random_indices:\n        image_path = df.loc[i,'id_code']\n        image_rating = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_width, img_width))\n        img = cv2.addWeighted ( img,4, cv2.GaussianBlur(img , (0,0) , sigmaX) ,-4 ,128)\n        \n        fig.add_subplot(rows, columns, count+1)\n        count += 1\n        plt.title(image_rating)\n        plt.imshow(img)\n    \n    plt.tight_layout()","07f040c3":"resize_bens(train_file, 4, 4)","b6b9cf4f":"resize_bens(train_file,4,4, sigmaX = 50)","4a1897d4":"resize_bens(train_file,4,4, sigmaX = 16)","ffe5b99e":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","94b9e82f":"def resize_bens_and_crop(df, columns=4, rows=3, sigmaX = 20, img_width = IMG_WIDTH): # Assume image is square \n    fig=plt.figure(figsize=(4*columns, 3*rows))\n    \n    random.seed(SEED)\n    random_indices = random.sample(range(0, len(train_file)), columns*rows)\n    count = 0\n    for i in random_indices:\n        image_path = df.loc[i,'id_code']\n        image_rating = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # First crop, then resize.\n        img = crop_image_from_gray(img)\n        img = cv2.resize(img, (img_width, img_width))\n        \n        # Applying Ben's method\n        img = cv2.addWeighted ( img,4, cv2.GaussianBlur(img , (0,0) , sigmaX) ,-4 ,128)\n        \n        fig.add_subplot(rows, columns, count+1)\n        count += 1\n        plt.title(image_rating)\n        plt.imshow(img)\n    \n    plt.tight_layout()","6d6391fd":"resize_bens_and_crop(train_file, 4, 4, sigmaX = 10)","dd97e35a":"# HE --> Histogram Equalization: Try to apply CLAHE to the color channel image\n\nprint(channels)\nprint(clipLimit)\nprint(tileGridSize)\n\ndef display_single_channel_crop_resize(df, columns=4, rows=3, channel = \"G\", HE = False):\n    fig=plt.figure(figsize=(4*columns, 3*rows))\n    random.seed(SEED) # This lines make sure that all the following function calls will\n                    # show the same set of randomly selected images\n    random_indices = random.sample(range(0, len(train_file)), columns*rows)\n    \n    count = 0\n    for i in random_indices:\n        # Load images and convert to RGB\n        image_path = df.loc[i,'id_code']\n        image_rating = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # Crop and then resize the image\n        img = crop_image_from_gray(img)\n        img = cv2.resize(img, (IMG_WIDTH, IMG_WIDTH))\n        \n        # Apply some pre-processing\n        img = img[:,:,channels[channel]]\n        if HE: #If the histogram equalization is applied\n            clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n            img = clahe.apply(img) #This is for creating the image with a higher contrast\n        else:\n            pass\n        \n        # Actually drawing stuff \n        fig.add_subplot(rows, columns, count+1)\n#         fig.add_subplot()\n        count += 1\n        plt.title(image_rating)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n","7c32242e":"resize_bens_and_crop(train_file, 5, 7, sigmaX = 10)","3d0fe992":"display_single_channel_crop_resize(train_file, 5, 7, HE = True)","35531b0d":"## Finally\nHere we provide an intuitive comparison between the effectiveness of using SINGLE BLUE CHANNEL WITH HISTOGRAM EQUALIZATION and using RGB IMAGE WITH BEN'S METHOD","59c7a60a":"** Blue Channel WITH histogram equalization**","1f6a2e07":"** Don't forget to add cropping and resizing functions to the SINGLE CHANNEL method we used before **","b47b3d12":"** Red Channel WITH histogram equalization**","47cd37dc":"## Load data and check distribution","c613c1ff":"### Some meta-data features of these images\n* They are actually very large\n* They can be in very different lighting conditions ==> Consider this in augmentations\n* They vary largely in size\n* They have quite different proportion of dark fringes","57392684":"## Display Original Images","8ce44da0":"## Define some important global variables here","5ef739f0":"** Green Channel WITH Histogram Equalization**\n\nWe can see that this is **slightly better** than the un-equalized version of these images as the contrast has been increased. In the green channel, the vessels are much more clear.\n\nNext, we try to visualiza another two channels, each **WITH** HE applied.\n\nNow, we can see that ","5968b42b":"## Summary\nThis kernel does preliminary exploratory data analysis on this dataset and explores some of the pre-processing techniques, some of which are proven to be potentially useful. Some code are borrowed or adapted from other public kernels and discussion threads. Credits are listed below.\n\n#### Thanks to:\n@Neuron Engineer for his excellent EDA code https:\/\/www.kaggle.com\/ratthachat\/aptos-updatedv14-preprocessing-ben-s-cropping#data\n\n@Bharat Singh for his great starter kernel https:\/\/www.kaggle.com\/bharatsingh213\/keras-resnet-tta\n\nPeople in this discussion https:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/discussion\/102613#latest-614367","50e4256b":"**Now we see the three different channels and see if one channel may contain most of the useful information** \n\nThe idea of single channel (green) images and the histogram equalization comes from this topic: https:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/discussion\/102613#latest-614367\n\nThe CLAHE (Contrast Limited Adaptive Histogram Equalization) used here\nhttps:\/\/docs.opencv.org\/3.1.0\/d5\/daf\/tutorial_py_histogram_equalization.html\n\n\n","3b2aa631":"Now try to gain some visual intuition into healthy and unhealthy patients' pictures.\n\nFollowing code borrowed from @Bharat Singh","dbe60743":"#### Try some different **sigmaX** values.\nWe can see below that maybe sigmaX = 50 is too high, causing some bright white fringes of picture at location (0,0).\n\nNext we tried sigmaX = 16. It looks very similar to sigmaX = 10","ee6875fa":"> ## Basic Image Pre-Processing","b94286f1":"### Crop them!\nFrom the examples above, it's intuitive to not set the sigmaX any where too high.\n\nNext, we want to be able to crop these images so that the dark fringes have approx. the same distribution among all images fed into the network. The code below are directly adapted from the kernel of @Neuron Engineer","6256cd43":"We can see that this dataset is quite imbalanced.\nNext we will visualize some of the training images","8d68cc74":"From the comparison above, we can see that histogram equalization is indeed helping out the blue channel **a little bit**. But it's still not providing much high-quality information.","1cb5e1c7":"#### Conclusion:\nThe green channel is indeed very helpful. The contrast can be effectively adjusted by a simple line of code. I will probably try to use pure green channel to fit a model, as an experiment.","9e291a63":"### Resize & Crop & Combine\nAs described in @Neuron engineer's EDA kernel, another good way to pre-process the RGB images is Ben Grahem's method (https:\/\/github.com\/btgraham\/SparseConvNet\/tree\/kaggle_Diabetic_Retinopathy_competition), which is simple yet powerful. The following function implements this method.","aa08cdbb":"**Green Channel WITHOUT histogram equalization**"}}