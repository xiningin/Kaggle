{"cell_type":{"3ea9ef69":"code","604d7c94":"code","a7a0f898":"code","a50bc555":"code","beb2a570":"code","aae9c1c0":"code","5a96c513":"code","410a6fe2":"code","7bc12a0b":"code","9decd696":"code","b3dd6fae":"code","bc74abde":"code","64b31e3b":"code","a6c32985":"code","3d89db30":"code","ef092e36":"code","a6678a35":"code","5fa637e8":"code","993c1ecf":"code","ee666009":"code","d90bdec8":"code","a9c5405b":"code","255a65ed":"code","7060b600":"code","5364fd52":"code","b571a726":"code","1394d623":"code","01e02c58":"code","fb96354d":"code","1442a904":"markdown","f07ca39f":"markdown","e1d3b92a":"markdown","a6917156":"markdown","6014455c":"markdown","2aa249ef":"markdown","ade224f3":"markdown","d5faa104":"markdown","c2870be3":"markdown","df39a7a0":"markdown","bb096982":"markdown"},"source":{"3ea9ef69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","604d7c94":"df = pd.read_csv(\"\/kaggle\/input\/ecommerce-data\/data.csv\")\ndf.head()","a7a0f898":"df.shape","a50bc555":"df.dtypes","beb2a570":"df[\"InvoiceDateTime\"] = pd.to_datetime(df[\"InvoiceDate\"])\ndf[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDateTime\"].apply(lambda x:x.date()))\ndf.dtypes","aae9c1c0":"df.describe()","5a96c513":"df.isna().sum()","410a6fe2":"print(f\"No. of invoices in the data is {df.InvoiceNo.nunique()}\")\nprint(f\"No. of stock codes in the data is {df.StockCode.nunique()}\")\nprint(f\"No. of descriptions in the data is {df.Description.nunique()}\")\nprint(f\"No. of customers in the data is {df.CustomerID.nunique()}\")\nprint(f\"No. of countries in the data is {df.Country.nunique()}\")\nprint(f\"No. of days in the data is {df.InvoiceDate.nunique()}\")","7bc12a0b":"#Dummy encoding\ndf_dummy = pd.get_dummies(df,dummy_na=True,columns=[\"StockCode\",\"Country\"],drop_first=True)\ndf_dummy.shape","9decd696":"#One Hot encoding\ndf_onehot = pd.get_dummies(df,dummy_na=True,columns=[\"StockCode\",\"Country\"],drop_first=False)\ndf_onehot.shape","b3dd6fae":"np.sort(df.Country.unique())[0]","bc74abde":"df[\"country_temp\"] = df[\"Country\"]\ndf_effect = pd.get_dummies(df,dummy_na=True,columns=[\"country_temp\"],drop_first=True,prefix=\"Country\")\ncol_list = [i for i in list(df_effect.columns) if i.startswith(\"Country_\")]\nfor col in col_list:\n    df_effect[col] = np.where(df_effect[\"Country\"] == \"Australia\",-1,df_effect[col])\ndf_effect.Country_Spain.value_counts()","64b31e3b":"def get_effect_encoded(data,varlist):\n    for var in varlist:\n        data[var+\"_temp\"] = data[var]\n        data_effect = pd.get_dummies(data,dummy_na=True,columns=[var+\"_temp\"],drop_first=True,prefix=var)\n        col_list = [i for i in list(data_effect.columns) if i.startswith(var+\"_\")]\n        for col in col_list:\n            data_effect[col] = np.where(data_effect[var] == np.sort(data[var].unique())[0],-1,data_effect[col])\n    return data_effect","a6c32985":"label_list = df.StockCode.value_counts().rank(ascending=False).reset_index()\nlabel_list.columns = [\"StockCode\",\"StockCode_label\"]\npd.merge(df,label_list,on=\"StockCode\").head()","3d89db30":"def get_freq_labels(data,varlist,ascending=False,tie_method=\"max\"):\n    for var in varlist:\n        label_list = data[var].value_counts().rank(ascending=ascending,method=tie_method).reset_index()\n        label_list.columns = [var,var+\"_label\"]\n        data = pd.merge(data,label_list,on=var)\n    return data","ef092e36":"df_label = get_freq_labels(df,[\"StockCode\",\"Country\"])\ndf_label.head()","a6678a35":"label_list = df.groupby(\"StockCode\")[\"UnitPrice\"].sum().rank(ascending=False).reset_index()\nlabel_list.columns = [\"StockCode\",\"StockCode_label\"]\npd.merge(df,label_list,on=\"StockCode\").head()","5fa637e8":"def get_ordered_labels(data,varlist,targetvar,targetfunc,ascending=False,tie_method=\"max\"):\n    for var in varlist:\n        label_list = data.groupby([var])[targetvar].apply(targetfunc).rank(ascending=ascending,method=tie_method).reset_index()\n        label_list.columns = [var,var+\"_label\"]\n        data = pd.merge(data,label_list,on=var)\n    return data.sort_values([\"InvoiceNo\"])","993c1ecf":"df_label = get_ordered_labels(df,[\"StockCode\",\"Country\"],\"UnitPrice\",sum)\ndf_label.head()","ee666009":"label_list = df.StockCode.value_counts().reset_index()\nlabel_list.columns = [\"StockCode\",\"StockCode_label\"]\npd.merge(df,label_list,on=\"StockCode\").head()","d90bdec8":"def get_freq_encode(data,varlist):\n    for var in varlist:\n        label_list = data[var].value_counts().reset_index()\n        label_list.columns = [var,var+\"_label\"]\n        data = pd.merge(data,label_list,on=var)\n    return data","a9c5405b":"df_label = get_freq_encode(df,[\"StockCode\",\"Country\"])\ndf_label.head()","255a65ed":"label_list = df.groupby(\"StockCode\")[\"UnitPrice\"].sum().rank(ascending=False).reset_index()\nlabel_list.columns = [\"StockCode\",\"StockCode_label\"]\npd.merge(df,label_list,on=\"StockCode\").head()","7060b600":"def get_mean_encode(data,varlist,targetvar,targetfunc):\n    for var in varlist:\n        label_list = data.groupby([var])[targetvar].apply(targetfunc).reset_index()\n        label_list.columns = [var,var+\"_label\"]\n        data = pd.merge(data,label_list,on=var)\n    return data","5364fd52":"df_label = get_mean_encode(df,[\"StockCode\",\"Country\"],\"UnitPrice\",sum)\ndf_label.head()","b571a726":"df[\"rand_bin\"] = np.where(df[\"Quantity\"] > 10,1,0)\ndf_woe = pd.DataFrame(df.groupby(\"Country\")[\"rand_bin\"].mean())\ndf_woe[\"WOE\"] = np.log((df_woe.rand_bin+0.00001)\/(1-(df_woe.rand_bin)+0.00001))\ndf_woe","1394d623":"df[\"country_woe\"] = df[\"Country\"].map(df_woe[\"WOE\"])\ndf.head()","01e02c58":"def get_woe(data,varlist,targetvar):\n    for var in varlist:\n        df_woe = pd.DataFrame(df.groupby(var)[targetvar].mean())\n        df_woe[\"WOE\"] = np.log((df_woe[targetvar]+0.00001)\/(1-(df_woe[targetvar])+0.00001))\n        df[var+\"_woe\"] = df[var].map(df_woe[\"WOE\"])\n    return data","fb96354d":"df_label = get_woe(df,[\"StockCode\",\"Country\"],\"rand_bin\")\ndf_label.head()","1442a904":"## Pros and Cons of each method\n\n1. Dummy, One-hot and effect are most easy to interpret and create. But using these techniques are computationally expensive when the cardinality is very large. These techniques also increase the feature space and can lead to sparse datasets and henceworth weaker models\n2. Effect encoding can be used over dummy\/one-hot encoding if there are constraints over the output. For example, when predicting the house price using number of bedrooms (categorical variable), 2 bedrooms cannot have higher predicted price than 3 bedrooms. If there is a clear cut constraint imposed by the problem statement, then effect encoding perform better than dummy encoding.\n3. Mean encoding and frequency encoding are very helpful as they create only one feature  ut can lead to over fitting, especially mean encoding\n4. WOE encoding is the best encoding technique for a logistic regression model as the WOE variables are similar to logit transformation and hence can give better outputs","f07ca39f":"### One Hot Encoding\/Dummy Encoding\n\nWe create a binary variable indicator for every category. Both the one hot encoding and dummy encoding are very similar except one difference. Taking a variable with k categories, in dummy encoding, we create k-1 features and in one hot encoding, we create k features.\n\n*Example with a picture*","e1d3b92a":"### Weight of Evidence Encoding (Only binary target variable)\n\nThis is most probably the most complex and most widely used categorical encoding technique. WOE is a metric that measures how well a particular category can separate 1 and 0. Below is the formula of WOE\n\n![](https:\/\/miro.medium.com\/max\/281\/1*AqcqDwUB4fk8rcmbvxGiEQ.gif)\n\nWe can encode the different categories with their WOE value. Since we don't have a binary variable in this case, lets create one.","a6917156":"### Ordered Label Encoding\n\nWe give a numeric label to each and every category in the order of the target variable frequency or mean depending on the data type. In this case, if the goal is to predict the sales of a particular product, then ranking in total sales would be the encoding\n\n*Example with a picture*","6014455c":"\n### Mean Encoding\n\nMean encoding is similar to ordered label encoding in the same way frequency encoding is similar to frequency label encoding. We encode the categorical variable by the mean (or sum) of the target variable","2aa249ef":"### Frequency Encoding\n\nThis is very similar to frequency label encoding. Instead of putting the labels, we encode the categories with the frequencies themselves. When we want the scale of the frequency also to be known this is useful","ade224f3":"## Effect Encoding\n\nInstead of using 0,1 as in dummy encoding, we use -1,0,1 in effect encoding. We put 1 if the particular observation belongs to the categoory, 0 if it does not belong to the category and -1 if it belongs to the reference category. In dummy encoding, we put 0 even if the observation belongs to the reference category. More information about effect encoding is present in [this paper](https:\/\/www.researchgate.net\/publication\/256349393_Categorical_Variables_in_Regression_Analysis_A_Comparison_of_Dummy_and_Effect_Coding)","d5faa104":"To avoid encountering 0, add a small number","c2870be3":"## Categorical Variables","df39a7a0":"### Frequency Label Encoding\n\nWe give a numeric label to each and every category in the order of that categories' frequency.\n\n*Example with a picture*","bb096982":"As seen from the shape, One hot encoding have two features more than that of dummy encoding."}}