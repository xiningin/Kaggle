{"cell_type":{"d60554fd":"code","0a6c3e2e":"code","68747692":"code","c0576967":"code","868e6f90":"code","bc96334d":"code","e7adb2be":"code","64b3ba9c":"code","8e2636b1":"code","ce76fb0b":"code","1beb1e0d":"code","8f8013b3":"code","50d07a86":"code","64fe86b2":"code","be9ec487":"code","31d20d7f":"code","5d2c2385":"code","4a868f1d":"code","569dff8c":"code","2c459c8f":"code","26b2520f":"code","0c4e8a97":"code","99891ce9":"code","67a8b460":"code","9c57e135":"code","c8edf026":"code","72e48892":"code","e35ff109":"code","66a8b699":"code","8ec75bf6":"code","e679ed19":"code","58894e5c":"code","7c45297e":"code","3e159a18":"markdown","02396d70":"markdown","be7c8e99":"markdown","05445165":"markdown","d6f699ad":"markdown","e40c12c6":"markdown","97c6c059":"markdown","92fa6638":"markdown","0c9f91bd":"markdown","1862c853":"markdown","fd28f5f7":"markdown","0a24766c":"markdown","0fa514a3":"markdown","18de1c13":"markdown","ed08b5fa":"markdown","7ea402fc":"markdown","e4e58301":"markdown","c613932c":"markdown","6de9d86a":"markdown"},"source":{"d60554fd":"#Importing all the required libraries at once\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns","0a6c3e2e":"#importing the required data set from my data set library\ndf=pd.read_csv(\"..\/input\/used-cars-85-dataset\/Used Cars 85 Dataset.csv\")\n\n#immediately having an idea about how the data set looks\ndf.head(10)","68747692":"#lets get some more info about our data\ndf.info()","c0576967":"#checking NaN values in 'price' feature\ndf['price'].isnull().sum()","868e6f90":"#dropping samples having NaN values for 'price' feature\ndf.dropna(subset=['price'],axis=0,inplace=True)","bc96334d":"#checking NaN values in 'symboling' feature\ndf['symboling'].isnull().sum()","e7adb2be":"#checking NaN values in 'normalized-losses'\ndf['normalized-losses'].isnull().sum()","64b3ba9c":"#replacing NaN values in 'normalized-losses' with its mean\ndf['normalized-losses']=df['normalized-losses'].replace(np.nan,df['normalized-losses'].mean())","8e2636b1":"#checking NaN values in 'wheel-base'\ndf['wheel-base'].isnull().sum()","ce76fb0b":"#checking NaN values in 'length'\ndf['length'].isnull().sum()","1beb1e0d":"#checking NaN values in 'width'\ndf['width'].isnull().sum()","8f8013b3":"#checking NaN values in 'height'\ndf['height'].isnull().sum()","50d07a86":"#checking NaN values in 'curb-weight'\ndf['curb-weight'].isnull().sum()","64fe86b2":"#checking NaN values in 'engine-size'\ndf['engine-size'].isnull().sum()","be9ec487":"#checking NaN values in 'bore'\ndf['bore'].isnull().sum()","31d20d7f":"#replacing NaN values in 'bore' with its mean\ndf['bore']=df['bore'].replace(np.nan,df['bore'].mean())","5d2c2385":"#checking NaN values in 'stroke'\ndf['stroke'].isnull().sum()","4a868f1d":"#replacing NaN values in 'stroke' with its mean\ndf['stroke']=df['stroke'].replace(np.nan,df['stroke'].mean())","569dff8c":"#checking NaN values in 'compression-ratio'\ndf['compression-ratio'].isnull().sum()","2c459c8f":"#checking NaN values in 'horsepower'\ndf['horsepower'].isnull().sum()","26b2520f":"#replacing NaN values in 'horsepower' with its mean\ndf['horsepower']=df['horsepower'].replace(np.nan,df['horsepower'].mean())","0c4e8a97":"#checking NaN values in 'peak-rpm'\ndf['peak-rpm'].isnull().sum()","99891ce9":"#replacing NaN values in 'peak-rpm' with its mean\ndf['peak-rpm']=df['peak-rpm'].replace(np.nan,df['peak-rpm'].mean())","67a8b460":"#checking NaN values in 'city-mpg'\ndf['city-mpg'].isnull().sum()","9c57e135":"#checking NaN values in 'highway-mpg'\ndf['highway-mpg'].isnull().sum()","c8edf026":"#creating LinearRegression object\nlm=LinearRegression()","72e48892":"#predictor or independent variable\nx=df[['symboling','normalized-losses','wheel-base','length','width',\n    'height','curb-weight','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm',\n     'city-mpg','highway-mpg']]\n\n#target or dependent variable\ny=df['price']","e35ff109":"#splitting dataset into ratio of 70% training and 30% testing\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)","66a8b699":"lm.fit(x_train,y_train)","8ec75bf6":"#Model accuracy for training dataset\nlm.score(x_train,y_train)","e679ed19":"#Model accuracy for testing dataset\nlm.score(x_test,y_test)","58894e5c":"yhat=lm.predict(x_test)","7c45297e":"#creating a distribution plot comparing actual values and predicted values of model\naxl = sns.distplot(df['price'], hist=False, label=\"Actual Value\", color='r')\nsns.distplot(yhat, hist=False, label=\"Predicted Value\", color='b', ax=axl)","3e159a18":"To train the model, we will fit the training data using the LinearRegression object.","02396d70":"So the distribution plot gives a perfect visual representation of comparision between actual and predicted values.","be7c8e99":"Now using the distribution plot we can see the difference between actual and predicted values.","05445165":"As we can see that all the datatypes are perfect, we can move ahead.","d6f699ad":"As we have performed data wrangling accurately, let's move ahead. \nNow we will create a simple LinearRegression Model object to apply on our datset.","e40c12c6":"Now let us predict all the values over testing data for further Model evaluation.","97c6c059":"For this project, i am using the data provided at http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/autos\/ which is the used cars dataset of 85'. I downloaded the data and properly uploaded it to my dataset collection for easy access. The data is licence free and custom.","92fa6638":"Here, we will split the data into the ratio of 70% training and 30% testing as it is an ideal amount of division.","0c9f91bd":"As we can see that we got above average model score on both training and testing data having the score of 84% approx. and 78% approx. respectively.","1862c853":"We witnessed that our data have some missing values, we will counter them one by one but firstly we will do for 'price' as it is our target feature here.","fd28f5f7":"As we had a quick look at the dataset, let us verify the datatypes of features so it don't hinder in further processes. We will do it by getting some more information about out dataset.","0a24766c":"So, here we can conclude that our model is capable enough to predict an above average price of used cars using LinearRegression method with testing accuracy of approximately 78%.","0fa514a3":"Now we will one by one deal with all the other required features with keeping in mind that we should not overfit the model.","18de1c13":"Let's have a look how accurate our model is when deployed on training data.","ed08b5fa":"Now, we will declare the predictor and target variable for our model development.","7ea402fc":"We noticed that 'price' feature has 4 missing values. We will prefer dropping them as it is not advised to guess the values of target variable.","e4e58301":"As we only have one dataset, we will have to split it into 2 parts named training and testing data to make model efficiently trained and tested.","c613932c":"And now we will do the same on testing data.","6de9d86a":"As we can see that 'normalized-losses' has missing values, we will try fixing it with the mean value, also we will do the same for other features if we encounter missing values in them."}}