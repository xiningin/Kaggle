{"cell_type":{"374da53b":"code","25cabcac":"code","6a5d7d72":"code","cf89c5a8":"code","0de7870e":"code","afaf4493":"code","3b332324":"code","00b41e34":"code","e1bad212":"code","bd9ba54f":"code","626acda6":"code","31ed25e8":"code","dfbce09c":"code","711ded60":"code","0b739c6b":"code","5f3c6ef5":"code","2af9d938":"markdown"},"source":{"374da53b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","25cabcac":"# libraries\nimport pandas as pd\nfrom tqdm.auto import tqdm\ntqdm.pandas()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport itertools\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor\n\nimport random\nrandom.seed(7)\ntf.random.set_seed(7)","6a5d7d72":"directory = '..\/input\/ventilator-pressure-prediction'\ntrain = pd.read_csv(os.path.join(directory, 'train.csv'))\ntest = pd.read_csv(os.path.join(directory, 'test.csv'))\nsub = pd.read_csv(os.path.join(directory, 'sample_submission.csv'))","cf89c5a8":"train[['R', 'C', 'time_step', 'u_in', 'u_out']].values","0de7870e":"X = train[['R', 'C', 'time_step', 'u_in', 'u_out']].values\nY = train.pressure.values\n\nsample_length = 80\ninput_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  X, None, sequence_length=sample_length, sequence_stride=sample_length)\ntarget_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n\nfor batch in zip(input_dataset, target_dataset):\n  inputs, targets = batch\n  assert np.array_equal(inputs[0], X[:sample_length])\n\n  # second sample equals output timestamps 20-40\n  assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n  break","afaf4493":"import time\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor","3b332324":"train.shape","00b41e34":"def lstm_model():\n    # create model\n    model = Sequential()\n    model.add(Input(shape = (inputs.shape[1], inputs.shape[2])))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer='adam', metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","e1bad212":"def bi_lstm_model():\n    # create model\n    model = Sequential()\n    model.add(Input(shape = (inputs.shape[1], inputs.shape[2])))\n    model.add(Bidirectional(LSTM(640, return_sequences=True)))\n    model.add(Bidirectional(LSTM(320, return_sequences=True)))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(Dense(320, activation = 'relu'))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer='adam', metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","bd9ba54f":"def cnn_lstm_model():\n    # create model\n\n    model = Sequential()\n    model.add(Input(shape = ( inputs.shape[1], inputs.shape[2])))\n    model.add(Conv1D(filters = 320, kernel_size = 3, strides = 1, padding = 'causal', activation = \"relu\" ))\n    model.add(LSTM(320, return_sequences=True, activation = 'tanh'))\n    model.add(LSTM(320, return_sequences=True, activation = 'tanh'))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer = tensorflow.keras.optimizers.Adam(), metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","626acda6":"# define the stages of the pipeline\npipeline = Pipeline(steps= [('model', KerasRegressor(build_fn=cnn_lstm_model, epochs=500, batch_size = 512, verbose=1))])\n\n# fit the pipeline model with the training data                            \npipeline.fit(inputs, targets)","31ed25e8":"4024000\/80","dfbce09c":"sub_array = pipeline.predict(test[['R', 'C', 'time_step', 'u_in', 'u_out']].to_numpy().reshape(50300, 80, 5))\n#list(itertools.chain(*sub_array))","711ded60":"sub_array =list(itertools.chain(*sub_array))","0b739c6b":"#sub_array = pipeline.predict(test[['R', 'C', 'time_step', 'u_in', 'u_out']])","5f3c6ef5":"pd.DataFrame({'id':test.id, 'pressure':sub_array}).to_csv('mark_5.csv', index=False)","2af9d938":"Building from the top down: Implementation of deep-lstms"}}