{"cell_type":{"237e0e77":"code","5e3ed5fe":"code","4ebc4e4e":"code","f9bc1ea2":"code","64c34041":"code","b91b2e80":"code","ef768154":"code","3ede0a14":"code","09a109aa":"code","de934495":"code","2117559e":"code","96ff0e79":"code","27adbc74":"code","15c631f3":"code","4eac4aa7":"code","f9627a24":"code","4798a5d3":"code","422960ba":"code","ab10eb64":"code","9d8dc9c4":"code","3569c1c8":"code","aeb75c1b":"code","e68870b2":"code","76344e59":"code","b20d2de3":"code","398332d5":"code","deec4159":"code","c6a583d0":"markdown","708c322a":"markdown","1bd422b3":"markdown","602b2293":"markdown","04d9cc32":"markdown","f7db701e":"markdown","ceafc07d":"markdown","506d5139":"markdown","ac6c0dc4":"markdown","1b090ec0":"markdown","3ba3e8b7":"markdown","f2baeef9":"markdown","d682e503":"markdown","ed32c2c8":"markdown","0a9eee25":"markdown","ea4edfe6":"markdown","4ef1c714":"markdown","ce1384f8":"markdown"},"source":{"237e0e77":"#Installing PyCaret\n!pip install pycaret","5e3ed5fe":"!python -V","4ebc4e4e":"!pip show pycaret","f9bc1ea2":"import pandas as pd\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ndata_unseen = pd.read_csv('..\/input\/titanic\/test.csv')\nsub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","64c34041":"train.head()","b91b2e80":"import pandas_profiling\ntrain.profile_report()","ef768154":"from pycaret.classification import *\n\n# target = 'objective variable'\nexp = setup(data = train, target = 'Survived', session_id=123)","3ede0a14":"compare_models()","09a109aa":"# choose normal decision tree \ndt = create_model('dt')","de934495":"#trained model object is stored in the variable 'dt'. \nprint(dt)","2117559e":"# Other side, lightgbm model for comparison\nlgb = create_model('lightgbm')","96ff0e79":"print(lgb)","27adbc74":"tuned_dt = tune_model(dt)","15c631f3":"print(tuned_dt)","4eac4aa7":"tuned_lgb = tune_model(lgb)","f9627a24":"%matplotlib inline","4798a5d3":"plot_model(tuned_dt, plot = 'auc')","422960ba":"plot_model(tuned_dt, plot = 'confusion_matrix')","ab10eb64":"evaluate_model(tuned_dt)","9d8dc9c4":"evaluate_model(tuned_lgb)","3569c1c8":"final_dt = finalize_model(tuned_dt)\nresult_dt = predict_model(final_dt, data = data_unseen)","aeb75c1b":"result_dt","e68870b2":"final_lgb = finalize_model(tuned_lgb)\nresult_lgb = predict_model(final_lgb, data = data_unseen)","76344e59":"result_lgb[\"Label\"]","b20d2de3":"y_pred = result_dt[\"Label\"]","398332d5":"sub['Survived'] = y_pred\nsub.to_csv('submission_dt.csv', index=False)","deec4159":"y_pred2 = result_lgb[\"Label\"]\nsub['Survived'] = y_pred2\nsub.to_csv('submission_lgb.csv', index=False)","c6a583d0":"## 3. Import pycaret.classification","708c322a":"> Target Type : Binary or Multiclass. The Target type is automatically detected and shown. There is no difference in how the experiment is performed for Binary or Multiclass problems. All functionalities are identical.","1bd422b3":"## 4. Comparing all models","602b2293":"## 5. Create models","04d9cc32":"## 1. Getting the data","f7db701e":"#### the score of lgb is 0.74641","ceafc07d":"In this notebook, I create models and predict by using [Pycaret](https:\/\/pycaret.org\/),low-code machine learning library.\nAnd this [github](https:\/\/github.com\/pycaret\/pycaret\/blob\/master\/tutorials\/Binary%20Classification%20Tutorial%20Level%20Beginner%20-%20%20CLF101.ipynb) help you getting started and understand with Binary Classification using the 'pycaret.classification' module. ","506d5139":"## 8. Finalize model and Predict on test","ac6c0dc4":"### evaluete_model()\nevaluate_model() function which displays a user interface for all of the available plots for a given model.","1b090ec0":"# Pycaret","3ba3e8b7":"## 6. Tune models","f2baeef9":"#### create_model is the most granular function in PyCaret and is often the foundation behind most of the PyCaret functionalities. As the name suggests this function trains and evaluates a model using cross validation that can be set with fold parameter. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold.","d682e503":"#### Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using stratified cross validation for metric evaluation. The output prints a score grid that shows average Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC accross the folds (10 by default) along with training times.","ed32c2c8":"#### When a model is created using the create_model() function it uses the default hyperparameters to train the model. In order to tune hyperparameters, the tune_model() function is used. This function automatically tunes the hyperparameters of a model using Random Grid Search on a pre-defined search space. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC by fold for the best model. To use the custom search grid, you can pass custom_grid parameter in the tune_model function","0a9eee25":"## 7. Plot a model","ea4edfe6":"#### Model finalization is the last step in the experiment. A normal machine learning workflow in PyCaret starts with setup(), followed by comparing all models using compare_models() and shortlisting a few candidate models (based on the metric of interest) to perform several modeling techniques such as hyperparameter tuning, ensembling, stacking etc. This workflow will eventually lead you to the best model for use in making predictions on new and unseen data. The finalize_model() function fits the model onto the complete dataset including the test\/hold-out sample ","4ef1c714":"## 9. Submit predicts","ce1384f8":"## 2. Check the data"}}