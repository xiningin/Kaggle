{"cell_type":{"b560960e":"code","2501fb14":"code","434e8a04":"code","2988b694":"code","2843f786":"code","c69d626a":"code","ce7be6b9":"code","fd84ba5b":"code","b3b18927":"code","dae428bb":"code","337b8ecd":"code","be285839":"code","27e31f80":"code","26799af1":"code","1d534ee7":"markdown","afaa7efe":"markdown","eed290e8":"markdown","fe409e7c":"markdown","051b75d8":"markdown","6bef6523":"markdown","f576d2fa":"markdown","949aa047":"markdown","e9d83045":"markdown","5285e31a":"markdown","eb6051f2":"markdown"},"source":{"b560960e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Reshape, Flatten\n\nimport random\nimport os\nprint(os.listdir(\"..\/input\"))","2501fb14":"os.listdir('..\/input\/notmnist\/notMNIST\/notMNIST_small')","434e8a04":"from PIL import Image\nim = Image.open(\"..\/input\/notmnist\/notMNIST\/notMNIST_small\/A\/MjAwcHJvb2Ztb29uc2hpbmUgcmVtaXgudHRm.png\")\nprint(im.format, im.size, im.mode)","2988b694":"a_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/A')\nb_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/B')\nc_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/C')\nd_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/D')\ne_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/E')\nf_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/F')\ng_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/G')\nh_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/H')\ni_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/I')\nj_dir = os.path.join('..\/input\/notmnist\/notMNIST\/notMNIST_small\/J')\n\n\nprint('Total training A images:', len(os.listdir(a_dir)))\nprint('Total training B images:', len(os.listdir(b_dir)))\nprint('Total training C images:', len(os.listdir(c_dir)))\nprint('Total training D images:', len(os.listdir(d_dir)))\nprint('Total training E images:', len(os.listdir(e_dir)))\nprint('Total training F images:', len(os.listdir(f_dir)))\nprint('Total training G images:', len(os.listdir(g_dir)))\nprint('Total training H images:', len(os.listdir(h_dir)))\nprint('Total training I images:', len(os.listdir(i_dir)))\nprint('Total training J images:', len(os.listdir(j_dir)))\n\na_files = os.listdir(a_dir)\nprint(a_files[:5])\n\nb_files = os.listdir(b_dir)\nprint(b_files[:5])\n\nc_files = os.listdir(c_dir)\nprint(c_files[:5])\n\nd_files = os.listdir(d_dir)\nprint(d_files[:5])\n\ne_files = os.listdir(e_dir)\nprint(e_files[:5])\n\nf_files = os.listdir(f_dir)\nprint(f_files[:5])\n\ng_files = os.listdir(g_dir)\nprint(g_files[:5])\n\nh_files = os.listdir(h_dir)\nprint(h_files[:5])\n\ni_files = os.listdir(i_dir)\nprint(i_files[:5])\n\nj_files = os.listdir(j_dir)\nprint(j_files[:5])","2843f786":"pic_index = 2\n\nnext_a = [os.path.join(a_dir, fname) \n                for fname in a_files[pic_index-2:pic_index]]\nnext_b = [os.path.join(b_dir, fname) \n                for fname in b_files[pic_index-2:pic_index]]\nnext_c = [os.path.join(c_dir, fname) \n                for fname in c_files[pic_index-2:pic_index]]\nnext_d = [os.path.join(d_dir, fname) \n                for fname in d_files[pic_index-2:pic_index]]\nnext_e = [os.path.join(e_dir, fname) \n                for fname in e_files[pic_index-2:pic_index]]\nnext_f = [os.path.join(f_dir, fname) \n                for fname in f_files[pic_index-2:pic_index]]\nnext_g = [os.path.join(g_dir, fname) \n                for fname in g_files[pic_index-2:pic_index]]\nnext_h = [os.path.join(h_dir, fname) \n                for fname in h_files[pic_index-2:pic_index]]\nnext_i = [os.path.join(i_dir, fname) \n                for fname in i_files[pic_index-2:pic_index]]\nnext_j = [os.path.join(j_dir, fname) \n                for fname in j_files[pic_index-2:pic_index]]\n\nfor i, img_path in enumerate(next_a+next_b+next_c+next_d+next_e+next_f+next_g+next_h+next_i+next_j):\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n    plt.axis('Off')\n    plt.show()","c69d626a":"X = []\nlabels = []\nDATA_PATH = '..\/input\/notmnist\/notMNIST\/notMNIST_small'\n# for each folder (holding a different set of letters)\nfor directory in os.listdir(DATA_PATH):\n    # for each image\n    for image in os.listdir(DATA_PATH + '\/' + directory):\n        # open image and load array data\n        try:\n            file_path = DATA_PATH + '\/' + directory + '\/' + image\n            img = Image.open(file_path)\n            img.load()\n            img_data = np.asarray(img, dtype=np.int16)\n            # add image to dataset\n            X.append(img_data)\n            # add label to labels\n            labels.append(directory)\n        except:\n            None # do nothing if couldn't load file\nN = len(X) # number of images\nimg_size = len(X[0]) # width of image\n# add our single channel for processing purposes\nX = np.asarray(X).reshape(N, img_size, img_size,1) \n# convert to one-hot\nlabels = to_categorical(list(map(lambda x: ord(x)-ord('A'), labels)), 10) ","ce7be6b9":"# TRAINING_DIR = \"..\/input\/notmnist\/notMNIST\/notMNIST_small\/\"\n# training_datagen = ImageDataGenerator(\n#     rescale = 1.\/255,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode='nearest')\n\n# train_generator = training_datagen.flow_from_directory(\n#     TRAINING_DIR,\n#     target_size=(28,28),\n#     batch_size=32,\n#     class_mode='categorical')","fd84ba5b":"temp = list(zip(X, labels))\nnp.random.shuffle(temp)\nX, labels = zip(*temp)\nX, labels = np.asarray(X), np.asarray(labels)\nPROP_TRAIN = 0.7 # proportion to use for training\nNUM_TRAIN = int(N * PROP_TRAIN) # number to use for training\nX_train, X_test = X[:NUM_TRAIN], X[NUM_TRAIN:]\nlabels_train, labels_test = labels[:NUM_TRAIN], labels[NUM_TRAIN:]","b3b18927":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 28x28 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28,1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n#     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","dae428bb":"model.summary()","337b8ecd":"model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","be285839":"# history = model.fit_generator(train_generator,epochs=25,verbose = 1)\ncsv_logger = tf.keras.callbacks.CSVLogger('training.csv', append=True)\n\n# train model\nmodel.fit(X_train, labels_train,\n          epochs=40, batch_size=64,\n          validation_data=[X_test, labels_test],\n          callbacks=[csv_logger])\n\nmodel.save(\"font_basic.h5\")","27e31f80":"data = np.genfromtxt('training.csv', delimiter=',')\ndata = data[1:][:,1:]\n\nfig, axes = plt.subplots(1, 2)\n\n# plot train and test accuracies\naxes[0].plot(data[:,0]) # training accuracy\naxes[0].plot(data[:,2]) # testing accuracy\naxes[0].legend(['Training', 'Testing'])\naxes[0].set_title('Accuracy Over Time')\naxes[0].set_xlabel('epoch')\naxes[0].set_ybound(0.0, 1.0)\n\n# same plot zoomed into [0.85, 1.00]\naxes[1].plot(np.log(1-data[:,0])) # training accuracy\naxes[1].plot(np.log(1-data[:,2])) # testing accuracy\naxes[1].legend(['Training', 'Testing'])\naxes[1].set_title('Log-Inverse Accuracy')\naxes[1].set_xlabel('epoch')\n#axes[1].set_ybound(0.90,1.0)\nplt.show()","26799af1":"score = model.evaluate(X_test, labels_test, verbose=False)\nprint('Loss: {}'.format(score[0]))\nprint('Accuracy: {}%'.format(np.round(10000*score[1])\/100))","1d534ee7":"Next we'll load up all of our images from the subdirectories, storing the labels in a list with one-hot encoding.","afaa7efe":"## Building Model","eed290e8":"Evaluate the model's accuracy on the testing data.","fe409e7c":"## Training","051b75d8":"## Image contents","6bef6523":"## Dataset Overview\n`notMNIST` dataset is created from some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.","f576d2fa":"## Explore the Data","949aa047":"## Import Packages","e9d83045":"## Data Preprocessing","5285e31a":"Then shuffle the data around and split the data into test and training sets.","eb6051f2":"## Evaluating Accuracy and Loss for the Model"}}