{"cell_type":{"2b441400":"code","23f7a444":"code","39992bb9":"code","3fea3ecc":"code","9a97e048":"code","7daa9a20":"code","334cef14":"code","40fc53b1":"code","7bfaab2c":"code","b75a6e4c":"code","455ffd1e":"code","ba96ab98":"code","ecf55b2e":"code","ff740b70":"code","49877894":"code","aaec49d5":"code","22cbb217":"code","f8c96a5f":"code","c55b54a8":"code","94e843ac":"code","d9223147":"code","8308c73e":"code","4437ea84":"code","3eca2cca":"code","087521a2":"code","d70ca05c":"code","fc73f407":"code","375e390f":"code","589da8b6":"code","a6717828":"code","fe8cd8f6":"code","de43b6b6":"code","02a7b25f":"code","f7ce82f2":"code","09b5fa70":"markdown","ec47af8a":"markdown","df7b9586":"markdown","8b4b88e4":"markdown","819d8c0a":"markdown","a879b6ba":"markdown","ee227f4b":"markdown","7f626818":"markdown","63d367ca":"markdown","d8ab783f":"markdown","9fadf747":"markdown","0d01dfb8":"markdown","8f3d9fd3":"markdown","a65256ad":"markdown"},"source":{"2b441400":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23f7a444":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","39992bb9":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')","3fea3ecc":"train.head()","9a97e048":"test.head()","7daa9a20":"print('Training dataset size : ',train.shape)\nprint('Testing dataset size : ',test.shape)","334cef14":"print('Null value is train dataset :\\n',train.isnull().sum())","40fc53b1":"print('Null value is test dataset :\\n',test.isnull().sum())","7bfaab2c":"fig=plt.figure(figsize=(12,8))\nfig=sns.heatmap(train.isnull())","b75a6e4c":"col=[col for col in train.columns if train[col].isnull().sum()>0]\nfor x in col:\n    print('{} missing value : {} %'.format(x,np.round(train[x].isnull().mean(),3)))","455ffd1e":"fig=plt.figure(figsize=(12,8))\nfig=sns.heatmap(test.isnull())","ba96ab98":"col=[col for col in test.columns if test[col].isnull().sum()>0]\nfor x in col:\n    print('{} missing value : {} %'.format(x,np.round(test[x].isnull().mean(),3)))","ecf55b2e":"train.drop('Cabin',axis=1,inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)","ff740b70":"sns.countplot(x='Survived',data=train)","49877894":"sns.countplot(x='Survived',hue='Sex',data=train)","aaec49d5":"sns.countplot(x='Pclass',data=train)","22cbb217":"sns.countplot(x='Pclass',hue='Survived',data=train)","f8c96a5f":"train['Age'].plot.hist(bins=30)","c55b54a8":"train['Fare'].plot.hist(bins=40)","94e843ac":"train['Age']=train['Age'].fillna(train['Age'].mean())\ntest['Age']=test['Age'].fillna(test['Age'].mean())","d9223147":"sex_train=pd.get_dummies(train[\"Sex\"],drop_first=True)\nembarked_train=pd.get_dummies(train[\"Embarked\"],drop_first=True)\n\nsex_test=pd.get_dummies(test[\"Sex\"],drop_first=True)\nembarked_test=pd.get_dummies(test[\"Embarked\"],drop_first=True)","8308c73e":"train=pd.concat([train,sex_train,embarked_train],axis=1)\ntrain.drop(['PassengerId','Sex','Embarked','Name','Ticket'],axis=1,inplace=True)\n\n\n\ntest=pd.concat([test,sex_test,embarked_test],axis=1)\ntest_id=test['PassengerId']  # we will use it at data submission time\ntest.drop(['PassengerId','Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","4437ea84":"test_id","3eca2cca":"train.head(2)","087521a2":"test['Fare']=test['Fare'].fillna(test['Fare'].mean())","d70ca05c":"test.head(2)","fc73f407":"X=train.drop(['Survived'],axis=1)\ny=train['Survived']","375e390f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)","589da8b6":"sc=StandardScaler()\nX_scaled=sc.fit_transform(X_train)","a6717828":"test_scaled=sc.transform(test)","fe8cd8f6":"knn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_scaled,y_train)\nt_scaled=sc.transform(X_test)\np_test=knn.predict(t_scaled)\nprint('accuracy :',accuracy_score(y_test,p_test))\n","de43b6b6":"model = RandomForestClassifier(criterion= 'entropy',n_estimators=500,\n                               bootstrap = True,\n                               max_features = 'sqrt',\n                              random_state=5,max_depth=4,\n                              )\nmodel.fit(X_scaled,y_train)\nt_scaled=sc.transform(X_test)\np_test=model.predict(t_scaled)\nprint('accuracy :',accuracy_score(y_test,p_test))","02a7b25f":"log_reg = LogisticRegression()\nlog_reg.fit(X_scaled,y_train)\nt_scaled=sc.transform(X_test)\np_test=log_reg.predict(t_scaled)\nprint('accuracy :',accuracy_score(y_test,p_test))","f7ce82f2":"pred=model.predict(test_scaled)\nfinal_df=pd.DataFrame({ 'PassengerId' : test_id, 'Survived': pred })\nfinal_df.to_csv('final_dataset.csv',index=False)","09b5fa70":"#### As we can see Cabin column has around 77% missing value so we will just drop this column ","ec47af8a":"## RandomForestClassifier ","df7b9586":"# Data Visualization","8b4b88e4":"### it clearly show that more people in pclass 3 compare to other class because its more cheap lets check the survival rate of different Pcalss ","819d8c0a":"### import libraries","a879b6ba":"### lets first handle age column because it has some nan value","ee227f4b":"### reading our train and test dataset","7f626818":"### Now its looks good","63d367ca":"### Handling categorical features","d8ab783f":"### No of female survivor is much more then the male survivor ","9fadf747":"## KNeighbourClassifier ","0d01dfb8":"## Data Preprocessing ","8f3d9fd3":"## LogisticRegression","a65256ad":"**lets check first five rows of dataset**"}}