{"cell_type":{"7b7d4f65":"code","ca94864e":"code","9e9968fa":"code","30c482b8":"code","2c4067b0":"code","8d846b57":"code","5e1ddded":"code","54687543":"code","87aebf9e":"code","b33e1899":"code","2fae07fb":"code","27411298":"code","6dc990c5":"markdown","350ba894":"markdown","7297224a":"markdown"},"source":{"7b7d4f65":"%%html\n<style>\n@import url('https:\/\/fonts.googleapis.com\/css?family=Ewert|Roboto&effect=3d');\nspan {font-family:'Roboto'; color:black; text-shadow:4px 4px 4px slategray;}  \ndiv.output_area pre{font-family:'Roboto'; font-size:110%; color:#ff355e;}      \n<\/style>","ca94864e":"import numpy as np,pandas as pd\nimport os,h5py,warnings,urllib\nimport tensorflow as tf,pylab as pl\nfrom tensorflow import image as timg\nimport tensorflow.keras.layers as tfkl\nimport tensorflow.keras.applications as tfka\nimport tensorflow_hub as th\nfrom sklearn.metrics import confusion_matrix,\\\nclassification_report\nfrom IPython.core.magic import register_line_magic\nwarnings.filterwarnings('ignore')\npl.style.use('seaborn-whitegrid')\nstyle_dict={'background-color':'silver','color':'#ff355e', \n            'border-color':'white','font-family':'Roboto'}\nfpath='..\/input\/quick-draw-images-from-key-points\/'\nfpath2='..\/input\/quick-draw-images-from-key-points-2\/'\nfpath3='..\/input\/quick-draw-images-from-key-points-3\/'\nfpath4='..\/input\/quick-draw-images-from-key-points-4\/'\nfpath5='..\/input\/quick-draw-images-from-key-points-5\/'\nfpath6='..\/input\/quick-draw-images-from-key-points-6\/'\nfpath7='..\/input\/quick-draw-images-from-key-points-7\/'\nfiles=sorted(os.listdir(fpath))\nfiles2=sorted(os.listdir(fpath2))\nfiles3=sorted(os.listdir(fpath3))\nfiles4=sorted(os.listdir(fpath4))\nfiles5=sorted(os.listdir(fpath5))\nfiles6=sorted(os.listdir(fpath6))\nfiles7=sorted(os.listdir(fpath7))\nfiles2=files2[1:]+[files2[0]]","9e9968fa":"labels=os.listdir('..\/input\/quickdraw-doodle-recognition\/'+\\\n                  'train_simplified\/')\nlabels=np.array(sorted([l[:-4] for l in labels]))","30c482b8":"D=400; x=[]; y=[]\n@register_line_magic\ndef load_img(n):\n    global D,x,y\n    if n=='1': fp=fpath; fns=files; m=5\n    if n=='2': fp=fpath2; fns=files2; m=5\n    if n=='3': fp=fpath3; fns=files3; m=5\n    if n=='4': fp=fpath4; fns=files4; m=5\n    if n=='5': fp=fpath5; fns=files5; m=5\n    if n=='6': fp=fpath6; fns=files6; m=5\n    if n=='7': fp=fpath7; fns=files7; m=4\n    for i in range(m):\n        f=h5py.File(fp+fns[i],'r')\n        keys=list(f.keys())\n        x+=[f[keys[0]][i*10000:i*10000+D] \n            for i in range(10)]\n        y+=[f[keys[1]][i*10000:i*10000+D]\n            for i in range(10)]","2c4067b0":"%load_img 1\n%load_img 2\n%load_img 3\n%load_img 4\n%load_img 5\n%load_img 6\n%load_img 7","8d846b57":"img_size=96\nx=np.array(x)\nnum_classes=x.shape[0]\nx=x.reshape(num_classes*D,img_size,img_size,1)\nx=tf.convert_to_tensor(x,dtype=tf.uint8)\nx=timg.grayscale_to_rgb(x).numpy()\ny=np.array(y).reshape(num_classes*D)\nN=y.shape[0]; n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(12).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx.shape,y.shape","5e1ddded":"nn=np.random.randint(0,N,7)\nll=[labels[y[nn[i]]] for i in range(7)]\npl.figure(figsize=(10,2))\nfor i in range(7):\n    pl.subplot(1,7,i+1)\n    pl.imshow(x[nn[i]])\npl.suptitle('Key Points to Lines: \\n%s'%ll);","54687543":"x_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\ndel x,y,shuffle_ids","87aebf9e":"def premodel(pix,den,mh,lbl,activ,loss):\n    model=tf.keras.Sequential([\n        tf.keras.layers.Input((pix,pix,3),\n                              name='input'),\n        th.KerasLayer(mh,trainable=True),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(den,activation='relu'),\n        tf.keras.layers.Dropout(rate=.5),\n        tf.keras.layers.Dense(lbl,activation=activ)])\n    model.compile(optimizer='adam',\n                  metrics=['accuracy'],loss=loss)\n    display(model.summary())\n    return model\ndef cb(fw):\n    early_stopping=tf.keras.callbacks\\\n    .EarlyStopping(monitor='val_loss',patience=20,verbose=2)\n    checkpointer=tf.keras.callbacks\\\n    .ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)\n    lr_reduction=tf.keras.callbacks\\\n    .ReduceLROnPlateau(monitor='val_loss',verbose=2,\n                       patience=5,factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]","b33e1899":"fw='weights.best.cv001-%s'%num_classes+'.hdf5'\n[handle_base,pixels]=[\"mobilenet_v2_050_96\",img_size]\nmhandle=\"https:\/\/tfhub.dev\/google\/imagenet\/{}\/feature_vector\/4\"\\\n.format(handle_base)","2fae07fb":"model=premodel(pixels,2048,mhandle,num_classes,\n               'softmax','sparse_categorical_crossentropy')\nhistory=model.fit(x=x_train,y=y_train,batch_size=128,\n                  epochs=10,callbacks=cb(fw),\n                  validation_data=(x_valid,y_valid))","27411298":"model.load_weights(fw)\nmodel.evaluate(x_test,y_test)","6dc990c5":"<h1 class='font-effect-3d' style='font-family:Ewert; color:#ff355e; font-size:150%;'> \n    TFHub Models<\/h1>","350ba894":"<h1 class='font-effect-3d' style='font-family:Ewert; color:#ff355e; font-size:150%;'> \n    Data Construction<\/h1>","7297224a":"<h1 class='font-effect-3d' style='font-family:Ewert; color:#ff355e; font-size:150%;'> \n    Code Library, Style, & Links<\/h1>"}}