{"cell_type":{"4e9ed11a":"code","bdf44cd4":"code","194d6065":"code","6756eb35":"code","c763023d":"code","d4eb7cfb":"code","9d40eb16":"code","3eeae461":"code","9100a468":"code","5966dbeb":"code","3ac8f359":"code","25f9ec2f":"code","04482010":"code","4d5f356a":"markdown"},"source":{"4e9ed11a":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n#from keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\n\nIMAGE_SIZE = [224, 224]\n\n\ntrain_directory='..\/input\/fruit-and-vegetables-ssm\/train'\ntest_directory='..\/input\/fruit-and-vegetables-ssm\/test'\nval_directory='..\/input\/fruit-and-vegetables-ssm\/validation'\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdf44cd4":"mobilenet = MobileNetV2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in mobilenet.layers:\n    layer.trainable = False\n\nfolders = glob('..\/input\/fruit-and-vegetables-ssm\/train\/*')\nlen(folders)\n","194d6065":"x = Flatten()(mobilenet.output)\n\nprediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=mobilenet.input, outputs=prediction)","6756eb35":"# view the structure of the model\nmodel.summary()","c763023d":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n\n\n\n# model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\n# step_size_train=train_generator.n\/\/train_generator.batch_size\n# model.fit_generator(generator=train_generator,\n#                    steps_per_epoch=step_size_train,\n#                    epochs=10)","d4eb7cfb":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntraining_set = train_datagen.flow_from_directory(train_directory,\n                                                 target_size = (224, 224),\n                                                 batch_size = 50,\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory(test_directory,\n                                            target_size = (224, 224),\n                                            batch_size = 50,\n                                            class_mode = 'categorical')\n\nprint(len(training_set))\nprint(len(test_set))","9d40eb16":"r = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n)\n# r = model.fit(training_set, train_labels,validation_split=0.1, batch_size = 10, epochs = 20, shuffle=True, verbose=2)","3eeae461":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","9100a468":"model.save(\"ssm_model_50_10.h5\")","5966dbeb":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nmodel = load_model('.\/ssm_model_50_10.h5',compile=False)","3ac8f359":"import json\nlab = training_set.class_indices\nlab={k:v for v,k in lab.items()}\nprint(lab)\nprint(json.dumps(lab, indent=4))","25f9ec2f":"# import matplotlib.pyplot as plt\n# def output(location):\n#     img=load_img(location,target_size=(224,224,3))\n#     plt.imshow(img)\n#     img=img_to_array(img)\n    \n#     img=img\/255\n#     plt.imshow(img)\n#     img=np.expand_dims(img,[0])\n    \n#     answer=model.predict(img)\n#   #  ans2 = imagenet_utils.decode_predictions(answer)\n#     print(answer)\n#     y_class = answer.argmax(axis=-1)\n#     print(answer.argmax(axis=-1))\n#     y = \" \".join(str(x) for x in y_class)\n#     y = int(y)\n#     res = lab[y]\n#     return res\ndef output(location):\n    img=load_img(location,target_size=(224,224,3))\n    img=img_to_array(img)\n    print(img)\n    img=img\/255\n    print(\"after 255 divide\")\n    print(img)\n    img=np.expand_dims(img,[0])\n    print(\"after expanding dims\\n\")\n    print(img)\n    answer=model.predict(img)\n    print(\"after predict\\n\")\n    print(answer)\n    y_class = answer.argmax(axis=-1)\n    print(\"after argmax\\n\")\n    print(y_class)\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = lab[y]\n    return res","04482010":"import matplotlib.pyplot as plt\nimg='..\/input\/fruit-and-vegetable-image-recognition\/test\/pomegranate\/Image_6.jpg'\n# pic=load_img(img)\n#plt.imshow(pic)\noutput(img)","4d5f356a":"# fit the model\n# Run the cell. It will take some time to execute\nr = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)"}}