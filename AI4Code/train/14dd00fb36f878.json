{"cell_type":{"4f7e35c0":"code","61ac18a9":"code","abe190a5":"code","beb68548":"code","3f97894a":"code","01bb09d9":"code","39e49218":"code","3d16d517":"code","f70159e7":"code","c082ff4a":"code","055c9291":"code","83f8d056":"code","e1838d25":"code","fa54ff19":"code","be598553":"code","08a09dc4":"code","47d4e7ef":"code","fb259f22":"code","06a4ab83":"code","bdb91431":"code","ce1d7ed5":"code","7a515bc2":"code","8b72b799":"code","722ea356":"code","8af95176":"code","97bbe898":"code","8802ef93":"code","8ea7da8f":"code","f0a34460":"code","8cc0cf03":"code","4a1cd138":"code","ae1b00fe":"code","06348c7c":"code","7eec2dc1":"code","bdd3e928":"code","1d9ab378":"code","203c59f5":"code","f2dd0d70":"code","89d4c535":"code","6edee57c":"code","52349d2e":"code","acd6cd9d":"code","69ac9d25":"code","0880beb1":"code","b62aff6c":"code","e04c54b9":"code","0893d36d":"code","6cfc5e6f":"code","d4a84bb5":"code","f0986e4c":"code","b5bb72ed":"code","0dc12980":"code","334f1590":"code","80862e07":"code","12950ef9":"code","48179811":"code","014d0401":"markdown","80c02cf1":"markdown","5c932e09":"markdown","35dc701d":"markdown","d42e996d":"markdown"},"source":{"4f7e35c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61ac18a9":"df = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/train.csv\")","abe190a5":"df.columns","beb68548":"df.dtypes","3f97894a":"for i in df.columns:\n    if df[i].dtype != \"object\":\n        print(df[i].value_counts())","01bb09d9":"for i in df.columns:\n    if df[i].dtype == \"object\":\n        print(df[i].value_counts())","39e49218":"for i in df.columns:\n    if df[i].dtype == \"object\":\n        print(i+\": \"+str(df[i].nunique()))","3d16d517":"for i in df.columns:\n    print(df.groupby(i).agg({\"target\":\"mean\"}))","f70159e7":"for i in [1,2,3,4,5,6,7]:\n    print(np.cos(2*np.pi\/6 * (i-1)))","c082ff4a":"df[\"day\"] = np.cos((2*np.pi\/6 * (df.day-1)))","055c9291":"df.groupby(\"day\").agg({\"target\":\"mean\"})","83f8d056":"df.day.unique()","e1838d25":"df[\"ord_5_1\"] = df.ord_5.apply(lambda x: x[0])\ndf[\"ord_5_2\"] = df.ord_5.apply(lambda x: x[1])","fa54ff19":"df.drop(\"ord_5\",axis=1,inplace=True)","be598553":"df.groupby(\"ord_5_1\").agg({\"target\":\"mean\"})","08a09dc4":"df.groupby(\"ord_5_2\").agg({\"target\":\"mean\"})","47d4e7ef":"df[\"bin_3\"] = df.bin_3.replace({\"F\":0,\"T\":1})","fb259f22":"df[\"bin_4\"] = df.bin_4.replace({\"N\":0,\"Y\":1})","06a4ab83":"for i in [\"nom_%d\"%i for i in [5,6,7,8,9]]:\n    df[i] = df[i].apply(lambda x:int(x,16))","bdb91431":"for i in [5,6,7,8,9]:\n    value, bins = pd.qcut(df[\"nom_%d\"%(i)],50,retbins=True)\n    bins = [\"<\"+str(int(i)) for i in bins]\n    plt.plot(bins[1:],pd.concat([df.target,value],axis=1).groupby(\"nom_%d\"%(i)).agg({\"target\":\"mean\"}),marker=\"o\")\n    plt.title(\"nom_%d\"%(i))\n    plt.xticks(rotation=90)\n    plt.show()","ce1d7ed5":"df.nom_5.describe()","7a515bc2":"#for i in [\"nom_%d\"%i for i in [5,6,7,8,9]]:\n#    for j in range(3):\n#        df[\"%s_%d\"%(i,j)] = df[i].apply(lambda x:int(x[j*3:(j+1)*3],16))","8b72b799":"import matplotlib.pyplot as plt","722ea356":"#for i in [5,6,7,8,9]:\n#    for j in [0,1,2]:\n#        value, bins = pd.qcut(df[\"nom_%d_%d\"%(i,j)],10,retbins=True)\n#        bins = [\"<\"+str(int(i)) for i in bins]\n#        plt.plot(bins[1:],pd.concat([df.target,value],axis=1).groupby(\"nom_%d_%d\"%(i,j)).agg({\"target\":\"mean\"}),marker=\"o\")\n#        plt.title(\"nom_%d_%d\"%(i,j))\n#        plt.xticks(rotation=90)\n#        plt.show()","8af95176":"#df.drop([\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\"],axis=1,inplace=True)","97bbe898":"df.ord_1.unique()","8802ef93":"df[\"ord_1\"] = df.ord_1.replace({\"Novice\":1,\"Contributor\":2,\"Expert\":3,\"Master\":4,\"Grandmaster\":5})","8ea7da8f":"df.ord_2.unique()","f0a34460":"df[\"ord_2\"] = df.ord_2.replace({\"Freezing\":1,\"Cold\":2,\"Warm\":3,\"Hot\":4,\"Boiling Hot\":5,\"Lava Hot\":6})","8cc0cf03":"df.groupby(\"ord_1\").agg({\"target\":\"mean\"})","4a1cd138":"df.groupby(\"ord_2\").agg({\"target\":\"mean\"})","ae1b00fe":"df[\"ord_3\"] = df.ord_3.apply(lambda x: ord(x)-64)\ndf[\"ord_4\"] = df.ord_4.apply(lambda x: ord(x)-64)\ndf[\"ord_5_1\"] = df.ord_5_1.apply(lambda x: ord(x)-64)\ndf[\"ord_5_2\"] = df.ord_5_2.apply(lambda x: ord(x)-64)","06348c7c":"df[\"ord_5_concat\"] = df.ord_5_1*100+df.ord_5_2","7eec2dc1":"df.groupby(\"ord_5_concat\").agg({\"target\":\"mean\"})","bdd3e928":"\nplt.plot(np.sort(np.array(df.ord_5_concat.unique())),df.groupby(\"ord_5_concat\").agg({\"target\":\"mean\"}),marker=\".\")\nplt.xticks(rotation=90)\nplt.show()","1d9ab378":"df.drop([\"ord_5_1\",\"ord_5_2\"],axis=1,inplace=True)","203c59f5":"import lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold","f2dd0d70":"value, bins = pd.qcut(df[\"id\"],100,retbins=True)\nbins = [\"<\"+str(int(i)) for i in bins]\nplt.plot(bins[1:],pd.concat([df.target,value],axis=1).groupby(\"id\").agg({\"target\":\"mean\"}),marker=\"o\")\nplt.xticks(rotation=90)\nplt.show()","89d4c535":"def feature_encoding(df):\n    df[\"day\"] = np.cos((2*np.pi\/6 * (df.day-1)))\n    df[\"ord_5_1\"] = df.ord_5.apply(lambda x: x[0])\n    df[\"ord_5_2\"] = df.ord_5.apply(lambda x: x[1])\n\n    df = df.drop(\"ord_5\",axis=1)\n    df[\"bin_3\"] = df.bin_3.replace({\"F\":0,\"T\":1})\n\n    df[\"bin_4\"] = df.bin_4.replace({\"N\":0,\"Y\":1})\n    for i in [\"nom_%d\"%i for i in [5,6,7,8,9]]:\n        df[i] = df[i].apply(lambda x:int(x,16))\n        df[i] = df[i]\/df[i].max()\n    #df = df.drop([\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\"],axis=1)\n    df[\"ord_1\"] = df.ord_1.replace({\"Novice\":1,\"Contributor\":2,\"Expert\":3,\"Master\":4,\"Grandmaster\":5})\n    df[\"ord_2\"] = df.ord_2.replace({\"Freezing\":1,\"Cold\":2,\"Warm\":3,\"Hot\":4,\"Boiling Hot\":5,\"Lava Hot\":6})\n    df[\"ord_3\"] = df.ord_3.apply(lambda x: ord(x)-64)\n    df[\"ord_4\"] = df.ord_4.apply(lambda x: ord(x)-64)\n    df[\"ord_5_1\"] = df.ord_5_1.apply(lambda x: ord(x)-64)\n    df[\"ord_5_2\"] = df.ord_5_2.apply(lambda x: ord(x)-64)\n    df[\"ord_5_concat\"] = df.ord_5_1*100+df.ord_5_2\n    df = df.drop([\"ord_5_1\",\"ord_5_2\"],axis=1)\n    for i in df.columns:\n        if df[i].dtype == 'object':\n            df[i] = df[i].astype(\"category\")\n    return df","6edee57c":"test_df = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/test.csv\")\ndf = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/train.csv\")","52349d2e":"df = feature_encoding(df)","acd6cd9d":"X = df.drop([\"id\",\"target\"],axis=1)\ny = df.target\n\nfor i in X.columns:\n    if X[i].dtype == 'object':\n        X[i] = X[i].astype(\"category\")","69ac9d25":"test_df = feature_encoding(test_df)","0880beb1":"test_id = test_df.id","b62aff6c":"test_df.drop(\"id\",axis=1,inplace=True)","e04c54b9":"import category_encoders as ce\nsmoothing=50\n\noof = pd.DataFrame([])\nfor train_idx, oof_idx in StratifiedKFold(\n    n_splits=5, random_state=123, shuffle=True).split(\n        X, y):\n    ce_target_encoder = ce.TargetEncoder(cols = list(X.dtypes[X.dtypes == \"category\"].index)+[\"nom_%d\"%i for i in [5,6,7,8,9]], smoothing=smoothing)\n    ce_target_encoder.fit(X.iloc[train_idx, :], y.iloc[train_idx])\n    oof = oof.append(ce_target_encoder.transform(X.iloc[oof_idx, :]), ignore_index=False)\n\nce_target_encoder = ce.TargetEncoder(cols = list(X.dtypes[X.dtypes == \"category\"].index)+[\"nom_%d\"%i for i in [5,6,7,8,9]], smoothing=smoothing)\nce_target_encoder.fit(X, y)\nX = oof.sort_index() \ntest_df = ce_target_encoder.transform(test_df)","0893d36d":"X.columns","6cfc5e6f":"test_df.columns","d4a84bb5":"\n\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\npred = []\nfor train_index, test_index in kf.split(X,y):\n    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    train_data = lgb.Dataset(X_train,y_train)\n    eval_data = lgb.Dataset(X_test, label=y_test, reference= train_data)\n    # hyper parameter is imported from other notebook.\n    params={\n        \"learning_rate\":0.05,\n        'max_depth': 2, \n        'num_leaves': 150,\n        'reg_alpha': 0.6, \n        'reg_lambda': 0.6,\n        'objective': 'binary',\n        \"boosting_type\": \"gbdt\",\n        \"metric\": 'auc',\n        'random_state': 1}\n\n    gbm = lgb.train(\n        params,\n        train_data,\n        valid_sets=[train_data,eval_data],\n        num_boost_round=7000,\n        early_stopping_rounds=50,\n        verbose_eval=200,\n    )\n    lgb.plot_importance(gbm,importance_type=\"gain\")\n    pred.append(gbm.predict(test_df, num_iteration=gbm.best_iteration))","f0986e4c":"pred = np.array(pred).mean(axis=0)\ntest_id = pd.DataFrame(test_id)\ntest_id[\"target\"] = pred\n\nsub = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/sample_submission.csv\")\n\ntest_id.to_csv(\"submission.csv\",index=False)","b5bb72ed":"from sklearn.linear_model import LinearRegression, LogisticRegression","0dc12980":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX=scaler.fit_transform(X)\ntest=scaler.transform(test_df)","334f1590":"lr_params = {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.123456789, 'max_iter':500}\nlin = LogisticRegression(**lr_params)\n\nlin.fit(X, y)\npred_lin = lin.predict_proba(test)[:,1]","80862e07":"pred = lin.predict_proba(X)[:,1]","12950ef9":"test_id[\"target\"] = pred_lin\ntest_id.to_csv(\"submission2.csv\",index=False)","48179811":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y,pred)","014d0401":"- `id`: don't have time dependency","80c02cf1":"# Variables survey\n- `id`: unique id (not use)\n- `bin_0,1,2`: 0 or 1\n- `ord_0`: 1,2,3\n- `day`: means day of week","5c932e09":"# category vs target\n- ord3,4: the latter letter has the higher mean value","35dc701d":"- `nom_5,6,7,8,9`: continuos values don't have information...(use target encoding with smoothing)","d42e996d":"- `bin_3,4`: mean true(T) or false(F), Yes(Y) or No(N)\n- `non_5,6,7,8,9`: Too many categories (maybe hex value (36bit), we can convert continous value)"}}