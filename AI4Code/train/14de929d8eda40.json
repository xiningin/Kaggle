{"cell_type":{"0223c7b6":"code","7abc6349":"code","79dac6ae":"code","f261c013":"code","2e41d473":"code","836e529b":"code","ba94acaa":"code","8b661cf7":"code","d1c2734b":"code","a169727c":"code","ea498120":"code","72661700":"code","aceeab96":"code","80dc5068":"code","db6df49d":"code","a8134dac":"code","504ad43b":"code","bf6d954a":"code","4f45935f":"code","6a2f3e5a":"code","fc440b85":"code","d83c39af":"code","4410c767":"code","b605d0be":"code","64b75900":"code","95d3efe8":"code","7ed2160b":"code","e00293ce":"code","4649ceaf":"code","0804d1b9":"code","81ba7d7a":"code","df9f04da":"code","81efcfab":"code","b49a27f7":"code","129613ba":"code","bf0f27fd":"code","4ed124d1":"code","6b985016":"code","e62dda98":"code","a4fdb723":"code","ede83e6f":"code","729f68df":"code","c8942031":"code","46b887cb":"code","dbd2d6a9":"code","11c434c2":"code","25a6d29d":"code","312607d2":"code","e962663b":"code","29c112c8":"code","87116e45":"code","65420a80":"code","2a65db99":"code","10386376":"code","226079e2":"code","0a95082b":"code","700d0ceb":"code","8d85a6ed":"code","0b6ef515":"code","f72c2654":"code","d0f61afd":"code","dcda4e48":"code","bf9b633b":"code","bbc644c8":"code","47b9d208":"code","10a29883":"code","4338b94b":"code","8c5034ef":"code","0a7ec30d":"code","5c6991ad":"code","38ae1747":"code","32639506":"code","b6a8693a":"code","0b6ffa50":"code","747c40d6":"code","c76ca3c4":"code","aa676f0d":"code","95eca221":"code","c263ad3b":"code","88dcd3bf":"code","0e2e0a62":"code","e9bf7710":"code","c02a6519":"code","22b68419":"code","ff5a66ae":"code","218cec92":"code","b05cf959":"code","d9ba3f7d":"code","6e8228e2":"code","605691a6":"code","ef1a7493":"code","90b82ada":"code","32925bca":"code","578bbd58":"code","365b4ddc":"code","64a33ec4":"code","c2e433a3":"code","d60e47d3":"code","3f27a9fa":"code","b3df2336":"code","cd11422e":"code","8f0ba33d":"code","39acb51a":"code","af0e88f9":"code","b2446b76":"code","5e96f3b9":"code","e3ac7d36":"code","e344d053":"markdown","3cd8cd4b":"markdown","fd46e095":"markdown","9eccc06e":"markdown","c8b16495":"markdown","16d3e2e1":"markdown","b4e4d38b":"markdown","20490437":"markdown","c7f66077":"markdown","58a88c60":"markdown","6654867b":"markdown","ccb38685":"markdown","e7d38000":"markdown","e7eb12c4":"markdown","f38a7769":"markdown","8f3755e8":"markdown","d0c3f88f":"markdown","14ba217f":"markdown","079099bb":"markdown","27a300e9":"markdown","e8e87215":"markdown","7cfade7f":"markdown","08d226a3":"markdown","c209f830":"markdown","466b34c2":"markdown","b6ec5794":"markdown","b1efa08f":"markdown","fd02ec5f":"markdown","d9854344":"markdown","735aa15b":"markdown","d2054537":"markdown","784df02c":"markdown","83e1d567":"markdown","9e229758":"markdown","66715bf4":"markdown","316c3930":"markdown","4df84b3e":"markdown","cdf20c64":"markdown","3ca32914":"markdown","21e36567":"markdown","66e2ac34":"markdown","da07b4b0":"markdown","41751f24":"markdown","19681788":"markdown","9a9943ca":"markdown","6a59c891":"markdown","48f6ae93":"markdown","6fdc62aa":"markdown","f8c37b38":"markdown","c515faf4":"markdown","1f1c00d1":"markdown","f8b82f80":"markdown","efa7b421":"markdown","7e6d8bd0":"markdown","81570386":"markdown","3920674e":"markdown","c8ecec27":"markdown","620bd5cf":"markdown","46b299ab":"markdown","a3c9272d":"markdown","d229abd0":"markdown","96560965":"markdown","c1c25891":"markdown","c742f68d":"markdown","90b0a710":"markdown","a2407edf":"markdown","b90dff16":"markdown","9987fe2b":"markdown","24c43469":"markdown","ae3fd025":"markdown","5a178607":"markdown","db9d0dca":"markdown","a92ee83b":"markdown","b0cccb01":"markdown","d63794d2":"markdown","c7f7a026":"markdown","94c72dd5":"markdown","91d79d68":"markdown","c612e50a":"markdown","650fea2f":"markdown","12ae3013":"markdown","09c688f0":"markdown","a1fd0425":"markdown","abd1e7a4":"markdown","ee904f99":"markdown","b6029bd3":"markdown"},"source":{"0223c7b6":"# Importing the requires libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport sklearn\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Displaying all columns\npd.set_option('display.max_columns',200)","7abc6349":"# Surpress warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","79dac6ae":"# Importing the dataset\n\nbike = pd.read_csv('..\/input\/bikesharing\/day.csv')\nbike.head()","f261c013":"# Checking the number of rows and columns in the dataframe\n\nbike.shape","2e41d473":"# Checking the data types and the column-wise info in the data frame\n\nbike.info()","836e529b":"# Checking the numeric columns in the dataframe\n\nbike.describe()","ba94acaa":"# Listing of all the columns\n\nlist(bike.describe().columns)","8b661cf7":"bike.isnull().sum()","d1c2734b":"# Converting to Date Time\n\nbike['dteday'] = pd.to_datetime(bike['dteday'])\nbike['dteday'].dtypes","a169727c":"# Mapping the Season column\ndef map_season(x):\n    return x.map({1:'Spring',2:'Summer',3:'Fall',4:'Winter'})\nbike[['season']] = bike[['season']].apply(map_season)\n\n# Mapping the Month column\ndef map_month(x):\n    return x.map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'June',7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\nbike[['mnth']] = bike[['mnth']].apply(map_month)\n\n# Mapping the Weathersit column\ndef map_weathersit(x):\n    return x.map({1:'Clear',2:'Mist + Cloudy',3:'Light Snow',4:'Heavy Rain + Snow'})\nbike[['weathersit']] = bike[['weathersit']].apply(map_weathersit)\n\n# Mapping the Weekday column\ndef map_weekday(x):\n    return x.map({0:'Sunday',1:'Monday',2:'Tuesday',3:'Wednesday',4:'Thursday',5:'Friday',6:'Saturday'})\nbike[['weekday']] = bike[['weekday']].apply(map_weekday)\n\nbike.head()","ea498120":"# Categorical Columns\n\nbike_categorical = bike.select_dtypes(exclude=['float64', 'int64', 'datetime64'])\nbike_categorical.columns","72661700":"# Numerical Columns\n\nbike_numerical = bike.select_dtypes(exclude=['object','datetime64'])\nbike_numerical.columns","aceeab96":"bike_numerical.columns","80dc5068":"# Plotting pair plot for all of the numerical variables\n\nsns.pairplot(data = bike, vars = bike_numerical)\nplt.show()","db6df49d":"bike['temp'].describe()","a8134dac":"plt.figure(figsize=(12,8))\nsns.distplot(bike['temp'])\n\nplt.xlabel('Temp')\nplt.ylabel('Count')\nplt.title('Relationship Between Target Variable and Temp')\n\nplt.show()","504ad43b":"bike['atemp'].describe()","bf6d954a":"plt.figure(figsize=(12,8))\nsns.distplot(bike['atemp'])\n\nplt.xlabel('ATemp')\nplt.ylabel('Count')\nplt.title('Relationship Between Target Variable and Adjusted Temp')\nplt.show()","4f45935f":"bike['hum'].describe()","6a2f3e5a":"plt.figure(figsize=(12,8))\nsns.distplot(bike['hum'])\n\nplt.xlabel('Humidity')\nplt.ylabel('Count')\nplt.title('Relationship Between Target Variable and Humidity')\n\nplt.show()","fc440b85":"bike['windspeed'].describe()","d83c39af":"plt.figure(figsize=(12,8))\nsns.distplot(bike['windspeed'])\n\nplt.xlabel('Windspeed')\nplt.ylabel('Count')\nplt.title('Relationship Between Target Variable and Windspeed')\n\nplt.show()","4410c767":"num = ['temp', 'atemp', 'hum', 'windspeed', 'cnt']\n\nplt.figure(figsize=(14,6))\n\nfor i in enumerate(num):\n    plt.subplot(3,2, i[0]+1)\n    sns.boxplot(x = i[1], data = bike, palette='mako')","b605d0be":"bike_categorical.columns","64b75900":"# Visualisation of the categorical variables\n\nplt.figure(figsize=(20,20))\nplt.subplot(3,3,1)\nsns.countplot(x = 'yr', data = bike)\nplt.subplot(3,3,2)\nsns.countplot(x='mnth', data = bike)\nplt.subplot(3,3,3)\nsns.countplot(x='season', data = bike)\nplt.subplot(3,3,4)\nsns.countplot(x='weathersit', data = bike)\nplt.subplot(3,3,5)\nsns.countplot(x='workingday', data = bike)\nplt.subplot(3,3,6)\nsns.countplot(x='weekday', data = bike)\nplt.subplot(3,3,7)\nsns.countplot(x='holiday', data = bike)\n\nplt.show()","95d3efe8":"# Checking the value for the 'Year' column\n\nbike['yr'].value_counts()","7ed2160b":"sns.boxplot('yr','cnt', data = bike, palette='viridis')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with the Year 2018 and 2019')\n\n\nplt.show()","e00293ce":"# Checking the value for the Month column\n\nbike['mnth'].value_counts()","4649ceaf":"plt.figure(figsize=(12,6))\nsns.boxplot('mnth','cnt',hue='yr', data = bike, palette='viridis')\n\nplt.xlabel('Month')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with the Year and Month')\n\n\nplt.show()","0804d1b9":"# Checking the value for the Season column\n\nbike['season'].value_counts()","81ba7d7a":"sns.boxplot('season','cnt', data = bike, palette='viridis')\nplt.xlabel('Seasons')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with the Seasons')\n\n\n\nplt.show()","df9f04da":"# Checking the value for the weekday column\n\nbike['weekday'].value_counts()","81efcfab":"plt.figure(figsize=[10,9])\nsns.boxplot('weekday','cnt', data = bike, palette='viridis')\nplt.xlabel('Weekday')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with Weekday')\n\n\nplt.show()","b49a27f7":"# Checking the value for the Working Day column\n\nbike['workingday'].value_counts()","129613ba":"sns.boxplot('workingday','cnt', data = bike, palette='viridis')\nplt.xlabel('Working Day')\nplt.ylabel('Count')\nplt.title('Distribution of Target Variable with Working Day')\n\n\nplt.show()","bf0f27fd":"# Checking the value for the Weathersit column\n\nbike['weathersit'].value_counts()","4ed124d1":"sns.boxplot('weathersit','cnt', data = bike, palette='viridis')\nplt.xlabel('Weathersit')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with the weathersit')\n\n\nplt.show()","6b985016":"# Checking the value for the Holiday column\n\nbike['holiday'].value_counts()","e62dda98":"sns.boxplot('holiday','cnt', data = bike, palette='viridis')\nplt.xlabel('Holiday')\nplt.ylabel('Count')\nplt.title('Distribution of the Target Variable with Holiday')\n\n\nplt.show()","a4fdb723":"# Drop the instant column as it is an index column\n\nbike.drop(['instant'], axis=1, inplace=True)\nbike.head()","ede83e6f":"# Checking the correlation between variables\n\nplt.figure(figsize=(20,10))\nmask = np.array(bike.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(bike.corr(), mask = mask, vmax = .8, square =  True, annot=True, cmap='YlGnBu')\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.title('Correlations Between Variables in the Dataset')\nplt.show()","729f68df":"# Dropping the atemp column based on the high correlation of 0.99 with temp \n\nbike.drop(['atemp'], axis=1, inplace=True)\n\n# Dropping the casual and registered column as the total is the value for our target variable\n\nbike.drop(['casual'], axis=1, inplace=True)\nbike.drop(['registered'], axis=1, inplace=True)\n\n#Dropping the dteday column as the yr and mnth columns are available\n\nbike.drop(['dteday'], axis=1, inplace=True)\n\nbike.head()","c8942031":"# Checking the number of rows and columns\n\nbike.shape","46b887cb":"# Checking the data type for season, month, weekday and weathersit columns\n\nbike[['season','mnth','weekday','weathersit']].dtypes","dbd2d6a9":"# Creating the dummy variables for season, mnth, weekday and weathersit columns\n\nseasons = pd.get_dummies(bike['season'], drop_first=True)\nmonths = pd.get_dummies(bike['mnth'], drop_first=True)\nweekdays = pd.get_dummies(bike['weekday'], drop_first=True)\nweathersit = pd.get_dummies(bike['weathersit'], drop_first=True)","11c434c2":"# Concatenate the dummy variables to the original dataframe\n\nbike = pd.concat([bike, seasons, months, weekdays, weathersit], axis=1)\n\nbike.head()","25a6d29d":"# Dropping the columns which dummy was created\n\nbike.drop(['season','mnth','weekday','weathersit'], axis=1, inplace=True)\nbike.head()","312607d2":"# Checking the rows and columns\n\nbike.shape","e962663b":"# Splitting the dataframe\n\ntrain, test = train_test_split(bike, train_size = 0.7, test_size = 0.3, random_state = 100)\n","29c112c8":"# First thing we have to do is to Instatiate an object\n# Min-Max scaling converted the data to 0 and 1\n\nscaler = MinMaxScaler()\n\n","87116e45":"# We will select out Numerical variables as follows\n\nnum = ['temp','hum','windspeed','cnt']","65420a80":"# Applying Scaler() to all of the numerical columns\n\ntrain[num] = scaler.fit_transform(train[num])\n","2a65db99":"# Checking the variables\n\ntrain.head()","10386376":"# Checking whether the Max values is == 1.\n\ntrain.describe()","226079e2":"# Plotting heatmap to check on the correlation coefficients\n\nplt.figure(figsize=(30,24))\nmask = np.array(train.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(train.corr(), mask = mask, vmax = .8, square =  True, annot=True, cmap='YlGnBu', fmt=\".2f\")\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.title('Correlations Between Variables on the Training Set')\nplt.show()","0a95082b":"# Trained Target variable\n\ny_train = train.cnt\nx_train = train.drop('cnt', axis = 1)","700d0ceb":"# Applying LM\n\nlm = LinearRegression()\nlm.fit(x_train, y_train)","8d85a6ed":"# Rows and columns for the train data\n\nx_train.shape","0b6ef515":"# Selecting total 15 variables for RFE selection\n\nrfe = RFE(lm, 15)\nrfe = rfe.fit(x_train, y_train)","f72c2654":"# The list of all of the variables selected and their ranking\n\nlist(zip(x_train.columns, rfe.support_, rfe.ranking_))\n","d0f61afd":"# Determining the columns with RFE selected variables\n\ncol = x_train.columns[rfe.support_]\ncol","dcda4e48":"# The total values of selected variables\n\n(rfe.support_ == True).sum()","bf9b633b":"# Determining the columns with RFE NOT selected variables\n\nx_train.columns[~rfe.support_]","bbc644c8":"# The total values of NON selected variables\n\n(rfe.support_ == False).sum()","47b9d208":"# Creating x_train_rfe with RFE selected variables\n\nx_train_rfe = x_train[col]","10a29883":"# Add a constant variable\n\nx_train_rfe = sm.add_constant(x_train_rfe)\n\n# Running the Linear Model\n\nlm = sm.OLS(y_train, x_train_rfe).fit()","4338b94b":"# Summary of the 1st Linear Model\n\nprint(lm.summary())","8c5034ef":"# Calculating the VIF for the model\n\nvif = pd.DataFrame()\nvif['Features'] = x_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(x_train_rfe.values, i) for i in range(x_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nprint(vif)","0a7ec30d":"x_train_rfe = x_train_rfe.drop(['const'], axis=1)","5c6991ad":"# Checking VIF after dropping const\n\nvif = pd.DataFrame()\nvif['Features'] = x_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(x_train_rfe.values, i) for i in range(x_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nprint(vif)","38ae1747":"# Drop the 'hum' variable\n\nx_train_rfe1 = x_train_rfe.drop(['hum'], axis = 1)\n","32639506":"# Rebuilding the 2nd model\n\n# Add a constant variable\n\nx_train_lm = sm.add_constant(x_train_rfe1)\n\n# Running the Linear Model\n\nlm = sm.OLS(y_train, x_train_lm).fit()","b6a8693a":"# Summary of the 2nd Linear Model\n\nprint(lm.summary())","0b6ffa50":"# VIF for the 2nd Model\n\nvif = pd.DataFrame()\nX = x_train_rfe1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","747c40d6":"# Drop the Summer variable\n\nx_train_rfe1 = x_train_rfe1.drop(['Summer'], axis = 1)\n","c76ca3c4":"# Rebuilding the 3rd model\n\n# Add a constant variable\n\nx_train_lm = sm.add_constant(x_train_rfe1)\n\n# Running the Linear Model\n\nlm3 = sm.OLS(y_train, x_train_lm).fit()","aa676f0d":"# Summary of the 3rd Linear Model\n\nprint(lm3.summary())","95eca221":"# VIF for the 3rd Model\n\nvif = pd.DataFrame()\nX = x_train_rfe1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c263ad3b":"# Dropping Nov\n\nx_train_rfe1 = x_train_rfe1.drop(['Nov'], axis = 1)","88dcd3bf":"# Rebuilding the 4th model\n\n# Add a constant variable\n\nx_train_lm = sm.add_constant(x_train_rfe1)\n\n# Running the Linear Model\n\nlm4 = sm.OLS(y_train, x_train_lm).fit()","0e2e0a62":"# Summary of the 4th Linear Model\n\nprint(lm4.summary())","e9bf7710":"# VIF for the 4th Model\n\nvif = pd.DataFrame()\nX = x_train_rfe1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c02a6519":"# Dropping 'Dec'\n\nx_train_rfe1 = x_train_rfe1.drop(['Dec'], axis = 1)","22b68419":"# Rebuilding the 5th model\n\n# Add a constant variable\n\nx_train_lm = sm.add_constant(x_train_rfe1)\n\n# Running the Linear Model\n\nlm5 = sm.OLS(y_train, x_train_lm).fit()","ff5a66ae":"# Summary of the 5th Linear Model\n\nprint(lm5.summary())\n","218cec92":"# VIF for the 5th Model\n\nvif = pd.DataFrame()\nX = x_train_rfe1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","b05cf959":"# Drop the 'Jan' column\n\nx_train_rfe1 = x_train_rfe1.drop(['Jan'], axis = 1)","d9ba3f7d":"# Rebuilding the 6th model\n\n# Add a constant variable\n\nx_train_lm = sm.add_constant(x_train_rfe1)\n\n# Running the Linear Model\n\nlm6 = sm.OLS(y_train, x_train_lm).fit()","6e8228e2":"# Summary of the 6th Linear Model\n\nprint(lm6.summary())","605691a6":"# VIF for the 6th Model\n\nvif = pd.DataFrame()\nX = x_train_rfe1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ef1a7493":"# The coefficient values for our 6th Model with 10 variables are as follows:\n\nlm6.params","90b82ada":"y_train_pred = lm6.predict(x_train_lm)","32925bca":"# Checking the Residuals\n\nres = y_train - y_train_pred","578bbd58":"# Plotting the Histogram for the Residual\n\nfig = plt.figure()\nplt.figure(figsize=(14,7))\nsns.distplot((res), bins = 20)\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nplt.title('Error Terms')\nplt.xlabel('Error')\nplt.show()","365b4ddc":"# Print R squared for train\n\nr2_score(y_train, y_train_pred)","64a33ec4":"# Applying Scaler() to all of the numeric variables and fit on data\n\nnum_test = ['temp','hum','windspeed','cnt']\ntest[num_test] = scaler.transform(test[num_test])","c2e433a3":"# Checking whether the value is compressed between 0-1\n# All of the max values are equals to 1\n\ntest.describe()","d60e47d3":"# Plotting heatmap to check on the correlation coefficients\n\nplt.figure(figsize=(30,26))\nmask = np.array(test.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(test.corr(), mask = mask, vmax = .8, square =  True, annot=True, cmap='YlGnBu', fmt=\".2f\")\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.title('Correlations Between Variables on the Test Set')\nplt.show()","3f27a9fa":"# Test columns\n\ntest.columns","b3df2336":"# Creating X and Y for the Test\n\ny_test = test.pop('cnt')\nx_test = test","cd11422e":"# Add a constant variable\n\nx_test = sm.add_constant(x_test)\n\ntest_col = x_train_lm.columns\nx_test = x_test[test_col[1:]]\n\nx_test = sm.add_constant(x_test)\n\nx_test.info()","8f0ba33d":"# Making Predictions for the Test\n\ny_pred = lm6.predict(x_test)\n","39acb51a":"# R2 for our 6th Model\n\nr2 = r2_score(y_test, y_pred)\nround(r2, 4)","af0e88f9":"n = x_test.shape[0]    # No. of rows of test data\np = x_test.shape[1]    # No. of columns of test data\n\nadj_r2 = (1-(1-r2)*(n-1)\/(n-p-1))\nadj_r2","b2446b76":"# Mean Squared Error\n\nmse = mean_squared_error(y_test, y_pred)\nround(mse,4)","5e96f3b9":"# Plotting scatter plot against Actual and Predicted Values\n\nfig = plt.figure(figsize=(15,8))\nsns.regplot(x=y_test, y=y_pred, ci=68, fit_reg=True,scatter_kws={\"color\": \"green\"}, line_kws={\"color\": \"red\"})\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nplt.title('Actual Test Points vs Predicted Test Points')\nplt.xlabel('y_test')\nplt.ylabel('y_pred')\nplt.show()","e3ac7d36":"plt.figure(figsize=(11,5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(x=y_train, y=y_train_pred, c=\"#7CAE00\", alpha=0.3)\n\nplt.tick_params(axis='x', which='both', bottom=False,\n                top=False, labelbottom=False)\n\nz = np.polyfit(y_train, y_train_pred, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test),\"#F8766D\")\n\nplt.ylabel('Predicted')\nplt.xlabel('Train - Actual')\n\nplt.subplot(1, 2, 2)\nplt.scatter(x=y_test, y=y_pred, c=\"#619CFF\", alpha=0.3)\n\nz = np.polyfit(y_test, y_pred, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test),\"#F8766D\")\n\nplt.xlabel('Test - Actual')\n\nplt.show()","e344d053":"### Categorical Variables","3cd8cd4b":"### **`MODEL 5`**","fd46e095":"### _Step 4: Splitting the Data into Training and Test Sets_","9eccc06e":"### SUMMARY:","c8b16495":">> For the 4th Model, our R-Squared is 0.836. We will be removing **Dec** with p-value of 0.037. We will still removing one-by-one till we satisfied with out model.","16d3e2e1":"> For the `humidity\/ hum`, the mean is 62.765, median is at 62.625 and max humidity is at 97.25.","b4e4d38b":"### _STEP 2. Data Visualisation_","20490437":"#### Significant Variables to predict the demand for shared bikes are:\n\n- [X] Temperature \/ Temp\n- [X] Yr\n- [X] Sep\n- [X] Winter\n- [X] July\n- [X] Mist + Cloudy\n- [X] Holiday\n- [X] Spring\n- [X] Light Snow\n- [X] Windspeed","c7f66077":"**Inferences:**\n> High Demands are there within the `Humidity\/ hum` range of 40-80.","58a88c60":"**Inferences:**\n> There more more concentrations of the Target Variable(cnt) within the `windspeed` range of 5-20.","6654867b":"### _**EQUATION OF BEST FITTED LINE:**_\n    \n>**cnt** = 0.2519 +  0.2340(**`yr`**) + (-0.0986)(**`holiday`**) + 0.4515(**`temp`**) + (-0.1398)(**`windspeed`**) + (-0.1108)(**`Spring`**) + 0.04272(**`winter`**) + 0.0577(**`Sep`**) + (-0.2864)(**`Light Snow`**) + (-0.0811)(**`Mist + Cloudy`**)","ccb38685":"`3. Humidity\/Hum`","e7d38000":"> **RFE Support** is True means the variable will be selected, and **RFE Ranking** will rank the variables according to its importance.","e7eb12c4":">> * R-squared values for our 3rd model is 0.838.\n>> We will be removing **'Nov'** further, to find the best model.","f38a7769":"### Dummy Variables","8f3755e8":"### **`MODEL 6`**","d0c3f88f":"**Inferences:**\n> The demand for the year 2019 is far greater than the demand for the year 2018. There are outliers for the year 2019.","14ba217f":">> In our 1st Model, we can see that all of our variables has an acceptable p-values < 0.05, then we will be checking our VIF to check for multicollinearity, hence we will drop the **hum** variable due it its significantly high VIF value = 30.94.","079099bb":"**Inferences:**\n> There are positive relationship between the `Temperature` and the Target Variable. However once the temperature are in range of 10-15, 25-30, the demand has started reducing.","27a300e9":"**Inferences:**\n> The demand for the bike rental is almost equally distributed among the days of the weeks, however slightly higher on Thursday and Friday as compared with the other days.","e8e87215":"**From our above model, we can see that the above model is acceptable due to the following reasons:**\n\n* R-Squared is **0.833 (83.3%)**\n\n> *This explained the variance of the target variable **`(cnt)`**.*\n    \n    \n* Adj R-Squared is **0.30 (83.0%)**\n\n\n* P-values for all of the 10 variables are equivalent to **0.** \n\n* VIF values are **less than 5.** \n\n* F-statistic is **248.7** ( greater than 1) and Prob(F-statistic) is **1.16e-186** (very low).\n\n> *The greater the value of F-Statistics, and the Prob is low indicates that the model is significant.*\n\n* Finally, for this model, all of the p-values are equivalent to 0, and our VIF for all of the variables are less than 5.0. Thus we can say that this is our best model to proceed further.","7cfade7f":"### Checking the Correlations","08d226a3":"### **`MODEL 4`**\n","c209f830":">> Our R-Squared decrease slightly from 0.836 to 0.835. Howver, we will still be removing our variable. Next is **Jan**.","466b34c2":"### _`STEP 1. Making Predictions`_","b6ec5794":"### _Step 5: Building the Linear Model_","b1efa08f":"`2. Atemp\/ Adjusted Temperature`","fd02ec5f":"> For the `Adjusted Temperature\/ Atemp`, the mean temperature lies in 23.726, median at 24.368, and max temperature at 42.044.","d9854344":"**Inferences:**\nThe Correlations for the Train data set are as follows:\n\n`Top 5 Positive Correlations:`\n1. Temp - cnt : 0.64\n2. Yr - cnt : 0.59\n3. Jan - Spring : 0.55\n4. Oct - Winter : 0.55\n5. Nov - Winter : 0.53\n\n> The positive correlations indicates that if 1 variables is increase, the other variable will increase (moves in the same direction).\n\n`Top 5 Negative Correlations:`\n1. Sunday - workingday : -0.63\n2. Saturday - workingday : -0.61\n3. Spring - temp : -0.61\n4. Spring - cnt : -0.55\n5. Jan - temp : -0.45\n\n> The negative correlations indicates the inversely relationship between both variables, where if 1 variable increase, the other 1 variable will decrease.","735aa15b":"`1. Year`","d2054537":"**Inferences:**\n> On a Clear weather, we can see a significant increment on teh demand, followed by Mist + Cloudy weather and very few demand during the Light Snow.","784df02c":"For our Model Building, we decided to go froward with the Mixed approach, whereby we will be applying **Recursive Feature Elimination \/ RFE** by selecting 15 variables from our data. \n\nThen manually we will be removing each variable one-by-one based on its p-value and VIF before finding our best model.","83e1d567":"`1. Temperature`","9e229758":"**Inferences:**\nThe Correlations for the Test data set are as follows:\n\n**`Top 5 Positive Correlations:`**\n1. Temp - cnt : 0.59\n2. Feb - Spring : 0.57\n3. Oct - Winter : 0.54\n4. Nov - Winter : 0.51\n5. Yr - cnt : 0.49\n\n> The positive correlations indicates that if 1 variables is increase, the other variable will increase (moves in the same direction).\n\n**`Top 5 Negative Correlations:`**\n1. Spring - temp : -0.65\n2. Saturday - workingday : -0.61\n3. Spring - cnt : -0.59\n4. Sunday - workingday : -0.57\n5. Jan - temp : -0.40\n\n> The negative correlations indicates the inversely relationship between both variables, where if 1 variable increase, the other 1 variable will decrease.","66715bf4":"### **`MODEL 3`**","316c3930":"> Tha values are all mapped to 0 - 1. And the max values for all of the variables are equal to 1.","4df84b3e":"> There are **`730 rows and 29 columns`**in our data set now.","cdf20c64":"### Checking the Outliers for the Numerical Column","3ca32914":"**Inferences:**\n> As we can see the demand is increasing in the mid-year starting from the month of Mar to Oct and slowly decreasing from the month of Nov and Dec. We can see that there any outliers in almost every month in the dataset.","21e36567":"### Rescalling the Features\n\n2 ways of Rescalling:\n\n1. **Min-Max Scalling (normalisation)** \n    > Data is compressed into 0 and 1\n2. **Standardisation (mean-0, sigma-1)**\n\n\nFor our Modelling, we will choose `Min-Max Scalling.`","66e2ac34":"### _`STEP 7: Model Evaluation`_","da07b4b0":"### Dropping the unnecessary and redundant columns","41751f24":"### Numerical Variables\n","19681788":"**Inferences:**\n> There are no outliers for cnt, temp and atemp, however, few outliers are there in the humidity (hum) variable and many outliers presents in the windspeed column.","9a9943ca":"#### PROBLEM STATEMENT :\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n\nSpecifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\n1. Which variables are significant in predicting the demand for shared bikes.\n2. How well those variables describe the bike demands\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n\n##### Goal:\nModel the demand for shared bikes with the available independent variables.\n\n1. It will be used by the management to understand how exactly the demands vary with different features.\n2. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. \n\n> The model will be a good way for management to understand the demand dynamics of a new market.","6a59c891":"**Inferences:**\n\nFrom the above heatmap, we can see there is a high correlation between Temp and Atemp column. Thus in our next step, we shall drop either 1 of the column before proceed further with our analysis.\n\nAlso, there are positive correlation for our **`Target variable\/ Cnt `** with the columns below:\n* Registered\n* Temp\n* Atemp\n* Casual\n* Yr\n\nThe negative correlations with our **`Target variable\/ Cnt `** can be seen with the columns:\n* Holiday\n* Workingday\n* Hum\n* Windspeed","48f6ae93":"### **`MODEL 2`**","6fdc62aa":"### _STEP 1. Reading And Understanding The Data_","f8c37b38":"#### Checking VIF","c515faf4":"### Building our Model using the statsmodel.","1f1c00d1":"### _Step 3: Data Preparation_","f8b82f80":"**Inferences:**\n> For working day or non-working day, there nare not much of differences in the demand of the bike rental.","efa7b421":"> The mean value for the `Temperature \/ temp` is 20.3193, and the median is 20.4658 while the max temp is 35.328.","7e6d8bd0":"`7. Holiday`","81570386":"### Dropping the unnecessary and redundant columns","3920674e":"`5. WorkingDay`","c8ecec27":"### Applying Scalar on the Test sets","620bd5cf":"### **`MODEL 1`**","46b299ab":"* VIF determines the correlations between the independent variables. The good Vif for the variable shall be less than <= 5. The closer the R-Squared to 1, the higher the value of VIF and multicollinearity.","a3c9272d":"<h2 style = \"color : Brown\"> BIKE SHARING ASSIGNMENT <\/h2>","d229abd0":"The 4 most significant variables which affecting the demand for bike sharing are:\n\n- [X] Temperature - 0.4515\n- [X] Year\/ Yr - 0.2340\n- [X] Sep - 0.0577\n- [X] Winter - 0.0427\n\nAs all of these 4 variables provides positive coefficents with the target variable, thus in order to increase the demand, the 4 variables\/ factors shall be highly considered before making any business decisions.\n\nHence, once the COVID situation is back to normal, in order to increase the sales and volume, the company may focus on these 4 factors.","96560965":">> Our R-Squared for this Model is 84.5%. There are couple variables with quite a bit high of p-value, we will decide further once we look into the VIF of the variables.","c1c25891":"`4. Weekday`","c742f68d":"> There are no Null values in the dataset","90b0a710":"`6. Weathersit`","a2407edf":"> It is important to ensure that the data types of these 4 variables are 'object' data types, before we create our dummy variable.","b90dff16":">**Inferences:**\n    \n    - From the above graphs, we can see that the Residuals are normally distributed and it centered towards 0. Thus it means that the model has a constant variance, HOMOSCEDASTICITY.","9987fe2b":"### Analysing Categorical variables","24c43469":"##### Checking VIF","ae3fd025":"### Analysing Numerical variables","5a178607":"### RESULT COMPARISON:\n\n* R-SQUARED (TRAIN) - **0.833 (83.3%)**\n* R-SQUARED (TEST) - **0.807 (80.7%)**\n* ADJ R-SQUARED (TRAIN) - **0.827 (82.7%)**\n* ADJ R-SQUARED (TEST) - **0.7967 (79.67%)**\n\n> The difference for R-Squared for Train and Test data is only **2.6%**. We can say that the value which is less than 5%, and this is a good R-squared value, hence we can see our model is performing good even on unseen data (test data).\n","db9d0dca":"**_Checking the Null values in the dataframe_**","a92ee83b":"> The mean for the variable `windspeed` is 12.7636, median is at 12.1253 and max is at 34.00\n","b0cccb01":"**Inferences:**\n> There are direct relationship between `Adjusted temperature` and the Target Variable, however once the Adjusted Temperature reached 30, the count has started reducing.","d63794d2":"`4. Wind Speed`","c7f7a026":"##### Checking VIF","94c72dd5":"* All of the coefficients with positive values indicates that they are positively correlated, means the value of independant variables increase, the dependent variable also tends to increase.\n\n* For the Negative coefficients, if the values of the independent variable increase, the dependent variable will decrease.\n\n* If we would have started with Null Hypothesis that all coefficients are zero , then from summary of our 6th model, we see that none of the coeeficients is zero. \n>> Thus, we **reject our null hypothesis in favour of Alternate Hypothesis that our model is statistically significant.**","91d79d68":"**Inferences:**\n> During Summer and Fall season, there is an increase number of demand from the above graph. Followed by Winter and Spring. There are outliers for the season of Spring and Winter.","c612e50a":"### Residual Analysis\n\nResidual analysis is used by assessing the appropriateness of the linear regression model by defining the residuals and examining it by plotting the graphs.","650fea2f":"`2. Month`","12ae3013":"### Dividing into X-Test and Y-test","09c688f0":"### Dividing Data set into X and Y","a1fd0425":"`3. Season`","abd1e7a4":">> * Our R-Squared for our 2nd model is 0.840.\n>> For the next model, we will be dropping **'Summer'** variable. Since there are still VIF values which is > 5.0, thus we will be removing our variable to find the acceptable model.","ee904f99":"### Recursive Feature Elimination (RFE)","b6029bd3":"### Finding the R2, Adjusted R2 and Mean Squared Error"}}