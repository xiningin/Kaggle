{"cell_type":{"53db3e22":"code","42c90aaf":"code","99a4a7e3":"code","038be403":"code","cb71268c":"code","d91b655c":"code","bf19114a":"code","e5d9ae2c":"code","62bf3f50":"code","4b487f45":"code","af77923b":"code","250f8197":"code","e6cea135":"code","c83ab837":"code","36ba3a2d":"code","9bcc0688":"code","ac27cdc4":"code","c46397be":"code","0c4b21ed":"code","c5db47c6":"code","e880d19e":"code","a68e5b53":"code","33ca7de9":"code","3755bd7e":"code","2521b6c5":"code","b79cbcbb":"code","4c7c8021":"code","71100d48":"code","25b88830":"code","9e3a8e86":"code","36343796":"code","50b7210a":"code","3ab07927":"code","1993a4fc":"code","5019cb9e":"code","b118ac3a":"code","1e8d6b55":"code","e6145b99":"code","417662f6":"code","fbfa4f8c":"code","069af60f":"code","7e1fc076":"code","e38ba3be":"code","f7c7b56b":"code","9cf36116":"code","84166c17":"code","ce3971f2":"code","222f3d51":"markdown","8163f73c":"markdown","d0ffd9bf":"markdown","830c5915":"markdown","0a95ee5e":"markdown","ee7e83da":"markdown"},"source":{"53db3e22":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42c90aaf":"metadata = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv')","99a4a7e3":"metadata.dx.value_counts()","038be403":"df_gray = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_L.csv')","cb71268c":"df_gray.head()","d91b655c":"df_gray.label.value_counts()","bf19114a":"labels = [\"akiec\",\"bcc\", \"bkl\", \"df\", \"nv\", \"vasc\", \"mel\"]\ny = df_gray['label']\nX = df_gray.drop(['label'], axis = 1)\nX1 = np.array(X)","e5d9ae2c":"n_samples = len(df_gray.index)\nimages = X1.reshape(n_samples,28,28)","62bf3f50":"plt.figure(figsize = (10,20))\nfor i in range(0,50) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap = 'gray_r')\n    plt.title(labels[y[i]])","4b487f45":"from sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier","af77923b":"# On normalise les valeurs entre 0 et 1\nX = X\/225","250f8197":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","e6cea135":"mlp = MLPClassifier(hidden_layer_sizes = (200,100,50))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","c83ab837":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","36ba3a2d":"Gray_sklearn = mlp_score","9bcc0688":"pd.crosstab(y_test, y_mlp, rownames = ['Reel'], colnames = ['Prediction'], margins = True)","ac27cdc4":"from keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense","c46397be":"print(y[0])\ny_cat = to_categorical(y)\nprint(y_cat[0])","0c4b21ed":"num_classes = y_cat.shape[1]\nprint(num_classes)","c5db47c6":"X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=1)\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","e880d19e":"model = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","a68e5b53":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs = 50, verbose=1)","33ca7de9":"a = model.evaluate(X_test,y_test)\na","3755bd7e":"Gray_Keras = a[1]","2521b6c5":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","b79cbcbb":"plot_scores(train)","4c7c8021":"df_rgb = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_RGB.csv')\ndf_rgb.head()","71100d48":"y_ = df_rgb['label']\nX_ = df_rgb.drop(['label'], axis = 1)\nX1_ = np.array(X_)","25b88830":"image = X1_[0].reshape(28,28,3)\nplt.imshow(image)","9e3a8e86":"n_samples = len(df_rgb.index)\nimages = X1_.reshape(n_samples,28,28,3)","36343796":"plt.figure(figsize = (10,20))\nfor i in range(0,50) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i])\n    plt.title(labels[y[i]])","50b7210a":"# On normalise les valeurs entre 0 et 1\nX_ = X_\/225","3ab07927":"X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2, random_state = 1)","1993a4fc":"mlp = MLPClassifier(hidden_layer_sizes = (200,100,50))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","5019cb9e":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","b118ac3a":"Colore_sklearn = mlp_score","1e8d6b55":"pd.crosstab(y_test, y_mlp, rownames = ['Reel'], colnames = ['Prediction'], margins = True)","e6145b99":"print(y_[0])\ny_cat = to_categorical(y_)\nprint(y_cat[0])","417662f6":"num_classes = y_cat.shape[1]\nprint(num_classes)","fbfa4f8c":"X_train, X_test, y_train, y_test = train_test_split(X_, y_cat, test_size = 0.2, random_state = 1)\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","069af60f":"model = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","7e1fc076":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=30, verbose=1)","e38ba3be":"a = model.evaluate(X_test,y_test)\na","f7c7b56b":"Colore_Keras = a[1]","9cf36116":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","84166c17":"plot_scores(train)","ce3971f2":"print(\"Gray :\")\nprint(\"Sklearn: \", Gray_sklearn)\nprint(\"Keras : \", Gray_Keras)\nprint(\"Color :\")\nprint(\"Sklearn: \", Colore_sklearn)\nprint(\"Keras : \", Colore_Keras)","222f3d51":"## Sklearn","8163f73c":"# Donnes Gray","d0ffd9bf":"## Keras\/Tensorflow","830c5915":"## Keras\/Tensorflow","0a95ee5e":"# Donnes RGB","ee7e83da":"## Sklearn"}}