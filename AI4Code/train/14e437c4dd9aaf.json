{"cell_type":{"4d7d08bd":"code","7130c92c":"code","e83679a9":"code","919a647f":"code","14282baf":"code","57444d08":"code","bb6cfe9a":"code","97265879":"code","83dde990":"code","1c3fd2ec":"code","97631cf4":"code","9d35cfe5":"code","2b2a4939":"code","a9a17eb7":"code","f8fa7cb1":"code","66c5a202":"code","32ade78c":"code","3eea7718":"code","ad825889":"code","e75dc0bf":"code","61193bcd":"code","00aee22c":"code","a1143689":"code","a228cc7b":"code","9833d033":"code","ab7aafe6":"code","01526b4e":"code","3b336730":"code","331d6484":"code","5cd767db":"code","3a45fd6d":"code","e42d7149":"code","e6faea24":"code","6cc0b4af":"code","b3ed5819":"code","1f5e5c37":"code","bc425641":"code","22b71770":"code","7aece59e":"code","78baaeb7":"markdown","24e5a510":"markdown","dad4f76b":"markdown","f2d42228":"markdown","c70d61ae":"markdown","2d974680":"markdown","615db2bb":"markdown","1702402b":"markdown","3eb69fec":"markdown","caf5f5c8":"markdown","6dc900ae":"markdown","69f05b51":"markdown","3ab344f7":"markdown","e866db87":"markdown","a727c9ec":"markdown","be3584bd":"markdown","4313acac":"markdown","f9294d65":"markdown","d9de7812":"markdown","b3b9d8f0":"markdown","3f393a1d":"markdown","2e24b186":"markdown","2a096e8c":"markdown","559a85d2":"markdown","1b9657c3":"markdown","07801d88":"markdown","90381702":"markdown","54aca259":"markdown","470c784a":"markdown","1d3705ef":"markdown","e0816769":"markdown","d5008efd":"markdown","d8eb7110":"markdown","6b3d6a78":"markdown","a63a7794":"markdown","f0ec1a5c":"markdown","1c2facff":"markdown","76cf6278":"markdown","bbcae34f":"markdown","c4de4447":"markdown","41fb518e":"markdown","04fc3be7":"markdown","a66d2d36":"markdown","f0600eae":"markdown","85cd55ee":"markdown","c3386990":"markdown","c6ced6a8":"markdown","c413c113":"markdown","47b51fe1":"markdown","09c5c885":"markdown","c80b4dea":"markdown","ebff25ea":"markdown","d9401e17":"markdown","8846b607":"markdown","38a3e41c":"markdown","51043581":"markdown","2feaffc4":"markdown","8121320e":"markdown","075ebd0c":"markdown","54caaae3":"markdown","c9597736":"markdown","20818a93":"markdown"},"source":{"4d7d08bd":"import pandas as pd # used for reading and manipulating the data\nimport seaborn as sns # used for plotting\nimport matplotlib.pyplot as plt\nfrom keras.utils.np_utils import to_categorical # to_categorical converts vectors to \"1-hot\" vectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport numpy as np\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.losses import categorical_crossentropy\nfrom keras.models import Sequential # used to define the ML model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Lambda, Flatten, Dense, Conv2D, MaxPool2D, Dropout\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom sklearn.metrics import confusion_matrix\n\n","7130c92c":"dataToUse = 5000 # how much data out of the dataset do we want to use? theres 42,000 in total.\ntotalData = 42000\nimageDimensions = [28,28]","e83679a9":"# store the paths to the train and test datasets. Using the kaggle notebook these are available \n# via the \"Data\" tab at the top right corner of the interface.\ndatasetTrainPath = \"..\/input\/digit-recognizer\/train.csv\"\ndatasetTestPath = \"..\/input\/digit-recognizer\/test.csv\"\n#datasetTrain = pd.read_csv(datasetTrainPath, nrows = dataToUse)\n#datasetTest = pd.read_csv(datasetTestPath, nrows = dataToUse)\ndatasetTrain = pd.read_csv(datasetTrainPath)\ndatasetTest = pd.read_csv(datasetTestPath)","919a647f":"datasetTrain.head(5) ## look at the first few items of each dataset","14282baf":"datasetTest.head(5)","57444d08":"# split the train data into x and y, in this case digit image and digit label, respectiely.\ndatasetTrainY = datasetTrain[\"label\"]\ndatasetTrainX = datasetTrain.drop(labels = [\"label\"] , axis = 1)\n# the test data can't be split as it is unlabeled and contains \"only x\".\n# check data for uniformity\nlabelDistributionPlot = sns.countplot(datasetTrainY)","bb6cfe9a":"datasetTrainX.isnull() # converts all non-null values to \"False\" and all null values to \"True\"","97265879":"datasetTrainX.isnull().any() # returns True or False in case there are \/ there aren't any null values for every column","83dde990":"datasetTrainX.isnull().any().describe() # describes the results in a more human-readable manner","1c3fd2ec":"datasetTrainY.head(5)","97631cf4":"datasetTrainY.isnull().any() # for y we can't use \"describe\" because \"any\" already returns just one result because\n# there is just one single column","9d35cfe5":"datasetTest.isnull().any().describe()","2b2a4939":"# values converts the first ([0]) datasetTrainX data into a numpy.ndarray\n# reshape reshapes trainImageExample into a 28x28 grayscale image. the 1 is for grayscale (for RGB we would have 3)\n# and the -1 is for the number of images, which is set to -1 in order to make the reshape function\n# pick the correct number automatically based on the other dimensions chosen.\ntrainImageExample = datasetTrainX.values.reshape(-1,*imageDimensions,1)\n# plot the whole width and height (\":,:\") of the third ([2]) train image (\"0\" is for the only (grayscale) channel)\ndatasetTrainPlot = plt.imshow(trainImageExample[2][:,:,0])","a9a17eb7":"plt.figure(figsize=(12,10))\nnumToPlot = 30\nfor i in range(30):\n    plt.subplot(3,10,i+1)\n    plt.imshow(datasetTrainX.values[i].reshape(*imageDimensions), interpolation = \"nearest\")\nplt.show()","f8fa7cb1":"plt.figure(figsize=(12,10))\nnumToPlot = 30\nfor i in range(30):\n    plt.subplot(3,10,i+1)\n    plt.imshow(datasetTest.values[i].reshape(*imageDimensions), interpolation = \"nearest\")\nplt.show()","66c5a202":"# split 20% of the train data set into a validation data set in a random fashion.\n# if the data was not evenly distributed we would have possibly needed\n# to have used stratify = True in order to avoid unequally splitting the data\nrandomSeed = 0\ndatasetTrainX , datasetValX , datasetTrainY , datasetValY = train_test_split(datasetTrainX, datasetTrainY,\n                                                                             test_size = 0.2, random_state = randomSeed)","32ade78c":"# it is probably enough to either have .astype(\"float32\") or the \".0\" in order to convert the expression to a float\ndatasetTrainX = datasetTrainX.astype(\"float32\") \/ 255.0\ndatasetValX = datasetValX.astype(\"float32\") \/ 255.0","3eea7718":"datasetTrainY = to_categorical(datasetTrainY, num_classes = 10)\ndatasetValY = to_categorical(datasetValY, num_classes = 10)","ad825889":"# reshape the training data\n# values converts datasetTrainX into a numpy.ndarray\n# reshape datasetTrainX into a 28x28 grayscale image. the 1 is for grayscale (for RGB we would have 3)\n# and the -1 is for the number of images, which is set to -1 in order to make the reshape function\n# pick the correct number automatically based on the other dimensions chosen.\n# instead of -1 we could have used datasetTrainX.shape[0] and datasetValX.shape[0]\ndatasetTrainX = datasetTrainX.values.reshape(-1,*imageDimensions,1)\n\n# reshape the validation data\ndatasetValX = datasetValX.values.reshape(-1,*imageDimensions,1)","e75dc0bf":"#batch_size = int(64*(dataToUse\/totalData))\n# explanation on batch_size: with 42000 examples and 80% 20% split we have 42000 * 0.8 = 33600 train examples\n# bath_size 64 means we will have 33600\/64 = 525 batches.\n# steps_per_epoch should in that case not be 33600 but 525 because each step is a batch.\n# this is unlike whats done in https:\/\/www.kaggle.com\/poonaml\/deep-neural-network-keras-way\/notebook\n# where the number of steps is simply the number of train data examples. I don't understand why his notebook compiles.\n# similarly validation_steps should not be genFlowVal.n but genFlowVal.n\/batch_size\nbatch_size = 64\n\ngen = ImageDataGenerator() # used for data augmentation, which we don't do for this model.\ngenFlowTrain = gen.flow(datasetTrainX, datasetTrainY, batch_size = batch_size)\ngenFlowVal = gen.flow(datasetValX, datasetValY, batch_size = batch_size)","61193bcd":"datasetTrainXMean = datasetTrainX.mean().astype(np.float32)\ndatasetTrainXstd = datasetTrainX.std().astype(np.float32)\n\ndef standardize(x):\n    return (x-datasetTrainXMean)\/datasetTrainXstd\n\nmodel = Sequential([\n    Lambda(standardize, input_shape=(*imageDimensions,1)),\n    Flatten(),\n#    Dense(512, activation=\"relu\"),\n    Dense(10, activation=\"softmax\")]) # 10 is the output size, softmax gives probability weights for each output\n\nmodel.compile(optimizer = RMSprop(lr=0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n#model.compile(optimizer = Adam(lr=0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n\n\nprint(\"the model's input shape is \" + str(model.input_shape) + \" and its output shape is \" + str(model.output_shape))","00aee22c":"epochs = 3\n#steps_per_epoch = genFlowTrain.n # total number of examples in batchesTrain\nsteps_per_epoch = genFlowTrain.n \/\/ batch_size\nvalidation_steps = genFlowVal.n \/\/ batch_size\n#history = model.fit(datasetTrainX, datasetTrainY, batch_size = batch_size, epochs = epochs,\n#                   validation_data = (datasetValX, datasetValY), verbose = 2)\nhistory = model.fit_generator(generator = genFlowTrain, steps_per_epoch = steps_per_epoch,epochs = epochs,\n                             validation_data = genFlowVal , validation_steps = validation_steps)","a1143689":"plt.plot(history.history[\"loss\"], color = \"r\")\nplt.plot(history.history[\"val_loss\"], color = \"g\")\nplt.title(\"train (red) and validation (green) losses\")","a228cc7b":"plt.plot(history.history[\"accuracy\"], color = \"r\")\nplt.plot(history.history[\"val_accuracy\"], color = \"g\")\nplt.title(\"train (red) and validation (green) accuracy\")","9833d033":"optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-8, decay = 0.0)","ab7aafe6":"model = Sequential()\n# note the input_shape = (28,28,1) for the first Conv2D layer to account for the size of the input\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\", input_shape = (*imageDimensions,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\")) # note \"10\" because thats the output size (number of digits)\n# also note \"softmax\" which returns probabilities (weights) for each output (digit)","01526b4e":"# note that the metrics used is accuracy, which is only used at the evaluation stage, not in the training stage.\nmodel.compile(optimizer = RMSprop(), loss = categorical_crossentropy, metrics = [\"accuracy\"])","3b336730":"epochs = 10\nbatch_size = 64\n\ngen = ImageDataGenerator() # used for data augmentation, which we don't do for this model.\n#gen.fit(datasetTrainX)\ngenFlowTrain = gen.flow(datasetTrainX, datasetTrainY, batch_size = batch_size)\ngenFlowVal = gen.flow(datasetValX, datasetValY, batch_size = batch_size)\nsteps_per_epoch = genFlowTrain.n \/\/ batch_size # \/\/ performs rounded-down division to int\nvalidation_steps = genFlowVal.n \/\/ batch_size \nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\nhistory = model.fit_generator(generator = genFlowTrain, steps_per_epoch = steps_per_epoch, epochs = epochs,\n                             validation_data = genFlowVal, validation_steps = validation_steps,\n                             )","331d6484":"plt.plot(history.history[\"loss\"], color = \"r\")\nplt.plot(history.history[\"val_loss\"], color = \"g\")\nplt.title(\"train (red) and validation (green) losses\")\nplt.plot()","5cd767db":"plt.plot(history.history[\"accuracy\"], color = \"r\")\nplt.plot(history.history[\"val_accuracy\"], color = \"g\")\nplt.title(\"train (red) and validation (green) accuracy\")\nplt.plot()","3a45fd6d":"gen = ImageDataGenerator(zoom_range = 0.15, height_shift_range = 0.15, width_shift_range = 0.15, rotation_range = 15)\ngenFlowTrain = gen.flow(datasetTrainX, datasetTrainY, batch_size = batch_size)\ngenFlowVal = gen.flow(datasetValX, datasetValY, batch_size = batch_size)","e42d7149":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n","e6faea24":"epochs = 30\n# use just a subset of the validation data in order to speed up the calculation. We will use the rest of it later.\nvalidationDataSample = (datasetValX[:500,:], datasetValY[:500,:])\nhistory2 = model.fit_generator(generator = genFlowTrain, steps_per_epoch = steps_per_epoch, epochs = epochs,\n                             validation_data = validationDataSample, validation_steps = validation_steps,\n                               callbacks = [annealer]\n                             )","6cc0b4af":"final_val_loss, final_val_acc = model.evaluate(datasetValX, datasetValY, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_val_loss, final_val_acc))","b3ed5819":"plt.plot(history2.history[\"loss\"], color = \"r\")\nplt.plot(history2.history[\"val_loss\"], color = \"g\")\nplt.title(\"train (red) and validation (green) losses\")\nplt.plot()","1f5e5c37":"plt.plot(history2.history[\"accuracy\"], color = \"r\")\nplt.plot(history2.history[\"val_accuracy\"], color = \"g\")\nplt.title(\"train (red) and validation (green) accuracy\")\nplt.plot()","bc425641":"predictionsProbabilities = model.predict(datasetValX)\npredictions = np.argmax(predictionsProbabilities, axis = 1)\nactualLabels = np.argmax(datasetValY, axis = 1)\ncm = confusion_matrix(actualLabels,predictions)\nprint(cm)\n","22b71770":"datasetTestArray = np.array(datasetTest)\ndatasetTestArray = datasetTestArray.reshape(-1,28,28,1)\npredictions = model.predict(datasetTestArray)\nprint(predictions)\npredictionsTest = []\nfor prediction in predictions:\n    predictionsTest.append(np.argmax(prediction))","7aece59e":"# create a new data structure with our predicted image labels\nsubmission = pd.DataFrame({\n    \"ImageId\" : datasetTest.index+1,\n    \"Label\": predictionsTest\n})\n# convert it to a csv and save\nsubmission.to_csv('submission.csv', index = False)","78baaeb7":"plot the results","24e5a510":"## Method #3 - Deeper Neural Network ##","dad4f76b":"the images are given as a 1-dimensional vector with 784 values which actually represents a 28x28 grayscale image.\n\nto plot them they are reshaped into these dimensions.","f2d42228":"it is possible to plot multiple images using","c70d61ae":"## import ##","2d974680":"## confusion matrix ##","615db2bb":"in addition to augmentation we use a changing learning rate.","1702402b":"clf = svm.SVC(kernel=\"linear\")\nclf.fit(datasetTrainX, datasetTrainY.ravel()) # ravel returns the flattened underlying data in the form of a ndarray\nclf.score(datasetValX, datasetValY)\n","3eb69fec":"loss: 0.0964 - accuracy: 0.9741","caf5f5c8":"it is important to have validation data in order to test our model on. The validation data is labeled, as opposed to the test data. However, we were not given validation data. Therefore we split the train data into train and validation.\nThis is the first time in the code that randomness comes into play. We define a randomness seed in order to make consequent runs more consistent.","6dc900ae":"results:\n\nRMSprop\n\n3 epochs - loss: 0.2875 - accuracy: 0.9181 - val_loss: 0.2963 - val_accuracy: 0.9198\n100 epochs - loss: 0.2096 - accuracy: 0.9422 - val_loss: 0.3530 - val_accuracy: 0.9173\n\nAdam\n\n3 epochs = loss: 0.1987 - accuracy: 0.9418 - val_loss: 0.3449 - val_accuracy: 0.9141\n\n100 epochs - loss: 0.1988 - accuracy: 0.9418 - val_loss: 0.3469 - val_accuracy: 0.9141\n\nplotting the loss","69f05b51":"result: 87.2% with 42000 data examples. Worse than SVC, at least with the default parameters.","3ab344f7":"SVC: SVC 0.942\n\nshallow neural network: 0.9198\n\ndeep neural network: 0.9914\n\nan accuracy of >99% was reached for the validation data using just 10 epochs and without data augmentation.","e866db87":"\n\n## Method #2 - Neural Network ##","a727c9ec":"try with a different kernel: (cell set to markdown to increase running speed for higher samples, output noted below)","be3584bd":"now calculate the results for the entire validation set","4313acac":"results loss: 0.0964 - accuracy: 0.9741 - val_loss: 0.0297, val_accuracy: 0.9925\n\n","f9294d65":"run the model again","d9de7812":"## predict the results for the test dataset ##","b3b9d8f0":"## preparing the data in preparation for the next methods ##","3f393a1d":"result: with 5000 samples 0.942 as in 94.2% of the validation images are correct. with 42000 samples 97.48%","2e24b186":"result with 5000 samples = 91%, worse than before. With 42000 samples took a long time to run. The documentation states the model is impractical for tens of thousands of examples and above, which is exactly what we see.","2a096e8c":"plot results: the train losses and accuracy indeed go down and up respectively across many epochs, but the validation losses an accuracy stay about the same after the first few epochs. The graphs shows there is no need to perform more than 3-4-5 epochs, and that beyond 20 epochs the quality of the results even degrades due to overfitting.","559a85d2":"## Method #1 - using a Support Vector Machine - SVM SVC & SVM LinearSVC ##","1b9657c3":"## plot some of the data ##","07801d88":"In this notebook I solve the CNN NMIST digit recognizer classifier by using Tensor Flow.\n\nI try several different methods and compare between them with detailed documentation.\n\nThis exercise includes using Convulated Neural Networks (CNNs) to perform 2D image recognition, data augmentation and more. \n\nThe Challenge page on kaggle.com \nhttps:\/\/www.kaggle.com\/c\/digit-recognizer\/overview\n\nThis notebook relies on the following other notebooks:\n\nhttps:\/\/www.kaggle.com\/archaeocharlie\/a-beginner-s-approach-to-classification\n\nhttps:\/\/www.kaggle.com\/toregil\/welcome-to-deep-learning-cnn-99\n\nhttps:\/\/www.kaggle.com\/poonaml\/deep-neural-network-keras-way\n\n","90381702":"## define the model ##","54aca259":"Support Vector Machines (SVM) and specifically SVC NuSVC and LinearSVC perform binary as well as multi classification on a dataset. They define a metric in which the dataset members are placed and divided into areas. The algorithm converges on the boundaries minimizing the loss function, such that the most dataset members are correctly clasified.\n\nread about SVMs here https:\/\/scikit-learn.org\/stable\/modules\/svm.html\n\n (cell set to markdown to increase running speed for higher samples, output noted below)","470c784a":"results loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0283 - val_accuracy: 0.9914","1d3705ef":"the model chosen is:\n- a Conv2D layer with 32 filters with a kernel size of 5x5 which acts like a set of 5x5 filters using a relu activation function, which is a non-linear activation function.\n- another identical Conv2D layer\n- a MaxPool2D layer with a pool size of 2x2 which downsamples the image with a window of 2x2\n- a Dropout layer with a proportionality factor of 0.25 which randomly ignores 25% of the nodes in each step, which reduces overfitting and enhances the connections between the nodes\n- another set of 2 Conv2D, MaxPool2D and Dropout layers, but with 64 filters of 3x3 kernel size for the Conv2D which can possibly be thought of as more numerous, more precise filters for the pre-filtered and downsampled image, as well as strides of 2x2 for the MaxPool2D layer.\n- a Flatten layer in order to convert the image back to 1D\n- two dense layers with another Dropout 50% in-between.","e0816769":"## compile the model ##","d5008efd":"## summary ##","d8eb7110":"best results obtained using a deep convulated  neural network (CNN) with augmentation\n\nresults loss: 0.0964 - accuracy: 0.9741 - val_loss: 0.0297, val_accuracy: 0.9925","6b3d6a78":"plot the gain","a63a7794":"## load the data ##","f0ec1a5c":"## continuing attempt #1 following normalization ##","1c2facff":"try a different SVC which should handle a large number of examples better, a LinearSVC:","76cf6278":"normalization is in general important as it speeds up the calculation.\n\nSpecifically for this dataset it has the added benefit of accounting for differences in brightness between the images.","bbcae34f":"check whether the datasets have any null values","c4de4447":"## define parameters ##","41fb518e":"we see that the data is more or less uniform, theres a more or less equal representation of the different digits.","04fc3be7":"summary:\n\nso far val_accuracy 0.942 with SVC and 0.9198 with a neural network using RMSProp, so that SVC performs better.","a66d2d36":"encode the labels into \"1-hot\" vectors, which are 1d, 10-cells long vectors, with a \"1\" at the index representing the digit and \"0\" in the rest","f0600eae":"## split the train dataset into train and validation datasets ##","85cd55ee":"plot the results","c3386990":"## normalize the data ##","c6ced6a8":"redefine gen to include:\n- random zooming +-15%\n- random shifts in height +-15%\n- random shifts in width +-15%\n- random rotations +- 15 degrees","c413c113":"## check data for difficulties ##","47b51fe1":"reshape the data\n\nthe images are given as a 1-dimensional vector with 784 values which actually represents a 28x28 grayscale image.\n\nwe reshape the images into these dimensions.","09c5c885":"clf = svm.LinearSVC()\nclf.fit(datasetTrainX, datasetTrainY.ravel()) # ravel returns the flattened underlying data in the form of a ndarray\nclf.score(datasetValX, datasetValY)\n","c80b4dea":"## observe the data and look for difficulties ##","ebff25ea":"## submit the results ##","d9401e17":"## Method #4 - Same Deep Neural Network With Data Augmentation ##","8846b607":"try again with normalized data","38a3e41c":"before defining the actual model we will define the optimizer function which the model will use to adjust the different parameters of the neural network in order to minimize the loss function.\n\nThe optimizer is RMSprop with default values. It starts with a high learning rate and decreases it.\n\nthe loss function itself which we will use is \"categorical_crossentropy\" which is the difference between the calculated the actual labels.","51043581":"result: 94.2%, same as before normalization.","2feaffc4":"## Tom Segal's Digit Recognizer Submission","8121320e":"clf = svm.SVC()\nclf.fit(datasetTrainX, datasetTrainY.ravel()) # ravel returns the flattened underlying data in the form of a ndarray\nclf.score(datasetValX, datasetValY)\n","075ebd0c":"clf = svm.SVC() # use the default values C = 1, kernel = \"rbf\", degree = 3, gamma = \"scale\" and so on\nclf.fit(datasetTrainX, datasetTrainY.ravel()) # ravel returns the flattened underlying data in the form of a ndarray\nclf.score(datasetValX, datasetValY)","54caaae3":"we see that there are no null values for datasetTrainX.\nCheck the rest in an identical fashion.","c9597736":"## run the model ##","20818a93":"## results ##"}}