{"cell_type":{"145d2c2b":"code","56d9070b":"code","5fe1f63b":"code","e1674ee6":"code","7374bdec":"code","cfada514":"code","764c6f88":"code","be59a58b":"code","5116790c":"code","44957df9":"code","57884f95":"code","27fab685":"code","39337c11":"code","5746400d":"markdown","f1a36d3a":"markdown","91942c17":"markdown","6b544ff1":"markdown","5f1f7a0d":"markdown","35b54d94":"markdown"},"source":{"145d2c2b":"import pandas as pd\nimport itertools\nfrom scipy.special import comb\nfrom collections import defaultdict","56d9070b":"df_train = pd.read_csv('..\/input\/shopee-train-with-objects\/train_obj_07.csv')\n# Since dataframe is recovered from file, lists have to be converted from strings to Python lists. \n# This step (with high cost) will not be necessary in the test eval, since objects are computed in same instance\nfeatures = ['class_index', 'confidence', 'area', 'coordinates']\nnew_cols = [f'objects_{feature}' for feature in features]\nfor col in new_cols:\n    df_train[col] = df_train.apply(lambda row: eval(row[col]), axis=1)\ndf_train","5fe1f63b":"total_rows = df_train.shape[0]\ntotal_groups = df_train['label_group'].nunique()\nn_elements_per_group = df_train['label_group'].value_counts()","e1674ee6":"df_without_objects = df_train[df_train['objects_class_index'].map(lambda l: l == [])]\nprint(f'Rows without predicted objects {df_without_objects.shape[0]} out of {total_rows} ({round(df_without_objects.shape[0]\/total_rows * 100, 2)}%)')","7374bdec":"objects_names = eval(open('..\/input\/shopee-train-with-objects\/objects_names.txt').read())","cfada514":"count_per_object = []\n\nfor object_index, object_name in enumerate(objects_names):\n    \n    df_with_object = df_train[df_train['objects_class_index'].map(lambda l: object_index in l)]\n    count = df_with_object.shape[0]\n    \n    count_per_object.append(count)\n    \n    if count == 0:\n        print(f'No occurences for object {object_name} ({object_index})')\n        print()\n        continue\n        \n    print(f'Stats for object {object_name} ({object_index})')\n    \n    print(f'\\tAppears in {count} rows (out of {total_rows})')\n    \n    n_groups = df_with_object['label_group'].nunique()\n    print(f'\\tAppears in {n_groups} groups (out of {total_groups})')\n    \n    print(f'\\tInverted Ratio: {round(1 - n_groups \/ count,2)}')\n    \n    n_elements_per_group_with_object = df_with_object['label_group'].value_counts()\n    print(f'\\tAppears in {round(n_elements_per_group_with_object.mean(), 2)} elements on average per group (min = {n_elements_per_group_with_object.min()}, max = {n_elements_per_group_with_object.max()})')\n    \n    # Compute stats of completeness per group\n    percentages = [round(value \/ n_elements_per_group[label_id] * 100, 2) for label_id, value in n_elements_per_group_with_object.items()]\n    print(f'\\tThese elements represent {round(sum(percentages)\/len(percentages),2)}% of their group on average (min = {min(percentages)}%, max = {max(percentages)}%)')\n    \n    confidence_avg = df_with_object.apply(lambda row: row['objects_confidence'][row['objects_class_index'].index(object_index)], axis=1).mean()\n    print(f'\\tConfidence average: {confidence_avg}')\n    print()","764c6f88":"df_train['objects_class_index_set'] = df_train.apply(lambda row: set(row['objects_class_index']), axis=1)","be59a58b":"def group_by_common_objects(n_common_objects: int, min_percentage: float = 5):\n    count = 0\n    average = 0\n    n_min = float('inf')\n    n_max = 0\n    for current_objects in itertools.combinations(range(len(objects_names)), n_common_objects):\n        current_objects = set(current_objects)\n        df_with_current_objects = df_train[df_train['objects_class_index_set'].map(lambda element_objects: current_objects <= element_objects)]\n        n_matches = df_with_current_objects.shape[0]\n        \n        if n_matches > 1:\n            count += 1\n            average = ((count-1)*average + n_matches)\/ count  # Incremental average\n            n_min = min(n_min, n_matches)\n            n_max = max(n_max, n_matches)\n            \n            current_objects = sorted(list(current_objects))\n            percentages = [round(n_matches \/ count_per_object[object_index] * 100, 2) for object_index in current_objects]\n            \n            if all(p > min_percentage for p in percentages):\n                print('Stats for objects:', current_objects, f'N_MATCHES: {n_matches}')\n                for object_index, percentage in zip(current_objects, percentages):\n                    print(f'\\t{objects_names[object_index]} ({object_index}): ORIGINAL_MATCHES {count_per_object[object_index]} - {percentage}%')\n                print()\n            \n    possible_pairs = int(comb(len(objects_names), n_common_objects))\n    print('*'*50)\n    print(f'Total pairs with matches: {count} out of {possible_pairs} ({round(count\/possible_pairs * 100, 2)}%)')\n    print(f'Number of matches stats: Average: {round(average, 2)} Min: {n_min} Max: {n_max}')","5116790c":"#%%time  \n# 28.3s\ngroup_by_common_objects(2)","44957df9":"#%%time  # 12 min 3s\n#group_by_common_objects(3)\n# TODO: function to re-use already computed work with 2 common_objects (only try triples with pairs that have matches)","57884f95":"#%%time\n#group_by_common_objects(4)","27fab685":"def objects_in_groups(min_objects: int, max_objects: int, min_freq: int = 10):\n    objects_in_same_group_freq = defaultdict(lambda: 0)\n    objects_per_label = df_train.groupby('label_group')['objects_class_index_set'].apply(lambda objects: set().union(*objects))\n    \n    for objects in objects_per_label:\n        if min_objects <= len(objects) <= max_objects:\n            objects_in_same_group_freq[tuple(sorted(objects))] += 1\n            \n    for objects in sorted(objects_in_same_group_freq, key=objects_in_same_group_freq.get, reverse=True):\n        if objects_in_same_group_freq[objects] >= min_freq:\n            for object_index in objects:\n                print(f'{objects_names[object_index]} ({object_index})', end=' ')\n            print('appear in ', objects_in_same_group_freq[objects], 'different groups')","39337c11":"objects_in_groups(min_objects=2, max_objects=3)","5746400d":"Read objects names from YOLO list to access name by index afterwards","f1a36d3a":"The following function obtains stats related to objects appearing in the same elements. Also, when this combination represents a high % of the total elements with these objects, info is printed. That is, if the combination between spoon and fork represents more than 5% of the objects with a spoon and more than 5% of the objects with a fork, info is printed (the 5% is arbitrary)","91942c17":"Let's check how many rows do not contain detected objects","6b544ff1":"The following function shows info about combinations of objects that appear alone in the set of detected objects for a group. Thanks to this insight and the information obtained from the previous function, we may be able to understand better what combinations could be determinant and what combinations could be joined to create supergroups","5f1f7a0d":"The following cell displays some general stats per object. We are interested in:\n* High inverted ratio (1- original_ratio), that means that the object appears in few groups with a great number of rows\n* High percentage of representation in groups, that means that the object appear in most of the elements inside a group","35b54d94":"To speed up the following computation and since we are only interested in the appearence or not of the object, let's create a set from the list of detected objects"}}