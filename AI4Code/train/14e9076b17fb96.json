{"cell_type":{"fc3148e8":"code","86085ecc":"code","8cca7ede":"code","df96af9a":"code","d8000641":"code","11f12a66":"code","035d517f":"code","0e9e144e":"code","edab10f6":"code","c6a3d25d":"code","db1c4662":"code","15c5081f":"code","cb7ea66f":"code","86385c52":"code","30d510fa":"code","738cd0ce":"code","6cd215d7":"code","09726d05":"code","89ccdc89":"code","59b95cd5":"code","c88e1a8a":"code","38b2f675":"code","7e3c186b":"code","01b0e5dd":"code","d67857c2":"code","a1222797":"code","707a2f7f":"code","7dffd33e":"code","2f0a66ef":"code","85d023e8":"code","92a8f0eb":"code","e40b9afc":"code","48dbe7a1":"code","9ca4c009":"code","9b977a63":"code","9ca19b98":"code","f5e213ae":"code","f6481ecd":"code","90efee09":"code","4aba2609":"code","464755ec":"code","3a2d704f":"code","7e7a05cb":"code","91587958":"markdown","921bb467":"markdown","57ca1caf":"markdown"},"source":{"fc3148e8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","86085ecc":"train = pd.read_csv('..\/input\/janatahack-machine-learning-for-banking\/train_fNxu4vz.csv')\ntest = pd.read_csv('..\/input\/janatahack-machine-learning-for-banking\/test_fjtUOL8.csv')","8cca7ede":"train.head()","df96af9a":"train.isnull().sum()","d8000641":"train.shape, test.shape","11f12a66":"combine = train.append(test)\ncombine.shape","035d517f":"combine.columns","0e9e144e":"combine['Annual_Income'].describe()","edab10f6":"combine['Annual_Income'] = np.log(combine['Annual_Income'])\ncombine['Annual_Income'].fillna(combine['Annual_Income'].mean(), inplace=True)\ncombine['Annual_Income'].describe()","c6a3d25d":"combine['Debt_To_Income'].describe()","db1c4662":"combine['Debt_To_Income'] = np.log1p(combine['Debt_To_Income'])\ncombine['Debt_To_Income'].describe()","15c5081f":"combine['Gender'].value_counts()","cb7ea66f":"combine['Home_Owner'].value_counts()","86385c52":"combine['Home_Owner'].fillna('Unknown', inplace=True)\ncombine['Home_Owner'].value_counts()","30d510fa":"combine['Income_Verified'].value_counts()","738cd0ce":"combine['Income_Verified'] = combine['Income_Verified'].replace('VERIFIED - income', 'Verf_inc')\ncombine['Income_Verified'] = combine['Income_Verified'].replace('VERIFIED - income source', 'Verf_inc_src')\ncombine['Income_Verified'] = combine['Income_Verified'].replace('not verified', 'Not_verf')\ncombine['Income_Verified'].value_counts()","6cd215d7":"combine['Inquiries_Last_6Mo'].value_counts()","09726d05":"combine['Length_Employed'].value_counts()","89ccdc89":"combine['Length_Employed'] = combine['Length_Employed'].replace('10+ years', 10)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('2 years', 2)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('3 years', 3)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('< 1 year', 0)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('5 years', 5)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('1 year', 1)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('4 years', 4)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('7 years', 7)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('6 years', 6)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('8 years', 8)\ncombine['Length_Employed'] = combine['Length_Employed'].replace('9 years', 9)\ncombine['Length_Employed'].fillna(-1, inplace=True)\ncombine['Length_Employed'] = combine['Length_Employed'].astype('int')\ncombine['Length_Employed'].value_counts()","59b95cd5":"combine['Loan_Amount_Requested'] = combine['Loan_Amount_Requested'].str.replace(',','').astype('int')\ncombine['Loan_Amount_Requested'].describe()","c88e1a8a":"combine['Loan_Amount_Requested'] = np.log(combine['Loan_Amount_Requested'])\ncombine['Loan_Amount_Requested'].describe()","38b2f675":"combine['Months_Since_Deliquency'].describe()","7e3c186b":"combine['Months_Since_Deliquency'].fillna(-1, inplace=True)\nbins= [-1, 0, 30, 60, 182]\nlabels = ['Unknown', 'Month_1', 'Month_2', 'Month_3Plus']\ncombine['Months_Since_Deliquency'] = pd.cut(combine['Months_Since_Deliquency'], bins=bins, labels=labels, right=False)\ncombine['Months_Since_Deliquency'].value_counts()","01b0e5dd":"combine['Number_Open_Accounts'].describe()","d67857c2":"bins= [0, 10, 20, 86]\nlabels = ['Acc_Tier_1', 'Acc_Tier_2', 'Acc_Tier_3']\ncombine['Number_Open_Accounts'] = pd.cut(combine['Number_Open_Accounts'], bins=bins, labels=labels, right=False)\ncombine['Number_Open_Accounts'].value_counts()","a1222797":"combine['Purpose_Of_Loan'].value_counts()","707a2f7f":"combine['Total_Accounts'].describe()","7dffd33e":"bins= [2, 12, 22, 32, 159]\nlabels = ['Tot_Acc_1', 'Tot_Acc_2', 'Tot_Acc_3', 'Tot_Acc_4']\ncombine['Total_Accounts'] = pd.cut(combine['Total_Accounts'], bins=bins, labels=labels, right=False)\ncombine['Total_Accounts'].value_counts()","2f0a66ef":"combine.isnull().sum()","85d023e8":"combine.dtypes","92a8f0eb":"train_cleaned = combine[combine['Interest_Rate'].isnull()!=True].drop(['Loan_ID'], axis=1)\ntrain_cleaned.head()","e40b9afc":"Gender = pd.crosstab(train_cleaned['Gender'], train_cleaned['Interest_Rate'])\nHome_Owner = pd.crosstab(train_cleaned['Home_Owner'], train_cleaned['Interest_Rate'])\nIncome_Verified = pd.crosstab(train_cleaned['Income_Verified'], train_cleaned['Interest_Rate'])\nInquiries_Last_6Mo = pd.crosstab(train_cleaned['Inquiries_Last_6Mo'], train_cleaned['Interest_Rate'])\nLength_Employed = pd.crosstab(train_cleaned['Length_Employed'], train_cleaned['Interest_Rate'])\nMonths_Since_Deliquency = pd.crosstab(train_cleaned['Months_Since_Deliquency'], train_cleaned['Interest_Rate'])\nNumber_Open_Accounts = pd.crosstab(train_cleaned['Number_Open_Accounts'], train_cleaned['Interest_Rate'])\nPurpose_Of_Loan = pd.crosstab(train_cleaned['Purpose_Of_Loan'], train_cleaned['Interest_Rate'])\nTotal_Accounts = pd.crosstab(train_cleaned['Total_Accounts'], train_cleaned['Interest_Rate'])\n\n\nGender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", figsize=(4,4))\nHome_Owner.div(Home_Owner.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nIncome_Verified.div(Income_Verified.sum(1).astype(float), axis=0).plot(kind=\"bar\", figsize=(4,4))\nInquiries_Last_6Mo.div(Inquiries_Last_6Mo.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nLength_Employed.div(Length_Employed.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nMonths_Since_Deliquency.div(Months_Since_Deliquency.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nNumber_Open_Accounts.div(Number_Open_Accounts.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nPurpose_Of_Loan.div(Purpose_Of_Loan.sum(1).astype(float), axis=0).plot(kind=\"bar\")\nTotal_Accounts.div(Total_Accounts.sum(1).astype(float), axis=0).plot(kind=\"bar\")\n\nplt.show()","48dbe7a1":"matrix = train_cleaned.corr() \nf, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(matrix, vmax=.8, square=True, annot=True)","9ca4c009":"combine = pd.get_dummies(combine)\ncombine.shape","9b977a63":"X = combine[combine['Interest_Rate'].isnull()!=True].drop(['Loan_ID','Interest_Rate'], axis=1)\ny = combine[combine['Interest_Rate'].isnull()!=True]['Interest_Rate']\n\nX_test = combine[combine['Interest_Rate'].isnull()==True].drop(['Loan_ID','Interest_Rate'], axis=1)\n\nX.shape, y.shape, X_test.shape","9ca19b98":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.5,\n    'boost': 'gbdt',\n    'feature_fraction': 0.7,\n    'learning_rate': 0.005,\n    'num_class':4,\n    'metric':'multi_logloss',\n    'max_depth': 8,  \n    'num_leaves': 70,\n    'min_data_in_leaf':40,\n    'objective': 'multiclass',\n    'scale_pos_weight':1,\n    'verbosity': 1,\n    'device':'gpu'\n}","f5e213ae":"import lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, f1_score\n\nfeatures = X.columns\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1048)\n\npred_test = np.zeros((len(X_test), 4))\n\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n    print(\"Fold {}\".format(fold_))\n    train_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n    val_data = lgb.Dataset(X.iloc[val_idx], label=y.iloc[val_idx])\n\n    num_round = 1000000\n    classifier = lgb.train(param, train_data, num_round, valid_sets = [train_data, val_data], \n                    verbose_eval=1000, early_stopping_rounds = 1000)\n    pred_y = np.argmax(classifier.predict(X.iloc[val_idx], num_iteration=classifier.best_iteration), axis=1)\n    \n    print(\"CV score: \", f1_score(pred_y, y.iloc[val_idx], average='weighted'))\n    print(confusion_matrix(pred_y, y.iloc[val_idx]))\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = classifier.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    pred_test += classifier.predict(X_test, num_iteration=classifier.best_iteration) \/ folds.n_splits","f6481ecd":"all_feat = feature_importance_df[[\"Feature\",\n                                  \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\", \n                                                                                           ascending=False)\nall_feat.reset_index(inplace=True)\nimportant_feat = list(all_feat['Feature'])\nall_feat","90efee09":"df = X[important_feat]\ncorr_matrix = df.corr().abs()\n\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\nhigh_cor = [column for column in upper.columns if any(upper[column] > 0.98)]\nprint(len(high_cor))\nprint(high_cor)","4aba2609":"features = [i for i in important_feat if i not in high_cor]\nprint(len(features))\nprint(features)","464755ec":"p_test = np.argmax(pred_test, axis=1)","3a2d704f":"submission = pd.DataFrame()\nsubmission['Loan_ID'] = test['Loan_ID']\nsubmission['Interest_Rate'] = p_test.astype('int')\nsubmission.head()","7e7a05cb":"submission.to_csv('submission.csv', index=False)\nsubmission['Interest_Rate'].value_counts()","91587958":"# Problem Statement","921bb467":"Have you ever wondered how lenders use various factors such as credit score, annual income, the loan amount approved, tenure, debt-to-income ratio etc. and select your interest rates? \n\nThe process, defined as \u2018risk-based pricing\u2019, uses a sophisticated algorithm that leverages different determining factors of a loan applicant. Selection of significant factors will help develop a prediction algorithm which can estimate loan interest rates based on clients\u2019 information. On one hand, knowing the factors will help consumers and borrowers to increase their credit worthiness and place themselves in a better position to negotiate for getting a lower interest rate. On the other hand, this will help lending companies to get an immediate fixed interest rate estimation based on clients information. Here, your goal is to use a training dataset to predict the loan rate category (1 \/ 2 \/ 3) that will be assigned to each loan in our test set.\n\nYou can use any combination of the features in the dataset to make your loan rate category predictions. Some features will be easier to use than others.","57ca1caf":"Github Repo: https:\/\/github.com\/bilalProgTech\/online-data-science-ml-challenges\/tree\/master\/AV-Janata-Hack-ML-Banking-Challenge"}}