{"cell_type":{"687491ab":"code","9532b45f":"code","86b24178":"code","63c994ff":"markdown"},"source":{"687491ab":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain=np.loadtxt('..\/input\/parkinglot\/train.csv',delimiter=',',dtype=np.float32, skiprows=1,usecols=range(0,14)) \n\nxtrain=torch.from_numpy(train[:,0:-1])\nytrain=torch.from_numpy(train[:,[-1]])\n\nscaler = preprocessing.StandardScaler() #\uc2a4\ucf00\uc77c \uc870\uc815\nxtrain = scaler.fit_transform(xtrain)\n\nxtrain = torch.FloatTensor(xtrain)\nytrain = torch.FloatTensor(ytrain)","9532b45f":"dataset = TensorDataset(xtrain, ytrain)\ndataloader=DataLoader(dataset, batch_size=16, shuffle=True)\n\nmodel = nn.Sequential(\n    nn.Linear(13, 1),\n    nn.Sigmoid()\n)\n\ntorch.manual_seed(0)\n\noptimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2)\n\nnb_epochs = 100\nfor epoch in range(nb_epochs + 1):\n  for batch_idx, samples in enumerate(dataloader):\n    x_data, y_data = samples\n\n    H = model(x_data)\n    cost = -(y_data * torch.log(H) + (1-y_data)*torch.log(1-H)).mean()\n\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n\n  if epoch % 10 == 0:\n    prediction = H >= torch.FloatTensor([0.5])\n    correct_prediction = prediction.float() == y_data\n    accuracy = correct_prediction.sum().item() \/ len(correct_prediction)\n    print('Epoch {} Cost {} Accuracy {:.2f}%'.format(epoch, cost.item(), accuracy*100))","86b24178":"test=np.loadtxt('..\/input\/parkinglot\/test.csv',delimiter=',',dtype=np.float32, skiprows=1,usecols=range(0,13))  \nxtest=torch.from_numpy(test)\n\nxtest = scaler.transform(xtest)\n\nxtest = torch.FloatTensor(xtest)\n\nH = model(xtest)\n\npredict = H >= torch.FloatTensor([0.5])\n\nsubmit=pd.read_csv('..\/input\/parkinglot\/submission.csv')\n\nfor i in range(len(predict)):\n  submit['Expected'][i]=int(predict[i])\n\nsubmit=submit.astype(int)\nsubmit.to_csv('sub.csv',index=False) \nsubmit","63c994ff":"baseline\uacfc \ub2e4\ub978 \uc810\n\n* train\ub370\uc774\ud130\uc758 \uc2a4\ucf00\uc77c \uc870\uc815\n* \ubbf8\ub2c8\ubc30\uce58\ud559\uc2b5\n* Adagrad \uc635\ud2f0\ub9c8\uc774\uc800 \uc0ac\uc6a9"}}