{"cell_type":{"66fcffa9":"code","cded2fc1":"code","4083c5d1":"code","6ed043c6":"code","cb55cd3f":"code","80d8fe87":"code","fa88fc7a":"code","15c1218c":"code","dd4e65cb":"code","b27ce859":"code","d4c16188":"code","7d9761f0":"code","d3bba994":"code","58788141":"code","79446ef3":"code","d98a71d8":"code","1ede0cda":"code","4bff0314":"code","2a0e4c6e":"code","54e96a47":"code","497c38bd":"code","0b9b76c2":"code","c741293c":"code","b6a31074":"code","789bce30":"code","bcc04272":"code","d072fa12":"code","96028fb9":"code","885ca1b2":"code","2a9487f0":"code","a5b4b858":"code","34dc5d80":"code","ec75e160":"code","2fdb8951":"code","206ccf4a":"code","97bcd1a8":"code","18134e28":"code","9027d782":"code","dfb2657a":"code","a27d8cf2":"code","2a8dbad4":"code","449f8fb8":"code","8272c6f3":"code","3504230f":"code","d46c944e":"code","f8003bcc":"code","b46ab7c6":"code","6bfe82b2":"code","efce9678":"code","91430cb1":"code","72de3ec7":"code","954f4561":"code","816474f1":"code","6d956517":"code","647bd6dd":"code","f7023c75":"code","544fc87d":"code","65b34e8d":"code","63602fb3":"code","5d7201e9":"code","52d5d4a6":"code","1804974c":"code","f7619da8":"code","507fbb70":"code","dbd0d753":"code","4a0187de":"code","6e628929":"code","6885259b":"code","621f1809":"code","435cfa91":"code","e1513c7a":"code","606fa331":"code","388f1960":"code","695ebb8c":"code","6ae4a8e9":"code","45be5da2":"code","d33f9ea5":"code","75114861":"code","7b3de1ff":"markdown","445ebc8b":"markdown","6189203a":"markdown","aaca6b36":"markdown","d0f9d4a3":"markdown"},"source":{"66fcffa9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# for visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# for logistic regression\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nimport sklearn.linear_model as lm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import plot_confusion_matrix\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cded2fc1":"df = pd.read_csv('\/kaggle\/input\/titanicdataset-traincsv\/train.csv')\ndf.head()","4083c5d1":"# for eda\ndf1 = df.copy() # for visualization","6ed043c6":"df1.info()","cb55cd3f":"df1.head()","80d8fe87":"total = df1.isnull().sum().sort_values(ascending=False)\npercent_1 = df1.isnull().sum()\/df1.isnull().count()*100\npercent_2 = (round(percent_1,1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(12)","fa88fc7a":"survived_dict = {\n    1 : 'Survive',\n    0 : 'Dead'\n}","15c1218c":"df1['Survive'] = df1.Survived.map(survived_dict)","dd4e65cb":"df1.drop('Survived', axis =1, inplace=True)\ndf1.head()","b27ce859":"dfsex = df1.groupby(['Survive']).Sex.value_counts().reset_index(level='Survive')\ndfsex = dfsex.rename(columns={\"Survive\":\"Survive\",\"Sex\":\"Count\"}).reset_index()\ndfsex","d4c16188":"labels = ['male', 'female']\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=labels, values=[109, 233], name=\"Survive\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=labels, values=[268, 81], name=\"Dead\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Sex\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Survive', x=0.15, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Dead', x=0.82, y=0.5, font_size=20, showarrow=False)])\nfig.show()","7d9761f0":"fig = px.bar(dfsex, x=\"Sex\", y=\"Count\", color=\"Survive\", barmode='group', height=500, text = 'Count',\n             title =\"According to Class\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide')\nfig.show()","d3bba994":"#sum of living and dead\ndfsurvive = df1.Survive.value_counts().reset_index()\ndfsurvive = pd.DataFrame(dfsurvive)\ndfsurvive","58788141":"fig = px.pie(dfsurvive, values = 'Survive', names = 'index',title = 'Survive and Die')\nfig.show()","79446ef3":"fig = px.histogram(df, x=\"Age\")\nfig.show()","d98a71d8":"# average age of the dead and the living\ndf1.groupby(['Survive']).Age.mean()","1ede0cda":"df1['Pclass'] = df1['Pclass'].replace(1, 'first class')\ndf1['Pclass'] = df1['Pclass'].replace(2, 'second class')\ndf1['Pclass'] = df1['Pclass'].replace(3, 'economy class')","4bff0314":"# Average age by class\ndfclass = df1.groupby(['Pclass']).Age.mean().reset_index()\ndfclass = pd.DataFrame(dfclass)\ndfclass","2a0e4c6e":"fig = px.bar(dfclass, x='Pclass', y='Age', color = 'Pclass')\nfig.show()","54e96a47":"df1.head()","497c38bd":"dfclass1 = df1.groupby(['Survive']).Pclass.value_counts().reset_index(level='Survive')\ndfclass1 = dfclass1.rename(columns={\"Survive\":\"Survive\",\"Pclass\":\"Count\"}).reset_index()\ndfclass1","0b9b76c2":"fig = px.bar(dfclass1, x=\"Pclass\", y=\"Count\", color=\"Survive\", barmode='group', height=500, text = 'Count',\n             title =\"According to Class\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide')\nfig.show()","c741293c":"# transform age\ndef age_level(Age):\n    if Age > 55:\n        return 'old'\n    elif Age > 40 and Age < 55:\n        return 'midlife'\n    elif Age > 18 and Age < 40 :\n        return 'young'\n    else:\n        return 'kid'","b6a31074":"df1['age_level'] = df1.Age.apply(age_level)","789bce30":"df1.age_level.value_counts()","bcc04272":"df1.drop('Age', axis = 1, inplace = True)","d072fa12":"# Number of deaths by age level\ndfagelevel = df1.groupby(['Survive']).age_level.value_counts().reset_index(level='Survive')\ndfagelevel = dfagelevel.rename(columns={\"Survive\":\"Survived\",\"age_level\":\"Count\"}).reset_index()\ndfagelevel","96028fb9":"fig = px.bar(dfagelevel, x=\"age_level\", y=\"Count\", color=\"Survived\", barmode='group', height=500, text = 'Count',\n             title =\"According to Age Level\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide')\nfig.show()","885ca1b2":"df1['city']=df1.Embarked.apply(lambda x: 'Southampton' if x == 'S' else 'Queenstown' if x == 'Q' else 'Cherbourg')","2a9487f0":"df1.drop('Embarked', axis=1, inplace=True)","a5b4b858":"# how many people from which city\ndf1.city.value_counts()","34dc5d80":"gender_city = df1.groupby(['Sex']).city.value_counts().reset_index(level='Sex')\ngender_city = gender_city.rename(columns={'Sex':'Sex', 'city':'Count'}).reset_index()\ngender_city","ec75e160":"fig = px.bar(gender_city, x=\"city\", y=\"Count\", color=\"Sex\", title=\"Gender and City\")\nfig.show()","2fdb8951":"df1.groupby(['Survive']).city.value_counts()","206ccf4a":"# Cinsiyete g\u00f6re bilet fiyat\u0131 ortalamas\u0131 \ndf1.groupby(['Sex']).Fare.mean()","97bcd1a8":"# Average ticket price by gender\ndf1.groupby(['Sex']).Pclass.value_counts()","18134e28":"data = df1[['SibSp','Parch']]\ndata ['relatives'] = data['SibSp']+data['Parch']\ndata.head()","9027d782":"# Created a new column according to whether it is alone or not\ndf1['relatives']=data ['relatives'].apply(lambda x: 'not alone' if x > 0 else 'alone')","dfb2657a":"df1.drop('SibSp', axis=1, inplace=True)\ndf1.drop('Parch', axis=1, inplace=True)","a27d8cf2":"# how many of the dead and the living are alone, how many are not alone\ndf1.groupby(['Survive']).relatives.value_counts()","2a8dbad4":"df1['Fare'].describe()","449f8fb8":"# ticket price transformation\ndef fare_level(Fare):\n    if Fare > 31.500000:\n        return 'rich'\n    elif Fare > 14.454200 and Fare < 31.000000:\n        return 'middle-up'\n    elif Fare > 7.895800 and Fare < 14.454200 :\n        return 'middle-down'\n    else:\n        return 'poor'","8272c6f3":"df1['fare_level'] = df1.Fare.apply(fare_level)","3504230f":"df1.drop('Fare', axis = 1, inplace = True)","d46c944e":"dfare_level = df1.groupby(['fare_level']).Survive.value_counts().reset_index(level='fare_level')\ndfare_level = dfare_level.rename(columns={'fare_level':'Fare_level', 'Survive':'Count'}).reset_index()\ndfare_level","f8003bcc":"labels = ['middle-down', 'middle-up','poor','rich']\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=labels, values=[67, 99, 50, 126], name=\"Survive\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=labels, values=[150, 120, 194, 126], name=\"Dead\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Survive and Dead\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Survive', x=0.15, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Dead', x=0.82, y=0.5, font_size=20, showarrow=False)])\nfig.show()","b46ab7c6":"df['Sex']=df.Sex.apply(lambda x: 0 if x == 'male' else 1 )","6bfe82b2":"df['relatives'] = df['SibSp']+df['Parch']\ndf['relatives'] = df['relatives'].apply(lambda x: 1 if x > 0 else 0)\ndf = df.drop(['SibSp'], axis=1 )\ndf = df.drop(['Parch'], axis=1 )","efce9678":"df.Fare.fillna(0, inplace=True)","91430cb1":"age_mean = df.Age.mean()\ndf.Age.fillna(age_mean, inplace=True)","72de3ec7":"df.Embarked.fillna('S', inplace=True)","954f4561":"# ticket price transformation\ndef fare_level(Fare):\n    if Fare > 31.500000:\n        return 1\n    elif Fare > 14.454200 and Fare < 31.500000:\n        return 2\n    elif Fare > 7.895800 and Fare < 14.454200 :\n        return 3\n    else:\n        return 4","816474f1":"df['fare_level'] = df.Fare.apply(fare_level)\ndf = df.drop(['Fare'], axis=1)","6d956517":"df = df.drop(['Ticket'], axis = 1)","647bd6dd":"# Age transformation\ndef age_level(Age):\n    if Age > 55:\n        return 4\n    elif Age > 40 and Age < 55:\n        return 3\n    elif Age > 18 and Age < 40 :\n        return 2\n    else:\n        return 1","f7023c75":"df['Age'] = df.Age.apply(age_level)","544fc87d":"df = df.drop(['Name'], axis = 1)\ndf = df.drop(['Cabin'], axis = 1)\ndf = df.drop(['PassengerId'], axis = 1)","65b34e8d":"df = pd.get_dummies(df,columns=['Embarked'])","63602fb3":"sns.heatmap(df.corr(), cmap='RdBu', annot=True, vmin=-1, vmax=1)","5d7201e9":"df.isnull().sum() # There is no null values","52d5d4a6":"# slice data into features and target\nX = df.drop(columns=[\"Survived\"]).astype(int)\ny = df.loc[:,\"Survived\"].astype(int)","1804974c":"#Split data into train, test \n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)","f7619da8":"#stats model","507fbb70":"log = sm.Logit(y_train,X_train)\nlog_model = log.fit()\nlog_model.summary()","dbd0d753":"#scikit-learn","4a0187de":"log = lm.LogisticRegression(solver='liblinear')\nlog_model = log.fit(X_train,y_train)\nlog_model","6e628929":"log_model.score(X_test,y_test)","6885259b":"log_model.score(X_train,y_train)","621f1809":"log_model.coef_","435cfa91":"y_pred = log_model.predict(X)","e1513c7a":"confusion_matrix(y,y_pred)","606fa331":"logreg = LogisticRegression()\nclassifier = logreg.fit(X_train, y_train)\n\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(15,10),dpi=200),\nplt.style.use('default')\n\n# Plot non-normalized confusion matrix\ntitles_options = [(\"Confusion matrix\", None)]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, X_test, y_test,\n                                 display_labels=['Survive', 'Dead'],\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","388f1960":"accuracy_score(y, y_pred)","695ebb8c":"print(classification_report(y,y_pred))","6ae4a8e9":"logit_roc_auc = roc_auc_score(y, log_model.predict(X))\n\nfpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(X)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.show()","45be5da2":"log = LogisticRegression(solver='liblinear')\nlog_model = log.fit(X_train,y_train)\nlog_model","d33f9ea5":"accuracy_score(y_test, log_model.predict(X_test))","75114861":"cross_val_score(log_model, X_test, y_test, cv=10).mean()","7b3de1ff":"<a id = \"1\"><\/a>\n# Load and Check Data","445ebc8b":"<a id = \"3\"><\/a>\n# Machine Learning (Logistic Regression)","6189203a":"# Introduction\n\nthe sinking of Titanic is one of the most notorious shipwrecks in the hisyory. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\n\n<font color = 'blue'>\n\nContent:\n\n1. [Load and Check Data](#1)\n    \n2. [Exploratory Data Analysis (EDA)](#2)\n    \n3. [Machine Learning (Logistic Regression)](#3)\n","aaca6b36":"<a id = \"2\"><\/a>\n# Exploratory Data Analysis","d0f9d4a3":"*we choose logistic regression because our dependent variable (y) is categorical that's why we choose it.*"}}