{"cell_type":{"82982c27":"code","1f4cb24d":"code","73c8434d":"code","08cf37e2":"code","4c0d51ec":"code","38643484":"code","e5712b22":"code","ca3ea524":"code","a7e61fc5":"code","309d151f":"code","ed203bf0":"code","74faccfe":"code","32e8f401":"code","25de69b3":"code","a6afece6":"code","fe1f4471":"code","95f9f833":"code","e1010744":"code","6841377a":"code","4e0e0eb7":"code","0fc24138":"markdown","f4e4bf31":"markdown","5f5804c1":"markdown","e626d666":"markdown","3d5c8583":"markdown","9a03877f":"markdown","70650b38":"markdown"},"source":{"82982c27":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","1f4cb24d":"# The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. \n# It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.","73c8434d":"df = pd.read_csv('..\/input\/spam.csv', encoding='latin-1')\ndf.head()","08cf37e2":"df.shape","4c0d51ec":"df.columns = ['label', 'msg', 'var1', 'var2', 'var3']","38643484":"df['var1'].describe()","e5712b22":"df['var2'].describe()","ca3ea524":"df['var3'].describe()","a7e61fc5":"df['spam'] = np.where(df['label']=='spam', 1, 0)\ndf.head()","309d151f":"df[df['spam']==1].head() ","ed203bf0":"stopwords = set(STOPWORDS)","74faccfe":"words = ''.join(list(df[df['spam']==1]['msg']))\nspam_wc = WordCloud(background_color='white',\n                    stopwords=set(STOPWORDS),\n                    max_words=50,).generate(words)\nplt.figure(figsize=(10,8), facecolor='k')\nplt.imshow(spam_wc)\nplt.axis('off')\nplt.tight_layout(pad=0)","32e8f401":"df[df['spam']==0].head()","25de69b3":"words = ''.join(list(df[df['spam']==1]['msg']))\nspam_wc = WordCloud(background_color='white',\n                    stopwords=set(STOPWORDS),\n                    max_words=50,).generate(words)\nplt.figure(figsize=(10,8), facecolor='k')\nplt.imshow(spam_wc)\nplt.axis('off')\nplt.tight_layout(pad=0)","a6afece6":"X_train, X_test, y_train, y_test = train_test_split(df['msg'],\n                                                    df['spam'],\n                                                    random_state=0)","fe1f4471":"vect = CountVectorizer().fit(X_train)\nX_train_vectorized = vect.transform(X_train)\n\nprint('every other 700th feature - ',vect.get_feature_names()[::700])\nprint('total number of rows\/documents in of the training dataframe\/corpus - ', X_train.shape)\nprint('number of features\/words - ', len(vect.get_feature_names()))\nprint('shape of the vectorized train sparse matrix - ', X_train_vectorized.shape)","95f9f833":"model = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\npred = model.predict(vect.transform(X_test))\n\nscore = roc_auc_score(y_test, pred)\nfeature_names = np.array(vect.get_feature_names())\nsorted_coef_index = model.coef_[0].argsort()\n\nprint(score, '\\n')\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:15]]))\nprint('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-15:-1]]))\nprint(model.predict(vect.transform(['you won the free call offer. call back to claim.', \n                                    'how are you'])))","e1010744":"print(classification_report(y_test, pred, target_names=['ham', 'spam']))\n\ncm = confusion_matrix(pred, y_test)\ndf_cm = pd.DataFrame(cm, \n                     columns=np.unique(y_test), \n                     index = np.unique(y_test))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\n\nsns.heatmap(df_cm, \n            cmap=\"Blues\", \n            annot=True, \n            fmt='g')","6841377a":"vect = TfidfVectorizer(min_df=5).fit(X_train)\nX_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\npred = model.predict(vect.transform(X_test))\n\nscore = roc_auc_score(y_test, pred)\nfeature_names = np.array(vect.get_feature_names())\nsorted_coef_index = model.coef_[0].argsort()\n\nprint(score, '\\n')\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:15]]))\nprint('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-15:-1]]))\nprint(model.predict(vect.transform(['you won the free call offer. call back to claim.', \n                                    'how are you'])))","4e0e0eb7":"vect = TfidfVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train)\nX_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\npred = model.predict(vect.transform(X_test))\n\nscore = roc_auc_score(y_test, pred)\nfeature_names = np.array(vect.get_feature_names())\nsorted_coef_index = model.coef_[0].argsort()\n\nprint(score, '\\n')\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:15]]))\nprint('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-15:-1]]))\nprint(model.predict(vect.transform(['you won the free call offer. call back to claim.', \n                                    'how are you'])))","0fc24138":"# importing libraries","f4e4bf31":"# spam and not spam messages","5f5804c1":"# importing csv file","e626d666":"# using word count \/ count vectorizer","3d5c8583":"# train test split","9a03877f":"# using n-grams","70650b38":"# using TF-IDF"}}