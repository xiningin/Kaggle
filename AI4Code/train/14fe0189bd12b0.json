{"cell_type":{"546d68f6":"code","3f33e14a":"code","a1b06849":"code","87beb99b":"code","575641d7":"code","f20d695d":"code","d7082bd8":"code","4c135847":"code","812fb49c":"code","c9757624":"code","7fca0ae5":"code","fc4214eb":"code","892d11b6":"code","234ce363":"code","aea8c8f4":"markdown","752c88ce":"markdown","f3320e66":"markdown","56e94a01":"markdown","755118e0":"markdown","3793a92f":"markdown"},"source":{"546d68f6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\nimport glob\nfrom collections import Counter\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D","3f33e14a":"order_book_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\n\n# custom aggregate function\ndef wap2vol(df):\n    # wap2vol stands for WAP to Realized Volatility\n    temp = np.log(df).diff() # calculating tik to tik returns\n    # returning realized volatility\n    return np.sqrt(np.sum(temp**2)) \n\n\n\n# function for calculating realized volatility per time id for a given stock\ndef rel_vol_time_id(path):\n    # book: book is an order book\n    book = pd.read_parquet(path) # order book for a stock id loaded\n    # calculating WAP\n    p1 = book[\"bid_price1\"]\n    p2 = book[\"ask_price1\"]\n    s1 = book[\"bid_size1\"]\n    s2 = book[\"ask_size1\"]\n    \n    book[\"WAP\"] = (p1*s2 + p2*s1) \/ (s1 + s2)\n    # calculating realized volatility for each time_id\n    transbook = book.groupby(\"time_id\")[\"WAP\"].agg(wap2vol)\n    return transbook\n\n","a1b06849":"%%time \nstock_id = []\ntime_id = []\nrelvol = []\nfor i in order_book_training:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    # find the realized volatility for all time_id of temp_stock\n    temp_relvol = rel_vol_time_id(i)\n    stock_id += [temp_stock]*temp_relvol.shape[0]\n    time_id += list(temp_relvol.index)\n    relvol += list(temp_relvol)\n\npast_volatility = pd.DataFrame({\"stock_id\": stock_id, \"time_id\": time_id, \"volatility\": relvol})","87beb99b":"train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\njoined = train.merge(past_volatility, on = [\"stock_id\",\"time_id\"], how = \"left\")\nstockID = 0\nsns.scatterplot(data = joined[joined[\"stock_id\"]==stockID], x = \"target\", y = \"volatility\")\nplt.show()","575641d7":"# finding the number of time_id each stock_id has \ncount_stock_id = Counter(stock_id)","f20d695d":"count_stock_id","d7082bd8":"eligible_stock_id = []\nfor i in count_stock_id:\n    if count_stock_id[i] == 3830:\n        eligible_stock_id.append(i)","4c135847":"past_volatility = past_volatility.loc[past_volatility[\"stock_id\"].isin(eligible_stock_id),:]","812fb49c":"vecx = np.array(past_volatility[\"volatility\"])","c9757624":"X = np.reshape(vecx, (3830,-1))","7fca0ae5":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X.T)\npca = PCA(n_components=3)\nPC = pca.fit_transform(X)\nPC.shape","fc4214eb":"sns.set_style(\"whitegrid\", {'axes.grid' : False})\nfig = plt.figure(figsize=(6,6))\nax = Axes3D(fig) \n\nx = PC[:,0]\ny = PC[:,1]\nz = PC[:,2]\n\n\nax.scatter(x, y, z, c=x, marker='o')\nax.set_xlabel('PC_0')\nax.set_ylabel('PC_1')\nax.set_zlabel('PC_2')\n\nplt.show()\n","892d11b6":"print(pca.explained_variance_ratio_)","234ce363":"sns.set_theme(style=\"white\")\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(np.corrcoef(X), cmap=cmap)\nplt.show()","aea8c8f4":"### Importing all the necessary librarires","752c88ce":"Conclusion being: in terms of volatility, the stocks are almost uncorrelated. ","f3320e66":"We can see not all the *stock_id* has equal number of time_id. For now I am proceeding with *stock_id* with number of *time_id* = 3830 ","56e94a01":"Principal Component Analysis (PCA) is scale sensitive, hence I am preprocessing the data using *StandardScalar* from sklearn. I am also using a 2-component PCA for the ease of visualization to see if there actually exists any stock classes.","755118e0":"All data wrangling + volatility calculation codes were pulled from my another notebook [Overly simplified OLS prediction](https:\/\/www.kaggle.com\/shahmahdihasan\/overly-simplified-ols-prediction). The goal of this codebook to cluster the *stock_id* based on their *realized volatility*. ","3793a92f":"All the necessary functions are there, now let's calculate the realized volatility for each *(stock_id, time_id)* tuples."}}