{"cell_type":{"f43427d7":"code","7c86401f":"code","241f0f07":"code","b3580914":"code","6f8fd33e":"code","b3ab53d8":"code","d6b71a65":"code","a89d8876":"code","3d7d2d21":"code","6ab4b6fa":"code","6aeeed2f":"code","e064988a":"code","90d4f921":"code","d2798523":"code","ef0dd609":"code","53f29aa5":"code","ee8f69ba":"code","1788dfff":"markdown","0bc640ea":"markdown","f3348d93":"markdown","ca95aa1a":"markdown"},"source":{"f43427d7":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom datetime import datetime\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom keras.models import load_model, Model\n\n%matplotlib inline ","7c86401f":"path = \"\/kaggle\/input\/competitive-data-science-predict-future-sales\/\"\n\nitems = pd.read_csv(path+'\/items.csv')\nitem_cats = pd.read_csv(path+'\/item_categories.csv')\nshops = pd.read_csv(path+'\/shops.csv')\nsales = pd.read_csv(path+'\/sales_train.csv')\ntest = pd.read_csv(path+'\/test.csv')\nsubmission = pd.read_csv(path+'\/sample_submission.csv')\n\nprint(\"Data set loaded successfully.\")","241f0f07":"sales['year'] = pd.to_datetime(sales['date']).dt.strftime('%Y')\nsales['month'] = sales.date.apply(lambda x: datetime.strptime(x,'%d.%m.%Y').strftime('%m')) \n\nsales.head(2)","b3580914":"grouped = pd.DataFrame(sales.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=grouped)","6f8fd33e":"grouped_price = pd.DataFrame(sales.groupby(['year','month'])['item_price'].mean().reset_index())\nsns.pointplot(x='month', y='item_price', hue='year', data=grouped_price)","b3ab53d8":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the whole time period')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","d6b71a65":"sales.item_cnt_day.hist(bins=100)\nsales.item_cnt_day.describe()","a89d8876":"print('Data set size before remove item price 0 cleaning:', sales.shape)\nsales = sales.query('item_price > 0')\nprint('Data set size after remove item price 0 cleaning:', sales.shape)","3d7d2d21":"print('Data set size before filter valid:', sales.shape)\n# Only shops that exist in test set.\nsales = sales[sales['shop_id'].isin(test['shop_id'].unique())]\n# Only items that exist in test set.\nsales = sales[sales['item_id'].isin(test['item_id'].unique())]\nprint('Data set size after filter valid:', sales.shape)","6ab4b6fa":"print('Data set size before remove outliers:', sales.shape)\nsales = sales.query('item_cnt_day >= 0 and item_cnt_day <= 125 and item_price < 75000')\nprint('Data set size after remove outliers:', sales.shape)","6aeeed2f":"monthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date_block_num\",\"date\",\"item_price\",\"item_cnt_day\"].agg({\"date_block_num\":'mean',\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\nmonthly_sales.head(5)","e064988a":"sales_data_flat = monthly_sales.item_cnt_day.apply(list).reset_index()\n#Keep only the test data of valid\nsales_data_flat = pd.merge(test,sales_data_flat,on = ['item_id','shop_id'],how = 'left')\n#fill na with 0\nsales_data_flat.fillna(0,inplace = True)\nsales_data_flat.drop(['shop_id','item_id'],inplace = True, axis = 1)\nsales_data_flat.head(20)","90d4f921":"#We will create pivot table.\n# Rows = each shop+item code\n# Columns will be out time sequence\npivoted_sales = sales_data_flat.pivot_table(index='ID', columns='date_block_num',fill_value = 0,aggfunc='sum' )\npivoted_sales.head(20)","d2798523":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(pivoted_sales.values[:,:-1],axis = 2)\n# the last column is our prediction\ny_train = pivoted_sales.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(pivoted_sales.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","ef0dd609":"sales_model = Sequential()\nsales_model.add(LSTM(units = 64,input_shape = (33,1)))\nsales_model.add(Dropout(0.5))\nsales_model.add(Dense(1))\n\nsales_model.compile(loss = 'mse',optimizer = 'adam',metrics =['mean_squared_error'] )\nsales_model.summary()","53f29aa5":"sales_model.fit(X_train,y_train,batch_size = 2048,epochs = 50)","ee8f69ba":"submission_output = sales_model.predict(X_test)\nsubmission = pd.DataFrame({'ID':test['ID'],'item_cnt_month':submission_output.ravel()})\n\nsubmission.to_csv('submission_stacked.csv',index = False)\nsubmission.head()","1788dfff":"\nBy seeing this graph we can see that\n*     last two months of the year having more sales.\n*     2015, we are expecting more sales.\n","0bc640ea":"# Aggregate to monthly level the sales","f3348d93":"# LSTM Model","ca95aa1a":"# Price"}}