{"cell_type":{"634d0727":"code","b9470081":"code","04482d13":"code","e7a2a904":"code","9b7168e1":"code","5a2651be":"code","ad6bb9e0":"code","2d8d8f36":"code","3ea8bc8f":"code","2efa18f3":"code","36e8b348":"code","83c7a032":"code","110e1bf9":"code","6e76223f":"code","66f43302":"code","76892e4e":"code","4fc6b942":"code","395c8f54":"code","1985ad96":"code","f79590fd":"code","c90f637a":"code","6e917a1c":"code","abf30078":"code","d11db170":"code","2c8b2614":"code","875b4ef9":"code","a10d0594":"code","d558cf6c":"code","cd974d8b":"code","a1ddc05a":"code","9325661c":"code","f96e5c65":"code","c8d96600":"code","8e98c603":"code","554458ec":"code","d21c519f":"code","49111126":"code","1bf09b7b":"code","d1d789a3":"markdown","94ae2cc1":"markdown","bb7eac6f":"markdown","9039f7f5":"markdown","14796395":"markdown","02f7c6ae":"markdown","224ba8d5":"markdown","9daa8ac0":"markdown","bdbdc54c":"markdown","37104e82":"markdown","1d11f777":"markdown","d124c301":"markdown","235e6a63":"markdown","73c04369":"markdown","b1320acc":"markdown","e8f04c3f":"markdown","0940306c":"markdown","f77c35f9":"markdown","1f17272b":"markdown","0c81a405":"markdown","9e9c093f":"markdown","7b19fd11":"markdown","257b6794":"markdown","c67aff4d":"markdown","5dedb6a1":"markdown","bcbb6b2f":"markdown","0130ff66":"markdown","94147a03":"markdown","4d2d52a6":"markdown","e2ba6e6a":"markdown","7289f9f6":"markdown","7108e86c":"markdown","713bc375":"markdown","33f402f4":"markdown","95058ec9":"markdown","bf6c9165":"markdown","832e9cd4":"markdown","fe2ffd00":"markdown","3343c39f":"markdown"},"source":{"634d0727":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, ShuffleSplit, GridSearchCV\n\n# Modeling\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n\n# Metrics\nfrom sklearn.metrics import r2_score","b9470081":"# Download training data\ntrain = pd.read_csv('\/kaggle\/input\/ammonium-prediction-in-river-water\/train.csv')","04482d13":"# Display the first 5 rows of the training dataframe.\ntrain.head()","e7a2a904":"# Information for training data\ntrain.info()","9b7168e1":"# Download test data\ntest = pd.read_csv('..\/input\/ammonium-prediction-in-river-water\/test.csv')","5a2651be":"# Display the 7 last rows of the training dataframe\ntest.tail()","ad6bb9e0":"test.info()","2d8d8f36":"# Select the stations with the most data in training dataset\ntrain = train.drop(['Id','3','4','5','6','7'], axis = 1)\ntrain = train.dropna().reset_index(drop=True)\ntrain.info()","3ea8bc8f":"# Display the statistics for training data\ntrain.describe()","2efa18f3":"# EDA with Pandas Profiling\npp.ProfileReport(train)","36e8b348":"# Selecting a target featute and removing it from training dataset\ntarget = train.pop('target')","83c7a032":"# Select the stations with the most data in test dataset\ntest = test.drop(['Id','3','4','5','6','7'], axis = 1)\ntest = test.dropna().reset_index(drop=True)","110e1bf9":"# EDA with Pandas Profiling\n","6e76223f":"# Display basic information about the test data\ntest.info()","66f43302":"# Standartization data\nscaler = StandardScaler()\ntrain = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n\n# Display training data\ntrain","76892e4e":"# Display the statistics for training data\ntrain.describe()","4fc6b942":"# Standartization data\n\n# Display test\n","395c8f54":"# Display the statistics for training data\n","1985ad96":"# Training data splitting to new training (part of the all training) and validation data\ntrain_all = train.copy()\ntarget_all = target.copy()\ntrain, valid, target_train, target_valid = train_test_split(train_all, target_all, test_size=0.2, random_state=0)","f79590fd":"# Display information about new training data\ntrain.info()","c90f637a":"# Display information about validation data\n","6e917a1c":"# Cross-validation of training data with shuffle\ncv_train = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)","abf30078":"# Creation the dataframe with the resulting score of all models\nresult = pd.DataFrame({'model' : ['Decision Tree Regressor', 'Random Forest Regressor', 'XGBoost Regressor'], \n                       'train_score': 0, 'valid_score': 0})\nresult","d11db170":"# Decision Tree Regressor\ndecision_tree = DecisionTreeRegressor()\nparam_grid = {'min_samples_leaf': [i for i in range(5,10)], 'max_depth': [i for i in range(3,12)]}\n\n# Training model\ndecision_tree_CV = GridSearchCV(decision_tree, param_grid=param_grid, cv=cv_train, verbose=False)\ndecision_tree_CV.fit(train, target_train)\nprint(decision_tree_CV.best_params_)\n\n# Prediction for training data\ny_train_decision_tree = decision_tree_CV.predict(train)\n\n# Accuracy of model\nr2_score_acc = round(r2_score(target_train, y_train_decision_tree)*100, 1)\nprint(f'Accuracy of DecisionTreeRegressor model training is {r2_score_acc}')\n\n# Save to result dataframe\nresult.loc[result['model'] == 'Decision Tree Regressor', 'train_score'] = r2_score_acc","2c8b2614":"# Print rounded r2_score_acc to 2 decimal values after the text\ny_val_decision_tree = decision_tree_CV.predict(valid)\nr2_score_acc_valid = round(r2_score(target_valid, y_val_decision_tree)*100,1)\nresult.loc[result['model'] == 'Decision Tree Regressor', 'valid_score'] = r2_score_acc_valid\nprint(f'Accuracy of DecisionTreeRegressor model prediction for valid dataset is {r2_score_acc_valid}')","875b4ef9":"# Random Forest Regressor\nrf = RandomForestRegressor()\nparam_grid = {'n_estimators': [10, 100, 500], 'min_samples_leaf': [i for i in range(5,10)], \n              'max_features': ['auto'], 'max_depth': [i for i in range(4,6)], \n              'criterion': ['mse'], 'bootstrap': [False]}\n\n# Training model\nrf_CV = GridSearchCV(rf, param_grid=param_grid, cv=cv_train, verbose=False)\nrf_CV.fit(train, target_train)\nprint(rf_CV.best_params_)\n\n# Prediction for training data\ny_train_rf = rf_CV.predict(train)\n\n# Accuracy of model\nr2_score_acc = round(r2_score(target_train, y_train_rf)*100,1)\nprint(f'Accuracy of RandomForestRegressor model training is {r2_score_acc}')\n\n# Save to result dataframe\nresult.loc[result['model'] == 'Random Forest Regressor', 'train_score'] = r2_score_acc","a10d0594":"# Print rounded r2_score_acc to 2 decimal values after the text\ny_val_rf = rf_CV.predict(valid)\nr2_score_acc_valid = round(r2_score(target_valid, y_val_rf)*100,1)\nresult.loc[result['model'] == 'Random Forest Regressor', 'valid_score'] = r2_score_acc_valid\nprint(f'Accuracy of RandomForestRegressor model prediction for valid dataset is {r2_score_acc_valid}')","d558cf6c":"# XGBoost Regressor\n\n# Training model\n\n# Prediction for training data\n\n# Accuracy of model\n","cd974d8b":"# Print rounded r2_score_acc to 2 decimal values after the text","a1ddc05a":"# Prediction of target for test data for all models\ny_test_decision_tree = decision_tree_CV.predict(test)\ny_test_rf = rf_CV.predict(test)","9325661c":"# Building plot for prediction for the training data \nx = np.arange(len(train))\nplt.figure(figsize=(16,10))\nplt.scatter(x, target_train, label = \"Target data\", color = 'g')\nplt.scatter(x, y_train_decision_tree, label = \"Decision Tree prediction\", color = 'b')\nplt.scatter(x, y_train_rf, label = \"Random Forest prediction\", color = 'y')\nplt.plot(x, np.full(len(train), 0.5), label = \"Maximum allowable value\", color = 'r')\nplt.title('Prediction for the training data')\nplt.legend(loc='best')\nplt.grid(True)","f96e5c65":"# Building plot for prediction for the valid data \n","c8d96600":"# Building plot for prediction for the test data \n","8e98c603":"# Display results of modeling\nresult.sort_values(by=['valid_score', 'train_score'], ascending=False)","554458ec":"# Select models with minimal overfitting\nresult_best = result[(result['train_score'] - result['valid_score']).abs() < 5]\nresult_best.sort_values(by=['valid_score', 'train_score'], ascending=False)","d21c519f":"# Select the best model\nresult_best.nlargest(1, 'valid_score')","49111126":"# Find a name of the best model (with maximal valid score)\nbest_model_name = result_best.loc[result_best['valid_score'].idxmax(result_best['valid_score'].max()), 'model']","1bf09b7b":"print(f'The best model is \"{best_model_name}\"')","d1d789a3":"## Dataset [Ammonium prediction in river water](https:\/\/www.kaggle.com\/vbmokin\/ammonium-prediction-in-river-water)","94ae2cc1":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","bb7eac6f":"**ADDITIONAL TASK:** Try use RobustScaler or MinMaxScaler instead of StandardScaler and to analyze what is the difference for accuracy of models will be below.","9039f7f5":"### 3.4. Cross-validation of training data<a class=\"anchor\" id=\"3.4\"><\/a>\n\n[Back to Table of Contents](#0.1)","14796395":"### 4.2. Random Forest Regressor<a class=\"anchor\" id=\"4.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","02f7c6ae":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","224ba8d5":"**TASK:** Building plot for prediction for the test data.","9daa8ac0":"# The concept of training:\n* the **last version (commit)** of the notebook has:\n        * the basic tasks (after \"TASK:\")\n        * the additional tasks for self-execution (after \"ADDITIONAL TASK:\")\n* the **previuos version (commit)** of the notebook has **answers** for the basic tasks","bdbdc54c":"## 5. Test prediction<a class=\"anchor\" id=\"5\"><\/a>\n\n[Back to Table of Contents](#0.1)","37104e82":"**TASK:** Display information about validation data","1d11f777":"<a class=\"anchor\" id=\"0\"><\/a>\n# [AI-ML-DS : Training for beginners](https:\/\/www.kaggle.com\/vbmokin\/ai-ml-ds-training-for-beginners-in-kaggle). Level 2 (simple). 2020\n## Kaggle GM, Prof. [@vbmokin](https:\/\/www.kaggle.com\/vbmokin)\n### [Vinnytsia National Technical University](https:\/\/vntu.edu.ua\/), Ukraine\n#### [Chair of the System Analysis and Information Technologies](http:\/\/mmss.vntu.edu.ua\/index.php\/ua\/)","d124c301":"## 6. Visualization<a class=\"anchor\" id=\"6\"><\/a>\n\n[Back to Table of Contents](#0.1)","235e6a63":"### Map of the stations:\nhttp:\/\/monitoring.davr.gov.ua\/EcoWaterMon\/GDKMap\/Index\n\n![image.png](attachment:image.png)\n\nThe upper reaches of the Pivdennyi Bug river","73c04369":"### It is recommended to start studying this course from notebooks:\n* [AI-ML-DS Training. L1T : Titanic - Decision Tree](https:\/\/www.kaggle.com\/vbmokin\/ai-ml-ds-training-l1t-titanic-decision-tree)\n* [AI-ML-DS Training. L1T : NH4 - linear regression](https:\/\/www.kaggle.com\/vbmokin\/ai-ml-ds-training-l1t-nh4-linear-regression)\n* [BOD prediction in river - 15 regression models](https:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models)\n\nand then move on to this notebook.","b1320acc":"**ADDITIONAL TASK:** Add the XGBRegressor model (the same commands as in 4.1 and 4.2 adapted to the library xgb). Please see example in the notebooks: \n* [BOD prediction in river - 15 regression models](https:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models)\n* [XGBRegressor with GridSearchCV](https:\/\/www.kaggle.com\/jayatou\/xgbregressor-with-gridsearchcv)","e8f04c3f":"## Acknowledgements\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [Datasets for river water quality prediction](https:\/\/www.kaggle.com\/vbmokin\/datasets-for-river-water-quality-prediction)\n* [Heart Disease - Automatic AdvEDA & FE & 20 models](https:\/\/www.kaggle.com\/vbmokin\/heart-disease-automatic-adveda-fe-20-models)\n* [BOD prediction in river - 15 regression models](https:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models)\n* [The system \"MONITORING AND ENVIRONMENTAL ASSESSMENT OF WATER RESOURCES OF UKRAINE\", State Agency of Water Resources of Ukraine](http:\/\/monitoring.davr.gov.ua\/EcoWaterMon\/GDKMap\/Index)","0940306c":"### 4.1. Decision Tree Regressor<a class=\"anchor\" id=\"4.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","f77c35f9":"## 3. EDA & FE & Preprocessing data<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","1f17272b":"**ADDITIONAL TASKS:** \n1. Add to dataframe result also calculated array: y_test.\n2. Add the line with XGBRegressor model prediction (train, valid, test take from the dataframe result).\n3. Creation the function with all commands and output information for all models (for type_plot = 'training', 'valid' or 'test'):\n\n        plot_prediction(result, type_plot='training')","0c81a405":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n1. [EDA & FE & Preprocessing data](#3)\n    - [Statistics & FE](#3.1)\n    - [Data standartization](#3.2)\n    - [Training data splitting](#3.3)\n    - [Cross-validation of training data](#3.4)\n1. [Modeling](#4)\n    - [Decision Tree Regressor](#4.1)\n    - [Random Forest Regressor](#4.2)\n    - [XGBoost Regressor](#4.3)    \n1. [Test prediction](#5)\n1. [Results visualization](#6)\n1. [Select the best model](#6)","9e9c093f":"**ADDITIONAL TASKS:** \n1. Set number of splitting = 5, 7, 10 and to compare of results.\n2. Try use another method for cross-validation of training data (without shuffle):\n\n        KFold(n_splits=5, shuffle=False, random_state=0)","7b19fd11":"### 3.2. Data standartization<a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","257b6794":"**It is important to make sure** that all features in the training and test datasets:\n* do not have missing values (number of non-null values = number of entries of index) \n* all features have a numeric data type (int8, int16, int32, int64 or float16, float32, float64).","c67aff4d":"### 4.3. XGBoost Regressor<a class=\"anchor\" id=\"4.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","5dedb6a1":"**ADDITIONAL TASKS:** \n1. Add to dataframe result also calculated array: y_train, y_val.\n2. Creation the function with all commands and output information (in each section of this chapter 4) for all models:\n\n        result = get_model(train, valid, target_train, target_valid, model_name, param_grid, cv_train, result)","bcbb6b2f":"### 3.3. Training data splitting<a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","0130ff66":"## 4. Modeling<a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","94147a03":"**TASK:** Building plot for prediction for the valid data.","4d2d52a6":"Dataset has data of the Ammonium ions concentration in river water (the maximum permissible value in Ukraine is 0.5 mg\/cub. dm).\n\nAmmonium ions (NH4) concentration is measured in mg\/cub. dm (ie milligrams in the cubic decimeter).\n\nDatasets has data of river water quality from 8 consecutive stations of the state water monitoring system for Pivdennyi Bug river (from the source of the river to the water intake of the city of Vinnytsia).\n\nTarget is a NH4 concentration in the river crossection with the water intake of the Vinnytsia city.\n\nData for the 1997-2019.","e2ba6e6a":"### 3.1. Statistics & FE<a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","7289f9f6":"![image.png](attachment:image.png)\n* 1 - the source of the river (see at the station first on the left), \n* ....\n* 8 (target) - the place of water intake in Vinnytsia (see at the station in the lower right corner)","7108e86c":"**ADDITIONAL TASK:** Try use other values in the parameter test_size above: 0.1, 0.15, 0.3, 0.5 and to analyze what is the difference for accuracy of models will be below.","713bc375":"## 7. Select the best model <a class=\"anchor\" id=\"7\"><\/a>\n\n[Back to Table of Contents](#0.1)","33f402f4":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","95058ec9":"### Possible Tasks:\n\n* Analysis of data dependences, including EDA.\n\n* Prediction the target data (water quaity in the target station) with the highest accuracy.\n\n* Analysis of impact on the prediction accuracy in target station from the different number of stations (1, 2, ... 7).","bf6c9165":"The analysis showed that many values are only available in stations 1 and 2, while others have much less data. I propose select only these two stations.","832e9cd4":"**TASK:** Make EDA for the test dataset by Pandas Profiling","fe2ffd00":"**TASK:** Standardize the test dataset with the same scaler and display it","3343c39f":"**TASK:** Display the statistics for test data"}}