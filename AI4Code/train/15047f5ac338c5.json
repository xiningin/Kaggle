{"cell_type":{"654b918f":"code","0140fd3a":"code","c93473e8":"code","67148ea5":"code","8cc4b040":"code","d2e4bd35":"code","2adf88a7":"markdown","e8290f73":"markdown","31b8f464":"markdown","ba5959dd":"markdown","5887cade":"markdown","2ac27a02":"markdown","6a3fdc63":"markdown","2ed089d0":"markdown","ce52299d":"markdown"},"source":{"654b918f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\n\n# Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, gaussian_process, discriminant_analysis\nfrom xgboost import XGBClassifier\nimport sklearn\nprint(sklearn.__version__)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\n\n# Depress xgboost gcc eror on mac\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n\n# Any results you write to the current directory are saved as output.\n# load raw data from csv file\ndata = pd.read_csv('..\/input\/car.data.csv')\n\n# See if there is any null value for each feature\nprint(data.isnull().any())\n\n# Overview of the data\ndata.info()\ndata.describe()","0140fd3a":"# Overview of the dataset\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\ndata_rating = pd.factorize(data['rating'])\ndata['rating'] = pd.Series(data_rating[0])\nsns.barplot(x = 'buying', y = 'rating', data=data, ax = saxis[0,0])\nsns.barplot(x = 'maint', y = 'rating', data=data, ax = saxis[0,1])\nsns.barplot(x = 'doors', y = 'rating', data=data, ax = saxis[0,2])\nsns.barplot(x = 'persons', y = 'rating', data=data, ax = saxis[1,0])\nsns.barplot(x = 'lug_boot', y = 'rating', data=data, ax = saxis[1,1])\nsns.barplot(x = 'safety', y = 'rating', data=data, ax = saxis[1,2])","c93473e8":"# Factorize data label to numeric for scikit-learn pipeline\ndata_rating = pd.factorize(data.loc[:,'rating'])\ndata.loc[:,'rating'] = pd.Series(data_rating[0])\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X[self.attribute_names]\n\n\nclass MostFrequentImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        for col in X.columns:\n            if X.loc[:,col].dtype != 'int64':\n                col_data = pd.factorize(X.loc[:,col])\n                X.loc[:, col] = pd.Series(col_data[0], name=col)\n        self.most_frequent_ = pd.Series([X.loc[:,c].value_counts().index[0] for c in X],\n                                        index=X.columns)\n        return self\n\n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)\n\n# Define the data pipeline to extract, convert and transform data\ncat_pipeline = Pipeline([\n        (\"select_cat\", DataFrameSelector([\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"])),\n        (\"imputer\", MostFrequentImputer()),\n        (\"cat_encoder\", OneHotEncoder(sparse=False))\n])\n\nX_data = cat_pipeline.fit_transform(data)\ncol_data = pd.factorize(data.loc[:,'rating'])\ny_data = pd.Series(col_data[0]).values\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=42)","67148ea5":"# Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    # Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    # Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n\n    # GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n\n    # Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n\n    # Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n\n    # Trees\n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n\n    # Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    # xgboost: http:\/\/xgboost.readthedocs.io\/en\/latest\/model.html\n    XGBClassifier()\n]\n\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\nMLA_predict = data.loc[:,'rating']\n\n# a = ensemble.ExtraTreesClassifier()\n# a.fit(X_train, y_train)\n# print(a.score(X_test, y_test))\nrow_index = 0\nfor alg in MLA:\n    fit = alg.fit(X_train, y_train)\n    predicted = fit.predict(X_test)\n    # fp, tp, th = roc_curve(y_test, predicted)\n    MLA_name = alg.__class__.__name__\n    print(alg.__class__.__name__)\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    #score model with cross validation: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n    cv_results = model_selection.cross_validate(alg, X_data, y_data, cv=cv_split, return_train_score=True)\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n    # if this is a non-bias random sample, then +\/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std() * 3  # let's know the worst that can happen!\n\n    # save MLA predictions - see section 6 for usage\n    alg.fit(X_data, y_data)\n    MLA_predict[MLA_name] = alg.predict(X_data)\n\n    row_index += 1\npd.set_option('display.max_columns', None)\n\n\n#print and sort table: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.sort_values.html\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')","8cc4b040":"vote_est = [\n    #Ensemble Methods: http:\/\/scikit-learn.org\/stable\/modules\/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n\n    #Gaussian Processes: http:\/\/scikit-learn.org\/stable\/modules\/gaussian_process.html#gaussian-process-classification-gpc\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    #GLM: http:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression\n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    #Navies Bayes: http:\/\/scikit-learn.org\/stable\/modules\/naive_bayes.html\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    \n    #Nearest Neighbor: http:\/\/scikit-learn.org\/stable\/modules\/neighbors.html\n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    #SVM: http:\/\/scikit-learn.org\/stable\/modules\/svm.html\n    ('svc', svm.SVC(probability=True)),\n    \n    #xgboost: http:\/\/xgboost.readthedocs.io\/en\/latest\/model.html\n   ('xgb', XGBClassifier())\n\n]\n\n\n#Hard Vote or majority rules\nvote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\nvote_hard_cv = model_selection.cross_validate(vote_hard, X_train, y_train, cv  = cv_split)\nvote_hard.fit(X_train, y_train)\n\nprint(\"Hard Voting Training w\/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting Test w\/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting Test w\/bin score 3*std: +\/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\n\n#Soft Vote or weighted probabilities\nvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\nvote_soft_cv = model_selection.cross_validate(vote_soft, X_data, y_data, cv  = cv_split)\nvote_soft.fit(X_data, y_data)\n\nprint(\"Soft Voting Training w\/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting Test w\/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting Test w\/bin score 3*std: +\/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\nprint('-'*10)","d2e4bd35":"# This is an example how to use random search on GradientBoostingClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint \nn_iter_search = 20\nparam_dist= {\n    \"max_depth\": sp_randint(2, 17),\n    \"min_samples_split\": sp_randint(2, 101),\n    \"min_samples_leaf\": sp_randint(1, 101)\n}\n\ngsearch1 = RandomizedSearchCV(estimator = ensemble.GradientBoostingClassifier(learning_rate=0.1, \n                              max_features='sqrt', subsample=0.8,random_state=10),\n                              param_distributions=param_dist, n_iter=n_iter_search)\ngsearch1.fit(X_train, y_train)\ngsearch1.best_params_, gsearch1.best_score_","2adf88a7":"## Prepare Data for Consumption\nFortunately there is not too much work to do data preparation. Just import useful libraries.\n\n### Import necessary libraries\nData load and transform: pandas\nData ETL and pipeline: scikit-learn\nData visualization: seaborn","e8290f73":"# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n2. **Gather the Data:** John Naisbitt wrote in his 1984 (yes, 1984) book Megatrends, we are \u201cdrowning in data, yet staving for knowledge.\" So, chances are, the dataset(s) already exist somewhere, in some format. It may be external or internal, structured or unstructured, static or streamed, objective or subjective, etc. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming \"dirty data\" to \"clean data.\"\n3. **Prepare Data for Consumption:** This step is often referred to as data wrangling, a required process to turn \u201cwild\u201d data into \u201cmanageable\u201d data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control, data extraction (i.e. ETL and web scraping), and data cleaning to identify aberrant, missing, or outlier data points.\n4. **Perform Exploratory Analysis:** Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (i.e. qualitative vs quantitative) is also important to understand and select the correct hypothesis test or data model.\n5. **Model Data:** Like descriptive and inferential statistics, data modeling can either summarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magical wands or silver bullets. You must still be the master craft (wo)man that knows how-to select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modelling. The wrong model can lead to poor performance at best and the wrong conclusion (that\u2019s used as actionable intelligence) at worst.\n6. **Validate and Implement Data Model:** After you've trained your model based on a subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step we determine if our [model overfit, generalize, or underfit our dataset](http:\/\/docs.aws.amazon.com\/machine-learning\/latest\/dg\/model-fit-underfitting-vs-overfitting.html).\n7. **Optimize and Strategize:** This is the \"bionic man\" step, where you iterate back through the process to make it better...stronger...faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you have more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your \u201ccurrency exchange\" rate.","31b8f464":"# Car Evaluation\n\nThis is a typical dataset for classification which can be downloaded from [UCI Dataset](http:\/\/archive.ics.uci.edu\/ml\/datasets\/Car+Evaluation). In the discussion, a common and simple framework of data science is built up.  The introduction below is referred from [A Data Science Framework](https:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy)  could be awesome for beginners.","ba5959dd":"## Model data\nUp to now, we have prepared the data and slit them into train set and test set. Let's define a set of classifier thatwould be applied to this problem. As for classification issue, there are  Trees, Bagging, Random Forests, and Boosting algorithms which need to be used and evaluated.","5887cade":"## Parameter Optimization\nIn scikit-learn, [RandomizedSearchCV](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)  search on hyper parameters which a range of parameters can be evaluated.","2ac27a02":"## Validate and Implement Data Model","6a3fdc63":"### Data clean and transformation","2ed089d0":"## Define the Problem\n**Summary**: Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.).  \n\n**Analysis**\nApparently it is a classification question that could apply discriminative model and the rating of the car can be predicted from the features in the data source. Accordingly we may choose classification algorithm or even deep neural network.\n\n**Tool**\nscikit-learn, Keras, Tensorflow ...","ce52299d":"## Gather the data\nGet the data from [UCI Dataset](http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/car\/)"}}