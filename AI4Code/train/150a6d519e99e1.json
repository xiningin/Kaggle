{"cell_type":{"41297a8c":"code","4c8a22c2":"code","e87631f0":"code","a0db7e32":"code","ab152a68":"code","d040a7fc":"code","60859d0f":"code","8a4cdb23":"code","02b830ff":"code","f9166c38":"code","a4fa9ddf":"code","ccc36eed":"code","cb6b049b":"code","04020561":"code","7dfab498":"code","66239671":"code","09500719":"code","b9a1658e":"code","d76228ea":"code","fbb01bb5":"code","02ddb8b1":"code","54e6d5c8":"code","8e8dc937":"code","9b812d2a":"code","553db625":"code","84178618":"code","154e69f0":"code","a08f7804":"code","0b714d15":"code","4faef87f":"code","d12e4c19":"code","ff59316a":"code","797370e6":"markdown","f8457de2":"markdown"},"source":{"41297a8c":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport random\nimport matplotlib.pylab as plt","4c8a22c2":"img_path=[]\nfor name in glob('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/*\/*',recursive=True):\n    if name.endswith('txt') or name.endswith('.m'):\n        pass\n    else:\n        img_path.append(name)","e87631f0":"img_path","a0db7e32":"patches=[]\nfor i in img_path:\n    if i.endswith('GT'):\n        pass\n    else:\n        patches+=glob(i+'\/*.png', recursive=True)","ab152a68":"img_path=patches","d040a7fc":"img_path = pd.Series(img_path).astype(str)\nimg_path.head()","60859d0f":"labels=[]\nfor i in img_path:\n    labels.append(i.split('\/')[5])\n","8a4cdb23":"print(set(labels))","02b830ff":"pd.set_option('display.max_colwidth', None)","f9166c38":"labels[0]","a4fa9ddf":"print(len(img_path),len(labels))","ccc36eed":"img_path.head()","cb6b049b":"labels=pd.Series(labels)","04020561":"data = pd.concat([img_path,labels],axis=1)\ndata.sample(5)","7dfab498":"import matplotlib.pyplot as plt\nimport seaborn as sns","66239671":"plt.figure(figsize=(15,5))\nsns.countplot(x=data[1])","09500719":"from sklearn.model_selection import train_test_split\ntrain_set , test_set = train_test_split(data,test_size=0.2,random_state=17)","b9a1658e":"train_set.shape,test_set.shape","d76228ea":"test_set","fbb01bb5":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras","02ddb8b1":"train_gen = ImageDataGenerator(validation_split=0.1)\ntest_gen = ImageDataGenerator()\n\ntrain_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = True,\n    subset = 'training'\n)\n\nval_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False,\n    subset = 'validation'\n)\n\ntest_data = test_gen.flow_from_dataframe(\n    dataframe = test_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False\n)","54e6d5c8":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(9, activation='softmax')\n])","8e8dc937":"model.compile(\n    optimizer=tf.optimizers.Adam(lr=0.00001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy','Recall']\n)","9b812d2a":"model.summary()","553db625":"history = model.fit(train_data,epochs=15,validation_data=val_data)","84178618":"import matplotlib.pyplot as plt\n#plotting the Accuracy of test and training sets\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","154e69f0":"#plotting the loss of test and training sets\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a08f7804":"y_pred = model.predict(test_data)\ny_pred = np.argmax(y_pred,axis=1)","0b714d15":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_data.labels,y_pred))","4faef87f":"print(y_pred[0])","d12e4c19":"classes=[i for i in range(9)]\ncon_mat_df = pd.DataFrame(confusion_matrix(test_data.labels,y_pred),\n                     index = classes, \n                     columns = classes)","ff59316a":"import seaborn as sns\nfigure = plt.figure(figsize=(15, 8))\nsns.heatmap(con_mat_df, annot=True,cmap=plt.cm.cool,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","797370e6":"**Eliminating GT images**","f8457de2":"**Getting All Folders**"}}