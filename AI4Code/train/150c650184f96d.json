{"cell_type":{"d92ae1cb":"code","9f9a69df":"code","b0c26400":"code","35aa45e8":"code","38e225c5":"code","4c0973df":"code","38c288cf":"code","a70e7557":"code","07c99ef7":"code","ed661e2e":"code","5ea8896d":"code","86571cea":"code","1cbcdd1c":"code","598f614a":"code","ba70d973":"code","1e2497d4":"code","18f4c9a3":"code","52c9f9ce":"code","0842b4d6":"code","ca83f9d9":"code","fc964b3d":"code","7b9493e5":"code","b8610eef":"code","5970eb05":"code","56c7ae0a":"code","a69c0b2c":"code","73ed85ca":"code","b6d4e915":"code","d2f2ca51":"code","1815e5b5":"code","7b4a4d01":"code","d93eef53":"code","67bf3913":"code","e829156f":"code","06b12b87":"code","e3788a49":"code","cfc183d9":"code","b8ec624a":"code","6a188b7e":"code","9caedaf4":"code","81d2a975":"code","b31455b4":"code","4df4d3bc":"code","b2c58fd0":"code","9ca644be":"code","ae864ab2":"code","618160a8":"code","8dad53e5":"code","7ef28f1a":"code","e8c278b7":"markdown","b0f0fafd":"markdown","d547d65f":"markdown","9f2de80a":"markdown","cfb8a94f":"markdown","e6b49a2c":"markdown","08ad9f90":"markdown"},"source":{"d92ae1cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f9a69df":"# Essentials\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport random\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Models & TRansformers \n\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV","b0c26400":"# Read in the dataset as a dataframe\ntrain_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_df.shape, test_df.shape","35aa45e8":"df = pd.concat((train_df, test_df)).reset_index(drop=True)\ny=df['SalePrice']\n\nprint(\"all_data size is : {}\".format(df.shape))","38e225c5":"df.head()","4c0973df":"df.info()","38c288cf":"quantitative = [f for f in df.columns if df.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nqualitative = [f for f in df.columns if df.dtypes[f] == 'object']","a70e7557":"quantitative","07c99ef7":"qualitative","ed661e2e":"corr = df.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"Blues\", square=True)","5ea8896d":"f, ax = plt.subplots(figsize=(15, 12))\nfig = sns.boxplot(x=df['OverallQual'], y=df[\"SalePrice\"], data=df)\nfig.axis(ymin=0, ymax=800000);","86571cea":"sns.pairplot(df[[\"SalePrice\", 'OverallQual']])","1cbcdd1c":"sns.pairplot(df[[\"SalePrice\", 'GrLivArea']])","598f614a":"sns.pairplot(df[[\"SalePrice\", 'GrLivArea']])","ba70d973":"sns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(df['SalePrice'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","1e2497d4":"# log(1+x) transform\ndf[\"SalePrice\"] = np.log1p(df[\"SalePrice\"])","18f4c9a3":"sns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(df['SalePrice'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","52c9f9ce":"# # Remove outliers\n# df.drop(df[(df['OverallQual']<5) & (df['SalePrice']>200000)].index, inplace=True)\n# df.drop(df[(df['GrLivArea']>4500) & (df['SalePrice']<300000)].index, inplace=True)\n# df.reset_index(drop=True, inplace=True)","0842b4d6":"def percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data))\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)})\n    \n    return dict_x\n\nmissing = percent_missing(df)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\nprint('Percent of missing data')\ndf_miss[0:15]","ca83f9d9":"sns.set_style(\"whitegrid\")\nmissing = df.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","fc964b3d":"missing","7b9493e5":"df['Fence'].value_counts()","b8610eef":"def missing_data(df):\n    #Imputing each feature according to the values and understandig of data :\n    \n    df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n    # Replacing the missing values with 0, since no garage = no cars in garage\n    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n        df[col] = df[col].fillna(0)\n    # Replacing the missing values with None\n    for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n        df[col] = df[col].fillna('None')\n    # NaN values for these categorical basement features, means there's no basement\n    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n        df[col] = df[col].fillna('None')\n    \n    # to handle all categorical missing data : we will impute with none :\n    objects = []\n    for i in df.columns:\n        if df[i].dtype == object:\n            objects.append(i)\n    df.update(df[objects].fillna('None'))\n    \n    numeric=[]\n    for i in df.columns:\n        if df[i].dtype != object:\n              numeric.append(i)  \n    df.update(df[numeric].fillna(0))       \n        \n        \n    return df","5970eb05":"df=missing_data(df)","56c7ae0a":"missing=df.isnull().sum()","a69c0b2c":"missing","73ed85ca":"def convert_string(df):\n    df['MSSubClass'] = df['MSSubClass'].apply(str)\n    df['YrSold'] = df['YrSold'].astype(str)\n    df['MoSold'] = df['MoSold'].astype(str)\n    \n    return df","b6d4e915":"df=convert_string(df)\n","d2f2ca51":"df.columns","1815e5b5":"df.info()","7b4a4d01":"def logs(res, ls):\n    m = res.shape[1]\n    for l in ls:\n        res = res.assign(newcol=pd.Series(np.log(1.01+res[l])).values)   \n        res.columns.values[m] = l + '_log'\n        m += 1\n    return res\n\nlog_features = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n                 'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n                 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n                 'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n                 'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd']\n\n","d93eef53":"print(df.shape)\n","67bf3913":"df = logs(df, log_features)\n","e829156f":"y=df['SalePrice']","06b12b87":"df=df.drop(['SalePrice','Id'],axis=1)","e3788a49":"print(df.shape)\n","cfc183d9":"#Encode categorical features\ndf = pd.get_dummies(df).reset_index(drop=True)\ndf.shape","b8ec624a":"X_train = df[:train_df.shape[0]]\nX_test = df[train_df.shape[0]:]","6a188b7e":"print(X_train.shape)\nprint(X_test.shape)","9caedaf4":"y=y[:train_df.shape[0]]","81d2a975":"X_t, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42)","b31455b4":"# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=42, shuffle=True)\n# Define error metrics\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model, X=X_t):\n    rmse = np.sqrt(-cross_val_score(model, X, X.columns, scoring=\"neg_mean_squared_error\", cv=kf))\n    return (rmse)","4df4d3bc":"# Ridge Regressor\nridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))","b2c58fd0":" ridge.fit(X_t, y_train)","9ca644be":"y_pred_tr=ridge.predict(X_t)\ny_pred_val=ridge.predict(X_val)","ae864ab2":"print(r2_score(y_true=y_train, y_pred=y_pred_tr))\nprint(r2_score(y_true=y_val, y_pred=y_pred_val))","618160a8":"preds = np.exp(ridge.predict(X_test))","8dad53e5":"predictions = pd.DataFrame({'Id': test_df['Id'] ,'SalePrice': preds })","7ef28f1a":"predictions.to_csv(\"submession_house_prices.csv\",index=False)","e8c278b7":"The SalePrice is skewed to the right. This is a problem because most ML models don't do well with non-normally distributed data. We can apply a log(1+x) tranform to fix the skew.","b0f0fafd":"**Quantitative & Qualitative Data Seperation :**","d547d65f":"**Missing Values**","9f2de80a":"**Corelation Matrix for quantitaive features :**","cfb8a94f":"Log Transformation ","e6b49a2c":"# **EDA**","08ad9f90":"Sale Price distribution after transformation :"}}