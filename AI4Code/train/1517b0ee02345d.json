{"cell_type":{"c7e1f36c":"code","c67211e5":"code","a3385810":"code","6a2d0c8d":"code","91a8ef86":"code","a85c1e1a":"code","1eae689c":"code","40491170":"code","63c55eda":"code","1566cfa0":"code","0c356f51":"code","3f168e57":"code","cacb8438":"code","e1f3bab8":"code","d2d1f794":"code","34496d53":"code","3247e670":"code","1a8249f3":"markdown","21196652":"markdown","79a8b7e8":"markdown","4bbf0deb":"markdown","9ba0100a":"markdown","e8522fac":"markdown","a43c4ec6":"markdown"},"source":{"c7e1f36c":"import os\nimport glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt","c67211e5":"data_dir = '\/kaggle\/input\/hubmap-kidney-segmentation'\nsplit = 'train' # Change this to use test\ntile_size = 512\next = 'jpg' # Change to jpg for smaller files\nFOLDS = 8\nSEED = 32\nnp.random.seed(seed=32)","a3385810":"# https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","6a2d0c8d":"train_df = pd.read_csv(f'{data_dir}\/train.csv')\nsub_df = pd.read_csv(f'{data_dir}\/sample_submission.csv')","91a8ef86":"# Those folders will store our images\nos.makedirs(f'{split}_tiles\/images', exist_ok=True)\nos.makedirs(f'{split}_tiles\/masks', exist_ok=True)\n\n# This list will contain information about all our images\nmeta_ls = []\n\n# Choose a dataframe based on the split\nif split == 'train':\n    df = train_df\nelse:\n    df = sub_df\n\n# The break down starts here\nfor ix in range(df.shape[0]):\n    img_id = df.id[ix]\n    path = f\"{data_dir}\/{split}\/{img_id}.tiff\"\n    print(path)\n    img = skimage.io.imread(path).squeeze()\n    mask = rle2mask(df.encoding[ix], shape=img.shape[1::-1])\n\n    x_max, y_max = img.shape[:2]\n\n    for x0 in tqdm(range(0, x_max, tile_size)):\n        x1 = min(x_max, x0 + tile_size)\n        for y0 in range(0, y_max, tile_size):\n            y1 = min(y_max, y0 + tile_size)\n            \n            if x1-x0!=tile_size or y1-y0!=tile_size:\n                continue\n\n            img_tile = img[x0:x1, y0:y1]\n            mask_tile = mask[x0:x1, y0:y1]\n            \n            # undersampling\n            if np.count_nonzero(mask_tile>=1)==0:\n                if np.random.rand()>0.5:\n                    continue\n\n            img_tile_path = f\"{split}_tiles\/images\/{img_id}_{x0}-{x1}x_{y0}-{y1}y.{ext}\"\n            mask_tile_path = f\"{split}_tiles\/masks\/{img_id}_{x0}-{x1}x_{y0}-{y1}y.png\"\n\n            cv2.imwrite(img_tile_path, cv2.cvtColor(img_tile, cv2.COLOR_RGB2BGR))\n            cv2.imwrite(mask_tile_path, mask_tile*255)\n            \n            # remove concatains too much black or white area \n            if os.path.getsize(img_tile_path)<50000:\n                if np.random.rand()<0.99:\n                    os.remove(img_tile_path)\n                    os.remove(mask_tile_path)\n                    continue\n\n            meta_ls.append([\n                img_id, x0, x1, y0, y1, img_tile.min(), img_tile.max(), \n                mask_tile.max(), img_tile_path, mask_tile_path\n            ])","a85c1e1a":"meta_df = pd.DataFrame(meta_ls, columns=['image_id', 'x0', 'x1', 'y0', 'y1', 'min_pixel_value', 'max_pixel_value', 'max_mask_value', 'image_tile_path', 'mask_tile_path'])\nmeta_df.to_csv(f'{split}_metadata.csv', index=False)\nmeta_df.head()","1eae689c":"# CreateTfrecord","40491170":"folder_img = \".\/train_tiles\/images\"\nfolder_mask = \".\/train_tiles\/masks\"","63c55eda":"img_set = []\nmask_set = []\nids = []\nfolds_id = []\nx = np.arange(8)\ny = np.arange(8)\nnp.random.shuffle(y)\nprint(x,y)\nfor i, j, ix in zip(x, y, df[\"id\"]):\n    img_id = ix\n    imgs = glob.glob(folder_img + f\"\/{img_id}*\")\n    imgs = sorted(imgs)\n    masks = glob.glob(folder_mask + f\"\/{img_id}*\")\n    masks = sorted(masks)\n    \n    img_set.append(imgs)\n    mask_set.append(masks)\n    ids.append([i] * len(imgs))\n    folds_id.append([j] * len(imgs))\n    \nimg_set = np.concatenate(img_set)\nmask_set = np.concatenate(mask_set)\nids = np.concatenate(ids)\nfolds_id = np.concatenate(folds_id)\n\nif len(img_set)!=len(mask_set) or len(img_set)!=len(ids):\n    assert \"invalid\"","1566cfa0":"df=pd.DataFrame({'image_name': img_set,\n                    'mask_name': mask_set,\n                    \"patient_id\": ids,\n                    \"fold\": folds_id})","0c356f51":"df.head()","3f168e57":"folds = df.copy()\n#Fold = KFold(n_splits=8, shuffle=True, random_state=42)\n#for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['mask_name'])):\n#    folds.loc[val_index, 'fold'] = int(n)\n#folds['fold'] = folds['fold'].astype(int)\n#print(folds.groupby(['fold', 'mask_name']).size())","cacb8438":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","e1f3bab8":"def serialize_example(feature0, feature1):\n  feature = {\n      'image': _bytes_feature(feature0),\n      'mask':  _bytes_feature(feature1),\n  }\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()","d2d1f794":"for f in range(FOLDS):\n    ct = (folds['fold'] == f).sum()\n    idx = folds[folds['fold'] == f].index\n    print(idx)\n    print(ct)\n    print('Writing TFRecord %i of %i...'%(f,ct))\n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(f,ct)) as writer:\n        for k in range(ct):\n            path = folds['image_name'][idx[k]]    \n            img = cv2.imread(path)\n            img = cv2.resize(img, (512,512))\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 98))[1].tostring()\n            \n            path2 = folds['mask_name'][idx[k]]    \n            #print(path,path2)\n            \n            mask = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, (512,512))\n            mask = cv2.imencode('.png', mask)[1].tostring()\n            #name = folds['image_id'][idx[k]].split('.')[0]\n            \n            \n            #row = folds.loc[folds.image_id==name]\n            example = serialize_example(\n                img, \n                mask,\n                )\n            writer.write(example)\n            if k%100==0: print(k,', ',end='')\n            if k<5:\n                img = cv2.imread(path)\n                img = cv2.resize(img, (512,512))\n                plt.imshow(img)\n                plt.show()\n                mask = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)\n                mask = cv2.resize(mask, (512,512))\n                plt.imshow(mask)\n                plt.show()","34496d53":"#%%time\n# c: create, q: quiet, f: file\n#!tar -cf train_tiles.tar train_tiles --remove-files\n#!zip -r train_tiles.zip train_tiles ","3247e670":"import shutil\nshutil.rmtree(folder_img)\nshutil.rmtree(folder_mask)","1a8249f3":"## References\n\n[HuBMAP: Break down images into 512x512 tiles](https:\/\/www.kaggle.com\/xhlulu\/hubmap-break-down-images-into-512x512-tiles)\n[How To Create TFRecords](https:\/\/www.kaggle.com\/cdeotte\/how-to-create-tfrecords)","21196652":"## Convert to tar","79a8b7e8":"## Variables","4bbf0deb":"## Helper function","9ba0100a":"## Break down all images","e8522fac":"## Load the CSVs","a43c4ec6":"### other notebooks\n\nMake Tfrecords of 512x512 or other tiles (This notebook)\n\n[HUBMAP TPU Train Phase](https:\/\/www.kaggle.com\/itsuki9180\/hubmap-tpu-train-phase)\n\n[HUBMAP GPU Inference Phase](https:\/\/www.kaggle.com\/itsuki9180\/hubmap-gpu-inference-phase)"}}