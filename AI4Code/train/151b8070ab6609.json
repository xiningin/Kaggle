{"cell_type":{"5d90f9c2":"code","9d6fe937":"code","f2d23b7d":"code","a9046061":"code","5da0dd21":"code","b2a4e359":"code","95728fba":"code","1b13bcdf":"code","8031cb34":"code","cbd0f407":"code","66e6e493":"code","9416bd12":"code","40892902":"markdown","9232e986":"markdown","efb86ed1":"markdown","cd0a0d6b":"markdown","85b6ee6e":"markdown","cedc03fe":"markdown","edb5d30f":"markdown","7587a9be":"markdown","b7065913":"markdown","128faf18":"markdown","5c42e2d2":"markdown","97edaf99":"markdown"},"source":{"5d90f9c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n   \"\"\"  for filename in filenames:\n        print(os.path.join(dirname, filename))\"\"\"\n\n# Any results you write to the current directory are saved as output.","9d6fe937":"import numpy as np\nimport pandas as pd\nimport scipy.io ","f2d23b7d":"def combineMultipleDatas(data_names):\n   datas = data_names[0]\n   x = 0\n   for data in data_names:\n       if x == 0:\n           result = datas.append(data,ignore_index=True)\n       else:\n           result = result.append(data,ignore_index=True)\n       x = x+ 1\n   return result","a9046061":"def dataTableOptimizerUpdated(mat_file):\n    our_data = mat_file['d_skel']\n    datas = []\n    frame_size = len(our_data[0][0])-1\n    for each in range(0,frame_size):\n        data_flatten = our_data[:,:,each].flatten()\n        data_flatten = data_flatten[np.newaxis]\n        datas.append(data_flatten)\n    return datas,frame_size","5da0dd21":"def Loader(path,chosen_class_number):\n    full_list = []\n    for entry in sorted(os.listdir(path)):\n        if os.path.isfile(os.path.join(path, entry)):\n            mat = scipy.io.loadmat(path+entry)\n            all_data, frame = dataTableOptimizerUpdated(mat_file=mat)\n            full_list.extend(all_data)\n    #data_ready = dataTableForCluster2(data=full_list,joint_names=joint_names,column_names=col_names,frame=len(full_list))\n    full_list = np.concatenate(full_list)\n    data_re = pd.DataFrame(full_list)\n    data_re['classs'] = np.full((1,len(data_re)),chosen_class_number).T\n    return data_re","b2a4e359":"root_path = \"\/\/kaggle\/\/input\/\/human-action-recognition-dataset\/\/\"\npath= root_path + \"a1\/\/\"\na_1_files = Loader(path=path,chosen_class_number=1)\npath = root_path + \"a2\/\/\"\na_2_files = Loader(path,chosen_class_number=2)\npath = root_path + \"a3\/\/\"\na_3_files = Loader(path,chosen_class_number=3)\npath = root_path + \"a4\/\/\"\na_4_files = Loader(path,chosen_class_number=4)\npath = root_path + \"a5\/\/\"\na_5_files = Loader(path,chosen_class_number=5)\npath = root_path + \"a6\/\/\"\na_6_files = Loader(path,chosen_class_number=6)\npath = root_path + \"a7\/\/\"\na_7_files = Loader(path,chosen_class_number=7)\npath = root_path + \"a8\/\/\"\na_8_files = Loader(path,chosen_class_number=8)\npath = root_path + \"a9\/\/\"\na_9_files = Loader(path,chosen_class_number=9)\npath = root_path + \"a10\/\/\"\na_10_files = Loader(path,chosen_class_number=10)\npath = root_path + \"a11\/\/\"\na_11_files = Loader(path,chosen_class_number=11)\npath = root_path + \"a12\/\/\"\na_12_files = Loader(path,chosen_class_number=12)\npath = root_path + \"a13\/\/\"\na_13_files = Loader(path,chosen_class_number=13)\npath = root_path + \"a14\/\/\"\na_14_files = Loader(path,chosen_class_number=14)\npath = root_path + \"a15\/\/\"\na_15_files = Loader(path,chosen_class_number=15)\npath = root_path + \"a16\/\/\"\na_16_files = Loader(path,chosen_class_number=16)\npath = root_path + \"a17\/\/\"\na_17_files = Loader(path,chosen_class_number=17)\npath = root_path + \"a18\/\/\"\na_18_files = Loader(path,chosen_class_number=18)\npath = root_path + \"a19\/\/\"\na_19_files = Loader(path,chosen_class_number=19)\npath = root_path + \"a20\/\/\"\na_20_files = Loader(path,chosen_class_number=20)\npath = root_path + \"a21\/\/\"\na_21_files = Loader(path,chosen_class_number=21)\npath = root_path + \"a22\/\/\"\na_22_files = Loader(path,chosen_class_number=22)\npath = root_path + \"a23\/\/\"\na_23_files = Loader(path,chosen_class_number=23)\npath = root_path + \"a24\/\/\"\na_24_files = Loader(path,chosen_class_number=24)\npath = root_path + \"a25\/\/\"\na_25_files = Loader(path,chosen_class_number=25)\npath = root_path + \"a26\/\/\"\na_26_files = Loader(path,chosen_class_number=26)\npath = root_path + \"a27\/\/\"\na_27_files = Loader(path,chosen_class_number=27)","95728fba":"data_names = [a_1_files,a_2_files,a_3_files,a_4_files,a_5_files,a_6_files,a_7_files,a_8_files,a_9_files,a_10_files,a_11_files,a_12_files,a_13_files,a_14_files,a_15_files,a_16_files,a_17_files,a_18_files,a_19_files,a_20_files,a_21_files,a_22_files,a_23_files,a_24_files,a_25_files,a_26_files,a_27_files]\nout = combineMultipleDatas(data_names=data_names)","1b13bcdf":"x = out.drop([\"classs\"],axis=1)\ny = out.classs.values","8031cb34":"from sklearn.model_selection import train_test_split\nx_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)","cbd0f407":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(x_train,y_train)\n\n\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\nknn = KNeighborsClassifier(n_neighbors = 4) #n_neighbors = k\nknn.fit(x_train,y_train)\n\nrf = RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\n\nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)\n\n\nprint(\"acc of svm is :\",svm.score(x_test,y_test))\nprint('Random Forest accuracy on test data is : ',rf.score(x_test,y_test))\nprint(\"k={} nn score:{}\".format(3,knn.score(x_test,y_test)))\nprint('accuracy of bayes in test data is :', nb.score(x_test,y_test))\nprint('acc_of_sgd is: ', sgd.score(x_test,y_test))","66e6e493":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\nclass_names=['swipe left','swipe right','wave','clap','throw','arm cross','basketball shot','draw x','draw circle(clockwise)','draw circle(counter_cloclwise)','draw triangle','bowling','boxing','baseball swing','tennis swing','arm curl','tennis serve','push','knock','catch','pickup-throw','jog','walk','sit_to_stand','stand_to_sit','lunge','squat']\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(rf, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","9416bd12":"from sklearn.model_selection import cross_val_score\n\naccuracy = cross_val_score(estimator = rf, X = x_train, y =y_train, cv = 10)\nprint(\"avg acc: \",np.mean(accuracy))\nprint(\"acg std: \",np.std(accuracy))","40892902":"**Results show that Random Forest has best accuracy.So I choose random forest to make cross validation and see confusion matrix, but in kaggle sklearn version is not updated, so we can't use confusion matrix func**","9232e986":"**We call multiple classifiers and fit all of them then measure the score with test data to see Accuracy.**","efb86ed1":"**A function to make flatten data.**","cd0a0d6b":"**Results show that mean accuracy is really high and standart deviation is very low which says the accuracy scores are really close to each other.**","85b6ee6e":"**We define a list about data with dataframe included, then we combine all datas in one dataframe with classes included which we define 'out'.**","cedc03fe":"**Let's try 10 fold cross validation to see is the algorithm really good?**","edb5d30f":"**First we define root path.The root path is dataset path and it contains 27 folders include 27 action.Then, we add path to corresponding action folder and we Load dataframe.**","7587a9be":"**A function to combine multiple dataframe**","b7065913":"**We split the datas as train test with ratio 75%\/25%**","128faf18":"**We have 27 different human pose actions.The actions are (1) right arm swipe to the left, (2) right arm swipe to the right, (3) right hand wave, (4) two hand front clap, (5) right arm throw, (6) cross arms in the chest, (7) basketball shoot, (8) right hand draw x, (9) right hand draw circle (clockwise), (10) right hand draw circle (counter clockwise), (11) draw triangle, (12) bowling (right hand), (13) front boxing, (14) baseball swing from right, (15) tennis right hand forehand swing, (16) arm curl (two arms), (17) tennis serve, (18) two hand push, (19) right hand knock on door, (20) right hand catch an object, (21) right hand pick up and throw, (22) jogging in place, (23) walking in place, (24) sit to stand, (25) stand to sit, (26) forward lunge (left foot forward), (27) squat (two arms stretch out).**\n\n\n**We will classify all actions.**","5c42e2d2":"**We split data as 'class' columns and the other columns as data.**","97edaf99":"**Main function to Load correct .mat files and convert it to dataframes**"}}