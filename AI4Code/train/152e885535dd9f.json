{"cell_type":{"eed2c0c4":"code","b0aba08d":"code","8878c32a":"code","d37f82f6":"code","2c634545":"code","f7888786":"code","381d14a3":"code","fa9e0068":"code","bb929811":"code","e8f2cea5":"code","130ad090":"code","44c41d66":"code","56a540e8":"code","c297a35d":"code","d23dc84e":"code","04a12288":"code","1791f035":"code","ac2ed8ee":"code","68955bd6":"code","4f5975d3":"code","b99b204f":"code","b1da02f3":"code","bf6708a4":"code","1efecb67":"code","1fa4d96e":"code","52b7704b":"code","f7fe5147":"code","17e338fc":"code","d8e4e399":"code","3857d042":"code","b4132d84":"code","d7307242":"code","5ad66d9a":"code","6ef46cad":"code","7a1f3a2a":"code","bd557cbf":"code","ce2eca71":"code","42fe2ad6":"code","198ba848":"code","aa745f1d":"code","3e8bb7b8":"code","1774f839":"code","258bc820":"code","c620d918":"code","5ff10c56":"code","cdcb5354":"code","6b8112f5":"code","9209590b":"code","fd6a537a":"code","06759aad":"code","d61bbf69":"code","001a65d6":"code","64f4e4f5":"code","c56d92fa":"code","992799f1":"code","63156f9e":"code","19092cc7":"code","84c3faf9":"code","b088de6e":"code","bc56cfc9":"code","b0517440":"code","6a1b82c2":"code","64708e93":"code","9e888266":"code","b7ff39c6":"code","e2d84b52":"code","84c5cbad":"code","2064a0cb":"code","44bb1951":"code","8f46ae65":"code","5d450616":"code","fdf5d391":"code","f5b102e5":"code","d331974b":"code","a039a1c6":"code","57b2b4fb":"code","8db4aa95":"code","969e2b2a":"code","a8d94bfb":"markdown","6ff8c6d2":"markdown","850751f6":"markdown","c98ca4bc":"markdown","e89cc165":"markdown","a3e28e37":"markdown","3666daef":"markdown","caab5220":"markdown","d311a2fa":"markdown","6bd8082f":"markdown","f033c2b5":"markdown","f13c966a":"markdown","1516a229":"markdown","af094824":"markdown","e9708b01":"markdown","2651db98":"markdown","317930e2":"markdown","ffcb8326":"markdown","19910b46":"markdown","a41f921e":"markdown","82890771":"markdown"},"source":{"eed2c0c4":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","b0aba08d":"#importing the dataset\n\ndf = pd.read_csv('..\/input\/data-engineer-jobs\/DataEngineer.csv')\ndf","8878c32a":"print(df.isnull().sum()) #checking for null values in the dataset\nprint(df.info()) #checking the general information of the dataset: non-null count, d-type, etc","d37f82f6":"df['Easy Apply'] = df['Easy Apply'].fillna(False).astype(bool) #As seen in dataset, Easy Apply column has -1 values, replacing them with boolean value False\ndf['Easy Apply'].value_counts() # Checking for value count of Easy Apply column","2c634545":"df.replace(['-1'], [np.nan], inplace=True)\ndf.replace(['-1.0'], [np.nan], inplace=True)\ndf.replace([-1], [np.nan], inplace=True)","f7888786":"df.isnull().sum()  #After replacing -1 with nan, we can see that there are null values in the dataset","381d14a3":"df_salary = df['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = df_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = df_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\nmaximum_salary = maximum_salary.str.replace('Employer est.', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype(int)\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype(int)","fa9e0068":"df['Minimum Salary'] = minimum_salary\ndf['Maximum Salary'] = maximum_salary\n\ndf.drop('Salary Estimate',axis = 1,inplace = True)","bb929811":"df['Company Name'] = df['Company Name'].str.replace('\\n.*', ' ')","e8f2cea5":"Location = df['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndf['Location City'] = Location_City\ndf['Location State'] = Location_State\ndf.drop('Location',axis = 1, inplace = True)\n\nHQ = df['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndf['Headquarters City'] = Headquarters_City\ndf['Headquarters State'] = Headquarters_State\ndf.drop('Headquarters',axis = 1, inplace = True)\n","130ad090":"department = df['Job Title'].str.split(',', expand = True)\ndf['Job Title'], df['Department'] = department[0],department[1]","44c41d66":"df.drop('Department',1, inplace = True)","56a540e8":"df['Job Title'].value_counts()\n","c297a35d":"df['Job Title'] = df['Job Title'].str.replace('Sr.', 'Senior')","d23dc84e":"df.info()","04a12288":"df['Type of ownership'].value_counts()","1791f035":"df['Industry'].value_counts()","ac2ed8ee":"df['Sector'].value_counts()","68955bd6":"df['Revenue'].value_counts()","4f5975d3":"df['Revenue'] = df['Revenue'].replace('Unknown \/ Non-Applicable', None)\n# data['Revenue']=data['Revenue'].replace('Unknown \/ Non-Applicable', None)","b99b204f":"df['Revenue'] = df['Revenue'].str.replace('$', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(USD)', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(')', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(' ', '')","b1da02f3":"df['Revenue'].value_counts()","bf6708a4":"df['Revenue'] = df['Revenue'].str.replace('2to5billion', '2billionto5billion')\ndf['Revenue'] = df['Revenue'].str.replace('5to10billion ', '5billionto10billion ')\n","1efecb67":"df['Revenue'].value_counts()","1fa4d96e":"df['Revenue'] = df['Revenue'].replace('million', ' ')\ndf['Revenue'] = df['Revenue'].replace('10+billion', '10billionto11billion')\ndf['Revenue'] = df['Revenue'].str.replace('Lessthan1million', '0millionto1million')","52b7704b":"df['Revenue'].value_counts()","f7fe5147":"df['Revenue'] = df['Revenue'].str.replace('million', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('billion', '000 ')","17e338fc":"df['Revenue'].value_counts()\n","d8e4e399":"Revenue = df['Revenue'].str.split(\"to\",expand=True)","3857d042":"Revenue[0].value_counts()","b4132d84":"Revenue[1].value_counts()","d7307242":"df['Revenue'].value_counts()","5ad66d9a":"df['Minimum Revenue'] = Revenue[0]\ndf['Maximum Revenue'] = Revenue[1]\n","6ef46cad":"df['Maximum Revenue'] = pd.to_numeric(df['Maximum Revenue'])\ndf['Minimum Revenue'] = pd.to_numeric(df['Minimum Revenue'])","7a1f3a2a":"df.drop('Revenue',1,inplace=True)","bd557cbf":"df","ce2eca71":"df['Size'].value_counts()","42fe2ad6":"df['Size'] = df['Size'].str.replace('employees', '')\n","198ba848":"df['Size'] = df['Size'].str.replace('+', 'plus')\ndf['Size'] = df['Size'].replace('Unknown', None)\n\n","aa745f1d":"df['Size'] = df['Size'].str.replace('10000plus', '10000 to 10001')","3e8bb7b8":"size = df['Size'].str.split(\"to\",expand=True)","1774f839":"df['Minimum Size'] = size[0]\ndf['Maximum Size'] = size[1]\ndf","258bc820":"df.drop('Size',1,inplace = True)","c620d918":"# def contains_word(s, w):\n#     return f' {w} ' in f' {s} '\n\n# # def rev(text):\n# #     #if contains_word(text,'billion') is True:\n# #     text.str.replace('billion','')\n         \n# #     return text\n\n# def revenue(text):\n#     if contains_word(text,'billion') is True:\n#         max_rev = float(data_analyst_jobs['Maximum Revenue'].replace(\"billion\", \" \").strip())*1000\n#         #revenue = float(maxRev[0].replace('+','').strip())*100\n#     return max_rev\n\n# data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].apply(lambda text: clean_revenue(text))","5ff10c56":"f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(df['Minimum Salary'],color = 'r',ax = axes[0])\nsns.distplot(df['Maximum Salary'],ax = axes[1])\nplt.legend();","cdcb5354":"sns.boxplot(x = df['Rating']);","6b8112f5":"df['Minimum Size'] = df['Minimum Size'].astype('float')\ndf['Maximum Size'] = df['Maximum Size'].astype('float')\n\n","9209590b":"f, axes = plt.subplots(1, 2, figsize=(20, 5), sharex=True)\nsns.boxplot(x = df['Minimum Size'], ax = axes[0],palette='Set1');\nsns.boxplot(x = df['Maximum Size'], ax = axes[1],palette='Set2');","fd6a537a":"plt.subplots(figsize=(10,10))\nsplot = sns.barplot(x=df['Job Title'].value_counts()[0:20].index,y=df['Job Title'].value_counts()[0:20], palette = 'winter_r')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Job Title',fontsize=15)\nplt.ylabel('Job Count',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=15)\nplt.title('Top 20 Job Title Counts',fontsize=25);\n\n# for index, row in data_analyst_jobs.iterrows():\n#     splot.text(row.name,row.tip, round('Job Title',2), color='black', ha=\"center\")\n","06759aad":"plt.subplots(figsize=(15,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Maximum Revenue'][0:20], data = df, palette = 'spring')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\n\nplt.xlabel('Company Name',fontsize=15)\nplt.ylabel('Maximum revenue in million dollars',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Maximum Revenue of top 20 Companies',fontsize=25);","d61bbf69":"df['Average Revenue'] = df[['Minimum Revenue','Maximum Revenue']].mean(axis=1)\n","001a65d6":"avg_rev = df['Average Revenue'][0:20]\navg_rev","64f4e4f5":"plt.subplots(figsize=(20,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Average Revenue'][0:20], data = df, palette = 'summer')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Company Name')\nplt.ylabel('Average revenue in million dollars')\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Average Revenue of top 20 Companies',fontsize=25);\n","c56d92fa":"data = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata","992799f1":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 cities', barmode = 'group')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","63156f9e":"data1 = df.groupby('Job Title')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata1","19092cc7":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 job titles', barmode = 'stack')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","84c3faf9":"df['Average Salary'] = df[['Minimum Salary', 'Maximum Salary']].mean(axis = 1)","b088de6e":"import plotly.express as px\nfig = px.scatter(df, x=df['Rating'], y= df['Average Salary'])\nfig.update_layout(title = 'Relation between average salary and rating of companies')\nfig.show()\n","bc56cfc9":"data2 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).head(25)\ndata2","b0517440":"fig = px.line(x=data2['Average Revenue'], y=data2.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","6a1b82c2":"data3 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).tail(25)\ndata3","64708e93":"fig = px.line(x=data3['Average Revenue'], y=data3.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","9e888266":"data4 = pd.DataFrame(df['Sector'].value_counts())\ndata4","b7ff39c6":"import plotly.express as px\nfig = px.pie(data4, values=data4['Sector'], names=data4.index)\nfig.update_layout(title = 'Percentage of Different Sectors with requirement of Data Engineer Roles')\nfig.show()\n","e2d84b52":"data5 = pd.DataFrame(df['Industry'].value_counts().head(25))\ndata5","84c5cbad":"import plotly.express as px\nfig = px.pie(data5, values=data5['Industry'], names=data5.index)\nfig.update_layout(title = 'Percentage of top 25 Industries with requirement of Data Analyst Roles')\nfig.show()\n\n","2064a0cb":"data6 = pd.DataFrame(df['Type of ownership'].value_counts())\ndata6\n\nimport plotly.express as px\nfig = px.pie(data6, values=data6['Type of ownership'], names=data6.index)\nfig.update_layout(title = 'Type of ownership')\nfig.show()\n\n\n","44bb1951":"data7 = pd.DataFrame(df['Headquarters City'].value_counts().head(25))\ndata7\n\nimport plotly.express as px\nfig = px.pie(data7, values=data7['Headquarters City'], names=data7.index)\nfig.update_layout(title = 'Top 25 Headquarter City')\nfig.show()\n\n\n\n","8f46ae65":"data8 = pd.DataFrame(df['Location City'].value_counts().head(25))\ndata8\n\nimport plotly.express as px\nfig = px.pie(data8, values=data8['Location City'], names=data8.index)\nfig.update_layout(title = 'Top 25 Job Locations')\nfig.show()\n\n\n\n\n","5d450616":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","fdf5d391":"plt.subplots(figsize=(15,15))\nwc = WordCloud()\ntext = df['Job Title']\nwc.generate(str(' '.join(text)))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()","f5b102e5":"# import nltk\n# from nltk.corpus import stopwords\n# import re\n# from nltk.stem.porter import PorterStemmer\n# print(stopwords.words('english'))\n\n# stop_words = set(stopwords.words('english'))\n# jobdes = data_analyst_jobs['Job Description'].to_csv()\n# jobdes = jobdes.split(' ')\n# jobdes = jobdes.lower()\n# jobdes","d331974b":"\n# skills = ['python', 'java','c', 'r','c++', 'hadoop', 'communication']\n\n# for word in all_words:\n#     print(word)","a039a1c6":"usa_map = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_map = usa_map.reset_index()\nusa_map.head(20)\n","57b2b4fb":"cities = usa_map['Location City']\ncities.head(20)\n\n['Daly City','Marin City', 'Los Gatos', 'Berkeley', 'San Jose', 'Cupertino','Santa Clara', 'Pico Rivera', 'Whittier','Far Rockaway', 'Secaucus', 'Sunnyvale', 'Menlo Park', 'Elk Grove Village', 'Glenview', 'Maywood', 'Northfield', 'Stanford', 'San Francisco', 'El Cajon']","8db4aa95":"usa_maps = df.groupby('Location State')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_maps = usa_maps.reset_index()\n\nusa_maps = usa_maps.drop([3, 0])\nusa_maps","969e2b2a":"import plotly.express as px\n\nfig = px.choropleth(locations= ['AZ','NJ','NY','CO','IL','NC','VA','SC','WA','PA','DE','TX','KS','FL','IN','OH','GA','UT'], \n                    locationmode=\"USA-states\", \n                    color=[94.494845, 90.232558, 89.026087, 89.022727, 88.829268,85.233333, 85.125000, 83.000000, 82.759259, 77.824561, 75.909091, 74.116751, 67.000000, 66.666667, 61.000000, 58.800000, 56.000000, 48.454545],\n                    labels={'color':'Maximum Salary', 'locations':'State'},\n                    scope=\"usa\") \n\n\nfig.update_layout(\n    \n    title_text = 'Top 20 States with Maximum Salary',\n    geo_scope='usa'\n)\nfig.show()","a8d94bfb":"# 3. Data Visualization# ","6ff8c6d2":"Checking values from the columns for cleaning","850751f6":"**Replacing -1 with nan**","c98ca4bc":"I have implemented some newly gained data analysis and visualization skills on 'Data Engineer Jobs'\n\nYou can also check my similar work on:\n1. [Analysis of Data Analyst Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-analyst-jobs) \n2. [Analysis of Data Scientist Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-scientist-jobs)\n\n\nData Ananlysis on 'Data Engineer Jobs' Data Set.\n1. Data Cleaning\n2. Statistics\n3. Data Visulization\n","e89cc165":"# **1. Data Cleaning**","a3e28e37":"**Cleaning the Size column**","3666daef":"**Separating department and from job title column**","caab5220":"Distribution of minimum and maximum salary of all Data Analyst job titles","d311a2fa":"**Creating separate columns of Size as minimum and maximum size**","6bd8082f":"**If you like my notebook, give it an upvote! Suggestions for improvements are welcomed!**","f033c2b5":"**Creating two separate columns of Revenue as Minimum and Maximum Revenue**","f13c966a":"Checking for outliers in company size","1516a229":"Creating a new DataFrame 'use_maps' consisting of 'Location State', 'Minimum Salary' and 'Maximum Salary' columns for ploting choropleth map for top 20 states with maximum salary.","af094824":"**Word Cloud of Job Titles**","e9708b01":"Creating 'Average Revenue' column","2651db98":"Checking for outliers in Company Ratings","317930e2":"# 2. Statistics","ffcb8326":"**Making city and state columns for both Location and Headquaters**","19910b46":"**Cleaning the Revenue column**","a41f921e":"**Creating separate columns of Salary Estimate as minimum and maximum salary**","82890771":"Since, department has too many missing values (2023\/2253), it can be dropped."}}