{"cell_type":{"b3f9d17e":"code","04997376":"code","23ded9c8":"code","f7ae9b10":"code","3c132f4e":"code","3d955471":"code","56df1749":"code","85db7236":"code","2b9aa012":"code","a62fc59b":"code","171d1841":"code","3b2798a2":"code","40de7deb":"code","e29bf65a":"code","464e2954":"code","100a9b21":"code","c44ebc51":"code","e9d77da9":"code","1e923d29":"code","bd88e8ab":"code","ad6dd5ca":"code","0a49b443":"code","760f4d1b":"code","2c204c72":"code","f35d7271":"code","f805b235":"code","1b79426f":"code","a721be82":"code","2a62f0b1":"code","e7aab7bc":"code","a9013bec":"code","63e92189":"code","b173abb6":"code","2d6e9331":"code","5eb60d50":"code","cb9702dd":"code","6cf4272e":"code","e19194cb":"code","f183c769":"code","be8807d8":"code","f09b0ecf":"code","ee94f44c":"code","b8ee2557":"code","ab41e734":"code","b82a0e14":"code","254730d6":"code","99d6e772":"code","8fbf4f7c":"code","c5f29573":"code","5e41a47f":"code","5574033c":"code","4ad56ac1":"code","baea5032":"code","d26cdf5d":"code","4b587112":"code","a64fd91c":"code","638d9fdc":"code","aa1723fb":"code","bccd8787":"code","b2ba3393":"code","2dbc0bd3":"code","6e3d3faa":"code","15332803":"code","da9c75c5":"code","3bba476c":"code","1357b522":"code","66b25272":"code","835d985d":"code","d2379887":"code","e0f4f9d8":"code","1621df26":"code","3b9dcf59":"code","f06104de":"code","b1d9ad78":"code","ce6e8755":"code","c0fb4eed":"code","b11a8dc0":"code","850d221e":"code","93623f55":"code","904a86e5":"code","9d18909a":"code","56ff2e52":"code","41fc81d4":"code","070b6dd7":"code","b5743554":"code","c2e548db":"code","b939bcb1":"code","74a093ca":"code","b1a75a0a":"code","78f71fc8":"code","17f57add":"code","3644613d":"code","551cbc97":"code","a08d2736":"code","34fcfab9":"code","b79a684a":"code","77632dfb":"code","5cbf8ea8":"code","f3a52912":"code","14555b78":"code","76b24081":"code","cdac8c4b":"code","248dda9d":"code","2169bbb7":"code","d99227aa":"code","3bf11f47":"code","617f1ee6":"code","6596bc83":"code","e842d25e":"code","deee0848":"code","d2290dde":"code","3b2465eb":"code","964ea99e":"code","54bd7fce":"code","c1b652f6":"code","06d78c9c":"code","677105f6":"code","eb470531":"code","53f2ac62":"code","a0e0e012":"code","ad2dc454":"code","674bc62d":"code","b6a6ff63":"code","4aac34fa":"code","c4ae32ef":"code","d109ebb9":"code","723d845a":"code","c624ffa9":"code","c10b1cc4":"code","f276cc80":"code","9de07c88":"code","93062568":"code","98e272fa":"code","3fcb730b":"code","69d722ab":"code","a341912a":"code","dbf77575":"code","8659c5d6":"code","ee4d4ac5":"code","85fe4f9f":"code","b797ed90":"code","248280b4":"code","d1c5061b":"code","d2db1bbb":"code","56b46ad6":"code","6a8b516d":"code","7a15263d":"code","dedf20f1":"code","89e7ec4b":"code","1a58f372":"code","d0926c15":"code","e5e8ac85":"code","ce3a343f":"code","f067e485":"code","62b3cdbe":"markdown","8b0a5a54":"markdown","6c0dac37":"markdown","747f918d":"markdown","2fae2efb":"markdown","e7ad85f7":"markdown","c39801f6":"markdown","172b32cf":"markdown","797b1b6d":"markdown","a00d9d10":"markdown","5fb3104f":"markdown","2e7ecd6f":"markdown","de00fc5d":"markdown"},"source":{"b3f9d17e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04997376":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings","23ded9c8":"warnings.simplefilter(action='ignore', category=FutureWarning)","f7ae9b10":"debug = True","3c132f4e":"num_rows = 30000 if debug else None","3d955471":"# df = get_train_test(DATA_DIRECTORY, num_rows=num_rows)","56df1749":"NUM_THREADS = 4\nDATA_DIRECTORY = '..\/input\/home-credit-default-risk\/'\nSUBMISSION_SUFIX = \"_model2_04\"","85db7236":"path = DATA_DIRECTORY\nnum_rows = num_rows","2b9aa012":"train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows= num_rows)\ntest = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows= num_rows)","a62fc59b":"train.head()","171d1841":"train['TARGET'].value_counts().plot.bar()","3b2798a2":"df = train.append(test)","40de7deb":"del train, test;","e29bf65a":"gc.collect()","464e2954":"df['CODE_GENDER'].value_counts()","100a9b21":"df['CODE_GENDER'] != 'XNA'","c44ebc51":"df = df[df['CODE_GENDER'] != 'XNA'] # 4 people with XNA code gender","e9d77da9":"df = df[df['AMT_INCOME_TOTAL'] < 20000000]  # Max income in test is 4M; train has a 117M value","1e923d29":"(df['DAYS_EMPLOYED'] ==365243).sum()","bd88e8ab":"df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)","ad6dd5ca":"df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)","0a49b443":"[col for col in df.columns if 'FLAG_DOC' in col]","760f4d1b":"docs = [col for col in df.columns if 'FLAG_DOC' in col]","2c204c72":"df[docs].sum(axis=1)","f35d7271":"df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)","f805b235":"len(docs)","1b79426f":"df['DOCUMENT_COUNT'].hist()","a721be82":"df[docs].kurtosis(axis=1).hist()","2a62f0b1":"df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)","e7aab7bc":"- df['DAYS_BIRTH'] \/ 365 # \ub098\uc774 \uacc4\uc0b0","a9013bec":"def get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \"\"\"\n    age_years = -days_birth \/ 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0","63e92189":"df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x : get_age_label(x))","b173abb6":"df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']","2d6e9331":"df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']","5eb60d50":"df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']","cb9702dd":"# df['EXT_SOURCES_PROD_12'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']","6cf4272e":"# df['EXT_SOURCES_PROD_23'] = df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']","e19194cb":"df['EXT_SOURCES_WEIGHTED'] = df['EXT_SOURCE_1'] * 2 + df['EXT_SOURCE_2'] * 1 + df['EXT_SOURCE_3'] * 3","f183c769":"np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n# \uc774\uac74 \uc65c\ud558\uc9c0?","be8807d8":"np.min([500, 600])","f09b0ecf":"eval('np.min([500, 600])')","ee94f44c":"for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n        df[feature_name] = eval('np.{}'.format(function_name))(\n            df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)","b8ee2557":"df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_ANNUITY']\n# annuity \uc5f0\uae08 - \uc0c1\uc2dd\uc801\uc73c\ub85c \uc7ac\uc815\uc0c1\ud0dc\ub97c \ubcfc \uc218 \uc788\ub294 \ubcc0\uc218","ab41e734":"df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_GOODS_PRICE']\n# \uad6c\ub9e4\ud55c \uc0c1\ud488 \uac00\uaca9 \ub300\ube44 \ube5a","b82a0e14":"df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] \/ df['AMT_INCOME_TOTAL']\n# \uc218\uc785 \ub300\ube44 \uc5f0\uae08","254730d6":"df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_INCOME_TOTAL']\n# \uc218\uc785 \ub300\ube44 \ube5a","99d6e772":"df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] \/ df['DAYS_EMPLOYED']\n# \uace0\uc6a9\uae30\uac04 \ub300\ube44 \uc218\uc785","8fbf4f7c":"df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] \/ df['DAYS_BIRTH']\n# \ub098\uc774 \ub300\ube44 \uc218\uc785","c5f29573":"df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] \/ df['DAYS_BIRTH']\n# \ub098\uc774 \ub300\ube44 \uc77c\ud55c \uae30\uac04","5e41a47f":"df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] \/ df['DAYS_BIRTH']\n# \ub098\uc774 \ub300\ube44 \ud68c\uc0ac\uc5d0 id \ub9cc\ub4e4\uc5b4\uc9c4 \uc9c0 \uc5bc\ub9c8\ub098 \ub418\uc5c8\ub294\uac00","5574033c":"df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_BIRTH']\n","4ad56ac1":"df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_EMPLOYED']","baea5032":"df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] \/ df['DAYS_BIRTH']","d26cdf5d":"# \uc911\uc694\ud55c groupby\n# statistics for applications in the same group\ngroup = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']","4b587112":"# \uadf8\ub8f9\uc744 \ub098\ub204\uace0 \uadf8\ub8f9 \ubcc4 \ud1b5\uacc4\ub7c9\uc744 \ud53c\uccd0\ub85c \uc4f0\uace0 \uc2f6\uc740 \uac83\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n","a64fd91c":"df, group_cols, counted, agg_name = df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN'","638d9fdc":"group_cols","aa1723fb":"counted","bccd8787":"agg_name","b2ba3393":"group_cols + [counted]","2dbc0bd3":"df[group_cols]","6e3d3faa":"df[group_cols + [counted]]","15332803":"df[group_cols + [counted]].groupby(group_cols)","da9c75c5":"df[group_cols + [counted]].groupby(group_cols)[counted]","3bba476c":"df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index()","1357b522":"df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(columns={counted:agg_name})","66b25272":"gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(columns={counted:agg_name})","835d985d":"gp.head()","d2379887":"# merge \ndf.merge(gp, on=group_cols, how='left')","e0f4f9d8":"agg = {}\nagg['counted'] = ['max', 'min', 'median', 'std', 'mean']","1621df26":"agg","3b9dcf59":"# df[group_cols + [counted]].groupby(group_cols)[counted].agg(agg)","f06104de":"df[group_cols + [counted]].groupby(group_cols)[counted].agg(agg['counted'])","b1d9ad78":"df[group_cols + [counted]].groupby(group_cols)[counted].agg(agg['counted']).reset_index()","ce6e8755":"FOO = df[group_cols + [counted]].groupby(group_cols)[counted].agg(agg['counted']).reset_index()","c0fb4eed":"FOO.columns","b11a8dc0":"for i in FOO.columns:\n    print(i)","850d221e":"for i in FOO.columns.values:\n    print(i)","93623f55":"'_'.join('median')","904a86e5":"['_'.join(col) for col in FOO.columns[-5:]]","9d18909a":"['_'.join(col) for col in FOO.columns[-5:]]","56ff2e52":"['counted_' + col for col in FOO.columns[-5:]]","41fc81d4":"FOO.columns = ['_'.join(col).strip() for col in FOO.columns.values]","070b6dd7":"FOO ","b5743554":"del FOO","c2e548db":"def do_mean(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n","b939bcb1":"group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\ndf = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\ndf = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\ndf = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\ndf = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\ndf = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\ndf = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\ndf = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\ndf = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\ndf = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')","74a093ca":"def label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns","b1a75a0a":"df = df\ncategorical_columns=None","78f71fc8":"if not categorical_columns:\n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']","17f57add":"categorical_columns","3644613d":"# sklearn label_encoder, pd factorizer \ub450\uac00\uc9c0 \ubc29\ubc95\nfor col in categorical_columns:\n    break","551cbc97":"pd.factorize(df[col])","a08d2736":"for col in categorical_columns:\n    df[col], uniques = pd.factorize(df[col])","34fcfab9":"df[col]","b79a684a":"uniques","77632dfb":"def label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns","5cbf8ea8":"df, le_encoded_cols = label_encoder(df, None)","f3a52912":"df[group_cols[0]]","14555b78":"def drop_application_columns(df):\n    \"\"\" Drop features based on permutation feature importance. \"\"\"\n    drop_list = [\n        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n    ]\n    # Drop most flag document columns\n    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n    df.drop(drop_list, axis=1, inplace=True)\n    return df","76b24081":"def drop_application_columns(df):\n    \"\"\" Drop features based on permutation feature importance. \"\"\"\n    drop_list = [\n        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n    ]\n    # Drop most flag document columns\n    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n    df.drop(drop_list, axis=1, inplace=True)\n    return df\n","cdac8c4b":"df = drop_application_columns(df)","248dda9d":"# bureau_df = get_bureau(DATA_DIRECTORY, num_rows= num_rows)","2169bbb7":"# \uc678\ubd80 \ub370\uc774\ud130 \uac00\uc838\uc624\ub294 \uac83. \ub2e4\ub978 \ud68c\uc0ac\uc758 \uc2e0\uc6a9 \ud3c9\uac00 \ub370\uc774\ud130\nbureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows= num_rows)","d99227aa":"bureau","3bf11f47":"#credit \ub0a8\uc740 \uc815\ub3c4 : -\ub294 \ub05d\ub09c\uac83 +\ub294 \ub0a8\uc740\uac83\nbureau['DAYS_CREDIT_ENDDATE']","617f1ee6":"bureau['DAYS_CREDIT_ENDDATE'].max()","6596bc83":"bureau['DAYS_CREDIT_ENDDATE'].min()","e842d25e":"# Credit duration and credit\/account end date difference\nbureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\nbureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n# Credit to debt ratio and difference\nbureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] \/ bureau['AMT_CREDIT_SUM_DEBT']\nbureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\nbureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] \/ bureau['AMT_ANNUITY']","deee0848":"def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n    original_columns = list(df.columns)\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n    categorical_columns = [c for c in df.columns if c not in original_columns]\n    return df, categorical_columns","d2290dde":"# bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n# null value\ub97c \uce74\ud14c\uace0\ub9ac\ub85c \uce58\uc9c0 \uc54a\uace0 null data\ub85c \uc720\uc9c0\n# light gbm\uc740 null data \ubb34\uc2dc\ud558\uace0 \ud559\uc2b5\ud558\uace0 null data \ucc44\uc6cc\uc8fc\uc9c0 \uc54a\uc544\ub3c4 \ub428.","3b2465eb":"bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)","964ea99e":"def get_bureau_balance(path, num_rows= None):\n    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n    # Calculate rate for each category with decay\n    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n    # Min, Max, Count and mean duration of payments (months)\n    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n    del bb; gc.collect()\n    return bb_processed\n","54bd7fce":"bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)","c1b652f6":"bb.head()","06d78c9c":"bb['STATUS'].head()","677105f6":"bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)","eb470531":"bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()","53f2ac62":"bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()","a0e0e012":"agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}","ad2dc454":"# bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')","674bc62d":"def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)","b6a6ff63":"df_to_agg = bb\ndf_to_merge = bb_processed\nprefix = ''\naggregations = agg\naggregate_by = 'SK_ID_BUREAU'","4aac34fa":"def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])\n    return agg_df.reset_index()","c4ae32ef":"df_to_agg","d109ebb9":"aggregate_by = 'SK_ID_BUREAU'\naggregations = agg\ndf_to_agg.groupby(aggregate_by).agg(aggregations)","723d845a":"agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)","c624ffa9":"agg_df.columns","c10b1cc4":"pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])","f276cc80":"agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])","9de07c88":"agg_df.head()","93062568":"agg_df.reset_index()","98e272fa":"agg_df.head()","3fcb730b":"agg_df = agg_df.reset_index()","69d722ab":"agg_df.head()","a341912a":"'''\ndef group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n'''","dbf77575":"df_to_merge.merge(agg_df, how='left', on=aggregate_by)","8659c5d6":"'''\ndef get_bureau_balance(path, num_rows= None):\n    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n    # Calculate rate for each category with decay\n    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n    # Min, Max, Count and mean duration of payments (months)\n    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n    del bb; gc.collect()\n    return bb_processed\n'''","ee4d4ac5":"bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')","85fe4f9f":"bureau['STATUS_5']","b797ed90":"bureau['STATUS_12345'] = 0","248280b4":"for i in range(1, 6):\n    bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]","d1c5061b":"bureau['STATUS_12345'].unique()","d2db1bbb":"bureau['STATUS_12345'].value_counts()","56b46ad6":"features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']","6a8b516d":"features","7a15263d":"# month_balance_size\ub85c \uadf8\ub8f9\uc744 \ub9cc\ub4e4\uace0 numerical feature\ub4e4\uc758 \ud3c9\uade0 \ubcf4\uae30\nbureau.groupby('MONTHS_BALANCE_SIZE')[features].mean()\n#\uc774\uac8c \ub610 \ud558\ub098\uc758 \uc815\ubcf4\uac00 \ub420 \uc218 \uc788\ub2e4.","dedf20f1":"agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()","89e7ec4b":"# agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)","1a58f372":"{feat: 'LL_' + feat for feat in features}","d0926c15":"agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)","e5e8ac85":"agg_length.head()","ce3a343f":"bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')","f067e485":"bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')","62b3cdbe":"+ \ud604\uc5c5\uc5d0\uc11c\ub294 \uc124\uba85 \uac00\ub2a5\ud55c \ud53c\ucc98\ub97c \uc4f0\uc9c0\ub9cc \uce90\uae00\uc5d0\uc11c\ub294 \uc124\uba85\uc774 \ub418\uc9c0 \uc54a\uc544\ub3c4 \ub7ad\ud0b9 \uc62c\ub9b4 \uc218 \uc788\ub2e4\uba74 \uc4f4\ub2e4\uace0 \ud55c\ub2e4.","8b0a5a54":"+ \ub300\ucd9c\ud68c\uc0ac\uc758 loan\uc758 \ud615\u314c\u3150","6c0dac37":"## 2\uac15 \ub05d\n---\n# 3\uac15","747f918d":"+ EXT_SOURCE_1 \uc774 feature importance\uac00 \ub192\uac8c \ub098\uc624\ub294 \ubcc0\uc218\uc600\ub294\ub370 \ubb54\uc9c0\ub294 \uc720\ucd94\ud558\uc9c0 \ubabb\ud588\uc5c8\ub2e4\uace0 \ud568.\n+ \uadf8\ub798\ub3c4 \uc911\uc694\ub3c4\uac00 \ub192\uac8c \ub098\uc624\ub2c8\uae4c \uc911\uc694\ud55c \uac83 * \uc911\uc694\ud55c \uac83\uc73c\ub85c \ub354 \uc88b\uc740 \ubcc0\uc218\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uace0\uc790 \ud558\ub294 \uc2dc\ub3c4","2fae2efb":"+ aggregate by number of months in balance and merge with bureau(loan length agg)","e7ad85f7":"imbalanced data","c39801f6":"# mere copywork of astonishing 7th place solution to the home credit competition\n[original work](https:\/\/www.kaggle.com\/jsaguiar\/lightgbm-7th-place-solution)","172b32cf":"+ \uc0c1\uae30 \uc5d0\ub7ec\ub294 pandas aggregation \uba54\uc18c\ub4dc\uc758 deprecated \uc6a9\ubc95\uc5d0 \ub530\ub978 \uac83.   \n+ [\ucc38\uace0: 1st deprecation \ucc38\uc870](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/whatsnew\/v0.20.0.html#whatsnew-0200-api-breaking-deprecate-group-agg-dict)","797b1b6d":"# credit ratio","a00d9d10":"+ `agg`\ub85c \ud615\uc131\ub418\ub294 \ub370\uc774\ud130 \ud504\ub808\uc784 \ud615\ud0dc\uac00 \ub2e4\ub974\uae30 \ub54c\ubb38\uc5d0 string join\uc73c\ub85c \ud615\uc131\ub418\ub294 \uc774\ub984\ub3c4 \ub2ec\ub77c\uc9c4\ub2e4. ","5fb3104f":"+ \ub2e4\ub978 \uc0ac\ub78c\ub4e4\uc774 \uc2dc\ud5d8\ud574 \ubd24\ub294\ub370 \uc774\ub807\uac8c \ubcc0\uacbd\ud574\uc11c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc131\ub2a5\uc774 \uc88b\uc558\ub2e4\uace0 \ud568.\n+ \ud63c\uc790 \ud478\ub294 \uce90\uae00\uc774 \uc544\ub2c8\ub2e4.","2e7ecd6f":"# preprocessing\n\n## EDA\ub294 \uac01\uc790 \uacf5\ubd80 \ud63c\uc790 \ud560 \uc218 \uc788\uc5b4\uc57c.","de00fc5d":"# \uc65c \ub4dc\ub78d\uc744 \ud574\uc57c \ud558\ub294\uac00?\n# eda \ud574\uc11c \uacb0\uc815 \ud55c \uac83\n[null importance](https:\/\/www.kaggle.com\/ogrellier\/feature-selection-with-null-importances)   \n[permutation importance](https:\/\/academic.oup.com\/bioinformatics\/article\/26\/10\/1340\/193348)\n+ \ubaa9\uc801\uc774 \ub300\ucd9c \uc0c1\ud658 \uc608\uce21\n+ \ud559\uc2b5 \ud558\ub2c8\uae4c feature 1\uc774 \uc911\uc694\n    + \uc77c\ubd80\ub7ec \ud0c0\uac9f\uc744 \uaf2c\uc544\uc8fc\uace0\ub098\uc11c \ud559\uc2b5\uc744 \uc2dc\ud0b4 feature1\uc774 \ub354\uc774\uc0c1 \uc911\uc694\ud558\uc9c0 \uc54a\ub2e4 -> feature1\uc740 \ud0c0\uac9f\uacfc \uc0c1\uad00\uad00\uacc4\uac00 \ud06c\ub2e4\n+ \ud559\uc2b5\ud558\ub2c8\uae4c feature2\uac00 \uc911\uc694 x\n    + \ud0c0\uac9f \uaf2c\uc544\uc11c \ud559\uc2b5\uc2dc\ud0a4\ub2c8 feature2\uac00 \uc911\uc694\ud574\uc84c\ub2e4. feature2 \uc911\uc694 X\n+ \uac1c\uc778\uc801\uc73c\ub85c \uacf5\ubd80\ud558\ub294 \uac83\uc774 \uc88b\uc740 \ub178\ud2b8\ubd81\uc785\ub2c8\ub2e4.\n  + feature\ub97c \ub9ce\uc774 \ubc84\ub838\ub2e4."}}