{"cell_type":{"8d76d163":"code","07d2def6":"code","a9a21f06":"code","f3489a85":"code","98c7614c":"code","4a262bd2":"code","bcb642a4":"code","f523410c":"code","727955a2":"code","64225a82":"code","b488975c":"code","5d9ad29f":"code","5a09a1a6":"code","dbabf9cb":"code","b8566c98":"code","55304462":"code","a2c1ec89":"code","3b886f11":"code","947962ad":"code","7422364e":"code","37f20fa5":"code","3eb89b40":"markdown","5bef200d":"markdown","ca028222":"markdown","4f0b1c38":"markdown","a8e67c4d":"markdown","ce5d7d78":"markdown","7013aba5":"markdown","1ade09ce":"markdown","a3d6d48b":"markdown","71c0cb83":"markdown"},"source":{"8d76d163":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nfrom scipy import io\nimport matplotlib.pyplot as plt \nfrom tensorflow.keras import layers\nimport tensorflow_io as tfio\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07d2def6":"!pip install imutils","a9a21f06":"from imutils import paths","f3489a85":"image_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/\")\nmask_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/\")","98c7614c":"path_mask = list(paths.list_images(\"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/\"))\npath_image = list(paths.list_images(\"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/\"))","4a262bd2":"images = os.listdir(image_path)\nmask = os.listdir(mask_path)\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\nlen(image_file_name), len(mask)","bcb642a4":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\",len(check))","f523410c":"size = (256, 256)\ndef image_resize(img):\n    return cv2.resize(img,size )","727955a2":"x = np.array([np.array(np.stack(( image_resize(cv2.imread(os.path.join(image_path,filename.split(\"_mask\")[0]+\".png\"),  0)),), axis=-1)) for filename in image_file_name])\ny= np.array([np.array(np.stack(( cv2.resize(cv2.imread(filename, 0), (256,256)),), axis=-1)) for filename in path_mask])","64225a82":"print(x.shape, y.shape)","b488975c":"plt.figure(figsize = (10,10))\nplt.subplot(121)\nplt.imshow(x[11])\nplt.subplot(122)\nplt.imshow(y[11])\nplt.show()","5d9ad29f":"x_flip = np.flip(x , axis = 2)\ny_flip = np.flip(y, axis = 2)\n\nX = np.append(x, x_flip, axis = 0)\nY = np.append(y, y_flip, axis = 0)\n\nprint(\"X Shape: \", X.shape, \"Y Shape: \", Y.shape)","5a09a1a6":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)","dbabf9cb":"x_train_norm = x_train\/255.\nx_test_norm = x_test\/255.\n\ny_train_norm = (y_train\/255. > 0.5).astype(int)\ny_test_norm = (y_test\/255. > 0.5).astype(int)","b8566c98":"inputs = layers.Input(shape=(256,256,1))\n\nc0 = layers.Conv2D(64, activation='relu', kernel_size=(3,3), padding='same', name = 'C0')(inputs)\nDrop = layers.Dropout(0.1)(c0)\nc1 = layers.Conv2D(64, activation='relu', kernel_size=(3,3), padding='same', name = 'C1')(Drop)  \nc2 = layers.MaxPool2D(pool_size=(2, 2), name = 'MaxPool_1')(c1)\n\nc3 = layers.Conv2D(128, activation='relu', kernel_size=(3,3), padding='same', name = 'C3')(c2)\nDrop = layers.Dropout(0.1)(c3)\nc4 = layers.Conv2D(128, activation='relu', kernel_size=(3,3), padding='same', name = 'C4')(Drop) \nc5 = layers.MaxPool2D(pool_size=(2, 2), name = 'MaxPool_2')(c4)\n\nc6 = layers.Conv2D(256, activation='relu', kernel_size=(3,3), padding='same', name = 'C6')(c5)\nDrop = layers.Dropout(0.2)(c6)\nc7 = layers.Conv2D(256, activation='relu', kernel_size=(3,3), padding='same', name = 'C7')(Drop)  \nc8 = layers.MaxPool2D(pool_size=(2, 2), name = 'MaxPool_3')(c7) \n\nc9 = layers.Conv2D(512, activation='relu', kernel_size=(3,3),padding='same',  name = 'C9')(c8)\nDrop = layers.Dropout(0.2)(c9)\nc10 = layers.Conv2D(512, activation='relu', kernel_size=(3,3), padding='same', name = 'C10')(Drop)  \nc11 = layers.MaxPool2D(pool_size=(2, 2), name = 'MaxPool_4')(c10)\n\nc12 = layers.Conv2D(1024, activation='relu', kernel_size=(3,3), padding='same', name = 'C12')(c11)\nDrop = layers.Dropout(0.3)(c12)\nc13 = layers.Conv2D(1024, activation='relu', kernel_size=(3,3), padding='same', name = 'C13')(Drop)\n\n\nt01 = layers.Conv2DTranspose(512, kernel_size=(2,2), strides=(2,2), padding='same', name = 'Transpose_T01')(c13)\nconcat01 = layers.concatenate([t01, c10], axis=3, name= 'Concat_1')\n\nc14 = layers.Conv2D(512, activation='relu', kernel_size=(3,3), padding='same', name = 'C14')(concat01)\nDrop = layers.Dropout(0.3)(c14)\nc15 = layers.Conv2D(512, activation='relu', kernel_size=(3,3), padding='same', name = 'C15')(Drop)\n\nt02 = layers.Conv2DTranspose(256, kernel_size=(2,2), strides=(2,2), padding='same', name = 'Transpose_T02')(c15)\nconcat02 = layers.concatenate([t02, c7], axis=3, name= 'Concat_2')\n\nc16 = layers.Conv2D(256, activation='relu', kernel_size=(3,3), padding='same', name = 'C16')(concat02)\nDrop = layers.Dropout(0.2)(c16)\nc17 = layers.Conv2D(256, activation='relu', kernel_size=(3,3), padding='same', name = 'C17')(Drop)\n\nt03 = layers.Conv2DTranspose(128, kernel_size=(2,2), strides=(2, 2), name = 'Transpose_T03')(c17)\nconcat03 = layers.concatenate([t03, c4], axis=3, name= 'Concat_3')\n\nc18 = layers.Conv2D(128, activation='relu', kernel_size=(3,3), padding='same', name = 'C18')(concat03)\nDrop = layers.Dropout(0.2)(c18)\nc19 = layers.Conv2D(128, activation='relu', kernel_size=(3,3), padding='same', name = 'C19')(Drop)\n\nt04 = layers.Conv2DTranspose(64, kernel_size=(2,2), strides=(2, 2), padding='same', name = 'Transpose_T04')(c19)\nconcat04 = layers.concatenate([t04, c1], axis=3, name= 'Concat_4')\n\nc20 = layers.Conv2D(64, activation='relu', kernel_size=(3,3), name = 'C20', padding = 'same')(concat04)\nDrop = layers.Dropout(0.1)(c20)\nc21 = layers.Conv2D(64, activation='relu', kernel_size=(3,3), name = 'C21', padding = 'same')(Drop)\n\noutput = layers.Conv2D(1, activation='sigmoid', kernel_size=(1,1), name = 'O\/P')(c21)\n\nmodel_UNet = tf.keras.Model(inputs=inputs, outputs=output, name='UNet')","55304462":"model_UNet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])","a2c1ec89":"model_UNet.summary()","3b886f11":"model_UNet.fit(x_train_norm, y_train_norm, epochs = 5, validation_data = (x_test_norm, y_test_norm), batch_size = 20)","947962ad":"pred = model_UNet.predict(x_test_norm)[0]","7422364e":"plt.imshow(pred)","37f20fa5":"plt.imshow(x_test_norm[0])","3eb89b40":"## ***Model Building***","5bef200d":"## ***Data Augmentation***","ca028222":"## ***Split data into train and test***","4f0b1c38":"## ***Fit data to model***","a8e67c4d":"## ***Model Summary***","ce5d7d78":"## ***Model Compilation***","7013aba5":"## ***Display Sample Image***","1ade09ce":"## ***Data Normalization***","a3d6d48b":"## ***Prediction***","71c0cb83":"## ***Image Data Gathering***"}}