{"cell_type":{"904214d4":"code","7145fc06":"code","70bf11c7":"code","21aac32f":"code","94655c70":"code","c9b1fd87":"code","71c85b8d":"code","eec4e39c":"code","2a2e573a":"code","b356257f":"code","2488448d":"code","f9ec4673":"code","2f42fc0e":"code","8dfd2c7d":"code","4fbf7199":"code","d86d8be3":"code","0c8e6c03":"code","978589eb":"code","8c4f9ed7":"code","ace9df4f":"code","ca51926c":"code","6dc02950":"code","8a4d9357":"code","5703de7f":"code","c3e3d29f":"code","365126c8":"code","a73b75fc":"markdown","618b91d3":"markdown","27aeb5df":"markdown","a3bcfaf7":"markdown","b19b15b9":"markdown","c808cd16":"markdown","d652fdbc":"markdown","7ff9a9e8":"markdown","4215f94a":"markdown","b80e0ffd":"markdown","737650f4":"markdown"},"source":{"904214d4":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader ","7145fc06":"train_csv = '..\/input\/digit-recognizer\/train.csv'\ntest_csv = '..\/input\/digit-recognizer\/test.csv'","70bf11c7":"train_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)","21aac32f":"train_df.head()","94655c70":"test_df.head()","c9b1fd87":"class CustomDataset(Dataset):\n    def __init__(self, df, transform, train_data=True):\n        self.df = df\n        self.transform = transform\n        self.train_data = train_data\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        \n        if self.train_data:\n            label = self.df.iloc[index, 0]\n            flatten_image = self.df.iloc[index, 1:].astype('float32').values # shape: (784)\n        else:\n            flatten_image = self.df.iloc[index].astype('float32').values # shape: (784)\n        \n        # reshape \n        image_np = flatten_image.reshape(28,28)\n        \n        image = Image.fromarray(image_np)\n        image = self.transform(image)\n        \n        if self.train_data:\n            return image, torch.tensor(label)\n        return image","71c85b8d":"transform = transforms.Compose([\n    transforms.Resize((28,28)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5), (0.5))\n])\ntrain_dataset = CustomDataset(train_df, transform=transform, train_data=True)\ntest_dataset = CustomDataset(test_df, transform=transform, train_data=False)","eec4e39c":"# split train into train and val\ntrain_size = int(0.8 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])","2a2e573a":"BATCH_SIZE = 32\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)","b356257f":"X, y = next(iter(train_loader))\nX.shape, y.shape","2488448d":"num_cols = 8\nnum_rows = BATCH_SIZE \/\/ num_cols\nf, ax = plt.subplots(num_rows, num_cols)\ncomp = 0\n\nfor i in range(num_rows):\n    for j in range(num_cols):\n        comp += 1\n        idx = i*num_cols+j\n        img = X[idx]\n        img = img.squeeze()\n        img = img.numpy()\n        ax[i,j].imshow(img, cmap='gray')\n        ax[i,j].set_title(y[idx].item())\n        ax[i,j].axis('off')\n\n    f.set_figheight(7)\n    f.set_figwidth(15)\n\nplt.show()","f9ec4673":"class CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN, self).__init__()\n        \n        # conv layers\n        self.conv1 = nn.Conv2d(in_channels=1,\n                               out_channels=16,\n                               kernel_size=(3,3),\n                               stride=(1,1),\n                               padding=(1,1))\n        \n        self.conv2 = nn.Conv2d(in_channels=16,\n                               out_channels=32,\n                               kernel_size=(3,3),\n                               stride=(1,1),\n                               padding=(1,1))\n        \n        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.relu = nn.ReLU()\n        \n        # linear layers\n        self.fc1 = nn.Linear(32*7*7, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, num_classes)\n        \n        # dropout \n        self.dropout = nn.Dropout(p=0.5)\n    \n    def forward(self, x):\n        # shape of x: (batch_size, channels, h, w)\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n\n        # flattten x\n        x = x.reshape(x.shape[0], -1)\n        x = self.dropout(self.relu(self.fc1(x)))\n        x = self.dropout(self.relu(self.fc2(x)))\n        x = self.fc3(x)\n        return x","2f42fc0e":"# Test model on sample example\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = CNN().to(device)\nout = model(X.to(device))\nprint(out.shape)","8dfd2c7d":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)","4fbf7199":"def train_epoch(model, data_loader, device, criterion, optimizer):\n    model.train()\n\n    losses = []\n    correct = 0\n    total = 0\n\n    for batch_idx, (x, y) in enumerate(tqdm(data_loader)):\n        x = x.to(device)  \n        y = y.to(device) \n\n        output = model(x)\n\n        loss = criterion(output, y)\n\n        losses.append(loss.item())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        preds = F.softmax(output, dim=1)\n        preds = preds.argmax(dim=1, keepdim=True).reshape(-1)\n        correct += (preds == y).sum().item()\n        total += preds.size(0)\n\n    acc = (correct * 1.0) \/ total\n    \n    return acc, np.mean(losses)","d86d8be3":"def val_epoch(model, data_loader, device, criterion):\n    model.eval()\n\n    losses = []\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch_idx, (x, y) in enumerate(tqdm(data_loader)):\n            x = x.to(device)  \n            y = y.to(device) \n\n            output = model(x)\n\n            loss = criterion(output, y)\n\n            losses.append(loss.item())\n\n            preds = F.softmax(output, dim=1)\n            preds = preds.argmax(dim=1, keepdim=True).reshape(-1)\n            correct += (preds == y).sum().item()\n            total += preds.size(0)\n\n    acc = (correct * 1.0) \/ total\n\n    return acc, np.mean(losses)","0c8e6c03":"# Train model\nEPOCHS = 50\n\nbest_val_acc = 0\n\nfor epoch in range(EPOCHS):\n    print(f'Epoch: {epoch+1}\/{EPOCHS}')\n    print('-'*10)\n    print('Training')\n    train_acc, train_loss = train_epoch(model, train_loader, device, criterion, optimizer)\n    print('Validating')\n    val_acc, val_loss = val_epoch(model, val_loader, device, criterion)\n    print(f'Train Loss: {train_loss}\\tTrain Acc: {train_acc}')\n    print(f'Val Loss: {val_loss}\\tVal Acc: {val_acc}')\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_model.pth.tar')","978589eb":"# Load best model\nmodel.load_state_dict(torch.load('best_model.pth.tar'))","8c4f9ed7":"def test_model(model, data_loader, device):\n    model.eval()\n\n    predictions_list = []\n\n    with torch.no_grad():\n        for batch_idx, x in enumerate(tqdm(data_loader)):\n            x = x.to(device)  \n\n            output = model(x)\n\n            _, preds = torch.max(output, dim=1)\n\n            predictions_list.append(preds.view(-1).cpu())\n\n    return predictions_list","ace9df4f":"predictions_list = test_model(model, test_loader, device)\ny_pred = torch.cat(predictions_list).numpy()","ca51926c":"X_test = next(iter(test_loader))\nX_test.shape","6dc02950":"output = model(X_test.to(device))\n_, preds = torch.max(output, dim=1)\npreds.shape","8a4d9357":"num_cols = 8\nnum_rows = BATCH_SIZE \/\/ num_cols\nf, ax = plt.subplots(num_rows, num_cols)\ncomp = 0\nf.suptitle('Predictions')\nfor i in range(num_rows):\n    for j in range(num_cols):\n        comp += 1\n        idx = i*num_cols+j\n        img = X_test[idx]\n        img = img.squeeze()\n        img = img.numpy()\n        ax[i,j].imshow(img, cmap='gray')\n        ax[i,j].set_title(preds[idx].item())\n        ax[i,j].axis('off')\n\n    f.set_figheight(7)\n    f.set_figwidth(15)\n\nplt.show()","5703de7f":"submission_df = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","c3e3d29f":"submission_df.head()","365126c8":"submission_df['Label'] = y_pred\nsubmission_df.to_csv('submission.csv', index=False)\nprint('Done!')","a73b75fc":"### Define loss function and optimizer","618b91d3":"### Let's train model","27aeb5df":"### Let's visualize predicted output","a3bcfaf7":"### Let's build CNN architecture","b19b15b9":"### Building Custom Dataset","c808cd16":"### Loading data into pandas dataframe","d652fdbc":"Looks pretty good.","7ff9a9e8":"### Let's test the model","4215f94a":"### Make submission","b80e0ffd":"### Importing Libraries","737650f4":"### Visulaize one batch from training data"}}