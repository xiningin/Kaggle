{"cell_type":{"f477338a":"code","1d30092a":"code","0f59f1b5":"code","1bee45d8":"code","1e2f3aa1":"code","2d77148f":"code","10796479":"code","7c95171a":"code","3a011a88":"code","617808a5":"code","dee97ece":"code","c76a8a12":"code","02316449":"code","f5974c91":"markdown","1ac89f5a":"markdown","efe71c8b":"markdown","35d41edb":"markdown","c0ea6e7d":"markdown","0586bcd7":"markdown","46672016":"markdown","bbe51f06":"markdown","7c80903a":"markdown","1974775c":"markdown","95b73c37":"markdown","f81d5631":"markdown"},"source":{"f477338a":"import pandas as pd\n\ntrain_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","1d30092a":"train_data.head()","0f59f1b5":"train_data.shape, test_data.shape","1bee45d8":"# Remove rows with missing target, separate target from predictors\ntrain_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\nX = train_data.drop(['SalePrice'], axis=1)\ny = train_data.SalePrice              ","1e2f3aa1":"numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\ncategorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and X[cname].dtype == \"object\"]\n\n# Concating columns\nmy_cols = categorical_cols + numerical_cols\n\n# Copying datasets\nX_data = X[my_cols].copy()\nX_test = test_data[my_cols].copy()","2d77148f":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='median')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=\n                       [('preprocessor', preprocessor),\n                        ('model', model)])","10796479":"from sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"Average MAE score:\", scores.mean())","7c95171a":"def get_score(n_estimators):\n    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n    \n    Keyword argument:\n    n_estimators -- the number of trees in the forest\n    \"\"\"\n    # Replace this body with your own code\n    my_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor(n_estimators, random_state=0))\n    ])\n    scores = -1 * cross_val_score(my_pipeline, train_data, y,\n                                  cv=3,\n                                  scoring='neg_mean_absolute_error')\n    return scores.mean()","3a011a88":"results = {}\nfor i in range(3,8):\n    results[50*i] = get_score(50*i)","617808a5":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(list(results.keys()), list(results.values()))\nplt.show()","dee97ece":"model = RandomForestRegressor(n_estimators=300, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=\n                       [('preprocessor', preprocessor),\n                        ('model', model)])","c76a8a12":"my_pipeline.fit(X_data, y)\npreds_test = my_pipeline.predict(X_test)","02316449":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","f5974c91":"## Creating the model and the pipeline","1ac89f5a":"## Using cros-validation","efe71c8b":"## Finding best score  ","35d41edb":"## Plot the scores","c0ea6e7d":"## Creating pipeline","0586bcd7":"Submitting to competition","46672016":"[Housing Prices Competition for Kaggle Learn Users](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course)\n\n![Ames Housing dataset image](https:\/\/i.imgur.com\/lTJVG4e.png)","bbe51f06":"## Creating a function for evaluating scores","7c80903a":"## Creating the input and output variables","1974775c":"## Selecting numeric and categorical columns","95b73c37":"## Refitting model and predicting test set","f81d5631":"## Read Datasets"}}