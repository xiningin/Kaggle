{"cell_type":{"cebe64fb":"code","d265b5cd":"code","5325d030":"code","4672ba02":"code","3d010890":"code","69f8ef43":"code","cbb92f76":"code","513d63e7":"code","aee26e1d":"code","6606997e":"code","0435b457":"code","c626667b":"code","b08faf73":"code","4ae34476":"code","d4de5f49":"code","b713ccae":"markdown"},"source":{"cebe64fb":"# importamos librerias\nfrom fastai.vision import *\nwarnings.simplefilter(\"ignore\")","d265b5cd":"path = Path('..\/input\/medical-mnist\/')\npath.ls()","5325d030":"data = (ImageList.from_folder(path)\n                 .split_by_rand_pct()\n                 .label_from_folder()\n                 .transform(get_transforms(), size=64)\n                 .databunch(bs=64)\n                 .normalize())\ndata","4672ba02":"data.show_batch(3, figsize=(8,8))","3d010890":"# Examinemos la data\nxb,yb = data.one_batch()","69f8ef43":"xb.shape\n# [batch_size, channels (RGB), ancho, alto]","cbb92f76":"yb\n# Tenemos 1 label por cada imagen","513d63e7":"data.c2i","aee26e1d":"model = nn.Sequential(\n    nn.Conv2d(3, 16, kernel_size=3),\n    nn.MaxPool2d(2),\n    nn.ReLU(),\n    nn.Conv2d(16, 32, kernel_size=3),\n    nn.MaxPool2d(2),\n    nn.ReLU(),\n    nn.Conv2d(32, 64, kernel_size=3),\n    nn.MaxPool2d(2),\n    nn.ReLU(),\n    nn.Conv2d(64, 128, kernel_size=3),\n    nn.MaxPool2d(2),\n    nn.ReLU(),\n    nn.Flatten(),\n    nn.Linear(512,data.c) # data.c = numero de clases en el dataset\n)\n\nmodel","6606997e":"learn = Learner(data, model, metrics=accuracy)","0435b457":"learn.fit_one_cycle(3, 1e-3)","c626667b":"learn.show_results(DatasetType.Train, 4)","b08faf73":"interp = learn.interpret()","4ae34476":"interp.plot_confusion_matrix()","d4de5f49":"interp.plot_top_losses(9)","b713ccae":"# Modelo"}}