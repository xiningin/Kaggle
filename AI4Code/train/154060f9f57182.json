{"cell_type":{"b06136a0":"code","8f83b3e2":"code","ec0c8a34":"code","5dd28b69":"code","7f8c8e54":"code","15d33a25":"code","510619ba":"code","954d5401":"code","185689cf":"code","26f454d7":"code","c14a6666":"code","8cec3ce2":"code","5e0ad45e":"code","3b3c21c6":"code","75c0e91b":"code","42adadda":"code","8e290662":"code","76bc3097":"code","d5fdd90f":"code","14559fb8":"code","4c29403a":"code","c93d0c73":"markdown","519387ea":"markdown","f2c8f86a":"markdown","e431259d":"markdown","2a7c1e0d":"markdown","906303e7":"markdown","667fbd89":"markdown","96bf2fcb":"markdown","b65df74f":"markdown","1d7b9b60":"markdown","fe3032a8":"markdown","41ae9843":"markdown","feb7a55a":"markdown","88124384":"markdown","10d496bf":"markdown","18bb98ef":"markdown","f347a109":"markdown","9fd3953c":"markdown","13045e4e":"markdown","7c12f7db":"markdown","63ce1b85":"markdown","e635ce24":"markdown","f73f3327":"markdown","75124505":"markdown","70445e95":"markdown","1465b750":"markdown","46c2cf4e":"markdown","a1cd25a7":"markdown","719b7589":"markdown","f77a5043":"markdown","4e7bca52":"markdown","9a447a51":"markdown"},"source":{"b06136a0":"from fastai import __version__\nprint(f\"fastai version {__version__}\")\n\nimport graphviz\nimport matplotlib as mpl\nimport numpy as np\nimport pandas as pd\nimport shutil\n\nfrom fastai.tabular.all import *\n\nfrom pandas.api.types import CategoricalDtype\nfrom scipy.cluster import hierarchy as hc\n\nmpl.rcParams['savefig.dpi']= 200\nmpl.rcParams['font.size']=12\n\nset_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\npd.set_option('display.max_columns',999)\nnp.set_printoptions(linewidth=200)\ntorch.set_printoptions(linewidth=200)\n\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')\n\n# Prepare diagram 'Top Level'\ntop_level = '''ordering=in\n            problem[shape=cds width=1 height=1 label=\"1\\nFrame business problem \\ninto a ML problem\"]\n            data[shape=cylinder width=1 height=1 label=\"2\\nCollect, and prepare \\ndata, incl. labeling\"]\n            modeling[shape=box3d width=1 height=1 label=\"3\\nBuild model \\nand train it\"]\n            evaluate[shape=component width=1 height=1 label=\"4\\nEvaluate and \\nvalidate model\"]\n            improve[shape=rarrow width=1 height=1 label=\"5\\nImprove model to \\nreach expected standard\"]\n            problem->data->modeling->evaluate->improve'''\n\nprint(\"Imports and Configurations Done\")","8f83b3e2":"gv(top_level)","ec0c8a34":"gv(top_level)","5dd28b69":"p2data = Path('\/kaggle\/input\/house-prices-advanced-regression-techniques')\ntrain = pd.read_csv(p2data \/ 'train.csv')\ndisplay(train.head(10))","7f8c8e54":"print('Description of the features with possible values:\\n')\nwith open(p2data\/'data_description.txt', 'r') as f:\n    print(f.read())","15d33a25":"dep_var = 'SalePrice'\n\nfeature_list = list(train.columns)\nfeature_list.remove(dep_var)\nprint(f\"{len(feature_list)} features and target: {dep_var}\")","510619ba":"conts, cats = cont_cat_split(train, dep_var=dep_var)\n\nconts.remove('Id')\n\nprint(f\"{len(conts)} continuous features and {len(cats)} categorical features. Total of {len(conts)+len(cats)} features\")","954d5401":"to_be_ordered = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', \n                 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n\norder_values = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']\n\ntrain.loc[:, to_be_ordered] = train.loc[:, to_be_ordered].astype('category')\nfor col in to_be_ordered:\n    train[col].cat.set_categories(order_values, ordered=True, inplace=True)","185689cf":"pd.DataFrame({'NaN': train.isna().sum(axis='rows'), \n              \"NaN %\": train.isna().sum(axis='rows')\/train.shape[0]}).sort_values(by='NaN %', ascending=False).head(10)","26f454d7":"print(f\"Before: {len(conts)} continuous features and {len(cats)} categoricals for a total of {len(cats) + len(conts)}\")\nfor f in ['PoolQC', 'MiscFeature', 'Alley', 'Fence']:\n    if f in conts:\n        conts.remove(f)\n    elif f in cats:\n        cats.remove(f)\n\nprint(f\"After: {len(conts)} continuous features and {len(cats)} categoricals for a total of {len(cats) + len(conts)}\")","c14a6666":"print(f\"Before taking the log: Min Sale Price: {train[dep_var].min():,.0f}; Max Sale Price: {train[dep_var].max():,.0f}\")\ntrain[dep_var].plot(kind='kde');","8cec3ce2":"train[dep_var] = np.log(train[dep_var])\nprint(f\"After taking the log: Min log Sale Price: {train[dep_var].min():,.0f}; Max log Sale Price: {train[dep_var].max():,.0f}\")\ntrain[dep_var].plot(kind='kde');","5e0ad45e":"idxs_ordered_by_time = train.loc[:, ['YrSold', 'MoSold']].copy().sort_values(by=['YrSold', 'MoSold']).index\nnbr_rows = train.shape[0]\ncut_off = int(nbr_rows * 0.8)\n# (Index of all rows with date before the cut off date, index of all rows with data after the cut off date)\nsplits = (list(idxs_ordered_by_time[:cut_off]), list(idxs_ordered_by_time[cut_off:]))","3b3c21c6":"to = TabularPandas(train,\n                   cat_names=cats,\n                   cont_names=conts,\n                   y_names=dep_var,\n                   procs=[Categorify, FillMissing, Normalize],\n                   y_block=RegressionBlock,\n#                    splits=RandomSplitter(seed=88)(range_of(train))\n                   splits=splits\n                   )\n\ndls = to.dataloaders(64)\ndls.show_batch()","75c0e91b":"gv(top_level)","42adadda":"print(f\"Min log Sale Price: {train[dep_var].min():,.0f}; Max log Sale Price: {train[dep_var].max():,.0f}\")","8e290662":"learn = tabular_learner(dls, \n                        layers=[150, 50],\n                        n_out=1,\n                        y_range=[5, 20], \n                        metrics=rmse)","76bc3097":"learn.fit_one_cycle(30, lr_max=5e-3)","d5fdd90f":"gv(top_level)","14559fb8":"preds_valid, _ = learn.get_preds(dl=dls.valid)\n\n_, ax = plt.subplots(1, 1, figsize=(18, 6))\nax.set_title('SalePrice: Predictions vs Ground Truth')\nax.plot(np.exp(preds_valid), label='Predictions')\nax.plot(np.exp(dls.valid.y.values), label='Ground Truth')\nax.set_ylim(ymin=np.exp(train[dep_var].min()), ymax=np.exp(train[dep_var].max()))\nax.legend()\nplt.show();","4c29403a":"_, ax = plt.subplots(1, 1, figsize=(8, 8))\nax.scatter((preds_valid), (dls.valid.y.values))\nax.set_title('SalePrice: Predictions vs Ground Truth Scatter Plot')\nax.set_xlim(xmin=11, xmax=13)\nax.set_xlabel('Predictions')\nax.set_ylim(ymin=11, ymax=13)\nax.set_ylabel('Ground Truth')\nplt.show();","c93d0c73":"Now it is time to build our model. \n\nTabular data models are simple compared to image or natural language processing models. We do not need to use pretrained models. We will use `tabular_learner` which tells fastai that the model is intended for tabular data.\n\nWe have all we need to create a model by telling the computer:\n- the data to use to train the model: `dls`\n- a description of the layers we want our model to have. In our case, two layers: one with 150 inputs and one with 50 inputs\n- the range we expect `y` or `SalePrice` to be in. It helps the model train faster\n- the metrics we want to monitor to evaluate the performance. We will use Root Mean Squared Error\n\n","519387ea":"#### Process those categorical features that should be ordered\n\nLooking that the description above, it is clear that some of the categorical values have a logical order. In particular, the following variables share the same ordering.\n```\nExterQual, ExterCond, BsmtQual, BsmtCond, HeatingQC, KitchenQual, FireplaceQu, GarageQual, GarageCond, PoolQC\n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n       NA\tNone\n```\nWe will add this order to the data so that the model can also take this into account.\n\nWe also could do the same for some of the other features such as `Electrical`, but because they do not share a specific order, we do not do it in this first iteration.","f2c8f86a":"# Final comments and next step\n\nThis is a quick overview of tabular data. The results are not bad but certainly can be improved. Some participants to the competition have achieved better results. But again, this is not the purpose of this notebook to come to the top result.","e431259d":"### Load training data\n- Let's load the data in `train.csv` into pandas `DataFrame` object called `train`. \n- Then we display the first 10 rows to visualize the data.\nWe see the 80 features (columns) defined by their column name, and their values for each row. All the way to the right, `SalePrice` is the target sale price we want to learn how to predict.","2a7c1e0d":"Now we have `conts` and `cats` and we have ordered a few of the features. We still need to check which feature have a too high `NaN` rate. \n\nLet's print the 10 features with the highest percentage of `NaN`. We will drop any feature with more than 60%.","906303e7":"## 3\ufe0f\u20e3 Build a model and train it","667fbd89":"In tabular, data preparation include the following:\n- verify whether all rows have a value for all features. Typically, some rows will have missing values, a.k.a. `NaN`. We will check whether some of the features have a high percentage of `NaN`. \n- review types of features: \n    - numerical\/continuous: which can take any value and is a number\n    - categorical: text or number but taking a limited number or predefined values\n    - ordered: categorical feature but for which the order has a meaning. For instance: `good`, `average`, `poor` have an intrinsic order.\n    - unstructured\/text: can take any type of text content, as a comment or a remark. These types of variables cannot be easily handled by the tools we will use here. They require preprocessing with a natural language processing tool first. We do not have any such feature in the current dataset.","96bf2fcb":"#### Check features with high percentage of `NaN` and drop any column with more than 60% `NaN`","b65df74f":"We can see that the model learned very well with RMSE evolving from 0.966 down to 0.167 !","1d7b9b60":"Kaggle provides the following files:\n- `data_description.txt`: a descrition of each column in the table (a.k.a. features)\n- `sample_submission.csv`: a format to submit prediction on the test set for evaluation\n- `test.csv`: a set of information without the sale price, which we need to predict\n- `train.csv`: the set of information with sale price for training\n\nThe `comma separated value` file `train.csv` includes the values required to train the model. It is easy to load into Python using a package called `pandas`. \n\nThe file includes **1,460 rows** of data, corresponding to one piece of real estate. Each row counts **80 features** a.k.a. inputs a.k.a. independant variables and the **sale price** corresponding to that specific peice of real estate. \n\nDuring training, we want to learn the relationship between the 80 features and the sale price so that we can predict the price for new unseen pieces of real estate.","fe3032a8":"### Evaluate based on the training and validation set","41ae9843":"[Double click here and write your thoughts]","feb7a55a":"#### Define the target which we want to predict, a.k.a. dependant variable: `dep_var`.","88124384":"### Prepare data to feed the model.\n\nFor these structured data, we use another function to present the data to the computer, instead of a `DataBlock`, we use something very similar called a Tabular Object `to` which received its data directly from Pandas.\n\nIn this example, we tell the computer:\n- we get all the data from a pandas DateFrame, `train`\n- we tell the computer which are the continuous and continuous features\n- we tell the computer which is the target a.k.a. dependant variable a.k.a. `y`\n- before using the data, the computer should **Categorify** non numerical values into numbers, **Fill** missing values and **Normalize** the numbers\n- we inform the computer that this is a **regression** problem, not a **classificatin** one\n- finaly, we keep a **validation set** of 20% of the row, which will not be used for training, but to test whether the training gives good results.","10d496bf":"Do not forget to save your notebook before you close this window.\n\nNext step is to experiment with a few tools available for natural language processing.  Click on the link below to reach the reference notebook which you can copy and edit:\n\n<a href=\"https:\/\/www.kaggle.com\/vtecftwy\/ai-deep-dive-03-nlp\" target=\"_black\"><div align=\"center\"><button >Click here to open the \"Experiment with NLP: notebook<\/button><\/div><\/a>","18bb98ef":"### What is the problem we want to solve?\n\n\ud83d\udc77 Think of what we are trying to predict and write it in the cell below","f347a109":"## 1\ufe0f\u20e3 Frame the problem","9fd3953c":"Let's say that we are interested in real estate pricing and want to predict the value of a specific piece of real estate based on a set of parameters available on that estate. Things such as the area, the number of bedrooms, the number of bathrooms, size of the garage, the date of construction, etc ...\n\nWe have access to a dataset of more than 1,000 rows of information from Kaggle [housing prices](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques)\n\n<div align=\"left\"><img src=\"https:\/\/www.kaggle.com\/static\/images\/site-logo.png\" width=10%><\/div>\n\n<div align=\"left\"><img src=\"https:\/\/raw.githubusercontent.com\/vtecftwy\/fastbook\/master\/resources\/img\/kaggle-housing-logo.png\" width=50%><\/div>","13045e4e":"### Review the content of the table\nHere is a list of the 80 features. More details in the file `data_description.txt` printed in next cell.\n\n**target - dependent variable**\n```\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n```\n\n**features:**\n```\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: $Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale\n```","7c12f7db":"### Prepare the data\n","63ce1b85":"<h1>","e635ce24":"## 2\ufe0f\u20e3 Collect and Prepare Data, including Labeling","f73f3327":"# \ud83d\udcc8 Tabular Data - Deep Dive in AI\n\nThis notebook is the second of three notebooks, guiding anyone interested in understanding what deep learning do through the steps of what deep learning practitioners do. For each step, you will see an explanation in words, and the corresponding simple code allowing you to execute\/run each step.\n\nIf you have not gone through the first notebook, you should start there: <a href=\"https:\/\/www.kaggle.com\/vtecftwy\/ai-deep-dive-01-cv\" target=\"_black\"><div align=\"center\"><button >Click here to open the first notebook<\/button><\/div><\/a>","75124505":"# \ud83e\uddf0 Imports and configurations\nJust run the cell below to get ready.","70445e95":"## 4\ufe0f\u20e3 Evaluate the trained model","1465b750":"### The set of data\n\nThe dataset counts 80 piece of information for each estate, and the price at which the estate was sold. The purpose is to predict the sales price for new estates based on new sets of information.\n\nSubset of info in the dataset (see lower for more details on each of the 80)\n- The building class (1-story, 2-story, duplex, ...)\n- Lot size in square feet\n- General shape of property\n- Type of utilities available\n- Proximity to main road or railroad\n- Type of dwelling (single family, townhouse, ...)\n- Original construction date\n- Type of roof\n- General condition of the basement\n- Type of heating\n- Number of kitchens\n- Kitchen quality\n- Year Sold\n. . . .\n","46c2cf4e":"**Important note**: In this dataset time is important: real estate is sold at different dates and we can expect that the newly sold items will have a higher price than the ones sold earlier. Therefore, we will split all the rows for training will be chronologically prior to the ones in the validation set.\n>The code cell below does this this by selecting all the rows before a cut off date for training and those after the cut off date for testing.","a1cd25a7":"We have a clean dataset available on Kaggle. There is not much clearning up or verification we need to do.\n\nIn real life, you will have to build this dataset from data available from different systems in the organization or\/and from publicly available data. We will have to check the consistency and coherence of the data. And of course, whether we can produce similar data easily in the future for prediction.","719b7589":"#### Special handling of `SalePrice`\nThe kaggle competition description indicates that the result will tested by using the *root mean squared error* on the *logarithm* of the target. This is a common metric when applied to sales prices or things that grow geometrically (growth by an average rate over a period of time).\n\nTo keep it simple, we will transform all `SalePrice` into `log(SalePrice)` and use the normal rmse metric. Then when we make a prediction, we will take the exponential of the prediction to get the predicted `SalePrice`.","f77a5043":"**Preparation steps:**\n1. Define the target which we want to predict, a.k.a. dependant variable: `dep_var`.\n2. Make a list of the continous features: `conts`\n3. Make a list of the categorical features: `cats`\n4. Process those categorical features that should be ordered\n5. Check features with high percentage of `NaN` and drop any column with more than 60% `NaN`.","4e7bca52":"#### Make a list of the continous features: `conts` and a list of the categorical features: `cats`\n\nNote: we remove `Id` from the list because it is an arbitrary number with no meaning","9a447a51":"Here we train the model from scratch. We will not use `finetune` but another action: `fit_one_cycle`, standing for fit (train) in a special efficient cycle (fastai uses a state-of-the-art cycle to train faster and better.\n\nSince we train from scratch, we will also use more epochs. Fortunately, tabular data trains faster."}}