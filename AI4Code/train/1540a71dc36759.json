{"cell_type":{"552454a9":"code","bc5586a6":"code","ac79d4ec":"code","43c1ea37":"code","fb3a54fb":"code","e0bdb1c3":"code","972c9841":"code","c7d8c945":"code","8b682c53":"code","6e2baafd":"markdown","f1c58871":"markdown","2d064566":"markdown","72f8ebb3":"markdown","8ba3def3":"markdown","1b593273":"markdown"},"source":{"552454a9":"import os\nimport math\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport plotly.graph_objs as go\nimport plotly.express as px","bc5586a6":"df = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ntrain = df.copy()\n\nn_groups = df.shape[0] \/\/ 50000\ndf[\"group\"] = 0\nfor i in range(n_groups):\n    ids = np.arange(i*50000, (i+1)*50000)\n    df.loc[ids,\"group\"] = i\n\nfor i in range(n_groups):\n    sub = df[df.group == i]\n    signals = sub.signal.values\n    imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n    signals = (signals - np.min(signals))\/(np.max(signals) - np.min(signals))\n    signals = signals*(imax-imin)\n    df.loc[sub.index,\"pred_open_channels\"] = np.array(signals,np.int)\n\ny_true = df.open_channels.values\ny_pred = df.pred_open_channels.values","ac79d4ec":"%%time\ncm = metrics.confusion_matrix(y_true, y_pred, normalize='true')","43c1ea37":"fig = px.imshow(cm)\nfig.show()","fb3a54fb":"%time report = metrics.classification_report(y_true, y_pred)","e0bdb1c3":"print(report)","972c9841":"%%time\nlwk = metrics.cohen_kappa_score(y_true, y_pred, weights='linear')\nqwk = metrics.cohen_kappa_score(y_true, y_pred, weights='quadratic')\\\n\nprint(\"Linear Weighted Kappa Score:\", lwk)\nprint(\"Quadratic Weighted Kappa Score:\", qwk)","c7d8c945":"true_bins = np.bincount(y_true)\npred_bins = np.bincount(y_pred.astype(int))[:10]","8b682c53":"fig = go.Figure([\n    go.Bar(y=true_bins, name='True Labels'),\n    go.Bar(y=pred_bins, name='Pred Labels')\n])\n\nfig.show()","6e2baafd":"# Looking at prediction histogram","f1c58871":"# Visualize normalization confusion matrix\n\nWe will normalize along the true axis.","2d064566":"# Comparing various kappa scoring","72f8ebb3":"# About this kernel\n\nThis is to show how different ways of measuring the performance of this model will yield very different results, and as a conclusion we will see that QWK is perhaps far from the best metrics for this type of data. We will show\n\n- Confusion Matrix: How \"blurred\" the diagonal line is, compared to a perfect scoring.\n- Classification Report: How the f1 score decrease dramatically as we go into more rare classes.\n- LWK vs QWK: How a simple weighting changes the score by 10%\n- Prediction Histogram: How the predicted classes frequency are pretty \"off\" compared to ground truth.","8ba3def3":"# Reproducing simple baseline\n\nEssentially [this kernel](https:\/\/www.kaggle.com\/suicaokhoailang\/an-embarrassingly-simple-baseline-0-960-lb), but applied on training set.","1b593273":"# Looking at f1 score by class"}}