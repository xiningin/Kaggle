{"cell_type":{"6ed1c6b7":"code","b1c89fec":"code","fc53dca7":"code","193c1c5c":"code","fce9b4d0":"code","f5df7107":"code","0c0279aa":"code","340f5cf6":"code","d993be55":"code","fb18d1e1":"code","9b6b302b":"code","500ac471":"code","a4ae84c8":"code","2c36f5f9":"code","5a206851":"code","ec240b25":"code","ad479de0":"code","ce2be7b4":"code","ab7e1ffb":"code","8ae7a870":"code","03e7fc73":"code","82ae7d45":"code","cefe16c4":"code","57828dad":"code","b1c87969":"code","ece29564":"code","4f38eee3":"code","d584a803":"code","bbffa544":"code","a6077fc1":"code","43ff866d":"code","457d4271":"code","66ccf8e8":"code","e0859955":"code","a8ca24ef":"code","3ce47956":"code","2cf8c134":"code","7d131eb9":"code","f93a0142":"code","b58e6d60":"code","5f6baa80":"code","4cb82d83":"code","cf508be5":"code","e1fb256f":"code","9c3450ba":"code","e0c7a530":"code","98183c74":"code","0200e052":"code","b3ba2678":"code","b96bdd3d":"code","f1c82a45":"code","6f2b979e":"code","fcae8846":"code","2689e76e":"code","dfb8407e":"code","5cd9653f":"markdown","68c39def":"markdown","5a9ad383":"markdown","2f1cbb75":"markdown","1f607a0f":"markdown","f08f69af":"markdown","f62ac84f":"markdown","3bfc2fd2":"markdown","446a97bd":"markdown","518993bb":"markdown","9cb86cf8":"markdown","79abd43b":"markdown"},"source":{"6ed1c6b7":"!pip install \/kaggle\/input\/wheels\/torch-1.5.0cu101-cp37-cp37m-linux_x86_64.whl","b1c89fec":"!pip install \/kaggle\/input\/wheels\/torchvision-0.6.0cu101-cp37-cp37m-linux_x86_64.whl","fc53dca7":"!pip install \/kaggle\/input\/wheels\/yacs-0.1.7-py3-none-any.whl","193c1c5c":"!pip install \/kaggle\/input\/wheels\/fvcore-0.1.1.post200513-py3-none-any.whl","fce9b4d0":"!pip install \/kaggle\/input\/wheels\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl","f5df7107":"!pip install \/kaggle\/input\/wheels\/detectron2-0.1.3cu101-cp37-cp37m-linux_x86_64.whl","0c0279aa":"!pip install -U \/kaggle\/input\/wheels\/watermark-2.0.2-py2.py3-none-any.whl","340f5cf6":"%reload_ext watermark\n%watermark -v -p numpy,pandas,pycocotools,torch,torchvision,detectron2","d993be55":"from pathlib import Path","fb18d1e1":"DATA_DIR = Path('\/kaggle\/input\/global-wheat-detection')\nTRAIN_PATH = Path(DATA_DIR \/ 'train')\nTEST_PATH = Path(DATA_DIR \/ 'test')\n\nSUB_PATH = Path(DATA_DIR \/ 'sample_submission.csv')","9b6b302b":"import torch, torchvision\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\nimport glob\n\nimport os\nimport ntpath\nimport numpy as np\nimport cv2\nimport random\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\nimport urllib\nimport json\nimport PIL.Image as Image\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 12, 8\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","500ac471":"torch.device('cuda' if torch.cuda.is_available() else 'cpu')","a4ae84c8":"train_df = pd.read_csv(DATA_DIR \/ 'train.csv')\n\ntrain_df.head()","2c36f5f9":"train_df.shape","5a206851":"train_df.info()","ec240b25":"train_df['source'].unique()","ad479de0":"train_df['image_id'].unique().shape","ce2be7b4":"dataset = []\n\nfor index, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n    image_name = f\"{row['image_id']}.jpg\"\n\n    bboxes = row['bbox']\n    bboxes = bboxes.replace('[', '')\n    bboxes = bboxes.replace(']', '')\n    bboxes = bboxes.split(',')\n\n    x_min = float(bboxes[0])\n    y_min = float(bboxes[1])\n    x_max = float(bboxes[2])\n    y_max = float(bboxes[3])\n\n    data = {}\n\n    width = row['width']\n    height = row['height']\n\n    data['file_name'] = image_name\n    data['width'] = width\n    data['height'] = height\n\n    data[\"x_min\"] = x_min\n    data[\"y_min\"] = y_min\n    data[\"x_max\"] = x_max\n    data[\"y_max\"] = y_max\n\n    data['class_name'] = 'wheat'\n      \n    dataset.append(data)","ab7e1ffb":"df = pd.DataFrame(dataset)\n\ndf.shape","8ae7a870":"df.head()","03e7fc73":"def annotate_image(annotations, resize=True, path=str(TRAIN_PATH)):\n  file_name = annotations.file_name.to_numpy()[0]\n  img = cv2.cvtColor(cv2.imread(f'{path}\/{file_name}'), cv2.COLOR_BGR2RGB)\n  for i, a in annotations.iterrows():\n    cv2.rectangle(img, (int(a.x_min), int(a.y_min)), (int(a.x_max) + int(a.x_min), int(a.y_max) + int(a.y_min)), (0, 255, 0), 2)\n  if not resize:\n    return img\n  return cv2.resize(img, (384, 384), interpolation = cv2.INTER_AREA)","82ae7d45":"img_id = np.random.randint(len(df.file_name.unique())) \nimg_df = df[df.file_name == df.file_name.unique()[img_id]]\n# img_df\n\nimg = annotate_image(img_df, resize=False)\nplt.imshow(img)\nplt.axis('off')","cefe16c4":"# import torch, torchvision\nsample_images = [annotate_image(df[df.file_name == f]) for f in df.file_name.unique()[:10]]\nsample_images = torch.as_tensor(sample_images)\n\nsample_images = sample_images.permute(0, 3, 1, 2)\n\nplt.figure(figsize=(24, 12))\ngrid_img = torchvision.utils.make_grid(sample_images, nrow=5)\n\nplt.imshow(grid_img.permute(1, 2, 0))\nplt.axis('off')","57828dad":"# TRAINING\nunique_files = df.file_name.unique()\n\ntrain_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace=False))\ntrain_df = df[df.file_name.isin(train_files)]\nval_df = df[~df.file_name.isin(train_files)]\n","b1c87969":"train_df.shape","ece29564":"val_df.shape\n","4f38eee3":"classes = df.class_name.unique().tolist()\nclasses\n","d584a803":"# Convert to format used by detectron2\ndef create_dataset_dicts(df, classes):\n  dataset_dicts = []\n  for image_id, img_name in enumerate(df.file_name.unique()):\n    record = {}\n    image_df = df[df.file_name == img_name]\n    file_path = f'{TRAIN_PATH}\/{img_name}'\n    record[\"file_name\"] = file_path\n    record[\"image_id\"] = image_id\n    record[\"height\"] = int(image_df.iloc[0].height)\n    record[\"width\"] = int(image_df.iloc[0].width)\n    objs = []\n    for _, row in image_df.iterrows():\n      xmin = int(row.x_min)\n      ymin = int(row.y_min)\n      xmax = int(row.x_max)\n      ymax = int(row.y_max)\n\n      poly = [\n          (xmin, ymin), (xmin+xmax, ymin),\n          (xmin+xmax, ymin+ymax), (xmin, ymin+ymax)\n      ]\n      poly = list(itertools.chain.from_iterable(poly))\n\n      obj = {\n        \"bbox\": [xmin, ymin, xmin+xmax, ymin+ymax],\n        \"bbox_mode\": BoxMode.XYXY_ABS,\n        \"segmentation\": [poly],\n        \"category_id\": classes.index(row.class_name),\n        \"iscrowd\": 0\n      }\n      objs.append(obj)\n    record[\"annotations\"] = objs\n    dataset_dicts.append(record)\n  return dataset_dicts","bbffa544":"# register dataset inot the dataset and metadata catalogues\nfor d in [\"train\", \"val\"]:\n  DatasetCatalog.register(\"wheat_\" + d, lambda d=d: create_dataset_dicts(train_df if d == \"train\" else val_df, classes))\n  MetadataCatalog.get(\"wheat_\" + d).set(thing_classes=classes)\n  \nstatement_metadata = MetadataCatalog.get(\"wheat_train\")\n","a6077fc1":"dataset_dicts = create_dataset_dicts(train_df, classes)","43ff866d":"nrows = 1\nncols = 3\n\n# Index for iterating over images\npic_index = 0\n\n\nfig = plt.gcf()\n\nfig.set_size_inches(ncols * 8, nrows * 12)\n\nfor i, d in enumerate(random.sample(dataset_dicts, 3)):\n    \n    sp = plt.subplot(nrows, ncols, i + 1, facecolor='red')\n    sp.axis('Off')\n    \n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=statement_metadata, scale=0.5)\n    vis = visualizer.draw_dataset_dict(d)\n    plt.imshow(vis.get_image()[:, :, ::-1], interpolation = 'bicubic')","457d4271":"# DatasetCatalog.get(name='wheat_train')[1]\n\n# evaluator\nclass CocoTrainer(DefaultTrainer):\n  @classmethod\n  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n    if output_folder is None:\n        os.makedirs(\"coco_eval\", exist_ok=True)\n        output_folder = \"coco_eval\"\n    return COCOEvaluator(dataset_name, cfg, False, output_folder)","66ccf8e8":"# Load the config file and the pre-trained model weights\ncfg = get_cfg()","e0859955":"cfg.merge_from_file(\n  model_zoo.get_config_file(\n    \"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n)","a8ca24ef":"WEIGHT_PATH = '\/kaggle\/input\/weights\/model_final.pth'\ncfg.MODEL.WEIGHTS = WEIGHT_PATH","3ce47956":"\"\"\"\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n  \"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n)\n\"\"\"","2cf8c134":"# print(cfg.dump())\n\ncfg.DATASETS.TRAIN = (\"wheat_train\",)\ncfg.DATASETS.TEST = (\"wheat_val\",)\ncfg.DATALOADER.NUM_WORKERS = 4\n\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.001\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 100\ncfg.SOLVER.STEPS = (10, 50)\ncfg.SOLVER.GAMMA = 0.05\n\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\ncfg.TEST.EVAL_PERIOD = 1000","7d131eb9":"# print(cfg.dump())\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)","f93a0142":"trainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=False)","b58e6d60":"trainer.train()","5f6baa80":"print(cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)","4cb82d83":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n# predictor = DefaultPredictor(cfg)","cf508be5":"evaluator = COCOEvaluator(\"wheat_val\", cfg, False, output_dir=\".\/output\/\")\nval_loader = build_detection_test_loader(cfg, \"wheat_val\")\ninference_on_dataset(trainer.model, val_loader, evaluator)","e1fb256f":"# Finding wheats in images\n\n# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.45\npredictor = DefaultPredictor(cfg)","9c3450ba":"# os.makedirs(\"annotated_results\", exist_ok=True)\ntest_image_paths = os.listdir(TEST_PATH)\n\ntest_image_paths","e0c7a530":"annotated_results = []\n\nfor wheat_image in test_image_paths:\n  file_path = f'{TEST_PATH}\/{wheat_image}'\n  im = cv2.imread(file_path)\n  outputs = predictor(im)\n  v = Visualizer(\n    im[:, :, ::-1],\n    metadata=statement_metadata,\n    scale=1.,\n    instance_mode=ColorMode.IMAGE\n  )\n  instances = outputs[\"instances\"].to(\"cpu\")\n  # instances.remove('pred_masks')\n  v = v.draw_instance_predictions(instances)\n  result = v.get_image()[:, :, ::-1]\n  file_name = ntpath.basename(wheat_image)\n  annotated_results.append(result)","98183c74":"img =cv2.cvtColor(annotated_results[0], cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis('off')","0200e052":"img =cv2.cvtColor(annotated_results[1], cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis('off')","b3ba2678":"img =cv2.cvtColor(annotated_results[9], cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis('off')","b96bdd3d":"img =cv2.cvtColor(annotated_results[4], cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis('off')","f1c82a45":"sub_df = pd.read_csv(SUB_PATH)\nsub_df","6f2b979e":"def submit():\n    for idx, row in tqdm(sub_df.iterrows(), total=len(sub_df)):\n        img_path = os.path.join(TEST_PATH, row.image_id + '.jpg')\n        \n        img = cv2.imread(img_path)\n        outputs = predictor(img)['instances']\n        # instances.remove('pred_masks')\n        outputs.remove('pred_masks')\n        boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n        scores = outputs.scores.cpu().detach().numpy()\n        list_str = []\n        for box, score in zip(boxes, scores):\n            box[3] -= box[1]\n            box[2] -= box[0]\n            box = list(map(int,box))\n            score = round(score, 4)\n            list_str.append(score)\n            list_str.extend(box)\n        sub_df.loc[idx, 'PredictionString'] = ' '.join(map(str, list_str))\n        \n    return sub_df","fcae8846":"subm_df = submit()\nsubm_df.to_csv('submission.csv', index=False)","2689e76e":"subm_df","dfb8407e":"subm_df['PredictionString'][2]","5cd9653f":"# TEST IMAGES","68c39def":"# INSTALL LIBRARIES","5a9ad383":"# TRAIN MODEL","2f1cbb75":"# SUBMISSION","1f607a0f":"# Visualize prepared dict","f08f69af":"# SET PATHS","f62ac84f":"# Prepare train and val","3bfc2fd2":"# EVALUATE","446a97bd":"# Prepare Dataset for training","518993bb":"# IMPORT NECESSARY LIBRARIES","9cb86cf8":"# TRAINING CONFIG","79abd43b":"# EDA"}}