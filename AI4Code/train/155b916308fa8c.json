{"cell_type":{"730a620b":"code","f64c1965":"code","78be5cb5":"code","d90e7dae":"code","ae9c853a":"code","fdb4dcd8":"code","35fc5611":"code","9810a881":"code","4f956a51":"code","410d28be":"code","7da5f7c2":"code","115b4285":"code","2c84397f":"markdown"},"source":{"730a620b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f64c1965":"dataset = pd.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")","78be5cb5":"dataset","d90e7dae":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","ae9c853a":"ps = PorterStemmer()\ndata = []\nfor i in range(0,len(dataset)):\n    review = dataset[\"review\"][i]\n    review = re.sub('[^a-zA-Z]',' ',review)\n    \n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in set(stopwords.words(\"english\"))]\n    review = ' '.join(review)\n    \n    data.append(review)","fdb4dcd8":"from sklearn.feature_extraction.text import CountVectorizer","35fc5611":"cv = CountVectorizer(max_features=2000)\nx = cv.fit_transform(data)\nx = x.toarray()\n\ny = dataset.iloc[:,1:2].values\nfor i in range(0,len(y)):\n    if y[i] == \"positive\":\n        y[i] = 1\n    else:\n        y[i] = 0\ny","9810a881":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=0)","4f956a51":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","410d28be":"model = Sequential()\nmodel.add(Dense(units=1565,kernel_initializer=\"random_uniform\",activation=\"relu\"))\nmodel.add(Dense(units=3000,kernel_initializer=\"random_uniform\",activation=\"relu\"))\nmodel.add(Dense(units=3000,kernel_initializer=\"random_uniform\",activation=\"relu\"))\nmodel.add(Dense(units=1,kernel_initializer=\"random_uniform\",activation=\"sigmoid\"))\nmodel.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\nhistory=model.fit(x_train.astype(np.float),y_train.astype(np.float),epochs=10)","7da5f7c2":"print(history.history[\"accuracy\"])","115b4285":"pred = model.predict(x_test)\npred=pred>0.5\npred","2c84397f":"# 18BIS0032\n# ASHWATH A"}}