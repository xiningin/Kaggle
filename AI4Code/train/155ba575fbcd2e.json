{"cell_type":{"2758528d":"code","004f4f74":"code","e0bfdd40":"code","a30a64e6":"code","03b02af7":"code","9f5add43":"code","5c853970":"code","0c6d1d72":"code","3f1e9546":"code","bcfddce4":"code","f7a7faed":"code","99c6b5ae":"code","d04d90e0":"code","290a1b6c":"code","d2413e6e":"code","96bc4d6f":"code","5452c5b5":"code","f2478aea":"code","0f259c33":"code","42e68972":"code","8c855571":"code","74543258":"code","f3514431":"code","14ec81e5":"code","dc95204c":"code","97acfe08":"code","5cdf8cea":"code","74f83447":"code","75307b5b":"code","3def3b9c":"code","c154debc":"code","6692c82a":"code","b665a114":"code","c71a228a":"code","105ea643":"code","b555ee5f":"code","fd5f0b92":"code","b9354403":"code","b48d2f8d":"code","5bd55ad8":"code","6c6d4e78":"code","7ed517fb":"code","51a3ace5":"code","d3f846ca":"code","46c5eed5":"code","f79911eb":"code","51041cf9":"code","b376598a":"code","d020ff85":"code","158eb109":"code","c22c9bba":"code","fc417a60":"code","1030ee0c":"code","84fc94f0":"code","26bdaaf1":"code","f4bb352b":"code","830d4d9e":"code","7de3b006":"code","10b20d11":"code","20be6752":"code","fe5d8545":"code","d831abc9":"code","e33e6670":"code","a9262304":"code","14f5f2de":"code","0e93d2e5":"code","570d7a4f":"code","21c564e1":"code","46154c37":"code","43c468d2":"code","6f2791b1":"code","1770a1e9":"code","bf34585b":"code","16c024c8":"code","36be927f":"code","5ae97d4a":"code","d79e0c62":"code","3bf5924c":"code","915f71ac":"code","8cacc75e":"code","07c3d9fd":"code","f6ff0ea4":"code","1be0b432":"code","0fd4b119":"code","ed0435c4":"code","c1e68eb8":"code","12d3a43c":"code","d25ca6ae":"code","6a6bd07f":"code","5bb3d64a":"code","080a2d77":"code","e3e505da":"code","6dc882e6":"code","f9cc25ce":"markdown","7d2743cf":"markdown","473d1e71":"markdown","ea570fdd":"markdown","183ff958":"markdown","d690e781":"markdown","4e3d6c8e":"markdown","9877186e":"markdown","9256cafa":"markdown","7985efd9":"markdown","be8838fe":"markdown","af33455f":"markdown","489254da":"markdown","32905f28":"markdown","bea61166":"markdown","c4836b91":"markdown","7d410e89":"markdown","6cbfccaa":"markdown","be9c7c6a":"markdown","22dbc169":"markdown","ce2d0cc2":"markdown","d6b191bc":"markdown","65eb75d4":"markdown","15a91698":"markdown","855e3c0c":"markdown","04c386a1":"markdown","c7b83b00":"markdown","9cd8504d":"markdown","9c2f52ee":"markdown","54142b51":"markdown","c09d4e6c":"markdown","d1f1eef8":"markdown","9252fc9c":"markdown","62e6ba40":"markdown","4c0e3eb7":"markdown","889f3f93":"markdown","d3fbf05e":"markdown","b6e5bd18":"markdown","d921bbbb":"markdown","7db6680a":"markdown","779ec213":"markdown","ded072ed":"markdown","ce67c7f1":"markdown","b274e6b9":"markdown","3f00f401":"markdown","bcfc773b":"markdown","9a5e3aeb":"markdown","5a2c3827":"markdown","b9166755":"markdown","e4d6d25c":"markdown","b133bbaa":"markdown","ea612080":"markdown","60903c37":"markdown","ab7cf004":"markdown","8965bd11":"markdown","92136aff":"markdown"},"source":{"2758528d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","004f4f74":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport datetime as dt\nfrom datetime import timedelta\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error, r2_score, make_scorer\nfrom sklearn.preprocessing import PolynomialFeatures\n\nimport scipy.cluster.hierarchy as sch\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\npy.init_notebook_mode(connected= True)\n\nfrom fbprophet import Prophet\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","e0bfdd40":"df1= pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\ndf1.head(5)","a30a64e6":"print('Shape of the dataset: \\n', df1.shape,'\\n\\n')\nprint('Check for NULL values: \\n', df1.isnull().sum(), '\\n\\n')\nprint('Datatype of each independent variable: ', df1.dtypes)","03b02af7":"# Dropping the SNo column\n\ndf1.drop([\"SNo\"], 1, inplace= True)\ndf1.head(2)","9f5add43":"# Converting the given date-time format into pandas provided datetime format\n\ndf1['ObservationDate']= pd.to_datetime(df1['ObservationDate'])\ndf1['Last Update']= pd.to_datetime(df1['Last Update'])\ndf1.head(2)","5c853970":"# Check if the data is updated\nprint(\"Dataset Description\")\nprint(\"Earliest Entry: \",df1['ObservationDate'].min())\nprint(\"Last Entry:    \",df1['ObservationDate'].max())\nprint(\"Total Days:    \",(df1['ObservationDate'].max() - df1['ObservationDate'].min()))","0c6d1d72":"# Grouping the dataframe by 'ObservationDate' and 'Country\/Region' and aggregating with 'Confirmed', 'Recovered' and 'Death' cases.\n\ncou_grp= df1.groupby(['Country\/Region','ObservationDate']).agg({\n                                                \"Confirmed\": 'sum',\n                                                \"Recovered\": 'sum',\n                                                \"Deaths\": 'sum'\n})\n\ncou_grp.head(2)","3f1e9546":"# Adding a column of 'Active Cases' in the cou_grp dataframe\ncou_grp['Active Cases']= cou_grp['Confirmed']- cou_grp['Recovered']- cou_grp['Deaths']\n\n# applying and adding coumns for log transformation to 'Confirmed' and 'Active' columns in the cou_grp dataframe to initiate the removal of skewness in them if any.\ncou_grp['log_confirmed']= np.log(cou_grp['Confirmed'])\ncou_grp['log_active']= np.log(cou_grp['Active Cases'])\n\ncou_grp.head(2)","bcfddce4":"# Creating a temporary dataframe by grouping different types of cases present in the new dataframe as per date and aggregating with 'Confirmed', 'Recovered' and 'Deaths' cases\n\ndate_wise= df1.groupby(['ObservationDate']).agg({\n                            \"Confirmed\": 'sum',\n                            \"Recovered\": 'sum',\n                            \"Deaths\": 'sum'})\n\n#Adding a column 'Days Since' in 'date_wise' dataframe to keep the count of the days from initial date\n\ndate_wise['Days Since']= date_wise.index- date_wise.index.min()\n\ndate_wise.head(2)","f7a7faed":"print(\"No. of Countries suffering: \",len(df1['Country\/Region'].unique()))\nprint(\"Total Confirmed Cases worldwide:  \",date_wise['Confirmed'].iloc[-1])\nprint(\"Total Recovered Cases worldwide:  \",date_wise['Recovered'].iloc[-1])\nprint(\"Total Death Cases worldwide:  \",date_wise['Deaths'].iloc[-1])\n#print(\"Total Active Cases worldwide:  \",(date_wise['Confirmed']- date_wise['Recovered']- date_wise['Deaths'])\n#print(\"Total Closed Cases worldwide:  \",date_wise['Recovered'] + date_wise['Deaths'])\n\n\n\nprint(\"Confirmed Cases\/Day worldwide: \",np.round(date_wise['Confirmed'].iloc[-1]\/date_wise.shape[0]))\nprint(\"Recovered Cases\/Day worldwide: \",np.round(date_wise['Recovered'].iloc[-1]\/date_wise.shape[0]))\nprint(\"Deaths Cases\/Day worldwide: \",np.round(date_wise['Deaths'].iloc[-1]\/date_wise.shape[0]))\n\n\nprint(\"Confirmed Cases\/Hour worldwide: \",np.round(date_wise['Confirmed'].iloc[-1]\/date_wise.shape[0]*24))\nprint(\"Recovered Cases\/Hour worldwide: \",np.round(date_wise['Recovered'].iloc[-1]\/date_wise.shape[0]*24))\nprint(\"Death Cases\/Hour worldwide: \",np.round(date_wise['Deaths'].iloc[-1]\/date_wise.shape[0]*24))\n\n\nprint(\"Confirmed Cases in last 24 hrs: \",date_wise['Confirmed'].iloc[-1]-date_wise['Confirmed'].iloc[-2])\nprint(\"Recovered Cases in last 24 hrs: \",date_wise['Recovered'].iloc[-1]-date_wise['Recovered'].iloc[-2])\nprint(\"Death Cases in last 24 hrs: \",date_wise['Deaths'].iloc[-1]-date_wise['Deaths'].iloc[-2])","99c6b5ae":"# Distribution of Number of Active Cases\n\nfig= px.bar(x=date_wise.index, y=date_wise[\"Confirmed\"]- date_wise[\"Recovered\"]- date_wise[\"Deaths\"])\nfig.update_layout(title=\"Distribution of number of Active cases\", xaxis_title=\"Date\", yaxis_title=\"Number of Cases\")\nfig.show()","d04d90e0":"# Distribution of number of Closed cases\n\nfig= px.bar(x= date_wise.index, y= date_wise['Recovered']+ date_wise['Deaths'])\nfig.update_layout(title=\" Distribution of number of Closed Cases\", xaxis_title=\"Date\", yaxis_title=\"Number of Cases\")\nfig.show()","290a1b6c":"# Weekly Growth of Different types of cases(Recovered, Confirmed, Deaths)\n\n\ndate_wise[\"WeekOfYear\"]= date_wise.index.weekofyear\n\nweek_num=[]\nweek_wise_confirmed= []\nweek_wise_recovered= []\nweek_wise_deaths= []\n\nw=1\n\nfor i in list(date_wise[\"WeekOfYear\"].unique()):\n                        week_wise_confirmed.append(date_wise[date_wise['WeekOfYear']==i][\"Confirmed\"].iloc[-1])\n                        week_wise_recovered.append(date_wise[date_wise['WeekOfYear']==i][\"Recovered\"].iloc[-1])\n                        week_wise_deaths.append(date_wise[date_wise['WeekOfYear']==i][\"Deaths\"].iloc[-1])\n                        week_num.append(w)\n                        w+=1\n\nfig= go.Figure()\nfig.add_trace(go.Scatter(x= week_num, y= week_wise_confirmed, mode='lines+markers', name= 'Weekly Growth of Confirmed cases'))\nfig.add_trace(go.Scatter(x= week_num, y= week_wise_recovered, mode='lines+markers', name= 'Weekly Growth of Recovered cases'))\nfig.add_trace(go.Scatter(x= week_num, y= week_wise_deaths, mode='lines+markers', name= 'Weekly Growth of Death cases'))\n\nfig.update_layout(title=\"Weekly Growth of Different types of Cases worldwide \", xaxis_title='Week Number', yaxis_title='Number of Cases', legend= dict(x=0, y=1, traceorder='normal'))\nfig.show()                                                   \n                 ","d2413e6e":"# Weekly variation of confirmed and Death cases\n\nfig, (ax1, ax2)= plt.subplots(1,2, figsize=(15,5))\n\nsns.barplot(x= week_num, y= pd.Series(week_wise_confirmed).diff().fillna(0), ax= ax1)\nsns.barplot(x= week_num, y= pd.Series(week_wise_deaths).diff().fillna(0), ax= ax2)\\\n\nax1.set_xlabel(\"Week Number\")\nax1.set_ylabel(\"Number of Confirmed Cases\")\nax1.set_title(\"Weekly variation in number of Confirmed cases\")\n\nax2.set_xlabel(\"Week Number\")\nax2.set_ylabel(\"Number of Death Cases\")\nax2.set_title(\"Weekly variation in number of Death cases\")\n","96bc4d6f":"# Growth of different types of the cases( Confirmed, Recovered, Deaths)\n\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Confirmed'], mode='lines+markers', name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Recovered'], mode='lines+markers', name='Recovered Cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Deaths'], mode='lines+markers', name='Death Cases'))\n\nfig.update_layout(title=\" Growth of Different types of cases\", xaxis_title=\"Date\", yaxis_title=\"Number of Cases\", legend= dict(x=0, y=1, traceorder=\"normal\"))\nfig.show()","5452c5b5":"# Calculation of Mortality Rate and Recovery Rate\n\ndate_wise['Mortality Rate']= (date_wise['Deaths']\/date_wise['Confirmed'])*100\ndate_wise['Recovery Rate']= (date_wise['Recovered']\/date_wise['Confirmed'])*100\ndate_wise['Active Cases']= date_wise['Confirmed']- date_wise['Recovered']- date_wise['Deaths']\ndate_wise['Closed Cases']= date_wise['Recovered']+ date_wise['Deaths']\n\nprint(\"Average Mortality Rate :\", date_wise['Mortality Rate'].mean())\nprint(\"Median Mortality Rate :\", date_wise['Mortality Rate'].median())\nprint(\"Average Recovery Rate :\", date_wise['Recovery Rate'].mean())\nprint(\"Median Recovery Rate :\", date_wise['Recovery Rate'].median())\n\n# Plotting Mortality and Recoevry Rate\n\nfig= make_subplots(rows=2, cols=1, subplot_titles=(\"Recovery Rate\", \"Mortality Rate\"))\n\nfig.add_trace(\n    go.Scatter(x=date_wise.index, y=(date_wise[\"Recovered\"]\/date_wise[\"Confirmed\"])*100,name=\"Recovery Rate\"),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(x=date_wise.index, y=(date_wise[\"Deaths\"]\/date_wise[\"Confirmed\"])*100,name=\"Mortality Rate\"),\n    row=2, col=1\n)\n\nfig.update_layout(height=1000, legend=dict(x=0, y=1, traceorder='normal'))\nfig.update_xaxes(title_text=\"Date\", row=1, col=1)\nfig.update_yaxes(title_text=\"Recovery Rate\", row=1, col=1)\nfig.update_xaxes(title_text=\"Date\", row=1, col=2)\nfig.update_yaxes(title_text=\"Mortality Rate\", row=1, col=2)\nfig.show()","f2478aea":"# Daily variation of different types (Recovered, Confirmed, Deaths) of cases\n\nprint(\"Average Daily increase in number of Confirmed Cases: \", np.round(date_wise['Confirmed'].diff().fillna(0).mean()))\nprint(\"Average Daily increase in number of Recovered Cases: \", np.round(date_wise['Recovered'].diff().fillna(0).mean()))\nprint(\"Average Daily increase in number of Death Cases: \", np.round(date_wise['Deaths'].diff().fillna(0).mean()))\n\nfig= go.Figure()\nfig.add_trace(go.Scatter(x=date_wise.index, y= date_wise['Confirmed'].diff().fillna(0), mode='lines+markers', name='Confirmed cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y= date_wise['Recovered'].diff().fillna(0), mode='lines+markers', name='Recovered cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y= date_wise['Deaths'].diff().fillna(0), mode='lines+markers', name='Death cases'))\n\nfig.update_layout(title='Daily variattion of different types (Recovered, Confirmed, Deaths) of cases', xaxis_title='Date', yaxis_title='Number of Cases', legend= dict(x=0,y=1, traceorder= 'normal'))\nfig.show()","0f259c33":"\n\nfig= go.Figure()\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Confirmed'].diff().rolling(window=7).mean(), mode='lines+markers', name='Confirmed cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Recovered'].diff().rolling(window=7).mean(), mode='lines+markers', name='Recovered cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y=date_wise['Deaths'].diff().rolling(window=7).mean(), mode='lines+markers', name='Death cases'))\n\nfig.update_layout(title='7 days rolling Mean of daily Increase of Confirmed, Recovered and Death Cases', xaxis_title='Date', yaxis_title='Number of Cases', legend=dict(x=0,y=1, traceorder='normal'))\nfig.show()","42e68972":"# Datewise Growth Factor of Active and Closed Cases\n\nfig= go.Figure()\nfig.add_trace(go.Scatter(x=date_wise.index, y=(date_wise['Confirmed']-date_wise['Recovered']- date_wise['Deaths'])\/(date_wise['Confirmed']-date_wise['Recovered']- date_wise['Deaths']).shift(), mode='lines', name=' Growth factor of Active cases'))\nfig.add_trace(go.Scatter(x=date_wise.index, y=(date_wise['Recovered']+ date_wise['Deaths'])\/(date_wise['Recovered']+date_wise['Deaths']).shift(), mode='lines', name=' Growth factor of Closed cases'))\n\nfig.update_layout(title='Datewise Growth Factor of Active and Closed Cases', xaxis_title='Date', yaxis_title='Growth Factor', legend=dict(x=0,y=1, traceorder='normal'))\nfig.show()","8c855571":"# Calculation of Countrywise mortality and recovery rate\n\ncountry_wise= df1[df1['ObservationDate']== df1['ObservationDate'].max()].groupby(['Country\/Region']).agg({\n    \"Confirmed\": 'sum',\n    \"Recovered\": 'sum',\n    \"Deaths\": 'sum'\n}).sort_values(['Confirmed'], ascending= False)\n\n# adding two more columns to the country_wise dataframe named 'Mortality' and 'Recovery' which will be keeping the values of Recovery and Mortality rate.\n\ncountry_wise['Mortality']= (country_wise['Deaths']\/country_wise['Confirmed'])*100\ncountry_wise['Recovery']= (country_wise['Recovered']\/country_wise['Confirmed'])*100","74543258":"country_wise_last_24_confirmed=[]\ncountry_wise_last_24_recovered=[]\ncountry_wise_last_24_deaths=[]\n\nfor country in country_wise.index:\n    country_wise_last_24_confirmed.append((cou_grp.loc[country].iloc[-1]- cou_grp.loc[country].iloc[-2])['Confirmed'])\n    country_wise_last_24_recovered.append((cou_grp.loc[country].iloc[-1]- cou_grp.loc[country].iloc[-2])['Recovered'])\n    country_wise_last_24_deaths.append((cou_grp.loc[country].iloc[-1]- cou_grp.loc[country].iloc[-2])['Deaths'])","f3514431":"last_day_country_wise= pd.DataFrame(list(zip(country_wise.index, country_wise_last_24_confirmed, country_wise_last_24_recovered, country_wise_last_24_deaths)),\n                                    columns=[\"Country Name\", \"Last 24 Hours Confirmed\", \"Last 24 Hours Recovered\", \"Last 24 Hours Deaths\"])","14ec81e5":"top_15_confirmed_last24= last_day_country_wise.sort_values(['Last 24 Hours Confirmed'], ascending= False).head(15)\ntop_15_recovered_last24= last_day_country_wise.sort_values(['Last 24 Hours Recovered'], ascending= False).head(15)\ntop_15_deaths_last24= last_day_country_wise.sort_values(['Last 24 Hours Deaths'], ascending= False).head(15)\n\n\nfig, (ax1, ax2, ax3)= plt.subplots(3,1, figsize=(10,20))\n\nsns.barplot(x= top_15_confirmed_last24['Last 24 Hours Confirmed'], y=top_15_confirmed_last24['Country Name'], ax= ax1)\nax1.set_title(\"Top 15 Countries with highest number of confirmed cases in last 24 hours\")\n\nsns.barplot(x= top_15_recovered_last24['Last 24 Hours Recovered'], y=top_15_recovered_last24['Country Name'], ax= ax2)\nax2.set_title(\"Top 15 Countries with highest number of Recovered cases in last 24 hours\")\n\nsns.barplot(x= top_15_deaths_last24['Last 24 Hours Deaths'], y=top_15_deaths_last24['Country Name'], ax= ax3)\nax3.set_title(\"Top 15 Countries with highest number of Death cases in last 24 hours\")","dc95204c":"# Proportion of countries in confirmed, recovered and death cases\n\nlast_day_country_wise['Proportion got Confirmed']= (last_day_country_wise['Last 24 Hours Confirmed']\/(date_wise['Confirmed'].iloc[-1]- date_wise['Confirmed'].iloc[-2]))*100\nlast_day_country_wise['Proportion got Recovered']= (last_day_country_wise['Last 24 Hours Recovered']\/(date_wise['Recovered'].iloc[-1]- date_wise['Recovered'].iloc[-2]))*100\nlast_day_country_wise['Proportion got dead']= (last_day_country_wise['Last 24 Hours Deaths']\/(date_wise['Deaths'].iloc[-1]- date_wise['Deaths'].iloc[-2]))*100\n\n\nlast_day_country_wise[['Country Name', 'Proportion got Confirmed', 'Proportion got Recovered', 'Proportion got dead']].sort_values(['Proportion got Confirmed', 'Proportion got Recovered', 'Proportion got dead'], ascending= False).style.background_gradient(cmap=\"Reds\")","97acfe08":"# Top 15 Countries as per number of confirmed and death cases\n\nfig, (ax1, ax2)= plt.subplots(2,1, figsize=(10,12))\n\ntop_15_countries_confirmed= country_wise.sort_values(['Confirmed'], ascending= False).head(15)\ntop_15_countries_deaths= country_wise.sort_values(['Deaths'], ascending= False).head(15)\n\nsns.barplot(x= top_15_countries_confirmed['Confirmed'], y= top_15_countries_confirmed.index, ax=ax1)\nsns.barplot(x= top_15_countries_deaths['Deaths'], y= top_15_countries_deaths.index, ax=ax2)\n\nax1.set_title(\"Top 15 countries as per no. of Confirmed Cases\")\nax2.set_title(\"Top 15 countries as per no. of Death Cases\")","5cdf8cea":"# Top 10 Countries as per Mortality and Recovery Rate with more than 1000 Confirmed cases\n\nfig, (ax1, ax2)= plt.subplots(2,1, figsize=(10,15))\n\nmortality_country_wise= country_wise[country_wise['Confirmed']>1000].sort_values(['Mortality'], ascending= False).head(10)\nrecovery_country_wise= country_wise[country_wise['Confirmed']>1000].sort_values(['Recovery'], ascending= False).head(10)\n\nsns.barplot(x= mortality_country_wise['Mortality'], y=mortality_country_wise.index, ax= ax1)\nsns.barplot(x= recovery_country_wise['Recovery'], y=recovery_country_wise.index, ax= ax2)\n\nax1.set_title(\"Top 10 Countries according to high Mortality Rate (Confirmed Cases > 1000)\")\nax2.set_title(\"Top 10 Countries according to high Recovery Rate (Confirmed Cases > 1000)\")\n\nax1.set_xlabel(\"Mortality (%)\")\nax2.set_xlabel(\"Recovery (%)\")\n","74f83447":"# Top 10 Countries as per Survival Probability\n\nfig, (ax1)= plt.subplots(1,1, figsize=(10,15))\n\ncountry_wise['Survival Probability']=(1-(country_wise['Deaths']\/country_wise['Confirmed']))*100\n\ntop_10_countries_sur_prob= country_wise[country_wise['Confirmed']> 1000].sort_values(['Survival Probability'], ascending=False).head(50)\n\nsns.barplot(x=top_10_countries_sur_prob['Survival Probability'], y=top_10_countries_sur_prob.index, ax=ax1)\nax1.set_title(\"Top 10 Countries with Maximum Survival Probability in % (Confirmed cases >1000)\")\n\nprint(\"Mean of Survival Probability: \", country_wise['Survival Probability'].mean())\nprint(\"Median of Survival Probability: \", country_wise['Survival Probability'].median())\nprint(\"Mean of Death Probability: \", 100-country_wise['Survival Probability'].mean())\nprint(\"Median of Death Probability: \", 100-country_wise['Survival Probability'].median())\n","75307b5b":"fig= go.Figure()\n\nfor country in country_wise.head(10).index:\n    fig.add_trace(go.Scatter(x=cou_grp.loc[country]['log_confirmed'], y= cou_grp.loc[country]['log_active'], mode='lines', name= country))\n    fig.update_layout(height=600, title='Transition of some worstly affected countries with Active vs Confirmed cases',\n                     xaxis_title='Confirmed Cases (Log Scale)', yaxis_title='Active Cases (log Scale)', legend= dict(x=0, y=1, traceorder='normal'))\n\nfig.show()","3def3b9c":"X= country_wise[['Mortality', 'Recovery']]\n\n# Preprocessing the data with standardisation and normalisation as KMeans Clustering works well with normalised data\nstd= StandardScaler()\nX= std.fit_transform(X)\n\n\nss=[]   # Initiating array for Sum of Squares\nsil=[]  # Initiating array for silhoutte scores\n\nfor i in range(2,11):\n    clf= KMeans(n_clusters=i, init='k-means++', random_state=42)\n    clf.fit(X)\n    labels= clf.labels_\n    centroids= clf.cluster_centers_\n    sil.append(silhouette_score(X, labels, metric=\"euclidean\"))\n    ss.append(clf.inertia_)\n    \nx= np.arange(2,11)\nplt.figure(figsize=(10,5))\nplt.plot(x, ss, marker='o')\nplt.xlabel('Number of Clusters')\nplt.ylabel(\"Within Cluster Sum of Squares\")\nplt.title(\"Elbow Curve\")\n","c154debc":"plt.figure(figsize=(20,15))\ndendogram= sch.dendrogram(sch.linkage(X, method=\"ward\"))","6692c82a":"# Taking k=3 for KMeans Clustering and observing the summary\n\nclf_fin= KMeans(n_clusters=3, init=\"k-means++\", random_state=6)\nclf_fin.fit(X)\n\ncountry_wise['Clusters']= clf_fin.predict(X)\n\n\n# Summary of Clustering\n\n\nsummary= pd.concat([country_wise[country_wise['Clusters']==1].head(10), country_wise[country_wise['Clusters']==2].head(10), country_wise[country_wise['Clusters']==0].head(10)])\nsummary.style.background_gradient(cmap='Reds').format(\"{:.2f}\")\n","b665a114":"# Statistical findings from Clusters\n\nprint(\"Average Mortality rate in Cluster 0: \", country_wise[country_wise['Clusters']==0]['Mortality'].mean())\nprint(\"Average Recovery rate in Cluster 0: \", country_wise[country_wise['Clusters']==0]['Recovery'].mean())\n\nprint(\"Average Mortality rate in Cluster 1: \", country_wise[country_wise['Clusters']==1]['Mortality'].mean())\nprint(\"Average Recovery rate in Cluster 1: \", country_wise[country_wise['Clusters']==1]['Recovery'].mean())\n\nprint(\"Average Mortality rate in Cluster 2: \", country_wise[country_wise['Clusters']==2]['Mortality'].mean())\nprint(\"Average Recovery rate in Cluster 2: \", country_wise[country_wise['Clusters']==2]['Recovery'].mean())","c71a228a":"# Observing it in  plot\n\nplt.figure(figsize=(10,5))\nsns.scatterplot(x= country_wise['Recovery'], y=country_wise['Mortality'], hue=country_wise['Clusters'], s=100)\n\nplt.axvline(((date_wise['Recovered']\/date_wise['Confirmed'])*100).mean(), color='green', linestyle=\"--\", label='Mean Recovery rate worldwide')\nplt.axhline(((date_wise['Deaths']\/date_wise['Confirmed'])*100).mean(), color='blue', linestyle=\"--\", label='Mean Mortality rate worldwide')\nplt.legend()","105ea643":"# Countries belonging to different clusters\n\nprint(\"Countries belong to Cluster (0): \", list(country_wise[country_wise['Clusters']==0].index))\nprint(\"Countries belong to Cluster (1): \", list(country_wise[country_wise['Clusters']==1].index))\nprint(\"Countries belong to Cluster (2): \", list(country_wise[country_wise['Clusters']==2].index))","b555ee5f":"data_india= df1[df1['Country\/Region']== 'India']\ndate_wise_india= data_india.groupby(['ObservationDate']).agg({\"Confirmed\": 'sum', \"Recovered\":'sum', \"Deaths\": 'sum'})\n\nprint(date_wise_india.iloc[-1])\n\nprint(\"Total Active Cases: \", date_wise_india['Confirmed'].iloc[-1]-date_wise_india['Recovered'].iloc[-1]- date_wise_india['Deaths'].iloc[-1])\nprint(\"Total Closed Cases: \", date_wise_india['Recovered'].iloc[-1]+ date_wise_india['Deaths'].iloc[-1])","fd5f0b92":"# Growth of different types of cases in India\n\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x= date_wise_india.index, y=date_wise_india['Confirmed'], mode='lines+markers', name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x= date_wise_india.index, y=date_wise_india['Recovered'], mode='lines+markers', name='Recovered Cases'))\nfig.add_trace(go.Scatter(x= date_wise_india.index, y=date_wise_india['Deaths'], mode='lines+markers', name='Death Cases'))\n\nfig.update_layout(title='Growth of different types of cases in India', xaxis_title='Date', yaxis_title='Number of Cases', legend=dict(x=0, y=1, traceorder='normal'))\nfig.show()","b9354403":"# Distribution of Active Cases in India\n\nfig= px.bar(x= date_wise_india.index, y= date_wise_india['Confirmed']- date_wise_india['Recovered']- date_wise_india['Deaths'])\nfig.update_layout(title='Distribution of Active Cases in India', xaxis_title='Date', yaxis_title='Number of Cases')\nfig.show()","b48d2f8d":"# Datewise Growth factors of different cases in India\n\nind_confirm_inc=[]\nind_recover_inc=[]\nind_death_inc=[]\n\nfor i in range(date_wise_india.shape[0]-1):\n    ind_confirm_inc.append(((date_wise_india['Confirmed'].iloc[i+1])\/date_wise_india['Confirmed'].iloc[i]))\n    ind_recover_inc.append(((date_wise_india['Recovered'].iloc[i+1])\/date_wise_india['Recovered'].iloc[i]))\n    ind_death_inc.append(((date_wise_india['Deaths'].iloc[i+1])\/date_wise_india['Deaths'].iloc[i]))\n    \n    \nind_confirm_inc.insert(0,1)\nind_recover_inc.insert(0,1)\nind_death_inc.insert(0,1)\n\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x=date_wise_india.index, y= ind_confirm_inc, mode='lines', name='Growth of Confirmed Cases'))\nfig.add_trace(go.Scatter(x=date_wise_india.index, y= ind_recover_inc, mode='lines', name='Growth of Recovered Cases'))\nfig.add_trace(go.Scatter(x=date_wise_india.index, y= ind_death_inc, mode='lines', name='Growth of Death Cases'))\n\n\nfig.update_layout(title='Datewise Growth Factor of different types cases in India', xaxis_title='Date', yaxis_title='Growth Factor', legend= dict(x=0, y=1, traceorder='normal'))\nfig.show()","5bd55ad8":"# Daily increase in Different types of cases in India\n\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x= date_wise_india.index, y= date_wise_india['Confirmed'].diff().fillna(0), mode= 'lines+markers', name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x= date_wise_india.index, y= date_wise_india['Recovered'].diff().fillna(0), mode= 'lines+markers', name='Recovered Cases'))\nfig.add_trace(go.Scatter(x= date_wise_india.index, y= date_wise_india['Deaths'].diff().fillna(0), mode= 'lines+markers', name='Death Cases'))\n\nfig.update_layout(title='Daily Variation of Different types of cases in India', xaxis_title='Dates', yaxis_title='Number of Cases', legend= dict(x=0, y=1, traceorder='normal'))\nfig.show()","6c6d4e78":"# India's week wisie variatioin in confirmed and death cases\n\ndate_wise_india['WeekOfYear']= date_wise_india.index.weekofyear\n\n\nweek_num_india=[]\n\nind_confirm_weekwise=[]\nind_recover_weekwise=[]\nind_death_weekwise=[]\nw=1\n\nfor i in list(date_wise_india['WeekOfYear'].unique()):\n    ind_confirm_weekwise.append(date_wise_india[date_wise_india['WeekOfYear']==i]['Confirmed'].iloc[-1])\n    ind_recover_weekwise.append(date_wise_india[date_wise_india['WeekOfYear']==i]['Recovered'].iloc[-1])\n    ind_death_weekwise.append(date_wise_india[date_wise_india['WeekOfYear']==i]['Deaths'].iloc[-1])\n    week_num_india.append(w)\n    w+=1\n    \n\nfig, (ax1, ax2)= plt.subplots(1,2, figsize=(15,5))\n\nsns.barplot(x=week_num_india, y= pd.Series(ind_confirm_weekwise).diff().fillna(0), ax= ax1)\nsns.barplot(x=week_num_india, y= pd.Series(ind_death_weekwise).diff().fillna(0), ax= ax2)\n\nax1.set_xlabel(\"Week Number\")\nax2.set_xlabel(\"Week Number\")\n\nax1.set_ylabel(\"Number of Confirmed Cases\")\nax2.set_ylabel(\"Number of Death Casses\")\n\nax1.set_title(\"India's week wise variatioin in Confirmed cases\")\nax2.set_title(\"India's week wise variatioin in Death cases\")","7ed517fb":"# Data Preprocessing\n\ndate_wise['Days Since']= date_wise.index- date_wise.index[0]\ndate_wise['Days Since']= date_wise['Days Since'].dt.days\n\nmodel_scores=[]\n\ntrain_set= date_wise.iloc[:int(date_wise.shape[0]*0.95)]\ntest_set= date_wise.iloc[int(date_wise.shape[0]*0.95):]\n\n# Standardisation of training dataset\n\nX_train= np.array(train_set['Days Since']).reshape(-1,1)\ny_train= np.array(train_set['Confirmed']).reshape(-1,1)\nX_test= np.array(test_set['Days Since']).reshape(-1,1)\ny_test= np.array(test_set['Confirmed'])\n\n\n# Instantiating Linear Regression model\n\nlin_reg= LinearRegression(normalize=True)\n\n# fitting the model to the training set\n\nlin_reg.fit(X_train, y_train)\n\n# Predicting the model with test dataset\n\ny_pred= lin_reg.predict(X_test)\n\n# Model accuracy metrics\n\nmodel_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n\nprint(\"RMSE for Linear Regression: \",np.sqrt(mean_squared_error(y_test, y_pred)))","51a3ace5":"# Prediction plot for Confirmed Cases by Linear Regression Model\n\nlin_reg_output=[]\n\ny_pred_date_wise= lin_reg.predict(np.array(date_wise['Days Since']).reshape(-1,1))\nfor i in range(y_pred_date_wise.shape[0]):\n    lin_reg_output.append(y_pred_date_wise[i][0])\n    \nplt.figure(figsize=(10,5))\n\nfig= go.Figure()\nfig.add_trace(go.Scatter(x= date_wise.index, y=date_wise['Confirmed'], mode='lines', name='Actual Confirmed Cases'))\nfig.add_trace(go.Scatter(x= date_wise.index, y=lin_reg_output, mode='lines+markers', name='Predicted Confirmed Cases'))\n\nfig.update_layout(title='Prediction plot for Confirmed Cases by Linear Regression Model', xaxis_title='Date', yaxis_title='No. of Confirmed Cases', legend= dict(x=0, y=1, traceorder='normal'))\n\nfig.show()","d3f846ca":"# Adding polynomial features to the model\n\npoly= PolynomialFeatures(degree=7)\n\nX_train_poly= poly.fit_transform(X_train)\ny_train_poly= train_set['Confirmed']\nX_test_poly= poly.fit_transform(X_test)\ny_test_poly= test_set['Confirmed']\n\n# Instantiating the Polynomial Regression Model\n\npoly_lin_reg= LinearRegression(normalize= True)\n\n# Fitting the model to the training data\n\npoly_lin_reg.fit(X_train_poly, y_train_poly)\n\n# Predicting the model on the test data\n\ny_pred_poly= poly_lin_reg.predict(X_test_poly)\n\n# Model Accuracy through RSME\n\nrmse_poly= np.sqrt(mean_squared_error(y_test_poly, y_pred_poly))\n\nmodel_scores.append(rmse_poly)\n\nprint(\"RMSE for Polynomial Regression: \", rmse_poly)\n","46c5eed5":"# Prediction Plot for by Polynomial Regression Model\n\nX_test_poly_datewise= poly.fit_transform(np.array(date_wise['Days Since']).reshape(-1,1))\ny_pred_poly_datewise= poly_lin_reg.predict(X_test_poly_datewise)\n\nlin_reg_output=[]\n\ny_pred_date_wise= lin_reg.predict(np.array(date_wise['Days Since']).reshape(-1,1))\nfor i in range(y_pred_date_wise.shape[0]):\n    lin_reg_output.append(y_pred_date_wise[i][0])\nplt.figure(figsize=(10,5))\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x= date_wise.index, y= date_wise['Confirmed'], mode='lines', name=\"Actual Confirmed Cases\"))\nfig.add_trace(go.Scatter(x= date_wise.index, y= y_pred_poly_datewise, mode='lines+markers', name=\"Predicted Confirmed Cases\"))\n\nfig.update_layout(title='Prediction Plot for Confirmed Cases by Polynomial Regression Model', xaxis_title='Date', yaxis_title='No. of Confirmed Cases', legend= dict(x=0, y=1, traceorder='normal'))\nfig.show()","f79911eb":"# Instantiating the model\n\nsvm= SVR(C=1, degree=5, kernel='poly', epsilon=0.01)\n\n# Fitting the model to the training data\n\nsvm.fit(X_train, y_train)\n\n# Predicting the model with the test data\n\ny_pred_svm= svm.predict(X_test)\n\n# Model Accuracy through RSME metric\n\nrmse_svm= np.sqrt(mean_squared_error(y_test, y_pred_svm))\n\nmodel_scores.append(rmse_svm)\n\nprint(\"RSME for Support Vector Machine Model: \",rmse_svm)","51041cf9":"# Prediction Plot for Confirmed Cases by Support Vector Machine Model\n\ny_pred_svm_datewise= svm.predict(np.array(date_wise['Days Since']).reshape(-1,1))\n\nplt.figure(figsize=(10,5))\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x= date_wise.index, y=date_wise['Confirmed'], mode= 'lines', name='Actual Confirmed Cases'))\nfig.add_trace(go.Scatter(x= date_wise.index, y=y_pred_svm_datewise, mode='lines+markers', name='Predicted Confirmed Cases'))\nfig.update_layout(title='Prediction Plot for Confirmed Cases by Support Vector Machine Model', xaxis_title='Date',yaxis_title='No. of Confirmed Cases', legend= dict(x=0, y=1, traceorder='normal'))\nfig.show()","b376598a":"# Instantiating the model\n\nprophet_c= Prophet(interval_width=0.95, weekly_seasonality=True)\nprophet_confirmed= pd.DataFrame(zip(list(date_wise.index), list(date_wise['Confirmed'])), columns=['ds','y'])\n\n# Fitting the model to the data\n\nprophet_c.fit(prophet_confirmed)\n\n\nforecast_c= prophet_c.make_future_dataframe(periods=17)\nforecast_confirmed= forecast_c.copy()\n\n# Predicting with the model\n\nconfirmed_forecast= prophet_c.predict(forecast_c)\n\n# Model accuracy check through RMSE\n\nrmse_prophet= np.sqrt(mean_squared_error(date_wise['Confirmed'], confirmed_forecast['yhat'].head(date_wise.shape[0])))\n\nprint(\"RMSE for Facebook Prophets Model: \", rmse_prophet)\n\nmodel_scores.append(rmse_prophet)","d020ff85":"# Plot for forecast of Confirmed cases by Facebook Prophet Model.\n\nprint(prophet_c.plot(confirmed_forecast))","158eb109":"# Plot of components of Prophets model\n\nprint(prophet_c.plot_components(confirmed_forecast))","c22c9bba":"new_date=[]\n\nnew_pred_lr=[]\nnew_pred_poly=[]\nnew_pred_svm=[]\n\nfor i in range(1,25):\n    new_date.append(date_wise.index[-1]+ timedelta(days=i))\n    new_pred_lr.append(lin_reg.predict(np.array(date_wise['Days Since'].max()+i).reshape(-1,1))[0][0])\n    new_pred_svm.append(svm.predict(np.array(date_wise['Days Since'].max()+i).reshape(-1,1))[0])","fc417a60":"new_pred_prophet= list(confirmed_forecast['yhat'].tail(25))","1030ee0c":"pd.set_option('display.float_format', lambda x: '%.2f' %x)\n\nmodel_preds= pd.DataFrame(zip(new_date, new_pred_lr, new_pred_svm, new_pred_prophet), columns=['Dates', 'Linear Reg. Pred.', 'SVM Pred.', 'Facebook Prophet Pred.'])\nmodel_preds","84fc94f0":"mod_list=['Linear Regression','Polynomial Linear Regression', 'Support Vector Machine Regressor', 'Facebook Prophet Model']\nmod_summary= pd.DataFrame(zip(mod_list, model_scores), columns=[\"Model Name\", \"RMSE\"]).sort_values([\"RMSE\"])\nmod_summary","26bdaaf1":"# Reading the dataset\n\ndf2= pd.read_csv('..\/input\/corona-virus-report\/covid_19_clean_complete.csv', parse_dates=['Date'])\ndf2.head(5)","f4bb352b":"# Data Preprocessing and Cleaning\n\ncases= ['Confirmed', 'Recovered', 'Active', 'Deaths']\n\ndf2['Active']= df2['Confirmed']- df2['Recovered']- df2['Deaths']\n\n# Filling missing values\n\ndf2[['Province\/State']]= df2[['Province\/State']].fillna('')\ndf2[cases]= df2[cases].fillna(0)\n\n# Latest trends\n\ndf2_latest= df2[df2['Date']== max(df2['Date'])].reset_index()\ndf2_grouped= df2_latest.groupby('Country\/Region')['Confirmed', 'Recovered', 'Active', 'Deaths'].sum().reset_index()","830d4d9e":"df2_temp= df2_grouped.sort_values(by=['Confirmed', 'Recovered', 'Deaths', 'Active'], ascending=False)\ndf2_temp= df2_temp.reset_index(drop= True)\ndf2_temp.style.background_gradient(cmap='Reds')","7de3b006":"# Time Series plot to observe the spread\n\nfig= go.Figure()\n\nfig.add_trace(go.Scatter(x=df2.Date,\n                         y=df2['Confirmed'],\n                         name='Confirmed',\n                         line_color='orange',\n                         opacity=0.8))\n\nfig.add_trace(go.Scatter(x=df2.Date,\n                         y=df2['Recovered'],\n                         name='Recovered',\n                         line_color='blue',\n                         opacity=0.8))\n\nfig.add_trace(go.Scatter(x=df2.Date,\n                         y=df2['Deaths'],\n                         name='Deaths',\n                         line_color='green',\n                         opacity=0.8))\n\nfig.add_trace(go.Scatter(x=df2.Date,\n                         y=df2['Active'],\n                         name='Active',\n                         line_color='pink',\n                         opacity=0.8))\n\nfig.update_layout(title= 'Time Series for Confirmed, Recovered, Death and Active Cases', xaxis_rangeslider_visible= True)\nfig.show()","10b20d11":"# Progression of spread across the globe\n\ndf2_formatted= df2.groupby(['Date', 'Country\/Region'])['Confirmed', 'Recovered', 'Deaths'].max().reset_index()\ndf2_formatted['Date']= pd.to_datetime(df2_formatted['Date']).dt.strftime('%m-%d-%Y')\ndf2_formatted['size']= df2_formatted['Confirmed'].pow(0.3)\n\nfig= px.scatter_geo(df2_formatted, locations='Country\/Region',\n                    locationmode='country names',\n                    color='Confirmed', size='size',\n                    hover_name='Country\/Region',\n                    projection='natural earth',\n                    range_color= [0, max(df2_formatted['Confirmed'])+2],\n                    animation_frame='Date',\n                    title='Progression of spread of COVID-19')\n\nfig.update(layout_coloraxis_showscale= False)\nfig.show()","20be6752":"# defining small functions to convert the datatype of some of the features\n\ndef p2f(x):\n    \n    try:\n        return float(x.strip('%'))\/100\n    except:\n        return np.nan\n\ndef age2int(x):\n    \n    try:\n        return int(x)\n    except:\n        return np.nan\n\ndef fert2float(x):\n   \n    try:\n        return float(x)\n    except:\n        return np.nan\n\n# Reading the dataset for features like population, density, fertility rate, median age, urban population for modeling. \n\ndf_country = pd.read_csv(\"..\/input\/population-by-country-2020\/population_by_country_2020.csv\", converters={'Urban Pop %':p2f,\n                                                                                                             'Fert. Rate':fert2float,\n                                                                                                             'Med. Age':age2int})\ndf_country.rename(columns={'Country (or dependency)': 'Country\/Region',\n                             'Population (2020)' : 'Population',\n                             'Density (P\/Km\u00b2)' : 'Density',\n                             'Fert. Rate' : 'Fertility',\n                             'Med. Age' : \"Age\",\n                             'Urban Pop %' : 'Urban Percentage'}, inplace=True)\n\n\n\ndf_country['Country\/Region'] = df_country['Country\/Region'].replace('United States', 'US')\ndf_country = df_country[[\"Country\/Region\", \"Population\", \"Density\", \"Fertility\", \"Age\", \"Urban Percentage\"]]\n\ndf_country.head()\n","fe5d8545":"# Merging the above sub dataframe to our main 2nd dataframe\n\ndf2= pd.merge(df2, df_country, on='Country\/Region')","d831abc9":"# Reading the ICU-beds-per-Country data \n\ndf_icu= pd.read_csv('..\/input\/icu-beds-per-1000-individuals\/API_SH.MED.BEDS.ZS_DS2_en_csv_v2_887506.csv')\ndf_icu.head(5)","e33e6670":"# Checking for null values\n\ndf_icu.isnull().sum()","a9262304":"# Data Preprocessing and Cleaning\n\ndf_icu['Country Name']= df_icu['Country Name'].replace({\n                                                        'United States': 'US',\n                                                        'Russian Federation': 'Russia',\n                                                        'Iran, Islamic Rep.': 'Iran',\n                                                        'Egypt, Arab Rep.': 'Egypt',\n                                                        'Venezuela, RB': 'Venezuela',\n                                                        'Czechia': 'Czech Republic'})","14f5f2de":"df_icu_temp= pd.DataFrame()\ndf_icu_temp['Country\/Region']= df_icu['Country Name']\ndf_icu_temp['ICU']= np.nan\n\nfor year in range(1960, 2020):\n    df_year= df_icu[str(year)].dropna()\n    df_icu_temp['ICU'].loc[df_year.index]= df_year.values\n    \ndf_icu_temp.head(5)","0e93d2e5":"# Merging the ICU beds dataset to main 2nd dataframe.\n\ndf2= pd.merge(df2, df_icu_temp, on='Country\/Region')\ndf2.head(2)","570d7a4f":"df2['Province\/State']= df2['Province\/State'].fillna('')\n\ntemp= df2[[col for col in df2.columns if col!='Province\/State']]\n\ndf_temp= temp[temp['Date']== max(temp['Date'])].reset_index()\ndf_temp_grp= df_temp.groupby('Country\/Region')['ICU'].mean().reset_index()\n\nfig= px.choropleth(df_temp_grp, locations=\"Country\/Region\",\n                  locationmode='country names', color='ICU',\n                  hover_name='Country\/Region', range_color=[1,15],\n                  color_continuous_scale='algae',\n                  title='Ratio of ICU beds per 1000 peoples')\nfig.show()","21c564e1":"# Reading temperature dataset containing some other features like humidity, sunHour and wind speed.\n\ndf_temperature= pd.read_csv('..\/input\/temperature-dataframe\/temperature_dataframe.csv')\ndf_temperature.head(2)","46154c37":"# Data preprocessing and Cleaning\n\ndf_temperature['country']= df_temperature['country'].replace({'USA': 'US', 'UK': 'United Kingdom'})\ndf_temperature= df_temperature[['country','province','date', 'humidity','sunHour', 'tempC', 'windspeedKmph']].reset_index()\ndf_temperature.rename(columns={'country': 'Country\/Region',\n                               'province': 'Province\/State',\n                               'date': 'Date',\n                               'humidity': 'Humidity',\n                               'tempC': 'Temp. in Celcious',\n                               'windspeedKmph': 'Wind Speed in KMPH'}, inplace= True)\ndf_temperature['Date'] =pd.to_datetime(df_temperature['Date'])\ndf_temperature['Province\/State']= df_temperature['Province\/State'].fillna('')\ndf_temperature.drop(['index'], axis=1, inplace= True)\ndf_temperature.head()","43c468d2":"# Merging teh rest of the features to the main 2nd dataframe\n\ndf2= df2.merge(df_temperature, on=['Country\/Region', 'Date', 'Province\/State'], how='inner')\ndf2.head(2)","6f2791b1":"# Check if the data is updated\nprint(\"Dataset Description\")\nprint(\"Earliest Entry: \",df2['Date'].min())\nprint(\"Last Entry:     \",df2['Date'].max())\nprint(\"Total Days:     \",(df2['Date'].max() - df2['Date'].min()))","1770a1e9":"# Preparing the training set\n\ntrain= df2\ntrain.info()","bf34585b":"# Checking for null values\n\ntrain.isnull().sum()","16c024c8":"# Dealing with null values\n\ntrain.fillna(0, inplace= True)\ntrain.info()","36be927f":"# Filtering the training dataset above a threshold barrier of 0 i.e only using the values which are having Infected rate >0\n\nbarrier=0\ntrain['Infection Rate']= round(train['Confirmed']\/train['Population']*100,6)\ntrain= train[train['Infection Rate']>= barrier]\ntrain.info()","5ae97d4a":"# Further data- preprocessing\n\ntrain= train.drop(['Country\/Region', 'Province\/State', 'Date', 'Lat', 'Long', 'Active', 'Recovered', 'Infection Rate', 'WHO Region', 'Fertility'], axis=1).dropna()\ntrain.info()","d79e0c62":"# Preparing data for train test split\n\ny=train[['Confirmed','Deaths']]\nX=train.drop(['Confirmed','Deaths'], axis= 1)","3bf5924c":"y.shape","915f71ac":"X.shape","8cacc75e":"# Checking the correlation between all the features\n\nplt.figure(figsize=(20,10))\nsns.heatmap(train.corr(), annot= True)","07c3d9fd":"# Defining a function to calculate Root Mean Square Log Error\n\ndef rmsle(y_test, y_pred):\n    \n    return np.sqrt(mean_squared_log_error(y_test, y_pred))\n\n# Making the rsmle as scoring metric\n\nrmsle_scorer= make_scorer(rmsle)\n\n# Performing train-test split\n\nX_train,X_test,y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42, shuffle= True)\n\n# Instantiating the Decision Tree Regressor Model\n\ndt_reg= DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\n# Performing the cross validation on trained data for confirmed cases\nscores_for_confirmed_cases= cross_val_score(dt_reg, X_train, y_train['Confirmed'], cv=5, scoring=rmsle_scorer)\n\n# fitting the model to training data\n\ndt_reg.fit(X_train, y_train['Confirmed'])\n\n# Checking model accuracy by RMSLE as metric\nrmsle_dt_for_confirmed_cases= rmsle(y_test['Confirmed'], dt_reg.predict(X_test))\n\nprint(\"Validation of Confirmed Cases by RMSLE: \", rmsle_dt_for_confirmed_cases)\n\n# Performing the cross validation on trained data for death cases\nscores_for_death_cases= cross_val_score(dt_reg, X_train, y_train['Deaths'], cv=5, scoring=rmsle_scorer)\n\n# fitting the model to training data\n\ndt_reg.fit(X_train, y_train['Deaths'])\n\n# Checking model accuracy by RMSLE as metric\n\nrmsle_dt_for_death_cases= rmsle(y_test['Deaths'], dt_reg.predict(X_test))\nprint(\"Validation of Death Cases by RMSLE: \", rmsle_dt_for_death_cases)","f6ff0ea4":"dt_reg_confirmed= dt_reg.fit(X, y['Confirmed'])\ndt_reg_deaths= dt_reg.fit(X, y['Deaths'])\n\n# Defining a function to get the feature importance of various features \n\ndef feature_importance(dt):\n    importance= dt.feature_importances_\n    indices= np.argsort(importance)[::-1]\n    \n    plt.figure(figsize=(20,10))\n    plt.bar(range(X.shape[1]), importance[indices])\n    plt.xticks(range(X.shape[1]), X.columns[indices], rotation='vertical')\n    plt.show()","1be0b432":"# Feature importantce for Confirmed Cases\n\nfeature_importance(dt_reg_confirmed)","0fd4b119":"# Feature importance for Death cases\n\nfeature_importance(dt_reg_deaths)","ed0435c4":"# Dropping 'Wind Speed in KMPH' column from df2 dataframe.\n\ntrain= train.drop(['Wind Speed in KMPH'], axis=1).dropna()\ntrain.info()","c1e68eb8":"y=train[['Confirmed','Deaths']]\nX=train.drop(['Confirmed','Deaths'], axis= 1)","12d3a43c":"y.shape","d25ca6ae":"X.shape","6a6bd07f":"# Checking the correlation between all the features\n\nplt.figure(figsize=(20,10))\nsns.heatmap(train.corr(), annot= True)","5bb3d64a":"# Defining a function to calculate Root Mean Square Log Error\n\ndef rmsle(y_test, y_pred):\n    \n    return np.sqrt(mean_squared_log_error(y_test, y_pred))\n\n# Making the rsmle as scoring metric\n\nrmsle_scorer= make_scorer(rmsle)\n\n# Performing train-test split\n\nX_train,X_test,y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42, shuffle= True)\n\n# Instantiating the Decision Tree Regressor Model\n\ndt_reg= DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\n# Performing the cross validation on trained data for confirmed cases\nscores_for_confirmed_cases= cross_val_score(dt_reg, X_train, y_train['Confirmed'], cv=5, scoring=rmsle_scorer)\n\n# fitting the model to training data\n\ndt_reg.fit(X_train, y_train['Confirmed'])\n\n# Checking model accuracy by RMSLE as metric\nrmsle_dt_for_confirmed_cases= rmsle(y_test['Confirmed'], dt_reg.predict(X_test))\n\nprint(\"Validation of Confirmed Cases by RMSLE: \", rmsle_dt_for_confirmed_cases)\n\n# Performing the cross validation on trained data for death cases\nscores_for_death_cases= cross_val_score(dt_reg, X_train, y_train['Deaths'], cv=5, scoring=rmsle_scorer)\n\n# fitting the model to training data\n\ndt_reg.fit(X_train, y_train['Deaths'])\n\n# Checking model accuracy by RMSLE as metric\n\nrmsle_dt_for_death_cases= rmsle(y_test['Deaths'], dt_reg.predict(X_test))\nprint(\"Validation of Death Cases by RMSLE: \", rmsle_dt_for_death_cases)","080a2d77":"dt_reg_confirmed= dt_reg.fit(X, y['Confirmed'])\ndt_reg_deaths= dt_reg.fit(X, y['Deaths'])\n\n# Defining a function to get the feature importance of various features \n\ndef feature_importance(dt):\n    importance= dt.feature_importances_\n    indices= np.argsort(importance)[::-1]\n    \n    plt.figure(figsize=(20,10))\n    plt.bar(range(X.shape[1]), importance[indices])\n    plt.xticks(range(X.shape[1]), X.columns[indices], rotation='vertical')\n    plt.show()","e3e505da":"# Feature importantce for Confirmed Cases\n\nfeature_importance(dt_reg_confirmed)","6dc882e6":"# Feature importantce for Confirmed Cases\n\nfeature_importance(dt_reg_deaths)","f9cc25ce":"<h3>What could we do?<\/h3>","7d2743cf":"### Analysis of CoVID-19 using physical natural and man-made features","473d1e71":"__Comments:__\n\nIt seems the spread is much more than in the temperate zone of world compared to tropical zones and the drier parts of the world has lesser prone to transmission.","ea570fdd":"<h5>Distribution of number of Active cases worldwide<\/h5>","183ff958":"<h4>Modeling Phase<\/h4>","d690e781":"<h3>Introduction<\/h3>\n\nAn ongoing outbreak of pneumonia caused by a novel coronavirus, currently designated as the __Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2)__, was reported recently. However, as SARS-CoV-2 is an emerging virus, we know little about it. In late December 2019, a number of local health authorities reported clusters of patients with pneumonia of unknown cause, which were epidemiologically linked to a seafood market in Wuhan, Hubei Province, China. On 30 January 2020, the World Health Organization (WHO) declared that CoVID-19 is a __\u201cPublic-Health Emergency of International Concern\u201d__. The pathogen was identified by local hospitals using a surveillance mechanism for __\u201cPneumonia of Unknown Etiology\u201d__ that was established in the wake of the 2003 SARS outbreak with the aim of allowing timely identification of novel pathogens.\n\n\nDespite the current mortality rate is less as of now, the emergence of large number of infected patients within short period of time could result in the collapse of health care system, and thus the mortality rate might be elevated. Every virus has __Basic Reproduction number (R0)__ which implies how many people will get the disease from the infected person. If the value of R0 is greater than 1 then the disease probably continues to spread and if it is < 1 then the disease slowly dies down. Since COVID-19\u2019s R0 is > 2, so an average infected person spreads it to 2 or more people who again spread it to 2 or more people and that is how this infection continues to spread across the globe. There are other parameters in the model like and which needs to be estimated.\n\nCurrently the goal of all scientists around the world is to __\"Flatten the Curve\"__. SARS-CoV-2 currently has exponential growth rate around the world and flattening this growth typically implies even if the number of Confirmed Cases is increasing but the distribution of those cases should be over longer timestamp. To tackle the widespread, various countries are imposing Travel Ban, Cross-Border shutdown, ban on immigrants and are Testing, Contact Tracing and Quarantining the suscpectible cases.","4e3d6c8e":"<h5>Datewise Growth Factor of Active and Closed Cases worldwide<\/h5>","9877186e":"- <h4>Survival Probability<\/h4>","9256cafa":"<center><b>END<\/b><\/center>","7985efd9":"<h4>Data preprocessing and Cleaning<\/h4>","be8838fe":"__Comments:__\n\nIt can be clearly observed through the data that Linear Regression doest fit good to the datsets we have as the trends are not at all linear.","af33455f":"__Comments:__\n\nOne can observe from the above plot that the daily groth of confirmed cases are gradually increasing only but shows certain irregularity in its growth and this is amid the lockdown phase which is not a positive response.This shows people are not much frightened due to this pandemic as it has a low mortality rate and are continuing to disobey the strict imposition of rules and restriction.\n\nLooking at the plot for Recovered cases, it has shown positive response amid the increase of confirmed cases.It has significantly took a positive slope with reduced variations than confirmed cases is approaching the trend to confirmed cases which is a positive thing\n\nLastly, with the trend of Death cases, it gives a sense of relief that it's still keeping a constant growth rate and is not increasing.But, our sole aim should be to bring it to zero and for that we need to follow the norms strictly.","489254da":"- <h4>Facebook's Prophet Model<\/h4>","32905f28":"- <h4>Mortality and Recovery Rate Analysis<\/h4>","bea61166":"<h5>Transition of some worstly affected countries with Active vs Confirmed cases<\/h5>","c4836b91":"<h4>Loading and understanding 1st dataset of CoVID-19<\/h4>","7d410e89":"- <h4>Growth Factor Analysis<\/h4>","6cbfccaa":"## Analysis of India","be9c7c6a":"Clustering analysis can be done taking into consideration of various factors. Here we will consider the mortality and recovery rates as features. We majorly took these two factors for our analysis because both of these take into account our three important sub factors i.e Confirmed,Recovered and Death Cases\n","22dbc169":"Here's a link to a presentation made by me in the regard.Hope you find it interesting:\n\nhttps:\/\/github.com\/ikigai-aa\/SARS-CoV-2-Outbreak-Analysis\/blob\/master\/Presentation%20-%20COVID_19.pptx","ce2d0cc2":"__Comments:__\n\n\nActive cases= No. of Confirmed Cases - No. of Recovered Cases- No. of Death Cases\n\nSo, it can be indirectly inferred that increase in active cases means there is probably a drop in the number of recovered and death cases.","d6b191bc":"### Prediction using Machine Learning Models","65eb75d4":"- <h4>Trends of Confirmed, Recovered and Death Cases worldwide<\/h4>","15a91698":"<h5>Ratio of ICU beds per 1000 people worldwide<\/h5>","855e3c0c":"<h3>Objective<\/h3>\n\nThe main objective of this project are:\n\n- To study SARS-CoV-2 outbreak with the help of some basic visualizations\u2019 techniques. \n- To Perform predictions and Time Series forecasting in order to study the impact and spread of the SARS-CoV-2 in coming days.\n- To study some important factors that impact transmission rate of SARS-CoV-2 like Air Transmission, Relative humidity., Temperature.\n- To study the responses of countries to SARS-CoV-2 i.e. to classify the changes in the number of infections in different countries, hoping to find out the factors that affect the country's ability to respond to it.\n- To have a sensible study to classify the trend of the number of infected people under the influence of different factors, and then modify the policy according to the trend of the expected number of infected people.\n- To analyze Growth Factor & Inflection.\n- To have an Exploratory Data analysis, Forecasting and implementing the Machine Learning Models wherever needed.","04c386a1":"__Comments:__\n\nMortality Rate= (Number of Death cases\/ Number of Confirmed Cases)X100\nRecovery Rate= (Number of Recovered cases \/ Number of Confirmed cases)X100\n\nFrom the above graphs one can infer that the recovery rate has picked up after a significant rise from early April due to complete lockdowns followed by most of the countries which is a good sign and the mortality rate is maintaining to be in single digits (around 6) which is also a positive response and has shown improvement from early May.","c7b83b00":"<center><b>-- Stay Home & Stay Safe --<\/b><\/center>","9cd8504d":"<h4>Prediction by COVID-19 cases by different Machine Learning Models<\/h4>","9c2f52ee":"__Comments:__\n\nLooking at the graph for weekly variation in death cases, one can infer that the death toll got decreased at Week no. 14 and from Week 15 onwards, there can be seen a dip in the number of cases.The considerable decrease in death cases has somehow motivated us.\n\nLooking at the variation of Confirmed cases(weekly), we can observe that there had been a dip during week 15 but then it is gradualy increasing. This may be due to relaxation of the lockdown but again there got a sharp decrease in the number of cases in week 20 which may be due to the partial imposition of curfew after office hours.","54142b51":"<h4>We will now look into the gradual changes in different cases of the transmission of Coronavirus worldwide using a 2nd dataframe.<\/h4>","c09d4e6c":"__Comments:__\n\nAs, it can be seen the Growth factor for all the different types of cases remains above 1 which is an indication that it's still in exponential groth phase but its relieving to observe that there is no uphill trend post March end and is lying close to 1 only throught the time period.","d1f1eef8":"__Comments:__\n\nCluster (0): Having Countries with low Mortality Rate and Considerably high Recovery rate. These are some countries which got badly affected but are recovering now with increasingly rate.\n\nCluster (1): Having countries with Low Mortality Rate and Moderate Recovery rate.These are some countries which are following the norms and guidlines strictly now.India is one of them. These all countries need to speed up the recovery rate.\n\nCLuster (2): Having countries with also low Mortality rate and Recovery rate between that of clusters 0 and 1.These countries need to speed up their recovery rate too.","9252fc9c":"<h4>Summary of Accuracy of different models with RMSE as metric:<\/h4>","62e6ba40":"- <h4>Polynomial Regression<\/h4>","4c0e3eb7":"<h5>Weekly Growth of Different types of cases (Recovered, Confirmed, Deaths) worldwide<\/h5>","889f3f93":"__Comments:__\n\nTaking a 7 day window somehow reduced the variability in cases but the trend still remain similar.We can observe a little dip in confirmed cases from early April till early may.This was the time when every country was following the norms strictly.But with advent of mid May, some countries lifted off the complete lockdowns norms and imposed only partial lockdowns as the economy met an 'Worldwide Economic Depression'.They needed to do something to revive it to some extent.This in an obvious practical sense created an uplift to the number of Confirmed cases through suspectible cases.\n\nRecovered cases follows similar trend as like the previous plot and is continuing to increase only in its trend which is a positive sign.\n\nHappy to see that the trend for death cases is taking a gradual dip after mid May and hope it continues to follow this trend only.","d3fbf05e":"__Comments:__\n\n\nClosed Cases= Number of Recovered cases + Number of Death Cases\n\nSo, Increase in number of closed cases also infer that more & more no. of pateints are getting recovered or more and more people are dying due to this virus.","b6e5bd18":"<h4>Importing neccessary libraries for effiecient analysis<\/h4>","d921bbbb":"__Comments:__\n\nFrom KMeans and Hierarchical Clustering techniques, we can accurately say that the suitable number of clusters for our modelling will be K=3.","7db6680a":"__Comments:__\n\nWe Observe different number of cases as prediction by different Machine Learning Models but the one with the minimum error was found to be by Facebook Prphet Model.Therefore we may take this model as our best prediction model and we can also look around with model if it gets us lower RMSE than  Facebook Prophets Model.","779ec213":"- <h4>Countrywise Mortality and Recovery Rate Analysis<\/h4>","ded072ed":"__Comments:__\n\nFrom this above graph one can infer that, most of the countries are following the trajectory similarly i.e. in uncontrolled Exponential Growth.Some of the countries like Spain, Italy, Germany, Turkey are starting to get control over it as we can see a dip of the curve for them. Countries like USA, Russia, UK are still in exponential growth.\n","ce67c7f1":"- <h4>Cluster Analysis<\/h4>","b274e6b9":"__Comments:__\n\nFrom the plot above we can see that many variables are positively correlated to the number of COVID19 infections such as: temperature, hours of sunlight, population, sunHour, wind speed, humidity, and age.\n\nIf we observe precisely, the more people there are in a country, the more likely they are to get infected. Also, is it possible, that older people are more likely to be infected. Weather conditions can help the virus to spread faster, such as temperature and humidity. It could be that the more hours of sunlight in a country, the more that people will want to be out and interact with social groups. The percentage of people living in an urban area also has some importance because it signifies a higher density of people, making it easier to transmit the virus.\n\nBut again looking into the graphs above, we see that wind speed has got highest feature importance which is I think not very much considerable if we take factors for COVID-19 into account. This is where we get into a type of correlation called \"Spurious Correlation\" where practically less important feature get upvoted in the modelling process. One solution to it could be dropping the feature.Hence, we now will drop \"Wind Speed in KMPH\" column from the dataframe, then again check the correlation and calculate the feature importance. ","3f00f401":"<h5>7 days rolling Mean of daily Increase of Confirmed, Recovered and Death Cases<\/h5>","bcfc773b":"Some of the features (Country wise)I have took under consideration area as follows:\n\n- Confirmed             \n- Deaths                \n- Population        \n- Avg Density(P\/Km\u00b2)               \n- Avg Fertility Rate            \n- Median Age                   \n- Avg Urban Percentage      \n- ICU beds per 1000 individuals                \n- Avg Humidity              \n- Avg sunHour               \n- Avg Temp. in Celcious     \n- Avg Wind Speed in KMPH","9a5e3aeb":"<h5>Weekly variation of confirmed and Death cases worldwide<\/h5>","5a2c3827":"Growth Factor: It is the factor by which the quantity multiplies itself over time.\n\nGrowth Factor= ( New day(Confirmed+Recovered+Deaths)\/Previous day(Confirmed+Recovered+Deaths)\n\nSome important info reagrding Growth factor:\n\n- Greater than 1 : increase in corresponding cases\n- Greater than 1 but trending downward: Positive Sign but it's still in exponential growth\n- Equalds to 1 : Contant and no change in any type of cases","b9166755":"Now, it seems to be correct.All features now are aligned in a practically possible scenario and we conclude that Temperature, Humidity, Population , Sun Hours are the most important features impacting the spread of Coronavirus.","e4d6d25c":"<center><h1>SARS-CoV-2 Outbreak Analysis<\/h1><\/center>","b133bbaa":"__Comments:__\n\nThis is a positive sign as almost all countries have Survival Probability of more than 95%.","ea612080":"- <h4>Linear Regression<\/h4>","60903c37":"<h4>Basic Information Extraction from 1st dataset<\/h4>","ab7cf004":"<h5>Distribution of number of Closed cases worldwide<\/h5>","8965bd11":"Since there is no vaccine available right now, the only way to handle the spread is to slow down the transmission. As it can be seen even in the under-estimates and from the actual data around us, the sharply increasing number of cases is bound to overwhelm the medical infrastructure of any nation. So, by slowing down the transmission, we don\u2019t actually stop the spread but keep the transmission and the active cases at any point in time well within the limits of the medical handling capacity. This is what is being referred to as \u201cFlattening The Curve\u201d. \n\n<h3>But How do we Flatten the Curve?<\/h3>\n\nSince the virus is being spread from one human to another, experts suggest three things that can help flatten the curve:\n\n1. Travel Restrictions \n\nIt is quite obvious that by restricting people from travelling in or out of a particular region, the transmission could be reduced.\n\n2. Social Distancing \n\nThis is what reduces transmission significantly. Now as we saw in the SIR modelling that COVID-19 has a high R0 and each infected person ends up infecting 2- 3 people and so on and so forth. So, maintaining social distance during these times will definitely help reduce the transmission from the infected to the others. Here is a very simple GIF that illustrates the impact of social distancing. \n\n3. More Testing\n\nThis is to quickly identify and isolate the infected from the non-infected. Given that Covid-19 has a long incubation period (symptoms start appearing after 5-7 days), a person does not even realize that he\/she is infected and, in the meantime may spread the infection too. To be able to do this, extensive testing is required. Doctors and medical staff need to be provided with safety equipment. Laboratories need to procure testing kits. Hospitals need to have ICUs and quarantine units in large numbers. Most of these are infrastructure problems at national and international levels. And therefore, the need to \u201cFlatten the Curve\u201d.\n\n","92136aff":"- <h4>Support Vector Machine<\/h4>"}}