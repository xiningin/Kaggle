{"cell_type":{"21bff949":"code","7a279561":"code","f3b9ac41":"code","edf63066":"code","b118b6b4":"code","c5616b83":"code","d860cc5a":"code","06b5bf02":"code","9d36003e":"code","5e01abce":"code","ff8b978d":"code","1ad73254":"code","30ff495a":"code","21de1558":"code","15a553c7":"code","0a848898":"code","15d56610":"code","68c952db":"code","8c30b31a":"code","3c82e4aa":"code","e7cf07f0":"code","c1c2d929":"code","224943ad":"code","4cd04bde":"code","ce3c916a":"code","9f5ab431":"code","687de02d":"code","a38c84c4":"code","4c56448a":"code","1fe30b0a":"code","2cb886bf":"code","be92edef":"code","a4246af9":"code","5e5e7c43":"code","13147277":"code","b136485a":"code","9ca33a21":"code","2c71f1e6":"code","9f38f118":"code","43335584":"code","a5dc0347":"code","db06ad8f":"code","22f3a0d2":"code","7dd3a0e9":"code","826040d6":"code","cad4bfed":"code","1f1b2a57":"code","5424223b":"code","9af84d3e":"code","854b5908":"code","8e28e75a":"code","ecec87db":"code","9eecb3d6":"code","00eca939":"code","a381fd4a":"code","92a870be":"code","1d8388b9":"code","a299c4bc":"code","e3c48d9d":"code","9729d900":"code","8840dd7b":"code","005d4ebf":"code","e91a2e46":"code","c92b4460":"code","94a617f7":"markdown","cc58dedb":"markdown","c00de59f":"markdown","d138e97a":"markdown","6b5061d8":"markdown","59248de9":"markdown","c5243216":"markdown","10748b83":"markdown","371cfffb":"markdown","22af4301":"markdown","0cad72dc":"markdown","2de13e3e":"markdown","02e47011":"markdown","2957a96a":"markdown","4635189f":"markdown","0e042bc2":"markdown","7e9e0a53":"markdown","f427927e":"markdown","2a3bded3":"markdown","596bdafb":"markdown","373643ca":"markdown","6d80af03":"markdown","ade311f4":"markdown","06f209c8":"markdown","6764f374":"markdown","dbe9a74e":"markdown","95f408aa":"markdown","7907b97f":"markdown","70fd4d68":"markdown","95707034":"markdown","a3d29dda":"markdown","91faa46f":"markdown","7507b621":"markdown","c42eba48":"markdown","cb32fdf7":"markdown","af9f0f27":"markdown","841fb80f":"markdown","746d8141":"markdown","677f7a1d":"markdown","bbf401a9":"markdown","c8f23dcc":"markdown","f9eefae1":"markdown","03436e11":"markdown","f375ee5c":"markdown","67261327":"markdown","50a68120":"markdown","4e8335e3":"markdown","12ac72af":"markdown","da298081":"markdown","f4bac7f5":"markdown","d72293a4":"markdown","5099e6eb":"markdown","49b22b6d":"markdown","9ce7dac4":"markdown","3059faa5":"markdown","81642786":"markdown","b2bdfbb0":"markdown","baeae180":"markdown","0ed44bc6":"markdown","7e83e167":"markdown","aa5bbe48":"markdown","ab6dc341":"markdown","e204581a":"markdown","dab8da81":"markdown","f1ee69cb":"markdown"},"source":{"21bff949":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tempfile\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a279561":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.image import imread\nimport cv2\n# Technically not necessary in newest versions of jupyter\n%matplotlib inline","f3b9ac41":"train = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/sample_submission.csv\")\ntrain_features = pd.read_csv(\"..\/input\/siimisicimagefeaturesextracted\/Image Features\/train_img_features.csv\")\ntest_features = pd.read_csv(\"..\/input\/siimisicimagefeaturesextracted\/Image Features\/test_img_features.csv\")","edf63066":"train_features = train_features.rename(columns={\"Unnamed: 0\" : \"image_name\"})","b118b6b4":"test_features = test_features.rename(columns={\"Unnamed: 0\" : \"image_name\"})","c5616b83":"train_features.head()","d860cc5a":"test_features.head()","06b5bf02":"train.head()","9d36003e":"train.shape","5e01abce":"train.info()","ff8b978d":"test.head()","1ad73254":"test.shape","30ff495a":"test.info()","21de1558":"path, dirs, files = next(os.walk(\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\"))\nfile_count = len(files)\nfile_count","15a553c7":"path, dirs, files = next(os.walk(\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\"))\nfile_count = len(files)\nfile_count","0a848898":"train['patient_id'].nunique()","15d56610":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.countplot(x='sex',data=train,ax=ax[0])\nax[0].set_xlabel(\" \")\nax[0].set_title(\"Gender counts in train set\")\n\nsns.countplot(x='sex',data=test,ax=ax[1])\nax[1].set_xlabel(\" \")\nax[1].set_title(\"Gender counts in test set\")","68c952db":"train[train['sex'].isnull() == True]['target'].value_counts()","8c30b31a":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.countplot(x='age_approx',data=train,ax=ax[0])\nax[0].set_xlabel(\" \")\nax[0].set_title(\"Age distribution in train set\")\n\nsns.countplot(x='age_approx',data=test,ax=ax[1])\nax[1].set_xlabel(\" \")\nax[1].set_title(\"Age distribution in test set\")","3c82e4aa":"temp_train = train.anatom_site_general_challenge.value_counts().sort_values(ascending=False)\ntemp_test = test.anatom_site_general_challenge.value_counts().sort_values(ascending=False)\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.barplot(x=temp_train.index.values, y=temp_train.values,ax=ax[0])\nax[0].set_xlabel(\" \")\nlabels = ax[0].get_xticklabels()\nax[0].set_xticklabels(labels, rotation=90)\nax[0].set_title(\"Image location in train set\")\n\nsns.barplot(x=temp_test.index.values, y=temp_test.values,ax=ax[1])\nax[1].set_xlabel(\" \")\nlabels = ax[1].get_xticklabels()\nax[1].set_xticklabels(labels, rotation=90)\nax[1].set_title(\"Image location in test set\")","e7cf07f0":"chart = sns.countplot(x='diagnosis', data = train)\nchart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')","c1c2d929":"sns.countplot(x='target',data=train)","224943ad":"sns.countplot(x='benign_malignant',data=train)","4cd04bde":"#Paths to train and test images\ntrain_img_path = '\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_img_path = '\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'","ce3c916a":"fig = plt.figure(figsize=(50, 50))\nfor i,idx in enumerate(np.random.choice(train[train['benign_malignant']=='benign'].index,8)):\n    img = cv2.imread(train_img_path+str(train.loc[idx,'image_name'])+'.jpg')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    fig.add_subplot(2, 4, i+1)\n    plt.imshow(img)\n    plt.title('Patient_id: '+train.loc[idx,'patient_id']+'\\n'\\\n              +'Site: '+str(train.loc[idx,'anatom_site_general_challenge'])+'\\n'\\\n              +'Sex: '+str(train.loc[idx,'sex'])+'\\n'\\\n              +'Approximate Age: '+str(train.loc[idx,'age_approx'])+'\\n'\\\n              +'Diagnosis: '+str(train.loc[idx,'diagnosis']),fontsize=30)\n    plt.axis(\"off\")\n    plt.tight_layout()","9f5ab431":"fig = plt.figure(figsize=(50, 50))\nfor i,idx in enumerate(np.random.choice(train[train['benign_malignant']=='malignant'].index,8)):\n    img = cv2.imread(train_img_path+str(train.loc[idx,'image_name'])+'.jpg')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    fig.add_subplot(2, 4, i+1)\n    plt.imshow(img)\n    plt.title('Patient_id: '+train.loc[idx,'patient_id']+'\\n'\\\n              +'Site: '+str(train.loc[idx,'anatom_site_general_challenge'])+'\\n'\\\n              +'Sex: '+str(train.loc[idx,'sex'])+'\\n'\\\n              +'Approximate Age: '+str(train.loc[idx,'age_approx'])+'\\n'\\\n              +'Diagnosis: '+str(train.loc[idx,'diagnosis']),fontsize=30)\n    plt.axis(\"off\")\n    plt.tight_layout()","687de02d":"fig = plt.figure(figsize=(50, 50))\nfor i,idx in enumerate(np.random.choice(test.index,8)):\n    img = cv2.imread(test_img_path+str(test.loc[idx,'image_name'])+'.jpg')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    fig.add_subplot(2, 4, i+1)\n    plt.imshow(img)\n    plt.title('Patient_id: '+test.loc[idx,'patient_id']+'\\n'\\\n              +'Site: '+str(test.loc[idx,'anatom_site_general_challenge'])+'\\n'\\\n              +'Sex: '+str(test.loc[idx,'sex'])+'\\n'\\\n              +'Approximate Age: '+str(test.loc[idx,'age_approx']),fontsize=30)\n    plt.axis(\"off\")\n    plt.tight_layout()","a38c84c4":"df = train[['image_name','sex', 'age_approx','anatom_site_general_challenge','target']]","4c56448a":"df = pd.merge(df, train_features, on='image_name')","1fe30b0a":"df.head()","2cb886bf":"df1 = test[['image_name','sex','age_approx','anatom_site_general_challenge']]","be92edef":"df1 = pd.merge(df1, test_features, on='image_name')","a4246af9":"df1.head()","5e5e7c43":"df = df.dropna(axis=0, subset=['sex'])","13147277":"sex = {\"male\":0, \"female\":1}\ndf['sex'] = df['sex'].map(sex)\ndf1['sex'] = df1['sex'].map(sex)","b136485a":"df['age_approx'].fillna(df['age_approx'].mean(), inplace=True)","9ca33a21":"df1['age_approx'].fillna(df1['age_approx'].mean(), inplace=True)","2c71f1e6":"df['anatom_site_general_challenge'].fillna('unknown', inplace=True)\ndf1['anatom_site_general_challenge'].fillna('unknown', inplace=True)\nimg_loc = {'head\/neck':1, 'upper extremity':2, 'lower extremity':3, 'torso':4, 'palms\/soles':5, 'oral\/genital':6, 'unknown':7}\ndf['anatom_site_general_challenge'] = df['anatom_site_general_challenge'].map(img_loc)\ndf1['anatom_site_general_challenge'] = df1['anatom_site_general_challenge'].map(img_loc)","9f38f118":"df = pd.get_dummies(df, columns=[\"sex\"])\ndf1 = pd.get_dummies(df1, columns=[\"sex\"])\ndf = pd.get_dummies(df, columns=[\"anatom_site_general_challenge\"])\ndf1 = pd.get_dummies(df1, columns=[\"anatom_site_general_challenge\"])","43335584":"df.head()","a5dc0347":"df1.head()","db06ad8f":"neg, pos = np.bincount(df['target'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","22f3a0d2":"X = df.drop(columns = ['target','image_name'], axis=1)\ny = df['target']\ndf_test = df1.drop(columns = ['image_name'],axis=1)","7dd3a0e9":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33, random_state=101)","826040d6":"from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN,BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.under_sampling import NearMiss \nfrom numpy import mean\nfrom imblearn.pipeline import Pipeline\nfrom collections import Counter\n# summarize class distribution\ncounter = Counter(y_train)\nprint(counter)\n# Oversample with SMOTE and random undersample for imbalanced dataset\nover = ADASYN()\n#under = RandomUnderSampler(sampling_strategy=0.5)\n#steps = [('o', over), ('u', under)]\n#pipeline = Pipeline(steps=steps)\nX_train, y_train= over.fit_resample(X_train, y_train)\n# summarize the new class distribution\ncounter = Counter(y_train)\nprint(counter)","cad4bfed":"X_train.shape","1f1b2a57":"X_test.shape","5424223b":"def learning_rate_010_decay_power_099(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_010_decay_power_0995(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_005_decay_power_099(current_iter):\n    base_learning_rate = 0.05\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3","9af84d3e":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparam_test ={'num_leaves': sp_randint(6, 50), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}","854b5908":"#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 100\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=True)","8e28e75a":"fit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_test,y_test)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}","ecec87db":"gs.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","9eecb3d6":"opt_parameters = {'colsample_bytree': 0.9023523372315546, \n                  'min_child_samples': 237, \n                  'min_child_weight': 0.01, \n                  'num_leaves': 39, \n                  'reg_alpha': 10, \n                  'reg_lambda': 0.1, \n                  'subsample': 0.7187028219151861}","00eca939":"clf_sw = lgb.LGBMClassifier(**clf.get_params())\n#set optimal parameters\nclf_sw.set_params(**opt_parameters)","a381fd4a":"gs_sample_weight = GridSearchCV(estimator=clf_sw, \n                                param_grid={'scale_pos_weight':[1,2,6,12]},\n                                scoring='roc_auc',\n                                cv=5,\n                                refit=True,\n                                verbose=True)","92a870be":"gs_sample_weight.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs_sample_weight.best_score_, gs_sample_weight.best_params_))","1d8388b9":"#Configure from the HP optimisation\nclf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n\n#Configure locally from hardcoded values\n#clf_final = lgb.LGBMClassifier(**clf.get_params())\n#set optimal parameters\nclf_final.set_params(**opt_parameters)\n\n#Train the final model with learning rate decay\nclf_final.fit(X_train, y_train, **fit_params, callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])","a299c4bc":"feat_imp = pd.Series(clf_final.feature_importances_, index=X.columns)\nfeat_imp.nlargest(20).plot(kind='barh', figsize=(8,10))","e3c48d9d":"from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score","9729d900":"#Prediction\ny_pred=clf_final.predict_proba(df_test)","8840dd7b":"y_pred = y_pred[:,1]","005d4ebf":"submission = pd.DataFrame({\n    \"image_name\": df1.image_name, \n    \"target\": y_pred\n})","e91a2e46":"submission.head()","c92b4460":"submission.to_csv('submission.csv', index=False)","94a617f7":"I will use **Adaptive Synthetic Sampling (ADASYN)** to increase the minority class. It is a type of **Synthetic Minority Oversampling Technique(SMOTE)** which generates more synthetic examples in regions of the feature space where the density of minority examples is low, and fewer or none where the density is high. More details of different types of SMOTE approaches can be found from the below link:-\n\nhttps:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/\n\nAfter applying ADASYN we can see that the samples belonging to target class 1 increased from 382 to 21754 in the X_train dataset. Also, SMOTE is applied only on the training set and not on the test set because we want to keep real data in test set.","cc58dedb":"Just like the train set I then displayed the first rows of the test set as shown below.","c00de59f":"* # Set up HyperParameter search\nWe use random search, which is more flexible and more efficient than a grid search","d138e97a":"From the train set I took the columns image_name, sex, age_approx, anatom_site_general_challenge and traget and created a new dataframe df. The columns diagnosis , bening_malignant won't be of any use. Hence, I didnot consider them for model building.","6b5061d8":"Now, lets make the X and y set. So, all the columns except the image_name and target will go to X. The target column would be our y set.","59248de9":"Next, the same set of steps were repeated for the test set and a dataset df1 was created. Note, that df1 has no target column as this would be added later after model's prediction.","c5243216":"# MODEL BUILDING\n","10748b83":"# MELANOMA CLASSIFICATION","371cfffb":"From, the test dataframe's info column it seems that the anatom_Site_general_challenge column has some null values.","22af4301":"Next I checked the count of images that we have in train and test set. The train set has 33126 images and test set has 10982 images.","0cad72dc":"* # Build the final model\nI used the tuned parameter values but a smaller learning rate to allow smoother convergence to the minimum.","2de13e3e":"The results after one hot encoding is shown below for both the dataframes df and df1.","02e47011":"Next I one hot encoded the columns sex and anatom_site_general_challenge as shown below for both the datasets df and df1.","2957a96a":"The Hyper parameter optimization using random search was run as shown below.","4635189f":"Next I calculated the percentage of target 1 records in the dataframe. It seems the target 1 records only forms 1.77% of the entire dataset. This hints that we have to resmaple and increase the target 1 records to prevent overfitting of the model to the target class 0.","0e042bc2":"People belonging to male gender is more in both train and test set. In test set male gender count is even more than in train set.","7e9e0a53":"**Now let's take a look at some malignant tumours from the train set.**","f427927e":"After merging the dataframe looks as shown below.","2a3bded3":"Now, its time build my model. I chose Light GBM Classifier to build my model.Light GBM is prefixed as \u2018Light\u2019 because of its high speed. Light GBM can handle the large size of data and takes lower memory to run. Another reason of why Light GBM is popular is because it focuses on accuracy of results. LGBM also supports GPU learning. \n\nIn this model I will also do hyper parameter tuning of LGBMClassifier with Random search followed by Grid Search. All of these are shown below. The implementation was referred from the below kernel:-\n\nhttps:\/\/www.kaggle.com\/mlisovyi\/lightgbm-hyperparameter-optimisation-lb-0-761\n","596bdafb":"# DATA PREPROCESSING","373643ca":"The optimal parameters from the search was saved in the dictionary opt_parameters.","6d80af03":"Next coming to the age_approx column I already highlighted during EDA that it has some null values so best thing to do would be to replace the null values with the mean age. This was done in both the dataframes df and df1.","ade311f4":"Next I made a count plot to check the age distribution in both train and test set.","06f209c8":"* # Some more tuning","6764f374":"Also, as shown above for 65 records in the training set we have sex as null. Also, the target values for those records are 0. Since, we have maximum images belonging to target 0 so we may drop these 65 records during our model building.","dbe9a74e":"The dataset used is under CC BY-NC 4.0 with the following attribution:\n\nThe ISIC 2020 Challenge Dataset https:\/\/doi.org\/10.34970\/2020-ds01 (c) by ISDIS, 2020\n\nCreative Commons Attribution-Non Commercial 4.0 International License.\n\nThe dataset was generated by the International Skin Imaging Collaboration (ISIC) and images are from the following sources: Hospital Cl\u00ednic de Barcelona, Medical University of Vienna, Memorial Sloan Kettering Cancer Center, Melanoma Institute Australia, The University of Queensland, and the University of Athens Medical School.\n\nYou should have received a copy of the license along with this work.\n\nIf not, see https:\/\/creativecommons.org\/licenses\/by-nc\/4.0\/legalcode.txt.","95f408aa":"Next, lets see what the diagnosis column of the train set has to tell us.","7907b97f":"From the above results it seems the train set has 43522 samples and test set has 10911 samples.","70fd4d68":"As already highlighted in my section EDA I dropped the 65 records which has null value in the sex column of the dataset df. This won't impact our model's performance much as the records having null values under the sex column belonged to target class 0. And as highlighted the taget class is highly imbalanced with maximum number of images belonging to target 0, so removing 65 records belonging to target 0 won't cause much impact.","95707034":"Next, let's analyze the columns **target** and **benign_malignant**. Both,the columns are providing the same message. Hence, during model building I will only use target. The column **benign_malignant** will be dropped.","a3d29dda":"Since, there is comparitively less number of malignat images so we will try resampling to increase the amount of malignat images during our data preprocessing.","91faa46f":"From both the count plots we can see that the dataset is highly imbalanced i.e we have very minimal number of images belonging to class malignant.","7507b621":"From the above results it can be seen that the columns sex,age_approx and anatom_site_general_challenge under the train dataframe have some null values. It would be interesting to see how we can deal with these missing values.","c42eba48":"# PREDICTIONS","cb32fdf7":"The sex column has 2 unique values **\"male\"** and **\"female\"**. Since, it is hard to make a model with text data so I converted the values to numeric with male replaced by 0 and female replaced by 1. This was done in both the dataframes df and df1.","af9f0f27":"* # Use test subset for early stopping criterion\nThis allows us to avoid overtraining and we do not need to optimise the number of trees","841fb80f":"Skin cancer is the most prevalent type of cancer. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020. It's also expected that almost 7,000 people will die from the disease. As with other cancers, early and accurate detection\u2014potentially aided by data science\u2014can make treatment more effective.\n\nCurrently, dermatologists evaluate every one of a patient's moles to identify outlier lesions or \u201cugly ducklings\u201d that are most likely to be melanoma. Existing AI approaches have not adequately considered this clinical frame of reference. Dermatologists could enhance their diagnostic accuracy if detection algorithms take into account \u201ccontextual\u201d images within the same patient to determine which images represent a melanoma. If successful, classifiers would be more accurate and could better support dermatological clinic work.\n\nAs the leading healthcare organization for informatics in medical imaging, the Society for Imaging Informatics in Medicine (SIIM)'s mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. SIIM is joined by the International Skin Imaging Collaboration (ISIC), an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions.\n\nMelanoma is a deadly disease, but if caught early, most melanomas can be cured with minor surgery. Image analysis tools that automate the diagnosis of melanoma will improve dermatologists' diagnostic accuracy. Better detection of melanoma has the opportunity to positively impact millions of people.","746d8141":"* # Prepare learning rate shrinkage","677f7a1d":"Next I made a train test split of our X and y dataset.","bbf401a9":"# Plot feature importance","c8f23dcc":"Next I made a data analysis of both the train and test set based on gender as shown below.","f9eefae1":"# SUBMISSIONS ","03436e11":"The train set contains dimension is 33126 row and 8 columns.","f375ee5c":"Next the predictions were made on the df_test dataset which contains the unknown images.","67261327":"I started by making some imports.","50a68120":"The test set is of dimension 10982 rows and 5 columns as shown below. The test set don't have the columns diagnosis, beningn_malignant and target.","4e8335e3":"Next I replaced the null values appearing in anatom_site_general_challenge with value unknown and then assigned a class to each values of this column as shown below. This was done for both dataframes df and df1.","12ac72af":"Next I changed the column name under which the image names in the train_features as well as the test_features dataframes appeared to **\"image_name\"** as in both the train_features and test_features dataframe they appeared with a name **\"Unnamed: 0\"**.","da298081":"Next I will display some images in the train and test set. The code for this was referred from the kernel given below:-\n\nhttps:\/\/www.kaggle.com\/siddhartamukherjee\/siim-isic-melanoma-analysis-eda-prediction","f4bac7f5":"Next I made a graphical display of the location of the images belonging to both train and test set.","d72293a4":"It seems for most images diagnosis is unknown. So, we may drop this column during our model building.","5099e6eb":"After this I analyzed how many unique patient ids is present. From the below results it can be found that in the train set we have 2056 unique patient ids.","49b22b6d":"**Let's take a look at some benign tumours from the train set.**","9ce7dac4":"Next I merged the dataframe df with the train features by image_name.","3059faa5":"This kernel demostrates the steps followed in building a classifier for the various skin images shared under the SIIM-ISIC Melanoma Classification competition. The final model predicts the probabilities of malignancy of the lesions in the images. Let's start!!!","81642786":"The distribution of image locations is same in both train and test set.","b2bdfbb0":"Next I displayed the first five rows of the train set and also checked the individual column information as shown below.","baeae180":"# EXPLORATORY DATA ANALYSIS(EDA)","0ed44bc6":"Next I displayed the shape of X_train and X_test to check how many records we now have in train and test set. ","7e83e167":"It seems the age distribution is uneven in test set.","aa5bbe48":"# About the Data","ab6dc341":"To check if the change reflected we displayed the first five columns of both the train_features and the test_features dataframes. From the below results it can be also seen that both train_features and the test_features dataframes contains 256 features per image.","e204581a":"# About Melanoma","dab8da81":"Next I read the contents of the train and test csv into two dataframes train and test. Here I have worked only with the images under the jpeg folders. As a start I got the image features of the images in both train and test folders extracted using a DenseNet121 architecture. The reference to the kernel is attached below:-\n\nhttps:\/\/www.kaggle.com\/siddhartamukherjee\/melanoma-classification-image-feature-extraction\n\nThe image features csv files were included here under the folder image features. These image features were copied in two dataframes train_features and test_features as shown below:-","f1ee69cb":"**Finally,let's check what we have to predict.**"}}