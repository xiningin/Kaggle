{"cell_type":{"9e50d507":"code","803c82d5":"code","eb9829bc":"code","3ce7fd35":"code","9c1af2be":"code","d4d6e62a":"code","3e84de94":"code","81fc466c":"code","a73cf031":"code","acebd18a":"code","cc8aa740":"code","81f91a54":"code","5723fe92":"code","8808e3fc":"code","c6c2e62c":"code","973751c3":"code","a3197783":"code","3a11c61c":"code","5429f412":"code","ee81572d":"code","609dd3fe":"code","56956285":"code","1df1d6af":"code","31ea619c":"code","7f38cc18":"markdown","44fb4851":"markdown","44e2053f":"markdown","63597ced":"markdown"},"source":{"9e50d507":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom lightgbm.sklearn import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,accuracy_score\nimport warnings\n%matplotlib inline\nwarnings.filterwarnings('ignore')\ngc.enable()\n","803c82d5":"#DATASET VIEW\npath1= \"..\/input\/\"\ndata_files=list(os.listdir(path1))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path1+x).st_size\/(1024*1024),2))\ndf_files","eb9829bc":"#All functions\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))\n\n#FUNCTION USED FOR GROUPING DATA \ndef cnt_unique(df):\n    return(len(df.unique()))","3ce7fd35":"%%time\n#READING INSTALLMENTS_PAYMENT DATA\ninst_pay=pd.read_csv(path1+'installments_payments.csv')\nprint('installments_payments set reading complete...')","9c1af2be":"#TAKING ABSOLUTE VALUE FOR DAYS_ FEATURES\nfor col in inst_pay.columns:\n    if 'DAYS_' in col:\n        inst_pay[col]=inst_pay[col].abs()","d4d6e62a":"%%time\n#MANUAL FEATURE ENGINEERING\n\ninst_pay['CALC_DAYS_LATE_PAYMENT']=inst_pay['DAYS_ENTRY_PAYMENT']-inst_pay['DAYS_INSTALMENT']\ninst_pay['CALC_PERC_LESS_PAYMENT']=inst_pay['AMT_PAYMENT']\/inst_pay['AMT_INSTALMENT']\ninst_pay['CALC_PERC_LESS_PAYMENT'].replace(np.inf,0,inplace=True)\ninst_pay['CALC_DIFF_INSTALMENT']=inst_pay['AMT_INSTALMENT']-inst_pay['AMT_PAYMENT']\ninst_pay['CALC_PERC_DIFF_INSTALMENT']=np.abs(inst_pay['CALC_DIFF_INSTALMENT'])\/inst_pay['AMT_INSTALMENT']\ninst_pay['CALC_PERC_DIFF_INSTALMENT'].replace(np.inf,0,inplace=True)\ninst_pay['CALC_INSTAL_PAID_LATE'] = (inst_pay['CALC_DAYS_LATE_PAYMENT'] > 0).astype(int)\ninst_pay['CALC_OVERPAID']= (inst_pay['CALC_DIFF_INSTALMENT'] < 0).astype(int)","3e84de94":"#FEATURE SUMMARY\ninst_pay_fs=feature_summary(inst_pay)\ninst_pay_fs","81fc466c":"#DATA VIEW FOR SINGLE SK_ID_CURR\ninst_pay[(inst_pay.SK_ID_CURR==100001)].sort_values('SK_ID_PREV')","a73cf031":"#DEFINING AGGREGATION RULES AND CREATING LIST OF NEW FEATURES\ninst_pay_cols=[x for x in list(inst_pay.columns) if x not in ['SK_ID_CURR','SK_ID_PREV']]\ninst_pay_agg={}\ninst_pay_name=['SK_ID_CURR','SK_ID_PREV']\nfor col in inst_pay_cols:\n    if 'NUM_INSTALMENT_VERSION'==col:\n        inst_pay_agg[col]=[cnt_unique]#CUSTOM FUNCTION FOR COUNTING UNIQUE INSTALMENT_VERSION\n        inst_pay_name.append(col+'_'+'unique')\n    elif 'NUM_INSTALMENT_NUMBER'==col:\n        inst_pay_agg[col]=['max','count']\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'count')\n    elif 'AMT_' in col:\n        inst_pay_agg[col]=['sum','mean','max','min','var','std']\n        inst_pay_name.append(col+'_'+'sum')\n        inst_pay_name.append(col+'_'+'mean')\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'min')\n        inst_pay_name.append(col+'_'+'var')\n        inst_pay_name.append(col+'_'+'std')\n    elif 'CALC_DAYS_' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col+'_'+'sum')\n    elif 'DAYS_' in col:\n        inst_pay_agg[col]=['sum','max','min']\n        inst_pay_name.append(col+'_'+'sum')\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'min')\n    else:\n        inst_pay_agg[col]=['mean']\n        inst_pay_name.append(col+'_'+'mean')\n","acebd18a":"%%time\n#AGGREGATING DATA ON SK_ID_CURR,SK_ID_PREV USING RULES CREATED IN PREVIOUS STEP\ninst_pay_f=inst_pay.groupby(['SK_ID_CURR','SK_ID_PREV']).aggregate(inst_pay_agg)\ninst_pay_f.reset_index(inplace=True)\ninst_pay_f.columns=inst_pay_name","cc8aa740":"inst_pay_f.head()","81f91a54":"#NUMBER OF MISSED INATALLMENTS\ninst_pay_f['CALC_NUM_INSTALMENT_MISSED']=inst_pay_f['NUM_INSTALMENT_NUMBER_max']-inst_pay_f['NUM_INSTALMENT_NUMBER_count']","5723fe92":"#DEFINING RULES FOR SECOND AGGREGATION ON SK_ID_CURR\ninst_pay_cols=[x for x in list(inst_pay_f.columns) if x not in ['SK_ID_PREV']]\ninst_pay_agg={}\ninst_pay_name=['SK_ID_CURR']\nfor col in inst_pay_cols:\n    if 'SK_ID_CURR'==col:\n        inst_pay_agg[col]=['count']\n        inst_pay_name.append('SK_ID_PREV_count')\n    elif '_unique' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)\n    elif '_mean' in col:\n        inst_pay_agg[col]=['mean']\n        inst_pay_name.append(col)\n    elif '_max' in col:\n        inst_pay_agg[col]=['max']\n        inst_pay_name.append(col)\n    elif '_min' in col:\n        inst_pay_agg[col]=['min']\n        inst_pay_name.append(col)\n    elif '_count' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)\n    else:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)","8808e3fc":"%%time\n#AGGREGATING DATA ON SK_ID_CURR\ninst_pay_f.drop(['SK_ID_PREV'],axis=1,inplace=True)\ninst_pay_fg=inst_pay_f.groupby(['SK_ID_CURR']).aggregate(inst_pay_agg)\ninst_pay_fg.reset_index(inplace=True)\ninst_pay_fg.columns=inst_pay_name","c6c2e62c":"inst_pay_fg.head(10)","973751c3":"#INSTALMENT_VERSION CHANGE\ninst_pay_fg['CALC_CNT_INSTALMENT_VERSION_CHG']=inst_pay_fg['NUM_INSTALMENT_VERSION_unique']-inst_pay_fg['SK_ID_PREV_count']","a3197783":"del inst_pay,inst_pay_f\ngc.collect()","3a11c61c":"# %%time\n# inst_pay_fg['inst_mean'] = inst_pay_fg.mean(axis=1)\n# print('the_mean calculated...')\n# inst_pay_fg['inst_sum'] =inst_pay_fg.sum(axis=1)\n# print('the_sum calculated...')\n# inst_pay_fg['inst_std'] = inst_pay_fg.std(axis=1)\n# print('the_std calculated...')\n# inst_pay_fg['inst_kur'] = inst_pay_fg.kurtosis(axis=1)\n# print('the_kur calculated...')","5429f412":"#READING APPLICATION TRAIN DATA (ONLY 'SK_ID_CURR','TARGET' FIELDS)\n#JOINING WITH INSTALLEMENT DATA\ntrain=pd.read_csv(path1+'application_train.csv',usecols=['SK_ID_CURR','TARGET'])\ndf_final=train.join(inst_pay_fg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_INP')","ee81572d":"df_final.head()","609dd3fe":"df_final.shape","56956285":"%%time\n#BASELINE SCORE\ntrain_X,test_X,train_y,test_y=train_test_split(df_final.drop(['SK_ID_CURR','TARGET'],axis=1),df_final['TARGET'],random_state=200)\nmodel=LGBMClassifier(learning_rate=0.05,objective='binary',n_estimators=200,n_jobs=-1,reg_alpha=0.1,min_split_gain=.1,verbose=-1)\nmodel.fit(train_X,train_y)\nscore2=roc_auc_score(test_y,model.predict_proba(test_X)[:,1])\nprint('BASELINE SCORE:',score2)","1df1d6af":"%%time\n#FORWARD FEATURE SELCTION \nscore=0\nscore1=0\nscore2=0\nselect_list=[]\ncol_list=[x for x in list(df_final.columns) if x not in ['SK_ID_CURR','TARGET']]  \nk=0\n\n\nwhile True:\n    score1=0\n    score2=0\n    temp_list=select_list\n    for i,col in enumerate(col_list):\n        if k==0:\n            train_X,test_X,train_y,test_y=train_test_split(df_final[col],df_final['TARGET'],random_state=200)\n            model =LGBMClassifier(learning_rate=0.05,n_estimators=200,n_jobs=-1,reg_alpha=0.1,min_split_gain=.1,verbose=-1)\n            model.fit(np.array(train_X).reshape(-1,1),train_y)\n            score2=roc_auc_score(test_y,model.predict_proba(np.array(test_X).reshape(-1,1))[:,1])\n        else:\n            temp_list.extend([col])\n            train_X,test_X,train_y,test_y=train_test_split(df_final[temp_list],df_final['TARGET'],random_state=200)\n            model =LGBMClassifier(learning_rate=0.05,n_estimators=200,n_jobs=-1,reg_alpha=0.1,min_split_gain=.1,verbose=-1)\n            model.fit(train_X,train_y)\n            score2=roc_auc_score(test_y,model.predict_proba(test_X)[:,1])\n            temp_list.remove(col)\n        if score1<=score2:\n            score1=score2\n            col1=col\n#        print('dropped col',col,':',score2)\n    k=k+1\n    if score<=score1:\n        score=score1\n        print('select col',col1,':',score)\n        select_list.extend([col1])\n        col_list.remove(col1)\n    else:\n        print('Best score achieved')\n        break\n    \nprint(select_list)\nprint('best score:',score)","31ea619c":"%%time\n#FEATURE EXCLUSION\nscore=0\nscore1=0\nscore2=0\ndrop_list=[]\ncol_list=[x for x in list(df_final.columns) if x not in ['SK_ID_CURR','TARGET']]\n\n\nwhile True:\n    score1=0\n    score2=0\n    for i,col in enumerate(col_list):\n        col_list.remove(col)\n        train_X,test_X,train_y,test_y=train_test_split(df_final[col_list],df_final['TARGET'],random_state=200)\n        model =LGBMClassifier(learning_rate=0.05,n_estimators=200,n_jobs=-1,reg_alpha=0.1,min_split_gain=.1,verbose=-1)\n        model.fit(train_X,train_y)\n        score2=roc_auc_score(test_y,model.predict_proba(test_X)[:,1])\n        col_list.extend([col])\n#        dummy_1.at[i,'score']=score2\n        if score1<score2:\n            score1=score2\n            col1=col\n#        print('dropped col',col,':',score2)\n    if score<score1:\n        score=score1\n        print('dropped col',col1,':',score)\n        drop_list.extend([col1])\n        col_list.remove(col1)\n    else:\n        print('Best score achieved')\n        break\nprint(drop_list)\nprint('best score:',score)","7f38cc18":"<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/home-credit\/home_credit.png\" alt=\"Count of Operation\" height=\"800\" width=\"800\"><\/img>","44fb4851":"<h2>Notebook Objective<\/h2>\n<ul>\n    <li>Feature engineering on Instalments table\n    <li>Selecting best features using <b>Forward Feature selection<\/b> and <b>Feature exclusion<\/b>\n    <li>Comparing both approaches\n<\/ul>\n<h3>Approach<\/h3>\n<ol>\n<li>Manual feature engineering\n<li>Defining Aggregation rules\n<li>Aggregating data using Aggregation rules\n<li>Creating join with Application Train table (only SK_ID_CURR and TARGET fields)\n<li>Applying forward feature selection\n<li>Applying feature exclusion\n<li>Comparing forward feature selection and feature exclusion results\n <\/ol>\n \n <h3>Observations<\/h3>\n <ol>\n <li>In first Version feature exclusion works better than forward feature selection. Feature selection was below base score\n <li>In Latest version with further feature engineering feature selection gives score better than base score and preforms better than feature exclusion\n  <\/ol>\n  \n   <h3>Conclusion<\/h3>\n   <ol>\n    <li>So we can conclude either for the approaches (Forward feature selection or Feature exclusion) can give us better result.\n    <li>We must try both and select one which gives us better result.\n    <li>Stronger the Engineered Features better the Feature Selection results.\n    <\/ol>","44e2053f":"<h3>Feature exclusion approach<\/h3>\n<ol>\n    <li>Using iterative process to exclude one feature at a time and calculate score\n    <li>Each iteration will go though each and every feature and exclude one feature with best score\n    <li>The process will end if there is no improvement from previous iteration\n <\/ol>","63597ced":"<h3>Forward Feature selection approach<\/h3>\n<ol>\n    <li>Using iterative process to select features one by one\n    <li>Each iteration will go though each and every feature and select one with best score\n    <li>The process will end if there is no improvement from previous iteration\n <\/ol>"}}