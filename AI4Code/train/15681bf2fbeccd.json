{"cell_type":{"f31a0d0a":"code","5482fba6":"code","ea991b0f":"code","45297f08":"code","2047cb59":"code","352f6014":"code","86bec7a1":"code","d63adc9d":"code","2736d19b":"code","10cdf367":"code","1fd7955a":"code","6141985d":"code","12bb59cc":"code","b79c2613":"code","e05357cc":"code","1a8b6308":"code","ed7a9f2c":"code","8f702d54":"code","631310b9":"code","ffb7a414":"code","fb562d9e":"code","7d2361c5":"code","04008e1d":"code","e3eb873f":"code","93a92ba5":"code","a2354711":"code","eafdfd11":"code","57529809":"code","b21340be":"code","5540918d":"code","5dd2e1d1":"code","d496e44a":"code","f7c2bf2c":"code","f0e02572":"code","f8698aa4":"code","80c6aab6":"code","6ac0beee":"code","9672d6a7":"code","9dfb2f7a":"markdown","b7f2bcd5":"markdown","dac8238c":"markdown","be5d7547":"markdown","c9b8eb67":"markdown","520d53ee":"markdown"},"source":{"f31a0d0a":"#import library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport re\nimport string\nstring.punctuation\nimport matplotlib.pyplot as plt\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","5482fba6":"comic = pd.read_csv('..\/input\/webtoon-comics-dataset\/Webtoon Dataset.csv')","ea991b0f":"comic.shape","45297f08":"comic.head()","2047cb59":"comic.describe()","352f6014":"comic.info()","86bec7a1":"#selection data\ndf1 = comic[['Rating', 'Genre', 'Summary']]\ndf1.head()","d63adc9d":"#defining the function to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\n\n#storing the puntuation free text\ndf1['Clean_Summary'] = df1['Summary'].apply(lambda x:remove_punctuation(x))\ndf1.head()","2736d19b":"#setting lower case\ndf1['Summary_Lower'] = df1['Clean_Summary'].apply(lambda x: x.lower())\ndf1.head()","10cdf367":"#defining function for tokenization\ndef tokenization(text):\n    tokens = re.split('W+', text)\n    return tokens\n\n#applying function to the column\ndf1['Summary_Tokenied'] = df1['Summary_Lower'].apply(lambda x: tokenization(x))\ndf1.head()","1fd7955a":"#stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\nstopwords[0:10]","6141985d":"#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output\n\n#applying the function\ndf1['No_Stopwords'] = df1['Summary_Tokenied'].apply(lambda x:remove_stopwords(x))\ndf1.head()","12bb59cc":"#defining the object for stemming\nporter_stemmer = PorterStemmer()\n\n#defining a function for stemming\ndef stemming(text):\n    stem_text = [porter_stemmer.stem(word) for word in text]\n    return stem_text\n\ndf1['Summary_Stemmed'] = df1['No_Stopwords'].apply(lambda x: stemming(x))\ndf1.head()","b79c2613":"#selection data\ndf2 = df1[['Rating', 'Genre', 'Clean_Summary']]\ndf2.head()","e05357cc":"#create function to get subjectivity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\n#create function to get polarity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\n#apply function to data \ndf2['Subjectivity'] = df2['Clean_Summary'].apply(getSubjectivity)\ndf2['Polarity'] = df2['Clean_Summary'].apply(getPolarity)\ndf2.head()","1a8b6308":"#create function to get sentiment data\ndef getSentiment(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'\n    \n#apply function to data\ndf2['Sentiment'] = df2['Polarity'].apply(getSentiment)\ndf2.head()","ed7a9f2c":"positive = \" \".join(df2[df2.Sentiment == 'Positive']['Clean_Summary'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(positive)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Positive Summary\")\nplt.axis('off')\nplt.show()","8f702d54":"neutral = \" \".join(df2[df2.Sentiment == 'Neutral']['Clean_Summary'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(neutral)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Neutral Summary\")\nplt.axis('off')\nplt.show()","631310b9":"negative = \" \".join(df2[df2.Sentiment == 'Negative']['Clean_Summary'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(negative)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Negative Summary\")\nplt.axis('off')\nplt.show()","ffb7a414":"#visualize sentiment\ndf2['Sentiment'].value_counts()\n\nplt.figure(figsize = (10,6))\nplt.title(\"Sentiment Analysis of Webtoon Comics Summary\")\nplt.xlabel(\"Sentiment\")\nplt.ylabel(\"Count\")\n\ndf2['Sentiment'].value_counts().plot(kind = 'bar')\nplt.show()","fb562d9e":"#group genre & sentiment\ngenre_sentiment = df2.groupby(['Genre', 'Sentiment']).size().reset_index(name = 'Count')\nprint(genre_sentiment)","7d2361c5":"#visualize genre ~ sentiment\nplt.figure(figsize = (20,10))\nsns.barplot(x = 'Genre', y = 'Count', hue = 'Sentiment', data = genre_sentiment)\nplt.title(\"Genre ~ Sentiment\")\nplt.show()","04008e1d":"#seletion data\ndf3 = comic[['Name', 'Writer', 'Likes', 'Genre', 'Subscribers', 'Rating']]\ndf3.head()","e3eb873f":"#handling categorical data\ndf3 = pd.get_dummies(df3, drop_first = True)\ndf3.head()","93a92ba5":"#split data\nX = df3.drop('Rating', axis = 1)\ny = df3['Rating']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a2354711":"linreg = LinearRegression()\nmodel = %time linreg.fit(X_train, y_train)\nprint(model)","eafdfd11":"#prediction\ny_pred = linreg.predict(X_test)\nprint(y_pred)","57529809":"#result of prediction\nprediction = pd.DataFrame({'Actual' : y_test, 'Prediction' : y_pred})\nprediction.head()","b21340be":"#heatmap correlation\nplt.figure(figsize = (10,6))\nsns.heatmap(prediction.corr(), annot = True, cmap = 'Blues')\nplt.title(\"Pearson Correlation\")\nplt.show()","5540918d":"#check MAE\nprint('Mean Absolute Error : ', metrics.mean_absolute_error(y_test, y_pred).round(2))","5dd2e1d1":"#check MSE\nprint('Mean Squared Error : ', metrics.mean_squared_error(y_test, y_pred).round(2))","d496e44a":"#check RMSE\nprint('Root Mean Squared Error : ', np.sqrt(metrics.mean_absolute_error(y_test, y_pred).round(2)))","f7c2bf2c":"#check r2 score \nprint('r2_score : ', metrics.r2_score(y_test, y_pred))","f0e02572":"#visualization model\nx = y_test\ny = y_pred\n\nplt.figure(figsize = (10,6))\nplt.title(\"Linear Regression Plot Model\")\nplt.plot(x, y, 'o')\n\nm, b = np.polyfit(x, y, 1)\nplt.plot(x, m * x + b)","f8698aa4":"coef = pd.Series(model.coef_, index = X.columns)","80c6aab6":"imp_coef = pd.concat([coef.sort_values().head(10),\n                     coef.sort_values().tail(10)])","6ac0beee":"plt.figure(figsize = (10,6))\nimp_coef.plot(kind = 'barh')\nplt.title(\"Feature Importance\")\nplt.show()","9672d6a7":"#distribution\nplt.figure(figsize = (10,6))\nsns.distplot(df3['Rating'])\nplt.title(\"Distribution of Webtoon Comics Rating\")\nplt.show()","9dfb2f7a":"## Sentiment Analysis","b7f2bcd5":"# Webtoon Comics Prediction","dac8238c":"## Linear Regression Model","be5d7547":"## Text Processing","c9b8eb67":"## Data Extraction","520d53ee":"## Check Feature Importance"}}