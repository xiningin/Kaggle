{"cell_type":{"c158a47d":"code","0678cd2c":"code","9a96f52f":"code","2fcbc2b1":"code","3b8fe2a1":"code","7c26c779":"code","8b1060db":"code","1cbc8128":"code","6b5a7059":"code","3edbc471":"code","d853f57a":"code","629fa839":"code","dff798e2":"code","74f7c008":"code","7aab593e":"code","569285fb":"code","de8f4351":"markdown","bb1342ee":"markdown","9beb443f":"markdown","60ffb5b6":"markdown"},"source":{"c158a47d":"import os\nimport numpy as np \nimport pandas as pd\n\nfrom spacy import displacy\n\n# settings\npd.set_option('display.max_colwidth', 200)","0678cd2c":"train_dir = '..\/input\/feedback-prize-2021\/train'\ntrain_csv_path = '..\/input\/feedback-prize-2021\/train.csv'","9a96f52f":"# total number of files\ntrain_files = os.listdir(train_dir)\nlen(train_files)","2fcbc2b1":"# read the CSV file\ntrain_df = pd.read_csv(train_csv_path)\ntrain_df.head()","3b8fe2a1":"# Label names\ntrain_df.discourse_type.unique().tolist()","7c26c779":"# CSV total number of rows\nlen(train_df.index)","8b1060db":"# Check if there is any null\ntrain_df.isnull().sum()","1cbc8128":"# Column names\ncols = [*train_df]\ncols","6b5a7059":"# Type of data in each column\ntrain_df.dtypes","3edbc471":"# Discourse type distribution\ntrain_df.discourse_type.value_counts()","d853f57a":"train_df.discourse_type.value_counts().plot(kind='pie', figsize=(8,8), ylabel='')","629fa839":"# number of chars frequency in discourse text\ntrain_df['discourse_text'].apply(len).value_counts().hist()","dff798e2":"# View a text file\nindex = 1\nfile_path = os.path.join(train_dir, train_files[index])\nfile_content = open(file_path).read()\nfile_content","74f7c008":"# View discourses\nfile_id = train_files[index].split('.')[0]\ntrain_df[train_df['id'] == file_id]","7aab593e":"# Visualizing the segments. \ncolors = {\n    'Lead': '#F5B7B1',\n    'Position': '#D7BDE2',\n    'Evidence': '#AED6F1',\n    'Claim': '#A3E4D7',\n    'Concluding Statement': '#F9E79F',\n    'Counterclaim': '#E5E7E9',\n    'Rebuttal': '#FEF9E7'\n}\n\ndef visualize_segments(df, text, file_id):\n    segments = []\n    seg_df = df[df['id'] == file_id]\n    lable_names = df.discourse_type.unique().tolist()\n    \n    for _, row in seg_df.iterrows():\n        seg_info = {\n            'start': int(row['discourse_start']),\n            'end': int(row['discourse_end']),\n            'label': row['discourse_type'],\n        }\n        segments.append(seg_info)\n\n    text_info = {\n        'text': text,\n        'ents': segments,\n        'title': f'{file_id}.txt'\n    }\n    \n    configs = {\n        'colors': colors\n    }\n    \n    displacy.render(\n        text_info, \n        style='ent',\n        options=configs,\n        manual=True,\n        jupyter=True\n    )","569285fb":"visualize_segments(train_df, file_content, file_id)","de8f4351":"# EDA","bb1342ee":"# Visualization ","9beb443f":"There are total *15,594* text files in the training dir. But *1,44,293* rows in the CSV file. That meas one file may contain multiple lebels\/segments. Thus this can be a **multi-label classification problem** like NER.","60ffb5b6":"Clearly the dataset is not balanced. Examples of *Evidence* and *Claim* contains many examples where other labels have very few examples. "}}