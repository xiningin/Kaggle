{"cell_type":{"ddb85ef5":"code","ca82f1aa":"code","82b9c7e5":"code","5813691e":"code","81fca8f1":"code","4c1d09f4":"code","da9fda92":"code","631361c5":"code","ab7751a4":"code","d575f916":"code","5adaa33c":"code","9687ab9b":"code","4adbae00":"code","105b44bb":"code","378a4eed":"code","a60f68af":"code","16e1479c":"code","c56dcd4a":"code","0d094587":"code","d3318634":"code","208aa697":"code","eb584d68":"code","3d6ad24d":"code","43a290bf":"code","e88dd107":"code","0d3528c5":"code","1474e16f":"code","cd0d0328":"code","6bd143db":"code","0e070698":"code","828391da":"code","61a58066":"code","cb0c04a7":"code","e6357d81":"code","01474601":"code","50838334":"code","e39fc15d":"code","497b24a8":"code","5f097db9":"code","df130472":"code","abc48999":"code","1f597ad1":"code","58fd6906":"markdown","36b6571e":"markdown","3bcfca7e":"markdown","f3f7b5ae":"markdown","91f5a766":"markdown","7f6d25ce":"markdown","0836174a":"markdown","890a9be1":"markdown","005fcdd7":"markdown","724d29b5":"markdown","013c38b6":"markdown","1d5de842":"markdown","1f8f950f":"markdown","b03d959a":"markdown","a62366dc":"markdown","12697172":"markdown","2df2a821":"markdown","4a577fee":"markdown","4b70827a":"markdown","3b3e92d5":"markdown","61e79360":"markdown","6f9ed096":"markdown","c891ae58":"markdown","4fd300a1":"markdown","e96407bc":"markdown","e7b51d4e":"markdown"},"source":{"ddb85ef5":"!pip install pyspark","ca82f1aa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport pyspark # only run after findspark.init()\nfrom pyspark.sql import SparkSession\n\n\n# May take awhile locally\nspark = SparkSession.builder.appName(\"Pyspark_3\").getOrCreate()\n\ncores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\nprint(\"You are working with\", cores, \"core(s)\")\nspark","82b9c7e5":"path =\"\"\nbase_df = spark.read.csv(path+'\/kaggle\/input\/heart-failure-prediction\/heart.csv',inferSchema=True,header=True)","5813691e":"base_df.printSchema()","81fca8f1":"base_df.toPandas().head()","4c1d09f4":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n#set seaborn plotting aesthetics as default\nsns.set()\n\n#define plotting region (2 rows, 2 columns)\nfig, axes = plt.subplots(7, 3, squeeze=True, figsize=(15,30))\n\n#fig.(figsize=(12,10))\n\nvis_df = base_df.toPandas()\n#create boxplot in each subplot\nsns.histplot(data=vis_df, x='Oldpeak', ax=axes[0,0])\nsns.histplot(data=vis_df, x='Age', ax=axes[0,1])\nsns.histplot(data=vis_df, x='RestingBP', ax=axes[0,2])\n\nsns.histplot(data=vis_df, x='Cholesterol', ax=axes[1,0])\nsns.histplot(data=vis_df, x='FastingBS',  ax=axes[1,1])\nsns.histplot(data=vis_df, x='MaxHR', ax=axes[1,2])\n\nsns.countplot(data=vis_df, x='HeartDisease', ax=axes[2,0])\nsns.countplot(data=vis_df, x='Sex', ax=axes[2,1])\nsns.countplot(data=vis_df, x='ChestPainType',  ax=axes[2,2])\n\nsns.countplot(data=vis_df, x='FastingBS', ax=axes[3,0])\nsns.countplot(data=vis_df, x='RestingECG', ax=axes[3,1])\nsns.countplot(data=vis_df, x='ExerciseAngina',  ax=axes[3,2])\n\nsns.countplot(data=vis_df, x='ST_Slope', ax=axes[4,0])\nsns.boxplot(data=vis_df, x='HeartDisease', y='Age', ax=axes[4,1])\nsns.boxplot(data=vis_df, x='HeartDisease', y='Cholesterol',  ax=axes[4,2])\n\ni = 5\nsns.pointplot(data=vis_df, x='FastingBS', y='HeartDisease',estimator= np.mean,  ax=axes[i,0])\nsns.pointplot(data=vis_df, x='ExerciseAngina', y='HeartDisease',estimator= np.mean,  ax=axes[i,1])\nsns.pointplot(data=vis_df, x='ChestPainType', y='HeartDisease',estimator= np.mean,  ax=axes[i,2])\n\ni = 6\nsns.pointplot(data=vis_df, x='ST_Slope', y='HeartDisease',estimator= np.mean,  ax=axes[i,0])\nsns.pointplot(data=vis_df, x='Sex', y='HeartDisease',estimator= np.mean,  ax=axes[i,1])\nsns.pointplot(data=vis_df, x='RestingECG', y='HeartDisease',estimator= np.mean,  ax=axes[i,2])\n\n#plt.show()","da9fda92":"sns.pairplot(data = vis_df, hue = 'HeartDisease')","631361c5":"plt.figure(figsize =(10,10))\nsns.heatmap(vis_df.select_dtypes(np.number).corr(), annot=True, center=0, cmap ='RdYlGn')","ab7751a4":"from pyspark.sql.functions import *\n\nbase_df.select([count(when(col(c).contains('None') | \\\n                            col(c).contains('NULL') | \\\n                            (col(c) == '' ) | \\\n                            col(c).isNull() | \\\n                            isnan(c), c \n                           )).alias(c)\n                    for c in base_df.columns]).show()","d575f916":"base_df.count()","5adaa33c":"from pyspark.sql.types import * \nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\n\n\ndef target_indexer(df, dependent_var_column_name):\n    # change label (class variable) to string type to prep for reindexing\n    # Pyspark is expecting a zero indexed integer for the label column. \n    # Just incase our data is not in that format... we will treat it by using the StringIndexer built in method\n    \n    renamed = df.withColumn(\"label_str\", df[dependent_var_column_name].cast(StringType())) #Rename and change to string type\n    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n    indexed_df = indexer.fit(renamed).transform(renamed)\n    return indexed_df","9687ab9b":"def custom_transforms(df):\n    trans_df = df.select(\"*\",(when(df.ExerciseAngina=='Y', 1).otherwise(0)).alias('yes_exercise_angina')\n                 ,(when(df.ChestPainType=='ATA', 1).otherwise(0)).alias('ata_chest_pain_type')\n              ,(when(df.ChestPainType=='ASY', 1).otherwise(0)).alias('asy_chest_pain_type')\n              ,(when(df.ST_Slope=='Up', 1).otherwise(0)).alias('up_st_slope')\n              ,(when(df.Sex=='F', 1).otherwise(0)).alias('f_sex')\n              ,(when(df.RestingECG=='ST', 1).otherwise(0)).alias('st_resting_ecg')\n                 )\\\n        .drop('ExerciseAngina','ChestPainType', 'ST_Slope', 'Sex', 'RestingECG')\\\n        .withColumnRenamed(\"HeartDisease\", 'label')\n    \n    #trans_base_data = trans_base_data\n    \n    features_list = trans_df.columns\n    print(features_list)\n    features_list.remove('label')\n    assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n    vector_trans_df = assembler.transform(trans_df).select('features','label')\n    \n    return vector_trans_df, trans_df","4adbae00":"vector_trans_df, trans_df = custom_transforms(base_df)","105b44bb":"vector_trans_df.show(5, False)","378a4eed":"vector_trans_df.toPandas().head()","a60f68af":"trans_df.toPandas().head()","16e1479c":"trans_df.toPandas().head()","c56dcd4a":"train,test = vector_trans_df.randomSplit([0.7,0.3], seed = 13)","0d094587":"dataset_size=float(train.select(\"label\").count())\nPositives=train.select(\"label\").where('label == 1').count()\npercentage_ones=(float(Positives)\/float(dataset_size))*100\nNegatives=float(dataset_size-Positives)\nprint('The number of ones are {}'.format(Positives))\nprint('Percentage of ones are {}'.format(percentage_ones))","d3318634":"train.select(\"label\").count()","208aa697":"test.select(\"label\").count()","eb584d68":"from pyspark.ml.classification import DecisionTreeClassifier","3d6ad24d":"params = {'maxDepth':4}\n\ndTree_classifier = DecisionTreeClassifier(**params, seed= 13)\ndTree_classifier","43a290bf":"dTree_model = dTree_classifier.fit(train)","e88dd107":"# test data prediction\npredictionAndLabels = dTree_model.transform(test)\npredictionAndLabels.show(2,False)","0d3528c5":"from pyspark.ml.evaluation import *\n\n#dt_hyper_eval = BinaryClassificationEvaluator(predictionAndLabels)\ndt_hyper_eval2= MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\ndt_hyper_ACC  = dt_hyper_eval2.evaluate(predictionAndLabels, {dt_hyper_eval2.metricName:\"accuracy\"})\nprint(\"Decision Tree Performance Measure\")\nprint(\"Accuracy = %0.2f\" % dt_hyper_ACC)\n","1474e16f":"dt_hyper_eval = BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"label\")\ndt_hyper_AUC  = dt_hyper_eval.evaluate(predictionAndLabels)\nprint(\"AUC = %.2f\" % dt_hyper_AUC)","cd0d0328":"from pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.sql.types import FloatType\n\n#preds_and_labels = predictionAndLabels.select(['predictions','d']).withColumn('label', F.col('d').cast(FloatType())).orderBy('prediction')\n#important: need to cast to float type, and order by prediction, else it won't work\n\n#select only prediction and label columns\npreds_and_labels = predictionAndLabels.select(['prediction','label']).withColumn('label', col('label').cast(FloatType())).orderBy('prediction')\nmetrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n#print(metrics.confusionMatrix().toArray())","6bd143db":"#confusion matrix\ncm_dt_result = predictionAndLabels.crosstab(\"prediction\", \"label\")\ncm_dt_result = cm_dt_result.toPandas()\ncm_dt_result.sort_values(by = ['prediction_label'])","0e070698":"#calculate accuracy, sensitivity, specificity and precision\nTP = cm_dt_result[\"1\"][0]\nFP = cm_dt_result[\"0\"][0]\nTN = cm_dt_result[\"0\"][1]\nFN = cm_dt_result[\"1\"][1]\nAccuracy = (TP+TN)\/(TP+FP+TN+FN)\nSensitivity = TP\/(TP+FN)\nSpecificity = TN\/(TN+FP)\nPrecision = TP\/(TP+FP)\n\nprint (\"Accuracy = %0.2f\" %Accuracy )\nprint (\"Sensitivity = %0.2f\" %Sensitivity )\nprint (\"Specificity = %0.2f\" %Specificity )\nprint (\"Precision = %0.2f\" %Precision )","828391da":"import pyspark.sql.functions as F\ndef classification_report_pyspark(metrics_multiclass,preds_and_labels, labels_list):\n    #import math\n    columns = ['target_class', 'precision', 'recall', 'f1-score', 'support']\n\n    data = []\n    for i in labels_list:\n        support = preds_and_labels.where('label = ' + str(i)).count()\n        data.append((str(i), float(np.round(metrics_multiclass.precision(label = i),3)), \n                     float(np.round(metrics_multiclass.recall(label = i), 3)), \n                     float(np.round(metrics_multiclass.fMeasure(i), 3)), support)), \n\n    data.append(('weighted avg', float(np.round(metrics_multiclass.weightedPrecision, 3)), \n                                 float(np.round(metrics_multiclass.weightedRecall, 3)), \n                                   float(np.round(metrics_multiclass.weightedFMeasure(), 3)), preds_and_labels.count() ))\n    class_rep = spark.createDataFrame(data, columns)\n    return class_rep","61a58066":"class_rep = classification_report_pyspark(metrics, preds_and_labels, [0.0, 1.0])","cb0c04a7":"class_rep.show()","e6357d81":"from sklearn.metrics import classification_report\npreds_and_labels_pdf = preds_and_labels.toPandas()\nprint(classification_report(preds_and_labels_pdf['label'], preds_and_labels_pdf['prediction']))","01474601":"evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",probabilityCol=\"probability\")\nevaluator.setMetricName(\"logLoss\")\n#MulticlassClassificationEvaluator...\nevaluator.evaluate(predictionAndLabels)","50838334":"from pyspark.sql.types import ArrayType\nfrom pyspark.ml.functions import vector_to_array\n# add probability to the pred and label set, convert data type of probability and add weights column to the dataframe \npreds_labels_prob = predictionAndLabels.select(['prediction','label', 'probability'])\\\n                                       .withColumn('label', col('label')\\\n                                       .cast(FloatType())).orderBy('prediction')\\\n                                       .withColumn('weight', lit(1.0))\\\n                                        .select(['prediction','label', 'weight', 'probability'])\\\n                                        .withColumn('probability', vector_to_array(predictionAndLabels['probability']))\nmetrics_ll = MulticlassMetrics(preds_labels_prob.rdd.map(tuple))\nmetrics_ll.logLoss()","e39fc15d":"preds_labels_prob.show(5,False)","497b24a8":"print(dTree_model.toDebugString)","5f097db9":"feature_imp = dict(zip(trans_df.columns, np.round(dTree_model.featureImportances.toArray()*100,2)))\nfeature_imp","df130472":"from matplotlib import pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\nplt.figure(figsize= (30,5))\ntotal = np.sum(list(feature_imp.values()))\nplt.bar(feature_imp.keys(), [v\/total for v in feature_imp.values()], color='salmon')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=0))\nplt.grid(axis='y')\nplt.show()","abc48999":"base_df.select('RestingECG').distinct().rdd.map(lambda r: r[0]).collect()","1f597ad1":"[i.RestingECG for i in base_df.select('RestingECG').distinct().collect()]","58fd6906":"> confusionMatrix()[source]\n> Returns confusion matrix: predicted classes are in columns, they are ordered by class label ascending, as in \u201clabels\u201d.\n> \nReference https:\/\/spark.apache.org\/docs\/2.0.0\/api\/python\/pyspark.mllib.html#pyspark.mllib.evaluation.MulticlassMetrics","36b6571e":"# Confusion Matrix","3bcfca7e":"# Classification Report","f3f7b5ae":"# Evaluation for Classification Model","91f5a766":"# Train Test Split","7f6d25ce":"# Feature Engineering","0836174a":"# Modelling","890a9be1":"# Prediction","005fcdd7":"# Logloss","724d29b5":"# Area Under Curve AUC","013c38b6":"Another possible way :-","1d5de842":"# Checking Null Values in the Data","1f8f950f":"Many times it is required to have the list of distinct values present in a column. How to work that out in PySpark?","b03d959a":"# Basic EDA","a62366dc":"Since this data doesn't have any class imbalance the randomSplit() function works well. However it doesn't seem to be as good as the train_test_split() method from scikit-learn which provides multiple options like stratify to handle class imbalance while spliting the data.\n\n\nA stackoverflow question has also been raised regarding the same which is currently open.\nhttps:\/\/stackoverflow.com\/questions\/70721631\/sklearn-train-test-split-equivalent-in-pyspark","12697172":"# Bonus","2df2a821":"## Thanks!","4a577fee":"# Visualisations","4b70827a":"All the datatypes have been inferred correctly.","3b3e92d5":"# Accuracy","61e79360":"The Evaluator object has been used to calculate logloss as it seemed that doing the same with the previously used class was tedious. The original class has still been used to show how logloss can be calculated using that for completeness's sake.","6f9ed096":"The similarity between the scikit learn classification report and custom PySpark classification report function seem to be very impressive.","c891ae58":"Reference\n\nhttps:\/\/www.statology.org\/seaborn-subplots\/","4fd300a1":"# Model Summary","e96407bc":"# Feature Importance","e7b51d4e":"Reference:-\n* https:\/\/stackoverflow.com\/questions\/64896418\/how-can-i-plot-a-seaborn-percentage-bar-graph-using-a-dictionary\n* https:\/\/stackoverflow.com\/questions\/58404845\/confusion-matrix-to-get-precsion-recall-f1score\n* https:\/\/stackoverflow.com\/questions\/39383557\/show-distinct-column-values-in-pyspark-dataframe\n* https:\/\/spark.apache.org\/docs\/latest\/api\/python\/reference\/api\/pyspark.mllib.evaluation.MulticlassMetrics.html\n* https:\/\/github.com\/elsyifa\/Classification-Pyspark\/blob\/master\/Classification_Using%20_Pyspark.py\n* https:\/\/spark.apache.org\/docs\/latest\/\/api\/python\/reference\/api\/pyspark.ml.functions.vector_to_array.html\n* https:\/\/sparkbyexamples.com\/pyspark\/pyspark-add-new-column-to-dataframe\/"}}