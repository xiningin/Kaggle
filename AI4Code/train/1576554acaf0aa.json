{"cell_type":{"bb231849":"code","dea1f476":"code","ecbf2c85":"code","584f5a26":"code","beafc176":"code","ac0d82aa":"code","d44766ec":"code","bdadbc65":"code","b1859f26":"code","8c56cf2b":"code","69b0f18c":"code","3d988345":"code","d226b9b0":"code","e81d41ba":"code","8fb4daa8":"code","8e89edd9":"code","4bb9365c":"code","2aa53a7d":"code","f47813fa":"code","0da93f2c":"code","4166a153":"code","0e4e698f":"code","c9688667":"code","8aa1460b":"code","fca59e7c":"code","45d68747":"code","e61496a5":"code","1a1ac235":"code","b69d1bd7":"code","be62a60c":"code","f5c3d9d6":"code","0e128ec3":"code","49d103e0":"code","3a5da176":"code","91f37839":"code","bcf677e6":"code","68211f88":"code","3da74b3c":"code","ea49441c":"code","4e2ace55":"code","f4d8ff31":"code","8139736d":"code","11fdc78d":"code","2636ec79":"code","895c970d":"code","8162f188":"code","d904f34b":"code","301339ab":"code","eb9e8893":"code","0b8bb792":"code","d7db5dda":"code","b8078a38":"code","e4359fb6":"code","e020a662":"code","be900b15":"code","88c8cbbb":"code","645feb2d":"code","6fcb2523":"code","6f61bbc6":"code","96b106b5":"code","ae1063ad":"code","f01e18c8":"markdown","67f6590e":"markdown","7446302e":"markdown","dea7c074":"markdown","0fd838a4":"markdown","6ddae2e2":"markdown","2f5d7069":"markdown","9a2fa798":"markdown","020c8a7c":"markdown","9fbdb457":"markdown","3a398d47":"markdown","824210d4":"markdown","084d9a17":"markdown","4067c705":"markdown","a5b70abc":"markdown","010c5208":"markdown","93daad44":"markdown","ea12dd7b":"markdown","831cadca":"markdown","3bbca448":"markdown","db9004fe":"markdown","46c24533":"markdown","f7630bba":"markdown","ba129cd4":"markdown","e2ba53c1":"markdown","b7dea6c8":"markdown","ed19f8ea":"markdown","8a7de1b9":"markdown","9e99b9b4":"markdown","0aeca7d4":"markdown","c38554e0":"markdown","9d958642":"markdown","f6339aba":"markdown","9a6ddcdf":"markdown","8c4a8d81":"markdown","4c2d2b73":"markdown","d78863e7":"markdown","2d74147c":"markdown","71285b9a":"markdown","a0935604":"markdown","e3d08be3":"markdown","4e7ff2c4":"markdown","f0f466b3":"markdown","53142f67":"markdown","aaf9bc75":"markdown","18fccd7c":"markdown","8efeacda":"markdown"},"source":{"bb231849":"# Import nessecary packages\n\n# Packages for dataframe operations\nimport numpy as np \nimport pandas as pd\n\n# Packages for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport collections\n\n# Packages for text analysis\nfrom wordcloud import WordCloud\nimport string\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n#!pip install gensim --user\nfrom gensim.summarization import keywords\nfrom gensim.summarization import summarize\nimport spacy\nimport plotly\nplotly.offline.init_notebook_mode (connected = True)","dea1f476":"# To set the plot styles of the study using Seaborn white style.\nsns.set_style('white')","ecbf2c85":"job = pd.read_csv(\"\/kaggle\/input\/data-analyst-jobs\/DataAnalyst.csv\")","584f5a26":"job.head()","beafc176":"job.shape","ac0d82aa":"job.columns","d44766ec":"job.info()","bdadbc65":"#Delete a column not needed \njob.reset_index(drop=True)\ndel job['Unnamed: 0']","b1859f26":"job.head()","8c56cf2b":"job.isnull().sum()","69b0f18c":"# fill the NA with -1\njob.fillna(-1,inplace=True)","3d988345":"job.isnull().sum()","d226b9b0":"# To check the unique catagories of 'Size'\njob[\"Size\"].unique()","e81d41ba":"# To check the unique catagories of 'Revenue'\njob[\"Revenue\"].unique()","8fb4daa8":"# To check the unique catagories of 'Salary Estimate'\njob[\"Salary Estimate\"].unique()","8e89edd9":"# Add 4 columns based on \"Salary Estimate\"\njob['Salary_From'] = job[\"Salary Estimate\"].str.extractall(r\"[$](\\d+)\").xs(0, level='match')\njob['Salary_To'] = job[\"Salary Estimate\"].str.extractall(r\"[$](\\d+)\").xs(1, level='match')\njob.fillna(-1,inplace=True)\njob['Salary_From'] = job['Salary_From'].astype(int)\njob[\"Salary_To\"] = job[\"Salary_To\"].astype(int)\njob['Salary_Mean'] = (job[\"Salary_To\"] + job['Salary_From'])\/2\njob['Salary_Range'] = job[\"Salary_To\"] - job['Salary_From']\n\n# Can also be achieved by:\n#job['Salary_From'] = job[\"Salary Estimate\"].str.extract(r\"[$](\\d+)\")\n#job['Salary_To'] = job[\"Salary Estimate\"].str.extract(r\"(\\d+)\\S \")\n","4bb9365c":"# Strip '\\n' from \"Company Name\"\njob[\"Company Name\"] = job[\"Company Name\"].str.replace(\"(\\n).*\",\"\")","2aa53a7d":"# Add two columns based on 'Location', to seperate city and state\njob[\"Location_State\"] = job[\"Location\"].agg(lambda x: x[-2:])\njob[\"Location_City\"] = job[\"Location\"].agg(lambda x: x[:-4])","f47813fa":"job.head(3)","0da93f2c":"job[job[\"Company Name\"].isnull()]","4166a153":"job.fillna(-1,inplace=True)","0e4e698f":"# To check the unique catagories of \"Type of ownership\"\njob[\"Type of ownership\"].unique()","c9688667":"# To check the unique catagories of \"Industry\"\njob[\"Industry\"].unique()","8aa1460b":"# Visualize the salary lower and upper bound\nfig,(ax0, ax1) = plt.subplots(nrows =1, ncols = 2, figsize = (20,4))\nsns.distplot(job['Salary_From'], ax = ax0)\nsns.distplot(job['Salary_To'], color = 'r', ax = ax1)\nax0.set(xlabel = \"Salary Lower Bound ($ k\/year)\", ylabel = 'Percentage')\nax0.set(title = \"Salary Lower Bound Distribution\")\nax1.set(xlabel = \"Salary Upper Bound ($ k\/year)\", ylabel = 'Percentage')\nax1.set(title = \"Salary Upper Bound Distribution\")\nplt.show()","fca59e7c":"# Visualize the salary range and the salary mean\nfig,(ax0, ax1) = plt.subplots(nrows =1, ncols = 2, figsize = (20,4))\nsns.distplot(job['Salary_Range'], color = 'g', ax = ax0)\nsns.distplot(job['Salary_Mean'], color = 'y', ax = ax1)\nax0.set(xlabel = \"Salary Range ($ k\/year)\", ylabel = 'Percentage')\nax0.set(title = \"Salary Range Distribution\")\nax1.set(xlabel = \"Average Salary ($ k\/year)\", ylabel = 'Percentage')\nax1.set(title = \"Average Salary Distribution\")\nplt.show()","45d68747":"Salary_df = job[['Salary_From','Salary_To', 'Salary_Range', 'Salary_Mean']].drop(2149)\nSalary_df.describe()","e61496a5":"# Make a order list\nsort_list = sorted(job.groupby('Location_State')['Salary_Mean'].median().items(), key= lambda x:x[1], reverse = True)\nstate_list_sort = [x[0] for x in sort_list]","1a1ac235":"plt.figure(figsize = (20,8))\nsns.boxplot(x='Salary_Mean',y = 'Location_State', data=job, whis = 10, order = state_list_sort, palette=\"vlag\" )\nplt.xlabel(\"Average Salary ($ k\/year)\")\nplt.title(\"Average Salary Per State\", size =20)\nplt.show()","b69d1bd7":"# Make a order list\ncity_20_list = job.groupby('Location')['Location'].count().sort_values(ascending = False).head(20)\ncity_count_list = [x for x in city_20_list.index]\nsort_list_city = sorted(job[job['Location'].isin(city_count_list)].groupby('Location')['Salary_Mean'].median().items(), key= lambda x:x[1], reverse = True)\ncity_list = [x[0] for x in sort_list_city ]","be62a60c":"plt.figure(figsize = (20,8))\nsns.boxplot(x='Salary_Mean',y = 'Location', data=job, whis = 10, order = city_list, palette=\"vlag\" )\nplt.xlabel(\"Average Salary ($ k\/year)\")\nplt.title(\"Average Salary Per City\", size = 20)\nplt.show()","f5c3d9d6":"# Create a count Count dataframe to count the job numbers by each city\nState_City_df = job.groupby(['Location_State','Location_City'])['Location_City'].count().to_frame('Count').reset_index()\nState_City_df['Country'] = 'US'\n\n# Use the Count dataframe to draw the treemap\nfig = px.treemap(State_City_df, path=['Country', 'Location_State', 'Location_City'], values='Count',\n                 color= 'Count'\n                ,color_continuous_scale='Blues', title = 'Job No. by State and City')\nfig.data[0].textinfo = 'label+text+value+percent parent'\nfig.show()","0e128ec3":"# Make a order list by # of jobs in each state\nstate_list = sorted(job.groupby('Location_State')['Location_State'].count().items(), key= lambda x:x[1], reverse = True)\nstate_count_list = [x[0] for x in state_list]","49d103e0":"# Show both the job # and average salaries of each state\nplt.figure(figsize = (20,8))\nstate_mean = job.groupby('Location_State')['Salary_Mean'].mean()\nsns.countplot(x='Location_State',data=job, order = state_count_list, palette=\"ch:s=.25,rot=-.25\")\nax2 = plt.twinx()\nsns.pointplot(x = 'Location_State', y = 'Salary_Mean', data = job,order = state_count_list,ax=ax2, linestyles=[\"--\"])\nax2.set(ylabel = 'Average Salary ($ k\/year)')\nplt.title(\"Job No. and Average Salary Per State\", size = 20)\nplt.show()","3a5da176":"city_15_list = job.groupby('Location')['Location'].count().sort_values(ascending = False).head(15)\ncity_count_list_15 = [x for x in city_15_list.index]\n\n# Show both the job # and average salaries of each city\nplt.figure(figsize = (20,8))\nstate_mean = job.groupby('Location')['Salary_Mean'].mean()\nsns.countplot(x='Location',data=job, order = city_count_list_15, palette=\"ch:s=.25,rot=-.25\")\nax2 = plt.twinx()\nsns.pointplot(x = 'Location', y = 'Salary_Mean', data = job, alpha = 0.1, linestyles=[\"--\"],order = city_count_list_15,ax=ax2)\nax2.set(ylabel = 'Average Salary ($ k\/year)')\nplt.title(\"Job No. and Average Salary Per City (Top 15)\", size = 20)\nplt.show()","91f37839":"# Create a count Count dataframe to count the job numbers by each company\ncompany_list = sorted(job.groupby('Company Name')['Company Name'].count().items(), key= lambda x:x[1], reverse = True)\ntop20_company = company_list[0:20]\ncompany_count_list = [x[0] for x in top20_company]\n\nCompany_df = job.groupby(['Company Name','Job Title'])['Job Title'].count().to_frame('Count').reset_index()\nCompany_df = Company_df[Company_df['Company Name'].isin(company_count_list)]\nCompany_df['Country'] = 'US'\nCompany_df_sort = Company_df.sort_values('Count', ascending = False)","bcf677e6":"# Create a count Count dataframe to count the job numbers by each company\n#Company_df = job.groupby(['Company Name','Job Title'])['Job Title'].count().to_frame('Count').reset_index()\n#Company_df['Country'] = 'US'\n#Company_df_sort = Company_df.sort_values('Count', ascending = False)\n\n# Use the Count dataframe to draw the treemap\nfig = px.treemap(Company_df_sort, path=['Country', 'Company Name','Job Title'], values='Count',\n                 color= 'Count'\n                ,color_continuous_scale='Blues', title = 'Top 50 Hirers')\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","68211f88":" len(sorted(job.groupby('Company Name')['Company Name'].count().items(), key= lambda x:x[1], reverse = True))","3da74b3c":"company_s = job.groupby(['Company Name'])['Company Name'].count().sort_values(ascending = False)[:10]\ncomapny_l = [x for x in company_s.index if x != '-1' ]\nplt.figure(figsize = (18,6))\nsns.countplot(x='Company Name', data=job, order = comapny_l, palette=\"ch:s=.25,rot=-.25\")\nax2 = plt.twinx()\nsns.pointplot(x = 'Company Name', y = 'Salary_Mean', data = job, alpha = 0.1, linestyles=[\"--\"],order = comapny_l,ax=ax2)\nax2.set(ylabel = 'Average Salary ($ k\/year)')\nplt.title(\"Job No. and Average Salary of Top 10 Hirers\", size = 20)\nplt.show()","ea49441c":"company_s = job.groupby(['Company Name'])['Company Name'].count().sort_values(ascending = False)[:10]\ncomapny_l = [x for x in company_s.index if x != '-1' ]\ntemp=job[job['Company Name'].isin(comapny_l)]\ndf_top10_company = temp.groupby('Company Name').first().reset_index()\ndf_top10_company[['Company Name','Location','Headquarters','Size','Founded','Type of ownership','Revenue','Sector','Industry','Competitors']]","4e2ace55":"# Create a count Count dataframe to count the job numbers by each city\nSector_df = job.groupby(['Sector','Industry'])['Industry'].count().to_frame('Count').reset_index()\nSector_df = Sector_df [Sector_df ['Industry']!= '-1']\nSector_df['Country'] = 'US'\n\n# Use the Count dataframe to draw the treemap\nfig = px.treemap(Sector_df, path=['Country', 'Sector', 'Industry'], values='Count',\n                 color= 'Count'\n                ,color_continuous_scale='Blues', title = 'Job No. by Sector')\nfig.data[0].textinfo = 'label+text+value+percent parent'\nfig.show()","f4d8ff31":"sector_s = job.groupby(['Sector'])['Sector'].count().sort_values(ascending = False)[:11]\nsector_l = [x for x in sector_s.index if x != '-1' ]\nplt.figure(figsize = (18,6))\nsns.countplot(x='Sector', data=job, order = sector_l, palette=\"ch:s=.25,rot=-.25\")\nax2 = plt.twinx()\nsns.pointplot(x = 'Sector', y = 'Salary_Mean', data = job, alpha = 0.1, linestyles=[\"--\"],order = sector_l,ax=ax2)\nax2.set(ylabel = 'Average Salary ($ k\/year)')\nplt.title(\"Job No. and Average Salary of Top 10 Sectors\", size = 20)\nplt.show()\n","8139736d":"plt.figure(figsize = (18,6))\njob_4 = job[job['Sector'].isin(sector_l)]\njob_4 = job_4[job_4['Salary_Mean'] != -1 ]\nsns.swarmplot(y = job_4['Salary_Mean'], x = job_4['Sector'], order = sector_l)\nplt.title(\"Average Salary of Top 10 Sectors\", size = 20)\nplt.show()","11fdc78d":"# Download stopwords for NLP analysis\nnltk.download('stopwords') \nstopwords = nltk.corpus.stopwords.words('english')","2636ec79":"# Set up a set for removal\nremove_these = set(stopwords + list(string.punctuation) + list(string.digits))","895c970d":"# Check most frequent words in job titles after removing unwanted words\njt_lst = job[job['Job Title'] != '-1']['Job Title'].tolist()\nword_list = []\nfor item in jt_lst:\n    content = nltk.word_tokenize(item)\n    for word in content:\n        if word.lower() not in remove_these and word.lower() != 'data'and word.lower() != 'analyst' and word.lower() != 'data analyst':\n            word_list.append(word.lower())\nfreq = nltk.FreqDist(word_list)\nplt.figure(figsize = (10,4))\nfreq.plot(20)","8162f188":"text = \"\"\nfor item in word_list:\n    if item.lower() not in remove_these and item.lower() != 'data'and item.lower() != 'analyst' and item.lower() != 'data analyst':\n        text += \" \"+str(item.lower())\n\nwordcloud = WordCloud(width = 800, height = 400).generate(text)\nplt.figure(figsize = (20,10))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","d904f34b":"nlp = spacy.load('en', tagger=False, parser=False, matcher=False)","301339ab":"# To extract NERs from all job titles and save in a dictionary\n# jt_lst = job[job['Job Title'] != '-1']['Job Title'].tolist()\n# word_list = []\njob_title_ner = {}\n#c=0\nfor item in jt_lst:\n    token = nlp(item)\n    for ent in token.ents:      \n        job_title_ner.setdefault(ent.label_ , []).append(ent.text) \n#    c = c+1\n#    print (c)\n","eb9e8893":"job_title_ner.keys()","0b8bb792":"collections.Counter(job_title_ner['ORG']).most_common(10)","d7db5dda":"skill_word_list = ['sql','sap','sas','python','erp','bi','microsoft','dynamics','usmft','excel','dax','latam','tableau','efl','java','mongo','aws','vba','oracle']","b8078a38":"skill_word_count = []\nfor word in word_list:\n    if word in skill_word_list:\n        skill_word_count.append(word)\n\ncollections.Counter(skill_word_count).most_common(10)\nfreq_skills = nltk.FreqDist(skill_word_count)\nplt.figure(figsize = (10,4))\nfreq_skills.plot(10)","e4359fb6":"# Check most frequent words in job titles after removing unwanted words\njd_lst = job[job['Job Description'] != '-1']['Job Description'].tolist()\nword_list_jd = []\nfor item in jd_lst:\n    content = nltk.word_tokenize(item)\n    for word in content:\n        if word.lower() not in remove_these and word.lower() != 'data'and word.lower() != 'analyst' and word.lower() != 'data analyst':\n            word_list_jd.append(word.lower())\nfreq = nltk.FreqDist(word_list_jd)\nplt.figure(figsize = (10,4))\nfreq.plot(20)","e020a662":"text_jd = \"\"\nfor item in word_list_jd:\n    text_jd += \" \"+str(item.lower())\n\nwordcloud = WordCloud(width = 800, height = 400).generate(text_jd)\nplt.figure(figsize = (20,10))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","be900b15":"#jd_lst = job[job['Job Description'] != '-1']['Job Description'].tolist()\n#word_list_jd = []\njob_description_ner = {}\n#c=0\nfor item in jd_lst:\n    token = nlp(item)\n    for ent in token.ents:      \n        job_description_ner.setdefault(ent.label_ , []).append(ent.text) \n#    c = c+1\n#    print (c)\n","88c8cbbb":"job_description_ner.keys()","645feb2d":"collections.Counter(job_description_ner['ORG']).most_common(10)","6fcb2523":"skill_word_list = ['sql','sap','sas','python','erp','bi','microsoft','dynamics','usmft','excel','dax','latam','tableau','efl','java','mongo','aws','vba','oracle','spss','javascript','visio','access','git','github','python\/r'       ]","6f61bbc6":"skill_word_count_jd = []\nfor word in word_list_jd:\n    if word in skill_word_list:\n        skill_word_count_jd.append(word)\n\ncollections.Counter(skill_word_count_jd).most_common(10)\nfreq_skills = nltk.FreqDist(skill_word_count_jd)\nplt.figure(figsize = (10,4))\nfreq_skills.plot(20)","96b106b5":"# Education:\nprint('Times of GED mentioned: ' + str(collections.Counter(word_list_jd)['ged']))\nprint('Times of Bachelor mentioned: ' + str(collections.Counter(word_list_jd)['bachelor']+collections.Counter(word_list_jd)['undergraduate']))\nprint('Times of Master mentioned: ' + str(collections.Counter(word_list_jd)['master']+collections.Counter(word_list_jd)['postgraduate']))\nprint('Times of Doctor mentioned: ' + str(collections.Counter(word_list_jd)['dr.']+collections.Counter(word_list_jd)['dr']))","ae1063ad":"# Experience:\ncollections.Counter(job_description_ner['DATE']).most_common()\nnew_lst = []\nfor word in job_description_ner['DATE']:\n    if 'year' in word:\n        new_lst.append(word)\n\n# to re-classify the experience years catagory\nyears = collections.Counter(new_lst).most_common()\nnew_year_dict = {'1':0, '2':0, '3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\nfor tup in years:\n    if '1'in tup[0]:\n        new_year_dict['1'] += tup[1]\n    elif '2'in tup[0]:\n        new_year_dict['2'] += tup[1]\n    elif '3'in tup[0]:\n        new_year_dict['3'] += tup[1]\n    elif '4'in tup[0]:\n        new_year_dict['4'] += tup[1]        \n    elif '5'in tup[0]:\n        new_year_dict['5'] += tup[1]\n    elif '6'in tup[0]:\n        new_year_dict['6'] += tup[1]\n    elif '7'in tup[0]:\n        new_year_dict['7'] += tup[1]\n    elif '8'in tup[0]:\n        new_year_dict['8'] += tup[1]\n    elif '9'in tup[0]:\n        new_year_dict['9'] += tup[1]\n\n\nyears_s = pd.Series(new_year_dict)\n\nplt.figure(figsize = (10,5))\nsns.barplot(x= years_s.index, y = years_s.values,  palette=\"ch:s=.25,rot=-.25\")\nplt.xlabel('Years of Experience')\nplt.ylabel('Times appeared in Job Descriptions')\nplt.title(\"Years of Experience Mentioned in Job Descriptions\", size = 15)\nplt.show()\n","f01e18c8":"'Support', 'team','experience' seem to be highly frequently mentioned words in JDs. ","67f6590e":"As we learned from the top hirers, IT services and Staffing & Outsourcing companies stand for a big chunck of the total job market.","7446302e":"Then we are going to look at the mean salary distribution in different states.","dea7c074":"> Then we move on to job descriptions:","0fd838a4":"Then we want to check the most_common skills mentioned under the tag 'ORG':","6ddae2e2":"From the above, we can see that among all companies (1502):\nthere is one company (staffigo Technico Services) offering 58 openings; and nine companies with 20+ positions.\nThe jobs are sparsely distributed among different companies.","2f5d7069":"Finally, we are interested to check the general skills needed for DA jobs. We will look into the skills mentioned in:\n1. Job Titles;\n2. Job Descriptions","9a2fa798":"From the above Treemap, we can see that among the 19 states which offer data analyst jobs:\n* The top 5 states: Califonia, Texas, New York, Illinois, Pennsylvania offer more than 50% of total jobs.\n* Califonia and Taxas are the most significant job market at the state level:\n    Four big cities (San Jose, San Francisco, San Diego and Los Angeles) of CA are the major job contributors. Also, about 50% of jobs are in numerous CA cities.\n    Jobs in TX are mainly from 6 big cities (Austin, Houston, Dallas, San Antonio) \n* New York City & Chicago are the most significant job markets at the city level.","020c8a7c":"Now we are checking the top 50 companies in terms of job listing numbers:","9fbdb457":"We noticed that 'Senior' as the most frequently mentioned word in job titles.\nThen we will try to find out the most frequently mentioned skills in job titles:","3a398d47":"Data Importation","824210d4":"By observation, we noticed some additional tech skills to the skill_word_list:","084d9a17":"Now we want to contrast the job numbers by the average salary of the states \/ cities:","4067c705":"# Analysis ","a5b70abc":"The above shows:\nSalary Lower bound: the majority are within 40-60k, the average is 54k,\nSalary Upperbound: the majority are within 70-100k; the standard is 90k.\nWe also notice that the upper bound variation (std about 30) is more expansive than lower bounds (std about 20).\n\nSalary Range: the majority are within 25-45k, the average is 35k.\nSalary Mean: the majority are within 55-80k; the average is 72k.","010c5208":"1-5 years'experience are mostly common-mentioned requirement in job descriptions.","93daad44":"From above analysis we can see that SQL\/Excel\/Tableau\/Python\/BI are all very popular skills mentioned in JDs.","ea12dd7b":"WordCloud for job titles:\n","831cadca":"The above shows that jobs in cities (San Jose, San Francisco, San Diego and Los Angeles) of Califonia have higher average salaries.","3bbca448":"# Content:\n\nPreparation:\n\n* Package importation\n* Data importation\n* Data Observation & Cleaning\n\nAnalysis:\n\n* Salary\n* Location\n* Top Hirers\n* Skills\n\nSummary","db9004fe":"# Summary\n\nWe gained a general picture of the US job market for data analysts through the dataset analysis. \n\nFirstly, **Salary-wise**, the average salary of most jobs is within 55-80k, the average is 72k; companies typically gave out a salary range within 25-45k, the average is 35k. \n\n**Geographically**, all jobs are located in 19 states, Califonia, Texas, New York provides more than 50% of total employment; New York City & Chicago are the most significant job markets at the city level. \n\nAlmost all **top hirers** (like:Staffigo\/Diverse Lynx\/Kforce etc., except Apple) are IT staffing companies. So it is reasonable to assume that the real demand for DA jobs is from their clients; on the other hand, job seekers may consider getting in touch with these agents to get in the talent pool. \n\nFinally, job titles and descriptions show that some **hard tech skills** are popular, such as SQL\/Tableau\/Power BI\/Excel, so that job seeker could consider horning the skills beforehand. Besides, a bachelor's degree and 1-5 years' experience are generally preferred as well.\n\n","46c24533":"* Top Hirers","f7630bba":"We can see from above that SQL, BI, SAP, Python seem to be the most commonly mentioned skills in job titles","ba129cd4":"* Location","e2ba53c1":"Package Importation:","b7dea6c8":"* Salary","ed19f8ea":"Then we are going to check the mean salary distribution in different cities.","8a7de1b9":"Then we want to contrast the job numbers by the average salary of cities:","9e99b9b4":"The Average Salary of top hirer Staffigo Technical Service is lower than other companies, as the openings are mostly for junior DAs. \nApple Jobs are with higher average salaries.\nHere are the links to the website of the top 5 hirers:\n\n* Staffigo: https:\/\/www.staffigo.com\/it-staffing.html\n* Diverse Lynx: https:\/\/www.diverselynx.com\/\n* Kforce:https:\/\/www.kforce.com\/\n* Lorven Technologies Inc: https:\/\/www.lorventech.com\/\n* Mondo: https:\/\/mondo.com\/\n\nThe research finds out that almost all top hirers are IT staffing companies, so it is reasonable to assume that the real demand for DA jobs are from their clients. And since staffing companies stand for a large proportion, no further digging in company-related info, such as size\/revenue, etc.","0aeca7d4":"# Introduction\n\nData analytics jobs are becoming trendy nowadays. A general understanding of the job market can help job seekers navigate the job search and career preparation. The purpose of exploring data analysis is to answer some questions with data for data analyst dream chasers:\n\n* How are salaries?\n* Where are the jobs?\n* Who are the top hirers?\n* What skills\/education\/years of experience are needed?\n\nThis study is based on the dataset of data-analyst-jobs, created by picklesueat. The dataset contains 2253 job listings for data analyst positions in the US from Glassdoor. Based on the data features analysis, such as Salary Estimate, Location, Company Rating, Job Description etc., some recommendations are generated at the end of the study.\n\nKeywords: EDA, Visualization, NLP","c38554e0":"Noticed from above, companies in IT\/ Business Services\/Health Care offer higher average salaries.","9d958642":"We continue to check other observations (education \/ experience requirments):","f6339aba":"Data Cleaning","9a6ddcdf":"Data Observation:","8c4a8d81":"By observations, we noticed that some hard tech skills are mentioned:\n* SQL\n* SAP\n* Python\n* SAS\n* BI\n* ERP\n* Microsoft Dynamics\n* USMTF\n* Excel\n* DAX\n* LATAM\n* Tableau\n* AB Testing\n* EFL\n* Java\n* Mongo\n* AWS\n* VBA\n* Oracle\nSince we identified them, then we are going to check how often they appear in the job titles.","4c2d2b73":"First we will have a look at the job numbers by state:","d78863e7":"* Skills","2d74147c":"There are 253 cities with DA jobs, and New York is the city's biggest job market. \nSalary-wise, jobs in the cities of Califonia has significantly higher salaries compared with other cities.","71285b9a":"Top 10 Hirers' Company Profile:","a0935604":"Then let have a look at the salaries of the top 10 hirers:","e3d08be3":"# Preparation","4e7ff2c4":"We will first check job titles:","f0f466b3":"We can see that, the column consist salary ranges strings. To make the data comparable and easy to analyze, the code below add 4 columns: 'Salary_From', 'Salary_To', 'Salary_Mean', 'Salary_Range'","53142f67":"We can see that the states of Califonia, Illinois are leading the salaries.","aaf9bc75":"From the above, we can see that Califonia has the most job offerings and the highest average salaries; Texas jobs have the lowest average wages among the top 5 job supply states. ","18fccd7c":"Then we catagorize companies by sectors","8efeacda":"Now we have a general idea of the salaries of the data analyst jobs and how salaries differentiate among locations. In the following sections, we will also look at the wages in detail (combined with job numbers) according to different places, companies, sectors."}}