{"cell_type":{"1a81893e":"code","004388d8":"code","586dbba0":"code","534aef06":"code","8c1c58b4":"code","32b5548e":"code","26e5a8bf":"code","c2df062a":"code","04353397":"markdown","8a1c6ef9":"markdown","389ed1e8":"markdown","fb3c02d7":"markdown","6b770396":"markdown"},"source":{"1a81893e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","004388d8":"!pip install tensorflow==1.13.1\nimport os\nimport numpy as np\n# import pandas as pd\nimport tensorflow as tf\n\nLR = 0.01\nBatchSize = 50\nEPOCH = 2\nprint(tf.__version__)","586dbba0":"def load_data(filefolder):\n    ori_filefolder = filefolder\n    filefolder = '..\/input\/ve445-2019-fall-project\/'+os.path.join(filefolder,filefolder)\n    data = np.load(os.path.abspath(filefolder+ '\/names_onehots.npy'), allow_pickle=True).item()\n    data = data['onehots']\n    if ori_filefolder == 'test':\n        label_filename = filefolder + '\/output_sample.csv'\n#         label = pd.read_csv(os.path.abspath(filefolder + '\/output_sample.csv'), sep=',')\n    else:\n        label_filename = filefolder + '\/names_labels.csv'\n#         label = pd.read_csv(os.path.abspath(filefolder + '\/names_labels.csv'), sep=',')\n    label = []\n    with open(label_filename,'r') as f:\n        header = f.readline().replace('\\n','').split(',')\n        if header[0]=='Label':\n            label_index = 0\n        else:label_index = 1\n        for line in f.readlines():\n            line = line.replace('\\n','').split(',')\n            label.append(int(line[label_index]))\n    label = np.array(label)\n#     label = label['Label'].values\n    return data, label","534aef06":"# data,label = load_data('test')\n# print(data.shape)","8c1c58b4":"def net(onehots_shape):  # [73,398]\n    if not isinstance(onehots_shape, list):\n        onehots_shape = list(onehots_shape)\n    input = tf.placeholder(tf.float32, [None] + onehots_shape, name='input')\n    input = tf.reshape(input, [-1] + onehots_shape + [1])\n    # input = tf.reshape(input, [None, 73, 398, 1])\n    label = tf.placeholder(tf.int32, [None], name='label')\n    label = tf.one_hot(label, 2)\n    conv1 = tf.keras.layers.Conv2D(32, 5, 1, 'same', activation=tf.nn.relu)(input)\n    pool1 = tf.keras.layers.MaxPool2D(2, 2)(conv1)\n    conv2 = tf.keras.layers.Conv2D(32, 3, (1, 2), padding='same', activation=tf.nn.relu)(pool1)\n    pool2 = tf.keras.layers.MaxPool2D(2, 2)(conv2)\n    flat = tf.reshape(pool2, [-1, 18*50*32])\n    output = tf.keras.layers.Dense(2, name='output')(flat)\n    loss = tf.losses.softmax_cross_entropy(onehot_labels=label, logits=output)  # compute cost\n    train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n    accuracy = tf.metrics.accuracy(  # return (acc, update_op), and create 2 local variables\n        labels=tf.argmax(label, axis=1), predictions=tf.argmax(output, axis=1), )[1]\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())  # the local var is for accuracy_op\n    return init_op, train_op, loss, accuracy","32b5548e":"train_x, train_y = load_data('train')\nvalid_x, valid_y = load_data('validation')\ntest_x, test_y = load_data('test')\ninit_op, train_op, loss, accuracy = net(train_x.shape[1:])\nsess = tf.Session()\nsess.run(init_op)\n\ntrain_size = train_x.shape[0]\nfor epoch in range(EPOCH):\n    for i in range(0, train_size, BatchSize):\n        b_x, b_y = train_x[i:i + BatchSize], train_y[i:i + BatchSize]\n        _, loss_ = sess.run([train_op, loss], {'input:0': b_x, 'label:0': b_y})\n    if epoch % 1 == 0:\n        accuracy_ = 0\n        for i in range(0, valid_x.shape[0], BatchSize):\n            b_x, b_y = valid_x[i:i + BatchSize], valid_y[i:i + BatchSize]\n            accuracy_ += sess.run(accuracy, {'input:0': b_x, 'label:0': b_y})\n        accuracy_ = accuracy_ * BatchSize \/ valid_x.shape[0]\n        print('epoch:', epoch, '| train loss: %.4f' % loss_, '| valid accuracy: %.2f' % accuracy_)\naccuracy_ = 0\nfor i in range(0, test_x.shape[0], BatchSize):\n    b_x, b_y = test_x[i:i + BatchSize], test_y[i:i + BatchSize]\n    accuracy_ += sess.run(accuracy, {'input:0': b_x, 'label:0': b_y})\naccuracy_ = accuracy_ * BatchSize \/ test_x.shape[0]\nprint('test accuracy:%.2f' % accuracy_)\n\nsaver = tf.train.Saver()\nsaver.save(sess, '.\/weights\/model')\nsess.close()","26e5a8bf":"def load_model():\n    data = np.load('..\/input\/ve445-2019-fall-project\/test\/test\/names_onehots.npy', allow_pickle=True).item()\n    onehots = data['onehots']\n    name = data['names']\n    data_size = onehots.shape[0]\n    \n    _, _, loss, accuracy = net(train_x.shape[1:])\n    sess = tf.Session()\n    saver = tf.train.Saver()\n    saver.restore(sess, '.\/weights\/model')\n\n    prediction = []\n    for i in range(0, data_size, BatchSize):\n        test_output = sess.run('output\/BiasAdd:0', {'input:0': onehots[i:i + BatchSize]})\n        pred = np.argmax(test_output, axis=1)\n        prediction.extend(list(pred))\n    sess.close()\n    f = open('output_5130309315.csv', 'w')\n    f.write('Chemical,Label\\n')\n    for i, v in enumerate(prediction):\n        f.write(name[i] + ',%d\\n' % v)\n    print('predict all')\n    f.close()\ntf.reset_default_graph()\nload_model()","c2df062a":"# for node in sess.graph_def.node:\n#     print(node)","04353397":"<a href='.\/output_5130309315.csv'>prediction<\/a>","8a1c6ef9":"# load model weight & predict","389ed1e8":"# load data","fb3c02d7":"# training","6b770396":"# network building"}}