{"cell_type":{"4a61c25c":"code","34b7b394":"code","7e056c61":"code","fe38ad3d":"code","2c394776":"code","889b08ea":"code","5a230eae":"code","1e8cfe3e":"markdown","de3d0d9c":"markdown","5e91d695":"markdown","e0a210b2":"markdown","86edc940":"markdown","db37c715":"markdown"},"source":{"4a61c25c":"import numpy as np","34b7b394":"# f = w*x --> f = 2*x\nX = np.array([1,2,3,4],dtype=np.float32)\ny = np.array([2,4,6,8], dtype=np.float32)\n\nw = 0.0\n\n# model prediction\ndef forward(x):\n    return w*x\n\n# loss = MSE\ndef loss(y,y_predicted):\n    return ((y_predicted-y)**2).mean()\n\n\n# gradient\n# MSE = 1\/N * (w*x - y)**2\n# dJ\/dw = 1\/N 2x (w*x - y)\ndef gradient(x,y,y_predicted):\n    return np.dot(2*x, (y_predicted-y)).mean()\n\n\nprint(f'Prediction before training: f(5) = {forward(5):.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 10\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = forward(X)\n    \n    # loss\n    l = loss(y,y_pred)\n    \n    # gradients\n    dw = gradient(X,y,y_pred)\n    \n    # update weights\n    w -= learning_rate * dw\n    \n    if epoch % 1==0:\n        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n        \n\n\nprint(f'Prediction after training: f(5) = {forward(5):.3f}')","7e056c61":"import torch\n# f = w*x --> f = 2*x\nX = torch.tensor([1,2,3,4],dtype=torch.float32)\ny = torch.tensor([2,4,6,8], dtype=torch.float32)\n\nw = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n\n# model prediction\ndef forward(x):\n    return w*x\n\n# loss = MSE\ndef loss(y,y_predicted):\n    return ((y_predicted-y)**2).mean()\n\n\nprint(f'Prediction before training: f(5) = {forward(5):.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 10\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = forward(X)\n    \n    # loss\n    l = loss(y,y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl\/dw\n    \n    # update weights\n    with torch.no_grad():\n        w -= learning_rate * w.grad\n    \n    # zero gradients\n    w.grad.zero_()\n    if epoch % 1==0:\n        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n        \n\n\nprint(f'Prediction after training: f(5) = {forward(5):.3f}')","fe38ad3d":"import torch.nn as nn","2c394776":"import torch\n# f = w*x --> f = 2*x\nX = torch.tensor([1,2,3,4],dtype=torch.float32)\ny = torch.tensor([2,4,6,8], dtype=torch.float32)\n\nw = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n\n# model prediction\ndef forward(x):\n    return w*x\n\nprint(f'Prediction before training: f(5) = {forward(5):.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 10\n\nloss = nn.MSELoss()\noptimizer = torch.optim.SGD([w], lr = learning_rate)\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = forward(X)\n    \n    # loss\n    l = loss(y,y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl\/dw\n    \n    # update weights\n    optimizer.step()\n    \n    # zero gradients\n    optimizer.zero_grad()\n    \n    if epoch % 1==0:\n        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n        \n\n\nprint(f'Prediction after training: f(5) = {forward(5):.3f}')","889b08ea":"import torch\n# f = w*x --> f = 2*x\n\n# Input size have a certain size\nX = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\ny = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n\nX_test = torch.tensor([5], dtype= torch.float32)\nn_samples, n_features = X.shape\nprint(n_samples, n_features)\n\ninput_size = n_features\noutput_size = n_features\n\nmodel = nn.Linear(input_size, output_size)\n\nprint(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 10\n\nloss = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = model(X)\n    \n    # loss\n    l = loss(y,y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl\/dw\n    \n    # update weights\n    optimizer.step()\n    \n    # zero gradients\n    optimizer.zero_grad()\n    \n    if epoch % 1==0:\n        [w,b] = model.parameters()\n        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n        \n\n\nprint(f'Prediction after training: f(5) = {model(X_test).item():.3f}')","5a230eae":"import torch\n# f = w*x --> f = 2*x\n\n# Input size have a certain size\nX = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\ny = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n\nX_test = torch.tensor([5], dtype= torch.float32)\nn_samples, n_features = X.shape\nprint(n_samples, n_features)\n\ninput_size = n_features\noutput_size = n_features\n\nmodel = nn.Linear(input_size, output_size)\n\nclass LinearRegression(nn.Module):\n    \n    def __init__(self,input_dim,output_dim):\n        super(LinearRegression,self).__init__()\n        \n        self.lin = nn.Linear(input_dim,output_dim)\n    def forward(self,x):\n        return self.lin(x)\n\nmodel = LinearRegression(input_size, output_size)\n\nprint(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 10\n\nloss = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = model(X)\n    \n    # loss\n    l = loss(y,y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl\/dw\n    \n    # update weights\n    optimizer.step()\n    \n    # zero gradients\n    optimizer.zero_grad()\n    \n    if epoch % 1==0:\n        [w,b] = model.parameters()\n        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n        \n\n\nprint(f'Prediction after training: f(5) = {model(X_test).item():.3f}')","1e8cfe3e":"### Automatic loss and optimization","de3d0d9c":"## Linear Regression model,loss, and optimization automatic\n1. Design model (input, output size, forward pass)\n2. Construct loss and optimizer\n3. Training loop\n    - forward pass: compute prediction\n    - backward pass: gradients\n    - update weights","5e91d695":"### custom model","e0a210b2":"## Linear Regression manually but with Autograd","86edc940":"### automatic model","db37c715":"## Create model manually : Linear Regression"}}