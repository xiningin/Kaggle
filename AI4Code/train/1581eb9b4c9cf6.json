{"cell_type":{"a2087655":"code","27c1495a":"code","dd0c0c49":"code","f74261b5":"code","59b66cfb":"code","cf5ad47b":"code","62695d6b":"code","5feb87de":"code","298ea12d":"code","e1130fae":"code","f5b7cd76":"code","62cbda0f":"code","d7938741":"code","d179b70e":"code","5ceccfe3":"code","127346cb":"code","fb7f1a54":"code","f76e638c":"code","191dcd1e":"code","243c07e2":"code","62bb140e":"code","773cba12":"code","e8a994ef":"code","d25441c7":"code","fd9c6aef":"code","cd23bf89":"code","e3688b40":"code","1eaa4b12":"code","db8f094a":"code","d53676ee":"code","04b30610":"code","0d4c864f":"code","dd1a9f97":"code","e591b0d9":"code","a03bdcfe":"code","ea4b7c26":"code","1b1df383":"code","6fbb1524":"code","6c0ccfcd":"markdown","0d45022d":"markdown","5ccb45f8":"markdown","fc9af019":"markdown","54f323ef":"markdown","10a1db1e":"markdown","bf0d4325":"markdown","1ebbde25":"markdown","c15376df":"markdown","a2419baa":"markdown","88879f3c":"markdown","5b41ce7d":"markdown","21c66479":"markdown","eb08c6df":"markdown","d4b88f51":"markdown","217f14bc":"markdown","cd7a3d1d":"markdown","ce0d426c":"markdown","76591b52":"markdown","0b3be64f":"markdown","708396a9":"markdown","fa811b89":"markdown","4c0bd9d6":"markdown"},"source":{"a2087655":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27c1495a":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","dd0c0c49":"df.info()","f74261b5":"df.describe()","59b66cfb":"df.isnull().sum()","cf5ad47b":"df.shape","62695d6b":"df_1 = df[df.TotalCharges!=' ']\ndf_1.shape","5feb87de":"df_1.TotalCharges = pd.to_numeric(df_1.TotalCharges)","298ea12d":"df_1.info()","e1130fae":"df_1 = df_1.drop(['customerID'], axis='columns')","f5b7cd76":"def print_unique_col_values(df):\n       for column in df:\n            if df[column].dtypes=='object':\n                print(f'{column}: {df[column].unique()}')","62cbda0f":"print_unique_col_values(df_1)","d7938741":"df_1.replace('No internet service','No',inplace=True)\ndf_1.replace('No phone service','No',inplace=True)","d179b70e":"print_unique_col_values(df_1)","5ceccfe3":"binary_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\nfor col in binary_columns:\n    df_1[col].replace({'Yes': 1,'No': 0},inplace=True)","127346cb":"df_1.info()","fb7f1a54":"print_unique_col_values(df_1)","f76e638c":"features = df_1\nfeatures.info()","191dcd1e":"from sklearn.preprocessing import LabelEncoder\nle_gender = LabelEncoder()\nfeatures['gender_label'] = le_gender.fit_transform(features['gender'])\nfeatures = features.drop(['gender'], axis='columns')\nfeatures.head()","243c07e2":"features = pd.get_dummies(data=features, columns=['InternetService','Contract','PaymentMethod'])\nfeatures.info()","62bb140e":"features.head()","773cba12":"features.isnull().sum()","e8a994ef":"features.describe()","d25441c7":"features.corr()","fd9c6aef":"features[features.columns[1:]].corr()['Churn'][:].sort_values(ascending=False)","cd23bf89":"features.describe()","e3688b40":"from sklearn.preprocessing import MinMaxScaler\nfeatures_scaler = MinMaxScaler()\nfeatures = features_scaler.fit_transform(features)\nfeatures","1eaa4b12":"x = features\ny = df_1.Churn","db8f094a":"y.value_counts()","d53676ee":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(sampling_strategy='minority')\nx_sm, y_sm = smote.fit_resample(x, y)\n\ny_sm.value_counts()","04b30610":"x_sm.shape","0d4c864f":"y_sm.shape","dd1a9f97":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_params = {\n    'svm': {\n        'model': SVC(gamma='auto'),\n        'params' : {\n            'C': [1,10,20,30],\n            'kernel': ['rbf','linear','poly']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'n_estimators': [10,50,100]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1,5,10]\n        }\n    },\n    'KNN' : {\n        'model': KNeighborsClassifier(),\n        'params': {\n            'n_neighbors': [3,7,11,13]\n        }\n    }\n    \n}","e591b0d9":"from sklearn.model_selection import GridSearchCV\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(x_sm, y_sm)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_score = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_score","a03bdcfe":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)","ea4b7c26":"model = SVC(C=1, kernel='rbf')\nmodel.fit(x_train,y_train)\nmodel.score(x_test,y_test)","1b1df383":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sb\ny_predicted = model.predict(x_test)\ncm = confusion_matrix(y_test,y_predicted)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True, fmt=\".1f\")\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","6fbb1524":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_predicted))","6c0ccfcd":"Normalization data using minmax","0d45022d":"Using one hot encoder to change categorical value into numerical value with create new column every category using pandas get_dummies","5ccb45f8":"Many machine learning alghoritm make good predictions","fc9af019":"# 3. Predict using Machine Learning Alghoritm","54f323ef":"Replace 'No internet service' and 'No phone service' to 'No' because that basically the same thing","10a1db1e":"List all data that have 'yes' and 'no' value to 1 and 0","bf0d4325":"Check the type of the dataset","1ebbde25":"# 2. Handling Imbalance Data using SMOTE","c15376df":"# 1. Explora Data & Prepare Data","a2419baa":"# Telco Customer Churn Prediction Using Machine Learning Alghoritm - 100% accuracy","88879f3c":"See the correlation of every columns","5b41ce7d":"Many columns have data type object that we need to change to numeric data type","21c66479":"See the correlation features column with column 'Churn'","eb08c6df":"TotalCharges column have value that blank string, so we remove data that have TotalCharges blank string","d4b88f51":"## Step for Predcition\n### 1. Explora Data & Prepare Data\n### 2. Handling Imbalance Data\n### 3. Predict using Machine Learning Alghoritm","217f14bc":"Check that TotalChanges column have been change to numeric type","cd7a3d1d":"Change 'Male' and 'Female' into 1 and 0 value","ce0d426c":"Change data type to numeric","76591b52":"Choosing one machine learning alghoritms to make confusion matrix and classificaation report","0b3be64f":"create function to print unique data type","708396a9":"check column data that have null value","fa811b89":"Drop customerID that not useful for features","4c0bd9d6":"Data label is not balance so we handling using SMOTE to create some data to make data balance"}}