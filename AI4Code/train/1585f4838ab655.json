{"cell_type":{"24af3edb":"code","d8f55350":"code","14358030":"code","0d0b5ef0":"code","d7ec6d87":"code","d7677a76":"code","9a8fe903":"code","486a53e7":"code","8cf973a6":"code","7ca25b53":"code","8ce5857c":"code","c9e1c06c":"code","3f5b946f":"code","d751c13a":"code","a71a8309":"code","61b4aa33":"code","2115f690":"code","d742e478":"code","70663c2f":"code","61915aa2":"code","7e877c11":"code","30121acc":"code","02b5c5ef":"code","f8afcfb4":"code","3cc077d6":"code","21237796":"code","640086ed":"code","3aa72764":"code","5b792c57":"code","b912fc69":"markdown","7e444f0d":"markdown","082849db":"markdown","b3845ebc":"markdown","9b6c32a8":"markdown"},"source":{"24af3edb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8f55350":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","14358030":"df","0d0b5ef0":"df.shape","d7ec6d87":"df.drop(columns='Unnamed: 32', inplace=True)","d7677a76":"X = df.iloc[:,2:].values","9a8fe903":"X.shape","486a53e7":"y=df['diagnosis']","8cf973a6":"y.shape","7ca25b53":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","8ce5857c":"X = scaler.fit_transform(X)","c9e1c06c":"from sklearn.model_selection import train_test_split","3f5b946f":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","d751c13a":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a71a8309":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=13,n_jobs=-1)","61b4aa33":"knn.fit(X_train,y_train)","2115f690":"y_pred = knn.predict(X_test)","d742e478":"from sklearn.metrics import accuracy_score","70663c2f":"accuracy_score(y_pred,y_test)","61915aa2":"results = []\nfor i in range(1,25):\n    knn = KNeighborsClassifier(n_neighbors=i,n_jobs=-1)\n    knn.fit(X_train,y_train)\n    y_pred=knn.predict(X_test)\n    results.append(accuracy_score(y_pred,y_test))","7e877c11":"max_accuracy = max(results)\nresults.index(max_accuracy)+1","30121acc":"print(\"highest accuracy = \",max_accuracy)\nprint(\"n_neighbors = \",results.index(max_accuracy)+1)","02b5c5ef":"from sklearn.tree import DecisionTreeClassifier\nclf=DecisionTreeClassifier(max_depth=4)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)","f8afcfb4":"accuracy_score(y_pred,y_test)","3cc077d6":"param={\n    \"criterion\":[\"gini\",\"entropy\"],\n    \"max_depth\":[1,2,3,4,5,None]\n}","21237796":"from sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(clf,param_grid=param,cv=10,n_jobs=-1)\ngrid.fit(X_train,y_train)\ny_pred = grid.predict(X_test)","640086ed":"grid.best_estimator_","3aa72764":"grid.best_score_","5b792c57":"accuracy_score(y_pred,y_test)","b912fc69":"### For n_neighbors=7, we are getting the highest accuracy in KNN.","7e444f0d":"## we should definitly use KNN as it's accuracy is 99%","082849db":"### DecisionTreeClassifier didn't performed well with an accuracy_score of 94% as compaired with KNN.","b3845ebc":"## Let's try with Decision Tree Classifier","9b6c32a8":"### Trying different n_neighbors values to get the best result."}}