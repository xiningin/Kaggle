{"cell_type":{"f0312b43":"code","04971c4f":"code","da572623":"code","42034ba9":"code","a5deb6f5":"code","985305f1":"code","3312f922":"code","84d7e9b7":"code","ec602307":"code","846a5735":"code","7215f61e":"code","b1e53eab":"code","72967dd8":"code","3aec231e":"code","37063183":"code","0c5b528c":"code","5615eec7":"code","dee4350e":"code","939bff25":"code","351e4975":"code","8127eaa9":"code","b1275b0a":"code","fbd64346":"code","582e4433":"code","374b0d6f":"code","59f23a07":"code","fefdcca8":"code","294392f8":"code","7a2594ea":"code","3c244136":"markdown","d622ee3b":"markdown","ebfac418":"markdown","8922d04f":"markdown","ca74876d":"markdown","4db3c77b":"markdown","72e33717":"markdown"},"source":{"f0312b43":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","04971c4f":"movie=pd.read_csv(r'\/kaggle\/input\/movie-for-forever\/Movie_regression.csv')\nmovie.head()","da572623":"movie.info()","42034ba9":"movie.shape","a5deb6f5":"movie.describe()","985305f1":"round((movie.isnull().sum() * 100 \/ len(movie)),2)","3312f922":"\nsns.distplot(movie['Time_taken'])\nplt.show()","84d7e9b7":"#Encode categorical data\ndummy = pd.get_dummies(movie[[\"Genre\",\"3D_available\"]]).iloc[:,:-1]\nmovie = pd.concat([movie,dummy], axis=1)\nmovie = movie.drop([\"Genre\",\"3D_available\"], axis=1)\nmovie.shape","ec602307":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nit = IterativeImputer(estimator=LinearRegression())\nnewdata_lr = pd.DataFrame(it.fit_transform(movie))\nnewdata_lr.columns = movie.columns\nnewdata_lr.head()","846a5735":"import scipy.stats as stats\nstats.ttest_ind(newdata_lr.Time_taken,movie.Time_taken,nan_policy='omit')","7215f61e":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nit = IterativeImputer(estimator=RandomForestRegressor(random_state=42))\nnewdata_rfr = pd.DataFrame(it.fit_transform(movie))\nnewdata_rfr.columns = movie.columns\nnewdata_rfr.head()","b1e53eab":"import scipy.stats as stats\nstats.ttest_ind(newdata_rfr.Time_taken,movie.Time_taken,nan_policy='omit')","72967dd8":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=tree.DecisionTreeRegressor(random_state=42))\nnewdata_bg = pd.DataFrame(it.fit_transform(movie))\nnewdata_bg.columns = movie.columns\nnewdata_bg.head()","3aec231e":"import scipy.stats as stats\nstats.ttest_ind(newdata_bg.Time_taken,movie.Time_taken,nan_policy='omit')","37063183":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=AdaBoostRegressor(random_state=42))\nnewdata_abc = pd.DataFrame(it.fit_transform(movie))\nnewdata_abc.columns = movie.columns\nnewdata_abc.head()","0c5b528c":"import scipy.stats as stats\nstats.ttest_ind(newdata_abc.Time_taken,movie.Time_taken,nan_policy='omit')","5615eec7":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=GradientBoostingRegressor(random_state=42))\nnewdata_gbr = pd.DataFrame(it.fit_transform(movie))\nnewdata_gbr.columns = movie.columns\nnewdata_gbr.head()","dee4350e":"import scipy.stats as stats\nstats.ttest_ind(newdata_gbr.Time_taken,movie.Time_taken,nan_policy='omit')","939bff25":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\nfrom sklearn import tree\nit = IterativeImputer(estimator=xgb.XGBRegressor(random_state=42))\nnewdata_xgb = pd.DataFrame(it.fit_transform(movie))\nnewdata_xgb.columns = movie.columns\nnewdata_xgb.head()","351e4975":"import scipy.stats as stats\nstats.ttest_ind(newdata_xgb.Time_taken,movie.Time_taken,nan_policy='omit')","8127eaa9":"# Compare with original v\/s modified ","b1275b0a":"movie.Time_taken.describe()","fbd64346":"newdata_lr.Time_taken.describe()","582e4433":"newdata_rfr.Time_taken.describe()","374b0d6f":"newdata_bg.Time_taken.describe()","59f23a07":"newdata_abc.Time_taken.describe()","fefdcca8":"newdata_gbr.Time_taken.describe()","294392f8":"newdata_xgb.Time_taken.describe()","7a2594ea":"print('Linear Regression         :',stats.ttest_ind(newdata_lr.Time_taken,movie.Time_taken,nan_policy='omit'))\nprint('RandomForest Regressor    :',stats.ttest_ind(newdata_rfr.Time_taken,movie.Time_taken,nan_policy='omit'))\nprint('Bagging Regressor         :',stats.ttest_ind(newdata_bg.Time_taken,movie.Time_taken,nan_policy='omit'))\nprint('AdaBoost Regressor        :',stats.ttest_ind(newdata_abc.Time_taken,movie.Time_taken,nan_policy='omit'))\nprint('GradientBoosting Regressor:',stats.ttest_ind(newdata_gbr.Time_taken,movie.Time_taken,nan_policy='omit'))\nprint('XGB Regressor             :',stats.ttest_ind(newdata_xgb.Time_taken,movie.Time_taken,nan_policy='omit'))","3c244136":"# Missing Value Treatment ","d622ee3b":"**If you find interesting, Do upvote, Follow & Share the notebook**\n![image.png](attachment:image.png)\n\nFollow : [Gaurav Dutta](https:\/\/www.kaggle.com\/gauravduttakiit)\n\n\n","ebfac418":"![image.png](attachment:image.png)","8922d04f":"# Conclusion ","ca74876d":"# Impute Missing Value with Machine Learning","4db3c77b":"We used following algorithms to maniputate missing values :\n- Linear Regression\n- RandomForest Regressor\n- Bagging Regressor\n- AdaBoost Regressor\n- GradientBoosting Regressor\n- XGB Regressor\n\nBut we found, AdaBoost Regressor works the best with max p value & t value ","72e33717":"We will use Machine learning Algorithm to compute the missing value "}}