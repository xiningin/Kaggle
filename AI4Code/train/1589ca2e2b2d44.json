{"cell_type":{"a56b9008":"code","0d613e37":"code","19aa9a4a":"code","ac652b66":"code","fdc3ee15":"code","e7324777":"code","1efbab21":"code","69d3cb3a":"code","114e7e9c":"code","df63a434":"code","bd363102":"code","c6a14fd5":"code","898d5317":"code","85004d3f":"code","36f872e1":"code","0ba0a4e5":"markdown","4e61928a":"markdown","bfe3419b":"markdown","f7b91c6c":"markdown","4f8ea1bd":"markdown","763a6bb7":"markdown","f54eb20a":"markdown","c5bac844":"markdown","febc42ce":"markdown"},"source":{"a56b9008":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator     # for images\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n%config Completer.use_jedi = False\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d613e37":"data_train = pd.read_csv(\"\/kaggle\/input\/google-stock-price\/Google_Stock_Price_Train.csv\")\ndata_train.head()","19aa9a4a":"#training set through which we train the RNN\ntraining_set = data_train.iloc[:,1:2].values\ntraining_set","ac652b66":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range=(0,1))\n#dataset with scaled value\ntraining_set_scaled = sc.fit_transform(training_set)","fdc3ee15":"training_set_scaled    #all is between 0 and 1","e7324777":"#input 60 previous timesteps\nX_train = [] \n#y_train contain stock price at time T+1\ny_train = []\n\nfor i in range(60, 1258):\n    X_train.append(training_set_scaled[i-60:i,0])  #60 previous stock price from i\n    y_train.append(training_set_scaled[i, 0])\n    \n# make them numpy array\nX_train, y_train = np.array(X_train), np.array(y_train)\n    \n    \nprint(\"X_TRAIN \" ,X_train)\nprint(\"Y_TRAIN \" ,y_train)","1efbab21":"print(\"SHAPE BEFORE RESHAPING: X_Train is \", X_train.shape)\n\nprint(\"\\n\\nRESHAPING to 3D........\\n\\n\")\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nprint(\"SHAPE AFTER RESHAPING: X_Train is \", X_train.shape)\n","69d3cb3a":"#import LIbraries\nfrom keras.models import Sequential #for seqntial model\nfrom keras.layers import LSTM, Dropout, Dense","114e7e9c":"#initialize RNN\nmodel = Sequential()\n\n#adding First LSTM LAYER AND SOME DROPOUT REgularisation\nmodel.add(LSTM(units = 50, return_sequences=True, input_shape = (X_train.shape[1],1)))\n#dropout 20% of neuron during each epoch of traiing\nmodel.add(Dropout(0.2))\n\n#adding Second LSTM Layer with dropout Regularisation\nmodel.add(LSTM(units = 50, return_sequences=True)) #in next layers we dont need input shape\nmodel.add(Dropout(0.2))\n\n#adding Third LSTM Layer\nmodel.add(LSTM(units = 50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\n#adding Fourth LSTM Layer  --> return seq == False(no more layers now)\nmodel.add(LSTM(units = 50, return_sequences=False))\nmodel.add(Dropout(0.2))\n\n#adding output layer\nmodel.add(Dense(units=1))\n\nmodel.summary()","df63a434":"#Compiling the RNN\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n","bd363102":"#fitting the RNN to traiing set\nmodel.fit(X_train, y_train,epochs=100, batch_size=32)","c6a14fd5":"data_test = pd.read_csv(\"\/kaggle\/input\/google-stock-price\/Google_Stock_Price_Test.csv\")\nreal_stock_price = data_test.iloc[:,1:2].values\nprint(real_stock_price)\nprint(data_test.head())","898d5317":"#Predict Stock Price of 2017\ndataset_total = pd.concat((data_train['Open'], data_test['Open']), axis=0)\ninputs =  dataset_total[len(dataset_total) - len(data_test) -60: ].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)\n\nX_test = [] \n\nfor i in range(60, 80):\n    X_test.append(inputs[i-60:i,0])      \n\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\npredicted_stock_price = model.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","85004d3f":"plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title(\"Google Stock Price Prediction\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Stock Price\")\n\nplt.legend()\nplt.show()","36f872e1":"import math\nfrom sklearn.metrics import mean_squared_error\nrmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\nrmse","0ba0a4e5":"# 4 Reshaping the X_train to 3 Dimension","4e61928a":"# Imporving RNN\n\nHi guys,\n\nhere are different ways to improve the RNN model:\n\n1. Getting more training data: we trained our model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.\n2. Increasing the number of timesteps: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. That\u2019s because we chose a number of 60 timesteps (3 months). You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n3. Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n4. Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n5. Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers.\n\n\nEnjoy Deep Learning!","bfe3419b":"# 3. Creating a data structure with 60 timesteps and 1 output  \n\n- ` 60 timesteps means at each time t the rnn will lookat 60 stock prices before time t and based on trends it will predict the next output. `\n\n- ` it will use the preivous 60 information to predict the output`\n\n- `60 timesteps means stock price of 3 months (20 timesteps each month)`","f7b91c6c":"### Visulaize the Result","4f8ea1bd":"## Evaluate the RNN","763a6bb7":"# 6. Predicting and Visualising Result","f54eb20a":"# Part 1 : Importing Data set\n\nwe will only import trainnig set","c5bac844":"# PART 5: Building RNN","febc42ce":"# 2. Feature Scaling\nwe will use Normalisation, for this we use min max saclaer class\n\nIt will convert all stock price in between 0 and 1"}}