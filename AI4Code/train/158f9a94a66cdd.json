{"cell_type":{"00f82302":"code","2d4cbd0f":"code","218e0776":"code","a31373bb":"code","996797e2":"code","ae9ee0fe":"code","feffe936":"code","66caea3c":"code","3918c4d5":"code","c9db446e":"code","93c8db64":"code","42b616b1":"code","2aef28c8":"code","6e5bb9c7":"code","45f2c42e":"code","7a5b9877":"code","1a85099f":"code","922e3648":"code","7556397a":"code","9c308569":"code","3a848fbe":"code","79e6d81f":"code","251ab883":"code","b51ec988":"markdown","7b563f51":"markdown","a04825eb":"markdown","5365d4db":"markdown","934dd1d0":"markdown","827e8c2e":"markdown","5b65270a":"markdown","9d4295c5":"markdown"},"source":{"00f82302":"import sys\nsys.path.append(\"..\/input\/pytorch-tabnet-zip\")","2d4cbd0f":"import os\n\nimport pandas as pd\nimport numpy as np\nimport datatable as dt\nimport warnings\nimport random\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns',None)\nfrom sklearn.metrics import mean_squared_error\n\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor","218e0776":"FOLDER = \"\/kaggle\/input\/petfinder-pawpularity-score\/\"\nTRAIN_FNAME = os.path.join(FOLDER, \"train.csv\")\nTEST_FNAME = os.path.join(FOLDER, \"test.csv\")\nSUBMISSION_FNAME = os.path.join(FOLDER, \"sample_submission.csv\")\n\nRANDOM_STATE = 42\nTEST_SIZE = 0.1\nMAX_EPOCHS_TABNET = 200","a31373bb":"def rmse_fn(y_pred, y_true):\n    return np.sqrt(mean_squared_error(y_pred, y_true))","996797e2":"train = pd.read_csv(TRAIN_FNAME)\ntest = pd.read_csv(TEST_FNAME)\nsubmission = pd.read_csv(SUBMISSION_FNAME)","ae9ee0fe":"train.shape, test.shape, submission.shape","feffe936":"train.head()","66caea3c":"train.shape","3918c4d5":"train = train.rename(columns={\"Pawpularity\": \"target\"})","c9db446e":"X_train, X_val, y_train, y_val = train_test_split(\n    train.drop([\"target\", \"Id\"], axis=1),\n    train.target,\n    test_size=TEST_SIZE,\n    random_state=RANDOM_STATE,\n    stratify=train.target\n)\nX_train = X_train.values\nX_val = X_val.values\ny_train = y_train.values.reshape(-1, 1)\ny_val = y_val.values.reshape(-1, 1)","93c8db64":"from pytorch_tabnet.tab_model import TabNetRegressor\n\n\ndef fit_pred_tabnet(X_train, y_train, X_val, random_state=RANDOM_STATE, max_epochs_tabnet=MAX_EPOCHS_TABNET):\n    model = TabNetRegressor(verbose=1,seed=random_state)\n    print(\"Fit tabnet\")\n    model.fit(X_train=X_train, y_train=y_train,\n               patience=5,max_epochs=max_epochs_tabnet,batch_size=256,\n               eval_metric=['rmse'])\n    print(\"Predict tabnet\")\n    pred_tabnet = model.predict(X_val)\n    pred_tabnet = pred_tabnet.reshape(len(pred_tabnet))\n    return pred_tabnet\n\n\npred_tabnet = fit_pred_tabnet(X_train, y_train, X_val)","42b616b1":"rmse_tabnet = rmse_fn(pred_tabnet, y_val)\nrmse_tabnet","2aef28c8":"import xgboost as xgb\n\n\ndef fit_pred_xgb(X_train, y_train, X_val, random_state=RANDOM_STATE):\n    xgb_regressor = xgb.XGBRegressor(seed=random_state, **{'n_estimators': 10000, 'max_depth': 7, 'learning_rate': 0.0022137388320075573})\n    print(\"Fit XGB\")\n    xgb_regressor.fit(X_train, y_train)\n    print(\"Predict XGB\")\n    pred_xgb = xgb_regressor.predict(X_val)\n    return pred_xgb\n\npred_xgb = fit_pred_xgb(X_train, y_train, X_val)","6e5bb9c7":"rmse_xgb = rmse_fn(pred_xgb, y_val)\nrmse_xgb","45f2c42e":"weights = list(np.arange(0, 1, 0.1))\nweights","7a5b9877":"def avg_tabnet_xgb(pred_tabnet, pred_xgb, w_tabnet):\n    return np.average([pred_tabnet, pred_xgb], weights=[w_tabnet, 1-w_tabnet], axis=0)","1a85099f":"list_rmse = []\n\nfor w_tabnet in weights:\n    pred_stack = avg_tabnet_xgb(pred_tabnet, pred_xgb, w_tabnet)\n    rmse = rmse_fn(pred_stack, y_val)\n    list_rmse.append(rmse)\n\nprint(list_rmse)\nidx_best_w = list_rmse.index(min(list_rmse))\nidx_best_w","922e3648":"print(f\"rmse_tabnet={rmse_tabnet}\")\nprint(f\"rmse_xgb={rmse_xgb}\")","7556397a":"best_weight = weights[idx_best_w]\npred_stack = avg_tabnet_xgb(pred_tabnet, pred_xgb, best_weight)\nrmse_weighted_avg = rmse_fn(pred_stack, y_val)\n\nprint(f\"best weight is w={best_weight}\")\nprint(f\"weighted average ={rmse_weighted_avg}\")","9c308569":"def get_final_pred(X_train, y_train, X_val, w_tabnet):\n    pred_tabnet = fit_pred_tabnet(X_train, y_train, X_val)\n    pred_xgb = fit_pred_xgb(X_train, y_train, X_val)\n    pred_stack = avg_tabnet_xgb(pred_tabnet, pred_xgb, w_tabnet)\n    return pred_stack","3a848fbe":"X_train = train.drop([\"target\", \"Id\"], axis=1).values\ny_train = train.target.values.reshape(-1, 1)\n\nX_test = test.drop([\"Id\"], axis=1).values","79e6d81f":"predictions = get_final_pred(X_train=X_train, y_train=y_train, X_val=X_test, w_tabnet=best_weight)","251ab883":"test[\"Pawpularity\"] = predictions\ntest[[\"Id\", \"Pawpularity\"]].to_csv('submission.csv', index=False)","b51ec988":"## Cross validation for Tabnet, XGBoost & both together","7b563f51":"## Defined global variables","a04825eb":"## Install Tabnet library","5365d4db":"## Import required libraries","934dd1d0":"## Prepare data","827e8c2e":"## Respective RMSE","5b65270a":"## Make the final prediction","9d4295c5":"## Import data"}}