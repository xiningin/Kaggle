{"cell_type":{"b217d233":"code","47d03e04":"code","4432abc1":"code","1f166eb2":"code","40a25707":"code","91f9c722":"code","0abed8d3":"code","26c5efd2":"code","d75d94ff":"code","efbb26a2":"code","41969397":"code","7dba3ce3":"code","3da8c13d":"code","47040696":"code","0b6fba10":"code","187d1b61":"code","c084a599":"code","9c40d8a0":"code","8f4f3798":"code","0c997435":"code","75298c0f":"code","d737f79a":"code","de2a3d78":"code","0e932eb1":"code","b43052b0":"code","cdaee69f":"code","df5ca9bd":"code","9642a4aa":"code","f3ea64a5":"code","b12df375":"code","3aaf7b92":"code","c60f9abd":"code","c9e0400e":"code","f33e75fc":"code","87800a38":"code","73d0d7ff":"code","a212d1d8":"code","f5aa5fb5":"code","19ce386a":"code","589be88e":"code","82b15ad7":"code","c1f8e471":"code","5fdaf36b":"code","b5f1cde2":"code","7c7f55d8":"code","51726d43":"code","996ce636":"code","d3bf1624":"code","b35b7ae4":"code","a3199741":"code","33dde410":"code","dc46496e":"code","4de61fe2":"code","98699ce4":"code","5407ab47":"code","ce1f17d0":"code","41db4e77":"code","52c86c05":"code","d8ea8464":"code","bcfcce34":"code","ff5999da":"markdown","4c255c9a":"markdown","a30b39b9":"markdown","c18850ae":"markdown","2da70395":"markdown","8ce9dd63":"markdown","9406ce2f":"markdown","c2b2b159":"markdown","59d44f61":"markdown","288234ca":"markdown","25900305":"markdown","3c05f4e8":"markdown","e76d5074":"markdown","572f0724":"markdown","4c996c28":"markdown","48156904":"markdown","5d25b14f":"markdown","42e51030":"markdown","aec3fafb":"markdown","51fae636":"markdown"},"source":{"b217d233":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\nimport seaborn as sns","47d03e04":"df = pd.read_csv('..\/input\/craigslist-carstrucks-data\/craigslistVehicles.csv')","4432abc1":"# First 5 rows of our data\ndf.head()","1f166eb2":"#Delete some columns\ndf = df.drop(columns=['image_url', 'lat', 'long', 'city_url', 'desc', 'city', 'VIN'])","40a25707":"#Find and delete duplicates\ndf.drop_duplicates(subset='url')\ndf.shape","91f9c722":"df[df.isnull().sum(axis=1) < 9].shape, df[df.isnull().sum(axis=1) >= 9].shape","0abed8d3":"#Let's leave lines with less than 9 missing values\ndf = df[df.isnull().sum(axis=1) < 9]\ndf.shape","26c5efd2":"#let's take a look how many missing values we have in our dataset\ndf.isnull().sum()","d75d94ff":"df[df.price == 0].shape","efbb26a2":"df = df[df.price != 0]\ndf.shape","41969397":"plt.figure(figsize=(8, 8))\nsns.boxplot(y= 'price', data=df)","7dba3ce3":"#delete data with prices above 100k\ndf = df[df.price < 100000]\ndf.shape","3da8c13d":"plt.figure(figsize=(8, 10))\nsns.boxplot(y= 'price', data=df)","47040696":"plt.figure(figsize=(15, 13))\nyear_plot = sns.countplot(x = 'year', data=df)\nyear_plot.set_xticklabels(year_plot.get_xticklabels(), rotation=90,fontsize=8);","0b6fba10":"df = df[df.year > 1985]\ndf.shape","187d1b61":"plt.figure(figsize=(15, 13))\nax = sns.countplot(x = 'year', data=df, palette='Set1')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90,fontsize=10);","c084a599":"df.odometer.quantile(.999)","9c40d8a0":"df = df[~(df.odometer > 500000)]\ndf.shape","8f4f3798":"plt.figure(figsize = (8, 12))\nsns.boxplot(y = 'odometer', data = df[~(df.odometer > 500000)])","0c997435":"sns.set(style=\"ticks\", color_codes='palette')\nsns.pairplot(df, hue= 'condition');","75298c0f":"df.isnull().sum()","d737f79a":"mean= df[df['year'] == 2010]['odometer'].mean()\nmean","de2a3d78":"df.odometer = df.groupby('year')['odometer'].apply(lambda x: x.fillna(x.mean()))","0e932eb1":"df.odometer.isnull().sum()","b43052b0":"df['condition'].isnull().sum()","cdaee69f":"df.loc[(df['year'] >= 2019)]['condition'].isnull().sum()","df5ca9bd":"df.loc[df.year>=2019, 'condition'] = df.loc[df.year>=2019, 'condition'].fillna('new')","9642a4aa":"df.loc[(df['year'] >= 2019)]['condition'].isnull().sum()","f3ea64a5":"df['condition'].unique()","b12df375":"excellent_odo_mean = df[df['condition'] == 'excellent']['odometer'].mean()\ngood_odo_mean = df[df['condition'] == 'good']['odometer'].mean()\nlike_new_odo_mean = df[df['condition'] == 'like new']['odometer'].mean()\nsalvage_odo_mean = df[df['condition'] == 'salvage']['odometer'].mean()\nfair_odo_mean = df[df['condition'] == 'fair']['odometer'].mean()\nprint('excelent {}, good {}, like_new {}, salvage {}, fair {}'.format(excellent_odo_mean, good_odo_mean,\n                                                                like_new_odo_mean, salvage_odo_mean,\n                                                                fair_odo_mean))","3aaf7b92":"df.loc[df['odometer'] <= like_new_odo_mean, 'condition'] = df.loc[df['odometer'] <= like_new_odo_mean, 'condition'].fillna('like new')\ndf.loc[df['odometer'] >= fair_odo_mean, 'condition'] = df.loc[df['odometer'] >= fair_odo_mean, 'condition'].fillna('fair')\ndf.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'] = df.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'].fillna('excellent')\ndf.loc[((df['odometer'] > excellent_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'] = df.loc[((df['odometer'] > excellent_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'].fillna('good')\ndf.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'] = df.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'].fillna('salvage')","c60f9abd":"df.isnull().sum()","c9e0400e":"df['cylinders'].unique()","f33e75fc":"df['cylinders'].value_counts().head()","87800a38":"df['cylinders'].isnull().sum()","73d0d7ff":"df['cylinders'] = df['cylinders'].fillna(df['cylinders'].value_counts().index[0])","a212d1d8":"df['transmission'] = df['transmission'].fillna(df['transmission'].value_counts().index[0])\ndf['title_status'] = df['title_status'].fillna(df['title_status'].value_counts().index[0])\ndf['fuel'] = df['fuel'].fillna(df['fuel'].value_counts().index[0])\ndf['size'] = df['size'].fillna(df['size'].value_counts().index[0])","f5aa5fb5":"df = df.dropna(subset=['make'])","19ce386a":"df = df.fillna('Unkown')","589be88e":"df.isnull().sum()","82b15ad7":"df = df.drop(columns=['url'])","c1f8e471":"df.head()","5fdaf36b":"from sklearn.preprocessing import LabelEncoder","b5f1cde2":"labels = ['manufacturer', 'make', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', \n          'drive', 'size', 'type', 'paint_color']\nles = {}\n\nfor l in labels:\n    les[l] = LabelEncoder()\n    les[l].fit(df[l])\n    tr = les[l].transform(df[l]) \n    df.loc[:, l + '_feat'] = pd.Series(tr, index=df.index)\n\nlabeled = df[ ['price'\n                ,'odometer'\n                ,'year'] \n                 + [x+\"_feat\" for x in labels]]","7c7f55d8":"labeled.head()","51726d43":"X = labeled.drop(columns=['price'])\ny = labeled['price']\nprint(X.shape, y.shape)","996ce636":"from sklearn.model_selection import train_test_split","d3bf1624":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)\nprint(X_train.shape, X_test.shape)","b35b7ae4":"from sklearn.preprocessing import MinMaxScaler","a3199741":"scaler = MinMaxScaler()  \nscaler.fit(X_train)    \nX_train_normed = pd.DataFrame(scaler.transform(X_train))\nX_test_normed = pd.DataFrame(scaler.transform(X_test))","33dde410":"from sklearn.ensemble import RandomForestRegressor","dc46496e":"rdf = RandomForestRegressor()\nrdf.fit(X_train_normed, y_train)","4de61fe2":"from sklearn.metrics import mean_squared_error as MSE","98699ce4":"y_pred = rdf.predict(X_test_normed)\nrmse2 = np.sqrt(MSE(y_test, y_pred))\nprint(\"RMSE = {:.2f}\".format((rmse2)))","5407ab47":"accuracy = rdf.score(X_test_normed,y_test)\nprint(accuracy*100,'%')","ce1f17d0":"from sklearn.model_selection import GridSearchCV\nparameters = {'n_estimators': [100]}","41db4e77":"clf = GridSearchCV(rdf, parameters, cv=5, n_jobs= -1)","52c86c05":"clf.fit(X_train_normed, y_train)","d8ea8464":"clf.best_estimator_","bcfcce34":"y_pred = clf.best_estimator_.predict(X_test_normed)\nrmse2 = np.sqrt(MSE(y_test, y_pred))\nprint(\"RMSE = {:.2f}\".format(rmse2))\naccuracy = clf.score(X_test_normed,y_test)\nprint(accuracy*100,'%')","ff5999da":"## Let's read our dataset","4c255c9a":"As we can see there are a lot of unreasonably high prices(above 100k)","a30b39b9":"The remaining missing values in next 4 columns are filled with the most common value","c18850ae":"Price can't be 0, so I deleted all rows with 0 price","2da70395":"The scale of the odometer is much larger than that of other features. So I decided to bring all the data to a single scale using MinMaxScaler. Here is an article about it ( https:\/\/www.quora.com\/Minmaxscaler-vs-Standardscaler-Are-there-any-specific-rules-to-use-one-over-the-other-for-a-particular-application )","8ce9dd63":"## Let's build our model","9406ce2f":"I decided to mark all cars produced in 2019 or later with the label \" New\"","c2b2b159":"Most cars have four, six or eight cylinders, although some have three, five or ten(https:\/\/itstillruns.com\/determine-many-cylinders-3374.html ). So I decide to use 6 cylinders to fill missing data.","59d44f61":"I chose RandomForestRegressor as an algorithm.","288234ca":"I used some plots from Eli Gertz's kernel (https:\/\/www.kaggle.com\/eligertz\/used-cars-price-prediction )","25900305":"I made the assumption that the condition of the car depends on the number of kilometers traveled.","3c05f4e8":"## Let's do something with missing data","e76d5074":"### In this kernel I will try to explain what empirical strategies I used to fill in the missing data. Sometimes the explanations may be too detailed. So let's jump into it.","572f0724":"Remove extremely high odometer values.","4c996c28":"This is where we start filling in the missing data. I have used empirical strategies that may be wrong.","48156904":"So I got an accuracy of 86.6% and Root Mean Square Error (RMSE) of 4071.35","5d25b14f":"Most of the cars in our dataset have been manufactured since 1985. Let's keep cars with year above the year of 1985.","42e51030":"The remaining missing values are filled with the label 'Unknown'","aec3fafb":"For our algorithm, we have to transform categorical features for further use. I decide to use LabelEncoder. Here is an article about it ( https:\/\/medium.com\/@contactsunny\/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621 )","51fae636":"Odometer is a counter of how many kilometers or miles a car has traveled. Some cars are used more, some less. But the starting point for each car is the year in which it was produced. So we find the average value for a particular year, and fill in all the missing values for that year with this value."}}