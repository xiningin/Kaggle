{"cell_type":{"3d3a6201":"code","58d67ce5":"code","568e0c93":"code","cb2db21b":"code","626f9e63":"code","39087e57":"code","8cdc398d":"code","f4d52247":"code","ff55ac58":"code","06b17e49":"code","62c0ebab":"code","52a06bf3":"code","8b6d96e1":"markdown","85ea02b7":"markdown","98c4584a":"markdown","00402e42":"markdown","e9b013a7":"markdown","7823cf4d":"markdown","e2ce7454":"markdown","6af604dc":"markdown","60dd0c6f":"markdown","785a4a72":"markdown","d0d0fc1b":"markdown","7c80e230":"markdown","4c424c2b":"markdown","c617aa71":"markdown"},"source":{"3d3a6201":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten\nfrom tensorflow.keras.models import Sequential\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport os\n","58d67ce5":"root_dir  =  Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')\n# Get filepaths and Class\nfilepaths = list(root_dir.glob(r'**\/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Class')\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)\n\n# Drop GT images\nimage_df['Class'] = image_df['Class'].apply(lambda x: np.NaN if x[-2:] == 'GT' else x)\nimage_df = image_df.dropna(axis=0)\n# Sample 200 images from each class\nsamples = []\n\nfor category in image_df['Class'].unique():\n    category_slice = image_df.query(\"Class == @category\")\n    samples.append(category_slice.sample(200, random_state=1))\n\nimage_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)","568e0c93":"x_train, x_test = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=1)","cb2db21b":"# Train Generator\n\ntrain_generator = ImageDataGenerator(\n                             rescale=1.\/255,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             validation_split=0.2\n)\n\n# Test Generator\ntest_generator = ImageDataGenerator(rescale=1.\/255)","626f9e63":"\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=x_train,\n    x_col='Filepath',\n    y_col='Class',\n    target_size=(256, 256),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=x_train,\n    x_col='Filepath',\n    y_col='Class',\n    target_size=(256, 256),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=x_test,\n    x_col='Filepath',\n    y_col='Class',\n    target_size=(256, 256),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n)\n","39087e57":"BATCH_SIZE=32\nLearning_Rate= 0.001\nINPUT_SHAPE=(256,256,3)\nEPOCHS = 15\nNET=16","8cdc398d":"# Model\n\nmodel  = Sequential(\n[\n    Conv2D(NET,(3,3),activation='relu',input_shape=INPUT_SHAPE),\n    Conv2D(NET,(3,3),activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(NET,(3,3),activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(NET,(3,3),activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(NET,(3,3),activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(NET,(3,3),activation='relu'),\n    Flatten(),\n    Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.L1(l1=0.001)),\n    Dense(128,activation='relu'),\n    Dense(9,activation='softmax')\n])\n\n# Model Compiling with loss and optimizers\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=Learning_Rate),loss='categorical_crossentropy',metrics=['acc'])\nmodel.summary()","f4d52247":"history = model.fit(train_images,batch_size=BATCH_SIZE,validation_data=val_images,epochs=EPOCHS,verbose=1)","ff55ac58":"val_acc = history.history['val_acc']\nacc = history.history['acc']\n\nval_loss=history.history['val_loss']\nloss = history.history['loss']\n\nepochs = np.arange(EPOCHS)\n","06b17e49":"plt.plot(epochs, acc)\nplt.plot(epochs,val_acc)\nplt.show()","62c0ebab":"\nplt.plot(epochs,loss)\nplt.plot(epochs,val_loss)\nplt.show()","52a06bf3":"model.evaluate(test_images)","8b6d96e1":"# Model testing","85ea02b7":"# Spliting the data into Test and Train","98c4584a":"# Model Structure","00402e42":"# Loss Plot","e9b013a7":"# Modules ","7823cf4d":"Solution:\n\nThe possible solution is using a transfer learning method which is easier and reliable solution for this type of scenarios. There is another solution of this problem is using a state of the art tensorflow CNN model to extract features and then classify images using Dense networks with Softmax funtion.","e2ce7454":"# Metrics","6af604dc":"# Input files as Pandas Database","60dd0c6f":"# Hyper parameters\n\nHyper parameters can be tunned to improve model performance\n\n* Batch Size : Batch size is responsible for how many images will be processed in a batch\n* Learning Rate: Learning rate is the alpha value of the internal network which is responsible improving the learning capabilities\n* INPUT_SHAPE: Input shape of the images into the model\n* EPOCHS: How many time the process will go through\n* NET: How many Networks or nodes will be there.","785a4a72":"# Spliting the Pandas data to Train,Test & validation Generator ","d0d0fc1b":"# Using ImageDataGenerator ","7c80e230":"# **Problem**\n\nAs we have the pictures of different fish species. So it's clearly a classification problem. ","4c424c2b":"# Model Training","c617aa71":"# Accuracy Plot"}}