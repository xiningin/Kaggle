{"cell_type":{"f258f322":"code","8774b9c6":"code","65d42bef":"code","6371faac":"code","6ed84938":"code","d1a88637":"code","93b8d83a":"code","2ccec1b8":"code","eab9306c":"code","14cc8310":"code","54390f5e":"code","5d9fd852":"code","b6178aeb":"code","336e50be":"code","b6723471":"code","9dd687d2":"code","f19beb6f":"code","11feb6e8":"code","a7a7b212":"code","0fec24b8":"code","19532af2":"code","815702ac":"code","a80f0f05":"code","550f54bb":"code","e2a158e5":"code","2f9e6187":"code","10878304":"code","b8878ad4":"code","2f5fe8bd":"code","b9271cdb":"code","b2ec2845":"code","e34f9007":"code","32062072":"code","ba57769a":"code","b5520f07":"code","4645333c":"code","4f7a90cb":"code","4ef8af81":"code","87bd188a":"code","eb4df7b8":"code","78af2109":"code","60f45389":"code","96c067c9":"code","c1812560":"code","a09881ee":"code","da6749e7":"code","1e73ea55":"code","7bc90cc8":"code","8f952cb7":"code","9a52fceb":"code","0c5105dc":"code","596986bc":"code","7fc29d1e":"code","7fdc92ab":"code","5b5185d5":"code","eff88e26":"code","4cd6e3b0":"code","316f040e":"code","6f1c1022":"code","64d7b1fc":"code","d07635ce":"code","c7887924":"code","7d22eb9a":"code","fdb5af1d":"code","147e3b0e":"code","f3498b6b":"code","2ea2efc1":"code","34bac3f3":"code","fdd84448":"code","23ce4f6c":"code","a64479e3":"code","33b9b0aa":"code","c6ed1b9d":"code","7cc1f3ef":"code","55766a15":"code","a240c231":"code","c5d4f05d":"code","262c153d":"code","e2063401":"markdown","4f9d36ee":"markdown","2d121a92":"markdown","3dde3a1e":"markdown","1e5fcadb":"markdown","133dcb11":"markdown","8736bc1d":"markdown","3568b9e7":"markdown","d520cd76":"markdown","d81cdb6d":"markdown","5222248d":"markdown","4cddaa65":"markdown","8eac8a23":"markdown","c0000a2b":"markdown","23372071":"markdown","1350cf24":"markdown","81366580":"markdown","670db5d8":"markdown","8794959f":"markdown","12b698e3":"markdown","9d115697":"markdown","b0713765":"markdown","bbaed5f8":"markdown","3dd5018f":"markdown","ee7fe066":"markdown","9878f783":"markdown","da44cbea":"markdown","f546ebd6":"markdown","63ad7b03":"markdown"},"source":{"f258f322":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom PIL import Image\nfrom collections import OrderedDict\n%matplotlib inline","8774b9c6":"dataset = ImageFolder('..\/input\/stanford-dogs-dataset\/images\/Images')","65d42bef":"len(dataset)","6371faac":"len(dataset.classes)","6ed84938":"dataset.classes","d1a88637":"breeds = []\n\ndef rename(name):\n    return ' '.join(' '.join(name.split('-')[1:]).split('_'))\n\nfor n in dataset.classes:\n    breeds.append(rename(n))","93b8d83a":"breeds","2ccec1b8":"random_seed = 45\ntorch.manual_seed(random_seed);","eab9306c":"test_pct = 0.1\ntest_size = int(len(dataset)*test_pct)\ndataset_size = len(dataset) - test_size\n\nval_pct = 0.1\nval_size = int(dataset_size*val_pct)\ntrain_size = dataset_size - val_size\n\n\ntrain_size, val_size, test_size","14cc8310":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)","54390f5e":"img, label = train_ds[6]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","5d9fd852":"img, label = train_ds[256]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","b6178aeb":"img, label = train_ds[89]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","336e50be":"img, label = val_ds[335]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","b6723471":"img, label = val_ds[1000]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","9dd687d2":"img, label = test_ds[256]\nprint(dataset.classes[label])\nplt.imshow(img)\nprint(type(img))","f19beb6f":"class DogBreedClassification(Dataset):\n    \n    def __init__(self, ds, transform=None):\n        self.ds = ds\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.ds)\n    \n    def __getitem__(self, idx):\n        img, label = self.ds[idx]\n        if self.transform:\n            img = self.transform(img)  \n            return img, label","11feb6e8":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_transform = transforms.Compose([\n#    transforms.Resize((224, 224)),\n    transforms.Resize((256, 256)),\n    transforms.RandomCrop(224, padding=4, padding_mode='reflect'),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.RandomRotation(degrees=30),\n    transforms.ToTensor(),\n#    transforms.Normalize(*imagenet_stats, inplace=True)\n    \n])\n\n\nval_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n#    transforms.Normalize(*imagenet_stats, inplace=True)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224,224)), \n    transforms.ToTensor(),\n#    transforms.Normalize(*imagenet_stats, inplace=True)\n])","a7a7b212":"train_dataset = DogBreedClassification(train_ds, train_transform)\nval_dataset = DogBreedClassification(val_ds, val_transform)\ntest_dataset = DogBreedClassification(test_ds, test_transform)","0fec24b8":"img, label = train_dataset[22]\nprint(label)\nplt.imshow(img.permute(1,2,0))","19532af2":"batch_size =64\n\n# Create DataLoaders\ntrain_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_dl = DataLoader(val_dataset, batch_size*2, num_workers=2, pin_memory=True)\ntest_dl = DataLoader(test_dataset, batch_size*2, num_workers=2, pin_memory=True)","815702ac":"def show_batch(dl):\n    for img, lb in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(img.cpu(), nrow=16).permute(1,2,0))\n        break","a80f0f05":"show_batch(train_dl)","550f54bb":"show_batch(val_dl)","e2a158e5":"show_batch(test_dl)","2f9e6187":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","10878304":"class ImageClassificationBase(nn.Module):\n    # training step\n    def training_step(self, batch):\n        img, targets = batch\n        out = self(img)\n        loss = F.nll_loss(out, targets)\n        return loss\n    \n    # validation step\n    def validation_step(self, batch):\n        img, targets = batch\n        out = self(img)\n        loss = F.nll_loss(out, targets)\n        acc = accuracy(out, targets)\n        return {'val_acc':acc.detach(), 'val_loss':loss.detach()}\n    \n    # validation epoch end\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss':epoch_loss.item(), 'val_acc':epoch_acc.item()}\n        \n    # print result end epoch\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}] : train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))\n        ","b8878ad4":"class DogBreedClassificationCNN(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, 3, stride=1, padding=1),   # 224 * 244 * 32\n            nn.ReLU(),                                   \n            nn.Conv2d(32, 32, 3, stride=1, padding=1),       \n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),                         # 112 * 112 * 32\n            \n            nn.Conv2d(32, 64, 3, stride=1, padding=1),   # 112 * 112* 64\n            nn.ReLU(), \n            nn.Conv2d(64, 128, 3, stride=1, padding=1),    # 112 * 112* 128\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),                          # 56 * 56* 128\n            \n            nn.Conv2d(128, 256, 3, stride=1, padding=1),   # 56*56*256\n            nn.ReLU(),\n            nn.Conv2d(256, 256, 3, stride=1, padding=1),  # 56*56*256\n            nn.ReLU(), \n            nn.MaxPool2d(2,2),                        # 28*28*256\n            \n            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),                            # 14*14*256\n            \n            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),                            # 7*7*256\n            \n            nn.Flatten(),\n            nn.Linear(7*7*256, 512),\n            nn.ReLU(),\n            nn.Linear(512, 120),\n            nn.LogSoftmax(dim = 1),\n        )\n    \n    def forward(self, xb):\n        return self.network(xb)","2f5fe8bd":"model = DogBreedClassificationCNN()\nmodel","b9271cdb":"class DogBreedPretrainedResnet34(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","b2ec2845":"model2 = DogBreedPretrainedResnet34()\nmodel2","e34f9007":"class DogBreedPretrainedResNet50(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.resnet50(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","32062072":"model3 = DogBreedPretrainedResNet50()\nmodel3","ba57769a":"class DogBreedPretrainedResnet152(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.resnet152(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","b5520f07":"model4 = DogBreedPretrainedResnet152()\nmodel4","4645333c":"class DogBreedPretrainedVGG16(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.vgg16(pretrained=True)\n        # Replace last layer  \n        self.network.classifier = nn.Sequential(\n           nn.Linear(in_features=25088, out_features=4096, bias=True),\n           nn.ReLU(inplace=True),\n           nn.Dropout(p=0.5, inplace=False),\n           nn.Linear(in_features=4096, out_features=4096, bias=True),\n           nn.ReLU(inplace=True),\n           nn.Dropout(p=0.5, inplace=False),\n           nn.Linear(in_features=4096, out_features=120, bias=True),\n           nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","4f7a90cb":"model5 = DogBreedPretrainedVGG16()\nmodel5","4ef8af81":"class DogBreedPretrainedGoogleNet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.googlenet(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","87bd188a":"model6 = DogBreedPretrainedGoogleNet()\nmodel6","eb4df7b8":"class DogBreedPretrainedResNet101(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.resnet101(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","78af2109":"model10 = DogBreedPretrainedResNet101()\nmodel10","60f45389":"class DogBreedPretrainedDenseNet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.densenet161(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.classifier.in_features\n        self.network.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","96c067c9":"model7 = DogBreedPretrainedDenseNet()\nmodel7","c1812560":"class DogBreedPretrainedWideResnet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.wide_resnet50_2(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","a09881ee":"model1 = DogBreedPretrainedWideResnet()\nmodel1","da6749e7":"class DogBreedPretrainedAlexNet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        \n        self.network = models.alexnet(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Sequential(\n            nn.Linear(num_ftrs, 120),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","1e73ea55":"model8 = DogBreedPretrainedAlexNet()\nmodel8","7bc90cc8":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(d, device) for d in data]\n    else:\n        return data.to(device, non_blocking=True)","8f952cb7":"device1 = get_default_device()\nprint(device1)","9a52fceb":"class DeviceDataLoader:\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    \n    def __len__(self):\n        return len(self.dl)\n    \n    def __iter__(self):\n        for batch in self.dl:\n            yield to_device(batch, self.device)","0c5105dc":"# getting default device\ndevice = get_default_device()\nprint(device)\n\n# moving train dataloader and val dataloader to gpu\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\n\n\n# moving model to gpu\nto_device(model1, device);\nto_device(model3, device);\nto_device(model4, device);\nto_device(model10, device);","596986bc":"# check the model \ndef try_batch(dl):\n    for imgs, labels in dl:\n        print(\"images shape : \", imgs.shape)\n        print(\"labels : \", labels)\n        outs = model1(imgs)                                  # Change model object here\n        print(\"outs.shape :\", outs.shape)\n        print(\"outs : \", outs)\n        break\n        \ntry_batch(train_dl)","7fc29d1e":"from tqdm.notebook import tqdm","7fdc92ab":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n        \n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func = torch.optim.Adam):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # set up one cycle lr scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        \n        # Training phase\n        model.train()       \n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            \n            # calculates gradients\n            loss.backward()\n            \n            # check gradient clipping \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            # perform gradient descent and modifies the weights\n            optimizer.step()\n            \n            # reset the gradients\n            optimizer.zero_grad()\n            \n            # record and update lr\n            lrs.append(get_lr(optimizer))\n            \n            # modifies the lr value\n            sched.step()\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n        \n    return history\n        \n    \n\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","5b5185d5":"evaluate(model1, val_dl)            #resnet34     # you can change model object here","eff88e26":"#evaluate(model2, val_dl)              #resnet50","4cd6e3b0":"# set hyperparams\nnum_epochs = 3\nopt_func = torch.optim.Adam\n\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4","316f040e":"history = fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)","6f1c1022":"num_epochs = 6    # you can increase epochs , I think this lr is working good\nmax_lr = 0.001\nhistory += fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)","64d7b1fc":"#num_epochs = 3\n#max_lr = 0.0001\n#history += fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)","d07635ce":"history[0].keys()","c7887924":"val_loss = []\ntrain_loss = []\nval_acc = []\ntime = list(range(len(history)))\nfor h in history:\n    val_loss.append(h['val_loss'])\n    train_loss.append(h['train_loss'])\n    val_acc.append(h['val_acc'])","7d22eb9a":"plt.plot(time, val_loss, c='red', label='val_loss', marker='x')\nplt.plot(time, train_loss, c='blue', label='train_loss', marker='x')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.show()","fdb5af1d":"plt.plot(time, val_acc, c='red', label='accuracy', marker='x')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.show()","147e3b0e":"lrs = np.concatenate([x.get('lrs', []) for x in history])\nplt.xlabel('epochs')\nplt.ylabel('lr')\nplt.plot(lrs)\nplt.show()","f3498b6b":"def predict_single(img, label):\n    xb = img.unsqueeze(0) # adding extra dimension\n    xb = to_device(xb, device)\n    preds = model1(xb)                   # change model object here\n    predictions = preds[0]\n    \n    max_val, kls = torch.max(predictions, dim=0)\n    print('Actual :', breeds[label], ' | Predicted :', breeds[kls])\n    plt.imshow(img.permute(1,2,0))\n    plt.show()","2ea2efc1":"predict_single(*test_dataset[6])","34bac3f3":"predict_single(*test_dataset[1])","fdd84448":"predict_single(*test_dataset[93])","23ce4f6c":"test_dl = DeviceDataLoader(test_dl, device)","a64479e3":"result = evaluate(model1, test_dl)\nresult","33b9b0aa":"weights_fname = 'dog-breed-classifier-wideresnet_with_data_aug.pth'\ntorch.save(model4.state_dict(), weights_fname)","c6ed1b9d":"!pip install jovian --upgrade --quiet","7cc1f3ef":"import jovian","55766a15":"jovian.reset()\njovian.log_hyperparams(arch='wideresnet_with_data_aug', \n                       epochs=len(history), \n                       max_lr_01=0.001,\n                       \n                       \n                       max_lr_02=0.001,\n                       #max_lr_03=0.0001,\n                       scheduler='one-cycle', \n                       batch_size = batch_size,\n                       weight_decay=weight_decay, \n                       grad_clip=grad_clip,\n                       opt=opt_func.__name__)","a240c231":"jovian.log_metrics(\n    train_loss=history[-1]['train_loss'],\n    val_loss=history[-1]['val_loss'], \n    val_score=history[-1]['val_acc'],\n    test_score=result['val_acc'],\n    test_loss=result['val_loss']\n)","c5d4f05d":"project_name='dog-breed-classification-using-different-nets'","262c153d":"jovian.commit(project=project_name, environment=None, outputs=[weights_fname])","e2063401":"### Resnet 152","4f9d36ee":"## Dataset Exploration and Analysis ","2d121a92":"### Loss v\/s Epochs plot","3dde3a1e":"Let's define ResNet-34 Pre-trained model","1e5fcadb":"## Prediction","133dcb11":"### Accuracy v\/s Epochs plot","8736bc1d":"### DenseNet","3568b9e7":"## Moving Data to GPU","d520cd76":"### Training the model","d81cdb6d":"## Creating Custom Dataset","5222248d":"## Training ","4cddaa65":"## Plotting history","8eac8a23":"### Wide ResNet-50-2","c0000a2b":"### VGG16","23372071":"### ResNet50","1350cf24":"##  creating Training , validation data and test data loader ","81366580":"### This a example code , I got accuracy of 47% . But you can change the hyperparameters and the pretrained models to increase the accuracy . ","670db5d8":"## Save model","8794959f":"Lets quickly take a look into our training dataset","12b698e3":"### GoogleNet","9d115697":"## Commit to Jovian","b0713765":"We can also take a peek into our dataset by creating grid of images using Pytorch's `make_grid()` method.","bbaed5f8":"## Creating training, validation and testing dataset","3dd5018f":"### Let's use some more pre-trained models","ee7fe066":"## Network Architecture","9878f783":"To create our custom Dataset, we need to extend Pytorch's `Dataset` class.\nWe need to implement 3 methods inside our Custom Dataset Class:\n\n1. `__init__`\n2. `__len__`\n3. `__getitem__`","da44cbea":"### resnet 101","f546ebd6":"### AlexNet","63ad7b03":"## Importing Libraries"}}