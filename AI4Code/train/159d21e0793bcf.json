{"cell_type":{"bd4882b9":"code","9f48a619":"code","49c5fe36":"code","02bc3a5f":"code","13e01c7e":"code","0fc7933b":"code","fca5d9c1":"code","464f83c5":"code","90acef27":"code","ff925929":"code","c8cffdfe":"code","35b6bffa":"code","183f1083":"code","fbc90fb1":"code","ab773d24":"code","f859ff70":"code","aa32cfc5":"markdown","ac636559":"markdown","d3d3103c":"markdown","28879e23":"markdown","531cdb8a":"markdown","982807a3":"markdown","f9889234":"markdown","c428ffc6":"markdown","f4429ff8":"markdown","7e09af10":"markdown","bb612fc1":"markdown","9bb4fa55":"markdown"},"source":{"bd4882b9":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\nimport re\nimport math\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom random import shuffle\nfrom sklearn import model_selection as sk_model_selection\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport tensorflow_addons as tfa","9f48a619":"data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\npytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\n \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nIMAGE_SIZE = 256\nNUM_IMAGES = 48","49c5fe36":"sample_submission = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntest=sample_submission\ntest['BraTS21ID5'] = [format(x, '05d') for x in test.BraTS21ID]\ntest.head(3)","02bc3a5f":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=IMAGE_SIZE, mri_type=\"FLAIR\", split=\"test\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n            \n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00001\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))\nimage = a[0]\nprint(\"Dimension of the CT scan is:\", image.shape)\nplt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")","13e01c7e":"def plot_slices(num_rows, num_columns, width, height, data):\n    \"\"\"Plot a montage of 20 CT slices\"\"\"\n    data = np.rot90(np.array(data))  \n    data = np.transpose(data)\n    data = np.reshape(data, (num_rows, num_columns, width, height))\n    rows_data, columns_data = data.shape[0], data.shape[1]\n    heights = [slc[0].shape[0] for slc in data]\n    widths = [slc.shape[1] for slc in data[0]]\n    fig_width = 12.0\n    fig_height = fig_width * sum(heights) \/ sum(widths)\n    f, axarr = plt.subplots(\n        rows_data,\n        columns_data,\n        figsize=(fig_width, fig_height),\n        gridspec_kw={\"height_ratios\": heights},\n    )\n    for i in range(rows_data):\n        for j in range(columns_data):\n            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n            axarr[i, j].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n    plt.show()\n# Visualize montage of slices.\n# 5 rows and 10 columns for 100 slices of the CT scan.\nplot_slices(3, 10, 256, 256, image[:, :, :30])","0fc7933b":"from keras.utils import Sequence\nclass Dataset(Sequence):\n    def __init__(self,df,is_train=True,batch_size=1,shuffle=True):\n        self.idx = df[\"BraTS21ID\"].values\n        self.paths = df[\"BraTS21ID5\"].values\n        self.y =  df[\"MGMT_value\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n   \n    def __getitem__(self,ids):\n        id_path= self.paths[ids]\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x =  load_dicom_images_3d(id_path)#str(scan_id).zfill(5)\n        #list_x =  [load_dicom_images_3d(x) for x in batch_paths]\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X,batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","fca5d9c1":"#train_dataset = Dataset(df_train)\n#valid_dataset = Dataset(df_valid)\ntest_dataset = Dataset(test,is_train=False)","464f83c5":"for i in range(1):\n    image = test_dataset[i]\n    print(\"Dimension of the CT scan is:\", image.shape)\n    plt.imshow(image[0,:,:, 30], cmap=\"gray\")\n    plt.show()","90acef27":"def get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n     \n    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.01)(x)\n    \n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.02)(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.03)(x)\n\n    x = layers.Conv3D(filters=512, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.04)(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=1024, activation=\"relu\")(x)\n    x = layers.Dropout(0.08)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n\n    return model\n\n# Build model.\nmodel = get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=64)\nmodel.summary()","ff925929":"model.load_weights('..\/input\/brain-tumor-3d-classification-weights2\/Brain_3d_cls_FLAIR.h5')","c8cffdfe":"preds = model.predict(test_dataset)\npreds = preds.reshape(-1)","35b6bffa":"preds","183f1083":"submission = pd.DataFrame({'BraTS21ID':sample_submission['BraTS21ID'],'MGMT_value':preds})","fbc90fb1":"submission","ab773d24":"submission.to_csv('submission.csv',index=False)","f859ff70":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","aa32cfc5":"### Hi kagglers, This is `Inference` notebook using `Keras`.\n\n> \n* [Brain Tumor 3D [Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/brain-tumor-3d-training) \n* [Brain Tumor 3D [EDA]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/brain-tumor-3d-eda)\n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","ac636559":"#  Custom Data Generator","d3d3103c":"# \ud83e\udde0 Brain Tumor 3D [Inference]","28879e23":"# Functions to load images\n","531cdb8a":"# Loading Model","982807a3":"# Make predictions","f9889234":"# References","c428ffc6":"## \u2600\ufe0f Importing Libraries","f4429ff8":"# Loading Data","7e09af10":"1. https:\/\/keras.io\/examples\/vision\/3D_image_classification\/\n1. https:\/\/www.kaggle.com\/rluethy\/efficientnet3d-with-one-mri-type\n","bb612fc1":"![download.jpg](attachment:bcd79dfb-f7c2-459e-bc2c-d2da9813d10d.jpg)","9bb4fa55":"model = keras.Model()\nmodel = tf.keras.models.load_model('..\/input\/brain-tumor-3d-weights-l\/Brain_3d_cls_FLAIR.h5')"}}