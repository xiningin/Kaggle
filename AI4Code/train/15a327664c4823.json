{"cell_type":{"565a43ec":"code","a7457ef6":"code","aa39c127":"code","75c9fbd9":"code","ed64b7f0":"code","4e26ddd4":"code","d8818427":"code","031c9650":"code","6a7c4d8c":"code","ab7770dd":"code","6a092edf":"code","64f24667":"code","b6f1df72":"code","68dfd3bc":"code","b92b3a44":"code","b2561b6d":"code","2438f8d0":"code","81f43f74":"code","0c93d7a7":"code","e19d9506":"code","c61066e6":"code","6bceafbb":"code","5a449130":"code","1eb6b3e9":"code","d717b5aa":"code","3ff3eb38":"code","ec02e9f5":"markdown"},"source":{"565a43ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a7457ef6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","aa39c127":"# loading data\ndata = pd.read_csv('\/kaggle\/input\/kaggle_fake_train.csv')\ndata.head()","75c9fbd9":"# lets build the model on title and label\ndata_filtered = data.copy(deep= True)\ndata_filtered.drop(columns = ['id', 'author', 'text'],axis = 1, inplace = True)\ndata_filtered.head()","ed64b7f0":"# visualizing target class\nplt.style.use('seaborn')\nsns.countplot(x = 'label', data = data_filtered)\nplt.show()","4e26ddd4":"# checking for missing values\ndata_filtered.isna().sum()","d8818427":"# dropping missing values\ndata_filtered.dropna(inplace= True)\ndata_filtered.isna().sum()","031c9650":"print('original data shape: {}'.format(data.shape))\nprint('shape of the data after handling nulls : {}'.format(data_filtered.shape))","6a7c4d8c":"data_filtered.head()","ab7770dd":"data_filtered.reset_index(inplace = True)\ndata_filtered.head()","6a092edf":"import nltk\nimport re\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","64f24667":"corpus = []\nps = PorterStemmer()\n\nfor i in range(0,data_filtered.shape[0]):\n\n  # Cleaning special character from the news-title\n  title = re.sub(pattern='[^a-zA-Z]', repl=' ', string=data_filtered.title[i])\n\n  # Converting the entire news-title to lower case\n  title = title.lower()\n\n  # Tokenizing the news-title by words\n  words = title.split()\n\n  # Removing the stopwords\n  words = [word for word in words if word not in set(stopwords.words('english'))]\n\n  # Stemming the words\n  words = [ps.stem(word) for word in words]\n\n  # Joining the stemmed words\n  title = ' '.join(words)\n\n  # Building a corpus of news-title\n  corpus.append(title)","b6f1df72":"corpus[:10]","68dfd3bc":"# bag of words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features= 1000, ngram_range= (1,3))\nX = cv.fit_transform(corpus).toarray()\nX","b92b3a44":"print(X.ndim)\nprint(X.shape)","b2561b6d":"y = data_filtered['label']\ny","2438f8d0":"# train and test split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)","81f43f74":"X_test","0c93d7a7":"# model\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nmodel = nb.fit(X_train,y_train)","e19d9506":"\nprint('training score: {}'.format(model.score(X_train, y_train)))\nprint('testing score: {}'.format(model.score(X_test, y_test)))","c61066e6":"# predictions\ny_pred = model.predict(X_test)","6bceafbb":"# performance metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_test, y_pred)\ncm","5a449130":"# other way\npd.crosstab(y_test, y_pred, rownames=['actual'], colnames= ['predicted'])","1eb6b3e9":"print(classification_report(y_test, y_pred))","d717b5aa":"# model accuracy\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, y_pred))","3ff3eb38":"\nprint(y_test[:10])\nprint(y_pred[:10])","ec02e9f5":"### There is misclassification because our model performance was 88% :)"}}