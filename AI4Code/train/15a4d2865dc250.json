{"cell_type":{"59a13893":"code","95876f5b":"code","5c2aa5d3":"code","fb34984c":"code","19ca2e09":"code","e0daf653":"markdown","4fa603b5":"markdown","25734551":"markdown","bef66d3d":"markdown","cdb1c2af":"markdown","26811ede":"markdown","994641bb":"markdown","66eb1329":"markdown","51967038":"markdown"},"source":{"59a13893":"from keras.applications import VGG19\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nfrom numpy import newaxis\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,Dense,Activation,Dropout,Flatten,BatchNormalization\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom keras.applications import VGG19\nfrom skimage.feature import local_binary_pattern\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom tensorflow.keras.regularizers import l2\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","95876f5b":"ad_time = '..\/input\/cartoon-classification\/cartoon_classification\/TRAIN\/adventure_time\/adventure_time_1033.jpg'\nad_time = cv2.imread(ad_time)\nprint(\"Sample Image\",\", Image shape is: \",ad_time.shape,\", type is : \",type(ad_time))\nad_time= cv2.cvtColor(ad_time, cv2.COLOR_BGR2RGB)\nplt.imshow(ad_time)","5c2aa5d3":"img_width, img_height = 250, 350 #\ntrain_data_dir = r'..\/input\/cartoon-classification\/cartoon_classification\/TRAIN'\nvalidation_data_dir = r'..\/input\/cartoon-classification\/cartoon_classification\/TEST\/'\n\nbatch_size = 8\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    vertical_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n","fb34984c":"numberOfClass=10\nbatch_size = 8\nepochs=8\n\n\nvgg = VGG19(include_top= False, weights = \"imagenet\", input_shape=(250,350,3))\nvgg_layer_list = vgg.layers\n\nmodel = Sequential ()\n\nfor layer in vgg_layer_list:\n    model.add(layer)\n    \nfor layer in model.layers:\n    layer.trainable = False\n    \n    \nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\nmodel.summary()\n\nopt = Adam(lr=0.001)\n\nmodel.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n\nhist = model.fit_generator(\n        generator=train_generator,\n        steps_per_epoch = 1500,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps = 220,\n        shuffle=True)","19ca2e09":"print(hist.history.keys())\n\nplt.plot(hist.history[\"loss\"], label =\"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label =\"Validation Loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(hist.history[\"accuracy\"], label =\"Train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"], label =\"Validation accuracy\")\nplt.legend()\nplt.show()","e0daf653":"## $\\color{Pink}{\\text{Chapter 1. Introduction}}$ <a class=\"anchor\" id=\"chapter1\"><\/a>","4fa603b5":"## $\\color{Pink}{\\text{Chapter 3. Conclusion}}$ <a class=\"anchor\" id=\"chapter3\"><\/a>","25734551":"\n## $\\color{Pink}{\\text{Table of Contents}}$\n\n* [Chapter 1. Introduction](#chapter1)     \n* [Chapter 2. VGG19 Training](#chapter2)\n* [Chapter 3. Conclusion](#chapter3)\n\n\n\n\n\n ### ****$\\color{orange}{\\text{If You like my work, Please upvote!}}$****","bef66d3d":"Hello Everyone!!\n\nI prepared a dataset for all deep learning enthusiast to practice their skills with deeplearning classification, hyperparameter optimization, dealing with overfitting, style transfer and more. Let me explain the nature of the dataset to understand the problem better. Dataset contains at least 10k training images from 10 different famous cartoon scenes. Scenes are prepared from several sequences of different episodes. After that, i croped the frames and save them. Test set contains images in the same logic from different episodes.\n\nThe task is: To develop a predictor decides which image or frame will belong to which cartoon.","cdb1c2af":"![1_Q_bg1E3trWcjdk9_jnVGwg.png](attachment:db5d7213-e121-4397-b4f2-d5e71d69932c.png)\n\n\n","26811ede":"![kaggle (1).jpg](attachment:279d4d55-c678-43c7-9b3d-5825bc794aea.jpg)","994641bb":"As conclusion, on Cartoon Classification dataset we got apprx. 0.8 accuracy on test step only with 8 epcohs. A long training (~100 epochs ) with early stopping callback will be a nice training. Morely, for hyperparameter optimization, using a search method (grid search, random search, hyperopt, optuna) would be the exact solution. \n\nSo you are free to give a try on the dataset!! and play with little more.\n\n\n**UPVOTE** if you like my effort (dataset prep. and first notebook) Thanks!!","66eb1329":"## $\\color{Pink}{\\text{Chapter 2. VGG19 Training}}$ <a class=\"anchor\" id=\"chapter2\"><\/a>","51967038":"VGG19 is a well known traditional CNN architecture. It is trained on iamgenet dataset which has 1000 classes. Here we will use TRANSFER LEARNING VGG19 on already trained on imagenet. We will freeze the weights of the convolutional blocks and only traine the 2 fully connected layer's weights. After that we will have a 10 dense softmax for categorical classification. "}}