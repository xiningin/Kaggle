{"cell_type":{"fb94591b":"code","e1fcb3a6":"code","d6ac4eac":"code","b2805590":"code","39ff7559":"code","f2388524":"code","becdb618":"code","78d42485":"code","94a2f4d8":"code","89c98d58":"code","fe61f751":"code","4ecad48c":"code","1a391598":"code","dca2cd15":"code","a26bf788":"code","8a77dd3c":"code","41d38033":"code","b7220c05":"code","39b8efd5":"code","0f160484":"code","66ff88ab":"code","87f146c3":"code","c9efb455":"code","f50dd726":"code","09057db7":"code","df2a0091":"code","d1553c47":"code","0f0ec80b":"code","9f749ca9":"code","ed23651d":"code","6abffcdd":"code","f7e215e8":"code","4b7abb6a":"code","5245e244":"code","122676dc":"code","76cdaf16":"code","9883cc2b":"code","93c0fa4d":"code","d3842dc5":"code","305fed4d":"code","39f0bd9d":"code","d0906290":"code","c3f49906":"code","e296066c":"code","f373756d":"code","0c7e8e49":"markdown","88f3f667":"markdown","5001edfd":"markdown","a35fdad7":"markdown","35f1233c":"markdown","e40a8c57":"markdown","021562de":"markdown","2c709681":"markdown","b8947af6":"markdown","850ebdc9":"markdown","0fa8596f":"markdown","42931ea7":"markdown","aea251b7":"markdown","ee8bfbe8":"markdown","a4ff9ca7":"markdown","6dd8b4ee":"markdown","31b68d46":"markdown","2984339f":"markdown"},"source":{"fb94591b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nplt.style.use([\"seaborn-bright\",\"dark_background\"])","e1fcb3a6":"data = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndata.head()","d6ac4eac":"data.info()","b2805590":"for i in data.columns:\n    perc = data[i].isnull().sum()\n    print(\"Missing data in column {} = {}%\".format(i,(perc\/len(data))*100))","39ff7559":"data.describe()","f2388524":"val = [\"bmi\"]\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values= np.nan, strategy=\"mean\" )\ndata[val] = imputer.fit_transform(data[val])","becdb618":"cat_data = [x for x in data.columns if data[x].dtype == \"object\"]\nnum_data = [y for y in data.columns if data[y].dtype != \"object\"]","78d42485":"for i in cat_data:\n    print(i,\" = \",data[i].unique())","94a2f4d8":"for i in cat_data:\n    plt.figure(figsize=(8,5))\n    sns.countplot(data[i])\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","89c98d58":"data['gender'].value_counts()","fe61f751":"data.shape","4ecad48c":"data = data[data.gender!=\"Other\"]","1a391598":"for i in num_data:\n    plt.figure(figsize=(8,5))\n    sns.histplot(data[i],kde=True)\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","dca2cd15":"num_data = [\"age\",\"avg_glucose_level\",\"bmi\"]\nfor i in num_data:\n    plt.figure(figsize=(8,5))\n    sns.boxplot(data[\"work_type\"],data[i],hue=data[\"gender\"])\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","a26bf788":"def find_outliers(feature):\n    q1 = data[feature].quantile(0.25)\n    q3 = data[feature].quantile(0.75)\n    iqr = q3 - q1\n    upper = q3 + 1.5*iqr\n    lower = q1 - 1.5*iqr\n    return upper,lower","8a77dd3c":"def func(feature):\n    upper,lower = find_outliers(feature)\n    data[feature] = np.where(data[feature]>upper,upper,data[feature])\n    data[feature] = np.where(data[feature]<lower,lower,data[feature])","41d38033":"for feature in num_data:\n    func(feature)    ","b7220c05":"cat_data","39b8efd5":"data = pd.get_dummies(data,columns=[\"gender\",\"ever_married\",\"Residence_type\"],drop_first=True)\ndata = pd.get_dummies(data,columns=[\"work_type\",\"smoking_status\"],drop_first=False)","0f160484":"data = data.drop(columns=[\"id\"])","66ff88ab":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,cmap=\"rainbow\")\nplt.title(\"Correleation Heatmap\",fontsize=20,color=\"c\")\nplt.show()","87f146c3":"X = data.drop(columns=[\"stroke\"])\nY = data[\"stroke\"]","c9efb455":"from sklearn.model_selection import train_test_split\nx1_train,x1_test,y1_train,y1_test = train_test_split(X,Y,test_size=0.2,random_state=100)","f50dd726":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(n_estimators=100)","09057db7":"RFC.fit(x1_train,y1_train)\nRFC.score(x1_train,y1_train)","df2a0091":"y1_train = pd.DataFrame(y1_train,columns=[\"stroke\"])\ny1_train.stroke.value_counts()","d1553c47":"RFC.score(x1_test,y1_test)","0f0ec80b":"prob1 = RFC.predict_proba(x1_test)","9f749ca9":"from sklearn.metrics import confusion_matrix,classification_report\nprint(\"For train data \\n\",confusion_matrix(y1_train,RFC.predict(x1_train)))\nprint(\"For test data \\n\",confusion_matrix(y1_test,RFC.predict(x1_test)))","ed23651d":"print(\"For train data \\n\",classification_report(y1_train,RFC.predict(x1_train)))\nprint(\"For test data \\n\",classification_report(y1_test,RFC.predict(x1_test)))","6abffcdd":"from imblearn.over_sampling import SMOTE\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=100)\nsm = SMOTE(random_state=27)\nx_train, y_train = sm.fit_resample(x_train, y_train)\nx_train.shape, y_train.shape\n","f7e215e8":"y_train = pd.DataFrame(y_train, columns = ['stroke'])","4b7abb6a":"y_train.stroke.value_counts()","5245e244":"sm = SMOTE(random_state=27)\nx_test, y_test = sm.fit_resample(x_test, y_test)\nx_test.shape, y_test.shape","122676dc":"y_test = pd.DataFrame(y_test, columns = ['stroke'])\ny_test.stroke.value_counts()","76cdaf16":"RFC.fit(x_train,y_train)","9883cc2b":"RFC.score(x_train,y_train)","93c0fa4d":"RFC.score(x_test,y_test)","d3842dc5":"prob = RFC.predict_proba(x_test)","305fed4d":"from sklearn.metrics import confusion_matrix,classification_report\nprint(\"For train data \\n\",confusion_matrix(y_train,RFC.predict(x_train)))\nprint(\"For test data \\n\",confusion_matrix(y_test,RFC.predict(x_test)))","39f0bd9d":"print(\"For train data \\n\",classification_report(y_train,RFC.predict(x_train)))\nprint(\"For test data \\n\",classification_report(y_test,RFC.predict(x_test)))","d0906290":"from sklearn.metrics import precision_recall_curve\nprecision_points, recall_points, threshold_points = precision_recall_curve(y1_test,prob1[:,1])\nplt.figure(dpi =100, figsize=(6,6))\nplt.plot(threshold_points, precision_points[:-1], color = 'r', label = 'Precision')\nplt.plot(threshold_points, recall_points[:-1], color = 'b', label = 'Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Frequency')\nplt.title('Precision-Recall Curve for X1_Test')\nplt.legend()\nplt.show()","c3f49906":"from sklearn.metrics import precision_recall_curve\nprecision_points, recall_points, threshold_points = precision_recall_curve(y_test,prob[:,1])\nplt.figure(dpi =100, figsize=(6,6))\nplt.plot(threshold_points, precision_points[:-1], color = 'r', label = 'Precision')\nplt.plot(threshold_points, recall_points[:-1], color = 'b', label = 'Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Frequency')\nplt.title('Precision-Recall Curve for X_Test')\nplt.legend()\nplt.show()","e296066c":"from sklearn.metrics import roc_curve,roc_auc_score\nfpr, tpr, threshold = roc_curve(y1_test ,prob1[:,1])\nplt.figure(dpi = 100, figsize=(8,6))\nplt.plot(fpr,tpr, color = 'r', label='FPR-TPR')\nplt.plot([0,1],[0,1], color = 'g', label = 'Baseline')\nplt.title('AUC-ROC Curve for X1_Test')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend()\nplt.show()","f373756d":"from sklearn.metrics import roc_curve,roc_auc_score\nfpr, tpr, threshold = roc_curve(y_test ,prob[:,1])\nplt.figure(dpi = 100, figsize=(8,6))\nplt.plot(fpr,tpr, color = 'r', label='FPR-TPR')\nplt.plot([0,1],[0,1], color = 'g', label = 'Baseline')\nplt.title('AUC-ROC Curve for X_Test')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend()\nplt.show()","0c7e8e49":"#### Visualizing categorical values using countplot.","88f3f667":"### AUC-ROC curve for balanced dataset.","5001edfd":"### Importing libraries and dataset.","a35fdad7":"#### Ploting boxplot to check outliers.","35f1233c":"#### Ploting histogram for numerical values.","e40a8c57":"#### Removing outliers.","021562de":"#### Train score.","2c709681":"#### Test score.","b8947af6":"#### Classification Report.","850ebdc9":"### Precision-Recall curve for balanced dataset.","0fa8596f":"#### Ploting correleation heatmap.","42931ea7":"#### Creating dummies.","aea251b7":"#### Confusion matrix.","ee8bfbe8":"### Precision-Recall curve for imbalanced dataset.","a4ff9ca7":"#### Removing the row with \"Other\" as gender value as it is only 1 in count.","6dd8b4ee":"### Checking for missing value percentage.","31b68d46":"### AUC-ROC curve for imbalanced dataset.","2984339f":"#### The precision , recall and f1-score for class 1 is very bad, as our dataset is imbalanced. So now we will balance the dataset using the library imblearn."}}