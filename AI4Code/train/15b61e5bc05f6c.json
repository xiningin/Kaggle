{"cell_type":{"ed9850f6":"code","be47ccb4":"code","0c05cb00":"code","25fa82d8":"code","b5422f69":"code","910f76de":"code","15553863":"code","dd65ff61":"code","83f9eac1":"code","e539e442":"code","0daedbb6":"code","38b81c40":"markdown","94430f67":"markdown"},"source":{"ed9850f6":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\nfrom keras.models import Sequential\n\nimport glob, os, random","be47ccb4":"base_path = '..\/input\/garbage classification\/Garbage classification'\n\nimg_list = glob.glob(os.path.join(base_path, '*\/*.jpg'))\n\nprint(len(img_list))","0c05cb00":"for i, img_path in enumerate(random.sample(img_list, 6)):\n    img = load_img(img_path)\n    img = img_to_array(img, dtype=np.uint8)\n\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img.squeeze())","25fa82d8":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.1\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    seed=0\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    base_path,\n    target_size=(300, 300),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    seed=0\n)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nprint(labels)","b5422f69":"model = Sequential([\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n    MaxPooling2D(pool_size=2),\n\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    \n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n\n    Flatten(),\n\n    Dense(64, activation='relu'),\n\n    Dense(6, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","910f76de":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","15553863":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","dd65ff61":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","83f9eac1":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","e539e442":"model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)","0daedbb6":"test_x, test_y = validation_generator.__getitem__(1)\n\npreds = model.predict(test_x)\n\nplt.figure(figsize=(16, 16))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n    plt.title('pred:%s \/ truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))\n    plt.imshow(test_x[i])","38b81c40":"# Another Shot","94430f67":"# Take a Shot"}}