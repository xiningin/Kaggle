{"cell_type":{"a107b27e":"code","dbf6ed89":"code","eb607f21":"code","6b9d7012":"code","3d55ed1d":"code","032812f8":"code","3148b153":"code","f0920e0c":"code","df0af6d7":"code","270d9820":"code","aaf49f0b":"code","466cc624":"code","2add5ae1":"code","642a46f4":"code","e3382ad6":"code","2aff1d58":"code","8ae1a971":"code","3ed46961":"code","a77d1337":"code","4683fa91":"code","138a8e9a":"code","7c31fa80":"code","9a25103c":"code","c3112439":"code","40d9646b":"code","e83419ed":"code","f4b330be":"code","555ef6b7":"code","2a2403ef":"code","4570cac4":"code","dde63408":"code","5d550eaa":"code","4b2380df":"code","a358d2f3":"markdown","4d96959e":"markdown","ac56082c":"markdown","c0c7a245":"markdown","49520d33":"markdown","aca40f6e":"markdown","2f7e99b2":"markdown","9b7f6e4c":"markdown","7af936da":"markdown","3fad2874":"markdown","a790a0f5":"markdown","5748f2b4":"markdown","375ab3cf":"markdown","2062f990":"markdown","fb121eb0":"markdown","52456c97":"markdown","6051f009":"markdown","fbc1d979":"markdown","ab650b9c":"markdown","75f29f9c":"markdown"},"source":{"a107b27e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport time\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier \n%matplotlib inline\n","dbf6ed89":"data_treino=\"..\/input\/adult-pmr3508\/train_data.csv\"\ndata_teste=\"..\/input\/adult-pmr3508\/test_data.csv\"","eb607f21":"data_adult=pd.read_csv(data_treino, names=\n        [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education.num\", \"marital.status\",\n        \"occupation\", \"relationship\", \"race\", \"sex\", \"capital.gain\", \"capital.loss\",\n        \"hours.per.week\", \"country\", \"target\" ],\n        \n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nbase_teste=pd.read_csv(data_teste, sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","6b9d7012":"data_adult.shape","3d55ed1d":"data_adult","032812f8":"n_dadult= data_adult.dropna()\nn_badult= base_teste.dropna()","3148b153":"n_dadult #base de treino sem as linhas com dados faltantes","f0920e0c":"n_badult # base de testes sem as linhas com dados faltantes ","df0af6d7":"n_dadult[\"sex\"].value_counts().plot(kind=\"pie\") #an\u00e1lise de sexos","270d9820":"n_dadult[\"marital.status\"].value_counts().plot(kind=\"bar\") #an\u00e1lise de status civil","aaf49f0b":"n_dadult[\"occupation\"].value_counts().plot(kind=\"bar\") #an\u00e1lise de profiss\u00f5es","466cc624":"# Transformando as vari\u00e1veis categ\u00f3ricas em n\u00fameros (encoding)\ndef number_encode_features(df):\n    result = df.copy()\n    encoders = {}\n    for column in result.columns:\n        if result.dtypes[column] == np.object:\n            encoders[column] = preprocessing.LabelEncoder()\n            result[column] = encoders[column].fit_transform(result[column])\n    return result, encoders\n\n# Calcular a correla\u00e7\u00e3o e plotar um HeatMap\nencoded_data, _ = number_encode_features(n_dadult)\nsns.heatmap(encoded_data.corr(), square=True,vmin=-1, vmax=1)\nplt.show()","2add5ae1":"sns.stripplot('education.num', 'target', data=encoded_data) ","642a46f4":"n_dadult[[\"education\", \"education.num\"]].head(15)","e3382ad6":"#como a coluna education_num \u00e9 a que melhor caracteriza a educa\u00e7\u00e3o, podemos fazer:\ndel n_dadult[\"education\"]","2aff1d58":"#selecionaremos alguns atributos de acordo com as observa\u00e7\u00f5es acima\nattributes = [\"sex\", \"workclass\", \"education_num\", \"occupation\", \"marital_status\"]","8ae1a971":"n_dadult","3ed46961":"encoded_data","a77d1337":"n_badult","4683fa91":"attributes = [\"sex\", \"workclass\", \"education.num\", \"occupation\", \"marital.status\"]","138a8e9a":"train_adult_x = encoded_data[attributes]\ntrain_adult_y = encoded_data.target","7c31fa80":"test_adult_x = n_badult.apply(preprocessing.LabelEncoder().fit_transform) #j\u00e1 numerizando as vari\u00e1veis categ\u00f3ricas","9a25103c":"# utilizaremos os dados num\u00e9ricos para a implementa\u00e7\u00e3o dos 3 algor\u00edtimos\nXtreino=encoded_data[[\"age\",\"education.num\",\"capital.gain\", \"capital.loss\", \"hours.per.week\"]]\nYtreino=encoded_data[[\"target\"]]\nXteste =test_adult_x[[\"age\",\"education.num\",\"capital.gain\", \"capital.loss\", \"hours.per.week\"]]","c3112439":"# fazendo a regress\u00e3o logistica\nlogreg = LogisticRegression()\nlogreg.fit(Xtreino,Ytreino)\nYpred=logreg.predict(Xteste)\n# avalia\u00e7\u00e3o por validacao cruzada\nscores = cross_val_score(logreg, Xtreino, Ytreino, cv=10)\nmed_logreg=np.mean(scores) #media dos valores da valida\u00e7\u00e3o cruzada\n# avalia\u00e7\u00e3o da acur\u00e1cia\nYpredt=logreg.predict(Xtreino)\nac_logreg=accuracy_score(Ytreino,Ypredt,normalize=True,sample_weight=None)","40d9646b":"ac_logreg","e83419ed":"med_logreg","f4b330be":"# fazendo uma floresta aleat\u00f3ria\nrand=RandomForestClassifier(n_estimators=100) #utilizando uma floresta de 100 \u00e1rvores\nrand.fit(Xtreino,Ytreino)\nYpred=rand.predict(Xteste)\n# avalia\u00e7\u00e3o por validacao cruzada\nscores = cross_val_score(rand, Xtreino, Ytreino, cv=10)\nmed_randflor=np.mean(scores) #media dos valores da valida\u00e7\u00e3o cruzada\n# avalia\u00e7\u00e3o da acur\u00e1cia\nYpredt=rand.predict(Xtreino)\nac_randflor=accuracy_score(Ytreino,Ypredt,normalize=True,sample_weight=None)","555ef6b7":"ac_randflor #acur\u00e1cia","2a2403ef":"med_randflor","4570cac4":"arvore = DecisionTreeClassifier()\narvore.fit(Xtreino,Ytreino)\nYpred=arvore.predict(Xteste)\n# avalia\u00e7\u00e3o por validacao cruzada\nscores = cross_val_score(arvore, Xtreino, Ytreino, cv=10)\nmed_arvore=np.mean(scores) #media dos valores da valida\u00e7\u00e3o cruzada\n# avalia\u00e7\u00e3o da acur\u00e1cia\nYpredt=arvore.predict(Xtreino)\nac_arvore=accuracy_score(Ytreino,Ypredt,normalize=True,sample_weight=None)","dde63408":"ac_arvore","5d550eaa":"med_arvore","4b2380df":"knn = KNeighborsClassifier(n_neighbors = 23, p = 1)\nstart = time.time()\nscores = cross_val_score(knn, Xtreino, Ytreino, cv = 10)\nprint('K-Nearest Neighbors CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(scores.mean(), scores.std()))\nprint ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))","a358d2f3":"# 1.2 An\u00e1lises iniciais da base Adult","4d96959e":"# Modelo KNN","ac56082c":"# 1.1.Importa\u00e7\u00e3o de bibliotecas e estrutura\u00e7\u00e3o","c0c7a245":"# 4.0 Implementa\u00e7\u00e3o de Algoritmos","49520d33":"A chamada da base data_treino acima foi feita e agora pode-se analisar melhor as vari\u00e1veis e detalhes","aca40f6e":"# Regressao logistica","2f7e99b2":"# 1.3 Processamento dos bancos de dados","9b7f6e4c":"# 2.0 Data Preparation","7af936da":"# 1.4 Visualiza\u00e7\u00e3o de Dados","3fad2874":"# Modelo Random Forest","a790a0f5":"# Dados da base teste ","5748f2b4":"Trabalho 2 - Base Adult e Classificadores\nMarcos Lucio Afonso Beleza Filho - 11260082","375ab3cf":"# 1.Introdu\u00e7\u00e3o \nO presente trabalho possui como objetivo: testar no m\u00ednimo 3 t\u00e9cnicas de classifica\u00e7\u00e3o na base Adult, para verificar at\u00e9 onde \u00e9 poss\u00edvel chegar em termos de acur\u00e1cia, analisando fatores como dificuldade de implementa\u00e7\u00e3o, de interpreta\u00e7\u00e3o e funcionamento do classificador.","2062f990":"Vamos come\u00e7ar a analisar os dados com um gr\u00e1fico de barras","fb121eb0":"Nesta etapa prepararei os dados para deix\u00e1-los de acordo com as observa\u00e7\u00f5es realizadas acima, sabendo que \"encoded_data\" cont\u00e9m os dados categ\u00f3ricos j\u00e1 numerizados.","52456c97":"# 5.0 Conclus\u00f5es","6051f009":"Acur\u00e1cia:\n Dentre os 4 modelos utilizados, o que se demonstrou mais eficiante diante de menor processamento foi o Tree Classifier, o qual obteve resultado semelhante ao Random Forest e com menos tempo de processamento.\n \nSimplicidade:\nO modelo mais f\u00e1cil de explicar resultados seria o KNN diante dos conceitos estat\u00edsticos j\u00e1 existentes.\n\nData Manipulation:\nHonestamente, a manipula\u00e7ao de dados foi parte confusa para mim, atrapalhei-me ao elabor\u00e1-la e precisei analisar como outras pessoas o fizeram, pois\ncontinuava a ter problemas em rela\u00e7\u00e3o a formata\u00e7\u00e3o da base de dados teste e como pensar na vari\u00e1vel target na mesma.\n","fbc1d979":"Nesse HeatMap obseva-se que h\u00e1 uma maior correla\u00e7\u00e3o entre as vari\u00e1veis Education e Education-Num, RelationShip e Sex, Target e Relationship, Marital Status e Education-Num e outras.","ab650b9c":"# Dados de Treino","75f29f9c":"# Modelo Tree Classifier"}}