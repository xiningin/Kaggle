{"cell_type":{"41af096a":"code","bd3f0b40":"code","fa96720a":"code","2010a098":"code","4a159b44":"code","3e6ca727":"code","b570cc2e":"code","70d7a1d4":"code","db157e8b":"code","2cd7a773":"code","57ed7b58":"code","d29b9adc":"code","fb12faf1":"code","79abcc4c":"code","c955b482":"code","64038485":"code","507ae8a1":"code","04d22a26":"code","4484479f":"code","452bbb13":"code","5090c224":"code","cd3fc8fd":"code","5667ab78":"code","9ff122b9":"code","fd6d804c":"code","7797d098":"code","be3656c9":"markdown","d2e97f06":"markdown","70a5899d":"markdown","72574cd6":"markdown","64848f16":"markdown","c11bc060":"markdown","60993215":"markdown","25e4c6b5":"markdown","04557c8d":"markdown","12441cec":"markdown","91400b06":"markdown","b53bf798":"markdown","20ae577a":"markdown","33914801":"markdown","69a7f4c4":"markdown","f95d75d5":"markdown","cf77b894":"markdown","81aee05f":"markdown","ff7d6f50":"markdown","3f7877e5":"markdown","6173320c":"markdown","2169d604":"markdown","9ec689c8":"markdown"},"source":{"41af096a":"!pip install pandas-bokeh","bd3f0b40":"import pandas as pd\nimport numpy as np\nfrom bokeh.io import output_file,show,output_notebook,push_notebook\nimport pandas_bokeh\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource,HoverTool,CategoricalColorMapper\nfrom bokeh.layouts import row,column,gridplot\nfrom bokeh.models.widgets import Tabs,Panel,DataTable, TableColumn\nfrom bokeh.palettes import Spectral3\noutput_notebook()\npandas_bokeh.output_notebook()\npd.set_option('plotting.backend', 'pandas_bokeh')\n","fa96720a":"%%time\n\ntrain = pd.read_pickle(\"..\/input\/riiid-train-data-multiple-formats\/riiid_train.pkl.gzip\")\n\nprint(\"Train size:\", train.shape)\np=train.head(30)\np.style.set_properties(**{'background-color': 'black',\n                           'color': 'lawngreen',\n                           'border-color': 'white'})","2010a098":"train['prior_question_had_explanation'] = train['prior_question_had_explanation'].astype('bool')\n\ntrain.memory_usage(deep=True)","4a159b44":"print(f\"Total unique users are {train.user_id.nunique()}\")\nprint(f\"However the total interactions which seem to be recorded are {len(train.user_id)}\")\nx=len(train.user_id)\/train.user_id.nunique()\nprint(\"On average the interactions of a user should be\",x) \nprint(train.user_id.value_counts())","3e6ca727":"Users=pd.DataFrame(train.user_id.value_counts())\nUsers=Users[:10]\nUsers.head()\nUsers=Users.rename(columns={\"user_id\" :\"Interactions\"})\nfrom bokeh.palettes import RdYlGn\nUsers['color'] = RdYlGn[len(Users)]\np_bar = Users.plot_bokeh.bar(\n   ylabel=\"No of Interaction\", \n   title=\"Top 10 Most Interactive Users\",\n   alpha=0.6,fill_color='color',line_color=\"white\",fontsize_title=\"18pt\",fontsize_label=\"16pt\",figsize=(1200,800),fontsize_ticks=\"14pt\",hatch_pattern=\"vertical_wave\",hatch_color=\"white\"\n    )\n    ","b570cc2e":"print(sum(train.user_id.value_counts() == 1))\nprint(sum(train.user_id.value_counts() <= 258))\n","70d7a1d4":"x=train.describe()\n# Import seaborn library \ny=x.drop(['count'])\nimport seaborn as sns \ncm = sns.light_palette(\"blue\", as_cmap=True) \ny.style.background_gradient(cmap=cm).set_precision(2)","db157e8b":"%%time\n\nquestions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')\nlectures = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')\nexample_test = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_test.csv')\nexample_sample_submission = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_sample_submission.csv')\nl=example_sample_submission.head()\nl.style.set_properties(**{'background-color': 'black',\n                           'color': 'lawngreen',\n                           'border-color': 'white'})","2cd7a773":"e=questions.head()\ne.style.set_properties(**{'background-color': 'black',\n                           'color': 'lawngreen',\n                           'border-color': 'white'})","57ed7b58":"print(f\"We have {questions.question_id.nunique()} questions for training\")","d29b9adc":"print(questions.bundle_id.value_counts())\nprint(f\"We have {questions.question_id.nunique()} questions for training which are divided in {questions.bundle_id.nunique()} bundles\")","fb12faf1":"bundle=pd.DataFrame(questions.bundle_id.value_counts())\nbundle=bundle[:15]\nbundle.head()\nbundle=bundle.rename(columns={\"bundle_id\" :\"Times used\"})\nfrom bokeh.palettes import Category20c\nbundle['color'] = Category20c[len(bundle)]\n\np_bar = bundle.plot_bokeh.bar(\n   ylabel=\"No of Interaction\", \n   title=\"Top 15 Bundles Used\",\n   alpha=0.6,fill_color='color',line_color=\"white\",fontsize_title=\"18pt\",fontsize_label=\"16pt\",figsize=(1200,800),fontsize_ticks=\"14pt\",hatch_pattern=\"vertical_wave\",hatch_color=\"white\"\n    )\n    ","79abcc4c":"print(f\"Unique bundles of tags {questions.tags.nunique()} which are given to question\")","c955b482":"questions['tags'] = questions['tags'].astype(str)\n\ntags = [x.split() for x in questions[questions.tags != \"nan\"].tags.values]\ntags = [item for elem in tags for item in elem]\ntags = set(tags)\ntags = list(tags)\nprint(f'There are total {len(tags)} different tags')\nprint","64038485":"print(questions.tags[:50])","507ae8a1":"w=lectures.head(5)\nw.style.set_properties(**{'background-color': 'black',\n                           'color': 'lawngreen',\n                           'border-color': 'white'})","04d22a26":"print(f\"We have {lectures.lecture_id.nunique()} different lectures\")","4484479f":"lectures['tag'] = lectures['tag'].astype(str)\n\ntag = [x.split() for x in lectures[lectures.tag != \"nan\"].tag.values]\ntag = [item for elem in tag for item in elem]\ntag = set(tag)\ntag = list(tag)\nprint(f'There are total {len(tag)} different tags')\nprint(tag)","452bbb13":"print(lectures.tag.value_counts())\ny=len(lectures.tag)\/lectures.tag.nunique()\nprint(\"We can check the average to see that how much some lecture are overused\", y )\nprint(sum(lectures.tag.value_counts() == 1))\nprint(sum(lectures.tag.value_counts() >= 2.7))","5090c224":"z=pd.DataFrame(lectures.type_of.value_counts())\nz.style.background_gradient(cmap='Greens_r').set_precision(2)","cd3fc8fd":"time=train.timestamp\ntime.value_counts()","5667ab78":"prior_questions=train[[\"prior_question_elapsed_time\" ,\"prior_question_had_explanation\"]]\nprior_questions.head()","9ff122b9":"prior_questions.prior_question_had_explanation.value_counts()","fd6d804c":"from math import pi\nfrom bokeh.io import output_file, show\nfrom bokeh.palettes import RdYlBu,Viridis\nfrom bokeh.plotting import figure\nfrom bokeh.transform import cumsum\nz = {\n    \"Yes\": 89685560,\n    \"No\":11544772\n}\n\ndata = pd.Series(z).reset_index(name='value').rename(columns={'index':'country'})\ndata['angle'] = data['value']\/data['value'].sum() * 2*pi\ndata['color'] = [\"Green\",\"Darkred\"]\n\np = figure(plot_height=350, title=\"Previous Questions had explanations\", toolbar_location=None,\n           tools=\"hover\", tooltips=\"@country: @value\", x_range=(-0.5, 1.0),background_fill_color=\"beige\")\n\np.wedge(x=0, y=1, radius=0.4,\n        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n        line_color=\"white\", fill_color='color', legend_field='country', source=data)\n\np.axis.axis_label=None\np.axis.visible=False\np.grid.grid_line_color = None\np.title.text_color = \"midnightblue\"\np.title.text_font = \"times\"\np.title.text_font_style = \"italic\"\np.title.text_font_size = \"18pt\"\nshow(p)","7797d098":"pq=pd.DataFrame(prior_questions.prior_question_elapsed_time.value_counts())\npl=pq.head(15)\npx=pl.sort_index()\npx=px.rename(columns={\"Time_elapsed\" :\"Value\"})\nfrom bokeh.palettes import Category20c\npx['color'] = Category20c[len(px)]\n\np_bar = px.plot_bokeh.bar(\n  ylabel=\"No of Interaction\", \n  title=\"Top 10 Time Values Used\",\n  alpha=0.6,fill_color='color',line_color=\"white\",fontsize_title=\"18pt\",fontsize_label=\"16pt\",figsize=(1200,800),fontsize_ticks=\"14pt\",hatch_pattern=\"vertical_wave\",hatch_color=\"white\"\n    )\n","be3656c9":"One of the interesesting thing about this graphs is that perhpaes on medain people take 17 milliseconds to answer the question , whereas I was expecting a downward sloping curver forthe the questions , however a lot of questions take higher time on average and how data is skewed right shows that .","d2e97f06":"Link for my modelling notebook:\nhttps:\/\/www.kaggle.com\/sahilmaheshwari\/making-ensemble-of-catboost-and-lgbm","70a5899d":"Looking at train describe, we can see how almost 63% percent of questions are correctly answered. So , if we can try to keep predictions for unknown target at a baseline of 0.6 .","72574cd6":"# <a id='data' span style=\"color:orange\">Basic EDA and Insights so far<\/a>","64848f16":"Note: While in the earlier editions of Kernel , I was trying to create a basic model , however since I have been using Bokeh for analysis , it requires internet , rendering the modelling useless if done in the same notebook.","c11bc060":"Thus , it seems that there are 151 lectures tags and 188 different question tags.Moreover the tags on the lectures seem to be unrelated , one lecture seems to have one tag which is very interesting .","60993215":"Note : I still have to also check with regards to Part , while related to TOEIC , it also seems to be important ","25e4c6b5":"The data shows how some users have way more interactions while studying , while some users have quite less interactions. The data is skewed , some questions which I am now thinking about are :\n1.) Our predictions will vary with regards to how much user has already interacted with platform , but one hypotheses which should be tested with regards if he faces a new topic or new user interacts with the question to check the prediction should we keep the threshold with regards to how new users performed.","04557c8d":"In the description, timestamp is decribed as the time in milliseconds between this user interaction and the first event completion from that user.\nSo perhaps it could mean that user is required to do a event(i.e lecture or answers questions when he first joins the site.)","12441cec":"## <span style=color:Coral>Analyzing Time-series Data\n    \nWell , one of the most interesting findings which can be explored with respect to the competition seems to be analyzing the time-series data and even getting the different properties of the question which can be helped in creating the questions .\n    ","91400b06":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\" >\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of Contents<\/h3>\n  <a span style =\"color:orange\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#data\" role=\"tab\" aria-controls=\"profile\">Introduction to Riids Competition<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n    <a span style =\"color:orange\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#data\" role=\"tab\" aria-controls=\"profile\"> References <span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a span style =\"color:orange\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#down\" role=\"tab\" aria-controls=\"messages\">Basic EDA and Insights so far<span class=\"badge badge-primary badge-pill\" >3<\/span><\/a>\n ","b53bf798":"Hi, I have taken this code directly from Erik's notebook .","20ae577a":"# <span style= color:coral>Checking Lectures Data ","33914801":"### Fin\n\nWhile this is a quick eda , there still seems to be many areas for inspecting , feature tag can be checked for correlation with question and even with respect to other tags to understand what kind of relations do they have .\nWhile lectures tags are a bit different , these tags seem to be the kind of topics , however lectures having different tags is a bit unexpected . \n### <span style = color:Salmon> If you liked the notebook, please upvote , but more importantly please drop down suggestions\/critiques, I would love to improve on those areas !! ","69a7f4c4":"So there are 1519 different bundles of tags which are made with 188 tags , we can try to find which tags are more related to each other perhaps as use tags correlation to understand the the question. I have to furthur explore this aspect . Just looking at head you can see how 9, 10 are more related and even 131 and 162 seem to be more correlated ","f95d75d5":" # <a id='data' span style=\"color:orange\">References<\/a>\nFirst and foremost I want to acknowlegde the notebooks which I have taken the inspiration from to create this notebook. If you consider upvoting this notebook , please upvote these as well. I would highly encourage you to read them to get the gist of the problem  :\n \n https:\/\/www.kaggle.com\/erikbruin\/riiid-comprehensive-eda-baseline\n \n https:\/\/www.kaggle.com\/isaienkov\/riiid-answer-correctness-prediction-eda-modeling\n \n https:\/\/www.kaggle.com\/carlmcbrideellis\/riiid-eda-and-feature-importance","cf77b894":"My insight on this : \nSo one of thing I have noticed is that the values are in multiples of each other , if you look carefully. When we just look at the compelete dataframe , while unique values might be different, row_id is 2 times user_id , which might show that at two transactions were taken per user atleast.So let's check the different hypothesis which can be made from the same .","81aee05f":"So only 87 users are it seems having only one interaction, and more than 320000 users are having less than what was supposed average amount of interactions , so should all the values above the threshold i.e some 10.000 values be considered as outliers !! ","ff7d6f50":" ## <span style= color:Aquamarine> Small Summary of Data \nWe have been given `Train.csv` which contains the data which is in relation to the user , `questions.csv` contains all the data with regards to the questions which are posed to the user , `lectures.csv` contains all the data with regards to lectures , in the `test data` there seems to be the same data as train.csv but it includes two more rows `prior_group_responses` and `prior_group_answers_correct`i.e it contains data of user with regards to his previous performance and how many questions he has responded correctly . Thus the task is to  predict how a user would fare to a new question when we have been provided his past data.\n\nFor detailed information of the csvs: https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/data","3f7877e5":"We import the required libraries and use the pickle which had been generously created by @Vopani","6173320c":"# <a id='data' span style=\"color:orange\">Introduction to Riids Competition<\/a>\nThe competition has been quite interesting so far, and there still remains room for more improvement.\nIn this competition , we have been given tabular data , and it seems to be the case of supervised learning problem.\n\n![image.png](attachment:image.png)","2169d604":"## *Loading Train Data*","9ec689c8":"# <span style= color:Navy>Checking Question Data"}}