{"cell_type":{"7e2a22da":"code","2f37f26f":"code","7fff2934":"code","476d1763":"code","b7e3678f":"code","722b8bbd":"code","0029d11f":"code","ccc0ce9e":"code","e07ed13d":"code","6f66c1e9":"code","f1eb6f87":"code","57c28645":"code","042ff091":"code","51826f75":"code","40211a8e":"code","5198c369":"code","cd560148":"code","d555cbfe":"code","703355ca":"code","96634425":"code","35398648":"code","9e71a0f3":"code","bf605314":"code","620e4c5b":"code","59a164ba":"code","66bf92f8":"code","334a03ad":"code","1ef3505f":"code","7e15d020":"code","77fd60c1":"markdown","67bdc3e7":"markdown","2a00036c":"markdown","29b473d8":"markdown","2f182dc6":"markdown","82f676aa":"markdown","ade65e9a":"markdown","b49b56eb":"markdown","03c5ad49":"markdown","3c072e44":"markdown","e3a35536":"markdown","8bc9c91f":"markdown","01928b46":"markdown"},"source":{"7e2a22da":"import pandas as pd\nimport numpy as np\n\nimport random, os\n\nimport cv2\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.optimizers import Adam","2f37f26f":"base_dir = '..\/input\/hackerearth-deep-learning-identify-the-snake-breed\/dataset'\ntrain_img_dir = os.path.join(base_dir, 'train\/')\ntrain_images = os.listdir(train_img_dir)\n\ntest_img_dir = os.path.join(base_dir, 'test\/')\n","7fff2934":"print(train_img_dir)\nprint(len(train_images))","476d1763":"train_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\ntrain_df.head()","b7e3678f":"def append_ext(fn):\n    return fn+\".jpg\"\n\ntrain_df[\"image_id\"]=train_df[\"image_id\"].apply(append_ext)\ntrain_df.head()","722b8bbd":"num_classes = len(train_df.breed.unique())\nnum_classes","0029d11f":"train_df.info()","ccc0ce9e":"train_df[\"breed\"] = train_df[\"breed\"].astype('category')\ntrain_df.dtypes","e07ed13d":"train_df[\"label\"] = train_df[\"breed\"].cat.codes\ntrain_df.head()","6f66c1e9":"# Check Categories.\nLABEL = train_df[\"breed\"].cat.categories\nLABEL","f1eb6f87":"LABEL[15], LABEL[25]","57c28645":"plt.figure(figsize=(20,8))\nax = sns.countplot(x=\"breed\", data=train_df) \nplt.xticks(rotation = 90)","042ff091":"((train_df.groupby('breed').size()\/train_df['breed'].count())*100 ).sort_values(ascending=False)","51826f75":"uniqueIds = train_df['image_id'].nunique()\n\nif(uniqueIds == len(train_df)):\n    print('There are no repeating Image IDs in the dataset')\nelse:\n    print('There are {len(train_df) - uniqueIds} repeating Image IDs')","40211a8e":"# Main parameters\nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = len(train_df)*0.8 \/ BATCH_SIZE\nVALIDATION_STEPS = len(train_df)*0.2 \/ BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 300","5198c369":"train_df.label = train_df.label.astype('str')\ntrain_df.head()","cd560148":"train_df.info()","d555cbfe":"train_datagen = ImageDataGenerator(\n    validation_split = 0.2,\n    preprocessing_function = None,\n    rotation_range = 20,\n    zoom_range = 0.2,\n    cval = 0.1,\n    horizontal_flip = True,\n    vertical_flip = True,\n    fill_mode = 'nearest',\n    shear_range = 0.15,\n    height_shift_range = 0.15,\n    width_shift_range = 0.15,\n    featurewise_center = True,\n    featurewise_std_normalization = True\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory = train_img_dir,\n    subset = \"training\",\n    x_col = \"image_id\",\n    y_col = \"label\",\n    target_size = (TARGET_SIZE, TARGET_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = \"sparse\"\n)","703355ca":"validation_datagen = ImageDataGenerator(validation_split = 0.2)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    train_df,\n    directory = train_img_dir,\n    subset = \"validation\",\n    x_col = \"image_id\",\n    y_col = \"label\",\n    target_size = (TARGET_SIZE, TARGET_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = \"sparse\"\n)","96634425":"conv_base = EfficientNetB0(\n    include_top = False, \n    weights = 'imagenet',\n    input_shape = (TARGET_SIZE, TARGET_SIZE, 3)\n)\n\nmodel = conv_base.output\nmodel = layers.GlobalAveragePooling2D()(model)\nmodel = layers.Dense(5, activation = \"softmax\")(model)\nmodel = models.Model(conv_base.input, model)\n\nmodel.compile(\n    optimizer = Adam(lr = 0.001),\n    loss = \"sparse_categorical_crossentropy\",\n    metrics = [\"acc\"]\n)\n\nmodel.summary()","35398648":"early_stop = EarlyStopping(\n    monitor = 'val_loss', \n    min_delta = 0.001, \n    patience = 5, \n    mode = 'min', \n    verbose = 1,\n    restore_best_weights = True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor = 'val_loss', \n    factor = 0.3, \n    patience = 2, \n    min_delta = 0.001, \n    mode = 'min', \n    verbose = 1\n)","9e71a0f3":"model_save = ModelCheckpoint(\n    '.\/SnakeBreed_EfficientNetB0_Model_1.h5', \n    save_best_only = True, \n    save_weights_only = True,\n    monitor = 'val_loss', \n    mode = 'min', \n    verbose = 1\n)","bf605314":"history = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n#     callbacks = [early_stop, reduce_lr]\n#     callbacks = [model_save, early_stop, reduce_lr]\n)","620e4c5b":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","59a164ba":"# image_path = os.path.join(train_dir,'8b492b973d'+'.jpg')\n# image_path","66bf92f8":"# img = plt.imread(image_path)\n# plt.imshow(img)\n# plt.title('Original Bree --> pantherophis-vulpinus')\n# plt.show()","334a03ad":"# img_for_prediction = load_img(image_path, target_size = input_dim)\n# img_for_prediction = img_to_array(img_for_prediction)\n# img_for_prediction = img_for_prediction.reshape((1, *img_for_prediction.shape))\n# img_for_prediction = preprocess_input(img_for_prediction)","1ef3505f":"# predictions = model.predict(img_for_prediction)\n# pred = np.argsort(predictions)[0][-5:]\n# pred \n# # the Order is from 0 to 5 and 5th Position breed is highest.","7e15d020":"# le.inverse_transform(pred)","77fd60c1":"# Visualize the Images.\nAlready done in my other Notebooks Refer to \n1. https:\/\/www.kaggle.com\/dskagglemt\/identify-the-snake-breed\n2. https:\/\/www.kaggle.com\/dskagglemt\/snake-breed-classification-vgg","67bdc3e7":"# Set Directory Path","2a00036c":"# Visualize the Performance","29b473d8":"# Target Information from csv file","2f182dc6":"So we found that 9+% of data belongs to breed \"thamnophis-sirtalis\" and downup to 1+5 for breed \"crotalus-scutulatus\".","82f676aa":"# Training the Model","ade65e9a":"# Converting Target (breed) into Numerical","b49b56eb":"# Prediction\n\nImage ID : 8b492b973d\t\n\nBreed : pantherophis-vulpinus\n   ","03c5ad49":"In the image_id we do not have image extension, so lets first add the .jpg extension, so that we can refer to the image_id directly and refer to its image.","3c072e44":"# Class Distribution\nLets visualize the Class distribution.","e3a35536":"# Import Library","8bc9c91f":"Identify the snake breed\nhttps:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-deep-learning-challenge-snake-breed-detection\/machine-learning\/identify-the-snake-breed-5-66d9a9f5\/\n\nThis is a challenge from HackerEarth.com, and one of the participant from HE has uploaded the dataset on Kaggle. Refer below details on the challenge.\n\n# Problem statement\nThe government has been facing a long-standing issue of wild animals entering residential areas due to various reasons. It's of critical importance that if any such dangerous animal is encountered, the concerned authority should be notified immediately. Reptiles, especially snakes, are among the most dangerous animals and they often enter residential areas.\n\nRecently due to an incident of a youngster getting bitten by a snake, the government decided to install cameras at every corner of the road to detect snakes and other animals.\n\nYou have been hired as a Deep Learning engineer to create a sophisticated model that can detect the breed of a snake from its image.","01928b46":"# Check for Duplicate"}}