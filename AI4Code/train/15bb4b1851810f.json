{"cell_type":{"01979508":"code","d056fce8":"code","f8dbff01":"code","02eb1caf":"code","a97f59c9":"code","7f80a468":"code","c98cbfe3":"code","0b0b6600":"code","698f5d5c":"code","9cfb40b1":"code","bc2689b4":"code","77165ea1":"code","45578529":"code","04d4083f":"code","7a1fe9ea":"code","ec4e291c":"code","ba36939b":"code","ac5b5bd3":"code","f4051d41":"code","6285c976":"code","b75157de":"code","0cc13dfa":"code","05b30bb7":"code","bccfbdca":"code","e2261e67":"code","64922cac":"code","1bc2890c":"code","8a63b61c":"code","08422f2b":"code","b0de9942":"code","7dd4ca63":"code","fbffa861":"code","bf172a22":"code","e833ac74":"code","31a9765e":"code","a22b0f3c":"code","bc5441e6":"code","21f7c68f":"code","ed90c337":"code","dee51921":"code","1e382566":"code","bb3af0d9":"code","759eee0f":"code","3994f0cb":"code","606d8b7f":"code","6b02d21c":"markdown","3124f6a9":"markdown","2f5d0233":"markdown","fb67486c":"markdown","f097e39a":"markdown","9639fd55":"markdown","7fad37a8":"markdown","4d94f313":"markdown","7f4d4651":"markdown","a353f591":"markdown","aa697ade":"markdown","1ed74b7f":"markdown","903b8a1d":"markdown","6a600199":"markdown","b6ecb442":"markdown","b3e3ac75":"markdown","c3656a40":"markdown","c1f1dbd8":"markdown","a73da180":"markdown","c3d59483":"markdown","33436b81":"markdown","456085f9":"markdown"},"source":{"01979508":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # data visualization advanced","d056fce8":"df_train = pd.read_csv('..\/input\/da-coaching-human-activity\/train.csv')\ndf_test = pd.read_csv('..\/input\/da-coaching-human-activity\/test.csv')","f8dbff01":"df_train.head()","02eb1caf":"df_test.head()","a97f59c9":"df_train.shape","7f80a468":"df_test.shape","c98cbfe3":"df_train.shape","0b0b6600":"df_train.dtypes.value_counts()","698f5d5c":"df_train.select_dtypes('int64').head(3)","9cfb40b1":"df_train.select_dtypes('object').head(3)","bc2689b4":"import re","77165ea1":"columns = df_train.columns.to_numpy()","45578529":"time_feats = []\ntime_func = set()\nfreq_feats = []\nfreq_func = set()\nother_feats = []\n\nn_time = 0\nn_freq = 0\nn_other = 0\n\nregex_func = re.compile('-([a-z]+)')\nregex_axis = re.compile('-([A-Z])')\n\nfor i in range(564):\n    if np.char.startswith(columns[i],'t'):\n        time_feats.append(columns[i])\n        time_func.add(regex_func.findall(columns[i])[0])\n        n_time += 1\n    elif np.char.startswith(columns[i],'f'):\n        freq_feats.append(columns[i])\n        freq_func.add(regex_func.findall(columns[i])[0])\n        n_freq += 1\n    else:\n        other_feats.append(columns[i])\n        n_other += 1","04d4083f":"print('Time freatures:',sorted(time_func))\nprint('Frequency freatures:',sorted(freq_func))","7a1fe9ea":"print('Other features:',sorted(other_feats))","ec4e291c":"n_time, n_freq, n_other, n_time + n_freq + n_other","ba36939b":"df_train['Activity'].value_counts()","ac5b5bd3":"chart = sns.countplot(df_train['Activity'])\nt = chart.set_xticklabels(chart.get_xticklabels(),rotation=25)","f4051d41":"act_map = {'STANDING':0, 'SITTING':1, 'LAYING':2, 'WALKING':3, 'WALKING_DOWNSTAIRS':4, 'WALKING_UPSTAIRS':5}\ndf_train['activity_code'] = df_train['Activity'].map(act_map)","6285c976":"df_train['Activity'].value_counts()","b75157de":"df_train['activity_code'].value_counts()","0cc13dfa":"fig, ax = plt.subplots(1,1, figsize=(15,15))\nsns.heatmap(df_train[time_feats+['activity_code']].corr(), \n            cmap=sns.diverging_palette(240, 10, n=25), \n            cbar=True,ax=ax)","05b30bb7":"fig, ax = plt.subplots(1,1, figsize=(15,15))\nsns.heatmap(df_train[freq_feats+['activity_code']].corr(), \n            cmap=sns.diverging_palette(240, 10, n=25), \n            cbar=True,ax=ax)","bccfbdca":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV","e2261e67":"df_train.drop(columns=['Id', 'subject', 'Activity'], inplace=True)","64922cac":"y = df_train.pop('activity_code')\nX = df_train","1bc2890c":"X.shape, y.shape","8a63b61c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)","08422f2b":"X_train.shape, y_train.shape","b0de9942":"X_test.shape, y_test.shape","7dd4ca63":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import classification_report","fbffa861":"std_scaler = StandardScaler()\nX_prep_train = std_scaler.fit_transform(X_train)\nX_prep_test = std_scaler.transform(X_test)","bf172a22":"LR_clf = LogisticRegression()\nLR_clf.fit(X_prep_train, y_train)\n\ny_pred = LR_clf.predict(X_prep_train)\nprint(classification_report(y_train, y_pred))","e833ac74":"from sklearn.model_selection import cross_val_score, KFold","31a9765e":"kfold = KFold(n_splits=5)","a22b0f3c":"scores = cross_val_score(LR_clf, X_prep_train, y_train, scoring='accuracy', cv=kfold)\nprint('Scores:',scores)\nprint('Mean:',np.mean(scores))\nprint('Std:',np.std(scores))","bc5441e6":"y_pred = LR_clf.predict(X_prep_test)\n\nprint(classification_report(y_test, y_pred))","21f7c68f":"df_test.drop(columns=['Id', 'subject'], inplace=True)","ed90c337":"X_final_test = df_test","dee51921":"X_final_prep_test = std_scaler.transform(X_final_test)","1e382566":"y_final_pred = LR_clf.predict(X_final_prep_test)","bb3af0d9":"y_final_pred","759eee0f":"rev_act_map = {0:'STANDING', 1:'SITTING', 2:'LAYING', 3:'WALKING', 4:'WALKING_DOWNSTAIRS', 5:'WALKING_UPSTAIRS'}\ny_final = [rev_act_map[code] for code in y_final_pred]","3994f0cb":"submission = pd.DataFrame({\n        \"Id\": range(1,len(y_final)+1),\n        \"Activity\": y_final\n    })\n\nsubmission.to_csv('lr_sub.csv',index=False)","606d8b7f":"submission.head()","6b02d21c":"# Modelling","3124f6a9":"Let's come up with a quick base model before further exploring the data. \\\nFirstly, let's remove Id, subject, Activity from the data.","2f5d0233":"Let's do feature standardization before training the models","fb67486c":"# Loading the Data","f097e39a":"**WOW**","9639fd55":"# Data Exploration","7fad37a8":"Let's check for validation data","4d94f313":"Seems pretty much balanced.","7f4d4651":"Looking at some of the names of the features, it seems that these are derived features from raw sensor data. \\\nThe features starting with small 't' are time-domain features.\\\nThe features starting with small 'f' are frequency-domain features.","a353f591":"\n#### 4. Which features are important?","aa697ade":"Training the models","1ed74b7f":"# Human Activity Recognition - Starter Model\n\nThe purpose of this notebook is to get you started to solve this problem.\n\nThe main steps of any Data Science Project can be roughly jotted as follows:\n\n* Data Exploration\n* Data Visualization\n* Data Preprocessing\n* Feature Engineering\n* Modelling\n* Validation, Evaluation, Testing\n\nThese steps overlap in multiple places and serve only as a guide to loosely follow.\n\nLet's start by importing common data science packages","903b8a1d":"With so many features, it would be impossible to see the plots for all. \\\nWe will limit our exploration to get a basic understanding of what is happening.","6a600199":"#### 1. How many features are there? What are their datatypes?","b6ecb442":"# Testing","b3e3ac75":"There are 564 features","c3656a40":"Given the excellent results here, let's try to submit a solution and see what score we get on the test set.","c1f1dbd8":"So there are 561 floats, 2 integers and 1 object. \\\nOf which the 2 integers (Id and Subject) aren't relevant for predictions. \\\nThe 1 object is the Activity (target) that is to be predicted. \\\nRemaining all 561 features are real values from sensor data.","a73da180":"**Superb**","c3d59483":"#### 2. Summarize the features","33436b81":"#### 3. Is the target balanced?","456085f9":"**Amazing** \\\nHow about on the test set?"}}