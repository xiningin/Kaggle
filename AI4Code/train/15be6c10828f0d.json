{"cell_type":{"5335b5c4":"code","57817a9e":"code","d2a3529c":"code","0b3293df":"code","73ba811d":"code","68826f93":"code","8e99ab16":"code","c6a05f4d":"code","b5c2c942":"markdown","0c3e3dcc":"markdown","d856af40":"markdown","0fc6f5ba":"markdown","892235c1":"markdown","4b27ce7c":"markdown","7146c932":"markdown","c8b960d2":"markdown"},"source":{"5335b5c4":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\nimport os\n\ndata_dir = \"..\/input\/\"\n\nw_size = 1024\no_size = 512\n\ntrain = pd.read_csv(data_dir+\"\/train.csv\")\nprint(train.head())\n","57817a9e":"train_dataset_info = []\n\nfor name, labels in zip(train['Id'], train['Target'].str.split(' ')):\n        lb = np.zeros(28, dtype='int')\n        for label in labels:\n            lb[int(label) ] = 1\n        train_dataset_info.append({\n        'path':os.path.join(data_dir+\"train\/\", name),\n        'labels':lb})\ntrain_dataset_info = np.array(train_dataset_info)\ntrain_num = train_dataset_info.shape[0]\nprint (\" images num \", train_num)","d2a3529c":"idx = np.zeros((28),dtype='int')\ntst = np.zeros((train_num),dtype='int')[:]>0\nfor k in range(train_num):\n    for i in range(28):\n        if idx[i]<100 and train_dataset_info[k][\"labels\"][i] > 0:\n            idx += train_dataset_info[k][\"labels\"]\n            tst[k] = True\n            break\nw_train_dataset_info = train_dataset_info[tst]\nw_num = w_train_dataset_info.shape[0]\n#w_num, idx","0b3293df":"num_classes = 28\nw_imgs = np.zeros((w_num,w_size,w_size,1), dtype='float32')\nw_class = np.zeros((w_num,num_classes), dtype='float32')\n\nfor k in tqdm_notebook(range(w_num)):\n    red =   np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_red.png\"   ))\n    green = np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_green.png\" ))\n    blue =  np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_blue.png\"  ))\n    yellow =np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_yellow.png\"))\n    w_imgs[k,::2,::2,0]  = red\/255.\n    w_imgs[k,1::2,::2,0] = blue\/255.\n    w_imgs[k,::2,1::2,0] = green\/255.\n    w_imgs[k,1::2,1::2,0]= yellow\/255.\n    w_class[k] = w_train_dataset_info[k][\"labels\"]\n","73ba811d":"from keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, Activation, Add\nfrom keras.layers import Dense, Flatten, BatchNormalization, AveragePooling2D\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n#import keras as keras\nfrom keras import backend as K\n","68826f93":"def f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n'''\nThanks Iafoss.\npretrained ResNet34 with RGBY\nhttps:\/\/www.kaggle.com\/iafoss\/pretrained-resnet34-with-rgby-0-460-public-lb\n'''\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n    y_true = tf.convert_to_tensor(y_true, np.float32)\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    #return binary_crossentropy(y_true, y_pred) + loss\n    return loss\n\nfrom keras.utils.generic_utils import get_custom_objects\n\nget_custom_objects().update({'focal_loss': focal_loss })\nget_custom_objects().update({'f1': f1 })\n","8e99ab16":"def build_model(input_layer, start_neurons):\n\n    conv1 = Conv2D(start_neurons * 1, (14, 14), strides=(2, 2), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    drop = Dropout(0.5)(convm)\n\n    flat = Flatten()(drop)\n#    hidden = Dense(128, activation='relu')(flat)\n#    drop = Dropout(0.5)(hidden)\n    output_layer = Dense(num_classes, activation='sigmoid')(flat)\n    \n    return output_layer\ninput_layer = Input((w_size, w_size, 1))\noutput_layer = build_model(input_layer, 8)\nmodel = Model(input_layer, output_layer)\nmodel.compile(loss=\"focal_loss\", optimizer=Adam(lr=1e-3), metrics=[\"binary_accuracy\",\"f1\"])\n# model.save_weights('.\/init.weights')\n\nmodel.summary()","c6a05f4d":"early_stopping = EarlyStopping(monitor='f1', mode = 'max',patience=10, verbose=1)\n#model_checkpoint = ModelCheckpoint(\".\/keras_1-28_200.model\",monitor='val_f1', \n#                               mode = 'max', save_best_only=True, verbose=1)\n#reduce_lr = ReduceLROnPlateau(monitor='val_f1', \n#                              mode = 'max',\n#                              factor=0.2, \n#                              patience=5, min_lr=0.00001, \n#                              verbose=1)\n\nhistory = model.fit(w_imgs,w_class,\n                        epochs=20,\n                        batch_size=32,\n                        callbacks=[early_stopping],\n                        verbose=2)\n","b5c2c942":"prepare a list of image files","0c3e3dcc":"compute","d856af40":"we will choose the signs so that each sign would be no more than 100, \nor if there are not many of them, then all are chosen","0fc6f5ba":"load libraries","892235c1":"make a small training set","4b27ce7c":"compose an array of names and labels","7146c932":"building functions F1 and Loss","c8b960d2":"build model and special first layer"}}