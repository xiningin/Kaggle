{"cell_type":{"89fd38fc":"code","55206d53":"code","69238e1d":"code","dec8823f":"code","51798bc2":"code","8b0c1af7":"code","de64516d":"code","30fe0e91":"code","0ef735a1":"code","f0a6a54d":"code","369f489a":"code","ad5e22c1":"code","1fabd649":"code","7ebb8a43":"code","34e3e101":"code","379e0485":"code","1a1ab50d":"code","2a22dbca":"code","3e36e581":"code","ffc6a9f4":"code","c640e4cf":"code","bdfe81b3":"markdown","ced363f3":"markdown","8be9009a":"markdown","e6a128de":"markdown","63a47ccb":"markdown"},"source":{"89fd38fc":"!git clone https:\/\/github.com\/mnpinto\/learn_ai_today.git\n!pip install -e learn_ai_today","55206d53":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom fastai.vision import Module\nfrom IPython.core.debugger import set_trace\n\nfrom learn_ai_today.learn_ai_today.n01 import GeneralFit","69238e1d":"iris = datasets.load_iris()\nX = iris.data   # Get training attributes\ny = iris.target # Get labels\ninput_size = X.shape[-1]\ncats = np.sum(np.unique(y)).astype(int)\nprint('Number of samples:', X.shape[0])\nprint('Number of attributes:', input_size)\nprint('Number of categories:', cats)","dec8823f":"df = pd.DataFrame({k:X[:,i] for i,k in enumerate(iris['feature_names'])})\nfig, ax = plt.subplots(figsize=(12,12), dpi=150)\npd.plotting.scatter_matrix(df, figsize=(12,12), c=y, s=200, alpha=1, ax=ax);","51798bc2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=2020)","8b0c1af7":"model = GeneralFit(int(input_size), int(cats))\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","de64516d":"x_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).long()\nx_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).long()","30fe0e91":"def accuracy_multi(x, y):\n    return (x.argmax(-1) == y).float().mean()\n\ndef fit(x_train, y_train, x_test, y_test, model, criterion, optimizer, num_epochs):\n    loss_history      = [] # to save the loss at each epoch.\n    loss_test_history = [] # to save the test loss at each epoch.\n    out_history       = [] # to save the parameters at each epoch\n    acc_train_history = []\n    acc_test_history  = [] \n    for ii, epoch in enumerate(range(num_epochs)):\n        # forward\n        model.train()\n        out       = model(x_train)\n        loss      = criterion(out, y_train)\n        acc_train = accuracy_multi(out, y_train)\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # test\n        model.eval()\n        out_test  = model(x_test)\n        loss_test = criterion(out_test, y_test)\n        acc_test  = accuracy_multi(out_test, y_test)\n        \n        loss_history.append(loss.item())\n        loss_test_history.append(loss_test.item())\n        acc_train_history.append(acc_train)\n        acc_test_history.append(acc_test)\n        if ii == 0:\n            out_history = out.detach().cpu().numpy()\n        else:\n            out_history = np.concatenate((out_history, out.detach().cpu().numpy()), axis=-1)\n        \n    print('Epoch[{}\/{}], loss:{:.6f}'.format(epoch+1, num_epochs, loss.item()))\n    return loss_history, loss_test_history, out_history, acc_train_history, acc_test_history","0ef735a1":"%time \nloss_train, loss_test, out, acc_train, acc_test = fit(\n    x_train, y_train, x_test, y_test, model, criterion, optimizer, num_epochs=1000)","f0a6a54d":"plt.figure(figsize=(6,3), dpi=120)\nplt.plot(loss_train, color='red', label='train loss')\nplt.plot(loss_test, color='green', label='test loss')\nplt.xlabel('epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","369f489a":"plt.figure(figsize=(6,3), dpi=120)\nplt.plot(acc_train, color='red', label='train accuracy')\nplt.plot(acc_test, color='green', label='test accuracy')\nplt.xlabel('epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","ad5e22c1":"yep = model(x_train) # compute the y estimate\nyep = yep.detach() # get the values from the variable, them pass them to the cpu and convert to a numpy array\nye = np.argmax(yep, axis=-1) \n\nyetp = model(x_test) # compute the y estimate\nyetp = yetp.detach() # get the values from the variable, them pass them to the cpu and convert to a numpy array\nyet = np.argmax(yetp, axis=-1)","1fabd649":"print('Train accuracy: ', (torch.sum(y_train == ye).float()\/len(ye)).item())\nprint('Test accuracy: ', (torch.sum(y_test == yet).float()\/len(yet)).item())","7ebb8a43":"def accuracy_multi(x, y):\n    return (x.argmax(-1) == y).float().mean()\n\ndef fit(x_train, y_train, x_test, y_test, model, criterion, optimizer, num_epochs):\n    loss_history      = [] # to save the loss at each epoch.\n    loss_test_history = [] # to save the test loss at each epoch.\n    out_history       = [] # to save the parameters at each epoch\n    acc_train_history = []\n    acc_test_history  = [] \n    predss = []\n    for ii, epoch in enumerate(range(num_epochs)):\n        # forward\n        model.train()\n        out       = model(x_train)\n        loss      = criterion(out, y_train)\n        acc_train = accuracy_multi(out, y_train)\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # test\n        model.eval()\n        out_test  = model(x_test)\n        loss_test = criterion(out_test, y_test)\n        acc_test  = accuracy_multi(out_test, y_test)\n        \n        loss_history.append(loss.item())\n        loss_test_history.append(loss_test.item())\n        acc_train_history.append(acc_train)\n        acc_test_history.append(acc_test)\n        if ii == 0:\n            out_history = out.detach().cpu().numpy()\n        else:\n            out_history = np.concatenate((out_history, out.detach().cpu().numpy()), axis=-1)\n        \n        x1 = np.linspace(0, 5, num=100)\n        x2 = np.linspace(0, 5, num=100)\n        x1, x2 = np.meshgrid(x1, x2)\n        x1 = torch.from_numpy(x1).float()\n        x2 = torch.from_numpy(x2).float()\n\n        model.eval()\n        with torch.no_grad():\n            preds = model(torch.cat((x1.view(-1,1), x2.view(-1,1)), dim=-1))\n            preds = preds.view(100,100,-1).argmax(-1)\n        predss.append(preds)\n        \n    print('Epoch[{}\/{}], loss:{:.6f}'.format(epoch+1, num_epochs, loss.item()))\n    return loss_history, loss_test_history, out_history, acc_train_history, acc_test_history, predss","34e3e101":"model = GeneralFit(2, int(cats))\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nx_train = x_train[:, (1,3)]\nx_test = x_test[:,(1,3)]","379e0485":"plt.scatter(x_train[:,0], x_train[:,1], c=y_train)","1a1ab50d":"%time \nloss_train, loss_test, out, acc_train, acc_test, predss = fit(\n    x_train, y_train, x_test, y_test, model, criterion, optimizer, num_epochs=1000)\n\npredss = np.array(torch.cat([p[None] for p in predss]).numpy())[::2]","2a22dbca":"x1 = np.linspace(0, 5, num=100)\nx2 = np.linspace(0, 5, num=100)\nx1, x2 = np.meshgrid(x1, x2)","3e36e581":"from matplotlib import animation, rc\nfrom IPython.display import HTML","ffc6a9f4":"%%capture\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10,5), dpi=120)\n\ntrain_plot = ax1.pcolormesh(x1, x2, predss[0], cmap='RdYlGn_r')\nax1.scatter(x_train[:,0], x_train[:,1], c=y_train)\nax1.axis([1.9, 4.3, 0, 3])\n\ntest_plot = ax2.pcolormesh(x1, x2, predss[0], cmap='RdYlGn_r')\nax2.scatter(x_test[:,0], x_test[:,1], c=y_test)\nax2.axis([1.9, 4.3, 0, 3])\n\nax1.set_title('Train')\nax2.set_title('Test')\n\n# animation function. This is called sequentially\ndef animate(i):\n    train_plot.set_array(predss[i][:-1, :-1].ravel())\n    test_plot.set_array(predss[i][:-1, :-1].ravel())\n    return (train_plot, test_plot)\n\n# call the animator. blit=True means only re-draw the parts that have changed.\nanim = animation.FuncAnimation(fig, animate, frames=len(predss), interval=30, blit=True)","c640e4cf":"HTML(anim.to_html5_video())","bdfe81b3":"# Note: The full description of the code and steps is available on [Medium at this link](https:\/\/towardsdatascience.com\/learn-ai-today-02-introduction-to-classification-problems-using-pytorch-b710918cba63).","ced363f3":"**What you will learn in this\u00a0story:**\n* The Importance of Validation\n* How to Train Models for Classification Problems\n* Visualize the Decision Boundaries Dynamically\n* How to Avoid Overfitting","8be9009a":"# Learn AI Today: 02 - Classification with PyTorch","e6a128de":"**If you want to receive updates consider joining my mailing list at [learn-ai-today.com](http:\/\/learn-ai-today.com)**","63a47ccb":"## Train for simple example and plot decision boundaries"}}