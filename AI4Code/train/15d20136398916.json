{"cell_type":{"e21b26ad":"code","c1e6110a":"code","a90e6f39":"code","4bb9f8bd":"code","8ee37c78":"code","7787fa8d":"code","f9be591c":"code","66243b18":"code","9b42dc8a":"code","1abc9ea3":"code","4912ce44":"code","e674d955":"code","7d698728":"code","79d114d9":"code","681ecdbd":"code","2b83829b":"code","0a58eb2e":"code","80132d2e":"code","c50b041c":"code","77cab3f2":"code","deb95d03":"code","e1b7e58e":"code","048c773f":"code","2d5574ee":"code","44c5727a":"code","379a0e0b":"code","32cf565b":"code","531fc49f":"code","06113426":"code","87f70238":"code","63975cb4":"code","c5f9aae2":"code","00bde47d":"markdown","93aa5773":"markdown","355b8885":"markdown","15b5eeca":"markdown","eaa5eff3":"markdown","b01b51b7":"markdown","dad90266":"markdown","6c36afcf":"markdown","4754c5ea":"markdown","de422628":"markdown","94916f1f":"markdown","d0372eb2":"markdown","5c5cc5e4":"markdown","7fb56e41":"markdown","11046663":"markdown","9662395d":"markdown","c8dd122d":"markdown","92c0c176":"markdown","4c928368":"markdown","a4234268":"markdown","68e10968":"markdown","b3dbba52":"markdown","f9983f1a":"markdown","522eb288":"markdown","ee62ab4a":"markdown","40065c06":"markdown","a4dc78a8":"markdown","5447c63d":"markdown","a9526e68":"markdown","e5c01386":"markdown","16c2b620":"markdown","053ae38e":"markdown","26cfcba2":"markdown","eee5ed86":"markdown","a46f59b0":"markdown","554c6a6e":"markdown","3626ebf8":"markdown","04ea02f7":"markdown","58d59d4a":"markdown","825d2f50":"markdown","066a761f":"markdown","22ddcea5":"markdown","68eca5bc":"markdown","77ea5136":"markdown"},"source":{"e21b26ad":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","c1e6110a":"df = pd.read_csv('..\/input\/heart.csv')\ndf.shape","a90e6f39":"#  check for NULL values\nprint('\\n--- NULL count ---\\n{}'.format(df.isnull().sum()))\n#df.dropna(inplace=True)             #  drop NULLs\n\n#  check for DUPLICATES\nprint('\\n1st DUPLICATE count:\\t{}'.format(df.duplicated().sum()))\ndf.drop_duplicates(inplace = True)  #  drop duplitcates\nprint('2nd DUPLICATE count:\\t{}'.format(df.duplicated().sum()))","4bb9f8bd":"df.rename(columns={\n        'cp':'chest_pain_type', 'trestbps':'resting_blood_pressure',\n        'chol':'cholestoral','fbs':'fasting_blood_sugar',\n        'restecg':'resting_electrocardiographic','thalach':'maximum_heart_rate',\n        'exang':'exercise_induced_angina','oldpeak':'ST_depression',\n        'slope':'slope_peak_exercise_ST','ca':'number_of_major_vessels'},\n    inplace=True)\n\nprint(df.columns.tolist())","8ee37c78":"df['sex'] = df['sex'].map({0:'female', 1:'male'})\ndf['chest_pain_type'] = df['chest_pain_type'].map({\n        0:'typical angina', 1:'atypical angina',\n        2:'non-anginal',    3:'asymptomatic'})\ndf['fasting_blood_sugar'] = df['fasting_blood_sugar'].map({\n        0:'> 120 mg\/dl', 1:'< 120 mg\/dl'})\ndf['resting_electrocardiographic'] = df['resting_electrocardiographic'].map({\n        0:'normal', 1:'ST-T wave abnormality', 2:'ventricular hypertrophy'})\ndf['exercise_induced_angina'] = df['exercise_induced_angina'].map({\n        0:'no', 1:'yes'})\ndf['slope_peak_exercise_ST'] = df['slope_peak_exercise_ST'].map({\n        0:'upsloping', 1:'flat', 2:'downsloping'})\ndf['thal'] = df['thal'].map({\n        0:'normal 0',     1:'normal 1',\n        2:'fixed defect', 3:'reversable defect'})\ndf['target'] = df['target'].map({0:'no disease', 1:'disease'})\n\ndf.head()","7787fa8d":"print(df.info())         #  dataset size and types\nprint('\\nData Shape:  {}'.format(df.shape))","f9be591c":"df.describe()   #  NUMERICAL DATA","66243b18":"df.describe(include=['O'])   #  CATEGORICAL DATA","9b42dc8a":"df.head()","1abc9ea3":"#  Separate out Categorical and Numeric data\ncolCAT = []\ncolNUM = []\nfor i in df.columns:\n    if (len(df[i].unique())) > 5:\n        colNUM.append(i)\n    else:\n        colCAT.append(i)\n    print('unique values:  {}\\t{}'.format(len(df[i].unique()),i))\n\ndataCAT = df[colCAT]     #  Categorical columns\ncolNUM.append('target')  #  add target column to Numeric\ndataNUM = df[colNUM]     #  Numeric columns","4912ce44":"dataCAT.head()  # categorical dataframe from Section 3.3","e674d955":"diseaseCAT    = df[(df['target'] == 'disease')]\nno_diseaseCAT = df[(df['target'] == 'no disease')]\n\n#  fig.add_subplot([# of rows] by [# of columns] by [plot#])\nsubNumOfRow = len(dataCAT.columns)\nsubNumOfCol = 3     # three columns: overall, no disease, disease\nsubPlotNum  = 1     # initialize plot number\n\nfig = plt.figure(figsize=(16,60))\n\nfor i in colCAT:\n    # overall\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('OVERALL - {}'.format(i), fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    sns.swarmplot(data=df, x=df[i],y=df.age,hue=df.target)\n    subPlotNum = subPlotNum + 1\n    # no_diseaseCAT\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('NO DISEASE, target = 0', fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    sns.swarmplot(data=no_diseaseCAT, x=no_diseaseCAT[i],y=no_diseaseCAT.age,color='darkorange')\n    subPlotNum = subPlotNum + 1\n    # diseaseCAT\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('DISEASE, target = 1', fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    #sns.countplot(diseaseCAT[i], hue=df.sex)#,color='darkred')\n    sns.swarmplot(data=diseaseCAT, x=diseaseCAT[i],y=diseaseCAT.age,color='blue')\n    subPlotNum = subPlotNum + 1\nplt.show()","7d698728":"dataNUM.head()  # numeric dataframe from Section 3.3","79d114d9":"#  assign NUM dataframe for \"no disease\" and \"disease\"\nno_diseaseNUM = dataNUM[(df['target'] == 'no disease')]\ndiseaseNUM    = dataNUM[(df['target'] == 'disease')]\n\n#  fig.add_subplot([# of rows] by [# of columns] by [plot#])\nsubNumOfRow = len(dataNUM.columns)-1   #  x='age' in plots, drop column\nsubNumOfCol = 3     # three columns: overall, no disease, disease\nsubPlotNum  = 1     # initialize plot number\n\nfig = plt.figure(figsize=(16,30))\n\nfor i in dataNUM.columns.drop([\"age\",\"target\"]):\n    # overall\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('OVERALL', fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    sns.distplot(df[i],color='black')\n    subPlotNum = subPlotNum + 1\n    # no_diseaseNUM\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('NO DISEASE, target = 0', fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    sns.distplot(no_diseaseNUM[i],color='darkorange')\n    subPlotNum = subPlotNum + 1\n    # diseaseNUM\n    fig.add_subplot(subNumOfRow, subNumOfCol, subPlotNum)\n    plt.title('DISEASE, target = 1', fontsize=14)\n    plt.xlabel(i, fontsize=12)\n    sns.distplot(diseaseNUM[i],color='darkblue')\n    subPlotNum = subPlotNum + 1\n\nplt.show()","681ecdbd":"#  one hot encoding works on type 'object'\nfor i in colCAT:\n    df[i] = df[i].astype(object)\n    \ndf_OHE = df[colCAT]               #  dataframe with categorical values\ndf_OHE = pd.get_dummies(df_OHE)   #  one-hot encoding\ndf_OHE = df_OHE.join(df[colNUM])  #  add numeric columns\n\n#  change target data to 0\/1\ndf_OHE['target'] = df_OHE['target'].map({'no disease':0,'disease':1})\ndf_OHE = df_OHE.drop(['target_disease', 'target_no disease'], axis=1)\n\ndf_OHE.head()","2b83829b":"from sklearn.preprocessing import MinMaxScaler\nnorm = MinMaxScaler().fit_transform(df_OHE)\nnorm[0:2]","0a58eb2e":"#  dataframe with the One Hot Encoding and Normalized data\ndf = pd.DataFrame(norm, index=df_OHE.index, columns=df_OHE.columns)\ndf.head()","80132d2e":"dataCorr = df.corr()\nplt.figure(figsize=(20,20))\nplt.title('Heart Disease - CORRELATION, Overall', fontsize=14)\nsns.heatmap(dataCorr, annot=True, fmt='.2f', square=True, cmap = 'Blues_r')","c50b041c":"corrALL = dataCorr['target'].sort_values(ascending=False)\ncorrALL = corrALL.drop(['target'])\ncorrALL.to_frame()","77cab3f2":"plt.figure(figsize=(16,16))\nplt.title('Heart Disease - CORRELATION, Overall', fontsize=14)\nax = sns.barplot(y=corrALL.index,x=corrALL.values)\nfor p in ax.patches:\n    ax.annotate(\"%.4f\" % p.get_width(), (p.get_x() + p.get_width(), p.get_y()))\nplt.show()","deb95d03":"dataFemale = df[(df['sex_female'] == 1)]\ndataFemaleCorr = dataFemale.drop(['sex_female','sex_male'], axis=1).corr()\ndataFemaleCorr = dataFemaleCorr['target'].sort_values(ascending=False)\ndataFemaleCorr['number_of_major_vessels_4'] = 0  # -7.9e-17  all numbers will be exp if not set to 0\ndataFemaleCorr.to_frame()\ndataFemaleCorr = dataFemaleCorr.drop(['target'])  # for barplot\n\nplt.figure(figsize=(16,16))\nplt.title('Heart Disease - CORRELATION, Female', fontsize=14)\nax = sns.barplot(y=dataFemaleCorr.index,x=dataFemaleCorr.values)\nfor p in ax.patches:\n    ax.annotate(\"%.4f\" % p.get_width(), (p.get_x() + p.get_width(), p.get_y()))\nplt.show()","e1b7e58e":"dataMale   = df[(df['sex_male'] == 1)]\ndataMaleCorr = dataMale.drop(['sex_female','sex_male'], axis=1).corr()\ndataMaleCorr = dataMaleCorr['target'].sort_values(ascending=False)\ndataMaleCorr = dataMaleCorr.drop(['target'])\n\nplt.figure(figsize=(16,16))\nplt.title('Heart Disease - CORRELATION, Male', fontsize=14)\nax = sns.barplot(y=dataMaleCorr.index,x=dataMaleCorr.values)\nfor p in ax.patches:\n    ax.annotate(\"%.4f\" % p.get_width(), (p.get_x() + p.get_width(), p.get_y()))\nplt.show()","048c773f":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['target'], axis = 1)\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:  ', X_train.shape,  y_train.shape)\nprint ('Test set:   ', X_test.shape,  y_test.shape)","2d5574ee":"from sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR","44c5727a":"#  predict\ny_predict = LR.predict(X_test)\ny_predict[0:10]","379a0e0b":"from sklearn.model_selection import cross_val_score\n\nprint(cross_val_score(LR, X_train, y_train, cv=5, scoring='accuracy'))\nprint('Cross Validation Score (mean):  {:3.4%}'.format(cross_val_score(LR, X_train, y_train, cv=5, scoring='accuracy').mean()))","32cf565b":"from sklearn.metrics import accuracy_score\n\nprint('Accuracy Score:  {:3.4%}'.format(accuracy_score(y_test,y_predict)))","531fc49f":"from sklearn.metrics import f1_score\n\nf1score = f1_score(y_test, y_predict)\nprint('F1 Score:  {:3.4%}'.format(f1score))","06113426":"from sklearn.metrics import confusion_matrix\n\nconf_matrix = confusion_matrix(y_test, y_predict)\n\nsns.heatmap(conf_matrix, annot=True,cmap='Blues',annot_kws={\"size\": 30})\nplt.title(\"Confusion Matrix, F1 Score: {:3.4%}\".format(f1score))\nplt.show()\n\nprint('True Positive:\\t{}'.format(conf_matrix[0,0]))\nprint('True Negative:\\t{}'.format(conf_matrix[0,1]))\nprint('False Positive:\\t{}'.format(conf_matrix[1,0]))\nprint('False Negative:\\t{}'.format(conf_matrix[1,1]))","87f70238":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nLR.probability = True   # need for predict_proba to work\nLR.fit(X_train,y_train)\ny_predita = LR.predict_proba(X_test)\ny_predita = y_predita[:,1]   # positive values only\n    \nROC_AUC = roc_auc_score(y_test, y_predita)\nfpr, tpr, thresholds = roc_curve(y_test, y_predita)\n\nplt.plot([0,1],[0,1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.title(\"ROC Curve, ROC_AUC Score: {:3.4%}\".format(ROC_AUC))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","63975cb4":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_predict))","c5f9aae2":"from sklearn.metrics import log_loss\n\n#  predict_proba returns estimates for all classes\ny_predict_prob = LR.predict_proba(X_test)\nprint(y_predict_prob[0:5])\n\nprint(\"\\nLog Loss:  {:3.4}\".format(log_loss(y_test, y_predict_prob)))","00bde47d":"### OBSERVATIONS:\n\n-  There are no discernible patterns from the plots between blood pressure, cholesterol, max heartbeat, ST depression and heart disease with respect to age & sex.\n-  [Correlation](#model_corr) will give us better understanding of the relationships between the attributes and heart disease.","93aa5773":"## 4.1  Plots - Categorical Data<a id=\"eda_cat\"><\/a>\nCategorical data can be plotted using Seaborn's **swarmplot**.","355b8885":"##  6.4 Confusion Matrix<a id=\"eval_conf\"><\/a>   \nConfusion matrix shows the corrected and wrong predictions, in comparison with the actual labels. It shows the model\u2019s ability to correctly predict or separate the classes.\n\n   - **True Positive** \u2013 model predicted positive class correctly to be a positive class\n   - **False Positive** \u2013 model predicted negative class incorrectly to be a positive class\n   - **False Negative** \u2013 model predicted positive class incorrectly to be the negative class\n   - **True Negative** \u2013 model predicted negative class correctly to be the negative class","15b5eeca":"##  6.6 Classification Report<a id=\"eval_class\"><\/a>   \n**Precision** is a measure of the accuracy, provided that a class label has been predicted. It is defined by:   \n    ```precision = True Positive\/(True Positive + False Positive)```   \n    \n**Recall** is the true positive rate:    \n    ```recall = True Positive\/(True Positive + False Negative)```   \n    \n**F1-Score** is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (which represents perfect precision and recall) and its worst at 0    \n    ```F1-Score = 2x (precision x recall)\/ (precision + recall)```","eaa5eff3":"### OBSERVATIONS:\n\n-  **sex** - data has more male population with no heart disease than female, however, the population of patients with heart disease is almost the same, with the female population spread over a longer age range.\n-  **chest_pain_type** - typical angina accounts for most cases with no heart disease.  Populations with anything other than typical angina have a higher chance of having heart disease.\n-  **fasting_blood_sugar** - is not a good indicator of heart disease since healthy and unhealthy population distribution is almost the same.\n-  **resting_electrocardiographic** - is not a good indicator of heart disease since healthy and unhealthy population distribution is almost the same.  \n-  **exercise_induced_angina** - is not a good indicator of heart disease since healthy and unhealthy population distribution is almost the same.  \n-  **slope_peak_exercise_ST** - populations with downsloping and flat sloping have a higher incidence of heart disease.\n-  **number_of_major_vessels** - patients with no vessels colored by fluoroscopy have a much higher incidence of heart disease.\n-  **thal** - patients with fixed defect have a significantly higher incidence of heart disease.","b01b51b7":"### OBSERVATIONS: \nFactors resulting in heart disease are markedly different for female and males.  \n-  **female** - thal fixed and reversable defect are major factors in heart disease, as well as angina type chest pains and ST_depression.\n-  **male** -  number of vessels, angina type chest pains and maximum_heart_rate are major factors in heart disease.\n","dad90266":"##  3.1  Data Types   <a id=\"data_type\"><\/a>\nSome of the data types of the features will be changed to 'object' after rename\/updates.","6c36afcf":"###  5.3.1  Correlation - OVERALL","4754c5ea":"##  3.3  Types of Data <a id=\"data_type2\"><\/a>\nSeparate out the **Categorical** and **Numeric** data.","de422628":"The original dataframe (**df**) now had One Hot Encoding and Normalized data and is ready for machine learning.","94916f1f":"##  5.3 CORRELATION <a id=\"model_corr\"><\/a>\nKeeping in mind that males and females can have different factors resulting in heart disease (see Section 4 observations), this correlation section will have three parts:\n\n   *  Correlation OVERALL - heatmap, table, barplot\n   *  Correlation FEMALE  - barplot\n   *  Correlation MALE    - barplot\n\nNOTE: barplots conveys the correlation information the best.  Heatmap and table can be excluded, however, I'm doing them for OVERALL data.","d0372eb2":"---\n[go to top of document](#top)  \n###  END\n\n---\nPlease upvote if you found this useful :-)","5c5cc5e4":"Finally, create the dataframe that can be used for machine learning with the One Hot Encoding and Normalized data.","7fb56e41":" **TABLE for Categorical and Numeric Data**\n \n| CATEGORICAL ATTRIBUTES   | NUMERIC ATTRIBUTES    |\n| :-- | :-- |\n|sex   |age  |\n|chest_pain_type  |resting_blood_pressure  |\n|fasting_blood_sugar  |cholestoral  |\n|resting_electrocardiographic  |maximum_heart_rate  |\n|exercise_induced_angina  |ST_depression  |\n|slope_peak_exercise_ST  |  |\n|number_of_major_vessels  |  |\n|thal  |  |\n|target  |  |\n\n","11046663":"##  5.4  Train\/Test Split <a id=\"model_split\"><\/a>\nTrain\/Test Split randomly splits a dataset into training and testing subsets.  The model learns on the training set based on known output, and the test data is used to evaluate the accuracy of the model.","9662395d":"[go to top of document](#top)     \n\n---\n#  2.  Data Preparation <a id=\"prep\"><\/a>","c8dd122d":"##  6.3 F1 Score<a id=\"eval_f1\"><\/a>   \n**F1 Score** is the weighted average of Precision and Recall.","92c0c176":"##  5.5  Classification Model - Logistic Regression<a id=\"model_lr\"><\/a>   \nIn machine learning, **classification** is a *supervised* learning approach which attempts to learn the relationship between a set of feature variables and a target variable. The target attribute in classification is a categorical variable with discrete values.\n\n**Logistic regression** is a classification algorithm for categorical variables.  Logistic regression is analogous to linear regression, but tries to predict a categorical or discrete target field, such as 0 or 1, yes or no, etc., instead of a numeric one.\n","4c928368":"**Statistical Summary - CATEGORICAL DATA**   \nSummarize the count, uniqueness and frequency of categorical features, excluding numerical values.","a4234268":"**Update categorical attribute values (features) for better readability & plotting.**\n\n| Attribute   | Updated Feature Values \n| :-- | :-- \n|**sex** |0:female<br>1:male|\n|**chest_pain_type** | 0:typical angina<br>1:atypical angina<br><br>2:non-anginal<br>3:asymptomatic|\n|**fasting_blood_sugar** |0:> 120 mg\/dl<br>1:< 120 mg\/dl|\n|**resting_electrocardiographic** |0:normal<br>1:ST-T wave abnormality<br>2:ventricular hypertrophy|\n|**exercise_induced_angina** |0:no<br>1:yes|\n|**slope_peak_exercise_ST** |0:upsloping<br>1:flat<br>2:downsloping|\n|**thal** |0:normal 0<br>1:normal 1<br>2:fixed defect<br>3:reversable defect|\n|**target** |0:no disease<br>1:disease|","68e10968":"###  5.3.2  Correlation - FEMALE\nStep for creating the correlation **Barplot for FEMALE**\n\n1.  Select 'sex_female' = 1 data\n2.  Drop 'sex_female' and 'sex_male' attributes and take correlation\n3.  Sort on 'target' column\n4.  Drop 'target' column\n5.  Plot bar for 'sex_female'","b3dbba52":"Following code will separate out catergorical and numerical data. *number_of_major_vessels* has the most discrete unique values (5)...any column with more than \"5\" unique values is considered a numeric value.","f9983f1a":"**BARPLOT - OVERALL**   \nBarplot provides the best visualization for the correlation.","522eb288":"[go to top of document](#top)     \n\n---\n#  5.  Model - Logistic Regression<a id=\"model\"><\/a>","ee62ab4a":"##  6.1 Cross Validation Score<a id=\"eval_cv\"><\/a>   \n**Cross Validation Score** splits the dataset into K equal groups. Each group is referred to as a fold.  Some of the folds are used for training and the reamaining for testing the model.  The process is repeated until each partition is used for both training and testing.","40065c06":"[go to top of document](#top)     \n\n---\n#  4. Exploratory Data Analysis <a id=\"eda\"><\/a>\nData can be plotted now that the attributes have been separated into categorical and numeric dataframes, and attributes and feature values have been renamed\/updated for easier readability.\n\nThe subplots will have three plots per attribute: \n  - `plot#1`:  **OVERALL**\n  - `plot#2`:  **NO DISEASE**\n  - `plot#3`:  **DISEASE**\n\nAs noted above, this section has way too many plots.  Intent was to plot everything using subplots inside FOR loops for kicks. You can go to the next section by clicking [here](#model).","a4dc78a8":"**TABLE - OVERALL**   \nTable with the sorted 'target' data provides a better format for understanding heart disease correlation.","5447c63d":"##  6.2 Accuracy Score<a id=\"eval_acc\"><\/a>   \n**Accuracy Score** function computes subset accuracy in a multilabel classification dataset and is equal to the **Jaccard Score** function in binary and multiclass classification.","a9526e68":"<a id=\"top\"><\/a>  \n# Heart Disease UCI - EDA and ML w\/LR\n---\n\n**Heart Disease UCI** is a small dataset containing 14 attributes, and is very useful in learning how to prepare data in order to produce meaningful plots and perform to machine learning.  This project will cover:\n\n-  data preperation, primarily feature engineering\n-  explanation of the data\n-  exploratory data analysis - plots, plots and more plots\n-  machine learning using Logistic Regression\n-  evaluation of the model\n\n---\n![heart.PNG](attachment:heart.PNG)\n\n---\n### Table Of Content\n1. [Data Collection](#coll)   \n2. [Data Preparation](#prep)   \n      2.1 [Check for NULLs\/Duplicates](#prep_null)   \n      2.2 [Feature Engineering (rename attributes and features)](#prep_name) \n3. [Understanding the Data](#data)   \n      3.1 [Data Types](#data_type)   \n      3.2 [Statistical Summary](#data_summ)   \n      3.3 [Types of Data (categorical\/numeric)](#data_type2)   \n4. [Exploratory Data Analysis](#eda)   \n      4.1 [Plot Categorical Data](#eda_cat)   \n      4.2 [Plot Numeric Data](#eda_num)   \n5. [Model - Logistic Regression](#model)   \n      5.1 [One Hot Encoding](#model_oneH)   \n      5.2 [Normalize Data](#model_norm)   \n      5.3 [Correlation](#model_corr)   \n      5.4 [Train\/Test Split](#model_split)   \n      5.5 [Classification Model - Logistic Regression](#model_lr)   \n6. [Evaluate the Model](#eval)   \n      6.1 [Cross-Validation Score](#eval_cv)   \n      6.2 [Accuracy Score\/Jaccard Index](#eval_acc)   \n      6.3 [F1 Score](#eval_f1)   \n      6.4 [Confusion Matrix](#eval_conf)   \n      6.5 [Receiver Operating Characteristics (ROC) Curve](#eval_roc)   \n      6.6 [Classification Report](#eval_class)   \n      6.7 [Log Loss](#eval_log) \n--- \n<div class=\"alert alert-block alert-info\">\n<b>NOTE:<\/b>  I wanted to use subplot with a FOR loop for categorical and numeric data, so I went a little crazy with the plotting in Section 4  :-)<\/div>","e5c01386":"[go to top of document](#top)     \n\n---\n#  3.  Understanding the Data <a id=\"data\"><\/a>","16c2b620":"##  3.2  Statistical Summary <a id=\"data_summ\"><\/a>\nSummarize descriptive statistics of the dataset for *numerical* and *categorical* features. ","053ae38e":"**Predict** generates output predictions from the input samples and is used for evaluating the model.","26cfcba2":"##  5.1  One Hot Encoding <a id=\"model_oneH\"><\/a>\nMachine learning algorithms cannot process categorical or text data unless they have been converted to numbers.  **One hot encoding** maps categorical values to integer values, which are represented as a binary vector that are all zero values, except the index of the integer, which is set to 1.","eee5ed86":"## 2.2 Feature Engineering <a id=\"prep_name\"><\/a>\nRename columns (attributes) for better readability.\n\n| Original Attribute Name | New Attribute Name   |  Description |\n| :-- | :--  | :--- |\n|**age**|age|age of patient\n|**sex**|sex|sex of patient:  0 = female; 1 = male\n|**cp**|chest_pain_type|chest pain type (4 values)\n|**trestbps**|resting_blood_pressure|resting blood pressure\n|**chol**|cholestoral|serum cholestoral in mg\/dl\n|**fbs**|fasting_blood_sugar|fasting blood sugar > 120 mg\/dl\n|**restecg**|resting_electrocardiographic|resting electrocardiographic results (values 0,1,2)\n|**thalach**|maximum_heart_rate|maximum heart rate achieved\n|**exang**|exercise_induced_angina|exercise induced angina\n|**oldpeak**|ST_depression|oldpeak = ST depression induced by exercise relative to rest\n|**slope**|slope_peak_exercise_ST|slope of the peak exercise ST segment\n|**ca**|number_of_major_vessels|number of major vessels (0-3) colored by flourosopy\n|**thal**|thal|thal: 3 = normal; 6 = fixed defect; 7 = reversable defect","a46f59b0":"##  5.2  Normalize Data <a id=\"model_norm\"><\/a>\nNormalization is a rescaling of the data from the original range so that all values are within a certain range, typically between 0 and 1.  Normalized data is essential in machine learning.  Correlation and models will not produce good results if the scales are not standardized.\n\nUsing **MixMaxScalar** to keep the 'sex' columns as '0' and '1'.  **StandardScaler** converts the 'sex' columns as -0.68 & 1.46 for female and -1.46 & 0.68 for male.","554c6a6e":"###  5.3.3  Correlation - MALE\nStep for creating the correlation the **Barplot for MALE**\n\n1.  Select 'sex_male' = 1 data\n2.  Drop 'sex_female' and 'sex_male' attributes and take correlation\n3.  Sort on 'target' column\n4.  Drop 'target' column\n5.  Plot bar for 'sex_female'","3626ebf8":"##  6.5 Receiver Operating Characteristics (ROC) Curve<a id=\"eval_roc\"><\/a>   \nAUC\u2013ROC curve is the model selection probability curve. AUC area is covered by the curve is the area between the orange line (ROC) and the axis.  The bigger the area covered, the better the machine learning models. Ideal value for AUC is 1.\n\n*  **ROC** - Receiver Operating Characteristics\n*  **AUC** - Area Under the Curve","04ea02f7":"## 2.1 Check for NULLs\/Duplicates <a id=\"prep_null\"><\/a>\nCleaning up the NULL and duplicate values in the dataset.","58d59d4a":"---\n#  1.  Data Collection <a id=\"coll\"><\/a>\nImport Python libraries and load the dataset.","825d2f50":"## 4.2  Plots - Numeric Data<a id=\"eda_num\"><\/a>\nNumeric data can be plotted using Seaborn's **distplot**.","066a761f":"**HEATMAP - OVERALL**   \nHeatmaps are a great way of representing correlation visually.  However, due to the amount of attributes in the dataframe, it looks very cluttered.","22ddcea5":"**Statistical Summary - NUMERICAL DATA**   \nSummarize the central tendency, dispersion and shape of numeric features, excluding categorical and NaN values.","68eca5bc":"##  6.7 Log Loss<a id=\"eval_log\"><\/a>   \nLogarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0 and 1. The goal of machine learning models is to minimize this value. A perfect model would have a log loss of 0.","77ea5136":"[go to top of document](#top)     \n\n---\n#  6.  Evaluate the Model  <a id=\"eval\"><\/a>\nThis section will evalute the Logistic Regression model."}}