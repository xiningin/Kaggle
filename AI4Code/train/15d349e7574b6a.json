{"cell_type":{"7059fc76":"code","c17f5596":"code","4a8f377e":"code","fdf17367":"code","8be22de9":"code","ed7a0b2a":"code","2c733229":"code","3024dd72":"code","dae97486":"code","6729d571":"code","39d8710a":"code","9ea97c92":"code","28af5496":"code","375da4dd":"code","9482c6d3":"code","5f2a0fa2":"code","3c0ba51e":"code","89c4686d":"code","38a6d8d4":"code","af1037a7":"code","49ce4368":"code","ae46f007":"code","451da56a":"code","438eef37":"code","f80b891e":"code","5557b1b8":"code","3810e580":"code","1412636d":"code","6c46495d":"code","a79aab93":"code","a4ec65e3":"code","02371f28":"code","1b5cab5d":"code","943d40d6":"code","a0cadbd9":"code","4fd1f45d":"code","c000086e":"code","75f2a34b":"code","11738a42":"markdown","086d3393":"markdown","8a714c90":"markdown","88f1fc2a":"markdown","d44041cc":"markdown","65c0ec31":"markdown","c81aa180":"markdown","0fd4ccf3":"markdown","24e4ee17":"markdown","807488a4":"markdown"},"source":{"7059fc76":"import numpy as np \nimport pandas as pd ","c17f5596":"!pip install ipytest","4a8f377e":"import pytest\nimport ipytest\n\nipytest.autoconfig()","fdf17367":"full_grouped=pd.read_csv('..\/input\/corona-virus-report\/full_grouped.csv')\n\nonly_death = full_grouped[['Date', 'Country\/Region', 'New deaths']]\nonly_death = only_death[only_death['Country\/Region'] == 'United Kingdom']\nonly_death = only_death[['Date', 'New deaths']]","8be22de9":"%%run_pytest[clean]\n\ndef test_valid_dates():\n    assert((pd.to_datetime(only_death['Date']).isnull() == True).any() == False)\n    \ndef test_valid_new_deaths():\n    assert((only_death['New deaths'].isnull() == True).any() == False)\n    assert((only_death['New deaths'] < 0).any() == False)","ed7a0b2a":"trainDataset = only_death.sample(frac=0.8,random_state=0)\ntestDataset = only_death.drop(trainDataset.index)","2c733229":"import datetime\n\ntrainInput = pd.Series([datetime.datetime.strptime(\n    d, '%Y-%m-%d') for d in trainDataset['Date']])\nstart_date = trainInput.min()\ntrainInput = pd.Series(\n    [(d - start_date) \/ datetime.timedelta(days=1) for d in trainInput])\ntrainTarget = trainDataset['New deaths']\ntestInput = pd.Series(\n    [(datetime.datetime.strptime(d, '%Y-%m-%d') - start_date) \/\n     datetime.timedelta(days=1) for d in testDataset['Date']]\n)\ntestTarget = testDataset['New deaths']","3024dd72":"import tensorflow as tf\nfrom tensorflow import keras","dae97486":"model = keras.Sequential([\n      keras.layers.Dense(1, use_bias=True, input_shape=(1,))\n    ])","6729d571":"optimizer = keras.optimizers.Adam(\n    learning_rate=0.01, beta_1=0.9, beta_2=0.99, epsilon=1e-05, amsgrad=False,\n    name='Adam')\n  \n# Model compiling settings\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mae','mse'])","39d8710a":"n_idle_epochs = 100\nearlyStopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=n_idle_epochs, min_delta=0.01\n)\n\nn_epochs = 200\nhistory = model.fit(\n    trainInput, trainTarget, batch_size=10,\n    epochs=n_epochs, validation_split=0.1, verbose=1, callbacks=[earlyStopping]\n)\n","9ea97c92":"import matplotlib.pyplot as plt\n\n# The fit model returns the history object for each Keras model\n# Let's explore what is inside history\nprint('keys:', history.history.keys())\n\n# Returning the desired values for plotting and turn to numpy array\nmae = np.asarray(history.history['mae'])\nval_mae = np.asarray(history.history['val_mae'])\n\n# Creating the data frame\nnum_values = (len(mae))\nvalues = np.zeros((num_values,2), dtype=float)\nvalues[:,0] = mae\nvalues[:,1] = val_mae\n\n# Using pandas to frame the data\nsteps = pd.RangeIndex(start=0,stop=num_values)\ndata = pd.DataFrame(values, steps, columns=[\"training-mae\", \"val-mae\"])\n\n# Plotting\nplt.figure(figsize=(20,10))\nplt.plot(data['training-mae'], label='train')\nplt.plot(data['val-mae'], label='validation')\nplt.title('Training and validation loss', fontsize=18)\nplt.ylabel('Loss', fontsize=18)\nplt.xlabel('Epoch', fontsize=18)\nplt.legend(prop={'size': 18})\n","28af5496":"predictions = model.predict(testInput).flatten()\nmetric = keras.metrics.MeanAbsoluteError()\nmetric.update_state(predictions, testTarget)\nmetric.result().numpy()","375da4dd":"model.summary()\nlayer = model.get_layer('dense')\nw1,w0 = layer.get_weights()\nw1 = float(w1[0])\nw0 = float(w0[0])","9482c6d3":"plt.plot(pd.to_datetime(only_death['Date']),\n         only_death['New deaths'], 'g', label=\"real\")\nonly_death['Linear'] = (pd.to_datetime(\n    only_death['Date']) - start_date) \/ datetime.timedelta(days=1) * w1 + w0\nplt.plot(pd.to_datetime(\n    only_death['Date']), only_death['Linear'], 'b', marker='.', label=\"linear\")\nplt.show()\n","5f2a0fa2":"from sklearn.preprocessing import PolynomialFeatures\nfrom keras.layers import Input, Dense\nfrom keras.optimizers import Adam\n\ntrX, trY = pd.to_datetime(only_death['Date']), only_death['New deaths']\ntrX = (trX - trX.min()) \/ datetime.timedelta(days = 1)\ntrX, trY = trX\/trX.max(), trY\/trY.max()\n\n\ntrs, models = [], []\nns = [3, 5, 10, 15]\nfor n in ns:\n    poly = PolynomialFeatures(n)\n\n\n    trX_expanded = np.expand_dims(trX, axis=1)\n    trX_expanded = poly.fit_transform(trX_expanded)\n    \n    graph = tf.Graph()\n    inp = Input((n+1)) \n\n    out = Dense(1)(inp)\n    model = keras.Model(inputs=inp, outputs=out)\n    model.compile(optimizer=Adam(lr=1e-3), loss=\"mean_squared_error\")\n\n    model.fit(trX_expanded, trY, epochs=500)\n    models.append(model)\n    trs.append(trX_expanded)","3c0ba51e":"plt.figure(figsize=(20, 10))\nplt.plot(pd.to_datetime(only_death['Date']),\n         only_death['New deaths'], 'g', label=\"real\")\n\ncolors = ['violet', 'blue', 'yellow', 'orange']\ndates = pd.to_datetime(only_death['Date'])\n\npolynomial_predictions = []\nfor m, n, trX_expanded, c in zip(models, ns, trs, colors):\n    polynomial_predictions.append(\n        m.predict(trX_expanded) * only_death['New deaths'].max())\n    plt.plot(dates, polynomial_predictions[-1], c, label=f'polynomial {n}')\nplt.plot(pd.to_datetime(\n    only_death['Date']), only_death['Linear'], 'cyan', marker='.', label=\"linear\")\nplt.ylabel('New deaths', fontsize=18)\nplt.xlabel('Date', fontsize=18)\nplt.legend(prop={'size': 18})\nplt.show()\n","89c4686d":"from pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nrcParams['figure.figsize'] = 16, 10\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","38a6d8d4":"def get_cases_by_date(data, country):\n    if country not in np.unique(data['Country\/Region']):\n        return\n    data = data[data['Country\/Region'] == country][['New deaths']]\n\n    return data","af1037a7":"dates = only_death['Date']\n","49ce4368":"plt.plot(pd.to_datetime(dates),\n         only_death['New deaths'], label='Deaths by date')\nplt.legend();","ae46f007":"res = np.array(only_death['New deaths']).flatten()\ndates = np.array(dates).flatten()\ndf = pd.DataFrame(dict(dead=res), index=dates, columns=['dead'])\nprint(df.head())","451da56a":"train_size = int(len(df) * 0.8) \ntest_size = len(df) - train_size\ntrain, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]","438eef37":"def create_dataset(X, y, time_steps=1):\n    Xs, ys = [], []\n    for i in range(len(X) - time_steps):\n        v = X.iloc[i:(i + time_steps)].values\n        Xs.append(v)        \n        ys.append(y.iloc[i + time_steps])\n    return np.array(Xs), np.array(ys)","f80b891e":"time_steps = 1\n\n# reshape to [samples, time_steps, n_features]\nprint(train.iloc[: time_steps].values)\nprint(train.iloc[: time_steps])\nX_train, y_train = create_dataset(train, train.dead, time_steps)\nX_test, y_test = create_dataset(test, test.dead, time_steps)\nprint(train)\nprint(X_train.shape, y_train.shape)","5557b1b8":"model = keras.Sequential()\nmodel.add(keras.layers.LSTM(128, input_shape=(\n    X_train.shape[1], X_train.shape[2])))\nmodel.add(keras.layers.Dense(1))\nmodel.compile(loss='mean_squared_error',\n              optimizer=keras.optimizers.Adam(0.001))\n","3810e580":"history = model.fit(\n    X_train, y_train, \n    epochs=100, \n    batch_size=1, \n    validation_split=0.1, \n    verbose=1, \n    shuffle=False\n)","1412636d":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.title('Training and validation loss', fontsize=18)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend();","6c46495d":"y_pred = model.predict(X_test)","a79aab93":"%%run_pytest[clean]\n\ndef test_predict():\n    assert ((y_pred < 0).any() == False)","a4ec65e3":"plt.plot(pd.to_datetime(dates[:len(y_train)]), y_train, 'g', label=\"previous\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, marker='.', label=\"true\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train) + len(y_test)]), y_pred, 'r', label=\"prediction\")\nplt.title('Prediction on the background of previous values')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.legend()\nplt.show()","02371f28":"plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, 'magenta', marker='.', label=\"true\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_pred, 'r', label=\"prediction\")\nfor m, n, trX_expanded, c in zip(models, ns, trs, colors):\n    plt.plot(\n        pd.to_datetime(\n            dates[len(y_train):len(y_train)+len(y_test)]\n        ),\n        m.predict(trX_expanded)[len(y_train):len(\n            y_train)+len(y_test)] * only_death['New deaths'].max(),\n        c,\n        linestyle=':',\n        label=f'polynomial {n}')\nplt.plot(\n    pd.to_datetime(dates[len(y_train):len(y_train) +\n                         len(y_test)]),\n    only_death['Linear'][len(y_train):len(y_train)+len(y_test)],\n    'cyan',\n    linestyle=':',\n    label='linear'\n)\n\nplt.title('Prediction against the true values')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.xticks(rotation=40)\nplt.legend()\nplt.show()\n","1b5cab5d":"metric = keras.metrics.MeanAbsoluteError()\nmetric.update_state(y_pred, y_test)\n# only_death['Linear'][len(y_train):len(y_train)+len(y_test)]\nprint(F'LSTM MAE: {metric.result():.2f}')\nmetric.update_state(only_death['Linear'][len(\n    y_train):len(y_train)+len(y_test)], y_test)\nprint(F'Linear regression MAE: {metric.result():.2f}')\n\ngraph = tf.Graph()\nfor m, n, trX_expanded, pred in zip(models, ns, trs, polynomial_predictions):\n    metric.update_state(np.array(pred).flatten()[\n                        len(y_train):len(y_train)+len(y_test)], y_test)\n    print('Polynomial {} regression MAE {:.2f}'\n          .format(n, metric.result()\n                  )\n          )\n","943d40d6":"train_size = int(len(df) * 0.8) \ntest_size = len(df) - train_size\ntrain, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]","a0cadbd9":"time_steps = [2, 3, 4, 5, 10]\n\n# reshape to [samples, time_steps, n_features]\ntrain_list, test_list = [], []\n\nfor t in time_steps:\n    X_train, y_train = create_dataset(train, train.dead, t)\n    X_test, y_test = create_dataset(test, test.dead, t)\n    train_list.append((X_train, y_train))\n    test_list.append((X_test, y_test))","4fd1f45d":"predictions = []\n\nfor X_train, y_train in train_list:\n    model = keras.Sequential()\n    model.add(keras.layers.LSTM(128, input_shape=(\n    X_train.shape[1], X_train.shape[2])))\n    model.add(keras.layers.Dense(1))\n    model.compile(loss='mean_squared_error',\n              optimizer=keras.optimizers.Adam(0.001))\n\n    model.fit(\n        X_train, y_train, \n        epochs=100, \n        batch_size=1, \n        validation_split=0.1, \n        verbose=1, \n        shuffle=False\n    )\n    \n    y_pred = model.predict(X_test)\n    predictions.append(y_pred)\n    ","c000086e":"plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, 'magenta', marker='.', label=\"true\")\n\nfor p, c, s in zip(predictions, colors + ['black'], time_steps):\n    plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), p, c, linestyle=':', label=f'steps {s}')\n\nplt.title('Predictions comparison')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.xticks(rotation=40)\nplt.legend()\nplt.show()","75f2a34b":"graph = tf.Graph()\n\nfor p, step in zip(predictions, time_steps):\n    metric.update_state(np.array(p).flatten(), y_test)\n    print('Step {} LSTM MAE {:.2f}'\n          .format(step, metric.result()\n                  )\n          )","11738a42":"## Relation between steps count and prediction accuracy","086d3393":"### Prepare pytest for unit testing","8a714c90":"## Long short-term memory (LSTM)","88f1fc2a":"## Test predicted values","d44041cc":"## Polynomial regression","65c0ec31":"### Training and validation loss","c81aa180":"## Models MAE comparison","0fd4ccf3":"\n### Data processing","24e4ee17":"## Linear regression","807488a4":"### Check that all dates and New deaths in dataset are valid"}}