{"cell_type":{"55177243":"code","0861087a":"code","48c09f4f":"code","b422df89":"code","57363eba":"code","9e984e09":"code","0f67b696":"code","308b12e7":"code","ef3dfc38":"code","f06052c4":"code","5cdda998":"code","93db6f68":"code","e1629184":"code","0e715b55":"code","740d515f":"code","06bf411c":"code","14871646":"code","6cd7288d":"code","74a2c619":"code","2f512550":"code","7abc4a54":"code","7d157c8f":"code","b8596a9b":"code","86d82f51":"code","36dff284":"code","2a042d36":"code","9550d02e":"code","97e62aa2":"code","0d46b94c":"code","f725b6c6":"code","d4991798":"code","3e82763a":"code","c357165e":"code","6d45253c":"code","ed6bfb9c":"code","f2f01526":"code","203e142e":"code","a33deae9":"markdown","3bf2d33c":"markdown","39c6a275":"markdown","90aaeefb":"markdown","33a2cc5c":"markdown","7c3a3aad":"markdown","e4bb9ac6":"markdown","3847ebc4":"markdown","12d7c1d8":"markdown","be313953":"markdown","1f7fc8e3":"markdown","48de61e7":"markdown","04eb9f00":"markdown","e0f4950a":"markdown","3afd350a":"markdown","f9d235ca":"markdown","1c143cf1":"markdown","c7e5d9d3":"markdown","cbcb7ac9":"markdown","7a2322f4":"markdown","1a8df9df":"markdown","684b5702":"markdown","4e469aec":"markdown","ff59161b":"markdown","fe6f1a05":"markdown","7c236d18":"markdown","a1d88012":"markdown"},"source":{"55177243":"import numpy as np \nimport pandas as pd\nimport os\nimport re\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn import preprocessing\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\n\n\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","0861087a":"df_train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv', index_col='id')\ndf_test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv', index_col='id')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\n\ndf_all = pd.concat([df_train, df_test]).reset_index(drop=True)","48c09f4f":"df_all.shape","b422df89":"df_test.shape","57363eba":"df_train.head()","9e984e09":"df_train.isnull().sum()","0f67b696":"df_train.isnull().sum().sum()","308b12e7":"df_test.isnull().sum()","ef3dfc38":"df_test.isnull().sum().sum()","f06052c4":"df_train.target.value_counts()","5cdda998":"target_vc = df_train.target.value_counts()\nvalues = target_vc.values.tolist()\nindexes = target_vc.index.tolist()\ncolors = ['lightskyblue', 'indianred', 'aqua', 'limegreen', 'gold','teal','coral','tan','deeppink']\n\n\nax,fig = plt.subplots(1,2,figsize=(20,8))\nplt.subplot(1,2,1)\nplt.bar(indexes,values, color = 'darkturquoise')\nplt.title(\"Target Distribution Bar Chart\")\nplt.subplot(1,2,2)\nplt.pie(values,colors=colors, labels=indexes)\nplt.title(\"Target Distribution Pie Chart\")\nplt.show()","93db6f68":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\ny = np.array([df_train[f'feature_{i}'].nunique() for i in range(75)])\ny2 = np.array([df_test[f'feature_{i}'].nunique() for i in range(75)])\ncomp = y-y2\n\n\nax.bar(range(75), y2, alpha=0.7, color='darkturquoise', label='Test Dataset')\nax.bar(range(75),  comp*(comp>0), bottom=y2, color='green', alpha=0.7, label='Train > Test')\nax.bar(range(75), comp*(comp<0), bottom=y2-comp*(comp<0), color='red', alpha=0.7, label='Train < Test')\n\nax.set_yticks(range(0, 120, 5))\nax.margins(0.02)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('# of Features Unique Values (Train\/Test)', loc='left', fontweight='bold')\nax.set_xlabel('Feature')\nax.legend()\nplt.show()","e1629184":"pd.DataFrame(data={'feature' : np.arange(75)[comp>0], \n              'delta' : comp[comp>0]}, index=None)","0e715b55":"features_set = df_train.drop(labels=['target'],axis=1)\ndef plot_diag_heatmap(data):\n    corr = data.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    f, ax = plt.subplots(figsize=(11, 9))\n    sns.heatmap(corr, mask=mask, cmap='viridis', center=0,square=True, linewidths=1, cbar_kws={\"shrink\": 1.0})\nplot_diag_heatmap(features_set)","740d515f":"display(df_train.sort_values(by=['target'], ascending=True).head())","06bf411c":"display(df_train.sort_values(by=['target'], ascending=False).head())","14871646":"df_train.shape","6cd7288d":"df_train.describe()","74a2c619":"target = df_train['target'].apply(lambda x: int(x.split(\"_\")[-1])-1).to_numpy()","2f512550":"target","7abc4a54":"y_train = tf.keras.utils.to_categorical(target, num_classes=9)","7d157c8f":"y_train","b8596a9b":"df_train.drop('target', axis=1, inplace=True)","86d82f51":"scaler = StandardScaler()","36dff284":"scaler.fit(df_train)","2a042d36":"df_train = scaler.fit_transform(df_train)","9550d02e":"df_train","97e62aa2":"#Train-test split\ntrain_X, val_X, train_y, val_y = train_test_split(df_train,y_train,random_state=1,test_size=0.2)","0d46b94c":"train_X","f725b6c6":"train_y","d4991798":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)","3e82763a":"model = keras.Sequential([\n    layers.Dense(units=128, activation='relu', input_shape=[df_train.shape[1]]),\n    layers.Dense(units=32, activation='relu'),\n    layers.Dense(units=16, activation='relu'),\n    layers.Dense(units=8, activation='relu'),\n    # the linear output layer \n    layers.Dense(9, activation='softmax'),\n])","c357165e":"model.compile(\n    optimizer=Adam(lr=0.01), \n    loss='categorical_crossentropy',\n    metrics='accuracy'\n)","6d45253c":"history = model.fit(\n    train_X, train_y,\n    validation_data=(val_X, val_y),\n    #batch_size=32,\n    epochs=50,\n    callbacks=[early_stopping, learning_rate_reduction]\n)","ed6bfb9c":"score = model.evaluate(val_X, val_y, verbose = 0)\nprint('Test loss: {}%'.format(score[0]))\nprint('Test score: {}%'.format(score[1] * 100))\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","f2f01526":"fig, ax = plt.subplots(figsize = (10, 4))\nsns.lineplot(x = history.epoch, y = history.history['loss'],color ='red')\nsns.lineplot(x = history.epoch, y = history.history['val_loss'], color='blue')\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc = 'best')\nplt.show()","203e142e":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']] = model.predict(df_test)\nsample_submission.to_csv('submission.csv', index = False)","a33deae9":"Check for missing values for each column for the train dataset\nThis can be done by\n*dataset.isnull().sum()*","3bf2d33c":"[Back to Top](#section-zero)","39c6a275":"<a id=\"section-libraryimportation\"><\/a>\n# Import all the required libraries","90aaeefb":"> Seems like we do not have any missing values on the train dataset","33a2cc5c":"[Back to Top](#section-zero)","7c3a3aad":"[Back to Top](#section-zero)","e4bb9ac6":"**Features**","3847ebc4":"**Define Callbacks**","12d7c1d8":"<a id=\"section-loadingdatasets\"><\/a>\n# Load datasets","be313953":"Check total missing values. This can be done by\n*dataset.isnull().sum().sum()* (sum() on the above cell command)","1f7fc8e3":"[Back to Top](#section-zero)","48de61e7":"<a id=\"section-preprocessing\"><\/a>\n# Data Preprocessing","04eb9f00":"> Seems like we do not have any missing values on the test dataset","e0f4950a":"**Missing Values**","3afd350a":"value_counts() return a Series containing counts of unique values.\n\nThe resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default.","f9d235ca":"Check for missing values for each column for the test dataset\nThis can be done by\n*dataset.isnull().sum()*","1c143cf1":"[Back to Top](#section-zero)","c7e5d9d3":"**Define Model**","cbcb7ac9":"Plot a correlation matrix","7a2322f4":"<a id=\"section-submission\"><\/a>\n# Making the Submission","1a8df9df":"**Target Column**","684b5702":"Plot line plots for loss and validation loss for the model","4e469aec":"[Back to Top](#section-zero)","ff59161b":"<a id=\"section-EDA\"><\/a>\n# Exploratory Data Analysis (EDA)","fe6f1a05":"\n<a id=\"section-zero\"><\/a>\n\n# TABLE OF CONTENTS\n\n\n* [Library Importations](#section-libraryimportation)\n* [Loading Datasets](#section-loadingdatasets)\n* [Exploratory Data Analysis](#section-EDA)\n* [Data Preprocessing](#section-preprocessing)\n* [Building Model](#section-six)\n    - [Neural Network](#subsection-six-five)\n* [Submission](#section-submission)","7c236d18":"Let's check the features with more no of unique values in Train dataset than test dataset","a1d88012":"Let's plot the number of unique values of the features."}}