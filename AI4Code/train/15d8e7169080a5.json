{"cell_type":{"36f38488":"code","aceaaca9":"code","b8f15312":"code","13aa5aac":"code","88b2502f":"code","59b4e560":"code","17e948c9":"code","6fb19a04":"code","616aba60":"code","a87c995f":"code","6ba6b367":"code","ee056bbc":"code","5e07c530":"code","96b2cbaa":"code","23989d38":"code","c4a75832":"code","d582fd23":"code","e4c9fe01":"code","9fe4fc85":"code","cd272f5b":"code","925090b8":"code","b58a24f7":"code","1b0f4ea5":"code","6cce50a3":"code","a8f2d30e":"code","4059b2b3":"code","f72a2fe8":"code","d08826fd":"code","977982d3":"markdown","e4a380de":"markdown","489fa989":"markdown","595fc4d4":"markdown","e395a70f":"markdown","2547e120":"markdown","c5415030":"markdown","e3181584":"markdown","17016392":"markdown","fdd526ff":"markdown","15d1f051":"markdown","c3123782":"markdown","f69c0129":"markdown","caa86f78":"markdown","1467202c":"markdown","381032e3":"markdown"},"source":{"36f38488":"#Import Necessary Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os # accessing directory structure","aceaaca9":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b8f15312":"df = pd.read_csv('\/kaggle\/input\/hepatitis-c-dataset\/HepatitisCdata.csv')","13aa5aac":"# lets look top few rows\ndf.head()","88b2502f":"# Lets look few bottom rows\ndf.tail()","59b4e560":"#lets droped the column 0 as it looks like srial nos.\ndf = df.drop(labels =\"Unnamed: 0\", axis=1)","17e948c9":"# lets gather some information about data\ndf.info()","6fb19a04":"#lets drop null values as we cant fill null values wrongly for medical data\ndf = df.dropna()\ndf.info()","616aba60":"# lets see how many category are there \ndf[\"Category\"].unique()","a87c995f":"# Though there are many categories, we are breaking it into binary: healthy and unhealthy.\ndf['Category'].loc[df['Category'].isin([\"1=Hepatitis\",\"2=Fibrosis\", \"3=Cirrhosis\"])] = 1\ndf['Category'].loc[df['Category'].isin([\"0=Blood Donor\", \"0s=suspect Blood Donor\"])] = 0\ndf = df.astype({'Category': 'int'})","6ba6b367":"# lets see how many records falls in each category\ndf[\"Category\"].value_counts()","ee056bbc":"# lets group by sex\ndf.groupby([\"Sex\", \"Category\"]).size()","5e07c530":"# lets look at Statical attributes of dataset\ndf.describe()","96b2cbaa":"# Box and whisker plot\ndf.plot(kind=\"box\", subplots = True, layout=(2,6), figsize=(12,6))\nplt.show()","23989d38":"#Histogram\ndf.hist(layout=(4,3), figsize=(10,12))\nplt.show()","c4a75832":"# Let's plot category against age , group by sex\nx = df['Age']\ny = df[\"Category\"]\nscatter = plt.scatter(x, df[\"Sex\"], c=y, cmap='winter')\nplt.title('Category by Age ')\nplt.xlabel('Age')\nplt.ylabel('Category')\nplt.legend(*scatter.legend_elements(), title='Hepatitis')\nplt.show()","d582fd23":"# We also need to use numerical data for the sex column, lets encode\ndf['Sex'].loc[df['Sex']=='m']=1\ndf['Sex'].loc[df['Sex']=='f']=0\ndf = df.astype({'Sex': 'int'})","e4c9fe01":"# input variable\nX = df.drop(labels=\"Category\", axis=1)\n\n# Output variable\ny = df[\"Category\"]","9fe4fc85":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","cd272f5b":"# lets import necessary libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC","925090b8":"# Lets create a dictionary for Model parameters\n\nmodel_param = {'DecisionTreeClassifier':{'model': DecisionTreeClassifier(random_state=0), 'param': {'criterion': ['gini','entropy']}},\n              'Randomforest': {'model': RandomForestClassifier(random_state=0), 'param': {'n_estimators':[1,5,10,15,20,25,30,40,50,60,80,100]}},\n              'LogisticRegression':{'model': LogisticRegression(solver='liblinear',multi_class='auto', random_state=0),'param': {'C': [1,5,10,15,20]}},\n              'GaussianNB':{'model': GaussianNB(), 'param': {}},\n              'MultinomialNB':{'model': MultinomialNB(), 'param': {}},\n               'SVM':{'model': SVC(gamma='auto', random_state=0), 'param': {'C': [0.001,0.1,1],'kernel':['rbf', 'linear']}}\n              }","b58a24f7":"# Applying GridSearchCV to evaluate models\n\nfrom sklearn.model_selection import GridSearchCV\n\nscores = []\n\nfor model_name, mp in model_param.items():\n    cl = GridSearchCV(mp['model'], mp['param'], cv=5, return_train_score=None)\n    cl.fit(X,y)\n    scores.append({\n        'model': model_name,\n        'best_score': cl.best_score_,\n        'best_params': cl.best_params_\n    })","1b0f4ea5":"scores","6cce50a3":"# lets see scores as a dataframe\nscore1 = pd.DataFrame(scores)\nscore1.sort_values(by=['best_score'], inplace = True, ascending=False)\nscore1","a8f2d30e":"# Apply random forest\nmodel = SVC(C=0.1, kernel='linear')\nmodel.fit(X_train, y_train)\n\n# make predictions\npredictions = model.predict(X_test)","4059b2b3":"# lets create confusion matrix to compare results\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, predictions)\ncm","f72a2fe8":"# Lets plot confusion matrix \nsns.heatmap(cm, annot=True, cmap=\"viridis\" ,fmt='g')\nplt.title('Confusion matrix')\nplt.xlabel('Actual label')\nplt.ylabel('Predicted label')\nplt.show()","d08826fd":"# lets calculate the classification accuracy \n#classification accuracy = correct predictions \/ total predictions * 100\ncls_acc = (108+9)\/(108++1+0+9)*100\nprint(\"Calssification Accuracy:\"+str(round(cls_acc,2))+\"%\")\n#error rate = 100- Calssification accuracy\nerror_rate = 100-cls_acc\nprint(\"Error Rate:\"+str(round(error_rate,2))+\"%\")","977982d3":"We can see that there are lot of outliers in most of the input variables, but I'm not going to do anything about them beacause:\n\n- I'm not into medical field and I dont have enough knowledege abot most of the features and what they represent.\n- Blood analysis values for each feature can differ hugely between healthy and unhealthy individual and the outliers in this DataFrame may contain some important information for the models to come in order to predict the disease.\n- This dataset is very small, only 589 records are there, That is very few and most of them refer to healthy people so I want to exploit each and every single one of them.","e4a380de":"\n### Step 7: Applying best model on Training Set","489fa989":"### Objective:\nPatient category prediction if healthy or unhealthy\n\n**Dataset:** \nThe data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age. The data was obtained from UCI Machine Learning Repository: https:\/\/archive.ics.uci.edu\/ml\/datasets\/HCV+data\n\n**By:** Sanket Sharma, ur.sanketsharma@gmail.com\n","595fc4d4":"By above graph be can see that all males below the age 30 are positive. The model used will likely put too much weight on this coincidence due to such strong correlation. But we are not droping males below the age 30 because we have very less records.","e395a70f":"We can see that few variables are following nearly normal distribution ","2547e120":"it means there are 533 healthy people and 56 unhealty","c5415030":"### Step 5: Spliting into training and testing sets","e3181584":"### Step 1: Load Data","17016392":" We can see that **Category** and **Sex** column holds categorical data and all other variables have numerical values\n \n Columns **ALB**, **ALP**, **ALT**, **CHOL**, and **PROT** have few records missing, now we can either fill those records or drop those rows having missing data. but we cant fill assumed values for medical data so lets drop them","fdd526ff":"There are 210 healthy and 16 unhealthy females, while 323 healthy and 40 unhealthy males","15d1f051":"\nHere we can See that SVM is giving best results while parameters are 'C':0.1, 'kernel':'linear', We will be using SVM model","c3123782":"### Step6: Evaluating different Models\nWe dont know which calssification Model will perform best for this problem, So we will be evaluating below models using GridSearchCV: 1.DecisionTreeClassifier 2.RandomForest 3.LogisticRegression 4.GaussianNB 5.MultinomialNB 6.SVM","f69c0129":"We can see that there are 108 True-Negative predictions, 0 False-Negative prediction, 1 False-Positive prediction and 9 True-Positive predictions. it means our model is actually predicting well","caa86f78":"### Step 4: Define Input and Output variable","1467202c":"### Step 2: Summarize Dataset","381032e3":"### Step 4: Visualise Data\n\n**Univariate plots**"}}