{"cell_type":{"e34bd2b3":"code","db4ba6c4":"code","d19ea677":"code","568cfb35":"code","5db33d42":"code","afe75442":"code","7dbdf44f":"code","43cbcf2f":"code","4d3ea1d1":"code","5e75f09f":"code","d09e7e90":"markdown","a8104eb8":"markdown"},"source":{"e34bd2b3":"import torch","db4ba6c4":"# The autograd package provides automatic differentiation \n# for all operations on Tensors\n\n# requires_grad = True -> tracks all operations on the tensor. \nx = torch.randn(3, requires_grad=True)\ny = x + 2\n# y was created as a result of an operation, so it has a grad_fn attribute.\n# grad_fn: references a Function that has created the Tensor\nprint(x) # created by the user -> grad_fn is None\nprint(y)\nprint(y.grad_fn)","d19ea677":"# Do more operations on y\nz = y * y * 3\nprint(z)\nz = z.mean()\nprint(z)","568cfb35":"# Let's compute the gradients with backpropagation\n# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n# The gradient for this tensor will be accumulated into .grad attribute.\n# It is the partial derivate of the function w.r.t. the tensor\n\nz.backward()\nprint(x.grad) # dz\/dx","5db33d42":"\n# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n# It computes partial derivates while applying the chain rule\n\n# -------------\n# Model with non-scalar output:\n# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward() \n# specify a gradient argument that is a tensor of matching shape.\n# needed for vector-Jacobian product\n\nx = torch.randn(3, requires_grad=True)\n\ny = x * 2\nfor _ in range(10):\n    y = y * 2\n\nprint(y)\nprint(y.shape)\n\nv = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\ny.backward(v)\nprint(x.grad)","afe75442":"\n# Stop a tensor from tracking history:\n# For example during our training loop when we want to update our weights\n# then this update operation should not be part of the gradient computation\n# - x.requires_grad_(False)\n# - x.detach()\n# - wrap in 'with torch.no_grad():'\n\n# .requires_grad_(...) changes an existing flag in-place.\na = torch.randn(2, 2)\nprint(a.requires_grad)\nb = ((a * 3) \/ (a - 1))\nprint(b.grad_fn)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)","7dbdf44f":"\n\n# .detach(): get a new Tensor with the same content but no gradient computation:\na = torch.randn(2, 2, requires_grad=True)\nprint(a.requires_grad)\nb = a.detach()\nprint(b.requires_grad)","43cbcf2f":"# wrap in 'with torch.no_grad():'\na = torch.randn(2, 2, requires_grad=True)\nprint(a.requires_grad)\nwith torch.no_grad():\n    print((x ** 2).requires_grad)","4d3ea1d1":"\n# backward() accumulates the gradient for this tensor into .grad attribute.\n# !!! We need to be careful during optimization !!!\n# Use .zero_() to empty the gradients before a new optimization step!\nweights = torch.ones(4, requires_grad=True)\n\nfor epoch in range(3):\n    # just a dummy example\n    model_output = (weights*3).sum()\n    model_output.backward()\n    \n    print(weights.grad)\n","5e75f09f":"\n    # optimize model, i.e. adjust weights...\n    with torch.no_grad():\n        weights -= 0.1 * weights.grad\n\n    # this is important! It affects the final weights & output\n    weights.grad.zero_()\n\nprint(weights)\nprint(model_output)\n\n# Optimizer has zero_grad() method\n# optimizer = torch.optim.SGD([weights], lr=0.1)\n# During training:\n# optimizer.step()\n# optimizer.zero_grad()","d09e7e90":"Credits: Python Engineer\n\nDon't hesitate to watch YouTube video. It has clear explanation\n\nhttps:\/\/youtu.be\/DbeIqrwb_dE\n\nIf you like my notebook Please upvote\n\nI will going to create more notebooks on pytorch","a8104eb8":"By deafult grad function will be false. To enable autograd we need to specify it as true\n\ngradient-- slope\n\nwhen we specify grad as true, it will save all information in graphical represetaion and we can apply backprop on that function"}}