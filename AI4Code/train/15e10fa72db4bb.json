{"cell_type":{"e466fc5d":"code","65b6d7d8":"code","f300e8c6":"code","15bb5e79":"code","8fac1497":"code","2ac085d9":"code","b09d50ec":"code","22c31f5c":"code","3b2e4755":"code","13cdcbc9":"code","cb83f6a4":"code","e83dbcce":"code","7eaaf7bf":"code","b8eb8cca":"code","7b4309bc":"code","22a50b07":"code","44b4d3b0":"code","b6a2ddd4":"code","3530d948":"code","1e6f9603":"code","196909bc":"code","8dea1572":"code","af455089":"code","a567c9a6":"code","1f0e523e":"code","834dc58a":"code","2ba7b74b":"code","be179e96":"code","289f5b3c":"code","d43b7419":"code","50e26476":"code","5c47646b":"code","74aa1899":"code","634826d5":"code","72fcd2f0":"code","78466240":"code","55c67fb2":"code","71727856":"code","00abd9ad":"code","b02c5d70":"code","3f3639ca":"code","40c6aabd":"code","c98a18c5":"code","0b5f0ede":"code","c9e65086":"code","2c94268e":"code","15b98c11":"code","f2420bf3":"code","8365e140":"code","aa1019c7":"code","993e9921":"code","27fc7f3b":"code","b051c560":"code","560e6f1b":"code","60b17928":"code","b2888763":"code","8e1493f6":"code","36a91de8":"code","a45d8c73":"markdown"},"source":{"e466fc5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","65b6d7d8":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","f300e8c6":"import matplotlib.pyplot as plt\nimport missingno as msno\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","15bb5e79":"train_label = train[['Id', 'SalePrice']]\nfeatures = pd.concat([train.drop(columns=['SalePrice']), test])\nfeatures.shape, train_label.shape, train.shape","8fac1497":"msno.matrix(features)","2ac085d9":"features['totalArea'] = features['TotalBsmtSF'] + features['GrLivArea']\n\n## \ub9ac\ubaa8\ub378\ub9c1 \uc774\ud6c4\uc5d0 \ud310\ub9e4\ub418\uc5c8\uc73c\uba74 \uac74\uc124\uc2dc\uc810 \uae30\uc900\uc73c\ub85c \ubc14\uafd4\uc918\uc57c\ud568!!\ntemp = []\nfor ind, val in features.iterrows():\n    if val['YearRemodAdd'] > val['YrSold']:\n        temp.append(val['YrSold']-val['YearBuilt'])\n    else:\n        temp.append(val['YrSold']-val['YearRemodAdd'])\n\n\nfeatures['SinceRemod'] = temp\n\n\n\n\nc_features = features[['Id', 'totalArea', 'MSSubClass', 'Neighborhood', 'SaleType', 'Heating', 'SinceRemod', 'OverallQual', 'ExterQual', 'TotRmsAbvGrd', 'GarageCars']]\nc_features.head()","b09d50ec":"c_features['SinceRemod'].describe()","22c31f5c":"c_features[c_features['SinceRemod']<0]","3b2e4755":"features.iloc[2549][['YearBuilt', 'YearRemodAdd', 'YrSold']]","13cdcbc9":"train_label.tail()","cb83f6a4":"x = train_label['SalePrice']\n\nplt.figure(figsize=(16,9))\nplt.title(\"SalePrice Dist\")\nsns.distplot(x)\nplt.show()","e83dbcce":"X = features.iloc[:1460]['totalArea']\ny = train_label['SalePrice']\n\nplt.figure(figsize=(16,9))\nplt.scatter(X, y, s=5, color='dodgerblue')\nplt.title('Area-Price')\nplt.show()","7eaaf7bf":"X = features.iloc[:1460]['totalArea']\ny = np.log(train_label['SalePrice'])\n\nplt.figure(figsize=(16,9))\nplt.scatter(X, y, s=5, color='dodgerblue')\nplt.title('Area-Price')\nplt.axvline(7500, ls='--', color='#070707')\nplt.show()","b8eb8cca":"features[features['totalArea']>7500]","7b4309bc":"c_features['SinceRemod'] = c_features['SinceRemod'].replace(-1, 0)","22a50b07":"c_features.sample(5)","44b4d3b0":"train_label.sample(5)","b6a2ddd4":"train_label['SalePrice_log'] = np.log1p(train_label['SalePrice'])\n\nplt.figure(figsize=(9,6))\nstats.probplot(train_label['SalePrice'], plot=plt)\nplt.show()\n\nplt.figure(figsize=(9,6))\nstats.probplot(train_label['SalePrice_log'], plot=plt)\nplt.show()\n","3530d948":"c_features.reset_index(inplace=True, drop=True)\nc_features = c_features.drop(index=[523, 1298])","1e6f9603":"c_features.shape","196909bc":"train.shape[0], test.shape[0], train.shape[0] +test.shape[0]","8dea1572":"train_label.drop(index=[523, 1298], inplace=True)\ntrain_label.shape","af455089":"c_features.isna().sum()","a567c9a6":"c_features[np.isnan(c_features['totalArea'])]","1f0e523e":"c_features[np.isnan(c_features['GarageCars'])]","834dc58a":"c_features.SaleType.sort_values()","2ba7b74b":"test[test['Id']==2121][['GrLivArea', 'TotalBsmtSF']]","be179e96":"test.columns","289f5b3c":"test[test['Id']==2121][['GrLivArea', 'TotalBsmtSF', 'BsmtQual', 'BsmtCond', 'BsmtExposure']]","d43b7419":"temp = c_features['totalArea'].replace(np.nan, 896)\nc_features['totalArea'] = temp","50e26476":"test[test['Id']==2577][['GarageType', 'GarageYrBlt', 'GarageArea', 'GarageQual', 'GarageCond']]","5c47646b":"temp = c_features['GarageCars'].replace(np.nan, 0)\nc_features['GarageCars'] = temp","74aa1899":"test[test['Id']==2490]","634826d5":"c_features.SaleType.value_counts()","72fcd2f0":"temp = c_features['SaleType'].fillna('WD')\nc_features['SaleType'] = temp","78466240":"c_features.isna().sum()","55c67fb2":"c_features.shape, train_label.shape","71727856":"c_features.head(3)","00abd9ad":"c_features.sample(6)","b02c5d70":"num = c_features.dtypes[c_features.dtypes != \"object\"].index\nc_features[num].skew()","3f3639ca":"from scipy.special import boxcox1p\n\nprint(boxcox1p(c_features['totalArea'], 0.15).skew())\n# c_features['totalArea'] = boxcox1p(c_features['totalArea'], 0.15)\nc_features['MSSubClass'] = c_features['MSSubClass'].apply(str)\n\nc_features = pd.get_dummies(c_features)\nc_features.shape","40c6aabd":"c_features.head()","c98a18c5":"# c_features.drop(columns=['Id'], inplace=True)","0b5f0ede":"ntrain = train_label.shape[0]\ntrain_f = c_features[:ntrain]\ntest_f = c_features[ntrain:]\ntrain_f.shape, test_f.shape","c9e65086":"train_f.head()","2c94268e":"from sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","15b98c11":"lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.001, random_state=99))\nenet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.001, random_state=11))\ngbr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05, max_features='sqrt', loss='huber', random_state=5)\nrfr = RandomForestRegressor(n_estimators=100, random_state=77)\nxgbr = xgb.XGBRegressor(gamma=0.05, learning_rate=0.05, max_depth=3, n_estimators=1200, random_state =100)\nlgbr = lgb.LGBMRegressor(objective='regression', learning_rate=0.05, n_estimators=200)","f2420bf3":"models = [lasso, enet, gbr, rfr, xgbr, lgbr]\n\nfor model in models:\n    print(\"cross_val_score: {:.3f}\".format(sum(cross_val_score(model, train_f, train_label['SalePrice_log'], cv=5))\/5))","8365e140":"chosen_models = [lasso, enet, gbr, xgbr]\nclass avg_models():\n    def __init__(self, models):\n        self.models = models\n        \n    def fit(self, X, y):\n        self.models_ = [x for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([model.predict(X) for model in self.models_])\n        return np.mean(predictions, axis=1)   ","aa1019c7":"avg = avg_models(models=chosen_models)\navg.fit(train_f, train_label['SalePrice_log'])\navg.predict(test_f)","993e9921":"predictions = avg.predict(test_f)\nlen(predictions)","27fc7f3b":"len(test_f)","b051c560":"test['SalePrice'] = np.array(np.exp(predictions)-1)\n\nsubmission = test[['Id', 'SalePrice']]\nsubmission.head(5)","560e6f1b":"len(test['Id']) ,len(predictions)","60b17928":"sample_submission.head(5)","b2888763":"submission.shape, sample_submission.shape","8e1493f6":"submission","36a91de8":"submission.to_csv('submission4.csv', index=False)","a45d8c73":"Thanks to serigne\nhttps:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard#Modelling"}}