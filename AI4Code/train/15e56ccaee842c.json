{"cell_type":{"989952ac":"code","8b2e8ea0":"code","401d2ef2":"code","a737518f":"code","86d955fa":"code","15f96de6":"code","42889826":"code","8c2a2175":"code","c0ba6b24":"code","652bda3b":"code","88096045":"code","6e102f8f":"code","1ca4c801":"code","c08d9d0c":"code","f6efc89a":"code","f64044b7":"code","5b4a4838":"code","9a1b9f28":"code","67eaad8d":"code","839e00ab":"code","4a608489":"code","43c1bdd3":"code","a9b20d05":"code","3ca734d9":"code","25a871a6":"code","9f21edcf":"code","e013da2c":"markdown","22f6cfb8":"markdown","2c3e290e":"markdown","574338b4":"markdown","34a22954":"markdown","6a8be3af":"markdown","fd1f1f03":"markdown","e2dc3165":"markdown","b73ea397":"markdown"},"source":{"989952ac":"# !pip install -q -U pip\n!pip install -q cython\n# Install pycocotools, the version by default in Colab\n# has a bug fixed in https:\/\/github.com\/cocodataset\/cocoapi\/pull\/354\n!pip install -q -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n!pip install -q -U segmentation-models-pytorch\n# !pip install -q -U albumentations","8b2e8ea0":"import json\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.path as plt_path\n\nfrom PIL import Image\n\nfrom pathlib import Path\nfrom pycocotools.coco import COCO\n\nDATASET_PATH = Path('..\/input\/synthetic-word-ocr')\nimg_root_path = DATASET_PATH \/ 'train\/images'","401d2ef2":"import albumentations as albu\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, Lambda\n    )\nfrom albumentations.pytorch import ToTensorV2","a737518f":"from sklearn.model_selection import train_test_split","86d955fa":"import segmentation_models_pytorch as smp","15f96de6":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.optim import Adam, SGD\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchvision.io import read_image\nimport torchvision.models as models\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","42889826":"print(torch.__version__)\nprint(torchvision.__version__)\nprint(albu.__version__)","8c2a2175":"anno_path = DATASET_PATH \/ 'annotation-small.json'\nwith open(DATASET_PATH \/ 'annotation-small.json', 'r') as f:\n    annot_data = json.load(f)","c0ba6b24":"coco_anno = COCO(str(anno_path))\ncat_ids = coco_anno.getCatIds()\ncats = coco_anno.loadCats(cat_ids)\nimg_ids = coco_anno.getImgIds(catIds=cat_ids)","652bda3b":"EPOCHS = 10\nBATCH_SIZE = 32","88096045":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\n# https:\/\/stackoverflow.com\/questions\/50805634\/how-to-create-mask-images-from-coco-dataset\ndef get_mask(coco, img_id, cat_ids):\n    img_inf = coco.loadImgs(img_id)[0]\n    img_shape = (img_inf['width'], img_inf['height'], len(cat_ids))\n    ann_ids = coco_anno.getAnnIds(imgIds=img_id,\n                                  catIds=cat_ids,\n                                  iscrowd=None)\n    anns = coco.loadAnns(ann_ids)\n#     masks = np.zeros((img_inf['height'],img_inf['width'], len(cat_ids)))\n#     for idx, cat_id in enumerate(cat_ids):\n#         mask = np.zeros((img_inf['height'],img_inf['width']))\n#         for ann in anns:\n#             if cat_id == ann['category_id']:\n# #                 mask = coco_anno.annToMask(ann)\n#                 mask = np.maximum(mask, coco_anno.annToMask(ann))\n#         masks[:, :, idx] = mask\n    masks = np.zeros(img_shape)\n    for idx, cat_id in enumerate(cat_ids):\n        mask = np.zeros(img_shape[:2])\n        for ann in anns:\n            if cat_id == ann['category_id']:\n                mask = np.maximum(mask, coco_anno.annToMask(ann))\n        masks[:, :, idx] = mask\n    return masks\n\n\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()\n    \n\nseed_torch()","6e102f8f":"def get_training_augmentation(width=320, height=320):\n    train_transform = [\n\n        albu.HorizontalFlip(p=0.5),\n\n        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n\n        albu.PadIfNeeded(min_height=height, min_width=width, always_apply=True, border_mode=0),\n        albu.RandomCrop(height=height, width=width, always_apply=True),\n\n        albu.IAAAdditiveGaussianNoise(p=0.2),\n        albu.IAAPerspective(p=0.5),\n\n        albu.OneOf(\n            [\n                albu.CLAHE(p=1),\n                albu.RandomBrightness(p=1),\n                albu.RandomGamma(p=1),\n            ],\n            p=0.9,\n        ),\n\n        albu.OneOf(\n            [\n                albu.IAASharpen(p=1),\n                albu.Blur(blur_limit=3, p=1),\n                albu.MotionBlur(blur_limit=3, p=1),\n            ],\n            p=0.9,\n        ),\n\n        albu.OneOf(\n            [\n                albu.RandomContrast(p=1),\n                albu.HueSaturationValue(p=1),\n            ],\n            p=0.9,\n        ),\n    ]\n    return albu.Compose(train_transform)\n\n\ndef get_validation_augmentation(width=320, height=320):\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [\n#         albu.PadIfNeeded(min_height=height, min_width=width)\n        albu.Resize(width, height)\n    ]\n    return albu.Compose(test_transform)\n\n\ndef get_transform(resize, phase='train'):\n    _transforms = []\n    _mean = [0.485, 0.456, 0.406]\n    _std = [0.229, 0.224, 0.225]\n    if phase == 'train':\n        _transforms.append(Resize(resize, resize))\n        _transforms.append(HorizontalFlip(p=0.5))\n        _transforms.append(VerticalFlip(p=0.5))\n#         for t in [\n#             RandomResizedCrop(resize, resize),\n#             Transpose(p=0.5),\n#             HorizontalFlip(p=0.5),\n#             VerticalFlip(p=0.5),\n#             ShiftScaleRotate(p=0.5)]:\n#             _transforms.append(t)\n        ,\n    else:\n        _transforms.append(Resize(resize, resize))\n    # \n    _transforms.append(Normalize(\n                mean=_mean,\n                std=_std,\n            ))\n    _transforms.append(ToTensorV2())\n    return Compose(_transforms)\n\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n\n    Args:\n        preprocessing_fn (callbale): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n\n    \"\"\"\n\n    _transform = [\n        Lambda(image=preprocessing_fn),\n        Lambda(image=to_tensor, mask=to_tensor)\n    ]\n    return Compose(_transform)\n\n\nclass SegDataset(Dataset):\n    def __init__(self, root_dir, img_ids, cat_ids, coco_api, transforms=None, preprocessing=None):\n        self.root_dir = root_dir\n        self.img_ids = img_ids\n        self.cat_ids = cat_ids\n        self.coco_api = coco_api\n        self.transforms = transforms\n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        img_inf = self.coco_api.loadImgs(img_id)[0]\n        file_name = img_inf['file_name']\n        file_path = self.root_dir \/ file_name\n        img = Image.open(file_path).convert('RGB')\n        mask = get_mask(self.coco_api, img_id, self.cat_ids)\n        \n        if self.transforms:\n            augmented = self.transforms(image=np.array(img), mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n\n        if self.preprocessing:\n            augmented = self.preprocessing(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n\n        return img, mask\n    \n    def __len__(self):\n        return len(self.img_ids)","1ca4c801":"train_img_ids, valid_img_ids = train_test_split(img_ids, test_size=0.1, random_state=42)\nvalid_img_ids, test_img_ids = train_test_split(valid_img_ids, test_size=0.5, random_state=42)\nprint(len(train_img_ids), len(valid_img_ids), len(test_img_ids))","c08d9d0c":"sample_dataset = SegDataset(root_dir=img_root_path,\n                           img_ids=train_img_ids,\n                           cat_ids=cat_ids,\n                           coco_api=coco_anno)\nimage, mask = sample_dataset[4] # get some sample\nvisualize(\n    image=image, \n    builing_mask=mask.squeeze(),\n)","f6efc89a":"augmented_dataset = SegDataset(root_dir=img_root_path,\n                               img_ids=train_img_ids,\n                               cat_ids=cat_ids,\n                               coco_api=coco_anno,\n                               transforms=get_transform(resize=300, phase='train'))\nfor i in range(3):\n    image, mask = augmented_dataset[4]\n    visualize(image=image.numpy().transpose(1, 2, 0), mask=mask.squeeze())","f64044b7":"ENCODER = 'resnet50'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['building']\nACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n\n# create segmentation model with pretrained encoder\nmodel = smp.Unet(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=len(CLASSES), \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","5b4a4838":"_preprocessing = get_preprocessing(preprocessing_fn)\n\ntrain_dataset = SegDataset(root_dir=img_root_path,\n                           img_ids=train_img_ids,\n                           cat_ids=cat_ids,\n                           coco_api=coco_anno,\n                           transforms=get_training_augmentation(288, 288),\n                           preprocessing=_preprocessing)\nvalid_dataset = SegDataset(root_dir=img_root_path,\n                           img_ids=valid_img_ids,\n                           cat_ids=cat_ids,\n                           coco_api=coco_anno,\n                           transforms=get_validation_augmentation(288, 288),\n                           preprocessing=_preprocessing)","9a1b9f28":"train_loader = DataLoader(train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          num_workers=4,\n                          pin_memory=True,\n                          drop_last=True)\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=False,\n                          num_workers=4,\n                          pin_memory=True,\n                          drop_last=True)","67eaad8d":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.0001),\n])","839e00ab":"train_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","4a608489":"max_score = 0\n\n\n#train accurascy, train loss, val_accuracy, val_loss \u3092\u30b0\u30e9\u30d5\u5316\u3067\u304d\u308b\u3088\u3046\u306b\u8a2d\u5b9a\uff0e\nx_epoch_data = []\ntrain_dice_loss = []\ntrain_iou_score = []\nvalid_dice_loss = []\nvalid_iou_score = []\n\nfor i in range(EPOCHS):\n\n    print(f'\\nEpoch: {i + 1}')\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n\n    x_epoch_data.append(i)\n    train_dice_loss.append(train_logs['dice_loss'])\n    train_iou_score.append(train_logs['iou_score'])\n    valid_dice_loss.append(valid_logs['dice_loss'])\n    valid_iou_score.append(valid_logs['iou_score'])\n\n    # do something (save model, change lr, etc.)\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(model, '.\/best_model_Unet_resnet50.pth')\n        print('Model saved!')\n\n    if i == 25:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')","43c1bdd3":"fig = plt.figure(figsize=(14, 5))\n\nax1 = fig.add_subplot(1, 2, 1)\nline1, = ax1.plot(x_epoch_data,train_dice_loss,label='train') \nline2, = ax1.plot(x_epoch_data,valid_dice_loss,label='validation')\nax1.set_title(\"dice loss\")\nax1.set_xlabel('epoch')\nax1.set_ylabel('dice_loss')\nax1.legend(loc='upper right')\n\nax2 = fig.add_subplot(1, 2, 2)\nline1, = ax2.plot(x_epoch_data,train_iou_score,label='train')\nline2, = ax2.plot(x_epoch_data,valid_iou_score,label='validation') \nax2.set_title(\"iou score\")\nax2.set_xlabel('epoch')\nax2.set_ylabel('iou_score')\nax2.legend(loc='upper left')\n\nplt.show()","a9b20d05":"best_model = torch.load('.\/best_model_Unet_resnet50.pth')","3ca734d9":"test_dataset = SegDataset(root_dir=img_root_path,\n                           img_ids=test_img_ids,\n                           cat_ids=cat_ids,\n                           coco_api=coco_anno,\n                           transforms=get_validation_augmentation(288, 288),\n                           preprocessing=_preprocessing)\ntest_dataloader = DataLoader(test_dataset)","25a871a6":"test_epoch = smp.utils.train.ValidEpoch(\n    model=best_model,\n    loss=loss,\n    metrics=metrics,\n    device=device,\n    verbose=True\n)\n\nlogs = test_epoch.run(test_dataloader)","9f21edcf":"for i in range(3):\n    n = np.random.choice(len(test_dataset))\n    image, gt_mask = test_dataset[n]\n\n    gt_mask = gt_mask.squeeze()\n\n    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n\n    visualize(\n        image=image.transpose(1, 2, 0), \n        ground_truth_mask=gt_mask, \n        predicted_mask=pr_mask\n    )","e013da2c":"# Load Libraries","22f6cfb8":"# PyTorch Functions","2c3e290e":"# Settings","574338b4":"# Traininig","34a22954":"# Util Functions","6a8be3af":"# Load Datasets","fd1f1f03":"# Reference\n- https:\/\/github.com\/qubvel\/segmentation_models.pytorch\/blob\/master\/examples\/cars%20segmentation%20(camvid).ipynb\n- https:\/\/qiita.com\/nigo1973\/items\/1d7495a963c23c97189c","e2dc3165":"# segmentation-models-pytorch","b73ea397":"# Install Libararies"}}