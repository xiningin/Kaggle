{"cell_type":{"4031e7ca":"code","60e15456":"code","d3951761":"code","9b56aed1":"code","ef468883":"code","7bdb3147":"code","43cd8e06":"code","5122e180":"code","4c429079":"code","cbe2f570":"code","dab95a20":"code","f4fdb588":"code","0847e918":"code","01b5c844":"code","a04ef4e0":"code","5a6bf87d":"code","43882380":"code","f8eb5441":"code","562d053c":"code","a5d7df70":"code","85f86a26":"code","79834a7c":"code","bed03220":"code","c34d235c":"code","6eb8e2fe":"code","e5f7342a":"code","3a619517":"code","7440d646":"code","697b0ba8":"code","22769ee3":"code","d65952b0":"code","ac571aa1":"code","f6e264cd":"code","542b0096":"code","3143f461":"code","d3212f31":"code","c8de4cec":"code","8d1e4c9c":"code","11299942":"code","38cc952d":"code","350553ad":"code","98fe251a":"code","6156862c":"markdown","62aa22bb":"markdown","4c3c05d6":"markdown","8fd9cf4f":"markdown","ed45ae3b":"markdown","6065d683":"markdown","ee84e966":"markdown","66643524":"markdown","540d5fda":"markdown","0d2f350d":"markdown","73fbe829":"markdown","4de08896":"markdown","cb4a4f31":"markdown","499231a3":"markdown","ddef1f47":"markdown","2524315d":"markdown","ffefe62c":"markdown","2db59891":"markdown","51c877ab":"markdown"},"source":{"4031e7ca":"!pip install pycaret --user","60e15456":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns","d3951761":"Date_Augmentation = True\nS = 12  #season","9b56aed1":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/train.csv\",index_col = 0)\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/test.csv\",index_col = 0)","ef468883":"train.head()","7bdb3147":"train.info()","43cd8e06":"display(train.isnull().sum())\ndisplay(train.duplicated().sum())","5122e180":"print(\"Max train date:\" ,train[\"date\"].max())\nprint(\"Min train date:\" ,train[\"date\"].min())\n\nprint(\"Max test date:\" ,test[\"date\"].max())\nprint(\"Min test date:\" ,test[\"date\"].min())","4c429079":"train[\"date\"] = pd.to_datetime(train[\"date\"])\ntest[\"date\"] = pd.to_datetime(test[\"date\"])","cbe2f570":"sns.set_theme(style =\"whitegrid\")\npalette = {\"Sweden\":\"c\",\"Norway\":\"red\",\"Finland\":\"y\"}","dab95a20":"fig,ax = plt.subplots(3,2, figsize=(20,10),sharey= True)\n\nax[0,0].set_title(\"Train Country Distribution\")\nsns.countplot(ax=ax[0,0], x =train[\"country\"])\nax[0,1].set_title(\"Test Country Distribution\")\nsns.countplot(ax=ax[0,1], x= test[\"country\"])\n\nax[1,0].set_title(\"Train Store Distribution\")\nsns.countplot(ax=ax[1,0], x =train[\"store\"])\nax[1,1].set_title(\"Test Store Distribution\")\nsns.countplot(ax=ax[1,1], x= test[\"store\"])\n\nax[2,0].set_title(\"Train Product Distribution\")\nsns.countplot(ax=ax[2,0], x =train[\"product\"])\nax[2,1].set_title(\"Test Product Distribution\")\nsns.countplot(ax=ax[2,1], x= test[\"product\"])\n\nfig.suptitle(\"Distributions\")\nplt.tight_layout()\nplt.show()","f4fdb588":"plt.figure(figsize=(25,10))\nsns.lineplot(data= train, x=\"date\",y=\"num_sold\")\nplt.title(\"Total Sales\")\n\n#X axis as months\nlocator = mdates.MonthLocator()  # every month\nfmt = mdates.DateFormatter('%b')\nX = plt.gca().xaxis\nX.set_major_locator(locator)\n# Specify formatter\nX.set_major_formatter(fmt)\nplt.show()","0847e918":"plt.figure(figsize=(25,10))\nsns.lineplot(data= train[ (train[\"date\"]>=\"2015-01-01\") & (train[\"date\"]<\"2016-01-01\") ], x=\"date\",y=\"num_sold\",)\nsns.lineplot(data= train[ (train[\"date\"]>=\"2016-01-01\") & (train[\"date\"]<\"2017-01-01\") ], x=\"date\",y=\"num_sold\")\nplt.title(\"2015\/ 2016 Sales closer look \")\n\n#X axis as months\nlocator = mdates.MonthLocator()  # every month\nfmt = mdates.DateFormatter('%b')\nX = plt.gca().xaxis\nX.set_major_locator(locator)\n# Specify formatter\nX.set_major_formatter(fmt)\nplt.show()","01b5c844":"plt.figure(figsize=(25,10))\nsns.lineplot(data= train, x=\"date\",y=\"num_sold\", hue=\"country\", palette = palette,ci=None)\nplt.title(\"Sales by Country\")\n\n#X axis as months\nlocator = mdates.MonthLocator()  # every month\nfmt = mdates.DateFormatter('%b')\nX = plt.gca().xaxis\nX.set_major_locator(locator)\n# Specify formatter\nX.set_major_formatter(fmt)\nplt.show()","a04ef4e0":"plt.figure(figsize=(25,10))\nsns.lineplot(data= train, x=\"date\",y=\"num_sold\", hue=\"product\",ci=None)\nplt.title(\"Product Sales\")\n\n#X axis as months\nlocator = mdates.MonthLocator()  # every month\nfmt = mdates.DateFormatter('%b')\nX = plt.gca().xaxis\nX.set_major_locator(locator)\n# Specify formatter\nX.set_major_formatter(fmt)\nplt.show()","5a6bf87d":"if Date_Augmentation:\n    print(\"Running augementation on date field\")\n    \n    train[\"day\"] = train[\"date\"].dt.day\n    train[\"dayofweek\"] = train[\"date\"].dt.dayofweek\n    train[\"month\"] = train[\"date\"].dt.month\n    train[\"year\"] = train[\"date\"].dt.year\n    \n    test[\"day\"] = test[\"date\"].dt.day\n    test[\"dayofweek\"] = test[\"date\"].dt.dayofweek\n    test[\"month\"] = test[\"date\"].dt.month\n    test[\"year\"] = test[\"date\"].dt.year","43882380":"fig,ax = plt.subplots(4,1, figsize=(25,20),sharey= True)\n\nax[0].set_title(\"Day-of-Month Sales\")\nsns.lineplot(ax=ax[0], data= train, x=\"day\",y=\"num_sold\")\n\nax[1].set_title(\"Day-of-week Sales\")\nsns.lineplot(ax=ax[1], data= train, x=train[\"dayofweek\"]+1,y=\"num_sold\")\n             \nax[2].set_title(\"Month Sales\")\nsns.lineplot(ax=ax[2], data= train, x=\"month\",y=\"num_sold\")\n\nax[3].set_title(\"Year Sales\")\nsns.lineplot(ax=ax[3], data= train, x=\"year\",y=\"num_sold\")\n\nplt.tight_layout()\nplt.show()","f8eb5441":"fig,ax = plt.subplots(4,1, figsize=(25,20),sharey= True)\n\nfig.suptitle(\"Products View\",ha = \"left\")\nax[0].set_title(\"Day-of-Month Sales\")\nsns.lineplot(ax=ax[0], data= train, x=\"day\",y=\"num_sold\",ci=None, hue=\"product\")\n\nax[1].set_title(\"Day-of-week Sales\")\nsns.lineplot(ax=ax[1], data= train, x=train[\"dayofweek\"]+1,y=\"num_sold\",ci=None,hue=\"product\")\n             \nax[2].set_title(\"Month Sales\")\nsns.lineplot(ax=ax[2], data= train, x=\"month\",y=\"num_sold\",ci=None,hue=\"product\")\n\nax[3].set_title(\"Year Sales\")\nsns.lineplot(ax=ax[3], data= train, x=\"year\",y=\"num_sold\",ci=None,hue=\"product\")\n\nplt.tight_layout()\nplt.show()","562d053c":"train.head()","a5d7df70":"#train.index = train[\"date\"]\n#train.drop(\"date\",axis=1,inplace=True)\n#train.head()","85f86a26":"\"\"\"from statsmodels.tsa.stattools import adfuller\nadf, pvalue, usedlag_, nobs_, critical_values_, icbest_ = adfuller(train)\"\"\"","79834a7c":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","bed03220":"KaggleHat= train[train[\"product\"] ==\"Kaggle Hat\"]\nKaggleMart= train[train[\"store\"] ==\"KaggleMart\"]\nNorway= train[train[\"country\"] ==\"Norway\"]\nSweden= train[train[\"country\"] ==\"Sweden\"]\nFinland= train[train[\"country\"] ==\"Finland\"]","c34d235c":"fig, ax = plt.subplots(2,1, figsize=(25,10))\nfig = plot_acf(Norway[\"num_sold\"],  ax=ax[0],title='ACF Norway',lags = 150)\nfig = plot_pacf(Norway[\"num_sold\"],  ax=ax[1],title='PCF Norway',lags = 20)\nplt.show()","6eb8e2fe":"fig, ax = plt.subplots(2,1, figsize=(25,10))\nfig = plot_acf(KaggleMart[\"num_sold\"],  ax=ax[0],title='ACF KaggleMart',lags = 150)\nfig = plot_pacf(KaggleMart[\"num_sold\"],  ax=ax[1],title='PCF KaggleMart',lags = 20)\nplt.show()","e5f7342a":"fig, ax = plt.subplots(2,1, figsize=(25,10))\nfig = plot_acf(KaggleHat[\"num_sold\"],  ax=ax[0],title='ACF KaggleHat',lags = 150)\nfig = plot_pacf(KaggleHat[\"num_sold\"],  ax=ax[1],title='PCF KaggleHat',lags = 20)\nplt.show()","3a619517":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","7440d646":"from pycaret.regression import *\nreg1 = setup(train, target = 'num_sold', session_id=123, log_experiment=True, experiment_name='tps jan 2022',silent=True)","697b0ba8":"best_model = compare_models(fold=5,sort = 'MAPE')","22769ee3":"add_metric(id=\"SMAPE_metric\", name=\"SMAPE\", score_func=SMAPE ,greater_is_better=False)","d65952b0":"lightgbm = create_model('lightgbm')\ntuned_lightgbm = tune_model(lightgbm, n_iter=100, custom_scorer = \"SMAPE_metric\",optimize=\"SMAPE_metric\")","ac571aa1":"tuned_lightgbm","f6e264cd":"interpret_model(tuned_lightgbm)","542b0096":"plot_model(tuned_lightgbm, plot='feature')","3143f461":"#training\npreds_train =  predict_model(tuned_lightgbm, train)","d3212f31":"#Test prediction\npreds_test = predict_model(tuned_lightgbm, test)","c8de4cec":"#preds_test[\"date\"] = test[\"date\"]\npreds_train[\"date\"] =train[\"date\"] ","8d1e4c9c":"preds_train.head()","11299942":"plt.figure(figsize=(25,10))\n\nsns.lineplot(data= train.reset_index(), x=\"date\",y=\"num_sold\", label=\"Train Actual\")\nsns.lineplot(data =preds_train.reset_index(),x = \"date\" , y = \"Label\", label=\"Train Prediction\" ) \nsns.lineplot(data = preds_test.reset_index(),x = \"date\" , y = \"Label\", label =\"Test Prediction\" )\nplt.title(\"Actual and Predicted Sales\")","38cc952d":"sub = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv\",index_col = 0)","350553ad":"sub[\"num_sold\"] = preds_test[\"Label\"]\nsub.to_csv(\"submission.csv\")","98fe251a":"sub.head()","6156862c":"## Day, week , month analysis","62aa22bb":"**Notes** Definite Seasonality;\n* Huge spikes end Dec \/ beginning Jan  -- Christmas\/ Holiday season \n* Spikes in April - Easter?\n* Slight spikes in May and June \n* Decline in sales fro jul to oct - with a steady rise leading up to Dec\n\n==> Investigate seasonality **Seasonal ARIMA Model**?","4c3c05d6":"**Note**: \nFrom the above the predicted Seasonality seems good but the value increase wasn't as pronounced as the actual historical values. \\\nThe model seems to try keep the data Stationary ","8fd9cf4f":"# EDA ","ed45ae3b":"## Visualization of data ","6065d683":"### Plot Predictions with Training data","ee84e966":"**Notes** Disimilar products \n* products dont seem to have any consistent relationship other than following the seasonality \n* Actual seasons could impact product sales (summer, winter etc)\n * Hats sales drop after Jun (getting colder?)\n * Mug sales increase after Jun (getting colder - more hot drinks?)\n * stickers dont follow seasons \n\n=> Extract Season type? or temperate? \\\n=> use 3 seperate models for products?","66643524":"# Load libraries and data ","540d5fda":"# Initial Thoughts \nIn this notebook I go through a few visuals trying to understand the data better \\\nAfter each set of visuals I have my intial thoughts on how to process \/ predict the data in another kernel\n\n\n**Note** this is a work in progress \n\n### To do\n1. Decomposition analysis - seasonality, trend, residuals ","0d2f350d":"## SMAPE code","73fbe829":"**Notes**\n* More sales on Saturday and Sunday \n* More Mug sales on April and all sales in Dec\/Jan","4de08896":"# Submissions \nAlthough this isnt a complete notebook for preduction scoring we will submit ot get a baseline ","cb4a4f31":"# Pycaret Baseline Testing","499231a3":"## AR and MA check ","ddef1f47":"## Augmented Dickey\u2013Fuller ---Stationarity test\nCheck to if the data is stationary \\\nStationary indicates that there isnt any variance of the data accross seasons - i,e, we wouldnt need a model for predictions as the data repeats itself perfectly\n- null hypothesis = p>0.05  ==> data is stationary ","2524315d":"# Predictions and scoring","ffefe62c":"## Feature importance","2db59891":"**Notes**\n* Similar pattern\/trend for each country however different volumes \n* Will seperate models be required for each country if countries have such similar patterns \n\n=> use 1 model for Countries?","51c877ab":"Baseline Lightgbm Model\nWith custom SMAPE scoring"}}