{"cell_type":{"fb334e0f":"code","7b89f282":"code","a9ee86d3":"code","cd204c8a":"code","269ad142":"code","ef61206a":"code","dcce1003":"code","907b835f":"code","89014126":"code","8071a8b2":"code","54d4b62a":"code","e34f79e8":"code","dd67a595":"code","3236daca":"code","79003e85":"code","e5cd958a":"code","080d06a6":"code","6d86398d":"code","620d57f7":"code","ebb28f9a":"code","bc47c9ed":"code","05bf687b":"code","8836f768":"code","1e9e945e":"code","15c780ca":"code","c553a2de":"code","02c7a604":"code","dcc835f5":"code","92c5e780":"code","c85b7b69":"markdown","d11b6d23":"markdown","1b6c80c9":"markdown","af723c85":"markdown","569af8b7":"markdown","6de6fc7b":"markdown","44b70dd2":"markdown","ee90e293":"markdown","757fa373":"markdown","9337129c":"markdown","2faa1c95":"markdown","ea5f0d51":"markdown","ee77c47d":"markdown","2a3edace":"markdown","8ec481f5":"markdown","31ed6db1":"markdown","590d264d":"markdown"},"source":{"fb334e0f":"!pip install wandb -q","7b89f282":"import tensorflow as tf\nprint(tf.__version__)\n\nimport os\nimport cv2\nimport json\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom functools import partial","a9ee86d3":"import wandb\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\nwandb.login(key=wandb_api)","cd204c8a":"train_csv_2020 = '..\/input\/cassava-leaf-disease-classification\/train.csv'\ntrain_img_paths_2020 = '..\/input\/cassava-leaf-disease-classification\/train_images\/'\n\ntrain_2020_df = pd.read_csv(train_csv_2020)\ntrain_2020_df.head()","269ad142":"# change image_id to path_to_image_id for ease. \ntrain_2020_df['image_id'] = train_img_paths_2020 + train_2020_df['image_id'].astype(str)\ntrain_2020_df.to_csv('raw_2020_train.csv', index=False)\n\ntrain_2020_df.head()","ef61206a":"run = wandb.init(entity='ayush-thakur', project='cassava', job_type='dataset_creation')\nartifact = wandb.Artifact('raw_2020', type='dataset')\nartifact.add_file('raw_2020_train.csv')\nrun.log_artifact(artifact)\nrun.join()","dcce1003":"# Function to plot the distribution of the dataset.\ndef show_label_distribution(label_count):\n    fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n    ax = sns.countplot(y=label_count, palette='viridis')\n    ax.tick_params(labelsize=16)\n    \nshow_label_distribution(train_2020_df['label'].values)","907b835f":"train_image_names_2020 = os.listdir(train_img_paths_2020)\nprint('Sample Image Name: ', train_image_names_2020[0])\nprint('Total number of train images in 2020 challenege: ', len(train_image_names_2020))","89014126":"train_images_2019 = '..\/input\/cassavachallenge\/old_competition\/train\/'\n\ntrain_label_dirs_2019 = os.listdir(train_images_2019)\nprint(train_label_dirs_2019)","8071a8b2":"label_map = '..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json'\n\nwith open(label_map) as json_file: \n    data = json.load(json_file) \nprint(f'Label Map: {data}')\n    \nlabel_dict = {}\nfor key, val in data.items():\n    if 'CBB' in val:\n        label_dict['cbb'] = int(key)\n    elif 'CBSD' in val:\n        label_dict['cbsd'] = int(key)\n    elif 'CGM' in val:\n        label_dict['cgm'] = int(key)\n    elif 'CMD' in val:\n        label_dict['cmd'] = int(key)\n    else:\n        label_dict['healthy'] = int(key)\n        \nprint(f'\\nRestructured label map to: {label_dict}')","54d4b62a":"train_image_names_2019 = []\ntrain_2019_labels = []\n\nfor dir_name in train_label_dirs_2019:\n    # get image names within the dir_name\n    image_names = os.listdir(train_images_2019+dir_name)\n    image_names = [train_images_2019+dir_name+'\/'+img_name for img_name in image_names]\n    train_image_names_2019.extend(image_names)\n    \n    # get label \n    label_name = image_names[0].split('-')[1]\n    labels = np.full((len(image_names),), label_dict[label_name])\n    train_2019_labels.extend(labels)","e34f79e8":"print(f'Total number of train image names: {len(train_image_names_2019)} and labels: {len(train_2019_labels)}')","dd67a595":"# create dataframe\ntrain_2019_df = pd.DataFrame(list(zip(train_image_names_2019, train_2019_labels)),\n                            columns=['image_id', 'label'])\ntrain_2020_df.to_csv('raw_2019_train.csv', index=False)\n\ntrain_2019_df.head()","3236daca":"run = wandb.init(entity='ayush-thakur', project='cassava', job_type='dataset_creation')\nartifact = wandb.Artifact('raw_2019', type='dataset')\nartifact.add_file('raw_2019_train.csv')\nrun.log_artifact(artifact)\nrun.join()","79003e85":"show_label_distribution(train_2019_df['label'].values)","e5cd958a":"train_df = pd.concat([train_2020_df, train_2019_df]).sample(frac=1).reset_index(drop=True)\ntrain_df.to_csv('cassava_2019_2020.csv', index=False)\n\ntrain_df.head()","080d06a6":"run = wandb.init(entity='ayush-thakur', project='cassava', job_type='dataset_merge')\n\nartifact_2019 = run.use_artifact('ayush-thakur\/cassava\/raw_2019:v0', type='dataset')\nartifact_2020 = run.use_artifact('ayush-thakur\/cassava\/raw_2020:v0', type='dataset')\n\nartifact_merge = wandb.Artifact('cassava_2019_2020', type='dataset')\n\nartifact_merge.add_file('cassava_2019_2020.csv')\nrun.log_artifact(artifact_merge)\nrun.join()","6d86398d":"show_label_distribution(train_df['label'].values)","620d57f7":"skf = StratifiedKFold(n_splits=16, shuffle=True)\n\ndf_images = train_df['image_id']\ndf_labels = train_df['label']","ebb28f9a":"os.makedirs('folds', exist_ok=True)\n\nfor fold, (train_index, val_index) in enumerate(skf.split(df_images,df_labels)):\n    print(f'Fold Number: {fold} has {len(val_index)} samples')\n    \n    df_images_tmp, df_labels_tmp = df_images[val_index], df_labels[val_index]\n    df_tmp = pd.concat([df_images_tmp, df_labels_tmp], axis=1)\n    \n    df_tmp.to_csv(f'folds\/fold_{fold}.csv', index=False)\n    \n    fig, ax = plt.subplots(1, 1, figsize=(18, 8))\n    fig.suptitle(f'File {fold+1}', fontsize=22)\n    ax = sns.countplot(y=df_tmp['label'].values, palette='viridis')\n    ax.tick_params(labelsize=16)","bc47c9ed":"run = wandb.init(entity='ayush-thakur', project='cassava', job_type='dataset_split')\n\nartifact_merge = run.use_artifact('ayush-thakur\/cassava\/cassava_2019_2020:v0', type='dataset')\n\nartifact_fold = wandb.Artifact('cassava_folds', type='dataset')\nartifact_fold.add_dir('folds')\nrun.log_artifact(artifact_fold)\n\nrun.join()","05bf687b":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","8836f768":"def serialize_example(feature0, feature1):\n  feature = {\n      'image': _bytes_feature(feature0),\n      'label': _int64_feature(feature1)\n  }\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()","1e9e945e":"def TFRecordWriter(count, CSV_FILE_PATH, DEST_PATH):\n    # read csv and extract image paths and labels\n    df = pd.read_csv(CSV_FILE_PATH)\n    IMG_PATHS = df['image_id'].values\n    LABELS = df['label'].values\n    SIZE = len(IMG_PATHS)\n\n    # make destination dir\n    os.makedirs(DEST_PATH, exist_ok=True)\n\n    with tf.io.TFRecordWriter(DEST_PATH+'train%.2i-%i.tfrec'%(count,SIZE)) as writer:\n        for j in range(SIZE):\n            # get image\n            img = cv2.imread(IMG_PATHS[j])\n#             img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n\n            # get label\n            label = LABELS[j]\n\n            # get TFRecord example\n            example = serialize_example(img, label)\n\n            writer.write(example)\n\n            if j%100==0: \n                print(j,', ',end='')","15c780ca":"FOLDS_PATH = '.\/folds\/'\nCSV_FILES = os.listdir(FOLDS_PATH)\n\nos.makedirs('tfrecords\/', exist_ok=True)\n\nfor count, csv_file in enumerate(CSV_FILES):\n    print(f'Creating TFRecords for: {csv_file}\\n')\n    \n    TFRecordWriter(count,\n                   FOLDS_PATH+csv_file,\n                  'tfrecords\/')\n    print('\\n')","c553a2de":"run = wandb.init(entity='ayush-thakur', project='cassava', job_type='dataset_tfrecord')\n\nartifact_folds = run.use_artifact('ayush-thakur\/cassava\/cassava_folds:v0', type='dataset')\n\nartifact_tfrecord = wandb.Artifact('cassava_tfrecord', type='dataset')\nartifact_tfrecord.add_dir('tfrecords')\nrun.log_artifact(artifact_tfrecord)\n\nrun.join()","02c7a604":"# Decode image from TFRecord file.\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, [512, 512])\n    return image\n\n# Read the TFRecord file.\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    label = tf.cast(example['label'], tf.int32)\n    \n    return image, label\n\n# Return tf.data dataset\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset","dcc835f5":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(20,20))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.axis('off')","92c5e780":"TFRECORDS = np.array(tf.io.gfile.glob('.\/tfrecords\/train*.tfrec'))     \nloader = load_dataset(TFRECORDS[0]).batch(32)\n\nimage_batch, label_batch = next(iter(loader))\nshow_batch(image_batch, label_batch)","c85b7b69":"# \u26a1 Stratified K-Fold Split\n\nStratified K-Fold ensures that every split will have similar data distribution which is crucial from an imbalanced dataset point of view.\n\nNote: We are going to use K=16. Each split will be converted to `TFRecord`. If we use cross validation training, train and validation split will have same data distribution which is crucial for accurate evaluation of model performance. ","d11b6d23":"## II. Cassava 2019 Dataset","1b6c80c9":"### Save as W&B Artifact for dataset versioning","af723c85":"### Save as W&B Artifact for dataset versioning","569af8b7":"# Visualize For Sanity Check","6de6fc7b":"# \u26c4 Prepare Dataset","44b70dd2":"## Generate TFRecords","ee90e293":"# \u2744\ufe0f Imports and Setups","757fa373":"We will use this dataset to train an image classifier. I will be using this [training kernel](https:\/\/www.kaggle.com\/ayuraj\/efficientnet-mixup-k-fold-using-tf-and-wandb). \n\nThe final preview of the graph view of the dataset versioning.\n\n![Screenshot%20%2842%29.png](attachment:Screenshot%20%2842%29.png)\n\n# Use the TFRecord Dataset\n\nIn order to use the dataset created use this code snippet:\n\n```\nimport wandb\nrun = wandb.init()\nartifact = run.use_artifact('ayush-thakur\/cassava\/cassava_tfrecord:v0', type='dataset')\nartifact_dir = artifact.download()\n```\n\nThe [training notebook](https:\/\/www.kaggle.com\/ayuraj\/efficientnet-mixup-k-fold-using-tf-and-wandb) will showcase the use W&B artifacts to download the dataset and train the model. ","9337129c":"You can visit the W&B project page and click on the Artifact's icon. It's situated at the left hand panel. \n\nHere's a preview of the graph view of the dataset versioning. \n\n* The square box is the job type(dataset creation, train, evaluate, etc).\n* The round circle is the stored artifact. It can be dataset, model files, results, etc. \n\n## The Story So Far..\n\n* We created two artifacts - `raw_2019` and `raw_2020` using two different jobs called `dataset_creation`.\n* We merged both the dataset during job - `dataset_merge`. The resulting artifact is `cassava_2019_2020`.\n* We then did Stratified K-Fold split(K=16) during job - `dataset_split`. The resulting artifact is `cassava_folds`.\n\nAt this point each artifact is storing `csv` files. And they can be downloaded to ensure reproducibility using the code snippet which you can find in the **API** tab as shown in the image below. \n\n\n![image.png](attachment:image.png)\n\n\nNow we will use these folds and convert them to TFRecord files of different sizes. We will again rely on artifacts for version control and monitoring.","2faa1c95":"### Save as W&B Artifact for dataset versioning","ea5f0d51":"## III. Cassava 2019+2020","ee77c47d":"### Save as W&B Artifact for dataset versioning","2a3edace":"# \ud83d\udca5 Includes\n\nThis kernel builds TFRecord dataset to be used for Cassava Leaf Disease Classification Challenege. This dataset can be used for cross validation training pipeline for image classification. \n\nI have used Weights and Biases to show Dataset version control with [Weights and Biases](https:\/\/wandb.ai\/site).\n\n* Uses Datset from Cassava Leaf Disease Classification Challenge 2019.\n* Stratified K-Fold train and validation split. (Here K=5)\n* Uses Weights and Biases for dataset version control.\n* TFRecords for each fold.\n\n### \ud83d\udc24 Quick introduction on Weights and Biases Artifacts\n\nYou can use W&B Artifacts to store and keep track of datasets, models, and evaluation results across machine learning pipelines. Think of an artifact as a versioned folder of data. You can store entire datasets directly in artifacts, or use artifact references to point to data in other systems.\n\nIn this notebook, we will create a [Stratified K-Fold](https:\/\/machinelearningmastery.com\/cross-validation-for-imbalanced-classification\/) train and validation split to train image classifiers. Since we are modifying and creating new `csv` files(containing `image_id` and `label`) it's important to incorporate dataset version control in the dataset creating pipeline. This is particularly useful for competitions like these where .5% improvement in score can win you a gold medal. \n\nLearn more about W&B artifacts [here](https:\/\/docs.wandb.ai\/artifacts). Check out this [YouTube tutorial](https:\/\/www.youtube.com\/watch?v=Hd94gatGMic&list=PLD80i8An1OEGajeVo15ohAQYF1Ttle0lk&index=3) as well.\n\n### \ud83d\udc40 Note\n\nThis kernel is producing TFRecords with each `.tfrec` file containing similar data distribution. Hence it can be used for Stratified K-Fold training. \n\nIf you want to use the dataset, use this code snippet:\n\n```\nimport wandb\nrun = wandb.init()\nartifact = run.use_artifact('ayush-thakur\/cassava\/cassava_tfrecord:v0', type='dataset')\nartifact_dir = artifact.download()\n```\n\nThe [training notebook](https:\/\/www.kaggle.com\/ayuraj\/efficientnet-mixup-k-fold-using-tf-and-wandb) will showcase the use W&B artifacts to download the dataset and train the model. ","8ec481f5":"# \ud83c\udf0a Write TFRecords","31ed6db1":"## Utils","590d264d":"## I. Cassava 2020 Dataset"}}