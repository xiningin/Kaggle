{"cell_type":{"585b3887":"code","2bd89465":"code","47f41932":"code","2a2bc6b6":"code","56721dbc":"code","2e14f140":"code","ac3ac702":"code","d756e679":"code","a9ca55ff":"code","7cd583fd":"code","142eda0b":"code","617253d6":"code","eecb7ee6":"code","1bffdf94":"code","25cbaa7e":"code","b0b49e55":"code","78489fb7":"code","bba8d52d":"code","817b2432":"code","7577fa18":"code","4bdb1f07":"code","4e189d14":"code","3ef2fbe3":"code","8ea959d5":"code","9828758b":"code","99d53a2a":"code","ef3ac267":"code","814829fd":"code","1064e1cd":"code","1f0c406b":"code","c53bd5a9":"code","8c3ec3c0":"code","f9adf83e":"code","2e70fb1c":"code","7ee124d7":"markdown"},"source":{"585b3887":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","2bd89465":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","47f41932":"df.columns","2a2bc6b6":"df.head()","56721dbc":"df.describe()","2e14f140":"df.shape","ac3ac702":"df.isnull().values.any()","d756e679":"df.hist(figsize=(20,20))\n#before preprocessing","a9ca55ff":"df.groupby('Outcome').size()","7cd583fd":"sns.countplot(x='Outcome', data=df)","142eda0b":"df.plot(kind='box', figsize=(20,10))\nplt.show()","617253d6":"df = df[df['SkinThickness'] < 80]\ndf = df[df['Insulin'] <= 600]\ndf.shape","eecb7ee6":"corrmat = df.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(corrmat, annot=True, cmap='coolwarm')","1bffdf94":"df.corr()","25cbaa7e":"print(\"total number of rows : {0}\".format(len(df)))\nprint(\"number of missing pregnancies: {0}\".format(len(df.loc[df['Pregnancies'] == 0])))\nprint(\"number of missing glucose: {0}\".format(len(df.loc[df['Glucose'] == 0])))\nprint(\"number of missing bp: {0}\".format(len(df.loc[df['BloodPressure'] == 0])))\nprint(\"number of missing skinthickness: {0}\".format(len(df.loc[df['SkinThickness'] == 0])))\nprint(\"number of missing insulin: {0}\".format(len(df.loc[df['Insulin'] == 0])))\nprint(\"number of missing bmi: {0}\".format(len(df.loc[df['BMI'] == 0])))\nprint(\"number of missing diabetespedigree: {0}\".format(len(df.loc[df['DiabetesPedigreeFunction'] == 0])))\nprint(\"number of missing age: {0}\".format(len(df.loc[df['Age'] == 0])))","b0b49e55":"df.loc[df['Insulin'] == 0, 'Insulin'] = df['Insulin'].mean() \ndf.loc[df['Glucose'] == 0, 'Glucose'] = df['Glucose'].mean() \ndf.loc[df['BMI'] == 0, 'BMI'] = df['BMI'].mean() \ndf.loc[df['BloodPressure'] == 0, 'BloodPressure'] = df['BloodPressure'].mean() \ndf.loc[df['SkinThickness'] == 0, 'SkinThickness'] = df['SkinThickness'].mean() ","78489fb7":"df.head()","bba8d52d":"sns.pairplot(df, hue='Outcome')","817b2432":"df.hist(figsize=(20,20))\n#after preprocessing","7577fa18":"df = df\/df.max()\ndf.head()","4bdb1f07":"X = df.iloc[:,0:-1]\ny = df.iloc[:,-1]\nX.head(10)\n#y.head()","4e189d14":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","3ef2fbe3":"l=[]","8ea959d5":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nclassifier = SVC(kernel = 'linear', random_state = 42)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('SVM:', acc * 100)\nl.append(acc)","9828758b":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, cmap='YlGnBu')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","99d53a2a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Logistic Regression:', acc * 100)\nl.append(acc)","ef3ac267":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, cmap='YlGnBu')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","814829fd":"from sklearn.metrics import classification_report as cr\nprint(cr(y_test, y_pred))","1064e1cd":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Decision Tree:', acc * 100)\nl.append(acc)","1f0c406b":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Naive Bayes:', acc * 100)\nl.append(acc)","c53bd5a9":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Random Forest:',acc * 100)\nl.append(acc)","8c3ec3c0":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Knn:',acc * 100)\nl.append(acc)","f9adf83e":"l","2e70fb1c":"y_axis=['Support Vector Classifier',\n      'Logistic Regression',\n      'Decision Tree Classifier',\n       'Gaussian Naive Bayes',\n      'Random Forest Classifier',\n      'K-Neighbors Classifier']\nx_axis=l\nsns.barplot(x=x_axis,y=y_axis)\nplt.xlabel('Accuracy')","7ee124d7":"Logistic Regression shows the best accuracy (82.35 %)"}}