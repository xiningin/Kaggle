{"cell_type":{"3fd4927f":"code","f4ed2930":"code","ee944789":"code","cf7b12e5":"code","90ffd37f":"code","9794ddf5":"code","c812a18a":"code","13702d5f":"code","8caca71a":"code","0a1fec2b":"code","388e9aa4":"code","a128e68d":"code","af525b9c":"code","364b7b8f":"code","887408bb":"code","a1e019f9":"markdown","77109834":"markdown","f9077ffb":"markdown"},"source":{"3fd4927f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\n","f4ed2930":"df = pd.read_csv('..\/input\/winequality-red.csv')","ee944789":"df.head()","cf7b12e5":"df.describe()","90ffd37f":"correlations = df.corr()['quality'].drop('quality')\nprint(correlations)","9794ddf5":"_ = correlations.plot(kind='bar')","c812a18a":"import seaborn as sns\nsns.heatmap(df.corr())","13702d5f":"train = df.sample(frac=0.8)\ntest_and_validation = df.loc[~df.index.isin(train.index)]\nvalidation = test_and_validation.sample(frac=0.5)\ntest = test_and_validation.loc[~test_and_validation.index.isin(validation.index)]\n\nprint(train.shape, validation.shape, test.shape)","8caca71a":"def get_features(correlation_threshold):\n    abs_corrs = correlations.abs()\n    high_correlations = abs_corrs[abs_corrs > correlation_threshold].index.values.tolist()\n    return high_correlations","0a1fec2b":"def compare_predictions(predicted, test_df, target_col):\n    # Since we have to predict integer values, and the regressor will return float, let's round predicted dataframe\n    predicted = predicted.round(0)\n    check_df = pd.DataFrame(data=predicted, index=test_df.index, columns=[\"Predicted \"+target_col])\n    check_df = pd.concat([check_df, test_df[[target_col]]], axis=1)\n    check_df[\"Error, %\"] = np.abs(check_df[\"Predicted \"+target_col]*100\/check_df[target_col] - 100)\n    check_df['Error, val'] = check_df[\"Predicted \"+target_col] - check_df[target_col]\n    return (check_df.sort_index(), check_df[\"Error, %\"].mean())","388e9aa4":"def evaluate_predictions(model, train_df, test_df, features, target_col):\n    train_pred = model.predict(train_df[features])\n    train_rmse = mean_squared_error(train_pred, train_df[target_col]) ** 0.5\n\n    test_pred = model.predict(test_df[features])\n    test_rmse = mean_squared_error(test_pred, test_df[target_col]) ** 0.5\n\n    print(\"RMSEs:\")\n    print(train_rmse, test_rmse)\n    \n    return test_pred","a128e68d":"def lr_model_evaluation(feature_correlation_threshold=0):\n    lr = LinearRegression()\n    features = get_features(feature_correlation_threshold)\n    lr.fit(train[features], train['quality'])\n    lr_validation_predictions = evaluate_predictions(lr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(lr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df","af525b9c":"check = lr_model_evaluation()","364b7b8f":"thresholds = [x * 0.05 for x in range(1, 8)] #threshold will scale up to 0.4\n\nfor thr in thresholds:\n    print('For threshold =', thr)\n    _ = lr_model_evaluation(thr)\n    print()","887408bb":"print(get_features(0.15))","a1e019f9":"# Linear regression approach","77109834":"Let's try different feature selection thresholds in hopes for better results","f9077ffb":"The best result so far was achieved with feature selection threshold of 0.15, but improvement was not too impressive."}}