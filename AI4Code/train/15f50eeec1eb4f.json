{"cell_type":{"0b8a7b43":"code","642effe1":"code","863e92a5":"code","ca98c35c":"code","6c8d36c6":"code","f50ba0c2":"code","960d09da":"code","ab6d0fd2":"code","a123a944":"code","59a2b24f":"code","b95b1bcc":"code","a93c3d3c":"code","e7e811ee":"code","5b8f5355":"code","bee6d7b6":"code","06ffb225":"code","3733e2f1":"code","51776249":"code","7e16e757":"code","8a472a96":"code","7434371e":"code","0200be79":"code","a768ea0f":"code","00d261e6":"code","d0fb0f74":"code","5f6abc44":"code","ebda1913":"code","4aae5952":"code","beec6f3e":"code","b8c13925":"code","d6cc7e8c":"code","0f58103a":"code","3df17665":"code","0ff984d9":"code","f9ea9460":"code","99ccf981":"code","f46e1ab2":"code","8e016826":"code","fd00a046":"code","b2d6896b":"code","c8e6edc0":"code","b1d3ca05":"code","39f6989f":"code","b17db7b6":"code","9fa67cb9":"code","91592618":"markdown","706a5c84":"markdown","c9dea572":"markdown","0724ed3b":"markdown","4bbb8ce4":"markdown","ca32ed65":"markdown","13735dac":"markdown","d19a7020":"markdown","baa79433":"markdown","ef0fa841":"markdown","83db9b68":"markdown","99cbe772":"markdown","34556d56":"markdown","0e2d11ca":"markdown","6c3c0636":"markdown","81342e05":"markdown","7c76c1ef":"markdown","9d5a4a9d":"markdown","14f1127e":"markdown","ccd0ccff":"markdown","dba247d4":"markdown","7fb38c1e":"markdown","d6fd9a56":"markdown","2e19a307":"markdown","a800a34a":"markdown","71bfbc7e":"markdown","5bb00914":"markdown","1cec0f9c":"markdown","8175e2e4":"markdown","5baee599":"markdown","b045f3b5":"markdown","209504de":"markdown","14d4064d":"markdown","fcfe486e":"markdown","9dc76e83":"markdown","08afb44b":"markdown","6d7e0dad":"markdown","b4584905":"markdown","5ad3c608":"markdown","7cf45b98":"markdown","9cf3d44e":"markdown","902eb244":"markdown","d58be189":"markdown","5fd1ba96":"markdown","29a6ef1c":"markdown","4a53d055":"markdown","30dffef0":"markdown","e5a5809f":"markdown","904ce4dd":"markdown","c6b3fac1":"markdown","cfb6682a":"markdown","1f19cedf":"markdown","86096a17":"markdown","853e1231":"markdown","38df615b":"markdown","c1f6e396":"markdown","0616271a":"markdown","cbd1527d":"markdown","a3271b00":"markdown","cf679c11":"markdown","f194fe4e":"markdown","933b0c55":"markdown","dd67289c":"markdown","cf08da8d":"markdown","36b84296":"markdown","430d23f8":"markdown","f455048e":"markdown","7a0e5f33":"markdown","c2c05a57":"markdown","de5aa44c":"markdown","fcdb651c":"markdown","2578a437":"markdown","09b30621":"markdown","2a220da0":"markdown","81b584b8":"markdown","a7617bc8":"markdown"},"source":{"0b8a7b43":"# Import das bibliotecas\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","642effe1":"# Import dos dados de treino e teste\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","863e92a5":"# Atribui\u00e7\u00e3o das vari\u00e1veis os dados de treino e teste\ndf_train = pd.read_csv(\"..\/input\/atividade-regressao-PMR3508\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/atividade-regressao-PMR3508\/test.csv\")","ca98c35c":"df_train.head()","6c8d36c6":"df_train.shape","f50ba0c2":"df_test.head()","960d09da":"df_test.shape","ab6d0fd2":"df_train.info()","a123a944":"df_train.describe()","59a2b24f":"!pip install -U pandas-profiling","b95b1bcc":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(df_train, title='Exploratory Analysis of California Housing',html={'style':{'full_width':True}});\nprofile","a93c3d3c":"eda = pd.plotting.scatter_matrix(df_train, alpha=0.2, figsize=(20, 20), diagonal='hist')","e7e811ee":"# Missing data\ndf_train.isnull().sum(axis = 0)","5b8f5355":"# Criando as vari\u00e1veis nos dados de treino\n\n# Hip\u00f3tese 1\ndf_train[\"person_per_house\"] = df_train[\"population\"] \/ df_train[\"households\"]\n\n# Hip\u00f3tese 2\ndf_train[\"income_per_person\"] = df_train[\"median_income\"] \/ df_train[\"person_per_house\"] \n\n# Hip\u00f3tese 3\ndf_train[\"bedrooms_per_person\"] = df_train[\"total_bedrooms\"] \/ df_train[\"population\"]\n\n# Hip\u00f3tese 4\ndf_train[\"rooms_per_person\"] = df_train[\"total_rooms\"] \/ df_train[\"population\"]\n\n# Hip\u00f3tese 5\ndf_train[\"bedrooms_per_households\"] = df_train[\"total_bedrooms\"] \/ df_train[\"households\"]\n\n# Hip\u00f3tese 6\ndf_train[\"rooms_per_households\"] = df_train[\"total_rooms\"] \/ df_train[\"households\"]\n\n\ndf_train.head()","bee6d7b6":"# Criando as vari\u00e1veis nos dados de teste\n\n# Hip\u00f3tese 1\ndf_test[\"person_per_house\"] = df_test[\"population\"] \/ df_test[\"households\"]\n\n# Hip\u00f3tese 2\ndf_test[\"income_per_person\"] = df_test[\"median_income\"] \/ df_test[\"person_per_house\"] \n\n# Hip\u00f3tese 3\ndf_test[\"bedrooms_per_person\"] = df_test[\"total_bedrooms\"] \/ df_test[\"population\"]\n\n# Hip\u00f3tese 4\ndf_test[\"rooms_per_person\"] = df_test[\"total_rooms\"] \/ df_test[\"population\"]\n\n# Hip\u00f3tese 5\ndf_test[\"bedrooms_per_households\"] = df_test[\"total_bedrooms\"] \/ df_test[\"households\"]\n\n# Hip\u00f3tese 6\ndf_test[\"rooms_per_households\"] = df_test[\"total_rooms\"] \/ df_test[\"households\"]\n\ndf_test.head()","06ffb225":"# Reorganizando a ordem das features e retirando o Id\ndf_train = df_train[['longitude', 'latitude', 'median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'person_per_house', 'income_per_person', 'bedrooms_per_person', 'rooms_per_person', 'bedrooms_per_households', 'rooms_per_households', 'median_house_value']]\nprint(df_train.info())\n\nprint(\"\\n\")\n\nteste_id = df_test.Id\n\n# Reorganizando a ordem das features e retirando o Id\ndf_test = df_test[['longitude', 'latitude', 'median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'person_per_house', 'income_per_person', 'bedrooms_per_person', 'rooms_per_person', 'bedrooms_per_households', 'rooms_per_households']]\nprint(df_test.info())","3733e2f1":"plt.figure(figsize=(15,15))\nplt.title(\"Matriz de correla\u00e7\u00e3o\")\nsns.heatmap(df_train.corr(), annot=True, linewidths=0.2);","51776249":"# Exclus\u00e3o das vari\u00e1veis com multicolinearidade\ndf_train = df_train.drop([\"total_bedrooms\", \"population\", \"households\", \"median_income\", \"bedrooms_per_person\", \"bedrooms_per_households\", \"rooms_per_households\"], axis = 1)\ndf_test = df_test.drop([\"total_bedrooms\", \"population\", \"households\", \"median_income\", \"bedrooms_per_person\", \"bedrooms_per_households\", \"rooms_per_households\"], axis = 1)","7e16e757":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\nscaler = MinMaxScaler()\ntrain_feat = list(df_train.columns)\nfeature_sel = train_feat[0:-1]\ndf_train_scaler = scaler.fit_transform(df_train[feature_sel])\n\nX_train, X_test, Y_train, Y_test = train_test_split(df_train_scaler, df_train['median_house_value'], test_size=0.20)","8a472a96":"df_test_scaler = scaler.fit_transform(df_test[feature_sel])","7434371e":"from sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import make_scorer\n\ndef RMSLE(y_test, y_pred):\n    return np.sqrt(mean_squared_log_error(np.abs(y_test), np.abs(y_pred)))\n\nscorer = make_scorer(RMSLE, greater_is_better=False)","0200be79":"# Import do regressor\nfrom sklearn.linear_model import LinearRegression\n\n# Instanciando o regressor\nlin_reg = LinearRegression()\n\n# Ver os parametros do modelo\nlin_reg.get_params()","a768ea0f":"# Import do GridSearch\nfrom sklearn.model_selection import GridSearchCV\n\n# Parametros para serem testados\ngrid_params_lin_reg = {'fit_intercept': [True, False],\n                       'normalize': [True, False]}\n\n# Instanciando o GridSearch com Cross validation de 10 folds\ngrid_lin_reg = GridSearchCV(lin_reg,\n                            grid_params_lin_reg,\n                            cv=10,\n                            scoring=scorer)\n\n# Fit do modelo\ngrid_lin_reg.fit(X_train, Y_train)\n\n# Print dos melhor hiper-parametros para o modelo\nprint(grid_lin_reg.best_estimator_)","00d261e6":"# Gera\u00e7\u00e3o de um moelo com os melhores hiper-parametros\nlin_reg = grid_lin_reg.best_estimator_\n\n# Fit do modelo\nlin_reg.fit(X_train, Y_train)\n\n# Predi\u00e7\u00e3o nos dados de teste\nY_pred = lin_reg.predict(X_test)\n\n# C\u00e1lculo do RMSLE\nlin_reg_RMSLE = RMSLE(Y_pred, Y_test)\nprint(\"RMSLE:\", lin_reg_RMSLE)","d0fb0f74":"# Score m\u00e9dio usando cross validation scorer\nlin_reg_score = np.mean(cross_val_score(lin_reg, X_train, Y_train, cv = 10))\nprint(\"Score:\", lin_reg_score)","5f6abc44":"# Cria\u00e7\u00e3o de listas para salvar os resultados\nregressor_name = []\nRMSLE_result = []\nScore_result = []\n\n# Adicionar dados a lista\nregressor_name.append(\"Linear Regression\")\nRMSLE_result.append(lin_reg_RMSLE)\nScore_result.append(lin_reg_score)\n\nprint(regressor_name)\nprint(RMSLE_result)\nprint(Score_result)","ebda1913":"from sklearn.linear_model import Ridge\n\nridge_reg = Ridge()\nridge_reg.get_params()","4aae5952":"grid_params_ridge = {\"alpha\":np.linspace(0.1,20,101).tolist()}\ngrid_ridge_reg = GridSearchCV(ridge_reg,grid_params_ridge,cv=10,scoring=scorer)\n\ngrid_ridge_reg.fit(X_train, Y_train)\nprint(grid_ridge_reg.best_estimator_)","beec6f3e":"ridge_reg = grid_ridge_reg.best_estimator_\nridge_reg.fit(X_train, Y_train)\nY_pred = ridge_reg.predict(X_test)\nridge_reg_RMSLE = RMSLE(Y_pred, Y_test)\nprint(\"RMSLE:\", ridge_reg_RMSLE)","b8c13925":"ridge_reg_score = np.mean(cross_val_score(ridge_reg, X_train, Y_train, cv = 10))\nridge_reg_score","d6cc7e8c":"regressor_name.append(\"Ridge\")\nRMSLE_result.append(ridge_reg_RMSLE)\nScore_result.append(ridge_reg_score)\n\nprint(regressor_name)\nprint(RMSLE_result)\nprint(Score_result)","0f58103a":"from sklearn.linear_model import Lasso\n\nlasso_reg = Lasso()\nlasso_reg.get_params()","3df17665":"grid_params_lasso_reg = {\"alpha\":np.linspace(0.1,20,100).tolist(),\n                        \"normalize\":[True,False]}\n\ngrid_lasso_reg = GridSearchCV(lasso_reg, grid_params_lasso_reg, cv=10, scoring=scorer);\n\ngrid_lasso_reg.fit(X_train, Y_train)\nprint(grid_lasso_reg.best_estimator_)","0ff984d9":"lasso_reg = grid_lasso_reg.best_estimator_\nlasso_reg.fit(X_train, Y_train)\nY_pred = lasso_reg.predict(X_test)\nlasso_reg_RMSLE = RMSLE(Y_pred, Y_test)\nprint(\"RMSLE:\", lasso_reg_RMSLE)","f9ea9460":"lasso_reg_score = np.mean(cross_val_score(lasso_reg, X_train, Y_train, cv = 10))\nlasso_reg_score","99ccf981":"regressor_name.append(\"Lasso\")\nRMSLE_result.append(lasso_reg_RMSLE)\nScore_result.append(lasso_reg_score)\n\nprint(regressor_name)\nprint(RMSLE_result)\nprint(Score_result)","f46e1ab2":"from sklearn.neighbors import KNeighborsRegressor\n\nknn_reg = KNeighborsRegressor()\nknn_reg.get_params()","8e016826":"grid_params_knn_reg = {\"n_neighbors\":[i for i in range(1,31)],\n                       \"weights\":[\"uniform\",\"distance\"],\n                       \"p\":[1,2]}\n\ngrid_knn_reg = GridSearchCV(knn_reg,grid_params_knn_reg,cv=10)\n\ngrid_knn_reg.fit(X_train, Y_train)\nprint(grid_knn_reg.best_estimator_)","fd00a046":"knn_reg = grid_knn_reg.best_estimator_\nknn_reg.fit(X_train, Y_train)\nY_pred = knn_reg.predict(X_test)\nknn_reg_RMSLE = RMSLE(Y_pred, Y_test)\nprint(\"RMSLE:\", knn_reg_RMSLE)","b2d6896b":"knn_reg_score = np.mean(cross_val_score(knn_reg, X_train, Y_train, cv = 10))\nknn_reg_score","c8e6edc0":"regressor_name.append(\"kNN\")\nRMSLE_result.append(knn_reg_RMSLE)\nScore_result.append(knn_reg_score)\n\nprint(regressor_name)\nprint(RMSLE_result)\nprint(Score_result)","b1d3ca05":"# Cria\u00e7\u00e3o de um DataFrame com os resultados\nresults = pd.DataFrame(list(zip(regressor_name, RMSLE_result, Score_result)),\n                       columns = [\"Regressor\", \"RMSLE\", \"Score\"])\nresults.sort_values(by=[\"RMSLE\"])","39f6989f":"# Predi\u00e7\u00e3o\nknn_reg.fit(X_train, Y_train)","b17db7b6":"# Cria\u00e7\u00e3o do csv para submiss\u00e3o\nY_pred = knn_reg.predict(df_test)\nsubmission = pd.DataFrame()\nsubmission[\"Id\"] = teste_id\nsubmission[\"median_house_value\"] = Y_pred\nsubmission.to_csv(\"submission.csv\", index = False)","9fa67cb9":"submission.head()","91592618":"Nesta etapa, foi feita uma an\u00e1lise explorat\u00f3ria dos dados, com objetivo de compreender melhor o banco de dados que estamos trabalhando. Para isso, foi feita uma descri\u00e7\u00e3o das vari\u00e1veis, avalio-se seus tipos, estat\u00edsticas descritivas, distribui\u00e7\u00f5es, correla\u00e7\u00f5es, al\u00e9m de alguns cruzamentos com a vari\u00e1vel <code>**median_house_value**<\/code>, que \u00e9 nossa vari\u00e1vel alvo neste estudo.","706a5c84":"Nesta etapa, vamos normalizar as vari\u00e1veis para que estas tenham a mesma ordem de grandeza","c9dea572":"O primeiro modelo testado foi a <code>**Regress\u00e3o Linear**<\/code>, para isso importamos o modelo do sklearn, fizemos a otimiza\u00e7\u00e3o dos hiper-parametros, treinamos o modelo, calculamos o RMSLE e o Score","0724ed3b":"Comparamos os erros dos algoritmos e escolher o com menor RMSLE (que \u00e9 a m\u00e9trica utilizada na competi\u00e7\u00e3o)","4bbb8ce4":"<a id=\"sec-7\"><\/a>\n## 7. Conclus\u00e3o","ca32ed65":"Calculamos o Score m\u00e9dio usando Cross Validation ","13735dac":"Geramos um modelo com os melhores parametros encontrados no GridSearch, treinamos o modelo e calculamos o erro (RMSLE)","d19a7020":"Primeiro importamos o regressor, instanciamos e vemos seus hiper-parametros","baa79433":"Ap\u00f3s testar diferentes modelos e otimizar seus hiperparametros verificamos que o kNN Regression foi o mais adequado para predizer o pre\u00e7o das casas da base de dados California Houseing.\n\nO modelo escolhido apresentou um RSMLE de 0.269 noa dados de treino, sendo o melhor entre os algoritmos testados. J\u00e1 na base de teste, o algoritmo apresentou um \u00f3timo desempenho, com um RSMLE de 0.065","ef0fa841":"Para uma melhor an\u00e1lise explorat\u00f3ria dos dados, foi utilizado o <code>ProfileReport<\/code> do <code>pandas<\/code>. Este report gera uma an\u00e1lise das vari\u00e1veis, intera\u00e7\u00f5es, correla\u00e7\u00f5ese e missing, de uma maneira f\u00e1cil e r\u00e1pida.\n\nPara mais informa\u00e7\u00f5es veja: **[GitHub Pandas Profiling](https:\/\/github.com\/pandas-profiling\/pandas-profiling)**","83db9b68":"<a id=\"sec-4\"><\/a>\n## 4. Desenvolvimento do regressor","99cbe772":"## 4.1 Normalizar as features","34556d56":"## Objetivo\n\nEste estudo tem como objetivo explorar os dados, compreendendo as vari\u00e1veis, fazendo o feature engineering e desenvolver um regressor capaz de prever o pre\u00e7o m\u00e9dio de uma casa na Calif\u00f3rnia. Para isso, alguns algoritmos foram testados e comparados atrav\u00e9s da m\u00e9trica RSMLE, sendo: \n* Regress\u00e3o linear\n* Regress\u00e3o Ridge\n* Regress\u00e3o Lasso\n* Regress\u00e3o kNN","0e2d11ca":"Verificamos os valores missing","6c3c0636":"Primeiro importamos o regressor, instanciamos e vemos seus hiper-parametros","81342e05":"Para analisar vari\u00e1veis n\u00famericas, pode-se usar o comando <code>**.describe()**<\/code> para avaliar estat\u00edsticas b\u00e1sicas","7c76c1ef":"O primeiro modelo testado foi a <code>**Regress\u00e3o Lasso**<\/code>, para isso importamos o modelo do sklearn, fizemos a otimiza\u00e7\u00e3o dos hiper-parametros, treinamos o modelo, calculamos o RMSLE e o Score","9d5a4a9d":"### 1.1 Import das bibliotecas","14f1127e":"Utilizamos o GridSearchCV para otimizar os hiper-parametros que passamos e fazemos o fit nos dados de treino","ccd0ccff":"Geramos um modelo com os melhores parametros encontrados no GridSearch, treinamos o modelo e calculamos o erro (RMSLE)","dba247d4":"Instala\u00e7\u00e3o do pandas-profiling:","7fb38c1e":"### Etapas\n\n1. [Prepara\u00e7\u00e3o dos dados](#sec-1)   \n2. [An\u00e1lise explorat\u00f3ria](#sec-2)\n3. [Pr\u00e9-processamento](#sec-3)\n4. [Desenvolvimento do regressor](#sec-4)\n5. [Compara\u00e7\u00e3o dos modelos](#sec-5)\n6. [Predi\u00e7\u00e3o e submiss\u00e3o](#sec-6)\n7. [Conclus\u00e3o](#sec-7)","d6fd9a56":"Primeiro importamos o regressor, instanciamos e vemos seus hiper-parametros","2e19a307":"### 2.3 An\u00e1lise com Pandas Profile Report","a800a34a":"Calculamos o Score m\u00e9dio usando Cross Validation ","71bfbc7e":"### 2.1 Descri\u00e7\u00e3o das vari\u00e1veis","5bb00914":"H\u00e1 10 vari\u00e1veis em nosso banco de dados, sendo que todas s\u00e3o n\u00famericas (float ou int). A seguir h\u00e1 a descri\u00e7\u00e3o das mesmas:\n\n1. <code>**Id**<\/code> identifica a observa\u00e7\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**longitude**<\/code> indica a longitude da casa (qu\u00e3o distante a oeste est\u00e1 a casa). Vari\u00e1vel num\u00e9rica.\n* <code>**latitude**<\/code> indica a latitude da casa (qu\u00e3o distante ao norte est\u00e1 a casa). Vari\u00e1vel num\u00e9rica.\n* <code>**median_age**<\/code> idade m\u00e9dia de uma casa dentro de um quarteir\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**total_rooms**<\/code> n\u00famero total de comodos em um quarteir\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**total_bedrooms**<\/code> n\u00famero total de comodos em um quarteir\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**population**<\/code> n\u00famero total de pessoas que moram no quarteir\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**households**<\/code> n\u00famero total de casas no quarteir\u00e3o. Vari\u00e1vel num\u00e9rica.\n* <code>**median_income**<\/code> renda m\u00e9dia das fam\u00edlias no quarteir\u00e3o (em d\u00f3lares). Vari\u00e1vel num\u00e9rica.\n* <code>**median_house_value**<\/code> pre\u00e7o m\u00e9dio das casas de um quarteir\u00e3o (em d\u00f3lares). Vari\u00e1vel num\u00e9rica.\n\t","1cec0f9c":"Utilizamos a mesma m\u00e9trica da competi\u00e7\u00e3o para avaliar nossos regressores, o <code>**RMSLE**<\/code>. Para isso criamos uma fun\u00e7\u00e3o e utilizamos uma m\u00e9trica j\u00e1 implementado no <code>**sklearn.metrics**<\/code>, o <code>**mean_squared_log_error**<\/code>. Al\u00e9m disso, criamos um <code>**Scorer**<\/code> que leva em conta o RSMLE","8175e2e4":"Calculamos o Score m\u00e9dio usando Cross Validation ","5baee599":"N\u00e3o h\u00e1 missing data, portanto podemos seguir com o pr\u00e9-processamento","b045f3b5":"### 3.1 Missing Data","209504de":"Nesta etapa, as vari\u00e1veis foram normalizadas, os diferente modelos foram desenvolvidos e seus hiper-parametros otimizados","14d4064d":"<a id=\"sec-3\"><\/a>\n## 3. Pr\u00e9-processamento","fcfe486e":"## 4.5 Regress\u00e3o Lasso","9dc76e83":"## 4.2 Defini\u00e7\u00e3o da m\u00e9trca de erro e Scorer","08afb44b":"Adicionamos os dados obtidos na lista","6d7e0dad":"Gera\u00e7\u00e3o do report a partir do banco de dados <code>**df_train()**<\/code>","b4584905":"<a id=\"sec-6\"><\/a>\n## 6. Predi\u00e7\u00e3o e Submiss\u00e3o","5ad3c608":"<a id=\"sec-5\"><\/a>\n## 5. Compara\u00e7\u00e3o dos modelos","7cf45b98":"Ap\u00f3s a importa\u00e7\u00e3o, os dados foram colcoados em dois DataFrames, um de treino e outro de test.\n\n**Obs:** a vari\u00e1vel <code>median_house_value<\/code> j\u00e1 foi retirada j\u00e1 que \u00e9 justamente a vari\u00e1vel target.","9cf3d44e":"Nesta etapa, foi feita a prepara\u00e7\u00e3o do ambiente importando das principais bibliotecas que foram utilizadas e a importa\u00e7\u00e3o da base de dados California Housing, j\u00e1 separada em treino e teste.","902eb244":"## 2.4 Vari\u00e1veis vs. Pre\u00e7o das casas","d58be189":"Adicionamos os dados obtidos na lista","5fd1ba96":"<a id=\"sec-2\"><\/a>\n## 2. An\u00e1lise explorat\u00f3ria","29a6ef1c":"Os dados de treino tem 14.448 observa\u00e7\u00f5es (70%)","4a53d055":"## 4.6 Regress\u00e3o kNN","30dffef0":"A seguir visualizamos as primeiras 5 linhas das bases de treino e teste","e5a5809f":"<a id=\"sec-1\"><\/a>\n## 1. Prepara\u00e7\u00e3o dos Dados","904ce4dd":"## 3.2 Feature Engineering","c6b3fac1":"Para evitar multicolinearidade entre as vari\u00e1veis, algumas foram retiradas:\n\n* total_bedrooms\n* population\n* households\n* median_income\n* bedrooms_per_person\n* bedrooms_per_households\n* rooms_per_households","cfb6682a":"## 4.3 Regress\u00e3o Linear","1f19cedf":"## 3.3 Feature Selection","86096a17":"O obsjetivo desta etapa \u00e9 gerar novas features a partir de hip\u00f3teses que est\u00e3o expostas a seguir","853e1231":"# Regression for the Dataset CaliforniaHousingP\u00e1gina\n\nEstudo da base de dados [California Housing](https:\/\/www.kaggle.com\/c\/atividade-regressao-PMR3508\/overview), para a disciplina de Aprendizado de M\u00e1quina - PMR3508.\n\n**Desenvolvido por:** Jo\u00e3o \u00c1lex de S\u00e1 Bugelli - n\u00ba 10281542\n","38df615b":"**Hip\u00f3teses:**\n\n1. Quanto mais pessoas por casa, menor o pre\u00e7o da casa;\n2. Quanto marior a renda por pessoa maior o pre\u00e7o da casa;\n3. Quanto mais quartos por pessoa maior o valor da casa;\n4. Quanto mais c\u00f4modos por pessoa maior o valor da casa;\n5. Quanto maior o n\u00famero m\u00e9dio de quartos por casa, maior o valor da casa;\n6. Quanto maior o n\u00famero m\u00e9dio de c\u00f4modo por casa, maior o valor da casa;\n\n**Vari\u00e1veis criadas:**\n\n1. <code>person_per_house<\/code> = population \/ households\n2. <code>income_per_person<\/code> = median_income \/ person_per_house\n3. <code>bedroom_per_person<\/code> = total_bedrooms \/ population\n4. <code>rooms_per_person<\/code> = total_rooms \/ population\n5. <code>bedroom_per_households<\/code> = total_bedrooms \/ households\n6. <code>rooms_per_households<\/code> = total_rooms \/ households","c1f6e396":"### 2.2 An\u00e1lise das vari\u00e1veis","0616271a":"Foi criado um gr\u00e1fico de dispers\u00e3o, com objetivo de entender a rela\u00e7\u00e3o entre as vari\u00e1veis do banco e a vari\u00e1vel target","cbd1527d":"O primeiro modelo testado foi a <code>**Regress\u00e3o kNN**<\/code>, para isso importamos o modelo do sklearn, fizemos a otimiza\u00e7\u00e3o dos hiper-parametros, treinamos o modelo, calculamos o RMSLE e o Score","a3271b00":"Nesta etapa, foi realizado o pr\u00e9-processamento dos dados, observando o missing data, fazendo o feature engineering e selecionando as features para o modelo.","cf679c11":"Tamb\u00e9m normalizamos as vari\u00e1veis nos dados de teste","f194fe4e":"Geramos um modelo com os melhores parametros encontrados no GridSearch, treinamos o modelo e calculamos o erro (RMSLE)","933b0c55":"Ap\u00f3s selecionarmos o modelo com o menor erro, vamos fazer a predi\u00e7\u00e3o na base de teste e gerar um csv com o <code>**Id**<\/code> e o <code>**sklearn.metrics**<\/code>","dd67289c":"Os dados de treino tem 6.192 observa\u00e7\u00f5es (30%)","cf08da8d":"Utilizamos o GridSearchCV para otimizar os hiper-parametros que passamos e fazemos o fit nos dados de treino","36b84296":"Utilizamos o GridSearchCV para otimizar os hiper-parametros que passamos e fazemos o fit nos dados de treino","430d23f8":"Primeiro importamos o regressor, instanciamos e vemos seus hiper-parametros","f455048e":"Criamos listas para salvar os resultados e adicionamos os dados obtidos na lista","7a0e5f33":"### 1.2 Import dos dados","c2c05a57":"Calculamos o Score m\u00e9dio usando Cross Validation ","de5aa44c":"O primeiro modelo testado foi a <code>**Regress\u00e3o Ridge**<\/code>, para isso importamos o modelo do sklearn, fizemos a otimiza\u00e7\u00e3o dos hiper-parametros, treinamos o modelo, calculamos o RMSLE e o Score","fcdb651c":"Utilizamos o GridSearchCV para otimizar os hiper-parametros que passamos e fazemos o fit nos dados de treino","2578a437":"Ap\u00f3s verificamos a rela\u00e7\u00e3o entre as vari\u00e1veis, podemos ver que a vari\u00e1vel <code>**median_income()**<\/code> apresenta uma rela\u00e7\u00e3o forte com a nossa vari\u00e1vel target","09b30621":"De modo geral:\n\n* <code>median_age<\/code> As casa tem em m\u00e9dia 28,7 anos (std 12,5, min 1, max 52), o que mostra uma certa varia\u00e7\u00e3o da idade das casas;\n* <code>total_rooms<\/code> A m\u00e9dia de c\u00f4modos no quarteir\u00e3o \u00e9 de 2622 (std 2145, min 2, max 39.320), o que mostra uma grande varia\u00e7\u00e3o no n\u00famero de c\u00f4modos da amostra;\n* <code>total_bedrooms<\/code> A m\u00e9dia do total de quartos no quarteir\u00e3o \u00e9 de 535 (std 416, min 2, max 645), o que tamb\u00e9m mostra uma grande varia\u00e7\u00e3o no n\u00famero de quartos entre as observa\u00e7\u00f5es;\n* <code>population<\/code> A popula\u00e7\u00e3o m\u00e9dia por quarteir\u00e3o \u00e9 de 1413 (std 416, min 3, max 28.566), o que mostra certa varia\u00e7\u00e3o com alguns quarteir\u00f5es com grande concentra\u00e7\u00e3o de pessoas.\n* <code>households<\/code> O n\u00famero m\u00e9dio de fam\u00edlias por quarteir\u00e3o \u00e9 de 496 (std 376, min 2, max 602), o que mostra uma grande varia\u00e7\u00e3o em torno da m\u00e9dia.\n* <code>median_income<\/code> A m\u00e9dia da renda m\u00e9dia das fam\u00edlias por quarteir\u00e3o \u00e9 de 38.747 d\u00f3lares (std 19.091, min 4.999, max 150.001), o que novamente apresenta uma grande varia\u00e7\u00e3o na amostra.\n* <code>median_house_value<\/code> O valor m\u00e9dio do pre\u00e7o m\u00e9dio das casas no quarteir\u00e3o \u00e9 de 207.556 d\u00f3lares (std 116.441, min 14.999, max 500.001)","2a220da0":"## 4.4 Regress\u00e3o Ridge","81b584b8":"Adicionamos os dados obtidos na lista","a7617bc8":"Geramos um modelo com os melhores parametros encontrados no GridSearch, treinamos o modelo e calculamos o erro (RMSLE)"}}