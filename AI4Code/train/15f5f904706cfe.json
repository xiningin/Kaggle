{"cell_type":{"61f79451":"code","cb70b549":"code","3ab713b0":"code","53fe36f5":"code","2a9f00bf":"code","e74c386c":"code","4b13a23b":"code","fd4554ef":"code","6aaf36e7":"code","ba14ef7a":"code","b721ec08":"code","4a29fc02":"code","bf723995":"code","89ce318b":"code","07a6261c":"code","fd232537":"code","27cdbc81":"code","027dd81a":"code","0137d2e9":"code","fb93152f":"code","62f46f53":"code","704f0ae4":"code","cdf054d3":"code","2b5aa768":"code","aa1b1929":"code","a7be550a":"code","c2e450b3":"code","1fa2d487":"code","6e28d9d3":"code","aad14582":"code","cea4187e":"code","a8460e51":"code","c757be85":"code","c050d512":"code","cd505f04":"code","c03e0a0b":"code","6e854144":"code","a9b6fa8d":"code","ba780ec5":"code","0e97b3fd":"code","1c5a157d":"code","1c992fbc":"code","66a5243b":"code","7a10f4a9":"code","cdfb1a4a":"code","a8f14be7":"code","a77f4d50":"code","c07e615c":"code","7ba8f25b":"code","b15d4d16":"code","81f7b3be":"code","3b94f744":"code","bcd33465":"code","3a59fcf9":"code","b04f9e29":"code","21a368c4":"code","e712a4ce":"markdown","3a8a004d":"markdown","65ab20d1":"markdown","163e0755":"markdown","5b6702f7":"markdown","66158462":"markdown","56e0b33c":"markdown","208208bb":"markdown","99316569":"markdown","c8f23794":"markdown","b22bca5c":"markdown","72219306":"markdown","1694fe50":"markdown","d969f917":"markdown","9ef0773c":"markdown","1f070c77":"markdown","6dd84ea8":"markdown","89145706":"markdown","8175042c":"markdown"},"source":{"61f79451":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\n#MUSIC PROCESS\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape,\\\nConv2DTranspose, LeakyReLU, Conv1D, AveragePooling1D, MaxPooling1D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","cb70b549":"Meta_Data_CSV = pd.read_csv(\"..\/input\/urbansound8k\/UrbanSound8K.csv\")","3ab713b0":"Path_Wav_List = []\nCategory_List = []\n\nfor path_number in range(8732):\n    File_Path_Name = \"..\/input\/urbansound8k\/fold\" + str(Meta_Data_CSV[\"fold\"][path_number]) + \"\/\" + Meta_Data_CSV[\"slice_file_name\"][path_number]\n    Path_Wav_List.append(File_Path_Name)\n    Category_List.append(Meta_Data_CSV[\"class\"][path_number])","53fe36f5":"Path_Wav_Series = pd.Series(Path_Wav_List,name=\"WAV\").astype(str)\nCategory_Series = pd.Series(Category_List,name=\"CATEGORY\")","2a9f00bf":"Main_Train_Data = pd.concat([Path_Wav_Series,Category_Series],axis=1)","e74c386c":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)","4b13a23b":"def noise_function(data):\n    noise_value = 0.009 * np.random.uniform() * np.amax(data)\n    data = data + noise_value * np.random.normal(size=data.shape[0])\n    \n    return data\n\n\n\ndef stretch_function(data,rate=0.8):\n    \n    return librosa.effects.time_stretch(data,rate)\n\n\n\ndef shift_function(data):\n    shift_range = int(np.random.uniform(-5,5) * 1000)\n    \n    return np.roll(data,shift_range)\n\n\n\ndef pitch_function(data,sampling_rate,pitch_factor=0.5):\n    \n    return librosa.effects.pitch_shift(data,sampling_rate,pitch_factor)\n\n\n\ndef extract_function(data):\n    \n    output_result = np.array([])\n    mean_zero = np.mean(librosa.feature.zero_crossing_rate(y=data).T,axis=0)\n    output_result = np.hstack((output_result,mean_zero))\n    \n    stft_output = np.abs(librosa.stft(data))\n    chroma_output = np.mean(librosa.feature.chroma_stft(S=stft_output,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,chroma_output))\n    \n    mfcc_output = np.mean(librosa.feature.mfcc(y=data,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,mfcc_output))\n    \n    root_output = np.mean(librosa.feature.rms(y=data).T,axis=0)\n    output_result = np.hstack((output_result,root_output))\n    \n    mel_output = np.mean(librosa.feature.melspectrogram(y=data,sr=sample_rate).T,axis=0)\n    output_result = np.hstack((output_result,mel_output))\n    \n    return output_result\n\n\n\ndef export_function(path):\n    \n    data,sample_rate = librosa.load(path,duration=1.0)\n    \n    output_One = extract_function(data)\n    result = np.array(output_One)\n    \n    noise_output = noise_function(data)\n    output_Two = extract_function(noise_output)\n    result = np.vstack((result,output_Two))\n    \n    stretch_output = stretch_function(data)\n    stretch_pitch = pitch_function(stretch_output,sample_rate)\n    output_Three = extract_function(stretch_pitch)\n    result = np.vstack((result,output_Three))\n    \n    return result","fd4554ef":"sample_rate = 22050","6aaf36e7":"x_Train = []\ny_Train = []\n\n\nfor path,category_wav in zip(Main_Train_Data.WAV,Main_Train_Data.CATEGORY):\n    \n    wav_features = export_function(path)\n    \n    for indexing in wav_features:\n        x_Train.append(indexing)\n        y_Train.append(category_wav)","ba14ef7a":"New_Features_Wav = pd.DataFrame(x_Train)\nNew_Features_Wav[\"CATEGORY\"] = y_Train\n\nNew_Features_Wav.to_csv(\"New_Wav_Features_Data.csv\",index=False)","b721ec08":"New_Features_Wav.head(-1)","4a29fc02":"print(New_Features_Wav[\"CATEGORY\"].value_counts())","bf723995":"OHE_Function = OneHotEncoder()","89ce318b":"Scaler_Function = StandardScaler()","07a6261c":"Part_X = New_Features_Wav.iloc[:,:-1].values\nPart_Y = New_Features_Wav[\"CATEGORY\"].values","fd232537":"print(Part_X.shape)\nprint(Part_Y.shape)","27cdbc81":"Part_Y_Encode = OHE_Function.fit_transform(np.array(Part_Y).reshape(-1,1)).toarray()","027dd81a":"print(Part_Y_Encode.shape)","0137d2e9":"xTrain,xTest,yTrain,yTest = train_test_split(Part_X,Part_Y_Encode,train_size=0.9,random_state=42,shuffle=True)","fb93152f":"print(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","62f46f53":"xTrain = Scaler_Function.fit_transform(xTrain)\nxTest = Scaler_Function.transform(xTest)","704f0ae4":"print(xTrain.shape)\nprint(xTest.shape)","cdf054d3":"xTrain = np.expand_dims(xTrain,axis=2)\nxTest = np.expand_dims(xTest,axis=2)","2b5aa768":"print(xTrain.shape)\nprint(xTest.shape)","aa1b1929":"output_labels = 10\ncompile_metrics = [\"accuracy\"]\ncompile_loss = \"categorical_crossentropy\"\ncompile_optimizer = \"adam\"","a7be550a":"Call_Back_Early_Stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\nCall_Back_Check = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_model\")","c2e450b3":"Model_Conv1D = Sequential()\n#\nModel_Conv1D.add(Conv1D(256,5,strides=1,padding=\"same\",activation=\"relu\",input_shape=(xTrain.shape[1],1)))\nModel_Conv1D.add(BatchNormalization())\nModel_Conv1D.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n#\nModel_Conv1D.add(Conv1D(256,5,strides=1,padding=\"same\",activation=\"relu\"))\nModel_Conv1D.add(Dropout(0.3))\nModel_Conv1D.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel_Conv1D.add(Conv1D(128,5,strides=1,padding=\"same\",activation=\"relu\"))\nModel_Conv1D.add(Dropout(0.3))\nModel_Conv1D.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n\n\nModel_Conv1D.add(Conv1D(64,5,strides=1,padding=\"same\",activation=\"relu\"))\nModel_Conv1D.add(Dropout(0.3))\nModel_Conv1D.add(MaxPooling1D(3,strides=2,padding=\"same\"))\n#\nModel_Conv1D.add(Flatten())\nModel_Conv1D.add(Dense(units=1024, activation='relu'))\nModel_Conv1D.add(Dropout(0.3))\n#\nModel_Conv1D.add(Dense(units=output_labels, activation='softmax'))","1fa2d487":"print(Model_Conv1D.summary())","6e28d9d3":"Model_Conv1D.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","aad14582":"Conv1D_Model = Model_Conv1D.fit(xTrain, yTrain, batch_size=64, epochs=50,\n                                validation_data=(xTest, yTest), callbacks=[Call_Back_Early_Stop,Call_Back_Check])","cea4187e":"plt.style.use(\"dark_background\")","a8460e51":"Grap_Data = pd.DataFrame(Conv1D_Model.history)\nGrap_Data.plot()","c757be85":"plt.plot(Conv1D_Model.history[\"accuracy\"])\nplt.plot(Conv1D_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","c050d512":"plt.plot(Conv1D_Model.history[\"loss\"])\nplt.plot(Conv1D_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","cd505f04":"Model_Results = Model_Conv1D.evaluate(xTest,yTest)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])","c03e0a0b":"prediction_test = Model_Conv1D.predict(xTest)\ny_prediction = OHE_Function.inverse_transform(prediction_test)\n\nyTest = OHE_Function.inverse_transform(yTest)","6e854144":"print(prediction_test[0:5])\nprint(\"---\"*20)\nprint(y_prediction[0:5])\nprint(\"---\"*20)\nprint(yTest[0:5])","a9b6fa8d":"conf_matrix = confusion_matrix(yTest, y_prediction)\nacc_score = accuracy_score(yTest, y_prediction)\nclass_report = classification_report(yTest, y_prediction)","ba780ec5":"sns.heatmap(conf_matrix, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Prediction', size=7)\nplt.ylabel('Main Labels', size=7)\nplt.show()","0e97b3fd":"print(acc_score)\nprint(\"---\"*20)\nprint(class_report)","1c5a157d":"X_train, X_test, Y_train, Y_test = train_test_split(Part_X, Part_Y_Encode, train_size=0.9, random_state = 42, shuffle=True)","1c992fbc":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","66a5243b":"X_train = X_train.reshape(X_train.shape[0], 18, 9, 1)\nX_test = X_test.reshape(X_test.shape[0], 18, 9, 1)","7a10f4a9":"print(X_train.shape)\nprint(X_test.shape)","cdfb1a4a":"Call_Back_Check_Conv2D = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_Conv2D_model\")","a8f14be7":"Model_Conv2D = Sequential()\n#\nModel_Conv2D.add(Conv2D(64,(3, 3),padding=\"same\",activation=\"relu\",input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n#\nModel_Conv2D.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.3))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n#\nModel_Conv2D.add(Conv2D(256, (3, 3), padding = \"same\", activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.3))\nModel_Conv2D.add(MaxPool2D(pool_size=(2, 2)))\n#\nModel_Conv2D.add(Flatten())\nModel_Conv2D.add(Dense(1024, activation = \"relu\"))\nModel_Conv2D.add(Dropout(0.5))\nModel_Conv2D.add(Dense(output_labels, activation = \"softmax\"))","a77f4d50":"Model_Conv2D.compile(optimizer=compile_optimizer,loss=compile_loss,metrics=compile_metrics)","c07e615c":"Conv2D_Model = Model_Conv2D.fit(X_train, Y_train, batch_size=64, epochs=50,\n                                validation_data=(X_test, Y_test), callbacks=[Call_Back_Early_Stop,Call_Back_Check_Conv2D])","7ba8f25b":"Grap_Data_Conv2D = pd.DataFrame(Conv2D_Model.history)\nGrap_Data_Conv2D.plot()","b15d4d16":"plt.plot(Conv2D_Model.history[\"accuracy\"])\nplt.plot(Conv2D_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","81f7b3be":"plt.plot(Conv2D_Model.history[\"loss\"])\nplt.plot(Conv2D_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","3b94f744":"Model_Results_Conv2D = Model_Conv2D.evaluate(X_test,Y_test)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_Conv2D[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results_Conv2D[1])","bcd33465":"prediction_test_Conv2D = Model_Conv2D.predict(X_test)\nprediction_test_Conv2D_Arg = np.argmax(prediction_test_Conv2D,axis=1)","3a59fcf9":"print(prediction_test_Conv2D_Arg)","b04f9e29":"y_prediction_Conv2D = OHE_Function.inverse_transform(prediction_test_Conv2D)","21a368c4":"print(y_prediction_Conv2D)","e712a4ce":"#### SPLITTING","3a8a004d":"#### PROCESS CHECKING","65ab20d1":"#### STRUCTURE","163e0755":"# PATH, LABEL, TRANSFORMATION","5b6702f7":"#### PREDICTION CHECKING","66158462":"# MODEL STRUCTURE WITH CONV1D","56e0b33c":"#### PREDICTION CHECKING","208208bb":"#### END OF THE PROJECT\nPlease check for the first step: https:\/\/www.kaggle.com\/brsdincer\/urban-sound-prediction-i-ai-ml-process","99316569":"#### DATA PROCESS AND SPLITTING FOR CONV2D","c8f23794":"# PACKAGES AND LIBRARIES","b22bca5c":"#### TRANSFORMATION AND EXPORTATION","72219306":"#### PREDICTION","1694fe50":"# DATA PROCESS AND ENGINEERING","d969f917":"#### PARAMETERS","9ef0773c":"#### MODEL STRUCTURE","1f070c77":"# PROCESS FUNCTIONS","6dd84ea8":"#### PREDICTION","89145706":"#### PROCESS CHECKING","8175042c":"# MODEL STRUCTURE WITH CONV2D"}}