{"cell_type":{"3e04e061":"code","8084d3b2":"code","7b6724c3":"code","50e991fb":"code","64015dac":"code","10c83421":"code","e4995fb8":"code","dd53cf66":"code","9ce50549":"code","7b9eaa2a":"markdown","6419d26c":"markdown","05867ee3":"markdown"},"source":{"3e04e061":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8084d3b2":"import pandas as pd\n\n# Read the data\nX = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice              \nX.drop(['SalePrice'], axis=1, inplace=True)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n                        X[cname].dtype == \"object\"]\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","7b6724c3":"\"\"\"from xgboost import XGBRegressor\n \nmodel = XGBRegressor()\n\nn_estimators = [100, 500, 900, 1000, 1300]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }\"\"\"\n","50e991fb":"'''from sklearn.model_selection import RandomizedSearchCV\n\nrandoms_cv = RandomizedSearchCV(estimator=model,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)'''","64015dac":"#randoms_cv.fit(X_train,y)","10c83421":"#randoms_cv.best_estimator_","e4995fb8":"from numpy import nan\nfrom xgboost import XGBRegressor\n\nmodel=XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=nan, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","dd53cf66":"model.fit(X_train,y)","9ce50549":"preds_test = model.predict(X_test)\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","7b9eaa2a":"Best Estimator:","6419d26c":"Run above three cells to get Best Estimator","05867ee3":"Hyper Parameter Optimization"}}