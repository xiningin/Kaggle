{"cell_type":{"a788b8bc":"code","7f4d9548":"code","4f4f2558":"code","6f354cd8":"code","07904c31":"code","2f1c1a27":"code","9c350fc9":"code","1044e38b":"markdown","a7d3f973":"markdown","38901cff":"markdown","eb438f2b":"markdown","dd8913fa":"markdown","a6e3c798":"markdown","914bf5aa":"markdown"},"source":{"a788b8bc":"import cv2\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport os","7f4d9548":"def shade_of_gray_cc(img, power=6, gamma=None):\n    \"\"\"\n    img (numpy array): the original image with format of (h, w, c)\n    power (int): the degree of norm, 6 is used in reference paper\n    gamma (float): the value of gamma correction, 2.2 is used in reference paper\n    \"\"\"\n    img_dtype = img.dtype\n\n    if gamma is not None:\n        img = img.astype('uint8')\n        look_up_table = np.ones((256,1), dtype='uint8') * 0\n        for i in range(256):\n            look_up_table[i][0] = 255 * pow(i\/255, 1\/gamma)\n        img = cv2.LUT(img, look_up_table)\n\n    img = img.astype('float32')\n    img_power = np.power(img, power)\n    rgb_vec = np.power(np.mean(img_power, (0,1)), 1\/power)\n    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n    rgb_vec = rgb_vec\/rgb_norm\n    rgb_vec = 1\/(rgb_vec*np.sqrt(3))\n    img = np.multiply(img, rgb_vec)\n\n    # Andrew Anikin suggestion\n    img = np.clip(img, a_min=0, a_max=255)\n    \n    return img.astype(img_dtype)","4f4f2558":"img_train_paths = glob(\"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/*.jpg\")\nimg_test_paths = glob(\"..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/*.jpg\")","6f354cd8":"_n_samples = 8\n\nfor path in img_train_paths[0:_n_samples]:\n    _img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(_img, cv2.COLOR_BGR2RGB)\n    img_cc = shade_of_gray_cc (img)  \n    _, (ax1,ax2) = plt.subplots(1, 2)\n    ax1.imshow(img)\n    ax2.imshow(img_cc)\n    plt.show()","07904c31":"def apply_cc (img_paths, output_folder_path, resize=None):\n    \n    if not os.path.isdir(output_folder_path):\n        os.mkdir(output_folder_path)    \n\n    with tqdm(total=len(img_paths), ascii=True, ncols=100) as t:\n        \n        for img_path in img_paths:\n            img_name = img_path.split('\/')[-1]\n            img_ = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            if resize is not None:\n                img_ = cv2.resize(img_, resize, cv2.INTER_AREA)\n            np_img = shade_of_gray_cc (img_)            \n            cv2.imwrite(os.path.join(output_folder_path, img_name.split('.')[0] + '.jpg'), np_img)\n            t.update()","2f1c1a27":"apply_cc (img_train_paths, 'cc_train\/', (224,224))","9c350fc9":"apply_cc (img_test_paths, 'cc_test\/', (224,224))","1044e38b":"**That's all folks!**\n\nI hope it was useful for you!","a7d3f973":"### Applying the color constacy method to the whole dataset","38901cff":"Testing the method and displaying random images to compare the image with and without color constancy","eb438f2b":"The function below was originally designed by [LincolnZjx](https:\/\/github.com\/LincolnZjx\/ISIC_2018_Classification) for the ISIC 2018 challenge.\n\nEdit: As [Andrew Anikin](https:\/\/www.kaggle.com\/andrewanikin) pointed out in comments, we shoud include `img = np.clip(img, a_min=0, a_max=255)` to avoid values above 255 in the image, which results in red, yellow, purple etc colors.","dd8913fa":"Applying the color constancy to the train folder","a6e3c798":"Applying the color constancy to the test folder","914bf5aa":"# Introduction\n\nThe paper [Improving dermoscopy image classification using color constancy](https:\/\/ieeexplore.ieee.org\/abstract\/document\/6866131\/) shows that using a color compensation technique to reduce the influence of the acquisition setup on the color features extracted from the images provides a improvement on the performance for skin cancer classification. \n\nIn ISIC 2019 challenge, the top three approaches in both tasks [[1]](https:\/\/isic-challenge-stade.s3.amazonaws.com\/99bdfa5c-4b6b-4c3c-94c0-f614e6a05bc4\/method_description.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=3myZOh3ZfEdZ5UFO8Z1DGmelRrk%3D&Expires=1593068545) [[2]](https:\/\/isic-challenge-stade.s3.amazonaws.com\/9e2e7c9c-480c-48dc-a452-c1dd577cc2b2\/ISIC2019-paper-0816.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=Up3vDSfqGwmf%2FS6nKDOlNSmKZug%3D&Expires=1593068545) [[3]](https:\/\/isic-challenge-stade.s3.amazonaws.com\/f6d46ceb-bf66-42ff-8b22-49562aefd4b8\/ISIC_2019.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=3XwGMDlkwcusfCwZ1Nk%2Fw5IFwUY%3D&Expires=1593068545) applied the Shades of Gray algorithm [[4]](https:\/\/pdfs.semanticscholar.org\/acf3\/6cdadfec869f136602ea41cad8b07e3f8ddb.pdf) as their color constancy method to improve their performance.\n\nThe goal of this notebook is to apply this algorithm to the current dataset and rise some discussion about this method."}}