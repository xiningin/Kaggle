{"cell_type":{"ee1d2d99":"code","86d180fd":"code","f6f97c74":"code","b0d9ad19":"code","bf039bb6":"code","38790a17":"code","c5e39dd8":"code","44eee9ba":"code","90856172":"code","5206522b":"code","10407ab1":"code","e118b0ad":"code","c205fae0":"code","c61e04f1":"markdown","d4f52b6c":"markdown","aeabcdef":"markdown","ba8077a4":"markdown","a5a3159a":"markdown","b87d9b6c":"markdown","b4a6f223":"markdown","868177f0":"markdown","23ca3d06":"markdown","c3842b4c":"markdown","a2928885":"markdown"},"source":{"ee1d2d99":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nimport time\nfrom PIL import Image\n\nfrom keras.datasets.fashion_mnist import load_data\n\nprint(tf.__version__)\n\nTPU_used = False\n\nif TPU_used:\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n    except ValueError:\n        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","86d180fd":"np.random.seed(1337)\nnum_classes = 10\n\nepochs = 30\nlatent_dim = 128\n\nadam_lr = 0.0002\nadam_beta_1 = 0.5","f6f97c74":"batch_size = 64\n(x_train, _), (x_test, _) = load_data()\nall_images = np.concatenate([x_train, x_test])\nall_images = all_images.astype(\"float32\") \/ 255\nall_images = np.reshape(all_images, (-1, 28, 28, 1))\ndataset = tf.data.Dataset.from_tensor_slices(all_images)\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)","b0d9ad19":"def define_discriminator():\n    model = tf.keras.Sequential(\n        [\n            layers.Conv2D(32, 3, strides=2, padding='same',\n                          input_shape=(28, 28, 1)),\n            layers.LeakyReLU(alpha=0.2),\n            layers.Dropout(0.5),\n            \n            layers.Conv2D(64, 3, padding='same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha=0.2),\n            layers.Dropout(0.5),\n            \n            layers.Conv2D(128, 3, strides=2, padding='same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha=0.2),\n            layers.Dropout(0.5),\n            \n            layers.Conv2D(256, 3, padding='same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(alpha=0.2),\n            layers.Dropout(0.5),\n            \n            layers.GlobalMaxPooling2D(),\n            layers.Dense(1, activation='sigmoid')\n        ]\n    )\n    \n    return model","bf039bb6":"if TPU_used:\n    with tpu_strategy.scope():\n        discriminator = define_discriminator()\nelse:\n    discriminator = define_discriminator()\ndiscriminator.summary()","38790a17":"def define_generator(latent_size):\n    model = tf.keras.Sequential(\n        [\n            layers.Dense(7 * 7 * 128, input_dim=latent_size),\n            layers.LeakyReLU(alpha=0.2),\n            layers.Reshape((7, 7, 128)),\n            \n            layers.Conv2DTranspose(128, 4, strides=2, padding='same',\n                                   kernel_initializer='glorot_normal'),\n            layers.LeakyReLU(alpha=0.2),\n            layers.BatchNormalization(),\n            \n            layers.Conv2DTranspose(128, 4, strides=2, padding='same',\n                                   kernel_initializer='glorot_normal'),\n            layers.LeakyReLU(alpha=0.2),\n            layers.BatchNormalization(),\n            \n            layers.Conv2D(1, 7, padding='same',\n                          activation='tanh',\n                          kernel_initializer='glorot_normal')\n        ]\n    )\n    \n    return model","c5e39dd8":"if TPU_used:\n    with tpu_strategy.scope():\n        generator = define_generator(latent_dim)\nelse:\n    generator = define_generator(latent_dim)\ngenerator.summary()","44eee9ba":"class GAN(tf.keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, real_images):\n        if isinstance(real_images, tuple):\n            real_images = real_images[0]\n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}","90856172":"class GANMonitor(tf.keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))","5206522b":"if TPU_used:\n    with tpu_strategy.scope():\n        gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n        gan.compile(\n            d_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n            g_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n            loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True,\n                                                       reduction=tf.keras.losses.Reduction.NONE),\n        )\nelse:\n    gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n    gan.compile(\n        d_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n        g_optimizer=tf.keras.optimizers.Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n        loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    )\n","10407ab1":"gan.fit(\n    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n)","e118b0ad":"!ls","c205fae0":"Image.open(\"generated_img_2_20.png\")","c61e04f1":"## 6. Train the model\n\nThe following function defines how the model is going to be trained. It is trained with a batch, half of which is real images and the other half is fake images created by the generator.\n\nRun the following cell to train the model.","d4f52b6c":"The random seed allows for the notebook to be reproducible. As there are the 10 classes in the Fashion MNIST dataset, we set the number of classes to to 10. The number of epochs is initially set to 30 but feel free to change the number of epochs. The learning rate and beta value will be used later when we compile our models.","aeabcdef":"Adapted from [Machine Learning Mastery Article](https:\/\/machinelearningmastery.com\/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras\/) and [Keras Training Override Example](https:\/\/github.com\/keras-team\/keras-io\/blob\/master\/examples\/generative\/dcgan_overriding_train_step.py)\n\n\nTensorFlow 1.x --> TensorFlow 2.x","ba8077a4":"## 7. Visualize images using created by the model","a5a3159a":"Let's now build our combined model.","b87d9b6c":"## 2. Building the discriminator\n\nTo build a GAN, a discriminator model must first be built. The discriminator takes an image in as its input and returns the probability that the image is real.\n\nWe define the method to build our discriminator in the following cell using the TensorFlow Keras API.\n\nConv2D is a convolution layer that applies a filter of a specified size (in this example, a 3x3 kernel, on each pixel). This allows for certain features to stand out.\n\nLeakyRelu is similar to a rectifier, but instead of having all negative values become 0, there is a small negative slope. This layer allows the model to find nonlinearities.\n\nDropout randomly ignores 0.5 of the input nodes. This prevents overfitting  by forcing to model to learn new features.","b4a6f223":"## 4. Building the generator\n\nLike the discriminator, the generator must also be built before we can move on to our GAN model.\n\nThe generator take in a random point from the latent space and a class label, and it returns a generated image that falls under the specified class label. A latent space is a way to represent condensed information in a way that similar datapoints have smaller distances between them.\n\nA point in the latent space can by used to create multiple 7x7 feature maps, and these maps, along with the feature map created by the class label, can be upcaled to a 14x14 and then a 28x28 image.\n\nBecause the generator is trained with the discriminator, it should not be compiled.","868177f0":"We will also create a subclass of the TensorFlow Keras Callback class called GANMonitor. Calling an instance of this subclass allows us to save a generated image at the end of each epoch to see how the model is improving.","23ca3d06":"# Introduction\n\nThis tutorial will go over how to train an ACGAN (auxiliary classifier generative adversarial network) using the Fashion MNIST dataset. An ACGAN model will generate images for a given condition, with the condition being a class.\n\nThe Fashion MNIST dataset is a datset consistng of 60000 training examples. Each example is a 28x28 image of an article of clothing, with each example falling under one of 10 classes.\n\nThe classes are as follows:\n0. T-shirt\n1. Trouser\n2. Pullover\n3. Dress\n4. Coat\n5. Sandal\n6. Shirt\n7. Sneaker\n8. Bag\n9. Ankle boot\n\nRun the following cell to download the necessary packages. If running on a TPU, change the ```TPU_used``` variable to true. Else, change the accelerator on the right to GPU.\n","c3842b4c":"## 5. Buiding the composite model.\n\nAs mentioned previously, the generator is trained using the discriminator model. The composite model will take in the same input as the generator, feed it into the generator, and the generated image will be fed into the discriminator. During training, we do not want to update the weights in the discriminator. The discriminator will be trained separately from within the composite model.\n\nWe are going to create a new class called GAN and it will be a subclass of the TensorFlow Keras Model class. By creating a new subclass, we can rewrite the train_step function, which will allow us to call ```model.fit()```. This reduces the code that we have to write to train this generative model and it allows for ease of readability.","a2928885":"## 1. Importing data\n\nThe following cell defines a function to import the Fashion MNIST dataset. As we are building a generative model, we don't need a separate testing set and all the images in the datset will be used as real images for our model.\n\nThe data is scaled so that the data is normalized to [0, 1] rather than [0, 255]. Normalizing the data is an important part of preprocessing."}}